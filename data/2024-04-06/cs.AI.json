{
  "date": "2024-04-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-06 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 44 篇论文，主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLMs）在多代理系统、医疗诊断和优化中的应用，以及图像处理和强化学习的创新亮点。其中，令人印象深刻的文章有第 4 篇 MACM（利用多代理系统提升 LLMs 在复杂数学推理的准确率，从 54.68% 提高到 76.73%）和第 10 篇（LLMs 作为肿瘤学决策引擎，实现高准确率的自主工具集成），这些工作展示了 LLMs 的潜力，同时涉及知名学者如 Nikolaus Schultz 和 Jakob Nikolas Kather。\n\n下面，我将挑选并简要讨论重点论文，先从 LLMs 和多代理相关主题入手，再聊医疗 AI 和优化领域，最后快速掠过其他次要文章。每个条目包括论文标题（中文 + 英文）和核心贡献，力求简洁明了。\n\n### LLMs 和多代理系统\n- **挑战大型语言模型在多代理聚群中的难题 / Challenges Faced by Large Language Models in Solving Multi-Agent Flocking**（第 1 篇）：这篇论文揭示了 LLMs 在多代理聚群任务中的局限性，如无法理解保持形状或距离，导致代理趋向于初始位置平均或分散。主要贡献是分析这些挑战，并建议未来改进协作空间推理。\n  \n- **利用多代理系统进行条件挖掘解决复杂数学问题 / MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems**（第 4 篇）：这是一篇印象深刻的作品，使用 MACM 方法提升 LLMs（如 GPT-4）在 MATH 数据集复杂数学问题的准确率，从 54.68% 提高到 76.73%。主要发现是多代理框架增强了泛化能力和逻辑推理，无需针对性提示设计。\n\n- **自治人工智能代理在肿瘤学临床决策中的应用 / Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology**（第 10 篇）：由知名学者 Jakob Nikolas Kather 等撰写，提出 LLMs 作为中心引擎协调多种医疗工具（如图像和基因分析），在肿瘤学场景中实现 93.6% 的正确结论和 89.2% 的有用推荐。主要贡献是构建可信赖的自治代理，简化监管合规。\n\n- **二分类器优化用于大型语言模型对齐 / Binary Classifier Optimization for Large Language Model Alignment**（第 14 篇）：这篇工作证明优化二分类器（作为奖励函数）隐式最小化 DPO 损失，实现 LLMs 的鲁棒对齐。主要发现是引入奖励偏移和分布匹配，提高了从二元反馈（如点赞/点踩）中学习的效果。\n\n### 医疗 AI 和图像处理\n- **ProtoAL: 基于原型的可解释深度主动学习在医疗图像中的应用 / ProtoAL: Interpretable Deep Active Learning with prototypes for medical imaging**（第 3 篇）：提出 ProtoAL 方法，将可解释深度模型集成到主动学习框架中，在 Messidor 数据集上仅用 76.54% 的标注数据达到 0.79 的精度-召回曲线面积。主要贡献是提升医疗图像诊断的解释性和数据效率。\n\n- **可解释的多模态学习用于心血管血流动力学评估 / Interpretable Multimodal Learning for Cardiovascular Hemodynamics Assessment**（第 5 篇）：由 Haiping Lu 等学者开发的多模态管道，使用张量学习和图注意力网络预测 PAWP 标记，在 2641 个样本上超越 SOTA 方法。主要发现是线性融合策略提升了模型的可解释性和临床筛查实用性。\n\n- **基于焦点主动学习的组织病理图像分类 / Focused Active Learning for Histopathological Image Classification**（第 12 篇）：提出 FocAL 方法，使用贝叶斯神经网络和异常检测处理图像模糊和不平衡，在 Panda 数据集中以 0.69% 的标注数据达到 0.764 的 Cohen's kappa。主要贡献是避免非信息性样本，提高病理图像分类的鲁棒性。\n\n- **泛视知觉：一个新的遥感图像解释任务和细粒度数据集 / Panoptic Perception: A Novel Task and Fine-Grained Dataset for Universal Remote Sensing Image Interpretation**（第 21 篇）：引入泛视知觉任务，结合像素级、实例级和图像级信息，在 FineGrip 数据集上实现多任务优化。主要发现是多任务交互提升了遥感图像的全面理解。\n\n### 强化学习和优化\n- **适应性多目标软件配置调优 / Adapting Multi-objectivized Software Configuration Tuning**（第 2 篇）：提出 AdMMO 方法，通过权重适应和重复保留机制，在 71% 的案例中比 SOTA 优化器快 2.2-20 倍。主要贡献是缓解局部最优陷阱，提高软件性能调优效率。\n\n- **组合保守主义：一种基于转导的离线强化学习方法 / Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning**（第 8 篇）：引入 COCOA 方法，在 D4RL 基准上提升离线 RL 算法性能，通过组合输入空间实现保守性。主要发现是独立于行为保守性的新视角。\n\n- **变换后探索：用于强化学习的简单有效技术 / Transform then Explore: a Simple and Effective Technique for Exploratory Combinatorial Optimization with Reinforcement Learning**（第 13 篇）：提出 gauge transformation 技术，使 RL 模型在测试时更好地探索组合优化问题，在 MaxCut 上达到 SOTA 性能。主要贡献是少于 10 行代码的简单实现。\n\n其他论文如生成模型（第 9、15、27 篇）和推荐系统（第 20、33 篇）等，虽然有创新，但相对次要，这里快速掠过：例如，第 20 篇 RecGPT 使用 GPT 框架生成个性化推荐提示；第 27 篇 BeyondScene 通过分层方法生成高分辨率人类中心场景。这些工作展示了 AI 在音乐生成和图像超分辨率的潜力，但未涉及重大突破，故不展开讨论。\n\n总之，今天的 arXiv 强调了 LLMs 在复杂任务中的扩展应用和 AI 的医疗优化潜力，读者可关注 MACM 和肿瘤学代理等高影响力论文。如果您对特定领域感兴趣，建议查看相关代码链接进行深入！",
  "papers": [
    {
      "arxiv_id": "2404.04752v2",
      "title": "Challenges Faced by Large Language Models in Solving Multi-Agent Flocking",
      "title_zh": "大型语言模型在解决多智能体聚群中面临的挑战",
      "authors": [
        "Peihan Li",
        "Vishnu Menon",
        "Bhavanaraj Gudiguntla",
        "Daniel Ting",
        "Lifeng Zhou"
      ],
      "abstract": "Flocking is a behavior where multiple agents in a system attempt to stay\nclose to each other while avoiding collision and maintaining a desired\nformation. This is observed in the natural world and has applications in\nrobotics, including natural disaster search and rescue, wild animal tracking,\nand perimeter surveillance and patrol. Recently, large language models (LLMs)\nhave displayed an impressive ability to solve various collaboration tasks as\nindividual decision-makers. Solving multi-agent flocking with LLMs would\ndemonstrate their usefulness in situations requiring spatial and decentralized\ndecision-making. Yet, when LLM-powered agents are tasked with implementing\nmulti-agent flocking, they fall short of the desired behavior. After extensive\ntesting, we find that agents with LLMs as individual decision-makers typically\nopt to converge on the average of their initial positions or diverge from each\nother. After breaking the problem down, we discover that LLMs cannot understand\nmaintaining a shape or keeping a distance in a meaningful way. Solving\nmulti-agent flocking with LLMs would enhance their ability to understand\ncollaborative spatial reasoning and lay a foundation for addressing more\ncomplex multi-agent tasks. This paper discusses the challenges LLMs face in\nmulti-agent flocking and suggests areas for future improvement and research.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在解决多智能体聚群（Multi-Agent Flocking）问题时的挑战，聚群涉及代理保持接近、避免碰撞并维持特定队形。研究通过广泛测试发现，LLMs 作为个体决策者通常导致代理收敛于初始位置的平均值或相互发散，原因是 LLMs 无法有效理解保持形状或距离等空间关系。论文强调，这些局限性突显了 LLMs 在协作空间推理方面的不足，并建议未来研究重点提升其能力，以支持更复杂的多智能体任务。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04752v2",
      "published_date": "2024-04-06 22:34:07 UTC",
      "updated_date": "2024-12-16 19:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:12:25.876716"
    },
    {
      "arxiv_id": "2404.04744v1",
      "title": "Adapting Multi-objectivized Software Configuration Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Chen",
        "Miqing Li"
      ],
      "abstract": "When tuning software configuration for better performance (e.g., latency or\nthroughput), an important issue that many optimizers face is the presence of\nlocal optimum traps, compounded by a highly rugged configuration landscape and\nexpensive measurements. To mitigate these issues, a recent effort has shifted\nto focus on the level of optimization model (called meta multi-objectivization\nor MMO) instead of designing better optimizers as in traditional methods. This\nis done by using an auxiliary performance objective, together with the target\nperformance objective, to help the search jump out of local optima. While\neffective, MMO needs a fixed weight to balance the two objectives-a parameter\nthat has been found to be crucial as there is a large deviation of the\nperformance between the best and the other settings. However, given the variety\nof configurable software systems, the \"sweet spot\" of the weight can vary\ndramatically in different cases and it is not possible to find the right\nsetting without time-consuming trial and error. In this paper, we seek to\novercome this significant shortcoming of MMO by proposing a weight adaptation\nmethod, dubbed AdMMO. Our key idea is to adaptively adjust the weight at the\nright time during tuning, such that a good proportion of the nondominated\nconfigurations can be maintained. Moreover, we design a partial duplicate\nretention mechanism to handle the issue of too many duplicate configurations\nwithout losing the rich information provided by the \"good\" duplicates.\n  Experiments on several real-world systems, objectives, and budgets show that,\nfor 71% of the cases, AdMMO is considerably superior to MMO and a wide range of\nstate-of-the-art optimizers while achieving generally better efficiency with\nthe best speedup between 2.2x and 20x.",
      "tldr_zh": "本研究针对软件配置调优中存在的局部最优陷阱、高度崎岖的配置景观和昂贵的测量成本，提出了一种自适应多目标化方法AdMMO，以解决传统MMO（meta multi-objectivization）对固定权重的依赖问题。AdMMO的核心在于动态调整权重，确保在调优过程中维持良好的non-dominated configurations比例，同时引入部分重复保留机制来处理重复配置并保留有用信息。实验结果显示，在多个真实系统中，AdMMO在71%的案例中显著优于MMO和其他最先进优化器，效率提升最高达20倍。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.SE",
      "comment": "This paper has been accepted at ACM FSE'24",
      "pdf_url": "http://arxiv.org/pdf/2404.04744v1",
      "published_date": "2024-04-06 22:08:09 UTC",
      "updated_date": "2024-04-06 22:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:12:37.728836"
    },
    {
      "arxiv_id": "2404.04736v1",
      "title": "ProtoAL: Interpretable Deep Active Learning with prototypes for medical imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Iury B. de A. Santos",
        "André C. P. L. F. de Carvalho"
      ],
      "abstract": "The adoption of Deep Learning algorithms in the medical imaging field is a\nprominent area of research, with high potential for advancing AI-based\nComputer-aided diagnosis (AI-CAD) solutions. However, current solutions face\nchallenges due to a lack of interpretability features and high data demands,\nprompting recent efforts to address these issues. In this study, we propose the\nProtoAL method, where we integrate an interpretable DL model into the Deep\nActive Learning (DAL) framework. This approach aims to address both challenges\nby focusing on the medical imaging context and utilizing an inherently\ninterpretable model based on prototypes. We evaluated ProtoAL on the Messidor\ndataset, achieving an area under the precision-recall curve of 0.79 while\nutilizing only 76.54\\% of the available labeled data. These capabilities can\nenhances the practical usability of a DL model in the medical field, providing\na means of trust calibration in domain experts and a suitable solution for\nlearning in the data scarcity context often found.",
      "tldr_zh": "本研究提出ProtoAL方法，将基于prototypes的可解释深度学习(DL)模型集成到Deep Active Learning(DAL)框架中，以解决医疗成像领域中模型可解释性不足和高数据需求的问题。该方法通过利用prototypes来提升模型的内在可解释性，并在医疗成像上下文中优化主动学习过程。在Messidor数据集上的实验显示，ProtoAL仅使用76.54%的标记数据就达到了0.79的precision-recall曲线面积(AUC)，从而提高了DL模型在数据稀缺场景中的实用性和领域专家的信任水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04736v1",
      "published_date": "2024-04-06 21:39:49 UTC",
      "updated_date": "2024-04-06 21:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:12:50.123141"
    },
    {
      "arxiv_id": "2404.04735v2",
      "title": "MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems",
      "title_zh": "MACM：利用多智能体系统进行条件挖掘以解决复杂数学问题",
      "authors": [
        "Bin Lei",
        "Yi Zhang",
        "Shan Zuo",
        "Ali Payani",
        "Caiwen Ding"
      ],
      "abstract": "Recent advancements in large language models, such as GPT-4, have\ndemonstrated remarkable capabilities in processing standard queries. Despite\nthese advancements, their performance substantially declines in\n\\textbf{advanced mathematical problems requiring complex, multi-step logical\nreasoning}. To enhance their inferential capabilities, current research has\ndelved into \\textit{prompting engineering}, exemplified by methodologies such\nas the Tree of Thought and Graph of Thought. Nonetheless, these existing\napproaches encounter two significant limitations. Firstly, their effectiveness\nin tackling complex mathematical problems is somewhat constrained. Secondly,\nthe necessity to design distinct prompts for individual problems hampers their\ngeneralizability. In response to these limitations, this paper introduces the\n\\textit{Multi-Agent System for conditional Mining} (\\textbf{MACM}) prompting\nmethod. It not only resolves intricate mathematical problems but also\ndemonstrates strong generalization capabilities across various mathematical\ncontexts. With the assistance of MACM, the accuracy of GPT-4 Turbo on the most\nchallenging level five mathematical problems in the MATH dataset increase from\n$\\mathbf{54.68\\%} \\text{ to } \\mathbf{76.73\\%}$. The code is available in\n\\url{https://github.com/bin123apple/MACM}.",
      "tldr_zh": "本文研究发现，大型语言模型如 GPT-4 在处理复杂多步逻辑推理的先进数学问题时，准确率显著下降，而现有提示工程方法如 Tree of Thought 和 Graph of Thought 存在效果有限和缺乏通用性的局限。为此，提出 Multi-Agent System for Condition Mining (MACM) 提示方法，利用多智能体系统进行条件挖掘，以提升模型在复杂数学问题上的推理能力。实验结果显示，MACM 使 GPT-4 Turbo 在 MATH 数据集最难的级别五问题上的准确率从 54.68% 提高到 76.73%，并展示了强大的泛化能力。代码已开源，可从 GitHub 获取。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04735v2",
      "published_date": "2024-04-06 21:39:01 UTC",
      "updated_date": "2024-07-22 22:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:13:02.933958"
    },
    {
      "arxiv_id": "2404.04718v1",
      "title": "Interpretable Multimodal Learning for Cardiovascular Hemodynamics Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Prasun C Tripathi",
        "Sina Tabakhi",
        "Mohammod N I Suvon",
        "Lawrence Schöb",
        "Samer Alabed",
        "Andrew J Swift",
        "Shuo Zhou",
        "Haiping Lu"
      ],
      "abstract": "Pulmonary Arterial Wedge Pressure (PAWP) is an essential cardiovascular\nhemodynamics marker to detect heart failure. In clinical practice, Right Heart\nCatheterization is considered a gold standard for assessing cardiac\nhemodynamics while non-invasive methods are often needed to screen high-risk\npatients from a large population. In this paper, we propose a multimodal\nlearning pipeline to predict PAWP marker. We utilize complementary information\nfrom Cardiac Magnetic Resonance Imaging (CMR) scans (short-axis and\nfour-chamber) and Electronic Health Records (EHRs). We extract spatio-temporal\nfeatures from CMR scans using tensor-based learning. We propose a graph\nattention network to select important EHR features for prediction, where we\nmodel subjects as graph nodes and feature relationships as graph edges using\nthe attention mechanism. We design four feature fusion strategies: early,\nintermediate, late, and hybrid fusion. With a linear classifier and linear\nfusion strategies, our pipeline is interpretable. We validate our pipeline on a\nlarge dataset of $2,641$ subjects from our ASPIRE registry. The comparative\nstudy against state-of-the-art methods confirms the superiority of our\npipeline. The decision curve analysis further validates that our pipeline can\nbe applied to screen a large population. The code is available at\nhttps://github.com/prasunc/hemodynamics.",
      "tldr_zh": "这篇论文提出了一种可解释的多模态学习管道，用于预测心血管血流动力学标记 PAWP，从而帮助非侵入性筛查心力衰竭高风险患者。该管道结合 Cardiac Magnetic Resonance Imaging (CMR) 扫描和 Electronic Health Records (EHRs) 数据，通过张量-based learning 提取 CMR 的时空特征，并使用 graph attention network 建模 EHR 特征关系并选择关键要素。研究设计了 early、intermediate、late 和 hybrid 等四种特征融合策略，并采用线性分类器确保模型的可解释性；在 2,641 个受试者的 ASPIRE 注册数据集上验证，该方法优于现有技术，并经决策曲线分析证明适用于大规模人群筛查。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04718v1",
      "published_date": "2024-04-06 19:42:25 UTC",
      "updated_date": "2024-04-06 19:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:13:15.739105"
    },
    {
      "arxiv_id": "2404.04714v1",
      "title": "Data Poisoning Attacks on Off-Policy Policy Evaluation Methods",
      "title_zh": "针对脱策略策略评估方法的数据投毒攻击",
      "authors": [
        "Elita Lobo",
        "Harvineet Singh",
        "Marek Petrik",
        "Cynthia Rudin",
        "Himabindu Lakkaraju"
      ],
      "abstract": "Off-policy Evaluation (OPE) methods are a crucial tool for evaluating\npolicies in high-stakes domains such as healthcare, where exploration is often\ninfeasible, unethical, or expensive. However, the extent to which such methods\ncan be trusted under adversarial threats to data quality is largely unexplored.\nIn this work, we make the first attempt at investigating the sensitivity of OPE\nmethods to marginal adversarial perturbations to the data. We design a generic\ndata poisoning attack framework leveraging influence functions from robust\nstatistics to carefully construct perturbations that maximize error in the\npolicy value estimates. We carry out extensive experimentation with multiple\nhealthcare and control datasets. Our results demonstrate that many existing OPE\nmethods are highly prone to generating value estimates with large errors when\nsubject to data poisoning attacks, even for small adversarial perturbations.\nThese findings question the reliability of policy values derived using OPE\nmethods and motivate the need for developing OPE methods that are statistically\nrobust to train-time data poisoning attacks.",
      "tldr_zh": "这篇论文探讨了 Off-Policy Evaluation (OPE) 方法在高风险领域（如医疗）中的应用可靠性，重点考察其对数据毒化攻击的敏感性。研究者设计了一个通用攻击框架，利用影响函数（influence functions from robust statistics）来构建边缘性对抗扰动，以最大化策略价值估计错误。在多个医疗和控制数据集上的实验结果显示，现有的 OPE 方法即使面对小规模扰动，也容易产生显著错误，这质疑了其可靠性，并呼吁开发对训练时数据毒化攻击具有统计鲁棒性的新方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at UAI 2022",
      "pdf_url": "http://arxiv.org/pdf/2404.04714v1",
      "published_date": "2024-04-06 19:27:57 UTC",
      "updated_date": "2024-04-06 19:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:13:26.792911"
    },
    {
      "arxiv_id": "2404.04686v1",
      "title": "Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Taminul Islam",
        "Md. Alif Sheakh",
        "Mst. Sazia Tahosin",
        "Most. Hasna Hena",
        "Shopnil Akash",
        "Yousef A. Bin Jardan",
        "Gezahign Fentahun Wondmie",
        "Hiba-Allah Nafidi",
        "Mohammed Bourhia"
      ],
      "abstract": "Breast cancer has rapidly increased in prevalence in recent years, making it\none of the leading causes of mortality worldwide. Among all cancers, it is by\nfar the most common. Diagnosing this illness manually requires significant time\nand expertise. Since detecting breast cancer is a time-consuming process,\npreventing its further spread can be aided by creating machine-based forecasts.\nMachine learning and Explainable AI are crucial in classification as they not\nonly provide accurate predictions but also offer insights into how the model\narrives at its decisions, aiding in the understanding and trustworthiness of\nthe classification results. In this study, we evaluate and compare the\nclassification accuracy, precision, recall, and F-1 scores of five different\nmachine learning methods using a primary dataset (500 patients from Dhaka\nMedical College Hospital). Five different supervised machine learning\ntechniques, including decision tree, random forest, logistic regression, naive\nbayes, and XGBoost, have been used to achieve optimal results on our dataset.\nAdditionally, this study applied SHAP analysis to the XGBoost model to\ninterpret the model's predictions and understand the impact of each feature on\nthe model's output. We compared the accuracy with which several algorithms\nclassified the data, as well as contrasted with other literature in this field.\nAfter final evaluation, this study found that XGBoost achieved the best model\naccuracy, which is 97%.",
      "tldr_zh": "本研究针对乳腺癌在孟加拉国患者的分类问题，提出了一种基于监督机器学习的预测模型，并结合 Explainable AI 来提升模型的可解释性。研究使用决策树、随机森林、逻辑回归、朴素贝叶斯和 XGBoost 等五种算法，对来自 Dhaka Medical College Hospital 的 500 名患者数据集进行评估和比较，重点考察准确率、精确率、召回率和 F1 分数。结果显示，XGBoost 模型取得了最高的准确率（97%），并通过 SHAP 分析解释了特征对预测结果的影响。该方法不仅提高了乳腺癌诊断的效率，还增强了模型的可信度和临床应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for the Scientific Reports (Nature) journal. 32 pages, 12\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2404.04686v1",
      "published_date": "2024-04-06 17:23:21 UTC",
      "updated_date": "2024-04-06 17:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:13:38.843315"
    },
    {
      "arxiv_id": "2404.04682v1",
      "title": "Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yeda Song",
        "Dongwook Lee",
        "Gunhee Kim"
      ],
      "abstract": "Offline reinforcement learning (RL) is a compelling framework for learning\noptimal policies from past experiences without additional interaction with the\nenvironment. Nevertheless, offline RL inevitably faces the problem of\ndistributional shifts, where the states and actions encountered during policy\nexecution may not be in the training dataset distribution. A common solution\ninvolves incorporating conservatism into the policy or the value function to\nsafeguard against uncertainties and unknowns. In this work, we focus on\nachieving the same objectives of conservatism but from a different perspective.\nWe propose COmpositional COnservatism with Anchor-seeking (COCOA) for offline\nRL, an approach that pursues conservatism in a compositional manner on top of\nthe transductive reparameterization (Netanyahu et al., 2023), which decomposes\nthe input variable (the state in our case) into an anchor and its difference\nfrom the original input. Our COCOA seeks both in-distribution anchors and\ndifferences by utilizing the learned reverse dynamics model, encouraging\nconservatism in the compositional input space for the policy or value function.\nSuch compositional conservatism is independent of and agnostic to the prevalent\nbehavioral conservatism in offline RL. We apply COCOA to four state-of-the-art\noffline RL algorithms and evaluate them on the D4RL benchmark, where COCOA\ngenerally improves the performance of each algorithm. The code is available at\nhttps://github.com/runamu/compositional-conservatism.",
      "tldr_zh": "该论文针对离线强化学习（Offline RL）中的分布偏移问题，提出了一种新的方法：COmpositional COnservatism with Anchor-seeking (COCOA)，通过 transductive reparameterization 将状态分解为 anchor 和其差异，利用 learned reverse dynamics model 来实现 compositional conservatism，从而在输入空间中增强策略或价值函数的保守性。COCOA 与传统的 behavioral conservatism 独立，并可应用于多种算法。实验结果显示，在 D4RL benchmark 上，COCOA 显著提升了四个 state-of-the-art 算法的整体性能，为离线 RL 的鲁棒性提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04682v1",
      "published_date": "2024-04-06 17:02:18 UTC",
      "updated_date": "2024-04-06 17:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:13:50.051076"
    },
    {
      "arxiv_id": "2404.05765v1",
      "title": "A Novel Bi-LSTM And Transformer Architecture For Generating Tabla Music",
      "title_zh": "一种新颖的 Bi-LSTM 和 Transformer 架构用于生成 Tabla 音乐",
      "authors": [
        "Roopa Mayya",
        "Vivekanand Venkataraman",
        "Anwesh P R",
        "Narayana Darapaneni"
      ],
      "abstract": "Introduction: Music generation is a complex task that has received\nsignificant attention in recent years, and deep learning techniques have shown\npromising results in this field. Objectives: While extensive work has been\ncarried out on generating Piano and other Western music, there is limited\nresearch on generating classical Indian music due to the scarcity of Indian\nmusic in machine-encoded formats. In this technical paper, methods for\ngenerating classical Indian music, specifically tabla music, is proposed.\nInitially, this paper explores piano music generation using deep learning\narchitectures. Then the fundamentals are extended to generating tabla music.\nMethods: Tabla music in waveform (.wav) files are pre-processed using the\nlibrosa library in Python. A novel Bi-LSTM with an Attention approach and a\ntransformer model are trained on the extracted features and labels. Results:\nThe models are then used to predict the next sequences of tabla music. A loss\nof 4.042 and MAE of 1.0814 are achieved with the Bi-LSTM model. With the\ntransformer model, a loss of 55.9278 and MAE of 3.5173 are obtained for tabla\nmusic generation. Conclusion: The resulting music embodies a harmonious fusion\nof novelty and familiarity, pushing the limits of music composition to new\nhorizons.",
      "tldr_zh": "这篇论文提出了一种新颖的Bi-LSTM with Attention和Transformer架构，用于生成古典印度Tabla音乐，以解决该领域数据稀缺的问题。方法包括使用librosa库预处理Tabla音乐的.wav文件，提取特征并训练模型预测后续序列。结果显示，Bi-LSTM模型在Tabla音乐生成中取得了较低的损失（4.042）和MAE（1.0814），而Transformer模型的损失为55.9278和MAE为3.5173。总体上，该研究推动了音乐生成技术的创新，使生成的音乐融合了新颖性和熟悉性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05765v1",
      "published_date": "2024-04-06 16:15:02 UTC",
      "updated_date": "2024-04-06 16:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:14:02.114742"
    },
    {
      "arxiv_id": "2404.04667v1",
      "title": "Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology",
      "title_zh": "自主人工智能代理用于肿瘤学临床决策",
      "authors": [
        "Dyke Ferber",
        "Omar S. M. El Nahhas",
        "Georg Wölflein",
        "Isabella C. Wiest",
        "Jan Clusmann",
        "Marie-Elisabeth Leßman",
        "Sebastian Foersch",
        "Jacqueline Lammert",
        "Maximilian Tschochohei",
        "Dirk Jäger",
        "Manuel Salto-Tellez",
        "Nikolaus Schultz",
        "Daniel Truhn",
        "Jakob Nikolas Kather"
      ],
      "abstract": "Multimodal artificial intelligence (AI) systems have the potential to enhance\nclinical decision-making by interpreting various types of medical data.\nHowever, the effectiveness of these models across all medical fields is\nuncertain. Each discipline presents unique challenges that need to be addressed\nfor optimal performance. This complexity is further increased when attempting\nto integrate different fields into a single model. Here, we introduce an\nalternative approach to multimodal medical AI that utilizes the generalist\ncapabilities of a large language model (LLM) as a central reasoning engine.\nThis engine autonomously coordinates and deploys a set of specialized medical\nAI tools. These tools include text, radiology and histopathology image\ninterpretation, genomic data processing, web searches, and document retrieval\nfrom medical guidelines. We validate our system across a series of clinical\noncology scenarios that closely resemble typical patient care workflows. We\nshow that the system has a high capability in employing appropriate tools\n(97%), drawing correct conclusions (93.6%), and providing complete (94%), and\nhelpful (89.2%) recommendations for individual patient cases while consistently\nreferencing relevant literature (82.5%) upon instruction. This work provides\nevidence that LLMs can effectively plan and execute domain-specific models to\nretrieve or synthesize new information when used as autonomous agents. This\nenables them to function as specialist, patient-tailored clinical assistants.\nIt also simplifies regulatory compliance by allowing each component tool to be\nindividually validated and approved. We believe, that our work can serve as a\nproof-of-concept for more advanced LLM-agents in the medical domain.",
      "tldr_zh": "这篇论文提出了一种自主AI代理系统，用于肿瘤学临床决策，采用大型语言模型(LLM)作为中央推理引擎来协调多种专业医疗工具，包括文本、放射学图像、组织病理学图像、基因组数据处理、网络搜索和医疗指南文档检索。系统在模拟真实患者护理流程的肿瘤学场景中进行验证，表现出色：97%正确使用工具、93.6%得出正确结论、94%提供完整推荐以及89.2%提供有帮助建议，同时82.5%能引用相关文献。该方法证明了LLM作为自主代理的有效性，能简化监管合规，并为医疗领域更先进的LLM应用提供证明概念。",
      "categories": [
        "cs.AI",
        "q-bio.TO"
      ],
      "primary_category": "cs.AI",
      "comment": "91 pages, 2 Figures",
      "pdf_url": "http://arxiv.org/pdf/2404.04667v1",
      "published_date": "2024-04-06 15:50:19 UTC",
      "updated_date": "2024-04-06 15:50:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:14:14.962886"
    },
    {
      "arxiv_id": "2404.04665v1",
      "title": "Adaptive Intra-Class Variation Contrastive Learning for Unsupervised Person Re-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Lingzhi Liu",
        "Haiyang Zhang",
        "Chengwei Tang",
        "Tiantian Zhang"
      ],
      "abstract": "The memory dictionary-based contrastive learning method has achieved\nremarkable results in the field of unsupervised person Re-ID. However, The\nmethod of updating memory based on all samples does not fully utilize the\nhardest sample to improve the generalization ability of the model, and the\nmethod based on hardest sample mining will inevitably introduce false-positive\nsamples that are incorrectly clustered in the early stages of the model.\nClustering-based methods usually discard a significant number of outliers,\nleading to the loss of valuable information. In order to address the issues\nmentioned before, we propose an adaptive intra-class variation contrastive\nlearning algorithm for unsupervised Re-ID, called AdaInCV. And the algorithm\nquantitatively evaluates the learning ability of the model for each class by\nconsidering the intra-class variations after clustering, which helps in\nselecting appropriate samples during the training process of the model. To be\nmore specific, two new strategies are proposed: Adaptive Sample Mining (AdaSaM)\nand Adaptive Outlier Filter (AdaOF). The first one gradually creates more\nreliable clusters to dynamically refine the memory, while the second can\nidentify and filter out valuable outliers as negative samples.",
      "tldr_zh": "本文提出了一种针对无监督人重识别（Unsupervised Person Re-ID）的自适应类内变异对比学习算法（AdaInCV），旨在解决现有方法在样本利用和泛化能力方面的不足，如基于所有样本更新内存忽略最难样本（hardest sample），或引入假阳性样本（false-positive samples）。该算法通过量化评估聚类后的类内变异（intra-class variations）来选择合适的训练样本，引入两个新策略：自适应样本挖掘（AdaSaM）用于逐步构建更可靠的聚类以动态优化内存，以及自适应异常值过滤（AdaOF）用于识别并过滤有价值的异常值（outliers）作为负样本。总体上，AdaInCV 提升了模型的泛化能力和信息利用效率，为无监督 Re-ID 任务提供了更有效的训练框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04665v1",
      "published_date": "2024-04-06 15:48:14 UTC",
      "updated_date": "2024-04-06 15:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:14:29.620956"
    },
    {
      "arxiv_id": "2404.04663v1",
      "title": "Focused Active Learning for Histopathological Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Arne Schmidt",
        "Pablo Morales-Álvarez",
        "Lee A. D. Cooper",
        "Lee A. Newberg",
        "Andinet Enquobahrie",
        "Aggelos K. Katsaggelos",
        "Rafael Molina"
      ],
      "abstract": "Active Learning (AL) has the potential to solve a major problem of digital\npathology: the efficient acquisition of labeled data for machine learning\nalgorithms. However, existing AL methods often struggle in realistic settings\nwith artifacts, ambiguities, and class imbalances, as commonly seen in the\nmedical field. The lack of precise uncertainty estimations leads to the\nacquisition of images with a low informative value. To address these\nchallenges, we propose Focused Active Learning (FocAL), which combines a\nBayesian Neural Network with Out-of-Distribution detection to estimate\ndifferent uncertainties for the acquisition function. Specifically, the\nweighted epistemic uncertainty accounts for the class imbalance, aleatoric\nuncertainty for ambiguous images, and an OoD score for artifacts. We perform\nextensive experiments to validate our method on MNIST and the real-world Panda\ndataset for the classification of prostate cancer. The results confirm that\nother AL methods are 'distracted' by ambiguities and artifacts which harm the\nperformance. FocAL effectively focuses on the most informative images, avoiding\nambiguities and artifacts during acquisition. For both experiments, FocAL\noutperforms existing AL approaches, reaching a Cohen's kappa of 0.764 with only\n0.69% of the labeled Panda data.",
      "tldr_zh": "这篇论文提出 Focused Active Learning (FocAL) 方法，用于改善组织病理图像分类中的数据标记效率，解决现有 Active Learning (AL) 方法在处理工件、模糊性和类别不平衡时的不足。FocAL 通过结合 Bayesian Neural Network 和 Out-of-Distribution (OoD) 检测，估计加权认知不确定性（weighted epistemic uncertainty）、偶然不确定性（aleatoric uncertainty）和 OoD 分数，从而优先选择最具信息价值的图像，避免无关干扰。实验结果显示，在 MNIST 和真实世界 Panda 数据集（前列腺癌分类）上，FocAL 优于其他 AL 方法，仅使用 0.69% 的标记数据就达到 Cohen's kappa 0.764。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04663v1",
      "published_date": "2024-04-06 15:31:57 UTC",
      "updated_date": "2024-04-06 15:31:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:14:40.370254"
    },
    {
      "arxiv_id": "2404.04661v1",
      "title": "Transform then Explore: a Simple and Effective Technique for Exploratory Combinatorial Optimization with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tianle Pu",
        "Changjun Fan",
        "Mutian Shen",
        "Yizhou Lu",
        "Li Zeng",
        "Zohar Nussinov",
        "Chao Chen",
        "Zhong Liu"
      ],
      "abstract": "Many complex problems encountered in both production and daily life can be\nconceptualized as combinatorial optimization problems (COPs) over graphs.\nRecent years, reinforcement learning (RL) based models have emerged as a\npromising direction, which treat the COPs solving as a heuristic learning\nproblem. However, current finite-horizon-MDP based RL models have inherent\nlimitations. They are not allowed to explore adquately for improving solutions\nat test time, which may be necessary given the complexity of NP-hard\noptimization tasks. Some recent attempts solve this issue by focusing on reward\ndesign and state feature engineering, which are tedious and ad-hoc. In this\nwork, we instead propose a much simpler but more effective technique, named\ngauge transformation (GT). The technique is originated from physics, but is\nvery effective in enabling RL agents to explore to continuously improve the\nsolutions during test. Morever, GT is very simple, which can be implemented\nwith less than 10 lines of Python codes, and can be applied to a vast majority\nof RL models. Experimentally, we show that traditional RL models with GT\ntechnique produce the state-of-the-art performances on the MaxCut problem.\nFurthermore, since GT is independent of any RL models, it can be seamlessly\nintegrated into various RL frameworks, paving the way of these models for more\neffective explorations in the solving of general COPs.",
      "tldr_zh": "本文提出了一种简单有效的技术 gauge transformation (GT)，用于解决强化学习 (RL) 在组合优化问题 (COPs) 中的探索局限性，该方法允许 RL 代理在测试时持续改进解决方案，而无需复杂的奖励设计或状态特征工程。GT 源自物理学，仅需不到 10 行 Python 代码即可实现，并适用于大多数 RL 模型。实验结果显示，在 MaxCut 问题上，传统 RL 模型结合 GT 达到了最先进性能，并可无缝集成到各种 RL 框架中，从而为更有效的 COPs 解决铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04661v1",
      "published_date": "2024-04-06 15:31:17 UTC",
      "updated_date": "2024-04-06 15:31:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:14:52.378624"
    },
    {
      "arxiv_id": "2404.04656v1",
      "title": "Binary Classifier Optimization for Large Language Model Alignment",
      "title_zh": "用于大语言模型对齐的二进制分类器优化",
      "authors": [
        "Seungjae Jung",
        "Gunsoo Han",
        "Daniel Wontae Nam",
        "Kyoung-Woon On"
      ],
      "abstract": "Aligning Large Language Models (LLMs) to human preferences through preference\noptimization has been crucial but labor-intensive, necessitating for each\nprompt a comparison of both a chosen and a rejected text completion by\nevaluators. Recently, Kahneman-Tversky Optimization (KTO) has demonstrated that\nLLMs can be aligned using merely binary \"thumbs-up\" or \"thumbs-down\" signals on\neach prompt-completion pair. In this paper, we present theoretical foundations\nto explain the successful alignment achieved through these binary signals. Our\nanalysis uncovers a new perspective: optimizing a binary classifier, whose\nlogit is a reward, implicitly induces minimizing the Direct Preference\nOptimization (DPO) loss. In the process of this discovery, we identified two\ntechniques for effective alignment: reward shift and underlying distribution\nmatching. Consequently, we propose a new algorithm, \\textit{Binary Classifier\nOptimization}, that integrates the techniques. We validate our methodology in\ntwo settings: first, on a paired preference dataset, where our method performs\non par with DPO and KTO; and second, on binary signal datasets simulating\nreal-world conditions with divergent underlying distributions between thumbs-up\nand thumbs-down data. Our model consistently demonstrates effective and robust\nalignment across two base LLMs and three different binary signal datasets,\nshowcasing the strength of our approach to learning from binary feedback.",
      "tldr_zh": "本论文探讨了使用二元信号（如“thumbs-up”或“thumbs-down”）对 Large Language Models (LLMs) 进行对齐优化的方法，以减少传统偏好优化的劳动密集型需求。研究通过理论分析揭示，优化二元分类器的 logit（奖励）会隐式最小化 Direct Preference Optimization (DPO) 损失，并引入 reward shift 和 underlying distribution matching 两种技术，进而提出新的 Binary Classifier Optimization 算法。实验结果显示，该算法在配对偏好数据集上与 DPO 和 Kahneman-Tversky Optimization (KTO) 相当，而在模拟真实世界二元信号数据集上表现出色，实现了更有效和鲁棒的模型对齐。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.04656v1",
      "published_date": "2024-04-06 15:20:59 UTC",
      "updated_date": "2024-04-06 15:20:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:15:04.581061"
    },
    {
      "arxiv_id": "2404.04642v1",
      "title": "Power-Efficient Image Storage: Leveraging Super Resolution Generative Adversarial Network for Sustainable Compression and Reduced Carbon Footprint",
      "title_zh": "翻译失败",
      "authors": [
        "Ashok Mondal",
        "Satyam Singh"
      ],
      "abstract": "In recent years, large-scale adoption of cloud storage solutions has\nrevolutionized the way we think about digital data storage. However, the\nexponential increase in data volume, especially images, has raised\nenvironmental concerns regarding power and resource consumption, as well as the\nrising digital carbon footprint emissions. The aim of this research is to\npropose a methodology for cloud-based image storage by integrating image\ncompression technology with SuperResolution Generative Adversarial Networks\n(SRGAN). Rather than storing images in their original format directly on the\ncloud, our approach involves initially reducing the image size through\ncompression and downsizing techniques before storage. Upon request, these\ncompressed images will be retrieved and processed by SRGAN to generate images.\nThe efficacy of the proposed method is evaluated in terms of PSNR and SSIM\nmetrics. Additionally, a mathematical analysis is given to calculate power\nconsumption and carbon footprint assesment. The proposed data compression\ntechnique provides a significant solution to achieve a reasonable trade off\nbetween environmental sustainability and industrial efficiency.",
      "tldr_zh": "本文提出了一种高效的图像存储方法，以缓解云存储图像数据增长导致的电力消耗和碳足迹问题。方法通过先对图像进行压缩和缩小处理后再存储，并在请求时利用 SuperResolution Generative Adversarial Networks (SRGAN) 生成高质量图像，实现可持续压缩。实验结果显示，该方法在 PSNR 和 SSIM 指标上表现出色，并通过数学分析证明了其在环境可持续性与工业效率之间的有效平衡。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG",
        "68T07",
        "I.2.m; H.3.2"
      ],
      "primary_category": "eess.IV",
      "comment": "5 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.04642v1",
      "published_date": "2024-04-06 14:27:22 UTC",
      "updated_date": "2024-04-06 14:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:15:15.713778"
    },
    {
      "arxiv_id": "2404.15193v2",
      "title": "Structurally Flexible Neural Networks: Evolving the Building Blocks for General Agents",
      "title_zh": "结构灵活的神经网络：演化构建块用于通用代理",
      "authors": [
        "Joachim Winther Pedersen",
        "Erwan Plantec",
        "Eleni Nisioti",
        "Milton Montero",
        "Sebastian Risi"
      ],
      "abstract": "Artificial neural networks used for reinforcement learning are structurally\nrigid, meaning that each optimized parameter of the network is tied to its\nspecific placement in the network structure. It also means that a network only\nworks with pre-defined and fixed input- and output sizes. This is a consequence\nof having the number of optimized parameters being directly dependent on the\nstructure of the network. Structural rigidity limits the ability to optimize\nparameters of policies across multiple environments that do not share input and\noutput spaces. Here, we evolve a set of neurons and plastic synapses each\nrepresented by a gated recurrent unit (GRU). During optimization, the\nparameters of these fundamental units of a neural network are optimized in\ndifferent random structural configurations. Earlier work has shown that\nparameter sharing between units is important for making structurally flexible\nneurons We show that it is possible to optimize a set of distinct neuron- and\nsynapse types allowing for a mitigation of the symmetry dilemma. We demonstrate\nthis by optimizing a single set of neurons and synapses to solve multiple\nreinforcement learning control tasks simultaneously.",
      "tldr_zh": "该论文探讨了强化学习(reinforcement learning)中神经网络(neural networks)的结构性刚性问题，即参数与固定网络结构绑定，导致无法跨不同输入输出环境的优化。研究者提出了一种演化方法，通过优化一组由门控循环单元(GRU)表示的神经元和可塑性突触，在随机结构配置中进行参数共享，以缓解对称性困境(symmetry dilemma)。这种结构灵活的框架允许同一组神经元和突触同时解决多个强化学习控制任务。实验结果证明，该方法有效提升了神经网络的泛化能力，为构建通用代理(general agents)提供了新途径。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15193v2",
      "published_date": "2024-04-06 14:04:14 UTC",
      "updated_date": "2024-05-17 09:21:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:15:28.329567"
    },
    {
      "arxiv_id": "2404.04626v1",
      "title": "Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Duanyu Feng",
        "Bowen Qin",
        "Chen Huang",
        "Zheng Zhang",
        "Wenqiang Lei"
      ],
      "abstract": "Direct Preference Optimization (DPO), which derives reward signals directly\nfrom pairwise preference data, has shown its effectiveness on aligning Large\nLanguage Models (LLMs) with human preferences. Despite its widespread use\nacross various tasks, DPO has been criticized for its sensitivity to the SFT's\neffectiveness and its hindrance to the learning capacity towards\nhuman-preferred responses, leading to less satisfactory performance. To\novercome those limitations, the theoretical understanding of DPO are\nindispensable but still lacking. To this end, we take a step towards\ntheoretically analyzing and understanding the limitations of DPO. Specifically,\nwe provide an analytical framework using the field theory to analyze the\noptimization process of DPO. By analyzing the gradient vector field of the DPO\nloss function, we find that the DPO loss function decreases the probability of\nproducing human dispreferred data at a faster rate than it increases the\nprobability of producing preferred data. This provides theoretical insights for\nunderstanding the limitations of DPO discovered in the related research\nexperiments, thereby setting the foundation for its improvement.",
      "tldr_zh": "本研究从理论角度分析了Direct Preference Optimization (DPO)在对齐Large Language Models (LLMs)时存在的局限性，包括对SFT有效性的敏感性和对人类偏好响应学习能力的阻碍。作者提出一个基于场理论的分析框架，通过考察DPO损失函数的梯度向量场，发现DPO更快速地降低人类不喜欢的输出概率，而非提升喜欢的输出概率。这种分析为解释相关实验中的DPO局限性提供了理论依据，并为改进DPO奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Draft version",
      "pdf_url": "http://arxiv.org/pdf/2404.04626v1",
      "published_date": "2024-04-06 13:24:37 UTC",
      "updated_date": "2024-04-06 13:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:15:40.203983"
    },
    {
      "arxiv_id": "2404.04619v1",
      "title": "Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zhonghan Zhao",
        "Ke Ma",
        "Wenhao Chai",
        "Xuan Wang",
        "Kewei Chen",
        "Dongxu Guo",
        "Yanting Zhang",
        "Hongwei Wang",
        "Gaoang Wang"
      ],
      "abstract": "With the power of large language models (LLMs), open-ended embodied agents\ncan flexibly understand human instructions, generate interpretable guidance\nstrategies, and output executable actions. Nowadays, Multi-modal Language\nModels~(MLMs) integrate multi-modal signals into LLMs, further bringing richer\nperception to entity agents and allowing embodied agents to perceive\nworld-understanding tasks more delicately. However, existing works: 1) operate\nindependently by agents, each containing multiple LLMs, from perception to\naction, resulting in gaps between complex tasks and execution; 2) train MLMs on\nstatic data, struggling with dynamics in open-ended scenarios; 3) input prior\nknowledge directly as prompts, suppressing application flexibility. We propose\nSTEVE-2, a hierarchical knowledge distillation framework for open-ended\nembodied tasks, characterized by 1) a hierarchical system for multi-granular\ntask division, 2) a mirrored distillation method for parallel simulation data,\nand 3) an extra expert model for bringing additional knowledge into parallel\nsimulation. After distillation, embodied agents can complete complex,\nopen-ended tasks without additional expert guidance, utilizing the performance\nand knowledge of a versatile MLM. Extensive evaluations on navigation and\ncreation tasks highlight the superior performance of STEVE-2 in open-ended\ntasks, with $1.4 \\times$ - $7.3 \\times$ in performance.",
      "tldr_zh": "本论文质疑复杂代理系统的必要性，提出 STEVE-2 框架，通过分层知识蒸馏将具身代理简化成单一模型，以解决现有系统在多 LLM 或 MLM 间的任务间隙、静态数据训练和知识输入灵活性问题。STEVE-2 采用分层系统进行多粒度任务划分、镜像蒸馏方法处理并行模拟数据，以及额外专家模型引入知识，使代理能在开放式任务中独立运作。实验评估显示，该框架在导航和创建任务上性能提升 1.4 倍至 7.3 倍，显著提高了效率和适用性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2403.08282",
      "pdf_url": "http://arxiv.org/pdf/2404.04619v1",
      "published_date": "2024-04-06 12:51:00 UTC",
      "updated_date": "2024-04-06 12:51:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:15:52.598935"
    },
    {
      "arxiv_id": "2404.04615v1",
      "title": "PointSAGE: Mesh-independent superresolution approach to fluid flow predictions",
      "title_zh": "PointSAGE：网格无关的超分辨率方法用于流体流动预测",
      "authors": [
        "Rajat Sarkar",
        "Krishna Sai Sudhir Aripirala",
        "Vishal Sudam Jadhav",
        "Sagar Srinivas Sakhinana",
        "Venkataramana Runkana"
      ],
      "abstract": "Computational Fluid Dynamics (CFD) serves as a powerful tool for simulating\nfluid flow across diverse industries. High-resolution CFD simulations offer\nvaluable insights into fluid behavior and flow patterns, aiding in optimizing\ndesign features or enhancing system performance. However, as resolution\nincreases, computational data requirements and time increase proportionately.\nThis presents a persistent challenge in CFD. Recently, efforts have been\ndirected towards accurately predicting fine-mesh simulations using coarse-mesh\nsimulations, with geometry and boundary conditions as input. Drawing\ninspiration from models designed for super-resolution, deep learning techniques\nlike UNets have been applied to address this challenge. However, these existing\nmethods are limited to structured data and fail if the mesh is unstructured due\nto its inability to convolute. Additionally, incorporating geometry/mesh\ninformation in the training process introduces drawbacks such as increased data\nrequirements, challenges in generalizing to unseen geometries for the same\nphysical phenomena, and issues with robustness to mesh distortions. To address\nthese concerns, we propose a novel framework, PointSAGE a mesh-independent\nnetwork that leverages the unordered, mesh-less nature of Pointcloud to learn\nthe complex fluid flow and directly predict fine simulations, completely\nneglecting mesh information. Utilizing an adaptable framework, the model\naccurately predicts the fine data across diverse point cloud sizes, regardless\nof the training dataset's dimension. We have evaluated the effectiveness of\nPointSAGE on diverse datasets in different scenarios, demonstrating notable\nresults and a significant acceleration in computational time in generating fine\nsimulations compared to standard CFD techniques.",
      "tldr_zh": "本文提出 PointSAGE，一种独立于网格的超分辨率框架，用于 Computational Fluid Dynamics (CFD) 流体流动预测。它利用 Pointcloud 的无序、无网格特性，直接从粗网格模拟学习并预测细网格模拟，避免了传统方法如 UNets 的局限性，包括对结构化数据依赖和泛化问题。实验在多样数据集上验证了 PointSAGE 的有效性，实现了显著的计算时间加速，同时保持了高准确性。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "Accepted at Data-Centric Machine Learning Workshop (DMLR) at ICLR,\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04615v1",
      "published_date": "2024-04-06 12:49:09 UTC",
      "updated_date": "2024-04-06 12:49:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:16:03.728258"
    },
    {
      "arxiv_id": "2404.08675v1",
      "title": "RecGPT: Generative Personalized Prompts for Sequential Recommendation via ChatGPT Training Paradigm",
      "title_zh": "翻译失败",
      "authors": [
        "Yabin Zhang",
        "Wenhui Yu",
        "Erhan Zhang",
        "Xu Chen",
        "Lantao Hu",
        "Peng Jiang",
        "Kun Gai"
      ],
      "abstract": "ChatGPT has achieved remarkable success in natural language understanding.\nConsidering that recommendation is indeed a conversation between users and the\nsystem with items as words, which has similar underlying pattern with ChatGPT,\nwe design a new chat framework in item index level for the recommendation task.\nOur novelty mainly contains three parts: model, training and inference. For the\nmodel part, we adopt Generative Pre-training Transformer (GPT) as the\nsequential recommendation model and design a user modular to capture\npersonalized information. For the training part, we adopt the two-stage\nparadigm of ChatGPT, including pre-training and fine-tuning. In the\npre-training stage, we train GPT model by auto-regression. In the fine-tuning\nstage, we train the model with prompts, which include both the newly-generated\nresults from the model and the user's feedback. For the inference part, we\npredict several user interests as user representations in an autoregressive\nmanner. For each interest vector, we recall several items with the highest\nsimilarity and merge the items recalled by all interest vectors into the final\nresult. We conduct experiments with both offline public datasets and online A/B\ntest to demonstrate the effectiveness of our proposed method.",
      "tldr_zh": "该论文提出RecGPT框架，将ChatGPT的训练范式应用于顺序推荐任务，将推荐视为用户与系统的对话。模型部分采用Generative Pre-training Transformer (GPT)作为推荐模型，并设计用户模块捕获个性化信息；训练部分包括预训练（自回归方式）和微调（使用包含模型输出和用户反馈的提示）；推理部分通过自回归预测用户兴趣向量，并召回相似度最高的物品合并为最终推荐结果。实验在离线公共数据集和在线A/B测试中证明了RecGPT的有效性，提升了推荐的个性化性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08675v1",
      "published_date": "2024-04-06 12:38:54 UTC",
      "updated_date": "2024-04-06 12:38:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:16:15.464262"
    },
    {
      "arxiv_id": "2404.04608v2",
      "title": "Panoptic Perception: A Novel Task and Fine-grained Dataset for Universal Remote Sensing Image Interpretation",
      "title_zh": "翻译失败",
      "authors": [
        "Danpei Zhao",
        "Bo Yuan",
        "Ziqiang Chen",
        "Tian Li",
        "Zhuoran Liu",
        "Wentao Li",
        "Yue Gao"
      ],
      "abstract": "Current remote-sensing interpretation models often focus on a single task\nsuch as detection, segmentation, or caption. However, the task-specific\ndesigned models are unattainable to achieve the comprehensive multi-level\ninterpretation of images. The field also lacks support for multi-task joint\ninterpretation datasets. In this paper, we propose Panoptic Perception, a novel\ntask and a new fine-grained dataset (FineGrip) to achieve a more thorough and\nuniversal interpretation for RSIs. The new task, 1) integrates pixel-level,\ninstance-level, and image-level information for universal image perception, 2)\ncaptures image information from coarse to fine granularity, achieving deeper\nscene understanding and description, and 3) enables various independent tasks\nto complement and enhance each other through multi-task learning. By\nemphasizing multi-task interactions and the consistency of perception results,\nthis task enables the simultaneous processing of fine-grained foreground\ninstance segmentation, background semantic segmentation, and global\nfine-grained image captioning. Concretely, the FineGrip dataset includes 2,649\nremote sensing images, 12,054 fine-grained instance segmentation masks\nbelonging to 20 foreground things categories, 7,599 background semantic masks\nfor 5 stuff classes and 13,245 captioning sentences. Furthermore, we propose a\njoint optimization-based panoptic perception model. Experimental results on\nFineGrip demonstrate the feasibility of the panoptic perception task and the\nbeneficial effect of multi-task joint optimization on individual tasks. The\ndataset will be publicly available.",
      "tldr_zh": "本论文提出了一种新型任务“Panoptic Perception”，旨在实现遥感图像（RSIs）的全面多级别解释，该任务整合像素级、实例级和图像级信息，从粗到细的粒度捕捉场景细节，并通过多任务学习增强任务间的互补性。论文引入了细粒度数据集FineGrip，包含2649张遥感图像、12054个细粒度实例分割掩码（20个前景类别）、7599个背景语义掩码（5个类别）和13245个图像描述句子，支持前景实例分割、背景语义分割及全局图像描述的联合优化。为此，作者设计了一个基于联合优化的全景感知模型，实验在FineGrip数据集上证明了该任务的可行性，并显示多任务联合优化显著提升了单个任务的性能，该数据集将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04608v2",
      "published_date": "2024-04-06 12:27:21 UTC",
      "updated_date": "2024-04-26 01:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:16:28.751765"
    },
    {
      "arxiv_id": "2404.05762v1",
      "title": "Evaluating the Effectiveness of Artificial Intelligence in Predicting Adverse Drug Reactions among Cancer Patients: A Systematic Review and Meta-Analysis",
      "title_zh": "评估人工智能在预测癌症患者不良药物反应的有效性：一项系统综述和荟萃分析",
      "authors": [
        "Fatma Zahra Abdeldjouad",
        "Menaouer Brahami",
        "Mohammed Sabri"
      ],
      "abstract": "Adverse drug reactions considerably impact patient outcomes and healthcare\ncosts in cancer therapy. Using artificial intelligence to predict adverse drug\nreactions in real time could revolutionize oncology treatment. This study aims\nto assess the performance of artificial intelligence models in predicting\nadverse drug reactions in patients with cancer. This is the first systematic\nreview and meta-analysis. Scopus, PubMed, IEEE Xplore, and ACM Digital Library\ndatabases were searched for studies in English, French, and Arabic from January\n1, 2018, to August 20, 2023. The inclusion criteria were: (1) peer-reviewed\nresearch articles; (2) use of artificial intelligence algorithms (machine\nlearning, deep learning, knowledge graphs); (3) study aimed to predict adverse\ndrug reactions (cardiotoxicity, neutropenia, nephrotoxicity, hepatotoxicity);\n(4) study was on cancer patients. The data were extracted and evaluated by\nthree reviewers for study quality. Of the 332 screened articles, 17 studies\n(5%) involving 93,248 oncology patients from 17 countries were included in the\nsystematic review, of which ten studies synthesized the meta-analysis. A\nrandom-effects model was created to pool the sensitivity, specificity, and AUC\nof the included studies. The pooled results were 0.82 (95% CI:0.69, 0.9), 0.84\n(95% CI:0.75, 0.9), and 0.83 (95% CI:0.77, 0.87) for sensitivity, specificity,\nand AUC, respectively, of ADR predictive models. Biomarkers proved their\neffectiveness in predicting ADRs, yet they were adopted by only half of the\nreviewed studies. The use of AI in cancer treatment shows great potential, with\nmodels demonstrating high specificity and sensitivity in predicting ADRs.\nHowever, standardized research and multicenter studies are needed to improve\nthe quality of evidence. AI can enhance cancer patient care by bridging the gap\nbetween data-driven insights and clinical expertise.",
      "tldr_zh": "本研究通过系统综述和荟萃分析，评估了人工智能（AI）模型在预测癌症患者不良药物反应（ADRs）方面的表现，这是该领域的首个此类研究。研究从多个数据库中筛选了2018年至2023年的332篇文章，最终纳入17篇研究，涉及93,248名患者，并使用随机效应模型汇总了AI模型的敏感性（0.82）、特异性（0.84）和AUC（0.83）。结果显示，AI模型在预测ADRs（如心毒性、中性粒细胞减少症）方面表现出色，生物标记物也证明有效，但仅被一半研究采用；未来需通过标准化和多中心研究来提升证据质量，以桥接数据洞见与临床实践。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Paper has been accepted at the IEEE Challenges and Innovations on TIC\n  (IEEE I2CIT) International Conference",
      "pdf_url": "http://arxiv.org/pdf/2404.05762v1",
      "published_date": "2024-04-06 11:20:28 UTC",
      "updated_date": "2024-04-06 11:20:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:16:42.014024"
    },
    {
      "arxiv_id": "2404.04587v2",
      "title": "Neuroevolving Electronic Dynamical Networks",
      "title_zh": "神经演化电子动态网络",
      "authors": [
        "Derek Whitley"
      ],
      "abstract": "Neuroevolution is a powerful method of applying an evolutionary algorithm to\nrefine the performance of artificial neural networks through natural selection;\nhowever, the fitness evaluation of these networks can be time-consuming and\ncomputationally expensive, particularly for continuous time recurrent neural\nnetworks (CTRNNs) that necessitate the simulation of differential equations. To\novercome this challenge, field programmable gate arrays (FPGAs) have emerged as\nan increasingly popular solution, due to their high performance and low power\nconsumption. Further, their ability to undergo dynamic and partial\nreconfiguration enables the extremely rapid evaluation of the fitness of\nCTRNNs, effectively addressing the bottleneck associated with conventional\nmethods of evolvable hardware. By incorporating fitness evaluation directly\nupon the programmable logic of the FPGA, hyper-parallel evaluation becomes\nfeasible, dramatically reducing the time required for assessment. This inherent\nparallelism of FPGAs accelerates the entire neuroevolutionary process by\nseveral orders of magnitude, facilitating faster convergence to an optimal\nsolution. The work presented in this study demonstrates the potential of\nutilizing dynamic and partial reconfiguration on capable FPGAs as a powerful\nplatform for neuroevolving dynamic neural networks.",
      "tldr_zh": "本研究探讨了Neuroevolution技术，即通过进化算法优化人工神经网络性能，但强调了评估过程（如CTRNNs的微分方程模拟）耗时高的问题。为解决这一瓶颈，论文提出利用FPGAs（现场可编程门阵列）进行动态和部分重新配置，实现超并行适应性评估，从而大幅加速神经进化过程。实验结果显示，这种方法可将评估时间减少数个数量级，促进更快收敛到最优解，并证明FPGAs是神经进化的强大平台。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.NE",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.04587v2",
      "published_date": "2024-04-06 10:54:35 UTC",
      "updated_date": "2024-04-17 14:50:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:16:52.128933"
    },
    {
      "arxiv_id": "2404.04575v3",
      "title": "To Cool or not to Cool? Temperature Network Meets Large Foundation Models via DRO",
      "title_zh": "翻译失败",
      "authors": [
        "Zi-Hao Qiu",
        "Siqi Guo",
        "Mao Xu",
        "Tuo Zhao",
        "Lijun Zhang",
        "Tianbao Yang"
      ],
      "abstract": "The temperature parameter plays a profound role during training and/or\ninference with large foundation models (LFMs) such as large language models\n(LLMs) and CLIP models. Particularly, it adjusts the logits in the softmax\nfunction in LLMs, which is crucial for next token generation, and it scales the\nsimilarities in the contrastive loss for training CLIP models. A significant\nquestion remains: Is it viable to learn a neural network to predict a\npersonalized temperature of any input data for enhancing LFMs\"? In this paper,\nwe present a principled framework for learning a small yet generalizable\ntemperature prediction network (TempNet) to improve LFMs. Our solution is\ncomposed of a novel learning framework with a robust loss underpinned by\nconstrained distributionally robust optimization (DRO), and a properly designed\nTempNet with theoretical inspiration. TempNet can be trained together with a\nlarge foundation model from scratch or learned separately given a pretrained\nfoundation model. It is not only useful for predicting personalized temperature\nto promote the training of LFMs but also generalizable and transferable to new\ntasks. Our experiments on LLMs and CLIP models demonstrate that TempNet greatly\nimproves the performance of existing solutions or models, e.g. Table 1. The\ncode to reproduce the experimental results in this paper can be found at\nhttps://github.com/zhqiu/TempNet.",
      "tldr_zh": "本研究探讨了温度参数在大型基础模型（LFMs，如 LLMs 和 CLIP models）中的关键作用，并提出了一种学习温度预测网络（TempNet）的框架，以提升模型性能。TempNet 采用基于约束分布鲁棒优化（DRO）的鲁棒损失函数和理论启发的设计，可与 LFMs 从零开始训练或单独应用于预训练模型，从而预测个性化温度并促进模型训练的泛化与转移。实验结果显示，TempNet 显著提高了 LLMs 和 CLIP models 的性能，例如在基准测试中超越现有解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "41 pages, 10 figures, accepted by ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04575v3",
      "published_date": "2024-04-06 09:55:03 UTC",
      "updated_date": "2024-06-16 12:43:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:17:04.217708"
    },
    {
      "arxiv_id": "2404.04564v1",
      "title": "Enhancing Video Summarization with Context Awareness",
      "title_zh": "利用上下文感知增强视频摘要",
      "authors": [
        "Hai-Dang Huynh-Lam",
        "Ngoc-Phuong Ho-Thi",
        "Minh-Triet Tran",
        "Trung-Nghia Le"
      ],
      "abstract": "Video summarization is a crucial research area that aims to efficiently\nbrowse and retrieve relevant information from the vast amount of video content\navailable today. With the exponential growth of multimedia data, the ability to\nextract meaningful representations from videos has become essential. Video\nsummarization techniques automatically generate concise summaries by selecting\nkeyframes, shots, or segments that capture the video's essence. This process\nimproves the efficiency and accuracy of various applications, including video\nsurveillance, education, entertainment, and social media. Despite the\nimportance of video summarization, there is a lack of diverse and\nrepresentative datasets, hindering comprehensive evaluation and benchmarking of\nalgorithms. Existing evaluation metrics also fail to fully capture the\ncomplexities of video summarization, limiting accurate algorithm assessment and\nhindering the field's progress. To overcome data scarcity challenges and\nimprove evaluation, we propose an unsupervised approach that leverages video\ndata structure and information for generating informative summaries. By moving\naway from fixed annotations, our framework can produce representative summaries\neffectively. Moreover, we introduce an innovative evaluation pipeline tailored\nspecifically for video summarization. Human participants are involved in the\nevaluation, comparing our generated summaries to ground truth summaries and\nassessing their informativeness. This human-centric approach provides valuable\ninsights into the effectiveness of our proposed techniques. Experimental\nresults demonstrate that our training-free framework outperforms existing\nunsupervised approaches and achieves competitive results compared to\nstate-of-the-art supervised methods.",
      "tldr_zh": "视频摘要技术旨在从海量视频内容中提取关键信息，但目前面临数据集多样性不足和评估指标不全面的问题，导致算法评估受限。  \n本文提出一个无监督方法，通过利用视频数据结构生成信息丰富的摘要，避免依赖固定标注，同时引入创新的人类参与评估管道，以比较生成摘要与真实摘要的信息性。  \n实验结果表明，该框架在性能上优于现有无监督方法，并与最先进的有监督方法竞争，为视频摘要应用（如监控、教育和社交媒体）提供了更有效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "115 pages, 1 supplementary paper, undergraduate thesis report at\n  US-VNUHCM",
      "pdf_url": "http://arxiv.org/pdf/2404.04564v1",
      "published_date": "2024-04-06 09:08:34 UTC",
      "updated_date": "2024-04-06 09:08:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:17:15.957915"
    },
    {
      "arxiv_id": "2404.04547v1",
      "title": "Exhaustive Exploitation of Nature-inspired Computation for Cancer Screening in an Ensemble Manner",
      "title_zh": "翻译失败",
      "authors": [
        "Xubin Wang",
        "Yunhe Wang",
        "Zhiqing Ma",
        "Ka-Chun Wong",
        "Xiangtao Li"
      ],
      "abstract": "Accurate screening of cancer types is crucial for effective cancer detection\nand precise treatment selection. However, the association between gene\nexpression profiles and tumors is often limited to a small number of biomarker\ngenes. While computational methods using nature-inspired algorithms have shown\npromise in selecting predictive genes, existing techniques are limited by\ninefficient search and poor generalization across diverse datasets. This study\npresents a framework termed Evolutionary Optimized Diverse Ensemble Learning\n(EODE) to improve ensemble learning for cancer classification from gene\nexpression data. The EODE methodology combines an intelligent grey wolf\noptimization algorithm for selective feature space reduction, guided random\ninjection modeling for ensemble diversity enhancement, and subset model\noptimization for synergistic classifier combinations. Extensive experiments\nwere conducted across 35 gene expression benchmark datasets encompassing varied\ncancer types. Results demonstrated that EODE obtained significantly improved\nscreening accuracy over individual and conventionally aggregated models. The\nintegrated optimization of advanced feature selection, directed specialized\nmodeling, and cooperative classifier ensembles helps address key challenges in\ncurrent nature-inspired approaches. This provides an effective framework for\nrobust and generalized ensemble learning with gene expression biomarkers.\nSpecifically, we have opened EODE source code on Github at\nhttps://github.com/wangxb96/EODE.",
      "tldr_zh": "本研究针对癌症筛查中基因表达谱与肿瘤关联有限的问题，提出了一种名为Evolutionary Optimized Diverse Ensemble Learning (EODE)的框架，利用nature-inspired算法提升癌症分类准确性。EODE结合智能grey wolf optimization algorithm进行特征空间减少、guided random injection modeling增强集成多样性，以及subset model optimization优化协同分类器组合。在35个基因表达基准数据集上的实验显示，EODE显著优于单个模型和传统聚合方法，提供了一个鲁棒且泛化的ensemble learning框架。该框架的开源代码已在GitHub上发布，助力进一步应用和改进。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04547v1",
      "published_date": "2024-04-06 08:07:48 UTC",
      "updated_date": "2024-04-06 08:07:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:17:28.419963"
    },
    {
      "arxiv_id": "2404.04544v1",
      "title": "BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion",
      "title_zh": "BeyondScene：基于预训练扩散模型的更高分辨率以人为中心场景生成",
      "authors": [
        "Gwanghyun Kim",
        "Hayeon Kim",
        "Hoigi Seo",
        "Dong Un Kang",
        "Se Young Chun"
      ],
      "abstract": "Generating higher-resolution human-centric scenes with details and controls\nremains a challenge for existing text-to-image diffusion models. This challenge\nstems from limited training image size, text encoder capacity (limited tokens),\nand the inherent difficulty of generating complex scenes involving multiple\nhumans. While current methods attempted to address training size limit only,\nthey often yielded human-centric scenes with severe artifacts. We propose\nBeyondScene, a novel framework that overcomes prior limitations, generating\nexquisite higher-resolution (over 8K) human-centric scenes with exceptional\ntext-image correspondence and naturalness using existing pretrained diffusion\nmodels. BeyondScene employs a staged and hierarchical approach to initially\ngenerate a detailed base image focusing on crucial elements in instance\ncreation for multiple humans and detailed descriptions beyond token limit of\ndiffusion model, and then to seamlessly convert the base image to a\nhigher-resolution output, exceeding training image size and incorporating\ndetails aware of text and instances via our novel instance-aware hierarchical\nenlargement process that consists of our proposed high-frequency injected\nforward diffusion and adaptive joint diffusion. BeyondScene surpasses existing\nmethods in terms of correspondence with detailed text descriptions and\nnaturalness, paving the way for advanced applications in higher-resolution\nhuman-centric scene creation beyond the capacity of pretrained diffusion models\nwithout costly retraining. Project page:\nhttps://janeyeon.github.io/beyond-scene.",
      "tldr_zh": "本文研究了现有文本-to-image扩散模型在生成高分辨率以人为中心的场景时面临的挑战，包括训练图像尺寸限制、文本编码器令牌容量和处理多个人的复杂性。提出BeyondScene框架，通过分阶段和分层方法，利用预训练diffusion models首先生成详细的基图像（聚焦于人类实例和超出令牌限制的描述），然后采用实例-aware hierarchical enlargement过程（包括high-frequency injected forward diffusion和adaptive joint diffusion）来实现超过8K分辨率的输出。实验结果显示，BeyondScene在文本-图像对应性和自然性上显著优于现有方法，为无需昂贵重新训练的高分辨率场景创建开辟新路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://janeyeon.github.io/beyond-scene",
      "pdf_url": "http://arxiv.org/pdf/2404.04544v1",
      "published_date": "2024-04-06 07:53:49 UTC",
      "updated_date": "2024-04-06 07:53:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:17:42.420864"
    },
    {
      "arxiv_id": "2404.04540v1",
      "title": "The Case for Developing a Foundation Model for Planning-like Tasks from Scratch",
      "title_zh": "翻译失败",
      "authors": [
        "Biplav Srivastava",
        "Vishal Pallagani"
      ],
      "abstract": "Foundation Models (FMs) have revolutionized many areas of computing,\nincluding Automated Planning and Scheduling (APS). For example, a recent study\nfound them useful for planning problems: plan generation, language translation,\nmodel construction, multi-agent planning, interactive planning, heuristics\noptimization, tool integration, and brain-inspired planning. Besides APS, there\nare many seemingly related tasks involving the generation of a series of\nactions with varying guarantees of their executability to achieve intended\ngoals, which we collectively call planning-like (PL) tasks like business\nprocesses, programs, workflows, and guidelines, where researchers have\nconsidered using FMs. However, previous works have primarily focused on\npre-trained, off-the-shelf FMs and optionally fine-tuned them. This paper\ndiscusses the need for a comprehensive FM for PL tasks from scratch and\nexplores its design considerations. We argue that such an FM will open new and\nefficient avenues for PL problem-solving, just like LLMs are creating for APS.",
      "tldr_zh": "本论文主张从零开发一个专门的 Foundation Model (FMs) 来处理 planning-like (PL) 任务，如业务流程、程序、工作流和指南，以弥补现有预训练模型的局限性。作者分析了 FMs 在 Automated Planning and Scheduling (APS) 领域的应用，包括计划生成、语言翻译和多智能体规划等，但指出这些工作主要依赖现成模型的微调，而非从头构建。论文探讨了这种新 FM 的设计考虑，包括其对 PL 任务的全面支持，并认为它将像 Large Language Models (LLMs) 对 APS 一样，开辟高效的 PL 问题解决新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04540v1",
      "published_date": "2024-04-06 07:44:40 UTC",
      "updated_date": "2024-04-06 07:44:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:17:52.960795"
    },
    {
      "arxiv_id": "2404.04538v1",
      "title": "Soft-Prompting with Graph-of-Thought for Multi-modal Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Juncheng Yang",
        "Zuchao Li",
        "Shuai Xie",
        "Wei Yu",
        "Shijun Li",
        "Bo Du"
      ],
      "abstract": "The chain-of-thought technique has been received well in multi-modal tasks.\nIt is a step-by-step linear reasoning process that adjusts the length of the\nchain to improve the performance of generated prompts. However, human thought\nprocesses are predominantly non-linear, as they encompass multiple aspects\nsimultaneously and employ dynamic adjustment and updating mechanisms.\nTherefore, we propose a novel Aggregation-Graph-of-Thought (AGoT) mechanism for\nsoft-prompt tuning in multi-modal representation learning. The proposed AGoT\nmodels the human thought process not only as a chain but also models each step\nas a reasoning aggregation graph to cope with the overlooked multiple aspects\nof thinking in single-step reasoning. This turns the entire reasoning process\ninto prompt aggregation and prompt flow operations. Experiments show that our\nmulti-modal model enhanced with AGoT soft-prompting achieves good results in\nseveral tasks such as text-image retrieval, visual question answering, and\nimage recognition. In addition, we demonstrate that it has good domain\ngeneralization performance due to better reasoning.",
      "tldr_zh": "本研究指出，传统的Chain-of-Thought（CoT）技术虽在多模态任务中有效，但其线性推理过程无法捕捉人类思维的多方面特性。针对此问题，作者提出Aggregation-Graph-of-Thought（AGoT）机制，用于soft-prompt tuning在multi-modal representation learning中的应用，将每个推理步骤建模为一个推理聚合图，从而实现提示聚合和提示流操作。实验结果显示，增强AGoT的多模态模型在文本-图像检索、视觉问答和图像识别等任务上取得了良好性能，并展示了出色的领域泛化能力，归功于更全面的推理过程。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper is accepted to LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04538v1",
      "published_date": "2024-04-06 07:39:44 UTC",
      "updated_date": "2024-04-06 07:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:18:04.268033"
    },
    {
      "arxiv_id": "2404.04534v2",
      "title": "Impact of Fairness Regulations on Institutions' Policies and Population Qualifications",
      "title_zh": "公平性法规对机构政策和人口资格的影响",
      "authors": [
        "Hamidreza Montaseri",
        "Amin Gohari"
      ],
      "abstract": "The proliferation of algorithmic systems has fueled discussions surrounding\nthe regulation and control of their social impact. Herein, we consider a system\nwhose primary objective is to maximize utility by selecting the most qualified\nindividuals. To promote demographic parity in the selection algorithm, we\nconsider penalizing discrimination across social groups. We examine conditions\nunder which a discrimination penalty can effectively reduce disparity in the\nselection. Additionally, we explore the implications of such a penalty when\nindividual qualifications may evolve over time in response to the imposed\npenalizing policy. We identify scenarios where the penalty could hinder the\nnatural attainment of equity within the population. Moreover, we propose\ncertain conditions that can counteract this undesirable outcome, thus ensuring\nfairness.",
      "tldr_zh": "这篇论文探讨了公平性法规对机构政策和人口资格的影响，针对算法系统在最大化效用（如选择最合格个体）时的歧视问题，引入了 discrimination penalty 来促进 demographic parity。研究分析了这种惩罚在减少社会群体不平等的条件，同时考察了当个体资格随政策变化时，可能导致公平自然实现的阻碍。最终，论文提出了特定条件来抵消负面影响，确保算法系统的公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Added experiments",
      "pdf_url": "http://arxiv.org/pdf/2404.04534v2",
      "published_date": "2024-04-06 07:21:41 UTC",
      "updated_date": "2024-05-19 11:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:18:15.385994"
    },
    {
      "arxiv_id": "2404.04527v1",
      "title": "VTR: An Optimized Vision Transformer for SAR ATR Acceleration on FPGA",
      "title_zh": "翻译失败",
      "authors": [
        "Sachini Wickramasinghe",
        "Dhruv Parikh",
        "Bingyi Zhang",
        "Rajgopal Kannan",
        "Viktor Prasanna",
        "Carl Busart"
      ],
      "abstract": "Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) is a key\ntechnique used in military applications like remote-sensing image recognition.\nVision Transformers (ViTs) are the current state-of-the-art in various computer\nvision applications, outperforming their CNN counterparts. However, using ViTs\nfor SAR ATR applications is challenging due to (1) standard ViTs require\nextensive training data to generalize well due to their low locality; the\nstandard SAR datasets, however, have a limited number of labeled training data\nwhich reduces the learning capability of ViTs; (2) ViTs have a high parameter\ncount and are computation intensive which makes their deployment on\nresource-constrained SAR platforms difficult. In this work, we develop a\nlightweight ViT model that can be trained directly on small datasets without\nany pre-training by utilizing the Shifted Patch Tokenization (SPT) and Locality\nSelf-Attention (LSA) modules. We directly train this model on SAR datasets\nwhich have limited training samples to evaluate its effectiveness for SAR ATR\napplications. We evaluate our proposed model, that we call VTR (ViT for SAR\nATR), on three widely used SAR datasets: MSTAR, SynthWakeSAR, and GBSAR.\nFurther, we propose a novel FPGA accelerator for VTR, in order to enable\ndeployment for real-time SAR ATR applications.",
      "tldr_zh": "本研究针对 Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) 的挑战，优化了 Vision Transformer (ViT) 模型，以解决其对大量训练数据的需求和计算密集问题。论文提出 VTR 模型，利用 Shifted Patch Tokenization (SPT) 和 Locality Self-Attention (LSA) 模块，使其能在小数据集上直接训练，并在 MSTAR、SynthWakeSAR 和 GBSAR 等数据集上表现出色。最终，作者设计了一个新型 FPGA 加速器，以实现 VTR 在资源受限平台上的实时部署，提升 SAR ATR 应用的效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR",
        "cs.DC"
      ],
      "primary_category": "cs.CV",
      "comment": "SPIE DCS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04527v1",
      "published_date": "2024-04-06 06:49:55 UTC",
      "updated_date": "2024-04-06 06:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:18:28.012841"
    },
    {
      "arxiv_id": "2404.04525v1",
      "title": "IITK at SemEval-2024 Task 10: Who is the speaker? Improving Emotion Recognition and Flip Reasoning in Conversations via Speaker Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Patel",
        "Divyaksh Shukla",
        "Ashutosh Modi"
      ],
      "abstract": "This paper presents our approach for the SemEval-2024 Task 10: Emotion\nDiscovery and Reasoning its Flip in Conversations. For the Emotion Recognition\nin Conversations (ERC) task, we utilize a masked-memory network along with\nspeaker participation. We propose a transformer-based speaker-centric model for\nthe Emotion Flip Reasoning (EFR) task. We also introduce Probable Trigger Zone,\na region of the conversation that is more likely to contain the utterances\ncausing the emotion to flip. For sub-task 3, the proposed approach achieves a\n5.9 (F1 score) improvement over the task baseline. The ablation study results\nhighlight the significance of various design choices in the proposed method.",
      "tldr_zh": "这篇论文针对 SemEval-2024 Task 10，提出了通过说话者嵌入改善对话中情感识别和翻转推理的方法，以更好地识别说话者角色。研究团队为 Emotion Recognition in Conversations (ERC) 任务使用了 masked-memory network 结合 speaker participation，而为 Emotion Flip Reasoning (EFR) 任务开发了 transformer-based speaker-centric model，并引入了 Probable Trigger Zone 来定位可能引发情感翻转的对话区域。实验结果显示，在子任务 3 上，F1 score 比基线提高了 5.9 分，消融研究进一步验证了这些设计选择的显著作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SemEval 2024, NAACL 2024; 10 Pages",
      "pdf_url": "http://arxiv.org/pdf/2404.04525v1",
      "published_date": "2024-04-06 06:47:44 UTC",
      "updated_date": "2024-04-06 06:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:18:41.992732"
    },
    {
      "arxiv_id": "2404.04522v2",
      "title": "Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models",
      "title_zh": "Q-PEFT：查询相关的参数高效微调，用于大型语言模型的文本",
      "authors": [
        "Zhiyuan Peng",
        "Xuyang Wu",
        "Qifan Wang",
        "Sravanthi Rajanala",
        "Yi Fang"
      ],
      "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods have been extensively utilized\nin Large Language Models (LLMs) to improve the down-streaming tasks without the\ncost of fine-tuing the whole LLMs. Recent studies have shown how to effectively\nuse PEFT for fine-tuning LLMs in ranking tasks with convincing performance;\nthere are some limitations, including the learned prompt being fixed for\ndifferent documents, overfitting to specific tasks, and low adaptation ability.\nIn this paper, we introduce a query-dependent parameter efficient fine-tuning\n(Q-PEFT) approach for text reranking to leak the information of the true\nqueries to LLMs and then make the generation of true queries from input\ndocuments much easier. Specifically, we utilize the query to extract the\ntop-$k$ tokens from concatenated documents, serving as contextual clues. We\nfurther augment Q-PEFT by substituting the retrieval mechanism with a\nmulti-head attention layer to achieve end-to-end training and cover all the\ntokens in the documents, guiding the LLMs to generate more document-specific\nsynthetic queries, thereby further improving the reranking performance.\nExtensive experiments are conducted on four public datasets, demonstrating the\neffectiveness of our proposed approach.",
      "tldr_zh": "该论文提出了一种查询依赖的参数高效微调方法（Q-PEFT），旨在解决传统 Parameter Efficient Fine-Tuning (PEFT) 在文本重排序任务中存在的固定提示、过拟合和适应性差等问题。通过利用查询信息提取文档中的 top-k 标记作为上下文线索，Q-PEFT 帮助 Large Language Models (LLMs) 生成更准确的合成查询。进一步改进包括用多头注意力层替换检索机制，实现端到端训练并覆盖所有文档标记，从而提升重排序性能。在四个公共数据集上的实验证明，Q-PEFT 有效提高了任务表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04522v2",
      "published_date": "2024-04-06 06:44:41 UTC",
      "updated_date": "2024-04-12 00:18:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:18:51.879558"
    },
    {
      "arxiv_id": "2404.04520v1",
      "title": "IITK at SemEval-2024 Task 4: Hierarchical Embeddings for Detection of Persuasion Techniques in Memes",
      "title_zh": "翻译失败",
      "authors": [
        "Shreenaga Chikoti",
        "Shrey Mehta",
        "Ashutosh Modi"
      ],
      "abstract": "Memes are one of the most popular types of content used in an online\ndisinformation campaign. They are primarily effective on social media platforms\nsince they can easily reach many users. Memes in a disinformation campaign\nachieve their goal of influencing the users through several rhetorical and\npsychological techniques, such as causal oversimplification, name-calling, and\nsmear. The SemEval 2024 Task 4 \\textit{Multilingual Detection of Persuasion\nTechnique in Memes} on identifying such techniques in the memes is divided\nacross three sub-tasks: ($\\mathbf{1}$) Hierarchical multi-label classification\nusing only textual content of the meme, ($\\mathbf{2}$) Hierarchical multi-label\nclassification using both, textual and visual content of the meme and\n($\\mathbf{3}$) Binary classification of whether the meme contains a persuasion\ntechnique or not using it's textual and visual content. This paper proposes an\nensemble of Class Definition Prediction (CDP) and hyperbolic embeddings-based\napproaches for this task. We enhance meme classification accuracy and\ncomprehensiveness by integrating HypEmo's hierarchical label embeddings (Chen\net al., 2023) and a multi-task learning framework for emotion prediction. We\nachieve a hierarchical F1-score of 0.60, 0.67, and 0.48 on the respective\nsub-tasks.",
      "tldr_zh": "该论文针对SemEval-2024 Task 4，提出了一种基于层次化嵌入的方法，用于检测模因中的说服技巧，如causal oversimplification和name-calling。研究团队开发了Class Definition Prediction (CDP)和hyperbolic embeddings的集成模型，并结合HypEmo's层次化标签嵌入及多任务学习框架，以提升模因文本和视觉内容的分类准确性。实验结果显示，该方法在三个子任务（仅文本、文本+视觉、二元分类）上分别取得了0.60、0.67和0.48的hierarchical F1-score，增强了对在线虚假信息的影响分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SemEval 2024, NAACL 2024; 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.04520v1",
      "published_date": "2024-04-06 06:28:02 UTC",
      "updated_date": "2024-04-06 06:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:19:05.753167"
    },
    {
      "arxiv_id": "2404.07234v4",
      "title": "Goal-guided Generative Prompt Injection Attack on Large Language Models",
      "title_zh": "基于目标引导的生成式提示注入攻击于大型语言模型",
      "authors": [
        "Chong Zhang",
        "Mingyu Jin",
        "Qinkai Yu",
        "Chengzhi Liu",
        "Haochen Xue",
        "Xiaobo Jin"
      ],
      "abstract": "Current large language models (LLMs) provide a strong foundation for\nlarge-scale user-oriented natural language tasks. A large number of users can\neasily inject adversarial text or instructions through the user interface, thus\ncausing LLMs model security challenges. Although there is currently a large\namount of research on prompt injection attacks, most of these black-box attacks\nuse heuristic strategies. It is unclear how these heuristic strategies relate\nto the success rate of attacks and thus effectively improve model robustness.\nTo solve this problem, we redefine the goal of the attack: to maximize the KL\ndivergence between the conditional probabilities of the clean text and the\nadversarial text. Furthermore, we prove that maximizing the KL divergence is\nequivalent to maximizing the Mahalanobis distance between the embedded\nrepresentation $x$ and $x'$ of the clean text and the adversarial text when the\nconditional probability is a Gaussian distribution and gives a quantitative\nrelationship on $x$ and $x'$. Then we designed a simple and effective\ngoal-guided generative prompt injection strategy (G2PIA) to find an injection\ntext that satisfies specific constraints to achieve the optimal attack effect\napproximately. It is particularly noteworthy that our attack method is a\nquery-free black-box attack method with low computational cost. Experimental\nresults on seven LLM models and four datasets show the effectiveness of our\nattack method.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）的安全挑战，重新定义了提示注入攻击的目标：最大化干净文本和对抗文本的条件概率之间的 KL divergence，以提升攻击效果。作者证明了在条件概率为高斯分布时，最大化 KL divergence 等价于最大化干净文本和对抗文本嵌入表示之间的 Mahalanobis distance，并给出了定量关系。基于此，他们提出了一种简单有效的 G2PIA（Goal-guided Generative Prompt Injection Attack）策略，该方法是无查询的黑盒攻击，计算成本低。实验结果显示，在七个 LLM 模型和四个数据集上，该攻击方法显著提高了成功率，从而为提升模型鲁棒性提供了新见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.07234v4",
      "published_date": "2024-04-06 06:17:10 UTC",
      "updated_date": "2024-11-09 04:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:19:17.524075"
    },
    {
      "arxiv_id": "2404.04517v2",
      "title": "Latent-based Diffusion Model for Long-tailed Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Pengxiao Han",
        "Changkun Ye",
        "Jieming Zhou",
        "Jing Zhang",
        "Jie Hong",
        "Xuesong Li"
      ],
      "abstract": "Long-tailed imbalance distribution is a common issue in practical computer\nvision applications. Previous works proposed methods to address this problem,\nwhich can be categorized into several classes: re-sampling, re-weighting,\ntransfer learning, and feature augmentation. In recent years, diffusion models\nhave shown an impressive generation ability in many sub-problems of deep\ncomputer vision. However, its powerful generation has not been explored in\nlong-tailed problems. We propose a new approach, the Latent-based Diffusion\nModel for Long-tailed Recognition (LDMLR), as a feature augmentation method to\ntackle the issue. First, we encode the imbalanced dataset into features using\nthe baseline model. Then, we train a Denoising Diffusion Implicit Model (DDIM)\nusing these encoded features to generate pseudo-features. Finally, we train the\nclassifier using the encoded and pseudo-features from the previous two steps.\nThe model's accuracy shows an improvement on the CIFAR-LT and ImageNet-LT\ndatasets by using the proposed method.",
      "tldr_zh": "本论文针对计算机视觉中的长尾分布（long-tailed imbalance distribution）问题，提出了一种新的特征增强方法：Latent-based Diffusion Model for Long-tailed Recognition (LDMLR)。该方法首先使用baseline model将不平衡数据集编码成features，然后训练Denoising Diffusion Implicit Model (DDIM)来生成pseudo-features，最后结合encoded features和pseudo-features训练classifier，以缓解类别不平衡问题。实验结果显示，在CIFAR-LT和ImageNet-LT数据集上，LDMLR显著提高了模型的准确率，证明了diffusion models在长尾识别中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 3 figures. Accepted by L3DIVU-CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04517v2",
      "published_date": "2024-04-06 06:15:07 UTC",
      "updated_date": "2024-04-23 04:54:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:19:27.772338"
    },
    {
      "arxiv_id": "2404.04513v1",
      "title": "IITK at SemEval-2024 Task 1: Contrastive Learning and Autoencoders for Semantic Textual Relatedness in Multilingual Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Udvas Basak",
        "Rajarshi Dutta",
        "Shivam Pandey",
        "Ashutosh Modi"
      ],
      "abstract": "This paper describes our system developed for the SemEval-2024 Task 1:\nSemantic Textual Relatedness. The challenge is focused on automatically\ndetecting the degree of relatedness between pairs of sentences for 14 languages\nincluding both high and low-resource Asian and African languages. Our team\nparticipated in two subtasks consisting of Track A: supervised and Track B:\nunsupervised. This paper focuses on a BERT-based contrastive learning and\nsimilarity metric based approach primarily for the supervised track while\nexploring autoencoders for the unsupervised track. It also aims on the creation\nof a bigram relatedness corpus using negative sampling strategy, thereby\nproducing refined word embeddings.",
      "tldr_zh": "本论文介绍了 IITK 团队为 SemEval-2024 Task 1 开发的系统，用于检测 14 种语言（包括高资源和低资源亚洲及非洲语言）中句子对的语义文本相关性。系统针对监督轨道 (Track A) 采用基于 BERT 的对比学习和相似度度量方法，而在无监督轨道 (Track B) 中探索自编码器进行相关性分析。此外，他们通过负采样策略创建了双元相关性语料库，从而产生精炼的词嵌入，以提升多语言文本处理的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SemEval 2024, NAACL 2024; 6 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.04513v1",
      "published_date": "2024-04-06 05:58:42 UTC",
      "updated_date": "2024-04-06 05:58:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:19:43.069706"
    },
    {
      "arxiv_id": "2404.04511v1",
      "title": "Cluster-based Video Summarization with Temporal Context Awareness",
      "title_zh": "基于聚类的视频摘要，具有时间上下文感知",
      "authors": [
        "Hai-Dang Huynh-Lam",
        "Ngoc-Phuong Ho-Thi",
        "Minh-Triet Tran",
        "Trung-Nghia Le"
      ],
      "abstract": "In this paper, we present TAC-SUM, a novel and efficient training-free\napproach for video summarization that addresses the limitations of existing\ncluster-based models by incorporating temporal context. Our method partitions\nthe input video into temporally consecutive segments with clustering\ninformation, enabling the injection of temporal awareness into the clustering\nprocess, setting it apart from prior cluster-based summarization methods. The\nresulting temporal-aware clusters are then utilized to compute the final\nsummary, using simple rules for keyframe selection and frame importance\nscoring. Experimental results on the SumMe dataset demonstrate the\neffectiveness of our proposed approach, outperforming existing unsupervised\nmethods and achieving comparable performance to state-of-the-art supervised\nsummarization techniques. Our source code is available for reference at\n\\url{https://github.com/hcmus-thesis-gulu/TAC-SUM}.",
      "tldr_zh": "本研究提出了一种名为 TAC-SUM 的新型训练-free 视频摘要方法，通过融入时间上下文（temporal context）来改进传统基于聚类的（cluster-based）模型。该方法将输入视频分成基于聚类的连续时间段，并注入时间意识，以生成时间感知聚类，随后通过简单规则选择关键帧和评估帧重要性来计算最终摘要。在 SumMe 数据集上的实验显示，TAC-SUM 超过了现有无监督方法，并在性能上与最先进的监督摘要技术相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 6 figures, accepted in PSIVT 2023",
      "pdf_url": "http://arxiv.org/pdf/2404.04511v1",
      "published_date": "2024-04-06 05:55:14 UTC",
      "updated_date": "2024-04-06 05:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:19:51.611913"
    },
    {
      "arxiv_id": "2404.04510v1",
      "title": "IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials",
      "title_zh": "翻译失败",
      "authors": [
        "Shreyasi Mandal",
        "Ashutosh Modi"
      ],
      "abstract": "Large Language models (LLMs) have demonstrated state-of-the-art performance\nin various natural language processing (NLP) tasks across multiple domains, yet\nthey are prone to shortcut learning and factual inconsistencies. This research\ninvestigates LLMs' robustness, consistency, and faithful reasoning when\nperforming Natural Language Inference (NLI) on breast cancer Clinical Trial\nReports (CTRs) in the context of SemEval 2024 Task 2: Safe Biomedical Natural\nLanguage Inference for Clinical Trials. We examine the reasoning capabilities\nof LLMs and their adeptness at logical problem-solving. A comparative analysis\nis conducted on pre-trained language models (PLMs), GPT-3.5, and Gemini Pro\nunder zero-shot settings using Retrieval-Augmented Generation (RAG) framework,\nintegrating various reasoning chains. The evaluation yields an F1 score of\n0.69, consistency of 0.71, and a faithfulness score of 0.90 on the test\ndataset.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在 SemEval-2024 Task 2 中的性能，专注于安全生物医学自然语言推理 (NLI) 任务，以评估其在乳腺癌临床试验报告 (CTRs) 中的鲁棒性、一致性和忠实推理能力。研究采用检索增强生成 (RAG) 框架，在零样本设置下比较了预训练语言模型 (PLMs)、GPT-3.5 和 Gemini Pro 的表现，并整合了各种推理链来解决捷径学习和事实不一致问题。结果显示，模型在测试数据集上达到了 F1 分数 0.69、一致性 0.71 和忠实度 0.90 的水平，为提升 LLMs 在生物医学领域的可靠应用提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SemEval 2024, NAACL 2024; 8 Pages",
      "pdf_url": "http://arxiv.org/pdf/2404.04510v1",
      "published_date": "2024-04-06 05:44:53 UTC",
      "updated_date": "2024-04-06 05:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:20:06.476736"
    },
    {
      "arxiv_id": "2404.04500v1",
      "title": "Trustless Audits without Revealing Data or Models",
      "title_zh": "翻译失败",
      "authors": [
        "Suppakit Waiwitlikhit",
        "Ion Stoica",
        "Yi Sun",
        "Tatsunori Hashimoto",
        "Daniel Kang"
      ],
      "abstract": "There is an increasing conflict between business incentives to hide models\nand data as trade secrets, and the societal need for algorithmic transparency.\nFor example, a rightsholder wishing to know whether their copyrighted works\nhave been used during training must convince the model provider to allow a\nthird party to audit the model and data. Finding a mutually agreeable third\nparty is difficult, and the associated costs often make this approach\nimpractical.\n  In this work, we show that it is possible to simultaneously allow model\nproviders to keep their model weights (but not architecture) and data secret\nwhile allowing other parties to trustlessly audit model and data properties. We\ndo this by designing a protocol called ZkAudit in which model providers publish\ncryptographic commitments of datasets and model weights, alongside a\nzero-knowledge proof (ZKP) certifying that published commitments are derived\nfrom training the model. Model providers can then respond to audit requests by\nprivately computing any function F of the dataset (or model) and releasing the\noutput of F alongside another ZKP certifying the correct execution of F. To\nenable ZkAudit, we develop new methods of computing ZKPs for SGD on modern\nneural nets for simple recommender systems and image classification models\ncapable of high accuracies on ImageNet. Empirically, we show it is possible to\nprovide trustless audits of DNNs, including copyright, censorship, and\ncounterfactual audits with little to no loss in accuracy.",
      "tldr_zh": "这篇论文解决了算法透明性与商业秘密保护之间的冲突，提出ZkAudit协议，允许模型提供者隐藏数据和模型权重（但不包括架构），同时实现无信任审计。协议通过发布数据集和模型权重的加密承诺，以及zero-knowledge proof (ZKP)来证明承诺的真实性，并支持私密计算审计函数F并验证其执行。实验结果显示，ZkAudit在SGD训练的DNNs上实现了高准确性的版权、审查和反事实审计，几乎没有准确性损失。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04500v1",
      "published_date": "2024-04-06 04:43:06 UTC",
      "updated_date": "2024-04-06 04:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:20:16.874767"
    },
    {
      "arxiv_id": "2404.04492v1",
      "title": "Automated Lane Change Behavior Prediction and Environmental Perception Based on SLAM Technology",
      "title_zh": "基于 SLAM 技术的自动变道行为预测和环境感知",
      "authors": [
        "Han Lei",
        "Baoming Wang",
        "Zuwei Shui",
        "Peiyuan Yang",
        "Penghao Liang"
      ],
      "abstract": "In addition to environmental perception sensors such as cameras, radars, etc.\nin the automatic driving system, the external environment of the vehicle is\nperceived, in fact, there is also a perception sensor that has been silently\ndedicated in the system, that is, the positioning module. This paper explores\nthe application of SLAM (Simultaneous Localization and Mapping) technology in\nthe context of automatic lane change behavior prediction and environment\nperception for autonomous vehicles. It discusses the limitations of traditional\npositioning methods, introduces SLAM technology, and compares LIDAR SLAM with\nvisual SLAM. Real-world examples from companies like Tesla, Waymo, and Mobileye\nshowcase the integration of AI-driven technologies, sensor fusion, and SLAM in\nautonomous driving systems. The paper then delves into the specifics of SLAM\nalgorithms, sensor technologies, and the importance of automatic lane changes\nin driving safety and efficiency. It highlights Tesla's recent update to its\nAutopilot system, which incorporates automatic lane change functionality using\nSLAM technology. The paper concludes by emphasizing the crucial role of SLAM in\nenabling accurate environment perception, positioning, and decision-making for\nautonomous vehicles, ultimately enhancing safety and driving experience.",
      "tldr_zh": "这篇论文探讨了 SLAM (Simultaneous Localization and Mapping) 技术在自动驾驶车辆中的应用，专注于自动变道行为预测和环境感知，以弥补传统定位方法的局限性。论文比较了 LIDAR SLAM 和 visual SLAM，分析了传感器融合以及 AI 驱动技术的整合，并通过 Tesla、Waymo 和 Mobileye 的真实案例展示了这些技术的实际部署，如 Tesla Autopilot 系统的更新。研究强调 SLAM 算法和传感器技术在提升驾驶安全性和效率方面的关键作用，最终增强了自主车辆的定位、决策和整体驾驶体验。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04492v1",
      "published_date": "2024-04-06 03:48:29 UTC",
      "updated_date": "2024-04-06 03:48:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:20:30.501752"
    },
    {
      "arxiv_id": "2404.04481v1",
      "title": "Joint Identifiability of Cross-Domain Recommendation via Hierarchical Subspace Disentanglement",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Du",
        "Zesheng Ye",
        "Bin Guo",
        "Zhiwen Yu",
        "Lina Yao"
      ],
      "abstract": "Cross-Domain Recommendation (CDR) seeks to enable effective knowledge\ntransfer across domains. Existing works rely on either representation alignment\nor transformation bridges, but they struggle on identifying domain-shared from\ndomain-specific latent factors. Specifically, while CDR describes user\nrepresentations as a joint distribution over two domains, these methods fail to\naccount for its joint identifiability as they primarily fixate on the marginal\ndistribution within a particular domain. Such a failure may overlook the\nconditionality between two domains and how it contributes to latent factor\ndisentanglement, leading to negative transfer when domains are weakly\ncorrelated. In this study, we explore what should and should not be transferred\nin cross-domain user representations from a causality perspective. We propose a\nHierarchical subspace disentanglement approach to explore the Joint\nIDentifiability of cross-domain joint distribution, termed HJID, to preserve\ndomain-specific behaviors from domain-shared factors. HJID organizes user\nrepresentations into layers: generic shallow subspaces and domain-oriented deep\nsubspaces. We first encode the generic pattern in the shallow subspace by\nminimizing the Maximum Mean Discrepancy of initial layer activation. Then, to\ndissect how domain-oriented latent factors are encoded in deeper layers\nactivation, we construct a cross-domain causality-based data generation graph,\nwhich identifies cross-domain consistent and domain-specific components,\nadhering to the Minimal Change principle. This allows HJID to maintain\nstability whilst discovering unique factors for different domains, all within a\ngenerative framework of invertible transformations that guarantee the joint\nidentifiability. With experiments on real-world datasets, we show that HJID\noutperforms SOTA methods on a range of strongly and weakly correlated CDR\ntasks.",
      "tldr_zh": "本研究针对跨域推荐 (Cross-Domain Recommendation, CDR) 的挑战，指出现有方法未能区分领域共享和领域特定潜在因素，导致负转移问题，特别是当领域弱相关时。作者提出 Hierarchical subspace disentanglement 框架，名为 HJID，通过层次化用户表示（包括泛化浅层子空间和领域导向深层子空间）来探索跨域联合分布的联合可识别性：先最小化浅层子空间的 Maximum Mean Discrepancy (MMD) 以编码泛化模式，然后基于跨域因果图识别深层组件，确保遵循 Minimal Change 原则。实验结果显示，HJID 在真实数据集上优于最先进 (SOTA) 方法，尤其在强相关和弱相关 CDR 任务中，显著提升了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "accepted to SIGIR 2024 as a Full Research Paper",
      "pdf_url": "http://arxiv.org/pdf/2404.04481v1",
      "published_date": "2024-04-06 03:11:31 UTC",
      "updated_date": "2024-04-06 03:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:20:43.078013"
    },
    {
      "arxiv_id": "2404.04475v2",
      "title": "Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators",
      "title_zh": "翻译失败",
      "authors": [
        "Yann Dubois",
        "Balázs Galambosi",
        "Percy Liang",
        "Tatsunori B. Hashimoto"
      ],
      "abstract": "LLM-based auto-annotators have become a key component of the LLM development\nprocess due to their cost-effectiveness and scalability compared to human-based\nevaluation. However, these auto-annotators can introduce biases that are hard\nto remove. Even simple, known confounders such as preference for longer outputs\nremain in existing automated evaluation metrics. We propose a simple regression\nanalysis approach for controlling biases in auto-evaluations. As a real case\nstudy, we focus on reducing the length bias of AlpacaEval, a fast and\naffordable benchmark for instruction-tuned LLMs that uses LLMs to estimate\nresponse quality. Despite being highly correlated with human preferences,\nAlpacaEval is known to favor models that generate longer outputs. We introduce\na length-controlled AlpacaEval that aims to answer the counterfactual question:\n\"What would the preference be if the model's and baseline's output had the same\nlength?\" To achieve this, we first fit a generalized linear model to predict\nthe biased auto-annotator's preferences based on the mediators we want to\ncontrol for (length difference) and other relevant features. We then obtain\nlength-controlled preferences by predicting preferences while conditioning the\nGLM with a zero difference in lengths. Length-controlling not only improves the\nrobustness of the metric to manipulations in model verbosity, but we also find\nthat it increases the Spearman correlation with LMSYS Chatbot Arena from 0.94\nto 0.98.",
      "tldr_zh": "该论文提出了一种简单的方法，通过回归分析来减少基于LLM的自动评估器中的偏差，特别是针对输出长度偏好问题。研究聚焦于AlpacaEval基准，该基准虽与人类偏好高度相关，但倾向于偏好更长的输出。作者使用广义线性模型(GLM)预测偏置偏好，基于长度差异和其他特征进行控制，并通过条件化GLM使长度差异为零，生成长度控制的偏好评估。结果显示，这种方法不仅提升了指标对模型冗长性的鲁棒性，还将与LMSYS Chatbot Arena的Spearman相关性从0.94提高到0.98。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04475v2",
      "published_date": "2024-04-06 02:29:02 UTC",
      "updated_date": "2025-03-10 09:27:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:20:54.110606"
    },
    {
      "arxiv_id": "2404.04456v1",
      "title": "Beyond the Known: Adversarial Autoencoders in Novelty Detection",
      "title_zh": "超越已知：对抗自动编码器在新颖性检测中",
      "authors": [
        "Muhammad Asad",
        "Ihsan Ullah",
        "Ganesh Sistu",
        "Michael G. Madden"
      ],
      "abstract": "In novelty detection, the goal is to decide if a new data point should be\ncategorized as an inlier or an outlier, given a training dataset that primarily\ncaptures the inlier distribution. Recent approaches typically use deep encoder\nand decoder network frameworks to derive a reconstruction error, and employ\nthis error either to determine a novelty score, or as the basis for a one-class\nclassifier. In this research, we use a similar framework but with a lightweight\ndeep network, and we adopt a probabilistic score with reconstruction error. Our\nmethodology calculates the probability of whether the sample comes from the\ninlier distribution or not. This work makes two key contributions. The first is\nthat we compute the novelty probability by linearizing the manifold that holds\nthe structure of the inlier distribution. This allows us to interpret how the\nprobability is distributed and can be determined in relation to the local\ncoordinates of the manifold tangent space. The second contribution is that we\nimprove the training protocol for the network. Our results indicate that our\napproach is effective at learning the target class, and it outperforms recent\nstate-of-the-art methods on several benchmark datasets.",
      "tldr_zh": "本研究针对novelty detection问题，使用轻量级深度网络框架结合reconstruction error计算概率分数，以判断新数据点是否来自inlier分布。关键贡献包括：通过线性化inlier分布的manifold来计算新奇度概率，并解释其在manifold tangent space中的分布；以及改进网络的训练协议。这些创新使方法在学习目标类方面更有效，并在多个基准数据集上优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the VISAAP 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04456v1",
      "published_date": "2024-04-06 00:04:19 UTC",
      "updated_date": "2024-04-06 00:04:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:21:05.783561"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 44,
  "processed_papers_count": 44,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T22:21:29.027059"
}