[
  {
    "arxiv_id": "2404.04752v2",
    "title": "Challenges Faced by Large Language Models in Solving Multi-Agent Flocking",
    "authors": [
      "Peihan Li",
      "Vishnu Menon",
      "Bhavanaraj Gudiguntla",
      "Daniel Ting",
      "Lifeng Zhou"
    ],
    "abstract": "Flocking is a behavior where multiple agents in a system attempt to stay\nclose to each other while avoiding collision and maintaining a desired\nformation. This is observed in the natural world and has applications in\nrobotics, including natural disaster search and rescue, wild animal tracking,\nand perimeter surveillance and patrol. Recently, large language models (LLMs)\nhave displayed an impressive ability to solve various collaboration tasks as\nindividual decision-makers. Solving multi-agent flocking with LLMs would\ndemonstrate their usefulness in situations requiring spatial and decentralized\ndecision-making. Yet, when LLM-powered agents are tasked with implementing\nmulti-agent flocking, they fall short of the desired behavior. After extensive\ntesting, we find that agents with LLMs as individual decision-makers typically\nopt to converge on the average of their initial positions or diverge from each\nother. After breaking the problem down, we discover that LLMs cannot understand\nmaintaining a shape or keeping a distance in a meaningful way. Solving\nmulti-agent flocking with LLMs would enhance their ability to understand\ncollaborative spatial reasoning and lay a foundation for addressing more\ncomplex multi-agent tasks. This paper discusses the challenges LLMs face in\nmulti-agent flocking and suggests areas for future improvement and research.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04752v2",
    "published_date": "2024-04-06 22:34:07 UTC",
    "updated_date": "2024-12-16 19:45:53 UTC"
  },
  {
    "arxiv_id": "2404.04744v1",
    "title": "Adapting Multi-objectivized Software Configuration Tuning",
    "authors": [
      "Tao Chen",
      "Miqing Li"
    ],
    "abstract": "When tuning software configuration for better performance (e.g., latency or\nthroughput), an important issue that many optimizers face is the presence of\nlocal optimum traps, compounded by a highly rugged configuration landscape and\nexpensive measurements. To mitigate these issues, a recent effort has shifted\nto focus on the level of optimization model (called meta multi-objectivization\nor MMO) instead of designing better optimizers as in traditional methods. This\nis done by using an auxiliary performance objective, together with the target\nperformance objective, to help the search jump out of local optima. While\neffective, MMO needs a fixed weight to balance the two objectives-a parameter\nthat has been found to be crucial as there is a large deviation of the\nperformance between the best and the other settings. However, given the variety\nof configurable software systems, the \"sweet spot\" of the weight can vary\ndramatically in different cases and it is not possible to find the right\nsetting without time-consuming trial and error. In this paper, we seek to\novercome this significant shortcoming of MMO by proposing a weight adaptation\nmethod, dubbed AdMMO. Our key idea is to adaptively adjust the weight at the\nright time during tuning, such that a good proportion of the nondominated\nconfigurations can be maintained. Moreover, we design a partial duplicate\nretention mechanism to handle the issue of too many duplicate configurations\nwithout losing the rich information provided by the \"good\" duplicates.\n  Experiments on several real-world systems, objectives, and budgets show that,\nfor 71% of the cases, AdMMO is considerably superior to MMO and a wide range of\nstate-of-the-art optimizers while achieving generally better efficiency with\nthe best speedup between 2.2x and 20x.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper has been accepted at ACM FSE'24",
    "pdf_url": "http://arxiv.org/pdf/2404.04744v1",
    "published_date": "2024-04-06 22:08:09 UTC",
    "updated_date": "2024-04-06 22:08:09 UTC"
  },
  {
    "arxiv_id": "2404.04736v1",
    "title": "ProtoAL: Interpretable Deep Active Learning with prototypes for medical imaging",
    "authors": [
      "Iury B. de A. Santos",
      "André C. P. L. F. de Carvalho"
    ],
    "abstract": "The adoption of Deep Learning algorithms in the medical imaging field is a\nprominent area of research, with high potential for advancing AI-based\nComputer-aided diagnosis (AI-CAD) solutions. However, current solutions face\nchallenges due to a lack of interpretability features and high data demands,\nprompting recent efforts to address these issues. In this study, we propose the\nProtoAL method, where we integrate an interpretable DL model into the Deep\nActive Learning (DAL) framework. This approach aims to address both challenges\nby focusing on the medical imaging context and utilizing an inherently\ninterpretable model based on prototypes. We evaluated ProtoAL on the Messidor\ndataset, achieving an area under the precision-recall curve of 0.79 while\nutilizing only 76.54\\% of the available labeled data. These capabilities can\nenhances the practical usability of a DL model in the medical field, providing\na means of trust calibration in domain experts and a suitable solution for\nlearning in the data scarcity context often found.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04736v1",
    "published_date": "2024-04-06 21:39:49 UTC",
    "updated_date": "2024-04-06 21:39:49 UTC"
  },
  {
    "arxiv_id": "2404.04735v2",
    "title": "MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems",
    "authors": [
      "Bin Lei",
      "Yi Zhang",
      "Shan Zuo",
      "Ali Payani",
      "Caiwen Ding"
    ],
    "abstract": "Recent advancements in large language models, such as GPT-4, have\ndemonstrated remarkable capabilities in processing standard queries. Despite\nthese advancements, their performance substantially declines in\n\\textbf{advanced mathematical problems requiring complex, multi-step logical\nreasoning}. To enhance their inferential capabilities, current research has\ndelved into \\textit{prompting engineering}, exemplified by methodologies such\nas the Tree of Thought and Graph of Thought. Nonetheless, these existing\napproaches encounter two significant limitations. Firstly, their effectiveness\nin tackling complex mathematical problems is somewhat constrained. Secondly,\nthe necessity to design distinct prompts for individual problems hampers their\ngeneralizability. In response to these limitations, this paper introduces the\n\\textit{Multi-Agent System for conditional Mining} (\\textbf{MACM}) prompting\nmethod. It not only resolves intricate mathematical problems but also\ndemonstrates strong generalization capabilities across various mathematical\ncontexts. With the assistance of MACM, the accuracy of GPT-4 Turbo on the most\nchallenging level five mathematical problems in the MATH dataset increase from\n$\\mathbf{54.68\\%} \\text{ to } \\mathbf{76.73\\%}$. The code is available in\n\\url{https://github.com/bin123apple/MACM}.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04735v2",
    "published_date": "2024-04-06 21:39:01 UTC",
    "updated_date": "2024-07-22 22:37:40 UTC"
  },
  {
    "arxiv_id": "2404.04718v1",
    "title": "Interpretable Multimodal Learning for Cardiovascular Hemodynamics Assessment",
    "authors": [
      "Prasun C Tripathi",
      "Sina Tabakhi",
      "Mohammod N I Suvon",
      "Lawrence Schöb",
      "Samer Alabed",
      "Andrew J Swift",
      "Shuo Zhou",
      "Haiping Lu"
    ],
    "abstract": "Pulmonary Arterial Wedge Pressure (PAWP) is an essential cardiovascular\nhemodynamics marker to detect heart failure. In clinical practice, Right Heart\nCatheterization is considered a gold standard for assessing cardiac\nhemodynamics while non-invasive methods are often needed to screen high-risk\npatients from a large population. In this paper, we propose a multimodal\nlearning pipeline to predict PAWP marker. We utilize complementary information\nfrom Cardiac Magnetic Resonance Imaging (CMR) scans (short-axis and\nfour-chamber) and Electronic Health Records (EHRs). We extract spatio-temporal\nfeatures from CMR scans using tensor-based learning. We propose a graph\nattention network to select important EHR features for prediction, where we\nmodel subjects as graph nodes and feature relationships as graph edges using\nthe attention mechanism. We design four feature fusion strategies: early,\nintermediate, late, and hybrid fusion. With a linear classifier and linear\nfusion strategies, our pipeline is interpretable. We validate our pipeline on a\nlarge dataset of $2,641$ subjects from our ASPIRE registry. The comparative\nstudy against state-of-the-art methods confirms the superiority of our\npipeline. The decision curve analysis further validates that our pipeline can\nbe applied to screen a large population. The code is available at\nhttps://github.com/prasunc/hemodynamics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04718v1",
    "published_date": "2024-04-06 19:42:25 UTC",
    "updated_date": "2024-04-06 19:42:25 UTC"
  },
  {
    "arxiv_id": "2404.04714v1",
    "title": "Data Poisoning Attacks on Off-Policy Policy Evaluation Methods",
    "authors": [
      "Elita Lobo",
      "Harvineet Singh",
      "Marek Petrik",
      "Cynthia Rudin",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Off-policy Evaluation (OPE) methods are a crucial tool for evaluating\npolicies in high-stakes domains such as healthcare, where exploration is often\ninfeasible, unethical, or expensive. However, the extent to which such methods\ncan be trusted under adversarial threats to data quality is largely unexplored.\nIn this work, we make the first attempt at investigating the sensitivity of OPE\nmethods to marginal adversarial perturbations to the data. We design a generic\ndata poisoning attack framework leveraging influence functions from robust\nstatistics to carefully construct perturbations that maximize error in the\npolicy value estimates. We carry out extensive experimentation with multiple\nhealthcare and control datasets. Our results demonstrate that many existing OPE\nmethods are highly prone to generating value estimates with large errors when\nsubject to data poisoning attacks, even for small adversarial perturbations.\nThese findings question the reliability of policy values derived using OPE\nmethods and motivate the need for developing OPE methods that are statistically\nrobust to train-time data poisoning attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at UAI 2022",
    "pdf_url": "http://arxiv.org/pdf/2404.04714v1",
    "published_date": "2024-04-06 19:27:57 UTC",
    "updated_date": "2024-04-06 19:27:57 UTC"
  },
  {
    "arxiv_id": "2404.04686v1",
    "title": "Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI",
    "authors": [
      "Taminul Islam",
      "Md. Alif Sheakh",
      "Mst. Sazia Tahosin",
      "Most. Hasna Hena",
      "Shopnil Akash",
      "Yousef A. Bin Jardan",
      "Gezahign Fentahun Wondmie",
      "Hiba-Allah Nafidi",
      "Mohammed Bourhia"
    ],
    "abstract": "Breast cancer has rapidly increased in prevalence in recent years, making it\none of the leading causes of mortality worldwide. Among all cancers, it is by\nfar the most common. Diagnosing this illness manually requires significant time\nand expertise. Since detecting breast cancer is a time-consuming process,\npreventing its further spread can be aided by creating machine-based forecasts.\nMachine learning and Explainable AI are crucial in classification as they not\nonly provide accurate predictions but also offer insights into how the model\narrives at its decisions, aiding in the understanding and trustworthiness of\nthe classification results. In this study, we evaluate and compare the\nclassification accuracy, precision, recall, and F-1 scores of five different\nmachine learning methods using a primary dataset (500 patients from Dhaka\nMedical College Hospital). Five different supervised machine learning\ntechniques, including decision tree, random forest, logistic regression, naive\nbayes, and XGBoost, have been used to achieve optimal results on our dataset.\nAdditionally, this study applied SHAP analysis to the XGBoost model to\ninterpret the model's predictions and understand the impact of each feature on\nthe model's output. We compared the accuracy with which several algorithms\nclassified the data, as well as contrasted with other literature in this field.\nAfter final evaluation, this study found that XGBoost achieved the best model\naccuracy, which is 97%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for the Scientific Reports (Nature) journal. 32 pages, 12\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2404.04686v1",
    "published_date": "2024-04-06 17:23:21 UTC",
    "updated_date": "2024-04-06 17:23:21 UTC"
  },
  {
    "arxiv_id": "2404.04682v1",
    "title": "Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning",
    "authors": [
      "Yeda Song",
      "Dongwook Lee",
      "Gunhee Kim"
    ],
    "abstract": "Offline reinforcement learning (RL) is a compelling framework for learning\noptimal policies from past experiences without additional interaction with the\nenvironment. Nevertheless, offline RL inevitably faces the problem of\ndistributional shifts, where the states and actions encountered during policy\nexecution may not be in the training dataset distribution. A common solution\ninvolves incorporating conservatism into the policy or the value function to\nsafeguard against uncertainties and unknowns. In this work, we focus on\nachieving the same objectives of conservatism but from a different perspective.\nWe propose COmpositional COnservatism with Anchor-seeking (COCOA) for offline\nRL, an approach that pursues conservatism in a compositional manner on top of\nthe transductive reparameterization (Netanyahu et al., 2023), which decomposes\nthe input variable (the state in our case) into an anchor and its difference\nfrom the original input. Our COCOA seeks both in-distribution anchors and\ndifferences by utilizing the learned reverse dynamics model, encouraging\nconservatism in the compositional input space for the policy or value function.\nSuch compositional conservatism is independent of and agnostic to the prevalent\nbehavioral conservatism in offline RL. We apply COCOA to four state-of-the-art\noffline RL algorithms and evaluate them on the D4RL benchmark, where COCOA\ngenerally improves the performance of each algorithm. The code is available at\nhttps://github.com/runamu/compositional-conservatism.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04682v1",
    "published_date": "2024-04-06 17:02:18 UTC",
    "updated_date": "2024-04-06 17:02:18 UTC"
  },
  {
    "arxiv_id": "2404.05765v1",
    "title": "A Novel Bi-LSTM And Transformer Architecture For Generating Tabla Music",
    "authors": [
      "Roopa Mayya",
      "Vivekanand Venkataraman",
      "Anwesh P R",
      "Narayana Darapaneni"
    ],
    "abstract": "Introduction: Music generation is a complex task that has received\nsignificant attention in recent years, and deep learning techniques have shown\npromising results in this field. Objectives: While extensive work has been\ncarried out on generating Piano and other Western music, there is limited\nresearch on generating classical Indian music due to the scarcity of Indian\nmusic in machine-encoded formats. In this technical paper, methods for\ngenerating classical Indian music, specifically tabla music, is proposed.\nInitially, this paper explores piano music generation using deep learning\narchitectures. Then the fundamentals are extended to generating tabla music.\nMethods: Tabla music in waveform (.wav) files are pre-processed using the\nlibrosa library in Python. A novel Bi-LSTM with an Attention approach and a\ntransformer model are trained on the extracted features and labels. Results:\nThe models are then used to predict the next sequences of tabla music. A loss\nof 4.042 and MAE of 1.0814 are achieved with the Bi-LSTM model. With the\ntransformer model, a loss of 55.9278 and MAE of 3.5173 are obtained for tabla\nmusic generation. Conclusion: The resulting music embodies a harmonious fusion\nof novelty and familiarity, pushing the limits of music composition to new\nhorizons.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05765v1",
    "published_date": "2024-04-06 16:15:02 UTC",
    "updated_date": "2024-04-06 16:15:02 UTC"
  },
  {
    "arxiv_id": "2404.04667v1",
    "title": "Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology",
    "authors": [
      "Dyke Ferber",
      "Omar S. M. El Nahhas",
      "Georg Wölflein",
      "Isabella C. Wiest",
      "Jan Clusmann",
      "Marie-Elisabeth Leßman",
      "Sebastian Foersch",
      "Jacqueline Lammert",
      "Maximilian Tschochohei",
      "Dirk Jäger",
      "Manuel Salto-Tellez",
      "Nikolaus Schultz",
      "Daniel Truhn",
      "Jakob Nikolas Kather"
    ],
    "abstract": "Multimodal artificial intelligence (AI) systems have the potential to enhance\nclinical decision-making by interpreting various types of medical data.\nHowever, the effectiveness of these models across all medical fields is\nuncertain. Each discipline presents unique challenges that need to be addressed\nfor optimal performance. This complexity is further increased when attempting\nto integrate different fields into a single model. Here, we introduce an\nalternative approach to multimodal medical AI that utilizes the generalist\ncapabilities of a large language model (LLM) as a central reasoning engine.\nThis engine autonomously coordinates and deploys a set of specialized medical\nAI tools. These tools include text, radiology and histopathology image\ninterpretation, genomic data processing, web searches, and document retrieval\nfrom medical guidelines. We validate our system across a series of clinical\noncology scenarios that closely resemble typical patient care workflows. We\nshow that the system has a high capability in employing appropriate tools\n(97%), drawing correct conclusions (93.6%), and providing complete (94%), and\nhelpful (89.2%) recommendations for individual patient cases while consistently\nreferencing relevant literature (82.5%) upon instruction. This work provides\nevidence that LLMs can effectively plan and execute domain-specific models to\nretrieve or synthesize new information when used as autonomous agents. This\nenables them to function as specialist, patient-tailored clinical assistants.\nIt also simplifies regulatory compliance by allowing each component tool to be\nindividually validated and approved. We believe, that our work can serve as a\nproof-of-concept for more advanced LLM-agents in the medical domain.",
    "categories": [
      "cs.AI",
      "q-bio.TO"
    ],
    "primary_category": "cs.AI",
    "comment": "91 pages, 2 Figures",
    "pdf_url": "http://arxiv.org/pdf/2404.04667v1",
    "published_date": "2024-04-06 15:50:19 UTC",
    "updated_date": "2024-04-06 15:50:19 UTC"
  },
  {
    "arxiv_id": "2404.04665v1",
    "title": "Adaptive Intra-Class Variation Contrastive Learning for Unsupervised Person Re-Identification",
    "authors": [
      "Lingzhi Liu",
      "Haiyang Zhang",
      "Chengwei Tang",
      "Tiantian Zhang"
    ],
    "abstract": "The memory dictionary-based contrastive learning method has achieved\nremarkable results in the field of unsupervised person Re-ID. However, The\nmethod of updating memory based on all samples does not fully utilize the\nhardest sample to improve the generalization ability of the model, and the\nmethod based on hardest sample mining will inevitably introduce false-positive\nsamples that are incorrectly clustered in the early stages of the model.\nClustering-based methods usually discard a significant number of outliers,\nleading to the loss of valuable information. In order to address the issues\nmentioned before, we propose an adaptive intra-class variation contrastive\nlearning algorithm for unsupervised Re-ID, called AdaInCV. And the algorithm\nquantitatively evaluates the learning ability of the model for each class by\nconsidering the intra-class variations after clustering, which helps in\nselecting appropriate samples during the training process of the model. To be\nmore specific, two new strategies are proposed: Adaptive Sample Mining (AdaSaM)\nand Adaptive Outlier Filter (AdaOF). The first one gradually creates more\nreliable clusters to dynamically refine the memory, while the second can\nidentify and filter out valuable outliers as negative samples.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04665v1",
    "published_date": "2024-04-06 15:48:14 UTC",
    "updated_date": "2024-04-06 15:48:14 UTC"
  },
  {
    "arxiv_id": "2404.04663v1",
    "title": "Focused Active Learning for Histopathological Image Classification",
    "authors": [
      "Arne Schmidt",
      "Pablo Morales-Álvarez",
      "Lee A. D. Cooper",
      "Lee A. Newberg",
      "Andinet Enquobahrie",
      "Aggelos K. Katsaggelos",
      "Rafael Molina"
    ],
    "abstract": "Active Learning (AL) has the potential to solve a major problem of digital\npathology: the efficient acquisition of labeled data for machine learning\nalgorithms. However, existing AL methods often struggle in realistic settings\nwith artifacts, ambiguities, and class imbalances, as commonly seen in the\nmedical field. The lack of precise uncertainty estimations leads to the\nacquisition of images with a low informative value. To address these\nchallenges, we propose Focused Active Learning (FocAL), which combines a\nBayesian Neural Network with Out-of-Distribution detection to estimate\ndifferent uncertainties for the acquisition function. Specifically, the\nweighted epistemic uncertainty accounts for the class imbalance, aleatoric\nuncertainty for ambiguous images, and an OoD score for artifacts. We perform\nextensive experiments to validate our method on MNIST and the real-world Panda\ndataset for the classification of prostate cancer. The results confirm that\nother AL methods are 'distracted' by ambiguities and artifacts which harm the\nperformance. FocAL effectively focuses on the most informative images, avoiding\nambiguities and artifacts during acquisition. For both experiments, FocAL\noutperforms existing AL approaches, reaching a Cohen's kappa of 0.764 with only\n0.69% of the labeled Panda data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04663v1",
    "published_date": "2024-04-06 15:31:57 UTC",
    "updated_date": "2024-04-06 15:31:57 UTC"
  },
  {
    "arxiv_id": "2404.04661v1",
    "title": "Transform then Explore: a Simple and Effective Technique for Exploratory Combinatorial Optimization with Reinforcement Learning",
    "authors": [
      "Tianle Pu",
      "Changjun Fan",
      "Mutian Shen",
      "Yizhou Lu",
      "Li Zeng",
      "Zohar Nussinov",
      "Chao Chen",
      "Zhong Liu"
    ],
    "abstract": "Many complex problems encountered in both production and daily life can be\nconceptualized as combinatorial optimization problems (COPs) over graphs.\nRecent years, reinforcement learning (RL) based models have emerged as a\npromising direction, which treat the COPs solving as a heuristic learning\nproblem. However, current finite-horizon-MDP based RL models have inherent\nlimitations. They are not allowed to explore adquately for improving solutions\nat test time, which may be necessary given the complexity of NP-hard\noptimization tasks. Some recent attempts solve this issue by focusing on reward\ndesign and state feature engineering, which are tedious and ad-hoc. In this\nwork, we instead propose a much simpler but more effective technique, named\ngauge transformation (GT). The technique is originated from physics, but is\nvery effective in enabling RL agents to explore to continuously improve the\nsolutions during test. Morever, GT is very simple, which can be implemented\nwith less than 10 lines of Python codes, and can be applied to a vast majority\nof RL models. Experimentally, we show that traditional RL models with GT\ntechnique produce the state-of-the-art performances on the MaxCut problem.\nFurthermore, since GT is independent of any RL models, it can be seamlessly\nintegrated into various RL frameworks, paving the way of these models for more\neffective explorations in the solving of general COPs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04661v1",
    "published_date": "2024-04-06 15:31:17 UTC",
    "updated_date": "2024-04-06 15:31:17 UTC"
  },
  {
    "arxiv_id": "2404.04656v1",
    "title": "Binary Classifier Optimization for Large Language Model Alignment",
    "authors": [
      "Seungjae Jung",
      "Gunsoo Han",
      "Daniel Wontae Nam",
      "Kyoung-Woon On"
    ],
    "abstract": "Aligning Large Language Models (LLMs) to human preferences through preference\noptimization has been crucial but labor-intensive, necessitating for each\nprompt a comparison of both a chosen and a rejected text completion by\nevaluators. Recently, Kahneman-Tversky Optimization (KTO) has demonstrated that\nLLMs can be aligned using merely binary \"thumbs-up\" or \"thumbs-down\" signals on\neach prompt-completion pair. In this paper, we present theoretical foundations\nto explain the successful alignment achieved through these binary signals. Our\nanalysis uncovers a new perspective: optimizing a binary classifier, whose\nlogit is a reward, implicitly induces minimizing the Direct Preference\nOptimization (DPO) loss. In the process of this discovery, we identified two\ntechniques for effective alignment: reward shift and underlying distribution\nmatching. Consequently, we propose a new algorithm, \\textit{Binary Classifier\nOptimization}, that integrates the techniques. We validate our methodology in\ntwo settings: first, on a paired preference dataset, where our method performs\non par with DPO and KTO; and second, on binary signal datasets simulating\nreal-world conditions with divergent underlying distributions between thumbs-up\nand thumbs-down data. Our model consistently demonstrates effective and robust\nalignment across two base LLMs and three different binary signal datasets,\nshowcasing the strength of our approach to learning from binary feedback.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.04656v1",
    "published_date": "2024-04-06 15:20:59 UTC",
    "updated_date": "2024-04-06 15:20:59 UTC"
  },
  {
    "arxiv_id": "2404.04642v1",
    "title": "Power-Efficient Image Storage: Leveraging Super Resolution Generative Adversarial Network for Sustainable Compression and Reduced Carbon Footprint",
    "authors": [
      "Ashok Mondal",
      "Satyam Singh"
    ],
    "abstract": "In recent years, large-scale adoption of cloud storage solutions has\nrevolutionized the way we think about digital data storage. However, the\nexponential increase in data volume, especially images, has raised\nenvironmental concerns regarding power and resource consumption, as well as the\nrising digital carbon footprint emissions. The aim of this research is to\npropose a methodology for cloud-based image storage by integrating image\ncompression technology with SuperResolution Generative Adversarial Networks\n(SRGAN). Rather than storing images in their original format directly on the\ncloud, our approach involves initially reducing the image size through\ncompression and downsizing techniques before storage. Upon request, these\ncompressed images will be retrieved and processed by SRGAN to generate images.\nThe efficacy of the proposed method is evaluated in terms of PSNR and SSIM\nmetrics. Additionally, a mathematical analysis is given to calculate power\nconsumption and carbon footprint assesment. The proposed data compression\ntechnique provides a significant solution to achieve a reasonable trade off\nbetween environmental sustainability and industrial efficiency.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG",
      "68T07",
      "I.2.m; H.3.2"
    ],
    "primary_category": "eess.IV",
    "comment": "5 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.04642v1",
    "published_date": "2024-04-06 14:27:22 UTC",
    "updated_date": "2024-04-06 14:27:22 UTC"
  },
  {
    "arxiv_id": "2404.15193v2",
    "title": "Structurally Flexible Neural Networks: Evolving the Building Blocks for General Agents",
    "authors": [
      "Joachim Winther Pedersen",
      "Erwan Plantec",
      "Eleni Nisioti",
      "Milton Montero",
      "Sebastian Risi"
    ],
    "abstract": "Artificial neural networks used for reinforcement learning are structurally\nrigid, meaning that each optimized parameter of the network is tied to its\nspecific placement in the network structure. It also means that a network only\nworks with pre-defined and fixed input- and output sizes. This is a consequence\nof having the number of optimized parameters being directly dependent on the\nstructure of the network. Structural rigidity limits the ability to optimize\nparameters of policies across multiple environments that do not share input and\noutput spaces. Here, we evolve a set of neurons and plastic synapses each\nrepresented by a gated recurrent unit (GRU). During optimization, the\nparameters of these fundamental units of a neural network are optimized in\ndifferent random structural configurations. Earlier work has shown that\nparameter sharing between units is important for making structurally flexible\nneurons We show that it is possible to optimize a set of distinct neuron- and\nsynapse types allowing for a mitigation of the symmetry dilemma. We demonstrate\nthis by optimizing a single set of neurons and synapses to solve multiple\nreinforcement learning control tasks simultaneously.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15193v2",
    "published_date": "2024-04-06 14:04:14 UTC",
    "updated_date": "2024-05-17 09:21:03 UTC"
  },
  {
    "arxiv_id": "2404.04626v1",
    "title": "Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective",
    "authors": [
      "Duanyu Feng",
      "Bowen Qin",
      "Chen Huang",
      "Zheng Zhang",
      "Wenqiang Lei"
    ],
    "abstract": "Direct Preference Optimization (DPO), which derives reward signals directly\nfrom pairwise preference data, has shown its effectiveness on aligning Large\nLanguage Models (LLMs) with human preferences. Despite its widespread use\nacross various tasks, DPO has been criticized for its sensitivity to the SFT's\neffectiveness and its hindrance to the learning capacity towards\nhuman-preferred responses, leading to less satisfactory performance. To\novercome those limitations, the theoretical understanding of DPO are\nindispensable but still lacking. To this end, we take a step towards\ntheoretically analyzing and understanding the limitations of DPO. Specifically,\nwe provide an analytical framework using the field theory to analyze the\noptimization process of DPO. By analyzing the gradient vector field of the DPO\nloss function, we find that the DPO loss function decreases the probability of\nproducing human dispreferred data at a faster rate than it increases the\nprobability of producing preferred data. This provides theoretical insights for\nunderstanding the limitations of DPO discovered in the related research\nexperiments, thereby setting the foundation for its improvement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Draft version",
    "pdf_url": "http://arxiv.org/pdf/2404.04626v1",
    "published_date": "2024-04-06 13:24:37 UTC",
    "updated_date": "2024-04-06 13:24:37 UTC"
  },
  {
    "arxiv_id": "2404.04619v1",
    "title": "Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model",
    "authors": [
      "Zhonghan Zhao",
      "Ke Ma",
      "Wenhao Chai",
      "Xuan Wang",
      "Kewei Chen",
      "Dongxu Guo",
      "Yanting Zhang",
      "Hongwei Wang",
      "Gaoang Wang"
    ],
    "abstract": "With the power of large language models (LLMs), open-ended embodied agents\ncan flexibly understand human instructions, generate interpretable guidance\nstrategies, and output executable actions. Nowadays, Multi-modal Language\nModels~(MLMs) integrate multi-modal signals into LLMs, further bringing richer\nperception to entity agents and allowing embodied agents to perceive\nworld-understanding tasks more delicately. However, existing works: 1) operate\nindependently by agents, each containing multiple LLMs, from perception to\naction, resulting in gaps between complex tasks and execution; 2) train MLMs on\nstatic data, struggling with dynamics in open-ended scenarios; 3) input prior\nknowledge directly as prompts, suppressing application flexibility. We propose\nSTEVE-2, a hierarchical knowledge distillation framework for open-ended\nembodied tasks, characterized by 1) a hierarchical system for multi-granular\ntask division, 2) a mirrored distillation method for parallel simulation data,\nand 3) an extra expert model for bringing additional knowledge into parallel\nsimulation. After distillation, embodied agents can complete complex,\nopen-ended tasks without additional expert guidance, utilizing the performance\nand knowledge of a versatile MLM. Extensive evaluations on navigation and\ncreation tasks highlight the superior performance of STEVE-2 in open-ended\ntasks, with $1.4 \\times$ - $7.3 \\times$ in performance.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2403.08282",
    "pdf_url": "http://arxiv.org/pdf/2404.04619v1",
    "published_date": "2024-04-06 12:51:00 UTC",
    "updated_date": "2024-04-06 12:51:00 UTC"
  },
  {
    "arxiv_id": "2404.04615v1",
    "title": "PointSAGE: Mesh-independent superresolution approach to fluid flow predictions",
    "authors": [
      "Rajat Sarkar",
      "Krishna Sai Sudhir Aripirala",
      "Vishal Sudam Jadhav",
      "Sagar Srinivas Sakhinana",
      "Venkataramana Runkana"
    ],
    "abstract": "Computational Fluid Dynamics (CFD) serves as a powerful tool for simulating\nfluid flow across diverse industries. High-resolution CFD simulations offer\nvaluable insights into fluid behavior and flow patterns, aiding in optimizing\ndesign features or enhancing system performance. However, as resolution\nincreases, computational data requirements and time increase proportionately.\nThis presents a persistent challenge in CFD. Recently, efforts have been\ndirected towards accurately predicting fine-mesh simulations using coarse-mesh\nsimulations, with geometry and boundary conditions as input. Drawing\ninspiration from models designed for super-resolution, deep learning techniques\nlike UNets have been applied to address this challenge. However, these existing\nmethods are limited to structured data and fail if the mesh is unstructured due\nto its inability to convolute. Additionally, incorporating geometry/mesh\ninformation in the training process introduces drawbacks such as increased data\nrequirements, challenges in generalizing to unseen geometries for the same\nphysical phenomena, and issues with robustness to mesh distortions. To address\nthese concerns, we propose a novel framework, PointSAGE a mesh-independent\nnetwork that leverages the unordered, mesh-less nature of Pointcloud to learn\nthe complex fluid flow and directly predict fine simulations, completely\nneglecting mesh information. Utilizing an adaptable framework, the model\naccurately predicts the fine data across diverse point cloud sizes, regardless\nof the training dataset's dimension. We have evaluated the effectiveness of\nPointSAGE on diverse datasets in different scenarios, demonstrating notable\nresults and a significant acceleration in computational time in generating fine\nsimulations compared to standard CFD techniques.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "Accepted at Data-Centric Machine Learning Workshop (DMLR) at ICLR,\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04615v1",
    "published_date": "2024-04-06 12:49:09 UTC",
    "updated_date": "2024-04-06 12:49:09 UTC"
  },
  {
    "arxiv_id": "2404.08675v1",
    "title": "RecGPT: Generative Personalized Prompts for Sequential Recommendation via ChatGPT Training Paradigm",
    "authors": [
      "Yabin Zhang",
      "Wenhui Yu",
      "Erhan Zhang",
      "Xu Chen",
      "Lantao Hu",
      "Peng Jiang",
      "Kun Gai"
    ],
    "abstract": "ChatGPT has achieved remarkable success in natural language understanding.\nConsidering that recommendation is indeed a conversation between users and the\nsystem with items as words, which has similar underlying pattern with ChatGPT,\nwe design a new chat framework in item index level for the recommendation task.\nOur novelty mainly contains three parts: model, training and inference. For the\nmodel part, we adopt Generative Pre-training Transformer (GPT) as the\nsequential recommendation model and design a user modular to capture\npersonalized information. For the training part, we adopt the two-stage\nparadigm of ChatGPT, including pre-training and fine-tuning. In the\npre-training stage, we train GPT model by auto-regression. In the fine-tuning\nstage, we train the model with prompts, which include both the newly-generated\nresults from the model and the user's feedback. For the inference part, we\npredict several user interests as user representations in an autoregressive\nmanner. For each interest vector, we recall several items with the highest\nsimilarity and merge the items recalled by all interest vectors into the final\nresult. We conduct experiments with both offline public datasets and online A/B\ntest to demonstrate the effectiveness of our proposed method.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08675v1",
    "published_date": "2024-04-06 12:38:54 UTC",
    "updated_date": "2024-04-06 12:38:54 UTC"
  },
  {
    "arxiv_id": "2404.04608v2",
    "title": "Panoptic Perception: A Novel Task and Fine-grained Dataset for Universal Remote Sensing Image Interpretation",
    "authors": [
      "Danpei Zhao",
      "Bo Yuan",
      "Ziqiang Chen",
      "Tian Li",
      "Zhuoran Liu",
      "Wentao Li",
      "Yue Gao"
    ],
    "abstract": "Current remote-sensing interpretation models often focus on a single task\nsuch as detection, segmentation, or caption. However, the task-specific\ndesigned models are unattainable to achieve the comprehensive multi-level\ninterpretation of images. The field also lacks support for multi-task joint\ninterpretation datasets. In this paper, we propose Panoptic Perception, a novel\ntask and a new fine-grained dataset (FineGrip) to achieve a more thorough and\nuniversal interpretation for RSIs. The new task, 1) integrates pixel-level,\ninstance-level, and image-level information for universal image perception, 2)\ncaptures image information from coarse to fine granularity, achieving deeper\nscene understanding and description, and 3) enables various independent tasks\nto complement and enhance each other through multi-task learning. By\nemphasizing multi-task interactions and the consistency of perception results,\nthis task enables the simultaneous processing of fine-grained foreground\ninstance segmentation, background semantic segmentation, and global\nfine-grained image captioning. Concretely, the FineGrip dataset includes 2,649\nremote sensing images, 12,054 fine-grained instance segmentation masks\nbelonging to 20 foreground things categories, 7,599 background semantic masks\nfor 5 stuff classes and 13,245 captioning sentences. Furthermore, we propose a\njoint optimization-based panoptic perception model. Experimental results on\nFineGrip demonstrate the feasibility of the panoptic perception task and the\nbeneficial effect of multi-task joint optimization on individual tasks. The\ndataset will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04608v2",
    "published_date": "2024-04-06 12:27:21 UTC",
    "updated_date": "2024-04-26 01:07:26 UTC"
  },
  {
    "arxiv_id": "2404.05762v1",
    "title": "Evaluating the Effectiveness of Artificial Intelligence in Predicting Adverse Drug Reactions among Cancer Patients: A Systematic Review and Meta-Analysis",
    "authors": [
      "Fatma Zahra Abdeldjouad",
      "Menaouer Brahami",
      "Mohammed Sabri"
    ],
    "abstract": "Adverse drug reactions considerably impact patient outcomes and healthcare\ncosts in cancer therapy. Using artificial intelligence to predict adverse drug\nreactions in real time could revolutionize oncology treatment. This study aims\nto assess the performance of artificial intelligence models in predicting\nadverse drug reactions in patients with cancer. This is the first systematic\nreview and meta-analysis. Scopus, PubMed, IEEE Xplore, and ACM Digital Library\ndatabases were searched for studies in English, French, and Arabic from January\n1, 2018, to August 20, 2023. The inclusion criteria were: (1) peer-reviewed\nresearch articles; (2) use of artificial intelligence algorithms (machine\nlearning, deep learning, knowledge graphs); (3) study aimed to predict adverse\ndrug reactions (cardiotoxicity, neutropenia, nephrotoxicity, hepatotoxicity);\n(4) study was on cancer patients. The data were extracted and evaluated by\nthree reviewers for study quality. Of the 332 screened articles, 17 studies\n(5%) involving 93,248 oncology patients from 17 countries were included in the\nsystematic review, of which ten studies synthesized the meta-analysis. A\nrandom-effects model was created to pool the sensitivity, specificity, and AUC\nof the included studies. The pooled results were 0.82 (95% CI:0.69, 0.9), 0.84\n(95% CI:0.75, 0.9), and 0.83 (95% CI:0.77, 0.87) for sensitivity, specificity,\nand AUC, respectively, of ADR predictive models. Biomarkers proved their\neffectiveness in predicting ADRs, yet they were adopted by only half of the\nreviewed studies. The use of AI in cancer treatment shows great potential, with\nmodels demonstrating high specificity and sensitivity in predicting ADRs.\nHowever, standardized research and multicenter studies are needed to improve\nthe quality of evidence. AI can enhance cancer patient care by bridging the gap\nbetween data-driven insights and clinical expertise.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Paper has been accepted at the IEEE Challenges and Innovations on TIC\n  (IEEE I2CIT) International Conference",
    "pdf_url": "http://arxiv.org/pdf/2404.05762v1",
    "published_date": "2024-04-06 11:20:28 UTC",
    "updated_date": "2024-04-06 11:20:28 UTC"
  },
  {
    "arxiv_id": "2404.04587v2",
    "title": "Neuroevolving Electronic Dynamical Networks",
    "authors": [
      "Derek Whitley"
    ],
    "abstract": "Neuroevolution is a powerful method of applying an evolutionary algorithm to\nrefine the performance of artificial neural networks through natural selection;\nhowever, the fitness evaluation of these networks can be time-consuming and\ncomputationally expensive, particularly for continuous time recurrent neural\nnetworks (CTRNNs) that necessitate the simulation of differential equations. To\novercome this challenge, field programmable gate arrays (FPGAs) have emerged as\nan increasingly popular solution, due to their high performance and low power\nconsumption. Further, their ability to undergo dynamic and partial\nreconfiguration enables the extremely rapid evaluation of the fitness of\nCTRNNs, effectively addressing the bottleneck associated with conventional\nmethods of evolvable hardware. By incorporating fitness evaluation directly\nupon the programmable logic of the FPGA, hyper-parallel evaluation becomes\nfeasible, dramatically reducing the time required for assessment. This inherent\nparallelism of FPGAs accelerates the entire neuroevolutionary process by\nseveral orders of magnitude, facilitating faster convergence to an optimal\nsolution. The work presented in this study demonstrates the potential of\nutilizing dynamic and partial reconfiguration on capable FPGAs as a powerful\nplatform for neuroevolving dynamic neural networks.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.NE",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.04587v2",
    "published_date": "2024-04-06 10:54:35 UTC",
    "updated_date": "2024-04-17 14:50:36 UTC"
  },
  {
    "arxiv_id": "2404.04575v3",
    "title": "To Cool or not to Cool? Temperature Network Meets Large Foundation Models via DRO",
    "authors": [
      "Zi-Hao Qiu",
      "Siqi Guo",
      "Mao Xu",
      "Tuo Zhao",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "abstract": "The temperature parameter plays a profound role during training and/or\ninference with large foundation models (LFMs) such as large language models\n(LLMs) and CLIP models. Particularly, it adjusts the logits in the softmax\nfunction in LLMs, which is crucial for next token generation, and it scales the\nsimilarities in the contrastive loss for training CLIP models. A significant\nquestion remains: Is it viable to learn a neural network to predict a\npersonalized temperature of any input data for enhancing LFMs\"? In this paper,\nwe present a principled framework for learning a small yet generalizable\ntemperature prediction network (TempNet) to improve LFMs. Our solution is\ncomposed of a novel learning framework with a robust loss underpinned by\nconstrained distributionally robust optimization (DRO), and a properly designed\nTempNet with theoretical inspiration. TempNet can be trained together with a\nlarge foundation model from scratch or learned separately given a pretrained\nfoundation model. It is not only useful for predicting personalized temperature\nto promote the training of LFMs but also generalizable and transferable to new\ntasks. Our experiments on LLMs and CLIP models demonstrate that TempNet greatly\nimproves the performance of existing solutions or models, e.g. Table 1. The\ncode to reproduce the experimental results in this paper can be found at\nhttps://github.com/zhqiu/TempNet.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "41 pages, 10 figures, accepted by ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04575v3",
    "published_date": "2024-04-06 09:55:03 UTC",
    "updated_date": "2024-06-16 12:43:39 UTC"
  },
  {
    "arxiv_id": "2404.04564v1",
    "title": "Enhancing Video Summarization with Context Awareness",
    "authors": [
      "Hai-Dang Huynh-Lam",
      "Ngoc-Phuong Ho-Thi",
      "Minh-Triet Tran",
      "Trung-Nghia Le"
    ],
    "abstract": "Video summarization is a crucial research area that aims to efficiently\nbrowse and retrieve relevant information from the vast amount of video content\navailable today. With the exponential growth of multimedia data, the ability to\nextract meaningful representations from videos has become essential. Video\nsummarization techniques automatically generate concise summaries by selecting\nkeyframes, shots, or segments that capture the video's essence. This process\nimproves the efficiency and accuracy of various applications, including video\nsurveillance, education, entertainment, and social media. Despite the\nimportance of video summarization, there is a lack of diverse and\nrepresentative datasets, hindering comprehensive evaluation and benchmarking of\nalgorithms. Existing evaluation metrics also fail to fully capture the\ncomplexities of video summarization, limiting accurate algorithm assessment and\nhindering the field's progress. To overcome data scarcity challenges and\nimprove evaluation, we propose an unsupervised approach that leverages video\ndata structure and information for generating informative summaries. By moving\naway from fixed annotations, our framework can produce representative summaries\neffectively. Moreover, we introduce an innovative evaluation pipeline tailored\nspecifically for video summarization. Human participants are involved in the\nevaluation, comparing our generated summaries to ground truth summaries and\nassessing their informativeness. This human-centric approach provides valuable\ninsights into the effectiveness of our proposed techniques. Experimental\nresults demonstrate that our training-free framework outperforms existing\nunsupervised approaches and achieves competitive results compared to\nstate-of-the-art supervised methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "115 pages, 1 supplementary paper, undergraduate thesis report at\n  US-VNUHCM",
    "pdf_url": "http://arxiv.org/pdf/2404.04564v1",
    "published_date": "2024-04-06 09:08:34 UTC",
    "updated_date": "2024-04-06 09:08:34 UTC"
  },
  {
    "arxiv_id": "2404.04547v1",
    "title": "Exhaustive Exploitation of Nature-inspired Computation for Cancer Screening in an Ensemble Manner",
    "authors": [
      "Xubin Wang",
      "Yunhe Wang",
      "Zhiqing Ma",
      "Ka-Chun Wong",
      "Xiangtao Li"
    ],
    "abstract": "Accurate screening of cancer types is crucial for effective cancer detection\nand precise treatment selection. However, the association between gene\nexpression profiles and tumors is often limited to a small number of biomarker\ngenes. While computational methods using nature-inspired algorithms have shown\npromise in selecting predictive genes, existing techniques are limited by\ninefficient search and poor generalization across diverse datasets. This study\npresents a framework termed Evolutionary Optimized Diverse Ensemble Learning\n(EODE) to improve ensemble learning for cancer classification from gene\nexpression data. The EODE methodology combines an intelligent grey wolf\noptimization algorithm for selective feature space reduction, guided random\ninjection modeling for ensemble diversity enhancement, and subset model\noptimization for synergistic classifier combinations. Extensive experiments\nwere conducted across 35 gene expression benchmark datasets encompassing varied\ncancer types. Results demonstrated that EODE obtained significantly improved\nscreening accuracy over individual and conventionally aggregated models. The\nintegrated optimization of advanced feature selection, directed specialized\nmodeling, and cooperative classifier ensembles helps address key challenges in\ncurrent nature-inspired approaches. This provides an effective framework for\nrobust and generalized ensemble learning with gene expression biomarkers.\nSpecifically, we have opened EODE source code on Github at\nhttps://github.com/wangxb96/EODE.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04547v1",
    "published_date": "2024-04-06 08:07:48 UTC",
    "updated_date": "2024-04-06 08:07:48 UTC"
  },
  {
    "arxiv_id": "2404.04544v1",
    "title": "BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion",
    "authors": [
      "Gwanghyun Kim",
      "Hayeon Kim",
      "Hoigi Seo",
      "Dong Un Kang",
      "Se Young Chun"
    ],
    "abstract": "Generating higher-resolution human-centric scenes with details and controls\nremains a challenge for existing text-to-image diffusion models. This challenge\nstems from limited training image size, text encoder capacity (limited tokens),\nand the inherent difficulty of generating complex scenes involving multiple\nhumans. While current methods attempted to address training size limit only,\nthey often yielded human-centric scenes with severe artifacts. We propose\nBeyondScene, a novel framework that overcomes prior limitations, generating\nexquisite higher-resolution (over 8K) human-centric scenes with exceptional\ntext-image correspondence and naturalness using existing pretrained diffusion\nmodels. BeyondScene employs a staged and hierarchical approach to initially\ngenerate a detailed base image focusing on crucial elements in instance\ncreation for multiple humans and detailed descriptions beyond token limit of\ndiffusion model, and then to seamlessly convert the base image to a\nhigher-resolution output, exceeding training image size and incorporating\ndetails aware of text and instances via our novel instance-aware hierarchical\nenlargement process that consists of our proposed high-frequency injected\nforward diffusion and adaptive joint diffusion. BeyondScene surpasses existing\nmethods in terms of correspondence with detailed text descriptions and\nnaturalness, paving the way for advanced applications in higher-resolution\nhuman-centric scene creation beyond the capacity of pretrained diffusion models\nwithout costly retraining. Project page:\nhttps://janeyeon.github.io/beyond-scene.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://janeyeon.github.io/beyond-scene",
    "pdf_url": "http://arxiv.org/pdf/2404.04544v1",
    "published_date": "2024-04-06 07:53:49 UTC",
    "updated_date": "2024-04-06 07:53:49 UTC"
  },
  {
    "arxiv_id": "2404.04540v1",
    "title": "The Case for Developing a Foundation Model for Planning-like Tasks from Scratch",
    "authors": [
      "Biplav Srivastava",
      "Vishal Pallagani"
    ],
    "abstract": "Foundation Models (FMs) have revolutionized many areas of computing,\nincluding Automated Planning and Scheduling (APS). For example, a recent study\nfound them useful for planning problems: plan generation, language translation,\nmodel construction, multi-agent planning, interactive planning, heuristics\noptimization, tool integration, and brain-inspired planning. Besides APS, there\nare many seemingly related tasks involving the generation of a series of\nactions with varying guarantees of their executability to achieve intended\ngoals, which we collectively call planning-like (PL) tasks like business\nprocesses, programs, workflows, and guidelines, where researchers have\nconsidered using FMs. However, previous works have primarily focused on\npre-trained, off-the-shelf FMs and optionally fine-tuned them. This paper\ndiscusses the need for a comprehensive FM for PL tasks from scratch and\nexplores its design considerations. We argue that such an FM will open new and\nefficient avenues for PL problem-solving, just like LLMs are creating for APS.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04540v1",
    "published_date": "2024-04-06 07:44:40 UTC",
    "updated_date": "2024-04-06 07:44:40 UTC"
  },
  {
    "arxiv_id": "2404.04538v1",
    "title": "Soft-Prompting with Graph-of-Thought for Multi-modal Representation Learning",
    "authors": [
      "Juncheng Yang",
      "Zuchao Li",
      "Shuai Xie",
      "Wei Yu",
      "Shijun Li",
      "Bo Du"
    ],
    "abstract": "The chain-of-thought technique has been received well in multi-modal tasks.\nIt is a step-by-step linear reasoning process that adjusts the length of the\nchain to improve the performance of generated prompts. However, human thought\nprocesses are predominantly non-linear, as they encompass multiple aspects\nsimultaneously and employ dynamic adjustment and updating mechanisms.\nTherefore, we propose a novel Aggregation-Graph-of-Thought (AGoT) mechanism for\nsoft-prompt tuning in multi-modal representation learning. The proposed AGoT\nmodels the human thought process not only as a chain but also models each step\nas a reasoning aggregation graph to cope with the overlooked multiple aspects\nof thinking in single-step reasoning. This turns the entire reasoning process\ninto prompt aggregation and prompt flow operations. Experiments show that our\nmulti-modal model enhanced with AGoT soft-prompting achieves good results in\nseveral tasks such as text-image retrieval, visual question answering, and\nimage recognition. In addition, we demonstrate that it has good domain\ngeneralization performance due to better reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper is accepted to LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04538v1",
    "published_date": "2024-04-06 07:39:44 UTC",
    "updated_date": "2024-04-06 07:39:44 UTC"
  },
  {
    "arxiv_id": "2404.04534v2",
    "title": "Impact of Fairness Regulations on Institutions' Policies and Population Qualifications",
    "authors": [
      "Hamidreza Montaseri",
      "Amin Gohari"
    ],
    "abstract": "The proliferation of algorithmic systems has fueled discussions surrounding\nthe regulation and control of their social impact. Herein, we consider a system\nwhose primary objective is to maximize utility by selecting the most qualified\nindividuals. To promote demographic parity in the selection algorithm, we\nconsider penalizing discrimination across social groups. We examine conditions\nunder which a discrimination penalty can effectively reduce disparity in the\nselection. Additionally, we explore the implications of such a penalty when\nindividual qualifications may evolve over time in response to the imposed\npenalizing policy. We identify scenarios where the penalty could hinder the\nnatural attainment of equity within the population. Moreover, we propose\ncertain conditions that can counteract this undesirable outcome, thus ensuring\nfairness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Added experiments",
    "pdf_url": "http://arxiv.org/pdf/2404.04534v2",
    "published_date": "2024-04-06 07:21:41 UTC",
    "updated_date": "2024-05-19 11:40:42 UTC"
  },
  {
    "arxiv_id": "2404.04527v1",
    "title": "VTR: An Optimized Vision Transformer for SAR ATR Acceleration on FPGA",
    "authors": [
      "Sachini Wickramasinghe",
      "Dhruv Parikh",
      "Bingyi Zhang",
      "Rajgopal Kannan",
      "Viktor Prasanna",
      "Carl Busart"
    ],
    "abstract": "Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) is a key\ntechnique used in military applications like remote-sensing image recognition.\nVision Transformers (ViTs) are the current state-of-the-art in various computer\nvision applications, outperforming their CNN counterparts. However, using ViTs\nfor SAR ATR applications is challenging due to (1) standard ViTs require\nextensive training data to generalize well due to their low locality; the\nstandard SAR datasets, however, have a limited number of labeled training data\nwhich reduces the learning capability of ViTs; (2) ViTs have a high parameter\ncount and are computation intensive which makes their deployment on\nresource-constrained SAR platforms difficult. In this work, we develop a\nlightweight ViT model that can be trained directly on small datasets without\nany pre-training by utilizing the Shifted Patch Tokenization (SPT) and Locality\nSelf-Attention (LSA) modules. We directly train this model on SAR datasets\nwhich have limited training samples to evaluate its effectiveness for SAR ATR\napplications. We evaluate our proposed model, that we call VTR (ViT for SAR\nATR), on three widely used SAR datasets: MSTAR, SynthWakeSAR, and GBSAR.\nFurther, we propose a novel FPGA accelerator for VTR, in order to enable\ndeployment for real-time SAR ATR applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.AR",
      "cs.DC"
    ],
    "primary_category": "cs.CV",
    "comment": "SPIE DCS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04527v1",
    "published_date": "2024-04-06 06:49:55 UTC",
    "updated_date": "2024-04-06 06:49:55 UTC"
  },
  {
    "arxiv_id": "2404.04525v1",
    "title": "IITK at SemEval-2024 Task 10: Who is the speaker? Improving Emotion Recognition and Flip Reasoning in Conversations via Speaker Embeddings",
    "authors": [
      "Shubham Patel",
      "Divyaksh Shukla",
      "Ashutosh Modi"
    ],
    "abstract": "This paper presents our approach for the SemEval-2024 Task 10: Emotion\nDiscovery and Reasoning its Flip in Conversations. For the Emotion Recognition\nin Conversations (ERC) task, we utilize a masked-memory network along with\nspeaker participation. We propose a transformer-based speaker-centric model for\nthe Emotion Flip Reasoning (EFR) task. We also introduce Probable Trigger Zone,\na region of the conversation that is more likely to contain the utterances\ncausing the emotion to flip. For sub-task 3, the proposed approach achieves a\n5.9 (F1 score) improvement over the task baseline. The ablation study results\nhighlight the significance of various design choices in the proposed method.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SemEval 2024, NAACL 2024; 10 Pages",
    "pdf_url": "http://arxiv.org/pdf/2404.04525v1",
    "published_date": "2024-04-06 06:47:44 UTC",
    "updated_date": "2024-04-06 06:47:44 UTC"
  },
  {
    "arxiv_id": "2404.04522v2",
    "title": "Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models",
    "authors": [
      "Zhiyuan Peng",
      "Xuyang Wu",
      "Qifan Wang",
      "Sravanthi Rajanala",
      "Yi Fang"
    ],
    "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods have been extensively utilized\nin Large Language Models (LLMs) to improve the down-streaming tasks without the\ncost of fine-tuing the whole LLMs. Recent studies have shown how to effectively\nuse PEFT for fine-tuning LLMs in ranking tasks with convincing performance;\nthere are some limitations, including the learned prompt being fixed for\ndifferent documents, overfitting to specific tasks, and low adaptation ability.\nIn this paper, we introduce a query-dependent parameter efficient fine-tuning\n(Q-PEFT) approach for text reranking to leak the information of the true\nqueries to LLMs and then make the generation of true queries from input\ndocuments much easier. Specifically, we utilize the query to extract the\ntop-$k$ tokens from concatenated documents, serving as contextual clues. We\nfurther augment Q-PEFT by substituting the retrieval mechanism with a\nmulti-head attention layer to achieve end-to-end training and cover all the\ntokens in the documents, guiding the LLMs to generate more document-specific\nsynthetic queries, thereby further improving the reranking performance.\nExtensive experiments are conducted on four public datasets, demonstrating the\neffectiveness of our proposed approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04522v2",
    "published_date": "2024-04-06 06:44:41 UTC",
    "updated_date": "2024-04-12 00:18:06 UTC"
  },
  {
    "arxiv_id": "2404.04520v1",
    "title": "IITK at SemEval-2024 Task 4: Hierarchical Embeddings for Detection of Persuasion Techniques in Memes",
    "authors": [
      "Shreenaga Chikoti",
      "Shrey Mehta",
      "Ashutosh Modi"
    ],
    "abstract": "Memes are one of the most popular types of content used in an online\ndisinformation campaign. They are primarily effective on social media platforms\nsince they can easily reach many users. Memes in a disinformation campaign\nachieve their goal of influencing the users through several rhetorical and\npsychological techniques, such as causal oversimplification, name-calling, and\nsmear. The SemEval 2024 Task 4 \\textit{Multilingual Detection of Persuasion\nTechnique in Memes} on identifying such techniques in the memes is divided\nacross three sub-tasks: ($\\mathbf{1}$) Hierarchical multi-label classification\nusing only textual content of the meme, ($\\mathbf{2}$) Hierarchical multi-label\nclassification using both, textual and visual content of the meme and\n($\\mathbf{3}$) Binary classification of whether the meme contains a persuasion\ntechnique or not using it's textual and visual content. This paper proposes an\nensemble of Class Definition Prediction (CDP) and hyperbolic embeddings-based\napproaches for this task. We enhance meme classification accuracy and\ncomprehensiveness by integrating HypEmo's hierarchical label embeddings (Chen\net al., 2023) and a multi-task learning framework for emotion prediction. We\nachieve a hierarchical F1-score of 0.60, 0.67, and 0.48 on the respective\nsub-tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SemEval 2024, NAACL 2024; 9 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.04520v1",
    "published_date": "2024-04-06 06:28:02 UTC",
    "updated_date": "2024-04-06 06:28:02 UTC"
  },
  {
    "arxiv_id": "2404.07234v4",
    "title": "Goal-guided Generative Prompt Injection Attack on Large Language Models",
    "authors": [
      "Chong Zhang",
      "Mingyu Jin",
      "Qinkai Yu",
      "Chengzhi Liu",
      "Haochen Xue",
      "Xiaobo Jin"
    ],
    "abstract": "Current large language models (LLMs) provide a strong foundation for\nlarge-scale user-oriented natural language tasks. A large number of users can\neasily inject adversarial text or instructions through the user interface, thus\ncausing LLMs model security challenges. Although there is currently a large\namount of research on prompt injection attacks, most of these black-box attacks\nuse heuristic strategies. It is unclear how these heuristic strategies relate\nto the success rate of attacks and thus effectively improve model robustness.\nTo solve this problem, we redefine the goal of the attack: to maximize the KL\ndivergence between the conditional probabilities of the clean text and the\nadversarial text. Furthermore, we prove that maximizing the KL divergence is\nequivalent to maximizing the Mahalanobis distance between the embedded\nrepresentation $x$ and $x'$ of the clean text and the adversarial text when the\nconditional probability is a Gaussian distribution and gives a quantitative\nrelationship on $x$ and $x'$. Then we designed a simple and effective\ngoal-guided generative prompt injection strategy (G2PIA) to find an injection\ntext that satisfies specific constraints to achieve the optimal attack effect\napproximately. It is particularly noteworthy that our attack method is a\nquery-free black-box attack method with low computational cost. Experimental\nresults on seven LLM models and four datasets show the effectiveness of our\nattack method.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.07234v4",
    "published_date": "2024-04-06 06:17:10 UTC",
    "updated_date": "2024-11-09 04:01:22 UTC"
  },
  {
    "arxiv_id": "2404.04517v2",
    "title": "Latent-based Diffusion Model for Long-tailed Recognition",
    "authors": [
      "Pengxiao Han",
      "Changkun Ye",
      "Jieming Zhou",
      "Jing Zhang",
      "Jie Hong",
      "Xuesong Li"
    ],
    "abstract": "Long-tailed imbalance distribution is a common issue in practical computer\nvision applications. Previous works proposed methods to address this problem,\nwhich can be categorized into several classes: re-sampling, re-weighting,\ntransfer learning, and feature augmentation. In recent years, diffusion models\nhave shown an impressive generation ability in many sub-problems of deep\ncomputer vision. However, its powerful generation has not been explored in\nlong-tailed problems. We propose a new approach, the Latent-based Diffusion\nModel for Long-tailed Recognition (LDMLR), as a feature augmentation method to\ntackle the issue. First, we encode the imbalanced dataset into features using\nthe baseline model. Then, we train a Denoising Diffusion Implicit Model (DDIM)\nusing these encoded features to generate pseudo-features. Finally, we train the\nclassifier using the encoded and pseudo-features from the previous two steps.\nThe model's accuracy shows an improvement on the CIFAR-LT and ImageNet-LT\ndatasets by using the proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 3 figures. Accepted by L3DIVU-CVPR2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04517v2",
    "published_date": "2024-04-06 06:15:07 UTC",
    "updated_date": "2024-04-23 04:54:51 UTC"
  },
  {
    "arxiv_id": "2404.04513v1",
    "title": "IITK at SemEval-2024 Task 1: Contrastive Learning and Autoencoders for Semantic Textual Relatedness in Multilingual Texts",
    "authors": [
      "Udvas Basak",
      "Rajarshi Dutta",
      "Shivam Pandey",
      "Ashutosh Modi"
    ],
    "abstract": "This paper describes our system developed for the SemEval-2024 Task 1:\nSemantic Textual Relatedness. The challenge is focused on automatically\ndetecting the degree of relatedness between pairs of sentences for 14 languages\nincluding both high and low-resource Asian and African languages. Our team\nparticipated in two subtasks consisting of Track A: supervised and Track B:\nunsupervised. This paper focuses on a BERT-based contrastive learning and\nsimilarity metric based approach primarily for the supervised track while\nexploring autoencoders for the unsupervised track. It also aims on the creation\nof a bigram relatedness corpus using negative sampling strategy, thereby\nproducing refined word embeddings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SemEval 2024, NAACL 2024; 6 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.04513v1",
    "published_date": "2024-04-06 05:58:42 UTC",
    "updated_date": "2024-04-06 05:58:42 UTC"
  },
  {
    "arxiv_id": "2404.04511v1",
    "title": "Cluster-based Video Summarization with Temporal Context Awareness",
    "authors": [
      "Hai-Dang Huynh-Lam",
      "Ngoc-Phuong Ho-Thi",
      "Minh-Triet Tran",
      "Trung-Nghia Le"
    ],
    "abstract": "In this paper, we present TAC-SUM, a novel and efficient training-free\napproach for video summarization that addresses the limitations of existing\ncluster-based models by incorporating temporal context. Our method partitions\nthe input video into temporally consecutive segments with clustering\ninformation, enabling the injection of temporal awareness into the clustering\nprocess, setting it apart from prior cluster-based summarization methods. The\nresulting temporal-aware clusters are then utilized to compute the final\nsummary, using simple rules for keyframe selection and frame importance\nscoring. Experimental results on the SumMe dataset demonstrate the\neffectiveness of our proposed approach, outperforming existing unsupervised\nmethods and achieving comparable performance to state-of-the-art supervised\nsummarization techniques. Our source code is available for reference at\n\\url{https://github.com/hcmus-thesis-gulu/TAC-SUM}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 6 figures, accepted in PSIVT 2023",
    "pdf_url": "http://arxiv.org/pdf/2404.04511v1",
    "published_date": "2024-04-06 05:55:14 UTC",
    "updated_date": "2024-04-06 05:55:14 UTC"
  },
  {
    "arxiv_id": "2404.04510v1",
    "title": "IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials",
    "authors": [
      "Shreyasi Mandal",
      "Ashutosh Modi"
    ],
    "abstract": "Large Language models (LLMs) have demonstrated state-of-the-art performance\nin various natural language processing (NLP) tasks across multiple domains, yet\nthey are prone to shortcut learning and factual inconsistencies. This research\ninvestigates LLMs' robustness, consistency, and faithful reasoning when\nperforming Natural Language Inference (NLI) on breast cancer Clinical Trial\nReports (CTRs) in the context of SemEval 2024 Task 2: Safe Biomedical Natural\nLanguage Inference for Clinical Trials. We examine the reasoning capabilities\nof LLMs and their adeptness at logical problem-solving. A comparative analysis\nis conducted on pre-trained language models (PLMs), GPT-3.5, and Gemini Pro\nunder zero-shot settings using Retrieval-Augmented Generation (RAG) framework,\nintegrating various reasoning chains. The evaluation yields an F1 score of\n0.69, consistency of 0.71, and a faithfulness score of 0.90 on the test\ndataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SemEval 2024, NAACL 2024; 8 Pages",
    "pdf_url": "http://arxiv.org/pdf/2404.04510v1",
    "published_date": "2024-04-06 05:44:53 UTC",
    "updated_date": "2024-04-06 05:44:53 UTC"
  },
  {
    "arxiv_id": "2404.04500v1",
    "title": "Trustless Audits without Revealing Data or Models",
    "authors": [
      "Suppakit Waiwitlikhit",
      "Ion Stoica",
      "Yi Sun",
      "Tatsunori Hashimoto",
      "Daniel Kang"
    ],
    "abstract": "There is an increasing conflict between business incentives to hide models\nand data as trade secrets, and the societal need for algorithmic transparency.\nFor example, a rightsholder wishing to know whether their copyrighted works\nhave been used during training must convince the model provider to allow a\nthird party to audit the model and data. Finding a mutually agreeable third\nparty is difficult, and the associated costs often make this approach\nimpractical.\n  In this work, we show that it is possible to simultaneously allow model\nproviders to keep their model weights (but not architecture) and data secret\nwhile allowing other parties to trustlessly audit model and data properties. We\ndo this by designing a protocol called ZkAudit in which model providers publish\ncryptographic commitments of datasets and model weights, alongside a\nzero-knowledge proof (ZKP) certifying that published commitments are derived\nfrom training the model. Model providers can then respond to audit requests by\nprivately computing any function F of the dataset (or model) and releasing the\noutput of F alongside another ZKP certifying the correct execution of F. To\nenable ZkAudit, we develop new methods of computing ZKPs for SGD on modern\nneural nets for simple recommender systems and image classification models\ncapable of high accuracies on ImageNet. Empirically, we show it is possible to\nprovide trustless audits of DNNs, including copyright, censorship, and\ncounterfactual audits with little to no loss in accuracy.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04500v1",
    "published_date": "2024-04-06 04:43:06 UTC",
    "updated_date": "2024-04-06 04:43:06 UTC"
  },
  {
    "arxiv_id": "2404.04492v1",
    "title": "Automated Lane Change Behavior Prediction and Environmental Perception Based on SLAM Technology",
    "authors": [
      "Han Lei",
      "Baoming Wang",
      "Zuwei Shui",
      "Peiyuan Yang",
      "Penghao Liang"
    ],
    "abstract": "In addition to environmental perception sensors such as cameras, radars, etc.\nin the automatic driving system, the external environment of the vehicle is\nperceived, in fact, there is also a perception sensor that has been silently\ndedicated in the system, that is, the positioning module. This paper explores\nthe application of SLAM (Simultaneous Localization and Mapping) technology in\nthe context of automatic lane change behavior prediction and environment\nperception for autonomous vehicles. It discusses the limitations of traditional\npositioning methods, introduces SLAM technology, and compares LIDAR SLAM with\nvisual SLAM. Real-world examples from companies like Tesla, Waymo, and Mobileye\nshowcase the integration of AI-driven technologies, sensor fusion, and SLAM in\nautonomous driving systems. The paper then delves into the specifics of SLAM\nalgorithms, sensor technologies, and the importance of automatic lane changes\nin driving safety and efficiency. It highlights Tesla's recent update to its\nAutopilot system, which incorporates automatic lane change functionality using\nSLAM technology. The paper concludes by emphasizing the crucial role of SLAM in\nenabling accurate environment perception, positioning, and decision-making for\nautonomous vehicles, ultimately enhancing safety and driving experience.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04492v1",
    "published_date": "2024-04-06 03:48:29 UTC",
    "updated_date": "2024-04-06 03:48:29 UTC"
  },
  {
    "arxiv_id": "2404.04481v1",
    "title": "Joint Identifiability of Cross-Domain Recommendation via Hierarchical Subspace Disentanglement",
    "authors": [
      "Jing Du",
      "Zesheng Ye",
      "Bin Guo",
      "Zhiwen Yu",
      "Lina Yao"
    ],
    "abstract": "Cross-Domain Recommendation (CDR) seeks to enable effective knowledge\ntransfer across domains. Existing works rely on either representation alignment\nor transformation bridges, but they struggle on identifying domain-shared from\ndomain-specific latent factors. Specifically, while CDR describes user\nrepresentations as a joint distribution over two domains, these methods fail to\naccount for its joint identifiability as they primarily fixate on the marginal\ndistribution within a particular domain. Such a failure may overlook the\nconditionality between two domains and how it contributes to latent factor\ndisentanglement, leading to negative transfer when domains are weakly\ncorrelated. In this study, we explore what should and should not be transferred\nin cross-domain user representations from a causality perspective. We propose a\nHierarchical subspace disentanglement approach to explore the Joint\nIDentifiability of cross-domain joint distribution, termed HJID, to preserve\ndomain-specific behaviors from domain-shared factors. HJID organizes user\nrepresentations into layers: generic shallow subspaces and domain-oriented deep\nsubspaces. We first encode the generic pattern in the shallow subspace by\nminimizing the Maximum Mean Discrepancy of initial layer activation. Then, to\ndissect how domain-oriented latent factors are encoded in deeper layers\nactivation, we construct a cross-domain causality-based data generation graph,\nwhich identifies cross-domain consistent and domain-specific components,\nadhering to the Minimal Change principle. This allows HJID to maintain\nstability whilst discovering unique factors for different domains, all within a\ngenerative framework of invertible transformations that guarantee the joint\nidentifiability. With experiments on real-world datasets, we show that HJID\noutperforms SOTA methods on a range of strongly and weakly correlated CDR\ntasks.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "accepted to SIGIR 2024 as a Full Research Paper",
    "pdf_url": "http://arxiv.org/pdf/2404.04481v1",
    "published_date": "2024-04-06 03:11:31 UTC",
    "updated_date": "2024-04-06 03:11:31 UTC"
  },
  {
    "arxiv_id": "2404.04475v2",
    "title": "Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators",
    "authors": [
      "Yann Dubois",
      "Balázs Galambosi",
      "Percy Liang",
      "Tatsunori B. Hashimoto"
    ],
    "abstract": "LLM-based auto-annotators have become a key component of the LLM development\nprocess due to their cost-effectiveness and scalability compared to human-based\nevaluation. However, these auto-annotators can introduce biases that are hard\nto remove. Even simple, known confounders such as preference for longer outputs\nremain in existing automated evaluation metrics. We propose a simple regression\nanalysis approach for controlling biases in auto-evaluations. As a real case\nstudy, we focus on reducing the length bias of AlpacaEval, a fast and\naffordable benchmark for instruction-tuned LLMs that uses LLMs to estimate\nresponse quality. Despite being highly correlated with human preferences,\nAlpacaEval is known to favor models that generate longer outputs. We introduce\na length-controlled AlpacaEval that aims to answer the counterfactual question:\n\"What would the preference be if the model's and baseline's output had the same\nlength?\" To achieve this, we first fit a generalized linear model to predict\nthe biased auto-annotator's preferences based on the mediators we want to\ncontrol for (length difference) and other relevant features. We then obtain\nlength-controlled preferences by predicting preferences while conditioning the\nGLM with a zero difference in lengths. Length-controlling not only improves the\nrobustness of the metric to manipulations in model verbosity, but we also find\nthat it increases the Spearman correlation with LMSYS Chatbot Arena from 0.94\nto 0.98.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04475v2",
    "published_date": "2024-04-06 02:29:02 UTC",
    "updated_date": "2025-03-10 09:27:03 UTC"
  },
  {
    "arxiv_id": "2404.04456v1",
    "title": "Beyond the Known: Adversarial Autoencoders in Novelty Detection",
    "authors": [
      "Muhammad Asad",
      "Ihsan Ullah",
      "Ganesh Sistu",
      "Michael G. Madden"
    ],
    "abstract": "In novelty detection, the goal is to decide if a new data point should be\ncategorized as an inlier or an outlier, given a training dataset that primarily\ncaptures the inlier distribution. Recent approaches typically use deep encoder\nand decoder network frameworks to derive a reconstruction error, and employ\nthis error either to determine a novelty score, or as the basis for a one-class\nclassifier. In this research, we use a similar framework but with a lightweight\ndeep network, and we adopt a probabilistic score with reconstruction error. Our\nmethodology calculates the probability of whether the sample comes from the\ninlier distribution or not. This work makes two key contributions. The first is\nthat we compute the novelty probability by linearizing the manifold that holds\nthe structure of the inlier distribution. This allows us to interpret how the\nprobability is distributed and can be determined in relation to the local\ncoordinates of the manifold tangent space. The second contribution is that we\nimprove the training protocol for the network. Our results indicate that our\napproach is effective at learning the target class, and it outperforms recent\nstate-of-the-art methods on several benchmark datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the VISAAP 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04456v1",
    "published_date": "2024-04-06 00:04:19 UTC",
    "updated_date": "2024-04-06 00:04:19 UTC"
  }
]