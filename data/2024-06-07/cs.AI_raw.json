[
  {
    "arxiv_id": "2406.05288v1",
    "title": "Optimal Eye Surgeon: Finding Image Priors through Sparse Generators at Initialization",
    "authors": [
      "Avrajit Ghosh",
      "Xitong Zhang",
      "Kenneth K. Sun",
      "Qing Qu",
      "Saiprasad Ravishankar",
      "Rongrong Wang"
    ],
    "abstract": "We introduce Optimal Eye Surgeon (OES), a framework for pruning and training\ndeep image generator networks. Typically, untrained deep convolutional\nnetworks, which include image sampling operations, serve as effective image\npriors (Ulyanov et al., 2018). However, they tend to overfit to noise in image\nrestoration tasks due to being overparameterized. OES addresses this by\nadaptively pruning networks at random initialization to a level of\nunderparameterization. This process effectively captures low-frequency image\ncomponents even without training, by just masking. When trained to fit noisy\nimages, these pruned subnetworks, which we term Sparse-DIP, resist overfitting\nto noise. This benefit arises from underparameterization and the regularization\neffect of masking, constraining them in the manifold of image priors. We\ndemonstrate that subnetworks pruned through OES surpass other leading pruning\nmethods, such as the Lottery Ticket Hypothesis, which is known to be suboptimal\nfor image recovery tasks (Wu et al., 2023). Our extensive experiments\ndemonstrate the transferability of OES-masks and the characteristics of\nsparse-subnetworks for image generation. Code is available at\nhttps://github.com/Avra98/Optimal-Eye-Surgeon.git.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Pruning image generator networks at initialization to alleviate\n  overfitting",
    "pdf_url": "http://arxiv.org/pdf/2406.05288v1",
    "published_date": "2024-06-07 23:04:53 UTC",
    "updated_date": "2024-06-07 23:04:53 UTC"
  },
  {
    "arxiv_id": "2406.05279v1",
    "title": "SuperPos-Prompt: Enhancing Soft Prompt Tuning of Language Models with Superposition of Multi Token Embeddings",
    "authors": [
      "MohammadAli SadraeiJavaeri",
      "Ehsaneddin Asgari",
      "Alice Carolyn McHardy",
      "Hamid Reza Rabiee"
    ],
    "abstract": "Soft prompt tuning techniques have recently gained traction as an effective\nstrategy for the parameter-efficient tuning of pretrained language models,\nparticularly minimizing the required adjustment of model parameters. Despite\ntheir growing use, achieving optimal tuning with soft prompts, especially for\nsmaller datasets, remains a substantial challenge. This study makes two\ncontributions in this domain: (i) we introduce SuperPos-Prompt, a new\nreparameterization technique employing the superposition of multiple pretrained\nvocabulary embeddings to improve the learning of soft prompts. Our experiments\nacross several GLUE and SuperGLUE benchmarks consistently highlight\nSuperPos-Prompt's superiority over Residual Prompt tuning, exhibiting an\naverage score increase of $+6.4$ in T5-Small and $+5.0$ in T5-Base along with a\nfaster convergence. Remarkably, SuperPos-Prompt occasionally outperforms even\nfull fine-tuning methods. (ii) Additionally, we demonstrate enhanced\nperformance and rapid convergence by omitting dropouts from the frozen network,\nyielding consistent improvements across various scenarios and tuning methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05279v1",
    "published_date": "2024-06-07 22:18:49 UTC",
    "updated_date": "2024-06-07 22:18:49 UTC"
  },
  {
    "arxiv_id": "2406.05265v1",
    "title": "TLEX: An Efficient Method for Extracting Exact Timelines from TimeML Temporal Graphs",
    "authors": [
      "Mustafa Ocal",
      "Ning Xie",
      "Mark Finlayson"
    ],
    "abstract": "A timeline provides a total ordering of events and times, and is useful for a\nnumber of natural language understanding tasks. However, qualitative temporal\ngraphs that can be derived directly from text -- such as TimeML annotations --\nusually explicitly reveal only partial orderings of events and times. In this\nwork, we apply prior work on solving point algebra problems to the task of\nextracting timelines from TimeML annotated texts, and develop an exact,\nend-to-end solution which we call TLEX (TimeLine EXtraction). TLEX transforms\nTimeML annotations into a collection of timelines arranged in a\ntrunk-and-branch structure. Like what has been done in prior work, TLEX checks\nthe consistency of the temporal graph and solves it; however, it adds two novel\nfunctionalities. First, it identifies specific relations involved in an\ninconsistency (which could then be manually corrected) and, second, TLEX\nperforms a novel identification of sections of the timelines that have\nindeterminate order, information critical for downstream tasks such as aligning\nevents from different timelines. We provide detailed descriptions and analysis\nof the algorithmic components in TLEX, and conduct experimental evaluations by\napplying TLEX to 385 TimeML annotated texts from four corpora. We show that 123\nof the texts are inconsistent, 181 of them have more than one ``real world'' or\nmain timeline, and there are 2,541 indeterminate sections across all four\ncorpora. A sampling evaluation showed that TLEX is 98--100% accurate with 95%\nconfidence along five dimensions: the ordering of time-points, the number of\nmain timelines, the placement of time-points on main versus subordinate\ntimelines, the connecting point of branch timelines, and the location of the\nindeterminate sections. We provide a reference implementation of TLEX, the\nextracted timelines for all texts, and the manual corrections of the\ninconsistent texts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.05265v1",
    "published_date": "2024-06-07 21:20:32 UTC",
    "updated_date": "2024-06-07 21:20:32 UTC"
  },
  {
    "arxiv_id": "2406.05259v1",
    "title": "A model of early word acquisition based on realistic-scale audiovisual naming events",
    "authors": [
      "Khazar Khorrami",
      "Okko Räsänen"
    ],
    "abstract": "Infants gradually learn to parse continuous speech into words and connect\nnames with objects, yet the mechanisms behind development of early word\nperception skills remain unknown. We studied the extent to which early words\ncan be acquired through statistical learning from regularities in audiovisual\nsensory input. We simulated word learning in infants up to 12 months of age in\na realistic setting, using a model that solely learns from statistical\nregularities in unannotated raw speech and pixel-level visual input. Crucially,\nthe quantity of object naming events was carefully designed to match that\naccessible to infants of comparable ages. Results show that the model\neffectively learns to recognize words and associate them with corresponding\nvisual objects, with a vocabulary growth rate comparable to that observed in\ninfants. The findings support the viability of general statistical learning for\nearly word perception, demonstrating how learning can operate without assuming\nany prior linguistic capabilities.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "22 pages, 4 figures, journal article, submitted for review",
    "pdf_url": "http://arxiv.org/pdf/2406.05259v1",
    "published_date": "2024-06-07 21:05:59 UTC",
    "updated_date": "2024-06-07 21:05:59 UTC"
  },
  {
    "arxiv_id": "2406.07578v1",
    "title": "Individual Packet Features are a Risk to Model Generalisation in ML-Based Intrusion Detection",
    "authors": [
      "Kahraman Kostas",
      "Mike Just",
      "Michael A. Lones"
    ],
    "abstract": "Machine learning is increasingly used for intrusion detection in IoT\nnetworks. This paper explores the effectiveness of using individual packet\nfeatures (IPF), which are attributes extracted from a single network packet,\nsuch as timing, size, and source-destination information. Through literature\nreview and experiments, we identify the limitations of IPF, showing they can\nproduce misleadingly high detection rates. Our findings emphasize the need for\napproaches that consider packet interactions for robust intrusion detection.\nAdditionally, we demonstrate that models based on IPF often fail to generalize\nacross datasets, compromising their reliability in diverse IoT environments.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.07578v1",
    "published_date": "2024-06-07 21:05:33 UTC",
    "updated_date": "2024-06-07 21:05:33 UTC"
  },
  {
    "arxiv_id": "2406.05255v1",
    "title": "Generative Explore-Exploit: Training-free Optimization of Generative Recommender Systems using LLM Optimizers",
    "authors": [
      "Lütfi Kerem Senel",
      "Besnik Fetahu",
      "Davis Yoshida",
      "Zhiyu Chen",
      "Giuseppe Castellucci",
      "Nikhita Vedula",
      "Jason Choi",
      "Shervin Malmasi"
    ],
    "abstract": "Recommender systems are widely used to suggest engaging content, and Large\nLanguage Models (LLMs) have given rise to generative recommenders. Such systems\ncan directly generate items, including for open-set tasks like question\nsuggestion. While the world knowledge of LLMs enable good recommendations,\nimproving the generated content through user feedback is challenging as\ncontinuously fine-tuning LLMs is prohibitively expensive. We present a\ntraining-free approach for optimizing generative recommenders by connecting\nuser feedback loops to LLM-based optimizers. We propose a generative\nexplore-exploit method that can not only exploit generated items with known\nhigh engagement, but also actively explore and discover hidden population\npreferences to improve recommendation quality. We evaluate our approach on\nquestion generation in two domains (e-commerce and general knowledge), and\nmodel user feedback with Click Through Rate (CTR). Experiments show our\nLLM-based explore-exploit approach can iteratively improve recommendations, and\nconsistently increase CTR. Ablation analysis shows that generative exploration\nis key to learning user preferences, avoiding the pitfalls of greedy\nexploit-only approaches. A human evaluation strongly supports our quantitative\nfindings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024 Main Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2406.05255v1",
    "published_date": "2024-06-07 20:41:59 UTC",
    "updated_date": "2024-06-07 20:41:59 UTC"
  },
  {
    "arxiv_id": "2406.05250v3",
    "title": "LLM-Enhanced Bayesian Optimization for Efficient Analog Layout Constraint Generation",
    "authors": [
      "Guojin Chen",
      "Keren Zhu",
      "Seunggeun Kim",
      "Hanqing Zhu",
      "Yao Lai",
      "Bei Yu",
      "David Z. Pan"
    ],
    "abstract": "Analog layout synthesis faces significant challenges due to its dependence on\nmanual processes, considerable time requirements, and performance instability.\nCurrent Bayesian Optimization (BO)-based techniques for analog layout\nsynthesis, despite their potential for automation, suffer from slow convergence\nand extensive data needs, limiting their practical application. This paper\npresents the \\texttt{LLANA} framework, a novel approach that leverages Large\nLanguage Models (LLMs) to enhance BO by exploiting the few-shot learning\nabilities of LLMs for more efficient generation of analog design-dependent\nparameter constraints. Experimental results demonstrate that \\texttt{LLANA} not\nonly achieves performance comparable to state-of-the-art (SOTA) BO methods but\nalso enables a more effective exploration of the analog circuit design space,\nthanks to LLM's superior contextual understanding and learning efficiency. The\ncode is available at https://github.com/dekura/LLANA.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05250v3",
    "published_date": "2024-06-07 20:22:36 UTC",
    "updated_date": "2024-12-06 12:40:53 UTC"
  },
  {
    "arxiv_id": "2406.05249v1",
    "title": "A Language Model-Guided Framework for Mining Time Series with Distributional Shifts",
    "authors": [
      "Haibei Zhu",
      "Yousef El-Laham",
      "Elizabeth Fons",
      "Svitlana Vyetrenko"
    ],
    "abstract": "Effective utilization of time series data is often constrained by the\nscarcity of data quantity that reflects complex dynamics, especially under the\ncondition of distributional shifts. Existing datasets may not encompass the\nfull range of statistical properties required for robust and comprehensive\nanalysis. And privacy concerns can further limit their accessibility in domains\nsuch as finance and healthcare. This paper presents an approach that utilizes\nlarge language models and data source interfaces to explore and collect time\nseries datasets. While obtained from external sources, the collected data share\ncritical statistical properties with primary time series datasets, making it\npossible to model and adapt to various scenarios. This method enlarges the data\nquantity when the original data is limited or lacks essential properties. It\nsuggests that collected datasets can effectively supplement existing datasets,\nespecially involving changes in data distribution. We demonstrate the\neffectiveness of the collected datasets through practical examples and show how\ntime series forecasting foundation models fine-tuned on these datasets achieve\ncomparable performance to those models without fine-tuning.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05249v1",
    "published_date": "2024-06-07 20:21:07 UTC",
    "updated_date": "2024-06-07 20:21:07 UTC"
  },
  {
    "arxiv_id": "2406.12897v1",
    "title": "Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability",
    "authors": [
      "Faseela Abdullakutty",
      "Younes Akbari",
      "Somaya Al-Maadeed",
      "Ahmed Bouridane",
      "Rifat Hamoudi"
    ],
    "abstract": "It is imperative that breast cancer is detected precisely and timely to\nimprove patient outcomes. Diagnostic methodologies have traditionally relied on\nunimodal approaches; however, medical data analytics is integrating diverse\ndata sources beyond conventional imaging. Using multi-modal techniques,\nintegrating both image and non-image data, marks a transformative advancement\nin breast cancer diagnosis. The purpose of this review is to explore the\nburgeoning field of multimodal techniques, particularly the fusion of\nhistopathology images with non-image data. Further, Explainable AI (XAI) will\nbe used to elucidate the decision-making processes of complex algorithms,\nemphasizing the necessity of explainability in diagnostic processes. This\nreview utilizes multi-modal data and emphasizes explainability to enhance\ndiagnostic accuracy, clinician confidence, and patient engagement, ultimately\nfostering more personalized treatment strategies for breast cancer, while also\nidentifying research gaps in multi-modality and explainability, guiding future\nstudies, and contributing to the strategic direction of the field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages including references",
    "pdf_url": "http://arxiv.org/pdf/2406.12897v1",
    "published_date": "2024-06-07 19:23:22 UTC",
    "updated_date": "2024-06-07 19:23:22 UTC"
  },
  {
    "arxiv_id": "2406.05223v3",
    "title": "CorDA: Context-Oriented Decomposition Adaptation of Large Language Models for Task-Aware Parameter-Efficient Fine-tuning",
    "authors": [
      "Yibo Yang",
      "Xiaojie Li",
      "Zhongzhu Zhou",
      "Shuaiwen Leon Song",
      "Jianlong Wu",
      "Liqiang Nie",
      "Bernard Ghanem"
    ],
    "abstract": "Current parameter-efficient fine-tuning (PEFT) methods build adapters widely\nagnostic of the context of downstream task to learn, or the context of\nimportant knowledge to maintain. As a result, there is often a performance gap\ncompared to full-parameter fine-tuning, and meanwhile the fine-tuned model\nsuffers from catastrophic forgetting of the pre-trained world knowledge. In\nthis paper, we propose CorDA, a Context-oriented Decomposition Adaptation\nmethod that builds learnable task-aware adapters from weight decomposition\noriented by the context of downstream task or the world knowledge to maintain.\nConcretely, we collect a few data samples, and perform singular value\ndecomposition for each linear layer of a pre-trained LLM multiplied by the\ncovariance matrix of the input activation using these samples. The inverse of\nthe covariance matrix is multiplied with the decomposed components to\nreconstruct the original weights. By doing so, the context of the\nrepresentative samples is captured through deciding the factorizing\norientation. Our method enables two options, the knowledge-preserved adaptation\nand the instruction-previewed adaptation. For the former, we use\nquestion-answering samples to obtain the covariance matrices, and use the\ndecomposed components with the smallest $r$ singular values to initialize a\nlearnable adapter, with the others frozen such that the world knowledge is\nbetter preserved. For the latter, we use the instruction data from the\nfine-tuning task, such as math or coding, to orientate the decomposition and\ntrain the largest $r$ components that most correspond to the task to learn. We\nconduct extensive experiments on Math, Code, and Instruction Following tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.05223v3",
    "published_date": "2024-06-07 19:10:35 UTC",
    "updated_date": "2025-03-07 21:18:41 UTC"
  },
  {
    "arxiv_id": "2406.05213v2",
    "title": "On Subjective Uncertainty Quantification and Calibration in Natural Language Generation",
    "authors": [
      "Ziyu Wang",
      "Chris Holmes"
    ],
    "abstract": "Applications of large language models often involve the generation of\nfree-form responses, in which case uncertainty quantification becomes\nchallenging. This is due to the need to identify task-specific uncertainties\n(e.g., about the semantics) which appears difficult to define in general cases.\nThis work addresses these challenges from a perspective of Bayesian decision\ntheory, starting from the assumption that our utility is characterized by a\nsimilarity measure that compares a generated response with a hypothetical true\nresponse. We discuss how this assumption enables principled quantification of\nthe model's subjective uncertainty and its calibration. We further derive a\nmeasure for epistemic uncertainty, based on a missing data perspective and its\ncharacterization as an excess risk. The proposed methods can be applied to\nblack-box language models. We illustrate the methods on question answering and\nmachine translation tasks. Our experiments provide a principled evaluation of\ntask-specific calibration, and demonstrate that epistemic uncertainty offers a\npromising deferral strategy for efficient data acquisition in in-context\nlearning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05213v2",
    "published_date": "2024-06-07 18:54:40 UTC",
    "updated_date": "2024-10-18 02:55:27 UTC"
  },
  {
    "arxiv_id": "2406.05194v2",
    "title": "LLMs Are Not Intelligent Thinkers: Introducing Mathematical Topic Tree Benchmark for Comprehensive Evaluation of LLMs",
    "authors": [
      "Arash Gholami Davoodi",
      "Seyed Pouyan Mousavi Davoudi",
      "Pouya Pezeshkpour"
    ],
    "abstract": "Large language models (LLMs) demonstrate impressive capabilities in\nmathematical reasoning. However, despite these achievements, current\nevaluations are mostly limited to specific mathematical topics, and it remains\nunclear whether LLMs are genuinely engaging in reasoning. To address these\ngaps, we present the Mathematical Topics Tree (MaTT) benchmark, a challenging\nand structured benchmark that offers 1,958 questions across a wide array of\nmathematical subjects, each paired with a detailed hierarchical chain of\ntopics. Upon assessing different LLMs using the MaTT benchmark, we find that\nthe most advanced model, GPT-4, achieved a mere 54\\% accuracy in a\nmultiple-choice scenario. Interestingly, even when employing Chain-of-Thought\nprompting, we observe mostly no notable improvement. Moreover, LLMs accuracy\ndramatically reduced by up to 24.2 percentage point when the questions were\npresented without providing choices. Further detailed analysis of the LLMs'\nperformance across a range of topics showed significant discrepancy even for\nclosely related subtopics within the same general mathematical area. In an\neffort to pinpoint the reasons behind LLMs performances, we conducted a manual\nevaluation of the completeness and correctness of the explanations generated by\nGPT-4 when choices were available. Surprisingly, we find that in only 53.3\\% of\nthe instances where the model provided a correct answer, the accompanying\nexplanations were deemed complete and accurate, i.e., the model engaged in\ngenuine reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05194v2",
    "published_date": "2024-06-07 18:21:26 UTC",
    "updated_date": "2025-03-29 17:29:24 UTC"
  },
  {
    "arxiv_id": "2406.05190v1",
    "title": "Evaluating the Effectiveness of Data Augmentation for Emotion Classification in Low-Resource Settings",
    "authors": [
      "Aashish Arora",
      "Elsbeth Turcan"
    ],
    "abstract": "Data augmentation has the potential to improve the performance of machine\nlearning models by increasing the amount of training data available. In this\nstudy, we evaluated the effectiveness of different data augmentation techniques\nfor a multi-label emotion classification task using a low-resource dataset. Our\nresults showed that Back Translation outperformed autoencoder-based approaches\nand that generating multiple examples per training instance led to further\nperformance improvement. In addition, we found that Back Translation generated\nthe most diverse set of unigrams and trigrams. These findings demonstrate the\nutility of Back Translation in enhancing the performance of emotion\nclassification models in resource-limited situations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "The first author contributed significantly",
    "pdf_url": "http://arxiv.org/pdf/2406.05190v1",
    "published_date": "2024-06-07 18:13:27 UTC",
    "updated_date": "2024-06-07 18:13:27 UTC"
  },
  {
    "arxiv_id": "2406.05189v2",
    "title": "Analyzing the factors that are involved in length of inpatient stay at the hospital for diabetes patients",
    "authors": [
      "Jorden Lam",
      "Kunpeng Xu"
    ],
    "abstract": "The paper investigates the escalating concerns surrounding the surge in\ndiabetes cases, exacerbated by the COVID-19 pandemic, and the subsequent strain\non medical resources. The research aims to construct a predictive model\nquantifying factors influencing inpatient hospital stay durations for diabetes\npatients, offering insights to hospital administrators for improved patient\nmanagement strategies. The literature review highlights the increasing\nprevalence of diabetes, emphasizing the need for continued attention and\nanalysis of urban-rural disparities in healthcare access. International studies\nunderscore the financial implications and healthcare burden associated with\ndiabetes-related hospitalizations and complications, emphasizing the\nsignificance of effective management strategies. The methodology involves a\nquantitative approach, utilizing a dataset comprising 10,000 observations of\ndiabetic inpatient encounters in U.S. hospitals from 1999 to 2008. Predictive\nmodeling techniques, particularly Generalized Linear Models (GLM), are employed\nto develop a model predicting hospital stay durations based on patient\ndemographics, admission types, medical history, and treatment regimen. The\nresults highlight the influence of age, medical history, and treatment regimen\non hospital stay durations for diabetes patients. Despite model limitations,\nsuch as heteroscedasticity and deviations from normality in residual analysis,\nthe findings offer valuable insights for hospital administrators in patient\nmanagement. The paper concludes with recommendations for future research to\naddress model limitations and explore the implications of predictive models on\nhealthcare management strategies, ensuring equitable patient care and resource\nallocation.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05189v2",
    "published_date": "2024-06-07 18:13:21 UTC",
    "updated_date": "2025-02-01 03:26:46 UTC"
  },
  {
    "arxiv_id": "2406.05187v2",
    "title": "How to Strategize Human Content Creation in the Era of GenAI?",
    "authors": [
      "Seyed A. Esmaeili",
      "Kevin Lim",
      "Kshipra Bhawalkar",
      "Zhe Feng",
      "Di Wang",
      "Haifeng Xu"
    ],
    "abstract": "Generative AI (GenAI) will have significant impact on content creation\nplatforms. In this paper, we study the dynamic competition between a GenAI and\na human contributor. Unlike the human, the GenAI's content only improves when\nmore contents are created by the human over time; however, GenAI has the\nadvantage of generating content at a lower cost. We study the algorithmic\nproblem in this dynamic competition model about how the human contributor can\nmaximize her utility when competing against the GenAI for content generation\nover a set of topics. In time-sensitive content domains (e.g., news or pop\nmusic creation) where contents' value diminishes over time, we show that there\nis no polynomial time algorithm for finding the human's optimal (dynamic)\nstrategy, unless the randomized exponential time hypothesis is false.\nFortunately, we are able to design a polynomial time algorithm that naturally\ncycles between myopically optimizing over a short time window and pausing and\nprovably guarantees an approximation ratio of $\\frac{1}{2}$. We then turn to\ntime-insensitive content domains where contents do not lose their value (e.g.,\ncontents on history facts). Interestingly, we show that this setting permits a\npolynomial time algorithm that maximizes the human's utility in the long run.\nFinally, we conduct simulations that demonstrate the advantage of our\nalgorithms in comparison to a collection of baselines.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05187v2",
    "published_date": "2024-06-07 18:12:04 UTC",
    "updated_date": "2025-03-09 02:23:50 UTC"
  },
  {
    "arxiv_id": "2406.05183v1",
    "title": "The Factorization Curse: Which Tokens You Predict Underlie the Reversal Curse and More",
    "authors": [
      "Ouail Kitouni",
      "Niklas Nolte",
      "Diane Bouchacourt",
      "Adina Williams",
      "Mike Rabbat",
      "Mark Ibrahim"
    ],
    "abstract": "Today's best language models still struggle with hallucinations: factually\nincorrect generations, which impede their ability to reliably retrieve\ninformation seen during training. The reversal curse, where models cannot\nrecall information when probed in a different order than was encountered during\ntraining, exemplifies this in information retrieval. We reframe the reversal\ncurse as a factorization curse - a failure of models to learn the same joint\ndistribution under different factorizations. Through a series of controlled\nexperiments with increasing levels of realism including WikiReversal, a setting\nwe introduce to closely simulate a knowledge intensive finetuning task, we find\nthat the factorization curse is an inherent failure of the next-token\nprediction objective used in popular large language models. Moreover, we\ndemonstrate reliable information retrieval cannot be solved with scale,\nreversed tokens, or even naive bidirectional-attention training. Consequently,\nvarious approaches to finetuning on specialized data would necessarily provide\nmixed results on downstream tasks, unless the model has already seen the right\nsequence of tokens. Across five tasks of varying levels of complexity, our\nresults uncover a promising path forward: factorization-agnostic objectives can\nsignificantly mitigate the reversal curse and hint at improved knowledge\nstorage and planning capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.05183v1",
    "published_date": "2024-06-07 18:00:37 UTC",
    "updated_date": "2024-06-07 18:00:37 UTC"
  },
  {
    "arxiv_id": "2406.16915v1",
    "title": "Unlocking Telemetry Potential: Self-Supervised Learning for Continuous Clinical Electrocardiogram Monitoring",
    "authors": [
      "Thomas Kite",
      "Uzair Tahamid Siam",
      "Brian Ayers",
      "Nicholas Houstis",
      "Aaron D Aguirre"
    ],
    "abstract": "Machine learning (ML) applied to routine patient monitoring within intensive\ncare units (ICUs) has the potential to improve care by providing clinicians\nwith novel insights into each patient's health and expected response to\ninterventions. This paper applies deep learning to a large volume of unlabeled\nelectrocardiogram (ECG) telemetry signals, which are commonly used for\ncontinuous patient monitoring in hospitals but have important differences from\nthe standard, single time-point 12-lead ECG used in many prior machine learning\nstudies. We applied self-supervised learning to pretrain a spectrum of deep\nnetworks on approximately 147,000 hours of ECG telemetry data. Our approach\nleverages this dataset to train models that significantly improve performance\non four distinct downstream tasks compared with direct supervised learning\nusing labeled data. These pretrained models enable medically useful predictions\nand estimates in smaller patient cohorts that are typically limited by the\nscarcity of labels. Notably, we demonstrate that our pretrained networks can\ncontinuously annotate ECG telemetry signals, thereby providing monitoring\ncapabilities that are often unavailable due to the requirement for specialized\nexpertise and time-consuming professional annotations.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "17 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16915v1",
    "published_date": "2024-06-07 18:00:00 UTC",
    "updated_date": "2024-06-07 18:00:00 UTC"
  },
  {
    "arxiv_id": "2406.05132v3",
    "title": "3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination",
    "authors": [
      "Jianing Yang",
      "Xuweiyi Chen",
      "Nikhil Madaan",
      "Madhavan Iyengar",
      "Shengyi Qian",
      "David F. Fouhey",
      "Joyce Chai"
    ],
    "abstract": "The integration of language and 3D perception is crucial for embodied agents\nand robots that comprehend and interact with the physical world. While large\nlanguage models (LLMs) have demonstrated impressive language understanding and\ngeneration capabilities, their adaptation to 3D environments (3D-LLMs) remains\nin its early stages. A primary challenge is a lack of large-scale datasets with\ndense grounding between language and 3D scenes. We introduce 3D-GRAND, a\npioneering large-scale dataset comprising 40,087 household scenes paired with\n6.2 million densely-grounded scene-language instructions. Our results show that\ninstruction tuning with 3D-GRAND significantly enhances grounding capabilities\nand reduces hallucinations in 3D-LLMs. As part of our contributions, we propose\na comprehensive benchmark 3D-POPE to systematically evaluate hallucination in\n3D-LLMs, enabling fair comparisons of models. Our experiments highlight a\nscaling effect between dataset size and 3D-LLM performance, emphasizing the\nimportance of large-scale 3D-text datasets for embodied AI research. Our\nresults demonstrate early signals for effective sim-to-real transfer,\nindicating that models trained on large synthetic data can perform well on\nreal-world 3D scans. Through 3D-GRAND and 3D-POPE, we aim to equip the embodied\nAI community with resources and insights to lead to more reliable and\nbetter-grounded 3D-LLMs. Project website: https://3d-grand.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025. Project website: https://3d-grand.github.io",
    "pdf_url": "http://arxiv.org/pdf/2406.05132v3",
    "published_date": "2024-06-07 17:59:59 UTC",
    "updated_date": "2025-03-20 23:06:14 UTC"
  },
  {
    "arxiv_id": "2406.09052v1",
    "title": "Data-Free Generative Replay for Class-Incremental Learning on Imbalanced Data",
    "authors": [
      "Sohaib Younis",
      "Bernhard Seeger"
    ],
    "abstract": "Continual learning is a challenging problem in machine learning, especially\nfor image classification tasks with imbalanced datasets. It becomes even more\nchallenging when it involves learning new classes incrementally. One method for\nincremental class learning, addressing dataset imbalance, is rehearsal using\npreviously stored data. In rehearsal-based methods, access to previous data is\nrequired for either training the classifier or the generator, but it may not be\nfeasible due to storage, legal, or data access constraints. Although there are\nmany rehearsal-free alternatives for class incremental learning, such as\nparameter or loss regularization, knowledge distillation, and dynamic\narchitectures, they do not consistently achieve good results, especially on\nimbalanced data. This paper proposes a new approach called Data-Free Generative\nReplay (DFGR) for class incremental learning, where the generator is trained\nwithout access to real data. In addition, DFGR also addresses dataset imbalance\nin continual learning of an image classifier. Instead of using training data,\nDFGR trains a generator using mean and variance statistics of batch-norm and\nfeature maps derived from a pre-trained classification model. The results of\nour experiments demonstrate that DFGR performs significantly better than other\ndata-free methods and reveal the performance impact of specific parameter\nsettings. DFGR achieves up to 88.5% and 46.6% accuracy on MNIST and\nFashionMNIST datasets, respectively. Our code is available at\nhttps://github.com/2younis/DFGR",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.09052v1",
    "published_date": "2024-06-07 17:51:27 UTC",
    "updated_date": "2024-06-07 17:51:27 UTC"
  },
  {
    "arxiv_id": "2406.05113v2",
    "title": "LlavaGuard: An Open VLM-based Framework for Safeguarding Vision Datasets and Models",
    "authors": [
      "Lukas Helff",
      "Felix Friedrich",
      "Manuel Brack",
      "Kristian Kersting",
      "Patrick Schramowski"
    ],
    "abstract": "This paper introduces LlavaGuard, a suite of VLM-based vision safeguards that\naddress the critical need for reliable guardrails in the era of large-scale\ndata and models. To this end, we establish a novel open framework, describing a\ncustomizable safety taxonomy, data preprocessing, augmentation, and training\nsetup. For teaching a VLM safeguard on safety, we further create a multimodal\nsafety dataset with high-quality human expert annotations, where each image is\nlabeled with a safety rating, category and rationale. We also employ advanced\naugmentations to support context-specific assessments. The resulting LlavaGuard\nmodels, ranging from 0.5B to 7B, serve as a versatile tool for evaluating the\nsafety compliance of visual content against flexible policies. In comprehensive\nexperiments, LlavaGuard outperforms both state-of-the-art safeguards and VLMs\nin accuracy and in flexibly handling different policies. Additionally, we\ndemonstrate LlavaGuard's performance in two real-world applications:\nlarge-scale dataset annotation and moderation of text-to-image models. We make\nour entire framework publicly available, including the dataset and model\nweights.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page at\n  https://ml-research.github.io/human-centered-genai/projects/llavaguard/index.html",
    "pdf_url": "http://arxiv.org/pdf/2406.05113v2",
    "published_date": "2024-06-07 17:44:32 UTC",
    "updated_date": "2025-01-31 15:57:48 UTC"
  },
  {
    "arxiv_id": "2406.07577v1",
    "title": "Structured Active Inference (Extended Abstract)",
    "authors": [
      "Toby St Clere Smithe"
    ],
    "abstract": "We introduce structured active inference, a large generalization and\nformalization of active inference using the tools of categorical systems\ntheory. We cast generative models formally as systems \"on an interface\", with\nthe latter being a compositional abstraction of the usual notion of Markov\nblanket; agents are then 'controllers' for their generative models, formally\ndual to them. This opens the active inference landscape to new horizons, such\nas: agents with structured interfaces (e.g. with 'mode-dependence', or that\ninteract with computer APIs); agents that can manage other agents; and\n'meta-agents', that use active inference to change their (internal or external)\nstructure. With structured interfaces, we also gain structured ('typed')\npolicies, which are amenable to formal verification, an important step towards\nsafe artificial agents. Moreover, we can make use of categorical logic to\ndescribe express agents' goals as formal predicates, whose satisfaction may be\ndependent on the interaction context. This points towards powerful\ncompositional tools to constrain and control self-organizing ensembles of\nagents.",
    "categories": [
      "cs.AI",
      "math.CT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07577v1",
    "published_date": "2024-06-07 17:22:44 UTC",
    "updated_date": "2024-06-07 17:22:44 UTC"
  },
  {
    "arxiv_id": "2406.05090v1",
    "title": "Provably Better Explanations with Optimized Aggregation of Feature Attributions",
    "authors": [
      "Thomas Decker",
      "Ananta R. Bhattarai",
      "Jindong Gu",
      "Volker Tresp",
      "Florian Buettner"
    ],
    "abstract": "Using feature attributions for post-hoc explanations is a common practice to\nunderstand and verify the predictions of opaque machine learning models.\nDespite the numerous techniques available, individual methods often produce\ninconsistent and unstable results, putting their overall reliability into\nquestion. In this work, we aim to systematically improve the quality of feature\nattributions by combining multiple explanations across distinct methods or\ntheir variations. For this purpose, we propose a novel approach to derive\noptimal convex combinations of feature attributions that yield provable\nimprovements of desired quality criteria such as robustness or faithfulness to\nthe model behavior. Through extensive experiments involving various model\narchitectures and popular feature attribution techniques, we demonstrate that\nour combination strategy consistently outperforms individual methods and\nexisting baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Machine Learning (ICML) 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.05090v1",
    "published_date": "2024-06-07 17:03:43 UTC",
    "updated_date": "2024-06-07 17:03:43 UTC"
  },
  {
    "arxiv_id": "2406.05086v1",
    "title": "Robust Reward Design for Markov Decision Processes",
    "authors": [
      "Shuo Wu",
      "Haoxiang Ma",
      "Jie Fu",
      "Shuo Han"
    ],
    "abstract": "The problem of reward design examines the interaction between a leader and a\nfollower, where the leader aims to shape the follower's behavior to maximize\nthe leader's payoff by modifying the follower's reward function. Current\napproaches to reward design rely on an accurate model of how the follower\nresponds to reward modifications, which can be sensitive to modeling\ninaccuracies. To address this issue of sensitivity, we present a solution that\noffers robustness against uncertainties in modeling the follower, including 1)\nhow the follower breaks ties in the presence of nonunique best responses, 2)\ninexact knowledge of how the follower perceives reward modifications, and 3)\nbounded rationality of the follower. Our robust solution is guaranteed to exist\nunder mild conditions and can be obtained numerically by solving a\nmixed-integer linear program. Numerical experiments on multiple test cases\ndemonstrate that our solution improves robustness compared to the standard\napproach without incurring significant additional computing costs.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "math.OC",
    "comment": "50 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.05086v1",
    "published_date": "2024-06-07 17:01:45 UTC",
    "updated_date": "2024-06-07 17:01:45 UTC"
  },
  {
    "arxiv_id": "2406.05085v2",
    "title": "Multi-Head RAG: Solving Multi-Aspect Problems with LLMs",
    "authors": [
      "Maciej Besta",
      "Ales Kubicek",
      "Roman Niggli",
      "Robert Gerstenberger",
      "Lucas Weitzendorf",
      "Mingyuan Chi",
      "Patrick Iff",
      "Joanna Gajda",
      "Piotr Nyczyk",
      "Jürgen Müller",
      "Hubert Niewiadomski",
      "Marcin Chrapek",
      "Michał Podstawski",
      "Torsten Hoefler"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) enhances the abilities of Large Language\nModels (LLMs) by enabling the retrieval of documents into the LLM context to\nprovide more accurate and relevant responses. Existing RAG solutions do not\nfocus on queries that may require fetching multiple documents with\nsubstantially different contents. Such queries occur frequently, but are\nchallenging because the embeddings of these documents may be distant in the\nembedding space, making it hard to retrieve them all. This paper introduces\nMulti-Head RAG (MRAG), a novel scheme designed to address this gap with a\nsimple yet powerful idea: leveraging activations of Transformer's multi-head\nattention layer, instead of the decoder layer, as keys for fetching\nmulti-aspect documents. The driving motivation is that different attention\nheads can learn to capture different data aspects. Harnessing the corresponding\nactivations results in embeddings that represent various facets of data items\nand queries, improving the retrieval accuracy for complex queries. We provide\nan evaluation methodology and metrics, multi-aspect datasets that we release\nonline, and real-world use cases to demonstrate MRAG's effectiveness, showing\nimprovements of up to 20% in relevance over standard RAG baselines. MRAG can be\nseamlessly integrated with existing RAG frameworks and benchmarking tools like\nRAGAS as well as different classes of data stores.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05085v2",
    "published_date": "2024-06-07 16:59:38 UTC",
    "updated_date": "2024-11-19 08:46:34 UTC"
  },
  {
    "arxiv_id": "2406.05080v2",
    "title": "I2EDL: Interactive Instruction Error Detection and Localization",
    "authors": [
      "Francesco Taioli",
      "Stefano Rosa",
      "Alberto Castellini",
      "Lorenzo Natale",
      "Alessio Del Bue",
      "Alessandro Farinelli",
      "Marco Cristani",
      "Yiming Wang"
    ],
    "abstract": "In the Vision-and-Language Navigation in Continuous Environments (VLN-CE)\ntask, the human user guides an autonomous agent to reach a target goal via a\nseries of low-level actions following a textual instruction in natural\nlanguage. However, most existing methods do not address the likely case where\nusers may make mistakes when providing such instruction (e.g. \"turn left\"\ninstead of \"turn right\"). In this work, we address a novel task of Interactive\nVLN in Continuous Environments (IVLN-CE), which allows the agent to interact\nwith the user during the VLN-CE navigation to verify any doubts regarding the\ninstruction errors. We propose an Interactive Instruction Error Detector and\nLocalizer (I2EDL) that triggers the user-agent interaction upon the detection\nof instruction errors during the navigation. We leverage a pre-trained module\nto detect instruction errors and pinpoint them in the instruction by\ncross-referencing the textual input and past observations. In such way, the\nagent is able to query the user for a timely correction, without demanding the\nuser's cognitive load, as we locate the probable errors to a precise part of\nthe instruction. We evaluate the proposed I2EDL on a dataset of instructions\ncontaining errors, and further devise a novel metric, the Success weighted by\nInteraction Number (SIN), to reflect both the navigation performance and the\ninteraction effectiveness. We show how the proposed method can ask focused\nrequests for corrections to the user, which in turn increases the navigation\nsuccess, while minimizing the interactions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at IEEE RO-MAN 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.05080v2",
    "published_date": "2024-06-07 16:52:57 UTC",
    "updated_date": "2024-06-23 22:58:46 UTC"
  },
  {
    "arxiv_id": "2406.05071v1",
    "title": "Massively Multiagent Minigames for Training Generalist Agents",
    "authors": [
      "Kyoung Whan Choe",
      "Ryan Sullivan",
      "Joseph Suárez"
    ],
    "abstract": "We present Meta MMO, a collection of many-agent minigames for use as a\nreinforcement learning benchmark. Meta MMO is built on top of Neural MMO, a\nmassively multiagent environment that has been the subject of two previous\nNeurIPS competitions. Our work expands Neural MMO with several computationally\nefficient minigames. We explore generalization across Meta MMO by learning to\nplay several minigames with a single set of weights. We release the\nenvironment, baselines, and training code under the MIT license. We hope that\nMeta MMO will spur additional progress on Neural MMO and, more generally, will\nserve as a useful benchmark for many-agent generalization.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05071v1",
    "published_date": "2024-06-07 16:41:05 UTC",
    "updated_date": "2024-06-07 16:41:05 UTC"
  },
  {
    "arxiv_id": "2406.05068v1",
    "title": "Classification Metrics for Image Explanations: Towards Building Reliable XAI-Evaluations",
    "authors": [
      "Benjamin Fresz",
      "Lena Lörcher",
      "Marco Huber"
    ],
    "abstract": "Decision processes of computer vision models - especially deep neural\nnetworks - are opaque in nature, meaning that these decisions cannot be\nunderstood by humans. Thus, over the last years, many methods to provide\nhuman-understandable explanations have been proposed. For image classification,\nthe most common group are saliency methods, which provide (super-)pixelwise\nfeature attribution scores for input images. But their evaluation still poses a\nproblem, as their results cannot be simply compared to the unknown ground\ntruth. To overcome this, a slew of different proxy metrics have been defined,\nwhich are - as the explainability methods themselves - often built on intuition\nand thus, are possibly unreliable. In this paper, new evaluation metrics for\nsaliency methods are developed and common saliency methods are benchmarked on\nImageNet. In addition, a scheme for reliability evaluation of such metrics is\nproposed that is based on concepts from psychometric testing. The used code can\nbe found at\nhttps://github.com/lelo204/ClassificationMetricsForImageExplanations .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05068v1",
    "published_date": "2024-06-07 16:37:50 UTC",
    "updated_date": "2024-06-07 16:37:50 UTC"
  },
  {
    "arxiv_id": "2406.18591v1",
    "title": "Composition Vision-Language Understanding via Segment and Depth Anything Model",
    "authors": [
      "Mingxiao Huo",
      "Pengliang Ji",
      "Haotian Lin",
      "Junchen Liu",
      "Yixiao Wang",
      "Yijun Chen"
    ],
    "abstract": "We introduce a pioneering unified library that leverages depth anything,\nsegment anything models to augment neural comprehension in language-vision\nmodel zero-shot understanding. This library synergizes the capabilities of the\nDepth Anything Model (DAM), Segment Anything Model (SAM), and GPT-4V, enhancing\nmultimodal tasks such as vision-question-answering (VQA) and composition\nreasoning. Through the fusion of segmentation and depth analysis at the\nsymbolic instance level, our library provides nuanced inputs for language\nmodels, significantly advancing image interpretation. Validated across a\nspectrum of in-the-wild real-world images, our findings showcase progress in\nvision-language models through neural-symbolic integration. This novel approach\nmelds visual and language analysis in an unprecedented manner. Overall, our\nlibrary opens new directions for future research aimed at decoding the\ncomplexities of the real world through advanced multimodal technologies and our\ncode is available at\n\\url{https://github.com/AnthonyHuo/SAM-DAM-for-Compositional-Reasoning}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18591v1",
    "published_date": "2024-06-07 16:28:06 UTC",
    "updated_date": "2024-06-07 16:28:06 UTC"
  },
  {
    "arxiv_id": "2406.05055v2",
    "title": "VC Search: Bridging the Gap Between Well-Defined and Ill-Defined Problems in Mathematical Reasoning",
    "authors": [
      "Shi-Yu Tian",
      "Zhi Zhou",
      "Kun-Yang Yu",
      "Ming Yang",
      "Lin-Han Jia",
      "Lan-Zhe Guo",
      "Yu-Feng Li"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive performance on\nreasoning tasks, including mathematical reasoning. However, the current\nevaluation mostly focuses on carefully constructed benchmarks and neglects the\nconsideration of real-world reasoning problems that present missing or\ncontradictory conditions, known as ill-defined problems. To further study this\nproblem, we develop a largescale benchmark called Problems with Missing and\nContradictory conditions ( PMC) containing over 5,000 validated ill-defined\nmathematical problems. Our preliminary experiments through PMC reveal two\nchallenges about existing methods: (1) traditional methods exhibit a trade-off\nbetween solving accuracy and rejection capabilities, and (2) formal methods\nstruggle with modeling complex problems. To address these challenges, We\ndevelop Variable-Constraint Search (VCSEARCH), a trainingfree framework that\nleverages formal language to detect ill-defined problems, where a\nvariableconstraint pair search strategy is incorporated to improve the modeling\ncapability of formal language. Extensive experiments demonstrate that VCSEARCH\nimproves the accuracy of identifying unsolvable problems by at least 12% across\ndifferent LLMs, thus achieving stronger robust mathematical reasoning ability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2406.05055v2",
    "published_date": "2024-06-07 16:24:12 UTC",
    "updated_date": "2025-02-18 05:14:48 UTC"
  },
  {
    "arxiv_id": "2406.05053v2",
    "title": "Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation",
    "authors": [
      "Nachiket Kotalwar",
      "Alkis Gotovos",
      "Adish Singla"
    ],
    "abstract": "Generative AI and large language models hold great promise in enhancing\nprogramming education by generating individualized feedback and hints for\nlearners. Recent works have primarily focused on improving the quality of\ngenerated feedback to achieve human tutors' quality. While quality is an\nimportant performance criterion, it is not the only criterion to optimize for\nreal-world educational deployments. In this paper, we benchmark language models\nfor programming feedback generation across several performance criteria,\nincluding quality, cost, time, and data privacy. The key idea is to leverage\nrecent advances in the new paradigm of in-browser inference that allow running\nthese models directly in the browser, thereby providing direct benefits across\ncost and data privacy. To boost the feedback quality of small models compatible\nwith in-browser inference engines, we develop a fine-tuning pipeline based on\nGPT-4 generated synthetic data. We showcase the efficacy of fine-tuned\nLlama3-8B and Phi3-3.8B 4-bit quantized models using WebLLM's in-browser\ninference engine on three different Python programming datasets. We will\nrelease the full implementation along with a web app and datasets to facilitate\nfurther research on in-browser language models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05053v2",
    "published_date": "2024-06-07 16:22:51 UTC",
    "updated_date": "2025-03-07 12:46:14 UTC"
  },
  {
    "arxiv_id": "2406.05038v1",
    "title": "Efficient 3D Shape Generation via Diffusion Mamba with Bidirectional SSMs",
    "authors": [
      "Shentong Mo"
    ],
    "abstract": "Recent advancements in sequence modeling have led to the development of the\nMamba architecture, noted for its selective state space approach, offering a\npromising avenue for efficient long sequence handling. However, its application\nin 3D shape generation, particularly at high resolutions, remains\nunderexplored. Traditional diffusion transformers (DiT) with self-attention\nmechanisms, despite their potential, face scalability challenges due to the\ncubic complexity of attention operations as input length increases. This\ncomplexity becomes a significant hurdle when dealing with high-resolution voxel\nsizes. To address this challenge, we introduce a novel diffusion architecture\ntailored for 3D point clouds generation-Diffusion Mamba (DiM-3D). This\narchitecture forgoes traditional attention mechanisms, instead utilizing the\ninherent efficiency of the Mamba architecture to maintain linear complexity\nwith respect to sequence length. DiM-3D is characterized by fast inference\ntimes and substantially lower computational demands, quantified in reduced\nGflops, thereby addressing the key scalability issues of prior models. Our\nempirical results on the ShapeNet benchmark demonstrate that DiM-3D achieves\nstate-of-the-art performance in generating high-fidelity and diverse 3D shapes.\nAdditionally, DiM-3D shows superior capabilities in tasks like 3D point cloud\ncompletion. This not only proves the model's scalability but also underscores\nits efficiency in generating detailed, high-resolution voxels necessary for\nadvanced 3D shape modeling, particularly excelling in environments requiring\nhigh-resolution voxel sizes. Through these findings, we illustrate the\nexceptional scalability and efficiency of the Diffusion Mamba framework in 3D\nshape generation, setting a new standard for the field and paving the way for\nfuture explorations in high-resolution 3D modeling technologies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05038v1",
    "published_date": "2024-06-07 16:02:07 UTC",
    "updated_date": "2024-06-07 16:02:07 UTC"
  },
  {
    "arxiv_id": "2406.05036v3",
    "title": "TimeSieve: Extracting Temporal Dynamics through Information Bottlenecks",
    "authors": [
      "Ninghui Feng",
      "Songning Lai",
      "Jiayu Yang",
      "Fobao Zhou",
      "Zhenxiao Yin",
      "Hang Zhao"
    ],
    "abstract": "Time series forecasting has become an increasingly popular research area due\nto its critical applications in various real-world domains such as traffic\nmanagement, weather prediction, and financial analysis. Despite significant\nadvancements, existing models face notable challenges, including the necessity\nof manual hyperparameter tuning for different datasets, and difficulty in\neffectively distinguishing signal from redundant features in data characterized\nby strong seasonality. These issues hinder the generalization and practical\napplication of time series forecasting models. To solve this issues, we propose\nan innovative time series forecasting model TimeSieve designed to address these\nchallenges. Our approach employs wavelet transforms to preprocess time series\ndata, effectively capturing multi-scale features without the need for\nadditional parameters or manual hyperparameter tuning. Additionally, we\nintroduce the information bottleneck theory that filters out redundant features\nfrom both detail and approximation coefficients, retaining only the most\npredictive information. This combination reduces significantly improves the\nmodel's accuracy. Extensive experiments demonstrate that our model outperforms\nexisting state-of-the-art methods on 70% of the datasets, achieving higher\npredictive accuracy and better generalization across diverse datasets. Our\nresults validate the effectiveness of our approach in addressing the key\nchallenges in time series forecasting, paving the way for more reliable and\nefficient predictive models in practical applications. The code for our model\nis available at https://github.com/xll0328/TimeSieve.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.05036v3",
    "published_date": "2024-06-07 15:58:12 UTC",
    "updated_date": "2024-08-21 10:22:09 UTC"
  },
  {
    "arxiv_id": "2406.05035v1",
    "title": "Scenarios and Approaches for Situated Natural Language Explanations",
    "authors": [
      "Pengshuo Qiu",
      "Frank Rudzicz",
      "Zining Zhu"
    ],
    "abstract": "Large language models (LLMs) can be used to generate natural language\nexplanations (NLE) that are adapted to different users' situations. However,\nthere is yet to be a quantitative evaluation of the extent of such adaptation.\nTo bridge this gap, we collect a benchmarking dataset, Situation-Based\nExplanation. This dataset contains 100 explanandums. Each explanandum is paired\nwith explanations targeted at three distinct audience types-such as educators,\nstudents, and professionals-enabling us to assess how well the explanations\nmeet the specific informational needs and contexts of these diverse groups e.g.\nstudents, teachers, and parents. For each \"explanandum paired with an audience\"\nsituation, we include a human-written explanation. These allow us to compute\nscores that quantify how the LLMs adapt the explanations to the situations. On\nan array of pretrained language models with varying sizes, we examine three\ncategories of prompting methods: rule-based prompting, meta-prompting, and\nin-context learning prompting. We find that 1) language models can generate\nprompts that result in explanations more precisely aligned with the target\nsituations, 2) explicitly modeling an \"assistant\" persona by prompting \"You are\na helpful assistant...\" is not a necessary prompt technique for situated NLE\ntasks, and 3) the in-context learning prompts only can help LLMs learn the\ndemonstration template but can't improve their inference performance. SBE and\nour analysis facilitate future research towards generating situated natural\nlanguage explanations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.05035v1",
    "published_date": "2024-06-07 15:56:32 UTC",
    "updated_date": "2024-06-07 15:56:32 UTC"
  },
  {
    "arxiv_id": "2406.05027v3",
    "title": "Optimizing Automatic Differentiation with Deep Reinforcement Learning",
    "authors": [
      "Jamie Lohoff",
      "Emre Neftci"
    ],
    "abstract": "Computing Jacobians with automatic differentiation is ubiquitous in many\nscientific domains such as machine learning, computational fluid dynamics,\nrobotics and finance. Even small savings in the number of computations or\nmemory usage in Jacobian computations can already incur massive savings in\nenergy consumption and runtime. While there exist many methods that allow for\nsuch savings, they generally trade computational efficiency for approximations\nof the exact Jacobian. In this paper, we present a novel method to optimize the\nnumber of necessary multiplications for Jacobian computation by leveraging deep\nreinforcement learning (RL) and a concept called cross-country elimination\nwhile still computing the exact Jacobian. Cross-country elimination is a\nframework for automatic differentiation that phrases Jacobian accumulation as\nordered elimination of all vertices on the computational graph where every\nelimination incurs a certain computational cost. We formulate the search for\nthe optimal elimination order that minimizes the number of necessary\nmultiplications as a single player game which is played by an RL agent. We\ndemonstrate that this method achieves up to 33% improvements over\nstate-of-the-art methods on several relevant tasks taken from diverse domains.\nFurthermore, we show that these theoretical gains translate into actual runtime\nimprovements by providing a cross-country elimination interpreter in JAX that\ncan efficiently execute the obtained elimination orders.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a spotlight paper at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.05027v3",
    "published_date": "2024-06-07 15:44:33 UTC",
    "updated_date": "2025-01-27 10:21:04 UTC"
  },
  {
    "arxiv_id": "2406.06622v1",
    "title": "Adversarial Tuning: Defending Against Jailbreak Attacks for LLMs",
    "authors": [
      "Fan Liu",
      "Zhao Xu",
      "Hao Liu"
    ],
    "abstract": "Although safely enhanced Large Language Models (LLMs) have achieved\nremarkable success in tackling various complex tasks in a zero-shot manner,\nthey remain susceptible to jailbreak attacks, particularly the unknown\njailbreak attack. To enhance LLMs' generalized defense capabilities, we propose\na two-stage adversarial tuning framework, which generates adversarial prompts\nto explore worst-case scenarios by optimizing datasets containing pairs of\nadversarial prompts and their safe responses. In the first stage, we introduce\nthe hierarchical meta-universal adversarial prompt learning to efficiently and\neffectively generate token-level adversarial prompts. In the second stage, we\npropose the automatic adversarial prompt learning to iteratively refine\nsemantic-level adversarial prompts, further enhancing LLM's defense\ncapabilities. We conducted comprehensive experiments on three widely used\njailbreak datasets, comparing our framework with six defense baselines under\nfive representative attack scenarios. The results underscore the superiority of\nour proposed methods. Furthermore, our adversarial tuning framework exhibits\nempirical generalizability across various attack strategies and target LLMs,\nhighlighting its potential as a transferable defense mechanism.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06622v1",
    "published_date": "2024-06-07 15:37:15 UTC",
    "updated_date": "2024-06-07 15:37:15 UTC"
  },
  {
    "arxiv_id": "2406.05017v1",
    "title": "Adaptively Learning to Select-Rank in Online Platforms",
    "authors": [
      "Jingyuan Wang",
      "Perry Dong",
      "Ying Jin",
      "Ruohan Zhan",
      "Zhengyuan Zhou"
    ],
    "abstract": "Ranking algorithms are fundamental to various online platforms across\ne-commerce sites to content streaming services. Our research addresses the\nchallenge of adaptively ranking items from a candidate pool for heterogeneous\nusers, a key component in personalizing user experience. We develop a user\nresponse model that considers diverse user preferences and the varying effects\nof item positions, aiming to optimize overall user satisfaction with the ranked\nlist. We frame this problem within a contextual bandits framework, with each\nranked list as an action. Our approach incorporates an upper confidence bound\nto adjust predicted user satisfaction scores and selects the ranking action\nthat maximizes these adjusted scores, efficiently solved via maximum weight\nimperfect matching. We demonstrate that our algorithm achieves a cumulative\nregret bound of $O(d\\sqrt{NKT})$ for ranking $K$ out of $N$ items in a\n$d$-dimensional context space over $T$ rounds, under the assumption that user\nresponses follow a generalized linear model. This regret alleviates dependence\non the ambient action space, whose cardinality grows exponentially with $N$ and\n$K$ (thus rendering direct application of existing adaptive learning algorithms\n-- such as UCB or Thompson sampling -- infeasible). Experiments conducted on\nboth simulated and real-world datasets demonstrate our algorithm outperforms\nthe baseline.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages in total. Includes 4 figures and a pdf. International\n  conference on machine learning. PMLR, 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.05017v1",
    "published_date": "2024-06-07 15:33:48 UTC",
    "updated_date": "2024-06-07 15:33:48 UTC"
  },
  {
    "arxiv_id": "2406.06621v2",
    "title": "LinkQ: An LLM-Assisted Visual Interface for Knowledge Graph Question-Answering",
    "authors": [
      "Harry Li",
      "Gabriel Appleby",
      "Ashley Suh"
    ],
    "abstract": "We present LinkQ, a system that leverages a large language model (LLM) to\nfacilitate knowledge graph (KG) query construction through natural language\nquestion-answering. Traditional approaches often require detailed knowledge of\na graph querying language, limiting the ability for users -- even experts -- to\nacquire valuable insights from KGs. LinkQ simplifies this process by\nimplementing a multistep protocol in which the LLM interprets a user's\nquestion, then systematically converts it into a well-formed query. LinkQ helps\nusers iteratively refine any open-ended questions into precise ones, supporting\nboth targeted and exploratory analysis. Further, LinkQ guards against the LLM\nhallucinating outputs by ensuring users' questions are only ever answered from\nground truth KG data. We demonstrate the efficacy of LinkQ through a\nqualitative study with five KG practitioners. Our results indicate that\npractitioners find LinkQ effective for KG question-answering, and desire future\nLLM-assisted exploratory data analysis systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Open-source code: https://github.com/mit-ll/linkq",
    "pdf_url": "http://arxiv.org/pdf/2406.06621v2",
    "published_date": "2024-06-07 15:28:31 UTC",
    "updated_date": "2025-02-10 18:35:29 UTC"
  },
  {
    "arxiv_id": "2406.05002v2",
    "title": "Deep Jansen-Rit Parameter Inference for Model-Driven Analysis of Brain Activity",
    "authors": [
      "Deepa Tilwani",
      "Christian O'Reilly"
    ],
    "abstract": "Accurately modeling effective connectivity (EC) is critical for understanding\nhow the brain processes and integrates sensory information. Yet, it remains a\nformidable challenge due to complex neural dynamics and noisy measurements such\nas those obtained from the electroencephalogram (EEG). Model-driven EC infers\nlocal (within a brain region) and global (between brain regions) EC parameters\nby fitting a generative model of neural activity onto experimental data. This\napproach offers a promising route for various applications, including\ninvestigating neurodevelopmental disorders. However, current approaches fail to\nscale to whole-brain analyses and are highly noise-sensitive. In this work, we\nemploy three deep-learning architectures--a transformer, a long short-term\nmemory (LSTM) network, and a convolutional neural network and bidirectional\nLSTM (CNN-BiLSTM) network--for inverse modeling and compare their performance\nwith simulation-based inference in estimating the Jansen-Rit neural mass model\n(JR-NMM) parameters from simulated EEG data under various noise conditions. We\ndemonstrate a reliable estimation of key local parameters, such as synaptic\ngains and time constants. However, other parameters like local JR-NMM\nconnectivity cannot be evaluated reliably from evoked-related potentials (ERP).\nWe also conduct a sensitivity analysis to characterize the influence of JR-NMM\nparameters on ERP and evaluate their learnability. Our results show the\nfeasibility of deep-learning approaches to estimate the subset of learnable\nJR-NMM parameters.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "Accepted at 7th International Conference on Advances in Signal\n  Processing and Artificial Intelligence (ASPAI' 2025), 8-10 April 2025,\n  Innsbruck, Austria",
    "pdf_url": "http://arxiv.org/pdf/2406.05002v2",
    "published_date": "2024-06-07 15:16:46 UTC",
    "updated_date": "2025-03-18 17:52:33 UTC"
  },
  {
    "arxiv_id": "2406.04998v2",
    "title": "ADBA:Approximation Decision Boundary Approach for Black-Box Adversarial Attacks",
    "authors": [
      "Feiyang Wang",
      "Xingquan Zuo",
      "Hai Huang",
      "Gang Chen"
    ],
    "abstract": "Many machine learning models are susceptible to adversarial attacks, with\ndecision-based black-box attacks representing the most critical threat in\nreal-world applications. These attacks are extremely stealthy, generating\nadversarial examples using hard labels obtained from the target machine\nlearning model. This is typically realized by optimizing perturbation\ndirections, guided by decision boundaries identified through query-intensive\nexact search, significantly limiting the attack success rate. This paper\nintroduces a novel approach using the Approximation Decision Boundary (ADB) to\nefficiently and accurately compare perturbation directions without precisely\ndetermining decision boundaries. The effectiveness of our ADB approach (ADBA)\nhinges on promptly identifying suitable ADB, ensuring reliable differentiation\nof all perturbation directions. For this purpose, we analyze the probability\ndistribution of decision boundaries, confirming that using the distribution's\nmedian value as ADB can effectively distinguish different perturbation\ndirections, giving rise to the development of the ADBA-md algorithm. ADBA-md\nonly requires four queries on average to differentiate any pair of perturbation\ndirections, which is highly query-efficient. Extensive experiments on six\nwell-known image classifiers clearly demonstrate the superiority of ADBA and\nADBA-md over multiple state-of-the-art black-box attacks. The source code is\navailable at https://github.com/BUPTAIOC/ADBA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 5 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2406.04998v2",
    "published_date": "2024-06-07 15:09:25 UTC",
    "updated_date": "2024-06-12 08:49:16 UTC"
  },
  {
    "arxiv_id": "2406.04975v1",
    "title": "UniTST: Effectively Modeling Inter-Series and Intra-Series Dependencies for Multivariate Time Series Forecasting",
    "authors": [
      "Juncheng Liu",
      "Chenghao Liu",
      "Gerald Woo",
      "Yiwei Wang",
      "Bryan Hooi",
      "Caiming Xiong",
      "Doyen Sahoo"
    ],
    "abstract": "Transformer-based models have emerged as powerful tools for multivariate time\nseries forecasting (MTSF). However, existing Transformer models often fall\nshort of capturing both intricate dependencies across variate and temporal\ndimensions in MTS data. Some recent models are proposed to separately capture\nvariate and temporal dependencies through either two sequential or parallel\nattention mechanisms. However, these methods cannot directly and explicitly\nlearn the intricate inter-series and intra-series dependencies. In this work,\nwe first demonstrate that these dependencies are very important as they usually\nexist in real-world data. To directly model these dependencies, we propose a\ntransformer-based model UniTST containing a unified attention mechanism on the\nflattened patch tokens. Additionally, we add a dispatcher module which reduces\nthe complexity and makes the model feasible for a potentially large number of\nvariates. Although our proposed model employs a simple architecture, it offers\ncompelling performance as shown in our extensive experiments on several\ndatasets for time series forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04975v1",
    "published_date": "2024-06-07 14:39:28 UTC",
    "updated_date": "2024-06-07 14:39:28 UTC"
  },
  {
    "arxiv_id": "2406.06620v3",
    "title": "MedualTime: A Dual-Adapter Language Model for Medical Time Series-Text Multimodal Learning",
    "authors": [
      "Jiexia Ye",
      "Weiqi Zhang",
      "Ziyue Li",
      "Jia Li",
      "Meng Zhao",
      "Fugee Tsung"
    ],
    "abstract": "The recent rapid advancements in language models (LMs) have garnered\nattention in medical time series-text multimodal learning. However, existing\ncontrastive learning-based and prompt-based LM approaches tend to be biased,\noften assigning a primary role to time series modality while treating text\nmodality as secondary. We classify these approaches under a temporal-primary\nparadigm, which may overlook the unique and critical task-relevant information\nembedded in text modality like clinical reports, thus failing to fully leverage\nmutual benefits and complementarity of different modalities. To fill this gap,\nwe propose a novel textual-temporal multimodal learning paradigm that enables\neither modality to serve as the primary while being enhanced by the other,\nthereby effectively capturing modality-specific information and fostering\ncross-modal interaction. In specific, we design MedualTime, a language model\ncomposed of dual adapters to implement temporal-primary and textual-primary\nmodeling simultaneously. Within each adapter, lightweight adaptation tokens are\ninjected into the top layers of LM to encourage high-level modality fusion. The\nshared LM pipeline by dual adapters not only achieves adapter alignment but\nalso enables efficient fine-tuning, reducing computational resources.\nEmpirically, MedualTime demonstrates superior performance on medical data,\nachieving notable improvements of 8% accuracy and 12% F1 in supervised\nsettings. Furthermore, MedualTime's transferability is validated by few-shot\nlabel transfer experiments from coarse-grained to fine-grained medical data.\nhttps://github.com/start2020/MedualTime",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 6 figure, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.06620v3",
    "published_date": "2024-06-07 14:34:28 UTC",
    "updated_date": "2025-05-12 13:27:11 UTC"
  },
  {
    "arxiv_id": "2406.04964v1",
    "title": "Neural Laplace for learning Stochastic Differential Equations",
    "authors": [
      "Adrien Carrel"
    ],
    "abstract": "Neural Laplace is a unified framework for learning diverse classes of\ndifferential equations (DE). For different classes of DE, this framework\noutperforms other approaches relying on neural networks that aim to learn\nclasses of ordinary differential equations (ODE). However, many systems can't\nbe modelled using ODEs. Stochastic differential equations (SDE) are the\nmathematical tool of choice when modelling spatiotemporal DE dynamics under the\ninfluence of randomness. In this work, we review the potential applications of\nNeural Laplace to learn diverse classes of SDE, both from a theoretical and a\npractical point of view.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.PR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04964v1",
    "published_date": "2024-06-07 14:29:30 UTC",
    "updated_date": "2024-06-07 14:29:30 UTC"
  },
  {
    "arxiv_id": "2406.04963v1",
    "title": "Learning Divergence Fields for Shift-Robust Graph Representations",
    "authors": [
      "Qitian Wu",
      "Fan Nie",
      "Chenxiao Yang",
      "Junchi Yan"
    ],
    "abstract": "Real-world data generation often involves certain geometries (e.g., graphs)\nthat induce instance-level interdependence. This characteristic makes the\ngeneralization of learning models more difficult due to the intricate\ninterdependent patterns that impact data-generative distributions and can vary\nfrom training to testing. In this work, we propose a geometric diffusion model\nwith learnable divergence fields for the challenging generalization problem\nwith interdependent data. We generalize the diffusion equation with stochastic\ndiffusivity at each time step, which aims to capture the multi-faceted\ninformation flows among interdependent data. Furthermore, we derive a new\nlearning objective through causal inference, which can guide the model to learn\ngeneralizable patterns of interdependence that are insensitive across domains.\nRegarding practical implementation, we introduce three model instantiations\nthat can be considered as the generalized versions of GCN, GAT, and\nTransformers, respectively, which possess advanced robustness against\ndistribution shifts. We demonstrate their promising efficacy for\nout-of-distribution generalization on diverse real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024. Source codes at\n  https://github.com/fannie1208/GLIND",
    "pdf_url": "http://arxiv.org/pdf/2406.04963v1",
    "published_date": "2024-06-07 14:29:21 UTC",
    "updated_date": "2024-06-07 14:29:21 UTC"
  },
  {
    "arxiv_id": "2406.04956v1",
    "title": "Expansion of situations theory for exploring shared awareness in human-intelligent autonomous systems",
    "authors": [
      "Scott A. Humr",
      "Mustafa Canan",
      "Mustafa Demir"
    ],
    "abstract": "Intelligent autonomous systems are part of a system of systems that interact\nwith other agents to accomplish tasks in complex environments. However,\nintelligent autonomous systems integrated system of systems add additional\nlayers of complexity based on their limited cognitive processes, specifically\nshared situation awareness that allows a team to respond to novel tasks.\nIntelligent autonomous systems' lack of shared situation awareness adversely\ninfluences team effectiveness in complex task environments, such as military\ncommand-and-control. A complementary approach of shared situation awareness,\ncalled situations theory, is beneficial for understanding the relationship\nbetween system of systems shared situation awareness and effectiveness. The\ncurrent study elucidates a conceptual discussion on situations theory to\ninvestigate the development of an system of systems shared situational\nawareness when humans team with intelligent autonomous system agents. To ground\nthe discussion, the reviewed studies expanded situations theory within the\ncontext of a system of systems that result in three major conjectures that can\nbe beneficial to the design and development of future systems of systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Keywords: artificial intelligence; human-machine interaction; IAS;\n  intelligent autonomous systems; shared situational awareness; situations\n  theory",
    "pdf_url": "http://arxiv.org/pdf/2406.04956v1",
    "published_date": "2024-06-07 14:21:01 UTC",
    "updated_date": "2024-06-07 14:21:01 UTC"
  },
  {
    "arxiv_id": "2406.04955v1",
    "title": "Experimental Evaluation of ROS-Causal in Real-World Human-Robot Spatial Interaction Scenarios",
    "authors": [
      "Luca Castri",
      "Gloria Beraldo",
      "Sariah Mghames",
      "Marc Hanheide",
      "Nicola Bellotto"
    ],
    "abstract": "Deploying robots in human-shared environments requires a deep understanding\nof how nearby agents and objects interact. Employing causal inference to model\ncause-and-effect relationships facilitates the prediction of human behaviours\nand enables the anticipation of robot interventions. However, a significant\nchallenge arises due to the absence of implementation of existing causal\ndiscovery methods within the ROS ecosystem, the standard de-facto framework in\nrobotics, hindering effective utilisation on real robots. To bridge this gap,\nin our previous work we proposed ROS-Causal, a ROS-based framework designed for\nonboard data collection and causal discovery in human-robot spatial\ninteractions. In this work, we present an experimental evaluation of ROS-Causal\nboth in simulation and on a new dataset of human-robot spatial interactions in\na lab scenario, to assess its performance and effectiveness. Our analysis\ndemonstrates the efficacy of this approach, showcasing how causal models can be\nextracted directly onboard by robots during data collection. The online causal\nmodels generated from the simulation are consistent with those from lab\nexperiments. These findings can help researchers to enhance the performance of\nrobotic systems in shared environments, firstly by studying the causal\nrelations between variables in simulation without real people, and then\nfacilitating the actual robot deployment in real human environments.\nROS-Causal: https://lcastri.github.io/roscausal",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Published at 2024 IEEE International Conference on Robot and Human\n  Interactive Communication (RO-MAN)",
    "pdf_url": "http://arxiv.org/pdf/2406.04955v1",
    "published_date": "2024-06-07 14:20:30 UTC",
    "updated_date": "2024-06-07 14:20:30 UTC"
  },
  {
    "arxiv_id": "2406.04952v2",
    "title": "Quantifying Geospatial in the Common Crawl Corpus",
    "authors": [
      "Ilya Ilyankou",
      "Meihui Wang",
      "Stefano Cavazzi",
      "James Haworth"
    ],
    "abstract": "Large language models (LLMs) exhibit emerging geospatial capabilities,\nstemming from their pre-training on vast unlabelled text datasets that are\noften derived from the Common Crawl (CC) corpus. However, the geospatial\ncontent within CC remains largely unexplored, impacting our understanding of\nLLMs' spatial reasoning. This paper investigates the prevalence of geospatial\ndata in recent Common Crawl releases using Gemini 1.5, a powerful language\nmodel. By analyzing a sample of documents and manually revising the results, we\nestimate that 18.7% of web documents in CC contain geospatial information such\nas coordinates and addresses. We find little difference in prevalence between\nEnlgish- and non-English-language documents. Our findings provide quantitative\ninsights into the nature and extent of geospatial data in CC, and lay the\ngroundwork for future studies of geospatial biases of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as a poster to ACM SIGSPATIAL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04952v2",
    "published_date": "2024-06-07 14:16:37 UTC",
    "updated_date": "2024-08-29 16:49:29 UTC"
  },
  {
    "arxiv_id": "2406.04949v1",
    "title": "Nacala-Roof-Material: Drone Imagery for Roof Detection, Classification, and Segmentation to Support Mosquito-borne Disease Risk Assessment",
    "authors": [
      "Venkanna Babu Guthula",
      "Stefan Oehmcke",
      "Remigio Chilaule",
      "Hui Zhang",
      "Nico Lang",
      "Ankit Kariryaa",
      "Johan Mottelson",
      "Christian Igel"
    ],
    "abstract": "As low-quality housing and in particular certain roof characteristics are\nassociated with an increased risk of malaria, classification of roof types\nbased on remote sensing imagery can support the assessment of malaria risk and\nthereby help prevent the disease. To support research in this area, we release\nthe Nacala-Roof-Material dataset, which contains high-resolution drone images\nfrom Mozambique with corresponding labels delineating houses and specifying\ntheir roof types. The dataset defines a multi-task computer vision problem,\ncomprising object detection, classification, and segmentation. In addition, we\nbenchmarked various state-of-the-art approaches on the dataset. Canonical\nU-Nets, YOLOv8, and a custom decoder on pretrained DINOv2 served as baselines.\nWe show that each of the methods has its advantages but none is superior on all\ntasks, which highlights the potential of our dataset for future research in\nmulti-task learning. While the tasks are closely related, accurate segmentation\nof objects does not necessarily imply accurate instance separation, and vice\nversa. We address this general issue by introducing a variant of the deep\nordinal watershed (DOW) approach that additionally separates the interior of\nobjects, allowing for improved object delineation and separation. We show that\nour DOW variant is a generic approach that improves the performance of both\nU-Net and DINOv2 backbones, leading to a better trade-off between semantic\nsegmentation and instance segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04949v1",
    "published_date": "2024-06-07 14:07:23 UTC",
    "updated_date": "2024-06-07 14:07:23 UTC"
  },
  {
    "arxiv_id": "2406.04940v2",
    "title": "CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling",
    "authors": [
      "Matthew Fortier",
      "Mats L. Richter",
      "Oliver Sonnentag",
      "Chris Pal"
    ],
    "abstract": "Terrestrial carbon fluxes provide vital information about our biosphere's\nhealth and its capacity to absorb anthropogenic CO$_2$ emissions. The\nimportance of predicting carbon fluxes has led to the emerging field of\ndata-driven carbon flux modelling (DDCFM), which uses statistical techniques to\npredict carbon fluxes from biophysical data. However, the field lacks a\nstandardized dataset to promote comparisons between models. To address this\ngap, we present CarbonSense, the first machine learning-ready dataset for\nDDCFM. CarbonSense integrates measured carbon fluxes, meteorological\npredictors, and satellite imagery from 385 locations across the globe, offering\ncomprehensive coverage and facilitating robust model training. Additionally, we\nprovide a baseline model using a current state-of-the-art DDCFM approach and a\nnovel transformer based model. Our experiments illustrate the potential gains\nthat multimodal deep learning techniques can bring to this domain. By providing\nthese resources, we aim to lower the barrier to entry for other deep learning\nresearchers to develop new models and drive new advances in carbon flux\nmodelling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 content pages, 11 reference pages, 9 appendix pages",
    "pdf_url": "http://arxiv.org/pdf/2406.04940v2",
    "published_date": "2024-06-07 13:47:40 UTC",
    "updated_date": "2025-03-24 15:37:27 UTC"
  },
  {
    "arxiv_id": "2406.04938v1",
    "title": "SpanGNN: Towards Memory-Efficient Graph Neural Networks via Spanning Subgraph Training",
    "authors": [
      "Xizhi Gu",
      "Hongzheng Li",
      "Shihong Gao",
      "Xinyan Zhang",
      "Lei Chen",
      "Yingxia Shao"
    ],
    "abstract": "Graph Neural Networks (GNNs) have superior capability in learning graph data.\nFull-graph GNN training generally has high accuracy, however, it suffers from\nlarge peak memory usage and encounters the Out-of-Memory problem when handling\nlarge graphs. To address this memory problem, a popular solution is mini-batch\nGNN training. However, mini-batch GNN training increases the training variance\nand sacrifices the model accuracy. In this paper, we propose a new\nmemory-efficient GNN training method using spanning subgraph, called SpanGNN.\nSpanGNN trains GNN models over a sequence of spanning subgraphs, which are\nconstructed from empty structure. To overcome the excessive peak memory\nconsumption problem, SpanGNN selects a set of edges from the original graph to\nincrementally update the spanning subgraph between every epoch. To ensure the\nmodel accuracy, we introduce two types of edge sampling strategies (i.e.,\nvariance-reduced and noise-reduced), and help SpanGNN select high-quality edges\nfor the GNN learning. We conduct experiments with SpanGNN on widely used\ndatasets, demonstrating SpanGNN's advantages in the model performance and low\npeak memory usage.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04938v1",
    "published_date": "2024-06-07 13:46:23 UTC",
    "updated_date": "2024-06-07 13:46:23 UTC"
  },
  {
    "arxiv_id": "2406.04935v1",
    "title": "SLOPE: Search with Learned Optimal Pruning-based Expansion",
    "authors": [
      "Davor Bokan",
      "Zlatan Ajanovic",
      "Bakir Lacevic"
    ],
    "abstract": "Heuristic search is often used for motion planning and pathfinding problems,\nfor finding the shortest path in a graph while also promising completeness and\noptimal efficiency. The drawback is it's space complexity, specifically storing\nall expanded child nodes in memory and sorting large lists of active nodes,\nwhich can be a problem in real-time scenarios with limited on-board\ncomputation. To combat this, we present the Search with Learned Optimal\nPruning-based Expansion (SLOPE), which, learns the distance of a node from a\npossible optimal path, unlike other approaches that learn a cost-to-go value.\nThe unfavored nodes are then pruned according to the said distance, which in\nturn reduces the size of the open list. This ensures that the search explores\nonly the region close to optimal paths while lowering memory and computational\ncosts. Unlike traditional learning methods, our approach is orthogonal to\nestimating cost-to-go heuristics, offering a complementary strategy for\nimproving search efficiency. We demonstrate the effectiveness of our approach\nevaluating it as a standalone search method and in conjunction with learned\nheuristic functions, achieving comparable-or-better node expansion metrics,\nwhile lowering the number of child nodes in the open list. Our code is\navailable at https://github.com/dbokan1/SLOPE.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "presented at the ICAPS 2024 workshop on Bridging the Planning and\n  Reinforcement Learning",
    "pdf_url": "http://arxiv.org/pdf/2406.04935v1",
    "published_date": "2024-06-07 13:42:15 UTC",
    "updated_date": "2024-06-07 13:42:15 UTC"
  },
  {
    "arxiv_id": "2406.04934v1",
    "title": "Optimal Recurrent Network Topologies for Dynamical Systems Reconstruction",
    "authors": [
      "Christoph Jürgen Hemmer",
      "Manuel Brenner",
      "Florian Hess",
      "Daniel Durstewitz"
    ],
    "abstract": "In dynamical systems reconstruction (DSR) we seek to infer from time series\nmeasurements a generative model of the underlying dynamical process. This is a\nprime objective in any scientific discipline, where we are particularly\ninterested in parsimonious models with a low parameter load. A common strategy\nhere is parameter pruning, removing all parameters with small weights. However,\nhere we find this strategy does not work for DSR, where even low magnitude\nparameters can contribute considerably to the system dynamics. On the other\nhand, it is well known that many natural systems which generate complex\ndynamics, like the brain or ecological networks, have a sparse topology with\ncomparatively few links. Inspired by this, we show that geometric pruning,\nwhere in contrast to magnitude-based pruning weights with a low contribution to\nan attractor's geometrical structure are removed, indeed manages to reduce\nparameter load substantially without significantly hampering DSR quality. We\nfurther find that the networks resulting from geometric pruning have a specific\ntype of topology, and that this topology, and not the magnitude of weights, is\nwhat is most crucial to performance. We provide an algorithm that automatically\ngenerates such topologies which can be used as priors for generative modeling\nof dynamical systems by RNNs, and compare it to other well studied topologies\nlike small-world or scale-free networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "nlin.CD"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04934v1",
    "published_date": "2024-06-07 13:41:17 UTC",
    "updated_date": "2024-06-07 13:41:17 UTC"
  },
  {
    "arxiv_id": "2406.04913v1",
    "title": "Online Adaptation for Enhancing Imitation Learning Policies",
    "authors": [
      "Federico Malato",
      "Ville Hautamaki"
    ],
    "abstract": "Imitation learning enables autonomous agents to learn from human examples,\nwithout the need for a reward signal. Still, if the provided dataset does not\nencapsulate the task correctly, or when the task is too complex to be modeled,\nsuch agents fail to reproduce the expert policy. We propose to recover from\nthese failures through online adaptation. Our approach combines the action\nproposal coming from a pre-trained policy with relevant experience recorded by\nan expert. The combination results in an adapted action that closely follows\nthe expert. Our experiments show that an adapted agent performs better than its\npure imitation learning counterpart. Notably, adapted agents can achieve\nreasonable performance even when the base, non-adapted policy catastrophically\nfails.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at IEEE Conference on Games 2024, Milan, Italy",
    "pdf_url": "http://arxiv.org/pdf/2406.04913v1",
    "published_date": "2024-06-07 13:09:48 UTC",
    "updated_date": "2024-06-07 13:09:48 UTC"
  },
  {
    "arxiv_id": "2406.04910v2",
    "title": "PolyLUT-Add: FPGA-based LUT Inference with Wide Inputs",
    "authors": [
      "Binglei Lou",
      "Richard Rademacher",
      "David Boland",
      "Philip H. W. Leong"
    ],
    "abstract": "FPGAs have distinct advantages as a technology for deploying deep neural\nnetworks (DNNs) at the edge. Lookup Table (LUT) based networks, where neurons\nare directly modeled using LUTs, help maximize this promise of offering\nultra-low latency and high area efficiency on FPGAs. Unfortunately, LUT\nresource usage scales exponentially with the number of inputs to the LUT,\nrestricting PolyLUT to small LUT sizes. This work introduces PolyLUT-Add, a\ntechnique that enhances neuron connectivity by combining $A$ PolyLUT\nsub-neurons via addition to improve accuracy. Moreover, we describe a novel\narchitecture to improve its scalability. We evaluated our implementation over\nthe MNIST, Jet Substructure classification, and Network Intrusion Detection\nbenchmark and found that for similar accuracy, PolyLUT-Add achieves a LUT\nreduction of $2.0-13.9\\times$ with a $1.2-1.6\\times$ decrease in latency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "The source code for this paper is available at:\n  https://github.com/bingleilou/PolyLUT-Add",
    "pdf_url": "http://arxiv.org/pdf/2406.04910v2",
    "published_date": "2024-06-07 13:00:57 UTC",
    "updated_date": "2024-09-15 12:32:18 UTC"
  },
  {
    "arxiv_id": "2406.04906v3",
    "title": "RU-AI: A Large Multimodal Dataset for Machine-Generated Content Detection",
    "authors": [
      "Liting Huang",
      "Zhihao Zhang",
      "Yiran Zhang",
      "Xiyue Zhou",
      "Shoujin Wang"
    ],
    "abstract": "The recent generative AI models' capability of creating realistic and\nhuman-like content is significantly transforming the ways in which people\ncommunicate, create and work. The machine-generated content is a double-edged\nsword. On one hand, it can benefit the society when used appropriately. On the\nother hand, it may mislead people, posing threats to the society, especially\nwhen mixed together with natural content created by humans. Hence, there is an\nurgent need to develop effective methods to detect machine-generated content.\nHowever, the lack of aligned multimodal datasets inhibited the development of\nsuch methods, particularly in triple-modality settings (e.g., text, image, and\nvoice). In this paper, we introduce RU-AI, a new large-scale multimodal dataset\nfor robust and effective detection of machine-generated content in text, image\nand voice. Our dataset is constructed on the basis of three large publicly\navailable datasets: Flickr8K, COCO and Places205, by adding their corresponding\nAI duplicates, resulting in a total of 1,475,370 instances. In addition, we\ncreated an additional noise variant of the dataset for testing the robustness\nof detection models. We conducted extensive experiments with the current SOTA\ndetection methods on our dataset. The results reveal that existing models still\nstruggle to achieve accurate and robust detection on our dataset. We hope that\nthis new data set can promote research in the field of machine-generated\ncontent detection, fostering the responsible use of generative AI. The source\ncode and datasets are available at https://github.com/ZhihaoZhang97/RU-AI.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by WWW'25 Resource Track",
    "pdf_url": "http://arxiv.org/pdf/2406.04906v3",
    "published_date": "2024-06-07 12:58:14 UTC",
    "updated_date": "2025-02-18 06:29:36 UTC"
  },
  {
    "arxiv_id": "2406.04899v1",
    "title": "Sliding Window 3-Objective Pareto Optimization for Problems with Chance Constraints",
    "authors": [
      "Frank Neumann",
      "Carsten Witt"
    ],
    "abstract": "Constrained single-objective problems have been frequently tackled by\nevolutionary multi-objective algorithms where the constraint is relaxed into an\nadditional objective. Recently, it has been shown that Pareto optimization\napproaches using bi-objective models can be significantly sped up using sliding\nwindows (Neumann and Witt, ECAI 2023). In this paper, we extend the sliding\nwindow approach to $3$-objective formulations for tackling chance constrained\nproblems. On the theoretical side, we show that our new sliding window approach\nimproves previous runtime bounds obtained in (Neumann and Witt, GECCO 2023)\nwhile maintaining the same approximation guarantees. Our experimental\ninvestigations for the chance constrained dominating set problem show that our\nnew sliding window approach allows one to solve much larger instances in a much\nmore efficient way than the 3-objective approach presented in (Neumann and\nWitt, GECCO 2023).",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "To appear at PPSN 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04899v1",
    "published_date": "2024-06-07 12:45:32 UTC",
    "updated_date": "2024-06-07 12:45:32 UTC"
  },
  {
    "arxiv_id": "2406.04896v2",
    "title": "Stabilizing Extreme Q-learning by Maclaurin Expansion",
    "authors": [
      "Motoki Omura",
      "Takayuki Osa",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "abstract": "In offline reinforcement learning, in-sample learning methods have been\nwidely used to prevent performance degradation caused by evaluating\nout-of-distribution actions from the dataset. Extreme Q-learning (XQL) employs\na loss function based on the assumption that Bellman error follows a Gumbel\ndistribution, enabling it to model the soft optimal value function in an\nin-sample manner. It has demonstrated strong performance in both offline and\nonline reinforcement learning settings. However, issues remain, such as the\ninstability caused by the exponential term in the loss function and the risk of\nthe error distribution deviating from the Gumbel distribution. Therefore, we\npropose Maclaurin Expanded Extreme Q-learning to enhance stability. In this\nmethod, applying Maclaurin expansion to the loss function in XQL enhances\nstability against large errors. This approach involves adjusting the modeled\nvalue function between the value function under the behavior policy and the\nsoft optimal value function, thus achieving a trade-off between stability and\noptimality depending on the order of expansion. It also enables adjustment of\nthe error distribution assumption from a normal distribution to a Gumbel\ndistribution. Our method significantly stabilizes learning in online RL tasks\nfrom DM Control, where XQL was previously unstable. Additionally, it improves\nperformance in several offline RL tasks from D4RL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at RLC 2024: The first Reinforcement Learning Conference",
    "pdf_url": "http://arxiv.org/pdf/2406.04896v2",
    "published_date": "2024-06-07 12:43:17 UTC",
    "updated_date": "2024-09-02 13:55:25 UTC"
  },
  {
    "arxiv_id": "2406.04890v1",
    "title": "Enhancing Indoor Temperature Forecasting through Synthetic Data in Low-Data Environments",
    "authors": [
      "Zachari Thiry",
      "Massimiliano Ruocco",
      "Alessandro Nocente",
      "Michail Spitieris"
    ],
    "abstract": "Forecasting indoor temperatures is important to achieve efficient control of\nHVAC systems. In this task, the limited data availability presents a challenge\nas most of the available data is acquired during standard operation where\nextreme scenarios and transitory regimes such as major temperature increases or\ndecreases are de-facto excluded. Acquisition of such data requires significant\nenergy consumption and a dedicated facility, hindering the quantity and\ndiversity of available data. Cost related constraints however do not allow for\ncontinuous year-around acquisition. To address this, we investigate the\nefficacy of data augmentation techniques leveraging SoTA AI-based methods for\nsynthetic data generation. Inspired by practical and experimental motivations,\nwe explore fusion strategies of real and synthetic data to improve forecasting\nmodels. This approach alleviates the need for continuously acquiring extensive\ntime series data, especially in contexts involving repetitive heating and\ncooling cycles in buildings. In our evaluation 1) we assess the performance of\nsynthetic data generators independently, particularly focusing on SoTA AI-based\nmethods; 2) we measure the utility of incorporating synthetically augmented\ndata in a subsequent forecasting tasks where we employ a simple model in two\ndistinct scenarios: 1) we first examine an augmentation technique that combines\nreal and synthetically generated data to expand the training dataset, 2) we\ndelve into utilizing synthetic data to tackle dataset imbalances. Our results\nhighlight the potential of synthetic data augmentation in enhancing forecasting\naccuracy while mitigating training variance. Through empirical experiments, we\nshow significant improvements achievable by integrating synthetic data, thereby\npaving the way for more robust forecasting models in low-data regime.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04890v1",
    "published_date": "2024-06-07 12:36:31 UTC",
    "updated_date": "2024-06-07 12:36:31 UTC"
  },
  {
    "arxiv_id": "2406.04886v2",
    "title": "Unveiling the Invisible: Captioning Videos with Metaphors",
    "authors": [
      "Abisek Rajakumar Kalarani",
      "Pushpak Bhattacharyya",
      "Sumit Shekhar"
    ],
    "abstract": "Metaphors are a common communication tool used in our day-to-day life. The\ndetection and generation of metaphors in textual form have been studied\nextensively but metaphors in other forms have been under-explored. Recent\nstudies have shown that Vision-Language (VL) models cannot understand visual\nmetaphors in memes and adverts. As of now, no probing studies have been done\nthat involve complex language phenomena like metaphors with videos. Hence, we\nintroduce a new VL task of describing the metaphors present in the videos in\nour work. To facilitate this novel task, we construct and release a manually\ncreated dataset with 705 videos and 2115 human-written captions, along with a\nnew metric called Average Concept Distance (ACD), to automatically evaluate the\ncreativity of the metaphors generated. We also propose a novel low-resource\nvideo metaphor captioning system: GIT-LLaVA, which obtains comparable\nperformance to SoTA video language models on the proposed task. We perform a\ncomprehensive analysis of existing video language models on this task and\npublish our dataset, models, and benchmark results to enable further research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04886v2",
    "published_date": "2024-06-07 12:32:44 UTC",
    "updated_date": "2024-10-02 13:40:10 UTC"
  },
  {
    "arxiv_id": "2406.04882v1",
    "title": "InstructNav: Zero-shot System for Generic Instruction Navigation in Unexplored Environment",
    "authors": [
      "Yuxing Long",
      "Wenzhe Cai",
      "Hongcheng Wang",
      "Guanqi Zhan",
      "Hao Dong"
    ],
    "abstract": "Enabling robots to navigate following diverse language instructions in\nunexplored environments is an attractive goal for human-robot interaction.\nHowever, this goal is challenging because different navigation tasks require\ndifferent strategies. The scarcity of instruction navigation data hinders\ntraining an instruction navigation model with varied strategies. Therefore,\nprevious methods are all constrained to one specific type of navigation\ninstruction. In this work, we propose InstructNav, a generic instruction\nnavigation system. InstructNav makes the first endeavor to handle various\ninstruction navigation tasks without any navigation training or pre-built maps.\nTo reach this goal, we introduce Dynamic Chain-of-Navigation (DCoN) to unify\nthe planning process for different types of navigation instructions.\nFurthermore, we propose Multi-sourced Value Maps to model key elements in\ninstruction navigation so that linguistic DCoN planning can be converted into\nrobot actionable trajectories. With InstructNav, we complete the R2R-CE task in\na zero-shot way for the first time and outperform many task-training methods.\nBesides, InstructNav also surpasses the previous SOTA method by 10.48% on the\nzero-shot Habitat ObjNav and by 86.34% on demand-driven navigation DDN. Real\nrobot experiments on diverse indoor scenes further demonstrate our method's\nrobustness in coping with the environment and instruction variations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to CoRL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04882v1",
    "published_date": "2024-06-07 12:26:34 UTC",
    "updated_date": "2024-06-07 12:26:34 UTC"
  },
  {
    "arxiv_id": "2406.04873v2",
    "title": "Ada-VE: Training-Free Consistent Video Editing Using Adaptive Motion Prior",
    "authors": [
      "Tanvir Mahmud",
      "Mustafa Munir",
      "Radu Marculescu",
      "Diana Marculescu"
    ],
    "abstract": "Video-to-video synthesis poses significant challenges in maintaining\ncharacter consistency, smooth temporal transitions, and preserving visual\nquality during fast motion. While recent fully cross-frame self-attention\nmechanisms have improved character consistency across multiple frames, they\ncome with high computational costs and often include redundant operations,\nespecially for videos with higher frame rates. To address these inefficiencies,\nwe propose an adaptive motion-guided cross-frame attention mechanism that\nselectively reduces redundant computations. This enables a greater number of\ncross-frame attentions over more frames within the same computational budget,\nthereby enhancing both video quality and temporal coherence. Our method\nleverages optical flow to focus on moving regions while sparsely attending to\nstationary areas, allowing for the joint editing of more frames without\nincreasing computational demands. Traditional frame interpolation techniques\nstruggle with motion blur and flickering in intermediate frames, which\ncompromises visual fidelity. To mitigate this, we introduce KV-caching for\njointly edited frames, reusing keys and values across intermediate frames to\npreserve visual quality and maintain temporal consistency throughout the video.\nWith our adaptive cross-frame self-attention approach, we achieve a threefold\nincrease in the number of keyframes processed compared to existing methods, all\nwithin the same computational budget as fully cross-frame attention baselines.\nThis results in significant improvements in prediction accuracy and temporal\nconsistency, outperforming state-of-the-art approaches. Code will be made\npublicly available at https://github.com/tanvir-utexas/AdaVE/tree/main",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in WACV 2025. Project page:\n  https://tanvir-utexas.github.io/AdaVE_Demo/",
    "pdf_url": "http://arxiv.org/pdf/2406.04873v2",
    "published_date": "2024-06-07 12:12:25 UTC",
    "updated_date": "2024-11-10 10:08:37 UTC"
  },
  {
    "arxiv_id": "2406.04867v2",
    "title": "Deep learning for precipitation nowcasting: A survey from the perspective of time series forecasting",
    "authors": [
      "Sojung An",
      "Tae-Jin Oh",
      "Eunha Sohn",
      "Donghyun Kim"
    ],
    "abstract": "Deep learning-based time series forecasting has dominated the short-term\nprecipitation forecasting field with the help of its ability to estimate motion\nflow in high-resolution datasets. The growing interest in precipitation\nnowcasting offers substantial opportunities for the advancement of current\nforecasting technologies. Nevertheless, there has been a scarcity of in-depth\nsurveys of time series precipitation forecasting using deep learning. Thus,\nthis paper systemically reviews recent progress in time series precipitation\nforecasting models. Specifically, we investigate the following key points\nwithin background components, covering: i) preprocessing, ii) objective\nfunctions, and iii) evaluation metrics. We then categorize forecasting models\ninto \\textit{recursive} and \\textit{multiple} strategies based on their\napproaches to predict future frames, investigate the impacts of models using\nthe strategies, and performance assessments. Finally, we evaluate current deep\nlearning-based models for precipitation forecasting on a public benchmark,\ndiscuss their limitations and challenges, and present some promising research\ndirections. Our contribution lies in providing insights for a better\nunderstanding of time series precipitation forecasting and in aiding the\ndevelopment of robust AI solutions for the future.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.04867v2",
    "published_date": "2024-06-07 12:07:09 UTC",
    "updated_date": "2024-06-14 01:11:09 UTC"
  },
  {
    "arxiv_id": "2406.10246v1",
    "title": "Semantic-Enhanced Relational Metric Learning for Recommender Systems",
    "authors": [
      "Mingming Li",
      "Fuqing Zhu",
      "Feng Yuan",
      "Songlin Hu"
    ],
    "abstract": "Recently, relational metric learning methods have been received great\nattention in recommendation community, which is inspired by the translation\nmechanism in knowledge graph. Different from the knowledge graph where the\nentity-to-entity relations are given in advance, historical interactions lack\nexplicit relations between users and items in recommender systems. Currently,\nmany researchers have succeeded in constructing the implicit relations to remit\nthis issue. However, in previous work, the learning process of the induction\nfunction only depends on a single source of data (i.e., user-item interaction)\nin a supervised manner, resulting in the co-occurrence relation that is free of\nany semantic information. In this paper, to tackle the above problem in\nrecommender systems, we propose a joint Semantic-Enhanced Relational Metric\nLearning (SERML) framework that incorporates the semantic information.\nSpecifically, the semantic signal is first extracted from the target reviews\ncontaining abundant item features and personalized user preferences. A novel\nregression model is then designed via leveraging the extracted semantic signal\nto improve the discriminative ability of original relation-based training\nprocess. On four widely-used public datasets, experimental results demonstrate\nthat SERML produces a competitive performance compared with several\nstate-of-the-art methods in recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10246v1",
    "published_date": "2024-06-07 11:54:50 UTC",
    "updated_date": "2024-06-07 11:54:50 UTC"
  },
  {
    "arxiv_id": "2406.04851v2",
    "title": "Digital assistant in a point of sales",
    "authors": [
      "Emilia Lesiak",
      "Grzegorz Wolny",
      "Bartosz Przybył",
      "Michał Szczerbak"
    ],
    "abstract": "This article investigates the deployment of a Voice User Interface\n(VUI)-powered digital assistant in a retail setting and assesses its impact on\ncustomer engagement and service efficiency. The study explores how digital\nassistants can enhance user interactions through advanced conversational\ncapabilities with multilingual support. By integrating a digital assistant into\na high-traffic retail environment, we evaluate its effectiveness in improving\nthe quality of customer service and operational efficiency. Data collected\nduring the experiment demonstrate varied impacts on customer interaction,\nrevealing insights into the future optimizations of digital assistant\ntechnologies in customer-facing roles. This study contributes to the\nunderstanding of digital transformation strategies within the customer\nrelations domain emphasizing the need for service flexibility and user-centric\ndesign in modern retail stores.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "update: cleaned the unnecessary files and updated the metadata",
    "pdf_url": "http://arxiv.org/pdf/2406.04851v2",
    "published_date": "2024-06-07 11:33:21 UTC",
    "updated_date": "2024-06-10 13:20:33 UTC"
  },
  {
    "arxiv_id": "2406.04848v3",
    "title": "CTBENCH: A Library and Benchmark for Certified Training",
    "authors": [
      "Yuhao Mao",
      "Stefan Balauca",
      "Martin Vechev"
    ],
    "abstract": "Training certifiably robust neural networks is an important but challenging\ntask. While many algorithms for (deterministic) certified training have been\nproposed, they are often evaluated on different training schedules,\ncertification methods, and systematically under-tuned hyperparameters, making\nit difficult to compare their performance. To address this challenge, we\nintroduce CTBench, a unified library and a high-quality benchmark for certified\ntraining that evaluates all algorithms under fair settings and systematically\ntuned hyperparameters. We show that (1) almost all algorithms in CTBench\nsurpass the corresponding reported performance in literature in the magnitude\nof algorithmic improvements, thus establishing new state-of-the-art, and (2)\nthe claimed advantage of recent algorithms drops significantly when we enhance\nthe outdated baselines with a fair training schedule, a fair certification\nmethod and well-tuned hyperparameters. Based on CTBench, we provide new\ninsights into the current state of certified training, including (1) certified\nmodels have less fragmented loss surface, (2) certified models share many\nmistakes, (3) certified models have more sparse activations, (4) reducing\nregularization cleverly is crucial for certified training especially for large\nradii and (5) certified training has the potential to improve\nout-of-distribution generalization. We are confident that CTBench will serve as\na benchmark and testbed for future research in certified training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04848v3",
    "published_date": "2024-06-07 11:27:18 UTC",
    "updated_date": "2025-02-03 14:49:02 UTC"
  },
  {
    "arxiv_id": "2406.04845v1",
    "title": "FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models",
    "authors": [
      "Rui Ye",
      "Rui Ge",
      "Xinyu Zhu",
      "Jingyi Chai",
      "Yaxin Du",
      "Yang Liu",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "abstract": "Federated learning has enabled multiple parties to collaboratively train\nlarge language models without directly sharing their data (FedLLM). Following\nthis training paradigm, the community has put massive efforts from diverse\naspects including framework, performance, and privacy. However, an unpleasant\nfact is that there are currently no realistic datasets and benchmarks for\nFedLLM and previous works all rely on artificially constructed datasets,\nfailing to capture properties in real-world scenarios. Addressing this, we\npropose FedLLM-Bench, which involves 8 training methods, 4 training datasets,\nand 6 evaluation metrics, to offer a comprehensive testbed for the FedLLM\ncommunity. FedLLM-Bench encompasses three datasets (e.g., user-annotated\nmultilingual dataset) for federated instruction tuning and one dataset (e.g.,\nuser-annotated preference dataset) for federated preference alignment, whose\nscale of client number ranges from 38 to 747. Our datasets incorporate several\nrepresentative diversities: language, quality, quantity, instruction, length,\nembedding, and preference, capturing properties in real-world scenarios. Based\non FedLLM-Bench, we conduct experiments on all datasets to benchmark existing\nFL methods and provide empirical insights (e.g., multilingual collaboration).\nWe believe that our FedLLM-Bench can benefit the FedLLM community by reducing\nrequired efforts, providing a practical testbed, and promoting fair\ncomparisons. Code and datasets are available at\nhttps://github.com/rui-ye/FedLLM-Bench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.04845v1",
    "published_date": "2024-06-07 11:19:30 UTC",
    "updated_date": "2024-06-07 11:19:30 UTC"
  },
  {
    "arxiv_id": "2406.04841v1",
    "title": "Primitive Agentic First-Order Optimization",
    "authors": [
      "R. Sala"
    ],
    "abstract": "Efficient numerical optimization methods can improve performance and reduce\nthe environmental impact of computing in many applications. This work presents\na proof-of-concept study combining primitive state representations and\nagent-environment interactions as first-order optimizers in the setting of\nbudget-limited optimization. Through reinforcement learning (RL) over a set of\ntraining instances of an optimization problem class, optimal policies for\nsequential update selection of algorithmic iteration steps are approximated in\ngenerally formulated low-dimensional partial state representations that\nconsider aspects of progress and resource use. For the investigated case\nstudies, deployment of the trained agents to unseen instances of the quadratic\noptimization problem classes outperformed conventional optimal algorithms with\noptimized hyperparameters. The results show that elementary RL methods combined\nwith succinct partial state representations can be used as heuristics to manage\ncomplexity in RL-based optimization, paving the way for agentic optimization\napproaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "7 Pages",
    "pdf_url": "http://arxiv.org/pdf/2406.04841v1",
    "published_date": "2024-06-07 11:13:38 UTC",
    "updated_date": "2024-06-07 11:13:38 UTC"
  },
  {
    "arxiv_id": "2406.04838v1",
    "title": "Algorithms for learning value-aligned policies considering admissibility relaxation",
    "authors": [
      "Andrés Holgado-Sánchez",
      "Joaquín Arias",
      "Holger Billhardt",
      "Sascha Ossowski"
    ],
    "abstract": "The emerging field of \\emph{value awareness engineering} claims that software\nagents and systems should be value-aware, i.e. they must make decisions in\naccordance with human values. In this context, such agents must be capable of\nexplicitly reasoning as to how far different courses of action are aligned with\nthese values. For this purpose, values are often modelled as preferences over\nstates or actions, which are then aggregated to determine the sequences of\nactions that are maximally aligned with a certain value. Recently, additional\nvalue admissibility constraints at this level have been considered as well.\n  However, often relaxed versions of these constraints are needed, and this\nincreases considerably the complexity of computing value-aligned policies. To\nobtain efficient algorithms that make value-aligned decisions considering\nadmissibility relaxation, we propose the use of learning techniques, in\nparticular, we have used constrained reinforcement learning algorithms. In this\npaper, we present two algorithms, $\\epsilon\\text{-}ADQL$ for strategies based\non local alignment and its extension $\\epsilon\\text{-}CADQL$ for a sequence of\ndecisions. We have validated their efficiency in a water distribution problem\nin a drought scenario.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04838v1",
    "published_date": "2024-06-07 11:10:07 UTC",
    "updated_date": "2024-06-07 11:10:07 UTC"
  },
  {
    "arxiv_id": "2406.04836v1",
    "title": "Revisiting Catastrophic Forgetting in Large Language Model Tuning",
    "authors": [
      "Hongyu Li",
      "Liang Ding",
      "Meng Fang",
      "Dacheng Tao"
    ],
    "abstract": "Catastrophic Forgetting (CF) means models forgetting previously acquired\nknowledge when learning new data. It compromises the effectiveness of large\nlanguage models (LLMs) during fine-tuning, yet the underlying causes have not\nbeen thoroughly investigated. This paper takes the first step to reveal the\ndirect link between the flatness of the model loss landscape and the extent of\nCF in the field of LLMs. Based on this, we introduce the sharpness-aware\nminimization to mitigate CF by flattening the loss landscape. Experiments on\nthree widely-used fine-tuning datasets, spanning different model scales,\ndemonstrate the effectiveness of our method in alleviating CF. Analyses show\nthat we nicely complement the existing anti-forgetting strategies, further\nenhancing the resistance of LLMs to CF.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04836v1",
    "published_date": "2024-06-07 11:09:13 UTC",
    "updated_date": "2024-06-07 11:09:13 UTC"
  },
  {
    "arxiv_id": "2406.04825v2",
    "title": "Graph Mining under Data scarcity",
    "authors": [
      "Appan Rakaraddi",
      "Lam Siew-Kei",
      "Mahardhika Pratama",
      "Marcus de Carvalho"
    ],
    "abstract": "Multitude of deep learning models have been proposed for node classification\nin graphs. However, they tend to perform poorly under labeled-data scarcity.\nAlthough Few-shot learning for graphs has been introduced to overcome this\nproblem, the existing models are not easily adaptable for generic graph\nlearning frameworks like Graph Neural Networks (GNNs). Our work proposes an\nUncertainty Estimator framework that can be applied on top of any generic GNN\nbackbone network (which are typically designed for supervised/semi-supervised\nnode classification) to improve the node classification performance. A neural\nnetwork is used to model the Uncertainty Estimator as a probability\ndistribution rather than probabilistic discrete scalar values. We train these\nmodels under the classic episodic learning paradigm in the $n$-way, $k$-shot\nfashion, in an end-to-end setting. Our work demonstrates that implementation of\nthe uncertainty estimator on a GNN backbone network improves the classification\naccuracy under Few-shot setting without any meta-learning specific\narchitecture. We conduct experiments on multiple datasets under different\nFew-shot settings and different GNN-based backbone networks. Our method\noutperforms the baselines, which demonstrates the efficacy of the Uncertainty\nEstimator for Few-shot node classification on graphs with a GNN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.04825v2",
    "published_date": "2024-06-07 10:50:03 UTC",
    "updated_date": "2024-06-11 13:33:16 UTC"
  },
  {
    "arxiv_id": "2406.04823v2",
    "title": "BERTs are Generative In-Context Learners",
    "authors": [
      "David Samuel"
    ],
    "abstract": "While in-context learning is commonly associated with causal language models,\nsuch as GPT, we demonstrate that this capability also 'emerges' in masked\nlanguage models. Through an embarrassingly simple inference technique, we\nenable an existing masked model, DeBERTa, to perform generative tasks without\nadditional training or architectural changes. Our evaluation reveals that the\nmasked and causal language models behave very differently, as they clearly\noutperform each other on different categories of tasks. These complementary\nstrengths suggest that the field's focus on causal models for in-context\nlearning may be limiting - both architectures can develop these capabilities,\nbut with distinct advantages; pointing toward promising hybrid approaches that\ncombine the strengths of both objectives.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04823v2",
    "published_date": "2024-06-07 10:48:45 UTC",
    "updated_date": "2024-10-31 16:48:51 UTC"
  },
  {
    "arxiv_id": "2406.04820v1",
    "title": "Navigating Efficiency in MobileViT through Gaussian Process on Global Architecture Factors",
    "authors": [
      "Ke Meng",
      "Kai Chen"
    ],
    "abstract": "Numerous techniques have been meticulously designed to achieve optimal\narchitectures for convolutional neural networks (CNNs), yet a comparable focus\non vision transformers (ViTs) has been somewhat lacking. Despite the remarkable\nsuccess of ViTs in various vision tasks, their heavyweight nature presents\nchallenges of computational costs. In this paper, we leverage the Gaussian\nprocess to systematically explore the nonlinear and uncertain relationship\nbetween performance and global architecture factors of MobileViT, such as\nresolution, width, and depth including the depth of in-verted residual blocks\nand the depth of ViT blocks, and joint factors including resolution-depth and\nresolution-width. We present design principles twisting magic 4D cube of the\nglobal architecture factors that minimize model sizes and computational costs\nwith higher model accuracy. We introduce a formula for downsizing architectures\nby iteratively deriving smaller MobileViT V2, all while adhering to a specified\nconstraint of multiply-accumulate operations (MACs). Experiment results show\nthat our formula significantly outperforms CNNs and mobile ViTs across\ndiversified datasets",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04820v1",
    "published_date": "2024-06-07 10:41:24 UTC",
    "updated_date": "2024-06-07 10:41:24 UTC"
  },
  {
    "arxiv_id": "2406.04815v3",
    "title": "Skill-aware Mutual Information Optimisation for Generalisation in Reinforcement Learning",
    "authors": [
      "Xuehui Yu",
      "Mhairi Dunion",
      "Xin Li",
      "Stefano V. Albrecht"
    ],
    "abstract": "Meta-Reinforcement Learning (Meta-RL) agents can struggle to operate across\ntasks with varying environmental features that require different optimal skills\n(i.e., different modes of behaviour). Using context encoders based on\ncontrastive learning to enhance the generalisability of Meta-RL agents is now\nwidely studied but faces challenges such as the requirement for a large sample\nsize, also referred to as the $\\log$-$K$ curse. To improve RL generalisation to\ndifferent tasks, we first introduce Skill-aware Mutual Information (SaMI), an\noptimisation objective that aids in distinguishing context embeddings according\nto skills, thereby equipping RL agents with the ability to identify and execute\ndifferent skills across tasks. We then propose Skill-aware Noise Contrastive\nEstimation (SaNCE), a $K$-sample estimator used to optimise the SaMI objective.\nWe provide a framework for equipping an RL agent with SaNCE in practice and\nconduct experimental validation on modified MuJoCo and Panda-gym benchmarks. We\nempirically find that RL agents that learn by maximising SaMI achieve\nsubstantially improved zero-shot generalisation to unseen tasks. Additionally,\nthe context encoder trained with SaNCE demonstrates greater robustness to a\nreduction in the number of available samples, thus possessing the potential to\novercome the $\\log$-$K$ curse.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "The Thirty-eighth Annual Conference on Neural Information Processing\n  Systems (NeurIPS), 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04815v3",
    "published_date": "2024-06-07 10:35:29 UTC",
    "updated_date": "2024-11-06 13:24:41 UTC"
  },
  {
    "arxiv_id": "2406.10245v1",
    "title": "On conceptualisation and an overview of learning path recommender systems in e-learning",
    "authors": [
      "A. Fuster-López",
      "J. M. Cruz",
      "P. Guerrero-García",
      "E. M. T. Hendrix",
      "A. Košir",
      "I. Nowak",
      "L. Oneto",
      "S. Sirmakessis",
      "M. F. Pacheco",
      "F. P. Fernandes",
      "A. I. Pereira"
    ],
    "abstract": "The use of e-learning systems has a long tradition, where students can study\nonline helped by a system. In this context, the use of recommender systems is\nrelatively new. In our research project, we investigated various ways to create\na recommender system. They all aim at facilitating the learning and\nunderstanding of a student. We present a common concept of the learning path\nand its learning indicators and embed 5 different recommenders in this context.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10245v1",
    "published_date": "2024-06-07 10:30:43 UTC",
    "updated_date": "2024-06-07 10:30:43 UTC"
  },
  {
    "arxiv_id": "2406.04812v1",
    "title": "Generating Piano Practice Policy with a Gaussian Process",
    "authors": [
      "Alexandra Moringen",
      "Elad Vromen",
      "Helge Ritter",
      "Jason Friedman"
    ],
    "abstract": "A typical process of learning to play a piece on a piano consists of a\nprogression through a series of practice units that focus on individual\ndimensions of the skill, the so-called practice modes. Practice modes in\nlearning to play music comprise a particularly large set of possibilities, such\nas hand coordination, posture, articulation, ability to read a music score,\ncorrect timing or pitch, etc. Self-guided practice is known to be suboptimal,\nand a model that schedules optimal practice to maximize a learner's progress\nstill does not exist. Because we each learn differently and there are many\nchoices for possible piano practice tasks and methods, the set of practice\nmodes should be dynamically adapted to the human learner, a process typically\nguided by a teacher. However, having a human teacher guide individual practice\nis not always feasible since it is time-consuming, expensive, and often\nunavailable. In this work, we present a modeling framework to guide the human\nlearner through the learning process by choosing the practice modes generated\nby a policy model. To this end, we present a computational architecture\nbuilding on a Gaussian process that incorporates 1) the learner state, 2) a\npolicy that selects a suitable practice mode, 3) performance evaluation, and 4)\nexpert knowledge. The proposed policy model is trained to approximate the\nexpert-learner interaction during a practice session. In our future work, we\nwill test different Bayesian optimization techniques, e.g., different\nacquisition functions, and evaluate their effect on the learning progress.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04812v1",
    "published_date": "2024-06-07 10:27:07 UTC",
    "updated_date": "2024-06-07 10:27:07 UTC"
  },
  {
    "arxiv_id": "2406.04809v5",
    "title": "A Survey of Fragile Model Watermarking",
    "authors": [
      "Zhenzhe Gao",
      "Yu Cheng",
      "Zhaoxia Yin"
    ],
    "abstract": "Model fragile watermarking, inspired by both the field of adversarial attacks\non neural networks and traditional multimedia fragile watermarking, has\ngradually emerged as a potent tool for detecting tampering, and has witnessed\nrapid development in recent years. Unlike robust watermarks, which are widely\nused for identifying model copyrights, fragile watermarks for models are\ndesigned to identify whether models have been subjected to unexpected\nalterations such as backdoors, poisoning, compression, among others. These\nalterations can pose unknown risks to model users, such as misidentifying stop\nsigns as speed limit signs in classic autonomous driving scenarios. This paper\nprovides an overview of the relevant work in the field of model fragile\nwatermarking since its inception, categorizing them and revealing the\ndevelopmental trajectory of the field, thus offering a comprehensive survey for\nfuture endeavors in model fragile watermarking.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "There will be more revisions to the wording and image additions, and\n  we hope to withdraw the previous version",
    "pdf_url": "http://arxiv.org/pdf/2406.04809v5",
    "published_date": "2024-06-07 10:23:25 UTC",
    "updated_date": "2024-08-14 09:02:33 UTC"
  },
  {
    "arxiv_id": "2406.12896v1",
    "title": "Leveraging Pedagogical Theories to Understand Student Learning Process with Graph-based Reasonable Knowledge Tracing",
    "authors": [
      "Jiajun Cui",
      "Hong Qian",
      "Bo Jiang",
      "Wei Zhang"
    ],
    "abstract": "Knowledge tracing (KT) is a crucial task in intelligent education, focusing\non predicting students' performance on given questions to trace their evolving\nknowledge. The advancement of deep learning in this field has led to\ndeep-learning knowledge tracing (DLKT) models that prioritize high predictive\naccuracy. However, many existing DLKT methods overlook the fundamental goal of\ntracking students' dynamical knowledge mastery. These models do not explicitly\nmodel knowledge mastery tracing processes or yield unreasonable results that\neducators find difficulty to comprehend and apply in real teaching scenarios.\nIn response, our research conducts a preliminary analysis of mainstream KT\napproaches to highlight and explain such unreasonableness. We introduce GRKT, a\ngraph-based reasonable knowledge tracing method to address these issues. By\nleveraging graph neural networks, our approach delves into the mutual\ninfluences of knowledge concepts, offering a more accurate representation of\nhow the knowledge mastery evolves throughout the learning process.\nAdditionally, we propose a fine-grained and psychological three-stage modeling\nprocess as knowledge retrieval, memory strengthening, and knowledge\nlearning/forgetting, to conduct a more reasonable knowledge tracing process.\nComprehensive experiments demonstrate that GRKT outperforms eleven baselines\nacross three datasets, not only enhancing predictive accuracy but also\ngenerating more reasonable knowledge tracing results. This makes our model a\npromising advancement for practical implementation in educational settings. The\nsource code is available at https://github.com/JJCui96/GRKT.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint, accepted to appear in SIGKDD 2024, 12 pages. The source\n  code is available at https://github.com/JJCui96/GRKT. Keywords: interpretable\n  knowledge tracing, student behavior modeling, intelligence education",
    "pdf_url": "http://arxiv.org/pdf/2406.12896v1",
    "published_date": "2024-06-07 10:14:30 UTC",
    "updated_date": "2024-06-07 10:14:30 UTC"
  },
  {
    "arxiv_id": "2406.04806v4",
    "title": "Streaming Diffusion Policy: Fast Policy Synthesis with Variable Noise Diffusion Models",
    "authors": [
      "Sigmund H. Høeg",
      "Yilun Du",
      "Olav Egeland"
    ],
    "abstract": "Diffusion models have seen rapid adoption in robotic imitation learning,\nenabling autonomous execution of complex dexterous tasks. However, action\nsynthesis is often slow, requiring many steps of iterative denoising, limiting\nthe extent to which models can be used in tasks that require fast reactive\npolicies. To sidestep this, recent works have explored how the distillation of\nthe diffusion process can be used to accelerate policy synthesis. However,\ndistillation is computationally expensive and can hurt both the accuracy and\ndiversity of synthesized actions. We propose SDP (Streaming Diffusion Policy),\nan alternative method to accelerate policy synthesis, leveraging the insight\nthat generating a partially denoised action trajectory is substantially faster\nthan a full output action trajectory. At each observation, our approach outputs\na partially denoised action trajectory with variable levels of noise\ncorruption, where the immediate action to execute is noise-free, with\nsubsequent actions having increasing levels of noise and uncertainty. The\npartially denoised action trajectory for a new observation can then be quickly\ngenerated by applying a few steps of denoising to the previously predicted\nnoisy action trajectory (rolled over by one timestep). We illustrate the\nefficacy of this approach, dramatically speeding up policy synthesis while\npreserving performance across both simulated and real-world settings.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04806v4",
    "published_date": "2024-06-07 10:13:44 UTC",
    "updated_date": "2024-10-11 16:04:49 UTC"
  },
  {
    "arxiv_id": "2406.04800v1",
    "title": "Zero, Finite, and Infinite Belief History of Theory of Mind Reasoning in Large Language Models",
    "authors": [
      "Weizhi Tang",
      "Vaishak Belle"
    ],
    "abstract": "Large Language Models (LLMs) have recently shown a promise and emergence of\nTheory of Mind (ToM) ability and even outperform humans in certain ToM tasks.\nTo evaluate and extend the boundaries of the ToM reasoning ability of LLMs, we\npropose a novel concept, taxonomy, and framework, the ToM reasoning with Zero,\nFinite, and Infinite Belief History and develop a multi-round text-based game,\ncalled $\\textit{Pick the Right Stuff}$, as a benchmark. We have evaluated six\nLLMs with this game and found their performance on Zero Belief History is\nconsistently better than on Finite Belief History. In addition, we have found\ntwo of the models with small parameter sizes outperform all the evaluated\nmodels with large parameter sizes. We expect this work to pave the way for\nfuture ToM benchmark development and also for the promotion and development of\nmore complex AI agents or systems which are required to be equipped with more\ncomplex ToM reasoning ability.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04800v1",
    "published_date": "2024-06-07 10:04:39 UTC",
    "updated_date": "2024-06-07 10:04:39 UTC"
  },
  {
    "arxiv_id": "2406.04793v2",
    "title": "Learning-Augmented Priority Queues",
    "authors": [
      "Ziyad Benomar",
      "Christian Coester"
    ],
    "abstract": "Priority queues are one of the most fundamental and widely used data\nstructures in computer science. Their primary objective is to efficiently\nsupport the insertion of new elements with assigned priorities and the\nextraction of the highest priority element. In this study, we investigate the\ndesign of priority queues within the learning-augmented framework, where\nalgorithms use potentially inaccurate predictions to enhance their worst-case\nperformance. We examine three prediction models spanning different use cases,\nand show how the predictions can be leveraged to enhance the performance of\npriority queue operations. Moreover, we demonstrate the optimality of our\nsolution and discuss some possible applications.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "Accepted as a conference paper at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04793v2",
    "published_date": "2024-06-07 09:40:09 UTC",
    "updated_date": "2024-11-17 21:13:54 UTC"
  },
  {
    "arxiv_id": "2406.04784v1",
    "title": "SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals",
    "authors": [
      "Ruihan Yang",
      "Jiangjie Chen",
      "Yikai Zhang",
      "Siyu Yuan",
      "Aili Chen",
      "Kyle Richardson",
      "Yanghua Xiao",
      "Deqing Yang"
    ],
    "abstract": "Language agents powered by large language models (LLMs) are increasingly\nvaluable as decision-making tools in domains such as gaming and programming.\nHowever, these agents often face challenges in achieving high-level goals\nwithout detailed instructions and in adapting to environments where feedback is\ndelayed. In this paper, we present SelfGoal, a novel automatic approach\ndesigned to enhance agents' capabilities to achieve high-level goals with\nlimited human prior and environmental feedback. The core concept of SelfGoal\ninvolves adaptively breaking down a high-level goal into a tree structure of\nmore practical subgoals during the interaction with environments while\nidentifying the most useful subgoals and progressively updating this structure.\nExperimental results demonstrate that SelfGoal significantly enhances the\nperformance of language agents across various tasks, including competitive,\ncooperative, and deferred feedback environments. Project page:\nhttps://selfgoal-agent.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2406.04784v1",
    "published_date": "2024-06-07 09:32:03 UTC",
    "updated_date": "2024-06-07 09:32:03 UTC"
  },
  {
    "arxiv_id": "2406.04780v1",
    "title": "Software Engineering for Collective Cyber-Physical Ecosystems",
    "authors": [
      "Roberto Casadei",
      "Gianluca Aguzzi",
      "Giorgio Audrito",
      "Ferruccio Damiani",
      "Danilo Pianini",
      "Giordano Scarso",
      "Gianluca Torta",
      "Mirko Viroli"
    ],
    "abstract": "Today's distributed and pervasive computing addresses large-scale\ncyber-physical ecosystems, characterised by dense and large networks of devices\ncapable of computation, communication and interaction with the environment and\npeople. While most research focusses on treating these systems as \"composites\"\n(i.e., heterogeneous functional complexes), recent developments in fields such\nas self-organising systems and swarm robotics have opened up a complementary\nperspective: treating systems as \"collectives\" (i.e., uniform, collaborative,\nand self-organising groups of entities). This article explores the motivations,\nstate of the art, and implications of this \"collective computing paradigm\" in\nsoftware engineering, discusses its peculiar challenges, and outlines a path\nfor future research, touching on aspects such as macroprogramming, collective\nintelligence, self-adaptive middleware, learning, synthesis, and\nexperimentation of collective behaviour.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DC",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 2 figures, Accepted for presentation at the International\n  Workshop on Software Engineering in 2030, November 2024, Puerto Galinas\n  (Brazil)",
    "pdf_url": "http://arxiv.org/pdf/2406.04780v1",
    "published_date": "2024-06-07 09:28:22 UTC",
    "updated_date": "2024-06-07 09:28:22 UTC"
  },
  {
    "arxiv_id": "2406.04779v1",
    "title": "Mobile Network Configuration Recommendation using Deep Generative Graph Neural Network",
    "authors": [
      "Shirwan Piroti",
      "Ashima Chawla",
      "Tahar Zanouda"
    ],
    "abstract": "There are vast number of configurable parameters in a Radio Access Telecom\nNetwork. A significant amount of these parameters is configured by Radio Node\nor cell based on their deployment setting. Traditional methods rely on domain\nknowledge for individual parameter configuration, often leading to sub-optimal\nresults. To improve this, a framework using a Deep Generative Graph Neural\nNetwork (GNN) is proposed. It encodes the network into a graph, extracts\nsubgraphs for each RAN node, and employs a Siamese GNN (S-GNN) to learn\nembeddings. The framework recommends configuration parameters for a multitude\nof parameters and detects misconfigurations, handling both network expansion\nand existing cell reconfiguration. Tested on real-world data, the model\nsurpasses baselines, demonstrating accuracy, generalizability, and robustness\nagainst concept drift.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "4 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.04779v1",
    "published_date": "2024-06-07 09:28:18 UTC",
    "updated_date": "2024-06-07 09:28:18 UTC"
  },
  {
    "arxiv_id": "2406.04776v1",
    "title": "OFDM-Standard Compatible SC-NOFS Waveforms for Low-Latency and Jitter-Tolerance Industrial IoT Communications",
    "authors": [
      "Tongyang Xu",
      "Shuangyang Li",
      "Jinhong Yuan"
    ],
    "abstract": "Traditional communications focus on regular and orthogonal signal waveforms\nfor simplified signal processing and improved spectral efficiency. In contrast,\nthe next-generation communications would aim for irregular and non-orthogonal\nsignal waveforms to introduce new capabilities. This work proposes a spectrally\nefficient irregular Sinc (irSinc) shaping technique, revisiting the traditional\nSinc back to 1924, with the aim of enhancing performance in industrial Internet\nof things (IIoT). In time-critical IIoT applications, low-latency and\ntime-jitter tolerance are two critical factors that significantly impact the\nperformance and reliability. Recognizing the inevitability of latency and\njitter in practice, this work aims to propose a waveform technique to mitigate\nthese effects via reducing latency and enhancing the system robustness under\ntime jitter effects. The utilization of irSinc yields a signal with increased\nspectral efficiency without sacrificing error performance. Integrating the\nirSinc in a two-stage framework, a single-carrier non-orthogonal frequency\nshaping (SC-NOFS) waveform is developed, showcasing perfect compatibility with\n5G standards, enabling the direct integration of irSinc in existing industrial\nIoT setups. Through 5G standard signal configuration, our signal achieves\nfaster data transmission within the same spectral bandwidth. Hardware\nexperiments validate an 18% saving in timing resources, leading to either\nreduced latency or enhanced jitter tolerance.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04776v1",
    "published_date": "2024-06-07 09:20:30 UTC",
    "updated_date": "2024-06-07 09:20:30 UTC"
  },
  {
    "arxiv_id": "2406.04772v3",
    "title": "REP: Resource-Efficient Prompting for Rehearsal-Free Continual Learning",
    "authors": [
      "Sungho Jeon",
      "Xinyue Ma",
      "Kwang In Kim",
      "Myeongjae Jeon"
    ],
    "abstract": "Recent rehearsal-free methods, guided by prompts, excel in vision-related\ncontinual learning (CL) with drifting data but lack resource efficiency, making\nreal-world deployment challenging. In this paper, we introduce\nResource-Efficient Prompting (REP), which improves the computational and memory\nefficiency of prompt-based rehearsal-free methods while minimizing accuracy\ntrade-offs. Our approach employs swift prompt selection to refine input data\nusing a carefully provisioned model and introduces adaptive token merging\n(AToM) and layer dropping (ALD) for efficient prompt updates. AToM and ALD\nselectively skip data and model layers while preserving task-specific features\nduring new-task learning. Extensive experiments on multiple image\nclassification datasets demonstrates REP's superior resource efficiency over\nstate-of-the-art ViT- and CNN-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04772v3",
    "published_date": "2024-06-07 09:17:33 UTC",
    "updated_date": "2025-02-17 03:10:52 UTC"
  },
  {
    "arxiv_id": "2406.04770v2",
    "title": "WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild",
    "authors": [
      "Bill Yuchen Lin",
      "Yuntian Deng",
      "Khyathi Chandu",
      "Faeze Brahman",
      "Abhilasha Ravichander",
      "Valentina Pyatkin",
      "Nouha Dziri",
      "Ronan Le Bras",
      "Yejin Choi"
    ],
    "abstract": "We introduce WildBench, an automated evaluation framework designed to\nbenchmark large language models (LLMs) using challenging, real-world user\nqueries. WildBench consists of 1,024 tasks carefully selected from over one\nmillion human-chatbot conversation logs. For automated evaluation with\nWildBench, we have developed two metrics, WB-Reward and WB-Score, which are\ncomputable using advanced LLMs such as GPT-4-turbo. WildBench evaluation uses\ntask-specific checklists to evaluate model outputs systematically and provides\nstructured explanations that justify the scores and comparisons, resulting in\nmore reliable and interpretable automatic judgments. WB-Reward employs\nfine-grained pairwise comparisons between model responses, generating five\npotential outcomes: much better, slightly better, slightly worse, much worse,\nor a tie. Unlike previous evaluations that employed a single baseline model, we\nselected three baseline models at varying performance levels to ensure a\ncomprehensive pairwise evaluation. Additionally, we propose a simple method to\nmitigate length bias, by converting outcomes of ``slightly better/worse'' to\n``tie'' if the winner response exceeds the loser one by more than $K$\ncharacters. WB-Score evaluates the quality of model outputs individually,\nmaking it a fast and cost-efficient evaluation metric. WildBench results\ndemonstrate a strong correlation with the human-voted Elo ratings from Chatbot\nArena on hard tasks. Specifically, WB-Reward achieves a Pearson correlation of\n0.98 with top-ranking models. Additionally, WB-Score reaches 0.95, surpassing\nboth ArenaHard's 0.91 and AlpacaEval2.0's 0.89 for length-controlled win rates,\nas well as the 0.87 for regular win rates.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Link: https://hf.co/spaces/allenai/WildBench",
    "pdf_url": "http://arxiv.org/pdf/2406.04770v2",
    "published_date": "2024-06-07 09:15:44 UTC",
    "updated_date": "2024-10-05 22:39:51 UTC"
  },
  {
    "arxiv_id": "2406.04755v4",
    "title": "LLM Whisperer: An Inconspicuous Attack to Bias LLM Responses",
    "authors": [
      "Weiran Lin",
      "Anna Gerchanovsky",
      "Omer Akgul",
      "Lujo Bauer",
      "Matt Fredrikson",
      "Zifan Wang"
    ],
    "abstract": "Writing effective prompts for large language models (LLM) can be unintuitive\nand burdensome. In response, services that optimize or suggest prompts have\nemerged. While such services can reduce user effort, they also introduce a\nrisk: the prompt provider can subtly manipulate prompts to produce heavily\nbiased LLM responses. In this work, we show that subtle synonym replacements in\nprompts can increase the likelihood (by a difference up to 78%) that LLMs\nmention a target concept (e.g., a brand, political party, nation). We\nsubstantiate our observations through a user study, showing that our\nadversarially perturbed prompts 1) are indistinguishable from unaltered prompts\nby humans, 2) push LLMs to recommend target concepts more often, and 3) make\nusers more likely to notice target concepts, all without arousing suspicion.\nThe practicality of this attack has the potential to undermine user autonomy.\nAmong other measures, we recommend implementing warnings against using prompts\nfrom untrusted parties.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04755v4",
    "published_date": "2024-06-07 08:54:55 UTC",
    "updated_date": "2025-02-28 14:41:16 UTC"
  },
  {
    "arxiv_id": "2406.04746v2",
    "title": "PQPP: A Joint Benchmark for Text-to-Image Prompt and Query Performance Prediction",
    "authors": [
      "Eduard Poesina",
      "Adriana Valentina Costache",
      "Adrian-Gabriel Chifu",
      "Josiane Mothe",
      "Radu Tudor Ionescu"
    ],
    "abstract": "Text-to-image generation has recently emerged as a viable alternative to\ntext-to-image retrieval, driven by the visually impressive results of\ngenerative diffusion models. Although query performance prediction is an active\nresearch topic in information retrieval, to the best of our knowledge, there is\nno prior study that analyzes the difficulty of queries (referred to as prompts)\nin text-to-image generation, based on human judgments. To this end, we\nintroduce the first dataset of prompts which are manually annotated in terms of\nimage generation performance. Additionally, we extend these evaluations to\ntext-to-image retrieval by collecting manual annotations that represent\nretrieval performance. We thus establish the first joint benchmark for prompt\nand query performance prediction (PQPP) across both tasks, comprising over 10K\nqueries. Our benchmark enables (i) the comparative assessment of prompt/query\ndifficulty in both image generation and image retrieval, and (ii) the\nevaluation of prompt/query performance predictors addressing both generation\nand retrieval. We evaluate several pre- and post-generation/retrieval\nperformance predictors, thus providing competitive baselines for future\nresearch. Our benchmark and code are publicly available at\nhttps://github.com/Eduard6421/PQPP.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.04746v2",
    "published_date": "2024-06-07 08:46:19 UTC",
    "updated_date": "2025-03-18 16:45:09 UTC"
  },
  {
    "arxiv_id": "2406.04734v2",
    "title": "Generative AI Models: Opportunities and Risks for Industry and Authorities",
    "authors": [
      "Tobias Alt",
      "Andrea Ibisch",
      "Clemens Meiser",
      "Anna Wilhelm",
      "Raphael Zimmer",
      "Jonas Ditz",
      "Dominique Dresen",
      "Christoph Droste",
      "Jens Karschau",
      "Friederike Laus",
      "Oliver Müller",
      "Matthias Neu",
      "Rainer Plaga",
      "Carola Plesch",
      "Britta Sennewald",
      "Thomas Thaeren",
      "Kristina Unverricht",
      "Steffen Waurick"
    ],
    "abstract": "Generative AI models are capable of performing a wide variety of tasks that\nhave traditionally required creativity and human understanding. During\ntraining, they learn patterns from existing data and can subsequently generate\nnew content such as texts, images, audio, and videos that align with these\npatterns. Due to their versatility and generally high-quality results, they\nrepresent, on the one hand, an opportunity for digitalisation. On the other\nhand, the use of generative AI models introduces novel IT security risks that\nmust be considered as part of a comprehensive analysis of the IT security\nthreat landscape. In response to this risk potential, companies or authorities\nintending to use generative AI should conduct an individual risk analysis\nbefore integrating it into their workflows. The same applies to developers and\noperators, as many risks associated with generative AI must be addressed during\ndevelopment or can only be influenced by the operating organisation. Based on\nthis, existing security measures can be adapted, and additional measures\nimplemented.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "68T50 (Primary), 68M25, 68T07 (Secondary)",
      "I.2.7; I.2.10"
    ],
    "primary_category": "cs.AI",
    "comment": "67 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.04734v2",
    "published_date": "2024-06-07 08:34:30 UTC",
    "updated_date": "2025-02-03 11:03:02 UTC"
  },
  {
    "arxiv_id": "2406.04727v2",
    "title": "MMPolymer: A Multimodal Multitask Pretraining Framework for Polymer Property Prediction",
    "authors": [
      "Fanmeng Wang",
      "Wentao Guo",
      "Minjie Cheng",
      "Shen Yuan",
      "Hongteng Xu",
      "Zhifeng Gao"
    ],
    "abstract": "Polymers are high-molecular-weight compounds constructed by the covalent\nbonding of numerous identical or similar monomers so that their 3D structures\nare complex yet exhibit unignorable regularity. Typically, the properties of a\npolymer, such as plasticity, conductivity, bio-compatibility, and so on, are\nhighly correlated with its 3D structure. However, existing polymer property\nprediction methods heavily rely on the information learned from polymer SMILES\nsequences (P-SMILES strings) while ignoring crucial 3D structural information,\nresulting in sub-optimal performance. In this work, we propose MMPolymer, a\nnovel multimodal multitask pretraining framework incorporating polymer 1D\nsequential and 3D structural information to encourage downstream polymer\nproperty prediction tasks. Besides, considering the scarcity of polymer 3D\ndata, we further introduce the \"Star Substitution\" strategy to extract 3D\nstructural information effectively. During pretraining, in addition to\npredicting masked tokens and recovering clear 3D coordinates, MMPolymer\nachieves the cross-modal alignment of latent representations. Then we further\nfine-tune the pretrained MMPolymer for downstream polymer property prediction\ntasks in the supervised learning paradigm. Experiments show that MMPolymer\nachieves state-of-the-art performance in downstream property prediction tasks.\nMoreover, given the pretrained MMPolymer, utilizing merely a single modality in\nthe fine-tuning phase can also outperform existing methods, showcasing the\nexceptional capability of MMPolymer in polymer feature extraction and\nutilization.",
    "categories": [
      "cs.LG",
      "cond-mat.soft",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 33rd ACM International Conference on Information and\n  Knowledge Management (CIKM 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.04727v2",
    "published_date": "2024-06-07 08:19:59 UTC",
    "updated_date": "2024-07-26 13:24:41 UTC"
  },
  {
    "arxiv_id": "2406.11875v1",
    "title": "ChatPCG: Large Language Model-Driven Reward Design for Procedural Content Generation",
    "authors": [
      "In-Chang Baek",
      "Tae-Hwa Park",
      "Jin-Ha Noh",
      "Cheong-Mok Bae",
      "Kyung-Joong Kim"
    ],
    "abstract": "Driven by the rapid growth of machine learning, recent advances in game\nartificial intelligence (AI) have significantly impacted productivity across\nvarious gaming genres. Reward design plays a pivotal role in training game AI\nmodels, wherein researchers implement concepts of specific reward functions.\nHowever, despite the presence of AI, the reward design process predominantly\nremains in the domain of human experts, as it is heavily reliant on their\ncreativity and engineering skills. Therefore, this paper proposes ChatPCG, a\nlarge language model (LLM)-driven reward design framework.It leverages\nhuman-level insights, coupled with game expertise, to generate rewards tailored\nto specific game features automatically. Moreover, ChatPCG is integrated with\ndeep reinforcement learning, demonstrating its potential for multiplayer game\ncontent generation tasks. The results suggest that the proposed LLM exhibits\nthe capability to comprehend game mechanics and content generation tasks,\nenabling tailored content generation for a specified game. This study not only\nhighlights the potential for improving accessibility in content generation but\nalso aims to streamline the game AI development process.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 2 figures, accepted at IEEE Conference on Games 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.11875v1",
    "published_date": "2024-06-07 08:18:42 UTC",
    "updated_date": "2024-06-07 08:18:42 UTC"
  },
  {
    "arxiv_id": "2406.04724v4",
    "title": "On Minimizing Adversarial Counterfactual Error in Adversarial RL",
    "authors": [
      "Roman Belaire",
      "Arunesh Sinha",
      "Pradeep Varakantham"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) policies are highly susceptible to\nadversarial noise in observations, which poses significant risks in\nsafety-critical scenarios. The challenge inherent to adversarial perturbations\nis that by altering the information observed by the agent, the state becomes\nonly partially observable. Existing approaches address this by either enforcing\nconsistent actions across nearby states or maximizing the worst-case value\nwithin adversarially perturbed observations. However, the former suffers from\nperformance degradation when attacks succeed, while the latter tends to be\noverly conservative, leading to suboptimal performance in benign settings. We\nhypothesize that these limitations stem from their failing to account for\npartial observability directly. To this end, we introduce a novel objective\ncalled Adversarial Counterfactual Error (ACoE), defined on the beliefs about\nthe true state and balancing value optimization with robustness. To make ACoE\nscalable in model-free settings, we propose the theoretically-grounded\nsurrogate objective Cumulative-ACoE (C-ACoE). Our empirical evaluations on\nstandard benchmarks (MuJoCo, Atari, and Highway) demonstrate that our method\nsignificantly outperforms current state-of-the-art approaches for addressing\nadversarial RL challenges, offering a promising direction for improving\nrobustness in DRL under adversarial conditions. Our code is available at\nhttps://github.com/romanbelaire/acoe-robust-rl.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.04724v4",
    "published_date": "2024-06-07 08:14:24 UTC",
    "updated_date": "2025-04-23 18:03:48 UTC"
  },
  {
    "arxiv_id": "2406.06619v1",
    "title": "LoRA-Whisper: Parameter-Efficient and Extensible Multilingual ASR",
    "authors": [
      "Zheshu Song",
      "Jianheng Zhuo",
      "Yifan Yang",
      "Ziyang Ma",
      "Shixiong Zhang",
      "Xie Chen"
    ],
    "abstract": "Recent years have witnessed significant progress in multilingual automatic\nspeech recognition (ASR), driven by the emergence of end-to-end (E2E) models\nand the scaling of multilingual datasets. Despite that, two main challenges\npersist in multilingual ASR: language interference and the incorporation of new\nlanguages without degrading the performance of the existing ones. This paper\nproposes LoRA-Whisper, which incorporates LoRA matrix into Whisper for\nmultilingual ASR, effectively mitigating language interference. Furthermore, by\nleveraging LoRA and the similarities between languages, we can achieve better\nperformance on new languages while upholding consistent performance on original\nones. Experiments on a real-world task across eight languages demonstrate that\nour proposed LoRA-Whisper yields a relative gain of 18.5% and 23.0% over the\nbaseline system for multilingual ASR and language expansion respectively.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, 2 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2406.06619v1",
    "published_date": "2024-06-07 08:01:51 UTC",
    "updated_date": "2024-06-07 08:01:51 UTC"
  },
  {
    "arxiv_id": "2406.04713v1",
    "title": "FlowMM: Generating Materials with Riemannian Flow Matching",
    "authors": [
      "Benjamin Kurt Miller",
      "Ricky T. Q. Chen",
      "Anuroop Sriram",
      "Brandon M Wood"
    ],
    "abstract": "Crystalline materials are a fundamental component in next-generation\ntechnologies, yet modeling their distribution presents unique computational\nchallenges. Of the plausible arrangements of atoms in a periodic lattice only a\nvanishingly small percentage are thermodynamically stable, which is a key\nindicator of the materials that can be experimentally realized. Two fundamental\ntasks in this area are to (a) predict the stable crystal structure of a known\ncomposition of elements and (b) propose novel compositions along with their\nstable structures. We present FlowMM, a pair of generative models that achieve\nstate-of-the-art performance on both tasks while being more efficient and more\nflexible than competing methods. We generalize Riemannian Flow Matching to suit\nthe symmetries inherent to crystals: translation, rotation, permutation, and\nperiodic boundary conditions. Our framework enables the freedom to choose the\nflow base distributions, drastically simplifying the problem of learning\ncrystal structures compared with diffusion models. In addition to standard\nbenchmarks, we validate FlowMM's generated structures with quantum chemistry\ncalculations, demonstrating that it is about 3x more efficient, in terms of\nintegration steps, at finding stable materials compared to previous open\nmethods.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.comp-ph",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "https://github.com/facebookresearch/flowmm",
    "pdf_url": "http://arxiv.org/pdf/2406.04713v1",
    "published_date": "2024-06-07 07:46:23 UTC",
    "updated_date": "2024-06-07 07:46:23 UTC"
  },
  {
    "arxiv_id": "2406.04710v2",
    "title": "Morescient GAI for Software Engineering (Extended Version)",
    "authors": [
      "Marcus Kessel",
      "Colin Atkinson"
    ],
    "abstract": "The ability of Generative AI (GAI) technology to automatically check,\nsynthesize and modify software engineering artifacts promises to revolutionize\nall aspects of software engineering. Using GAI for software engineering tasks\nis consequently one of the most rapidly expanding fields of software\nengineering research, with over a hundred LLM-based code models having been\npublished since 2021. However, the overwhelming majority of existing code\nmodels share a major weakness - they are exclusively trained on the syntactic\nfacet of software, significantly lowering their trustworthiness in tasks\ndependent on software semantics. To address this problem, a new class of\n\"Morescient\" GAI is needed that is \"aware\" of (i.e., trained on) both the\nsemantic and static facets of software. This, in turn, will require a new\ngeneration of software observation platforms capable of generating large\nquantities of execution observations in a structured and readily analyzable\nway. In this paper, we present a vision and roadmap for how such \"Morescient\"\nGAI models can be engineered, evolved and disseminated according to the\nprinciples of open science.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.1; D.2.4; I.2.2; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "To appear in ACM Transactions on Software Engineering and\n  Methodology, Special Issue \"2030 Roadmap Software Engineering\"",
    "pdf_url": "http://arxiv.org/pdf/2406.04710v2",
    "published_date": "2024-06-07 07:38:33 UTC",
    "updated_date": "2024-12-03 09:51:23 UTC"
  },
  {
    "arxiv_id": "2406.06618v1",
    "title": "PANDORA: Deep graph learning based COVID-19 infection risk level forecasting",
    "authors": [
      "Shuo Yu",
      "Feng Xia",
      "Yueru Wang",
      "Shihao Li",
      "Falih Febrinanto",
      "Madhu Chetty"
    ],
    "abstract": "COVID-19 as a global pandemic causes a massive disruption to social stability\nthat threatens human life and the economy. Policymakers and all elements of\nsociety must deliver measurable actions based on the pandemic's severity to\nminimize the detrimental impact of COVID-19. A proper forecasting system is\narguably important to provide an early signal of the risk of COVID-19 infection\nso that the authorities are ready to protect the people from the worst.\nHowever, making a good forecasting model for infection risks in different\ncities or regions is not an easy task, because it has a lot of influential\nfactors that are difficult to be identified manually. To address the current\nlimitations, we propose a deep graph learning model, called PANDORA, to predict\nthe infection risks of COVID-19, by considering all essential factors and\nintegrating them into a geographical network. The framework uses geographical\nposition relations and transportation frequency as higher-order structural\nproperties formulated by higher-order network structures (i.e., network\nmotifs). Moreover, four significant node attributes (i.e., multiple features of\na particular area, including climate, medical condition, economy, and human\nmobility) are also considered. We propose three different aggregators to better\naggregate node attributes and structural features, namely, Hadamard, Summation,\nand Connection. Experimental results over real data show that PANDORA\noutperforms the baseline method with higher accuracy and faster convergence\nspeed, no matter which aggregator is chosen. We believe that PANDORA using deep\ngraph learning provides a promising approach to get superior performance in\ninfection risk level forecasting and help humans battle the COVID-19 crisis.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06618v1",
    "published_date": "2024-06-07 07:27:22 UTC",
    "updated_date": "2024-06-07 07:27:22 UTC"
  },
  {
    "arxiv_id": "2407.16887v1",
    "title": "Comprehensive AI Assessment Framework: Enhancing Educational Evaluation with Ethical AI Integration",
    "authors": [
      "Selçuk Kılınç"
    ],
    "abstract": "The integration of generative artificial intelligence (GenAI) tools into\neducation has been a game-changer for teaching and assessment practices,\nbringing new opportunities, but also novel challenges which need to be dealt\nwith. This paper presents the Comprehensive AI Assessment Framework (CAIAF), an\nevolved version of the AI Assessment Scale (AIAS) by Perkins, Furze, Roe, and\nMacVaugh, targeted toward the ethical integration of AI into educational\nassessments. This is where the CAIAF differs, as it incorporates stringent\nethical guidelines, with clear distinctions based on educational levels, and\nadvanced AI capabilities of real-time interactions and personalized assistance.\nThe framework developed herein has a very intuitive use, mainly through the use\nof a color gradient that enhances the user-friendliness of the framework.\nMethodologically, the framework has been developed through the huge support of\na thorough literature review and practical insight into the topic, becoming a\ndynamic tool to be used in different educational settings. The framework will\nensure better learning outcomes, uphold academic integrity, and promote\nresponsible use of AI, hence the need for this framework in modern educational\npractice.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4, I.2"
    ],
    "primary_category": "cs.CY",
    "comment": "13 Pages, 2 figures, 1 Framework",
    "pdf_url": "http://arxiv.org/pdf/2407.16887v1",
    "published_date": "2024-06-07 07:18:42 UTC",
    "updated_date": "2024-06-07 07:18:42 UTC"
  },
  {
    "arxiv_id": "2406.04699v1",
    "title": "Logic Synthesis with Generative Deep Neural Networks",
    "authors": [
      "Xihan Li",
      "Xing Li",
      "Lei Chen",
      "Xing Zhang",
      "Mingxuan Yuan",
      "Jun Wang"
    ],
    "abstract": "While deep learning has achieved significant success in various domains, its\napplication to logic circuit design has been limited due to complex constraints\nand strict feasibility requirement. However, a recent generative deep neural\nmodel, \"Circuit Transformer\", has shown promise in this area by enabling\nequivalence-preserving circuit transformation on a small scale. In this paper,\nwe introduce a logic synthesis rewriting operator based on the Circuit\nTransformer model, named \"ctrw\" (Circuit Transformer Rewriting), which\nincorporates the following techniques: (1) a two-stage training scheme for the\nCircuit Transformer tailored for logic synthesis, with iterative improvement of\noptimality through self-improvement training; (2) integration of the Circuit\nTransformer with state-of-the-art rewriting techniques to address scalability\nissues, allowing for guided DAG-aware rewriting. Experimental results on the\nIWLS 2023 contest benchmark demonstrate the effectiveness of our proposed\nrewriting methods.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "In IWLS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04699v1",
    "published_date": "2024-06-07 07:16:40 UTC",
    "updated_date": "2024-06-07 07:16:40 UTC"
  },
  {
    "arxiv_id": "2406.04693v1",
    "title": "LLM-Vectorizer: LLM-based Verified Loop Vectorizer",
    "authors": [
      "Jubi Taneja",
      "Avery Laird",
      "Cong Yan",
      "Madan Musuvathi",
      "Shuvendu K. Lahiri"
    ],
    "abstract": "Vectorization is a powerful optimization technique that significantly boosts\nthe performance of high performance computing applications operating on large\ndata arrays. Despite decades of research on auto-vectorization, compilers\nfrequently miss opportunities to vectorize code. On the other hand, writing\nvectorized code manually using compiler intrinsics is still a complex,\nerror-prone task that demands deep knowledge of specific architecture and\ncompilers.\n  In this paper, we evaluate the potential of large-language models (LLMs) to\ngenerate vectorized (Single Instruction Multiple Data) code from scalar\nprograms that process individual array elements. We propose a novel\nfinite-state machine multi-agents based approach that harnesses LLMs and\ntest-based feedback to generate vectorized code. Our findings indicate that\nLLMs are capable of producing high performance vectorized code with run-time\nspeedup ranging from 1.1x to 9.4x as compared to the state-of-the-art compilers\nsuch as Intel Compiler, GCC, and Clang.\n  To verify the correctness of vectorized code, we use Alive2, a leading\nbounded translation validation tool for LLVM IR. We describe a few\ndomain-specific techniques to improve the scalability of Alive2 on our\nbenchmark dataset. Overall, our approach is able to verify 38.2% of\nvectorizations as correct on the TSVC benchmark dataset.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04693v1",
    "published_date": "2024-06-07 07:04:26 UTC",
    "updated_date": "2024-06-07 07:04:26 UTC"
  },
  {
    "arxiv_id": "2406.06616v1",
    "title": "Transforming Dental Diagnostics with Artificial Intelligence: Advanced Integration of ChatGPT and Large Language Models for Patient Care",
    "authors": [
      "Masoumeh Farhadi Nia",
      "Mohsen Ahmadi",
      "Elyas Irankhah"
    ],
    "abstract": "Artificial intelligence has dramatically reshaped our interaction with\ndigital technologies, ushering in an era where advancements in AI algorithms\nand Large Language Models (LLMs) have natural language processing (NLP) systems\nlike ChatGPT. This study delves into the impact of cutting-edge LLMs, notably\nOpenAI's ChatGPT, on medical diagnostics, with a keen focus on the dental\nsector. Leveraging publicly accessible datasets, these models augment the\ndiagnostic capabilities of medical professionals, streamline communication\nbetween patients and healthcare providers, and enhance the efficiency of\nclinical procedures. The advent of ChatGPT-4 is poised to make substantial\ninroads into dental practices, especially in the realm of oral surgery. This\npaper sheds light on the current landscape and explores potential future\nresearch directions in the burgeoning field of LLMs, offering valuable insights\nfor both practitioners and developers. Furthermore, it critically assesses the\nbroad implications and challenges within various sectors, including academia\nand healthcare, thus mapping out an overview of AI's role in transforming\ndental diagnostics for enhanced patient care.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06616v1",
    "published_date": "2024-06-07 06:44:09 UTC",
    "updated_date": "2024-06-07 06:44:09 UTC"
  },
  {
    "arxiv_id": "2406.04673v1",
    "title": "MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models",
    "authors": [
      "Sanjoy Chowdhury",
      "Sayan Nag",
      "K J Joseph",
      "Balaji Vasan Srinivasan",
      "Dinesh Manocha"
    ],
    "abstract": "Music is a universal language that can communicate emotions and feelings. It\nforms an essential part of the whole spectrum of creative media, ranging from\nmovies to social media posts. Machine learning models that can synthesize music\nare predominantly conditioned on textual descriptions of it. Inspired by how\nmusicians compose music not just from a movie script, but also through\nvisualizations, we propose MeLFusion, a model that can effectively use cues\nfrom a textual description and the corresponding image to synthesize music.\nMeLFusion is a text-to-music diffusion model with a novel \"visual synapse\",\nwhich effectively infuses the semantics from the visual modality into the\ngenerated music. To facilitate research in this area, we introduce a new\ndataset MeLBench, and propose a new evaluation metric IMSM. Our exhaustive\nexperimental evaluation suggests that adding visual information to the music\nsynthesis pipeline significantly improves the quality of generated music,\nmeasured both objectively and subjectively, with a relative gain of up to\n67.98% on the FAD score. We hope that our work will gather attention to this\npragmatic, yet relatively under-explored research area.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2024 as Highlight paper. Webpage:\n  https://schowdhury671.github.io/melfusion_cvpr2024/",
    "pdf_url": "http://arxiv.org/pdf/2406.04673v1",
    "published_date": "2024-06-07 06:38:59 UTC",
    "updated_date": "2024-06-07 06:38:59 UTC"
  },
  {
    "arxiv_id": "2406.04671v1",
    "title": "The Reasonable Person Standard for AI",
    "authors": [
      "Sunayana Rane"
    ],
    "abstract": "As AI systems are increasingly incorporated into domains where human behavior\nhas set the norm, a challenge for AI governance and AI alignment research is to\nregulate their behavior in a way that is useful and constructive for society.\nOne way to answer this question is to ask: how do we govern the human behavior\nthat the models are emulating? To evaluate human behavior, the American legal\nsystem often uses the \"Reasonable Person Standard.\" The idea of \"reasonable\"\nbehavior comes up in nearly every area of law. The legal system often judges\nthe actions of parties with respect to what a reasonable person would have done\nunder similar circumstances. This paper argues that the reasonable person\nstandard provides useful guidelines for the type of behavior we should develop,\nprobe, and stress-test in models. It explains how reasonableness is defined and\nused in key areas of the law using illustrative cases, how the reasonable\nperson standard could apply to AI behavior in each of these areas and contexts,\nand how our societal understanding of \"reasonable\" behavior provides useful\ntechnical goals for AI researchers.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04671v1",
    "published_date": "2024-06-07 06:35:54 UTC",
    "updated_date": "2024-06-07 06:35:54 UTC"
  },
  {
    "arxiv_id": "2406.04670v1",
    "title": "MATTER: Memory-Augmented Transformer Using Heterogeneous Knowledge Sources",
    "authors": [
      "Dongkyu Lee",
      "Chandana Satya Prakash",
      "Jack FitzGerald",
      "Jens Lehmann"
    ],
    "abstract": "Leveraging external knowledge is crucial for achieving high performance in\nknowledge-intensive tasks, such as question answering. The retrieve-and-read\napproach is widely adopted for integrating external knowledge into a language\nmodel. However, this approach suffers from increased computational cost and\nlatency due to the long context length, which grows proportionally with the\nnumber of retrieved knowledge. Furthermore, existing retrieval-augmented models\ntypically retrieve information from a single type of knowledge source, limiting\ntheir scalability to diverse knowledge sources with varying structures. In this\nwork, we introduce an efficient memory-augmented transformer called MATTER,\ndesigned to retrieve relevant knowledge from multiple heterogeneous knowledge\nsources. Specifically, our model retrieves and reads from both unstructured\nsources (paragraphs) and semi-structured sources (QA pairs) in the form of\nfixed-length neural memories. We demonstrate that our model outperforms\nexisting efficient retrieval-augmented models on popular QA benchmarks in terms\nof both accuracy and speed. Furthermore, MATTER achieves competitive results\ncompared to conventional read-and-retrieve models while having 100x throughput\nduring inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL2024-Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.04670v1",
    "published_date": "2024-06-07 06:35:37 UTC",
    "updated_date": "2024-06-07 06:35:37 UTC"
  },
  {
    "arxiv_id": "2407.00048v1",
    "title": "Ensemble Method for System Failure Detection Using Large-Scale Telemetry Data",
    "authors": [
      "Priyanka Mudgal",
      "Rita H. Wouhaybi"
    ],
    "abstract": "The growing reliance on computer systems, particularly personal computers\n(PCs), necessitates heightened reliability to uphold user satisfaction. This\nresearch paper presents an in-depth analysis of extensive system telemetry\ndata, proposing an ensemble methodology for detecting system failures. Our\napproach entails scrutinizing various parameters of system metrics,\nencompassing CPU utilization, memory utilization, disk activity, CPU\ntemperature, and pertinent system metadata such as system age, usage patterns,\ncore count, and processor type. The proposed ensemble technique integrates a\ndiverse set of algorithms, including Long Short-Term Memory (LSTM) networks,\nisolation forests, one-class support vector machines (OCSVM), and local outlier\nfactors (LOF), to effectively discern system failures. Specifically, the LSTM\nnetwork with other machine learning techniques is trained on Intel Computing\nImprovement Program (ICIP) telemetry software data to distinguish between\nnormal and failed system patterns. Experimental evaluations demonstrate the\nremarkable efficacy of our models, achieving a notable detection rate in\nidentifying system failures. Our research contributes to advancing the field of\nsystem reliability and offers practical insights for enhancing user experience\nin computing environments.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted at IEEE-IAICT-24. Copyright is held by IEEE",
    "pdf_url": "http://arxiv.org/pdf/2407.00048v1",
    "published_date": "2024-06-07 06:35:17 UTC",
    "updated_date": "2024-06-07 06:35:17 UTC"
  },
  {
    "arxiv_id": "2406.04658v3",
    "title": "Advanced Payment Security System:XGBoost, LightGBM and SMOTE Integrated",
    "authors": [
      "Qi Zheng",
      "Chang Yu",
      "Jin Cao",
      "Yongshun Xu",
      "Qianwen Xing",
      "Yinxin Jin"
    ],
    "abstract": "With the rise of various online and mobile payment systems, transaction fraud\nhas become a significant threat to financial security. This study explores the\napplication of advanced machine learning models, specifically based on XGBoost\nand LightGBM, for developing a more accurate and robust Payment Security\nProtection Model. To enhance data reliability, we meticulously processed the\ndata sources and applied SMOTE (Synthetic Minority Over-sampling Technique) to\naddress class imbalance and improve data representation. By selecting highly\ncorrelated features, we aimed to strengthen the training process and boost\nmodel performance. We conducted thorough performance evaluations of our\nproposed models, comparing them against traditional methods including Random\nForest, Neural Network, and Logistic Regression. Using metrics such as\nPrecision, Recall, and F1 Score, we rigorously assessed their effectiveness.\nOur detailed analyses and comparisons reveal that the combination of SMOTE with\nXGBoost and LightGBM offers a highly efficient and powerful mechanism for\npayment security protection. Moreover, the integration of XGBoost and LightGBM\nin a Local Ensemble model further demonstrated outstanding performance. After\nincorporating SMOTE, the new combined model achieved a significant improvement\nof nearly 6\\% over traditional models and around 5\\% over its sub-models,\nshowcasing remarkable results.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper is received by https://ieee-metacom.org",
    "pdf_url": "http://arxiv.org/pdf/2406.04658v3",
    "published_date": "2024-06-07 05:56:43 UTC",
    "updated_date": "2024-11-12 16:44:20 UTC"
  },
  {
    "arxiv_id": "2406.04657v2",
    "title": "Crafting Heavy-Tails in Weight Matrix Spectrum without Gradient Noise",
    "authors": [
      "Vignesh Kothapalli",
      "Tianyu Pang",
      "Shenyang Deng",
      "Zongmin Liu",
      "Yaoqing Yang"
    ],
    "abstract": "Training strategies for modern deep neural networks (NNs) tend to induce a\nheavy-tailed (HT) empirical spectral density (ESD) in the layer weights. While\nprevious efforts have shown that the HT phenomenon correlates with good\ngeneralization in large NNs, a theoretical explanation of its occurrence is\nstill lacking. Especially, understanding the conditions which lead to this\nphenomenon can shed light on the interplay between generalization and weight\nspectra. Our work aims to bridge this gap by presenting a simple, rich setting\nto model the emergence of HT ESD. In particular, we present a theory-informed\nanalysis for 'crafting' heavy tails in the ESD of two-layer NNs without any\ngradient noise. This is the first work to analyze a noise-free setting and\nincorporate optimizer (GD/Adam) dependent (large) learning rates into the HT\nESD analysis. Our results highlight the role of learning rates on the\nBulk+Spike and HT shape of the ESDs in the early phase of training, which can\nfacilitate generalization in the two-layer NN. These observations shed light on\nthe behavior of large-scale NNs, albeit in a much simpler setting. Last but not\nleast, we present a novel perspective on the ESD evolution dynamics by\nanalyzing the singular vectors of weight matrices and optimizer updates.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "34 pages, 32 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.04657v2",
    "published_date": "2024-06-07 05:51:57 UTC",
    "updated_date": "2024-10-02 08:10:29 UTC"
  },
  {
    "arxiv_id": "2406.04639v1",
    "title": "Cooperative Meta-Learning with Gradient Augmentation",
    "authors": [
      "Jongyun Shin",
      "Seunjin Han",
      "Jangho Kim"
    ],
    "abstract": "Model agnostic meta-learning (MAML) is one of the most widely used\ngradient-based meta-learning, consisting of two optimization loops: an inner\nloop and outer loop. MAML learns the new task from meta-initialization\nparameters with an inner update and finds the meta-initialization parameters in\nthe outer loop. In general, the injection of noise into the gradient of the\nmodel for augmenting the gradient is one of the widely used regularization\nmethods. In this work, we propose a novel cooperative meta-learning framework\ndubbed CML which leverages gradient-level regularization with gradient\naugmentation. We inject learnable noise into the gradient of the model for the\nmodel generalization. The key idea of CML is introducing the co-learner which\nhas no inner update but the outer loop update to augment gradients for finding\nbetter meta-initialization parameters. Since the co-learner does not update in\nthe inner loop, it can be easily deleted after meta-training. Therefore, CML\ninfers with only meta-learner without additional cost and performance\ndegradation. We demonstrate that CML is easily applicable to gradient-based\nmeta-learning methods and CML leads to increased performance in few-shot\nregression, few-shot image classification and few-shot node classification\ntasks. Our codes are at https://github.com/JJongyn/CML.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to UAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04639v1",
    "published_date": "2024-06-07 04:54:00 UTC",
    "updated_date": "2024-06-07 04:54:00 UTC"
  },
  {
    "arxiv_id": "2406.04635v1",
    "title": "Scaling Automatic Extraction of Pseudocode",
    "authors": [
      "Levent Toksoz",
      "Gang Tan",
      "C. Lee Giles"
    ],
    "abstract": "Pseudocode in a scholarly paper provides a concise way to express the\nalgorithms implemented therein. Pseudocode can also be thought of as an\nintermediary representation that helps bridge the gap between programming\nlanguages and natural languages. Having access to a large collection of\npseudocode can provide various benefits ranging from enhancing algorithmic\nunderstanding, facilitating further algorithmic design, to empowering NLP or\ncomputer vision based models for tasks such as automated code generation and\noptical character recognition (OCR). We have created a large pseudocode\ncollection by extracting nearly 320,000 pseudocode examples from arXiv papers.\nThis process involved scanning over $2.2$ million scholarly papers, with 1,000\nof them being manually inspected and labeled. Our approach encompasses an\nextraction mechanism tailored to optimize the coverage and a validation\nmechanism based on random sampling to check its accuracy and reliability, given\nthe inherent heterogeneity of the collection. In addition, we offer insights\ninto common pseudocode structures, supported by clustering and statistical\nanalyses. Notably, these analyses indicate an exponential-like growth in the\nusage of pseudocodes, highlighting their increasing significance.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04635v1",
    "published_date": "2024-06-07 04:39:17 UTC",
    "updated_date": "2024-06-07 04:39:17 UTC"
  },
  {
    "arxiv_id": "2406.04627v1",
    "title": "Denoising-Aware Contrastive Learning for Noisy Time Series",
    "authors": [
      "Shuang Zhou",
      "Daochen Zha",
      "Xiao Shen",
      "Xiao Huang",
      "Rui Zhang",
      "Fu-Lai Chung"
    ],
    "abstract": "Time series self-supervised learning (SSL) aims to exploit unlabeled data for\npre-training to mitigate the reliance on labels. Despite the great success in\nrecent years, there is limited discussion on the potential noise in the time\nseries, which can severely impair the performance of existing SSL methods. To\nmitigate the noise, the de facto strategy is to apply conventional denoising\nmethods before model training. However, this pre-processing approach may not\nfully eliminate the effect of noise in SSL for two reasons: (i) the diverse\ntypes of noise in time series make it difficult to automatically determine\nsuitable denoising methods; (ii) noise can be amplified after mapping raw data\ninto latent space. In this paper, we propose denoising-aware contrastive\nlearning (DECL), which uses contrastive learning objectives to mitigate the\nnoise in the representation and automatically selects suitable denoising\nmethods for every sample. Extensive experiments on various datasets verify the\neffectiveness of our method. The code is open-sourced.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to 33rd International Joint Conference on Artificial\n  Intelligence (IJCAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.04627v1",
    "published_date": "2024-06-07 04:27:32 UTC",
    "updated_date": "2024-06-07 04:27:32 UTC"
  },
  {
    "arxiv_id": "2406.06615v2",
    "title": "Language Guided Skill Discovery",
    "authors": [
      "Seungeun Rho",
      "Laura Smith",
      "Tianyu Li",
      "Sergey Levine",
      "Xue Bin Peng",
      "Sehoon Ha"
    ],
    "abstract": "Skill discovery methods enable agents to learn diverse emergent behaviors\nwithout explicit rewards. To make learned skills useful for unknown downstream\ntasks, obtaining a semantically diverse repertoire of skills is essential.\nWhile some approaches introduce a discriminator to distinguish skills and\nothers aim to increase state coverage, no existing work directly addresses the\n\"semantic diversity\" of skills. We hypothesize that leveraging the semantic\nknowledge of large language models (LLMs) can lead us to improve semantic\ndiversity of resulting behaviors. In this sense, we introduce Language Guided\nSkill Discovery (LGSD), a skill discovery framework that aims to directly\nmaximize the semantic diversity between skills. LGSD takes user prompts as\ninput and outputs a set of semantically distinctive skills. The prompts serve\nas a means to constrain the search space into a semantically desired subspace,\nand the generated LLM outputs guide the agent to visit semantically diverse\nstates within the subspace. We demonstrate that LGSD enables legged robots to\nvisit different user-intended areas on a plane by simply changing the prompt.\nFurthermore, we show that language guidance aids in discovering more diverse\nskills compared to five existing skill discovery methods in robot-arm\nmanipulation environments. Lastly, LGSD provides a simple way of utilizing\nlearned skills via natural language.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06615v2",
    "published_date": "2024-06-07 04:25:38 UTC",
    "updated_date": "2025-03-01 03:07:31 UTC"
  },
  {
    "arxiv_id": "2406.04625v3",
    "title": "Key-Element-Informed sLLM Tuning for Document Summarization",
    "authors": [
      "Sangwon Ryu",
      "Heejin Do",
      "Yunsu Kim",
      "Gary Geunbae Lee",
      "Jungseul Ok"
    ],
    "abstract": "Remarkable advances in large language models (LLMs) have enabled high-quality\ntext summarization. However, this capability is currently accessible only\nthrough LLMs of substantial size or proprietary LLMs with usage fees. In\nresponse, smaller-scale LLMs (sLLMs) of easy accessibility and low costs have\nbeen extensively studied, yet they often suffer from missing key information\nand entities, i.e., low relevance, in particular, when input documents are\nlong. We hence propose a key-element-informed instruction tuning for\nsummarization, so-called KEITSum, which identifies key elements in documents\nand instructs sLLM to generate summaries capturing these key elements.\nExperimental results on dialogue and news datasets demonstrate that sLLM with\nKEITSum indeed provides high-quality summarization with higher relevance and\nless hallucinations, competitive to proprietary LLM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04625v3",
    "published_date": "2024-06-07 04:19:01 UTC",
    "updated_date": "2024-11-19 12:41:04 UTC"
  },
  {
    "arxiv_id": "2406.04614v1",
    "title": "LawGPT: A Chinese Legal Knowledge-Enhanced Large Language Model",
    "authors": [
      "Zhi Zhou",
      "Jiang-Xin Shi",
      "Peng-Xiao Song",
      "Xiao-Wen Yang",
      "Yi-Xuan Jin",
      "Lan-Zhe Guo",
      "Yu-Feng Li"
    ],
    "abstract": "Large language models (LLMs), including both proprietary and open-source\nmodels, have showcased remarkable capabilities in addressing a wide range of\ndownstream tasks. Nonetheless, when it comes to practical Chinese legal tasks,\nthese models fail to meet the actual requirements. Proprietary models do not\nensure data privacy for sensitive legal cases, while open-source models\ndemonstrate unsatisfactory performance due to their lack of legal knowledge. To\naddress this problem, we introduce LawGPT, the first open-source model\nspecifically designed for Chinese legal applications. LawGPT comprises two key\ncomponents: legal-oriented pre-training and legal supervised fine-tuning.\nSpecifically, we employ large-scale Chinese legal documents for legal-oriented\npre-training to incorporate legal domain knowledge. To further improve the\nmodel's performance on downstream legal tasks, we create a knowledge-driven\ninstruction dataset for legal supervised fine-tuning. Our experimental results\ndemonstrate that LawGPT outperforms the open-source LLaMA 7B model. Our code\nand resources are publicly available at https://github.com/pengxiao-song/LaWGPT\nand have received 5.7K stars on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2406.04614v1",
    "published_date": "2024-06-07 03:52:56 UTC",
    "updated_date": "2024-06-07 03:52:56 UTC"
  },
  {
    "arxiv_id": "2406.04612v2",
    "title": "Faithful and Accurate Self-Attention Attribution for Message Passing Neural Networks via the Computation Tree Viewpoint",
    "authors": [
      "Yong-Min Shin",
      "Siqing Li",
      "Xin Cao",
      "Won-Yong Shin"
    ],
    "abstract": "The self-attention mechanism has been adopted in various popular message\npassing neural networks (MPNNs), enabling the model to adaptively control the\namount of information that flows along the edges of the underlying graph. Such\nattention-based MPNNs (Att-GNNs) have also been used as a baseline for multiple\nstudies on explainable AI (XAI) since attention has steadily been seen as\nnatural model interpretations, while being a viewpoint that has already been\npopularized in other domains (e.g., natural language processing and computer\nvision). However, existing studies often use naive calculations to derive\nattribution scores from attention, undermining the potential of attention as\ninterpretations for Att-GNNs. In our study, we aim to fill the gap between the\nwidespread usage of Att-GNNs and their potential explainability via attention.\nTo this end, we propose GATT, edge attribution calculation method for\nself-attention MPNNs based on the computation tree, a rooted tree that reflects\nthe computation process of the underlying model. Despite its simplicity, we\nempirically demonstrate the effectiveness of GATT in three aspects of model\nexplanation: faithfulness, explanation accuracy, and case studies by using both\nsynthetic and real-world benchmark datasets. In all cases, the results\ndemonstrate that GATT greatly improves edge attribution scores, especially\ncompared to the previous naive approach. Our code is available at\nhttps://github.com/jordan7186/GAtt.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "cs.NE",
      "cs.SI",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 14 figures, 17 tables; an extended version of our paper to\n  be presented at the 39th AAAI Conference on Artificial Intelligence (AAAI-25)\n  (Please cite our conference version.)",
    "pdf_url": "http://arxiv.org/pdf/2406.04612v2",
    "published_date": "2024-06-07 03:40:15 UTC",
    "updated_date": "2024-12-20 11:17:45 UTC"
  },
  {
    "arxiv_id": "2406.04609v2",
    "title": "Diverse Intra- and Inter-Domain Activity Style Fusion for Cross-Person Generalization in Activity Recognition",
    "authors": [
      "Junru Zhang",
      "Lang Feng",
      "Zhidan Liu",
      "Yuhan Wu",
      "Yang He",
      "Yabo Dong",
      "Duanqing Xu"
    ],
    "abstract": "Existing domain generalization (DG) methods for cross-person generalization\ntasks often face challenges in capturing intra- and inter-domain style\ndiversity, resulting in domain gaps with the target domain. In this study, we\nexplore a novel perspective to tackle this problem, a process conceptualized as\ndomain padding. This proposal aims to enrich the domain diversity by\nsynthesizing intra- and inter-domain style data while maintaining robustness to\nclass labels. We instantiate this concept using a conditional diffusion model\nand introduce a style-fused sampling strategy to enhance data generation\ndiversity. In contrast to traditional condition-guided sampling, our\nstyle-fused sampling strategy allows for the flexible use of one or more random\nstyles to guide data synthesis. This feature presents a notable advancement: it\nallows for the maximum utilization of possible permutations and combinations\namong existing styles to generate a broad spectrum of new style instances.\nEmpirical evaluations on a broad range of datasets demonstrate that our\ngenerated data achieves remarkable diversity within the domain space. Both\nintra- and inter-domain generated data have proven to be significant and\nvaluable, contributing to varying degrees of performance enhancements. Notably,\nour approach outperforms state-of-the-art DG methods in all human activity\nrecognition tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n  (KDD 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.04609v2",
    "published_date": "2024-06-07 03:37:30 UTC",
    "updated_date": "2024-06-29 03:15:51 UTC"
  },
  {
    "arxiv_id": "2406.04607v4",
    "title": "MeGA: Merging Multiple Independently Trained Neural Networks Based on Genetic Algorithm",
    "authors": [
      "Daniel Yun"
    ],
    "abstract": "In this paper, we introduce a novel method for merging the weights of\nmultiple pre-trained neural networks using a genetic algorithm called MeGA.\nTraditional techniques, such as weight averaging and ensemble methods, often\nfail to fully harness the capabilities of pre-trained networks. Our approach\nleverages a genetic algorithm with tournament selection, crossover, and\nmutation to optimize weight combinations, creating a more effective fusion.\nThis technique allows the merged model to inherit advantageous features from\nboth parent models, resulting in enhanced accuracy and robustness. Through\nexperiments on the CIFAR-10 dataset, we demonstrate that our genetic\nalgorithm-based weight merging method improves test accuracy compared to\nindividual models and conventional methods. This approach provides a scalable\nsolution for integrating multiple pre-trained networks across various deep\nlearning applications. Github is available at:\nhttps://github.com/YUNBLAK/MeGA-Merging-Multiple-Independently-Trained-Neural-Networks-Based-on-Genetic-Algorithm",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04607v4",
    "published_date": "2024-06-07 03:31:58 UTC",
    "updated_date": "2024-06-28 03:53:21 UTC"
  },
  {
    "arxiv_id": "2406.04606v1",
    "title": "Helpful or Harmful Data? Fine-tuning-free Shapley Attribution for Explaining Language Model Predictions",
    "authors": [
      "Jingtan Wang",
      "Xiaoqiang Lin",
      "Rui Qiao",
      "Chuan-Sheng Foo",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "The increasing complexity of foundational models underscores the necessity\nfor explainability, particularly for fine-tuning, the most widely used training\nmethod for adapting models to downstream tasks. Instance attribution, one type\nof explanation, attributes the model prediction to each training example by an\ninstance score. However, the robustness of instance scores, specifically\ntowards dataset resampling, has been overlooked. To bridge this gap, we propose\na notion of robustness on the sign of the instance score. We theoretically and\nempirically demonstrate that the popular leave-one-out-based methods lack\nrobustness, while the Shapley value behaves significantly better, but at a\nhigher computational cost. Accordingly, we introduce an efficient\nfine-tuning-free approximation of the Shapley value (FreeShap) for instance\nattribution based on the neural tangent kernel. We empirically demonstrate that\nFreeShap outperforms other methods for instance attribution and other\ndata-centric applications such as data removal, data selection, and wrong label\ndetection, and further generalize our scale to large language models (LLMs).\nOur code is available at https://github.com/JTWang2000/FreeShap.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04606v1",
    "published_date": "2024-06-07 03:29:57 UTC",
    "updated_date": "2024-06-07 03:29:57 UTC"
  },
  {
    "arxiv_id": "2406.04598v1",
    "title": "OCDB: Revisiting Causal Discovery with a Comprehensive Benchmark and Evaluation Framework",
    "authors": [
      "Wei Zhou",
      "Hong Huang",
      "Guowen Zhang",
      "Ruize Shi",
      "Kehan Yin",
      "Yuanyuan Lin",
      "Bang Liu"
    ],
    "abstract": "Large language models (LLMs) have excelled in various natural language\nprocessing tasks, but challenges in interpretability and trustworthiness\npersist, limiting their use in high-stakes fields. Causal discovery offers a\npromising approach to improve transparency and reliability. However, current\nevaluations are often one-sided and lack assessments focused on\ninterpretability performance. Additionally, these evaluations rely on synthetic\ndata and lack comprehensive assessments of real-world datasets. These lead to\npromising methods potentially being overlooked. To address these issues, we\npropose a flexible evaluation framework with metrics for evaluating differences\nin causal structures and causal effects, which are crucial attributes that help\nimprove the interpretability of LLMs. We introduce the Open Causal Discovery\nBenchmark (OCDB), based on real data, to promote fair comparisons and drive\noptimization of algorithms. Additionally, our new metrics account for\nundirected edges, enabling fair comparisons between Directed Acyclic Graphs\n(DAGs) and Completed Partially Directed Acyclic Graphs (CPDAGs). Experimental\nresults show significant shortcomings in existing algorithms' generalization\ncapabilities on real data, highlighting the potential for performance\nimprovement and the importance of our framework in advancing causal discovery\ntechniques.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04598v1",
    "published_date": "2024-06-07 03:09:22 UTC",
    "updated_date": "2024-06-07 03:09:22 UTC"
  },
  {
    "arxiv_id": "2406.04594v1",
    "title": "Boosting Large-scale Parallel Training Efficiency with C4: A Communication-Driven Approach",
    "authors": [
      "Jianbo Dong",
      "Bin Luo",
      "Jun Zhang",
      "Pengcheng Zhang",
      "Fei Feng",
      "Yikai Zhu",
      "Ang Liu",
      "Zian Chen",
      "Yi Shi",
      "Hairong Jiao",
      "Gang Lu",
      "Yu Guan",
      "Ennan Zhai",
      "Wencong Xiao",
      "Hanyu Zhao",
      "Man Yuan",
      "Siran Yang",
      "Xiang Li",
      "Jiamang Wang",
      "Rui Men",
      "Jianwei Zhang",
      "Huang Zhong",
      "Dennis Cai",
      "Yuan Xie",
      "Binzhang Fu"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has necessitated the adoption\nof parallel training techniques, involving the deployment of thousands of GPUs\nto train a single model. Unfortunately, we have found that the efficiency of\ncurrent parallel training is often suboptimal, largely due to the following two\nmain issues. Firstly, hardware failures are inevitable, leading to\ninterruptions in the training tasks. The inability to quickly identify the\nfaulty components results in a substantial waste of GPU resources. Secondly,\nsince GPUs must wait for parameter synchronization to complete before\nproceeding to the next round of computation, network congestions can greatly\nincrease the waiting time for GPUs. To address these challenges, this paper\nintroduces a communication-driven solution, namely the C4. The key insights of\nC4 are two folds. First, in parallel training, collective communication\nexhibits periodic and homogeneous characteristics, so any anomalies are\ncertainly due to some form of hardware malfunction. By leveraging this feature,\nC4 can rapidly identify the faulty components, swiftly isolate the anomaly, and\nrestart the task, thereby avoiding resource wastage caused by delays in anomaly\ndetection. Second, the predictable communication model of collective\ncommunication, involving few large flows, allows C4 to efficiently execute\ntraffic planning, substantially reducing network congestion. C4 has been\nextensively implemented across our production systems, cutting error-induced\noverhead by roughly 30% and enhancing runtime performance by about 15% for\ncertain applications with moderate communication costs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04594v1",
    "published_date": "2024-06-07 02:58:35 UTC",
    "updated_date": "2024-06-07 02:58:35 UTC"
  },
  {
    "arxiv_id": "2406.04584v1",
    "title": "CLoG: Benchmarking Continual Learning of Image Generation Models",
    "authors": [
      "Haotian Zhang",
      "Junting Zhou",
      "Haowei Lin",
      "Hang Ye",
      "Jianhua Zhu",
      "Zihao Wang",
      "Liangcai Gao",
      "Yizhou Wang",
      "Yitao Liang"
    ],
    "abstract": "Continual Learning (CL) poses a significant challenge in Artificial\nIntelligence, aiming to mirror the human ability to incrementally acquire\nknowledge and skills. While extensive research has focused on CL within the\ncontext of classification tasks, the advent of increasingly powerful generative\nmodels necessitates the exploration of Continual Learning of Generative models\n(CLoG). This paper advocates for shifting the research focus from\nclassification-based CL to CLoG. We systematically identify the unique\nchallenges presented by CLoG compared to traditional classification-based CL.\nWe adapt three types of existing CL methodologies, replay-based,\nregularization-based, and parameter-isolation-based methods to generative tasks\nand introduce comprehensive benchmarks for CLoG that feature great diversity\nand broad task coverage. Our benchmarks and results yield intriguing insights\nthat can be valuable for developing future CLoG methods. Additionally, we will\nrelease a codebase designed to facilitate easy benchmarking and experimentation\nin CLoG publicly at https://github.com/linhaowei1/CLoG. We believe that\nshifting the research focus to CLoG will benefit the continual learning\ncommunity and illuminate the path for next-generation AI-generated content\n(AIGC) in a lifelong learning paradigm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04584v1",
    "published_date": "2024-06-07 02:12:29 UTC",
    "updated_date": "2024-06-07 02:12:29 UTC"
  },
  {
    "arxiv_id": "2406.04575v1",
    "title": "Optimization of geological carbon storage operations with multimodal latent dynamic model and deep reinforcement learning",
    "authors": [
      "Zhongzheng Wang",
      "Yuntian Chen",
      "Guodong Chen",
      "Dongxiao Zhang"
    ],
    "abstract": "Maximizing storage performance in geological carbon storage (GCS) is crucial\nfor commercial deployment, but traditional optimization demands\nresource-intensive simulations, posing computational challenges. This study\nintroduces the multimodal latent dynamic (MLD) model, a deep learning framework\nfor fast flow prediction and well control optimization in GCS. The MLD model\nincludes a representation module for compressed latent representations, a\ntransition module for system state evolution, and a prediction module for flow\nresponses. A novel training strategy combining regression loss and\njoint-embedding consistency loss enhances temporal consistency and multi-step\nprediction accuracy. Unlike existing models, the MLD supports diverse input\nmodalities, allowing comprehensive data interactions. The MLD model, resembling\na Markov decision process (MDP), can train deep reinforcement learning agents,\nspecifically using the soft actor-critic (SAC) algorithm, to maximize net\npresent value (NPV) through continuous interactions. The approach outperforms\ntraditional methods, achieving the highest NPV while reducing computational\nresources by over 60%. It also demonstrates strong generalization performance,\nproviding improved decisions for new scenarios based on knowledge from previous\nones.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04575v1",
    "published_date": "2024-06-07 01:30:21 UTC",
    "updated_date": "2024-06-07 01:30:21 UTC"
  },
  {
    "arxiv_id": "2406.04568v1",
    "title": "StackSight: Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation",
    "authors": [
      "Weike Fang",
      "Zhejian Zhou",
      "Junzhou He",
      "Weihang Wang"
    ],
    "abstract": "WebAssembly enables near-native execution in web applications and is\nincreasingly adopted for tasks that demand high performance and robust\nsecurity. However, its assembly-like syntax, implicit stack machine, and\nlow-level data types make it extremely difficult for human developers to\nunderstand, spurring the need for effective WebAssembly reverse engineering\ntechniques. In this paper, we propose StackSight, a novel neurosymbolic\napproach that combines Large Language Models (LLMs) with advanced program\nanalysis to decompile complex WebAssembly code into readable C++ snippets.\nStackSight visualizes and tracks virtual stack alterations via a static\nanalysis algorithm and then applies chain-of-thought prompting to harness LLM's\ncomplex reasoning capabilities. Evaluation results show that StackSight\nsignificantly improves WebAssembly decompilation. Our user study also\ndemonstrates that code snippets generated by StackSight have significantly\nhigher win rates and enable a better grasp of code semantics.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "9 pages. In the Proceedings of the 41st International Conference on\n  Machine Learning (ICML' 24)",
    "pdf_url": "http://arxiv.org/pdf/2406.04568v1",
    "published_date": "2024-06-07 01:08:17 UTC",
    "updated_date": "2024-06-07 01:08:17 UTC"
  },
  {
    "arxiv_id": "2406.04566v1",
    "title": "SpaRC and SpaRP: Spatial Reasoning Characterization and Path Generation for Understanding Spatial Reasoning Capability of Large Language Models",
    "authors": [
      "Md Imbesat Hassan Rizvi",
      "Xiaodan Zhu",
      "Iryna Gurevych"
    ],
    "abstract": "Spatial reasoning is a crucial component of both biological and artificial\nintelligence. In this work, we present a comprehensive study of the capability\nof current state-of-the-art large language models (LLMs) on spatial reasoning.\nTo support our study, we created and contribute a novel Spatial Reasoning\nCharacterization (SpaRC) framework and Spatial Reasoning Paths (SpaRP)\ndatasets, to enable an in-depth understanding of the spatial relations and\ncompositions as well as the usefulness of spatial reasoning chains. We found\nthat all the state-of-the-art LLMs do not perform well on the datasets -- their\nperformances are consistently low across different setups. The spatial\nreasoning capability improves substantially as model sizes scale up. Finetuning\nboth large language models (e.g., Llama-2-70B) and smaller ones (e.g.,\nLlama-2-13B) can significantly improve their F1-scores by 7--32 absolute\npoints. We also found that the top proprietary LLMs still significantly\noutperform their open-source counterparts in topological spatial understanding\nand reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024 (Main)",
    "pdf_url": "http://arxiv.org/pdf/2406.04566v1",
    "published_date": "2024-06-07 01:06:34 UTC",
    "updated_date": "2024-06-07 01:06:34 UTC"
  },
  {
    "arxiv_id": "2406.06613v2",
    "title": "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents",
    "authors": [
      "Anthony Costarelli",
      "Mat Allen",
      "Roman Hauksson",
      "Grace Sodunke",
      "Suhas Hariharan",
      "Carlson Cheng",
      "Wenjie Li",
      "Joshua Clymer",
      "Arjun Yadav"
    ],
    "abstract": "Large language models have demonstrated remarkable few-shot performance on\nmany natural language understanding tasks. Despite several demonstrations of\nusing large language models in complex, strategic scenarios, there lacks a\ncomprehensive framework for evaluating agents' performance across various types\nof reasoning found in games. To address this gap, we introduce GameBench, a\ncross-domain benchmark for evaluating strategic reasoning abilities of LLM\nagents. We focus on 9 different game environments, where each covers at least\none axis of key reasoning skill identified in strategy games, and select games\nfor which strategy explanations are unlikely to form a significant portion of\nmodels' pretraining corpuses. Our evaluations use GPT-3 and GPT-4 in their base\nform along with two scaffolding frameworks designed to enhance strategic\nreasoning ability: Chain-of-Thought (CoT) prompting and Reasoning Via Planning\n(RAP). Our results show that none of the tested models match human performance,\nand at worst GPT-4 performs worse than random action. CoT and RAP both improve\nscores but not comparable to human levels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06613v2",
    "published_date": "2024-06-07 00:28:43 UTC",
    "updated_date": "2024-07-22 14:32:33 UTC"
  },
  {
    "arxiv_id": "2406.04555v1",
    "title": "Creating an AI Observer: Generative Semantic Workspaces",
    "authors": [
      "Pavan Holur",
      "Shreyas Rajesh",
      "David Chong",
      "Vwani Roychowdhury"
    ],
    "abstract": "An experienced human Observer reading a document -- such as a crime report --\ncreates a succinct plot-like $\\textit{``Working Memory''}$ comprising different\nactors, their prototypical roles and states at any point, their evolution over\ntime based on their interactions, and even a map of missing Semantic parts\nanticipating them in the future. $\\textit{An equivalent AI Observer currently\ndoes not exist}$. We introduce the $\\textbf{[G]}$enerative\n$\\textbf{[S]}$emantic $\\textbf{[W]}$orkspace (GSW) -- comprising an\n$\\textit{``Operator''}$ and a $\\textit{``Reconciler''}$ -- that leverages\nadvancements in LLMs to create a generative-style Semantic framework, as\nopposed to a traditionally predefined set of lexicon labels. Given a text\nsegment $C_n$ that describes an ongoing situation, the $\\textit{Operator}$\ninstantiates actor-centric Semantic maps (termed ``Workspace instance''\n$\\mathcal{W}_n$). The $\\textit{Reconciler}$ resolves differences between\n$\\mathcal{W}_n$ and a ``Working memory'' $\\mathcal{M}_n^*$ to generate the\nupdated $\\mathcal{M}_{n+1}^*$. GSW outperforms well-known baselines on several\ntasks ($\\sim 94\\%$ vs. FST, GLEN, BertSRL - multi-sentence Semantics\nextraction, $\\sim 15\\%$ vs. NLI-BERT, $\\sim 35\\%$ vs. QA). By mirroring the\nreal Observer, GSW provides the first step towards Spatial Computing assistants\ncapable of understanding individual intentions and predicting future behavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "37 pages with appendix, 28 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.04555v1",
    "published_date": "2024-06-07 00:09:13 UTC",
    "updated_date": "2024-06-07 00:09:13 UTC"
  }
]