{
  "date": "2024-10-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-06 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 56 篇论文，主要聚焦 AI 模型的优化、生成和应用（如 LLM 的推理能力与基准测试）、机器人故障检测，以及医疗和多模态感知领域的创新，其中 Polymath 基准测试和 Gödel Agent 框架最为令人印象深刻，后者由知名学者如 William Yang Wang 参与，展示了 LLM 在自进化中的潜力。\n\n### 重点论文亮点\n我们先聊聊几篇重要的论文，这些涉及热门话题如 LLM 推理、多模态基准和机器人可靠性，具有高话题度和实际应用潜力。\n\n- **Polymath: A Challenging Multi-modal Mathematical Reasoning Benchmark**（中文标题：多模态数学推理的挑战性基准）  \n  这篇论文提出 Polymath 基准，评估多模态大语言模型（MLLMs）在模式识别和空间推理等任务中的认知能力。通过 5000 个高质量图像数据集，实验显示 GPT-4o 等模型在复杂推理上仅达到 41% 的准确率，揭示 MLLMs 在空间关系理解上的缺陷，并通过消融实验证明模型更依赖文本而非视觉信息。主要贡献：提供了一个全面评估 MLLMs 抽象推理能力的基准，促进未来模型改进。\n\n- **Gödel Agent: A Self-Referential Agent Framework for Recursive Self-Improvement**（中文标题：哥德尔代理：用于递归自进化的自指代理框架）  \n  由知名学者 William Yang Wang 等合作，这篇工作引入 Gödel Agent 框架，允许 LLM 代理动态修改自身逻辑，实现递归自优化。实验在数学推理和代理任务中证明，该框架能超越手动设计的代理，提高效率和泛化性。主要发现：LLM 可通过提示引导实现持续自进化，这为 AI 自主学习提供了新路径。\n\n- **Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF**（中文标题：回归相对未来：多轮 RLHF 的高效策略优化）  \n  这篇论文提出 REFUEL 方法，针对多轮强化学习从人类反馈（RLHF）优化问题，使用回归任务处理协变量偏移。实验显示，REFUEL 在 Llama 模型上显著提升对话性能，甚至让小型模型超越 Llama-3.1-70B。主要贡献：提供高效、多轮 RLHF 优化框架，减少训练数据依赖，适用于复杂对话场景。\n\n- **Unpacking Failure Modes of Generative Policies: Runtime Monitoring of Consistency and Progress**（中文标题：解构生成策略的故障模式：一致性和进展的运行时监控）  \n  由 Marco Pavone 和 Jeannette Bohg 等知名学者参与，论文引入 Sentinel 框架，用于检测机器人生成策略的故障，包括不一致行为和任务进展问题。实验在模拟和真实环境中证明，Sentinel 比单一检测器多检测 18% 的故障。主要发现：结合统计一致性和视觉语言模型（VLMs）可提升机器人部署的安全性。\n\n- **MVP-Bench: Can Large Vision–Language Models Conduct Multi-level Visual Perception Like Humans?**（中文标题：多级视觉感知的基准：大视觉语言模型能否像人类一样进行多级感知？）  \n  这篇工作构建 MVP-Bench 基准，评估 LVLMs 在低级（如物体识别）和高级（如行为理解）视觉感知中的表现。实验显示，GPT-4o 在 Yes/No 任务上仅 56% 准确率，且模型在合成图像上泛化差。主要贡献：首次系统评估 LVLMs 的多级感知能力，强调视觉理解的局限性。\n\n### 其他相关论文简评\n接下来快速掠过其他论文，聚焦有代表性的主题。AI 和 LLM 相关较多，我们优先提这些。\n\n- **Graph Fourier Neural Kernels (G-FuNK): Learning Solutions of Nonlinear Diffusive Parametric PDEs on Multiple Domains**（中文标题：图傅立叶神经核：学习非线性扩散参数 PDE 的解决方案）  \n  由 Natalia Trayanova 等知名学者提出，G-FuNK 框架用于高效求解非线性 PDE，实验显示在热传导和心脏电生理学上显著加速预测。主要发现：结合图拉普拉斯和傅立叶算子提升泛化性。\n\n- **DeepLTL: Learning to Efficiently Satisfy Complex LTL Specifications for Multi-Task RL**（中文标题：DeepLTL：为多任务强化学习高效满足复杂 LTL 规范的学习方法）  \n  提出基于 Buchi 自动机的策略，零样本满足有限和无限视野规范，实验优于现有方法。主要贡献：提升多任务 RL 的规范遵守效率。\n\n- **FAMMA: A Benchmark for Financial Domain Multilingual Multimodal Question Answering**（中文标题：金融领域多语言多模态问答基准）  \n  构建金融问答基准，支持英语、中文和法语，实验显示微调模型显著改善性能。主要发现：LLMs 在金融推理上仍有挑战。\n\n机器人和感知领域有几篇值得一提：\n- **Multimodal 3D Fusion and In-Situ Learning for Spatially Aware AI**（中文标题：多模态 3D 融合和原位学习用于空间感知 AI）  \n  提出多模态 3D 表示，提升 AR 中的语义理解，应用于空间搜索。主要贡献：融合 CLIP 和几何表示。\n\n- **Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task**（中文标题：比较激进和克制 AI 推荐在真实人类-AI 协作任务中的表现）  \n  实验显示高召回 AI 提升任务效率，但可能导致负面训练效果。\n\n医疗和生成模型论文较多，但我们简略：\n- **Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection**（中文标题：多层自对比学习用于医疗微波辐射计的乳腺癌检测）  \n  提出自对比模型，提升乳腺癌诊断准确性，Matthew's 相关系数达 0.74。\n\n- **VideoGuide: Improving Video Diffusion Models without Training Through a Teacher's Guide**（中文标题：VideoGuide：通过教师引导改进视频扩散模型无需训练）  \n  无需重新训练提升视频生成的一致性，实验显示显著改善图像保真度。\n\n其他如知识图谱、图像生成等论文（如第27、38、42）虽有创新，但影响力较小，就不展开了。今天 arXiv 整体偏向 AI 应用，LLM 相关研究尤其值得关注，读者可根据兴趣优先查看这些方向！",
  "papers": [
    {
      "arxiv_id": "2410.04655v2",
      "title": "Graph Fourier Neural Kernels (G-FuNK): Learning Solutions of Nonlinear Diffusive Parametric PDEs on Multiple Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Shane E. Loeffler",
        "Zan Ahmad",
        "Syed Yusuf Ali",
        "Carolyna Yamamoto",
        "Dan M. Popescu",
        "Alana Yee",
        "Yash Lal",
        "Natalia Trayanova",
        "Mauro Maggioni"
      ],
      "abstract": "Predicting time-dependent dynamics of complex systems governed by non-linear\npartial differential equations (PDEs) with varying parameters and domains is a\nchallenging task motivated by applications across various fields. We introduce\na novel family of neural operators based on our Graph Fourier Neural Kernels,\ndesigned to learn solution generators for nonlinear PDEs in which the\nhighest-order term is diffusive, across multiple domains and parameters. G-FuNK\ncombines components that are parameter- and domain-adapted with others that are\nnot. The domain-adapted components are constructed using a weighted graph on\nthe discretized domain, where the graph Laplacian approximates the\nhighest-order diffusive term, ensuring boundary condition compliance and\ncapturing the parameter and domain-specific behavior. Meanwhile, the learned\ncomponents transfer across domains and parameters using our variant Fourier\nNeural Operators. This approach naturally embeds geometric and directional\ninformation, improving generalization to new test domains without need for\nretraining the network. To handle temporal dynamics, our method incorporates an\nintegrated ODE solver to predict the evolution of the system. Experiments show\nG-FuNK's capability to accurately approximate heat, reaction diffusion, and\ncardiac electrophysiology equations across various geometries and anisotropic\ndiffusivity fields. G-FuNK achieves low relative errors on unseen domains and\nfiber fields, significantly accelerating predictions compared to traditional\nfinite-element solvers.",
      "tldr_zh": "本文提出 Graph Fourier Neural Kernels (G-FuNK)，一种新型神经算子，用于学习非线性扩散型偏微分方程 (PDEs) 的解决方案，支持多个域和参数变化。G-FuNK 结合了基于加权图的域适配组件（利用 Graph Laplacian 近似最高阶扩散项以确保边界条件遵守）和可转移的 Fourier Neural Operators 组件，实现几何和方向信息的嵌入，提高泛化能力无需重新训练。方法还整合 ODE 求解器来处理系统的时间动态。实验结果显示，G-FuNK 在热方程、反应扩散方程和心脏电生理方程上表现出色，在未见域和各向异性扩散场中实现低相对误差，并显著加速预测，优于传统有限元求解器。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.SP",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04655v2",
      "published_date": "2024-10-06 23:55:34 UTC",
      "updated_date": "2024-10-09 13:46:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:41:16.383029"
    },
    {
      "arxiv_id": "2410.04652v1",
      "title": "Multimodal 3D Fusion and In-Situ Learning for Spatially Aware AI",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyuan Xu",
        "Radha Kumaran",
        "Noah Stier",
        "Kangyou Yu",
        "Tobias Höllerer"
      ],
      "abstract": "Seamless integration of virtual and physical worlds in augmented reality\nbenefits from the system semantically \"understanding\" the physical environment.\nAR research has long focused on the potential of context awareness,\ndemonstrating novel capabilities that leverage the semantics in the 3D\nenvironment for various object-level interactions. Meanwhile, the computer\nvision community has made leaps in neural vision-language understanding to\nenhance environment perception for autonomous tasks. In this work, we introduce\na multimodal 3D object representation that unifies both semantic and linguistic\nknowledge with the geometric representation, enabling user-guided machine\nlearning involving physical objects. We first present a fast multimodal 3D\nreconstruction pipeline that brings linguistic understanding to AR by fusing\nCLIP vision-language features into the environment and object models. We then\npropose \"in-situ\" machine learning, which, in conjunction with the multimodal\nrepresentation, enables new tools and interfaces for users to interact with\nphysical spaces and objects in a spatially and linguistically meaningful\nmanner. We demonstrate the usefulness of the proposed system through two\nreal-world AR applications on Magic Leap 2: a) spatial search in physical\nenvironments with natural language and b) an intelligent inventory system that\ntracks object changes over time. We also make our full implementation and demo\ndata available at (https://github.com/cy-xu/spatially_aware_AI) to encourage\nfurther exploration and research in spatially aware AI.",
      "tldr_zh": "这篇论文提出了Multimodal 3D Fusion和In-Situ Learning框架，用于构建空间感知AI系统，通过统一语义、语言和几何知识的多模态3D对象表示，提升增强现实(AR)对物理环境的理解。该方法包括一个快速多模态3D重建管道，将CLIP的视觉-语言特征融合到环境和对象模型中，并引入In-Situ机器学习，允许用户以空间和语言上有意义的方式互动。作者在Magic Leap 2上演示了两个实际应用：自然语言驱动的空间搜索和智能库存系统跟踪对象变化，并开源了代码以推动相关研究。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "I.4.8; H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 6 figures, accepted to IEEE ISMAR 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04652v1",
      "published_date": "2024-10-06 23:25:21 UTC",
      "updated_date": "2024-10-06 23:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:41:26.845619"
    },
    {
      "arxiv_id": "2410.11860v1",
      "title": "Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyuan Xu",
        "Kuo-Chin Lien",
        "Tobias Höllerer"
      ],
      "abstract": "When designing an AI-assisted decision-making system, there is often a\ntradeoff between precision and recall in the AI's recommendations. We argue\nthat careful exploitation of this tradeoff can harness the complementary\nstrengths in the human-AI collaboration to significantly improve team\nperformance. We investigate a real-world video anonymization task for which\nrecall is paramount and more costly to improve. We analyze the performance of\n78 professional annotators working with a) no AI assistance, b) a\nhigh-precision \"restrained\" AI, and c) a high-recall \"zealous\" AI in over 3,466\nperson-hours of annotation work. In comparison, the zealous AI helps human\nteammates achieve significantly shorter task completion time and higher recall.\nIn a follow-up study, we remove AI assistance for everyone and find negative\ntraining effects on annotators trained with the restrained AI. These findings\nand our analysis point to important implications for the design of AI\nassistance in recall-demanding scenarios.",
      "tldr_zh": "这篇论文比较了在人类-AI协作任务中，zealous AI（高召回率）和restrained AI（高精确率）的推荐策略，旨在利用二者权衡提升团队性能。\n研究者通过一个真实的视频匿名化任务，分析了78名专业标注者在无AI辅助、高精确率AI和高召回率AI三种条件下超过3466人小时的性能表现。\n结果显示，zealous AI显著缩短了任务完成时间并提高了召回率，而使用restrained AI的标注者在后续无AI辅助时出现了负面训练效果。\n这些发现为设计AI辅助系统在召回率要求高的场景提供了重要指导。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "H.5.0; I.2.0"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages, 14 figures, accepted to ACM CHI 2023",
      "pdf_url": "http://arxiv.org/pdf/2410.11860v1",
      "published_date": "2024-10-06 23:19:19 UTC",
      "updated_date": "2024-10-06 23:19:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:41:40.319794"
    },
    {
      "arxiv_id": "2410.04640v2",
      "title": "Unpacking Failure Modes of Generative Policies: Runtime Monitoring of Consistency and Progress",
      "title_zh": "剖析生成策略的失败模式：一致性和进展的运行时监控",
      "authors": [
        "Christopher Agia",
        "Rohan Sinha",
        "Jingyun Yang",
        "Zi-ang Cao",
        "Rika Antonova",
        "Marco Pavone",
        "Jeannette Bohg"
      ],
      "abstract": "Robot behavior policies trained via imitation learning are prone to failure\nunder conditions that deviate from their training data. Thus, algorithms that\nmonitor learned policies at test time and provide early warnings of failure are\nnecessary to facilitate scalable deployment. We propose Sentinel, a runtime\nmonitoring framework that splits the detection of failures into two\ncomplementary categories: 1) Erratic failures, which we detect using\nstatistical measures of temporal action consistency, and 2) task progression\nfailures, where we use Vision Language Models (VLMs) to detect when the policy\nconfidently and consistently takes actions that do not solve the task. Our\napproach has two key strengths. First, because learned policies exhibit diverse\nfailure modes, combining complementary detectors leads to significantly higher\naccuracy at failure detection. Second, using a statistical temporal action\nconsistency measure ensures that we quickly detect when multimodal, generative\npolicies exhibit erratic behavior at negligible computational cost. In\ncontrast, we only use VLMs to detect failure modes that are less\ntime-sensitive. We demonstrate our approach in the context of diffusion\npolicies trained on robotic mobile manipulation domains in both simulation and\nthe real world. By unifying temporal consistency detection and VLM runtime\nmonitoring, Sentinel detects 18% more failures than using either of the two\ndetectors alone and significantly outperforms baselines, thus highlighting the\nimportance of assigning specialized detectors to complementary categories of\nfailure. Qualitative results are made available at\nhttps://sites.google.com/stanford.edu/sentinel.",
      "tldr_zh": "这篇论文提出 Sentinel 框架，用于运行时监控模仿学习训练的生成策略（generative policies），以检测机器人行为在偏离训练数据的条件下的失败模式。Sentinel 将失败分为两类：Erratic failures（通过统计措施评估临时动作一致性）和 Task progression failures（使用 Vision Language Models (VLMs) 检测策略自信但不解决任务的动作），从而结合互补检测器显著提高准确率。实验在模拟和真实世界的 diffusion policies 机器人移动操作领域中表明，Sentinel 比单独使用任一检测器多检测 18% 的失败，并优于基线方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.7; I.2.9; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "Project page: https://sites.google.com/stanford.edu/sentinel. 35\n  pages, 9 figures. Accepted to the Conference on Robot Learning (CoRL) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04640v2",
      "published_date": "2024-10-06 22:13:30 UTC",
      "updated_date": "2024-10-10 17:09:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:41:50.521809"
    },
    {
      "arxiv_id": "2410.04636v2",
      "title": "Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Christoforos Galazis",
        "Huiyi Wu",
        "Igor Goryanin"
      ],
      "abstract": "Improving breast cancer detection and monitoring techniques is a critical\nobjective in healthcare, driving the need for innovative imaging technologies\nand diagnostic approaches. This study introduces a novel multi-tiered\nself-contrastive model tailored for microwave radiometry (MWR) in breast cancer\ndetection. Our approach incorporates three distinct models: Local-MWR (L-MWR),\nRegional-MWR (R-MWR), and Global-MWR (G-MWR), designed to analyze varying\nsub-regional comparisons within the breasts. These models are integrated\nthrough the Joint-MWR (J-MWR) network, which leverages self-contrastive results\nat each analytical level to improve diagnostic accuracy. Utilizing a dataset of\n4,932 female patients, our research demonstrates the efficacy of our proposed\nmodels. Notably, the J-MWR model achieves a Matthew's correlation coefficient\nof 0.74 $\\pm$ 0.018, surpassing existing MWR neural networks and contrastive\nmethods. These findings highlight the potential of self-contrastive learning\ntechniques in improving the diagnostic accuracy and generalizability for\nMWR-based breast cancer detection. This advancement holds considerable promise\nfor future investigations into enabling point-of-care testing. The source code\nis available at: https://github.com/cgalaz01/self_contrastive_mwr.",
      "tldr_zh": "本研究提出了一种多层自对比学习模型（Multi-Tiered Self-Contrastive Learning），专门用于微波辐射测量 (MWR) 的乳腺癌检测，通过分析乳房的局部 (Local-MWR, L-MWR)、区域 (Regional-MWR, R-MWR) 和全局 (Global-MWR, G-MWR) 子区域比较，并通过 Joint-MWR (J-MWR) 网络整合这些层级的结果，以提升诊断准确性。利用包含 4,932 名女性的数据集，J-MWR 模型实现了 Matthew's 相关系数为 0.74 ± 0.018 的性能，超过了现有 MWR 神经网络和对比方法。研究结果突出了自对比学习技术在提高 MWR 基于乳腺癌检测的准确性和泛化能力方面的潜力，有望促进点-of-care 测试的应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04636v2",
      "published_date": "2024-10-06 21:51:02 UTC",
      "updated_date": "2025-01-27 12:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:42:03.213742"
    },
    {
      "arxiv_id": "2410.04631v2",
      "title": "DeepLTL: Learning to Efficiently Satisfy Complex LTL Specifications for Multi-Task RL",
      "title_zh": "翻译失败",
      "authors": [
        "Mathias Jackermeier",
        "Alessandro Abate"
      ],
      "abstract": "Linear temporal logic (LTL) has recently been adopted as a powerful formalism\nfor specifying complex, temporally extended tasks in multi-task reinforcement\nlearning (RL). However, learning policies that efficiently satisfy arbitrary\nspecifications not observed during training remains a challenging problem.\nExisting approaches suffer from several shortcomings: they are often only\napplicable to finite-horizon fragments of LTL, are restricted to suboptimal\nsolutions, and do not adequately handle safety constraints. In this work, we\npropose a novel learning approach to address these concerns. Our method\nleverages the structure of B\\\"uchi automata, which explicitly represent the\nsemantics of LTL specifications, to learn policies conditioned on sequences of\ntruth assignments that lead to satisfying the desired formulae. Experiments in\na variety of discrete and continuous domains demonstrate that our approach is\nable to zero-shot satisfy a wide range of finite- and infinite-horizon\nspecifications, and outperforms existing methods in terms of both satisfaction\nprobability and efficiency. Code available at: https://deep-ltl.github.io/",
      "tldr_zh": "这篇论文提出 DeepLTL 方法，用于在多任务强化学习 (RL) 中高效满足复杂的 LTL (Linear Temporal Logic) 规范，解决了现有方法仅适用于有限时域、子优解和无法处理安全约束等问题。方法通过利用 B\\\"uchi automata 的结构，学习基于真值序列的条件策略，实现对各种规范的零样本 (zero-shot) 满足。实验在离散和连续域中证明，该方法在满足概率和效率上均优于现有方法，并提供了代码实现 (https://deep-ltl.github.io/)。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR'25 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2410.04631v2",
      "published_date": "2024-10-06 21:30:38 UTC",
      "updated_date": "2025-03-29 11:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:42:14.055393"
    },
    {
      "arxiv_id": "2410.04620v1",
      "title": "Passage Retrieval of Polish Texts Using OKAPI BM25 and an Ensemble of Cross Encoders",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Pokrywka"
      ],
      "abstract": "Passage Retrieval has traditionally relied on lexical methods like TF-IDF and\nBM25. Recently, some neural network models have surpassed these methods in\nperformance. However, these models face challenges, such as the need for large\nannotated datasets and adapting to new domains. This paper presents a winning\nsolution to the Poleval 2023 Task 3: Passage Retrieval challenge, which\ninvolves retrieving passages of Polish texts in three domains: trivia, legal,\nand customer support. However, only the trivia domain was used for training and\ndevelopment data. The method used the OKAPI BM25 algorithm to retrieve\ndocuments and an ensemble of publicly available multilingual Cross Encoders for\nReranking. Fine-tuning the reranker models slightly improved performance but\nonly in the training domain, while it worsened in other domains.",
      "tldr_zh": "这篇论文介绍了在 Poleval 2023 Task 3 比赛中获胜的 Passage Retrieval 方法，针对波兰文本的三个领域（trivia、legal 和 customer support），仅使用 trivia 领域的数据进行训练。方法结合了 OKAPI BM25 算法进行初始文档检索，以及一组公开的多语言 Cross Encoders 的集成进行 Reranking。实验结果显示，微调 reranker 模型在训练领域略微提升了性能，但在其他领域表现反而下降，突显了神经网络模型在适应新领域时的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04620v1",
      "published_date": "2024-10-06 20:43:42 UTC",
      "updated_date": "2024-10-06 20:43:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:42:28.318576"
    },
    {
      "arxiv_id": "2410.14702v1",
      "title": "Polymath: A Challenging Multi-modal Mathematical Reasoning Benchmark",
      "title_zh": "Polymath：一个具有挑战性的多模态数学推理基准",
      "authors": [
        "Himanshu Gupta",
        "Shreyas Verma",
        "Ujjwala Anantheswaran",
        "Kevin Scaria",
        "Mihir Parmar",
        "Swaroop Mishra",
        "Chitta Baral"
      ],
      "abstract": "Multi-modal Large Language Models (MLLMs) exhibit impressive problem-solving\nabilities in various domains, but their visual comprehension and abstract\nreasoning skills remain under-evaluated. To this end, we present PolyMATH, a\nchallenging benchmark aimed at evaluating the general cognitive reasoning\nabilities of MLLMs. PolyMATH comprises 5,000 manually collected high-quality\nimages of cognitive textual and visual challenges across 10 distinct\ncategories, including pattern recognition, spatial reasoning, and relative\nreasoning. We conducted a comprehensive, and quantitative evaluation of 15\nMLLMs using four diverse prompting strategies, including Chain-of-Thought and\nStep-Back. The best scores achieved on PolyMATH are ~41%, ~36%, and ~27%,\nobtained by Claude-3.5 Sonnet, GPT-4o and Gemini-1.5 Pro respectively -\nhighlighting the logical and visual complexity of these questions. A further\nfine-grained error analysis reveals that these models struggle to understand\nspatial relations and perform drawn-out, high-level reasoning. This is further\nstrengthened by our ablation study estimating MLLM performance when given\ntextual descriptions in place of diagrams. As evidenced by ~4% improvement over\ntextual descriptions as opposed to actual images, we discover that models do\nnot truly comprehend visual diagrams and the spatial information therein, and\nare thus prone to logical errors. Finally, we evaluate the OpenAI o1 models and\nfind that their performance only matches the human baseline, highlighting the\ndifficulty of the benchmark. The results on PolyMATH highlight the room for\nimprovement in multi-modal reasoning and provide unique insights to guide the\ndevelopment of future MLLMs.",
      "tldr_zh": "本论文提出了Polymath基准，这是一个挑战性的多模态数学推理评估工具，旨在测试MLLMs在视觉理解和抽象推理方面的能力。该基准包括5,000个手动收集的高质量图像，涵盖10个类别如模式识别、空间推理和相对推理，并通过四种提示策略（如Chain-of-Thought和Step-Back）评估了15个MLLMs模型。实验结果显示，顶级模型Claude-3.5 Sonnet的准确率仅为约41%，而OpenAI o1模型的性能仅达到人类基线，且模型在理解空间关系和高水平推理时存在显著困难。研究还通过消融实验发现，使用文本描述代替图像可提升约4%的性能，突显了MLLMs在处理视觉图表和逻辑错误方面的改进空间。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "49 pages, (10 pages paper, 9 pages references, 30 pages appendix)",
      "pdf_url": "http://arxiv.org/pdf/2410.14702v1",
      "published_date": "2024-10-06 20:35:41 UTC",
      "updated_date": "2024-10-06 20:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:42:39.325015"
    },
    {
      "arxiv_id": "2410.04612v2",
      "title": "Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF",
      "title_zh": "回归相对未来：针对多轮 RLHF 的高效策略优化",
      "authors": [
        "Zhaolin Gao",
        "Wenhao Zhan",
        "Jonathan D. Chang",
        "Gokul Swamy",
        "Kianté Brantley",
        "Jason D. Lee",
        "Wen Sun"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success at tasks like\nsummarization that involve a single turn of interaction. However, they can\nstill struggle with multi-turn tasks like dialogue that require long-term\nplanning. Previous works on multi-turn dialogue extend single-turn\nreinforcement learning from human feedback (RLHF) methods to the multi-turn\nsetting by treating all prior dialogue turns as a long context. Such approaches\nsuffer from covariate shift: the conversations in the training set have\nprevious turns generated by some reference policy, which means that low\ntraining error may not necessarily correspond to good performance when the\nlearner is actually in the conversation loop. In response, we introduce\nREgressing the RELative FUture (REFUEL), an efficient policy optimization\napproach designed to address multi-turn RLHF in LLMs. REFUEL employs a single\nmodel to estimate $Q$-values and trains on self-generated data, addressing the\ncovariate shift issue. REFUEL frames the multi-turn RLHF problem as a sequence\nof regression tasks on iteratively collected datasets, enabling ease of\nimplementation. Theoretically, we prove that REFUEL can match the performance\nof any policy covered by the training set. Empirically, we evaluate our\nalgorithm by using Llama-3.1-70B-it to simulate a user in conversation with our\nmodel. REFUEL consistently outperforms state-of-the-art methods such as DPO and\nREBEL across various settings. Furthermore, despite having only 8 billion\nparameters, Llama-3-8B-it fine-tuned with REFUEL outperforms Llama-3.1-70B-it\non long multi-turn dialogues. Implementation of REFUEL can be found at\nhttps://github.com/ZhaolinGao/REFUEL/, and models trained by REFUEL can be\nfound at https://huggingface.co/Cornell-AGI.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在多轮对话任务中的长期规划挑战，提出了一种高效政策优化方法 REFUEL（REgressing the RELative FUture），以解决多轮强化学习从人类反馈（RLHF）中的 covariate shift 问题。REFUEL 使用单个模型估计 Q-values，并在自生成数据上训练，将问题转化为一系列回归任务，从而便于实现和迭代优化。理论上，该方法证明能匹配训练集覆盖的任何策略性能；实验结果显示，REFUEL 优于 DPO 和 REBEL 等基准，在使用 Llama-3.1-70B-it 模拟用户的情景下，即使是 8 亿参数的 Llama-3-8B-it 模型也在长多轮对话中超越 70 亿参数的 Llama-3.1-70B-it。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04612v2",
      "published_date": "2024-10-06 20:20:22 UTC",
      "updated_date": "2025-04-23 22:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:42:51.733020"
    },
    {
      "arxiv_id": "2410.05338v1",
      "title": "Distributed Inference on Mobile Edge and Cloud: An Early Exit based Clustering Approach",
      "title_zh": "在移动边缘和云上的分布式推理：一种基于早期退出的聚类方法",
      "authors": [
        "Divya Jyoti Bajpai",
        "Manjesh Kumar Hanawal"
      ],
      "abstract": "Recent advances in Deep Neural Networks (DNNs) have demonstrated outstanding\nperformance across various domains. However, their large size is a challenge\nfor deployment on resource-constrained devices such as mobile, edge, and IoT\nplatforms. To overcome this, a distributed inference setup can be used where a\nsmall-sized DNN (initial few layers) can be deployed on mobile, a bigger\nversion on the edge, and the full-fledged, on the cloud. A sample that has low\ncomplexity (easy) could be then inferred on mobile, that has moderate\ncomplexity (medium) on edge, and higher complexity (hard) on the cloud. As the\ncomplexity of each sample is not known beforehand, the following question\narises in distributed inference: how to decide complexity so that it is\nprocessed by enough layers of DNNs. We develop a novel approach named DIMEE\nthat utilizes Early Exit (EE) strategies developed to minimize inference\nlatency in DNNs. DIMEE aims to improve the accuracy, taking into account the\noffloading cost from mobile to edge/cloud. Experimental validation on GLUE\ndatasets, encompassing various NLP tasks, shows that our method significantly\nreduces the inference cost (> 43%) while maintaining a minimal drop in accuracy\n(< 0.3%) compared to the case where all the inference is made in cloud.",
      "tldr_zh": "该论文探讨了深度神经网络(DNNs)在资源受限设备（如移动、边缘和IoT平台）上的部署挑战，并提出分布式推理框架。作者开发了名为DIMEE的新方法，利用Early Exit (EE)策略和聚类技术，根据样本复杂度（如简单、中等或复杂）在移动设备、边缘或云端进行推理，从而优化准确性和卸载成本。在GLUE数据集的实验中，DIMEE显著降低了推理成本（超过43%），同时准确性下降不到0.3%。这为高效的分布式DNNs推理提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.05338v1",
      "published_date": "2024-10-06 20:14:27 UTC",
      "updated_date": "2024-10-06 20:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:43:02.282849"
    },
    {
      "arxiv_id": "2410.10855v3",
      "title": "Core Knowledge Deficits in Multi-Modal Language Models",
      "title_zh": "多模态语言模型中的核心知识缺陷",
      "authors": [
        "Yijiang Li",
        "Qingying Gao",
        "Tianwei Zhao",
        "Bingyang Wang",
        "Haoran Sun",
        "Haiyun Lyu",
        "Dezhi Luo",
        "Hokin Deng"
      ],
      "abstract": "While Multimodal Large Language Models (MLLMs) demonstrate impressive\nabilities over high level perception and reasoning, their robustness in the\nwild still lags behind humans and exhibits diminished efficacy on simple tasks\nthat are intuitive for humans. We examine the hypothesis that these\ndeficiencies stem from the absence of core knowledge, rudimentary cognitive\nabilities innate to humans from early childhood. To probe core knowledge\nrepresentation in MLLMs, we draw from developmental cognitive sciences and\ndevelop a large-scale benchmark, CoreCognition dataset, encompassing 12 core\ncognitive concepts. We evaluate 219 models with 10 different prompts, leading\nto a total of 2409 data points for analysis. Our findings reveal core knowledge\ndeficits in early developed core abilities while models demonstrate human\ncomparable performance in high level cognition. Moreover, we find that low\nlevel abilities show little to no scaling, in stark contrast to high level\nabilities. Finally, we introduce an evaluation technique, Concept Hacking,\nthrough which we demonstrate that MLLMs do not genuinely advance toward core\nknowledge but instead rely on illusory understanding and shortcut learning as\nthey scale. Website with this\n$\\href{https://growing-ai-like-a-child.github.io/}{link}$.",
      "tldr_zh": "这篇论文探讨了多模态大语言模型(MLLMs) 在核心知识方面的缺陷，认为这些模型虽然在高级感知和推理上表现出色，但缺乏人类幼年就拥有的基本认知能力，导致在简单任务上表现不佳。研究者开发了大规模基准数据集 CoreCognition，涵盖12个核心认知概念，并评估了219个模型的2409个数据点，结果显示模型在低级能力上几乎不随规模增长，而在高级认知上可与人类相当。最终，他们引入了 Concept Hacking 评估技术，证明 MLLMs 依赖于幻觉理解和捷径学习，而不是真正掌握核心知识。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Website with this\n  $\\href{https://growing-ai-like-a-child.github.io/}{link}$",
      "pdf_url": "http://arxiv.org/pdf/2410.10855v3",
      "published_date": "2024-10-06 20:13:11 UTC",
      "updated_date": "2025-03-09 04:39:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:43:15.022256"
    },
    {
      "arxiv_id": "2410.10854v1",
      "title": "Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Shramay Palta",
        "Nishant Balepur",
        "Peter Rankel",
        "Sarah Wiegreffe",
        "Marine Carpuat",
        "Rachel Rudinger"
      ],
      "abstract": "Questions involving commonsense reasoning about everyday situations often\nadmit many $\\textit{possible}$ or $\\textit{plausible}$ answers. In contrast,\nmultiple-choice question (MCQ) benchmarks for commonsense reasoning require a\nhard selection of a single correct answer, which, in principle, should\nrepresent the $\\textit{most}$ plausible answer choice. On $250$ MCQ items\nsampled from two commonsense reasoning benchmarks, we collect $5,000$\nindependent plausibility judgments on answer choices. We find that for over 20%\nof the sampled MCQs, the answer choice rated most plausible does not match the\nbenchmark gold answers; upon manual inspection, we confirm that this subset\nexhibits higher rates of problems like ambiguity or semantic mismatch between\nquestion and answer choices. Experiments with LLMs reveal low accuracy and high\nvariation in performance on the subset, suggesting our plausibility criterion\nmay be helpful in identifying more reliable benchmark items for commonsense\nevaluation.",
      "tldr_zh": "本研究调查了常理推理多项选择题（MCQs）基准中存在的问题，这些问题通常有多个合理的答案，但基准强制选择一个“最合理”的选项。通过从两个常理推理基准中采样250个MCQs并收集5000个独立的可信度判断，研究发现超过20%的样本中，被评定为最合理的答案与基准的黄金答案不匹配，且这些问题常伴随歧义或语义不匹配。进一步的LLMs实验显示，在此子集上的准确率较低且表现不稳定。该工作建议使用可信度标准来识别更可靠的基准项目，从而提升常理推理评估的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2410.10854v1",
      "published_date": "2024-10-06 19:04:24 UTC",
      "updated_date": "2024-10-06 19:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:43:28.732800"
    },
    {
      "arxiv_id": "2410.04587v2",
      "title": "Hammer: Robust Function-Calling for On-Device Language Models via Function Masking",
      "title_zh": "翻译失败",
      "authors": [
        "Qiqiang Lin",
        "Muning Wen",
        "Qiuying Peng",
        "Guanyu Nie",
        "Junwei Liao",
        "Jun Wang",
        "Xiaoyun Mo",
        "Jiamu Zhou",
        "Cheng Cheng",
        "Yin Zhao",
        "Jun Wang",
        "Weinan Zhang"
      ],
      "abstract": "Large language models have demonstrated impressive value in performing as\nautonomous agents when equipped with external tools and API calls. Nonetheless,\neffectively harnessing their potential for executing complex tasks crucially\nrelies on enhancements in their function calling capabilities. This paper\nidentifies a critical gap in existing function calling models, where\nperformance varies significantly across benchmarks, often due to being misled\nby specific naming conventions. To address such an issue, we introduce Hammer,\na novel family of foundation models specifically engineered for on-device\nfunction calling. Hammer employs an augmented dataset that enhances models'\nsensitivity to irrelevant functions and incorporates function masking\ntechniques to minimize misleading. Our empirical evaluations reveal that Hammer\nnot only outperforms larger models but also demonstrates robust generalization\nacross diverse benchmarks, achieving sota results. Our open source\ncontributions include a specialized dataset for irrelevance detection, a tuning\nframework for enhanced generalization, and the Hammer models, establishing a\nnew standard for function calling performance.",
      "tldr_zh": "该论文识别出现有功能调用模型在不同基准上的性能不稳定，常因特定命名约定而被误导。作者引入 Hammer，一系列针对设备端语言模型的功能调用基模型，通过增强数据集提高对无关函数的敏感性，并采用功能掩码技术来最小化误导。实验结果显示，Hammer 不仅在多样基准上超越更大模型并实现 SOTA 性能，还提供了开源资源，包括无关性检测数据集、泛化增强的微调框架和 Hammer 模型本身。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04587v2",
      "published_date": "2024-10-06 18:57:46 UTC",
      "updated_date": "2024-10-10 17:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:43:37.570799"
    },
    {
      "arxiv_id": "2410.04568v1",
      "title": "Ranking Policy Learning via Marketplace Expected Value Estimation From Observational Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Ebrahimzadeh",
        "Nikhil Monga",
        "Hang Gao",
        "Alex Cozzi",
        "Abraham Bagherjeiran"
      ],
      "abstract": "We develop a decision making framework to cast the problem of learning a\nranking policy for search or recommendation engines in a two-sided e-commerce\nmarketplace as an expected reward optimization problem using observational\ndata. As a value allocation mechanism, the ranking policy allocates retrieved\nitems to the designated slots so as to maximize the user utility from the\nslotted items, at any given stage of the shopping journey. The objective of\nthis allocation can in turn be defined with respect to the underlying\nprobabilistic user browsing model as the expected number of interaction events\non presented items matching the user intent, given the ranking context. Through\nrecognizing the effect of ranking as an intervention action to inform users'\ninteractions with slotted items and the corresponding economic value of the\ninteraction events for the marketplace, we formulate the expected reward of the\nmarketplace as the collective value from all presented ranking actions. The key\nelement in this formulation is a notion of context value distribution, which\nsignifies not only the attribution of value to ranking interventions within a\nsession but also the distribution of marketplace reward across user sessions.\nWe build empirical estimates for the expected reward of the marketplace from\nobservational data that account for the heterogeneity of economic value across\nsession contexts as well as the distribution shifts in learning from\nobservational user activity data. The ranking policy can then be trained by\noptimizing the empirical expected reward estimates via standard Bayesian\ninference techniques. We report empirical results for a product search ranking\ntask in a major e-commerce platform demonstrating the fundamental trade-offs\ngoverned by ranking polices trained on empirical reward estimates with respect\nto extreme choices of the context value distribution.",
      "tldr_zh": "该研究提出了一种决策框架，将搜索或推荐引擎的排名策略学习问题建模为使用观察数据的期望奖励优化问题，旨在最大化两侧电子商务市场的用户效用。框架通过引入上下文价值分布（context value distribution）来评估排名干预对用户互动的经济价值，并从观察数据中估计期望奖励，考虑经济价值异质性和分布偏移（distribution shifts）。最终，排名策略通过标准贝叶斯推理技术（Bayesian inference）进行训练，并在主要电子商务平台的商品搜索任务中实证验证了不同上下文价值分布下策略的权衡取舍。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.04568v1",
      "published_date": "2024-10-06 17:53:44 UTC",
      "updated_date": "2024-10-06 17:53:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:43:50.793613"
    },
    {
      "arxiv_id": "2410.04552v1",
      "title": "Modeling Social Media Recommendation Impacts Using Academic Networks: A Graph Neural Network Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Sabrina Guidotti",
        "Gregor Donabauer",
        "Simone Somazzi",
        "Udo Kruschwitz",
        "Davide Taibi",
        "Dimitri Ognibene"
      ],
      "abstract": "The widespread use of social media has highlighted potential negative impacts\non society and individuals, largely driven by recommendation algorithms that\nshape user behavior and social dynamics. Understanding these algorithms is\nessential but challenging due to the complex, distributed nature of social\nmedia networks as well as limited access to real-world data. This study\nproposes to use academic social networks as a proxy for investigating\nrecommendation systems in social media. By employing Graph Neural Networks\n(GNNs), we develop a model that separates the prediction of academic infosphere\nfrom behavior prediction, allowing us to simulate recommender-generated\ninfospheres and assess the model's performance in predicting future\nco-authorships. Our approach aims to improve our understanding of\nrecommendation systems' roles and social networks modeling. To support the\nreproducibility of our work we publicly make available our implementations:\nhttps://github.com/DimNeuroLab/academic_network_project",
      "tldr_zh": "本研究探讨了社会媒体推荐算法对社会和个体的负面影响，使用学术社交网络作为代理来模拟和分析这些算法。作者采用 Graph Neural Networks (GNNs) 构建模型，将学术信息圈预测与行为预测分开，从而模拟推荐系统生成的信息环境，并评估其在预测未来合著方面的性能。结果表明，该方法提升了对推荐系统作用和社会网络建模的理解，并通过公开代码仓库（https://github.com/DimNeuroLab/academic_network_project）支持研究的可重复性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04552v1",
      "published_date": "2024-10-06 17:03:27 UTC",
      "updated_date": "2024-10-06 17:03:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:44:02.427471"
    },
    {
      "arxiv_id": "2410.04543v1",
      "title": "Pullback Flow Matching on Data Manifolds",
      "title_zh": "翻译失败",
      "authors": [
        "Friso de Kruiff",
        "Erik Bekkers",
        "Ozan Öktem",
        "Carola-Bibiane Schönlieb",
        "Willem Diepeveen"
      ],
      "abstract": "We propose Pullback Flow Matching (PFM), a novel framework for generative\nmodeling on data manifolds. Unlike existing methods that assume or learn\nrestrictive closed-form manifold mappings for training Riemannian Flow Matching\n(RFM) models, PFM leverages pullback geometry and isometric learning to\npreserve the underlying manifold's geometry while enabling efficient generation\nand precise interpolation in latent space. This approach not only facilitates\nclosed-form mappings on the data manifold but also allows for designable latent\nspaces, using assumed metrics on both data and latent manifolds. By enhancing\nisometric learning through Neural ODEs and proposing a scalable training\nobjective, we achieve a latent space more suitable for interpolation, leading\nto improved manifold learning and generative performance. We demonstrate PFM's\neffectiveness through applications in synthetic data, protein dynamics and\nprotein sequence data, generating novel proteins with specific properties. This\nmethod shows strong potential for drug discovery and materials science, where\ngenerating novel samples with specific properties is of great interest.",
      "tldr_zh": "本研究提出Pullback Flow Matching (PFM)，一种用于数据流形上生成建模的新框架，通过pullback geometry和isometric learning保留底层流形的几何，同时在潜在空间实现高效生成和精确插值。PFM避免了现有Riemannian Flow Matching (RFM)方法对闭形式流形映射的限制，利用Neural ODEs和可扩展训练目标设计更适合插值的潜在空间，从而提升流形学习和生成性能。在合成数据、蛋白质动力学及蛋白质序列数据上的实验中，PFM成功生成具有特定属性的新蛋白质，展现出在药物发现和材料科学领域的强大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DG",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04543v1",
      "published_date": "2024-10-06 16:41:26 UTC",
      "updated_date": "2024-10-06 16:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:45:08.871737"
    },
    {
      "arxiv_id": "2410.04541v1",
      "title": "On Evaluating LLMs' Capabilities as Functional Approximators: A Bayesian Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Shoaib Ahmed Siddiqui",
        "Yanzhi Chen",
        "Juyeon Heo",
        "Menglin Xia",
        "Adrian Weller"
      ],
      "abstract": "Recent works have successfully applied Large Language Models (LLMs) to\nfunction modeling tasks. However, the reasons behind this success remain\nunclear. In this work, we propose a new evaluation framework to comprehensively\nassess LLMs' function modeling abilities. By adopting a Bayesian perspective of\nfunction modeling, we discover that LLMs are relatively weak in understanding\npatterns in raw data, but excel at utilizing prior knowledge about the domain\nto develop a strong understanding of the underlying function. Our findings\noffer new insights about the strengths and limitations of LLMs in the context\nof function modeling.",
      "tldr_zh": "本研究提出了一种新的评估框架，从贝叶斯视角评估大型语言模型（LLMs）作为函数逼近器的能力。研究发现，LLMs 在理解原始数据中的模式方面相对薄弱，但擅长利用领域的先验知识来构建对底层函数的强认知。这些发现为理解 LLMs 在函数建模中的优势和局限提供了新的见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04541v1",
      "published_date": "2024-10-06 16:30:47 UTC",
      "updated_date": "2024-10-06 16:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:44:26.495788"
    },
    {
      "arxiv_id": "2410.04526v4",
      "title": "FAMMA: A Benchmark for Financial Domain Multilingual Multimodal Question Answering",
      "title_zh": "FAMMA：金融领域多语言多模态问答基准",
      "authors": [
        "Siqiao Xue",
        "Xiaojing Li",
        "Fan Zhou",
        "Qingyang Dai",
        "Zhixuan Chu",
        "Hongyuan Mei"
      ],
      "abstract": "In this paper, we introduce FAMMA, an open-source benchmark for\n\\underline{f}in\\underline{a}ncial \\underline{m}ultilingual\n\\underline{m}ultimodal question \\underline{a}nswering (QA). Our benchmark aims\nto evaluate the abilities of large language models (LLMs) in answering complex\nreasoning questions that require advanced financial knowledge. The benchmark\nhas two versions: FAMMA-Basic consists of 1,945 questions extracted from\nuniversity textbooks and exams, along with human-annotated answers and\nrationales; FAMMA-LivePro consists of 103 novel questions created by human\ndomain experts, with answers and rationales held out from the public for a\ncontamination-free evaluation. These questions cover advanced knowledge of 8\nmajor subfields in finance (e.g., corporate finance, derivatives, and portfolio\nmanagement). Some are in Chinese or French, while a majority of them are in\nEnglish. Each question has some non-text data such as charts, diagrams, or\ntables. Our experiments reveal that FAMMA poses a significant challenge on\nLLMs, including reasoning models such as GPT-o1 and DeepSeek-R1. Additionally,\nwe curated 1,270 reasoning trajectories of DeepSeek-R1 on the FAMMA-Basic data,\nand fine-tuned a series of open-source Qwen models using this reasoning data.\nWe found that training a model on these reasoning trajectories can\nsignificantly improve its performance on FAMMA-LivePro. We released our\nleaderboard, data, code, and trained models at\nhttps://famma-bench.github.io/famma/.",
      "tldr_zh": "这篇论文引入了 FAMMA，这是一个开源基准，用于评估大型语言模型 (LLMs) 在金融领域多语言多模态问答 (QA) 的性能，特别针对需要高级金融知识的复杂推理问题。基准包括两个版本：FAMMA-Basic 包含 1,945 个从教科书和考试中提取的问题，并有手动标注的答案和理由；FAMMA-LivePro 则有 103 个由专家创建的新问题，用于无污染评估，答案不公开。问题覆盖 8 个主要金融子领域（如公司金融和衍生品），涉及英语、中文和法语，并包含图表等非文本数据。实验结果显示，现有 LLMs（如 GPT-o1 和 DeepSeek-R1）在 FAMMA 上面临重大挑战，但通过使用 DeepSeek-R1 的推理轨迹微调 Qwen 模型，能显著提升性能，并已公开相关资源以推动进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04526v4",
      "published_date": "2024-10-06 15:41:26 UTC",
      "updated_date": "2025-05-15 02:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:44:40.535790"
    },
    {
      "arxiv_id": "2410.04523v1",
      "title": "Semi-Markovian Planning to Coordinate Aerial and Maritime Medical Evacuation Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Al-Husseini",
        "Kyle H. Wray",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "The transfer of patients between two aircraft using an underway watercraft\nincreases medical evacuation reach and flexibility in maritime environments.\nThe selection of any one of multiple underway watercraft for patient exchange\nis complicated by participating aircraft utilization history and a\nparticipating watercraft position and velocity. The selection problem is\nmodeled as a semi-Markov decision process with an action space including both\nfixed land and moving watercraft exchange points. Monte Carlo tree search with\nroot parallelization is used to select optimal exchange points and determine\naircraft dispatch times. Model parameters are varied in simulation to identify\nrepresentative scenarios where watercraft exchange points reduce incident\nresponse times. We find that an optimal policy with watercraft exchange points\noutperforms an optimal policy without watercraft exchange points and a greedy\npolicy by 35% and 40%, respectively. In partnership with the United States\nArmy, we deploy for the first time the watercraft exchange point by executing a\nmock patient transfer with a manikin between two HH-60M medical evacuation\nhelicopters and an underway Army Logistic Support Vessel south of the Hawaiian\nisland of Oahu. Both helicopters were dispatched in accordance with our\noptimized decision strategy.",
      "tldr_zh": "该研究针对海上环境中使用水上船只进行空中医疗疏散患者转移的问题，提出了一种基于semi-Markov decision process的规划方法，以协调飞机和船只的行动空间，包括固定陆地和移动水上交换点。研究采用Monte Carlo tree search with root parallelization算法来优化交换点选择和飞机派遣时间，通过模拟实验发现，这种策略比无水上交换点的优化策略和贪婪策略分别减少响应时间35%和40%。此外，研究与美国陆军合作，首次实际部署该方法，成功模拟在两架HH-60M直升机和一艘军用后勤支援船之间转移患者模型，验证了其可行性和有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04523v1",
      "published_date": "2024-10-06 15:32:59 UTC",
      "updated_date": "2024-10-06 15:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:44:50.609275"
    },
    {
      "arxiv_id": "2410.04503v1",
      "title": "LRHP: Learning Representations for Human Preferences via Preference Pairs",
      "title_zh": "翻译失败",
      "authors": [
        "Chenglong Wang",
        "Yang Gan",
        "Yifu Huo",
        "Yongyu Mu",
        "Qiaozhi He",
        "Murun Yang",
        "Tong Xiao",
        "Chunliang Zhang",
        "Tongran Liu",
        "Jingbo Zhu"
      ],
      "abstract": "To improve human-preference alignment training, current research has\ndeveloped numerous preference datasets consisting of preference pairs labeled\nas \"preferred\" or \"dispreferred\". These preference pairs are typically used to\nencode human preferences into a single numerical value through reward modeling,\nwhich acts as a reward signal during reinforcement learning from human feedback\n(RLHF). However, representing these human preferences as a numerical value\ncomplicates the analysis of these preferences and restricts their broader\napplications other than RLHF. In contrast, in this work, we introduce a\npreference representation learning task that aims to construct a richer and\nmore structured representation of human preferences. We further develop a more\ngeneralizable framework, Learning Representations for Human Preferences via\npreference pairs (namely LRHP), which extends beyond traditional reward\nmodeling to tackle this task. We verify the utility of preference\nrepresentations in two downstream tasks: preference data selection and\npreference margin prediction. Building upon the human preferences in\nrepresentations, we achieve strong performance in both tasks, significantly\noutperforming baselines.",
      "tldr_zh": "本文提出了一种新的偏好表示学习任务，旨在通过偏好 pairs 构建更丰富和结构化的 human preferences 表示，以克服传统 reward modeling 将偏好简化为单一数值的局限性。研究引入了 LRHP 框架（Learning Representations for Human Preferences via preference pairs），扩展了现有方法，用于处理偏好数据。实验结果显示，LRHP 在偏好数据选择和偏好 margin prediction 等下游任务中显著优于基线模型，证明了其在 RLHF 之外的更广泛应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04503v1",
      "published_date": "2024-10-06 14:48:28 UTC",
      "updated_date": "2024-10-06 14:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:45:02.928541"
    },
    {
      "arxiv_id": "2410.04501v3",
      "title": "Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Vy Nguyen",
        "Chau Pham"
      ],
      "abstract": "The increasing frequency of suicidal thoughts highlights the importance of\nearly detection and intervention. Social media platforms, where users often\nshare personal experiences and seek help, could be utilized to identify\nindividuals at risk. However, the large volume of daily posts makes manual\nreview impractical. This paper explores the use of Large Language Models (LLMs)\nto automatically detect suicidal content in text-based social media posts. We\npropose a novel method for generating pseudo-labels for unlabeled data by\nprompting LLMs, along with traditional classification fine-tuning techniques to\nenhance label accuracy. To create a strong suicide detection model, we develop\nan ensemble approach involving prompting with Qwen2-72B-Instruct, and using\nfine-tuned models such as Llama3-8B, Llama3.1-8B, and Gemma2-9B. We evaluate\nour approach on the dataset of the Suicide Ideation Detection on Social Media\nChallenge, a track of the IEEE Big Data 2024 Big Data Cup. Additionally, we\nconduct a comprehensive analysis to assess the impact of different models and\nfine-tuning strategies on detection performance. Experimental results show that\nthe ensemble model significantly improves the detection accuracy, by 5% points\ncompared with the individual models. It achieves a weight F1 score of 0.770 on\nthe public test set, and 0.731 on the private test set, providing a promising\nsolution for identifying suicidal content in social media. Our analysis shows\nthat the choice of LLMs affects the prompting performance, with larger models\nproviding better accuracy. Our code and checkpoints are publicly available at\nhttps://github.com/khanhvynguyen/Suicide_Detection_LLMs.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型（LLMs）在标签有限的情况下检测社交媒体上的自杀内容，以实现早期干预。研究提出一种新方法，通过提示 LLMs 生成伪标签，并结合传统分类微调技术和集成模型（如 Qwen2-72B-Instruct、Llama3-8B 和 Gemma2-9B），提升检测准确性。实验结果显示，集成模型在 IEEE Big Data 2024 数据集上比单个模型提高5个百分点，权重 F1 分数达到公共测试集的0.770和私有测试集的0.731，并分析表明较大模型在提示性能上更优。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IEEE International Conference on Big Data 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04501v3",
      "published_date": "2024-10-06 14:45:01 UTC",
      "updated_date": "2024-11-01 03:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:45:20.845853"
    },
    {
      "arxiv_id": "2410.04499v1",
      "title": "Adjusting Pretrained Backbones for Performativity",
      "title_zh": "翻译失败",
      "authors": [
        "Berker Demirel",
        "Lingjing Kong",
        "Kun Zhang",
        "Theofanis Karaletsos",
        "Celestine Mendler-Dünner",
        "Francesco Locatello"
      ],
      "abstract": "With the widespread deployment of deep learning models, they influence their\nenvironment in various ways. The induced distribution shifts can lead to\nunexpected performance degradation in deployed models. Existing methods to\nanticipate performativity typically incorporate information about the deployed\nmodel into the feature vector when predicting future outcomes. While enjoying\nappealing theoretical properties, modifying the input dimension of the\nprediction task is often not practical. To address this, we propose a novel\ntechnique to adjust pretrained backbones for performativity in a modular way,\nachieving better sample efficiency and enabling the reuse of existing deep\nlearning assets. Focusing on performative label shift, the key idea is to train\na shallow adapter module to perform a Bayes-optimal label shift correction to\nthe backbone's logits given a sufficient statistic of the model to be deployed.\nAs such, our framework decouples the construction of input-specific feature\nembeddings from the mechanism governing performativity. Motivated by dynamic\nbenchmarking as a use-case, we evaluate our approach under adversarial\nsampling, for vision and language tasks. We show how it leads to smaller loss\nalong the retraining trajectory and enables us to effectively select among\ncandidate models to anticipate performance degradations. More broadly, our work\nprovides a first baseline for addressing performativity in deep learning.",
      "tldr_zh": "该研究针对深层学习模型部署后引发的分布偏移问题，提出了一种模块化方法来调整预训练 backbones 以应对 performativity。核心创新是通过训练一个浅层适配器模块，对骨干网络的 logits 进行 Bayes-optimal label shift correction，利用部署模型的充分统计量，从而将特征嵌入与 performativity 机制分离，提高样本效率并复用现有资产。在视觉和语言任务的动态基准测试中，该方法在对抗采样下显著减少了重新训练损失，并帮助有效选择候选模型以预测性能下降，为深层学习中的 performativity 提供了首个基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04499v1",
      "published_date": "2024-10-06 14:41:13 UTC",
      "updated_date": "2024-10-06 14:41:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:45:33.272813"
    },
    {
      "arxiv_id": "2410.04497v1",
      "title": "Generalizability analysis of deep learning predictions of human brain responses to augmented and semantically novel visual stimuli",
      "title_zh": "翻译失败",
      "authors": [
        "Valentyn Piskovskyi",
        "Riccardo Chimisso",
        "Sabrina Patania",
        "Tom Foulsham",
        "Giuseppe Vizzari",
        "Dimitri Ognibene"
      ],
      "abstract": "The purpose of this work is to investigate the soundness and utility of a\nneural network-based approach as a framework for exploring the impact of image\nenhancement techniques on visual cortex activation. In a preliminary study, we\nprepare a set of state-of-the-art brain encoding models, selected among the top\n10 methods that participated in The Algonauts Project 2023 Challenge [16]. We\nanalyze their ability to make valid predictions about the effects of various\nimage enhancement techniques on neural responses. Given the impossibility of\nacquiring the actual data due to the high costs associated with brain imaging\nprocedures, our investigation builds up on a series of experiments.\nSpecifically, we analyze the ability of brain encoders to estimate the cerebral\nreaction to various augmentations by evaluating the response to augmentations\ntargeting objects (i.e., faces and words) with known impact on specific areas.\nMoreover, we study the predicted activation in response to objects unseen\nduring training, exploring the impact of semantically out-of-distribution\nstimuli. We provide relevant evidence for the generalization ability of the\nmodels forming the proposed framework, which appears to be promising for the\nidentification of the optimal visual augmentation filter for a given task,\nmodel-driven design strategies as well as for AR and VR applications.",
      "tldr_zh": "本研究分析了深度学习模型在预测人类对增强图像和语义新颖视觉刺激的脑响应方面的泛化能力，旨在探索图像增强技术对视觉皮层激活的影响。研究者使用 The Algonauts Project 2023 Challenge 中的前 10 脑编码模型，通过模拟实验评估模型对已知对象（如面部和文字）的增强响应，以及对训练中未见的语义上分布外刺激的预测能力。结果表明，这些模型显示出良好的泛化性能，可用于识别最佳视觉增强过滤器、驱动设计策略，并应用于增强现实(AR)和虚拟现实(VR)领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04497v1",
      "published_date": "2024-10-06 14:29:02 UTC",
      "updated_date": "2024-10-06 14:29:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:45:45.464990"
    },
    {
      "arxiv_id": "2410.10853v1",
      "title": "Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support",
      "title_zh": "翻译失败",
      "authors": [
        "Abdul Muqtadir",
        "Hafiz Syed Muhammad Bilal",
        "Ayesha Yousaf",
        "Hafiz Farooq Ahmed",
        "Jamil Hussain"
      ],
      "abstract": "This research work delves into the manifestation of hallucination within\nLarge Language Models (LLMs) and its consequential impacts on applications\nwithin the domain of mental health. The primary objective is to discern\neffective strategies for curtailing hallucinatory occurrences, thereby\nbolstering the dependability and security of LLMs in facilitating mental health\ninterventions such as therapy, counseling, and the dissemination of pertinent\ninformation. Through rigorous investigation and analysis, this study seeks to\nelucidate the underlying mechanisms precipitating hallucinations in LLMs and\nsubsequently propose targeted interventions to alleviate their occurrence. By\naddressing this critical issue, the research endeavors to foster a more robust\nframework for the utilization of LLMs within mental health contexts, ensuring\ntheir efficacy and reliability in aiding therapeutic processes and delivering\naccurate information to individuals seeking mental health support.",
      "tldr_zh": "这篇研究探讨了Large Language Models (LLMs)中hallucinations（幻觉）现象及其对心理健康领域的影响，旨在通过有效的策略提升LLMs在治疗、咨询和信息传播等干预中的可靠性和安全性。研究采用Knowledge Graph和Vector Store的集成（Ensemble）方法，分析hallucinations的成因并提出针对性干预措施，以减少其发生。最终，该框架为LLMs在心理健康支持中的应用提供了更稳健的解决方案，确保其在辅助治疗过程中更有效和可信。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10853v1",
      "published_date": "2024-10-06 14:26:37 UTC",
      "updated_date": "2024-10-06 14:26:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:45:56.793943"
    },
    {
      "arxiv_id": "2410.04492v5",
      "title": "Interpret Your Decision: Logical Reasoning Regularization for Generalization in Visual Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaorui Tan",
        "Xi Yang",
        "Qiufeng Wang",
        "Anh Nguyen",
        "Kaizhu Huang"
      ],
      "abstract": "Vision models excel in image classification but struggle to generalize to\nunseen data, such as classifying images from unseen domains or discovering\nnovel categories. In this paper, we explore the relationship between logical\nreasoning and deep learning generalization in visual classification. A logical\nregularization termed L-Reg is derived which bridges a logical analysis\nframework to image classification. Our work reveals that L-Reg reduces the\ncomplexity of the model in terms of the feature distribution and classifier\nweights. Specifically, we unveil the interpretability brought by L-Reg, as it\nenables the model to extract the salient features, such as faces to persons,\nfor classification. Theoretical analysis and experiments demonstrate that L-Reg\nenhances generalization across various scenarios, including multi-domain\ngeneralization and generalized category discovery. In complex real-world\nscenarios where images span unknown classes and unseen domains, L-Reg\nconsistently improves generalization, highlighting its practical efficacy.",
      "tldr_zh": "该论文探讨了视觉分类模型在处理未见数据（如新领域或类别）时的泛化问题，并引入逻辑推理正则化（L-Reg）作为解决方案。L-Reg 通过将逻辑分析框架桥接到图像分类，减少模型的特征分布和分类器权重复杂度，同时提升模型的可解释性，例如提取显著特征（如人脸用于识别人物）。实验和理论分析证明，L-Reg 在多领域泛化和广义类别发现等场景中显著改善泛化性能，尤其在真实世界复杂环境中，处理未知类和未见领域时表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS2024 as Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2410.04492v5",
      "published_date": "2024-10-06 14:11:39 UTC",
      "updated_date": "2025-01-27 20:34:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:46:08.267908"
    },
    {
      "arxiv_id": "2410.04491v1",
      "title": "Knowledge-Guided Dynamic Modality Attention Fusion Framework for Multimodal Sentiment Analysis",
      "title_zh": "知识引导的动态模态注意力融合框架",
      "authors": [
        "Xinyu Feng",
        "Yuming Lin",
        "Lihua He",
        "You Li",
        "Liang Chang",
        "Ya Zhou"
      ],
      "abstract": "Multimodal Sentiment Analysis (MSA) utilizes multimodal data to infer the\nusers' sentiment. Previous methods focus on equally treating the contribution\nof each modality or statically using text as the dominant modality to conduct\ninteraction, which neglects the situation where each modality may become\ndominant. In this paper, we propose a Knowledge-Guided Dynamic Modality\nAttention Fusion Framework (KuDA) for multimodal sentiment analysis. KuDA uses\nsentiment knowledge to guide the model dynamically selecting the dominant\nmodality and adjusting the contributions of each modality. In addition, with\nthe obtained multimodal representation, the model can further highlight the\ncontribution of dominant modality through the correlation evaluation loss.\nExtensive experiments on four MSA benchmark datasets indicate that KuDA\nachieves state-of-the-art performance and is able to adapt to different\nscenarios of dominant modality.",
      "tldr_zh": "本文提出了一种Knowledge-Guided Dynamic Modality Attention Fusion Framework (KuDA)，用于Multimodal Sentiment Analysis，通过sentiment knowledge动态指导模型选择主导模态并调整各模态的贡献，解决了传统方法忽略模态主导性变化的问题。KuDA进一步利用correlation evaluation loss突出主导模态的作用，提升多模态表示的准确性。在四个MSA基准数据集上的广泛实验显示，该框架达到了state-of-the-art性能，并能适应不同情境下的模态主导性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04491v1",
      "published_date": "2024-10-06 14:10:28 UTC",
      "updated_date": "2024-10-06 14:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:46:20.658066"
    },
    {
      "arxiv_id": "2410.04488v1",
      "title": "A Pluggable Common Sense-Enhanced Framework for Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Guanglin Niu",
        "Bo Li",
        "Siling Feng"
      ],
      "abstract": "Knowledge graph completion (KGC) tasks aim to infer missing facts in a\nknowledge graph (KG) for many knowledge-intensive applications. However,\nexisting embedding-based KGC approaches primarily rely on factual triples,\npotentially leading to outcomes inconsistent with common sense. Besides,\ngenerating explicit common sense is often impractical or costly for a KG. To\naddress these challenges, we propose a pluggable common sense-enhanced KGC\nframework that incorporates both fact and common sense for KGC. This framework\nis adaptable to different KGs based on their entity concept richness and has\nthe capability to automatically generate explicit or implicit common sense from\nfactual triples. Furthermore, we introduce common sense-guided negative\nsampling and a coarse-to-fine inference approach for KGs with rich entity\nconcepts. For KGs without concepts, we propose a dual scoring scheme involving\na relation-aware concept embedding mechanism. Importantly, our approach can be\nintegrated as a pluggable module for many knowledge graph embedding (KGE)\nmodels, facilitating joint common sense and fact-driven training and inference.\nThe experiments illustrate that our framework exhibits good scalability and\noutperforms existing models across various KGC tasks.",
      "tldr_zh": "本文提出一个可插入的常识增强框架，用于知识图谱补全(KGC)，旨在解决现有基于嵌入的方法仅依赖事实三元组而忽略常识，导致结果不一致的问题。该框架能根据知识图谱(KG)的实体概念丰富度自动生成显式或隐式常识，并引入常识引导负采样、粗到细推理方法，以及针对无概念KG的双重评分方案和关系感知概念嵌入机制。作为一个可插入模块，该框架可整合到多种知识图谱嵌入(KGE)模型中，支持常识与事实的联合训练和推理。实验结果表明，该框架具有良好的可扩展性，并在各种KGC任务中优于现有模型。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2; I.2.4; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 7 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.04488v1",
      "published_date": "2024-10-06 14:06:12 UTC",
      "updated_date": "2024-10-06 14:06:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:47:16.314371"
    },
    {
      "arxiv_id": "2410.04485v1",
      "title": "Exploring the Potential of Conversational Test Suite Based Program Repair on SWE-bench",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Cheshkov",
        "Pavel Zadorozhny",
        "Rodion Levichev",
        "Evgeny Maslov",
        "Ronaldo Franco Jaldin"
      ],
      "abstract": "Automatic program repair at project level may open yet to be seen\nopportunities in various fields of human activity. Since the SWE-Bench\nchallenge was presented, we have seen numerous of solutions. Patch generation\nis a part of program repair, and test suite-based conversational patch\ngeneration has proven its effectiveness. However, the potential of\nconversational patch generation has not yet specifically estimated on\nSWE-Bench. This study reports experimental results aimed at evaluating the\nindividual effectiveness of conversational patch generation on problems from\nSWE-Bench. The experiments show that a simple conversational pipeline based on\nLLaMA 3.1 70B can generate valid patches in 47\\% of cases, which is comparable\nto the state-of-the-art in program repair on SWE-Bench.",
      "tldr_zh": "本研究探讨了基于对话的测试套件程序修复（conversational test suite based program repair）在 SWE-Bench 上的潜力，旨在评估其在项目级别自动程序修复中的有效性。研究采用一个简单对话管道，利用 LLaMA 3.1 70B 模型进行补丁生成，并针对 SWE-Bench 中的问题进行实验。结果显示，该方法在 47% 的情况下成功生成有效补丁，与当前 SWE-Bench 上的最先进程序修复技术相当，为未来对话式修复应用提供了可行性见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.SE",
      "comment": "3 pages, 2 figures, 1 algorithm, appendix",
      "pdf_url": "http://arxiv.org/pdf/2410.04485v1",
      "published_date": "2024-10-06 13:55:33 UTC",
      "updated_date": "2024-10-06 13:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:46:44.177060"
    },
    {
      "arxiv_id": "2410.04480v1",
      "title": "Learning to Solve Abstract Reasoning Problems with Neurosymbolic Program Synthesis and Task Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Bednarek",
        "Krzysztof Krawiec"
      ],
      "abstract": "The ability to think abstractly and reason by analogy is a prerequisite to\nrapidly adapt to new conditions, tackle newly encountered problems by\ndecomposing them, and synthesize knowledge to solve problems comprehensively.\nWe present TransCoder, a method for solving abstract problems based on neural\nprogram synthesis, and conduct a comprehensive analysis of decisions made by\nthe generative module of the proposed architecture. At the core of TransCoder\nis a typed domain-specific language, designed to facilitate feature engineering\nand abstract reasoning. In training, we use the programs that failed to solve\ntasks to generate new tasks and gather them in a synthetic dataset. As each\nsynthetic task created in this way has a known associated program (solution),\nthe model is trained on them in supervised mode. Solutions are represented in a\ntransparent programmatic form, which can be inspected and verified. We\ndemonstrate TransCoder's performance using the Abstract Reasoning Corpus\ndataset, for which our framework generates tens of thousands of synthetic\nproblems with corresponding solutions and facilitates systematic progress in\nlearning.",
      "tldr_zh": "本论文提出TransCoder方法，通过neurosymbolic program synthesis和task generation来解决抽象推理问题，帮助模型快速适应新任务并进行知识合成。该方法的的核心是typed domain-specific language，用于便于特征工程和抽象推理，并在训练中利用失败程序生成合成数据集进行监督式学习。实验结果显示，TransCoder在Abstract Reasoning Corpus数据集上生成了数万个合成问题及其解决方案，提升了模型的系统性学习能力。",
      "categories": [
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "18th International Conference on Neural-Symbolic Learning and\n  Reasoning",
      "pdf_url": "http://arxiv.org/pdf/2410.04480v1",
      "published_date": "2024-10-06 13:42:53 UTC",
      "updated_date": "2024-10-06 13:42:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:47:35.480839"
    },
    {
      "arxiv_id": "2410.10852v1",
      "title": "SafeLLM: Domain-Specific Safety Monitoring for Large Language Models: A Case Study of Offshore Wind Maintenance",
      "title_zh": "翻译失败",
      "authors": [
        "Connor Walker",
        "Callum Rothon",
        "Koorosh Aslansefat",
        "Yiannis Papadopoulos",
        "Nina Dethlefs"
      ],
      "abstract": "The Offshore Wind (OSW) industry is experiencing significant expansion,\nresulting in increased Operations \\& Maintenance (O\\&M) costs. Intelligent\nalarm systems offer the prospect of swift detection of component failures and\nprocess anomalies, enabling timely and precise interventions that could yield\nreductions in resource expenditure, as well as scheduled and unscheduled\ndowntime. This paper introduces an innovative approach to tackle this challenge\nby capitalising on Large Language Models (LLMs). We present a specialised\nconversational agent that incorporates statistical techniques to calculate\ndistances between sentences for the detection and filtering of hallucinations\nand unsafe output. This potentially enables improved interpretation of alarm\nsequences and the generation of safer repair action recommendations by the\nagent. Preliminary findings are presented with the approach applied to\nChatGPT-4 generated test sentences. The limitation of using ChatGPT-4 and the\npotential for enhancement of this agent through re-training with specialised\nOSW datasets are discussed.",
      "tldr_zh": "该研究针对离岸风电（Offshore Wind, OSW）维护领域的运维成本问题，提出SafeLLM框架，这是一种领域特定的安全监控系统，利用Large Language Models (LLMs)构建对话代理。SafeLLM结合统计技术计算句子间距离，以检测和过滤hallucinations（幻觉）和不安全输出，从而提升警报序列的解释和修复行动建议的安全性。初步实验在ChatGPT-4生成的测试句子上显示了积极效果，但论文指出使用ChatGPT-4的局限性，并建议通过重新训练专用OSW数据集来进一步优化该代理。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10852v1",
      "published_date": "2024-10-06 13:00:53 UTC",
      "updated_date": "2024-10-06 13:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:47:09.526705"
    },
    {
      "arxiv_id": "2410.10851v2",
      "title": "LLM Gesticulator: Leveraging Large Language Models for Scalable and Controllable Co-Speech Gesture Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhou Pang",
        "Tianwei Ding",
        "Lanshan He",
        "Ming Tao",
        "Lu Zhang",
        "Qi Gan"
      ],
      "abstract": "In this work, we present LLM Gesticulator, an LLM-based audio-driven\nco-speech gesture generation framework that synthesizes full-body animations\nthat are rhythmically aligned with the input audio while exhibiting natural\nmovements and editability. Compared to previous work, our model demonstrates\nsubstantial scalability. As the size of the backbone LLM model increases, our\nframework shows proportional improvements in evaluation metrics (a.k.a. scaling\nlaw). Our method also exhibits strong controllability where the content, style\nof the generated gestures can be controlled by text prompt. To the best of our\nknowledge, LLM gesticulator is the first work that use LLM on the co-speech\ngeneration task. Evaluation with existing objective metrics and user studies\nindicate that our framework outperforms prior works.",
      "tldr_zh": "本研究提出LLM Gesticulator，一种基于大型语言模型(LLM)的音频驱动共语手势生成框架，能够合成与输入音频节奏同步的全身动画，并实现自然的动作和可编辑性。与以往方法相比，该框架具有显著的可扩展性，随着LLM模型规模增加，评估指标按scaling law成比例提升。用户可以通过文本提示控制生成手势的内容和风格，这也是首次将LLM应用于共语生成任务。实验结果显示，该框架在客观指标和用户研究中均优于现有工作。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10851v2",
      "published_date": "2024-10-06 12:53:07 UTC",
      "updated_date": "2024-10-22 13:08:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:47:46.745942"
    },
    {
      "arxiv_id": "2410.04468v4",
      "title": "Revisiting In-context Learning Inference Circuit in Large Language Models",
      "title_zh": "重访大语言模型中的上下文学习推理电路",
      "authors": [
        "Hakaze Cho",
        "Mariko Kato",
        "Yoshihiro Sakai",
        "Naoya Inoue"
      ],
      "abstract": "In-context Learning (ICL) is an emerging few-shot learning paradigm on\nLanguage Models (LMs) with inner mechanisms un-explored. There are already\nexisting works describing the inner processing of ICL, while they struggle to\ncapture all the inference phenomena in large language models. Therefore, this\npaper proposes a comprehensive circuit to model the inference dynamics and try\nto explain the observed phenomena of ICL. In detail, we divide ICL inference\ninto 3 major operations: (1) Input Text Encode: LMs encode every input text (in\nthe demonstrations and queries) into linear representation in the hidden states\nwith sufficient information to solve ICL tasks. (2) Semantics Merge: LMs merge\nthe encoded representations of demonstrations with their corresponding label\ntokens to produce joint representations of labels and demonstrations. (3)\nFeature Retrieval and Copy: LMs search the joint representations of\ndemonstrations similar to the query representation on a task subspace, and copy\nthe searched representations into the query. Then, language model heads capture\nthese copied label representations to a certain extent and decode them into\npredicted labels. Through careful measurements, the proposed inference circuit\nsuccessfully captures and unifies many fragmented phenomena observed during the\nICL process, making it a comprehensive and practical explanation of the ICL\ninference process. Moreover, ablation analysis by disabling the proposed steps\nseriously damages the ICL performance, suggesting the proposed inference\ncircuit is a dominating mechanism. Additionally, we confirm and list some\nbypass mechanisms that solve ICL tasks in parallel with the proposed circuit.",
      "tldr_zh": "这篇论文重新审视了大型语言模型 (LMs) 中 In-context Learning (ICL) 的推理电路，提出一个全面的推理模型来解释 ICL 的内部动态。论文将 ICL 推理分为三个主要操作：Input Text Encode（编码输入文本为线性表示）、Semantics Merge（合并演示和标签的表示）以及 Feature Retrieval and Copy（检索类似查询的表示并复制到查询中，以生成预测标签）。通过实验验证，该电路成功统一了 ICL 过程中的多种现象，并通过消融分析证明它是主导机制，同时确认了存在一些并行机制。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages, 41 figures, 8 tables. ICLR 2025 Accepted. Camera-ready\n  Version",
      "pdf_url": "http://arxiv.org/pdf/2410.04468v4",
      "published_date": "2024-10-06 12:50:15 UTC",
      "updated_date": "2025-02-20 12:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:47:59.517038"
    },
    {
      "arxiv_id": "2410.04457v1",
      "title": "An Attention-Based Algorithm for Gravity Adaptation Zone Calibration",
      "title_zh": "基于注意力的重力适应区校准算法",
      "authors": [
        "Chen Yu"
      ],
      "abstract": "Accurate calibration of gravity adaptation zones is of great significance in\nfields such as underwater navigation, geophysical exploration, and marine\nengineering. With the increasing application of gravity field data in these\nareas, traditional calibration methods based on single features are becoming\ninadequate for capturing the complex characteristics of gravity fields and\naddressing the intricate interrelationships among multidimensional data. This\npaper proposes an attention-enhanced algorithm for gravity adaptation zone\ncalibration. By introducing an attention mechanism, the algorithm adaptively\nfuses multidimensional gravity field features and dynamically assigns feature\nweights, effectively solving the problems of multicollinearity and redundancy\ninherent in traditional feature selection methods, significantly improving\ncalibration accuracy and robustness.In addition, a large-scale gravity field\ndataset with over 10,000 sampling points was constructed, and Kriging\ninterpolation was used to enhance the spatial resolution of the data, providing\na reliable data foundation for model training and evaluation. We conducted both\nqualitative and quantitative experiments on several classical machine learning\nmodels (such as SVM, GBDT, and RF), and the results demonstrate that the\nproposed algorithm significantly improves performance across these models,\noutperforming other traditional feature selection methods. The method proposed\nin this paper provides a new solution for gravity adaptation zone calibration,\nshowing strong generalization ability and potential for application in complex\nenvironments. The code is available at \\href{this link}\n{https://github.com/hulnifox/RF-ATTN}.",
      "tldr_zh": "本论文提出了一种基于注意力机制(attention mechanism)的算法，用于重力适应区校准，以应对传统单一特征方法在处理多维重力场复杂特性和数据关联时存在的不足。该算法通过自适应融合多维特征并动态分配权重，解决了多重共线性(multicollinearity)和冗余问题，从而显著提升校准的准确性和鲁棒性。研究者构建了一个包含超过10,000个采样点的重力场数据集，并使用Kriging插值增强数据空间分辨率，在SVM、GBDT和RF等经典机器学习模型上进行实验，结果显示该算法使模型性能得到显著改善，优于传统特征选择方法。该方法为重力适应区校准提供新解决方案，展现出强大的泛化能力和在复杂环境中的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "15pages",
      "pdf_url": "http://arxiv.org/pdf/2410.04457v1",
      "published_date": "2024-10-06 12:03:13 UTC",
      "updated_date": "2024-10-06 12:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:48:11.201584"
    },
    {
      "arxiv_id": "2410.09084v1",
      "title": "Diagnosing Robotics Systems Issues with Large Language Models",
      "title_zh": "使用大语言模型诊断机器人系统问题",
      "authors": [
        "Jordis Emilia Herrmann",
        "Aswath Mandakath Gopinath",
        "Mikael Norrlof",
        "Mark Niklas Müller"
      ],
      "abstract": "Quickly resolving issues reported in industrial applications is crucial to\nminimize economic impact. However, the required data analysis makes diagnosing\nthe underlying root causes a challenging and time-consuming task, even for\nexperts. In contrast, large language models (LLMs) excel at analyzing large\namounts of data. Indeed, prior work in AI-Ops demonstrates their effectiveness\nin analyzing IT systems. Here, we extend this work to the challenging and\nlargely unexplored domain of robotics systems. To this end, we create\nSYSDIAGBENCH, a proprietary system diagnostics benchmark for robotics,\ncontaining over 2500 reported issues. We leverage SYSDIAGBENCH to investigate\nthe performance of LLMs for root cause analysis, considering a range of model\nsizes and adaptation techniques. Our results show that QLoRA finetuning can be\nsufficient to let a 7B-parameter model outperform GPT-4 in terms of diagnostic\naccuracy while being significantly more cost-effective. We validate our\nLLM-as-a-judge results with a human expert study and find that our best model\nachieves similar approval ratings as our reference labels.",
      "tldr_zh": "该研究探讨了利用大型语言模型（LLMs）诊断机器人系统问题，以快速解决工业应用中的故障并减少经济损失。研究者创建了SYSDIAGBENCH基准数据集，包含超过2500个报告问题，用于评估LLMs在根因分析中的性能，包括不同模型规模和适应技术如QLoRA微调。结果显示，通过QLoRA微调，一个7B参数模型在诊断准确性上超过了GPT-4，同时更具成本效益，且经人类专家验证，该模型的批准率与参考标签相当。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09084v1",
      "published_date": "2024-10-06 11:58:12 UTC",
      "updated_date": "2024-10-06 11:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:48:23.593021"
    },
    {
      "arxiv_id": "2410.16293v1",
      "title": "Hawk: An Efficient NALM System for Accurate Low-Power Appliance Recognition",
      "title_zh": "Hawk：高效的 NALM 系统，用于准确的低功率电器识别",
      "authors": [
        "Zijian Wang",
        "Xingzhou Zhang",
        "Yifan Wang",
        "Xiaohui Peng",
        "Zhiwei Xu"
      ],
      "abstract": "Non-intrusive Appliance Load Monitoring (NALM) aims to recognize individual\nappliance usage from the main meter without indoor sensors. However, existing\nsystems struggle to balance dataset construction efficiency and event/state\nrecognition accuracy, especially for low-power appliance recognition. This\npaper introduces Hawk, an efficient and accurate NALM system that operates in\ntwo stages: dataset construction and event recognition. In the data\nconstruction stage, we efficiently collect a balanced and diverse dataset,\nHawkDATA, based on balanced Gray code and enable automatic data annotations via\na sampling synchronization strategy called shared perceptible time. During the\nevent recognition stage, our algorithm integrates steady-state differential\npre-processing and voting-based post-processing for accurate event recognition\nfrom the aggregate current. Experimental results show that HawkDATA takes only\n1/71.5 of the collection time to collect 6.34x more appliance state\ncombinations than the baseline. In HawkDATA and a widely used dataset, Hawk\nachieves an average F1 score of 93.94% for state recognition and 97.07% for\nevent recognition, which is a 47. 98% and 11. 57% increase over SOTA\nalgorithms. Furthermore, selected appliance subsets and the model trained from\nHawkDATA are deployed in two real-world scenarios with many unknown background\nappliances. The average F1 scores of event recognition are 96.02% and 94.76%.\nHawk's source code and HawkDATA are accessible at\nhttps://github.com/WZiJ/SenSys24-Hawk.",
      "tldr_zh": "这篇论文介绍了 Hawk，一种高效的 Non-intrusive Appliance Load Monitoring (NALM) 系统，旨在平衡数据集构建效率与低功率家电识别准确性。Hawk 通过两阶段方法实现：首先，使用平衡 Gray code 和共享可感知时间策略快速构建平衡、多样数据集 HawkDATA，并实现自动标注；其次，整合稳态差分预处理和基于投票的后处理，从聚合电流中精确识别事件。实验结果显示，HawkDATA 的收集时间仅为基线的 1/71.5，但覆盖 6.34 倍家电状态组合，且 Hawk 在状态识别和事件识别的 F1 score 分别达到 93.94% 和 97.07%，比 SOTA 算法提高了 47.98% 和 11.57%；在真实场景中，事件识别 F1 score 平均为 96.02%。系统开源，可访问 https://github.com/WZiJ/SenSys24-Hawk。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted to the 22nd ACM Conference on Embedded Networked Sensor\n  Systems (SenSys 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.16293v1",
      "published_date": "2024-10-06 11:26:30 UTC",
      "updated_date": "2024-10-06 11:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:48:37.967828"
    },
    {
      "arxiv_id": "2410.04452v1",
      "title": "MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhentao Xie",
        "Jiabao Zhao",
        "Yilei Wang",
        "Jinxin Shi",
        "Yanhong Bai",
        "Xingjiao Wu",
        "Liang He"
      ],
      "abstract": "Detecting cognitive biases in large language models (LLMs) is a fascinating\ntask that aims to probe the existing cognitive biases within these models.\nCurrent methods for detecting cognitive biases in language models generally\nsuffer from incomplete detection capabilities and a restricted range of\ndetectable bias types. To address this issue, we introduced the 'MindScope'\ndataset, which distinctively integrates static and dynamic elements. The static\ncomponent comprises 5,170 open-ended questions spanning 72 cognitive bias\ncategories. The dynamic component leverages a rule-based, multi-agent\ncommunication framework to facilitate the generation of multi-round dialogues.\nThis framework is flexible and readily adaptable for various psychological\nexperiments involving LLMs. In addition, we introduce a multi-agent detection\nmethod applicable to a wide range of detection tasks, which integrates\nRetrieval-Augmented Generation (RAG), competitive debate, and a reinforcement\nlearning-based decision module. Demonstrating substantial effectiveness, this\nmethod has shown to improve detection accuracy by as much as 35.10% compared to\nGPT-4. Codes and appendix are available at\nhttps://github.com/2279072142/MindScope.",
      "tldr_zh": "这篇论文介绍了MindScope数据集，用于探索大型语言模型(LLMs)中的认知偏差问题，旨在解决现有检测方法检测能力不完整和偏差类型有限的缺陷。数据集包含静态部分（5,170个开放式问题，覆盖72个认知偏差类别）和动态部分（基于规则的多智能体通信框架生成多轮对话，便于心理实验应用）。此外，论文提出了一种多智能体检测方法，整合Retrieval-Augmented Generation (RAG)、竞争性辩论和基于强化学习的决策模块。实验结果显示，该方法比GPT-4提高了35.10%的检测准确率，为LLMs偏差检测提供了更有效的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages,7 figures,Our paper has been accepted for presentation at the\n  2024 European Conference on Artificial Intelligence (ECAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.04452v1",
      "published_date": "2024-10-06 11:23:56 UTC",
      "updated_date": "2024-10-06 11:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:48:47.828667"
    },
    {
      "arxiv_id": "2410.04444v3",
      "title": "Gödel Agent: A Self-Referential Agent Framework for Recursive Self-Improvement",
      "title_zh": "翻译失败",
      "authors": [
        "Xunjian Yin",
        "Xinyi Wang",
        "Liangming Pan",
        "Xiaojun Wan",
        "William Yang Wang"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has significantly\nenhanced the capabilities of AI-driven agents across various tasks. However,\nexisting agentic systems, whether based on fixed pipeline algorithms or\npre-defined meta-learning frameworks, cannot search the whole agent design\nspace due to the restriction of human-designed components, and thus might miss\nthe globally optimal agent design. In this paper, we introduce G\\\"odel Agent, a\nself-evolving framework inspired by the G\\\"odel machine, enabling agents to\nrecursively improve themselves without relying on predefined routines or fixed\noptimization algorithms. G\\\"odel Agent leverages LLMs to dynamically modify its\nown logic and behavior, guided solely by high-level objectives through\nprompting. Experimental results on mathematical reasoning and complex agent\ntasks demonstrate that implementation of G\\\"odel Agent can achieve continuous\nself-improvement, surpassing manually crafted agents in performance,\nefficiency, and generalizability.",
      "tldr_zh": "该研究介绍了Gödel Agent，一种受Gödel机器启发的自引用代理框架，旨在实现递归自我改进，以克服现有代理系统因依赖人类设计组件而无法探索完整代理设计空间的局限性。该框架利用LLMs动态修改自身的逻辑和行为，仅通过高层次目标的提示进行引导，而不依赖预定义的例程或优化算法。在数学推理和复杂代理任务的实验中，Gödel Agent实现了持续自我改进，在性能、效率和泛化性方面均超越手动设计的代理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress. The code can be found at\n  https://github.com/Arvid-pku/Godel_Agent",
      "pdf_url": "http://arxiv.org/pdf/2410.04444v3",
      "published_date": "2024-10-06 10:49:40 UTC",
      "updated_date": "2025-02-18 06:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:48:58.576277"
    },
    {
      "arxiv_id": "2410.04439v1",
      "title": "Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training",
      "title_zh": "通过输入粒度控制和字形感知训练增强骨干模型的视觉文本生成能力",
      "authors": [
        "Wenbo Li",
        "Guohao Li",
        "Zhibin Lan",
        "Xue Xu",
        "Wanru Zhuang",
        "Jiachen Liu",
        "Xinyan Xiao",
        "Jinsong Su"
      ],
      "abstract": "Diffusion-based text-to-image models have demonstrated impressive\nachievements in diversity and aesthetics but struggle to generate images with\nlegible visual texts. Existing backbone models have limitations such as\nmisspelling, failing to generate texts, and lack of support for Chinese text,\nbut their development shows promising potential. In this paper, we propose a\nseries of methods, aiming to empower backbone models to generate visual texts\nin English and Chinese. We first conduct a preliminary study revealing that\nByte Pair Encoding (BPE) tokenization and the insufficient learning of\ncross-attention modules restrict the performance of the backbone models. Based\non these observations, we make the following improvements: (1) We design a\nmixed granularity input strategy to provide more suitable text representations;\n(2) We propose to augment the conventional training objective with three\nglyph-aware training losses, which enhance the learning of cross-attention\nmodules and encourage the model to focus on visual texts. Through experiments,\nwe demonstrate that our methods can effectively empower backbone models to\ngenerate semantic relevant, aesthetically appealing, and accurate visual text\nimages, while maintaining their fundamental image generation quality.",
      "tldr_zh": "本文研究了如何增强backbone models在视觉文本生成中的能力，以解决扩散模型生成的图像文本问题，如拼写错误、无法生成文本和不支持中文。作者通过初步分析发现，Byte Pair Encoding (BPE)标记化和cross-attention modules的学习不足是主要限制因素，因此提出混合粒度输入策略来优化文本表示，并引入三种glyph-aware training losses来加强模块学习和模型对视觉文本的关注。实验结果表明，这些方法能有效提升生成图像的语义相关性、美观度和准确性，同时保持了backbone models的基本图像生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04439v1",
      "published_date": "2024-10-06 10:25:39 UTC",
      "updated_date": "2024-10-06 10:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:49:11.696855"
    },
    {
      "arxiv_id": "2410.04433v1",
      "title": "CAPEEN: Image Captioning with Early Exits and Knowledge Distillation",
      "title_zh": "CAPEEN：利用早期退出和知识蒸馏的图像字幕生成",
      "authors": [
        "Divya Jyoti Bajpai",
        "Manjesh Kumar Hanawal"
      ],
      "abstract": "Deep neural networks (DNNs) have made significant progress in recognizing\nvisual elements and generating descriptive text in image-captioning tasks.\nHowever, their improved performance comes from increased computational burden\nand inference latency. Early Exit (EE) strategies can be used to enhance their\nefficiency, but their adaptation presents challenges in image captioning as it\nrequires varying levels of semantic information for accurate predictions. To\novercome this, we introduce CAPEEN to improve the performance of EE strategies\nusing knowledge distillation. Inference in CAPEEN is completed at intermediary\nlayers if prediction confidence exceeds a predefined value learned from the\ntraining data. To account for real-world deployments, where target\ndistributions could drift from that of training samples, we introduce a variant\nA-CAPEEN to adapt the thresholds on the fly using Multiarmed bandits framework.\nExperiments on the MS COCO and Flickr30k datasets show that CAPEEN gains\nspeedup of 1.77x while maintaining competitive performance compared to the\nfinal layer, and A-CAPEEN additionally offers robustness against distortions.\nThe source code is available at https://github.com/Div290/CapEEN",
      "tldr_zh": "本文提出 CAPEEN，一种结合 Early Exits 和 Knowledge Distillation 的图像字幕方法，旨在解决深度神经网络(DNNs) 在任务中的高计算负担和推理延迟问题。CAPEEN 通过在中间层根据预测置信度阈值提前退出推理，从而在 MS COCO 和 Flickr30k 数据集上实现 1.77x 速度提升，同时保持与最终层相当的性能。针对真实部署中的分布漂移，作者引入 A-CAPEEN 变体，使用 Multiarmed bandits 框架动态调整阈值，进一步提升对失真的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear in EMNLP (finding) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04433v1",
      "published_date": "2024-10-06 10:05:01 UTC",
      "updated_date": "2024-10-06 10:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:49:24.096177"
    },
    {
      "arxiv_id": "2410.16292v1",
      "title": "An evaluation of LLM code generation capabilities through graded exercises",
      "title_zh": "翻译失败",
      "authors": [
        "Álvaro Barbero Jiménez"
      ],
      "abstract": "Large Language Models have shown prominent capabilities in generating\nfunctional code from natural language descriptions. However, a standardized way\nto evaluate these capabilities in an objective and unbiased manner is still to\nbe found. In this paper we review the current evaluation methods available to\nthis end, and run a new evaluation of the performance of one state-of-the-art\nmodel (GPT4-o-mini) in solving curated coding challenges in 8 programming\nlanguages, obtained from Codewars, a software development community. Our\nanalysis shows that the chance of success of the model has a positive\ncorrelation with the task difficulty, the popularity of the programming\nlanguage being used and the time elapsed since the publication of the\nchallenge. A further approximate explanatory analysis in terms of high-level\nfeatures hints that while 46.6% of the model performance could be attributed to\ntask difficulty, a 37.4% seems to be related to leakage of the challenge\nsolutions into the model training set, while the remaining 16% depends on the\nprogramming language. These results suggest that current evaluation\nmethodologies might be overestimating the actual skill of Large Language Models\nfor generating functional code.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 从自然语言描述生成功能代码的能力，审查了现有评估方法并提出了一种基于分级编码挑战的新评估框架。作者使用 GPT-4o-mini 模型在 8 种编程语言的 Codewars 社区挑战中进行测试，结果显示模型成功率与任务难度、语言流行度和挑战发布时间正相关。进一步分析发现，46.6% 的性能归因于任务难度，37.4% 可能由于挑战解决方案泄露到模型训练集，而剩余 16% 取决于编程语言。这些发现表明，当前评估方法可能高估了 LLMs 生成代码的实际技能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16292v1",
      "published_date": "2024-10-06 09:54:54 UTC",
      "updated_date": "2024-10-06 09:54:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:49:35.618267"
    },
    {
      "arxiv_id": "2410.04424v1",
      "title": "DAdEE: Unsupervised Domain Adaptation in Early Exit PLMs",
      "title_zh": "DAdEE：早期退出 PLMs 中的无监督域适应",
      "authors": [
        "Divya Jyoti Bajpai",
        "Manjesh Kumar Hanawal"
      ],
      "abstract": "Pre-trained Language Models (PLMs) exhibit good accuracy and generalization\nability across various tasks using self-supervision, but their large size\nresults in high inference latency. Early Exit (EE) strategies handle the issue\nby allowing the samples to exit from classifiers attached to the intermediary\nlayers, but they do not generalize well, as exit classifiers can be sensitive\nto domain changes. To address this, we propose Unsupervised Domain Adaptation\nin EE framework (DADEE) that employs multi-level adaptation using knowledge\ndistillation. DADEE utilizes GAN-based adversarial adaptation at each layer to\nachieve domain-invariant representations, reducing the domain gap between the\nsource and target domain across all layers. The attached exits not only speed\nup inference but also enhance domain adaptation by reducing catastrophic\nforgetting and mode collapse, making it more suitable for real-world scenarios.\nExperiments on tasks such as sentiment analysis, entailment classification, and\nnatural language inference demonstrate that DADEE consistently outperforms not\nonly early exit methods but also various domain adaptation methods under domain\nshift scenarios. The anonymized source code is available at\nhttps://github.com/Div290/DAdEE.",
      "tldr_zh": "本研究针对预训练语言模型 (PLMs) 的高推理延迟问题，提出 DAdEE 框架，即在 Early Exit (EE) 策略中进行无监督领域适应，以提升模型在领域变化下的泛化能力。DAdEE 通过多级知识蒸馏和每个层面的 GAN-based adversarial adaptation，实现源域和目标域之间的领域无关表示，减少域间差距，同时利用附加的退出机制来缓解灾难性遗忘和模式崩溃。实验结果显示，在情感分析、蕴含分类和自然语言推理等任务上，DAdEE 不仅优于传统 EE 方法，还超越了多种领域适应方法，证明其在实际场景中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in EMNLP (findings) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04424v1",
      "published_date": "2024-10-06 09:44:58 UTC",
      "updated_date": "2024-10-06 09:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:49:47.742700"
    },
    {
      "arxiv_id": "2410.04421v2",
      "title": "Disentangling Regional Primitives for Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengting Chen",
        "Lei Cheng",
        "Lianghui Ding",
        "Quanshi Zhang"
      ],
      "abstract": "This paper presents a method to explain the internal representation structure\nof a neural network for image generation. Specifically, our method disentangles\nprimitive feature components from the intermediate-layer feature of the neural\nnetwork, which ensures that each feature component is exclusively used to\ngenerate a specific set of image regions. In this way, the generation of the\nentire image can be considered as the superposition of different pre-encoded\nprimitive regional patterns, each being generated by a feature component. We\nfind that the feature component can be represented as an OR relationship\nbetween the demands for generating different image regions, which is encoded by\nthe neural network. Therefore, we extend the Harsanyi interaction to represent\nsuch an OR interaction to disentangle the feature component. Experiments show a\nclear correspondence between each feature component and the generation of\nspecific image regions.",
      "tldr_zh": "这篇论文提出了一种方法，用于解释神经网络在图像生成中的内部表示结构，通过从中间层特征中解耦原始特征组件（primitive feature components），确保每个组件仅用于生成特定图像区域，从而将整个图像生成视为不同预编码区域模式的叠加。作者发现这些特征组件可以表示为生成不同区域的 OR 关系，并扩展了 Harsanyi interaction 来实现这种解耦。实验结果显示，每个特征组件与特定图像区域的生成存在清晰对应，增强了对神经网络生成过程的理解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04421v2",
      "published_date": "2024-10-06 09:27:45 UTC",
      "updated_date": "2024-10-11 11:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:49:59.752793"
    },
    {
      "arxiv_id": "2410.04415v3",
      "title": "Geometric Analysis of Reasoning Trajectories: A Phase Space Approach to Understanding Valid and Invalid Multi-Hop Reasoning in LLMs",
      "title_zh": "推理轨迹的几何分析：相",
      "authors": [
        "Javier Marin"
      ],
      "abstract": "This paper proposes a novel approach to analyzing multi-hop reasoning in\nlanguage models through Hamiltonian mechanics. We map reasoning chains in\nembedding spaces to Hamiltonian systems, defining a function that balances\nreasoning progression (kinetic energy) against question relevance (potential\nenergy). Analyzing reasoning chains from a question-answering dataset reveals\nthat valid reasoning shows lower Hamiltonian energy values, representing an\noptimal trade-off between information gathering and targeted answering. While\nour framework offers complex visualization and quantification methods, the\nclaimed ability to \"steer\" or \"improve\" reasoning algorithms requires more\nrigorous empirical validation, as the connection between physical systems and\nreasoning remains largely metaphorical. Nevertheless, our analysis reveals\nconsistent geometric patterns distinguishing valid reasoning, suggesting this\nphysics-inspired approach offers promising diagnostic tools and new\nperspectives on reasoning processes in large language models.",
      "tldr_zh": "本研究提出了一种基于哈密顿力学(Hamiltonian mechanics)的几何分析方法，将语言模型(LLMs)中的多跳推理(multi-hop reasoning)轨迹映射到相空间(phase space)，通过平衡推理进展(kinetic energy)和问题相关性(potential energy)来量化推理过程。分析结果显示，有效推理链表现出较低的哈密顿能量值，代表了信息收集与针对性回答的优化权衡，并揭示了区分有效与无效推理的几何模式。尽管该框架提供复杂的可视化和量化工具，但其声称的“引导”或“改进”推理能力仍需更严格的实证验证。总体而言，此方法为理解LLMs的推理过程提供了新颖的诊断工具和物理学视角。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04415v3",
      "published_date": "2024-10-06 09:09:14 UTC",
      "updated_date": "2025-03-08 13:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:50:11.124870"
    },
    {
      "arxiv_id": "2410.09083v1",
      "title": "Alignment Between the Decision-Making Logic of LLMs and Human Cognition: A Case Study on Legal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Lu Chen",
        "Yuxuan Huang",
        "Yixing Li",
        "Yaohui Jin",
        "Shuai Zhao",
        "Zilong Zheng",
        "Quanshi Zhang"
      ],
      "abstract": "This paper presents a method to evaluate the alignment between the\ndecision-making logic of Large Language Models (LLMs) and human cognition in a\ncase study on legal LLMs. Unlike traditional evaluations on language generation\nresults, we propose to evaluate the correctness of the detailed decision-making\nlogic of an LLM behind its seemingly correct outputs, which represents the core\nchallenge for an LLM to earn human trust. To this end, we quantify the\ninteractions encoded by the LLM as primitive decision-making logic, because\nrecent theoretical achievements have proven several mathematical guarantees of\nthe faithfulness of the interaction-based explanation. We design a set of\nmetrics to evaluate the detailed decision-making logic of LLMs. Experiments\nshow that even when the language generation results appear correct, a\nsignificant portion of the internal inference logic contains notable issues.",
      "tldr_zh": "本论文提出了一种评估大型语言模型(LLMs)决策逻辑与人类认知对齐度的方法，通过一个法律LLMs的案例研究来实现。不同于传统的语言生成结果评估，该方法聚焦于量化LLMs中编码的交互作为原始决策逻辑，并设计一组指标来检验其详细决策逻辑的正确性，该方法基于最近的理论成果，确保了解释的可靠性。实验结果表明，即使LLMs的输出看似正确，其内部推理逻辑中仍存在显著问题，这突显了LLMs在赢得人类信任方面的核心挑战。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09083v1",
      "published_date": "2024-10-06 08:33:39 UTC",
      "updated_date": "2024-10-06 08:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:50:24.429800"
    },
    {
      "arxiv_id": "2410.04397v2",
      "title": "Towards Understanding and Enhancing Security of Proof-of-Training for DNN Model Ownership Verification",
      "title_zh": "迈向理解与增强 Proof-of-Training 在 DNN 模型所有权验证中的安全性",
      "authors": [
        "Yijia Chang",
        "Hanrui Jiang",
        "Chao Lin",
        "Xinyi Huang",
        "Jian Weng"
      ],
      "abstract": "The great economic values of deep neural networks (DNNs) urge AI enterprises\nto protect their intellectual property (IP) for these models. Recently,\nproof-of-training (PoT) has been proposed as a promising solution to DNN IP\nprotection, through which AI enterprises can utilize the record of DNN training\nprocess as their ownership proof. To prevent attackers from forging ownership\nproof, a secure PoT scheme should be able to distinguish honest training\nrecords from those forged by attackers. Although existing PoT schemes provide\nvarious distinction criteria, these criteria are based on intuitions or\nobservations. The effectiveness of these criteria lacks clear and comprehensive\nanalysis, resulting in existing schemes initially deemed secure being swiftly\ncompromised by simple ideas. In this paper, we make the first move to identify\ndistinction criteria in the style of formal methods, so that their\neffectiveness can be explicitly demonstrated. Specifically, we conduct\nsystematic modeling to cover a wide range of attacks and then theoretically\nanalyze the distinctions between honest and forged training records. The\nanalysis results not only induce a universal distinction criterion, but also\nprovide detailed reasoning to demonstrate its effectiveness in defending\nagainst attacks covered by our model. Guided by the criterion, we propose a\ngeneric PoT construction that can be instantiated into concrete schemes. This\nconstruction sheds light on the realization that trajectory matching\nalgorithms, previously employed in data distillation, possess significant\nadvantages in PoT construction. Experimental results demonstrate that our\nscheme can resist attacks that have compromised existing PoT schemes, which\ncorroborates its superiority in security.",
      "tldr_zh": "该论文探讨了Proof-of-Training (PoT) 在深度神经网络 (DNN) 模型所有权验证中的安全问题，旨在区分诚实训练记录与攻击者伪造记录。作者首次采用形式化方法进行系统建模，覆盖多种攻击，并理论分析训练记录的差异，从而提出一个通用区分标准，以证明其对抗攻击的有效性。基于此标准，他们设计了一个通用PoT构造，利用轨迹匹配算法（trajectory matching algorithms）来增强安全性。实验结果显示，该方案能成功抵御已知攻击，比现有PoT方案更具优势。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by USENIX Security 2025 (Major Revision -> Accept)",
      "pdf_url": "http://arxiv.org/pdf/2410.04397v2",
      "published_date": "2024-10-06 08:30:31 UTC",
      "updated_date": "2024-10-10 07:43:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:50:35.319867"
    },
    {
      "arxiv_id": "2410.10850v2",
      "title": "On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Toluwani Aremu",
        "Oluwakemi Akinwehinmi",
        "Chukwuemeka Nwagu",
        "Syed Ishtiaque Ahmed",
        "Rita Orji",
        "Pedro Arnau Del Amo",
        "Abdulmotaleb El Saddik"
      ],
      "abstract": "We investigate and observe the behaviour and performance of Large Language\nModel (LLM)-backed chatbots in addressing misinformed prompts and questions\nwith demographic information within the domains of Climate Change and Mental\nHealth. Through a combination of quantitative and qualitative methods, we\nassess the chatbots' ability to discern the veracity of statements, their\nadherence to facts, and the presence of bias or misinformation in their\nresponses. Our quantitative analysis using True/False questions reveals that\nthese chatbots can be relied on to give the right answers to these close-ended\nquestions. However, the qualitative insights, gathered from domain experts,\nshows that there are still concerns regarding privacy, ethical implications,\nand the necessity for chatbots to direct users to professional services. We\nconclude that while these chatbots hold significant promise, their deployment\nin sensitive areas necessitates careful consideration, ethical oversight, and\nrigorous refinement to ensure they serve as a beneficial augmentation to human\nexpertise rather than an autonomous solution.",
      "tldr_zh": "本文研究了 Large Language Models (LLM) 支持的聊天机器人处理误导信息和包含人口统计信息的提示的可靠性，重点关注气候变化和心理健康领域。通过定量分析（如 True/False 问题测试）和定性分析（领域专家反馈），结果显示聊天机器人能准确回答封闭式问题，但存在隐私、伦理问题和潜在偏见。研究强调，虽然 LLM 在这些领域有潜力作为人类专业知识的辅助工具，但其在敏感领域的部署需经过严格的伦理监督和优化，以避免成为自治解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Study conducted between August and December 2023. Under review at\n  AAAI-AI Magazine. Submitted for archival purposes only",
      "pdf_url": "http://arxiv.org/pdf/2410.10850v2",
      "published_date": "2024-10-06 07:40:11 UTC",
      "updated_date": "2024-10-17 11:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:50:47.302547"
    },
    {
      "arxiv_id": "2410.04368v1",
      "title": "Algorithmic Capabilities of Random Transformers",
      "title_zh": "随机Transformer的算法能力",
      "authors": [
        "Ziqian Zhong",
        "Jacob Andreas"
      ],
      "abstract": "Trained transformer models have been found to implement interpretable\nprocedures for tasks like arithmetic and associative recall, but little is\nunderstood about how the circuits that implement these procedures originate\nduring training. To what extent do they depend on the supervisory signal\nprovided to models, and to what extent are they attributable to behavior\nalready present in models at the beginning of training? To investigate these\nquestions, we investigate what functions can be learned by randomly initialized\ntransformers in which only the embedding layers are optimized, so that the only\ninput--output mappings learnable from data are those already implemented (up to\na choice of encoding scheme) by the randomly initialized model. We find that\nthese random transformers can perform a wide range of meaningful algorithmic\ntasks, including modular arithmetic, in-weights and in-context associative\nrecall, decimal addition, parenthesis balancing, and even some aspects of\nnatural language text generation. Our results indicate that some algorithmic\ncapabilities are present in transformers (and accessible via appropriately\nstructured inputs) even before these models are trained. Code is available at\nhttps://github.com/fjzzq2002/random_transformers.",
      "tldr_zh": "本研究探讨了随机初始化的 Transformer 模型在训练前是否已具备算法能力，通过仅优化嵌入层来测试模型能从数据中学习哪些输入-输出映射。结果显示，这些随机 Transformer 可以执行多种任务，包括 modular arithmetic、in-weights and in-context associative recall、decimal addition、parenthesis balancing 以及部分自然语言文本生成。研究表明，某些算法功能是 Transformer 固有的，并可通过适当的输入结构访问，为理解模型训练机制提供了新洞见。代码可在 GitHub 上获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04368v1",
      "published_date": "2024-10-06 06:04:23 UTC",
      "updated_date": "2024-10-06 06:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:50:58.874911"
    },
    {
      "arxiv_id": "2410.04366v1",
      "title": "RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory Waveform Estimation from PPG Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyang Miao",
        "Zehua Chen",
        "Chang Li",
        "Danilo Mandic"
      ],
      "abstract": "Respiratory rate (RR) is a critical health indicator often monitored under\ninconvenient scenarios, limiting its practicality for continuous monitoring.\nPhotoplethysmography (PPG) sensors, increasingly integrated into wearable\ndevices, offer a chance to continuously estimate RR in a portable manner. In\nthis paper, we propose RespDiff, an end-to-end multi-scale RNN diffusion model\nfor respiratory waveform estimation from PPG signals. RespDiff does not require\nhand-crafted features or the exclusion of low-quality signal segments, making\nit suitable for real-world scenarios. The model employs multi-scale encoders,\nto extract features at different resolutions, and a bidirectional RNN to\nprocess PPG signals and extract respiratory waveform. Additionally, a spectral\nloss term is introduced to optimize the model further. Experiments conducted on\nthe BIDMC dataset demonstrate that RespDiff outperforms notable previous works,\nachieving a mean absolute error (MAE) of 1.18 bpm for RR estimation while\nothers range from 1.66 to 2.15 bpm, showing its potential for robust and\naccurate respiratory monitoring in real-world applications.",
      "tldr_zh": "这篇论文提出了一种名为 RespDiff 的端到端多尺度 RNN 扩散模型，用于从 PPG 信号估计呼吸波形，从而实现便携式连续呼吸频率（RR）监测。模型无需手工特征提取或排除低质量信号段，通过多尺度编码器提取不同分辨率特征，并结合双向 RNN 处理 PPG 信号，同时引入 spectral loss 进一步优化性能。在 BIDMC 数据集上的实验中，RespDiff 实现了 RR 估计的 MAE 为 1.18 bpm，优于其他方法的 1.66 到 2.15 bpm，展示了其在真实场景中进行鲁棒呼吸监测的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04366v1",
      "published_date": "2024-10-06 05:54:49 UTC",
      "updated_date": "2024-10-06 05:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:51:11.547088"
    },
    {
      "arxiv_id": "2410.04364v3",
      "title": "VideoGuide: Improving Video Diffusion Models without Training Through a Teacher's Guide",
      "title_zh": "翻译失败",
      "authors": [
        "Dohun Lee",
        "Bryan S Kim",
        "Geon Yeong Park",
        "Jong Chul Ye"
      ],
      "abstract": "Text-to-image (T2I) diffusion models have revolutionized visual content\ncreation, but extending these capabilities to text-to-video (T2V) generation\nremains a challenge, particularly in preserving temporal consistency. Existing\nmethods that aim to improve consistency often cause trade-offs such as reduced\nimaging quality and impractical computational time. To address these issues we\nintroduce VideoGuide, a novel framework that enhances the temporal consistency\nof pretrained T2V models without the need for additional training or\nfine-tuning. Instead, VideoGuide leverages any pretrained video diffusion model\n(VDM) or itself as a guide during the early stages of inference, improving\ntemporal quality by interpolating the guiding model's denoised samples into the\nsampling model's denoising process. The proposed method brings about\nsignificant improvement in temporal consistency and image fidelity, providing a\ncost-effective and practical solution that synergizes the strengths of various\nvideo diffusion models. Furthermore, we demonstrate prior distillation,\nrevealing that base models can achieve enhanced text coherence by utilizing the\nsuperior data prior of the guiding model through the proposed method. Project\nPage: https://dohunlee1.github.io/videoguide.github.io/",
      "tldr_zh": "本文提出 VideoGuide，一种无需额外训练或 fine-tuning 的框架，用于提升文本到视频 (T2V) 扩散模型的 temporal consistency，同时避免现有方法带来的图像质量降低和计算时间增加问题。该框架利用预训练的 video diffusion model (VDM) 作为指导，在 inference 早期阶段通过插值 guiding model's denoised samples 到 sampling model's denoising process 中，显著改善视频的 temporal quality 和 image fidelity。此外，VideoGuide 支持 prior distillation，使基础模型通过 guiding model's superior data prior 提升 text coherence，提供了一个高效且实用的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages, 19 figures, Project Page:\n  https://dohunlee1.github.io/videoguide.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.04364v3",
      "published_date": "2024-10-06 05:46:17 UTC",
      "updated_date": "2024-12-08 18:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:51:23.990074"
    },
    {
      "arxiv_id": "2410.04360v2",
      "title": "GenSim: A General Social Simulation Platform with Large Language Model based Agents",
      "title_zh": "GenSim：基于大型语言模型的通用社会模拟平台",
      "authors": [
        "Jiakai Tang",
        "Heyang Gao",
        "Xuchen Pan",
        "Lei Wang",
        "Haoran Tan",
        "Dawei Gao",
        "Yushuo Chen",
        "Xu Chen",
        "Yankai Lin",
        "Yaliang Li",
        "Bolin Ding",
        "Jingren Zhou",
        "Jun Wang",
        "Ji-Rong Wen"
      ],
      "abstract": "With the rapid advancement of large language models (LLMs), recent years have\nwitnessed many promising studies on leveraging LLM-based agents to simulate\nhuman social behavior. While prior work has demonstrated significant potential\nacross various domains, much of it has focused on specific scenarios involving\na limited number of agents and has lacked the ability to adapt when errors\noccur during simulation. To overcome these limitations, we propose a novel\nLLM-agent-based simulation platform called \\textit{GenSim}, which: (1)\n\\textbf{Abstracts a set of general functions} to simplify the simulation of\ncustomized social scenarios; (2) \\textbf{Supports one hundred thousand agents}\nto better simulate large-scale populations in real-world contexts; (3)\n\\textbf{Incorporates error-correction mechanisms} to ensure more reliable and\nlong-term simulations. To evaluate our platform, we assess both the efficiency\nof large-scale agent simulations and the effectiveness of the error-correction\nmechanisms. To our knowledge, GenSim represents an initial step toward a\ngeneral, large-scale, and correctable social simulation platform based on LLM\nagents, promising to further advance the field of social science.",
      "tldr_zh": "这篇论文提出了 GenSim，一个基于 Large Language Model (LLMs) 的代理社交模拟平台，用于模拟人类社会行为。GenSim 通过抽象出一套通用函数，支持十万个代理的模拟，并整合错误修正机制，来简化自定义社会场景的构建，并确保模拟过程的可靠性和长期稳定性。实验评估显示，该平台在大型代理模拟效率和错误修正机制有效性方面表现出色，为基于 LLM agents 的通用、大规模社会模拟领域提供了初步框架。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04360v2",
      "published_date": "2024-10-06 05:02:23 UTC",
      "updated_date": "2024-10-09 09:03:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:51:34.627066"
    },
    {
      "arxiv_id": "2410.10849v1",
      "title": "Continuous Approximations for Improving Quantization Aware Training of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "He Li",
        "Jianhang Hong",
        "Yuanzhuo Wu",
        "Snehal Adbol",
        "Zonglin Li"
      ],
      "abstract": "Model compression methods are used to reduce the computation and energy\nrequirements for Large Language Models (LLMs). Quantization Aware Training\n(QAT), an effective model compression method, is proposed to reduce performance\ndegradation after quantization. To further minimize this degradation, we\nintroduce two continuous approximations to the QAT process on the rounding\nfunction, traditionally approximated by the Straight-Through Estimator (STE),\nand the clamping function. By applying both methods, the perplexity (PPL) on\nthe WikiText-v2 dataset of the quantized model reaches 9.0815, outperforming\n9.9621 by the baseline. Also, we achieve a 2.76% improvement on BoolQ, and a\n5.47% improvement on MMLU, proving that the step sizes and weights can be\nlearned more accurately with our approach. Our method achieves better\nperformance with the same precision, model size, and training setup,\ncontributing to the development of more energy-efficient LLMs technology that\naligns with global sustainability goals.",
      "tldr_zh": "本研究针对大语言模型(LLMs)的量化感知训练(Quantization Aware Training, QAT)，提出两种连续逼近方法来改进 rounding function 和 clamping function 的处理，取代传统 Straight-Through Estimator (STE)，从而减少量化后的性能下降。  \n通过这些方法，量化模型在 WikiText-v2 数据集上的 perplexity (PPL) 由基线的 9.9621 降至 9.0815，并在 BoolQ 和 MMLU 任务上分别实现了 2.76% 和 5.47% 的性能提升。  \n该方法在相同精度、模型大小和训练设置下表现出色，有助于开发更节能的 LLMs 技术，支持全球可持续发展目标。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10849v1",
      "published_date": "2024-10-06 04:33:06 UTC",
      "updated_date": "2024-10-06 04:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:51:48.673809"
    },
    {
      "arxiv_id": "2410.04345v1",
      "title": "MVP-Bench: Can Large Vision--Language Models Conduct Multi-level Visual Perception Like Humans?",
      "title_zh": "翻译失败",
      "authors": [
        "Guanzhen Li",
        "Yuxi Xie",
        "Min-Yen Kan"
      ],
      "abstract": "Humans perform visual perception at multiple levels, including low-level\nobject recognition and high-level semantic interpretation such as behavior\nunderstanding. Subtle differences in low-level details can lead to substantial\nchanges in high-level perception. For example, substituting the shopping bag\nheld by a person with a gun suggests violent behavior, implying criminal or\nviolent activity. Despite significant advancements in various multimodal tasks,\nLarge Visual-Language Models (LVLMs) remain unexplored in their capabilities to\nconduct such multi-level visual perceptions.\n  To investigate the perception gap between LVLMs and humans, we introduce\nMVP-Bench, the first visual-language benchmark systematically evaluating both\nlow- and high-level visual perception of LVLMs. We construct MVP-Bench across\nnatural and synthetic images to investigate how manipulated content influences\nmodel perception. Using MVP-Bench, we diagnose the visual perception of 10\nopen-source and 2 closed-source LVLMs, showing that high-level perception tasks\nsignificantly challenge existing LVLMs. The state-of-the-art GPT-4o only\nachieves an accuracy of $56\\%$ on Yes/No questions, compared with $74\\%$ in\nlow-level scenarios. Furthermore, the performance gap between natural and\nmanipulated images indicates that current LVLMs do not generalize in\nunderstanding the visual semantics of synthetic images as humans do. Our data\nand code are publicly available at https://github.com/GuanzhenLi/MVP-Bench.",
      "tldr_zh": "该论文探讨了大型视觉语言模型（LVLMs）是否能像人类一样进行多级视觉感知，包括低级物体识别和高高级义解释。研究者引入了首个系统性基准MVP-Bench，使用自然和合成图像评估LVLMs在操纵内容下的感知能力。实验结果显示，现有LVLMs在高水平感知任务上表现欠佳，例如GPT-4o在Yes/No问题的准确率仅为56%，远低于低级场景的74%。此外，模型在合成图像上的泛化能力不足，凸显了与人类感知的差距，并公开了相关数据和代码以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04345v1",
      "published_date": "2024-10-06 03:47:57 UTC",
      "updated_date": "2024-10-06 03:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:52:00.113899"
    },
    {
      "arxiv_id": "2410.17258v1",
      "title": "Representing Web Applications As Knowledge Graphs",
      "title_zh": "将 Web 应用程序表示为知识图谱",
      "authors": [
        "Yogesh Chandrasekharuni"
      ],
      "abstract": "Traditional methods for crawling and parsing web applications predominantly\nrely on extracting hyperlinks from initial pages and recursively following\nlinked resources. This approach constructs a graph where nodes represent\nunstructured data from web pages, and edges signify transitions between them.\nHowever, these techniques are limited in capturing the dynamic and interactive\nbehaviors inherent to modern web applications. In contrast, the proposed method\nmodels each node as a structured representation of the application's current\nstate, with edges reflecting user-initiated actions or transitions. This\nstructured representation enables a more comprehensive and functional\nunderstanding of web applications, offering valuable insights for downstream\ntasks such as automated testing and behavior analysis.",
      "tldr_zh": "这篇论文指出了传统 web 应用爬取方法（如提取超链接并构建非结构化图）的局限性，这些方法无法有效捕捉现代 web applications 的动态和交互行为。作者提出了一种新方法，将 web applications 表示为 Knowledge Graphs，其中节点是应用当前状态的结构化表示，边反映用户发起的动作或过渡。这种方法提升了对 web 应用的全面理解，并为下游任务如 automated testing 和 behavior analysis 提供了宝贵洞见。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17258v1",
      "published_date": "2024-10-06 02:50:41 UTC",
      "updated_date": "2024-10-06 02:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:52:10.838922"
    },
    {
      "arxiv_id": "2410.04332v2",
      "title": "Gradient Routing: Masking Gradients to Localize Computation in Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Cloud",
        "Jacob Goldman-Wetzler",
        "Evžen Wybitul",
        "Joseph Miller",
        "Alexander Matt Turner"
      ],
      "abstract": "Neural networks are trained primarily based on their inputs and outputs,\nwithout regard for their internal mechanisms. These neglected mechanisms\ndetermine properties that are critical for safety, like (i) transparency; (ii)\nthe absence of sensitive information or harmful capabilities; and (iii)\nreliable generalization of goals beyond the training distribution. To address\nthis shortcoming, we introduce gradient routing, a training method that\nisolates capabilities to specific subregions of a neural network. Gradient\nrouting applies data-dependent, weighted masks to gradients during\nbackpropagation. These masks are supplied by the user in order to configure\nwhich parameters are updated by which data points. We show that gradient\nrouting can be used to (1) learn representations which are partitioned in an\ninterpretable way; (2) enable robust unlearning via ablation of a pre-specified\nnetwork subregion; and (3) achieve scalable oversight of a reinforcement\nlearner by localizing modules responsible for different behaviors. Throughout,\nwe find that gradient routing localizes capabilities even when applied to a\nlimited, ad-hoc subset of the data. We conclude that the approach holds promise\nfor challenging, real-world applications where quality data are scarce.",
      "tldr_zh": "该论文提出 gradient routing，一种神经网络训练方法，通过在反向传播中应用数据相关的加权掩码，将网络能力隔离到特定子区域，从而提升透明度、消除敏感信息和确保可靠泛化。用户可配置掩码来指定哪些参数由哪些数据点更新，实现可解释的表示分区、鲁棒的 unlearning（如通过消融预指定子区域）和可扩展的 reinforcement learner 监督。实验结果显示，即使在数据有限的情况下，gradient routing 也能有效本地化能力，为数据稀缺的真实世界应用提供前景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04332v2",
      "published_date": "2024-10-06 02:43:49 UTC",
      "updated_date": "2024-11-29 18:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:52:23.271233"
    },
    {
      "arxiv_id": "2410.04328v1",
      "title": "OD-Stega: LLM-Based Near-Imperceptible Steganography via Optimized Distributions",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Shin Huang",
        "Peter Just",
        "Krishna Narayanan",
        "Chao Tian"
      ],
      "abstract": "We consider coverless steganography where a Large Language Model (LLM) drives\nan arithmetic coding decoder to generate stego-texts. An efficient method\nshould embed secret message bits in as few language tokens as possible, while\nstill keeping the stego-text natural and fluent. We show that on the individual\ntoken level, this problem is mathematically equivalent to maximizing the\nentropy of a replacement probability distribution of the next token generation,\nsubject to a constraint on the KL divergence between the chosen probability\ndistribution and the original distribution given by the LLM. A closed-form\nsolution is provided for the optimization problem, which can be computed\nefficiently. Several important practical issues are also tackled: 1) An\noften-overlooked tokenization mismatch issue is resolved with a simple prompt\nselection approach, 2) The combination of the optimized distribution and the\nvocabulary truncation technique is considered, and 3) The combination of the\noptimized distribution with other sequence-level selection heuristics to\nfurther enhance the efficiency and reliability is studied.",
      "tldr_zh": "这篇论文提出了 OD-Stega，一种基于 Large Language Model (LLM) 的近乎不可察觉的隐写术方法，通过优化概率分布来嵌入秘密消息位，同时保持生成文本的自然流畅。核心技术将问题建模为最大化下一个标记生成替换分布的熵，同时约束 KL divergence 与原始分布的差异，并提供了一个高效的闭式解。论文还解决了实际挑战，包括标记化不匹配问题、词汇截断技术的结合，以及与其他序列级选择启发式方法的整合，以提升隐写效率和可靠性。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.04328v1",
      "published_date": "2024-10-06 01:30:45 UTC",
      "updated_date": "2024-10-06 01:30:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:52:35.999644"
    },
    {
      "arxiv_id": "2410.05331v2",
      "title": "Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion",
      "title_zh": "翻译失败",
      "authors": [
        "Guanchu Wang",
        "Yu-Neng Chuang",
        "Ruixiang Tang",
        "Shaochen Zhong",
        "Jiayi Yuan",
        "Hongye Jin",
        "Zirui Liu",
        "Vipin Chaudhary",
        "Shuai Xu",
        "James Caverlee",
        "Xia Hu"
      ],
      "abstract": "Ensuring the security of released large language models (LLMs) poses a\nsignificant dilemma, as existing mechanisms either compromise ownership rights\nor raise data privacy concerns. To address this dilemma, we introduce TaylorMLP\nto protect the ownership of released LLMs and prevent their abuse.\nSpecifically, TaylorMLP preserves the ownership of LLMs by transforming the\nweights of LLMs into parameters of Taylor-series. Instead of releasing the\noriginal weights, developers can release the Taylor-series parameters with\nusers, thereby ensuring the security of LLMs. Moreover, TaylorMLP can prevent\nabuse of LLMs by adjusting the generation speed. It can induce low-speed token\ngeneration for the protected LLMs by increasing the terms in the Taylor-series.\nThis intentional delay helps LLM developers prevent potential large-scale\nunauthorized uses of their models. Empirical experiments across five datasets\nand three LLM architectures demonstrate that TaylorMLP induces over 4x increase\nin latency, producing the tokens precisely matched with original LLMs.\nSubsequent defensive experiments further confirm that TaylorMLP effectively\nprevents users from reconstructing the weight values based on downstream\ndatasets.",
      "tldr_zh": "这篇论文提出了 TaylorMLP 方法，通过 Taylor 展开将大型语言模型（LLMs）的权重转换为 Taylor-series 参数，从而保护模型所有权并解决发布过程中的安全困境。开发者可以发布这些参数而非原始权重，并通过增加 Taylor-series 中的项来有意降低生成速度，导致延迟增加超过4倍，以防止潜在的滥用。实验在五个数据集和三个 LLM 架构上验证了该方法的有效性，同时证明它能有效阻挡用户基于下游数据集重建权重值。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05331v2",
      "published_date": "2024-10-06 01:13:49 UTC",
      "updated_date": "2025-03-11 02:16:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:52:47.358240"
    },
    {
      "arxiv_id": "2410.04324v4",
      "title": "Where are we in audio deepfake detection? A systematic analysis over generative and detection models",
      "title_zh": "音频深度伪造检测的现状如何？针对生成模型和检测模型的系统分析",
      "authors": [
        "Xiang Li",
        "Pin-Yu Chen",
        "Wenqi Wei"
      ],
      "abstract": "Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using\ngenerative Artificial Intelligence (AI) technology have made it possible to\ngenerate high-quality and realistic human-like audio. This poses growing\nchallenges in distinguishing AI-synthesized speech from the genuine human voice\nand could raise concerns about misuse for impersonation, fraud, spreading\nmisinformation, and scams. However, existing detection methods for\nAI-synthesized audio have not kept pace and often fail to generalize across\ndiverse datasets. In this paper, we introduce SONAR, a synthetic AI-Audio\nDetection Framework and Benchmark, aiming to provide a comprehensive evaluation\nfor distinguishing cutting-edge AI-synthesized auditory content. SONAR includes\na novel evaluation dataset sourced from 9 diverse audio synthesis platforms,\nincluding leading TTS providers and state-of-the-art TTS models. It is the\nfirst framework to uniformly benchmark AI-audio detection across both\ntraditional and foundation model-based detection systems. Through extensive\nexperiments, (1) we reveal the limitations of existing detection methods and\ndemonstrate that foundation models exhibit stronger generalization\ncapabilities, likely due to their model size and the scale and quality of\npretraining data. (2) Speech foundation models demonstrate robust cross-lingual\ngeneralization capabilities, maintaining strong performance across diverse\nlanguages despite being fine-tuned solely on English speech data. This finding\nalso suggests that the primary challenges in audio deepfake detection are more\nclosely tied to the realism and quality of synthetic audio rather than\nlanguage-specific characteristics. (3) We explore the effectiveness and\nefficiency of few-shot fine-tuning in improving generalization, highlighting\nits potential for tailored applications, such as personalized detection systems\nfor specific entities or individuals.",
      "tldr_zh": "该论文系统分析了文本到语音(TTS)和语音转换(VC)生成AI技术在音频深度伪造检测领域的挑战，强调现有检测方法泛化能力不足。研究引入了SONAR框架和基准数据集，该框架首次统一评估传统和foundation model-based检测系统，使用来自9个音频合成平台的多样化数据。通过实验，发现foundation models因模型规模和预训练数据而表现出更强的泛化能力，speech foundation models在仅用英语数据微调的情况下仍具备稳健的跨语言性能，且few-shot fine-tuning能有效提升检测效率和针对性。总的来说，这为音频深度伪造检测提供了关键洞见和改进路径。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04324v4",
      "published_date": "2024-10-06 01:03:42 UTC",
      "updated_date": "2025-03-22 01:10:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:52:59.788002"
    },
    {
      "arxiv_id": "2410.04322v1",
      "title": "Toward Debugging Deep Reinforcement Learning Programs with RLExplorer",
      "title_zh": "翻译失败",
      "authors": [
        "Rached Bouchoucha",
        "Ahmed Haj Yahmed",
        "Darshan Patil",
        "Janarthanan Rajendran",
        "Amin Nikanjam",
        "Sarath Chandar",
        "Foutse Khomh"
      ],
      "abstract": "Deep reinforcement learning (DRL) has shown success in diverse domains such\nas robotics, computer games, and recommendation systems. However, like any\nother software system, DRL-based software systems are susceptible to faults\nthat pose unique challenges for debugging and diagnosing. These faults often\nresult in unexpected behavior without explicit failures and error messages,\nmaking debugging difficult and time-consuming. Therefore, automating the\nmonitoring and diagnosis of DRL systems is crucial to alleviate the burden on\ndevelopers. In this paper, we propose RLExplorer, the first fault diagnosis\napproach for DRL-based software systems. RLExplorer automatically monitors\ntraining traces and runs diagnosis routines based on properties of the DRL\nlearning dynamics to detect the occurrence of DRL-specific faults. It then logs\nthe results of these diagnoses as warnings that cover theoretical concepts,\nrecommended practices, and potential solutions to the identified faults. We\nconducted two sets of evaluations to assess RLExplorer. Our first evaluation of\nfaulty DRL samples from Stack Overflow revealed that our approach can\neffectively diagnose real faults in 83% of the cases. Our second evaluation of\nRLExplorer with 15 DRL experts/developers showed that (1) RLExplorer could\nidentify 3.6 times more defects than manual debugging and (2) RLExplorer is\neasily integrated into DRL applications.",
      "tldr_zh": "本文提出 RLExplorer，一种针对深度强化学习(DRL)软件系统的首创故障诊断方法，用于自动监控训练痕迹并基于 DRL 学习动态的属性检测特定故障，同时提供警告包括理论概念、推荐实践和潜在解决方案。实验评估显示，RLExplorer 在 Stack Overflow 的真实 DRL 故障样本中有效诊断了83%的案例。相比手动调试，该方法能识别 3.6 倍的缺陷，且易于集成到 DRL 应用中，从而显著减轻开发者的调试负担。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication in The International Conference on Software\n  Maintenance and Evolution (ICSME 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.04322v1",
      "published_date": "2024-10-06 01:01:21 UTC",
      "updated_date": "2024-10-06 01:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:53:11.242051"
    },
    {
      "arxiv_id": "2410.04320v2",
      "title": "Channel-Aware Throughput Maximization for Cooperative Data Fusion in CAV",
      "title_zh": "翻译失败",
      "authors": [
        "Haonan An",
        "Zhengru Fang",
        "Yuang Zhang",
        "Senkang Hu",
        "Xianhao Chen",
        "Guowen Xu",
        "Yuguang Fang"
      ],
      "abstract": "Connected and autonomous vehicles (CAVs) have garnered significant attention\ndue to their extended perception range and enhanced sensing coverage. To\naddress challenges such as blind spots and obstructions, CAVs employ\nvehicle-to-vehicle (V2V) communications to aggregate sensory data from\nsurrounding vehicles. However, cooperative perception is often constrained by\nthe limitations of achievable network throughput and channel quality. In this\npaper, we propose a channel-aware throughput maximization approach to\nfacilitate CAV data fusion, leveraging a self-supervised autoencoder for\nadaptive data compression. We formulate the problem as a mixed integer\nprogramming (MIP) model, which we decompose into two sub-problems to derive\noptimal data rate and compression ratio solutions under given link conditions.\nAn autoencoder is then trained to minimize bitrate with the determined\ncompression ratio, and a fine-tuning strategy is employed to further reduce\nspectrum resource consumption. Experimental evaluation on the OpenCOOD platform\ndemonstrates the effectiveness of our proposed algorithm, showing more than\n20.19\\% improvement in network throughput and a 9.38\\% increase in average\nprecision (AP@IoU) compared to state-of-the-art methods, with an optimal\nlatency of 19.99 ms.",
      "tldr_zh": "本论文针对CAV（Connected and Autonomous Vehicles）中的合作数据融合问题，提出了一种基于信道的吞吐量最大化方法，利用自监督autoencoder进行自适应数据压缩，以克服V2V通信的网络限制。方法将问题形式化为MIP（Mixed Integer Programming）模型，并分解为两个子问题，优化数据速率和压缩比，同时训练autoencoder最小化比特率并通过微调策略降低频谱资源消耗。实验结果在OpenCOOD平台上显示，该算法比现有方法提升了20.19%的网络吞吐量和9.38%的AP@IoU（Average Precision at IoU），并实现了19.99 ms的优化延迟。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04320v2",
      "published_date": "2024-10-06 00:43:46 UTC",
      "updated_date": "2025-04-28 01:50:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:53:24.278931"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 59,
  "processed_papers_count": 59,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T07:53:41.044260"
}