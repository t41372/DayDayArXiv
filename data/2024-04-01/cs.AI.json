{
  "date": "2024-04-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-01 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLMs）的优化、多模态生成、计算机视觉应用以及强化学习等，重点突出 LLMs 在科学和生成任务中的潜力与挑战，令人印象深刻的文章有那些探讨 LLMs 是否超越人类在化学领域的表现，以及多模态模型的创新方法。\n\n下面，我将挑选最具话题度和影响力的论文进行简要讨论，将相关主题（如 LLMs 和视觉模型）归类放在一起，对其他较次要的论文快速掠过。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### LLMs 和生成模型\n- **Are large language models superhuman chemists?（大型语言模型是否超越人类化学家？）**  \n  作者包括 Philippe Schwaller 和 Kevin Maik Jablonka 等知名学者。该文构建了 ChemBench 基准框架，使用超过 2700 个问题评估 LLMs 在化学知识和推理上的表现，发现顶级模型如 GPT-4 平均超越人类，但存在过度自信和基本任务错误的问题，强调了改进 LLMs 安全性和实用性的必要性。\n  \n- **Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward（基于语言模型奖励的视频大型多模态模型直接偏好优化）**  \n  该文提出一种优化框架，使用语言模型作为奖励函数来提升视频多模态模型的性能，通过实验证明了其在视频问答任务中的鲁棒性，显著提高了模型对真实视频的响应准确性。\n\n- **Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data（模型崩溃不可避免吗？通过积累真实和合成数据打破递归诅咒）**  \n  作者包括 David L. Donoho 和 Sanmi Koyejo。该文通过理论和实验证明，积累真实和合成数据可以避免模型在训练循环中的崩溃现象，并在文本、分子和图像生成任务中展示了这种方法的有效性。\n\n- **Self-Demos: Eliciting Out-of-Demonstration Generalizability in Large Language Models（Self-Demos：激发大型语言模型的超出演示泛化能力）**  \n  该文引入 Self-Demos 方法，通过生成查询相关的演示来提升 LLMs 在工具使用等任务中的泛化能力，实验显示其在工具集数据集上提高了 25% 的准确率。\n\n- **Prompt-prompted Adaptive Structured Pruning for Efficient LLM Generation（基于提示引导的自适应结构化剪枝用于高效的 LLM 生成）**  \n  该文提出 GRIFFIN 方法，通过提示引导的自适应剪枝减少 LLM 参数，同时保持性能，实验在分类和生成任务中实现了 1.25 倍的速度提升。\n\n其他 LLMs 相关论文，如关于 LLMs 偏差的分析和评估框架，显示了模型在多语言和时间数据上的挑战，但细节较常规，故快速掠过。\n\n### 计算机视觉和图像处理\n- **On Train-Test Class Overlap and Detection for Image Retrieval（训练-测试类重叠及其在图像检索中的检测）**  \n  CVPR 2024 接受。该文识别并移除 Google Landmarks v2 中的类重叠问题，提出 CiDeR 管道，通过端到端检测提升图像检索性能，实验显示其在基准数据集上超越了现有方法。\n\n- **Can Biases in ImageNet Models Explain Generalization?（ImageNet 模型中的偏差能解释泛化吗？）**  \n  CVPR 2024 接受。该文通过大规模实验分析 ImageNet 模型的形状偏差和光谱偏差，发现这些偏差不足以全面预测模型泛化，提供了新的理解和代码资源。\n\n- **NeRF-MAE: Masked AutoEncoders for Self-Supervised 3D Representation Learning for Neural Radiance Fields（NeRF-MAE：用于神经辐射场自监督 3D 表示学习的掩码自动编码器）**  \n  ECCV 2024 接受。该文提出 NeRF-MAE 方法，使用掩码自动编码器在 3D 场景上进行自监督学习，实验在 Front3D 和 ScanNet 数据集上提升了 20% 的检测性能。\n\n- **Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On（保持纹理的扩散模型用于高保真虚拟试穿）**  \n  该文开发了 TPD 模型，通过空间拼接和掩码预测实现服装纹理的高保真传输，实验在虚拟试穿任务中超越了 SOTA 方法。\n\n其他视觉论文，如小对象检测和 3D 重建方法，在特定任务上表现出色，但整体影响较小，故简要提及。\n\n### 强化学习和多模态应用\n- **QuAD: Query-based Interpretable Neural Motion Planning for Autonomous Driving（QuAD：基于查询的可解释神经运动规划用于自动驾驶）**  \n  该文提出 QuAD 框架，通过查询占用网格进行可解释的自动驾驶规划，实验在模拟环境中超越了 SOTA，在碰撞避免和舒适性上表现出色。\n\n- **Game-Theoretic Deep Reinforcement Learning to Minimize Carbon Emissions and Energy Costs for AI Inference Workloads（博弈论深度强化学习用于最小化 AI 推理工作负载的碳排放和能源成本）**  \n  该文结合博弈论和 DRL 优化数据中心负载分配，实验显示其在减少碳排放和成本上优于现有方法。\n\n其他强化学习论文，如城市规划中的应用，展示了实际潜力，但细节较为技术化，故快速掠过。\n\n### 其他领域快速掠过\n今天的论文还包括量子计算、医疗图像和文本生成等领域，如 \"VortexViz\" 在流体模拟中使用了神经网络，但这些主题较 niche，且贡献不具广泛话题度，仅提及其在特定领域（如医疗分割）的技术进步。同样，哲学性论文如 \"Cooperative Evolutionary Pressure and Diminishing Returns Might Explain the Fermi Paradox\" 探讨了 AI 与进化理论，但影响力有限。\n\n总之，今天 arXiv 的论文突显了 AI 模型的优化和应用潜力，但也暴露了偏差和泛化挑战。感兴趣的读者可关注 LLMs 和视觉领域的创新，以推动更可靠的 AI 系统。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2404.01526v1",
      "title": "Categorical semiotics: Foundations for Knowledge Integration",
      "title_zh": "范畴符号学：知识集成的基础",
      "authors": [
        "Carlos Leandro"
      ],
      "abstract": "The integration of knowledge extracted from diverse models, whether described\nby domain experts or generated by machine learning algorithms, has historically\nbeen challenged by the absence of a suitable framework for specifying and\nintegrating structures, learning processes, data transformations, and data\nmodels or rules. In this work, we extend algebraic specification methods to\naddress these challenges within such a framework.\n  In our work, we tackle the challenging task of developing a comprehensive\nframework for defining and analyzing deep learning architectures. We believe\nthat previous efforts have fallen short by failing to establish a clear\nconnection between the constraints a model must adhere to and its actual\nimplementation.\n  Our methodology employs graphical structures that resemble Ehresmann's\nsketches, interpreted within a universe of fuzzy sets. This approach offers a\nunified theory that elegantly encompasses both deterministic and\nnon-deterministic neural network designs. Furthermore, we highlight how this\ntheory naturally incorporates fundamental concepts from computer science and\nautomata theory. Our extended algebraic specification framework, grounded in\ngraphical structures akin to Ehresmann's sketches, offers a promising solution\nfor integrating knowledge across disparate models and domains. By bridging the\ngap between domain-specific expertise and machine-generated insights, we pave\nthe way for more comprehensive, collaborative, and effective approaches to\nknowledge integration and modeling.",
      "tldr_zh": "这篇论文提出了一种基于范畴符号学的框架，用于解决从不同来源（如领域专家或机器学习算法）提取知识的整合挑战，扩展了algebraic specification methods来指定和整合结构、学习过程、数据转换以及数据模型或规则。作者采用类似于Ehresmann's sketches的图形结构，在fuzzy sets的宇宙中进行解释，从而为定义和分析deep learning architectures提供一个统一理论，该理论涵盖了确定性和非确定性神经网络设计，并整合了计算机科学和automata theory的基本概念。该框架桥接了领域特定专业知识与机器生成洞见，促进了更全面的知识整合和建模。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "71 pages, 15 figures. arXiv admin note: substantial text overlap with\n  arXiv:1604.02790",
      "pdf_url": "http://arxiv.org/pdf/2404.01526v1",
      "published_date": "2024-04-01 23:19:01 UTC",
      "updated_date": "2024-04-01 23:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:35:12.847871"
    },
    {
      "arxiv_id": "2404.01524v1",
      "title": "On Train-Test Class Overlap and Detection for Image Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Chull Hwan Song",
        "Jooyoung Yoon",
        "Taebaek Hwang",
        "Shunghyun Choi",
        "Yeong Hyeon Gu",
        "Yannis Avrithis"
      ],
      "abstract": "How important is it for training and evaluation sets to not have class\noverlap in image retrieval? We revisit Google Landmarks v2 clean, the most\npopular training set, by identifying and removing class overlap with Revisited\nOxford and Paris [34], the most popular evaluation set. By comparing the\noriginal and the new RGLDv2-clean on a benchmark of reproduced state-of-the-art\nmethods, our findings are striking. Not only is there a dramatic drop in\nperformance, but it is inconsistent across methods, changing the ranking.What\ndoes it take to focus on objects or interest and ignore background clutter when\nindexing? Do we need to train an object detector and the representation\nseparately? Do we need location supervision? We introduce Single-stage\nDetect-to-Retrieve (CiDeR), an end-to-end, single-stage pipeline to detect\nobjects of interest and extract a global image representation. We outperform\nprevious state-of-the-art on both existing training sets and the new\nRGLDv2-clean. Our dataset is available at\nhttps://github.com/dealicious-inc/RGLDv2-clean.",
      "tldr_zh": "这篇论文探讨了图像检索中训练集和测试集类重叠的影响，通过移除Google Landmarks v2 clean与Revisited Oxford and Paris的重叠，发现性能大幅下降且不同方法的排名发生变化。作者强调了关注对象而忽略背景杂物的必要性，并引入了Single-stage Detect-to-Retrieve (CiDeR)，一个端到端单阶段管道，用于检测感兴趣的对象并提取全局图像表示。新方法在现有数据集和新RGLDv2-clean数据集上超过了先前的状态-of-the-art性能，为图像检索的鲁棒性提供了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2404.01524v1",
      "published_date": "2024-04-01 23:11:15 UTC",
      "updated_date": "2024-04-01 23:11:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:35:25.949127"
    },
    {
      "arxiv_id": "2404.01509v1",
      "title": "Can Biases in ImageNet Models Explain Generalization?",
      "title_zh": "ImageNet 模型中的偏差能解释泛化吗？",
      "authors": [
        "Paul Gavrikov",
        "Janis Keuper"
      ],
      "abstract": "The robust generalization of models to rare, in-distribution (ID) samples\ndrawn from the long tail of the training distribution and to\nout-of-training-distribution (OOD) samples is one of the major challenges of\ncurrent deep learning methods. For image classification, this manifests in the\nexistence of adversarial attacks, the performance drops on distorted images,\nand a lack of generalization to concepts such as sketches. The current\nunderstanding of generalization in neural networks is very limited, but some\nbiases that differentiate models from human vision have been identified and\nmight be causing these limitations. Consequently, several attempts with varying\nsuccess have been made to reduce these biases during training to improve\ngeneralization. We take a step back and sanity-check these attempts. Fixing the\narchitecture to the well-established ResNet-50, we perform a large-scale study\non 48 ImageNet models obtained via different training methods to understand how\nand if these biases - including shape bias, spectral biases, and critical bands\n- interact with generalization. Our extensive study results reveal that\ncontrary to previous findings, these biases are insufficient to accurately\npredict the generalization of a model holistically. We provide access to all\ncheckpoints and evaluation code at\nhttps://github.com/paulgavrikov/biases_vs_generalization",
      "tldr_zh": "这篇论文探讨了ImageNet模型中的偏差（如shape bias、spectral biases和critical bands）是否能解释其泛化能力，包括对罕见分布内样本和分布外（OOD）样本的鲁棒性。作者采用ResNet-50架构，训练了48个不同方法的模型，进行大规模实证研究，分析这些偏差与泛化的交互关系。结果显示，这些偏差不足以全面预测模型的整体泛化表现，挑战了先前减少偏差以改善泛化的尝试。论文提供了代码和检查点资源，以促进进一步复现和验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01509v1",
      "published_date": "2024-04-01 22:25:48 UTC",
      "updated_date": "2024-04-01 22:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:35:37.279299"
    },
    {
      "arxiv_id": "2404.01503v1",
      "title": "Some Orders Are Important: Partially Preserving Orders in Top-Quality Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Katz",
        "Junkyu Lee",
        "Jungkoo Kang",
        "Shirin Sohrabi"
      ],
      "abstract": "The ability to generate multiple plans is central to using planning in\nreal-life applications. Top-quality planners generate sets of such top-cost\nplans, allowing flexibility in determining equivalent ones. In terms of the\norder between actions in a plan, the literature only considers two extremes --\neither all orders are important, making each plan unique, or all orders are\nunimportant, treating two plans differing only in the order of actions as\nequivalent. To allow flexibility in selecting important orders, we propose\nspecifying a subset of actions the orders between which are important,\ninterpolating between the top-quality and unordered top-quality planning\nproblems. We explore the ways of adapting partial order reduction search\npruning techniques to address this new computational problem and present\nexperimental evaluations demonstrating the benefits of exploiting such\ntechniques in this setting.",
      "tldr_zh": "该论文探讨了在顶尖质量规划(top-quality planning)中部分保留动作顺序的重要性，介于所有顺序均重要与均不重要两种极端之间。作者提出了一种新方法，允许用户指定子集动作的顺序为重要，从而在 top-quality 和 unordered top-quality 规划问题间进行插值。论文还适应了部分顺序减少(partial order reduction)搜索修剪技术来解决这一计算问题，并通过实验评估证明了该方法的益处，提升了规划的灵活性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at SoCS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01503v1",
      "published_date": "2024-04-01 22:10:12 UTC",
      "updated_date": "2024-04-01 22:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:35:48.827726"
    },
    {
      "arxiv_id": "2404.01492v3",
      "title": "Modality Translation for Object Detection Adaptation Without Forgetting Prior Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Heitor Rapela Medeiros",
        "Masih Aminbeidokhti",
        "Fidel Guerrero Pena",
        "David Latortue",
        "Eric Granger",
        "Marco Pedersoli"
      ],
      "abstract": "A common practice in deep learning involves training large neural networks on\nmassive datasets to achieve high accuracy across various domains and tasks.\nWhile this approach works well in many application areas, it often fails\ndrastically when processing data from a new modality with a significant\ndistribution shift from the data used to pre-train the model. This paper\nfocuses on adapting a large object detection model trained on RGB images to new\ndata extracted from IR images with a substantial modality shift. We propose\nModality Translator (ModTr) as an alternative to the common approach of\nfine-tuning a large model to the new modality. ModTr adapts the IR input image\nwith a small transformation network trained to directly minimize the detection\nloss. The original RGB model can then work on the translated inputs without any\nfurther changes or fine-tuning to its parameters. Experimental results on\ntranslating from IR to RGB images on two well-known datasets show that our\nsimple approach provides detectors that perform comparably or better than\nstandard fine-tuning, without forgetting the knowledge of the original model.\nThis opens the door to a more flexible and efficient service-based detection\npipeline, where a unique and unaltered server, such as an RGB detector, runs\nconstantly while being queried by different modalities, such as IR with the\ncorresponding translations model. Our code is available at:\nhttps://github.com/heitorrapela/ModTr.",
      "tldr_zh": "本研究探讨了深度学习模型在处理新模态数据（如IR图像）时的适应挑战，特别是在避免遗忘原有RGB图像训练知识的前提下。作者提出Modality Translator (ModTr)，一个小型转换网络，通过直接最小化检测损失来转换IR输入图像，使其适应未经微调的原RGB模型。实验结果显示，在两个知名数据集上，ModTr方法使检测性能与标准fine-tuning相当或更好，同时保持了原模型的知识完整性，从而实现更灵活、高效的服务型检测管道。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024: European Conference on Computer Vision, Milan Italy",
      "pdf_url": "http://arxiv.org/pdf/2404.01492v3",
      "published_date": "2024-04-01 21:28:50 UTC",
      "updated_date": "2024-07-31 21:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:36:01.002486"
    },
    {
      "arxiv_id": "2404.01486v1",
      "title": "QuAD: Query-based Interpretable Neural Motion Planning for Autonomous Driving",
      "title_zh": "QuAD:",
      "authors": [
        "Sourav Biswas",
        "Sergio Casas",
        "Quinlan Sykora",
        "Ben Agro",
        "Abbas Sadat",
        "Raquel Urtasun"
      ],
      "abstract": "A self-driving vehicle must understand its environment to determine the\nappropriate action. Traditional autonomy systems rely on object detection to\nfind the agents in the scene. However, object detection assumes a discrete set\nof objects and loses information about uncertainty, so any errors compound when\npredicting the future behavior of those agents. Alternatively, dense occupancy\ngrid maps have been utilized to understand free-space. However, predicting a\ngrid for the entire scene is wasteful since only certain spatio-temporal\nregions are reachable and relevant to the self-driving vehicle. We present a\nunified, interpretable, and efficient autonomy framework that moves away from\ncascading modules that first perceive, then predict, and finally plan. Instead,\nwe shift the paradigm to have the planner query occupancy at relevant\nspatio-temporal points, restricting the computation to those regions of\ninterest. Exploiting this representation, we evaluate candidate trajectories\naround key factors such as collision avoidance, comfort, and progress for\nsafety and interpretability. Our approach achieves better highway driving\nquality than the state-of-the-art in high-fidelity closed-loop simulations.",
      "tldr_zh": "本研究提出QuAD框架，一种基于查询的神经运动规划方法，用于提升自动驾驶车辆的安全性和可解释性。传统系统依赖物体检测或密集占用网格图，但这些方法存在信息丢失和计算浪费的问题；QuAD通过让规划器直接查询相关时空区域的占用信息，避免了级联感知-预测-规划模块，从而高效评估候选轨迹，考虑碰撞避免、舒适度和进展等关键因素。在高保真闭环模拟中，QuAD在高速公路驾驶质量上超过了现有技术。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01486v1",
      "published_date": "2024-04-01 21:11:43 UTC",
      "updated_date": "2024-04-01 21:11:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:36:12.146647"
    },
    {
      "arxiv_id": "2404.01476v2",
      "title": "TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Chuyi Shang",
        "Amos You",
        "Sanjay Subramanian",
        "Trevor Darrell",
        "Roei Herzig"
      ],
      "abstract": "Recently, image-based Large Multimodal Models (LMMs) have made significant\nprogress in video question-answering (VideoQA) using a frame-wise approach by\nleveraging large-scale pretraining in a zero-shot manner. Nevertheless, these\nmodels need to be capable of finding relevant information, extracting it, and\nanswering the question simultaneously. Currently, existing methods perform all\nof these steps in a single pass without being able to adapt if insufficient or\nincorrect information is collected. To overcome this, we introduce a modular\nmulti-LMM agent framework based on several agents with different roles,\ninstructed by a Planner agent that updates its instructions using shared\nfeedback from the other agents. Specifically, we propose TraveLER, a method\nthat can create a plan to \"Traverse\" through the video, ask questions about\nindividual frames to \"Locate\" and store key information, and then \"Evaluate\" if\nthere is enough information to answer the question. Finally, if there is not\nenough information, our method is able to \"Replan\" based on its collected\nknowledge. Through extensive experiments, we find that the proposed TraveLER\napproach improves performance on several VideoQA benchmarks without the need to\nfine-tune on specific datasets. Our code is available at\nhttps://github.com/traveler-framework/TraveLER.",
      "tldr_zh": "该研究提出TraveLER，一种模块化多-LMM代理框架，用于提升视频问答(VideoQA)任务的性能。该框架由Planner代理指导多个角色代理，通过“Traverse”（遍历视频）、“Locate”（定位并存储关键信息）、“Evaluate”（评估信息充足性）和“Replan”（基于反馈重新规划）的流程，解决现有LMMs在信息提取和适应性方面的不足。实验结果显示，TraveLER在多个VideoQA基准上实现了性能提升，且无需在特定数据集上进行微调，为更灵活的视频理解提供了新方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2024 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2404.01476v2",
      "published_date": "2024-04-01 20:58:24 UTC",
      "updated_date": "2024-10-19 19:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:36:24.807900"
    },
    {
      "arxiv_id": "2404.01475v2",
      "title": "Are large language models superhuman chemists?",
      "title_zh": "翻译失败",
      "authors": [
        "Adrian Mirza",
        "Nawaf Alampara",
        "Sreekanth Kunchapu",
        "Martiño Ríos-García",
        "Benedict Emoekabu",
        "Aswanth Krishnan",
        "Tanya Gupta",
        "Mara Schilling-Wilhelmi",
        "Macjonathan Okereke",
        "Anagha Aneesh",
        "Amir Mohammad Elahi",
        "Mehrdad Asgari",
        "Juliane Eberhardt",
        "Hani M. Elbeheiry",
        "María Victoria Gil",
        "Maximilian Greiner",
        "Caroline T. Holick",
        "Christina Glaubitz",
        "Tim Hoffmann",
        "Abdelrahman Ibrahim",
        "Lea C. Klepsch",
        "Yannik Köster",
        "Fabian Alexander Kreth",
        "Jakob Meyer",
        "Santiago Miret",
        "Jan Matthias Peschel",
        "Michael Ringleb",
        "Nicole Roesner",
        "Johanna Schreiber",
        "Ulrich S. Schubert",
        "Leanne M. Stafast",
        "Dinga Wonanke",
        "Michael Pieler",
        "Philippe Schwaller",
        "Kevin Maik Jablonka"
      ],
      "abstract": "Large language models (LLMs) have gained widespread interest due to their\nability to process human language and perform tasks on which they have not been\nexplicitly trained.\n  However, we possess only a limited systematic understanding of the chemical\ncapabilities of LLMs, which would be required to improve models and mitigate\npotential harm. Here, we introduce \"ChemBench,\" an automated framework for\nevaluating the chemical knowledge and reasoning abilities of state-of-the-art\nLLMs against the expertise of chemists.\n  We curated more than 2,700 question-answer pairs, evaluated leading open- and\nclosed-source LLMs, and found that the best models outperformed the best human\nchemists in our study on average. However, the models struggle with some basic\ntasks and provide overconfident predictions.\n  These findings reveal LLMs' impressive chemical capabilities while\nemphasizing the need for further research to improve their safety and\nusefulness. They also suggest adapting chemistry education and show the value\nof benchmarking frameworks for evaluating LLMs in specific domains.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在化学领域的能力，引入了“ChemBench”自动化框架来测试其化学知识和推理能力，并与人类化学家进行比较。该框架基于超过2,700个问题-答案对，评估了领先的开源和闭源LLMs，发现最佳模型在平均表现上超过了研究中的顶级人类化学家。然而，LLMs在某些基本任务上表现不佳，并倾向于提供过度自信的预测。这些发现突出了LLMs的强大化学潜力，同时强调了进一步研究以提升其安全性和实用性，并建议调整化学教育及推广benchmarking frameworks用于领域特定评估。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01475v2",
      "published_date": "2024-04-01 20:56:25 UTC",
      "updated_date": "2024-11-01 07:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:36:36.932552"
    },
    {
      "arxiv_id": "2404.03686v1",
      "title": "Securing Social Spaces: Harnessing Deep Learning to Eradicate Cyberbullying",
      "title_zh": "保护社交空间：利用深度学习根除网络欺凌",
      "authors": [
        "Rohan Biswas",
        "Kasturi Ganguly",
        "Arijit Das",
        "Diganta Saha"
      ],
      "abstract": "In today's digital world, cyberbullying is a serious problem that can harm\nthe mental and physical health of people who use social media. This paper\nexplains just how serious cyberbullying is and how it really affects\nindi-viduals exposed to it. It also stresses how important it is to find better\nways to detect cyberbullying so that online spaces can be safer. Plus, it talks\nabout how making more accurate tools to spot cyberbullying will be really\nhelpful in the future. Our paper introduces a deep learning-based ap-proach,\nprimarily employing BERT and BiLSTM architectures, to effective-ly address\ncyberbullying. This approach is designed to analyse large vol-umes of posts and\npredict potential instances of cyberbullying in online spaces. Our results\ndemonstrate the superiority of the hateBERT model, an extension of BERT focused\non hate speech detection, among the five mod-els, achieving an accuracy rate of\n89.16%. This research is a significant con-tribution to \"Computational\nIntelligence for Social Transformation,\" prom-ising a safer and more inclusive\ndigital landscape.",
      "tldr_zh": "本论文探讨了网络欺凌对个体心理和身体健康的严重影响，并强调了开发更准确的检测工具以提升在线空间安全的重要性。研究引入了一种基于深度学习的检测方法，主要利用 BERT 和 BiLSTM 架构，特别是 hateBERT 模型，来分析海量社交媒体帖子并预测潜在的网络欺凌实例。实验结果显示，hateBERT 在五种模型中表现出色，准确率达到 89.16%，为计算智能在社会变革中的应用提供了重要贡献，推动了更安全、包容的数字环境。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03686v1",
      "published_date": "2024-04-01 20:41:28 UTC",
      "updated_date": "2024-04-01 20:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:36:48.800212"
    },
    {
      "arxiv_id": "2405.14875v1",
      "title": "BloodCell-Net: A lightweight convolutional neural network for the classification of all microscopic blood cell images of the human body",
      "title_zh": "BloodCell-Net：一种轻量级卷",
      "authors": [
        "Sohag Kumar Mondal",
        "Md. Simul Hasan Talukder",
        "Mohammad Aljaidi",
        "Rejwan Bin Sulaiman",
        "Md Mohiuddin Sarker Tushar",
        "Amjad A Alsuwaylimi"
      ],
      "abstract": "Blood cell classification and counting are vital for the diagnosis of various\nblood-related diseases, such as anemia, leukemia, and thrombocytopenia. The\nmanual process of blood cell classification and counting is time-consuming,\nprone to errors, and labor-intensive. Therefore, we have proposed a DL based\nautomated system for blood cell classification and counting from microscopic\nblood smear images. We classify total of nine types of blood cells, including\nErythrocyte, Erythroblast, Neutrophil, Basophil, Eosinophil, Lymphocyte,\nMonocyte, Immature Granulocytes, and Platelet. Several preprocessing steps like\nimage resizing, rescaling, contrast enhancement and augmentation are utilized.\nTo segment the blood cells from the entire microscopic images, we employed the\nU-Net model. This segmentation technique aids in extracting the region of\ninterest (ROI) by removing complex and noisy background elements. Both\npixel-level metrics such as accuracy, precision, and sensitivity, and\nobject-level evaluation metrics like Intersection over Union (IOU) and Dice\ncoefficient are considered to comprehensively evaluate the performance of the\nU-Net model. The segmentation model achieved impressive performance metrics,\nincluding 98.23% accuracy, 98.40% precision, 98.25% sensitivity, 95.97%\nIntersection over Union (IOU), and 97.92% Dice coefficient. Subsequently, a\nwatershed algorithm is applied to the segmented images to separate overlapped\nblood cells and extract individual cells. We have proposed a BloodCell-Net\napproach incorporated with custom light weight convolutional neural network\n(LWCNN) for classifying individual blood cells into nine types. Comprehensive\nevaluation of the classifier's performance is conducted using metrics including\naccuracy, precision, recall, and F1 score. The classifier achieved an average\naccuracy of 97.10%, precision of 97.19%, recall of 97.01%, and F1 score of\n97.10%.",
      "tldr_zh": "本论文提出了一种基于深度学习的自动化系统，用于从显微镜血涂片图像中分类和计数九种血细胞类型，包括 Erythrocyte、Erythroblast、Neutrophil、Basophil、Eosinophil、Lymphocyte、Monocyte、Immature Granulocytes 和 Platelet，以辅助诊断血液相关疾病。系统首先通过图像预处理（如调整大小和增强）和 U-Net 模型进行血细胞分割，取得了 98.23% accuracy、98.40% precision 和 97.92% Dice coefficient 的出色性能；随后，使用 watershed 算法分离重叠细胞。最终，作者引入 BloodCell-Net，这是一个轻量级卷积神经网络 (LWCNN)，实现了 97.10% accuracy、97.19% precision 和 97.10% F1 score 的分类结果，显著提高了效率和准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "24 pages, 7 tables and 13 Figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14875v1",
      "published_date": "2024-04-01 20:38:58 UTC",
      "updated_date": "2024-04-01 20:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:37:03.811855"
    },
    {
      "arxiv_id": "2404.01464v1",
      "title": "Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images",
      "title_zh": "翻译失败",
      "authors": [
        "JungEun Kim",
        "Hangyul Yoon",
        "Geondo Park",
        "Kyungsu Kim",
        "Eunho Yang"
      ],
      "abstract": "4D medical images, which represent 3D images with temporal information, are\ncrucial in clinical practice for capturing dynamic changes and monitoring\nlong-term disease progression. However, acquiring 4D medical images poses\nchallenges due to factors such as radiation exposure and imaging duration,\nnecessitating a balance between achieving high temporal resolution and\nminimizing adverse effects. Given these circumstances, not only is data\nacquisition challenging, but increasing the frame rate for each dataset also\nproves difficult. To address this challenge, this paper proposes a simple yet\neffective Unsupervised Volumetric Interpolation framework, UVI-Net. This\nframework facilitates temporal interpolation without the need for any\nintermediate frames, distinguishing it from the majority of other existing\nunsupervised methods. Experiments on benchmark datasets demonstrate significant\nimprovements across diverse evaluation metrics compared to unsupervised and\nsupervised baselines. Remarkably, our approach achieves this superior\nperformance even when trained with a dataset as small as one, highlighting its\nexceptional robustness and efficiency in scenarios with sparse supervision.\nThis positions UVI-Net as a compelling alternative for 4D medical imaging,\nparticularly in settings where data availability is limited. The source code is\navailable at https://github.com/jungeun122333/UVI-Net.",
      "tldr_zh": "该论文针对4D medical images的获取挑战，提出了一种数据高效的无监督插值框架UVI-Net，用于在不依赖任何intermediate frame的情况下实现temporal interpolation。该框架无需中间帧，支持简单有效的体积分插，显著提高了图像时间分辨率的同时减少辐射暴露风险。在基准数据集上的实验表明，UVI-Net在多种评估指标上优于无监督和监督基线，即使仅用一个数据集训练也能表现出色，突显其鲁棒性和效率，适用于数据稀缺的医疗成像场景。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01464v1",
      "published_date": "2024-04-01 20:25:04 UTC",
      "updated_date": "2024-04-01 20:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:37:16.965643"
    },
    {
      "arxiv_id": "2404.01459v1",
      "title": "Game-Theoretic Deep Reinforcement Learning to Minimize Carbon Emissions and Energy Costs for AI Inference Workloads in Geo-Distributed Data Centers",
      "title_zh": "基于博弈论的深度强化学习，用于最小化地理分布数据中心中AI推理工作负载的碳排放和能源成本",
      "authors": [
        "Ninad Hogade",
        "Sudeep Pasricha"
      ],
      "abstract": "Data centers are increasingly using more energy due to the rise in Artificial\nIntelligence (AI) workloads, which negatively impacts the environment and\nraises operational costs. Reducing operating expenses and carbon emissions\nwhile maintaining performance in data centers is a challenging problem. This\nwork introduces a unique approach combining Game Theory (GT) and Deep\nReinforcement Learning (DRL) for optimizing the distribution of AI inference\nworkloads in geo-distributed data centers to reduce carbon emissions and cloud\noperating (energy + data transfer) costs. The proposed technique integrates the\nprinciples of non-cooperative Game Theory into a DRL framework, enabling data\ncenters to make intelligent decisions regarding workload allocation while\nconsidering the heterogeneity of hardware resources, the dynamic nature of\nelectricity prices, inter-data center data transfer costs, and carbon\nfootprints. We conducted extensive experiments comparing our game-theoretic DRL\n(GT-DRL) approach with current DRL-based and other optimization techniques. The\nresults demonstrate that our strategy outperforms the state-of-the-art in\nreducing carbon emissions and minimizing cloud operating costs without\ncompromising computational performance. This work has significant implications\nfor achieving sustainability and cost-efficiency in data centers handling AI\ninference workloads across diverse geographic locations.",
      "tldr_zh": "这篇论文提出了一种结合 Game Theory (GT) 和 Deep Reinforcement Learning (DRL) 的方法，用于优化 AI 推理工作负载在地理分布数据中心的分配，从而最小化碳排放和能源成本。方法将非合作博弈理论融入 DRL 框架，考虑硬件资源异质性、电力价格动态性、数据传输成本以及碳足迹等因素。实验结果显示，该 GT-DRL 策略比现有 DRL 和优化技术更出色，在不影响计算性能的情况下显著降低了碳排放和运营成本。该研究为实现数据中心的可持续性和成本效率提供了重要启示。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "arXiv admin note: text overlap with arXiv:2106.00066",
      "pdf_url": "http://arxiv.org/pdf/2404.01459v1",
      "published_date": "2024-04-01 20:13:28 UTC",
      "updated_date": "2024-04-01 20:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:37:29.847968"
    },
    {
      "arxiv_id": "2404.01453v1",
      "title": "Unveiling Divergent Inductive Biases of LLMs on Temporal Data",
      "title_zh": "翻译失败",
      "authors": [
        "Sindhu Kishore",
        "Hangfeng He"
      ],
      "abstract": "Unraveling the intricate details of events in natural language necessitates a\nsubtle understanding of temporal dynamics. Despite the adeptness of Large\nLanguage Models (LLMs) in discerning patterns and relationships from data,\ntheir inherent comprehension of temporal dynamics remains a formidable\nchallenge. This research meticulously explores these intrinsic challenges\nwithin LLMs, with a specific emphasis on evaluating the performance of GPT-3.5\nand GPT-4 models in the analysis of temporal data. Employing two distinct\nprompt types, namely Question Answering (QA) format and Textual Entailment (TE)\nformat, our analysis probes into both implicit and explicit events. The\nfindings underscore noteworthy trends, revealing disparities in the performance\nof GPT-3.5 and GPT-4. Notably, biases toward specific temporal relationships\ncome to light, with GPT-3.5 demonstrating a preference for \"AFTER'' in the QA\nformat for both implicit and explicit events, while GPT-4 leans towards\n\"BEFORE''. Furthermore, a consistent pattern surfaces wherein GPT-3.5 tends\ntowards \"TRUE'', and GPT-4 exhibits a preference for \"FALSE'' in the TE format\nfor both implicit and explicit events. This persistent discrepancy between\nGPT-3.5 and GPT-4 in handling temporal data highlights the intricate nature of\ninductive bias in LLMs, suggesting that the evolution of these models may not\nmerely mitigate bias but may introduce new layers of complexity.",
      "tldr_zh": "本研究揭示了大型语言模型 (LLMs) 在处理时间数据时的内在归纳偏差 (inductive biases)，重点评估了 GPT-3.5 和 GPT-4 模型在理解时间动态方面的表现。研究采用 Question Answering (QA) 和 Textual Entailment (TE) 两种提示格式，分析模型对隐式和显式事件的响应，发现 GPT-3.5 偏好 \"AFTER\" 在 QA 格式和 \"TRUE\" 在 TE 格式，而 GPT-4 则偏向 \"BEFORE\" 和 \"FALSE\"。这些差异突显了 LLMs 模型演进可能不仅减少偏差，还会引入更复杂的层级，强调了提升时间数据处理能力的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01453v1",
      "published_date": "2024-04-01 19:56:41 UTC",
      "updated_date": "2024-04-01 19:56:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:37:42.193905"
    },
    {
      "arxiv_id": "2405.19338v1",
      "title": "Accurate Patient Alignment without Unnecessary Imaging Dose via Synthesizing Patient-specific 3D CT Images from 2D kV Images",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhen Ding",
        "Jason M. Holmes",
        "Hongying Feng",
        "Baoxin Li",
        "Lisa A. McGee",
        "Jean-Claude M. Rwigema",
        "Sujay A. Vora",
        "Daniel J. Ma",
        "Robert L. Foote",
        "Samir H. Patel",
        "Wei Liu"
      ],
      "abstract": "In radiotherapy, 2D orthogonally projected kV images are used for patient\nalignment when 3D-on-board imaging(OBI) unavailable. But tumor visibility is\nconstrained due to the projection of patient's anatomy onto a 2D plane,\npotentially leading to substantial setup errors. In treatment room with 3D-OBI\nsuch as cone beam CT(CBCT), the field of view(FOV) of CBCT is limited with\nunnecessarily high imaging dose, thus unfavorable for pediatric patients. A\nsolution to this dilemma is to reconstruct 3D CT from kV images obtained at the\ntreatment position. Here, we propose a dual-models framework built with\nhierarchical ViT blocks. Unlike a proof-of-concept approach, our framework\nconsiders kV images as the solo input and can synthesize accurate, full-size 3D\nCT in real time(within milliseconds). We demonstrate the feasibility of the\nproposed approach on 10 patients with head and neck (H&N) cancer using image\nquality(MAE: <45HU), dosimetrical accuracy(Gamma passing rate (2%/2mm/10%)>97%)\nand patient position uncertainty(shift error: <0.4mm). The proposed framework\ncan generate accurate 3D CT faithfully mirroring real-time patient position,\nthus significantly improving patient setup accuracy, keeping imaging dose\nminimum, and maintaining treatment veracity.",
      "tldr_zh": "该研究针对放射治疗中2D kV图像用于患者对齐的局限性（如肿瘤可见性差和设置错误），提出了一种双模型框架，利用分层ViT块从单一2D kV图像实时合成患者特定的全尺寸3D CT图像，从而避免不必要的成像剂量。框架设计考虑了临床实际需求，能在毫秒内完成合成，确保准确性和效率。在10名头颈癌患者实验中，该方法实现了图像质量（MAE <45HU）、剂量准确性（Gamma passing rate >97%）和患者位置不确定性（shift error <0.4mm）的优异性能，最终提高了患者设置准确性、降低了辐射风险并维持了治疗真实性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.SP",
      "comment": "17 pages, 8 figures and tables",
      "pdf_url": "http://arxiv.org/pdf/2405.19338v1",
      "published_date": "2024-04-01 19:55:03 UTC",
      "updated_date": "2024-04-01 19:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:37:53.487790"
    },
    {
      "arxiv_id": "2404.02176v1",
      "title": "Versatile Navigation under Partial Observability via Value-guided Diffusion Policy",
      "title_zh": "通过价值引导扩散策略实现部分可观察性下的多功能导航",
      "authors": [
        "Gengyu Zhang",
        "Hao Tang",
        "Yan Yan"
      ],
      "abstract": "Route planning for navigation under partial observability plays a crucial\nrole in modern robotics and autonomous driving. Existing route planning\napproaches can be categorized into two main classes: traditional autoregressive\nand diffusion-based methods. The former often fails due to its myopic nature,\nwhile the latter either assumes full observability or struggles to adapt to\nunfamiliar scenarios, due to strong couplings with behavior cloning from\nexperts. To address these deficiencies, we propose a versatile diffusion-based\napproach for both 2D and 3D route planning under partial observability.\nSpecifically, our value-guided diffusion policy first generates plans to\npredict actions across various timesteps, providing ample foresight to the\nplanning. It then employs a differentiable planner with state estimations to\nderive a value function, directing the agent's exploration and goal-seeking\nbehaviors without seeking experts while explicitly addressing partial\nobservability. During inference, our policy is further enhanced by a\nbest-plan-selection strategy, substantially boosting the planning success rate.\nMoreover, we propose projecting point clouds, derived from RGB-D inputs, onto\n2D grid-based bird-eye-view maps via semantic segmentation, generalizing to 3D\nenvironments. This simple yet effective adaption enables zero-shot transfer\nfrom 2D-trained policy to 3D, cutting across the laborious training for 3D\npolicy, and thus certifying our versatility. Experimental results demonstrate\nour superior performance, particularly in navigating situations beyond expert\ndemonstrations, surpassing state-of-the-art autoregressive and diffusion-based\nbaselines for both 2D and 3D scenarios.",
      "tldr_zh": "该论文提出了一种基于 Value-guided Diffusion Policy 的方法，用于处理部分可观察性（partial observability）下的 2D 和 3D 路线规划问题，旨在克服现有自回归方法短视和扩散方法适应性差的缺陷。该方法通过生成多时间步动作计划并结合可微分规划器推导价值函数，来指导代理的探索和目标行为，而无需依赖专家演示。论文还引入了 best-plan-selection 策略和点云投影到 2D 鸟瞰图的技术，实现从 2D 到 3D 的零样本转移。实验结果表明，该方法在 2D 和 3D 场景中均超越了最先进基线，尤其在超出专家演示的复杂环境中。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "13 pages, 7 figures, CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02176v1",
      "published_date": "2024-04-01 19:52:08 UTC",
      "updated_date": "2024-04-01 19:52:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:38:07.075994"
    },
    {
      "arxiv_id": "2404.01446v2",
      "title": "Finding Regions of Interest in Whole Slide Images Using Multiple Instance Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Martim Afonso",
        "Praphulla M. S. Bhawsar",
        "Monjoy Saha",
        "Jonas S. Almeida",
        "Arlindo L. Oliveira"
      ],
      "abstract": "Whole Slide Images (WSI), obtained by high-resolution digital scanning of\nmicroscope slides at multiple scales, are the cornerstone of modern Digital\nPathology. However, they represent a particular challenge to\nAI-based/AI-mediated analysis because pathology labeling is typically done at\nslide-level, instead of tile-level. It is not just that medical diagnostics is\nrecorded at the specimen level, the detection of oncogene mutation is also\nexperimentally obtained, and recorded by initiatives like The Cancer Genome\nAtlas (TCGA), at the slide level. This configures a dual challenge: a)\naccurately predicting the overall cancer phenotype and b) finding out what\ncellular morphologies are associated with it at the tile level. To address\nthese challenges, a weakly supervised Multiple Instance Learning (MIL) approach\nwas explored for two prevalent cancer types, Invasive Breast Carcinoma\n(TCGA-BRCA) and Lung Squamous Cell Carcinoma (TCGA-LUSC). This approach was\nexplored for tumor detection at low magnification levels and TP53 mutations at\nvarious levels. Our results show that a novel additive implementation of MIL\nmatched the performance of reference implementation (AUC 0.96), and was only\nslightly outperformed by Attention MIL (AUC 0.97). More interestingly from the\nperspective of the molecular pathologist, these different AI architectures\nidentify distinct sensitivities to morphological features (through the\ndetection of Regions of Interest, RoI) at different amplification levels.\nTellingly, TP53 mutation was most sensitive to features at the higher\napplications where cellular morphology is resolved.",
      "tldr_zh": "本研究针对 Whole Slide Images (WSI) 在数字病理学中的分析挑战，使用弱监督的 Multiple Instance Learning (MIL) 方法，处理 Invasive Breast Carcinoma (TCGA-BRCA) 和 Lung Squamous Cell Carcinoma (TCGA-LUSC) 数据集，旨在预测整体癌症表型并识别相关细胞形态。研究探索了添加式 MIL 和 Attention MIL 等架构，在低放大级别检测肿瘤以及各种级别检测 TP53 mutations。结果显示，添加式 MIL 的性能与参考实现相当（AUC 0.96），而 Attention MIL 略优（AUC 0.97），且不同 AI 架构在不同放大级别显示出对形态特征的独特敏感性，特别是 TP53 mutations 对较高放大级别的细胞形态更敏感，从而为精确识别 Regions of Interest (RoI) 提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01446v2",
      "published_date": "2024-04-01 19:33:41 UTC",
      "updated_date": "2024-04-11 06:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:38:20.232120"
    },
    {
      "arxiv_id": "2404.01440v2",
      "title": "Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Yijia Weng",
        "Bowen Wen",
        "Jonathan Tremblay",
        "Valts Blukis",
        "Dieter Fox",
        "Leonidas Guibas",
        "Stan Birchfield"
      ],
      "abstract": "We address the problem of building digital twins of unknown articulated\nobjects from two RGBD scans of the object at different articulation states. We\ndecompose the problem into two stages, each addressing distinct aspects. Our\nmethod first reconstructs object-level shape at each state, then recovers the\nunderlying articulation model including part segmentation and joint\narticulations that associate the two states. By explicitly modeling point-level\ncorrespondences and exploiting cues from images, 3D reconstructions, and\nkinematics, our method yields more accurate and stable results compared to\nprior work. It also handles more than one movable part and does not rely on any\nobject shape or structure priors. Project page:\nhttps://github.com/NVlabs/DigitalTwinArt",
      "tldr_zh": "本研究提出了一种基于Neural Implicit Representation的方法，用于从两个RGBD scans构建未知Articulated Objects的数字孪生。方法分为两个阶段：首先重建每个铰接状态下的对象级形状，然后恢复底层Articulation Model，包括部分分割和关节铰接，以关联不同状态。该方法通过显式建模点级对应关系并利用图像、3D重建和运动学线索，实现了比现有工作更准确和稳定的结果，且能处理多个可移动部分而不依赖任何对象形状或结构先验。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01440v2",
      "published_date": "2024-04-01 19:23:00 UTC",
      "updated_date": "2024-06-06 23:20:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:38:27.707014"
    },
    {
      "arxiv_id": "2404.01439v1",
      "title": "Creating emoji lexica from unsupervised sentiment analysis of their descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Milagros Fernández-Gavilanes",
        "Jonathan Juncal-Martínez",
        "Silvia García-Méndez",
        "Enrique Costa-Montenegro",
        "Francisco Javier González-Castaño"
      ],
      "abstract": "Online media, such as blogs and social networking sites, generate massive\nvolumes of unstructured data of great interest to analyze the opinions and\nsentiments of individuals and organizations. Novel approaches beyond Natural\nLanguage Processing are necessary to quantify these opinions with polarity\nmetrics. So far, the sentiment expressed by emojis has received little\nattention. The use of symbols, however, has boomed in the past four years.\nAbout twenty billion are typed in Twitter nowadays, and new emojis keep\nappearing in each new Unicode version, making them increasingly relevant to\nsentiment analysis tasks. This has motivated us to propose a novel approach to\npredict the sentiments expressed by emojis in online textual messages, such as\ntweets, that does not require human effort to manually annotate data and saves\nvaluable time for other analysis tasks. For this purpose, we automatically\nconstructed a novel emoji sentiment lexicon using an unsupervised sentiment\nanalysis system based on the definitions given by emoji creators in Emojipedia.\nAdditionally, we automatically created lexicon variants by also considering the\nsentiment distribution of the informal texts accompanying emojis. All these\nlexica are evaluated and compared regarding the improvement obtained by\nincluding them in sentiment analysis of the annotated datasets provided by\nKralj Novak et al. (2015). The results confirm the competitiveness of our\napproach.",
      "tldr_zh": "这篇论文提出了一种基于无监督情感分析（unsupervised sentiment analysis）的创新方法，用于从表情符号（emojis）的描述中自动创建表情符号词典（emoji lexica），以量化在线文本中的情感极性，而无需手动标注数据。方法利用 Emojipedia 中的表情符号定义作为基础，并结合伴随表情符号的非正式文本情感分布，构建多种词典变体。实验评估显示，这些词典在整合到 Kralj Novak et al. (2015) 的标注数据集中的情感分析任务中，显著提升了性能，并证明了该方法的竞争力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01439v1",
      "published_date": "2024-04-01 19:22:58 UTC",
      "updated_date": "2024-04-01 19:22:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:38:41.188022"
    },
    {
      "arxiv_id": "2404.01438v2",
      "title": "Generation and Detection of Sign Language Deepfakes - A Linguistic and Visual Analysis",
      "title_zh": "手语深度伪造的生成与检测——一种语言学与视觉分析",
      "authors": [
        "Shahzeb Naeem",
        "Muhammad Riyyan Khan",
        "Usman Tariq",
        "Abhinav Dhall",
        "Carlos Ivan Colon",
        "Hasan Al-Nashash"
      ],
      "abstract": "This research explores the positive application of deepfake technology for\nupper body generation, specifically sign language for the Deaf and Hard of\nHearing (DHoH) community. Given the complexity of sign language and the\nscarcity of experts, the generated videos are vetted by a sign language expert\nfor accuracy. We construct a reliable deepfake dataset, evaluating its\ntechnical and visual credibility using computer vision and natural language\nprocessing models. The dataset, consisting of over 1200 videos featuring both\nseen and unseen individuals, is also used to detect deepfake videos targeting\nvulnerable individuals. Expert annotations confirm that the generated videos\nare comparable to real sign language content. Linguistic analysis, using\ntextual similarity scores and interpreter evaluations, shows that the\ninterpretation of generated videos is at least 90% similar to authentic sign\nlanguage. Visual analysis demonstrates that convincingly realistic deepfakes\ncan be produced, even for new subjects. Using a pose/style transfer model, we\npay close attention to detail, ensuring hand movements are accurate and align\nwith the driving video. We also apply machine learning algorithms to establish\na baseline for deepfake detection on this dataset, contributing to the\ndetection of fraudulent sign language videos.",
      "tldr_zh": "本研究探讨 deepfake 技术的积极应用，用于生成上半身 sign language 视频，以支持 Deaf and Hard of Hearing (DHoH) 社区，并构建了一个包含超过 1200 个视频的可靠数据集。研究采用 computer vision 和 natural language processing 模型进行技术与视觉评估，以及 pose/style transfer 模型确保手部动作的准确性。语言分析显示，生成的视频解释至少 90% 类似于真实 sign language 内容，而视觉分析证明这些 deepfake 高度真实。最终，应用 machine learning 算法建立了 deepfake 检测基线，以识别针对脆弱个体的欺诈视频。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 11 figures, IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL\n  SYSTEM",
      "pdf_url": "http://arxiv.org/pdf/2404.01438v2",
      "published_date": "2024-04-01 19:22:43 UTC",
      "updated_date": "2025-02-17 18:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:38:54.586835"
    },
    {
      "arxiv_id": "2404.01430v1",
      "title": "Position-Aware Parameter Efficient Fine-Tuning Approach for Reducing Positional Bias in LLMs",
      "title_zh": "位置感知参数高效微调方法，用于减少LLMs中的位置偏差",
      "authors": [
        "Zheng Zhang",
        "Fan Yang",
        "Ziyan Jiang",
        "Zheng Chen",
        "Zhengyang Zhao",
        "Chengyuan Ma",
        "Liang Zhao",
        "Yang Liu"
      ],
      "abstract": "Recent advances in large language models (LLMs) have enhanced their ability\nto process long input contexts. This development is particularly crucial for\ntasks that involve retrieving knowledge from an external datastore, which can\nresult in long inputs. However, recent studies show a positional bias in LLMs,\ndemonstrating varying performance depending on the location of useful\ninformation within the input sequence. In this study, we conduct extensive\nexperiments to investigate the root causes of positional bias. Our findings\nindicate that the primary contributor to LLM positional bias stems from the\ninherent positional preferences of different models. We demonstrate that merely\nemploying prompt-based solutions is inadequate for overcoming the positional\npreferences. To address this positional bias issue of a pre-trained LLM, we\ndeveloped a Position-Aware Parameter Efficient Fine-Tuning (PAPEFT) approach\nwhich is composed of a data augmentation technique and a parameter efficient\nadapter, enhancing a uniform attention distribution across the input context.\nOur experiments demonstrate that the proposed approach effectively reduces\npositional bias, improving LLMs' effectiveness in handling long context\nsequences for various tasks that require externally retrieved knowledge.",
      "tldr_zh": "最近研究发现，大型语言模型（LLMs）在处理长输入上下文时存在位置偏差（positional bias），导致模型对输入序列中信息的位置表现出不一致性能。论文通过广泛实验确认，这种偏差主要源于模型固有的位置偏好，而基于提示（prompt-based）的解决方案无法有效解决此问题。为此，研究提出了一种Position-Aware Parameter Efficient Fine-Tuning（PAPEFT）方法，该方法结合数据增强技术和参数高效适配器，以实现输入上下文的均匀注意力分布。实验结果显示，PAPEFT显著减少了位置偏差，提升了LLMs在涉及外部知识检索的长序列任务中的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01430v1",
      "published_date": "2024-04-01 19:04:17 UTC",
      "updated_date": "2024-04-01 19:04:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:39:04.616136"
    },
    {
      "arxiv_id": "2404.01413v2",
      "title": "Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Gerstgrasser",
        "Rylan Schaeffer",
        "Apratim Dey",
        "Rafael Rafailov",
        "Henry Sleight",
        "John Hughes",
        "Tomasz Korbak",
        "Rajashree Agrawal",
        "Dhruv Pai",
        "Andrey Gromov",
        "Daniel A. Roberts",
        "Diyi Yang",
        "David L. Donoho",
        "Sanmi Koyejo"
      ],
      "abstract": "The proliferation of generative models, combined with pretraining on\nweb-scale data, raises a timely question: what happens when these models are\ntrained on their own generated outputs? Recent investigations into model-data\nfeedback loops proposed that such loops would lead to a phenomenon termed model\ncollapse, under which performance progressively degrades with each model-data\nfeedback iteration until fitted models become useless. However, those studies\nlargely assumed that new data replace old data over time, where an arguably\nmore realistic assumption is that data accumulate over time. In this paper, we\nask: what effect does accumulating data have on model collapse? We empirically\nstudy this question by pretraining sequences of language models on text\ncorpora. We confirm that replacing the original real data by each generation's\nsynthetic data does indeed tend towards model collapse, then demonstrate that\naccumulating the successive generations of synthetic data alongside the\noriginal real data avoids model collapse; these results hold across a range of\nmodel sizes, architectures, and hyperparameters. We obtain similar results for\ndeep generative models on other types of real data: diffusion models for\nmolecule conformation generation and variational autoencoders for image\ngeneration. To understand why accumulating data can avoid model collapse, we\nuse an analytically tractable framework introduced by prior work in which a\nsequence of linear models are fit to the previous models' outputs. Previous\nwork used this framework to show that if data are replaced, the test error\nincreases with the number of model-fitting iterations; we extend this argument\nto prove that if data instead accumulate, the test error has a finite upper\nbound independent of the number of iterations, meaning model collapse no longer\noccurs.",
      "tldr_zh": "本文研究了生成模型（如语言模型）在自身输出上训练时，是否会不可避免地导致 model collapse（模型性能逐渐下降的现象）。作者通过实验对比了数据替换与数据积累的场景，结果显示：如果用新合成数据替换原有真实数据，会引发 model collapse；但如果积累真实和合成数据，则能有效避免这一问题，并在语言模型、diffusion models 和 variational autoencoders 等模型上得到验证。理论上，作者扩展了先前的线性模型框架，证明数据积累时测试误差有有限上界，从而打破了递归诅咒。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.ET",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01413v2",
      "published_date": "2024-04-01 18:31:24 UTC",
      "updated_date": "2024-04-29 23:13:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:39:17.950869"
    },
    {
      "arxiv_id": "2404.01409v1",
      "title": "OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiongwei Wu",
        "Sicheng Yu",
        "Ee-Peng Lim",
        "Chong-Wah Ngo"
      ],
      "abstract": "In the realm of food computing, segmenting ingredients from images poses\nsubstantial challenges due to the large intra-class variance among the same\ningredients, the emergence of new ingredients, and the high annotation costs\nassociated with large food segmentation datasets. Existing approaches primarily\nutilize a closed-vocabulary and static text embeddings setting. These methods\noften fall short in effectively handling the ingredients, particularly new and\ndiverse ones. In response to these limitations, we introduce OVFoodSeg, a\nframework that adopts an open-vocabulary setting and enhances text embeddings\nwith visual context. By integrating vision-language models (VLMs), our approach\nenriches text embedding with image-specific information through two innovative\nmodules, eg, an image-to-text learner FoodLearner and an Image-Informed Text\nEncoder. The training process of OVFoodSeg is divided into two stages: the\npre-training of FoodLearner and the subsequent learning phase for segmentation.\nThe pre-training phase equips FoodLearner with the capability to align visual\ninformation with corresponding textual representations that are specifically\nrelated to food, while the second phase adapts both the FoodLearner and the\nImage-Informed Text Encoder for the segmentation task. By addressing the\ndeficiencies of previous models, OVFoodSeg demonstrates a significant\nimprovement, achieving an 4.9\\% increase in mean Intersection over Union (mIoU)\non the FoodSeg103 dataset, setting a new milestone for food image segmentation.",
      "tldr_zh": "这项研究针对食品图像分割面临的挑战，如成分内部类变异大、新成分出现和高标注成本，提出了OVFoodSeg框架，该框架采用开放词汇(open-vocabulary)设置，并通过视觉语言模型(VLMs)增强文本嵌入。OVFoodSeg包括两个创新模块：FoodLearner（图像到文本学习器）和Image-Informed Text Encoder，它们利用图像特定信息来丰富文本表示，训练过程分为预训练阶段（对齐视觉与文本）和后续分割适应阶段。实验结果显示，该框架在FoodSeg103数据集上将平均交并比(mIoU)提高了4.9%，为食品图像分割设定了新标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024; 12 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.01409v1",
      "published_date": "2024-04-01 18:26:29 UTC",
      "updated_date": "2024-04-01 18:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:39:29.894701"
    },
    {
      "arxiv_id": "2404.01402v2",
      "title": "ContactHandover: Contact-Guided Robot-to-Human Object Handover",
      "title_zh": "翻译失败",
      "authors": [
        "Zixi Wang",
        "Zeyi Liu",
        "Nicolas Ouporov",
        "Shuran Song"
      ],
      "abstract": "Robot-to-human object handover is an important step in many human robot\ncollaboration tasks. A successful handover requires the robot to maintain a\nstable grasp on the object while making sure the human receives the object in a\nnatural and easy-to-use manner. We propose ContactHandover, a robot to human\nhandover system that consists of two phases: a contact-guided grasping phase\nand an object delivery phase. During the grasping phase, ContactHandover\npredicts both 6-DoF robot grasp poses and a 3D affordance map of human contact\npoints on the object. The robot grasp poses are re-ranked by penalizing those\nthat block human contact points, and the robot executes the highest ranking\ngrasp. During the delivery phase, the robot end effector pose is computed by\nmaximizing human contact points close to the human while minimizing the human\narm joint torques and displacements. We evaluate our system on 27 diverse\nhousehold objects and show that our system achieves better visibility and\nreachability of human contacts to the receiver compared to several baselines.\nMore results can be found on\nhttps://clairezixiwang.github.io/ContactHandover.github.io",
      "tldr_zh": "该研究提出ContactHandover系统，用于指导机器人向人类递交物体，确保递交过程稳定、自然。系统分为两个阶段：首先，在接触引导抓取阶段，预测机器人的6-DoF抓取姿势和物体的3D affordance map，并通过惩罚阻挡人类接触点的姿势来重新排名，选择最佳抓取；其次，在物体递交阶段，优化机器人末端执行器姿势，以最大化人类接触点接近度，同时最小化人类手臂的关节扭矩和位移。实验在27种家用物体上评估，结果显示该系统比基线方法提供了更好的人类接触点可见性和可达性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IROS 2024. Project website:\n  https://clairezixiwang.github.io/ContactHandover.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2404.01402v2",
      "published_date": "2024-04-01 18:12:09 UTC",
      "updated_date": "2024-09-30 07:34:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:39:41.639955"
    },
    {
      "arxiv_id": "2404.01397v1",
      "title": "Object-conditioned Bag of Instances for Few-Shot Personalized Instance Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Umberto Michieli",
        "Jijoong Moon",
        "Daehyun Kim",
        "Mete Ozay"
      ],
      "abstract": "Nowadays, users demand for increased personalization of vision systems to\nlocalize and identify personal instances of objects (e.g., my dog rather than\ndog) from a few-shot dataset only. Despite outstanding results of deep networks\non classical label-abundant benchmarks (e.g., those of the latest YOLOv8 model\nfor standard object detection), they struggle to maintain within-class\nvariability to represent different instances rather than object categories\nonly. We construct an Object-conditioned Bag of Instances (OBoI) based on\nmulti-order statistics of extracted features, where generic object detection\nmodels are extended to search and identify personal instances from the OBoI's\nmetric space, without need for backpropagation. By relying on multi-order\nstatistics, OBoI achieves consistent superior accuracy in distinguishing\ndifferent instances. In the results, we achieve 77.1% personal object\nrecognition accuracy in case of 18 personal instances, showing about 12%\nrelative gain over the state of the art.",
      "tldr_zh": "本文提出了一种 Object-conditioned Bag of Instances (OBoI) 方法，用于处理 Few-Shot 个性化实例识别问题，例如从少量数据中定位和识别特定个人对象（如“我的狗”而非一般“狗”）。OBoI 基于提取特征的多阶统计扩展通用对象检测模型（如 YOLOv8），在不需反向传播的情况下，通过其度量空间搜索和区分不同实例，实现更高的类内变异性。实验结果显示，在包含 18 个个人实例的场景下，OBoI 达到了 77.1% 的识别准确率，比最先进方法提高了约 12%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "ICASSP 2024. Copyright 2024 IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses, in any\n  current or future media, including reprinting/republishing this material for\n  advertising or promotional purposes, creating new collective works, for\n  resale or redistribution to servers or lists, or reuse of any copyrighted\n  component of this work in other",
      "pdf_url": "http://arxiv.org/pdf/2404.01397v1",
      "published_date": "2024-04-01 18:08:58 UTC",
      "updated_date": "2024-04-01 18:08:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:39:54.610875"
    },
    {
      "arxiv_id": "2404.01300v3",
      "title": "NeRF-MAE: Masked AutoEncoders for Self-Supervised 3D Representation Learning for Neural Radiance Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Zubair Irshad",
        "Sergey Zakharov",
        "Vitor Guizilini",
        "Adrien Gaidon",
        "Zsolt Kira",
        "Rares Ambrus"
      ],
      "abstract": "Neural fields excel in computer vision and robotics due to their ability to\nunderstand the 3D visual world such as inferring semantics, geometry, and\ndynamics. Given the capabilities of neural fields in densely representing a 3D\nscene from 2D images, we ask the question: Can we scale their self-supervised\npretraining, specifically using masked autoencoders, to generate effective 3D\nrepresentations from posed RGB images. Owing to the astounding success of\nextending transformers to novel data modalities, we employ standard 3D Vision\nTransformers to suit the unique formulation of NeRFs. We leverage NeRF's\nvolumetric grid as a dense input to the transformer, contrasting it with other\n3D representations such as pointclouds where the information density can be\nuneven, and the representation is irregular. Due to the difficulty of applying\nmasked autoencoders to an implicit representation, such as NeRF, we opt for\nextracting an explicit representation that canonicalizes scenes across domains\nby employing the camera trajectory for sampling. Our goal is made possible by\nmasking random patches from NeRF's radiance and density grid and employing a\nstandard 3D Swin Transformer to reconstruct the masked patches. In doing so,\nthe model can learn the semantic and spatial structure of complete scenes. We\npretrain this representation at scale on our proposed curated posed-RGB data,\ntotaling over 1.8 million images. Once pretrained, the encoder is used for\neffective 3D transfer learning. Our novel self-supervised pretraining for\nNeRFs, NeRF-MAE, scales remarkably well and improves performance on various\nchallenging 3D tasks. Utilizing unlabeled posed 2D data for pretraining,\nNeRF-MAE significantly outperforms self-supervised 3D pretraining and NeRF\nscene understanding baselines on Front3D and ScanNet datasets with an absolute\nperformance improvement of over 20% AP50 and 8% AP25 for 3D object detection.",
      "tldr_zh": "本研究提出 NeRF-MAE，一种基于 Masked AutoEncoders 的自监督方法，用于从 NeRF（Neural Radiance Fields）中学习有效的 3D 表示，从而提升对 3D 场景的语义和空间理解。方法利用 3D Vision Transformers 处理 NeRF 的体积网格，通过对辐射度和密度网格进行随机掩码并重建，解决了隐式表示的训练挑战，并借助相机轨迹进行跨域规范采样。在超过 180 万张标注姿态 RGB 图像的数据集上进行大规模预训练后，NeRF-MAE 显著提高了 3D 转移学习性能，在 Front3D 和 ScanNet 数据集上的 3D 对象检测任务中，比自监督基线提升超过 20% AP50 和 8% AP25。总的来说，该方法为无标签 2D 数据驱动的 3D 表示学习提供了高效框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024. Project Page: https://nerf-mae.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2404.01300v3",
      "published_date": "2024-04-01 17:59:55 UTC",
      "updated_date": "2024-07-18 17:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:40:06.883090"
    },
    {
      "arxiv_id": "2404.01299v2",
      "title": "CausalChaos! Dataset for Comprehensive Causal Action Question Answering Over Longer Causal Chains Grounded in Dynamic Visual Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Paritosh Parmar",
        "Eric Peh",
        "Ruirui Chen",
        "Ting En Lam",
        "Yuhan Chen",
        "Elston Tan",
        "Basura Fernando"
      ],
      "abstract": "Causal video question answering (QA) has garnered increasing interest, yet\nexisting datasets often lack depth in causal reasoning. To address this gap, we\ncapitalize on the unique properties of cartoons and construct CausalChaos!, a\nnovel, challenging causal Why-QA dataset built upon the iconic \"Tom and Jerry\"\ncartoon series. Cartoons use the principles of animation that allow animators\nto create expressive, unambiguous causal relationships between events to form a\ncoherent storyline. Utilizing these properties, along with thought-provoking\nquestions and multi-level answers (answer and detailed causal explanation), our\nquestions involve causal chains that interconnect multiple dynamic interactions\nbetween characters and visual scenes. These factors demand models to solve more\nchallenging, yet well-defined causal relationships. We also introduce hard\nincorrect answer mining, including a causally confusing version that is even\nmore challenging. While models perform well, there is much room for\nimprovement, especially, on open-ended answers. We identify more\nadvanced/explicit causal relationship modeling & joint modeling of vision and\nlanguage as the immediate areas for future efforts to focus upon. Along with\nthe other complementary datasets, our new challenging dataset will pave the way\nfor these developments in the field.",
      "tldr_zh": "这篇论文引入了CausalChaos!数据集，用于全面的因果动作问答（Causal Video QA），专注于动态视觉场景中更长因果链的Why-QA问题，以解决现有数据集在因果推理深度上的不足。数据集基于Tom and Jerry卡通系列，利用动画的明确因果关系，构建了涉及多级答案（包括详细因果解释）和硬错误答案挖掘的挑战性问题。实验结果显示，模型在某些任务上表现良好，但开放式答案仍有较大改进空间，未来应聚焦于更先进的因果关系建模和视觉语言联合建模，以推动该领域的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://github.com/LUNAProject22/CausalChaos",
      "pdf_url": "http://arxiv.org/pdf/2404.01299v2",
      "published_date": "2024-04-01 17:59:53 UTC",
      "updated_date": "2024-06-14 17:46:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:40:19.339806"
    },
    {
      "arxiv_id": "2404.01295v1",
      "title": "Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Lin Tuan",
        "Xilun Chen",
        "Eric Michael Smith",
        "Louis Martin",
        "Soumya Batra",
        "Asli Celikyilmaz",
        "William Yang Wang",
        "Daniel M. Bikel"
      ],
      "abstract": "As large language models (LLMs) become easily accessible nowadays, the\ntrade-off between safety and helpfulness can significantly impact user\nexperience. A model that prioritizes safety will cause users to feel less\nengaged and assisted while prioritizing helpfulness will potentially cause\nharm. Possible harms include teaching people how to build a bomb, exposing\nyouth to inappropriate content, and hurting users' mental health. In this work,\nwe propose to balance safety and helpfulness in diverse use cases by\ncontrolling both attributes in LLM. We explore training-free and fine-tuning\nmethods that do not require extra human annotations and analyze the challenges\nof controlling safety and helpfulness in LLMs. Our experiments demonstrate that\nour method can rewind a learned model and unlock its controllability.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在安全性和帮助性之间的权衡问题，强调过度优先安全可能降低用户参与度，而优先帮助性则可能导致危害，如教导制造炸弹或暴露不当内容。\n为了平衡两者，论文提出无需额外人类标注的训练-free 和 fine-tuning 方法，来控制LLMs中的安全和帮助属性，并分析了相关挑战。\n实验结果显示，该方法能有效“rewind”模型并提升其可控性，从而在多样化场景中实现更可靠的用户响应。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01295v1",
      "published_date": "2024-04-01 17:59:06 UTC",
      "updated_date": "2024-04-01 17:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:40:28.854179"
    },
    {
      "arxiv_id": "2404.01291v2",
      "title": "Evaluating Text-to-Visual Generation with Image-to-Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiu Lin",
        "Deepak Pathak",
        "Baiqi Li",
        "Jiayao Li",
        "Xide Xia",
        "Graham Neubig",
        "Pengchuan Zhang",
        "Deva Ramanan"
      ],
      "abstract": "Despite significant progress in generative AI, comprehensive evaluation\nremains challenging because of the lack of effective metrics and standardized\nbenchmarks. For instance, the widely-used CLIPScore measures the alignment\nbetween a (generated) image and text prompt, but it fails to produce reliable\nscores for complex prompts involving compositions of objects, attributes, and\nrelations. One reason is that text encoders of CLIP can notoriously act as a\n\"bag of words\", conflating prompts such as \"the horse is eating the grass\" with\n\"the grass is eating the horse\". To address this, we introduce the VQAScore,\nwhich uses a visual-question-answering (VQA) model to produce an alignment\nscore by computing the probability of a \"Yes\" answer to a simple \"Does this\nfigure show '{text}'?\" question. Though simpler than prior art, VQAScore\ncomputed with off-the-shelf models produces state-of-the-art results across\nmany (8) image-text alignment benchmarks. We also compute VQAScore with an\nin-house model that follows best practices in the literature. For example, we\nuse a bidirectional image-question encoder that allows image embeddings to\ndepend on the question being asked (and vice versa). Our in-house model,\nCLIP-FlanT5, outperforms even the strongest baselines that make use of the\nproprietary GPT-4V. Interestingly, although we train with only images, VQAScore\ncan also align text with video and 3D models. VQAScore allows researchers to\nbenchmark text-to-visual generation using complex texts that capture the\ncompositional structure of real-world prompts. We introduce GenAI-Bench, a more\nchallenging benchmark with 1,600 compositional text prompts that require\nparsing scenes, objects, attributes, relationships, and high-order reasoning\nlike comparison and logic. GenAI-Bench also offers over 15,000 human ratings\nfor leading image and video generation models such as Stable Diffusion, DALL-E\n3, and Gen2.",
      "tldr_zh": "本论文针对生成式 AI 的评估挑战，提出 VQAScore 作为一种新型图像-文本对齐指标，使用视觉问答 (VQA) 模型通过计算“Does this figure show '{text}'?”的“Yes”概率来评估复杂提示的准确性，从而克服 CLIPScore 在处理物体、属性和关系组合时的不足。实验显示，VQAScore 基于现成模型已在多个基准上达到最先进水平，而作者开发的 CLIP-FlanT5 模型（采用双向图像-问题编码器）甚至超越了 GPT-4V 基线。值得注意的是，VQAScore 可扩展到文本与视频或 3D 模型的匹配。论文还引入 GenAI-Bench 基准，包含 1600 个组合文本提示和超过 15,000 个人类评分，用于评估如 Stable Diffusion 和 DALL-E 3 等模型的生成性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "We open-source our data, model, and code at:\n  https://github.com/linzhiqiu/t2v_metrics ; Project page:\n  https://linzhiqiu.github.io/papers/vqascore",
      "pdf_url": "http://arxiv.org/pdf/2404.01291v2",
      "published_date": "2024-04-01 17:58:06 UTC",
      "updated_date": "2024-06-18 07:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:40:43.453238"
    },
    {
      "arxiv_id": "2404.01365v3",
      "title": "Prompt-prompted Adaptive Structured Pruning for Efficient LLM Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Dong",
        "Beidi Chen",
        "Yuejie Chi"
      ],
      "abstract": "With the development of transformer-based large language models (LLMs), they\nhave been applied to many fields due to their remarkable utility, but this\ncomes at a considerable computational cost at deployment. Fortunately, some\nmethods such as pruning or constructing a mixture of experts (MoE) aim at\nexploiting sparsity in transformer feedforward (FF) blocks to gain boosts in\nspeed and reduction in memory requirements. However, these techniques can be\nvery costly and inflexible in practice, as they often require training or are\nrestricted to specific types of architectures. To address this, we introduce\nGRIFFIN, a novel training-free and calibration-free method that selects unique\nFF experts at the sequence level for efficient generation across a plethora of\nLLMs with different non-ReLU activation functions. This is possible due to a\ncritical observation that many trained LLMs naturally produce highly structured\nFF activation patterns within a sequence, which we call flocking. Despite our\nmethod's simplicity, we show with 50% of the FF parameters, GRIFFIN maintains\nthe original model's performance with little to no degradation on a variety of\nclassification and generation tasks, all while improving latency (e.g.\n1.29$\\times$ and 1.25$\\times$ speed-ups in Gemma 7B and Llama 2 13B,\nrespectively, on an NVIDIA L40). Code is available at\nhttps://github.com/hdong920/GRIFFIN.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的计算成本问题，提出了一种名为 GRIFFIN 的训练-free 和 calibration-free 方法，通过 prompt-prompted adaptive structured pruning 利用 LLMs 中的 flocking 现象，选择序列级别的 FF experts，实现高效生成。GRIFFIN 能够适应不同非-ReLU 激活函数的 LLMs，无需额外训练或校准，即可显著减少参数（使用 50% 的 FF 参数）。实验结果显示，该方法在分类和生成任务上维持了原模型性能，几乎无退化，同时提高了延迟，例如在 Gemma 7B 和 Llama 2 13B 上分别实现了 1.29× 和 1.25× 的速度提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Revision 1: Updated abstract with code link; re-ran top-k + sampling\n  rows in Table 4, conclusions unchanged Revision 2: Reframing and new\n  experiments, conclusions unchanged",
      "pdf_url": "http://arxiv.org/pdf/2404.01365v3",
      "published_date": "2024-04-01 17:56:06 UTC",
      "updated_date": "2024-08-11 19:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:40:55.372041"
    },
    {
      "arxiv_id": "2404.01268v1",
      "title": "Mapping the Increasing Use of LLMs in Scientific Papers",
      "title_zh": "映射大型语言模型在科学",
      "authors": [
        "Weixin Liang",
        "Yaohui Zhang",
        "Zhengxuan Wu",
        "Haley Lepp",
        "Wenlong Ji",
        "Xuandong Zhao",
        "Hancheng Cao",
        "Sheng Liu",
        "Siyu He",
        "Zhi Huang",
        "Diyi Yang",
        "Christopher Potts",
        "Christopher D Manning",
        "James Y. Zou"
      ],
      "abstract": "Scientific publishing lays the foundation of science by disseminating\nresearch findings, fostering collaboration, encouraging reproducibility, and\nensuring that scientific knowledge is accessible, verifiable, and built upon\nover time. Recently, there has been immense speculation about how many people\nare using large language models (LLMs) like ChatGPT in their academic writing,\nand to what extent this tool might have an effect on global scientific\npractices. However, we lack a precise measure of the proportion of academic\nwriting substantially modified or produced by LLMs. To address this gap, we\nconduct the first systematic, large-scale analysis across 950,965 papers\npublished between January 2020 and February 2024 on the arXiv, bioRxiv, and\nNature portfolio journals, using a population-level statistical framework to\nmeasure the prevalence of LLM-modified content over time. Our statistical\nestimation operates on the corpus level and is more robust than inference on\nindividual instances. Our findings reveal a steady increase in LLM usage, with\nthe largest and fastest growth observed in Computer Science papers (up to\n17.5%). In comparison, Mathematics papers and the Nature portfolio showed the\nleast LLM modification (up to 6.3%). Moreover, at an aggregate level, our\nanalysis reveals that higher levels of LLM-modification are associated with\npapers whose first authors post preprints more frequently, papers in more\ncrowded research areas, and papers of shorter lengths. Our findings suggests\nthat LLMs are being broadly used in scientific writings.",
      "tldr_zh": "本研究通过分析950,965篇科学论文（涵盖arXiv、bioRxiv和Nature期刊，从2020年1月至2024年2月），使用一种基于整体统计框架的方法，首次系统量化大型语言模型（LLMs）如ChatGPT在学术写作中的使用比例。结果显示，LLMs修改内容的比例稳步上升，计算机科学论文增长最快（高达17.5%），而数学论文和Nature期刊增长最小（仅达6.3%）。此外，LLM使用更常见于频繁发布预印本的第一作者、研究领域竞争激烈且论文长度较短的文章，这表明LLMs正广泛影响科学写作实践。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01268v1",
      "published_date": "2024-04-01 17:45:15 UTC",
      "updated_date": "2024-04-01 17:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:41:06.197738"
    },
    {
      "arxiv_id": "2404.01266v3",
      "title": "IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Deqing Fu",
        "Ruohao Guo",
        "Ghazal Khalighinejad",
        "Ollie Liu",
        "Bhuwan Dhingra",
        "Dani Yogatama",
        "Robin Jia",
        "Willie Neiswanger"
      ],
      "abstract": "Current foundation models exhibit impressive capabilities when prompted\neither with text only or with both image and text inputs. But do their\ncapabilities change depending on the input modality? In this work, we propose\n$\\textbf{IsoBench}$, a benchmark dataset containing problems from four major\nareas: math, science, algorithms, and games. Each example is presented with\nmultiple $\\textbf{isomorphic representations}$ of inputs, such as visual,\ntextual, and mathematical presentations. IsoBench provides fine-grained\nfeedback to diagnose performance gaps caused by the form of the representation.\nAcross various foundation models, we observe that on the same problem, models\nhave a consistent preference towards textual representations. Most prominently,\nwhen evaluated on all IsoBench problems, Claude-3 Opus performs 28.7 points\nworse when provided with images instead of text; similarly, GPT-4 Turbo is 18.7\npoints worse and Gemini Pro is 14.9 points worse. Finally, we present two\nprompting techniques, $\\textit{IsoCombination}$ and $\\textit{IsoScratchPad}$,\nwhich improve model performance by considering combinations of, and\ntranslations between, different input representations.",
      "tldr_zh": "本研究提出IsoBench基准数据集，用于评估多模态基础模型在不同输入形式上的性能差异，涵盖数学、科学、算法和游戏等四个领域的任务，每个示例采用多种isomorphic representations（如视觉、文本和数学表示）进行呈现。实验结果显示，模型对文本表示有显著偏好，例如Claude-3 Opus在图像输入时比文本输入低28.7分，GPT-4 Turbo低18.7分，Gemini Pro低14.9分，这突显了表示形式对模型表现的影响。IsoBench通过提供细粒度反馈，帮助诊断这些性能差距。最终，研究引入了两种提示技术：IsoCombination和IsoScratchPad，通过结合和翻译不同表示形式来提升模型性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "1st Conference on Language Modeling (COLM), 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01266v3",
      "published_date": "2024-04-01 17:43:27 UTC",
      "updated_date": "2024-08-18 23:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:41:19.500697"
    },
    {
      "arxiv_id": "2404.01364v1",
      "title": "Information Plane Analysis Visualization in Deep Learning via Transfer Entropy",
      "title_zh": "翻译失败",
      "authors": [
        "Adrian Moldovan",
        "Angel Cataron",
        "Razvan Andonie"
      ],
      "abstract": "In a feedforward network, Transfer Entropy (TE) can be used to measure the\ninfluence that one layer has on another by quantifying the information transfer\nbetween them during training. According to the Information Bottleneck\nprinciple, a neural model's internal representation should compress the input\ndata as much as possible while still retaining sufficient information about the\noutput. Information Plane analysis is a visualization technique used to\nunderstand the trade-off between compression and information preservation in\nthe context of the Information Bottleneck method by plotting the amount of\ninformation in the input data against the compressed representation. The claim\nthat there is a causal link between information-theoretic compression and\ngeneralization, measured by mutual information, is plausible, but results from\ndifferent studies are conflicting. In contrast to mutual information, TE can\ncapture temporal relationships between variables. To explore such links, in our\nnovel approach we use TE to quantify information transfer between neural layers\nand perform Information Plane analysis. We obtained encouraging experimental\nresults, opening the possibility for further investigations.",
      "tldr_zh": "本文提出了一种新方法，使用 Transfer Entropy (TE) 来量化深度学习前馈网络中层间的信息传输，并应用于 Information Plane 分析。该方法基于 Information Bottleneck 原理，通过捕捉变量之间的时间关系，探讨数据压缩与泛化性能的因果联系，与传统的 Mutual Information 相比更具优势。实验结果显示，该方法取得了积极效果，为进一步研究信息理论在深度学习中的作用提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01364v1",
      "published_date": "2024-04-01 17:34:18 UTC",
      "updated_date": "2024-04-01 17:34:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:41:30.049145"
    },
    {
      "arxiv_id": "2404.01261v2",
      "title": "FABLES: Evaluating faithfulness and content selection in book-length summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Yekyung Kim",
        "Yapei Chang",
        "Marzena Karpinska",
        "Aparna Garimella",
        "Varun Manjunatha",
        "Kyle Lo",
        "Tanya Goyal",
        "Mohit Iyyer"
      ],
      "abstract": "While long-context large language models (LLMs) can technically summarize\nbook-length documents (>100K tokens), the length and complexity of the\ndocuments have so far prohibited evaluations of input-dependent aspects like\nfaithfulness. In this paper, we conduct the first large-scale human evaluation\nof faithfulness and content selection on LLM-generated summaries of fictional\nbooks. Our study mitigates the issue of data contamination by focusing on\nsummaries of books published in 2023 or 2024, and we hire annotators who have\nfully read each book prior to the annotation task to minimize cost and\ncognitive burden. We collect FABLES, a dataset of annotations on 3,158 claims\nmade in LLM-generated summaries of 26 books, at a cost of $5.2K USD, which\nallows us to rank LLM summarizers based on faithfulness: Claude-3-Opus\nsignificantly outperforms all closed-source LLMs, while the open-source Mixtral\nis on par with GPT-3.5-Turbo. An analysis of the annotations reveals that most\nunfaithful claims relate to events and character states, and they generally\nrequire indirect reasoning over the narrative to invalidate. While LLM-based\nauto-raters have proven reliable for factuality and coherence in other\nsettings, we implement several LLM raters of faithfulness and find that none\ncorrelates strongly with human annotations, especially with regard to detecting\nunfaithful claims. Our experiments suggest that detecting unfaithful claims is\nan important future direction not only for summarization evaluation but also as\na testbed for long-context understanding. Finally, we move beyond faithfulness\nby exploring content selection errors in book-length summarization: we develop\na typology of omission errors related to crucial narrative elements and also\nidentify a systematic over-emphasis on events occurring towards the end of the\nbook.",
      "tldr_zh": "本研究引入 FABLES 数据集，对大语言模型 (LLMs) 生成的书籍长度总结 (>100K tokens) 进行首次大规模人类评估，焦点在于忠实度 (faithfulness) 和内容选择。研究者通过雇佣完整阅读过 26 本 2023-2024 年出版书籍的标注者，收集了 3,158 个声明的标注，结果显示 Claude-3-Opus 在忠实度上显著优于其他封闭源 LLMs，而开源 Mixtral 与 GPT-3.5-Turbo 相当。大多数不忠实声明涉及事件和人物状态，通常需间接推理识别，且 LLM 自动评估器无法可靠地与人类标注相关联。该研究还分析了内容选择错误，如遗漏关键叙事元素和过度强调书籍结尾事件，并建议检测不忠实声明作为未来总结评估和长上下文理解的重要方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint - 39 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.01261v2",
      "published_date": "2024-04-01 17:33:38 UTC",
      "updated_date": "2024-09-30 17:39:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:41:44.964868"
    },
    {
      "arxiv_id": "2404.01363v1",
      "title": "AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review",
      "title_zh": "AIOps 事件管理",
      "authors": [
        "Youcef Remil",
        "Anes Bendimerad",
        "Romain Mathonat",
        "Mehdi Kaytoue"
      ],
      "abstract": "The management of modern IT systems poses unique challenges, necessitating\nscalability, reliability, and efficiency in handling extensive data streams.\nTraditional methods, reliant on manual tasks and rule-based approaches, prove\ninefficient for the substantial data volumes and alerts generated by IT\nsystems. Artificial Intelligence for Operating Systems (AIOps) has emerged as a\nsolution, leveraging advanced analytics like machine learning and big data to\nenhance incident management. AIOps detects and predicts incidents, identifies\nroot causes, and automates healing actions, improving quality and reducing\noperational costs. However, despite its potential, the AIOps domain is still in\nits early stages, decentralized across multiple sectors, and lacking\nstandardized conventions. Research and industrial contributions are distributed\nwithout consistent frameworks for data management, target problems,\nimplementation details, requirements, and capabilities. This study proposes an\nAIOps terminology and taxonomy, establishing a structured incident management\nprocedure and providing guidelines for constructing an AIOps framework. The\nresearch also categorizes contributions based on criteria such as incident\nmanagement tasks, application areas, data sources, and technical approaches.\nThe goal is to provide a comprehensive review of technical and research aspects\nin AIOps for incident management, aiming to structure knowledge, identify gaps,\nand establish a foundation for future developments in the field.",
      "tldr_zh": "这篇论文探讨了 AIOps 在事件管理中的应用，强调其利用机器学习和大数据技术来检测、预测事件、识别根因并自动化修复，从而提升 IT 系统效率并降低成本。论文提出 AIOps 术语和分类法，建立结构化的事件管理流程，并提供构建 AIOps 框架的指导，包括对贡献的分类（如事件管理任务、应用领域、数据来源和技术方法）。通过全面文献回顾，该研究识别了 AIOps 领域的知识空白，并为未来标准化和开发奠定基础。",
      "categories": [
        "cs.OS",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.OS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01363v1",
      "published_date": "2024-04-01 17:32:22 UTC",
      "updated_date": "2024-04-01 17:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:41:55.768088"
    },
    {
      "arxiv_id": "2404.01260v1",
      "title": "Bridging Remote Sensors with Multisensor Geospatial Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Boran Han",
        "Shuai Zhang",
        "Xingjian Shi",
        "Markus Reichstein"
      ],
      "abstract": "In the realm of geospatial analysis, the diversity of remote sensors,\nencompassing both optical and microwave technologies, offers a wealth of\ndistinct observational capabilities. Recognizing this, we present msGFM, a\nmultisensor geospatial foundation model that effectively unifies data from four\nkey sensor modalities. This integration spans an expansive dataset of two\nmillion multisensor images. msGFM is uniquely adept at handling both paired and\nunpaired sensor data. For data originating from identical geolocations, our\nmodel employs an innovative cross-sensor pretraining approach in masked image\nmodeling, enabling the synthesis of joint representations from diverse sensors.\nmsGFM, incorporating four remote sensors, upholds strong performance, forming a\ncomprehensive model adaptable to various sensor types. msGFM has demonstrated\nenhanced proficiency in a range of both single-sensor and multisensor\ndownstream tasks. These include scene classification, segmentation, cloud\nremoval, and pan-sharpening. A key discovery of our research is that\nrepresentations derived from natural images are not always compatible with the\ndistinct characteristics of geospatial remote sensors, underscoring the\nlimitations of existing representations in this field. Our work can serve as a\nguide for developing multisensor geospatial pretraining models, paving the way\nfor more advanced geospatial capabilities.",
      "tldr_zh": "本研究提出 msGFM，一种多传感器地理空间基础模型，旨在整合光学和微波等四种遥感器数据，利用两百万张多传感器图像处理配对和非配对数据。模型采用创新的 cross-sensor pretraining 方法结合 masked image modeling，生成联合表示以适应各种传感器类型。实验结果显示，msGFM 在单传感器和多传感器下游任务（如场景分类、分割、云移除和全色锐化）中表现出色，并发现自然图像表示不兼容地理空间传感器的特性，为未来多传感器预训练模型的发展提供指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR",
      "pdf_url": "http://arxiv.org/pdf/2404.01260v1",
      "published_date": "2024-04-01 17:30:56 UTC",
      "updated_date": "2024-04-01 17:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:42:06.071485"
    },
    {
      "arxiv_id": "2404.01258v2",
      "title": "Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward",
      "title_zh": "翻译失败",
      "authors": [
        "Ruohong Zhang",
        "Liangke Gui",
        "Zhiqing Sun",
        "Yihao Feng",
        "Keyang Xu",
        "Yuanhan Zhang",
        "Di Fu",
        "Chunyuan Li",
        "Alexander Hauptmann",
        "Yonatan Bisk",
        "Yiming Yang"
      ],
      "abstract": "Preference modeling techniques, such as direct preference optimization (DPO),\nhas shown effective in enhancing the generalization abilities of large language\nmodel (LLM). However, in tasks involving video instruction-following, providing\ninformative feedback, especially for detecting hallucinations in generated\nresponses, remains a significant challenge. Previous studies have explored\nusing large large multimodal models (LMMs) as reward models to guide preference\nmodeling, but their ability to accurately assess the factuality of generated\nresponses compared to corresponding videos has not been conclusively\nestablished. This paper introduces a novel framework that utilizes detailed\nvideo captions as a proxy of video content, enabling language models to\nincorporate this information as supporting evidence for scoring video Question\nAnswering (QA) predictions. Our approach demonstrates robust alignment with\nOpenAI GPT-4V model's reward mechanism, which directly takes video frames as\ninput. Furthermore, we show that applying this tailored reward through DPO\nsignificantly improves the performance of video LMMs on video QA tasks.",
      "tldr_zh": "这篇论文提出了一种新框架，使用详细视频字幕作为视频内容的代理，让语言模型（LLM）结合这些信息为视频问答（QA）预测提供奖励评分，从而解决视频大型多模态模型（LMMs）在指令遵循任务中检测幻觉的挑战。该框架与 OpenAI GPT-4V 的奖励机制高度一致，并通过直接偏好优化（DPO）显著提升了 LMMs 的性能。实验结果表明，这种方法在视频 QA 任务上取得了稳健的改进，为视频模型的优化提供了有效途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01258v2",
      "published_date": "2024-04-01 17:28:16 UTC",
      "updated_date": "2024-04-02 12:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:42:19.613629"
    },
    {
      "arxiv_id": "2404.16041v1",
      "title": "Forklift: An Extensible Neural Lifter",
      "title_zh": "翻译失败",
      "authors": [
        "Jordi Armengol-Estapé",
        "Rodrigo C. O. Rocha",
        "Jackson Woodruff",
        "Pasquale Minervini",
        "Michael F. P. O'Boyle"
      ],
      "abstract": "The escalating demand to migrate legacy software across different Instruction\nSet Architectures (ISAs) has driven the development of assembly-to-assembly\ntranslators to map between their respective assembly languages. However, the\ndevelopment of these tools requires substantial engineering effort.\nState-of-the-art approaches use lifting, a technique where source assembly code\nis translated to an architecture-independent intermediate representation (IR)\n(for example, the LLVM IR) and use a pre-existing compiler to recompile the IR\nto the target ISA. However, the hand-written rules these lifters employ are\nsensitive to the particular compiler and optimization level used to generate\nthe code and require significant engineering effort to support each new ISA. We\npropose Forklift, the first neural lifter that learns how to translate assembly\nto LLVM IR using a token-level encoder-decoder Transformer. We show how to\nincrementally add support to new ISAs by fine tuning the assembly encoder and\nfreezing the IR decoder, improving the overall accuracy and efficiency. We\ncollect millions of parallel LLVM IR, x86, ARM, and RISC-V programs across\ncompilers and optimization levels to train Forklift and set up an\ninput/output-based accuracy harness. We evaluate Forklift on two challenging\nbenchmark suites and translate 2.5x more x86 programs than a state-of-the-art\nhand-written lifter and 4.4x more x86 programs than GPT-4 as well as enabling\ntranslation from new ISAs.",
      "tldr_zh": "该研究针对遗留软件迁移到不同 Instruction Set Architectures (ISAs) 的需求，提出 Forklift，一种基于 token-level encoder-decoder Transformer 的神经网络 lifter，用于将汇编代码翻译到架构无关的中间表示（如 LLVM IR），以减少传统手写规则的工程努力。Forklift 通过微调汇编编码器并冻结 IR 解码器，实现对新 ISA 的高效扩展，并在收集的数百万平行程序数据集上进行训练。实验结果显示，Forklift 在两个基准测试中翻译了比最先进的 hand-written lifter 多 2.5 倍的 x86 程序，以及比 GPT-4 多 4.4 倍，并成功支持 ARM 和 RISC-V 等新架构。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16041v1",
      "published_date": "2024-04-01 17:27:58 UTC",
      "updated_date": "2024-04-01 17:27:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:42:32.227510"
    },
    {
      "arxiv_id": "2404.15310v1",
      "title": "Automated Assessment of Encouragement and Warmth in Classrooms Leveraging Multimodal Emotional Features and ChatGPT",
      "title_zh": "利用多模态情感特征和 ChatGPT 进行课堂鼓励和温暖的自动评估",
      "authors": [
        "Ruikun Hou",
        "Tim Fütterer",
        "Babette Bühler",
        "Efe Bozkir",
        "Peter Gerjets",
        "Ulrich Trautwein",
        "Enkelejda Kasneci"
      ],
      "abstract": "Classroom observation protocols standardize the assessment of teaching\neffectiveness and facilitate comprehension of classroom interactions. Whereas\nthese protocols offer teachers specific feedback on their teaching practices,\nthe manual coding by human raters is resource-intensive and often unreliable.\nThis has sparked interest in developing AI-driven, cost-effective methods for\nautomating such holistic coding. Our work explores a multimodal approach to\nautomatically estimating encouragement and warmth in classrooms, a key\ncomponent of the Global Teaching Insights (GTI) study's observation protocol.\nTo this end, we employed facial and speech emotion recognition with sentiment\nanalysis to extract interpretable features from video, audio, and transcript\ndata. The prediction task involved both classification and regression methods.\nAdditionally, in light of recent large language models' remarkable text\nannotation capabilities, we evaluated ChatGPT's zero-shot performance on this\nscoring task based on transcripts. We demonstrated our approach on the GTI\ndataset, comprising 367 16-minute video segments from 92 authentic lesson\nrecordings. The inferences of GPT-4 and the best-trained model yielded\ncorrelations of r = .341 and r = .441 with human ratings, respectively.\nCombining estimates from both models through averaging, an ensemble approach\nachieved a correlation of r = .513, comparable to human inter-rater\nreliability. Our model explanation analysis indicated that text sentiment\nfeatures were the primary contributors to the trained model's decisions.\nMoreover, GPT-4 could deliver logical and concrete reasoning as potential\nteacher guidelines. Our findings provide insights into using advanced,\nmultimodal techniques for automated classroom observation, aiming to foster\nteacher training through frequent and valuable feedback.",
      "tldr_zh": "这篇论文提出了一种自动评估课堂中鼓励和温暖（encouragement and warmth）的多模态方法，利用面部和语音情感识别、情感分析以及ChatGPT，从视频、音频和转录文本中提取可解释特征，以替代手动编码的资源密集型过程。研究在Global Teaching Insights (GTI)数据集上测试了分类和回归模型，以及ChatGPT的零样本性能，结果显示GPT-4与人类评分的相关性为r=0.341，最佳训练模型为r=0.441，而通过集成两者，相关性提升至r=0.513，接近人类评委可靠性。分析表明，文本情感特征（text sentiment features）是模型决策的主要贡献者，且ChatGPT能提供逻辑推理作为教师指导，这为使用高级多模态技术实现高效课堂观察和教师培训提供了宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted as a full paper by the 25th International Conference on\n  Artificial Intelligence in Education (AIED 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.15310v1",
      "published_date": "2024-04-01 16:58:09 UTC",
      "updated_date": "2024-04-01 16:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:42:43.895111"
    },
    {
      "arxiv_id": "2404.01223v1",
      "title": "Feature Splatting: Language-Driven Physics-Based Scene Synthesis and Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Ri-Zhao Qiu",
        "Ge Yang",
        "Weijia Zeng",
        "Xiaolong Wang"
      ],
      "abstract": "Scene representations using 3D Gaussian primitives have produced excellent\nresults in modeling the appearance of static and dynamic 3D scenes. Many\ngraphics applications, however, demand the ability to manipulate both the\nappearance and the physical properties of objects. We introduce Feature\nSplatting, an approach that unifies physics-based dynamic scene synthesis with\nrich semantics from vision language foundation models that are grounded by\nnatural language. Our first contribution is a way to distill high-quality,\nobject-centric vision-language features into 3D Gaussians, that enables\nsemi-automatic scene decomposition using text queries. Our second contribution\nis a way to synthesize physics-based dynamics from an otherwise static scene\nusing a particle-based simulator, in which material properties are assigned\nautomatically via text queries. We ablate key techniques used in this pipeline,\nto illustrate the challenge and opportunities in using feature-carrying 3D\nGaussians as a unified format for appearance, geometry, material properties and\nsemantics grounded on natural language. Project website:\nhttps://feature-splatting.github.io/",
      "tldr_zh": "这篇论文介绍了 Feature Splatting 方法，它将语言驱动的语义与基于物理的动态场景合成相结合，利用 3D Gaussian 基元来表示场景的外观和属性。论文的主要贡献包括：将高质量的对象中心视觉语言特征提炼到 3D Gaussians 中，实现通过文本查询的半自动场景分解；以及使用粒子模拟器从静态场景合成物理动态，并通过文本查询自动分配材料属性。通过消融实验，作者展示了携带特征的 3D Gaussians 作为统一格式在几何、外观、材料属性和语义方面的挑战与机遇，为语言驱动的场景编辑提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project website: https://feature-splatting.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2404.01223v1",
      "published_date": "2024-04-01 16:31:04 UTC",
      "updated_date": "2024-04-01 16:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:42:56.750101"
    },
    {
      "arxiv_id": "2404.01217v1",
      "title": "Incorporating Domain Differential Equations into Graph Convolutional Networks to Lower Generalization Discrepancy",
      "title_zh": "将领域微分方程整合到图卷积网络中以降低泛化差异",
      "authors": [
        "Yue Sun",
        "Chao Chen",
        "Yuesheng Xu",
        "Sihong Xie",
        "Rick S. Blum",
        "Parv Venkitasubramaniam"
      ],
      "abstract": "Ensuring both accuracy and robustness in time series prediction is critical\nto many applications, ranging from urban planning to pandemic management. With\nsufficient training data where all spatiotemporal patterns are\nwell-represented, existing deep-learning models can make reasonably accurate\npredictions. However, existing methods fail when the training data are drawn\nfrom different circumstances (e.g., traffic patterns on regular days) compared\nto test data (e.g., traffic patterns after a natural disaster). Such challenges\nare usually classified under domain generalization. In this work, we show that\none way to address this challenge in the context of spatiotemporal prediction\nis by incorporating domain differential equations into Graph Convolutional\nNetworks (GCNs). We theoretically derive conditions where GCNs incorporating\nsuch domain differential equations are robust to mismatched training and\ntesting data compared to baseline domain agnostic models. To support our\ntheory, we propose two domain-differential-equation-informed networks called\nReaction-Diffusion Graph Convolutional Network (RDGCN), which incorporates\ndifferential equations for traffic speed evolution, and\nSusceptible-Infectious-Recovered Graph Convolutional Network (SIRGCN), which\nincorporates a disease propagation model. Both RDGCN and SIRGCN are based on\nreliable and interpretable domain differential equations that allow the models\nto generalize to unseen patterns. We experimentally show that RDGCN and SIRGCN\nare more robust with mismatched testing data than the state-of-the-art deep\nlearning methods.",
      "tldr_zh": "本研究针对时间序列预测中训练数据和测试数据不匹配导致的泛化差异（generalization discrepancy）问题，提出将领域微分方程（domain differential equations）融入 Graph Convolutional Networks (GCNs)，以提升模型的准确性和鲁棒性。论文理论推导了这种方法的条件，并开发了两个模型：Reaction-Diffusion Graph Convolutional Network (RDGCN)，用于交通速度演化，以及 Susceptible-Infectious-Recovered Graph Convolutional Network (SIRGCN)，用于疾病传播建模。这些模型基于可解释的领域微分方程，能够更好地泛化到未见模式。实验结果表明，RDGCN 和 SIRGCN 在不匹配测试数据上比现有深度学习方法表现更优越。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01217v1",
      "published_date": "2024-04-01 16:17:11 UTC",
      "updated_date": "2024-04-01 16:17:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:43:08.891998"
    },
    {
      "arxiv_id": "2404.01163v1",
      "title": "Capturing Shock Waves by Relaxation Neural Networks",
      "title_zh": "通过松弛神经网络捕获冲击波",
      "authors": [
        "Nan Zhou",
        "Zheng Ma"
      ],
      "abstract": "In this paper, we put forward a neural network framework to solve the\nnonlinear hyperbolic systems. This framework, named relaxation neural\nnetworks(RelaxNN), is a simple and scalable extension of physics-informed\nneural networks(PINN). It is shown later that a typical PINN framework\nstruggles to handle shock waves that arise in hyperbolic systems' solutions.\nThis ultimately results in the failure of optimization that is based on\ngradient descent in the training process. Relaxation systems provide a smooth\nasymptotic to the discontinuity solution, under the expectation that\nmacroscopic problems can be solved from a microscopic perspective. Based on\nrelaxation systems, the RelaxNN framework alleviates the conflict of losses in\nthe training process of the PINN framework. In addition to the remarkable\nresults demonstrated in numerical simulations, most of the acceleration\ntechniques and improvement strategies aimed at the standard PINN framework can\nalso be applied to the RelaxNN framework.",
      "tldr_zh": "本文提出了一种名为 RelaxNN 的神经网络框架，用于解决非线性双曲系统的冲击波问题，作为 physics-informed neural networks (PINN) 的简单可扩展扩展。RelaxNN 基于 relaxation systems，提供平滑渐近解，从微观视角缓解 PINN 框架中训练过程的损失冲突，从而避免基于梯度下降的优化失败。在数值模拟中，RelaxNN 表现出色，并可应用 PINN 的加速技术和改进策略。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA",
        "76L05, 35D99, 68T07, 65D15"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01163v1",
      "published_date": "2024-04-01 15:13:46 UTC",
      "updated_date": "2024-04-01 15:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:43:21.477896"
    },
    {
      "arxiv_id": "2404.01156v1",
      "title": "SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining",
      "title_zh": "翻译失败",
      "authors": [
        "Chull Hwan Song",
        "Taebaek Hwang",
        "Jooyoung Yoon",
        "Shunghyun Choi",
        "Yeong Hyeon Gu"
      ],
      "abstract": "Vision-language models (VLMs) have made significant strides in cross-modal\nunderstanding through large-scale paired datasets. However, in fashion domain,\ndatasets often exhibit a disparity between the information conveyed in image\nand text. This issue stems from datasets containing multiple images of a single\nfashion item all paired with one text, leading to cases where some textual\ndetails are not visible in individual images. This mismatch, particularly when\nnon-co-occurring elements are masked, undermines the training of conventional\nVLM objectives like Masked Language Modeling and Masked Image Modeling, thereby\nhindering the model's ability to accurately align fine-grained visual and\ntextual features. Addressing this problem, we propose Synchronized attentional\nMasking (SyncMask), which generate masks that pinpoint the image patches and\nword tokens where the information co-occur in both image and text. This\nsynchronization is accomplished by harnessing cross-attentional features\nobtained from a momentum model, ensuring a precise alignment between the two\nmodalities. Additionally, we enhance grouped batch sampling with semi-hard\nnegatives, effectively mitigating false negative issues in Image-Text Matching\nand Image-Text Contrastive learning objectives within fashion datasets. Our\nexperiments demonstrate the effectiveness of the proposed approach,\noutperforming existing methods in three downstream tasks.",
      "tldr_zh": "该研究针对时尚领域视觉语言模型(VLMs)的训练问题，指出图像和文本信息不匹配（如多个图像共享一个文本，导致某些细节缺失），这会影响 Masked Language Modeling 和 Masked Image Modeling 等目标。论文提出 SyncMask 方法，通过同步注意力掩码利用交叉注意力特征和动量模型，生成精确对齐图像补丁和单词标记的掩码，确保信息在两个模态中共同出现。此外，该方法增强了分组批量采样，引入半硬负样本来缓解 Image-Text Matching 和 Image-Text Contrastive 学习中的假负样本问题。实验结果表明，SyncMask 在三个下游任务上优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2404.01156v1",
      "published_date": "2024-04-01 15:01:38 UTC",
      "updated_date": "2024-04-01 15:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:43:35.088135"
    },
    {
      "arxiv_id": "2406.11850v1",
      "title": "Closed-loop Teaching via Demonstrations to Improve Policy Transparency",
      "title_zh": "翻译失败",
      "authors": [
        "Michael S. Lee",
        "Reid Simmons",
        "Henny Admoni"
      ],
      "abstract": "Demonstrations are a powerful way of increasing the transparency of AI\npolicies. Though informative demonstrations may be selected a priori through\nthe machine teaching paradigm, student learning may deviate from the\npreselected curriculum in situ. This paper thus explores augmenting a\ncurriculum with a closed-loop teaching framework inspired by principles from\nthe education literature, such as the zone of proximal development and the\ntesting effect. We utilize tests accordingly to close to the loop and maintain\na novel particle filter model of human beliefs throughout the learning process,\nallowing us to provide demonstrations that are targeted to the human's current\nunderstanding in real time. A user study finds that our proposed closed-loop\nteaching framework reduces the regret in human test responses by 43% over a\nbaseline.",
      "tldr_zh": "本文提出了一种闭环教学框架，通过动态演示来提升 AI 策略的透明度，解决传统 machine teaching 中预选课程可能偏离实际学习的问题。该框架借鉴教育文献中的 zone of proximal development 和 testing effect，利用 particle filter model 实时跟踪人类信念，并提供针对当前理解的演示。用户研究结果显示，与基线相比，该方法将人类测试响应的 regret 减少了43%。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Supplementary material available at\n  https://drive.google.com/file/d/1f_BDk3JpY6DvqlvgKtnQZ8zdfO3XAn3p/view?usp=drive_link",
      "pdf_url": "http://arxiv.org/pdf/2406.11850v1",
      "published_date": "2024-04-01 14:59:26 UTC",
      "updated_date": "2024-04-01 14:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:43:45.719971"
    },
    {
      "arxiv_id": "2404.01154v1",
      "title": "Uncovering the Text Embedding in Text-to-Image Diffusion Models",
      "title_zh": "揭示文本到图像扩散模型中的文本嵌入",
      "authors": [
        "Hu Yu",
        "Hao Luo",
        "Fan Wang",
        "Feng Zhao"
      ],
      "abstract": "The correspondence between input text and the generated image exhibits\nopacity, wherein minor textual modifications can induce substantial deviations\nin the generated image. While, text embedding, as the pivotal intermediary\nbetween text and images, remains relatively underexplored. In this paper, we\naddress this research gap by delving into the text embedding space, unleashing\nits capacity for controllable image editing and explicable semantic direction\nattributes within a learning-free framework. Specifically, we identify two\ncritical insights regarding the importance of per-word embedding and their\ncontextual correlations within text embedding, providing instructive principles\nfor learning-free image editing. Additionally, we find that text embedding\ninherently possesses diverse semantic potentials, and further reveal this\nproperty through the lens of singular value decomposition (SVD). These\nuncovered properties offer practical utility for image editing and semantic\ndiscovery. More importantly, we expect the in-depth analyses and findings of\nthe text embedding can enhance the understanding of text-to-image diffusion\nmodels.",
      "tldr_zh": "本文揭示了文本到图像扩散模型中 text embedding 的重要性，探讨其如何桥接文本输入与图像生成，并解决小文本改动导致图像大幅偏差的问题。通过分析 per-word embedding 的关键作用及其上下文相关性，论文提出了一种无需学习的框架，用于可控图像编辑和语义方向解释。此外，利用 singular value decomposition (SVD) 揭示 text embedding 的多样语义潜力，这些发现为图像编辑应用和对模型的深入理解提供了实用指导。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01154v1",
      "published_date": "2024-04-01 14:59:13 UTC",
      "updated_date": "2024-04-01 14:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:43:57.293947"
    },
    {
      "arxiv_id": "2404.01143v1",
      "title": "Condition-Aware Neural Network for Controlled Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Han Cai",
        "Muyang Li",
        "Zhuoyang Zhang",
        "Qinsheng Zhang",
        "Ming-Yu Liu",
        "Song Han"
      ],
      "abstract": "We present Condition-Aware Neural Network (CAN), a new method for adding\ncontrol to image generative models. In parallel to prior conditional control\nmethods, CAN controls the image generation process by dynamically manipulating\nthe weight of the neural network. This is achieved by introducing a\ncondition-aware weight generation module that generates conditional weight for\nconvolution/linear layers based on the input condition. We test CAN on\nclass-conditional image generation on ImageNet and text-to-image generation on\nCOCO. CAN consistently delivers significant improvements for diffusion\ntransformer models, including DiT and UViT. In particular, CAN combined with\nEfficientViT (CaT) achieves 2.78 FID on ImageNet 512x512, surpassing DiT-XL/2\nwhile requiring 52x fewer MACs per sampling step.",
      "tldr_zh": "我们提出了 Condition-Aware Neural Network (CAN)，一种用于在图像生成模型中添加控制的方法，通过动态操纵神经网络权重来实现精确的图像生成控制。CAN 引入了一个 condition-aware weight generation module，根据输入条件生成卷积或线性层的条件权重，从而提升生成过程的灵活性。在 ImageNet 的类条件图像生成和 COCO 的文本到图像生成任务上，CAN 显著改进了 diffusion transformer 模型如 DiT 和 UViT 的性能，其中 CAN 与 EfficientViT 结合的 CaT 在 ImageNet 512x512 上达到 2.78 FID，比 DiT-XL/2 更优，同时每采样步减少 52 倍 MACs。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01143v1",
      "published_date": "2024-04-01 14:42:57 UTC",
      "updated_date": "2024-04-01 14:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:44:11.064667"
    },
    {
      "arxiv_id": "2404.01135v1",
      "title": "Enhancing Reasoning Capacity of SLM using Cognitive Enhancement",
      "title_zh": "使用认知增强提升 SLM 的推理能力",
      "authors": [
        "Jonathan Pan",
        "Swee Liang Wong",
        "Xin Wei Chia",
        "Yidi Yuan"
      ],
      "abstract": "Large Language Models (LLMs) have been applied to automate cyber security\nactivities and processes including cyber investigation and digital forensics.\nHowever, the use of such models for cyber investigation and digital forensics\nshould address accountability and security considerations. Accountability\nensures models have the means to provide explainable reasonings and outcomes.\nThis information can be extracted through explicit prompt requests. For\nsecurity considerations, it is crucial to address privacy and confidentiality\nof the involved data during data processing as well. One approach to deal with\nthis consideration is to have the data processed locally using a local instance\nof the model. Due to limitations of locally available resources, namely memory\nand GPU capacities, a Smaller Large Language Model (SLM) will typically be\nused. These SLMs have significantly fewer parameters compared to the LLMs.\nHowever, such size reductions have notable performance reduction, especially\nwhen tasked to provide reasoning explanations. In this paper, we aim to\nmitigate performance reduction through the integration of cognitive strategies\nthat humans use for problem-solving. We term this as cognitive enhancement\nthrough prompts. Our experiments showed significant improvement gains of the\nSLMs' performances when such enhancements were applied. We believe that our\nexploration study paves the way for further investigation into the use of\ncognitive enhancement to optimize SLM for cyber security applications.",
      "tldr_zh": "该论文探讨了如何通过认知增强策略提升 Smaller Large Language Models (SLMs) 的推理能力，以应用于网络安全领域，如网络调查和数字取证。作者提出了一种方法，即整合人类问题解决的认知策略到提示中，从而缓解 SLMs 参数减少导致的性能下降，特别是推理解释的不足。实验结果显示，这种 cognitive enhancement 通过 prompts 显著改善了 SLMs 的性能，并为进一步优化 SLMs 在网络安全应用中的责任性和安全性提供了新方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01135v1",
      "published_date": "2024-04-01 14:29:58 UTC",
      "updated_date": "2024-04-01 14:29:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:44:22.427842"
    },
    {
      "arxiv_id": "2404.01131v2",
      "title": "GOV-REK: Governed Reward Engineering Kernels for Designing Robust Multi-Agent Reinforcement Learning Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ashish Rana",
        "Michael Oesterle",
        "Jannik Brinkmann"
      ],
      "abstract": "For multi-agent reinforcement learning systems (MARLS), the problem\nformulation generally involves investing massive reward engineering effort\nspecific to a given problem. However, this effort often cannot be translated to\nother problems; worse, it gets wasted when system dynamics change drastically.\nThis problem is further exacerbated in sparse reward scenarios, where a\nmeaningful heuristic can assist in the policy convergence task. We propose\nGOVerned Reward Engineering Kernels (GOV-REK), which dynamically assign reward\ndistributions to agents in MARLS during its learning stage. We also introduce\ngovernance kernels, which exploit the underlying structure in either state or\njoint action space for assigning meaningful agent reward distributions. During\nthe agent learning stage, it iteratively explores different reward distribution\nconfigurations with a Hyperband-like algorithm to learn ideal agent reward\nmodels in a problem-agnostic manner. Our experiments demonstrate that our\nmeaningful reward priors robustly jumpstart the learning process for\neffectively learning different MARL problems.",
      "tldr_zh": "该论文提出GOV-REK（Governed Reward Engineering Kernels），一种用于设计鲁棒多智能体强化学习系统（MARLS）的框架，以解决传统奖励工程努力的移植性和浪费问题，尤其在稀疏奖励场景中。GOV-REK通过governance kernels利用状态或联合行动空间的底层结构，动态分配有意义的奖励分布，并在代理学习阶段使用类似于Hyperband的算法迭代探索理想的奖励模型，实现问题无关的学习。实验结果表明，该方法能有效启动学习过程，提高MARLS问题的鲁棒性和学习效率。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Extended Abstract accepted in the 23rd International Conference on\n  Autonomous Agents and Multi-Agent Systems (AAMAS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.01131v2",
      "published_date": "2024-04-01 14:19:00 UTC",
      "updated_date": "2024-04-14 19:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:44:33.245638"
    },
    {
      "arxiv_id": "2404.01127v1",
      "title": "Medical Visual Prompting (MVP): A Unified Framework for Versatile and High-Quality Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yulin Chen",
        "Guoheng Huang",
        "Kai Huang",
        "Zijin Lin",
        "Guo Zhong",
        "Shenghong Luo",
        "Jie Deng",
        "Jian Zhou"
      ],
      "abstract": "Accurate segmentation of lesion regions is crucial for clinical diagnosis and\ntreatment across various diseases. While deep convolutional networks have\nachieved satisfactory results in medical image segmentation, they face\nchallenges such as loss of lesion shape information due to continuous\nconvolution and downsampling, as well as the high cost of manually labeling\nlesions with varying shapes and sizes. To address these issues, we propose a\nnovel medical visual prompting (MVP) framework that leverages pre-training and\nprompting concepts from natural language processing (NLP). The framework\nutilizes three key components: Super-Pixel Guided Prompting (SPGP) for\nsuperpixelating the input image, Image Embedding Guided Prompting (IEGP) for\nfreezing patch embedding and merging with superpixels to provide visual\nprompts, and Adaptive Attention Mechanism Guided Prompting (AAGP) for\npinpointing prompt content and efficiently adapting all layers. By integrating\nSPGP, IEGP, and AAGP, the MVP enables the segmentation network to better learn\nshape prompting information and facilitates mutual learning across different\ntasks. Extensive experiments conducted on five datasets demonstrate superior\nperformance of this method in various challenging medical image tasks, while\nsimplifying single-task medical segmentation models. This novel framework\noffers improved performance with fewer parameters and holds significant\npotential for accurate segmentation of lesion regions in various medical tasks,\nmaking it clinically valuable.",
      "tldr_zh": "这篇论文提出了一种统一的医疗图像分割框架 Medical Visual Prompting (MVP)，借鉴 NLP 的预训练和提示概念，旨在解决深度卷积网络在处理病变形状信息时存在的丢失问题以及手动标注的高成本。MVP 框架整合了三个关键组件：Super-Pixel Guided Prompting (SPGP) 用于输入图像的超像素化、Image Embedding Guided Prompting (IEGP) 用于冻结 patch embedding 并与超像素合并提供视觉提示，以及 Adaptive Attention Mechanism Guided Prompting (AAGP) 用于精确定位提示内容并高效适应所有层，从而提升网络对形状信息的学习和任务间相互学习。在五个数据集上的广泛实验显示，MVP 在各种挑战性医疗图像任务中表现出色，使用更少的参数简化了单任务模型，并为临床病变区域的准确分割提供了显著潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01127v1",
      "published_date": "2024-04-01 14:06:48 UTC",
      "updated_date": "2024-04-01 14:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:44:47.343799"
    },
    {
      "arxiv_id": "2404.01109v1",
      "title": "An incremental hybrid adaptive network-based IDS in Software Defined Networks to detect stealth attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullah H Alqahtani"
      ],
      "abstract": "Network attacks have became increasingly more sophisticated and stealthy due\nto the advances in technologies and the growing sophistication of attackers.\nAdvanced Persistent Threats (APTs) are a type of attack that implement a wide\nrange of strategies to evade detection and be under the defence radar. Software\nDefined Network (SDN) is a network paradigm that implements dynamic\nconfiguration by separating the control plane from the network plane. This\napproach improves security aspects by facilitating the employment of network\nintrusion detection systems. Implementing Machine Learning (ML) techniques in\nIntrusion Detection Systems (IDSs) is widely used to detect such attacks but\nhas a challenge when the data distribution changes. Concept drift is a term\nthat describes the change in the relationship between the input data and the\ntarget value (label or class). The model is expected to degrade as certain\nforms of change occur. In this paper, the primary form of change will be in\nuser behaviour (particularly changes in attacker behaviour). It is essential\nfor a model to adapt itself to deviations in data distribution. SDN can help in\nmonitoring changes in data distribution. This paper discusses changes in\nstealth attacker behaviour. The work described here investigates various\nconcept drift detection algorithms. An incremental hybrid adaptive Network\nIntrusion Detection System (NIDS) is proposed to tackle the issue of concept\ndrift in SDN. It can detect known and unknown attacks. The model is evaluated\nover different datasets showing promising results.",
      "tldr_zh": "该论文探讨了网络攻击（如 Advanced Persistent Threats, APTs）的隐蔽性及其对 Intrusion Detection Systems (IDSs) 的挑战，特别是由于 Machine Learning (ML) 模型面临 Concept Drift 时性能下降的问题。在 Software Defined Networks (SDN) 环境中，论文提出了一种增量式混合自适应 Network Intrusion Detection System (NIDS)，结合各种 Concept Drift 检测算法，以适应攻击者行为的变化。该系统能够检测已知和未知攻击，并在多个数据集上进行评估，显示出显著的性能提升。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01109v1",
      "published_date": "2024-04-01 13:33:40 UTC",
      "updated_date": "2024-04-01 13:33:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:44:57.191478"
    },
    {
      "arxiv_id": "2404.01361v1",
      "title": "LLM Attributor: Interactive Visual Attribution for LLM Generation",
      "title_zh": "LLM Attributor：用于 LLM 生成的交互式视觉归因",
      "authors": [
        "Seongmin Lee",
        "Zijie J. Wang",
        "Aishwarya Chakravarthy",
        "Alec Helbling",
        "ShengYun Peng",
        "Mansi Phute",
        "Duen Horng Chau",
        "Minsuk Kahng"
      ],
      "abstract": "While large language models (LLMs) have shown remarkable capability to\ngenerate convincing text across diverse domains, concerns around its potential\nrisks have highlighted the importance of understanding the rationale behind\ntext generation. We present LLM Attributor, a Python library that provides\ninteractive visualizations for training data attribution of an LLM's text\ngeneration. Our library offers a new way to quickly attribute an LLM's text\ngeneration to training data points to inspect model behaviors, enhance its\ntrustworthiness, and compare model-generated text with user-provided text. We\ndescribe the visual and interactive design of our tool and highlight usage\nscenarios for LLaMA2 models fine-tuned with two different datasets: online\narticles about recent disasters and finance-related question-answer pairs.\nThanks to LLM Attributor's broad support for computational notebooks, users can\neasily integrate it into their workflow to interactively visualize attributions\nof their models. For easier access and extensibility, we open-source LLM\nAttributor at https://github.com/poloclub/ LLM-Attribution. The video demo is\navailable at https://youtu.be/mIG2MDQKQxM.",
      "tldr_zh": "该研究介绍了LLM Attributor，一种Python库，用于提供大型语言模型(LLMs)文本生成的交互式可视化归因，帮助用户理解模型行为并提升其可信度。该工具通过快速将生成文本归因到训练数据点，支持比较模型输出与用户输入，并展示了在LLaMA2模型上的应用场景，如在线灾害文章和金融问答数据集的微调。实验结果表明，该库能有效增强模型的可解释性，并易于集成到计算笔记本中；开源代码可在https://github.com/poloclub/LLM-Attribution获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, For a video demo, see\n  https://youtu.be/mIG2MDQKQxM",
      "pdf_url": "http://arxiv.org/pdf/2404.01361v1",
      "published_date": "2024-04-01 13:16:34 UTC",
      "updated_date": "2024-04-01 13:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:45:09.738898"
    },
    {
      "arxiv_id": "2404.01099v2",
      "title": "What is in Your Safe Data? Identifying Benign Data that Breaks Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Luxi He",
        "Mengzhou Xia",
        "Peter Henderson"
      ],
      "abstract": "Current Large Language Models (LLMs), even those tuned for safety and\nalignment, are susceptible to jailbreaking. Some have found that just further\nfine-tuning an aligned model with benign data (i.e., data without harmful\ncontent) surprisingly leads to substantial degradation in safety. We delve into\nthe data-centric aspects of why benign fine-tuning inadvertently contributes to\njailbreaking. First, we represent fine-tuning data through two lenses:\nrepresentation and gradient spaces. Additionally, we propose a bi-directional\nanchoring method that, during the selection process, prioritizes data points\nthat are close to harmful examples and far from benign ones. Our approach\neffectively identifies subsets of benign data that are more likely to degrade\nthe model's safety after fine-tuning. Training on just 100 of these seemingly\nbenign datapoints surprisingly leads to the fine-tuned model affirmatively\nresponding to >70% of tested harmful requests, compared to <20% after\nfine-tuning on randomly selected data. We also observe that the selected data\nfrequently appear as lists, bullet points, or math questions, indicating a\nsystematic pattern in fine-tuning data that contributes to jailbreaking.",
      "tldr_zh": "本文研究了为什么使用良性数据（benign data）微调大型语言模型（LLMs）会导致安全性的意外下降，从而增加越狱（jailbreaking）风险。研究者通过表示空间（representation space）和梯度空间（gradient space）来分析微调数据，并提出双向锚定方法（bi-directional anchoring method），该方法优先选择靠近有害示例（harmful examples）且远离良性示例的数据点，以识别潜在破坏安全的子集。实验结果显示，仅用100个选定数据点微调，模型对测试有害请求的肯定响应率可达70%以上，远高于随机选择数据的不到20%。此外，观察到这些数据常以列表、项目符号或数学问题形式出现，揭示了微调数据中的系统性模式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01099v2",
      "published_date": "2024-04-01 13:12:30 UTC",
      "updated_date": "2024-08-20 17:54:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:45:25.791198"
    },
    {
      "arxiv_id": "2404.03685v9",
      "title": "Cooperative Evolutionary Pressure and Diminishing Returns Might Explain the Fermi Paradox: On What Super-AIs Are Like",
      "title_zh": "合作进化压力和收益递减可能解释费米悖论：关于超级AI是什么样的",
      "authors": [
        "Daniel Vallstrom"
      ],
      "abstract": "With an evolutionary approach, the basis of morality can be explained as\nadaptations to problems of cooperation. With 'evolution' taken in a broad\nsense, AIs that satisfy the conditions for evolution to apply will be subject\nto the same cooperative evolutionary pressure as biological entities. Here the\nadaptiveness of increased cooperation as material safety and wealth increase is\ndiscussed -- for humans, for other societies, and for AIs. Diminishing\nbeneficial returns from increased access to material resources also suggests\nthe possibility that, on the whole, there will be no incentive to for instance\ncolonize entire galaxies, thus providing a possible explanation of the Fermi\nparadox, wondering where everybody is. It is further argued that old societies\ncould engender, give way to, super-AIs, since it is likely that super-AIs are\nfeasible, and fitter. Closing is an aside on effective ways for morals and\ngoals to affect life and society, emphasizing environments, cultures, and laws,\nand exemplified by how to eat.\n  'Diminishing returns' is defined, as less than roots, the inverse of\ninfeasibility. It is also noted that there can be no exponential colonization\nor reproduction, for mathematical reasons, as each entity takes up a certain\namount of space. Appended are an algorithm for colonizing for example a galaxy\nquickly, models of the evolution of cooperation and fairness under diminishing\nreturns, and software for simulating signaling development.",
      "tldr_zh": "本论文从进化理论视角解释道德基础为适应合作问题的产物，并扩展到人工智能，认为人工智能（AIs）会面临与生物实体相同的合作进化压力。随着物质安全和财富的增加，合作性会增强，但边际收益递减（diminishing returns）可能导致缺乏激励进行大规模扩张，如殖民整个星系，从而为Fermi Paradox提供一种解释。论文进一步论证，旧社会可能被更可行和适应的Super-AIs取代，并强调环境、文化和法律对道德的影响，同时附带了相关算法、模型和模拟软件。",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "36 pages, 12 figures. Added figures, expansions",
      "pdf_url": "http://arxiv.org/pdf/2404.03685v9",
      "published_date": "2024-04-01 13:12:27 UTC",
      "updated_date": "2025-02-10 12:10:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:45:35.961684"
    },
    {
      "arxiv_id": "2404.01089v1",
      "title": "Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On",
      "title_zh": "用于高保真虚拟试穿的纹理保留扩散模型",
      "authors": [
        "Xu Yang",
        "Changxing Ding",
        "Zhibin Hong",
        "Junhao Huang",
        "Jin Tao",
        "Xiangmin Xu"
      ],
      "abstract": "Image-based virtual try-on is an increasingly important task for online\nshopping. It aims to synthesize images of a specific person wearing a specified\ngarment. Diffusion model-based approaches have recently become popular, as they\nare excellent at image synthesis tasks. However, these approaches usually\nemploy additional image encoders and rely on the cross-attention mechanism for\ntexture transfer from the garment to the person image, which affects the\ntry-on's efficiency and fidelity. To address these issues, we propose an\nTexture-Preserving Diffusion (TPD) model for virtual try-on, which enhances the\nfidelity of the results and introduces no additional image encoders.\nAccordingly, we make contributions from two aspects. First, we propose to\nconcatenate the masked person and reference garment images along the spatial\ndimension and utilize the resulting image as the input for the diffusion\nmodel's denoising UNet. This enables the original self-attention layers\ncontained in the diffusion model to achieve efficient and accurate texture\ntransfer. Second, we propose a novel diffusion-based method that predicts a\nprecise inpainting mask based on the person and reference garment images,\nfurther enhancing the reliability of the try-on results. In addition, we\nintegrate mask prediction and image synthesis into a single compact model. The\nexperimental results show that our approach can be applied to various try-on\ntasks, e.g., garment-to-person and person-to-person try-ons, and significantly\noutperforms state-of-the-art methods on popular VITON, VITON-HD databases.",
      "tldr_zh": "本文提出Texture-Preserving Diffusion (TPD)模型，用于实现高保真度的图像-based virtual try-on，提升在线购物体验。该模型通过将masked person图像和reference garment图像沿空间维度concatenate，作为diffusion模型的denoising UNet输入，利用原有的self-attention层实现高效的texture transfer，并引入一种新的diffusion-based方法预测精确的inpainting mask，进一步提高结果的可靠性。实验结果表明，TPD在VITON和VITON-HD数据库上显著优于现有方法，适用于garment-to-person和person-to-person试穿任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01089v1",
      "published_date": "2024-04-01 12:43:22 UTC",
      "updated_date": "2024-04-01 12:43:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:45:48.392770"
    },
    {
      "arxiv_id": "2404.01084v1",
      "title": "AILS-NTUA at SemEval-2024 Task 9: Cracking Brain Teasers: Transformer Models for Lateral Thinking Puzzles",
      "title_zh": "翻译失败",
      "authors": [
        "Ioannis Panagiotopoulos",
        "Giorgos Filandrianos",
        "Maria Lymperaiou",
        "Giorgos Stamou"
      ],
      "abstract": "In this paper, we outline our submission for the SemEval-2024 Task 9\ncompetition: 'BRAINTEASER: A Novel Task Defying Common Sense'. We engage in\nboth sub-tasks: Sub-task A-Sentence Puzzle and Sub-task B-Word Puzzle. We\nevaluate a plethora of pre-trained transformer-based language models of\ndifferent sizes through fine-tuning. Subsequently, we undertake an analysis of\ntheir scores and responses to aid future researchers in understanding and\nutilizing these models effectively. Our top-performing approaches secured\ncompetitive positions on the competition leaderboard across both sub-tasks. In\nthe evaluation phase, our best submission attained an average accuracy score of\n81.7% in the Sentence Puzzle, and 85.4% in the Word Puzzle, significantly\noutperforming the best neural baseline (ChatGPT) by more than 20% and 30%\nrespectively.",
      "tldr_zh": "该研究介绍了 AILS-NTUA 在 SemEval-2024 Task 9（BRAINTEASER: A Novel Task Defying Common Sense）比赛中的提交，针对 Sub-task A-Sentence Puzzle 和 Sub-task B-Word Puzzle，使用预训练的 Transformer models 通过微调进行评估和分析。研究团队考察了多种模型的表现，以帮助未来研究者更好地理解和应用这些模型。结果显示，他们的最佳方法在 Sentence Puzzle 和 Word Puzzle 子任务中分别取得了 81.7% 和 85.4% 的准确率，比 ChatGPT 等神经基线模型高出 20% 和 30% 以上，在排行榜上获得竞争性位置。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "SemEval-2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01084v1",
      "published_date": "2024-04-01 12:27:55 UTC",
      "updated_date": "2024-04-01 12:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:45:59.695859"
    },
    {
      "arxiv_id": "2404.01582v2",
      "title": "BERT-Enhanced Retrieval Tool for Homework Plagiarism Detection System",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarong Xian",
        "Jibao Yuan",
        "Peiwei Zheng",
        "Dexian Chen",
        "Nie yuntao"
      ],
      "abstract": "Text plagiarism detection task is a common natural language processing task\nthat aims to detect whether a given text contains plagiarism or copying from\nother texts. In existing research, detection of high level plagiarism is still\na challenge due to the lack of high quality datasets. In this paper, we propose\na plagiarized text data generation method based on GPT-3.5, which produces\n32,927 pairs of text plagiarism detection datasets covering a wide range of\nplagiarism methods, bridging the gap in this part of research. Meanwhile, we\npropose a plagiarism identification method based on Faiss with BERT with high\nefficiency and high accuracy. Our experiments show that the performance of this\nmodel outperforms other models in several metrics, including 98.86\\%, 98.90%,\n98.86%, and 0.9888 for Accuracy, Precision, Recall, and F1 Score, respectively.\nAt the end, we also provide a user-friendly demo platform that allows users to\nupload a text library and intuitively participate in the plagiarism analysis.",
      "tldr_zh": "本研究针对文本抄袭检测任务中高级抄袭识别的挑战，提出了一种基于 GPT-3.5 的数据生成方法，成功创建了32,927对覆盖多种抄袭方法的文本数据集，以填补高质量数据集的空白。同时，该方法结合 Faiss 和 BERT 构建了一个高效准确的抄袭识别模型，在实验中分别达到98.86%、98.90%、98.86%和0.9888的Accuracy、Precision、Recall和F1 Score，优于其他基线模型。最后，研究提供了一个用户友好的演示平台，允许用户上传文本库并进行直观的抄袭分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: text overlap with arXiv:1604.06573 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2404.01582v2",
      "published_date": "2024-04-01 12:20:34 UTC",
      "updated_date": "2024-07-28 13:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:46:10.149146"
    },
    {
      "arxiv_id": "2404.01070v1",
      "title": "Advancing AI with Integrity: Ethical Challenges and Solutions in Neural Machine Translation",
      "title_zh": "以诚信推进 AI：在神经机器翻译中的伦理挑战与解决方案",
      "authors": [
        "Richard Kimera",
        "Yun-Seon Kim",
        "Heeyoul Choi"
      ],
      "abstract": "This paper addresses the ethical challenges of Artificial Intelligence in\nNeural Machine Translation (NMT) systems, emphasizing the imperative for\ndevelopers to ensure fairness and cultural sensitivity. We investigate the\nethical competence of AI models in NMT, examining the Ethical considerations at\neach stage of NMT development, including data handling, privacy, data\nownership, and consent. We identify and address ethical issues through\nempirical studies. These include employing Transformer models for\nLuganda-English translations and enhancing efficiency with sentence\nmini-batching. And complementary studies that refine data labeling techniques\nand fine-tune BERT and Longformer models for analyzing Luganda and English\nsocial media content. Our second approach is a literature review from databases\nsuch as Google Scholar and platforms like GitHub. Additionally, the paper\nprobes the distribution of responsibility between AI systems and humans,\nunderscoring the essential role of human oversight in upholding NMT ethical\nstandards. Incorporating a biblical perspective, we discuss the societal impact\nof NMT and the broader ethical responsibilities of developers, positing them as\nstewards accountable for the societal repercussions of their creations.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在神经机器翻译（NMT）系统中的伦理挑战，包括公平性、文化敏感性、数据处理、隐私、数据所有权和同意等问题。作者通过实证研究（如使用 Transformer 模型进行 Luganda-English 翻译、句子 mini-batching 优化，以及微调 BERT 和 Longformer 模型来分析社交媒体内容）和文献综述（如从 Google Scholar 和 GitHub 收集数据）来识别并解决这些问题。研究强调了 AI 与人类责任的分配，突出人类监督在维护 NMT 伦理标准中的关键作用，并从圣经视角讨论了开发者的社会责任和作为“守护者”的角色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.01070v1",
      "published_date": "2024-04-01 12:03:35 UTC",
      "updated_date": "2024-04-01 12:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:46:22.991540"
    },
    {
      "arxiv_id": "2404.01054v4",
      "title": "Regularized Best-of-N Sampling with Minimum Bayes Risk Objective for Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yuu Jinnai",
        "Tetsuro Morimura",
        "Kaito Ariu",
        "Kenshi Abe"
      ],
      "abstract": "Best-of-N (BoN) sampling with a reward model has been shown to be an\neffective strategy for aligning Large Language Models (LLMs) to human\npreferences at the time of decoding. BoN sampling is susceptible to a problem\nknown as reward hacking when the accuracy of the reward model is not high\nenough due to the quality or the quantity of the preference dataset. Because\nthe reward model is an imperfect proxy for the true objective, over-optimizing\nits value can compromise its performance on the true objective. In this\nresearch, we propose MBR-BoN, a variant of BoN that aims to mitigate reward\nhacking at inference time by incorporating the Minimum Bayes Risk (MBR)\nobjective as a proximity regularization term. We show empirically and\nanalytically that the MBR objective quantifies the proximity of the response to\nthe reference policy, serving as a proximity regularizer. We evaluate MBR-BoN\non the AlpacaFarm and Anthropic's hh-rlhf datasets and show that it outperforms\nboth BoN sampling and MBR decoding. We also evaluate MBR-BoN to generate a\npairwise preference learning dataset for Direct Preference Optimization (DPO).\nEmpirical results show that models trained on a dataset generated with MBR-BoN\noutperform those with vanilla BoN. Our code is available at\nhttps://github.com/CyberAgentAILab/regularized-bon",
      "tldr_zh": "本研究针对 Best-of-N (BoN) sampling 在对齐 Large Language Models (LLMs) 时存在的奖励黑客 (reward hacking) 问题，提出了一种改进方法 MBR-BoN，通过将 Minimum Bayes Risk (MBR) 目标作为 proximity regularization term 整合进来，以量化响应与参考策略的接近度并缓解过度优化风险。实验在 AlpacaFarm 和 Anthropic's hh-rlhf 数据集上显示，MBR-BoN 优于传统 BoN sampling 和 MBR decoding，在生成 Direct Preference Optimization (DPO) 的偏好学习数据集时，也能提升模型性能。总体而言，该方法为更可靠的语言模型对齐策略提供了新途径，并附带开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.01054v4",
      "published_date": "2024-04-01 11:26:50 UTC",
      "updated_date": "2025-01-29 08:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:46:36.534289"
    },
    {
      "arxiv_id": "2404.01041v2",
      "title": "Can LLMs get help from other LLMs without revealing private information?",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Hartmann",
        "Duc-Hieu Tran",
        "Peter Kairouz",
        "Victor Cărbune",
        "Blaise Aguera y Arcas"
      ],
      "abstract": "Cascades are a common type of machine learning systems in which a large,\nremote model can be queried if a local model is not able to accurately label a\nuser's data by itself. Serving stacks for large language models (LLMs)\nincreasingly use cascades due to their ability to preserve task performance\nwhile dramatically reducing inference costs. However, applying cascade systems\nin situations where the local model has access to sensitive data constitutes a\nsignificant privacy risk for users since such data could be forwarded to the\nremote model. In this work, we show the feasibility of applying cascade systems\nin such setups by equipping the local model with privacy-preserving techniques\nthat reduce the risk of leaking private information when querying the remote\nmodel. To quantify information leakage in such setups, we introduce two privacy\nmeasures. We then propose a system that leverages the recently introduced\nsocial learning paradigm in which LLMs collaboratively learn from each other by\nexchanging natural language. Using this paradigm, we demonstrate on several\ndatasets that our methods minimize the privacy loss while at the same time\nimproving task performance compared to a non-cascade baseline.",
      "tldr_zh": "本文探讨了大型语言模型(LLMs)是否能在级联系统(cascades)中查询其他模型，而不泄露私人信息的问题。作者引入了两个隐私度量(privacy measures)来量化信息泄露风险，并提出了一种基于社会学习范式(social learning paradigm)的系统，让LLMs通过交换自然语言协作学习，从而减少隐私风险。实验在多个数据集上证明，该方法相较于非级联基线，提高了任务性能，同时最小化了隐私损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01041v2",
      "published_date": "2024-04-01 10:54:49 UTC",
      "updated_date": "2024-04-02 06:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:46:46.988785"
    },
    {
      "arxiv_id": "2404.01036v1",
      "title": "Higher education assessment practice in the era of generative AI tools",
      "title_zh": "翻译失败",
      "authors": [
        "Bayode Ogunleye",
        "Kudirat Ibilola Zakariyyah",
        "Oluwaseun Ajao",
        "Olakunle Olayinka",
        "Hemlata Sharma"
      ],
      "abstract": "The higher education (HE) sector benefits every nation's economy and society\nat large. However, their contributions are challenged by advanced technologies\nlike generative artificial intelligence (GenAI) tools. In this paper, we\nprovide a comprehensive assessment of GenAI tools towards assessment and\npedagogic practice and, subsequently, discuss the potential impacts. This study\nexperimented using three assessment instruments from data science, data\nanalytics, and construction management disciplines. Our findings are two-fold:\nfirst, the findings revealed that GenAI tools exhibit subject knowledge,\nproblem-solving, analytical, critical thinking, and presentation skills and\nthus can limit learning when used unethically. Secondly, the design of the\nassessment of certain disciplines revealed the limitations of the GenAI tools.\nBased on our findings, we made recommendations on how AI tools can be utilised\nfor teaching and learning in HE.",
      "tldr_zh": "本研究探讨了生成式人工智能（GenAI）工具对高等教育评估实践的影响，强调这些工具可能挑战传统教学和学习模式。研究者通过实验评估了数据科学、数据分析和建筑管理三个学科的评估工具，发现GenAI工具展示了主题知识、问题解决、分析、批判性思考和表达技能，但如果不道德使用，可能限制学生的学习。实验还揭示了GenAI工具在某些学科评估中的局限性，如处理复杂任务的不足。最后，论文基于这些发现，提出了在高等教育中有效利用AI工具的推荐，以提升教学质量。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "I.2.7; I.2.10; H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, 7 tables published in the Journal of Applied Learning &\n  Teaching",
      "pdf_url": "http://arxiv.org/pdf/2404.01036v1",
      "published_date": "2024-04-01 10:43:50 UTC",
      "updated_date": "2024-04-01 10:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:46:59.161573"
    },
    {
      "arxiv_id": "2404.01359v1",
      "title": "Parallel Proportional Fusion of Spiking Quantum Neural Network for Optimizing Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Zuyu Xu",
        "Kang Shen",
        "Pengnian Cai",
        "Tao Yang",
        "Yuanming Hu",
        "Shixian Chen",
        "Yunlai Zhu",
        "Zuheng Wu",
        "Yuehua Dai",
        "Jun Wang",
        "Fei Yang"
      ],
      "abstract": "The recent emergence of the hybrid quantum-classical neural network (HQCNN)\narchitecture has garnered considerable attention due to the potential\nadvantages associated with integrating quantum principles to enhance various\nfacets of machine learning algorithms and computations. However, the current\ninvestigated serial structure of HQCNN, wherein information sequentially passes\nfrom one network to another, often imposes limitations on the trainability and\nexpressivity of the network. In this study, we introduce a novel architecture\ntermed Parallel Proportional Fusion of Quantum and Spiking Neural Networks\n(PPF-QSNN). The dataset information is simultaneously fed into both the spiking\nneural network and the variational quantum circuits, with the outputs\namalgamated in proportion to their individual contributions. We systematically\nassess the impact of diverse PPF-QSNN parameters on network performance for\nimage classification, aiming to identify the optimal configuration. Numerical\nresults on the MNIST dataset unequivocally illustrate that our proposed\nPPF-QSNN outperforms both the existing spiking neural network and the serial\nquantum neural network across metrics such as accuracy, loss, and robustness.\nThis study introduces a novel and effective amalgamation approach for HQCNN,\nthereby laying the groundwork for the advancement and application of quantum\nadvantage in artificial intelligent computations.",
      "tldr_zh": "该研究提出了一种新型混合量子-经典神经网络架构PPF-QSNN（Parallel Proportional Fusion of Quantum and Spiking Neural Networks），旨在优化图像分类任务，通过同时将数据输入Spiking Neural Network和Variational Quantum Circuits，并按比例融合输出，解决了传统串行结构的训练性和表达性局限。实验评估了不同参数对网络性能的影响，并在MNIST数据集上，PPF-QSNN在准确率、损失和鲁棒性方面均优于现有的Spiking Neural Network和串行Quantum Neural Network。该方法为HQCNN的创新融合提供了新途径，推动量子优势在人工智能计算中的应用。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01359v1",
      "published_date": "2024-04-01 10:35:35 UTC",
      "updated_date": "2024-04-01 10:35:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:47:11.967940"
    },
    {
      "arxiv_id": "2404.01030v3",
      "title": "Survey of Bias In Text-to-Image Generation: Definition, Evaluation, and Mitigation",
      "title_zh": "文本到图像生成中的偏见调查：定义、评估和缓解",
      "authors": [
        "Yixin Wan",
        "Arjun Subramonian",
        "Anaelia Ovalle",
        "Zongyu Lin",
        "Ashima Suvarna",
        "Christina Chance",
        "Hritik Bansal",
        "Rebecca Pattichis",
        "Kai-Wei Chang"
      ],
      "abstract": "The recent advancement of large and powerful models with Text-to-Image (T2I)\ngeneration abilities -- such as OpenAI's DALLE-3 and Google's Gemini -- enables\nusers to generate high-quality images from textual prompts. However, it has\nbecome increasingly evident that even simple prompts could cause T2I models to\nexhibit conspicuous social bias in generated images. Such bias might lead to\nboth allocational and representational harms in society, further marginalizing\nminority groups. Noting this problem, a large body of recent works has been\ndedicated to investigating different dimensions of bias in T2I systems.\nHowever, an extensive review of these studies is lacking, hindering a\nsystematic understanding of current progress and research gaps. We present the\nfirst extensive survey on bias in T2I generative models. In this survey, we\nreview prior studies on dimensions of bias: Gender, Skintone, and Geo-Culture.\nSpecifically, we discuss how these works define, evaluate, and mitigate\ndifferent aspects of bias. We found that: (1) while gender and skintone biases\nare widely studied, geo-cultural bias remains under-explored; (2) most works on\ngender and skintone bias investigated occupational association, while other\naspects are less frequently studied; (3) almost all gender bias works overlook\nnon-binary identities in their studies; (4) evaluation datasets and metrics are\nscattered, with no unified framework for measuring biases; and (5) current\nmitigation methods fail to resolve biases comprehensively. Based on current\nlimitations, we point out future research directions that contribute to\nhuman-centric definitions, evaluations, and mitigation of biases. We hope to\nhighlight the importance of studying biases in T2I systems, as well as\nencourage future efforts to holistically understand and tackle biases, building\nfair and trustworthy T2I technologies for everyone.",
      "tldr_zh": "这篇论文对 Text-to-Image (T2I) 生成模型中的偏见进行了首次广泛调查，涵盖偏见的定义、评估和缓解方法，重点审视 Gender、Skintone 和 Geo-Culture 等维度。研究发现，虽然 Gender 和 Skintone 偏见（如职业关联）已被广泛探讨，但 Geo-Culture 偏见研究不足，且几乎所有 Gender 偏见研究忽略了非二元性别身份。当前评估数据集和指标缺乏统一框架，缓解方法也未能全面解决问题。论文建议未来研究应采用人类中心的方法，进一步推动公平可靠的 T2I 技术发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01030v3",
      "published_date": "2024-04-01 10:19:05 UTC",
      "updated_date": "2024-05-01 23:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:47:25.252887"
    },
    {
      "arxiv_id": "2404.01358v1",
      "title": "Utilizing AI and Social Media Analytics to Discover Adverse Side Effects of GLP-1 Receptor Agonists",
      "title_zh": "翻译失败",
      "authors": [
        "Alon Bartal",
        "Kathleen M. Jagodnik",
        "Nava Pliskin",
        "Abraham Seidmann"
      ],
      "abstract": "Adverse side effects (ASEs) of drugs, revealed after FDA approval, pose a\nthreat to patient safety. To promptly detect overlooked ASEs, we developed a\ndigital health methodology capable of analyzing massive public data from social\nmedia, published clinical research, manufacturers' reports, and ChatGPT. We\nuncovered ASEs associated with the glucagon-like peptide 1 receptor agonists\n(GLP-1 RA), a market expected to grow exponentially to $133.5 billion USD by\n2030. Using a Named Entity Recognition (NER) model, our method successfully\ndetected 21 potential ASEs overlooked upon FDA approval, including irritability\nand numbness. Our data-analytic approach revolutionizes the detection of\nunreported ASEs associated with newly deployed drugs, leveraging cutting-edge\nAI-driven social media analytics. It can increase the safety of new drugs in\nthe marketplace by unlocking the power of social media to support regulators\nand manufacturers in the rapid discovery of hidden ASE risks.",
      "tldr_zh": "该研究开发了一种数字健康方法，利用 AI 驱动的社交媒体分析、临床研究数据、制造商报告和 ChatGPT，及时检测 GLP-1 Receptor Agonists (GLP-1 RA) 的 Adverse Side Effects (ASEs)。通过 Named Entity Recognition (NER) 模型，该方法从海量公共数据中识别出 21 种 FDA 批准时忽略的潜在 ASEs，例如 irritability 和 numbness。整体方法革新了新药风险发现过程，提高了市场安全，并为监管者和制造商提供快速识别隐藏风险的工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG",
        "cs.SI",
        "62"
      ],
      "primary_category": "q-bio.QM",
      "comment": "19 pages, 7 figures, 3 tables, 1 Appendix table",
      "pdf_url": "http://arxiv.org/pdf/2404.01358v1",
      "published_date": "2024-04-01 09:48:14 UTC",
      "updated_date": "2024-04-01 09:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:47:38.469600"
    },
    {
      "arxiv_id": "2404.01019v3",
      "title": "Source-Aware Training Enables Knowledge Attribution in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Khalifa",
        "David Wadden",
        "Emma Strubell",
        "Honglak Lee",
        "Lu Wang",
        "Iz Beltagy",
        "Hao Peng"
      ],
      "abstract": "Large language models (LLMs) learn a vast amount of knowledge during\npretraining, but they are often oblivious to the source(s) of such knowledge.\nWe investigate the problem of intrinsic source citation, where LLMs are\nrequired to cite the pretraining source supporting a generated response.\nIntrinsic source citation can enhance LLM transparency, interpretability, and\nverifiability. To give LLMs such ability, we explore source-aware training -- a\nrecipe that involves (i) training the LLM to associate unique source document\nidentifiers with the knowledge in each document, followed by (ii) an\ninstruction-tuning stage to teach the LLM to cite a supporting pretraining\nsource when prompted. Source-aware training borrows from existing\npretraining/fine-tuning frameworks and requires minimal changes to the model\narchitecture or implementation. Through experiments on synthetic data, we\ndemonstrate that our training recipe can enable faithful attribution to the\npretraining data without a substantial impact on the model's perplexity\ncompared to standard pretraining. Our findings also highlight the importance of\npretraining data augmentation in achieving attribution. Code and data available\nhere: \\url{https://github.com/mukhal/intrinsic-source-citation}",
      "tldr_zh": "该研究探讨了如何让大型语言模型（LLMs）在生成响应时能够内在引用预训练数据的来源，从而提升模型的透明度、可解释性和可验证性。作者提出source-aware training方法，包括两个阶段：首先训练模型将独特来源文档标识符与知识关联，其次通过指令微调教模型在提示下引用支持的预训练来源。该方法基于现有预训练和微调框架，仅需最小架构调整，并在合成数据实验中证明能实现忠实的知识归因，同时不显著影响模型的perplexity。研究还强调了预训练数据增强在提升归因能力中的关键作用，并提供了相关代码和数据以供参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLM '24",
      "pdf_url": "http://arxiv.org/pdf/2404.01019v3",
      "published_date": "2024-04-01 09:39:38 UTC",
      "updated_date": "2024-08-13 03:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:47:48.570094"
    },
    {
      "arxiv_id": "2404.01013v1",
      "title": "Teeth-SEG: An Efficient Instance Segmentation Framework for Orthodontic Treatment based on Anthropic Prior Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Zou",
        "Shaofeng Wang",
        "Hao Liu",
        "Gaoyue Sun",
        "Yajie Wang",
        "FeiFei Zuo",
        "Chengbin Quan",
        "Youjian Zhao"
      ],
      "abstract": "Teeth localization, segmentation, and labeling in 2D images have great\npotential in modern dentistry to enhance dental diagnostics, treatment\nplanning, and population-based studies on oral health. However, general\ninstance segmentation frameworks are incompetent due to 1) the subtle\ndifferences between some teeth' shapes (e.g., maxillary first premolar and\nsecond premolar), 2) the teeth's position and shape variation across subjects,\nand 3) the presence of abnormalities in the dentition (e.g., caries and\nedentulism). To address these problems, we propose a ViT-based framework named\nTeethSEG, which consists of stacked Multi-Scale Aggregation (MSA) blocks and an\nAnthropic Prior Knowledge (APK) layer. Specifically, to compose the two\nmodules, we design 1) a unique permutation-based upscaler to ensure high\nefficiency while establishing clear segmentation boundaries with 2) multi-head\nself/cross-gating layers to emphasize particular semantics meanwhile\nmaintaining the divergence between token embeddings. Besides, we collect 3) the\nfirst open-sourced intraoral image dataset IO150K, which comprises over 150k\nintraoral photos, and all photos are annotated by orthodontists using a\nhuman-machine hybrid algorithm. Experiments on IO150K demonstrate that our\nTeethSEG outperforms the state-of-the-art segmentation models on dental image\nsegmentation.",
      "tldr_zh": "本研究针对牙齿在2D图像中的定位、分割和标记问题，提出了一种高效的实例分割框架Teeth-SEG，以解决牙齿形状微妙差异、个体变异和异常（如龋齿）带来的挑战。框架基于ViT（Vision Transformer），结合堆叠的多尺度聚合（MSA）块和人类学先验知识（APK）层，并设计了基于置换的放大器（permutation-based upscaler）和多头自/交叉门控层（multi-head self/cross-gating layers），以实现清晰的分割边界和语义强调。同时，研究团队构建了首个开源口腔图像数据集IO150K，包含超过15万张由正畸医生标注的图像。实验结果显示，Teeth-SEG在IO150K数据集上超过了现有最先进模型，在牙科图像分割任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted by CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01013v1",
      "published_date": "2024-04-01 09:34:51 UTC",
      "updated_date": "2024-04-01 09:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:48:02.285483"
    },
    {
      "arxiv_id": "2404.01012v2",
      "title": "Query Performance Prediction using Relevance Judgments Generated by Large Language Models",
      "title_zh": "利用大型语言模型生成的相关性判断进行查询性能预测",
      "authors": [
        "Chuan Meng",
        "Negar Arabzadeh",
        "Arian Askari",
        "Mohammad Aliannejadi",
        "Maarten de Rijke"
      ],
      "abstract": "Query performance prediction (QPP) aims to estimate the retrieval quality of\na search system for a query without human relevance judgments. Previous QPP\nmethods typically return a single scalar value and do not require the predicted\nvalues to approximate a specific information retrieval (IR) evaluation measure,\nleading to certain drawbacks: (i) a single scalar is insufficient to accurately\nrepresent different IR evaluation measures, especially when metrics do not\nhighly correlate, and (ii) a single scalar limits the interpretability of QPP\nmethods because solely using a scalar is insufficient to explain QPP results.\nTo address these issues, we propose a QPP framework using automatically\ngenerated relevance judgments (QPP-GenRE), which decomposes QPP into\nindependent subtasks of predicting the relevance of each item in a ranked list\nto a given query. This allows us to predict any IR evaluation measure using the\ngenerated relevance judgments as pseudo-labels. This also allows us to\ninterpret predicted IR evaluation measures, and identify, track and rectify\nerrors in generated relevance judgments to improve QPP quality. We predict an\nitem's relevance by using open-source large language models (LLMs) to ensure\nscientific reproducibility.\n  We face two main challenges: (i) excessive computational costs of judging an\nentire corpus for predicting a metric considering recall, and (ii) limited\nperformance in prompting open-source LLMs in a zero-/few-shot manner. To solve\nthe challenges, we devise an approximation strategy to predict an IR measure\nconsidering recall and propose to fine-tune open-source LLMs using\nhuman-labeled relevance judgments. Experiments on the TREC 2019-2022 deep\nlearning tracks show that QPP-GenRE achieves state-of-the-art QPP quality for\nboth lexical and neural rankers.",
      "tldr_zh": "该论文提出了一种新的查询性能预测 (QPP) 框架 QPP-GenRE，以解决传统方法依赖单一标量值导致的准确性和可解释性问题，该框架通过使用大型语言模型 (LLMs) 生成的相关性判断，将 QPP 分解为预测每个检索项目对查询的相关性子任务，从而支持预测任意信息检索 (IR) 评估指标。针对计算成本高和 LLMs 零/少样本提示性能有限的挑战，研究团队开发了近似策略来处理召回相关的 IR 指标，并通过人类标记的相关性判断对 LLMs 进行微调。实验在 TREC 2019-2022 深度学习轨道上显示，QPP-GenRE 实现了比现有词汇和神经排序器更先进的 QPP 质量，提高了预测的准确性和解释性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01012v2",
      "published_date": "2024-04-01 09:33:05 UTC",
      "updated_date": "2024-06-17 11:23:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:48:14.092737"
    },
    {
      "arxiv_id": "2404.01356v1",
      "title": "The Double-Edged Sword of Input Perturbations to Robust Accurate Fairness",
      "title_zh": "翻译失败",
      "authors": [
        "Xuran Li",
        "Peng Wu",
        "Yanting Chen",
        "Xingjun Ma",
        "Zhen Zhang",
        "Kaixiang Dong"
      ],
      "abstract": "Deep neural networks (DNNs) are known to be sensitive to adversarial input\nperturbations, leading to a reduction in either prediction accuracy or\nindividual fairness. To jointly characterize the susceptibility of prediction\naccuracy and individual fairness to adversarial perturbations, we introduce a\nnovel robustness definition termed robust accurate fairness. Informally, robust\naccurate fairness requires that predictions for an instance and its similar\ncounterparts consistently align with the ground truth when subjected to input\nperturbations. We propose an adversarial attack approach dubbed RAFair to\nexpose false or biased adversarial defects in DNN, which either deceive\naccuracy or compromise individual fairness. Then, we show that such adversarial\ninstances can be effectively addressed by carefully designed benign\nperturbations, correcting their predictions to be accurate and fair. Our work\nexplores the double-edged sword of input perturbations to robust accurate\nfairness in DNN and the potential of using benign perturbations to correct\nadversarial instances.",
      "tldr_zh": "这篇论文探讨了深度神经网络(DNNs)对对抗性输入扰动的敏感性，引入了robust accurate fairness的新定义，要求实例及其相似实例在扰动下保持预测准确性和个体公平性一致。作者提出了一种对抗攻击方法RAFair，用于暴露DNN中的假冒或偏见缺陷，这些缺陷可能欺骗预测准确性或损害个体公平性。通过精心设计的良性扰动，论文展示了如何有效修正这些对抗实例，使预测变得准确和公平。该研究揭示了输入扰动在提升DNN鲁棒性方面的双重作用，既是挑战也是解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01356v1",
      "published_date": "2024-04-01 09:29:16 UTC",
      "updated_date": "2024-04-01 09:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:48:25.404751"
    },
    {
      "arxiv_id": "2407.00814v1",
      "title": "Privacy-Aware Spectrum Pricing and Power Control Optimization for LEO Satellite Internet-of-Things",
      "title_zh": "面向 LEO 卫星物联网的隐私感知频谱定价和功率控制优化",
      "authors": [
        "Bowen Shen",
        "Kwok-Yan Lam",
        "Feng Li"
      ],
      "abstract": "Low earth orbit (LEO) satellite systems play an important role in next\ngeneration communication networks due to their ability to provide extensive\nglobal coverage with guaranteed communications in remote areas and isolated\nareas where base stations cannot be cost-efficiently deployed. With the\npervasive adoption of LEO satellite systems, especially in the LEO\nInternet-of-Things (IoT) scenarios, their spectrum resource management\nrequirements have become more complex as a result of massive service requests\nand high bandwidth demand from terrestrial terminals. For instance, when\nleasing the spectrum to terrestrial users and controlling the uplink transmit\npower, satellites collect user data for machine learning purposes, which\nusually are sensitive information such as location, budget and quality of\nservice (QoS) requirement. To facilitate model training in LEO IoT while\npreserving the privacy of data, blockchain-driven federated learning (FL) is\nwidely used by leveraging on a fully decentralized architecture. In this paper,\nwe propose a hybrid spectrum pricing and power control framework for LEO IoT by\ncombining blockchain technology and FL. We first design a local deep\nreinforcement learning algorithm for LEO satellite systems to learn a\nrevenue-maximizing pricing and power control scheme. Then the agents\ncollaborate to form a FL system. We also propose a reputation-based blockchain\nwhich is used in the global model aggregation phase of FL. Based on the\nreputation mechanism, a node is selected for each global training round to\nperform model aggregation and block generation, which can further enhance the\ndecentralization of the network and guarantee the trust. Simulation tests are\nconducted to evaluate the performances of the proposed scheme. Our results show\nthe efficiency of finding the maximum revenue scheme for LEO satellite systems\nwhile preserving the privacy of each agent.",
      "tldr_zh": "这篇论文针对 LEO Satellite Internet-of-Things (IoT) 中的谱资源管理和隐私挑战，提出一个结合区块链和 Federated Learning (FL) 的混合框架，以优化谱定价和功率控制。框架设计了一个本地深度强化学习算法，让卫星系统学习最大化收入的定价方案，同时保护用户敏感数据如位置和 QoS 要求。代理通过 FL 系统协作，并引入基于声誉的区块链机制，在全局模型聚合阶段选择节点进行块生成，从而增强网络的去中心化和信任。模拟测试证明，该方案能高效实现最大收入优化，同时有效保障每个代理的隐私。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00814v1",
      "published_date": "2024-04-01 09:15:48 UTC",
      "updated_date": "2024-04-01 09:15:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:48:38.178002"
    },
    {
      "arxiv_id": "2404.00998v1",
      "title": "LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report Generation",
      "title_zh": "LLM-RadJudge：实现放射科医生水平的X射线报告生成评估",
      "authors": [
        "Zilong Wang",
        "Xufang Luo",
        "Xinyang Jiang",
        "Dongsheng Li",
        "Lili Qiu"
      ],
      "abstract": "Evaluating generated radiology reports is crucial for the development of\nradiology AI, but existing metrics fail to reflect the task's clinical\nrequirements. This study proposes a novel evaluation framework using large\nlanguage models (LLMs) to compare radiology reports for assessment. We compare\nthe performance of various LLMs and demonstrate that, when using GPT-4, our\nproposed metric achieves evaluation consistency close to that of radiologists.\nFurthermore, to reduce costs and improve accessibility, making this method\npractical, we construct a dataset using LLM evaluation results and perform\nknowledge distillation to train a smaller model. The distilled model achieves\nevaluation capabilities comparable to GPT-4. Our framework and distilled model\noffer an accessible and efficient evaluation method for radiology report\ngeneration, facilitating the development of more clinically relevant models.\nThe model will be further open-sourced and accessible.",
      "tldr_zh": "这篇论文提出LLM-RadJudge框架，使用大型语言模型(LLMs)来评估X射线报告生成，以解决现有指标无法满足临床需求的问题。研究比较了各种LLMs的性能，发现使用GPT-4时，评估一致性接近放射科医生的水平；同时，通过知识蒸馏训练了一个小型模型，使其评估能力与GPT-4相当，从而降低成本并提高可访问性。该框架和模型提供了一种高效的评估方法，促进放射学AI的临床相关发展，并计划开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.00998v1",
      "published_date": "2024-04-01 09:02:12 UTC",
      "updated_date": "2024-04-01 09:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:48:49.819717"
    },
    {
      "arxiv_id": "2404.00989v2",
      "title": "360+x: A Panoptic Multi-modal Scene Understanding Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Chen",
        "Yuqi Hou",
        "Chenyuan Qu",
        "Irene Testini",
        "Xiaohan Hong",
        "Jianbo Jiao"
      ],
      "abstract": "Human perception of the world is shaped by a multitude of viewpoints and\nmodalities. While many existing datasets focus on scene understanding from a\ncertain perspective (e.g. egocentric or third-person views), our dataset offers\na panoptic perspective (i.e. multiple viewpoints with multiple data\nmodalities). Specifically, we encapsulate third-person panoramic and front\nviews, as well as egocentric monocular/binocular views with rich modalities\nincluding video, multi-channel audio, directional binaural delay, location data\nand textual scene descriptions within each scene captured, presenting\ncomprehensive observation of the world. Figure 1 offers a glimpse of all 28\nscene categories of our 360+x dataset. To the best of our knowledge, this is\nthe first database that covers multiple viewpoints with multiple data\nmodalities to mimic how daily information is accessed in the real world.\nThrough our benchmark analysis, we presented 5 different scene understanding\ntasks on the proposed 360+x dataset to evaluate the impact and benefit of each\ndata modality and perspective in panoptic scene understanding. We hope this\nunique dataset could broaden the scope of comprehensive scene understanding and\nencourage the community to approach these problems from more diverse\nperspectives.",
      "tldr_zh": "本研究引入了名为360+x的全景多模态场景理解数据集（A Panoptic Multi-modal Scene Understanding Dataset），旨在模拟人类通过多种视角和模态感知世界的过程。该数据集涵盖第三人称的全景和正面视图、第一人称的单目/双目视图，以及视频、多通道音频、双耳延迟、位置数据和文本描述等丰富模态，总计28个场景类别。相比现有数据集，这是首个整合多视角和多模态的数据库；通过基准分析，该数据集支持5个场景理解任务，评估了不同模态和视角对全面场景理解的益处，并鼓励社区从更多样化的角度探索相关问题。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 (Oral Presentation), Project page:\n  https://x360dataset.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2404.00989v2",
      "published_date": "2024-04-01 08:34:42 UTC",
      "updated_date": "2024-04-08 02:37:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:49:02.219829"
    },
    {
      "arxiv_id": "2404.00983v1",
      "title": "Continual Learning for Smart City: A Survey",
      "title_zh": "面向智能城市的持续学习：综述",
      "authors": [
        "Li Yang",
        "Zhipeng Luo",
        "Shiming Zhang",
        "Fei Teng",
        "Tianrui Li"
      ],
      "abstract": "With the digitization of modern cities, large data volumes and powerful\ncomputational resources facilitate the rapid update of intelligent models\ndeployed in smart cities. Continual learning (CL) is a novel machine learning\nparadigm that constantly updates models to adapt to changing environments,\nwhere the learning tasks, data, and distributions can vary over time. Our\nsurvey provides a comprehensive review of continual learning methods that are\nwidely used in smart city development. The content consists of three parts: 1)\nMethodology-wise. We categorize a large number of basic CL methods and advanced\nCL frameworks in combination with other learning paradigms including graph\nlearning, spatial-temporal learning, multi-modal learning, and federated\nlearning. 2) Application-wise. We present numerous CL applications covering\ntransportation, environment, public health, safety, networks, and associated\ndatasets related to urban computing. 3) Challenges. We discuss current problems\nand challenges and envision several promising research directions. We believe\nthis survey can help relevant researchers quickly familiarize themselves with\nthe current state of continual learning research used in smart city development\nand direct them to future research trends.",
      "tldr_zh": "这篇调查论文回顾了持续学习（Continual Learning, CL）在智能城市中的应用，旨在帮助模型适应动态环境中的任务和数据变化。论文从方法论角度分类了基本 CL 方法和高级框架，包括与 graph learning、spatial-temporal learning、多模态学习和 federated learning 的结合；从应用角度，涵盖了交通、环境、公共健康、安全、网络等领域，并介绍了相关的城市计算数据集。最终，论文讨论了当前挑战并展望了未来研究方向，如提升模型适应性和数据隐私，以推动智能城市的发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2404.00983v1",
      "published_date": "2024-04-01 07:59:29 UTC",
      "updated_date": "2024-04-01 07:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:49:12.776706"
    },
    {
      "arxiv_id": "2404.00977v2",
      "title": "Nonlinear dynamical social and political prediction algorithm for city planning and public participation using the Impulse Pattern Formulation",
      "title_zh": "翻译失败",
      "authors": [
        "Rolf Bader",
        "Simon Linke",
        "Stefanie Gernert"
      ],
      "abstract": "A nonlinear-dynamical algorithm for city planning is proposed as an Impulse\nPattern Formulation (IPF) for predicting relevant parameters like health,\nartistic freedom, or financial developments of different social or political\nstakeholders over the cause of a planning process. The IPF has already shown\nhigh predictive precision at low computational cost in musical instrument\nsimulations, brain dynamics, and human-human interactions. The social and\npolitical IPF consists of three basic equations of system state developments,\nself-adaptation of stakeholders, two adaptive interactions, and external impact\nterms suitable for respective planning situations. Typical scenarios of\nstakeholder interactions and developments are modeled by adjusting a set of\nsystem parameters. These include stakeholder reaction to external input,\nenhanced system stability through self-adaptation, stakeholder convergence due\nto adaptive interaction, as well as complex dynamics in terms of fixed\nstakeholder impacts. A workflow for implementing the algorithm in real city\nplanning scenarios is outlined. This workflow includes machine learning of a\nsuitable set of parameters suggesting best-practice planning to aim at the\ndesired development of the planning process and its output.",
      "tldr_zh": "本论文提出了一种非线性动态算法Impulse Pattern Formulation (IPF)，用于城市规划中预测社会和政治利益相关者的参数，如健康、艺术自由和财务发展。\nIPF 由三个基本方程组成，包括系统状态发展、利益相关者的自我适应、适应性互动以及外部影响项，能够以低计算成本实现高精度预测。\n通过调整系统参数，该算法可以模拟典型利益相关者互动场景，如对外部输入的反应、系统稳定性增强以及复杂动态。\n论文还概述了在实际城市规划中的实施流程，利用机器学习优化参数，以支持最佳实践和公众参与，实现期望的规划结果。",
      "categories": [
        "nlin.AO",
        "cs.AI",
        "math.DS"
      ],
      "primary_category": "nlin.AO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00977v2",
      "published_date": "2024-04-01 07:49:10 UTC",
      "updated_date": "2024-06-14 18:47:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:49:26.800269"
    },
    {
      "arxiv_id": "2404.01353v1",
      "title": "Efficiently Distilling LLMs for Edge Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Achintya Kundu",
        "Fabian Lim",
        "Aaron Chew",
        "Laura Wynter",
        "Penny Chong",
        "Rhui Dih Lee"
      ],
      "abstract": "Supernet training of LLMs is of great interest in industrial applications as\nit confers the ability to produce a palette of smaller models at constant cost,\nregardless of the number of models (of different size / latency) produced. We\npropose a new method called Multistage Low-rank Fine-tuning of\nSuper-transformers (MLFS) for parameter-efficient supernet training. We show\nthat it is possible to obtain high-quality encoder models that are suitable for\ncommercial edge applications, and that while decoder-only models are resistant\nto a comparable degree of compression, decoders can be effectively sliced for a\nsignificant reduction in training time.",
      "tldr_zh": "本论文提出了一种名为Multistage Low-rank Fine-tuning of Super-transformers (MLFS)的新方法，用于参数高效的Supernet训练，从而以恒定成本生成一系列不同大小的LLMs模型，适用于边缘应用。MLFS通过多阶段低秩微调技术，成功获得了高质量的编码器模型，满足商业边缘场景的需求。实验结果显示，虽然解码器模型对压缩有一定抵抗力，但可以通过切片显著减少训练时间，为高效LLMs部署提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for publication in NAACL 2024 (Industry\n  Track)",
      "pdf_url": "http://arxiv.org/pdf/2404.01353v1",
      "published_date": "2024-04-01 07:35:15 UTC",
      "updated_date": "2024-04-01 07:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:49:36.740239"
    },
    {
      "arxiv_id": "2404.00971v2",
      "title": "Exploring and Evaluating Hallucinations in LLM-Powered Code Generation",
      "title_zh": "探索与评估 LLM 驱动代码生成中的幻觉",
      "authors": [
        "Fang Liu",
        "Yang Liu",
        "Lin Shi",
        "Houkun Huang",
        "Ruifeng Wang",
        "Zhen Yang",
        "Li Zhang",
        "Zhongqi Li",
        "Yuchi Ma"
      ],
      "abstract": "The rise of Large Language Models (LLMs) has significantly advanced many\napplications on software engineering tasks, particularly in code generation.\nDespite the promising performance, LLMs are prone to generate hallucinations,\nwhich means LLMs might produce outputs that deviate from users' intent, exhibit\ninternal inconsistencies, or misalign with the factual knowledge, making the\ndeployment of LLMs potentially risky in a wide range of applications. Existing\nwork mainly focuses on investing the hallucination in the domain of natural\nlanguage generation (NLG), leaving a gap in understanding the types and extent\nof hallucinations in the context of code generation. To bridge the gap, we\nconducted a thematic analysis of the LLM-generated code to summarize and\ncategorize the hallucinations present in it. Our study established a\ncomprehensive taxonomy of hallucinations in LLM-generated code, encompassing 5\nprimary categories of hallucinations depending on the conflicting objectives\nand varying degrees of deviation observed in code generation. Furthermore, we\nsystematically analyzed the distribution of hallucinations, exploring\nvariations among different LLMs and their correlation with code correctness.\nBased on the results, we proposed HalluCode, a benchmark for evaluating the\nperformance of code LLMs in recognizing hallucinations. Hallucination\nrecognition and mitigation experiments with HalluCode and HumanEval show\nexisting LLMs face great challenges in recognizing hallucinations, particularly\nin identifying their types, and are hardly able to mitigate hallucinations. We\nbelieve our findings will shed light on future research about hallucination\nevaluation, detection, and mitigation, ultimately paving the way for building\nmore effective and reliable code LLMs in the future.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在代码生成中的 hallucinations（幻觉）问题，这些幻觉可能导致输出偏离用户意图、不一致或不符合事实，从而增加应用风险。作者通过主题分析建立了 hallucinations 在代码生成领域的综合 taxonomy，涵盖5个主要类别，并系统分析了其分布、在不同 LLMs 间的差异以及与代码正确性的相关性。论文提出了 HalluCode 基准，用于评估 LLMs 识别 hallucinations 的性能，并通过实验发现，现有的 LLMs 在识别 hallucinations 类型和缓解方面面临巨大挑战。研究结果为未来 hallucinations 的评估、检测和缓解提供了关键见解，推动更可靠的代码 LLMs 发展。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00971v2",
      "published_date": "2024-04-01 07:31:45 UTC",
      "updated_date": "2024-05-11 02:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:49:50.255793"
    },
    {
      "arxiv_id": "2404.03683v1",
      "title": "Stream of Search (SoS): Learning to Search in Language",
      "title_zh": "搜索流 (SoS)：在语言中学习搜索",
      "authors": [
        "Kanishk Gandhi",
        "Denise Lee",
        "Gabriel Grand",
        "Muxin Liu",
        "Winson Cheng",
        "Archit Sharma",
        "Noah D. Goodman"
      ],
      "abstract": "Language models are rarely shown fruitful mistakes while training. They then\nstruggle to look beyond the next token, suffering from a snowballing of errors\nand struggling to predict the consequence of their actions several steps ahead.\nIn this paper, we show how language models can be taught to search by\nrepresenting the process of search in language, as a flattened string -- a\nstream of search (SoS). We propose a unified language for search that captures\nan array of different symbolic search strategies. We demonstrate our approach\nusing the simple yet difficult game of Countdown, where the goal is to combine\ninput numbers with arithmetic operations to reach a target number. We pretrain\na transformer-based language model from scratch on a dataset of streams of\nsearch generated by heuristic solvers. We find that SoS pretraining increases\nsearch accuracy by 25% over models trained to predict only the optimal search\ntrajectory. We further finetune this model with two policy improvement methods:\nAdvantage-Induced Policy Alignment (APA) and Self-Taught Reasoner (STaR). The\nfinetuned SoS models solve 36% of previously unsolved problems, including\nproblems that cannot be solved by any of the heuristic solvers. Our results\nindicate that language models can learn to solve problems via search,\nself-improve to flexibly use different search strategies, and potentially\ndiscover new ones.",
      "tldr_zh": "本论文提出 Stream of Search (SoS) 方法，通过将搜索过程表示为扁平化的语言字符串，教语言模型学会处理多步决策问题，解决其在预测错误后果时的局限性。研究者使用统一的搜索语言捕捉多种符号策略，并在 Countdown 游戏中预训练一个 transformer 模型，利用启发式求解器生成的数据集，使搜索准确率较仅预测最优轨迹的模型提高 25%。进一步通过 Advantage-Induced Policy Alignment (APA) 和 Self-Taught Reasoner (STaR) 微调后，该模型解决了 36% 的之前未解问题，甚至发现了新策略，证明语言模型能通过搜索实现自提升和灵活问题解决。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03683v1",
      "published_date": "2024-04-01 06:50:52 UTC",
      "updated_date": "2024-04-01 06:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:50:03.043472"
    },
    {
      "arxiv_id": "2404.00943v2",
      "title": "Evalverse: Unified and Accessible Library for Large Language Model Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jihoo Kim",
        "Wonho Song",
        "Dahyun Kim",
        "Yunsu Kim",
        "Yungi Kim",
        "Chanjun Park"
      ],
      "abstract": "This paper introduces Evalverse, a novel library that streamlines the\nevaluation of Large Language Models (LLMs) by unifying disparate evaluation\ntools into a single, user-friendly framework. Evalverse enables individuals\nwith limited knowledge of artificial intelligence to easily request LLM\nevaluations and receive detailed reports, facilitated by an integration with\ncommunication platforms like Slack. Thus, Evalverse serves as a powerful tool\nfor the comprehensive assessment of LLMs, offering both researchers and\npractitioners a centralized and easily accessible evaluation framework.\nFinally, we also provide a demo video for Evalverse, showcasing its\ncapabilities and implementation in a two-minute format.",
      "tldr_zh": "本文介绍了 Evalverse，一种统一的库，用于简化 Large Language Models (LLMs) 的评估，通过整合各种评估工具提供一个用户友好的框架。Evalverse 允许 AI 知识有限的用户轻松请求评估并通过 Slack 等通信平台获取详细报告，从而为研究者和从业者提供一个集中的、可访问的评估解决方案。该库还附带了一个两分钟的演示视频，展示了其功能和实现方式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Demo Track",
      "pdf_url": "http://arxiv.org/pdf/2404.00943v2",
      "published_date": "2024-04-01 06:03:39 UTC",
      "updated_date": "2024-10-07 02:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:50:13.758205"
    },
    {
      "arxiv_id": "2404.00942v1",
      "title": "Evaluating the Factuality of Large Language Models using Large-Scale Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoze Liu",
        "Feijie Wu",
        "Tianyang Xu",
        "Zhuo Chen",
        "Yichi Zhang",
        "Xiaoqian Wang",
        "Jing Gao"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has significantly transformed the\nAI landscape, enhancing machine learning and AI capabilities. Factuality issue\nis a critical concern for LLMs, as they may generate factually incorrect\nresponses. In this paper, we propose GraphEval to evaluate an LLM's performance\nusing a substantially large test dataset. Specifically, the test dataset is\nretrieved from a large knowledge graph with more than 10 million facts without\nexpensive human efforts. Unlike conventional methods that evaluate LLMs based\non generated responses, GraphEval streamlines the evaluation process by\ncreating a judge model to estimate the correctness of the answers given by the\nLLM. Our experiments demonstrate that the judge model's factuality assessment\naligns closely with the correctness of the LLM's generated outputs, while also\nsubstantially reducing evaluation costs. Besides, our findings offer valuable\ninsights into LLM performance across different metrics and highlight the\npotential for future improvements in ensuring the factual integrity of LLM\noutputs. The code is publicly available at https://github.com/xz-liu/GraphEval.",
      "tldr_zh": "本研究针对Large Language Models (LLMs)的事实性问题，提出GraphEval框架，利用一个包含超过1000万事实的大型Knowledge Graphs构建大规模测试数据集，从而避免昂贵的人工标注。GraphEval通过创建一个judge model来评估LLMs生成的答案正确性，与传统基于响应评估的方法相比，大大简化了过程并降低了成本。实验结果显示，judge model's评估与LLMs输出的事实准确性高度一致，并提供了LLMs在不同指标上的性能洞见，为提升LLMs的事实完整性提供了宝贵方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00942v1",
      "published_date": "2024-04-01 06:01:17 UTC",
      "updated_date": "2024-04-01 06:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:50:25.216622"
    },
    {
      "arxiv_id": "2404.00929v3",
      "title": "A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Yuemei Xu",
        "Ling Hu",
        "Jiayi Zhao",
        "Zihan Qiu",
        "Kexin XU",
        "Yuqi Ye",
        "Hanwen Gu"
      ],
      "abstract": "Based on the foundation of Large Language Models (LLMs), Multilingual LLMs\n(MLLMs) have been developed to address the challenges faced in multilingual\nnatural language processing, hoping to achieve knowledge transfer from\nhigh-resource languages to low-resource languages. However, significant\nlimitations and challenges still exist, such as language imbalance,\nmultilingual alignment, and inherent bias. In this paper, we aim to provide a\ncomprehensive analysis of MLLMs, delving deeply into discussions surrounding\nthese critical issues. First of all, we start by presenting an overview of\nMLLMs, covering their evolutions, key techniques, and multilingual capacities.\nSecondly, we explore the multilingual training corpora of MLLMs and the\nmultilingual datasets oriented for downstream tasks that are crucial to enhance\nthe cross-lingual capability of MLLMs. Thirdly, we survey the state-of-the-art\nstudies of multilingual representations and investigate whether the current\nMLLMs can learn a universal language representation. Fourthly, we discuss bias\non MLLMs, including its categories, evaluation metrics, and debiasing\ntechniques. Finally, we discuss existing challenges and point out promising\nresearch directions of MLLMs.",
      "tldr_zh": "这篇论文对多语言大型语言模型(MLLMs)进行了全面调查，旨在解决多语言自然语言处理中的挑战，如语言不平衡、多语言 alignment 和固有 bias。论文首先概述了 MLLMs 的演变、关键技术以及多语言能力，其次探讨了多语言训练语料和下游任务数据集，以提升跨语言性能。最终，它分析了多语言表示的学习可能性、bias 的类别、评估指标和去偏置技术，并指出了当前挑战以及未来研究方向，如实现更有效的知识转移。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The article has been accepted by Frontiers of Computer Science (FCS),\n  with the DOI: {10.1007/s11704-024-40579-4}",
      "pdf_url": "http://arxiv.org/pdf/2404.00929v3",
      "published_date": "2024-04-01 05:13:56 UTC",
      "updated_date": "2024-12-09 14:30:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:50:37.775380"
    },
    {
      "arxiv_id": "2404.01352v1",
      "title": "VortexViz: Finding Vortex Boundaries by Learning from Particle Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Akila de Silva",
        "Nicholas Tee",
        "Omkar Ghanekar",
        "Fahim Hasan Khan",
        "Gregory Dusek",
        "James Davis",
        "Alex Pang"
      ],
      "abstract": "Vortices are studied in various scientific disciplines, offering insights\ninto fluid flow behavior. Visualizing the boundary of vortices is crucial for\nunderstanding flow phenomena and detecting flow irregularities. This paper\naddresses the challenge of accurately extracting vortex boundaries using deep\nlearning techniques. While existing methods primarily train on velocity\ncomponents, we propose a novel approach incorporating particle trajectories\n(streamlines or pathlines) into the learning process. By leveraging the\nregional/local characteristics of the flow field captured by streamlines or\npathlines, our methodology aims to enhance the accuracy of vortex boundary\nextraction.",
      "tldr_zh": "本论文提出了一种名为VortexViz的方法，利用深度学习从粒子轨迹（streamlines 或 pathlines）中学习，以准确提取涡流边界。传统方法主要依赖速度组件，而VortexViz通过整合流场的区域/局部特征，显著提升了边界识别的精确性。该方法有助于更好地理解流体流动行为和检测异常现象。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2404.01352v1",
      "published_date": "2024-04-01 05:12:55 UTC",
      "updated_date": "2024-04-01 05:12:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:50:49.207578"
    },
    {
      "arxiv_id": "2404.00923v1",
      "title": "MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements",
      "title_zh": "翻译失败",
      "authors": [
        "Lisong C. Sun",
        "Neel P. Bhatt",
        "Jonathan C. Liu",
        "Zhiwen Fan",
        "Zhangyang Wang",
        "Todd E. Humphreys",
        "Ufuk Topcu"
      ],
      "abstract": "Simultaneous localization and mapping is essential for position tracking and\nscene understanding. 3D Gaussian-based map representations enable\nphotorealistic reconstruction and real-time rendering of scenes using multiple\nposed cameras. We show for the first time that using 3D Gaussians for map\nrepresentation with unposed camera images and inertial measurements can enable\naccurate SLAM. Our method, MM3DGS, addresses the limitations of prior neural\nradiance field-based representations by enabling faster rendering, scale\nawareness, and improved trajectory tracking. Our framework enables\nkeyframe-based mapping and tracking utilizing loss functions that incorporate\nrelative pose transformations from pre-integrated inertial measurements, depth\nestimates, and measures of photometric rendering quality. We also release a\nmulti-modal dataset, UT-MM, collected from a mobile robot equipped with a\ncamera and an inertial measurement unit. Experimental evaluation on several\nscenes from the dataset shows that MM3DGS achieves 3x improvement in tracking\nand 5% improvement in photometric rendering quality compared to the current\n3DGS SLAM state-of-the-art, while allowing real-time rendering of a\nhigh-resolution dense 3D map. Project Webpage:\nhttps://vita-group.github.io/MM3DGS-SLAM",
      "tldr_zh": "本文提出 MM3DGS，一种多模态 3D Gaussian Splatting 方法，用于 SLAM（Simultaneous Localization and Mapping），首次结合视觉、深度和惯性测量来实现准确的定位和地图构建。方法通过关键帧-based 映射和跟踪，利用损失函数整合相对位姿变换、深度估计以及光度渲染质量，解决了传统神经辐射场表示的渲染速度和尺度感知问题。作者发布了新数据集 UT-MM，由配备相机和 IMU 的移动机器人收集。实验结果显示，MM3DGS 在多个场景中比现有 3DGS SLAM 状态最先进方法提高了 3 倍的跟踪精度和 5% 的光度渲染质量，同时支持实时渲染高分辨率密集 3D 地图。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Webpage: https://vita-group.github.io/MM3DGS-SLAM",
      "pdf_url": "http://arxiv.org/pdf/2404.00923v1",
      "published_date": "2024-04-01 04:57:41 UTC",
      "updated_date": "2024-04-01 04:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:51:03.937595"
    },
    {
      "arxiv_id": "2404.00914v1",
      "title": "Token-Efficient Leverage Learning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhao Zeng",
        "Min Wang",
        "Yihang Wang",
        "Yingxia Shao"
      ],
      "abstract": "Large Language Models (LLMs) have excelled in various tasks but perform\nbetter in high-resource scenarios, which presents challenges in low-resource\nscenarios. Data scarcity and the inherent difficulty of adapting LLMs to\nspecific tasks compound the challenge. To address the twin hurdles, we\nintroduce \\textbf{Leverage Learning}. We present a streamlined implement of\nthis methodology called Token-Efficient Leverage Learning (TELL). TELL\nshowcases the potential of Leverage Learning, demonstrating effectiveness\nacross various LLMs and low-resource tasks, ranging from $10^4$ to $10^6$\ntokens. It reduces task data requirements by up to nearly an order of magnitude\ncompared to conventional Supervised Fine-Tuning (SFT) while delivering\ncompetitive performance. With the same amount of task data, TELL leads in\nimproving task performance compared to SFT. We discuss the mechanism of\nLeverage Learning, suggesting it aligns with quantization hypothesis and\nexplore its promising potential through empirical testing.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在低资源场景下的数据稀缺和适应难题，提出了一种名为Leverage Learning的新方法，并开发了其简化实现Token-Efficient Leverage Learning (TELL)。TELL 通过高效利用标记数据，将任务数据需求减少近一个数量级，与传统监督微调（SFT）相比，在$10^4$至$10^6$标记的低资源任务中实现相竞争性能，并在相同数据量下显著提升任务表现。研究还探讨了Leverage Learning的机制，表明其与量化假设相符，并通过实证测试验证了其在各种LLMs中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.00914v1",
      "published_date": "2024-04-01 04:39:44 UTC",
      "updated_date": "2024-04-01 04:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:51:14.192314"
    },
    {
      "arxiv_id": "2404.00913v1",
      "title": "LLaMA-Excitor: General Instruction Tuning via Indirect Feature Interaction",
      "title_zh": "LLaMA-Excitor：通过间接特征交互的通用指令微调",
      "authors": [
        "Bo Zou",
        "Chao Yang",
        "Yu Qiao",
        "Chengbin Quan",
        "Youjian Zhao"
      ],
      "abstract": "Existing methods to fine-tune LLMs, like Adapter, Prefix-tuning, and LoRA,\nwhich introduce extra modules or additional input sequences to inject new\nskills or knowledge, may compromise the innate abilities of LLMs. In this\npaper, we propose LLaMA-Excitor, a lightweight method that stimulates the LLMs'\npotential to better follow instructions by gradually paying more attention to\nworthwhile information. Specifically, the LLaMA-Excitor does not directly\nchange the intermediate hidden state during the self-attention calculation of\nthe transformer structure. We designed the Excitor block as a bypass module for\nthe similarity score computation in LLMs' self-attention to reconstruct keys\nand change the importance of values by learnable prompts. LLaMA-Excitor ensures\na self-adaptive allocation of additional attention to input instructions, thus\neffectively preserving LLMs' pre-trained knowledge when fine-tuning LLMs on\nlow-quality instruction-following datasets. Furthermore, we unify the modeling\nof multi-modal tuning and language-only tuning, extending LLaMA-Excitor to a\npowerful visual instruction follower without the need for complex multi-modal\nalignment. Our proposed approach is evaluated in language-only and multi-modal\ntuning experimental scenarios. Notably, LLaMA-Excitor is the only method that\nmaintains basic capabilities while achieving a significant improvement (+6%) on\nthe MMLU benchmark. In the visual instruction tuning, we achieve a new\nstate-of-the-art image captioning performance of 157.5 CIDEr on MSCOCO, and a\ncomparable performance (88.39%) on ScienceQA to cutting-edge models with more\nparameters and extensive vision-language pertaining.",
      "tldr_zh": "本研究提出LLaMA-Excitor，一种轻量级指令调优方法，通过间接特征交互（Indirect Feature Interaction）避免传统方法如Adapter、Prefix-tuning和LoRA引入额外模块可能损害LLMs先天能力的问题。LLaMA-Excitor设计了Excitor block作为自注意力(self-attention)机制的旁路模块，利用可学习提示重建keys并调整values的重要性，从而实现自适应地分配注意力并保留LLMs的预训练知识。实验结果显示，该方法在MMLU基准上提升6%同时保持基本能力，在视觉指令调优中达到MSCOCO图像描述的157.5 CIDEr新最优性能，并在ScienceQA上与参数更多且经过广泛视觉语言预训练的先进模型相当。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is accepted by CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00913v1",
      "published_date": "2024-04-01 04:39:21 UTC",
      "updated_date": "2024-04-01 04:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:51:28.190272"
    },
    {
      "arxiv_id": "2404.01351v1",
      "title": "AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Taeckyung Lee",
        "Sorn Chottananurak",
        "Taesik Gong",
        "Sung-Ju Lee"
      ],
      "abstract": "Test-time adaptation (TTA) has emerged as a viable solution to adapt\npre-trained models to domain shifts using unlabeled test data. However, TTA\nfaces challenges of adaptation failures due to its reliance on blind adaptation\nto unknown test samples in dynamic scenarios. Traditional methods for\nout-of-distribution performance estimation are limited by unrealistic\nassumptions in the TTA context, such as requiring labeled data or re-training\nmodels. To address this issue, we propose AETTA, a label-free accuracy\nestimation algorithm for TTA. We propose the prediction disagreement as the\naccuracy estimate, calculated by comparing the target model prediction with\ndropout inferences. We then improve the prediction disagreement to extend the\napplicability of AETTA under adaptation failures. Our extensive evaluation with\nfour baselines and six TTA methods demonstrates that AETTA shows an average of\n19.8%p more accurate estimation compared with the baselines. We further\ndemonstrate the effectiveness of accuracy estimation with a model recovery case\nstudy, showcasing the practicality of our model recovery based on accuracy\nestimation. The source code is available at https://github.com/taeckyung/AETTA.",
      "tldr_zh": "该论文针对测试时适应（Test-Time Adaptation, TTA）中存在的适应失败问题，提出了一种无标签准确率估计算法AETTA，以解决传统方法依赖标记数据或重新训练模型的局限性。AETTA通过计算预测分歧（prediction disagreement），即比较目标模型预测与dropout inferences的结果，来估计算确率，并对其进行改进以应对适应失败场景。在四种基线和六种TTA方法的广泛评估中，AETTA的准确率估计平均比基线高19.8%，并通过模型恢复案例研究证明了其在实际应用中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01351v1",
      "published_date": "2024-04-01 04:21:49 UTC",
      "updated_date": "2024-04-01 04:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:51:41.017230"
    },
    {
      "arxiv_id": "2404.00903v1",
      "title": "Maximizing User Experience with LLMOps-Driven Personalized Recommendation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxi Shi",
        "Penghao Liang",
        "Yichao Wu",
        "Tong Zhan",
        "Zhengyu Jin"
      ],
      "abstract": "The integration of LLMOps into personalized recommendation systems marks a\nsignificant advancement in managing LLM-driven applications. This innovation\npresents both opportunities and challenges for enterprises, requiring\nspecialized teams to navigate the complexity of engineering technology while\nprioritizing data security and model interpretability. By leveraging LLMOps,\nenterprises can enhance the efficiency and reliability of large-scale machine\nlearning models, driving personalized recommendations aligned with user\npreferences. Despite ethical considerations, LLMOps is poised for widespread\nadoption, promising more efficient and secure machine learning services that\nelevate user experience and shape the future of personalized recommendation\nsystems.",
      "tldr_zh": "该研究探讨了将 LLMOps 整合到个性化推荐系统中，以最大化用户体验。LLMOps 通过提升大型机器学习模型的效率和可靠性，帮助企业管理 LLM 驱动应用，同时强调数据安全和模型可解释性。论文指出，这种方法能生成与用户偏好一致的个性化推荐，尽管存在伦理考虑，但有望推动推荐系统的广泛采用和未来发展。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00903v1",
      "published_date": "2024-04-01 04:13:42 UTC",
      "updated_date": "2024-04-01 04:13:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:51:49.710723"
    },
    {
      "arxiv_id": "2404.00897v3",
      "title": "Machine Learning Robustness: A Primer",
      "title_zh": "机器学习鲁棒性：入门",
      "authors": [
        "Houssem Ben Braiek",
        "Foutse Khomh"
      ],
      "abstract": "This chapter explores the foundational concept of robustness in Machine\nLearning (ML) and its integral role in establishing trustworthiness in\nArtificial Intelligence (AI) systems. The discussion begins with a detailed\ndefinition of robustness, portraying it as the ability of ML models to maintain\nstable performance across varied and unexpected environmental conditions. ML\nrobustness is dissected through several lenses: its complementarity with\ngeneralizability; its status as a requirement for trustworthy AI; its\nadversarial vs non-adversarial aspects; its quantitative metrics; and its\nindicators such as reproducibility and explainability. The chapter delves into\nthe factors that impede robustness, such as data bias, model complexity, and\nthe pitfalls of underspecified ML pipelines. It surveys key techniques for\nrobustness assessment from a broad perspective, including adversarial attacks,\nencompassing both digital and physical realms. It covers non-adversarial data\nshifts and nuances of Deep Learning (DL) software testing methodologies. The\ndiscussion progresses to explore amelioration strategies for bolstering\nrobustness, starting with data-centric approaches like debiasing and\naugmentation. Further examination includes a variety of model-centric methods\nsuch as transfer learning, adversarial training, and randomized smoothing.\nLastly, post-training methods are discussed, including ensemble techniques,\npruning, and model repairs, emerging as cost-effective strategies to make\nmodels more resilient against the unpredictable. This chapter underscores the\nongoing challenges and limitations in estimating and achieving ML robustness by\nexisting approaches. It offers insights and directions for future research on\nthis crucial concept, as a prerequisite for trustworthy AI systems.",
      "tldr_zh": "本章作为机器学习（ML）鲁棒性的入门指南，探讨了鲁棒性在建立可信赖人工智能（AI）系统中的核心作用，定义为ML模型在各种意外环境条件下保持稳定性能的能力，并分析其与泛化性互补、对抗与非对抗方面、量化指标以及可重复性和可解释性等关键特性。论文审视了影响鲁棒性的因素，如数据偏差、模型复杂度和ML管道不足，并总结了评估技术，包括对抗攻击（数字和物理）、非对抗数据偏移以及深度学习（DL）软件测试方法。最终，它提出改进策略，如数据中心方法（去偏置和增强）、模型中心方法（迁移学习、对抗训练和随机平滑）以及后训练方法（集成技术、剪枝和模型修复），并强调现有方法的挑战和局限性，为未来ML鲁棒性研究提供方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00897v3",
      "published_date": "2024-04-01 03:49:42 UTC",
      "updated_date": "2024-05-04 00:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:52:03.536898"
    },
    {
      "arxiv_id": "2404.00886v1",
      "title": "MTLight: Efficient Multi-Task Reinforcement Learning for Traffic Signal Control",
      "title_zh": "MTLight：高效的多任务强化学习用于交通信号控制",
      "authors": [
        "Liwen Zhu",
        "Peixi Peng",
        "Zongqing Lu",
        "Yonghong Tian"
      ],
      "abstract": "Traffic signal control has a great impact on alleviating traffic congestion\nin modern cities. Deep reinforcement learning (RL) has been widely used for\nthis task in recent years, demonstrating promising performance but also facing\nmany challenges such as limited performances and sample inefficiency. To handle\nthese challenges, MTLight is proposed to enhance the agent observation with a\nlatent state, which is learned from numerous traffic indicators. Meanwhile,\nmultiple auxiliary and supervisory tasks are constructed to learn the latent\nstate, and two types of embedding latent features, the task-specific feature\nand task-shared feature, are used to make the latent state more abundant.\nExtensive experiments conducted on CityFlow demonstrate that MTLight has\nleading convergence speed and asymptotic performance. We further simulate under\npeak-hour pattern in all scenarios with increasing control difficulty and the\nresults indicate that MTLight is highly adaptable.",
      "tldr_zh": "这篇论文提出MTLight，一种高效的多任务强化学习（RL）方法，用于优化交通信号控制，以解决传统RL在性能和样本效率方面的挑战。MTLight通过学习一个从众多交通指标中提取的潜在状态，并构建多个辅助和监督任务，使用任务特定特征和任务共享特征来增强该状态的丰富性。实验结果显示，在CityFlow模拟环境中，MTLight实现了领先的收敛速度和渐进性能，并在高峰期场景下表现出高度适应性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00886v1",
      "published_date": "2024-04-01 03:27:46 UTC",
      "updated_date": "2024-04-01 03:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:52:15.290224"
    },
    {
      "arxiv_id": "2404.00884v1",
      "title": "Self-Demos: Eliciting Out-of-Demonstration Generalizability in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wei He",
        "Shichun Liu",
        "Jun Zhao",
        "Yiwen Ding",
        "Yi Lu",
        "Zhiheng Xi",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "Large language models (LLMs) have shown promising abilities of in-context\nlearning (ICL), adapting swiftly to new tasks with only few-shot\ndemonstrations. However, current few-shot methods heavily depend on\nhigh-quality, query-specific demos, which are often lacking. When faced with\nout-of-demonstration (OOD) queries, methods that rely on hand-crafted demos or\nexternal retrievers might fail. To bridge the gap between limited demos and OOD\nqueries, we propose Self-Demos, a novel prompting method that elicits the\ninherent generalizability in LLMs by query-aware demo generation. The generated\ndemos strategically interpolate between existing demos and the given query,\ntransforming the query from OOD to ID. To evaluate the effectiveness of our\napproach, we manually constructed OOD-Toolset, a dataset in the tool-using\nscenario with over 300 real-world APIs and 1000 instances, each consisting of\nthree tool-use cases as demos and an OOD query. Thorough experiments on our\ndataset and two public math benchmarks have shown that our method can\noutperform state-of-the-art baselines in the OOD setting. Moreover, we conduct\na range of analyses to validate Self-Demos's generalization and provide more\ninsights.",
      "tldr_zh": "本论文提出 Self-Demos，一种新型提示方法，用于激发 Large Language Models (LLMs) 在 out-of-demonstration (OOD) 查询中的内在泛化能力，以解决传统 in-context learning (ICL) 对高质量特定演示的依赖。Self-Demos 通过查询感知的演示生成，在现有演示和给定查询之间进行插值，将 OOD 查询转化为 in-demonstration (ID) 查询，从而提升模型的适应性。研究团队构建了 OOD-Toolset 数据集（包含300多个真实API和1000个实例），并通过实验证明该方法在工具使用场景和公共数学基准上优于现有基线，同时进行了广泛分析以验证其泛化性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2404.00884v1",
      "published_date": "2024-04-01 03:25:06 UTC",
      "updated_date": "2024-04-01 03:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:52:27.379994"
    },
    {
      "arxiv_id": "2405.01561v1",
      "title": "Rapid Mobile App Development for Generative AI Agents on MIT App Inventor",
      "title_zh": "翻译失败",
      "authors": [
        "Jaida Gao",
        "Calab Su",
        "Etai Miller",
        "Kevin Lu",
        "Yu Meng"
      ],
      "abstract": "The evolution of Artificial Intelligence (AI) stands as a pivotal force\nshaping our society, finding applications across diverse domains such as\neducation, sustainability, and safety. Leveraging AI within mobile applications\nmakes it easily accessible to the public, catalyzing its transformative\npotential. In this paper, we present a methodology for the rapid development of\nAI agent applications using the development platform provided by MIT App\nInventor. To demonstrate its efficacy, we share the development journey of\nthree distinct mobile applications: SynchroNet for fostering sustainable\ncommunities; ProductiviTeams for addressing procrastination; and iHELP for\nenhancing community safety. All three applications seamlessly integrate a\nspectrum of generative AI features, leveraging OpenAI APIs. Furthermore, we\noffer insights gleaned from overcoming challenges in integrating diverse tools\nand AI functionalities, aiming to inspire young developers to join our efforts\nin building practical AI agent applications.",
      "tldr_zh": "这篇论文提出了一种使用MIT App Inventor平台快速开发生成式AI代理应用的methodology，旨在使AI更易于整合到移动应用中，促进其在教育、可持续性和安全等领域的影响。作者展示了三个实际应用的开发案例：SynchroNet用于推动可持续社区、ProductiviTeams针对拖延问题、以及iHELP提升社区安全，这些应用均整合了OpenAI APIs的AI功能。论文还分享了整合工具和AI功能的挑战及经验教训，以激励年轻开发者参与构建实用AI代理应用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01561v1",
      "published_date": "2024-04-01 02:35:19 UTC",
      "updated_date": "2024-04-01 02:35:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:52:38.969987"
    },
    {
      "arxiv_id": "2404.00862v1",
      "title": "Bailong: Bilingual Transfer Learning based on QLoRA and Zip-tie Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Lung-Chuan Chen",
        "Zong-Ru Li"
      ],
      "abstract": "Large language models (LLMs) have demonstrated exceptional performance in\nvarious NLP applications. However, the majority of existing open-source LLMs\nare pre-trained primarily on English data and little part of other languages.\nThis deficiency in multilingual training data results in suboptimal performance\nwhen applied to languages with fewer available resources. Furthermore,\nenhancing the performance of LLMs on low-resource languages by full-parameter\nfine-tuning with additional data requires substantial computational resources,\nposing computational barriers for research organizations and individual\nresearchers. Consequently, several techniques such as parameter-efficient\ntuning and advanced embedding initialization have been proposed to address\nthese challenges. In this work, we combine them to facilitate cross-lingual\ntransfer on English-dominated open-source LLM. To effectively enhance the\nmodel's proficiency in Traditional Chinese, we conduct secondary pre-training\non Llama 2 7B with Traditional Chinese data by leveraging QLoRA and our\nproposed zip-tie embedding initialization. The resulting model called Bailong,\nwhich stands for Bilingual trAnsfer learnIng based on qLOra and zip-tie\nembeddiNG. We present Bailong-instruct 7B, a fine-tuned version of Bailong 7B\noptimized for multi-turn dialogue scenarios. Recognizing the inadequacy of\nbenchmark datasets in Traditional Chinese, we further introduce Bailong-bench\nto assess the alignment of models with human preferences and the capability to\nfollow instructions in both Traditional Chinese and English tasks. In our\nevaluation, Bailong-instruct 7B exhibits competitive performance on\nBailong-bench and other benchmark datasets when compared to other open-source\nmodels of similar or even larger parameter sizes. Bailong-instruct 7B and\nBailong-bench are publicly available with the aim of empowering the community\nto build upon our efforts.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在低资源语言（如传统中文）上的性能不足问题，提出了一种双语转移学习方法Bailong，结合QLoRA参数高效微调和Zip-tie Embedding初始化，在Llama 2 7B模型上进行二次预训练以增强其传统中文处理能力。研究团队开发了Bailong-instruct 7B版本，针对多轮对话场景进行优化，并创建了Bailong-bench基准，用于评估模型在传统中文和英文任务中的指令遵循和人类偏好对齐。实验结果显示，Bailong-instruct 7B在多个基准数据集上表现出色，与类似或更大参数的开源模型竞争，并已开源以支持社区进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00862v1",
      "published_date": "2024-04-01 02:04:44 UTC",
      "updated_date": "2024-04-01 02:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:52:52.253890"
    },
    {
      "arxiv_id": "2404.00856v1",
      "title": "Removing Speaker Information from Speech Representation using Variable-Length Soft Pooling",
      "title_zh": "使用可变长度软池化从语音表示中移除说话者信息",
      "authors": [
        "Injune Hwang",
        "Kyogu Lee"
      ],
      "abstract": "Recently, there have been efforts to encode the linguistic information of\nspeech using a self-supervised framework for speech synthesis. However,\npredicting representations from surrounding representations can inadvertently\nentangle speaker information in the speech representation. This paper aims to\nremove speaker information by exploiting the structured nature of speech,\ncomposed of discrete units like phonemes with clear boundaries. A neural\nnetwork predicts these boundaries, enabling variable-length pooling for\nevent-based representation extraction instead of fixed-rate methods. The\nboundary predictor outputs a probability for the boundary between 0 and 1,\nmaking pooling soft. The model is trained to minimize the difference with the\npooled representation of the data augmented by time-stretch and pitch-shift. To\nconfirm that the learned representation includes contents information but is\nindependent of speaker information, the model was evaluated with libri-light's\nphonetic ABX task and SUPERB's speaker identification task.",
      "tldr_zh": "本文提出了一种从语音表示中去除说话者信息的方法，针对自监督框架中可能混入的说话者信息问题。利用语音的结构化特性（如音素的离散边界），神经网络预测边界概率，实现变量长度软池化（variable-length soft pooling），并通过数据增强（如 time-stretch 和 pitch-shift）最小化表示差异。实验结果显示，该方法在 phonetic ABX task 中保留了内容信息，而在 speaker identification task 中证实了表示与说话者信息无关，从而提升了语音表示的鲁棒性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00856v1",
      "published_date": "2024-04-01 01:49:09 UTC",
      "updated_date": "2024-04-01 01:49:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:53:03.702242"
    },
    {
      "arxiv_id": "2404.00855v1",
      "title": "TSOM: Small Object Motion Detection Neural Network Inspired by Avian Visual Circuit",
      "title_zh": "翻译失败",
      "authors": [
        "Pignge Hu",
        "Xiaoteng Zhang",
        "Mengmeng Li",
        "Yingjie Zhu",
        "Li Shi"
      ],
      "abstract": "Detecting small moving objects in complex backgrounds from an overhead\nperspective is a highly challenging task for machine vision systems. As an\ninspiration from nature, the avian visual system is capable of processing\nmotion information in various complex aerial scenes, and its Retina-OT-Rt\nvisual circuit is highly sensitive to capturing the motion information of small\nobjects from high altitudes. However, more needs to be done on small object\nmotion detection algorithms based on the avian visual system. In this paper, we\nconducted mathematical modeling based on extensive studies of the biological\nmechanisms of the Retina-OT-Rt visual circuit. Based on this, we proposed a\nnovel tectum small object motion detection neural network (TSOM). The neural\nnetwork includes the retina, SGC dendritic, SGC Soma, and Rt layers, each layer\ncorresponding to neurons in the visual pathway. The Retina layer is responsible\nfor accurately projecting input content, the SGC dendritic layer perceives and\nencodes spatial-temporal information, the SGC Soma layer computes complex\nmotion information and extracts small objects, and the Rt layer integrates and\ndecodes motion information from multiple directions to determine the position\nof small objects. Extensive experiments on pigeon neurophysiological\nexperiments and image sequence data showed that the TSOM is biologically\ninterpretable and effective in extracting reliable small object motion features\nfrom complex high-altitude backgrounds.",
      "tldr_zh": "本研究受鸟类视觉系统（尤其是 Retina-OT-Rt 电路）启发，提出了一种新型神经网络 TSOM，用于检测复杂背景中从高空视角的小物体运动。TSOM 包括 Retina 层（负责输入投影）、SGC dendritic 层（感知编码时空信息）、SGC Soma 层（计算复杂运动信息并提取小物体）以及 Rt 层（整合多方向运动信息以定位小物体），这些层基于生物机制的数学建模来模拟视觉通路。实验在鸽子神经生理数据和图像序列上验证了 TSOM 的生物可解释性和有效性，能够从复杂高空背景中可靠地提取小物体运动特征。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00855v1",
      "published_date": "2024-04-01 01:49:08 UTC",
      "updated_date": "2024-04-01 01:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:53:15.225897"
    },
    {
      "arxiv_id": "2404.02174v1",
      "title": "Bounds of Block Rewards in Honest PinFi Systems",
      "title_zh": "诚实 PinFi 系统中的区块奖励边界",
      "authors": [
        "Qi He",
        "Yunwei Mao",
        "Ju Li"
      ],
      "abstract": "PinFi is a class of novel protocols for decentralized pricing of dissipative\nassets, whose value naturally declines over time. Central to the protocol's\nfunctionality and its market efficiency is the role of liquidity providers\n(LPs). This study addresses critical stability and sustainability challenges\nwithin the protocol, namely: the propensity of LPs to prefer selling in\nexternal markets over participation in the protocol; a similar inclination\ntowards selling within the PinFi system rather than contributing as LPs; and a\nscenario where LPs are disinclined to sell within the protocol. Employing a\ngame-theoretic approach, we explore PinFi's mechanisms and its broader\nramifications. Our findings reveal that, under a variety of common conditions\nand with an assumption of participant integrity, PinFi is capable of fostering\na dynamic equilibrium among LPs, sellers, and buyers. This balance is\nmaintained through a carefully calibrated range of block rewards for LPs,\nensuring the protocol's long-term stability and utility.",
      "tldr_zh": "这篇论文探讨了 PinFi 协议中 block rewards 的边界问题，该协议用于去中心化定价易耗资产，并强调流动性提供者 (LPs) 的关键作用。研究采用博弈论方法，分析了 LPs 倾向于在外部市场或协议内出售资产而非参与协议的挑战。结果表明，在假设参与者诚信的情况下，通过校准的 block rewards 范围，PinFi 能实现 LPs、卖家和买家的动态平衡，从而确保协议的长期稳定和实用性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02174v1",
      "published_date": "2024-04-01 01:25:40 UTC",
      "updated_date": "2024-04-01 01:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:53:27.270202"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 91,
  "processed_papers_count": 91,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T20:53:54.358875"
}