{
  "date": "2024-05-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于人工智能和机器学习领域，尤其是 Large Language Models (LLM) 的应用创新、Federated Learning 的效率提升，以及图像处理和生物医学领域的进展。其中，令人印象深刻的文章包括 Yoshua Bengio 参与的 LLM 创意研究，以及量子计算在基因组学中的潜力；重点讨论 LLM 在跨领域（如医疗和推荐系统）的适应性、Federated Learning 的能量优化，以及视觉模型的必要性评估。\n\n下面，我将挑选并简要讨论几篇重要的、话题度高的论文，先从 LLM 和 AI 核心主题入手，再快速触及其他相关领域。对于其他论文，我会简要列出标题并掠过细节，以控制篇幅。\n\n### LLM 和创意生成\n- **Divergent Creativity in Humans and Large Language Models（人类与大型语言模型的发散式创意）**  \n  作者包括 Yoshua Bengio。这篇论文通过定量基准框架比较 LLM 和人类的发散式创意，发现 LLM 在某些任务（如联想和写作）中可能超越人类。主要贡献是构建一个基准框架，促进更具创意的 LLM 开发，同时强调了人类思维独特性的研究价值。\n\n- **LLM Theory of Mind and Alignment: Opportunities and Risks（LLM 的理论心智与对齐：机会与风险）**  \n  这篇论文探讨 LLM 在模拟人类社交智能（理论心智）时的表现，分析其在目标指定、对话适应和道德判断中的机会与风险。主要发现是 LLM 的心智模拟能提升对齐效果，但也带来潜在风险，如在群体互动中的偏差。\n\n- **RLHF Workflow: From Reward Modeling to Online RLHF（RLHF 工作流：从奖励建模到在线强化学习人类反馈）**  \n  论文提出一个在线 RLHF 框架，用于训练 LLM。核心贡献是详细的工作流和开源实现，帮助 LLM 更好地处理人类反馈，提高性能；在实验中，模型在聊天和学术基准上表现出色。\n\n### Federated Learning 和优化\n- **Towards Energy-Aware Federated Learning via MARL: A Dual-Selection Approach for Model and Client（通过 MARL 实现能量感知的联邦学习：模型和客户端的双选方法）**  \n  这篇论文针对异构设备下的联邦学习提出 DR-FL 框架，使用多代理强化学习 (MARL) 优化模型和客户端选择。主要发现是，该方法在能量受限场景下显著提高了性能，并在多个数据集上验证了其有效性。\n\n- **Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data（基于 Stable Diffusion 的数据增强，用于非独立同分布数据的联邦学习）**  \n  论文引入 Stable Diffusion 生成合成数据，解决联邦学习中的非 IID 数据问题。关键贡献是生成的数据增强了模型鲁棒性，并在实验中展示了通信成本的降低。\n\n### 图像和视觉处理\n- **MambaOut: Do We Really Need Mamba for Vision?（MambaOut：视觉任务真的需要 Mamba 吗？）**  \n  作者质疑 Mamba 架构在视觉任务中的必要性，通过构建 MambaOut 模型（去除核心部分）证明，在图像分类中无需 Mamba 也能实现高性能。主要发现是 Mamba 适合长序列任务，但视觉任务可简化。\n\n- **VQDNA: Unleashing the Power of Vector Quantization for Multi-Species Genomic Sequence Modeling（VQDNA：释放向量量化在多物种基因组序列建模中的潜力）**  \n  这篇论文（ICML 2024 预印本）提出 VQDNA 框架，使用向量量化学习基因组词汇，改进了序列建模。核心贡献是 Hierarchical Residual Quantization (HRQ) 方法，提升了参数效率，并在 SARS-CoV-2 突变分析中展示了实际应用价值。\n\n### 其他快速掠过\n其他论文涉及机器人、音频生成和生物医学等领域，但相对次要，我仅列出部分标题并简述：\n- **Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT（Silver-Tongued and Sundry：使用 ChatGPT 探索交叉身份代词）** – 通过实验发现代词影响 LLM 的社交身份模拟，荣获 CHI'24 奖。\n- **SPIN: Simultaneous Perception, Interaction and Navigation（SPIN：同时感知、交互和导航）** – 提出机器人框架实现全视角协调，适用于复杂环境。\n- **FastSAG: Towards Fast Non-Autoregressive Singing Accompaniment Generation（FastSAG：面向快速非自回归的歌唱伴奏生成）** – 使用扩散模型加速音频生成，显著提高了效率。\n- **CANTONMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation（CANTONMT：调查粤语-英语神经机器翻译中的回译和模型切换机制）** – 开发了粤语翻译模型，并开源了应用。\n- 其余如 **Estimating Direct and Indirect Causal Effects...**（因果效应估计）、**AnomalyLLM...**（异常检测）等，均在特定领域有贡献，但细节较技术化，故不展开。\n\n总之，今天的论文突显了 LLM 在创意和实际应用的潜力，以及优化 AI 系统的趋势。如果您对特定领域感兴趣，建议查看这些重点论文的原文！",
  "papers": [
    {
      "arxiv_id": "2405.08238v1",
      "title": "Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Takao Fujii",
        "Katie Seaborn",
        "Madeleine Steeds"
      ],
      "abstract": "ChatGPT is a conversational agent built on a large language model. Trained on\na significant portion of human output, ChatGPT can mimic people to a degree. As\nsuch, we need to consider what social identities ChatGPT simulates (or can be\ndesigned to simulate). In this study, we explored the case of identity\nsimulation through Japanese first-person pronouns, which are tightly connected\nto social identities in intersectional ways, i.e., intersectional pronouns. We\nconducted a controlled online experiment where people from two regions in Japan\n(Kanto and Kinki) witnessed interactions with ChatGPT using ten sets of\nfirst-person pronouns. We discovered that pronouns alone can evoke perceptions\nof social identities in ChatGPT at the intersections of gender, age, region,\nand formality, with caveats. This work highlights the importance of pronoun use\nfor social identity simulation, provides a language-based methodology for\nculturally-sensitive persona development, and advances the potential of\nintersectional identities in intelligent agents.",
      "tldr_zh": "本研究探讨了 ChatGPT 如何通过日语的 intersectional pronouns（交叉身份代词）模拟社会身份，这些代词与性别、年龄、地域和正式性等因素紧密相关。研究采用控制的在线实验，让日本 Kanto 和 Kinki 地区的参与者观察 ChatGPT 使用十组 first-person pronouns 的互动。结果发现，代词本身能唤起对 ChatGPT 社会身份的交叉感知，但存在某些限制。该工作强调了代词在身份模拟中的关键作用，并为文化敏感的角色开发提供了基于语言的方法论，推进了智能代理中 intersectional identities 的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "Honorable Mention award (top 5%) at CHI '24",
      "pdf_url": "http://arxiv.org/pdf/2405.08238v1",
      "published_date": "2024-05-13 23:38:50 UTC",
      "updated_date": "2024-05-13 23:38:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:59:32.129827"
    },
    {
      "arxiv_id": "2405.13012v1",
      "title": "Divergent Creativity in Humans and Large Language Models",
      "title_zh": "人类和大语言模型中的发散创造力",
      "authors": [
        "Antoine Bellemare-Pepin",
        "François Lespinasse",
        "Philipp Thölke",
        "Yann Harel",
        "Kory Mathewson",
        "Jay A. Olson",
        "Yoshua Bengio",
        "Karim Jerbi"
      ],
      "abstract": "The recent surge in the capabilities of Large Language Models (LLMs) has led\nto claims that they are approaching a level of creativity akin to human\ncapabilities. This idea has sparked a blend of excitement and apprehension.\nHowever, a critical piece that has been missing in this discourse is a\nsystematic evaluation of LLM creativity, particularly in comparison to human\ndivergent thinking. To bridge this gap, we leverage recent advances in\ncreativity science to build a framework for in-depth analysis of divergent\ncreativity in both state-of-the-art LLMs and a substantial dataset of 100,000\nhumans. We found evidence suggesting that LLMs can indeed surpass human\ncapabilities in specific creative tasks such as divergent association and\ncreative writing. Our quantitative benchmarking framework opens up new paths\nfor the development of more creative LLMs, but it also encourages more granular\ninquiries into the distinctive elements that constitute human inventive thought\nprocesses, compared to those that can be artificially generated.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)与人类的发散创造力，构建了一个系统评估框架来比较二者。作者利用创意科学进展，分析了LLMs和10万人类数据集在发散联想和创意写作等任务中的表现。结果显示，LLMs在某些特定任务中可能超过人类能力。该框架不仅为开发更具创造力的LLMs开辟新路径，还鼓励更深入地探究人类创新思维与AI生成的独特差异。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "First two and last listed authors are corresponding authors. The\n  first two listed authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2405.13012v1",
      "published_date": "2024-05-13 22:37:52 UTC",
      "updated_date": "2024-05-13 22:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:59:43.183769"
    },
    {
      "arxiv_id": "2405.08183v2",
      "title": "Towards Energy-Aware Federated Learning via MARL: A Dual-Selection Approach for Model and Client",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Xia",
        "Yi Zhang",
        "Yiyu Shi"
      ],
      "abstract": "Although Federated Learning (FL) is promising in knowledge sharing for\nheterogeneous Artificial Intelligence of Thing (AIoT) devices, their training\nperformance and energy efficacy are severely restricted in practical\nbattery-driven scenarios due to the ``wooden barrel effect'' caused by the\nmismatch between homogeneous model paradigms and heterogeneous device\ncapability. As a result, due to various kinds of differences among devices, it\nis hard for existing FL methods to conduct training effectively in\nenergy-constrained scenarios, such as battery constraints of devices. To tackle\nthe above issues, we propose an energy-aware FL framework named DR-FL, which\nconsiders the energy constraints in both clients and heterogeneous deep\nlearning models to enable energy-efficient FL. Unlike Vanilla FL, DR-FL adopts\nour proposed Muti-Agents Reinforcement Learning (MARL)-based dual-selection\nmethod, which allows participated devices to make contributions to the global\nmodel effectively and adaptively based on their computing capabilities and\nenergy capacities in a MARL-based manner. Experiments conducted with various\nwidely recognized datasets demonstrate that DR-FL has the capability to\noptimize the exchange of knowledge among diverse models in large-scale AIoT\nsystems while adhering to energy limitations. Additionally, it improves the\nperformance of each individual heterogeneous device's model.",
      "tldr_zh": "本论文针对 Federated Learning (FL) 在异构 AIoT 设备中的能量效率问题，提出了一种能量感知框架 DR-FL，以解决设备差异和电池约束导致的训练性能低下。DR-FL 采用基于 Multi-Agents Reinforcement Learning (MARL) 的双重选择方法，允许设备根据其计算能力和能量容量自适应地选择模型和参与训练，从而优化知识交换。实验结果显示，DR-FL 在多种数据集上显著提升了异构设备的模型性能，同时满足能量限制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08183v2",
      "published_date": "2024-05-13 21:02:31 UTC",
      "updated_date": "2024-07-09 16:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:59:55.050751"
    },
    {
      "arxiv_id": "2405.08174v2",
      "title": "Estimating Direct and Indirect Causal Effects of Spatiotemporal Interventions in Presence of Spatial Interference",
      "title_zh": "在存在空间干扰的情况下估计时空干预的直接和间接因果效应",
      "authors": [
        "Sahara Ali",
        "Omar Faruque",
        "Jianwu Wang"
      ],
      "abstract": "Spatial interference (SI) occurs when the treatment at one location affects\nthe outcomes at other locations. Accounting for spatial interference in\nspatiotemporal settings poses further challenges as interference violates the\nstable unit treatment value assumption, making it infeasible for standard\ncausal inference methods to quantify the effects of time-varying treatment at\nspatially varying outcomes. In this paper, we first formalize the concept of\nspatial interference in case of time-varying treatment assignments by extending\nthe potential outcome framework under the assumption of no unmeasured\nconfounding. We then propose our deep learning based potential outcome model\nfor spatiotemporal causal inference. We utilize latent factor modeling to\nreduce the bias due to time-varying confounding while leveraging the power of\nU-Net architecture to capture global and local spatial interference in data\nover time. Our causal estimators are an extension of average treatment effect\n(ATE) for estimating direct (DATE) and indirect effects (IATE) of spatial\ninterference on treated and untreated data. Being the first of its kind deep\nlearning based spatiotemporal causal inference technique, our approach shows\nadvantages over several baseline methods based on the experiment results on two\nsynthetic datasets, with and without spatial interference. Our results on\nreal-world climate dataset also align with domain knowledge, further\ndemonstrating the effectiveness of our proposed method.",
      "tldr_zh": "该论文探讨了在存在空间干扰（Spatial interference）的情况下，估算时空干预的直接和间接因果效果的问题，扩展了潜在结果框架（potential outcome framework）以处理时间变化处理分配下的干扰。研究提出了一种基于深度学习的模型，利用潜变量建模（latent factor modeling）减少时间变化混杂偏差，并结合 U-Net 架构捕获全局和局部空间干扰，从而估算直接效果（DATE）和间接效果（IATE）的扩展版本。实验结果显示，该方法在合成数据集上优于基线方法，并在真实世界气候数据集上验证了其有效性，与领域知识一致。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08174v2",
      "published_date": "2024-05-13 20:39:27 UTC",
      "updated_date": "2024-08-29 23:21:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:00:07.728191"
    },
    {
      "arxiv_id": "2405.08172v1",
      "title": "CANTONMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Kung Yin Hong",
        "Lifeng Han",
        "Riza Batista-Navarro",
        "Goran Nenadic"
      ],
      "abstract": "This paper investigates the development and evaluation of machine translation\nmodels from Cantonese to English, where we propose a novel approach to tackle\nlow-resource language translations. The main objectives of the study are to\ndevelop a model that can effectively translate Cantonese to English and\nevaluate it against state-of-the-art commercial models. To achieve this, a new\nparallel corpus has been created by combining different available corpora\nonline with preprocessing and cleaning. In addition, a monolingual Cantonese\ndataset has been created through web scraping to aid the synthetic parallel\ncorpus generation. Following the data collection process, several approaches,\nincluding fine-tuning models, back-translation, and model switch, have been\nused. The translation quality of models has been evaluated with multiple\nquality metrics, including lexicon-based metrics (SacreBLEU and hLEPOR) and\nembedding-space metrics (COMET and BERTscore). Based on the automatic metrics,\nthe best model is selected and compared against the 2 best commercial\ntranslators using the human evaluation framework HOPES. The best model proposed\nin this investigation (NLLB-mBART) with model switch mechanisms has reached\ncomparable and even better automatic evaluation scores against State-of-the-art\ncommercial models (Bing and Baidu Translators), with a SacreBLEU score of 16.8\non our test set. Furthermore, an open-source web application has been developed\nto allow users to translate between Cantonese and English, with the different\ntrained models available for effective comparisons between models from this\ninvestigation and users. CANTONMT is available at\nhttps://github.com/kenrickkung/CantoneseTranslation",
      "tldr_zh": "本研究调查了Cantonese-English神经机器翻译的开发，提出了一种结合back-translation和model-switch机制的新方法，以应对低资源语言翻译的挑战。研究团队创建了新的平行语料库和单语Cantonese数据集，通过微调模型（如NLLB-mBART）并应用多种评估指标（包括SacreBLEU、hLEPOR、COMET和BERTscore），发现最佳模型在SacreBLEU得分达到16.8，与Bing和Baidu等商业模型相比表现出色或相当。最终，该模型通过开源web应用（CANTONMT）提供，用户可比较不同模型的翻译效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "on-going work, 30 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.08172v1",
      "published_date": "2024-05-13 20:37:04 UTC",
      "updated_date": "2024-05-13 20:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:00:19.502403"
    },
    {
      "arxiv_id": "2405.10812v2",
      "title": "VQDNA: Unleashing the Power of Vector Quantization for Multi-Species Genomic Sequence Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Li",
        "Zedong Wang",
        "Zicheng Liu",
        "Di Wu",
        "Cheng Tan",
        "Jiangbin Zheng",
        "Yufei Huang",
        "Stan Z. Li"
      ],
      "abstract": "Similar to natural language models, pre-trained genome language models are\nproposed to capture the underlying intricacies within genomes with unsupervised\nsequence modeling. They have become essential tools for researchers and\npractitioners in biology. However, the hand-crafted tokenization policies used\nin these models may not encode the most discriminative patterns from the\nlimited vocabulary of genomic data. In this paper, we introduce VQDNA, a\ngeneral-purpose framework that renovates genome tokenization from the\nperspective of genome vocabulary learning. By leveraging vector-quantized\ncodebooks as learnable vocabulary, VQDNA can adaptively tokenize genomes into\npattern-aware embeddings in an end-to-end manner. To further push its limits,\nwe propose Hierarchical Residual Quantization (HRQ), where varying scales of\ncodebooks are designed in a hierarchy to enrich the genome vocabulary in a\ncoarse-to-fine manner. Extensive experiments on 32 genome datasets demonstrate\nVQDNA's superiority and favorable parameter efficiency compared to existing\ngenome language models. Notably, empirical analysis of SARS-CoV-2 mutations\nreveals the fine-grained pattern awareness and biological significance of\nlearned HRQ vocabulary, highlighting its untapped potential for broader\napplications in genomics.",
      "tldr_zh": "该论文提出 VQDNA 框架，通过 Vector Quantization 技术实现基因组序列的自适应标记化，旨在解决现有基因组语言模型中手工标记化策略无法捕获最有辨识度模式的局限性。VQDNA 使用可学习的代码本作为词汇，结合 Hierarchical Residual Quantization (HRQ) 的层次化设计，从粗到细丰富基因组词汇，从而提升模型的端到端性能。在 32 个多物种基因组数据集上的实验证明，VQDNA 比传统模型表现出色，并具有更高的参数效率；此外，对 SARS-CoV-2 突变的分析突显了 HRQ 词汇的细粒度模式感知和生物学意义，为基因组研究提供新工具。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "ICML 2024. Preprint V2 with 17 pages and 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.10812v2",
      "published_date": "2024-05-13 20:15:03 UTC",
      "updated_date": "2024-06-02 17:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:00:31.873699"
    },
    {
      "arxiv_id": "2405.08154v1",
      "title": "LLM Theory of Mind and Alignment: Opportunities and Risks",
      "title_zh": "LLM 心智理论与对齐：机会与风险",
      "authors": [
        "Winnie Street"
      ],
      "abstract": "Large language models (LLMs) are transforming human-computer interaction and\nconceptions of artificial intelligence (AI) with their impressive capacities\nfor conversing and reasoning in natural language. There is growing interest in\nwhether LLMs have theory of mind (ToM); the ability to reason about the mental\nand emotional states of others that is core to human social intelligence. As\nLLMs are integrated into the fabric of our personal, professional and social\nlives and given greater agency to make decisions with real-world consequences,\nthere is a critical need to understand how they can be aligned with human\nvalues. ToM seems to be a promising direction of inquiry in this regard.\nFollowing the literature on the role and impacts of human ToM, this paper\nidentifies key areas in which LLM ToM will show up in human:LLM interactions at\nindividual and group levels, and what opportunities and risks for alignment are\nraised in each. On the individual level, the paper considers how LLM ToM might\nmanifest in goal specification, conversational adaptation, empathy and\nanthropomorphism. On the group level, it considers how LLM ToM might facilitate\ncollective alignment, cooperation or competition, and moral judgement-making.\nThe paper lays out a broad spectrum of potential implications and suggests the\nmost pressing areas for future research.",
      "tldr_zh": "该论文探讨了大型语言模型（LLM）是否具备理论心智（ToM），即理解他人心理和情感状态的能力，并分析其对模型与人类价值观对齐（Alignment）的机会与风险。随着LLM融入日常生活并影响决策，该研究基于人类ToM文献，考察了ToM在个体层面（如目标指定、对话适应、移情和拟人化）和群体层面（如集体一致、合作竞争及道德判断）的表现。论文识别出ToM可能提升人机互动的潜在益处，同时警告可能带来的风险，如误导性决策，并建议未来研究重点关注这些领域以促进LLM的安全应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.1.2; H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08154v1",
      "published_date": "2024-05-13 19:52:16 UTC",
      "updated_date": "2024-05-13 19:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:00:43.368062"
    },
    {
      "arxiv_id": "2405.13011v1",
      "title": "Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups",
      "title_zh": "翻译失败",
      "authors": [
        "Andrés Carvallo",
        "Tamara Quiroga",
        "Carlos Aspillaga",
        "Marcelo Mendoza"
      ],
      "abstract": "While civilized users employ social media to stay informed and discuss daily\noccurrences, haters perceive these platforms as fertile ground for attacking\ngroups and individuals. The prevailing approach to counter this phenomenon\ninvolves detecting such attacks by identifying toxic language. Effective\nplatform measures aim to report haters and block their network access. In this\ncontext, employing hate speech detection methods aids in identifying these\nattacks amidst vast volumes of text, which are impossible for humans to analyze\nmanually. In our study, we expand upon the usual hate speech detection methods,\ntypically based on text classifiers, to develop a Named Entity Recognition\n(NER) System for Identity Groups. To achieve this, we created a dataset that\nallows extending a conventional NER to recognize identity groups. Consequently,\nour tool not only detects whether a sentence contains an attack but also tags\nthe sentence tokens corresponding to the mentioned group. Results indicate that\nthe model performs competitively in identifying groups with an average f1-score\nof 0.75, outperforming in identifying ethnicity attack spans with an f1-score\nof 0.80 compared to other identity groups. Moreover, the tool shows an\noutstanding generalization capability to minority classes concerning sexual\norientation and gender, achieving an f1-score of 0.77 and 0.72, respectively.\nWe tested the utility of our tool in a case study on social media, annotating\nand comparing comments from Facebook related to news mentioning identity\ngroups. The case study reveals differences in the types of attacks recorded,\neffectively detecting named entities related to the categories of the analyzed\nnews articles. Entities are accurately tagged within their categories, with a\nnegligible error rate for inter-category tagging.",
      "tldr_zh": "本研究提出了一种新型 Named Entity Recognition (NER) 系统，旨在识别社交媒体中针对身份群体的仇恨言论，从而扩展传统基于文本分类的仇恨检测方法。该系统通过创建专用数据集，扩展常规 NER 功能，不仅检测句子是否包含攻击，还能标记相关身份群体实体。实验结果显示，模型平均 F1-score 为 0.75，在种族攻击识别上达到 0.80，对性取向和性别少数群体的泛化能力突出，F1-score 分别为 0.77 和 0.72。在 Facebook 评论的案例研究中，该系统准确标注实体并揭示不同攻击类型差异，错误率低，证明了其实用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13011v1",
      "published_date": "2024-05-13 19:33:18 UTC",
      "updated_date": "2024-05-13 19:33:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:00:58.594526"
    },
    {
      "arxiv_id": "2405.08131v1",
      "title": "When factorization meets argumentation: towards argumentative explanations",
      "title_zh": "当因子分解遇见论证：朝向论证性解释",
      "authors": [
        "Jinfeng Zhong",
        "Elsa Negre"
      ],
      "abstract": "Factorization-based models have gained popularity since the Netflix challenge\n{(2007)}. Since that, various factorization-based models have been developed\nand these models have been proven to be efficient in predicting users' ratings\ntowards items. A major concern is that explaining the recommendations generated\nby such methods is non-trivial because the explicit meaning of the latent\nfactors they learn are not always clear. In response, we propose a novel model\nthat combines factorization-based methods with argumentation frameworks (AFs).\nThe integration of AFs provides clear meaning at each stage of the model,\nenabling it to produce easily understandable explanations for its\nrecommendations. In this model, for every user-item interaction, an AF is\ndefined in which the features of items are considered as arguments, and the\nusers' ratings towards these features determine the strength and polarity of\nthese arguments. This perspective allows our model to treat feature attribution\nas a structured argumentation procedure, where each calculation is marked with\nexplicit meaning, enhancing its inherent interpretability. Additionally, our\nframework seamlessly incorporates side information, such as user contexts,\nleading to more accurate predictions. We anticipate at least three practical\napplications for our model: creating explanation templates, providing\ninteractive explanations, and generating contrastive explanations. Through\ntesting on real-world datasets, we have found that our model, along with its\nvariants, not only surpasses existing argumentation-based methods but also\ncompetes effectively with current context-free and context-aware methods.",
      "tldr_zh": "该论文探讨了因子分解模型（factorization-based models）在推荐系统中的解释性问题，提出了一种新模型，将factorization-based methods与argumentation frameworks (AFs)相结合，以生成更易理解的论证式解释。在该模型中，每个用户-物品互动被定义为一个AF，其中物品特征作为参数，用户对这些特征的评分决定参数的强度和极性，从而将特征归因转化为结构化的论证过程，并无缝整合侧信息如用户上下文以提升预测准确性。该框架支持多种实际应用，包括创建解释模板、提供交互式解释和生成对比解释；实验结果显示，该模型及其变体在真实数据集上优于现有argumentation-based方法，并与当前context-free和context-aware方法竞争。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2310.16157",
      "pdf_url": "http://arxiv.org/pdf/2405.08131v1",
      "published_date": "2024-05-13 19:16:28 UTC",
      "updated_date": "2024-05-13 19:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:01:07.536132"
    },
    {
      "arxiv_id": "2405.08125v2",
      "title": "AI-Cybersecurity Education Through Designing AI-based Cyberharassment Detection Lab",
      "title_zh": "翻译失败",
      "authors": [
        "Ebuka Okpala",
        "Nishant Vishwamitra",
        "Keyan Guo",
        "Song Liao",
        "Long Cheng",
        "Hongxin Hu",
        "Yongkai Wu",
        "Xiaohong Yuan",
        "Jeannette Wade",
        "Sajad Khorsandroo"
      ],
      "abstract": "Cyberharassment is a critical, socially relevant cybersecurity problem\nbecause of the adverse effects it can have on targeted groups or individuals.\nWhile progress has been made in understanding cyber-harassment, its detection,\nattacks on artificial intelligence (AI) based cyberharassment systems, and the\nsocial problems in cyberharassment detectors, little has been done in designing\nexperiential learning educational materials that engage students in this\nemerging social cybersecurity in the era of AI. Experiential learning\nopportunities are usually provided through capstone projects and engineering\ndesign courses in STEM programs such as computer science. While capstone\nprojects are an excellent example of experiential learning, given the\ninterdisciplinary nature of this emerging social cybersecurity problem, it can\nbe challenging to use them to engage non-computing students without prior\nknowledge of AI. Because of this, we were motivated to develop a hands-on lab\nplatform that provided experiential learning experiences to non-computing\nstudents with little or no background knowledge in AI and discussed the lessons\nlearned in developing this lab. In this lab used by social science students at\nNorth Carolina A&T State University across two semesters (spring and fall) in\n2022, students are given a detailed lab manual and are to complete a set of\nwell-detailed tasks. Through this process, students learn AI concepts and the\napplication of AI for cyberharassment detection. Using pre- and post-surveys,\nwe asked students to rate their knowledge or skills in AI and their\nunderstanding of the concepts learned. The results revealed that the students\nmoderately understood the concepts of AI and cyberharassment.",
      "tldr_zh": "这篇论文探讨了通过设计基于AI的网络骚扰（cyberharassment）检测实验平台来提升AI网络安全教育的途径，针对缺乏AI背景的非计算专业学生提供体验式学习（experiential learning）机会。研究团队开发了一个动手实验室，包括详细的手册和任务，让学生学习AI概念及其在网络骚扰检测中的应用，并在2022年春季和秋季学期于北卡罗来纳A&T州立大学的社会科学课程中进行测试。通过前后调查，结果显示学生对AI和网络骚扰概念有中等程度的理解，为跨学科社会网络安全教育提供了创新方法。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.08125v2",
      "published_date": "2024-05-13 19:09:50 UTC",
      "updated_date": "2024-05-16 12:10:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:01:19.001697"
    },
    {
      "arxiv_id": "2405.08120v1",
      "title": "From Questions to Insightful Answers: Building an Informed Chatbot for University Resources",
      "title_zh": "翻译失败",
      "authors": [
        "Subash Neupane",
        "Elias Hossain",
        "Jason Keith",
        "Himanshu Tripathi",
        "Farbod Ghiasi",
        "Noorbakhsh Amiri Golilarz",
        "Amin Amirlatifi",
        "Sudip Mittal",
        "Shahram Rahimi"
      ],
      "abstract": "This paper presents BARKPLUG V.2, a Large Language Model (LLM)-based chatbot\nsystem built using Retrieval Augmented Generation (RAG) pipelines to enhance\nthe user experience and access to information within academic settings.The\nobjective of BARKPLUG V.2 is to provide information to users about various\ncampus resources, including academic departments, programs, campus facilities,\nand student resources at a university setting in an interactive fashion. Our\nsystem leverages university data as an external data corpus and ingests it into\nour RAG pipelines for domain-specific question-answering tasks. We evaluate the\neffectiveness of our system in generating accurate and pertinent responses for\nMississippi State University, as a case study, using quantitative measures,\nemploying frameworks such as Retrieval Augmented Generation Assessment(RAGAS).\nFurthermore, we evaluate the usability of this system via subjective\nsatisfaction surveys using the System Usability Scale (SUS). Our system\ndemonstrates impressive quantitative performance, with a mean RAGAS score of\n0.96, and experience, as validated by usability assessments.",
      "tldr_zh": "这篇论文介绍了 BARKPLUG V.2，一种基于 LLM 的聊天机器人系统，利用 RAG 管道整合大学数据作为外部语料库，提供交互式查询服务，如学术部门、校园设施和学生资源。系统针对特定领域的问答任务进行了优化，并以密西西比州立大学为例进行评估。结果显示，BARKPLUG V.2 在 RAGAS 框架中获得 0.96 的平均分数，并在 SUS 主观满意度调查中表现出色，证明了其准确性和可用性。",
      "categories": [
        "cs.ET",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08120v1",
      "published_date": "2024-05-13 19:05:42 UTC",
      "updated_date": "2024-05-13 19:05:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:01:31.948806"
    },
    {
      "arxiv_id": "2405.07992v3",
      "title": "MambaOut: Do We Really Need Mamba for Vision?",
      "title_zh": "MambaOut: 我们真的需要 Mamba 用于视觉吗？",
      "authors": [
        "Weihao Yu",
        "Xinchao Wang"
      ],
      "abstract": "Mamba, an architecture with RNN-like token mixer of state space model (SSM),\nwas recently introduced to address the quadratic complexity of the attention\nmechanism and subsequently applied to vision tasks. Nevertheless, the\nperformance of Mamba for vision is often underwhelming when compared with\nconvolutional and attention-based models. In this paper, we delve into the\nessence of Mamba, and conceptually conclude that Mamba is ideally suited for\ntasks with long-sequence and autoregressive characteristics. For vision tasks,\nas image classification does not align with either characteristic, we\nhypothesize that Mamba is not necessary for this task; Detection and\nsegmentation tasks are also not autoregressive, yet they adhere to the\nlong-sequence characteristic, so we believe it is still worthwhile to explore\nMamba's potential for these tasks. To empirically verify our hypotheses, we\nconstruct a series of models named MambaOut through stacking Mamba blocks while\nremoving their core token mixer, SSM. Experimental results strongly support our\nhypotheses. Specifically, our MambaOut model surpasses all visual Mamba models\non ImageNet image classification, indicating that Mamba is indeed unnecessary\nfor this task. As for detection and segmentation, MambaOut cannot match the\nperformance of state-of-the-art visual Mamba models, demonstrating the\npotential of Mamba for long-sequence visual tasks. The code is available at\nhttps://github.com/yuweihao/MambaOut",
      "tldr_zh": "这篇论文质疑了Mamba架构（基于状态空间模型SSM的RNN-like token mixer）在视觉任务中的必要性，认为其更适合长序列和自回归任务，而非典型的图像分类。作者构建了MambaOut模型，通过移除Mamba的核心组件SSM并堆叠Mamba块，对其进行了实验验证。结果显示，在ImageNet图像分类任务上，MambaOut超过了现有视觉Mamba模型，证明Mamba对该任务不必要；然而，在检测和分割等长序列视觉任务上，Mamba仍显示出潜力。代码已开源于https://github.com/yuweihao/MambaOut。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/yuweihao/MambaOut",
      "pdf_url": "http://arxiv.org/pdf/2405.07992v3",
      "published_date": "2024-05-13 17:59:56 UTC",
      "updated_date": "2024-05-20 16:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:01:44.300387"
    },
    {
      "arxiv_id": "2405.07991v1",
      "title": "SPIN: Simultaneous Perception, Interaction and Navigation",
      "title_zh": "SPIN：同时感知、交互与导航",
      "authors": [
        "Shagun Uppal",
        "Ananye Agarwal",
        "Haoyu Xiong",
        "Kenneth Shaw",
        "Deepak Pathak"
      ],
      "abstract": "While there has been remarkable progress recently in the fields of\nmanipulation and locomotion, mobile manipulation remains a long-standing\nchallenge. Compared to locomotion or static manipulation, a mobile system must\nmake a diverse range of long-horizon tasks feasible in unstructured and dynamic\nenvironments. While the applications are broad and interesting, there are a\nplethora of challenges in developing these systems such as coordination between\nthe base and arm, reliance on onboard perception for perceiving and interacting\nwith the environment, and most importantly, simultaneously integrating all\nthese parts together. Prior works approach the problem using disentangled\nmodular skills for mobility and manipulation that are trivially tied together.\nThis causes several limitations such as compounding errors, delays in\ndecision-making, and no whole-body coordination. In this work, we present a\nreactive mobile manipulation framework that uses an active visual system to\nconsciously perceive and react to its environment. Similar to how humans\nleverage whole-body and hand-eye coordination, we develop a mobile manipulator\nthat exploits its ability to move and see, more specifically -- to move in\norder to see and to see in order to move. This allows it to not only move\naround and interact with its environment but also, choose \"when\" to perceive\n\"what\" using an active visual system. We observe that such an agent learns to\nnavigate around complex cluttered scenarios while displaying agile whole-body\ncoordination using only ego-vision without needing to create environment maps.\nResults visualizations and videos at https://spin-robot.github.io/",
      "tldr_zh": "该论文探讨了移动操纵（mobile manipulation）的挑战，指出现有模块化技能方法存在错误积累、决策延迟和缺乏全身协调的问题。作者提出SPIN框架，一种反应式的移动操纵系统，利用主动视觉系统（active visual system）实现同时感知、互动和导航，允许机器人通过“移动以查看”和“查看以移动”的策略进行敏捷全身协调。实验结果显示，该系统仅依赖自我视觉（ego-vision）即可在复杂杂乱环境中导航互动，无需环境地图，从而提升了整体性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "In CVPR 2024. Website at https://spin-robot.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.07991v1",
      "published_date": "2024-05-13 17:59:36 UTC",
      "updated_date": "2024-05-13 17:59:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:01:56.406740"
    },
    {
      "arxiv_id": "2405.07987v5",
      "title": "The Platonic Representation Hypothesis",
      "title_zh": "翻译失败",
      "authors": [
        "Minyoung Huh",
        "Brian Cheung",
        "Tongzhou Wang",
        "Phillip Isola"
      ],
      "abstract": "We argue that representations in AI models, particularly deep networks, are\nconverging. First, we survey many examples of convergence in the literature:\nover time and across multiple domains, the ways by which different neural\nnetworks represent data are becoming more aligned. Next, we demonstrate\nconvergence across data modalities: as vision models and language models get\nlarger, they measure distance between datapoints in a more and more alike way.\nWe hypothesize that this convergence is driving toward a shared statistical\nmodel of reality, akin to Plato's concept of an ideal reality. We term such a\nrepresentation the platonic representation and discuss several possible\nselective pressures toward it. Finally, we discuss the implications of these\ntrends, their limitations, and counterexamples to our analysis.",
      "tldr_zh": "该研究提出 Platonic Representation Hypothesis，认为 AI 模型，尤其是深度网络的表示（representations）正在趋同，即不同神经网络在处理数据的方式上越来越一致。论文通过文献调查和实验，展示了这种趋同现象在时间跨度和数据模态（如视觉和语言模型）上的表现，特别是模型规模增大后，它们测量数据点距离的方式变得更加相似。作者假设这种趋同是朝着一个共享的统计现实模型（类似于柏拉图的理想现实）发展，称为 Platonic Representation，并探讨了可能的 selective pressures，同时分析了其含义、限制和反例。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Equal contributions. Project: https://phillipi.github.io/prh/ Code:\n  https://github.com/minyoungg/platonic-rep",
      "pdf_url": "http://arxiv.org/pdf/2405.07987v5",
      "published_date": "2024-05-13 17:58:30 UTC",
      "updated_date": "2024-07-25 09:33:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:02:08.140895"
    },
    {
      "arxiv_id": "2405.07976v3",
      "title": "Localized Adaptive Risk Control",
      "title_zh": "局部自适应风险控制",
      "authors": [
        "Matteo Zecchin",
        "Osvaldo Simeone"
      ],
      "abstract": "Adaptive Risk Control (ARC) is an online calibration strategy based on set\nprediction that offers worst-case deterministic long-term risk control, as well\nas statistical marginal coverage guarantees. ARC adjusts the size of the\nprediction set by varying a single scalar threshold based on feedback from past\ndecisions. In this work, we introduce Localized Adaptive Risk Control (L-ARC),\nan online calibration scheme that targets statistical localized risk guarantees\nranging from conditional risk to marginal risk, while preserving the worst-case\nperformance of ARC. L-ARC updates a threshold function within a reproducing\nkernel Hilbert space (RKHS), with the kernel determining the level of\nlocalization of the statistical risk guarantee. The theoretical results\nhighlight a trade-off between localization of the statistical risk and\nconvergence speed to the long-term risk target. Thanks to localization, L-ARC\nis demonstrated via experiments to produce prediction sets with risk guarantees\nacross different data subpopulations, significantly improving the fairness of\nthe calibrated model for tasks such as image segmentation and beam selection in\nwireless networks.",
      "tldr_zh": "本文提出Localized Adaptive Risk Control (L-ARC)，一种基于Adaptive Risk Control (ARC)的在线校准方法，能够提供从条件风险到边际风险的统计本地化保证，同时保留ARC的最坏情况下的长期风险控制性能。L-ARC通过在reproducing kernel Hilbert space (RKHS)中更新阈值函数，利用核函数来控制风险保证的本地化水平，从而实现对不同数据子群体的针对性调整。理论分析揭示了统计风险本地化与收敛速度之间的权衡，即更高的本地化可能导致更慢的收敛。实验结果显示，L-ARC在图像分割和无线网络波束选择等任务中生成风险保证的预测集，显著提升了模型的公平性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07976v3",
      "published_date": "2024-05-13 17:48:45 UTC",
      "updated_date": "2024-10-10 07:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:02:20.696842"
    },
    {
      "arxiv_id": "2405.07969v1",
      "title": "Investigating the Semantic Robustness of CLIP-based Zero-Shot Anomaly Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Stangl",
        "Marius Arvinte",
        "Weilin Xu",
        "Cory Cornelius"
      ],
      "abstract": "Zero-shot anomaly segmentation using pre-trained foundation models is a\npromising approach that enables effective algorithms without expensive,\ndomain-specific training or fine-tuning. Ensuring that these methods work\nacross various environmental conditions and are robust to distribution shifts\nis an open problem. We investigate the performance of WinCLIP [14] zero-shot\nanomaly segmentation algorithm by perturbing test data using three semantic\ntransformations: bounded angular rotations, bounded saturation shifts, and hue\nshifts. We empirically measure a lower performance bound by aggregating across\nper-sample worst-case perturbations and find that average performance drops by\nup to 20% in area under the ROC curve and 40% in area under the per-region\noverlap curve. We find that performance is consistently lowered on three CLIP\nbackbones, regardless of model architecture or learning objective,\ndemonstrating a need for careful performance evaluation.",
      "tldr_zh": "本研究调查了基于 CLIP 的零样本异常分割（Zero-Shot Anomaly Segmentation）的语义鲁棒性，针对 WinCLIP 算法在分布偏移下的性能表现。\n研究者通过施加三种语义变换（bounded angular rotations、bounded saturation shifts 和 hue shifts）扰动测试数据，并聚合每个样本的最坏情况扰动来评估性能。\n结果显示，平均性能下降高达 20% 的 ROC 曲线下面积和 40% 的每个区域重叠曲线下面积，这种现象在多个 CLIP 骨干模型上一致出现。\n这突出了在不同环境条件下评估这些方法的必要性，以确保算法的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07969v1",
      "published_date": "2024-05-13 17:47:08 UTC",
      "updated_date": "2024-05-13 17:47:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:02:32.970696"
    },
    {
      "arxiv_id": "2405.07966v1",
      "title": "OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition",
      "title_zh": "OverlapM",
      "authors": [
        "Qiuchi Xiang",
        "Jintao Cheng",
        "Jiehao Luo",
        "Jin Wu",
        "Rui Fan",
        "Xieyuanli Chen",
        "Xiaoyu Tang"
      ],
      "abstract": "Place recognition is the foundation for enabling autonomous systems to\nachieve independent decision-making and safe operations. It is also crucial in\ntasks such as loop closure detection and global localization within SLAM.\nPrevious methods utilize mundane point cloud representations as input and deep\nlearning-based LiDAR-based Place Recognition (LPR) approaches employing\ndifferent point cloud image inputs with convolutional neural networks (CNNs) or\ntransformer architectures. However, the recently proposed Mamba deep learning\nmodel, combined with state space models (SSMs), holds great potential for long\nsequence modeling. Therefore, we developed OverlapMamba, a novel network for\nplace recognition, which represents input range views (RVs) as sequences. In a\nnovel way, we employ a stochastic reconstruction approach to build shift state\nspace models, compressing the visual representation. Evaluated on three\ndifferent public datasets, our method effectively detects loop closures,\nshowing robustness even when traversing previously visited locations from\ndifferent directions. Relying on raw range view inputs, it outperforms typical\nLiDAR and multi-view combination methods in time complexity and speed,\nindicating strong place recognition capabilities and real-time efficiency.",
      "tldr_zh": "该论文提出了一种名为OverlapMamba的新型网络，用于LiDAR-based Place Recognition（LPR），旨在提升自主系统的定位和决策能力。方法将range views (RVs)表示为序列，并通过stochastic reconstruction approach构建shift state space models（SSMs），结合Mamba模型来压缩视觉表示，从而实现高效的长序列建模。在三个公共数据集上的实验显示，OverlapMamba在loop closure detection方面表现出色，即使从不同方向访问相同位置也保持鲁棒性，并在时间复杂度和速度上优于传统LiDAR和多视图组合方法，支持实时应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07966v1",
      "published_date": "2024-05-13 17:46:35 UTC",
      "updated_date": "2024-05-13 17:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:02:42.802572"
    },
    {
      "arxiv_id": "2405.07943v2",
      "title": "Decision Mamba Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "André Correia",
        "Luís A. Alexandre"
      ],
      "abstract": "Recent advancements in imitation learning have been largely fueled by the\nintegration of sequence models, which provide a structured flow of information\nto effectively mimic task behaviours. Currently, Decision Transformer (DT) and\nsubsequently, the Hierarchical Decision Transformer (HDT), presented\nTransformer-based approaches to learn task policies. Recently, the Mamba\narchitecture has shown to outperform Transformers across various task domains.\nIn this work, we introduce two novel methods, Decision Mamba (DM) and\nHierarchical Decision Mamba (HDM), aimed at enhancing the performance of the\nTransformer models. Through extensive experimentation across diverse\nenvironments such as OpenAI Gym and D4RL, leveraging varying demonstration data\nsets, we demonstrate the superiority of Mamba models over their Transformer\ncounterparts in a majority of tasks. Results show that DM outperforms other\nmethods in most settings. The code can be found at\nhttps://github.com/meowatthemoon/DecisionMamba.",
      "tldr_zh": "该研究提出两种新方法，Decision Mamba (DM) 和 Hierarchical Decision Mamba (HDM)，基于 Mamba 架构来提升模仿学习中的任务策略表现，取代传统的 Transformer-based 模型如 Decision Transformer (DT) 和 Hierarchical Decision Transformer (HDT)。这些方法通过序列模型处理信息流，并在 OpenAI Gym 和 D4RL 等环境中进行广泛实验，利用不同演示数据集。结果显示，DM 在大多数任务中优于 Transformer 对应模型，并在多数设置中表现出色，为模仿学习提供更高效的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07943v2",
      "published_date": "2024-05-13 17:18:08 UTC",
      "updated_date": "2024-10-17 09:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:02:56.199815"
    },
    {
      "arxiv_id": "2405.07932v2",
      "title": "PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Zhang",
        "Qizhen Zhang",
        "Jakob Foerster"
      ],
      "abstract": "Large language models (LLMs) have shown success in many natural language\nprocessing tasks. Despite rigorous safety alignment processes, supposedly\nsafety-aligned LLMs like Llama 2 and Claude 2 are still susceptible to\njailbreaks, leading to security risks and abuse of the models. One option to\nmitigate such risks is to augment the LLM with a dedicated \"safeguard\", which\nchecks the LLM's inputs or outputs for undesired behaviour. A promising\napproach is to use the LLM itself as the safeguard. Nonetheless, baseline\nmethods, such as prompting the LLM to self-classify toxic content, demonstrate\nlimited efficacy. We hypothesise that this is due to domain shift: the\nalignment training imparts a self-censoring behaviour to the model (\"Sorry I\ncan't do that\"), while the self-classify approach shifts it to a classification\nformat (\"Is this prompt malicious\"). In this work, we propose PARDEN, which\navoids this domain shift by simply asking the model to repeat its own outputs.\nPARDEN neither requires finetuning nor white box access to the model. We\nempirically verify the effectiveness of our method and show that PARDEN\nsignificantly outperforms existing jailbreak detection baselines for Llama-2\nand Claude-2. Code and data are available at https://github.com/Ed-Zh/PARDEN.\n  We find that PARDEN is particularly powerful in the relevant regime of high\nTrue Positive Rate (TPR) and low False Positive Rate (FPR). For instance, for\nLlama2-7B, at TPR equal to 90%, PARDEN accomplishes a roughly 11x reduction in\nthe FPR from 24.8% to 2.0% on the harmful behaviours dataset.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)易受jailbreaks攻击的安全风险，提出PARDEN方法，通过简单要求模型重复其输出来检测恶意行为，从而避免了传统自分类方法中的领域偏移问题。PARDEN无需微调或白盒访问模型，即可有效提升检测性能。实验结果显示，在Llama-2和Claude-2模型上，PARDEN显著优于基线，例如在Llama2-7B上，当True Positive Rate(TPR)为90%时，False Positive Rate(FPR)从24.8%降至2.0%。这为LLMs的安全防护提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICML 20224",
      "pdf_url": "http://arxiv.org/pdf/2405.07932v2",
      "published_date": "2024-05-13 17:08:42 UTC",
      "updated_date": "2024-05-14 15:56:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:03:08.481907"
    },
    {
      "arxiv_id": "2405.07925v1",
      "title": "Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Morafah",
        "Matthias Reisser",
        "Bill Lin",
        "Christos Louizos"
      ],
      "abstract": "The proliferation of edge devices has brought Federated Learning (FL) to the\nforefront as a promising paradigm for decentralized and collaborative model\ntraining while preserving the privacy of clients' data. However, FL struggles\nwith a significant performance reduction and poor convergence when confronted\nwith Non-Independent and Identically Distributed (Non-IID) data distributions\namong participating clients. While previous efforts, such as client drift\nmitigation and advanced server-side model fusion techniques, have shown some\nsuccess in addressing this challenge, they often overlook the root cause of the\nperformance reduction - the absence of identical data accurately mirroring the\nglobal data distribution among clients. In this paper, we introduce Gen-FedSD,\na novel approach that harnesses the powerful capability of state-of-the-art\ntext-to-image foundation models to bridge the significant Non-IID performance\ngaps in FL. In Gen-FedSD, each client constructs textual prompts for each class\nlabel and leverages an off-the-shelf state-of-the-art pre-trained Stable\nDiffusion model to synthesize high-quality data samples. The generated\nsynthetic data is tailored to each client's unique local data gaps and\ndistribution disparities, effectively making the final augmented local data\nIID. Through extensive experimentation, we demonstrate that Gen-FedSD achieves\nstate-of-the-art performance and significant communication cost savings across\nvarious datasets and Non-IID settings.",
      "tldr_zh": "联邦学习(FL) 在处理 Non-IID 数据时常面临性能下降和收敛问题，本文提出 Gen-FedSD 方法，使用 Stable Diffusion 模型进行数据增强，以桥接数据分布差异。\n在 Gen-FedSD 中，每个客户端为每个类别构建文本提示，并利用预训练的 Stable Diffusion 模型生成高质量合成数据，针对本地数据差距进行定制化增强，使最终本地数据更接近 IID。\n实验结果表明，该方法在各种数据集和 Non-IID 设置中实现了最先进性能，并显著降低了通信成本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "International Workshop on Federated Foundation Models for the Web\n  2024 (FL@FM-TheWebConf'24)",
      "pdf_url": "http://arxiv.org/pdf/2405.07925v1",
      "published_date": "2024-05-13 16:57:48 UTC",
      "updated_date": "2024-05-13 16:57:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:03:19.633896"
    },
    {
      "arxiv_id": "2405.07916v1",
      "title": "IMAFD: An Interpretable Multi-stage Approach to Flood Detection from time series Multispectral Data",
      "title_zh": "IMAFD：一种基于时间序列多光谱数据的可解释多阶段洪水检测方法",
      "authors": [
        "Ziyang Zhang",
        "Plamen Angelov",
        "Dmitry Kangin",
        "Nicolas Longépé"
      ],
      "abstract": "In this paper, we address two critical challenges in the domain of flood\ndetection: the computational expense of large-scale time series change\ndetection and the lack of interpretable decision-making processes on\nexplainable AI (XAI). To overcome these challenges, we proposed an\ninterpretable multi-stage approach to flood detection, IMAFD has been proposed.\nIt provides an automatic, efficient and interpretable solution suitable for\nlarge-scale remote sensing tasks and offers insight into the decision-making\nprocess. The proposed IMAFD approach combines the analysis of the dynamic time\nseries image sequences to identify images with possible flooding with the\nstatic, within-image semantic segmentation. It combines anomaly detection (at\nboth image and pixel level) with semantic segmentation. The flood detection\nproblem is addressed through four stages: (1) at a sequence level: identifying\nthe suspected images (2) at a multi-image level: detecting change within\nsuspected images (3) at an image level: semantic segmentation of images into\nLand, Water or Cloud class (4) decision making. Our contributions are two\nfolder. First, we efficiently reduced the number of frames to be processed for\ndense change detection by providing a multi-stage holistic approach to flood\ndetection. Second, the proposed semantic change detection method (stage 3)\nprovides human users with an interpretable decision-making process, while most\nof the explainable AI (XAI) methods provide post hoc explanations. The\nevaluation of the proposed IMAFD framework was performed on three datasets,\nWorldFloods, RavAEn and MediaEval. For all the above datasets, the proposed\nframework demonstrates a competitive performance compared to other methods\noffering also interpretability and insight.",
      "tldr_zh": "本研究提出IMAFD框架，这是一种可解释的多阶段方法，用于从时间序列多光谱数据中检测洪水，旨在解决大规模变化检测的计算开销和可解释AI (XAI) 决策过程的缺失问题。IMAFD通过四个阶段处理洪水检测：序列级别识别可疑图像、多图像级别检测变化、图像级别语义分割成Land、Water或Cloud类别，以及最终决策阶段，结合异常检测和语义分割来提高效率。该框架在WorldFloods、RavAEn和MediaEval数据集上表现出与现有方法相当的性能，同时提供内在的可解释决策过程，而非事后解释，从而为大规模遥感任务带来自动化和洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07916v1",
      "published_date": "2024-05-13 16:47:53 UTC",
      "updated_date": "2024-05-13 16:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:03:32.170223"
    },
    {
      "arxiv_id": "2405.07893v1",
      "title": "Science based AI model certification for new operational environments with application in traffic state estimation",
      "title_zh": "基于科学的AI模型认证，用于新操作环境，并应用于交通状态估计",
      "authors": [
        "Daryl Mupupuni",
        "Anupama Guntu",
        "Liang Hong",
        "Kamrul Hasan",
        "Leehyun Keel"
      ],
      "abstract": "The expanding role of Artificial Intelligence (AI) in diverse engineering\ndomains highlights the challenges associated with deploying AI models in new\noperational environments, involving substantial investments in data collection\nand model training. Rapid application of AI necessitates evaluating the\nfeasibility of utilizing pre-trained models in unobserved operational settings\nwith minimal or no additional data. However, interpreting the opaque nature of\nAI's black-box models remains a persistent challenge. Addressing this issue,\nthis paper proposes a science-based certification methodology to assess the\nviability of employing pre-trained data-driven models in new operational\nenvironments. The methodology advocates a profound integration of domain\nknowledge, leveraging theoretical and analytical models from physics and\nrelated disciplines, with data-driven AI models. This novel approach introduces\ntools to facilitate the development of secure engineering systems, providing\ndecision-makers with confidence in the trustworthiness and safety of AI-based\nmodels across diverse environments characterized by limited training data and\ndynamic, uncertain conditions. The paper demonstrates the efficacy of this\nmethodology in real-world safety-critical scenarios, particularly in the\ncontext of traffic state estimation. Through simulation results, the study\nillustrates how the proposed methodology efficiently quantifies physical\ninconsistencies exhibited by pre-trained AI models. By utilizing analytical\nmodels, the methodology offers a means to gauge the applicability of\npre-trained AI models in new operational environments. This research\ncontributes to advancing the understanding and deployment of AI models,\noffering a robust certification framework that enhances confidence in their\nreliability and safety across a spectrum of operational conditions.",
      "tldr_zh": "这篇论文针对AI模型在新操作环境中的部署挑战，提出了一种基于科学的认证方法，以评估预-trained AI模型的可行性，而无需大量额外数据。该方法通过整合领域知识（如物理理论和分析模型）与数据驱动AI模型，解决AI黑箱问题的解释性和可信度问题，并在交通状态估计等安全关键场景中进行验证。实验结果显示，该方法能有效量化预-trained模型的物理不一致性，提供决策者对AI模型可靠性和安全性的信心，从而推进AI在动态不确定环境中的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 Pages, 5 figures, \\c{opyright}2024 IEEE INTERNATIONAL CONFERENCE on\n  ELECTRO/INFORMATION TECHNOLOGY",
      "pdf_url": "http://arxiv.org/pdf/2405.07893v1",
      "published_date": "2024-05-13 16:28:00 UTC",
      "updated_date": "2024-05-13 16:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:03:44.238827"
    },
    {
      "arxiv_id": "2405.07863v3",
      "title": "RLHF Workflow: From Reward Modeling to Online RLHF",
      "title_zh": "RLHF 工作流：从奖励建模到在线 RLHF",
      "authors": [
        "Hanze Dong",
        "Wei Xiong",
        "Bo Pang",
        "Haoxiang Wang",
        "Han Zhao",
        "Yingbo Zhou",
        "Nan Jiang",
        "Doyen Sahoo",
        "Caiming Xiong",
        "Tong Zhang"
      ],
      "abstract": "We present the workflow of Online Iterative Reinforcement Learning from Human\nFeedback (RLHF) in this technical report, which is widely reported to\noutperform its offline counterpart by a large margin in the recent large\nlanguage model (LLM) literature. However, existing open-source RLHF projects\nare still largely confined to the offline learning setting. In this technical\nreport, we aim to fill in this gap and provide a detailed recipe that is easy\nto reproduce for online iterative RLHF. In particular, since online human\nfeedback is usually infeasible for open-source communities with limited\nresources, we start by constructing preference models using a diverse set of\nopen-source datasets and use the constructed proxy preference model to\napproximate human feedback. Then, we discuss the theoretical insights and\nalgorithmic principles behind online iterative RLHF, followed by a detailed\npractical implementation. Our trained LLM achieves impressive performance on\nLLM chatbot benchmarks, including AlpacaEval-2, Arena-Hard, and MT-Bench, as\nwell as other academic benchmarks such as HumanEval and TruthfulQA. We have\nshown that supervised fine-tuning (SFT) and iterative RLHF can obtain\nstate-of-the-art performance with fully open-source datasets. Further, we have\nmade our models, curated datasets, and comprehensive step-by-step code\nguidebooks publicly available. Please refer to\nhttps://github.com/RLHFlow/RLHF-Reward-Modeling and\nhttps://github.com/RLHFlow/Online-RLHF for more detailed information.",
      "tldr_zh": "本研究介绍了 Online Iterative Reinforcement Learning from Human Feedback (RLHF) 的工作流程，旨在填补现有开源项目中在线 RLHF 的空白，并展示其在大型语言模型(LLM)领域的显著性能优势。研究首先使用开源数据集构建代理偏好模型来模拟人类反馈，然后结合理论洞见和算法原则，详细实现了在线迭代 RLHF 的实践步骤。实验结果显示，训练的LLM在AlpacaEval-2、Arena-Hard、MT-Bench、HumanEval和TruthfulQA等基准上表现出色，证明Supervised Fine-Tuning (SFT)与迭代RLHF能使用完全开源数据集达到最先进水平。该研究已公开模型、数据集和详细代码指南，供社区复现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in Transactions on Machine Learning Research (09/2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.07863v3",
      "published_date": "2024-05-13 15:50:39 UTC",
      "updated_date": "2024-11-12 11:18:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:03:56.192798"
    },
    {
      "arxiv_id": "2405.07857v3",
      "title": "Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyu Kim",
        "Jun-Seong Kim",
        "Se-Young Yun",
        "Jin-Hwa Kim"
      ],
      "abstract": "The multi-plane representation has been highlighted for its fast training and\ninference across static and dynamic neural radiance fields. This approach\nconstructs relevant features via projection onto learnable grids and\ninterpolating adjacent vertices. However, it has limitations in capturing\nlow-frequency details and tends to overuse parameters for low-frequency\nfeatures due to its bias toward fine details, despite its multi-resolution\nconcept. This phenomenon leads to instability and inefficiency when training\nposes are sparse. In this work, we propose a method that synergistically\nintegrates multi-plane representation with a coordinate-based MLP network known\nfor strong bias toward low-frequency signals. The coordinate-based network is\nresponsible for capturing low-frequency details, while the multi-plane\nrepresentation focuses on capturing fine-grained details. We demonstrate that\nusing residual connections between them seamlessly preserves their own inherent\nproperties. Additionally, the proposed progressive training scheme accelerates\nthe disentanglement of these two features. We demonstrate empirically that our\nproposed method not only outperforms baseline models for both static and\ndynamic NeRFs with sparse inputs, but also achieves comparable results with\nfewer parameters.",
      "tldr_zh": "这篇论文针对Neural Radiance Fields (NeRFs) 在稀疏输入下的问题，提出了一种协同整合multi-plane representation和coordinate-based MLP网络的方法，以改善低频细节捕捉和参数效率。coordinate-based MLP网络负责处理低频信号，而multi-plane representation专注于细粒度细节，通过residual connections保留各自特性，并采用progressive training scheme加速特征分离。实验结果表明，该方法在静态和动态NeRFs上优于基线模型，同时使用更少的参数。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML2024 ; Project page is accessible at\n  https://mingyukim87.github.io/SynergyNeRF ; Code is available at\n  https://github.com/MingyuKim87/SynergyNeRF",
      "pdf_url": "http://arxiv.org/pdf/2405.07857v3",
      "published_date": "2024-05-13 15:42:46 UTC",
      "updated_date": "2024-06-05 09:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:04:08.323823"
    },
    {
      "arxiv_id": "2405.07839v2",
      "title": "Constrained Exploration via Reflected Replica Exchange Stochastic Gradient Langevin Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyang Zheng",
        "Hengrong Du",
        "Qi Feng",
        "Wei Deng",
        "Guang Lin"
      ],
      "abstract": "Replica exchange stochastic gradient Langevin dynamics (reSGLD) is an\neffective sampler for non-convex learning in large-scale datasets. However, the\nsimulation may encounter stagnation issues when the high-temperature chain\ndelves too deeply into the distribution tails. To tackle this issue, we propose\nreflected reSGLD (r2SGLD): an algorithm tailored for constrained non-convex\nexploration by utilizing reflection steps within a bounded domain.\nTheoretically, we observe that reducing the diameter of the domain enhances\nmixing rates, exhibiting a $\\textit{quadratic}$ behavior. Empirically, we test\nits performance through extensive experiments, including identifying dynamical\nsystems with physical constraints, simulations of constrained multi-modal\ndistributions, and image classification tasks. The theoretical and empirical\nfindings highlight the crucial role of constrained exploration in improving the\nsimulation efficiency.",
      "tldr_zh": "这篇论文提出了 reflected reSGLD (r2SGLD) 算法，用于解决 replica exchange stochastic gradient Langevin dynamics (reSGLD) 在大规模数据集非凸学习中的模拟停滞问题，通过在边界域内引入反射步骤实现约束探索。理论分析显示，缩小域直径可以以 quadratic 方式提升混合率，从而改善采样效率。实验验证包括动态系统识别、受约束多模态分布模拟和图像分类任务，结果证明 r2SGLD 显著提高了模拟性能，并强调了约束探索在非凸优化中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07839v2",
      "published_date": "2024-05-13 15:25:03 UTC",
      "updated_date": "2024-06-03 13:48:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:04:20.926837"
    },
    {
      "arxiv_id": "2405.07838v2",
      "title": "Adaptive Exploration for Data-Efficient General Value Function Evaluations",
      "title_zh": "翻译失败",
      "authors": [
        "Arushi Jain",
        "Josiah P. Hanna",
        "Doina Precup"
      ],
      "abstract": "General Value Functions (GVFs) (Sutton et al., 2011) represent predictive\nknowledge in reinforcement learning. Each GVF computes the expected return for\na given policy, based on a unique reward. Existing methods relying on fixed\nbehavior policies or pre-collected data often face data efficiency issues when\nlearning multiple GVFs in parallel using off-policy methods. To address this,\nwe introduce GVFExplorer, which adaptively learns a single behavior policy that\nefficiently collects data for evaluating multiple GVFs in parallel. Our method\noptimizes the behavior policy by minimizing the total variance in return across\nGVFs, thereby reducing the required environmental interactions. We use an\nexisting temporal-difference-style variance estimator to approximate the return\nvariance. We prove that each behavior policy update decreases the overall mean\nsquared error in GVF predictions. We empirically show our method's performance\nin tabular and nonlinear function approximation settings, including Mujoco\nenvironments, with stationary and non-stationary reward signals, optimizing\ndata usage and reducing prediction errors across multiple GVFs.",
      "tldr_zh": "该论文针对强化学习中的 General Value Functions (GVFs) 提出了一种数据高效的评估方法，以解决现有依赖固定行为策略或预收集数据的 off-policy 方法在并行学习多个 GVFs 时的数据效率问题。研究引入 GVFExplorer，通过自适应学习单一行为策略并最小化 GVFs 的总回报方差来优化数据收集过程，利用时序差分风格的方差估计器进行近似。实验证明，每次行为策略更新都能减少 GVF 预测的整体均方误差，并在表格、非线性函数逼近以及 Mujoco 环境中验证了该方法的有效性，提高了数据使用效率并降低了预测错误。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 16 figures, Accepted in NeurIPS 2024 Conference",
      "pdf_url": "http://arxiv.org/pdf/2405.07838v2",
      "published_date": "2024-05-13 15:24:27 UTC",
      "updated_date": "2024-10-13 15:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:04:33.672736"
    },
    {
      "arxiv_id": "2405.07827v1",
      "title": "Automatic Recognition of Food Ingestion Environment from the AIM-2 Wearable Sensor",
      "title_zh": "翻译失败",
      "authors": [
        "Yuning Huang",
        "Mohamed Abul Hassan",
        "Jiangpeng He",
        "Janine Higgins",
        "Megan McCrory",
        "Heather Eicher-Miller",
        "Graham Thomas",
        "Edward O Sazonov",
        "Fengqing Maggie Zhu"
      ],
      "abstract": "Detecting an ingestion environment is an important aspect of monitoring\ndietary intake. It provides insightful information for dietary assessment.\nHowever, it is a challenging problem where human-based reviewing can be\ntedious, and algorithm-based review suffers from data imbalance and perceptual\naliasing problems. To address these issues, we propose a neural network-based\nmethod with a two-stage training framework that tactfully combines fine-tuning\nand transfer learning techniques. Our method is evaluated on a newly collected\ndataset called ``UA Free Living Study\", which uses an egocentric wearable\ncamera, AIM-2 sensor, to simulate food consumption in free-living conditions.\nThe proposed training framework is applied to common neural network backbones,\ncombined with approaches in the general imbalanced classification field.\nExperimental results on the collected dataset show that our proposed method for\nautomatic ingestion environment recognition successfully addresses the\nchallenging data imbalance problem in the dataset and achieves a promising\noverall classification accuracy of 96.63%.",
      "tldr_zh": "这篇论文提出了一种基于神经网络的方法，用于从 AIM-2 可穿戴传感器自动识别摄食环境，以解决数据不平衡和感知混淆等问题。该方法采用两阶段训练框架，结合 fine-tuning 和 transfer learning 技术，应用于新收集的 UA Free Living Study 数据集，该数据集使用第一人称可穿戴相机模拟自由生活条件下食物消耗。实验结果显示，该方法成功处理了数据不平衡挑战，并实现了 96.63% 的整体分类准确率，为饮食评估提供更高效的见解。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "Accepted at CVPRw 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.07827v1",
      "published_date": "2024-05-13 15:12:21 UTC",
      "updated_date": "2024-05-13 15:12:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:04:44.647708"
    },
    {
      "arxiv_id": "2405.07822v2",
      "title": "Synthetic Tabular Data Validation: A Divergence-Based Approach",
      "title_zh": "合成表格数据验证：一种基于散度的方法",
      "authors": [
        "Patricia A. Apellániz",
        "Ana Jiménez",
        "Borja Arroyo Galende",
        "Juan Parras",
        "Santiago Zazo"
      ],
      "abstract": "The ever-increasing use of generative models in various fields where tabular\ndata is used highlights the need for robust and standardized validation metrics\nto assess the similarity between real and synthetic data. Current methods lack\na unified framework and rely on diverse and often inconclusive statistical\nmeasures. Divergences, which quantify discrepancies between data distributions,\noffer a promising avenue for validation. However, traditional approaches\ncalculate divergences independently for each feature due to the complexity of\njoint distribution modeling. This paper addresses this challenge by proposing a\nnovel approach that uses divergence estimation to overcome the limitations of\nmarginal comparisons. Our core contribution lies in applying a divergence\nestimator to build a validation metric considering the joint distribution of\nreal and synthetic data. We leverage a probabilistic classifier to approximate\nthe density ratio between datasets, allowing the capture of complex\nrelationships. We specifically calculate two divergences: the well-known\nKullback-Leibler (KL) divergence and the Jensen-Shannon (JS) divergence. KL\ndivergence offers an established use in the field, while JS divergence is\nsymmetric and bounded, providing a reliable metric. The efficacy of this\napproach is demonstrated through a series of experiments with varying\ndistribution complexities. The initial phase involves comparing estimated\ndivergences with analytical solutions for simple distributions, setting a\nbenchmark for accuracy. Finally, we validate our method on a real-world dataset\nand its corresponding synthetic counterpart, showcasing its effectiveness in\npractical applications. This research offers a significant contribution with\napplicability beyond tabular data and the potential to improve synthetic data\nvalidation in various fields.",
      "tldr_zh": "该论文针对合成表格数据的验证问题，提出了一种基于散度估计的新方法，以克服现有方法仅依赖边缘比较而忽略联合分布的局限性。该方法利用概率分类器近似密度比，计算Kullback-Leibler (KL) divergence和Jensen-Shannon (JS) divergence，从而全面评估真实数据和合成数据的相似性。通过实验验证，该方法在简单分布和真实世界数据集上表现出色，与分析解相比准确性高，并展示了其在各种领域的潜在应用。总的来说，此研究为合成数据验证提供了统一的框架，提升了可靠性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07822v2",
      "published_date": "2024-05-13 15:07:52 UTC",
      "updated_date": "2024-07-31 10:00:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:04:55.487890"
    },
    {
      "arxiv_id": "2405.07817v1",
      "title": "The Power of Combined Modalities in Interactive Robot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Helen Beierling",
        "Anna-Lisa Vollmer"
      ],
      "abstract": "This study contributes to the evolving field of robot learning in interaction\nwith humans, examining the impact of diverse input modalities on learning\noutcomes. It introduces the concept of \"meta-modalities\" which encapsulate\nadditional forms of feedback beyond the traditional preference and scalar\nfeedback mechanisms. Unlike prior research that focused on individual\nmeta-modalities, this work evaluates their combined effect on learning\noutcomes. Through a study with human participants, we explore user preferences\nfor these modalities and their impact on robot learning performance. Our\nfindings reveal that while individual modalities are perceived differently,\ntheir combination significantly improves learning behavior and usability. This\nresearch not only provides valuable insights into the optimization of\nhuman-robot interactive task learning but also opens new avenues for enhancing\nthe interactive freedom and scaffolding capabilities provided to users in such\nsettings.",
      "tldr_zh": "本文研究了人类与机器人互动学习中不同输入模式对学习结果的影响，引入了“meta-modalities”概念，该概念扩展了传统偏好和标量反馈以外的额外反馈形式。不同于以往专注于单个“meta-modalities”的研究，本文通过人类参与者实验评估了这些模式的组合效果。结果表明，虽然个体模式被用户感知不同，但其结合显著提高了机器人学习行为和可用性。该研究为优化人类-机器人互动任务学习提供了宝贵洞见，并拓展了互动自由和支架能力的可能性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07817v1",
      "published_date": "2024-05-13 14:59:44 UTC",
      "updated_date": "2024-05-13 14:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:05:07.864689"
    },
    {
      "arxiv_id": "2405.07816v1",
      "title": "Quick and Accurate Affordance Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Fedor Scholz",
        "Erik Ayari",
        "Johannes Bertram",
        "Martin V. Butz"
      ],
      "abstract": "Infants learn actively in their environments, shaping their own learning\ncurricula. They learn about their environments' affordances, that is, how local\ncircumstances determine how their behavior can affect the environment. Here we\nmodel this type of behavior by means of a deep learning architecture. The\narchitecture mediates between global cognitive map exploration and local\naffordance learning. Inference processes actively move the simulated agent\ntowards regions where they expect affordance-related knowledge gain. We\ncontrast three measures of uncertainty to guide this exploration: predicted\nuncertainty of a model, standard deviation between the means of several models\n(SD), and the Jensen-Shannon Divergence (JSD) between several models. We show\nthat the first measure gets fooled by aleatoric uncertainty inherent in the\nenvironment, while the two other measures focus learning on epistemic\nuncertainty. JSD exhibits the most balanced exploration strategy. From a\ncomputational perspective, our model suggests three key ingredients for\ncoordinating the active generation of learning curricula: (1) Navigation\nbehavior needs to be coordinated with local motor behavior for enabling active\naffordance learning. (2) Affordances need to be encoded locally for acquiring\ngeneralized knowledge. (3) Effective active affordance learning mechanisms\nshould use density comparison techniques for estimating expected knowledge\ngain. Future work may seek collaborations with developmental psychology to\nmodel active play in children in more realistic scenarios.",
      "tldr_zh": "本研究提出一个深度学习架构，模拟代理主动学习环境的 affordance（即本地环境如何影响行为），通过协调全局认知地图探索和本地 affordance 学习来生成主动学习课程。模型使用三种不确定性措施（预测不确定性、多个模型均值之间的标准差（SD）和 Jensen-Shannon Divergence（JSD））指导代理向预期知识增益区域移动，结果显示 JSD 提供最平衡的探索策略，能有效聚焦于 epistemic 不确定性而非环境的 aleatoric 不确定性。该框架强调三个关键成分：协调导航与本地运动行为、局部编码 affordances 以实现知识泛化，以及使用密度比较技术估计预期知识增益，为未来与发展心理学合作模拟儿童主动游戏提供基础。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07816v1",
      "published_date": "2024-05-13 14:58:57 UTC",
      "updated_date": "2024-05-13 14:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:05:21.471951"
    },
    {
      "arxiv_id": "2405.08045v1",
      "title": "Comparative analysis of neural network architectures for short-term FOREX forecasting",
      "title_zh": "短期 FOREX 预测的神经网络架构比较分析",
      "authors": [
        "Theodoros Zafeiriou",
        "Dimitris Kalles"
      ],
      "abstract": "The present document delineates the analysis, design, implementation, and\nbenchmarking of various neural network architectures within a short-term\nfrequency prediction system for the foreign exchange market (FOREX). Our aim is\nto simulate the judgment of the human expert (technical analyst) using a system\nthat responds promptly to changes in market conditions, thus enabling the\noptimization of short-term trading strategies. We designed and implemented a\nseries of LSTM neural network architectures which are taken as input the\nexchange rate values and generate the short-term market trend forecasting\nsignal and an ANN custom architecture based on technical analysis indicator\nsimulators We performed a comparative analysis of the results and came to\nuseful conclusions regarding the suitability of each architecture and the cost\nin terms of time and computational power to implement them. The ANN custom\narchitecture produces better prediction quality with higher sensitivity using\nfewer resources and spending less time than LSTM architectures. The ANN custom\narchitecture appears to be ideal for use in low-power computing systems and for\nuse cases that need fast decisions with the least possible computational cost.",
      "tldr_zh": "本文对各种神经网络架构在外汇市场（FOREX）短期预测中的性能进行了比较分析，旨在模拟人类技术分析师的判断并优化短期交易策略。研究设计并实施了多种 LSTM 架构（输入汇率值、输出市场趋势预测信号）和基于技术分析指标的 ANN 自定义架构。结果表明，ANN 自定义架构在预测质量和敏感性方面优于 LSTM 架构，同时需要更少的计算资源和时间。总之，该架构特别适合低功率计算系统和快速决策场景。",
      "categories": [
        "q-fin.MF",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "q-fin.MF",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08045v1",
      "published_date": "2024-05-13 14:51:02 UTC",
      "updated_date": "2024-05-13 14:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:05:34.541629"
    },
    {
      "arxiv_id": "2405.07798v2",
      "title": "FreeVA: Offline MLLM as Training-Free Video Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Wu"
      ],
      "abstract": "This paper undertakes an empirical study to revisit the latest advancements\nin Multimodal Large Language Models (MLLMs): Video Assistant. This study,\nnamely FreeVA, aims to extend existing image-based MLLM to the video domain in\na training-free manner. The study provides an essential, yet must-know\nbaseline, and reveals several surprising findings: 1) FreeVA, leveraging only\noffline image-based MLLM without additional training, excels in zero-shot video\nquestion-answering (e.g., MSVD-QA, ActivityNet-QA, and MSRVTT-QA), even\nsurpassing state-of-the-art methods that involve video instruction tuning. 2)\nWhile mainstream video-based MLLMs typically initialize with an image-based\nMLLM (e.g., LLaVA) and then fine-tune using video instruction tuning, the study\nindicates that utilizing the widely adopted VideoInstruct-100K for video\ninstruction tuning doesn't actually lead to better performance compared to not\ntraining at all. 3) The commonly used evaluation metrics in existing works are\nsignificantly influenced by changes in the GPT API version over time. If\nignored, this could affect the fairness and uniformity of comparisons between\ndifferent methods and impact the analysis and judgment of researchers in the\nfield. The advancement of MLLMs is currently thriving, drawing numerous\nresearchers into the field. We aim for this work to serve as a plug-and-play,\nsimple yet effective baseline, encouraging the direct evaluation of existing\nMLLMs in video domain while also standardizing the field of video\nconversational models to a certain extent. Also, we encourage researchers to\nreconsider: Have current video MLLM methods truly acquired knowledge beyond\nimage MLLM? Code is available at https://github.com/whwu95/FreeVA",
      "tldr_zh": "本论文提出 FreeVA，一种无需额外训练的框架，将图像-based Multimodal Large Language Models (MLLMs) 扩展到视频领域，作为一个训练-free 的视频助手基线。研究发现，FreeVA 在零-shot 视频问答任务（如 MSVD-QA、ActivityNet-QA 和 MSRVTT-QA）上表现出色，甚至超越了涉及 VideoInstruct-100K 视频指令微调的 SOTA 方法。令人惊讶的是，主流视频-based MLLMs 通过微调图像 MLLM（如 LLaVA）并不会带来性能提升，与不训练相比效果类似。论文还强调，现有评估指标易受 GPT API 版本变化影响，可能导致研究比较不公平，并呼吁标准化视频对话模型领域，提供代码以鼓励直接评估现有 MLLM。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2405.07798v2",
      "published_date": "2024-05-13 14:42:13 UTC",
      "updated_date": "2024-06-10 13:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:05:48.545523"
    },
    {
      "arxiv_id": "2405.07780v1",
      "title": "Harnessing Hierarchical Label Distribution Variations in Test Agnostic Long-tail Recognition",
      "title_zh": "在测试无关长尾识别中利用层次标签分布变化",
      "authors": [
        "Zhiyong Yang",
        "Qianqian Xu",
        "Zitai Wang",
        "Sicong Li",
        "Boyu Han",
        "Shilong Bao",
        "Xiaochun Cao",
        "Qingming Huang"
      ],
      "abstract": "This paper explores test-agnostic long-tail recognition, a challenging\nlong-tail task where the test label distributions are unknown and arbitrarily\nimbalanced. We argue that the variation in these distributions can be broken\ndown hierarchically into global and local levels. The global ones reflect a\nbroad range of diversity, while the local ones typically arise from milder\nchanges, often focused on a particular neighbor. Traditional methods\npredominantly use a Mixture-of-Expert (MoE) approach, targeting a few fixed\ntest label distributions that exhibit substantial global variations. However,\nthe local variations are left unconsidered. To address this issue, we propose a\nnew MoE strategy, $\\mathsf{DirMixE}$, which assigns experts to different\nDirichlet meta-distributions of the label distribution, each targeting a\nspecific aspect of local variations. Additionally, the diversity among these\nDirichlet meta-distributions inherently captures global variations. This\ndual-level approach also leads to a more stable objective function, allowing us\nto sample different test distributions better to quantify the mean and variance\nof performance outcomes. Theoretically, we show that our proposed objective\nbenefits from enhanced generalization by virtue of the variance-based\nregularization. Comprehensive experiments across multiple benchmarks confirm\nthe effectiveness of $\\mathsf{DirMixE}$. The code is available at\n\\url{https://github.com/scongl/DirMixE}.",
      "tldr_zh": "这篇论文探讨了测试无关的长尾识别（test-agnostic long-tail recognition）问题，其中测试标签分布未知且任意不平衡，并将这些分布的变化分解为全局和局部层次。作者提出了一种新颖的Mixture-of-Expert (MoE)策略，$\\mathsf{DirMixE}$，通过将专家分配到不同的Dirichlet meta-distributions来针对局部变化，同时利用这些分布的多样性捕捉全局变化，从而实现更稳定的目标函数和更好的性能量化。实验结果在多个基准上证实了$\\mathsf{DirMixE}$的有效性，并理论证明了其基于方差的正则化提高了模型的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07780v1",
      "published_date": "2024-05-13 14:24:56 UTC",
      "updated_date": "2024-05-13 14:24:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:05:59.365815"
    },
    {
      "arxiv_id": "2405.07778v1",
      "title": "A Comprehensive Analysis of Static Word Embeddings for Turkish",
      "title_zh": "针对土耳其语的静态词嵌入全面分析",
      "authors": [
        "Karahan Sarıtaş",
        "Cahid Arda Öz",
        "Tunga Güngör"
      ],
      "abstract": "Word embeddings are fixed-length, dense and distributed word representations\nthat are used in natural language processing (NLP) applications. There are\nbasically two types of word embedding models which are non-contextual (static)\nmodels and contextual models. The former method generates a single embedding\nfor a word regardless of its context, while the latter method produces distinct\nembeddings for a word based on the specific contexts in which it appears. There\nare plenty of works that compare contextual and non-contextual embedding models\nwithin their respective groups in different languages. However, the number of\nstudies that compare the models in these two groups with each other is very few\nand there is no such study in Turkish. This process necessitates converting\ncontextual embeddings into static embeddings. In this paper, we compare and\nevaluate the performance of several contextual and non-contextual models in\nboth intrinsic and extrinsic evaluation settings for Turkish. We make a\nfine-grained comparison by analyzing the syntactic and semantic capabilities of\nthe models separately. The results of the analyses provide insights about the\nsuitability of different embedding models in different types of NLP tasks. We\nalso build a Turkish word embedding repository comprising the embedding models\nused in this work, which may serve as a valuable resource for researchers and\npractitioners in the field of Turkish NLP. We make the word embeddings,\nscripts, and evaluation datasets publicly available.",
      "tldr_zh": "这篇论文对土耳其语的静态词嵌入（static word embeddings）进行了全面分析，比较了非上下文（non-contextual）和上下文（contextual）模型的表现，填补了该语言中跨组模型比较的空白。研究方法包括将上下文嵌入转换为静态嵌入，并通过内在和外在评估设置，细致分析模型的句法和语义能力。结果显示，不同嵌入模型适用于各种NLP任务，并提供了宝贵见解；此外，论文构建了一个土耳其语词嵌入仓库，并公开了词嵌入、脚本和评估数据集，以支持未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07778v1",
      "published_date": "2024-05-13 14:23:37 UTC",
      "updated_date": "2024-05-13 14:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:06:09.102544"
    },
    {
      "arxiv_id": "2405.07773v2",
      "title": "Human-Modeling in Sequential Decision-Making: An Analysis through the Lens of Human-Aware AI",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia Tulli",
        "Stylianos Loukas Vasileiou",
        "Sarath Sreedharan"
      ],
      "abstract": "\"Human-aware\" has become a popular keyword used to describe a particular\nclass of AI systems that are designed to work and interact with humans. While\nthere exists a surprising level of consistency among the works that use the\nlabel human-aware, the term itself mostly remains poorly understood. In this\nwork, we retroactively try to provide an account of what constitutes a\nhuman-aware AI system. We see that human-aware AI is a design oriented\nparadigm, one that focuses on the need for modeling the humans it may interact\nwith. Additionally, we see that this paradigm offers us intuitive dimensions to\nunderstand and categorize the kinds of interactions these systems might have\nwith humans. We show the pedagogical value of these dimensions by using them as\na tool to understand and review the current landscape of work related to\nhuman-AI systems that purport some form of human modeling. To fit the scope of\na workshop paper, we specifically narrowed our review to papers that deal with\nsequential decision-making and were published in a major AI conference in the\nlast three years. Our analysis helps identify the space of potential research\nproblems that are currently being overlooked. We perform additional analysis on\nthe degree to which these works make explicit reference to results from social\nscience and whether they actually perform user-studies to validate their\nsystems. We also provide an accounting of the various AI methods used by these\nworks.",
      "tldr_zh": "这篇论文分析了Human-Aware AI的概念，强调它是一种设计导向范式，需要通过建模人类行为来优化AI系统与人类的互动。作者提出了直观的维度框架，用于理解和分类这些互动，并以此审阅了过去三年主要AI会议中关于Sequential Decision-Making的论文。研究发现，许多论文忽略了潜在的研究问题，且较少引用社会科学成果或进行用户研究，同时总结了这些论文中使用的各种AI方法。该工作为Human-Aware AI的未来发展提供了宝贵的分类工具和研究空白识别。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2405.07773v2",
      "published_date": "2024-05-13 14:17:52 UTC",
      "updated_date": "2024-07-15 15:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:06:22.257787"
    },
    {
      "arxiv_id": "2405.07767v1",
      "title": "Synthetic Test Collections for Retrieval Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein A. Rahmani",
        "Nick Craswell",
        "Emine Yilmaz",
        "Bhaskar Mitra",
        "Daniel Campos"
      ],
      "abstract": "Test collections play a vital role in evaluation of information retrieval\n(IR) systems. Obtaining a diverse set of user queries for test collection\nconstruction can be challenging, and acquiring relevance judgments, which\nindicate the appropriateness of retrieved documents to a query, is often costly\nand resource-intensive. Generating synthetic datasets using Large Language\nModels (LLMs) has recently gained significant attention in various\napplications. In IR, while previous work exploited the capabilities of LLMs to\ngenerate synthetic queries or documents to augment training data and improve\nthe performance of ranking models, using LLMs for constructing synthetic test\ncollections is relatively unexplored. Previous studies demonstrate that LLMs\nhave the potential to generate synthetic relevance judgments for use in the\nevaluation of IR systems. In this paper, we comprehensively investigate whether\nit is possible to use LLMs to construct fully synthetic test collections by\ngenerating not only synthetic judgments but also synthetic queries. In\nparticular, we analyse whether it is possible to construct reliable synthetic\ntest collections and the potential risks of bias such test collections may\nexhibit towards LLM-based models. Our experiments indicate that using LLMs it\nis possible to construct synthetic test collections that can reliably be used\nfor retrieval evaluation.",
      "tldr_zh": "这篇论文探讨了使用大语言模型（LLMs）生成合成测试集合，以解决信息检索（IR）系统评估中查询获取和相关性判断的资源挑战。研究方法包括利用 LLMs 不仅生成合成相关性判断，还创建合成查询，从而构建完整的合成测试集合，并分析这些集合可能存在的偏见风险，特别是对 LLM 基于模型的偏好。实验结果显示，生成的合成测试集合可靠，可有效用于 IR 系统的评估，提供了一种高效替代传统方法的途径。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "SIGIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.07767v1",
      "published_date": "2024-05-13 14:11:09 UTC",
      "updated_date": "2024-05-13 14:11:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:06:33.123197"
    },
    {
      "arxiv_id": "2405.07766v1",
      "title": "Challenges and Opportunities of NLP for HR Applications: A Discussion Paper",
      "title_zh": "翻译失败",
      "authors": [
        "Jochen L. Leidner",
        "Mark Stevenson"
      ],
      "abstract": "Over the course of the recent decade, tremendous progress has been made in\nthe areas of machine learning and natural language processing, which opened up\nvast areas of potential application use cases, including hiring and human\nresource management. We review the use cases for text analytics in the realm of\nhuman resources/personnel management, including actually realized as well as\npotential but not yet implemented ones, and we analyze the opportunities and\nrisks of these.",
      "tldr_zh": "这篇讨论纸探讨了自然语言处理（NLP）在人力资源（HR）应用中的挑战和机会，回顾了过去十年机器学习和 NLP 的快速发展及其在招聘和人员管理中的潜在用例。论文审视了已实现和尚未实施的文本分析应用，包括实际案例和未来可能性，并分析了这些应用的机遇，如提高效率，以及风险，如隐私和偏见问题。通过这一分析，论文为 NLP 在 HR 领域的安全有效应用提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.2.1"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2405.07766v1",
      "published_date": "2024-05-13 14:09:06 UTC",
      "updated_date": "2024-05-13 14:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:06:46.126991"
    },
    {
      "arxiv_id": "2405.07761v2",
      "title": "LLM4ED: Large Language Models for Automatic Equation Discovery",
      "title_zh": "LL",
      "authors": [
        "Mengge Du",
        "Yuntian Chen",
        "Zhongzheng Wang",
        "Longfeng Nie",
        "Dongxiao Zhang"
      ],
      "abstract": "Equation discovery is aimed at directly extracting physical laws from data\nand has emerged as a pivotal research domain. Previous methods based on\nsymbolic mathematics have achieved substantial advancements, but often require\nthe design of implementation of complex algorithms. In this paper, we introduce\na new framework that utilizes natural language-based prompts to guide large\nlanguage models (LLMs) in automatically mining governing equations from data.\nSpecifically, we first utilize the generation capability of LLMs to generate\ndiverse equations in string form, and then evaluate the generated equations\nbased on observations. In the optimization phase, we propose two alternately\niterated strategies to optimize generated equations collaboratively. The first\nstrategy is to take LLMs as a black-box optimizer and achieve equation\nself-improvement based on historical samples and their performance. The second\nstrategy is to instruct LLMs to perform evolutionary operators for global\nsearch. Experiments are extensively conducted on both partial differential\nequations and ordinary differential equations. Results demonstrate that our\nframework can discover effective equations to reveal the underlying physical\nlaws under various nonlinear dynamic systems. Further comparisons are made with\nstate-of-the-art models, demonstrating good stability and usability. Our\nframework substantially lowers the barriers to learning and applying equation\ndiscovery techniques, demonstrating the application potential of LLMs in the\nfield of knowledge discovery.",
      "tldr_zh": "本文提出 LLM4ED 框架，利用 Large Language Models (LLMs) 通过自然语言提示自动从数据中发现方程，解决了传统符号数学方法依赖复杂算法的局限。框架的核心方法包括 LLMs 生成多样方程字符串、基于观察进行评估，以及两种交替优化策略：将 LLMs 作为黑箱优化器利用历史样本自我改进，以及指导 LLMs 执行进化运算符进行全局搜索。实验在 partial differential equations 和 ordinary differential equations 上表明，该框架能有效揭示各种非线性动态系统的底层物理定律，并与最先进模型相比显示出更好的稳定性和可用性。该框架显著降低了方程发现技术的学习和应用门槛，展示了 LLMs 在知识发现领域的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC",
        "math-ph",
        "math.MP",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07761v2",
      "published_date": "2024-05-13 14:03:49 UTC",
      "updated_date": "2024-07-22 07:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:06:59.344951"
    },
    {
      "arxiv_id": "2405.07759v2",
      "title": "MADRL-Based Rate Adaptation for 360° Video Streaming with Multi-Viewpoint Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Haopeng Wang",
        "Zijian Long",
        "Haiwei Dong",
        "Abdulmotaleb El Saddik"
      ],
      "abstract": "Over the last few years, 360{\\deg} video traffic on the network has grown\nsignificantly. A key challenge of 360{\\deg} video playback is ensuring a high\nquality of experience (QoE) with limited network bandwidth. Currently, most\nstudies focus on tile-based adaptive bitrate (ABR) streaming based on single\nviewport prediction to reduce bandwidth consumption. However, the performance\nof models for single-viewpoint prediction is severely limited by the inherent\nuncertainty in head movement, which can not cope with the sudden movement of\nusers very well. This paper first presents a multimodal spatial-temporal\nattention transformer to generate multiple viewpoint trajectories with their\nprobabilities given a historical trajectory. The proposed method models\nviewpoint prediction as a classification problem and uses attention mechanisms\nto capture the spatial and temporal characteristics of input video frames and\nviewpoint trajectories for multi-viewpoint prediction. After that, a\nmulti-agent deep reinforcement learning (MADRL)-based ABR algorithm utilizing\nmulti-viewpoint prediction for 360{\\deg} video streaming is proposed for\nmaximizing different QoE objectives under various network conditions. We\nformulate the ABR problem as a decentralized partially observable Markov\ndecision process (Dec-POMDP) problem and present a MAPPO algorithm based on\ncentralized training and decentralized execution (CTDE) framework to solve the\nproblem. The experimental results show that our proposed method improves the\ndefined QoE metric by up to 85.5% compared to existing ABR methods.",
      "tldr_zh": "本研究针对 360° 视频流媒体的带宽限制和高质量体验 (QoE) 挑战，提出了一种基于多视点预测的速率自适应方法。首先，引入多模态空间-时间注意力 Transformer 模型，将视点预测视为分类问题，通过注意力机制捕捉视频帧和轨迹的空间-时间特征，从而生成多个视点轨迹及其概率。接着，采用多智能体深度强化学习 (MADRL) 的自适应比特率 (ABR) 算法，将问题建模为去中心化部分可观测 Markov 决策过程 (Dec-POMDP)，并使用基于集中训练和去中心化执行 (CTDE) 的 MAPPO 算法优化 QoE 目标。实验结果显示，该方法相较现有 ABR 方法，可将 QoE 指标提高高达 85.5%。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.NI",
        "eess.IV"
      ],
      "primary_category": "cs.MM",
      "comment": "Accepted by IEEE Internet of Things Journal",
      "pdf_url": "http://arxiv.org/pdf/2405.07759v2",
      "published_date": "2024-05-13 13:59:59 UTC",
      "updated_date": "2024-05-17 23:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:07:10.304586"
    },
    {
      "arxiv_id": "2405.08044v3",
      "title": "On the Volatility of Shapley-Based Contribution Metrics in Federated Learning",
      "title_zh": "关于联邦学习中基于Shapley的贡献指标波动性",
      "authors": [
        "Arno Geimer",
        "Beltran Fiz",
        "Radu State"
      ],
      "abstract": "Federated learning (FL) is a collaborative and privacy-preserving Machine\nLearning paradigm, allowing the development of robust models without the need\nto centralize sensitive data. A critical challenge in FL lies in fairly and\naccurately allocating contributions from diverse participants. Inaccurate\nallocation can undermine trust, lead to unfair compensation, and thus\nparticipants may lack the incentive to join or actively contribute to the\nfederation. Various remuneration strategies have been proposed to date,\nincluding auction-based approaches and Shapley-value-based methods, the latter\noffering a means to quantify the contribution of each participant. However,\nlittle to no work has studied the stability of these contribution evaluation\nmethods. In this paper, we evaluate participant contributions in federated\nlearning using gradient-based model reconstruction techniques with Shapley\nvalues and compare the round-based contributions to a classic data contribution\nmeasurement scheme. We provide an extensive analysis of the discrepancies of\nShapley values across a set of aggregation strategies, and examine them on an\noverall and a per-client level. We show that, between different aggregation\ntechniques, Shapley values lead to unstable reward allocations among\nparticipants. Our analysis spans various data heterogeneity distributions,\nincluding independent and identically distributed (IID) and non-IID scenarios.",
      "tldr_zh": "本研究探讨了Federated Learning (FL) 中基于Shapley值的贡献指标的波动性问题，旨在解决参与者贡献分配不准确可能导致的信任和激励不足问题。作者使用梯度-based模型重构技术计算Shapley值，并将其与经典数据贡献测量方案进行比较，分析了不同聚合策略在IID和non-IID数据异质性场景下的表现。结果显示，Shapley值在各种聚合方法间会导致不稳定的奖励分配，强调了改进贡献评估机制的必要性，以促进FL的公平协作。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08044v3",
      "published_date": "2024-05-13 13:55:34 UTC",
      "updated_date": "2025-04-03 13:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:07:21.922531"
    },
    {
      "arxiv_id": "2405.07749v1",
      "title": "DeepHYDRA: Resource-Efficient Time-Series Anomaly Detection in Dynamically-Configured Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Franz Kevin Stehle",
        "Wainer Vandelli",
        "Giuseppe Avolio",
        "Felix Zahn",
        "Holger Fröning"
      ],
      "abstract": "Anomaly detection in distributed systems such as High-Performance Computing\n(HPC) clusters is vital for early fault detection, performance optimisation,\nsecurity monitoring, reliability in general but also operational insights. Deep\nNeural Networks have seen successful use in detecting long-term anomalies in\nmultidimensional data, originating for instance from industrial or medical\nsystems, or weather prediction. A downside of such methods is that they require\na static input size, or lose data through cropping, sampling, or other\ndimensionality reduction methods, making deployment on systems with variability\non monitored data channels, such as computing clusters difficult. To address\nthese problems, we present DeepHYDRA (Deep Hybrid DBSCAN/Reduction-Based\nAnomaly Detection) which combines DBSCAN and learning-based anomaly detection.\nDBSCAN clustering is used to find point anomalies in time-series data,\nmitigating the risk of missing outliers through loss of information when\nreducing input data to a fixed number of channels. A deep learning-based\ntime-series anomaly detection method is then applied to the reduced data in\norder to identify long-term outliers. This hybrid approach reduces the chances\nof missing anomalies that might be made indistinguishable from normal data by\nthe reduction process, and likewise enables the algorithm to be scalable and\ntolerate partial system failures while retaining its detection capabilities.\nUsing a subset of the well-known SMD dataset family, a modified variant of the\nEclipse dataset, as well as an in-house dataset with a large variability in\nactive data channels, made publicly available with this work, we furthermore\nanalyse computational intensity, memory footprint, and activation counts.\nDeepHYDRA is shown to reliably detect different types of anomalies in both\nlarge and complex datasets.",
      "tldr_zh": "该论文提出 DeepHYDRA，一种资源高效的时间序列异常检测方法，针对动态配置系统（如 HPC 集群）中数据通道变化带来的挑战，通过结合 DBSCAN 聚类和深度学习技术来检测点异常和长期异常，避免数据减少导致的信息丢失。DBSCAN 用于识别时间序列中的离群点，而后续的深度学习模型则处理减少后的数据，确保算法在可扩展性和容错性上表现出色。实验结果基于 SMD 数据集子集、修改的 Eclipse 数据集以及一个新公开的内部数据集显示，DeepHYDRA 可靠地检测不同类型异常，同时在计算强度、内存占用和激活计数方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07749v1",
      "published_date": "2024-05-13 13:47:15 UTC",
      "updated_date": "2024-05-13 13:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:07:35.644082"
    },
    {
      "arxiv_id": "2405.07745v1",
      "title": "LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language",
      "title_zh": "LlamaTurk：",
      "authors": [
        "Cagri Toraman"
      ],
      "abstract": "Despite advancements in English-dominant generative large language models,\nfurther development is needed for low-resource languages to enhance global\naccessibility. The primary methods for representing these languages are\nmonolingual and multilingual pretraining. Monolingual pretraining is expensive\ndue to hardware requirements, and multilingual models often have uneven\nperformance across languages. This study explores an alternative solution by\nadapting large language models, primarily trained on English, to low-resource\nlanguages. We assess various strategies, including continual training,\ninstruction fine-tuning, task-specific fine-tuning, and vocabulary extension.\nThe results show that continual training improves language comprehension, as\nreflected in perplexity scores, and task-specific tuning generally enhances\nperformance of downstream tasks. However, extending the vocabulary shows no\nsubstantial benefits. Additionally, while larger models improve task\nperformance with few-shot tuning, multilingual models perform worse than their\nmonolingual counterparts when adapted.",
      "tldr_zh": "该研究探讨了如何将开源生成式大型语言模型（Large Language Models）适配到低资源语言，以提升全球可访问性。研究评估了多种策略，包括持续训练（continual training）、指令微调（instruction fine-tuning）、任务特定微调（task-specific fine-tuning）和词汇扩展（vocabulary extension）。结果显示，持续训练显著改善了语言理解能力（如通过困惑度分数（perplexity scores）体现），而任务特定调优提升了下游任务性能；然而，词汇扩展并未带来实质益处。总体上，更大模型在少样本调优（few-shot tuning）中表现更好，但多语模型（multilingual models）适配后不如单语模型（monolingual counterparts）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07745v1",
      "published_date": "2024-05-13 13:41:59 UTC",
      "updated_date": "2024-05-13 13:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:07:46.956819"
    },
    {
      "arxiv_id": "2405.07735v2",
      "title": "Federated Hierarchical Tensor Networks: a Collaborative Learning Quantum AI-Driven Framework for Healthcare",
      "title_zh": "联邦层次张量网络：一种用于医疗保健的协作学习量子AI驱动框架",
      "authors": [
        "Amandeep Singh Bhatia",
        "David E. Bernal Neira"
      ],
      "abstract": "Healthcare industries frequently handle sensitive and proprietary data, and\ndue to strict privacy regulations, they are often reluctant to share data\ndirectly. In today's context, Federated Learning (FL) stands out as a crucial\nremedy, facilitating the rapid advancement of distributed machine learning\nwhile effectively managing critical concerns regarding data privacy and\ngovernance. The fusion of federated learning and quantum computing represents a\ngroundbreaking interdisciplinary approach with immense potential to\nrevolutionize various industries, from healthcare to finance. In this work, we\nproposed a federated learning framework based on quantum tensor networks, which\nleverages the principles of many-body quantum physics. Currently, there are no\nknown classical tensor networks implemented in federated settings. Furthermore,\nwe investigated the effectiveness and feasibility of the proposed framework by\nconducting a differential privacy analysis to ensure the security of sensitive\ndata across healthcare institutions. Experiments on popular medical image\ndatasets show that the federated quantum tensor network model achieved a mean\nreceiver-operator characteristic area under the curve (ROC-AUC) between\n0.91-0.98. Experimental results demonstrate that the quantum federated global\nmodel, consisting of highly entangled tensor network structures, showed better\ngeneralization and robustness and achieved higher testing accuracy, surpassing\nthe performance of locally trained clients under unbalanced data distributions\namong healthcare institutions.",
      "tldr_zh": "该研究提出了一种基于量子 AI 的联邦学习框架（Federated Hierarchical Tensor Networks），旨在解决医疗保健领域的数据隐私问题，通过利用多体量子物理原理的张量网络（tensor networks）实现机构间协作学习。该框架首次在联邦设置中整合量子张量网络，并通过差分隐私分析（differential privacy analysis）确保敏感数据的安全。实验在流行医疗图像数据集上显示，该模型的 ROC-AUC 得分在 0.91-0.98 之间，并表现出更高的泛化和鲁棒性，尤其在数据分布不平衡时优于局部训练模型。总的来说，这一框架为隐私保护下的医疗 AI 应用提供了创新途径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07735v2",
      "published_date": "2024-05-13 13:32:02 UTC",
      "updated_date": "2024-07-04 01:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:07:59.727876"
    },
    {
      "arxiv_id": "2405.13010v1",
      "title": "UCCIX: Irish-eXcellence Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Khanh-Tung Tran",
        "Barry O'Sullivan",
        "Hoang D. Nguyen"
      ],
      "abstract": "The development of Large Language Models (LLMs) has predominantly focused on\nhigh-resource languages, leaving extremely low-resource languages like Irish\nwith limited representation. This work presents UCCIX, a pioneering effort on\nthe development of an open-source Irish-based LLM. We propose a novel framework\nfor continued pre-training of LLMs specifically adapted for extremely\nlow-resource languages, requiring only a fraction of the textual data typically\nneeded for training LLMs according to scaling laws. Our model, based on Llama\n2-13B, outperforms much larger models on Irish language tasks with up to 12%\nperformance improvement, showcasing the effectiveness and efficiency of our\napproach. We also contribute comprehensive Irish benchmarking datasets,\nincluding IrishQA, a question-answering dataset, and Irish version of MT-bench.\nThese datasets enable rigorous evaluation and facilitate future research in\nIrish LLM systems. Our work aims to preserve and promote the Irish language,\nknowledge, and culture of Ireland in the digital era while providing a\nframework for adapting LLMs to other indigenous languages.",
      "tldr_zh": "本研究介绍了 UCCIX，一种开源的大型语言模型（LLM），专注于极低资源语言如爱尔兰语的开发，以解决现有模型对高资源语言的偏重问题。研究提出了一种新型框架，通过持续预训练，仅需少量文本数据就实现了高效适应，基于 Llama 2-13B 模型在爱尔兰语任务上比更大模型提升了高达 12% 的性能。论文还贡献了全面的爱尔兰语基准数据集，包括 IrishQA（问答数据集）和爱尔兰版的 MT-bench，以支持未来研究，并为保护爱尔兰语言、文化以及适应其他本土语言提供框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13010v1",
      "published_date": "2024-05-13 13:19:27 UTC",
      "updated_date": "2024-05-13 13:19:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:08:12.316908"
    },
    {
      "arxiv_id": "2405.07719v5",
      "title": "USP: A Unified Sequence Parallelism Approach for Long Context Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarui Fang",
        "Shangchun Zhao"
      ],
      "abstract": "Sequence parallelism (SP), which divides the sequence dimension of input\ntensors across multiple computational devices, is becoming key to unlocking the\nlong-context capabilities of generative AI models. This paper investigates the\nstate-of-the-art SP approaches, i.e. DeepSpeed-Ulysses and Ring-Attention, and\nproposes a unified SP approach, which is more robust to transformer model\narchitectures and network hardware topology. This paper compares the\ncommunication and memory cost of SP and existing parallelism, including\ndata/tensor/zero/pipeline parallelism, and discusses the best practices for\ndesigning hybrid 4D parallelism involving SP. We achieved 47% MFU on two 8xA800\nnodes using SP for the LLAMA3-8B model training using sequence length 208K. Our\ncode is publicly available at\nhttps://github.com/feifeibear/long-context-attention.",
      "tldr_zh": "该论文提出了一种统一的序列并行（SP）方法，用于提升生成AI模型的长上下文能力，相比现有方法如DeepSpeed-Ulysses和Ring-Attention，更适用于不同的Transformer模型架构和网络硬件拓扑。研究者比较了SP与其他并行策略（如数据/张量/零/流水线并行）的通信和内存成本，并讨论了设计混合4D并行性的最佳实践。实验结果显示，使用SP在两个8xA800节点上训练LLAMA3-8B模型时，序列长度达208K，实现了47%的MFU，代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07719v5",
      "published_date": "2024-05-13 13:08:02 UTC",
      "updated_date": "2024-07-02 09:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:08:22.766212"
    },
    {
      "arxiv_id": "2405.08042v1",
      "title": "LLAniMAtion: LLAMA Driven Gesture Animation",
      "title_zh": "LLAniMAtion：LLAMA 驱动的手势动画",
      "authors": [
        "Jonathan Windle",
        "Iain Matthews",
        "Sarah Taylor"
      ],
      "abstract": "Co-speech gesturing is an important modality in conversation, providing\ncontext and social cues. In character animation, appropriate and synchronised\ngestures add realism, and can make interactive agents more engaging.\nHistorically, methods for automatically generating gestures were predominantly\naudio-driven, exploiting the prosodic and speech-related content that is\nencoded in the audio signal. In this paper we instead experiment with using LLM\nfeatures for gesture generation that are extracted from text using LLAMA2. We\ncompare against audio features, and explore combining the two modalities in\nboth objective tests and a user study. Surprisingly, our results show that\nLLAMA2 features on their own perform significantly better than audio features\nand that including both modalities yields no significant difference to using\nLLAMA2 features in isolation. We demonstrate that the LLAMA2 based model can\ngenerate both beat and semantic gestures without any audio input, suggesting\nLLMs can provide rich encodings that are well suited for gesture generation.",
      "tldr_zh": "本文提出 LLAniMAtion，一种使用 LLAMA2 从文本中提取特征来驱动手势动画生成的方法，旨在为对话和角色动画提供更真实、同步的手势。相比传统音频驱动方法，实验结果显示 LLAMA2 特征单独使用在客观测试和用户研究中表现更优，且结合音频模态未带来显著提升。该方法无需音频输入即可生成 beat 和 semantic 手势，证明 LLMs 能提供丰富的编码支持手势生成。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08042v1",
      "published_date": "2024-05-13 12:40:18 UTC",
      "updated_date": "2024-05-13 12:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:08:34.061000"
    },
    {
      "arxiv_id": "2405.07682v1",
      "title": "FastSAG: Towards Fast Non-Autoregressive Singing Accompaniment Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jianyi Chen",
        "Wei Xue",
        "Xu Tan",
        "Zhen Ye",
        "Qifeng Liu",
        "Yike Guo"
      ],
      "abstract": "Singing Accompaniment Generation (SAG), which generates instrumental music to\naccompany input vocals, is crucial to developing human-AI symbiotic art\ncreation systems. The state-of-the-art method, SingSong, utilizes a multi-stage\nautoregressive (AR) model for SAG, however, this method is extremely slow as it\ngenerates semantic and acoustic tokens recursively, and this makes it\nimpossible for real-time applications. In this paper, we aim to develop a Fast\nSAG method that can create high-quality and coherent accompaniments. A non-AR\ndiffusion-based framework is developed, which by carefully designing the\nconditions inferred from the vocal signals, generates the Mel spectrogram of\nthe target accompaniment directly. With diffusion and Mel spectrogram modeling,\nthe proposed method significantly simplifies the AR token-based SingSong\nframework, and largely accelerates the generation. We also design semantic\nprojection, prior projection blocks as well as a set of loss functions, to\nensure the generated accompaniment has semantic and rhythm coherence with the\nvocal signal. By intensive experimental studies, we demonstrate that the\nproposed method can generate better samples than SingSong, and accelerate the\ngeneration by at least 30 times. Audio samples and code are available at\nhttps://fastsag.github.io/.",
      "tldr_zh": "本论文针对Singing Accompaniment Generation (SAG)中的生成速度问题，提出FastSAG方法，以非autoregressive (AR) 的diffusion-based框架直接从输入歌声信号生成伴奏的Mel spectrogram，从而显著简化了现有SingSong的多阶段AR模型。方法通过设计semantic projection、prior projection blocks以及专用损失函数，确保生成的伴奏在语义和节奏上与歌声高度一致。实验结果表明，FastSAG生成的伴奏质量优于SingSong，且生成速度至少加快30倍，适用于实时应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.07682v1",
      "published_date": "2024-05-13 12:14:54 UTC",
      "updated_date": "2024-05-13 12:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:08:46.662824"
    },
    {
      "arxiv_id": "2407.04710v2",
      "title": "Visual Evaluative AI: A Hypothesis-Driven Tool with Concept-Based Explanations and Weight of Evidence",
      "title_zh": "翻译失败",
      "authors": [
        "Thao Le",
        "Tim Miller",
        "Ruihan Zhang",
        "Liz Sonenberg",
        "Ronal Singh"
      ],
      "abstract": "This paper presents Visual Evaluative AI, a decision aid that provides\npositive and negative evidence from image data for a given hypothesis. This\ntool finds high-level human concepts in an image and generates the Weight of\nEvidence (WoE) for each hypothesis in the decision-making process. We apply and\nevaluate this tool in the skin cancer domain by building a web-based\napplication that allows users to upload a dermatoscopic image, select a\nhypothesis and analyse their decisions by evaluating the provided evidence.\nFurther, we demonstrate the effectiveness of Visual Evaluative AI on different\nconcept-based explanation approaches.",
      "tldr_zh": "本文介绍了 Visual Evaluative AI，一种基于假设的决策辅助工具，它从图像数据中提取正负证据，并通过识别高级人类概念计算每个假设的 Weight of Evidence (WoE)。该工具应用于皮肤癌领域，开发了一个网络应用，用户可上传皮肤镜图像、选择假设并分析证据，以支持决策过程。实验结果证明了 Visual Evaluative AI 在不同 concept-based explanations 方法上的有效性，为解释性 AI 在医疗领域的应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.04710v2",
      "published_date": "2024-05-13 12:09:01 UTC",
      "updated_date": "2025-01-19 01:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:08:58.537396"
    },
    {
      "arxiv_id": "2405.07668v1",
      "title": "CrossCert: A Cross-Checking Detection Approach to Patch Robustness Certification for Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qilin Zhou",
        "Zhengyuan Wei",
        "Haipeng Wang",
        "Bo Jiang",
        "W. K. Chan"
      ],
      "abstract": "Patch robustness certification is an emerging kind of defense technique\nagainst adversarial patch attacks with provable guarantees. There are two\nresearch lines: certified recovery and certified detection. They aim to label\nmalicious samples with provable guarantees correctly and issue warnings for\nmalicious samples predicted to non-benign labels with provable guarantees,\nrespectively. However, existing certified detection defenders suffer from\nprotecting labels subject to manipulation, and existing certified recovery\ndefenders cannot systematically warn samples about their labels. A certified\ndefense that simultaneously offers robust labels and systematic warning\nprotection against patch attacks is desirable. This paper proposes a novel\ncertified defense technique called CrossCert. CrossCert formulates a novel\napproach by cross-checking two certified recovery defenders to provide\nunwavering certification and detection certification. Unwavering certification\nensures that a certified sample, when subjected to a patched perturbation, will\nalways be returned with a benign label without triggering any warnings with a\nprovable guarantee. To our knowledge, CrossCert is the first certified\ndetection technique to offer this guarantee. Our experiments show that, with a\nslightly lower performance than ViP and comparable performance with PatchCensor\nin terms of detection certification, CrossCert certifies a significant\nproportion of samples with the guarantee of unwavering certification.",
      "tldr_zh": "该论文针对深度学习模型对抗性补丁攻击，提出了CrossCert方法，通过交叉检查两个certified recovery defenders，提供unwavering certification和detection certification，以同时确保鲁棒标签和系统警告。CrossCert的unwavering certification保证了在补丁扰动下，认证样本始终返回良性标签且不触发警告，这是首个实现此保障的certified detection技术。实验结果表明，CrossCert在检测认证方面略低于ViP但与PatchCensor相当，并为显著比例的样本提供了可靠的unwavering certification。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "23 pages, 2 figures, accepted by FSE 2024 (The ACM International\n  Conference on the Foundations of Software Engineering)",
      "pdf_url": "http://arxiv.org/pdf/2405.07668v1",
      "published_date": "2024-05-13 11:54:03 UTC",
      "updated_date": "2024-05-13 11:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:09:11.023803"
    },
    {
      "arxiv_id": "2405.07664v1",
      "title": "Geospatial Knowledge Graphs",
      "title_zh": "地理空间知识图谱",
      "authors": [
        "Rui Zhu"
      ],
      "abstract": "Geospatial knowledge graphs have emerged as a novel paradigm for representing\nand reasoning over geospatial information. In this framework, entities such as\nplaces, people, events, and observations are depicted as nodes, while their\nrelationships are represented as edges. This graph-based data format lays the\nfoundation for creating a \"FAIR\" (Findable, Accessible, Interoperable, and\nReusable) environment, facilitating the management and analysis of geographic\ninformation. This entry first introduces key concepts in knowledge graphs along\nwith their associated standardization and tools. It then delves into the\napplication of knowledge graphs in geography and environmental sciences,\nemphasizing their role in bridging symbolic and subsymbolic GeoAI to address\ncross-disciplinary geospatial challenges. At the end, new research directions\nrelated to geospatial knowledge graphs are outlined.",
      "tldr_zh": "地理空间知识图谱（Geospatial Knowledge Graphs）是一种新兴范式，用于表示和推理地理信息，将实体（如地点、人物、事件）作为节点、关系作为边，从而构建一个FAIR（Findable, Accessible, Interoperable, and Reusable）环境，便于地理数据的管理和分析。该框架在地理和环境科学中发挥关键作用，通过桥接符号和子符号GeoAI，帮助解决跨学科的地理空间挑战。论文首先介绍了知识图谱的核心概念、标准化工具及其应用，最后概述了相关的新研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07664v1",
      "published_date": "2024-05-13 11:45:22 UTC",
      "updated_date": "2024-05-13 11:45:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:09:21.543812"
    },
    {
      "arxiv_id": "2405.07662v1",
      "title": "Squeezing Lemons with Hammers: An Evaluation of AutoML and Tabular Deep Learning for Data-Scarce Classification Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Knauer",
        "Erik Rodner"
      ],
      "abstract": "Many industry verticals are confronted with small-sized tabular data. In this\nlow-data regime, it is currently unclear whether the best performance can be\nexpected from simple baselines, or more complex machine learning approaches\nthat leverage meta-learning and ensembling. On 44 tabular classification\ndatasets with sample sizes $\\leq$ 500, we find that L2-regularized logistic\nregression performs similar to state-of-the-art automated machine learning\n(AutoML) frameworks (AutoPrognosis, AutoGluon) and off-the-shelf deep neural\nnetworks (TabPFN, HyperFast) on the majority of the benchmark datasets. We\ntherefore recommend to consider logistic regression as the first choice for\ndata-scarce applications with tabular data and provide practitioners with best\npractices for further method selection.",
      "tldr_zh": "该研究评估了在数据稀缺（样本大小 ≤ 500）的表格分类任务中，简单基线模型与复杂方法（如 AutoML 框架 AutoPrognosis 和 AutoGluon，以及深度学习模型 TabPFN 和 HyperFast）的性能表现。研究在 44 个数据集上进行比较，发现 L2-regularized logistic regression 的表现与这些先进方法相当，在大多数基准数据集上不相上下。因此，作者推荐在类似数据稀缺应用中优先选择 logistic regression，并提供方法选择的best practices，以指导从业者。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024 Workshop on Practical ML for Low Resource Settings",
      "pdf_url": "http://arxiv.org/pdf/2405.07662v1",
      "published_date": "2024-05-13 11:43:38 UTC",
      "updated_date": "2024-05-13 11:43:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:09:35.183983"
    },
    {
      "arxiv_id": "2405.07653v1",
      "title": "Fast Training Data Acquisition for Object Detection and Segmentation using Black Screen Luminance Keying",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Pöllabauer",
        "Volker Knauthe",
        "André Boller",
        "Arjan Kuijper",
        "Dieter Fellner"
      ],
      "abstract": "Deep Neural Networks (DNNs) require large amounts of annotated training data\nfor a good performance. Often this data is generated using manual labeling\n(error-prone and time-consuming) or rendering (requiring geometry and material\ninformation). Both approaches make it difficult or uneconomic to apply them to\nmany small-scale applications. A fast and straightforward approach of acquiring\nthe necessary training data would allow the adoption of deep learning to even\nthe smallest of applications. Chroma keying is the process of replacing a color\n(usually blue or green) with another background. Instead of chroma keying, we\npropose luminance keying for fast and straightforward training image\nacquisition. We deploy a black screen with high light absorption (99.99\\%) to\nrecord roughly 1-minute long videos of our target objects, circumventing\ntypical problems of chroma keying, such as color bleeding or color overlap\nbetween background color and object color. Next we automatically mask our\nobjects using simple brightness thresholding, saving the need for manual\nannotation. Finally, we automatically place the objects on random backgrounds\nand train a 2D object detector. We do extensive evaluation of the performance\non the widely-used YCB-V object set and compare favourably to other\nconventional techniques such as rendering, without needing 3D meshes, materials\nor any other information of our target objects and in a fraction of the time\nneeded for other approaches. Our work demonstrates highly accurate training\ndata acquisition allowing to start training state-of-the-art networks within\nminutes.",
      "tldr_zh": "本研究提出了一种快速获取训练数据的方法，用于物体检测和分割，采用Black Screen Luminance Keying技术，以解决Deep Neural Networks (DNNs) 训练所需的大量标注数据的难题。方法涉及使用高吸收光线（99.99%）的黑屏录制目标物体视频（约1分钟），通过简单亮度阈值自动生成物体掩码，并将物体置于随机背景上进行训练2D对象检测器。该方法无需手动标注或3D网格/材料信息，在YCB-V数据集上表现出色，与传统渲染技术相比，准确率更高且可在几分钟内启动训练，适用于小规模应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "32. International Conference in Central Europe on Computer Graphics,\n  Visualization and Computer Vision'2024",
      "pdf_url": "http://arxiv.org/pdf/2405.07653v1",
      "published_date": "2024-05-13 11:28:58 UTC",
      "updated_date": "2024-05-13 11:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:09:46.995114"
    },
    {
      "arxiv_id": "2405.07652v1",
      "title": "G-VOILA: Gaze-Facilitated Information Querying in Daily Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Wang",
        "Yuanchun Shi",
        "Yuntao Wang",
        "Yuchen Yao",
        "Kun Yan",
        "Yuhan Wang",
        "Lei Ji",
        "Xuhai Xu",
        "Chun Yu"
      ],
      "abstract": "Modern information querying systems are progressively incorporating\nmultimodal inputs like vision and audio. However, the integration of gaze -- a\nmodality deeply linked to user intent and increasingly accessible via\ngaze-tracking wearables -- remains underexplored. This paper introduces a novel\ngaze-facilitated information querying paradigm, named G-VOILA, which synergizes\nusers' gaze, visual field, and voice-based natural language queries to\nfacilitate a more intuitive querying process. In a user-enactment study\ninvolving 21 participants in 3 daily scenarios (p = 21, scene = 3), we revealed\nthe ambiguity in users' query language and a gaze-voice coordination pattern in\nusers' natural query behaviors with G-VOILA. Based on the quantitative and\nqualitative findings, we developed a design framework for the G-VOILA paradigm,\nwhich effectively integrates the gaze data with the in-situ querying context.\nThen we implemented a G-VOILA proof-of-concept using cutting-edge deep learning\ntechniques. A follow-up user study (p = 16, scene = 2) demonstrates its\neffectiveness by achieving both higher objective score and subjective score,\ncompared to a baseline without gaze data. We further conducted interviews and\nprovided insights for future gaze-facilitated information querying systems.",
      "tldr_zh": "该研究引入了 G-VOILA 范式，一种结合用户 gaze（注视）、视觉场和语音查询的多模态信息查询系统，旨在提升日常场景下的查询直观性。通过一项用户研究（21 名参与者，3 个场景），论文揭示了查询语言的模糊性和 gaze-voice 协调模式，并据此开发了一个设计框架来整合 gaze 数据与查询上下文。研究团队使用先进的 deep learning 技术实现了 G-VOILA 的概念验证系统。后续用户研究（16 名参与者，2 个场景）显示，该系统相较于不使用 gaze 数据的基线，取得了更高的客观和主观评分，并通过访谈提供了未来 gaze-facilitated 查询系统的设计见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "25 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07652v1",
      "published_date": "2024-05-13 11:24:53 UTC",
      "updated_date": "2024-05-13 11:24:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:09:58.344124"
    },
    {
      "arxiv_id": "2405.07640v3",
      "title": "Hyperparameter Importance Analysis for Multi-Objective AutoML",
      "title_zh": "多目标 AutoML 的超参数重要性分析",
      "authors": [
        "Daphne Theodorakopoulos",
        "Frederic Stahl",
        "Marius Lindauer"
      ],
      "abstract": "Hyperparameter optimization plays a pivotal role in enhancing the predictive\nperformance and generalization capabilities of ML models. However, in many\napplications, we do not only care about predictive performance but also about\nadditional objectives such as inference time, memory, or energy consumption. In\nsuch multi-objective scenarios, determining the importance of hyperparameters\nposes a significant challenge due to the complex interplay between the\nconflicting objectives. In this paper, we propose the first method for\nassessing the importance of hyperparameters in multi-objective hyperparameter\noptimization. Our approach leverages surrogate-based hyperparameter importance\nmeasures, i.e., fANOVA and ablation paths, to provide insights into the impact\nof hyperparameters on the optimization objectives. Specifically, we compute the\na-priori scalarization of the objectives and determine the importance of the\nhyperparameters for different objective tradeoffs. Through extensive empirical\nevaluations on diverse benchmark datasets with three different objective pairs,\neach combined with accuracy, namely time, demographic parity loss, and energy\nconsumption, we demonstrate the effectiveness and robustness of our proposed\nmethod. Our findings not only offer valuable guidance for hyperparameter tuning\nin multi-objective optimization tasks but also contribute to advancing the\nunderstanding of hyperparameter importance in complex optimization scenarios.",
      "tldr_zh": "这篇论文针对多目标自动机器学习（Multi-Objective AutoML）中的超参数优化（Hyperparameter optimization），提出了一种首创方法，用于评估超参数在多个冲突目标（如预测性能、推理时间、内存或能耗）下的重要性。方法基于 fANOVA 和 ablation paths 等基于代理的措施，通过计算目标的 a-priori scalarization，分析超参数对不同目标权衡的影响。实验在多种基准数据集上进行，结合准确性与时间、demographic parity loss 或 energy consumption 等目标对，证明了方法的有效性和鲁棒性，为多目标优化任务的超参数调整提供宝贵指导，并深化了对复杂优化场景的理解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the 27th European Conference on Artificial Intelligence,\n  19-24 October 2024, Santiago de Compostela, Spain",
      "pdf_url": "http://arxiv.org/pdf/2405.07640v3",
      "published_date": "2024-05-13 11:00:25 UTC",
      "updated_date": "2025-01-02 13:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:10:12.150099"
    },
    {
      "arxiv_id": "2405.07638v1",
      "title": "DoLLM: How Large Language Models Understanding Network Flow Data to Detect Carpet Bombing DDoS",
      "title_zh": "DoLLM：大型语言模型如何理解网络流量数据",
      "authors": [
        "Qingyang Li",
        "Yihang Zhang",
        "Zhidong Jia",
        "Yannan Hu",
        "Lei Zhang",
        "Jianrong Zhang",
        "Yongming Xu",
        "Yong Cui",
        "Zongming Guo",
        "Xinggong Zhang"
      ],
      "abstract": "It is an interesting question Can and How Large Language Models (LLMs)\nunderstand non-language network data, and help us detect unknown malicious\nflows. This paper takes Carpet Bombing as a case study and shows how to exploit\nLLMs' powerful capability in the networking area. Carpet Bombing is a new DDoS\nattack that has dramatically increased in recent years, significantly\nthreatening network infrastructures. It targets multiple victim IPs within\nsubnets, causing congestion on access links and disrupting network services for\na vast number of users. Characterized by low-rates, multi-vectors, these\nattacks challenge traditional DDoS defenses. We propose DoLLM, a DDoS detection\nmodel utilizes open-source LLMs as backbone. By reorganizing non-contextual\nnetwork flows into Flow-Sequences and projecting them into LLMs semantic space\nas token embeddings, DoLLM leverages LLMs' contextual understanding to extract\nflow representations in overall network context. The representations are used\nto improve the DDoS detection performance. We evaluate DoLLM with public\ndatasets CIC-DDoS2019 and real NetFlow trace from Top-3 countrywide ISP. The\ntests have proven that DoLLM possesses strong detection capabilities. Its F1\nscore increased by up to 33.3% in zero-shot scenarios and by at least 20.6% in\nreal ISP traces.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 是否能理解非语言的网络流量数据，并将其应用于检测未知恶意流量，以 Carpet Bombing DDoS 攻击为例。Carpet Bombing 是一种低速率、多向量的 DDoS 攻击，导致网络拥塞并挑战传统防御。研究提出 DoLLM 模型，使用开源 LLMs 作为骨干，通过将网络流量重组为 Flow-Sequences 并投射到 LLMs 的语义空间中作为 token embeddings，提取流量表示以提升检测性能。在 CIC-DDoS2019 数据集和真实 ISP 追踪上测试，DoLLM 在零样本场景下 F1 分数提高多达 33.3%，在真实追踪中至少提高 20.6%。这为 LLMs 在网络安全领域的应用提供了新见解。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07638v1",
      "published_date": "2024-05-13 10:53:41 UTC",
      "updated_date": "2024-05-13 10:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:10:22.284370"
    },
    {
      "arxiv_id": "2405.13009v2",
      "title": "MetaReflection: Learning Instructions for Language Agents using Past Reflections",
      "title_zh": "MetaReflection：利用过去的反思为语言代理学习指令",
      "authors": [
        "Priyanshu Gupta",
        "Shashank Kirtania",
        "Ananya Singha",
        "Sumit Gulwani",
        "Arjun Radhakrishna",
        "Sherry Shi",
        "Gustavo Soares"
      ],
      "abstract": "The popularity of Large Language Models (LLMs) have unleashed a new age\nofLanguage Agents for solving a diverse range of tasks. While contemporary\nfrontier LLMs are capable enough to power reasonably good Language agents, the\nclosed-API model makes it hard to improve in cases they perform sub-optimally.\nTo address this, recent works have explored ways to improve their performance\nusing techniques like self-reflection and prompt optimization. Unfortunately,\ntechniques like self-reflection can be used only in an online setup, while\ncontemporary prompt optimization techniques are designed and tested to work on\nsimple tasks. To this end, we introduce MetaReflection, a novel offline\nreinforcement learning technique that enhances the performance of Language\nAgents by augmenting a semantic memory based on experiential learnings from\npast trials. We demonstrate the efficacy of MetaReflection by evaluating across\nmultiple domains, including complex logical reasoning, biomedical semantic\nsimilarity, open world question answering, and vulnerability threat detection,\nin Infrastructure-as-Code, spanning different agent designs. MetaReflection\nboosts Language agents' performance by 4% to 16.82% over the raw GPT-4 baseline\nand performs on par with existing state-of-the-art prompt optimization\ntechniques while requiring fewer LLM calls.",
      "tldr_zh": "本文提出 MetaReflection，一种新型离线强化学习技术，用于通过基于过去试验的经验学习增强 Language Agents 的语义记忆，从而改善其在复杂任务中的性能。该方法针对多个领域如复杂逻辑推理、生物医学语义相似性、开放世界问答和 Infrastructure-as-Code 中的漏洞威胁检测进行评估，结果显示 MetaReflection 比原始 GPT-4 基线提高了 4% 到 16.82% 的性能，并与现有最先进提示优化技术相当，同时减少了 LLM 调用次数。这种创新方法为优化 Large Language Models (LLMs) 驱动的代理提供了一种高效的离线策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "We release our experimental code at:\n  https://aka.ms/metareflection-code",
      "pdf_url": "http://arxiv.org/pdf/2405.13009v2",
      "published_date": "2024-05-13 10:51:43 UTC",
      "updated_date": "2024-10-10 11:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:10:36.035244"
    },
    {
      "arxiv_id": "2405.07626v2",
      "title": "AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models",
      "title_zh": "An",
      "authors": [
        "Shuo Liu",
        "Di Yao",
        "Lanting Fang",
        "Zhetao Li",
        "Wenbin Li",
        "Kaiyu Feng",
        "XiaoWen Ji",
        "Jingping Bi"
      ],
      "abstract": "Detecting anomaly edges for dynamic graphs aims to identify edges\nsignificantly deviating from the normal pattern and can be applied in various\ndomains, such as cybersecurity, financial transactions and AIOps. With the\nevolving of time, the types of anomaly edges are emerging and the labeled\nanomaly samples are few for each type. Current methods are either designed to\ndetect randomly inserted edges or require sufficient labeled data for model\ntraining, which harms their applicability for real-world applications. In this\npaper, we study this problem by cooperating with the rich knowledge encoded in\nlarge language models(LLMs) and propose a method, namely AnomalyLLM. To align\nthe dynamic graph with LLMs, AnomalyLLM pre-trains a dynamic-aware encoder to\ngenerate the representations of edges and reprograms the edges using the\nprototypes of word embeddings. Along with the encoder, we design an in-context\nlearning framework that integrates the information of a few labeled samples to\nachieve few-shot anomaly detection. Experiments on four datasets reveal that\nAnomalyLLM can not only significantly improve the performance of few-shot\nanomaly detection, but also achieve superior results on new anomalies without\nany update of model parameters.",
      "tldr_zh": "该论文针对动态图中的异常边检测问题，提出AnomalyLLM方法，利用Large Language Models (LLMs)的丰富知识来处理异常类型多样且标注样本稀少的few-shot场景。AnomalyLLM通过预训练一个dynamic-aware encoder生成边表示，并使用词嵌入原型重新编程边，同时设计in-context learning框架整合少量标注样本，实现高效的异常检测。实验在四个数据集上显示，该方法显著提升了few-shot异常检测性能，并在新异常类型上取得优异结果，而无需更新模型参数。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13pages",
      "pdf_url": "http://arxiv.org/pdf/2405.07626v2",
      "published_date": "2024-05-13 10:37:50 UTC",
      "updated_date": "2024-08-28 06:18:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:10:46.228850"
    },
    {
      "arxiv_id": "2405.07621v2",
      "title": "Towards Adaptive IMFs -- Generalization of utility functions in Multi-Agent Frameworks",
      "title_zh": "面向自适应的 IMFs —— 多智能体框架",
      "authors": [
        "Kaushik Dey",
        "Satheesh K. Perepu",
        "Abir Das",
        "Pallab Dasgupta"
      ],
      "abstract": "Intent Management Function (IMF) is an integral part of future-generation\nnetworks. In recent years, there has been some work on AI-based IMFs that can\nhandle conflicting intents and prioritize the global objective based on apriori\ndefinition of the utility function and accorded priorities for competing\nintents. Some of the earlier works use Multi-Agent Reinforcement Learning\n(MARL) techniques with AdHoc Teaming (AHT) approaches for efficient conflict\nhandling in IMF. However, the success of such frameworks in real-life scenarios\nrequires them to be flexible to business situations. The intent priorities can\nchange and the utility function, which measures the extent of intent\nfulfilment, may also vary in definition. This paper proposes a novel mechanism\nwhereby the IMF can generalize to different forms of utility functions and\nchange of intent priorities at run-time without additional training. Such\ngeneralization ability, without additional training requirements, would help to\ndeploy IMF in live networks where customer intents and priorities change\nfrequently. Results on the network emulator demonstrate the efficacy of the\napproach, scalability for new intents, outperforming existing techniques that\nrequire additional training to achieve the same degree of flexibility thereby\nsaving cost, and increasing efficiency and adaptability.",
      "tldr_zh": "本文探讨了Intent Management Function (IMF)在多智能体框架中的泛化问题，针对现有基于Multi-Agent Reinforcement Learning (MARL)和AdHoc Teaming (AHT)技术的IMF在处理冲突意图时缺乏灵活性。研究提出了一种新机制，使IMF能够在运行时适应不同的utility functions和意图优先级变化，而无需额外训练，从而提升其在实时网络中的适用性。实验结果显示，该方法在网络仿真器上表现出色，能够扩展到新意图，并优于传统技术，在成本节省、效率和适应性方面实现了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in Netsoft-2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2405.07621v2",
      "published_date": "2024-05-13 10:27:11 UTC",
      "updated_date": "2024-05-14 06:29:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:10:59.241659"
    },
    {
      "arxiv_id": "2405.07609v2",
      "title": "NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Elena Merdjanovska",
        "Ansar Aynetdinov",
        "Alan Akbik"
      ],
      "abstract": "Available training data for named entity recognition (NER) often contains a\nsignificant percentage of incorrect labels for entity types and entity\nboundaries. Such label noise poses challenges for supervised learning and may\nsignificantly deteriorate model quality. To address this, prior work proposed\nvarious noise-robust learning approaches capable of learning from data with\npartially incorrect labels. These approaches are typically evaluated using\nsimulated noise where the labels in a clean dataset are automatically\ncorrupted. However, as we show in this paper, this leads to unrealistic noise\nthat is far easier to handle than real noise caused by human error or\nsemi-automatic annotation. To enable the study of the impact of various types\nof real noise, we introduce NoiseBench, an NER benchmark consisting of clean\ntraining data corrupted with 6 types of real noise, including expert errors,\ncrowdsourcing errors, automatic annotation errors and LLM errors. We present an\nanalysis that shows that real noise is significantly more challenging than\nsimulated noise, and show that current state-of-the-art models for noise-robust\nlearning fall far short of their theoretically achievable upper bound. We\nrelease NoiseBench to the research community.",
      "tldr_zh": "本研究探讨了命名实体识别（Named Entity Recognition, NER）任务中真实标签噪声（如实体类型和边界错误）对模型性能的影响，指出现有噪声鲁棒性学习方法主要依赖模拟噪声，导致评估结果不切实际。论文引入NoiseBench基准，该基准使用6种真实噪声类型（包括专家错误、众包错误、自动标注错误和LLM错误）对干净训练数据进行污染，以更准确地评估噪声影响。实验分析显示，真实噪声远比模拟噪声更具挑战性，当前最先进模型的表现远低于理论上限；研究社区可使用NoiseBench进一步优化噪声鲁棒性方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "data available at https://github.com/elenamer/NoiseBench; to appear\n  at EMNLP2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2405.07609v2",
      "published_date": "2024-05-13 10:20:31 UTC",
      "updated_date": "2024-10-14 10:19:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:11:12.457591"
    },
    {
      "arxiv_id": "2405.07603v1",
      "title": "Reducing Risk for Assistive Reinforcement Learning Policies with Diffusion Models",
      "title_zh": "利用扩散模型降低辅助强化学习策略的风险",
      "authors": [
        "Andrii Tytarenko"
      ],
      "abstract": "Care-giving and assistive robotics, driven by advancements in AI, offer\npromising solutions to meet the growing demand for care, particularly in the\ncontext of increasing numbers of individuals requiring assistance. This creates\na pressing need for efficient and safe assistive devices, particularly in light\nof heightened demand due to war-related injuries. While cost has been a barrier\nto accessibility, technological progress is able to democratize these\nsolutions. Safety remains a paramount concern, especially given the intricate\ninteractions between assistive robots and humans. This study explores the\napplication of reinforcement learning (RL) and imitation learning, in improving\npolicy design for assistive robots. The proposed approach makes the risky\npolicies safer without additional environmental interactions. Through\nexperimentation using simulated environments, the enhancement of the\nconventional RL approaches in tasks related to assistive robotics is\ndemonstrated.",
      "tldr_zh": "这篇论文探讨了如何利用扩散模型（Diffusion Models）来降低辅助强化学习（RL）策略的风险，以提升护理和辅助机器人的安全性，尤其在处理战争伤残者等高需求场景中。研究提出了一种方法，通过模仿学习结合扩散模型，使风险策略在不需额外环境交互的情况下变得更可靠。实验结果显示，该方法在模拟环境中显著改善了传统 RL 在辅助机器人任务中的表现，为更安全的人机互动应用提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07603v1",
      "published_date": "2024-05-13 10:07:36 UTC",
      "updated_date": "2024-05-13 10:07:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:11:22.649009"
    },
    {
      "arxiv_id": "2405.07601v2",
      "title": "On-device Online Learning and Semantic Management of TinyML Systems",
      "title_zh": "设备上的在线学习与 TinyML 系统的语义管理",
      "authors": [
        "Haoyu Ren",
        "Xue Li",
        "Darko Anicic",
        "Thomas A. Runkler"
      ],
      "abstract": "Recent advances in Tiny Machine Learning (TinyML) empower low-footprint\nembedded devices for real-time on-device Machine Learning. While many\nacknowledge the potential benefits of TinyML, its practical implementation\npresents unique challenges. This study aims to bridge the gap between\nprototyping single TinyML models and developing reliable TinyML systems in\nproduction: (1) Embedded devices operate in dynamically changing conditions.\nExisting TinyML solutions primarily focus on inference, with models trained\noffline on powerful machines and deployed as static objects. However, static\nmodels may underperform in the real world due to evolving input data\ndistributions. We propose online learning to enable training on constrained\ndevices, adapting local models towards the latest field conditions. (2)\nNevertheless, current on-device learning methods struggle with heterogeneous\ndeployment conditions and the scarcity of labeled data when applied across\nnumerous devices. We introduce federated meta-learning incorporating online\nlearning to enhance model generalization, facilitating rapid learning. This\napproach ensures optimal performance among distributed devices by knowledge\nsharing. (3) Moreover, TinyML's pivotal advantage is widespread adoption.\nEmbedded devices and TinyML models prioritize extreme efficiency, leading to\ndiverse characteristics ranging from memory and sensors to model architectures.\nGiven their diversity and non-standardized representations, managing these\nresources becomes challenging as TinyML systems scale up. We present semantic\nmanagement for the joint management of models and devices at scale. We\ndemonstrate our methods through a basic regression example and then assess them\nin three real-world TinyML applications: handwritten character image\nclassification, keyword audio classification, and smart building presence\ndetection, confirming our approaches' effectiveness.",
      "tldr_zh": "本研究针对 TinyML 系统在实际部署中的挑战，提出在线学习方法，使嵌入式设备能够在资源受限环境下实时训练模型，以适应动态变化的输入数据分布。论文进一步引入联邦元学习结合在线学习，提升模型泛化性，通过知识共享优化分布式设备的性能；同时，开发语义管理框架，用于大规模管理异构模型和设备资源。实验通过一个基本回归示例以及三个真实应用（手写字符图像分类、关键词音频分类和智能建筑存在检测）验证了这些方法的有效性，展示了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Journal Transactions on Embedded Computing Systems (TECS)",
      "pdf_url": "http://arxiv.org/pdf/2405.07601v2",
      "published_date": "2024-05-13 10:03:34 UTC",
      "updated_date": "2024-05-15 20:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:11:34.152135"
    },
    {
      "arxiv_id": "2405.07595v1",
      "title": "Environmental Matching Attack Against Unmanned Aerial Vehicles Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Dehong Kong",
        "Siyuan Liang",
        "Wenqi Ren"
      ],
      "abstract": "Object detection techniques for Unmanned Aerial Vehicles (UAVs) rely on Deep\nNeural Networks (DNNs), which are vulnerable to adversarial attacks.\nNonetheless, adversarial patches generated by existing algorithms in the UAV\ndomain pay very little attention to the naturalness of adversarial patches.\nMoreover, imposing constraints directly on adversarial patches makes it\ndifficult to generate patches that appear natural to the human eye while\nensuring a high attack success rate. We notice that patches are natural looking\nwhen their overall color is consistent with the environment. Therefore, we\npropose a new method named Environmental Matching Attack(EMA) to address the\nissue of optimizing the adversarial patch under the constraints of color. To\nthe best of our knowledge, this paper is the first to consider natural patches\nin the domain of UAVs. The EMA method exploits strong prior knowledge of a\npretrained stable diffusion to guide the optimization direction of the\nadversarial patch, where the text guidance can restrict the color of the patch.\nTo better match the environment, the contrast and brightness of the patch are\nappropriately adjusted. Instead of optimizing the adversarial patch itself, we\noptimize an adversarial perturbation patch which initializes to zero so that\nthe model can better trade off attacking performance and naturalness.\nExperiments conducted on the DroneVehicle and Carpk datasets have shown that\nour work can reach nearly the same attack performance in the digital attack(no\ngreater than 2 in mAP$\\%$), surpass the baseline method in the physical\nspecific scenarios, and exhibit a significant advantage in terms of naturalness\nin visualization and color difference with the environment.",
      "tldr_zh": "该研究针对无人驾驶飞行器（UAVs）物体检测中的深度神经网络（DNNs）漏洞，提出了一种新的对抗攻击方法Environmental Matching Attack (EMA)，旨在生成自然外观的对抗patch，同时保持高攻击成功率。EMA利用预训练的Stable Diffusion模型的先验知识，通过文本指导优化patch的颜色，并调整对比度和亮度，以使其与环境颜色一致，而不是直接优化patch本身。实验在DroneVehicle和Carpk数据集上显示，EMA在数字攻击中mAP下降不超过2%，在物理场景中超越基线方法，并在视觉和颜色差异方面表现出显著优势，从而首次在UAV领域实现了自然对抗patch的平衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07595v1",
      "published_date": "2024-05-13 09:56:57 UTC",
      "updated_date": "2024-05-13 09:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:11:47.178853"
    },
    {
      "arxiv_id": "2405.07590v1",
      "title": "Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data",
      "title_zh": "翻译失败",
      "authors": [
        "Camelia Oprea",
        "Mike Grüne",
        "Mateusz Buglowski",
        "Lena Olivier",
        "Thorsten Orlikowsky",
        "Stefan Kowalewski",
        "Mark Schoberer",
        "André Stollenwerk"
      ],
      "abstract": "With the digitalization of health care systems, artificial intelligence\nbecomes more present in medicine. Especially machine learning shows great\npotential for complex tasks such as time series classification, usually at the\ncost of transparency and comprehensibility. This leads to a lack of trust by\nhumans and thus hinders its active usage. Explainable artificial intelligence\ntries to close this gap by providing insight into the decision-making process,\nthe actual usefulness of its different methods is however unclear. This paper\nproposes a user study based evaluation of the explanation method Grad-CAM with\napplication to a neural network for the classification of breaths in time\nseries neonatal ventilation data. We present the perceived usefulness of the\nexplainability method by different stakeholders, exposing the difficulty to\nachieve actual transparency and the wish for more in-depth explanations by many\nof the participants.",
      "tldr_zh": "该论文评估了可解释AI方法Grad-CAM在新生儿时间序列数据呼吸分类任务中的有效性，旨在解决AI模型透明度和可理解性问题。研究使用Grad-CAM解释神经网络对新生儿通气数据中呼吸类型的分类决策，并通过用户研究调查不同利益相关者对这些解释的感知有用性。结果显示，Grad-CAM难以提供真正的透明度，许多参与者希望获得更深入的解释，从而突显了在医疗AI中提升解释性的必要性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "I.2.1; K.4.m; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "\\c{opyright} 2024 The authors. This work has been accepted to IFAC\n  for publication under a Creative Commons Licence CC-BY-NC-ND. Accepted for\n  the 12th IFAC Symposium on Biological and Medical Systems. 6 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07590v1",
      "published_date": "2024-05-13 09:53:25 UTC",
      "updated_date": "2024-05-13 09:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:11:57.780815"
    },
    {
      "arxiv_id": "2405.08041v1",
      "title": "DeepFMEA -- A Scalable Framework Harmonizing Process Expertise and Data-Driven PHM",
      "title_zh": "翻译失败",
      "authors": [
        "Christoph Netsch",
        "Till Schöpe",
        "Benedikt Schindele",
        "Joyam Jayakumar"
      ],
      "abstract": "Machine Learning (ML) based prognostics and health monitoring (PHM) tools\nprovide new opportunities for manufacturers to operate and maintain their\nequipment in a risk-optimized manner and utilize it more sustainably along its\nlifecycle. Yet, in most industrial settings, data is often limited in quantity,\nand its quality can be inconsistent - both critical for developing and\noperating reliable ML models. To bridge this gap in practice, successfully\nindustrialized PHM tools rely on the introduction of domain expertise as a\nprior, to enable sufficiently accurate predictions, while enhancing their\ninterpretability.\n  Thus, a key challenge while developing data-driven PHM tools involves\ntranslating the experience and process knowledge of maintenance personnel,\ndevelopment, and service engineers into a data structure. This structure must\nnot only capture the diversity and variability of the expertise but also render\nthis knowledge accessible for various data-driven algorithms. This results in\ndata models that are heavily tailored towards a specific application and the\nfailure modes the development team aims to detect or predict. The lack of a\nstandardized approach limits developments' extensibility to new failure modes,\ntheir transferability to new applications, and it inhibits the utilization of\nstandard data management and MLOps tools, increasing the burden on the\ndevelopment team.\n  DeepFMEA draws inspiration from the Failure Mode and Effects Analysis (FMEA)\nin its structured approach to the analysis of any technical system and the\nresulting standardized data model, while considering aspects that are crucial\nto capturing process and maintenance expertise in a way that is both intuitive\nto domain experts and the resulting information can be introduced as priors to\nML algorithms.",
      "tldr_zh": "DeepFMEA 提出了一种可扩展框架，将过程专家知识与数据驱动的预测性健康监测（PHM）相结合，解决机器学习（ML）模型在工业应用中数据量有限和质量不一致的问题。框架借鉴故障模式与影响分析（FMEA）的结构化方法，将维护人员和工程师的经验转化为标准数据模型，使其易于融入 ML 算法作为先验知识。相比传统方法，DeepFMEA 提升了 PHM 工具的准确性、解释性和可转移性，支持新故障模式的扩展以及标准数据管理和 MLOps 的应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.08041v1",
      "published_date": "2024-05-13 09:41:34 UTC",
      "updated_date": "2024-05-13 09:41:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:12:10.690215"
    },
    {
      "arxiv_id": "2405.07580v1",
      "title": "DynLLM: When Large Language Models Meet Dynamic Graph Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Zhao",
        "Fake Lin",
        "Xi Zhu",
        "Zhi Zheng",
        "Tong Xu",
        "Shitian Shen",
        "Xueying Li",
        "Zikai Yin",
        "Enhong Chen"
      ],
      "abstract": "Last year has witnessed the considerable interest of Large Language Models\n(LLMs) for their potential applications in recommender systems, which may\nmitigate the persistent issue of data sparsity. Though large efforts have been\nmade for user-item graph augmentation with better graph-based recommendation\nperformance, they may fail to deal with the dynamic graph recommendation task,\nwhich involves both structural and temporal graph dynamics with inherent\ncomplexity in processing time-evolving data. To bridge this gap, in this paper,\nwe propose a novel framework, called DynLLM, to deal with the dynamic graph\nrecommendation task with LLMs. Specifically, DynLLM harnesses the power of LLMs\nto generate multi-faceted user profiles based on the rich textual features of\nhistorical purchase records, including crowd segments, personal interests,\npreferred categories, and favored brands, which in turn supplement and enrich\nthe underlying relationships between users and items. Along this line, to fuse\nthe multi-faceted profiles with temporal graph embedding, we engage LLMs to\nderive corresponding profile embeddings, and further employ a distilled\nattention mechanism to refine the LLM-generated profile embeddings for\nalleviating noisy signals, while also assessing and adjusting the relevance of\neach distilled facet embedding for seamless integration with temporal graph\nembedding from continuous time dynamic graphs (CTDGs). Extensive experiments on\ntwo real e-commerce datasets have validated the superior improvements of DynLLM\nover a wide range of state-of-the-art baseline methods.",
      "tldr_zh": "本文提出 DynLLM 框架，将 Large Language Models (LLMs) 应用于动态图推荐任务，以解决数据稀疏问题和处理结构及时间动态的复杂性。DynLLM 通过 LLMs 基于用户历史购买记录生成多方面的用户配置文件（如人群细分、个人兴趣、偏好类别和品牌），并将这些配置文件嵌入与 Continuous Time Dynamic Graphs (CTDGs) 的嵌入整合，使用蒸馏注意力机制（distilled attention mechanism）减少噪声信号并优化相关性。在两个真实电商数据集上的实验显示，DynLLM 显著优于多种最先进基线方法，提高了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07580v1",
      "published_date": "2024-05-13 09:36:17 UTC",
      "updated_date": "2024-05-13 09:36:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:12:23.280800"
    },
    {
      "arxiv_id": "2405.13008v1",
      "title": "Control Token with Dense Passage Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Juhwan Lee",
        "Jisu Kim"
      ],
      "abstract": "This study addresses the hallucination problem in large language models\n(LLMs). We adopted Retrieval-Augmented Generation(RAG) (Lewis et al., 2020), a\ntechnique that involves embedding relevant information in the prompt to obtain\naccurate answers. However, RAG also faced inherent issues in retrieving correct\ninformation. To address this, we employed the Dense Passage Retrieval(DPR)\n(Karpukhin et al., 2020) model for fetching domain-specific documents related\nto user queries. Despite this, the DPR model still lacked accuracy in document\nretrieval. We enhanced the DPR model by incorporating control tokens, achieving\nsignificantly superior performance over the standard DPR model, with a 13%\nimprovement in Top-1 accuracy and a 4% improvement in Top-20 accuracy.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)中的幻觉问题，采用了检索增强生成(RAG)技术来嵌入相关信息以获得准确答案。然而，RAG在检索正确信息方面存在局限，因此研究者使用了密集通道检索(DPR)模型来获取与用户查询相关的领域特定文档，并通过加入control tokens对DPR进行了增强。实验结果显示，增强后的DPR模型在Top-1准确率上提高了13%，在Top-20准确率上提高了4%，显著提升了整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13008v1",
      "published_date": "2024-05-13 09:17:19 UTC",
      "updated_date": "2024-05-13 09:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:12:35.511919"
    },
    {
      "arxiv_id": "2405.13007v1",
      "title": "News Recommendation with Category Description by a Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yuki Yada",
        "Hayato Yamana"
      ],
      "abstract": "Personalized news recommendations are essential for online news platforms to\nassist users in discovering news articles that match their interests from a\nvast amount of online content. Appropriately encoded content features, such as\ntext, categories, and images, are essential for recommendations. Among these\nfeatures, news categories, such as tv-golden-globe, finance-real-estate, and\nnews-politics, play an important role in understanding news content, inspiring\nus to enhance the categories' descriptions. In this paper, we propose a novel\nmethod that automatically generates informative category descriptions using a\nlarge language model (LLM) without manual effort or domain-specific knowledge\nand incorporates them into recommendation models as additional information. In\nour comprehensive experimental evaluations using the MIND dataset, our method\nsuccessfully achieved 5.8% improvement at most in AUC compared with baseline\napproaches without the LLM's generated category descriptions for the\nstate-of-the-art content-based recommendation models including NAML, NRMS, and\nNPA. These results validate the effectiveness of our approach. The code is\navailable at https://github.com/yamanalab/gpt-augmented-news-recommendation.",
      "tldr_zh": "这篇论文提出了一种使用 Large Language Model (LLM) 自动生成新闻类别描述的方法，以提升个性化新闻推荐系统的性能，而无需手动干预或领域特定知识。方法将生成的描述作为额外信息整合到现有推荐模型中，如 NAML、NRMS 和 NPA。实验在 MIND 数据集上显示，与基线模型相比，AUC 指标最多提高了 5.8%，验证了该方法的有效性。代码已开源在 GitHub 上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13007v1",
      "published_date": "2024-05-13 08:53:43 UTC",
      "updated_date": "2024-05-13 08:53:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:12:46.970917"
    },
    {
      "arxiv_id": "2405.07562v1",
      "title": "GLiRA: Black-Box Membership Inference Attack via Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Andrey V. Galichin",
        "Mikhail Pautov",
        "Alexey Zhavoronkin",
        "Oleg Y. Rogov",
        "Ivan Oseledets"
      ],
      "abstract": "While Deep Neural Networks (DNNs) have demonstrated remarkable performance in\ntasks related to perception and control, there are still several unresolved\nconcerns regarding the privacy of their training data, particularly in the\ncontext of vulnerability to Membership Inference Attacks (MIAs). In this paper,\nwe explore a connection between the susceptibility to membership inference\nattacks and the vulnerability to distillation-based functionality stealing\nattacks. In particular, we propose {GLiRA}, a distillation-guided approach to\nmembership inference attack on the black-box neural network. We observe that\nthe knowledge distillation significantly improves the efficiency of likelihood\nratio of membership inference attack, especially in the black-box setting,\ni.e., when the architecture of the target model is unknown to the attacker. We\nevaluate the proposed method across multiple image classification datasets and\nmodels and demonstrate that likelihood ratio attacks when guided by the\nknowledge distillation, outperform the current state-of-the-art membership\ninference attacks in the black-box setting.",
      "tldr_zh": "本论文探讨了深度神经网络(DNNs)在隐私方面的问题，特别是易受Membership Inference Attacks (MIAs)的影响，并提出GLiRA，一种基于知识蒸馏的黑箱MIAs方法。GLiRA通过知识蒸馏指导似然比攻击，显著提升了攻击效率，尤其在攻击者未知目标模型架构的黑箱场景中。实验结果显示，在多个图像分类数据集和模型上，GLiRA超过了现有最先进MIAs方法的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07562v1",
      "published_date": "2024-05-13 08:52:04 UTC",
      "updated_date": "2024-05-13 08:52:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:12:59.231118"
    },
    {
      "arxiv_id": "2405.07551v1",
      "title": "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Yin",
        "Weihao You",
        "Zhilong Ji",
        "Guoqiang Zhong",
        "Jinfeng Bai"
      ],
      "abstract": "The tool-use Large Language Models (LLMs) that integrate with external Python\ninterpreters have significantly enhanced mathematical reasoning capabilities\nfor open-source LLMs, while tool-free methods chose another track: augmenting\nmath reasoning data. However, a great method to integrate the above two\nresearch paths and combine their advantages remains to be explored. In this\nwork, we firstly include new math questions via multi-perspective data\naugmenting methods and then synthesize code-nested solutions to them. The open\nLLMs (i.e., Llama-2) are finetuned on the augmented dataset to get the\nresulting models, MuMath-Code ($\\mu$-Math-Code). During the inference phase,\nour MuMath-Code generates code and interacts with the external python\ninterpreter to get the execution results. Therefore, MuMath-Code leverages the\nadvantages of both the external tool and data augmentation. To fully leverage\nthe advantages of our augmented data, we propose a two-stage training strategy:\nIn Stage-1, we finetune Llama-2 on pure CoT data to get an intermediate model,\nwhich then is trained on the code-nested data in Stage-2 to get the resulting\nMuMath-Code. Our MuMath-Code-7B achieves 83.8 on GSM8K and 52.4 on MATH, while\nMuMath-Code-70B model achieves new state-of-the-art performance among open\nmethods -- achieving 90.7% on GSM8K and 55.1% on MATH. Extensive experiments\nvalidate the combination of tool use and data augmentation, as well as our\ntwo-stage training strategy. We release the proposed dataset along with the\nassociated code for public use.",
      "tldr_zh": "本研究提出 MuMath-Code 框架，通过结合工具使用 Large Language Models (LLMs) 与多视角数据增强方法，提升开源 LLMs 的数学推理能力。具体方法包括使用多视角数据增强生成新数学问题、合成代码嵌套解决方案，并采用两阶段训练策略：先在纯 Chain-of-Thought (CoT) 数据上微调 Llama-2，然后在代码嵌套数据上进一步训练。推理阶段，MuMath-Code 通过外部 Python 解释器执行代码，从而整合工具和数据增强的优势。实验结果显示，MuMath-Code-7B 在 GSM8K 上达到 83.8%、在 MATH 上达到 52.4%，而 MuMath-Code-70B 则在这些基准上实现新的开源最先进性能（90.7% 和 55.1%），并公开了数据集和代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The state-of-the-art open-source tool-use LLMs for mathematical\n  reasoning",
      "pdf_url": "http://arxiv.org/pdf/2405.07551v1",
      "published_date": "2024-05-13 08:32:19 UTC",
      "updated_date": "2024-05-13 08:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:13:12.762089"
    },
    {
      "arxiv_id": "2405.07541v4",
      "title": "Walk model that continuously generates Brownian walks to Lévy walks depending on destination attractiveness",
      "title_zh": "翻译失败",
      "authors": [
        "Shuji Shinohara",
        "Daiki Morita",
        "Hayato Hirai",
        "Ryosuke Kuribayashi",
        "Nobuhito Manome",
        "Toru Moriyama",
        "Hiroshi Okamoto",
        "Yoshihiro Nakajima",
        "Yukio-Pegio Gunji",
        "Ung-il Chung"
      ],
      "abstract": "The L\\'evy walk, a type of random walk characterized by linear step lengths\nthat follow a power-law distribution, is observed in the migratory behaviors of\nvarious organisms, ranging from bacteria to humans. Notably, L\\'evy walks with\npower exponents close to two, also known as Cauchy walks, are frequently\nobserved, though their underlying causes remain elusive. This study proposes a\nwalk model in which agents move toward a destination in multi-dimensional space\nand their movement strategy is parameterized by the extent to which they pursue\nthe shortest path to the destination. This parameter is taken to represent the\nattractiveness of the destination to the agents. Our findings reveal that if\nthe destination is very attractive, agents intensively search the area around\nit using Brownian walks, whereas if the destination is unattractive, they\nexplore a distant region away from the point using L\\'evy walks with power\nexponents less than two. In the case where agents are unable to determine\nwhether the destination is attractive or unattractive, Cauchy walks emerge. The\nCauchy walker searches the region with a probability inversely proportional to\nthe distance from the destination. This suggests that it preferentially\nsearches the area close to the destination, while concurrently having the\npotential to extend the search area much further. Our model, which can change\nthe search method and search area depending on the attractiveness of the\ndestination, has the potential to be utilized for exploring the parameter space\nof optimization problems.",
      "tldr_zh": "本论文提出一个新型走模型，根据目的地吸引力，代理在多维空间中从 Brownian walks 到 Lévy walks 连续生成移动策略，该策略由代理追求最短路径的程度参数化，以代表目的地吸引力。研究发现，如果目的地高度吸引人，代理会采用 Brownian walks 密集搜索周边区域；若吸引力低，则使用幂指数小于2的 Lévy walks 探索远区；当吸引力不确定时，会出现 Cauchy walks，这种走法以与距离成反比的概率优先搜索近处区域，同时具备扩展搜索的潜力。该模型可根据吸引力动态调整搜索方法和区域，具有应用于优化问题参数空间探索的潜力。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07541v4",
      "published_date": "2024-05-13 08:22:44 UTC",
      "updated_date": "2024-09-12 01:31:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:13:23.650183"
    },
    {
      "arxiv_id": "2405.07527v1",
      "title": "Train Faster, Perform Better: Modular Adaptive Training in Over-Parameterized Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yubin Shi",
        "Yixuan Chen",
        "Mingzhi Dong",
        "Xiaochen Yang",
        "Dongsheng Li",
        "Yujiang Wang",
        "Robert P. Dick",
        "Qin Lv",
        "Yingying Zhao",
        "Fan Yang",
        "Tun Lu",
        "Ning Gu",
        "Li Shang"
      ],
      "abstract": "Despite their prevalence in deep-learning communities, over-parameterized\nmodels convey high demands of computational costs for proper training. This\nwork studies the fine-grained, modular-level learning dynamics of\nover-parameterized models to attain a more efficient and fruitful training\nstrategy. Empirical evidence reveals that when scaling down into network\nmodules, such as heads in self-attention models, we can observe varying\nlearning patterns implicitly associated with each module's trainability. To\ndescribe such modular-level learning capabilities, we introduce a novel concept\ndubbed modular neural tangent kernel (mNTK), and we demonstrate that the\nquality of a module's learning is tightly associated with its mNTK's principal\neigenvalue $\\lambda_{\\max}$. A large $\\lambda_{\\max}$ indicates that the module\nlearns features with better convergence, while those miniature ones may impact\ngeneralization negatively. Inspired by the discovery, we propose a novel\ntraining strategy termed Modular Adaptive Training (MAT) to update those\nmodules with their $\\lambda_{\\max}$ exceeding a dynamic threshold selectively,\nconcentrating the model on learning common features and ignoring those\ninconsistent ones. Unlike most existing training schemes with a complete BP\ncycle across all network modules, MAT can significantly save computations by\nits partially-updating strategy and can further improve performance.\nExperiments show that MAT nearly halves the computational cost of model\ntraining and outperforms the accuracy of baselines.",
      "tldr_zh": "该研究针对过参数化模型的训练计算成本高的问题，分析了模块级学习动态，发现不同模块的学习能力与 modular neural tangent kernel (mNTK) 的主特征值 λ_max 密切相关，高 λ_max 模块的学习收敛更好。基于这一发现，他们提出了 Modular Adaptive Training (MAT) 策略，通过选择性地更新 λ_max 超过动态阈值的模块，专注于高效学习共同特征，从而减少不必要的计算。实验结果表明，MAT 几乎减半了训练计算成本，同时提高了模型的准确率表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.07527v1",
      "published_date": "2024-05-13 07:46:48 UTC",
      "updated_date": "2024-05-13 07:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:13:36.380839"
    },
    {
      "arxiv_id": "2405.07523v1",
      "title": "Adaptation of Distinct Semantics for Uncertain Areas in Polyp Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Quang Vinh Nguyen",
        "Van Thong Huynh",
        "Soo-Hyung Kim"
      ],
      "abstract": "Colonoscopy is a common and practical method for detecting and treating\npolyps. Segmenting polyps from colonoscopy image is useful for diagnosis and\nsurgery progress. Nevertheless, achieving excellent segmentation performance is\nstill difficult because of polyp characteristics like shape, color, condition,\nand obvious non-distinction from the surrounding context. This work presents a\nnew novel architecture namely Adaptation of Distinct Semantics for Uncertain\nAreas in Polyp Segmentation (ADSNet), which modifies misclassified details and\nrecovers weak features having the ability to vanish and not be detected at the\nfinal stage. The architecture consists of a complementary trilateral decoder to\nproduce an early global map. A continuous attention module modifies semantics\nof high-level features to analyze two separate semantics of the early global\nmap. The suggested method is experienced on polyp benchmarks in learning\nability and generalization ability, experimental results demonstrate the great\ncorrection and recovery ability leading to better segmentation performance\ncompared to the other state of the art in the polyp image segmentation task.\nEspecially, the proposed architecture could be experimented flexibly for other\nCNN-based encoders, Transformer-based encoders, and decoder backbones.",
      "tldr_zh": "本研究针对结肠镜图像中息肉分割的挑战（如息肉的形状、颜色和与周围环境的相似性），提出了一种新架构Adaptation of Distinct Semantics for Uncertain Areas in Polyp Segmentation (ADSNet)，旨在修正错误分类并恢复弱特征。ADSNet 包括一个 complementary trilateral decoder 用于生成早期的全局地图，以及一个 continuous attention module 来修改高层特征的语义并分析两个独立语义。实验结果显示，该方法在息肉基准数据集上表现出色，比现有最先进方法具有更好的分割性能，且可灵活与其他 CNN-based encoders、Transformer-based encoders 和解码器骨干结合。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.5.4, I.2.1, I.4.6, J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages with 7 figures, British Machine Vision Conference 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.07523v1",
      "published_date": "2024-05-13 07:41:28 UTC",
      "updated_date": "2024-05-13 07:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:13:48.370087"
    },
    {
      "arxiv_id": "2405.07518v2",
      "title": "SambaNova SN40L: Scaling the AI Memory Wall with Dataflow and Composition of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Raghu Prabhakar",
        "Ram Sivaramakrishnan",
        "Darshan Gandhi",
        "Yun Du",
        "Mingran Wang",
        "Xiangyu Song",
        "Kejie Zhang",
        "Tianren Gao",
        "Angela Wang",
        "Karen Li",
        "Yongning Sheng",
        "Joshua Brot",
        "Denis Sokolov",
        "Apurv Vivek",
        "Calvin Leung",
        "Arjun Sabnis",
        "Jiayu Bai",
        "Tuowen Zhao",
        "Mark Gottscho",
        "David Jackson",
        "Mark Luttrell",
        "Manish K. Shah",
        "Edison Chen",
        "Kaizhao Liang",
        "Swayambhoo Jain",
        "Urmish Thakker",
        "Dawei Huang",
        "Sumti Jairath",
        "Kevin J. Brown",
        "Kunle Olukotun"
      ],
      "abstract": "Monolithic large language models (LLMs) like GPT-4 have paved the way for\nmodern generative AI applications. Training, serving, and maintaining\nmonolithic LLMs at scale, however, remains prohibitively expensive and\nchallenging. The disproportionate increase in compute-to-memory ratio of modern\nAI accelerators have created a memory wall, necessitating new methods to deploy\nAI. Composition of Experts (CoE) is an alternative modular approach that lowers\nthe cost and complexity of training and serving. However, this approach\npresents two key challenges when using conventional hardware: (1) without fused\noperations, smaller models have lower operational intensity, which makes high\nutilization more challenging to achieve; and (2) hosting a large number of\nmodels can be either prohibitively expensive or slow when dynamically switching\nbetween them.\n  In this paper, we describe how combining CoE, streaming dataflow, and a\nthree-tier memory system scales the AI memory wall. We describe Samba-CoE, a\nCoE system with 150 experts and a trillion total parameters. We deploy\nSamba-CoE on the SambaNova SN40L Reconfigurable Dataflow Unit (RDU) - a\ncommercial dataflow accelerator architecture that has been co-designed for\nenterprise inference and training applications. The chip introduces a new\nthree-tier memory system with on-chip distributed SRAM, on-package HBM, and\noff-package DDR DRAM. A dedicated inter-RDU network enables scaling up and out\nover multiple sockets. We demonstrate speedups ranging from 2$\\times$ to\n13$\\times$ on various benchmarks running on eight RDU sockets compared with an\nunfused baseline. We show that for CoE inference deployments, the 8-socket RDU\nNode reduces machine footprint by up to 19$\\times$, speeds up model switching\ntime by 15$\\times$ to 31$\\times$, and achieves an overall speedup of\n3.7$\\times$ over a DGX H100 and 6.6$\\times$ over a DGX A100.",
      "tldr_zh": "该论文探讨了训练和部署大型语言模型（LLMs）的挑战，特别是AI内存墙问题，提出了一种结合Composition of Experts (CoE)、streaming dataflow和三层内存系统（包括on-chip SRAM、on-package HBM和off-package DDR DRAM）的解决方案，以降低成本并提高效率。研究开发了Samba-CoE系统，包含150个专家和万亿级参数，并部署在SambaNova SN40L Reconfigurable Dataflow Unit (RDU)上，该架构支持多插槽扩展。实验结果显示，与基线相比，SN40L在各种基准测试中实现了2倍至13倍的速度提升，并在CoE推理部署中，减少机器占用空间高达19倍，加速模型切换时间15倍至31倍，总性能比DGX H100快3.7倍、比DGX A100快6.6倍。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "C.1.3; C.0"
      ],
      "primary_category": "cs.AR",
      "comment": "2024 57th IEEE/ACM International Symposium on Microarchitecture\n  (MICRO)",
      "pdf_url": "http://arxiv.org/pdf/2405.07518v2",
      "published_date": "2024-05-13 07:32:45 UTC",
      "updated_date": "2024-11-05 02:53:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:14:01.098974"
    },
    {
      "arxiv_id": "2405.07515v1",
      "title": "OpenBot-Fleet: A System for Collective Learning with Real Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Müller",
        "Samarth Brahmbhatt",
        "Ankur Deka",
        "Quentin Leboutet",
        "David Hafner",
        "Vladlen Koltun"
      ],
      "abstract": "We introduce OpenBot-Fleet, a comprehensive open-source cloud robotics system\nfor navigation. OpenBot-Fleet uses smartphones for sensing, local compute and\ncommunication, Google Firebase for secure cloud storage and off-board compute,\nand a robust yet low-cost wheeled robot toact in real-world environments. The\nrobots collect task data and upload it to the cloud where navigation policies\ncan be learned either offline or online and can then be sent back to the robot\nfleet. In our experiments we distribute 72 robots to a crowd of workers who\noperate them in homes, and show that OpenBot-Fleet can learn robust navigation\npolicies that generalize to unseen homes with >80% success rate. OpenBot-Fleet\nrepresents a significant step forward in cloud robotics, making it possible to\ndeploy large continually learning robot fleets in a cost-effective and scalable\nmanner. All materials can be found at https://www.openbot.org. A video is\navailable at https://youtu.be/wiv2oaDgDi8",
      "tldr_zh": "该研究介绍了 OpenBot-Fleet，一个开源的云机器人系统，用于实现真实机器人的集体学习。该系统利用智能手机进行感知、本地计算和通信，结合 Google Firebase 的云存储和离线计算，以及低成本轮式机器人，在真实环境中收集任务数据并上传到云端进行导航策略的在线或离线学习。实验中，72 个机器人由众包工人操作，系统成功学习了鲁棒的导航策略，在未见过的家庭环境中实现超过 80% 的成功率。OpenBot-Fleet 推动了 cloud robotics 的发展，使大规模持续学习的机器人群部署变得经济且可扩展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at ICRA'24",
      "pdf_url": "http://arxiv.org/pdf/2405.07515v1",
      "published_date": "2024-05-13 07:22:50 UTC",
      "updated_date": "2024-05-13 07:22:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:14:12.459852"
    },
    {
      "arxiv_id": "2405.07509v1",
      "title": "RESTAD: REconstruction and Similarity based Transformer for time series Anomaly Detection",
      "title_zh": "RESTAD：基于重构和相似性的 Transformer 用于",
      "authors": [
        "Ramin Ghorbani",
        "Marcel J. T. Reinders",
        "David M. J. Tax"
      ],
      "abstract": "Anomaly detection in time series data is crucial across various domains. The\nscarcity of labeled data for such tasks has increased the attention towards\nunsupervised learning methods. These approaches, often relying solely on\nreconstruction error, typically fail to detect subtle anomalies in complex\ndatasets. To address this, we introduce RESTAD, an adaptation of the\nTransformer model by incorporating a layer of Radial Basis Function (RBF)\nneurons within its architecture. This layer fits a non-parametric density in\nthe latent representation, such that a high RBF output indicates similarity\nwith predominantly normal training data. RESTAD integrates the RBF similarity\nscores with the reconstruction errors to increase sensitivity to anomalies. Our\nempirical evaluations demonstrate that RESTAD outperforms various established\nbaselines across multiple benchmark datasets.",
      "tldr_zh": "该论文针对时间序列异常检测问题，指出传统无监督方法依赖重构错误往往无法识别复杂数据集中的微妙异常。RESTAD 模型基于 Transformer 架构，引入 Radial Basis Function (RBF) 神经元层来拟合潜在表示的非参数密度，并将 RBF 相似性分数与重构错误整合，以提升对异常的敏感性。实验结果表明，RESTAD 在多个基准数据集上优于现有基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Manuscript under review",
      "pdf_url": "http://arxiv.org/pdf/2405.07509v1",
      "published_date": "2024-05-13 07:10:35 UTC",
      "updated_date": "2024-05-13 07:10:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:14:24.018717"
    },
    {
      "arxiv_id": "2405.08038v1",
      "title": "Feature Expansion and enhanced Compression for Class Incremental Learning",
      "title_zh": "特征扩展和增强压缩用于类增量学习",
      "authors": [
        "Quentin Ferdinand",
        "Gilles Le Chenadec",
        "Benoit Clement",
        "Panagiotis Papadakis",
        "Quentin Oliveau"
      ],
      "abstract": "Class incremental learning consists in training discriminative models to\nclassify an increasing number of classes over time. However, doing so using\nonly the newly added class data leads to the known problem of catastrophic\nforgetting of the previous classes. Recently, dynamic deep learning\narchitectures have been shown to exhibit a better stability-plasticity\ntrade-off by dynamically adding new feature extractors to the model in order to\nlearn new classes followed by a compression step to scale the model back to its\noriginal size, thus avoiding a growing number of parameters. In this context,\nwe propose a new algorithm that enhances the compression of previous class\nknowledge by cutting and mixing patches of previous class samples with the new\nimages during compression using our Rehearsal-CutMix method. We show that this\nnew data augmentation reduces catastrophic forgetting by specifically targeting\npast class information and improving its compression. Extensive experiments\nperformed on the CIFAR and ImageNet datasets under diverse incremental learning\nevaluation protocols demonstrate that our approach consistently outperforms the\nstate-of-the-art . The code will be made available upon publication of our\nwork.",
      "tldr_zh": "该论文针对Class Incremental Learning（类增量学习）中的灾难性遗忘（catastrophic forgetting）问题，提出了一种新算法，通过动态添加特征提取器来学习新类，并引入Rehearsal-CutMix方法在压缩步骤中切割和混合旧类样本的补丁与新图像，从而增强对过去类知识的压缩。Rehearsal-CutMix作为一种数据增强技术，专门针对旧类信息进行优化，提高了模型的稳定性-可塑性权衡。实验结果显示，该方法在CIFAR和ImageNet数据集上的多种增量学习协议中， consistently outperforms the state-of-the-art基准，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08038v1",
      "published_date": "2024-05-13 06:57:18 UTC",
      "updated_date": "2024-05-13 06:57:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:14:36.068547"
    },
    {
      "arxiv_id": "2405.07503v2",
      "title": "Consistency Policy: Accelerated Visuomotor Policies via Consistency Distillation",
      "title_zh": "一致性策略：通过一致性蒸馏加速视觉运动策略",
      "authors": [
        "Aaditya Prasad",
        "Kevin Lin",
        "Jimmy Wu",
        "Linqi Zhou",
        "Jeannette Bohg"
      ],
      "abstract": "Many robotic systems, such as mobile manipulators or quadrotors, cannot be\nequipped with high-end GPUs due to space, weight, and power constraints. These\nconstraints prevent these systems from leveraging recent developments in\nvisuomotor policy architectures that require high-end GPUs to achieve fast\npolicy inference. In this paper, we propose Consistency Policy, a faster and\nsimilarly powerful alternative to Diffusion Policy for learning visuomotor\nrobot control. By virtue of its fast inference speed, Consistency Policy can\nenable low latency decision making in resource-constrained robotic setups. A\nConsistency Policy is distilled from a pretrained Diffusion Policy by enforcing\nself-consistency along the Diffusion Policy's learned trajectories. We compare\nConsistency Policy with Diffusion Policy and other related speed-up methods\nacross 6 simulation tasks as well as three real-world tasks where we\ndemonstrate inference on a laptop GPU. For all these tasks, Consistency Policy\nspeeds up inference by an order of magnitude compared to the fastest\nalternative method and maintains competitive success rates. We also show that\nthe Conistency Policy training procedure is robust to the pretrained Diffusion\nPolicy's quality, a useful result that helps practioners avoid extensive\ntesting of the pretrained model. Key design decisions that enabled this\nperformance are the choice of consistency objective, reduced initial sample\nvariance, and the choice of preset chaining steps.",
      "tldr_zh": "该论文提出 Consistency Policy，一种通过一致性蒸馏（Consistency Distillation）加速视觉运动策略（visuomotor policies）的框架，用于资源受限的机器人系统，如无法配备高端 GPU 的移动机械臂或四旋翼无人机。方法涉及从预训练的 Diffusion Policy 中蒸馏模型，确保沿学习轨迹的自一致性，并通过一致性目标（consistency objective）、减少初始样本方差（reduced initial sample variance）和预设链式步骤（preset chaining steps）优化性能。实验结果显示，在6个模拟任务和3个真实世界任务上，Consistency Policy 比其他方法推理速度提高一个数量级，同时保持竞争性的成功率，且其训练过程对预训练模型质量具有鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "https://consistency-policy.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.07503v2",
      "published_date": "2024-05-13 06:53:42 UTC",
      "updated_date": "2024-06-28 21:56:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:14:48.587048"
    },
    {
      "arxiv_id": "2405.07500v1",
      "title": "PromptLink: Leveraging Large Language Models for Cross-Source Biomedical Concept Linking",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhang Xie",
        "Jiaying Lu",
        "Joyce Ho",
        "Fadi Nahab",
        "Xiao Hu",
        "Carl Yang"
      ],
      "abstract": "Linking (aligning) biomedical concepts across diverse data sources enables\nvarious integrative analyses, but it is challenging due to the discrepancies in\nconcept naming conventions. Various strategies have been developed to overcome\nthis challenge, such as those based on string-matching rules, manually crafted\nthesauri, and machine learning models. However, these methods are constrained\nby limited prior biomedical knowledge and can hardly generalize beyond the\nlimited amounts of rules, thesauri, or training samples. Recently, large\nlanguage models (LLMs) have exhibited impressive results in diverse biomedical\nNLP tasks due to their unprecedentedly rich prior knowledge and strong\nzero-shot prediction abilities. However, LLMs suffer from issues including high\ncosts, limited context length, and unreliable predictions. In this research, we\npropose PromptLink, a novel biomedical concept linking framework that leverages\nLLMs. It first employs a biomedical-specialized pre-trained language model to\ngenerate candidate concepts that can fit in the LLM context windows. Then it\nutilizes an LLM to link concepts through two-stage prompts, where the\nfirst-stage prompt aims to elicit the biomedical prior knowledge from the LLM\nfor the concept linking task and the second-stage prompt enforces the LLM to\nreflect on its own predictions to further enhance their reliability. Empirical\nresults on the concept linking task between two EHR datasets and an external\nbiomedical KG demonstrate the effectiveness of PromptLink. Furthermore,\nPromptLink is a generic framework without reliance on additional prior\nknowledge, context, or training data, making it well-suited for concept linking\nacross various types of data sources. The source code is available at\nhttps://github.com/constantjxyz/PromptLink.",
      "tldr_zh": "这篇论文提出了 PromptLink 框架，利用 Large Language Models (LLMs) 来解决生物医学概念在不同数据源间的链接问题，该问题因命名约定不一致而难以处理。PromptLink 的方法包括先用生物医学预训练语言模型生成候选概念，以适应 LLM 的上下文窗口，然后通过两阶段提示：第一阶段提取 LLM 的生物医学先验知识进行概念链接，第二阶段让 LLM 反思预测以提升可靠性。实验结果显示，PromptLink 在 EHR 数据集和外部生物医学知识图谱 (KG) 上表现出色，显著提高了链接准确性。该框架通用性强，不依赖额外知识或训练数据，适用于各种跨源场景。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07500v1",
      "published_date": "2024-05-13 06:36:30 UTC",
      "updated_date": "2024-05-13 06:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:15:00.686938"
    },
    {
      "arxiv_id": "2405.07495v1",
      "title": "MacBehaviour: An R package for behavioural experimentation on large language models",
      "title_zh": "MacBehaviour：用于大语言模型行为实验的 R 包",
      "authors": [
        "Xufeng Duan",
        "Shixuan Li",
        "Zhenguang G. Cai1"
      ],
      "abstract": "There has been increasing interest in investigating the behaviours of large\nlanguage models (LLMs) and LLM-powered chatbots by treating an LLM as a\nparticipant in a psychological experiment. We therefore developed an R package\ncalled \"MacBehaviour\" that aims to interact with more than 60 language models\nin one package (e.g., OpenAI's GPT family, the Claude family, Gemini, Llama\nfamily, and open-source models) and streamline the experimental process of LLMs\nbehaviour experiments. The package offers a comprehensive set of functions\ndesigned for LLM experiments, covering experiment design, stimuli presentation,\nmodel behaviour manipulation, logging response and token probability. To\ndemonstrate the utility and effectiveness of \"MacBehaviour,\" we conducted three\nvalidation experiments on three LLMs (GPT-3.5, Llama-2 7B, and Vicuna-1.5 13B)\nto replicate sound-gender association in LLMs. The results consistently showed\nthat they exhibit human-like tendencies to infer gender from novel personal\nnames based on their phonology, as previously demonstrated (Cai et al., 2023).\nIn summary, \"MacBehaviour\" is an R package for machine behaviour studies which\noffers a user-friendly interface and comprehensive features to simplify and\nstandardize the experimental process.",
      "tldr_zh": "这篇论文介绍了 MacBehaviour，一个 R package，旨在简化大语言模型 (LLMs) 的行为实验，通过将 LLMs 视为心理实验参与者，支持与超过 60 个模型（如 OpenAI's GPT 家族、Claude 家族和 Llama 家族）的互动，并提供实验设计、刺激呈现、行为操作和响应记录等功能。研究团队进行了三个验证实验，使用 GPT-3.5、Llama-2 7B 和 Vicuna-1.5 13B 模型，成功复制了声音-性别关联（sound-gender association），结果显示这些 LLMs 像人类一样基于音韵从新名字推断性别。总之，MacBehaviour 提供了一个用户友好的接口，帮助标准化机器行为研究，提高实验效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.07495v1",
      "published_date": "2024-05-13 06:31:48 UTC",
      "updated_date": "2024-05-13 06:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:15:13.668049"
    },
    {
      "arxiv_id": "2405.08037v1",
      "title": "Layout Generation Agents with Large Language Models",
      "title_zh": "基于大型语言模型的布局生成代理",
      "authors": [
        "Yuichi Sasazawa",
        "Yasuhiro Sogawa"
      ],
      "abstract": "In recent years, there has been an increasing demand for customizable 3D\nvirtual spaces. Due to the significant human effort required to create these\nvirtual spaces, there is a need for efficiency in virtual space creation. While\nexisting studies have proposed methods for automatically generating layouts\nsuch as floor plans and furniture arrangements, these methods only generate\ntext indicating the layout structure based on user instructions, without\nutilizing the information obtained during the generation process. In this\nstudy, we propose an agent-driven layout generation system using the GPT-4V\nmultimodal large language model and validate its effectiveness. Specifically,\nthe language model manipulates agents to sequentially place objects in the\nvirtual space, thus generating layouts that reflect user instructions.\nExperimental results confirm that our proposed method can generate virtual\nspaces reflecting user instructions with a high success rate. Additionally, we\nsuccessfully identified elements contributing to the improvement in behavior\ngeneration performance through ablation study.",
      "tldr_zh": "该研究针对3D虚拟空间创建的效率问题，提出了一种基于Large Language Models（如GPT-4V）的代理驱动布局生成系统。该系统让语言模型控制代理依次放置物体，从而生成符合用户指令的布局结构，并利用生成过程中的信息提升准确性。实验结果显示，该方法在虚拟空间生成中取得了高成功率，通过ablation study成功识别了性能提升的关键元素。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08037v1",
      "published_date": "2024-05-13 06:27:23 UTC",
      "updated_date": "2024-05-13 06:27:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:15:24.576778"
    },
    {
      "arxiv_id": "2405.07490v1",
      "title": "Strategic Data Ordering: Enhancing Large Language Model Performance through Curriculum Learning",
      "title_zh": "战略数据排序：通过课程学习增强大型语言模型性能",
      "authors": [
        "Jisu Kim",
        "Juhwan Lee"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has improved text\nunderstanding and generation but poses challenges in computational resources.\nThis study proposes a curriculum learning-inspired, data-centric training\nstrategy that begins with simpler tasks and progresses to more complex ones,\nusing criteria such as prompt length, attention scores, and loss values to\nstructure the training data. Experiments with Mistral-7B (Jiang et al., 2023)\nand Gemma-7B (Team et al., 2024) models demonstrate that curriculum learning\nslightly improves performance compared to traditional random data shuffling.\nNotably, we observed that sorting data based on our proposed attention criteria\ngenerally led to better performance. This approach offers a sustainable method\nto enhance LLM performance without increasing model size or dataset volume,\naddressing scalability challenges in LLM training.",
      "tldr_zh": "该研究提出了一种基于课程学习（curriculum learning）的战略数据排序方法，以提升大型语言模型（LLMs）的性能，通过从简单任务逐步过渡到复杂任务，使用提示长度（prompt length）、注意力分数（attention scores）和损失值（loss values）作为数据结构化标准。实验在 Mistral-7B 和 Gemma-7B 模型上表明，这种方法相对于传统随机数据排序略微提高了性能，尤其是基于注意力标准的排序效果更佳。这种数据中心策略提供了一种可持续的训练方式，能够在不增加模型大小或数据集体积的情况下，解决 LLM 训练的可扩展性挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07490v1",
      "published_date": "2024-05-13 06:09:10 UTC",
      "updated_date": "2024-05-13 06:09:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:15:38.279955"
    },
    {
      "arxiv_id": "2405.07474v2",
      "title": "Integrating Intent Understanding and Optimal Behavior Planning for Behavior Tree Generation from Human Instructions",
      "title_zh": "整合意图理解与最优行为规划，用于从人类指令生成行为树",
      "authors": [
        "Xinglin Chen",
        "Yishuai Cai",
        "Yunxin Mao",
        "Minglong Li",
        "Wenjing Yang",
        "Weixia Xu",
        "Ji Wang"
      ],
      "abstract": "Robots executing tasks following human instructions in domestic or industrial\nenvironments essentially require both adaptability and reliability. Behavior\nTree (BT) emerges as an appropriate control architecture for these scenarios\ndue to its modularity and reactivity. Existing BT generation methods, however,\neither do not involve interpreting natural language or cannot theoretically\nguarantee the BTs' success. This paper proposes a two-stage framework for BT\ngeneration, which first employs large language models (LLMs) to interpret goals\nfrom high-level instructions, then constructs an efficient goal-specific BT\nthrough the Optimal Behavior Tree Expansion Algorithm (OBTEA). We represent\ngoals as well-formed formulas in first-order logic, effectively bridging intent\nunderstanding and optimal behavior planning. Experiments in the service robot\nvalidate the proficiency of LLMs in producing grammatically correct and\naccurately interpreted goals, demonstrate OBTEA's superiority over the baseline\nBT Expansion algorithm in various metrics, and finally confirm the practical\ndeployability of our framework. The project website is\nhttps://dids-ei.github.io/Project/LLM-OBTEA/.",
      "tldr_zh": "本论文提出一个两阶段框架，用于从人类指令生成Behavior Tree (BT)，以提升机器人在家庭或工业环境中的适应性和可靠性。该框架首先利用Large Language Models (LLMs)解析高水平指令，将目标表示为First-Order Logic的well-formed formulas，从而桥接意图理解；随后，通过Optimal Behavior Tree Expansion Algorithm (OBTEA)构建高效的目标特定BT，确保行为规划的最优性。实验在服务机器人上验证了LLMs在准确解释目标方面的优势，OBTEA在多种指标上优于基线算法，并证明了框架的实际部署潜力。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07474v2",
      "published_date": "2024-05-13 05:23:48 UTC",
      "updated_date": "2024-06-27 13:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:15:50.423705"
    },
    {
      "arxiv_id": "2405.07468v1",
      "title": "Evaluating large language models in medical applications: a survey",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolan Chen",
        "Jiayang Xiang",
        "Shanfu Lu",
        "Yexin Liu",
        "Mingguang He",
        "Danli Shi"
      ],
      "abstract": "Large language models (LLMs) have emerged as powerful tools with\ntransformative potential across numerous domains, including healthcare and\nmedicine. In the medical domain, LLMs hold promise for tasks ranging from\nclinical decision support to patient education. However, evaluating the\nperformance of LLMs in medical contexts presents unique challenges due to the\ncomplex and critical nature of medical information. This paper provides a\ncomprehensive overview of the landscape of medical LLM evaluation, synthesizing\ninsights from existing studies and highlighting evaluation data sources, task\nscenarios, and evaluation methods. Additionally, it identifies key challenges\nand opportunities in medical LLM evaluation, emphasizing the need for continued\nresearch and innovation to ensure the responsible integration of LLMs into\nclinical practice.",
      "tldr_zh": "本调查综述了大型语言模型（LLMs）在医疗应用中的性能评估，强调了LLMs在临床决策支持和患者教育等任务中的潜力，同时指出了评估面临的挑战，如医疗信息的复杂性和关键性。论文综合了现有研究，涵盖了评估数据来源、任务场景（如临床决策）和各种评估方法。最终，它识别了关键挑战和机会，呼吁持续创新以确保LLMs负责任地整合到临床实践中。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2405.07468v1",
      "published_date": "2024-05-13 05:08:33 UTC",
      "updated_date": "2024-05-13 05:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:16:00.430686"
    },
    {
      "arxiv_id": "2405.07460v4",
      "title": "HoneyBee: A Scalable Modular Framework for Creating Multimodal Oncology Datasets with Foundational Embedding Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aakash Tripathi",
        "Asim Waqas",
        "Matthew B. Schabath",
        "Yasin Yilmaz",
        "Ghulam Rasool"
      ],
      "abstract": "Developing accurate machine learning models for oncology requires\nlarge-scale, high-quality multimodal datasets. However, creating such datasets\nremains challenging due to the complexity and heterogeneity of medical data. To\naddress this challenge, we introduce HoneyBee, a scalable modular framework for\nbuilding multimodal oncology datasets that leverages foundation models to\ngenerate representative embeddings. HoneyBee integrates various data\nmodalities, including clinical diagnostic and pathology imaging data, medical\nnotes, reports, records, and molecular data. It employs data preprocessing\ntechniques and foundation models to generate embeddings that capture the\nessential features and relationships within the raw medical data. The generated\nembeddings are stored in a structured format using Hugging Face datasets and\nPyTorch dataloaders for accessibility. Vector databases enable efficient\nquerying and retrieval for machine learning applications. We demonstrate the\neffectiveness of HoneyBee through experiments assessing the quality and\nrepresentativeness of these embeddings. The framework is designed to be\nextensible to other medical domains and aims to accelerate oncology research by\nproviding high-quality, machine learning-ready datasets. HoneyBee is an ongoing\nopen-source effort, and the code, datasets, and models are available at the\nproject repository.",
      "tldr_zh": "该研究引入了 HoneyBee，一个可扩展的模块化框架，用于构建大规模、高质量的多模态肿瘤学数据集，以解决医疗数据复杂性和异质性挑战。HoneyBee 通过整合临床诊断、病理影像、医疗笔记、报告、记录和分子数据，并利用 foundation models 生成代表性 embeddings，从而捕获数据中的关键特征和关系。框架采用数据预处理技术，并将 embeddings 存储在 Hugging Face datasets 和 PyTorch dataloaders 中，支持向量数据库的查询。实验验证了 embeddings 的质量和代表性，证明 HoneyBee 可加速肿瘤学研究，并易于扩展到其他医疗领域，同时作为开源项目提供代码、数据集和模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07460v4",
      "published_date": "2024-05-13 04:35:14 UTC",
      "updated_date": "2024-11-21 16:12:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:16:14.045934"
    },
    {
      "arxiv_id": "2407.04709v1",
      "title": "Efficient 4D Radar Data Auto-labeling Method using LiDAR-based Object Detection Network",
      "title_zh": "翻译失败",
      "authors": [
        "Min-Hyeok Sun",
        "Dong-Hee Paek",
        "Seung-Hyun Song",
        "Seung-Hyun Kong"
      ],
      "abstract": "Focusing on the strength of 4D (4-Dimensional) radar, research about robust\n3D object detection networks in adverse weather conditions has gained\nattention. To train such networks, datasets that contain large amounts of 4D\nradar data and ground truth labels are essential. However, the existing 4D\nradar datasets (e.g., K-Radar) lack sufficient sensor data and labels, which\nhinders the advancement in this research domain. Furthermore, enlarging the 4D\nradar datasets requires a time-consuming and expensive manual labeling process.\nTo address these issues, we propose the auto-labeling method of 4D radar tensor\n(4DRT) in the K-Radar dataset. The proposed method initially trains a\nLiDAR-based object detection network (LODN) using calibrated LiDAR point cloud\n(LPC). The trained LODN then automatically generates ground truth labels (i.e.,\nauto-labels, ALs) of the K-Radar train dataset without human intervention. The\ngenerated ALs are used to train the 4D radar-based object detection network\n(4DRODN), Radar Tensor Network with Height (RTNH). The experimental results\ndemonstrate that RTNH trained with ALs has achieved a similar detection\nperformance to the original RTNH which is trained with manually annotated\nground truth labels, thereby verifying the effectiveness of the proposed\nauto-labeling method. All relevant codes will be soon available at the\nfollowing GitHub project: https://github.com/kaist-avelab/K-Radar",
      "tldr_zh": "本研究针对4D Radar数据集（如K-Radar）数据不足和手动标注耗时的问题，提出了一种高效的4D Radar数据自动标注方法。方法首先训练基于LiDAR的物体检测网络(LODN)使用校准的LiDAR点云(LPC)，然后利用训练好的LODN自动生成K-Radar训练数据集的地面真实标签(auto-labels, ALs)。随后，使用这些ALs训练4D Radar-based物体检测网络(4DRODN)，即Radar Tensor Network with Height (RTNH)，实验结果显示其检测性能与使用手动标注标签的原始网络相当，验证了该方法的有效性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.SP",
      "comment": "Accept at IEEE IVS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.04709v1",
      "published_date": "2024-05-13 04:28:06 UTC",
      "updated_date": "2024-05-13 04:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:16:24.844277"
    },
    {
      "arxiv_id": "2405.09572v1",
      "title": "Deep Neural Operator Enabled Digital Twin Modeling for Additive Manufacturing",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Liu",
        "Xuxiao Li",
        "Manoj R. Rajanna",
        "Edward W. Reutzel",
        "Brady Sawyer",
        "Prahalada Rao",
        "Jim Lua",
        "Nam Phan",
        "Yue Yu"
      ],
      "abstract": "A digital twin (DT), with the components of a physics-based model, a\ndata-driven model, and a machine learning (ML) enabled efficient surrogate,\nbehaves as a virtual twin of the real-world physical process. In terms of Laser\nPowder Bed Fusion (L-PBF) based additive manufacturing (AM), a DT can predict\nthe current and future states of the melt pool and the resulting defects\ncorresponding to the input laser parameters, evolve itself by assimilating\nin-situ sensor data, and optimize the laser parameters to mitigate defect\nformation. In this paper, we present a deep neural operator enabled\ncomputational framework of the DT for closed-loop feedback control of the L-PBF\nprocess. This is accomplished by building a high-fidelity computational model\nto accurately represent the melt pool states, an efficient surrogate model to\napproximate the melt pool solution field, followed by an physics-based\nprocedure to extract information from the computed melt pool simulation that\ncan further be correlated to the defect quantities of interest (e.g., surface\nroughness). In particular, we leverage the data generated from the\nhigh-fidelity physics-based model and train a series of Fourier neural operator\n(FNO) based ML models to effectively learn the relation between the input laser\nparameters and the corresponding full temperature field of the melt pool.\nSubsequently, a set of physics-informed variables such as the melt pool\ndimensions and the peak temperature can be extracted to compute the resulting\ndefects. An optimization algorithm is then exercised to control laser input and\nminimize defects. On the other hand, the constructed DT can also evolve with\nthe physical twin via offline finetuning and online material calibration.\nFinally, a probabilistic framework is adopted for uncertainty quantification.\nThe developed DT is envisioned to guide the AM process and facilitate\nhigh-quality manufacturing.",
      "tldr_zh": "本论文提出了一种基于深度神经操作符的数字孪生(Digital Twin, DT)模型，用于激光粉末床熔融(Laser Powder Bed Fusion, L-PBF)增材制造(Additive Manufacturing, AM)，以预测熔池状态、缺陷并优化激光参数。框架结合高保真物理模型和Fourier neural operator (FNO)模型，通过训练学习激光输入与温度场的关联，并提取物理变量进行缺陷计算和最小化优化。实验结果显示，该DT支持闭环反馈控制、离线微调和不确定性量化，最终提升了AM过程的精确性和制造质量。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09572v1",
      "published_date": "2024-05-13 03:53:46 UTC",
      "updated_date": "2024-05-13 03:53:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:16:38.437240"
    },
    {
      "arxiv_id": "2405.10976v1",
      "title": "On Constructing Algorithm Portfolios in Algorithm Selection for Computationally Expensive Black-box Optimization in the Fixed-budget Setting",
      "title_zh": "翻译失败",
      "authors": [
        "Takushi Yoshikawa",
        "Ryoji Tanabe"
      ],
      "abstract": "Feature-based offline algorithm selection has shown its effectiveness in a\nwide range of optimization problems, including the black-box optimization\nproblem. An algorithm selection system selects the most promising optimizer\nfrom an algorithm portfolio, which is a set of pre-defined optimizers. Thus,\nalgorithm selection requires a well-constructed algorithm portfolio consisting\nof efficient optimizers complementary to each other. Although construction\nmethods for the fixed-target setting have been well studied, those for the\nfixed-budget setting have received less attention. Here, the fixed-budget\nsetting is generally used for computationally expensive optimization, where a\nbudget of function evaluations is small. In this context, first, this paper\npoints out some undesirable properties of experimental setups in previous\nstudies. Then, this paper argues the importance of considering the number of\nfunction evaluations used in the sampling phase when constructing algorithm\nportfolios, whereas the previous studies ignored that. The results show that\nalgorithm portfolios constructed by our approach perform significantly better\nthan those by the previous approach.",
      "tldr_zh": "该论文探讨了在固定预算设置(fixed-budget setting)下，为计算昂贵的黑箱优化(black-box optimization)构建算法组合(algorithm portfolios)的挑战，强调了特征-based offline algorithm selection的有效性。作者指出，现有研究忽略了采样阶段函数评估数量的重要性，并提出一种新方法来考虑这一因素，以构建互补高效的优化器集合。实验结果显示，该方法构建的算法组合比传统方法显著提高了性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for GECCO 2024 Workshop Industrial Applications of\n  Metaheuristics",
      "pdf_url": "http://arxiv.org/pdf/2405.10976v1",
      "published_date": "2024-05-13 03:31:13 UTC",
      "updated_date": "2024-05-13 03:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:16:48.829539"
    },
    {
      "arxiv_id": "2405.13006v1",
      "title": "Auto FAQ Generation",
      "title_zh": "自动 FAQ 生成",
      "authors": [
        "Anjaneya Teja Kalvakolanu",
        "NagaSai Chandra",
        "Michael Fekadu"
      ],
      "abstract": "FAQ documents are commonly used with text documents and websites to provide\nimportant information in the form of question answer pairs to either aid in\nreading comprehension or provide a shortcut to the key ideas. We suppose that\nsalient sentences from a given document serve as a good proxy fro the answers\nto an aggregated set of FAQs from readers. We propose a system for generating\nFAQ documents that extract the salient questions and their corresponding\nanswers from sizeable text documents scraped from the Stanford Encyclopedia of\nPhilosophy. We use existing text summarization, sentence ranking via the Text\nrank algorithm, and question-generation tools to create an initial set of\nquestions and answers. Finally, we apply some heuristics to filter out invalid\nquestions. We use human evaluation to rate the generated questions on grammar,\nwhether the question is meaningful, and whether the question's answerability is\npresent within a summarized context. On average, participants thought 71\npercent of the questions were meaningful.",
      "tldr_zh": "这篇论文提出了一种自动 FAQ 生成系统，用于从大型文本文档（如斯坦福哲学百科全书）中提取显著句子作为答案代理，并生成问题答案对以辅助阅读理解。方法结合了文本总结（text summarization）、TextRank 算法进行句子排名、问题生成工具（question-generation tools），并应用启发式规则（heuristics）过滤无效问题。人类评估结果显示，生成的问句中平均 71% 被认为在语法和意义上合理，且答案可在总结上下文中找到。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "3 figures and peer evaluated",
      "pdf_url": "http://arxiv.org/pdf/2405.13006v1",
      "published_date": "2024-05-13 03:30:27 UTC",
      "updated_date": "2024-05-13 03:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:17:01.350814"
    },
    {
      "arxiv_id": "2405.08036v5",
      "title": "POWQMIX: Weighted Value Factorization with Potentially Optimal Joint Actions Recognition for Cooperative Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Huang",
        "Shatong Zhu",
        "Junqiao Zhao",
        "Hongtu Zhou",
        "Chen Ye",
        "Tiantian Feng",
        "Changjun Jiang"
      ],
      "abstract": "Value function factorization methods are commonly used in cooperative\nmulti-agent reinforcement learning, with QMIX receiving significant attention.\nMany QMIX-based methods introduce monotonicity constraints between the joint\naction value and individual action values to achieve decentralized execution.\nHowever, such constraints limit the representation capacity of value\nfactorization, restricting the joint action values it can represent and\nhindering the learning of the optimal policy. To address this challenge, we\npropose the Potentially Optimal Joint Actions Weighted QMIX (POWQMIX)\nalgorithm, which recognizes the potentially optimal joint actions and assigns\nhigher weights to the corresponding losses of these joint actions during\ntraining. We theoretically prove that with such a weighted training approach\nthe optimal policy is guaranteed to be recovered. Experiments in matrix games,\ndifficulty-enhanced predator-prey, and StarCraft II Multi-Agent Challenge\nenvironments demonstrate that our algorithm outperforms the state-of-the-art\nvalue-based multi-agent reinforcement learning methods.",
      "tldr_zh": "该论文提出POWQMIX算法，用于改进合作多智能体强化学习（Cooperative Multi-Agent Reinforcement Learning），通过识别潜在的最优联合动作并为其分配更高权重损失，从而克服QMIX等方法的单调性约束限制。理论证明表明，这种加权训练方式能保证恢复最优策略。实验在矩阵游戏、难度增强的捕食者-猎物游戏以及StarCraft II多智能体挑战环境中显示，POWQMIX优于现有最先进的价值分解方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper needs further refinement",
      "pdf_url": "http://arxiv.org/pdf/2405.08036v5",
      "published_date": "2024-05-13 03:27:35 UTC",
      "updated_date": "2025-04-10 01:21:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:17:13.573186"
    },
    {
      "arxiv_id": "2405.17440v1",
      "title": "CataLM: Empowering Catalyst Design Through Large Language Models",
      "title_zh": "CataLM：通过大型语言模型赋能催化剂设计",
      "authors": [
        "Ludi Wang",
        "Xueqing Chen",
        "Yi Du",
        "Yuanchun Zhou",
        "Yang Gao",
        "Wenjuan Cui"
      ],
      "abstract": "The field of catalysis holds paramount importance in shaping the trajectory\nof sustainable development, prompting intensive research efforts to leverage\nartificial intelligence (AI) in catalyst design. Presently, the fine-tuning of\nopen-source large language models (LLMs) has yielded significant breakthroughs\nacross various domains such as biology and healthcare. Drawing inspiration from\nthese advancements, we introduce CataLM Cata}lytic Language Model), a large\nlanguage model tailored to the domain of electrocatalytic materials. Our\nfindings demonstrate that CataLM exhibits remarkable potential for facilitating\nhuman-AI collaboration in catalyst knowledge exploration and design. To the\nbest of our knowledge, CataLM stands as the pioneering LLM dedicated to the\ncatalyst domain, offering novel avenues for catalyst discovery and development.",
      "tldr_zh": "本研究引入 CataLM，一种针对电催化材料的 Large Language Models (LLMs)，旨在通过人工智能增强催化剂设计并推动可持续发展的研究。CataLM 基于开源 LLMs 的微调，借鉴生物和医疗领域的突破，实现人类-AI 协作在催化知识探索和设计中的应用。实验结果表明，CataLM 展示了巨大潜力，是首个专注于催化领域的 LLM，为催化剂发现和发展开辟了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17440v1",
      "published_date": "2024-05-13 03:19:47 UTC",
      "updated_date": "2024-05-13 03:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:17:27.668851"
    },
    {
      "arxiv_id": "2405.08035v1",
      "title": "A LLM-based Controllable, Scalable, Human-Involved User Simulator Framework for Conversational Recommender Systems",
      "title_zh": "一种基于 LLM 的可控、可扩展、涉及人类的用户模拟器框架，用于对话推荐",
      "authors": [
        "Lixi Zhu",
        "Xiaowen Huang",
        "Jitao Sang"
      ],
      "abstract": "Conversational Recommender System (CRS) leverages real-time feedback from\nusers to dynamically model their preferences, thereby enhancing the system's\nability to provide personalized recommendations and improving the overall user\nexperience. CRS has demonstrated significant promise, prompting researchers to\nconcentrate their efforts on developing user simulators that are both more\nrealistic and trustworthy. The emergence of Large Language Models (LLMs) has\nmarked the onset of a new epoch in computational capabilities, exhibiting\nhuman-level intelligence in various tasks. Research efforts have been made to\nutilize LLMs for building user simulators to evaluate the performance of CRS.\nAlthough these efforts showcase innovation, they are accompanied by certain\nlimitations. In this work, we introduce a Controllable, Scalable, and\nHuman-Involved (CSHI) simulator framework that manages the behavior of user\nsimulators across various stages via a plugin manager. CSHI customizes the\nsimulation of user behavior and interactions to provide a more lifelike and\nconvincing user interaction experience. Through experiments and case studies in\ntwo conversational recommendation scenarios, we show that our framework can\nadapt to a variety of conversational recommendation settings and effectively\nsimulate users' personalized preferences. Consequently, our simulator is able\nto generate feedback that closely mirrors that of real users. This facilitates\na reliable assessment of existing CRS studies and promotes the creation of\nhigh-quality conversational recommendation datasets.",
      "tldr_zh": "这篇论文提出了一种基于 LLM（Large Language Models）的 CSHI（Controllable, Scalable, and Human-Involved）用户模拟器框架，用于对话推荐系统（CRS），以更真实地模拟用户行为并提供个性化反馈。框架通过插件管理器控制用户模拟器的各个阶段，实现可扩展性和人为参与，从而提升交互的真实性和说服力。实验和案例研究在两个对话推荐场景中证明，CSHI 能适应多种设置，生成与真实用户相似的反馈，促进 CRS 的可靠评估和高品质数据集的创建。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08035v1",
      "published_date": "2024-05-13 03:02:56 UTC",
      "updated_date": "2024-05-13 03:02:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:17:40.116776"
    },
    {
      "arxiv_id": "2405.07442v2",
      "title": "Rene: A Pre-trained Multi-modal Architecture for Auscultation of Respiratory Diseases",
      "title_zh": "Rene：用于呼吸系统疾病听诊的预训练多模态架构",
      "authors": [
        "Pengfei Zhang",
        "Zhihang Zheng",
        "Shichen Zhang",
        "Minghao Yang",
        "Shaojun Tang"
      ],
      "abstract": "Compared with invasive examinations that require tissue sampling, respiratory\nsound testing is a non-invasive examination method that is safer and easier for\npatients to accept. In this study, we introduce Rene, a pioneering large-scale\nmodel tailored for respiratory sound recognition. Rene has been rigorously\nfine-tuned with an extensive dataset featuring a broad array of respiratory\naudio samples, targeting disease detection, sound pattern classification, and\nevent identification. Our innovative approach applies a pre-trained speech\nrecognition model to process respiratory sounds, augmented with patient medical\nrecords. The resulting multi-modal deep-learning framework addresses\ninterpretability and real-time diagnostic challenges that have hindered\nprevious respiratory-focused models. Benchmark comparisons reveal that Rene\nsignificantly outperforms existing models, achieving improvements of 10.27%,\n16.15%, 15.29%, and 18.90% in respiratory event detection and audio\nclassification on the SPRSound database. Disease prediction accuracy on the\nICBHI database improved by 23% over the baseline in both mean average and\nharmonic scores. Moreover, we have developed a real-time respiratory sound\ndiscrimination system utilizing the Rene architecture. Employing\nstate-of-the-art Edge AI technology, this system enables rapid and accurate\nresponses for respiratory sound\nauscultation(https://github.com/zpforlove/Rene).",
      "tldr_zh": "本文提出 Rene，一种预训练的多-modal architecture，用于呼吸疾病的听诊。该模型通过微调大规模数据集并结合患者医疗记录，构建多-modal深度学习框架，解决了现有模型的解释性和实时诊断挑战。在基准测试中，Rene 在 SPRSound 数据库上实现了呼吸事件检测和音频分类的改进（分别提高 10.27%、16.15%、15.29% 和 18.90%），并在 ICBHI 数据库上使疾病预测准确率提升 23%。此外，基于 Edge AI 技术，开发了实时呼吸音鉴别系统，以支持临床应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "q-bio.QM"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07442v2",
      "published_date": "2024-05-13 03:00:28 UTC",
      "updated_date": "2024-06-07 00:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:17:52.468969"
    },
    {
      "arxiv_id": "2405.07437v2",
      "title": "Evaluation of Retrieval-Augmented Generation: A Survey",
      "title_zh": "检索增强生成的评估：一项综述",
      "authors": [
        "Hao Yu",
        "Aoran Gan",
        "Kai Zhang",
        "Shiwei Tong",
        "Qi Liu",
        "Zhaofeng Liu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has recently gained traction in natural\nlanguage processing. Numerous studies and real-world applications are\nleveraging its ability to enhance generative models through external\ninformation retrieval. Evaluating these RAG systems, however, poses unique\nchallenges due to their hybrid structure and reliance on dynamic knowledge\nsources. To better understand these challenges, we conduct A Unified Evaluation\nProcess of RAG (Auepora) and aim to provide a comprehensive overview of the\nevaluation and benchmarks of RAG systems. Specifically, we examine and compare\nseveral quantifiable metrics of the Retrieval and Generation components, such\nas relevance, accuracy, and faithfulness, within the current RAG benchmarks,\nencompassing the possible output and ground truth pairs. We then analyze the\nvarious datasets and metrics, discuss the limitations of current benchmarks,\nand suggest potential directions to advance the field of RAG benchmarks.",
      "tldr_zh": "这篇调查论文系统评估了 Retrieval-Augmented Generation (RAG) 系统，聚焦于其在自然语言处理中的应用及其评估挑战。作者引入了 A Unified Evaluation Process of RAG (Auepora) 框架，比较了检索和生成组件的量化指标，如 relevance、accuracy 和 faithfulness，并在现有基准中分析输出与地面真相对的性能。论文讨论了当前数据集和指标的局限性，并提出潜在方向，以推进 RAG 基准的改进和发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07437v2",
      "published_date": "2024-05-13 02:33:25 UTC",
      "updated_date": "2024-07-03 04:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:18:03.175906"
    },
    {
      "arxiv_id": "2405.07436v1",
      "title": "Can Language Models Explain Their Own Classification Behavior?",
      "title_zh": "语言模型能否解释自身的分类行为？",
      "authors": [
        "Dane Sherburn",
        "Bilal Chughtai",
        "Owain Evans"
      ],
      "abstract": "Large language models (LLMs) perform well at a myriad of tasks, but\nexplaining the processes behind this performance is a challenge. This paper\ninvestigates whether LLMs can give faithful high-level explanations of their\nown internal processes. To explore this, we introduce a dataset,\nArticulateRules, of few-shot text-based classification tasks generated by\nsimple rules. Each rule is associated with a simple natural-language\nexplanation. We test whether models that have learned to classify inputs\ncompetently (both in- and out-of-distribution) are able to articulate freeform\nnatural language explanations that match their classification behavior. Our\ndataset can be used for both in-context and finetuning evaluations. We evaluate\na range of LLMs, demonstrating that articulation accuracy varies considerably\nbetween models, with a particularly sharp increase from GPT-3 to GPT-4. We then\ninvestigate whether we can improve GPT-3's articulation accuracy through a\nrange of methods. GPT-3 completely fails to articulate 7/10 rules in our test,\neven after additional finetuning on correct explanations. We release our\ndataset, ArticulateRules, which can be used to test self-explanation for LLMs\ntrained either in-context or by finetuning.",
      "tldr_zh": "这篇论文探讨大型语言模型 (LLMs) 是否能提供对其内部分类过程的忠实高层解释。研究者引入了 ArticulateRules 数据集，该数据集包含基于简单规则的少样本文本分类任务，每个规则配有自然语言解释，并用于评估模型在 in-context 和 finetuning 场景下生成匹配行为的自由形式解释。实验结果显示，不同 LLMs 的表达准确性差异明显，GPT-4 远超 GPT-3，而对 GPT-3 的改进尝试（如额外 finetuning）仍无法完全表达 7/10 的规则。作者发布了 ArticulateRules 数据集，以促进对 LLMs 自解释能力的进一步测试。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07436v1",
      "published_date": "2024-05-13 02:31:08 UTC",
      "updated_date": "2024-05-13 02:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:18:16.297599"
    },
    {
      "arxiv_id": "2405.07414v2",
      "title": "Binning as a Pretext Task: Improving Self-Supervised Learning in Tabular Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungeun Lee",
        "Ye Seul Sim",
        "Hye-Seung Cho",
        "Moonjung Eo",
        "Suhee Yoon",
        "Sanghyu Yoon",
        "Woohyung Lim"
      ],
      "abstract": "The ability of deep networks to learn superior representations hinges on\nleveraging the proper inductive biases, considering the inherent properties of\ndatasets. In tabular domains, it is critical to effectively handle\nheterogeneous features (both categorical and numerical) in a unified manner and\nto grasp irregular functions like piecewise constant functions. To address the\nchallenges in the self-supervised learning framework, we propose a novel\npretext task based on the classical binning method. The idea is\nstraightforward: reconstructing the bin indices (either orders or classes)\nrather than the original values. This pretext task provides the encoder with an\ninductive bias to capture the irregular dependencies, mapping from continuous\ninputs to discretized bins, and mitigates the feature heterogeneity by setting\nall features to have category-type targets. Our empirical investigations\nascertain several advantages of binning: capturing the irregular function,\ncompatibility with encoder architecture and additional modifications,\nstandardizing all features into equal sets, grouping similar values within a\nfeature, and providing ordering information. Comprehensive evaluations across\ndiverse tabular datasets corroborate that our method consistently improves\ntabular representation learning performance for a wide range of downstream\ntasks. The codes are available in\nhttps://github.com/kyungeun-lee/tabularbinning.",
      "tldr_zh": "本文提出了一种基于 binning 的预训练任务（pretext task），旨在提升表格领域（tabular domains）的自监督学习（self-supervised learning），通过处理异构特征（如分类和数值）和不规则函数（如分段常量函数）来改善模型表示。方法的核心是重建 bin 索引（顺序或类别）而非原始值，这为编码器提供了 inductive biases，帮助捕捉不规则依赖性并标准化特征。实验在多种表格数据集上验证了该方法的优势，包括特征分组、排序信息和与编码器架构的兼容性，最终在下游任务中 consistently 提高了性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024, 18 pages (including supplementary materials)",
      "pdf_url": "http://arxiv.org/pdf/2405.07414v2",
      "published_date": "2024-05-13 01:23:14 UTC",
      "updated_date": "2024-05-14 01:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:18:28.664831"
    },
    {
      "arxiv_id": "2405.07411v1",
      "title": "MoVL:Exploring Fusion Strategies for the Domain-Adaptive Application of Pretrained Models in Medical Imaging Tasks",
      "title_zh": "MoVL：探索预训练模型在医学成像任务中的领域自适应",
      "authors": [
        "Haijiang Tian",
        "Jingkun Yue",
        "Xiaohong Liu",
        "Guoxing Yang",
        "Zeyu Jiang",
        "Guangyu Wang"
      ],
      "abstract": "Medical images are often more difficult to acquire than natural images due to\nthe specialism of the equipment and technology, which leads to less medical\nimage datasets. So it is hard to train a strong pretrained medical vision\nmodel. How to make the best of natural pretrained vision model and adapt in\nmedical domain still pends. For image classification, a popular method is\nlinear probe (LP). However, LP only considers the output after feature\nextraction. Yet, there exists a gap between input medical images and natural\npretrained vision model. We introduce visual prompting (VP) to fill in the gap,\nand analyze the strategies of coupling between LP and VP. We design a joint\nlearning loss function containing categorisation loss and discrepancy loss,\nwhich describe the variance of prompted and plain images, naming this joint\ntraining strategy MoVL (Mixture of Visual Prompting and Linear Probe). We\nexperiment on 4 medical image classification datasets, with two mainstream\narchitectures, ResNet and CLIP. Results shows that without changing the\nparameters and architecture of backbone model and with less parameters, there\nis potential for MoVL to achieve full finetune (FF) accuracy (on four medical\ndatasets, average 90.91% for MoVL and 91.13% for FF). On out of distribution\nmedical dataset, our method(90.33%) can outperform FF (85.15%) with absolute\n5.18 % lead.",
      "tldr_zh": "本研究探讨了如何将自然图像预训练模型适应到医疗图像任务中，以解决数据稀缺问题。作者提出 MoVL 方法，通过结合 visual prompting (VP) 和 linear probe (LP)，设计了一个联合学习损失函数，包括 categorization loss 和 discrepancy loss，以填补输入图像间的领域差距。实验在 4 个医疗图像分类数据集上使用 ResNet 和 CLIP 架构表明，MoVL 仅需较少参数即可达到接近 full finetune (FF) 的准确率（平均 90.91%），并在分布外数据集上超越 FF（90.33% vs 85.15%），展示了其高效的领域适应潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07411v1",
      "published_date": "2024-05-13 01:18:25 UTC",
      "updated_date": "2024-05-13 01:18:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:18:39.990766"
    },
    {
      "arxiv_id": "2405.07407v1",
      "title": "PitcherNet: Powering the Moneyball Evolution in Baseball Video Analytics",
      "title_zh": "翻译失败",
      "authors": [
        "Jerrin Bright",
        "Bavesh Balaji",
        "Yuhao Chen",
        "David A Clausi",
        "John S Zelek"
      ],
      "abstract": "In the high-stakes world of baseball, every nuance of a pitcher's mechanics\nholds the key to maximizing performance and minimizing runs. Traditional\nanalysis methods often rely on pre-recorded offline numerical data, hindering\ntheir application in the dynamic environment of live games. Broadcast video\nanalysis, while seemingly ideal, faces significant challenges due to factors\nlike motion blur and low resolution. To address these challenges, we introduce\nPitcherNet, an end-to-end automated system that analyzes pitcher kinematics\ndirectly from live broadcast video, thereby extracting valuable pitch\nstatistics including velocity, release point, pitch position, and release\nextension. This system leverages three key components: (1) Player tracking and\nidentification by decoupling actions from player kinematics; (2) Distribution\nand depth-aware 3D human modeling; and (3) Kinematic-driven pitch statistics.\nExperimental validation demonstrates that PitcherNet achieves robust analysis\nresults with 96.82% accuracy in pitcher tracklet identification, reduced joint\nposition error by 1.8mm and superior analytics compared to baseline methods. By\nenabling performance-critical kinematic analysis from broadcast video,\nPitcherNet paves the way for the future of baseball analytics by optimizing\npitching strategies, preventing injuries, and unlocking a deeper understanding\nof pitcher mechanics, forever transforming the game.",
      "tldr_zh": "该研究提出PitcherNet，一种端到端的自动化系统，用于从直播棒球视频中分析投手运动学（kinematics），解决传统方法依赖离线数据和视频模糊问题的局限性。系统包括三大关键组件：玩家跟踪和识别（通过分离动作与运动学）、分布和深度感知的3D人体建模，以及运动学驱动的投球统计提取，如速度、释放点和投球位置。实验结果显示，PitcherNet在投手轨迹识别中达到96.82%的准确率，关节位置误差降低1.8mm，并优于基线方法，从而为优化投球策略、预防伤病和深化棒球分析（Moneyball Evolution）提供新路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  Workshops (CVPRW'24)",
      "pdf_url": "http://arxiv.org/pdf/2405.07407v1",
      "published_date": "2024-05-13 01:03:06 UTC",
      "updated_date": "2024-05-13 01:03:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:18:52.087518"
    },
    {
      "arxiv_id": "2405.07406v2",
      "title": "Machine Unlearning: A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Weiqi Wang",
        "Zhiyi Tian",
        "Chenhan Zhang",
        "Shui Yu"
      ],
      "abstract": "As the right to be forgotten has been legislated worldwide, many studies\nattempt to design unlearning mechanisms to protect users' privacy when they\nwant to leave machine learning service platforms. Specifically, machine\nunlearning is to make a trained model to remove the contribution of an erased\nsubset of the training dataset. This survey aims to systematically classify a\nwide range of machine unlearning and discuss their differences, connections and\nopen problems. We categorize current unlearning methods into four scenarios:\ncentralized unlearning, distributed and irregular data unlearning, unlearning\nverification, and privacy and security issues in unlearning. Since centralized\nunlearning is the primary domain, we use two parts to introduce: firstly, we\nclassify centralized unlearning into exact unlearning and approximate\nunlearning; secondly, we offer a detailed introduction to the techniques of\nthese methods. Besides the centralized unlearning, we notice some studies about\ndistributed and irregular data unlearning and introduce federated unlearning\nand graph unlearning as the two representative directions. After introducing\nunlearning methods, we review studies about unlearning verification. Moreover,\nwe consider the privacy and security issues essential in machine unlearning and\norganize the latest related literature. Finally, we discuss the challenges of\nvarious unlearning scenarios and address the potential research directions.",
      "tldr_zh": "这篇调查论文系统地概述了machine unlearning的概念和方法，旨在通过移除训练数据子集的贡献来保护用户隐私并满足“被遗忘权”的要求。论文将unlearning方法分类为centralized unlearning（包括exact unlearning和approximate unlearning）、distributed and irregular data unlearning（如federated unlearning和graph unlearning）、unlearning verification，以及相关的隐私和安全问题，并详细介绍了这些技术的实现。最终，该研究讨论了各种场景的挑战和潜在研究方向，为未来machine unlearning的应用提供了全面指导。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07406v2",
      "published_date": "2024-05-13 00:58:34 UTC",
      "updated_date": "2024-07-25 01:03:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:19:03.989693"
    },
    {
      "arxiv_id": "2405.07404v1",
      "title": "Indoor PM2.5 forecasting and the association with outdoor air pollution: a modelling study based on sensor data in Australia",
      "title_zh": "室内 PM2.5 预测及其与室外空气污染的关联：基于澳大利亚传感器数据的建模研究",
      "authors": [
        "Wenhua Yu",
        "Bahareh Nakisa",
        "Seng W. Loke",
        "Svetlana Stevanovic",
        "Yuming Guo",
        "Mohammad Naim Rastgoo"
      ],
      "abstract": "Exposure to poor indoor air quality poses significant health risks,\nnecessitating thorough assessment to mitigate associated dangers. This study\naims to predict hourly indoor fine particulate matter (PM2.5) concentrations\nand investigate their correlation with outdoor PM2.5 levels across 24 distinct\nbuildings in Australia. Indoor air quality data were gathered from 91\nmonitoring sensors in eight Australian cities spanning 2019 to 2022. Employing\nan innovative three-stage deep ensemble machine learning framework (DEML),\ncomprising three base models (Support Vector Machine, Random Forest, and\neXtreme Gradient Boosting) and two meta-models (Random Forest and Generalized\nLinear Model), hourly indoor PM2.5 concentrations were predicted. The model's\naccuracy was evaluated using a rolling windows approach, comparing its\nperformance against three benchmark algorithms (SVM, RF, and XGBoost).\nAdditionally, a correlation analysis assessed the relationship between indoor\nand outdoor PM2.5 concentrations. Results indicate that the DEML model\nconsistently outperformed benchmark models, achieving an R2 ranging from 0.63\nto 0.99 and RMSE from 0.01 to 0.663 mg/m3 for most sensors. Notably, outdoor\nPM2.5 concentrations significantly impacted indoor air quality, particularly\nevident during events like bushfires. This study underscores the importance of\naccurate indoor air quality prediction, crucial for developing\nlocation-specific early warning systems and informing effective interventions.\nBy promoting protective behaviors, these efforts contribute to enhanced public\nhealth outcomes.",
      "tldr_zh": "本研究旨在预测澳大利亚24个建筑的室内PM2.5浓度，并探讨其与室外PM2.5的相关性，使用2019-2022年间来自八个城市的91个传感器的数据。  \n研究采用了一个创新的三阶段深度集成机器学习框架(DEML)，包括基础模型(SVM、Random Forest和XGBoost)以及元模型(Random Forest和Generalized Linear Model)，并通过滚动窗口方法评估模型性能，与基准算法进行比较。  \n结果显示，DEML模型的表现优于基准算法，R2值从0.63到0.99、RMSE从0.01到0.663 mg/m3，并证实室外PM2.5浓度显著影响室内空气质量，尤其在野火事件期间。  \n这项研究强调了准确预测室内空气质量的重要性，可用于开发位置特定的早期预警系统和干预措施，以提升公共健康。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07404v1",
      "published_date": "2024-05-13 00:51:36 UTC",
      "updated_date": "2024-05-13 00:51:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:19:18.536090"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 99,
  "processed_papers_count": 99,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T08:19:41.671649"
}