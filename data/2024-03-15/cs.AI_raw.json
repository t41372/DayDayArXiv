[
  {
    "arxiv_id": "2403.10732v1",
    "title": "Variance-Dependent Regret Bounds for Non-stationary Linear Bandits",
    "authors": [
      "Zhiyong Wang",
      "Jize Xie",
      "Yi Chen",
      "John C. S. Lui",
      "Dongruo Zhou"
    ],
    "abstract": "We investigate the non-stationary stochastic linear bandit problem where the\nreward distribution evolves each round. Existing algorithms characterize the\nnon-stationarity by the total variation budget $B_K$, which is the summation of\nthe change of the consecutive feature vectors of the linear bandits over $K$\nrounds. However, such a quantity only measures the non-stationarity with\nrespect to the expectation of the reward distribution, which makes existing\nalgorithms sub-optimal under the general non-stationary distribution setting.\nIn this work, we propose algorithms that utilize the variance of the reward\ndistribution as well as the $B_K$, and show that they can achieve tighter\nregret upper bounds. Specifically, we introduce two novel algorithms: Restarted\nWeighted$\\text{OFUL}^+$ and Restarted $\\text{SAVE}^+$. These algorithms address\ncases where the variance information of the rewards is known and unknown,\nrespectively. Notably, when the total variance $V_K$ is much smaller than $K$,\nour algorithms outperform previous state-of-the-art results on non-stationary\nstochastic linear bandits under different settings. Experimental evaluations\nfurther validate the superior performance of our proposed algorithms over\nexisting works.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.10732v1",
    "published_date": "2024-03-15 23:36:55 UTC",
    "updated_date": "2024-03-15 23:36:55 UTC"
  },
  {
    "arxiv_id": "2403.10726v2",
    "title": "Strict Partitioning for Sporadic Rigid Gang Tasks",
    "authors": [
      "Binqi Sun",
      "Tomasz Kloda",
      "Marco Caccamo"
    ],
    "abstract": "The rigid gang task model is based on the idea of executing multiple threads\nsimultaneously on a fixed number of processors to increase efficiency and\nperformance. Although there is extensive literature on global rigid gang\nscheduling, partitioned approaches have several practical advantages (e.g.,\ntask isolation and reduced scheduling overheads). In this paper, we propose a\nnew partitioned scheduling strategy for rigid gang tasks, named strict\npartitioning. The method creates disjoint partitions of tasks and processors to\navoid inter-partition interference. Moreover, it tries to assign tasks with\nsimilar volumes (i.e., parallelisms) to the same partition so that the\nintra-partition interference can be reduced. Within each partition, the tasks\ncan be scheduled using any type of scheduler, which allows the use of a less\npessimistic schedulability test. Extensive synthetic experiments and a case\nstudy based on Edge TPU benchmarks show that strict partitioning achieves\nbetter schedulability performance than state-of-the-art global gang\nschedulability analyses for both preemptive and non-preemptive rigid gang task\nsets.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.DC",
    "comment": "Published in IEEE Real-Time and Embedded Technology and Applications\n  Symposium (RTAS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.10726v2",
    "published_date": "2024-03-15 23:17:24 UTC",
    "updated_date": "2024-09-01 05:05:17 UTC"
  },
  {
    "arxiv_id": "2403.10720v1",
    "title": "Development and Application of a Monte Carlo Tree Search Algorithm for Simulating Da Vinci Code Game Strategies",
    "authors": [
      "Ye Zhang",
      "Mengran Zhu",
      "Kailin Gui",
      "Jiayue Yu",
      "Yong Hao",
      "Haozhan Sun"
    ],
    "abstract": "In this study, we explore the efficiency of the Monte Carlo Tree Search\n(MCTS), a prominent decision-making algorithm renowned for its effectiveness in\ncomplex decision environments, contingent upon the volume of simulations\nconducted. Notwithstanding its broad applicability, the algorithm's performance\ncan be adversely impacted in certain scenarios, particularly within the domain\nof game strategy development. This research posits that the inherent branch\ndivergence within the Da Vinci Code board game significantly impedes\nparallelism when executed on Graphics Processing Units (GPUs). To investigate\nthis hypothesis, we implemented and meticulously evaluated two variants of the\nMCTS algorithm, specifically designed to assess the impact of branch divergence\non computational performance. Our comparative analysis reveals a linear\nimprovement in performance with the CPU-based implementation, in stark contrast\nto the GPU implementation, which exhibits a non-linear enhancement pattern and\ndiscernible performance troughs. These findings contribute to a deeper\nunderstanding of the MCTS algorithm's behavior in divergent branch scenarios,\nhighlighting critical considerations for optimizing game strategy algorithms on\nparallel computing architectures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted by CVIDL2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10720v1",
    "published_date": "2024-03-15 22:43:37 UTC",
    "updated_date": "2024-03-15 22:43:37 UTC"
  },
  {
    "arxiv_id": "2403.10717v1",
    "title": "Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency",
    "authors": [
      "Soumyadeep Pal",
      "Yuguang Yao",
      "Ren Wang",
      "Bingquan Shen",
      "Sijia Liu"
    ],
    "abstract": "Modern machine learning (ML) systems demand substantial training data, often\nresorting to external sources. Nevertheless, this practice renders them\nvulnerable to backdoor poisoning attacks. Prior backdoor defense strategies\nhave primarily focused on the identification of backdoored models or poisoned\ndata characteristics, typically operating under the assumption of access to\nclean data. In this work, we delve into a relatively underexplored challenge:\nthe automatic identification of backdoor data within a poisoned dataset, all\nunder realistic conditions, i.e., without the need for additional clean data or\nwithout manually defining a threshold for backdoor detection. We draw an\ninspiration from the scaled prediction consistency (SPC) technique, which\nexploits the prediction invariance of poisoned data to an input scaling factor.\nBased on this, we pose the backdoor data identification problem as a\nhierarchical data splitting optimization problem, leveraging a novel SPC-based\nloss function as the primary optimization objective. Our innovation unfolds in\nseveral key aspects. First, we revisit the vanilla SPC method, unveiling its\nlimitations in addressing the proposed backdoor identification problem.\nSubsequently, we develop a bi-level optimization-based approach to precisely\nidentify backdoor data by minimizing the advanced SPC loss. Finally, we\ndemonstrate the efficacy of our proposal against a spectrum of backdoor\nattacks, encompassing basic label-corrupted attacks as well as more\nsophisticated clean-label attacks, evaluated across various benchmark datasets.\nExperiment results show that our approach often surpasses the performance of\ncurrent baselines in identifying backdoor data points, resulting in about\n4%-36% improvement in average AUROC. Codes are available at\nhttps://github.com/OPTML-Group/BackdoorMSPC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "The Twelfth International Conference on Learning Representations\n  (ICLR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.10717v1",
    "published_date": "2024-03-15 22:35:07 UTC",
    "updated_date": "2024-03-15 22:35:07 UTC"
  },
  {
    "arxiv_id": "2403.10707v2",
    "title": "Discovering Latent Themes in Social Media Messaging: A Machine-in-the-Loop Approach Integrating LLMs",
    "authors": [
      "Tunazzina Islam",
      "Dan Goldwasser"
    ],
    "abstract": "Grasping the themes of social media content is key to understanding the\nnarratives that influence public opinion and behavior. The thematic analysis\ngoes beyond traditional topic-level analysis, which often captures only the\nbroadest patterns, providing deeper insights into specific and actionable\nthemes such as \"public sentiment towards vaccination\", \"political discourse\nsurrounding climate policies,\" etc. In this paper, we introduce a novel\napproach to uncovering latent themes in social media messaging. Recognizing the\nlimitations of the traditional topic-level analysis, which tends to capture\nonly overarching patterns, this study emphasizes the need for a finer-grained,\ntheme-focused exploration. Traditional theme discovery methods typically\ninvolve manual processes and a human-in-the-loop approach. While valuable,\nthese methods face challenges in scalability, consistency, and resource\nintensity in terms of time and cost. To address these challenges, we propose a\nmachine-in-the-loop approach that leverages the advanced capabilities of Large\nLanguage Models (LLMs). To demonstrate our approach, we apply our framework to\ncontentious topics, such as climate debate and vaccine debate. We use two\npublicly available datasets: (1) the climate campaigns dataset of 21k Facebook\nads and (2) the COVID-19 vaccine campaigns dataset of 9k Facebook ads. Our\nquantitative and qualitative analysis shows that our methodology yields more\naccurate and interpretable results compared to the baselines. Our results not\nonly demonstrate the effectiveness of our approach in uncovering latent themes\nbut also illuminate how these themes are tailored for demographic targeting in\nsocial media contexts. Additionally, our work sheds light on the dynamic nature\nof social media, revealing the shifts in the thematic focus of messaging in\nresponse to real-world events.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at 19th International AAAI Conference on Web and Social\n  Media (ICWSM-2025)",
    "pdf_url": "http://arxiv.org/pdf/2403.10707v2",
    "published_date": "2024-03-15 21:54:00 UTC",
    "updated_date": "2024-07-15 12:14:13 UTC"
  },
  {
    "arxiv_id": "2403.10704v2",
    "title": "Parameter Efficient Reinforcement Learning from Human Feedback",
    "authors": [
      "Hakim Sidahmed",
      "Samrat Phatale",
      "Alex Hutcheson",
      "Zhuonan Lin",
      "Zhang Chen",
      "Zac Yu",
      "Jarvis Jin",
      "Simral Chaudhary",
      "Roman Komarytsia",
      "Christiane Ahlheim",
      "Yonghao Zhu",
      "Bowen Li",
      "Saravanan Ganesh",
      "Bill Byrne",
      "Jessica Hoffmann",
      "Hassan Mansoor",
      "Wei Li",
      "Abhinav Rastogi",
      "Lucas Dixon"
    ],
    "abstract": "While Reinforcement Learning from Human Feedback (RLHF) effectively aligns\npretrained Large Language and Vision-Language Models (LLMs, and VLMs) with\nhuman preferences, its computational cost and complexity hamper its wider\nadoption. To alleviate some of the computational burden of fine-tuning,\nparameter efficient methods, like LoRA were introduced. In this work, we\nempirically evaluate the setup of Parameter Efficient Reinforcement Learning\nfrom Human Feedback (PE-RLHF) that leverages LoRA fine-tuning for Reward\nModeling, and Reinforcement Learning. We benchmark the PE-RLHF setup on six\ndiverse datasets spanning summarization, harmless/helpful response generation,\nUI automation, and visual question answering in terms of effectiveness of the\ntrained models, and the training resources required. Our findings show, for the\nfirst time, that PE-RLHF achieves comparable performance to RLHF, while\nsignificantly reducing training time (up to 90% faster for reward models, and\n30% faster for RL), and memory footprint (up to 50% reduction for reward\nmodels, and 27% for RL). We provide comprehensive ablations across LoRA ranks,\nand model sizes for both reward modeling and reinforcement learning. By\nmitigating the computational burden associated with RLHF, we push for a broader\nadoption of PE-RLHF as an alignment technique for LLMs and VLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10704v2",
    "published_date": "2024-03-15 21:43:46 UTC",
    "updated_date": "2024-09-12 18:25:16 UTC"
  },
  {
    "arxiv_id": "2403.15437v2",
    "title": "Apriori Knowledge in an Era of Computational Opacity: The Role of AI in Mathematical Discovery",
    "authors": [
      "Eamon Duede",
      "Kevin Davey"
    ],
    "abstract": "Can we acquire apriori knowledge of mathematical facts from the outputs of\ncomputer programs? People like Burge have argued (correctly in our opinion)\nthat, for example, Appel and Haken acquired apriori knowledge of the Four Color\nTheorem from their computer program insofar as their program simply automated\nhuman forms of mathematical reasoning. However, unlike such programs, we argue\nthat the opacity of modern LLMs and DNNs creates obstacles in obtaining apriori\nmathematical knowledge from them in similar ways. We claim though that if a\nproof-checker automating human forms of proof-checking is attached to such\nmachines, then we can obtain apriori mathematical knowledge from them after\nall, even though the original machines are entirely opaque to us and the proofs\nthey output may not, themselves, be human-surveyable.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "math.HO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15437v2",
    "published_date": "2024-03-15 21:38:26 UTC",
    "updated_date": "2024-12-16 21:31:15 UTC"
  },
  {
    "arxiv_id": "2403.10700v2",
    "title": "Mind the Error! Detection and Localization of Instruction Errors in Vision-and-Language Navigation",
    "authors": [
      "Francesco Taioli",
      "Stefano Rosa",
      "Alberto Castellini",
      "Lorenzo Natale",
      "Alessio Del Bue",
      "Alessandro Farinelli",
      "Marco Cristani",
      "Yiming Wang"
    ],
    "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) is one of\nthe most intuitive yet challenging embodied AI tasks. Agents are tasked to\nnavigate towards a target goal by executing a set of low-level actions,\nfollowing a series of natural language instructions. All VLN-CE methods in the\nliterature assume that language instructions are exact. However, in practice,\ninstructions given by humans can contain errors when describing a spatial\nenvironment due to inaccurate memory or confusion. Current VLN-CE benchmarks do\nnot address this scenario, making the state-of-the-art methods in VLN-CE\nfragile in the presence of erroneous instructions from human users. For the\nfirst time, we propose a novel benchmark dataset that introduces various types\nof instruction errors considering potential human causes. This benchmark\nprovides valuable insight into the robustness of VLN systems in continuous\nenvironments. We observe a noticeable performance drop (up to -25%) in Success\nRate when evaluating the state-of-the-art VLN-CE methods on our benchmark.\nMoreover, we formally define the task of Instruction Error Detection and\nLocalization, and establish an evaluation protocol on top of our benchmark\ndataset. We also propose an effective method, based on a cross-modal\ntransformer architecture, that achieves the best performance in error detection\nand localization, compared to baselines. Surprisingly, our proposed method has\nrevealed errors in the validation set of the two commonly used datasets for\nVLN-CE, i.e., R2R-CE and RxR-CE, demonstrating the utility of our technique in\nother tasks. Code and dataset available at\nhttps://intelligolabs.github.io/R2RIE-CE",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "3 figures, 8 pages. Accepted at IROS'24",
    "pdf_url": "http://arxiv.org/pdf/2403.10700v2",
    "published_date": "2024-03-15 21:36:15 UTC",
    "updated_date": "2025-01-15 12:45:24 UTC"
  },
  {
    "arxiv_id": "2403.10698v2",
    "title": "Robust Influence-based Training Methods for Noisy Brain MRI",
    "authors": [
      "Minh-Hao Van",
      "Alycia N. Carey",
      "Xintao Wu"
    ],
    "abstract": "Correctly classifying brain tumors is imperative to the prompt and accurate\ntreatment of a patient. While several classification algorithms based on\nclassical image processing or deep learning methods have been proposed to\nrapidly classify tumors in MR images, most assume the unrealistic setting of\nnoise-free training data. In this work, we study a difficult but realistic\nsetting of training a deep learning model on noisy MR images to classify brain\ntumors. We propose two training methods that are robust to noisy MRI training\ndata, Influence-based Sample Reweighing (ISR) and Influence-based Sample\nPerturbation (ISP), which are based on influence functions from robust\nstatistics. Using the influence functions, in ISR, we adaptively reweigh\ntraining examples according to how helpful/harmful they are to the training\nprocess, while in ISP, we craft and inject helpful perturbation proportional to\nthe influence score. Both ISR and ISP harden the classification model against\nnoisy training data without significantly affecting the generalization ability\nof the model on test data. We conduct empirical evaluations over a common brain\ntumor dataset and compare ISR and ISP to three baselines. Our empirical results\nshow that ISR and ISP can efficiently train deep learning models robust against\nnoisy training data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10698v2",
    "published_date": "2024-03-15 21:30:25 UTC",
    "updated_date": "2024-05-09 22:38:25 UTC"
  },
  {
    "arxiv_id": "2403.10692v1",
    "title": "EXPLORER: Exploration-guided Reasoning for Textual Reinforcement Learning",
    "authors": [
      "Kinjal Basu",
      "Keerthiram Murugesan",
      "Subhajit Chaudhury",
      "Murray Campbell",
      "Kartik Talamadupula",
      "Tim Klinger"
    ],
    "abstract": "Text-based games (TBGs) have emerged as an important collection of NLP tasks,\nrequiring reinforcement learning (RL) agents to combine natural language\nunderstanding with reasoning. A key challenge for agents attempting to solve\nsuch tasks is to generalize across multiple games and demonstrate good\nperformance on both seen and unseen objects. Purely deep-RL-based approaches\nmay perform well on seen objects; however, they fail to showcase the same\nperformance on unseen objects. Commonsense-infused deep-RL agents may work\nbetter on unseen data; unfortunately, their policies are often not\ninterpretable or easily transferable. To tackle these issues, in this paper, we\npresent EXPLORER which is an exploration-guided reasoning agent for textual\nreinforcement learning. EXPLORER is neurosymbolic in nature, as it relies on a\nneural module for exploration and a symbolic module for exploitation. It can\nalso learn generalized symbolic policies and perform well over unseen data. Our\nexperiments show that EXPLORER outperforms the baseline agents on Text-World\ncooking (TW-Cooking) and Text-World Commonsense (TWC) games.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10692v1",
    "published_date": "2024-03-15 21:22:37 UTC",
    "updated_date": "2024-03-15 21:22:37 UTC"
  },
  {
    "arxiv_id": "2403.10691v2",
    "title": "MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual Language Modeling",
    "authors": [
      "Tomasz Limisiewicz",
      "Terra Blevins",
      "Hila Gonen",
      "Orevaoghene Ahia",
      "Luke Zettlemoyer"
    ],
    "abstract": "A major consideration in multilingual language modeling is how to best\nrepresent languages with diverse vocabularies and scripts. Although\ncontemporary text encoding methods cover most of the world's writing systems,\nthey exhibit bias towards the high-resource languages of the Global West. As a\nresult, texts of underrepresented languages tend to be segmented into long\nsequences of linguistically meaningless units. To address the disparities, we\nintroduce a new paradigm that encodes the same information with segments of\nconsistent size across diverse languages. Our encoding convention (MYTE) is\nbased on morphemes, as their inventories are more balanced across languages\nthan characters, which are used in previous methods. We show that MYTE produces\nshorter encodings for all 99 analyzed languages, with the most notable\nimprovements for non-European languages and non-Latin scripts. This, in turn,\nimproves multilingual LM performance and diminishes the perplexity gap\nthroughout diverse languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10691v2",
    "published_date": "2024-03-15 21:21:11 UTC",
    "updated_date": "2024-11-11 13:33:25 UTC"
  },
  {
    "arxiv_id": "2403.10686v1",
    "title": "AutoHLS: Learning to Accelerate Design Space Exploration for HLS Designs",
    "authors": [
      "Md Rubel Ahmed",
      "Toshiaki Koike-Akino",
      "Kieran Parsons",
      "Ye Wang"
    ],
    "abstract": "High-level synthesis (HLS) is a design flow that leverages modern language\nfeatures and flexibility, such as complex data structures, inheritance,\ntemplates, etc., to prototype hardware designs rapidly. However, exploring\nvarious design space parameters can take much time and effort for hardware\nengineers to meet specific design specifications. This paper proposes a novel\nframework called AutoHLS, which integrates a deep neural network (DNN) with\nBayesian optimization (BO) to accelerate HLS hardware design optimization. Our\ntool focuses on HLS pragma exploration and operation transformation. It\nutilizes integrated DNNs to predict synthesizability within a given FPGA\nresource budget. We also investigate the potential of emerging quantum neural\nnetworks (QNNs) instead of classical DNNs for the AutoHLS pipeline. Our\nexperimental results demonstrate up to a 70-fold speedup in exploration time.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "5 pages, 6 figures, MWSCAS 2023",
    "pdf_url": "http://arxiv.org/pdf/2403.10686v1",
    "published_date": "2024-03-15 21:14:44 UTC",
    "updated_date": "2024-03-15 21:14:44 UTC"
  },
  {
    "arxiv_id": "2403.10684v1",
    "title": "Improved discrete particle swarm optimization using Bee Algorithm and multi-parent crossover method (Case study: Allocation problem and benchmark functions)",
    "authors": [
      "Hamed Zibaei",
      "Mohammad Saadi Mesgari"
    ],
    "abstract": "Compared to other techniques, particle swarm optimization is more frequently\nutilized because of its ease of use and low variability. However, it is\ncomplicated to find the best possible solution in the search space in\nlarge-scale optimization problems. Moreover, changing algorithm variables does\nnot influence algorithm convergence much. The PSO algorithm can be combined\nwith other algorithms. It can use their advantages and operators to solve this\nproblem. Therefore, this paper proposes the onlooker multi-parent crossover\ndiscrete particle swarm optimization (OMPCDPSO). To improve the efficiency of\nthe DPSO algorithm, we utilized multi-parent crossover on the best solutions.\nWe performed an independent and intensive neighborhood search using the\nonlooker bees of the bee algorithm. The algorithm uses onlooker bees and\ncrossover. They do local search (exploitation) and global search (exploration).\nEach of these searches is among the best solutions (employed bees). The\nproposed algorithm was tested on the allocation problem, which is an NP-hard\noptimization problem. Also, we used two types of simulated data. They were used\nto test the scalability and complexity of the better algorithm. Also, fourteen\n2D test functions and thirteen 30D test functions were used. They also used\ntwenty IEEE CEC2005 benchmark functions to test the efficiency of OMPCDPSO.\nAlso, to test OMPCDPSO's performance, we compared it to four new binary\noptimization algorithms and three classic ones. The results show that the\nOMPCDPSO version had high capability. It performed better than other\nalgorithms. The developed algorithm in this research (OMCDPSO) in 36 test\nfunctions out of 47 (76.60%) is better than other algorithms. The Onlooker bees\nand multi-parent operators significantly impact the algorithm's performance.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "34 pages, 8 figures, 15 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.10684v1",
    "published_date": "2024-03-15 21:08:37 UTC",
    "updated_date": "2024-03-15 21:08:37 UTC"
  },
  {
    "arxiv_id": "2403.14697v1",
    "title": "An AIC-based approach for articulating unpredictable problems in open complex environments",
    "authors": [
      "Haider AL-Shareefy",
      "Michael Butler",
      "Thai Son Hoang"
    ],
    "abstract": "This research paper presents an approach to enhancing the predictive\ncapability of architects in the design and assurance of systems, focusing on\nsystems operating in dynamic and unpredictable environments. By adopting a\nsystems approach, we aim to improve architects' predictive capabilities in\ndesigning dependable systems (for example, ML-based systems). An aerospace case\nstudy is used to illustrate the approach. Multiple factors (challenges)\ninfluencing aircraft detection are identified, demonstrating the effectiveness\nof our approach in a complex operational setting. Our approach primarily aimed\nto enhance the architect's predictive capability.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CY",
    "comment": "S. Bernardi, T. Zoppi (Editors), \"Fast Abstracts and Student Forum\n  Proceedings - EDCC 2024 - 19th European Dependable Computing Conference,\n  Leuven, Belgium, 8-11 April 2024\"",
    "pdf_url": "http://arxiv.org/pdf/2403.14697v1",
    "published_date": "2024-03-15 20:30:02 UTC",
    "updated_date": "2024-03-15 20:30:02 UTC"
  },
  {
    "arxiv_id": "2403.10667v2",
    "title": "Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond",
    "authors": [
      "Tianxin Wei",
      "Bowen Jin",
      "Ruirui Li",
      "Hansi Zeng",
      "Zhengyang Wang",
      "Jianhui Sun",
      "Qingyu Yin",
      "Hanqing Lu",
      "Suhang Wang",
      "Jingrui He",
      "Xianfeng Tang"
    ],
    "abstract": "Developing a universal model that can effectively harness heterogeneous\nresources and respond to a wide range of personalized needs has been a\nlongstanding community aspiration. Our daily choices, especially in domains\nlike fashion and retail, are substantially shaped by multi-modal data, such as\npictures and textual descriptions. These modalities not only offer intuitive\nguidance but also cater to personalized user preferences. However, the\npredominant personalization approaches mainly focus on the ID or text-based\nrecommendation problem, failing to comprehend the information spanning various\ntasks or modalities. In this paper, our goal is to establish a Unified paradigm\nfor Multi-modal Personalization systems (UniMP), which effectively leverages\nmulti-modal data while eliminating the complexities associated with task- and\nmodality-specific customization. We argue that the advancements in foundational\ngenerative modeling have provided the flexibility and effectiveness necessary\nto achieve the objective. In light of this, we develop a generic and extensible\npersonalization generative framework, that can handle a wide range of\npersonalized needs including item recommendation, product search, preference\nprediction, explanation generation, and further user-guided image generation.\nOur methodology enhances the capabilities of foundational language models for\npersonalized tasks by seamlessly ingesting interleaved cross-modal user history\ninformation, ensuring a more precise and customized experience for users. To\ntrain and evaluate the proposed multi-modal personalized tasks, we also\nintroduce a novel and comprehensive benchmark covering a variety of user\nrequirements. Our experiments on the real-world benchmark showcase the model's\npotential, outperforming competitive methods specialized for each task.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.IR",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10667v2",
    "published_date": "2024-03-15 20:21:31 UTC",
    "updated_date": "2024-03-27 21:11:19 UTC"
  },
  {
    "arxiv_id": "2403.10618v1",
    "title": "Limits of Approximating the Median Treatment Effect",
    "authors": [
      "Raghavendra Addanki",
      "Siddharth Bhandari"
    ],
    "abstract": "Average Treatment Effect (ATE) estimation is a well-studied problem in causal\ninference. However, it does not necessarily capture the heterogeneity in the\ndata, and several approaches have been proposed to tackle the issue, including\nestimating the Quantile Treatment Effects. In the finite population setting\ncontaining $n$ individuals, with treatment and control values denoted by the\npotential outcome vectors $\\mathbf{a}, \\mathbf{b}$, much of the prior work\nfocused on estimating median$(\\mathbf{a}) -$ median$(\\mathbf{b})$, where\nmedian($\\mathbf x$) denotes the median value in the sorted ordering of all the\nvalues in vector $\\mathbf x$. It is known that estimating the difference of\nmedians is easier than the desired estimand of median$(\\mathbf{a-b})$, called\nthe Median Treatment Effect (MTE). The fundamental problem of causal inference\n-- for every individual $i$, we can only observe one of the potential outcome\nvalues, i.e., either the value $a_i$ or $b_i$, but not both, makes estimating\nMTE particularly challenging. In this work, we argue that MTE is not estimable\nand detail a novel notion of approximation that relies on the sorted order of\nthe values in $\\mathbf{a-b}$. Next, we identify a quantity called variability\nthat exactly captures the complexity of MTE estimation. By drawing connections\nto instance-optimality studied in theoretical computer science, we show that\nevery algorithm for estimating the MTE obtains an approximation error that is\nno better than the error of an algorithm that computes variability. Finally, we\nprovide a simple linear time algorithm for computing the variability exactly.\nUnlike much prior work, a particular highlight of our work is that we make no\nassumptions about how the potential outcome vectors are generated or how they\nare correlated, except that the potential outcome values are $k$-ary, i.e.,\ntake one of $k$ discrete values.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "econ.EM",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10618v1",
    "published_date": "2024-03-15 18:30:06 UTC",
    "updated_date": "2024-03-15 18:30:06 UTC"
  },
  {
    "arxiv_id": "2403.10603v1",
    "title": "SurvRNC: Learning Ordered Representations for Survival Prediction using Rank-N-Contrast",
    "authors": [
      "Numan Saeed",
      "Muhammad Ridzuan",
      "Fadillah Adamsyah Maani",
      "Hussain Alasmawi",
      "Karthik Nandakumar",
      "Mohammad Yaqub"
    ],
    "abstract": "Predicting the likelihood of survival is of paramount importance for\nindividuals diagnosed with cancer as it provides invaluable information\nregarding prognosis at an early stage. This knowledge enables the formulation\nof effective treatment plans that lead to improved patient outcomes. In the\npast few years, deep learning models have provided a feasible solution for\nassessing medical images, electronic health records, and genomic data to\nestimate cancer risk scores. However, these models often fall short of their\npotential because they struggle to learn regression-aware feature\nrepresentations. In this study, we propose Survival Rank-N Contrast (SurvRNC)\nmethod, which introduces a loss function as a regularizer to obtain an ordered\nrepresentation based on the survival times. This function can handle censored\ndata and can be incorporated into any survival model to ensure that the learned\nrepresentation is ordinal. The model was extensively evaluated on a HEad \\&\nNeCK TumOR (HECKTOR) segmentation and the outcome-prediction task dataset. We\ndemonstrate that using the SurvRNC method for training can achieve higher\nperformance on different deep survival models. Additionally, it outperforms\nstate-of-the-art methods by 3.6% on the concordance index. The code is publicly\navailable on https://github.com/numanai/SurvRNC",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10603v1",
    "published_date": "2024-03-15 18:00:11 UTC",
    "updated_date": "2024-03-15 18:00:11 UTC"
  },
  {
    "arxiv_id": "2403.10596v1",
    "title": "Neural Erosion: Emulating Controlled Neurodegeneration and Aging in AI Systems",
    "authors": [
      "Antonios Alexos",
      "Yu-Dai Tsai",
      "Ian Domingo",
      "Maryam Pishgar",
      "Pierre Baldi"
    ],
    "abstract": "Creating controlled methods to simulate neurodegeneration in artificial\nintelligence (AI) is crucial for applications that emulate brain function\ndecline and cognitive disorders. We use IQ tests performed by Large Language\nModels (LLMs) and, more specifically, the LLaMA 2 to introduce the concept of\n``neural erosion.\" This deliberate erosion involves ablating synapses or\nneurons, or adding Gaussian noise during or after training, resulting in a\ncontrolled progressive decline in the LLMs' performance. We are able to\ndescribe the neurodegeneration in the IQ tests and show that the LLM first\nloses its mathematical abilities and then its linguistic abilities, while\nfurther losing its ability to understand the questions. To the best of our\nknowledge, this is the first work that models neurodegeneration with text data,\ncompared to other works that operate in the computer vision domain. Finally, we\ndraw similarities between our study and cognitive decline clinical studies\ninvolving test subjects. We find that with the application of neurodegenerative\nmethods, LLMs lose abstract thinking abilities, followed by mathematical\ndegradation, and ultimately, a loss in linguistic ability, responding to\nprompts incoherently. These findings are in accordance with human studies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 6 figures in the main text, 5 figures in the Appendix",
    "pdf_url": "http://arxiv.org/pdf/2403.10596v1",
    "published_date": "2024-03-15 18:00:00 UTC",
    "updated_date": "2024-03-15 18:00:00 UTC"
  },
  {
    "arxiv_id": "2403.10517v1",
    "title": "VideoAgent: Long-form Video Understanding with Large Language Model as Agent",
    "authors": [
      "Xiaohan Wang",
      "Yuhui Zhang",
      "Orr Zohar",
      "Serena Yeung-Levy"
    ],
    "abstract": "Long-form video understanding represents a significant challenge within\ncomputer vision, demanding a model capable of reasoning over long multi-modal\nsequences. Motivated by the human cognitive process for long-form video\nunderstanding, we emphasize interactive reasoning and planning over the ability\nto process lengthy visual inputs. We introduce a novel agent-based system,\nVideoAgent, that employs a large language model as a central agent to\niteratively identify and compile crucial information to answer a question, with\nvision-language foundation models serving as tools to translate and retrieve\nvisual information. Evaluated on the challenging EgoSchema and NExT-QA\nbenchmarks, VideoAgent achieves 54.1% and 71.3% zero-shot accuracy with only\n8.4 and 8.2 frames used on average. These results demonstrate superior\neffectiveness and efficiency of our method over the current state-of-the-art\nmethods, highlighting the potential of agent-based approaches in advancing\nlong-form video understanding.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10517v1",
    "published_date": "2024-03-15 17:57:52 UTC",
    "updated_date": "2024-03-15 17:57:52 UTC"
  },
  {
    "arxiv_id": "2403.10516v2",
    "title": "FeatUp: A Model-Agnostic Framework for Features at Any Resolution",
    "authors": [
      "Stephanie Fu",
      "Mark Hamilton",
      "Laura Brandt",
      "Axel Feldman",
      "Zhoutong Zhang",
      "William T. Freeman"
    ],
    "abstract": "Deep features are a cornerstone of computer vision research, capturing image\nsemantics and enabling the community to solve downstream tasks even in the\nzero- or few-shot regime. However, these features often lack the spatial\nresolution to directly perform dense prediction tasks like segmentation and\ndepth prediction because models aggressively pool information over large areas.\nIn this work, we introduce FeatUp, a task- and model-agnostic framework to\nrestore lost spatial information in deep features. We introduce two variants of\nFeatUp: one that guides features with high-resolution signal in a single\nforward pass, and one that fits an implicit model to a single image to\nreconstruct features at any resolution. Both approaches use a multi-view\nconsistency loss with deep analogies to NeRFs. Our features retain their\noriginal semantics and can be swapped into existing applications to yield\nresolution and performance gains even without re-training. We show that FeatUp\nsignificantly outperforms other feature upsampling and image super-resolution\napproaches in class activation map generation, transfer learning for\nsegmentation and depth prediction, and end-to-end training for semantic\nsegmentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the International Conference on Learning Representations\n  (ICLR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10516v2",
    "published_date": "2024-03-15 17:57:06 UTC",
    "updated_date": "2024-04-01 20:57:45 UTC"
  },
  {
    "arxiv_id": "2403.10506v2",
    "title": "HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation",
    "authors": [
      "Carmelo Sferrazza",
      "Dun-Ming Huang",
      "Xingyu Lin",
      "Youngwoon Lee",
      "Pieter Abbeel"
    ],
    "abstract": "Humanoid robots hold great promise in assisting humans in diverse\nenvironments and tasks, due to their flexibility and adaptability leveraging\nhuman-like morphology. However, research in humanoid robots is often\nbottlenecked by the costly and fragile hardware setups. To accelerate\nalgorithmic research in humanoid robots, we present a high-dimensional,\nsimulated robot learning benchmark, HumanoidBench, featuring a humanoid robot\nequipped with dexterous hands and a variety of challenging whole-body\nmanipulation and locomotion tasks. Our findings reveal that state-of-the-art\nreinforcement learning algorithms struggle with most tasks, whereas a\nhierarchical learning approach achieves superior performance when supported by\nrobust low-level policies, such as walking or reaching. With HumanoidBench, we\nprovide the robotics community with a platform to identify the challenges\narising when solving diverse tasks with humanoid robots, facilitating prompt\nverification of algorithms and ideas. The open-source code is available at\nhttps://humanoid-bench.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10506v2",
    "published_date": "2024-03-15 17:45:44 UTC",
    "updated_date": "2024-06-18 18:11:07 UTC"
  },
  {
    "arxiv_id": "2403.10502v1",
    "title": "Belief Change based on Knowledge Measures",
    "authors": [
      "Umberto Straccia",
      "Giovanni Casini"
    ],
    "abstract": "Knowledge Measures (KMs) aim at quantifying the amount of\nknowledge/information that a knowledge base carries. On the other hand, Belief\nChange (BC) is the process of changing beliefs (in our case, in terms of\ncontraction, expansion and revision) taking into account a new piece of\nknowledge, which possibly may be in contradiction with the current belief. We\npropose a new quantitative BC framework that is based on KMs by defining belief\nchange operators that try to minimise, from an information-theoretic point of\nview, the surprise that the changed belief carries. To this end, we introduce\nthe principle of minimal surprise. In particular, our contributions are (i) a\ngeneral information-theoretic approach to KMs for which [1] is a special case;\n(ii) KM-based BC operators that satisfy the so-called AGM postulates; and (iii)\na characterisation of any BC operator that satisfies the AGM postulates as a\nKM-based BC operator, i.e., any BC operator satisfying the AGM postulates can\nbe encoded within our quantitative BC framework. We also introduce quantitative\nmeasures that account for the information loss of contraction, information gain\nof expansion and information change of revision. We also give a succinct look\ninto the problem of iterated revision, which deals with the application of a\nsequence of revision operations in our framework, and also illustrate how one\nmay build from our KM-based contraction operator also one not satisfying the\n(in)famous recovery postulate, by focusing on the so-called severe withdrawal\nmodel as an illustrative example.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "48 pages, 3 figures, preprint",
    "pdf_url": "http://arxiv.org/pdf/2403.10502v1",
    "published_date": "2024-03-15 17:40:11 UTC",
    "updated_date": "2024-03-15 17:40:11 UTC"
  },
  {
    "arxiv_id": "2403.10499v1",
    "title": "Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study",
    "authors": [
      "Chenguang Wang",
      "Ruoxi Jia",
      "Xin Liu",
      "Dawn Song"
    ],
    "abstract": "Pre-training image representations from the raw text about images enables\nzero-shot vision transfer to downstream tasks. Through pre-training on millions\nof samples collected from the internet, multimodal foundation models, such as\nCLIP, produce state-of-the-art zero-shot results that often reach\ncompetitiveness with fully supervised methods without the need for\ntask-specific training. Besides the encouraging performance on classification\naccuracy, it is reported that these models close the robustness gap by matching\nthe performance of supervised models trained on ImageNet under natural\ndistribution shift. Because robustness is critical to real-world applications,\nespecially safety-critical ones, in this paper, we present a comprehensive\nevaluation based on a large-scale robustness benchmark covering 7 natural, 3\nsynthetic distribution shifts, and 11 adversarial attacks. We use CLIP as a\npilot study. We show that CLIP leads to a significant robustness drop compared\nto supervised ImageNet models on our benchmark, especially under synthetic\ndistribution shift and adversarial attacks. Furthermore, data overlap analysis\nsuggests that the observed robustness under natural distribution shifts could\nbe attributed, at least in part, to data overlap. In summary, our evaluation\nshows a comprehensive evaluation of robustness is necessary; and there is a\nsignificant need to improve the robustness of zero-shot multimodal models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10499v1",
    "published_date": "2024-03-15 17:33:49 UTC",
    "updated_date": "2024-03-15 17:33:49 UTC"
  },
  {
    "arxiv_id": "2403.10487v1",
    "title": "Stimulate the Potential of Robots via Competition",
    "authors": [
      "Kangyao Huang",
      "Di Guo",
      "Xinyu Zhang",
      "Xiangyang Ji",
      "Huaping Liu"
    ],
    "abstract": "It is common for us to feel pressure in a competition environment, which\narises from the desire to obtain success comparing with other individuals or\nopponents. Although we might get anxious under the pressure, it could also be a\ndrive for us to stimulate our potentials to the best in order to keep up with\nothers. Inspired by this, we propose a competitive learning framework which is\nable to help individual robot to acquire knowledge from the competition, fully\nstimulating its dynamics potential in the race. Specifically, the competition\ninformation among competitors is introduced as the additional auxiliary signal\nto learn advantaged actions. We further build a Multiagent-Race environment,\nand extensive experiments are conducted, demonstrating that robots trained in\ncompetitive environments outperform ones that are trained with SoTA algorithms\nin single robot environment.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10487v1",
    "published_date": "2024-03-15 17:21:39 UTC",
    "updated_date": "2024-03-15 17:21:39 UTC"
  },
  {
    "arxiv_id": "2403.10482v2",
    "title": "Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution Analyst?",
    "authors": [
      "Bruno de Melo",
      "Jamiel Sheikh"
    ],
    "abstract": "Performance attribution analysis, defined as the process of explaining the\ndrivers of the excess performance of an investment portfolio against a\nbenchmark, stands as a significant feature of portfolio management and plays a\ncrucial role in the investment decision-making process, particularly within the\nfund management industry. Rooted in a solid financial and mathematical\nframework, the importance and methodologies of this analytical technique are\nextensively documented across numerous academic research papers and books. The\nintegration of large language models (LLMs) and AI agents marks a\ngroundbreaking development in this field. These agents are designed to automate\nand enhance the performance attribution analysis by accurately calculating and\nanalyzing portfolio performances against benchmarks. In this study, we\nintroduce the application of an AI Agent for a variety of essential performance\nattribution tasks, including the analysis of performance drivers and utilizing\nLLMs as calculation engine for multi-level attribution analysis and\nquestion-answering (QA) tasks. Leveraging advanced prompt engineering\ntechniques such as Chain-of-Thought (CoT) and Plan and Solve (PS), and\nemploying a standard agent framework from LangChain, the research achieves\npromising results: it achieves accuracy rates exceeding 93% in analyzing\nperformance drivers, attains 100% in multi-level attribution calculations, and\nsurpasses 84% accuracy in QA exercises that simulate official examination\nstandards. These findings affirm the impactful role of AI agents, prompt\nengineering and evaluation in advancing portfolio management processes,\nhighlighting a significant development in the practical application and\nevaluation of Generative AI technologies within the domain.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "q-fin.PM"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10482v2",
    "published_date": "2024-03-15 17:12:57 UTC",
    "updated_date": "2024-03-22 13:59:34 UTC"
  },
  {
    "arxiv_id": "2403.10588v1",
    "title": "S3LLM: Large-Scale Scientific Software Understanding with LLMs using Source, Metadata, and Document",
    "authors": [
      "Kareem Shaik",
      "Dali Wang",
      "Weijian Zheng",
      "Qinglei Cao",
      "Heng Fan",
      "Peter Schwartz",
      "Yunhe Feng"
    ],
    "abstract": "The understanding of large-scale scientific software poses significant\nchallenges due to its diverse codebase, extensive code length, and target\ncomputing architectures. The emergence of generative AI, specifically large\nlanguage models (LLMs), provides novel pathways for understanding such complex\nscientific codes. This paper presents S3LLM, an LLM-based framework designed to\nenable the examination of source code, code metadata, and summarized\ninformation in conjunction with textual technical reports in an interactive,\nconversational manner through a user-friendly interface. S3LLM leverages\nopen-source LLaMA-2 models to enhance code analysis through the automatic\ntransformation of natural language queries into domain-specific language (DSL)\nqueries. Specifically, it translates these queries into Feature Query Language\n(FQL), enabling efficient scanning and parsing of entire code repositories. In\naddition, S3LLM is equipped to handle diverse metadata types, including DOT,\nSQL, and customized formats. Furthermore, S3LLM incorporates retrieval\naugmented generation (RAG) and LangChain technologies to directly query\nextensive documents. S3LLM demonstrates the potential of using locally deployed\nopen-source LLMs for the rapid understanding of large-scale scientific\ncomputing software, eliminating the need for extensive coding expertise, and\nthereby making the process more efficient and effective. S3LLM is available at\nhttps://github.com/ResponsibleAILab/s3llm.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10588v1",
    "published_date": "2024-03-15 17:04:27 UTC",
    "updated_date": "2024-03-15 17:04:27 UTC"
  },
  {
    "arxiv_id": "2403.10586v3",
    "title": "Reviewing AI's Role in Non-Muscle-Invasive Bladder Cancer Recurrence Prediction",
    "authors": [
      "Saram Abbas",
      "Rishad Shafik",
      "Naeem Soomro",
      "Rakesh Heer",
      "Kabita Adhikari"
    ],
    "abstract": "Notorious for its 70-80% recurrence rate, Non-muscle-invasive Bladder Cancer\n(NMIBC) imposes a significant human burden and is one of the costliest cancers\nto manage. Current tools for predicting NMIBC recurrence rely on scoring\nsystems that often overestimate risk and have poor accuracy. This is where\nMachine learning (ML)-based techniques have emerged as a promising approach for\npredicting NMIBC recurrence by leveraging molecular and clinical data. This\ncomprehensive review paper critically analyses ML-based frameworks for\npredicting NMIBC recurrence, focusing on their statistical robustness and\nalgorithmic efficacy. We meticulously examine the strengths and weaknesses of\neach study, by focusing on various prediction tasks, data modalities, and ML\nmodels, highlighting their remarkable performance alongside inherent\nlimitations. A diverse array of ML algorithms that leverage multimodal data\nspanning radiomics, clinical, histopathological, and genomic data, exhibit\nsignificant promise in accurately predicting NMIBC recurrence. However, the\npath to widespread adoption faces challenges concerning the generalisability\nand interpretability of models, emphasising the need for collaborative efforts,\nrobust datasets, and the incorporation of cost-effectiveness. Our detailed\ncategorisation and in-depth analysis illuminate the nuances, complexities, and\ncontexts that influence real-world advancement and adoption of these AI-based\ntechniques. This rigorous analysis equips researchers with a deeper\nunderstanding of the intricacies of the ML algorithms employed. Researchers can\nuse these insights to refine approaches, address limitations, and boost\ngeneralisability of their ML models, ultimately leading to reduced healthcare\ncosts and improved patient outcomes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 3 Figures",
    "pdf_url": "http://arxiv.org/pdf/2403.10586v3",
    "published_date": "2024-03-15 17:03:45 UTC",
    "updated_date": "2024-12-20 12:03:38 UTC"
  },
  {
    "arxiv_id": "2403.10462v2",
    "title": "Safety Cases: How to Justify the Safety of Advanced AI Systems",
    "authors": [
      "Joshua Clymer",
      "Nick Gabrieli",
      "David Krueger",
      "Thomas Larsen"
    ],
    "abstract": "As AI systems become more advanced, companies and regulators will make\ndifficult decisions about whether it is safe to train and deploy them. To\nprepare for these decisions, we investigate how developers could make a 'safety\ncase,' which is a structured rationale that AI systems are unlikely to cause a\ncatastrophe. We propose a framework for organizing a safety case and discuss\nfour categories of arguments to justify safety: total inability to cause a\ncatastrophe, sufficiently strong control measures, trustworthiness despite\ncapability to cause harm, and -- if AI systems become much more powerful --\ndeference to credible AI advisors. We evaluate concrete examples of arguments\nin each category and outline how arguments could be combined to justify that AI\nsystems are safe to deploy.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10462v2",
    "published_date": "2024-03-15 16:53:13 UTC",
    "updated_date": "2024-03-18 18:11:46 UTC"
  },
  {
    "arxiv_id": "2403.10460v1",
    "title": "Online Concurrent Multi-Robot Coverage Path Planning",
    "authors": [
      "Ratijit Mitra",
      "Indranil Saha"
    ],
    "abstract": "Recently, centralized receding horizon online multi-robot coverage path\nplanning algorithms have shown remarkable scalability in thoroughly exploring\nlarge, complex, unknown workspaces with many robots. In a horizon, the path\nplanning and the path execution interleave, meaning when the path planning\noccurs for robots with no paths, the robots with outstanding paths do not\nexecute, and subsequently, when the robots with new or outstanding paths\nexecute to reach respective goals, path planning does not occur for those\nrobots yet to get new paths, leading to wastage of both the robotic and the\ncomputation resources. As a remedy, we propose a centralized algorithm that is\nnot horizon-based. It plans paths at any time for a subset of robots with no\npaths, i.e., who have reached their previously assigned goals, while the rest\nexecute their outstanding paths, thereby enabling concurrent planning and\nexecution. We formally prove that the proposed algorithm ensures complete\ncoverage of an unknown workspace and analyze its time complexity. To\ndemonstrate scalability, we evaluate our algorithm to cover eight large $2$D\ngrid benchmark workspaces with up to 512 aerial and ground robots,\nrespectively. A comparison with a state-of-the-art horizon-based algorithm\nshows its superiority in completing the coverage with up to 1.6x speedup. For\nvalidation, we perform ROS + Gazebo simulations in six 2D grid benchmark\nworkspaces with 10 quadcopters and TurtleBots, respectively. We also\nsuccessfully conducted one outdoor experiment with three quadcopters and one\nindoor with two TurtleBots.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10460v1",
    "published_date": "2024-03-15 16:51:30 UTC",
    "updated_date": "2024-03-15 16:51:30 UTC"
  },
  {
    "arxiv_id": "2403.10454v2",
    "title": "Partially Observable Task and Motion Planning with Uncertainty and Risk Awareness",
    "authors": [
      "Aidan Curtis",
      "George Matheos",
      "Nishad Gothoskar",
      "Vikash Mansinghka",
      "Joshua Tenenbaum",
      "Tomás Lozano-Pérez",
      "Leslie Pack Kaelbling"
    ],
    "abstract": "Integrated task and motion planning (TAMP) has proven to be a valuable\napproach to generalizable long-horizon robotic manipulation and navigation\nproblems. However, the typical TAMP problem formulation assumes full\nobservability and deterministic action effects. These assumptions limit the\nability of the planner to gather information and make decisions that are\nrisk-aware. We propose a strategy for TAMP with Uncertainty and Risk Awareness\n(TAMPURA) that is capable of efficiently solving long-horizon planning problems\nwith initial-state and action outcome uncertainty, including problems that\nrequire information gathering and avoiding undesirable and irreversible\noutcomes. Our planner reasons under uncertainty at both the abstract task level\nand continuous controller level. Given a set of closed-loop goal-conditioned\ncontrollers operating in the primitive action space and a description of their\npreconditions and potential capabilities, we learn a high-level abstraction\nthat can be solved efficiently and then refined to continuous actions for\nexecution. We demonstrate our approach on several robotics problems where\nuncertainty is a crucial factor and show that reasoning under uncertainty in\nthese problems outperforms previously proposed determinized planning, direct\nsearch, and reinforcement learning strategies. Lastly, we demonstrate our\nplanner on two real-world robotics problems using recent advancements in\nprobabilistic perception.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10454v2",
    "published_date": "2024-03-15 16:42:14 UTC",
    "updated_date": "2024-10-06 17:34:15 UTC"
  },
  {
    "arxiv_id": "2403.10585v1",
    "title": "Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint",
    "authors": [
      "Haoyue Tang",
      "Tian Xie",
      "Aosong Feng",
      "Hanyu Wang",
      "Chenyang Zhang",
      "Yang Bai"
    ],
    "abstract": "Solving image inverse problems (e.g., super-resolution and inpainting)\nrequires generating a high fidelity image that matches the given input (the\nlow-resolution image or the masked image). By using the input image as\nguidance, we can leverage a pretrained diffusion generative model to solve a\nwide range of image inverse tasks without task specific model fine-tuning. To\nprecisely estimate the guidance score function of the input image, we propose\nDiffusion Policy Gradient (DPG), a tractable computation method by viewing the\nintermediate noisy images as policies and the target image as the states\nselected by the policy. Experiments show that our method is robust to both\nGaussian and Poisson noise degradation on multiple linear and non-linear\ninverse tasks, resulting into a higher image restoration quality on FFHQ,\nImageNet and LSUN datasets.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted and to Appear, AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10585v1",
    "published_date": "2024-03-15 16:38:47 UTC",
    "updated_date": "2024-03-15 16:38:47 UTC"
  },
  {
    "arxiv_id": "2405.06645v1",
    "title": "On Recovering Higher-order Interactions from Protein Language Models",
    "authors": [
      "Darin Tsui",
      "Amirali Aghazadeh"
    ],
    "abstract": "Protein language models leverage evolutionary information to perform\nstate-of-the-art 3D structure and zero-shot variant prediction. Yet, extracting\nand explaining all the mutational interactions that govern model predictions\nremains difficult as it requires querying the entire amino acid space for $n$\nsites using $20^n$ sequences, which is computationally expensive even for\nmoderate values of $n$ (e.g., $n\\sim10$). Although approaches to lower the\nsample complexity exist, they often limit the interpretability of the model to\njust single and pairwise interactions. Recently, computationally scalable\nalgorithms relying on the assumption of sparsity in the Fourier domain have\nemerged to learn interactions from experimental data. However, extracting\ninteractions from language models poses unique challenges: it's unclear if\nsparsity is always present or if it is the only metric needed to assess the\nutility of Fourier algorithms. Herein, we develop a framework to do a\nsystematic Fourier analysis of the protein language model ESM2 applied on three\nproteins-green fluorescent protein (GFP), tumor protein P53 (TP53), and G\ndomain B1 (GB1)-across various sites for 228 experiments. We demonstrate that\nESM2 is dominated by three regions in the sparsity-ruggedness plane, two of\nwhich are better suited for sparse Fourier transforms. Validations on two\nsample proteins demonstrate recovery of all interactions with $R^2=0.72$ in the\nmore sparse region and $R^2=0.66$ in the more dense region, using only 7\nmillion out of $20^{10}\\sim10^{13}$ ESM2 samples, reducing the computational\ntime by a staggering factor of 15,000. All codes and data are available on our\nGitHub repository https://github.com/amirgroup-codes/InteractionRecovery.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06645v1",
    "published_date": "2024-03-15 16:35:47 UTC",
    "updated_date": "2024-03-15 16:35:47 UTC"
  },
  {
    "arxiv_id": "2403.10438v1",
    "title": "Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams",
    "authors": [
      "Vanessa Aisyahsari Hanschke",
      "Dylan Rees",
      "Merve Alanyali",
      "David Hopkinson",
      "Paul Marshall"
    ],
    "abstract": "Researchers urge technology practitioners such as data scientists to consider\nthe impacts and ethical implications of algorithmic decisions. However, unlike\nprogramming, statistics, and data management, discussion of ethical\nimplications is rarely included in standard data science training. To begin to\naddress this gap, we designed and tested a toolbox called the data ethics\nemergency drill (DEED) to help data science teams discuss and reflect on the\nethical implications of their work. The DEED is a roleplay of a fictional\nethical emergency scenario that is contextually situated in the team's specific\nworkplace and applications. This paper outlines the DEED toolbox and describes\nthree studies carried out with two different data science teams that\niteratively shaped its design. Our findings show that practitioners can apply\nlessons learnt from the roleplay to real-life situations, and how the DEED\nopened up conversations around ethics and values.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "accepted to CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10438v1",
    "published_date": "2024-03-15 16:20:51 UTC",
    "updated_date": "2024-03-15 16:20:51 UTC"
  },
  {
    "arxiv_id": "2403.10433v4",
    "title": "AI-enhanced Collective Intelligence",
    "authors": [
      "Hao Cui",
      "Taha Yasseri"
    ],
    "abstract": "Current societal challenges exceed the capacity of humans operating either\nalone or collectively. As AI evolves, its role within human collectives will\nvary from an assistive tool to a participatory member. Humans and AI possess\ncomplementary capabilities that, together, can surpass the collective\nintelligence of either humans or AI in isolation. However, the interactions in\nhuman-AI systems are inherently complex, involving intricate processes and\ninterdependencies. This review incorporates perspectives from complex network\nscience to conceptualize a multilayer representation of human-AI collective\nintelligence, comprising cognition, physical, and information layers. Within\nthis multilayer network, humans and AI agents exhibit varying characteristics;\nhumans differ in diversity from surface-level to deep-level attributes, while\nAI agents range in degrees of functionality and anthropomorphism. We explore\nhow agents' diversity and interactions influence the system's collective\nintelligence and analyze real-world instances of AI-enhanced collective\nintelligence. We conclude by considering potential challenges and future\ndevelopments in this field.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "43 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.10433v4",
    "published_date": "2024-03-15 16:11:15 UTC",
    "updated_date": "2024-09-26 09:33:29 UTC"
  },
  {
    "arxiv_id": "2403.10425v1",
    "title": "NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices",
    "authors": [
      "Zhiyong Zhang",
      "Huaizu Jiang",
      "Hanumant Singh"
    ],
    "abstract": "Real-time high-accuracy optical flow estimation is a crucial component in\nvarious applications, including localization and mapping in robotics, object\ntracking, and activity recognition in computer vision. While recent\nlearning-based optical flow methods have achieved high accuracy, they often\ncome with heavy computation costs. In this paper, we propose a highly efficient\noptical flow architecture, called NeuFlow, that addresses both high accuracy\nand computational cost concerns. The architecture follows a global-to-local\nscheme. Given the features of the input images extracted at different spatial\nresolutions, global matching is employed to estimate an initial optical flow on\nthe 1/16 resolution, capturing large displacement, which is then refined on the\n1/8 resolution with lightweight CNN layers for better accuracy. We evaluate our\napproach on Jetson Orin Nano and RTX 2080 to demonstrate efficiency\nimprovements across different computing platforms. We achieve a notable 10x-80x\nspeedup compared to several state-of-the-art methods, while maintaining\ncomparable accuracy. Our approach achieves around 30 FPS on edge computing\nplatforms, which represents a significant breakthrough in deploying complex\ncomputer vision tasks such as SLAM on small robots like drones. The full\ntraining and evaluation code is available at\nhttps://github.com/neufieldrobotics/NeuFlow.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10425v1",
    "published_date": "2024-03-15 15:58:51 UTC",
    "updated_date": "2024-03-15 15:58:51 UTC"
  },
  {
    "arxiv_id": "2403.10415v1",
    "title": "Gradient based Feature Attribution in Explainable AI: A Technical Review",
    "authors": [
      "Yongjie Wang",
      "Tong Zhang",
      "Xu Guo",
      "Zhiqi Shen"
    ],
    "abstract": "The surge in black-box AI models has prompted the need to explain the\ninternal mechanism and justify their reliability, especially in high-stakes\napplications, such as healthcare and autonomous driving. Due to the lack of a\nrigorous definition of explainable AI (XAI), a plethora of research related to\nexplainability, interpretability, and transparency has been developed to\nexplain and analyze the model from various perspectives. Consequently, with an\nexhaustive list of papers, it becomes challenging to have a comprehensive\noverview of XAI research from all aspects. Considering the popularity of neural\nnetworks in AI research, we narrow our focus to a specific area of XAI\nresearch: gradient based explanations, which can be directly adopted for neural\nnetwork models. In this review, we systematically explore gradient based\nexplanation methods to date and introduce a novel taxonomy to categorize them\ninto four distinct classes. Then, we present the essence of technique details\nin chronological order and underscore the evolution of algorithms. Next, we\nintroduce both human and quantitative evaluations to measure algorithm\nperformance. More importantly, we demonstrate the general challenges in XAI and\nspecific challenges in gradient based explanations. We hope that this survey\ncan help researchers understand state-of-the-art progress and their\ncorresponding disadvantages, which could spark their interest in addressing\nthese issues in future work.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10415v1",
    "published_date": "2024-03-15 15:49:31 UTC",
    "updated_date": "2024-03-15 15:49:31 UTC"
  },
  {
    "arxiv_id": "2403.10403v1",
    "title": "Energy Correction Model in the Feature Space for Out-of-Distribution Detection",
    "authors": [
      "Marc Lafon",
      "Clément Rambour",
      "Nicolas Thome"
    ],
    "abstract": "In this work, we study the out-of-distribution (OOD) detection problem\nthrough the use of the feature space of a pre-trained deep classifier. We show\nthat learning the density of in-distribution (ID) features with an energy-based\nmodels (EBM) leads to competitive detection results. However, we found that the\nnon-mixing of MCMC sampling during the EBM's training undermines its detection\nperformance. To overcome this an energy-based correction of a mixture of\nclass-conditional Gaussian distributions. We obtains favorable results when\ncompared to a strong baseline like the KNN detector on the CIFAR-10/CIFAR-100\nOOD detection benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS ML Safety Workshop (2022)",
    "pdf_url": "http://arxiv.org/pdf/2403.10403v1",
    "published_date": "2024-03-15 15:37:04 UTC",
    "updated_date": "2024-03-15 15:37:04 UTC"
  },
  {
    "arxiv_id": "2403.10401v1",
    "title": "SculptDiff: Learning Robotic Clay Sculpting from Humans with Goal Conditioned Diffusion Policy",
    "authors": [
      "Alison Bartsch",
      "Arvind Car",
      "Charlotte Avra",
      "Amir Barati Farimani"
    ],
    "abstract": "Manipulating deformable objects remains a challenge within robotics due to\nthe difficulties of state estimation, long-horizon planning, and predicting how\nthe object will deform given an interaction. These challenges are the most\npronounced with 3D deformable objects. We propose SculptDiff, a\ngoal-conditioned diffusion-based imitation learning framework that works with\npoint cloud state observations to directly learn clay sculpting policies for a\nvariety of target shapes. To the best of our knowledge this is the first\nreal-world method that successfully learns manipulation policies for 3D\ndeformable objects. For sculpting videos and access to our dataset and hardware\nCAD models, see the project website:\nhttps://sites.google.com/andrew.cmu.edu/imitation-sculpting/home",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10401v1",
    "published_date": "2024-03-15 15:34:59 UTC",
    "updated_date": "2024-03-15 15:34:59 UTC"
  },
  {
    "arxiv_id": "2403.10380v5",
    "title": "BirdSet: A Large-Scale Dataset for Audio Classification in Avian Bioacoustics",
    "authors": [
      "Lukas Rauch",
      "Raphael Schwinger",
      "Moritz Wirth",
      "René Heinrich",
      "Denis Huseljic",
      "Marek Herde",
      "Jonas Lange",
      "Stefan Kahl",
      "Bernhard Sick",
      "Sven Tomforde",
      "Christoph Scholz"
    ],
    "abstract": "Deep learning (DL) has greatly advanced audio classification, yet the field\nis limited by the scarcity of large-scale benchmark datasets that have\npropelled progress in other domains. While AudioSet is a pivotal step to bridge\nthis gap as a universal-domain dataset, its restricted accessibility and\nlimited range of evaluation use cases challenge its role as the sole resource.\nTherefore, we introduce \\texttt{BirdSet}, a large-scale benchmark dataset for\naudio classification focusing on avian bioacoustics. \\texttt{BirdSet} surpasses\nAudioSet with over 6,800 recording hours~($\\uparrow\\!17\\%$) from nearly 10,000\nclasses~($\\uparrow\\!18\\times$) for training and more than 400\nhours~($\\uparrow\\!7\\times$) across eight strongly labeled evaluation datasets.\nIt serves as a versatile resource for use cases such as multi-label\nclassification, covariate shift or self-supervised learning. We benchmark six\nwell-known DL models in multi-label classification across three distinct\ntraining scenarios and outline further evaluation use cases in audio\nclassification. We host our dataset on Hugging Face for easy accessibility and\noffer an extensive codebase to reproduce our results.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "accepted@ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2403.10380v5",
    "published_date": "2024-03-15 15:10:40 UTC",
    "updated_date": "2025-02-03 10:39:15 UTC"
  },
  {
    "arxiv_id": "2403.10371v1",
    "title": "An Energy-Efficient Ensemble Approach for Mitigating Data Incompleteness in IoT Applications",
    "authors": [
      "Yousef AlShehri",
      "Lakshmish Ramaswamy"
    ],
    "abstract": "Machine Learning (ML) is becoming increasingly important for IoT-based\napplications. However, the dynamic and ad-hoc nature of many IoT ecosystems\nposes unique challenges to the efficacy of ML algorithms. One such challenge is\ndata incompleteness, which is manifested as missing sensor readings. Many\nfactors, including sensor failures and/or network disruption, can cause data\nincompleteness. Furthermore, most IoT systems are severely power-constrained.\nIt is important that we build IoT-based ML systems that are robust against data\nincompleteness while simultaneously being energy efficient. This paper presents\nan empirical study of SECOE - a recent technique for alleviating data\nincompleteness in IoT - with respect to its energy bottlenecks. Towards\naddressing the energy bottlenecks of SECOE, we propose ENAMLE - a proactive,\nenergy-aware technique for mitigating the impact of concurrent missing data.\nENAMLE is unique in the sense that it builds an energy-aware ensemble of\nsub-models, each trained with a subset of sensors chosen carefully based on\ntheir correlations. Furthermore, at inference time, ENAMLE adaptively alters\nthe number of the ensemble of models based on the amount of missing data rate\nand the energy-accuracy trade-off. ENAMLE's design includes several novel\nmechanisms for minimizing energy consumption while maintaining accuracy. We\npresent extensive experimental studies on two distinct datasets that\ndemonstrate the energy efficiency of ENAMLE and its ability to alleviate sensor\nfailures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 8 figures, 1 table, Accepted as a conference paper at IEEE\n  INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SMART SYSTEMS AND THE\n  INTERNET OF THINGS (DCOSS-IoT 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.10371v1",
    "published_date": "2024-03-15 15:01:48 UTC",
    "updated_date": "2024-03-15 15:01:48 UTC"
  },
  {
    "arxiv_id": "2403.10365v1",
    "title": "Scalable Algorithms for Individual Preference Stable Clustering",
    "authors": [
      "Ron Mosenzon",
      "Ali Vakilian"
    ],
    "abstract": "In this paper, we study the individual preference (IP) stability, which is an\nnotion capturing individual fairness and stability in clustering. Within this\nsetting, a clustering is $\\alpha$-IP stable when each data point's average\ndistance to its cluster is no more than $\\alpha$ times its average distance to\nany other cluster. In this paper, we study the natural local search algorithm\nfor IP stable clustering. Our analysis confirms a $O(\\log n)$-IP stability\nguarantee for this algorithm, where $n$ denotes the number of points in the\ninput. Furthermore, by refining the local search approach, we show it runs in\nan almost linear time, $\\tilde{O}(nk)$.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "59 pages, 9 figures, submitted to AIStats2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10365v1",
    "published_date": "2024-03-15 14:58:27 UTC",
    "updated_date": "2024-03-15 14:58:27 UTC"
  },
  {
    "arxiv_id": "2404.00014v1",
    "title": "Deep Geometry Handling and Fragment-wise Molecular 3D Graph Generation",
    "authors": [
      "Odin Zhang",
      "Yufei Huang",
      "Shichen Cheng",
      "Mengyao Yu",
      "Xujun Zhang",
      "Haitao Lin",
      "Yundian Zeng",
      "Mingyang Wang",
      "Zhenxing Wu",
      "Huifeng Zhao",
      "Zaixi Zhang",
      "Chenqing Hua",
      "Yu Kang",
      "Sunliang Cui",
      "Peichen Pan",
      "Chang-Yu Hsieh",
      "Tingjun Hou"
    ],
    "abstract": "Most earlier 3D structure-based molecular generation approaches follow an\natom-wise paradigm, incrementally adding atoms to a partially built molecular\nfragment within protein pockets. These methods, while effective in designing\ntightly bound ligands, often overlook other essential properties such as\nsynthesizability. The fragment-wise generation paradigm offers a promising\nsolution. However, a common challenge across both atom-wise and fragment-wise\nmethods lies in their limited ability to co-design plausible chemical and\ngeometrical structures, resulting in distorted conformations. In response to\nthis challenge, we introduce the Deep Geometry Handling protocol, a more\nabstract design that extends the design focus beyond the model architecture.\nThrough a comprehensive review of existing geometry-related models and their\nprotocols, we propose a novel hybrid strategy, culminating in the development\nof FragGen - a geometry-reliable, fragment-wise molecular generation method.\nFragGen marks a significant leap forward in the quality of generated geometry\nand the synthesis accessibility of molecules. The efficacy of FragGen is\nfurther validated by its successful application in designing type II kinase\ninhibitors at the nanomolar level.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.00014v1",
    "published_date": "2024-03-15 14:45:41 UTC",
    "updated_date": "2024-03-15 14:45:41 UTC"
  },
  {
    "arxiv_id": "2405.04538v1",
    "title": "DiffFinger: Advancing Synthetic Fingerprint Generation through Denoising Diffusion Probabilistic Models",
    "authors": [
      "Freddie Grabovski",
      "Lior Yasur",
      "Yaniv Hacmon",
      "Lior Nisimov",
      "Stav Nimrod"
    ],
    "abstract": "This study explores the generation of synthesized fingerprint images using\nDenoising Diffusion Probabilistic Models (DDPMs). The significant obstacles in\ncollecting real biometric data, such as privacy concerns and the demand for\ndiverse datasets, underscore the imperative for synthetic biometric\nalternatives that are both realistic and varied. Despite the strides made with\nGenerative Adversarial Networks (GANs) in producing realistic fingerprint\nimages, their limitations prompt us to propose DDPMs as a promising\nalternative. DDPMs are capable of generating images with increasing clarity and\nrealism while maintaining diversity. Our results reveal that DiffFinger not\nonly competes with authentic training set data in quality but also provides a\nricher set of biometric data, reflecting true-to-life variability. These\nfindings mark a promising stride in biometric synthesis, showcasing the\npotential of DDPMs to advance the landscape of fingerprint identification and\nauthentication systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04538v1",
    "published_date": "2024-03-15 14:34:29 UTC",
    "updated_date": "2024-03-15 14:34:29 UTC"
  },
  {
    "arxiv_id": "2403.14694v1",
    "title": "Application of GPT Language Models for Innovation in Activities in University Teaching",
    "authors": [
      "Manuel de Buenaga",
      "Francisco Javier Bueno"
    ],
    "abstract": "The GPT (Generative Pre-trained Transformer) language models are an\nartificial intelligence and natural language processing technology that enables\nautomatic text generation. There is a growing interest in applying GPT language\nmodels to university teaching in various dimensions. From the perspective of\ninnovation in student and teacher activities, they can provide support in\nunderstanding and generating content, problem-solving, as well as\npersonalization and test correction, among others. From the dimension of\ninternationalization, the misuse of these models represents a global problem\nthat requires taking a series of common measures in universities from different\ngeographical areas. In several countries, there has been a review of assessment\ntools to ensure that work is done by students and not by AI. To this end, we\nhave conducted a detailed experiment in a representative subject of Computer\nScience such as Software Engineering, which has focused on evaluating the use\nof ChatGPT as an assistant in theory activities, exercises, and laboratory\npractices, assessing its potential use as a support tool for both students and\nteachers.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "15 pages, in spanish language, 4 tables, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.14694v1",
    "published_date": "2024-03-15 14:31:52 UTC",
    "updated_date": "2024-03-15 14:31:52 UTC"
  },
  {
    "arxiv_id": "2403.10327v1",
    "title": "Unsupervised Threat Hunting using Continuous Bag-of-Terms-and-Time (CBoTT)",
    "authors": [
      "Varol Kayhan",
      "Shivendu Shivendu",
      "Rouzbeh Behnia",
      "Clinton Daniel",
      "Manish Agrawal"
    ],
    "abstract": "Threat hunting is sifting through system logs to detect malicious activities\nthat might have bypassed existing security measures. It can be performed in\nseveral ways, one of which is based on detecting anomalies. We propose an\nunsupervised framework, called continuous bag-of-terms-and-time (CBoTT), and\npublish its application programming interface (API) to help researchers and\ncybersecurity analysts perform anomaly-based threat hunting among SIEM logs\ngeared toward process auditing on endpoint devices. Analyses show that our\nframework consistently outperforms benchmark approaches. When logs are sorted\nby likelihood of being an anomaly (from most likely to least), our approach\nidentifies anomalies at higher percentiles (between 1.82-6.46) while benchmark\napproaches identify the same anomalies at lower percentiles (between\n3.25-80.92). This framework can be used by other researchers to conduct\nbenchmark analyses and cybersecurity analysts to find anomalies in SIEM logs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10327v1",
    "published_date": "2024-03-15 14:16:10 UTC",
    "updated_date": "2024-03-15 14:16:10 UTC"
  },
  {
    "arxiv_id": "2403.10326v1",
    "title": "CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model",
    "authors": [
      "Shang-Hsuan Chiang",
      "Ssu-Cheng Wang",
      "Yao-Chung Fan"
    ],
    "abstract": "Manually designing cloze test consumes enormous time and efforts. The major\nchallenge lies in wrong option (distractor) selection. Having carefully-design\ndistractors improves the effectiveness of learner ability assessment. As a\nresult, the idea of automatically generating cloze distractor is motivated. In\nthis paper, we investigate cloze distractor generation by exploring the\nemployment of pre-trained language models (PLMs) as an alternative for\ncandidate distractor generation. Experiments show that the PLM-enhanced model\nbrings a substantial performance improvement. Our best performing model\nadvances the state-of-the-art result from 14.94 to 34.17 (NDCG@10 score). Our\ncode and dataset is available at https://github.com/AndyChiangSH/CDGP.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of short paper, EMNLP 2022",
    "pdf_url": "http://arxiv.org/pdf/2403.10326v1",
    "published_date": "2024-03-15 14:14:26 UTC",
    "updated_date": "2024-03-15 14:14:26 UTC"
  },
  {
    "arxiv_id": "2403.10304v2",
    "title": "KIF: A Wikidata-Based Framework for Integrating Heterogeneous Knowledge Sources",
    "authors": [
      "Guilherme Lima",
      "João M. B. Rodrigues",
      "Marcelo Machado",
      "Elton Soares",
      "Sandro R. Fiorini",
      "Raphael Thiago",
      "Leonardo G. Azevedo",
      "Viviane T. da Silva",
      "Renato Cerqueira"
    ],
    "abstract": "We present a Wikidata-based framework, called KIF, for virtually integrating\nheterogeneous knowledge sources. KIF is written in Python and is released as\nopen-source. It leverages Wikidata's data model and vocabulary plus\nuser-defined mappings to construct a unified view of the underlying sources\nwhile keeping track of the context and provenance of their statements. The\nunderlying sources can be triplestores, relational databases, CSV files, etc.,\nwhich may or may not use the vocabulary and RDF encoding of Wikidata. The end\nresult is a virtual knowledge base which behaves like an \"extended Wikidata\"\nand which can be queried using a simple but expressive pattern language,\ndefined in terms of Wikidata's data model. In this paper, we present the design\nand implementation of KIF, discuss how we have used it to solve a real\nintegration problem in the domain of chemistry (involving Wikidata, PubChem,\nand IBM CIRCA), and present experimental results on the performance and\noverhead of KIF",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10304v2",
    "published_date": "2024-03-15 13:46:36 UTC",
    "updated_date": "2024-07-24 13:43:33 UTC"
  },
  {
    "arxiv_id": "2403.10299v1",
    "title": "A Multi-constraint and Multi-objective Allocation Model for Emergency Rescue in IoT Environment",
    "authors": [
      "Xinrun Xu",
      "Zhanbiao Lian",
      "Yurong Wu",
      "Manying Lv",
      "Zhiming Ding",
      "Jian Yan",
      "Shang Jiang"
    ],
    "abstract": "Emergency relief operations are essential in disaster aftermaths,\nnecessitating effective resource allocation to minimize negative impacts and\nmaximize benefits. In prolonged crises or extensive disasters, a systematic,\nmulti-cycle approach is key for timely and informed decision-making. Leveraging\nadvancements in IoT and spatio-temporal data analytics, we've developed the\nMulti-Objective Shuffled Gray-Wolf Frog Leaping Model (MSGW-FLM). This\nmulti-constraint, multi-objective resource allocation model has been rigorously\ntested against 28 diverse challenges, showing superior performance in\ncomparison to established models such as NSGA-II, IBEA, and MOEA/D. MSGW-FLM's\neffectiveness is particularly notable in complex, multi-cycle emergency rescue\nscenarios, which involve numerous constraints and objectives. This model\nrepresents a significant step forward in optimizing resource distribution in\nemergency response situations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 5 figures, ISCAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10299v1",
    "published_date": "2024-03-15 13:42:00 UTC",
    "updated_date": "2024-03-15 13:42:00 UTC"
  },
  {
    "arxiv_id": "2403.10288v1",
    "title": "Rough Transformers for Continuous and Efficient Time-Series Modelling",
    "authors": [
      "Fernando Moreno-Pino",
      "Álvaro Arroyo",
      "Harrison Waldon",
      "Xiaowen Dong",
      "Álvaro Cartea"
    ],
    "abstract": "Time-series data in real-world medical settings typically exhibit long-range\ndependencies and are observed at non-uniform intervals. In such contexts,\ntraditional sequence-based recurrent models struggle. To overcome this,\nresearchers replace recurrent architectures with Neural ODE-based models to\nmodel irregularly sampled data and use Transformer-based architectures to\naccount for long-range dependencies. Despite the success of these two\napproaches, both incur very high computational costs for input sequences of\nmoderate lengths and greater. To mitigate this, we introduce the Rough\nTransformer, a variation of the Transformer model which operates on\ncontinuous-time representations of input sequences and incurs significantly\nreduced computational costs, critical for addressing long-range dependencies\ncommon in medical contexts. In particular, we propose multi-view signature\nattention, which uses path signatures to augment vanilla attention and to\ncapture both local and global dependencies in input data, while remaining\nrobust to changes in the sequence length and sampling frequency. We find that\nRough Transformers consistently outperform their vanilla attention counterparts\nwhile obtaining the benefits of Neural ODE-based models using a fraction of the\ncomputational time and memory resources on synthetic and real-world time-series\ntasks.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10288v1",
    "published_date": "2024-03-15 13:29:45 UTC",
    "updated_date": "2024-03-15 13:29:45 UTC"
  },
  {
    "arxiv_id": "2403.10581v2",
    "title": "Large Language Model-informed ECG Dual Attention Network for Heart Failure Risk Prediction",
    "authors": [
      "Chen Chen",
      "Lei Li",
      "Marcel Beetz",
      "Abhirup Banerjee",
      "Ramneek Gupta",
      "Vicente Grau"
    ],
    "abstract": "Heart failure (HF) poses a significant public health challenge, with a rising\nglobal mortality rate. Early detection and prevention of HF could significantly\nreduce its impact. We introduce a novel methodology for predicting HF risk\nusing 12-lead electrocardiograms (ECGs). We present a novel, lightweight\ndual-attention ECG network designed to capture complex ECG features essential\nfor early HF risk prediction, despite the notable imbalance between low and\nhigh-risk groups. This network incorporates a cross-lead attention module and\ntwelve lead-specific temporal attention modules, focusing on cross-lead\ninteractions and each lead's local dynamics. To further alleviate model\noverfitting, we leverage a large language model (LLM) with a public ECG-Report\ndataset for pretraining on an ECG-report alignment task. The network is then\nfine-tuned for HF risk prediction using two specific cohorts from the UK\nBiobank study, focusing on patients with hypertension (UKB-HYP) and those who\nhave had a myocardial infarction (UKB-MI).The results reveal that LLM-informed\npre-training substantially enhances HF risk prediction in these cohorts. The\ndual-attention design not only improves interpretability but also predictive\naccuracy, outperforming existing competitive methods with C-index scores of\n0.6349 for UKB-HYP and 0.5805 for UKB-MI. This demonstrates our method's\npotential in advancing HF risk assessment with clinical complex ECG data.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Under journal revision",
    "pdf_url": "http://arxiv.org/pdf/2403.10581v2",
    "published_date": "2024-03-15 13:25:09 UTC",
    "updated_date": "2024-03-22 16:00:24 UTC"
  },
  {
    "arxiv_id": "2403.10281v1",
    "title": "Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification with Fine-Tuning",
    "authors": [
      "Shang-Hsuan Chiang",
      "Ming-Chih Lo",
      "Lin-Wei Chao",
      "Wen-Chih Peng"
    ],
    "abstract": "In this paper, we present Pre-CoFactv3, a comprehensive framework comprised\nof Question Answering and Text Classification components for fact verification.\nLeveraging In-Context Learning, Fine-tuned Large Language Models (LLMs), and\nthe FakeNet model, we address the challenges of fact verification. Our\nexperiments explore diverse approaches, comparing different Pre-trained LLMs,\nintroducing FakeNet, and implementing various ensemble methods. Notably, our\nteam, Trifecta, secured first place in the AAAI-24 Factify 3.0 Workshop,\nsurpassing the baseline accuracy by 103% and maintaining a 70% lead over the\nsecond competitor. This success underscores the efficacy of our approach and\nits potential contributions to advancing fact verification research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AAAI 2024 Workshop: FACTIFY 3.0 - Workshop Series on\n  Multimodal Fact-Checking and Hate Speech Detection",
    "pdf_url": "http://arxiv.org/pdf/2403.10281v1",
    "published_date": "2024-03-15 13:24:28 UTC",
    "updated_date": "2024-03-15 13:24:28 UTC"
  },
  {
    "arxiv_id": "2403.10275v1",
    "title": "A Question on the Explainability of Large Language Models and the Word-Level Univariate First-Order Plausibility Assumption",
    "authors": [
      "Jeremie Bogaert",
      "Francois-Xavier Standaert"
    ],
    "abstract": "The explanations of large language models have recently been shown to be\nsensitive to the randomness used for their training, creating a need to\ncharacterize this sensitivity. In this paper, we propose a characterization\nthat questions the possibility to provide simple and informative explanations\nfor such models. To this end, we give statistical definitions for the\nexplanations' signal, noise and signal-to-noise ratio. We highlight that, in a\ntypical case study where word-level univariate explanations are analyzed with\nfirst-order statistical tools, the explanations of simple feature-based models\ncarry more signal and less noise than those of transformer ones. We then\ndiscuss the possibility to improve these results with alternative definitions\nof signal and noise that would capture more complex explanations and analysis\nmethods, while also questioning the tradeoff with their plausibility for\nreaders.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 10 figures, Accepted and presented at AAAI 2024 (ReLM\n  workshop)",
    "pdf_url": "http://arxiv.org/pdf/2403.10275v1",
    "published_date": "2024-03-15 13:15:23 UTC",
    "updated_date": "2024-03-15 13:15:23 UTC"
  },
  {
    "arxiv_id": "2404.00013v1",
    "title": "Missing Data Imputation With Granular Semantics and AI-driven Pipeline for Bankruptcy Prediction",
    "authors": [
      "Debarati Chakraborty",
      "Ravi Ranjan"
    ],
    "abstract": "This work focuses on designing a pipeline for the prediction of bankruptcy.\nThe presence of missing values, high dimensional data, and highly\nclass-imbalance databases are the major challenges in the said task. A new\nmethod for missing data imputation with granular semantics has been introduced\nhere. The merits of granular computing have been explored here to define this\nmethod. The missing values have been predicted using the feature semantics and\nreliable observations in a low-dimensional space, in the granular space. The\ngranules are formed around every missing entry, considering a few of the highly\ncorrelated features and most reliable closest observations to preserve the\nrelevance and reliability, the context, of the database against the missing\nentries. An intergranular prediction is then carried out for the imputation\nwithin those contextual granules. That is, the contextual granules enable a\nsmall relevant fraction of the huge database to be used for imputation and\novercome the need to access the entire database repetitively for each missing\nvalue. This method is then implemented and tested for the prediction of\nbankruptcy with the Polish Bankruptcy dataset. It provides an efficient\nsolution for big and high-dimensional datasets even with large imputation\nrates. Then an AI-driven pipeline for bankruptcy prediction has been designed\nusing the proposed granular semantic-based data filling method followed by the\nsolutions to the issues like high dimensional dataset and high class-imbalance\nin the dataset. The rest of the pipeline consists of feature selection with the\nrandom forest for reducing dimensionality, data balancing with SMOTE, and\nprediction with six different popular classifiers including deep NN. All\nmethods defined here have been experimentally verified with suitable\ncomparative studies and proven to be effective on all the data sets captured\nover the five years.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.00013v1",
    "published_date": "2024-03-15 13:01:09 UTC",
    "updated_date": "2024-03-15 13:01:09 UTC"
  },
  {
    "arxiv_id": "2403.10259v1",
    "title": "Comprehensive Study Of Predictive Maintenance In Industries Using Classification Models And LSTM Model",
    "authors": [
      "Saket Maheshwari",
      "Sambhav Tiwari",
      "Shyam Rai",
      "Satyam Vinayak Daman Pratap Singh"
    ],
    "abstract": "In today's technology-driven era, the imperative for predictive maintenance\nand advanced diagnostics extends beyond aviation to encompass the\nidentification of damages, failures, and operational defects in rotating and\nmoving machines. Implementing such services not only curtails maintenance costs\nbut also extends machine lifespan, ensuring heightened operational efficiency.\nMoreover, it serves as a preventive measure against potential accidents or\ncatastrophic events. The advent of Artificial Intelligence (AI) has\nrevolutionized maintenance across industries, enabling more accurate and\nefficient prediction and analysis of machine failures, thereby conserving time\nand resources. Our proposed study aims to delve into various machine learning\nclassification techniques, including Support Vector Machine (SVM), Random\nForest, Logistic Regression, and Convolutional Neural Network LSTM-Based, for\npredicting and analyzing machine performance. SVM classifies data into\ndifferent categories based on their positions in a multidimensional space,\nwhile Random Forest employs ensemble learning to create multiple decision trees\nfor classification. Logistic Regression predicts the probability of binary\noutcomes using input data. The primary objective of the study is to assess\nthese algorithms' performance in predicting and analyzing machine performance,\nconsidering factors such as accuracy, precision, recall, and F1 score. The\nfindings will aid maintenance experts in selecting the most suitable machine\nlearning algorithm for effective prediction and analysis of machine\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10259v1",
    "published_date": "2024-03-15 12:47:45 UTC",
    "updated_date": "2024-03-15 12:47:45 UTC"
  },
  {
    "arxiv_id": "2403.10249v1",
    "title": "A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges",
    "authors": [
      "Xinrun Xu",
      "Yuxin Wang",
      "Chaoyi Xu",
      "Ziluo Ding",
      "Jiechuan Jiang",
      "Zhiming Ding",
      "Börje F. Karlsson"
    ],
    "abstract": "The swift evolution of Large-scale Models (LMs), either language-focused or\nmulti-modal, has garnered extensive attention in both academy and industry. But\ndespite the surge in interest in this rapidly evolving area, there are scarce\nsystematic reviews on their capabilities and potential in distinct impactful\nscenarios. This paper endeavours to help bridge this gap, offering a thorough\nexamination of the current landscape of LM usage in regards to complex game\nplaying scenarios and the challenges still open. Here, we seek to\nsystematically review the existing architectures of LM-based Agents (LMAs) for\ngames and summarize their commonalities, challenges, and any other insights.\nFurthermore, we present our perspective on promising future research avenues\nfor the advancement of LMs in games. We hope to assist researchers in gaining a\nclear understanding of the field and to generate more interest in this highly\nimpactful research direction. A corresponding resource, continuously updated,\ncan be found in our GitHub repository.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.10249v1",
    "published_date": "2024-03-15 12:37:12 UTC",
    "updated_date": "2024-03-15 12:37:12 UTC"
  },
  {
    "arxiv_id": "2403.10231v2",
    "title": "Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs",
    "authors": [
      "Zhanke Zhou",
      "Yongqi Zhang",
      "Jiangchao Yao",
      "Quanming Yao",
      "Bo Han"
    ],
    "abstract": "To deduce new facts on a knowledge graph (KG), a link predictor learns from\nthe graph structure and collects local evidence to find the answer to a given\nquery. However, existing methods suffer from a severe scalability problem due\nto the utilization of the whole KG for prediction, which hinders their promise\non large scale KGs and cannot be directly addressed by vanilla sampling\nmethods. In this work, we propose the one-shot-subgraph link prediction to\nachieve efficient and adaptive prediction. The design principle is that,\ninstead of directly acting on the whole KG, the prediction procedure is\ndecoupled into two steps, i.e., (i) extracting only one subgraph according to\nthe query and (ii) predicting on this single, query dependent subgraph. We\nreveal that the non-parametric and computation-efficient heuristics\nPersonalized PageRank (PPR) can effectively identify the potential answers and\nsupporting evidence. With efficient subgraph-based prediction, we further\nintroduce the automated searching of the optimal configurations in both data\nand model spaces. Empirically, we achieve promoted efficiency and leading\nperformances on five large-scale benchmarks. The code is publicly available at:\nhttps://github.com/tmlr-group/one-shot-subgraph.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 43 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.10231v2",
    "published_date": "2024-03-15 12:00:12 UTC",
    "updated_date": "2025-02-09 20:52:59 UTC"
  },
  {
    "arxiv_id": "2403.10228v1",
    "title": "HawkEye: Training Video-Text LLMs for Grounding Text in Videos",
    "authors": [
      "Yueqian Wang",
      "Xiaojun Meng",
      "Jianxin Liang",
      "Yuxuan Wang",
      "Qun Liu",
      "Dongyan Zhao"
    ],
    "abstract": "Video-text Large Language Models (video-text LLMs) have shown remarkable\nperformance in answering questions and holding conversations on simple videos.\nHowever, they perform almost the same as random on grounding text queries in\nlong and complicated videos, having little ability to understand and reason\nabout temporal information, which is the most fundamental difference between\nvideos and images. In this paper, we propose HawkEye, one of the first\nvideo-text LLMs that can perform temporal video grounding in a fully\ntext-to-text manner. To collect training data that is applicable for temporal\nvideo grounding, we construct InternVid-G, a large-scale video-text corpus with\nsegment-level captions and negative spans, with which we introduce two new\ntime-aware training objectives to video-text LLMs. We also propose a\ncoarse-grained method of representing segments in videos, which is more robust\nand easier for LLMs to learn and follow than other alternatives. Extensive\nexperiments show that HawkEye is better at temporal video grounding and\ncomparable on other video-text tasks with existing video-text LLMs, which\nverifies its superior video-text multi-modal understanding abilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10228v1",
    "published_date": "2024-03-15 11:58:18 UTC",
    "updated_date": "2024-03-15 11:58:18 UTC"
  },
  {
    "arxiv_id": "2403.10220v1",
    "title": "From Chaos to Clarity: Time Series Anomaly Detection in Astronomical Observations",
    "authors": [
      "Xinli Hao",
      "Yile Chen",
      "Chen Yang",
      "Zhihui Du",
      "Chaohong Ma",
      "Chao Wu",
      "Xiaofeng Meng"
    ],
    "abstract": "With the development of astronomical facilities, large-scale time series data\nobserved by these facilities is being collected. Analyzing anomalies in these\nastronomical observations is crucial for uncovering potential celestial events\nand physical phenomena, thus advancing the scientific research process.\nHowever, existing time series anomaly detection methods fall short in tackling\nthe unique characteristics of astronomical observations where each star is\ninherently independent but interfered by random concurrent noise, resulting in\na high rate of false alarms. To overcome the challenges, we propose AERO, a\nnovel two-stage framework tailored for unsupervised anomaly detection in\nastronomical observations. In the first stage, we employ a Transformer-based\nencoder-decoder architecture to learn the normal temporal patterns on each\nvariate (i.e., star) in alignment with the characteristic of variate\nindependence. In the second stage, we enhance the graph neural network with a\nwindow-wise graph structure learning to tackle the occurrence of concurrent\nnoise characterized by spatial and temporal randomness. In this way, AERO is\nnot only capable of distinguishing normal temporal patterns from potential\nanomalies but also effectively differentiating concurrent noise, thus\ndecreasing the number of false alarms. We conducted extensive experiments on\nthree synthetic datasets and three real-world datasets. The results demonstrate\nthat AERO outperforms the compared baselines. Notably, compared to the\nstate-of-the-art model, AERO improves the F1-score by up to 8.76% and 2.63% on\nsynthetic and real-world datasets respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted by ICDE 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10220v1",
    "published_date": "2024-03-15 11:39:12 UTC",
    "updated_date": "2024-03-15 11:39:12 UTC"
  },
  {
    "arxiv_id": "2405.04537v1",
    "title": "An intuitive multi-frequency feature representation for SO(3)-equivariant networks",
    "authors": [
      "Dongwon Son",
      "Jaehyung Kim",
      "Sanghyeon Son",
      "Beomjoon Kim"
    ],
    "abstract": "The usage of 3D vision algorithms, such as shape reconstruction, remains\nlimited because they require inputs to be at a fixed canonical rotation.\nRecently, a simple equivariant network, Vector Neuron (VN) has been proposed\nthat can be easily used with the state-of-the-art 3D neural network (NN)\narchitectures. However, its performance is limited because it is designed to\nuse only three-dimensional features, which is insufficient to capture the\ndetails present in 3D data. In this paper, we introduce an equivariant feature\nrepresentation for mapping a 3D point to a high-dimensional feature space. Our\nfeature can discern multiple frequencies present in 3D data, which is the key\nto designing an expressive feature for 3D vision tasks. Our representation can\nbe used as an input to VNs, and the results demonstrate that with our feature\nrepresentation, VN captures more details, overcoming the limitation raised in\nits original paper.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04537v1",
    "published_date": "2024-03-15 11:36:50 UTC",
    "updated_date": "2024-03-15 11:36:50 UTC"
  },
  {
    "arxiv_id": "2403.10216v1",
    "title": "Exploring Optical Flow Inclusion into nnU-Net Framework for Surgical Instrument Segmentation",
    "authors": [
      "Marcos Fernández-Rodríguez",
      "Bruno Silva",
      "Sandro Queirós",
      "Helena R. Torres",
      "Bruno Oliveira",
      "Pedro Morais",
      "Lukas R. Buschle",
      "Jorge Correia-Pinto",
      "Estevão Lima",
      "João L. Vilaça"
    ],
    "abstract": "Surgical instrument segmentation in laparoscopy is essential for\ncomputer-assisted surgical systems. Despite the Deep Learning progress in\nrecent years, the dynamic setting of laparoscopic surgery still presents\nchallenges for precise segmentation. The nnU-Net framework excelled in semantic\nsegmentation analyzing single frames without temporal information. The\nframework's ease of use, including its ability to be automatically configured,\nand its low expertise requirements, have made it a popular base framework for\ncomparisons. Optical flow (OF) is a tool commonly used in video tasks to\nestimate motion and represent it in a single frame, containing temporal\ninformation. This work seeks to employ OF maps as an additional input to the\nnnU-Net architecture to improve its performance in the surgical instrument\nsegmentation task, taking advantage of the fact that instruments are the main\nmoving objects in the surgical field. With this new input, the temporal\ncomponent would be indirectly added without modifying the architecture. Using\nCholecSeg8k dataset, three different representations of movement were estimated\nand used as new inputs, comparing them with a baseline model. Results showed\nthat the use of OF maps improves the detection of classes with high movement,\neven when these are scarce in the dataset. To further improve performance,\nfuture work may focus on implementing other OF-preserving augmentations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10216v1",
    "published_date": "2024-03-15 11:36:26 UTC",
    "updated_date": "2024-03-15 11:36:26 UTC"
  },
  {
    "arxiv_id": "2403.10205v1",
    "title": "Read between the lines -- Functionality Extraction From READMEs",
    "authors": [
      "Prince Kumar",
      "Srikanth Tamilselvam",
      "Dinesh Garg"
    ],
    "abstract": "While text summarization is a well-known NLP task, in this paper, we\nintroduce a novel and useful variant of it called functionality extraction from\nGit README files. Though this task is a text2text generation at an abstract\nlevel, it involves its own peculiarities and challenges making existing\ntext2text generation systems not very useful. The motivation behind this task\nstems from a recent surge in research and development activities around the use\nof large language models for code-related tasks, such as code refactoring, code\nsummarization, etc. We also release a human-annotated dataset called FuncRead,\nand develop a battery of models for the task. Our exhaustive experimentation\nshows that small size fine-tuned models beat any baseline models that can be\ndesigned using popular black-box or white-box large language models (LLMs) such\nas ChatGPT and Bard. Our best fine-tuned 7 Billion CodeLlama model exhibit 70%\nand 20% gain on the F1 score against ChatGPT and Bard respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10205v1",
    "published_date": "2024-03-15 11:11:57 UTC",
    "updated_date": "2024-03-15 11:11:57 UTC"
  },
  {
    "arxiv_id": "2403.10202v1",
    "title": "Learning on JPEG-LDPC Compressed Images: Classifying with Syndromes",
    "authors": [
      "Ahcen Aliouat",
      "Elsa Dupraz"
    ],
    "abstract": "In goal-oriented communications, the objective of the receiver is often to\napply a Deep-Learning model, rather than reconstructing the original data. In\nthis context, direct learning over compressed data, without any prior decoding,\nholds promise for enhancing the time-efficient execution of inference models at\nthe receiver. However, conventional entropic-coding methods like Huffman and\nArithmetic break data structure, rendering them unsuitable for learning without\ndecoding. In this paper, we propose an alternative approach in which entropic\ncoding is realized with Low-Density Parity Check (LDPC) codes. We hypothesize\nthat Deep Learning models can more effectively exploit the internal code\nstructure of LDPC codes. At the receiver, we leverage a specific class of\nRecurrent Neural Networks (RNNs), specifically Gated Recurrent Unit (GRU),\ntrained for image classification. Our numerical results indicate that\nclassification based on LDPC-coded bit-planes surpasses Huffman and Arithmetic\ncoding, while necessitating a significantly smaller learning model. This\ndemonstrates the efficiency of classification directly from LDPC-coded data,\neliminating the need for any form of decompression, even partial, prior to\napplying the learning model.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "94A08, 94A29, 68P30",
      "I.4.2; I.4.9; E.4; C.2.0; I.2.10"
    ],
    "primary_category": "eess.IV",
    "comment": "5 pages, 3 figures, conference paper, submitted to the EUSIPCO 2024\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2403.10202v1",
    "published_date": "2024-03-15 11:07:38 UTC",
    "updated_date": "2024-03-15 11:07:38 UTC"
  },
  {
    "arxiv_id": "2403.10190v1",
    "title": "Perceptual Quality-based Model Training under Annotator Label Uncertainty",
    "authors": [
      "Chen Zhou",
      "Mohit Prabhushankar",
      "Ghassan AlRegib"
    ],
    "abstract": "Annotators exhibit disagreement during data labeling, which can be termed as\nannotator label uncertainty. Annotator label uncertainty manifests in\nvariations of labeling quality. Training with a single low-quality annotation\nper sample induces model reliability degradations. In this work, we first\nexamine the effects of annotator label uncertainty in terms of the model's\ngeneralizability and prediction uncertainty. We observe that the model's\ngeneralizability and prediction uncertainty degrade with the presence of\nlow-quality noisy labels. Meanwhile, our evaluation of existing uncertainty\nestimation algorithms indicates their incapability in response to annotator\nlabel uncertainty. To mitigate performance degradation, prior methods show that\ntraining models with labels collected from multiple independent annotators can\nenhance generalizability. However, they require massive annotations. Hence, we\nintroduce a novel perceptual quality-based model training framework to\nobjectively generate multiple labels for model training to enhance reliability,\nwhile avoiding massive annotations. Specifically, we first select a subset of\nsamples with low perceptual quality scores ranked by statistical regularities\nof visual signals. We then assign de-aggregated labels to each sample in this\nsubset to obtain a training set with multiple labels. Our experiments and\nanalysis demonstrate that training with the proposed framework alleviates the\ndegradation of generalizability and prediction uncertainty caused by annotator\nlabel uncertainty.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10190v1",
    "published_date": "2024-03-15 10:52:18 UTC",
    "updated_date": "2024-03-15 10:52:18 UTC"
  },
  {
    "arxiv_id": "2403.10187v1",
    "title": "Grasp Anything: Combining Teacher-Augmented Policy Gradient Learning with Instance Segmentation to Grasp Arbitrary Objects",
    "authors": [
      "Malte Mosbach",
      "Sven Behnke"
    ],
    "abstract": "Interactive grasping from clutter, akin to human dexterity, is one of the\nlongest-standing problems in robot learning. Challenges stem from the\nintricacies of visual perception, the demand for precise motor skills, and the\ncomplex interplay between the two. In this work, we present Teacher-Augmented\nPolicy Gradient (TAPG), a novel two-stage learning framework that synergizes\nreinforcement learning and policy distillation. After training a teacher policy\nto master the motor control based on object pose information, TAPG facilitates\nguided, yet adaptive, learning of a sensorimotor policy, based on object\nsegmentation. We zero-shot transfer from simulation to a real robot by using\nSegment Anything Model for promptable object segmentation. Our trained policies\nadeptly grasp a wide variety of objects from cluttered scenarios in simulation\nand the real world based on human-understandable prompts. Furthermore, we show\nrobust zero-shot transfer to novel objects. Videos of our experiments are\navailable at \\url{https://maltemosbach.github.io/grasp_anything}.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10187v1",
    "published_date": "2024-03-15 10:48:16 UTC",
    "updated_date": "2024-03-15 10:48:16 UTC"
  },
  {
    "arxiv_id": "2403.10184v1",
    "title": "Lifted Causal Inference in Relational Domains",
    "authors": [
      "Malte Luttermann",
      "Mattis Hartwig",
      "Tanya Braun",
      "Ralf Möller",
      "Marcel Gehrke"
    ],
    "abstract": "Lifted inference exploits symmetries in probabilistic graphical models by\nusing a representative for indistinguishable objects, thereby speeding up query\nanswering while maintaining exact answers. Even though lifting is a\nwell-established technique for the task of probabilistic inference in\nrelational domains, it has not yet been applied to the task of causal\ninference. In this paper, we show how lifting can be applied to efficiently\ncompute causal effects in relational domains. More specifically, we introduce\nparametric causal factor graphs as an extension of parametric factor graphs\nincorporating causal knowledge and give a formal semantics of interventions\ntherein. We further present the lifted causal inference algorithm to compute\ncausal effects on a lifted level, thereby drastically speeding up causal\ninference compared to propositional inference, e.g., in causal Bayesian\nnetworks. In our empirical evaluation, we demonstrate the effectiveness of our\napproach.",
    "categories": [
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the Proceedings of the 3rd Conference on Causal Learning\n  and Reasoning (CLeaR-24)",
    "pdf_url": "http://arxiv.org/pdf/2403.10184v1",
    "published_date": "2024-03-15 10:44:27 UTC",
    "updated_date": "2024-03-15 10:44:27 UTC"
  },
  {
    "arxiv_id": "2403.10175v2",
    "title": "A Short Survey on Importance Weighting for Machine Learning",
    "authors": [
      "Masanari Kimura",
      "Hideitsu Hino"
    ],
    "abstract": "Importance weighting is a fundamental procedure in statistics and machine\nlearning that weights the objective function or probability distribution based\non the importance of the instance in some sense. The simplicity and usefulness\nof the idea has led to many applications of importance weighting. For example,\nit is known that supervised learning under an assumption about the difference\nbetween the training and test distributions, called distribution shift, can\nguarantee statistically desirable properties through importance weighting by\ntheir density ratio. This survey summarizes the broad applications of\nimportance weighting in machine learning and related research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10175v2",
    "published_date": "2024-03-15 10:31:46 UTC",
    "updated_date": "2024-05-14 05:58:19 UTC"
  },
  {
    "arxiv_id": "2403.10173v3",
    "title": "Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention",
    "authors": [
      "Soikat Hasan Ahmed",
      "Jan Finkbeiner",
      "Emre Neftci"
    ],
    "abstract": "Event cameras offer high temporal resolution and dynamic range with minimal\nmotion blur, making them promising for robust object detection. While Spiking\nNeural Networks (SNNs) on neuromorphic hardware are often considered for\nenergy-efficient and low latency event-based data processing, they often fall\nshort of Artificial Neural Networks (ANNs) in accuracy and flexibility. Here,\nwe introduce Attention-based Hybrid SNN-ANN backbones for event-based object\ndetection to leverage the strengths of both SNN and ANN architectures. A novel\nAttention-based SNN-ANN bridge module captures sparse spatial and temporal\nrelations from the SNN layer and converts them into dense feature maps for the\nANN part of the backbone. Additionally, we present a variant that integrates\nDWConvL-STMs to the ANN blocks to capture slower dynamics. This multi-timescale\nnetwork combines fast SNN processing for short timesteps with long-term dense\nRNN processing, effectively capturing both fast and slow dynamics. Experimental\nresults demonstrate that our proposed method surpasses SNN-based approaches by\nsignificant margins, with results comparable to existing ANN and RNN-based\nmethods. Unlike ANN-only networks, the hybrid setup allows us to implement the\nSNN blocks on digital neuromorphic hardware to investigate the feasibility of\nour approach. Extensive ablation studies and implementation on neuromorphic\nhardware confirm the effectiveness of our proposed modules and architectural\nchoices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance\nat a drastically reduced parameter, latency, and power budget.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10173v3",
    "published_date": "2024-03-15 10:28:31 UTC",
    "updated_date": "2025-03-11 18:54:44 UTC"
  },
  {
    "arxiv_id": "2403.12096v1",
    "title": "Enriching User Shopping History: Empowering E-commerce with a Hierarchical Recommendation System",
    "authors": [
      "Irem Islek",
      "Sule Gunduz Oguducu"
    ],
    "abstract": "Recommendation systems can provide accurate recommendations by analyzing user\nshopping history. A richer user history results in more accurate\nrecommendations. However, in real applications, users prefer e-commerce\nplatforms where the item they seek is at the lowest price. In other words, most\nusers shop from multiple e-commerce platforms simultaneously; different parts\nof the user's shopping history are shared between different e-commerce\nplatforms. Consequently, we assume in this study that any e-commerce platform\nhas a complete record of the user's history but can only access some parts of\nit. If a recommendation system is able to predict the missing parts first and\nenrich the user's shopping history properly, it will be possible to recommend\nthe next item more accurately. Our recommendation system leverages user\nshopping history to improve prediction accuracy. The proposed approach shows\nsignificant improvements in both NDCG@10 and HR@10.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12096v1",
    "published_date": "2024-03-15 10:28:03 UTC",
    "updated_date": "2024-03-15 10:28:03 UTC"
  },
  {
    "arxiv_id": "2403.10171v2",
    "title": "AUTONODE: A Neuro-Graphic Self-Learnable Engine for Cognitive GUI Automation",
    "authors": [
      "Arkajit Datta",
      "Tushar Verma",
      "Rajat Chawla",
      "Mukunda N. S",
      "Ishaan Bhola"
    ],
    "abstract": "In recent advancements within the domain of Large Language Models (LLMs),\nthere has been a notable emergence of agents capable of addressing Robotic\nProcess Automation (RPA) challenges through enhanced cognitive capabilities and\nsophisticated reasoning. This development heralds a new era of scalability and\nhuman-like adaptability in goal attainment. In this context, we introduce\nAUTONODE (Autonomous User-interface Transformation through Online Neuro-graphic\nOperations and Deep Exploration). AUTONODE employs advanced neuro-graphical\ntechniques to facilitate autonomous navigation and task execution on web\ninterfaces, thereby obviating the necessity for predefined scripts or manual\nintervention. Our engine empowers agents to comprehend and implement complex\nworkflows, adapting to dynamic web environments with unparalleled efficiency.\nOur methodology synergizes cognitive functionalities with robotic automation,\nendowing AUTONODE with the ability to learn from experience. We have integrated\nan exploratory module, DoRA (Discovery and mapping Operation for graph\nRetrieval Agent), which is instrumental in constructing a knowledge graph that\nthe engine utilizes to optimize its actions and achieve objectives with minimal\nsupervision. The versatility and efficacy of AUTONODE are demonstrated through\na series of experiments, highlighting its proficiency in managing a diverse\narray of web-based tasks, ranging from data extraction to transaction\nprocessing.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in MIPR-2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10171v2",
    "published_date": "2024-03-15 10:27:17 UTC",
    "updated_date": "2024-05-27 05:03:09 UTC"
  },
  {
    "arxiv_id": "2403.10167v2",
    "title": "Efficient Detection of Exchangeable Factors in Factor Graphs",
    "authors": [
      "Malte Luttermann",
      "Johann Machemer",
      "Marcel Gehrke"
    ],
    "abstract": "To allow for tractable probabilistic inference with respect to domain sizes,\nlifted probabilistic inference exploits symmetries in probabilistic graphical\nmodels. However, checking whether two factors encode equivalent semantics and\nhence are exchangeable is computationally expensive. In this paper, we\nefficiently solve the problem of detecting exchangeable factors in a factor\ngraph. In particular, we introduce the detection of exchangeable factors (DEFT)\nalgorithm, which allows us to drastically reduce the computational effort for\nchecking whether two factors are exchangeable in practice. While previous\napproaches iterate all $O(n!)$ permutations of a factor's argument list in the\nworst case (where $n$ is the number of arguments of the factor), we prove that\nDEFT efficiently identifies restrictions to drastically reduce the number of\npermutations and validate the efficiency of DEFT in our empirical evaluation.",
    "categories": [
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of paper accepted to the Proceedings of the 37th\n  International FLAIRS Conference (FLAIRS-24)",
    "pdf_url": "http://arxiv.org/pdf/2403.10167v2",
    "published_date": "2024-03-15 10:20:56 UTC",
    "updated_date": "2024-04-05 16:02:40 UTC"
  },
  {
    "arxiv_id": "2403.10164v2",
    "title": "CoReEcho: Continuous Representation Learning for 2D+time Echocardiography Analysis",
    "authors": [
      "Fadillah Adamsyah Maani",
      "Numan Saeed",
      "Aleksandr Matsun",
      "Mohammad Yaqub"
    ],
    "abstract": "Deep learning (DL) models have been advancing automatic medical image\nanalysis on various modalities, including echocardiography, by offering a\ncomprehensive end-to-end training pipeline. This approach enables DL models to\nregress ejection fraction (EF) directly from 2D+time echocardiograms, resulting\nin superior performance. However, the end-to-end training pipeline makes the\nlearned representations less explainable. The representations may also fail to\ncapture the continuous relation among echocardiogram clips, indicating the\nexistence of spurious correlations, which can negatively affect the\ngeneralization. To mitigate this issue, we propose CoReEcho, a novel training\nframework emphasizing continuous representations tailored for direct EF\nregression. Our extensive experiments demonstrate that CoReEcho: 1) outperforms\nthe current state-of-the-art (SOTA) on the largest echocardiography dataset\n(EchoNet-Dynamic) with MAE of 3.90 & R2 of 82.44, and 2) provides robust and\ngeneralizable features that transfer more effectively in related downstream\ntasks. The code is publicly available at https://github.com/fadamsyah/CoReEcho.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10164v2",
    "published_date": "2024-03-15 10:18:06 UTC",
    "updated_date": "2024-09-16 12:42:47 UTC"
  },
  {
    "arxiv_id": "2405.04536v1",
    "title": "When Training-Free NAS Meets Vision Transformer: A Neural Tangent Kernel Perspective",
    "authors": [
      "Qiqi Zhou",
      "Yichen Zhu"
    ],
    "abstract": "This paper investigates the Neural Tangent Kernel (NTK) to search vision\ntransformers without training. In contrast with the previous observation that\nNTK-based metrics can effectively predict CNNs performance at initialization,\nwe empirically show their inefficacy in the ViT search space. We hypothesize\nthat the fundamental feature learning preference within ViT contributes to the\nineffectiveness of applying NTK to NAS for ViT. We both theoretically and\nempirically validate that NTK essentially estimates the ability of neural\nnetworks that learn low-frequency signals, completely ignoring the impact of\nhigh-frequency signals in feature learning. To address this limitation, we\npropose a new method called ViNTK that generalizes the standard NTK to the\nhigh-frequency domain by integrating the Fourier features from inputs.\nExperiments with multiple ViT search spaces on image classification and\nsemantic segmentation tasks show that our method can significantly speed up\nsearch costs over prior state-of-the-art NAS for ViT while maintaining similar\nperformance on searched architectures.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICASSP2024 oral",
    "pdf_url": "http://arxiv.org/pdf/2405.04536v1",
    "published_date": "2024-03-15 10:12:45 UTC",
    "updated_date": "2024-03-15 10:12:45 UTC"
  },
  {
    "arxiv_id": "2403.10158v2",
    "title": "Functional Graph Convolutional Networks: A unified multi-task and multi-modal learning framework to facilitate health and social-care insights",
    "authors": [
      "Tobia Boschi",
      "Francesca Bonin",
      "Rodrigo Ordonez-Hurtado",
      "Cécile Rousseau",
      "Alessandra Pascale",
      "John Dinsmore"
    ],
    "abstract": "This paper introduces a novel Functional Graph Convolutional Network (funGCN)\nframework that combines Functional Data Analysis and Graph Convolutional\nNetworks to address the complexities of multi-task and multi-modal learning in\ndigital health and longitudinal studies. With the growing importance of health\nsolutions to improve health care and social support, ensure healthy lives, and\npromote well-being at all ages, funGCN offers a unified approach to handle\nmultivariate longitudinal data for multiple entities and ensures\ninterpretability even with small sample sizes. Key innovations include\ntask-specific embedding components that manage different data types, the\nability to perform classification, regression, and forecasting, and the\ncreation of a knowledge graph for insightful data interpretation. The efficacy\nof funGCN is validated through simulation experiments and a real-data\napplication.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10158v2",
    "published_date": "2024-03-15 10:01:19 UTC",
    "updated_date": "2024-03-27 08:57:20 UTC"
  },
  {
    "arxiv_id": "2403.10144v3",
    "title": "NLP Verification: Towards a General Methodology for Certifying Robustness",
    "authors": [
      "Marco Casadio",
      "Tanvi Dinkar",
      "Ekaterina Komendantskaya",
      "Luca Arnaboldi",
      "Matthew L. Daggitt",
      "Omri Isac",
      "Guy Katz",
      "Verena Rieser",
      "Oliver Lemon"
    ],
    "abstract": "Machine Learning (ML) has exhibited substantial success in the field of\nNatural Language Processing (NLP). For example large language models have\nempirically proven to be capable of producing text of high complexity and\ncohesion. However, they are prone to inaccuracies and hallucinations. As these\nsystems are increasingly integrated into real-world applications, ensuring\ntheir safety and reliability becomes a primary concern. There are safety\ncritical contexts where such models must be robust to variability or attack,\nand give guarantees over their output. Computer Vision had pioneered the use of\nformal verification of neural networks for such scenarios and developed common\nverification standards and pipelines, leveraging precise formal reasoning about\ngeometric properties of data manifolds. In contrast, NLP verification methods\nhave only recently appeared in the literature. While presenting sophisticated\nalgorithms, these papers have not yet crystallised into a common methodology.\nThey are often light on the pragmatical issues of NLP verification and the area\nremains fragmented. In this paper, we attempt to distil and evaluate general\ncomponents of an NLP verification pipeline, that emerges from the progress in\nthe field to date. Our contributions are two-fold. Firstly, we propose a\ngeneral methodology to analyse the effect of the embedding gap, a problem that\nrefers to the discrepancy between verification of geometric subspaces and the\nsemantic meaning of sentences, which the geometric subspaces are supposed to\nrepresent. We propose a number of practical NLP methods that can help to\nquantify the effects of the embedding gap. Secondly, we give a general method\nfor training and verification of neural networks that leverages a more precise\ngeometric estimation of semantic similarity of sentences in the embedding space\nand helps to overcome the effects of the embedding gap in practice.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.PL"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10144v3",
    "published_date": "2024-03-15 09:43:52 UTC",
    "updated_date": "2025-01-24 15:43:41 UTC"
  },
  {
    "arxiv_id": "2403.10136v2",
    "title": "Response Style Characterization for Repeated Measures Using the Visual Analogue Scale",
    "authors": [
      "Shunsuke Minusa",
      "Tadayuki Matsumura",
      "Kanako Esaki",
      "Yang Shao",
      "Chihiro Yoshimura",
      "Hiroyuki Mizuno"
    ],
    "abstract": "Self-report measures (e.g., Likert scales) are widely used to evaluate\nsubjective health perceptions. Recently, the visual analog scale (VAS), a\nslider-based scale, has become popular owing to its ability to precisely and\neasily assess how people feel. These data can be influenced by the response\nstyle (RS), a user-dependent systematic tendency that occurs regardless of\nquestionnaire instructions. Despite its importance, especially in\nbetween-individual analysis, little attention has been paid to handling the RS\nin the VAS (denoted as response profile (RP)), as it is mainly used for\nwithin-individual monitoring and is less affected by RP. However, VAS\nmeasurements often require repeated self-reports of the same questionnaire\nitems, making it difficult to apply conventional methods on a Likert scale. In\nthis study, we developed a novel RP characterization method for various types\nof repeatedly measured VAS data. This approach involves the modeling of RP as\ndistributional parameters ${\\theta}$ through a mixture of RS-like\ndistributions, and addressing the issue of unbalanced data through bootstrap\nsampling for treating repeated measures. We assessed the effectiveness of the\nproposed method using simulated pseudo-data and an actual dataset from an\nempirical study. The assessment of parameter recovery showed that our method\naccurately estimated the RP parameter ${\\theta}$, demonstrating its robustness.\nMoreover, applying our method to an actual VAS dataset revealed the presence of\nindividual RP heterogeneity, even in repeated VAS measurements, similar to the\nfindings of the Likert scale. Our proposed method enables RP\nheterogeneity-aware VAS data analysis, similar to Likert-scale data analysis.",
    "categories": [
      "stat.ME",
      "cs.AI"
    ],
    "primary_category": "stat.ME",
    "comment": "Accepted to IEEE Access. Accessible at\n  https://ieeexplore.ieee.org/document/10638535",
    "pdf_url": "http://arxiv.org/pdf/2403.10136v2",
    "published_date": "2024-03-15 09:33:10 UTC",
    "updated_date": "2024-08-20 03:32:55 UTC"
  },
  {
    "arxiv_id": "2403.10135v1",
    "title": "The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation",
    "authors": [
      "Lei Wang",
      "Ee-Peng Lim"
    ],
    "abstract": "Large language models (LLMs) have shown excellent performance on various NLP\ntasks. To use LLMs as strong sequential recommenders, we explore the in-context\nlearning approach to sequential recommendation. We investigate the effects of\ninstruction format, task consistency, demonstration selection, and number of\ndemonstrations. As increasing the number of demonstrations in ICL does not\nimprove accuracy despite using a long prompt, we propose a novel method called\nLLMSRec-Syn that incorporates multiple demonstration users into one aggregated\ndemonstration. Our experiments on three recommendation datasets show that\nLLMSRec-Syn outperforms state-of-the-art LLM-based sequential recommendation\nmethods. In some cases, LLMSRec-Syn can perform on par with or even better than\nsupervised learning methods. Our code is publicly available at\nhttps://github.com/demoleiwang/LLMSRec_Syn.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "NAACL 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2403.10135v1",
    "published_date": "2024-03-15 09:28:19 UTC",
    "updated_date": "2024-03-15 09:28:19 UTC"
  },
  {
    "arxiv_id": "2403.10131v2",
    "title": "RAFT: Adapting Language Model to Domain Specific RAG",
    "authors": [
      "Tianjun Zhang",
      "Shishir G. Patil",
      "Naman Jain",
      "Sheng Shen",
      "Matei Zaharia",
      "Ion Stoica",
      "Joseph E. Gonzalez"
    ],
    "abstract": "Pretraining Large Language Models (LLMs) on large corpora of textual data is\nnow a standard paradigm. When using these LLMs for many downstream\napplications, it is common to additionally bake in new knowledge (e.g.,\ntime-critical news, or private domain knowledge) into the pretrained model\neither through RAG-based-prompting, or fine-tuning. However, the optimal\nmethodology for the model to gain such new knowledge remains an open question.\nIn this paper, we present Retrieval Augmented FineTuning (RAFT), a training\nrecipe that improves the model's ability to answer questions in a \"open-book\"\nin-domain settings. In RAFT, given a question, and a set of retrieved\ndocuments, we train the model to ignore those documents that don't help in\nanswering the question, which we call, distractor documents. RAFT accomplishes\nthis by citing verbatim the right sequence from the relevant document that\nwould help answer the question. This coupled with RAFT's chain-of-thought-style\nresponse helps improve the model's ability to reason. In domain-specific RAG,\nRAFT consistently improves the model's performance across PubMed, HotpotQA, and\nGorilla datasets, presenting a post-training recipe to improve pre-trained LLMs\nto in-domain RAG. RAFT's code and demo are open-sourced at\ngithub.com/ShishirPatil/gorilla.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10131v2",
    "published_date": "2024-03-15 09:26:02 UTC",
    "updated_date": "2024-06-05 17:27:51 UTC"
  },
  {
    "arxiv_id": "2403.15434v1",
    "title": "ChatPattern: Layout Pattern Customization via Natural Language",
    "authors": [
      "Zixiao Wang",
      "Yunheng Shen",
      "Xufeng Yao",
      "Wenqian Zhao",
      "Yang Bai",
      "Farzan Farnia",
      "Bei Yu"
    ],
    "abstract": "Existing works focus on fixed-size layout pattern generation, while the more\npractical free-size pattern generation receives limited attention. In this\npaper, we propose ChatPattern, a novel Large-Language-Model (LLM) powered\nframework for flexible pattern customization. ChatPattern utilizes a two-part\nsystem featuring an expert LLM agent and a highly controllable layout pattern\ngenerator. The LLM agent can interpret natural language requirements and\noperate design tools to meet specified needs, while the generator excels in\nconditional layout generation, pattern modification, and memory-friendly\npatterns extension. Experiments on challenging pattern generation setting shows\nthe ability of ChatPattern to synthesize high-quality large-scale patterns.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by DAC24",
    "pdf_url": "http://arxiv.org/pdf/2403.15434v1",
    "published_date": "2024-03-15 09:15:22 UTC",
    "updated_date": "2024-03-15 09:15:22 UTC"
  },
  {
    "arxiv_id": "2403.10112v1",
    "title": "Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution Approach",
    "authors": [
      "George Stamatelis",
      "Angelos-Nikolaos Kanatas",
      "Ioannis Asprogerakas",
      "George C. Alexandropoulos"
    ],
    "abstract": "In this paper, we focus on one centralized and one decentralized problem of\nactive hypothesis testing in the presence of an eavesdropper. For the\ncentralized problem including a single legitimate agent, we present a new\nframework based on NeuroEvolution (NE), whereas, for the decentralized problem,\nwe develop a novel NE-based method for solving collaborative multi-agent tasks,\nwhich interestingly maintains all computational benefits of single-agent NE.\nThe superiority of the proposed EAHT approaches over conventional active\nhypothesis testing policies, as well as learning-based methods, is validated\nthrough numerical investigations in an example use case of anomaly detection\nover wireless sensor networks.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.MA",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)",
    "pdf_url": "http://arxiv.org/pdf/2403.10112v1",
    "published_date": "2024-03-15 08:55:56 UTC",
    "updated_date": "2024-03-15 08:55:56 UTC"
  },
  {
    "arxiv_id": "2403.10110v1",
    "title": "Meta Operator for Complex Query Answering on Knowledge Graphs",
    "authors": [
      "Hang Yin",
      "Zihao Wang",
      "Yangqiu Song"
    ],
    "abstract": "Knowledge graphs contain informative factual knowledge but are considered\nincomplete. To answer complex queries under incomplete knowledge,\nlearning-based Complex Query Answering (CQA) models are proposed to directly\nlearn from the query-answer samples to avoid the direct traversal of incomplete\ngraph data. Existing works formulate the training of complex query answering\nmodels as multi-task learning and require a large number of training samples.\nIn this work, we explore the compositional structure of complex queries and\nargue that the different logical operator types, rather than the different\ncomplex query types, are the key to improving generalizability. Accordingly, we\npropose a meta-learning algorithm to learn the meta-operators with limited data\nand adapt them to different instances of operators under various complex\nqueries. Empirical results show that learning meta-operators is more effective\nthan learning original CQA or meta-CQA models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10110v1",
    "published_date": "2024-03-15 08:54:25 UTC",
    "updated_date": "2024-03-15 08:54:25 UTC"
  },
  {
    "arxiv_id": "2403.10107v2",
    "title": "Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning",
    "authors": [
      "Hang Zhang",
      "Wenxiao Zhang",
      "Haoxuan Qu",
      "Jun Liu"
    ],
    "abstract": "Human-centered dynamic scene understanding plays a pivotal role in enhancing\nthe capability of robotic and autonomous systems, in which Video-based\nHuman-Object Interaction (V-HOI) detection is a crucial task in semantic scene\nunderstanding, aimed at comprehensively understanding HOI relationships within\na video to benefit the behavioral decisions of mobile robots and autonomous\ndriving systems. Although previous V-HOI detection models have made significant\nstrides in accurate detection on specific datasets, they still lack the general\nreasoning ability like human beings to effectively induce HOI relationships. In\nthis study, we propose V-HOI Multi-LLMs Collaborated Reasoning (V-HOI MLCR), a\nnovel framework consisting of a series of plug-and-play modules that could\nfacilitate the performance of current V-HOI detection models by leveraging the\nstrong reasoning ability of different off-the-shelf pre-trained large language\nmodels (LLMs). We design a two-stage collaboration system of different LLMs for\nthe V-HOI task. Specifically, in the first stage, we design a Cross-Agents\nReasoning scheme to leverage the LLM conduct reasoning from different aspects.\nIn the second stage, we perform Multi-LLMs Debate to get the final reasoning\nanswer based on the different knowledge in different LLMs. Additionally, we\ndevise an auxiliary training strategy that utilizes CLIP, a large\nvision-language model to enhance the base V-HOI models' discriminative ability\nto better cooperate with LLMs. We validate the superiority of our design by\ndemonstrating its effectiveness in improving the prediction accuracy of the\nbase V-HOI model via reasoning from multiple perspectives.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10107v2",
    "published_date": "2024-03-15 08:51:15 UTC",
    "updated_date": "2024-07-19 09:38:18 UTC"
  },
  {
    "arxiv_id": "2403.10105v1",
    "title": "Belief Aided Navigation using Bayesian Reinforcement Learning for Avoiding Humans in Blind Spots",
    "authors": [
      "Jinyeob Kim",
      "Daewon Kwak",
      "Hyunwoo Rim",
      "Donghan Kim"
    ],
    "abstract": "Recent research on mobile robot navigation has focused on socially aware\nnavigation in crowded environments. However, existing methods do not adequately\naccount for human robot interactions and demand accurate location information\nfrom omnidirectional sensors, rendering them unsuitable for practical\napplications. In response to this need, this study introduces a novel\nalgorithm, BNBRL+, predicated on the partially observable Markov decision\nprocess framework to assess risks in unobservable areas and formulate movement\nstrategies under uncertainty. BNBRL+ consolidates belief algorithms with\nBayesian neural networks to probabilistically infer beliefs based on the\npositional data of humans. It further integrates the dynamics between the\nrobot, humans, and inferred beliefs to determine the navigation paths and\nembeds social norms within the reward function, thereby facilitating socially\naware navigation. Through experiments in various risk laden scenarios, this\nstudy validates the effectiveness of BNBRL+ in navigating crowded environments\nwith blind spots. The model's ability to navigate effectively in spaces with\nlimited visibility and avoid obstacles dynamically can significantly improve\nthe safety and reliability of autonomous vehicles.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.10105v1",
    "published_date": "2024-03-15 08:50:39 UTC",
    "updated_date": "2024-03-15 08:50:39 UTC"
  },
  {
    "arxiv_id": "2403.14693v1",
    "title": "A2CI: A Cloud-based, Service-oriented Geospatial Cyberinfrastructure to Support Atmospheric Research",
    "authors": [
      "Wenwen Li",
      "Hu Shao",
      "Sizhe Wang",
      "Xiran Zhou",
      "Sheng Wu"
    ],
    "abstract": "Big earth science data offers the scientific community great opportunities.\nMany more studies at large-scales, over long-terms and at high resolution can\nnow be conducted using the rich information collected by remote sensing\nsatellites, ground-based sensor networks, and even social media input. However,\nthe hundreds of terabytes of information collected and compiled on an hourly\nbasis by NASA and other government agencies present a significant challenge for\natmospheric scientists seeking to improve the understanding of the Earth\natmospheric system. These challenges include effective discovery, organization,\nanalysis and visualization of large amounts of data. This paper reports the\noutcomes of an NSF-funded project that developed a geospatial\ncyberinfrastructure -- the A2CI (Atmospheric Analysis Cyberinfrastructure) --\nto support atmospheric research. We first introduce the service-oriented system\nframework then describe in detail the implementation of the data discovery\nmodule, data management module, data integration module, data analysis and\nvisualization modules following the cloud computing\nprinciples-Data-as-a-Service, Software-as-a-Service, Platform-as-a-Service and\nInfrastructure-as-a-Service. We demonstrate the graphic user interface by\nperforming an analysis between Sea Surface Temperature and the intensity of\ntropical storms in the North Atlantic and Pacific oceans. We expect this work\nto contribute to the technical advancement of cyberinfrastructure research as\nwell as to the development of an online, collaborative scientific analysis\nsystem for atmospheric science.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.DC",
      "cs.IR",
      "big data, cyberinfrastructure, cloud computing"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14693v1",
    "published_date": "2024-03-15 08:28:38 UTC",
    "updated_date": "2024-03-15 08:28:38 UTC"
  },
  {
    "arxiv_id": "2403.10097v1",
    "title": "Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks",
    "authors": [
      "Shin'ya Yamaguchi",
      "Sekitoshi Kanai",
      "Kazuki Adachi",
      "Daiki Chijiwa"
    ],
    "abstract": "While fine-tuning is a de facto standard method for training deep neural\nnetworks, it still suffers from overfitting when using small target datasets.\nPrevious methods improve fine-tuning performance by maintaining knowledge of\nthe source datasets or introducing regularization terms such as contrastive\nloss. However, these methods require auxiliary source information (e.g., source\nlabels or datasets) or heavy additional computations. In this paper, we propose\na simple method called adaptive random feature regularization (AdaRand).\nAdaRand helps the feature extractors of training models to adaptively change\nthe distribution of feature vectors for downstream classification tasks without\nauxiliary source information and with reasonable computation costs. To this\nend, AdaRand minimizes the gap between feature vectors and random reference\nvectors that are sampled from class conditional Gaussian distributions.\nFurthermore, AdaRand dynamically updates the conditional distribution to follow\nthe currently updated feature extractors and balance the distance between\nclasses in feature spaces. Our experiments show that AdaRand outperforms the\nother fine-tuning regularization, which requires auxiliary source information\nand heavy computation costs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10097v1",
    "published_date": "2024-03-15 08:26:59 UTC",
    "updated_date": "2024-03-15 08:26:59 UTC"
  },
  {
    "arxiv_id": "2403.10088v1",
    "title": "Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF",
    "authors": [
      "Amey Hengle",
      "Aswini Kumar",
      "Sahajpreet Singh",
      "Anil Bandhakavi",
      "Md Shad Akhtar",
      "Tanmoy Chakroborty"
    ],
    "abstract": "Counterspeech, defined as a response to mitigate online hate speech, is\nincreasingly used as a non-censorial solution. Addressing hate speech\neffectively involves dispelling the stereotypes, prejudices, and biases often\nsubtly implied in brief, single-sentence statements or abuses. These implicit\nexpressions challenge language models, especially in seq2seq tasks, as model\nperformance typically excels with longer contexts. Our study introduces CoARL,\na novel framework enhancing counterspeech generation by modeling the pragmatic\nimplications underlying social biases in hateful statements. CoARL's first two\nphases involve sequential multi-instruction tuning, teaching the model to\nunderstand intents, reactions, and harms of offensive statements, and then\nlearning task-specific low-rank adapter weights for generating\nintent-conditioned counterspeech. The final phase uses reinforcement learning\nto fine-tune outputs for effectiveness and non-toxicity. CoARL outperforms\nexisting benchmarks in intent-conditioned counterspeech generation, showing an\naverage improvement of 3 points in intent-conformity and 4 points in\nargument-quality metrics. Extensive human evaluation supports CoARL's efficacy\nin generating superior and more context-appropriate responses compared to\nexisting systems, including prominent LLMs like ChatGPT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10088v1",
    "published_date": "2024-03-15 08:03:49 UTC",
    "updated_date": "2024-03-15 08:03:49 UTC"
  },
  {
    "arxiv_id": "2403.10086v2",
    "title": "Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties",
    "authors": [
      "Denis Schwachhofer",
      "Peter Domanski",
      "Steffen Becker",
      "Stefan Wagner",
      "Matthias Sauer",
      "Dirk Pflüger",
      "Ilia Polian"
    ],
    "abstract": "System-Level Test (SLT) has been a part of the test flow for integrated\ncircuits for over a decade and still gains importance. However, no systematic\napproaches exist for test program generation, especially targeting\nnon-functional properties of the Device under Test (DUT). Currently, test\nengineers manually compose test suites from off-the-shelf software,\napproximating the end-user environment of the DUT. This is a challenging and\ntedious task that does not guarantee sufficient control over non-functional\nproperties. This paper proposes Large Language Models (LLMs) to generate test\nprograms. We take a first glance at how pre-trained LLMs perform in test\nprogram generation to optimize non-functional properties of the DUT. Therefore,\nwe write a prompt to generate C code snippets that maximize the instructions\nper cycle of a super-scalar, out-of-order architecture in simulation.\nAdditionally, we apply prompt and hyperparameter optimization to achieve the\nbest possible results without further training.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.ET",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "Testmethoden und Zuverl\\\"assigkeit von Schaltungen und Systemen, TuZ\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2403.10086v2",
    "published_date": "2024-03-15 08:01:02 UTC",
    "updated_date": "2024-03-19 09:30:21 UTC"
  },
  {
    "arxiv_id": "2403.14692v3",
    "title": "The AI Assessment Scale (AIAS) in action: A pilot implementation of GenAI supported assessment- A Preprint",
    "authors": [
      "Leon Furze",
      "Mike Perkins",
      "Jasper Roe",
      "Jason MacVaugh"
    ],
    "abstract": "The rapid adoption of Generative Artificial Intelligence (GenAI) technologies\nin higher education has raised concerns about academic integrity, assessment\npractices, and student learning. Banning or blocking GenAI tools has proven\nineffective, and punitive approaches ignore the potential benefits of these\ntechnologies. This paper presents the findings of a pilot study conducted at\nBritish University Vietnam (BUV) exploring the implementation of the Artificial\nIntelligence Assessment Scale (AIAS), a flexible framework for incorporating\nGenAI into educational assessments. The AIAS consists of five levels, ranging\nfrom 'No AI' to 'Full AI', enabling educators to design assessments that focus\non areas requiring human input and critical thinking.\n  Following the implementation of the AIAS, the pilot study results indicate a\nsignificant reduction in academic misconduct cases related to GenAI, a 5.9%\nincrease in student attainment across the university, and a 33.3% increase in\nmodule passing rates. The AIAS facilitated a shift in pedagogical practices,\nwith faculty members incorporating GenAI tools into their modules and students\nproducing innovative multimodal submissions. The findings suggest that the AIAS\ncan support the effective integration of GenAI in HE, promoting academic\nintegrity while leveraging the technology's potential to enhance learning\nexperiences.\n  Refer to published version for final text.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14692v3",
    "published_date": "2024-03-15 08:00:02 UTC",
    "updated_date": "2025-02-25 10:47:46 UTC"
  },
  {
    "arxiv_id": "2403.10079v1",
    "title": "Learning Physical Dynamics for Object-centric Visual Prediction",
    "authors": [
      "Huilin Xu",
      "Tao Chen",
      "Feng Xu"
    ],
    "abstract": "The ability to model the underlying dynamics of visual scenes and reason\nabout the future is central to human intelligence. Many attempts have been made\nto empower intelligent systems with such physical understanding and prediction\nabilities. However, most existing methods focus on pixel-to-pixel prediction,\nwhich suffers from heavy computational costs while lacking a deep understanding\nof the physical dynamics behind videos. Recently, object-centric prediction\nmethods have emerged and attracted increasing interest. Inspired by it, this\npaper proposes an unsupervised object-centric prediction model that makes\nfuture predictions by learning visual dynamics between objects. Our model\nconsists of two modules, perceptual, and dynamic module. The perceptual module\nis utilized to decompose images into several objects and synthesize images with\na set of object-centric representations. The dynamic module fuses contextual\ninformation, takes environment-object and object-object interaction into\naccount, and predicts the future trajectory of objects. Extensive experiments\nare conducted to validate the effectiveness of the proposed method. Both\nquantitative and qualitative experimental results demonstrate that our model\ngenerates higher visual quality and more physically reliable predictions\ncompared to the state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.10079v1",
    "published_date": "2024-03-15 07:45:25 UTC",
    "updated_date": "2024-03-15 07:45:25 UTC"
  },
  {
    "arxiv_id": "2403.10069v1",
    "title": "Boundary Matters: A Bi-Level Active Finetuning Framework",
    "authors": [
      "Han Lu",
      "Yichen Xie",
      "Xiaokang Yang",
      "Junchi Yan"
    ],
    "abstract": "The pretraining-finetuning paradigm has gained widespread adoption in vision\ntasks and other fields, yet it faces the significant challenge of high sample\nannotation costs. To mitigate this, the concept of active finetuning has\nemerged, aiming to select the most appropriate samples for model finetuning\nwithin a limited budget. Traditional active learning methods often struggle in\nthis setting due to their inherent bias in batch selection. Furthermore, the\nrecent active finetuning approach has primarily concentrated on aligning the\ndistribution of selected subsets with the overall data pool, focusing solely on\ndiversity. In this paper, we propose a Bi-Level Active Finetuning framework to\nselect the samples for annotation in one shot, which includes two stages: core\nsample selection for diversity, and boundary sample selection for uncertainty.\nThe process begins with the identification of pseudo-class centers, followed by\nan innovative denoising method and an iterative strategy for boundary sample\nselection in the high-dimensional feature space, all without relying on\nground-truth labels. Our comprehensive experiments provide both qualitative and\nquantitative evidence of our method's efficacy, outperforming all the existing\nbaselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10069v1",
    "published_date": "2024-03-15 07:19:15 UTC",
    "updated_date": "2024-03-15 07:19:15 UTC"
  },
  {
    "arxiv_id": "2403.10063v2",
    "title": "Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization",
    "authors": [
      "Mohammad Pedramfar",
      "Yididiya Y. Nadew",
      "Christopher J. Quinn",
      "Vaneet Aggarwal"
    ],
    "abstract": "This paper introduces unified projection-free Frank-Wolfe type algorithms for\nadversarial continuous DR-submodular optimization, spanning scenarios such as\nfull information and (semi-)bandit feedback, monotone and non-monotone\nfunctions, different constraints, and types of stochastic queries. For every\nproblem considered in the non-monotone setting, the proposed algorithms are\neither the first with proven sub-linear $\\alpha$-regret bounds or have better\n$\\alpha$-regret bounds than the state of the art, where $\\alpha$ is a\ncorresponding approximation bound in the offline setting. In the monotone\nsetting, the proposed approach gives state-of-the-art sub-linear\n$\\alpha$-regret bounds among projection-free algorithms in 7 of the 8\nconsidered cases while matching the result of the remaining case. Additionally,\nthis paper addresses semi-bandit and bandit feedback for adversarial\nDR-submodular optimization, advancing the understanding of this optimization\narea.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper is published in ICLR 2024. This version includes a\n  correction for regret bounds in the full-information zeroth order feedback\n  setting (see the footnote on page 1 for details)",
    "pdf_url": "http://arxiv.org/pdf/2403.10063v2",
    "published_date": "2024-03-15 07:05:44 UTC",
    "updated_date": "2024-04-26 21:05:00 UTC"
  },
  {
    "arxiv_id": "2403.12094v2",
    "title": "Are LLMs Good Cryptic Crossword Solvers?",
    "authors": [
      "Abdelrahman Sadallah",
      "Daria Kotova",
      "Ekaterina Kochmar"
    ],
    "abstract": "Cryptic crosswords are puzzles that rely not only on general knowledge but\nalso on the solver's ability to manipulate language on different levels and\ndeal with various types of wordplay. Previous research suggests that solving\nsuch puzzles is a challenge even for modern NLP models. However, the abilities\nof large language models (LLMs) have not yet been tested on this task. In this\npaper, we establish the benchmark results for three popular LLMs -- LLaMA2,\nMistral, and ChatGPT -- showing that their performance on this task is still\nfar from that of humans.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12094v2",
    "published_date": "2024-03-15 06:57:08 UTC",
    "updated_date": "2025-01-13 11:46:59 UTC"
  },
  {
    "arxiv_id": "2403.10056v1",
    "title": "Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning",
    "authors": [
      "Yongquan He",
      "Xuancheng Huang",
      "Minghao Tang",
      "Lingxun Meng",
      "Xiang Li",
      "Wei Lin",
      "Wenyuan Zhang",
      "Yifu Gao"
    ],
    "abstract": "Instruction tuning for large language models (LLMs) can drive them to produce\nresults consistent with human goals in specific downstream tasks. However, the\nprocess of continual instruction tuning (CIT) for LLMs may bring about the\ncatastrophic forgetting (CF) problem, where previously learned abilities are\ndegraded. Recent methods try to alleviate the CF problem by modifying models or\nreplaying data, which may only remember the surface-level pattern of\ninstructions and get confused on held-out tasks. In this paper, we propose a\nnovel continual instruction tuning method based on Key-part Information Gain\n(KPIG). Our method computes the information gain on masked parts to dynamically\nreplay data and refine the training objective, which enables LLMs to capture\ntask-aware information relevant to the correct response and alleviate\noverfitting to general descriptions in instructions. In addition, we propose\ntwo metrics, P-score and V-score, to measure the generalization and\ninstruction-following abilities of LLMs. Experiments demonstrate our method\nachieves superior performance on both seen and held-out tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.10056v1",
    "published_date": "2024-03-15 06:54:20 UTC",
    "updated_date": "2024-03-15 06:54:20 UTC"
  },
  {
    "arxiv_id": "2403.10049v1",
    "title": "PPM : A Pre-trained Plug-in Model for Click-through Rate Prediction",
    "authors": [
      "Yuanbo Gao",
      "Peng Lin",
      "Dongyue Wang",
      "Feng Mei",
      "Xiwei Zhao",
      "Sulong Xu",
      "Jinghe Hu"
    ],
    "abstract": "Click-through rate (CTR) prediction is a core task in recommender systems.\nExisting methods (IDRec for short) rely on unique identities to represent\ndistinct users and items that have prevailed for decades. On one hand, IDRec\noften faces significant performance degradation on cold-start problem; on the\nother hand, IDRec cannot use longer training data due to constraints imposed by\niteration efficiency. Most prior studies alleviate the above problems by\nintroducing pre-trained knowledge(e.g. pre-trained user model or multi-modal\nembeddings). However, the explosive growth of online latency can be attributed\nto the huge parameters in the pre-trained model. Therefore, most of them cannot\nemploy the unified model of end-to-end training with IDRec in industrial\nrecommender systems, thus limiting the potential of the pre-trained model. To\nthis end, we propose a $\\textbf{P}$re-trained $\\textbf{P}$lug-in CTR\n$\\textbf{M}$odel, namely PPM. PPM employs multi-modal features as input and\nutilizes large-scale data for pre-training. Then, PPM is plugged in IDRec model\nto enhance unified model's performance and iteration efficiency. Upon\nincorporating IDRec model, certain intermediate results within the network are\ncached, with only a subset of the parameters participating in training and\nserving. Hence, our approach can successfully deploy an end-to-end model\nwithout causing huge latency increases. Comprehensive offline experiments and\nonline A/B testing at JD E-commerce demonstrate the efficiency and\neffectiveness of PPM.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by ACM Web Conference 2024 (WWW'24)",
    "pdf_url": "http://arxiv.org/pdf/2403.10049v1",
    "published_date": "2024-03-15 06:42:23 UTC",
    "updated_date": "2024-03-15 06:42:23 UTC"
  },
  {
    "arxiv_id": "2403.10041v2",
    "title": "Towards Embedding Dynamic Personas in Interactive Robots: Masquerading Animated Social Kinematics (MASK)",
    "authors": [
      "Jeongeun Park",
      "Taemoon Jeong",
      "Hyeonseong Kim",
      "Taehyun Byun",
      "Seungyoon Shin",
      "Keunjun Choi",
      "Jaewoon Kwon",
      "Taeyoon Lee",
      "Matthew Pan",
      "Sungjoon Choi"
    ],
    "abstract": "This paper presents the design and development of an innovative interactive\nrobotic system to enhance audience engagement using character-like personas.\nBuilt upon the foundations of persona-driven dialog agents, this work extends\nthe agent's application to the physical realm, employing robots to provide a\nmore captivating and interactive experience. The proposed system, named the\nMasquerading Animated Social Kinematic (MASK), leverages an anthropomorphic\nrobot which interacts with guests using non-verbal interactions, including\nfacial expressions and gestures. A behavior generation system based upon a\nfinite-state machine structure effectively conditions robotic behavior to\nconvey distinct personas. The MASK framework integrates a perception engine, a\nbehavior selection engine, and a comprehensive action library to enable\nreal-time, dynamic interactions with minimal human intervention in behavior\ndesign. Throughout the user subject studies, we examined whether the users\ncould recognize the intended character in both personality- and\nfilm-character-based persona conditions. We conclude by discussing the role of\npersonas in interactive agents and the factors to consider for creating an\nengaging user experience.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at Robotics and Automation Letters",
    "pdf_url": "http://arxiv.org/pdf/2403.10041v2",
    "published_date": "2024-03-15 06:22:32 UTC",
    "updated_date": "2024-10-07 14:33:28 UTC"
  },
  {
    "arxiv_id": "2403.10039v2",
    "title": "Motion-Boundary-Driven Unsupervised Surgical Instrument Segmentation in Low-Quality Optical Flow",
    "authors": [
      "Yang Liu",
      "Peiran Wu",
      "Jiayu Huo",
      "Gongyu Zhang",
      "Zhen Yuan",
      "Christos Bergeles",
      "Rachel Sparks",
      "Prokar Dasgupta",
      "Alejandro Granados",
      "Sebastien Ourselin"
    ],
    "abstract": "Unsupervised video-based surgical instrument segmentation has the potential\nto accelerate the adoption of robot-assisted procedures by reducing the\nreliance on manual annotations. However, the generally low quality of optical\nflow in endoscopic footage poses a great challenge for unsupervised methods\nthat rely heavily on motion cues. To overcome this limitation, we propose a\nnovel approach that pinpoints motion boundaries, regions with abrupt flow\nchanges, while selectively discarding frames with globally low-quality flow and\nadapting to varying motion patterns. Experiments on the EndoVis2017 VOS and\nEndoVis2017 Challenge datasets show that our method achieves mean\nIntersection-over-Union (mIoU) scores of 0.75 and 0.72, respectively,\neffectively alleviating the constraints imposed by suboptimal optical flow.\nThis enables a more scalable and robust surgical instrument segmentation\nsolution in clinical settings. The code will be publicly released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10039v2",
    "published_date": "2024-03-15 06:19:02 UTC",
    "updated_date": "2025-03-25 20:18:43 UTC"
  },
  {
    "arxiv_id": "2403.10024v1",
    "title": "MR-MT3: Memory Retaining Multi-Track Music Transcription to Mitigate Instrument Leakage",
    "authors": [
      "Hao Hao Tan",
      "Kin Wai Cheuk",
      "Taemin Cho",
      "Wei-Hsiang Liao",
      "Yuki Mitsufuji"
    ],
    "abstract": "This paper presents enhancements to the MT3 model, a state-of-the-art (SOTA)\ntoken-based multi-instrument automatic music transcription (AMT) model. Despite\nSOTA performance, MT3 has the issue of instrument leakage, where transcriptions\nare fragmented across different instruments. To mitigate this, we propose\nMR-MT3, with enhancements including a memory retention mechanism, prior token\nsampling, and token shuffling are proposed. These methods are evaluated on the\nSlakh2100 dataset, demonstrating improved onset F1 scores and reduced\ninstrument leakage. In addition to the conventional multi-instrument\ntranscription F1 score, new metrics such as the instrument leakage ratio and\nthe instrument detection F1 score are introduced for a more comprehensive\nassessment of transcription quality. The study also explores the issue of\ndomain overfitting by evaluating MT3 on single-instrument monophonic datasets\nsuch as ComMU and NSynth. The findings, along with the source code, are shared\nto facilitate future work aimed at refining token-based multi-instrument AMT\nmodels.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10024v1",
    "published_date": "2024-03-15 05:13:38 UTC",
    "updated_date": "2024-03-15 05:13:38 UTC"
  },
  {
    "arxiv_id": "2403.10575v1",
    "title": "Exploring Language Model's Code Generation Ability with Auxiliary Functions",
    "authors": [
      "Seonghyeon Lee",
      "Sanghwan Jang",
      "Seongbo Jang",
      "Dongha Lee",
      "Hwanjo Yu"
    ],
    "abstract": "Auxiliary function is a helpful component to improve language model's code\ngeneration ability. However, a systematic exploration of how they affect has\nyet to be done. In this work, we comprehensively evaluate the ability to\nutilize auxiliary functions encoded in recent code-pretrained language models.\nFirst, we construct a human-crafted evaluation set, called HumanExtension,\nwhich contains examples of two functions where one function assists the other.\nWith HumanExtension, we design several experiments to examine their ability in\na multifaceted way. Our evaluation processes enable a comprehensive\nunderstanding of including auxiliary functions in the prompt in terms of\neffectiveness and robustness. An additional implementation style analysis\ncaptures the models' various implementation patterns when they access the\nauxiliary function. Through this analysis, we discover the models' promising\nability to utilize auxiliary functions including their self-improving behavior\nby implementing the two functions step-by-step. However, our analysis also\nreveals the model's underutilized behavior to call the auxiliary function,\nsuggesting the future direction to enhance their implementation by eliciting\nthe auxiliary function call ability encoded in the models. We release our code\nand dataset to facilitate this research direction.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "NAACL2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2403.10575v1",
    "published_date": "2024-03-15 04:41:50 UTC",
    "updated_date": "2024-03-15 04:41:50 UTC"
  },
  {
    "arxiv_id": "2403.10014v1",
    "title": "NNCTC: Physical Layer Cross-Technology Communication via Neural Networks",
    "authors": [
      "Haoyu Wang",
      "Jiazhao Wang",
      "Demin Gao",
      "Wenchao Jiang"
    ],
    "abstract": "Cross-technology communication(CTC) enables seamless interactions between\ndiverse wireless technologies. Most existing work is based on reversing the\ntransmission path to identify the appropriate payload to generate the waveform\nthat the target devices can recognize. However, this method suffers from many\nlimitations, including dependency on specific technologies and the necessity\nfor intricate algorithms to mitigate distortion. In this work, we present\nNNCTC, a Neural-Network-based Cross-Technology Communication framework inspired\nby the adaptability of trainable neural models in wireless communications. By\nconverting signal processing components within the CTC pipeline into neural\nmodels, the NNCTC is designed for end-to-end training without requiring labeled\ndata. This enables the NNCTC system to autonomously derive the optimal CTC\npayload, which significantly eases the development complexity and showcases the\nscalability potential for various CTC links. Particularly, we construct a CTC\nsystem from Wi-Fi to ZigBee. The NNCTC system outperforms the well-recognized\nWEBee and WIDE design in error performance, achieving an average packet\nreception rate(PRR) of 92.3% and an average symbol error rate(SER) as low as\n1.3%.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "C.2.2"
    ],
    "primary_category": "cs.NI",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.10014v1",
    "published_date": "2024-03-15 04:36:44 UTC",
    "updated_date": "2024-03-15 04:36:44 UTC"
  },
  {
    "arxiv_id": "2403.14691v2",
    "title": "Large Language Models and User Trust: Consequence of Self-Referential Learning Loop and the Deskilling of Healthcare Professionals",
    "authors": [
      "Avishek Choudhury",
      "Zaria Chaudhry"
    ],
    "abstract": "This paper explores the evolving relationship between clinician trust in\nLLMs, the transformation of data sources from predominantly human-generated to\nAI-generated content, and the subsequent impact on the precision of LLMs and\nclinician competence. One of the primary concerns identified is the potential\nfeedback loop that arises as LLMs become more reliant on their outputs for\nlearning, which may lead to a degradation in output quality and a reduction in\nclinician skills due to decreased engagement with fundamental diagnostic\nprocesses. While theoretical at this stage, this feedback loop poses a\nsignificant challenge as the integration of LLMs in healthcare deepens,\nemphasizing the need for proactive dialogue and strategic measures to ensure\nthe safe and effective use of LLM technology. A key takeaway from our\ninvestigation is the critical role of user expertise and the necessity for a\ndiscerning approach to trusting and validating LLM outputs. The paper\nhighlights how expert users, particularly clinicians, can leverage LLMs to\nenhance productivity by offloading routine tasks while maintaining a critical\noversight to identify and correct potential inaccuracies in AI-generated\ncontent. This balance of trust and skepticism is vital for ensuring that LLMs\naugment rather than undermine the quality of patient care. Moreover, we delve\ninto the potential risks associated with LLMs' self-referential learning loops\nand the deskilling of healthcare professionals. The risk of LLMs operating\nwithin an echo chamber, where AI-generated content feeds into the learning\nalgorithms, threatens the diversity and quality of the data pool, potentially\nentrenching biases and reducing the efficacy of LLMs.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "1 figure",
    "pdf_url": "http://arxiv.org/pdf/2403.14691v2",
    "published_date": "2024-03-15 04:04:45 UTC",
    "updated_date": "2024-04-01 05:03:45 UTC"
  },
  {
    "arxiv_id": "2403.13840v1",
    "title": "Whose Side Are You On? Investigating the Political Stance of Large Language Models",
    "authors": [
      "Pagnarasmey Pit",
      "Xingjun Ma",
      "Mike Conway",
      "Qingyu Chen",
      "James Bailey",
      "Henry Pit",
      "Putrasmey Keo",
      "Watey Diep",
      "Yu-Gang Jiang"
    ],
    "abstract": "Large Language Models (LLMs) have gained significant popularity for their\napplication in various everyday tasks such as text generation, summarization,\nand information retrieval. As the widespread adoption of LLMs continues to\nsurge, it becomes increasingly crucial to ensure that these models yield\nresponses that are politically impartial, with the aim of preventing\ninformation bubbles, upholding fairness in representation, and mitigating\nconfirmation bias. In this paper, we propose a quantitative framework and\npipeline designed to systematically investigate the political orientation of\nLLMs. Our investigation delves into the political alignment of LLMs across a\nspectrum of eight polarizing topics, spanning from abortion to LGBTQ issues.\nAcross topics, the results indicate that LLMs exhibit a tendency to provide\nresponses that closely align with liberal or left-leaning perspectives rather\nthan conservative or right-leaning ones when user queries include details\npertaining to occupation, race, or political affiliation. The findings\npresented in this study not only reaffirm earlier observations regarding the\nleft-leaning characteristics of LLMs but also surface particular attributes,\nsuch as occupation, that are particularly susceptible to such inclinations even\nwhen directly steered towards conservatism. As a recommendation to avoid these\nmodels providing politicised responses, users should be mindful when crafting\nqueries, and exercise caution in selecting neutral prompt language.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.13840v1",
    "published_date": "2024-03-15 04:02:24 UTC",
    "updated_date": "2024-03-15 04:02:24 UTC"
  },
  {
    "arxiv_id": "2403.09998v2",
    "title": "FBPT: A Fully Binary Point Transformer",
    "authors": [
      "Zhixing Hou",
      "Yuzhang Shang",
      "Yan Yan"
    ],
    "abstract": "This paper presents a novel Fully Binary Point Cloud Transformer (FBPT) model\nwhich has the potential to be widely applied and expanded in the fields of\nrobotics and mobile devices. By compressing the weights and activations of a\n32-bit full-precision network to 1-bit binary values, the proposed binary point\ncloud Transformer network significantly reduces the storage footprint and\ncomputational resource requirements of neural network models for point cloud\nprocessing tasks, compared to full-precision point cloud networks. However,\nachieving a fully binary point cloud Transformer network, where all parts\nexcept the modules specific to the task are binary, poses challenges and\nbottlenecks in quantizing the activations of Q, K, V and self-attention in the\nattention module, as they do not adhere to simple probability distributions and\ncan vary with input data. Furthermore, in our network, the binary attention\nmodule undergoes a degradation of the self-attention module due to the uniform\ndistribution that occurs after the softmax operation. The primary focus of this\npaper is on addressing the performance degradation issue caused by the use of\nbinary point cloud Transformer modules. We propose a novel binarization\nmechanism called dynamic-static hybridization. Specifically, our approach\ncombines static binarization of the overall network model with fine granularity\ndynamic binarization of data-sensitive components. Furthermore, we make use of\na novel hierarchical training scheme to obtain the optimal model and\nbinarization parameters. These above improvements allow the proposed\nbinarization method to outperform binarization methods applied to convolution\nneural networks when used in point cloud Transformer structures. To demonstrate\nthe superiority of our algorithm, we conducted experiments on two different\ntasks: point cloud classification and place recognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICRA 2024. arXiv admin note: substantial text overlap\n  with arXiv:2303.01166",
    "pdf_url": "http://arxiv.org/pdf/2403.09998v2",
    "published_date": "2024-03-15 03:45:10 UTC",
    "updated_date": "2024-05-09 06:35:38 UTC"
  },
  {
    "arxiv_id": "2403.09977v1",
    "title": "EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba",
    "authors": [
      "Xiaohuan Pei",
      "Tao Huang",
      "Chang Xu"
    ],
    "abstract": "Prior efforts in light-weight model development mainly centered on CNN and\nTransformer-based designs yet faced persistent challenges. CNNs adept at local\nfeature extraction compromise resolution while Transformers offer global reach\nbut escalate computational demands $\\mathcal{O}(N^2)$. This ongoing trade-off\nbetween accuracy and efficiency remains a significant hurdle. Recently, state\nspace models (SSMs), such as Mamba, have shown outstanding performance and\ncompetitiveness in various tasks such as language modeling and computer vision,\nwhile reducing the time complexity of global information extraction to\n$\\mathcal{O}(N)$. Inspired by this, this work proposes to explore the potential\nof visual state space models in light-weight model design and introduce a novel\nefficient model variant dubbed EfficientVMamba. Concretely, our EfficientVMamba\nintegrates a atrous-based selective scan approach by efficient skip sampling,\nconstituting building blocks designed to harness both global and local\nrepresentational features. Additionally, we investigate the integration between\nSSM blocks and convolutions, and introduce an efficient visual state space\nblock combined with an additional convolution branch, which further elevate the\nmodel performance. Experimental results show that, EfficientVMamba scales down\nthe computational complexity while yields competitive results across a variety\nof vision tasks. For example, our EfficientVMamba-S with $1.3$G FLOPs improves\nVim-Ti with $1.5$G FLOPs by a large margin of $5.6\\%$ accuracy on ImageNet.\nCode is available at: \\url{https://github.com/TerryPei/EfficientVMamba}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09977v1",
    "published_date": "2024-03-15 02:48:47 UTC",
    "updated_date": "2024-03-15 02:48:47 UTC"
  },
  {
    "arxiv_id": "2403.09974v3",
    "title": "GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery",
    "authors": [
      "Enguang Wang",
      "Zhimao Peng",
      "Zhengyuan Xie",
      "Fei Yang",
      "Xialei Liu",
      "Ming-Ming Cheng"
    ],
    "abstract": "Given unlabelled datasets containing both old and new categories, generalized\ncategory discovery (GCD) aims to accurately discover new classes while\ncorrectly classifying old classes. Current GCD methods only use a single visual\nmodality of information, resulting in a poor classification of visually similar\nclasses. As a different modality, text information can provide complementary\ndiscriminative information, which motivates us to introduce it into the GCD\ntask. However, the lack of class names for unlabelled data makes it impractical\nto utilize text information. To tackle this challenging problem, in this paper,\nwe propose a Text Embedding Synthesizer (TES) to generate pseudo text\nembeddings for unlabelled samples. Specifically, our TES leverages the property\nthat CLIP can generate aligned vision-language features, converting visual\nembeddings into tokens of the CLIP's text encoder to generate pseudo text\nembeddings. Besides, we employ a dual-branch framework, through the joint\nlearning and instance consistency of different modality branches, visual and\nsemantic information mutually enhance each other, promoting the interaction and\nfusion of visual and text knowledge. Our method unlocks the multi-modal\npotentials of CLIP and outperforms the baseline methods by a large margin on\nall GCD benchmarks, achieving new state-of-the-art. Our code is available at:\nhttps://github.com/enguangW/GET.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.09974v3",
    "published_date": "2024-03-15 02:40:13 UTC",
    "updated_date": "2025-03-21 01:50:55 UTC"
  },
  {
    "arxiv_id": "2405.15772v1",
    "title": "Scenario Engineering for Autonomous Transportation: A New Stage in Open-Pit Mines",
    "authors": [
      "Siyu Teng",
      "Xuan Li",
      "Yucheng Li",
      "Zhe Xuanyuan",
      "Yunfeng Ai",
      "Long Chen"
    ],
    "abstract": "In recent years, open-pit mining has seen significant advancement, the\ncooperative operation of various specialized machinery substantially enhancing\nthe efficiency of mineral extraction. However, the harsh environment and\ncomplex conditions in open-pit mines present substantial challenges for the\nimplementation of autonomous transportation systems. This research introduces a\nnovel paradigm that integrates Scenario Engineering (SE) with autonomous\ntransportation systems to significantly improve the trustworthiness,\nrobustness, and efficiency in open-pit mines by incorporating the four key\ncomponents of SE, including Scenario Feature Extractor, Intelligence and Index\n(I&I), Calibration and Certification (C&C), and Verification and Validation\n(V&V). This paradigm has been validated in two famous open-pit mines, the\nexperiment results demonstrate marked improvements in robustness,\ntrustworthiness, and efficiency. By enhancing the capacity, scalability, and\ndiversity of autonomous transportation, this paradigm fosters the integration\nof SE and parallel driving and finally propels the achievement of the '6S'\nobjectives.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "11 Pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15772v1",
    "published_date": "2024-03-15 02:36:27 UTC",
    "updated_date": "2024-03-15 02:36:27 UTC"
  },
  {
    "arxiv_id": "2403.15433v1",
    "title": "HyPer-EP: Meta-Learning Hybrid Personalized Models for Cardiac Electrophysiology",
    "authors": [
      "Xiajun Jiang",
      "Sumeet Vadhavkar",
      "Yubo Ye",
      "Maryam Toloubidokhti",
      "Ryan Missel",
      "Linwei Wang"
    ],
    "abstract": "Personalized virtual heart models have demonstrated increasing potential for\nclinical use, although the estimation of their parameters given\npatient-specific data remain a challenge. Traditional physics-based modeling\napproaches are computationally costly and often neglect the inherent structural\nerrors in these models due to model simplifications and assumptions. Modern\ndeep learning approaches, on the other hand, rely heavily on data supervision\nand lacks interpretability. In this paper, we present a novel hybrid modeling\nframework to describe a personalized cardiac digital twin as a combination of a\nphysics-based known expression augmented by neural network modeling of its\nunknown gap to reality. We then present a novel meta-learning framework to\nenable the separate identification of both the physics-based and neural\ncomponents in the hybrid model. We demonstrate the feasibility and generality\nof this hybrid modeling framework with two examples of instantiations and their\nproof-of-concept in synthetic experiments.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15433v1",
    "published_date": "2024-03-15 02:30:00 UTC",
    "updated_date": "2024-03-15 02:30:00 UTC"
  },
  {
    "arxiv_id": "2405.00690v1",
    "title": "Scenarios Engineering driven Autonomous Transportation in Open-Pit Mines",
    "authors": [
      "Siyu Teng",
      "Xuan Li",
      "Yuchen Li",
      "Lingxi Li",
      "Yunfeng Ai",
      "Long Chen"
    ],
    "abstract": "One critical bottleneck that impedes the development and deployment of\nautonomous transportation in open-pit mines is guaranteed robustness and\ntrustworthiness in prohibitively extreme scenarios. In this research, a novel\nscenarios engineering (SE) methodology for the autonomous mining truck is\nproposed for open-pit mines. SE increases the trustworthiness and robustness of\nautonomous trucks from four key components: Scenario Feature Extractor,\nIntelligence & Index (I&I), Calibration & Certification (C&C), and Verification\n& Validation (V&V). Scenario feature extractor is a comprehensive pipeline\napproach that captures complex interactions and latent dependencies in complex\nmining scenarios. I&I effectively enhances the quality of the training dataset,\nthereby establishing a solid foundation for autonomous transportation in mining\nareas. C&C is grounded in the intrinsic regulation, capabilities, and\ncontributions of the intelligent systems employed in autonomous transportation\nto align with traffic participants in the real world and ensure their\nperformance through certification. V&V process ensures that the autonomous\ntransportation system can be correctly implemented, while validation focuses on\nevaluating the ability of the well-trained model to operate efficiently in the\ncomplex and dynamic conditions of the open-pit mines. This methodology\naddresses the unique challenges of autonomous transportation in open-pit\nmining, promoting productivity, safety, and performance in mining operations.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00690v1",
    "published_date": "2024-03-15 02:26:55 UTC",
    "updated_date": "2024-03-15 02:26:55 UTC"
  },
  {
    "arxiv_id": "2403.09963v2",
    "title": "Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction",
    "authors": [
      "Ziyang Xu",
      "Keqin Peng",
      "Liang Ding",
      "Dacheng Tao",
      "Xiliang Lu"
    ],
    "abstract": "Recent research shows that pre-trained language models (PLMs) suffer from\n\"prompt bias\" in factual knowledge extraction, i.e., prompts tend to introduce\nbiases toward specific labels. Prompt bias presents a significant challenge in\nassessing the factual knowledge within PLMs. Therefore, this paper aims to\nimprove the reliability of existing benchmarks by thoroughly investigating and\nmitigating prompt bias. We show that: 1) all prompts in the experiments exhibit\nnon-negligible bias, with gradient-based prompts like AutoPrompt and OptiPrompt\ndisplaying significantly higher levels of bias; 2) prompt bias can amplify\nbenchmark accuracy unreasonably by overfitting the test datasets, especially on\nimbalanced datasets like LAMA. Based on these findings, we propose a\nrepresentation-based approach to mitigate the prompt bias during inference\ntime. Specifically, we first estimate the biased representation using\nprompt-only querying, and then remove it from the model's internal\nrepresentations to generate the debiased representations, which are used to\nproduce the final debiased outputs. Experiments across various prompts, PLMs,\nand benchmarks show that our approach can not only correct the overfitted\nperformance caused by prompt bias, but also significantly improve the prompt\nretrieval capability (up to 10% absolute performance gain). These results\nindicate that our approach effectively alleviates prompt bias in knowledge\nevaluation, thereby enhancing the reliability of benchmark assessments.\nHopefully, our plug-and-play approach can be a golden standard to strengthen\nPLMs toward reliable knowledge bases. Code and data are released in\nhttps://github.com/FelliYang/PromptBias.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.09963v2",
    "published_date": "2024-03-15 02:04:35 UTC",
    "updated_date": "2024-03-26 04:08:47 UTC"
  },
  {
    "arxiv_id": "2403.09948v2",
    "title": "RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training",
    "authors": [
      "Zhixiu Lu",
      "Hailong Li",
      "Nehal A. Parikh",
      "Jonathan R. Dillman",
      "Lili He"
    ],
    "abstract": "The integration of artificial intelligence (AI) with radiology marks a\ntransformative era in medicine. Vision foundation models have been adopted to\nenhance radiologic imaging analysis. However, the distinct complexities of\nradiologic 2D and 3D radiologic data pose unique challenges that existing\nmodels, pre-trained on general non-medical images, fail to address adequately.\nTo bridge this gap and capitalize on the diagnostic precision required in\nradiologic imaging, we introduce Radiologic Contrastive Language-Image\nPre-training (RadCLIP): a cross-modal vision-language foundational model that\nharnesses Vision Language Pre-training (VLP) framework to improve radiologic\nimage analysis. Building upon Contrastive Language-Image Pre-training (CLIP),\nRadCLIP incorporates a slice pooling mechanism tailored for volumetric image\nanalysis and is pre-trained using a large and diverse dataset of radiologic\nimage-text pairs. The RadCLIP was pre-trained to effectively align radiologic\nimages with their corresponding text annotations, creating a robust vision\nbackbone for radiologic images. Extensive experiments demonstrate RadCLIP's\nsuperior performance in both uni-modal radiologic image classification and\ncross-modal image-text matching, highlighting its significant promise for\nimproving diagnostic accuracy and efficiency in clinical settings. Our Key\ncontributions include curating a large dataset with diverse radiologic 2D/3D\nradiologic image-text pairs, a slice pooling adapter using an attention\nmechanism for integrating 2D images, and comprehensive evaluations of RadCLIP\non various radiologic downstream tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09948v2",
    "published_date": "2024-03-15 01:18:08 UTC",
    "updated_date": "2024-09-05 18:13:16 UTC"
  },
  {
    "arxiv_id": "2403.09940v2",
    "title": "Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries",
    "authors": [
      "Swetha Ganesh",
      "Jiayu Chen",
      "Gugan Thoppe",
      "Vaneet Aggarwal"
    ],
    "abstract": "Federated Reinforcement Learning (FRL) allows multiple agents to\ncollaboratively build a decision making policy without sharing raw\ntrajectories. However, if a small fraction of these agents are adversarial, it\ncan lead to catastrophic results. We propose a policy gradient based approach\nthat is robust to adversarial agents which can send arbitrary values to the\nserver. Under this setting, our results form the first global convergence\nguarantees with general parametrization. These results demonstrate resilience\nwith adversaries, while achieving optimal sample complexity of order\n$\\tilde{\\mathcal{O}}\\left( \\frac{1}{N\\epsilon^2} \\left( 1+\n\\frac{f^2}{N}\\right)\\right)$, where $N$ is the total number of agents and\n$f<N/2$ is the number of adversarial agents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 14 figures and 1 table",
    "pdf_url": "http://arxiv.org/pdf/2403.09940v2",
    "published_date": "2024-03-15 00:45:36 UTC",
    "updated_date": "2024-11-05 08:15:33 UTC"
  },
  {
    "arxiv_id": "2403.09930v3",
    "title": "Quality-Diversity Actor-Critic: Learning High-Performing and Diverse Behaviors via Value and Successor Features Critics",
    "authors": [
      "Luca Grillotti",
      "Maxence Faldor",
      "Borja G. León",
      "Antoine Cully"
    ],
    "abstract": "A key aspect of intelligence is the ability to demonstrate a broad spectrum\nof behaviors for adapting to unexpected situations. Over the past decade,\nadvancements in deep reinforcement learning have led to groundbreaking\nachievements to solve complex continuous control tasks. However, most\napproaches return only one solution specialized for a specific problem. We\nintroduce Quality-Diversity Actor-Critic (QDAC), an off-policy actor-critic\ndeep reinforcement learning algorithm that leverages a value function critic\nand a successor features critic to learn high-performing and diverse behaviors.\nIn this framework, the actor optimizes an objective that seamlessly unifies\nboth critics using constrained optimization to (1) maximize return, while (2)\nexecuting diverse skills. Compared with other Quality-Diversity methods, QDAC\nachieves significantly higher performance and more diverse behaviors on six\nchallenging continuous control locomotion tasks. We also demonstrate that we\ncan harness the learned skills to adapt better than other baselines to five\nperturbed environments. Finally, qualitative analyses showcase a range of\nremarkable behaviors: adaptive-intelligent-robotics.github.io/QDAC.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The first two authors contributed equally to this work. Accepted at\n  ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.09930v3",
    "published_date": "2024-03-15 00:09:47 UTC",
    "updated_date": "2024-06-03 09:46:32 UTC"
  }
]