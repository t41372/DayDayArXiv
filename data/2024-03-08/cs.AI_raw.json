[
  {
    "arxiv_id": "2403.05732v2",
    "title": "Conservative DDPG -- Pessimistic RL without Ensemble",
    "authors": [
      "Nitsan Soffair",
      "Shie Mannor"
    ],
    "abstract": "DDPG is hindered by the overestimation bias problem, wherein its\n$Q$-estimates tend to overstate the actual $Q$-values. Traditional solutions to\nthis bias involve ensemble-based methods, which require significant\ncomputational resources, or complex log-policy-based approaches, which are\ndifficult to understand and implement. In contrast, we propose a\nstraightforward solution using a $Q$-target and incorporating a behavioral\ncloning (BC) loss penalty. This solution, acting as an uncertainty measure, can\nbe easily implemented with minimal code and without the need for an ensemble.\nOur empirical findings strongly support the superiority of Conservative DDPG\nover DDPG across various MuJoCo and Bullet tasks. We consistently observe\nbetter performance in all evaluated tasks and even competitive or superior\nperformance compared to TD3 and TD7, all achieved with significantly reduced\ncomputational requirements.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper do not ready",
    "pdf_url": "http://arxiv.org/pdf/2403.05732v2",
    "published_date": "2024-03-08 23:59:38 UTC",
    "updated_date": "2024-06-02 19:40:48 UTC"
  },
  {
    "arxiv_id": "2403.09705v1",
    "title": "A Novel Nuanced Conversation Evaluation Framework for Large Language Models in Mental Health",
    "authors": [
      "Alexander Marrapese",
      "Basem Suleiman",
      "Imdad Ullah",
      "Juno Kim"
    ],
    "abstract": "Understanding the conversation abilities of Large Language Models (LLMs) can\nhelp lead to its more cautious and appropriate deployment. This is especially\nimportant for safety-critical domains like mental health, where someone's life\nmay depend on the exact wording of a response to an urgent question. In this\npaper, we propose a novel framework for evaluating the nuanced conversation\nabilities of LLMs. Within it, we develop a series of quantitative metrics\ndeveloped from literature on using psychotherapy conversation analysis\nliterature. While we ensure that our framework and metrics are transferable by\nresearchers to relevant adjacent domains, we apply them to the mental health\nfield. We use our framework to evaluate several popular frontier LLMs,\nincluding some GPT and Llama models, through a verified mental health dataset.\nOur results show that GPT4 Turbo can perform significantly more similarly to\nverified therapists than other selected LLMs. We conduct additional analysis to\nexamine how LLM conversation performance varies across specific mental health\ntopics. Our results indicate that GPT4 Turbo performs well in achieving high\ncorrelation with verified therapists in particular topics such as Parenting and\nRelationships. We believe our contributions will help researchers develop\nbetter LLMs that, in turn, will more positively support people's lives.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09705v1",
    "published_date": "2024-03-08 23:46:37 UTC",
    "updated_date": "2024-03-08 23:46:37 UTC"
  },
  {
    "arxiv_id": "2403.05720v5",
    "title": "A dataset and benchmark for hospital course summarization with adapted large language models",
    "authors": [
      "Asad Aali",
      "Dave Van Veen",
      "Yamin Ishraq Arefeen",
      "Jason Hom",
      "Christian Bluethgen",
      "Eduardo Pontes Reis",
      "Sergios Gatidis",
      "Namuun Clifford",
      "Joseph Daws",
      "Arash S. Tehrani",
      "Jangwon Kim",
      "Akshay S. Chaudhari"
    ],
    "abstract": "Brief hospital course (BHC) summaries are clinical documents that summarize a\npatient's hospital stay. While large language models (LLMs) depict remarkable\ncapabilities in automating real-world tasks, their capabilities for healthcare\napplications such as synthesizing BHCs from clinical notes have not been shown.\nWe introduce a novel pre-processed dataset, the MIMIC-IV-BHC, encapsulating\nclinical note and brief hospital course (BHC) pairs to adapt LLMs for BHC\nsynthesis. Furthermore, we introduce a benchmark of the summarization\nperformance of two general-purpose LLMs and three healthcare-adapted LLMs.\nUsing clinical notes as input, we apply prompting-based (using in-context\nlearning) and fine-tuning-based adaptation strategies to three open-source LLMs\n(Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5,\nGPT-4). We evaluate these LLMs across multiple context-length inputs using\nnatural language similarity metrics. We further conduct a clinical study with\nfive clinicians, comparing clinician-written and LLM-generated BHCs across 30\nsamples, focusing on their potential to enhance clinical decision-making\nthrough improved summary quality. We observe that the Llama2-13B fine-tuned LLM\noutperforms other domain-adapted models given quantitative evaluation metrics\nof BLEU and BERT-Score. GPT-4 with in-context learning shows more robustness to\nincreasing context lengths of clinical note inputs than fine-tuned Llama2-13B.\nDespite comparable quantitative metrics, the reader study depicts a significant\npreference for summaries generated by GPT-4 with in-context learning compared\nto both Llama2-13B fine-tuned summaries and the original summaries,\nhighlighting the need for qualitative clinical evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05720v5",
    "published_date": "2024-03-08 23:17:55 UTC",
    "updated_date": "2025-04-23 02:16:48 UTC"
  },
  {
    "arxiv_id": "2403.05715v1",
    "title": "A Framework for Effective AI Recommendations in Cyber-Physical-Human Systems",
    "authors": [
      "Aditya Dave",
      "Heeseung Bang",
      "Andreas A. Malikopoulos"
    ],
    "abstract": "Many cyber-physical-human systems (CPHS) involve a human decision-maker who\nmay receive recommendations from an artificial intelligence (AI) platform while\nholding the ultimate responsibility of making decisions. In such CPHS\napplications, the human decision-maker may depart from an optimal recommended\ndecision and instead implement a different one for various reasons. In this\nletter, we develop a rigorous framework to overcome this challenge. In our\nframework, we consider that humans may deviate from AI recommendations as they\nperceive and interpret the system's state in a different way than the AI\nplatform. We establish the structural properties of optimal recommendation\nstrategies and develop an approximate human model (AHM) used by the AI. We\nprovide theoretical bounds on the optimality gap that arises from an AHM and\nillustrate the efficacy of our results in a numerical example.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05715v1",
    "published_date": "2024-03-08 23:02:20 UTC",
    "updated_date": "2024-03-08 23:02:20 UTC"
  },
  {
    "arxiv_id": "2403.07938v1",
    "title": "Text-to-Audio Generation Synchronized with Videos",
    "authors": [
      "Shentong Mo",
      "Jing Shi",
      "Yapeng Tian"
    ],
    "abstract": "In recent times, the focus on text-to-audio (TTA) generation has intensified,\nas researchers strive to synthesize audio from textual descriptions. However,\nmost existing methods, though leveraging latent diffusion models to learn the\ncorrelation between audio and text embeddings, fall short when it comes to\nmaintaining a seamless synchronization between the produced audio and its\nvideo. This often results in discernible audio-visual mismatches. To bridge\nthis gap, we introduce a groundbreaking benchmark for Text-to-Audio generation\nthat aligns with Videos, named T2AV-Bench. This benchmark distinguishes itself\nwith three novel metrics dedicated to evaluating visual alignment and temporal\nconsistency. To complement this, we also present a simple yet effective\nvideo-aligned TTA generation model, namely T2AV. Moving beyond traditional\nmethods, T2AV refines the latent diffusion approach by integrating\nvisual-aligned text embeddings as its conditional foundation. It employs a\ntemporal multi-head attention transformer to extract and understand temporal\nnuances from video data, a feat amplified by our Audio-Visual ControlNet that\nadeptly merges temporal visual representations with text embeddings. Further\nenhancing this integration, we weave in a contrastive learning objective,\ndesigned to ensure that the visual-aligned text embeddings resonate closely\nwith the audio features. Extensive evaluations on the AudioCaps and T2AV-Bench\ndemonstrate that our T2AV sets a new standard for video-aligned TTA generation\nin ensuring visual alignment and temporal consistency.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "arXiv admin note: text overlap with arXiv:2305.12903",
    "pdf_url": "http://arxiv.org/pdf/2403.07938v1",
    "published_date": "2024-03-08 22:27:38 UTC",
    "updated_date": "2024-03-08 22:27:38 UTC"
  },
  {
    "arxiv_id": "2403.05701v2",
    "title": "Are Large Language Models Aligned with People's Social Intuitions for Human-Robot Interactions?",
    "authors": [
      "Lennart Wachowiak",
      "Andrew Coles",
      "Oya Celiktutan",
      "Gerard Canal"
    ],
    "abstract": "Large language models (LLMs) are increasingly used in robotics, especially\nfor high-level action planning. Meanwhile, many robotics applications involve\nhuman supervisors or collaborators. Hence, it is crucial for LLMs to generate\nsocially acceptable actions that align with people's preferences and values. In\nthis work, we test whether LLMs capture people's intuitions about behavior\njudgments and communication preferences in human-robot interaction (HRI)\nscenarios. For evaluation, we reproduce three HRI user studies, comparing the\noutput of LLMs with that of real participants. We find that GPT-4 strongly\noutperforms other models, generating answers that correlate strongly with\nusers' answers in two studies $\\unicode{x2014}$ the first study dealing with\nselecting the most appropriate communicative act for a robot in various\nsituations ($r_s$ = 0.82), and the second with judging the desirability,\nintentionality, and surprisingness of behavior ($r_s$ = 0.83). However, for the\nlast study, testing whether people judge the behavior of robots and humans\ndifferently, no model achieves strong correlations. Moreover, we show that\nvision models fail to capture the essence of video stimuli and that LLMs tend\nto rate different communicative acts and behavior desirability higher than\npeople.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS), 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05701v2",
    "published_date": "2024-03-08 22:23:23 UTC",
    "updated_date": "2024-07-09 11:27:40 UTC"
  },
  {
    "arxiv_id": "2406.16868v1",
    "title": "Neural Network-based Two-Dimensional Filtering for OTFS Symbol Detection",
    "authors": [
      "Jiarui Xu",
      "Karim Said",
      "Lizhong Zheng",
      "Lingjia Liu"
    ],
    "abstract": "Orthogonal time frequency space (OTFS) is a promising modulation scheme for\nwireless communication in high-mobility scenarios. Recently, a reservoir\ncomputing (RC) based approach has been introduced for online subframe-based\nsymbol detection in the OTFS system, where only the limited over-the-air (OTA)\npilot symbols are utilized for training. However, the previous RC-based\napproach does not design the RC architecture based on the properties of the\nOTFS system to fully unlock the potential of RC. This paper introduces a novel\ntwo-dimensional RC (2D-RC) approach for online symbol detection on a subframe\nbasis in the OTFS system. The 2D-RC is designed to have a two-dimensional (2D)\nfiltering structure to equalize the 2D circular channel effect in the\ndelay-Doppler (DD) domain of the OTFS system. With the introduced architecture,\nthe 2D-RC can operate in the DD domain with only a single neural network,\nunlike our previous work which requires multiple RCs to track channel\nvariations in the time domain. Experimental results demonstrate the advantages\nof the 2D-RC approach over the previous RC-based approach and the compared\nmodel-based methods across different modulation orders.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "6 pages, conference paper. arXiv admin note: substantial text overlap\n  with arXiv:2311.08543",
    "pdf_url": "http://arxiv.org/pdf/2406.16868v1",
    "published_date": "2024-03-08 21:33:41 UTC",
    "updated_date": "2024-03-08 21:33:41 UTC"
  },
  {
    "arxiv_id": "2403.05683v1",
    "title": "Efficient Public Health Intervention Planning Using Decomposition-Based Decision-Focused Learning",
    "authors": [
      "Sanket Shah",
      "Arun Suggala",
      "Milind Tambe",
      "Aparna Taneja"
    ],
    "abstract": "The declining participation of beneficiaries over time is a key concern in\npublic health programs. A popular strategy for improving retention is to have\nhealth workers `intervene' on beneficiaries at risk of dropping out. However,\nthe availability and time of these health workers are limited resources. As a\nresult, there has been a line of research on optimizing these limited\nintervention resources using Restless Multi-Armed Bandits (RMABs). The key\ntechnical barrier to using this framework in practice lies in the need to\nestimate the beneficiaries' RMAB parameters from historical data. Recent\nresearch has shown that Decision-Focused Learning (DFL), which focuses on\nmaximizing the beneficiaries' adherence rather than predictive accuracy,\nimproves the performance of intervention targeting using RMABs. Unfortunately,\nthese gains come at a high computational cost because of the need to solve and\nevaluate the RMAB in each DFL training step. In this paper, we provide a\nprincipled way to exploit the structure of RMABs to speed up intervention\nplanning by cleverly decoupling the planning for different beneficiaries. We\nuse real-world data from an Indian NGO, ARMMAN, to show that our approach is up\nto two orders of magnitude faster than the state-of-the-art approach while also\nyielding superior model performance. This would enable the NGO to scale up\ndeployments using DFL to potentially millions of mothers, ultimately advancing\nprogress toward UNSDG 3.1.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.05683v1",
    "published_date": "2024-03-08 21:31:00 UTC",
    "updated_date": "2024-03-08 21:31:00 UTC"
  },
  {
    "arxiv_id": "2403.09704v1",
    "title": "Alignment Studio: Aligning Large Language Models to Particular Contextual Regulations",
    "authors": [
      "Swapnaja Achintalwar",
      "Ioana Baldini",
      "Djallel Bouneffouf",
      "Joan Byamugisha",
      "Maria Chang",
      "Pierre Dognin",
      "Eitan Farchi",
      "Ndivhuwo Makondo",
      "Aleksandra Mojsilovic",
      "Manish Nagireddy",
      "Karthikeyan Natesan Ramamurthy",
      "Inkit Padhi",
      "Orna Raz",
      "Jesus Rios",
      "Prasanna Sattigeri",
      "Moninder Singh",
      "Siphiwe Thwala",
      "Rosario A. Uceda-Sosa",
      "Kush R. Varshney"
    ],
    "abstract": "The alignment of large language models is usually done by model providers to\nadd or control behaviors that are common or universally understood across use\ncases and contexts. In contrast, in this article, we present an approach and\narchitecture that empowers application developers to tune a model to their\nparticular values, social norms, laws and other regulations, and orchestrate\nbetween potentially conflicting requirements in context. We lay out three main\ncomponents of such an Alignment Studio architecture: Framers, Instructors, and\nAuditors that work in concert to control the behavior of a language model. We\nillustrate this approach with a running example of aligning a company's\ninternal-facing enterprise chatbot to its business conduct guidelines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.09704v1",
    "published_date": "2024-03-08 21:26:49 UTC",
    "updated_date": "2024-03-08 21:26:49 UTC"
  },
  {
    "arxiv_id": "2403.05681v1",
    "title": "DP-TabICL: In-Context Learning with Differentially Private Tabular Data",
    "authors": [
      "Alycia N. Carey",
      "Karuna Bhaila",
      "Kennedy Edemacu",
      "Xintao Wu"
    ],
    "abstract": "In-context learning (ICL) enables large language models (LLMs) to adapt to\nnew tasks by conditioning on demonstrations of question-answer pairs and it has\nbeen shown to have comparable performance to costly model retraining and\nfine-tuning. Recently, ICL has been extended to allow tabular data to be used\nas demonstration examples by serializing individual records into natural\nlanguage formats. However, it has been shown that LLMs can leak information\ncontained in prompts, and since tabular data often contain sensitive\ninformation, understanding how to protect the underlying tabular data used in\nICL is a critical area of research. This work serves as an initial\ninvestigation into how to use differential privacy (DP) -- the long-established\ngold standard for data privacy and anonymization -- to protect tabular data\nused in ICL. Specifically, we investigate the application of DP mechanisms for\nprivate tabular ICL via data privatization prior to serialization and\nprompting. We formulate two private ICL frameworks with provable privacy\nguarantees in both the local (LDP-TabICL) and global (GDP-TabICL) DP scenarios\nvia injecting noise into individual records or group statistics, respectively.\nWe evaluate our DP-based frameworks on eight real-world tabular datasets and\nacross multiple ICL and DP settings. Our evaluations show that DP-based ICL can\nprotect the privacy of the underlying tabular data while achieving comparable\nperformance to non-LLM baselines, especially under high privacy regimes.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "15 pages, 2 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.05681v1",
    "published_date": "2024-03-08 21:19:01 UTC",
    "updated_date": "2024-03-08 21:19:01 UTC"
  },
  {
    "arxiv_id": "2403.05680v2",
    "title": "How Well Do Multi-modal LLMs Interpret CT Scans? An Auto-Evaluation Framework for Analyses",
    "authors": [
      "Qingqing Zhu",
      "Benjamin Hou",
      "Tejas S. Mathai",
      "Pritam Mukherjee",
      "Qiao Jin",
      "Xiuying Chen",
      "Zhizheng Wang",
      "Ruida Cheng",
      "Ronald M. Summers",
      "Zhiyong Lu"
    ],
    "abstract": "Automatically interpreting CT scans can ease the workload of radiologists.\nHowever, this is challenging mainly due to the scarcity of adequate datasets\nand reference standards for evaluation. This study aims to bridge this gap by\nintroducing a novel evaluation framework, named ``GPTRadScore''. This framework\nassesses the capabilities of multi-modal LLMs, such as GPT-4 with Vision\n(GPT-4V), Gemini Pro Vision, LLaVA-Med, and RadFM, in generating descriptions\nfor prospectively-identified findings. By employing a decomposition technique\nbased on GPT-4, GPTRadScore compares these generated descriptions with\ngold-standard report sentences, analyzing their accuracy in terms of body part,\nlocation, and type of finding. Evaluations demonstrated a high correlation with\nclinician assessments and highlighted its potential over traditional metrics,\nsuch as BLEU, METEOR, and ROUGE. Furthermore, to contribute to future studies,\nwe plan to release a benchmark dataset annotated by clinicians. Using\nGPTRadScore, we found that while GPT-4V and Gemini Pro Vision fare better,\ntheir performance revealed significant areas for improvement, primarily due to\nlimitations in the dataset used for training these models. To demonstrate this\npotential, RadFM was fine-tuned and it resulted in significant accuracy\nimprovements: location accuracy rose from 3.41\\% to 12.8\\%, body part accuracy\nfrom 29.12\\% to 53\\%, and type accuracy from 9.24\\% to 30\\%, thereby validating\nour hypothesis.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05680v2",
    "published_date": "2024-03-08 21:16:28 UTC",
    "updated_date": "2024-06-18 12:43:18 UTC"
  },
  {
    "arxiv_id": "2403.05658v1",
    "title": "Feature CAM: Interpretable AI in Image Classification",
    "authors": [
      "Frincy Clement",
      "Ji Yang",
      "Irene Cheng"
    ],
    "abstract": "Deep Neural Networks have often been called the black box because of the\ncomplex, deep architecture and non-transparency presented by the inner layers.\nThere is a lack of trust to use Artificial Intelligence in critical and\nhigh-precision fields such as security, finance, health, and manufacturing\nindustries. A lot of focused work has been done to provide interpretable\nmodels, intending to deliver meaningful insights into the thoughts and behavior\nof neural networks. In our research, we compare the state-of-the-art methods in\nthe Activation-based methods (ABM) for interpreting predictions of CNN models,\nspecifically in the application of Image Classification. We then extend the\nsame for eight CNN-based architectures to compare the differences in\nvisualization and thus interpretability. We introduced a novel technique\nFeature CAM, which falls in the perturbation-activation combination, to create\nfine-grained, class-discriminative visualizations. The resulting saliency maps\nfrom our experiments proved to be 3-4 times better human interpretable than the\nstate-of-the-art in ABM. At the same time it reserves machine interpretability,\nwhich is the average confidence scores in classification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05658v1",
    "published_date": "2024-03-08 20:16:00 UTC",
    "updated_date": "2024-03-08 20:16:00 UTC"
  },
  {
    "arxiv_id": "2403.05652v2",
    "title": "What is different between these datasets?",
    "authors": [
      "Varun Babbar",
      "Zhicheng Guo",
      "Cynthia Rudin"
    ],
    "abstract": "The performance of machine learning models relies heavily on the quality of\ninput data, yet real-world applications often face significant data-related\nchallenges. A common issue arises when curating training data or deploying\nmodels: two datasets from the same domain may exhibit differing distributions.\nWhile many techniques exist for detecting such distribution shifts, there is a\nlack of comprehensive methods to explain these differences in a\nhuman-understandable way beyond opaque quantitative metrics. To bridge this\ngap, we propose a versatile toolbox of interpretable methods for comparing\ndatasets. Using a variety of case studies, we demonstrate the effectiveness of\nour approach across diverse data modalities -- including tabular data, text\ndata, images, time series signals -- in both low and high-dimensional settings.\nThese methods complement existing techniques by providing actionable and\ninterpretable insights to better understand and address distribution shifts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05652v2",
    "published_date": "2024-03-08 19:52:39 UTC",
    "updated_date": "2025-01-29 17:10:45 UTC"
  },
  {
    "arxiv_id": "2403.05645v3",
    "title": "Geometric Neural Network based on Phase Space for BCI-EEG decoding",
    "authors": [
      "Igor Carrara",
      "Bruno Aristimunha",
      "Marie-Constance Corsi",
      "Raphael Y. de Camargo",
      "Sylvain Chevallier",
      "Théodore Papadopoulo"
    ],
    "abstract": "Objective: The integration of Deep Learning (DL) algorithms on brain signal\nanalysis is still in its nascent stages compared to their success in fields\nlike Computer Vision. This is particularly true for BCI, where the brain\nactivity is decoded to control external devices without requiring muscle\ncontrol. Electroencephalography (EEG) is a widely adopted choice for designing\nBCI systems due to its non-invasive and cost-effective nature and excellent\ntemporal resolution. Still, it comes at the expense of limited training data,\npoor signal-to-noise, and a large variability across and within-subject\nrecordings. Finally, setting up a BCI system with many electrodes takes a long\ntime, hindering the widespread adoption of reliable DL architectures in BCIs\noutside research laboratories. To improve adoption, we need to improve user\ncomfort using, for instance, reliable algorithms that operate with few\nelectrodes. Approach: Our research aims to develop a DL algorithm that delivers\neffective results with a limited number of electrodes. Taking advantage of the\nAugmented Covariance Method and the framework of SPDNet, we propose the\nPhase-SPDNet architecture and analyze its performance and the interpretability\nof the results. The evaluation is conducted on 5-fold cross-validation, using\nonly three electrodes positioned above the Motor Cortex. The methodology was\ntested on nearly 100 subjects from several open-source datasets using the\nMother Of All BCI Benchmark (MOABB) framework. Main results: The results of our\nPhase-SPDNet demonstrate that the augmented approach combined with the SPDNet\nsignificantly outperforms all the current state-of-the-art DL architecture in\nMI decoding. Significance: This new architecture is explainable and with a low\nnumber of trainable parameters.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "q-bio.NC",
      "I.5.1; I.6.3; I.2.6"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05645v3",
    "published_date": "2024-03-08 19:36:20 UTC",
    "updated_date": "2024-08-28 15:39:45 UTC"
  },
  {
    "arxiv_id": "2403.05641v1",
    "title": "A Feature-based Generalizable Prediction Model for Both Perceptual and Abstract Reasoning",
    "authors": [
      "Quan Do",
      "Thomas M. Morin",
      "Chantal E. Stern",
      "Michael E. Hasselmo"
    ],
    "abstract": "A hallmark of human intelligence is the ability to infer abstract rules from\nlimited experience and apply these rules to unfamiliar situations. This\ncapacity is widely studied in the visual domain using the Raven's Progressive\nMatrices. Recent advances in deep learning have led to multiple artificial\nneural network models matching or even surpassing human performance. However,\nwhile humans can identify and express the rule underlying these tasks with\nlittle to no exposure, contemporary neural networks often rely on massive\npattern-based training and cannot express or extrapolate the rule inferred from\nthe task. Furthermore, most Raven's Progressive Matrices or Raven-like tasks\nused for neural network training used symbolic representations, whereas humans\ncan flexibly switch between symbolic and continuous perceptual representations.\nIn this work, we present an algorithmic approach to rule detection and\napplication using feature detection, affine transformation estimation and\nsearch. We applied our model to a simplified Raven's Progressive Matrices task,\npreviously designed for behavioral testing and neuroimaging in humans. The\nmodel exhibited one-shot learning and achieved near human-level performance in\nthe symbolic reasoning condition of the simplified task. Furthermore, the model\ncan express the relationships discovered and generate multi-step predictions in\naccordance with the underlying rule. Finally, the model can reason using\ncontinuous patterns. We discuss our results and their relevance to studying\nabstract reasoning in humans, as well as their implications for improving\nintelligent machines.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05641v1",
    "published_date": "2024-03-08 19:26:30 UTC",
    "updated_date": "2024-03-08 19:26:30 UTC"
  },
  {
    "arxiv_id": "2403.05636v1",
    "title": "Tuning-Free Accountable Intervention for LLM Deployment -- A Metacognitive Approach",
    "authors": [
      "Zhen Tan",
      "Jie Peng",
      "Tianlong Chen",
      "Huan Liu"
    ],
    "abstract": "Large Language Models (LLMs) have catalyzed transformative advances across a\nspectrum of natural language processing tasks through few-shot or zero-shot\nprompting, bypassing the need for parameter tuning. While convenient, this\nmodus operandi aggravates ``hallucination'' concerns, particularly given the\nenigmatic ``black-box'' nature behind their gigantic model sizes. Such concerns\nare exacerbated in high-stakes applications (e.g., healthcare), where\nunaccountable decision errors can lead to devastating consequences. In\ncontrast, human decision-making relies on nuanced cognitive processes, such as\nthe ability to sense and adaptively correct misjudgments through conceptual\nunderstanding. Drawing inspiration from human cognition, we propose an\ninnovative \\textit{metacognitive} approach, dubbed \\textbf{CLEAR}, to equip\nLLMs with capabilities for self-aware error identification and correction. Our\nframework facilitates the construction of concept-specific sparse subnetworks\nthat illuminate transparent decision pathways. This provides a novel interface\nfor model \\textit{intervention} after deployment. Our intervention offers\ncompelling advantages: (\\textit{i})~at deployment or inference time, our\nmetacognitive LLMs can self-consciously identify potential mispredictions with\nminimum human involvement, (\\textit{ii})~the model has the capability to\nself-correct its errors efficiently, obviating the need for additional tuning,\nand (\\textit{iii})~the rectification procedure is not only self-explanatory but\nalso user-friendly, enhancing the interpretability and accessibility of the\nmodel. By integrating these metacognitive features, our approach pioneers a new\npath toward engendering greater trustworthiness and accountability in the\ndeployment of LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05636v1",
    "published_date": "2024-03-08 19:18:53 UTC",
    "updated_date": "2024-03-08 19:18:53 UTC"
  },
  {
    "arxiv_id": "2403.05632v1",
    "title": "Can Large Language Models Play Games? A Case Study of A Self-Play Approach",
    "authors": [
      "Hongyi Guo",
      "Zhihan Liu",
      "Yufeng Zhang",
      "Zhaoran Wang"
    ],
    "abstract": "Large Language Models (LLMs) harness extensive data from the Internet,\nstoring a broad spectrum of prior knowledge. While LLMs have proven beneficial\nas decision-making aids, their reliability is hampered by limitations in\nreasoning, hallucination phenomenon, and so on. On the other hand, Monte-Carlo\nTree Search (MCTS) is a heuristic search algorithm that provides reliable\ndecision-making solutions, achieved through recursive rollouts and self-play.\nHowever, the effectiveness of MCTS relies heavily on heuristic pruning and\nexternal value functions, particularly in complex decision scenarios. This work\nintroduces an innovative approach that bolsters LLMs with MCTS self-play to\nefficiently resolve deterministic turn-based zero-sum games (DTZG), such as\nchess and go, without the need for additional training. Specifically, we\nutilize LLMs as both action pruners and proxies for value functions without the\nneed for additional training. We theoretically prove that the suboptimality of\nthe estimated value in our proposed method scales with $\\tilde{\\mathcal\nO}\\Bigl(\\frac{|\\tilde {\\mathcal A}|}{\\sqrt{N}} + \\epsilon_\\mathrm{pruner} +\n\\epsilon_\\mathrm{critic}\\Bigr)$, where \\(N\\) is the number of simulations,\n$|\\tilde {\\mathcal A}|$ is the cardinality of the pruned action space by LLM,\nand $\\epsilon_\\mathrm{pruner}$ and $\\epsilon_\\mathrm{critic}$ quantify the\nerrors incurred by adopting LLMs as action space pruner and value function\nproxy, respectively. Our experiments in chess and go demonstrate the capability\nof our method to address challenges beyond the scope of MCTS and improve the\nperformance of the directly application of LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05632v1",
    "published_date": "2024-03-08 19:16:29 UTC",
    "updated_date": "2024-03-08 19:16:29 UTC"
  },
  {
    "arxiv_id": "2403.09703v2",
    "title": "Concept-aware Data Construction Improves In-context Learning of Language Models",
    "authors": [
      "Michal Štefánik",
      "Marek Kadlčík",
      "Petr Sojka"
    ],
    "abstract": "Many recent language models (LMs) are capable of in-context learning (ICL),\nmanifested in the LMs' ability to perform a new task solely from\nnatural-language instruction. Previous work curating in-context learners\nassumes that ICL emerges from a vast over-parametrization or the scale of\nmulti-task training. However, recent theoretical work attributes the ICL\nability to concept-dependent training data and creates functional in-context\nlearners even in small-scale, synthetic settings.\n  In this work, we practically explore this newly identified axis of ICL\nquality. We propose Concept-aware Training (CoAT), a framework for constructing\ntraining scenarios that make it beneficial for the LM to learn to utilize the\nanalogical reasoning concepts from demonstrations. We find that by using CoAT,\npre-trained transformers can learn to better utilise new latent concepts from\ndemonstrations and that such ability makes ICL more robust to the functional\ndeficiencies of the previous models. Finally, we show that concept-aware\nin-context learning is more effective for a majority of new tasks when compared\nto traditional instruction tuning, resulting in a performance comparable to the\nprevious in-context learners using magnitudes of more training data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Long paper to appear in Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.09703v2",
    "published_date": "2024-03-08 19:07:47 UTC",
    "updated_date": "2024-06-28 08:03:19 UTC"
  },
  {
    "arxiv_id": "2403.05535v3",
    "title": "Tell, Don't Show!: Language Guidance Eases Transfer Across Domains in Images and Videos",
    "authors": [
      "Tarun Kalluri",
      "Bodhisattwa Prasad Majumder",
      "Manmohan Chandraker"
    ],
    "abstract": "We introduce LaGTran, a novel framework that utilizes text supervision to\nguide robust transfer of discriminative knowledge from labeled source to\nunlabeled target data with domain gaps. While unsupervised adaptation methods\nhave been established to address this problem, they show limitations in\nhandling challenging domain shifts due to their exclusive operation within the\npixel-space. Motivated by our observation that semantically richer text\nmodality has more favorable transfer properties, we devise a transfer mechanism\nto use a source-trained text-classifier to generate predictions on the target\ntext descriptions, and utilize these predictions as supervision for the\ncorresponding images. Our approach driven by language guidance is surprisingly\neasy and simple, yet significantly outperforms all prior approaches on\nchallenging datasets like GeoNet and DomainNet, validating its extreme\neffectiveness. To further extend the scope of our study beyond images, we\nintroduce a new benchmark called Ego2Exo to study ego-exo transfer in videos\nand find that our language-aided approach LaGTran yields significant gains in\nthis highly challenging and non-trivial transfer setting. Code, models, and\nproposed datasets are publicly available at\nhttps://tarun005.github.io/lagtran/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2024 Camera-Ready. Project Page and Code:\n  https://tarun005.github.io/lagtran/",
    "pdf_url": "http://arxiv.org/pdf/2403.05535v3",
    "published_date": "2024-03-08 18:58:46 UTC",
    "updated_date": "2024-06-06 01:44:48 UTC"
  },
  {
    "arxiv_id": "2403.05530v5",
    "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
    "authors": [
      "Gemini Team",
      "Petko Georgiev",
      "Ving Ian Lei",
      "Ryan Burnell",
      "Libin Bai",
      "Anmol Gulati",
      "Garrett Tanzer",
      "Damien Vincent",
      "Zhufeng Pan",
      "Shibo Wang",
      "Soroosh Mariooryad",
      "Yifan Ding",
      "Xinyang Geng",
      "Fred Alcober",
      "Roy Frostig",
      "Mark Omernick",
      "Lexi Walker",
      "Cosmin Paduraru",
      "Christina Sorokin",
      "Andrea Tacchetti",
      "Colin Gaffney",
      "Samira Daruki",
      "Olcan Sercinoglu",
      "Zach Gleicher",
      "Juliette Love",
      "Paul Voigtlaender",
      "Rohan Jain",
      "Gabriela Surita",
      "Kareem Mohamed",
      "Rory Blevins",
      "Junwhan Ahn",
      "Tao Zhu",
      "Kornraphop Kawintiranon",
      "Orhan Firat",
      "Yiming Gu",
      "Yujing Zhang",
      "Matthew Rahtz",
      "Manaal Faruqui",
      "Natalie Clay",
      "Justin Gilmer",
      "JD Co-Reyes",
      "Ivo Penchev",
      "Rui Zhu",
      "Nobuyuki Morioka",
      "Kevin Hui",
      "Krishna Haridasan",
      "Victor Campos",
      "Mahdis Mahdieh",
      "Mandy Guo",
      "Samer Hassan",
      "Kevin Kilgour",
      "Arpi Vezer",
      "Heng-Tze Cheng",
      "Raoul de Liedekerke",
      "Siddharth Goyal",
      "Paul Barham",
      "DJ Strouse",
      "Seb Noury",
      "Jonas Adler",
      "Mukund Sundararajan",
      "Sharad Vikram",
      "Dmitry Lepikhin",
      "Michela Paganini",
      "Xavier Garcia",
      "Fan Yang",
      "Dasha Valter",
      "Maja Trebacz",
      "Kiran Vodrahalli",
      "Chulayuth Asawaroengchai",
      "Roman Ring",
      "Norbert Kalb",
      "Livio Baldini Soares",
      "Siddhartha Brahma",
      "David Steiner",
      "Tianhe Yu",
      "Fabian Mentzer",
      "Antoine He",
      "Lucas Gonzalez",
      "Bibo Xu",
      "Raphael Lopez Kaufman",
      "Laurent El Shafey",
      "Junhyuk Oh",
      "Tom Hennigan",
      "George van den Driessche",
      "Seth Odoom",
      "Mario Lucic",
      "Becca Roelofs",
      "Sid Lall",
      "Amit Marathe",
      "Betty Chan",
      "Santiago Ontanon",
      "Luheng He",
      "Denis Teplyashin",
      "Jonathan Lai",
      "Phil Crone",
      "Bogdan Damoc",
      "Lewis Ho",
      "Sebastian Riedel",
      "Karel Lenc",
      "Chih-Kuan Yeh",
      "Aakanksha Chowdhery",
      "Yang Xu",
      "Mehran Kazemi",
      "Ehsan Amid",
      "Anastasia Petrushkina",
      "Kevin Swersky",
      "Ali Khodaei",
      "Gowoon Chen",
      "Chris Larkin",
      "Mario Pinto",
      "Geng Yan",
      "Adria Puigdomenech Badia",
      "Piyush Patil",
      "Steven Hansen",
      "Dave Orr",
      "Sebastien M. R. Arnold",
      "Jordan Grimstad",
      "Andrew Dai",
      "Sholto Douglas",
      "Rishika Sinha",
      "Vikas Yadav",
      "Xi Chen",
      "Elena Gribovskaya",
      "Jacob Austin",
      "Jeffrey Zhao",
      "Kaushal Patel",
      "Paul Komarek",
      "Sophia Austin",
      "Sebastian Borgeaud",
      "Linda Friso",
      "Abhimanyu Goyal",
      "Ben Caine",
      "Kris Cao",
      "Da-Woon Chung",
      "Matthew Lamm",
      "Gabe Barth-Maron",
      "Thais Kagohara",
      "Kate Olszewska",
      "Mia Chen",
      "Kaushik Shivakumar",
      "Rishabh Agarwal",
      "Harshal Godhia",
      "Ravi Rajwar",
      "Javier Snaider",
      "Xerxes Dotiwalla",
      "Yuan Liu",
      "Aditya Barua",
      "Victor Ungureanu",
      "Yuan Zhang",
      "Bat-Orgil Batsaikhan",
      "Mateo Wirth",
      "James Qin",
      "Ivo Danihelka",
      "Tulsee Doshi",
      "Martin Chadwick",
      "Jilin Chen",
      "Sanil Jain",
      "Quoc Le",
      "Arjun Kar",
      "Madhu Gurumurthy",
      "Cheng Li",
      "Ruoxin Sang",
      "Fangyu Liu",
      "Lampros Lamprou",
      "Rich Munoz",
      "Nathan Lintz",
      "Harsh Mehta",
      "Heidi Howard",
      "Malcolm Reynolds",
      "Lora Aroyo",
      "Quan Wang",
      "Lorenzo Blanco",
      "Albin Cassirer",
      "Jordan Griffith",
      "Dipanjan Das",
      "Stephan Lee",
      "Jakub Sygnowski",
      "Zach Fisher",
      "James Besley",
      "Richard Powell",
      "Zafarali Ahmed",
      "Dominik Paulus",
      "David Reitter",
      "Zalan Borsos",
      "Rishabh Joshi",
      "Aedan Pope",
      "Steven Hand",
      "Vittorio Selo",
      "Vihan Jain",
      "Nikhil Sethi",
      "Megha Goel",
      "Takaki Makino",
      "Rhys May",
      "Zhen Yang",
      "Johan Schalkwyk",
      "Christina Butterfield",
      "Anja Hauth",
      "Alex Goldin",
      "Will Hawkins",
      "Evan Senter",
      "Sergey Brin",
      "Oliver Woodman",
      "Marvin Ritter",
      "Eric Noland",
      "Minh Giang",
      "Vijay Bolina",
      "Lisa Lee",
      "Tim Blyth",
      "Ian Mackinnon",
      "Machel Reid",
      "Obaid Sarvana",
      "David Silver",
      "Alexander Chen",
      "Lily Wang",
      "Loren Maggiore",
      "Oscar Chang",
      "Nithya Attaluri",
      "Gregory Thornton",
      "Chung-Cheng Chiu",
      "Oskar Bunyan",
      "Nir Levine",
      "Timothy Chung",
      "Evgenii Eltyshev",
      "Xiance Si",
      "Timothy Lillicrap",
      "Demetra Brady",
      "Vaibhav Aggarwal",
      "Boxi Wu",
      "Yuanzhong Xu",
      "Ross McIlroy",
      "Kartikeya Badola",
      "Paramjit Sandhu",
      "Erica Moreira",
      "Wojciech Stokowiec",
      "Ross Hemsley",
      "Dong Li",
      "Alex Tudor",
      "Pranav Shyam",
      "Elahe Rahimtoroghi",
      "Salem Haykal",
      "Pablo Sprechmann",
      "Xiang Zhou",
      "Diana Mincu",
      "Yujia Li",
      "Ravi Addanki",
      "Kalpesh Krishna",
      "Xiao Wu",
      "Alexandre Frechette",
      "Matan Eyal",
      "Allan Dafoe",
      "Dave Lacey",
      "Jay Whang",
      "Thi Avrahami",
      "Ye Zhang",
      "Emanuel Taropa",
      "Hanzhao Lin",
      "Daniel Toyama",
      "Eliza Rutherford",
      "Motoki Sano",
      "HyunJeong Choe",
      "Alex Tomala",
      "Chalence Safranek-Shrader",
      "Nora Kassner",
      "Mantas Pajarskas",
      "Matt Harvey",
      "Sean Sechrist",
      "Meire Fortunato",
      "Christina Lyu",
      "Gamaleldin Elsayed",
      "Chenkai Kuang",
      "James Lottes",
      "Eric Chu",
      "Chao Jia",
      "Chih-Wei Chen",
      "Peter Humphreys",
      "Kate Baumli",
      "Connie Tao",
      "Rajkumar Samuel",
      "Cicero Nogueira dos Santos",
      "Anders Andreassen",
      "Nemanja Rakićević",
      "Dominik Grewe",
      "Aviral Kumar",
      "Stephanie Winkler",
      "Jonathan Caton",
      "Andrew Brock",
      "Sid Dalmia",
      "Hannah Sheahan",
      "Iain Barr",
      "Yingjie Miao",
      "Paul Natsev",
      "Jacob Devlin",
      "Feryal Behbahani",
      "Flavien Prost",
      "Yanhua Sun",
      "Artiom Myaskovsky",
      "Thanumalayan Sankaranarayana Pillai",
      "Dan Hurt",
      "Angeliki Lazaridou",
      "Xi Xiong",
      "Ce Zheng",
      "Fabio Pardo",
      "Xiaowei Li",
      "Dan Horgan",
      "Joe Stanton",
      "Moran Ambar",
      "Fei Xia",
      "Alejandro Lince",
      "Mingqiu Wang",
      "Basil Mustafa",
      "Albert Webson",
      "Hyo Lee",
      "Rohan Anil",
      "Martin Wicke",
      "Timothy Dozat",
      "Abhishek Sinha",
      "Enrique Piqueras",
      "Elahe Dabir",
      "Shyam Upadhyay",
      "Anudhyan Boral",
      "Lisa Anne Hendricks",
      "Corey Fry",
      "Josip Djolonga",
      "Yi Su",
      "Jake Walker",
      "Jane Labanowski",
      "Ronny Huang",
      "Vedant Misra",
      "Jeremy Chen",
      "RJ Skerry-Ryan",
      "Avi Singh",
      "Shruti Rijhwani",
      "Dian Yu",
      "Alex Castro-Ros",
      "Beer Changpinyo",
      "Romina Datta",
      "Sumit Bagri",
      "Arnar Mar Hrafnkelsson",
      "Marcello Maggioni",
      "Daniel Zheng",
      "Yury Sulsky",
      "Shaobo Hou",
      "Tom Le Paine",
      "Antoine Yang",
      "Jason Riesa",
      "Dominika Rogozinska",
      "Dror Marcus",
      "Dalia El Badawy",
      "Qiao Zhang",
      "Luyu Wang",
      "Helen Miller",
      "Jeremy Greer",
      "Lars Lowe Sjos",
      "Azade Nova",
      "Heiga Zen",
      "Rahma Chaabouni",
      "Mihaela Rosca",
      "Jiepu Jiang",
      "Charlie Chen",
      "Ruibo Liu",
      "Tara Sainath",
      "Maxim Krikun",
      "Alex Polozov",
      "Jean-Baptiste Lespiau",
      "Josh Newlan",
      "Zeyncep Cankara",
      "Soo Kwak",
      "Yunhan Xu",
      "Phil Chen",
      "Andy Coenen",
      "Clemens Meyer",
      "Katerina Tsihlas",
      "Ada Ma",
      "Juraj Gottweis",
      "Jinwei Xing",
      "Chenjie Gu",
      "Jin Miao",
      "Christian Frank",
      "Zeynep Cankara",
      "Sanjay Ganapathy",
      "Ishita Dasgupta",
      "Steph Hughes-Fitt",
      "Heng Chen",
      "David Reid",
      "Keran Rong",
      "Hongmin Fan",
      "Joost van Amersfoort",
      "Vincent Zhuang",
      "Aaron Cohen",
      "Shixiang Shane Gu",
      "Anhad Mohananey",
      "Anastasija Ilic",
      "Taylor Tobin",
      "John Wieting",
      "Anna Bortsova",
      "Phoebe Thacker",
      "Emma Wang",
      "Emily Caveness",
      "Justin Chiu",
      "Eren Sezener",
      "Alex Kaskasoli",
      "Steven Baker",
      "Katie Millican",
      "Mohamed Elhawaty",
      "Kostas Aisopos",
      "Carl Lebsack",
      "Nathan Byrd",
      "Hanjun Dai",
      "Wenhao Jia",
      "Matthew Wiethoff",
      "Elnaz Davoodi",
      "Albert Weston",
      "Lakshman Yagati",
      "Arun Ahuja",
      "Isabel Gao",
      "Golan Pundak",
      "Susan Zhang",
      "Michael Azzam",
      "Khe Chai Sim",
      "Sergi Caelles",
      "James Keeling",
      "Abhanshu Sharma",
      "Andy Swing",
      "YaGuang Li",
      "Chenxi Liu",
      "Carrie Grimes Bostock",
      "Yamini Bansal",
      "Zachary Nado",
      "Ankesh Anand",
      "Josh Lipschultz",
      "Abhijit Karmarkar",
      "Lev Proleev",
      "Abe Ittycheriah",
      "Soheil Hassas Yeganeh",
      "George Polovets",
      "Aleksandra Faust",
      "Jiao Sun",
      "Alban Rrustemi",
      "Pen Li",
      "Rakesh Shivanna",
      "Jeremiah Liu",
      "Chris Welty",
      "Federico Lebron",
      "Anirudh Baddepudi",
      "Sebastian Krause",
      "Emilio Parisotto",
      "Radu Soricut",
      "Zheng Xu",
      "Dawn Bloxwich",
      "Melvin Johnson",
      "Behnam Neyshabur",
      "Justin Mao-Jones",
      "Renshen Wang",
      "Vinay Ramasesh",
      "Zaheer Abbas",
      "Arthur Guez",
      "Constant Segal",
      "Duc Dung Nguyen",
      "James Svensson",
      "Le Hou",
      "Sarah York",
      "Kieran Milan",
      "Sophie Bridgers",
      "Wiktor Gworek",
      "Marco Tagliasacchi",
      "James Lee-Thorp",
      "Michael Chang",
      "Alexey Guseynov",
      "Ale Jakse Hartman",
      "Michael Kwong",
      "Ruizhe Zhao",
      "Sheleem Kashem",
      "Elizabeth Cole",
      "Antoine Miech",
      "Richard Tanburn",
      "Mary Phuong",
      "Filip Pavetic",
      "Sebastien Cevey",
      "Ramona Comanescu",
      "Richard Ives",
      "Sherry Yang",
      "Cosmo Du",
      "Bo Li",
      "Zizhao Zhang",
      "Mariko Iinuma",
      "Clara Huiyi Hu",
      "Aurko Roy",
      "Shaan Bijwadia",
      "Zhenkai Zhu",
      "Danilo Martins",
      "Rachel Saputro",
      "Anita Gergely",
      "Steven Zheng",
      "Dawei Jia",
      "Ioannis Antonoglou",
      "Adam Sadovsky",
      "Shane Gu",
      "Yingying Bi",
      "Alek Andreev",
      "Sina Samangooei",
      "Mina Khan",
      "Tomas Kocisky",
      "Angelos Filos",
      "Chintu Kumar",
      "Colton Bishop",
      "Adams Yu",
      "Sarah Hodkinson",
      "Sid Mittal",
      "Premal Shah",
      "Alexandre Moufarek",
      "Yong Cheng",
      "Adam Bloniarz",
      "Jaehoon Lee",
      "Pedram Pejman",
      "Paul Michel",
      "Stephen Spencer",
      "Vladimir Feinberg",
      "Xuehan Xiong",
      "Nikolay Savinov",
      "Charlotte Smith",
      "Siamak Shakeri",
      "Dustin Tran",
      "Mary Chesus",
      "Bernd Bohnet",
      "George Tucker",
      "Tamara von Glehn",
      "Carrie Muir",
      "Yiran Mao",
      "Hideto Kazawa",
      "Ambrose Slone",
      "Kedar Soparkar",
      "Disha Shrivastava",
      "James Cobon-Kerr",
      "Michael Sharman",
      "Jay Pavagadhi",
      "Carlos Araya",
      "Karolis Misiunas",
      "Nimesh Ghelani",
      "Michael Laskin",
      "David Barker",
      "Qiujia Li",
      "Anton Briukhov",
      "Neil Houlsby",
      "Mia Glaese",
      "Balaji Lakshminarayanan",
      "Nathan Schucher",
      "Yunhao Tang",
      "Eli Collins",
      "Hyeontaek Lim",
      "Fangxiaoyu Feng",
      "Adria Recasens",
      "Guangda Lai",
      "Alberto Magni",
      "Nicola De Cao",
      "Aditya Siddhant",
      "Zoe Ashwood",
      "Jordi Orbay",
      "Mostafa Dehghani",
      "Jenny Brennan",
      "Yifan He",
      "Kelvin Xu",
      "Yang Gao",
      "Carl Saroufim",
      "James Molloy",
      "Xinyi Wu",
      "Seb Arnold",
      "Solomon Chang",
      "Julian Schrittwieser",
      "Elena Buchatskaya",
      "Soroush Radpour",
      "Martin Polacek",
      "Skye Giordano",
      "Ankur Bapna",
      "Simon Tokumine",
      "Vincent Hellendoorn",
      "Thibault Sottiaux",
      "Sarah Cogan",
      "Aliaksei Severyn",
      "Mohammad Saleh",
      "Shantanu Thakoor",
      "Laurent Shefey",
      "Siyuan Qiao",
      "Meenu Gaba",
      "Shuo-yiin Chang",
      "Craig Swanson",
      "Biao Zhang",
      "Benjamin Lee",
      "Paul Kishan Rubenstein",
      "Gan Song",
      "Tom Kwiatkowski",
      "Anna Koop",
      "Ajay Kannan",
      "David Kao",
      "Parker Schuh",
      "Axel Stjerngren",
      "Golnaz Ghiasi",
      "Gena Gibson",
      "Luke Vilnis",
      "Ye Yuan",
      "Felipe Tiengo Ferreira",
      "Aishwarya Kamath",
      "Ted Klimenko",
      "Ken Franko",
      "Kefan Xiao",
      "Indro Bhattacharya",
      "Miteyan Patel",
      "Rui Wang",
      "Alex Morris",
      "Robin Strudel",
      "Vivek Sharma",
      "Peter Choy",
      "Sayed Hadi Hashemi",
      "Jessica Landon",
      "Mara Finkelstein",
      "Priya Jhakra",
      "Justin Frye",
      "Megan Barnes",
      "Matthew Mauger",
      "Dennis Daun",
      "Khuslen Baatarsukh",
      "Matthew Tung",
      "Wael Farhan",
      "Henryk Michalewski",
      "Fabio Viola",
      "Felix de Chaumont Quitry",
      "Charline Le Lan",
      "Tom Hudson",
      "Qingze Wang",
      "Felix Fischer",
      "Ivy Zheng",
      "Elspeth White",
      "Anca Dragan",
      "Jean-baptiste Alayrac",
      "Eric Ni",
      "Alexander Pritzel",
      "Adam Iwanicki",
      "Michael Isard",
      "Anna Bulanova",
      "Lukas Zilka",
      "Ethan Dyer",
      "Devendra Sachan",
      "Srivatsan Srinivasan",
      "Hannah Muckenhirn",
      "Honglong Cai",
      "Amol Mandhane",
      "Mukarram Tariq",
      "Jack W. Rae",
      "Gary Wang",
      "Kareem Ayoub",
      "Nicholas FitzGerald",
      "Yao Zhao",
      "Woohyun Han",
      "Chris Alberti",
      "Dan Garrette",
      "Kashyap Krishnakumar",
      "Mai Gimenez",
      "Anselm Levskaya",
      "Daniel Sohn",
      "Josip Matak",
      "Inaki Iturrate",
      "Michael B. Chang",
      "Jackie Xiang",
      "Yuan Cao",
      "Nishant Ranka",
      "Geoff Brown",
      "Adrian Hutter",
      "Vahab Mirrokni",
      "Nanxin Chen",
      "Kaisheng Yao",
      "Zoltan Egyed",
      "Francois Galilee",
      "Tyler Liechty",
      "Praveen Kallakuri",
      "Evan Palmer",
      "Sanjay Ghemawat",
      "Jasmine Liu",
      "David Tao",
      "Chloe Thornton",
      "Tim Green",
      "Mimi Jasarevic",
      "Sharon Lin",
      "Victor Cotruta",
      "Yi-Xuan Tan",
      "Noah Fiedel",
      "Hongkun Yu",
      "Ed Chi",
      "Alexander Neitz",
      "Jens Heitkaemper",
      "Anu Sinha",
      "Denny Zhou",
      "Yi Sun",
      "Charbel Kaed",
      "Brice Hulse",
      "Swaroop Mishra",
      "Maria Georgaki",
      "Sneha Kudugunta",
      "Clement Farabet",
      "Izhak Shafran",
      "Daniel Vlasic",
      "Anton Tsitsulin",
      "Rajagopal Ananthanarayanan",
      "Alen Carin",
      "Guolong Su",
      "Pei Sun",
      "Shashank V",
      "Gabriel Carvajal",
      "Josef Broder",
      "Iulia Comsa",
      "Alena Repina",
      "William Wong",
      "Warren Weilun Chen",
      "Peter Hawkins",
      "Egor Filonov",
      "Lucia Loher",
      "Christoph Hirnschall",
      "Weiyi Wang",
      "Jingchen Ye",
      "Andrea Burns",
      "Hardie Cate",
      "Diana Gage Wright",
      "Federico Piccinini",
      "Lei Zhang",
      "Chu-Cheng Lin",
      "Ionel Gog",
      "Yana Kulizhskaya",
      "Ashwin Sreevatsa",
      "Shuang Song",
      "Luis C. Cobo",
      "Anand Iyer",
      "Chetan Tekur",
      "Guillermo Garrido",
      "Zhuyun Xiao",
      "Rupert Kemp",
      "Huaixiu Steven Zheng",
      "Hui Li",
      "Ananth Agarwal",
      "Christel Ngani",
      "Kati Goshvadi",
      "Rebeca Santamaria-Fernandez",
      "Wojciech Fica",
      "Xinyun Chen",
      "Chris Gorgolewski",
      "Sean Sun",
      "Roopal Garg",
      "Xinyu Ye",
      "S. M. Ali Eslami",
      "Nan Hua",
      "Jon Simon",
      "Pratik Joshi",
      "Yelin Kim",
      "Ian Tenney",
      "Sahitya Potluri",
      "Lam Nguyen Thiet",
      "Quan Yuan",
      "Florian Luisier",
      "Alexandra Chronopoulou",
      "Salvatore Scellato",
      "Praveen Srinivasan",
      "Minmin Chen",
      "Vinod Koverkathu",
      "Valentin Dalibard",
      "Yaming Xu",
      "Brennan Saeta",
      "Keith Anderson",
      "Thibault Sellam",
      "Nick Fernando",
      "Fantine Huot",
      "Junehyuk Jung",
      "Mani Varadarajan",
      "Michael Quinn",
      "Amit Raul",
      "Maigo Le",
      "Ruslan Habalov",
      "Jon Clark",
      "Komal Jalan",
      "Kalesha Bullard",
      "Achintya Singhal",
      "Thang Luong",
      "Boyu Wang",
      "Sujeevan Rajayogam",
      "Julian Eisenschlos",
      "Johnson Jia",
      "Daniel Finchelstein",
      "Alex Yakubovich",
      "Daniel Balle",
      "Michael Fink",
      "Sameer Agarwal",
      "Jing Li",
      "Dj Dvijotham",
      "Shalini Pal",
      "Kai Kang",
      "Jaclyn Konzelmann",
      "Jennifer Beattie",
      "Olivier Dousse",
      "Diane Wu",
      "Remi Crocker",
      "Chen Elkind",
      "Siddhartha Reddy Jonnalagadda",
      "Jong Lee",
      "Dan Holtmann-Rice",
      "Krystal Kallarackal",
      "Rosanne Liu",
      "Denis Vnukov",
      "Neera Vats",
      "Luca Invernizzi",
      "Mohsen Jafari",
      "Huanjie Zhou",
      "Lilly Taylor",
      "Jennifer Prendki",
      "Marcus Wu",
      "Tom Eccles",
      "Tianqi Liu",
      "Kavya Kopparapu",
      "Francoise Beaufays",
      "Christof Angermueller",
      "Andreea Marzoca",
      "Shourya Sarcar",
      "Hilal Dib",
      "Jeff Stanway",
      "Frank Perbet",
      "Nejc Trdin",
      "Rachel Sterneck",
      "Andrey Khorlin",
      "Dinghua Li",
      "Xihui Wu",
      "Sonam Goenka",
      "David Madras",
      "Sasha Goldshtein",
      "Willi Gierke",
      "Tong Zhou",
      "Yaxin Liu",
      "Yannie Liang",
      "Anais White",
      "Yunjie Li",
      "Shreya Singh",
      "Sanaz Bahargam",
      "Mark Epstein",
      "Sujoy Basu",
      "Li Lao",
      "Adnan Ozturel",
      "Carl Crous",
      "Alex Zhai",
      "Han Lu",
      "Zora Tung",
      "Neeraj Gaur",
      "Alanna Walton",
      "Lucas Dixon",
      "Ming Zhang",
      "Amir Globerson",
      "Grant Uy",
      "Andrew Bolt",
      "Olivia Wiles",
      "Milad Nasr",
      "Ilia Shumailov",
      "Marco Selvi",
      "Francesco Piccinno",
      "Ricardo Aguilar",
      "Sara McCarthy",
      "Misha Khalman",
      "Mrinal Shukla",
      "Vlado Galic",
      "John Carpenter",
      "Kevin Villela",
      "Haibin Zhang",
      "Harry Richardson",
      "James Martens",
      "Matko Bosnjak",
      "Shreyas Rammohan Belle",
      "Jeff Seibert",
      "Mahmoud Alnahlawi",
      "Brian McWilliams",
      "Sankalp Singh",
      "Annie Louis",
      "Wen Ding",
      "Dan Popovici",
      "Lenin Simicich",
      "Laura Knight",
      "Pulkit Mehta",
      "Nishesh Gupta",
      "Chongyang Shi",
      "Saaber Fatehi",
      "Jovana Mitrovic",
      "Alex Grills",
      "Joseph Pagadora",
      "Tsendsuren Munkhdalai",
      "Dessie Petrova",
      "Danielle Eisenbud",
      "Zhishuai Zhang",
      "Damion Yates",
      "Bhavishya Mittal",
      "Nilesh Tripuraneni",
      "Yannis Assael",
      "Thomas Brovelli",
      "Prateek Jain",
      "Mihajlo Velimirovic",
      "Canfer Akbulut",
      "Jiaqi Mu",
      "Wolfgang Macherey",
      "Ravin Kumar",
      "Jun Xu",
      "Haroon Qureshi",
      "Gheorghe Comanici",
      "Jeremy Wiesner",
      "Zhitao Gong",
      "Anton Ruddock",
      "Matthias Bauer",
      "Nick Felt",
      "Anirudh GP",
      "Anurag Arnab",
      "Dustin Zelle",
      "Jonas Rothfuss",
      "Bill Rosgen",
      "Ashish Shenoy",
      "Bryan Seybold",
      "Xinjian Li",
      "Jayaram Mudigonda",
      "Goker Erdogan",
      "Jiawei Xia",
      "Jiri Simsa",
      "Andrea Michi",
      "Yi Yao",
      "Christopher Yew",
      "Steven Kan",
      "Isaac Caswell",
      "Carey Radebaugh",
      "Andre Elisseeff",
      "Pedro Valenzuela",
      "Kay McKinney",
      "Kim Paterson",
      "Albert Cui",
      "Eri Latorre-Chimoto",
      "Solomon Kim",
      "William Zeng",
      "Ken Durden",
      "Priya Ponnapalli",
      "Tiberiu Sosea",
      "Christopher A. Choquette-Choo",
      "James Manyika",
      "Brona Robenek",
      "Harsha Vashisht",
      "Sebastien Pereira",
      "Hoi Lam",
      "Marko Velic",
      "Denese Owusu-Afriyie",
      "Katherine Lee",
      "Tolga Bolukbasi",
      "Alicia Parrish",
      "Shawn Lu",
      "Jane Park",
      "Balaji Venkatraman",
      "Alice Talbert",
      "Lambert Rosique",
      "Yuchung Cheng",
      "Andrei Sozanschi",
      "Adam Paszke",
      "Praveen Kumar",
      "Jessica Austin",
      "Lu Li",
      "Khalid Salama",
      "Bartek Perz",
      "Wooyeol Kim",
      "Nandita Dukkipati",
      "Anthony Baryshnikov",
      "Christos Kaplanis",
      "XiangHai Sheng",
      "Yuri Chervonyi",
      "Caglar Unlu",
      "Diego de Las Casas",
      "Harry Askham",
      "Kathryn Tunyasuvunakool",
      "Felix Gimeno",
      "Siim Poder",
      "Chester Kwak",
      "Matt Miecnikowski",
      "Vahab Mirrokni",
      "Alek Dimitriev",
      "Aaron Parisi",
      "Dangyi Liu",
      "Tomy Tsai",
      "Toby Shevlane",
      "Christina Kouridi",
      "Drew Garmon",
      "Adrian Goedeckemeyer",
      "Adam R. Brown",
      "Anitha Vijayakumar",
      "Ali Elqursh",
      "Sadegh Jazayeri",
      "Jin Huang",
      "Sara Mc Carthy",
      "Jay Hoover",
      "Lucy Kim",
      "Sandeep Kumar",
      "Wei Chen",
      "Courtney Biles",
      "Garrett Bingham",
      "Evan Rosen",
      "Lisa Wang",
      "Qijun Tan",
      "David Engel",
      "Francesco Pongetti",
      "Dario de Cesare",
      "Dongseong Hwang",
      "Lily Yu",
      "Jennifer Pullman",
      "Srini Narayanan",
      "Kyle Levin",
      "Siddharth Gopal",
      "Megan Li",
      "Asaf Aharoni",
      "Trieu Trinh",
      "Jessica Lo",
      "Norman Casagrande",
      "Roopali Vij",
      "Loic Matthey",
      "Bramandia Ramadhana",
      "Austin Matthews",
      "CJ Carey",
      "Matthew Johnson",
      "Kremena Goranova",
      "Rohin Shah",
      "Shereen Ashraf",
      "Kingshuk Dasgupta",
      "Rasmus Larsen",
      "Yicheng Wang",
      "Manish Reddy Vuyyuru",
      "Chong Jiang",
      "Joana Ijazi",
      "Kazuki Osawa",
      "Celine Smith",
      "Ramya Sree Boppana",
      "Taylan Bilal",
      "Yuma Koizumi",
      "Ying Xu",
      "Yasemin Altun",
      "Nir Shabat",
      "Ben Bariach",
      "Alex Korchemniy",
      "Kiam Choo",
      "Olaf Ronneberger",
      "Chimezie Iwuanyanwu",
      "Shubin Zhao",
      "David Soergel",
      "Cho-Jui Hsieh",
      "Irene Cai",
      "Shariq Iqbal",
      "Martin Sundermeyer",
      "Zhe Chen",
      "Elie Bursztein",
      "Chaitanya Malaviya",
      "Fadi Biadsy",
      "Prakash Shroff",
      "Inderjit Dhillon",
      "Tejasi Latkar",
      "Chris Dyer",
      "Hannah Forbes",
      "Massimo Nicosia",
      "Vitaly Nikolaev",
      "Somer Greene",
      "Marin Georgiev",
      "Pidong Wang",
      "Nina Martin",
      "Hanie Sedghi",
      "John Zhang",
      "Praseem Banzal",
      "Doug Fritz",
      "Vikram Rao",
      "Xuezhi Wang",
      "Jiageng Zhang",
      "Viorica Patraucean",
      "Dayou Du",
      "Igor Mordatch",
      "Ivan Jurin",
      "Lewis Liu",
      "Ayush Dubey",
      "Abhi Mohan",
      "Janek Nowakowski",
      "Vlad-Doru Ion",
      "Nan Wei",
      "Reiko Tojo",
      "Maria Abi Raad",
      "Drew A. Hudson",
      "Vaishakh Keshava",
      "Shubham Agrawal",
      "Kevin Ramirez",
      "Zhichun Wu",
      "Hoang Nguyen",
      "Ji Liu",
      "Madhavi Sewak",
      "Bryce Petrini",
      "DongHyun Choi",
      "Ivan Philips",
      "Ziyue Wang",
      "Ioana Bica",
      "Ankush Garg",
      "Jarek Wilkiewicz",
      "Priyanka Agrawal",
      "Xiaowei Li",
      "Danhao Guo",
      "Emily Xue",
      "Naseer Shaik",
      "Andrew Leach",
      "Sadh MNM Khan",
      "Julia Wiesinger",
      "Sammy Jerome",
      "Abhishek Chakladar",
      "Alek Wenjiao Wang",
      "Tina Ornduff",
      "Folake Abu",
      "Alireza Ghaffarkhah",
      "Marcus Wainwright",
      "Mario Cortes",
      "Frederick Liu",
      "Joshua Maynez",
      "Andreas Terzis",
      "Pouya Samangouei",
      "Riham Mansour",
      "Tomasz Kępa",
      "François-Xavier Aubet",
      "Anton Algymr",
      "Dan Banica",
      "Agoston Weisz",
      "Andras Orban",
      "Alexandre Senges",
      "Ewa Andrejczuk",
      "Mark Geller",
      "Niccolo Dal Santo",
      "Valentin Anklin",
      "Majd Al Merey",
      "Martin Baeuml",
      "Trevor Strohman",
      "Junwen Bai",
      "Slav Petrov",
      "Yonghui Wu",
      "Demis Hassabis",
      "Koray Kavukcuoglu",
      "Jeff Dean",
      "Oriol Vinyals"
    ],
    "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing\nthe next generation of highly compute-efficient multimodal models capable of\nrecalling and reasoning over fine-grained information from millions of tokens\nof context, including multiple long documents and hours of video and audio. The\nfamily includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds\nthe February version on the great majority of capabilities and benchmarks; (2)\nGemini 1.5 Flash, a more lightweight variant designed for efficiency with\nminimal regression in quality. Gemini 1.5 models achieve near-perfect recall on\nlong-context retrieval tasks across modalities, improve the state-of-the-art in\nlong-document QA, long-video QA and long-context ASR, and match or surpass\nGemini 1.0 Ultra's state-of-the-art performance across a broad set of\nbenchmarks. Studying the limits of Gemini 1.5's long-context ability, we find\ncontinued improvement in next-token prediction and near-perfect retrieval\n(>99%) up to at least 10M tokens, a generational leap over existing models such\nas Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world\nuse cases, such as Gemini 1.5 collaborating with professionals on completing\ntheir tasks achieving 26 to 75% time savings across 10 different job\ncategories, as well as surprising new capabilities of large language models at\nthe frontier; when given a grammar manual for Kalamang, a language with fewer\nthan 200 speakers worldwide, the model learns to translate English to Kalamang\nat a similar level to a person who learned from the same content.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05530v5",
    "published_date": "2024-03-08 18:54:20 UTC",
    "updated_date": "2024-12-16 17:39:39 UTC"
  },
  {
    "arxiv_id": "2403.05527v4",
    "title": "GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM",
    "authors": [
      "Hao Kang",
      "Qingru Zhang",
      "Souvik Kundu",
      "Geonhwa Jeong",
      "Zaoxing Liu",
      "Tushar Krishna",
      "Tuo Zhao"
    ],
    "abstract": "Key-value (KV) caching has become the de-facto to accelerate generation speed\nfor large language models (LLMs) inference. However, the growing cache demand\nwith increasing sequence length has transformed LLM inference to be a memory\nbound problem, significantly constraining the system throughput. Existing\nmethods rely on dropping unimportant tokens or quantizing all entries\nuniformly. Such methods, however, often incur high approximation errors to\nrepresent the compressed matrices. The autoregressive decoding process further\ncompounds the error of each step, resulting in critical deviation in model\ngeneration and deterioration of performance. To tackle this challenge, we\npropose GEAR, an efficient KV cache compression framework that achieves\nnear-lossless high-ratio compression. GEAR first applies quantization to\nmajority of entries of similar magnitudes to ultra-low precision. It then\nemploys a low rank matrix to approximate the quantization error, and a sparse\nmatrix to remedy individual errors from outlier entries. By adeptly integrating\nthree techniques, GEAR is able to fully exploit their synergistic potentials.\nOur experiments demonstrate that compared to alternatives, GEAR achieves\nnear-lossless 4-bit KV cache compression with up to 2.38x throughput\nimprovement, while reducing peak-memory size up to 2.29x. Our code is publicly\navailable at https://github.com/HaoKang-Timmy/GEAR.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05527v4",
    "published_date": "2024-03-08 18:48:30 UTC",
    "updated_date": "2024-09-30 22:44:58 UTC"
  },
  {
    "arxiv_id": "2403.05525v2",
    "title": "DeepSeek-VL: Towards Real-World Vision-Language Understanding",
    "authors": [
      "Haoyu Lu",
      "Wen Liu",
      "Bo Zhang",
      "Bingxuan Wang",
      "Kai Dong",
      "Bo Liu",
      "Jingxiang Sun",
      "Tongzheng Ren",
      "Zhuoshu Li",
      "Hao Yang",
      "Yaofeng Sun",
      "Chengqi Deng",
      "Hanwei Xu",
      "Zhenda Xie",
      "Chong Ruan"
    ],
    "abstract": "We present DeepSeek-VL, an open-source Vision-Language (VL) Model designed\nfor real-world vision and language understanding applications. Our approach is\nstructured around three key dimensions:\n  We strive to ensure our data is diverse, scalable, and extensively covers\nreal-world scenarios including web screenshots, PDFs, OCR, charts, and\nknowledge-based content, aiming for a comprehensive representation of practical\ncontexts. Further, we create a use case taxonomy from real user scenarios and\nconstruct an instruction tuning dataset accordingly. The fine-tuning with this\ndataset substantially improves the model's user experience in practical\napplications. Considering efficiency and the demands of most real-world\nscenarios, DeepSeek-VL incorporates a hybrid vision encoder that efficiently\nprocesses high-resolution images (1024 x 1024), while maintaining a relatively\nlow computational overhead. This design choice ensures the model's ability to\ncapture critical semantic and detailed information across various visual tasks.\nWe posit that a proficient Vision-Language Model should, foremost, possess\nstrong language abilities. To ensure the preservation of LLM capabilities\nduring pretraining, we investigate an effective VL pretraining strategy by\nintegrating LLM training from the beginning and carefully managing the\ncompetitive dynamics observed between vision and language modalities.\n  The DeepSeek-VL family (both 1.3B and 7B models) showcases superior user\nexperiences as a vision-language chatbot in real-world applications, achieving\nstate-of-the-art or competitive performance across a wide range of\nvisual-language benchmarks at the same model size while maintaining robust\nperformance on language-centric benchmarks. We have made both 1.3B and 7B\nmodels publicly accessible to foster innovations based on this foundation\nmodel.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "https://github.com/deepseek-ai/DeepSeek-VL",
    "pdf_url": "http://arxiv.org/pdf/2403.05525v2",
    "published_date": "2024-03-08 18:46:00 UTC",
    "updated_date": "2024-03-11 16:47:41 UTC"
  },
  {
    "arxiv_id": "2403.05518v1",
    "title": "Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought",
    "authors": [
      "James Chua",
      "Edward Rees",
      "Hunar Batra",
      "Samuel R. Bowman",
      "Julian Michael",
      "Ethan Perez",
      "Miles Turpin"
    ],
    "abstract": "While chain-of-thought prompting (CoT) has the potential to improve the\nexplainability of language model reasoning, it can systematically misrepresent\nthe factors influencing models' behavior--for example, rationalizing answers in\nline with a user's opinion without mentioning this bias. To mitigate this\nbiased reasoning problem, we introduce bias-augmented consistency training\n(BCT), an unsupervised fine-tuning scheme that trains models to give consistent\nreasoning across prompts with and without biasing features. We construct a\nsuite testing nine forms of biased reasoning on seven question-answering tasks,\nand find that applying BCT to GPT-3.5-Turbo with one bias reduces the rate of\nbiased reasoning by 86% on held-out tasks. Moreover, this model generalizes to\nother forms of bias, reducing biased reasoning on held-out biases by an average\nof 37%. As BCT generalizes to held-out biases and does not require gold labels,\nthis method may hold promise for reducing biased reasoning from as-of-yet\nunknown biases and on tasks where supervision for ground truth reasoning is\nunavailable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05518v1",
    "published_date": "2024-03-08 18:41:42 UTC",
    "updated_date": "2024-03-08 18:41:42 UTC"
  },
  {
    "arxiv_id": "2403.05612v2",
    "title": "Unfamiliar Finetuning Examples Control How Language Models Hallucinate",
    "authors": [
      "Katie Kang",
      "Eric Wallace",
      "Claire Tomlin",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "abstract": "Large language models are known to hallucinate when faced with unfamiliar\nqueries, but the underlying mechanism that govern how models hallucinate are\nnot yet fully understood. In this work, we find that unfamiliar examples in the\nmodels' finetuning data -- those that introduce concepts beyond the base\nmodel's scope of knowledge -- are crucial in shaping these errors. In\nparticular, we find that an LLM's hallucinated predictions tend to mirror the\nresponses associated with its unfamiliar finetuning examples. This suggests\nthat by modifying how unfamiliar finetuning examples are supervised, we can\ninfluence a model's responses to unfamiliar queries (e.g., say ``I don't\nknow''). We empirically validate this observation in a series of controlled\nexperiments involving SFT, RL, and reward model finetuning on TriviaQA and\nMMLU. Our work further investigates RL finetuning strategies for improving the\nfactuality of long-form model generations. We find that, while hallucinations\nfrom the reward model can significantly undermine the effectiveness of RL\nfactuality finetuning, strategically controlling how reward models hallucinate\ncan minimize these negative effects. Leveraging our previous observations on\ncontrolling hallucinations, we propose an approach for learning more reliable\nreward models, and show that they improve the efficacy of RL factuality\nfinetuning in long-form biography and book/movie plot generation tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05612v2",
    "published_date": "2024-03-08 18:28:13 UTC",
    "updated_date": "2024-05-28 23:56:14 UTC"
  },
  {
    "arxiv_id": "2403.05490v1",
    "title": "Poly-View Contrastive Learning",
    "authors": [
      "Amitis Shidani",
      "Devon Hjelm",
      "Jason Ramapuram",
      "Russ Webb",
      "Eeshan Gunesh Dhekane",
      "Dan Busbridge"
    ],
    "abstract": "Contrastive learning typically matches pairs of related views among a number\nof unrelated negative views. Views can be generated (e.g. by augmentations) or\nbe observed. We investigate matching when there are more than two related views\nwhich we call poly-view tasks, and derive new representation learning\nobjectives using information maximization and sufficient statistics. We show\nthat with unlimited computation, one should maximize the number of related\nviews, and with a fixed compute budget, it is beneficial to decrease the number\nof unique samples whilst increasing the number of views of those samples. In\nparticular, poly-view contrastive models trained for 128 epochs with batch size\n256 outperform SimCLR trained for 1024 epochs at batch size 4096 on ImageNet1k,\nchallenging the belief that contrastive models require large batch sizes and\nmany training epochs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2024. 42 pages, 7 figures, 3 tables, loss\n  pseudo-code included in appendix",
    "pdf_url": "http://arxiv.org/pdf/2403.05490v1",
    "published_date": "2024-03-08 17:55:41 UTC",
    "updated_date": "2024-03-08 17:55:41 UTC"
  },
  {
    "arxiv_id": "2403.05468v1",
    "title": "Will GPT-4 Run DOOM?",
    "authors": [
      "Adrian de Wynter"
    ],
    "abstract": "We show that GPT-4's reasoning and planning capabilities extend to the 1993\nfirst-person shooter Doom. This large language model (LLM) is able to run and\nplay the game with only a few instructions, plus a textual\ndescription--generated by the model itself from screenshots--about the state of\nthe game being observed. We find that GPT-4 can play the game to a passable\ndegree: it is able to manipulate doors, combat enemies, and perform pathing.\nMore complex prompting strategies involving multiple model calls provide better\nresults. While further work is required to enable the LLM to play the game as\nwell as its classical, reinforcement learning-based counterparts, we note that\nGPT-4 required no training, leaning instead on its own reasoning and\nobservational capabilities. We hope our work pushes the boundaries on\nintelligent, LLM-based agents in video games. We conclude by discussing the\nethical implications of our work.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05468v1",
    "published_date": "2024-03-08 17:30:41 UTC",
    "updated_date": "2024-03-08 17:30:41 UTC"
  },
  {
    "arxiv_id": "2403.05465v2",
    "title": "Algorithm-Hardware Co-Design of Distribution-Aware Logarithmic-Posit Encodings for Efficient DNN Inference",
    "authors": [
      "Akshat Ramachandran",
      "Zishen Wan",
      "Geonhwa Jeong",
      "John Gustafson",
      "Tushar Krishna"
    ],
    "abstract": "Traditional Deep Neural Network (DNN) quantization methods using integer,\nfixed-point, or floating-point data types struggle to capture diverse DNN\nparameter distributions at low precision, and often require large silicon\noverhead and intensive quantization-aware training. In this study, we introduce\nLogarithmic Posits (LP), an adaptive, hardware-friendly data type inspired by\nposits that dynamically adapts to DNN weight/activation distributions by\nparameterizing LP bit fields. We also develop a novel genetic-algorithm based\nframework, LP Quantization (LPQ), to find optimal layer-wise LP parameters\nwhile reducing representational divergence between quantized and full-precision\nmodels through a novel global-local contrastive objective. Additionally, we\ndesign a unified mixed-precision LP accelerator (LPA) architecture comprising\nof processing elements (PEs) incorporating LP in the computational datapath.\nOur algorithm-hardware co-design demonstrates on average <1% drop in top-1\naccuracy across various CNN and ViT models. It also achieves ~ 2x improvements\nin performance per unit area and 2.2x gains in energy efficiency compared to\nstate-of-the-art quantization accelerators using different data types.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AR",
    "comment": "2024 61st IEEE/ACM Design Automation Conference (DAC)",
    "pdf_url": "http://arxiv.org/pdf/2403.05465v2",
    "published_date": "2024-03-08 17:28:49 UTC",
    "updated_date": "2024-03-26 18:43:35 UTC"
  },
  {
    "arxiv_id": "2403.05407v2",
    "title": "Algorithmic Identification of Essential Exogenous Nodes for Causal Sufficiency in Brain Networks",
    "authors": [
      "Abdolmahdi Bagheri",
      "Mahdi Dehshiri",
      "Babak Nadjar Araabi",
      "Alireza Akhondi Asl"
    ],
    "abstract": "In the investigation of any causal mechanisms, such as the brain's causal\nnetworks, the assumption of causal sufficiency plays a critical role. Notably,\nneglecting this assumption can result in significant errors, a fact that is\noften disregarded in the causal analysis of brain networks. In this study, we\npropose an algorithmic identification approach for determining essential\nexogenous nodes that satisfy the critical need for causal sufficiency to adhere\nto it in such inquiries. Our approach consists of three main steps: First, by\ncapturing the essence of the Peter-Clark (PC) algorithm, we conduct\nindependence tests for pairs of regions within a network, as well as for the\nsame pairs conditioned on nodes from other networks. Next, we distinguish\ncandidate confounders by analyzing the differences between the conditional and\nunconditional results, using the Kolmogorov-Smirnov test. Subsequently, we\nutilize Non-Factorized identifiable Variational Autoencoders (NF-iVAE) along\nwith the Correlation Coefficient index (CCI) metric to identify the confounding\nvariables within these candidate nodes. Applying our method to the Human\nConnectome Projects (HCP) movie-watching task data, we demonstrate that while\ninteractions exist between dorsal and ventral regions, only dorsal regions\nserve as confounders for the visual networks, and vice versa. These findings\nalign consistently with those resulting from the neuroscientific perspective.\nFinally, we show the reliability of our results by testing 30 independent runs\nfor NF-iVAE initialization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05407v2",
    "published_date": "2024-03-08 16:05:47 UTC",
    "updated_date": "2024-03-15 14:35:35 UTC"
  },
  {
    "arxiv_id": "2403.05406v1",
    "title": "Considering Nonstationary within Multivariate Time Series with Variational Hierarchical Transformer for Forecasting",
    "authors": [
      "Muyao Wang",
      "Wenchao Chen",
      "Bo Chen"
    ],
    "abstract": "The forecasting of Multivariate Time Series (MTS) has long been an important\nbut challenging task. Due to the non-stationary problem across long-distance\ntime steps, previous studies primarily adopt stationarization method to\nattenuate the non-stationary problem of the original series for better\npredictability. However, existing methods always adopt the stationarized\nseries, which ignores the inherent non-stationarity, and has difficulty in\nmodeling MTS with complex distributions due to the lack of stochasticity. To\ntackle these problems, we first develop a powerful hierarchical probabilistic\ngenerative module to consider the non-stationarity and stochastic\ncharacteristics within MTS, and then combine it with transformer for a\nwell-defined variational generative dynamic model named Hierarchical Time\nseries Variational Transformer (HTV-Trans), which recovers the intrinsic\nnon-stationary information into temporal dependencies. Being a powerful\nprobabilistic model, HTV-Trans is utilized to learn expressive representations\nof MTS and applied to forecasting tasks. Extensive experiments on diverse\ndatasets show the efficiency of HTV-Trans on MTS forecasting tasks",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted by AAAI2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05406v1",
    "published_date": "2024-03-08 16:04:36 UTC",
    "updated_date": "2024-03-08 16:04:36 UTC"
  },
  {
    "arxiv_id": "2403.05396v2",
    "title": "HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction",
    "authors": [
      "Zhengrui Guo",
      "Jiabo Ma",
      "Yingxue Xu",
      "Yihui Wang",
      "Liansheng Wang",
      "Hao Chen"
    ],
    "abstract": "Histopathology serves as the gold standard in cancer diagnosis, with clinical\nreports being vital in interpreting and understanding this process, guiding\ncancer treatment and patient care. The automation of histopathology report\ngeneration with deep learning stands to significantly enhance clinical\nefficiency and lessen the labor-intensive, time-consuming burden on\npathologists in report writing. In pursuit of this advancement, we introduce\nHistGen, a multiple instance learning-empowered framework for histopathology\nreport generation together with the first benchmark dataset for evaluation.\nInspired by diagnostic and report-writing workflows, HistGen features two\ndelicately designed modules, aiming to boost report generation by aligning\nwhole slide images (WSIs) and diagnostic reports from local and global\ngranularity. To achieve this, a local-global hierarchical encoder is developed\nfor efficient visual feature aggregation from a region-to-slide perspective.\nMeanwhile, a cross-modal context module is proposed to explicitly facilitate\nalignment and interaction between distinct modalities, effectively bridging the\ngap between the extensive visual sequences of WSIs and corresponding highly\nsummarized reports. Experimental results on WSI report generation show the\nproposed model outperforms state-of-the-art (SOTA) models by a large margin.\nMoreover, the results of fine-tuning our model on cancer subtyping and survival\nanalysis tasks further demonstrate superior performance compared to SOTA\nmethods, showcasing strong transfer learning capability. Dataset, model\nweights, and source code are available in\nhttps://github.com/dddavid4real/HistGen.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by MICCAI2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05396v2",
    "published_date": "2024-03-08 15:51:43 UTC",
    "updated_date": "2024-06-18 05:58:43 UTC"
  },
  {
    "arxiv_id": "2403.05379v2",
    "title": "Self-Supervised Multiple Instance Learning for Acute Myeloid Leukemia Classification",
    "authors": [
      "Salome Kazeminia",
      "Max Joosten",
      "Dragan Bosnacki",
      "Carsten Marr"
    ],
    "abstract": "Automated disease diagnosis using medical image analysis relies on deep\nlearning, often requiring large labeled datasets for supervised model training.\nDiseases like Acute Myeloid Leukemia (AML) pose challenges due to scarce and\ncostly annotations on a single-cell level. Multiple Instance Learning (MIL)\naddresses weakly labeled scenarios but necessitates powerful encoders typically\ntrained with labeled data. In this study, we explore Self-Supervised Learning\n(SSL) as a pre-training approach for MIL-based AML subtype classification from\nblood smears, removing the need for labeled data during encoder training. We\ninvestigate the three state-of-the-art SSL methods SimCLR, SwAV, and DINO, and\ncompare their performance against supervised pre-training. Our findings show\nthat SSL-pretrained encoders achieve comparable performance, showcasing the\npotential of SSL in MIL. This breakthrough offers a cost-effective and\ndata-efficient solution, propelling the field of AI-based disease diagnosis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05379v2",
    "published_date": "2024-03-08 15:16:15 UTC",
    "updated_date": "2024-08-22 21:42:24 UTC"
  },
  {
    "arxiv_id": "2403.05334v2",
    "title": "WatChat: Explaining perplexing programs by debugging mental models",
    "authors": [
      "Kartik Chandra",
      "Katherine M. Collins",
      "Will Crichton",
      "Tony Chen",
      "Tzu-Mao Li",
      "Adrian Weller",
      "Rachit Nigam",
      "Joshua Tenenbaum",
      "Jonathan Ragan-Kelley"
    ],
    "abstract": "Often, a good explanation for a program's unexpected behavior is a bug in the\nprogrammer's code. But sometimes, an even better explanation is a bug in the\nprogrammer's mental model of the language or API they are using. Instead of\nmerely debugging our current code (\"giving the programmer a fish\"), what if our\ntools could directly debug our mental models (\"teaching the programmer to\nfish\")? In this paper, we apply recent ideas from computational cognitive\nscience to offer a principled framework for doing exactly that. Given a \"why?\"\nquestion about a program, we automatically infer potential misconceptions about\nthe language/API that might cause the user to be surprised by the program's\nbehavior -- and then analyze those misconceptions to provide explanations of\nthe program's behavior. Our key idea is to formally represent misconceptions as\ncounterfactual (erroneous) semantics for the language/API, which can be\ninferred and debugged using program synthesis techniques. We demonstrate our\nframework, WatChat, by building systems for explanation in two domains:\nJavaScript type coercion, and the Git version control system. We evaluate\nWatChatJS and WatChatGit by comparing their outputs to experimentally-collected\nhuman-written explanations in these two domains: we show that WatChat's\nexplanations exhibit key features of human-written explanation, unlike those of\na state-of-the-art language model.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.PL",
    "comment": "This is a preprint of work presented in early-stage non-archival form\n  at the ACL Natural Language Reasoning and Structured Explanations Workshop",
    "pdf_url": "http://arxiv.org/pdf/2403.05334v2",
    "published_date": "2024-03-08 14:10:25 UTC",
    "updated_date": "2024-10-02 17:05:24 UTC"
  },
  {
    "arxiv_id": "2403.05326v4",
    "title": "ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in Dialogues",
    "authors": [
      "Yiding Liu",
      "Jingjing Wang",
      "Jiamin Luo",
      "Tao Zeng",
      "Guodong Zhou"
    ],
    "abstract": "Aspect Sentiment Understanding (ASU) in interactive scenarios (e.g.,\nQuestion-Answering and Dialogue) has attracted ever-more interest in recent\nyears and achieved important progresses. However, existing studies on\ninteractive ASU largely ignore the coreference issue for opinion targets (i.e.,\naspects), while this phenomenon is ubiquitous in interactive scenarios\nespecially dialogues, limiting the ASU performance. Recently, large language\nmodels (LLMs) shows the powerful ability to integrate various NLP tasks with\nthe chat paradigm. In this way, this paper proposes a new Chat-based Aspect\nSentiment Understanding (ChatASU) task, aiming to explore LLMs' ability in\nunderstanding aspect sentiments in dialogue scenarios. Particularly, this\nChatASU task introduces a sub-task, i.e., Aspect Chain Reasoning (ACR) task, to\naddress the aspect coreference issue. On this basis, we propose a Trusted\nSelf-reflexion Approach (TSA) with ChatGLM as backbone to ChatASU.\nSpecifically, this TSA treats the ACR task as an auxiliary task to boost the\nperformance of the primary ASU task, and further integrates trusted learning\ninto reflexion mechanisms to alleviate the LLMs-intrinsic factual hallucination\nproblem in TSA. Furthermore, a high-quality ChatASU dataset is annotated to\nevaluate TSA, and extensive experiments show that our proposed TSA can\nsignificantly outperform several state-of-the-art baselines, justifying the\neffectiveness of TSA to ChatASU and the importance of considering the\ncoreference and hallucination issues in ChatASU.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05326v4",
    "published_date": "2024-03-08 14:05:36 UTC",
    "updated_date": "2024-04-10 13:08:07 UTC"
  },
  {
    "arxiv_id": "2403.05318v1",
    "title": "Looking Ahead to Avoid Being Late: Solving Hard-Constrained Traveling Salesman Problem",
    "authors": [
      "Jingxiao Chen",
      "Ziqin Gong",
      "Minghuan Liu",
      "Jun Wang",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "abstract": "Many real-world problems can be formulated as a constrained Traveling\nSalesman Problem (TSP). However, the constraints are always complex and\nnumerous, making the TSPs challenging to solve. When the number of complicated\nconstraints grows, it is time-consuming for traditional heuristic algorithms to\navoid illegitimate outcomes. Learning-based methods provide an alternative to\nsolve TSPs in a soft manner, which also supports GPU acceleration to generate\nsolutions quickly. Nevertheless, the soft manner inevitably results in\ndifficulty solving hard-constrained problems with learning algorithms, and the\nconflicts between legality and optimality may substantially affect the\noptimality of the solution. To overcome this problem and to have an effective\nsolution against hard constraints, we proposed a novel learning-based method\nthat uses looking-ahead information as the feature to improve the legality of\nTSP with Time Windows (TSPTW) solutions. Besides, we constructed TSPTW datasets\nwith hard constraints in order to accurately evaluate and benchmark the\nstatistical performance of various approaches, which can serve the community\nfor future research. With comprehensive experiments on diverse datasets, MUSLA\noutperforms existing baselines and shows generalizability potential.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05318v1",
    "published_date": "2024-03-08 13:49:21 UTC",
    "updated_date": "2024-03-08 13:49:21 UTC"
  },
  {
    "arxiv_id": "2403.05313v1",
    "title": "RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation",
    "authors": [
      "Zihao Wang",
      "Anji Liu",
      "Haowei Lin",
      "Jiaqi Li",
      "Xiaojian Ma",
      "Yitao Liang"
    ],
    "abstract": "We explore how iterative revising a chain of thoughts with the help of\ninformation retrieval significantly improves large language models' reasoning\nand generation ability in long-horizon generation tasks, while hugely\nmitigating hallucination. In particular, the proposed method --\n*retrieval-augmented thoughts* (RAT) -- revises each thought step one by one\nwith retrieved information relevant to the task query, the current and the past\nthought steps, after the initial zero-shot CoT is generated. Applying RAT to\nGPT-3.5, GPT-4, and CodeLLaMA-7b substantially improves their performances on\nvarious long-horizon generation tasks; on average of relatively increasing\nrating scores by 13.63% on code generation, 16.96% on mathematical reasoning,\n19.2% on creative writing, and 42.78% on embodied task planning. The demo page\ncan be found at https://craftjarvis.github.io/RAT",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05313v1",
    "published_date": "2024-03-08 13:42:19 UTC",
    "updated_date": "2024-03-08 13:42:19 UTC"
  },
  {
    "arxiv_id": "2403.05307v1",
    "title": "Tapilot-Crossing: Benchmarking and Evolving LLMs Towards Interactive Data Analysis Agents",
    "authors": [
      "Jinyang Li",
      "Nan Huo",
      "Yan Gao",
      "Jiayi Shi",
      "Yingxiu Zhao",
      "Ge Qu",
      "Yurong Wu",
      "Chenhao Ma",
      "Jian-Guang Lou",
      "Reynold Cheng"
    ],
    "abstract": "Interactive Data Analysis, the collaboration between humans and LLM agents,\nenables real-time data exploration for informed decision-making. The challenges\nand costs of collecting realistic interactive logs for data analysis hinder the\nquantitative evaluation of Large Language Model (LLM) agents in this task. To\nmitigate this issue, we introduce Tapilot-Crossing, a new benchmark to evaluate\nLLM agents on interactive data analysis. Tapilot-Crossing contains 1024\ninteractions, covering 4 practical scenarios: Normal, Action, Private, and\nPrivate Action. Notably, Tapilot-Crossing is constructed by an economical\nmulti-agent environment, Decision Company, with few human efforts. We evaluate\npopular and advanced LLM agents in Tapilot-Crossing, which underscores the\nchallenges of interactive data analysis. Furthermore, we propose Adaptive\nInteraction Reflection (AIR), a self-generated reflection strategy that guides\nLLM agents to learn from successful history. Experiments demonstrate that Air\ncan evolve LLMs into effective interactive data analysis agents, achieving a\nrelative performance improvement of up to 44.5%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.05307v1",
    "published_date": "2024-03-08 13:34:20 UTC",
    "updated_date": "2024-03-08 13:34:20 UTC"
  },
  {
    "arxiv_id": "2403.05300v5",
    "title": "Unity by Diversity: Improved Representation Learning in Multimodal VAEs",
    "authors": [
      "Thomas M. Sutter",
      "Yang Meng",
      "Andrea Agostini",
      "Daphné Chopard",
      "Norbert Fortin",
      "Julia E. Vogt",
      "Babak Shahbaba",
      "Stephan Mandt"
    ],
    "abstract": "Variational Autoencoders for multimodal data hold promise for many tasks in\ndata analysis, such as representation learning, conditional generation, and\nimputation. Current architectures either share the encoder output, decoder\ninput, or both across modalities to learn a shared representation. Such\narchitectures impose hard constraints on the model. In this work, we show that\na better latent representation can be obtained by replacing these hard\nconstraints with a soft constraint. We propose a new mixture-of-experts prior,\nsoftly guiding each modality's latent representation towards a shared aggregate\nposterior. This approach results in a superior latent representation and allows\neach encoding to preserve information better from its uncompressed original\nfeatures. In extensive experiments on multiple benchmark datasets and two\nchallenging real-world datasets, we show improved learned latent\nrepresentations and imputation of missing data modalities compared to existing\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05300v5",
    "published_date": "2024-03-08 13:29:46 UTC",
    "updated_date": "2025-01-07 17:42:16 UTC"
  },
  {
    "arxiv_id": "2403.05297v3",
    "title": "PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck",
    "authors": [
      "Thang M. Pham",
      "Peijie Chen",
      "Tin Nguyen",
      "Seunghyun Yoon",
      "Trung Bui",
      "Anh Totti Nguyen"
    ],
    "abstract": "CLIP-based classifiers rely on the prompt containing a {class name} that is\nknown to the text encoder. Therefore, they perform poorly on new classes or the\nclasses whose names rarely appear on the Internet (e.g., scientific names of\nbirds). For fine-grained classification, we propose PEEB - an explainable and\neditable classifier to (1) express the class name into a set of text\ndescriptors that describe the visual parts of that class; and (2) match the\nembeddings of the detected parts to their textual descriptors in each class to\ncompute a logit score for classification. In a zero-shot setting where the\nclass names are unknown, PEEB outperforms CLIP by a huge margin (~10x in top-1\naccuracy). Compared to part-based classifiers, PEEB is not only the\nstate-of-the-art (SOTA) on the supervised-learning setting (88.80% and 92.20%\naccuracy on CUB-200 and Dogs-120, respectively) but also the first to enable\nusers to edit the text descriptors to form a new classifier without any\nre-training. Compared to concept bottleneck models, PEEB is also the SOTA in\nboth zero-shot and supervised-learning settings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Findings of NAACL 2024 (long paper)",
    "pdf_url": "http://arxiv.org/pdf/2403.05297v3",
    "published_date": "2024-03-08 13:24:46 UTC",
    "updated_date": "2024-04-12 20:10:29 UTC"
  },
  {
    "arxiv_id": "2403.05266v3",
    "title": "ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models",
    "authors": [
      "Jio Oh",
      "Soyeon Kim",
      "Junseok Seo",
      "Jindong Wang",
      "Ruochen Xu",
      "Xing Xie",
      "Steven Euijong Whang"
    ],
    "abstract": "Large language models (LLMs) have achieved unprecedented performances in\nvarious applications, yet evaluating them is still challenging. Existing\nbenchmarks are either manually constructed or are automatic, but lack the\nability to evaluate the thought process of LLMs with arbitrary complexity. We\ncontend that utilizing existing relational databases based on the\nentity-relationship (ER) model is a promising approach for constructing\nbenchmarks as they contain structured knowledge that can be used to question\nLLMs. Unlike knowledge graphs, which are also used to evaluate LLMs, relational\ndatabases have integrity constraints that can be used to better construct\ncomplex in-depth questions and verify answers: (1) functional dependencies can\nbe used to pinpoint critical keywords that an LLM must know to properly answer\na given question containing certain attribute values; and (2) foreign key\nconstraints can be used to join relations and construct multi-hop questions,\nwhich can be arbitrarily long and used to debug intermediate answers. We thus\npropose ERBench, which uses these integrity constraints to convert any database\ninto an LLM benchmark. ERBench supports continuous evaluation as databases\nchange, multimodal questions, and various prompt engineering techniques. In our\nexperiments, we construct LLM benchmarks using databases of multiple domains\nand make an extensive comparison of contemporary LLMs. We show how ERBench can\nproperly evaluate any LLM by not only checking for answer correctness, but also\neffectively verifying the rationales by looking for the right keywords.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05266v3",
    "published_date": "2024-03-08 12:42:36 UTC",
    "updated_date": "2024-11-03 18:38:50 UTC"
  },
  {
    "arxiv_id": "2403.05265v2",
    "title": "MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts",
    "authors": [
      "Zinan Zeng",
      "Sen Ye",
      "Zijian Cai",
      "Heng Wang",
      "Yuhan Liu",
      "Haokai Zhang",
      "Minnan Luo"
    ],
    "abstract": "Online movie review websites are valuable for information and discussion\nabout movies. However, the massive spoiler reviews detract from the\nmovie-watching experience, making spoiler detection an important task. Previous\nmethods simply focus on reviews' text content, ignoring the heterogeneity of\ninformation in the platform. For instance, the metadata and the corresponding\nuser's information of a review could be helpful. Besides, the spoiler language\nof movie reviews tends to be genre-specific, thus posing a domain\ngeneralization challenge for existing methods. To this end, we propose MMoE, a\nmulti-modal network that utilizes information from multiple modalities to\nfacilitate robust spoiler detection and adopts Mixture-of-Experts to enhance\ndomain generalization. MMoE first extracts graph, text, and meta feature from\nthe user-movie network, the review's textual content, and the review's metadata\nrespectively. To handle genre-specific spoilers, we then adopt\nMixture-of-Experts architecture to process information in three modalities to\npromote robustness. Finally, we use an expert fusion layer to integrate the\nfeatures from different perspectives and make predictions based on the fused\nembedding. Experiments demonstrate that MMoE achieves state-of-the-art\nperformance on two widely-used spoiler detection datasets, surpassing previous\nSOTA methods by 2.56% and 8.41% in terms of accuracy and F1-score. Further\nexperiments also demonstrate MMoE's superiority in robustness and\ngeneralization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05265v2",
    "published_date": "2024-03-08 12:42:04 UTC",
    "updated_date": "2024-03-14 03:43:54 UTC"
  },
  {
    "arxiv_id": "2403.05260v2",
    "title": "Towards generalization of drug response prediction to single cells and patients utilizing importance-aware multi-source domain transfer learning",
    "authors": [
      "Hui Liu",
      "Wei Duan",
      "Judong Luo"
    ],
    "abstract": "The advancement of single-cell sequencing technology has promoted the\ngeneration of a large amount of single-cell transcriptional profiles, providing\nunprecedented opportunities to identify drug-resistant cell subpopulations\nwithin a tumor. However, few studies have focused on drug response prediction\nat single-cell level, and their performance remains suboptimal. This paper\nproposed scAdaDrug, a novel multi-source domain adaptation model powered by\nadaptive importance-aware representation learning to predict drug response of\nindividual cells. We used a shared encoder to extract domain-invariant features\nrelated to drug response from multiple source domains by utilizing adversarial\ndomain adaptation. Particularly, we introduced a plug-and-play module to\ngenerate importance-aware and mutually independent weights, which could\nadaptively modulate the latent representation of each sample in element-wise\nmanner between source and target domains. Extensive experimental results showed\nthat our model achieved state-of-the-art performance in predicting drug\nresponse on multiple independent datasets, including single-cell datasets\nderived from both cell lines and patient-derived xenografts (PDX) models, as\nwell as clinical tumor patient cohorts. Moreover, the ablation experiments\ndemonstrated our model effectively captured the underlying patterns determining\ndrug response from multiple source domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05260v2",
    "published_date": "2024-03-08 12:31:03 UTC",
    "updated_date": "2025-01-07 00:53:48 UTC"
  },
  {
    "arxiv_id": "2403.05245v2",
    "title": "Noise Level Adaptive Diffusion Model for Robust Reconstruction of Accelerated MRI",
    "authors": [
      "Shoujin Huang",
      "Guanxiong Luo",
      "Xi Wang",
      "Ziran Chen",
      "Yuwan Wang",
      "Huaishui Yang",
      "Pheng-Ann Heng",
      "Lingyan Zhang",
      "Mengye Lyu"
    ],
    "abstract": "In general, diffusion model-based MRI reconstruction methods incrementally\nremove artificially added noise while imposing data consistency to reconstruct\nthe underlying images. However, real-world MRI acquisitions already contain\ninherent noise due to thermal fluctuations. This phenomenon is particularly\nnotable when using ultra-fast, high-resolution imaging sequences for advanced\nresearch, or using low-field systems favored by low- and middle-income\ncountries. These common scenarios can lead to sub-optimal performance or\ncomplete failure of existing diffusion model-based reconstruction techniques.\nSpecifically, as the artificially added noise is gradually removed, the\ninherent MRI noise becomes increasingly pronounced, making the actual noise\nlevel inconsistent with the predefined denoising schedule and consequently\ninaccurate image reconstruction. To tackle this problem, we propose a posterior\nsampling strategy with a novel NoIse Level Adaptive Data Consistency (Nila-DC)\noperation. Extensive experiments are conducted on two public datasets and an\nin-house clinical dataset with field strength ranging from 0.3T to 3T, showing\nthat our method surpasses the state-of-the-art MRI reconstruction methods, and\nis highly robust against various noise levels. The code for Nila is available\nat https://github.com/Solor-pikachu/Nila.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05245v2",
    "published_date": "2024-03-08 12:07:18 UTC",
    "updated_date": "2024-07-31 14:53:08 UTC"
  },
  {
    "arxiv_id": "2403.05239v1",
    "title": "Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation",
    "authors": [
      "Junyan Wang",
      "Zhenhong Sun",
      "Zhiyu Tan",
      "Xuanbai Chen",
      "Weihua Chen",
      "Hao Li",
      "Cheng Zhang",
      "Yang Song"
    ],
    "abstract": "Vanilla text-to-image diffusion models struggle with generating accurate\nhuman images, commonly resulting in imperfect anatomies such as unnatural\npostures or disproportionate limbs.Existing methods address this issue mostly\nby fine-tuning the model with extra images or adding additional controls --\nhuman-centric priors such as pose or depth maps -- during the image generation\nphase. This paper explores the integration of these human-centric priors\ndirectly into the model fine-tuning stage, essentially eliminating the need for\nextra conditions at the inference stage. We realize this idea by proposing a\nhuman-centric alignment loss to strengthen human-related information from the\ntextual prompts within the cross-attention maps. To ensure semantic detail\nrichness and human structural accuracy during fine-tuning, we introduce\nscale-aware and step-wise constraints within the diffusion process, according\nto an in-depth analysis of the cross-attention layer. Extensive experiments\nshow that our method largely improves over state-of-the-art text-to-image\nmodels to synthesize high-quality human images based on user-written prompts.\nProject page: \\url{https://hcplayercvpr2024.github.io}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05239v1",
    "published_date": "2024-03-08 11:59:32 UTC",
    "updated_date": "2024-03-08 11:59:32 UTC"
  },
  {
    "arxiv_id": "2403.05235v1",
    "title": "Fairness-Aware Interpretable Modeling (FAIM) for Trustworthy Machine Learning in Healthcare",
    "authors": [
      "Mingxuan Liu",
      "Yilin Ning",
      "Yuhe Ke",
      "Yuqing Shang",
      "Bibhas Chakraborty",
      "Marcus Eng Hock Ong",
      "Roger Vaughan",
      "Nan Liu"
    ],
    "abstract": "The escalating integration of machine learning in high-stakes fields such as\nhealthcare raises substantial concerns about model fairness. We propose an\ninterpretable framework - Fairness-Aware Interpretable Modeling (FAIM), to\nimprove model fairness without compromising performance, featuring an\ninteractive interface to identify a \"fairer\" model from a set of\nhigh-performing models and promoting the integration of data-driven evidence\nand clinical expertise to enhance contextualized fairness. We demonstrated\nFAIM's value in reducing sex and race biases by predicting hospital admission\nwith two real-world databases, MIMIC-IV-ED and SGH-ED. We show that for both\ndatasets, FAIM models not only exhibited satisfactory discriminatory\nperformance but also significantly mitigated biases as measured by\nwell-established fairness metrics, outperforming commonly used bias-mitigation\nmethods. Our approach demonstrates the feasibility of improving fairness\nwithout sacrificing performance and provides an a modeling mode that invites\ndomain experts to engage, fostering a multidisciplinary effort toward tailored\nAI fairness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05235v1",
    "published_date": "2024-03-08 11:51:00 UTC",
    "updated_date": "2024-03-08 11:51:00 UTC"
  },
  {
    "arxiv_id": "2403.05229v1",
    "title": "Developing Federated Time-to-Event Scores Using Heterogeneous Real-World Survival Data",
    "authors": [
      "Siqi Li",
      "Yuqing Shang",
      "Ziwen Wang",
      "Qiming Wu",
      "Chuan Hong",
      "Yilin Ning",
      "Di Miao",
      "Marcus Eng Hock Ong",
      "Bibhas Chakraborty",
      "Nan Liu"
    ],
    "abstract": "Survival analysis serves as a fundamental component in numerous healthcare\napplications, where the determination of the time to specific events (such as\nthe onset of a certain disease or death) for patients is crucial for clinical\ndecision-making. Scoring systems are widely used for swift and efficient risk\nprediction. However, existing methods for constructing survival scores presume\nthat data originates from a single source, posing privacy challenges in\ncollaborations with multiple data owners. We propose a novel framework for\nbuilding federated scoring systems for multi-site survival outcomes, ensuring\nboth privacy and communication efficiency. We applied our approach to sites\nwith heterogeneous survival data originating from emergency departments in\nSingapore and the United States. Additionally, we independently developed local\nscores at each site. In testing datasets from each participant site, our\nproposed federated scoring system consistently outperformed all local models,\nevidenced by higher integrated area under the receiver operating characteristic\ncurve (iAUC) values, with a maximum improvement of 11.6%. Additionally, the\nfederated score's time-dependent AUC(t) values showed advantages over local\nscores, exhibiting narrower confidence intervals (CIs) across most time points.\nThe model developed through our proposed method exhibits effective performance\non each local site, signifying noteworthy implications for healthcare research.\nSites participating in our proposed federated scoring model training gained\nbenefits by acquiring survival models with enhanced prediction accuracy and\nefficiency. This study demonstrates the effectiveness of our privacy-preserving\nfederated survival score generation framework and its applicability to\nreal-world heterogeneous survival data.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05229v1",
    "published_date": "2024-03-08 11:32:00 UTC",
    "updated_date": "2024-03-08 11:32:00 UTC"
  },
  {
    "arxiv_id": "2403.05220v1",
    "title": "Synthetic Privileged Information Enhances Medical Image Representation Learning",
    "authors": [
      "Lucas Farndale",
      "Chris Walsh",
      "Robert Insall",
      "Ke Yuan"
    ],
    "abstract": "Multimodal self-supervised representation learning has consistently proven to\nbe a highly effective method in medical image analysis, offering strong task\nperformance and producing biologically informed insights. However, these\nmethods heavily rely on large, paired datasets, which is prohibitive for their\nuse in scenarios where paired data does not exist, or there is only a small\namount available. In contrast, image generation methods can work well on very\nsmall datasets, and can find mappings between unpaired datasets, meaning an\neffectively unlimited amount of paired synthetic data can be generated. In this\nwork, we demonstrate that representation learning can be significantly improved\nby synthetically generating paired information, both compared to training on\neither single-modality (up to 4.4x error reduction) or authentic multi-modal\npaired datasets (up to 5.6x error reduction).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.TO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05220v1",
    "published_date": "2024-03-08 11:18:26 UTC",
    "updated_date": "2024-03-08 11:18:26 UTC"
  },
  {
    "arxiv_id": "2403.05217v1",
    "title": "Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering",
    "authors": [
      "Hongda Sun",
      "Yuxuan Liu",
      "Chengwei Wu",
      "Haiyu Yan",
      "Cheng Tai",
      "Xin Gao",
      "Shuo Shang",
      "Rui Yan"
    ],
    "abstract": "Open-domain question answering (ODQA) has emerged as a pivotal research\nspotlight in information systems. Existing methods follow two main paradigms to\ncollect evidence: (1) The \\textit{retrieve-then-read} paradigm retrieves\npertinent documents from an external corpus; and (2) the\n\\textit{generate-then-read} paradigm employs large language models (LLMs) to\ngenerate relevant documents. However, neither can fully address multifaceted\nrequirements for evidence. To this end, we propose LLMQA, a generalized\nframework that formulates the ODQA process into three basic steps: query\nexpansion, document selection, and answer generation, combining the superiority\nof both retrieval-based and generation-based evidence. Since LLMs exhibit their\nexcellent capabilities to accomplish various tasks, we instruct LLMs to play\nmultiple roles as generators, rerankers, and evaluators within our framework,\nintegrating them to collaborate in the ODQA process. Furthermore, we introduce\na novel prompt optimization algorithm to refine role-playing prompts and steer\nLLMs to produce higher-quality evidence and answers. Extensive experimental\nresults on widely used benchmarks (NQ, WebQ, and TriviaQA) demonstrate that\nLLMQA achieves the best performance in terms of both answer accuracy and\nevidence quality, showcasing its potential for advancing ODQA research and\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "TheWebConf 2024 (WWW 2024) oral, code repo:\n  https://github.com/EthanLeo-LYX/LLMQA",
    "pdf_url": "http://arxiv.org/pdf/2403.05217v1",
    "published_date": "2024-03-08 11:09:13 UTC",
    "updated_date": "2024-03-08 11:09:13 UTC"
  },
  {
    "arxiv_id": "2403.05209v1",
    "title": "Overcoming Data Inequality across Domains with Semi-Supervised Domain Generalization",
    "authors": [
      "Jinha Park",
      "Wonguk Cho",
      "Taesup Kim"
    ],
    "abstract": "While there have been considerable advancements in machine learning driven by\nextensive datasets, a significant disparity still persists in the availability\nof data across various sources and populations. This inequality across domains\nposes challenges in modeling for those with limited data, which can lead to\nprofound practical and ethical concerns. In this paper, we address a\nrepresentative case of data inequality problem across domains termed\nSemi-Supervised Domain Generalization (SSDG), in which only one domain is\nlabeled while the rest are unlabeled. We propose a novel algorithm, ProUD,\nwhich can effectively learn domain-invariant features via domain-aware\nprototypes along with progressive generalization via uncertainty-adaptive\nmixing of labeled and unlabeled domains. Our experiments on three different\nbenchmark datasets demonstrate the effectiveness of ProUD, outperforming all\nbaseline models including single domain generalization and semi-supervised\nlearning. Source code will be released upon acceptance of the paper.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.05209v1",
    "published_date": "2024-03-08 10:49:37 UTC",
    "updated_date": "2024-03-08 10:49:37 UTC"
  },
  {
    "arxiv_id": "2403.05189v1",
    "title": "Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge",
    "authors": [
      "Xin Zhao",
      "Naoki Yoshinaga",
      "Daisuke Oba"
    ],
    "abstract": "Acquiring factual knowledge for language models (LMs) in low-resource\nlanguages poses a serious challenge, thus resorting to cross-lingual transfer\nin multilingual LMs (ML-LMs). In this study, we ask how ML-LMs acquire and\nrepresent factual knowledge. Using the multilingual factual knowledge probing\ndataset, mLAMA, we first conducted a neuron investigation of ML-LMs\n(specifically, multilingual BERT). We then traced the roots of facts back to\nthe knowledge source (Wikipedia) to identify the ways in which ML-LMs acquire\nspecific facts. We finally identified three patterns of acquiring and\nrepresenting facts in ML-LMs: language-independent, cross-lingual shared and\ntransferred, and devised methods for differentiating them. Our findings\nhighlight the challenge of maintaining consistent factual knowledge across\nlanguages, underscoring the need for better fact representation learning in\nML-LMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2403.05189v1",
    "published_date": "2024-03-08 10:09:57 UTC",
    "updated_date": "2024-03-08 10:09:57 UTC"
  },
  {
    "arxiv_id": "2403.05175v1",
    "title": "Continual Learning and Catastrophic Forgetting",
    "authors": [
      "Gido M. van de Ven",
      "Nicholas Soures",
      "Dhireesha Kudithipudi"
    ],
    "abstract": "This book chapter delves into the dynamics of continual learning, which is\nthe process of incrementally learning from a non-stationary stream of data.\nAlthough continual learning is a natural skill for the human brain, it is very\nchallenging for artificial neural networks. An important reason is that, when\nlearning something new, these networks tend to quickly and drastically forget\nwhat they had learned before, a phenomenon known as catastrophic forgetting.\nEspecially in the last decade, continual learning has become an extensively\nstudied topic in deep learning. This book chapter reviews the insights that\nthis field has generated.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "q-bio.NC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint of a book chapter; 21 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.05175v1",
    "published_date": "2024-03-08 09:32:43 UTC",
    "updated_date": "2024-03-08 09:32:43 UTC"
  },
  {
    "arxiv_id": "2403.05171v2",
    "title": "Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation",
    "authors": [
      "Xiaoying Zhang",
      "Jean-Francois Ton",
      "Wei Shen",
      "Hongning Wang",
      "Yang Liu"
    ],
    "abstract": "We introduce Adversarial Policy Optimization (AdvPO), a novel solution to the\npervasive issue of reward over-optimization in Reinforcement Learning from\nHuman Feedback (RLHF) for Large Language Models (LLMs). Over-optimization\noccurs when a reward model serves as an imperfect proxy for human preference,\nand RL-driven policy optimization erroneously exploits reward inaccuracies. In\nthis paper, we begin by introducing a lightweight way to quantify uncertainties\nin rewards, relying solely on the last layer embeddings of the reward model,\nwithout the need for computationally expensive reward ensembles. AdvPO then\naddresses a distributionally robust optimization problem centred around the\nconfidence interval of the reward model's predictions for policy improvement.\nThrough comprehensive experiments on the Anthropic HH and TL;DR summarization\ndatasets, we illustrate the efficacy of AdvPO in mitigating the\noveroptimization issue, consequently resulting in enhanced performance as\nevaluated through human-assisted evaluation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05171v2",
    "published_date": "2024-03-08 09:20:12 UTC",
    "updated_date": "2024-07-09 13:17:36 UTC"
  },
  {
    "arxiv_id": "2403.05168v1",
    "title": "Unlocking the Potential of Multimodal Unified Discrete Representation through Training-Free Codebook Optimization and Hierarchical Alignment",
    "authors": [
      "Hai Huang",
      "Yan Xia",
      "Shengpeng Ji",
      "Shulei Wang",
      "Hanting Wang",
      "Jieming Zhu",
      "Zhenhua Dong",
      "Zhou Zhao"
    ],
    "abstract": "Recent advances in representation learning have demonstrated the significance\nof multimodal alignment. The Dual Cross-modal Information Disentanglement\n(DCID) model, utilizing a unified codebook, shows promising results in\nachieving fine-grained representation and cross-modal generalization. However,\nit is still hindered by equal treatment of all channels and neglect of minor\nevent information, resulting in interference from irrelevant channels and\nlimited performance in fine-grained tasks. Thus, in this work, We propose a\nTraining-free Optimization of Codebook (TOC) method to enhance model\nperformance by selecting important channels in the unified space without\nretraining. Additionally, we introduce the Hierarchical Dual Cross-modal\nInformation Disentanglement (H-DCID) approach to extend information separation\nand alignment to two levels, capturing more cross-modal details. The experiment\nresults demonstrate significant improvements across various downstream tasks,\nwith TOC contributing to an average improvement of 1.70% for DCID on four\ntasks, and H-DCID surpassing DCID by an average of 3.64%. The combination of\nTOC and H-DCID further enhances performance, exceeding DCID by 4.43%. These\nfindings highlight the effectiveness of our methods in facilitating robust and\nnuanced cross-modal learning, opening avenues for future enhancements. The\nsource code and pre-trained models can be accessed at\nhttps://github.com/haihuangcode/TOC_H-DCID.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05168v1",
    "published_date": "2024-03-08 09:16:47 UTC",
    "updated_date": "2024-03-08 09:16:47 UTC"
  },
  {
    "arxiv_id": "2403.05164v1",
    "title": "Synthetic data generation for system identification: leveraging knowledge transfer from similar systems",
    "authors": [
      "Dario Piga",
      "Matteo Rufolo",
      "Gabriele Maroni",
      "Manas Mejari",
      "Marco Forgione"
    ],
    "abstract": "This paper addresses the challenge of overfitting in the learning of\ndynamical systems by introducing a novel approach for the generation of\nsynthetic data, aimed at enhancing model generalization and robustness in\nscenarios characterized by data scarcity. Central to the proposed methodology\nis the concept of knowledge transfer from systems within the same class.\nSpecifically, synthetic data is generated through a pre-trained meta-model that\ndescribes a broad class of systems to which the system of interest is assumed\nto belong. Training data serves a dual purpose: firstly, as input to the\npre-trained meta model to discern the system's dynamics, enabling the\nprediction of its behavior and thereby generating synthetic output sequences\nfor new input sequences; secondly, in conjunction with synthetic data, to\ndefine the loss function used for model estimation. A validation dataset is\nused to tune a scalar hyper-parameter balancing the relative importance of\ntraining and synthetic data in the definition of the loss function. The same\nvalidation set can be also used for other purposes, such as early stopping\nduring the training, fundamental to avoid overfitting in case of small-size\ntraining datasets. The efficacy of the approach is shown through a numerical\nexample that highlights the advantages of integrating synthetic data into the\nsystem identification process.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05164v1",
    "published_date": "2024-03-08 09:09:15 UTC",
    "updated_date": "2024-03-08 09:09:15 UTC"
  },
  {
    "arxiv_id": "2403.05158v2",
    "title": "Adaptive Split Learning over Energy-Constrained Wireless Edge Networks",
    "authors": [
      "Zuguang Li",
      "Wen Wu",
      "Shaohua Wu",
      "Wei Wang"
    ],
    "abstract": "Split learning (SL) is a promising approach for training artificial\nintelligence (AI) models, in which devices collaborate with a server to train\nan AI model in a distributed manner, based on a same fixed split point.\nHowever, due to the device heterogeneity and variation of channel conditions,\nthis way is not optimal in training delay and energy consumption. In this\npaper, we design an adaptive split learning (ASL) scheme which can dynamically\nselect split points for devices and allocate computing resource for the server\nin wireless edge networks. We formulate an optimization problem to minimize the\naverage training latency subject to long-term energy consumption constraint.\nThe difficulties in solving this problem are the lack of future information and\nmixed integer programming (MIP). To solve it, we propose an online algorithm\nleveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP\nproblem only with the current information. Then, a two-layer optimization\nmethod is proposed to solve the MIP problem. Extensive simulation results\ndemonstrate that the ASL scheme can reduce the average training delay and\nenergy consumption by 53.7% and 22.1%, respectively, as compared to the\nexisting SL schemes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 5 figures, 20 conferences",
    "pdf_url": "http://arxiv.org/pdf/2403.05158v2",
    "published_date": "2024-03-08 08:51:37 UTC",
    "updated_date": "2025-03-13 13:27:47 UTC"
  },
  {
    "arxiv_id": "2403.05152v3",
    "title": "Towards a Psychology of Machines: Large Language Models Predict Human Memory",
    "authors": [
      "Markus Huff",
      "Elanur Ulakçı"
    ],
    "abstract": "Large language models (LLMs), such as ChatGPT, have shown remarkable\nabilities in natural language processing, opening new avenues in psychological\nresearch. This study explores whether LLMs can predict human memory performance\nin tasks involving garden-path sentences and contextual information. In the\nfirst part, we used ChatGPT to rate the relatedness and memorability of\ngarden-path sentences preceded by either fitting or unfitting contexts. In the\nsecond part, human participants read the same sentences, rated their\nrelatedness, and completed a surprise memory test. The results demonstrated\nthat ChatGPT's relatedness ratings closely matched those of the human\nparticipants, and its memorability ratings effectively predicted human memory\nperformance. Both LLM and human data revealed that higher relatedness in the\nunfitting context condition was associated with better memory performance,\naligning with probabilistic frameworks of context-dependent learning. These\nfindings suggest that LLMs, despite lacking human-like memory mechanisms, can\nmodel aspects of human cognition and serve as valuable tools in psychological\nresearch. We propose the field of machine psychology to explore this interplay\nbetween human cognition and artificial intelligence, offering a bidirectional\napproach where LLMs can both benefit from and contribute to our understanding\nof human cognitive processes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "34 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.05152v3",
    "published_date": "2024-03-08 08:41:14 UTC",
    "updated_date": "2024-12-04 19:01:43 UTC"
  },
  {
    "arxiv_id": "2403.05149v1",
    "title": "Inverse Design of Photonic Crystal Surface Emitting Lasers is a Sequence Modeling Problem",
    "authors": [
      "Ceyao Zhang",
      "Renjie Li",
      "Cheng Zhang",
      "Zhaoyu Zhang",
      "Feng Yin"
    ],
    "abstract": "Photonic Crystal Surface Emitting Lasers (PCSEL)'s inverse design demands\nexpert knowledge in physics, materials science, and quantum mechanics which is\nprohibitively labor-intensive. Advanced AI technologies, especially\nreinforcement learning (RL), have emerged as a powerful tool to augment and\naccelerate this inverse design process. By modeling the inverse design of PCSEL\nas a sequential decision-making problem, RL approaches can construct a\nsatisfactory PCSEL structure from scratch. However, the data inefficiency\nresulting from online interactions with precise and expensive simulation\nenvironments impedes the broader applicability of RL approaches. Recently,\nsequential models, especially the Transformer architecture, have exhibited\ncompelling performance in sequential decision-making problems due to their\nsimplicity and scalability to large language models. In this paper, we\nintroduce a novel framework named PCSEL Inverse Design Transformer (PiT) that\nabstracts the inverse design of PCSEL as a sequence modeling problem. The\ncentral part of our PiT is a Transformer-based structure that leverages the\npast trajectories and current states to predict the current actions. Compared\nwith the traditional RL approaches, PiT can output the optimal actions and\nachieve target PCSEL designs by leveraging offline data and conditioning on the\ndesired return. Results demonstrate that PiT achieves superior performance and\ndata efficiency compared to baselines.",
    "categories": [
      "physics.app-ph",
      "cs.AI"
    ],
    "primary_category": "physics.app-ph",
    "comment": "accepted by AAAI workshop\n  AI2ASE(2024)https://ai-2-ase.github.io/papers/29%5cCameraReady%5cPIT__PSCEL_inverse_design_transformer.pdf",
    "pdf_url": "http://arxiv.org/pdf/2403.05149v1",
    "published_date": "2024-03-08 08:38:50 UTC",
    "updated_date": "2024-03-08 08:38:50 UTC"
  },
  {
    "arxiv_id": "2403.05132v1",
    "title": "ChatUIE: Exploring Chat-based Unified Information Extraction using Large Language Models",
    "authors": [
      "Jun Xu",
      "Mengshu Sun",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ],
    "abstract": "Recent advancements in large language models have shown impressive\nperformance in general chat. However, their domain-specific capabilities,\nparticularly in information extraction, have certain limitations. Extracting\nstructured information from natural language that deviates from known schemas\nor instructions has proven challenging for previous prompt-based methods. This\nmotivated us to explore domain-specific modeling in chat-based language models\nas a solution for extracting structured information from natural language. In\nthis paper, we present ChatUIE, an innovative unified information extraction\nframework built upon ChatGLM. Simultaneously, reinforcement learning is\nemployed to improve and align various tasks that involve confusing and limited\nsamples. Furthermore, we integrate generation constraints to address the issue\nof generating elements that are not present in the input. Our experimental\nresults demonstrate that ChatUIE can significantly improve the performance of\ninformation extraction with a slight decrease in chatting ability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05132v1",
    "published_date": "2024-03-08 07:59:19 UTC",
    "updated_date": "2024-03-08 07:59:19 UTC"
  },
  {
    "arxiv_id": "2403.05131v2",
    "title": "Sora as an AGI World Model? A Complete Survey on Text-to-Video Generation",
    "authors": [
      "Joseph Cho",
      "Fachrina Dewi Puspitasari",
      "Sheng Zheng",
      "Jingyao Zheng",
      "Lik-Hang Lee",
      "Tae-Ho Kim",
      "Choong Seon Hong",
      "Chaoning Zhang"
    ],
    "abstract": "The evolution of video generation from text, starting with animating MNIST\nnumbers to simulating the physical world with Sora, has progressed at a\nbreakneck speed over the past seven years. While often seen as a superficial\nexpansion of the predecessor text-to-image generation model, text-to-video\ngeneration models are developed upon carefully engineered constituents. Here,\nwe systematically discuss these elements consisting of but not limited to core\nbuilding blocks (vision, language, and temporal) and supporting features from\nthe perspective of their contributions to achieving a world model. We employ\nthe PRISMA framework to curate 97 impactful research articles from renowned\nscientific databases primarily studying video synthesis using text conditions.\nUpon minute exploration of these manuscripts, we observe that text-to-video\ngeneration involves more intricate technologies beyond the plain extension of\ntext-to-image generation. Our additional review into the shortcomings of\nSora-generated videos pinpoints the call for more in-depth studies in various\nenabling aspects of video generation such as dataset, evaluation metric,\nefficient architecture, and human-controlled generation. Finally, we conclude\nthat the study of the text-to-video generation may still be in its infancy,\nrequiring contribution from the cross-discipline research community towards its\nadvancement as the first step to realize artificial general intelligence (AGI).",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "First complete survey on Text-to-Video Generation, 44 pages, 20\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2403.05131v2",
    "published_date": "2024-03-08 07:58:13 UTC",
    "updated_date": "2024-06-07 07:40:07 UTC"
  },
  {
    "arxiv_id": "2403.05130v2",
    "title": "From Chain to Tree: Refining Chain-like Rules into Tree-like Rules on Knowledge Graphs",
    "authors": [
      "Wangtao Sun",
      "Shizhu He",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "With good explanatory power and controllability, rule-based methods play an\nimportant role in many tasks such as knowledge reasoning and decision support.\nHowever, existing studies primarily focused on learning chain-like rules, which\nlimit their semantic expressions and accurate prediction abilities. As a\nresult, chain-like rules usually fire on the incorrect grounding values,\nproducing inaccurate or even erroneous reasoning results. In this paper, we\npropose the concept of tree-like rules on knowledge graphs to expand the\napplication scope and improve the reasoning ability of rule-based methods.\nMeanwhile, we propose an effective framework for refining chain-like rules into\ntree-like rules. Experimental comparisons on four public datasets show that the\nproposed framework can easily adapt to other chain-like rule induction methods\nand the refined tree-like rules consistently achieve better performances than\nchain-like rules on link prediction. The data and code of this paper can be\navailable at https://anonymous.4open.science/r/tree-rule-E3CD/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05130v2",
    "published_date": "2024-03-08 07:55:42 UTC",
    "updated_date": "2025-01-05 03:42:29 UTC"
  },
  {
    "arxiv_id": "2403.05129v1",
    "title": "Unraveling the Molecular Magic: AI Insights on the Formation of Extraordinarily Stretchable Hydrogels",
    "authors": [
      "Shahriar Hojjati Emmami",
      "Ali Pilehvar Meibody",
      "Lobat Tayebi",
      "Mohammadamin Tavakoli",
      "Pierre Baldi"
    ],
    "abstract": "The deliberate manipulation of ammonium persulfate, methylenebisacrylamide,\ndimethyleacrylamide, and polyethylene oxide concentrations resulted in the\ndevelopment of a hydrogel with an exceptional stretchability, capable of\nextending up to 260 times its original length. This study aims to elucidate the\nmolecular architecture underlying this unique phenomenon by exploring potential\nreaction mechanisms, facilitated by an artificial intelligence prediction\nsystem. Artificial intelligence predictor introduces a novel approach to\ninterlinking two polymers, involving the formation of networks interconnected\nwith linear chains following random chain scission. This novel configuration\nleads to the emergence of a distinct type of hydrogel, herein referred to as a\n\"Span Network.\" Additionally, Fourier-transform infrared spectroscopy (FTIR) is\nused to investigate functional groups that may be implicated in the proposed\nmechanism, with ester formation confirmed among numerous hydroxyl end groups\nobtained from chain scission of PEO and carboxyl groups formed on hydrogel\nnetworks.",
    "categories": [
      "cond-mat.soft",
      "cs.AI"
    ],
    "primary_category": "cond-mat.soft",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05129v1",
    "published_date": "2024-03-08 07:52:17 UTC",
    "updated_date": "2024-03-08 07:52:17 UTC"
  },
  {
    "arxiv_id": "2403.15416v1",
    "title": "Fuzzy hyperparameters update in a second order optimization",
    "authors": [
      "Abdelaziz Bensadok",
      "Muhammad Zeeshan Babar"
    ],
    "abstract": "This research will present a hybrid approach to accelerate convergence in a\nsecond order optimization. An online finite difference approximation of the\ndiagonal Hessian matrix will be introduced, along with fuzzy inferencing of\nseveral hyperparameters. Competitive results have been achieved",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15416v1",
    "published_date": "2024-03-08 07:47:27 UTC",
    "updated_date": "2024-03-08 07:47:27 UTC"
  },
  {
    "arxiv_id": "2403.05125v2",
    "title": "Evaluating Text-to-Image Generative Models: An Empirical Study on Human Image Synthesis",
    "authors": [
      "Muxi Chen",
      "Yi Liu",
      "Jian Yi",
      "Changran Xu",
      "Qiuxia Lai",
      "Hongliang Wang",
      "Tsung-Yi Ho",
      "Qiang Xu"
    ],
    "abstract": "In this paper, we present an empirical study introducing a nuanced evaluation\nframework for text-to-image (T2I) generative models, applied to human image\nsynthesis. Our framework categorizes evaluations into two distinct groups:\nfirst, focusing on image qualities such as aesthetics and realism, and second,\nexamining text conditions through concept coverage and fairness. We introduce\nan innovative aesthetic score prediction model that assesses the visual appeal\nof generated images and unveils the first dataset marked with low-quality\nregions in generated human images to facilitate automatic defect detection. Our\nexploration into concept coverage probes the model's effectiveness in\ninterpreting and rendering text-based concepts accurately, while our analysis\nof fairness reveals biases in model outputs, with an emphasis on gender, race,\nand age. While our study is grounded in human imagery, this dual-faceted\napproach is designed with the flexibility to be applicable to other forms of\nimage generation, enhancing our understanding of generative models and paving\nthe way to the next generation of more sophisticated, contextually aware, and\nethically attuned generative models. Code and data, including the dataset\nannotated with defective areas, are available at\n\\href{https://github.com/cure-lab/EvaluateAIGC}{https://github.com/cure-lab/EvaluateAIGC}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05125v2",
    "published_date": "2024-03-08 07:41:47 UTC",
    "updated_date": "2024-10-28 09:53:39 UTC"
  },
  {
    "arxiv_id": "2403.05112v1",
    "title": "RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning and Convolutional Feature Extraction",
    "authors": [
      "Tanvi Verma",
      "Linh Le Dinh",
      "Nicholas Tan",
      "Xinxing Xu",
      "Chingyu Cheng",
      "Yong Liu"
    ],
    "abstract": "Visual perimetry is an important eye examination that helps detect vision\nproblems caused by ocular or neurological conditions. During the test, a\npatient's gaze is fixed at a specific location while light stimuli of varying\nintensities are presented in central and peripheral vision. Based on the\npatient's responses to the stimuli, the visual field mapping and sensitivity\nare determined. However, maintaining high levels of concentration throughout\nthe test can be challenging for patients, leading to increased examination\ntimes and decreased accuracy.\n  In this work, we present RLPeri, a reinforcement learning-based approach to\noptimize visual perimetry testing. By determining the optimal sequence of\nlocations and initial stimulus values, we aim to reduce the examination time\nwithout compromising accuracy. Additionally, we incorporate reward shaping\ntechniques to further improve the testing performance. To monitor the patient's\nresponses over time during testing, we represent the test's state as a pair of\n3D matrices. We apply two different convolutional kernels to extract spatial\nfeatures across locations as well as features across different stimulus values\nfor each location. Through experiments, we demonstrate that our approach\nresults in a 10-20% reduction in examination time while maintaining the\naccuracy as compared to state-of-the-art methods. With the presented approach,\nwe aim to make visual perimetry testing more efficient and patient-friendly,\nwhile still providing accurate results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at AAAI-24",
    "pdf_url": "http://arxiv.org/pdf/2403.05112v1",
    "published_date": "2024-03-08 07:19:43 UTC",
    "updated_date": "2024-03-08 07:19:43 UTC"
  },
  {
    "arxiv_id": "2403.05606v1",
    "title": "A Concept-based Interpretable Model for the Diagnosis of Choroid Neoplasias using Multimodal Data",
    "authors": [
      "Yifan Wu",
      "Yang Liu",
      "Yue Yang",
      "Michael S. Yao",
      "Wenli Yang",
      "Xuehui Shi",
      "Lihong Yang",
      "Dongjun Li",
      "Yueming Liu",
      "James C. Gee",
      "Xuan Yang",
      "Wenbin Wei",
      "Shi Gu"
    ],
    "abstract": "Diagnosing rare diseases presents a common challenge in clinical practice,\nnecessitating the expertise of specialists for accurate identification. The\nadvent of machine learning offers a promising solution, while the development\nof such technologies is hindered by the scarcity of data on rare conditions and\nthe demand for models that are both interpretable and trustworthy in a clinical\ncontext. Interpretable AI, with its capacity for human-readable outputs, can\nfacilitate validation by clinicians and contribute to medical education. In the\ncurrent work, we focus on choroid neoplasias, the most prevalent form of eye\ncancer in adults, albeit rare with 5.1 per million. We built the so-far largest\ndataset consisting of 750 patients, incorporating three distinct imaging\nmodalities collected from 2004 to 2022. Our work introduces a concept-based\ninterpretable model that distinguishes between three types of choroidal tumors,\nintegrating insights from domain experts via radiological reports. Remarkably,\nthis model not only achieves an F1 score of 0.91, rivaling that of black-box\nmodels, but also boosts the diagnostic accuracy of junior doctors by 42%. This\nstudy highlights the significant potential of interpretable machine learning in\nimproving the diagnosis of rare diseases, laying a groundwork for future\nbreakthroughs in medical AI that could tackle a wider array of complex health\nscenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05606v1",
    "published_date": "2024-03-08 07:15:53 UTC",
    "updated_date": "2024-03-08 07:15:53 UTC"
  },
  {
    "arxiv_id": "2403.05110v2",
    "title": "Efficient Data Collection for Robotic Manipulation via Compositional Generalization",
    "authors": [
      "Jensen Gao",
      "Annie Xie",
      "Ted Xiao",
      "Chelsea Finn",
      "Dorsa Sadigh"
    ],
    "abstract": "Data collection has become an increasingly important problem in robotic\nmanipulation, yet there still lacks much understanding of how to effectively\ncollect data to facilitate broad generalization. Recent works on large-scale\nrobotic data collection typically vary many environmental factors of variation\n(e.g., object types, table textures) during data collection, to cover a diverse\nrange of scenarios. However, they do not explicitly account for the possible\ncompositional abilities of policies trained on the data. If robot policies can\ncompose environmental factors from their data to succeed when encountering\nunseen factor combinations, we can exploit this to avoid collecting data for\nsituations that composition would address. To investigate this possibility, we\nconduct thorough empirical studies both in simulation and on a real robot that\ncompare data collection strategies and assess whether visual imitation learning\npolicies can compose environmental factors. We find that policies do exhibit\ncomposition, although leveraging prior robotic datasets is critical for this on\na real robot. We use these insights to propose better in-domain data collection\nstrategies that exploit composition, which can induce better generalization\nthan naive approaches for the same amount of effort during data collection. We\nfurther demonstrate that a real robot policy trained on data from such a\nstrategy achieves a success rate of 77.5% when transferred to entirely new\nenvironments that encompass unseen combinations of environmental factors,\nwhereas policies trained using data collected without accounting for\nenvironmental variation fail to transfer effectively, with a success rate of\nonly 2.5%. We provide videos at http://iliad.stanford.edu/robot-data-comp/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "RSS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05110v2",
    "published_date": "2024-03-08 07:15:38 UTC",
    "updated_date": "2024-05-21 14:18:47 UTC"
  },
  {
    "arxiv_id": "2403.05108v1",
    "title": "A Task-Driven Multi-UAV Coalition Formation Mechanism",
    "authors": [
      "Xinpeng Lu",
      "Heng Song",
      "Huailing Ma",
      "Junwu Zhu"
    ],
    "abstract": "With the rapid advancement of UAV technology, the problem of UAV coalition\nformation has become a hotspot. Therefore, designing task-driven multi-UAV\ncoalition formation mechanism has become a challenging problem. However,\nexisting coalition formation mechanisms suffer from low relevance between UAVs\nand task requirements, resulting in overall low coalition utility and unstable\ncoalition structures. To address these problems, this paper proposed a novel\nmulti-UAV coalition network collaborative task completion model, considering\nboth coalition work capacity and task-requirement relationships. This model\nstimulated the formation of coalitions that match task requirements by using a\nrevenue function based on the coalition's revenue threshold. Subsequently, an\nalgorithm for coalition formation based on marginal utility was proposed.\nSpecifically, the algorithm utilized Shapley value to achieve fair utility\ndistribution within the coalition, evaluated coalition values based on marginal\nutility preference order, and achieved stable coalition partition through a\nlimited number of iterations. Additionally, we theoretically proved that this\nalgorithm has Nash equilibrium solution. Finally, experimental results\ndemonstrated that the proposed algorithm, compared to currently classical\nalgorithms, not only forms more stable coalitions but also further enhances the\noverall utility of coalitions effectively.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05108v1",
    "published_date": "2024-03-08 07:10:46 UTC",
    "updated_date": "2024-03-08 07:10:46 UTC"
  },
  {
    "arxiv_id": "2403.05105v1",
    "title": "Learning to Rematch Mismatched Pairs for Robust Cross-Modal Retrieval",
    "authors": [
      "Haochen Han",
      "Qinghua Zheng",
      "Guang Dai",
      "Minnan Luo",
      "Jingdong Wang"
    ],
    "abstract": "Collecting well-matched multimedia datasets is crucial for training\ncross-modal retrieval models. However, in real-world scenarios, massive\nmultimodal data are harvested from the Internet, which inevitably contains\nPartially Mismatched Pairs (PMPs). Undoubtedly, such semantical irrelevant data\nwill remarkably harm the cross-modal retrieval performance. Previous efforts\ntend to mitigate this problem by estimating a soft correspondence to\ndown-weight the contribution of PMPs. In this paper, we aim to address this\nchallenge from a new perspective: the potential semantic similarity among\nunpaired samples makes it possible to excavate useful knowledge from mismatched\npairs. To achieve this, we propose L2RM, a general framework based on Optimal\nTransport (OT) that learns to rematch mismatched pairs. In detail, L2RM aims to\ngenerate refined alignments by seeking a minimal-cost transport plan across\ndifferent modalities. To formalize the rematching idea in OT, first, we propose\na self-supervised cost function that automatically learns from explicit\nsimilarity-cost mapping relation. Second, we present to model a partial OT\nproblem while restricting the transport among false positives to further boost\nrefined alignments. Extensive experiments on three benchmarks demonstrate our\nL2RM significantly improves the robustness against PMPs for existing models.\nThe code is available at https://github.com/hhc1997/L2RM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05105v1",
    "published_date": "2024-03-08 07:09:30 UTC",
    "updated_date": "2024-03-08 07:09:30 UTC"
  },
  {
    "arxiv_id": "2403.05104v1",
    "title": "How Culture Shapes What People Want From AI",
    "authors": [
      "Xiao Ge",
      "Chunchen Xu",
      "Daigo Misaki",
      "Hazel Rose Markus",
      "Jeanne L Tsai"
    ],
    "abstract": "There is an urgent need to incorporate the perspectives of culturally diverse\ngroups into AI developments. We present a novel conceptual framework for\nresearch that aims to expand, reimagine, and reground mainstream visions of AI\nusing independent and interdependent cultural models of the self and the\nenvironment. Two survey studies support this framework and provide preliminary\nevidence that people apply their cultural models when imagining their ideal AI.\nCompared with European American respondents, Chinese respondents viewed it as\nless important to control AI and more important to connect with AI, and were\nmore likely to prefer AI with capacities to influence. Reflecting both cultural\nmodels, findings from African American respondents resembled both European\nAmerican and Chinese respondents. We discuss study limitations and future\ndirections and highlight the need to develop culturally responsive and relevant\nAI to serve a broader segment of the world population.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "To appear at CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05104v1",
    "published_date": "2024-03-08 07:08:19 UTC",
    "updated_date": "2024-03-08 07:08:19 UTC"
  },
  {
    "arxiv_id": "2403.05101v3",
    "title": "Rule-driven News Captioning",
    "authors": [
      "Ning Xu",
      "Tingting Zhang",
      "Hongshuo Tian",
      "An-An Liu"
    ],
    "abstract": "News captioning task aims to generate sentences by describing named entities\nor concrete events for an image with its news article. Existing methods have\nachieved remarkable results by relying on the large-scale pre-trained models,\nwhich primarily focus on the correlations between the input news content and\nthe output predictions. However, the news captioning requires adhering to some\nfundamental rules of news reporting, such as accurately describing the\nindividuals and actions associated with the event. In this paper, we propose\nthe rule-driven news captioning method, which can generate image descriptions\nfollowing designated rule signal. Specifically, we first design the news-aware\nsemantic rule for the descriptions. This rule incorporates the primary action\ndepicted in the image (e.g., \"performing\") and the roles played by named\nentities involved in the action (e.g., \"Agent\" and \"Place\"). Second, we inject\nthis semantic rule into the large-scale pre-trained model, BART, with the\nprefix-tuning strategy, where multiple encoder layers are embedded with\nnews-aware semantic rule. Finally, we can effectively guide BART to generate\nnews sentences that comply with the designated rule. Extensive experiments on\ntwo widely used datasets (i.e., GoodNews and NYTimes800k) demonstrate the\neffectiveness of our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05101v3",
    "published_date": "2024-03-08 07:06:43 UTC",
    "updated_date": "2024-03-14 08:00:51 UTC"
  },
  {
    "arxiv_id": "2403.05100v2",
    "title": "Exploring the Adversarial Frontier: Quantifying Robustness via Adversarial Hypervolume",
    "authors": [
      "Ping Guo",
      "Cheng Gong",
      "Xi Lin",
      "Zhiyuan Yang",
      "Qingfu Zhang"
    ],
    "abstract": "The escalating threat of adversarial attacks on deep learning models,\nparticularly in security-critical fields, has underscored the need for robust\ndeep learning systems. Conventional robustness evaluations have relied on\nadversarial accuracy, which measures a model's performance under a specific\nperturbation intensity. However, this singular metric does not fully\nencapsulate the overall resilience of a model against varying degrees of\nperturbation. To address this gap, we propose a new metric termed adversarial\nhypervolume, assessing the robustness of deep learning models comprehensively\nover a range of perturbation intensities from a multi-objective optimization\nstandpoint. This metric allows for an in-depth comparison of defense mechanisms\nand recognizes the trivial improvements in robustness afforded by less potent\ndefensive strategies. Additionally, we adopt a novel training algorithm that\nenhances adversarial robustness uniformly across various perturbation\nintensities, in contrast to methods narrowly focused on optimizing adversarial\naccuracy. Our extensive empirical studies validate the effectiveness of the\nadversarial hypervolume metric, demonstrating its ability to reveal subtle\ndifferences in robustness that adversarial accuracy overlooks. This research\ncontributes a new measure of robustness and establishes a standard for\nassessing and benchmarking the resilience of current and future defensive\nmodels against adversarial threats.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05100v2",
    "published_date": "2024-03-08 07:03:18 UTC",
    "updated_date": "2024-11-17 14:42:51 UTC"
  },
  {
    "arxiv_id": "2403.07005v1",
    "title": "Multi-Agent Reinforcement Learning with a Hierarchy of Reward Machines",
    "authors": [
      "Xuejing Zheng",
      "Chao Yu"
    ],
    "abstract": "In this paper, we study the cooperative Multi-Agent Reinforcement Learning\n(MARL) problems using Reward Machines (RMs) to specify the reward functions\nsuch that the prior knowledge of high-level events in a task can be leveraged\nto facilitate the learning efficiency. Unlike the existing work that RMs have\nbeen incorporated into MARL for task decomposition and policy learning in\nrelatively simple domains or with an assumption of independencies among the\nagents, we present Multi-Agent Reinforcement Learning with a Hierarchy of RMs\n(MAHRM) that is capable of dealing with more complex scenarios when the events\namong agents can occur concurrently and the agents are highly interdependent.\n  MAHRM exploits the relationship of high-level events to decompose a task into\na hierarchy of simpler subtasks that are assigned to a small group of agents,\nso as to reduce the overall computational complexity.\n  Experimental results in three cooperative MARL domains show that MAHRM\noutperforms other MARL methods using the same prior knowledge of high-level\nevents.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07005v1",
    "published_date": "2024-03-08 06:38:22 UTC",
    "updated_date": "2024-03-08 06:38:22 UTC"
  },
  {
    "arxiv_id": "2403.05066v2",
    "title": "Reset & Distill: A Recipe for Overcoming Negative Transfer in Continual Reinforcement Learning",
    "authors": [
      "Hongjoon Ahn",
      "Jinu Hyeon",
      "Youngmin Oh",
      "Bosun Hwang",
      "Taesup Moon"
    ],
    "abstract": "We argue that the negative transfer problem occurring when the new task to\nlearn arrives is an important problem that needs not be overlooked when\ndeveloping effective Continual Reinforcement Learning (CRL) algorithms. Through\ncomprehensive experimental validation, we demonstrate that such issue\nfrequently exists in CRL and cannot be effectively addressed by several recent\nwork on mitigating plasticity loss of RL agents. To that end, we develop Reset\n& Distill (R&D), a simple yet highly effective method, to overcome the negative\ntransfer problem in CRL. R&D combines a strategy of resetting the agent's\nonline actor and critic networks to learn a new task and an offline learning\nstep for distilling the knowledge from the online actor and previous expert's\naction probabilities. We carried out extensive experiments on long sequence of\nMeta World tasks and show that our method consistently outperforms recent\nbaselines, achieving significantly higher success rates across a range of\ntasks. Our findings highlight the importance of considering negative transfer\nin CRL and emphasize the need for robust strategies like R&D to mitigate its\ndetrimental effects.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05066v2",
    "published_date": "2024-03-08 05:37:59 UTC",
    "updated_date": "2024-08-14 06:32:11 UTC"
  },
  {
    "arxiv_id": "2403.05064v1",
    "title": "Unsupervised Graph Neural Architecture Search with Disentangled Self-supervision",
    "authors": [
      "Zeyang Zhang",
      "Xin Wang",
      "Ziwei Zhang",
      "Guangyao Shen",
      "Shiqi Shen",
      "Wenwu Zhu"
    ],
    "abstract": "The existing graph neural architecture search (GNAS) methods heavily rely on\nsupervised labels during the search process, failing to handle ubiquitous\nscenarios where supervisions are not available. In this paper, we study the\nproblem of unsupervised graph neural architecture search, which remains\nunexplored in the literature. The key problem is to discover the latent graph\nfactors that drive the formation of graph data as well as the underlying\nrelations between the factors and the optimal neural architectures. Handling\nthis problem is challenging given that the latent graph factors together with\narchitectures are highly entangled due to the nature of the graph and the\ncomplexity of the neural architecture search process. To address the challenge,\nwe propose a novel Disentangled Self-supervised Graph Neural Architecture\nSearch (DSGAS) model, which is able to discover the optimal architectures\ncapturing various latent graph factors in a self-supervised fashion based on\nunlabeled graph data. Specifically, we first design a disentangled graph\nsuper-network capable of incorporating multiple architectures with factor-wise\ndisentanglement, which are optimized simultaneously. Then, we estimate the\nperformance of architectures under different factors by our proposed\nself-supervised training with joint architecture-graph disentanglement.\nFinally, we propose a contrastive search with architecture augmentations to\ndiscover architectures with factor-specific expertise. Extensive experiments on\n11 real-world datasets demonstrate that the proposed model is able to achieve\nstate-of-the-art performance against several baseline methods in an\nunsupervised manner.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS'23",
    "pdf_url": "http://arxiv.org/pdf/2403.05064v1",
    "published_date": "2024-03-08 05:23:55 UTC",
    "updated_date": "2024-03-08 05:23:55 UTC"
  },
  {
    "arxiv_id": "2403.05063v2",
    "title": "Aligning Large Language Models for Controllable Recommendations",
    "authors": [
      "Wensheng Lu",
      "Jianxun Lian",
      "Wei Zhang",
      "Guanghua Li",
      "Mingyang Zhou",
      "Hao Liao",
      "Xing Xie"
    ],
    "abstract": "Inspired by the exceptional general intelligence of Large Language Models\n(LLMs), researchers have begun to explore their application in pioneering the\nnext generation of recommender systems - systems that are conversational,\nexplainable, and controllable. However, existing literature primarily\nconcentrates on integrating domain-specific knowledge into LLMs to enhance\naccuracy, often neglecting the ability to follow instructions. To address this\ngap, we initially introduce a collection of supervised learning tasks,\naugmented with labels derived from a conventional recommender model, aimed at\nexplicitly improving LLMs' proficiency in adhering to recommendation-specific\ninstructions. Subsequently, we develop a reinforcement learning-based alignment\nprocedure to further strengthen LLMs' aptitude in responding to users'\nintentions and mitigating formatting errors. Through extensive experiments on\ntwo real-world datasets, our method markedly advances the capability of LLMs to\ncomply with instructions within recommender systems, while sustaining a high\nlevel of accuracy performance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "68T50"
    ],
    "primary_category": "cs.IR",
    "comment": "14 pages; Accepted by ACL 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2403.05063v2",
    "published_date": "2024-03-08 05:23:27 UTC",
    "updated_date": "2024-08-04 11:49:48 UTC"
  },
  {
    "arxiv_id": "2403.05053v3",
    "title": "PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering",
    "authors": [
      "Yibin Wang",
      "Weizhong Zhang",
      "Jianwei Zheng",
      "Cheng Jin"
    ],
    "abstract": "Image composition involves seamlessly integrating given objects into a\nspecific visual context. Current training-free methods rely on composing\nattention weights from several samplers to guide the generator. However, since\nthese weights are derived from disparate contexts, their combination leads to\ncoherence confusion and loss of appearance information. These issues worsen\nwith their excessive focus on background generation, even when unnecessary in\nthis task. This not only impedes their swift implementation but also\ncompromises foreground generation quality. Moreover, these methods introduce\nunwanted artifacts in the transition area. In this paper, we formulate image\ncomposition as a subject-based local editing task, solely focusing on\nforeground generation. At each step, the edited foreground is combined with the\nnoisy background to maintain scene consistency. To address the remaining\nissues, we propose PrimeComposer, a faster training-free diffuser that\ncomposites the images by well-designed attention steering across different\nnoise levels. This steering is predominantly achieved by our Correlation\nDiffuser, utilizing its self-attention layers at each step. Within these\nlayers, the synthesized subject interacts with both the referenced object and\nbackground, capturing intricate details and coherent relationships. This prior\ninformation is encoded into the attention weights, which are then integrated\ninto the self-attention layers of the generator to guide the synthesis process.\nBesides, we introduce a Region-constrained Cross-Attention to confine the\nimpact of specific subject-related tokens to desired regions, addressing the\nunwanted artifacts shown in the prior method thereby further improving the\ncoherence in the transition area. Our method exhibits the fastest inference\nefficiency and extensive experiments demonstrate our superiority both\nqualitatively and quantitatively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACMMM2024. Code:\n  https://github.com/CodeGoat24/PrimeComposer",
    "pdf_url": "http://arxiv.org/pdf/2403.05053v3",
    "published_date": "2024-03-08 04:58:49 UTC",
    "updated_date": "2024-08-20 05:14:00 UTC"
  },
  {
    "arxiv_id": "2403.05050v4",
    "title": "DyRoNet: Dynamic Routing and Low-Rank Adapters for Autonomous Driving Streaming Perception",
    "authors": [
      "Xiang Huang",
      "Zhi-Qi Cheng",
      "Jun-Yan He",
      "Chenyang Li",
      "Wangmeng Xiang",
      "Baigui Sun"
    ],
    "abstract": "The advancement of autonomous driving systems hinges on the ability to\nachieve low-latency and high-accuracy perception. To address this critical\nneed, this paper introduces Dynamic Routing Network (DyRoNet), a low-rank\nenhanced dynamic routing framework designed for streaming perception in\nautonomous driving systems. DyRoNet integrates a suite of pre-trained branch\nnetworks, each meticulously fine-tuned to function under distinct environmental\nconditions. At its core, the framework offers a speed router module, developed\nto assess and route input data to the most suitable branch for processing. This\napproach not only addresses the inherent limitations of conventional models in\nadapting to diverse driving conditions but also ensures the balance between\nperformance and efficiency. Extensive experimental evaluations demonstrate the\nadaptability of DyRoNet to diverse branch selection strategies, resulting in\nsignificant performance enhancements across different scenarios. This work\nestablishes a new benchmark for streaming perception and provides valuable\nengineering insights for future work.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to WACV 2025. 17 pages, 8 figures. Project:\n  https://tastevision.github.io/DyRoNet/",
    "pdf_url": "http://arxiv.org/pdf/2403.05050v4",
    "published_date": "2024-03-08 04:53:53 UTC",
    "updated_date": "2024-12-15 20:29:34 UTC"
  },
  {
    "arxiv_id": "2403.05045v1",
    "title": "Are Human Conversations Special? A Large Language Model Perspective",
    "authors": [
      "Toshish Jawale",
      "Chaitanya Animesh",
      "Sekhar Vallath",
      "Kartik Talamadupula",
      "Larry Heck"
    ],
    "abstract": "This study analyzes changes in the attention mechanisms of large language\nmodels (LLMs) when used to understand natural conversations between humans\n(human-human). We analyze three use cases of LLMs: interactions over web\ncontent, code, and mathematical texts. By analyzing attention distance,\ndispersion, and interdependency across these domains, we highlight the unique\nchallenges posed by conversational data. Notably, conversations require nuanced\nhandling of long-term contextual relationships and exhibit higher complexity\nthrough their attention patterns. Our findings reveal that while language\nmodels exhibit domain-specific attention behaviors, there is a significant gap\nin their ability to specialize in human conversations. Through detailed\nattention entropy analysis and t-SNE visualizations, we demonstrate the need\nfor models trained with a diverse array of high-quality conversational data to\nenhance understanding and generation of human-like dialogue. This research\nhighlights the importance of domain specialization in language models and\nsuggests pathways for future advancement in modeling human conversational\nnuances.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05045v1",
    "published_date": "2024-03-08 04:44:25 UTC",
    "updated_date": "2024-03-08 04:44:25 UTC"
  },
  {
    "arxiv_id": "2403.05033v1",
    "title": "Quantifying Manifolds: Do the manifolds learned by Generative Adversarial Networks converge to the real data manifold",
    "authors": [
      "Anupam Chaudhuri",
      "Anj Simmons",
      "Mohamed Abdelrazek"
    ],
    "abstract": "This paper presents our experiments to quantify the manifolds learned by ML\nmodels (in our experiment, we use a GAN model) as they train. We compare the\nmanifolds learned at each epoch to the real manifolds representing the real\ndata. To quantify a manifold, we study the intrinsic dimensions and topological\nfeatures of the manifold learned by the ML model, how these metrics change as\nwe continue to train the model, and whether these metrics convergence over the\ncourse of training to the metrics of the real data manifold.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2311.13102",
    "pdf_url": "http://arxiv.org/pdf/2403.05033v1",
    "published_date": "2024-03-08 04:23:50 UTC",
    "updated_date": "2024-03-08 04:23:50 UTC"
  },
  {
    "arxiv_id": "2403.05030v4",
    "title": "Defending Against Unforeseen Failure Modes with Latent Adversarial Training",
    "authors": [
      "Stephen Casper",
      "Lennart Schulze",
      "Oam Patel",
      "Dylan Hadfield-Menell"
    ],
    "abstract": "Despite extensive diagnostics and debugging by developers, AI systems\nsometimes exhibit harmful unintended behaviors. Finding and fixing these is\nchallenging because the attack surface is so large -- it is not tractable to\nexhaustively search for inputs that may elicit harmful behaviors. Red-teaming\nand adversarial training (AT) are commonly used to improve robustness, however,\nthey empirically struggle to fix failure modes that differ from the attacks\nused during training. In this work, we utilize latent adversarial training\n(LAT) to defend against vulnerabilities without leveraging knowledge of what\nthey are or using inputs that elicit them. LAT makes use of the compressed,\nabstract, and structured latent representations of concepts that the network\nactually uses for prediction. Here, we use it to defend against failure modes\nwithout examples that elicit them. Specifically, we use LAT to remove trojans\nand defend against held-out classes of adversarial attacks. We show in image\nclassification, text classification, and text generation tasks that LAT usually\nimproves both robustness to novel attacks and performance on clean data\nrelative to AT. This suggests that LAT can be a promising tool for defending\nagainst failure modes that are not explicitly identified by developers.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05030v4",
    "published_date": "2024-03-08 04:22:48 UTC",
    "updated_date": "2024-08-22 00:24:50 UTC"
  },
  {
    "arxiv_id": "2403.05029v2",
    "title": "BjTT: A Large-scale Multimodal Dataset for Traffic Prediction",
    "authors": [
      "Chengyang Zhang",
      "Yong Zhang",
      "Qitan Shao",
      "Jiangtao Feng",
      "Bo Li",
      "Yisheng Lv",
      "Xinglin Piao",
      "Baocai Yin"
    ],
    "abstract": "Traffic prediction is one of the most significant foundations in Intelligent\nTransportation Systems (ITS). Traditional traffic prediction methods rely only\non historical traffic data to predict traffic trends and face two main\nchallenges. 1) insensitivity to unusual events. 2) limited performance in\nlong-term prediction. In this work, we explore how generative models combined\nwith text describing the traffic system can be applied for traffic generation,\nand name the task Text-to-Traffic Generation (TTG). The key challenge of the\nTTG task is how to associate text with the spatial structure of the road\nnetwork and traffic data for generating traffic situations. To this end, we\npropose ChatTraffic, the first diffusion model for text-to-traffic generation.\nTo guarantee the consistency between synthetic and real data, we augment a\ndiffusion model with the Graph Convolutional Network (GCN) to extract spatial\ncorrelations of traffic data. In addition, we construct a large dataset\ncontaining text-traffic pairs for the TTG task. We benchmarked our model\nqualitatively and quantitatively on the released dataset. The experimental\nresults indicate that ChatTraffic can generate realistic traffic situations\nfrom the text. Our code and dataset are available at\nhttps://github.com/ChyaZhang/ChatTraffic.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05029v2",
    "published_date": "2024-03-08 04:19:56 UTC",
    "updated_date": "2024-03-14 08:10:47 UTC"
  },
  {
    "arxiv_id": "2403.18846v2",
    "title": "The Blind Normalized Stein Variational Gradient Descent-Based Detection for Intelligent Random Access in Cellular IoT",
    "authors": [
      "Xin Zhu",
      "Ahmet Enis Cetin"
    ],
    "abstract": "The lack of an efficient preamble detection algorithm remains a challenge for\nsolving preamble collision problems in intelligent random access (RA) in the\ncellular Internet of Things (IoT). To address this problem, we present an early\npreamble detection scheme based on a maximum likelihood estimation (MLE) model\nat the first step of the grant-based RA procedure. A novel blind normalized\nStein variational gradient descent (SVGD)-based detector is proposed to obtain\nan approximate solution to the MLE model. First, by exploring the relationship\nbetween the Hadamard transform and wavelet packet transform, a new modified\nHadamard transform (MHT) is developed to separate high-frequency components\nfrom signals using the second-order derivative filter. Next, to eliminate noise\nand mitigate the vanishing gradients problem in the SVGD-based detectors, the\nblock MHT layer is designed based on the MHT, scaling layer, soft-thresholding\nlayer, inverse MHT and sparsity penalty. Then, the blind normalized SVGD\nalgorithm is derived to perform preamble detection without prior knowledge of\nnoise power and the number of active IoT devices. The experimental results show\nthe proposed block MHT layer outperforms other transform-based methods in terms\nof computation costs and denoising performance. Furthermore, with the\nassistance of the block MHT layer, the proposed blind normalized SVGD algorithm\nachieves a higher preamble detection accuracy and throughput than other\nstate-of-the-art detection methods.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "Accepted by the IEEE Internet of Things Journal",
    "pdf_url": "http://arxiv.org/pdf/2403.18846v2",
    "published_date": "2024-03-08 04:08:40 UTC",
    "updated_date": "2025-01-20 20:57:43 UTC"
  },
  {
    "arxiv_id": "2403.05026v1",
    "title": "Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts",
    "authors": [
      "Zeyang Zhang",
      "Xin Wang",
      "Ziwei Zhang",
      "Zhou Qin",
      "Weigao Wen",
      "Hui Xue",
      "Haoyang Li",
      "Wenwu Zhu"
    ],
    "abstract": "Dynamic graph neural networks (DyGNNs) currently struggle with handling\ndistribution shifts that are inherent in dynamic graphs. Existing work on\nDyGNNs with out-of-distribution settings only focuses on the time domain,\nfailing to handle cases involving distribution shifts in the spectral domain.\nIn this paper, we discover that there exist cases with distribution shifts\nunobservable in the time domain while observable in the spectral domain, and\npropose to study distribution shifts on dynamic graphs in the spectral domain\nfor the first time. However, this investigation poses two key challenges: i) it\nis non-trivial to capture different graph patterns that are driven by various\nfrequency components entangled in the spectral domain; and ii) it remains\nunclear how to handle distribution shifts with the discovered spectral\npatterns. To address these challenges, we propose Spectral Invariant Learning\nfor Dynamic Graphs under Distribution Shifts (SILD), which can handle\ndistribution shifts on dynamic graphs by capturing and utilizing invariant and\nvariant spectral patterns. Specifically, we first design a DyGNN with Fourier\ntransform to obtain the ego-graph trajectory spectrums, allowing the mixed\ndynamic graph patterns to be transformed into separate frequency components. We\nthen develop a disentangled spectrum mask to filter graph dynamics from various\nfrequency components and discover the invariant and variant spectral patterns.\nFinally, we propose invariant spectral filtering, which encourages the model to\nrely on invariant patterns for generalization under distribution shifts.\nExperimental results on synthetic and real-world dynamic graph datasets\ndemonstrate the superiority of our method for both node classification and link\nprediction tasks under distribution shifts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS'23",
    "pdf_url": "http://arxiv.org/pdf/2403.05026v1",
    "published_date": "2024-03-08 04:07:23 UTC",
    "updated_date": "2024-03-08 04:07:23 UTC"
  },
  {
    "arxiv_id": "2403.05025v3",
    "title": "Debiased Multimodal Understanding for Human Language Sequences",
    "authors": [
      "Zhi Xu",
      "Dingkang Yang",
      "Mingcheng Li",
      "Yuzheng Wang",
      "Zhaoyu Chen",
      "Jiawei Chen",
      "Jinjie Wei",
      "Lihua Zhang"
    ],
    "abstract": "Human multimodal language understanding (MLU) is an indispensable component\nof expression analysis (e.g., sentiment or humor) from heterogeneous\nmodalities, including visual postures, linguistic contents, and acoustic\nbehaviours. Existing works invariably focus on designing sophisticated\nstructures or fusion strategies to achieve impressive improvements.\nUnfortunately, they all suffer from the subject variation problem due to data\ndistribution discrepancies among subjects. Concretely, MLU models are easily\nmisled by distinct subjects with different expression customs and\ncharacteristics in the training data to learn subject-specific spurious\ncorrelations, limiting performance and generalizability across new subjects.\nMotivated by this observation, we introduce a recapitulative causal graph to\nformulate the MLU procedure and analyze the confounding effect of subjects.\nThen, we propose SuCI, a simple yet effective causal intervention module to\ndisentangle the impact of subjects acting as unobserved confounders and achieve\nmodel training via true causal effects. As a plug-and-play component, SuCI can\nbe widely applied to most methods that seek unbiased predictions. Comprehensive\nexperiments on several MLU benchmarks clearly show the effectiveness of the\nproposed module.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2403.05025v3",
    "published_date": "2024-03-08 04:03:54 UTC",
    "updated_date": "2024-12-13 03:49:02 UTC"
  },
  {
    "arxiv_id": "2403.05020v4",
    "title": "Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs",
    "authors": [
      "Xuhui Zhou",
      "Zhe Su",
      "Tiwalayo Eisape",
      "Hyunwoo Kim",
      "Maarten Sap"
    ],
    "abstract": "Recent advances in large language models (LLM) have enabled richer social\nsimulations, allowing for the study of various social phenomena. However, most\nrecent work has used a more omniscient perspective on these simulations (e.g.,\nsingle LLM to generate all interlocutors), which is fundamentally at odds with\nthe non-omniscient, information asymmetric interactions that involve humans and\nAI agents in the real world. To examine these differences, we develop an\nevaluation framework to simulate social interactions with LLMs in various\nsettings (omniscient, non-omniscient). Our experiments show that LLMs perform\nbetter in unrealistic, omniscient simulation settings but struggle in ones that\nmore accurately reflect real-world conditions with information asymmetry. Our\nfindings indicate that addressing information asymmetry remains a fundamental\nchallenge for LLM-based agents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.05020v4",
    "published_date": "2024-03-08 03:49:17 UTC",
    "updated_date": "2024-10-04 02:01:34 UTC"
  },
  {
    "arxiv_id": "2403.05014v1",
    "title": "Simple Multigraph Convolution Networks",
    "authors": [
      "Danyang Wu",
      "Xinjie Shen",
      "Jitao Lu",
      "Jin Xu",
      "Feiping Nie"
    ],
    "abstract": "Existing multigraph convolution methods either ignore the cross-view\ninteraction among multiple graphs, or induce extremely high computational cost\ndue to standard cross-view polynomial operators. To alleviate this problem,\nthis paper proposes a Simple MultiGraph Convolution Networks (SMGCN) which\nfirst extracts consistent cross-view topology from multigraphs including\nedge-level and subgraph-level topology, then performs polynomial expansion\nbased on raw multigraphs and consistent topologies. In theory, SMGCN utilizes\nthe consistent topologies in polynomial expansion rather than standard\ncross-view polynomial expansion, which performs credible cross-view spatial\nmessage-passing, follows the spectral convolution paradigm, and effectively\nreduces the complexity of standard polynomial expansion. In the simulations,\nexperimental results demonstrate that SMGCN achieves state-of-the-art\nperformance on ACM and DBLP multigraph benchmark datasets. Our codes are\navailable at https://github.com/frinkleko/SMGCN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by WWW 2024 Short",
    "pdf_url": "http://arxiv.org/pdf/2403.05014v1",
    "published_date": "2024-03-08 03:27:58 UTC",
    "updated_date": "2024-03-08 03:27:58 UTC"
  },
  {
    "arxiv_id": "2403.05010v3",
    "title": "RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction",
    "authors": [
      "Peng Liu",
      "Dongyang Dai",
      "Zhiyong Wu"
    ],
    "abstract": "Recent advancements in generative modeling have significantly enhanced the\nreconstruction of audio waveforms from various representations. While diffusion\nmodels are adept at this task, they are hindered by latency issues due to their\noperation at the individual sample point level and the need for numerous\nsampling steps. In this study, we introduce RFWave, a cutting-edge multi-band\nRectified Flow approach designed to reconstruct high-fidelity audio waveforms\nfrom Mel-spectrograms or discrete acoustic tokens. RFWave uniquely generates\ncomplex spectrograms and operates at the frame level, processing all subbands\nsimultaneously to boost efficiency. Leveraging Rectified Flow, which targets a\nstraight transport trajectory, RFWave achieves reconstruction with just 10\nsampling steps. Our empirical evaluations show that RFWave not only provides\noutstanding reconstruction quality but also offers vastly superior\ncomputational efficiency, enabling audio generation at speeds up to 160 times\nfaster than real-time on a GPU. An online demonstration is available at:\nhttps://rfwave-demo.github.io/rfwave/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05010v3",
    "published_date": "2024-03-08 03:16:47 UTC",
    "updated_date": "2024-10-07 02:08:05 UTC"
  },
  {
    "arxiv_id": "2403.05006v1",
    "title": "Provable Multi-Party Reinforcement Learning with Diverse Human Feedback",
    "authors": [
      "Huiying Zhong",
      "Zhun Deng",
      "Weijie J. Su",
      "Zhiwei Steven Wu",
      "Linjun Zhang"
    ],
    "abstract": "Reinforcement learning with human feedback (RLHF) is an emerging paradigm to\nalign models with human preferences. Typically, RLHF aggregates preferences\nfrom multiple individuals who have diverse viewpoints that may conflict with\neach other. Our work \\textit{initiates} the theoretical study of multi-party\nRLHF that explicitly models the diverse preferences of multiple individuals. We\nshow how traditional RLHF approaches can fail since learning a single reward\nfunction cannot capture and balance the preferences of multiple individuals. To\novercome such limitations, we incorporate meta-learning to learn multiple\npreferences and adopt different social welfare functions to aggregate the\npreferences across multiple parties. We focus on the offline learning setting\nand establish sample complexity bounds, along with efficiency and fairness\nguarantees, for optimizing diverse social welfare functions such as Nash,\nUtilitarian, and Leximin welfare functions. Our results show a separation\nbetween the sample complexities of multi-party RLHF and traditional\nsingle-party RLHF. Furthermore, we consider a reward-free setting, where each\nindividual's preference is no longer consistent with a reward model, and give\npessimistic variants of the von Neumann Winner based on offline preference\ndata. Taken together, our work showcases the advantage of multi-party RLHF but\nalso highlights its more demanding statistical complexity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05006v1",
    "published_date": "2024-03-08 03:05:11 UTC",
    "updated_date": "2024-03-08 03:05:11 UTC"
  },
  {
    "arxiv_id": "2403.05004v1",
    "title": "Can't Remember Details in Long Documents? You Need Some R&R",
    "authors": [
      "Devanshu Agrawal",
      "Shang Gao",
      "Martin Gajek"
    ],
    "abstract": "Long-context large language models (LLMs) hold promise for tasks such as\nquestion-answering (QA) over long documents, but they tend to miss important\ninformation in the middle of context documents (arXiv:2307.03172v3). Here, we\nintroduce $\\textit{R&R}$ -- a combination of two novel prompt-based methods\ncalled $\\textit{reprompting}$ and $\\textit{in-context retrieval}$ (ICR) -- to\nalleviate this effect in document-based QA. In reprompting, we repeat the\nprompt instructions periodically throughout the context document to remind the\nLLM of its original task. In ICR, rather than instructing the LLM to answer the\nquestion directly, we instruct it to retrieve the top $k$ passage numbers most\nrelevant to the given question, which are then used as an abbreviated context\nin a second QA prompt. We test R&R with GPT-4 Turbo and Claude-2.1 on documents\nup to 80k tokens in length and observe a 16-point boost in QA accuracy on\naverage. Our further analysis suggests that R&R improves performance on long\ndocument-based QA because it reduces the distance between relevant context and\nthe instructions. Finally, we show that compared to short-context chunkwise\nmethods, R&R enables the use of larger chunks that cost fewer LLM calls and\noutput tokens, while minimizing the drop in accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 1 figure, 9 tables. For associated code repository see\n  https://github.com/casetext/r-and-r",
    "pdf_url": "http://arxiv.org/pdf/2403.05004v1",
    "published_date": "2024-03-08 03:03:20 UTC",
    "updated_date": "2024-03-08 03:03:20 UTC"
  },
  {
    "arxiv_id": "2403.05000v3",
    "title": "Medical Speech Symptoms Classification via Disentangled Representation",
    "authors": [
      "Jianzong Wang",
      "Pengcheng Li",
      "Xulong Zhang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "abstract": "Intent is defined for understanding spoken language in existing works. Both\ntextual features and acoustic features involved in medical speech contain\nintent, which is important for symptomatic diagnosis. In this paper, we propose\na medical speech classification model named DRSC that automatically learns to\ndisentangle intent and content representations from textual-acoustic data for\nclassification. The intent representations of the text domain and the\nMel-spectrogram domain are extracted via intent encoders, and then the\nreconstructed text feature and the Mel-spectrogram feature are obtained through\ntwo exchanges. After combining the intent from two domains into a joint\nrepresentation, the integrated intent representation is fed into a decision\nlayer for classification. Experimental results show that our model obtains an\naverage accuracy rate of 95% in detecting 25 different medical symptoms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by the 27th International Conference on Computer Supported\n  Cooperative Work in Design (CSCWD 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.05000v3",
    "published_date": "2024-03-08 02:42:34 UTC",
    "updated_date": "2024-04-30 01:47:37 UTC"
  },
  {
    "arxiv_id": "2403.04977v1",
    "title": "Node Centrality Approximation For Large Networks Based On Inductive Graph Neural Networks",
    "authors": [
      "Yiwei Zou",
      "Ting Li",
      "Zong-fu Luo"
    ],
    "abstract": "Closeness Centrality (CC) and Betweenness Centrality (BC) are crucial metrics\nin network analysis, providing essential reference for discerning the\nsignificance of nodes within complex networks. These measures find wide\napplications in critical tasks, such as community detection and network\ndismantling. However, their practical implementation on extensive networks\nremains computationally demanding due to their high time complexity. To\nmitigate these computational challenges, numerous approximation algorithms have\nbeen developed to expedite the computation of CC and BC. Nevertheless, even\nthese approximations still necessitate substantial processing time when applied\nto large-scale networks. Furthermore, their output proves sensitive to even\nminor perturbations within the network structure.\n  In this work, We redefine the CC and BC node ranking problem as a machine\nlearning problem and propose the CNCA-IGE model, which is an encoder-decoder\nmodel based on inductive graph neural networks designed to rank nodes based on\nspecified CC or BC metrics. We incorporate the MLP-Mixer model as the decoder\nin the BC ranking prediction task to enhance the model's robustness and\ncapacity. Our approach is evaluated on diverse synthetic and real-world\nnetworks of varying scales, and the experimental results demonstrate that the\nCNCA-IGE model outperforms state-of-the-art baseline models, significantly\nreducing execution time while improving performance.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04977v1",
    "published_date": "2024-03-08 01:23:12 UTC",
    "updated_date": "2024-03-08 01:23:12 UTC"
  },
  {
    "arxiv_id": "2403.04965v2",
    "title": "StereoDiffusion: Training-Free Stereo Image Generation Using Latent Diffusion Models",
    "authors": [
      "Lezhong Wang",
      "Jeppe Revall Frisvad",
      "Mark Bo Jensen",
      "Siavash Arjomand Bigdeli"
    ],
    "abstract": "The demand for stereo images increases as manufacturers launch more XR\ndevices. To meet this demand, we introduce StereoDiffusion, a method that,\nunlike traditional inpainting pipelines, is trainning free, remarkably\nstraightforward to use, and it seamlessly integrates into the original Stable\nDiffusion model. Our method modifies the latent variable to provide an\nend-to-end, lightweight capability for fast generation of stereo image pairs,\nwithout the need for fine-tuning model weights or any post-processing of\nimages. Using the original input to generate a left image and estimate a\ndisparity map for it, we generate the latent vector for the right image through\nStereo Pixel Shift operations, complemented by Symmetric Pixel Shift Masking\nDenoise and Self-Attention Layers Modification methods to align the right-side\nimage with the left-side image. Moreover, our proposed method maintains a high\nstandard of image quality throughout the stereo generation process, achieving\nstate-of-the-art scores in various quantitative evaluations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Updated to CVPR 2024 GCV accepted version",
    "pdf_url": "http://arxiv.org/pdf/2403.04965v2",
    "published_date": "2024-03-08 00:30:25 UTC",
    "updated_date": "2024-06-02 14:31:09 UTC"
  },
  {
    "arxiv_id": "2403.04964v2",
    "title": "Tell me the truth: A system to measure the trustworthiness of Large Language Models",
    "authors": [
      "Carlo Lipizzi"
    ],
    "abstract": "Large Language Models (LLM) have taken the front seat in most of the news\nsince November 2022, when ChatGPT was introduced. After more than one year, one\nof the major reasons companies are resistant to adopting them is the limited\nconfidence they have in the trustworthiness of those systems. In a study by\n(Baymard, 2023), ChatGPT-4 showed an 80.1% false-positive error rate in\nidentifying usability issues on websites. A Jan. '24 study by JAMA Pediatrics\nfound that ChatGPT has an accuracy rate of 17% percent when diagnosing\npediatric medical cases (Barile et al., 2024). But then, what is \"trust\"? Trust\nis a relative, subject condition that can change based on culture, domain,\nindividuals. And then, given a domain, how can the trustworthiness of a system\nbe measured? In this paper, I present a systematic approach to measure\ntrustworthiness based on a predefined ground truth, represented as a knowledge\ngraph of the domain. The approach is a process with humans in the loop to\nvalidate the representation of the domain and to fine-tune the system.\n  Measuring the trustworthiness would be essential for all the entities\noperating in critical environments, such as healthcare, defense, finance, but\nit would be very relevant for all the users of LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04964v2",
    "published_date": "2024-03-08 00:27:57 UTC",
    "updated_date": "2024-03-11 18:41:29 UTC"
  },
  {
    "arxiv_id": "2403.04963v2",
    "title": "An In-depth Evaluation of Large Language Models in Sentence Simplification with Error-based Human Assessment",
    "authors": [
      "Xuanxin Wu",
      "Yuki Arase"
    ],
    "abstract": "Recent studies have used both automatic metrics and human evaluations to\nassess the simplification abilities of LLMs. However, the suitability of\nexisting evaluation methodologies for LLMs remains in question. First, the\nsuitability of current automatic metrics on LLMs' simplification evaluation is\nstill uncertain. Second, current human evaluation approaches in sentence\nsimplification often fall into two extremes: they are either too superficial,\nfailing to offer a clear understanding of the models' performance, or overly\ndetailed, making the annotation process complex and prone to inconsistency,\nwhich in turn affects the evaluation's reliability. To address these problems,\nthis study provides in-depth insights into LLMs' performance while ensuring the\nreliability of the evaluation. We design an error-based human annotation\nframework to assess the LLMs' simplification capabilities. We select both\nclosed-source and open-source LLMs, including GPT-4, Qwen2.5-72B, and\nLlama-3.2-3B. We believe that these models offer a representative selection\nacross large, medium, and small sizes of LLMs. Results show that GPT-4\ngenerally generates fewer erroneous simplification outputs compared to the\ncurrent state-of-the-art. However, LLMs have their limitations, as seen in\nGPT-4's struggles with lexical paraphrasing. Results show that LLMs generally\ngenerate fewer erroneous simplification outputs compared to the previous\nstate-of-the-art. However, LLMs have their limitations, as seen in GPT-4's and\nQwen2.5-72B's struggle with lexical paraphrasing. Furthermore, we conduct\nmeta-evaluations on widely used automatic metrics using our human annotations.\nWe find that these metrics lack sufficient sensitivity to assess the overall\nhigh-quality simplifications, particularly those generated by high-performance\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Extended evaluation with more LLMs and an additional dataset",
    "pdf_url": "http://arxiv.org/pdf/2403.04963v2",
    "published_date": "2024-03-08 00:19:24 UTC",
    "updated_date": "2025-04-08 02:31:31 UTC"
  },
  {
    "arxiv_id": "2403.04960v2",
    "title": "IsolateGPT: An Execution Isolation Architecture for LLM-Based Agentic Systems",
    "authors": [
      "Yuhao Wu",
      "Franziska Roesner",
      "Tadayoshi Kohno",
      "Ning Zhang",
      "Umar Iqbal"
    ],
    "abstract": "Large language models (LLMs) extended as systems, such as ChatGPT, have begun\nsupporting third-party applications. These LLM apps leverage the de facto\nnatural language-based automated execution paradigm of LLMs: that is, apps and\ntheir interactions are defined in natural language, provided access to user\ndata, and allowed to freely interact with each other and the system. These LLM\napp ecosystems resemble the settings of earlier computing platforms, where\nthere was insufficient isolation between apps and the system. Because\nthird-party apps may not be trustworthy, and exacerbated by the imprecision of\nnatural language interfaces, the current designs pose security and privacy\nrisks for users. In this paper, we evaluate whether these issues can be\naddressed through execution isolation and what that isolation might look like\nin the context of LLM-based systems, where there are arbitrary natural\nlanguage-based interactions between system components, between LLM and apps,\nand between apps. To that end, we propose IsolateGPT, a design architecture\nthat demonstrates the feasibility of execution isolation and provides a\nblueprint for implementing isolation, in LLM-based systems. We evaluate\nIsolateGPT against a number of attacks and demonstrate that it protects against\nmany security, privacy, and safety issues that exist in non-isolated LLM-based\nsystems, without any loss of functionality. The performance overhead incurred\nby IsolateGPT to improve security is under 30% for three-quarters of tested\nqueries.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by the Network and Distributed System Security (NDSS)\n  Symposium 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.04960v2",
    "published_date": "2024-03-08 00:02:30 UTC",
    "updated_date": "2025-01-30 22:55:18 UTC"
  }
]