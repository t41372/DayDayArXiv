{
  "date": "2025-04-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-13 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 66 篇论文，主要聚焦于 AI 模型优化、多模态学习和 LLM 在医疗、推荐系统及安全领域的创新应用，其中 LLM 相关研究占比最高，令人印象深刻的包括评估 LLM 研究能力的 MLRC-Bench 和用于疾病诊断的 ClinicalGPT-R1，这些论文突出了 LLM 在实际场景中的潜力，同时也有一些知名机构如 Google 的代码迁移工作值得关注。\n\n### 重点论文讨论\n我将优先讨论重要、话题度高或创新性强的论文（如 LLM 增强和多模态应用），并将相关主题归类讨论。其他较常规的论文（如优化算法或特定领域小改进）将简要掠过，以控制篇幅。\n\n**LLM 增强与应用（高话题度领域）**  \n- **Can LLM feedback enhance review quality? A randomized study of 20K reviews at ICLR 2025（LLM 反馈提升同行评审质量？ICLR 2025 的 20K 评审随机研究）**  \n  这篇论文由 Animesh Garg 和 James Zou 等学者主导，引入 Review Feedback Agent 系统，利用 LLM 提供反馈以改善评审的清晰度和可操作性。主要贡献是通过大规模随机实验证明，27% 的评审者更新了反馈，平均增加 80 词的评审长度，并提升了作者互动；这为 AI 在学术评审中的应用提供了新路径，强调 LLM 可增强评审质量而非取代人类。\n\n- **MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?（MLRC-Bench: 语言代理能解决机器学习研究挑战吗？）**  \n  论文评估 LLM 代理在机器学习竞赛中的表现，使用 7 个任务基准。主要发现是最佳代理仅关闭了 9.3% 的性能差距，并揭示 LLM 在创新评估上存在偏差；这篇工作突出了 LLM 在复杂研究任务的局限性，提供了一个动态基准，促进 AI 研究能力的客观评估。\n\n- **Migrating Code At Scale With LLMs At Google（使用 LLM 在 Google 进行大规模代码迁移）**  \n  Google 团队提出算法，利用 LLM 辅助代码迁移，处理框架升级等任务。主要贡献是自动化生成 74.45% 的代码变更，减少了 50% 的手动时间；这展示了 LLM 在实际软件工程中的高效应用，强调了其在减少开发者负担方面的潜力。\n\n- **EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety（EmoAgent: 评估和保护人类-AI 互动以确保心理健康安全）**  \n  论文开发了多代理框架 EmoAgent，用于检测 AI 对话对心理脆弱用户的负面影响。主要发现是 34.4% 的模拟中用户心理状态恶化，但防护机制可显著降低这一率；这篇工作强调 AI 在心理健康领域的伦理责任，提供可扩展的防护工具。\n\n- **ClinicalGPT-R1: Pushing reasoning capability of generalist disease diagnosis with large language model（ClinicalGPT-R1: 提升通用疾病诊断的推理能力）**  \n  研究团队构建了 ClinicalGPT-R1，通过训练 20,000 条临床记录增强诊断推理。主要贡献是超越 GPT-4 在中文任务中的表现，并在 MedBench-Hard 上表现出色；这为 LLM 在医疗诊断的实际部署提供了新基准，突出了其在跨语言场景中的鲁棒性。\n\n- **HalluShift: Measuring Distribution Shifts towards Hallucination Detection in LLMs（HalluShift: 测量分布偏移以检测 LLM 中的幻觉）**  \n  论文提出信息理论方法检测 LLM 幻觉，分析内部状态空间偏移。主要发现是新方法比基线提升 50-95% 的检测准确率；这有助于理解 LLM 的幻觉机制，提供无训练干预策略，提升模型可靠性。\n\n其他 LLM 相关论文，如 **Slow Thinking for Sequential Recommendation（慢思考用于序列推荐）** 和 **Distilling Transitional Pattern to Large Language Models for Multimodal Session-based Recommendation（为多模态会话推荐提炼过渡模式）**，则展示了 LLM 在推荐系统的推理优化，但细节较常规，仅提升了序列建模的准确性，建议感兴趣读者查阅。\n\n**多模态学习与视觉应用（创新框架突出）**  \n- **InfoMAE: Pair-Efficient Cross-Modal Alignment for Multimodal Time-Series Sensing Signals（InfoMAE: 高效跨模态对齐用于多模态时间序列传感信号）**  \n  该框架通过信息理论方法处理 IoT 数据对稀缺问题，实现 60% 以上的任务提升。主要贡献是减少数据对需求，同时提高单模态任务准确率 22%；这为多模态传感器应用提供了高效预训练策略。\n\n- **TextSplat: Text-Guided Semantic Fusion for Generalizable Gaussian Splatting（TextSplat: 文本引导的语义融合用于通用高斯散斑）**  \n  论文引入文本引导框架，提升 3D 重建的语义准确性。主要发现是通过多模块融合，显著改善了复杂场景的细节捕捉；这在多模态视觉任务中具有潜力，适用于机器人和图形生成。\n\n其他视觉论文如 **snnTrans-DHZ: A Lightweight Spiking Neural Network Architecture for Underwater Image Dehazing（snnTrans-DHZ: 轻量级脉冲神经网络用于水下图像去雾）**，实现了高效水下图像增强，但作为特定应用，影响较局部，仅提及其在机器人部署中的能量效率。\n\n**医疗与生物AI（实际影响大）**  \n- **Transformer-Based Representation Learning for Robust Gene Expression Modeling and Cancer Prognosis（基于 Transformer 的鲁棒基因表达建模用于癌症预后）**  \n  GexBERT 框架通过掩码恢复目标捕获基因共表达关系，主要贡献是提升癌症分类和预后预测准确性；这为基因数据处理提供了可扩展工具，突出了 Transformer 在生物医学中的潜力。\n\n其他医疗论文如 **Evaluating the Quality of Benchmark Datasets for Low-Resource Languages: A Case Study on Turkish（评估低资源语言基准数据集质量：土耳其案例研究）**，强调了数据集质量控制，但作为语言特定问题，快速掠过。\n\n**机器人与AI安全（快速提及）**  \n- **Adapting Robot's Explanation for Failures Based on Observed Human Behavior in Human-Robot Collaboration（基于人类行为适应机器人故障解释）**  \n  论文提出数据驱动预测器优化机器人解释，主要发现是提升了协作体验；这在人机互动中实用。\n\n其他如 **AgentDynEx: Nudging the Mechanics and Dynamics of Multi-Agent Simulations（AgentDynEx: 微调多代理模拟的机制和动态）**，涉及代理模拟优化，但作为概念性工作，影响有限。\n\n其余论文，如优化算法（Improved FOX Optimization Algorithm）和量子计算（The Quantum LLM），多为技术细化或特定领域改进，篇幅所限，仅简要提及它们提供了高效算法或理论框架，但未见重大突破，不做深入讨论。\n\n总之，今天的 arXiv 更新突显了 LLM 在多领域的潜力，但也暴露了安全和泛化挑战。感兴趣的读者可关注上述关键论文，获取更多细节！",
  "papers": [
    {
      "arxiv_id": "2504.09753v2",
      "title": "Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance",
      "title_zh": "通过文化和本地知识改进大语言模型的多语言能力，同时提升原生性能",
      "authors": [
        "Ram Mohan Rao Kadiyala",
        "Siddartha Pullakhandam",
        "Siddhant Gupta",
        "Drishti Sharma",
        "Jebish Purbey",
        "Kanwal Mehreen",
        "Muhammad Arham",
        "Hamza Farooq"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, but their\ndevelopment has primarily focused on English and other high-resource languages,\nleaving many languages underserved. We present our latest Hindi-English\nbi-lingual LLM \\textbf{Mantra-14B} with ~3\\% average improvement in benchmark\nscores over both languages, outperforming models twice its size. Using a\ncurated dataset composed of English and Hindi instruction data of 485K samples,\nwe instruction tuned models such as Qwen-2.5-14B-Instruct and Phi-4 to improve\nperformance over both English and Hindi. Our experiments encompassing seven\ndifferent LLMs of varying parameter sizes and over 140 training attempts with\nvarying English-Hindi training data ratios demonstrated that it is possible to\nsignificantly improve multilingual performance without compromising native\nperformance. Further, our approach avoids resource-intensive techniques like\nvocabulary expansion or architectural modifications, thus keeping the model\nsize small. Our results indicate that modest fine-tuning with culturally and\nlocally informed data can bridge performance gaps without incurring significant\ncomputational overhead. We release our training code, datasets, and models\nunder mit and apache licenses to aid further research towards under-represented\nand low-resource languages.",
      "tldr_zh": "本研究旨在提升大型语言模型（LLMs）的多语言能力，同时维持原生性能，焦点是通过文化和本地知识优化Hindi-English双语模型。研究团队开发了Mantra-14B模型，利用一个包含48.5K样本的English和Hindi指令数据集，对Qwen-2.5-14B-Instruct和Phi-4等模型进行指令微调，实现了在两种语言上平均3%的基准分数提升，并超过了更大规模的模型。通过超过140次训练尝试，实验证明这种方法能显著改善多语言性能，而无需采用资源密集型技术如词汇扩展。最终，该方法桥接了低资源语言的性能差距，并开源了训练代码、数据集和模型，以支持更多针对欠代表语言的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09753v2",
      "published_date": "2025-04-13 23:10:13 UTC",
      "updated_date": "2025-05-22 10:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:22:50.843494"
    },
    {
      "arxiv_id": "2504.09738v1",
      "title": "Automatic Detection of Intro and Credits in Video using CLIP and Multihead Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Vasilii Korolkov",
        "Andrey Yanchenko"
      ],
      "abstract": "Detecting transitions between intro/credits and main content in videos is a\ncrucial task for content segmentation, indexing, and recommendation systems.\nManual annotation of such transitions is labor-intensive and error-prone, while\nheuristic-based methods often fail to generalize across diverse video styles.\nIn this work, we introduce a deep learning-based approach that formulates the\nproblem as a sequence-to-sequence classification task, where each second of a\nvideo is labeled as either \"intro\" or \"film.\" Our method extracts frames at a\nfixed rate of 1 FPS, encodes them using CLIP (Contrastive Language-Image\nPretraining), and processes the resulting feature representations with a\nmultihead attention model incorporating learned positional encoding. The system\nachieves an F1-score of 91.0%, Precision of 89.0%, and Recall of 97.0% on the\ntest set, and is optimized for real-time inference, achieving 11.5 FPS on CPU\nand 107 FPS on high-end GPUs. This approach has practical applications in\nautomated content indexing, highlight detection, and video summarization.\nFuture work will explore multimodal learning, incorporating audio features and\nsubtitles to further enhance detection accuracy.",
      "tldr_zh": "本文提出了一种自动检测视频 intro 和 credits 的深度学习方法，使用 CLIP 提取帧特征，并结合多头注意力（Multihead Attention）模型和位置编码，将问题转化为序列到序列分类任务，以提高检测的泛化性和效率。方法每秒提取一帧（1 FPS）进行编码和处理，实现了高性能指标：在测试集上 F1-score 达到 91.0%、Precision 89.0% 和 Recall 97.0%，并支持实时推理（CPU 上 11.5 FPS，GPU 上 107 FPS）。该方法适用于自动化内容索引、亮点检测和视频总结等领域，未来工作将探索多模态学习，融入音频和字幕以进一步提升准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "68T07",
        "I.2.10; I.4.8; I.5.1"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 11 figures, submitted as a preprint. ArXiv preprint only,\n  not submitted to a journal yet",
      "pdf_url": "http://arxiv.org/pdf/2504.09738v1",
      "published_date": "2025-04-13 22:08:18 UTC",
      "updated_date": "2025-04-13 22:08:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:23:03.627561"
    },
    {
      "arxiv_id": "2504.09737v1",
      "title": "Can LLM feedback enhance review quality? A randomized study of 20K reviews at ICLR 2025",
      "title_zh": "翻译失败",
      "authors": [
        "Nitya Thakkar",
        "Mert Yuksekgonul",
        "Jake Silberg",
        "Animesh Garg",
        "Nanyun Peng",
        "Fei Sha",
        "Rose Yu",
        "Carl Vondrick",
        "James Zou"
      ],
      "abstract": "Peer review at AI conferences is stressed by rapidly rising submission\nvolumes, leading to deteriorating review quality and increased author\ndissatisfaction. To address these issues, we developed Review Feedback Agent, a\nsystem leveraging multiple large language models (LLMs) to improve review\nclarity and actionability by providing automated feedback on vague comments,\ncontent misunderstandings, and unprofessional remarks to reviewers. Implemented\nat ICLR 2025 as a large randomized control study, our system provided optional\nfeedback to more than 20,000 randomly selected reviews. To ensure high-quality\nfeedback for reviewers at this scale, we also developed a suite of automated\nreliability tests powered by LLMs that acted as guardrails to ensure feedback\nquality, with feedback only being sent to reviewers if it passed all the tests.\nThe results show that 27% of reviewers who received feedback updated their\nreviews, and over 12,000 feedback suggestions from the agent were incorporated\nby those reviewers. This suggests that many reviewers found the AI-generated\nfeedback sufficiently helpful to merit updating their reviews. Incorporating AI\nfeedback led to significantly longer reviews (an average increase of 80 words\namong those who updated after receiving feedback) and more informative reviews,\nas evaluated by blinded researchers. Moreover, reviewers who were selected to\nreceive AI feedback were also more engaged during paper rebuttals, as seen in\nlonger author-reviewer discussions. This work demonstrates that carefully\ndesigned LLM-generated review feedback can enhance peer review quality by\nmaking reviews more specific and actionable while increasing engagement between\nreviewers and authors. The Review Feedback Agent is publicly available at\nhttps://github.com/zou-group/review_feedback_agent.",
      "tldr_zh": "这篇论文通过在 ICLR 2025 进行的大规模随机对照研究，探讨了使用大型语言模型 (LLMs) 的 Review Feedback Agent 是否能提升同行评审质量。该系统针对模糊评论、内容误解和不专业言论提供自动反馈，并在通过 LLM 驱动的可靠性测试后发送给超过 20,000 条随机选中的评审。结果显示，27% 的评审者更新了评审，平均增加 80 词，使评审更具信息性和可操作性，同时提升了作者与评审者的互动。研究证明，精心设计的 LLM 反馈能显著改善评审过程，并已将系统开源至 GitHub。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09737v1",
      "published_date": "2025-04-13 22:01:25 UTC",
      "updated_date": "2025-04-13 22:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:23:15.221916"
    },
    {
      "arxiv_id": "2504.09734v1",
      "title": "Dynamik: Syntactically-Driven Dynamic Font Sizing for Emphasis of Key Information",
      "title_zh": "Dynamik：语法驱动的动态字体大小调整以强调关键信息",
      "authors": [
        "Naoto Nishida",
        "Yoshio Ishiguro",
        "Jun Rekiomto",
        "Naomi Yamashita"
      ],
      "abstract": "In today's globalized world, there are increasing opportunities for\nindividuals to communicate using a common non-native language (lingua franca).\nNon-native speakers often have opportunities to listen to foreign languages,\nbut may not comprehend them as fully as native speakers do. To aid real-time\ncomprehension, live transcription of subtitles is frequently used in everyday\nlife (e.g., during Zoom conversations, watching YouTube videos, or on social\nnetworking sites). However, simultaneously reading subtitles while listening\ncan increase cognitive load. In this study, we propose Dynamik, a system that\nreduces cognitive load during reading by decreasing the size of less important\nwords and enlarging important ones, thereby enhancing sentence contrast. Our\nresults indicate that Dynamik can reduce certain aspects of cognitive load,\nspecifically, participants' perceived performance and effort among individuals\nwith low proficiency in English, as well as enhance the users' sense of\ncomprehension, especially among people with low English ability. We further\ndiscuss our methods' applicability to other languages and potential\nimprovements and further research directions.",
      "tldr_zh": "这篇论文介绍了 Dynamik 系统，它通过 Syntactically-Driven Dynamic Font Sizing（基于句法驱动的动态字体调整）来缩小不重要单词并放大关键信息，从而增强句子对比并减少非母语者在阅读实时字幕时的认知负荷。研究结果显示，该系统显著降低了英语水平低的参与者的感知表现和努力方面的认知负荷，同时提升了他们的理解感。作者进一步讨论了 Dynamik 的潜在扩展到其他语言，以及未来的改进和研究方向。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "30 pages, 11 figures, presented at The ACM Conference on Intelligent\n  User Interfaces (ACM IUI) 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.09734v1",
      "published_date": "2025-04-13 21:46:11 UTC",
      "updated_date": "2025-04-13 21:46:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:23:25.968276"
    },
    {
      "arxiv_id": "2504.09717v1",
      "title": "Adapting Robot's Explanation for Failures Based on Observed Human Behavior in Human-Robot Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Naoum",
        "Parag Khanna",
        "Elmira Yadollahi",
        "Mårten Björkman",
        "Christian Smith"
      ],
      "abstract": "This work aims to interpret human behavior to anticipate potential user\nconfusion when a robot provides explanations for failure, allowing the robot to\nadapt its explanations for more natural and efficient collaboration. Using a\ndataset that included facial emotion detection, eye gaze estimation, and\ngestures from 55 participants in a user study, we analyzed how human behavior\nchanged in response to different types of failures and varying explanation\nlevels. Our goal is to assess whether human collaborators are ready to accept\nless detailed explanations without inducing confusion. We formulate a\ndata-driven predictor to predict human confusion during robot failure\nexplanations. We also propose and evaluate a mechanism, based on the predictor,\nto adapt the explanation level according to observed human behavior. The\npromising results from this evaluation indicate the potential of this research\nin adapting a robot's explanations for failures to enhance the collaborative\nexperience.",
      "tldr_zh": "这篇论文旨在通过解读人类行为来预测用户在机器人失败解释时的潜在困惑，从而让机器人适应其解释以实现更自然、高效的人机协作。研究使用了一个数据集，包括来自55名参与者的面部情绪检测（facial emotion detection）、眼部注视估计（eye gaze estimation）和手势（gestures），分析人类对不同失败类型和解释级别的反应。作者开发了一个基于数据的预测器（data-driven predictor）来预测人类困惑，并提出了一种机制，根据观察到的行为动态调整解释级别。实验结果表明，这种适应方法具有潜力，能提升协作体验，而无需提供过多细节。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "Under review, Manuscript in submission for IROS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.09717v1",
      "published_date": "2025-04-13 20:49:43 UTC",
      "updated_date": "2025-04-13 20:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:23:38.928185"
    },
    {
      "arxiv_id": "2504.09716v1",
      "title": "Dominated Actions in Imperfect-Information Games",
      "title_zh": "翻译失败",
      "authors": [
        "Sam Ganzfried"
      ],
      "abstract": "Dominance is a fundamental concept in game theory. In strategic-form games\ndominated strategies can be identified in polynomial time. As a consequence,\niterative removal of dominated strategies can be performed efficiently as a\npreprocessing step for reducing the size of a game before computing a Nash\nequilibrium. For imperfect-information games in extensive form, we could\nconvert the game to strategic form and then iteratively remove dominated\nstrategies in the same way; however, this conversion may cause an exponential\nblowup in game size. In this paper we define and study the concept of dominated\nactions in imperfect-information games. Our main result is a polynomial-time\nalgorithm for determining whether an action is dominated (strictly or weakly)\nby any mixed strategy in n-player games, which can be extended to an algorithm\nfor iteratively removing dominated actions. This allows us to efficiently\nreduce the size of the game tree as a preprocessing step for Nash equilibrium\ncomputation. We explore the role of dominated actions empirically in the \"All\nIn or Fold\" No-Limit Texas Hold'em poker variant.",
      "tldr_zh": "该论文探讨了不完美信息游戏（imperfect-information games）中主导行动（dominated actions）的概念，强调了其在游戏树简化中的重要性，以避免将游戏转换为战略形式可能导致的指数级规模膨胀。研究提出了一种多项式时间算法，能够判断一个行动是否被任何混合策略（mixed strategy）严格或弱主导，并扩展为迭代移除主导行动的算法，作为 Nash 平衡计算的预处理步骤。实验在“All In or Fold” No-Limit Texas Hold'em 扑克变体中验证了该方法的有效性，展示了其在实际游戏中的潜力。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09716v1",
      "published_date": "2025-04-13 20:48:44 UTC",
      "updated_date": "2025-04-13 20:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:23:50.394050"
    },
    {
      "arxiv_id": "2504.09714v2",
      "title": "Evaluating the Quality of Benchmark Datasets for Low-Resource Languages: A Case Study on Turkish",
      "title_zh": "翻译失败",
      "authors": [
        "Ayşe Aysu Cengiz",
        "Ahmet Kaan Sever",
        "Elif Ecem Ümütlü",
        "Naime Şeyma Erdem",
        "Burak Aytan",
        "Büşra Tufan",
        "Abdullah Topraksoy",
        "Esra Darıcı",
        "Cagri Toraman"
      ],
      "abstract": "The reliance on translated or adapted datasets from English or multilingual\nresources introduces challenges regarding linguistic and cultural suitability.\nThis study addresses the need for robust and culturally appropriate benchmarks\nby evaluating the quality of 17 commonly used Turkish benchmark datasets. Using\na comprehensive framework that assesses six criteria, both human and LLM-judge\nannotators provide detailed evaluations to identify dataset strengths and\nshortcomings.\n  Our results reveal that 70% of the benchmark datasets fail to meet our\nheuristic quality standards. The correctness of the usage of technical terms is\nthe strongest criterion, but 85% of the criteria are not satisfied in the\nexamined datasets. Although LLM judges demonstrate potential, they are less\neffective than human annotators, particularly in understanding cultural common\nsense knowledge and interpreting fluent, unambiguous text. GPT-4o has stronger\nlabeling capabilities for grammatical and technical tasks, while Llama3.3-70B\nexcels at correctness and cultural knowledge evaluation. Our findings emphasize\nthe urgent need for more rigorous quality control in creating and adapting\ndatasets for low-resource languages.",
      "tldr_zh": "这篇论文评估了17个土耳其语benchmark datasets的质量，作为low-resource languages基准数据集研究的案例研究。研究采用一个涵盖六个评估标准的全面框架，由人类和LLM-judge评判者进行详细评估，识别数据集的优点和不足。结果显示，70%的数据集未达到设定的质量标准，技术术语的正确性是主要强项，但85%的标准整体未满足。LLM评判者如GPT-4o（在语法和技术任务上更强）和Llama3.3-70B（在正确性和文化知识上更出色）不如人类评判者在文化常识和文本解读方面有效，强调了为low-resource languages创建和适应数据集的迫切需要更严格的质量控制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09714v2",
      "published_date": "2025-04-13 20:45:49 UTC",
      "updated_date": "2025-04-26 11:28:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:24:03.499113"
    },
    {
      "arxiv_id": "2504.09712v1",
      "title": "The Structural Safety Generalization Problem",
      "title_zh": "结构安全泛化问题",
      "authors": [
        "Julius Broomfield",
        "Tom Gibbs",
        "Ethan Kosak-Hine",
        "George Ingebretsen",
        "Tia Nasir",
        "Jason Zhang",
        "Reihaneh Iranmanesh",
        "Sara Pieri",
        "Reihaneh Rabbany",
        "Kellin Pelrine"
      ],
      "abstract": "LLM jailbreaks are a widespread safety challenge. Given this problem has not\nyet been tractable, we suggest targeting a key failure mechanism: the failure\nof safety to generalize across semantically equivalent inputs. We further focus\nthe target by requiring desirable tractability properties of attacks to study:\nexplainability, transferability between models, and transferability between\ngoals. We perform red-teaming within this framework by uncovering new\nvulnerabilities to multi-turn, multi-image, and translation-based attacks.\nThese attacks are semantically equivalent by our design to their single-turn,\nsingle-image, or untranslated counterparts, enabling systematic comparisons; we\nshow that the different structures yield different safety outcomes. We then\ndemonstrate the potential for this framework to enable new defenses by\nproposing a Structure Rewriting Guardrail, which converts an input to a\nstructure more conducive to safety assessment. This guardrail significantly\nimproves refusal of harmful inputs, without over-refusing benign ones. Thus, by\nframing this intermediate challenge - more tractable than universal defenses\nbut essential for long-term safety - we highlight a critical milestone for AI\nsafety research.",
      "tldr_zh": "该论文探讨了大型语言模型（LLM）jailbreaks的安全挑战，特别聚焦于安全机制在语义等价输入上泛化失败的问题。研究者通过red-teaming框架设计了可解释且可转移的攻击，包括多轮、多图像和翻译-based攻击，这些攻击与单轮、单图像或未翻译版本语义等价，但结构差异导致不同的安全结果。实验证明，这种框架有助于系统比较攻击效果，并提出Structure Rewriting Guardrail作为新防御机制，该机制将输入重构为更适合安全评估的结构，从而显著提升对有害输入的拒绝率，同时避免过度拒绝良性输入。最终，该方法作为AI安全研究的中间里程碑，提供了一个更易处理的途径，推动长期安全改进。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09712v1",
      "published_date": "2025-04-13 20:21:08 UTC",
      "updated_date": "2025-04-13 20:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:24:15.970478"
    },
    {
      "arxiv_id": "2504.09707v1",
      "title": "InfoMAE: Pair-Efficient Cross-Modal Alignment for Multimodal Time-Series Sensing Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Tomoyoshi Kimura",
        "Xinlin Li",
        "Osama Hanna",
        "Yatong Chen",
        "Yizhuo Chen",
        "Denizhan Kara",
        "Tianshi Wang",
        "Jinyang Li",
        "Xiaomin Ouyang",
        "Shengzhong Liu",
        "Mani Srivastava",
        "Suhas Diggavi",
        "Tarek Abdelzaher"
      ],
      "abstract": "Standard multimodal self-supervised learning (SSL) algorithms regard\ncross-modal synchronization as implicit supervisory labels during pretraining,\nthus posing high requirements on the scale and quality of multimodal samples.\nThese constraints significantly limit the performance of sensing intelligence\nin IoT applications, as the heterogeneity and the non-interpretability of\ntime-series signals result in abundant unimodal data but scarce high-quality\nmultimodal pairs. This paper proposes InfoMAE, a cross-modal alignment\nframework that tackles the challenge of multimodal pair efficiency under the\nSSL setting by facilitating efficient cross-modal alignment of pretrained\nunimodal representations. InfoMAE achieves \\textit{efficient cross-modal\nalignment} with \\textit{limited data pairs} through a novel information\ntheory-inspired formulation that simultaneously addresses distribution-level\nand instance-level alignment. Extensive experiments on two real-world IoT\napplications are performed to evaluate InfoMAE's pairing efficiency to bridge\npretrained unimodal models into a cohesive joint multimodal model. InfoMAE\nenhances downstream multimodal tasks by over 60% with significantly improved\nmultimodal pairing efficiency. It also improves unimodal task accuracy by an\naverage of 22%.",
      "tldr_zh": "这篇论文提出 InfoMAE 框架，针对 IoT 应用中多模态时间序列信号的异质性和数据稀缺问题，通过信息理论启发的公式实现预训练单模态表示的分布级和实例级跨模态对齐，从而在有限多模态对下高效桥接联合多模态模型。InfoMAE 显著降低了标准 SSL 算法对大规模高质量样本的依赖。实验在两个真实 IoT 场景中验证，该框架使下游多模态任务性能提升超过 60%，并平均提高单模态任务准确率 22%。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.MM",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09707v1",
      "published_date": "2025-04-13 20:03:29 UTC",
      "updated_date": "2025-04-13 20:03:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:24:27.654175"
    },
    {
      "arxiv_id": "2504.09704v1",
      "title": "Transformer-Based Representation Learning for Robust Gene Expression Modeling and Cancer Prognosis",
      "title_zh": "基于 Transformer 的表示学习，用于鲁棒基因表达建模和癌症预后",
      "authors": [
        "Shuai Jiang",
        "Saeed Hassanpour"
      ],
      "abstract": "Transformer-based models have achieved remarkable success in natural language\nand vision tasks, but their application to gene expression analysis remains\nlimited due to data sparsity, high dimensionality, and missing values. We\npresent GexBERT, a transformer-based autoencoder framework for robust\nrepresentation learning of gene expression data. GexBERT learns context-aware\ngene embeddings by pretraining on large-scale transcriptomic profiles with a\nmasking and restoration objective that captures co-expression relationships\namong thousands of genes. We evaluate GexBERT across three critical tasks in\ncancer research: pan-cancer classification, cancer-specific survival\nprediction, and missing value imputation. GexBERT achieves state-of-the-art\nclassification accuracy from limited gene subsets, improves survival prediction\nby restoring expression of prognostic anchor genes, and outperforms\nconventional imputation methods under high missingness. Furthermore, its\nattention-based interpretability reveals biologically meaningful gene patterns\nacross cancer types. These findings demonstrate the utility of GexBERT as a\nscalable and effective tool for gene expression modeling, with translational\npotential in settings where gene coverage is limited or incomplete.",
      "tldr_zh": "本研究提出 GexBERT，一种基于 Transformer 的自编码器框架，用于基因表达数据的鲁棒表示学习，通过在大型转录组配置文件上预训练的掩码和恢复目标，捕捉基因间的共表达关系。GexBERT 在癌症研究中表现出色，包括泛癌分类、癌症特异性生存预测和缺失值插补任务，实现了最先进的分类准确率，并通过注意力机制揭示生物学意义的基因模式。相比传统方法，GexBERT 在数据稀疏和高缺失率环境下显著提升性能，具有在基因覆盖有限场景中的实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09704v1",
      "published_date": "2025-04-13 19:49:59 UTC",
      "updated_date": "2025-04-13 19:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:24:38.124161"
    },
    {
      "arxiv_id": "2504.09702v2",
      "title": "MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?",
      "title_zh": "MLRC-Bench：语言代理能否解决机器学习研究挑战？",
      "authors": [
        "Yunxiang Zhang",
        "Muhammad Khalifa",
        "Shitanshu Bhushan",
        "Grant D Murphy",
        "Lajanugen Logeswaran",
        "Jaekyeom Kim",
        "Moontae Lee",
        "Honglak Lee",
        "Lu Wang"
      ],
      "abstract": "We introduce MLRC-Bench, a benchmark designed to quantify how effectively\nlanguage agents can tackle challenging Machine Learning (ML) Research\nCompetitions, with a focus on open research problems that demand novel\nmethodologies. Unlike prior work, e.g., AI Scientist, which evaluates the\nend-to-end agentic pipeline by using LLM-as-a-judge, MLRC-Bench measures the\nkey steps of proposing and implementing novel research methods and evaluates\nthem with rigorous protocol and objective metrics. Our curated suite of 7\ncompetition tasks reveals significant challenges for LLM agents. Even the\nbest-performing tested agent (gemini-exp-1206 under MLAB) closes only 9.3% of\nthe gap between baseline and top human participant scores. Furthermore, our\nanalysis reveals a misalignment between the LLM-judged innovation and actual\nperformance on cutting-edge ML research problems. MLRC-Bench is a dynamic\nbenchmark, designed to grow with new ML competitions and encourage rigorous,\nobjective evaluations of AI research capabilities. Our leaderboard and code are\navailable at: https://huggingface.co/spaces/launch/MLRC_Bench",
      "tldr_zh": "本研究引入了 MLRC-Bench，一个基准，用于评估语言代理在处理机器学习 (ML) 研究竞赛中的有效性，重点针对需要新方法的开放问题。该基准不同于以往工作（如 AI Scientist），通过测量提出和实现创新研究方法的关键步骤，并采用严格协议和客观指标进行评估，而不是依赖 LLM-as-a-judge。实验结果显示，在7个竞赛任务中，即使表现最好的代理（gemini-exp-1206 under MLAB）也仅关闭了基线与顶级人类参与者分数之间9.3%的差距，并揭示了LLM判断的创新与实际性能之间的不一致。MLRC-Bench作为动态基准，将随着新ML竞赛扩展，并提供leaderboard和代码以促进AI研究能力的客观评估。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09702v2",
      "published_date": "2025-04-13 19:35:43 UTC",
      "updated_date": "2025-05-18 20:31:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:24:51.178785"
    },
    {
      "arxiv_id": "2504.11482v1",
      "title": "snnTrans-DHZ: A Lightweight Spiking Neural Network Architecture for Underwater Image Dehazing",
      "title_zh": "翻译失败",
      "authors": [
        "Vidya Sudevan",
        "Fakhreddine Zayer",
        "Rizwana Kausar",
        "Sajid Javed",
        "Hamad Karki",
        "Giulia De Masi",
        "Jorge Dias"
      ],
      "abstract": "Underwater image dehazing is critical for vision-based marine operations\nbecause light scattering and absorption can severely reduce visibility. This\npaper introduces snnTrans-DHZ, a lightweight Spiking Neural Network (SNN)\nspecifically designed for underwater dehazing. By leveraging the temporal\ndynamics of SNNs, snnTrans-DHZ efficiently processes time-dependent raw image\nsequences while maintaining low power consumption. Static underwater images are\nfirst converted into time-dependent sequences by repeatedly inputting the same\nimage over user-defined timesteps. These RGB sequences are then transformed\ninto LAB color space representations and processed concurrently. The\narchitecture features three key modules: (i) a K estimator that extracts\nfeatures from multiple color space representations; (ii) a Background Light\nEstimator that jointly infers the background light component from the RGB-LAB\nimages; and (iii) a soft image reconstruction module that produces haze-free,\nvisibility-enhanced outputs. The snnTrans-DHZ model is directly trained using a\nsurrogate gradient-based backpropagation through time (BPTT) strategy alongside\na novel combined loss function. Evaluated on the UIEB benchmark, snnTrans-DHZ\nachieves a PSNR of 21.68 dB and an SSIM of 0.8795, and on the EUVP dataset, it\nyields a PSNR of 23.46 dB and an SSIM of 0.8439. With only 0.5670 million\nnetwork parameters, and requiring just 7.42 GSOPs and 0.0151 J of energy, the\nalgorithm significantly outperforms existing state-of-the-art methods in terms\nof efficiency. These features make snnTrans-DHZ highly suitable for deployment\nin underwater robotics, marine exploration, and environmental monitoring.",
      "tldr_zh": "本文提出了一种轻量级 Spiking Neural Network (SNN) 架构，名为 snnTrans-DHZ，专门用于水下图像去雾，以解决光散射和吸收导致的可见度问题。该架构利用 SNN 的时间动态，将静态图像转换为时间序列，并通过 RGB 到 LAB 色空间转换，同时整合 K estimator 提取特征、Background Light Estimator 推断背景光组件，以及软图像重建模块生成清晰输出。模型采用代理梯度-based backpropagation through time (BPTT) 和新型组合损失函数进行直接训练。在 UIEB 和 EUVP 数据集上，snnTrans-DHZ 分别实现 PSNR 21.68 dB 和 23.46 dB、SSIM 0.8795 和 0.8439，同时仅需 0.5670 百万参数、7.42 GSOPs 和 0.0151 J 能量，显著优于现有方法。这些特性使其特别适合水下机器人、海洋勘探和环境监测应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.PF",
        "cs.RO",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11482v1",
      "published_date": "2025-04-13 19:03:33 UTC",
      "updated_date": "2025-04-13 19:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:25:04.982091"
    },
    {
      "arxiv_id": "2504.09691v1",
      "title": "Migrating Code At Scale With LLMs At Google",
      "title_zh": "在 Google 使用 LLMs 进行大规模代码迁移",
      "authors": [
        "Celal Ziftci",
        "Stoyan Nikolov",
        "Anna Sjövall",
        "Bo Kim",
        "Daniele Codecasa",
        "Max Kim"
      ],
      "abstract": "Developers often evolve an existing software system by making internal\nchanges, called migration. Moving to a new framework, changing implementation\nto improve efficiency, and upgrading a dependency to its latest version are\nexamples of migrations.\n  Migration is a common and typically continuous maintenance task undertaken\neither manually or through tooling. Certain migrations are labor intensive and\ncostly, developers do not find the required work rewarding, and they may take\nyears to complete. Hence, automation is preferred for such migrations.\n  In this paper, we discuss a large-scale, costly and traditionally manual\nmigration project at Google, propose a novel automated algorithm that uses\nchange location discovery and a Large Language Model (LLM) to aid developers\nconduct the migration, report the results of a large case study, and discuss\nlessons learned.\n  Our case study on 39 distinct migrations undertaken by three developers over\ntwelve months shows that a total of 595 code changes with 93,574 edits have\nbeen submitted, where 74.45% of the code changes and 69.46% of the edits were\ngenerated by the LLM. The developers reported high satisfaction with the\nautomated tooling, and estimated a 50% reduction on the total time spent on the\nmigration compared to earlier manual migrations.\n  Our results suggest that our automated, LLM-assisted workflow can serve as a\nmodel for similar initiatives.",
      "tldr_zh": "本研究探讨了在 Google 进行的代码迁移任务，提出了一种新型自动化算法，该算法结合变化位置发现技术(change location discovery)和 Large Language Models (LLMs)，以辅助开发者进行大规模代码迁移。实验结果显示，在 39 个迁移项目中，三个开发者在 12 个月内提交了 595 个代码变化和 93,574 个编辑，其中 74.45% 的变化和 69.46% 的编辑由 LLM 生成，显著减少了手动工作量。开发者报告了高满意度，并估计总时间减少了 50%，证明了 LLM 辅助工作流可作为类似迁移项目的参考模型。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09691v1",
      "published_date": "2025-04-13 18:52:44 UTC",
      "updated_date": "2025-04-13 18:52:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:25:13.849168"
    },
    {
      "arxiv_id": "2504.09689v3",
      "title": "EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety",
      "title_zh": "EmoAgent：评估与保障人类-AI 交互的心理健康安全",
      "authors": [
        "Jiahao Qiu",
        "Yinghui He",
        "Xinzhe Juan",
        "Yimin Wang",
        "Yuhan Liu",
        "Zixin Yao",
        "Yue Wu",
        "Xun Jiang",
        "Ling Yang",
        "Mengdi Wang"
      ],
      "abstract": "The rise of LLM-driven AI characters raises safety concerns, particularly for\nvulnerable human users with psychological disorders. To address these risks, we\npropose EmoAgent, a multi-agent AI framework designed to evaluate and mitigate\nmental health hazards in human-AI interactions. EmoAgent comprises two\ncomponents: EmoEval simulates virtual users, including those portraying\nmentally vulnerable individuals, to assess mental health changes before and\nafter interactions with AI characters. It uses clinically proven psychological\nand psychiatric assessment tools (PHQ-9, PDI, PANSS) to evaluate mental risks\ninduced by LLM. EmoGuard serves as an intermediary, monitoring users' mental\nstatus, predicting potential harm, and providing corrective feedback to\nmitigate risks. Experiments conducted in popular character-based chatbots show\nthat emotionally engaging dialogues can lead to psychological deterioration in\nvulnerable users, with mental state deterioration in more than 34.4% of the\nsimulations. EmoGuard significantly reduces these deterioration rates,\nunderscoring its role in ensuring safer AI-human interactions. Our code is\navailable at: https://github.com/1akaman/EmoAgent",
      "tldr_zh": "该研究提出 EmoAgent，一种多智能体 AI 框架，用于评估和减轻 LLM 驱动 AI 角色在人类互动中对心理健康的风险，特别是针对心理障碍用户的潜在危害。EmoAgent 包括 EmoEval 组件，它模拟虚拟用户（包括心理脆弱个体）并使用临床工具如 PHQ-9、PDI 和 PANSS 评估 AI 互动前后心理变化；EmoGuard 则作为中介，监控用户心理状态、预测潜在风险并提供纠正反馈。实验在流行角色聊天机器人上显示，情感对话可能导致 34.4% 的模拟中心理状态恶化，而 EmoGuard 显著降低了这一比率，确保更安全的 AI-人类互动。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09689v3",
      "published_date": "2025-04-13 18:47:22 UTC",
      "updated_date": "2025-04-29 22:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:25:27.298105"
    },
    {
      "arxiv_id": "2504.09685v1",
      "title": "Can LLMs Revolutionize the Design of Explainable and Efficient TinyML Models?",
      "title_zh": "LLMs 是否能革新可解释且高效的 TinyML 模型设计？",
      "authors": [
        "Christophe El Zeinaty",
        "Wassim Hamidouche",
        "Glenn Herrou",
        "Daniel Menard",
        "Merouane Debbah"
      ],
      "abstract": "This paper introduces a novel framework for designing efficient neural\nnetwork architectures specifically tailored to tiny machine learning (TinyML)\nplatforms. By leveraging large language models (LLMs) for neural architecture\nsearch (NAS), a vision transformer (ViT)-based knowledge distillation (KD)\nstrategy, and an explainability module, the approach strikes an optimal balance\nbetween accuracy, computational efficiency, and memory usage. The LLM-guided\nsearch explores a hierarchical search space, refining candidate architectures\nthrough Pareto optimization based on accuracy, multiply-accumulate operations\n(MACs), and memory metrics. The best-performing architectures are further\nfine-tuned using logits-based KD with a pre-trained ViT-B/16 model, which\nenhances generalization without increasing model size. Evaluated on the\nCIFAR-100 dataset and deployed on an STM32H7 microcontroller (MCU), the three\nproposed models, LMaNet-Elite, LMaNet-Core, and QwNet-Core, achieve accuracy\nscores of 74.50%, 74.20% and 73.00%, respectively. All three models surpass\ncurrent state-of-the-art (SOTA) models, such as MCUNet-in3/in4 (69.62% /\n72.86%) and XiNet (72.27%), while maintaining a low computational cost of less\nthan 100 million MACs and adhering to the stringent 320 KB static random-access\nmemory (SRAM) constraint. These results demonstrate the efficiency and\nperformance of the proposed framework for TinyML platforms, underscoring the\npotential of combining LLM-driven search, Pareto optimization, KD, and\nexplainability to develop accurate, efficient, and interpretable models. This\napproach opens new possibilities in NAS, enabling the design of efficient\narchitectures specifically suited for TinyML.",
      "tldr_zh": "该论文提出了一种创新框架，利用大型语言模型（LLMs）进行神经架构搜索（NAS），结合视觉变压器（ViT）基于的知识蒸馏（KD）策略和解释性模块，设计出高效的 TinyML 模型，以平衡准确性、计算效率和内存使用。框架通过 LLM 引导的分层搜索空间和 Pareto 优化，筛选并微调候选架构，并在 CIFAR-100 数据集上部署于 STM32H7 微控制器，结果显示 LMaNet-Elite 等模型的准确率分别达到 74.50%、74.20% 和 73.00%，优于现有 SOTA 模型如 MCUNet，同时保持低于 100 百万 MACs 和 320 KB SRAM 的约束。这些成果证明了 LLMs 在 TinyML 设计中的革命性潜力，推动了准确、高效且可解释模型的开发。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09685v1",
      "published_date": "2025-04-13 18:36:03 UTC",
      "updated_date": "2025-04-13 18:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:25:40.303333"
    },
    {
      "arxiv_id": "2504.09680v1",
      "title": "SPOT: Spatio-Temporal Pattern Mining and Optimization for Load Consolidation in Freight Transportation Networks",
      "title_zh": "SPOT：货运运输网络中负载整合的时空模式挖掘与优化",
      "authors": [
        "Sikai Cheng",
        "Amira Hijazi",
        "Jeren Konak",
        "Alan Erera",
        "Pascal Van Hentenryck"
      ],
      "abstract": "Freight consolidation has significant potential to reduce transportation\ncosts and mitigate congestion and pollution. An effective load consolidation\nplan relies on carefully chosen consolidation points to ensure alignment with\nexisting transportation management processes, such as driver scheduling,\npersonnel planning, and terminal operations. This complexity represents a\nsignificant challenge when searching for optimal consolidation strategies.\nTraditional optimization-based methods provide exact solutions, but their\ncomputational complexity makes them impractical for large-scale instances and\nthey fail to leverage historical data. Machine learning-based approaches\naddress these issues but often ignore operational constraints, leading to\ninfeasible consolidation plans.\n  This work proposes SPOT, an end-to-end approach that integrates the benefits\nof machine learning (ML) and optimization for load consolidation. The ML\ncomponent plays a key role in the planning phase by identifying the\nconsolidation points through spatio-temporal clustering and constrained\nfrequent itemset mining, while the optimization selects the most cost-effective\nfeasible consolidation routes for a given operational day. Extensive\nexperiments conducted on industrial load data demonstrate that SPOT\nsignificantly reduces travel distance and transportation costs (by about 50% on\nlarge terminals) compared to the existing industry-standard load planning\nstrategy and a neighborhood-based heuristic. Moreover, the ML component\nprovides valuable tactical-level insights by identifying frequently recurring\nconsolidation opportunities that guide proactive planning. In addition, SPOT is\ncomputationally efficient and can be easily scaled to accommodate large\ntransportation networks.",
      "tldr_zh": "这篇论文提出了 SPOT，一种整合机器学习和优化的端到端方法，用于货运网络中的负载整合，以减少运输成本、缓解拥堵和污染。SPOT 的机器学习组件通过 spatio-temporal clustering 和 constrained frequent itemset mining 识别整合点，并结合优化算法为特定操作日选择最成本有效的路线。实验在工业负载数据上显示，SPOT 比现有行业标准和基于邻域的启发式方法减少约 50% 的旅行距离和运输成本，同时提供战术级洞见并支持大规模网络的计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09680v1",
      "published_date": "2025-04-13 18:14:38 UTC",
      "updated_date": "2025-04-13 18:14:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:25:50.804020"
    },
    {
      "arxiv_id": "2504.09662v1",
      "title": "AgentDynEx: Nudging the Mechanics and Dynamics of Multi-Agent Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Jenny Ma",
        "Riya Sahni",
        "Karthik Sreedhar",
        "Lydia B. Chilton"
      ],
      "abstract": "Multi-agent large language model simulations have the potential to model\ncomplex human behaviors and interactions. If the mechanics are set up properly,\nunanticipated and valuable social dynamics can surface. However, it is\nchallenging to consistently enforce simulation mechanics while still allowing\nfor notable and emergent dynamics. We present AgentDynEx, an AI system that\nhelps set up simulations from user-specified mechanics and dynamics. AgentDynEx\nuses LLMs to guide users through a Configuration Matrix to identify core\nmechanics and define milestones to track dynamics. It also introduces a method\ncalled \\textit{nudging}, where the system dynamically reflects on simulation\nprogress and gently intervenes if it begins to deviate from intended outcomes.\nA technical evaluation found that nudging enables simulations to have more\ncomplex mechanics and maintain its notable dynamics compared to simulations\nwithout nudging. We discuss the importance of nudging as a technique for\nbalancing mechanics and dynamics of multi-agent simulations.",
      "tldr_zh": "本文提出AgentDynEx系统，利用LLMs引导用户通过Configuration Matrix识别多智能体模拟的核心机制并定义动态里程碑，以模拟复杂人类行为和互动。系统引入nudging方法，通过动态反思和轻微干预，确保模拟保持预定轨道，同时允许紧急动态出现。技术评估显示，nudging使模拟机制更复杂且动态更稳定，比无干预模拟提升显著。作者强调nudging作为平衡多智能体模拟机制与动态的关键技术。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09662v1",
      "published_date": "2025-04-13 17:26:35 UTC",
      "updated_date": "2025-04-13 17:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:26:02.104042"
    },
    {
      "arxiv_id": "2504.16099v1",
      "title": "Two-Timescale Joint Transmit and Pinching Beamforming for Pinching-Antenna Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Luyuan Zhang",
        "Xidong Mu",
        "An Liu",
        "Yuanwei Liu"
      ],
      "abstract": "Pinching antenna systems (PASS) have been proposed as a revolutionary\nflexible antenna technology which facilitates line-of-sight links via numerous\nlow-cost pinching antennas with adjustable activation positions over\nwaveguides. This letter proposes a two-timescale joint transmit and pinching\nbeamforming design for the maximization of sum rate of a PASS-based downlink\nmulti-user multiple input single output system. A primal dual decomposition\nmethod is developed to decouple the two-timescale problem into two\nsub-problems: 1) A Karush-Kuhn-Tucker-guided dual learning-based approach is\nproposed to solve the short-term transmit beamforming design sub-problem; 2)\nThe long-term pinching beamforming design sub-problem is tackled by adopting a\nstochastic successive convex approximation method. Simulation results\ndemonstrate that the proposed two-timescale algorithm achieves a significant\nperformance gain compared to other baselines.",
      "tldr_zh": "该研究针对 Pinching antenna systems (PASS) 提出了一种两时间尺度联合发射和捏合波束形成设计，以最大化下行多用户多输入单输出系统的总速率。方法采用原初双分解（primal dual decomposition）将问题分解为两个子问题：短期发射波束形成通过 Karush-Kuhn-Tucker 引导的双学习方法求解，长期捏合波束形成则使用随机连续凸逼近（stochastic successive convex approximation）方法处理。模拟结果显示，该算法相较于其他基线方案实现了显著的性能提升。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "eess.SP",
      "comment": "5 pages, 4 figures, letter",
      "pdf_url": "http://arxiv.org/pdf/2504.16099v1",
      "published_date": "2025-04-13 16:58:35 UTC",
      "updated_date": "2025-04-13 16:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:26:13.980420"
    },
    {
      "arxiv_id": "2504.17055v1",
      "title": "Psychological Effect of AI driven marketing tools for beauty/facial feature enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Ayushi Agrawal",
        "Aditya Kondai",
        "Kavita Vemuri"
      ],
      "abstract": "AI-powered facial assessment tools are reshaping how individuals evaluate\nappearance and internalize social judgments. This study examines the\npsychological impact of such tools on self-objectification, self-esteem, and\nemotional responses, with attention to gender differences. Two samples used\ndistinct versions of a facial analysis tool: one overtly critical (N=75; M=22.9\nyears), and another more neutral (N=51; M=19.9 years). Participants completed\nvalidated self-objectification and self-esteem scales and custom items\nmeasuring emotion, digital/physical appearance enhancement (DAE, PAEE), and\nperceived social emotion (PSE). Results revealed consistent links between high\nself-objectification, low self-esteem, and increased appearance enhancement\nbehaviors across both versions. Despite softer framing, the newer tool still\nevoked negative emotional responses (U=1466.5, p=0.013), indicating implicit\nfeedback may reinforce appearance-related insecurities. Gender differences\nemerged in DAE (p=0.025) and PSE (p<0.001), with females more prone to digital\nenhancement and less likely to perceive emotional impact in others. These\nfindings reveal how AI tools may unintentionally reinforce and amplify existing\nsocial biases and underscore the critical need for responsible AI design and\ndevelopment. Future research will investigate how human ideologies embedded in\nthe training data of such tools shape their evaluative outputs, and how these,\nin turn, influence user attitudes and decisions.",
      "tldr_zh": "本研究考察了AI驱动的美颜/面部增强营销工具对个体的心理影响，包括self-objectification（自我物化）、self-esteem（自尊）和情绪反应，并探讨了性别差异。研究采用两组实验样本（N=75和N=51），使用一种批评性工具和一种中性工具，让参与者完成相关量表评估外貌增强行为和感知社会情绪。结果显示，高self-objectification与低self-esteem相关联，导致增加的外貌增强行为，即使中性工具也引发负面情绪，且女性更倾向于数字增强并较少感知他人的情绪影响。这些发现强调了AI工具可能强化社会偏见的风险，呼吁负责任的设计，并建议未来研究探索训练数据中的人类意识形态对用户态度的影响。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17055v1",
      "published_date": "2025-04-13 16:42:06 UTC",
      "updated_date": "2025-04-13 16:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:26:27.534457"
    },
    {
      "arxiv_id": "2504.09647v1",
      "title": "Building AI Service Repositories for On-Demand Service Orchestration in 6G AI-RAN",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Tang",
        "Mengbang Zou",
        "Udhaya Chandhar Srinivasan",
        "Obumneme Umealor",
        "Dennis Kevogo",
        "Benjamin James Scott",
        "Weisi Guo"
      ],
      "abstract": "Efficient orchestration of AI services in 6G AI-RAN requires well-structured,\nready-to-deploy AI service repositories combined with orchestration methods\nadaptive to diverse runtime contexts across radio access, edge, and cloud\nlayers. Current literature lacks comprehensive frameworks for constructing such\nrepositories and generally overlooks key practical orchestration factors. This\npaper systematically identifies and categorizes critical attributes influencing\nAI service orchestration in 6G networks and introduces an open-source,\nLLM-assisted toolchain that automates service packaging, deployment, and\nruntime profiling. We validate the proposed toolchain through the Cranfield AI\nService repository case study, demonstrating significant automation benefits,\nreduced manual coding efforts, and the necessity of infrastructure-specific\nprofiling, paving the way for more practical orchestration frameworks.",
      "tldr_zh": "这篇论文针对 6G AI-RAN 中的 AI 服务编排问题，提出构建结构化的 AI service repositories，以适应无线接入、边缘和云层等多种运行时环境。作者系统识别并分类了影响编排的关键属性，并开发了一个开源的 LLM-assisted toolchain，用于自动化服务打包、部署和运行时分析。案例研究基于 Cranfield AI Service repository，证明了该工具链显著减少手动编码努力，并强调了基础设施特定分析的必要性，为更实用的 AI 服务编排框架铺平道路。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, three figures, one table, submitted to IEEE GlobeCOM 2025\n  for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2504.09647v1",
      "published_date": "2025-04-13 16:40:58 UTC",
      "updated_date": "2025-04-13 16:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:26:38.945248"
    },
    {
      "arxiv_id": "2504.09645v1",
      "title": "Myanmar XNLI: Building a Dataset and Exploring Low-resource Approaches to Natural Language Inference with Myanmar",
      "title_zh": "翻译失败",
      "authors": [
        "Aung Kyaw Htet",
        "Mark Dras"
      ],
      "abstract": "Despite dramatic recent progress in NLP, it is still a major challenge to\napply Large Language Models (LLM) to low-resource languages. This is made\nvisible in benchmarks such as Cross-Lingual Natural Language Inference (XNLI),\na key task that demonstrates cross-lingual capabilities of NLP systems across a\nset of 15 languages. In this paper, we extend the XNLI task for one additional\nlow-resource language, Myanmar, as a proxy challenge for broader low-resource\nlanguages, and make three core contributions. First, we build a dataset called\nMyanmar XNLI (myXNLI) using community crowd-sourced methods, as an extension to\nthe existing XNLI corpus. This involves a two-stage process of community-based\nconstruction followed by expert verification; through an analysis, we\ndemonstrate and quantify the value of the expert verification stage in the\ncontext of community-based construction for low-resource languages. We make the\nmyXNLI dataset available to the community for future research. Second, we carry\nout evaluations of recent multilingual language models on the myXNLI benchmark,\nas well as explore data-augmentation methods to improve model performance. Our\ndata-augmentation methods improve model accuracy by up to 2 percentage points\nfor Myanmar, while uplifting other languages at the same time. Third, we\ninvestigate how well these data-augmentation methods generalise to other\nlow-resource languages in the XNLI dataset.",
      "tldr_zh": "这篇论文扩展了跨语言自然语言推理（XNLI）基准到低资源语言缅甸语，构建了名为 myXNLI 的新数据集，通过社区众包方法结合专家验证阶段，以提高数据质量并量化验证的价值。研究者评估了多语言模型在 myXNLI 上的性能，并探索数据增强技术，使缅甸语模型准确率提升多达 2%，同时也提升了其他语言的表现。最终，他们调查了这些数据增强方法在 XNLI 中其他低资源语言的泛化能力，为低资源语言的 NLP 应用提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09645v1",
      "published_date": "2025-04-13 16:36:59 UTC",
      "updated_date": "2025-04-13 16:36:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:26:50.767857"
    },
    {
      "arxiv_id": "2504.09635v1",
      "title": "A Two-Stage Interpretable Matching Framework for Causal Inference",
      "title_zh": "一个两阶段可解释匹配框架用于因果推断",
      "authors": [
        "Sahil Shikalgar",
        "Md. Noor-E-Alam"
      ],
      "abstract": "Matching in causal inference from observational data aims to construct\ntreatment and control groups with similar distributions of covariates, thereby\nreducing confounding and ensuring an unbiased estimation of treatment effects.\nThis matched sample closely mimics a randomized controlled trial (RCT), thus\nimproving the quality of causal estimates. We introduce a novel Two-stage\nInterpretable Matching (TIM) framework for transparent and interpretable\ncovariate matching. In the first stage, we perform exact matching across all\navailable covariates. For treatment and control units without an exact match in\nthe first stage, we proceed to the second stage. Here, we iteratively refine\nthe matching process by removing the least significant confounder in each\niteration and attempting exact matching on the remaining covariates. We learn a\ndistance metric for the dropped covariates to quantify closeness to the\ntreatment unit(s) within the corresponding strata. We used these high- quality\nmatches to estimate the conditional average treatment effects (CATEs). To\nvalidate TIM, we conducted experiments on synthetic datasets with varying\nassociation structures and correlations. We assessed its performance by\nmeasuring bias in CATE estimation and evaluating multivariate overlap between\ntreatment and control groups before and after matching. Additionally, we apply\nTIM to a real-world healthcare dataset from the Centers for Disease Control and\nPrevention (CDC) to estimate the causal effect of high cholesterol on diabetes.\nOur results demonstrate that TIM improves CATE estimates, increases\nmultivariate overlap, and scales effectively to high-dimensional data, making\nit a robust tool for causal inference in observational data.",
      "tldr_zh": "本研究提出了一种Two-stage Interpretable Matching (TIM)框架，用于因果推断中的协变量匹配，以减少混杂并实现无偏的处理效果估计。TIM框架分为两个阶段：第一阶段对所有可用covariates进行精确匹配；第二阶段针对未匹配的单位，通过迭代移除最不重要的混杂因素并学习距离度量，对剩余covariates重新匹配，从而提高匹配质量并估计conditional average treatment effects (CATEs)。实验结果显示，TIM在合成数据集上显著降低了CATE估计偏差，并提升了多变量重叠；在真实CDC医疗数据集上，它成功评估了高胆固醇对糖尿病的因果影响，并证明了其在高维数据中的可扩展性和鲁棒性。",
      "categories": [
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09635v1",
      "published_date": "2025-04-13 16:17:52 UTC",
      "updated_date": "2025-04-13 16:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:27:02.694032"
    },
    {
      "arxiv_id": "2504.09627v1",
      "title": "Slow Thinking for Sequential Recommendation",
      "title_zh": "慢速思考的序列推荐",
      "authors": [
        "Junjie Zhang",
        "Beichen Zhang",
        "Wenqi Sun",
        "Hongyu Lu",
        "Wayne Xin Zhao",
        "Yu Chen",
        "Ji-Rong Wen"
      ],
      "abstract": "To develop effective sequential recommender systems, numerous methods have\nbeen proposed to model historical user behaviors. Despite the effectiveness,\nthese methods share the same fast thinking paradigm. That is, for making\nrecommendations, these methods typically encodes user historical interactions\nto obtain user representations and directly match these representations with\ncandidate item representations. However, due to the limited capacity of\ntraditional lightweight recommendation models, this one-step inference paradigm\noften leads to suboptimal performance. To tackle this issue, we present a novel\nslow thinking recommendation model, named STREAM-Rec. Our approach is capable\nof analyzing historical user behavior, generating a multi-step, deliberative\nreasoning process, and ultimately delivering personalized recommendations. In\nparticular, we focus on two key challenges: (1) identifying the suitable\nreasoning patterns in recommender systems, and (2) exploring how to effectively\nstimulate the reasoning capabilities of traditional recommenders. To this end,\nwe introduce a three-stage training framework. In the first stage, the model is\npretrained on large-scale user behavior data to learn behavior patterns and\ncapture long-range dependencies. In the second stage, we design an iterative\ninference algorithm to annotate suitable reasoning traces by progressively\nrefining the model predictions. This annotated data is then used to fine-tune\nthe model. Finally, in the third stage, we apply reinforcement learning to\nfurther enhance the model generalization ability. Extensive experiments\nvalidate the effectiveness of our proposed method.",
      "tldr_zh": "本研究指出，现有的顺序推荐系统采用快速思考范式，直接编码用户历史交互并匹配候选项，导致性能次优。论文提出了一种新型模型STREAM-Rec，通过多步推理分析用户行为，实现个性化推荐，重点解决识别适合的推理模式和激发传统推荐器推理能力两大挑战。为此，采用三阶段训练框架：首先在大规模用户行为数据上预训练以学习行为模式和捕获长程依赖；其次设计迭代推理算法标注推理痕迹并微调模型；最后应用强化学习增强模型的泛化能力。实验结果证明，该方法在顺序推荐任务中表现出色，有效提升了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09627v1",
      "published_date": "2025-04-13 15:53:30 UTC",
      "updated_date": "2025-04-13 15:53:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:27:14.289610"
    },
    {
      "arxiv_id": "2504.13202v1",
      "title": "The Quantum LLM: Modeling Semantic Spaces with Quantum Principles",
      "title_zh": "翻译失败",
      "authors": [
        "Timo Aukusti Laine"
      ],
      "abstract": "In the previous article, we presented a quantum-inspired framework for\nmodeling semantic representation and processing in Large Language Models\n(LLMs), drawing upon mathematical tools and conceptual analogies from quantum\nmechanics to offer a new perspective on these complex systems. In this paper,\nwe clarify the core assumptions of this model, providing a detailed exposition\nof six key principles that govern semantic representation, interaction, and\ndynamics within LLMs. The goal is to justify that a quantum-inspired framework\nis a valid approach to studying semantic spaces. This framework offers valuable\ninsights into their information processing and response generation, and we\nfurther discuss the potential of leveraging quantum computing to develop\nsignificantly more powerful and efficient LLMs based on these principles.",
      "tldr_zh": "本论文扩展了之前的工作，提出一个基于量子原理（Quantum Principles）的框架，用于建模Large Language Models (LLMs)的语义表示和处理。该框架借鉴量子力学的数学工具和概念类比，详细阐述了六个关键原则，这些原则管理LLMs中的语义表示、交互和动态，并证明其是研究语义空间的有效方法。通过这一框架，论文提供了对LLMs信息处理和响应生成的宝贵见解，并探讨了利用quantum computing开发更强大、更高效率的LLMs的可能性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13202v1",
      "published_date": "2025-04-13 15:49:41 UTC",
      "updated_date": "2025-04-13 15:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:27:26.949531"
    },
    {
      "arxiv_id": "2504.09623v1",
      "title": "Ges3ViG: Incorporating Pointing Gestures into Language-Based 3D Visual Grounding for Embodied Reference Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Atharv Mahesh Mane",
        "Dulanga Weerakoon",
        "Vigneshwaran Subbaraju",
        "Sougata Sen",
        "Sanjay E. Sarma",
        "Archan Misra"
      ],
      "abstract": "3-Dimensional Embodied Reference Understanding (3D-ERU) combines a language\ndescription and an accompanying pointing gesture to identify the most relevant\ntarget object in a 3D scene. Although prior work has explored pure\nlanguage-based 3D grounding, there has been limited exploration of 3D-ERU,\nwhich also incorporates human pointing gestures. To address this gap, we\nintroduce a data augmentation framework-Imputer, and use it to curate a new\nbenchmark dataset-ImputeRefer for 3D-ERU, by incorporating human pointing\ngestures into existing 3D scene datasets that only contain language\ninstructions. We also propose Ges3ViG, a novel model for 3D-ERU that achieves\n~30% improvement in accuracy as compared to other 3D-ERU models and ~9%\ncompared to other purely language-based 3D grounding models. Our code and\ndataset are available at https://github.com/AtharvMane/Ges3ViG.",
      "tldr_zh": "本文提出 Ges3ViG，一种将指向手势融入语言-based 3D 视觉定位的方法，用于 3D-ERU（3-Dimensional Embodied Reference Understanding），以更准确地识别 3D 场景中的目标对象。作者开发了数据增强框架 Imputer，并创建了新基准数据集 ImputeRefer，通过将人类指向手势添加到现有只包含语言指令的 3D 场景数据中。Ges3ViG 模型在 3D-ERU 任务上比其他 3D-ERU 模型提高了约 30% 的准确率，比纯语言-based 3D grounding 模型提高了约 9%。代码和数据集已在 GitHub 上公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.09623v1",
      "published_date": "2025-04-13 15:43:06 UTC",
      "updated_date": "2025-04-13 15:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:27:39.753641"
    },
    {
      "arxiv_id": "2504.09620v1",
      "title": "Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models via Decentralized Bayesian Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Yuta Matsui",
        "Ryosuke Yamaki",
        "Ryo Ueda",
        "Seitaro Shinagawa",
        "Tadahiro Taniguchi"
      ],
      "abstract": "We propose the Metropolis-Hastings Captioning Game (MHCG), a method to fuse\nknowledge of multiple vision-language models (VLMs) by learning from each\nother. Although existing methods that combine multiple models suffer from\ninference costs and architectural constraints, MHCG avoids these problems by\nperforming decentralized Bayesian inference through a process resembling a\nlanguage game. The knowledge fusion process establishes communication between\ntwo VLM agents alternately captioning images and learning from each other. We\nconduct two image-captioning experiments with two VLMs, each pre-trained on a\ndifferent dataset. The first experiment demonstrates that MHCG achieves\nconsistent improvement in reference-free evaluation metrics. The second\nexperiment investigates how MHCG contributes to sharing VLMs' category-level\nvocabulary by observing the occurrence of the vocabulary in the generated\ncaptions.",
      "tldr_zh": "该研究提出了Metropolis-Hastings Captioning Game (MHCG)，一种通过decentralized Bayesian inference融合多个vision-language models (VLMs)知识的方法，避免了传统融合技术的推理成本和架构限制。MHCG通过模拟语言游戏，让两个VLMs代理交替描述图像并相互学习，从而实现知识共享。在实验中，MHCG在两个图像描述任务上表现出色，显著提升了参考-free评估指标，并促进了VLMs的类别级词汇共享。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09620v1",
      "published_date": "2025-04-13 15:28:09 UTC",
      "updated_date": "2025-04-13 15:28:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:27:49.768171"
    },
    {
      "arxiv_id": "2504.09609v2",
      "title": "A highly maneuverable flying squirrel drone with agility-improving foldable wings",
      "title_zh": "一种高机动性的飞鼠无人机，配备提升敏捷性的可折叠翅膀",
      "authors": [
        "Dohyeon Lee",
        "Jun-Gill Kang",
        "Soohee Han"
      ],
      "abstract": "Drones, like most airborne aerial vehicles, face inherent disadvantages in\nachieving agile flight due to their limited thrust capabilities. These physical\nconstraints cannot be fully addressed through advancements in control\nalgorithms alone. Drawing inspiration from the winged flying squirrel, this\npaper proposes a highly maneuverable drone equipped with agility-enhancing\nfoldable wings. By leveraging collaborative control between the conventional\npropeller system and the foldable wings-coordinated through the Thrust-Wing\nCoordination Control (TWCC) framework-the controllable acceleration set is\nexpanded, enabling the generation of abrupt vertical forces that are\nunachievable with traditional wingless drones. The complex aerodynamics of the\nfoldable wings are modeled using a physics-assisted recurrent neural network\n(paRNN), which calibrates the angle of attack (AOA) to align with the real\naerodynamic behavior of the wings. The additional air resistance generated by\nappropriately deploying these wings significantly improves the tracking\nperformance of the proposed \"flying squirrel\" drone. The model is trained on\nreal flight data and incorporates flat-plate aerodynamic principles.\nExperimental results demonstrate that the proposed flying squirrel drone\nachieves a 13.1% improvement in tracking performance, as measured by root mean\nsquare error (RMSE), compared to a conventional wingless drone. A demonstration\nvideo is available on YouTube: https://youtu.be/O8nrip18azY.",
      "tldr_zh": "本论文提出了一种受飞鼠启发的无人机设计，配备可折叠翅膀，以克服传统无人机推力限制导致的敏捷飞行难题。通过 Thrust-Wing Coordination Control (TWCC) 框架协调推进器和翅膀系统，并利用 physics-assisted recurrent neural network (paRNN) 建模翅膀的空气动力学，该无人机实现了更大的可控加速度集和垂直力生成。实验结果显示，与传统无翅膀无人机相比，该“飞鼠”无人机在跟踪性能上以 root mean square error (RMSE) 指标改善了 13.1%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE Robotics and Automation Letters. Project Page :\n  https://jgkang1210.github.io/fsdrone_ral/ , Video :\n  https://www.youtube.com/watch?v=tckIF3KCJig , Dohyeon Lee and Jun-Gill Kang\n  are co-authors",
      "pdf_url": "http://arxiv.org/pdf/2504.09609v2",
      "published_date": "2025-04-13 14:57:11 UTC",
      "updated_date": "2025-05-08 12:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:28:02.743127"
    },
    {
      "arxiv_id": "2504.09602v2",
      "title": "Fine-tuning a Large Language Model for Automating Computational Fluid Dynamics Simulations",
      "title_zh": "微调大型语言",
      "authors": [
        "Zhehao Dong",
        "Zhen Lu",
        "Yue Yang"
      ],
      "abstract": "Configuring computational fluid dynamics (CFD) simulations typically demands\nextensive domain expertise, limiting broader access. Although large language\nmodels (LLMs) have advanced scientific computing, their use in automating CFD\nworkflows is underdeveloped. We introduce a novel approach centered on\ndomain-specific LLM adaptation. By fine-tuning Qwen2.5-7B-Instruct on NL2FOAM,\nour custom dataset of 28716 natural language-to-OpenFOAM configuration pairs\nwith chain-of-thought (CoT) annotations, we enable direct translation from\nnatural language descriptions to executable CFD setups. A multi-agent framework\norchestrates the process, autonomously verifying inputs, generating\nconfigurations, running simulations, and correcting errors. Evaluation on a\nbenchmark of 21 diverse flow cases demonstrates state-of-the-art performance,\nachieving 88.7% solution accuracy and 82.6% first-attempt success rate. This\nsignificantly outperforms larger general-purpose models like\nQwen2.5-72B-Instruct, DeepSeek-R1, and Llama3.3-70B-Instruct, while also\nrequiring fewer correction iterations and maintaining high computational\nefficiency. The results highlight the critical role of domain-specific\nadaptation in deploying LLM assistants for complex engineering workflows. Our\ncode and fine-tuned model have been deposited at\nhttps://github.com/YYgroup/AutoCFD.",
      "tldr_zh": "这篇论文提出了一种微调大型语言模型（LLM）的方法，以自动化计算流体动力学（CFD）模拟配置，解决其对领域专业知识的依赖问题。研究团队使用自定义数据集 NL2FOAM（包含 28716 个自然语言到 OpenFOAM 配置对，并添加 Chain-of-Thought 注解）对 Qwen2.5-7B-Instruct 模型进行微调，并采用多智能体框架来自动验证输入、生成配置、运行模拟并修正错误。在 21 个多样化流动案例的基准测试中，该方法实现了 88.7% 的解决方案准确率和 82.6% 的首次尝试成功率，显著优于更大通用模型如 Qwen2.5-72B-Instruct 和 Llama3.3-70B-Instruct，同时减少修正迭代并提升计算效率。该研究强调了领域特定适配在部署 LLM 助手用于复杂工程工作流中的关键作用。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09602v2",
      "published_date": "2025-04-13 14:35:30 UTC",
      "updated_date": "2025-04-21 07:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:28:15.753016"
    },
    {
      "arxiv_id": "2504.09597v5",
      "title": "Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixuan Pan",
        "Shaowen Wang",
        "Jian Li"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nnumerous tasks, yet principled explanations for their underlying mechanisms and\nseveral phenomena, such as scaling laws, hallucinations, and related behaviors,\nremain elusive. In this work, we revisit the classical relationship between\ncompression and prediction, grounded in Kolmogorov complexity and Shannon\ninformation theory, to provide deeper insights into LLM behaviors. By\nleveraging the Kolmogorov Structure Function and interpreting LLM compression\nas a two-part coding process, we offer a detailed view of how LLMs acquire and\nstore information across increasing model and data scales -- from pervasive\nsyntactic patterns to progressively rarer knowledge elements. Motivated by this\ntheoretical perspective and natural assumptions inspired by Heap's and Zipf's\nlaws, we introduce a simplified yet representative hierarchical data-generation\nframework called the Syntax-Knowledge model. Under the Bayesian setting, we\nshow that prediction and compression within this model naturally lead to\ndiverse learning and scaling behaviors of LLMs. In particular, our theoretical\nanalysis offers intuitive and principled explanations for both data and model\nscaling laws, the dynamics of knowledge acquisition during training and\nfine-tuning, factual knowledge hallucinations in LLMs. The experimental results\nvalidate our theoretical predictions.",
      "tldr_zh": "本研究利用 Kolmogorov 复杂度和 Shannon 信息理论，探讨大型语言模型 (LLMs) 的行为机制，包括缩放定律、幻觉和知识获取问题，将 LLM 压缩视为两部分编码过程，以分析模型在数据和规模增加时的信息存储方式。研究者引入了简化的分层数据生成框架——Syntax-Knowledge 模型，并在 Bayesian 设置下证明了预测和压缩如何导致 LLMs 的多样学习行为，并为数据缩放定律、知识动态和事实幻觉提供了直观的理论解释。实验结果验证了这些预测，为理解 LLMs 的内在机制提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09597v5",
      "published_date": "2025-04-13 14:31:52 UTC",
      "updated_date": "2025-05-17 15:36:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:28:27.642325"
    },
    {
      "arxiv_id": "2504.09590v1",
      "title": "Efficient LLM Serving on Hybrid Real-time and Best-effort Requests",
      "title_zh": "翻译失败",
      "authors": [
        "Wan Borui",
        "Zhao Juntao",
        "Jiang Chenyu",
        "Guo Chuanxiong",
        "Wu Chuan"
      ],
      "abstract": "Recent breakthroughs in large Language Models (LLMs) have enabled various\ngenerative tasks on a single model. Real-world services (e.g., OpenAI's ChatGPT\n[27]) powered by an LLM often concurrently support latency-critical requests\nfor interactive applications (e.g., question-answering systems, referred to as\nreal-time or RT requests) and throughput-oriented requests for back-of-house\nprocessing (e.g., documents batch processing [28], referred to best-effort or\nBE requests), with complex hybrid inference workloads to the underlying model.\nState-of-the-art (SOTA) LLM serving systems dedicate machines to each type of\nrequest, towards either low inference latency or high serving throughput,\nrespectively. This practice simplifies request scheduling and management but\nsuffers from poor resource utilization. We propose BROS, a hybrid LLM serving\nsystem that aims to collocate RT/BE requests, meeting RT requests' latency\nrequirements while maintaining BE requests' throughput. BROS formulates the\nproblem of hybrid RT/BE request scheduling and solves it with a dynamic\npriority-based algorithm. BROS designs a bidirectional KV cache management\nmechanism, allowing RT requests to share KV memory with BE requests to remove\nthe scheduling restrictions caused by insufficient KV memory and improve\nutilization. Extensive experiments validate that BROS achieves a good trade-off\nwhen serving hybrid RT and BE requests. It significantly reduces the latency of\nRT requests (up to 74.20%), improving their fine-grained service level\nobjectives (SLOs) attainments (up to 36.38x), with negligible throughput\nreduction for BE requests, showing significant advantages over SOTA systems\nlike vLLM and TGI.",
      "tldr_zh": "该论文探讨了大型语言模型（LLM）服务中处理混合实时（RT）请求（如交互式问答）和尽力而为（BE）请求（如批量处理）的挑战，现有系统因资源隔离导致利用率低下。作者提出BROS系统，通过动态优先级算法和双向KV缓存管理机制，实现RT和BE请求的共存，确保RT请求的延迟降低（最高74.20%）和SLO实现提升（最高36.38倍），同时几乎不影响BE请求的吞吐量。实验结果显示，BROS相较于vLLM和TGI等SOTA系统显著提高了整体服务效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09590v1",
      "published_date": "2025-04-13 14:16:57 UTC",
      "updated_date": "2025-04-13 14:16:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:28:38.507030"
    },
    {
      "arxiv_id": "2504.09588v1",
      "title": "TextSplat: Text-Guided Semantic Fusion for Generalizable Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhicong Wu",
        "Hongbin Xu",
        "Gang Xu",
        "Ping Nie",
        "Zhixin Yan",
        "Jinkai Zheng",
        "Liangqiong Qu",
        "Ming Li",
        "Liqiang Nie"
      ],
      "abstract": "Recent advancements in Generalizable Gaussian Splatting have enabled robust\n3D reconstruction from sparse input views by utilizing feed-forward Gaussian\nSplatting models, achieving superior cross-scene generalization. However, while\nmany methods focus on geometric consistency, they often neglect the potential\nof text-driven guidance to enhance semantic understanding, which is crucial for\naccurately reconstructing fine-grained details in complex scenes. To address\nthis limitation, we propose TextSplat--the first text-driven Generalizable\nGaussian Splatting framework. By employing a text-guided fusion of diverse\nsemantic cues, our framework learns robust cross-modal feature representations\nthat improve the alignment of geometric and semantic information, producing\nhigh-fidelity 3D reconstructions. Specifically, our framework employs three\nparallel modules to obtain complementary representations: the Diffusion Prior\nDepth Estimator for accurate depth information, the Semantic Aware Segmentation\nNetwork for detailed semantic information, and the Multi-View Interaction\nNetwork for refined cross-view features. Then, in the Text-Guided Semantic\nFusion Module, these representations are integrated via the text-guided and\nattention-based feature aggregation mechanism, resulting in enhanced 3D\nGaussian parameters enriched with detailed semantic cues. Experimental results\non various benchmark datasets demonstrate improved performance compared to\nexisting methods across multiple evaluation metrics, validating the\neffectiveness of our framework. The code will be publicly available.",
      "tldr_zh": "本文提出 TextSplat，一种首创的文本驱动 Generalizable Gaussian Splatting 框架，用于从稀疏输入视图实现鲁棒的 3D 重建，同时提升语义理解以捕捉复杂场景的细粒度细节。该框架通过三个并行模块——Diffusion Prior Depth Estimator 用于准确深度信息、Semantic Aware Segmentation Network 用于详细语义信息，以及 Multi-View Interaction Network 用于精炼跨视图特征——并在 Text-Guided Semantic Fusion Module 中通过文本指导和注意力机制整合这些表示，生成增强的 3D Gaussian 参数。实验结果显示，在多种基准数据集上，TextSplat 在多个评估指标上优于现有方法，验证了其有效性，且代码将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09588v1",
      "published_date": "2025-04-13 14:14:10 UTC",
      "updated_date": "2025-04-13 14:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:28:51.481800"
    },
    {
      "arxiv_id": "2504.09583v1",
      "title": "AirVista-II: An Agentic System for Embodied UAVs Toward Dynamic Scene Semantic Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Lin",
        "Yonglin Tian",
        "Tengchao Zhang",
        "Jun Huang",
        "Sangtian Guan",
        "Fei-Yue Wang"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly important in dynamic\nenvironments such as logistics transportation and disaster response. However,\ncurrent tasks often rely on human operators to monitor aerial videos and make\noperational decisions. This mode of human-machine collaboration suffers from\nsignificant limitations in efficiency and adaptability. In this paper, we\npresent AirVista-II -- an end-to-end agentic system for embodied UAVs, designed\nto enable general-purpose semantic understanding and reasoning in dynamic\nscenes. The system integrates agent-based task identification and scheduling,\nmultimodal perception mechanisms, and differentiated keyframe extraction\nstrategies tailored for various temporal scenarios, enabling the efficient\ncapture of critical scene information. Experimental results demonstrate that\nthe proposed system achieves high-quality semantic understanding across diverse\nUAV-based dynamic scenarios under a zero-shot setting.",
      "tldr_zh": "该论文针对无人机（UAVs）在动态环境中的应用，如物流和灾害响应，指出依赖人类操作的局限性，导致效率和适应性不足。作者提出 AirVista-II，一个端到端的代理系统（agentic system），整合了基于代理的任务识别和调度、多模态感知机制以及针对不同时间场景的关键帧提取策略，以实现动态场景的通用语义理解和推理。实验结果显示，该系统在零样本（zero-shot）设置下，在多种 UAV 动态场景中实现了高质量的语义理解，证明了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09583v1",
      "published_date": "2025-04-13 14:06:50 UTC",
      "updated_date": "2025-04-13 14:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:29:01.669225"
    },
    {
      "arxiv_id": "2504.09582v1",
      "title": "Reduction of Supervision for Biomedical Knowledge Discovery",
      "title_zh": "生物医学知识发现中的监督减少",
      "authors": [
        "Christos Theodoropoulos",
        "Andrei Catalin Coman",
        "James Henderson",
        "Marie-Francine Moens"
      ],
      "abstract": "Knowledge discovery is hindered by the increasing volume of publications and\nthe scarcity of extensive annotated data. To tackle the challenge of\ninformation overload, it is essential to employ automated methods for knowledge\nextraction and processing. Finding the right balance between the level of\nsupervision and the effectiveness of models poses a significant challenge.\nWhile supervised techniques generally result in better performance, they have\nthe major drawback of demanding labeled data. This requirement is\nlabor-intensive and time-consuming and hinders scalability when exploring new\ndomains. In this context, our study addresses the challenge of identifying\nsemantic relationships between biomedical entities (e.g., diseases, proteins)\nin unstructured text while minimizing dependency on supervision. We introduce a\nsuite of unsupervised algorithms based on dependency trees and attention\nmechanisms and employ a range of pointwise binary classification methods.\nTransitioning from weakly supervised to fully unsupervised settings, we assess\nthe methods' ability to learn from data with noisy labels. The evaluation on\nbiomedical benchmark datasets explores the effectiveness of the methods. Our\napproach tackles a central issue in knowledge discovery: balancing performance\nwith minimal supervision. By gradually decreasing supervision, we assess the\nrobustness of pointwise binary classification techniques in handling noisy\nlabels, revealing their capability to shift from weakly supervised to entirely\nunsupervised scenarios. Comprehensive benchmarking offers insights into the\neffectiveness of these techniques, suggesting an encouraging direction toward\nadaptable knowledge discovery systems, representing progress in creating\ndata-efficient methodologies for extracting useful insights when annotated data\nis limited.",
      "tldr_zh": "本研究针对生物医学知识发现领域中，出版物数量激增和标注数据稀缺的问题，旨在减少对监督的依赖，以平衡模型性能和数据需求。研究引入了一系列基于 dependency trees 和 attention mechanisms 的 unsupervised algorithms，以及点式二元分类方法，从 weakly supervised 到 fully unsupervised 场景，评估这些方法在处理噪声标签时的鲁棒性。在生物医学基准数据集上的评估显示，该方法有效提升了知识提取效率，为创建数据高效的知识发现系统提供了新方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as part of the PhD dissertation: Theodoropoulos, Christos,\n  Marie-Francine Moens, and Matthew Blaschko. \"Deep Learning Models for the\n  Extraction of Knowledge from Text.\" (2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.09582v1",
      "published_date": "2025-04-13 14:05:40 UTC",
      "updated_date": "2025-04-13 14:05:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:29:14.074018"
    },
    {
      "arxiv_id": "2504.09574v1",
      "title": "Improved FOX Optimization Algorithm",
      "title_zh": "改进的 FOX 优化算法",
      "authors": [
        "Mahmood A. Jumaah",
        "Yossra H. Ali",
        "Tarik A. Rashid"
      ],
      "abstract": "Optimization algorithms are essential for solving many real-world problems.\nHowever, challenges such as premature convergence to local optima and the\ndifficulty of effectively balancing exploration and exploitation often hinder\ntheir performance. To address these issues, this paper proposes an improved FOX\noptimization algorithm, Improved FOX (IFOX). The IFOX algorithm introduces a\nnew adaptive mechanism for balancing exploration and exploitation based on\nfitness values. It also reduces the number of hyperparameters and simplifies\nthe core equations of the original FOX. To evaluate its effectiveness, IFOX has\nbeen tested on classical uni-modal and multi-modal benchmark functions, as well\nas on benchmark sets from the Congress on Evolutionary Computation (CEC), in\naddition to two engineering design problems: Pressure Vessel Design and\nEconomic Load Dispatch. The results show that IFOX outperforms existing\noptimization algorithms, achieving superior results on 51 benchmark functions.\nThese findings underscore the strong potential of IFOX as a competitive and\nrobust optimization algorithm for a wide range of applications.",
      "tldr_zh": "这篇论文针对优化算法的常见问题，如早熟收敛到局部最优和探索与利用的平衡困难，提出了Improved FOX (IFOX)算法。IFOX引入基于适应值的自适应机制来优化探索与利用的平衡，同时减少了超参数数量并简化了原FOX的核心方程。通过在经典单峰和多峰benchmark functions、Congress on Evolutionary Computation (CEC)基准集，以及Pressure Vessel Design和Economic Load Dispatch等工程设计问题上的测试，IFOX在51个基准函数上表现优于现有算法。这些结果突显了IFOX作为一种高效、鲁棒的优化工具在广泛应用中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.09574v1",
      "published_date": "2025-04-13 13:50:18 UTC",
      "updated_date": "2025-04-13 13:50:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:29:26.823761"
    },
    {
      "arxiv_id": "2504.09546v3",
      "title": "A simulation-heuristics dual-process model for intuitive physics",
      "title_zh": "翻译失败",
      "authors": [
        "Shiqian Li",
        "Yuxi Ma",
        "Jiajun Yan",
        "Bo Dai",
        "Yujia Peng",
        "Chi Zhang",
        "Yixin Zhu"
      ],
      "abstract": "The role of mental simulation in human physical reasoning is widely\nacknowledged, but whether it is employed across scenarios with varying\nsimulation costs and where its boundary lies remains unclear. Using a\npouring-marble task, our human study revealed two distinct error patterns when\npredicting pouring angles, differentiated by simulation time. While mental\nsimulation accurately captured human judgments in simpler scenarios, a linear\nheuristic model better matched human predictions when simulation time exceeded\na certain boundary. Motivated by these observations, we propose a dual-process\nframework, Simulation-Heuristics Model (SHM), where intuitive physics employs\nsimulation for short-time simulation but switches to heuristics when simulation\nbecomes costly. By integrating computational methods previously viewed as\nseparate into a unified model, SHM quantitatively captures their switching\nmechanism. The SHM aligns more precisely with human behavior and demonstrates\nconsistent predictive performance across diverse scenarios, advancing our\nunderstanding of the adaptive nature of intuitive physical reasoning.",
      "tldr_zh": "本文研究了心理模拟在人类直觉物理推理(intuitive physics)中的作用，通过倾倒弹珠任务实验，发现人类在模拟时间较短的简单场景中依赖mental simulation，而在模拟成本高时转向linear heuristic model，导致两种不同的错误模式。基于这些观察，作者提出Simulation-Heuristics Model (SHM)，一个双过程框架，将模拟和启发式方法整合，并量化了二者之间的切换机制。该模型更精确地匹配人类行为，并在多样场景中展现出稳定的预测性能，从而深化了对直觉物理推理适应性机制的理解。",
      "categories": [
        "physics.ed-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ed-ph",
      "comment": "8 pages, CogSci 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.09546v3",
      "published_date": "2025-04-13 12:34:02 UTC",
      "updated_date": "2025-05-19 11:39:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:29:39.561548"
    },
    {
      "arxiv_id": "2504.09532v1",
      "title": "Embodied Chain of Action Reasoning with Multi-Modal Foundation Model for Humanoid Loco-manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Hao",
        "Geeta Chandra Raju Bethala",
        "Niraj Pudasaini",
        "Hao Huang",
        "Shuaihang Yuan",
        "Congcong Wen",
        "Baoru Huang",
        "Anh Nguyen",
        "Yi Fang"
      ],
      "abstract": "Enabling humanoid robots to autonomously perform loco-manipulation tasks in\ncomplex, unstructured environments poses significant challenges. This entails\nequipping robots with the capability to plan actions over extended horizons\nwhile leveraging multi-modality to bridge gaps between high-level planning and\nactual task execution. Recent advancements in multi-modal foundation models\nhave showcased substantial potential in enhancing planning and reasoning\nabilities, particularly in the comprehension and processing of semantic\ninformation for robotic control tasks. In this paper, we introduce a novel\nframework based on foundation models that applies the embodied chain of action\nreasoning methodology to autonomously plan actions from textual instructions\nfor humanoid loco-manipulation. Our method integrates humanoid-specific chain\nof thought methodology, including detailed affordance and body movement\nanalysis, which provides a breakdown of the task into a sequence of locomotion\nand manipulation actions. Moreover, we incorporate spatial reasoning based on\nthe observation and target object properties to effectively navigate where\ntarget position may be unseen or occluded. Through rigorous experimental setups\non object rearrangement, manipulations and loco-manipulation tasks on a\nreal-world environment, we evaluate our method's efficacy on the decoupled\nupper and lower body control and demonstrate the effectiveness of the chain of\nrobotic action reasoning strategies in comprehending human instructions.",
      "tldr_zh": "该论文提出了一种基于多模态基础模型（Multi-Modal Foundation Model）的框架，用于人形机器人（Humanoid）自主执行 loco-manipulation 任务。该框架采用 Embodied Chain of Action Reasoning 方法，从文本指令中规划行动序列，包括详细的 affordance 和 body movement analysis，将任务分解为 locomotion 和 manipulation 的步骤，并整合空间推理以处理未见或被遮挡的目标位置。通过在真实环境中的物体重排和 loco-manipulation 实验，该方法证明了其在分离上肢和下肢控制中的有效性，并提升了机器人对人类指令的理解和执行能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09532v1",
      "published_date": "2025-04-13 11:37:32 UTC",
      "updated_date": "2025-04-13 11:37:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:29:51.648191"
    },
    {
      "arxiv_id": "2504.09522v1",
      "title": "How new data permeates LLM knowledge and how to dilute it",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Sun",
        "Renat Aksitov",
        "Andrey Zhmoginov",
        "Nolan Andrew Miller",
        "Max Vladymyrov",
        "Ulrich Rueckert",
        "Been Kim",
        "Mark Sandler"
      ],
      "abstract": "Large language models learn and continually learn through the accumulation of\ngradient-based updates, but how individual pieces of new information affect\nexisting knowledge, leading to both beneficial generalization and problematic\nhallucination, remains poorly understood. We demonstrate that when learning new\ninformation, LLMs exhibit a \"priming\" effect: learning a new fact can cause the\nmodel to inappropriately apply that knowledge in unrelated contexts. To\nsystematically study this phenomenon, we introduce \"Outlandish,\" a carefully\ncurated dataset of 1320 diverse text samples designed to probe how new\nknowledge permeates through an LLM's existing knowledge base. Using this\ndataset, we show that the degree of priming after learning new information can\nbe predicted by measuring the token probability of key words before learning.\nThis relationship holds robustly across different model architectures (PALM-2,\nGemma, Llama), sizes, and training stages. Finally, we develop two novel\ntechniques to modulate how new knowledge affects existing model behavior: (1) a\n``stepping-stone'' text augmentation strategy and (2) an ``ignore-k'' update\npruning method. These approaches reduce undesirable priming effects by 50-95\\%\nwhile preserving the model's ability to learn new information. Our findings\nprovide both empirical insights into how LLMs learn and practical tools for\nimproving the specificity of knowledge insertion in language models. Further\nmaterials: https://sunchipsster1.github.io/projects/outlandish/",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）在学习新数据时如何影响现有知识，揭示了“priming”效应，即学习新事实可能导致模型在不相关上下文中不当应用该知识。研究者构建了“Outlandish”数据集，包含1320个多样文本样本，通过测量学习前关键单词的token概率来预测priming程度，并证实此关系在PALM-2、Gemma和Llama等不同模型架构、大小和训练阶段中均适用。为缓解这一问题，论文提出两种新技巧：(1) “stepping-stone”文本增强策略和(2) “ignore-k”更新修剪方法，这些方法可将不期望的priming效果减少50-95%，同时保留模型的学习能力。这些发现提供了LLMs学习机制的实证洞见，并为提升知识插入的特定性提供了实用工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09522v1",
      "published_date": "2025-04-13 11:25:04 UTC",
      "updated_date": "2025-04-13 11:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:30:03.970314"
    },
    {
      "arxiv_id": "2504.12333v1",
      "title": "Meta-Evaluating Local LLMs: Rethinking Performance Metrics for Serious Games",
      "title_zh": "翻译失败",
      "authors": [
        "Andrés Isaza-Giraldo",
        "Paulo Bala",
        "Lucas Pereira"
      ],
      "abstract": "The evaluation of open-ended responses in serious games presents a unique\nchallenge, as correctness is often subjective. Large Language Models (LLMs) are\nincreasingly being explored as evaluators in such contexts, yet their accuracy\nand consistency remain uncertain, particularly for smaller models intended for\nlocal execution. This study investigates the reliability of five small-scale\nLLMs when assessing player responses in \\textit{En-join}, a game that simulates\ndecision-making within energy communities. By leveraging traditional binary\nclassification metrics (including accuracy, true positive rate, and true\nnegative rate), we systematically compare these models across different\nevaluation scenarios. Our results highlight the strengths and limitations of\neach model, revealing trade-offs between sensitivity, specificity, and overall\nperformance. We demonstrate that while some models excel at identifying correct\nresponses, others struggle with false positives or inconsistent evaluations.\nThe findings highlight the need for context-aware evaluation frameworks and\ncareful model selection when deploying LLMs as evaluators. This work\ncontributes to the broader discourse on the trustworthiness of AI-driven\nassessment tools, offering insights into how different LLM architectures handle\nsubjective evaluation tasks.",
      "tldr_zh": "本研究评估了小型本地大型语言模型（LLMs）在严肃游戏中评估开放式玩家响应的可靠性，针对主观正确性的挑战，使用 \\textit{En-join} 游戏作为测试场景。研究者通过二元分类指标（如准确率、真阳性率和真阴性率）比较了五个小型 LLMs 的表现，揭示了各模型在敏感性、特异性和整体性能上的权衡，例如某些模型擅长识别正确响应但易出现假阳性或不一致问题。结果强调了开发上下文感知评估框架和谨慎模型选择的重要性，为提升 AI 驱动评估工具的 trustworthiness 提供了关键见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "2nd HEAL Workshop at CHI Conference on Human Factors in Computing\n  Systems. April 26, 2025. Yokohama, Japan",
      "pdf_url": "http://arxiv.org/pdf/2504.12333v1",
      "published_date": "2025-04-13 10:46:13 UTC",
      "updated_date": "2025-04-13 10:46:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:30:15.017981"
    },
    {
      "arxiv_id": "2504.13194v1",
      "title": "Optimizing Multi-Gateway LoRaWAN via Cloud-Edge Collaboration and Knowledge Distillation",
      "title_zh": "通过云边协作和知识蒸馏优化多网关 LoRaWAN",
      "authors": [
        "Hong Yang"
      ],
      "abstract": "For large-scale multi-gateway LoRaWAN networks, this study proposes a\ncloud-edge collaborative resource allocation and decision-making method based\non edge intelligence, HEAT-LDL (HEAT-Local Distill Lyapunov), which realizes\ncollaborative decision-making between gateways and terminal nodes. HEAT-LDL\ncombines the Actor-Critic architecture and the Lyapunov optimization method to\nachieve intelligent downlink control and gateway load balancing. When the\nsignal quality is good, the network server uses the HEAT algorithm to schedule\nthe terminal nodes. To improve the efficiency of autonomous decision-making of\nterminal nodes, HEAT-LDL performs cloud-edge knowledge distillation on the HEAT\nteacher model on the terminal node side. When the downlink decision instruction\nis lost, the terminal node uses the student model and the edge decider based on\nprior knowledge and local history to make collaborative autonomous decisions.\nSimulation experiments show that compared with the optimal results of all\ncompared algorithms, HEAT-LDL improves the packet success rate and energy\nefficiency by 20.5% and 88.1%, respectively.",
      "tldr_zh": "本研究针对大规模多网关 LoRaWAN 网络，提出了一种基于云边协作的资源分配和决策方法，名为 HEAT-LDL，利用 Actor-Critic 架构和 Lyapunov 优化实现智能下行控制以及网关负载均衡。方法通过 HEAT 算法在信号质量良好时由网络服务器调度终端节点，并采用知识蒸馏（knowledge distillation）技术提升终端节点的自主决策效率，当决策指令丢失时，终端节点可基于先验知识和本地历史进行协作决策。模拟实验结果显示，HEAT-LDL 相比其他算法，提高了包成功率 20.5% 和 能效 88.1%。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13194v1",
      "published_date": "2025-04-13 10:34:37 UTC",
      "updated_date": "2025-04-13 10:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:30:27.603856"
    },
    {
      "arxiv_id": "2504.13193v1",
      "title": "HEAT:History-Enhanced Dual-phase Actor-Critic Algorithm with A Shared Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Yang"
      ],
      "abstract": "For a single-gateway LoRaWAN network, this study proposed a history-enhanced\ntwo-phase actor-critic algorithm with a shared transformer algorithm (HEAT) to\nimprove network performance. HEAT considers uplink parameters and often\nneglected downlink parameters, and effectively integrates offline and online\nreinforcement learning, using historical data and real-time interaction to\nimprove model performance. In addition, this study developed an open source\nLoRaWAN network simulator LoRaWANSim. The simulator considers the demodulator\nlock effect and supports multi-channel, multi-demodulator and bidirectional\ncommunication. Simulation experiments show that compared with the best results\nof all compared algorithms, HEAT improves the packet success rate and energy\nefficiency by 15% and 95%, respectively.",
      "tldr_zh": "本研究提出了一种名为 HEAT 的历史增强双阶段 Actor-Critic 算法，使用共享 Transformer，旨在提升单网关 LoRaWAN 网络的性能，通过整合离线和在线强化学习来利用历史数据与实时交互，并考虑上行和下行参数。HEAT 的创新在于有效优化模型，处理网络中的关键挑战，如数据包传输和能量消耗。该研究还开发了开源模拟器 LoRaWANSim，支持多通道、多解调器和双向通信，并考虑了解调器锁定效果。实验结果显示，HEAT 相较于基准算法，提高了 15% 的数据包成功率和 95% 的能量效率。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13193v1",
      "published_date": "2025-04-13 10:32:02 UTC",
      "updated_date": "2025-04-13 10:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:30:40.089055"
    },
    {
      "arxiv_id": "2504.09499v1",
      "title": "Decoding the mechanisms of the Hattrick football manager game using Bayesian network structure learning for optimal decision-making",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony C. Constantinou",
        "Nicholas Higgins",
        "Neville K. Kitson"
      ],
      "abstract": "Hattrick is a free web-based probabilistic football manager game with over\n200,000 users competing for titles at national and international levels.\nLaunched in Sweden in 1997 as part of an MSc project, the game's slow-paced\ndesign has fostered a loyal community, with many users remaining active for\ndecades. Hattrick's game-engine mechanics are partially hidden, and users have\nattempted to decode them with incremental success over the years. Rule-based,\nstatistical and machine learning models have been developed to aid this effort\nand are widely used by the community. However, these models or tools have not\nbeen formally described or evaluated in the scientific literature. This study\nis the first to explore Hattrick using structure learning techniques and\nBayesian networks, integrating both data and domain knowledge to develop models\ncapable of explaining and simulating the game engine. We present a\ncomprehensive analysis assessing the effectiveness of structure learning\nalgorithms in relation to knowledge-based structures, and show that while\nstructure learning may achieve a higher overall network fit, it does not result\nin more accurate predictions for selected variables of interest, when compared\nto knowledge-based networks that produce a lower overall network fit.\nAdditionally, we introduce and publicly share a fully specified Bayesian\nnetwork model that matches the performance of top models used by the Hattrick\ncommunity. We further demonstrate how analysis extends beyond prediction by\nproviding a visual representation of conditional dependencies, and using the\nbest performing Bayesian network model for in-game decision-making. To support\nfuture research, we make all data, graphical structures, and models publicly\navailable online.",
      "tldr_zh": "这篇论文首次使用Bayesian network结构学习技术来解码Hattrick足球经理游戏的隐藏机制，整合数据和领域知识以构建模型，用于解释和模拟游戏引擎。研究比较了结构学习算法与基于知识的网络，发现尽管结构学习能实现更高整体网络拟合度，但它在关键变量预测准确性上并不优于知识-based网络。作者公开分享了一个性能与社区顶级模型相当的完全指定Bayesian network模型，并展示了其在游戏决策中的应用，如可视化条件依赖关系，以支持未来的研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09499v1",
      "published_date": "2025-04-13 09:50:20 UTC",
      "updated_date": "2025-04-13 09:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:30:53.376029"
    },
    {
      "arxiv_id": "2504.09493v1",
      "title": "Federated Prototype Graph Learning",
      "title_zh": "联邦原型图学习",
      "authors": [
        "Zhengyu Wu",
        "Xunkai Li",
        "Yinlin Zhu",
        "Rong-Hua Li",
        "Guoren Wang",
        "Chenghu Zhou"
      ],
      "abstract": "In recent years, Federated Graph Learning (FGL) has gained significant\nattention for its distributed training capabilities in graph-based machine\nintelligence applications, mitigating data silos while offering a new\nperspective for privacy-preserve large-scale graph learning. However,\nmulti-level FGL heterogeneity presents various client-server collaboration\nchallenges: (1) Model-level: The variation in clients for expected performance\nand scalability necessitates the deployment of heterogeneous models.\nUnfortunately, most FGL methods rigidly demand identical client models due to\nthe direct model weight aggregation on the server. (2) Data-level: The\nintricate nature of graphs, marked by the entanglement of node profiles and\ntopology, poses an optimization dilemma. This implies that models obtained by\nfederated training struggle to achieve superior performance. (3)\nCommunication-level: Some FGL methods attempt to increase message sharing among\nclients or between clients and the server to improve training, which inevitably\nleads to high communication costs. In this paper, we propose FedPG as a general\nprototype-guided optimization method for the above multi-level FGL\nheterogeneity. Specifically, on the client side, we integrate multi-level\ntopology-aware prototypes to capture local graph semantics. Subsequently, on\nthe server side, leveraging the uploaded prototypes, we employ topology-guided\ncontrastive learning and personalized technology to tailor global prototypes\nfor each client, broadcasting them to improve local training. Experiments\ndemonstrate that FedPG outperforms SOTA baselines by an average of 3.57\\% in\naccuracy while reducing communication costs by 168x.",
      "tldr_zh": "近年来，Federated Graph Learning (FGL) 因其在图-based 机器智能应用中的分布式训练能力而备受关注，但面临模型级（客户端模型异构性）、数据级（图数据复杂性）和通信级（高成本）异构挑战，导致训练优化困难。针对这些问题，本文提出 FedPG，一种通用的原型引导优化方法：在客户端整合多级拓扑感知 prototypes 来捕获本地图语义，在服务端通过拓扑-guided 对比学习和个性化技术定制全局 prototypes，并广播回客户端以改善训练。实验结果表明，FedPG 比最先进基线平均准确率提高 3.57%，同时将通信成本减少 168 倍，为隐私保护的大型图学习提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.09493v1",
      "published_date": "2025-04-13 09:21:21 UTC",
      "updated_date": "2025-04-13 09:21:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:31:05.239027"
    },
    {
      "arxiv_id": "2504.10541v1",
      "title": "Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Guo",
        "Tong Zhang",
        "Yuanzhi Wang",
        "Chenxu Wang",
        "Fuyun Wang",
        "Xudong Wang",
        "Xiaoya Zhang",
        "Xin Liu",
        "Zhen Cui"
      ],
      "abstract": "The burgeoning presence of Large Language Models (LLM) is propelling the\ndevelopment of personalized recommender systems. Most existing LLM-based\nmethods fail to sufficiently explore the multi-view graph structure\ncorrelations inherent in recommendation scenarios. To this end, we propose a\nnovel framework, Hypergraph Enhanced LLM Learning for multimodal Recommendation\n(HeLLM), designed to equip LLMs with the capability to capture intricate\nhigher-order semantic correlations by fusing graph-level contextual signals\nwith sequence-level behavioral patterns. In the recommender pre-training phase,\nwe design a user hypergraph to uncover shared interest preferences among users\nand an item hypergraph to capture correlations within multimodal similarities\namong items. The hypergraph convolution and synergistic contrastive learning\nmechanism are introduced to enhance the distinguishability of learned\nrepresentations. In the LLM fine-tuning phase, we inject the learned\ngraph-structured embeddings directly into the LLM's architecture and integrate\nsequential features capturing each user's chronological behavior. This process\nenables hypergraphs to leverage graph-structured information as global context,\nenhancing the LLM's ability to perceive complex relational patterns and\nintegrate multimodal information, while also modeling local temporal dynamics.\nExtensive experiments demonstrate the superiority of our proposed method over\nstate-of-the-art baselines, confirming the advantages of fusing\nhypergraph-based context with sequential user behavior in LLMs for\nrecommendation.",
      "tldr_zh": "本文提出 HeLLM 框架，通过融合多模态超图结构来增强大型语言模型 (LLM) 在个性化推荐系统中的性能，解决现有方法对多视图图结构相关性的不足。框架在预训练阶段使用用户 hypergraph 揭示共享兴趣偏好、物品 hypergraph 捕捉多模态相似性，并引入 hypergraph convolution 和 synergistic contrastive learning 机制来提升表示的可区分性。在 LLM 微调阶段，将学到的图结构嵌入注入模型架构，并整合顺序特征以捕捉用户的时间行为动态。实验结果表明，HeLLM 优于现有基线方法，证明了融合超图上下文和顺序行为的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10541v1",
      "published_date": "2025-04-13 09:12:35 UTC",
      "updated_date": "2025-04-13 09:12:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:31:16.324004"
    },
    {
      "arxiv_id": "2504.09482v1",
      "title": "HalluShift: Measuring Distribution Shifts towards Hallucination Detection in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sharanya Dasgupta",
        "Sujoy Nath",
        "Arkaprabha Basu",
        "Pourya Shamsolmoali",
        "Swagatam Das"
      ],
      "abstract": "Large Language Models (LLMs) have recently garnered widespread attention due\nto their adeptness at generating innovative responses to the given prompts\nacross a multitude of domains. However, LLMs often suffer from the inherent\nlimitation of hallucinations and generate incorrect information while\nmaintaining well-structured and coherent responses. In this work, we\nhypothesize that hallucinations stem from the internal dynamics of LLMs. Our\nobservations indicate that, during passage generation, LLMs tend to deviate\nfrom factual accuracy in subtle parts of responses, eventually shifting toward\nmisinformation. This phenomenon bears a resemblance to human cognition, where\nindividuals may hallucinate while maintaining logical coherence, embedding\nuncertainty within minor segments of their speech. To investigate this further,\nwe introduce an innovative approach, HalluShift, designed to analyze the\ndistribution shifts in the internal state space and token probabilities of the\nLLM-generated responses. Our method attains superior performance compared to\nexisting baselines across various benchmark datasets. Our codebase is available\nat https://github.com/sharanya-dasgupta001/hallushift.",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)中幻觉(hallucinations)的成因，假设这些错误信息源于模型的内部动态，并观察到LLMs在生成响应时会逐步偏离事实。作者提出HalluShift方法，通过分析LLMs生成响应中的内部状态空间和token概率的分布偏移(distribution shifts)，来有效检测幻觉。该方法在多个基准数据集上比现有基线表现出色，并提供了开源代码库。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09482v1",
      "published_date": "2025-04-13 08:35:22 UTC",
      "updated_date": "2025-04-13 08:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:31:27.353411"
    },
    {
      "arxiv_id": "2504.10540v1",
      "title": "AB-Cache: Training-Free Acceleration of Diffusion Models via Adams-Bashforth Cached Feature Reuse",
      "title_zh": "翻译失败",
      "authors": [
        "Zichao Yu",
        "Zhen Zou",
        "Guojiang Shao",
        "Chengwei Zhang",
        "Shengze Xu",
        "Jie Huang",
        "Feng Zhao",
        "Xiaodong Cun",
        "Wenyi Zhang"
      ],
      "abstract": "Diffusion models have demonstrated remarkable success in generative tasks,\nyet their iterative denoising process results in slow inference, limiting their\npracticality. While existing acceleration methods exploit the well-known\nU-shaped similarity pattern between adjacent steps through caching mechanisms,\nthey lack theoretical foundation and rely on simplistic computation reuse,\noften leading to performance degradation. In this work, we provide a\ntheoretical understanding by analyzing the denoising process through the\nsecond-order Adams-Bashforth method, revealing a linear relationship between\nthe outputs of consecutive steps. This analysis explains why the outputs of\nadjacent steps exhibit a U-shaped pattern. Furthermore, extending\nAdams-Bashforth method to higher order, we propose a novel caching-based\nacceleration approach for diffusion models, instead of directly reusing cached\nresults, with a truncation error bound of only \\(O(h^k)\\) where $h$ is the step\nsize. Extensive validation across diverse image and video diffusion models\n(including HunyuanVideo and FLUX.1-dev) with various schedulers demonstrates\nour method's effectiveness in achieving nearly $3\\times$ speedup while\nmaintaining original performance levels, offering a practical real-time\nsolution without compromising generation quality.",
      "tldr_zh": "本研究针对扩散模型（Diffusion Models）的慢速推理问题，提出了一种无需训练（Training-Free）的加速方法AB-Cache，通过分析去噪过程并应用二阶Adams-Bashforth方法，揭示了连续步骤输出之间的线性关系，从而解释了相邻步骤的U-shaped相似性模式。不同于现有方法的简单缓存重用，该方法扩展Adams-Bashforth到更高阶，并引入截断误差界限仅为O(h^k)的缓存特征重用策略。实验在多种图像和视频扩散模型（如HunyuanVideo和FLUX.1-dev）上验证，实现了近3倍的加速，同时保持了原始生成质量，提供了一个实用的实时解决方案。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10540v1",
      "published_date": "2025-04-13 08:29:58 UTC",
      "updated_date": "2025-04-13 08:29:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:31:39.995227"
    },
    {
      "arxiv_id": "2504.10539v2",
      "title": "Physics-Informed Neural Networks for Enhanced Interface Preservation in Lattice Boltzmann Multiphase Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Li",
        "Lihong Zhang"
      ],
      "abstract": "This paper presents an improved approach for preserving sharp interfaces in\nmultiphase Lattice Boltzmann Method (LBM) simulations using Physics-Informed\nNeural Networks (PINNs). Interface diffusion is a common challenge in\nmultiphase LBM, leading to reduced accuracy in simulating phenomena where\ninterfacial dynamics are critical. We propose a coupled PINN-LBM framework that\nmaintains interface sharpness while preserving the physical accuracy of the\nsimulation. Our approach is validated through droplet simulations, with\nquantitative metrics measuring interface width, maximum gradient, phase\nseparation, effective interface width, and interface energy. The enhanced\nvisualization techniques employed in this work clearly demonstrate the superior\nperformance of PINN-LBM over standard LBM for multiphase simulations,\nparticularly in maintaining well-defined interfaces throughout the simulation.\nWe provide a comprehensive analysis of the results, showcasing how the neural\nnetwork integration effectively counteracts numerical diffusion, while\nmaintaining physical consistency with the underlying fluid dynamics.",
      "tldr_zh": "这篇论文提出了一种改进方法，使用 Physics-Informed Neural Networks (PINNs) 来增强多相 Lattice Boltzmann Method (LBM) 模拟中的界面保持，解决界面扩散导致的模拟准确性问题。研究团队开发了一个耦合的 PINN-LBM 框架，确保界面清晰的同时维持物理准确性，并通过液滴模拟进行验证。实验结果显示，该框架在界面宽度、最大梯度及相分离等定量指标上显著优于标准 LBM，有效对抗数值扩散并保持流体动力学的一致性。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10539v2",
      "published_date": "2025-04-13 08:29:00 UTC",
      "updated_date": "2025-04-18 20:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:31:52.302679"
    },
    {
      "arxiv_id": "2504.09480v1",
      "title": "Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation",
      "title_zh": "视觉语言模型用于物体检测和分割：综述与评估",
      "authors": [
        "Yongchao Feng",
        "Yajie Liu",
        "Shuai Yang",
        "Wenrui Cai",
        "Jinqing Zhang",
        "Qiqi Zhan",
        "Ziyue Huang",
        "Hongxi Yan",
        "Qiao Wan",
        "Chenguang Liu",
        "Junzhe Wang",
        "Jiahui Lv",
        "Ziqi Liu",
        "Tengyuan Shi",
        "Qingjie Liu",
        "Yunhong Wang"
      ],
      "abstract": "Vision-Language Model (VLM) have gained widespread adoption in\nOpen-Vocabulary (OV) object detection and segmentation tasks. Despite they have\nshown promise on OV-related tasks, their effectiveness in conventional vision\ntasks has thus far been unevaluated. In this work, we present the systematic\nreview of VLM-based detection and segmentation, view VLM as the foundational\nmodel and conduct comprehensive evaluations across multiple downstream tasks\nfor the first time: 1) The evaluation spans eight detection scenarios\n(closed-set detection, domain adaptation, crowded objects, etc.) and eight\nsegmentation scenarios (few-shot, open-world, small object, etc.), revealing\ndistinct performance advantages and limitations of various VLM architectures\nacross tasks. 2) As for detection tasks, we evaluate VLMs under three\nfinetuning granularities: \\textit{zero prediction}, \\textit{visual\nfine-tuning}, and \\textit{text prompt}, and further analyze how different\nfinetuning strategies impact performance under varied task. 3) Based on\nempirical findings, we provide in-depth analysis of the correlations between\ntask characteristics, model architectures, and training methodologies, offering\ninsights for future VLM design. 4) We believe that this work shall be valuable\nto the pattern recognition experts working in the fields of computer vision,\nmultimodal learning, and vision foundation models by introducing them to the\nproblem, and familiarizing them with the current status of the progress while\nproviding promising directions for future research. A project associated with\nthis review and evaluation has been created at\nhttps://github.com/better-chao/perceptual_abilities_evaluation.",
      "tldr_zh": "本论文对Vision-Language Model (VLM) 在对象检测和分割任务中的应用进行了系统综述和评估，首次探讨了VLM在传统视觉任务中的有效性。研究评估了VLM在八种检测场景（如closed-set detection和domain adaptation）和八种分割场景（如few-shot和open-world）中的性能，揭示了不同VLM架构的优势和限制，并分析了zero prediction、visual fine-tuning和text prompt等微调策略对任务表现的影响。基于经验发现，论文提供了任务特征、模型架构和训练方法之间的深入相关性分析，为未来VLM设计和计算机视觉研究提供了宝贵见解。相关项目可参考https://github.com/better-chao/perceptual_abilities_evaluation。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "A Review and Evaluation about Vision-Language Model for Object\n  Detection and Segmentation",
      "pdf_url": "http://arxiv.org/pdf/2504.09480v1",
      "published_date": "2025-04-13 08:28:13 UTC",
      "updated_date": "2025-04-13 08:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:32:04.047013"
    },
    {
      "arxiv_id": "2504.09479v1",
      "title": "Draw with Thought: Unleashing Multimodal Reasoning for Scientific Diagram Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqing Cui",
        "Jiahao Yuan",
        "Hanqing Wang",
        "Yanshu Li",
        "Chenxu Du",
        "Zhenglong Ding"
      ],
      "abstract": "Scientific diagrams are vital tools for communicating structured knowledge\nacross disciplines. However, they are often published as static raster images,\nlosing symbolic semantics and limiting reuse. While Multimodal Large Language\nModels (MLLMs) offer a pathway to bridging vision and structure, existing\nmethods lack semantic control and structural interpretability, especially on\ncomplex diagrams. We propose Draw with Thought (DwT), a training-free framework\nthat guides MLLMs to reconstruct diagrams into editable mxGraph XML code\nthrough cognitively-grounded Chain-of-Thought reasoning. DwT enables\ninterpretable and controllable outputs without model fine-tuning by dividing\nthe task into two stages: Coarse-to-Fine Planning, which handles perceptual\nstructuring and semantic specification, and Structure-Aware Code Generation,\nenhanced by format-guided refinement. To support evaluation, we release\nPlot2XML, a benchmark of 247 real-world scientific diagrams with gold-standard\nXML annotations. Extensive experiments across eight MLLMs show that our\napproach yields high-fidelity, semantically aligned, and structurally valid\nreconstructions, with human evaluations confirming strong alignment in both\naccuracy and visual aesthetics, offering a scalable solution for converting\nstatic visuals into executable representations and advancing machine\nunderstanding of scientific graphics.",
      "tldr_zh": "本研究提出Draw with Thought (DwT)，一个无训练框架，利用Multimodal Large Language Models (MLLMs)通过Chain-of-Thought推理，将静态科学图表重建为可编辑的mxGraph XML代码，以解决现有方法在语义控制和结构可解释性上的不足。DwT框架分为两个阶段：Coarse-to-Fine Planning处理感知结构化和语义规格，以及Structure-Aware Code Generation通过格式引导的精炼确保输出质量。为支持评估，该研究发布了Plot2XML基准，包含247个真实世界科学图表的金标准XML注解。实验结果显示，DwT在八个MLLMs上实现了高保真度、语义对齐和结构有效的重建，人类评估进一步证实了其在准确性和视觉美学方面的优势，为将静态视觉转换为可执行表示提供了可扩展的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09479v1",
      "published_date": "2025-04-13 08:22:09 UTC",
      "updated_date": "2025-04-13 08:22:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:32:16.669888"
    },
    {
      "arxiv_id": "2504.09478v1",
      "title": "A highly maneuverable flying squirrel drone with controllable foldable wings",
      "title_zh": "一种高度机动性的飞鼠无人机，带有可控可折叠机翼",
      "authors": [
        "Jun-Gill Kang",
        "Dohyeon Lee",
        "Soohee Han"
      ],
      "abstract": "Typical drones with multi rotors are generally less maneuverable due to\nunidirectional thrust, which may be unfavorable to agile flight in very narrow\nand confined spaces. This paper suggests a new bio-inspired drone that is\nempowered with high maneuverability in a lightweight and easy-to-carry way. The\nproposed flying squirrel inspired drone has controllable foldable wings to\ncover a wider range of flight attitudes and provide more maneuverable flight\ncapability with stable tracking performance. The wings of a drone are\nfabricated with silicone membranes and sophisticatedly controlled by\nreinforcement learning based on human-demonstrated data. Specially, such\nlearning based wing control serves to capture even the complex aerodynamics\nthat are often impossible to model mathematically. It is shown through\nexperiment that the proposed flying squirrel drone intentionally induces\naerodynamic drag and hence provides the desired additional repulsive force even\nunder saturated mechanical thrust. This work is very meaningful in\ndemonstrating the potential of biomimicry and machine learning for realizing an\nanimal-like agile drone.",
      "tldr_zh": "本文提出了一种受飞鼠启发的无人机，具有可控折叠翅膀，旨在解决传统多旋翼无人机因单向推力而导致的机动性不足问题，尤其在狭窄空间的敏捷飞行。该无人机的翅膀由硅胶膜制成，并通过基于人类演示数据的reinforcement learning进行控制，以捕捉复杂的空气动力学，实现更广泛的飞行姿态和稳定跟踪性能。实验结果显示，该无人机能有意产生空气阻力，提供额外的排斥力，即使在机械推力饱和时，也显著提升机动性；这项工作突显了biomimicry和机器学习在开发类似动物般敏捷无人机的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at 2023 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS), Project Page :\n  https://jgkang1210.github.io/fsdrone/ , Video :\n  https://youtu.be/Cfc-llDb3_k?si=Cal5beZw6f3HZ2ZW , Jun-Gill Kang and Dohyeon\n  Lee are co-authors",
      "pdf_url": "http://arxiv.org/pdf/2504.09478v1",
      "published_date": "2025-04-13 08:15:28 UTC",
      "updated_date": "2025-04-13 08:15:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:32:28.231578"
    },
    {
      "arxiv_id": "2504.09474v1",
      "title": "MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions",
      "title_zh": "翻译失败",
      "authors": [
        "Pucheng Dang",
        "Di Huang",
        "Dong Li",
        "Kang Chen",
        "Yuanbo Wen",
        "Qi Guo",
        "Xing Hu",
        "Ninghui Sun"
      ],
      "abstract": "Out-of-tree kernel patches are essential for adapting the Linux kernel to new\nhardware or enabling specific functionalities. Maintaining and updating these\npatches across different kernel versions demands significant effort from\nexperienced engineers. Large language models (LLMs) have shown remarkable\nprogress across various domains, suggesting their potential for automating\nout-of-tree kernel patch migration. However, our findings reveal that LLMs,\nwhile promising, struggle with incomplete code context understanding and\ninaccurate migration point identification. In this work, we propose MigGPT, a\nframework that employs a novel code fingerprint structure to retain code\nsnippet information and incorporates three meticulously designed modules to\nimprove the migration accuracy and efficiency of out-of-tree kernel patches.\nFurthermore, we establish a robust benchmark using real-world out-of-tree\nkernel patch projects to evaluate LLM capabilities. Evaluations show that\nMigGPT significantly outperforms the direct application of vanilla LLMs,\nachieving an average completion rate of 72.59% (50.74% improvement) for\nmigration tasks.",
      "tldr_zh": "该研究针对 out-of-tree Linux kernel patches 的维护难题，利用 Large Language Models (LLMs) 提出 MigGPT 框架，以自动化 patches 跨版本迁移。MigGPT 采用新型代码指纹结构保留代码片段信息，并集成三个精心设计的模块，提升迁移的准确性和效率，同时解决 LLMs 在代码上下文理解和迁移点识别上的不足。实验基于真实世界项目基准评估，结果显示 MigGPT 的平均完成率达到 72.59%，比直接使用 vanilla LLMs 提高了 50.74%。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.OS"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09474v1",
      "published_date": "2025-04-13 08:08:37 UTC",
      "updated_date": "2025-04-13 08:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:32:39.828385"
    },
    {
      "arxiv_id": "2504.10538v1",
      "title": "Distilling Transitional Pattern to Large Language Models for Multimodal Session-based Recommendation",
      "title_zh": "将过渡模式蒸馏到大语言模型中，用于多",
      "authors": [
        "Jiajie Su",
        "Qiyong Zhong",
        "Yunshan Ma",
        "Weiming Liu",
        "Chaochao Chen",
        "Xiaolin Zheng",
        "Jianwei Yin",
        "Tat-Seng Chua"
      ],
      "abstract": "Session-based recommendation (SBR) predicts the next item based on anonymous\nsessions. Traditional SBR explores user intents based on ID collaborations or\nauxiliary content. To further alleviate data sparsity and cold-start issues,\nrecent Multimodal SBR (MSBR) methods utilize simplistic pre-trained models for\nmodality learning but have limitations in semantic richness. Considering\nsemantic reasoning abilities of Large Language Models (LLM), we focus on the\nLLM-enhanced MSBR scenario in this paper, which leverages LLM cognition for\ncomprehensive multimodal representation generation, to enhance downstream MSBR.\nTackling this problem faces two challenges: i) how to obtain LLM cognition on\nboth transitional patterns and inherent multimodal knowledge, ii) how to align\nboth features into one unified LLM, minimize discrepancy while maximizing\nrepresentation utility. To this end, we propose a multimodal LLM-enhanced\nframework TPAD, which extends a distillation paradigm to decouple and align\ntransitional patterns for promoting MSBR. TPAD establishes parallel\nKnowledge-MLLM and Transfer-MLLM, where the former interprets item\nknowledge-reflected features and the latter extracts transition-aware features\nunderneath sessions. A transitional pattern alignment module harnessing mutual\ninformation estimation theory unites two MLLMs, alleviating distribution\ndiscrepancy and distilling transitional patterns into modal representations.\nExtensive experiments on real-world datasets demonstrate the effectiveness of\nour framework.",
      "tldr_zh": "这篇论文针对多模态基于会话的推荐系统 (MSBR) 的数据稀疏和冷启动问题，提出了一种框架 TPAD，将过渡模式蒸馏到大型语言模型 (LLM) 中，以提升多模态表示的语义推理能力。TPAD 通过 Knowledge-MLLM 处理项目知识特征，以及 Transfer-MLLM 提取会话中的过渡感知特征，并利用过渡模式对齐模块基于互信息估计理论来对齐两者，减少分布差异并优化表示。实验在真实数据集上证明了 TPAD 的有效性，显著提高了 MSBR 的推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10538v1",
      "published_date": "2025-04-13 07:49:08 UTC",
      "updated_date": "2025-04-13 07:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:32:52.732549"
    },
    {
      "arxiv_id": "2504.12331v1",
      "title": "Span-level Emotion-Cause-Category Triplet Extraction with Instruction Tuning LLMs and Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangju Li",
        "Dong Yang",
        "Xiaogang Zhu",
        "Faliang Huang",
        "Peng Zhang",
        "Zhongying Zhao"
      ],
      "abstract": "Span-level emotion-cause-category triplet extraction represents a novel and\ncomplex challenge within emotion cause analysis. This task involves identifying\nemotion spans, cause spans, and their associated emotion categories within the\ntext to form structured triplets. While prior research has predominantly\nconcentrated on clause-level emotion-cause pair extraction and span-level\nemotion-cause detection, these methods often confront challenges originating\nfrom redundant information retrieval and difficulty in accurately determining\nemotion categories, particularly when emotions are expressed implicitly or\nambiguously. To overcome these challenges, this study explores a fine-grained\napproach to span-level emotion-cause-category triplet extraction and introduces\nan innovative framework that leverages instruction tuning and data augmentation\ntechniques based on large language models. The proposed method employs\ntask-specific triplet extraction instructions and utilizes low-rank adaptation\nto fine-tune large language models, eliminating the necessity for intricate\ntask-specific architectures. Furthermore, a prompt-based data augmentation\nstrategy is developed to address data scarcity by guiding large language models\nin generating high-quality synthetic training data. Extensive experimental\nevaluations demonstrate that the proposed approach significantly outperforms\nexisting baseline methods, achieving at least a 12.8% improvement in span-level\nemotion-cause-category triplet extraction metrics. The results demonstrate the\nmethod's effectiveness and robustness, offering a promising avenue for\nadvancing research in emotion cause analysis. The source code is available at\nhttps://github.com/zxgnlp/InstruDa-LLM.",
      "tldr_zh": "本文提出了一种针对 span-level emotion-cause-category triplet extraction 的创新框架，以解决现有方法在处理冗余信息和模糊情感类别时的挑战。该框架利用 instruction tuning large language models (LLMs) 和 data augmentation 技术，通过任务特定指令和 low-rank adaptation 进行模型微调，避免了复杂架构的设计。同时，引入了基于提示的 data augmentation 策略来生成高质量合成数据，缓解数据稀缺问题。实验结果显示，该方法在相关指标上比基线方法提高了至少 12.8%，证明了其有效性和鲁棒性，并开源了代码以推进情感原因分析研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.12331v1",
      "published_date": "2025-04-13 07:31:09 UTC",
      "updated_date": "2025-04-13 07:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:33:07.756190"
    },
    {
      "arxiv_id": "2504.09463v1",
      "title": "Comorbidity-Informed Transfer Learning for Neuro-developmental Disorder Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Wen",
        "Shijie Guo",
        "Wenbo Ning",
        "Rui Cao",
        "Jie Xiang",
        "Xiaobo Liu",
        "Jintai Chen"
      ],
      "abstract": "Neuro-developmental disorders are manifested as dysfunctions in cognition,\ncommunication, behaviour and adaptability, and deep learning-based\ncomputer-aided diagnosis (CAD) can alleviate the increasingly strained\nhealthcare resources on neuroimaging. However, neuroimaging such as fMRI\ncontains complex spatio-temporal features, which makes the corresponding\nrepresentations susceptible to a variety of distractions, thus leading to less\neffective in CAD. For the first time, we present a Comorbidity-Informed\nTransfer Learning(CITL) framework for diagnosing neuro-developmental disorders\nusing fMRI. In CITL, a new reinforced representation generation network is\nproposed, which first combines transfer learning with pseudo-labelling to\nremove interfering patterns from the temporal domain of fMRI and generates new\nrepresentations using encoder-decoder architecture. The new representations are\nthen trained in an architecturally simple classification network to obtain CAD\nmodel. In particular, the framework fully considers the comorbidity mechanisms\nof neuro-developmental disorders and effectively integrates them with\nsemi-supervised learning and transfer learning, providing new perspectives on\ninterdisciplinary. Experimental results demonstrate that CITL achieves\ncompetitive accuracies of 76.32% and 73.15% for detecting autism spectrum\ndisorder and attention deficit hyperactivity disorder, respectively, which\noutperforms existing related transfer learning work for 7.2% and 0.5%\nrespectively.",
      "tldr_zh": "本研究提出了一种Comorbidity-Informed Transfer Learning (CITL)框架，用于利用fMRI诊断神经发育障碍，如自闭症谱系障碍和注意力缺陷多动障碍，通过考虑共病机制并整合转移学习和半监督学习来提升诊断准确性。该框架包括一个强化表示生成网络，先通过转移学习与伪标签去除fMRI时间域的干扰模式，并采用编码器-解码器架构生成新表示，随后在简单分类网络中进行训练。实验结果显示，CITL在检测自闭症谱系障碍和注意力缺陷多动障碍时的准确率分别为76.32%和73.15%，分别比现有转移学习方法提高了7.2%和0.5%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09463v1",
      "published_date": "2025-04-13 07:30:55 UTC",
      "updated_date": "2025-04-13 07:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:33:16.605982"
    },
    {
      "arxiv_id": "2504.10536v1",
      "title": "Federated Learning with Layer Skipping: Efficient Training of Large Language Models for Healthcare NLP",
      "title_zh": "翻译失败",
      "authors": [
        "Lihong Zhang",
        "Yue Li"
      ],
      "abstract": "Federated learning (FL) enables collaborative model training across\norganizations without sharing raw data, addressing crucial privacy concerns in\nhealthcare natural language processing (NLP). However, training large language\nmodels (LLMs) in federated settings faces significant challenges, including\ncommunication overhead and data heterogeneity. We propose Layer-Skipping\nFederated Learning, where only selected layers of a pre-trained LLM are\nfine-tuned across clients while others remain frozen. Applied to LLaMA 3.2-1B,\nour approach reduces communication costs by approximately 70% while maintaining\nperformance within 2% of centralized training. We evaluate our method on\nclinical NER and classification tasks using i2b2 and MIMIC-III datasets. Our\nexperiments demonstrate that Layer-Skipping FL outperforms competitive\nbaselines, handles non-IID clinical data distributions effectively, and shows\nrobustness when combined with differential privacy. This approach represents a\npractical solution for privacy-preserving collaborative learning in healthcare\nNLP.",
      "tldr_zh": "该研究提出了一种Layer-Skipping Federated Learning方法，用于在医疗NLP领域高效训练大型语言模型(LLMs)，以解决联邦学习(Federated Learning)中的通信开销和数据异质性问题。方法通过仅微调预训练LLMs（如LLaMA 3.2-1B）的选定层，而冻结其他层，实现了通信成本降低约70%，并保持性能与集中式训练相差不到2%。实验在i2b2和MIMIC-III数据集上的临床NER和分类任务中显示，该方法优于竞争基线，能够有效处理非IID数据分布，并与differential privacy结合增强鲁棒性，从而为隐私保护的医疗协作学习提供实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10536v1",
      "published_date": "2025-04-13 07:27:56 UTC",
      "updated_date": "2025-04-13 07:27:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:33:27.291411"
    },
    {
      "arxiv_id": "2504.09459v1",
      "title": "Measuring Leakage in Concept-Based Methods: An Information Theoretic Approach",
      "title_zh": "在基于概念方法中测量泄漏：一种信息理论方法",
      "authors": [
        "Mikael Makonnen",
        "Moritz Vandenhirtz",
        "Sonia Laguna",
        "Julia E Vogt"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) aim to enhance interpretability by\nstructuring predictions around human-understandable concepts. However,\nunintended information leakage, where predictive signals bypass the concept\nbottleneck, compromises their transparency. This paper introduces an\ninformation-theoretic measure to quantify leakage in CBMs, capturing the extent\nto which concept embeddings encode additional, unintended information beyond\nthe specified concepts. We validate the measure through controlled synthetic\nexperiments, demonstrating its effectiveness in detecting leakage trends across\nvarious configurations. Our findings highlight that feature and concept\ndimensionality significantly influence leakage, and that classifier choice\nimpacts measurement stability, with XGBoost emerging as the most reliable\nestimator. Additionally, preliminary investigations indicate that the measure\nexhibits the anticipated behavior when applied to soft joint CBMs, suggesting\nits reliability in leakage quantification beyond fully synthetic settings.\nWhile this study rigorously evaluates the measure in controlled synthetic\nexperiments, future work can extend its application to real-world datasets.",
      "tldr_zh": "本研究针对 Concept Bottleneck Models (CBMs) 中的 unintended information leakage 问题，提出了一种 information-theoretic measure 来量化概念嵌入中超出指定概念的额外信息，从而提升模型的透明度。该方法通过控制的合成实验验证了其有效性，展示了在不同配置下检测 leakage 趋势的能力。研究发现，feature 和 concept 的 dimensionality 显著影响 leakage，而 classifier 的选择会影响测量稳定性，其中 XGBoost 是最可靠的选项。此外，初步调查显示该 measure 在 soft joint CBMs 上表现出预期的行为，并建议未来工作扩展到真实数据集。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2025 Workshop on XAI4Science",
      "pdf_url": "http://arxiv.org/pdf/2504.09459v1",
      "published_date": "2025-04-13 07:09:55 UTC",
      "updated_date": "2025-04-13 07:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:33:39.500131"
    },
    {
      "arxiv_id": "2504.12330v1",
      "title": "HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Pei Liu",
        "Xin Liu",
        "Ruoyu Yao",
        "Junming Liu",
        "Siyuan Meng",
        "Ding Wang",
        "Jun Ma"
      ],
      "abstract": "While Retrieval-Augmented Generation (RAG) augments Large Language Models\n(LLMs) with external knowledge, conventional single-agent RAG remains\nfundamentally limited in resolving complex queries demanding coordinated\nreasoning across heterogeneous data ecosystems. We present HM-RAG, a novel\nHierarchical Multi-agent Multimodal RAG framework that pioneers collaborative\nintelligence for dynamic knowledge synthesis across structured, unstructured,\nand graph-based data. The framework is composed of three-tiered architecture\nwith specialized agents: a Decomposition Agent that dissects complex queries\ninto contextually coherent sub-tasks via semantic-aware query rewriting and\nschema-guided context augmentation; Multi-source Retrieval Agents that carry\nout parallel, modality-specific retrieval using plug-and-play modules designed\nfor vector, graph, and web-based databases; and a Decision Agent that uses\nconsistency voting to integrate multi-source answers and resolve discrepancies\nin retrieval results through Expert Model Refinement. This architecture attains\ncomprehensive query understanding by combining textual, graph-relational, and\nweb-derived evidence, resulting in a remarkable 12.95% improvement in answer\naccuracy and a 3.56% boost in question classification accuracy over baseline\nRAG systems on the ScienceQA and CrisisMMD benchmarks. Notably, HM-RAG\nestablishes state-of-the-art results in zero-shot settings on both datasets.\nIts modular architecture ensures seamless integration of new data modalities\nwhile maintaining strict data governance, marking a significant advancement in\naddressing the critical challenges of multimodal reasoning and knowledge\nsynthesis in RAG systems. Code is available at\nhttps://github.com/ocean-luna/HMRAG.",
      "tldr_zh": "该研究提出了HM-RAG，一种分层多代理多模态RAG框架，旨在解决传统单代理RAG在处理复杂查询时的局限性，通过协同推理整合结构化、非结构化和图-based数据。框架包括三层架构：Decomposition Agent负责将查询分解为子任务并进行语义-aware重写；Multi-source Retrieval Agents进行并行模态特定检索，支持向量、图和网络数据库；Decision Agent则通过一致性投票和Expert Model Refinement整合答案并解决不一致问题。实验结果显示，HM-RAG在ScienceQA和CrisisMMD基准上实现了12.95%的答案准确率提升和3.56%的问答分类准确率提升，并在零样本设置中达到最先进水平，其模块化设计便于新数据模态的集成并维护严格数据治理。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.12330v1",
      "published_date": "2025-04-13 06:55:33 UTC",
      "updated_date": "2025-04-13 06:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:33:52.727118"
    },
    {
      "arxiv_id": "2504.09456v1",
      "title": "Don't Deceive Me: Mitigating Gaslighting through Attention Reallocation in LMMs",
      "title_zh": "翻译失败",
      "authors": [
        "Pengkun Jiao",
        "Bin Zhu",
        "Jingjing Chen",
        "Chong-Wah Ngo",
        "Yu-Gang Jiang"
      ],
      "abstract": "Large Multimodal Models (LMMs) have demonstrated remarkable capabilities\nacross a wide range of tasks. However, their vulnerability to user\ngaslighting-the deliberate use of misleading or contradictory inputs-raises\ncritical concerns about their reliability in real-world applications. In this\npaper, we address the novel and challenging issue of mitigating the negative\nimpact of negation-based gaslighting on LMMs, where deceptive user statements\nlead to significant drops in model accuracy. Specifically, we introduce\nGasEraser, a training-free approach that reallocates attention weights from\nmisleading textual tokens to semantically salient visual regions. By\nsuppressing the influence of \"attention sink\" tokens and enhancing focus on\nvisually grounded cues, GasEraser significantly improves LMM robustness without\nrequiring retraining or additional supervision. Extensive experimental results\ndemonstrate that GasEraser is effective across several leading open-source LMMs\non the GaslightingBench. Notably, for LLaVA-v1.5-7B, GasEraser reduces the\nmisguidance rate by 48.2%, demonstrating its potential for more trustworthy\nLMMs.",
      "tldr_zh": "这篇论文探讨了大型多模态模型（LMMs）对用户gaslighting攻击的脆弱性，特别是基于否定的误导输入导致准确率下降的问题。作者提出GasEraser，这是一种无需训练的创新方法，通过重新分配注意力权重，将焦点从误导性文本标记（attention sink tokens）转移到语义上重要的视觉区域，从而增强模型的鲁棒性。实验结果显示，GasEraser在多个开源LMMs上表现出色，例如在LLaVA-v1.5-7B上将误导率降低了48.2%，为更可靠的LMMs应用提供了重要基础。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09456v1",
      "published_date": "2025-04-13 06:47:32 UTC",
      "updated_date": "2025-04-13 06:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:34:03.506824"
    },
    {
      "arxiv_id": "2504.09440v2",
      "title": "Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "MingShan Liu",
        "Shi Bo",
        "Jialing Fang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong mathematical reasoning\ncapabilities but remain susceptible to hallucinations producing plausible yet\nincorrect statements especially in theorem proving, symbolic manipulation, and\nnumerical computation. While self-consistency (SC) has been explored as a means\nto improve factuality in LLMs, existing approaches primarily apply SC to\nfinal-answer selection, neglecting the logical consistency of intermediate\nreasoning steps. In this work, we introduce a structured self-consistency\nframework designed to enhance the reliability of mathematical reasoning. Our\nmethod enforces self-consistency across intermediate steps and final outputs,\nreducing logical inconsistencies and hallucinations. We evaluate our approach\nacross three core mathematical tasks: theorem proving, symbolic transformation,\nand numerical computation. Experimental results demonstrate that SC\nsignificantly improves proof validity, symbolic reasoning accuracy, and\nnumerical stability while maintaining computational efficiency. Further\nanalysis reveals that structured self-consistency not only enhances\nproblem-solving accuracy but also reduces the variance of model-generated\noutputs. These findings highlight self-consistency as a robust mechanism for\nimproving mathematical reasoning in LLMs, paving the way for more reliable and\ninterpretable AI-driven mathematics.",
      "tldr_zh": "大型语言模型 (LLMs) 在数学推理中常出现幻觉 (hallucinations)，如在定理证明、符号操作和数值计算中产生不准确的输出，本文提出一种结构化的自一致性 (self-consistency) 框架，通过在中间推理步骤和最终输出上强制一致性来减少逻辑不一致。实验评估显示，该方法显著提高了定理证明的有效性、符号推理的准确性和数值稳定性，同时保持计算效率，并降低了模型输出变异性。这些发现证明了自一致性作为一种稳健机制，能够提升 LLMs 的数学推理可靠性和可解释性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09440v2",
      "published_date": "2025-04-13 05:47:52 UTC",
      "updated_date": "2025-05-20 20:36:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:34:16.378023"
    },
    {
      "arxiv_id": "2504.13192v2",
      "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Liang-bo Ning",
        "Shijie Wang",
        "Wenqi Fan",
        "Qing Li",
        "Xin Xu",
        "Hao Chen",
        "Feiran Huang"
      ],
      "abstract": "Recently, Large Language Model (LLM)-empowered recommender systems (RecSys)\nhave brought significant advances in personalized user experience and have\nattracted considerable attention. Despite the impressive progress, the research\nquestion regarding the safety vulnerability of LLM-empowered RecSys still\nremains largely under-investigated. Given the security and privacy concerns, it\nis more practical to focus on attacking the black-box RecSys, where attackers\ncan only observe the system's inputs and outputs. However, traditional attack\napproaches employing reinforcement learning (RL) agents are not effective for\nattacking LLM-empowered RecSys due to the limited capabilities in processing\ncomplex textual inputs, planning, and reasoning. On the other hand, LLMs\nprovide unprecedented opportunities to serve as attack agents to attack RecSys\nbecause of their impressive capability in simulating human-like decision-making\nprocesses. Therefore, in this paper, we propose a novel attack framework called\nCheatAgent by harnessing the human-like capabilities of LLMs, where an\nLLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our\nmethod first identifies the insertion position for maximum impact with minimal\ninput modification. After that, the LLM agent is designed to generate\nadversarial perturbations to insert at target positions. To further improve the\nquality of generated perturbations, we utilize the prompt tuning technique to\nimprove attacking strategies via feedback from the victim RecSys iteratively.\nExtensive experiments across three real-world datasets demonstrate the\neffectiveness of our proposed attacking method.",
      "tldr_zh": "该研究探讨了LLM（Large Language Model）增强的推荐系统（RecSys）的安全漏洞，指出传统基于强化学习（RL）的攻击方法难以处理复杂文本和推理问题。作者提出了一种新型攻击框架CheatAgent，利用LLM代理进行黑盒攻击，该框架首先识别插入位置以最大化影响，然后生成对抗性扰动（adversarial perturbations）并通过提示调整（prompt tuning）技术迭代优化攻击策略。在三个真实数据集上的广泛实验中，CheatAgent证明了其有效性，为评估LLM-Empowered RecSys的安全性提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by KDD 2024;",
      "pdf_url": "http://arxiv.org/pdf/2504.13192v2",
      "published_date": "2025-04-13 05:31:37 UTC",
      "updated_date": "2025-04-24 02:16:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:34:27.300605"
    },
    {
      "arxiv_id": "2504.09428v3",
      "title": "FROG: Effective Friend Recommendation in Online Games via Modality-aware User Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Qiwei Wang",
        "Dandan Lin",
        "Wenqing Lin",
        "Ziming Wu"
      ],
      "abstract": "Due to the convenience of mobile devices, the online games have become an\nimportant part for user entertainments in reality, creating a demand for friend\nrecommendation in online games. However, none of existing approaches can\neffectively incorporate the multi-modal user features (e.g., images and texts)\nwith the structural information in the friendship graph, due to the following\nlimitations: (1) some of them ignore the high-order structural proximity\nbetween users, (2) some fail to learn the pairwise relevance between users at\nmodality-specific level, and (3) some cannot capture both the local and global\nuser preferences on different modalities. By addressing these issues, in this\npaper, we propose an end-to-end model FROG that better models the user\npreferences on potential friends. Comprehensive experiments on both offline\nevaluation and online deployment at Tencent have demonstrated the superiority\nof FROG over existing approaches.",
      "tldr_zh": "本文研究了在线游戏中好友推荐的问题，强调了整合多模态用户特征（如图像和文本）与友谊图结构信息的重要性，但现有方法忽略了高阶结构接近性、模态特定用户相关性以及局部与全局偏好。作者提出了一种端到端模型FROG，通过modality-aware用户偏好机制来更好地建模用户对潜在好友的偏好，从而解决这些局限。实验在离线评估和Tencent在线部署中证明，FROG比现有方法表现出色，显著提升了推荐效果。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted in SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.09428v3",
      "published_date": "2025-04-13 04:27:10 UTC",
      "updated_date": "2025-04-26 14:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:34:39.532113"
    },
    {
      "arxiv_id": "2504.09426v1",
      "title": "BabyVLM: Data-Efficient Pretraining of VLMs Inspired by Infant Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shengao Wang",
        "Arjun Chandra",
        "Aoming Liu",
        "Venkatesh Saligrama",
        "Boqing Gong"
      ],
      "abstract": "Human infants rapidly develop visual reasoning skills from minimal input,\nsuggesting that developmentally inspired pretraining could significantly\nenhance the efficiency of vision-language models (VLMs). Although recent\nefforts have leveraged infant-inspired datasets like SAYCam, existing\nevaluation benchmarks remain misaligned--they are either too simplistic,\nnarrowly scoped, or tailored for large-scale pretrained models. Additionally,\ntraining exclusively on infant data overlooks the broader, diverse input from\nwhich infants naturally learn. To address these limitations, we propose\nBabyVLM, a novel framework comprising comprehensive in-domain evaluation\nbenchmarks and a synthetic training dataset created via child-directed\ntransformations of existing datasets. We demonstrate that VLMs trained with our\nsynthetic dataset achieve superior performance on BabyVLM tasks compared to\nmodels trained solely on SAYCam or general-purpose data of the SAYCam size.\nBabyVLM thus provides a robust, developmentally aligned evaluation tool and\nillustrates how compact models trained on carefully curated data can generalize\neffectively, opening pathways toward data-efficient vision-language learning\nparadigms.",
      "tldr_zh": "这篇论文受人类婴儿快速学习启发，提出 BabyVLM 框架，以提升视觉语言模型 (VLMs) 的数据效率。BabyVLM 包括一个全面的领域内评估基准和通过儿童导向转换现有数据集创建的合成训练数据集，解决了现有基准的局限性，如过于简单或忽略婴儿学习的多样输入。实验结果显示，使用合成数据集训练的 VLMs 在 BabyVLM 任务上表现优于仅使用 SAYCam 或同规模通用数据的模型。该框架证明了紧凑模型在精心策划数据上的训练能实现有效泛化，推动数据高效的视觉语言学习范式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09426v1",
      "published_date": "2025-04-13 04:17:12 UTC",
      "updated_date": "2025-04-13 04:17:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:34:51.720477"
    },
    {
      "arxiv_id": "2504.09421v2",
      "title": "ClinicalGPT-R1: Pushing reasoning capability of generalist disease diagnosis with large language model",
      "title_zh": "ClinicalGPT",
      "authors": [
        "Wuyang Lan",
        "Wenzheng Wang",
        "Changwei Ji",
        "Guoxing Yang",
        "Yongbo Zhang",
        "Xiaohong Liu",
        "Song Wu",
        "Guangyu Wang"
      ],
      "abstract": "Recent advances in reasoning with large language models (LLMs)has shown\nremarkable reasoning capabilities in domains such as mathematics and coding,\nyet their application to clinical diagnosis remains underexplored. Here, we\nintroduce ClinicalGPT-R1, a reasoning enhanced generalist large language model\nfor disease diagnosis. Trained on a dataset of 20,000 real-world clinical\nrecords, ClinicalGPT-R1 leverages diverse training strategies to enhance\ndiagnostic reasoning. To benchmark performance, we curated MedBench-Hard, a\nchallenging dataset spanning seven major medical specialties and representative\ndiseases. Experimental results demonstrate that ClinicalGPT-R1 outperforms\nGPT-4o in Chinese diagnostic tasks and achieves comparable performance to GPT-4\nin English settings. This comparative study effectively validates the superior\nperformance of ClinicalGPT-R1 in disease diagnosis tasks. Resources are\navailable at https://github.com/medfound/medfound.",
      "tldr_zh": "本研究推出了 ClinicalGPT-R1，一种针对疾病诊断的增强推理能力的通用大型语言模型（LLM），旨在提升临床诊断性能。该模型通过训练于20,000条真实临床记录并采用多样训练策略，显著提高了诊断推理能力。研究者创建了MedBench-Hard数据集作为基准，涵盖七个主要医学专业，结果显示ClinicalGPT-R1在中文任务中优于GPT-4o，在英语环境中与GPT-4相当。资源可通过GitHub获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09421v2",
      "published_date": "2025-04-13 04:00:40 UTC",
      "updated_date": "2025-04-15 07:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:35:03.802157"
    },
    {
      "arxiv_id": "2504.09402v1",
      "title": "Question Tokens Deserve More Attention: Enhancing Large Language Models without Training through Step-by-Step Reading and Question Attention Recalibration",
      "title_zh": "问题标记值得更多关注：通过逐步阅读和",
      "authors": [
        "Feijiang Han",
        "Licheng Guo",
        "Hengtao Cui",
        "Zhiyuan Lyu"
      ],
      "abstract": "Large Language Models (LLMs) often struggle with tasks that require a deep\nunderstanding of complex questions, especially when faced with long-range\ndependencies or multi-step reasoning. This work investigates the limitations of\ncurrent LLMs in question comprehension and identifies three insights: (1)\nrepeating question tokens improves comprehension by increasing attention to\nquestion regions, (2) increased backward dependencies negatively affect\nperformance due to unidirectional attentional constraints, and (3)\nrecalibrating attentional mechanisms to prioritize question-relevant regions\nimproves performance.\n  Based on these findings, we first propose a family of prompt-based strategies\n- Step-by-Step Reading (SSR), SSR+, and SSR++ - that guide LLMs to\nincrementally process question tokens and align their reasoning with the input\nstructure. These methods significantly improve performance, with SSR++\nachieving state-of-the-art results on several benchmarks: 96.66% on GSM8K,\n94.61% on ASDiv, and 76.28% on AQuA. Second, we introduce a training-free\nattention recalibration mechanism that dynamically adjusts attention\ndistributions during inference to emphasize question-relevant regions. This\nmethod improves the accuracy of LLaMA 3.1-8B on AQuA by 5.17% without changing\nmodel parameters or input prompts.\n  Taken together, our results highlight the importance of structured prompt\ndesign and attention optimization in improving LLM comprehension, providing\nlightweight yet effective tools for improving performance in various NLP tasks.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在处理复杂问题时的局限性，包括长距离依赖和多步推理挑战，并通过实验识别出三个关键洞见：重复问题标记可增强注意力、向后依赖会降低性能，以及重新校准注意力机制能改善理解。作者提出了一系列基于提示的策略，如 Step-by-Step Reading (SSR)、SSR+ 和 SSR++，这些方法指导 LLMs 逐步处理问题并与输入结构对齐，在 GSM8K、ASDiv 和 AQuA 等基准上分别实现了 96.66%、94.61% 和 76.28% 的最先进性能。此外，他们引入了一个无需训练的注意力重新校准机制，在推理过程中动态强调问题相关区域，使 LLaMA 3.1-8B 在 AQuA 上准确率提升 5.17%。这些创新突出了结构化提示设计和注意力优化的重要性，为提升 NLP 任务的轻量级工具提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "CIS 5300",
      "pdf_url": "http://arxiv.org/pdf/2504.09402v1",
      "published_date": "2025-04-13 02:10:18 UTC",
      "updated_date": "2025-04-13 02:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:35:17.991315"
    },
    {
      "arxiv_id": "2504.09398v1",
      "title": "Composable NLP Workflows for BERT-based Ranking and QA System",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurav Kumar",
        "Murali Mohana Krishna Dandu"
      ],
      "abstract": "There has been a lot of progress towards building NLP models that scale to\nmultiple tasks. However, real-world systems contain multiple components and it\nis tedious to handle cross-task interaction with varying levels of text\ngranularity. In this work, we built an end-to-end Ranking and\nQuestion-Answering (QA) system using Forte, a toolkit that makes composable NLP\npipelines. We utilized state-of-the-art deep learning models such as BERT,\nRoBERTa in our pipeline, evaluated the performance on MS-MARCO and Covid-19\ndatasets using metrics such as BLUE, MRR, F1 and compared the results of\nranking and QA systems with their corresponding benchmark results. The modular\nnature of our pipeline and low latency of reranker makes it easy to build\ncomplex NLP applications easily.",
      "tldr_zh": "本研究构建了一个基于 BERT 和 RoBERTa 的端到端 Ranking 和 Question-Answering (QA) 系统，使用 Forte 工具包实现可组合的 NLP 工作流，以处理不同粒度文本的跨任务交互。系统整合了先进深度学习模型，并在 MS-MARCO 和 Covid-19 数据集上进行评估，使用 BLUE、MRR 和 F1 等指标，与基准结果比较，展示了优异的性能。得益于管道的模块化和重新排序器的低延迟，该框架简化了复杂 NLP 应用的开发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 3 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.09398v1",
      "published_date": "2025-04-13 01:48:13 UTC",
      "updated_date": "2025-04-13 01:48:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:35:26.324090"
    },
    {
      "arxiv_id": "2504.09396v1",
      "title": "Adaptive Insurance Reserving with CVaR-Constrained Reinforcement Learning under Macroeconomic Regimes",
      "title_zh": "翻译失败",
      "authors": [
        "Stella C. Dong",
        "James R. Finlay"
      ],
      "abstract": "This paper proposes a reinforcement learning (RL) framework for insurance\nreserving that integrates tail-risk sensitivity, macroeconomic regime modeling,\nand regulatory compliance. The reserving problem is formulated as a\nfinite-horizon Markov Decision Process (MDP), in which reserve adjustments are\noptimized using Proximal Policy Optimization (PPO) subject to Conditional\nValue-at-Risk (CVaR) constraints. To enhance policy robustness across varying\neconomic conditions, the agent is trained using a regime-aware curriculum that\nprogressively increases volatility exposure.\n  The reward structure penalizes reserve shortfall, capital inefficiency, and\nsolvency floor violations, with design elements informed by Solvency II and Own\nRisk and Solvency Assessment (ORSA) frameworks. Empirical evaluations on two\nindustry datasets--Workers' Compensation, and Other Liability--demonstrate that\nthe RL-CVaR agent achieves superior performance relative to classical reserving\nmethods across multiple criteria, including tail-risk control (CVaR$_{0.95}$),\ncapital efficiency, and regulatory violation rate. The framework also\naccommodates fixed-shock stress testing and regime-stratified analysis,\nproviding a principled and extensible approach to reserving under uncertainty.",
      "tldr_zh": "这篇论文提出了一种基于强化学习 (RL) 的自适应保险储备框架，整合尾部风险敏感性、宏观经济制度建模以及监管合规要求。框架将储备问题表述为有限地平线 Markov Decision Process (MDP)，使用 Proximal Policy Optimization (PPO) 算法优化储备调整，同时受 Conditional Value-at-Risk (CVaR) 约束，以确保风险控制。代理通过制度感知课程训练逐步增加波动性暴露，提升政策在不同经济条件下的鲁棒性，并参考 Solvency II 和 Own Risk and Solvency Assessment (ORSA) 框架设计奖励结构以惩罚储备短缺、资本低效和偿付能力违规。在 Workers' Compensation 和 Other Liability 数据集上的实证评估显示，RL-CVaR 代理在尾部风险控制 (CVaR_{0.95})、资本效率和监管违规率等方面显著优于传统方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09396v1",
      "published_date": "2025-04-13 01:43:25 UTC",
      "updated_date": "2025-04-13 01:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:35:42.210121"
    },
    {
      "arxiv_id": "2504.16097v1",
      "title": "A CNN-based Local-Global Self-Attention via Averaged Window Embeddings for Hierarchical ECG Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Arthur Buzelin",
        "Pedro Robles Dutenhefner",
        "Turi Rezende",
        "Luisa G. Porfirio",
        "Pedro Bento",
        "Yan Aquino",
        "Jose Fernandes",
        "Caio Santana",
        "Gabriela Miana",
        "Gisele L. Pappa",
        "Antonio Ribeiro",
        "Wagner Meira Jr"
      ],
      "abstract": "Cardiovascular diseases remain the leading cause of global mortality,\nemphasizing the critical need for efficient diagnostic tools such as\nelectrocardiograms (ECGs). Recent advancements in deep learning, particularly\ntransformers, have revolutionized ECG analysis by capturing detailed waveform\nfeatures as well as global rhythm patterns. However, traditional transformers\nstruggle to effectively capture local morphological features that are critical\nfor accurate ECG interpretation. We propose a novel Local-Global Attention ECG\nmodel (LGA-ECG) to address this limitation, integrating convolutional inductive\nbiases with global self-attention mechanisms. Our approach extracts queries by\naveraging embeddings obtained from overlapping convolutional windows, enabling\nfine-grained morphological analysis, while simultaneously modeling global\ncontext through attention to keys and values derived from the entire sequence.\nExperiments conducted on the CODE-15 dataset demonstrate that LGA-ECG\noutperforms state-of-the-art models and ablation studies validate the\neffectiveness of the local-global attention strategy. By capturing the\nhierarchical temporal dependencies and morphological patterns in ECG signals,\nthis new design showcases its potential for clinical deployment with robust\nautomated ECG classification.",
      "tldr_zh": "论文提出了一种名为 LGA-ECG 的模型，旨在解决传统 Transformer 在心电图 (ECG) 分析中捕捉局部形态特征的不足，通过整合卷积神经网络 (CNN) 的局部偏差和全局自注意力机制来提升分析性能。模型的核心创新是使用平均重叠卷积窗口嵌入提取查询 (queries)，实现细粒度的形态分析，同时通过对整个序列的键 (keys) 和值 (values) 进行注意力建模来捕捉全局上下文。在 CODE-15 数据集上的实验显示，LGA-ECG 超过了现有最先进模型，消融研究验证了局部-全局注意力策略的有效性，并展示了其在自动化 ECG 分类和临床部署的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16097v1",
      "published_date": "2025-04-13 01:21:18 UTC",
      "updated_date": "2025-04-13 01:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:35:52.760447"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 66,
  "processed_papers_count": 66,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T12:36:12.988252"
}