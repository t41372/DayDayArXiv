[
  {
    "arxiv_id": "2504.09753v2",
    "title": "Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance",
    "authors": [
      "Ram Mohan Rao Kadiyala",
      "Siddartha Pullakhandam",
      "Siddhant Gupta",
      "Drishti Sharma",
      "Jebish Purbey",
      "Kanwal Mehreen",
      "Muhammad Arham",
      "Hamza Farooq"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, but their\ndevelopment has primarily focused on English and other high-resource languages,\nleaving many languages underserved. We present our latest Hindi-English\nbi-lingual LLM \\textbf{Mantra-14B} with ~3\\% average improvement in benchmark\nscores over both languages, outperforming models twice its size. Using a\ncurated dataset composed of English and Hindi instruction data of 485K samples,\nwe instruction tuned models such as Qwen-2.5-14B-Instruct and Phi-4 to improve\nperformance over both English and Hindi. Our experiments encompassing seven\ndifferent LLMs of varying parameter sizes and over 140 training attempts with\nvarying English-Hindi training data ratios demonstrated that it is possible to\nsignificantly improve multilingual performance without compromising native\nperformance. Further, our approach avoids resource-intensive techniques like\nvocabulary expansion or architectural modifications, thus keeping the model\nsize small. Our results indicate that modest fine-tuning with culturally and\nlocally informed data can bridge performance gaps without incurring significant\ncomputational overhead. We release our training code, datasets, and models\nunder mit and apache licenses to aid further research towards under-represented\nand low-resource languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.09753v2",
    "published_date": "2025-04-13 23:10:13 UTC",
    "updated_date": "2025-05-22 10:29:25 UTC"
  },
  {
    "arxiv_id": "2504.09738v1",
    "title": "Automatic Detection of Intro and Credits in Video using CLIP and Multihead Attention",
    "authors": [
      "Vasilii Korolkov",
      "Andrey Yanchenko"
    ],
    "abstract": "Detecting transitions between intro/credits and main content in videos is a\ncrucial task for content segmentation, indexing, and recommendation systems.\nManual annotation of such transitions is labor-intensive and error-prone, while\nheuristic-based methods often fail to generalize across diverse video styles.\nIn this work, we introduce a deep learning-based approach that formulates the\nproblem as a sequence-to-sequence classification task, where each second of a\nvideo is labeled as either \"intro\" or \"film.\" Our method extracts frames at a\nfixed rate of 1 FPS, encodes them using CLIP (Contrastive Language-Image\nPretraining), and processes the resulting feature representations with a\nmultihead attention model incorporating learned positional encoding. The system\nachieves an F1-score of 91.0%, Precision of 89.0%, and Recall of 97.0% on the\ntest set, and is optimized for real-time inference, achieving 11.5 FPS on CPU\nand 107 FPS on high-end GPUs. This approach has practical applications in\nautomated content indexing, highlight detection, and video summarization.\nFuture work will explore multimodal learning, incorporating audio features and\nsubtitles to further enhance detection accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "68T07",
      "I.2.10; I.4.8; I.5.1"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 11 figures, submitted as a preprint. ArXiv preprint only,\n  not submitted to a journal yet",
    "pdf_url": "http://arxiv.org/pdf/2504.09738v1",
    "published_date": "2025-04-13 22:08:18 UTC",
    "updated_date": "2025-04-13 22:08:18 UTC"
  },
  {
    "arxiv_id": "2504.09737v1",
    "title": "Can LLM feedback enhance review quality? A randomized study of 20K reviews at ICLR 2025",
    "authors": [
      "Nitya Thakkar",
      "Mert Yuksekgonul",
      "Jake Silberg",
      "Animesh Garg",
      "Nanyun Peng",
      "Fei Sha",
      "Rose Yu",
      "Carl Vondrick",
      "James Zou"
    ],
    "abstract": "Peer review at AI conferences is stressed by rapidly rising submission\nvolumes, leading to deteriorating review quality and increased author\ndissatisfaction. To address these issues, we developed Review Feedback Agent, a\nsystem leveraging multiple large language models (LLMs) to improve review\nclarity and actionability by providing automated feedback on vague comments,\ncontent misunderstandings, and unprofessional remarks to reviewers. Implemented\nat ICLR 2025 as a large randomized control study, our system provided optional\nfeedback to more than 20,000 randomly selected reviews. To ensure high-quality\nfeedback for reviewers at this scale, we also developed a suite of automated\nreliability tests powered by LLMs that acted as guardrails to ensure feedback\nquality, with feedback only being sent to reviewers if it passed all the tests.\nThe results show that 27% of reviewers who received feedback updated their\nreviews, and over 12,000 feedback suggestions from the agent were incorporated\nby those reviewers. This suggests that many reviewers found the AI-generated\nfeedback sufficiently helpful to merit updating their reviews. Incorporating AI\nfeedback led to significantly longer reviews (an average increase of 80 words\namong those who updated after receiving feedback) and more informative reviews,\nas evaluated by blinded researchers. Moreover, reviewers who were selected to\nreceive AI feedback were also more engaged during paper rebuttals, as seen in\nlonger author-reviewer discussions. This work demonstrates that carefully\ndesigned LLM-generated review feedback can enhance peer review quality by\nmaking reviews more specific and actionable while increasing engagement between\nreviewers and authors. The Review Feedback Agent is publicly available at\nhttps://github.com/zou-group/review_feedback_agent.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.09737v1",
    "published_date": "2025-04-13 22:01:25 UTC",
    "updated_date": "2025-04-13 22:01:25 UTC"
  },
  {
    "arxiv_id": "2504.09734v1",
    "title": "Dynamik: Syntactically-Driven Dynamic Font Sizing for Emphasis of Key Information",
    "authors": [
      "Naoto Nishida",
      "Yoshio Ishiguro",
      "Jun Rekiomto",
      "Naomi Yamashita"
    ],
    "abstract": "In today's globalized world, there are increasing opportunities for\nindividuals to communicate using a common non-native language (lingua franca).\nNon-native speakers often have opportunities to listen to foreign languages,\nbut may not comprehend them as fully as native speakers do. To aid real-time\ncomprehension, live transcription of subtitles is frequently used in everyday\nlife (e.g., during Zoom conversations, watching YouTube videos, or on social\nnetworking sites). However, simultaneously reading subtitles while listening\ncan increase cognitive load. In this study, we propose Dynamik, a system that\nreduces cognitive load during reading by decreasing the size of less important\nwords and enlarging important ones, thereby enhancing sentence contrast. Our\nresults indicate that Dynamik can reduce certain aspects of cognitive load,\nspecifically, participants' perceived performance and effort among individuals\nwith low proficiency in English, as well as enhance the users' sense of\ncomprehension, especially among people with low English ability. We further\ndiscuss our methods' applicability to other languages and potential\nimprovements and further research directions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "30 pages, 11 figures, presented at The ACM Conference on Intelligent\n  User Interfaces (ACM IUI) 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.09734v1",
    "published_date": "2025-04-13 21:46:11 UTC",
    "updated_date": "2025-04-13 21:46:11 UTC"
  },
  {
    "arxiv_id": "2504.09717v1",
    "title": "Adapting Robot's Explanation for Failures Based on Observed Human Behavior in Human-Robot Collaboration",
    "authors": [
      "Andreas Naoum",
      "Parag Khanna",
      "Elmira Yadollahi",
      "Mårten Björkman",
      "Christian Smith"
    ],
    "abstract": "This work aims to interpret human behavior to anticipate potential user\nconfusion when a robot provides explanations for failure, allowing the robot to\nadapt its explanations for more natural and efficient collaboration. Using a\ndataset that included facial emotion detection, eye gaze estimation, and\ngestures from 55 participants in a user study, we analyzed how human behavior\nchanged in response to different types of failures and varying explanation\nlevels. Our goal is to assess whether human collaborators are ready to accept\nless detailed explanations without inducing confusion. We formulate a\ndata-driven predictor to predict human confusion during robot failure\nexplanations. We also propose and evaluate a mechanism, based on the predictor,\nto adapt the explanation level according to observed human behavior. The\npromising results from this evaluation indicate the potential of this research\nin adapting a robot's explanations for failures to enhance the collaborative\nexperience.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Under review, Manuscript in submission for IROS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.09717v1",
    "published_date": "2025-04-13 20:49:43 UTC",
    "updated_date": "2025-04-13 20:49:43 UTC"
  },
  {
    "arxiv_id": "2504.09716v1",
    "title": "Dominated Actions in Imperfect-Information Games",
    "authors": [
      "Sam Ganzfried"
    ],
    "abstract": "Dominance is a fundamental concept in game theory. In strategic-form games\ndominated strategies can be identified in polynomial time. As a consequence,\niterative removal of dominated strategies can be performed efficiently as a\npreprocessing step for reducing the size of a game before computing a Nash\nequilibrium. For imperfect-information games in extensive form, we could\nconvert the game to strategic form and then iteratively remove dominated\nstrategies in the same way; however, this conversion may cause an exponential\nblowup in game size. In this paper we define and study the concept of dominated\nactions in imperfect-information games. Our main result is a polynomial-time\nalgorithm for determining whether an action is dominated (strictly or weakly)\nby any mixed strategy in n-player games, which can be extended to an algorithm\nfor iteratively removing dominated actions. This allows us to efficiently\nreduce the size of the game tree as a preprocessing step for Nash equilibrium\ncomputation. We explore the role of dominated actions empirically in the \"All\nIn or Fold\" No-Limit Texas Hold'em poker variant.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09716v1",
    "published_date": "2025-04-13 20:48:44 UTC",
    "updated_date": "2025-04-13 20:48:44 UTC"
  },
  {
    "arxiv_id": "2504.09714v2",
    "title": "Evaluating the Quality of Benchmark Datasets for Low-Resource Languages: A Case Study on Turkish",
    "authors": [
      "Ayşe Aysu Cengiz",
      "Ahmet Kaan Sever",
      "Elif Ecem Ümütlü",
      "Naime Şeyma Erdem",
      "Burak Aytan",
      "Büşra Tufan",
      "Abdullah Topraksoy",
      "Esra Darıcı",
      "Cagri Toraman"
    ],
    "abstract": "The reliance on translated or adapted datasets from English or multilingual\nresources introduces challenges regarding linguistic and cultural suitability.\nThis study addresses the need for robust and culturally appropriate benchmarks\nby evaluating the quality of 17 commonly used Turkish benchmark datasets. Using\na comprehensive framework that assesses six criteria, both human and LLM-judge\nannotators provide detailed evaluations to identify dataset strengths and\nshortcomings.\n  Our results reveal that 70% of the benchmark datasets fail to meet our\nheuristic quality standards. The correctness of the usage of technical terms is\nthe strongest criterion, but 85% of the criteria are not satisfied in the\nexamined datasets. Although LLM judges demonstrate potential, they are less\neffective than human annotators, particularly in understanding cultural common\nsense knowledge and interpreting fluent, unambiguous text. GPT-4o has stronger\nlabeling capabilities for grammatical and technical tasks, while Llama3.3-70B\nexcels at correctness and cultural knowledge evaluation. Our findings emphasize\nthe urgent need for more rigorous quality control in creating and adapting\ndatasets for low-resource languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09714v2",
    "published_date": "2025-04-13 20:45:49 UTC",
    "updated_date": "2025-04-26 11:28:53 UTC"
  },
  {
    "arxiv_id": "2504.09712v1",
    "title": "The Structural Safety Generalization Problem",
    "authors": [
      "Julius Broomfield",
      "Tom Gibbs",
      "Ethan Kosak-Hine",
      "George Ingebretsen",
      "Tia Nasir",
      "Jason Zhang",
      "Reihaneh Iranmanesh",
      "Sara Pieri",
      "Reihaneh Rabbany",
      "Kellin Pelrine"
    ],
    "abstract": "LLM jailbreaks are a widespread safety challenge. Given this problem has not\nyet been tractable, we suggest targeting a key failure mechanism: the failure\nof safety to generalize across semantically equivalent inputs. We further focus\nthe target by requiring desirable tractability properties of attacks to study:\nexplainability, transferability between models, and transferability between\ngoals. We perform red-teaming within this framework by uncovering new\nvulnerabilities to multi-turn, multi-image, and translation-based attacks.\nThese attacks are semantically equivalent by our design to their single-turn,\nsingle-image, or untranslated counterparts, enabling systematic comparisons; we\nshow that the different structures yield different safety outcomes. We then\ndemonstrate the potential for this framework to enable new defenses by\nproposing a Structure Rewriting Guardrail, which converts an input to a\nstructure more conducive to safety assessment. This guardrail significantly\nimproves refusal of harmful inputs, without over-refusing benign ones. Thus, by\nframing this intermediate challenge - more tractable than universal defenses\nbut essential for long-term safety - we highlight a critical milestone for AI\nsafety research.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09712v1",
    "published_date": "2025-04-13 20:21:08 UTC",
    "updated_date": "2025-04-13 20:21:08 UTC"
  },
  {
    "arxiv_id": "2504.09707v1",
    "title": "InfoMAE: Pair-Efficient Cross-Modal Alignment for Multimodal Time-Series Sensing Signals",
    "authors": [
      "Tomoyoshi Kimura",
      "Xinlin Li",
      "Osama Hanna",
      "Yatong Chen",
      "Yizhuo Chen",
      "Denizhan Kara",
      "Tianshi Wang",
      "Jinyang Li",
      "Xiaomin Ouyang",
      "Shengzhong Liu",
      "Mani Srivastava",
      "Suhas Diggavi",
      "Tarek Abdelzaher"
    ],
    "abstract": "Standard multimodal self-supervised learning (SSL) algorithms regard\ncross-modal synchronization as implicit supervisory labels during pretraining,\nthus posing high requirements on the scale and quality of multimodal samples.\nThese constraints significantly limit the performance of sensing intelligence\nin IoT applications, as the heterogeneity and the non-interpretability of\ntime-series signals result in abundant unimodal data but scarce high-quality\nmultimodal pairs. This paper proposes InfoMAE, a cross-modal alignment\nframework that tackles the challenge of multimodal pair efficiency under the\nSSL setting by facilitating efficient cross-modal alignment of pretrained\nunimodal representations. InfoMAE achieves \\textit{efficient cross-modal\nalignment} with \\textit{limited data pairs} through a novel information\ntheory-inspired formulation that simultaneously addresses distribution-level\nand instance-level alignment. Extensive experiments on two real-world IoT\napplications are performed to evaluate InfoMAE's pairing efficiency to bridge\npretrained unimodal models into a cohesive joint multimodal model. InfoMAE\nenhances downstream multimodal tasks by over 60% with significantly improved\nmultimodal pairing efficiency. It also improves unimodal task accuracy by an\naverage of 22%.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.MM",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09707v1",
    "published_date": "2025-04-13 20:03:29 UTC",
    "updated_date": "2025-04-13 20:03:29 UTC"
  },
  {
    "arxiv_id": "2504.09704v1",
    "title": "Transformer-Based Representation Learning for Robust Gene Expression Modeling and Cancer Prognosis",
    "authors": [
      "Shuai Jiang",
      "Saeed Hassanpour"
    ],
    "abstract": "Transformer-based models have achieved remarkable success in natural language\nand vision tasks, but their application to gene expression analysis remains\nlimited due to data sparsity, high dimensionality, and missing values. We\npresent GexBERT, a transformer-based autoencoder framework for robust\nrepresentation learning of gene expression data. GexBERT learns context-aware\ngene embeddings by pretraining on large-scale transcriptomic profiles with a\nmasking and restoration objective that captures co-expression relationships\namong thousands of genes. We evaluate GexBERT across three critical tasks in\ncancer research: pan-cancer classification, cancer-specific survival\nprediction, and missing value imputation. GexBERT achieves state-of-the-art\nclassification accuracy from limited gene subsets, improves survival prediction\nby restoring expression of prognostic anchor genes, and outperforms\nconventional imputation methods under high missingness. Furthermore, its\nattention-based interpretability reveals biologically meaningful gene patterns\nacross cancer types. These findings demonstrate the utility of GexBERT as a\nscalable and effective tool for gene expression modeling, with translational\npotential in settings where gene coverage is limited or incomplete.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09704v1",
    "published_date": "2025-04-13 19:49:59 UTC",
    "updated_date": "2025-04-13 19:49:59 UTC"
  },
  {
    "arxiv_id": "2504.09702v2",
    "title": "MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?",
    "authors": [
      "Yunxiang Zhang",
      "Muhammad Khalifa",
      "Shitanshu Bhushan",
      "Grant D Murphy",
      "Lajanugen Logeswaran",
      "Jaekyeom Kim",
      "Moontae Lee",
      "Honglak Lee",
      "Lu Wang"
    ],
    "abstract": "We introduce MLRC-Bench, a benchmark designed to quantify how effectively\nlanguage agents can tackle challenging Machine Learning (ML) Research\nCompetitions, with a focus on open research problems that demand novel\nmethodologies. Unlike prior work, e.g., AI Scientist, which evaluates the\nend-to-end agentic pipeline by using LLM-as-a-judge, MLRC-Bench measures the\nkey steps of proposing and implementing novel research methods and evaluates\nthem with rigorous protocol and objective metrics. Our curated suite of 7\ncompetition tasks reveals significant challenges for LLM agents. Even the\nbest-performing tested agent (gemini-exp-1206 under MLAB) closes only 9.3% of\nthe gap between baseline and top human participant scores. Furthermore, our\nanalysis reveals a misalignment between the LLM-judged innovation and actual\nperformance on cutting-edge ML research problems. MLRC-Bench is a dynamic\nbenchmark, designed to grow with new ML competitions and encourage rigorous,\nobjective evaluations of AI research capabilities. Our leaderboard and code are\navailable at: https://huggingface.co/spaces/launch/MLRC_Bench",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09702v2",
    "published_date": "2025-04-13 19:35:43 UTC",
    "updated_date": "2025-05-18 20:31:28 UTC"
  },
  {
    "arxiv_id": "2504.11482v1",
    "title": "snnTrans-DHZ: A Lightweight Spiking Neural Network Architecture for Underwater Image Dehazing",
    "authors": [
      "Vidya Sudevan",
      "Fakhreddine Zayer",
      "Rizwana Kausar",
      "Sajid Javed",
      "Hamad Karki",
      "Giulia De Masi",
      "Jorge Dias"
    ],
    "abstract": "Underwater image dehazing is critical for vision-based marine operations\nbecause light scattering and absorption can severely reduce visibility. This\npaper introduces snnTrans-DHZ, a lightweight Spiking Neural Network (SNN)\nspecifically designed for underwater dehazing. By leveraging the temporal\ndynamics of SNNs, snnTrans-DHZ efficiently processes time-dependent raw image\nsequences while maintaining low power consumption. Static underwater images are\nfirst converted into time-dependent sequences by repeatedly inputting the same\nimage over user-defined timesteps. These RGB sequences are then transformed\ninto LAB color space representations and processed concurrently. The\narchitecture features three key modules: (i) a K estimator that extracts\nfeatures from multiple color space representations; (ii) a Background Light\nEstimator that jointly infers the background light component from the RGB-LAB\nimages; and (iii) a soft image reconstruction module that produces haze-free,\nvisibility-enhanced outputs. The snnTrans-DHZ model is directly trained using a\nsurrogate gradient-based backpropagation through time (BPTT) strategy alongside\na novel combined loss function. Evaluated on the UIEB benchmark, snnTrans-DHZ\nachieves a PSNR of 21.68 dB and an SSIM of 0.8795, and on the EUVP dataset, it\nyields a PSNR of 23.46 dB and an SSIM of 0.8439. With only 0.5670 million\nnetwork parameters, and requiring just 7.42 GSOPs and 0.0151 J of energy, the\nalgorithm significantly outperforms existing state-of-the-art methods in terms\nof efficiency. These features make snnTrans-DHZ highly suitable for deployment\nin underwater robotics, marine exploration, and environmental monitoring.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.PF",
      "cs.RO",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11482v1",
    "published_date": "2025-04-13 19:03:33 UTC",
    "updated_date": "2025-04-13 19:03:33 UTC"
  },
  {
    "arxiv_id": "2504.09691v1",
    "title": "Migrating Code At Scale With LLMs At Google",
    "authors": [
      "Celal Ziftci",
      "Stoyan Nikolov",
      "Anna Sjövall",
      "Bo Kim",
      "Daniele Codecasa",
      "Max Kim"
    ],
    "abstract": "Developers often evolve an existing software system by making internal\nchanges, called migration. Moving to a new framework, changing implementation\nto improve efficiency, and upgrading a dependency to its latest version are\nexamples of migrations.\n  Migration is a common and typically continuous maintenance task undertaken\neither manually or through tooling. Certain migrations are labor intensive and\ncostly, developers do not find the required work rewarding, and they may take\nyears to complete. Hence, automation is preferred for such migrations.\n  In this paper, we discuss a large-scale, costly and traditionally manual\nmigration project at Google, propose a novel automated algorithm that uses\nchange location discovery and a Large Language Model (LLM) to aid developers\nconduct the migration, report the results of a large case study, and discuss\nlessons learned.\n  Our case study on 39 distinct migrations undertaken by three developers over\ntwelve months shows that a total of 595 code changes with 93,574 edits have\nbeen submitted, where 74.45% of the code changes and 69.46% of the edits were\ngenerated by the LLM. The developers reported high satisfaction with the\nautomated tooling, and estimated a 50% reduction on the total time spent on the\nmigration compared to earlier manual migrations.\n  Our results suggest that our automated, LLM-assisted workflow can serve as a\nmodel for similar initiatives.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09691v1",
    "published_date": "2025-04-13 18:52:44 UTC",
    "updated_date": "2025-04-13 18:52:44 UTC"
  },
  {
    "arxiv_id": "2504.09689v3",
    "title": "EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety",
    "authors": [
      "Jiahao Qiu",
      "Yinghui He",
      "Xinzhe Juan",
      "Yimin Wang",
      "Yuhan Liu",
      "Zixin Yao",
      "Yue Wu",
      "Xun Jiang",
      "Ling Yang",
      "Mengdi Wang"
    ],
    "abstract": "The rise of LLM-driven AI characters raises safety concerns, particularly for\nvulnerable human users with psychological disorders. To address these risks, we\npropose EmoAgent, a multi-agent AI framework designed to evaluate and mitigate\nmental health hazards in human-AI interactions. EmoAgent comprises two\ncomponents: EmoEval simulates virtual users, including those portraying\nmentally vulnerable individuals, to assess mental health changes before and\nafter interactions with AI characters. It uses clinically proven psychological\nand psychiatric assessment tools (PHQ-9, PDI, PANSS) to evaluate mental risks\ninduced by LLM. EmoGuard serves as an intermediary, monitoring users' mental\nstatus, predicting potential harm, and providing corrective feedback to\nmitigate risks. Experiments conducted in popular character-based chatbots show\nthat emotionally engaging dialogues can lead to psychological deterioration in\nvulnerable users, with mental state deterioration in more than 34.4% of the\nsimulations. EmoGuard significantly reduces these deterioration rates,\nunderscoring its role in ensuring safer AI-human interactions. Our code is\navailable at: https://github.com/1akaman/EmoAgent",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.09689v3",
    "published_date": "2025-04-13 18:47:22 UTC",
    "updated_date": "2025-04-29 22:29:52 UTC"
  },
  {
    "arxiv_id": "2504.09685v1",
    "title": "Can LLMs Revolutionize the Design of Explainable and Efficient TinyML Models?",
    "authors": [
      "Christophe El Zeinaty",
      "Wassim Hamidouche",
      "Glenn Herrou",
      "Daniel Menard",
      "Merouane Debbah"
    ],
    "abstract": "This paper introduces a novel framework for designing efficient neural\nnetwork architectures specifically tailored to tiny machine learning (TinyML)\nplatforms. By leveraging large language models (LLMs) for neural architecture\nsearch (NAS), a vision transformer (ViT)-based knowledge distillation (KD)\nstrategy, and an explainability module, the approach strikes an optimal balance\nbetween accuracy, computational efficiency, and memory usage. The LLM-guided\nsearch explores a hierarchical search space, refining candidate architectures\nthrough Pareto optimization based on accuracy, multiply-accumulate operations\n(MACs), and memory metrics. The best-performing architectures are further\nfine-tuned using logits-based KD with a pre-trained ViT-B/16 model, which\nenhances generalization without increasing model size. Evaluated on the\nCIFAR-100 dataset and deployed on an STM32H7 microcontroller (MCU), the three\nproposed models, LMaNet-Elite, LMaNet-Core, and QwNet-Core, achieve accuracy\nscores of 74.50%, 74.20% and 73.00%, respectively. All three models surpass\ncurrent state-of-the-art (SOTA) models, such as MCUNet-in3/in4 (69.62% /\n72.86%) and XiNet (72.27%), while maintaining a low computational cost of less\nthan 100 million MACs and adhering to the stringent 320 KB static random-access\nmemory (SRAM) constraint. These results demonstrate the efficiency and\nperformance of the proposed framework for TinyML platforms, underscoring the\npotential of combining LLM-driven search, Pareto optimization, KD, and\nexplainability to develop accurate, efficient, and interpretable models. This\napproach opens new possibilities in NAS, enabling the design of efficient\narchitectures specifically suited for TinyML.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09685v1",
    "published_date": "2025-04-13 18:36:03 UTC",
    "updated_date": "2025-04-13 18:36:03 UTC"
  },
  {
    "arxiv_id": "2504.09680v1",
    "title": "SPOT: Spatio-Temporal Pattern Mining and Optimization for Load Consolidation in Freight Transportation Networks",
    "authors": [
      "Sikai Cheng",
      "Amira Hijazi",
      "Jeren Konak",
      "Alan Erera",
      "Pascal Van Hentenryck"
    ],
    "abstract": "Freight consolidation has significant potential to reduce transportation\ncosts and mitigate congestion and pollution. An effective load consolidation\nplan relies on carefully chosen consolidation points to ensure alignment with\nexisting transportation management processes, such as driver scheduling,\npersonnel planning, and terminal operations. This complexity represents a\nsignificant challenge when searching for optimal consolidation strategies.\nTraditional optimization-based methods provide exact solutions, but their\ncomputational complexity makes them impractical for large-scale instances and\nthey fail to leverage historical data. Machine learning-based approaches\naddress these issues but often ignore operational constraints, leading to\ninfeasible consolidation plans.\n  This work proposes SPOT, an end-to-end approach that integrates the benefits\nof machine learning (ML) and optimization for load consolidation. The ML\ncomponent plays a key role in the planning phase by identifying the\nconsolidation points through spatio-temporal clustering and constrained\nfrequent itemset mining, while the optimization selects the most cost-effective\nfeasible consolidation routes for a given operational day. Extensive\nexperiments conducted on industrial load data demonstrate that SPOT\nsignificantly reduces travel distance and transportation costs (by about 50% on\nlarge terminals) compared to the existing industry-standard load planning\nstrategy and a neighborhood-based heuristic. Moreover, the ML component\nprovides valuable tactical-level insights by identifying frequently recurring\nconsolidation opportunities that guide proactive planning. In addition, SPOT is\ncomputationally efficient and can be easily scaled to accommodate large\ntransportation networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09680v1",
    "published_date": "2025-04-13 18:14:38 UTC",
    "updated_date": "2025-04-13 18:14:38 UTC"
  },
  {
    "arxiv_id": "2504.09662v1",
    "title": "AgentDynEx: Nudging the Mechanics and Dynamics of Multi-Agent Simulations",
    "authors": [
      "Jenny Ma",
      "Riya Sahni",
      "Karthik Sreedhar",
      "Lydia B. Chilton"
    ],
    "abstract": "Multi-agent large language model simulations have the potential to model\ncomplex human behaviors and interactions. If the mechanics are set up properly,\nunanticipated and valuable social dynamics can surface. However, it is\nchallenging to consistently enforce simulation mechanics while still allowing\nfor notable and emergent dynamics. We present AgentDynEx, an AI system that\nhelps set up simulations from user-specified mechanics and dynamics. AgentDynEx\nuses LLMs to guide users through a Configuration Matrix to identify core\nmechanics and define milestones to track dynamics. It also introduces a method\ncalled \\textit{nudging}, where the system dynamically reflects on simulation\nprogress and gently intervenes if it begins to deviate from intended outcomes.\nA technical evaluation found that nudging enables simulations to have more\ncomplex mechanics and maintain its notable dynamics compared to simulations\nwithout nudging. We discuss the importance of nudging as a technique for\nbalancing mechanics and dynamics of multi-agent simulations.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09662v1",
    "published_date": "2025-04-13 17:26:35 UTC",
    "updated_date": "2025-04-13 17:26:35 UTC"
  },
  {
    "arxiv_id": "2504.16099v1",
    "title": "Two-Timescale Joint Transmit and Pinching Beamforming for Pinching-Antenna Systems",
    "authors": [
      "Luyuan Zhang",
      "Xidong Mu",
      "An Liu",
      "Yuanwei Liu"
    ],
    "abstract": "Pinching antenna systems (PASS) have been proposed as a revolutionary\nflexible antenna technology which facilitates line-of-sight links via numerous\nlow-cost pinching antennas with adjustable activation positions over\nwaveguides. This letter proposes a two-timescale joint transmit and pinching\nbeamforming design for the maximization of sum rate of a PASS-based downlink\nmulti-user multiple input single output system. A primal dual decomposition\nmethod is developed to decouple the two-timescale problem into two\nsub-problems: 1) A Karush-Kuhn-Tucker-guided dual learning-based approach is\nproposed to solve the short-term transmit beamforming design sub-problem; 2)\nThe long-term pinching beamforming design sub-problem is tackled by adopting a\nstochastic successive convex approximation method. Simulation results\ndemonstrate that the proposed two-timescale algorithm achieves a significant\nperformance gain compared to other baselines.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "eess.SP",
    "comment": "5 pages, 4 figures, letter",
    "pdf_url": "http://arxiv.org/pdf/2504.16099v1",
    "published_date": "2025-04-13 16:58:35 UTC",
    "updated_date": "2025-04-13 16:58:35 UTC"
  },
  {
    "arxiv_id": "2504.17055v1",
    "title": "Psychological Effect of AI driven marketing tools for beauty/facial feature enhancement",
    "authors": [
      "Ayushi Agrawal",
      "Aditya Kondai",
      "Kavita Vemuri"
    ],
    "abstract": "AI-powered facial assessment tools are reshaping how individuals evaluate\nappearance and internalize social judgments. This study examines the\npsychological impact of such tools on self-objectification, self-esteem, and\nemotional responses, with attention to gender differences. Two samples used\ndistinct versions of a facial analysis tool: one overtly critical (N=75; M=22.9\nyears), and another more neutral (N=51; M=19.9 years). Participants completed\nvalidated self-objectification and self-esteem scales and custom items\nmeasuring emotion, digital/physical appearance enhancement (DAE, PAEE), and\nperceived social emotion (PSE). Results revealed consistent links between high\nself-objectification, low self-esteem, and increased appearance enhancement\nbehaviors across both versions. Despite softer framing, the newer tool still\nevoked negative emotional responses (U=1466.5, p=0.013), indicating implicit\nfeedback may reinforce appearance-related insecurities. Gender differences\nemerged in DAE (p=0.025) and PSE (p<0.001), with females more prone to digital\nenhancement and less likely to perceive emotional impact in others. These\nfindings reveal how AI tools may unintentionally reinforce and amplify existing\nsocial biases and underscore the critical need for responsible AI design and\ndevelopment. Future research will investigate how human ideologies embedded in\nthe training data of such tools shape their evaluative outputs, and how these,\nin turn, influence user attitudes and decisions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17055v1",
    "published_date": "2025-04-13 16:42:06 UTC",
    "updated_date": "2025-04-13 16:42:06 UTC"
  },
  {
    "arxiv_id": "2504.09647v1",
    "title": "Building AI Service Repositories for On-Demand Service Orchestration in 6G AI-RAN",
    "authors": [
      "Yun Tang",
      "Mengbang Zou",
      "Udhaya Chandhar Srinivasan",
      "Obumneme Umealor",
      "Dennis Kevogo",
      "Benjamin James Scott",
      "Weisi Guo"
    ],
    "abstract": "Efficient orchestration of AI services in 6G AI-RAN requires well-structured,\nready-to-deploy AI service repositories combined with orchestration methods\nadaptive to diverse runtime contexts across radio access, edge, and cloud\nlayers. Current literature lacks comprehensive frameworks for constructing such\nrepositories and generally overlooks key practical orchestration factors. This\npaper systematically identifies and categorizes critical attributes influencing\nAI service orchestration in 6G networks and introduces an open-source,\nLLM-assisted toolchain that automates service packaging, deployment, and\nruntime profiling. We validate the proposed toolchain through the Cranfield AI\nService repository case study, demonstrating significant automation benefits,\nreduced manual coding efforts, and the necessity of infrastructure-specific\nprofiling, paving the way for more practical orchestration frameworks.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, three figures, one table, submitted to IEEE GlobeCOM 2025\n  for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2504.09647v1",
    "published_date": "2025-04-13 16:40:58 UTC",
    "updated_date": "2025-04-13 16:40:58 UTC"
  },
  {
    "arxiv_id": "2504.09645v1",
    "title": "Myanmar XNLI: Building a Dataset and Exploring Low-resource Approaches to Natural Language Inference with Myanmar",
    "authors": [
      "Aung Kyaw Htet",
      "Mark Dras"
    ],
    "abstract": "Despite dramatic recent progress in NLP, it is still a major challenge to\napply Large Language Models (LLM) to low-resource languages. This is made\nvisible in benchmarks such as Cross-Lingual Natural Language Inference (XNLI),\na key task that demonstrates cross-lingual capabilities of NLP systems across a\nset of 15 languages. In this paper, we extend the XNLI task for one additional\nlow-resource language, Myanmar, as a proxy challenge for broader low-resource\nlanguages, and make three core contributions. First, we build a dataset called\nMyanmar XNLI (myXNLI) using community crowd-sourced methods, as an extension to\nthe existing XNLI corpus. This involves a two-stage process of community-based\nconstruction followed by expert verification; through an analysis, we\ndemonstrate and quantify the value of the expert verification stage in the\ncontext of community-based construction for low-resource languages. We make the\nmyXNLI dataset available to the community for future research. Second, we carry\nout evaluations of recent multilingual language models on the myXNLI benchmark,\nas well as explore data-augmentation methods to improve model performance. Our\ndata-augmentation methods improve model accuracy by up to 2 percentage points\nfor Myanmar, while uplifting other languages at the same time. Third, we\ninvestigate how well these data-augmentation methods generalise to other\nlow-resource languages in the XNLI dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09645v1",
    "published_date": "2025-04-13 16:36:59 UTC",
    "updated_date": "2025-04-13 16:36:59 UTC"
  },
  {
    "arxiv_id": "2504.09635v1",
    "title": "A Two-Stage Interpretable Matching Framework for Causal Inference",
    "authors": [
      "Sahil Shikalgar",
      "Md. Noor-E-Alam"
    ],
    "abstract": "Matching in causal inference from observational data aims to construct\ntreatment and control groups with similar distributions of covariates, thereby\nreducing confounding and ensuring an unbiased estimation of treatment effects.\nThis matched sample closely mimics a randomized controlled trial (RCT), thus\nimproving the quality of causal estimates. We introduce a novel Two-stage\nInterpretable Matching (TIM) framework for transparent and interpretable\ncovariate matching. In the first stage, we perform exact matching across all\navailable covariates. For treatment and control units without an exact match in\nthe first stage, we proceed to the second stage. Here, we iteratively refine\nthe matching process by removing the least significant confounder in each\niteration and attempting exact matching on the remaining covariates. We learn a\ndistance metric for the dropped covariates to quantify closeness to the\ntreatment unit(s) within the corresponding strata. We used these high- quality\nmatches to estimate the conditional average treatment effects (CATEs). To\nvalidate TIM, we conducted experiments on synthetic datasets with varying\nassociation structures and correlations. We assessed its performance by\nmeasuring bias in CATE estimation and evaluating multivariate overlap between\ntreatment and control groups before and after matching. Additionally, we apply\nTIM to a real-world healthcare dataset from the Centers for Disease Control and\nPrevention (CDC) to estimate the causal effect of high cholesterol on diabetes.\nOur results demonstrate that TIM improves CATE estimates, increases\nmultivariate overlap, and scales effectively to high-dimensional data, making\nit a robust tool for causal inference in observational data.",
    "categories": [
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09635v1",
    "published_date": "2025-04-13 16:17:52 UTC",
    "updated_date": "2025-04-13 16:17:52 UTC"
  },
  {
    "arxiv_id": "2504.09627v1",
    "title": "Slow Thinking for Sequential Recommendation",
    "authors": [
      "Junjie Zhang",
      "Beichen Zhang",
      "Wenqi Sun",
      "Hongyu Lu",
      "Wayne Xin Zhao",
      "Yu Chen",
      "Ji-Rong Wen"
    ],
    "abstract": "To develop effective sequential recommender systems, numerous methods have\nbeen proposed to model historical user behaviors. Despite the effectiveness,\nthese methods share the same fast thinking paradigm. That is, for making\nrecommendations, these methods typically encodes user historical interactions\nto obtain user representations and directly match these representations with\ncandidate item representations. However, due to the limited capacity of\ntraditional lightweight recommendation models, this one-step inference paradigm\noften leads to suboptimal performance. To tackle this issue, we present a novel\nslow thinking recommendation model, named STREAM-Rec. Our approach is capable\nof analyzing historical user behavior, generating a multi-step, deliberative\nreasoning process, and ultimately delivering personalized recommendations. In\nparticular, we focus on two key challenges: (1) identifying the suitable\nreasoning patterns in recommender systems, and (2) exploring how to effectively\nstimulate the reasoning capabilities of traditional recommenders. To this end,\nwe introduce a three-stage training framework. In the first stage, the model is\npretrained on large-scale user behavior data to learn behavior patterns and\ncapture long-range dependencies. In the second stage, we design an iterative\ninference algorithm to annotate suitable reasoning traces by progressively\nrefining the model predictions. This annotated data is then used to fine-tune\nthe model. Finally, in the third stage, we apply reinforcement learning to\nfurther enhance the model generalization ability. Extensive experiments\nvalidate the effectiveness of our proposed method.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09627v1",
    "published_date": "2025-04-13 15:53:30 UTC",
    "updated_date": "2025-04-13 15:53:30 UTC"
  },
  {
    "arxiv_id": "2504.13202v1",
    "title": "The Quantum LLM: Modeling Semantic Spaces with Quantum Principles",
    "authors": [
      "Timo Aukusti Laine"
    ],
    "abstract": "In the previous article, we presented a quantum-inspired framework for\nmodeling semantic representation and processing in Large Language Models\n(LLMs), drawing upon mathematical tools and conceptual analogies from quantum\nmechanics to offer a new perspective on these complex systems. In this paper,\nwe clarify the core assumptions of this model, providing a detailed exposition\nof six key principles that govern semantic representation, interaction, and\ndynamics within LLMs. The goal is to justify that a quantum-inspired framework\nis a valid approach to studying semantic spaces. This framework offers valuable\ninsights into their information processing and response generation, and we\nfurther discuss the potential of leveraging quantum computing to develop\nsignificantly more powerful and efficient LLMs based on these principles.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13202v1",
    "published_date": "2025-04-13 15:49:41 UTC",
    "updated_date": "2025-04-13 15:49:41 UTC"
  },
  {
    "arxiv_id": "2504.09623v1",
    "title": "Ges3ViG: Incorporating Pointing Gestures into Language-Based 3D Visual Grounding for Embodied Reference Understanding",
    "authors": [
      "Atharv Mahesh Mane",
      "Dulanga Weerakoon",
      "Vigneshwaran Subbaraju",
      "Sougata Sen",
      "Sanjay E. Sarma",
      "Archan Misra"
    ],
    "abstract": "3-Dimensional Embodied Reference Understanding (3D-ERU) combines a language\ndescription and an accompanying pointing gesture to identify the most relevant\ntarget object in a 3D scene. Although prior work has explored pure\nlanguage-based 3D grounding, there has been limited exploration of 3D-ERU,\nwhich also incorporates human pointing gestures. To address this gap, we\nintroduce a data augmentation framework-Imputer, and use it to curate a new\nbenchmark dataset-ImputeRefer for 3D-ERU, by incorporating human pointing\ngestures into existing 3D scene datasets that only contain language\ninstructions. We also propose Ges3ViG, a novel model for 3D-ERU that achieves\n~30% improvement in accuracy as compared to other 3D-ERU models and ~9%\ncompared to other purely language-based 3D grounding models. Our code and\ndataset are available at https://github.com/AtharvMane/Ges3ViG.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.09623v1",
    "published_date": "2025-04-13 15:43:06 UTC",
    "updated_date": "2025-04-13 15:43:06 UTC"
  },
  {
    "arxiv_id": "2504.09620v1",
    "title": "Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models via Decentralized Bayesian Inference",
    "authors": [
      "Yuta Matsui",
      "Ryosuke Yamaki",
      "Ryo Ueda",
      "Seitaro Shinagawa",
      "Tadahiro Taniguchi"
    ],
    "abstract": "We propose the Metropolis-Hastings Captioning Game (MHCG), a method to fuse\nknowledge of multiple vision-language models (VLMs) by learning from each\nother. Although existing methods that combine multiple models suffer from\ninference costs and architectural constraints, MHCG avoids these problems by\nperforming decentralized Bayesian inference through a process resembling a\nlanguage game. The knowledge fusion process establishes communication between\ntwo VLM agents alternately captioning images and learning from each other. We\nconduct two image-captioning experiments with two VLMs, each pre-trained on a\ndifferent dataset. The first experiment demonstrates that MHCG achieves\nconsistent improvement in reference-free evaluation metrics. The second\nexperiment investigates how MHCG contributes to sharing VLMs' category-level\nvocabulary by observing the occurrence of the vocabulary in the generated\ncaptions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09620v1",
    "published_date": "2025-04-13 15:28:09 UTC",
    "updated_date": "2025-04-13 15:28:09 UTC"
  },
  {
    "arxiv_id": "2504.09609v2",
    "title": "A highly maneuverable flying squirrel drone with agility-improving foldable wings",
    "authors": [
      "Dohyeon Lee",
      "Jun-Gill Kang",
      "Soohee Han"
    ],
    "abstract": "Drones, like most airborne aerial vehicles, face inherent disadvantages in\nachieving agile flight due to their limited thrust capabilities. These physical\nconstraints cannot be fully addressed through advancements in control\nalgorithms alone. Drawing inspiration from the winged flying squirrel, this\npaper proposes a highly maneuverable drone equipped with agility-enhancing\nfoldable wings. By leveraging collaborative control between the conventional\npropeller system and the foldable wings-coordinated through the Thrust-Wing\nCoordination Control (TWCC) framework-the controllable acceleration set is\nexpanded, enabling the generation of abrupt vertical forces that are\nunachievable with traditional wingless drones. The complex aerodynamics of the\nfoldable wings are modeled using a physics-assisted recurrent neural network\n(paRNN), which calibrates the angle of attack (AOA) to align with the real\naerodynamic behavior of the wings. The additional air resistance generated by\nappropriately deploying these wings significantly improves the tracking\nperformance of the proposed \"flying squirrel\" drone. The model is trained on\nreal flight data and incorporates flat-plate aerodynamic principles.\nExperimental results demonstrate that the proposed flying squirrel drone\nachieves a 13.1% improvement in tracking performance, as measured by root mean\nsquare error (RMSE), compared to a conventional wingless drone. A demonstration\nvideo is available on YouTube: https://youtu.be/O8nrip18azY.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IEEE Robotics and Automation Letters. Project Page :\n  https://jgkang1210.github.io/fsdrone_ral/ , Video :\n  https://www.youtube.com/watch?v=tckIF3KCJig , Dohyeon Lee and Jun-Gill Kang\n  are co-authors",
    "pdf_url": "http://arxiv.org/pdf/2504.09609v2",
    "published_date": "2025-04-13 14:57:11 UTC",
    "updated_date": "2025-05-08 12:44:32 UTC"
  },
  {
    "arxiv_id": "2504.09602v2",
    "title": "Fine-tuning a Large Language Model for Automating Computational Fluid Dynamics Simulations",
    "authors": [
      "Zhehao Dong",
      "Zhen Lu",
      "Yue Yang"
    ],
    "abstract": "Configuring computational fluid dynamics (CFD) simulations typically demands\nextensive domain expertise, limiting broader access. Although large language\nmodels (LLMs) have advanced scientific computing, their use in automating CFD\nworkflows is underdeveloped. We introduce a novel approach centered on\ndomain-specific LLM adaptation. By fine-tuning Qwen2.5-7B-Instruct on NL2FOAM,\nour custom dataset of 28716 natural language-to-OpenFOAM configuration pairs\nwith chain-of-thought (CoT) annotations, we enable direct translation from\nnatural language descriptions to executable CFD setups. A multi-agent framework\norchestrates the process, autonomously verifying inputs, generating\nconfigurations, running simulations, and correcting errors. Evaluation on a\nbenchmark of 21 diverse flow cases demonstrates state-of-the-art performance,\nachieving 88.7% solution accuracy and 82.6% first-attempt success rate. This\nsignificantly outperforms larger general-purpose models like\nQwen2.5-72B-Instruct, DeepSeek-R1, and Llama3.3-70B-Instruct, while also\nrequiring fewer correction iterations and maintaining high computational\nefficiency. The results highlight the critical role of domain-specific\nadaptation in deploying LLM assistants for complex engineering workflows. Our\ncode and fine-tuned model have been deposited at\nhttps://github.com/YYgroup/AutoCFD.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09602v2",
    "published_date": "2025-04-13 14:35:30 UTC",
    "updated_date": "2025-04-21 07:04:57 UTC"
  },
  {
    "arxiv_id": "2504.09597v5",
    "title": "Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws",
    "authors": [
      "Zhixuan Pan",
      "Shaowen Wang",
      "Jian Li"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nnumerous tasks, yet principled explanations for their underlying mechanisms and\nseveral phenomena, such as scaling laws, hallucinations, and related behaviors,\nremain elusive. In this work, we revisit the classical relationship between\ncompression and prediction, grounded in Kolmogorov complexity and Shannon\ninformation theory, to provide deeper insights into LLM behaviors. By\nleveraging the Kolmogorov Structure Function and interpreting LLM compression\nas a two-part coding process, we offer a detailed view of how LLMs acquire and\nstore information across increasing model and data scales -- from pervasive\nsyntactic patterns to progressively rarer knowledge elements. Motivated by this\ntheoretical perspective and natural assumptions inspired by Heap's and Zipf's\nlaws, we introduce a simplified yet representative hierarchical data-generation\nframework called the Syntax-Knowledge model. Under the Bayesian setting, we\nshow that prediction and compression within this model naturally lead to\ndiverse learning and scaling behaviors of LLMs. In particular, our theoretical\nanalysis offers intuitive and principled explanations for both data and model\nscaling laws, the dynamics of knowledge acquisition during training and\nfine-tuning, factual knowledge hallucinations in LLMs. The experimental results\nvalidate our theoretical predictions.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09597v5",
    "published_date": "2025-04-13 14:31:52 UTC",
    "updated_date": "2025-05-17 15:36:54 UTC"
  },
  {
    "arxiv_id": "2504.09590v1",
    "title": "Efficient LLM Serving on Hybrid Real-time and Best-effort Requests",
    "authors": [
      "Wan Borui",
      "Zhao Juntao",
      "Jiang Chenyu",
      "Guo Chuanxiong",
      "Wu Chuan"
    ],
    "abstract": "Recent breakthroughs in large Language Models (LLMs) have enabled various\ngenerative tasks on a single model. Real-world services (e.g., OpenAI's ChatGPT\n[27]) powered by an LLM often concurrently support latency-critical requests\nfor interactive applications (e.g., question-answering systems, referred to as\nreal-time or RT requests) and throughput-oriented requests for back-of-house\nprocessing (e.g., documents batch processing [28], referred to best-effort or\nBE requests), with complex hybrid inference workloads to the underlying model.\nState-of-the-art (SOTA) LLM serving systems dedicate machines to each type of\nrequest, towards either low inference latency or high serving throughput,\nrespectively. This practice simplifies request scheduling and management but\nsuffers from poor resource utilization. We propose BROS, a hybrid LLM serving\nsystem that aims to collocate RT/BE requests, meeting RT requests' latency\nrequirements while maintaining BE requests' throughput. BROS formulates the\nproblem of hybrid RT/BE request scheduling and solves it with a dynamic\npriority-based algorithm. BROS designs a bidirectional KV cache management\nmechanism, allowing RT requests to share KV memory with BE requests to remove\nthe scheduling restrictions caused by insufficient KV memory and improve\nutilization. Extensive experiments validate that BROS achieves a good trade-off\nwhen serving hybrid RT and BE requests. It significantly reduces the latency of\nRT requests (up to 74.20%), improving their fine-grained service level\nobjectives (SLOs) attainments (up to 36.38x), with negligible throughput\nreduction for BE requests, showing significant advantages over SOTA systems\nlike vLLM and TGI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09590v1",
    "published_date": "2025-04-13 14:16:57 UTC",
    "updated_date": "2025-04-13 14:16:57 UTC"
  },
  {
    "arxiv_id": "2504.09588v1",
    "title": "TextSplat: Text-Guided Semantic Fusion for Generalizable Gaussian Splatting",
    "authors": [
      "Zhicong Wu",
      "Hongbin Xu",
      "Gang Xu",
      "Ping Nie",
      "Zhixin Yan",
      "Jinkai Zheng",
      "Liangqiong Qu",
      "Ming Li",
      "Liqiang Nie"
    ],
    "abstract": "Recent advancements in Generalizable Gaussian Splatting have enabled robust\n3D reconstruction from sparse input views by utilizing feed-forward Gaussian\nSplatting models, achieving superior cross-scene generalization. However, while\nmany methods focus on geometric consistency, they often neglect the potential\nof text-driven guidance to enhance semantic understanding, which is crucial for\naccurately reconstructing fine-grained details in complex scenes. To address\nthis limitation, we propose TextSplat--the first text-driven Generalizable\nGaussian Splatting framework. By employing a text-guided fusion of diverse\nsemantic cues, our framework learns robust cross-modal feature representations\nthat improve the alignment of geometric and semantic information, producing\nhigh-fidelity 3D reconstructions. Specifically, our framework employs three\nparallel modules to obtain complementary representations: the Diffusion Prior\nDepth Estimator for accurate depth information, the Semantic Aware Segmentation\nNetwork for detailed semantic information, and the Multi-View Interaction\nNetwork for refined cross-view features. Then, in the Text-Guided Semantic\nFusion Module, these representations are integrated via the text-guided and\nattention-based feature aggregation mechanism, resulting in enhanced 3D\nGaussian parameters enriched with detailed semantic cues. Experimental results\non various benchmark datasets demonstrate improved performance compared to\nexisting methods across multiple evaluation metrics, validating the\neffectiveness of our framework. The code will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09588v1",
    "published_date": "2025-04-13 14:14:10 UTC",
    "updated_date": "2025-04-13 14:14:10 UTC"
  },
  {
    "arxiv_id": "2504.09583v1",
    "title": "AirVista-II: An Agentic System for Embodied UAVs Toward Dynamic Scene Semantic Understanding",
    "authors": [
      "Fei Lin",
      "Yonglin Tian",
      "Tengchao Zhang",
      "Jun Huang",
      "Sangtian Guan",
      "Fei-Yue Wang"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly important in dynamic\nenvironments such as logistics transportation and disaster response. However,\ncurrent tasks often rely on human operators to monitor aerial videos and make\noperational decisions. This mode of human-machine collaboration suffers from\nsignificant limitations in efficiency and adaptability. In this paper, we\npresent AirVista-II -- an end-to-end agentic system for embodied UAVs, designed\nto enable general-purpose semantic understanding and reasoning in dynamic\nscenes. The system integrates agent-based task identification and scheduling,\nmultimodal perception mechanisms, and differentiated keyframe extraction\nstrategies tailored for various temporal scenarios, enabling the efficient\ncapture of critical scene information. Experimental results demonstrate that\nthe proposed system achieves high-quality semantic understanding across diverse\nUAV-based dynamic scenarios under a zero-shot setting.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09583v1",
    "published_date": "2025-04-13 14:06:50 UTC",
    "updated_date": "2025-04-13 14:06:50 UTC"
  },
  {
    "arxiv_id": "2504.09582v1",
    "title": "Reduction of Supervision for Biomedical Knowledge Discovery",
    "authors": [
      "Christos Theodoropoulos",
      "Andrei Catalin Coman",
      "James Henderson",
      "Marie-Francine Moens"
    ],
    "abstract": "Knowledge discovery is hindered by the increasing volume of publications and\nthe scarcity of extensive annotated data. To tackle the challenge of\ninformation overload, it is essential to employ automated methods for knowledge\nextraction and processing. Finding the right balance between the level of\nsupervision and the effectiveness of models poses a significant challenge.\nWhile supervised techniques generally result in better performance, they have\nthe major drawback of demanding labeled data. This requirement is\nlabor-intensive and time-consuming and hinders scalability when exploring new\ndomains. In this context, our study addresses the challenge of identifying\nsemantic relationships between biomedical entities (e.g., diseases, proteins)\nin unstructured text while minimizing dependency on supervision. We introduce a\nsuite of unsupervised algorithms based on dependency trees and attention\nmechanisms and employ a range of pointwise binary classification methods.\nTransitioning from weakly supervised to fully unsupervised settings, we assess\nthe methods' ability to learn from data with noisy labels. The evaluation on\nbiomedical benchmark datasets explores the effectiveness of the methods. Our\napproach tackles a central issue in knowledge discovery: balancing performance\nwith minimal supervision. By gradually decreasing supervision, we assess the\nrobustness of pointwise binary classification techniques in handling noisy\nlabels, revealing their capability to shift from weakly supervised to entirely\nunsupervised scenarios. Comprehensive benchmarking offers insights into the\neffectiveness of these techniques, suggesting an encouraging direction toward\nadaptable knowledge discovery systems, representing progress in creating\ndata-efficient methodologies for extracting useful insights when annotated data\nis limited.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as part of the PhD dissertation: Theodoropoulos, Christos,\n  Marie-Francine Moens, and Matthew Blaschko. \"Deep Learning Models for the\n  Extraction of Knowledge from Text.\" (2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.09582v1",
    "published_date": "2025-04-13 14:05:40 UTC",
    "updated_date": "2025-04-13 14:05:40 UTC"
  },
  {
    "arxiv_id": "2504.09574v1",
    "title": "Improved FOX Optimization Algorithm",
    "authors": [
      "Mahmood A. Jumaah",
      "Yossra H. Ali",
      "Tarik A. Rashid"
    ],
    "abstract": "Optimization algorithms are essential for solving many real-world problems.\nHowever, challenges such as premature convergence to local optima and the\ndifficulty of effectively balancing exploration and exploitation often hinder\ntheir performance. To address these issues, this paper proposes an improved FOX\noptimization algorithm, Improved FOX (IFOX). The IFOX algorithm introduces a\nnew adaptive mechanism for balancing exploration and exploitation based on\nfitness values. It also reduces the number of hyperparameters and simplifies\nthe core equations of the original FOX. To evaluate its effectiveness, IFOX has\nbeen tested on classical uni-modal and multi-modal benchmark functions, as well\nas on benchmark sets from the Congress on Evolutionary Computation (CEC), in\naddition to two engineering design problems: Pressure Vessel Design and\nEconomic Load Dispatch. The results show that IFOX outperforms existing\noptimization algorithms, achieving superior results on 51 benchmark functions.\nThese findings underscore the strong potential of IFOX as a competitive and\nrobust optimization algorithm for a wide range of applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "34 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.09574v1",
    "published_date": "2025-04-13 13:50:18 UTC",
    "updated_date": "2025-04-13 13:50:18 UTC"
  },
  {
    "arxiv_id": "2504.09546v3",
    "title": "A simulation-heuristics dual-process model for intuitive physics",
    "authors": [
      "Shiqian Li",
      "Yuxi Ma",
      "Jiajun Yan",
      "Bo Dai",
      "Yujia Peng",
      "Chi Zhang",
      "Yixin Zhu"
    ],
    "abstract": "The role of mental simulation in human physical reasoning is widely\nacknowledged, but whether it is employed across scenarios with varying\nsimulation costs and where its boundary lies remains unclear. Using a\npouring-marble task, our human study revealed two distinct error patterns when\npredicting pouring angles, differentiated by simulation time. While mental\nsimulation accurately captured human judgments in simpler scenarios, a linear\nheuristic model better matched human predictions when simulation time exceeded\na certain boundary. Motivated by these observations, we propose a dual-process\nframework, Simulation-Heuristics Model (SHM), where intuitive physics employs\nsimulation for short-time simulation but switches to heuristics when simulation\nbecomes costly. By integrating computational methods previously viewed as\nseparate into a unified model, SHM quantitatively captures their switching\nmechanism. The SHM aligns more precisely with human behavior and demonstrates\nconsistent predictive performance across diverse scenarios, advancing our\nunderstanding of the adaptive nature of intuitive physical reasoning.",
    "categories": [
      "physics.ed-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ed-ph",
    "comment": "8 pages, CogSci 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.09546v3",
    "published_date": "2025-04-13 12:34:02 UTC",
    "updated_date": "2025-05-19 11:39:28 UTC"
  },
  {
    "arxiv_id": "2504.09532v1",
    "title": "Embodied Chain of Action Reasoning with Multi-Modal Foundation Model for Humanoid Loco-manipulation",
    "authors": [
      "Yu Hao",
      "Geeta Chandra Raju Bethala",
      "Niraj Pudasaini",
      "Hao Huang",
      "Shuaihang Yuan",
      "Congcong Wen",
      "Baoru Huang",
      "Anh Nguyen",
      "Yi Fang"
    ],
    "abstract": "Enabling humanoid robots to autonomously perform loco-manipulation tasks in\ncomplex, unstructured environments poses significant challenges. This entails\nequipping robots with the capability to plan actions over extended horizons\nwhile leveraging multi-modality to bridge gaps between high-level planning and\nactual task execution. Recent advancements in multi-modal foundation models\nhave showcased substantial potential in enhancing planning and reasoning\nabilities, particularly in the comprehension and processing of semantic\ninformation for robotic control tasks. In this paper, we introduce a novel\nframework based on foundation models that applies the embodied chain of action\nreasoning methodology to autonomously plan actions from textual instructions\nfor humanoid loco-manipulation. Our method integrates humanoid-specific chain\nof thought methodology, including detailed affordance and body movement\nanalysis, which provides a breakdown of the task into a sequence of locomotion\nand manipulation actions. Moreover, we incorporate spatial reasoning based on\nthe observation and target object properties to effectively navigate where\ntarget position may be unseen or occluded. Through rigorous experimental setups\non object rearrangement, manipulations and loco-manipulation tasks on a\nreal-world environment, we evaluate our method's efficacy on the decoupled\nupper and lower body control and demonstrate the effectiveness of the chain of\nrobotic action reasoning strategies in comprehending human instructions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09532v1",
    "published_date": "2025-04-13 11:37:32 UTC",
    "updated_date": "2025-04-13 11:37:32 UTC"
  },
  {
    "arxiv_id": "2504.09522v1",
    "title": "How new data permeates LLM knowledge and how to dilute it",
    "authors": [
      "Chen Sun",
      "Renat Aksitov",
      "Andrey Zhmoginov",
      "Nolan Andrew Miller",
      "Max Vladymyrov",
      "Ulrich Rueckert",
      "Been Kim",
      "Mark Sandler"
    ],
    "abstract": "Large language models learn and continually learn through the accumulation of\ngradient-based updates, but how individual pieces of new information affect\nexisting knowledge, leading to both beneficial generalization and problematic\nhallucination, remains poorly understood. We demonstrate that when learning new\ninformation, LLMs exhibit a \"priming\" effect: learning a new fact can cause the\nmodel to inappropriately apply that knowledge in unrelated contexts. To\nsystematically study this phenomenon, we introduce \"Outlandish,\" a carefully\ncurated dataset of 1320 diverse text samples designed to probe how new\nknowledge permeates through an LLM's existing knowledge base. Using this\ndataset, we show that the degree of priming after learning new information can\nbe predicted by measuring the token probability of key words before learning.\nThis relationship holds robustly across different model architectures (PALM-2,\nGemma, Llama), sizes, and training stages. Finally, we develop two novel\ntechniques to modulate how new knowledge affects existing model behavior: (1) a\n``stepping-stone'' text augmentation strategy and (2) an ``ignore-k'' update\npruning method. These approaches reduce undesirable priming effects by 50-95\\%\nwhile preserving the model's ability to learn new information. Our findings\nprovide both empirical insights into how LLMs learn and practical tools for\nimproving the specificity of knowledge insertion in language models. Further\nmaterials: https://sunchipsster1.github.io/projects/outlandish/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09522v1",
    "published_date": "2025-04-13 11:25:04 UTC",
    "updated_date": "2025-04-13 11:25:04 UTC"
  },
  {
    "arxiv_id": "2504.12333v1",
    "title": "Meta-Evaluating Local LLMs: Rethinking Performance Metrics for Serious Games",
    "authors": [
      "Andrés Isaza-Giraldo",
      "Paulo Bala",
      "Lucas Pereira"
    ],
    "abstract": "The evaluation of open-ended responses in serious games presents a unique\nchallenge, as correctness is often subjective. Large Language Models (LLMs) are\nincreasingly being explored as evaluators in such contexts, yet their accuracy\nand consistency remain uncertain, particularly for smaller models intended for\nlocal execution. This study investigates the reliability of five small-scale\nLLMs when assessing player responses in \\textit{En-join}, a game that simulates\ndecision-making within energy communities. By leveraging traditional binary\nclassification metrics (including accuracy, true positive rate, and true\nnegative rate), we systematically compare these models across different\nevaluation scenarios. Our results highlight the strengths and limitations of\neach model, revealing trade-offs between sensitivity, specificity, and overall\nperformance. We demonstrate that while some models excel at identifying correct\nresponses, others struggle with false positives or inconsistent evaluations.\nThe findings highlight the need for context-aware evaluation frameworks and\ncareful model selection when deploying LLMs as evaluators. This work\ncontributes to the broader discourse on the trustworthiness of AI-driven\nassessment tools, offering insights into how different LLM architectures handle\nsubjective evaluation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "2nd HEAL Workshop at CHI Conference on Human Factors in Computing\n  Systems. April 26, 2025. Yokohama, Japan",
    "pdf_url": "http://arxiv.org/pdf/2504.12333v1",
    "published_date": "2025-04-13 10:46:13 UTC",
    "updated_date": "2025-04-13 10:46:13 UTC"
  },
  {
    "arxiv_id": "2504.13194v1",
    "title": "Optimizing Multi-Gateway LoRaWAN via Cloud-Edge Collaboration and Knowledge Distillation",
    "authors": [
      "Hong Yang"
    ],
    "abstract": "For large-scale multi-gateway LoRaWAN networks, this study proposes a\ncloud-edge collaborative resource allocation and decision-making method based\non edge intelligence, HEAT-LDL (HEAT-Local Distill Lyapunov), which realizes\ncollaborative decision-making between gateways and terminal nodes. HEAT-LDL\ncombines the Actor-Critic architecture and the Lyapunov optimization method to\nachieve intelligent downlink control and gateway load balancing. When the\nsignal quality is good, the network server uses the HEAT algorithm to schedule\nthe terminal nodes. To improve the efficiency of autonomous decision-making of\nterminal nodes, HEAT-LDL performs cloud-edge knowledge distillation on the HEAT\nteacher model on the terminal node side. When the downlink decision instruction\nis lost, the terminal node uses the student model and the edge decider based on\nprior knowledge and local history to make collaborative autonomous decisions.\nSimulation experiments show that compared with the optimal results of all\ncompared algorithms, HEAT-LDL improves the packet success rate and energy\nefficiency by 20.5% and 88.1%, respectively.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13194v1",
    "published_date": "2025-04-13 10:34:37 UTC",
    "updated_date": "2025-04-13 10:34:37 UTC"
  },
  {
    "arxiv_id": "2504.13193v1",
    "title": "HEAT:History-Enhanced Dual-phase Actor-Critic Algorithm with A Shared Transformer",
    "authors": [
      "Hong Yang"
    ],
    "abstract": "For a single-gateway LoRaWAN network, this study proposed a history-enhanced\ntwo-phase actor-critic algorithm with a shared transformer algorithm (HEAT) to\nimprove network performance. HEAT considers uplink parameters and often\nneglected downlink parameters, and effectively integrates offline and online\nreinforcement learning, using historical data and real-time interaction to\nimprove model performance. In addition, this study developed an open source\nLoRaWAN network simulator LoRaWANSim. The simulator considers the demodulator\nlock effect and supports multi-channel, multi-demodulator and bidirectional\ncommunication. Simulation experiments show that compared with the best results\nof all compared algorithms, HEAT improves the packet success rate and energy\nefficiency by 15% and 95%, respectively.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13193v1",
    "published_date": "2025-04-13 10:32:02 UTC",
    "updated_date": "2025-04-13 10:32:02 UTC"
  },
  {
    "arxiv_id": "2504.09499v1",
    "title": "Decoding the mechanisms of the Hattrick football manager game using Bayesian network structure learning for optimal decision-making",
    "authors": [
      "Anthony C. Constantinou",
      "Nicholas Higgins",
      "Neville K. Kitson"
    ],
    "abstract": "Hattrick is a free web-based probabilistic football manager game with over\n200,000 users competing for titles at national and international levels.\nLaunched in Sweden in 1997 as part of an MSc project, the game's slow-paced\ndesign has fostered a loyal community, with many users remaining active for\ndecades. Hattrick's game-engine mechanics are partially hidden, and users have\nattempted to decode them with incremental success over the years. Rule-based,\nstatistical and machine learning models have been developed to aid this effort\nand are widely used by the community. However, these models or tools have not\nbeen formally described or evaluated in the scientific literature. This study\nis the first to explore Hattrick using structure learning techniques and\nBayesian networks, integrating both data and domain knowledge to develop models\ncapable of explaining and simulating the game engine. We present a\ncomprehensive analysis assessing the effectiveness of structure learning\nalgorithms in relation to knowledge-based structures, and show that while\nstructure learning may achieve a higher overall network fit, it does not result\nin more accurate predictions for selected variables of interest, when compared\nto knowledge-based networks that produce a lower overall network fit.\nAdditionally, we introduce and publicly share a fully specified Bayesian\nnetwork model that matches the performance of top models used by the Hattrick\ncommunity. We further demonstrate how analysis extends beyond prediction by\nproviding a visual representation of conditional dependencies, and using the\nbest performing Bayesian network model for in-game decision-making. To support\nfuture research, we make all data, graphical structures, and models publicly\navailable online.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09499v1",
    "published_date": "2025-04-13 09:50:20 UTC",
    "updated_date": "2025-04-13 09:50:20 UTC"
  },
  {
    "arxiv_id": "2504.09493v1",
    "title": "Federated Prototype Graph Learning",
    "authors": [
      "Zhengyu Wu",
      "Xunkai Li",
      "Yinlin Zhu",
      "Rong-Hua Li",
      "Guoren Wang",
      "Chenghu Zhou"
    ],
    "abstract": "In recent years, Federated Graph Learning (FGL) has gained significant\nattention for its distributed training capabilities in graph-based machine\nintelligence applications, mitigating data silos while offering a new\nperspective for privacy-preserve large-scale graph learning. However,\nmulti-level FGL heterogeneity presents various client-server collaboration\nchallenges: (1) Model-level: The variation in clients for expected performance\nand scalability necessitates the deployment of heterogeneous models.\nUnfortunately, most FGL methods rigidly demand identical client models due to\nthe direct model weight aggregation on the server. (2) Data-level: The\nintricate nature of graphs, marked by the entanglement of node profiles and\ntopology, poses an optimization dilemma. This implies that models obtained by\nfederated training struggle to achieve superior performance. (3)\nCommunication-level: Some FGL methods attempt to increase message sharing among\nclients or between clients and the server to improve training, which inevitably\nleads to high communication costs. In this paper, we propose FedPG as a general\nprototype-guided optimization method for the above multi-level FGL\nheterogeneity. Specifically, on the client side, we integrate multi-level\ntopology-aware prototypes to capture local graph semantics. Subsequently, on\nthe server side, leveraging the uploaded prototypes, we employ topology-guided\ncontrastive learning and personalized technology to tailor global prototypes\nfor each client, broadcasting them to improve local training. Experiments\ndemonstrate that FedPG outperforms SOTA baselines by an average of 3.57\\% in\naccuracy while reducing communication costs by 168x.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2504.09493v1",
    "published_date": "2025-04-13 09:21:21 UTC",
    "updated_date": "2025-04-13 09:21:21 UTC"
  },
  {
    "arxiv_id": "2504.10541v1",
    "title": "Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation",
    "authors": [
      "Xu Guo",
      "Tong Zhang",
      "Yuanzhi Wang",
      "Chenxu Wang",
      "Fuyun Wang",
      "Xudong Wang",
      "Xiaoya Zhang",
      "Xin Liu",
      "Zhen Cui"
    ],
    "abstract": "The burgeoning presence of Large Language Models (LLM) is propelling the\ndevelopment of personalized recommender systems. Most existing LLM-based\nmethods fail to sufficiently explore the multi-view graph structure\ncorrelations inherent in recommendation scenarios. To this end, we propose a\nnovel framework, Hypergraph Enhanced LLM Learning for multimodal Recommendation\n(HeLLM), designed to equip LLMs with the capability to capture intricate\nhigher-order semantic correlations by fusing graph-level contextual signals\nwith sequence-level behavioral patterns. In the recommender pre-training phase,\nwe design a user hypergraph to uncover shared interest preferences among users\nand an item hypergraph to capture correlations within multimodal similarities\namong items. The hypergraph convolution and synergistic contrastive learning\nmechanism are introduced to enhance the distinguishability of learned\nrepresentations. In the LLM fine-tuning phase, we inject the learned\ngraph-structured embeddings directly into the LLM's architecture and integrate\nsequential features capturing each user's chronological behavior. This process\nenables hypergraphs to leverage graph-structured information as global context,\nenhancing the LLM's ability to perceive complex relational patterns and\nintegrate multimodal information, while also modeling local temporal dynamics.\nExtensive experiments demonstrate the superiority of our proposed method over\nstate-of-the-art baselines, confirming the advantages of fusing\nhypergraph-based context with sequential user behavior in LLMs for\nrecommendation.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10541v1",
    "published_date": "2025-04-13 09:12:35 UTC",
    "updated_date": "2025-04-13 09:12:35 UTC"
  },
  {
    "arxiv_id": "2504.09482v1",
    "title": "HalluShift: Measuring Distribution Shifts towards Hallucination Detection in LLMs",
    "authors": [
      "Sharanya Dasgupta",
      "Sujoy Nath",
      "Arkaprabha Basu",
      "Pourya Shamsolmoali",
      "Swagatam Das"
    ],
    "abstract": "Large Language Models (LLMs) have recently garnered widespread attention due\nto their adeptness at generating innovative responses to the given prompts\nacross a multitude of domains. However, LLMs often suffer from the inherent\nlimitation of hallucinations and generate incorrect information while\nmaintaining well-structured and coherent responses. In this work, we\nhypothesize that hallucinations stem from the internal dynamics of LLMs. Our\nobservations indicate that, during passage generation, LLMs tend to deviate\nfrom factual accuracy in subtle parts of responses, eventually shifting toward\nmisinformation. This phenomenon bears a resemblance to human cognition, where\nindividuals may hallucinate while maintaining logical coherence, embedding\nuncertainty within minor segments of their speech. To investigate this further,\nwe introduce an innovative approach, HalluShift, designed to analyze the\ndistribution shifts in the internal state space and token probabilities of the\nLLM-generated responses. Our method attains superior performance compared to\nexisting baselines across various benchmark datasets. Our codebase is available\nat https://github.com/sharanya-dasgupta001/hallushift.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09482v1",
    "published_date": "2025-04-13 08:35:22 UTC",
    "updated_date": "2025-04-13 08:35:22 UTC"
  },
  {
    "arxiv_id": "2504.10540v1",
    "title": "AB-Cache: Training-Free Acceleration of Diffusion Models via Adams-Bashforth Cached Feature Reuse",
    "authors": [
      "Zichao Yu",
      "Zhen Zou",
      "Guojiang Shao",
      "Chengwei Zhang",
      "Shengze Xu",
      "Jie Huang",
      "Feng Zhao",
      "Xiaodong Cun",
      "Wenyi Zhang"
    ],
    "abstract": "Diffusion models have demonstrated remarkable success in generative tasks,\nyet their iterative denoising process results in slow inference, limiting their\npracticality. While existing acceleration methods exploit the well-known\nU-shaped similarity pattern between adjacent steps through caching mechanisms,\nthey lack theoretical foundation and rely on simplistic computation reuse,\noften leading to performance degradation. In this work, we provide a\ntheoretical understanding by analyzing the denoising process through the\nsecond-order Adams-Bashforth method, revealing a linear relationship between\nthe outputs of consecutive steps. This analysis explains why the outputs of\nadjacent steps exhibit a U-shaped pattern. Furthermore, extending\nAdams-Bashforth method to higher order, we propose a novel caching-based\nacceleration approach for diffusion models, instead of directly reusing cached\nresults, with a truncation error bound of only \\(O(h^k)\\) where $h$ is the step\nsize. Extensive validation across diverse image and video diffusion models\n(including HunyuanVideo and FLUX.1-dev) with various schedulers demonstrates\nour method's effectiveness in achieving nearly $3\\times$ speedup while\nmaintaining original performance levels, offering a practical real-time\nsolution without compromising generation quality.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10540v1",
    "published_date": "2025-04-13 08:29:58 UTC",
    "updated_date": "2025-04-13 08:29:58 UTC"
  },
  {
    "arxiv_id": "2504.10539v2",
    "title": "Physics-Informed Neural Networks for Enhanced Interface Preservation in Lattice Boltzmann Multiphase Simulations",
    "authors": [
      "Yue Li",
      "Lihong Zhang"
    ],
    "abstract": "This paper presents an improved approach for preserving sharp interfaces in\nmultiphase Lattice Boltzmann Method (LBM) simulations using Physics-Informed\nNeural Networks (PINNs). Interface diffusion is a common challenge in\nmultiphase LBM, leading to reduced accuracy in simulating phenomena where\ninterfacial dynamics are critical. We propose a coupled PINN-LBM framework that\nmaintains interface sharpness while preserving the physical accuracy of the\nsimulation. Our approach is validated through droplet simulations, with\nquantitative metrics measuring interface width, maximum gradient, phase\nseparation, effective interface width, and interface energy. The enhanced\nvisualization techniques employed in this work clearly demonstrate the superior\nperformance of PINN-LBM over standard LBM for multiphase simulations,\nparticularly in maintaining well-defined interfaces throughout the simulation.\nWe provide a comprehensive analysis of the results, showcasing how the neural\nnetwork integration effectively counteracts numerical diffusion, while\nmaintaining physical consistency with the underlying fluid dynamics.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10539v2",
    "published_date": "2025-04-13 08:29:00 UTC",
    "updated_date": "2025-04-18 20:52:58 UTC"
  },
  {
    "arxiv_id": "2504.09480v1",
    "title": "Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation",
    "authors": [
      "Yongchao Feng",
      "Yajie Liu",
      "Shuai Yang",
      "Wenrui Cai",
      "Jinqing Zhang",
      "Qiqi Zhan",
      "Ziyue Huang",
      "Hongxi Yan",
      "Qiao Wan",
      "Chenguang Liu",
      "Junzhe Wang",
      "Jiahui Lv",
      "Ziqi Liu",
      "Tengyuan Shi",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "abstract": "Vision-Language Model (VLM) have gained widespread adoption in\nOpen-Vocabulary (OV) object detection and segmentation tasks. Despite they have\nshown promise on OV-related tasks, their effectiveness in conventional vision\ntasks has thus far been unevaluated. In this work, we present the systematic\nreview of VLM-based detection and segmentation, view VLM as the foundational\nmodel and conduct comprehensive evaluations across multiple downstream tasks\nfor the first time: 1) The evaluation spans eight detection scenarios\n(closed-set detection, domain adaptation, crowded objects, etc.) and eight\nsegmentation scenarios (few-shot, open-world, small object, etc.), revealing\ndistinct performance advantages and limitations of various VLM architectures\nacross tasks. 2) As for detection tasks, we evaluate VLMs under three\nfinetuning granularities: \\textit{zero prediction}, \\textit{visual\nfine-tuning}, and \\textit{text prompt}, and further analyze how different\nfinetuning strategies impact performance under varied task. 3) Based on\nempirical findings, we provide in-depth analysis of the correlations between\ntask characteristics, model architectures, and training methodologies, offering\ninsights for future VLM design. 4) We believe that this work shall be valuable\nto the pattern recognition experts working in the fields of computer vision,\nmultimodal learning, and vision foundation models by introducing them to the\nproblem, and familiarizing them with the current status of the progress while\nproviding promising directions for future research. A project associated with\nthis review and evaluation has been created at\nhttps://github.com/better-chao/perceptual_abilities_evaluation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "A Review and Evaluation about Vision-Language Model for Object\n  Detection and Segmentation",
    "pdf_url": "http://arxiv.org/pdf/2504.09480v1",
    "published_date": "2025-04-13 08:28:13 UTC",
    "updated_date": "2025-04-13 08:28:13 UTC"
  },
  {
    "arxiv_id": "2504.09479v1",
    "title": "Draw with Thought: Unleashing Multimodal Reasoning for Scientific Diagram Generation",
    "authors": [
      "Zhiqing Cui",
      "Jiahao Yuan",
      "Hanqing Wang",
      "Yanshu Li",
      "Chenxu Du",
      "Zhenglong Ding"
    ],
    "abstract": "Scientific diagrams are vital tools for communicating structured knowledge\nacross disciplines. However, they are often published as static raster images,\nlosing symbolic semantics and limiting reuse. While Multimodal Large Language\nModels (MLLMs) offer a pathway to bridging vision and structure, existing\nmethods lack semantic control and structural interpretability, especially on\ncomplex diagrams. We propose Draw with Thought (DwT), a training-free framework\nthat guides MLLMs to reconstruct diagrams into editable mxGraph XML code\nthrough cognitively-grounded Chain-of-Thought reasoning. DwT enables\ninterpretable and controllable outputs without model fine-tuning by dividing\nthe task into two stages: Coarse-to-Fine Planning, which handles perceptual\nstructuring and semantic specification, and Structure-Aware Code Generation,\nenhanced by format-guided refinement. To support evaluation, we release\nPlot2XML, a benchmark of 247 real-world scientific diagrams with gold-standard\nXML annotations. Extensive experiments across eight MLLMs show that our\napproach yields high-fidelity, semantically aligned, and structurally valid\nreconstructions, with human evaluations confirming strong alignment in both\naccuracy and visual aesthetics, offering a scalable solution for converting\nstatic visuals into executable representations and advancing machine\nunderstanding of scientific graphics.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.09479v1",
    "published_date": "2025-04-13 08:22:09 UTC",
    "updated_date": "2025-04-13 08:22:09 UTC"
  },
  {
    "arxiv_id": "2504.09478v1",
    "title": "A highly maneuverable flying squirrel drone with controllable foldable wings",
    "authors": [
      "Jun-Gill Kang",
      "Dohyeon Lee",
      "Soohee Han"
    ],
    "abstract": "Typical drones with multi rotors are generally less maneuverable due to\nunidirectional thrust, which may be unfavorable to agile flight in very narrow\nand confined spaces. This paper suggests a new bio-inspired drone that is\nempowered with high maneuverability in a lightweight and easy-to-carry way. The\nproposed flying squirrel inspired drone has controllable foldable wings to\ncover a wider range of flight attitudes and provide more maneuverable flight\ncapability with stable tracking performance. The wings of a drone are\nfabricated with silicone membranes and sophisticatedly controlled by\nreinforcement learning based on human-demonstrated data. Specially, such\nlearning based wing control serves to capture even the complex aerodynamics\nthat are often impossible to model mathematically. It is shown through\nexperiment that the proposed flying squirrel drone intentionally induces\naerodynamic drag and hence provides the desired additional repulsive force even\nunder saturated mechanical thrust. This work is very meaningful in\ndemonstrating the potential of biomimicry and machine learning for realizing an\nanimal-like agile drone.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at 2023 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS), Project Page :\n  https://jgkang1210.github.io/fsdrone/ , Video :\n  https://youtu.be/Cfc-llDb3_k?si=Cal5beZw6f3HZ2ZW , Jun-Gill Kang and Dohyeon\n  Lee are co-authors",
    "pdf_url": "http://arxiv.org/pdf/2504.09478v1",
    "published_date": "2025-04-13 08:15:28 UTC",
    "updated_date": "2025-04-13 08:15:28 UTC"
  },
  {
    "arxiv_id": "2504.09474v1",
    "title": "MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions",
    "authors": [
      "Pucheng Dang",
      "Di Huang",
      "Dong Li",
      "Kang Chen",
      "Yuanbo Wen",
      "Qi Guo",
      "Xing Hu",
      "Ninghui Sun"
    ],
    "abstract": "Out-of-tree kernel patches are essential for adapting the Linux kernel to new\nhardware or enabling specific functionalities. Maintaining and updating these\npatches across different kernel versions demands significant effort from\nexperienced engineers. Large language models (LLMs) have shown remarkable\nprogress across various domains, suggesting their potential for automating\nout-of-tree kernel patch migration. However, our findings reveal that LLMs,\nwhile promising, struggle with incomplete code context understanding and\ninaccurate migration point identification. In this work, we propose MigGPT, a\nframework that employs a novel code fingerprint structure to retain code\nsnippet information and incorporates three meticulously designed modules to\nimprove the migration accuracy and efficiency of out-of-tree kernel patches.\nFurthermore, we establish a robust benchmark using real-world out-of-tree\nkernel patch projects to evaluate LLM capabilities. Evaluations show that\nMigGPT significantly outperforms the direct application of vanilla LLMs,\nachieving an average completion rate of 72.59% (50.74% improvement) for\nmigration tasks.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.OS"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09474v1",
    "published_date": "2025-04-13 08:08:37 UTC",
    "updated_date": "2025-04-13 08:08:37 UTC"
  },
  {
    "arxiv_id": "2504.10538v1",
    "title": "Distilling Transitional Pattern to Large Language Models for Multimodal Session-based Recommendation",
    "authors": [
      "Jiajie Su",
      "Qiyong Zhong",
      "Yunshan Ma",
      "Weiming Liu",
      "Chaochao Chen",
      "Xiaolin Zheng",
      "Jianwei Yin",
      "Tat-Seng Chua"
    ],
    "abstract": "Session-based recommendation (SBR) predicts the next item based on anonymous\nsessions. Traditional SBR explores user intents based on ID collaborations or\nauxiliary content. To further alleviate data sparsity and cold-start issues,\nrecent Multimodal SBR (MSBR) methods utilize simplistic pre-trained models for\nmodality learning but have limitations in semantic richness. Considering\nsemantic reasoning abilities of Large Language Models (LLM), we focus on the\nLLM-enhanced MSBR scenario in this paper, which leverages LLM cognition for\ncomprehensive multimodal representation generation, to enhance downstream MSBR.\nTackling this problem faces two challenges: i) how to obtain LLM cognition on\nboth transitional patterns and inherent multimodal knowledge, ii) how to align\nboth features into one unified LLM, minimize discrepancy while maximizing\nrepresentation utility. To this end, we propose a multimodal LLM-enhanced\nframework TPAD, which extends a distillation paradigm to decouple and align\ntransitional patterns for promoting MSBR. TPAD establishes parallel\nKnowledge-MLLM and Transfer-MLLM, where the former interprets item\nknowledge-reflected features and the latter extracts transition-aware features\nunderneath sessions. A transitional pattern alignment module harnessing mutual\ninformation estimation theory unites two MLLMs, alleviating distribution\ndiscrepancy and distilling transitional patterns into modal representations.\nExtensive experiments on real-world datasets demonstrate the effectiveness of\nour framework.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10538v1",
    "published_date": "2025-04-13 07:49:08 UTC",
    "updated_date": "2025-04-13 07:49:08 UTC"
  },
  {
    "arxiv_id": "2504.12331v1",
    "title": "Span-level Emotion-Cause-Category Triplet Extraction with Instruction Tuning LLMs and Data Augmentation",
    "authors": [
      "Xiangju Li",
      "Dong Yang",
      "Xiaogang Zhu",
      "Faliang Huang",
      "Peng Zhang",
      "Zhongying Zhao"
    ],
    "abstract": "Span-level emotion-cause-category triplet extraction represents a novel and\ncomplex challenge within emotion cause analysis. This task involves identifying\nemotion spans, cause spans, and their associated emotion categories within the\ntext to form structured triplets. While prior research has predominantly\nconcentrated on clause-level emotion-cause pair extraction and span-level\nemotion-cause detection, these methods often confront challenges originating\nfrom redundant information retrieval and difficulty in accurately determining\nemotion categories, particularly when emotions are expressed implicitly or\nambiguously. To overcome these challenges, this study explores a fine-grained\napproach to span-level emotion-cause-category triplet extraction and introduces\nan innovative framework that leverages instruction tuning and data augmentation\ntechniques based on large language models. The proposed method employs\ntask-specific triplet extraction instructions and utilizes low-rank adaptation\nto fine-tune large language models, eliminating the necessity for intricate\ntask-specific architectures. Furthermore, a prompt-based data augmentation\nstrategy is developed to address data scarcity by guiding large language models\nin generating high-quality synthetic training data. Extensive experimental\nevaluations demonstrate that the proposed approach significantly outperforms\nexisting baseline methods, achieving at least a 12.8% improvement in span-level\nemotion-cause-category triplet extraction metrics. The results demonstrate the\nmethod's effectiveness and robustness, offering a promising avenue for\nadvancing research in emotion cause analysis. The source code is available at\nhttps://github.com/zxgnlp/InstruDa-LLM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12331v1",
    "published_date": "2025-04-13 07:31:09 UTC",
    "updated_date": "2025-04-13 07:31:09 UTC"
  },
  {
    "arxiv_id": "2504.09463v1",
    "title": "Comorbidity-Informed Transfer Learning for Neuro-developmental Disorder Diagnosis",
    "authors": [
      "Xin Wen",
      "Shijie Guo",
      "Wenbo Ning",
      "Rui Cao",
      "Jie Xiang",
      "Xiaobo Liu",
      "Jintai Chen"
    ],
    "abstract": "Neuro-developmental disorders are manifested as dysfunctions in cognition,\ncommunication, behaviour and adaptability, and deep learning-based\ncomputer-aided diagnosis (CAD) can alleviate the increasingly strained\nhealthcare resources on neuroimaging. However, neuroimaging such as fMRI\ncontains complex spatio-temporal features, which makes the corresponding\nrepresentations susceptible to a variety of distractions, thus leading to less\neffective in CAD. For the first time, we present a Comorbidity-Informed\nTransfer Learning(CITL) framework for diagnosing neuro-developmental disorders\nusing fMRI. In CITL, a new reinforced representation generation network is\nproposed, which first combines transfer learning with pseudo-labelling to\nremove interfering patterns from the temporal domain of fMRI and generates new\nrepresentations using encoder-decoder architecture. The new representations are\nthen trained in an architecturally simple classification network to obtain CAD\nmodel. In particular, the framework fully considers the comorbidity mechanisms\nof neuro-developmental disorders and effectively integrates them with\nsemi-supervised learning and transfer learning, providing new perspectives on\ninterdisciplinary. Experimental results demonstrate that CITL achieves\ncompetitive accuracies of 76.32% and 73.15% for detecting autism spectrum\ndisorder and attention deficit hyperactivity disorder, respectively, which\noutperforms existing related transfer learning work for 7.2% and 0.5%\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09463v1",
    "published_date": "2025-04-13 07:30:55 UTC",
    "updated_date": "2025-04-13 07:30:55 UTC"
  },
  {
    "arxiv_id": "2504.10536v1",
    "title": "Federated Learning with Layer Skipping: Efficient Training of Large Language Models for Healthcare NLP",
    "authors": [
      "Lihong Zhang",
      "Yue Li"
    ],
    "abstract": "Federated learning (FL) enables collaborative model training across\norganizations without sharing raw data, addressing crucial privacy concerns in\nhealthcare natural language processing (NLP). However, training large language\nmodels (LLMs) in federated settings faces significant challenges, including\ncommunication overhead and data heterogeneity. We propose Layer-Skipping\nFederated Learning, where only selected layers of a pre-trained LLM are\nfine-tuned across clients while others remain frozen. Applied to LLaMA 3.2-1B,\nour approach reduces communication costs by approximately 70% while maintaining\nperformance within 2% of centralized training. We evaluate our method on\nclinical NER and classification tasks using i2b2 and MIMIC-III datasets. Our\nexperiments demonstrate that Layer-Skipping FL outperforms competitive\nbaselines, handles non-IID clinical data distributions effectively, and shows\nrobustness when combined with differential privacy. This approach represents a\npractical solution for privacy-preserving collaborative learning in healthcare\nNLP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10536v1",
    "published_date": "2025-04-13 07:27:56 UTC",
    "updated_date": "2025-04-13 07:27:56 UTC"
  },
  {
    "arxiv_id": "2504.09459v1",
    "title": "Measuring Leakage in Concept-Based Methods: An Information Theoretic Approach",
    "authors": [
      "Mikael Makonnen",
      "Moritz Vandenhirtz",
      "Sonia Laguna",
      "Julia E Vogt"
    ],
    "abstract": "Concept Bottleneck Models (CBMs) aim to enhance interpretability by\nstructuring predictions around human-understandable concepts. However,\nunintended information leakage, where predictive signals bypass the concept\nbottleneck, compromises their transparency. This paper introduces an\ninformation-theoretic measure to quantify leakage in CBMs, capturing the extent\nto which concept embeddings encode additional, unintended information beyond\nthe specified concepts. We validate the measure through controlled synthetic\nexperiments, demonstrating its effectiveness in detecting leakage trends across\nvarious configurations. Our findings highlight that feature and concept\ndimensionality significantly influence leakage, and that classifier choice\nimpacts measurement stability, with XGBoost emerging as the most reliable\nestimator. Additionally, preliminary investigations indicate that the measure\nexhibits the anticipated behavior when applied to soft joint CBMs, suggesting\nits reliability in leakage quantification beyond fully synthetic settings.\nWhile this study rigorously evaluates the measure in controlled synthetic\nexperiments, future work can extend its application to real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR 2025 Workshop on XAI4Science",
    "pdf_url": "http://arxiv.org/pdf/2504.09459v1",
    "published_date": "2025-04-13 07:09:55 UTC",
    "updated_date": "2025-04-13 07:09:55 UTC"
  },
  {
    "arxiv_id": "2504.12330v1",
    "title": "HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation",
    "authors": [
      "Pei Liu",
      "Xin Liu",
      "Ruoyu Yao",
      "Junming Liu",
      "Siyuan Meng",
      "Ding Wang",
      "Jun Ma"
    ],
    "abstract": "While Retrieval-Augmented Generation (RAG) augments Large Language Models\n(LLMs) with external knowledge, conventional single-agent RAG remains\nfundamentally limited in resolving complex queries demanding coordinated\nreasoning across heterogeneous data ecosystems. We present HM-RAG, a novel\nHierarchical Multi-agent Multimodal RAG framework that pioneers collaborative\nintelligence for dynamic knowledge synthesis across structured, unstructured,\nand graph-based data. The framework is composed of three-tiered architecture\nwith specialized agents: a Decomposition Agent that dissects complex queries\ninto contextually coherent sub-tasks via semantic-aware query rewriting and\nschema-guided context augmentation; Multi-source Retrieval Agents that carry\nout parallel, modality-specific retrieval using plug-and-play modules designed\nfor vector, graph, and web-based databases; and a Decision Agent that uses\nconsistency voting to integrate multi-source answers and resolve discrepancies\nin retrieval results through Expert Model Refinement. This architecture attains\ncomprehensive query understanding by combining textual, graph-relational, and\nweb-derived evidence, resulting in a remarkable 12.95% improvement in answer\naccuracy and a 3.56% boost in question classification accuracy over baseline\nRAG systems on the ScienceQA and CrisisMMD benchmarks. Notably, HM-RAG\nestablishes state-of-the-art results in zero-shot settings on both datasets.\nIts modular architecture ensures seamless integration of new data modalities\nwhile maintaining strict data governance, marking a significant advancement in\naddressing the critical challenges of multimodal reasoning and knowledge\nsynthesis in RAG systems. Code is available at\nhttps://github.com/ocean-luna/HMRAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12330v1",
    "published_date": "2025-04-13 06:55:33 UTC",
    "updated_date": "2025-04-13 06:55:33 UTC"
  },
  {
    "arxiv_id": "2504.09456v1",
    "title": "Don't Deceive Me: Mitigating Gaslighting through Attention Reallocation in LMMs",
    "authors": [
      "Pengkun Jiao",
      "Bin Zhu",
      "Jingjing Chen",
      "Chong-Wah Ngo",
      "Yu-Gang Jiang"
    ],
    "abstract": "Large Multimodal Models (LMMs) have demonstrated remarkable capabilities\nacross a wide range of tasks. However, their vulnerability to user\ngaslighting-the deliberate use of misleading or contradictory inputs-raises\ncritical concerns about their reliability in real-world applications. In this\npaper, we address the novel and challenging issue of mitigating the negative\nimpact of negation-based gaslighting on LMMs, where deceptive user statements\nlead to significant drops in model accuracy. Specifically, we introduce\nGasEraser, a training-free approach that reallocates attention weights from\nmisleading textual tokens to semantically salient visual regions. By\nsuppressing the influence of \"attention sink\" tokens and enhancing focus on\nvisually grounded cues, GasEraser significantly improves LMM robustness without\nrequiring retraining or additional supervision. Extensive experimental results\ndemonstrate that GasEraser is effective across several leading open-source LMMs\non the GaslightingBench. Notably, for LLaVA-v1.5-7B, GasEraser reduces the\nmisguidance rate by 48.2%, demonstrating its potential for more trustworthy\nLMMs.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09456v1",
    "published_date": "2025-04-13 06:47:32 UTC",
    "updated_date": "2025-04-13 06:47:32 UTC"
  },
  {
    "arxiv_id": "2504.09440v2",
    "title": "Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection",
    "authors": [
      "MingShan Liu",
      "Shi Bo",
      "Jialing Fang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong mathematical reasoning\ncapabilities but remain susceptible to hallucinations producing plausible yet\nincorrect statements especially in theorem proving, symbolic manipulation, and\nnumerical computation. While self-consistency (SC) has been explored as a means\nto improve factuality in LLMs, existing approaches primarily apply SC to\nfinal-answer selection, neglecting the logical consistency of intermediate\nreasoning steps. In this work, we introduce a structured self-consistency\nframework designed to enhance the reliability of mathematical reasoning. Our\nmethod enforces self-consistency across intermediate steps and final outputs,\nreducing logical inconsistencies and hallucinations. We evaluate our approach\nacross three core mathematical tasks: theorem proving, symbolic transformation,\nand numerical computation. Experimental results demonstrate that SC\nsignificantly improves proof validity, symbolic reasoning accuracy, and\nnumerical stability while maintaining computational efficiency. Further\nanalysis reveals that structured self-consistency not only enhances\nproblem-solving accuracy but also reduces the variance of model-generated\noutputs. These findings highlight self-consistency as a robust mechanism for\nimproving mathematical reasoning in LLMs, paving the way for more reliable and\ninterpretable AI-driven mathematics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09440v2",
    "published_date": "2025-04-13 05:47:52 UTC",
    "updated_date": "2025-05-20 20:36:50 UTC"
  },
  {
    "arxiv_id": "2504.13192v2",
    "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent",
    "authors": [
      "Liang-bo Ning",
      "Shijie Wang",
      "Wenqi Fan",
      "Qing Li",
      "Xin Xu",
      "Hao Chen",
      "Feiran Huang"
    ],
    "abstract": "Recently, Large Language Model (LLM)-empowered recommender systems (RecSys)\nhave brought significant advances in personalized user experience and have\nattracted considerable attention. Despite the impressive progress, the research\nquestion regarding the safety vulnerability of LLM-empowered RecSys still\nremains largely under-investigated. Given the security and privacy concerns, it\nis more practical to focus on attacking the black-box RecSys, where attackers\ncan only observe the system's inputs and outputs. However, traditional attack\napproaches employing reinforcement learning (RL) agents are not effective for\nattacking LLM-empowered RecSys due to the limited capabilities in processing\ncomplex textual inputs, planning, and reasoning. On the other hand, LLMs\nprovide unprecedented opportunities to serve as attack agents to attack RecSys\nbecause of their impressive capability in simulating human-like decision-making\nprocesses. Therefore, in this paper, we propose a novel attack framework called\nCheatAgent by harnessing the human-like capabilities of LLMs, where an\nLLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our\nmethod first identifies the insertion position for maximum impact with minimal\ninput modification. After that, the LLM agent is designed to generate\nadversarial perturbations to insert at target positions. To further improve the\nquality of generated perturbations, we utilize the prompt tuning technique to\nimprove attacking strategies via feedback from the victim RecSys iteratively.\nExtensive experiments across three real-world datasets demonstrate the\neffectiveness of our proposed attacking method.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by KDD 2024;",
    "pdf_url": "http://arxiv.org/pdf/2504.13192v2",
    "published_date": "2025-04-13 05:31:37 UTC",
    "updated_date": "2025-04-24 02:16:04 UTC"
  },
  {
    "arxiv_id": "2504.09428v3",
    "title": "FROG: Effective Friend Recommendation in Online Games via Modality-aware User Preferences",
    "authors": [
      "Qiwei Wang",
      "Dandan Lin",
      "Wenqing Lin",
      "Ziming Wu"
    ],
    "abstract": "Due to the convenience of mobile devices, the online games have become an\nimportant part for user entertainments in reality, creating a demand for friend\nrecommendation in online games. However, none of existing approaches can\neffectively incorporate the multi-modal user features (e.g., images and texts)\nwith the structural information in the friendship graph, due to the following\nlimitations: (1) some of them ignore the high-order structural proximity\nbetween users, (2) some fail to learn the pairwise relevance between users at\nmodality-specific level, and (3) some cannot capture both the local and global\nuser preferences on different modalities. By addressing these issues, in this\npaper, we propose an end-to-end model FROG that better models the user\npreferences on potential friends. Comprehensive experiments on both offline\nevaluation and online deployment at Tencent have demonstrated the superiority\nof FROG over existing approaches.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted in SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.09428v3",
    "published_date": "2025-04-13 04:27:10 UTC",
    "updated_date": "2025-04-26 14:35:22 UTC"
  },
  {
    "arxiv_id": "2504.09426v1",
    "title": "BabyVLM: Data-Efficient Pretraining of VLMs Inspired by Infant Learning",
    "authors": [
      "Shengao Wang",
      "Arjun Chandra",
      "Aoming Liu",
      "Venkatesh Saligrama",
      "Boqing Gong"
    ],
    "abstract": "Human infants rapidly develop visual reasoning skills from minimal input,\nsuggesting that developmentally inspired pretraining could significantly\nenhance the efficiency of vision-language models (VLMs). Although recent\nefforts have leveraged infant-inspired datasets like SAYCam, existing\nevaluation benchmarks remain misaligned--they are either too simplistic,\nnarrowly scoped, or tailored for large-scale pretrained models. Additionally,\ntraining exclusively on infant data overlooks the broader, diverse input from\nwhich infants naturally learn. To address these limitations, we propose\nBabyVLM, a novel framework comprising comprehensive in-domain evaluation\nbenchmarks and a synthetic training dataset created via child-directed\ntransformations of existing datasets. We demonstrate that VLMs trained with our\nsynthetic dataset achieve superior performance on BabyVLM tasks compared to\nmodels trained solely on SAYCam or general-purpose data of the SAYCam size.\nBabyVLM thus provides a robust, developmentally aligned evaluation tool and\nillustrates how compact models trained on carefully curated data can generalize\neffectively, opening pathways toward data-efficient vision-language learning\nparadigms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09426v1",
    "published_date": "2025-04-13 04:17:12 UTC",
    "updated_date": "2025-04-13 04:17:12 UTC"
  },
  {
    "arxiv_id": "2504.09421v2",
    "title": "ClinicalGPT-R1: Pushing reasoning capability of generalist disease diagnosis with large language model",
    "authors": [
      "Wuyang Lan",
      "Wenzheng Wang",
      "Changwei Ji",
      "Guoxing Yang",
      "Yongbo Zhang",
      "Xiaohong Liu",
      "Song Wu",
      "Guangyu Wang"
    ],
    "abstract": "Recent advances in reasoning with large language models (LLMs)has shown\nremarkable reasoning capabilities in domains such as mathematics and coding,\nyet their application to clinical diagnosis remains underexplored. Here, we\nintroduce ClinicalGPT-R1, a reasoning enhanced generalist large language model\nfor disease diagnosis. Trained on a dataset of 20,000 real-world clinical\nrecords, ClinicalGPT-R1 leverages diverse training strategies to enhance\ndiagnostic reasoning. To benchmark performance, we curated MedBench-Hard, a\nchallenging dataset spanning seven major medical specialties and representative\ndiseases. Experimental results demonstrate that ClinicalGPT-R1 outperforms\nGPT-4o in Chinese diagnostic tasks and achieves comparable performance to GPT-4\nin English settings. This comparative study effectively validates the superior\nperformance of ClinicalGPT-R1 in disease diagnosis tasks. Resources are\navailable at https://github.com/medfound/medfound.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.09421v2",
    "published_date": "2025-04-13 04:00:40 UTC",
    "updated_date": "2025-04-15 07:52:40 UTC"
  },
  {
    "arxiv_id": "2504.09402v1",
    "title": "Question Tokens Deserve More Attention: Enhancing Large Language Models without Training through Step-by-Step Reading and Question Attention Recalibration",
    "authors": [
      "Feijiang Han",
      "Licheng Guo",
      "Hengtao Cui",
      "Zhiyuan Lyu"
    ],
    "abstract": "Large Language Models (LLMs) often struggle with tasks that require a deep\nunderstanding of complex questions, especially when faced with long-range\ndependencies or multi-step reasoning. This work investigates the limitations of\ncurrent LLMs in question comprehension and identifies three insights: (1)\nrepeating question tokens improves comprehension by increasing attention to\nquestion regions, (2) increased backward dependencies negatively affect\nperformance due to unidirectional attentional constraints, and (3)\nrecalibrating attentional mechanisms to prioritize question-relevant regions\nimproves performance.\n  Based on these findings, we first propose a family of prompt-based strategies\n- Step-by-Step Reading (SSR), SSR+, and SSR++ - that guide LLMs to\nincrementally process question tokens and align their reasoning with the input\nstructure. These methods significantly improve performance, with SSR++\nachieving state-of-the-art results on several benchmarks: 96.66% on GSM8K,\n94.61% on ASDiv, and 76.28% on AQuA. Second, we introduce a training-free\nattention recalibration mechanism that dynamically adjusts attention\ndistributions during inference to emphasize question-relevant regions. This\nmethod improves the accuracy of LLaMA 3.1-8B on AQuA by 5.17% without changing\nmodel parameters or input prompts.\n  Taken together, our results highlight the importance of structured prompt\ndesign and attention optimization in improving LLM comprehension, providing\nlightweight yet effective tools for improving performance in various NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "CIS 5300",
    "pdf_url": "http://arxiv.org/pdf/2504.09402v1",
    "published_date": "2025-04-13 02:10:18 UTC",
    "updated_date": "2025-04-13 02:10:18 UTC"
  },
  {
    "arxiv_id": "2504.09398v1",
    "title": "Composable NLP Workflows for BERT-based Ranking and QA System",
    "authors": [
      "Gaurav Kumar",
      "Murali Mohana Krishna Dandu"
    ],
    "abstract": "There has been a lot of progress towards building NLP models that scale to\nmultiple tasks. However, real-world systems contain multiple components and it\nis tedious to handle cross-task interaction with varying levels of text\ngranularity. In this work, we built an end-to-end Ranking and\nQuestion-Answering (QA) system using Forte, a toolkit that makes composable NLP\npipelines. We utilized state-of-the-art deep learning models such as BERT,\nRoBERTa in our pipeline, evaluated the performance on MS-MARCO and Covid-19\ndatasets using metrics such as BLUE, MRR, F1 and compared the results of\nranking and QA systems with their corresponding benchmark results. The modular\nnature of our pipeline and low latency of reranker makes it easy to build\ncomplex NLP applications easily.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 3 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.09398v1",
    "published_date": "2025-04-13 01:48:13 UTC",
    "updated_date": "2025-04-13 01:48:13 UTC"
  },
  {
    "arxiv_id": "2504.09396v1",
    "title": "Adaptive Insurance Reserving with CVaR-Constrained Reinforcement Learning under Macroeconomic Regimes",
    "authors": [
      "Stella C. Dong",
      "James R. Finlay"
    ],
    "abstract": "This paper proposes a reinforcement learning (RL) framework for insurance\nreserving that integrates tail-risk sensitivity, macroeconomic regime modeling,\nand regulatory compliance. The reserving problem is formulated as a\nfinite-horizon Markov Decision Process (MDP), in which reserve adjustments are\noptimized using Proximal Policy Optimization (PPO) subject to Conditional\nValue-at-Risk (CVaR) constraints. To enhance policy robustness across varying\neconomic conditions, the agent is trained using a regime-aware curriculum that\nprogressively increases volatility exposure.\n  The reward structure penalizes reserve shortfall, capital inefficiency, and\nsolvency floor violations, with design elements informed by Solvency II and Own\nRisk and Solvency Assessment (ORSA) frameworks. Empirical evaluations on two\nindustry datasets--Workers' Compensation, and Other Liability--demonstrate that\nthe RL-CVaR agent achieves superior performance relative to classical reserving\nmethods across multiple criteria, including tail-risk control (CVaR$_{0.95}$),\ncapital efficiency, and regulatory violation rate. The framework also\naccommodates fixed-shock stress testing and regime-stratified analysis,\nproviding a principled and extensible approach to reserving under uncertainty.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09396v1",
    "published_date": "2025-04-13 01:43:25 UTC",
    "updated_date": "2025-04-13 01:43:25 UTC"
  },
  {
    "arxiv_id": "2504.16097v1",
    "title": "A CNN-based Local-Global Self-Attention via Averaged Window Embeddings for Hierarchical ECG Analysis",
    "authors": [
      "Arthur Buzelin",
      "Pedro Robles Dutenhefner",
      "Turi Rezende",
      "Luisa G. Porfirio",
      "Pedro Bento",
      "Yan Aquino",
      "Jose Fernandes",
      "Caio Santana",
      "Gabriela Miana",
      "Gisele L. Pappa",
      "Antonio Ribeiro",
      "Wagner Meira Jr"
    ],
    "abstract": "Cardiovascular diseases remain the leading cause of global mortality,\nemphasizing the critical need for efficient diagnostic tools such as\nelectrocardiograms (ECGs). Recent advancements in deep learning, particularly\ntransformers, have revolutionized ECG analysis by capturing detailed waveform\nfeatures as well as global rhythm patterns. However, traditional transformers\nstruggle to effectively capture local morphological features that are critical\nfor accurate ECG interpretation. We propose a novel Local-Global Attention ECG\nmodel (LGA-ECG) to address this limitation, integrating convolutional inductive\nbiases with global self-attention mechanisms. Our approach extracts queries by\naveraging embeddings obtained from overlapping convolutional windows, enabling\nfine-grained morphological analysis, while simultaneously modeling global\ncontext through attention to keys and values derived from the entire sequence.\nExperiments conducted on the CODE-15 dataset demonstrate that LGA-ECG\noutperforms state-of-the-art models and ablation studies validate the\neffectiveness of the local-global attention strategy. By capturing the\nhierarchical temporal dependencies and morphological patterns in ECG signals,\nthis new design showcases its potential for clinical deployment with robust\nautomated ECG classification.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16097v1",
    "published_date": "2025-04-13 01:21:18 UTC",
    "updated_date": "2025-04-13 01:21:18 UTC"
  }
]