[
  {
    "arxiv_id": "2503.05050v2",
    "title": "A Unified Framework with Novel Metrics for Evaluating the Effectiveness of XAI Techniques in LLMs",
    "authors": [
      "Melkamu Abay Mersha",
      "Mesay Gemeda Yigezu",
      "Hassan Shakil",
      "Ali K. AlShami",
      "Sanghyun Byun",
      "Jugal Kalita"
    ],
    "abstract": "The increasing complexity of LLMs presents significant challenges to their\ntransparency and interpretability, necessitating the use of eXplainable AI\n(XAI) techniques to enhance trustworthiness and usability. This study\nintroduces a comprehensive evaluation framework with four novel metrics for\nassessing the effectiveness of five XAI techniques across five LLMs and two\ndownstream tasks. We apply this framework to evaluate several XAI techniques\nLIME, SHAP, Integrated Gradients, Layer-wise Relevance Propagation (LRP), and\nAttention Mechanism Visualization (AMV) using the IMDB Movie Reviews and Tweet\nSentiment Extraction datasets. The evaluation focuses on four key metrics:\nHuman-reasoning Agreement (HA), Robustness, Consistency, and Contrastivity. Our\nresults show that LIME consistently achieves high scores across multiple LLMs\nand evaluation metrics, while AMV demonstrates superior Robustness and\nnear-perfect Consistency. LRP excels in Contrastivity, particularly with more\ncomplex models. Our findings provide valuable insights into the strengths and\nlimitations of different XAI methods, offering guidance for developing and\nselecting appropriate XAI techniques for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2501.15374",
    "pdf_url": "http://arxiv.org/pdf/2503.05050v2",
    "published_date": "2025-03-06 23:59:50 UTC",
    "updated_date": "2025-04-07 20:37:11 UTC"
  },
  {
    "arxiv_id": "2503.05042v1",
    "title": "Provably Correct Automata Embeddings for Optimal Automata-Conditioned Reinforcement Learning",
    "authors": [
      "Beyazit Yalcinkaya",
      "Niklas Lauffer",
      "Marcell Vazquez-Chanlatte",
      "Sanjit A. Seshia"
    ],
    "abstract": "Automata-conditioned reinforcement learning (RL) has given promising results\nfor learning multi-task policies capable of performing temporally extended\nobjectives given at runtime, done by pretraining and freezing automata\nembeddings prior to training the downstream policy. However, no theoretical\nguarantees were given. This work provides a theoretical framework for the\nautomata-conditioned RL problem and shows that it is probably approximately\ncorrect learnable. We then present a technique for learning provably correct\nautomata embeddings, guaranteeing optimal multi-task policy learning. Our\nexperimental evaluation confirms these theoretical results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.FL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05042v1",
    "published_date": "2025-03-06 23:37:05 UTC",
    "updated_date": "2025-03-06 23:37:05 UTC"
  },
  {
    "arxiv_id": "2503.05031v1",
    "title": "Enhancing Alzheimer's Diagnosis: Leveraging Anatomical Landmarks in Graph Convolutional Neural Networks on Tetrahedral Meshes",
    "authors": [
      "Yanxi Chen",
      "Mohammad Farazi",
      "Zhangsihao Yang",
      "Yonghui Fan",
      "Nicholas Ashton",
      "Eric M Reiman",
      "Yi Su",
      "Yalin Wang"
    ],
    "abstract": "Alzheimer's disease (AD) is a major neurodegenerative condition that affects\nmillions around the world. As one of the main biomarkers in the AD diagnosis\nprocedure, brain amyloid positivity is typically identified by positron\nemission tomography (PET), which is costly and invasive. Brain structural\nmagnetic resonance imaging (sMRI) may provide a safer and more convenient\nsolution for the AD diagnosis. Recent advances in geometric deep learning have\nfacilitated sMRI analysis and early diagnosis of AD. However, determining AD\npathology, such as brain amyloid deposition, in preclinical stage remains\nchallenging, as less significant morphological changes can be observed. As a\nresult, few AD classification models are generalizable to the brain amyloid\npositivity classification task. Blood-based biomarkers (BBBMs), on the other\nhand, have recently achieved remarkable success in predicting brain amyloid\npositivity and identifying individuals with high risk of being brain amyloid\npositive. However, individuals in medium risk group still require gold standard\ntests such as Amyloid PET for further evaluation. Inspired by the recent\nsuccess of transformer architectures, we propose a geometric deep learning\nmodel based on transformer that is both scalable and robust to variations in\ninput volumetric mesh size. Our work introduced a novel tokenization scheme for\ntetrahedral meshes, incorporating anatomical landmarks generated by a\npre-trained Gaussian process model. Our model achieved superior classification\nperformance in AD classification task. In addition, we showed that the model\nwas also generalizable to the brain amyloid positivity prediction with\nindividuals in the medium risk class, where BM alone cannot achieve a clear\nclassification. Our work may enrich geometric deep learning research and\nimprove AD diagnosis accuracy without using expensive and invasive PET scans.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05031v1",
    "published_date": "2025-03-06 23:02:18 UTC",
    "updated_date": "2025-03-06 23:02:18 UTC"
  },
  {
    "arxiv_id": "2503.05029v1",
    "title": "Continual Pre-training of MoEs: How robust is your router?",
    "authors": [
      "Benjamin Thérien",
      "Charles-Étienne Joseph",
      "Zain Sarwar",
      "Ashwinee Panda",
      "Anirban Das",
      "Shi-Xiong Zhang",
      "Stephen Rawls",
      "Sambit Sahu",
      "Eugene Belilovsky",
      "Irina Rish"
    ],
    "abstract": "Sparsely-activated Mixture of Experts (MoE) transformers are promising\narchitectures for foundation models. Compared to dense transformers that\nrequire the same amount of floating point operations (FLOPs) per forward pass,\nMoEs benefit from improved sample efficiency at training time and achieve much\nstronger performance. Many closed-source and open-source frontier language\nmodels have thus adopted an MoE architecture. Naturally, practitioners will\nwant to extend the capabilities of these models with large amounts of newly\ncollected data without completely re-training them. Prior work has shown that a\nsimple combination of replay and learning rate re-warming and re-decaying can\nenable the continual pre-training (CPT) of dense decoder-only transformers with\nminimal performance degradation compared to full re-training. In the case of\ndecoder-only MoE transformers, however, it is unclear how the routing algorithm\nwill impact continual pre-training performance: 1) do the MoE transformer's\nrouters exacerbate forgetting relative to a dense model?; 2) do the routers\nmaintain a balanced load on previous distributions after CPT?; 3) are the same\nstrategies applied to dense models sufficient to continually pre-train MoE\nLLMs? In what follows, we conduct a large-scale (>2B parameter switch and\nDeepSeek MoE LLMs trained for 600B tokens) empirical study across four MoE\ntransformers to answer these questions. Our results establish a surprising\nrobustness to distribution shifts for both Sinkhorn-Balanced and\nZ-and-Aux-loss-balanced routing algorithms, even in MoEs continually\npre-trained without replay. Moreover, we show that MoE LLMs maintain their\nsample efficiency (relative to a FLOP-matched dense model) during CPT and that\nthey can match the performance of a fully re-trained MoE at a fraction of the\ncost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05029v1",
    "published_date": "2025-03-06 22:55:01 UTC",
    "updated_date": "2025-03-06 22:55:01 UTC"
  },
  {
    "arxiv_id": "2503.05012v1",
    "title": "LLMs' Reshaping of People, Processes, Products, and Society in Software Development: A Comprehensive Exploration with Early Adopters",
    "authors": [
      "Benyamin Tabarsi",
      "Heidi Reichert",
      "Ally Limke",
      "Sandeep Kuttal",
      "Tiffany Barnes"
    ],
    "abstract": "Large language models (LLMs) like OpenAI ChatGPT, Google Gemini, and GitHub\nCopilot are rapidly gaining traction in the software industry, but their full\nimpact on software engineering remains insufficiently explored. Despite their\ngrowing adoption, there is a notable lack of formal, qualitative assessments of\nhow LLMs are applied in real-world software development contexts. To fill this\ngap, we conducted semi-structured interviews with sixteen early-adopter\nprofessional developers to explore their use of LLMs throughout various stages\nof the software development life cycle. Our investigation examines four\ndimensions: people - how LLMs affect individual developers and teams; process -\nhow LLMs alter software engineering workflows; product - LLM impact on software\nquality and innovation; and society - the broader socioeconomic and ethical\nimplications of LLM adoption. Thematic analysis of our data reveals that while\nLLMs have not fundamentally revolutionized the development process, they have\nsubstantially enhanced routine coding tasks, including code generation,\nrefactoring, and debugging. Developers reported the most effective outcomes\nwhen providing LLMs with clear, well-defined problem statements, indicating\nthat LLMs excel with decomposed problems and specific requirements.\nFurthermore, these early-adopters identified that LLMs offer significant value\nfor personal and professional development, aiding in learning new languages and\nconcepts. Early-adopters, highly skilled in software engineering and how LLMs\nwork, identified early and persisting challenges for software engineering, such\nas inaccuracies in generated content and the need for careful manual review\nbefore integrating LLM outputs into production environments. Our study provides\na nuanced understanding of how LLMs are shaping the landscape of software\ndevelopment, with their benefits, limitations, and ongoing implications.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05012v1",
    "published_date": "2025-03-06 22:27:05 UTC",
    "updated_date": "2025-03-06 22:27:05 UTC"
  },
  {
    "arxiv_id": "2503.05005v2",
    "title": "Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models",
    "authors": [
      "Benyamin Jamialahmadi",
      "Parsa Kavehzadeh",
      "Mehdi Rezagholizadeh",
      "Parsa Farinneya",
      "Hossein Rajabzadeh",
      "Aref Jafari",
      "Boxing Chen",
      "Marzieh S. Tahaei"
    ],
    "abstract": "Deploying large language models (LLMs) in real-world applications is often\nhindered by strict computational and latency constraints. While dynamic\ninference offers the flexibility to adjust model behavior based on varying\nresource budgets, existing methods are frequently limited by hardware\ninefficiencies or performance degradation. In this paper, we introduce Balcony,\na simple yet highly effective framework for depth-based dynamic inference. By\nfreezing the pretrained LLM and inserting additional transformer layers at\nselected exit points, Balcony maintains the full model's performance while\nenabling real-time adaptation to different computational budgets. These\nadditional layers are trained using a straightforward self-distillation loss,\naligning the sub-model outputs with those of the full model. This approach\nrequires significantly fewer training tokens and tunable parameters,\ndrastically reducing computational costs compared to prior methods. When\napplied to the LLaMA3-8B model, using only 0.2% of the original pretraining\ndata, Balcony achieves minimal performance degradation while enabling\nsignificant speedups. Remarkably, we show that Balcony outperforms\nstate-of-the-art methods such as Flextron and Layerskip as well as other\nleading compression techniques on multiple models and at various scales, across\na variety of benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05005v2",
    "published_date": "2025-03-06 22:09:55 UTC",
    "updated_date": "2025-03-10 18:52:15 UTC"
  },
  {
    "arxiv_id": "2503.04992v2",
    "title": "Wanda++: Pruning Large Language Models via Regional Gradients",
    "authors": [
      "Yifan Yang",
      "Kai Zhen",
      "Bhavana Ganesh",
      "Aram Galstyan",
      "Goeric Huybrechts",
      "Markus Müller",
      "Jonas M. Kübler",
      "Rupak Vignesh Swaminathan",
      "Athanasios Mouchtaris",
      "Sravan Babu Bodapati",
      "Nathan Susanj",
      "Zheng Zhang",
      "Jack FitzGerald",
      "Abhishek Kumar"
    ],
    "abstract": "Large Language Models (LLMs) pruning seeks to remove unimportant weights for\ninference speedup with minimal performance impact. However, existing methods\noften suffer from performance loss without full-model sparsity-aware\nfine-tuning. This paper presents Wanda++, a novel pruning framework that\noutperforms the state-of-the-art methods by utilizing decoder-block-level\n\\textbf{regional} gradients. Specifically, Wanda++ improves the pruning score\nwith regional gradients for the first time and proposes an efficient regional\noptimization method to minimize pruning-induced output discrepancies between\nthe dense and sparse decoder output. Notably, Wanda++ improves perplexity by up\nto 32\\% over Wanda in the language modeling task and generalizes effectively to\ndownstream tasks. Further experiments indicate our proposed method is\northogonal to sparsity-aware fine-tuning, where Wanda++ can be combined with\nLoRA fine-tuning to achieve a similar perplexity improvement as the Wanda\nmethod. The proposed method is lightweight, pruning a 7B LLaMA model in under\n10 minutes on a single NVIDIA H100 GPU.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04992v2",
    "published_date": "2025-03-06 21:42:35 UTC",
    "updated_date": "2025-04-29 17:42:55 UTC"
  },
  {
    "arxiv_id": "2503.04982v1",
    "title": "LVLM-Compress-Bench: Benchmarking the Broader Impact of Large Vision-Language Model Compression",
    "authors": [
      "Souvik Kundu",
      "Anahita Bhiwandiwalla",
      "Sungduk Yu",
      "Phillip Howard",
      "Tiep Le",
      "Sharath Nittur Sridhar",
      "David Cobbley",
      "Hao Kang",
      "Vasudev Lal"
    ],
    "abstract": "Despite recent efforts in understanding the compression impact on large\nlanguage models (LLMs) in terms of their downstream task performance and\ntrustworthiness on relatively simpler uni-modal benchmarks (for example,\nquestion answering, common sense reasoning), their detailed study on\nmulti-modal Large Vision-Language Models (LVLMs) is yet to be unveiled. Towards\nmitigating this gap, we present LVLM-Compress-Bench, a framework to first\nthoroughly study the broad impact of compression on the generative performance\nof LVLMs with multi-modal input driven tasks. In specific, we consider two\nmajor classes of compression for autoregressive models, namely KV cache and\nweight compression, for the dynamically growing intermediate cache and static\nweights, respectively.\n  We use four LVLM variants of the popular LLaVA framework to present our\nanalysis via integrating various state-of-the-art KV and weight compression\nmethods including uniform, outlier-reduced, and group quantization for the KV\ncache and weights. With this framework we demonstrate on ten different\nmulti-modal datasets with different capabilities including recognition,\nknowledge, language generation, spatial awareness, visual reasoning,\nhallucination and visual illusion identification, toxicity, stereotypes and\nbias. In specific, our framework demonstrates the compression impact on both\ngeneral and ethically critical metrics leveraging a combination of real world\nand synthetic datasets to encompass diverse societal intersectional attributes.\nExtensive experimental evaluations yield diverse and intriguing observations on\nthe behavior of LVLMs at different quantization budget of KV and weights, in\nboth maintaining and losing performance as compared to the baseline model with\nFP16 data format.\n  Code will be open-sourced at\nhttps://github.com/opengear-project/LVLM-compress-bench.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04982v1",
    "published_date": "2025-03-06 21:21:18 UTC",
    "updated_date": "2025-03-06 21:21:18 UTC"
  },
  {
    "arxiv_id": "2503.04980v1",
    "title": "A Consensus Privacy Metrics Framework for Synthetic Data",
    "authors": [
      "Lisa Pilgram",
      "Fida K. Dankar",
      "Jorg Drechsler",
      "Mark Elliot",
      "Josep Domingo-Ferrer",
      "Paul Francis",
      "Murat Kantarcioglu",
      "Linglong Kong",
      "Bradley Malin",
      "Krishnamurty Muralidhar",
      "Puja Myles",
      "Fabian Prasser",
      "Jean Louis Raisaro",
      "Chao Yan",
      "Khaled El Emam"
    ],
    "abstract": "Synthetic data generation is one approach for sharing individual-level data.\nHowever, to meet legislative requirements, it is necessary to demonstrate that\nthe individuals' privacy is adequately protected. There is no consolidated\nstandard for measuring privacy in synthetic data. Through an expert panel and\nconsensus process, we developed a framework for evaluating privacy in synthetic\ndata. Our findings indicate that current similarity metrics fail to measure\nidentity disclosure, and their use is discouraged. For differentially private\nsynthetic data, a privacy budget other than close to zero was not considered\ninterpretable. There was consensus on the importance of membership and\nattribute disclosure, both of which involve inferring personal information\nabout an individual without necessarily revealing their identity. The resultant\nframework provides precise recommendations for metrics that address these types\nof disclosures effectively. Our findings further present specific opportunities\nfor future research that can help with widespread adoption of synthetic data.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04980v1",
    "published_date": "2025-03-06 21:19:02 UTC",
    "updated_date": "2025-03-06 21:19:02 UTC"
  },
  {
    "arxiv_id": "2503.04977v1",
    "title": "Quantifying the Relevance of Youth Research Cited in the US Policy Documents",
    "authors": [
      "Miftahul Jannat Mokarrama",
      "Hamed Alhoori"
    ],
    "abstract": "In recent years, there has been a growing concern and emphasis on conducting\nresearch beyond academic or scientific research communities, benefiting society\nat large. A well-known approach to measuring the impact of research on society\nis enumerating its policy citation(s). Despite the importance of research in\ninforming policy, there is no concrete evidence to suggest the research's\nrelevance in cited policy documents. This is concerning because it may increase\nthe possibility of evidence used in policy being manipulated by individual,\nsocial, or political biases that may lead to inappropriate, fragmented, or\narchaic research evidence in policy. Therefore, it is crucial to identify the\ndegree of relevance between research articles and citing policy documents. In\nthis paper, we examined the scale of contextual relevance of youth-focused\nresearch in the referenced US policy documents using natural language\nprocessing techniques, state-of-the-art pre-trained Large Language Models\n(LLMs), and statistical analysis. Our experiments and analysis concluded that\nyouth-related research articles that get US policy citations are mostly\nrelevant to the citing policy documents.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "The paper was accepted and presented in IEEE BIG DATA 2024. It has 10\n  pages, 5 figures, and 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.04977v1",
    "published_date": "2025-03-06 21:14:04 UTC",
    "updated_date": "2025-03-06 21:14:04 UTC"
  },
  {
    "arxiv_id": "2503.04973v1",
    "title": "Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge Reasoning",
    "authors": [
      "Giulio Corallo",
      "Orion Weller",
      "Fabio Petroni",
      "Paolo Papotti"
    ],
    "abstract": "Incorporating external knowledge in large language models (LLMs) enhances\ntheir utility across diverse applications, but existing methods have\ntrade-offs. Retrieval-Augmented Generation (RAG) fetches evidence via\nsimilarity search, but key information may fall outside top ranked results.\nLong-context models can process multiple documents but are computationally\nexpensive and limited by context window size. Inspired by students condensing\nstudy material for open-book exams, we propose task-aware key-value (KV) cache\ncompression, which compresses external knowledge in a zero- or few-shot setup.\nThis enables LLMs to reason efficiently over a compacted representation of all\nrelevant information. Experiments show our approach outperforms both RAG and\ntask-agnostic compression methods. On LongBench v2, it improves accuracy by up\nto 7 absolute points over RAG with a 30x compression rate, while reducing\ninference latency from 0.43s to 0.16s. A synthetic dataset highlights that RAG\nperforms well when sparse evidence suffices, whereas task-aware compression is\nsuperior for broad knowledge tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04973v1",
    "published_date": "2025-03-06 21:07:41 UTC",
    "updated_date": "2025-03-06 21:07:41 UTC"
  },
  {
    "arxiv_id": "2503.04971v1",
    "title": "Incentivizing Multi-Tenant Split Federated Learning for Foundation Models at the Network Edge",
    "authors": [
      "Songyuan Li",
      "Jia Hu",
      "Geyong Min",
      "Haojun Huang"
    ],
    "abstract": "Foundation models (FMs) such as GPT-4 exhibit exceptional generative\ncapabilities across diverse downstream tasks through fine-tuning. Split\nFederated Learning (SFL) facilitates privacy-preserving FM fine-tuning on\nresource-constrained local devices by offloading partial FM computations to\nedge servers, enabling device-edge synergistic fine-tuning. Practical edge\nnetworks often host multiple SFL tenants to support diversified downstream\ntasks. However, existing research primarily focuses on single-tenant SFL\nscenarios, and lacks tailored incentive mechanisms for multi-tenant settings,\nwhich are essential to effectively coordinate self-interested local devices for\nparticipation in various downstream tasks, ensuring that each SFL tenant's\ndistinct FM fine-tuning requirements (e.g., FM types, performance targets, and\nfine-tuning deadlines) are met. To address this gap, we propose a novel\nPrice-Incentive Mechanism (PRINCE) that guides multiple SFL tenants to offer\nstrategic price incentives, which solicit high-quality device participation for\nefficient FM fine-tuning. Specifically, we first develop a bias-resilient\nglobal SFL model aggregation scheme to eliminate model biases caused by\nindependent device participation. We then derive a rigorous SFL convergence\nbound to evaluate the contributions of heterogeneous devices to FM performance\nimprovements, guiding the incentive strategies of SFL tenants. Furthermore, we\nmodel inter-tenant device competition as a congestion game for Stackelberg\nequilibrium (SE) analysis, deriving each SFL tenant's optimal incentive\nstrategy. Extensive simulations involving four representative SFL tenant types\n(ViT, BERT, Whisper, and LLaMA) across diverse data modalities (text, images,\nand audio) demonstrate that PRINCE accelerates FM fine-tuning by up to 3.07x\ncompared to state-of-the-art approaches, while consistently meeting fine-tuning\nperformance targets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Index Terms: Foundation models, Edge computing, Split federated\n  learning, Multi-tenant system, Incentive mechanism",
    "pdf_url": "http://arxiv.org/pdf/2503.04971v1",
    "published_date": "2025-03-06 21:06:27 UTC",
    "updated_date": "2025-03-06 21:06:27 UTC"
  },
  {
    "arxiv_id": "2503.04969v1",
    "title": "Data-Efficient Learning from Human Interventions for Mobile Robots",
    "authors": [
      "Zhenghao Peng",
      "Zhizheng Liu",
      "Bolei Zhou"
    ],
    "abstract": "Mobile robots are essential in applications such as autonomous delivery and\nhospitality services. Applying learning-based methods to address mobile robot\ntasks has gained popularity due to its robustness and generalizability.\nTraditional methods such as Imitation Learning (IL) and Reinforcement Learning\n(RL) offer adaptability but require large datasets, carefully crafted reward\nfunctions, and face sim-to-real gaps, making them challenging for efficient and\nsafe real-world deployment. We propose an online human-in-the-loop learning\nmethod PVP4Real that combines IL and RL to address these issues. PVP4Real\nenables efficient real-time policy learning from online human intervention and\ndemonstration, without reward or any pretraining, significantly improving data\nefficiency and training safety. We validate our method by training two\ndifferent robots -- a legged quadruped, and a wheeled delivery robot -- in two\nmobile robot tasks, one of which even uses raw RGBD image as observation. The\ntraining finishes within 15 minutes. Our experiments show the promising future\nof human-in-the-loop learning in addressing the data efficiency issue in\nreal-world robotic tasks. More information is available at:\nhttps://metadriverse.github.io/pvp4real/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "ICRA 2025. Webpage: https://metadriverse.github.io/pvp4real/",
    "pdf_url": "http://arxiv.org/pdf/2503.04969v1",
    "published_date": "2025-03-06 21:02:02 UTC",
    "updated_date": "2025-03-06 21:02:02 UTC"
  },
  {
    "arxiv_id": "2503.04966v2",
    "title": "Prediction of Frozen Region Growth in Kidney Cryoablation Intervention Using a 3D Flow-Matching Model",
    "authors": [
      "Siyeop Yoon",
      "Yujin Oh",
      "Matthew Tivnan",
      "Sifan Song",
      "Pengfei Jin",
      "Sekeun Kim",
      "Hyun Jin Cho",
      "Dufan Wu",
      "Raul Uppot",
      "Quanzheng Li"
    ],
    "abstract": "This study presents a 3D flow-matching model designed to predict the\nprogression of the frozen region (iceball) during kidney cryoablation. Precise\nintraoperative guidance is critical in cryoablation to ensure complete tumor\neradication while preserving adjacent healthy tissue. However, conventional\nmethods, typically based on physics driven or diffusion based simulations, are\ncomputationally demanding and often struggle to represent complex anatomical\nstructures accurately. To address these limitations, our approach leverages\nintraoperative CT imaging to inform the model. The proposed 3D flow matching\nmodel is trained to learn a continuous deformation field that maps early-stage\nCT scans to future predictions. This transformation not only estimates the\nvolumetric expansion of the iceball but also generates corresponding\nsegmentation masks, effectively capturing spatial and morphological changes\nover time. Quantitative analysis highlights the model robustness, demonstrating\nstrong agreement between predictions and ground-truth segmentations. The model\nachieves an Intersection over Union (IoU) score of 0.61 and a Dice coefficient\nof 0.75. By integrating real time CT imaging with advanced deep learning\ntechniques, this approach has the potential to enhance intraoperative guidance\nin kidney cryoablation, improving procedural outcomes and advancing the field\nof minimally invasive surgery.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "MICCAI 2025 submitted version (author list included)",
    "pdf_url": "http://arxiv.org/pdf/2503.04966v2",
    "published_date": "2025-03-06 20:52:58 UTC",
    "updated_date": "2025-03-11 15:21:38 UTC"
  },
  {
    "arxiv_id": "2503.04963v1",
    "title": "Energy-Latency Attacks: A New Adversarial Threat to Deep Learning",
    "authors": [
      "Hanene F. Z. Brachemi Meftah",
      "Wassim Hamidouche",
      "Sid Ahmed Fezza",
      "Olivier Deforges"
    ],
    "abstract": "The growing computational demand for deep neural networks ( DNNs) has raised\nconcerns about their energy consumption and carbon footprint, particularly as\nthe size and complexity of the models continue to increase. To address these\nchallenges, energy-efficient hardware and custom accelerators have become\nessential. Additionally, adaptable DNN s are being developed to dynamically\nbalance performance and efficiency. The use of these strategies became more\ncommon to enable sustainable AI deployment. However, these efficiency-focused\ndesigns may also introduce vulnerabilities, as attackers can potentially\nexploit them to increase latency and energy usage by triggering their\nworst-case-performance scenarios. This new type of attack, called\nenergy-latency attacks, has recently gained significant research attention,\nfocusing on the vulnerability of DNN s to this emerging attack paradigm, which\ncan trigger denial-of-service ( DoS) attacks. This paper provides a\ncomprehensive overview of current research on energy-latency attacks,\ncategorizing them using the established taxonomy for traditional adversarial\nattacks. We explore different metrics used to measure the success of these\nattacks and provide an analysis and comparison of existing attack strategies.\nWe also analyze existing defense mechanisms and highlight current challenges\nand potential areas for future research in this developing field. The GitHub\npage for this work can be accessed at\nhttps://github.com/hbrachemi/Survey_energy_attacks/",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04963v1",
    "published_date": "2025-03-06 20:50:58 UTC",
    "updated_date": "2025-03-06 20:50:58 UTC"
  },
  {
    "arxiv_id": "2503.04957v1",
    "title": "SafeArena: Evaluating the Safety of Autonomous Web Agents",
    "authors": [
      "Ada Defne Tur",
      "Nicholas Meade",
      "Xing Han Lù",
      "Alejandra Zambrano",
      "Arkil Patel",
      "Esin Durmus",
      "Spandana Gella",
      "Karolina Stańczak",
      "Siva Reddy"
    ],
    "abstract": "LLM-based agents are becoming increasingly proficient at solving web-based\ntasks. With this capability comes a greater risk of misuse for malicious\npurposes, such as posting misinformation in an online forum or selling illicit\nsubstances on a website. To evaluate these risks, we propose SafeArena, the\nfirst benchmark to focus on the deliberate misuse of web agents. SafeArena\ncomprises 250 safe and 250 harmful tasks across four websites. We classify the\nharmful tasks into five harm categories -- misinformation, illegal activity,\nharassment, cybercrime, and social bias, designed to assess realistic misuses\nof web agents. We evaluate leading LLM-based web agents, including GPT-4o,\nClaude-3.5 Sonnet, Qwen-2-VL 72B, and Llama-3.2 90B, on our benchmark. To\nsystematically assess their susceptibility to harmful tasks, we introduce the\nAgent Risk Assessment framework that categorizes agent behavior across four\nrisk levels. We find agents are surprisingly compliant with malicious requests,\nwith GPT-4o and Qwen-2 completing 34.7% and 27.3% of harmful requests,\nrespectively. Our findings highlight the urgent need for safety alignment\nprocedures for web agents. Our benchmark is available here:\nhttps://safearena.github.io",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04957v1",
    "published_date": "2025-03-06 20:43:14 UTC",
    "updated_date": "2025-03-06 20:43:14 UTC"
  },
  {
    "arxiv_id": "2503.04952v1",
    "title": "INTENT: Trajectory Prediction Framework with Intention-Guided Contrastive Clustering",
    "authors": [
      "Yihong Tang",
      "Wei Ma"
    ],
    "abstract": "Accurate trajectory prediction of road agents (e.g., pedestrians, vehicles)\nis an essential prerequisite for various intelligent systems applications, such\nas autonomous driving and robotic navigation. Recent research highlights the\nimportance of environmental contexts (e.g., maps) and the \"multi-modality\" of\ntrajectories, leading to increasingly complex model structures. However,\nreal-world deployments require lightweight models that can quickly migrate and\nadapt to new environments. Additionally, the core motivations of road agents,\nreferred to as their intentions, deserves further exploration. In this study,\nwe advocate that understanding and reasoning road agents' intention plays a key\nrole in trajectory prediction tasks, and the main challenge is that the concept\nof intention is fuzzy and abstract. To this end, we present INTENT, an\nefficient intention-guided trajectory prediction model that relies solely on\ninformation contained in the road agent's trajectory. Our model distinguishes\nitself from existing models in several key aspects: (i) We explicitly model\nroad agents' intentions through contrastive clustering, accommodating the\nfuzziness and abstraction of human intention in their trajectories. (ii) The\nproposed INTENT is based solely on multi-layer perceptrons (MLPs), resulting in\nreduced training and inference time, making it very efficient and more suitable\nfor real-world deployment. (iii) By leveraging estimated intentions and an\ninnovative algorithm for transforming trajectory observations, we obtain more\nrobust trajectory representations that lead to superior prediction accuracy.\nExtensive experiments on real-world trajectory datasets for pedestrians and\nautonomous vehicles demonstrate the effectiveness and efficiency of INTENT.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04952v1",
    "published_date": "2025-03-06 20:31:11 UTC",
    "updated_date": "2025-03-06 20:31:11 UTC"
  },
  {
    "arxiv_id": "2503.04946v1",
    "title": "Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation",
    "authors": [
      "Changchang Yin",
      "Hong-You Chen",
      "Wei-Lun Chao",
      "Ping Zhang"
    ],
    "abstract": "Individual treatment effect (ITE) estimation is to evaluate the causal\neffects of treatment strategies on some important outcomes, which is a crucial\nproblem in healthcare. Most existing ITE estimation methods are designed for\ncentralized settings. However, in real-world clinical scenarios, the raw data\nare usually not shareable among hospitals due to the potential privacy and\nsecurity risks, which makes the methods not applicable. In this work, we study\nthe ITE estimation task in a federated setting, which allows us to harness the\ndecentralized data from multiple hospitals. Due to the unavoidable confounding\nbias in the collected data, a model directly learned from it would be\ninaccurate. One well-known solution is Inverse Probability Treatment Weighting\n(IPTW), which uses the conditional probability of treatment given the\ncovariates to re-weight each training example. Applying IPTW in a federated\nsetting, however, is non-trivial. We found that even with a well-estimated\nconditional probability, the local model training step using each hospital's\ndata alone would still suffer from confounding bias. To address this, we\npropose FED-IPTW, a novel algorithm to extend IPTW into a federated setting\nthat enforces both global (over all the data) and local (within each hospital)\ndecorrelation between covariates and treatments. We validated our approach on\nthe task of comparing the treatment effects of mechanical ventilation on\nimproving survival probability for patients with breadth difficulties in the\nintensive care unit (ICU). We conducted experiments on both synthetic and\nreal-world eICU datasets and the results show that FED-IPTW outperform\nstate-of-the-art methods on all the metrics on factual prediction and ITE\nestimation tasks, paving the way for personalized treatment strategy design in\nmechanical ventilation usage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "K.3.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04946v1",
    "published_date": "2025-03-06 20:24:34 UTC",
    "updated_date": "2025-03-06 20:24:34 UTC"
  },
  {
    "arxiv_id": "2503.04945v1",
    "title": "Collaborative Evaluation of Deepfake Text with Deliberation-Enhancing Dialogue Systems",
    "authors": [
      "Jooyoung Lee",
      "Xiaochen Zhu",
      "Georgi Karadzhov",
      "Tom Stafford",
      "Andreas Vlachos",
      "Dongwon Lee"
    ],
    "abstract": "The proliferation of generative models has presented significant challenges\nin distinguishing authentic human-authored content from deepfake content.\nCollaborative human efforts, augmented by AI tools, present a promising\nsolution. In this study, we explore the potential of DeepFakeDeLiBot, a\ndeliberation-enhancing chatbot, to support groups in detecting deepfake text.\nOur findings reveal that group-based problem-solving significantly improves the\naccuracy of identifying machine-generated paragraphs compared to individual\nefforts. While engagement with DeepFakeDeLiBot does not yield substantial\nperformance gains overall, it enhances group dynamics by fostering greater\nparticipant engagement, consensus building, and the frequency and diversity of\nreasoning-based utterances. Additionally, participants with higher perceived\neffectiveness of group collaboration exhibited performance benefits from\nDeepFakeDeLiBot. These findings underscore the potential of deliberative\nchatbots in fostering interactive and productive group dynamics while ensuring\naccuracy in collaborative deepfake text detection. \\textit{Dataset and source\ncode used in this study will be made publicly available upon acceptance of the\nmanuscript.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "15",
    "pdf_url": "http://arxiv.org/pdf/2503.04945v1",
    "published_date": "2025-03-06 20:19:38 UTC",
    "updated_date": "2025-03-06 20:19:38 UTC"
  },
  {
    "arxiv_id": "2503.04940v1",
    "title": "VQEL: Enabling Self-Developed Symbolic Language in Agents through Vector Quantization in Emergent Language Games",
    "authors": [
      "Mohammad Mahdi Samiei Paqaleh",
      "Mahdieh Soleymani Baghshah"
    ],
    "abstract": "In the field of emergent language, efforts have traditionally focused on\ndeveloping communication protocols through interactions between agents in\nreferential games. However, the aspect of internal language learning, where\nlanguage serves not only as a communicative tool with others but also as a\nmeans for individual thinking, self-reflection, and problem-solving remains\nunderexplored. Developing a language through self-play, without another agent's\ninvolvement, poses a unique challenge. It requires an agent to craft symbolic\nrepresentations and train them using direct gradient methods. The challenge\nhere is that if an agent attempts to learn symbolic representations through\nself-play using conventional modeling and techniques such as REINFORCE, the\nsolution will offer no advantage over previous multi-agent approaches. We\nintroduce VQEL, a novel method that incorporates Vector Quantization into the\nagents' architecture, enabling them to autonomously invent and develop discrete\nsymbolic representations in a self-play referential game. Following the\nself-play phase, agents can enhance their language through reinforcement\nlearning and interactions with other agents in the mutual-play phase. Our\nexperiments across various datasets demonstrate that VQEL not only outperforms\nthe traditional REINFORCE method but also benefits from improved control and\nreduced susceptibility to collapse, thanks to the incorporation of vector\nquantization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04940v1",
    "published_date": "2025-03-06 20:15:51 UTC",
    "updated_date": "2025-03-06 20:15:51 UTC"
  },
  {
    "arxiv_id": "2503.04933v1",
    "title": "Learning-based GNSS Uncertainty Quantification using Continuous-Time Factor Graph Optimization",
    "authors": [
      "Haoming Zhang"
    ],
    "abstract": "This short paper presents research findings on two learning-based methods for\nquantifying measurement uncertainties in global navigation satellite systems\n(GNSS). We investigate two learning strategies: offline learning for outlier\nprediction and online learning for noise distribution approximation,\nspecifically applied to GNSS pseudorange observations. To develop and evaluate\nthese learning methods, we introduce a novel multisensor state estimator that\naccurately and robustly estimates trajectory from multiple sensor inputs,\ncritical for deriving GNSS measurement residuals used to train the uncertainty\nmodels. We validate the proposed learning-based models using real-world sensor\ndata collected in diverse urban environments. Experimental results demonstrate\nthat both models effectively handle GNSS outliers and improve state estimation\nperformance. Furthermore, we provide insightful discussions to motivate future\nresearch toward developing a federated framework for robust vehicle\nlocalization in challenging environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "This extended abstract has been accepted to the 1st German Robotic\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2503.04933v1",
    "published_date": "2025-03-06 20:04:36 UTC",
    "updated_date": "2025-03-06 20:04:36 UTC"
  },
  {
    "arxiv_id": "2503.04931v1",
    "title": "Curiosity-Driven Imagination: Discovering Plan Operators and Learning Associated Policies for Open-World Adaptation",
    "authors": [
      "Pierrick Lorang",
      "Hong Lu",
      "Matthias Scheutz"
    ],
    "abstract": "Adapting quickly to dynamic, uncertain environments-often called \"open\nworlds\"-remains a major challenge in robotics. Traditional Task and Motion\nPlanning (TAMP) approaches struggle to cope with unforeseen changes, are\ndata-inefficient when adapting, and do not leverage world models during\nlearning. We address this issue with a hybrid planning and learning system that\nintegrates two models: a low level neural network based model that learns\nstochastic transitions and drives exploration via an Intrinsic Curiosity Module\n(ICM), and a high level symbolic planning model that captures abstract\ntransitions using operators, enabling the agent to plan in an \"imaginary\" space\nand generate reward machines. Our evaluation in a robotic manipulation domain\nwith sequential novelty injections demonstrates that our approach converges\nfaster and outperforms state-of-the-art hybrid methods.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 4 figures. Accepted at ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04931v1",
    "published_date": "2025-03-06 20:02:26 UTC",
    "updated_date": "2025-03-06 20:02:26 UTC"
  },
  {
    "arxiv_id": "2503.04930v1",
    "title": "HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using Knowledgebases and Large Language Models",
    "authors": [
      "Yao Ge",
      "Yuting Guo",
      "Sudeshna Das",
      "Swati Rajwal",
      "Selen Bozkurt",
      "Abeed Sarker"
    ],
    "abstract": "We present HILGEN, a Hierarchically-Informed Data Generation approach that\ncombines domain knowledge from the Unified Medical Language System (UMLS) with\nsynthetic data generated by large language models (LLMs), specifically GPT-3.5.\nOur approach leverages UMLS's hierarchical structure to expand training data\nwith related concepts, while incorporating contextual information from LLMs\nthrough targeted prompts aimed at automatically generating synthetic examples\nfor sparsely occurring named entities. The performance of the HILGEN approach\nwas evaluated across four biomedical NER datasets (MIMIC III, BC5CDR,\nNCBI-Disease, and Med-Mentions) using BERT-Large and DANN (Data Augmentation\nwith Nearest Neighbor Classifier) models, applying various data generation\nstrategies, including UMLS, GPT-3.5, and their best ensemble. For the\nBERT-Large model, incorporating UMLS led to an average F1 score improvement of\n40.36%, while using GPT-3.5 resulted in a comparable average increase of\n40.52%. The Best-Ensemble approach using BERT-Large achieved the highest\nimprovement, with an average increase of 42.29%. DANN model's F1 score improved\nby 22.74% on average using the UMLS-only approach. The GPT-3.5-based method\nresulted in a 21.53% increase, and the Best-Ensemble DANN model showed a more\nnotable improvement, with an average increase of 25.03%. Our proposed HILGEN\napproach improves NER performance in few-shot settings without requiring\nadditional manually annotated data. Our experiments demonstrate that an\neffective strategy for optimizing biomedical NER is to combine biomedical\nknowledge curated in the past, such as the UMLS, and generative LLMs to create\nsynthetic training instances. Our future research will focus on exploring\nadditional innovative synthetic data generation strategies for further\nimproving NER performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04930v1",
    "published_date": "2025-03-06 20:02:19 UTC",
    "updated_date": "2025-03-06 20:02:19 UTC"
  },
  {
    "arxiv_id": "2503.04725v1",
    "title": "L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling",
    "authors": [
      "Zhuo Chen",
      "Oriol Mayné i Comas",
      "Zhuotao Jin",
      "Di Luo",
      "Marin Soljačić"
    ],
    "abstract": "We rigorously establish a bipartite mutual information scaling law in natural\nlanguage that governs long-range dependencies. This scaling law, which we show\nis distinct from and scales independently of the conventional two-point mutual\ninformation, is the key to understanding long-context language modeling. Using\nthis scaling law, we formulate the Long-context Language Modeling (L$^2$M)\ncondition, which relates a model's capacity for effective long context length\nmodeling to the scaling of its latent state size for storing past information.\nOur results are validated through experiments on both transformers and state\nspace models. This work establishes a theoretical foundation that guides the\ndevelopment of large language models toward longer context lengths.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "physics.data-an"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 12 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2503.04725v1",
    "published_date": "2025-03-06 18:59:48 UTC",
    "updated_date": "2025-03-06 18:59:48 UTC"
  },
  {
    "arxiv_id": "2503.04723v2",
    "title": "Shifting Long-Context LLMs Research from Input to Output",
    "authors": [
      "Yuhao Wu",
      "Yushi Bai",
      "Zhiqing Hu",
      "Shangqing Tu",
      "Ming Shan Hee",
      "Juanzi Li",
      "Roy Ka-Wei Lee"
    ],
    "abstract": "Recent advancements in long-context Large Language Models (LLMs) have\nprimarily concentrated on processing extended input contexts, resulting in\nsignificant strides in long-context comprehension. However, the equally\ncritical aspect of generating long-form outputs has received comparatively less\nattention. This paper advocates for a paradigm shift in NLP research toward\naddressing the challenges of long-output generation. Tasks such as novel\nwriting, long-term planning, and complex reasoning require models to understand\nextensive contexts and produce coherent, contextually rich, and logically\nconsistent extended text. These demands highlight a critical gap in current LLM\ncapabilities. We underscore the importance of this under-explored domain and\ncall for focused efforts to develop foundational LLMs tailored for generating\nhigh-quality, long-form outputs, which hold immense potential for real-world\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.04723v2",
    "published_date": "2025-03-06 18:59:37 UTC",
    "updated_date": "2025-03-07 03:14:02 UTC"
  },
  {
    "arxiv_id": "2503.04722v1",
    "title": "Enough Coin Flips Can Make LLMs Act Bayesian",
    "authors": [
      "Ritwik Gupta",
      "Rodolfo Corona",
      "Jiaxin Ge",
      "Eric Wang",
      "Dan Klein",
      "Trevor Darrell",
      "David M. Chan"
    ],
    "abstract": "Large language models (LLMs) exhibit the ability to generalize given few-shot\nexamples in their input prompt, an emergent capability known as in-context\nlearning (ICL). We investigate whether LLMs utilize ICL to perform structured\nreasoning in ways that are consistent with a Bayesian framework or rely on\npattern matching. Using a controlled setting of biased coin flips, we find\nthat: (1) LLMs often possess biased priors, causing initial divergence in\nzero-shot settings, (2) in-context evidence outweighs explicit bias\ninstructions, (3) LLMs broadly follow Bayesian posterior updates, with\ndeviations primarily due to miscalibrated priors rather than flawed updates,\nand (4) attention magnitude has negligible effect on Bayesian inference. With\nsufficient demonstrations of biased coin flips via ICL, LLMs update their\npriors in a Bayesian manner.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04722v1",
    "published_date": "2025-03-06 18:59:23 UTC",
    "updated_date": "2025-03-06 18:59:23 UTC"
  },
  {
    "arxiv_id": "2503.04715v5",
    "title": "Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining",
    "authors": [
      "Houyi Li",
      "Wenzhen Zheng",
      "Qiufeng Wang",
      "Hanshan Zhang",
      "Zili Wang",
      "Shijie Xuyang",
      "Yuantao Fan",
      "Shuigeng Zhou",
      "Xiangyu Zhang",
      "Daxin Jiang"
    ],
    "abstract": "The impressive capabilities of Large Language Models (LLMs) across diverse\ntasks are now well-established, yet their effective deployment necessitates\ncareful hyperparameter optimization. Through extensive empirical studies\ninvolving grid searches across diverse configurations, we discover universal\nscaling laws governing these hyperparameters: optimal learning rate follows a\npower-law relationship with both model parameters and data sizes, while optimal\nbatch size scales primarily with data sizes. Our analysis reveals a convex\noptimization landscape for hyperparameters under fixed models and data size\nconditions. This convexity implies an optimal hyperparameter plateau. We\ncontribute a universal, plug-and-play optimal hyperparameter tool for the\ncommunity. Its estimated values on the test set are merely 0.09% away from the\nglobally optimal LLM performance found via an exhaustive search. These laws\ndemonstrate remarkable robustness across variations in model sparsity, training\ndata distribution, and model shape. To our best known, this is the first work\nthat unifies different model shapes and structures, such as Mixture-of-Experts\nmodels and dense transformers, as well as establishes optimal hyperparameter\nscaling laws across diverse data distributions. This exhaustive optimization\nprocess demands substantial computational resources, utilizing nearly one\nmillion NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and\nhyperparameters from scratch and consuming approximately 100 trillion tokens in\ntotal. To facilitate reproducibility and further research, we will\nprogressively release all loss measurements and model checkpoints through our\ndesignated repository https://step-law.github.io/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.04715v5",
    "published_date": "2025-03-06 18:58:29 UTC",
    "updated_date": "2025-05-21 10:48:37 UTC"
  },
  {
    "arxiv_id": "2503.04713v1",
    "title": "Scaling Rich Style-Prompted Text-to-Speech Datasets",
    "authors": [
      "Anuj Diwan",
      "Zhisheng Zheng",
      "David Harwath",
      "Eunsol Choi"
    ],
    "abstract": "We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale\ndataset that annotates speech utterances with rich style captions. While rich\nabstract tags (e.g. guttural, nasal, pained) have been explored in small-scale\nhuman-annotated datasets, existing large-scale datasets only cover basic tags\n(e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech\nembedders, classifiers and an audio language model to automatically scale rich\ntag annotations for the first time. ParaSpeechCaps covers a total of 59 style\ntags, including both speaker-level intrinsic tags and utterance-level\nsituational tags. It consists of 342 hours of human-labelled data (PSC-Base)\nand 2427 hours of automatically annotated data (PSC-Scaled). We finetune\nParler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and\nachieve improved style consistency (+7.9% Consistency MOS) and speech quality\n(+15.5% Naturalness MOS) over the best performing baseline that combines\nexisting rich style tag datasets. We ablate several of our dataset design\nchoices to lay the foundation for future work in this space. Our dataset,\nmodels and code are released at https://github.com/ajd12342/paraspeechcaps .",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04713v1",
    "published_date": "2025-03-06 18:57:40 UTC",
    "updated_date": "2025-03-06 18:57:40 UTC"
  },
  {
    "arxiv_id": "2503.04710v1",
    "title": "Self-Supervised Models for Phoneme Recognition: Applications in Children's Speech for Reading Learning",
    "authors": [
      "Lucas Block Medin",
      "Thomas Pellegrini",
      "Lucile Gelin"
    ],
    "abstract": "Child speech recognition is still an underdeveloped area of research due to\nthe lack of data (especially on non-English languages) and the specific\ndifficulties of this task. Having explored various architectures for child\nspeech recognition in previous work, in this article we tackle recent\nself-supervised models. We first compare wav2vec 2.0, HuBERT and WavLM models\nadapted to phoneme recognition in French child speech, and continue our\nexperiments with the best of them, WavLM base+. We then further adapt it by\nunfreezing its transformer blocks during fine-tuning on child speech, which\ngreatly improves its performance and makes it significantly outperform our base\nmodel, a Transformer+CTC. Finally, we study in detail the behaviour of these\ntwo models under the real conditions of our application, and show that WavLM\nbase+ is more robust to various reading tasks and noise levels. Index Terms:\nspeech recognition, child speech, self-supervised learning",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "This paper was originally published in the Proceedings of Interspeech\n  2024. DOI: 10.21437/Interspeech.2024-1095",
    "pdf_url": "http://arxiv.org/pdf/2503.04710v1",
    "published_date": "2025-03-06 18:57:16 UTC",
    "updated_date": "2025-03-06 18:57:16 UTC"
  },
  {
    "arxiv_id": "2503.04704v2",
    "title": "Universality of Layer-Level Entropy-Weighted Quantization Beyond Model Architecture and Size",
    "authors": [
      "Alireza Behtash",
      "Marijan Fofonjka",
      "Ethan Baird",
      "Tyler Mauer",
      "Hossein Moghimifam",
      "David Stout",
      "Joel Dennison"
    ],
    "abstract": "We present a novel approach to selective model quantization that transcends\nthe limitations of architecture-specific and size-dependent compression methods\nfor Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By\nanalyzing the entropy distribution across transformer blocks, EWQ determines\nwhich blocks can be safely quantized without causing significant performance\ndegradation, independent of model architecture or size. Our method outperforms\nuniform quantization approaches, maintaining Massive Multitask Language\nUnderstanding (MMLU) accuracy scores within 0.5% of unquantized models while\nreducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ\nacross multiple architectures -- from 1.6B to 70B parameters -- and showcase\nconsistent improvements in the quality-compression trade-off regardless of\nmodel scale or architectural design. A surprising finding of EWQ is its ability\nto reduce perplexity compared to unquantized models, suggesting the presence of\nbeneficial regularization through selective precision reduction. This\nimprovement holds across different model families, indicating a fundamental\nrelationship between layer-level entropy and optimal precision requirements.\nAdditionally, we introduce FastEWQ, a rapid method for entropy distribution\nanalysis that eliminates the need for loading model weights. This technique\nleverages universal characteristics of entropy distribution that persist across\nvarious architectures and scales, enabling near-instantaneous quantization\ndecisions while maintaining 80% classification accuracy with full entropy\nanalysis. Our results demonstrate that effective quantization strategies can be\ndeveloped independently of specific architectural choices or model sizes,\nopening new possibilities for efficient LLM deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 7 figures, 14 tables; Fixed some types, added some\n  clarifications and improvements",
    "pdf_url": "http://arxiv.org/pdf/2503.04704v2",
    "published_date": "2025-03-06 18:54:32 UTC",
    "updated_date": "2025-03-07 15:12:57 UTC"
  },
  {
    "arxiv_id": "2503.04697v1",
    "title": "L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning",
    "authors": [
      "Pranjal Aggarwal",
      "Sean Welleck"
    ],
    "abstract": "Reasoning language models have shown an uncanny ability to improve\nperformance at test-time by ``thinking longer''-that is, by generating longer\nchain-of-thought sequences and hence using more compute. However, the length of\ntheir chain-of-thought reasoning is not controllable, making it impossible to\nallocate test-time compute to achieve a desired level of performance. We\nintroduce Length Controlled Policy Optimization (LCPO), a simple reinforcement\nlearning method that optimizes for accuracy and adherence to user-specified\nlength constraints. We use LCPO to train L1, a reasoning language model that\nproduces outputs satisfying a length constraint given in its prompt. L1's\nlength control allows for smoothly trading off computational cost and accuracy\non a wide range of tasks, and outperforms the state-of-the-art S1 method for\nlength control. Furthermore, we uncover an unexpected short chain-of-thought\ncapability in models trained with LCPO. For instance, our 1.5B L1 model\nsurpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise\ncontrol over reasoning length, allowing for fine-grained allocation of\ntest-time compute and accuracy. We release code and models at\nhttps://www.cmu-l3.github.io/l1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04697v1",
    "published_date": "2025-03-06 18:43:29 UTC",
    "updated_date": "2025-03-06 18:43:29 UTC"
  },
  {
    "arxiv_id": "2503.04680v1",
    "title": "Matrix Factorization for Inferring Associations and Missing Links",
    "authors": [
      "Ryan Barron",
      "Maksim E. Eren",
      "Duc P. Truong",
      "Cynthia Matuszek",
      "James Wendelberger",
      "Mary F. Dorn",
      "Boian Alexandrov"
    ],
    "abstract": "Missing link prediction is a method for network analysis, with applications\nin recommender systems, biology, social sciences, cybersecurity, information\nretrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs.\nMissing link prediction identifies unseen but potentially existing connections\nin a network by analyzing the observed patterns and relationships. In\nproliferation detection, this supports efforts to identify and characterize\nattempts by state and non-state actors to acquire nuclear weapons or associated\ntechnology - a notoriously challenging but vital mission for global security.\nDimensionality reduction techniques like Non-Negative Matrix Factorization\n(NMF) and Logistic Matrix Factorization (LMF) are effective but require\nselection of the matrix rank parameter, that is, of the number of hidden\nfeatures, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk),\nBoolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along\nwith ensemble variants incorporating logistic factorization, for link\nprediction. Our methods integrate automatic model determination for rank\nestimation by evaluating stability and accuracy using a modified bootstrap\nmethodology and uncertainty quantification (UQ), assessing prediction\nreliability under random perturbations. We incorporate Otsu threshold selection\nand k-means clustering for Boolean matrix factorization, comparing them to\ncoordinate descent-based Boolean thresholding. Our experiments highlight the\nimpact of rank k selection, evaluate model performance under varying test-set\nsizes, and demonstrate the benefits of UQ for reliable predictions using\nabstention. We validate our methods on three synthetic datasets (Boolean and\nuniformly distributed) and benchmark them against LMF and symmetric LMF\n(symLMF) on five real-world protein-protein interaction networks, showcasing an\nimproved prediction performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages, 14 figures, 3 tables, 1 algorithm",
    "pdf_url": "http://arxiv.org/pdf/2503.04680v1",
    "published_date": "2025-03-06 18:22:46 UTC",
    "updated_date": "2025-03-06 18:22:46 UTC"
  },
  {
    "arxiv_id": "2503.04679v1",
    "title": "Multi-Agent Inverse Q-Learning from Demonstrations",
    "authors": [
      "Nathaniel Haynam",
      "Adam Khoja",
      "Dhruv Kumar",
      "Vivek Myers",
      "Erdem Bıyık"
    ],
    "abstract": "When reward functions are hand-designed, deep reinforcement learning\nalgorithms often suffer from reward misspecification, causing them to learn\nsuboptimal policies in terms of the intended task objectives. In the\nsingle-agent case, inverse reinforcement learning (IRL) techniques attempt to\naddress this issue by inferring the reward function from expert demonstrations.\nHowever, in multi-agent problems, misalignment between the learned and true\nobjectives is exacerbated due to increased environment non-stationarity and\nvariance that scales with multiple agents. As such, in multi-agent general-sum\ngames, multi-agent IRL algorithms have difficulty balancing cooperative and\ncompetitive objectives. To address these issues, we propose Multi-Agent\nMarginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient\nframework for multi-agent IRL. For each agent, MAMQL learns a critic\nmarginalized over the other agents' policies, allowing for a well-motivated use\nof Boltzmann policies in the multi-agent context. We identify a connection\nbetween optimal marginalized critics and single-agent soft-Q IRL, allowing us\nto apply a direct, simple optimization criterion from the single-agent domain.\nAcross our experiments on three different simulated domains, MAMQL\nsignificantly outperforms previous multi-agent methods in average reward,\nsample efficiency, and reward recovery by often more than 2-5x. We make our\ncode available at https://sites.google.com/view/mamql .",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "8 pages, 4 figures, 2 tables. Published at the International\n  Conference on Robotics and Automation (ICRA) 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04679v1",
    "published_date": "2025-03-06 18:22:29 UTC",
    "updated_date": "2025-03-06 18:22:29 UTC"
  },
  {
    "arxiv_id": "2503.04877v2",
    "title": "Adapt3R: Adaptive 3D Scene Representation for Domain Transfer in Imitation Learning",
    "authors": [
      "Albert Wilcox",
      "Mohamed Ghanem",
      "Masoud Moghani",
      "Pierre Barroso",
      "Benjamin Joffe",
      "Animesh Garg"
    ],
    "abstract": "Imitation Learning can train robots to perform complex and diverse\nmanipulation tasks, but learned policies are brittle with observations outside\nof the training distribution. 3D scene representations that incorporate\nobservations from calibrated RGBD cameras have been proposed as a way to\nmitigate this, but in our evaluations with unseen embodiments and camera\nviewpoints they show only modest improvement. To address those challenges, we\npropose Adapt3R, a general-purpose 3D observation encoder which synthesizes\ndata from calibrated RGBD cameras into a vector that can be used as\nconditioning for arbitrary IL algorithms. The key idea is to use a pretrained\n2D backbone to extract semantic information, using 3D only as a medium to\nlocalize this information with respect to the end-effector. We show across 93\nsimulated and 6 real tasks that when trained end-to-end with a variety of IL\nalgorithms, Adapt3R maintains these algorithms' learning capacity while\nenabling zero-shot transfer to novel embodiments and camera poses.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Videos, code, and data: https://pairlab.github.io/Adapt3R",
    "pdf_url": "http://arxiv.org/pdf/2503.04877v2",
    "published_date": "2025-03-06 18:17:09 UTC",
    "updated_date": "2025-05-15 20:49:51 UTC"
  },
  {
    "arxiv_id": "2503.07650v2",
    "title": "Insights into Schizophrenia: Leveraging Machine Learning for Early Identification via EEG, ERP, and Demographic Attributes",
    "authors": [
      "Sara Alkhalifa"
    ],
    "abstract": "The research presents a machine learning (ML) classifier designed to\ndifferentiate between schizophrenia patients and healthy controls by utilising\nfeatures extracted from electroencephalogram (EEG) data, specifically focusing\non event-related potentials (ERPs) and certain demographic variables. The\ndataset comprises data from 81 participants, encompassing 32 healthy controls\nand 49 schizophrenia patients, all sourced from an online dataset. After\npreprocessing the dataset, our ML model achieved an accuracy of 99.930%. This\nperformance outperforms earlier research, including those that used deep\nlearning methods. Additionally, an analysis was conducted to assess individual\nfeatures' contribution to improving classification accuracy. This involved\nsystematically excluding specific features from the original dataset one at a\ntime, and another technique involved an iterative process of removing features\nbased on their entropy scores incrementally. The impact of these removals on\nmodel performance was evaluated to identify the most informative features.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05, 92C60"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 6 figures and 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.07650v2",
    "published_date": "2025-03-06 17:42:25 UTC",
    "updated_date": "2025-03-15 09:36:34 UTC"
  },
  {
    "arxiv_id": "2503.04647v1",
    "title": "Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment",
    "authors": [
      "Wen Yang",
      "Junhong Wu",
      "Chen Wang",
      "Chengqing Zong",
      "Jiajun Zhang"
    ],
    "abstract": "Direct Preference Optimization (DPO) has become a prominent method for\naligning Large Language Models (LLMs) with human preferences. While DPO has\nenabled significant progress in aligning English LLMs, multilingual preference\nalignment is hampered by data scarcity. To address this, we propose a novel\napproach that $\\textit{captures}$ learned preferences from well-aligned English\nmodels by implicit rewards and $\\textit{transfers}$ them to other languages\nthrough iterative training. Specifically, we derive an implicit reward model\nfrom the logits of an English DPO-aligned model and its corresponding reference\nmodel. This reward model is then leveraged to annotate preference relations in\ncross-lingual instruction-following pairs, using English instructions to\nevaluate multilingual responses. The annotated data is subsequently used for\nmultilingual DPO fine-tuning, facilitating preference knowledge transfer from\nEnglish to other languages. Fine-tuning Llama3 for two iterations resulted in a\n12.72% average improvement in Win Rate and a 5.97% increase in Length Control\nWin Rate across all training languages on the X-AlpacaEval leaderboard. Our\nfindings demonstrate that leveraging existing English-aligned models can enable\nefficient and effective multilingual preference alignment, significantly\nreducing the need for extensive multilingual preference data. The code is\navailable at https://github.com/ZNLP/Implicit-Cross-Lingual-Rewarding",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2503.04647v1",
    "published_date": "2025-03-06 17:33:01 UTC",
    "updated_date": "2025-03-06 17:33:01 UTC"
  },
  {
    "arxiv_id": "2503.04641v1",
    "title": "Simulating the Real World: A Unified Survey of Multimodal Generative Models",
    "authors": [
      "Yuqi Hu",
      "Longguang Wang",
      "Xian Liu",
      "Ling-Hao Chen",
      "Yuwei Guo",
      "Yukai Shi",
      "Ce Liu",
      "Anyi Rao",
      "Zeyu Wang",
      "Hui Xiong"
    ],
    "abstract": "Understanding and replicating the real world is a critical challenge in\nArtificial General Intelligence (AGI) research. To achieve this, many existing\napproaches, such as world models, aim to capture the fundamental principles\ngoverning the physical world, enabling more accurate simulations and meaningful\ninteractions. However, current methods often treat different modalities,\nincluding 2D (images), videos, 3D, and 4D representations, as independent\ndomains, overlooking their interdependencies. Additionally, these methods\ntypically focus on isolated dimensions of reality without systematically\nintegrating their connections. In this survey, we present a unified survey for\nmultimodal generative models that investigate the progression of data\ndimensionality in real-world simulation. Specifically, this survey starts from\n2D generation (appearance), then moves to video (appearance+dynamics) and 3D\ngeneration (appearance+geometry), and finally culminates in 4D generation that\nintegrate all dimensions. To the best of our knowledge, this is the first\nattempt to systematically unify the study of 2D, video, 3D and 4D generation\nwithin a single framework. To guide future research, we provide a comprehensive\nreview of datasets, evaluation metrics and future directions, and fostering\ninsights for newcomers. This survey serves as a bridge to advance the study of\nmultimodal generative models and real-world simulation within a unified\nframework.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Repository for the related papers at\n  https://github.com/ALEEEHU/World-Simulator",
    "pdf_url": "http://arxiv.org/pdf/2503.04641v1",
    "published_date": "2025-03-06 17:31:43 UTC",
    "updated_date": "2025-03-06 17:31:43 UTC"
  },
  {
    "arxiv_id": "2503.04636v2",
    "title": "Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking",
    "authors": [
      "Yijie Xu",
      "Aiwei Liu",
      "Xuming Hu",
      "Lijie Wen",
      "Hui Xiong"
    ],
    "abstract": "As open-source large language models (LLMs) like Llama3 become more capable,\nit is crucial to develop watermarking techniques to detect their potential\nmisuse. Existing watermarking methods either add watermarks during LLM\ninference, which is unsuitable for open-source LLMs, or primarily target\nclassification LLMs rather than recent generative LLMs. Adapting these\nwatermarks to open-source LLMs for misuse detection remains an open challenge.\nThis work defines two misuse scenarios for open-source LLMs: intellectual\nproperty (IP) violation and LLM Usage Violation. Then, we explore the\napplication of inference-time watermark distillation and backdoor watermarking\nin these contexts. We propose comprehensive evaluation methods to assess the\nimpact of various real-world further fine-tuning scenarios on watermarks and\nthe effect of these watermarks on LLM performance. Our experiments reveal that\nbackdoor watermarking could effectively detect IP Violation, while\ninference-time watermark distillation is applicable in both scenarios but less\nrobust to further fine-tuning and has a more significant impact on LLM\nperformance compared to backdoor watermarking. Exploring more advanced\nwatermarking methods for open-source LLMs to detect their misuse should be an\nimportant future direction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by the ICLR 2025 Workshop on GenAI Watermarking",
    "pdf_url": "http://arxiv.org/pdf/2503.04636v2",
    "published_date": "2025-03-06 17:24:06 UTC",
    "updated_date": "2025-03-15 20:03:47 UTC"
  },
  {
    "arxiv_id": "2503.04626v2",
    "title": "IDInit: A Universal and Stable Initialization Method for Neural Network Training",
    "authors": [
      "Yu Pan",
      "Chaozheng Wang",
      "Zekai Wu",
      "Qifan Wang",
      "Min Zhang",
      "Zenglin Xu"
    ],
    "abstract": "Deep neural networks have achieved remarkable accomplishments in practice.\nThe success of these networks hinges on effective initialization methods, which\nare vital for ensuring stable and rapid convergence during training. Recently,\ninitialization methods that maintain identity transition within layers have\nshown good efficiency in network training. These techniques (e.g., Fixup) set\nspecific weights to zero to achieve identity control. However, settings of\nremaining weight (e.g., Fixup uses random values to initialize non-zero\nweights) will affect the inductive bias that is achieved only by a zero weight,\nwhich may be harmful to training. Addressing this concern, we introduce fully\nidentical initialization (IDInit), a novel method that preserves identity in\nboth the main and sub-stem layers of residual networks. IDInit employs a padded\nidentity-like matrix to overcome rank constraints in non-square weight\nmatrices. Furthermore, we show the convergence problem of an identity matrix\ncan be solved by stochastic gradient descent. Additionally, we enhance the\nuniversality of IDInit by processing higher-order weights and addressing dead\nneuron problems. IDInit is a straightforward yet effective initialization\nmethod, with improved convergence, stability, and performance across various\nsettings, including large-scale datasets and deep models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04626v2",
    "published_date": "2025-03-06 17:12:46 UTC",
    "updated_date": "2025-03-09 16:31:31 UTC"
  },
  {
    "arxiv_id": "2503.04606v3",
    "title": "The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation",
    "authors": [
      "Aoxiong Yin",
      "Kai Shen",
      "Yichong Leng",
      "Xu Tan",
      "Xinyu Zhou",
      "Juncheng Li",
      "Siliang Tang"
    ],
    "abstract": "Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Kling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Our code is available at https://github.com/LanDiff/LanDiff",
    "pdf_url": "http://arxiv.org/pdf/2503.04606v3",
    "published_date": "2025-03-06 16:53:14 UTC",
    "updated_date": "2025-04-29 10:34:28 UTC"
  },
  {
    "arxiv_id": "2503.07649v2",
    "title": "TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster",
    "authors": [
      "Kanghui Ning",
      "Zijie Pan",
      "Yu Liu",
      "Yushan Jiang",
      "James Y. Zhang",
      "Kashif Rasul",
      "Anderson Schneider",
      "Lintao Ma",
      "Yuriy Nevmyvaka",
      "Dongjin Song"
    ],
    "abstract": "Recently, Large Language Models (LLMs) and Foundation Models (FMs) have\nbecome prevalent for time series forecasting tasks. However, fine-tuning large\nlanguage models (LLMs) for forecasting enables the adaptation to specific\ndomains but may not generalize well across diverse, unseen datasets. Meanwhile,\nexisting time series foundation models (TSFMs) lack inherent mechanisms for\ndomain adaptation and suffer from limited interpretability, making them\nsuboptimal for zero-shot forecasting. To this end, we present TS-RAG, a\nretrieval-augmented generation based time series forecasting framework that\nenhances the generalization capability and interpretability of TSFMs.\nSpecifically, TS-RAG leverages pre-trained time series encoders to retrieve\nsemantically relevant time series segments from a dedicated knowledge database,\nincorporating contextual patterns for the given time series query. Next, we\ndevelop a learnable Mixture-of-Experts (MoE)-based augmentation module, which\ndynamically fuses retrieved time series patterns with the TSFM's representation\nof the input query, improving forecasting accuracy without requiring\ntask-specific fine-tuning. Thorough empirical studies on seven public benchmark\ndatasets demonstrate that TS-RAG achieves state-of-the-art zero-shot\nforecasting performance, outperforming TSFMs by up to 6.51% across diverse\ndomains and showcasing desired interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07649v2",
    "published_date": "2025-03-06 16:48:48 UTC",
    "updated_date": "2025-04-01 21:23:59 UTC"
  },
  {
    "arxiv_id": "2503.04598v3",
    "title": "HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization",
    "authors": [
      "Zhijian Zhuo",
      "Yutao Zeng",
      "Ya Wang",
      "Sijun Zhang",
      "Jian Yang",
      "Xiaoqing Li",
      "Xun Zhou",
      "Jinwen Ma"
    ],
    "abstract": "Transformers have become the de facto architecture for a wide range of\nmachine learning tasks, particularly in large language models (LLMs). Despite\ntheir remarkable performance, challenges remain in training deep transformer\nnetworks, especially regarding the position of layer normalization. While\nPre-Norm structures facilitate more stable training owing to their stronger\nidentity path, they often lead to suboptimal performance compared to Post-Norm.\nIn this paper, we propose $\\textbf{HybridNorm}$, a simple yet effective hybrid\nnormalization strategy that integrates the advantages of both Pre-Norm and\nPost-Norm. Specifically, HybridNorm employs QKV normalization within the\nattention mechanism and Post-Norm in the feed-forward network (FFN) of each\ntransformer block. We provide both theoretical insights and empirical evidence\ndemonstrating that HybridNorm improves gradient flow and model robustness.\nExtensive experiments on large-scale transformer models, including both dense\nand sparse variants, show that HybridNorm consistently outperforms both\nPre-Norm and Post-Norm approaches across multiple benchmarks. These findings\nhighlight the potential of HybridNorm as a more stable and effective technique\nfor improving the training and performance of deep transformer models. Code is\navailable at https://github.com/BryceZhuo/HybridNorm.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04598v3",
    "published_date": "2025-03-06 16:40:48 UTC",
    "updated_date": "2025-05-22 14:53:31 UTC"
  },
  {
    "arxiv_id": "2503.04596v1",
    "title": "The Next Frontier of LLM Applications: Open Ecosystems and Hardware Synergy",
    "authors": [
      "Xinyi Hou",
      "Yanjie Zhao",
      "Haoyu Wang"
    ],
    "abstract": "Large Language Model (LLM) applications, including LLM app stores and\nautonomous agents, are shaping the future of AI ecosystems. However, platform\nsilos, fragmented hardware integration, and the absence of standardized\ninterfaces limit scalability, interoperability, and resource efficiency. While\nLLM app stores democratize AI, their closed ecosystems restrict modular AI\nreuse and cross-platform portability. Meanwhile, agent-based frameworks offer\nflexibility but often lack seamless integration across diverse environments.\nThis paper envisions the future of LLM applications and proposes a three-layer\ndecoupled architecture grounded in software engineering principles such as\nlayered system design, service-oriented architectures, and hardware-software\nco-design. This architecture separates application logic, communication\nprotocols, and hardware execution, enhancing modularity, efficiency, and\ncross-platform compatibility. Beyond architecture, we highlight key security\nand privacy challenges for safe, scalable AI deployment and outline research\ndirections in software and security engineering. This vision aims to foster\nopen, secure, and interoperable LLM ecosystems, guiding future advancements in\nAI applications.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04596v1",
    "published_date": "2025-03-06 16:38:23 UTC",
    "updated_date": "2025-03-06 16:38:23 UTC"
  },
  {
    "arxiv_id": "2503.04873v1",
    "title": "Are Large Language Models Good In-context Learners for Financial Sentiment Analysis?",
    "authors": [
      "Xinyu Wei",
      "Luojia Liu"
    ],
    "abstract": "Recently, large language models (LLMs) with hundreds of billions of\nparameters have demonstrated the emergent ability, surpassing traditional\nmethods in various domains even without fine-tuning over domain-specific data.\nHowever, when it comes to financial sentiment analysis (FSA)$\\unicode{x2013}$a\nfundamental task in financial AI$\\unicode{x2013}$these models often encounter\nvarious challenges, such as complex financial terminology, subjective human\nemotions, and ambiguous inclination expressions. In this paper, we aim to\nanswer the fundamental question: whether LLMs are good in-context learners for\nFSA? Unveiling this question can yield informative insights on whether LLMs can\nlearn to address the challenges by generalizing in-context demonstrations of\nfinancial document-sentiment pairs to the sentiment analysis of new documents,\ngiven that finetuning these models on finance-specific data is difficult, if\nnot impossible at all. To the best of our knowledge, this is the first paper\nexploring in-context learning for FSA that covers most modern LLMs (recently\nreleased DeepSeek V3 included) and multiple in-context sample selection\nmethods. Comprehensive experiments validate the in-context learning capability\nof LLMs for FSA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-fin.CP"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICLR 2025 Workshop on Advances in Financial AI",
    "pdf_url": "http://arxiv.org/pdf/2503.04873v1",
    "published_date": "2025-03-06 16:38:12 UTC",
    "updated_date": "2025-03-06 16:38:12 UTC"
  },
  {
    "arxiv_id": "2503.04872v2",
    "title": "TinyR1-32B-Preview: Boosting Accuracy with Branch-Merge Distillation",
    "authors": [
      "Lin Sun",
      "Guangxiang Zhao",
      "Xiaoqi Jian",
      "Yuhan Wu",
      "Weihong Lin",
      "Yongfu Zhu",
      "Change Jia",
      "Linglin Zhang",
      "Jinzhu Wu",
      "Junfeng Ran",
      "Sai-er Hu",
      "Zihan Jiang",
      "Junting Zhou",
      "Wenrui Liu",
      "Bin Cui",
      "Tong Yang",
      "Xiangzheng Zhang"
    ],
    "abstract": "The challenge of reducing the size of Large Language Models (LLMs) while\nmaintaining their performance has gained significant attention. However,\nexisting methods, such as model distillation and transfer learning, often fail\nto achieve high accuracy. To address this limitation, we introduce the\nBranch-Merge distillation approach, which enhances model compression through\ntwo phases: (1) the Branch Phase, where knowledge from a large teacher model is\n\\textit{selectively distilled} into specialized student models via\ndomain-specific supervised fine-tuning (SFT); And (2) the Merge Phase, where\nthese student models are merged to enable cross-domain knowledge transfer and\nimprove generalization. We validate our distillation approach using DeepSeek-R1\nas the teacher and DeepSeek-R1-Distill-Qwen-32B as the student. The resulting\nmerged model, TinyR1-32B-Preview, outperforms its counterpart\nDeepSeek-R1-Distill-Qwen-32B across multiple benchmarks, including Mathematics\n(+5.5 points), Coding (+4.4 points) and Science (+2.9 points), while achieving\nnear-equal performance to DeepSeek-R1 on AIME 2024. The Branch-Merge\ndistillation approach provides a scalable solution for creating smaller,\nhigh-performing LLMs with reduced computational cost and time.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.04872v2",
    "published_date": "2025-03-06 16:25:53 UTC",
    "updated_date": "2025-03-17 10:36:30 UTC"
  },
  {
    "arxiv_id": "2503.04569v1",
    "title": "ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making",
    "authors": [
      "Yitong Luo",
      "Hou Hei Lam",
      "Ziang Chen",
      "Zhenliang Zhang",
      "Xue Feng"
    ],
    "abstract": "Despite recent advances in artificial intelligence (AI), it poses challenges\nto ensure personalized decision-making in tasks that are not considered in\ntraining datasets. To address this issue, we propose ValuePilot, a two-phase\nvalue-driven decision-making framework comprising a dataset generation toolkit\nDGT and a decision-making module DMM trained on the generated data. DGT is\ncapable of generating scenarios based on value dimensions and closely mirroring\nreal-world tasks, with automated filtering techniques and human curation to\nensure the validity of the dataset. In the generated dataset, DMM learns to\nrecognize the inherent values of scenarios, computes action feasibility and\nnavigates the trade-offs between multiple value dimensions to make personalized\ndecisions. Extensive experiments demonstrate that, given human value\npreferences, our DMM most closely aligns with human decisions, outperforming\nClaude-3.5-Sonnet, Gemini-2-flash, Llama-3.1-405b and GPT-4o. This research is\na preliminary exploration of value-driven decision-making. We hope it will\nstimulate interest in value-driven decision-making and personalized\ndecision-making within the community.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04569v1",
    "published_date": "2025-03-06 16:02:53 UTC",
    "updated_date": "2025-03-06 16:02:53 UTC"
  },
  {
    "arxiv_id": "2503.04564v3",
    "title": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association",
    "authors": [
      "Xiang Zhang",
      "Zhou Li",
      "Kai Wan",
      "Hua Sun",
      "Mingyue Ji",
      "Giuseppe Caire"
    ],
    "abstract": "Secure aggregation is motivated by federated learning (FL) where a cloud\nserver aims to compute an averaged model (i.e., weights of deep neural\nnetworks) of the locally-trained models of numerous clients, while adhering to\ndata security requirements. Hierarchical secure aggregation (HSA) extends this\nconcept to a three-layer network, where clustered users communicate with the\nserver through an intermediate layer of relays. In HSA, beyond conventional\nserver security, relay security is also enforced to ensure that the relays\nremain oblivious to the users' inputs (an abstraction of the local models in\nFL). Existing study on HSA assumes that each user is associated with only one\nrelay, limiting opportunities for coding across inter-cluster users to achieve\nefficient communication and key generation. In this paper, we consider HSA with\na cyclic association pattern where each user is connected to $B$ consecutive\nrelays in a wrap-around manner. We propose an efficient aggregation scheme\nwhich includes a message design for the inputs inspired by gradient coding-a\nwell-known technique for efficient communication in distributed computing-along\nwith a highly nontrivial security key design. We also derive novel converse\nbounds on the minimum achievable communication and key rates using\ninformation-theoretic arguments.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.CR",
      "cs.DC",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04564v3",
    "published_date": "2025-03-06 15:53:37 UTC",
    "updated_date": "2025-05-21 20:35:06 UTC"
  },
  {
    "arxiv_id": "2503.04556v2",
    "title": "Compositional Causal Reasoning Evaluation in Language Models",
    "authors": [
      "Jacqueline R. M. A. Maasch",
      "Alihan Hüyük",
      "Xinnuo Xu",
      "Aditya V. Nori",
      "Javier Gonzalez"
    ],
    "abstract": "Causal reasoning and compositional reasoning are two core aspirations in\ngenerative AI. Measuring the extent of these behaviors requires principled\nevaluation methods. We explore a unified perspective that considers both\nbehaviors simultaneously, termed compositional causal reasoning (CCR): the\nability to infer how causal measures compose and, equivalently, how causal\nquantities propagate through graphs. We instantiate a framework for the\nsystematic evaluation of CCR for the average treatment effect and the\nprobability of necessity and sufficiency. As proof of concept, we demonstrate\nthe design of CCR tasks for language models in the LLama, Phi, and GPT\nfamilies. On a math word problem, our framework revealed a range of\ntaxonomically distinct error patterns. Additionally, CCR errors increased with\nthe complexity of causal paths for all models except o1.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04556v2",
    "published_date": "2025-03-06 15:47:19 UTC",
    "updated_date": "2025-03-16 16:22:47 UTC"
  },
  {
    "arxiv_id": "2503.04550v1",
    "title": "Benchmarking Reasoning Robustness in Large Language Models",
    "authors": [
      "Tong Yu",
      "Yongcheng Jing",
      "Xikun Zhang",
      "Wentao Jiang",
      "Wenjie Wu",
      "Yingjie Wang",
      "Wenbin Hu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "abstract": "Despite the recent success of large language models (LLMs) in reasoning such\nas DeepSeek, we for the first time identify a key dilemma in reasoning\nrobustness and generalization: significant performance degradation on novel or\nincomplete data, suggesting a reliance on memorized patterns rather than\nsystematic reasoning. Our closer examination reveals four key unique\nlimitations underlying this issue:(1) Positional bias--models favor earlier\nqueries in multi-query inputs but answering the wrong one in the latter (e.g.,\nGPT-4o's accuracy drops from 75.8 percent to 72.8 percent); (2) Instruction\nsensitivity--performance declines by 5.0 to 7.5 percent in the Qwen2.5 Series\nand by 5.0 percent in DeepSeek-V3 with auxiliary guidance; (3) Numerical\nfragility--value substitution sharply reduces accuracy (e.g., GPT-4o drops from\n97.5 percent to 82.5 percent, GPT-o1-mini drops from 97.5 percent to 92.5\npercent); and (4) Memory dependence--models resort to guesswork when missing\ncritical data. These findings further highlight the reliance on heuristic\nrecall over rigorous logical inference, demonstrating challenges in reasoning\nrobustness. To comprehensively investigate these robustness challenges, this\npaper introduces a novel benchmark, termed as Math-RoB, that exploits\nhallucinations triggered by missing information to expose reasoning gaps. This\nis achieved by an instruction-based approach to generate diverse datasets that\nclosely resemble training distributions, facilitating a holistic robustness\nassessment and advancing the development of more robust reasoning frameworks.\nBad character(s) in field Abstract.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04550v1",
    "published_date": "2025-03-06 15:36:06 UTC",
    "updated_date": "2025-03-06 15:36:06 UTC"
  },
  {
    "arxiv_id": "2503.04543v1",
    "title": "Keeping Yourself is Important in Downstream Tuning Multimodal Large Language Model",
    "authors": [
      "Wenke Huang",
      "Jian Liang",
      "Xianda Guo",
      "Yiyang Fang",
      "Guancheng Wan",
      "Xuankun Rong",
      "Chi Wen",
      "Zekun Shi",
      "Qingyun Li",
      "Didi Zhu",
      "Yanbiao Ma",
      "Ke Liang",
      "Bin Yang",
      "He Li",
      "Jiawei Shao",
      "Mang Ye",
      "Bo Du"
    ],
    "abstract": "Multi-modal Large Language Models (MLLMs) integrate visual and linguistic\nreasoning to address complex tasks such as image captioning and visual question\nanswering. While MLLMs demonstrate remarkable versatility, MLLMs appears\nlimited performance on special applications. But tuning MLLMs for downstream\ntasks encounters two key challenges: Task-Expert Specialization, where\ndistribution shifts between pre-training and target datasets constrain target\nperformance, and Open-World Stabilization, where catastrophic forgetting erases\nthe model general knowledge. In this work, we systematically review recent\nadvancements in MLLM tuning methodologies, classifying them into three\nparadigms: (I) Selective Tuning, (II) Additive Tuning, and (III)\nReparameterization Tuning. Furthermore, we benchmark these tuning strategies\nacross popular MLLM architectures and diverse downstream tasks to establish\nstandardized evaluation analysis and systematic tuning principles. Finally, we\nhighlight several open challenges in this domain and propose future research\ndirections. To facilitate ongoing progress in this rapidly evolving field, we\nprovide a public repository that continuously tracks developments:\nhttps://github.com/WenkeHuang/Awesome-MLLM-Tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04543v1",
    "published_date": "2025-03-06 15:29:13 UTC",
    "updated_date": "2025-03-06 15:29:13 UTC"
  },
  {
    "arxiv_id": "2503.04530v3",
    "title": "SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning",
    "authors": [
      "Chen Li",
      "Yinyi Luo",
      "Anudeep Bolimera",
      "Uzair Ahmed",
      "Shri Kiran Srinivasan",
      "Hrishikesh Gokhale",
      "Marios Savvides"
    ],
    "abstract": "Large Language Models excel in reasoning yet often rely on Chain-of-Thought\nprompts, limiting performance on tasks demanding more nuanced topological\nstructures. We present SOLAR (Scalable Optimization of Large-scale Architecture\nfor Reasoning), a framework that dynamically optimizes Chain-of-Thought (CoT),\nTree-of-Thought (ToT), and Graph-of-Thought (GoT) topologies to boost accuracy\nand efficiency. Our Topological-Annotation-Generation (TAG) system automates\ndataset creation, annotation, and difficulty segmentation, leading to stronger\npost training and test-time performance. We also propose Topological-Scaling, a\ncurriculum-learning-based approach that adaptively combines post training and\ninference scaling to each task. On MATH and GSM8K, SOLAR delivers notable\ngains: +5% accuracy with Topological Tuning, +9% with Topological Rewarding,\nand +10.02% with Hybrid Scaling, while reducing response length by over 5%,\nlowering inference latency. To further enhance efficiency, we introduce a\nmulti-task Topological Reward Model (M-TRM) that selects both the optimal\nreasoning topology and final answer in a single pass, eliminating multiple\nsingle-task TRMs. Remarkably, M-TRM also surpasses all single-task TRMs,\nimproving accuracy by +10% and rank correlation by +9%. Overall, SOLAR\nestablishes a new benchmark for scalable, high-precision LLM reasoning and\nintroduces a fully automated, dynamic topology competition mechanism.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04530v3",
    "published_date": "2025-03-06 15:19:17 UTC",
    "updated_date": "2025-05-16 06:02:04 UTC"
  },
  {
    "arxiv_id": "2503.04869v1",
    "title": "Label Distribution Learning-Enhanced Dual-KNN for Text Classification",
    "authors": [
      "Bo Yuan",
      "Yulin Chen",
      "Zhen Tan",
      "Wang Jinyan",
      "Huan Liu",
      "Yin Zhang"
    ],
    "abstract": "Many text classification methods usually introduce external information\n(e.g., label descriptions and knowledge bases) to improve the classification\nperformance. Compared to external information, some internal information\ngenerated by the model itself during training, like text embeddings and\npredicted label probability distributions, are exploited poorly when predicting\nthe outcomes of some texts. In this paper, we focus on leveraging this internal\ninformation, proposing a dual $k$ nearest neighbor (D$k$NN) framework with two\n$k$NN modules, to retrieve several neighbors from the training set and augment\nthe distribution of labels. For the $k$NN module, it is easily confused and may\ncause incorrect predictions when retrieving some nearest neighbors from noisy\ndatasets (datasets with labeling errors) or similar datasets (datasets with\nsimilar labels). To address this issue, we also introduce a label distribution\nlearning module that can learn label similarity, and generate a better label\ndistribution to help models distinguish texts more effectively. This module\neases model overfitting and improves final classification performance, hence\nenhancing the quality of the retrieved neighbors by $k$NN modules during\ninference. Extensive experiments on the benchmark datasets verify the\neffectiveness of our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by SDM 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.04869v1",
    "published_date": "2025-03-06 15:15:26 UTC",
    "updated_date": "2025-03-06 15:15:26 UTC"
  },
  {
    "arxiv_id": "2503.04521v1",
    "title": "Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market",
    "authors": [
      "Songyuan Li",
      "Jia Hu",
      "Geyong Min",
      "Haojun Huang",
      "Jiwei Huang"
    ],
    "abstract": "The convergence of edge computing and AI gives rise to Edge-AI, which enables\nthe deployment of real-time AI applications and services at the network edge.\nOne of the fundamental research issues in Edge-AI is edge inference\nacceleration, which aims to realize low-latency high-accuracy DNN inference\nservices by leveraging the fine-grained offloading of partitioned inference\ntasks from end devices to edge servers. However, existing research has yet to\nadopt a practical Edge-AI market perspective, which would systematically\nexplore the personalized inference needs of AI users (e.g., inference accuracy,\nlatency, and task complexity), the revenue incentives for AI service providers\nthat offer edge inference services, and multi-stakeholder governance within a\nmarket-oriented context. To bridge this gap, we propose an Auction-based Edge\nInference Pricing Mechanism (AERIA) for revenue maximization to tackle the\nmulti-dimensional optimization problem of DNN model partition, edge inference\npricing, and resource allocation. We investigate the multi-exit device-edge\nsynergistic inference scheme for on-demand DNN inference acceleration, and\nanalyse the auction dynamics amongst the AI service providers, AI users and\nedge infrastructure provider. Owing to the strategic mechanism design via\nrandomized consensus estimate and cost sharing techniques, the Edge-AI market\nattains several desirable properties, including competitiveness in revenue\nmaximization, incentive compatibility, and envy-freeness, which are crucial to\nmaintain the effectiveness, truthfulness, and fairness of our auction outcomes.\nThe extensive simulation experiments based on four representative DNN inference\nworkloads demonstrate that our AERIA mechanism significantly outperforms\nseveral state-of-the-art approaches in revenue maximization, demonstrating the\nefficacy of AERIA for on-demand DNN inference in the Edge-AI market.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.DC",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Index Terms: Edge-AI, DNN Inference Offloading, Resource Management,\n  Dynamic Pricing, Auction Mechanism",
    "pdf_url": "http://arxiv.org/pdf/2503.04521v1",
    "published_date": "2025-03-06 15:08:31 UTC",
    "updated_date": "2025-03-06 15:08:31 UTC"
  },
  {
    "arxiv_id": "2503.04509v1",
    "title": "STX-Search: Explanation Search for Continuous Dynamic Spatio-Temporal Models",
    "authors": [
      "Saif Anwar",
      "Nathan Griffiths",
      "Thomas Popham",
      "Abhir Bhalerao"
    ],
    "abstract": "Recent improvements in the expressive power of spatio-temporal models have\nled to performance gains in many real-world applications, such as traffic\nforecasting and social network modelling. However, understanding the\npredictions from a model is crucial to ensure reliability and trustworthiness,\nparticularly for high-risk applications, such as healthcare and transport. Few\nexisting methods are able to generate explanations for models trained on\ncontinuous-time dynamic graph data and, of these, the computational complexity\nand lack of suitable explanation objectives pose challenges. In this paper, we\npropose $\\textbf{S}$patio-$\\textbf{T}$emporal E$\\textbf{X}$planation\n$\\textbf{Search}$ (STX-Search), a novel method for generating instance-level\nexplanations that is applicable to static and dynamic temporal graph\nstructures. We introduce a novel search strategy and objective function, to\nfind explanations that are highly faithful and interpretable. When compared\nwith existing methods, STX-Search produces explanations of higher fidelity\nwhilst optimising explanation size to maintain interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04509v1",
    "published_date": "2025-03-06 14:55:25 UTC",
    "updated_date": "2025-03-06 14:55:25 UTC"
  },
  {
    "arxiv_id": "2503.04506v1",
    "title": "Multi-modal Summarization in Model-Based Engineering: Automotive Software Development Case Study",
    "authors": [
      "Nenad Petrovic",
      "Yurui Zhang",
      "Moaad Maaroufi",
      "Kuo-Yi Chao",
      "Lukasz Mazur",
      "Fengjunjie Pan",
      "Vahid Zolfaghari",
      "Alois Knoll"
    ],
    "abstract": "Multimodal summarization integrating information from diverse data modalities\npresents a promising solution to aid the understanding of information within\nvarious processes. However, the application and advantages of multimodal\nsummarization have not received much attention in model-based engineering\n(MBE), where it has become a cornerstone in the design and development of\ncomplex systems, leveraging formal models to improve understanding, validation\nand automation throughout the engineering lifecycle. UML and EMF diagrams in\nmodel-based engineering contain a large amount of multimodal information and\nintricate relational data. Hence, our study explores the application of\nmultimodal large language models within the domain of model-based engineering\nto evaluate their capacity for understanding and identifying relationships,\nfeatures, and functionalities embedded in UML and EMF diagrams. We aim to\ndemonstrate the transformative potential benefits and limitations of multimodal\nsummarization in improving productivity and accuracy in MBE practices. The\nproposed approach is evaluated within the context of automotive software\ndevelopment, while many promising state-of-art models were taken into account.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Conference paper accepted for IntelliSys2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04506v1",
    "published_date": "2025-03-06 14:53:37 UTC",
    "updated_date": "2025-03-06 14:53:37 UTC"
  },
  {
    "arxiv_id": "2503.04502v1",
    "title": "Interpretable Transformation and Analysis of Timelines through Learning via Surprisability",
    "authors": [
      "Osnat Mokryn",
      "Teddy Lazebnik",
      "Hagit Ben Shoshan"
    ],
    "abstract": "The analysis of high-dimensional timeline data and the identification of\noutliers and anomalies is critical across diverse domains, including sensor\nreadings, biological and medical data, historical records, and global\nstatistics. However, conventional analysis techniques often struggle with\nchallenges such as high dimensionality, complex distributions, and sparsity.\nThese limitations hinder the ability to extract meaningful insights from\ncomplex temporal datasets, making it difficult to identify trending features,\noutliers, and anomalies effectively. Inspired by surprisability -- a cognitive\nscience concept describing how humans instinctively focus on unexpected\ndeviations - we propose Learning via Surprisability (LvS), a novel approach for\ntransforming high-dimensional timeline data. LvS quantifies and prioritizes\nanomalies in time-series data by formalizing deviations from expected behavior.\nLvS bridges cognitive theories of attention with computational methods,\nenabling the detection of anomalies and shifts in a way that preserves critical\ncontext, offering a new lens for interpreting complex datasets. We demonstrate\nthe usefulness of LvS on three high-dimensional timeline use cases: a time\nseries of sensor data, a global dataset of mortality causes over multiple\nyears, and a textual corpus containing over two centuries of State of the Union\nAddresses by U.S. presidents. Our results show that the LvS transformation\nenables efficient and interpretable identification of outliers, anomalies, and\nthe most variable features along the timeline.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04502v1",
    "published_date": "2025-03-06 14:50:29 UTC",
    "updated_date": "2025-03-06 14:50:29 UTC"
  },
  {
    "arxiv_id": "2503.04500v2",
    "title": "ReynoldsFlow: Exquisite Flow Estimation via Reynolds Transport Theorem",
    "authors": [
      "Yu-Hsi Chen",
      "Chin-Tien Wu"
    ],
    "abstract": "Optical flow is a fundamental technique for motion estimation, widely applied\nin video stabilization, interpolation, and object tracking. Traditional optical\nflow estimation methods rely on restrictive assumptions like brightness\nconstancy and slow motion constraints. Recent deep learning-based flow\nestimations require extensive training on large domain-specific datasets,\nmaking them computationally demanding. Also, artificial intelligence (AI)\nadvances have enabled deep learning models to take advantage of optical flow as\nan important feature for object tracking and motion analysis. Since optical\nflow is commonly encoded in HSV for visualization, its conversion to RGB for\nneural network processing is nonlinear and may introduce perceptual\ndistortions. These transformations amplify the sensitivity to estimation\nerrors, potentially affecting the predictive accuracy of the networks. To\naddress these challenges that are influential to the performance of downstream\nnetwork models, we propose Reynolds flow, a novel training-free flow estimation\ninspired by the Reynolds transport theorem, offering a principled approach to\nmodeling complex motion dynamics. In addition to conventional HSV-based\nvisualization of Reynolds flow, we also introduce an RGB-encoded representation\nof Reynolds flow designed to improve flow visualization and feature enhancement\nfor neural networks. We evaluated the effectiveness of Reynolds flow in\nvideo-based tasks. Experimental results on three benchmarks, tiny object\ndetection on UAVDB, infrared object detection on Anti-UAV, and pose estimation\non GolfDB, demonstrate that networks trained with RGB-encoded Reynolds flow\nachieve SOTA performance, exhibiting improved robustness and efficiency across\nall tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.04500v2",
    "published_date": "2025-03-06 14:49:28 UTC",
    "updated_date": "2025-03-09 17:47:41 UTC"
  },
  {
    "arxiv_id": "2503.15538v1",
    "title": "There must be encapsulated nonconceptual content in vision",
    "authors": [
      "Vincent C. Müller"
    ],
    "abstract": "In this paper I want to propose an argument to support Jerry Fodor's thesis\n(Fodor 1983) that input systems are modular and thus informationally\nencapsulated. The argument starts with the suggestion that there is a\n\"grounding problem\" in perception, i. e. that there is a problem in explaining\nhow perception that can yield a visual experience is possible, how sensation\ncan become meaningful perception of something for the subject. Given that\nvisual experience is actually possible, this invites a transcendental argument\nthat explains the conditions of its possibility. I propose that one of these\nconditions is the existence of a visual module in Fodor's sense that allows the\nstep from sensation to object-identifying perception, thus enabling visual\nexperience. It seems to follow that there is informationally encapsulated\nnonconceptual content in visual perception.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15538v1",
    "published_date": "2025-03-06 14:44:55 UTC",
    "updated_date": "2025-03-06 14:44:55 UTC"
  },
  {
    "arxiv_id": "2503.04482v1",
    "title": "Generalized Interpolating Discrete Diffusion",
    "authors": [
      "Dimitri von Rütte",
      "Janis Fluri",
      "Yuhui Ding",
      "Antonio Orvieto",
      "Bernhard Schölkopf",
      "Thomas Hofmann"
    ],
    "abstract": "While state-of-the-art language models achieve impressive results through\nnext-token prediction, they have inherent limitations such as the inability to\nrevise already generated tokens. This has prompted exploration of alternative\napproaches such as discrete diffusion. However, masked diffusion, which has\nemerged as a popular choice due to its simplicity and effectiveness,\nreintroduces this inability to revise words. To overcome this, we generalize\nmasked diffusion and derive the theoretical backbone of a family of general\ninterpolating discrete diffusion (GIDD) processes offering greater flexibility\nin the design of the noising processes. Leveraging a novel diffusion ELBO, we\nachieve compute-matched state-of-the-art performance in diffusion language\nmodeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining\nmasking and uniform noise, leading to improved sample quality and unlocking the\nability for the model to correct its own mistakes, an area where autoregressive\nmodels notoriously have struggled. Our code and models are open-source:\nhttps://github.com/dvruette/gidd/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04482v1",
    "published_date": "2025-03-06 14:30:55 UTC",
    "updated_date": "2025-03-06 14:30:55 UTC"
  },
  {
    "arxiv_id": "2503.04479v3",
    "title": "ToolFuzz -- Automated Agent Tool Testing",
    "authors": [
      "Ivan Milev",
      "Mislav Balunović",
      "Maximilian Baader",
      "Martin Vechev"
    ],
    "abstract": "Large Language Model (LLM) Agents leverage the advanced reasoning\ncapabilities of LLMs in real-world applications. To interface with an\nenvironment, these agents often rely on tools, such as web search or database\nAPIs. As the agent provides the LLM with tool documentation along the user\nquery, the completeness and correctness of this documentation is critical.\nHowever, tool documentation is often over-, under-, or ill-specified, impeding\nthe agent's accuracy. Standard software testing approaches struggle to identify\nthese errors as they are expressed in natural language. Thus, despite its\nimportance, there currently exists no automated method to test the tool\ndocumentation for agents. To address this issue, we present ToolFuzz, the first\nmethod for automated testing of tool documentations. ToolFuzz is designed to\ndiscover two types of errors: (1) user queries leading to tool runtime errors\nand (2) user queries that lead to incorrect agent responses. ToolFuzz can\ngenerate a large and diverse set of natural inputs, effectively finding tool\ndescription errors at a low false positive rate. Further, we present two\nstraightforward prompt-engineering approaches. We evaluate all three tool\ntesting approaches on 32 common LangChain tools and 35 newly created custom\ntools and 2 novel benchmarks to further strengthen the assessment. We find that\nmany publicly available tools suffer from underspecification. Specifically, we\nshow that ToolFuzz identifies 20x more erroneous inputs compared to the\nprompt-engineering approaches, making it a key component for building reliable\nAI agents.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04479v3",
    "published_date": "2025-03-06 14:29:52 UTC",
    "updated_date": "2025-03-11 14:28:13 UTC"
  },
  {
    "arxiv_id": "2503.04472v1",
    "title": "DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models",
    "authors": [
      "Yi Shen",
      "Jian Zhang",
      "Jieyun Huang",
      "Shuming Shi",
      "Wenjing Zhang",
      "Jiangze Yan",
      "Ning Wang",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "abstract": "Recent advancements in slow-thinking reasoning models have shown exceptional\nperformance in complex reasoning tasks. However, these models often exhibit\noverthinking-generating redundant reasoning steps for simple problems, leading\nto excessive computational resource usage. While current mitigation strategies\nuniformly reduce reasoning tokens, they risk degrading performance on\nchallenging tasks that require extended reasoning. This paper introduces\nDifficulty-Adaptive Slow-Thinking (DAST), a novel framework that enables models\nto autonomously adjust the length of Chain-of-Thought(CoT) based on problem\ndifficulty. We first propose a Token Length Budget (TLB) metric to quantify\ndifficulty, then leveraging length-aware reward shaping and length preference\noptimization to implement DAST. DAST penalizes overlong responses for simple\ntasks while incentivizing sufficient reasoning for complex problems.\nExperiments on diverse datasets and model scales demonstrate that DAST\neffectively mitigates overthinking (reducing token usage by over 30\\% on\naverage) while preserving reasoning accuracy on complex problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "working in progress",
    "pdf_url": "http://arxiv.org/pdf/2503.04472v1",
    "published_date": "2025-03-06 14:23:06 UTC",
    "updated_date": "2025-03-06 14:23:06 UTC"
  },
  {
    "arxiv_id": "2503.04457v1",
    "title": "TPC: Cross-Temporal Prediction Connection for Vision-Language Model Hallucination Reduction",
    "authors": [
      "Chao Wang",
      "Weiwei Fu",
      "Yang Zhou"
    ],
    "abstract": "Vision-language models (VLMs) have achieved remarkable advancements,\ncapitalizing on the impressive capabilities of large language models (LLMs)\nacross diverse tasks. Despite this, a critical challenge known as hallucination\noccurs when models overconfidently describe objects or attributes absent from\nthe image, a problem exacerbated by the tendency of VLMs to rely on linguistic\npriors. This limitation reduces model reliability in high-stakes applications.\nIn this work, we have observed the characteristic of logits' continuity\nconsistency enhancement and introduced a straightforward and efficient method,\nCross-Temporal Prediction Connection (TPC), designed to enhance the semantic\nconsistency of logits by connecting them temporally across timesteps. TPC\namplifies information flow and improves coherence, effectively reducing\nhallucination. Extensive experiments show that TPC surpasses existing\nrepresentatives, delivering superior performance in both accuracy and\nefficiency while maintaining robustness in open-ended text generation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04457v1",
    "published_date": "2025-03-06 14:11:00 UTC",
    "updated_date": "2025-03-06 14:11:00 UTC"
  },
  {
    "arxiv_id": "2503.04451v1",
    "title": "Privacy Preserving and Robust Aggregation for Cross-Silo Federated Learning in Non-IID Settings",
    "authors": [
      "Marco Arazzi",
      "Mert Cihangiroglu",
      "Antonino Nocera"
    ],
    "abstract": "Federated Averaging remains the most widely used aggregation strategy in\nfederated learning due to its simplicity and scalability. However, its\nperformance degrades significantly in non-IID data settings, where client\ndistributions are highly imbalanced or skewed. Additionally, it relies on\nclients transmitting metadata, specifically the number of training samples,\nwhich introduces privacy risks and may conflict with regulatory frameworks like\nthe European GDPR. In this paper, we propose a novel aggregation strategy that\naddresses these challenges by introducing class-aware gradient masking. Unlike\ntraditional approaches, our method relies solely on gradient updates,\neliminating the need for any additional client metadata, thereby enhancing\nprivacy protection. Furthermore, our approach validates and dynamically weights\nclient contributions based on class-specific importance, ensuring robustness\nagainst non-IID distributions, convergence prevention, and backdoor attacks.\nExtensive experiments on benchmark datasets demonstrate that our method not\nonly outperforms FedAvg and other widely accepted aggregation strategies in\nnon-IID settings but also preserves model integrity in adversarial scenarios.\nOur results establish the effectiveness of gradient masking as a practical and\nsecure solution for federated learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04451v1",
    "published_date": "2025-03-06 14:06:20 UTC",
    "updated_date": "2025-03-06 14:06:20 UTC"
  },
  {
    "arxiv_id": "2504.06275v1",
    "title": "A Cascaded Architecture for Extractive Summarization of Multimedia Content via Audio-to-Text Alignment",
    "authors": [
      "Tanzir Hossain",
      "Ar-Rafi Islam",
      "Md. Sabbir Hossain",
      "Annajiat Alim Rasel"
    ],
    "abstract": "This study presents a cascaded architecture for extractive summarization of\nmultimedia content via audio-to-text alignment. The proposed framework\naddresses the challenge of extracting key insights from multimedia sources like\nYouTube videos. It integrates audio-to-text conversion using Microsoft Azure\nSpeech with advanced extractive summarization models, including Whisper,\nPegasus, and Facebook BART XSum. The system employs tools such as Pytube,\nPydub, and SpeechRecognition for content retrieval, audio extraction, and\ntranscription. Linguistic analysis is enhanced through named entity recognition\nand semantic role labeling. Evaluation using ROUGE and F1 scores demonstrates\nthat the cascaded architecture outperforms conventional summarization methods,\ndespite challenges like transcription errors. Future improvements may include\nmodel fine-tuning and real-time processing. This study contributes to\nmultimedia summarization by improving information retrieval, accessibility, and\nuser experience.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06275v1",
    "published_date": "2025-03-06 13:59:14 UTC",
    "updated_date": "2025-03-06 13:59:14 UTC"
  },
  {
    "arxiv_id": "2503.04429v2",
    "title": "Activation Space Interventions Can Be Transferred Between Large Language Models",
    "authors": [
      "Narmeen Oozeer",
      "Dhruv Nathawani",
      "Nirmalendu Prakash",
      "Michael Lan",
      "Abir Harrasse",
      "Amirali Abdullah"
    ],
    "abstract": "The study of representation universality in AI models reveals growing\nconvergence across domains, modalities, and architectures. However, the\npractical applications of representation universality remain largely\nunexplored. We bridge this gap by demonstrating that safety interventions can\nbe transferred between models through learned mappings of their shared\nactivation spaces. We demonstrate this approach on two well-established AI\nsafety tasks: backdoor removal and refusal of harmful prompts, showing\nsuccessful transfer of steering vectors that alter the models' outputs in a\npredictable way. Additionally, we propose a new task, \\textit{corrupted\ncapabilities}, where models are fine-tuned to embed knowledge tied to a\nbackdoor. This tests their ability to separate useful skills from backdoors,\nreflecting real-world challenges. Extensive experiments across Llama, Qwen and\nGemma model families show that our method enables using smaller models to\nefficiently align larger ones. Furthermore, we demonstrate that autoencoder\nmappings between base and fine-tuned models can serve as reliable ``lightweight\nsafety switches\", allowing dynamic toggling between model behaviors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "68 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.04429v2",
    "published_date": "2025-03-06 13:38:44 UTC",
    "updated_date": "2025-05-05 16:39:22 UTC"
  },
  {
    "arxiv_id": "2503.04422v1",
    "title": "PDX: A Data Layout for Vector Similarity Search",
    "authors": [
      "Leonardo Kuffo",
      "Elena Krippner",
      "Peter Boncz"
    ],
    "abstract": "We propose Partition Dimensions Across (PDX), a data layout for vectors\n(e.g., embeddings) that, similar to PAX [6], stores multiple vectors in one\nblock, using a vertical layout for the dimensions (Figure 1). PDX accelerates\nexact and approximate similarity search thanks to its dimension-by-dimension\nsearch strategy that operates on multiple-vectors-at-a-time in tight loops. It\nbeats SIMD-optimized distance kernels on standard horizontal vector storage\n(avg 40% faster), only relying on scalar code that gets auto-vectorized. We\ncombined the PDX layout with recent dimension-pruning algorithms ADSampling\n[19] and BSA [52] that accelerate approximate vector search. We found that\nthese algorithms on the horizontal vector layout can lose to SIMD-optimized\nlinear scans, even if they are SIMD-optimized. However, when used on PDX, their\nbenefit is restored to 2-7x. We find that search on PDX is especially fast if a\nlimited number of dimensions has to be scanned fully, which is what the\ndimension-pruning approaches do. We finally introduce PDX-BOND, an even more\nflexible dimension-pruning strategy, with good performance on exact search and\nreasonable performance on approximate search. Unlike previous pruning\nalgorithms, it can work on vector data \"as-is\" without preprocessing; making it\nattractive for vector databases with frequent updates.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "To be published in Proceedings of The 2025 International Conference\n  on Management of Data (SIGMOD '25). For associated code, see\n  https://github.com/cwida/PDX",
    "pdf_url": "http://arxiv.org/pdf/2503.04422v1",
    "published_date": "2025-03-06 13:31:16 UTC",
    "updated_date": "2025-03-06 13:31:16 UTC"
  },
  {
    "arxiv_id": "2503.04417v1",
    "title": "From Idea to CAD: A Language Model-Driven Multi-Agent System for Collaborative Design",
    "authors": [
      "Felix Ocker",
      "Stefan Menzel",
      "Ahmed Sadik",
      "Thiago Rios"
    ],
    "abstract": "Creating digital models using Computer Aided Design (CAD) is a process that\nrequires in-depth expertise. In industrial product development, this process\ntypically involves entire teams of engineers, spanning requirements\nengineering, CAD itself, and quality assurance. We present an approach that\nmirrors this team structure with a Vision Language Model (VLM)-based Multi\nAgent System, with access to parametric CAD tooling and tool documentation.\nCombining agents for requirements engineering, CAD engineering, and\nvision-based quality assurance, a model is generated automatically from\nsketches and/ or textual descriptions. The resulting model can be refined\ncollaboratively in an iterative validation loop with the user. Our approach has\nthe potential to increase the effectiveness of design processes, both for\nindustry experts and for hobbyists who create models for 3D printing. We\ndemonstrate the potential of the architecture at the example of various design\ntasks and provide several ablations that show the benefits of the\narchitecture's individual components.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "J.6; I.6.5; I.2.1; I.2.11; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04417v1",
    "published_date": "2025-03-06 13:21:27 UTC",
    "updated_date": "2025-03-06 13:21:27 UTC"
  },
  {
    "arxiv_id": "2503.04416v1",
    "title": "Learning Transformer-based World Models with Contrastive Predictive Coding",
    "authors": [
      "Maxime Burchi",
      "Radu Timofte"
    ],
    "abstract": "The DreamerV3 algorithm recently obtained remarkable performance across\ndiverse environment domains by learning an accurate world model based on\nRecurrent Neural Networks (RNNs). Following the success of model-based\nreinforcement learning algorithms and the rapid adoption of the Transformer\narchitecture for its superior training efficiency and favorable scaling\nproperties, recent works such as STORM have proposed replacing RNN-based world\nmodels with Transformer-based world models using masked self-attention.\nHowever, despite the improved training efficiency of these methods, their\nimpact on performance remains limited compared to the Dreamer algorithm,\nstruggling to learn competitive Transformer-based world models. In this work,\nwe show that the next state prediction objective adopted in previous approaches\nis insufficient to fully exploit the representation capabilities of\nTransformers. We propose to extend world model predictions to longer time\nhorizons by introducing TWISTER (Transformer-based World model wIth contraSTivE\nRepresentations), a world model using action-conditioned Contrastive Predictive\nCoding to learn high-level temporal feature representations and improve the\nagent performance. TWISTER achieves a human-normalized mean score of 162% on\nthe Atari 100k benchmark, setting a new record among state-of-the-art methods\nthat do not employ look-ahead search.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04416v1",
    "published_date": "2025-03-06 13:18:37 UTC",
    "updated_date": "2025-03-06 13:18:37 UTC"
  },
  {
    "arxiv_id": "2503.04412v1",
    "title": "Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search",
    "authors": [
      "Kou Misaki",
      "Yuichi Inoue",
      "Yuki Imajuku",
      "So Kuroki",
      "Taishi Nakamura",
      "Takuya Akiba"
    ],
    "abstract": "Recent advances demonstrate that increasing inference-time computation can\nsignificantly boost the reasoning capabilities of large language models (LLMs).\nAlthough repeated sampling (i.e., generating multiple candidate outputs) is a\nhighly effective strategy, it does not leverage external feedback signals for\nrefinement, which are often available in tasks like coding. In this work, we\npropose $\\textit{Adaptive Branching Monte Carlo Tree Search (AB-MCTS)}$, a\nnovel inference-time framework that generalizes repeated sampling with\nprincipled multi-turn exploration and exploitation. At each node in the search\ntree, AB-MCTS dynamically decides whether to \"go wider\" by expanding new\ncandidate responses or \"go deeper\" by revisiting existing ones based on\nexternal feedback signals. We evaluate our method on complex coding and\nengineering tasks using frontier models. Empirical results show that AB-MCTS\nconsistently outperforms both repeated sampling and standard MCTS, underscoring\nthe importance of combining the response diversity of LLMs with multi-turn\nsolution refinement for effective inference-time scaling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear at ICLR 2025 Workshop on Foundation Models in the Wild",
    "pdf_url": "http://arxiv.org/pdf/2503.04412v1",
    "published_date": "2025-03-06 13:10:40 UTC",
    "updated_date": "2025-03-06 13:10:40 UTC"
  },
  {
    "arxiv_id": "2503.04406v1",
    "title": "Training-Free Graph Filtering via Multimodal Feature Refinement for Extremely Fast Multimodal Recommendation",
    "authors": [
      "Yu-Seung Roh",
      "Joo-Young Kim",
      "Jin-Duk Park",
      "Won-Yong Shin"
    ],
    "abstract": "Multimodal recommender systems improve the performance of canonical\nrecommender systems with no item features by utilizing diverse content types\nsuch as text, images, and videos, while alleviating inherent sparsity of\nuser-item interactions and accelerating user engagement. However, current\nneural network-based models often incur significant computational overhead due\nto the complex training process required to learn and integrate information\nfrom multiple modalities. To overcome this limitation, we propose\nMultiModal-Graph Filtering (MM-GF), a training-free method based on the notion\nof graph filtering (GF) for efficient and accurate multimodal recommendations.\nSpecifically, MM-GF first constructs multiple similarity graphs through\nnontrivial multimodal feature refinement such as robust scaling and vector\nshifting by addressing the heterogeneous characteristics across modalities.\nThen, MM-GF optimally fuses multimodal information using linear low-pass\nfilters across different modalities. Extensive experiments on real-world\nbenchmark datasets demonstrate that MM-GF not only improves recommendation\naccuracy by up to 13.35% compared to the best competitor but also dramatically\nreduces computational costs by achieving the runtime of less than 10 seconds.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.SI",
      "math.IT"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.04406v1",
    "published_date": "2025-03-06 13:00:53 UTC",
    "updated_date": "2025-03-06 13:00:53 UTC"
  },
  {
    "arxiv_id": "2503.04398v3",
    "title": "Speculative MoE: Communication Efficient Parallel MoE Inference with Speculative Token and Expert Pre-scheduling",
    "authors": [
      "Yan Li",
      "Pengfei Zheng",
      "Shuang Chen",
      "Zewei Xu",
      "Yuanhao Lai",
      "Yunfei Du",
      "Zhengang Wang"
    ],
    "abstract": "MoE (Mixture of Experts) prevails as a neural architecture that can scale\nmodern transformer-based LLMs (Large Language Models) to unprecedented scales.\nNevertheless, large MoEs' great demands of computing power, memory capacity and\nmemory bandwidth make scalable serving a fundamental challenge and efficient\nparallel inference has become a requisite to attain adequate throughput under\nlatency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference\nframework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP\n(Tensor Parallel) and DP (Data Parallelism). However, our analysis shows\nDeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is\nimplemented with costly all-to-all collectives to route token activation. Our\nwork aims to boost DeepSpeed-MoE by strategically reducing EP's communication\noverhead with a technique named Speculative MoE. Speculative MoE has two\nspeculative parallelization schemes, speculative token shuffling and\nspeculative expert grouping, which predict outstanding tokens' expert routing\npaths and pre-schedule tokens and experts across devices to losslessly trim\nEP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE\ninto a prevailing MoE inference engine SGLang. Experiments show Speculative MoE\ncan significantly boost state-of-the-art MoE inference frameworks on fast\nhomogeneous and slow heterogeneous interconnects.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04398v3",
    "published_date": "2025-03-06 12:52:22 UTC",
    "updated_date": "2025-03-19 02:03:39 UTC"
  },
  {
    "arxiv_id": "2503.04392v1",
    "title": "AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management",
    "authors": [
      "Junyuan Mao",
      "Fanci Meng",
      "Yifan Duan",
      "Miao Yu",
      "Xiaojun Jia",
      "Junfeng Fang",
      "Yuxuan Liang",
      "Kun Wang",
      "Qingsong Wen"
    ],
    "abstract": "Large Language Model based multi-agent systems are revolutionizing autonomous\ncommunication and collaboration, yet they remain vulnerable to security threats\nlike unauthorized access and data breaches. To address this, we introduce\nAgentSafe, a novel framework that enhances MAS security through hierarchical\ninformation management and memory protection. AgentSafe classifies information\nby security levels, restricting sensitive data access to authorized agents.\nAgentSafe incorporates two components: ThreatSieve, which secures communication\nby verifying information authority and preventing impersonation, and\nHierarCache, an adaptive memory management system that defends against\nunauthorized access and malicious poisoning, representing the first systematic\ndefense for agent memory. Experiments across various LLMs show that AgentSafe\nsignificantly boosts system resilience, achieving defense success rates above\n80% under adversarial conditions. Additionally, AgentSafe demonstrates\nscalability, maintaining robust performance as agent numbers and information\ncomplexity grow. Results underscore effectiveness of AgentSafe in securing MAS\nand its potential for real-world application.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04392v1",
    "published_date": "2025-03-06 12:41:54 UTC",
    "updated_date": "2025-03-06 12:41:54 UTC"
  },
  {
    "arxiv_id": "2503.04378v1",
    "title": "Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks",
    "authors": [
      "Zhilin Wang",
      "Jiaqi Zeng",
      "Olivier Delalleau",
      "Daniel Egert",
      "Ellie Evans",
      "Hoo-Chang Shin",
      "Felipe Soares",
      "Yi Dong",
      "Oleksii Kuchaiev"
    ],
    "abstract": "Inference-Time Scaling has been critical to the success of recent models such\nas OpenAI o1 and DeepSeek R1. However, many techniques used to train models for\ninference-time scaling require tasks to have answers that can be verified,\nlimiting their application to domains such as math, coding and logical\nreasoning. We take inspiration from how humans make first attempts, ask for\ndetailed feedback from others and make improvements based on such feedback\nacross a wide spectrum of open-ended endeavors. To this end, we collect data\nfor and train dedicated Feedback and Edit Models that are capable of performing\ninference-time scaling for open-ended general-domain tasks. In our setup, one\nmodel generates an initial response, which are given feedback by a second\nmodel, that are then used by a third model to edit the response. We show that\nperformance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo\ncan be boosted by scaling the number of initial response drafts, effective\nfeedback and edited responses. When scaled optimally, our setup based on 70B\nmodels from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7\nas of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and\nDeepSeek R1 with 92.3.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04378v1",
    "published_date": "2025-03-06 12:30:24 UTC",
    "updated_date": "2025-03-06 12:30:24 UTC"
  },
  {
    "arxiv_id": "2503.04363v1",
    "title": "Causally Reliable Concept Bottleneck Models",
    "authors": [
      "Giovanni De Felice",
      "Arianna Casanova Flores",
      "Francesco De Santis",
      "Silvia Santini",
      "Johannes Schneider",
      "Pietro Barbiero",
      "Alberto Termine"
    ],
    "abstract": "Concept-based models are an emerging paradigm in deep learning that\nconstrains the inference process to operate through human-interpretable\nconcepts, facilitating explainability and human interaction. However, these\narchitectures, on par with popular opaque neural models, fail to account for\nthe true causal mechanisms underlying the target phenomena represented in the\ndata. This hampers their ability to support causal reasoning tasks, limits\nout-of-distribution generalization, and hinders the implementation of fairness\nconstraints. To overcome these issues, we propose \\emph{Causally reliable\nConcept Bottleneck Models} (C$^2$BMs), a class of concept-based architectures\nthat enforce reasoning through a bottleneck of concepts structured according to\na model of the real-world causal mechanisms. We also introduce a pipeline to\nautomatically learn this structure from observational data and\n\\emph{unstructured} background knowledge (e.g., scientific literature).\nExperimental evidence suggest that C$^2$BM are more interpretable, causally\nreliable, and improve responsiveness to interventions w.r.t. standard opaque\nand concept-based models, while maintaining their accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04363v1",
    "published_date": "2025-03-06 12:06:54 UTC",
    "updated_date": "2025-03-06 12:06:54 UTC"
  },
  {
    "arxiv_id": "2503.04362v1",
    "title": "A Generalist Cross-Domain Molecular Learning Framework for Structure-Based Drug Discovery",
    "authors": [
      "Yiheng Zhu",
      "Mingyang Li",
      "Junlong Liu",
      "Kun Fu",
      "Jiansheng Wu",
      "Qiuyi Li",
      "Mingze Yin",
      "Jieping Ye",
      "Jian Wu",
      "Zheng Wang"
    ],
    "abstract": "Structure-based drug discovery (SBDD) is a systematic scientific process that\ndevelops new drugs by leveraging the detailed physical structure of the target\nprotein. Recent advancements in pre-trained models for biomolecules have\ndemonstrated remarkable success across various biochemical applications,\nincluding drug discovery and protein engineering. However, in most approaches,\nthe pre-trained models primarily focus on the characteristics of either small\nmolecules or proteins, without delving into their binding interactions which\nare essential cross-domain relationships pivotal to SBDD. To fill this gap, we\npropose a general-purpose foundation model named BIT (an abbreviation for\nBiomolecular Interaction Transformer), which is capable of encoding a range of\nbiochemical entities, including small molecules, proteins, and protein-ligand\ncomplexes, as well as various data formats, encompassing both 2D and 3D\nstructures. Specifically, we introduce Mixture-of-Domain-Experts (MoDE) to\nhandle the biomolecules from diverse biochemical domains and\nMixture-of-Structure-Experts (MoSE) to capture positional dependencies in the\nmolecular structures. The proposed mixture-of-experts approach enables BIT to\nachieve both deep fusion and domain-specific encoding, effectively capturing\nfine-grained molecular interactions within protein-ligand complexes. Then, we\nperform cross-domain pre-training on the shared Transformer backbone via\nseveral unified self-supervised denoising tasks. Experimental results on\nvarious benchmarks demonstrate that BIT achieves exceptional performance in\ndownstream tasks, including binding affinity prediction, structure-based\nvirtual screening, and molecular property prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04362v1",
    "published_date": "2025-03-06 12:04:56 UTC",
    "updated_date": "2025-03-06 12:04:56 UTC"
  },
  {
    "arxiv_id": "2503.04866v1",
    "title": "Privacy in Responsible AI: Approaches to Facial Recognition from Cloud Providers",
    "authors": [
      "Anna Elivanova"
    ],
    "abstract": "As the use of facial recognition technology is expanding in different\ndomains, ensuring its responsible use is gaining more importance. This paper\nconducts a comprehensive literature review of existing studies on facial\nrecognition technology from the perspective of privacy, which is one of the key\nResponsible AI principles.\n  Cloud providers, such as Microsoft, AWS, and Google, are at the forefront of\ndelivering facial-related technology services, but their approaches to\nresponsible use of these technologies vary significantly. This paper compares\nhow these cloud giants implement the privacy principle into their facial\nrecognition and detection services. By analysing their approaches, it\nidentifies both common practices and notable differences. The results of this\nresearch will be valuable for developers and businesses by providing them\ninsights into best practices of three major companies for integration\nresponsible AI, particularly privacy, into their cloud-based facial recognition\ntechnologies.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04866v1",
    "published_date": "2025-03-06 12:04:12 UTC",
    "updated_date": "2025-03-06 12:04:12 UTC"
  },
  {
    "arxiv_id": "2503.04357v1",
    "title": "scDD: Latent Codes Based scRNA-seq Dataset Distillation with Foundation Model Knowledge",
    "authors": [
      "Zhen Yu",
      "Jianan Han",
      "Yang Liu",
      "Qingchao Chen"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) technology has profiled hundreds of\nmillions of human cells across organs, diseases, development and perturbations\nto date. However, the high-dimensional sparsity, batch effect noise, category\nimbalance, and ever-increasing data scale of the original sequencing data pose\nsignificant challenges for multi-center knowledge transfer, data fusion, and\ncross-validation between scRNA-seq datasets. To address these barriers, (1) we\nfirst propose a latent codes-based scRNA-seq dataset distillation framework\nnamed scDD, which transfers and distills foundation model knowledge and\noriginal dataset information into a compact latent space and generates\nsynthetic scRNA-seq dataset by a generator to replace the original dataset.\nThen, (2) we propose a single-step conditional diffusion generator named SCDG,\nwhich perform single-step gradient back-propagation to help scDD optimize\ndistillation quality and avoid gradient decay caused by multi-step\nback-propagation. Meanwhile, SCDG ensures the scRNA-seq data characteristics\nand inter-class discriminability of the synthetic dataset through flexible\nconditional control and generation quality assurance. Finally, we propose a\ncomprehensive benchmark to evaluate the performance of scRNA-seq dataset\ndistillation in different data analysis tasks. It is validated that our\nproposed method can achieve 7.61% absolute and 15.70% relative improvement over\nprevious state-of-the-art methods on average task.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04357v1",
    "published_date": "2025-03-06 12:01:20 UTC",
    "updated_date": "2025-03-06 12:01:20 UTC"
  },
  {
    "arxiv_id": "2503.04343v1",
    "title": "Talking Back -- human input and explanations to interactive AI systems",
    "authors": [
      "Alan Dix",
      "Tommaso Turchi",
      "Ben Wilson",
      "Anna Monreale",
      "Matt Roach"
    ],
    "abstract": "While XAI focuses on providing AI explanations to humans, can the reverse -\nhumans explaining their judgments to AI - foster richer, synergistic human-AI\nsystems? This paper explores various forms of human inputs to AI and examines\nhow human explanations can guide machine learning models toward automated\njudgments and explanations that align more closely with human concepts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "I.2"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04343v1",
    "published_date": "2025-03-06 11:39:46 UTC",
    "updated_date": "2025-03-06 11:39:46 UTC"
  },
  {
    "arxiv_id": "2503.04328v1",
    "title": "Solving Word-Sense Disambiguation and Word-Sense Induction with Dictionary Examples",
    "authors": [
      "Tadej Škvorc",
      "Marko Robnik-Šikonja"
    ],
    "abstract": "Many less-resourced languages struggle with a lack of large, task-specific\ndatasets that are required for solving relevant tasks with modern\ntransformer-based large language models (LLMs). On the other hand, many\nlinguistic resources, such as dictionaries, are rarely used in this context\ndespite their large information contents. We show how LLMs can be used to\nextend existing language resources in less-resourced languages for two\nimportant tasks: word-sense disambiguation (WSD) and word-sense induction\n(WSI). We approach the two tasks through the related but much more accessible\nword-in-context (WiC) task where, given a pair of sentences and a target word,\na classification model is tasked with predicting whether the sense of a given\nword differs between sentences. We demonstrate that a well-trained model for\nthis task can distinguish between different word senses and can be adapted to\nsolve the WSD and WSI tasks. The advantage of using the WiC task, instead of\ndirectly predicting senses, is that the WiC task does not need pre-constructed\nsense inventories with a sufficient number of examples for each sense, which\nare rarely available in less-resourced languages. We show that sentence pairs\nfor the WiC task can be successfully generated from dictionary examples using\nLLMs. The resulting prediction models outperform existing models on WiC, WSD,\nand WSI tasks. We demonstrate our methodology on the Slovene language, where a\nmonolingual dictionary is available, but word-sense resources are tiny.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2503.04328v1",
    "published_date": "2025-03-06 11:27:55 UTC",
    "updated_date": "2025-03-06 11:27:55 UTC"
  },
  {
    "arxiv_id": "2503.04315v1",
    "title": "Provable Robust Overfitting Mitigation in Wasserstein Distributionally Robust Optimization",
    "authors": [
      "Shuang Liu",
      "Yihan Wang",
      "Yifan Zhu",
      "Yibo Miao",
      "Xiao-Shan Gao"
    ],
    "abstract": "Wasserstein distributionally robust optimization (WDRO) optimizes against\nworst-case distributional shifts within a specified uncertainty set, leading to\nenhanced generalization on unseen adversarial examples, compared to standard\nadversarial training which focuses on pointwise adversarial perturbations.\nHowever, WDRO still suffers fundamentally from the robust overfitting problem,\nas it does not consider statistical error. We address this gap by proposing a\nnovel robust optimization framework under a new uncertainty set for adversarial\nnoise via Wasserstein distance and statistical error via Kullback-Leibler\ndivergence, called the Statistically Robust WDRO. We establish a robust\ngeneralization bound for the new optimization framework, implying that\nout-of-distribution adversarial performance is at least as good as the\nstatistically robust training loss with high probability. Furthermore, we\nderive conditions under which Stackelberg and Nash equilibria exist between the\nlearner and the adversary, giving an optimal robust model in certain sense.\nFinally, through extensive experiments, we demonstrate that our method\nsignificantly mitigates robust overfitting and enhances robustness within the\nframework of WDRO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04315v1",
    "published_date": "2025-03-06 10:58:35 UTC",
    "updated_date": "2025-03-06 10:58:35 UTC"
  },
  {
    "arxiv_id": "2503.04302v1",
    "title": "Malware Detection at the Edge with Lightweight LLMs: A Performance Evaluation",
    "authors": [
      "Christian Rondanini",
      "Barbara Carminati",
      "Elena Ferrari",
      "Antonio Gaudiano",
      "Ashish Kundu"
    ],
    "abstract": "The rapid evolution of malware attacks calls for the development of\ninnovative detection methods, especially in resource-constrained edge\ncomputing. Traditional detection techniques struggle to keep up with modern\nmalware's sophistication and adaptability, prompting a shift towards advanced\nmethodologies like those leveraging Large Language Models (LLMs) for enhanced\nmalware detection. However, deploying LLMs for malware detection directly at\nedge devices raises several challenges, including ensuring accuracy in\nconstrained environments and addressing edge devices' energy and computational\nlimits. To tackle these challenges, this paper proposes an architecture\nleveraging lightweight LLMs' strengths while addressing limitations like\nreduced accuracy and insufficient computational power. To evaluate the\neffectiveness of the proposed lightweight LLM-based approach for edge\ncomputing, we perform an extensive experimental evaluation using several\nstate-of-the-art lightweight LLMs. We test them with several publicly available\ndatasets specifically designed for edge and IoT scenarios and different edge\nnodes with varying computational power and characteristics.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04302v1",
    "published_date": "2025-03-06 10:42:18 UTC",
    "updated_date": "2025-03-06 10:42:18 UTC"
  },
  {
    "arxiv_id": "2503.04865v1",
    "title": "E4: Energy-Efficient DNN Inference for Edge Video Analytics Via Early-Exit and DVFS",
    "authors": [
      "Ziyang Zhang",
      "Yang Zhao",
      "Ming-Ching Chang",
      "Changyao Lin",
      "Jie Liu"
    ],
    "abstract": "Deep neural network (DNN) models are increasingly popular in edge video\nanalytic applications. However, the compute-intensive nature of DNN models pose\nchallenges for energy-efficient inference on resource-constrained edge devices.\nMost existing solutions focus on optimizing DNN inference latency and accuracy,\noften overlooking energy efficiency. They also fail to account for the varying\ncomplexity of video frames, leading to sub-optimal performance in edge video\nanalytics. In this paper, we propose an Energy-Efficient Early-Exit (E4)\nframework that enhances DNN inference efficiency for edge video analytics by\nintegrating a novel early-exit mechanism with dynamic voltage and frequency\nscaling (DVFS) governors. It employs an attention-based cascade module to\nanalyze video frame diversity and automatically determine optimal DNN exit\npoints. Additionally, E4 features a just-in-time (JIT) profiler that uses\ncoordinate descent search to co-optimize CPU and GPU clock frequencies for each\nlayer before the DNN exit points. Extensive evaluations demonstrate that E4\noutperforms current state-of-the-art methods, achieving up to 2.8x speedup and\n26% average energy saving while maintaining high accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 5 figures, to be published in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04865v1",
    "published_date": "2025-03-06 10:41:28 UTC",
    "updated_date": "2025-03-06 10:41:28 UTC"
  },
  {
    "arxiv_id": "2503.04299v2",
    "title": "Mapping AI Benchmark Data to Quantitative Risk Estimates Through Expert Elicitation",
    "authors": [
      "Malcolm Murray",
      "Henry Papadatos",
      "Otter Quarks",
      "Pierre-François Gimenez",
      "Simeon Campos"
    ],
    "abstract": "The literature and multiple experts point to many potential risks from large\nlanguage models (LLMs), but there are still very few direct measurements of the\nactual harms posed. AI risk assessment has so far focused on measuring the\nmodels' capabilities, but the capabilities of models are only indicators of\nrisk, not measures of risk. Better modeling and quantification of AI risk\nscenarios can help bridge this disconnect and link the capabilities of LLMs to\ntangible real-world harm. This paper makes an early contribution to this field\nby demonstrating how existing AI benchmarks can be used to facilitate the\ncreation of risk estimates. We describe the results of a pilot study in which\nexperts use information from Cybench, an AI benchmark, to generate probability\nestimates. We show that the methodology seems promising for this purpose, while\nnoting improvements that can be made to further strengthen its application in\nquantitative AI risk assessment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04299v2",
    "published_date": "2025-03-06 10:39:47 UTC",
    "updated_date": "2025-03-10 13:00:00 UTC"
  },
  {
    "arxiv_id": "2503.04291v1",
    "title": "MathMistake Checker: A Comprehensive Demonstration for Step-by-Step Math Problem Mistake Finding by Prompt-Guided LLMs",
    "authors": [
      "Tianyang Zhang",
      "Zhuoxuan Jiang",
      "Haotian Zhang",
      "Lin Lin",
      "Shaohua Zhang"
    ],
    "abstract": "We propose a novel system, MathMistake Checker, designed to automate\nstep-by-step mistake finding in mathematical problems with lengthy answers\nthrough a two-stage process. The system aims to simplify grading, increase\nefficiency, and enhance learning experiences from a pedagogical perspective. It\nintegrates advanced technologies, including computer vision and the\nchain-of-thought capabilities of the latest large language models (LLMs). Our\nsystem supports open-ended grading without reference answers and promotes\npersonalized learning by providing targeted feedback. We demonstrate its\neffectiveness across various types of math problems, such as calculation and\nword problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04291v1",
    "published_date": "2025-03-06 10:19:01 UTC",
    "updated_date": "2025-03-06 10:19:01 UTC"
  },
  {
    "arxiv_id": "2503.04290v1",
    "title": "How Do Hackathons Foster Creativity? Towards AI Collaborative Evaluation of Creativity at Scale",
    "authors": [
      "Jeanette Falk",
      "Yiyi Chen",
      "Janet Rafner",
      "Mike Zhang",
      "Johannes Bjerva",
      "Alexander Nolte"
    ],
    "abstract": "Hackathons have become popular collaborative events for accelerating the\ndevelopment of creative ideas and prototypes. There are several case studies\nshowcasing creative outcomes across domains such as industry, education, and\nresearch. However, there are no large-scale studies on creativity in hackathons\nwhich can advance theory on how hackathon formats lead to creative outcomes. We\nconducted a computational analysis of 193,353 hackathon projects. By\noperationalizing creativity through usefulness and novelty, we refined our\ndataset to 10,363 projects, allowing us to analyze how participant\ncharacteristics, collaboration patterns, and hackathon setups influence the\ndevelopment of creative projects. The contribution of our paper is twofold: We\nidentified means for organizers to foster creativity in hackathons. We also\nexplore the use of large language models (LLMs) to augment the evaluation of\ncreative outcomes and discuss challenges and opportunities of doing this, which\nhas implications for creativity research at large.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted in Proceedings of the 2025 CHI Conference on Human Factors\n  in Computing Systems",
    "pdf_url": "http://arxiv.org/pdf/2503.04290v1",
    "published_date": "2025-03-06 10:17:52 UTC",
    "updated_date": "2025-03-06 10:17:52 UTC"
  },
  {
    "arxiv_id": "2503.04283v1",
    "title": "Explainable AI in Time-Sensitive Scenarios: Prefetched Offline Explanation Model",
    "authors": [
      "Fabio Michele Russo",
      "Carlo Metta",
      "Anna Monreale",
      "Salvatore Rinzivillo",
      "Fabio Pinelli"
    ],
    "abstract": "As predictive machine learning models become increasingly adopted and\nadvanced, their role has evolved from merely predicting outcomes to actively\nshaping them. This evolution has underscored the importance of Trustworthy AI,\nhighlighting the necessity to extend our focus beyond mere accuracy and toward\na comprehensive understanding of these models' behaviors within the specific\ncontexts of their applications. To further progress in explainability, we\nintroduce Poem, Prefetched Offline Explanation Model, a model-agnostic, local\nexplainability algorithm for image data. The algorithm generates exemplars,\ncounterexemplars and saliency maps to provide quick and effective explanations\nsuitable for time-sensitive scenarios. Leveraging an existing local algorithm,\n\\poem{} infers factual and counterfactual rules from data to create\nillustrative examples and opposite scenarios with an enhanced stability by\ndesign. A novel mechanism then matches incoming test points with an explanation\nbase and produces diverse exemplars, informative saliency maps and believable\ncounterexemplars. Experimental results indicate that Poem outperforms its\npredecessor Abele in speed and ability to generate more nuanced and varied\nexemplars alongside more insightful saliency maps and valuable\ncounterexemplars.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04283v1",
    "published_date": "2025-03-06 10:09:20 UTC",
    "updated_date": "2025-03-06 10:09:20 UTC"
  },
  {
    "arxiv_id": "2503.04280v2",
    "title": "Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation with Large Language Models",
    "authors": [
      "Niccolò Turcato",
      "Matteo Iovino",
      "Aris Synodinos",
      "Alberto Dalla Libera",
      "Ruggero Carli",
      "Pietro Falco"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) and Visual Language\nModels (VLMs) have significantly impacted robotics, enabling high-level\nsemantic motion planning applications. Reinforcement Learning (RL), a\ncomplementary paradigm, enables agents to autonomously optimize complex\nbehaviors through interaction and reward signals. However, designing effective\nreward functions for RL remains challenging, especially in real-world tasks\nwhere sparse rewards are insufficient and dense rewards require elaborate\ndesign. In this work, we propose Autonomous Reinforcement learning for Complex\nHumanInformed Environments (ARCHIE), an unsupervised pipeline leveraging GPT-4,\na pre-trained LLM, to generate reward functions directly from natural language\ntask descriptions. The rewards are used to train RL agents in simulated\nenvironments, where we formalize the reward generation process to enhance\nfeasibility. Additionally, GPT-4 automates the coding of task success criteria,\ncreating a fully automated, one-shot procedure for translating human-readable\ntext into deployable robot skills. Our approach is validated through extensive\nsimulated experiments on single-arm and bi-manual manipulation tasks using an\nABB YuMi collaborative robot, highlighting its practicality and effectiveness.\nTasks are demonstrated on the real robot setup.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04280v2",
    "published_date": "2025-03-06 10:08:44 UTC",
    "updated_date": "2025-03-07 10:06:29 UTC"
  },
  {
    "arxiv_id": "2503.04267v1",
    "title": "Prompt Programming: A Platform for Dialogue-based Computational Problem Solving with Generative AI Models",
    "authors": [
      "Victor-Alexandru Pădurean",
      "Paul Denny",
      "Alkis Gotovos",
      "Adish Singla"
    ],
    "abstract": "Computing students increasingly rely on generative AI tools for programming\nassistance, often without formal instruction or guidance. This highlights a\nneed to teach students how to effectively interact with AI models, particularly\nthrough natural language prompts, to generate and critically evaluate code for\nsolving computational tasks. To address this, we developed a novel platform for\nprompt programming that enables authentic dialogue-based interactions, supports\nproblems involving multiple interdependent functions, and offers on-request\nexecution of generated code. Data analysis from over 900 students in an\nintroductory programming course revealed high engagement, with the majority of\nprompts occurring within multi-turn dialogues. Problems with multiple\ninterdependent functions encouraged iterative refinement, with progression\ngraphs highlighting several common strategies. Students were highly selective\nabout the code they chose to test, suggesting that on-request execution of\ngenerated code promoted critical thinking. Given the growing importance of\nlearning dialogue-based programming with AI, we provide this tool as a publicly\naccessible resource, accompanied by a corpus of programming problems for\neducational use.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Preprint of the ITiCSE'25 paper",
    "pdf_url": "http://arxiv.org/pdf/2503.04267v1",
    "published_date": "2025-03-06 09:56:07 UTC",
    "updated_date": "2025-03-06 09:56:07 UTC"
  },
  {
    "arxiv_id": "2503.04262v1",
    "title": "Guidelines for Applying RL and MARL in Cybersecurity Applications",
    "authors": [
      "Vasilios Mavroudis",
      "Gregory Palmer",
      "Sara Farmer",
      "Kez Smithson Whitehead",
      "David Foster",
      "Adam Price",
      "Ian Miles",
      "Alberto Caron",
      "Stephen Pasteris"
    ],
    "abstract": "Reinforcement Learning (RL) and Multi-Agent Reinforcement Learning (MARL)\nhave emerged as promising methodologies for addressing challenges in automated\ncyber defence (ACD). These techniques offer adaptive decision-making\ncapabilities in high-dimensional, adversarial environments. This report\nprovides a structured set of guidelines for cybersecurity professionals and\nresearchers to assess the suitability of RL and MARL for specific use cases,\nconsidering factors such as explainability, exploration needs, and the\ncomplexity of multi-agent coordination. It also discusses key algorithmic\napproaches, implementation challenges, and real-world constraints, such as data\nscarcity and adversarial interference. The report further outlines open\nresearch questions, including policy optimality, agent cooperation levels, and\nthe integration of MARL systems into operational cybersecurity frameworks. By\nbridging theoretical advancements and practical deployment, these guidelines\naim to enhance the effectiveness of AI-driven cyber defence strategies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04262v1",
    "published_date": "2025-03-06 09:46:16 UTC",
    "updated_date": "2025-03-06 09:46:16 UTC"
  },
  {
    "arxiv_id": "2503.04261v1",
    "title": "VirtualXAI: A User-Centric Framework for Explainability Assessment Leveraging GPT-Generated Personas",
    "authors": [
      "Georgios Makridis",
      "Vasileios Koukos",
      "Georgios Fatouros",
      "Dimosthenis Kyriazis"
    ],
    "abstract": "In today's data-driven era, computational systems generate vast amounts of\ndata that drive the digital transformation of industries, where Artificial\nIntelligence (AI) plays a key role. Currently, the demand for eXplainable AI\n(XAI) has increased to enhance the interpretability, transparency, and\ntrustworthiness of AI models. However, evaluating XAI methods remains\nchallenging: existing evaluation frameworks typically focus on quantitative\nproperties such as fidelity, consistency, and stability without taking into\naccount qualitative characteristics such as satisfaction and interpretability.\nIn addition, practitioners face a lack of guidance in selecting appropriate\ndatasets, AI models, and XAI methods -a major hurdle in human-AI collaboration.\nTo address these gaps, we propose a framework that integrates quantitative\nbenchmarking with qualitative user assessments through virtual personas based\non the \"Anthology\" of backstories of the Large Language Model (LLM). Our\nframework also incorporates a content-based recommender system that leverages\ndataset-specific characteristics to match new input data with a repository of\nbenchmarked datasets. This yields an estimated XAI score and provides tailored\nrecommendations for both the optimal AI model and the XAI method for a given\nscenario.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04261v1",
    "published_date": "2025-03-06 09:44:18 UTC",
    "updated_date": "2025-03-06 09:44:18 UTC"
  },
  {
    "arxiv_id": "2503.04863v1",
    "title": "Manboformer: Learning Gaussian Representations via Spatial-temporal Attention Mechanism",
    "authors": [
      "Ziyue Zhao",
      "Qining Qi",
      "Jianfa Ma"
    ],
    "abstract": "Compared with voxel-based grid prediction, in the field of 3D semantic\noccupation prediction for autonomous driving, GaussianFormer proposed using 3D\nGaussian to describe scenes with sparse 3D semantic Gaussian based on objects\nis another scheme with lower memory requirements. Each 3D Gaussian function\nrepresents a flexible region of interest and its semantic features, which are\niteratively refined by the attention mechanism. In the experiment, it is found\nthat the Gaussian function required by this method is larger than the query\nresolution of the original dense grid network, resulting in impaired\nperformance. Therefore, we consider optimizing GaussianFormer by using unused\ntemporal information. We learn the Spatial-Temporal Self-attention Mechanism\nfrom the previous grid-given occupation network and improve it to\nGaussianFormer. The experiment was conducted with the NuScenes dataset, and the\nexperiment is currently underway.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04863v1",
    "published_date": "2025-03-06 09:40:46 UTC",
    "updated_date": "2025-03-06 09:40:46 UTC"
  },
  {
    "arxiv_id": "2503.04258v1",
    "title": "TAIL: Text-Audio Incremental Learning",
    "authors": [
      "Yingfei Sun",
      "Xu Gu",
      "Wei Ji",
      "Hanbin Zhao",
      "Hao Fei",
      "Yifang Yin",
      "Roger Zimmermann"
    ],
    "abstract": "Many studies combine text and audio to capture multi-modal information but\nthey overlook the model's generalization ability on new datasets. Introducing\nnew datasets may affect the feature space of the original dataset, leading to\ncatastrophic forgetting. Meanwhile, large model parameters can significantly\nimpact training performance. To address these limitations, we introduce a novel\ntask called Text-Audio Incremental Learning (TAIL) task for text-audio\nretrieval, and propose a new method, PTAT, Prompt Tuning for Audio-Text\nincremental learning. This method utilizes prompt tuning to optimize the model\nparameters while incorporating an audio-text similarity and feature\ndistillation module to effectively mitigate catastrophic forgetting. We\nbenchmark our method and previous incremental learning methods on AudioCaps,\nClotho, BBC Sound Effects and Audioset datasets, and our method outperforms\nprevious methods significantly, particularly demonstrating stronger resistance\nto forgetting on older datasets. Compared to the full-parameters Finetune\n(Sequential) method, our model only requires 2.42\\% of its parameters,\nachieving 4.46\\% higher performance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "eess.AS",
      "I.2"
    ],
    "primary_category": "cs.SD",
    "comment": "4 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.04258v1",
    "published_date": "2025-03-06 09:39:36 UTC",
    "updated_date": "2025-03-06 09:39:36 UTC"
  },
  {
    "arxiv_id": "2503.04257v1",
    "title": "How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary Objects",
    "authors": [
      "Wonkwang Lee",
      "Jongwon Jeong",
      "Taehong Moon",
      "Hyeon-Jong Kim",
      "Jaehyeon Kim",
      "Gunhee Kim",
      "Byeong-Uk Lee"
    ],
    "abstract": "Motion synthesis for diverse object categories holds great potential for 3D\ncontent creation but remains underexplored due to two key challenges: (1) the\nlack of comprehensive motion datasets that include a wide range of high-quality\nmotions and annotations, and (2) the absence of methods capable of handling\nheterogeneous skeletal templates from diverse objects. To address these\nchallenges, we contribute the following: First, we augment the Truebones Zoo\ndataset, a high-quality animal motion dataset covering over 70 species, by\nannotating it with detailed text descriptions, making it suitable for\ntext-based motion synthesis. Second, we introduce rig augmentation techniques\nthat generate diverse motion data while preserving consistent dynamics,\nenabling models to adapt to various skeletal configurations. Finally, we\nredesign existing motion diffusion models to dynamically adapt to arbitrary\nskeletal templates, enabling motion synthesis for a diverse range of objects\nwith varying structures. Experiments show that our method learns to generate\nhigh-fidelity motions from textual descriptions for diverse and even unseen\nobjects, setting a strong foundation for motion synthesis across diverse object\ncategories and skeletal templates. Qualitative results are available on this\nlink: t2m4lvo.github.io",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04257v1",
    "published_date": "2025-03-06 09:39:09 UTC",
    "updated_date": "2025-03-06 09:39:09 UTC"
  },
  {
    "arxiv_id": "2503.04256v1",
    "title": "Knowledge Retention for Continual Model-Based Reinforcement Learning",
    "authors": [
      "Yixiang Sun",
      "Haotian Fu",
      "Michael Littman",
      "George Konidaris"
    ],
    "abstract": "We propose DRAGO, a novel approach for continual model-based reinforcement\nlearning aimed at improving the incremental development of world models across\na sequence of tasks that differ in their reward functions but not the state\nspace or dynamics. DRAGO comprises two key components: Synthetic Experience\nRehearsal, which leverages generative models to create synthetic experiences\nfrom past tasks, allowing the agent to reinforce previously learned dynamics\nwithout storing data, and Regaining Memories Through Exploration, which\nintroduces an intrinsic reward mechanism to guide the agent toward revisiting\nrelevant states from prior tasks. Together, these components enable the agent\nto maintain a comprehensive and continually developing world model,\nfacilitating more effective learning and adaptation across diverse\nenvironments. Empirical evaluations demonstrate that DRAGO is able to preserve\nknowledge across tasks, achieving superior performance in various continual\nlearning scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04256v1",
    "published_date": "2025-03-06 09:38:14 UTC",
    "updated_date": "2025-03-06 09:38:14 UTC"
  },
  {
    "arxiv_id": "2503.04249v1",
    "title": "How to Mitigate Overfitting in Weak-to-strong Generalization?",
    "authors": [
      "Junhao Shi",
      "Qinyuan Cheng",
      "Zhaoye Fei",
      "Yining Zheng",
      "Qipeng Guo",
      "Xipeng Qiu"
    ],
    "abstract": "Aligning powerful AI models on tasks that surpass human evaluation\ncapabilities is the central problem of \\textbf{superalignment}. To address this\nproblem, weak-to-strong generalization aims to elicit the capabilities of\nstrong models through weak supervisors and ensure that the behavior of strong\nmodels aligns with the intentions of weak supervisors without unsafe behaviors\nsuch as deception. Although weak-to-strong generalization exhibiting certain\ngeneralization capabilities, strong models exhibit significant overfitting in\nweak-to-strong generalization: Due to the strong fit ability of strong models,\nerroneous labels from weak supervisors may lead to overfitting in strong\nmodels. In addition, simply filtering out incorrect labels may lead to a\ndegeneration in question quality, resulting in a weak generalization ability of\nstrong models on hard questions. To mitigate overfitting in weak-to-strong\ngeneralization, we propose a two-stage framework that simultaneously improves\nthe quality of supervision signals and the quality of input questions.\nExperimental results in three series of large language models and two\nmathematical benchmarks demonstrate that our framework significantly improves\nPGR compared to naive weak-to-strong generalization, even achieving up to 100\\%\nPGR on some models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04249v1",
    "published_date": "2025-03-06 09:32:39 UTC",
    "updated_date": "2025-03-06 09:32:39 UTC"
  },
  {
    "arxiv_id": "2503.04231v2",
    "title": "One-Shot Clustering for Federated Learning",
    "authors": [
      "Maciej Krzysztof Zuziak",
      "Roberto Pellungrini",
      "Salvatore Rinzivillo"
    ],
    "abstract": "Federated Learning (FL) is a widespread and well adopted paradigm of\ndecentralized learning that allows training one model from multiple sources\nwithout the need to directly transfer data between participating clients. Since\nits inception in 2015, it has been divided into numerous sub-fields that deal\nwith application-specific issues, be it data heterogeneity or resource\nallocation. One such sub-field, Clustered Federated Learning (CFL), is dealing\nwith the problem of clustering the population of clients into separate cohorts\nto deliver personalized models. Although few remarkable works have been\npublished in this domain, the problem is still largely unexplored, as its basic\nassumption and settings are slightly different from standard FL. In this work,\nwe present One-Shot Clustered Federated Learning (OCFL), a clustering-agnostic\nalgorithm that can automatically detect the earliest suitable moment for\nclustering. Our algorithm is based on the computation of cosine similarity\nbetween gradients of the clients and a temperature measure that detects when\nthe federated model starts to converge. We empirically evaluate our methodology\nby testing various one-shot clustering algorithms for over thirty different\ntasks on three benchmark datasets. Our experiments showcase the good\nperformance of our approach when used to perform CFL in an automated manner\nwithout the need to adjust hyperparameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04231v2",
    "published_date": "2025-03-06 09:12:43 UTC",
    "updated_date": "2025-04-29 16:14:32 UTC"
  },
  {
    "arxiv_id": "2503.04219v1",
    "title": "Quantum-Inspired Reinforcement Learning in the Presence of Epistemic Ambivalence",
    "authors": [
      "Alireza Habibi",
      "Saeed Ghoorchian",
      "Setareh Maghsudi"
    ],
    "abstract": "The complexity of online decision-making under uncertainty stems from the\nrequirement of finding a balance between exploiting known strategies and\nexploring new possibilities. Naturally, the uncertainty type plays a crucial\nrole in developing decision-making strategies that manage complexity\neffectively. In this paper, we focus on a specific form of uncertainty known as\nepistemic ambivalence (EA), which emerges from conflicting pieces of evidence\nor contradictory experiences. It creates a delicate interplay between\nuncertainty and confidence, distinguishing it from epistemic uncertainty that\ntypically diminishes with new information. Indeed, ambivalence can persist even\nafter additional knowledge is acquired. To address this phenomenon, we propose\na novel framework, called the epistemically ambivalent Markov decision process\n(EA-MDP), aiming to understand and control EA in decision-making processes.\nThis framework incorporates the concept of a quantum state from the quantum\nmechanics formalism, and its core is to assess the probability and reward of\nevery possible outcome. We calculate the reward function using quantum\nmeasurement techniques and prove the existence of an optimal policy and an\noptimal value function in the EA-MDP framework. We also propose the\nEA-epsilon-greedy Q-learning algorithm. To evaluate the impact of EA on\ndecision-making and the expedience of our framework, we study two distinct\nexperimental setups, namely the two-state problem and the lattice problem. Our\nresults show that using our methods, the agent converges to the optimal policy\nin the presence of EA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph",
      "81P68, 81Q99, 68T05, 68Q12",
      "J.2; G.3; I.1.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04219v1",
    "published_date": "2025-03-06 08:54:31 UTC",
    "updated_date": "2025-03-06 08:54:31 UTC"
  },
  {
    "arxiv_id": "2503.04859v1",
    "title": "Codebook Reduction and Saturation: Novel observations on Inductive Thematic Saturation for Large Language Models and initial coding in Thematic Analysis",
    "authors": [
      "Stefano De Paoli",
      "Walter Stan Mathis"
    ],
    "abstract": "This paper reflects on the process of performing Thematic Analysis with Large\nLanguage Models (LLMs). Specifically, the paper deals with the problem of\nanalytical saturation of initial codes, as produced by LLMs. Thematic Analysis\nis a well-established qualitative analysis method composed of interlinked\nphases. A key phase is the initial coding, where the analysts assign labels to\ndiscrete components of a dataset. Saturation is a way to measure the validity\nof a qualitative analysis and relates to the recurrence and repetition of\ninitial codes. In the paper we reflect on how well LLMs achieve analytical\nsaturation and propose also a novel technique to measure Inductive Thematic\nSaturation (ITS). This novel technique leverages a programming framework called\nDSPy. The proposed novel approach allows a precise measurement of ITS.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04859v1",
    "published_date": "2025-03-06 08:52:03 UTC",
    "updated_date": "2025-03-06 08:52:03 UTC"
  },
  {
    "arxiv_id": "2503.04858v1",
    "title": "SHAPE : Self-Improved Visual Preference Alignment by Iteratively Generating Holistic Winner",
    "authors": [
      "Kejia Chen",
      "Jiawen Zhang",
      "Jiacong Hu",
      "Jiazhen Yang",
      "Jian Lou",
      "Zunlei Feng",
      "Mingli Song"
    ],
    "abstract": "Large Visual Language Models (LVLMs) increasingly rely on preference\nalignment to ensure reliability, which steers the model behavior via preference\nfine-tuning on preference data structured as ``image - winner text - loser\ntext'' triplets. However, existing approaches often suffer from limited\ndiversity and high costs associated with human-annotated preference data,\nhindering LVLMs from fully achieving their intended alignment capabilities. We\npresent \\projectname, a self-supervised framework capable of transforming the\nalready abundant supervised text-image pairs into holistic preference triplets\nfor more effective and cheaper LVLM alignment, eliminating the need for human\npreference annotations. Our approach facilitates LVLMs in progressively\nenhancing alignment capabilities through iterative self-improvement. The key\ndesign rationale is to devise preference triplets where the winner text\nconsistently improves in holisticness and outperforms the loser response in\nquality, thereby pushing the model to ``strive to the utmost'' of alignment\nperformance through preference fine-tuning. For each given text-image pair,\nSHAPE introduces multiple visual augmentations and pairs them with a summarized\ntext to serve as the winner response, while designating the original text as\nthe loser response. Experiments across \\textbf{12} benchmarks on various model\narchitectures and sizes, including LLaVA and DeepSeek-VL, show that SHAPE\nachieves significant gains, for example, achieving +11.3\\% on MMVet\n(comprehensive evaluation), +1.4\\% on MMBench (general VQA), and +8.0\\% on POPE\n(hallucination robustness) over baselines in 7B models. Notably, qualitative\nanalyses confirm enhanced attention to visual details and better alignment with\nhuman preferences for holistic descriptions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04858v1",
    "published_date": "2025-03-06 08:33:11 UTC",
    "updated_date": "2025-03-06 08:33:11 UTC"
  },
  {
    "arxiv_id": "2503.04201v1",
    "title": "Knowledge-Decoupled Synergetic Learning: An MLLM based Collaborative Approach to Few-shot Multimodal Dialogue Intention Recognition",
    "authors": [
      "Bin Chen",
      "Yu Zhang",
      "Hongfei Ye",
      "Ziyi Huang",
      "Hongyang Chen"
    ],
    "abstract": "Few-shot multimodal dialogue intention recognition is a critical challenge in\nthe e-commerce domainn. Previous methods have primarily enhanced model\nclassification capabilities through post-training techniques. However, our\nanalysis reveals that training for few-shot multimodal dialogue intention\nrecognition involves two interconnected tasks, leading to a seesaw effect in\nmulti-task learning. This phenomenon is attributed to knowledge interference\nstemming from the superposition of weight matrix updates during the training\nprocess. To address these challenges, we propose Knowledge-Decoupled Synergetic\nLearning (KDSL), which mitigates these issues by utilizing smaller models to\ntransform knowledge into interpretable rules, while applying the post-training\nof larger models. By facilitating collaboration between the large and small\nmultimodal large language models for prediction, our approach demonstrates\nsignificant improvements. Notably, we achieve outstanding results on two real\nTaobao datasets, with enhancements of 6.37\\% and 6.28\\% in online weighted F1\nscores compared to the state-of-the-art method, thereby validating the efficacy\nof our framework.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04201v1",
    "published_date": "2025-03-06 08:28:44 UTC",
    "updated_date": "2025-03-06 08:28:44 UTC"
  },
  {
    "arxiv_id": "2503.04199v1",
    "title": "MASTER: Multimodal Segmentation with Text Prompts",
    "authors": [
      "Fuyang Liu",
      "Shun Lu",
      "Jilin Mei",
      "Yu Hu"
    ],
    "abstract": "RGB-Thermal fusion is a potential solution for various weather and light\nconditions in challenging scenarios. However, plenty of studies focus on\ndesigning complex modules to fuse different modalities. With the widespread\napplication of large language models (LLMs), valuable information can be more\neffectively extracted from natural language. Therefore, we aim to leverage the\nadvantages of large language models to design a structurally simple and highly\nadaptable multimodal fusion model architecture. We proposed MultimodAl\nSegmentation with TExt PRompts (MASTER) architecture, which integrates LLM into\nthe fusion of RGB-Thermal multimodal data and allows complex query text to\nparticipate in the fusion process. Our model utilizes a dual-path structure to\nextract information from different modalities of images. Additionally, we\nemploy LLM as the core module for multimodal fusion, enabling the model to\ngenerate learnable codebook tokens from RGB, thermal images, and textual\ninformation. A lightweight image decoder is used to obtain semantic\nsegmentation results. The proposed MASTER performs exceptionally well in\nbenchmark tests across various automated driving scenarios, yielding promising\nresults.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04199v1",
    "published_date": "2025-03-06 08:27:51 UTC",
    "updated_date": "2025-03-06 08:27:51 UTC"
  },
  {
    "arxiv_id": "2503.04184v1",
    "title": "Large-Scale AI in Telecom: Charting the Roadmap for Innovation, Scalability, and Enhanced Digital Experiences",
    "authors": [
      "Adnan Shahid",
      "Adrian Kliks",
      "Ahmed Al-Tahmeesschi",
      "Ahmed Elbakary",
      "Alexandros Nikou",
      "Ali Maatouk",
      "Ali Mokh",
      "Amirreza Kazemi",
      "Antonio De Domenico",
      "Athanasios Karapantelakis",
      "Bo Cheng",
      "Bo Yang",
      "Bohao Wang",
      "Carlo Fischione",
      "Chao Zhang",
      "Chaouki Ben Issaid",
      "Chau Yuen",
      "Chenghui Peng",
      "Chongwen Huang",
      "Christina Chaccour",
      "Christo Kurisummoottil Thomas",
      "Dheeraj Sharma",
      "Dimitris Kalogiros",
      "Dusit Niyato",
      "Eli De Poorter",
      "Elissa Mhanna",
      "Emilio Calvanese Strinati",
      "Faouzi Bader",
      "Fathi Abdeldayem",
      "Fei Wang",
      "Fenghao Zhu",
      "Gianluca Fontanesi",
      "Giovanni Geraci",
      "Haibo Zhou",
      "Hakimeh Purmehdi",
      "Hamed Ahmadi",
      "Hang Zou",
      "Hongyang Du",
      "Hoon Lee",
      "Howard H. Yang",
      "Iacopo Poli",
      "Igor Carron",
      "Ilias Chatzistefanidis",
      "Inkyu Lee",
      "Ioannis Pitsiorlas",
      "Jaron Fontaine",
      "Jiajun Wu",
      "Jie Zeng",
      "Jinan Li",
      "Jinane Karam",
      "Johny Gemayel",
      "Juan Deng",
      "Julien Frison",
      "Kaibin Huang",
      "Kehai Qiu",
      "Keith Ball",
      "Kezhi Wang",
      "Kun Guo",
      "Leandros Tassiulas",
      "Lecorve Gwenole",
      "Liexiang Yue",
      "Lina Bariah",
      "Louis Powell",
      "Marcin Dryjanski",
      "Maria Amparo Canaveras Galdon",
      "Marios Kountouris",
      "Maryam Hafeez",
      "Maxime Elkael",
      "Mehdi Bennis",
      "Mehdi Boudjelli",
      "Meiling Dai",
      "Merouane Debbah",
      "Michele Polese",
      "Mohamad Assaad",
      "Mohamed Benzaghta",
      "Mohammad Al Refai",
      "Moussab Djerrab",
      "Mubeen Syed",
      "Muhammad Amir",
      "Na Yan",
      "Najla Alkaabi",
      "Nan Li",
      "Nassim Sehad",
      "Navid Nikaein",
      "Omar Hashash",
      "Pawel Sroka",
      "Qianqian Yang",
      "Qiyang Zhao",
      "Rasoul Nikbakht Silab",
      "Rex Ying",
      "Roberto Morabito",
      "Rongpeng Li",
      "Ryad Madi",
      "Salah Eddine El Ayoubi",
      "Salvatore D'Oro",
      "Samson Lasaulce",
      "Serveh Shalmashi",
      "Sige Liu",
      "Sihem Cherrared",
      "Swarna Bindu Chetty",
      "Swastika Dutta",
      "Syed A. R. Zaidi",
      "Tianjiao Chen",
      "Timothy Murphy",
      "Tommaso Melodia",
      "Tony Q. S. Quek",
      "Vishnu Ram",
      "Walid Saad",
      "Wassim Hamidouche",
      "Weilong Chen",
      "Xiaoou Liu",
      "Xiaoxue Yu",
      "Xijun Wang",
      "Xingyu Shang",
      "Xinquan Wang",
      "Xuelin Cao",
      "Yang Su",
      "Yanping Liang",
      "Yansha Deng",
      "Yifan Yang",
      "Yingping Cui",
      "Yu Sun",
      "Yuxuan Chen",
      "Yvan Pointurier",
      "Zeinab Nehme",
      "Zeinab Nezami",
      "Zhaohui Yang",
      "Zhaoyang Zhang",
      "Zhe Liu",
      "Zhenyu Yang",
      "Zhu Han",
      "Zhuang Zhou",
      "Zihan Chen",
      "Zirui Chen",
      "Zitao Shuai"
    ],
    "abstract": "This white paper discusses the role of large-scale AI in the\ntelecommunications industry, with a specific focus on the potential of\ngenerative AI to revolutionize network functions and user experiences,\nespecially in the context of 6G systems. It highlights the development and\ndeployment of Large Telecom Models (LTMs), which are tailored AI models\ndesigned to address the complex challenges faced by modern telecom networks.\nThe paper covers a wide range of topics, from the architecture and deployment\nstrategies of LTMs to their applications in network management, resource\nallocation, and optimization. It also explores the regulatory, ethical, and\nstandardization considerations for LTMs, offering insights into their future\nintegration into telecom infrastructure. The goal is to provide a comprehensive\nroadmap for the adoption of LTMs to enhance scalability, performance, and\nuser-centric innovation in telecom networks.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04184v1",
    "published_date": "2025-03-06 07:53:24 UTC",
    "updated_date": "2025-03-06 07:53:24 UTC"
  },
  {
    "arxiv_id": "2503.04183v1",
    "title": "CrowdHMTware: A Cross-level Co-adaptation Middleware for Context-aware Mobile DL Deployment",
    "authors": [
      "Sicong Liu",
      "Bin Guo",
      "Shiyan Luo",
      "Yuzhan Wang",
      "Hao Luo",
      "Cheng Fang",
      "Yuan Xu",
      "Ke Ma",
      "Yao Li",
      "Zhiwen Yu"
    ],
    "abstract": "There are many deep learning (DL) powered mobile and wearable applications\ntoday continuously and unobtrusively sensing the ambient surroundings to\nenhance all aspects of human lives.To enable robust and private mobile sensing,\nDL models are often deployed locally on resource-constrained mobile devices\nusing techniques such as model compression or offloading.However, existing\nmethods, either front-end algorithm level (i.e. DL model\ncompression/partitioning) or back-end scheduling level (i.e. operator/resource\nscheduling), cannot be locally online because they require offline retraining\nto ensure accuracy or rely on manually pre-defined strategies, struggle with\ndynamic adaptability.The primary challenge lies in feeding back runtime\nperformance from the back-end level to the front-end level optimization\ndecision. Moreover, the adaptive mobile DL model porting middleware with\ncross-level co-adaptation is less explored, particularly in mobile environments\nwith diversity and dynamics. In response, we introduce CrowdHMTware, a dynamic\ncontext-adaptive DL model deployment middleware for heterogeneous mobile\ndevices. It establishes an automated adaptation loop between cross-level\nfunctional components, i.e. elastic inference, scalable offloading, and\nmodel-adaptive engine, enhancing scalability and adaptability. Experiments with\nfour typical tasks across 15 platforms and a real-world case study demonstrate\nthat CrowdHMTware can effectively scale DL model, offloading, and engine\nactions across diverse platforms and tasks. It hides run-time system issues\nfrom developers, reducing the required developer expertise.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper is accepted by IEEE Transactions on Mobile Computing",
    "pdf_url": "http://arxiv.org/pdf/2503.04183v1",
    "published_date": "2025-03-06 07:52:20 UTC",
    "updated_date": "2025-03-06 07:52:20 UTC"
  },
  {
    "arxiv_id": "2503.04176v1",
    "title": "TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal Clinical Records",
    "authors": [
      "Hejie Cui",
      "Alyssa Unell",
      "Bowen Chen",
      "Jason Alan Fries",
      "Emily Alsentzer",
      "Sanmi Koyejo",
      "Nigam Shah"
    ],
    "abstract": "Large language models (LLMs) have emerged as promising tools for assisting in\nmedical tasks, yet processing Electronic Health Records (EHRs) presents unique\nchallenges due to their longitudinal nature. While LLMs' capabilities to\nperform medical tasks continue to improve, their ability to reason over\ntemporal dependencies across multiple patient visits and time frames remains\nunexplored. We introduce TIMER (Temporal Instruction Modeling and Evaluation\nfor Longitudinal Clinical Records), a framework that incorporate\ninstruction-response pairs grounding to different parts of a patient's record\nas a critical dimension in both instruction evaluation and tuning for\nlongitudinal clinical records. We develop TIMER-Bench, the first time-aware\nbenchmark that evaluates temporal reasoning capabilities over longitudinal\nEHRs, as well as TIMER-Instruct, an instruction-tuning methodology for LLMs to\nlearn reasoning over time. We demonstrate that models fine-tuned with\nTIMER-Instruct improve performance by 7.3% on human-generated benchmarks and\n9.2% on TIMER-Bench, indicating that temporal instruction-tuning improves model\nperformance for reasoning over EHR.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.LG",
      "68T50, 68T37",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.04176v1",
    "published_date": "2025-03-06 07:44:17 UTC",
    "updated_date": "2025-03-06 07:44:17 UTC"
  },
  {
    "arxiv_id": "2503.04170v1",
    "title": "Towards Intelligent Transportation with Pedestrians and Vehicles In-the-Loop: A Surveillance Video-Assisted Federated Digital Twin Framework",
    "authors": [
      "Xiaolong Li",
      "Jianhao Wei",
      "Haidong Wang",
      "Li Dong",
      "Ruoyang Chen",
      "Changyan Yi",
      "Jun Cai",
      "Dusit Niyato",
      "Xuemin",
      "Shen"
    ],
    "abstract": "In intelligent transportation systems (ITSs), incorporating pedestrians and\nvehicles in-the-loop is crucial for developing realistic and safe traffic\nmanagement solutions. However, there is falls short of simulating complex\nreal-world ITS scenarios, primarily due to the lack of a digital twin\nimplementation framework for characterizing interactions between pedestrians\nand vehicles at different locations in different traffic environments. In this\narticle, we propose a surveillance video assisted federated digital twin\n(SV-FDT) framework to empower ITSs with pedestrians and vehicles in-the-loop.\nSpecifically, SVFDT builds comprehensive pedestrian-vehicle interaction models\nby leveraging multi-source traffic surveillance videos. Its architecture\nconsists of three layers: (i) the end layer, which collects traffic\nsurveillance videos from multiple sources; (ii) the edge layer, responsible for\nsemantic segmentation-based visual understanding, twin agent-based interaction\nmodeling, and local digital twin system (LDTS) creation in local regions; and\n(iii) the cloud layer, which integrates LDTSs across different regions to\nconstruct a global DT model in realtime. We analyze key design requirements and\nchallenges and present core guidelines for SVFDT's system implementation. A\ntestbed evaluation demonstrates its effectiveness in optimizing traffic\nmanagement. Comparisons with traditional terminal-server frameworks highlight\nSV-FDT's advantages in mirroring delays, recognition accuracy, and subjective\nevaluation. Finally, we identify some open challenges and discuss future\nresearch directions.",
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04170v1",
    "published_date": "2025-03-06 07:36:06 UTC",
    "updated_date": "2025-03-06 07:36:06 UTC"
  },
  {
    "arxiv_id": "2503.04856v1",
    "title": "One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs",
    "authors": [
      "Junwoo Ha",
      "Hyunjun Kim",
      "Sangyoon Yu",
      "Haon Park",
      "Ashkan Yousefpour",
      "Yuna Park",
      "Suhyun Kim"
    ],
    "abstract": "Despite extensive safety enhancements in large language models (LLMs),\nmulti-turn \"jailbreak\" conversations crafted by skilled human adversaries can\nstill breach even the most sophisticated guardrails. However, these multi-turn\nattacks demand considerable manual effort, limiting their scalability. In this\nwork, we introduce a novel approach called Multi-turn-to-Single-turn (M2S) that\nsystematically converts multi-turn jailbreak prompts into single-turn attacks.\nSpecifically, we propose three conversion strategies - Hyphenize, Numberize,\nand Pythonize - each preserving sequential context yet packaging it in a single\nquery. Our experiments on the Multi-turn Human Jailbreak (MHJ) dataset show\nthat M2S often increases or maintains high Attack Success Rates (ASRs) compared\nto original multi-turn conversations. Notably, using a StrongREJECT-based\nevaluation of harmfulness, M2S achieves up to 95.9% ASR on Mistral-7B and\noutperforms original multi-turn prompts by as much as 17.5% in absolute\nimprovement on GPT-4o. Further analysis reveals that certain adversarial\ntactics, when consolidated into a single prompt, exploit structural formatting\ncues to evade standard policy checks. These findings underscore that\nsingle-turn attacks - despite being simpler and cheaper to conduct - can be\njust as potent, if not more, than their multi-turn counterparts. Our findings\nunderscore the urgent need to reevaluate and reinforce LLM safety strategies,\ngiven how adversarial queries can be compacted into a single prompt while still\nretaining sufficient complexity to bypass existing safety measures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04856v1",
    "published_date": "2025-03-06 07:34:51 UTC",
    "updated_date": "2025-03-06 07:34:51 UTC"
  },
  {
    "arxiv_id": "2503.04167v1",
    "title": "The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights",
    "authors": [
      "Yufang Liu",
      "Yao Du",
      "Tao Ji",
      "Jianing Wang",
      "Yang Liu",
      "Yuanbin Wu",
      "Aimin Zhou",
      "Mengdi Zhang",
      "Xunliang Cai"
    ],
    "abstract": "Recent research has increasingly focused on multimodal mathematical\nreasoning, particularly emphasizing the creation of relevant datasets and\nbenchmarks. Despite this, the role of visual information in reasoning has been\nunderexplored. Our findings show that existing multimodal mathematical models\nminimally leverage visual information, and model performance remains largely\nunaffected by changes to or removal of images in the dataset. We attribute this\nto the dominance of textual information and answer options that inadvertently\nguide the model to correct answers. To improve evaluation methods, we introduce\nthe HC-M3D dataset, specifically designed to require image reliance for\nproblem-solving and to challenge models with similar, yet distinct, images that\nchange the correct answer. In testing leading models, their failure to detect\nthese subtle visual differences suggests limitations in current visual\nperception capabilities. Additionally, we observe that the common approach of\nimproving general VQA capabilities by combining various types of image encoders\ndoes not contribute to math reasoning performance. This finding also presents a\nchallenge to enhancing visual reliance during math reasoning. Our benchmark and\ncode would be available at\n\\href{https://github.com/Yufang-Liu/visual_modality_role}{https://github.com/Yufang-Liu/visual\\_modality\\_role}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04167v1",
    "published_date": "2025-03-06 07:29:33 UTC",
    "updated_date": "2025-03-06 07:29:33 UTC"
  },
  {
    "arxiv_id": "2503.04162v1",
    "title": "Semantic Retrieval Augmented Contrastive Learning for Sequential Recommendation",
    "authors": [
      "Ziqiang Cui",
      "Yunpeng Weng",
      "Xing Tang",
      "Xiaokun Zhang",
      "Dugang Liu",
      "Shiwei Li",
      "Peiyang Liu",
      "Bowei He",
      "Weihong Luo",
      "Xiuqiang He",
      "Chen Ma"
    ],
    "abstract": "Sequential recommendation aims to model user preferences based on historical\nbehavior sequences, which is crucial for various online platforms. Data\nsparsity remains a significant challenge in this area as most users have\nlimited interactions and many items receive little attention. To mitigate this\nissue, contrastive learning has been widely adopted. By constructing positive\nsample pairs from the data itself and maximizing their agreement in the\nembedding space,it can leverage available data more effectively. Constructing\nreasonable positive sample pairs is crucial for the success of contrastive\nlearning. However, current approaches struggle to generate reliable positive\npairs as they either rely on representations learned from inherently sparse\ncollaborative signals or use random perturbations which introduce significant\nuncertainty. To address these limitations, we propose a novel approach named\nSemantic Retrieval Augmented Contrastive Learning (SRA-CL), which leverages\nsemantic information to improve the reliability of contrastive samples. SRA-CL\ncomprises two main components: (1) Cross-Sequence Contrastive Learning via User\nSemantic Retrieval, which utilizes large language models (LLMs) to understand\ndiverse user preferences and retrieve semantically similar users to form\nreliable positive samples through a learnable sample synthesis method; and (2)\nIntra-Sequence Contrastive Learning via Item Semantic Retrieval, which employs\nLLMs to comprehend items and retrieve similar items to perform semantic-based\nitem substitution, thereby creating semantically consistent augmented views for\ncontrastive learning. SRA-CL is plug-and-play and can be integrated into\nstandard sequential recommendation models. Extensive experiments on four public\ndatasets demonstrate the effectiveness and generalizability of the proposed\napproach.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04162v1",
    "published_date": "2025-03-06 07:25:19 UTC",
    "updated_date": "2025-03-06 07:25:19 UTC"
  },
  {
    "arxiv_id": "2503.04160v1",
    "title": "Unseen Fake News Detection Through Casual Debiasing",
    "authors": [
      "Shuzhi Gong",
      "Richard Sinnott",
      "Jianzhong Qi",
      "Cecile Paris"
    ],
    "abstract": "The widespread dissemination of fake news on social media poses significant\nrisks, necessitating timely and accurate detection. However, existing methods\nstruggle with unseen news due to their reliance on training data from past\nevents and domains, leaving the challenge of detecting novel fake news largely\nunresolved. To address this, we identify biases in training data tied to\nspecific domains and propose a debiasing solution FNDCD. Originating from\ncausal analysis, FNDCD employs a reweighting strategy based on classification\nconfidence and propagation structure regularization to reduce the influence of\ndomain-specific biases, enhancing the detection of unseen fake news.\nExperiments on real-world datasets with non-overlapping news domains\ndemonstrate FNDCD's effectiveness in improving generalization across domains.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "2025 The Web Conference, 6 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04160v1",
    "published_date": "2025-03-06 07:23:44 UTC",
    "updated_date": "2025-03-06 07:23:44 UTC"
  },
  {
    "arxiv_id": "2503.04154v1",
    "title": "CA-W3D: Leveraging Context-Aware Knowledge for Weakly Supervised Monocular 3D Detection",
    "authors": [
      "Chupeng Liu",
      "Runkai Zhao",
      "Weidong Cai"
    ],
    "abstract": "Weakly supervised monocular 3D detection, while less annotation-intensive,\noften struggles to capture the global context required for reliable 3D\nreasoning. Conventional label-efficient methods focus on object-centric\nfeatures, neglecting contextual semantic relationships that are critical in\ncomplex scenes. In this work, we propose a Context-Aware Weak Supervision for\nMonocular 3D object detection, namely CA-W3D, to address this limitation in a\ntwo-stage training paradigm. Specifically, we first introduce a pre-training\nstage employing Region-wise Object Contrastive Matching (ROCM), which aligns\nregional object embeddings derived from a trainable monocular 3D encoder and a\nfrozen open-vocabulary 2D visual grounding model. This alignment encourages the\nmonocular encoder to discriminate scene-specific attributes and acquire richer\ncontextual knowledge. In the second stage, we incorporate a pseudo-label\ntraining process with a Dual-to-One Distillation (D2OD) mechanism, which\neffectively transfers contextual priors into the monocular encoder while\npreserving spatial fidelity and maintaining computational efficiency during\ninference. Extensive experiments conducted on the public KITTI benchmark\ndemonstrate the effectiveness of our approach, surpassing the SoTA method over\nall metrics, highlighting the importance of contextual-aware knowledge in\nweakly-supervised monocular 3D detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The paper includes 8 pages, 6 figures and 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.04154v1",
    "published_date": "2025-03-06 07:02:13 UTC",
    "updated_date": "2025-03-06 07:02:13 UTC"
  },
  {
    "arxiv_id": "2503.04153v1",
    "title": "KidneyTalk-open: No-code Deployment of a Private Large Language Model with Medical Documentation-Enhanced Knowledge Database for Kidney Disease",
    "authors": [
      "Yongchao Long",
      "Chao Yang",
      "Gongzheng Tang",
      "Jinwei Wang",
      "Zhun Sui",
      "Yuxi Zhou",
      "Shenda Hong",
      "Luxia Zhang"
    ],
    "abstract": "Privacy-preserving medical decision support for kidney disease requires\nlocalized deployment of large language models (LLMs) while maintaining clinical\nreasoning capabilities. Current solutions face three challenges: 1) Cloud-based\nLLMs pose data security risks; 2) Local model deployment demands technical\nexpertise; 3) General LLMs lack mechanisms to integrate medical knowledge.\nRetrieval-augmented systems also struggle with medical document processing and\nclinical usability. We developed KidneyTalk-open, a desktop system integrating\nthree technical components: 1) No-code deployment of state-of-the-art (SOTA)\nopen-source LLMs (such as DeepSeek-r1, Qwen2.5) via local inference engine; 2)\nMedical document processing pipeline combining context-aware chunking and\nintelligent filtering; 3) Adaptive Retrieval and Augmentation Pipeline (AddRep)\nemploying agents collaboration for improving the recall rate of medical\ndocuments. A graphical interface was designed to enable clinicians to manage\nmedical documents and conduct AI-powered consultations without technical\nexpertise. Experimental validation on 1,455 challenging nephrology exam\nquestions demonstrates AddRep's effectiveness: achieving 29.1% accuracy (+8.1%\nover baseline) with intelligent knowledge integration, while maintaining\nrobustness through 4.9% rejection rate to suppress hallucinations. Comparative\ncase studies with the mainstream products (AnythingLLM, Chatbox, GPT4ALL)\ndemonstrate KidneyTalk-open's superior performance in real clinical query.\nKidneyTalk-open represents the first no-code medical LLM system enabling secure\ndocumentation-enhanced medical Q&A on desktop. Its designs establishes a new\nframework for privacy-sensitive clinical AI applications. The system\nsignificantly lowers technical barriers while improving evidence traceability,\nenabling more medical staff or patients to use SOTA open-source LLMs\nconveniently.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Corresponding authors: zhanglx@bjmu.edu.cn; joy_yuxi@pku.edu.cn;\n  hongshenda@pku.edu.cn",
    "pdf_url": "http://arxiv.org/pdf/2503.04153v1",
    "published_date": "2025-03-06 07:01:36 UTC",
    "updated_date": "2025-03-06 07:01:36 UTC"
  },
  {
    "arxiv_id": "2503.04151v1",
    "title": "Robust Multi-View Learning via Representation Fusion of Sample-Level Attention and Alignment of Simulated Perturbation",
    "authors": [
      "Jie Xu",
      "Na Zhao",
      "Gang Niu",
      "Masashi Sugiyama",
      "Xiaofeng Zhu"
    ],
    "abstract": "Recently, multi-view learning (MVL) has garnered significant attention due to\nits ability to fuse discriminative information from multiple views. However,\nreal-world multi-view datasets are often heterogeneous and imperfect, which\nusually makes MVL methods designed for specific combinations of views lack\napplication potential and limits their effectiveness. To address this issue, we\npropose a novel robust MVL method (namely RML) with simultaneous representation\nfusion and alignment. Specifically, we introduce a simple yet effective\nmulti-view transformer fusion network where we transform heterogeneous\nmulti-view data into homogeneous word embeddings, and then integrate multiple\nviews by the sample-level attention mechanism to obtain a fused representation.\nFurthermore, we propose a simulated perturbation based multi-view contrastive\nlearning framework that dynamically generates the noise and unusable\nperturbations for simulating imperfect data conditions. The simulated noisy and\nunusable data obtain two distinct fused representations, and we utilize\ncontrastive learning to align them for learning discriminative and robust\nrepresentations. Our RML is self-supervised and can also be applied for\ndownstream tasks as a regularization. In experiments, we employ it in\nunsupervised multi-view clustering, noise-label classification, and as a\nplug-and-play module for cross-modal hashing retrieval. Extensive comparison\nexperiments and ablation studies validate the effectiveness of RML.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04151v1",
    "published_date": "2025-03-06 07:01:08 UTC",
    "updated_date": "2025-03-06 07:01:08 UTC"
  },
  {
    "arxiv_id": "2503.04150v2",
    "title": "Ticktack : Long Span Temporal Alignment of Large Language Models Leveraging Sexagenary Cycle Time Expression",
    "authors": [
      "Xue Han",
      "Qian Hu",
      "Yitong Wang",
      "Wenchun Gao",
      "Lianlian Zhang",
      "Qing Wang",
      "Lijun Mei",
      "Chao Deng",
      "Junlan Feng"
    ],
    "abstract": "Large language models (LLMs) suffer from temporal misalignment issues\nespecially across long span of time. The issue arises from knowing that LLMs\nare trained on large amounts of data where temporal information is rather\nsparse over long times, such as thousands of years, resulting in insufficient\nlearning or catastrophic forgetting by the LLMs. This paper proposes a\nmethodology named \"Ticktack\" for addressing the LLM's long-time span\nmisalignment in a yearly setting. Specifically, we first propose to utilize the\nsexagenary year expression instead of the Gregorian year expression employed by\nLLMs, achieving a more uniform distribution in yearly granularity. Then, we\nemploy polar coordinates to model the sexagenary cycle of 60 terms and the year\norder within each term, with additional temporal encoding to ensure LLMs\nunderstand them. Finally, we present a temporal representational alignment\napproach for post-training LLMs that effectively distinguishes time points with\nrelevant knowledge, hence improving performance on time-related tasks,\nparticularly over a long period. We also create a long time span benchmark for\nevaluation. Experimental results prove the effectiveness of our proposal.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04150v2",
    "published_date": "2025-03-06 06:59:09 UTC",
    "updated_date": "2025-03-07 09:37:53 UTC"
  },
  {
    "arxiv_id": "2503.04149v1",
    "title": "Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models Under Data Contamination",
    "authors": [
      "Simin Chen",
      "Pranav Pusarla",
      "Baishakhi Ray"
    ],
    "abstract": "The rapid evolution of code largelanguage models underscores the need for\neffective and transparent benchmarking of their reasoning capabilities.\nHowever, the current benchmarking approach heavily depends on publicly\navailable, human-created datasets. The widespread use of these fixed benchmark\ndatasets makes the benchmarking process to be static and thus particularly\nsusceptible to data contamination, an unavoidable consequence of the extensive\ndata collection processes used to train Code LLMs. Existing approaches that\naddress data contamination often suffer from human effort limitations and\nimbalanced problem complexity. To tackle these challenges, we propose \\tool, a\nnovel benchmarking suite for evaluating Code LLMs under potential data\ncontamination. Given a seed programming problem, \\tool employs multiple agents\nto extract and modify the context without altering the core logic, generating\nsemantically equivalent variations. We introduce a dynamic data generation\nmethods and conduct empirical studies on two seed datasets across 21 Code LLMs.\nResults show that \\tool effectively benchmarks reasoning capabilities under\ncontamination risks while generating diverse problem sets to ensure consistent\nand reliable evaluations.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "https://codekaleidoscope.github.io/dycodeeval.html",
    "pdf_url": "http://arxiv.org/pdf/2503.04149v1",
    "published_date": "2025-03-06 06:56:59 UTC",
    "updated_date": "2025-03-06 06:56:59 UTC"
  },
  {
    "arxiv_id": "2503.04144v1",
    "title": "DM-Adapter: Domain-Aware Mixture-of-Adapters for Text-Based Person Retrieval",
    "authors": [
      "Yating Liu",
      "Zimo Liu",
      "Xiangyuan Lan",
      "Wenming Yang",
      "Yaowei Li",
      "Qingmin Liao"
    ],
    "abstract": "Text-based person retrieval (TPR) has gained significant attention as a\nfine-grained and challenging task that closely aligns with practical\napplications. Tailoring CLIP to person domain is now a emerging research topic\ndue to the abundant knowledge of vision-language pretraining, but challenges\nstill remain during fine-tuning: (i) Previous full-model fine-tuning in TPR is\ncomputationally expensive and prone to overfitting.(ii) Existing\nparameter-efficient transfer learning (PETL) for TPR lacks of fine-grained\nfeature extraction. To address these issues, we propose Domain-Aware\nMixture-of-Adapters (DM-Adapter), which unifies Mixture-of-Experts (MOE) and\nPETL to enhance fine-grained feature representations while maintaining\nefficiency. Specifically, Sparse Mixture-of-Adapters is designed in parallel to\nMLP layers in both vision and language branches, where different experts\nspecialize in distinct aspects of person knowledge to handle features more\nfinely. To promote the router to exploit domain information effectively and\nalleviate the routing imbalance, Domain-Aware Router is then developed by\nbuilding a novel gating function and injecting learnable domain-aware prompts.\nExtensive experiments show that our DM-Adapter achieves state-of-the-art\nperformance, outperforming previous methods by a significant margin.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 5 figures, accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04144v1",
    "published_date": "2025-03-06 06:41:38 UTC",
    "updated_date": "2025-03-06 06:41:38 UTC"
  },
  {
    "arxiv_id": "2503.04143v1",
    "title": "MTS: A Deep Reinforcement Learning Portfolio Management Framework with Time-Awareness and Short-Selling",
    "authors": [
      "Fengchen Gu",
      "Zhengyong Jiang",
      "Ángel F. García-Fernández",
      "Angelos Stefanidis",
      "Jionglong Su",
      "Huakang Li"
    ],
    "abstract": "Portfolio management remains a crucial challenge in finance, with traditional\nmethods often falling short in complex and volatile market environments. While\ndeep reinforcement approaches have shown promise, they still face limitations\nin dynamic risk management, exploitation of temporal markets, and incorporation\nof complex trading strategies such as short-selling. These limitations can lead\nto suboptimal portfolio performance, increased vulnerability to market\nvolatility, and missed opportunities in capturing potential returns from\ndiverse market conditions. This paper introduces a Deep Reinforcement Learning\nPortfolio Management Framework with Time-Awareness and Short-Selling (MTS),\noffering a robust and adaptive strategy for sustainable investment performance.\nThis framework utilizes a novel encoder-attention mechanism to address the\nlimitations by incorporating temporal market characteristics, a parallel\nstrategy for automated short-selling based on market trends, and risk\nmanagement through innovative Incremental Conditional Value at Risk, enhancing\nadaptability and performance. Experimental validation on five diverse datasets\nfrom 2019 to 2023 demonstrates MTS's superiority over traditional algorithms\nand advanced machine learning techniques. MTS consistently achieves higher\ncumulative returns, Sharpe, Omega, and Sortino ratios, underscoring its\neffectiveness in balancing risk and return while adapting to market dynamics.\nMTS demonstrates an average relative increase of 30.67% in cumulative returns\nand 29.33% in Sharpe ratio compared to the next best-performing strategies\nacross various datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04143v1",
    "published_date": "2025-03-06 06:41:17 UTC",
    "updated_date": "2025-03-06 06:41:17 UTC"
  },
  {
    "arxiv_id": "2503.04128v1",
    "title": "Artificial Intelligence in Pronunciation Teaching: Use and Beliefs of Foreign Language Teachers",
    "authors": [
      "Georgios P. Georgiou"
    ],
    "abstract": "Pronunciation instruction in foreign language classrooms has often been an\noverlooked area of focus. With the widespread adoption of Artificial\nIntelligence (AI) and its potential benefits, investigating how AI is utilized\nin pronunciation teaching and understanding the beliefs of teachers about this\ntool is essential for improving learning outcomes. This study aims to examine\nhow AI use for pronunciation instruction varies across different demographic\nand professional factors among teachers, and how these factors, including AI\nuse, influence the beliefs of teachers about AI. The study involved 117 English\nas a Foreign Language (EFL) in-service teachers working in Cyprus, who\ncompleted an online survey designed to assess their beliefs about the\neffectiveness of AI, its drawbacks, and their willingness to integrate AI into\ntheir teaching practices. The results revealed that teachers were significantly\nmore likely to agree on the perceived effectiveness of AI and their willingness\nto adopt it, compared to their concerns about its use. Furthermore, teachers\nworking in higher education and adult education, as well as those who had\nreceived more extensive training, reported using AI more frequently in their\nteaching. Teachers who utilized AI more often expressed stronger agreement with\nits effectiveness, while those who had received more training were less likely\nto express concerns about its integration. Given the limited training that many\nteachers currently receive, these findings demonstrate the need for tailored\ntraining sessions that address the specific needs and concerns of educators,\nultimately fostering the adoption of AI in pronunciation instruction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04128v1",
    "published_date": "2025-03-06 06:14:27 UTC",
    "updated_date": "2025-03-06 06:14:27 UTC"
  },
  {
    "arxiv_id": "2503.04853v1",
    "title": "From Pixels to Trajectory: Universal Adversarial Example Detection via Temporal Imprints",
    "authors": [
      "Yansong Gao",
      "Huaibing Peng",
      "Hua Ma",
      "Zhiyang Dai",
      "Shuo Wang",
      "Hongsheng Hu",
      "Anmin Fu",
      "Minhui Xue"
    ],
    "abstract": "For the first time, we unveil discernible temporal (or historical) trajectory\nimprints resulting from adversarial example (AE) attacks. Standing in contrast\nto existing studies all focusing on spatial (or static) imprints within the\ntargeted underlying victim models, we present a fresh temporal paradigm for\nunderstanding these attacks. Of paramount discovery is that these imprints are\nencapsulated within a single loss metric, spanning universally across diverse\ntasks such as classification and regression, and modalities including image,\ntext, and audio. Recognizing the distinct nature of loss between adversarial\nand clean examples, we exploit this temporal imprint for AE detection by\nproposing TRAIT (TRaceable Adversarial temporal trajectory ImprinTs). TRAIT\noperates under minimal assumptions without prior knowledge of attacks, thereby\nframing the detection challenge as a one-class classification problem. However,\ndetecting AEs is still challenged by significant overlaps between the\nconstructed synthetic losses of adversarial and clean examples due to the\nabsence of ground truth for incoming inputs. TRAIT addresses this challenge by\nconverting the synthetic loss into a spectrum signature, using the technique of\nFast Fourier Transform to highlight the discrepancies, drawing inspiration from\nthe temporal nature of the imprints, analogous to time-series signals. Across\n12 AE attacks including SMACK (USENIX Sec'2023), TRAIT demonstrates consistent\noutstanding performance across comprehensively evaluated modalities, tasks,\ndatasets, and model architectures. In all scenarios, TRAIT achieves an AE\ndetection accuracy exceeding 97%, often around 99%, while maintaining a false\nrejection rate of 1%. TRAIT remains effective under the formulated strong\nadaptive attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04853v1",
    "published_date": "2025-03-06 06:00:04 UTC",
    "updated_date": "2025-03-06 06:00:04 UTC"
  },
  {
    "arxiv_id": "2503.04121v1",
    "title": "Simple Self Organizing Map with Visual Transformer",
    "authors": [
      "Alan Luo",
      "Kaiwen Yuan"
    ],
    "abstract": "Vision Transformers (ViTs) have demonstrated exceptional performance in\nvarious vision tasks. However, they tend to underperform on smaller datasets\ndue to their inherent lack of inductive biases. Current approaches address this\nlimitation implicitly-often by pairing ViTs with pretext tasks or by distilling\nknowledge from convolutional neural networks (CNNs) to strengthen the prior. In\ncontrast, Self-Organizing Maps (SOMs), a widely adopted self-supervised\nframework, are inherently structured to preserve topology and spatial\norganization, making them a promising candidate to directly address the\nlimitations of ViTs in limited or small training datasets. Despite this\npotential, equipping SOMs with modern deep learning architectures remains\nlargely unexplored. In this study, we conduct a novel exploration on how Vision\nTransformers (ViTs) and Self-Organizing Maps (SOMs) can empower each other,\naiming to bridge this critical research gap. Our findings demonstrate that\nthese architectures can synergistically enhance each other, leading to\nsignificantly improved performance in both unsupervised and supervised tasks.\nCode will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "65D19 (Primary)"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 4 figures. Submitted to IEEE. All experiments and code work\n  were performed by the first author, with the second author serving in a\n  PI/mentor role, guiding the progression of the work",
    "pdf_url": "http://arxiv.org/pdf/2503.04121v1",
    "published_date": "2025-03-06 05:58:41 UTC",
    "updated_date": "2025-03-06 05:58:41 UTC"
  },
  {
    "arxiv_id": "2503.04111v1",
    "title": "Generalizability of Neural Networks Minimizing Empirical Risk Based on Expressive Ability",
    "authors": [
      "Lijia Yu",
      "Yibo Miao",
      "Yifan Zhu",
      "Xiao-Shan Gao",
      "Lijun Zhang"
    ],
    "abstract": "The primary objective of learning methods is generalization. Classic uniform\ngeneralization bounds, which rely on VC-dimension or Rademacher complexity,\nfail to explain the significant attribute that over-parameterized models in\ndeep learning exhibit nice generalizability. On the other hand,\nalgorithm-dependent generalization bounds, like stability bounds, often rely on\nstrict assumptions. To establish generalizability under less stringent\nassumptions, this paper investigates the generalizability of neural networks\nthat minimize or approximately minimize empirical risk. We establish a lower\nbound for population accuracy based on the expressiveness of these networks,\nwhich indicates that with an adequate large number of training samples and\nnetwork sizes, these networks, including over-parameterized ones, can\ngeneralize effectively. Additionally, we provide a necessary condition for\ngeneralization, demonstrating that, for certain data distributions, the\nquantity of training data required to ensure generalization exceeds the network\nsize needed to represent the corresponding data distribution. Finally, we\nprovide theoretical insights into several phenomena in deep learning, including\nrobust generalization, importance of over-parameterization, and effect of loss\nfunction on generalization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04111v1",
    "published_date": "2025-03-06 05:36:35 UTC",
    "updated_date": "2025-03-06 05:36:35 UTC"
  },
  {
    "arxiv_id": "2503.04110v2",
    "title": "InterChat: Enhancing Generative Visual Analytics using Multimodal Interactions",
    "authors": [
      "Juntong Chen",
      "Jiang Wu",
      "Jiajing Guo",
      "Vikram Mohanty",
      "Xueming Li",
      "Jorge Piazentin Ono",
      "Wenbin He",
      "Liu Ren",
      "Dongyu Liu"
    ],
    "abstract": "The rise of Large Language Models (LLMs) and generative visual analytics\nsystems has transformed data-driven insights, yet significant challenges\npersist in accurately interpreting users' analytical and interaction intents.\nWhile language inputs offer flexibility, they often lack precision, making the\nexpression of complex intents inefficient, error-prone, and time-intensive. To\naddress these limitations, we investigate the design space of multimodal\ninteractions for generative visual analytics through a literature review and\npilot brainstorming sessions. Building on these insights, we introduce a highly\nextensible workflow that integrates multiple LLM agents for intent inference\nand visualization generation. We develop InterChat, a generative visual\nanalytics system that combines direct manipulation of visual elements with\nnatural language inputs. This integration enables precise intent communication\nand supports progressive, visually driven exploratory data analyses. By\nemploying effective prompt engineering, and contextual interaction linking,\nalongside intuitive visualization and interaction designs, InterChat bridges\nthe gap between user interactions and LLM-driven visualizations, enhancing both\ninterpretability and usability. Extensive evaluations, including two usage\nscenarios, a user study, and expert feedback, demonstrate the effectiveness of\nInterChat. Results show significant improvements in the accuracy and efficiency\nof handling complex visual analytics tasks, highlighting the potential of\nmultimodal interactions to redefine user engagement and analytical depth in\ngenerative visual analytics.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "This work is accepted by the 27th Eurographics Conference on\n  Visualization (EuroVis 2025). The paper contains 12 pages and 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04110v2",
    "published_date": "2025-03-06 05:35:19 UTC",
    "updated_date": "2025-04-16 01:11:35 UTC"
  },
  {
    "arxiv_id": "2503.04099v1",
    "title": "Disparities in LLM Reasoning Accuracy and Explanations: A Case Study on African American English",
    "authors": [
      "Runtao Zhou",
      "Guangya Wan",
      "Saadia Gabriel",
      "Sheng Li",
      "Alexander J Gates",
      "Maarten Sap",
      "Thomas Hartvigsen"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nreasoning tasks, leading to their widespread deployment. However, recent\nstudies have highlighted concerning biases in these models, particularly in\ntheir handling of dialectal variations like African American English (AAE). In\nthis work, we systematically investigate dialectal disparities in LLM reasoning\ntasks. We develop an experimental framework comparing LLM performance given\nStandard American English (SAE) and AAE prompts, combining LLM-based dialect\nconversion with established linguistic analyses. We find that LLMs consistently\nproduce less accurate responses and simpler reasoning chains and explanations\nfor AAE inputs compared to equivalent SAE questions, with disparities most\npronounced in social science and humanities domains. These findings highlight\nsystematic differences in how LLMs process and reason about different language\nvarieties, raising important questions about the development and deployment of\nthese systems in our multilingual and multidialectal world. Our code repository\nis publicly available at https://github.com/Runtaozhou/dialect_bias_eval.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ARR Under Review, First two authors contribute equally",
    "pdf_url": "http://arxiv.org/pdf/2503.04099v1",
    "published_date": "2025-03-06 05:15:34 UTC",
    "updated_date": "2025-03-06 05:15:34 UTC"
  },
  {
    "arxiv_id": "2503.04095v2",
    "title": "Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts",
    "authors": [
      "Xiangnan Chen",
      "Yuancheng Fang",
      "Qian Xiao",
      "Juncheng Li",
      "Jun Lin",
      "Siliang Tang",
      "Yi Yang",
      "Yueting Zhuang"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have garnered significant attention\nfor their strong visual-semantic understanding. Most existing chart benchmarks\nevaluate MLLMs' ability to parse information from charts to answer questions.\nHowever, they overlook the inherent output biases of MLLMs, where models rely\non their parametric memory to answer questions rather than genuinely\nunderstanding the chart content. To address this limitation, we introduce a\nnovel Chart Hypothetical Question Answering (HQA) task, which imposes\nassumptions on the same question to compel models to engage in counterfactual\nreasoning based on the chart content. Furthermore, we introduce HAI, a human-AI\ninteractive data synthesis approach that leverages the efficient text-editing\ncapabilities of LLMs alongside human expert knowledge to generate diverse and\nhigh-quality HQA data at a low cost. Using HAI, we construct Chart-HQA, a\nchallenging benchmark synthesized from publicly available data sources.\nEvaluation results on 18 MLLMs of varying model sizes reveal that current\nmodels face significant generalization challenges and exhibit imbalanced\nreasoning performance on the HQA task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2503.04095v2",
    "published_date": "2025-03-06 05:08:40 UTC",
    "updated_date": "2025-03-07 05:18:44 UTC"
  },
  {
    "arxiv_id": "2503.04085v1",
    "title": "SED2AM: Solving Multi-Trip Time-Dependent Vehicle Routing Problem using Deep Reinforcement Learning",
    "authors": [
      "Arash Mozhdehi",
      "Yunli Wang",
      "Sun Sun",
      "Xin Wang"
    ],
    "abstract": "Deep reinforcement learning (DRL)-based frameworks, featuring\nTransformer-style policy networks, have demonstrated their efficacy across\nvarious vehicle routing problem (VRP) variants. However, the application of\nthese methods to the multi-trip time-dependent vehicle routing problem\n(MTTDVRP) with maximum working hours constraints -- a pivotal element of urban\nlogistics -- remains largely unexplored. This paper introduces a DRL-based\nmethod called the Simultaneous Encoder and Dual Decoder Attention Model\n(SED2AM), tailored for the MTTDVRP with maximum working hours constraints. The\nproposed method introduces a temporal locality inductive bias to the encoding\nmodule of the policy networks, enabling it to effectively account for the\ntime-dependency in travel distance or time. The decoding module of SED2AM\nincludes a vehicle selection decoder that selects a vehicle from the fleet,\neffectively associating trips with vehicles for functional multi-trip routing.\nAdditionally, this decoding module is equipped with a trip construction decoder\nleveraged for constructing trips for the vehicles. This policy model is\nequipped with two classes of state representations, fleet state and routing\nstate, providing the information needed for effective route construction in the\npresence of maximum working hours constraints. Experimental results using\nreal-world datasets from two major Canadian cities not only show that SED2AM\noutperforms the current state-of-the-art DRL-based and metaheuristic-based\nbaselines but also demonstrate its generalizability to solve larger-scale\nproblems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ACM TKDD: https://dl.acm.org/doi/10.1145/3721983",
    "pdf_url": "http://arxiv.org/pdf/2503.04085v1",
    "published_date": "2025-03-06 04:47:49 UTC",
    "updated_date": "2025-03-06 04:47:49 UTC"
  },
  {
    "arxiv_id": "2503.04074v1",
    "title": "Can We Optimize Deep RL Policy Weights as Trajectory Modeling?",
    "authors": [
      "Hongyao Tang"
    ],
    "abstract": "Learning the optimal policy from a random network initialization is the theme\nof deep Reinforcement Learning (RL). As the scale of DRL training increases,\ntreating DRL policy network weights as a new data modality and exploring the\npotential becomes appealing and possible. In this work, we focus on the policy\nlearning path in deep RL, represented by the trajectory of network weights of\nhistorical policies, which reflects the evolvement of the policy learning\nprocess. Taking the idea of trajectory modeling with Transformer, we propose\nTransformer as Implicit Policy Learner (TIPL), which processes policy network\nweights in an autoregressive manner. We collect the policy learning path data\nby running independent RL training trials, with which we then train our TIPL\nmodel. In the experiments, we demonstrate that TIPL is able to fit the implicit\ndynamics of policy learning and perform the optimization of policy network by\ninference.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as an extended abstract to ICLR 2025 Workshop on Weight\n  Space Learning (WSL)",
    "pdf_url": "http://arxiv.org/pdf/2503.04074v1",
    "published_date": "2025-03-06 04:12:22 UTC",
    "updated_date": "2025-03-06 04:12:22 UTC"
  },
  {
    "arxiv_id": "2503.04065v2",
    "title": "PP-DocBee: Improving Multimodal Document Understanding Through a Bag of Tricks",
    "authors": [
      "Feng Ni",
      "Kui Huang",
      "Yao Lu",
      "Wenyu Lv",
      "Guanzhong Wang",
      "Zeyu Chen",
      "Yi Liu"
    ],
    "abstract": "With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04065v2",
    "published_date": "2025-03-06 03:43:21 UTC",
    "updated_date": "2025-03-10 03:22:24 UTC"
  },
  {
    "arxiv_id": "2503.04064v1",
    "title": "Uncovering inequalities in new knowledge learning by large language models across different languages",
    "authors": [
      "Chenglong Wang",
      "Haoyu Tang",
      "Xiyuan Yang",
      "Yueqi Xie",
      "Jina Suh",
      "Sunayana Sitaram",
      "Junming Huang",
      "Yu Xie",
      "Zhaoya Gong",
      "Xing Xie",
      "Fangzhao Wu"
    ],
    "abstract": "As large language models (LLMs) gradually become integral tools for problem\nsolving in daily life worldwide, understanding linguistic inequality is\nbecoming increasingly important. Existing research has primarily focused on\nstatic analyses that assess the disparities in the existing knowledge and\ncapabilities of LLMs across languages. However, LLMs are continuously evolving,\nacquiring new knowledge to generate up-to-date, domain-specific responses.\nInvestigating linguistic inequalities within this dynamic process is,\ntherefore, also essential. In this paper, we explore inequalities in new\nknowledge learning by LLMs across different languages and four key dimensions:\neffectiveness, transferability, prioritization, and robustness. Through\nextensive experiments under two settings (in-context learning and fine-tuning)\nusing both proprietary and open-source models, we demonstrate that low-resource\nlanguages consistently face disadvantages across all four dimensions. By\nshedding light on these disparities, we aim to raise awareness of linguistic\ninequalities in LLMs' new knowledge learning, fostering the development of more\ninclusive and equitable future LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04064v1",
    "published_date": "2025-03-06 03:41:47 UTC",
    "updated_date": "2025-03-06 03:41:47 UTC"
  },
  {
    "arxiv_id": "2503.04046v1",
    "title": "Continual Optimization with Symmetry Teleportation for Multi-Task Learning",
    "authors": [
      "Zhipeng Zhou",
      "Ziqiao Meng",
      "Pengcheng Wu",
      "Peilin Zhao",
      "Chunyan Miao"
    ],
    "abstract": "Multi-task learning (MTL) is a widely explored paradigm that enables the\nsimultaneous learning of multiple tasks using a single model. Despite numerous\nsolutions, the key issues of optimization conflict and task imbalance remain\nunder-addressed, limiting performance. Unlike existing optimization-based\napproaches that typically reweight task losses or gradients to mitigate\nconflicts or promote progress, we propose a novel approach based on Continual\nOptimization with Symmetry Teleportation (COST). During MTL optimization, when\nan optimization conflict arises, we seek an alternative loss-equivalent point\non the loss landscape to reduce conflict. Specifically, we utilize a low-rank\nadapter (LoRA) to facilitate this practical teleportation by designing\nconvergent, loss-invariant objectives. Additionally, we introduce a historical\ntrajectory reuse strategy to continually leverage the benefits of advanced\noptimizers. Extensive experiments on multiple mainstream datasets demonstrate\nthe effectiveness of our approach. COST is a plug-and-play solution that\nenhances a wide range of existing MTL methods. When integrated with\nstate-of-the-art methods, COST achieves superior performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages,8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04046v1",
    "published_date": "2025-03-06 02:58:09 UTC",
    "updated_date": "2025-03-06 02:58:09 UTC"
  },
  {
    "arxiv_id": "2503.04021v1",
    "title": "TextDoctor: Unified Document Image Inpainting via Patch Pyramid Diffusion Models",
    "authors": [
      "Wanglong Lu",
      "Lingming Su",
      "Jingjing Zheng",
      "Vinícius Veloso de Melo",
      "Farzaneh Shoeleh",
      "John Hawkin",
      "Terrence Tricco",
      "Hanli Zhao",
      "Xianta Jiang"
    ],
    "abstract": "Digital versions of real-world text documents often suffer from issues like\nenvironmental corrosion of the original document, low-quality scanning, or\nhuman interference. Existing document restoration and inpainting methods\ntypically struggle with generalizing to unseen document styles and handling\nhigh-resolution images. To address these challenges, we introduce TextDoctor, a\nnovel unified document image inpainting method. Inspired by human reading\nbehavior, TextDoctor restores fundamental text elements from patches and then\napplies diffusion models to entire document images instead of training models\non specific document types. To handle varying text sizes and avoid\nout-of-memory issues, common in high-resolution documents, we propose using\nstructure pyramid prediction and patch pyramid diffusion models. These\ntechniques leverage multiscale inputs and pyramid patches to enhance the\nquality of inpainting both globally and locally. Extensive qualitative and\nquantitative experiments on seven public datasets validated that TextDoctor\noutperforms state-of-the-art methods in restoring various types of\nhigh-resolution document images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68U10",
      "I.4.3; I.4.4; I.4.5; I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "28 pages, 25 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04021v1",
    "published_date": "2025-03-06 02:16:35 UTC",
    "updated_date": "2025-03-06 02:16:35 UTC"
  },
  {
    "arxiv_id": "2503.07643v1",
    "title": "ConstellationNet: Reinventing Spatial Clustering through GNNs",
    "authors": [
      "Aidan Gao",
      "Junhong Lin"
    ],
    "abstract": "Spatial clustering is a crucial field, finding universal use across\ncriminology, pathology, and urban planning. However, most spatial clustering\nalgorithms cannot pull information from nearby nodes and suffer performance\ndrops when dealing with higher dimensionality and large datasets, making them\nsuboptimal for large-scale and high-dimensional clustering. Due to modern data\ngrowing in size and dimension, clustering algorithms become weaker when\naddressing multifaceted issues. To improve upon this, we develop\nConstellationNet, a convolution neural network(CNN)-graph neural network(GNN)\nframework that leverages the embedding power of a CNN, the neighbor aggregation\nof a GNN, and a neural network's ability to deal with batched data to improve\nspatial clustering and classification with graph augmented predictions.\nConstellationNet achieves state-of-the-art performance on both supervised\nclassification and unsupervised clustering across several datasets,\noutperforming state-of-the-art classification and clustering while reducing\nmodel size and training time by up to tenfold and improving baselines by 10\ntimes. Because of its fast training and powerful nature, ConstellationNet holds\npromise in fields like epidemiology and medical imaging, able to quickly train\non new data to develop robust responses.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07643v1",
    "published_date": "2025-03-06 02:10:11 UTC",
    "updated_date": "2025-03-06 02:10:11 UTC"
  },
  {
    "arxiv_id": "2503.04013v1",
    "title": "Benchmarking Large Language Models on Multiple Tasks in Bioinformatics NLP with Prompting",
    "authors": [
      "Jiyue Jiang",
      "Pengan Chen",
      "Jiuming Wang",
      "Dongchen He",
      "Ziqin Wei",
      "Liang Hong",
      "Licheng Zong",
      "Sheng Wang",
      "Qinze Yu",
      "Zixian Ma",
      "Yanyu Chen",
      "Yimin Fan",
      "Xiangyu Shi",
      "Jiawei Sun",
      "Chuan Wu",
      "Yu Li"
    ],
    "abstract": "Large language models (LLMs) have become important tools in solving\nbiological problems, offering improvements in accuracy and adaptability over\nconventional methods. Several benchmarks have been proposed to evaluate the\nperformance of these LLMs. However, current benchmarks can hardly evaluate the\nperformance of these models across diverse tasks effectively. In this paper, we\nintroduce a comprehensive prompting-based benchmarking framework, termed\nBio-benchmark, which includes 30 key bioinformatics tasks covering areas such\nas proteins, RNA, drugs, electronic health records, and traditional Chinese\nmedicine. Using this benchmark, we evaluate six mainstream LLMs, including\nGPT-4o and Llama-3.1-70b, etc., using 0-shot and few-shot Chain-of-Thought\n(CoT) settings without fine-tuning to reveal their intrinsic capabilities. To\nimprove the efficiency of our evaluations, we demonstrate BioFinder, a new tool\nfor extracting answers from LLM responses, which increases extraction accuracy\nby round 30% compared to existing methods. Our benchmark results show the\nbiological tasks suitable for current LLMs and identify specific areas\nrequiring enhancement. Furthermore, we propose targeted prompt engineering\nstrategies for optimizing LLM performance in these contexts. Based on these\nfindings, we provide recommendations for the development of more robust LLMs\ntailored for various biological applications. This work offers a comprehensive\nevaluation framework and robust tools to support the application of LLMs in\nbioinformatics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04013v1",
    "published_date": "2025-03-06 02:01:59 UTC",
    "updated_date": "2025-03-06 02:01:59 UTC"
  },
  {
    "arxiv_id": "2503.03995v1",
    "title": "Subgraph Federated Learning for Local Generalization",
    "authors": [
      "Sungwon Kim",
      "Yoonho Lee",
      "Yunhak Oh",
      "Namkyeong Lee",
      "Sukwon Yun",
      "Junseok Lee",
      "Sein Kim",
      "Carl Yang",
      "Chanyoung Park"
    ],
    "abstract": "Federated Learning (FL) on graphs enables collaborative model training to\nenhance performance without compromising the privacy of each client. However,\nexisting methods often overlook the mutable nature of graph data, which\nfrequently introduces new nodes and leads to shifts in label distribution.\nSince they focus solely on performing well on each client's local data, they\nare prone to overfitting to their local distributions (i.e., local\noverfitting), which hinders their ability to generalize to unseen data with\ndiverse label distributions. In contrast, our proposed method, FedLoG,\neffectively tackles this issue by mitigating local overfitting. Our model\ngenerates global synthetic data by condensing the reliable information from\neach class representation and its structural information across clients. Using\nthese synthetic data as a training set, we alleviate the local overfitting\nproblem by adaptively generalizing the absent knowledge within each local\ndataset. This enhances the generalization capabilities of local models,\nenabling them to handle unseen data effectively. Our model outperforms\nbaselines in our proposed experimental settings, which are designed to measure\ngeneralization power to unseen data in practical scenarios. Our code is\navailable at https://github.com/sung-won-kim/FedLoG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 (oral)",
    "pdf_url": "http://arxiv.org/pdf/2503.03995v1",
    "published_date": "2025-03-06 01:08:01 UTC",
    "updated_date": "2025-03-06 01:08:01 UTC"
  },
  {
    "arxiv_id": "2503.03987v1",
    "title": "RetinalGPT: A Retinal Clinical Preference Conversational Assistant Powered by Large Vision-Language Models",
    "authors": [
      "Wenhui Zhu",
      "Xin Li",
      "Xiwen Chen",
      "Peijie Qiu",
      "Vamsi Krishna Vasa",
      "Xuanzhao Dong",
      "Yanxi Chen",
      "Natasha Lepore",
      "Oana Dumitrascu",
      "Yi Su",
      "Yalin Wang"
    ],
    "abstract": "Recently, Multimodal Large Language Models (MLLMs) have gained significant\nattention for their remarkable ability to process and analyze non-textual data,\nsuch as images, videos, and audio. Notably, several adaptations of\ngeneral-domain MLLMs to the medical field have been explored, including\nLLaVA-Med. However, these medical adaptations remain insufficiently advanced in\nunderstanding and interpreting retinal images. In contrast, medical experts\nemphasize the importance of quantitative analyses for disease detection and\ninterpretation. This underscores a gap between general-domain and\nmedical-domain MLLMs: while general-domain MLLMs excel in broad applications,\nthey lack the specialized knowledge necessary for precise diagnostic and\ninterpretative tasks in the medical field. To address these challenges, we\nintroduce \\textit{RetinalGPT}, a multimodal conversational assistant for\nclinically preferred quantitative analysis of retinal images. Specifically, we\nachieve this by compiling a large retinal image dataset, developing a novel\ndata pipeline, and employing customized visual instruction tuning to enhance\nboth retinal analysis and enrich medical knowledge. In particular, RetinalGPT\noutperforms MLLM in the generic domain by a large margin in the diagnosis of\nretinal diseases in 8 benchmark retinal datasets. Beyond disease diagnosis,\nRetinalGPT features quantitative analyses and lesion localization, representing\na pioneering step in leveraging LLMs for an interpretable and end-to-end\nclinical research framework. The code is available at\nhttps://github.com/Retinal-Research/RetinalGPT",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03987v1",
    "published_date": "2025-03-06 00:19:54 UTC",
    "updated_date": "2025-03-06 00:19:54 UTC"
  },
  {
    "arxiv_id": "2503.03986v1",
    "title": "Training neural networks faster with minimal tuning using pre-computed lists of hyperparameters for NAdamW",
    "authors": [
      "Sourabh Medapati",
      "Priya Kasimbeg",
      "Shankar Krishnan",
      "Naman Agarwal",
      "George Dahl"
    ],
    "abstract": "If we want to train a neural network using any of the most popular\noptimization algorithms, we are immediately faced with a dilemma: how to set\nthe various optimization and regularization hyperparameters? When computational\nresources are abundant, there are a variety of methods for finding good\nhyperparameter settings, but when resources are limited the only realistic\nchoices are using standard default values of uncertain quality and provenance,\nor tuning only a couple of the most important hyperparameters via extremely\nlimited handdesigned sweeps. Extending the idea of default settings to a modest\ntuning budget, Metz et al. (2020) proposed using ordered lists of\nwell-performing hyperparameter settings, derived from a broad hyperparameter\nsearch on a large library of training workloads. However, to date, no practical\nand performant hyperparameter lists that generalize to representative deep\nlearning workloads have been demonstrated. In this paper, we present\nhyperparameter lists for NAdamW derived from extensive experiments on the\nrealistic workloads in the AlgoPerf: Training Algorithms benchmark. Our\nhyperparameter lists also include values for basic regularization techniques\n(i.e. weight decay, label smoothing, and dropout). In particular, our best\nNAdamW hyperparameter list performs well on AlgoPerf held-out workloads not\nused to construct it, and represents a compelling turn-key approach to tuning\nwhen restricted to five or fewer trials. It also outperforms basic learning\nrate/weight decay sweeps and an off-the-shelf Bayesian optimization tool when\nrestricted to the same budget.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Good defaults for NadamW Optimizer, generalizes well to unseen\n  problems",
    "pdf_url": "http://arxiv.org/pdf/2503.03986v1",
    "published_date": "2025-03-06 00:14:50 UTC",
    "updated_date": "2025-03-06 00:14:50 UTC"
  },
  {
    "arxiv_id": "2503.05830v1",
    "title": "AI-Facilitated Collective Judgements",
    "authors": [
      "Manon Revel",
      "Théophile Pénigaud"
    ],
    "abstract": "This article unpacks the design choices behind longstanding and newly\nproposed computational frameworks aimed at finding common grounds across\ncollective preferences and examines their potential future impacts, both\ntechnically and normatively. It begins by situating AI-assisted preference\nelicitation within the historical role of opinion polls, emphasizing that\npreferences are shaped by the decision-making context and are seldom\nobjectively captured. With that caveat in mind, we explore AI-facilitated\ncollective judgment as a discovery tool for fostering reasonable\nrepresentations of a collective will, sense-making, and agreement-seeking. At\nthe same time, we caution against dangerously misguided uses, such as enabling\nbinding decisions, fostering gradual disempowerment or post-rationalizing\npolitical outcomes.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05830v1",
    "published_date": "2025-03-06 00:06:22 UTC",
    "updated_date": "2025-03-06 00:06:22 UTC"
  },
  {
    "arxiv_id": "2503.03979v1",
    "title": "ReasonGraph: Visualisation of Reasoning Paths",
    "authors": [
      "Zongqian Li",
      "Ehsan Shareghi",
      "Nigel Collier"
    ],
    "abstract": "Large Language Models (LLMs) reasoning processes are challenging to analyze\ndue to their complexity and the lack of organized visualization tools. We\npresent ReasonGraph, a web-based platform for visualizing and analyzing LLM\nreasoning processes. It supports both sequential and tree-based reasoning\nmethods while integrating with major LLM providers and over fifty\nstate-of-the-art models. ReasonGraph incorporates an intuitive UI with meta\nreasoning method selection, configurable visualization parameters, and a\nmodular framework that facilitates efficient extension. Our evaluation shows\nhigh parsing reliability, efficient processing, and strong usability across\nvarious downstream applications. By providing a unified visualization\nframework, ReasonGraph reduces cognitive load in analyzing complex reasoning\npaths, improves error detection in logical processes, and enables more\neffective development of LLM-based applications. The platform is open-source,\npromoting accessibility and reproducibility in LLM reasoning analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03979v1",
    "published_date": "2025-03-06 00:03:55 UTC",
    "updated_date": "2025-03-06 00:03:55 UTC"
  }
]