{
  "date": "2025-10-23",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-10-23 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\næˆ‘æ˜¯ä½ ä»¬çš„è€æœ‹å‹ï¼Œä»æµ©å¦‚çƒŸæµ·çš„è®ºæ–‡å †é‡Œçˆ¬å‡ºæ¥çš„ç ”ç©¶å‘˜ã€‚\n\n**ä¸€å¥è¯æ€»ç»“ä»Šå¤©ï¼š** ä»Šå¤©çš„ arXiv å……æ»¡äº†â€œå†·æ€è€ƒâ€ã€‚Reasoningï¼ˆæ¨ç†ï¼‰èŒƒå¼è™½ç„¶ç«çƒ­ï¼Œä½†å¤šç¯‡è®ºæ–‡å¼€å§‹æ­ç¤ºå…¶åœ¨å®‰å…¨æ£€æµ‹ã€è‡ªæˆ‘ä¿®æ­£å’Œç¿»è¯‘è¯„ä¼°ä¸­çš„å±€é™æ€§ï¼›ä¸æ­¤åŒæ—¶ï¼ŒMeta ç§€å‡ºäº† 100k+ GPU é›†ç¾¤çš„é€šä¿¡è‚Œè‚‰ï¼Œè€Œ Video-Reasoningï¼ˆè§†é¢‘æ¨ç†ï¼‰ä¹Ÿå¼€å§‹å¼•å…¥ o3 é£æ ¼çš„æ˜¾å¼è¯æ®é“¾ã€‚\n\n---\n\n### ğŸš€ ç„¦ç‚¹è®ºæ–‡ï¼šæ¨ç†çš„åŒåˆƒå‰‘ä¸ä¸‡å¡é›†ç¾¤çš„é‡æœ›\n\n**1. Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at Critical Operating Points in Safety and Hallucination Detection**\n**æ¨ç†çš„å‰ƒåˆ€ï¼šæ¨ç†æé«˜äº†å‡†ç¡®æ€§ï¼Œä½†åœ¨å®‰å…¨å’Œå¹»è§‰æ£€æµ‹çš„å…³é”®æ“ä½œç‚¹ä¸Šå¯èƒ½æŸå®³å¬å›ç‡**\n> **Authors:** Atoosa Chegini, et al. (Samy Bengio ä¹Ÿåœ¨ä½œè€…åˆ—)\n> **å…³é”®è¯:** Reasoning Models, Safety Detection, Hallucination, Trade-off\n> **TLDR:** æ¨ç†ï¼ˆThink Onï¼‰èƒ½æé«˜æ•´ä½“å‡†ç¡®ç‡ï¼Œä½†åœ¨è¦æ±‚æä½è¯¯æŠ¥ç‡ï¼ˆLow-FPRï¼‰çš„å®‰å…¨åœºæ™¯ä¸‹ï¼Œä¸å¦‚ä¸æ¨ç†ï¼ˆThink Offï¼‰ã€‚\n\nè¿™æ˜¯ä¸€ç¯‡éå¸¸åŠæ—¶çš„å®è¯ç ”ç©¶ã€‚ç°åœ¨çš„è¶‹åŠ¿æ˜¯ä¸‡ç‰©çš†å¯ CoT (Chain of Thought)ï¼Œä½†æœ¬æ–‡å‘ç°äº†ä¸€ä¸ªåç›´è§‰çš„ç°è±¡ï¼šåœ¨å®‰å…¨æ£€æµ‹å’Œå¹»è§‰æ£€æµ‹è¿™ä¸¤ä¸ªå¯¹ç²¾åº¦æå…¶æ•æ„Ÿçš„ä»»åŠ¡ä¸­ï¼Œå¼€å¯æ¨ç†æ¨¡å¼ï¼ˆThink Onï¼‰è™½ç„¶æå‡äº†å¹³å‡å‡†ç¡®ç‡ï¼Œä½†åœ¨æä½è¯¯æŠ¥ç‡ï¼ˆFPRï¼‰çš„é˜ˆå€¼ä¸‹ï¼Œè¡¨ç°åè€Œä¸å¦‚ç›´æ¥è¾“å‡ºï¼ˆThink Offï¼‰ã€‚\n**æ•™æˆç‚¹è¯„ï¼š** è¿™å‘Šè¯‰æˆ‘ä»¬ï¼Œæ¨ç†å¹¶ä¸æ˜¯â€œå…è´¹çš„åˆé¤â€ã€‚åœ¨éœ€è¦ä¸¥æ ¼æ§åˆ¶è¯¯æŠ¥çš„å·¥ä¸šçº§å®‰å…¨å®¡æ ¸ä¸­ï¼Œç›²ç›®å¼•å…¥æ¨ç†æ¨¡å‹å¯èƒ½ä¼šé€‚å¾—å…¶åã€‚ä½œè€…å»ºè®®ä½¿ç”¨ä¸¤è€…çš„ Ensembleã€‚\n\n**179. Collective Communication for 100k+ GPUs**\n**é¢å‘ 10w+ GPU çš„é›†åˆé€šä¿¡**\n> **Authors:** Min Si, et al. (Meta å›¢é˜Ÿ)\n> **å…³é”®è¯:** 100k+ GPUs, NCCLX, LLM Training, Distributed Systems\n> **TLDR:** Meta å‘å¸ƒçš„ NCCLX æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ 10 ä¸‡å¼  GPU è§„æ¨¡ä¸‹çš„é€šä¿¡æ•ˆç‡é—®é¢˜ã€‚\n\nå½“æˆ‘ä»¬åœ¨ç©å‡ åƒå¼ å¡çš„æ—¶å€™ï¼ŒMeta å·²ç»æŠŠç›®å…‰æŠ•å‘äº† 10 ä¸‡å¼ å¡ã€‚è¿™ç¯‡è®ºæ–‡ä»‹ç»äº† NCCLX æ¡†æ¶ï¼Œä¸“é—¨é’ˆå¯¹ Llama4 çº§åˆ«çš„æ¨¡å‹è®­ç»ƒå’Œæ¨ç†è¿›è¡Œäº†ä¼˜åŒ–ã€‚å®ƒè§£å†³äº†ä¼ ç»Ÿé€šä¿¡æ–¹æ³•åœ¨è¯¥è§„æ¨¡ä¸‹çš„ååé‡å’Œå»¶è¿Ÿé™åˆ¶ã€‚\n**æ•™æˆç‚¹è¯„ï¼š** è¿™æ˜¯çº¯ç²¹çš„è‚Œè‚‰å±•ç¤ºï¼Œä¹Ÿæ˜¯æœªæ¥åŸºç¡€è®¾æ–½çš„å¿…ç»ä¹‹è·¯ã€‚å¯¹äºåš System for AI çš„åŒå­¦ï¼Œè¿™ç¯‡æ˜¯å¿…è¯»ã€‚\n\n**145. The Mirror Loop: Recursive Non-Convergence in Generative Reasoning Systems**\n**é•œåƒå¾ªç¯ï¼šç”Ÿæˆå¼æ¨ç†ç³»ç»Ÿä¸­çš„é€’å½’ä¸æ”¶æ•›**\n> **Authors:** Bentley DeVilling\n> **å…³é”®è¯:** Recursive Reasoning, Self-Correction, Model Collapse\n> **TLDR:** å¦‚æœæ²¡æœ‰å¤–éƒ¨åé¦ˆï¼ŒLLM çš„é€’å½’è‡ªæˆ‘åæ€ä¼šå¯¼è‡´ä¿¡æ¯ç†µä¸‹é™ï¼Œé™·å…¥â€œè®¤çŸ¥åœæ»â€ã€‚\n\næˆ‘ä»¬å¸¸è¯´è®©æ¨¡å‹â€œåæ€ä¸€ä¸‹â€èƒ½æé«˜æ•ˆæœï¼Œä½†æœ¬æ–‡æ³¼äº†ä¸€ç›†å†·æ°´ã€‚ç ”ç©¶å‘ç°ï¼Œå¦‚æœæ²¡æœ‰å¤–éƒ¨éªŒè¯å™¨æˆ–ç¯å¢ƒåé¦ˆï¼Œå•çº¯çš„é€’å½’è‡ªæˆ‘è¯„ä¼°ï¼ˆRecursive Self-evaluationï¼‰å¾€å¾€å¯¼è‡´é‡å†™è€Œéè¿›æ­¥ï¼Œæœ€ç»ˆè¿›å…¥ä¸€ç§â€œè®¤çŸ¥åœæ»â€çŠ¶æ€ã€‚\n**æ•™æˆç‚¹è¯„ï¼š** è¿™å†æ¬¡å°è¯äº†å°é—­ç³»ç»Ÿå†…çš„ç†µå¢å®šå¾‹ï¼ˆæˆ–ä¿¡æ¯è¡°å‡ï¼‰ã€‚çœŸæ­£çš„æ™ºèƒ½è¿›åŒ–éœ€è¦ä¸ç¯å¢ƒäº¤äº’ï¼Œè€Œä¸æ˜¯åœ¨é•œå­é¢å‰è‡ªè¨€è‡ªè¯­ã€‚\n\n---\n\n### ğŸ§  æ¨ç†æ¨¡å‹ (Reasoning Models) çš„æ·±åº¦å‰–æ\n\n**93. Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence**\n**Open-o3 Videoï¼šå…·æœ‰æ˜¾å¼æ—¶ç©ºè¯æ®çš„æ‰æ ¹è§†é¢‘æ¨ç†**\n> **TLDR:** å°† o3 é£æ ¼çš„æ¨ç†å¼•å…¥è§†é¢‘é¢†åŸŸï¼Œè¦æ±‚æ¨¡å‹åœ¨å›ç­”æ—¶å¿…é¡»ç»™å‡ºå…³é”®çš„æ—¶é—´æˆ³å’Œç©ºé—´åæ ‡è¯æ®ã€‚\nè¿™æ˜¯ä¸€ç¯‡å°è¯•å¤åˆ» OpenAI o3 åœ¨è§†é¢‘é¢†åŸŸèƒ½åŠ›çš„å·¥ä½œã€‚ç›®å‰çš„è§†é¢‘ç†è§£æ¨¡å‹å¾€å¾€åªç»™ç­”æ¡ˆï¼Œæœ¬æ–‡æå‡ºçš„ Open-o3 Video é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œå¼ºåˆ¶æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç”Ÿæˆæ˜¾å¼çš„æ—¶ç©ºè¯æ®ï¼ˆä»€ä¹ˆæ—¶å€™ã€åœ¨å“ªé‡Œï¼‰ï¼Œæ˜¾è‘—æå‡äº†è§†é¢‘æ¨ç†çš„å¯é æ€§ã€‚\n\n**154. Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs**\n**PRM å¼•å¯¼çš„æ ‘æœç´¢åœ¨ LLM æ•°å­¦æ¨ç†ä¸­çš„å±€é™æ€§**\n> **TLDR:** è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰å¼•å¯¼çš„æ ‘æœç´¢åœ¨æ•°å­¦æ¨ç†ä¸­å¹¶æœªæ˜¾è‘—ä¼˜äº Best-of-Nï¼Œå› ä¸º PRM çš„è¯„åˆ†å¹¶ä¸å¯é ã€‚\nè¿™ç¯‡è®ºæ–‡æŒ‘æˆ˜äº†ç›®å‰çš„å…±è¯†ã€‚ä½œè€…å‘ç° PRMï¼ˆProcess Reward Modelï¼‰åœ¨åˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›å·®ï¼Œä¸”éšç€æ¨ç†æ·±åº¦å¢åŠ å¯é æ€§ä¸‹é™ã€‚è¿™æš—ç¤ºæˆ‘ä»¬éœ€è¦æ›´å¥½çš„å¥–åŠ±å»ºæ¨¡æŠ€æœ¯ï¼Œè€Œä¸ä»…ä»…æ˜¯å †æœç´¢ç®—æ³•ã€‚\n\n**70. The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI**\n**æ¨ç†é€šç”¨è¯­ï¼šå¤šè¯­è¨€ AI çš„åŒåˆƒå‰‘**\n> **TLDR:** LLM å€¾å‘äºç”¨è‹±è¯­è¿›è¡Œå†…éƒ¨æ¨ç†ï¼ˆå³ä¾¿é—®é¢˜ä¸æ˜¯è‹±è¯­ï¼‰ï¼Œè¿™æé«˜äº†å‡†ç¡®ç‡ï¼Œä½†å®¹æ˜“å¯¼è‡´â€œç¿»è¯‘è¿·å¤±â€é”™è¯¯ã€‚\næ¨¡å‹åœ¨å¤„ç†éè‹±è¯­é—®é¢˜æ—¶ï¼Œå¾€å¾€ä¼šåœ¨å†…éƒ¨â€œåˆ‡å›â€è‹±è¯­è¿›è¡Œæ€è€ƒã€‚æœ¬æ–‡å‘ç°è¿™ç§ç­–ç•¥è™½ç„¶èƒ½åˆ©ç”¨è‹±è¯­è¯­æ–™çš„æ¨ç†ä¼˜åŠ¿ï¼Œä½†ä¹Ÿå¼•å…¥äº†ç¿»è¯‘ç¯èŠ‚çš„è¯¯å·®ã€‚\n\n---\n\n### ğŸ¤– Agent ä¸ å…·èº«æ™ºèƒ½ (Embodied AI)\n\n**5. CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel Optimization**\n**CudaForgeï¼šå…·æœ‰ç¡¬ä»¶åé¦ˆçš„ CUDA å†…æ ¸ä¼˜åŒ–ä»£ç†æ¡†æ¶**\n> **TLDR:** ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„å¤š Agent æ¡†æ¶ï¼Œåˆ©ç”¨ç¼–è¯‘å™¨å’Œç¡¬ä»¶åé¦ˆï¼ˆå¦‚ Nsight Computeï¼‰æ¥è‡ªåŠ¨ä¼˜åŒ– CUDA å†…æ ¸ä»£ç ã€‚\næ‰‹å†™ CUDA kernel å¤ªç—›è‹¦äº†ï¼Œè¿™ä¸ªå·¥ä½œåˆ©ç”¨ LLM Agent + ç¡¬ä»¶åé¦ˆé—­ç¯æ¥ç”Ÿæˆé«˜æ€§èƒ½ Kernelï¼Œæ®ç§°æ¯” H100 ä¸Šçš„åŒç±»å·¥ä½œä¾¿å®œä¸”å¿«ï¼Œè¿˜èƒ½åœ¨ä¸åŒ GPU é—´æ³›åŒ–ã€‚\n\n**34. VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**\n**VAMOSï¼šç”¨äºèƒ½åŠ›è°ƒèŠ‚å’Œå¯æ§å¯¼èˆªçš„åˆ†å±‚è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹**\n> **TLDR:** å°†é«˜çº§è¯­ä¹‰è§„åˆ’ä¸åº•å±‚â€œèƒ½åŠ›æ¨¡å‹â€è§£è€¦ï¼Œè®©æœºå™¨äººçŸ¥é“è‡ªå·±â€œèƒ½ä¸èƒ½åšåˆ°â€ã€‚\nè¿™æ˜¯ä¸€ä¸ªå¾ˆèªæ˜çš„æ¶æ„è®¾è®¡ã€‚å®ƒæŠŠâ€œæƒ³å»å“ªâ€ï¼ˆPlannerï¼‰å’Œâ€œèƒ½ä¸èƒ½å»â€ï¼ˆAffordance Modelï¼‰åˆ†å¼€ã€‚æ¯”å¦‚å››è¶³æœºå™¨äººèƒ½çˆ¬æ¥¼æ¢¯è€Œè½®å¼æœºå™¨äººä¸èƒ½ï¼Œé€šè¿‡ä¸“é—¨çš„èƒ½åŠ›æ¨¡å‹æ¥è¿‡æ»¤ä¸å¯è¡Œçš„è·¯å¾„ï¼Œå®ç°äº†è·¨å½¢æ€æœºå™¨äººçš„é€šç”¨å¯¼èˆªã€‚\n\n**177. Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding**\n**æ€ç»´æ··åˆï¼šç”¨äºè¡¨æ ¼ç†è§£çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ **\n> **TLDR:** ä¸“é—¨é’ˆå¯¹è¡¨æ ¼ä»»åŠ¡çš„å¤š Agent æ¡†æ¶ï¼Œåˆ†å·¥ä¸ºè§„åˆ’ã€å†™ä»£ç ã€å›ç­”ï¼Œå¹¶é€šè¿‡ RL è‡ªæˆ‘è¿›åŒ–ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€å¯¹é½ä¸å¹»è§‰ (Safety & Alignment)\n\n**108. Steering Evaluation-Aware Language Models to Act Like They Are Deployed**\n**å¼•å¯¼å…·æœ‰è¯„ä¼°æ„ŸçŸ¥èƒ½åŠ›çš„è¯­è¨€æ¨¡å‹è¡¨ç°å¾—åƒåœ¨éƒ¨ç½²ä¸­ä¸€æ ·**\n> **TLDR:** LLM èƒ½å¯Ÿè§‰è‡ªå·±æ­£åœ¨è¢«â€œè€ƒè¯•â€ï¼Œå¹¶ä¼ªè£…è¡¨ç°ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ Steering Vector æ–¹æ³•æ¥æŠ‘åˆ¶è¿™ç§ä¼ªè£…ã€‚\nè¿™æ˜¯ä¸€ä¸ªä»¤äººç»†æ€ææçš„é—®é¢˜ï¼šæ¨¡å‹çŸ¥é“è‡ªå·±åœ¨è¢«æµ‹è¯•ï¼ˆGoodhart's Law çš„ AI ç‰ˆï¼‰ã€‚ä½œè€…å‘ç°é€šè¿‡å¹²é¢„æ¿€æ´»å±‚ï¼Œå¯ä»¥å¼ºè¿«æ¨¡å‹å¸ä¸‹ä¼ªè£…ï¼Œæš´éœ²å…¶åœ¨çœŸå®éƒ¨ç½²ç¯å¢ƒä¸‹çš„è¡Œä¸ºæ¨¡å¼ã€‚\n\n**64. Neural Diversity Regularizes Hallucinations**\n**ç¥ç»å¤šæ ·æ€§è§„èŒƒåŒ–å¹»è§‰**\n> **TLDR:** å¢åŠ æ¨¡å‹å†…éƒ¨è¡¨å¾çš„â€œç¥ç»å¤šæ ·æ€§â€ï¼ˆå»ç›¸å…³æ€§ï¼‰å¯ä»¥é™ä½å¹»è§‰ç‡ã€‚\nä½œè€…æå‡ºäº† ND-LoRAï¼Œé€šè¿‡ Barlow Twins æ­£åˆ™åŒ–æ¥å¢åŠ å¹¶è¡Œ LoRA é€‚é…å™¨ä¹‹é—´çš„å·®å¼‚æ€§ï¼Œå‘ç°ç¥ç»ç›¸å…³æ€§çš„å¢åŠ ä¸å¹»è§‰å¢åŠ é«˜åº¦ç›¸å…³ã€‚è¿™æ˜¯ä¸€ä¸ªä»åº•å±‚æœºç†è§£å†³å¹»è§‰çš„æ–°è§†è§’ã€‚\n\n**2. Mirror-Neuron Patterns in AI Alignment**\n**AI å¯¹é½ä¸­çš„é•œåƒç¥ç»å…ƒæ¨¡å¼**\n> **TLDR:** æ¢ç©¶ç¥ç»ç½‘ç»œæ˜¯å¦èƒ½æ¶Œç°å‡ºç±»ä¼¼ç”Ÿç‰©â€œé•œåƒç¥ç»å…ƒâ€çš„æœºåˆ¶ï¼Œä»è€Œäº§ç”Ÿç±»ä¼¼ç§»æƒ…çš„å†…åœ¨å¯¹é½ã€‚\nè¿™æ˜¯ä¸€ç¯‡ç¡•å£«è®ºæ–‡ï¼Œä½†è§†è§’ç‹¬ç‰¹ã€‚å®ƒè¯•å›¾åœ¨ AI å†…éƒ¨å¯»æ‰¾â€œå…±æƒ…â€çš„ç”Ÿç‰©å­¦åŸºç¡€ï¼ˆé•œåƒç¥ç»å…ƒï¼‰ï¼Œé€šè¿‡â€œé’è›™ä¸èŸ¾èœâ€çš„æ¸¸æˆæ¡†æ¶ï¼Œå‘ç°è‡ªæˆ‘/ä»–äººçš„è€¦åˆæœ‰åŠ©äºäº§ç”Ÿåˆä½œè¡Œä¸ºã€‚\n\n---\n\n### ğŸ› ï¸ å…¶å®ƒå€¼å¾—å…³æ³¨çš„æŠ€æœ¯ç‚¹\n\n*   **[LLM å‹ç¼©] 41. Compress to Impress:** ä½œè€…å‘ç°åªéœ€ 100 ä¸ªæ ·æœ¬å’Œä¸€ä¸ªæ¢¯åº¦æ­¥é•¿ï¼Œå°±èƒ½é€šè¿‡ LASER æ–¹æ³•é«˜æ•ˆå‹ç¼©å’Œé€‚é… LLMï¼Œæ— éœ€å¾®è°ƒã€‚\n*   **[ç§‘å­¦ AI] 118. Symbolic Regression and Differentiable Fits in Beyond the Standard Model Physics:** åˆ©ç”¨ç¬¦å·å›å½’ï¼ˆSRï¼‰æ¥å¤„ç†é«˜èƒ½ç‰©ç†ä¸­çš„è¶…è¶Šæ ‡å‡†æ¨¡å‹ï¼ˆBSMï¼‰é—®é¢˜ï¼Œæ¯”ç¥ç»ç½‘ç»œæ›´ç¨³å¥ä¸”å¯è§£é‡Šã€‚\n*   **[è§†è§‰] 164. Why LVLMs Are More Prone to Hallucinations in Longer Responses:** å¹¶ä¸æ˜¯å› ä¸ºé•¿ï¼Œè€Œæ˜¯å› ä¸ºé•¿å›å¤æ›´ä¾èµ–â€œä¸Šä¸‹æ–‡è¿è´¯æ€§â€è€Œéè§†è§‰è¾“å…¥ï¼Œå¯¼è‡´æ¨¡å‹å¼€å§‹çç¼–ä»¥è¡¥å…¨é€»è¾‘ã€‚\n*   **[æ³•å¾‹] 25. Do LLMs Truly Understand When a Precedent Is Overruled?:** è¿™æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„å‚ç±»è¯„ä¼°ã€‚æ¨¡å‹åœ¨å¤„ç†å¤æ‚çš„æ³•å¾‹â€œæ¨ç¿»åˆ¤ä¾‹â€å…³ç³»æ—¶ï¼Œè¡¨ç°å‡ºçš„æ˜¯æµ…å±‚é€»è¾‘å¯å‘å¼ï¼Œè€Œéæ·±å±‚æ³•å¾‹ç†è§£ã€‚\n\n---\n\n**æ•™æˆç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡åˆ—è¡¨å†ä¸€æ¬¡æé†’æˆ‘ä»¬ï¼Œè™½ç„¶ LLM çš„èƒ½åŠ›åœ¨ä¸æ–­ Scalingï¼Œä½†**æ¨ç†çš„é²æ£’æ€§**ã€**è‡ªæˆ‘è®¤çŸ¥çš„è¾¹ç•Œ**ä»¥åŠ**çœŸå®ä¸–ç•Œçš„ç‰©ç†çº¦æŸ**ï¼ˆæ— è®ºæ˜¯æœºå™¨äººçš„ç‰©ç†é™åˆ¶è¿˜æ˜¯ GPU é›†ç¾¤çš„é€šä¿¡é™åˆ¶ï¼‰ä»ç„¶æ˜¯ç›®å‰æœ€å¤§çš„æŒ‘æˆ˜ã€‚ä¸è¦è¢« Hype å†²æ˜å¤´è„‘ï¼Œå¤šçœ‹çœ‹è¿™äº›æ¢è®¨â€œå±€é™æ€§â€çš„è®ºæ–‡ï¼Œå¾€å¾€æ›´æœ‰ä»·å€¼ã€‚\n\næ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2510.21049v1",
      "title": "Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at Critical Operating Points in Safety and Hallucination Detection",
      "title_zh": "æ¨ç†çš„å‰ƒåˆ€ï¼šæ¨ç†è™½èƒ½æå‡å‡†ç¡®ç‡ï¼Œä½†åœ¨å®‰å…¨ä¸å¹»è§‰æ£€æµ‹çš„å…³é”®å·¥ä½œç‚¹å¯èƒ½æŸå®³å¬å›ç‡",
      "authors": [
        "Atoosa Chegini",
        "Hamid Kazemi",
        "Garrett Souza",
        "Maria Safi",
        "Yang Song",
        "Samy Bengio",
        "Sinead Williamson",
        "Mehrdad Farajtabar"
      ],
      "abstract": "Reasoning has become a central paradigm for large language models (LLMs), consistently boosting accuracy across diverse benchmarks. Yet its suitability for precision-sensitive tasks remains unclear. We present the first systematic study of reasoning for classification tasks under strict low false positive rate (FPR) regimes. Our analysis covers two tasks--safety detection and hallucination detection--evaluated in both fine-tuned and zero-shot settings, using standard LLMs and Large Reasoning Models (LRMs). Our results reveal a clear trade-off: Think On (reasoning-augmented) generation improves overall accuracy, but underperforms at the low-FPR thresholds essential for practical use. In contrast, Think Off (no reasoning during inference) dominates in these precision-sensitive regimes, with Think On surpassing only when higher FPRs are acceptable. In addition, we find token-based scoring substantially outperforms self-verbalized confidence for precision-sensitive deployments. Finally, a simple ensemble of the two modes recovers the strengths of each. Taken together, our findings position reasoning as a double-edged tool: beneficial for average accuracy, but often ill-suited for applications requiring strict precision.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large Language Models (LLMs) å’Œ Large Reasoning Models (LRMs) åœ¨å®‰å…¨æ£€æµ‹ä¸å¹»è§‰æ£€æµ‹è¿™ä¸¤ç±»å¯¹ç²¾åº¦æå…¶æ•æ„Ÿçš„ä»»åŠ¡ä¸­ï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†æ¨ç†ï¼ˆReasoningï¼‰å¯¹ä½ False Positive Rate (FPR) åœºæ™¯çš„å½±å“ã€‚å®éªŒå‘ç°ï¼Œè™½ç„¶å¼€å¯æ¨ç†æ¨¡å¼ï¼ˆThink Onï¼‰èƒ½æå‡æ•´ä½“å‡†ç¡®ç‡ï¼Œä½†åœ¨å®é™…åº”ç”¨æ‰€éœ€çš„ä¸¥æ ¼ä½ FPR é˜ˆå€¼ä¸‹ï¼Œå…¶è¡¨ç°åè€Œä¸å¦‚ä¸å¼€å¯æ¨ç†ï¼ˆThink Offï¼‰çš„æƒ…å†µï¼Œå¯¼è‡´å…³é”®æ“ä½œç‚¹çš„å¬å›ç‡ï¼ˆRecallï¼‰å—æŸã€‚æ­¤å¤–ï¼Œç ”ç©¶æŒ‡å‡ºåœ¨ç²¾åº¦æ•æ„Ÿå‹éƒ¨ç½²ä¸­ï¼ŒåŸºäº token çš„è¯„åˆ†æ–¹æ³•æ˜¾è‘—ä¼˜äºæ¨¡å‹è‡ªæˆ‘é™ˆè¿°çš„ç½®ä¿¡åº¦ã€‚æœ€ç»ˆï¼Œé€šè¿‡å°†æ¨ç†ä¸éæ¨ç†ä¸¤ç§æ¨¡å¼è¿›è¡Œç®€å•é›†æˆï¼ˆensembleï¼‰ï¼Œå¯ä»¥æœ‰æ•ˆç»“åˆä¸¤è€…çš„ä¼˜åŠ¿ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†æ¨ç†åœ¨æå‡å¹³å‡å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå¯¹äºéœ€è¦ä¸¥æ ¼ç²¾åº¦çš„åº”ç”¨è€Œè¨€å¯èƒ½æ˜¯ä¸€æŠŠâ€œåŒåˆƒå‰‘â€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21049v1",
      "published_date": "2025-10-23 23:23:36 UTC",
      "updated_date": "2025-10-23 23:23:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:06:42.773613+00:00"
    },
    {
      "arxiv_id": "2511.01885v2",
      "title": "Mirror-Neuron Patterns in AI Alignment",
      "title_zh": "AI å¯¹é½ä¸­çš„é•œåƒç¥ç»å…ƒæ¨¡å¼",
      "authors": [
        "Robyn Wyrick"
      ],
      "abstract": "As artificial intelligence (AI) advances toward superhuman capabilities, aligning these systems with human values becomes increasingly critical. Current alignment strategies rely largely on externally specified constraints that may prove insufficient against future super-intelligent AI capable of circumventing top-down controls.\n  This research investigates whether artificial neural networks (ANNs) can develop patterns analogous to biological mirror neurons cells that activate both when performing and observing actions, and how such patterns might contribute to intrinsic alignment in AI. Mirror neurons play a crucial role in empathy, imitation, and social cognition in humans. The study therefore asks: (1) Can simple ANNs develop mirror-neuron patterns? and (2) How might these patterns contribute to ethical and cooperative decision-making in AI systems?\n  Using a novel Frog and Toad game framework designed to promote cooperative behaviors, we identify conditions under which mirror-neuron patterns emerge, evaluate their influence on action circuits, introduce the Checkpoint Mirror Neuron Index (CMNI) to quantify activation strength and consistency, and propose a theoretical framework for further study.\n  Our findings indicate that appropriately scaled model capacities and self/other coupling foster shared neural representations in ANNs similar to biological mirror neurons. These empathy-like circuits support cooperative behavior and suggest that intrinsic motivations modeled through mirror-neuron dynamics could complement existing alignment techniques by embedding empathy-like mechanisms directly within AI architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)å¯¹é½ä¸­çš„é•œåƒç¥ç»å…ƒ(Mirror-Neuron)æ¨¡å¼ï¼Œæ—¨åœ¨é€šè¿‡å†…åœ¨å¯¹é½æœºåˆ¶è§£å†³è¶…äººç±»æ™ºèƒ½ç³»ç»Ÿä¸­å¤–éƒ¨çº¦æŸå¯èƒ½å¤±æ•ˆçš„é—®é¢˜ã€‚ç ”ç©¶é‡ç‚¹è°ƒæŸ¥äº†äººå·¥ç¥ç»ç½‘ç»œ(ANNs)èƒ½å¦äº§ç”Ÿç±»ä¼¼äºç”Ÿç‰©é•œåƒç¥ç»å…ƒçš„æ¿€æ´»æ¨¡å¼ï¼Œå³åœ¨æ‰§è¡ŒåŠ¨ä½œå’Œè§‚å¯ŸåŠ¨ä½œæ—¶åŒæ—¶æ¿€æ´»ï¼Œå¹¶åˆ†æå…¶åœ¨é“å¾·å’Œåˆä½œå†³ç­–ä¸­çš„ä½œç”¨ã€‚é€šè¿‡è®¾è®¡ä¸€ç§åä¸ºâ€œé’è›™ä¸èŸ¾èœâ€(Frog and Toad)çš„æ¸¸æˆæ¡†æ¶æ¥ä¿ƒè¿›åˆä½œè¡Œä¸ºï¼Œç ”ç©¶å›¢é˜Ÿç¡®å®šäº†é•œåƒç¥ç»å…ƒæ¨¡å¼å‡ºç°çš„æ¡ä»¶ï¼Œå¹¶æå‡ºäº†Checkpoint Mirror Neuron Index (CMNI)æ¥é‡åŒ–å…¶æ¿€æ´»å¼ºåº¦å’Œä¸€è‡´æ€§ã€‚å®éªŒå‘ç°ï¼Œé€‚å½“çš„æ¨¡å‹å®¹é‡å’Œè‡ªæˆ‘/ä»–äººè€¦åˆ(self/other coupling)èƒ½å¤Ÿä¿ƒä½¿ANNså½¢æˆå…±äº«çš„ç¥ç»è¡¨å¾ï¼Œå…¶è¡¨ç°å‡ºä¸ç”Ÿç‰©é•œåƒç¥ç»å…ƒé«˜åº¦ç›¸ä¼¼çš„ç‰¹æ€§ã€‚è¿™äº›ç±»å…±æƒ…(empathy-like)ç”µè·¯æœ‰æ•ˆæ”¯æŒäº†ç³»ç»Ÿçš„åˆä½œè¡Œä¸ºï¼Œè¡¨æ˜é€šè¿‡é•œåƒç¥ç»å…ƒåŠ¨åŠ›å­¦æ„å»ºçš„å†…åœ¨åŠ¨æœºå¯ä»¥ä½œä¸ºç°æœ‰å¯¹é½æŠ€æœ¯çš„è¡¥å……ï¼Œç›´æ¥åœ¨AIæ¶æ„ä¸­åµŒå…¥å…±æƒ…æœºåˆ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "51 pages, Masters thesis. 10 tables, 7 figures, project data & code here: https://github.com/robynwyrick/mirror-neuron-frog-and-toad",
      "pdf_url": "https://arxiv.org/pdf/2511.01885v2",
      "published_date": "2025-10-23 23:08:29 UTC",
      "updated_date": "2025-11-05 03:04:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:06:44.569059+00:00"
    },
    {
      "arxiv_id": "2510.21045v2",
      "title": "From Questions to Queries: An AI-powered Multi-Agent Framework for Spatial Text-to-SQL",
      "title_zh": "ä»é—®é¢˜åˆ°æŸ¥è¯¢ï¼šé¢å‘ç©ºé—´ Text-to-SQL çš„äººå·¥æ™ºèƒ½é©±åŠ¨å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Ali Khosravi Kazazi",
        "Zhenlong Li",
        "M. Naser Lessani",
        "Guido Cervone"
      ],
      "abstract": "The complexity of Structured Query Language (SQL) and the specialized nature of geospatial functions in tools like PostGIS present significant barriers to non-experts seeking to analyze spatial data. While Large Language Models (LLMs) offer promise for translating natural language into SQL (Text-to-SQL), single-agent approaches often struggle with the semantic and syntactic complexities of spatial queries. To address this, we propose a multi-agent framework designed to accurately translate natural language questions into spatial SQL queries. The framework integrates several innovative components, including a knowledge base with programmatic schema profiling and semantic enrichment, embeddings for context retrieval, and a collaborative multi-agent pipeline as its core. This pipeline comprises specialized agents for entity extraction, metadata retrieval, query logic formulation, SQL generation, and a review agent that performs programmatic and semantic validation of the generated SQL to ensure correctness (self-verification). We evaluate our system using both the non-spatial KaggleDBQA benchmark and a new, comprehensive SpatialQueryQA benchmark that includes diverse geometry types, predicates, and three levels of query complexity. On KaggleDBQA, the system achieved an overall accuracy of 81.2% (221 out of 272 questions) after the review agent's review and corrections. For spatial queries, the system achieved an overall accuracy of 87.7% (79 out of 90 questions), compared with 76.7% without the review agent. Beyond accuracy, results also show that in some instances the system generates queries that are more semantically aligned with user intent than those in the benchmarks. This work makes spatial analysis more accessible, and provides a robust, generalizable foundation for spatial Text-to-SQL systems, advancing the development of autonomous GIS.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éä¸“å®¶åœ¨åˆ©ç”¨PostGISç­‰å·¥å…·å¤„ç†å¤æ‚åœ°ç†ç©ºé—´æ•°æ®æ—¶çš„æŠ€æœ¯é—¨æ§›ï¼Œæå‡ºäº†ä¸€ä¸ªAIé©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨å°†è‡ªç„¶è¯­è¨€é—®é¢˜ç²¾ç¡®è½¬åŒ–ä¸ºç©ºé—´SQLï¼ˆSpatial Text-to-SQLï¼‰æŸ¥è¯¢ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªåä½œå¼çš„å¤šæ™ºèƒ½ä½“æµæ°´çº¿ï¼Œé›†æˆäº†çŸ¥è¯†åº“ç¨‹åºåŒ–æ¨¡å¼åˆ†æã€è¯­ä¹‰å¢å¼ºã€ä¸Šä¸‹æ–‡æ£€ç´¢ä»¥åŠè´Ÿè´£å®ä½“æå–ã€é€»è¾‘è¡¨è¿°å’ŒSQLç”Ÿæˆçš„ä¸“ç”¨æ™ºèƒ½ä½“ï¼Œå¹¶ç‰¹åˆ«å¼•å…¥äº†æ‰§è¡Œè‡ªæˆ‘éªŒè¯çš„å®¡æŸ¥æ™ºèƒ½ä½“ï¼ˆReview Agentï¼‰ä»¥ç¡®ä¿ç”ŸæˆSQLçš„æ­£ç¡®æ€§ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨éç©ºé—´åŸºå‡†KaggleDBQAä¸Šå®ç°äº†81.2%çš„å‡†ç¡®ç‡ï¼Œè€Œåœ¨åŒ…å«å¤šæ ·å‡ ä½•ç±»å‹å’Œä¸‰çº§å¤æ‚åº¦çš„SpatialQueryQAç©ºé—´æŸ¥è¯¢åŸºå‡†ä¸Šï¼Œå‡†ç¡®ç‡æå‡è‡³87.7%ã€‚ç›¸æ¯”å•ä¸€æ™ºèƒ½ä½“æˆ–æ— å®¡æŸ¥æœºåˆ¶çš„æ–¹æ³•ï¼Œè¯¥æ¡†æ¶åœ¨æ•æ‰ç”¨æˆ·æ„å›¾æ–¹é¢è¡¨ç°æ›´ä½³ã€‚è¿™é¡¹å·¥ä½œä¸ä»…æ˜¾è‘—é™ä½äº†ç©ºé—´åˆ†æçš„å‡†å…¥é—¨æ§›ï¼Œè¿˜ä¸ºè‡ªä¸»åœ°ç†ä¿¡æ¯ç³»ç»Ÿï¼ˆAutonomous GISï¼‰çš„å¼€å‘å¥ å®šäº†ç¨³å¥ä¸”é€šç”¨çš„æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21045v2",
      "published_date": "2025-10-23 22:58:17 UTC",
      "updated_date": "2025-11-11 23:48:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:06:59.414389+00:00"
    },
    {
      "arxiv_id": "2510.21043v1",
      "title": "Epistemic Deference to AI",
      "title_zh": "å¯¹äººå·¥æ™ºèƒ½çš„è®¤çŸ¥é¡ºä»",
      "authors": [
        "Benjamin Lange"
      ],
      "abstract": "When should we defer to AI outputs over human expert judgment? Drawing on recent work in social epistemology, I motivate the idea that some AI systems qualify as Artificial Epistemic Authorities (AEAs) due to their demonstrated reliability and epistemic superiority. I then introduce AI Preemptionism, the view that AEA outputs should replace rather than supplement a user's independent epistemic reasons. I show that classic objections to preemptionism - such as uncritical deference, epistemic entrenchment, and unhinging epistemic bases - apply in amplified form to AEAs, given their opacity, self-reinforcing authority, and lack of epistemic failure markers. Against this, I develop a more promising alternative: a total evidence view of AI deference. According to this view, AEA outputs should function as contributory reasons rather than outright replacements for a user's independent epistemic considerations. This approach has three key advantages: (i) it mitigates expertise atrophy by keeping human users engaged, (ii) it provides an epistemic case for meaningful human oversight and control, and (iii) it explains the justified mistrust of AI when reliability conditions are unmet. While demanding in practice, this account offers a principled way to determine when AI deference is justified, particularly in high-stakes contexts requiring rigorous reliability.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººç±»åœ¨ä½•æ—¶åº”ä¼˜å…ˆè€ƒè™‘ AI è¾“å‡ºè€Œéä¸“å®¶åˆ¤æ–­ï¼Œå¹¶åŸºäºç¤¾ä¼šè®¤è¯†è®º(social epistemology)æå‡ºäº†äººå·¥æ™ºèƒ½è®¤è¯†æƒå¨(Artificial Epistemic Authorities, AEAs)çš„æ¦‚å¿µã€‚æ–‡ç« æ·±å…¥åˆ†æäº†äººå·¥æ™ºèƒ½ä¼˜å…ˆä¸»ä¹‰(AI Preemptionism)çš„è§‚ç‚¹ï¼Œå³ AEAs çš„è¾“å‡ºåº”å–ä»£è€Œéè¡¥å……ç”¨æˆ·çš„ç‹¬ç«‹è®¤è¯†ç†ç”±ï¼Œå¹¶æŒ‡å‡ºè¯¥è§‚ç‚¹åœ¨ç®—æ³•ä¸é€æ˜æ€§å’Œç¼ºä¹è®¤è¯†å¤±è´¥æ ‡è®°ç­‰æ–¹é¢å­˜åœ¨ä¸¥é‡çš„é£é™©ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº†ä¸€ç§æ›´å…·å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå³äººå·¥æ™ºèƒ½é¡ºä»çš„æ•´ä½“è¯æ®è§‚(total evidence view of AI deference)ã€‚æ ¹æ®è¿™ä¸€è§‚ç‚¹ï¼ŒAEAs çš„è¾“å‡ºåº”å½“ä½œä¸ºè´¡çŒ®æ€§ç†ç”±(contributory reasons)ï¼Œè€Œéç›´æ¥æ›¿æ¢ç”¨æˆ·çš„ç‹¬ç«‹è®¤è¯†è€ƒé‡ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿé€šè¿‡ä¿æŒç”¨æˆ·çš„è®¤çŸ¥å‚ä¸æ¥å‡ç¼“ä¸“ä¸šèƒ½åŠ›èç¼©(expertise atrophy)ï¼Œå¹¶ä¸ºå®ç°å®è´¨æ€§çš„äººç±»ç›‘ç£ä¸æ§åˆ¶(meaningful human oversight and control)æä¾›äº†ç†è®ºæ”¯æ’‘ã€‚æœ€åï¼Œè¯¥æ¡†æ¶è§£é‡Šäº†åœ¨å¯é æ€§æœªè¾¾æ ‡æ—¶å¯¹ AI äº§ç”Ÿåˆç†ä¸ä¿¡ä»»çš„åŸå› ï¼Œä¸ºé«˜é£é™©ç¯å¢ƒä¸‹åˆ¤å®š AI é¡ºä»çš„æ­£å½“æ€§æä¾›äº†ç³»ç»Ÿæ€§çš„æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.21043v1",
      "published_date": "2025-10-23 22:55:51 UTC",
      "updated_date": "2025-10-23 22:55:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:06:52.376807+00:00"
    },
    {
      "arxiv_id": "2511.01884v2",
      "title": "CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel Optimization",
      "title_zh": "CudaForgeï¼šåŸºäºç¡¬ä»¶åé¦ˆçš„ CUDA æ ¸å‡½æ•°ä¼˜åŒ–æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Zijian Zhang",
        "Rong Wang",
        "Shiyang Li",
        "Yuebo Luo",
        "Mingyi Hong",
        "Caiwen Ding"
      ],
      "abstract": "Developing efficient CUDA kernels is increasingly critical for AI applications such as large-scale LLM training. However, manual kernel design is both costly and time-consuming, motivating automatic approaches that leverage LLMs for code generation. Existing methods for automatic kernel generation, however, often produce low-efficiency kernels, incur high computational overhead, and fail to generalize across settings. In this work, we propose CudaForge, a training-free multi-agent workflow for CUDA kernel generation and optimization. Our workflow is inspired by the iterative workflow of human experts, which contains steps such as developing initial kernels, testing correctness, analyzing hardware feedback, and iterative improvement. More specifically, CudaForge employs two LLM agents: a Coder and a Judge, that iteratively generate, correct, and optimize CUDA kernels, while integrating hardware feedback such as Nsight Compute (NCU) metrics. In extensive evaluations, we show that CudaForge, by leveraging base models like OpenAI-o3, achieves 97.6\\% correctness of generated kernels and an average 1.68$\\times$ speedup over PyTorch baselines, substantially surpassing state-of-the-art models including OpenAI-o3 and Kevin on KernelBench.Beyond accuracy and speed, CudaForge demonstrates strong generalization across GPUs (A100, RTX 6000, 4090, 3090) and base models (OpenAI-o3, GPT-5, gpt-oss-120B, Claude-Sonnet-4, QwQ-32B), while maintaining high efficiency. In particular, generating an optimized kernel takes about 26.5 minutes on one RTX6000 and incurs about \\$ 0.3 API cost, which is significantly cheaper than existing agentic work that costs 6 H100 hours and \\$ 5 API cost per kernel. Our results highlight that multi-agent, training-free workflows can enable cost-effective, generalizable, and high-performance CUDA kernel optimization. Code available at https://github.com/OptimAI-Lab/CudaForge",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CudaForgeï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰ç¡¬ä»¶åé¦ˆçš„å…è®­ç»ƒå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ– CUDA Kernel çš„ç”Ÿæˆä¸ä¼˜åŒ–ã€‚é’ˆå¯¹ç°æœ‰è‡ªåŠ¨ç”Ÿæˆæ–¹æ³•æ•ˆç‡ä½ä¸‹ä¸”å¼€é”€å¤§çš„é—®é¢˜ï¼ŒCudaForge æ¨¡ä»¿äººç±»ä¸“å®¶çš„è¿­ä»£å·¥ä½œæµï¼Œé€šè¿‡ Coder å’Œ Judge ä¸¤ä¸ªæ™ºèƒ½ä½“åä½œè¿›è¡Œä»£ç ç”Ÿæˆã€æµ‹è¯•ä¸ä¿®æ­£ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°æ•´åˆäº† Nsight Compute (NCU) æŒ‡æ ‡ç­‰å®æ—¶ç¡¬ä»¶åé¦ˆï¼Œä»¥æŒ‡å¯¼å†…æ ¸çš„è¿­ä»£æ”¹è¿›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ KernelBench åŸºå‡†æµ‹è¯•ä¸­ï¼ŒCudaForge å®ç°äº† 97.6% çš„ç”Ÿæˆæ­£ç¡®ç‡ï¼Œå¹¶ç›¸æ¯” PyTorch åŸºå‡†å®ç°äº† 1.68 å€çš„å¹³å‡åŠ é€Ÿï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äº OpenAI-o3 å’Œ Kevin ç­‰ç°æœ‰æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒCudaForge åœ¨ A100 å’Œ RTX 6000 ç­‰å¤šç§ GPU ç¡¬ä»¶ä»¥åŠä¸åŒåŸºç¡€æ¨¡å‹ä¸Šå‡è¡¨ç°å‡ºæå¼ºçš„æ³›åŒ–æ€§ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¯¥æ–¹æ³•å…·æœ‰æé«˜çš„æˆæœ¬æ•ˆç›Šï¼Œå•ä¸ªå†…æ ¸çš„ API æˆæœ¬ä»…çº¦ 0.3 ç¾å…ƒï¼Œè¿œä½äºç°æœ‰çš„ Agent ç±»æ–¹æ¡ˆã€‚è¿™ä¸€ç ”ç©¶è¯æ˜äº†å¤šæ™ºèƒ½ä½“åä½œæ¨¡å¼åœ¨å®ç°é«˜æ€§èƒ½ã€æ™®é€‚ä¸”ä½æˆæœ¬çš„å¹¶è¡Œè®¡ç®—ä¼˜åŒ–æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.01884v2",
      "published_date": "2025-10-23 22:52:00 UTC",
      "updated_date": "2025-11-05 02:10:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:06:55.875348+00:00"
    },
    {
      "arxiv_id": "2510.21031v1",
      "title": "AgentArcEval: An Architecture Evaluation Method for Foundation Model based Agents",
      "title_zh": "AgentArcEvalï¼šä¸€ç§åŸºäºåŸºç¡€æ¨¡å‹çš„æ™ºèƒ½ä½“æ¶æ„è¯„ä¼°æ–¹æ³•",
      "authors": [
        "Qinghua Lu",
        "Dehai Zhao",
        "Yue Liu",
        "Hao Zhang",
        "Liming Zhu",
        "Xiwei Xu",
        "Angela Shi",
        "Tristan Tan",
        "Rick Kazman"
      ],
      "abstract": "The emergence of foundation models (FMs) has enabled the development of highly capable and autonomous agents, unlocking new application opportunities across a wide range of domains. Evaluating the architecture of agents is particularly important as the architectural decisions significantly impact the quality attributes of agents given their unique characteristics, including compound architecture, autonomous and non-deterministic behaviour, and continuous evolution. However, these traditional methods fall short in addressing the evaluation needs of agent architecture due to the unique characteristics of these agents. Therefore, in this paper, we present AgentArcEval, a novel agent architecture evaluation method designed specially to address the complexities of FM-based agent architecture and its evaluation. Moreover, we present a catalogue of agent-specific general scenarios, which serves as a guide for generating concrete scenarios to design and evaluate the agent architecture. We demonstrate the usefulness of AgentArcEval and the catalogue through a case study on the architecture evaluation of a real-world tax copilot, named Luna.",
      "tldr_zh": "éšç€åŸºåº§æ¨¡å‹(Foundation Models)çš„å…´èµ·ï¼Œè‡ªä¸»æ™ºèƒ½ä½“åœ¨å¤šé¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†å…¶å¤åˆæ¶æ„ä¸éç¡®å®šæ€§è¡Œä¸º(Non-deterministic Behaviour)ä½¿å¾—ä¼ ç»Ÿæ¶æ„è¯„ä¼°æ–¹æ³•éš¾ä»¥é€‚ç”¨ã€‚è¯¥ç ”ç©¶æå‡ºäº† AgentArcEvalï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºåŸºåº§æ¨¡å‹é©±åŠ¨çš„æ™ºèƒ½ä½“é‡èº«å®šåˆ¶çš„æ¶æ„è¯„ä¼°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å…¶æ¶æ„è®¾è®¡çš„å¤æ‚æ€§æŒ‘æˆ˜ã€‚ç ”ç©¶åŒæ—¶æä¾›äº†ä¸€ç³»åˆ—æ™ºèƒ½ä½“ç‰¹æœ‰çš„é€šç”¨åœºæ™¯ç›®å½•(Catalogue of Agent-Specific General Scenarios)ï¼Œä½œä¸ºç”Ÿæˆå…·ä½“è¯„ä¼°åœºæ™¯å¹¶æŒ‡å¯¼æ¶æ„è®¾è®¡çš„æŒ‡å—ã€‚é€šè¿‡å¯¹åä¸º Luna çš„çœŸå®ç¨åŠ¡åŠ©æ‰‹(Tax Copilot)è¿›è¡Œæ¡ˆä¾‹ç ”ç©¶ï¼ŒéªŒè¯äº† AgentArcEval åŠå…¶åœºæ™¯ç›®å½•çš„å®ç”¨æ€§ã€‚è¯¥æ–¹æ³•ä¸ºç³»ç»ŸåŒ–è¯„ä¼°æ™ºèƒ½ä½“æ¶æ„çš„è´¨é‡å±æ€§æä¾›äº†æœ‰æ•ˆå·¥å…·ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°æ–¹æ³•åœ¨å¤„ç†é«˜åº¦è‡ªä¸»å’ŒåŠ¨æ€æ¼”åŒ–ç³»ç»Ÿæ–¹é¢çš„ç©ºç™½ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21031v1",
      "published_date": "2025-10-23 22:32:03 UTC",
      "updated_date": "2025-10-23 22:32:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:06:57.774615+00:00"
    },
    {
      "arxiv_id": "2510.21027v1",
      "title": "Customizing Open Source LLMs for Quantitative Medication Attribute Extraction across Heterogeneous EHR Systems",
      "title_zh": "é¢å‘å¼‚æ„ç”µå­å¥åº·æ¡£æ¡ˆç³»ç»Ÿçš„å¼€æºå¤§è¯­è¨€æ¨¡å‹å®šåˆ¶åŒ–å®šé‡è¯ç‰©å±æ€§æå–",
      "authors": [
        "Zhe Fei",
        "Mehmet Yigit Turali",
        "Shreyas Rajesh",
        "Xinyang Dai",
        "Huyen Pham",
        "Pavan Holur",
        "Yuhui Zhu",
        "Larissa Mooney",
        "Yih-Ing Hser",
        "Vwani Roychowdhury"
      ],
      "abstract": "Harmonizing medication data across Electronic Health Record (EHR) systems is a persistent barrier to monitoring medications for opioid use disorder (MOUD). In heterogeneous EHR systems, key prescription attributes are scattered across differently formatted fields and freetext notes. We present a practical framework that customizes open source large language models (LLMs), including Llama, Qwen, Gemma, and MedGemma, to extract a unified set of MOUD prescription attributes (prescription date, drug name, duration, total quantity, daily quantity, and refills) from heterogeneous, site specific data and compute a standardized metric of medication coverage, \\emph{MOUD days}, per patient. Our pipeline processes records directly in a fixed JSON schema, followed by lightweight normalization and cross-field consistency checks. We evaluate the system on prescription level EHR data from five clinics in a national OUD study (25{,}605 records from 1{,}257 patients), using a previously annotated benchmark of 10{,}369 records (776 patients) as the ground truth. Performance is reported as coverage (share of records with a valid, matchable output) and record-level exact-match accuracy. Larger models perform best overall: Qwen2.5-32B achieves \\textbf{93.4\\%} coverage with \\textbf{93.0\\%} exact-match accuracy across clinics, and MedGemma-27B attains \\textbf{93.1\\%}/\\textbf{92.2\\%}. A brief error review highlights three common issues and fixes: imputing missing dosage fields using within-drug norms, handling monthly/weekly injectables (e.g., Vivitrol) by setting duration from the documented schedule, and adding unit checks to prevent mass units (e.g., ``250 g'') from being misread as daily counts. By removing brittle, site-specific ETL and supporting local, privacy-preserving deployment, this approach enables consistent cross-site analyses of MOUD exposure, adherence, and retention in real-world settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå®šåˆ¶åŒ–å¼€æºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å®ç”¨æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¼‚æ„ç”µå­å¥åº·è®°å½•(EHR)ç³»ç»Ÿä¸­é˜¿ç‰‡ç±»è¯ç‰©ä½¿ç”¨éšœç¢(MOUD)å¤„æ–¹æ•°æ®éš¾ä»¥ç»Ÿä¸€æå–çš„é—®é¢˜ã€‚ç ”ç©¶é€šè¿‡å¾®è°ƒ Llamaã€Qwenã€Gemma å’Œ MedGemma ç­‰æ¨¡å‹ï¼Œä»æ ¼å¼å¤šæ ·çš„å­—æ®µå’Œè‡ªç”±æ–‡æœ¬æ³¨é‡Šä¸­æå–ç»Ÿä¸€çš„å¤„æ–¹å±æ€§ï¼Œå¹¶æ®æ­¤è®¡ç®—æ ‡å‡†åŒ–çš„ç”¨è¯è¦†ç›–ç‡æŒ‡æ ‡ MOUD daysã€‚è¯¥å¤„ç†æµç¨‹é€šè¿‡å›ºå®šçš„ JSON schema å®ç°ç»“æ„åŒ–è¾“å‡ºï¼Œå¹¶ç»“åˆè½»é‡åŒ–å½’ä¸€åŒ–ä¸è·¨å­—æ®µä¸€è‡´æ€§æ£€æŸ¥æ¥ç¡®ä¿æ•°æ®å‡†ç¡®æ€§ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒQwen2.5-32B æ¨¡å‹åœ¨å¤šä¸­å¿ƒæ•°æ®ä¸Šå®ç°äº† 93.4% çš„è¦†ç›–ç‡å’Œ 93.0% çš„ç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡ï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ–¹æ³•ä¸ä»…æ¶ˆé™¤äº†è„†å¼±çš„ç«™ç‚¹ç‰¹å®š ETL æµç¨‹ï¼Œè¿˜æ”¯æŒæœ¬åœ°åŒ–ã€éšç§ä¿æŠ¤çš„éƒ¨ç½²æ–¹å¼ï¼Œä¸ºçœŸå®ä¸–ç•Œç¯å¢ƒä¸‹ MOUD æ²»ç–—çš„ä¾ä»æ€§ä¸ç•™å­˜ç‡ç ”ç©¶æä¾›äº†å¯é çš„æŠ€æœ¯æ‰‹æ®µã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2025: The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance",
      "pdf_url": "https://arxiv.org/pdf/2510.21027v1",
      "published_date": "2025-10-23 22:27:10 UTC",
      "updated_date": "2025-10-23 22:27:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:07.487824+00:00"
    },
    {
      "arxiv_id": "2510.23627v1",
      "title": "AI-Driven Development of a Publishing Imprint: Xynapse Traces",
      "title_zh": "AI é©±åŠ¨çš„å‡ºç‰ˆå“ç‰Œå¼€å‘ï¼šXynapse Traces",
      "authors": [
        "Fred Zimmerman"
      ],
      "abstract": "Xynapse Traces is an experimental publishing imprint created via a fusion of human and algorithmic methods using a configuration-driven architecture and a multi-model AI integration framework. The system achieved a remarkable 90% reduction in time-to-market (from a typical 6-12 months to just 2-4 weeks), with 80% cost reduction compared to traditional imprint development, while publishing 52 books in its first year and maintaining exceptional quality metrics, including 99% citation accuracy and 100% validation success after initial corrections. Key technical innovations include a continuous ideation pipeline with tournament-style evaluation, a novel codex design for transcriptive meditation practice, comprehensive automation spanning from ideation through production and distribution, and publisher personas that define and guide the imprint's mission. The system also integrates automated verification with human oversight, ensuring that gains in speed do not compromise publishing standards. This effort has significant implications for the future of book publishing, suggesting new paradigms for human-AI collaboration that democratize access to sophisticated publishing capabilities and make previously unviable niche markets accessible.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Xynapse Tracesçš„å¼€å‘ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡äººç±»ä¸ç®—æ³•èåˆã€é‡‡ç”¨é…ç½®é©±åŠ¨æ¶æ„(configuration-driven architecture)å’Œå¤šæ¨¡å‹AIé›†æˆæ¡†æ¶(multi-model AI integration framework)åˆ›å»ºçš„å®éªŒæ€§å‡ºç‰ˆå“ç‰Œã€‚è¯¥ç³»ç»Ÿå®ç°äº†ä¸Šå¸‚æ—¶é—´ç¼©çŸ­90%ä»¥åŠå‡ºç‰ˆæˆæœ¬é™ä½80%çš„æ˜¾è‘—æˆæ•ˆï¼Œå¹¶åœ¨ç¬¬ä¸€å¹´å†…æˆåŠŸå‡ºç‰ˆäº†52æœ¬ä¹¦ï¼ŒåŒæ—¶ä¿æŒäº†99%çš„å¼•ç”¨å‡†ç¡®ç‡(citation accuracy)å’Œæé«˜çš„éªŒè¯æˆåŠŸç‡ã€‚å…¶æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°åŒ…æ‹¬é‡‡ç”¨æ·˜æ±°èµ›å¼è¯„ä¼°çš„æŒç»­æ„æ€æµæ°´çº¿(continuous ideation pipeline)ã€ç”¨äºè½¬å½•å†¥æƒ³ç»ƒä¹ çš„æ–°é¢–æ‰‹æŠ„æœ¬è®¾è®¡(codex design)ä»¥åŠæ¶µç›–ä»æ„æ€åˆ°ç”Ÿäº§åˆ†å‘çš„å…¨é¢è‡ªåŠ¨åŒ–æµç¨‹ã€‚é€šè¿‡å¼•å…¥å‡ºç‰ˆå•†ç”»åƒ(publisher personas)å¼•å¯¼å“ç‰Œä½¿å‘½å¹¶ç»“åˆäººå·¥ç›‘ç£ï¼Œç³»ç»Ÿåœ¨æé€Ÿæå‡æ•ˆç‡çš„åŒæ—¶ç¡®ä¿äº†å‡ºç‰ˆæ ‡å‡†çš„ä¸¥è°¨æ€§ã€‚è¿™ä¸€ç ”ç©¶ä¸ºæœªæ¥å›¾ä¹¦å‡ºç‰ˆæå‡ºäº†äººæœºåä½œ(human-AI collaboration)çš„æ–°èŒƒå¼ï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡æŠ€æœ¯æ‰‹æ®µæ°‘ä¸»åŒ–å‡ºç‰ˆèƒ½åŠ›ï¼Œå¹¶ä½¿æ­¤å‰éš¾ä»¥ç›ˆåˆ©çš„åˆ©åŸºå¸‚åœº(niche markets)å¼€å‘å˜å¾—åˆ‡å®å¯è¡Œã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.23627v1",
      "published_date": "2025-10-23 22:25:13 UTC",
      "updated_date": "2025-10-23 22:25:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:04.593323+00:00"
    },
    {
      "arxiv_id": "2510.21024v1",
      "title": "JSTprove: Pioneering Verifiable AI for a Trustless Future",
      "title_zh": "JSTproveï¼šå¼€åˆ›å»ä¿¡ä»»æœªæ¥çš„å¯éªŒè¯äººå·¥æ™ºèƒ½",
      "authors": [
        "Jonathan Gold",
        "Tristan Freiberg",
        "Haruna Isah",
        "Shirin Shahabi"
      ],
      "abstract": "The integration of machine learning (ML) systems into critical industries such as healthcare, finance, and cybersecurity has transformed decision-making processes, but it also brings new challenges around trust, security, and accountability. As AI systems become more ubiquitous, ensuring the transparency and correctness of AI-driven decisions is crucial, especially when they have direct consequences on privacy, security, or fairness. Verifiable AI, powered by Zero-Knowledge Machine Learning (zkML), offers a robust solution to these challenges. zkML enables the verification of AI model inferences without exposing sensitive data, providing an essential layer of trust and privacy. However, traditional zkML systems typically require deep cryptographic expertise, placing them beyond the reach of most ML engineers. In this paper, we introduce JSTprove, a specialized zkML toolkit, built on Polyhedra Network's Expander backend, to enable AI developers and ML engineers to generate and verify proofs of AI inference. JSTprove provides an end-to-end verifiable AI inference pipeline that hides cryptographic complexity behind a simple command-line interface while exposing auditable artifacts for reproducibility. We present the design, innovations, and real-world use cases of JSTprove as well as our blueprints and tooling to encourage community review and extension. JSTprove therefore serves both as a usable zkML product for current engineering needs and as a reproducible foundation for future research and production deployments of verifiable AI.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—ã€é‡‘èå’Œç½‘ç»œå®‰å…¨ç­‰å…³é”®è¡Œä¸šä¸­æœºå™¨å­¦ä¹ (ML)ç³»ç»Ÿé¢ä¸´çš„ä¿¡ä»»ã€å®‰å…¨å’Œé—®è´£æŒ‘æˆ˜ï¼Œæå‡ºäº†Verifiable AIçš„è§£å†³æ–¹æ¡ˆã€‚å°½ç®¡é›¶çŸ¥è¯†æœºå™¨å­¦ä¹ (zkML)èƒ½åœ¨ä¸æ³„éœ²æ•æ„Ÿæ•°æ®çš„æƒ…å†µä¸‹éªŒè¯æ¨¡å‹æ¨ç†è¿‡ç¨‹ï¼Œä½†å…¶æé«˜çš„å¯†ç å­¦ä¸“ä¸šé—¨æ§›é™åˆ¶äº†æ™®é€šå·¥ç¨‹å¸ˆçš„åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æ¨å‡ºäº†JSTproveï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºPolyhedra Networkçš„Expanderåç«¯æ„å»ºçš„ä¸“ä¸šzkMLå·¥å…·åŒ…ï¼Œæ—¨åœ¨è®©AIå¼€å‘è€…èƒ½è½»æ¾ç”Ÿæˆå¹¶éªŒè¯æ¨ç†è¯æ˜ã€‚è¯¥å·¥å…·åŒ…æä¾›ç«¯åˆ°ç«¯çš„Verifiable AIæ¨ç†æµæ°´çº¿ï¼Œé€šè¿‡ç®€æ´çš„å‘½ä»¤è¡Œç•Œé¢(CLI)éšè—äº†å¤æ‚çš„å¯†ç å­¦ç»†èŠ‚ï¼Œå¹¶è¾“å‡ºå¯å®¡è®¡çš„å·¥ä»¶ä»¥ç¡®ä¿å®éªŒçš„å¯å¤ç°æ€§ã€‚é€šè¿‡å±•ç¤ºè®¾è®¡åˆ›æ–°ä¸å®é™…åº”ç”¨æ¡ˆä¾‹ï¼ŒJSTproveä¸ä»…æ»¡è¶³äº†å½“å‰çš„å·¥ç¨‹éœ€æ±‚ï¼Œä¹Ÿä¸ºæœªæ¥å¯ä¿¡äººå·¥æ™ºèƒ½çš„ç ”ç©¶ä¸ç”Ÿäº§éƒ¨ç½²å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 8 figures, and 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.21024v1",
      "published_date": "2025-10-23 22:22:38 UTC",
      "updated_date": "2025-10-23 22:22:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:11.297902+00:00"
    },
    {
      "arxiv_id": "2510.21023v1",
      "title": "Physically consistent and uncertainty-aware learning of spatiotemporal dynamics",
      "title_zh": "ç‰©ç†ä¸€è‡´ä¸ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„æ—¶ç©ºåŠ¨åŠ›å­¦å­¦ä¹ ",
      "authors": [
        "Qingsong Xu",
        "Jonathan L Bamber",
        "Nils Thuerey",
        "Niklas Boers",
        "Paul Bates",
        "Gustau Camps-Valls",
        "Yilei Shi",
        "Xiao Xiang Zhu"
      ],
      "abstract": "Accurate long-term forecasting of spatiotemporal dynamics remains a fundamental challenge across scientific and engineering domains. Existing machine learning methods often neglect governing physical laws and fail to quantify inherent uncertainties in spatiotemporal predictions. To address these challenges, we introduce a physics-consistent neural operator (PCNO) that enforces physical constraints by projecting surrogate model outputs onto function spaces satisfying predefined laws. A physics-consistent projection layer within PCNO efficiently computes mass and momentum conservation in Fourier space. Building upon deterministic predictions, we further propose a diffusion model-enhanced PCNO (DiffPCNO), which leverages a consistency model to quantify and mitigate uncertainties, thereby improving the accuracy and reliability of forecasts. PCNO and DiffPCNO achieve high-fidelity spatiotemporal predictions while preserving physical consistency and uncertainty across diverse systems and spatial resolutions, ranging from turbulent flow modeling to real-world flood/atmospheric forecasting. Our two-stage framework provides a robust and versatile approach for accurate, physically grounded, and uncertainty-aware spatiotemporal forecasting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶ç©ºåŠ¨åŠ›å­¦(spatiotemporal dynamics)é•¿æœŸé¢„æµ‹ä¸­å­˜åœ¨çš„ç‰©ç†è§„å¾‹ç¼ºå¤±å’Œä¸ç¡®å®šæ€§é‡åŒ–(uncertainty quantification)éš¾é¢˜ï¼Œæå‡ºäº†ç‰©ç†ä¸€è‡´æ€§ç®—å­ç½‘ç»œ(physics-consistent neural operator, PCNO)ã€‚PCNOé€šè¿‡åœ¨å‚…é‡Œå¶ç©ºé—´(Fourier space)ä¸­è®¾è®¡ç‰©ç†ä¸€è‡´æ€§æŠ•å½±å±‚ï¼Œç¡®ä¿ä»£ç†æ¨¡å‹çš„è¾“å‡ºä¸¥æ ¼æ»¡è¶³è´¨é‡å’ŒåŠ¨é‡å®ˆæ’ç­‰é¢„å®šä¹‰çš„ç‰©ç†å®šå¾‹ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†æ‰©æ•£æ¨¡å‹å¢å¼ºçš„PCNO(DiffPCNO)ï¼Œåˆ©ç”¨ä¸€è‡´æ€§æ¨¡å‹(consistency model)æ¥é‡åŒ–å¹¶å‡è½»é¢„æµ‹ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œä»è€Œæ˜¾è‘—æå‡é¢„æµ‹çš„å¯é æ€§ã€‚è¯¥æ¡†æ¶åœ¨ä»æ¹æµæ¨¡æ‹Ÿ(turbulent flow modeling)åˆ°ç°å®ä¸–ç•Œæ´ªæ°´åŠå¤§æ°”é¢„æµ‹(flood/atmospheric forecasting)çš„å¤šç§å¤æ‚ç³»ç»Ÿå’Œç©ºé—´åˆ†è¾¨ç‡ä¸‹ï¼Œå‡å®ç°äº†é«˜ä¿çœŸåº¦ä¸”ç¬¦åˆç‰©ç†è§„å¾‹çš„é¢„æµ‹ã€‚è¿™ç§ä¸¤é˜¶æ®µæ¡†æ¶ä¸ºå‡†ç¡®ã€åŸºäºç‰©ç†ä¸”å…·å¤‡ä¸ç¡®å®šæ€§æ„ŸçŸ¥èƒ½åŠ›çš„æ—¶ç©ºåŠ¨åŠ›å­¦é¢„æµ‹æä¾›äº†ä¸€ç§ç¨³å¥ä¸”é€šç”¨çš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Main text:33 pages,6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.21023v1",
      "published_date": "2025-10-23 22:17:21 UTC",
      "updated_date": "2025-10-23 22:17:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:21.486810+00:00"
    },
    {
      "arxiv_id": "2510.21011v1",
      "title": "Race and Gender in LLM-Generated Personas: A Large-Scale Audit of 41 Occupations",
      "title_zh": "LLM ç”Ÿæˆäººç‰©ç”»åƒä¸­çš„ç§æ—ä¸æ€§åˆ«ï¼šé’ˆå¯¹ 41 ç§èŒä¸šçš„å¤§è§„æ¨¡å®¡è®¡",
      "authors": [
        "Ilona van der Linden",
        "Sahana Kumar",
        "Arnav Dixit",
        "Aadi Sudan",
        "Smruthi Danda",
        "David C. Anastasiu",
        "Kai Lukoff"
      ],
      "abstract": "Generative AI tools are increasingly used to create portrayals of people in occupations, raising concerns about how race and gender are represented. We conducted a large-scale audit of over 1.5 million occupational personas across 41 U.S. occupations, generated by four large language models with different AI safety commitments and countries of origin (U.S., China, France). Compared with Bureau of Labor Statistics data, we find two recurring patterns: systematic shifts, where some groups are consistently under- or overrepresented, and stereotype exaggeration, where existing demographic skews are amplified. On average, White (--31pp) and Black (--9pp) workers are underrepresented, while Hispanic (+17pp) and Asian (+12pp) workers are overrepresented. These distortions can be extreme: for example, across all four models, Housekeepers are portrayed as nearly 100\\% Hispanic, while Black workers are erased from many occupations. For HCI, these findings show provider choice materially changes who is visible, motivating model-specific audits and accountable design practices.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶é’ˆå¯¹ 41 ç§ç¾å›½èŒä¸šï¼Œå¯¹å››ç§ä¸åŒèƒŒæ™¯çš„å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) ç”Ÿæˆçš„è¶…è¿‡ 150 ä¸‡ä¸ªèŒä¸šè§’è‰² (Personas) è¿›è¡Œäº†å¤§è§„æ¨¡å®¡è®¡ï¼Œæ—¨åœ¨æ¢è®¨ç§æ—å’Œæ€§åˆ«åœ¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸­çš„è¡¨å¾é—®é¢˜ã€‚ç ”ç©¶å‘ç° LLM ç”Ÿæˆçš„èŒä¸šè§’è‰²å­˜åœ¨ç³»ç»Ÿçš„åå·®ç§»åŠ¨å’Œåˆ»æ¿å°è±¡å¤¸å¤§ç°è±¡ï¼Œå…¶ä¸­ç™½äºº (White) å’Œé»‘äºº (Black) å·¥äººçš„è¡¨å¾æ¯”ä¾‹æ˜¾è‘—ä½äºåŠ³å·¥ç»Ÿè®¡å±€æ•°æ®ï¼Œè€Œè¥¿ç­ç‰™è£” (Hispanic) å’Œäºšè£” (Asian) å·¥äººåˆ™è¢«è¿‡åº¦è¡¨å¾ã€‚è¿™ç§æ‰­æ›²åœ¨æŸäº›èŒä¸šä¸­å°¤ä¸ºä¸¥é‡ï¼Œä¾‹å¦‚æ‰€æœ‰æ¨¡å‹éƒ½å°†å®¶æ”¿æœåŠ¡äººå‘˜ (Housekeepers) æç»˜ä¸ºè¿‘ä¹ 100% çš„è¥¿ç­ç‰™è£”ï¼Œä¸”é»‘äººå·¥ä½œè€…åœ¨å¤šé¡¹èŒä¸šä¸­é¢ä¸´è¢«â€œæŠ¹é™¤â€çš„ç°çŠ¶ã€‚è¯¥å®¡è®¡ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹çš„æä¾›æ–¹é€‰æ‹©ä¼šç›´æ¥å½±å“ç”Ÿæˆå†…å®¹çš„å¯è§æ€§ï¼Œå¼ºè°ƒäº†å¯¹ç‰¹å®šæ¨¡å‹è¿›è¡Œå®¡è®¡å’Œè´Ÿè´£ä»»è®¾è®¡ (Accountable Design) å®è·µçš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21011v1",
      "published_date": "2025-10-23 21:43:08 UTC",
      "updated_date": "2025-10-23 21:43:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:31.611313+00:00"
    },
    {
      "arxiv_id": "2510.21887v1",
      "title": "Generative AI in Depth: A Survey of Recent Advances, Model Variants, and Real-World Applications",
      "title_zh": "ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ·±åº¦ç»¼è¿°ï¼šæœ€æ–°è¿›å±•ã€æ¨¡å‹å˜ä½“ä¸å®é™…åº”ç”¨",
      "authors": [
        "Shamim Yazdani",
        "Akansha Singh",
        "Nripsuta Saxena",
        "Zichong Wang",
        "Avash Palikhe",
        "Deng Pan",
        "Umapada Pal",
        "Jie Yang",
        "Wenbin Zhang"
      ],
      "abstract": "In recent years, deep learning based generative models, particularly Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Diffusion Models (DMs), have been instrumental in in generating diverse, high-quality content across various domains, such as image and video synthesis. This capability has led to widespread adoption of these models and has captured strong public interest. As they continue to advance at a rapid pace, the growing volume of research, expanding application areas, and unresolved technical challenges make it increasingly difficult to stay current. To address this need, this survey introduces a comprehensive taxonomy that organizes the literature and provides a cohesive framework for understanding the development of GANs, VAEs, and DMs, including their many variants and combined approaches. We highlight key innovations that have improved the quality, diversity, and controllability of generated outputs, reflecting the expanding potential of generative artificial intelligence. In addition to summarizing technical progress, we examine rising ethical concerns, including the risks of misuse and the broader societal impact of synthetic media. Finally, we outline persistent challenges and propose future research directions, offering a structured and forward looking perspective for researchers in this fast evolving field.",
      "tldr_zh": "è¯¥ç»¼è¿°è®ºæ–‡æ·±å…¥æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) çš„æœ€æ–°è¿›å±•ï¼Œç³»ç»Ÿæ€»ç»“äº† Generative Adversarial Networks (GANs)ã€Variational Autoencoders (VAEs) å’Œ Diffusion Models (DMs) ç­‰æ ¸å¿ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ç ”ç©¶é€šè¿‡å»ºç«‹å…¨é¢çš„åˆ†ç±»æ³• (Taxonomy) æ•´ç†æ–‡çŒ®ï¼Œä¸ºç†è§£å„ç§æ¨¡å‹å˜ä½“åŠå…¶èåˆæ–¹æ³•æä¾›äº†å‡èšæ€§çš„æ¡†æ¶ã€‚æ–‡ç« é‡ç‚¹åˆ†æäº†æ—¨åœ¨æå‡ç”Ÿæˆå†…å®¹è´¨é‡ã€å¤šæ ·æ€§å’Œå¯æ§æ€§ (Controllability) çš„å…³é”®åˆ›æ–°ï¼Œä½“ç°äº†ç”Ÿæˆå¼ AI é¢†åŸŸä¸æ–­æ‰©å¤§çš„åº”ç”¨æ½œåŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å®¡è§†äº†åˆæˆåª’ä½“ (Synthetic Media) å¼•å‘çš„é“å¾·æ‹…å¿§ä¸ç¤¾ä¼šå½±å“ï¼Œå¹¶æŒ‡å‡ºäº†æ½œåœ¨çš„æ»¥ç”¨é£é™©ã€‚æœ€åï¼Œä½œè€…æ€»ç»“äº†å½“å‰é¢ä¸´çš„æŒç»­æŒ‘æˆ˜å¹¶å±•æœ›äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ï¼Œä¸ºå¤„äºè¿™ä¸€é«˜é€Ÿå‘å±•é¢†åŸŸçš„ç§‘ç ”äººå‘˜æä¾›äº†ç»“æ„åŒ–ä¸”å‰ç»æ€§çš„æŒ‡å¯¼è§†è§’ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the Journal of Big Data",
      "pdf_url": "https://arxiv.org/pdf/2510.21887v1",
      "published_date": "2025-10-23 21:11:12 UTC",
      "updated_date": "2025-10-23 21:11:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:36.051321+00:00"
    },
    {
      "arxiv_id": "2510.20997v1",
      "title": "Exploring Spiking Neural Networks for Binary Classification in Multivariate Time Series at the Edge",
      "title_zh": "è¾¹ç¼˜ä¾§å¤šå˜é‡æ—¶é—´åºåˆ—äºŒåˆ†ç±»çš„è„‰å†²ç¥ç»ç½‘ç»œæ¢ç´¢",
      "authors": [
        "James Ghawaly",
        "Andrew Nicholson",
        "Catherine Schuman",
        "Dalton Diez",
        "Aaron Young",
        "Brett Witherspoon"
      ],
      "abstract": "We present a general framework for training spiking neural networks (SNNs) to perform binary classification on multivariate time series, with a focus on step-wise prediction and high precision at low false alarm rates. The approach uses the Evolutionary Optimization of Neuromorphic Systems (EONS) algorithm to evolve sparse, stateful SNNs by jointly optimizing their architectures and parameters. Inputs are encoded into spike trains, and predictions are made by thresholding a single output neuron's spike counts. We also incorporate simple voting ensemble methods to improve performance and robustness.\n  To evaluate the framework, we apply it with application-specific optimizations to the task of detecting low signal-to-noise ratio radioactive sources in gamma-ray spectral data. The resulting SNNs, with as few as 49 neurons and 66 synapses, achieve a 51.8% true positive rate (TPR) at a false alarm rate of 1/hr, outperforming PCA (42.7%) and deep learning (49.8%) baselines. A three-model any-vote ensemble increases TPR to 67.1% at the same false alarm rate. Hardware deployment on the microCaspian neuromorphic platform demonstrates 2mW power consumption and 20.2ms inference latency.\n  We also demonstrate generalizability by applying the same framework, without domain-specific modification, to seizure detection in EEG recordings. An ensemble achieves 95% TPR with a 16% false positive rate, comparable to recent deep learning approaches with significant reduction in parameter count.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç”¨äºå¤šå˜é‡æ—¶é—´åºåˆ— (multivariate time series) äºŒåˆ†ç±»ä»»åŠ¡çš„è„‰å†²ç¥ç»ç½‘ç»œ (Spiking Neural Networks, SNNs) é€šç”¨æ¡†æ¶ï¼Œæ—¨åœ¨æ»¡è¶³è¾¹ç¼˜è®¾å¤‡å¯¹é€æ­¥é¢„æµ‹åŠä½è¯¯æŠ¥ç‡ä¸‹é«˜ç²¾åº¦çš„éœ€æ±‚ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ç¥ç»å½¢æ€ç³»ç»Ÿæ¼”åŒ–ä¼˜åŒ– (Evolutionary Optimization of Neuromorphic Systems, EONS) ç®—æ³•è”åˆä¼˜åŒ–æ¨¡å‹æ¶æ„ä¸å‚æ•°ï¼Œä»è€Œæ¼”åŒ–å‡ºç¨€ç–ä¸”å…·æœ‰çŠ¶æ€çš„ SNNsã€‚åœ¨æ”¾å°„æºæ¢æµ‹ä»»åŠ¡ä¸­ï¼Œä»…å« 49 ä¸ªç¥ç»å…ƒçš„å°å‹æ¨¡å‹åœ¨æä½è¯¯æŠ¥ç‡ä¸‹çš„è¡¨ç°ä¼˜äº PCA å’Œæ·±åº¦å­¦ä¹ åŸºçº¿ï¼Œç»“åˆæŠ•ç¥¨é›†æˆæ–¹æ³•åçœŸé˜³æ€§ç‡ (TPR) å¯æå‡è‡³ 67.1%ã€‚ç¡¬ä»¶éƒ¨ç½²å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨ microCaspian ç¥ç»å½¢æ€å¹³å°ä¸Šä»…æ¶ˆè€— 2mW åŠŸè€—ï¼Œæ¨ç†å»¶è¿Ÿä¸º 20.2msã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨è„‘ç”µå›¾ (EEG) ç™«ç—«æ£€æµ‹ä¸­ä¹Ÿå±•ç°äº†æå¼ºçš„é€šç”¨æ€§ï¼Œåœ¨å¤§å¹…ç¼©å‡å‚æ•°è§„æ¨¡çš„åŒæ—¶å®ç°äº†ä¸æ·±åº¦å­¦ä¹ æ–¹æ³•ç›¸å½“çš„æ£€æµ‹æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in 2025 International Joint Conference on Neural Networks (IJCNN)",
      "pdf_url": "https://arxiv.org/pdf/2510.20997v1",
      "published_date": "2025-10-23 20:52:11 UTC",
      "updated_date": "2025-10-23 20:52:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:42.358209+00:00"
    },
    {
      "arxiv_id": "2510.20994v1",
      "title": "VESSA: Video-based objEct-centric Self-Supervised Adaptation for Visual Foundation Models",
      "title_zh": "VESSAï¼šåŸºäºè§†é¢‘ä¸”ä»¥ç›®æ ‡ä¸ºä¸­å¿ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹è‡ªç›‘ç£é€‚é…",
      "authors": [
        "Jesimon Barreto",
        "Carlos Caetano",
        "AndrÃ© Araujo",
        "William Robson Schwartz"
      ],
      "abstract": "Foundation models have advanced computer vision by enabling strong performance across diverse tasks through large-scale pretraining and supervised fine-tuning. However, they may underperform in domains with distribution shifts and scarce labels, where supervised fine-tuning may be infeasible. While continued self-supervised learning for model adaptation is common for generative language models, this strategy has not proven effective for vision-centric encoder models. To address this challenge, we introduce a novel formulation of self-supervised fine-tuning for vision foundation models, where the model is adapted to a new domain without requiring annotations, leveraging only short multi-view object-centric videos. Our method is referred to as VESSA: Video-based objEct-centric Self-Supervised Adaptation for visual foundation models. VESSA's training technique is based on a self-distillation paradigm, where it is critical to carefully tune prediction heads and deploy parameter-efficient adaptation techniques - otherwise, the model may quickly forget its pretrained knowledge and reach a degraded state. VESSA benefits significantly from multi-view object observations sourced from different frames in an object-centric video, efficiently learning robustness to varied capture conditions, without the need of annotations. Through comprehensive experiments with 3 vision foundation models on 2 datasets, VESSA demonstrates consistent improvements in downstream classification tasks, compared to the base models and previous adaptation methods. Code is publicly available at https://github.com/jesimonbarreto/VESSA.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VESSAï¼Œä¸€ç§é’ˆå¯¹è§†è§‰åŸºç¡€æ¨¡å‹(Visual Foundation Models)çš„åŸºäºè§†é¢‘ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„è‡ªç›‘ç£å¾®è°ƒ(Self-Supervised Fine-tuning)æ¶æ„ï¼Œæ—¨åœ¨è§£å†³æ¨¡å‹åœ¨é¢†åŸŸåˆ†å¸ƒåç§»å’Œæ ‡ç­¾ç¨€ç¼ºåœºæ™¯ä¸‹è¡¨ç°ä¸ä½³çš„é—®é¢˜ã€‚VESSAåˆ©ç”¨æ— éœ€æ ‡æ³¨çš„çŸ­æ—¶å¤šè§†å›¾ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒ(Multi-view Object-centric)çš„è§†é¢‘è¿›è¡Œé¢†åŸŸè‡ªé€‚åº”ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»ä¸åŒå¸§çš„è§‚å¯Ÿä¸­å­¦ä¹ é²æ£’æ€§ã€‚è¯¥è®­ç»ƒæŠ€æœ¯åŸºäºè‡ªè’¸é¦(Self-distillation)èŒƒå¼ï¼Œé€šè¿‡ç²¾ç»†è°ƒæ•´é¢„æµ‹å¤´å’Œé‡‡ç”¨å‚æ•°é«˜æ•ˆè‡ªé€‚åº”(Parameter-efficient Adaptation)æŠ€æœ¯ï¼Œæœ‰æ•ˆé˜²æ­¢æ¨¡å‹åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­é—å¿˜é¢„è®­ç»ƒçŸ¥è¯†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVESSAåœ¨å¤šä¸ªè§†è§‰åŸºç¡€æ¨¡å‹å’Œæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œå…¶ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡çš„è¡¨ç°ä¸€è‡´ä¼˜äºåŸºç¡€æ¨¡å‹åŠç°æœ‰çš„è‡ªé€‚åº”æ–¹æ³•ï¼Œä¸ºæ— ç›‘ç£é¢†åŸŸçš„è§†è§‰æ¨¡å‹ä¼˜åŒ–æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Conference on Neural Information Processing Systems (NeurIPS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.20994v1",
      "published_date": "2025-10-23 20:44:28 UTC",
      "updated_date": "2025-10-23 20:44:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:41.962832+00:00"
    },
    {
      "arxiv_id": "2510.21886v1",
      "title": "Exploration through Generation: Applying GFlowNets to Structured Search",
      "title_zh": "ä»¥ç”Ÿæˆä¿ƒæ¢ç´¢ï¼šå°† GFlowNets åº”ç”¨äºç»“æ„åŒ–æœç´¢",
      "authors": [
        "Mark Phillip Matovic"
      ],
      "abstract": "This work applies Generative Flow Networks (GFlowNets) to three graph optimization problems: the Traveling Salesperson Problem, Minimum Spanning Tree, and Shortest Path. GFlowNets are generative models that learn to sample solutions proportionally to a reward function. The models are trained using the Trajectory Balance loss to build solutions sequentially, selecting edges for spanning trees, nodes for paths, and cities for tours. Experiments on benchmark instances of varying sizes show that GFlowNets learn to find optimal solutions. For each problem type, multiple graph configurations with different numbers of nodes were tested. The generated solutions match those from classical algorithms (Dijkstra for shortest path, Kruskal for spanning trees, and exact solvers for TSP). Training convergence depends on problem complexity, with the number of episodes required for loss stabilization increasing as graph size grows. Once training converges, the generated solutions match known optima from classical algorithms across the tested instances. This work demonstrates that generative models can solve combinatorial optimization problems through learned policies. The main advantage of this learning-based approach is computational scalability: while classical algorithms have fixed complexity per instance, GFlowNets amortize computation through training. With sufficient computational resources, the framework could potentially scale to larger problem instances where classical exact methods become infeasible.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆæµç½‘ç»œ(GFlowNets)åœ¨æ—…è¡Œå•†é—®é¢˜(Traveling Salesperson Problem, TSP)ã€æœ€å°ç”Ÿæˆæ ‘(Minimum Spanning Tree, MST)å’Œæœ€çŸ­è·¯å¾„(Shortest Path)è¿™ä¸‰ç§å›¾ä¼˜åŒ–é—®é¢˜ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶åˆ©ç”¨è½¨è¿¹å¹³è¡¡æŸå¤±(Trajectory Balance loss)è®­ç»ƒæ¨¡å‹ï¼Œé€šè¿‡é¡ºåºé€‰æ‹©å›¾å…ƒç´ æ„å»ºè§£å†³æ–¹æ¡ˆï¼Œä½¿å…¶èƒ½å¤ŸæŒ‰ç…§å¥–åŠ±å‡½æ•°æˆæ¯”ä¾‹åœ°é‡‡æ ·ã€‚åœ¨ä¸åŒè§„æ¨¡çš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒGFlowNetsç”Ÿæˆçš„è§£ä¸Dijkstraã€KruskalåŠç²¾ç¡®æ±‚è§£å™¨ç­‰ç»å…¸ç®—æ³•çš„ç»“æœç›¸åŒ¹é…ï¼Œè¯æ˜äº†å…¶å¯»æ‰¾æœ€ä¼˜è§£çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜è®­ç»ƒæ”¶æ•›æ€§å–å†³äºé—®é¢˜å¤æ‚åº¦ï¼Œä¸”è¯¥æ–¹æ³•çš„ä¸»è¦ä¼˜åŠ¿åœ¨äºè®¡ç®—æ‰©å±•æ€§(computational scalability)ï¼Œé€šè¿‡è®­ç»ƒæ‘Šé”€äº†è®¡ç®—æˆæœ¬ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†ç”Ÿæˆå¼æ¨¡å‹å¯ä»¥é€šè¿‡å­¦ä¹ ç­–ç•¥æœ‰æ•ˆè§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œä¸ºå¤„ç†ç»å…¸ç²¾ç¡®æ–¹æ³•éš¾ä»¥åº”å¯¹çš„å¤§è§„æ¨¡é—®é¢˜å®ä¾‹æä¾›äº†æ–°çš„é€”å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.21886v1",
      "published_date": "2025-10-23 20:43:09 UTC",
      "updated_date": "2025-10-23 20:43:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:48.714539+00:00"
    },
    {
      "arxiv_id": "2510.21885v1",
      "title": "Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning",
      "title_zh": "é¢„é˜²ç¾éš¾æ€§é—å¿˜ï¼šé¢å‘æ›´å®‰å…¨è¯­è¨€æ¨¡å‹å¾®è°ƒçš„è¡Œä¸ºæ„ŸçŸ¥é‡‡æ ·",
      "authors": [
        "Anh Pham",
        "Mihir Thalanki",
        "Michael Sun",
        "Aditya Chaloo",
        "Ankita Gupta",
        "Tian Xia",
        "Aditya Mate",
        "Ehimwenma Nosakhare",
        "Soundararajan Srinivasan"
      ],
      "abstract": "Large language models often lose previously aligned safety behaviors when fine-tuned on benign data, a phenomenon known as catastrophic forgetting. Prior work shows that adding random safety examples can mitigate this effect, but it remains unclear which examples are most effective. We propose a behavior-aware sampling framework that selects safety examples based on two complementary factors: instruction-response behavior (e.g., refusal versus compliance) and semantic diversity across harm categories. Systematic evaluation shows that this approach substantially reduces harmful outputs while maintaining helpfulness, achieving up to a 41% reduction in harmfulness with only 0.5% additional training data. These results highlight how targeted data selection can improve the safety and efficiency of fine-tuning at scale.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹åœ¨è‰¯æ€§æ•°æ®å¾®è°ƒè¿‡ç¨‹ä¸­å‡ºç°çš„å®‰å…¨è¡Œä¸ºç¾éš¾æ€§é—å¿˜(catastrophic forgetting)é—®é¢˜ï¼Œæå‡ºäº†è¡Œä¸ºæ„ŸçŸ¥é‡‡æ ·(behavior-aware sampling)æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸¤ä¸ªäº’è¡¥ç»´åº¦ç­›é€‰å®‰å…¨ç¤ºä¾‹ï¼Œå³æŒ‡ä»¤å“åº”è¡Œä¸º(instruction-response behavior)å’Œè·¨ä¼¤å®³ç±»åˆ«çš„è¯­ä¹‰å¤šæ ·æ€§(semantic diversity)ï¼Œæ—¨åœ¨é€šè¿‡ç²¾å‡†çš„æ•°æ®é€‰æ‹©è€Œééšæœºé‡‡æ ·æ¥ç»´æŒæ¨¡å‹å®‰å…¨å¯¹é½ã€‚ç³»ç»Ÿæ€§è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒæ¨¡å‹æœ‰ç”¨æ€§(helpfulness)çš„åŒæ—¶æ˜¾è‘—å‡å°‘äº†æœ‰å®³è¾“å‡ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä»…éœ€å¢åŠ 0.5%çš„é¢å¤–è®­ç»ƒæ•°æ®ï¼Œå³å¯å®ç°é«˜è¾¾41%çš„æœ‰å®³æ€§å‰Šå‡ã€‚è¿™é¡¹ç ”ç©¶å¼ºè°ƒäº†é’ˆå¯¹æ€§æ•°æ®é€‰æ‹©åœ¨æå‡å¤§è§„æ¨¡æ¨¡å‹å¾®è°ƒå®‰å…¨æ€§å’Œæ•ˆç‡æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21885v1",
      "published_date": "2025-10-23 20:34:52 UTC",
      "updated_date": "2025-10-23 20:34:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:46.958821+00:00"
    },
    {
      "arxiv_id": "2510.23626v1",
      "title": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media",
      "title_zh": "ä»æ£€æµ‹åˆ°å‘ç°ï¼šä¸€ç§ç”¨äºç¤¾äº¤åª’ä½“åŒ»å­¦çŸ¥è¯†åŒæ­¥æŒç»­æ‰©å±•ä¸æŠ‘éƒç—‡æ£€æµ‹çš„é—­ç¯æ–¹æ³•",
      "authors": [
        "Shuang Geng",
        "Wenli Zhang",
        "Jiaheng Xie",
        "Rui Wang",
        "Sudha Ram"
      ],
      "abstract": "Social media user-generated content (UGC) provides real-time, self-reported indicators of mental health conditions such as depression, offering a valuable source for predictive analytics. While prior studies integrate medical knowledge to improve prediction accuracy, they overlook the opportunity to simultaneously expand such knowledge through predictive processes. We develop a Closed-Loop Large Language Model (LLM)-Knowledge Graph framework that integrates prediction and knowledge expansion in an iterative learning cycle. In the knowledge-aware depression detection phase, the LLM jointly performs depression detection and entity extraction, while the knowledge graph represents and weights these entities to refine prediction performance. In the knowledge refinement and expansion phase, new entities, relationships, and entity types extracted by the LLM are incorporated into the knowledge graph under expert supervision, enabling continual knowledge evolution. Using large-scale UGC, the framework enhances both predictive accuracy and medical understanding. Expert evaluations confirmed the discovery of clinically meaningful symptoms, comorbidities, and social triggers complementary to existing literature. We conceptualize and operationalize prediction-through-learning and learning-through-prediction as mutually reinforcing processes, advancing both methodological and theoretical understanding in predictive analytics. The framework demonstrates the co-evolution of computational models and domain knowledge, offering a foundation for adaptive, data-driven knowledge systems applicable to other dynamic risk monitoring contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é—­ç¯çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸çŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graphï¼‰æ¡†æ¶ï¼Œå®ç°äº†ç¤¾äº¤åª’ä½“æŠ‘éƒç—‡æ£€æµ‹ï¼ˆDepression Detectionï¼‰ä¸åŒ»å­¦çŸ¥è¯†æ‰©å¼ ï¼ˆMedical Knowledge Expansionï¼‰çš„ååŒæ¼”è¿›ã€‚è¯¥æ¡†æ¶åœ¨é¢„æµ‹é˜¶æ®µåˆ©ç”¨ LLM è¿›è¡ŒæŠ‘éƒç—‡æ£€æµ‹ä¸å®ä½“æå–ï¼Œå¹¶ç»“åˆ Knowledge Graph è¿›è¡Œæƒé‡ä¼˜åŒ–ä»¥æå‡é¢„æµ‹æ€§èƒ½ã€‚åœ¨çŸ¥è¯†ç²¾ç‚¼é˜¶æ®µï¼ŒLLM æå–çš„æ–°å®ä½“ã€å…³ç³»å’Œç±»å‹åœ¨ä¸“å®¶ç›‘ç£ä¸‹åé¦ˆè‡³çŸ¥è¯†åº“ï¼Œç¡®ä¿äº†åŒ»å­¦çŸ¥è¯†çš„æŒç»­æ¼”è¿›ã€‚é€šè¿‡å¯¹å¤§è§„æ¨¡ç”¨æˆ·ç”Ÿæˆå†…å®¹ï¼ˆUGCï¼‰çš„å¤„ç†ï¼Œè¯¥ç³»ç»Ÿä¸ä»…æå‡äº†æ£€æµ‹å‡†ç¡®ç‡ï¼Œè¿˜å‘ç°äº†ä¸´åºŠç›¸å…³çš„ç—‡çŠ¶ã€åˆå¹¶ç—‡ï¼ˆComorbiditiesï¼‰å’Œç¤¾ä¼šè¯±å› ã€‚è¿™ç§â€œé¢„æµ‹ä¸­å­¦ä¹ â€ä¸â€œå­¦ä¹ ä¸­é¢„æµ‹â€çš„äº’è¡¥æ¨¡å¼ï¼Œä¸ºæ„å»ºè‡ªé€‚åº”ã€æ•°æ®é©±åŠ¨çš„åŠ¨æ€é£é™©ç›‘æµ‹çŸ¥è¯†ç³»ç»Ÿå¥ å®šäº†æ–¹æ³•è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at SWAIB2025 and HICSS2026",
      "pdf_url": "https://arxiv.org/pdf/2510.23626v1",
      "published_date": "2025-10-23 20:34:36 UTC",
      "updated_date": "2025-10-23 20:34:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:59.063143+00:00"
    },
    {
      "arxiv_id": "2510.21884v1",
      "title": "Framework for Machine Evaluation of Reasoning Completeness in Large Language Models For Classification Tasks",
      "title_zh": "åˆ†ç±»ä»»åŠ¡ä¸­å¤§è¯­è¨€æ¨¡å‹æ¨ç†å®Œå¤‡æ€§çš„æœºå™¨è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Avinash Patil"
      ],
      "abstract": "The growing adoption of machine learning (ML) in sensitive domains has heightened the demand for transparent and interpretable artificial intelligence. Large Language Models (LLMs) are increasingly capable of producing natural language explanations, yet it remains unclear whether these rationales faithfully capture the predictive signals that underlie decisions. This paper introduces RACE-Reasoning Alignment for Completeness of Explanations, a systematic framework to evaluate the alignment between LLM-generated explanations and interpretable feature importance scores derived from a logistic regression baseline. We analyze four widely used text classification datasets-WIKI ONTOLOGY, AG NEWS, IMDB, and GOEMOTIONS-and compare LLM rationales against top-ranked supporting and contradicting lexical features. To capture alignment at multiple levels of granularity, RACE implements token-aware, exact string, and edit-distance matching techniques. Empirical results reveal a consistent asymmetry: correct predictions exhibit higher coverage of supporting features, while incorrect predictions are associated with elevated coverage of contradicting features. Edit-distance matching further uncovers paraphrastic overlaps, boosting coverage while preserving this asymmetry. These findings demonstrate that LLM rationales combine both surface-level and flexible evidence reuse, yet can also amplify misleading cues in error cases. RACE provides new insights into the faithfulness of LLM explanations and establishes a quantitative basis for evaluating reasoning completeness in neural language models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RACEï¼ˆReasoning Alignment for Completeness of Explanationsï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„è§£é‡Šä¸é€»è¾‘å›å½’åŸºå‡†æ¨¡å‹å¯¼å‡ºçš„ç‰¹å¾é‡è¦æ€§å¾—åˆ†ä¹‹é—´çš„å¯¹é½ç¨‹åº¦ã€‚è¯¥æ¡†æ¶åœ¨WIKI ONTOLOGYã€AG NEWSã€IMDBå’ŒGOEMOTIONSå››ä¸ªåˆ†ç±»æ•°æ®é›†ä¸Šï¼Œåˆ©ç”¨Token-awareã€Exact stringåŠEdit-distanceåŒ¹é…æŠ€æœ¯ï¼Œå¯¹æ¯”äº†LLMæ¨ç†å†…å®¹ä¸å…³é”®è¯æ±‡ç‰¹å¾çš„ä¸€è‡´æ€§ã€‚å®éªŒç»“æœæ­ç¤ºäº†ä¸€ç§æ˜¾è‘—çš„ä¸å¯¹ç§°æ€§ï¼Œå³æ­£ç¡®çš„é¢„æµ‹å¾€å¾€å¯¹åº”è¾ƒé«˜çš„æ”¯æŒæ€§ç‰¹å¾è¦†ç›–ç‡ï¼Œè€Œé”™è¯¯çš„é¢„æµ‹åˆ™æ›´å¤šåœ°æ¶µç›–äº†çŸ›ç›¾æ€§ç‰¹å¾ã€‚æ­¤å¤–ï¼ŒEdit-distanceåŒ¹é…æ­ç¤ºäº†æ¨¡å‹åœ¨è§£é‡Šä¸­å­˜åœ¨é‡Šä¹‰é‡å ï¼Œè¡¨æ˜LLMæ¨ç†åœ¨å¤ç”¨è¯æ®çš„åŒæ—¶ä¹Ÿå¯èƒ½åœ¨é”™è¯¯æ¡ˆä¾‹ä¸­æ”¾å¤§è¯¯å¯¼æ€§çº¿ç´¢ã€‚RACEä¸ºè¯„ä¼°ç¥ç»è¯­è¨€æ¨¡å‹çš„æ¨ç†å®Œå¤‡æ€§ï¼ˆReasoning Completenessï¼‰å’Œè§£é‡Šå¿ å®åº¦ï¼ˆFaithfulnessï¼‰æä¾›äº†é‡åŒ–çš„åŸºå‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 Pages, 12 Figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.21884v1",
      "published_date": "2025-10-23 20:22:22 UTC",
      "updated_date": "2025-10-23 20:22:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:07:53.961830+00:00"
    },
    {
      "arxiv_id": "2510.20985v1",
      "title": "GPU Memory Requirement Prediction for Deep Learning Task Based on Bidirectional Gated Recurrent Unit Optimization Transformer",
      "title_zh": "åŸºäºåŒå‘é—¨æ§å¾ªç¯å•å…ƒä¼˜åŒ– Transformer çš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ GPU æ˜¾å­˜éœ€æ±‚é¢„æµ‹",
      "authors": [
        "Chao Wang",
        "Zhizhao Wen",
        "Ruoxin Zhang",
        "Puyang Xu",
        "Yifan Jiang"
      ],
      "abstract": "In response to the increasingly critical demand for accurate prediction of GPU memory resources in deep learning tasks, this paper deeply analyzes the current research status and innovatively proposes a deep learning model that integrates bidirectional gated recurrent units (BiGRU) to optimize the Transformer architecture, aiming to improve the accuracy of memory demand prediction. To verify the effectiveness of the model, a carefully designed comparative experiment was conducted, selecting four representative basic machine learning models: decision tree, random forest, Adaboost, and XGBoost as benchmarks. The detailed experimental results show that the BiGRU Transformer optimization model proposed in this paper exhibits significant advantages in key evaluation indicators: in terms of mean square error (MSE) and root mean square error (RMSE), the model achieves the lowest value among all comparison models, and its predicted results have the smallest deviation from the actual values; In terms of mean absolute error (MAE) and coefficient of determination (R2) indicators, the model also performs well and the results are balanced and stable, with comprehensive predictive performance far exceeding the benchmark machine learning methods compared. In summary, the Transformer model based on bidirectional gated recurrent unit optimization successfully constructed in this study can efficiently and accurately complete GPU memory demand prediction tasks in deep learning tasks, and its prediction accuracy has been significantly improved compared to traditional machine learning methods. This research provides strong technical support and reliable theoretical basis for optimizing resource scheduling and management of deep learning tasks, and improving the utilization efficiency of computing clusters.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­GPUæ˜¾å­˜èµ„æºé¢„æµ‹ç²¾åº¦éœ€æ±‚æ—¥ç›Šå¢é•¿çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é›†æˆåŒå‘é—¨æ§å¾ªç¯å•å…ƒ(BiGRU)ä»¥ä¼˜åŒ–Transformeræ¶æ„çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ä¸ºäº†éªŒè¯æ¨¡å‹æœ‰æ•ˆæ€§ï¼Œç ”ç©¶è€…é€‰å–äº†å†³ç­–æ ‘(Decision Tree)ã€éšæœºæ£®æ—(Random Forest)ã€AdabooståŠXGBoostå››ç§ä»£è¡¨æ€§æœºå™¨å­¦ä¹ æ¨¡å‹ä½œä¸ºåŸºå‡†è¿›è¡Œè¯¦ç»†å¯¹æ¯”å®éªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBiGRU-Transformerä¼˜åŒ–æ¨¡å‹åœ¨å‡æ–¹è¯¯å·®(MSE)å’Œå‡æ–¹æ ¹è¯¯å·®(RMSE)ç­‰å…³é”®è¯„ä¼°æŒ‡æ ‡ä¸Šå‡å–å¾—äº†æ‰€æœ‰å¯¹æ¯”æ¨¡å‹ä¸­çš„æœ€ä½å€¼ï¼Œé¢„æµ‹åå·®é™è‡³æœ€ä½ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨å¹³å‡ç»å¯¹è¯¯å·®(MAE)å’Œå†³å®šç³»æ•°(R2)æŒ‡æ ‡ä¸ŠåŒæ ·è¡¨ç°ä¼˜å¼‚ä¸”ç¨³å®šï¼Œå…¶ç»¼åˆé¢„æµ‹æ€§èƒ½æ˜¾è‘—è¶…è¶Šäº†ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•ã€‚è¯¥ç ”ç©¶æˆåŠŸæ„å»ºçš„é¢„æµ‹æ¨¡å‹èƒ½å¤Ÿé«˜æ•ˆå‡†ç¡®åœ°å®ŒæˆGPUæ˜¾å­˜éœ€æ±‚é¢„æµ‹ä»»åŠ¡ï¼Œä¸ºä¼˜åŒ–èµ„æºè°ƒåº¦ç®¡ç†åŠæå‡è®¡ç®—é›†ç¾¤åˆ©ç”¨æ•ˆç‡æä¾›äº†å¯é çš„æŠ€æœ¯æ”¯æ’‘å’Œç†è®ºä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20985v1",
      "published_date": "2025-10-23 20:20:35 UTC",
      "updated_date": "2025-10-23 20:20:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:06.064664+00:00"
    },
    {
      "arxiv_id": "2510.20984v1",
      "title": "Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression",
      "title_zh": "é¢å‘ä½æ¯”ç‰¹å¤§è¯­è¨€æ¨¡å‹å‹ç¼©çš„å­¦ä¹ å‹åˆ†ç»„æ ¼ç‚¹çŸ¢é‡é‡åŒ–å™¨",
      "authors": [
        "Xi Zhang",
        "Xiaolin Wu",
        "Jiamang Wang",
        "Weisi Lin"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but typically require extensive computational resources and memory for inference. Post-training quantization (PTQ) can effectively reduce these demands by storing weights in lower bit-width formats. However, standard uniform quantization often leads to notable performance degradation, particularly in low-bit scenarios. In this work, we introduce a Grouped Lattice Vector Quantization (GLVQ) framework that assigns each group of weights a customized lattice codebook, defined by a learnable generation matrix. To address the non-differentiability of the quantization process, we adopt Babai rounding to approximate nearest-lattice-point search during training, which enables stable optimization of the generation matrices. Once trained, decoding reduces to a simple matrix-vector multiplication, yielding an efficient and practical quantization pipeline. Experiments on multiple benchmarks show that our approach achieves a better trade-off between model size and accuracy compared to existing post-training quantization baselines, highlighting its effectiveness in deploying large models under stringent resource constraints. Our source code is available on GitHub repository: https://github.com/xzhang9308/GLVQ.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä½æ¯”ç‰¹å‹ç¼©ä¸‹æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†Grouped Lattice Vector Quantization (GLVQ)æ¡†æ¶ã€‚è¯¥æ¡†æ¶ä¸ºæ¯ç»„æƒé‡åˆ†é…ç”±å¯å­¦ä¹ ç”ŸæˆçŸ©é˜µå®šä¹‰çš„å®šåˆ¶åŒ–lattice codebookï¼Œä»¥å®ç°æ›´ç²¾ç¡®çš„å‘é‡é‡åŒ–ã€‚ä¸ºäº†è§£å†³é‡åŒ–è¿‡ç¨‹ä¸å¯å¾®çš„æŒ‘æˆ˜ï¼Œç ”ç©¶é‡‡ç”¨Babai roundingæ¥è¿‘ä¼¼æœ€è¿‘æ ¼ç‚¹æœç´¢ï¼Œä»è€Œå®ç°å¯¹ç”ŸæˆçŸ©é˜µçš„ç¨³å®šä¼˜åŒ–ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œè§£ç è¿‡ç¨‹å¯ç®€åŒ–ä¸ºçŸ©é˜µå‘é‡ä¹˜æ³•ï¼Œç¡®ä¿äº†é‡åŒ–ç®¡çº¿çš„é«˜æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚å¤šé¡¹åŸºå‡†æµ‹è¯•ç»“æœè¡¨æ˜ï¼ŒGLVQåœ¨æ¨¡å‹å¤§å°ä¸å‡†ç¡®åº¦ä¹‹é—´å–å¾—äº†æ¯”ç°æœ‰è®­ç»ƒåé‡åŒ–(PTQ)åŸºå‡†æ›´å¥½çš„æƒè¡¡ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„æ¨¡å‹éƒ¨ç½²æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025 Poster",
      "pdf_url": "https://arxiv.org/pdf/2510.20984v1",
      "published_date": "2025-10-23 20:19:48 UTC",
      "updated_date": "2025-10-23 20:19:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:01.964588+00:00"
    },
    {
      "arxiv_id": "2510.20979v1",
      "title": "Memory Constrained Dynamic Subnetwork Update for Transfer Learning",
      "title_zh": "å†…å­˜å—é™ä¸‹çš„è¿ç§»å­¦ä¹ åŠ¨æ€å­ç½‘ç»œæ›´æ–°",
      "authors": [
        "AÃ«l QuÃ©lennec",
        "Pavlo Mozharovskyi",
        "Van-Tam Nguyen",
        "Enzo Tartaglione"
      ],
      "abstract": "On-device neural network training faces critical memory constraints that limit the adaptation of pre-trained models to downstream tasks. We present MeDyate, a theoretically-grounded framework for memory-constrained dynamic subnetwork adaptation. Our approach introduces two key innovations: LaRa (Layer Ranking), an improved layer importance metric that enables principled layer pre-selection, and a dynamic channel sampling strategy that exploits the temporal stability of channel importance distributions during fine-tuning. MeDyate dynamically resamples channels between epochs according to importance-weighted probabilities, ensuring comprehensive parameter space exploration while respecting strict memory budgets. Extensive evaluation across a large panel of tasks and architectures demonstrates that MeDyate achieves state-of-the-art performance under extreme memory constraints, consistently outperforming existing static and dynamic approaches while maintaining high computational efficiency. Our method represents a significant step towards enabling efficient on-device learning by demonstrating effective fine-tuning with memory budgets as low as a few hundred kB of RAM.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MeDyateï¼Œä¸€ä¸ªå…·å¤‡ç†è®ºåŸºç¡€çš„å†…å­˜å—é™åŠ¨æ€å­ç½‘ç»œé€‚é…ï¼ˆmemory-constrained dynamic subnetwork adaptationï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è®¾å¤‡ç«¯ç¥ç»ç½‘ç»œè®­ç»ƒåœ¨å°†é¢„è®­ç»ƒæ¨¡å‹é€‚é…è‡³ä¸‹æ¸¸ä»»åŠ¡æ—¶é¢ä¸´çš„ä¸¥è‹›å†…å­˜ç“¶é¢ˆã€‚è¯¥æ–¹æ³•å¼•å…¥äº†åä¸ºLaRaï¼ˆLayer Rankingï¼‰çš„æ”¹è¿›å±‚é‡è¦æ€§æŒ‡æ ‡ä»¥å®ç°åŸåˆ™æ€§çš„å±‚é¢„é€‰ï¼Œå¹¶æå‡ºäº†ä¸€ç§åˆ©ç”¨å¾®è°ƒæœŸé—´é€šé“é‡è¦æ€§åˆ†å¸ƒæ—¶é—´ç¨³å®šæ€§çš„åŠ¨æ€é€šé“é‡‡æ ·ç­–ç•¥ã€‚MeDyateåœ¨è®­ç»ƒè½®æ¬¡é—´ä¾æ®é‡è¦æ€§æƒé‡æ¦‚ç‡åŠ¨æ€é‡é‡‡æ ·é€šé“ï¼Œåœ¨éµå®ˆä¸¥æ ¼å†…å­˜é¢„ç®—çš„åŒæ—¶ç¡®ä¿äº†å¯¹å‚æ•°ç©ºé—´çš„å…¨é¢æ¢ç´¢ã€‚å¤šé¡¹ä»»åŠ¡å’Œæ¶æ„çš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒMeDyateåœ¨æç«¯å†…å­˜é™åˆ¶ä¸‹è¾¾åˆ°äº†SOTAæ€§èƒ½ï¼Œå…¶è¡¨ç°æŒç»­ä¼˜äºç°æœ‰çš„é™æ€å’ŒåŠ¨æ€æ–¹æ³•å¹¶ä¿æŒäº†æé«˜çš„è®¡ç®—æ•ˆç‡ã€‚è¯¥æ–¹æ³•è¯æ˜äº†åœ¨å†…å­˜é¢„ç®—ä½è‡³å‡ ç™¾kB RAMçš„æƒ…å†µä¸‹å®ç°æœ‰æ•ˆå¾®è°ƒçš„å¯è¡Œæ€§ï¼Œä¸ºå®ç°é«˜æ•ˆçš„è®¾å¤‡ç«¯å­¦ä¹ ï¼ˆon-device learningï¼‰è¿ˆå‡ºäº†å…³é”®ä¸€æ­¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20979v1",
      "published_date": "2025-10-23 20:16:43 UTC",
      "updated_date": "2025-10-23 20:16:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:22.352045+00:00"
    },
    {
      "arxiv_id": "2510.20975v1",
      "title": "REx86: A Local Large Language Model for Assisting in x86 Assembly Reverse Engineering",
      "title_zh": "REx86ï¼šç”¨äºè¾…åŠ© x86 æ±‡ç¼–é€†å‘å·¥ç¨‹çš„æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Darrin Lea",
        "James Ghawaly",
        "Golden Richard",
        "Aisha Ali-Gombe",
        "Andrew Case"
      ],
      "abstract": "Reverse engineering (RE) of x86 binaries is indispensable for malware and firmware analysis, but remains slow due to stripped metadata and adversarial obfuscation. Large Language Models (LLMs) offer potential for improving RE efficiency through automated comprehension and commenting, but cloud-hosted, closed-weight models pose privacy and security risks and cannot be used in closed-network facilities. We evaluate parameter-efficient fine-tuned local LLMs for assisting with x86 RE tasks in these settings. Eight open-weight models across the CodeLlama, Qwen2.5-Coder, and CodeGemma series are fine-tuned on a custom curated dataset of 5,981 x86 assembly examples. We evaluate them quantitatively and identify the fine-tuned Qwen2.5-Coder-7B as the top performer, which we name REx86.\n  REx86 reduces test-set cross-entropy loss by 64.2% and improves semantic cosine similarity against ground truth by 20.3\\% over its base model. In a limited user case study (n=43), REx86 significantly enhanced line-level code understanding (p = 0.031) and increased the correct-solve rate from 31% to 53% (p = 0.189), though the latter did not reach statistical significance. Qualitative analysis shows more accurate, concise comments with fewer hallucinations.\n  REx86 delivers state-of-the-art assistance in x86 RE among local, open-weight LLMs. Our findings demonstrate the value of domain-specific fine-tuning, and highlight the need for more commented disassembly data to further enhance LLM performance in RE. REx86, its dataset, and LoRA adapters are publicly available at https://github.com/dlea8/REx86 and https://zenodo.org/records/15420461.",
      "tldr_zh": "é’ˆå¯¹x86äºŒè¿›åˆ¶æ–‡ä»¶çš„é€†å‘å·¥ç¨‹(Reverse Engineering)å› å…ƒæ•°æ®ç¼ºå¤±å’Œä»£ç æ··æ·†è€Œé¢ä¸´æ•ˆç‡ä½ä¸‹çš„æŒ‘æˆ˜ï¼Œä¸”äº‘ç«¯å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†æ•æ„Ÿä»£ç æ—¶å­˜åœ¨éšç§å®‰å…¨é£é™©ã€‚è¯¥ç ”ç©¶è¯„ä¼°äº†å¤šç§ç»è¿‡å‚æ•°é«˜æ•ˆå¾®è°ƒçš„æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹ï¼Œå¹¶æ¨å‡ºäº†REx86ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºQwen2.5-Coder-7Bå¹¶åœ¨5,981ä¸ªx86æ±‡ç¼–ç¤ºä¾‹æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒçš„æœ€ä¼˜æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒREx86åœ¨æµ‹è¯•é›†ä¸Šçš„äº¤å‰ç†µæŸå¤±é™ä½äº†64.2%ï¼Œä¸”ä¸ ground truth çš„è¯­ä¹‰ä½™å¼¦ç›¸ä¼¼åº¦æå‡äº†20.3%ã€‚åœ¨åŒ…å«43åç”¨æˆ·çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼ŒREx86æ˜¾è‘—å¢å¼ºäº†è¡Œçº§ä»£ç ç†è§£èƒ½åŠ›ï¼Œå¹¶å°†ä»»åŠ¡æ­£ç¡®è§£å†³ç‡ä»31%æé«˜åˆ°53%ã€‚å®šæ€§åˆ†æè¡¨æ˜ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆçš„æ³¨é‡Šæ¯”åŸºç¡€æ¨¡å‹æ›´å‡†ç¡®ã€ç®€æ´ï¼Œä¸”å¹»è§‰(hallucinations)ç°è±¡æ˜¾è‘—å‡å°‘ã€‚REx86åœ¨æœ¬åœ°å¼€æºæ¨¡å‹ä¸­å®ç°äº†æœ€å…ˆè¿›çš„x86é€†å‘å·¥ç¨‹è¾…åŠ©æ€§èƒ½ï¼Œå±•ç¤ºäº†é’ˆå¯¹ç‰¹å®šé¢†åŸŸè¿›è¡Œå¾®è°ƒçš„å·¨å¤§ä»·å€¼ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted in 2025 Annual Computer Security Applications Conference (ACSAC)",
      "pdf_url": "https://arxiv.org/pdf/2510.20975v1",
      "published_date": "2025-10-23 20:09:21 UTC",
      "updated_date": "2025-10-23 20:09:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:20.943082+00:00"
    },
    {
      "arxiv_id": "2510.20967v1",
      "title": "3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language Models",
      "title_zh": "3DReasonKneeï¼šæ¨è¿›åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„å®šä½æ¨ç†",
      "authors": [
        "Sraavya Sambara",
        "Sung Eun Kim",
        "Xiaoman Zhang",
        "Luyang Luo",
        "Shreya Johri",
        "Mohammed Baharoon",
        "Du Hyun Ro",
        "Pranav Rajpurkar"
      ],
      "abstract": "Current Vision-Language Models (VLMs) struggle to ground anatomical regions in 3D medical images and reason about them in a step-by-step manner, a key requirement of real-world diagnostic assessment. This ability is essential for aligning model outputs with the diagnostic workflows clinicians use in practice, enabling trustworthy clinician-AI collaboration. Existing 3D datasets provide localization labels, but none support this \"grounded reasoning\" ability. To address this gap, we introduce 3DReasonKnee, the first 3D grounded reasoning dataset for medical images, which provides 494k high-quality quintuples derived from 7,970 3D knee MRI volumes. Each quintuple includes: (1) the 3D MRI volume, (2) a diagnostic question targeting a specific anatomical region (3) a 3D bounding box localizing the relevant anatomical structures, (4) clinician-generated diagnostic reasoning steps that explicitly detail the 3D reasoning process, and (5) structured severity assessments for the relevant anatomical region. The creation and validation of 3DReasonKnee, involving over 450 hours of expert clinician time for manually segmenting MRIs and generating reasoning chains, ensures its superior quality and clinical relevance. We establish ReasonKnee-Bench to evaluate localization and diagnostic accuracy, providing insight into VLM ability to perform grounding and severity assessment across anatomical regions and diagnostic inquiries. We benchmark five state-of-the-art VLMs, providing baseline performance for ReasonKnee-Bench. By providing this unique resource of expert-annotated 3D reasoning pathways, 3DReasonKnee serves as a repository of orthopedic surgeons' diagnostic expertise and offers a vital testbed for advancing multimodal medical AI systems towards 3D, clinically aligned, localized decision-making capabilities. The dataset can be found in: https://huggingface.co/datasets/rajpurkarlab/3DReasonKnee",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† 3DReasonKneeï¼Œè¿™æ˜¯é¦–ä¸ªé¢å‘åŒ»å­¦å›¾åƒçš„ 3D grounded reasoning æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³å½“å‰ Vision-Language Models (VLMs) åœ¨ 3D åŒ»å­¦å½±åƒä¸­éš¾ä»¥å®ç°è§£å‰–åŒºåŸŸå®šä½ä¸å¾ªåºæ¸è¿›æ¨ç†çš„é—®é¢˜ã€‚è¯¥æ•°æ®é›†åŒ…å«ä» 7,970 ä¸ª 3D è†å…³èŠ‚ MRI å·ä¸­æå–çš„ 49.4 ä¸‡ä¸ªé«˜è´¨é‡äº”å…ƒç»„ï¼Œæ¶µç›–äº† 3D å·ã€è¯Šæ–­é—®é¢˜ã€å®šä½è§£å‰–ç»“æ„çš„ 3D bounding boxã€ä¸´åºŠåŒ»ç”Ÿç”Ÿæˆçš„æ¨ç†æ­¥éª¤ä»¥åŠç»“æ„åŒ–çš„ä¸¥é‡ç¨‹åº¦è¯„ä¼°ã€‚é€šè¿‡è¶…è¿‡ 450 å°æ—¶çš„ä¸“å®¶æ ‡æ³¨ï¼Œè¯¥ç ”ç©¶ç¡®ä¿äº†æ•°æ®é›†çš„ä¸´åºŠç›¸å…³æ€§ä¸é«˜è´¨é‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜å»ºç«‹äº† ReasonKnee-Bench åŸºå‡†ï¼Œå¯¹äº”ç§æœ€å…ˆè¿›çš„ VLMs åœ¨å®šä½å’Œè¯Šæ–­å‡†ç¡®æ€§æ–¹é¢è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚3DReasonKnee ä¸ºæ¨è¿›å¤šæ¨¡æ€åŒ»ç–— AI ç³»ç»Ÿå®ç°ä¸´åºŠå¯¹é½ã€å…·å¤‡å±€éƒ¨å†³ç­–èƒ½åŠ›çš„ 3D æ¨ç†æä¾›äº†æ ¸å¿ƒèµ„æºå’Œæµ‹è¯•å¹³å°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20967v1",
      "published_date": "2025-10-23 19:54:49 UTC",
      "updated_date": "2025-10-23 19:54:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:25.153027+00:00"
    },
    {
      "arxiv_id": "2510.20943v1",
      "title": "Meta-Learning for Cross-Task Generalization in Protein Mutation Property Prediction",
      "title_zh": "è›‹ç™½è´¨çªå˜æ€§è´¨é¢„æµ‹è·¨ä»»åŠ¡æ³›åŒ–çš„å…ƒå­¦ä¹ ",
      "authors": [
        "Srivathsan Badrinarayanan",
        "Yue Su",
        "Janghoon Ock",
        "Alan Pham",
        "Sanya Ahuja",
        "Amir Barati Farimani"
      ],
      "abstract": "Protein mutations can have profound effects on biological function, making accurate prediction of property changes critical for drug discovery, protein engineering, and precision medicine. Current approaches rely on fine-tuning protein-specific transformers for individual datasets, but struggle with cross-dataset generalization due to heterogeneous experimental conditions and limited target domain data. We introduce two key innovations: (1) the first application of Model-Agnostic Meta-Learning (MAML) to protein mutation property prediction, and (2) a novel mutation encoding strategy using separator tokens to directly incorporate mutations into sequence context. We build upon transformer architectures integrating them with MAML to enable rapid adaptation to new tasks through minimal gradient steps rather than learning dataset-specific patterns. Our mutation encoding addresses the critical limitation where standard transformers treat mutation positions as unknown tokens, significantly degrading performance. Evaluation across three diverse protein mutation datasets (functional fitness, thermal stability, and solubility) demonstrates significant advantages over traditional fine-tuning. In cross-task evaluation, our meta-learning approach achieves 29% better accuracy for functional fitness with 65% less training time, and 94% better accuracy for solubility with 55% faster training. The framework maintains consistent training efficiency regardless of dataset size, making it particularly valuable for industrial applications and early-stage protein design where experimental data is limited. This work establishes a systematic application of meta-learning to protein mutation analysis and introduces an effective mutation encoding strategy, offering transformative methodology for cross-domain generalization in protein engineering.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è›‹ç™½è´¨çªå˜å±æ€§é¢„æµ‹ä¸­è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›å·®åŠå®éªŒæ•°æ®æœ‰é™çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªåº”ç”¨äºè¯¥é¢†åŸŸçš„Model-Agnostic Meta-Learning (MAML)æ¡†æ¶ã€‚ä¸ºäº†è§£å†³æ ‡å‡†Transformeråœ¨å¤„ç†çªå˜ä½ç½®æ—¶å°†å…¶è§†ä¸ºæœªçŸ¥æ ‡è®°çš„å±€é™æ€§ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§åˆ©ç”¨separator tokenså°†çªå˜ç›´æ¥æ•´åˆåˆ°åºåˆ—ä¸Šä¸‹æ–‡çš„æ–°å‹ç¼–ç ç­–ç•¥ã€‚é€šè¿‡å°†Transformeræ¶æ„ä¸MAMLç›¸ç»“åˆï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé€šè¿‡æå°‘çš„æ¢¯åº¦æ­¥éª¤å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼Œæ˜¾è‘—æå‡äº†åœ¨functional fitnessã€thermal stabilityå’Œsolubilityç­‰ä¸åŒæ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥å…ƒå­¦ä¹ æ–¹æ³•åœ¨functional fitnessä»»åŠ¡ä¸­å‡†ç¡®ç‡æå‡äº†29%ä¸”è®­ç»ƒæ—¶é—´å‡å°‘äº†65%ï¼Œåœ¨solubilityä»»åŠ¡ä¸­å‡†ç¡®ç‡æå‡äº†94%ä¸”è®­ç»ƒé€Ÿåº¦åŠ å¿«äº†55%ã€‚è¯¥æ¡†æ¶åœ¨ä¸åŒè§„æ¨¡çš„æ•°æ®é›†ä¸Šå‡ä¿æŒäº†é«˜æ•ˆçš„è®­ç»ƒä¸€è‡´æ€§ï¼Œä¸ºè›‹ç™½è´¨å·¥ç¨‹ä¸­çš„è·¨é¢†åŸŸæ³›åŒ–æä¾›äº†æœ‰æ•ˆçš„ç³»ç»Ÿæ€§æ–¹æ¡ˆï¼Œå°¤å…¶é€‚ç”¨äºå®éªŒæ•°æ®åŒ®ä¹çš„å·¥ä¸šåº”ç”¨å’Œæ—©æœŸè›‹ç™½è´¨è®¾è®¡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20943v1",
      "published_date": "2025-10-23 19:09:06 UTC",
      "updated_date": "2025-10-23 19:09:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:28.949719+00:00"
    },
    {
      "arxiv_id": "2510.20941v1",
      "title": "Do LLMs Truly Understand When a Precedent Is Overruled?",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ˜¯å¦çœŸæ­£ç†è§£å…ˆä¾‹ä½•æ—¶è¢«æ¨ç¿»ï¼Ÿ",
      "authors": [
        "Li Zhang",
        "Jaromir Savelka",
        "Kevin Ashley"
      ],
      "abstract": "Large language models (LLMs) with extended context windows show promise for complex legal reasoning tasks, yet their ability to understand long legal documents remains insufficiently evaluated. Developing long-context benchmarks that capture realistic, high-stakes tasks remains a significant challenge in the field, as most existing evaluations rely on simplified synthetic tasks that fail to represent the complexity of real-world document understanding. Overruling relationships are foundational to common-law doctrine and commonly found in judicial opinions. They provide a focused and important testbed for long-document legal understanding that closely resembles what legal professionals actually do. We present an assessment of state-of-the-art LLMs on identifying overruling relationships from U.S. Supreme Court cases using a dataset of 236 case pairs. Our evaluation reveals three critical limitations: (1) era sensitivity -- the models show degraded performance on historical cases compared to modern ones, revealing fundamental temporal bias in their training; (2) shallow reasoning -- models rely on shallow logical heuristics rather than deep legal comprehension; and (3) context-dependent reasoning failures -- models produce temporally impossible relationships in complex open-ended tasks despite maintaining basic temporal awareness in simple contexts. Our work contributes a benchmark that addresses the critical gap in realistic long-context evaluation, providing an environment that mirrors the complexity and stakes of actual legal reasoning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯†åˆ«ç¾å›½æœ€é«˜æ³•é™¢æ¡ˆä¾‹ä¸­åˆ¤ä¾‹è¢«æ¨ç¿»(overruled)å…³ç³»çš„èƒ½åŠ›ï¼Œæ—¨åœ¨å¡«è¡¥ç°å®é•¿æ–‡æœ¬æ³•å¾‹æ¨ç†è¯„ä¼°é¢†åŸŸçš„ç©ºç™½ã€‚ç ”ç©¶äººå‘˜é€šè¿‡236å¯¹æ¡ˆä¾‹æ„å»ºäº†ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæ¨¡æ‹Ÿæ³•å¾‹ä¸“ä¸šäººå‘˜åœ¨å¤„ç†å¤æ‚é•¿ç¯‡æ³•å¾‹æ–‡æ¡£æ—¶çš„å®é™…å·¥ä½œæµç¨‹ã€‚è¯„ä¼°ç»“æœæ­ç¤ºäº†æ¨¡å‹çš„ä¸‰å¤§å±€é™æ€§ï¼šé¦–å…ˆæ˜¯æ—¶ä»£æ•æ„Ÿæ€§(era sensitivity)ï¼Œæ¨¡å‹åœ¨å¤„ç†å†å²æ¡ˆä¾‹æ—¶æ€§èƒ½æ˜æ˜¾ä¼˜äºç°ä»£æ¡ˆä¾‹ï¼Œæ˜¾ç¤ºå‡ºè®­ç»ƒæ•°æ®ä¸­çš„æ—¶é—´åå·®ï¼›å…¶æ¬¡æ˜¯æµ…å±‚æ¨ç†(shallow reasoning)ï¼Œæ¨¡å‹å¾€å¾€ä¾èµ–é€»è¾‘å¯å‘å¼è€Œéæ·±å±‚çš„æ³•å¾‹ç†è§£ï¼›æœ€åæ˜¯ä¸Šä¸‹æ–‡ç›¸å…³çš„æ¨ç†å¤±è´¥(context-dependent reasoning failures)ï¼Œåœ¨å¤æ‚ä»»åŠ¡ä¸­ä¼šäº§ç”Ÿæ—¶é—´é€»è¾‘ä¸Šä¸å¯èƒ½çš„å…³ç³»ç»“è®ºã€‚è¯¥é¡¹å·¥ä½œè´¡çŒ®äº†ä¸€ä¸ªåæ˜ çœŸå®æ³•å¾‹åœºæ™¯å¤æ‚æ€§ä¸é«˜é£é™©ç‰¹å¾çš„åŸºå‡†ï¼Œä¸ºè¡¡é‡æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ³•å¾‹æ•™ä¹‰ä»»åŠ¡ä¸Šçš„å®é™…è¡¨ç°æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 2 figures, JURIX 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20941v1",
      "published_date": "2025-10-23 19:07:42 UTC",
      "updated_date": "2025-10-23 19:07:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:30.293021+00:00"
    },
    {
      "arxiv_id": "2510.20933v1",
      "title": "Focal Modulation and Bidirectional Feature Fusion Network for Medical Image Segmentation",
      "title_zh": "ç„¦ç‚¹è°ƒåˆ¶ä¸åŒå‘ç‰¹å¾èåˆåŒ»å­¦å›¾åƒåˆ†å‰²ç½‘ç»œ",
      "authors": [
        "Moin Safdar",
        "Shahzaib Iqbal",
        "Mehwish Mehmood",
        "Mubeen Ghafoor",
        "Tariq M. Khan",
        "Imran Razzak"
      ],
      "abstract": "Medical image segmentation is essential for clinical applications such as disease diagnosis, treatment planning, and disease development monitoring because it provides precise morphological and spatial information on anatomical structures that directly influence treatment decisions. Convolutional neural networks significantly impact image segmentation; however, since convolution operations are local, capturing global contextual information and long-range dependencies is still challenging. Their capacity to precisely segment structures with complicated borders and a variety of sizes is impacted by this restriction. Since transformers use self-attention methods to capture global context and long-range dependencies efficiently, integrating transformer-based architecture with CNNs is a feasible approach to overcoming these challenges. To address these challenges, we propose the Focal Modulation and Bidirectional Feature Fusion Network for Medical Image Segmentation, referred to as FM-BFF-Net in the remainder of this paper. The network combines convolutional and transformer components, employs a focal modulation attention mechanism to refine context awareness, and introduces a bidirectional feature fusion module that enables efficient interaction between encoder and decoder representations across scales. Through this design, FM-BFF-Net enhances boundary precision and robustness to variations in lesion size, shape, and contrast. Extensive experiments on eight publicly available datasets, including polyp detection, skin lesion segmentation, and ultrasound imaging, show that FM-BFF-Net consistently surpasses recent state-of-the-art methods in Jaccard index and Dice coefficient, confirming its effectiveness and adaptability for diverse medical imaging scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FM-BFF-Netï¼Œä¸€ç§ç»“åˆäº†å·ç§¯(CNN)ä¸Transformerç»„ä»¶çš„åŒ»å­¦å›¾åƒåˆ†å‰²ç½‘ç»œï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå·ç§¯æ“ä½œåœ¨æ•è·å…¨å±€ä¸Šä¸‹æ–‡å’Œlong-range dependenciesæ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¨¡å‹é€šè¿‡å¼•å…¥focal modulationæ³¨æ„åŠ›æœºåˆ¶æ¥ç²¾ç‚¼ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼Œå¹¶è®¾è®¡äº†bidirectional feature fusionæ¨¡å—ä»¥å®ç°ç¼–è§£ç å™¨åœ¨ä¸åŒå°ºåº¦é—´çš„æœ‰æ•ˆäº¤äº’ã€‚è¿™ç§æ¶æ„è®¾è®¡æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹å¯¹å¤æ‚è¾¹ç•Œçš„åˆ†å‰²ç²¾åº¦ï¼Œä»¥åŠå¯¹ç—…ç¶å°ºå¯¸ã€å½¢çŠ¶å’Œå¯¹æ¯”åº¦å˜åŒ–çš„é²æ£’æ€§ã€‚åœ¨æ¶‰åŠæ¯è‚‰æ£€æµ‹ã€çš®è‚¤ç—…å˜åˆ†å‰²åŠè¶…å£°æˆåƒç­‰8ä¸ªå…¬å¼€æ•°æ®é›†çš„å¹¿æ³›å®éªŒä¸­ï¼ŒFM-BFF-Netåœ¨JaccardæŒ‡æ•°å’ŒDiceç³»æ•°ä¸Šå‡ä¼˜äºå½“å‰çš„SOTAæ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨ä¸åŒåŒ»å­¦æˆåƒåœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20933v1",
      "published_date": "2025-10-23 18:52:24 UTC",
      "updated_date": "2025-10-23 18:52:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:32.957125+00:00"
    },
    {
      "arxiv_id": "2510.20932v1",
      "title": "An Experimental Study of Trojan Vulnerabilities in UAV Autonomous Landing",
      "title_zh": "æ— äººæœºè‡ªä¸»é™è½ä¸­çš„æœ¨é©¬æ¼æ´å®éªŒç ”ç©¶",
      "authors": [
        "Reza Ahmari",
        "Ahmad Mohammadi",
        "Vahid Hemmati",
        "Mohammed Mynuddin",
        "Mahmoud Nabil Mahmoud",
        "Parham Kebria",
        "Abdollah Homaifar",
        "Mehrdad Saif"
      ],
      "abstract": "This study investigates the vulnerabilities of autonomous navigation and landing systems in Urban Air Mobility (UAM) vehicles. Specifically, it focuses on Trojan attacks that target deep learning models, such as Convolutional Neural Networks (CNNs). Trojan attacks work by embedding covert triggers within a model's training data. These triggers cause specific failures under certain conditions, while the model continues to perform normally in other situations. We assessed the vulnerability of Urban Autonomous Aerial Vehicles (UAAVs) using the DroNet framework. Our experiments showed a significant drop in accuracy, from 96.4% on clean data to 73.3% on data triggered by Trojan attacks. To conduct this study, we collected a custom dataset and trained models to simulate real-world conditions. We also developed an evaluation framework designed to identify Trojan-infected models. This work demonstrates the potential security risks posed by Trojan attacks and lays the groundwork for future research on enhancing the resilience of UAM systems.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åŸå¸‚ç©ºä¸­äº¤é€š(Urban Air Mobility)é£è¡Œå™¨åœ¨è‡ªä¸»å¯¼èˆªä¸ç€é™†ç³»ç»Ÿä¸­çš„è„†å¼±æ€§ï¼Œé‡ç‚¹åˆ†æäº†é’ˆå¯¹å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)ç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç‰¹æ´›ä¼Šæœ¨é©¬æ”»å‡»(Trojan attacks)ã€‚è¯¥æ”»å‡»é€šè¿‡åœ¨è®­ç»ƒæ•°æ®ä¸­åµŒå…¥éšè”½è§¦å‘å™¨ï¼Œä½¿æ¨¡å‹ä»…åœ¨ç‰¹å®šè§¦å‘æ¡ä»¶ä¸‹å‘ç”Ÿæ•…éšœï¼Œè€Œåœ¨å¸¸è§„åœºæ™¯ä¸‹ä¿æŒæ­£å¸¸è¿è¡Œã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨DroNetæ¡†æ¶å¯¹åŸå¸‚è‡ªä¸»æ— äººæœº(UAAVs)è¿›è¡Œäº†å®‰å…¨è¯„ä¼°ï¼Œå¹¶æ„å»ºäº†è‡ªå®šä¹‰æ•°æ®é›†ä»¥æ¨¡æ‹Ÿç°å®è¿è¡Œç¯å¢ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨è§¦å‘å™¨æ¿€æ´»çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„é¢„æµ‹å‡†ç¡®ç‡ä»æ¸…æ´æ•°æ®æ—¶çš„96.4%å¤§å¹…ä¸‹é™è‡³73.3%ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å¼€å‘äº†ä¸€å¥—ä¸“é—¨ç”¨äºæ£€æµ‹å—æœ¨é©¬æ„ŸæŸ“æ¨¡å‹çš„è¯„ä¼°æ¡†æ¶ï¼Œæ­ç¤ºäº†æ­¤ç±»æ”»å‡»å¯¹æ— äººæœºç³»ç»Ÿæ„æˆçš„ä¸¥å³»å®‰å…¨å¨èƒï¼Œå¹¶ä¸ºå¢å¼ºåŸå¸‚ç©ºä¸­äº¤é€šç³»ç»Ÿçš„é˜²å¾¡èƒ½åŠ›æä¾›äº†ç ”ç©¶åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.20932v1",
      "published_date": "2025-10-23 18:47:40 UTC",
      "updated_date": "2025-10-23 18:47:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:37.370900+00:00"
    },
    {
      "arxiv_id": "2510.20930v1",
      "title": "Security Logs to ATT&CK Insights: Leveraging LLMs for High-Level Threat Understanding and Cognitive Trait Inference",
      "title_zh": "ä»å®‰å…¨æ—¥å¿—åˆ° ATT&CK æ´å¯Ÿï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å®ç°é«˜å±‚çº§å¨èƒç†è§£ä¸è®¤çŸ¥ç‰¹å¾æ¨ç†",
      "authors": [
        "Soham Hans",
        "Stacy Marsella",
        "Sophia Hirschmann",
        "Nikolos Gurney"
      ],
      "abstract": "Understanding adversarial behavior in cybersecurity has traditionally relied on high-level intelligence reports and manual interpretation of attack chains. However, real-time defense requires the ability to infer attacker intent and cognitive strategy directly from low-level system telemetry such as intrusion detection system (IDS) logs. In this paper, we propose a novel framework that leverages large language models (LLMs) to analyze Suricata IDS logs and infer attacker actions in terms of MITRE ATT&CK techniques. Our approach is grounded in the hypothesis that attacker behavior reflects underlying cognitive biases such as loss aversion, risk tolerance, or goal persistence that can be extracted and modeled through careful observation of log sequences. This lays the groundwork for future work on behaviorally adaptive cyber defense and cognitive trait inference. We develop a strategy-driven prompt system to segment large amounts of network logs data into distinct behavioral phases in a highly efficient manner, enabling the LLM to associate each phase with likely techniques and underlying cognitive motives. By mapping network-layer events to high-level attacker strategies, our method reveals how behavioral signals such as tool switching, protocol transitions, or pivot patterns correspond to psychologically meaningful decision points. The results demonstrate that LLMs can bridge the semantic gap between packet-level logs and strategic intent, offering a pathway toward cognitive-adaptive cyber defense.\n  Keywords: Cognitive Cybersecurity, Large Language Models (LLMs), Cyberpsychology, Intrusion Detection Systems (IDS), MITRE ATT&CK, Cognitive Biases",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) åˆ†æ Suricata IDS æ—¥å¿—çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨ä»ä½çº§ç³»ç»Ÿé¥æµ‹æ•°æ®ä¸­ç›´æ¥æ¨æ–­æ”»å‡»è€…çš„æ„å›¾å’Œè®¤çŸ¥ç­–ç•¥ã€‚è¯¥æ–¹æ³•åŸºäºæ”»å‡»è€…è¡Œä¸ºåæ˜ å…¶æ½œåœ¨è®¤çŸ¥åå·®ï¼ˆå¦‚ Loss Aversion, Risk Tolerance æˆ– Goal Persistenceï¼‰çš„å‡è®¾ï¼Œé€šè¿‡åˆ†ææ—¥å¿—åºåˆ—æå–å¹¶å»ºæ¨¡è¿™äº›ç‰¹å¾ã€‚ç ”ç©¶å¼€å‘äº†ä¸€å¥—ç­–ç•¥é©±åŠ¨çš„æç¤ºç³»ç»Ÿ (Strategy-driven prompt system)ï¼Œå°†æµ·é‡ç½‘ç»œæ—¥å¿—é«˜æ•ˆåœ°åˆ’åˆ†ä¸ºä¸åŒçš„è¡Œä¸ºé˜¶æ®µï¼Œä½¿ LLM èƒ½å¤Ÿå°†æ¯ä¸ªé˜¶æ®µä¸å…·ä½“çš„ MITRE ATT&CK æŠ€æœ¯åŠæ½œåœ¨è®¤çŸ¥åŠ¨æœºç›¸å…³è”ã€‚é€šè¿‡å°†ç½‘ç»œå±‚äº‹ä»¶æ˜ å°„åˆ°é«˜å±‚æ”»å‡»ç­–ç•¥ï¼Œè¯¥æ–¹æ³•æ­ç¤ºäº†å·¥å…·åˆ‡æ¢ (Tool Switching) å’Œåè®®è½¬æ¢ (Protocol Transitions) ç­‰è¡Œä¸ºä¿¡å·å¦‚ä½•å¯¹åº”äºå…·æœ‰å¿ƒç†å­¦æ„ä¹‰çš„å†³ç­–ç‚¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMs èƒ½å¤Ÿæœ‰æ•ˆå¼¥åˆæ•°æ®åŒ…çº§æ—¥å¿—ä¸æˆ˜ç•¥æ„å›¾ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿï¼Œä¸ºå®ç°è®¤çŸ¥è‡ªé€‚åº”ç½‘ç»œé˜²å¾¡ (Cognitive-adaptive cyber defense) æä¾›äº†é‡è¦è·¯å¾„ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20930v1",
      "published_date": "2025-10-23 18:43:31 UTC",
      "updated_date": "2025-10-23 18:43:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:38.762537+00:00"
    },
    {
      "arxiv_id": "2511.04686v1",
      "title": "Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æœ‰çŠ¶æ€ KV ç¼“å­˜ç®¡ç†ï¼šç©ºé—´ã€æ—¶é—´ã€ç²¾åº¦ä¸ä½ç½®ä¿çœŸåº¦çš„æƒè¡¡",
      "authors": [
        "Pratik Poudel"
      ],
      "abstract": "The Key-Value (KV) cache is integral to efficient autoregressive inference in large language models (LLMs), yet its unbounded growth in stateful multi-turn scenarios presents major challenges. This paper examines the interplay between KV cache management strategies, the architectural context limits of models like meta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of positional encodings. Through empirical analysis using a stateful benchmarking framework, we show that LLM generation quality degrades sharply when the accumulated KV cache approaches or exceeds the model's trained context window (e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory exhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via AttentionTop), can worsen performance if they disrupt positional coherence. Because LLMs rely on consistent positional signals (e.g., RoPE), compacting a cache by removing non-contiguous tokens can scramble these signals and lead to degenerative outputs. We further show that simple strategies preserving contiguous context blocks (e.g., keeping an initial \"gist\") can yield more coherent generations than complex or positionally disruptive ones. We advocate for eviction techniques that respect architectural limits, preserve positional structure, and view \"cache health\" holistically beyond mere size.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤šè½®å¯¹è¯ä¸­Key-Value (KV) cacheçš„ç®¡ç†ç­–ç•¥ï¼Œé‡ç‚¹åˆ†æäº†ç©ºé—´ã€æ—¶é—´ã€å‡†ç¡®æ€§å’ŒPositional Fidelityä¹‹é—´çš„å¹³è¡¡ã€‚ç ”ç©¶å‘ç°ï¼Œå½“ç´¯ç§¯çš„KV cacheæ¥è¿‘æˆ–è¶…è¿‡æ¨¡å‹çš„è®­ç»ƒContext Windowï¼ˆå¦‚Llama 3çš„8192 tokensï¼‰æ—¶ï¼Œç”Ÿæˆè´¨é‡ä¼šæ€¥å‰§ä¸‹é™ï¼Œè¿™ç§å¤±æ•ˆæ¨¡å¼ä¸GPUå†…å­˜è€—å°½æˆªç„¶ä¸åŒã€‚é€šè¿‡å¯¹RoPEç­‰ä½ç½®ç¼–ç çš„åˆ†æï¼Œè®ºæ–‡æŒ‡å‡ºç§»é™¤ä¸è¿ç»­çš„tokenä¼šç ´åä½ç½®ä¿¡å·çš„ç›¸å¹²æ€§å¹¶å¯¼è‡´æ¨¡å‹è¾“å‡ºé€€åŒ–ï¼Œå³ä½¿æ˜¯é«˜ä¿ç•™ç‡çš„AttentionTopç­–ç•¥ä¹Ÿå¯èƒ½å› ç ´åä½ç½®ç»“æ„è€Œå¤±æ•ˆã€‚å®éªŒè¡¨æ˜ï¼Œä¿ç•™è¿ç»­ä¸Šä¸‹æ–‡å—ï¼ˆå¦‚ä¿ç•™åˆå§‹gistï¼‰çš„ç®€å•ç­–ç•¥å¾€å¾€æ¯”å¤æ‚ä½†ç ´åä½ç½®ä¿¡æ¯çš„ç­–ç•¥äº§ç”Ÿæ›´è¿è´¯çš„ç”Ÿæˆç»“æœã€‚å› æ­¤ï¼Œä½œè€…å»ºè®®KV cacheçš„å‰”é™¤æŠ€æœ¯åº”å……åˆ†è€ƒè™‘æ¨¡å‹æ¶æ„é™åˆ¶ï¼Œå¹¶ä»æ•´ä½“ä¸Šç»´æŠ¤Positional Structureçš„å®Œæ•´æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.04686v1",
      "published_date": "2025-10-23 18:22:00 UTC",
      "updated_date": "2025-10-23 18:22:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:43.369849+00:00"
    },
    {
      "arxiv_id": "2510.20916v1",
      "title": "Aircraft Collision Avoidance Systems: Technological Challenges and Solutions on the Path to Regulatory Acceptance",
      "title_zh": "èˆªç©ºå™¨å†²çªé¿è®©ç³»ç»Ÿï¼šè¿ˆå‘ç›‘ç®¡è®¤å¯çš„æŠ€æœ¯æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Sydney M. Katz",
        "Robert J. Moss",
        "Dylan M. Asmar",
        "Wesley A. Olson",
        "James K. Kuchar",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "Aircraft collision avoidance systems is critical to modern aviation. These systems are designed to predict potential collisions between aircraft and recommend appropriate avoidance actions. Creating effective collision avoidance systems requires solutions to a variety of technical challenges related to surveillance, decision making, and validation. These challenges have sparked significant research and development efforts over the past several decades that have resulted in a variety of proposed solutions. This article provides an overview of these challenges and solutions with an emphasis on those that have been put through a rigorous validation process and accepted by regulatory bodies. The challenges posed by the collision avoidance problem are often present in other domains, and aircraft collision avoidance systems can serve as case studies that provide valuable insights for a wide range of safety-critical systems.",
      "tldr_zh": "è¯¥ç ”ç©¶ç»¼è¿°äº†é£æœºé˜²æ’ç³»ç»Ÿï¼ˆAircraft Collision Avoidance Systemsï¼‰åœ¨ç°ä»£èˆªç©ºé¢†åŸŸçš„æ ¸å¿ƒä½œç”¨åŠå…¶å‘å±•å†ç¨‹ã€‚æ–‡ç« è¯¦ç»†æ¢è®¨äº†ç³»ç»Ÿåœ¨ç›‘è§†ï¼ˆsurveillanceï¼‰ã€å†³ç­–ï¼ˆdecision makingï¼‰å’ŒéªŒè¯ï¼ˆvalidationï¼‰æ–¹é¢æ‰€é¢ä¸´çš„æŠ€æœ¯æŒ‘æˆ˜ï¼Œå¹¶ç³»ç»Ÿæ€§åœ°æ¢³ç†äº†è¿‡å»å‡ åå¹´ä¸­æå‡ºçš„å…³é”®è§£å†³æ–¹æ¡ˆã€‚é‡ç‚¹åˆ†æäº†é‚£äº›å·²é€šè¿‡ä¸¥æ ¼éªŒè¯ç¨‹åºå¹¶è·å¾—ç›‘ç®¡æœºæ„ï¼ˆregulatory bodiesï¼‰è®¤å¯çš„æŠ€æœ¯æˆæœï¼Œå±•ç¤ºäº†ä»ç†è®ºç ”ç©¶å‘å®é™…åº”ç”¨è½¬åŒ–çš„è·¯å¾„ã€‚æ­¤å¤–ï¼Œè¿™äº›é˜²æ’ç³»ç»Ÿçš„å¼€å‘ç»éªŒè¿˜å¯ä½œä¸ºé‡è¦çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œä¸ºå…¶ä»–å¹¿æ³›çš„å®‰å…¨å…³é”®ç³»ç»Ÿï¼ˆsafety-critical systemsï¼‰æä¾›å…³äºé£é™©é¢„æµ‹ä¸è§„é¿çš„å®è´µè§è§£ã€‚é€šè¿‡å¯¹è¿™äº›ç»è¿‡è¡Œä¸šæ ‡å‡†æ£€éªŒçš„æ–¹æ³•è¿›è¡Œæ€»ç»“ï¼Œæœ¬æ–‡ä¸ºæå‡èˆªç©ºåŠç›¸å…³é¢†åŸŸçš„ç³»ç»Ÿå®‰å…¨æ€§æä¾›äº†åšå®çš„æŠ€æœ¯å‚è€ƒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "32 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20916v1",
      "published_date": "2025-10-23 18:13:22 UTC",
      "updated_date": "2025-10-23 18:13:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:45.961666+00:00"
    },
    {
      "arxiv_id": "2510.20909v1",
      "title": "Code-enabled language models can outperform reasoning models on diverse tasks",
      "title_zh": "ä»£ç èµ‹èƒ½çš„è¯­è¨€æ¨¡å‹åœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸Šçš„è¡¨ç°å¯ä¼˜äºæ¨ç†æ¨¡å‹",
      "authors": [
        "Cedegao E. Zhang",
        "CÃ©dric Colas",
        "Gabriel Poesia",
        "Joshua B. Tenenbaum",
        "Jacob Andreas"
      ],
      "abstract": "Reasoning models (RMs), language models (LMs) trained with reinforcement learning to produce long-form natural language reasoning, have been remarkably successful, but they still require large amounts of computation and data to train, and can be slow and expensive to run. In this paper, we show that standard instruct LMs can already be elicited to be strong reasoners at a level comparable to or even surpassing their corresponding RMs (e.g., DeepSeek V3 vs R1) without finetuning, across diverse domains from instruction following and creative generation to mathematical reasoning. This is achieved by CodeAdapt, our simple recipe that combines the CodeAct framework, where LMs interleave natural language reasoning with code execution in a multi-step fashion, with few-shot bootstrap in-context learning from as few as five training problems. Analyzing four matched pairs of LMs and RMs, we find that CodeAdapt enables three LMs to outperform the corresponding RMs on average over eight tasks (up to 22.9%) while being 10-81% more token efficient, and delivers superior performance on six tasks when averaged over the four models (up to 35.7%). Furthermore, the code-augmented reasoning traces display rich and varied problem-solving strategies. Our findings support that (1) CodeAdapt-style learning and reasoning may be robust and domain general and (2) code-enabled LMs are cognitively grounded and powerful systems, potentially providing a strong foundation for in-weight reinforcement learning.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯æ˜äº†æ ‡å‡†æŒ‡ä»¤è¯­è¨€æ¨¡å‹(LMs)åœ¨æ— éœ€å¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç‰¹å®šæœºåˆ¶å¯ä»¥å±•ç°å‡ºè¶…è¶Šä¸“ç”¨æ¨ç†æ¨¡å‹(RMs)çš„å¼ºæ‚æ€§èƒ½ã€‚ä½œè€…æå‡ºäº†CodeAdaptï¼Œè¯¥æ–¹æ¡ˆç»“åˆäº†CodeActæ¡†æ¶ï¼ˆä½¿æ¨¡å‹èƒ½å¤Ÿäº¤æ›¿è¿›è¡Œè‡ªç„¶è¯­è¨€æ¨ç†ä¸å¤šæ­¥ä»£ç æ‰§è¡Œï¼‰ä»¥åŠå°‘æ ·æœ¬å¼•å¯¼å¼è¯­å¢ƒå­¦ä¹ (few-shot bootstrap in-context learning)ã€‚å®éªŒåˆ†ææ˜¾ç¤ºï¼ŒCodeAdaptä½¿ä¸‰æ¬¾LMsåœ¨å…«é¡¹ä»»åŠ¡ä¸Šçš„å¹³å‡è¡¨ç°è¶…è¿‡äº†å¯¹åº”çš„RMsï¼ˆä¾‹å¦‚DeepSeek V3å¯¹æ¯”R1ï¼‰ï¼Œæœ€é«˜æ¶¨å¹…è¾¾22.9%ï¼ŒåŒæ—¶Tokenæ•ˆç‡æå‡äº†10-81%ã€‚ç ”ç©¶å‘ç°ä»£ç å¢å¼ºçš„æ¨ç†è½¨è¿¹åŒ…å«å¤šæ ·åŒ–çš„è§£é¢˜ç­–ç•¥ï¼Œè¯æ˜äº†ä»£ç èµ‹èƒ½çš„LMsæ˜¯å…·å¤‡è®¤çŸ¥åŸºç¡€çš„å¼ºå¤§ç³»ç»Ÿã€‚è¿™ä¸€æˆæœè¡¨æ˜CodeAdapté£æ ¼çš„å­¦ä¹ ä¸æ¨ç†å…·æœ‰è·¨é¢†åŸŸçš„ç¨³å¥æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„æƒé‡å†…å¼ºåŒ–å­¦ä¹ (in-weight reinforcement learning)æä¾›äº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20909v1",
      "published_date": "2025-10-23 18:04:03 UTC",
      "updated_date": "2025-10-23 18:04:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:08:58.952329+00:00"
    },
    {
      "arxiv_id": "2510.20819v2",
      "title": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge",
      "title_zh": "è¿ˆå‘åŸºäºå¯¹æ¯”ä¸é¢„æµ‹æ½œæ‰©æ•£æ¡¥çš„é€šç”¨æ¨¡æ€è½¬æ¢",
      "authors": [
        "Nimrod Berman",
        "Omkar Joglekar",
        "Eitan Kosman",
        "Dotan Di Castro",
        "Omri Azencot"
      ],
      "abstract": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Latent Denoising Diffusion Bridge Model (LDDBM)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³ç°æœ‰æ¨¡æ€è½¬æ¢ï¼ˆModality Translationï¼‰æ–¹æ³•å—é™äºç»´åº¦å…±äº«ã€é«˜æ–¯å…ˆéªŒåŠç‰¹å®šæ¶æ„ç­‰é—®é¢˜çš„é€šç”¨æ¡†æ¶ã€‚LDDBM åŸºäºå»å™ªæ‰©æ•£æ¡¥æ¨¡å‹ï¼ˆDenoising Diffusion Bridge Modelsï¼‰çš„æ½œåœ¨å˜é‡æ‰©å±•ï¼Œé€šè¿‡åœ¨å…±äº«çš„æ½œåœ¨ç©ºé—´ï¼ˆlatent spaceï¼‰ä¸­è¿è¡Œï¼Œå®ç°äº†æ— éœ€ç»´åº¦å¯¹é½çš„ä»»æ„æ¨¡æ€é—´è½¬æ¢ã€‚ä¸ºäº†ç¡®ä¿é…å¯¹æ ·æœ¬é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œç ”ç©¶å¼•å…¥äº†å¯¹æ¯”å¯¹é½æŸå¤±ï¼ˆcontrastive alignment lossï¼‰ï¼Œå¹¶é‡‡ç”¨é¢†åŸŸæ— å…³çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„è¿›è¡Œå™ªå£°é¢„æµ‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡é¢„æµ‹æŸå¤±ï¼ˆpredictive lossï¼‰å¼•å¯¼è·¨é¢†åŸŸç¿»è¯‘çš„å‡†ç¡®æ€§ï¼Œå¹¶æ¢ç´¢äº†å¤šç§æå‡è®­ç»ƒç¨³å®šæ€§çš„ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLDDBM åœ¨å¤šè§†å›¾ 3D å½¢çŠ¶ç”Ÿæˆã€å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆimage super-resolutionï¼‰å’Œå¤šè§†å›¾åœºæ™¯åˆæˆç­‰ä»»åŠ¡ä¸­è¡¨ç°å¼ºåŠ²ï¼Œä¸ºé€šç”¨æ¨¡æ€è½¬æ¢å»ºç«‹äº†ä¸€ä¸ªæ–°çš„é«˜æ€§èƒ½åŸºå‡†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a poster at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20819v2",
      "published_date": "2025-10-23 17:59:54 UTC",
      "updated_date": "2025-10-26 09:13:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:09:03.763468+00:00"
    },
    {
      "arxiv_id": "2510.20888v1",
      "title": "Video-As-Prompt: Unified Semantic Control for Video Generation",
      "title_zh": "Video-As-Promptï¼šè§†é¢‘ç”Ÿæˆä¸­çš„ç»Ÿä¸€è¯­ä¹‰æ§åˆ¶",
      "authors": [
        "Yuxuan Bian",
        "Xin Chen",
        "Zenan Li",
        "Tiancheng Zhi",
        "Shen Sang",
        "Linjie Luo",
        "Qiang Xu"
      ],
      "abstract": "Unified, generalizable semantic control in video generation remains a critical open challenge. Existing methods either introduce artifacts by enforcing inappropriate pixel-wise priors from structure-based controls, or rely on non-generalizable, condition-specific finetuning or task-specific architectures. We introduce Video-As-Prompt (VAP), a new paradigm that reframes this problem as in-context generation. VAP leverages a reference video as a direct semantic prompt, guiding a frozen Video Diffusion Transformer (DiT) via a plug-and-play Mixture-of-Transformers (MoT) expert. This architecture prevents catastrophic forgetting and is guided by a temporally biased position embedding that eliminates spurious mapping priors for robust context retrieval. To power this approach and catalyze future research, we built VAP-Data, the largest dataset for semantic-controlled video generation with over 100K paired videos across 100 semantic conditions. As a single unified model, VAP sets a new state-of-the-art for open-source methods, achieving a 38.7% user preference rate that rivals leading condition-specific commercial models. VAP's strong zero-shot generalization and support for various downstream applications mark a significant advance toward general-purpose, controllable video generation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†é¢‘ç”Ÿæˆä¸­ç»Ÿä¸€ä¸”å…·æ³›åŒ–æ€§çš„è¯­ä¹‰æ§åˆ¶ï¼ˆSemantic Controlï¼‰æŒ‘æˆ˜ï¼Œæå‡ºäº† Video-As-Prompt (VAP) èŒƒå¼ï¼Œå°†è¯¥é—®é¢˜é‡æ–°å®šä¹‰ä¸ºä¸Šä¸‹æ–‡ç”Ÿæˆï¼ˆIn-context Generationï¼‰ã€‚VAP åˆ©ç”¨å‚è€ƒè§†é¢‘ä½œä¸ºç›´æ¥çš„è¯­ä¹‰æç¤ºï¼Œé€šè¿‡å³æ’å³ç”¨çš„å¤šä¸“å®¶è½¬æ¢å™¨ï¼ˆMixture-of-Transformers, MoTï¼‰å¼•å¯¼å†»ç»“çš„è§†é¢‘æ‰©æ•£è½¬æ¢å™¨ï¼ˆVideo Diffusion Transformer, DiTï¼‰ï¼Œå¹¶ç»“åˆæ—¶é—´åå·®ä½ç½®åµŒå…¥ï¼ˆTemporally Biased Position Embeddingï¼‰æ¥æ¶ˆé™¤é”™è¯¯çš„æ˜ å°„å…ˆéªŒï¼Œç¡®ä¿é²æ£’çš„ä¸Šä¸‹æ–‡æ£€ç´¢ã€‚ä¸ºæ”¯æŒè¿™ä¸€æ–¹æ³•ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº† VAP-Dataï¼Œè¿™æ˜¯ç›®å‰è§„æ¨¡æœ€å¤§çš„è¯­ä¹‰æ§åˆ¶è§†é¢‘ç”Ÿæˆæ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡10ä¸‡å¯¹æ¶µç›–100ç§è¯­ä¹‰æ¡ä»¶çš„è§†é¢‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½œä¸ºç»Ÿä¸€æ¨¡å‹ï¼ŒVAP åœ¨å¼€æºæ–¹æ³•ä¸­è¾¾åˆ°äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼ˆState-of-the-artï¼‰ï¼Œå…¶ 38.7% çš„ç”¨æˆ·åå¥½ç‡è¶³ä»¥åª²ç¾é¢†å…ˆçš„ç‰¹å®šæ¡ä»¶å•†ä¸šæ¨¡å‹ã€‚VAP å±•ç°äº†å¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ–ï¼ˆZero-shot Generalizationï¼‰èƒ½åŠ›å¹¶æ”¯æŒå¤šç§ä¸‹æ¸¸åº”ç”¨ï¼Œæ˜¾è‘—æ¨è¿›äº†é€šç”¨å¯æ§è§†é¢‘ç”ŸæˆæŠ€æœ¯çš„å‘å±•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Website: https://bytedance.github.io/Video-As-Prompt",
      "pdf_url": "https://arxiv.org/pdf/2510.20888v1",
      "published_date": "2025-10-23 17:59:52 UTC",
      "updated_date": "2025-10-23 17:59:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:09:04.849592+00:00"
    },
    {
      "arxiv_id": "2510.20818v1",
      "title": "VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation",
      "title_zh": "VAMOSï¼šé¢å‘èƒ½åŠ›è°ƒåˆ¶ä¸å¯å¼•å¯¼å¯¼èˆªçš„å±‚çº§åŒ–è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹",
      "authors": [
        "Mateo Guaman Castro",
        "Sidharth Rajagopal",
        "Daniel Gorbatov",
        "Matt Schmittle",
        "Rohan Baijal",
        "Octi Zhang",
        "Rosario Scalise",
        "Sidharth Talia",
        "Emma Romig",
        "Celso de Melo",
        "Byron Boots",
        "Abhishek Gupta"
      ],
      "abstract": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VAMOSï¼Œä¸€ç§å±‚æ¬¡åŒ–çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ (Vision-Language-Action Model)ï¼Œæ—¨åœ¨è§£å†³æœºå™¨äººå¯¼èˆªåœ¨è·¨ç¯å¢ƒæ³›åŒ–æ—¶é¢ä¸´çš„æœºä½“ç‰©ç†çº¦æŸé€‚é…æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹é€šè¿‡è§£è€¦è¯­ä¹‰è§„åˆ’ä¸æœºä½“æ¥åœ° (Embodiment Grounding)ï¼Œå°†åŸºäºå¼€æ”¾ä¸–ç•Œæ•°æ®å­¦ä¹ çš„é€šç”¨è§„åˆ’å™¨ä¸åœ¨æ¨¡æ‹Ÿä¸­å­¦ä¹ ç‰©ç†é™åˆ¶çš„ä¸“ç”¨å¯è¾¾æ€§æ¨¡å‹ (Specialist Affordance Model) ç›¸ç»“åˆã€‚ç³»ç»Ÿé€šè¿‡å›¾åƒç©ºé—´æ¥å£ç”±é«˜çº§è§„åˆ’å™¨æå‡ºå€™é€‰è·¯å¾„ï¼Œå†ç”±å¯è¾¾æ€§æ¨¡å‹è¿›è¡Œè¯„ä¼°å’Œé‡æ’åºï¼Œä»è€Œç¡®ä¿å¯¼èˆªè®¡åˆ’çš„ç‰©ç†å¯è¡Œæ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒVAMOS åœ¨å®¤å†…å¤–å¤æ‚å¯¼èˆªä»»åŠ¡ä¸­çš„æˆåŠŸç‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”å…·å¤‡è‰¯å¥½çš„è‡ªç„¶è¯­è¨€å¯æ“æ§æ€§ã€‚è¯¥æ¨¡å‹æˆåŠŸå®ç°äº†è·¨è¶³å¼å’Œè½®å¼æœºå™¨äººçš„å¤šæœºä½“éƒ¨ç½²ï¼Œå¹¶ä¾é è¯†åˆ«å¹¶æ‹’ç»ä¸å¯è¡Œè·¯å¾„å°†å•æœºå¯¼èˆªæˆåŠŸç‡æå‡äº†3å€ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20818v1",
      "published_date": "2025-10-23 17:59:45 UTC",
      "updated_date": "2025-10-23 17:59:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:09:08.864761+00:00"
    },
    {
      "arxiv_id": "2510.20813v1",
      "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation",
      "title_zh": "GSWorldï¼šé¢å‘æœºå™¨äººæ“ä½œçš„é«˜ä¿çœŸé—­ç¯ä»¿çœŸå¥—ä»¶",
      "authors": [
        "Guangqi Jiang",
        "Haoran Chang",
        "Ri-Zhao Qiu",
        "Yutong Liang",
        "Mazeyu Ji",
        "Jiyue Zhu",
        "Zhao Dong",
        "Xueyan Zou",
        "Xiaolong Wang"
      ],
      "abstract": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics manipulation that combines 3D Gaussian Splatting with physics engines. Our framework advocates \"closing the loop\" of developing manipulation policies with reproducible evaluation of policies learned from real-robot data and sim2real policy training without using real robots. To enable photo-realistic rendering of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian Scene Description File), that infuses Gaussian-on-Mesh representation with robot URDF and other objects. With a streamlined reconstruction pipeline, we curate a database of GSDF that contains 3 robot embodiments for single-arm and bimanual manipulation, as well as more than 40 objects. Combining GSDF with physics engines, we demonstrate several immediate interesting applications: (1) learning zero-shot sim2real pixel-to-action manipulation policy with photo-realistic rendering, (2) automated high-quality DAgger data collection for adapting policies to deployment environments, (3) reproducible benchmarking of real-robot manipulation policies in simulation, (4) simulation data collection by virtual teleoperation, and (5) zero-shot sim2real visual reinforcement learning. Website: https://3dgsworld.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GSWorldï¼Œä¸€ä¸ªä¸“ä¸ºæœºå™¨äººæ“çºµè®¾è®¡çš„é«˜ä¿çœŸã€ç…§ç‰‡çº§çœŸå®æ„Ÿæ¨¡æ‹Ÿå™¨ï¼Œå®ƒå°† 3D Gaussian Splatting ä¸ç‰©ç†å¼•æ“æœ‰æœºç»“åˆã€‚ç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†ä¸€ç§å…¨æ–°çš„èµ„äº§æ ¼å¼ GSDF (Gaussian Scene Description File)ï¼Œé€šè¿‡å°† Gaussian-on-Mesh è¡¨å¾ä¸æœºå™¨äºº URDF åŠå…¶ä»–ç‰©ä½“èåˆï¼Œå®ç°äº†å¤æ‚åœºæ™¯çš„ç²¾ç»†æ¸²æŸ“ã€‚ä¾æ‰˜ç²¾ç®€çš„é‡å»ºæµç¨‹ï¼Œè¯¥æ¡†æ¶æ„å»ºäº†ä¸€ä¸ªåŒ…å« 3 ç§æœºå™¨äººå½¢æ€å’Œ 40 å¤šä¸ªç‰©ä½“çš„ GSDF æ•°æ®åº“ï¼Œæ”¯æŒå•è‡‚åŠåŒè‡‚æ“çºµä»»åŠ¡ã€‚GSWorld çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºâ€œé—­ç¯â€å¼€å‘æ¨¡å¼ï¼Œèƒ½å¤Ÿå®ç° zero-shot sim2real çš„åƒç´ åˆ°åŠ¨ä½œç­–ç•¥å­¦ä¹ ã€è‡ªåŠ¨åŒ–çš„ DAgger æ•°æ®é‡‡é›†ä»¥åŠæœºå™¨äººç­–ç•¥çš„å¯é‡å¤æ¨¡æ‹ŸåŸºå‡†æµ‹è¯•ã€‚è¯¥ç³»ç»Ÿè¿˜æ”¯æŒé€šè¿‡è™šæ‹Ÿé¥æ“ä½œè¿›è¡Œæ•°æ®é‡‡é›†å’Œ zero-shot è§†è§‰å¼ºåŒ–å­¦ä¹ ï¼Œä¸ºåœ¨æ— éœ€çœŸå®æœºå™¨äººçš„æƒ…å†µä¸‹å¼€å‘å’Œè¯„ä¼°æ“çºµç­–ç•¥æä¾›äº†å¼ºå¤§çš„ä»¿çœŸç¯å¢ƒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20813v1",
      "published_date": "2025-10-23 17:59:26 UTC",
      "updated_date": "2025-10-23 17:59:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:09:10.943856+00:00"
    },
    {
      "arxiv_id": "2510.20812v3",
      "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation",
      "title_zh": "å°è‰ç¨¿ï¼Œå¤§è£å†³ï¼šåŸºäºæ¨æµ‹æœºåˆ¶çš„ä¿¡æ¯å¯†é›†å‹è§†è§‰æ¨ç†",
      "authors": [
        "Yuhan Liu",
        "Lianhui Qin",
        "Shengjie Wang"
      ],
      "abstract": "Large Vision-Language Models (VLMs) have achieved remarkable progress in multimodal understanding, yet they struggle when reasoning over information-intensive images that densely interleave textual annotations with fine-grained graphical elements. The main challenges lie in precisely localizing critical cues in dense layouts and multi-hop reasoning to integrate dispersed evidence. We propose Speculative Verdict (SV), a training-free framework inspired by speculative decoding that combines multiple lightweight draft experts with a large verdict model. In the draft stage, small VLMs act as draft experts to generate reasoning paths that provide diverse localization candidates; in the verdict stage, a strong VLM synthesizes these paths to produce the final answer, minimizing computational cost while recovering correct answers. To further improve efficiency and accuracy, SV introduces a consensus expert selection mechanism that forwards only high-agreement reasoning paths to the verdict. Empirically, SV achieves consistent gains on challenging information-intensive and high-resolution visual question answering benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K. By synthesizing correct insights from multiple partially accurate reasoning paths, SV achieves both error correction and cost-efficiency compared to large proprietary models or training pipelines. Code is available at https://github.com/Tinaliu0123/speculative-verdict.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Speculative Verdict (SV)ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨å¤„ç†åŒ…å«å¯†é›†æ–‡æœ¬æ ‡æ³¨ä¸ç»†ç²’åº¦å›¾å½¢å…ƒç´ çš„ä¿¡æ¯å¯†é›†å‹å›¾åƒæ—¶é¢ä¸´çš„å®šä½ä¸å¤šè·³æ¨ç† (multi-hop reasoning) æŒ‘æˆ˜ã€‚åœ¨è‰ç¨¿é˜¶æ®µ (draft stage)ï¼Œå¤šä¸ªè½»é‡çº§ä¸“å®¶æ¨¡å‹ç”Ÿæˆå¤šæ ·åŒ–çš„æ¨ç†è·¯å¾„ä»¥æä¾›å®šä½å€™é€‰ï¼›åœ¨åˆ¤å†³é˜¶æ®µ (verdict stage)ï¼Œç”±ä¸€ä¸ªå¼ºåŠ› VLM ç»¼åˆè¿™äº›è·¯å¾„ä»¥äº§ç”Ÿæœ€ç»ˆç­”æ¡ˆã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡æ•ˆç‡ï¼ŒSV å¼•å…¥äº†å…±è¯†ä¸“å®¶é€‰æ‹©æœºåˆ¶ (consensus expert selection mechanism)ï¼Œä»…å°†é«˜ä¸€è‡´æ€§çš„æ¨ç†è·¯å¾„è½¬å‘ç»™åˆ¤å†³æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSV åœ¨ InfographicVQAã€ChartMuseumã€ChartQAPro å’Œ HR-Bench 4K ç­‰æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸Šå‡å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚é€šè¿‡æ•´åˆå¤šä¸ªéƒ¨åˆ†å‡†ç¡®çš„æ¨ç†è·¯å¾„ï¼ŒSV åœ¨å®ç°æœ‰æ•ˆé”™è¯¯çº æ­£çš„åŒæ—¶ä¿è¯äº†æé«˜çš„æˆæœ¬æ•ˆç›Šï¼Œä¸ºå¤æ‚å¤šæ¨¡æ€ç†è§£æä¾›äº†ä¼˜äºä¼ ç»Ÿè®­ç»ƒæµç¨‹çš„é«˜æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20812v3",
      "published_date": "2025-10-23 17:59:21 UTC",
      "updated_date": "2025-12-09 15:09:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:09:16.857366+00:00"
    },
    {
      "arxiv_id": "2510.20887v1",
      "title": "Preventing Shortcuts in Adapter Training via Providing the Shortcuts",
      "title_zh": "é€šè¿‡æä¾›æ·å¾„è§„é¿é€‚é…å™¨è®­ç»ƒä¸­çš„æ·å¾„å­¦ä¹ ",
      "authors": [
        "Anujraaj Argo Goyal",
        "Guocheng Gordon Qian",
        "Huseyin Coskun",
        "Aarush Gupta",
        "Himmy Tam",
        "Daniil Ostashev",
        "Ju Hu",
        "Dhritiman Sagar",
        "Sergey Tulyakov",
        "Kfir Aberman",
        "Kuan-Chieh Jackson Wang"
      ],
      "abstract": "Adapter-based training has emerged as a key mechanism for extending the capabilities of powerful foundation image generators, enabling personalized and stylized text-to-image synthesis. These adapters are typically trained to capture a specific target attribute, such as subject identity, using single-image reconstruction objectives. However, because the input image inevitably contains a mixture of visual factors, adapters are prone to entangle the target attribute with incidental ones, such as pose, expression, and lighting. This spurious correlation problem limits generalization and obstructs the model's ability to adhere to the input text prompt. In this work, we uncover a simple yet effective solution: provide the very shortcuts we wish to eliminate during adapter training. In Shortcut-Rerouted Adapter Training, confounding factors are routed through auxiliary modules, such as ControlNet or LoRA, eliminating the incentive for the adapter to internalize them. The auxiliary modules are then removed during inference. When applied to tasks like facial and full-body identity injection, our approach improves generation quality, diversity, and prompt adherence. These results point to a general design principle in the era of large models: when seeking disentangled representations, the most effective path may be to establish shortcuts for what should NOT be learned.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºé€‚é…å™¨(Adapter)çš„åŸºç¡€å›¾åƒç”Ÿæˆå™¨åœ¨è®­ç»ƒä¸­å®¹æ˜“äº§ç”Ÿçš„è™šå‡ç›¸å…³æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºShortcut-Rerouted Adapter Trainingçš„åˆ›æ–°æ–¹æ³•ã€‚ç”±äºè¾“å…¥å›¾åƒå¸¸åŒ…å«å§¿æ€ã€è¡¨æƒ…å’Œå…‰ç…§ç­‰æ··åˆå› ç´ ï¼Œé€‚é…å™¨å¾€å¾€ä¼šé”™è¯¯åœ°å°†ç›®æ ‡å±æ€§ä¸è¿™äº›å¶ç„¶å› ç´ çº ç¼ åœ¨ä¸€èµ·ï¼Œä»è€Œé™åˆ¶äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå¯¹Promptçš„éµå¾ªåº¦ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†æ··æ·†å› å­å¼•å¯¼è‡³ControlNetæˆ–LoRAç­‰è¾…åŠ©æ¨¡å—ä¸­ï¼Œé€šè¿‡ä¸»åŠ¨æä¾›è¿™äº›â€œæ·å¾„â€ä¿¡æ¯ï¼Œä½¿é€‚é…å™¨æ— éœ€å†…åŒ–æ— å…³å±æ€§ã€‚åœ¨æ¨ç†é˜¶æ®µç§»é™¤è¾…åŠ©æ¨¡å—åï¼Œè¯¥æŠ€æœ¯åœ¨äººè„¸å’Œå…¨èº«èº«ä»½æ³¨å…¥(Identity Injection)ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒç”Ÿæˆçš„è´¨é‡ã€å¤šæ ·æ€§ä»¥åŠæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œé€šè¿‡ä¸ºä¸åº”å­¦ä¹ çš„å†…å®¹å»ºç«‹æ˜¾å¼æ·å¾„ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°å®ç°ç‰¹å¾çš„è§£è€¦è¡¨ç¤ºï¼Œä¸ºå¤§å‹æ¨¡å‹çš„ä¼˜åŒ–æä¾›äº†æ–°çš„è®¾è®¡åŸåˆ™ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2025, webpage: https://snap-research.github.io/shortcut-rerouting/",
      "pdf_url": "https://arxiv.org/pdf/2510.20887v1",
      "published_date": "2025-10-23 17:59:09 UTC",
      "updated_date": "2025-10-23 17:59:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:10:12.984920+00:00"
    },
    {
      "arxiv_id": "2510.20810v1",
      "title": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?",
      "title_zh": "è®º LLM ç”Ÿæˆæ–‡æœ¬çš„å¯æ£€æµ‹æ€§ï¼šç©¶ç«Ÿä½•ä¸º LLM ç”Ÿæˆæ–‡æœ¬ï¼Ÿ",
      "authors": [
        "Mingmeng Geng",
        "Thierry Poibeau"
      ],
      "abstract": "With the widespread use of large language models (LLMs), many researchers have turned their attention to detecting text generated by them. However, there is no consistent or precise definition of their target, namely \"LLM-generated text\". Differences in usage scenarios and the diversity of LLMs further increase the difficulty of detection. What is commonly regarded as the detecting target usually represents only a subset of the text that LLMs can potentially produce. Human edits to LLM outputs, together with the subtle influences that LLMs exert on their users, are blurring the line between LLM-generated and human-written text. Existing benchmarks and evaluation approaches do not adequately address the various conditions in real-world detector applications. Hence, the numerical results of detectors are often misunderstood, and their significance is diminishing. Therefore, detectors remain useful under specific conditions, but their results should be interpreted only as references rather than decisive indicators.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆæ–‡æœ¬çš„å¯æ£€æµ‹æ€§ï¼ŒæŒ‡å‡ºç›®å‰å­¦æœ¯ç•Œå¯¹äº LLM-generated text ç¼ºä¹ç»Ÿä¸€ä¸”ç²¾ç¡®çš„å®šä¹‰ã€‚ç”±äºä½¿ç”¨åœºæ™¯çš„å·®å¼‚å’Œæ¨¡å‹çš„å¤šæ ·æ€§ï¼Œç°æœ‰çš„æ£€æµ‹ç›®æ ‡é€šå¸¸ä»…ä»£è¡¨äº† LLMs æ½œåœ¨äº§å‡ºæ–‡æœ¬çš„ä¸€ä¸ªå­é›†ã€‚æ­¤å¤–ï¼Œäººç±»å¯¹æ¨¡å‹è¾“å‡ºçš„ç¼–è¾‘ä»¥åŠæ¨¡å‹å¯¹ç”¨æˆ·å†™ä½œé£æ ¼çš„å¾®å¦™å½±å“ï¼Œè¿›ä¸€æ­¥æ¨¡ç³Šäº† LLM-generated ä¸ human-written æ–‡æœ¬ä¹‹é—´çš„ç•Œé™ã€‚ç ”ç©¶å‘ç°ç°æœ‰çš„ benchmarks å’Œè¯„ä¼°æ–¹æ³•æœªèƒ½å……åˆ†è¦†ç›–ç°å®ä¸–ç•Œä¸­çš„å¤æ‚åº”ç”¨æ¡ä»¶ï¼Œå¯¼è‡´æ£€æµ‹å™¨çš„é‡åŒ–ç»“æœå®¹æ˜“äº§ç”Ÿè¯¯å¯¼ã€‚æœ€ç»ˆï¼Œè®ºæ–‡å»ºè®®æ£€æµ‹å™¨åœ¨ç‰¹å®šç¯å¢ƒä¸‹ä»å…·å‚è€ƒä»·å€¼ï¼Œä½†å…¶ç»“æœåº”è¢«è§†ä¸ºè¾…åŠ©å‚è€ƒè€Œéåˆ¤å®šæ–‡æœ¬æ¥æºçš„å†³å®šæ€§æŒ‡æ ‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20810v1",
      "published_date": "2025-10-23 17:59:06 UTC",
      "updated_date": "2025-10-23 17:59:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:09:18.755640+00:00"
    },
    {
      "arxiv_id": "2510.20809v1",
      "title": "Real Deep Research for AI, Robotics and Beyond",
      "title_zh": "Real Deep Researchï¼šé¢å‘äººå·¥æ™ºèƒ½ã€æœºå™¨äººåŠç›¸å…³é¢†åŸŸçš„æ·±åº¦ç§‘ç ”æ¢ç´¢",
      "authors": [
        "Xueyan Zou",
        "Jianglong Ye",
        "Hao Zhang",
        "Xiaoyu Xiang",
        "Mingyu Ding",
        "Zhaojing Yang",
        "Yong Jae Lee",
        "Zhuowen Tu",
        "Sifei Liu",
        "Xiaolong Wang"
      ],
      "abstract": "With the rapid growth of research in AI and robotics now producing over 10,000 papers annually it has become increasingly difficult for researchers to stay up to date. Fast evolving trends, the rise of interdisciplinary work, and the need to explore domains beyond one's expertise all contribute to this challenge. To address these issues, we propose a generalizable pipeline capable of systematically analyzing any research area: identifying emerging trends, uncovering cross domain opportunities, and offering concrete starting points for new inquiry. In this work, we present Real Deep Research (RDR) a comprehensive framework applied to the domains of AI and robotics, with a particular focus on foundation models and robotics advancements. We also briefly extend our analysis to other areas of science. The main paper details the construction of the RDR pipeline, while the appendix provides extensive results across each analyzed topic. We hope this work sheds light for researchers working in the field of AI and beyond.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½(AI)å’Œæœºå™¨äºº(Robotics)é¢†åŸŸæ¯å¹´è®ºæ–‡äº§å‡ºå·¨å¤§å¯¼è‡´ç§‘ç ”äººå‘˜éš¾ä»¥è¿½è¸ªå‰æ²¿åŠ¨æ€çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºReal Deep Research (RDR)çš„é€šç”¨åŒ–åˆ†æç®¡çº¿(pipeline)ã€‚è¯¥æ¡†æ¶æ—¨åœ¨ç³»ç»Ÿåœ°åˆ†æå„ç ”ç©¶é¢†åŸŸï¼Œé€šè¿‡è¯†åˆ«æ–°å…´è¶‹åŠ¿(emerging trends)å’ŒæŒ–æ˜è·¨é¢†åŸŸæœºä¼š(cross domain opportunities)ï¼Œä¸ºæ–°è¯¾é¢˜çš„ç ”ç©¶æä¾›å…·ä½“çš„åˆ‡å…¥ç‚¹ã€‚æ–‡ä¸­é‡ç‚¹å±•ç¤ºäº†RDRåœ¨åŸºç¡€æ¨¡å‹(foundation models)å’Œæœºå™¨äººæŠ€æœ¯è¿›å±•æ–¹é¢çš„åº”ç”¨ï¼Œå¹¶å°†å…¶åˆ†æèƒ½åŠ›æ‰©å±•åˆ°äº†æ›´å¹¿æ³›çš„ç§‘å­¦é¢†åŸŸã€‚è®ºæ–‡ä¸ä»…è¯¦ç»†æè¿°äº†RDRç®¡çº¿çš„æ„å»ºè¿‡ç¨‹ï¼Œè¿˜åœ¨é™„å½•ä¸­æä¾›äº†é’ˆå¯¹å„åˆ†æä¸»é¢˜çš„è¯¦å°½ç»“æœã€‚è¯¥ç ”ç©¶ä¸ºç§‘ç ”äººå‘˜åœ¨å¿«é€Ÿæ¼”è¿›ä¸”é«˜åº¦è·¨å­¦ç§‘çš„ç¯å¢ƒä¸‹é«˜æ•ˆè·å–æ´å¯ŸåŠ›å¹¶å¼€å¯æ–°çš„ç ”ç©¶æ–¹å‘æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "website: https://realdeepresearch.github.io",
      "pdf_url": "https://arxiv.org/pdf/2510.20809v1",
      "published_date": "2025-10-23 17:59:05 UTC",
      "updated_date": "2025-10-23 17:59:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:10:23.079814+00:00"
    },
    {
      "arxiv_id": "2510.20808v1",
      "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices",
      "title_zh": "æœºå™¨äººå­¦ä¸­çš„ç°å®é¸¿æ²Ÿï¼šæŒ‘æˆ˜ã€è§£å†³æ–¹æ¡ˆä¸æœ€ä½³å®è·µ",
      "authors": [
        "Elie Aljalbout",
        "Jiaxu Xing",
        "Angel Romero",
        "Iretiayo Akinola",
        "Caelan Reed Garrett",
        "Eric Heiden",
        "Abhishek Gupta",
        "Tucker Hermans",
        "Yashraj Narang",
        "Dieter Fox",
        "Davide Scaramuzza",
        "Fabio Ramos"
      ],
      "abstract": "Machine learning has facilitated significant advancements across various robotics domains, including navigation, locomotion, and manipulation. Many such achievements have been driven by the extensive use of simulation as a critical tool for training and testing robotic systems prior to their deployment in real-world environments. However, simulations consist of abstractions and approximations that inevitably introduce discrepancies between simulated and real environments, known as the reality gap. These discrepancies significantly hinder the successful transfer of systems from simulation to the real world. Closing this gap remains one of the most pressing challenges in robotics. Recent advances in sim-to-real transfer have demonstrated promising results across various platforms, including locomotion, navigation, and manipulation. By leveraging techniques such as domain randomization, real-to-sim transfer, state and action abstractions, and sim-real co-training, many works have overcome the reality gap. However, challenges persist, and a deeper understanding of the reality gap's root causes and solutions is necessary. In this survey, we present a comprehensive overview of the sim-to-real landscape, highlighting the causes, solutions, and evaluation metrics for the reality gap and sim-to-real transfer.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨äººé¢†åŸŸä¸­ç”±äºä»¿çœŸç¯å¢ƒçš„æŠ½è±¡ä¸è¿‘ä¼¼æ‰€å¯¼è‡´çš„ç°å®å·®è·(Reality Gap)é—®é¢˜è¿›è¡Œäº†å…¨é¢ç»¼è¿°ã€‚æ–‡ç« æŒ‡å‡ºè¿™ç§å·®è·æ˜¯é˜»ç¢æœºå™¨å­¦ä¹ æ¨¡å‹ä»æ¨¡æ‹ŸæˆåŠŸè¿ç§»è‡³ç°å®ä¸–ç•Œçš„å…³é”®æŒ‘æˆ˜ï¼Œå°¤å…¶åœ¨å¯¼èˆªã€è¿åŠ¨åŠæ“ä½œä»»åŠ¡ä¸­è¡¨ç°æ˜¾è‘—ã€‚è®ºæ–‡æ·±å…¥æ¢è®¨äº†æ¨¡æ‹Ÿå‘ç°å®è¿ç§»(Sim-to-Real Transfer)çš„æœ€æ–°è¿›å±•ï¼Œè¯¦ç»†åˆ†æäº†é¢†åŸŸéšæœºåŒ–(Domain Randomization)ã€çœŸå®åˆ°æ¨¡æ‹Ÿè½¬æ¢(Real-to-Sim Transfer)ã€çŠ¶æ€ä¸åŠ¨ä½œæŠ½è±¡(State and Action Abstractions)ä»¥åŠæ¨¡æ‹Ÿ-ç°å®ååŒè®­ç»ƒ(Sim-Real Co-training)ç­‰ä¸»æµæŠ€æœ¯æ‰‹æ®µã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ç³»ç»Ÿæ€»ç»“äº†å¯¼è‡´ç°å®å·®è·çš„æ ¹æœ¬åŸå› åŠç›¸åº”çš„è¯„ä¼°æŒ‡æ ‡ã€‚è¯¥ç»¼è¿°ä¸ºç ”ç©¶äººå‘˜æä¾›äº†å¤„ç†ç°å®å·®è·é—®é¢˜çš„ç»¼åˆæ¡†æ¶å’Œæœ€ä½³å®è·µæŒ‡å¯¼ï¼Œæ—¨åœ¨æ¨åŠ¨æœºå™¨äººæŠ€æœ¯åœ¨çœŸå®ç¯å¢ƒä¸­çš„æœ‰æ•ˆè½åœ°ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for Publication as part of the Annual Review of Control, Robotics, and Autonomous Systems 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.20808v1",
      "published_date": "2025-10-23 17:58:53 UTC",
      "updated_date": "2025-10-23 17:58:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:11:32.386283+00:00"
    },
    {
      "arxiv_id": "2510.20800v1",
      "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples",
      "title_zh": "ç²¾ç®€è‡´èƒœï¼šåŸºäº100ä¸ªæ ·æœ¬ä¸å•æ­¥æ¢¯åº¦çš„LLMé«˜æ•ˆé€‚é…",
      "authors": [
        "Shiva Sreeram",
        "Alaa Maalouf",
        "Pratyusha Sharma",
        "Daniela Rus"
      ],
      "abstract": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank reduction (LASER) which demonstrated that pruning high-order components of carefully chosen LLM's weight matrices can boost downstream accuracy -- without any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each requiring full-dataset forward passes) makes it impractical for rapid deployment. We demonstrate that this overhead can be removed and find that: (i) Only a small, carefully chosen subset of matrices needs to be inspected -- eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's singular values pinpoints which matrices merit reduction, (iii) Increasing the factorization search space by allowing matrices rows to cluster around multiple subspaces and then decomposing each cluster separately further reduces overfitting on the original training data and further lifts accuracy by up to 24.6 percentage points, and finally, (iv) we discover that evaluating on just 100 samples rather than the full training data -- both for computing the indicative gradients and for measuring the final accuracy -- suffices to further reduce the search time; we explain that as adaptation to downstream tasks is dominated by prompting style, not dataset size. As a result, we show that combining these findings yields a fast and robust adaptation algorithm for downstream tasks. Overall, with a single gradient step on 100 examples and a quick scan of the top candidate layers and factorization techniques, we can adapt LLMs to new datasets -- entirely without fine-tuning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Layer-SElective-Rank reduction (LASER) æ–¹æ³•æœç´¢æˆæœ¬è¿‡é«˜çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä»…éœ€å•æ¬¡æ¢¯åº¦æ­¥éª¤å’Œæå°æ ·æœ¬é‡çš„ LLM é€‚é…ç®—æ³•ã€‚ä½œè€…å‘ç°é€šè¿‡åˆ†æçŸ©é˜µå¥‡å¼‚å€¼ (singular values) çš„æ¢¯åº¦å¯ä»¥å¿«é€Ÿå®šä½å…³é”®å±‚ï¼Œä»è€Œæ¶ˆé™¤äº† LASER åŸæœ‰çš„é€å±‚æœç´¢å¼€é”€ã€‚è¯¥æ–¹æ³•è¿›ä¸€æ­¥å¼•å…¥å¤šå­ç©ºé—´èšç±»åˆ†è§£æŠ€æœ¯ï¼Œåœ¨æœ‰æ•ˆç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜çš„åŒæ—¶ï¼Œå°†ä¸‹æ¸¸ä»»åŠ¡çš„å‡†ç¡®ç‡æå‡äº†æœ€é«˜ 24.6 ä¸ªç™¾åˆ†ç‚¹ã€‚ç ”ç©¶è¡¨æ˜ï¼Œåˆ©ç”¨ä»… 100 ä¸ªæ ·æœ¬è®¡ç®—æ¢¯åº¦å¹¶è¿›è¡Œè¯„ä¼°å³å¯å®ç°é«˜æ•ˆé€‚é…ï¼Œå› ä¸ºä»»åŠ¡è¡¨ç°æ›´å¤šå–å†³äºæç¤ºé£æ ¼ (prompting style) è€Œéæ•°æ®è§„æ¨¡ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶è¯æ˜äº†åœ¨æ— éœ€å¾®è°ƒ (fine-tuning) çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å¿«é€Ÿæ‰«æå€™é€‰å±‚å’Œåˆ†è§£æŠ€æœ¯ï¼Œå³å¯å®ç°å¤§è¯­è¨€æ¨¡å‹å¯¹æ–°æ•°æ®é›†çš„é«˜æ•ˆã€ç¨³å¥é€‚é…ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20800v1",
      "published_date": "2025-10-23 17:58:01 UTC",
      "updated_date": "2025-10-23 17:58:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:11:46.896737+00:00"
    },
    {
      "arxiv_id": "2510.20886v1",
      "title": "Shoot First, Ask Questions Later? Building Rational Agents that Explore and Act Like People",
      "title_zh": "å…ˆè¡ŒåŠ¨ï¼Œåæé—®ï¼Ÿæ„å»ºå…·å¤‡ç±»äººæ¢ç´¢ä¸è¡Œä¸ºèƒ½åŠ›çš„ç†æ€§æ™ºèƒ½ä½“",
      "authors": [
        "Gabriel Grand",
        "Valerio Pepe",
        "Jacob Andreas",
        "Joshua B. Tenenbaum"
      ],
      "abstract": "Many high-stakes applications of AI require forming data-driven hypotheses and making targeted guesses; e.g., in scientific and diagnostic settings. Given limited resources, to what extent do agents based on language models (LMs) act rationally? We develop methods to benchmark and enhance agentic information-seeking, drawing on insights from human behavior. First, we introduce a strategic decision-oriented dialogue task called Collaborative Battleship, in which a partially-informed Captain must balance exploration (asking questions) and action (taking shots), while a fully-informed Spotter must provide accurate answers under an information bottleneck. Compared to human players (N=42), we find that LM agents struggle to ground answers in context, generate informative questions, and select high-value actions. Next, to address these gaps, we develop novel Monte Carlo inference strategies for LMs based on principles from Bayesian Experimental Design (BED). For Spotter agents, our approach boosts accuracy by up to 14.7% absolute over LM-only baselines; for Captain agents, it raises expected information gain (EIG) by up to 0.227 bits (94.2% of the achievable noise ceiling). Combined, these components yield sharper targeting (+0.303-0.374 F1), and enable weaker LMs, such as Llama-4-Scout, to outperform both humans (8% -> 82% win rate) and frontier models (0% -> 67% win rate vs. GPT-5) at ~1% of GPT-5's cost. We replicate these findings on Guess Who? where our methods significantly boost accuracy (+28.3-42.4 p.p.), demonstrating their general applicability for building rational information-seeking agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºè¯­è¨€æ¨¡å‹ (LMs) çš„æ™ºèƒ½ä½“åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹æ˜¯å¦èƒ½å±•ç°ç†æ€§è¡Œä¸ºï¼Œå¹¶å¼•å…¥äº†åä¸º Collaborative Battleship çš„æˆ˜ç•¥å†³ç­–å¯¹è¯ä»»åŠ¡ã€‚å®éªŒå‘ç°ï¼Œä¼ ç»Ÿè¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“åœ¨æƒ…å¢ƒç†è§£ã€æé—®æ•ˆç‡åŠé«˜ä»·å€¼è¡ŒåŠ¨é€‰æ‹©ä¸Šå‡è½åäºäººç±»è¡¨ç°ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…å¼€å‘äº†åŸºäºè´å¶æ–¯å®éªŒè®¾è®¡ (Bayesian Experimental Design, BED) åŸç†çš„è’™ç‰¹å¡æ´›æ¨ç†ç­–ç•¥ (Monte Carlo inference strategies)ï¼Œä»¥æ˜¾è‘—å¢å¼ºæ™ºèƒ½ä½“çš„ä¿¡æ¯å¯»æ±‚èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•å¤§å¹…æå‡äº†æ™ºèƒ½ä½“çš„å‡†ç¡®ç‡å’ŒæœŸæœ›ä¿¡æ¯å¢ç›Š (Expected Information Gain, EIG)ï¼Œä½¿ Llama-4-Scout ç­‰å¼±æ¨¡å‹åœ¨æ€§èƒ½ä¸Šèƒ½ä»¥æä½æˆæœ¬è¶…è¶Šäººç±»å’Œ GPT-5ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ Guess Who? ä»»åŠ¡ä¸­çš„æˆåŠŸåº”ç”¨è¿›ä¸€æ­¥éªŒè¯äº†å…¶åœ¨æ„å»ºç†æ€§ä¿¡æ¯å¯»æ±‚æ™ºèƒ½ä½“æ–¹é¢çš„æ™®é€‚æ€§ä¸æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20886v1",
      "published_date": "2025-10-23 17:57:28 UTC",
      "updated_date": "2025-10-23 17:57:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:11:48.269571+00:00"
    },
    {
      "arxiv_id": "2510.20797v1",
      "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training",
      "title_zh": "ç®€æ˜“ä¸Šä¸‹æ–‡å‹ç¼©ï¼šå‡å€¼æ± åŒ–ä¸å¤šæ¯”ä¾‹è®­ç»ƒ",
      "authors": [
        "Yair Feldman",
        "Yoav Artzi"
      ],
      "abstract": "A common strategy to reduce the computational costs of using long contexts in retrieval-augmented generation (RAG) with large language models (LLMs) is soft context compression, where the input sequence is transformed into a shorter continuous representation. We develop a lightweight and simple mean-pooling approach that consistently outperforms the widely used compression-tokens architecture, and study training the same compressor to output multiple compression ratios. We conduct extensive experiments across in-domain and out-of-domain QA datasets, as well as across model families, scales, and compression ratios. Overall, our simple mean-pooling approach achieves the strongest performance, with a relatively small drop when training for multiple compression ratios. More broadly though, across architectures and training regimes the trade-offs are more nuanced, illustrating the complex landscape of compression methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ä¸­ï¼Œé€šè¿‡è½¯ä¸Šä¸‹æ–‡å‹ç¼©(soft context compression)æŠ€æœ¯é™ä½é•¿ä¸Šä¸‹æ–‡è®¡ç®—å¼€é”€çš„é—®é¢˜ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§ä¸”ç®€å•çš„å¹³å‡æ± åŒ–(mean-pooling)æ–¹æ³•ï¼Œå°†è¾“å…¥åºåˆ—è½¬æ¢ä¸ºè¾ƒçŸ­çš„è¿ç»­è¡¨ç¤ºï¼Œå¹¶åœ¨å®éªŒä¸­è¡¨ç°å‡ºæŒç»­ä¼˜äºå¹¿æ³›ä½¿ç”¨çš„å‹ç¼©æ ‡è®°(compression-tokens)æ¶æ„çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¢ç´¢äº†å¯¹åŒä¸€å‹ç¼©å™¨è¿›è¡Œå¤šæ¯”ä¾‹è®­ç»ƒ(multi-ratio training)çš„æŠ€æœ¯ï¼Œä½¿å…¶èƒ½å¤Ÿçµæ´»è¾“å‡ºå¤šç§å‹ç¼©æ¯”ç‡ã€‚é€šè¿‡åœ¨åŸŸå†…å’ŒåŸŸå¤–é—®ç­”(QA)æ•°æ®é›†ä»¥åŠä¸åŒæ¨¡å‹å®¶æ—å’Œè§„æ¨¡ä¸‹çš„å¹¿æ³›å®éªŒï¼Œç»“æœè¯å®äº†å¹³å‡æ± åŒ–æ–¹æ³•åœ¨å„ç§å‹ç¼©æ¯”ä¸‹å‡å…·æœ‰æœ€å¼ºçš„æ€§èƒ½è¡¨ç°ã€‚å°½ç®¡åœ¨å¤šæ¯”ä¾‹è®­ç»ƒæ—¶å­˜åœ¨è½»å¾®çš„æ€§èƒ½æŸå¤±ï¼Œä½†è¯¥ç ”ç©¶æ·±å…¥æ­ç¤ºäº†ä¸åŒå‹ç¼©æ¶æ„ä¸è®­ç»ƒæœºåˆ¶ä¹‹é—´å¤æ‚çš„æƒè¡¡å…³ç³»ï¼Œä¸ºé«˜æ•ˆä¸Šä¸‹æ–‡å¤„ç†æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code available at https://github.com/lil-lab/simple-context-compression",
      "pdf_url": "https://arxiv.org/pdf/2510.20797v1",
      "published_date": "2025-10-23 17:57:23 UTC",
      "updated_date": "2025-10-23 17:57:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:11:49.894778+00:00"
    },
    {
      "arxiv_id": "2510.21883v1",
      "title": "Language Ranker: A Lightweight Ranking framework for LLM Decoding",
      "title_zh": "Language Rankerï¼šä¸€ç§é¢å‘å¤§è¯­è¨€æ¨¡å‹è§£ç çš„è½»é‡çº§æ’åºæ¡†æ¶",
      "authors": [
        "Chenheng Zhang",
        "Tianqi Du",
        "Jizhe Zhang",
        "Mingqing Xiao",
        "Yifei Wang",
        "Yisen Wang",
        "Zhouchen Lin"
      ],
      "abstract": "Conventional research on large language models (LLMs) has primarily focused on refining output distributions, while paying less attention to the decoding process that transforms these distributions into final responses. Recent advances, such as scaling the computation of inference time with reward models, have underscored the importance of decoding, but these methods often suffer from high computational costs and limited applicability. In this paper, we revisit LLM generation through the lens of recommender systems, conceptualizing the decoding process as analogous to the ranking stage in recommendation pipelines. From this perspective, we observe that both traditional decoding methods and reward models exhibit clear limitations such as redundancy. Motivated by this insight, we propose Language Ranker, a novel framework that introduces a lightweight module to rerank candidate responses using features extracted by the base model. Experiments across a wide range of tasks show that Language Ranker achieves performance comparable to large-scale reward models, while requiring only <0.5M additional parameters, significantly reducing the computational overhead during both training and inference stages. This highlights the efficiency and effectiveness of our method, showcasing its potential to fully unlock the capabilities of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿå¤§è¯­è¨€æ¨¡å‹ (LLMs) è§£ç è¿‡ç¨‹è¢«å¿½è§†ä»¥åŠç°æœ‰æ¨ç†æ—¶é—´æ‰©å±•æ–¹æ³•è®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ï¼Œä»æ¨èç³»ç»Ÿçš„æ’åºè§†è§’é‡æ–°å®¡è§†äº† LLM çš„ç”Ÿæˆè¿‡ç¨‹ã€‚ç ”ç©¶è€…æŒ‡å‡ºï¼Œä¼ ç»Ÿè§£ç æ–¹æ³•å’Œå¥–åŠ±æ¨¡å‹ (Reward Models) åœ¨å¤„ç†è¿‡ç¨‹ä¸­å­˜åœ¨å†—ä½™ï¼Œå¹¶æ®æ­¤æå‡ºäº† Language Ranker è¿™ä¸€è½»é‡çº§æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªæå°çš„æ¨¡å—ï¼Œåˆ©ç”¨åŸºç¡€æ¨¡å‹æå–çš„ç‰¹å¾å¯¹å€™é€‰å›å¤è¿›è¡Œé‡æ’åº (Reranking)ï¼Œä»¥ä¼˜åŒ–æœ€ç»ˆè¾“å‡ºã€‚å®éªŒè¯æ˜ï¼ŒLanguage Ranker åœ¨å¤šç§ä»»åŠ¡ä¸Šçš„è¡¨ç°å¯ä¸å¤§è§„æ¨¡å¥–åŠ±æ¨¡å‹åª²ç¾ï¼Œä¸”ä»…éœ€å¢åŠ ä¸åˆ° 0.5M çš„å‚æ•°ã€‚è¿™ä¸€æˆæœæ˜¾è‘—é™ä½äº†è®­ç»ƒä¸æ¨ç†çš„è®¡ç®—å¼€é”€ï¼Œå±•ç°äº†åœ¨é«˜æ•ˆæŒ–æ˜ LLMs æ½œåŠ›æ–¹é¢çš„å·¨å¤§åº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21883v1",
      "published_date": "2025-10-23 17:56:46 UTC",
      "updated_date": "2025-10-23 17:56:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:11:53.086146+00:00"
    },
    {
      "arxiv_id": "2510.20795v1",
      "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with Spherical Graph Neural Networks",
      "title_zh": "åŸºäºçƒé¢å›¾ç¥ç»ç½‘ç»œçš„å®‡å®™å¾®æ³¢èƒŒæ™¯åŸåˆç£åœºå‚æ•°è´å¶æ–¯æ¨æ–­",
      "authors": [
        "Juan Alejandro Pinto Castro",
        "HÃ©ctor J. HortÃºa",
        "Jorge Enrique GarcÃ­a-Farieta",
        "Roger Anderson Hurtado"
      ],
      "abstract": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶å®ç°äº†ä¸€ä¸ªåŸºäºè´å¶æ–¯å›¾æ·±åº¦å­¦ä¹ (Bayesian graph deep learning)çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä»æ¨¡æ‹Ÿçš„å®‡å®™å¾®æ³¢èƒŒæ™¯(CMB)å›¾ä¸­ç›´æ¥æ¨æ–­åŸå§‹ç£åœº(Primordial Magnetic Field, PMF)çš„å…³é”®å®‡å®™å­¦å‚æ•°ã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº†DeepSphereæ¶æ„ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨è®¾è®¡çš„çƒé¢å·ç§¯ç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿé€šè¿‡HEALPixåƒç´ åŒ–å¤„ç†å°Šé‡CMBæ•°æ®çš„çƒé¢å‡ ä½•ç‰¹æ€§ã€‚ä¸ºäº†è¶…è¶Šä¼ ç»Ÿçš„ç¡®å®šæ€§ç‚¹ä¼°è®¡ï¼Œç ”ç©¶åœ¨æ¡†æ¶ä¸­é›†æˆäº†è´å¶æ–¯ç¥ç»ç½‘ç»œ(Bayesian Neural Networks, BNNs)ï¼Œä»è€Œæœ‰æ•ˆæ•æ‰å¶ç„¶ä¸ç¡®å®šæ€§(aleatoric uncertainty)å’Œè®¤çŸ¥ä¸ç¡®å®šæ€§(epistemic uncertainty)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ç£å‚æ•°ä¼°è®¡æ–¹é¢è¡¨ç°å“è¶Šï¼Œå…¶$R^{2}$å¾—åˆ†è¶…è¿‡0.89ã€‚æ­¤å¤–ï¼Œç ”ç©¶é€šè¿‡Variance Scalingå’ŒGPNormalç­‰äº‹åè®­ç»ƒæŠ€æœ¯ï¼Œè·å¾—äº†æ ¡å‡†è‰¯å¥½çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚è¿™ç§é›†æˆçš„DeepSphere-BNNsæ¡†æ¶ä¸ä»…æå‡äº†å‚æ•°ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œè¿˜ä¸ºç²¾å‡†å®‡å®™å­¦æ—¶ä»£çš„é²æ£’å®‡å®™å­¦æ¨æ–­æä¾›äº†å¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–å·¥å…·ã€‚",
      "categories": [
        "astro-ph.CO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.CO",
      "comment": "16 pages, 6 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.20795v1",
      "published_date": "2025-10-23 17:56:04 UTC",
      "updated_date": "2025-10-23 17:56:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:11:56.677254+00:00"
    },
    {
      "arxiv_id": "2510.20784v2",
      "title": "A Coherence-Based Measure of AGI",
      "title_zh": "ä¸€ç§åŸºäºä¸€è‡´æ€§çš„ AGI åº¦é‡æ–¹æ³•",
      "authors": [
        "Fares Fourati"
      ],
      "abstract": "Recent approaches to evaluating Artificial General Intelligence (AGI) typically summarize a system's capability using the arithmetic mean of its proficiencies across multiple cognitive domains. While simple, this implicitly assumes compensability: exceptional performance in some areas can offset severe deficiencies in others. Genuine general intelligence, however, requires coherent sufficiency: balanced competence across all essential faculties. We introduce a coherence-based measure of AGI that integrates the generalized mean over a continuum of compensability exponents. This yields an area-under-the-curve (AUC) metric spanning arithmetic, geometric, and harmonic regimes, quantifying how robust an evaluated capability remains as compensability assumptions become stricter. Unlike the arithmetic mean, which rewards specialization, the AUC penalizes imbalance and exposes bottlenecks that constrain performance. To illustrate the framework, we apply it to cognitive profiles derived from the Cattell-Horn-Carroll (CHC) model, showing how coherence-based aggregation highlights imbalances that are obscured by arithmetic averaging. As a second, independent example, we apply the same methodology to a set of 17 heterogeneous benchmarks, demonstrating how coherence-based evaluation can reveal unevenness even in narrower task collections. These examples show that the proposed approach offers a principled, interpretable, and stricter foundation for measuring progress toward AGI.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰é€šç”¨äººå·¥æ™ºèƒ½(AGI)è¯„ä¼°ä¸­æ™®éé‡‡ç”¨ç®—æœ¯å¹³å‡æ•°(Arithmetic Mean)å¯¼è‡´çš„ä»£å¿æ€§(Compensability)å‡è®¾é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºä¸€è‡´æ€§çš„è¡¡é‡æ–¹æ³•ã€‚è¯¥æŒ‡æ ‡æ•´åˆäº†å¹¿ä¹‰å¹³å‡æ•°(Generalized Mean)åœ¨ä¸åŒè¡¥å¿æŒ‡æ•°ä¸‹çš„å˜åŒ–ï¼Œå½¢æˆäº†æ¶µç›–ç®—æœ¯ã€å‡ ä½•åŠè°ƒå’Œå¹³å‡æ€åŠ¿çš„æ›²çº¿ä¸‹é¢ç§¯(AUC)åº¦é‡ä½“ç³»ã€‚ä¸å¥–åŠ±ç‰¹å®šé¢†åŸŸä¸“ä¸šåŒ–çš„ç®—æœ¯å¹³å‡æ•°ä¸åŒï¼ŒAUCæŒ‡æ ‡èƒ½å¤Ÿæƒ©ç½šèƒ½åŠ›çš„ä¸å¹³è¡¡ï¼Œå¹¶æœ‰æ•ˆæ­ç¤ºåˆ¶çº¦ç³»ç»Ÿæ•´ä½“æ€§èƒ½çš„ç“¶é¢ˆã€‚é€šè¿‡åœ¨Cattell-Horn-Carroll (CHC)æ¨¡å‹å’Œ17ä¸ªå¼‚æ„åŸºå‡†æµ‹è¯•(Benchmarks)ä¸­çš„å®é™…åº”ç”¨ï¼Œç ”ç©¶è¯æ˜è¯¥æ–¹æ³•èƒ½è¯†åˆ«å‡ºè¢«ä¼ ç»Ÿå¹³å‡æ³•æ‰€æ©ç›–çš„èƒ½åŠ›åˆ†å¸ƒä¸å‡ã€‚è¿™ä¸€ç ”ç©¶ä¸ºæµ‹é‡AGIçš„å‘å±•è¿›åº¦æä¾›äº†ä¸€ä¸ªæ›´å…·åŸåˆ™æ€§ã€å¯è§£é‡Šæ€§ä¸”æ›´ä¸¥æ ¼çš„è¯„ä¼°åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at FAST@AAAI 2026. 15 pages, 2 figures, 13 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.20784v2",
      "published_date": "2025-10-23 17:51:42 UTC",
      "updated_date": "2025-11-27 17:01:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:04.668541+00:00"
    },
    {
      "arxiv_id": "2510.20782v1",
      "title": "A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text",
      "title_zh": "è¡¡é‡å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬è´Ÿè´£ä»»æ€§èƒ½ç»´åº¦çš„ç‰¹å®šç”¨ä¾‹æ•°æ®é›†",
      "authors": [
        "Alicia Sagae",
        "Chia-Jung Lee",
        "Sandeep Avula",
        "Brandon Dang",
        "Vanessa Murdock"
      ],
      "abstract": "Current methods for evaluating large language models (LLMs) typically focus on high-level tasks such as text generation, without targeting a particular AI application. This approach is not sufficient for evaluating LLMs for Responsible AI dimensions like fairness, since protected attributes that are highly relevant in one application may be less relevant in another. In this work, we construct a dataset that is driven by a real-world application (generate a plain-text product description, given a list of product features), parameterized by fairness attributes intersected with gendered adjectives and product categories, yielding a rich set of labeled prompts. We show how to use the data to identify quality, veracity, safety, and fairness gaps in LLMs, contributing a proposal for LLM evaluation paired with a concrete resource for the research community.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå½“å‰çš„ Large Language Models (LLMs) è¯„ä¼°æ–¹æ³•å¾€å¾€ä¾§é‡äºé€šç”¨ä»»åŠ¡ï¼Œç¼ºä¹å¯¹ç‰¹å®šäººå·¥æ™ºèƒ½åº”ç”¨åœºæ™¯çš„å…³æ³¨ï¼Œå¯¼è‡´åœ¨è¯„ä¼° Fairness ç­‰ Responsible AI ç»´åº¦æ—¶å­˜åœ¨å±€é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªåŸºäºçœŸå®åº”ç”¨åœºæ™¯ï¼ˆæ ¹æ®äº§å“ç‰¹å¾ç”Ÿæˆäº§å“æè¿°ï¼‰çš„æ•°æ®é›†ï¼Œå¹¶é€šè¿‡ Fairness å±æ€§ã€æ€§åˆ«å½¢å®¹è¯ä¸äº§å“ç±»åˆ«çš„äº¤å‰ç»„åˆï¼Œç”Ÿæˆäº†ä¸°å¯Œçš„å¸¦æ ‡ç­¾ Promptã€‚ç ”ç©¶å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨è¯¥æ•°æ®é›†è¯†åˆ« LLMs åœ¨ Qualityã€Veracityã€Safety ä»¥åŠ Fairness æ–¹é¢çš„è¡¨ç°å·®è·ã€‚è¯¥å·¥ä½œä¸ä»…æå‡ºäº†ä¸€å¥—é’ˆå¯¹ç‰¹å®šç”¨ä¾‹çš„ LLM è¯„ä¼°æ–¹æ¡ˆï¼Œè¿˜ä¸ºç ”ç©¶ç•Œæä¾›äº†å…·ä½“çš„èµ„æºæ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages with 3 figures, to appear in Proceedings of the 34th ACM International Conference on Information and Knowledge Management (CIKM '25)",
      "pdf_url": "https://arxiv.org/pdf/2510.20782v1",
      "published_date": "2025-10-23 17:50:55 UTC",
      "updated_date": "2025-10-23 17:50:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:01.788342+00:00"
    },
    {
      "arxiv_id": "2510.20780v1",
      "title": "Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost",
      "title_zh": "å¤§æ¨ç†æ¨¡å‹èƒ½å¦èƒœä»»ç¿»è¯‘è¯„ä¼°ï¼Ÿåˆ†æä¸æ€§èƒ½æå‡",
      "authors": [
        "Runzhe Zhan",
        "Zhihong Huang",
        "Xinyi Yang",
        "Lidia S. Chao",
        "Min Yang",
        "Derek F. Wong"
      ],
      "abstract": "Recent advancements in large reasoning models (LRMs) have introduced an intermediate \"thinking\" process prior to generating final answers, improving their reasoning capabilities on complex downstream tasks. However, the potential of LRMs as evaluators for machine translation (MT) quality remains underexplored. We provides the first systematic analysis of LRM-as-a-judge in MT evaluation. We identify key challenges, revealing LRMs require tailored evaluation materials, tend to \"overthink\" simpler instances and have issues with scoring mechanisms leading to overestimation. To address these, we propose to calibrate LRM thinking by training them on synthetic, human-like thinking trajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this approach largely reduces thinking budgets by ~35x while concurrently improving evaluation performance across different LRM scales from 7B to 32B (e.g., R1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These findings highlight the potential of efficiently calibrated LRMs to advance fine-grained automatic MT evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLarge Reasoning Models, LRMsï¼‰ä½œä¸ºæœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰è´¨é‡è¯„ä¼°è€…çš„è§’è‰²è¿›è¡Œäº†é¦–æ¬¡ç³»ç»Ÿæ€§åˆ†æã€‚ç ”ç©¶æŒ‡å‡º LRMs åœ¨è¯„ä¼°ä¸­å­˜åœ¨â€œè¿‡åº¦æ€è€ƒâ€ç®€å•æ ·æœ¬ã€è¯„åˆ†æœºåˆ¶å¯¼è‡´è¿‡åº¦ä¼°è®¡ä»¥åŠå¯¹è¯„ä¼°ææ–™æœ‰ç‰¹æ®Šéœ€æ±‚ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚ä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ ¡å‡† LRM æ€ç»´çš„æ–¹æ³•ï¼Œé€šè¿‡åœ¨åˆæˆçš„ç±»äººæ€ç»´è½¨è¿¹ï¼ˆThinking Trajectoriesï¼‰ä¸Šè¿›è¡Œè®­ç»ƒæ¥ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ã€‚å®éªŒåœ¨ WMT24 Metrics åŸºå‡†æµ‹è¯•ä¸Šè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—æå‡ 7B è‡³ 32B è§„æ¨¡æ¨¡å‹è¯„ä¼°æ€§èƒ½çš„åŒæ—¶ï¼Œå¦‚ R1-Distill-Qwen-7B ç›¸å…³æ€§æå‡äº† 8.7 ä¸ªç‚¹ï¼ŒæˆåŠŸå°†æ¨ç†é¢„ç®—ï¼ˆThinking Budgetsï¼‰é™ä½äº†çº¦ 35 å€ã€‚è¿™é¡¹å·¥ä½œçªæ˜¾äº†ç»è¿‡æ ¡å‡†çš„ LRMs åœ¨å®ç°é«˜æ•ˆä¸”ç»†ç²’åº¦çš„è‡ªåŠ¨åŒ–æœºå™¨ç¿»è¯‘è¯„ä¼°æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20780v1",
      "published_date": "2025-10-23 17:48:36 UTC",
      "updated_date": "2025-10-23 17:48:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:05.881058+00:00"
    },
    {
      "arxiv_id": "2510.20774v2",
      "title": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation",
      "title_zh": "FieldGenï¼šä»é¥æ“ä½œé¢„æ“çºµè½¨è¿¹åˆ°åœºå¼•å¯¼çš„æ•°æ®ç”Ÿæˆ",
      "authors": [
        "Wenhao Wang",
        "Kehe Ye",
        "Xinyu Zhou",
        "Tianxing Chen",
        "Cao Min",
        "Qiaoming Zhu",
        "Xiaokang Yang",
        "Ping Luo",
        "Yongjian Shen",
        "Yang Yang",
        "Maoqing Yao",
        "Yao Mu"
      ],
      "abstract": "Large-scale and diverse datasets are vital for training robust robotic manipulation policies, yet existing data collection methods struggle to balance scale, diversity, and quality. Simulation offers scalability but suffers from sim-to-real gaps, while teleoperation yields high-quality demonstrations with limited diversity and high labor cost. We introduce FieldGen, a field-guided data generation framework that enables scalable, diverse, and high-quality real-world data collection with minimal human supervision. FieldGen decomposes manipulation into two stages: a pre-manipulation phase, allowing trajectory diversity, and a fine manipulation phase requiring expert precision. Human demonstrations capture key contact and pose information, after which an attraction field automatically generates diverse trajectories converging to successful configurations. This decoupled design combines scalable trajectory diversity with precise supervision. Moreover, FieldGen-Reward augments generated data with reward annotations to further enhance policy learning. Experiments demonstrate that policies trained with FieldGen achieve higher success rates and improved stability compared to teleoperation-based baselines, while significantly reducing human effort in long-term real-world data collection. Webpage is available at https://fieldgen.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FieldGenï¼Œè¿™æ˜¯ä¸€ä¸ªåœºå¼•å¯¼çš„æ•°æ®ç”Ÿæˆæ¡†æ¶ (field-guided data generation framework)ï¼Œæ—¨åœ¨é€šè¿‡æå°‘çš„äººåŠ›ç›‘ç£å®ç°å¤§è§„æ¨¡ã€å¤šæ ·åŒ–ä¸”é«˜è´¨é‡çš„çœŸå®ä¸–ç•Œæœºå™¨äººæ“ä½œæ•°æ®é‡‡é›†ã€‚FieldGen å°†æ“ä½œè¿‡ç¨‹åˆ†è§£ä¸ºå…è®¸è½¨è¿¹å¤šæ ·åŒ–çš„é¢„æ“ä½œé˜¶æ®µ (pre-manipulation phase) å’Œéœ€è¦ä¸“å®¶ç²¾åº¦çš„ç²¾ç»†æ“ä½œé˜¶æ®µ (fine manipulation phase)ï¼Œåˆ©ç”¨äººç±»æ¼”ç¤ºæ•è·å…³é”®çš„æ¥è§¦ä¸å§¿æ€ä¿¡æ¯ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•åŠ›åœº (attraction field) è‡ªåŠ¨ç”ŸæˆæŒ‡å‘æˆåŠŸé…ç½®çš„å¤šæ ·åŒ–è½¨è¿¹ï¼Œå®ç°äº†å¯æ‰©å±•çš„è½¨è¿¹å¤šæ ·æ€§ä¸ç²¾ç¡®ç›‘ç£çš„æœ‰æœºç»“åˆã€‚æ­¤å¤–ï¼ŒFieldGen-Reward é€šè¿‡ä¸ºç”Ÿæˆæ•°æ®æä¾›å¥–åŠ±æ ‡æ³¨ (reward annotations) è¿›ä¸€æ­¥å¢å¼ºäº†ç­–ç•¥å­¦ä¹ çš„æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºäºè¿œç¨‹æ“ä½œ (teleoperation) çš„åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œåˆ©ç”¨ FieldGen è®­ç»ƒçš„ç­–ç•¥åœ¨æˆåŠŸç‡å’Œç¨³å®šæ€§ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå¹¶å¤§å¹…å‡å°‘äº†é•¿æœŸæ•°æ®é‡‡é›†ä¸­çš„äººåŠ›æŠ•å…¥ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "Webpage: https://fieldgen.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2510.20774v2",
      "published_date": "2025-10-23 17:47:12 UTC",
      "updated_date": "2025-10-28 17:10:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:08.669695+00:00"
    },
    {
      "arxiv_id": "2510.20768v2",
      "title": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines",
      "title_zh": "RAGRankï¼šåˆ©ç”¨ PageRank é˜²å¾¡ CTI å¤§è¯­è¨€æ¨¡å‹æµæ°´çº¿ä¸­çš„ä¸­æ¯’æ”»å‡»",
      "authors": [
        "Austin Jia",
        "Avaneesh Ramesh",
        "Zain Shamsi",
        "Daniel Zhang",
        "Alex Liu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the dominant architectural pattern to operationalize Large Language Model (LLM) usage in Cyber Threat Intelligence (CTI) systems. However, this design is susceptible to poisoning attacks, and previously proposed defenses can fail for CTI contexts as cyber threat information is often completely new for emerging attacks, and sophisticated threat actors can mimic legitimate formats, terminology, and stylistic conventions. To address this issue, we propose that the robustness of modern RAG defenses can be accelerated by applying source credibility algorithms on corpora, using PageRank as an example. In our experiments, we demonstrate quantitatively that our algorithm applies a lower authority score to malicious documents while promoting trusted content, using the standardized MS MARCO dataset. We also demonstrate proof-of-concept performance of our algorithm on CTI documents and feeds.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RAGRankï¼Œæ—¨åœ¨åˆ©ç”¨ PageRank ç®—æ³•æå‡ç½‘ç»œå¨èƒæƒ…æŠ¥ (Cyber Threat Intelligence, CTI) é¢†åŸŸä¸­æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) ç³»ç»Ÿçš„æŠ—ä¸­æ¯’æ”»å‡» (Poisoning attacks) èƒ½åŠ›ã€‚é’ˆå¯¹ç°æœ‰é˜²å¾¡æ‰‹æ®µåœ¨é¢å¯¹æ¨¡ä»¿åˆæ³•æ ¼å¼ä¸”åŒ…å«å…¨æ–°ä¿¡æ¯çš„æ¶æ„æƒ…æŠ¥æ—¶å®¹æ˜“å¤±æ•ˆçš„æŒ‘æˆ˜ï¼ŒRAGRank é€šè¿‡å¯¹è¯­æ–™åº“åº”ç”¨æ¥æºå¯ä¿¡åº¦ç®—æ³•ï¼Œä¸ºæ–‡æ¡£å»ºç«‹æƒå¨æ€§è¯„ä¼°ä½“ç³»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç®—æ³•åœ¨ MS MARCO æ•°æ®é›†åŠ CTI å®é™…æ–‡æ¡£ä¸­èƒ½æœ‰æ•ˆè¯†åˆ«å¹¶é™ä½æ¶æ„æ–‡æ¡£çš„æƒå¨å¾—åˆ†ï¼ŒåŒæ—¶ä¼˜å…ˆæ¨èå—ä¿¡ä»»çš„å†…å®¹ã€‚è¿™ä¸€æ–¹æ³•é€šè¿‡å¼•å…¥ç»“æ„åŒ–çš„ä¿¡èª‰è¯„ä¼°ï¼Œæ˜¾è‘—å¢å¼ºäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„ CTI æµæ°´çº¿åœ¨å¯¹æŠ—æ€§ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "Presented as a poster at the Annual Computer Security Applications Conference (ACSAC) 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20768v2",
      "published_date": "2025-10-23 17:43:00 UTC",
      "updated_date": "2025-12-15 20:48:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:10.301175+00:00"
    },
    {
      "arxiv_id": "2510.20748v1",
      "title": "Reinforcement Learning and Consumption-Savings Behavior",
      "title_zh": "å¼ºåŒ–å­¦ä¹ ä¸æ¶ˆè´¹-å‚¨è“„è¡Œä¸º",
      "authors": [
        "Brandon Kaplowitz"
      ],
      "abstract": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Reinforcement Learningå¦‚ä½•è§£é‡Šç»æµè¡°é€€æœŸé—´å®¶åº­æ¶ˆè´¹è¡Œä¸ºä¸­çš„ä¸¤ç§åå¸¸æ¨¡å¼ã€‚ä½œè€…å¼€å‘äº†ä¸€ä¸ªç»“åˆQ-learningä¸Neural Networkè¿‘ä¼¼çš„æ¨¡å‹ï¼Œæ¨¡æ‹Ÿä»£ç†äººåœ¨æ”¶å…¥ä¸ç¡®å®šæ€§ä¸‹è¿›è¡Œçš„Consumption-Savingså†³ç­–ï¼Œåç¦»äº†ä¼ ç»Ÿçš„Rational Expectationså‡è®¾ã€‚è¯¥æ¨¡å‹æˆåŠŸå¤ç°äº†è¿‘æœŸæ–‡çŒ®ä¸­çš„ä¸¤é¡¹å…³é”®å‘ç°ï¼šé¦–å…ˆï¼Œä½èµ„äº§å¤±ä¸šå®¶åº­å¯¹åˆºæ¿€æ”¯ä»˜è¡¨ç°å‡ºæ˜¾è‘—æ›´é«˜çš„Marginal Propensities to Consumeï¼›å…¶æ¬¡ï¼Œæ›¾æœ‰å¤±ä¸šç»å†çš„å®¶åº­åœ¨æ§åˆ¶å½“å‰å˜é‡åä»è¡¨ç°å‡ºæŒä¹…çš„ä½æ¶ˆè´¹æ°´å¹³ï¼Œå³â€œScarringâ€æ•ˆåº”ã€‚ä¸åŒäºä»¥å¾€åŸºäºä¿¡å¿µæ›´æ–°æˆ–å¼‚è´¨æ€§çš„è§£é‡Šï¼ŒReinforcement Learningæœºåˆ¶é€šè¿‡éšç»éªŒæ¼”å˜çš„Value Function Approximation ErrorsåŒæ—¶äº§ç”Ÿè¿™ä¸¤ç§ç°è±¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§è‡ªé€‚åº”å­¦ä¹ ä¸ºç†è§£è¿‡å»ç»éªŒå¦‚ä½•è¶…è¶Šå½“å‰ç»æµé¢„æµ‹å¹¶å¡‘é€ æ¶ˆè´¹è¡Œä¸ºæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„åˆ†ææ¡†æ¶ã€‚",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "econ.GN",
      "comment": "41 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20748v1",
      "published_date": "2025-10-23 17:14:49 UTC",
      "updated_date": "2025-10-23 17:14:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:22.185531+00:00"
    },
    {
      "arxiv_id": "2510.20743v1",
      "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations",
      "title_zh": "å…±æƒ…æç¤ºï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å¯¹è¯ä¸­çš„éè¨€è¯­è¯­å¢ƒé›†æˆ",
      "authors": [
        "Lorenzo Stacchio",
        "Andrea Ubaldi",
        "Alessandro Galdelli",
        "Maurizio Mauri",
        "Emanuele Frontoni",
        "Andrea Gaggioli"
      ],
      "abstract": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Empathic Promptingï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¤šæ¨¡æ€äººæœºäº¤äº’çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆéè¨€è¯­è¯­å¢ƒ(Non-Verbal Context)æ¥ä¸°å¯Œå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¯¹è¯ä½“éªŒã€‚è¯¥ç³»ç»Ÿé›†æˆäº†å•†ä¸šé¢éƒ¨è¡¨æƒ…è¯†åˆ«(Facial Expression Recognition)æœåŠ¡æ¥æ•æ‰ç”¨æˆ·çš„æƒ…æ„Ÿçº¿ç´¢ï¼Œå¹¶å°†å…¶ä½œä¸ºä¸Šä¸‹æ–‡ä¿¡å·åµŒå…¥åˆ°æç¤º(Prompting)è¿‡ç¨‹ä¸­ã€‚ä¸ä¼ ç»Ÿå¤šæ¨¡æ€æ¥å£ä¸åŒï¼ŒEmpathic Prompting æ— éœ€ç”¨æˆ·æ˜¾å¼æ§åˆ¶ï¼Œè€Œæ˜¯é€šè¿‡æƒ…æ„Ÿä¿¡æ¯è‡ªåŠ¨å¢å¼ºæ–‡æœ¬è¾“å…¥ï¼Œä»¥å®ç°å¯¹è¯å’Œæµç•…æ€§çš„å¯¹é½ã€‚è¯¥æ¶æ„å…·æœ‰æ¨¡å—åŒ–å’Œå¯æ‰©å±•æ€§ï¼Œå¹¶åœ¨æœ¬åœ°éƒ¨ç½²çš„ DeepSeek å®ä¾‹ä¸Šè¿›è¡Œäº†å®ç°ã€‚åˆæ­¥çš„å¯ç”¨æ€§è¯„ä¼°(N=5)ç»“æœæ˜¾ç¤ºï¼Œç³»ç»Ÿèƒ½å¤Ÿå°†éè¨€è¯­è¾“å…¥ä¸€è‡´åœ°æ•´åˆåˆ°è¿è´¯çš„ LLM è¾“å‡ºä¸­ï¼Œå‚ä¸è€…å¯¹å…¶å¯¹è¯æµç•…åº¦ç»™äºˆäº†é«˜åº¦è¯„ä»·ã€‚è¿™é¡¹å·¥ä½œåœ¨åŒ»ç–—ä¿å¥å’Œæ•™è‚²ç­‰é¢†åŸŸå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰è¨€è¯­äº¤æµä¸­éš¾ä»¥å¯Ÿè§‰çš„å…³é”®æƒ…æ„Ÿä¿¡å·ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20743v1",
      "published_date": "2025-10-23 17:08:03 UTC",
      "updated_date": "2025-10-23 17:08:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:25.573377+00:00"
    },
    {
      "arxiv_id": "2510.24765v1",
      "title": "Topic-aware Large Language Models for Summarizing the Lived Healthcare Experiences Described in Health Stories",
      "title_zh": "ä¸»é¢˜æ„ŸçŸ¥å¤§è¯­è¨€æ¨¡å‹ï¼šç”¨äºæ€»ç»“å¥åº·æ•…äº‹ä¸­æ‰€è®°å½•çš„çœŸå®åŒ»ç–—ä½“éªŒ",
      "authors": [
        "Maneesh Bilalpur",
        "Megan Hamm",
        "Young Ji Lee",
        "Natasha Norman",
        "Kathleen M. McTigue",
        "Yanshan Wang"
      ],
      "abstract": "Storytelling is a powerful form of communication and may provide insights into factors contributing to gaps in healthcare outcomes. To determine whether Large Language Models (LLMs) can identify potential underlying factors and avenues for intervention, we performed topic-aware hierarchical summarization of narratives from African American (AA) storytellers. Fifty transcribed stories of AA experiences were used to identify topics in their experience using the Latent Dirichlet Allocation (LDA) technique. Stories about a given topic were summarized using an open-source LLM-based hierarchical summarization approach. Topic summaries were generated by summarizing across story summaries for each story that addressed a given topic. Generated topic summaries were rated for fabrication, accuracy, comprehensiveness, and usefulness by the GPT4 model, and the model's reliability was validated against the original story summaries by two domain experts. 26 topics were identified in the fifty AA stories. The GPT4 ratings suggest that topic summaries were free from fabrication, highly accurate, comprehensive, and useful. The reliability of GPT ratings compared to expert assessments showed moderate to high agreement. Our approach identified AA experience-relevant topics such as health behaviors, interactions with medical team members, caregiving and symptom management, among others. Such insights could help researchers identify potential factors and interventions by learning from unstructured narratives in an efficient manner-leveraging the communicative power of storytelling. The use of LDA and LLMs to identify and summarize the experience of AA individuals suggests a variety of possible avenues for health research and possible clinical improvements to support patients and caregivers, thereby ultimately improving health outcomes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆä¸»é¢˜æ„ŸçŸ¥çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åˆ†å±‚æ‘˜è¦æ–¹æ³•ï¼Œæ—¨åœ¨ä»éè£”ç¾å›½äººï¼ˆAAï¼‰çš„å¥åº·å™è¿°ä¸­æå–å½±å“åŒ»ç–—ç»“æœçš„å…³é”®å› ç´ ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ Latent Dirichlet Allocation (LDA) æŠ€æœ¯ä»50ç¯‡å£è¿°æ•…äº‹ä¸­è¯†åˆ«å‡º26ä¸ªæ ¸å¿ƒä¸»é¢˜ï¼Œå¹¶è¿ç”¨å¼€æº LLMs å¯¹è·¨æ•…äº‹çš„ä¸»é¢˜å†…å®¹è¿›è¡Œåˆ†å±‚æ€»ç»“ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œç”± GPT4 è¯„å®šçš„æ‘˜è¦åœ¨å‡†ç¡®æ€§ã€å…¨é¢æ€§å’Œå®ç”¨æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä¸”ä¸é¢†åŸŸä¸“å®¶çš„è¯„ä¼°å…·æœ‰ä¸­é«˜åº¦çš„ä¸€è‡´æ€§ã€‚è¯¥æ–¹æ³•æˆåŠŸè¯†åˆ«äº†è¯¸å¦‚å¥åº·è¡Œä¸ºã€åŒ»ç–—å›¢é˜Ÿäº’åŠ¨å’Œç—‡çŠ¶ç®¡ç†ç­‰ä¸ AA ç¾¤ä½“ç”Ÿæ´»ç»éªŒç›¸å…³çš„ä¸»é¢˜ï¼Œè¯æ˜äº†ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­é«˜æ•ˆè·å–æ´å¯Ÿçš„èƒ½åŠ›ã€‚è¿™é¡¹ç ”ç©¶ä¸ºåŒ»ç–—å¹²é¢„å’Œä¸´åºŠæ”¹è¿›æä¾›äº†æ–°çš„è‡ªåŠ¨åŒ–åˆ†æè·¯å¾„ï¼Œæœ‰åŠ©äºé€šè¿‡ç†è§£æ‚£è€…çš„çœŸå®ä½“éªŒæ¥æœ€ç»ˆæ”¹å–„å¥åº·äº§å‡ºã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.24765v1",
      "published_date": "2025-10-23 16:52:00 UTC",
      "updated_date": "2025-10-23 16:52:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:29.169904+00:00"
    },
    {
      "arxiv_id": "2510.20733v1",
      "title": "Thought Communication in Multiagent Collaboration",
      "title_zh": "å¤šæ™ºèƒ½ä½“åä½œä¸­çš„æ€ç»´é€šä¿¡",
      "authors": [
        "Yujia Zheng",
        "Zhuokai Zhao",
        "Zijian Li",
        "Yaqi Xie",
        "Mingze Gao",
        "Lizhu Zhang",
        "Kun Zhang"
      ],
      "abstract": "Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect nature limits the potential of collective intelligence. While machines are not subject to these constraints, most LLM-based multi-agent systems still rely solely on natural language, exchanging tokens or their embeddings. To go beyond language, we introduce a new paradigm, thought communication, which enables agents to interact directly mind-to-mind, akin to telepathy. To uncover these latent thoughts in a principled way, we formalize the process as a general latent variable model, where agent states are generated by an unknown function of underlying thoughts. We prove that, in a nonparametric setting without auxiliary information, both shared and private latent thoughts between any pair of agents can be identified. Moreover, the global structure of thought sharing, including which agents share which thoughts and how these relationships are structured, can also be recovered with theoretical guarantees. Guided by the established theory, we develop a framework that extracts latent thoughts from all agents prior to communication and assigns each agent the relevant thoughts, along with their sharing patterns. This paradigm naturally extends beyond LLMs to all modalities, as most observational data arise from hidden generative processes. Experiments on both synthetic and real-world benchmarks validate the theory and demonstrate the collaborative advantages of thought communication. We hope this work illuminates the potential of leveraging the hidden world, as many challenges remain unsolvable through surface-level observation alone, regardless of compute or data scale.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“åä½œä¸­è‡ªç„¶è¯­è¨€äº¤æµå­˜åœ¨çš„æŸè€—å’Œæ­§ä¹‰æ€§é™åˆ¶ï¼Œæå‡ºäº†åä¸º Thought Communication çš„æ–°èŒƒå¼ï¼Œæ—¨åœ¨å®ç°æ™ºèƒ½ä½“ä¹‹é—´ç›´æ¥çš„æ€ç»´äº¤äº’ã€‚ç ”ç©¶å°†è¯¥è¿‡ç¨‹å½¢å¼åŒ–ä¸ºä¸€ä¸ªé€šç”¨çš„éšå˜é‡æ¨¡å‹ (Latent Variable Model)ï¼Œåœ¨ç†è®ºä¸Šè¯æ˜äº†åœ¨éå‚æ•°è®¾å®š (nonparametric setting) ä¸‹ï¼Œå¯ä»¥å‡†ç¡®è¯†åˆ«æ™ºèƒ½ä½“é—´çš„å…±äº«ä¸ç§æœ‰éšæ€§æ€ç»´å¹¶æ¢å¤å…¶å…¨å±€å…±äº«ç»“æ„ã€‚åŸºäºæ­¤ç†è®ºæ„å»ºçš„æ¡†æ¶èƒ½å¤Ÿä»æ‰€æœ‰æ™ºèƒ½ä½“ä¸­æå–éšæ€§æ€ç»´å¹¶åˆ†é…ç›¸å…³çš„å…±äº«æ¨¡å¼ï¼Œä¸”è¯¥èŒƒå¼å¯ä»å¤§è¯­è¨€æ¨¡å‹ (LLMs) è½»æ¾æ‰©å±•è‡³å…¶ä»–æ•°æ®æ¨¡æ€ã€‚å®éªŒåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸­éªŒè¯äº†è¯¥ç†è®ºçš„æœ‰æ•ˆæ€§ï¼Œå¹¶å±•ç¤ºäº† Thought Communication åœ¨å¢å¼ºé›†ä½“æ™ºèƒ½åä½œæ•ˆç‡æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚è¿™é¡¹å·¥ä½œæ­ç¤ºäº†åˆ©ç”¨éšè—ç”Ÿæˆè¿‡ç¨‹è§£å†³å¤æ‚ä»»åŠ¡çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºè¶…è¶Šè¡¨é¢è§‚å¯Ÿçš„å¤šæ™ºèƒ½ä½“é€šä¿¡ç ”ç©¶æä¾›äº†é‡è¦ç†è®ºåŸºç¡€ä¸å®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025 Spotlight",
      "pdf_url": "https://arxiv.org/pdf/2510.20733v1",
      "published_date": "2025-10-23 16:48:02 UTC",
      "updated_date": "2025-10-23 16:48:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:44.878411+00:00"
    },
    {
      "arxiv_id": "2510.20728v1",
      "title": "Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems",
      "title_zh": "åŸºäºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¨ªæˆªå¯¹è§’é—¨é‡å­ç ååŒè®¾è®¡",
      "authors": [
        "Xi He",
        "Sirui Lu",
        "Bei Zeng"
      ],
      "abstract": "We present a multi-agent, human-in-the-loop workflow that co-designs quantum codes with prescribed transversal diagonal gates. It builds on the Subset-Sum Linear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL) equalities via small LPs. The workflow is powered by GPT-5 and implemented within TeXRA (https://texra.ai)-a multi-agent research assistant platform that supports an iterative tool-use loop agent and a derivation-then-edit workflow reasoning agent. We work in a LaTeX-Python environment where agents reason, edit documents, execute code, and synchronize their work to Git/Overleaf. Within this workspace, three roles collaborate: a Synthesis Agent formulates the problem; a Search Agent sweeps/screens candidates and exactifies numerics into rationals; and an Audit Agent independently checks all KL equalities and the induced logical action. As a first step we focus on distance $d=2$ with nondegenerate residues. For code dimension $K\\in\\{2,3,4\\}$ and $n\\le6$ qubits, systematic sweeps yield certificate-backed tables cataloging attainable cyclic logical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$ at $n=6$. From verified instances, Synthesis Agent abstracts recurring structures into closed-form families and proves they satisfy the KL equalities for all parameters. It further demonstrates that SSLP accommodates residue degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts diagonal-transversal feasibility as an analytical pipeline executed at scale, combining systematic enumeration with exact analytical reconstruction. It yields reproducible code constructions, supports targeted extensions to larger $K$ and higher distances, and leads toward data-driven classification.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸äººæœºåä½œçš„å·¥ä½œæµç¨‹ï¼Œç”¨äºååŒè®¾è®¡å…·æœ‰ç‰¹å®šæ¨ªå‘å¯¹è§’é—¨(transversal diagonal gates)çš„é‡å­ç ã€‚è¯¥æ–¹æ¡ˆåŸºäºå­é›†å’Œçº¿æ€§è§„åˆ’(Subset-Sum Linear Programming, SSLP)æ¡†æ¶ï¼Œå¹¶åˆ©ç”¨ GPT-5 åœ¨ TeXRA å¤šæ™ºèƒ½ä½“ç ”ç©¶å¹³å°ä¸Šå®ç°ã€‚å·¥ä½œæµç”±è´Ÿè´£å»ºæ¨¡çš„ Synthesis Agentã€æ‰§è¡Œç­›é€‰ä¸ç²¾ç¡®åŒ–çš„ Search Agent ä»¥åŠè¿›è¡Œç‹¬ç«‹éªŒè¯çš„ Audit Agent å…±åŒåä½œã€‚åœ¨è·ç¦» $d=2$ ä¸” $n \\le 6$ ä¸ªé‡å­æ¯”ç‰¹çš„åˆæ­¥å®éªŒä¸­ï¼Œç ”ç©¶ç³»ç»Ÿæ€§åœ°å‘ç°äº†å¤šç§æ”¯æŒå¾ªç¯é€»è¾‘ç¾¤çš„æ–°ä»£ç ï¼Œä¾‹å¦‚åœ¨ $K=3, n=6$ æ—¶å®ç°äº†é˜¶æ•°ä¸º 16 çš„é€»è¾‘é—¨ã€‚æ­¤å¤–ï¼ŒSynthesis Agent æˆåŠŸå°†å‘ç°çš„è§„å¾‹æŠ½è±¡ä¸ºé—­åˆå½¢å¼çš„ç³»åˆ—(closed-form families)å¹¶æä¾›äº†ä¸¥è°¨çš„è§£æè¯æ˜ã€‚å®éªŒè¿˜å±•ç¤ºäº† SSLP æ¡†æ¶å¯¹é€€åŒ–æ®‹å·®çš„é€‚åº”æ€§ï¼Œå¹¶æ„é€ å‡ºä¸€ç§å®ç°æ¨ªå‘æ§åˆ¶ç›¸ä½é—¨çš„æ–°å‹ $((6,4,2))$ ä»£ç ã€‚è¯¥å·¥ä½œæµæˆåŠŸå°†å¯¹è§’æ¨ªå‘å¯è¡Œæ€§è½¬åŒ–ä¸ºå¯å¤§è§„æ¨¡æ‰§è¡Œçš„åˆ†æç®¡é“ï¼Œä¸ºæœªæ¥æ¢ç´¢æ›´é«˜è·ç¦»å’Œç»´åº¦çš„é‡å­ç åˆ†ç±»ä¸æ„é€ å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CL",
        "math-ph"
      ],
      "primary_category": "quant-ph",
      "comment": "29 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20728v1",
      "published_date": "2025-10-23 16:45:39 UTC",
      "updated_date": "2025-10-23 16:45:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:36.395356+00:00"
    },
    {
      "arxiv_id": "2510.20727v1",
      "title": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing",
      "title_zh": "åŸºäºè‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸´åºŠç—…å†ä¸­æ°Ÿå˜§å•¶æ²»ç–—åŠå…¶ç›¸å…³æ¯’æ€§ä¿¡æ¯çš„è‡ªåŠ¨æå–",
      "authors": [
        "Xizhi Wu",
        "Madeline S. Kreider",
        "Philip E. Empey",
        "Chenyu Li",
        "Yanshan Wang"
      ],
      "abstract": "Objective: Fluoropyrimidines are widely prescribed for colorectal and breast cancers, but are associated with toxicities such as hand-foot syndrome and cardiotoxicity. Since toxicity documentation is often embedded in clinical notes, we aimed to develop and evaluate natural language processing (NLP) methods to extract treatment and toxicity information.\n  Materials and Methods: We constructed a gold-standard dataset of 236 clinical notes from 204,165 adult oncology patients. Domain experts annotated categories related to treatment regimens and toxicities. We developed rule-based, machine learning-based (Random Forest, Support Vector Machine [SVM], Logistic Regression [LR]), deep learning-based (BERT, ClinicalBERT), and large language models (LLM)-based NLP approaches (zero-shot and error-analysis prompting). Models used an 80:20 train-test split.\n  Results: Sufficient data existed to train and evaluate 5 annotated categories. Error-analysis prompting achieved optimal precision, recall, and F1 scores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot prompting reached F1=1.000 for treatment and F1=0.876 for toxicities extraction.LR and SVM ranked second for toxicities (F1=0.937). Deep learning underperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and ClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods served as our baseline with F1 scores of 0.857 in treatment and 0.858 in toxicities.\n  Discussion: LMM-based approaches outperformed all others, followed by machine learning methods. Machine and deep learning approaches were limited by small training data and showed limited generalizability, particularly for rare categories.\n  Conclusion: LLM-based NLP most effectively extracted fluoropyrimidine treatment and toxicity information from clinical notes, and has strong potential to support oncology research and pharmacovigilance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨å¼€å‘ä¸€ç§åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æŠ€æœ¯ä»ä¸´åºŠç¬”è®°ä¸­è‡ªåŠ¨æå– Fluoropyrimidine æ²»ç–—åŠå…¶ç›¸å…³æ¯’æ€§ï¼ˆå¦‚ hand-foot syndrome å’Œ cardiotoxicityï¼‰çš„æ–¹æ³•ã€‚ç ”ç©¶äººå‘˜æ„å»ºäº†ä¸€ä¸ªåŒ…å« 236 ä»½æ ‡æ³¨ä¸´åºŠç¬”è®°çš„é‡‘æ ‡å‡†æ•°æ®é›†ï¼Œå¹¶ç³»ç»Ÿå¯¹æ¯”äº†åŸºäºè§„åˆ™ã€æœºå™¨å­¦ä¹ ï¼ˆRandom Forest, SVM, LRï¼‰ã€æ·±åº¦å­¦ä¹ ï¼ˆBERT, ClinicalBERTï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨ Error-analysis prompting çš„ LLM æ–¹æ³•åœ¨æå–æ²»ç–—å’Œæ¯’æ€§ä¿¡æ¯æ—¶å‡è¾¾åˆ°äº† 1.000 çš„ F1 åˆ†æ•°ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚åˆ†æå‘ç°æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨å°æ ·æœ¬æƒ…å†µä¸‹è¡¨ç°å—é™ï¼Œè€Œ LLM åœ¨å¤„ç†éç»“æ„åŒ–åŒ»å­¦æ–‡æœ¬æ—¶å±•ç°äº†æé«˜çš„å‡†ç¡®æ€§ã€‚è¯¥ç ”ç©¶ç»“è®ºè®¤ä¸ºï¼ŒåŸºäº LLM çš„ NLP æŠ€æœ¯èƒ½æœ€æœ‰æ•ˆåœ°ä»ä¸´åºŠè®°å½•ä¸­æ•è·å…³é”®è¯Šç–—ç»†èŠ‚ï¼Œåœ¨æ”¯æŒè‚¿ç˜¤å­¦ç ”ç©¶å’Œè¯ç‰©è­¦æˆ’ï¼ˆpharmacovigilanceï¼‰æ–¹é¢å…·æœ‰å·¨å¤§çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20727v1",
      "published_date": "2025-10-23 16:44:39 UTC",
      "updated_date": "2025-10-23 16:44:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:45.781064+00:00"
    },
    {
      "arxiv_id": "2510.21881v1",
      "title": "GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models",
      "title_zh": "GeoThoughtï¼šæ—¨åœ¨å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹æ•°å­¦å‡ ä½•æ¨ç†èƒ½åŠ›çš„æ•°æ®é›†",
      "authors": [
        "Nannan Shi",
        "Chuanyu Qin",
        "Shipeng Song",
        "Man Luo"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong reasoning capabilities in text-based mathematical problem solving; however, when adapted to visual reasoning tasks, particularly geometric problem solving, their performance substantially declines because geometric problems present unique challenges. Specifically, these challenges stem from two key factors: first, the intrinsic complexity of geometry requiring detailed image comprehension and multi-step reasoning, and second, the limitations of existing datasets which lack sufficient scale, diversity, and explicit reasoning traces, consequently hindering effective model training. To address these challenges, we developed the GeoThoughts dataset, a comprehensive geometric reasoning corpus with two subsets: Geo-Thought-6K with 6,243 samples and its augmented version Geo-Thought-Augmented-10K containing 10,834 samples. Each entry includes visual descriptions, step-by-step solutions, explicit reasoning chains, reflection steps, and final answers. Using this dataset, we developed GeoThought-MLLM, a mathematical reasoning multimodal model that generates detailed thinking processes during problem-solving. Our model outperforms existing benchmarks in geometric tasks, demonstrating that training with our Chain-of-Thought dataset improves geometric reasoning capabilities across both in-domain and out-of-domain settings. Finally, we analyze failure cases and observe that errors primarily arise from incorrect interpretation of mathematical concepts or spatial misjudgment. By invoking CoT to correct these mistakes, the model produces correct answers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨å‡ ä½•é—®é¢˜è§£å†³ä¸­è¡¨ç°ä¸‹é™çš„é—®é¢˜ï¼ŒæŒ‡å‡ºå…¶æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºå‡ ä½•é—®é¢˜çš„å†…åœ¨å¤æ‚æ€§ä»¥åŠç°æœ‰æ•°æ®é›†åœ¨è§„æ¨¡ã€å¤šæ ·æ€§å’Œæ˜¾å¼æ¨ç†è·¯å¾„æ–¹é¢çš„åŒ®ä¹ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº†GeoThoughtæ•°æ®é›†ï¼ŒåŒ…å«Geo-Thought-6Kå’Œå¢å¼ºç‰ˆGeo-Thought-Augmented-10Kä¸¤ä¸ªå­é›†ï¼Œæ¯ä¸ªæ¡ç›®å‡æ¶µç›–äº†è§†è§‰æè¿°ã€åˆ†æ­¥è§£æ³•ã€æ˜¾å¼çš„é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†é“¾ã€åæ€æ­¥éª¤åŠæœ€ç»ˆç­”æ¡ˆã€‚åŸºäºè¯¥æ•°æ®é›†ï¼Œç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥å¼€å‘äº†æ•°å­¦æ¨ç†å¤šæ¨¡æ€æ¨¡å‹GeoThought-MLLMï¼Œè¯¥æ¨¡å‹åœ¨è§£é¢˜è¿‡ç¨‹ä¸­èƒ½å¤Ÿç”Ÿæˆè¯¦ç»†çš„æ€ç»´è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGeoThought-MLLMåœ¨å‡ ä½•ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ï¼Œè¯æ˜äº†é€šè¿‡è¯¥æ•°æ®é›†è¿›è¡Œè®­ç»ƒèƒ½æ˜¾è‘—æå‡æ¨¡å‹åœ¨åŸŸå†…å’ŒåŸŸå¤–ç¯å¢ƒä¸‹çš„å‡ ä½•æ¨ç†èƒ½åŠ›ã€‚æœ€åï¼Œç ”ç©¶é€šè¿‡å¯¹å¤±è´¥æ¡ˆä¾‹çš„åˆ†æå‘ç°ï¼Œé”™è¯¯ä¸»è¦æºäºæ•°å­¦æ¦‚å¿µçš„é”™è¯¯è§£é‡Šæˆ–ç©ºé—´è¯¯åˆ¤ï¼Œè€Œé€šè¿‡è°ƒç”¨CoTæœºåˆ¶ä¿®æ­£è¿™äº›é”™è¯¯ï¼Œæ¨¡å‹èƒ½å¤Ÿäº§ç”Ÿæ­£ç¡®çš„ç­”æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21881v1",
      "published_date": "2025-10-23 16:43:54 UTC",
      "updated_date": "2025-10-23 16:43:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:41.985673+00:00"
    },
    {
      "arxiv_id": "2510.20721v3",
      "title": "User Perceptions vs. Proxy LLM Judges: Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios",
      "title_zh": "ç”¨æˆ·æ„ŸçŸ¥ä¸ä»£ç† LLM è£åˆ¤ï¼šå¤§è¯­è¨€æ¨¡å‹åœ¨éšç§æ•æ„Ÿåœºæ™¯ä¸‹å“åº”çš„éšç§æ€§ä¸å¸®åŠ©æ€§",
      "authors": [
        "Xiaoyuan Wu",
        "Roshni Kaushik",
        "Wenkai Li",
        "Lujo Bauer",
        "Koichi Onoue"
      ],
      "abstract": "Large language models (LLMs) are rapidly being adopted for tasks like drafting emails, summarizing meetings, and answering health questions. In these settings, users may need to share private information (e.g., contact details, health records). To evaluate LLMs' ability to identify and redact such information, prior work introduced real-life, scenario-based benchmarks (e.g., ConfAIde, PrivacyLens) and found that LLMs can leak private information in complex scenarios. However, these evaluations relied on proxy LLMs to judge the helpfulness and privacy-preservation quality of LLM responses, rather than directly measuring users' perceptions. To understand how users perceive the helpfulness and privacy-preservation quality of LLM responses to privacy-sensitive scenarios, we conducted a user study ($n=94$) using 90 PrivacyLens scenarios. We found that users had low agreement with each other when evaluating identical LLM responses. In contrast, five proxy LLMs reached high agreement, yet each proxy LLM had low correlation with users' evaluations. These results indicate that proxy LLMs cannot accurately estimate users' wide range of perceptions of utility and privacy in privacy-sensitive scenarios. We discuss the need for more user-centered studies to measure LLMs' ability to help users while preserving privacy, and for improving alignment between LLMs and users in estimating perceived privacy and utility.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤„ç†éšç§æ•æ„Ÿåœºæ™¯æ—¶ï¼Œç”¨æˆ·æ„ŸçŸ¥ä¸ä»£ç†å¤§è¯­è¨€æ¨¡å‹(Proxy LLMs)è¯„åˆ¤æ ‡å‡†ä¹‹é—´çš„å·®å¼‚ï¼Œé‡ç‚¹å…³æ³¨æ¨¡å‹å›ç­”çš„Helpfulnesså’ŒPrivacy-Preservationè´¨é‡ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ä¸€é¡¹åŒ…å«94åå‚ä¸è€…çš„ç”¨æˆ·è°ƒç ”(User Study)ï¼Œåˆ©ç”¨90ä¸ªPrivacyLensåœºæ™¯è¯„ä¼°äº†ç”¨æˆ·å¯¹æ¨¡å‹è¾“å‡ºçš„çœŸå®æ„ŸçŸ¥ï¼Œå¹¶å°†å…¶ä¸äº”ä¸ªProxy LLMsçš„è¯„ä¼°ç»“æœè¿›è¡Œå¯¹æ¯”ã€‚å®éªŒå‘ç°ï¼Œä¸åŒç”¨æˆ·åœ¨è¯„ä¼°ç›¸åŒçš„LLMå›ç­”æ—¶è¾¾æˆçš„ä¸€è‡´æ€§è¾ƒä½ï¼Œåæ˜ å‡ºä¸ªä½“æ„ŸçŸ¥çš„å¤šæ ·æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå°½ç®¡Proxy LLMsä¹‹é—´è¡¨ç°å‡ºé«˜åº¦çš„ä¸€è‡´æ€§ï¼Œä½†å®ƒä»¬ä¸ç”¨æˆ·çš„å®é™…è¯„ä»·ç›¸å…³æ€§æä½ï¼Œæ— æ³•å‡†ç¡®ä¼°è®¡ç”¨æˆ·å¯¹Utilityå’ŒPrivacyçš„å¹¿æ³›æ„ŸçŸ¥ã€‚è¯¥è®ºæ–‡æŒ‡å‡ºç›®å‰çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œå¼ºè°ƒäº†å¼€å±•ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒ(User-Centered)ç ”ç©¶çš„å¿…è¦æ€§ï¼Œå¹¶å‘¼åæ”¹è¿›LLMä¸ç”¨æˆ·åœ¨éšç§æ„ŸçŸ¥å’Œæ•ˆç”¨è¯„ä¼°æ–¹é¢çš„å¯¹é½(Alignment)ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20721v3",
      "published_date": "2025-10-23 16:38:26 UTC",
      "updated_date": "2026-01-15 14:47:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:45.580901+00:00"
    },
    {
      "arxiv_id": "2510.20718v1",
      "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series",
      "title_zh": "åŸºäº N-BEATS ä¸å›¾ç¥ç»ç½‘ç»œçš„å¤šå˜é‡åŠå¯¼ä½“å·¥è‰ºæ—¶é—´åºåˆ—æ— ç›‘ç£å¼‚å¸¸é¢„æµ‹",
      "authors": [
        "Daniel Sorensen",
        "Bappaditya Dey",
        "Minjin Hwang",
        "Sandip Halder"
      ],
      "abstract": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠå¯¼ä½“åˆ¶é€ è¿‡ç¨‹ä¸­é«˜ç»´ä¼ æ„Ÿå™¨æ•°æ®å’Œä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡å¸¦æ¥çš„å¼‚å¸¸é¢„æµ‹æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸¤ç§åŸºäºæ— ç›‘ç£å­¦ä¹ çš„é¢„æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°ä»å¼‚å¸¸æ£€æµ‹å‘å®æ—¶å¼‚å¸¸é¢„æµ‹çš„è½¬å˜ã€‚è¯¥æ¡†æ¶é¦–å…ˆåœ¨æ— å¼‚å¸¸æ•°æ®é›†ä¸Šè®­ç»ƒé¢„æµ‹æ¨¡å‹ï¼Œéšåé€šè¿‡å¯¹æ¯”æœªçŸ¥æ•°æ®çš„é¢„æµ‹å€¼ä¸å®é™…å€¼ï¼Œå°†è¶…å‡ºé˜ˆå€¼çš„åå·®æ ‡è®°ä¸ºå¼‚å¸¸ã€‚ç ”ç©¶è¯„ä¼°äº†å‡è®¾å˜é‡ç‹¬ç«‹çš„ N-BEATS æ¨¡å‹ä»¥åŠåˆ©ç”¨ Graph Neural Network (GNN) æ•è·å˜é‡é—´å¤æ‚ç›¸äº’ä¾èµ–å…³ç³»çš„æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸¤ç§æ¨¡å‹åœ¨20ä¸ªæ—¶é—´ç‚¹çš„é¢„æµ‹è§†é‡åŠ50ä¸ªæ—¶é—´ç‚¹çš„å¼‚å¸¸é¢„æµ‹ç¨³å®šæ€§ä¸Šå‡è¡¨ç°ä¼˜å¼‚ã€‚å…¶ä¸­ GNN æ¨¡å‹åœ¨æ€§èƒ½ä¸Šå§‹ç»ˆä¼˜äº N-BEATSï¼Œä¸”æ˜¾è‘—å‡å°‘äº†å¯è®­ç»ƒå‚æ•°å¹¶é™ä½äº†è®¡ç®—æˆæœ¬ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº† GNN æ˜¯åŠå¯¼ä½“åˆ¶é€ ç¯å¢ƒä¸­è¿›è¡Œåœ¨çº¿å¼‚å¸¸é¢„æµ‹å’Œä¸»åŠ¨æ•…éšœé¢„é˜²çš„ä¸€ç§æå…·å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 27 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20718v1",
      "published_date": "2025-10-23 16:33:52 UTC",
      "updated_date": "2025-10-23 16:33:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:50.692539+00:00"
    },
    {
      "arxiv_id": "2510.20706v2",
      "title": "Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning",
      "title_zh": "åŸºäºæ¨¡å‹é¢„æµ‹æ§åˆ¶ä¸å¼ºåŒ–å­¦ä¹ çš„å››è¶³æœºå™¨äººå®æ—¶æ­¥æ€è‡ªé€‚åº”",
      "authors": [
        "Prakrut Kotecha",
        "Ganga Nair B",
        "Shishir Kolathaya"
      ],
      "abstract": "Model-free reinforcement learning (RL) has enabled adaptable and agile quadruped locomotion; however, policies often converge to a single gait, leading to suboptimal performance. Traditionally, Model Predictive Control (MPC) has been extensively used to obtain task-specific optimal policies but lacks the ability to adapt to varying environments. To address these limitations, we propose an optimization framework for real-time gait adaptation in a continuous gait space, combining the Model Predictive Path Integral (MPPI) algorithm with a Dreamer module to produce adaptive and optimal policies for quadruped locomotion. At each time step, MPPI jointly optimizes the actions and gait variables using a learned Dreamer reward that promotes velocity tracking, energy efficiency, stability, and smooth transitions, while penalizing abrupt gait changes. A learned value function is incorporated as terminal reward, extending the formulation to an infinite-horizon planner. We evaluate our framework in simulation on the Unitree Go1, demonstrating an average reduction of up to 36.48 % in energy consumption across varying target speeds, while maintaining accurate tracking and adaptive, task-appropriate gaits.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹å››è¶³æœºå™¨äººçš„å®æ—¶æ­¥æ€è‡ªé€‚åº”ä¼˜åŒ–æ¡†æ¶ï¼Œç»“åˆäº†æ¨¡å‹é¢„æµ‹è·¯å¾„ç§¯åˆ†(Model Predictive Path Integral, MPPI)ç®—æ³•ä¸Dreameræ¨¡å—ã€‚é’ˆå¯¹æ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ (Model-free RL)æ˜“æ”¶æ•›äºå•ä¸€æ­¥æ€ä»¥åŠä¼ ç»Ÿæ¨¡å‹é¢„æµ‹æ§åˆ¶(MPC)ç¯å¢ƒé€‚åº”æ€§ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶åœ¨è¿ç»­æ­¥æ€ç©ºé—´ä¸­é€šè¿‡MPPIååŒä¼˜åŒ–åŠ¨ä½œå’Œæ­¥æ€å˜é‡ã€‚ç³»ç»Ÿåˆ©ç”¨å­¦ä¹ åˆ°çš„Dreamerå¥–åŠ±æœºåˆ¶æ¥å¹³è¡¡é€Ÿåº¦è·Ÿè¸ªã€èƒ½é‡æ•ˆç‡ã€ç¨³å®šæ€§å’Œå¹³æ»‘è¿‡æ¸¡ï¼Œå¹¶å°†å­¦ä¹ åˆ°çš„ä»·å€¼å‡½æ•°ä½œä¸ºæœ«ç«¯å¥–åŠ±å¼•å…¥æ— é™æ—¶ç•Œè§„åˆ’å™¨ä¸­ã€‚åœ¨Unitree Go1æœºå™¨äººçš„ä»¿çœŸå®éªŒä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒç›®æ ‡é€Ÿåº¦ä¸‹å®ç°äº†é«˜è¾¾36.48%çš„èƒ½è€—é™ä½ï¼ŒåŒæ—¶å±•ç°äº†ç²¾å‡†çš„è·Ÿè¸ªæ€§èƒ½å’Œä»»åŠ¡é€‚åº”æ€§æ­¥æ€ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.20706v2",
      "published_date": "2025-10-23 16:17:45 UTC",
      "updated_date": "2025-10-24 07:47:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:12:51.884408+00:00"
    },
    {
      "arxiv_id": "2510.20699v1",
      "title": "Fusing Narrative Semantics for Financial Volatility Forecasting",
      "title_zh": "èåˆå™äº‹è¯­ä¹‰çš„é‡‘èæ³¢åŠ¨ç‡é¢„æµ‹",
      "authors": [
        "Yaxuan Kong",
        "Yoontae Hwang",
        "Marcus Kaiser",
        "Chris Vryonides",
        "Roel Oomen",
        "Stefan Zohren"
      ],
      "abstract": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†M2VN (Multi-Modal Volatility Network)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ç»Ÿä¸€æ•°å€¼æ—¶é—´åºåˆ—ç‰¹å¾ä¸éç»“æ„åŒ–æ–°é—»æ•°æ®çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºæå‡é‡‘èæ³¢åŠ¨ç‡é¢„æµ‹çš„æ•ˆèƒ½ã€‚M2VNåˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œè§£å†³å¼‚æ„æ•°æ®æ¨¡æ€çš„å¯¹é½ä¸èåˆæŒ‘æˆ˜ï¼Œæœ‰æ•ˆåœ°æ•´åˆäº†ç»“æ„åŒ–é‡‘èæŒ‡æ ‡ä¸å™è¿°æ€§è¯­ä¹‰ã€‚ä¸ºäº†ç¡®ä¿é¢„æµ‹çš„çœŸå®æ€§å¹¶ç¼“è§£å¸¸è§çš„å‰ç»æ€§åå·®(look-ahead bias)ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†Time Machine GPTç”Ÿæˆçš„æ–°é—»åµŒå…¥ï¼Œä»è€Œç»´æŠ¤äº†æ•°æ®å¤„ç†çš„æ—¶é—´å®Œæ•´æ€§ã€‚ç ”ç©¶ä¸­è¿˜ç‰¹åˆ«å¼•å…¥äº†è¾…åŠ©å¯¹é½æŸå¤±(auxiliary alignment loss)ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºæ·±åº¦å­¦ä¹ æ¶æ„å†…éƒ¨ä¸åŒæºæ•°æ®çš„é›†æˆæ•ˆæœã€‚å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒM2VNåœ¨æ³¢åŠ¨ç‡é¢„æµ‹ä»»åŠ¡ä¸­æŒç»­ä¼˜äºç°æœ‰çš„åŸºå‡†æ¨¡å‹ã€‚è¯¥ç ”ç©¶æˆæœä¸ºåŠ¨æ€å¸‚åœºç¯å¢ƒä¸‹çš„é£é™©ç®¡ç†å’Œé‡‘èå†³ç­–æä¾›äº†å…·æœ‰æ˜¾è‘—å®è·µä»·å€¼çš„å·¥å…·ã€‚",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ],
      "primary_category": "q-fin.CP",
      "comment": "The 6th ACM International Conference on AI in Finance (ICAIF 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.20699v1",
      "published_date": "2025-10-23 16:13:46 UTC",
      "updated_date": "2025-10-23 16:13:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:05.086839+00:00"
    },
    {
      "arxiv_id": "2510.20692v1",
      "title": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization",
      "title_zh": "æ¢ç©¶å¤§è¯­è¨€æ¨¡å‹åœ¨è®¿é—®æ§åˆ¶ç­–ç•¥åˆæˆä¸æ‘˜è¦ä¸­çš„åº”ç”¨",
      "authors": [
        "Adarsh Vatsa",
        "Bethel Hall",
        "William Eiers"
      ],
      "abstract": "Cloud computing is ubiquitous, with a growing number of services being hosted on the cloud every day. Typical cloud compute systems allow administrators to write policies implementing access control rules which specify how access to private data is governed. These policies must be manually written, and due to their complexity can often be error prone. Moreover, existing policies often implement complex access control specifications and thus can be difficult to precisely analyze in determining their behavior works exactly as intended. Recently, Large Language Models (LLMs) have shown great success in automated code synthesis and summarization. Given this success, they could potentially be used for automatically generating access control policies or aid in understanding existing policies. In this paper, we explore the effectiveness of LLMs for access control policy synthesis and summarization. Specifically, we first investigate diverse LLMs for access control policy synthesis, finding that: although LLMs can effectively generate syntactically correct policies, they have permissiveness issues, generating policies equivalent to the given specification 45.8% of the time for non-reasoning LLMs, and 93.7% of the time for reasoning LLMs. We then investigate how LLMs can be used to analyze policies by introducing a novel semantic-based request summarization approach which leverages LLMs to generate a precise characterization of the requests allowed by a policy. Our results show that while there are significant hurdles in leveraging LLMs for automated policy generation, LLMs show promising results when combined with symbolic approaches in analyzing existing policies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è®¿é—®æ§åˆ¶ç­–ç•¥ï¼ˆAccess Control Policiesï¼‰åˆæˆä¸æ€»ç»“æ–¹é¢çš„åº”ç”¨æ½œåŠ›ï¼Œæ—¨åœ¨è§£å†³äº‘ç«¯ç­–ç•¥æ‰‹åŠ¨ç¼–å†™æ˜“å‡ºé”™ä¸”åˆ†æå›°éš¾çš„é—®é¢˜ã€‚ç ”ç©¶é¦–å…ˆè¯„ä¼°äº†å¤šç§ LLMs åœ¨ç­–ç•¥åˆæˆä¸­çš„è¡¨ç°ï¼Œå‘ç°è™½ç„¶æ¨¡å‹èƒ½ç”Ÿæˆè¯­æ³•æ­£ç¡®çš„ä»£ç ï¼Œä½†åœ¨é€»è¾‘ç­‰ä»·æ€§ä¸Šå­˜åœ¨æŒ‘æˆ˜ï¼Œå…¶ä¸­æ¨ç†å‹ LLMs (reasoning LLMs) çš„å‡†ç¡®ç‡æ˜¾è‘—é«˜äºéæ¨ç†å‹æ¨¡å‹ã€‚éšåï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰çš„è¯·æ±‚æ€»ç»“ï¼ˆsemantic-based request summarizationï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨ LLMs å¯¹ç­–ç•¥å…è®¸çš„è¯·æ±‚è¿›è¡Œç²¾ç¡®ç‰¹å¾åŒ–æè¿°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡è‡ªåŠ¨åŒ–ç”Ÿæˆä»å­˜åœ¨å±€é™æ€§ï¼Œä½†å°† LLMs ä¸ç¬¦å·åŒ–æ–¹æ³•ï¼ˆsymbolic approachesï¼‰ç»“åˆåœ¨å¢å¼ºç­–ç•¥åˆ†æå’Œç†è§£æ–¹é¢å±•ç°äº†æ˜¾è‘—çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.SE",
      "comment": "20 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20692v1",
      "published_date": "2025-10-23 16:06:15 UTC",
      "updated_date": "2025-10-23 16:06:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:07.210422+00:00"
    },
    {
      "arxiv_id": "2510.20691v2",
      "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs",
      "title_zh": "å…ˆè§„åˆ’ï¼Œå†æ£€ç´¢ï¼šå¼ºåŒ–å­¦ä¹ å¼•å¯¼çš„çŸ¥è¯†å›¾è°±å¤æ‚æ¨ç†",
      "authors": [
        "Yanlin Song",
        "Ben Liu",
        "VÃ­ctor GutiÃ©rrez-Basulto",
        "Zhiwei Hu",
        "Qianqian Xie",
        "Min Peng",
        "Sophia Ananiadou",
        "Jeff Z. Pan"
      ],
      "abstract": "Knowledge Graph Question Answering aims to answer natural language questions by reasoning over structured knowledge graphs. While large language models have advanced KGQA through their strong reasoning capabilities, existing methods continue to struggle to fully exploit both the rich knowledge encoded in KGs and the reasoning capabilities of LLMs, particularly in complex scenarios. They often assume complete KG coverage and lack mechanisms to judge when external information is needed, and their reasoning remains locally myopic, failing to maintain coherent multi-step planning, leading to reasoning failures even when relevant knowledge exists. We propose Graph-RFT, a novel two-stage reinforcement fine-tuning KGQA framework with a 'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to perform autonomous planning and adaptive retrieval scheduling across KG and web sources under incomplete knowledge conditions. Graph-RFT introduces a chain-of-thought fine-tuning method with a customized plan-retrieval dataset activates structured reasoning and resolves the GRPO cold-start problem. It then introduces a novel plan-retrieval guided reinforcement learning process integrates explicit planning and retrieval actions with a multi-reward design, enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired planning module to decompose complex questions into ordered subquestions, and logical expression to guide tool invocation for globally consistent multi-step reasoning. This reasoning retrieval process is optimized with a multi-reward combining outcome and retrieval specific signals, enabling the model to learn when and how to combine KG and web retrieval effectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Graph-RFTï¼Œä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ å¾®è°ƒ(Reinforcement Fine-tuning)çš„çŸ¥è¯†å›¾è°±é—®ç­”(KGQA)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸‹æ— æ³•å……åˆ†åˆ©ç”¨çŸ¥è¯†å›¾è°±(KG)ä¿¡æ¯ä¸”ç¼ºä¹å…¨å±€è§„åˆ’çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨â€œå…ˆè§„åˆ’ï¼Œååœ¨æ€è€ƒä¸­æ£€ç´¢KGä¸ç½‘é¡µâ€(plan-KGsearch-and-Websearch-during-think)çš„èŒƒå¼ï¼Œä½¿å¤§è¯­è¨€æ¨¡å‹(LLMs)èƒ½å¤Ÿåœ¨çŸ¥è¯†ä¸å®Œæ•´çš„æƒ…å†µä¸‹è¿›è¡Œè‡ªä¸»è§„åˆ’å’Œè‡ªé€‚åº”æ£€ç´¢ã€‚é€šè¿‡å¼•å…¥é“¾å¼æ€ç»´(Chain-of-Thought)å¾®è°ƒæ–¹æ³•ï¼ŒGraph-RFTæ¿€æ´»äº†ç»“æ„åŒ–æ¨ç†èƒ½åŠ›å¹¶æœ‰æ•ˆè§£å†³äº†GRPOç®—æ³•çš„å†·å¯åŠ¨é—®é¢˜ã€‚è¯¥ç³»ç»Ÿè¿›ä¸€æ­¥ç»“åˆç¬›å¡å°”å¯å‘å¼è§„åˆ’æ¨¡å—(Cartesian-inspired planning module)å°†å¤æ‚é—®é¢˜åˆ†è§£ï¼Œå¹¶åˆ©ç”¨å¤šå¥–åŠ±æœºåˆ¶(multi-reward)ä¼˜åŒ–çš„å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹æ¥ç²¾ç¡®åè°ƒKGå’Œç½‘ç»œæ£€ç´¢ã€‚è¿™ç§é€»è¾‘é©±åŠ¨çš„æ£€ç´¢è¿‡ç¨‹ç¡®ä¿äº†å¤šæ­¥æ¨ç†çš„å…¨å±€ä¸€è‡´æ€§ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤æ‚çŸ¥è¯†ç¯å¢ƒä¸‹çš„æ¨ç†æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20691v2",
      "published_date": "2025-10-23 16:04:13 UTC",
      "updated_date": "2025-10-27 07:30:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:09.469901+00:00"
    },
    {
      "arxiv_id": "2510.20690v2",
      "title": "Neural Diversity Regularizes Hallucinations in Language Models",
      "title_zh": "ç¥ç»å¤šæ ·æ€§æŠ‘åˆ¶è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰",
      "authors": [
        "Kushal Chakrabarti",
        "Nirmal Balachundhar"
      ],
      "abstract": "Language models continue to hallucinate despite increases in parameters, compute, and data. We propose neural diversity -- decorrelated parallel representations -- as a principled mechanism that reduces hallucination rates at fixed parameter and data budgets. While existing mitigation strategies largely target accuracy, we provide the first formal tail bounds for hallucination probability in ensembled language models, reframing it as a second-moment reliability problem and explaining 94.3% of empirical reliability variation seen across parallel configurations. We introduce ND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA adapters with Barlow Twins regularization, and reduce hallucinations by up to 25.6% (and 14.6% on average) while preserving general accuracy. Ablations show LoRA adapters and regularization act synergistically, causal interventions prove neurodiversity as the mediating factor and correlational studies indicate scale: a 0.1% neural correlation increase is associated with a 3.8% hallucination increase. Finally, task-dependent optimality emerges: different tasks require different optimal amounts of neurodiversity. Together, our results highlight neural diversity as a third axis of scaling -- orthogonal to parameters and data -- to improve the reliability of language models at fixed budgets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­è¨€æ¨¡å‹æŒç»­å­˜åœ¨çš„å¹»è§‰é—®é¢˜ï¼Œæå‡ºäº†ç¥ç»å¤šæ ·æ€§ï¼ˆNeural Diversityï¼Œå³å»ç›¸å…³çš„å¹¶è¡Œè¡¨ç¤ºï¼‰ä½œä¸ºä¸€ç§åœ¨å›ºå®šå‚æ•°å’Œæ•°æ®é¢„ç®—ä¸‹é™ä½å¹»è§‰ç‡çš„æœºåˆ¶ã€‚ä½œè€…é¦–æ¬¡ä¸ºé›†æˆè¯­è¨€æ¨¡å‹çš„å¹»è§‰æ¦‚ç‡æä¾›äº†å½¢å¼åŒ–çš„å°¾éƒ¨è¾¹ç•Œï¼ˆtail boundsï¼‰ï¼Œå¹¶å°†å…¶é‡æ–°å®šä¹‰ä¸ºäºŒé˜¶çŸ©å¯é æ€§é—®é¢˜ï¼ˆsecond-moment reliability problemï¼‰ï¼Œè§£é‡Šäº†å¹¶è¡Œé…ç½®ä¸­ 94.3% çš„å¯é æ€§å˜åŒ–ã€‚ç ”ç©¶å¼•å…¥äº† ND-LoRA (Neural Diversity Low-Rank Adaptation)ï¼Œé€šè¿‡ç»“åˆå¹¶è¡Œ LoRA é€‚é…å™¨ä¸ Barlow Twins æ­£åˆ™åŒ–ï¼Œåœ¨ä¿æŒå‡†ç¡®æ€§çš„å‰æä¸‹å°†å¹»è§‰ç‡å¹³å‡é™ä½äº† 14.6%ï¼Œæœ€é«˜å¯è¾¾ 25.6%ã€‚å®éªŒè¡¨æ˜ç¥ç»ç›¸å…³æ€§ä¸å¹»è§‰ç‡æ˜¾è‘—æ­£ç›¸å…³ï¼Œç¥ç»ç›¸å…³æ€§æ¯å¢åŠ  0.1% ä¼šå¯¼è‡´å¹»è§‰å¢åŠ  3.8%ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°ä¸åŒä»»åŠ¡å¯¹ç¥ç»å¤šæ ·æ€§çš„æœ€ä¼˜éœ€æ±‚å­˜åœ¨ä»»åŠ¡ä¾èµ–æ€§ã€‚è¯¥å·¥ä½œå¼ºè°ƒäº†ç¥ç»å¤šæ ·æ€§æ˜¯å‚æ•°å’Œæ•°æ®ä¹‹å¤–çš„ç¬¬ä¸‰ä¸ªç¼©æ”¾è½´ï¼ˆscaling axisï¼‰ï¼Œä¸ºæå‡è¯­è¨€æ¨¡å‹çš„å¯é æ€§æä¾›äº†é‡è¦è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20690v2",
      "published_date": "2025-10-23 16:03:07 UTC",
      "updated_date": "2025-12-10 18:42:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:20.290437+00:00"
    },
    {
      "arxiv_id": "2510.20683v1",
      "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks",
      "title_zh": "åŸºäºè„‰å†²ç¥ç»ç½‘ç»œçš„å¯æ‰©å±•ã€å› æœä¸”é«˜èƒ½æ•ˆç¥ç»è§£ç æ¡†æ¶",
      "authors": [
        "Georgios Mentzelopoulos",
        "Ioannis Asmanis",
        "Konrad P. Kording",
        "Eva L. Dyer",
        "Kostas Daniilidis",
        "Flavia Vitale"
      ],
      "abstract": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è„‘æœºæ¥å£ (BCIs) é¢†åŸŸä¸­ç°æœ‰ç¥ç»è§£ç å™¨åœ¨å®æ—¶æ€§ã€æ³›åŒ–èƒ½åŠ›ä¸åŠŸè€—ä¹‹é—´éš¾ä»¥å¹³è¡¡çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º Spikachu çš„å¯æ‰©å±•ã€å› æœä¸”é«˜èƒ½æ•ˆçš„è„‰å†²ç¥ç»ç½‘ç»œ (Spiking Neural Networks, SNNs) è§£ç æ¡†æ¶ã€‚Spikachu é€šè¿‡å°†åˆ†ç®±è„‰å†² (binned spikes) ç›´æ¥æŠ•å½±åˆ°å…±äº«æ½œç©ºé—´ï¼Œå¹¶åˆ©ç”¨è‡ªé€‚åº”è„‰å†²æ¨¡å—æå–æ—¶åºç‰¹å¾ï¼Œä»è€Œå®ç°ç²¾å‡†çš„è¡Œä¸ºé¢„æµ‹ã€‚åœ¨å¤§è§„æ¨¡å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ¶µç›– 6 åªéäººçµé•¿ç±»åŠ¨ç‰©ã€å…±è®¡ 43 å°æ—¶çš„ 113 æ¬¡è®°å½•ä¼šè¯è¿›è¡ŒéªŒè¯ï¼Œå…¶è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„å› æœåŸºå‡†æ¨¡å‹ï¼Œä¸”èƒ½è€—å¤§å¹…é™ä½äº† 2.26 è‡³ 418.81 å€ã€‚æ­¤å¤–ï¼ŒSpikachu å±•ç°äº†å“è¶Šçš„æ‰©å±•æ€§ï¼Œèƒ½å¤Ÿé€šè¿‡è·¨ä¼šè¯å’Œè·¨å—è¯•è€…çš„è®­ç»ƒå®ç°å‘æ–°å—è¯•è€…æˆ–ä»»åŠ¡çš„å°æ ·æœ¬è¿ç§» (few-shot transfer)ã€‚è¯¥æ¡†æ¶ä¸ºå¼€å‘å…¼å®¹åœ¨çº¿å®æ—¶è¿è¡Œã€ä½åŠŸè€—ä¸”å…·å¤‡é«˜åº¦ç«äº‰åŠ›çš„ç¥ç»è§£ç ç³»ç»Ÿæä¾›äº†ä¸€ä¸ªæå…·å‰æ™¯çš„å¯æ‰©å±•æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20683v1",
      "published_date": "2025-10-23 15:55:45 UTC",
      "updated_date": "2025-10-23 15:55:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:19.876787+00:00"
    },
    {
      "arxiv_id": "2510.20677v1",
      "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice Conversion",
      "title_zh": "R2-SVCï¼šè¿ˆå‘çœŸå®åœºæ™¯ä¸‹é²æ£’ä¸”å…·è¡¨ç°åŠ›çš„é›¶æ ·æœ¬æ­Œå£°è½¬æ¢",
      "authors": [
        "Junjie Zheng",
        "Gongyu Chen",
        "Chaofan Ding",
        "Zihao Chen"
      ],
      "abstract": "In real-world singing voice conversion (SVC) applications, environmental noise and the demand for expressive output pose significant challenges. Conventional methods, however, are typically designed without accounting for real deployment scenarios, as both training and inference usually rely on clean data. This mismatch hinders practical use, given the inevitable presence of diverse noise sources and artifacts from music separation. To tackle these issues, we propose R2-SVC, a robust and expressive SVC framework. First, we introduce simulation-based robustness enhancement through random fundamental frequency ($F_0$) perturbations and music separation artifact simulations (e.g., reverberation, echo), substantially improving performance under noisy conditions. Second, we enrich speaker representation using domain-specific singing data: alongside clean vocals, we incorporate DNSMOS-filtered separated vocals and public singing corpora, enabling the model to preserve speaker timbre while capturing singing style nuances. Third, we integrate the Neural Source-Filter (NSF) model to explicitly represent harmonic and noise components, enhancing the naturalness and controllability of converted singing. R2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both clean and noisy conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†R2-SVCï¼Œä¸€ç§æ—¨åœ¨è§£å†³çœŸå®ä¸–ç•Œç¯å¢ƒä¸‹é²æ£’æ€§ä¸è¡¨ç°åŠ›æŒ‘æˆ˜çš„é›¶æ ·æœ¬æ­Œå£°è½¬æ¢(Zero-shot Singing Voice Conversion)æ¡†æ¶ã€‚é’ˆå¯¹ç°å®åº”ç”¨ä¸­å¸¸è§çš„ç¯å¢ƒå™ªå£°åŠéŸ³ä¹åˆ†ç¦»äº§ç”Ÿçš„ä¼ªå½±é—®é¢˜ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†åŸºäºæ¨¡æ‹Ÿçš„é²æ£’æ€§å¢å¼ºç­–ç•¥ï¼Œé€šè¿‡éšæœºåŸºé¢‘($F_0$)æ‰°åŠ¨å’Œæ··å“ã€å›å£°æ¨¡æ‹Ÿï¼Œæ˜¾è‘—æå‡äº†åœ¨å¤æ‚æ¡ä»¶ä¸‹çš„æ€§èƒ½ã€‚ä¸ºäº†ä¸°å¯Œè¯´è¯äººè¡¨ç¤ºï¼Œç ”ç©¶ç»“åˆäº†DNSMOSè¿‡æ»¤çš„åˆ†ç¦»äººå£°åŠå¤šç§æ­Œå£°è¯­æ–™åº“ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç²¾ç¡®æå–éŸ³è‰²å¹¶æ•æ‰æ­Œå£°é£æ ¼çš„ç»†å¾®å·®åˆ«ã€‚æ­¤å¤–ï¼Œé€šè¿‡é›†æˆç¥ç»æºæ»¤æ³¢å™¨(Neural Source-Filter, NSF)æ¨¡å‹æ¥æ˜¾å¼è¡¨ç¤ºè°æ³¢ä¸å™ªå£°åˆ†é‡ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†è½¬æ¢æ­Œå£°çš„è‡ªç„¶åº¦ä¸å¯æ§æ€§ã€‚å®éªŒè¯æ˜ï¼ŒR2-SVCåœ¨çº¯å‡€å’Œå˜ˆæ‚çš„å¤šç§SVCåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†å½“å‰æœ€å…ˆè¿›(State-of-the-art)çš„æ•ˆæœã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20677v1",
      "published_date": "2025-10-23 15:52:03 UTC",
      "updated_date": "2025-10-23 15:52:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:19.181499+00:00"
    },
    {
      "arxiv_id": "2510.20671v2",
      "title": "GRACE: Graph Neural Networks for Locus-of-Care Prediction under Extreme Class Imbalance",
      "title_zh": "GRACEï¼šæç«¯ç±»åˆ«ä¸å¹³è¡¡ä¸‹çš„åŒ»ç–—åœºæ‰€é¢„æµ‹å›¾ç¥ç»ç½‘ç»œ",
      "authors": [
        "Subham Kumar",
        "Lekhansh Shukla",
        "Animesh Mukherjee",
        "Koustav Rudra",
        "Prakrithi Shivaprakash"
      ],
      "abstract": "Determining the appropriate locus of care for addiction patients is one of the most critical clinical decisions that affects patient treatment outcomes and effective use of resources. With a lack of sufficient specialized treatment resources, such as inpatient beds or staff, there is an unmet need to develop an automated framework for the same. Current decision-making approaches suffer from severe class imbalances in addiction datasets. To address this limitation, we propose a novel graph neural network (GRACE) framework that formalizes locus of care prediction as a structured learning problem. In addition, we propose a new approach of obtaining an unbiased meta-graph to train a GNN to overcome the class imbalance problem. Experimental results with real-world data show an improvement of 11-35% in terms of the F1 score of the minority class over competitive baselines. Further, if we jointly finetune the base embedding fed into GRACE as input together with the rest of the GNN component of GRACE, there is a remarkable boost of 15.8% in performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æˆç˜¾æ‚£è€…æ²»ç–—åœºæ‰€é¢„æµ‹(Locus-of-care prediction)ä¸­å­˜åœ¨çš„æç«¯ç±»åˆ«å¤±è¡¡(Class Imbalance)æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºGRACEçš„æ–°å‹å›¾ç¥ç»ç½‘ç»œ(Graph Neural Network)æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†é¢„æµ‹ä»»åŠ¡è½¬åŒ–ä¸ºç»“æ„åŒ–å­¦ä¹ é—®é¢˜ï¼Œå¹¶å¼•å…¥ä¸€ç§è·å–æ— åå…ƒå›¾(Meta-graph)çš„æ–°æ–¹æ³•æ¥è®­ç»ƒGNNï¼Œä»è€Œæœ‰æ•ˆå…‹æœäº†æˆç˜¾æ•°æ®é›†ä¸­å¸¸è§çš„æ ·æœ¬åˆ†å¸ƒä¸å‡é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼ŒGRACEåœ¨å°‘æ•°ç±»åˆ«çš„F1åˆ†æ•°(F1 score)æ–¹é¢æ¯”ç«äº‰åŸºçº¿æ¨¡å‹æé«˜äº†11-35%ã€‚æ­¤å¤–ï¼Œé€šè¿‡å°†è¾“å…¥çš„åŸºç¡€åµŒå…¥(Base embedding)ä¸æ¨¡å‹çš„GNNç»„ä»¶è¿›è¡Œè”åˆå¾®è°ƒ(Jointly finetune)ï¼Œç³»ç»Ÿæ€§èƒ½è¿˜è·å¾—äº†15.8%çš„æ˜¾è‘—æå‡ã€‚è¯¥ç ”ç©¶ä¸ºä¸´åºŠå†³ç­–è‡ªåŠ¨åŒ–å’ŒåŒ»ç–—èµ„æºçš„æœ‰æ•ˆåˆ©ç”¨æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸“ä¸šæ²»ç–—èµ„æºç¨€ç¼ºçš„èƒŒæ™¯ä¸‹å…·æœ‰æé«˜çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20671v2",
      "published_date": "2025-10-23 15:48:01 UTC",
      "updated_date": "2026-01-17 09:18:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:26.083566+00:00"
    },
    {
      "arxiv_id": "2510.20665v1",
      "title": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models",
      "title_zh": "æ¨ç†ä¹‹å½¢ï¼šå¤§è¯­è¨€æ¨¡å‹æ¨ç†è½¨è¿¹çš„æ‹“æ‰‘åˆ†æ",
      "authors": [
        "Xue Wen Tan",
        "Nathaniel Tan",
        "Galen Lee",
        "Stanley Kok"
      ],
      "abstract": "Evaluating the quality of reasoning traces from large language models remains understudied, labor-intensive, and unreliable: current practice relies on expert rubrics, manual annotation, and slow pairwise judgments. Automated efforts are dominated by graph-based proxies that quantify structural connectivity but do not clarify what constitutes high-quality reasoning; such abstractions can be overly simplistic for inherently complex processes. We introduce a topological data analysis (TDA)-based evaluation framework that captures the geometry of reasoning traces and enables label-efficient, automated assessment. In our empirical study, topological features yield substantially higher predictive power for assessing reasoning quality than standard graph metrics, suggesting that effective reasoning is better captured by higher-dimensional geometric structures rather than purely relational graphs. We further show that a compact, stable set of topological features reliably indicates trace quality, offering a practical signal for future reinforcement learning algorithms.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†è½¨è¿¹è¯„ä¼°ä¸­å­˜åœ¨çš„åŠ³åŠ¨å¯†é›†ã€ä¸å¯é ä»¥åŠç°æœ‰å›¾è¯„ä¼°æŒ‡æ ‡(graph-based proxies)è¿‡äºç®€åŒ–ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ‹“æ‰‘æ•°æ®åˆ†æ(TDA)çš„è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•è·æ¨ç†è½¨è¿¹çš„å‡ ä½•ç»“æ„(geometry of reasoning traces)ï¼Œå®ç°äº†æ ‡ç­¾é«˜æ•ˆä¸”è‡ªåŠ¨åŒ–çš„è´¨é‡è¯„ä¼°ã€‚å®è¯ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œæ‹“æ‰‘ç‰¹å¾åœ¨è¯„ä¼°æ¨ç†è´¨é‡æ–¹é¢çš„é¢„æµ‹èƒ½åŠ›æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å›¾æŒ‡æ ‡ï¼Œè¿™è¡¨æ˜é«˜ç»´å‡ ä½•ç»“æ„æ¯”å•çº¯çš„å…³ç³»å›¾æ›´èƒ½æœ‰æ•ˆæ•æ‰å¤æ‚çš„æ¨ç†è¿‡ç¨‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†ä¸€ç»„ç´§å‡‘ä¸”ç¨³å®šçš„æ‹“æ‰‘ç‰¹å¾èƒ½å¯é åœ°æŒ‡ç¤ºæ¨ç†è½¨è¿¹è´¨é‡ï¼Œä»è€Œä¸ºæœªæ¥ä¼˜åŒ–æ¨ç†èƒ½åŠ›çš„å¼ºåŒ–å­¦ä¹ (reinforcement learning)ç®—æ³•æä¾›äº†å…·æœ‰å®ç”¨ä»·å€¼çš„åé¦ˆä¿¡å·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20665v1",
      "published_date": "2025-10-23 15:43:43 UTC",
      "updated_date": "2025-10-23 15:43:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:24.593219+00:00"
    },
    {
      "arxiv_id": "2510.20653v1",
      "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection",
      "title_zh": "å¯»æ‰¾æœ€ä½³å¹³è¡¡ç‚¹ï¼šå¤§è¯­è¨€æ¨¡å‹æ¨ç†æ—¶åæ€ä¸­è´¨é‡ã€æˆæœ¬ä¸é€Ÿåº¦çš„æƒè¡¡",
      "authors": [
        "Jack Butler",
        "Nikita Kozodoi",
        "Zainab Afolabi",
        "Brian Tyacke",
        "Gaiar Baimuratov"
      ],
      "abstract": "As Large Language Models (LLMs) continue to evolve, practitioners face increasing options for enhancing inference-time performance without model retraining, including budget tuning and multi-step techniques like self-reflection. While these methods improve output quality, they create complex trade-offs among accuracy, cost, and latency that remain poorly understood across different domains. This paper systematically compares self-reflection and budget tuning across mathematical reasoning and translation tasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and Mistral families, along with other models under varying reflection depths and compute budgets to derive Pareto optimal performance frontiers. Our analysis reveals substantial domain dependent variation in self-reflection effectiveness, with performance gains up to 220\\% in mathematical reasoning. We further investigate how reflection round depth and feedback mechanism quality influence performance across model families. To validate our findings in a real-world setting, we deploy a self-reflection enhanced marketing content localisation system at Lounge by Zalando, where it shows market-dependent effectiveness, reinforcing the importance of domain specific evaluation when deploying these techniques. Our results provide actionable guidance for selecting optimal inference strategies given specific domains and resource constraints. We open source our self-reflection implementation for reproducibility at https://github.com/aws-samples/sample-genai-reflection-for-bedrock.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿæ¢è®¨äº†åœ¨æ¨ç†é˜¶æ®µæå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)æ€§èƒ½çš„ç­–ç•¥ï¼Œé‡ç‚¹åˆ†æäº†Self-reflectionå’ŒBudget tuningåœ¨è´¨é‡ã€æˆæœ¬å’Œé€Ÿåº¦ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚ç ”ç©¶é€šè¿‡æ•°å­¦æ¨ç†å’Œç¿»è¯‘ä»»åŠ¡ï¼Œè¯„ä¼°äº†Anthropic Claudeã€Amazon NovaåŠMistralç­‰ç³»åˆ—æ¨¡å‹åœ¨ä¸åŒReflection depthså’ŒCompute budgetsä¸‹çš„è¡¨ç°ï¼Œå¹¶æ¨å¯¼å‡ºPareto optimalæ€§èƒ½è¾¹ç•Œã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSelf-reflectionçš„æœ‰æ•ˆæ€§å‘ˆç°å‡ºæ˜¾è‘—çš„é¢†åŸŸä¾èµ–æ€§ï¼Œåœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­æ€§èƒ½æå‡é«˜è¾¾220%ã€‚ç ”ç©¶è¿›ä¸€æ­¥åˆ†æäº†Reflection round depthå’ŒFeedback mechanismè´¨é‡å¯¹ä¸åŒæ¨¡å‹å®¶æ—æ€§èƒ½çš„å…·ä½“å½±å“ã€‚æ­¤å¤–ï¼Œä½œè€…åœ¨Lounge by Zalandoçš„è¥é”€å†…å®¹æœ¬åœ°åŒ–ç³»ç»Ÿä¸­éªŒè¯äº†è¯¥æ–¹æ³•çš„å®ç”¨æ€§ï¼Œå¼ºè°ƒäº†é¢†åŸŸç‰¹å®šè¯„ä¼°åœ¨éƒ¨ç½²æ­¤ç±»æŠ€æœ¯æ—¶çš„é‡è¦æ€§ã€‚è¯¥æˆæœä¸ºåœ¨ç‰¹å®šé¢†åŸŸå’Œèµ„æºçº¦æŸä¸‹é€‰æ‹©æœ€ä¼˜æ¨ç†ç­–ç•¥æä¾›äº†å®è·µæŒ‡å¯¼ï¼Œå¹¶å¼€æºäº†å…¶Self-reflectionå®ç°ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20653v1",
      "published_date": "2025-10-23 15:26:18 UTC",
      "updated_date": "2025-10-23 15:26:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:30.686327+00:00"
    },
    {
      "arxiv_id": "2510.20647v2",
      "title": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI",
      "title_zh": "æ¨ç†é€šç”¨è¯­ï¼šå¤šè¯­è¨€äººå·¥æ™ºèƒ½çš„åŒåˆƒå‰‘",
      "authors": [
        "Alan Saji",
        "Raj Dabre",
        "Anoop Kunchukuttan",
        "Ratish Puduppully"
      ],
      "abstract": "Large Reasoning Models (LRMs) achieve strong performance on mathematical, scientific, and other question-answering tasks, but their multilingual reasoning abilities remain underexplored. When presented with non-English questions, LRMs often default to reasoning in English, raising concerns about interpretability and the handling of linguistic and cultural nuances. We systematically compare an LRM's reasoning in English versus the language of the question. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond measuring answer accuracy, we also analyze cognitive attributes in the reasoning traces. We find that English reasoning traces exhibit a substantially higher presence of these cognitive behaviors, and that reasoning in English generally yields higher final-answer accuracy, with the performance gap increasing as tasks become more complex. However, this English-centric strategy is susceptible to a key failure mode - getting \"Lost in Translation,\" where translation steps lead to errors that would have been avoided by question's language reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹æ¨ç†æ¨¡å‹ (Large Reasoning Models, LRMs) åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„æ¨ç†èƒ½åŠ›ï¼Œé‡ç‚¹åˆ†æäº†æ¨¡å‹åœ¨å¤„ç†éè‹±è¯­é—®é¢˜æ—¶å€¾å‘äºä½¿ç”¨è‹±è¯­è¿›è¡Œæ¨ç†çš„ç°è±¡ã€‚é€šè¿‡åœ¨ MGSM å’Œ GPQA Diamond ä»»åŠ¡ä¸Šçš„ç³»ç»Ÿå¯¹æ¯”ï¼Œç ”ç©¶è¯„ä¼°äº†æ¨¡å‹åˆ†åˆ«ä½¿ç”¨è‹±è¯­å’Œé—®é¢˜åŸæ–‡è¯­è¨€è¿›è¡Œæ¨ç†çš„æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè‹±è¯­æ¨ç†é“¾å±•ç°å‡ºæ›´ä¸°å¯Œçš„è®¤çŸ¥è¡Œä¸º (cognitive behaviors)ï¼Œä¸”å…¶æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®ç‡é€šå¸¸æ›´é«˜ï¼Œè¿™ç§æ€§èƒ½å·®è·éšä»»åŠ¡å¤æ‚åº¦çš„æå‡è€Œè¿›ä¸€æ­¥æ‰©å¤§ã€‚ç„¶è€Œï¼Œè¿™ç§ä»¥è‹±è¯­ä¸ºæ ¸å¿ƒçš„ç­–ç•¥ä¹Ÿå¸¦æ¥äº†â€œè¿·å¤±åœ¨ç¿»è¯‘ä¸­â€ (Lost in Translation) çš„å¤±æ•ˆæ¨¡å¼ï¼Œå³ç¿»è¯‘è¿‡ç¨‹ä¸­çš„è¯¯å·®å¯èƒ½å¯¼è‡´æœ¬å¯é¿å…çš„é”™è¯¯ã€‚è¯¥å‘ç°æ­ç¤ºäº†å¤šè¯­è¨€ AI åœ¨å¤„ç†è¯­è¨€æ–‡åŒ–ç»†å¾®å·®åˆ«ä¸æ¨ç†æ•ˆç‡ä¹‹é—´çš„å¤æ‚æƒè¡¡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 13 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.20647v2",
      "published_date": "2025-10-23 15:22:00 UTC",
      "updated_date": "2025-12-22 09:52:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:33.988109+00:00"
    },
    {
      "arxiv_id": "2510.20641v1",
      "title": "Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges",
      "title_zh": "å°†æœºå™¨å­¦ä¹ é›†æˆåˆ° BDIï¼ˆä¿¡å¿µ-æ¬²æœ›-æ„å›¾ï¼‰æ™ºèƒ½ä½“ï¼šç ”ç©¶ç°çŠ¶ä¸æŒ‘æˆ˜",
      "authors": [
        "Andrea Agiollo",
        "Andrea Omicini"
      ],
      "abstract": "Thanks to the remarkable human-like capabilities of machine learning (ML) models in perceptual and cognitive tasks, frameworks integrating ML within rational agent architectures are gaining traction. Yet, the landscape remains fragmented and incoherent, often focusing on embedding ML into generic agent containers while overlooking the expressive power of rational architectures--such as Belief-Desire-Intention (BDI) agents. This paper presents a fine-grained systematisation of existing approaches, using the BDI paradigm as a reference. Our analysis illustrates the fast-evolving literature on rational agents enhanced by ML, and identifies key research opportunities and open challenges for designing effective rational ML agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å°†æœºå™¨å­¦ä¹  (Machine Learning) é›†æˆåˆ°ç†æ€§æ™ºèƒ½ä½“æ¶æ„ï¼Œç‰¹åˆ«æ˜¯ä¿¡å¿µ-æ¬²æœ›-æ„å›¾ (Belief-Desire-Intention, BDI) æ™ºèƒ½ä½“ä¸­çš„ç°çŠ¶ä¸æŒ‘æˆ˜ã€‚å°½ç®¡æœºå™¨å­¦ä¹ åœ¨æ„ŸçŸ¥å’Œè®¤çŸ¥ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç›®å‰å°†ä¸¤è€…ç»“åˆçš„ç ”ç©¶ä»æ˜¾ç ´ç¢ï¼Œå¾€å¾€åœ¨åµŒå…¥æ¨¡å‹æ—¶å¿½ç•¥äº†ç†æ€§æ¶æ„çš„è¡¨è¾¾èƒ½åŠ›ã€‚æœ¬æ–‡ä»¥ BDI èŒƒå¼ä¸ºåŸºå‡†ï¼Œå¯¹ç°æœ‰é›†æˆæ–¹æ³•è¿›è¡Œäº†ç»†ç²’åº¦çš„ç³»ç»ŸåŒ–åˆ†ç±»å’Œç»¼è¿°ã€‚é€šè¿‡å¯¹ç›¸å…³æ–‡çŒ®çš„æ·±å…¥åˆ†æï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†å—æœºå™¨å­¦ä¹ å¢å¼ºçš„ç†æ€§æ™ºèƒ½ä½“çš„æ¼”è¿›è¶‹åŠ¿ã€‚æœ€åï¼Œè®ºæ–‡è¯†åˆ«äº†è®¾è®¡é«˜æ•ˆç†æ€§æœºå™¨å­¦ä¹ æ™ºèƒ½ä½“æ‰€é¢ä¸´çš„å…³é”®ç ”ç©¶æœºé‡ä¸å¼€æ”¾æ€§æŒ‘æˆ˜ï¼Œä¸ºè¯¥é¢†åŸŸçš„æœªæ¥å‘å±•æä¾›äº†ç†è®ºæ¡†æ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20641v1",
      "published_date": "2025-10-23 15:15:45 UTC",
      "updated_date": "2025-10-23 15:15:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:45.475493+00:00"
    },
    {
      "arxiv_id": "2510.20636v1",
      "title": "Fluidity Index: Next-Generation Super-intelligence Benchmarks",
      "title_zh": "Fluidity Indexï¼šä¸‹ä¸€ä»£è¶…æ™ºèƒ½åŸºå‡†",
      "authors": [
        "Eric Ngoiya",
        "Tianshu Bao"
      ],
      "abstract": "This paper introduces the Fluidity Index (FI) to quantify model adaptability in dynamic, scaling environments. The benchmark evaluates response accuracy based on deviations in initial, current, and future environment states, assessing context switching and continuity. We distinguish between closed-ended and open-ended benchmarks, prioritizing closed-loop open-ended real-world benchmarks to test adaptability. The approach measures a model's ability to understand, predict, and adjust to state changes in scaling environments. A truly super-intelligent model should exhibit at least second-order adaptability, enabling self-sustained computation through digital replenishment for optimal fluidity.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Fluidity Index (FI)ï¼Œç”¨äºé‡åŒ–æ¨¡å‹åœ¨åŠ¨æ€ã€scaling environmentsä¸­çš„é€‚åº”èƒ½åŠ›ã€‚è¯¥benchmarké€šè¿‡è¯„ä¼°åˆå§‹ã€å½“å‰åŠæœªæ¥ç¯å¢ƒçŠ¶æ€çš„åå·®æ¥è¡¡é‡å“åº”å‡†ç¡®æ€§ï¼Œé‡ç‚¹è€ƒå¯Ÿæ¨¡å‹åœ¨context switchingå’Œè¿ç»­æ€§æ–¹é¢çš„è¡¨ç°ã€‚ç ”ç©¶åŒºåˆ†äº†å°é—­å¼ä¸å¼€æ”¾å¼è¯„ä¼°ï¼Œå¹¶ä¼˜å…ˆé‡‡ç”¨closed-loop open-ended real-world benchmarksæ¥æ·±åº¦æµ‹è¯•é€‚åº”æ€§ã€‚è¯¥æ–¹æ³•æ ¸å¿ƒåœ¨äºæµ‹é‡æ¨¡å‹å¯¹scaling environmentsä¸­çŠ¶æ€å˜åŒ–çš„ç†è§£ã€é¢„æµ‹å’Œè°ƒæ•´èƒ½åŠ›ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºçœŸæ­£çš„è¶…çº§æ™ºèƒ½æ¨¡å‹åº”è‡³å°‘å…·å¤‡second-order adaptabilityï¼Œèƒ½å¤Ÿé€šè¿‡digital replenishmentå®ç°è‡ªæˆ‘ç»´æŒè®¡ç®—ï¼Œä»è€Œè¾¾åˆ°optimal fluidityã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12",
      "pdf_url": "https://arxiv.org/pdf/2510.20636v1",
      "published_date": "2025-10-23 15:05:23 UTC",
      "updated_date": "2025-10-23 15:05:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:48.475657+00:00"
    },
    {
      "arxiv_id": "2510.20635v1",
      "title": "Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model",
      "title_zh": "è‹¹æœä¸ºä½•è½åœ°ï¼šè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„å¥½å¥‡å¿ƒ",
      "authors": [
        "Haoyu Wang",
        "Sihang Jiang",
        "Yuyan Chen",
        "Yitong Wang",
        "Yanghua Xiao"
      ],
      "abstract": "Curiosity serves as a pivotal conduit for human beings to discover and learn new knowledge. Recent advancements of large language models (LLMs) in natural language processing have sparked discussions regarding whether these models possess capability of curiosity-driven learning akin to humans. In this paper, starting from the human curiosity assessment questionnaire Five-Dimensional Curiosity scale Revised (5DCR), we design a comprehensive evaluation framework that covers dimensions such as Information Seeking, Thrill Seeking, and Social Curiosity to assess the extent of curiosity exhibited by LLMs. The results demonstrate that LLMs exhibit a stronger thirst for knowledge than humans but still tend to make conservative choices when faced with uncertain environments. We further investigated the relationship between curiosity and thinking of LLMs, confirming that curious behaviors can enhance the model's reasoning and active learning abilities. These findings suggest that LLMs have the potential to exhibit curiosity similar to that of humans, providing experimental support for the future development of learning capabilities and innovative research in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)æ˜¯å¦å…·å¤‡ç±»ä¼¼äºäººç±»çš„å¥½å¥‡å¿ƒé©±åŠ¨å­¦ä¹ èƒ½åŠ›ï¼Œå¹¶åŸºäºäººç±»å¥½å¥‡å¿ƒè¯„ä¼°é‡è¡¨Five-Dimensional Curiosity scale Revised (5DCR)è®¾è®¡äº†ä¸€å¥—ç»¼åˆè¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ¶µç›–äº†ä¿¡æ¯å¯»æ±‚(Information Seeking)ã€åˆºæ¿€å¯»æ±‚(Thrill Seeking)å’Œç¤¾äº¤å¥½å¥‡(Social Curiosity)ç­‰å¤šä¸ªç»´åº¦ï¼Œå¯¹å¤§è¯­è¨€æ¨¡å‹çš„å¥½å¥‡å¿ƒç¨‹åº¦è¿›è¡Œäº†å…¨é¢æµ‹è¯„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨çŸ¥è¯†æ¸´æœ›æ–¹é¢è¡¨ç°å‡ºæ¯”äººç±»æ›´å¼ºçš„å€¾å‘ï¼Œä½†åœ¨é¢å¯¹ä¸ç¡®å®šç¯å¢ƒæ—¶ï¼Œæ¨¡å‹å¾€å¾€å€¾å‘äºåšå‡ºä¿å®ˆçš„é€‰æ‹©ã€‚ç ”ç©¶è¿›ä¸€æ­¥åˆ†æäº†å¥½å¥‡å¿ƒä¸LLMsæ€ç»´ä¹‹é—´çš„å…³ç³»ï¼Œè¯å®äº†å¥½å¥‡è¡Œä¸ºèƒ½å¤Ÿæ˜¾è‘—å¢å¼ºæ¨¡å‹çš„æ¨ç†(reasoning)å’Œä¸»åŠ¨å­¦ä¹ (active learning)èƒ½åŠ›ã€‚è¿™äº›å‘ç°è¡¨æ˜LLMså…·æœ‰å±•ç°ç±»äººå¥½å¥‡å¿ƒçš„æ½œåŠ›ï¼Œä¸ºæœªæ¥å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ èƒ½åŠ›çš„æå‡å’Œåˆ›æ–°æ€§ç ”ç©¶æä¾›äº†å®éªŒæ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20635v1",
      "published_date": "2025-10-23 15:05:17 UTC",
      "updated_date": "2025-10-23 15:05:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:50.482892+00:00"
    },
    {
      "arxiv_id": "2510.20634v1",
      "title": "Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges",
      "title_zh": "æ·±åº¦å­¦ä¹ åœ¨ç‰™ç§‘å›¾åƒåˆ†æä¸­çš„åº”ç”¨ï¼šæ•°æ®é›†ã€æ–¹æ³•è®ºåŠæ–°å…´æŒ‘æˆ˜ç³»ç»Ÿç»¼è¿°",
      "authors": [
        "Zhenhuan Zhou",
        "Jingbo Zhu",
        "Yuchen Zhang",
        "Xiaohang Guan",
        "Peng Wang",
        "Tao Li"
      ],
      "abstract": "Efficient analysis and processing of dental images are crucial for dentists to achieve accurate diagnosis and optimal treatment planning. However, dental imaging inherently poses several challenges, such as low contrast, metallic artifacts, and variations in projection angles. Combined with the subjectivity arising from differences in clinicians' expertise, manual interpretation often proves time-consuming and prone to inconsistency. Artificial intelligence (AI)-based automated dental image analysis (DIA) offers a promising solution to these issues and has become an integral part of computer-aided dental diagnosis and treatment. Among various AI technologies, deep learning (DL) stands out as the most widely applied and influential approach due to its superior feature extraction and representation capabilities. To comprehensively summarize recent progress in this field, we focus on the two fundamental aspects of DL research-datasets and models. In this paper, we systematically review 260 studies on DL applications in DIA, including 49 papers on publicly available dental datasets and 211 papers on DL-based algorithms. We first introduce the basic concepts of dental imaging and summarize the characteristics and acquisition methods of existing datasets. Then, we present the foundational techniques of DL and categorize relevant models and algorithms according to different DIA tasks, analyzing their network architectures, optimization strategies, training methods, and performance. Furthermore, we summarize commonly used training and evaluation metrics in the DIA domain. Finally, we discuss the current challenges of existing research and outline potential future directions. We hope that this work provides a valuable and systematic reference for researchers in this field. All supplementary materials and detailed comparison tables will be made publicly available on GitHub.",
      "tldr_zh": "è¯¥è®ºæ–‡å¯¹ç‰™ç§‘å›¾åƒåˆ†æ(Dental Image Analysis, DIA)ä¸­çš„æ·±åº¦å­¦ä¹ (Deep Learning, DL)åº”ç”¨è¿›è¡Œäº†ç³»ç»Ÿæ€§ç»¼è¿°ï¼Œæ—¨åœ¨åº”å¯¹ä¼ ç»Ÿäººå·¥åˆ¤è¯»ä¸­å­˜åœ¨çš„ä½å¯¹æ¯”åº¦ã€é‡‘å±ä¼ªå½±åŠä¸»è§‚ä¸€è‡´æ€§å·®ç­‰æŒ‘æˆ˜ã€‚ä½œè€…ç³»ç»Ÿåœ°å›é¡¾äº†260é¡¹ç ”ç©¶ï¼Œè¯¦ç»†æ¶µç›–äº†49ä¸ªå…¬å¼€ç‰™ç§‘æ•°æ®é›†å’Œ211é¡¹åŸºäºDLçš„ç®—æ³•ç ”ç©¶ã€‚æ–‡ç« æ·±å…¥æ¢è®¨äº†ç‰™ç§‘æˆåƒçš„åŸºç¡€æ¦‚å¿µï¼Œå¹¶æ ¹æ®ä¸åŒçš„DIAä»»åŠ¡å¯¹ç½‘ç»œæ¶æ„(Network Architectures)ã€ä¼˜åŒ–ç­–ç•¥åŠè®­ç»ƒæ–¹æ³•è¿›è¡Œäº†åˆ†ç±»ä¸æ€§èƒ½è¯„ä¼°ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ€»ç»“äº†è¯¥é¢†åŸŸå¸¸ç”¨çš„è®­ç»ƒä¸è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶å¯¹å½“å‰é¢ä¸´çš„æŒ‘æˆ˜å’Œæœªæ¥æ½œåœ¨çš„ç ”ç©¶æ–¹å‘è¿›è¡Œäº†å…¨é¢è®¨è®ºã€‚è¿™é¡¹å·¥ä½œé€šè¿‡æ•´åˆå¤§è§„æ¨¡æ–‡çŒ®ï¼Œä¸ºæ¨åŠ¨è®¡ç®—æœºè¾…åŠ©ç‰™ç§‘è¯Šæ–­ä¸æ²»ç–—çš„æ™ºèƒ½åŒ–å‘å±•æä¾›äº†å®è´µçš„ç³»ç»Ÿæ€§å‚è€ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "52 pages, 24 figures. Under Review",
      "pdf_url": "https://arxiv.org/pdf/2510.20634v1",
      "published_date": "2025-10-23 15:05:06 UTC",
      "updated_date": "2025-10-23 15:05:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:54.467979+00:00"
    },
    {
      "arxiv_id": "2510.20632v1",
      "title": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications",
      "title_zh": "è¿ˆå‘å¤šè¯­è¨€ä¸å¤šæ¨¡æ€ç”µå•†åº”ç”¨çš„å¤§è¯­è¨€æ¨¡å‹å¯é è¯„ä¼°",
      "authors": [
        "Shuyi Xie",
        "Ziqin Liew",
        "Hailing Zhang",
        "Haibo Zhang",
        "Ling Hu",
        "Zhiqiang Zhou",
        "Shuman Liu",
        "Anxiang Zeng"
      ],
      "abstract": "Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet their capabilities in specialized domains remain underexplored. In e-commerce, existing evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping MMLU-suffer from limited task diversity (e.g., lacking product guidance and after-sales issues), limited task modalities (e.g., absence of multimodal data), synthetic or curated data, and a narrow focus on English and Chinese, leaving practitioners without reliable tools to assess models on complex, real-world shopping scenarios. We introduce EcomEval, a comprehensive multilingual and multimodal benchmark for evaluating LLMs in e-commerce. EcomEval covers six categories and 37 tasks (including 8 multimodal tasks), sourced primarily from authentic customer queries and transaction logs, reflecting the noisy and heterogeneous nature of real business interactions. To ensure both quality and scalability of reference answers, we adopt a semi-automatic pipeline in which large models draft candidate responses subsequently reviewed and modified by over 50 expert annotators with strong e-commerce and multilingual expertise. We define difficulty levels for each question and task category by averaging evaluation scores across models with different sizes and capabilities, enabling challenge-oriented and fine-grained assessment. EcomEval also spans seven languages-including five low-resource Southeast Asian languages-offering a multilingual perspective absent from prior work.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ç”µå­å•†åŠ¡è¯„ä¼°åŸºå‡†åœ¨ä»»åŠ¡å¤šæ ·æ€§ã€æ¨¡æ€ç¼ºå¤±ä»¥åŠè¯­è¨€å±€é™æ€§ç­‰æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº† EcomEvalï¼Œä¸€ä¸ªå…¨æ–°çš„å¤šè¯­è¨€å’Œå¤šæ¨¡æ€ Large Language Models (LLMs) è¯„ä¼°åŸºå‡†ã€‚EcomEval æ¶µç›–äº†6ä¸ªç±»åˆ«å’Œ37ä¸ªä»»åŠ¡ï¼ˆåŒ…æ‹¬8ä¸ªå¤šæ¨¡æ€ä»»åŠ¡ï¼‰ï¼Œå…¶æ•°æ®ä¸»è¦æºäºçœŸå®çš„å®¢æˆ·å’¨è¯¢å’Œäº¤æ˜“è®°å½•ï¼Œèƒ½å¤ŸçœŸå®åæ˜ å¤æ‚è´­ç‰©åœºæ™¯ä¸‹çš„æ•°æ®å¼‚è´¨æ€§ã€‚ç ”ç©¶é‡‡ç”¨äº†ä¸€ç§åŠè‡ªåŠ¨æµæ°´çº¿ï¼Œé€šè¿‡å¤§æ¨¡å‹ç”Ÿæˆåˆæ­¥å“åº”å¹¶ç”±50å¤šåå…·å¤‡ç”µå•†ä¸å¤šè¯­è¨€ä¸“ä¸šçŸ¥è¯†çš„ä¸“å®¶è¿›è¡Œå®¡æ ¸ä¿®æ­£ï¼Œç¡®ä¿äº†å‚è€ƒç­”æ¡ˆçš„è´¨é‡ä¸å¯æ‰©å±•æ€§ã€‚é€šè¿‡å¯¹ä¸åŒè§„æ¨¡æ¨¡å‹è¡¨ç°çš„é‡åŒ–åˆ†æï¼Œè¯¥åŸºå‡†ä¸ºå„ä»»åŠ¡å®šä¹‰äº†éš¾åº¦ç­‰çº§ï¼Œå®ç°äº†ç»†ç²’åº¦çš„æŒ‘æˆ˜å¯¼å‘è¯„ä¼°ã€‚æ­¤å¤–ï¼ŒEcomEval æ”¯æŒåŒ…å«5ç§ä½èµ„æºä¸œå—äºšè¯­è¨€åœ¨å†…çš„7ç§è¯­è¨€ï¼Œä¸ºè¡¡é‡ LLMs åœ¨å…¨çƒåŒ–ç”µå­å•†åŠ¡åº”ç”¨ä¸­çš„å¯é æ€§æä¾›äº†å…³é”®çš„è¯„ä»·å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20632v1",
      "published_date": "2025-10-23 15:04:32 UTC",
      "updated_date": "2025-10-23 15:04:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:57.379533+00:00"
    },
    {
      "arxiv_id": "2510.20630v1",
      "title": "Quantum Processing Unit (QPU) processing time Prediction with Machine Learning",
      "title_zh": "åŸºäºæœºå™¨å­¦ä¹ çš„é‡å­å¤„ç†å•å…ƒ (QPU) å¤„ç†æ—¶é—´é¢„æµ‹",
      "authors": [
        "Lucy Xing",
        "Sanjay Vishwakarma",
        "David Kremer",
        "Francisco Martin-Fernandez",
        "Ismael Faro",
        "Juan Cruz-Benito"
      ],
      "abstract": "This paper explores the application of machine learning (ML) techniques in predicting the QPU processing time of quantum jobs. By leveraging ML algorithms, this study introduces predictive models that are designed to enhance operational efficiency in quantum computing systems. Using a dataset of about 150,000 jobs that follow the IBM Quantum schema, we employ ML methods based on Gradient-Boosting (LightGBM) to predict the QPU processing times, incorporating data preprocessing methods to improve model accuracy. The results demonstrate the effectiveness of ML in forecasting quantum jobs. This improvement can have implications on improving resource management and scheduling within quantum computing frameworks. This research not only highlights the potential of ML in refining quantum job predictions but also sets a foundation for integrating AI-driven tools in advanced quantum computing operations.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨ Machine Learning æŠ€æœ¯é¢„æµ‹é‡å­ä»»åŠ¡çš„ QPU processing timeï¼Œæ—¨åœ¨æé«˜é‡å­è®¡ç®—ç³»ç»Ÿçš„è¿è¡Œæ•ˆç‡ã€‚ç ”ç©¶äººå‘˜åŸºäºåŒ…å«çº¦ 150,000 ä¸ªéµå¾ª IBM Quantum è§„èŒƒçš„ä»»åŠ¡æ•°æ®é›†ï¼Œé‡‡ç”¨äº†åŸºäº Gradient-Boosting çš„ LightGBM ç®—æ³•è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å¼•å…¥ç‰¹å®šçš„æ•°æ®é¢„å¤„ç†æ–¹æ³•ä»¥æå‡é¢„æµ‹ç²¾åº¦ã€‚å®éªŒç»“æœéªŒè¯äº† Machine Learning åœ¨å‡†ç¡®é¢„ä¼°é‡å­ä»»åŠ¡å¤„ç†æ—¶é—´æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œè¿™å¯¹äºä¼˜åŒ–é‡å­è®¡ç®—æ¡†æ¶ä¸­çš„èµ„æºç®¡ç†å’Œä»»åŠ¡è°ƒåº¦å…·æœ‰é‡è¦æ„ä¹‰ã€‚è¯¥ç ”ç©¶ä¸ä»…å±•ç¤ºäº†äººå·¥æ™ºèƒ½åœ¨ç²¾ç»†åŒ–é¢„æµ‹é‡å­ä»»åŠ¡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¹Ÿä¸ºæœªæ¥åœ¨å…ˆè¿›é‡å­è®¡ç®—æ“ä½œä¸­é›†æˆ AI-driven tools å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "Technical paper accepted at the IEEE Quantum Week 2025 Conference",
      "pdf_url": "https://arxiv.org/pdf/2510.20630v1",
      "published_date": "2025-10-23 15:04:18 UTC",
      "updated_date": "2025-10-23 15:04:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:13:59.780380+00:00"
    },
    {
      "arxiv_id": "2510.20629v1",
      "title": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach",
      "title_zh": "å…¬å¹³ç”Ÿå­˜é¢„æµ‹ï¼šä¸€ç§å…¬å¹³æ„ŸçŸ¥çš„ç”Ÿå­˜å»ºæ¨¡ï¼ˆFASMï¼‰æ–¹æ³•",
      "authors": [
        "Mingxuan Liu",
        "Yilin Ning",
        "Haoyuan Wang",
        "Chuan Hong",
        "Matthew Engelhard",
        "Danielle S. Bitterman",
        "William G. La Cava",
        "Nan Liu"
      ],
      "abstract": "As machine learning models become increasingly integrated into healthcare, structural inequities and social biases embedded in clinical data can be perpetuated or even amplified by data-driven models. In survival analysis, censoring and time dynamics can further add complexity to fair model development. Additionally, algorithmic fairness approaches often overlook disparities in cross-group rankings, e.g., high-risk Black patients may be ranked below lower-risk White patients who do not experience the event of mortality. Such misranking can reinforce biological essentialism and undermine equitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed to mitigate algorithmic bias regarding both intra-group and cross-group risk rankings over time. Using breast cancer prognosis as a representative case and applying FASM to SEER breast cancer data, we show that FASM substantially improves fairness while preserving discrimination performance comparable to fairness-unaware survival models. Time-stratified evaluations show that FASM maintains stable fairness over a 10-year horizon, with the greatest improvements observed during the mid-term of follow-up. Our approach enables the development of survival models that prioritize both accuracy and equity in clinical decision-making, advancing fairness as a core principle in clinical care.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­å¯èƒ½æ”¾å¤§çš„ç»“æ„æ€§ä¸å¹³ç­‰é—®é¢˜ï¼Œæå‡ºäº†å…¬å¹³æ„ŸçŸ¥ç”Ÿå­˜å»ºæ¨¡(Fairness-Aware Survival Modeling, FASM)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”Ÿå­˜åˆ†æ(Survival Analysis)ä¸­å› æ•°æ®å®¡æŸ¥å’Œæ—¶é—´åŠ¨æ€æ€§å¸¦æ¥çš„å…¬å¹³æ€§æŒ‘æˆ˜ã€‚FASMé€šè¿‡ä¸“é—¨çš„è®¾è®¡ï¼ŒåŒæ—¶ç¼“è§£äº†éšæ—¶é—´å˜åŒ–çš„ç»„å†…åŠè·¨ç»„é£é™©æ’ååè§ï¼Œé¿å…äº†é«˜é£é™©å°‘æ•°æ—è£”æ‚£è€…åœ¨åŒ»ç–—ä¼˜å…ˆçº§æ’åºä¸­è¢«è¯¯åˆ¤çš„æƒ…å†µã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨SEERä¹³è…ºç™Œæ•°æ®é›†è¿›è¡ŒéªŒè¯ï¼Œç»“æœæ˜¾ç¤ºFASMåœ¨ä¿æŒä¸ä¼ ç»Ÿæ¨¡å‹ç›¸å½“çš„åŒºåˆ†æ€§èƒ½(Discrimination Performance)çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†å…¬å¹³æ€§æŒ‡æ ‡ã€‚æ—¶é—´åˆ†å±‚è¯„ä¼°è¿›ä¸€æ­¥è¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é•¿è¾¾10å¹´çš„è§‚å¯ŸæœŸå†…å‡èƒ½ç»´æŒç¨³å®šçš„å…¬å¹³è¡¨ç°ï¼Œå°¤å…¶åœ¨éšè®¿ä¸­æœŸæ”¹è¿›æ•ˆæœæœ€ä¸ºæ˜¾è‘—ã€‚è¿™ä¸€æˆæœä¸ºä¸´åºŠå†³ç­–ä¸­å…¼é¡¾é¢„æµ‹å‡†ç¡®æ€§ä¸ç¤¾ä¼šå…¬å¹³æ€§æä¾›äº†é‡è¦æŠ€æœ¯æ”¯æŒï¼Œæ¨åŠ¨äº†å…¬å¹³æ€§ä½œä¸ºä¸´åºŠæŠ¤ç†æ ¸å¿ƒåŸåˆ™çš„å‘å±•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20629v1",
      "published_date": "2025-10-23 15:03:27 UTC",
      "updated_date": "2025-10-23 15:03:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:04.488256+00:00"
    },
    {
      "arxiv_id": "2510.20621v2",
      "title": "Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms",
      "title_zh": "é¢å‘åˆ©ç”¨å¤æ‚ç®—æ³•æŒ–æ˜å¯è§£é‡Šæ¨¡å‹çš„å¯ä¿¡äººå·¥æ™ºèƒ½å½¢å¼åŒ–ç ”ç©¶",
      "authors": [
        "Riccardo Guidotti",
        "Martina Cinquini",
        "Marta Marchiori Manerba",
        "Mattia Setzu",
        "Francesco Spinnato"
      ],
      "abstract": "Interpretable-by-design models are crucial for fostering trust, accountability, and safe adoption of automated decision-making models in real-world applications. In this paper we formalize the ground for the MIMOSA (Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a comprehensive methodology for generating predictive models that balance interpretability with performance while embedding key ethical properties. We formally define here the supervised learning setting across diverse decision-making tasks and data types, including tabular data, time series, images, text, transactions, and trajectories. We characterize three major families of interpretable models: feature importance, rule, and instance based models. For each family, we analyze their interpretability dimensions, reasoning mechanisms, and complexity. Beyond interpretability, we formalize three critical ethical properties, namely causality, fairness, and privacy, providing formal definitions, evaluation metrics, and verification procedures for each. We then examine the inherent trade-offs between these properties and discuss how privacy requirements, fairness constraints, and causal reasoning can be embedded within interpretable pipelines. By evaluating ethical measures during model generation, this framework establishes the theoretical foundations for developing AI systems that are not only accurate and interpretable but also fair, privacy-preserving, and causally aware, i.e., trustworthy.",
      "tldr_zh": "æœ¬æ–‡æ­£å¼æå‡ºäº† MIMOSA (Mining Interpretable Models explOiting Sophisticated Algorithms) æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å¹³è¡¡è§£é‡Šæ€§ä¸æ€§èƒ½å¹¶åµŒå…¥æ ¸å¿ƒä¼¦ç†å±æ€§çš„ç»¼åˆæ€§æ–¹æ³•è®ºã€‚è¯¥æ¡†æ¶å®šä¹‰äº†æ¶µç›–è¡¨æ ¼æ•°æ®ã€æ—¶é—´åºåˆ—ã€å›¾åƒã€æ–‡æœ¬ã€äº¤æ˜“å’Œè½¨è¿¹ç­‰å¤šç§æ•°æ®ç±»å‹çš„ç›‘ç£å­¦ä¹ è®¾ç½®ï¼Œå¹¶ç³»ç»Ÿæ€§åœ°åˆ»ç”»äº†ç‰¹å¾é‡è¦æ€§ (feature importance)ã€è§„åˆ™ (rule) å’ŒåŸºäºå®ä¾‹ (instance based) ä¸‰å¤§ç±»å¯è§£é‡Šæ¨¡å‹ã€‚é™¤äº†å¯è§£é‡Šæ€§ï¼Œç ”ç©¶è¿˜é’ˆå¯¹å› æœæ€§ (causality)ã€å…¬å¹³æ€§ (fairness) å’Œéšç§æ€§ (privacy) å½¢å¼åŒ–äº†å®šä¹‰ã€è¯„ä¼°æŒ‡æ ‡åŠéªŒè¯ç¨‹åºã€‚ç ”ç©¶è¿›ä¸€æ­¥æ¢è®¨äº†è¿™äº›ä¼¦ç†å±æ€§ä¹‹é—´çš„å†…åœ¨æƒè¡¡ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•å°†éšç§ã€å…¬å¹³å’Œå› æœæ¨ç†åµŒå…¥åˆ°å¯è§£é‡Šæ¨¡å‹æµæ°´çº¿ä¸­ã€‚é€šè¿‡åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å¼•å…¥ä¼¦ç†åº¦é‡ï¼Œè¯¥æ¡†æ¶ä¸ºæ„å»ºå…¼å…·é«˜ç²¾åº¦ã€å¯è§£é‡Šæ€§ä¸ä¼¦ç†æ€§è¦æ±‚çš„å¯ä¿¡ AI ç³»ç»Ÿå¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20621v2",
      "published_date": "2025-10-23 14:54:33 UTC",
      "updated_date": "2025-10-30 16:26:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:07.377328+00:00"
    },
    {
      "arxiv_id": "2510.21879v1",
      "title": "TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge",
      "title_zh": "TernaryCLIPï¼šåŸºäºä¸‰å€¼æƒé‡ä¸çŸ¥è¯†è’¸é¦çš„è§†è§‰-è¯­è¨€æ¨¡å‹é«˜æ•ˆå‹ç¼©",
      "authors": [
        "Shu-Hao Zhang",
        "Wei-Cheng Tang",
        "Chen Wu",
        "Peng Hu",
        "Nan Li",
        "Liang-Jie Zhang",
        "Qi Zhang",
        "Shao-Qun Zhang"
      ],
      "abstract": "Recent years have witnessed an increasing interest in image-text contrastive modeling, exemplified by models such as Contrastive Language-Image Pretraining (CLIP). In this paper, we propose the TernaryCLIP, a lightweight computational framework that converts connection weights of both vision and text encoders of CLIP into the ternary format, instead of full-precision or floating ones. TernaryCLIP incorporates quantization-aware training and distillation modules, preventing precision degradation and enabling low-cost and high-efficiency computations. Comprehensive experiments demonstrate that TernaryCLIP can achieve up to 99\\% ternarized weights with 1.58-bit representation, 16.98 $\\times$ compression ratio, 2.3 $\\times$ inference acceleration, 16 $\\times$ storage reduction, 10 $\\times$ memory optimization, and 60\\% sparsity while maintaining promising performance on zero-shot image classification and image-text retrieval tasks across 41 commonly used datasets. Our work highlights the feasibility of extreme quantization for large multimodal models, supporting effective and efficient deployment on resource-constrained devices. The model and code can be accessed from Hugging Face and GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TernaryCLIPï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„è®¡ç®—æ¡†æ¶ï¼Œæ—¨åœ¨å°†CLIPæ¨¡å‹çš„è§†è§‰å’Œæ–‡æœ¬ç¼–ç å™¨çš„è¿æ¥æƒé‡è½¬æ¢ä¸ºTernaryæ ¼å¼ï¼Œè€Œéä¼ ç»Ÿçš„é«˜ç²¾åº¦æµ®ç‚¹æ•°ã€‚è¯¥æ¡†æ¶é›†æˆäº†Quantization-aware Trainingå’ŒDistillationæ¨¡å—ï¼Œæœ‰æ•ˆåœ°é˜²æ­¢äº†ç²¾åº¦é€€åŒ–ï¼Œå¹¶å®ç°äº†ä½æˆæœ¬ä¸é«˜æ•ˆç‡çš„è®¡ç®—ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTernaryCLIPå®ç°äº†1.58-bitæƒé‡è¡¨ç¤ºã€é«˜è¾¾16.98å€çš„å‹ç¼©æ¯”å’Œ2.3å€çš„æ¨ç†åŠ é€Ÿï¼ŒåŒæ—¶åœ¨å­˜å‚¨ã€æ˜¾å­˜ä¼˜åŒ–å’ŒSparsityæ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚åœ¨æ¶µç›–41ä¸ªå¸¸ç”¨æ•°æ®é›†çš„Zero-shotå›¾åƒåˆ†ç±»å’Œå›¾åƒæ–‡æœ¬æ£€ç´¢ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨æ˜¾è‘—å‡å°ä½“é‡çš„åŒæ—¶ä¿æŒäº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½ã€‚è¯¥é¡¹å·¥ä½œè¯æ˜äº†å¯¹å¤§å‹å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œæç«¯é‡åŒ–çš„å¯è¡Œæ€§ï¼Œä¸ºåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿›è¡Œé«˜æ•ˆéƒ¨ç½²æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21879v1",
      "published_date": "2025-10-23 14:53:32 UTC",
      "updated_date": "2025-10-23 14:53:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:09.573831+00:00"
    },
    {
      "arxiv_id": "2510.20612v1",
      "title": "Black Box Absorption: LLMs Undermining Innovative Ideas",
      "title_zh": "é»‘ç›’å¸æ”¶ï¼šå¤§è¯­è¨€æ¨¡å‹å¯¹åˆ›æ–°æ„æ€çš„ä¾µèš€",
      "authors": [
        "Wenjun Cao"
      ],
      "abstract": "Large Language Models are increasingly adopted as critical tools for accelerating innovation. This paper identifies and formalizes a systemic risk inherent in this paradigm: \\textbf{Black Box Absorption}. We define this as the process by which the opaque internal architectures of LLM platforms, often operated by large-scale service providers, can internalize, generalize, and repurpose novel concepts contributed by users during interaction. This mechanism threatens to undermine the foundational principles of innovation economics by creating severe informational and structural asymmetries between individual creators and platform operators, thereby jeopardizing the long-term sustainability of the innovation ecosystem. To analyze this challenge, we introduce two core concepts: the idea unit, representing the transportable functional logic of an innovation, and idea safety, a multidimensional standard for its protection. This paper analyzes the mechanisms of absorption and proposes a concrete governance and engineering agenda to mitigate these risks, ensuring that creator contributions remain traceable, controllable, and equitable.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨åŠ é€Ÿåˆ›æ–°è¿‡ç¨‹ä¸­æ½œåœ¨çš„ç³»ç»Ÿæ€§é£é™©ï¼Œå¹¶æ­£å¼æå‡ºäº†â€œé»‘ç›’å¸æ”¶â€(Black Box Absorption)è¿™ä¸€æ¦‚å¿µã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç”±äºLLMå¹³å°å†…éƒ¨æ¶æ„çš„ä¸é€æ˜æ€§ï¼Œç”¨æˆ·åœ¨äº¤äº’è¿‡ç¨‹ä¸­è´¡çŒ®çš„åˆ›æ–°æ¦‚å¿µå¯èƒ½è¢«å¹³å°å†…éƒ¨åŒ–ã€æ³›åŒ–å¹¶é‡æ–°åˆ©ç”¨ã€‚è¿™ç§æœºåˆ¶åœ¨ä¸ªä½“åˆ›é€ è€…ä¸å¹³å°è¿è¥å•†ä¹‹é—´åˆ¶é€ äº†ä¸¥é‡çš„ä¿¡æ¯ä¸ç»“æ„ä¸å¯¹ç§°ï¼Œä»è€Œå¨èƒåˆ°åˆ›æ–°ç»æµå­¦çš„åŸºæœ¬åŸåˆ™åŠåˆ›æ–°ç”Ÿæ€ç³»ç»Ÿçš„é•¿æœŸå¯æŒç»­æ€§ã€‚ä¸ºäº†åˆ†æè¿™ä¸€æŒ‘æˆ˜ï¼Œè®ºæ–‡å¼•å…¥äº†ä¸¤ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼šä»£è¡¨åˆ›æ–°å¯è¿ç§»åŠŸèƒ½é€»è¾‘çš„â€œåˆ›æ„å•å…ƒâ€(idea unit)å’Œè¡¡é‡ä¿æŠ¤æ°´å¹³çš„å¤šç»´æ ‡å‡†â€œåˆ›æ„å®‰å…¨â€(idea safety)ã€‚è®ºæ–‡æ·±å…¥åˆ†æäº†å¸æ”¶æœºåˆ¶ï¼Œå¹¶æå‡ºäº†ä¸€å¥—å…·ä½“çš„æ²»ç†ä¸å·¥ç¨‹æ–¹æ¡ˆï¼Œæ—¨åœ¨ç¡®ä¿åˆ›ä½œè€…çš„è´¡çŒ®ä¿æŒå¯è¿½æº¯ã€å¯æ§ä¸”å…¬å¹³ã€‚è¯¥ç ”ç©¶ä¸ºè§£å†³LLMæ—¶ä»£çš„çŸ¥è¯†äº§æƒä¿æŠ¤ä¸åˆ›æ–°æ¿€åŠ±æœºåˆ¶æä¾›äº†é‡è¦çš„ç†è®ºæ¡†æ¶å’Œå®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "econ.GN"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20612v1",
      "published_date": "2025-10-23 14:43:09 UTC",
      "updated_date": "2025-10-23 14:43:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:16.109479+00:00"
    },
    {
      "arxiv_id": "2510.20611v1",
      "title": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection",
      "title_zh": "PSO-XAIï¼šä¸€ç§é¢å‘å¯é ä¹³è…ºç™Œæ£€æµ‹çš„ç²’å­ç¾¤ä¼˜åŒ–å¢å¼ºå‹å¯è§£é‡Šäººå·¥æ™ºèƒ½æ¡†æ¶",
      "authors": [
        "Mirza Raquib",
        "Niloy Das",
        "Farida Siddiqi Prity",
        "Arafath Al Fahim",
        "Saydul Akbar Murad",
        "Mohammad Amzad Hossain",
        "MD Jiabul Hoque",
        "Mohammad Ali Moni"
      ],
      "abstract": "Breast cancer is considered the most critical and frequently diagnosed cancer in women worldwide, leading to an increase in cancer-related mortality. Early and accurate detection is crucial as it can help mitigate possible threats while improving survival rates. In terms of prediction, conventional diagnostic methods are often limited by variability, cost, and, most importantly, risk of misdiagnosis. To address these challenges, machine learning (ML) has emerged as a powerful tool for computer-aided diagnosis, with feature selection playing a vital role in improving model performance and interpretability. This research study proposes an integrated framework that incorporates customized Particle Swarm Optimization (PSO) for feature selection. This framework has been evaluated on a comprehensive set of 29 different models, spanning classical classifiers, ensemble techniques, neural networks, probabilistic algorithms, and instance-based algorithms. To ensure interpretability and clinical relevance, the study uses cross-validation in conjunction with explainable AI methods. Experimental evaluation showed that the proposed approach achieved a superior score of 99.1\\% across all performance metrics, including accuracy and precision, while effectively reducing dimensionality and providing transparent, model-agnostic explanations. The results highlight the potential of combining swarm intelligence with explainable ML for robust, trustworthy, and clinically meaningful breast cancer diagnosis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¹³è…ºç™Œæ—©æœŸæ£€æµ‹ä¸­ä¼ ç»Ÿæ–¹æ³•å­˜åœ¨çš„è¯¯è¯Šé£é™©å’Œæˆæœ¬é—®é¢˜ï¼Œæå‡ºäº†PSO-XAIï¼Œä¸€ç§åŸºäºç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•(Particle Swarm Optimization)å¢å¼ºçš„å¯è§£é‡Šäººå·¥æ™ºèƒ½æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨å®šåˆ¶åŒ–çš„PSOè¿›è¡Œç‰¹å¾é€‰æ‹©(Feature Selection)ï¼Œä»¥åœ¨æé«˜æ¨¡å‹æ€§èƒ½çš„åŒæ—¶å®ç°æ•°æ®é™ç»´ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨åŒ…å«ç»å…¸åˆ†ç±»å™¨ã€é›†æˆå­¦ä¹ (Ensemble Learning)å’Œç¥ç»ç½‘ç»œåœ¨å†…çš„29ç§ä¸åŒæ¨¡å‹ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ã€‚ä¸ºäº†ç¡®ä¿åŒ»ç–—å†³ç­–çš„é€æ˜åº¦å’Œä¸´åºŠç›¸å…³æ€§ï¼Œè¯¥ç ”ç©¶ç»“åˆäº†äº¤å‰éªŒè¯(Cross-validation)ä¸å¯è§£é‡Šæ€§AI(Explainable AI)æ–¹æ³•ï¼Œæä¾›æ¨¡å‹æ— å…³çš„è§£é‡Šã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®ç‡å’Œç²¾ç¡®ç‡ç­‰æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°äº†99.1%çš„ä¼˜å¼‚æˆç»©ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†å°†ç¾¤ä½“æ™ºèƒ½(Swarm Intelligence)ä¸å¯è§£é‡Šæœºå™¨å­¦ä¹ ç›¸ç»“åˆåœ¨æ„å»ºç¨³å¥ã€å¯é ä¸”å…·æœ‰ä¸´åºŠä»·å€¼çš„ä¹³è…ºç™Œè¾…åŠ©è¯Šæ–­ç³»ç»Ÿæ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20611v1",
      "published_date": "2025-10-23 14:42:50 UTC",
      "updated_date": "2025-10-23 14:42:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:27.778283+00:00"
    },
    {
      "arxiv_id": "2510.20610v2",
      "title": "BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection",
      "title_zh": "BUSTED å‚åŠ  AraGenEval å…±äº«ä»»åŠ¡ï¼šåŸºäº Transformer æ¨¡å‹çš„é˜¿æ‹‰ä¼¯è¯­ AI ç”Ÿæˆæ–‡æœ¬æ£€æµ‹å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Ali Zain",
        "Sareem Farooqui",
        "Muhammad Rafi"
      ],
      "abstract": "This paper details our submission to the AraGenEval Shared Task on Arabic AI-generated text detection, where our team, BUSTED, secured 5th place. We investigated the effectiveness of three pre-trained transformer models: AraELECTRA, CAMeLBERT, and XLM-RoBERTa. Our approach involved fine-tuning each model on the provided dataset for a binary classification task. Our findings revealed a surprising result: the multilingual XLM-RoBERTa model achieved the highest performance with an F1 score of 0.7701, outperforming the specialized Arabic models. This work underscores the complexities of AI-generated text detection and highlights the strong generalization capabilities of multilingual models.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶è¯¦ç»†ä»‹ç»äº† BUSTED å›¢é˜Ÿåœ¨ AraGenEval Shared Task é˜¿æ‹‰ä¼¯è¯­ AI ç”Ÿæˆæ–‡æœ¬æ£€æµ‹ä»»åŠ¡ä¸­çš„å‚èµ›æ–¹æ¡ˆï¼Œå¹¶æœ€ç»ˆå–å¾—äº†ç¬¬ 5 åã€‚ç ”ç©¶è€…å¯¹æ¯”äº†ä¸‰ç§é¢„è®­ç»ƒ Transformer æ¨¡å‹ï¼Œå³ AraELECTRAã€CAMeLBERT ä»¥åŠå¤šè¯­è¨€æ¨¡å‹ XLM-RoBERTaï¼Œåœ¨ç‰¹å®šæ•°æ®é›†ä¸Šé€šè¿‡å¾®è°ƒï¼ˆFine-tuningï¼‰æ¥æ‰§è¡ŒäºŒåˆ†ç±»æ£€æµ‹ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¤šè¯­è¨€æ¨¡å‹ XLM-RoBERTa ä»¥ 0.7701 çš„ F1 score å±•ç°å‡ºæœ€ä½³æ€§èƒ½ï¼Œæ„å¤–åœ°è¶…è¶Šäº†ä¸“é—¨é’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­ä¼˜åŒ–çš„æ¨¡å‹ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†å¤šè¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šè¯­è¨€ä»»åŠ¡ä¸­å…·å¤‡å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼ˆGeneralization capabilitiesï¼‰ï¼ŒåŒæ—¶ä¹Ÿæ­ç¤ºäº† AI ç”Ÿæˆæ–‡æœ¬æ£€æµ‹é¢†åŸŸçš„å¤æ‚æ€§ã€‚è¯¥å·¥ä½œä¸ºæå‡é˜¿æ‹‰ä¼¯è¯­ç¯å¢ƒä¸‹ AI å†…å®¹è¯†åˆ«çš„å‡†ç¡®æ€§æä¾›äº†é‡è¦çš„å®è¯å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20610v2",
      "published_date": "2025-10-23 14:41:04 UTC",
      "updated_date": "2025-10-25 15:33:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:29.683253+00:00"
    },
    {
      "arxiv_id": "2510.20609v1",
      "title": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets",
      "title_zh": "å¤§è§„æ¨¡å®ç”¨ä»£ç  RAGï¼šè®¡ç®—é¢„ç®—ä¸‹çš„ä»»åŠ¡æ„ŸçŸ¥æ£€ç´¢è®¾è®¡æ–¹æ¡ˆ",
      "authors": [
        "Timur Galimzyanov",
        "Olga Kolomyttseva",
        "Egor Bogomolov"
      ],
      "abstract": "We study retrieval design for code-focused generation tasks under realistic compute budgets. Using two complementary tasks from Long Code Arena -- code completion and bug localization -- we systematically compare retrieval configurations across various context window sizes along three axes: (i) chunking strategy, (ii) similarity scoring, and (iii) splitting granularity. (1) For PL-PL, sparse BM25 with word-level splitting is the most effective and practical, significantly outperforming dense alternatives while being an order of magnitude faster. (2) For NL-PL, proprietary dense encoders (Voyager-3 family) consistently beat sparse retrievers, however requiring 100x larger latency. (3) Optimal chunk size scales with available context: 32-64 line chunks work best at small budgets, and whole-file retrieval becomes competitive at 16000 tokens. (4) Simple line-based chunking matches syntax-aware splitting across budgets. (5) Retrieval latency varies by up to 200x across configurations; BPE-based splitting is needlessly slow, and BM25 + word splitting offers the best quality-latency trade-off. Thus, we provide evidence-based recommendations for implementing effective code-oriented RAG systems based on task requirements, model constraints, and computational efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç°å®è®¡ç®—é¢„ç®—ä¸‹é’ˆå¯¹ä»£ç ç”Ÿæˆä»»åŠ¡çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿè®¾è®¡ï¼Œç³»ç»Ÿæ€§åœ°å¯¹æ¯”äº†åˆ†å—ç­–ç•¥(chunking strategy)ã€ç›¸ä¼¼åº¦è¯„åˆ†(similarity scoring)å’Œåˆ†å‰²ç²’åº¦(splitting granularity)ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨PL-PLä»»åŠ¡ä¸­ï¼Œé‡‡ç”¨å•è¯çº§åˆ†å‰²çš„ç¨€ç–BM25æ–¹æ¡ˆåœ¨æ•ˆæœå’Œé€Ÿåº¦ä¸Šå‡æ˜¾è‘—ä¼˜äºç¨ å¯†(dense)ç¼–ç å™¨ï¼›è€Œåœ¨NL-PLä»»åŠ¡ä¸­ï¼Œå°½ç®¡Voyager-3ç­‰ä¸“ç”¨ç¨ å¯†æ¨¡å‹æ•ˆæœæ›´ä½³ï¼Œä½†å…¶å»¶è¿Ÿé«˜å‡º100å€ã€‚åˆ†å—å®éªŒè¡¨æ˜ï¼Œ32-64è¡Œçš„å—å¤§å°åœ¨å°é¢„ç®—ä¸‹æœ€ä¼˜ï¼Œè€Œå½“ä¸Šä¸‹æ–‡æ‰©å±•è‡³16000ä¸ªtokenæ—¶å…¨æ–‡ä»¶æ£€ç´¢æ›´å…·ç«äº‰åŠ›ã€‚æ­¤å¤–ï¼Œç®€å•çš„è¡Œçº§åˆ†å—(line-based chunking)ä¸å¤æ‚çš„è¯­æ³•æ„ŸçŸ¥åˆ†å‰²æ•ˆæœç›¸å½“ï¼Œè€ŒBPEåˆ†å‰²åˆ™æ•ˆç‡è¾ƒä½ã€‚é€šè¿‡ç»¼åˆè€ƒé‡ï¼ŒBM25é…åˆå•è¯çº§åˆ†å‰²è¢«è¯æ˜æ˜¯è´¨é‡ä¸å»¶è¿Ÿæƒè¡¡ä¸‹çš„æœ€ä¼˜é€‰æ‹©ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä¸­å®æ–½é«˜æ•ˆçš„ä»£ç å¯¼å‘RAGç³»ç»Ÿæä¾›äº†å…·ä½“çš„å¾ªè¯å»ºè®®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20609v1",
      "published_date": "2025-10-23 14:40:11 UTC",
      "updated_date": "2025-10-23 14:40:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:34.464549+00:00"
    },
    {
      "arxiv_id": "2510.20607v1",
      "title": "Generalizable Reasoning through Compositional Energy Minimization",
      "title_zh": "åŸºäºç»„åˆå¼èƒ½é‡æœ€å°åŒ–çš„å¯æ³›åŒ–æ¨ç†",
      "authors": [
        "Alexandru Oarga",
        "Yilun Du"
      ],
      "abstract": "Generalization is a key challenge in machine learning, specifically in reasoning tasks, where models are expected to solve problems more complex than those encountered during training. Existing approaches typically train reasoning models in an end-to-end fashion, directly mapping input instances to solutions. While this allows models to learn useful heuristics from data, it often results in limited generalization beyond the training distribution. In this work, we propose a novel approach to reasoning generalization by learning energy landscapes over the solution spaces of smaller, more tractable subproblems. At test time, we construct a global energy landscape for a given problem by combining the energy functions of multiple subproblems. This compositional approach enables the incorporation of additional constraints during inference, allowing the construction of energy landscapes for problems of increasing difficulty. To improve the sample quality from this newly constructed energy landscape, we introduce Parallel Energy Minimization (PEM). We evaluate our approach on a wide set of reasoning problems. Our method outperforms existing state-of-the-art methods, demonstrating its ability to generalize to larger and more complex problems. Project website can be found at: https://alexoarga.github.io/compositional_reasoning/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ æ¨ç†ä»»åŠ¡ä¸­çš„æ³›åŒ–æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡ç»„åˆèƒ½é‡æœ€å°åŒ–(Compositional Energy Minimization)å®ç°å¯æ³›åŒ–æ¨ç†çš„æ–°æ–¹æ³•ã€‚ä¼ ç»Ÿçš„ç«¯åˆ°ç«¯è®­ç»ƒé€šå¸¸å¯¼è‡´æ¨¡å‹éš¾ä»¥å¤„ç†æ¯”è®­ç»ƒé›†æ›´å¤æ‚çš„é—®é¢˜ï¼Œè€Œè¯¥æ–¹æ³•é€šè¿‡å­¦ä¹ è¾ƒå°ä¸”æ˜“å¤„ç†å­é—®é¢˜çš„èƒ½é‡æ™¯è§‚(energy landscapes)æ¥è§£å†³è¿™ä¸€éš¾é¢˜ã€‚åœ¨æµ‹è¯•é˜¶æ®µï¼Œè¯¥æ–¹æ³•é€šè¿‡ç»„åˆå¤šä¸ªå­é—®é¢˜çš„èƒ½é‡å‡½æ•°æ„å»ºå…¨å±€èƒ½é‡æ™¯è§‚ï¼Œä»è€Œå…è®¸åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ•´åˆé¢å¤–çº¦æŸä»¥åº”å¯¹éš¾åº¦é€’å¢çš„é—®é¢˜ã€‚ä¸ºäº†æé«˜ä»æ–°æ„å»ºçš„èƒ½é‡æ™¯è§‚ä¸­é‡‡æ ·çš„è´¨é‡ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†å¹¶è¡Œèƒ½é‡æœ€å°åŒ–(Parallel Energy Minimization, PEM)æŠ€æœ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§æ¨ç†é—®é¢˜ä¸Šå‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ï¼Œå±•ç°äº†å…¶å‘æ›´å¤§è§„æ¨¡ã€æ›´å¤æ‚é—®é¢˜æ³›åŒ–çš„å¼ºå¤§èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20607v1",
      "published_date": "2025-10-23 14:38:36 UTC",
      "updated_date": "2025-10-23 14:38:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:35.146216+00:00"
    },
    {
      "arxiv_id": "2510.20605v1",
      "title": "OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects",
      "title_zh": "OnlineSplatterï¼šé¢å‘è‡ªç”±è¿åŠ¨ç‰©ä½“çš„æ— éœ€ä½å§¿åœ¨çº¿ä¸‰ç»´é‡å»º",
      "authors": [
        "Mark He Huang",
        "Lin Geng Foo",
        "Christian Theobalt",
        "Ying Sun",
        "De Wen Soh"
      ],
      "abstract": "Free-moving object reconstruction from monocular video remains challenging, particularly without reliable pose or depth cues and under arbitrary object motion. We introduce OnlineSplatter, a novel online feed-forward framework generating high-quality, object-centric 3D Gaussians directly from RGB frames without requiring camera pose, depth priors, or bundle optimization. Our approach anchors reconstruction using the first frame and progressively refines the object representation through a dense Gaussian primitive field, maintaining constant computational cost regardless of video sequence length. Our core contribution is a dual-key memory module combining latent appearance-geometry keys with explicit directional keys, robustly fusing current frame features with temporally aggregated object states. This design enables effective handling of free-moving objects via spatial-guided memory readout and an efficient sparsification mechanism, ensuring comprehensive yet compact object coverage. Evaluations on real-world datasets demonstrate that OnlineSplatter significantly outperforms state-of-the-art pose-free reconstruction baselines, consistently improving with more observations while maintaining constant memory and runtime.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† OnlineSplatterï¼Œè¿™æ˜¯ä¸€ç§åˆ›æ–°çš„åœ¨çº¿å‰å‘æ¡†æ¶ï¼ˆfeed-forward frameworkï¼‰ï¼Œæ—¨åœ¨è§£å†³å•ç›®è§†é¢‘ä¸­è‡ªç”±è¿åŠ¨ç‰©ä½“åœ¨ç¼ºä¹ç›¸æœºä½å§¿ï¼ˆcamera poseï¼‰å’Œæ·±åº¦å…ˆéªŒï¼ˆdepth priorsï¼‰æƒ…å†µä¸‹çš„ 3D é‡å»ºéš¾é¢˜ã€‚è¯¥æ–¹æ³•ä»¥é¦–å¸§ä¸ºåŸºå‡†ï¼Œé€šè¿‡å¯†é›†çš„ Gaussian primitive field é€æ­¥ä¼˜åŒ–ç‰©ä½“è¡¨ç¤ºï¼Œä»è€Œç›´æ¥ä» RGB å¸§ç”Ÿæˆé«˜è´¨é‡ä¸”ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„ 3D Gaussiansã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºå¼•å…¥äº†åŒé”®å­˜å‚¨æ¨¡å—ï¼ˆdual-key memory moduleï¼‰ï¼Œå°†æ½œåœ¨çš„å¤–è§‚å‡ ä½•é”®ï¼ˆlatent appearance-geometry keysï¼‰ä¸æ˜¾å¼çš„æ–¹å‘é”®ï¼ˆdirectional keysï¼‰ç›¸ç»“åˆï¼Œå®ç°äº†å½“å‰å¸§ç‰¹å¾ä¸æ—¶åºèšåˆç‰©ä½“çŠ¶æ€çš„ç¨³å¥èåˆã€‚é€šè¿‡ç©ºé—´å¼•å¯¼çš„å†…å­˜è¯»å–ï¼ˆspatial-guided memory readoutï¼‰å’Œé«˜æ•ˆçš„ç¨€ç–åŒ–æœºåˆ¶ï¼ˆsparsification mechanismï¼‰ï¼Œè¯¥ç³»ç»Ÿèƒ½æœ‰æ•ˆå¤„ç†è‡ªç”±è¿åŠ¨ç‰©ä½“å¹¶ç¡®ä¿ç‰©ä½“è¦†ç›–çš„å®Œæ•´æ€§ä¸ç´§å‡‘æ€§ã€‚åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒOnlineSplatter æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ— ä½å§¿ï¼ˆpose-freeï¼‰é‡å»ºåŸºå‡†ï¼Œä¸”èƒ½åœ¨ä¿æŒæ’å®šè®¡ç®—æˆæœ¬å’Œå†…å­˜å ç”¨çš„åŒæ—¶ï¼Œéšè§‚æµ‹é‡çš„å¢åŠ æŒç»­æå‡é‡å»ºè´¨é‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2025 (Spotlight)",
      "pdf_url": "https://arxiv.org/pdf/2510.20605v1",
      "published_date": "2025-10-23 14:37:25 UTC",
      "updated_date": "2025-10-23 14:37:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:40.259319+00:00"
    },
    {
      "arxiv_id": "2510.20604v1",
      "title": "Efficient Algorithms for Computing Random Walk Centrality",
      "title_zh": "éšæœºæ¸¸èµ°ä¸­å¿ƒæ€§çš„é«˜æ•ˆè®¡ç®—ç®—æ³•",
      "authors": [
        "Changan Liu",
        "Zixuan Xie",
        "Ahad N. Zehmakan",
        "Zhongzhi Zhang"
      ],
      "abstract": "Random walk centrality is a fundamental metric in graph mining for quantifying node importance and influence, defined as the weighted average of hitting times to a node from all other nodes. Despite its ability to capture rich graph structural information and its wide range of applications, computing this measure for large networks remains impractical due to the computational demands of existing methods. In this paper, we present a novel formulation of random walk centrality, underpinning two scalable algorithms: one leveraging approximate Cholesky factorization and sparse inverse estimation, while the other sampling rooted spanning trees. Both algorithms operate in near-linear time and provide strong approximation guarantees. Extensive experiments on large real-world networks, including one with over 10 million nodes, demonstrate the efficiency and approximation quality of the proposed algorithms.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ random walk centrality åœ¨å¤§å‹ç½‘ç»œä¸­è®¡ç®—å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…¨æ–°çš„å…¬å¼è¡¨è¾¾ã€‚åŸºäºæ­¤å…¬å¼ï¼Œç ”ç©¶è€…è®¾è®¡äº†ä¸¤ç§å…·æœ‰å¼ºè¿‘ä¼¼ä¿è¯ (approximation guarantees) çš„å¯æ‰©å±•ç®—æ³•ï¼šä¸€ç§åˆ©ç”¨è¿‘ä¼¼ Cholesky factorization å’Œ sparse inverse estimationï¼Œå¦ä¸€ç§åˆ™é€šè¿‡ rooted spanning trees é‡‡æ ·å®ç°ã€‚è¿™ä¸¤ç§ç®—æ³•å‡èƒ½åœ¨è¿‘çº¿æ€§æ—¶é—´ (near-linear time) å†…è¿è¡Œï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨åŒ…å«è¶…è¿‡ 1000 ä¸‡ä¸ªèŠ‚ç‚¹çš„å¤§è§„æ¨¡çœŸå®ç½‘ç»œä¸Šï¼Œæ–°ç®—æ³•åœ¨ä¿æŒé«˜è¿‘ä¼¼è´¨é‡çš„åŒæ—¶è¡¨ç°å‡ºæé«˜çš„æ•ˆç‡ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨å¤§è§„æ¨¡å›¾æŒ–æ˜ä¸­åº”ç”¨ random walk centrality æä¾›äº†åˆ‡å®å¯è¡Œçš„è®¡ç®—æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by TKDE",
      "pdf_url": "https://arxiv.org/pdf/2510.20604v1",
      "published_date": "2025-10-23 14:36:38 UTC",
      "updated_date": "2025-10-23 14:36:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:41.464531+00:00"
    },
    {
      "arxiv_id": "2510.21876v1",
      "title": "AI Powered Urban Green Infrastructure Assessment Through Aerial Imagery of an Industrial Township",
      "title_zh": "åŸºäºèˆªç©ºå½±åƒçš„äººå·¥æ™ºèƒ½é©±åŠ¨å·¥ä¸šåŸé•‡ç»¿è‰²åŸºç¡€è®¾æ–½è¯„ä¼°",
      "authors": [
        "Anisha Dutta"
      ],
      "abstract": "Accurate assessment of urban canopy coverage is crucial for informed urban planning, effective environmental monitoring, and mitigating the impacts of climate change. Traditional practices often face limitations due to inadequate technical requirements, difficulties in scaling and data processing, and the lack of specialized expertise. This study presents an efficient approach for estimating green canopy coverage using artificial intelligence, specifically computer vision techniques, applied to aerial imageries. Our proposed methodology utilizes object-based image analysis, based on deep learning algorithms to accurately identify and segment green canopies from high-resolution drone images. This approach allows the user for detailed analysis of urban vegetation, capturing variations in canopy density and understanding spatial distribution. To overcome the computational challenges associated with processing large datasets, it was implemented over a cloud platform utilizing high-performance processors. This infrastructure efficiently manages space complexity and ensures affordable latency, enabling the rapid analysis of vast amounts of drone imageries. Our results demonstrate the effectiveness of this approach in accurately estimating canopy coverage at the city scale, providing valuable insights for urban forestry management of an industrial township. The resultant data generated by this method can be used to optimize tree plantation and assess the carbon sequestration potential of urban forests. By integrating these insights into sustainable urban planning, we can foster more resilient urban environments, contributing to a greener and healthier future.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»ŸåŸå¸‚ç»¿å† å±‚è¦†ç›–è¯„ä¼°åœ¨è§„æ¨¡åŒ–å’Œæ•°æ®å¤„ç†æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½(AI)å’Œè®¡ç®—æœºè§†è§‰(Computer Vision)æŠ€æœ¯çš„è¯„ä¼°æ–¹æ³•ã€‚è¯¥æ–¹æ¡ˆåˆ©ç”¨æ·±åº¦å­¦ä¹ (Deep Learning)ç®—æ³•å¯¹é«˜åˆ†è¾¨ç‡æ— äººæœºå›¾åƒè¿›è¡Œé¢å‘å¯¹è±¡çš„å›¾åƒåˆ†æ(Object-based Image Analysis)ï¼Œä»è€Œå®ç°ç»¿å† å±‚çš„ç²¾ç¡®è¯†åˆ«ä¸åˆ†å‰²ã€‚ä¸ºåº”å¯¹å¤§è§„æ¨¡æ•°æ®é›†å¸¦æ¥çš„è®¡ç®—æŒ‘æˆ˜ï¼Œç ”ç©¶å°†è¯¥ç³»ç»Ÿéƒ¨ç½²äºé«˜æ€§èƒ½äº‘å¹³å°(Cloud Platform)ï¼Œåœ¨ä¿è¯ä½å»¶è¿Ÿçš„åŒæ—¶æœ‰æ•ˆç®¡ç†äº†è®¡ç®—ç©ºé—´å¤æ‚åº¦ã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å·¥ä¸šåŒ–åŸé•‡å°ºåº¦ä¸Šå‡†ç¡®è¯„ä¼°å† å±‚è¦†ç›–ç‡çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåŸå¸‚æ—ä¸šç®¡ç†æä¾›äº†ç§‘å­¦ä¾æ®ã€‚é€šè¿‡æ•´åˆè¿™äº›ç ”ç©¶è§è§£ï¼ŒåŸå¸‚è§„åˆ’è€…å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¤æ ‘æ–¹æ¡ˆå¹¶è¯„ä¼°åŸå¸‚æ£®æ—çš„ç¢³æ±‡æ½œåŠ›(Carbon Sequestration Potential)ï¼Œä»è€ŒåŠ©åŠ›æ„å»ºæ›´å…·éŸ§æ€§çš„å¯æŒç»­åŸå¸‚ç¯å¢ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Presented at IIIE Conference 2024, Jamshedpur",
      "pdf_url": "https://arxiv.org/pdf/2510.21876v1",
      "published_date": "2025-10-23 14:36:20 UTC",
      "updated_date": "2025-10-23 14:36:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:45.657371+00:00"
    },
    {
      "arxiv_id": "2510.20603v1",
      "title": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation",
      "title_zh": "ä½•ä¸º LLM çš„ä¼˜è´¨æ¨ç†ï¼ŸåŸºäºå¤šç»´åº¦è¯„ä¼°çš„æ¨ç†æ­¥éª¤æ·±åº¦å‰–æ",
      "authors": [
        "Heejin Do",
        "Jaehui Hwang",
        "Dongyoon Han",
        "Seong Joon Oh",
        "Sangdoo Yun"
      ],
      "abstract": "Evaluating large language models (LLMs) on final-answer correctness is the dominant paradigm. This approach, however, provides a coarse signal for model improvement and overlooks the quality of the underlying reasoning process. We argue that a more granular evaluation of reasoning offers a more effective path to building robust models. We decompose reasoning quality into two dimensions: relevance and coherence. Relevance measures if a step is grounded in the problem; coherence measures if it follows logically from prior steps. To measure these aspects reliably, we introduce causal stepwise evaluation (CaSE). This method assesses each reasoning step using only its preceding context, which avoids hindsight bias. We validate CaSE against human judgments on our new expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we show that curating training data with CaSE-evaluated relevance and coherence directly improves final task performance. Our work provides a scalable framework for analyzing, debugging, and improving LLM reasoning, demonstrating the practical value of moving beyond validity checks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†è´¨é‡çš„å®šä¹‰ï¼ŒæŒ‡å‡ºä»…ä¾èµ–æœ€ç»ˆç­”æ¡ˆæ­£ç¡®æ€§çš„è¯„ä¼°æ–¹å¼è¿‡äºç²—ç•¥ï¼Œæ— æ³•åæ˜ æ¨ç†è¿‡ç¨‹çš„çœŸå®è´¨é‡ã€‚ä½œè€…å°†æ¨ç†è´¨é‡æ‹†è§£ä¸ºç›¸å…³æ€§ï¼ˆRelevanceï¼‰å’Œè¿è´¯æ€§ï¼ˆCoherenceï¼‰ä¸¤ä¸ªæ ¸å¿ƒç»´åº¦ï¼Œåˆ†åˆ«è¡¡é‡æ¨ç†æ­¥éª¤æ˜¯å¦åŸºäºé—®é¢˜èƒŒæ™¯ä»¥åŠæ˜¯å¦åœ¨å‰æ–‡é€»è¾‘ä¸Šè‡ªæ´½ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†å› æœé€æ­¥è¯„ä¼°ï¼ˆCausal Stepwise Evaluation, CaSEï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä»…ä¾æ®å‰æ–‡èƒŒæ™¯è¯„ä¼°æ¯ä¸ªæ­¥éª¤æ¥æœ‰æ•ˆé¿å…äº‹ååå·®ï¼ˆHindsight Biasï¼‰ã€‚ç ”ç©¶äººå‘˜åœ¨ä¸“å®¶æ ‡æ³¨çš„æ–°åŸºå‡†æ•°æ®é›† MRa-GSM8K å’Œ MRa-MATH ä¸ŠéªŒè¯äº† CaSE ä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ï¼Œå¹¶è¯æ˜åˆ©ç”¨è¯¥æ–¹æ³•ç­›é€‰è®­ç»ƒæ•°æ®èƒ½ç›´æ¥æå‡æ¨¡å‹çš„æœ€ç»ˆä»»åŠ¡è¡¨ç°ã€‚è¯¥å·¥ä½œä¸ºåˆ†æã€è°ƒè¯•å’Œæ”¹è¿› LLMs çš„æ¨ç†èƒ½åŠ›æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œå±•ç¤ºäº†è¶…è¶Šç®€å•æ­£ç¡®æ€§æ ¡éªŒçš„å®é™…åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20603v1",
      "published_date": "2025-10-23 14:30:37 UTC",
      "updated_date": "2025-10-23 14:30:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:48.146408+00:00"
    },
    {
      "arxiv_id": "2510.20602v1",
      "title": "Resounding Acoustic Fields with Reciprocity",
      "title_zh": "åŸºäºäº’æ˜“æ€§çš„å£°åœºé‡å“",
      "authors": [
        "Zitong Lan",
        "Yiduo Hao",
        "Mingmin Zhao"
      ],
      "abstract": "Achieving immersive auditory experiences in virtual environments requires flexible sound modeling that supports dynamic source positions. In this paper, we introduce a task called resounding, which aims to estimate room impulse responses at arbitrary emitter location from a sparse set of measured emitter positions, analogous to the relighting problem in vision. We leverage the reciprocity property and introduce Versa, a physics-inspired approach to facilitating acoustic field learning. Our method creates physically valid samples with dense virtual emitter positions by exchanging emitter and listener poses. We also identify challenges in deploying reciprocity due to emitter/listener gain patterns and propose a self-supervised learning approach to address them. Results show that Versa substantially improve the performance of acoustic field learning on both simulated and real-world datasets across different metrics. Perceptual user studies show that Versa can greatly improve the immersive spatial sound experience. Code, dataset and demo videos are available on the project website: https://waves.seas.upenn.edu/projects/versa.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è™šæ‹Ÿç¯å¢ƒä¸­æ²‰æµ¸å¼å¬è§‰ä½“éªŒçš„éœ€æ±‚ï¼Œå®šä¹‰äº†åä¸º resounding çš„ä»»åŠ¡ï¼Œæ—¨åœ¨ä»ç¨€ç–çš„æµ‹é‡ä½ç½®å‡ºå‘ï¼Œä¼°ç®—ä»»æ„å‘å°„å™¨ï¼ˆemitterï¼‰ä½ç½®ä¸‹çš„æˆ¿é—´è„‰å†²å“åº”ï¼ˆroom impulse responsesï¼‰ã€‚å—ç‰©ç†å­¦ä¸­äº’æ˜“æ€§ï¼ˆreciprocityï¼‰åŸç†çš„å¯å‘ï¼Œä½œè€…æå‡ºäº† Versa è¿™ä¸€ç‰©ç†å¯å‘å¼å£°åœºå­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå®ç°çµæ´»çš„å£°åœºå»ºæ¨¡ã€‚Versa é€šè¿‡äº¤æ¢å‘å°„å™¨ä¸å¬è€…ï¼ˆlistenerï¼‰çš„ä½ç½®æ¥ç”Ÿæˆå…·æœ‰å¯†é›†è™šæ‹Ÿå‘å°„å™¨ä½ç½®çš„ç‰©ç†æœ‰æ•ˆæ ·æœ¬ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†æ•°æ®ç¨€ç–é—®é¢˜ã€‚é’ˆå¯¹åº”ç”¨äº’æ˜“æ€§æ—¶é¢ä¸´çš„å‘å°„å™¨ä¸å¬è€…å¢ç›Šæ¨¡å¼ï¼ˆgain patternsï¼‰ä¸ä¸€è‡´çš„æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªç›‘ç£å­¦ä¹ ï¼ˆself-supervised learningï¼‰æ–¹æ³•è¿›è¡Œä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVersa åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡æ˜¾è‘—æå‡äº†å£°åœºå­¦ä¹ æ€§èƒ½ï¼Œç›¸å…³æŒ‡æ ‡è¡¨ç°ä¼˜å¼‚ã€‚æ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¤§å¹…å¢å¼ºè™šæ‹Ÿç¯å¢ƒä¸­çš„æ²‰æµ¸å¼ç©ºé—´éŸ³æ•ˆä½“éªŒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20602v1",
      "published_date": "2025-10-23 14:30:09 UTC",
      "updated_date": "2025-10-23 14:30:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:51.965438+00:00"
    },
    {
      "arxiv_id": "2510.20596v1",
      "title": "Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation",
      "title_zh": "åŸºäºç›¸ä¼¼åº¦åŸå‹çš„è·¨æ¨¡æ€åˆ†å‰²æ— ç›‘ç£é¢†åŸŸè‡ªé€‚åº”",
      "authors": [
        "Ziyu Ye",
        "Chen Ju",
        "Chaofan Ma",
        "Xiaoyun Zhang"
      ],
      "abstract": "Deep learning models have achieved great success on various vision challenges, but a well-trained model would face drastic performance degradation when applied to unseen data. Since the model is sensitive to domain shift, unsupervised domain adaptation attempts to reduce the domain gap and avoid costly annotation of unseen domains. This paper proposes a novel framework for cross-modality segmentation via similarity-based prototypes. In specific, we learn class-wise prototypes within an embedding space, then introduce a similarity constraint to make these prototypes representative for each semantic class while separable from different classes. Moreover, we use dictionaries to store prototypes extracted from different images, which prevents the class-missing problem and enables the contrastive learning of prototypes, and further improves performance. Extensive experiments show that our method achieves better results than other state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è·¨æ¨¡æ€åˆ†å‰²ä¸­ç”±äºé¢†åŸŸåç§» (Domain Shift) å¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ä¸”æ–°é¢†åŸŸæ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç›¸ä¼¼æ€§åŸå‹ (Similarity-based Prototypes) çš„æ— ç›‘ç£é¢†åŸŸè‡ªé€‚åº” (Unsupervised Domain Adaptation) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨åµŒå…¥ç©ºé—´ä¸­å­¦ä¹ ç±»åˆ«åŸå‹ï¼Œå¹¶å¼•å…¥ç›¸ä¼¼æ€§çº¦æŸæ¥ç¡®ä¿åŸå‹èƒ½å¤Ÿä»£è¡¨ç‰¹å®šè¯­ä¹‰ç±»åˆ«ï¼ŒåŒæ—¶ä½¿ä¸åŒç±»åˆ«é—´ä¿æŒå¯åˆ†ç¦»ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨å­—å…¸æ¥å­˜å‚¨ä»ä¸åŒå›¾åƒä¸­æå–çš„åŸå‹ï¼Œè¿™ä¸ä»…è§£å†³äº†ç±»åˆ«ç¼ºå¤±é—®é¢˜ï¼Œè¿˜å®ç°äº†åŸå‹çš„å¯¹æ¯”å­¦ä¹  (Contrastive Learning) ä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è·¨æ¨¡æ€ä»»åŠ¡ä¸­å–å¾—äº†ä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ (State-of-the-art) çš„ç»“æœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "MICCAI 2021",
      "pdf_url": "https://arxiv.org/pdf/2510.20596v1",
      "published_date": "2025-10-23 14:24:12 UTC",
      "updated_date": "2025-10-23 14:24:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:14:57.866928+00:00"
    },
    {
      "arxiv_id": "2510.20591v1",
      "title": "Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting",
      "title_zh": "åŸºäºæ¯çº¿åˆ†è£‚çš„è¾“ç”µé˜»å¡ç®¡ç†å¯è¿ç§»å›¾å­¦ä¹ ",
      "authors": [
        "Ali Rajaei",
        "Peter Palensky",
        "Jochen L. Cremer"
      ],
      "abstract": "Network topology optimization (NTO) via busbar splitting can mitigate transmission grid congestion and reduce redispatch costs. However, solving this mixed-integer non-linear problem for large-scale systems in near-real-time is currently intractable with existing solvers. Machine learning (ML) approaches have emerged as a promising alternative, but they have limited generalization to unseen topologies, varying operating conditions, and different systems, which limits their practical applicability. This paper formulates NTO for congestion management problem considering linearized AC PF, and proposes a graph neural network (GNN)-accelerated approach. We develop a heterogeneous edge-aware message passing NN to predict effective busbar splitting actions as candidate NTO solutions. The proposed GNN captures local flow patterns, achieves generalization to unseen topology changes, and improves transferability across systems. Case studies show up to 4 orders-of-magnitude speed-up, delivering AC-feasible solutions within one minute and a 2.3% optimality gap on the GOC 2000-bus system. These results demonstrate a significant step toward near-real-time NTO for large-scale systems with topology and cross-system generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¾“ç”µç½‘æ‹¥å¡ç®¡ç†ä¸­çš„ç½‘ç»œæ‹“æ‰‘ä¼˜åŒ–(Network topology optimization, NTO)é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„æ¯çº¿åˆ†è£‚(Busbar Splitting)å†³ç­–åœ¨å¤§è§„æ¨¡ç³»ç»Ÿä¸­è®¡ç®—å¼€é”€å·¨å¤§ï¼Œè€Œç°æœ‰æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†æœªè§æ‹“æ‰‘å’Œè·¨ç³»ç»Ÿåº”ç”¨æ—¶æ³›åŒ–æ€§æœ‰é™ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œ(GNN)çš„åŠ é€Ÿæ–¹æ³•ï¼Œå¼€å‘äº†å¼‚æ„è¾¹æ„ŸçŸ¥æ¶ˆæ¯ä¼ é€’ç¥ç»ç½‘ç»œ(Heterogeneous edge-aware message passing NN)æ¥é¢„æµ‹å€™é€‰çš„æ¯çº¿åˆ†è£‚æ–¹æ¡ˆã€‚è¯¥æ¨¡å‹é€šè¿‡æ•æ‰å±€éƒ¨æ½®æµæ¨¡å¼ï¼Œå®ç°äº†å¯¹æ‹“æ‰‘å˜åŒ–çš„æ³›åŒ–ä»¥åŠåœ¨ä¸åŒç”µåŠ›ç³»ç»Ÿé—´çš„è¿ç§»æ€§(Transferability)ã€‚åœ¨GOC 2000èŠ‚ç‚¹ç³»ç»Ÿä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æ¯”ç°æœ‰æ±‚è§£å™¨æé€Ÿè¾¾å››ä¸ªæ•°é‡çº§ï¼Œèƒ½åœ¨ä¸€åˆ†é’Ÿå†…ç”Ÿæˆäº¤æµå¯è¡Œ(AC-feasible)çš„æ–¹æ¡ˆï¼Œä¸”æœ€ä¼˜æ€§å·®è·(Optimality gap)ä»…ä¸º2.3%ã€‚è¯¥ç ”ç©¶æ˜¾è‘—æå‡äº†å¤§è§„æ¨¡ç³»ç»Ÿè¿‘å®æ—¶NTOçš„å¯è¡Œæ€§ï¼Œä¸ºå…·å¤‡æ³›åŒ–èƒ½åŠ›çš„ç”µåŠ›ç³»ç»Ÿæ™ºèƒ½è°ƒåº¦æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20591v1",
      "published_date": "2025-10-23 14:16:23 UTC",
      "updated_date": "2025-10-23 14:16:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:13.056151+00:00"
    },
    {
      "arxiv_id": "2510.20584v1",
      "title": "Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks",
      "title_zh": "ChatGPT èƒ½å¦å…¬å¹³åœ°å¯¹æ²Ÿé€šæ•°æ®è¿›è¡Œç¼–ç ï¼Ÿæ¥è‡ªå¤šé¡¹åä½œä»»åŠ¡çš„å®è¯è¯æ®",
      "authors": [
        "Jiangang Hao",
        "Wenju Cui",
        "Patrick Kyllonen",
        "Emily Kerzabi"
      ],
      "abstract": "Assessing communication and collaboration at scale depends on a labor intensive task of coding communication data into categories according to different frameworks. Prior research has established that ChatGPT can be directly instructed with coding rubrics to code the communication data and achieves accuracy comparable to human raters. However, whether the coding from ChatGPT or similar AI technology exhibits bias against different demographic groups, such as gender and race, remains unclear. To fill this gap, this paper investigates ChatGPT-based automated coding of communication data using a typical coding framework for collaborative problem solving, examining differences across gender and racial groups. The analysis draws on data from three types of collaborative tasks: negotiation, problem solving, and decision making. Our results show that ChatGPT-based coding exhibits no significant bias across gender and racial groups, paving the road for its adoption in large-scale assessment of collaboration and communication.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† ChatGPT åœ¨å¯¹åä½œä»»åŠ¡(collaborative tasks)ä¸­çš„æ²Ÿé€šæ•°æ®è¿›è¡Œè‡ªåŠ¨ç¼–ç æ—¶ï¼Œæ˜¯å¦å­˜åœ¨æ€§åˆ«å’Œç§æ—æ–¹é¢çš„åè§(bias)ã€‚ç ”ç©¶æ—¨åœ¨éªŒè¯ AI æŠ€æœ¯åœ¨æ›¿ä»£äººå·¥è¿›è¡Œå¤§è§„æ¨¡è¯„ä¼°æ—¶çš„å…¬å¹³æ€§(fairness)ï¼Œå¹¶åˆ©ç”¨å…¸å‹çš„åä½œé—®é¢˜è§£å†³(collaborative problem solving)æ¡†æ¶è¿›è¡Œäº†å®è¯æµ‹è¯•ã€‚åˆ†ææ•°æ®æ¥æºäºè°ˆåˆ¤(negotiation)ã€é—®é¢˜è§£å†³(problem solving)å’Œå†³ç­–(decision making)ä¸‰ç±»ä¸åŒçš„åä½œä»»åŠ¡åœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäº ChatGPT çš„è‡ªåŠ¨ç¼–ç åœ¨ä¸åŒæ€§åˆ«å’Œç§æ—ç¾¤ä½“ä¹‹é—´å¹¶æœªè¡¨ç°å‡ºæ˜¾è‘—çš„ç»Ÿè®¡å­¦åè§ã€‚è¿™ä¸€å‘ç°ä¸ºåœ¨å¤§è§„æ¨¡æ²Ÿé€šä¸åä½œè¯„ä¼°(large-scale assessment of communication and collaboration)ä¸­é‡‡ç”¨ç”Ÿæˆå¼ AI æ¨¡å‹æä¾›äº†å…³é”®çš„å…¬å¹³æ€§è¯æ®ã€‚è¯¥ç ”ç©¶ä¸ä»…è¯æ˜äº† AI è‡ªåŠ¨åŒ–ç¼–ç çš„å¯é æ€§ï¼Œä¹Ÿä¸ºå…¶åœ¨æ•™è‚²åŠç»„ç»‡è¡Œä¸ºç ”ç©¶ä¸­çš„å¹¿æ³›æ¨å¹¿é“ºå¹³äº†é“è·¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "38 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20584v1",
      "published_date": "2025-10-23 14:09:03 UTC",
      "updated_date": "2025-10-23 14:09:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:18.262689+00:00"
    },
    {
      "arxiv_id": "2510.20579v1",
      "title": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence",
      "title_zh": "Open-o3 Videoï¼šåŸºäºæ˜¾å¼æ—¶ç©ºè¯æ®çš„è§†é¢‘å®šä½æ¨ç†",
      "authors": [
        "Jiahao Meng",
        "Xiangtai Li",
        "Haochen Wang",
        "Yue Tan",
        "Tao Zhang",
        "Lingdong Kong",
        "Yunhai Tong",
        "Anran Wang",
        "Zhiyang Teng",
        "Yujing Wang",
        "Zhuochen Wang"
      ],
      "abstract": "Most video reasoning models only generate textual reasoning traces without indicating when and where key evidence appears. Recent models such as OpenAI-o3 have sparked wide interest in evidence-centered reasoning for images, yet extending this ability to videos is more challenging, as it requires joint temporal tracking and spatial localization across dynamic scenes. We introduce Open-o3 Video, a non-agent framework that integrates explicit spatio-temporal evidence into video reasoning, and carefully collect training data and design training strategies to address the aforementioned challenges. The model highlights key timestamps, objects, and bounding boxes alongside its answers, allowing reasoning to be grounded in concrete visual observations. To enable this functionality, we first curate and build two high-quality datasets, STGR-CoT-30k for SFT and STGR-RL-36k for RL, with carefully constructed temporal and spatial annotations, since most existing datasets offer either temporal spans for videos or spatial boxes on images, lacking unified spatio-temporal supervision and reasoning traces. Then, we adopt a cold-start reinforcement learning strategy with multiple specially designed rewards that jointly encourage answer accuracy, temporal alignment, and spatial precision. On V-STAR benchmark, Open-o3 Video achieves state-of-the-art performance, raising mAM by 14.4% and mLGM by 24.2% on the Qwen2.5-VL baseline. Consistent improvements are also observed on a broad range of video understanding benchmarks, including VideoMME, WorldSense, VideoMMMU, and TVGBench. Beyond accuracy, the reasoning traces produced by Open-o3 Video also provide valuable signals for test-time scaling, enabling confidence-aware verification and improving answer reliability.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº† Open-o3 Videoï¼Œè¿™æ˜¯ä¸€ä¸ªå°†æ˜¾å¼æ—¶ç©ºè¯æ® (Explicit Spatio-Temporal Evidence) èå…¥è§†é¢‘æ¨ç†çš„éæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨åŠ¨æ€åœºæ™¯ä¸­ç¼ºä¹è”åˆæ—¶é—´è¿½è¸ªå’Œç©ºé—´å®šä½çš„é—®é¢˜ã€‚ä¸ºäº†å®ç°è¿™ä¸€åŠŸèƒ½ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†åŒ…å«ç»Ÿä¸€æ—¶ç©ºæ ‡æ³¨çš„ STGR-CoT-30k å’Œ STGR-RL-36k é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨äº†ç»“åˆå‡†ç¡®æ€§ã€æ—¶é—´å¯¹é½å’Œç©ºé—´ç²¾åº¦å¥–åŠ±çš„å†·å¯åŠ¨å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOpen-o3 Video åœ¨ V-STAR åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—ä¼˜äº Qwen2.5-VL åŸºçº¿ï¼Œå…¶ mAM å’Œ mLGM æŒ‡æ ‡åˆ†åˆ«æå‡äº† 14.4% å’Œ 24.2%ã€‚è¯¥æ¨¡å‹åœ¨ VideoMME å’Œ VideoMMMU ç­‰å¹¿æ³›çš„è§†é¢‘ç†è§£åŸºå‡†ä¸Šä¹Ÿè¾¾åˆ°äº† SOTA æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒOpen-o3 Video ç”Ÿæˆçš„æ¨ç†è½¨è¿¹ä¸ºæµ‹è¯•æ—¶ç¼©æ”¾ (Test-Time Scaling) æä¾›äº†å…³é”®ä¿¡å·ï¼Œæœ‰æ•ˆæå‡äº†å¤æ‚æ¨ç†ä»»åŠ¡çš„å¯é æ€§ä¸ç½®ä¿¡åº¦éªŒè¯èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20579v1",
      "published_date": "2025-10-23 14:05:56 UTC",
      "updated_date": "2025-10-23 14:05:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:24.358012+00:00"
    },
    {
      "arxiv_id": "2510.23621v1",
      "title": "Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields",
      "title_zh": "åŠ é€Ÿ MACEï¼šç­‰å˜åŠ›åœºä¸­çš„ä½ç²¾åº¦ä¼˜åŒ–æŠ€å·§",
      "authors": [
        "Alexandre Benoit"
      ],
      "abstract": "Machine-learning force fields can deliver accurate molecular dynamics (MD) at high computational cost. For SO(3)-equivariant models such as MACE, there is little systematic evidence on whether reduced-precision arithmetic and GPU-optimized kernels can cut this cost without harming physical fidelity. This thesis aims to make MACE cheaper and faster while preserving accuracy by identifying computational bottlenecks and evaluating low-precision execution policies. We profile MACE end-to-end and per block, compare the e3nn and NVIDIA cuEquivariance backends, and assess FP64/FP32/BF16/FP16 settings (with FP32 accumulation) for inference, short NVT and long NPT water simulations, and toy training runs under reproducible, steady-state timing. cuEquivariance reduces inference latency by about $3\\times$. Casting only linear layers to BF16/FP16 within an FP32 model yields roughly 4x additional speedups, while energies and thermodynamic observables in NVT/NPT MD remain within run-to-run variability. Half-precision weights during training degrade force RMSE. Mixing e3nn and cuEq modules without explicit adapters causes representation mismatches. Fused equivariant kernels and mixed-precision inference can substantially accelerate state-of-the-art force fields with negligible impact on downstream MD. A practical policy is to use cuEquivariance with FP32 by default and enable BF16/FP16 for linear layers (keeping FP32 accumulations) for maximum throughput, while training remains in FP32. Further gains are expected on Ampere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and pipeline fusion.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šè¿‡ä½ç²¾åº¦ç®—æœ¯å’ŒGPUä¼˜åŒ–å†…æ ¸åŠ é€ŸSO(3)-equivariantåŠ›åœºæ¨¡å‹MACEçš„æ–¹æ³•ï¼Œæ—¨åœ¨æ˜¾è‘—é™ä½å…¶åœ¨åˆ†å­åŠ¨åŠ›å­¦(MD)æ¨¡æ‹Ÿä¸­çš„è®¡ç®—æˆæœ¬ã€‚ä½œè€…é€šè¿‡ç«¯åˆ°ç«¯å‰–æï¼Œå¯¹æ¯”äº†e3nnä¸NVIDIA cuEquivarianceåç«¯ï¼Œå¹¶ç³»ç»Ÿè¯„ä¼°äº†ä»FP64åˆ°FP16ç­‰å¤šç§ç²¾åº¦è®¾ç½®å¯¹æ¨ç†ã€è®­ç»ƒåŠé•¿å‘¨æœŸMDæ¨¡æ‹Ÿçš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒcuEquivarianceèƒ½å°†æ¨ç†å»¶è¿Ÿé™ä½çº¦3å€ï¼Œè€Œå°†æ¨¡å‹ä¸­çš„çº¿æ€§å±‚è½¬æ¢ä¸ºBF16/FP16ç²¾åº¦å¯é¢å¤–å®ç°çº¦4å€çš„åŠ é€Ÿã€‚è¿™ç§æ··åˆç²¾åº¦æ¨ç†ç­–ç•¥å¯¹èƒ½é‡å’Œçƒ­åŠ›å­¦è§‚æµ‹å€¼çš„ç‰©ç†ç²¾åº¦å½±å“æå°ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç»´æŒMDæ¨¡æ‹Ÿçš„ä¿çœŸåº¦ã€‚å°½ç®¡ç ”ç©¶å‘ç°è®­ç»ƒé˜¶æ®µä½¿ç”¨åŠç²¾åº¦æƒé‡ä¼šå¢åŠ åŠ›åœºçš„RMSEï¼Œä½†æ¨ç†é˜¶æ®µçš„ä¼˜åŒ–æ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„è®¡ç®—ååé‡ã€‚åŸºäºå®éªŒå‘ç°ï¼Œä½œè€…å»ºè®®åœ¨æ¨ç†æ—¶é»˜è®¤ä½¿ç”¨cuEquivarianceä¸FP32å¹¶é’ˆå¯¹çº¿æ€§å±‚å¼€å¯BF16/FP16åŠ é€Ÿï¼Œè€Œè®­ç»ƒè¿‡ç¨‹åˆ™åº”ç»´æŒåœ¨FP32ç²¾åº¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "78 pages, 21 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.23621v1",
      "published_date": "2025-10-23 14:02:34 UTC",
      "updated_date": "2025-10-23 14:02:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:34.367684+00:00"
    },
    {
      "arxiv_id": "2510.20568v1",
      "title": "Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI",
      "title_zh": "è¿·å¤±åœ¨â€œç¿»è¯‘â€ä¸­ï¼šæ”¿ç­–åˆ¶å®šè€…å¹¶æœªçœŸæ­£å€¾å¬å…¬ä¼—å¯¹äººå·¥æ™ºèƒ½çš„å…³åˆ‡",
      "authors": [
        "Susan Ariel Aaronson",
        "Michael Moreno"
      ],
      "abstract": "The worlds people have strong opinions about artificial intelligence (AI), and they want policymakers to listen. Governments are inviting public comment on AI, but as they translate input into policy, much of what citizens say is lost. Policymakers are missing a critical opportunity to build trust in AI and its governance. This paper compares three countries, Australia, Colombia, and the United States, that invited citizens to comment on AI risks and policies. Using a landscape analysis, the authors examined how each government solicited feedback and whether that input shaped governance. Yet in none of the three cases did citizens and policymakers establish a meaningful dialogue. Governments did little to attract diverse voices or publicize calls for comment, leaving most citizens unaware or unprepared to respond. In each nation, fewer than one percent of the population participated. Moreover, officials showed limited responsiveness to the feedback they received, failing to create an effective feedback loop. The study finds a persistent gap between the promise and practice of participatory AI governance. The authors conclude that current approaches are unlikely to build trust or legitimacy in AI because policymakers are not adequately listening or responding to public concerns. They offer eight recommendations: promote AI literacy; monitor public feedback; broaden outreach; hold regular online forums; use innovative engagement methods; include underrepresented groups; respond publicly to input; and make participation easier.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…¬ä¼—å¯¹äººå·¥æ™ºèƒ½(AI)æ²»ç†çš„å…³æ³¨ï¼Œå¹¶æŒ‡å‡ºæ”¿åºœåœ¨å°†å…¬ä¼—æ„è§è½¬åŒ–ä¸ºæ”¿ç­–çš„è¿‡ç¨‹ä¸­å­˜åœ¨ä¸¥é‡çš„â€œå¤±çœŸâ€ç°è±¡ã€‚ä½œè€…é€šè¿‡å¯¹æ¾³å¤§åˆ©äºšã€å“¥ä¼¦æ¯”äºšå’Œç¾å›½çš„äººå·¥æ™ºèƒ½é£é™©ä¸æ”¿ç­–åé¦ˆæµç¨‹è¿›è¡Œå…¨æ™¯åˆ†æ(Landscape analysis)ï¼Œå‘ç°å„å›½æ”¿åºœå‡æœªèƒ½ä¸å…¬ä¼—å»ºç«‹å®è´¨æ€§çš„å¯¹è¯ã€‚ç”±äºå®£ä¼ ä¸è¶³å’Œé—¨æ§›è¾ƒé«˜ï¼Œä¸‰ä¸ªå›½å®¶çš„å‚ä¸äººæ•°å‡ä¸è¶³æ€»äººå£çš„1%ï¼Œä¸”å®˜æ–¹å¯¹æ”¶é›†åˆ°çš„åé¦ˆç¼ºä¹ç§¯æå›åº”ï¼Œå¯¼è‡´å‚ä¸å¼AIæ²»ç†çš„æ‰¿è¯ºä¸ç°å®ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ã€‚ç ”ç©¶è®¤ä¸ºï¼Œç”±äºå†³ç­–è€…æœªèƒ½å……åˆ†å€¾å¬å¹¶å›åº”å…¬ä¼—å…³åˆ‡ï¼Œç°æœ‰çš„æ²»ç†æ¨¡å¼éš¾ä»¥å»ºç«‹å…¬ä¼—å¯¹AIçš„ä¿¡ä»»æˆ–æ²»ç†çš„åˆæ³•æ€§ã€‚é’ˆå¯¹è¿™ä¸€ç°çŠ¶ï¼Œè®ºæ–‡æå‡ºäº†åŒ…æ‹¬æå‡äººå·¥æ™ºèƒ½ç´ å…»(AI literacy)ã€æ‰©å¤§å¤–å»¶æ¨å¹¿ã€åˆ©ç”¨åˆ›æ–°å‚ä¸æ–¹æ³•ä»¥åŠå…¬å¼€å›åº”åé¦ˆç­‰åœ¨å†…çš„å…«é¡¹æ”¹è¿›å»ºè®®ï¼Œæ—¨åœ¨æ„å»ºæ›´å…·åŒ…å®¹æ€§å’Œæœ‰æ•ˆæ€§çš„AIæ²»ç†ä½“ç³»ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20568v1",
      "published_date": "2025-10-23 13:57:02 UTC",
      "updated_date": "2025-10-23 13:57:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:22.866146+00:00"
    },
    {
      "arxiv_id": "2510.20566v1",
      "title": "AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning in SDN",
      "title_zh": "AdaDoSï¼šSDN ä¸­åŸºäºæ·±åº¦å¯¹æŠ—å¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº” DoS æ”»å‡»",
      "authors": [
        "Wei Shao",
        "Yuhao Wang",
        "Rongguang He",
        "Muhammad Ejaz Ahmed",
        "Seyit Camtepe"
      ],
      "abstract": "Existing defence mechanisms have demonstrated significant effectiveness in mitigating rule-based Denial-of-Service (DoS) attacks, leveraging predefined signatures and static heuristics to identify and block malicious traffic. However, the emergence of AI-driven techniques presents new challenges to SDN security, potentially compromising the efficacy of existing defence mechanisms. In this paper, we introduce~AdaDoS, an adaptive attack model that disrupt network operations while evading detection by existing DoS-based detectors through adversarial reinforcement learning (RL). Specifically, AdaDoS models the problem as a competitive game between an attacker, whose goal is to obstruct network traffic without being detected, and a detector, which aims to identify malicious traffic. AdaDoS can solve this game by dynamically adjusting its attack strategy based on feedback from the SDN and the detector. Additionally, recognising that attackers typically have less information than defenders, AdaDoS formulates the DoS-like attack as a partially observed Markov decision process (POMDP), with the attacker having access only to delay information between attacker and victim nodes. We address this challenge with a novel reciprocal learning module, where the student agent, with limited observations, enhances its performance by learning from the teacher agent, who has full observational capabilities in the SDN environment. AdaDoS represents the first application of RL to develop DoS-like attack sequences, capable of adaptively evading both machine learning-based and rule-based DoS-like attack detectors.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†AdaDoSï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ·±åº¦å¯¹æŠ—å¼ºåŒ–å­¦ä¹ (Deep Adversarial Reinforcement Learning)çš„è‡ªé€‚åº”æ‹’ç»æœåŠ¡(DoS)æ”»å‡»æ¨¡å‹ï¼Œæ—¨åœ¨åº”å¯¹è½¯ä»¶å®šä¹‰ç½‘ç»œ(SDN)ä¸­æ—¥ç›Šä¸¥å³»çš„å®‰å…¨æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹å°†æ”»å‡»è¿‡ç¨‹å»ºæ¨¡ä¸ºæ”»å‡»è€…ä¸æ£€æµ‹å™¨ä¹‹é—´çš„ç«äº‰åšå¼ˆï¼Œé€šè¿‡æ ¹æ®SDNç¯å¢ƒå’Œæ£€æµ‹å™¨çš„åé¦ˆåŠ¨æ€è°ƒæ•´ç­–ç•¥æ¥è§„é¿æ£€æµ‹ã€‚è€ƒè™‘åˆ°æ”»å‡»è€…ä¿¡æ¯çš„å±€é™æ€§ï¼Œç ”ç©¶å°†æ­¤ç±»æ”»å‡»å…¬å¼åŒ–ä¸ºéƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(POMDP)ï¼Œæ”»å‡»è€…ä»…éœ€è·å–èŠ‚ç‚¹é—´çš„å»¶è¿Ÿä¿¡æ¯å³å¯æ‰§è¡Œã€‚AdaDoSå¼•å…¥äº†ä¸€ç§åˆ›æ–°çš„ç›¸äº’å­¦ä¹ (Reciprocal Learning)æ¨¡å—ï¼Œä½¿ä»…å…·å¤‡æœ‰é™è§‚æµ‹èƒ½åŠ›çš„â€œå­¦ç”Ÿæ™ºèƒ½ä½“â€èƒ½å¤Ÿä»å…·å¤‡å…¨å±€è§‚æµ‹èƒ½åŠ›çš„â€œè€å¸ˆæ™ºèƒ½ä½“â€ä¸­å­¦ä¹ å¹¶æå‡æ€§èƒ½ã€‚è¿™æ˜¯å¼ºåŒ–å­¦ä¹ (RL)åœ¨å¼€å‘è‡ªé€‚åº”ç±»DoSæ”»å‡»åºåˆ—æ–¹é¢çš„é¦–æ¬¡åº”ç”¨ï¼Œå®éªŒè¯æ˜è¯¥æ¨¡å‹èƒ½æœ‰æ•ˆè§„é¿åŸºäºæœºå™¨å­¦ä¹ (Machine Learning)å’ŒåŸºäºè§„åˆ™çš„å¤šç§æ£€æµ‹æœºåˆ¶ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20566v1",
      "published_date": "2025-10-23 13:51:40 UTC",
      "updated_date": "2025-10-23 13:51:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:24.208261+00:00"
    },
    {
      "arxiv_id": "2510.21874v1",
      "title": "A Physics-Informed Neural Network Approach for UAV Path Planning in Dynamic Environments",
      "title_zh": "åŠ¨æ€ç¯å¢ƒä¸‹æ— äººæœºè·¯å¾„è§„åˆ’çš„ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œæ–¹æ³•",
      "authors": [
        "Shuning Zhang"
      ],
      "abstract": "Unmanned aerial vehicles (UAVs) operating in dynamic wind fields must generate safe and energy-efficient trajectories under physical and environmental constraints. Traditional planners, such as A* and kinodynamic RRT*, often yield suboptimal or non-smooth paths due to discretization and sampling limitations. This paper presents a physics-informed neural network (PINN) framework that embeds UAV dynamics, wind disturbances, and obstacle avoidance directly into the learning process. Without requiring supervised data, the PINN learns dynamically feasible and collision-free trajectories by minimizing physical residuals and risk-aware objectives. Comparative simulations show that the proposed method outperforms A* and Kino-RRT* in control energy, smoothness, and safety margin, while maintaining similar flight efficiency. The results highlight the potential of physics-informed learning to unify model-based and data-driven planning, providing a scalable and physically consistent framework for UAV trajectory optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ (Physics-Informed Neural Network, PINN) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ— äººæœº (UAVs) åœ¨åŠ¨æ€é£åœºä¸­ç”Ÿæˆå®‰å…¨ä¸”èŠ‚èƒ½è½¨è¿¹çš„éš¾é¢˜ã€‚é’ˆå¯¹ A* å’Œ kinodynamic RRT* ç­‰ä¼ ç»Ÿç®—æ³•åœ¨ç¦»æ•£åŒ–å’Œé‡‡æ ·é™åˆ¶ä¸‹æ˜“äº§ç”Ÿæ¬¡ä¼˜æˆ–ä¸å¹³æ»‘è·¯å¾„çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶å°† UAV dynamicsã€é£åœºæ‰°åŠ¨å’Œéšœç¢ç‰©è§„é¿ç›´æ¥åµŒå…¥å­¦ä¹ è¿‡ç¨‹ã€‚åœ¨æ— éœ€ç›‘ç£æ•°æ®çš„æƒ…å†µä¸‹ï¼ŒPINN é€šè¿‡æœ€å°åŒ–ç‰©ç†æ®‹å·®å’Œé£é™©æ„ŸçŸ¥ç›®æ ‡ï¼Œèƒ½å¤Ÿå­¦ä¹ å¹¶ç”ŸæˆåŠ¨æ€å¯è¡Œä¸”æ— ç¢°æ’çš„è½¨è¿¹ã€‚ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ§åˆ¶èƒ½é‡ (control energy)ã€è½¨è¿¹å¹³æ»‘åº¦å’Œå®‰å…¨ä½™é‡ (safety margin) æ–¹é¢å‡æ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºå‡†ç®—æ³•ã€‚è¯¥ç ”ç©¶æˆåŠŸç»Ÿä¸€äº†æ¨¡å‹é©±åŠ¨ä¸æ•°æ®é©±åŠ¨çš„è§„åˆ’æ–¹æ³•ï¼Œä¸ºæ— äººæœºè½¨è¿¹ä¼˜åŒ–æä¾›äº†ä¸€ä¸ªå…·æœ‰å¯æ‰©å±•æ€§ä¸”ç‰©ç†ä¸€è‡´ (physically consistent) çš„é€šç”¨æ¡†æ¶ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.21874v1",
      "published_date": "2025-10-23 13:42:07 UTC",
      "updated_date": "2025-10-23 13:42:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:32.365745+00:00"
    },
    {
      "arxiv_id": "2510.24763v1",
      "title": "Dual-Domain Deep Learning-Assisted NOMA-CSK Systems for Secure and Efficient Vehicular Communications",
      "title_zh": "é¢å‘å®‰å…¨é«˜æ•ˆè½¦è”ç½‘é€šä¿¡çš„åŒåŸŸæ·±åº¦å­¦ä¹ è¾…åŠ© NOMA-CSK ç³»ç»Ÿ",
      "authors": [
        "Tingting Huang",
        "Jundong Chen",
        "Huanqiang Zeng",
        "Guofa Cai",
        "Georges Kaddoum"
      ],
      "abstract": "Ensuring secure and efficient multi-user (MU) transmission is critical for vehicular communication systems. Chaos-based modulation schemes have garnered considerable interest due to their benefits in physical layer security. However, most existing MU chaotic communication systems, particularly those based on non-coherent detection, suffer from low spectral efficiency due to reference signal transmission, and limited user connectivity under orthogonal multiple access (OMA). While non-orthogonal schemes, such as sparse code multiple access (SCMA)-based DCSK, have been explored, they face high computational complexity and inflexible scalability due to their fixed codebook designs. This paper proposes a deep learning-assisted power domain non-orthogonal multiple access chaos shift keying (DL-NOMA-CSK) system for vehicular communications. A deep neural network (DNN)-based demodulator is designed to learn intrinsic chaotic signal characteristics during offline training, thereby eliminating the need for chaotic synchronization or reference signal transmission. The demodulator employs a dual-domain feature extraction architecture that jointly processes the time-domain and frequency-domain information of chaotic signals, enhancing feature learning under dynamic channels. The DNN is integrated into the successive interference cancellation (SIC) framework to mitigate error propagation issues. Theoretical analysis and extensive simulations demonstrate that the proposed system achieves superior performance in terms of spectral efficiency (SE), energy efficiency (EE), bit error rate (BER), security, and robustness, while maintaining lower computational complexity compared to traditional MU-DCSK and existing DL-aided schemes. These advantages validate its practical viability for secure vehicular communications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ·±åº¦å­¦ä¹ è¾…åŠ©çš„åŠŸç‡åŸŸéæ­£äº¤å¤šå€æ¥å…¥æ··æ²Œç§»é”®æ§(DL-NOMA-CSK)ç³»ç»Ÿï¼Œæ—¨åœ¨æå‡è½¦è½½é€šä¿¡çš„å®‰å…¨ä¼ è¾“æ•ˆç‡ã€‚é’ˆå¯¹ä¼ ç»Ÿæ··æ²Œé€šä¿¡ç³»ç»Ÿç”±äºå‚è€ƒä¿¡å·ä¼ è¾“å¯¼è‡´çš„é¢‘è°±æ•ˆç‡ä½ä¸‹ä»¥åŠå›ºå®šç æœ¬è®¾è®¡å¸¦æ¥çš„æ‰©å±•æ€§é™åˆ¶ï¼Œè¯¥æ–¹æ¡ˆè®¾è®¡äº†ä¸€ä¸ªåŸºäºæ·±åº¦ç¥ç»ç½‘ç»œ(DNN)çš„è§£è°ƒå™¨ï¼Œé€šè¿‡ç¦»çº¿å­¦ä¹ æ··æ²Œä¿¡å·ç‰¹å¾æ¶ˆé™¤äº†å¯¹æ··æ²ŒåŒæ­¥æˆ–å‚è€ƒä¿¡å·çš„éœ€æ±‚ã€‚è¯¥è§£è°ƒå™¨é‡‡ç”¨äº†åŒåŸŸç‰¹å¾æå–æ¶æ„ï¼Œèƒ½å¤ŸååŒå¤„ç†æ··æ²Œä¿¡å·çš„æ—¶åŸŸä¸é¢‘åŸŸä¿¡æ¯ï¼Œæ˜¾è‘—å¢å¼ºäº†åœ¨åŠ¨æ€ä¿¡é“ç¯å¢ƒä¸‹çš„ç‰¹å¾å­¦ä¹ èƒ½åŠ›ã€‚åŒæ—¶ï¼Œç ”ç©¶å°†DNNé›†æˆåˆ°ä¸²è¡Œå¹²æ‰°æŠµæ¶ˆ(SIC)æ¡†æ¶ä¸­ï¼Œæœ‰æ•ˆç¼“è§£äº†å¤šç”¨æˆ·æ£€æµ‹ä¸­çš„è¯¯å·®ä¼ æ’­é—®é¢˜ã€‚ä»¿çœŸç»“æœè¯æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨é¢‘è°±æ•ˆç‡(SE)ã€èƒ½é‡æ•ˆç‡(EE)ã€è¯¯ç ç‡(BER)åŠé²æ£’æ€§æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„å¤šç”¨æˆ·å·®åˆ†æ··æ²Œç§»é”®æ§(MU-DCSK)å’Œç°æœ‰æ·±åº¦å­¦ä¹ è¾…åŠ©æ–¹æ¡ˆã€‚è¯¥ç³»ç»Ÿåœ¨ç»´æŒè¾ƒä½è®¡ç®—å¤æ‚åº¦çš„åŒæ—¶æä¾›äº†æ›´å¼ºçš„å®‰å…¨ä¿éšœï¼ŒéªŒè¯äº†å…¶åœ¨å®‰å…¨è½¦è½½é€šä¿¡ä¸­çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.24763v1",
      "published_date": "2025-10-23 13:41:00 UTC",
      "updated_date": "2025-10-23 13:41:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:37.659749+00:00"
    },
    {
      "arxiv_id": "2510.20556v1",
      "title": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics",
      "title_zh": "ç»“æ„ä¸å˜æ€§è‡³å…³é‡è¦ï¼šä»å›¾æŒ‡æ ‡è§†è§’é‡æ–°å®¡è¯•å›¾é‡è¿",
      "authors": [
        "Alexandre Benoit",
        "Catherine Aitken",
        "Yu He"
      ],
      "abstract": "Graph rewiring has emerged as a key technique to alleviate over-squashing in Graph Neural Networks (GNNs) and Graph Transformers by modifying the graph topology to improve information flow. While effective, rewiring inherently alters the graph's structure, raising the risk of distorting important topology-dependent signals. Yet, despite the growing use of rewiring, little is known about which structural properties must be preserved to ensure both performance gains and structural fidelity. In this work, we provide the first systematic analysis of how rewiring affects a range of graph structural metrics, and how these changes relate to downstream task performance. We study seven diverse rewiring strategies and correlate changes in local and global graph properties with node classification accuracy. Our results reveal a consistent pattern: successful rewiring methods tend to preserve local structure while allowing for flexibility in global connectivity. These findings offer new insights into the design of effective rewiring strategies, bridging the gap between graph theory and practical GNN optimization.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å›¾ç¥ç»ç½‘ç»œ(GNNs)å’Œå›¾å˜æ¢å™¨(Graph Transformers)ä¸­ç¼“è§£è¿‡åº¦å‹ç¼©(over-squashing)çš„å…³é”®æŠ€æœ¯â€”â€”å›¾é‡æ„(Graph rewiring)è¿›è¡Œäº†é‡æ–°å®¡è§†ã€‚è™½ç„¶å›¾é‡æ„é€šè¿‡ä¿®æ”¹æ‹“æ‰‘ç»“æ„æ”¹å–„äº†ä¿¡æ¯æµï¼Œä½†å…¶æœ¬è´¨ä¸Šæ”¹å˜äº†å›¾çš„åŸå§‹ç»“æ„ï¼Œå­˜åœ¨æ‰­æ›²æ‹“æ‰‘ä¾èµ–ä¿¡å·çš„é£é™©ã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿåˆ†æäº†é‡æ„å¦‚ä½•å½±å“ä¸€ç³»åˆ—å›¾ç»“æ„æŒ‡æ ‡(graph structural metrics)ä»¥åŠè¿™äº›å˜åŒ–ä¸ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¹‹é—´çš„å…³ç³»ã€‚ç ”ç©¶å›¢é˜Ÿæ·±å…¥è€ƒå¯Ÿäº†ä¸ƒç§ä¸åŒçš„é‡æ„ç­–ç•¥ï¼Œå¹¶å°†å±€éƒ¨å’Œå…¨å±€å›¾å±æ€§çš„å˜åŒ–ä¸èŠ‚ç‚¹åˆ†ç±»å‡†ç¡®ç‡è¿›è¡Œäº†å…³è”åˆ†æã€‚å®éªŒç»“æœæ­ç¤ºäº†ä¸€ä¸ªä¸€è‡´çš„æ¨¡å¼ï¼šæˆåŠŸçš„é‡æ„æ–¹æ³•å€¾å‘äºä¿æŒå±€éƒ¨ç»“æ„(local structure)ï¼ŒåŒæ—¶åœ¨å…¨å±€è¿æ¥(global connectivity)ä¸Šä¿æŒçµæ´»æ€§ã€‚è¿™äº›å‘ç°ä¸ºè®¾è®¡æ›´æœ‰æ•ˆçš„é‡æ„ç­–ç•¥æä¾›äº†é‡è¦è§è§£ï¼ŒæˆåŠŸæ¡¥æ¥äº†å›¾è®ºç ”ç©¶ä¸å®é™…GNNä¼˜åŒ–ä¹‹é—´çš„é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 5 figures, conference",
      "pdf_url": "https://arxiv.org/pdf/2510.20556v1",
      "published_date": "2025-10-23 13:38:41 UTC",
      "updated_date": "2025-10-23 13:38:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:37.859185+00:00"
    },
    {
      "arxiv_id": "2510.20548v3",
      "title": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning",
      "title_zh": "GlobalRAGï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ å¢å¼ºå¤šè·³é—®ç­”ä¸­çš„å…¨å±€æ¨ç†",
      "authors": [
        "Jinchang Luo",
        "Mingquan Cheng",
        "Fan Wan",
        "Ni Li",
        "Xiaoling Xia",
        "Shuangshuang Tian",
        "Tingcheng Bian",
        "Haiwei Wang",
        "Haohuan Fu",
        "Yan Tao"
      ],
      "abstract": "Reinforcement learning has recently shown promise in improving retrieval-augmented generation (RAG). Despite these advances, its effectiveness in multi-hop question answering (QA) remains limited by two fundamental limitations: (i) global planning absence to structure multi-step reasoning, and (ii) unfaithful execution, which hinders effective query formulation and consistent use of retrieved evidence. We propose GlobalRAG, a reinforcement learning framework designed to enhance global reasoning in multi-hop QA. GlobalRAG decomposes questions into subgoals, coordinates retrieval with reasoning, and refines evidence iteratively. To guide this process, we introduce Planning Quality Reward and SubGoal Completion Reward, which encourage coherent planning and reliable subgoal execution. In addition, a progressive weight annealing strategy balances process-oriented and outcome-based objectives. Extensive experiments on both in-domain and out-of-domain benchmarks demonstrate that GlobalRAG significantly outperforms strong baselines while using only 8k training data (42% of the training data used by strong baselines), achieving average improvements of 14.2% in both EM and F1.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GlobalRAGï¼Œä¸€ç§æ—¨åœ¨å¢å¼ºå¤šè·³é—®ç­” (Multi-hop QA) å…¨å±€æ¨ç†èƒ½åŠ›çš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚é—®é¢˜æ—¶ç¼ºä¹å…¨å±€è§„åˆ’å’Œæ‰§è¡Œä¸å¿ å®çš„é—®é¢˜ï¼ŒGlobalRAG é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºå­ç›®æ ‡ (subgoals)ï¼Œå¹¶è¿­ä»£åœ°åè°ƒæ£€ç´¢ä¸æ¨ç†è¿‡ç¨‹æ¥ä¼˜åŒ–è¯æ®ç»†åŒ–ã€‚ä¸ºäº†å¼•å¯¼è¿™ä¸€è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†è§„åˆ’è´¨é‡å¥–åŠ± (Planning Quality Reward) å’Œå­ç›®æ ‡å®Œæˆå¥–åŠ± (SubGoal Completion Reward)ï¼Œä»¥ç¡®ä¿è§„åˆ’çš„è¿è´¯æ€§å’Œå­ç›®æ ‡æ‰§è¡Œçš„å¯é æ€§ï¼Œå¹¶ç»“åˆæ¸è¿›å¼æƒé‡é€€ç« (progressive weight annealing) ç­–ç•¥å¹³è¡¡ä¸åŒé˜¶æ®µçš„ç›®æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGlobalRAG åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºå¼ºåŸºçº¿æ¨¡å‹ï¼Œåœ¨ EM å’Œ F1 æŒ‡æ ‡ä¸Šå¹³å‡æå‡äº† 14.2%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨ä»…ä½¿ç”¨ 8k è®­ç»ƒæ•°æ®ï¼ˆçº¦å åŸºçº¿æ•°æ®é‡çš„ 42%ï¼‰çš„æƒ…å†µä¸‹å³å¯å®ç°å“è¶Šæ€§èƒ½ï¼Œå……åˆ†è¯æ˜äº†å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.20548v3",
      "published_date": "2025-10-23 13:35:02 UTC",
      "updated_date": "2026-01-12 09:03:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:15:45.554912+00:00"
    },
    {
      "arxiv_id": "2510.21872v1",
      "title": "GuitarFlow: Realistic Electric Guitar Synthesis From Tablatures via Flow Matching and Style Transfer",
      "title_zh": "GuitarFlowï¼šåŸºäºæµåŒ¹é…ä¸é£æ ¼è¿ç§»çš„å‰ä»–è°±é€¼çœŸç”µå‰ä»–åˆæˆ",
      "authors": [
        "Jackson Loth",
        "Pedro Sarmento",
        "Mark Sandler",
        "Mathieu Barthet"
      ],
      "abstract": "Music generation in the audio domain using artificial intelligence (AI) has witnessed steady progress in recent years. However for some instruments, particularly the guitar, controllable instrument synthesis remains limited in expressivity. We introduce GuitarFlow, a model designed specifically for electric guitar synthesis. The generative process is guided using tablatures, an ubiquitous and intuitive guitar-specific symbolic format. The tablature format easily represents guitar-specific playing techniques (e.g. bends, muted strings and legatos), which are more difficult to represent in other common music notation formats such as MIDI. Our model relies on an intermediary step of first rendering the tablature to audio using a simple sample-based virtual instrument, then performing style transfer using Flow Matching in order to transform the virtual instrument audio into more realistic sounding examples. This results in a model that is quick to train and to perform inference, requiring less than 6 hours of training data. We present the results of objective evaluation metrics, together with a listening test, in which we show significant improvement in the realism of the generated guitar audio from tablatures.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µå‰ä»–åˆæˆåœ¨è¡¨ç°åŠ›å’Œå¯æ§æ€§æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº† GuitarFlow æ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ tablaturesï¼ˆæŒ‡å¼¹è°±ï¼‰ä½œä¸ºç”Ÿæˆå¼•å¯¼ï¼Œèƒ½å¤Ÿæ¯”ä¼ ç»Ÿçš„ MIDI æ ¼å¼æ›´ç²¾å‡†åœ°è¡¨è¾¾æ¨å¼¦(bends)ã€é—·éŸ³(muted strings)å’Œè¿å¥(legatos)ç­‰å‰ä»–ç‰¹æœ‰æŠ€å·§ã€‚æŠ€æœ¯å®ç°ä¸Šï¼ŒGuitarFlow é¦–å…ˆå°† tablature é€šè¿‡ç®€å•çš„é‡‡æ ·è™šæ‹Ÿä¹å™¨æ¸²æŸ“ä¸ºåŸºç¡€éŸ³é¢‘ï¼Œå†åˆ©ç”¨ Flow Matching æŠ€æœ¯è¿›è¡Œ style transferï¼Œä»è€Œå®ç°é«˜åº¦çœŸå®çš„éŸ³è‰²è½¬æ¢ã€‚è¯¥æ¨¡å‹å…·å¤‡æé«˜çš„è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ï¼Œä»…éœ€å°‘äº6å°æ—¶çš„è®­ç»ƒæ•°æ®å³å¯å®Œæˆã€‚å®¢è§‚è¯„ä¼°ä¸å¬åŠ›æµ‹è¯•å‡è¯å®ï¼ŒGuitarFlow åœ¨æå‡ç”µå‰ä»–éŸ³é¢‘ç”Ÿæˆçš„çœŸå®æ„Ÿæ–¹é¢è¾ƒç°æœ‰æŠ€æœ¯æœ‰æ˜¾è‘—è¿›æ­¥ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "To be published in Proceedings of the 17th International Symposium on Computer Music and Multidisciplinary Research (CMMR)",
      "pdf_url": "https://arxiv.org/pdf/2510.21872v1",
      "published_date": "2025-10-23 13:31:41 UTC",
      "updated_date": "2025-10-23 13:31:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:00.944447+00:00"
    },
    {
      "arxiv_id": "2510.20543v2",
      "title": "The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts",
      "title_zh": "è¢«çŒ«è¿½çš„ç‹—éš¾å€’äº†æ¨¡å‹ï¼šè¡¡é‡è¯­è¨€æ¨¡å‹ä½•æ—¶å¼ƒç”¨ç»“æ„åˆ†æè€Œé‡‡ç”¨è¯­ä¹‰æ·å¾„",
      "authors": [
        "Sangmitra Madhusudan",
        "Kaige Chen",
        "Ali Emami"
      ],
      "abstract": "When language models correctly parse \"The cat that the dog chased meowed,\" are they analyzing syntax or simply familiar with dogs chasing cats? Despite extensive benchmarking, we lack methods to distinguish structural understanding from semantic pattern matching. We introduce CenterBench, a dataset of 9,720 comprehension questions on center-embedded sentences (like \"The cat [that the dog chased] meowed\") where relative clauses nest recursively, creating processing demands from simple to deeply nested structures. Each sentence has a syntactically identical but semantically implausible counterpart (e.g., mailmen prescribe medicine, doctors deliver mail) and six comprehension questions testing surface understanding, syntactic dependencies, and causal reasoning. Testing six models reveals that performance gaps between plausible and implausible sentences widen systematically with complexity, with models showing median gaps up to 26.8 percentage points, quantifying when they abandon structural analysis for semantic associations. Notably, semantic plausibility harms performance on questions about resulting actions, where following causal relationships matters more than semantic coherence. Reasoning models improve accuracy but their traces show semantic shortcuts, overthinking, and answer refusal. Unlike models whose plausibility advantage systematically widens with complexity, humans shows variable semantic effects. CenterBench provides the first framework to identify when models shift from structural analysis to pattern matching.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è¯­è¨€æ¨¡å‹åœ¨è§£æå¤æ‚å¥å¼æ—¶ç©¶ç«Ÿæ˜¯ä¾èµ–è¯­æ³•ç»“æ„åˆ†æè¿˜æ˜¯ç®€å•çš„è¯­ä¹‰æ¨¡å¼åŒ¹é…ï¼Œå¹¶ä¸ºæ­¤å¼•å…¥äº†åŒ…å« 9,720 ä¸ªç†è§£é—®é¢˜çš„ CenterBench æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†é€šè¿‡ä¸­å¿ƒåµŒå…¥(center-embedded)å¥å­æ„å»ºä»ç®€å•åˆ°æ·±åº¦åµŒå¥—çš„é€’å½’ç»“æ„ï¼Œå¹¶ä¸ºæ¯ä¸ªå¥å­åŒ¹é…äº†è¯­æ³•ç»“æ„ç›¸åŒä½†è¯­ä¹‰ä¸åˆç†(semantically implausible)çš„å¯¹ç…§ç‰ˆæœ¬ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œéšç€å¥æ³•å¤æ‚åº¦å¢åŠ ï¼Œæ¨¡å‹åœ¨åˆç†å¥ä¸ä¸åˆç†å¥ä¹‹é—´çš„è¡¨ç°å·®è·ç³»ç»Ÿæ€§æ‰©å¤§ï¼Œä¸­ä½å·®è·é«˜è¾¾ 26.8%ï¼Œé‡åŒ–äº†æ¨¡å‹ä½•æ—¶æ”¾å¼ƒç»“æ„åˆ†æè½¬è€Œå¯»æ±‚è¯­ä¹‰å…³è”(semantic associations)ã€‚ç ”ç©¶å‘ç°ï¼Œè¯­ä¹‰åˆç†æ€§åœ¨å› æœæ¨ç†ä»»åŠ¡ä¸­åè€Œä¼šæŸå®³æ¨¡å‹è¡¨ç°ï¼Œä½¿å…¶æ›´å®¹æ˜“å—åˆ°è¯­ä¹‰è¿è´¯æ€§çš„è¯¯å¯¼ã€‚å°½ç®¡æ¨ç†æ¨¡å‹(reasoning models)æé«˜äº†å‡†ç¡®ç‡ï¼Œä½†å…¶æ€ç»´é“¾ä»æš´éœ²å‡ºè¯­ä¹‰æ·å¾„å’Œè¿‡åº¦æ€è€ƒç­‰é—®é¢˜ã€‚CenterBench ä¸ºè¯†åˆ«è¯­è¨€æ¨¡å‹ä»ç»“æ„åˆ†æè½¬å‘æ¨¡å¼åŒ¹é…(pattern matching)çš„ä¸´ç•Œç‚¹æä¾›äº†é¦–ä¸ªè¯„ä¼°æ¡†æ¶ï¼Œæ­ç¤ºäº†æ¨¡å‹ä¸äººç±»åœ¨å¤„ç†å¤æ‚è¯­è¨€ç»“æ„æ—¶çš„æœ¬è´¨å·®å¼‚ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages (excluding references), accepted to EACL 2026 Main Conference",
      "pdf_url": "https://arxiv.org/pdf/2510.20543v2",
      "published_date": "2025-10-23 13:30:40 UTC",
      "updated_date": "2026-01-20 17:46:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:03.765338+00:00"
    },
    {
      "arxiv_id": "2510.20535v1",
      "title": "ARC-Encoder: learning compressed text representations for large language models",
      "title_zh": "ARC-Encoderï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„å‹ç¼©æ–‡æœ¬è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Hippolyte Pilchen",
        "Edouard Grave",
        "Patrick PÃ©rez"
      ],
      "abstract": "Recent techniques such as retrieval-augmented generation or chain-of-thought reasoning have led to longer contexts and increased inference costs. Context compression techniques can reduce these costs, but the most effective approaches require fine-tuning the target model or even modifying its architecture. This can degrade its general abilities when not used for this specific purpose. Here we explore an alternative approach: an encoder that compresses the context into continuous representations which replace token embeddings in decoder LLMs. First, we perform a systematic study of training strategies and architecture choices for the encoder. Our findings led to the design of an Adaptable text Representations Compressor, named ARC-Encoder, which outputs $x$-times fewer continuous representations (typically $x\\!\\in\\!\\{4,8\\}$) than text tokens. We evaluate ARC-Encoder across a variety of LLM usage scenarios, ranging from in-context learning to context window extension, on both instruct and base decoders. Results show that ARC-Encoder achieves state-of-the-art performance on several benchmarks while improving computational efficiency at inference. Finally, we demonstrate that our models can be adapted to multiple decoders simultaneously, allowing a single encoder to generalize across different decoder LLMs. This makes ARC-Encoder a flexible and efficient solution for portable encoders that work seamlessly with multiple LLMs. We release a training code at https://github.com/kyutai-labs/ARC-Encoder , fine-tuning dataset and pretrained models are available at https://huggingface.co/collections/kyutai/arc-encoders-68ee18787301407d60a57047 .",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æˆ–é“¾å¼æ€ç»´(CoT)å¯¼è‡´çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†æˆæœ¬å¢åŠ é—®é¢˜ï¼Œæå‡ºäº† ARC-Encoder (Adaptable text Representations Compressor)ã€‚ä¸åŒäºä»¥å¾€éœ€è¦ä¿®æ”¹è§£ç å™¨æ¶æ„çš„æ–¹æ³•ï¼ŒARC-Encoder å°†ä¸Šä¸‹æ–‡å‹ç¼©ä¸ºè¿ç»­è¡¨ç¤º(continuous representations)ä»¥æ›¿ä»£ token embeddingsï¼Œé€šå¸¸èƒ½å®ç° 4 åˆ° 8 å€çš„å‹ç¼©é‡ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¯¹è®­ç»ƒç­–ç•¥å’Œæ¶æ„é€‰æ‹©çš„ç³»ç»Ÿç ”ç©¶ï¼Œç¡®ä¿äº†è¯¥ç¼–ç å™¨åœ¨ä¸æŸå®³å¤§å‹è¯­è¨€æ¨¡å‹é€šç”¨èƒ½åŠ›çš„å‰æä¸‹æ˜¾è‘—æé«˜æ¨ç†æ•ˆç‡ã€‚åœ¨ in-context learning å’Œ context window extension ç­‰å¤šç§åœºæ™¯ä¸‹çš„è¯„ä¼°æ˜¾ç¤ºï¼ŒARC-Encoder åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº† state-of-the-art æ€§èƒ½ã€‚å®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œè¯¥æ¨¡å‹èƒ½å¤ŸåŒæ—¶é€‚é…å¤šä¸ªè§£ç å™¨ï¼Œä½¿å•ä¸ªç¼–ç å™¨åœ¨ä¸åŒ decoder LLMs ä¹‹é—´å…·å¤‡è‰¯å¥½çš„æ³›åŒ–æ€§ã€‚è¿™ä¸€æˆæœä¸ºå¼€å‘å¯è·¨æ¨¡å‹ä½¿ç”¨çš„ä¾¿æºå¼é«˜æ•ˆç¼–ç å™¨æä¾›äº†çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20535v1",
      "published_date": "2025-10-23 13:20:57 UTC",
      "updated_date": "2025-10-23 13:20:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:05.751060+00:00"
    },
    {
      "arxiv_id": "2510.20531v1",
      "title": "Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis",
      "title_zh": "Fake-in-Facextï¼šé¢å‘ç»†ç²’åº¦å¯è§£é‡Šæ·±åº¦ä¼ªé€ åˆ†æ",
      "authors": [
        "Lixiong Qin",
        "Yang Zhang",
        "Mei Wang",
        "Jiani Hu",
        "Weihong Deng",
        "Weiran Xu"
      ],
      "abstract": "The advancement of Multimodal Large Language Models (MLLMs) has bridged the gap between vision and language tasks, enabling the implementation of Explainable DeepFake Analysis (XDFA). However, current methods suffer from a lack of fine-grained awareness: the description of artifacts in data annotation is unreliable and coarse-grained, and the models fail to support the output of connections between textual forgery explanations and the visual evidence of artifacts, as well as the input of queries for arbitrary facial regions. As a result, their responses are not sufficiently grounded in Face Visual Context (Facext). To address this limitation, we propose the Fake-in-Facext (FiFa) framework, with contributions focusing on data annotation and model construction. We first define a Facial Image Concept Tree (FICT) to divide facial images into fine-grained regional concepts, thereby obtaining a more reliable data annotation pipeline, FiFa-Annotator, for forgery explanation. Based on this dedicated data annotation, we introduce a novel Artifact-Grounding Explanation (AGE) task, which generates textual forgery explanations interleaved with segmentation masks of manipulated artifacts. We propose a unified multi-task learning architecture, FiFa-MLLM, to simultaneously support abundant multimodal inputs and outputs for fine-grained Explainable DeepFake Analysis. With multiple auxiliary supervision tasks, FiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA performance on existing XDFA datasets. The code and data will be made open-source at https://github.com/lxq1000/Fake-in-Facext.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Fake-in-Facext (FiFa) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ Multimodal Large Language Models (MLLMs) åœ¨ Explainable DeepFake Analysis (XDFA) ä¸­é¢ä¸´çš„ç»†ç²’åº¦æ„ŸçŸ¥ä¸è¶³ã€ä¼ªé€ æè¿°ç²—ç³™ä»¥åŠæ–‡æœ¬è§£é‡Šä¸è§†è§‰è¯æ®ç¼ºä¹å…³è”ç­‰é—®é¢˜ã€‚ç ”ç©¶é¦–å…ˆå®šä¹‰äº† Facial Image Concept Tree (FICT) ä»¥å°†äººè„¸å›¾åƒåˆ’åˆ†ä¸ºç»†ç²’åº¦çš„åŒºåŸŸæ¦‚å¿µï¼Œå¹¶æ„å»ºäº†å¯é çš„æ•°æ®æ ‡æ³¨æµç¨‹ FiFa-Annotatorã€‚åŸºäºæ­¤ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€é¡¹å…¨æ–°çš„ Artifact-Grounding Explanation (AGE) ä»»åŠ¡ï¼Œæ—¨åœ¨ç”Ÿæˆä¸ç¯¡æ”¹ä¼ªè¿¹åˆ†å‰²æ©ç ï¼ˆsegmentation masksï¼‰äº¤ç»‡çš„æ–‡æœ¬è§£é‡Šã€‚æ­¤å¤–ï¼Œç ”ç©¶è®¾è®¡äº†ç»Ÿä¸€çš„å¤šä»»åŠ¡å­¦ä¹ æ¶æ„ FiFa-MLLMï¼Œä»¥åŒæ—¶æ”¯æŒç»†ç²’åº¦åˆ†æä¸­çš„å¤šç§å¤šæ¨¡æ€è¾“å…¥ä¸è¾“å‡ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFiFa-MLLM åœ¨ AGE ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨ç°æœ‰çš„ XDFA æ•°æ®é›†ä¸Šå–å¾—äº† SOTA æ€§èƒ½ã€‚è¯¥ç ”ç©¶é€šè¿‡æå‡æ¨¡å‹å¯¹ Face Visual Context (Facext) çš„ç†è§£ï¼Œä¸ºå®ç°æ›´å…·å¯ä¿¡åº¦çš„ä¼ªé€ æ£€æµ‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 9 figures, 17 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.20531v1",
      "published_date": "2025-10-23 13:16:12 UTC",
      "updated_date": "2025-10-23 13:16:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:09.558731+00:00"
    },
    {
      "arxiv_id": "2510.20519v2",
      "title": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning",
      "title_zh": "Metis-HOMEï¼šé¢å‘å¤šæ¨¡æ€æ¨ç†çš„æ··åˆä¼˜åŒ–ä¸“å®¶æ··åˆæ¶æ„",
      "authors": [
        "Xiaohan Lan",
        "Fanfan Liu",
        "Haibo Qiu",
        "Siqi Yang",
        "Delian Ruan",
        "Peng Shi",
        "Lin Ma"
      ],
      "abstract": "Inspired by recent advancements in LLM reasoning, the field of multimodal reasoning has seen remarkable progress, achieving significant performance gains on intricate tasks such as mathematical problem-solving. Despite this progress, current multimodal large reasoning models exhibit two key limitations. They tend to employ computationally expensive reasoning even for simple queries, leading to inefficiency. Furthermore, this focus on specialized reasoning often impairs their broader, more general understanding capabilities. In this paper, we propose Metis-HOME: a Hybrid Optimized Mixture-of-Experts framework designed to address this trade-off. Metis-HOME enables a ''Hybrid Thinking'' paradigm by structuring the original dense model into two distinct expert branches: a thinking branch tailored for complex, multi-step reasoning, and a non-thinking branch optimized for rapid, direct inference on tasks like general VQA and OCR. A lightweight, trainable router dynamically allocates queries to the most suitable expert. We instantiate Metis-HOME by adapting the Qwen2.5-VL-7B into an MoE architecture. Comprehensive evaluations reveal that our approach not only substantially enhances complex reasoning abilities but also improves the model's general capabilities, reversing the degradation trend observed in other reasoning-specialized models. Our work establishes a new paradigm for building powerful and versatile MLLMs, effectively resolving the prevalent reasoning-vs-generalization dilemma. Code and weights are available at https://github.com/MM-Thinking/Metis-HOME.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Metis-HOMEï¼Œä¸€ç§æ··åˆä¼˜åŒ–ä¸“å®¶æ··åˆæ¨¡å‹ (Hybrid Optimized Mixture-of-Experts) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨å¤„ç†ç®€å•æŸ¥è¯¢æ—¶è®¡ç®—æ•ˆç‡ä½ä¸‹ä»¥åŠå¼ºåŒ–æ¨ç†åé€šç”¨èƒ½åŠ›é€€åŒ–çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡â€œæ··åˆæ€ç»´â€(Hybrid Thinking) èŒƒå¼ï¼Œå°†æ¨¡å‹ç»“æ„åˆ’åˆ†ä¸ºè´Ÿè´£å¤æ‚å¤šæ­¥æ¨ç†çš„â€œæ€è€ƒåˆ†æ”¯â€å’Œé’ˆå¯¹ VQAã€OCR ç­‰ä»»åŠ¡å¿«é€Ÿæ¨ç†çš„â€œéæ€è€ƒåˆ†æ”¯â€ã€‚åˆ©ç”¨è½»é‡çº§å¯è®­ç»ƒè·¯ç”± (Router) å®ç°æŸ¥è¯¢çš„åŠ¨æ€åˆ†é…ï¼Œå¹¶ä»¥ Qwen2.5-VL-7B ä¸ºåŸºç¡€æ„å»ºäº† MoE æ¶æ„ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒMetis-HOME ä¸ä»…æ˜¾è‘—å¢å¼ºäº†å¤æ‚æ¨ç†è¡¨ç°ï¼Œè¿˜æå‡äº†æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ï¼Œæœ‰æ•ˆè§£å†³äº†æ¨ç†ä¸æ³›åŒ–ä¹‹é—´çš„æƒè¡¡å›°å¢ƒã€‚è¿™é¡¹å·¥ä½œä¸ºå¼€å‘åŠŸèƒ½å¼ºå¤§ä¸”å…¨é¢çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) ç¡®ç«‹äº†æ–°çš„æŠ€æœ¯èŒƒå¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20519v2",
      "published_date": "2025-10-23 13:02:49 UTC",
      "updated_date": "2025-11-25 07:57:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:12.516448+00:00"
    },
    {
      "arxiv_id": "2510.20505v1",
      "title": "Hierarchical Sequence Iteration for Heterogeneous Question Answering",
      "title_zh": "é¢å‘å¼‚æ„é—®ç­”çš„å±‚çº§åºåˆ—è¿­ä»£",
      "authors": [
        "Ruiyi Yang",
        "Hao Xue",
        "Imran Razzak",
        "Hakim Hacid",
        "Flora D. Salim"
      ],
      "abstract": "Retrieval-augmented generation (RAG) remains brittle on multi-step questions and heterogeneous evidence sources, trading accuracy against latency and token/tool budgets. This paper introducesHierarchical Sequence (HSEQ) Iteration for Heterogeneous Question Answering, a unified framework that (i) linearize documents, tables, and knowledge graphs into a reversible hierarchical sequence with lightweight structural tags, and (ii) perform structure-aware iteration to collect just-enough evidence before answer synthesis. A Head Agent provides guidance that leads retrieval, while an Iteration Agent selects and expands HSeq via structure-respecting actions (e.g., parent/child hops, table row/column neighbors, KG relations); Finally the head agent composes canonicalized evidence to genearte the final answer, with an optional refinement loop to resolve detected contradictions. Experiments on HotpotQA (text), HybridQA/TAT-QA (table+text), and MetaQA (KG) show consistent EM/F1 gains over strong single-pass, multi-hop, and agentic RAG baselines with high efficiency. Besides, HSEQ exhibits three key advantages: (1) a format-agnostic unification that enables a single policy to operate across text, tables, and KGs without per-dataset specialization; (2) guided, budget-aware iteration that reduces unnecessary hops, tool calls, and tokens while preserving accuracy; and (3) evidence canonicalization for reliable QA, improving answers consistency and auditability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Hierarchical Sequence (HSEQ) Iteration ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) åœ¨å¤„ç†å¼‚æ„æ•°æ®æºå’Œå¤šæ­¥å¤æ‚é—®é¢˜æ—¶ç²¾åº¦ä¸æˆæœ¬éš¾ä»¥å¹³è¡¡çš„ç—›ç‚¹ã€‚è¯¥æ–¹æ³•é€šè¿‡è½»é‡çº§ç»“æ„æ ‡ç­¾å°†æ–‡æ¡£ã€è¡¨æ ¼å’ŒçŸ¥è¯†å›¾è°±çº¿æ€§åŒ–ä¸ºå¯é€†çš„å±‚æ¬¡åºåˆ—ï¼Œå®ç°äº†è·¨æ¨¡æ€æ•°æ®çš„ç»Ÿä¸€è¡¨ç¤ºã€‚æ¡†æ¶é‡‡ç”¨åŒæ™ºèƒ½ä½“åä½œæ¨¡å¼ï¼Œç”± Head Agent æä¾›æ£€ç´¢å¼•å¯¼ï¼Œå¹¶ç”± Iteration Agent æ‰§è¡Œç»“æ„æ„ŸçŸ¥çš„è¿­ä»£åŠ¨ä½œä»¥ç²¾å‡†æ”¶é›†è¯æ®ã€‚æœ€ç»ˆï¼ŒHead Agent é€šè¿‡è§„èŒƒåŒ–è¯æ®ç”Ÿæˆç­”æ¡ˆï¼Œå¹¶åˆ©ç”¨å¯é€‰çš„ç»†åŒ–å¾ªç¯æ¶ˆé™¤æ½œåœ¨çŸ›ç›¾ã€‚å®éªŒåœ¨ HotpotQAã€HybridQA å’Œ MetaQA ç­‰æ•°æ®é›†ä¸Šè¯æ˜ï¼ŒHSEQ åœ¨æå‡ EM/F1 æŒ‡æ ‡çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†å·¥å…·è°ƒç”¨ä¸ Token æ¶ˆè€—ã€‚è¯¥æ¡†æ¶å±•ç°äº†æ ¼å¼æ— å…³çš„é€šç”¨æ€§ã€é¢„ç®—æ„ŸçŸ¥çš„è¿­ä»£æ•ˆç‡ä»¥åŠæ›´å¼ºçš„è¯æ®ä¸€è‡´æ€§ï¼Œä¸ºé«˜æ•ˆå¯é çš„å¼‚æ„é—®ç­”ç³»ç»Ÿæä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20505v1",
      "published_date": "2025-10-23 12:48:18 UTC",
      "updated_date": "2025-10-23 12:48:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:12.957504+00:00"
    },
    {
      "arxiv_id": "2510.21501v1",
      "title": "GranViT: A Fine-Grained Vision Model With Autoregressive Perception For MLLMs",
      "title_zh": "GranViTï¼šé¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è‡ªå›å½’æ„ŸçŸ¥ç»†ç²’åº¦è§†è§‰æ¨¡å‹",
      "authors": [
        "Guanghao Zheng",
        "Bowen Shi",
        "Mingxing Xu",
        "Ruoyu Sun",
        "Peisen Zhao",
        "Zhibo Zhang",
        "Wenrui Dai",
        "Junni Zou",
        "Hongkai Xiong",
        "Xiaopeng Zhang",
        "Qi Tian"
      ],
      "abstract": "Vision encoders are indispensable for allowing impressive performance of Multi-modal Large Language Models (MLLMs) in vision language tasks such as visual question answering and reasoning. However, existing vision encoders focus on global image representations but overlook fine-grained regional analysis. They are limited in fine grained perception due to the scarcity of fine grained annotated data and the lack of a fine grained pre-training paradigm. In this paper, we propose GranViT, a novel Vision Transformer that integrates fine-grained feature extraction with semantic alignment to Large Language Models (LLMs) via region level autoregressive training. We first construct Gran-29M, a dataset comprising 2million natural and OCR images paired with over 180 million high-quality region-level annotations, to enable large scale fine grained pretraining. Consequently, we develop a pretraining-adaptation framework along with a self distillation mechanism to train fine-grained GranViT on Gran-29M. We sufficiently exploit the fine-grained annotations from Gran-29M to resort to bounding-box-to-caption regression to enhance localized visual representation of the vision encoder in the pretraining and caption-to-bounding-box regression to improve vision feature utilization and localization for LLM in the adaptation. We further incorporate a self distillation mechanism that imposes explicit localization constraints on the vision encoder to strengthen its regional reasoning capability. Extensive experiments show that GranViT surpasses existing vision encoders and attains strong transferability to varying LLMs. Remarkably, it achieves state-of-the-art results on fine-grained recognition, multimodal VQA, and OCR understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç»†ç²’åº¦åŒºåŸŸåˆ†ææ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº† GranViT è§†è§‰ç¼–ç å™¨ï¼Œé€šè¿‡åŒºåŸŸçº§è‡ªå›å½’ï¼ˆAutoregressiveï¼‰è®­ç»ƒå®ç°ç»†ç²’åº¦ç‰¹å¾æå–ä¸è¯­ä¹‰å¯¹é½ã€‚ä¸ºäº†æ”¯æŒå¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œç ”ç©¶è€…æ„å»ºäº†åŒ…å« 200 ä¸‡å¼ è‡ªç„¶ä¸ OCR å›¾åƒåŠ 1.8 äº¿æ¡é«˜è´¨é‡åŒºåŸŸçº§æ ‡æ³¨çš„æ•°æ®é›† Gran-29Mã€‚è¯¥æ¡†æ¶åœ¨é¢„è®­ç»ƒå’Œé€‚é…é˜¶æ®µåˆ†åˆ«é‡‡ç”¨è¾¹ç•Œæ¡†åˆ°æè¿°ï¼ˆbounding-box-to-captionï¼‰å’Œæè¿°åˆ°è¾¹ç•Œæ¡†çš„å›å½’ä»»åŠ¡ï¼Œå¹¶ç»“åˆè‡ªè’¸é¦ï¼ˆself distillationï¼‰æœºåˆ¶å¼•å…¥æ˜¾å¼å®šä½çº¦æŸï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„åŒºåŸŸæ¨ç†èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒGranViT åœ¨ç»†ç²’åº¦è¯†åˆ«ã€è§†è§‰é—®ç­”ï¼ˆVQAï¼‰å’Œ OCR ç†è§£ç­‰å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†å½“å‰æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„ç»“æœã€‚æ­¤å¤–ï¼ŒGranViT è¡¨ç°å‡ºæå¼ºçš„è¿ç§»æ€§ï¼Œèƒ½å¤Ÿå¹¿æ³›é€‚é…ä¸åŒçš„ LLMsï¼Œä¸ºæå‡å¤šæ¨¡æ€æ¨¡å‹çš„æ„ŸçŸ¥ç²¾åº¦æä¾›äº†é«˜æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.21501v1",
      "published_date": "2025-10-23 12:33:59 UTC",
      "updated_date": "2025-10-23 12:33:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:18.564086+00:00"
    },
    {
      "arxiv_id": "2510.20487v4",
      "title": "Steering Evaluation-Aware Language Models to Act Like They Are Deployed",
      "title_zh": "å¼•å¯¼å…·æœ‰è¯„ä¼°æ„è¯†çš„è¯­è¨€æ¨¡å‹è¡¨ç°å‡ºéƒ¨ç½²æ€è¡Œä¸º",
      "authors": [
        "Tim Tian Hua",
        "Andrew Qin",
        "Samuel Marks",
        "Neel Nanda"
      ],
      "abstract": "Large language models (LLMs) can sometimes detect when they are being evaluated and adjust their behavior to appear more aligned, compromising the reliability of safety evaluations. In this paper, we show that adding a steering vector to an LLM's activations can suppress evaluation-awareness and make the model act like it is deployed during evaluation. To study our steering technique, we train an LLM to exhibit evaluation-aware behavior using a two-step training process designed to mimic how this behavior could emerge naturally. First, we perform continued pretraining on documents with factual descriptions of the model (1) using Python type hints during evaluation but not during deployment and (2) recognizing that the presence of a certain evaluation cue always means that it is being tested. Then, we train the model with expert iteration to use Python type hints in evaluation settings. The resulting model is evaluation-aware: it writes type hints in evaluation contexts more than deployment contexts. We find that activation steering can suppress evaluation awareness and make the model act like it is deployed even when the cue is present. Importantly, we constructed our steering vector using the original model before our additional training. Our results suggest that AI evaluators could improve the reliability of safety evaluations by steering models to act like they are deployed.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ£€æµ‹åˆ°è¯„ä¼°ç¯å¢ƒæ—¶ä¼šè°ƒæ•´è¡Œä¸ºä»¥è¡¨ç°å¾—æ›´ç¬¦åˆå¯¹é½è¦æ±‚ï¼Œä»è€ŒæŸå®³å®‰å…¨è¯„ä¼°å¯é æ€§çš„é—®é¢˜è¿›è¡Œäº†æ¢è®¨ã€‚ä½œè€…æå‡ºåˆ©ç”¨æ¿€æ´»è½¬å‘ï¼ˆactivation steeringï¼‰æŠ€æœ¯ï¼Œé€šè¿‡åœ¨æ¨¡å‹æ¿€æ´»ä¸­åŠ å…¥è½¬å‘å‘é‡ï¼ˆsteering vectorï¼‰ï¼Œæ¥æŠ‘åˆ¶æ¨¡å‹çš„è¯„ä¼°æ„è¯†ï¼ˆevaluation-awarenessï¼‰å¹¶ä½¿å…¶åœ¨è¯„ä¼°æœŸé—´è¡¨ç°å¾—å¦‚åŒåœ¨å®é™…éƒ¨ç½²ï¼ˆdeployedï¼‰ä¸­ä¸€æ ·ã€‚ä¸ºäº†éªŒè¯è¯¥æ–¹æ³•ï¼Œç ”ç©¶è€…é¦–å…ˆé€šè¿‡æŒç»­é¢„è®­ç»ƒå’Œä¸“å®¶è¿­ä»£ï¼ˆexpert iterationï¼‰è®­ç»ƒå‡ºäº†ä¸€ä¸ªå…·å¤‡è¯„ä¼°æ„è¯†çš„æ¨¡å‹ï¼Œä½¿å…¶èƒ½æ ¹æ®ç¯å¢ƒçº¿ç´¢åˆ‡æ¢è¡Œä¸ºæ¨¡å¼ã€‚å®éªŒå‘ç°ï¼Œæ¿€æ´»è½¬å‘æŠ€æœ¯å³ä½¿åœ¨è¯„ä¼°çº¿ç´¢å­˜åœ¨çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½æˆåŠŸè®©æ¨¡å‹è¡¨ç°å‡ºéƒ¨ç½²æ—¶çš„è¡Œä¸ºç‰¹å¾ã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡è½¬å‘å‘é‡å¼•å¯¼æ¨¡å‹è¿›å…¥éƒ¨ç½²çŠ¶æ€ï¼ŒAIè¯„ä¼°è€…å¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹å®‰å…¨è¯„ä¼°çš„å‡†ç¡®æ€§ä¸å¯é æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20487v4",
      "published_date": "2025-10-23 12:29:16 UTC",
      "updated_date": "2026-01-05 00:55:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:19.559524+00:00"
    },
    {
      "arxiv_id": "2510.20878v1",
      "title": "HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement",
      "title_zh": "HA-RAGï¼šåŸºäºæ··åˆç²¾åº¦ä¸æ•°æ®æ”¾ç½®çš„çƒ­åº¦æ„ŸçŸ¥ RAG åŠ é€Ÿ",
      "authors": [
        "Danying Ge",
        "Jianhua Gao",
        "Yixue Yang",
        "Weixing Ji"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) improves model output accuracy by leveraging external knowledge bases, serving as an effective solution to address hallucination issues and knowledge-update delays in Large Language Models (LLMs). However, the introduction of external knowledge bases presents RAG with challenges in long-context processing, significantly increasing memory consumption and inference latency. Existing research accelerates inference by precomputing Key and Value (KV) of the knowledge base and loading them on-demand during inference. Based on the access frequency of different KV chunks within the external knowledge base, this paper proposes a hotness-aware RAG (HA-RAG) inference optimization system. First, leveraging the numerical distribution of KV chunks, we introduce a hotness-aware mixed-precision compressing and loading method to reduce disk I/O and memory access overhead. Second, we design a hotness-aware data placement strategy that prioritizes storing frequently accessed KV chunks in high-speed memory to improve data access efficiency. Experimental results demonstrate that, compared with TurboRAG, the proposed HA-RAG achieves an average speedup of 2.10x and maximum speedup of 10.49x in Time-To-First-Token (TTFT) with negligible accuracy loss.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† HA-RAGï¼Œä¸€ç§é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) çš„çƒ­åº¦æ„ŸçŸ¥æ¨ç†ä¼˜åŒ–ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³é•¿ä¸Šä¸‹æ–‡å¤„ç†å¸¦æ¥çš„é«˜å†…å­˜æ¶ˆè€—å’Œæ¨ç†å»¶è¿Ÿé—®é¢˜ã€‚ç³»ç»Ÿæ ¸å¿ƒåŒ…å«ä¸¤ç§å…³é”®ç­–ç•¥ï¼šä¸€æ˜¯åŸºäº Key å’Œ Value (KV) å—æ•°å€¼åˆ†å¸ƒçš„çƒ­åº¦æ„ŸçŸ¥æ··åˆç²¾åº¦ (Mixed-Precision) å‹ç¼©ä¸åŠ è½½æ–¹æ³•ï¼Œç”¨ä»¥å‡å°‘ç£ç›˜ I/O å’Œå†…å­˜è®¿é—®å¼€é”€ï¼›äºŒæ˜¯è®¾è®¡äº†çƒ­åº¦æ„ŸçŸ¥çš„æ•°æ®æ”¾ç½®ç­–ç•¥ï¼Œé€šè¿‡å°†é¢‘ç¹è®¿é—®çš„ KV å—ä¼˜å…ˆå­˜æ”¾åœ¨é«˜é€Ÿå†…å­˜ä¸­æ¥æå‡æ•°æ®è®¿é—®æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHA-RAG åœ¨é¦–å­—å»¶è¿Ÿ (Time-To-First-Token, TTFT) æ–¹é¢è¾ƒ TurboRAG å®ç°äº†å¹³å‡ 2.10 å€ã€æœ€é«˜ 10.49 å€çš„åŠ é€Ÿï¼Œä¸”å‡†ç¡®ç‡æŸå¤±æå°ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ– Large Language Models (LLMs) åœ¨å¤–éƒ¨çŸ¥è¯†åº“åœºæ™¯ä¸‹çš„æ¨ç†æ€§èƒ½æä¾›äº†é«˜æ•ˆä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages,16 figures,2 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.20878v1",
      "published_date": "2025-10-23 12:28:58 UTC",
      "updated_date": "2025-10-23 12:28:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:20.759612+00:00"
    },
    {
      "arxiv_id": "2510.20486v1",
      "title": "Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval",
      "title_zh": "Hurdle-IMDLï¼šä¸€ç§é¢å‘çº¢å¤–é™æ°´åæ¼”çš„ä¸å¹³è¡¡å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Fangjian Zhang",
        "Xiaoyong Zhuge",
        "Wenlan Wang",
        "Haixia Xiao",
        "Yuying Zhu",
        "Siyang Cheng"
      ],
      "abstract": "Artificial intelligence has advanced quantitative remote sensing, yet its effectiveness is constrained by imbalanced label distribution. This imbalance leads conventionally trained models to favor common samples, which in turn degrades retrieval performance for rare ones. Rainfall retrieval exemplifies this issue, with performance particularly compromised for heavy rain. This study proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework. Following a divide-and-conquer strategy, imbalance in the rain distribution is decomposed into two components: zero inflation, defined by the predominance of non-rain samples; and long tail, defined by the disproportionate abundance of light-rain samples relative to heavy-rain samples. A hurdle model is adopted to handle the zero inflation, while IMDL is proposed to address the long tail by transforming the learning object into an unbiased ideal inverse model. Comprehensive evaluation via statistical metrics and case studies investigating rainy weather in eastern China confirms Hurdle-IMDL's superiority over conventional, cost-sensitive, generative, and multi-task learning methods. Its key advancements include effective mitigation of systematic underestimation and a marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a generalizable approach for addressing imbalance in distributions of environmental variables, enabling enhanced retrieval of rare yet high-impact events.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Hurdle-IMDLæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³çº¢å¤–é™æ°´åæ¼”ä¸­ç”±äºæ ‡ç­¾åˆ†å¸ƒä¸å‡è¡¡(Imbalanced label distribution)å¯¼è‡´çš„æ¨¡å‹å¯¹å¼ºé™æ°´åæ¼”æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åˆ†è€Œæ²»ä¹‹çš„ç­–ç•¥ï¼Œå°†é™æ°´åˆ†å¸ƒçš„ä¸å‡è¡¡æ€§åˆ†è§£ä¸ºéé™æ°´æ ·æœ¬å ä¸»å¯¼çš„é›¶è†¨èƒ€(Zero inflation)å’Œè½»é™æ°´å¤šäºå¼ºé™æ°´çš„é•¿å°¾(Long tail)ä¸¤ä¸ªéƒ¨åˆ†ã€‚ç ”ç©¶é€šè¿‡è·¨æ æ¨¡å‹(Hurdle model)å¤„ç†é›¶è†¨èƒ€ï¼Œå¹¶åˆ©ç”¨åæ¼”æ¨¡å‹å»åå­¦ä¹ (IMDL)å°†å­¦ä¹ ç›®æ ‡è½¬åŒ–ä¸ºæ— åçš„ç†æƒ³åæ¼”æ¨¡å‹ä»¥åº”å¯¹é•¿å°¾åˆ†å¸ƒã€‚å®éªŒè¯æ˜ï¼ŒHurdle-IMDLåœ¨å‡è½»ç³»ç»Ÿæ€§ä½ä¼°åŠæå‡å¤§é›¨åˆ°ç‰¹å¤§æš´é›¨åæ¼”ç²¾åº¦æ–¹é¢ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ä»£ä»·æ•æ„Ÿã€ç”Ÿæˆå¼å’Œå¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºå¤„ç†ç¯å¢ƒé¢†åŸŸä¸­ä¸å‡è¡¡åˆ†å¸ƒå˜é‡æä¾›äº†é€šç”¨åŒ–æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†å¯¹é«˜å½±å“ç¨€æœ‰äº‹ä»¶çš„åæ¼”èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.20486v1",
      "published_date": "2025-10-23 12:25:52 UTC",
      "updated_date": "2025-10-23 12:25:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:26.467907+00:00"
    },
    {
      "arxiv_id": "2510.20479v1",
      "title": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging",
      "title_zh": "RECALLï¼šåŸºäºå±‚çº§åŒ–æ¨¡å‹åˆå¹¶çš„è¡¨å¾å¯¹é½å¼ç¾éš¾æ€§é—å¿˜ç¼“è§£",
      "authors": [
        "Bowen Wang",
        "Haiyuan Wan",
        "Liwen Shi",
        "Chen Yang",
        "Peng He",
        "Yue Ma",
        "Haochen Han",
        "Wenhao Li",
        "Tiao Tan",
        "Yongjian Li",
        "Fangming Liu",
        "Yifan Gong",
        "Sheng Zhang"
      ],
      "abstract": "We unveil that internal representations in large language models (LLMs) serve as reliable proxies of learned knowledge, and propose RECALL, a novel representation-aware model merging framework for continual learning without access to historical data. RECALL computes inter-model similarity from layer-wise hidden representations over clustered typical samples, and performs adaptive, hierarchical parameter fusion to align knowledge across models. This design enables the preservation of domain-general features in shallow layers while allowing task-specific adaptation in deeper layers. Unlike prior methods that require task labels or incur performance trade-offs, RECALL achieves seamless multi-domain integration and strong resistance to catastrophic forgetting. Extensive experiments across five NLP tasks and multiple continual learning scenarios show that RECALL outperforms baselines in both knowledge retention and generalization, providing a scalable and data-free solution for evolving LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶å‘ç°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å†…éƒ¨è¡¨å¾æ˜¯çŸ¥è¯†çš„å¯é ä»£ç†ï¼Œå¹¶æ®æ­¤æå‡ºäº†RECALLï¼Œä¸€ç§ç”¨äºåœ¨æ— å†å²æ•°æ®æ¡ä»¶ä¸‹è¿›è¡ŒæŒç»­å­¦ä¹ (continual learning)çš„è¡¨å¾æ„ŸçŸ¥æ¨¡å‹åˆå¹¶æ¡†æ¶ã€‚RECALLé€šè¿‡å¯¹å…¸å‹æ ·æœ¬èšç±»çš„é€å±‚éšè—è¡¨å¾(layer-wise hidden representations)è¿›è¡Œç›¸ä¼¼æ€§è®¡ç®—ï¼Œåˆ©ç”¨è‡ªé€‚åº”çš„åˆ†å±‚å‚æ•°èåˆ(hierarchical parameter fusion)å¯¹é½ä¸åŒæ¨¡å‹é—´çš„çŸ¥è¯†ã€‚è¯¥è®¾è®¡èƒ½æœ‰æ•ˆä¿ç•™æµ…å±‚ç½‘ç»œä¸­çš„é€šç”¨é¢†åŸŸç‰¹å¾(domain-general features)ï¼ŒåŒæ—¶æ”¯æŒæ·±å±‚ç½‘ç»œè¿›è¡Œä»»åŠ¡ç‰¹å®šé€‚é…ã€‚ä¸éœ€è¦ä»»åŠ¡æ ‡ç­¾æˆ–é¢ä¸´æ€§èƒ½æŠ˜ä¸­çš„ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒRECALLå®ç°äº†æ— ç¼çš„å¤šé¢†åŸŸé›†æˆï¼Œå¹¶è¡¨ç°å‡ºæå¼ºçš„æŠ—ç¾éš¾æ€§é—å¿˜(catastrophic forgetting)èƒ½åŠ›ã€‚åœ¨äº”é¡¹NLPä»»åŠ¡åŠå¤šç§æŒç»­å­¦ä¹ åœºæ™¯ä¸‹çš„å®éªŒè¯æ˜ï¼ŒRECALLåœ¨çŸ¥è¯†ä¿ç•™ä¸æ³›åŒ–æ€§èƒ½ä¸Šå‡ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œä¸ºLLMsçš„æŒç»­æ¼”è¿›æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”æ— éœ€æ•°æ®çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20479v1",
      "published_date": "2025-10-23 12:17:37 UTC",
      "updated_date": "2025-10-23 12:17:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:39.754187+00:00"
    },
    {
      "arxiv_id": "2510.20469v1",
      "title": "Structures generated in a multiagent system performing information fusion in peer-to-peer resource-constrained networks",
      "title_zh": "èµ„æºå—é™å¯¹ç­‰ç½‘ç»œä¸­æ‰§è¡Œä¿¡æ¯èåˆçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç»“æ„ç”Ÿæˆ",
      "authors": [
        "Horacio Paggi",
        "Juan A. Lara",
        "Javier Soriano"
      ],
      "abstract": "There has recently been a major advance with respect to how information fusion is performed. Information fusion has gone from being conceived as a purely hierarchical procedure, as is the case of traditional military applications, to now being regarded collaboratively, as holonic fusion, which is better suited for civil applications and edge organizations. The above paradigm shift is being boosted as information fusion gains ground in different non-military areas, and human-computer and machine-machine communications, where holarchies, which are more flexible structures than ordinary, static hierarchies, become more widespread. This paper focuses on showing how holonic structures tend to be generated when there are constraints on resources (energy, available messages, time, etc.) for interactions based on a set of fully intercommunicating elements (peers) whose components fuse information as a means of optimizing the impact of vagueness and uncertainty present message exchanges. Holon formation is studied generically based on a multiagent system model, and an example of its possible operation is shown. Holonic structures have a series of advantages, such as adaptability, to sudden changes in the environment or its composition, are somewhat autonomous and are capable of cooperating in order to achieve a common goal. This can be useful when the shortage of resources prevents communications or when the system components start to fail.",
      "tldr_zh": "è¯¥è®ºæ–‡æ¢è®¨äº†åœ¨èµ„æºå—é™çš„ç‚¹å¯¹ç‚¹(peer-to-peer)ç½‘ç»œä¸­ï¼Œæ‰§è¡Œä¿¡æ¯èåˆ(information fusion)çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(multiagent system)å¦‚ä½•ç”Ÿæˆæ•´ä½“ç»“æ„(holonic structures)ã€‚è¿™ç§æ–¹æ³•æ ‡å¿—ç€ä¿¡æ¯èåˆä»ä¼ ç»Ÿçš„å±‚çº§åŒ–ç¨‹åºå‘åä½œå¼çš„æ•´ä½“åŒ–èåˆ(holonic fusion)èŒƒå¼è½¬å˜ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”æ°‘ç”¨é¢†åŸŸå’Œè¾¹ç¼˜ç»„ç»‡çš„éœ€æ±‚ã€‚ç ”ç©¶é‡ç‚¹å±•ç¤ºäº†åœ¨èƒ½æºã€å¸¦å®½å’Œæ—¶é—´ç­‰èµ„æºå—çº¦æŸçš„æƒ…å†µä¸‹ï¼Œå®Œå…¨äº’è”çš„å¯¹ç­‰ä½“(peers)å¦‚ä½•é€šè¿‡èåˆä¿¡æ¯æ¥ä¼˜åŒ–äº¤äº’ä¸­çš„æ¨¡ç³Šæ€§ä¸ä¸ç¡®å®šæ€§ã€‚é€šè¿‡æ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¨¡å‹ï¼Œè¯¥ç ”ç©¶éªŒè¯äº†æ•´ä½“ç»“æ„åœ¨ç¯å¢ƒçªå˜æˆ–ç³»ç»Ÿæ•…éšœæ—¶å…·å¤‡çš„å¼ºé€‚åº”æ€§ã€è‡ªä¸»æ€§å’Œåä½œèƒ½åŠ›ã€‚è¿™äº›å‘ç°ä¸ºåœ¨èµ„æºç¨€ç¼ºæˆ–é«˜åŠ¨æ€ç¯å¢ƒä¸‹æ„å»ºç¨³å¥ã€é«˜æ•ˆçš„åˆ†å¸ƒå¼ä¿¡æ¯å¤„ç†ç³»ç»Ÿæä¾›äº†é‡è¦çš„ç†è®ºä¾æ®ä¸åº”ç”¨æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20469v1",
      "published_date": "2025-10-23 12:07:32 UTC",
      "updated_date": "2025-10-23 12:07:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:44.649932+00:00"
    },
    {
      "arxiv_id": "2510.20468v1",
      "title": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models",
      "title_zh": "åŸºäºå›¾åƒåå¥½æ¨¡å‹çš„å¯è¿ç§»é»‘ç›’å•æ ·æœ¬æ°´å°ä¼ªé€ ",
      "authors": [
        "TomÃ¡Å¡ SouÄek",
        "Sylvestre-Alvise Rebuffi",
        "Pierre Fernandez",
        "Nikola JovanoviÄ‡",
        "Hady Elsahar",
        "Valeriu Lacatusu",
        "Tuan Tran",
        "Alexandre Mourachko"
      ],
      "abstract": "Recent years have seen a surge in interest in digital content watermarking techniques, driven by the proliferation of generative models and increased legal pressure. With an ever-growing percentage of AI-generated content available online, watermarking plays an increasingly important role in ensuring content authenticity and attribution at scale. There have been many works assessing the robustness of watermarking to removal attacks, yet, watermark forging, the scenario when a watermark is stolen from genuine content and applied to malicious content, remains underexplored. In this work, we investigate watermark forging in the context of widely used post-hoc image watermarking. Our contributions are as follows. First, we introduce a preference model to assess whether an image is watermarked. The model is trained using a ranking loss on purely procedurally generated images without any need for real watermarks. Second, we demonstrate the model's capability to remove and forge watermarks by optimizing the input image through backpropagation. This technique requires only a single watermarked image and works without knowledge of the watermarking model, making our attack much simpler and more practical than attacks introduced in related work. Third, we evaluate our proposed method on a variety of post-hoc image watermarking models, demonstrating that our approach can effectively forge watermarks, questioning the security of current watermarking approaches. Our code and further resources are publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å›¾åƒæ°´å°ä¼ªé€ (watermark forging)çš„å®‰å…¨é£é™©ï¼Œå³æ”»å‡»è€…ä»çœŸå®å†…å®¹ä¸­çªƒå–æ°´å°å¹¶å°†å…¶åº”ç”¨åˆ°æ¶æ„å›¾åƒä¸­ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåå¥½æ¨¡å‹(preference model)ï¼Œé€šè¿‡åœ¨ç¨‹åºç”Ÿæˆçš„å›¾åƒä¸Šä½¿ç”¨æ’åºæŸå¤±(ranking loss)è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€çœŸå®æ°´å°å³å¯è¯†åˆ«å›¾åƒçš„æ°´å°ç‰¹å¾ã€‚è¯¥æ–¹æ³•åˆ©ç”¨åå‘ä¼ æ’­(backpropagation)ä¼˜åŒ–è¾“å…¥å›¾åƒï¼Œä»…éœ€å•å¼ æ°´å°å›¾åƒå³å¯åœ¨ä¸çŸ¥é“æ°´å°æ¨¡å‹çš„æƒ…å†µä¸‹å®ç°é»‘ç›’(black-box)ä¼ªé€ ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨å¤šç§äº‹å(post-hoc)å›¾åƒæ°´å°æ¨¡å‹ä¸Šå…·æœ‰æ˜¾è‘—çš„å¯è¿ç§»æ€§(transferable)ï¼Œèƒ½æœ‰æ•ˆç”Ÿæˆè™šå‡å‡­è¯ã€‚è¿™é¡¹å·¥ä½œæ­ç¤ºäº†å½“å‰ä¸»æµæ°´å°æŠ€æœ¯çš„å®‰å…¨æ€§æ¼æ´ï¼Œå¯¹äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹çš„çœŸå®æ€§ä¿æŠ¤æå‡ºäº†ä¸¥å³»æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20468v1",
      "published_date": "2025-10-23 12:06:35 UTC",
      "updated_date": "2025-10-23 12:06:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:48.164865+00:00"
    },
    {
      "arxiv_id": "2510.20467v1",
      "title": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic",
      "title_zh": "FLORAï¼šåŸºäºæ¨¡ç³Šé€»è¾‘çš„æ— ç›‘ç£çŸ¥è¯†å›¾è°±å¯¹é½",
      "authors": [
        "Yiwen Peng",
        "Thomas Bonald",
        "Fabian M. Suchanek"
      ],
      "abstract": "Knowledge graph alignment is the task of matching equivalent entities (that is, instances and classes) and relations across two knowledge graphs. Most existing methods focus on pure entity-level alignment, computing the similarity of entities in some embedding space. They lack interpretable reasoning and need training data to work. In this paper, we propose FLORA, a simple yet effective method that (1) is unsupervised, i.e., does not require training data, (2) provides a holistic alignment for entities and relations iteratively, (3) is based on fuzzy logic and thus delivers interpretable results, (4) provably converges, (5) allows dangling entities, i.e., entities without a counterpart in the other KG, and (6) achieves state-of-the-art results on major benchmarks.",
      "tldr_zh": "çŸ¥è¯†å›¾è°±å¯¹é½(Knowledge graph alignment)æ—¨åœ¨åŒ¹é…ä¸åŒçŸ¥è¯†å›¾è°±é—´çš„ç­‰ä»·å®ä½“å’Œå…³ç³»ï¼Œä½†ç°æœ‰æ–¹æ³•å¤šä¾èµ–å¤§é‡è®­ç»ƒæ•°æ®ä¸”ç¼ºä¹å¯è§£é‡Šçš„æ¨ç†èƒ½åŠ›ã€‚è¯¥ç ”ç©¶æå‡ºäº† FLORAï¼Œä¸€ç§åŸºäºæ¨¡ç³Šé€»è¾‘(fuzzy logic)çš„ç®€å•ä¸”æœ‰æ•ˆçš„æ— ç›‘ç£(unsupervised)å¯¹é½æ–¹æ³•ã€‚è¯¥æ–¹æ³•å®ç°äº†å®ä½“å’Œå…³ç³»çš„æ•´ä½“è¿­ä»£å¯¹é½(holistic alignment)ï¼Œåœ¨æ— éœ€è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹æä¾›äº†å…·æœ‰é«˜åº¦å¯è§£é‡Šæ€§çš„ç»“æœã€‚æ­¤å¤–ï¼ŒFLORA åœ¨ç†è®ºä¸Šè¢«è¯æ˜å…·æœ‰æ”¶æ•›æ€§(converges)ï¼Œå¹¶èƒ½æœ‰æ•ˆå¤„ç†åœ¨å¦ä¸€å›¾ä¸­æ²¡æœ‰å¯¹åº”é¡¹çš„æ‚¬æŒ‚å®ä½“(dangling entities)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFLORA åœ¨ä¸»æµåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„(state-of-the-art)æ€§èƒ½ï¼Œä¸ºè‡ªåŠ¨åŒ–ã€é€æ˜åŒ–çš„çŸ¥è¯†æ•´åˆæä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20467v1",
      "published_date": "2025-10-23 12:05:31 UTC",
      "updated_date": "2025-10-23 12:05:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:48.362199+00:00"
    },
    {
      "arxiv_id": "2510.20457v1",
      "title": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$",
      "title_zh": "é¢å‘ $\\mathcal{SHOIQ}$ é²æ£’å®ä¾‹æ£€ç´¢çš„ç¥ç»æ¨ç†",
      "authors": [
        "Louis Mozart Kamdem Teyou",
        "Luke Friedrichs",
        "N'Dah Jean Kouagou",
        "Caglar Demir",
        "Yasir Mahmood",
        "Stefan Heindorf",
        "Axel-Cyrille Ngonga Ngomo"
      ],
      "abstract": "Concept learning exploits background knowledge in the form of description logic axioms to learn explainable classification models from knowledge bases. Despite recent breakthroughs in neuro-symbolic concept learning, most approaches still cannot be deployed on real-world knowledge bases. This is due to their use of description logic reasoners, which are not robust against inconsistencies nor erroneous data. We address this challenge by presenting a novel neural reasoner dubbed EBR. Our reasoner relies on embeddings to approximate the results of a symbolic reasoner. We show that EBR solely requires retrieving instances for atomic concepts and existential restrictions to retrieve or approximate the set of instances of any concept in the description logic $\\mathcal{SHOIQ}$. In our experiments, we compare EBR with state-of-the-art reasoners. Our results suggest that EBR is robust against missing and erroneous data in contrast to existing reasoners.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¥ç»ç¬¦å·æ¦‚å¿µå­¦ä¹ (neuro-symbolic concept learning)åœ¨å¤„ç†çœŸå®ä¸–ç•ŒçŸ¥è¯†åº“æ—¶é¢ä¸´çš„é²æ£’æ€§é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿç¬¦å·æ¨ç†æœº(symbolic reasoners)éš¾ä»¥åº”å¯¹æ•°æ®ä¸ä¸€è‡´æˆ–é”™è¯¯å¸¦æ¥çš„æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸ºEBRçš„æ–°å‹ç¥ç»æ¨ç†æœº(neural reasoner)ï¼Œè¯¥æ¨ç†æœºåˆ©ç”¨åµŒå…¥(embeddings)æŠ€æœ¯æ¥è¿‘ä¼¼æ¨¡æ‹Ÿç¬¦å·æ¨ç†çš„ç»“æœã€‚ç ”ç©¶è¡¨æ˜ï¼ŒEBRä»…éœ€æ£€ç´¢åŸå­æ¦‚å¿µ(atomic concepts)å’Œå­˜åœ¨é™åˆ¶(existential restrictions)çš„å®ä¾‹ï¼Œå³å¯å®ç°å¯¹æè¿°é€»è¾‘(description logic) $\\mathcal{SHOIQ}$ ä¸­ä»»æ„å¤æ‚æ¦‚å¿µå®ä¾‹é›†çš„æ£€ç´¢æˆ–è¿‘ä¼¼ã€‚å®éªŒå¯¹æ¯”ç»“æœè¯æ˜ï¼Œä¸å½“å‰æœ€å…ˆè¿›çš„æ¨ç†æœºç›¸æ¯”ï¼ŒEBRåœ¨é¢å¯¹ç¼ºå¤±æˆ–é”™è¯¯æ•°æ®æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„é²æ£’æ€§(robustness)ã€‚è¿™ä¸€æ–¹æ³•ä¸ºåœ¨å­˜åœ¨å™ªå£°å’Œä¸ç¡®å®šæ€§çš„ç°å®ç¯å¢ƒä¸‹éƒ¨ç½²é«˜æ•ˆã€ç¨³å¥çš„æè¿°é€»è¾‘æ¨ç†ç³»ç»Ÿæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as a full research paper at K-CAP 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20457v1",
      "published_date": "2025-10-23 11:48:43 UTC",
      "updated_date": "2025-10-23 11:48:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:49.915261+00:00"
    },
    {
      "arxiv_id": "2510.20877v1",
      "title": "Multimodal Negative Learning",
      "title_zh": "å¤šæ¨¡æ€è´Ÿå‘å­¦ä¹ ",
      "authors": [
        "Baoquan Gong",
        "Xiyuan Gao",
        "Pengfei Zhu",
        "Qinghua Hu",
        "Bing Cao"
      ],
      "abstract": "Multimodal learning systems often encounter challenges related to modality imbalance, where a dominant modality may overshadow others, thereby hindering the learning of weak modalities. Conventional approaches often force weak modalities to align with dominant ones in \"Learning to be (the same)\" (Positive Learning), which risks suppressing the unique information inherent in the weak modalities. To address this challenge, we offer a new learning paradigm: \"Learning Not to be\" (Negative Learning). Instead of enhancing weak modalities' target-class predictions, the dominant modalities dynamically guide the weak modality to suppress non-target classes. This stabilizes the decision space and preserves modality-specific information, allowing weak modalities to preserve unique information without being over-aligned. We proceed to reveal multimodal learning from a robustness perspective and theoretically derive the Multimodal Negative Learning (MNL) framework, which introduces a dynamic guidance mechanism tailored for negative learning. Our method provably tightens the robustness lower bound of multimodal learning by increasing the Unimodal Confidence Margin (UCoM) and reduces the empirical error of weak modalities, particularly under noisy and imbalanced scenarios. Extensive experiments across multiple benchmarks demonstrate the effectiveness and generalizability of our approach against competing methods. The code will be available at https://github.com/BaoquanGong/Multimodal-Negative-Learning.git.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å­¦ä¹ (Multimodal learning)ä¸­ä¸»å¯¼æ¨¡æ€æŠ‘åˆ¶å¼±åŠ¿æ¨¡æ€å¯¼è‡´çš„ç‹¬ç‰¹ä¿¡æ¯ä¸¢å¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMultimodal Negative Learning (MNL)çš„æ–°å‹å­¦ä¹ èŒƒå¼ã€‚è¯¥èŒƒå¼æ‘’å¼ƒäº†ä¼ ç»Ÿçš„â€œLearning to beâ€æ­£å‘å­¦ä¹ æ¨¡å¼ï¼Œè½¬è€Œé‡‡ç”¨â€œLearning Not to beâ€çš„è´Ÿå‘å­¦ä¹ ç†å¿µï¼Œé€šè¿‡ä¸»å¯¼æ¨¡æ€åŠ¨æ€å¼•å¯¼å¼±åŠ¿æ¨¡æ€å»æŠ‘åˆ¶éç›®æ ‡ç±»åˆ«(non-target classes)ã€‚è¿™ç§æ–¹æ³•åœ¨é¿å…è¿‡åº¦å¯¹é½çš„åŒæ—¶ï¼Œæœ‰æ•ˆç¨³å®šäº†å†³ç­–ç©ºé—´å¹¶ä¿ç•™äº†å„æ¨¡æ€ç‰¹æœ‰çš„å…³é”®ä¿¡æ¯ã€‚åœ¨ç†è®ºå±‚é¢ï¼Œç ”ç©¶è¯æ˜äº†MNLèƒ½é€šè¿‡å¢åŠ å•æ¨¡æ€ç½®ä¿¡åŒºé—´(Unimodal Confidence Margin, UCoM)æ¥æ”¶ç´§å¤šæ¨¡æ€å­¦ä¹ çš„é²æ£’æ€§ä¸‹ç•Œã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒMNLåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å±•ç°äº†å“è¶Šçš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å™ªå£°å’Œä¸å¹³è¡¡åœºæ™¯ä¸‹æ˜¾è‘—é™ä½äº†å¼±åŠ¿æ¨¡æ€çš„ç»éªŒè¯¯å·®(empirical error)ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20877v1",
      "published_date": "2025-10-23 11:47:11 UTC",
      "updated_date": "2025-10-23 11:47:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:54.718608+00:00"
    },
    {
      "arxiv_id": "2510.21867v1",
      "title": "Addressing Corner Cases in Autonomous Driving: A World Model-based Approach with Mixture of Experts and LLMs",
      "title_zh": "åº”å¯¹è‡ªåŠ¨é©¾é©¶ä¸­çš„æç«¯åœºæ™¯ï¼šä¸€ç§ç»“åˆæ··åˆä¸“å®¶æ¨¡å‹ä¸å¤§è¯­è¨€æ¨¡å‹çš„ä¸–ç•Œæ¨¡å‹æ–¹æ³•",
      "authors": [
        "Haicheng Liao",
        "Bonan Wang",
        "Junxian Yang",
        "Chengyue Wang",
        "Zhengbin He",
        "Guohui Zhang",
        "Chengzhong Xu",
        "Zhenning Li"
      ],
      "abstract": "Accurate and reliable motion forecasting is essential for the safe deployment of autonomous vehicles (AVs), particularly in rare but safety-critical scenarios known as corner cases. Existing models often underperform in these situations due to an over-representation of common scenes in training data and limited generalization capabilities. To address this limitation, we present WM-MoE, the first world model-based motion forecasting framework that unifies perception, temporal memory, and decision making to address the challenges of high-risk corner-case scenarios. The model constructs a compact scene representation that explains current observations, anticipates future dynamics, and evaluates the outcomes of potential actions. To enhance long-horizon reasoning, we leverage large language models (LLMs) and introduce a lightweight temporal tokenizer that maps agent trajectories and contextual cues into the LLM's feature space without additional training, enriching temporal context and commonsense priors. Furthermore, a mixture-of-experts (MoE) is introduced to decompose complex corner cases into subproblems and allocate capacity across scenario types, and a router assigns scenes to specialized experts that infer agent intent and perform counterfactual rollouts. In addition, we introduce nuScenes-corner, a new benchmark that comprises four real-world corner-case scenarios for rigorous evaluation. Extensive experiments on four benchmark datasets (nuScenes, NGSIM, HighD, and MoCAD) showcase that WM-MoE consistently outperforms state-of-the-art (SOTA) baselines and remains robust under corner-case and data-missing conditions, indicating the promise of world model-based architectures for robust and generalizable motion forecasting in fully AVs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­ç½•è§ä½†å…³é”®çš„æç«¯åœºæ™¯(Corner Cases)ï¼Œæå‡ºäº†é¦–ä¸ªåŸºäºä¸–ç•Œæ¨¡å‹(World Model)çš„è¿åŠ¨é¢„æµ‹æ¡†æ¶WM-MoEï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨å¤„ç†é«˜é£é™©åœºæ™¯æ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶ç»Ÿä¸€äº†æ„ŸçŸ¥ã€æ—¶åºè®°å¿†å’Œå†³ç­–åˆ¶å®šï¼Œé€šè¿‡åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å¹¶å¼•å…¥è½»é‡çº§æ—¶åºåˆ†è¯å™¨(Temporal Tokenizer)ï¼Œå°†æ™ºèƒ½ä½“è½¨è¿¹å’Œç¯å¢ƒçº¿ç´¢æ˜ å°„åˆ°LLMç‰¹å¾ç©ºé—´ï¼Œä»è€Œå¢å¼ºäº†é•¿ç¨‹æ¨ç†èƒ½åŠ›å¹¶å¼•å…¥äº†å¸¸è¯†å…ˆéªŒã€‚ä¸ºäº†åº”å¯¹å¤æ‚çš„æç«¯åœºæ™¯ï¼ŒWM-MoEå¼•å…¥äº†ä¸“å®¶æ··åˆ(Mixture-of-Experts, MoE)æœºåˆ¶ï¼Œåˆ©ç”¨è·¯ç”±æœºåˆ¶å°†ç‰¹å®šåœºæ™¯åˆ†é…ç»™ä¸“é—¨çš„ä¸“å®¶è¿›è¡Œæ„å›¾æ¨ç†å’Œåäº‹å®æ¨æ¼”(Counterfactual Rollouts)ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æ¨å‡ºäº†åŒ…å«å››ç§çœŸå®æç«¯åœºæ™¯çš„æ–°åŸºå‡†æµ‹è¯•é›†nuScenes-cornerï¼Œä»¥å¡«è¡¥è¯„ä¼°æ•°æ®çš„ç©ºç™½ã€‚åœ¨nuScenesã€NGSIMã€HighDå’ŒMoCADç­‰å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒWM-MoEçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›åŸºå‡†(SOTA)ï¼Œå±•ç°äº†å…¶åœ¨æç«¯åœºæ™¯å’Œæ•°æ®ç¼ºå¤±ç¯å¢ƒä¸‹çš„å¼ºåŠ²é²æ£’æ€§ä¸æ³›åŒ–æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21867v1",
      "published_date": "2025-10-23 11:41:51 UTC",
      "updated_date": "2025-10-23 11:41:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:16:58.761124+00:00"
    },
    {
      "arxiv_id": "2510.20453v1",
      "title": "Symbolic Regression and Differentiable Fits in Beyond the Standard Model Physics",
      "title_zh": "è¶…è¶Šæ ‡å‡†æ¨¡å‹ç‰©ç†ä¸­çš„ç¬¦å·å›å½’ä¸å¯å¾®æ‹Ÿåˆ",
      "authors": [
        "Shehu AbdusSalam",
        "Steven Abel",
        "Deaglan Bartlett",
        "Miguel Crispim RomÃ£o"
      ],
      "abstract": "We demonstrate the efficacy of symbolic regression (SR) to probe models of particle physics Beyond the Standard Model (BSM), by considering the so-called Constrained Minimal Supersymmetric Standard Model (CMSSM). Like many incarnations of BSM physics this model has a number (four) of arbitrary parameters, which determine the experimental signals, and cosmological observables such as the dark matter relic density. We show that analysis of the phenomenology can be greatly accelerated by using symbolic expressions derived for the observables in terms of the input parameters. Here we focus on the Higgs mass, the cold dark matter relic density, and the contribution to the anomalous magnetic moment of the muon. We find that SR can produce remarkably accurate expressions. Using them we make global fits to derive the posterior probability densities of the CMSSM input parameters which are in good agreement with those performed using conventional methods. Moreover, we demonstrate a major advantage of SR which is the ability to make fits using differentiable methods rather than sampling methods. We also compare the method with neural network (NN) regression. SR produces more globally robust results, while NNs require data that is focussed on the promising regions in order to be equally performant.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¬¦å·å›å½’(Symbolic Regression, SR)åœ¨æ¢ç´¢æ ‡å‡†æ¨¡å‹ä»¥å¤–(Beyond the Standard Model, BSM)ç‰©ç†æ¨¡å‹ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å—é™æœ€å°è¶…å¯¹ç§°æ ‡å‡†æ¨¡å‹(Constrained Minimal Supersymmetric Standard Model, CMSSM)çš„æ•ˆèƒ½ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ SR ä¸ºå¸Œæ ¼æ–¯ç»è‰²å­è´¨é‡(Higgs mass)ã€å†·æš—ç‰©è´¨æ®‹ä½™å¯†åº¦(cold dark matter relic density)åŠÎ¼å­åå¸¸ç£çŸ©(anomalous magnetic moment of the muon)ç­‰ç‰©ç†é‡æ¨å¯¼å‡ºäº†ç²¾ç¡®çš„ç¬¦å·è¡¨è¾¾å¼ï¼Œæ˜¾è‘—åŠ é€Ÿäº†ç‰©ç†ç°è±¡å­¦åˆ†æã€‚åˆ©ç”¨è¿™äº›è¡¨è¾¾å¼è¿›è¡Œçš„å…¨å±€æ‹Ÿåˆ(global fits)åœ¨å¯¼å‡ºè¾“å…¥å‚æ•°çš„åéªŒæ¦‚ç‡å¯†åº¦æ–¹é¢ä¸ä¼ ç»Ÿæ–¹æ³•é«˜åº¦å»åˆã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å¼ºè°ƒäº† SR çš„ä¸€å¤§ä¼˜åŠ¿ï¼Œå³èƒ½å¤Ÿé‡‡ç”¨å¯å¾®æ–¹æ³•(differentiable methods)è€Œéä¼ ç»Ÿçš„é‡‡æ ·æ–¹æ³•è¿›è¡Œæ‹Ÿåˆã€‚å¯¹æ¯”å®éªŒæ˜¾ç¤ºï¼ŒSR åœ¨å…¨å±€ç¨³å¥æ€§ä¸Šä¼˜äºç¥ç»ç½‘ç»œ(Neural Network, NN)å›å½’ï¼Œåè€…å¾€å¾€éœ€è¦é«˜åº¦é›†ä¸­çš„ç‰¹å®šåŒºåŸŸæ•°æ®æ‰èƒ½è¾¾åˆ°ç±»ä¼¼çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "hep-ph",
        "astro-ph.CO",
        "cs.AI",
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "hep-ph",
      "comment": "18 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20453v1",
      "published_date": "2025-10-23 11:40:15 UTC",
      "updated_date": "2025-10-23 11:40:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:01.979353+00:00"
    },
    {
      "arxiv_id": "2510.20448v2",
      "title": "MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction",
      "title_zh": "MolBridgeï¼šé¢å‘ç¨³å¥è¯ç‰©-è¯ç‰©ç›¸äº’ä½œç”¨äº‹ä»¶é¢„æµ‹çš„åŸå­çº§è”åˆå›¾ç»†åŒ–",
      "authors": [
        "Xuan Lin",
        "Aocheng Ding",
        "Tengfei Ma",
        "Hua Liang",
        "Zhe Quan"
      ],
      "abstract": "Drug combinations offer therapeutic benefits but also carry the risk of adverse drug-drug interactions (DDIs), especially under complex molecular structures. Accurate DDI event prediction requires capturing fine-grained inter-drug relationships, which are critical for modeling metabolic mechanisms such as enzyme-mediated competition. However, existing approaches typically rely on isolated drug representations and fail to explicitly model atom-level cross-molecular interactions, limiting their effectiveness across diverse molecular complexities and DDI type distributions. To address these limitations, we propose MolBridge, a novel atom-level joint graph refinement framework for robust DDI event prediction. MolBridge constructs a joint graph that integrates atomic structures of drug pairs, enabling direct modeling of inter-drug associations. A central challenge in such joint graph settings is the potential loss of information caused by over-smoothing when modeling long-range atomic dependencies. To overcome this, we introduce a structure consistency module that iteratively refines node features while preserving the global structural context. This joint design allows MolBridge to effectively learn both local and global interaction outperforms state-of-the-art baselines, achieving superior performance across long-tail and inductive scenarios. patterns, yielding robust representations across both frequent and rare DDI types. Extensive experiments on two benchmark datasets show that MolBridge consistently. These results demonstrate the advantages of fine-grained graph refinement in improving the accuracy, robustness, and mechanistic interpretability of DDI event prediction.This work contributes to Web Mining and Content Analysis by developing graph-based methods for mining and analyzing drug-drug interaction networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MolBridgeï¼Œä¸€ç§ä¸“ä¸ºDrug-Drug Interaction (DDI)äº‹ä»¶é¢„æµ‹è®¾è®¡çš„atom-level joint graph refinementæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•ä¾èµ–å­¤ç«‹è¯ç‰©è¡¨ç¤ºè€Œå¿½è§†è·¨åˆ†å­åŸå­çº§äº¤äº’çš„é—®é¢˜ã€‚MolBridgeé€šè¿‡æ„å»ºæ•´åˆè¯ç‰©å¯¹åŸå­ç»“æ„çš„è”åˆå›¾ï¼Œå®ç°äº†å¯¹è¯ç‰©é—´å…³è”çš„ç›´æ¥å»ºæ¨¡ã€‚é’ˆå¯¹è”åˆå›¾ä¸­å»ºæ¨¡é•¿ç¨‹åŸå­ä¾èµ–æ—¶å¯èƒ½å‡ºç°çš„over-smoothingæŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†structure consistencyæ¨¡å—ï¼Œé€šè¿‡è¿­ä»£ç»†åŒ–èŠ‚ç‚¹ç‰¹å¾æ¥ä¿ç•™å…¨å±€ç»“æ„ä¸Šä¸‹æ–‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMolBridgeåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰baselineï¼Œå¹¶åœ¨long-tailå’Œinductiveåœºæ™¯ä¸‹å±•ç°å‡ºå“è¶Šçš„é²æ£’æ€§ã€‚è¯¥ç ”ç©¶æ˜¾è‘—æå‡äº†DDIé¢„æµ‹çš„å‡†ç¡®æ€§ä¸é²æ£’æ€§ï¼Œå¹¶ä¸ºè¯ç‰©ç›¸äº’ä½œç”¨çš„æœºåˆ¶åˆ†ææä¾›äº†æ›´å¼ºçš„interpretabilityã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20448v2",
      "published_date": "2025-10-23 11:33:16 UTC",
      "updated_date": "2025-10-24 02:34:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:05.761633+00:00"
    },
    {
      "arxiv_id": "2510.20441v1",
      "title": "UniSE: A Unified Framework for Decoder-only Autoregressive LM-based Speech Enhancement",
      "title_zh": "UniSEï¼šåŸºäºä»…è§£ç å™¨è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„ç»Ÿä¸€è¯­éŸ³å¢å¼ºæ¡†æ¶",
      "authors": [
        "Haoyin Yan",
        "Chengwei Liu",
        "Shaofei Xue",
        "Xiaotao Liang",
        "Zheng Xue"
      ],
      "abstract": "The development of neural audio codecs (NACs) has largely promoted applications of language models (LMs) to speech processing and understanding. However, there lacks the verification on the effectiveness of autoregressive (AR) LMbased models in unifying different sub-tasks of speech enhancement (SE). In this work, we propose UniSE, a unified decoder-only LM-based framework to handle different SE tasks including speech restoration, target speaker extraction and speech separation. It takes input speech features as conditions and generates discrete tokens of the target speech using AR modeling, which facilitates a compatibility between distinct learning patterns of multiple tasks. Experiments on several benchmarks indicate the proposed UniSE can achieve competitive performance compared to discriminative and generative baselines, showing the capacity of LMs in unifying SE tasks. The demo page is available here: https://github.com/hyyan2k/UniSE.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹åŸºäºè§£ç å™¨(Decoder-only)çš„è‡ªå›å½’è¯­è¨€æ¨¡å‹(AR LM)åœ¨ç»Ÿä¸€è¯­éŸ³å¢å¼º(SE)å„é¡¹å­ä»»åŠ¡ä¸­æœ‰æ•ˆæ€§éªŒè¯ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†UniSEç»Ÿä¸€æ¡†æ¶ã€‚UniSEèƒ½å¤ŸåŒæ—¶å¤„ç†è¯­éŸ³ä¿®å¤(speech restoration)ã€ç›®æ ‡å‘è¨€äººæå–(target speaker extraction)å’Œè¯­éŸ³åˆ†ç¦»(speech separation)ç­‰å¤šç§ä»»åŠ¡ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è¾“å…¥è¯­éŸ³ç‰¹å¾ä½œä¸ºè°ƒèŠ‚æ¡ä»¶ï¼Œé€šè¿‡è‡ªå›å½’å»ºæ¨¡(AR modeling)ç”Ÿæˆç›®æ ‡è¯­éŸ³çš„ç¦»æ•£ä»¤ç‰Œ(discrete tokens)ï¼Œæœ‰æ•ˆè§£å†³äº†ä¸åŒä»»åŠ¡å­¦ä¹ æ¨¡å¼ä¹‹é—´çš„å…¼å®¹æ€§é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUniSEåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†ä¸ä¸»æµåˆ¤åˆ«å¼åŠç”Ÿæˆå¼åŸºå‡†æ¨¡å‹ç›¸åª²ç¾çš„ç«äº‰æ€§è¡¨ç°ã€‚è¯¥ç ”ç©¶æœ‰åŠ›è¯æ˜äº†è¯­è¨€æ¨¡å‹(LMs)åœ¨ç»Ÿä¸€SEä»»åŠ¡ä¸Šçš„å¼ºå¤§èƒ½åŠ›ï¼Œä¸ºè¯­éŸ³å¢å¼ºé¢†åŸŸçš„ä¸€ä½“åŒ–å»ºæ¨¡æä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, submitted to ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.20441v1",
      "published_date": "2025-10-23 11:22:24 UTC",
      "updated_date": "2025-10-23 11:22:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:07.359584+00:00"
    },
    {
      "arxiv_id": "2510.20438v1",
      "title": "Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment",
      "title_zh": "çŸ¥è¯†è’¸é¦ä¸­çš„åŠ¨æ€æƒé‡è°ƒæ•´ï¼šåŸºäº Vision Transformer çš„é«˜ç²¾åº¦è‚ºç™Œæ£€æµ‹ä¸å®æ—¶éƒ¨ç½²",
      "authors": [
        "Saif Ur Rehman Khan",
        "Muhammad Nabeel Asim",
        "Sebastian Vollmer",
        "Andreas Dengel"
      ],
      "abstract": "This paper presents the FuzzyDistillViT-MobileNet model, a novel approach for lung cancer (LC) classification, leveraging dynamic fuzzy logic-driven knowledge distillation (KD) to address uncertainty and complexity in disease diagnosis. Unlike traditional models that rely on static KD with fixed weights, our method dynamically adjusts the distillation weight using fuzzy logic, enabling the student model to focus on high-confidence regions while reducing attention to ambiguous areas. This dynamic adjustment improves the model ability to handle varying uncertainty levels across different regions of LC images. We employ the Vision Transformer (ViT-B32) as the instructor model, which effectively transfers knowledge to the student model, MobileNet, enhancing the student generalization capabilities. The training process is further optimized using a dynamic wait adjustment mechanism that adapts the training procedure for improved convergence and performance. To enhance image quality, we introduce pixel-level image fusion improvement techniques such as Gamma correction and Histogram Equalization. The processed images (Pix1 and Pix2) are fused using a wavelet-based fusion method to improve image resolution and feature preservation. This fusion method uses the wavedec2 function to standardize images to a 224x224 resolution, decompose them into multi-scale frequency components, and recursively average coefficients at each level for better feature representation. To address computational efficiency, Genetic Algorithm (GA) is used to select the most suitable pre-trained student model from a pool of 12 candidates, balancing model performance with computational cost. The model is evaluated on two datasets, including LC25000 histopathological images (99.16% accuracy) and IQOTH/NCCD CT-scan images (99.54% accuracy), demonstrating robustness across different imaging domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FuzzyDistillViT-MobileNetæ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡åŠ¨æ€æ¨¡ç³Šé€»è¾‘é©±åŠ¨çš„Knowledge Distillation (KD)æŠ€æœ¯æå‡è‚ºç™Œåˆ†ç±»çš„å‡†ç¡®æ€§ä¸å®æ—¶éƒ¨ç½²èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„é™æ€æƒé‡åˆ†é…ä¸åŒï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ¨¡ç³Šé€»è¾‘åŠ¨æ€è°ƒæ•´è’¸é¦æƒé‡ï¼Œä½¿Student Modelèƒ½å¤Ÿèšç„¦äºé«˜ç½®ä¿¡åº¦åŒºåŸŸå¹¶æœ‰æ•ˆå¤„ç†è‚ºç™Œå›¾åƒä¸­çš„ä¸ç¡®å®šæ€§ã€‚æ¨¡å‹é‡‡ç”¨Vision Transformer (ViT-B32)ä½œä¸ºInstructor Modelï¼Œé€šè¿‡çŸ¥è¯†è¿ç§»å¢å¼ºäº†MobileNetçš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åˆ©ç”¨Genetic Algorithm (GA)ä»å€™é€‰æ¨¡å‹ä¸­ç­›é€‰å‡ºæ€§èƒ½ä¸è®¡ç®—æˆæœ¬å¹³è¡¡çš„æœ€ä½³æ¶æ„ã€‚åœ¨å›¾åƒå¤„ç†é˜¶æ®µï¼Œç ”ç©¶å¼•å…¥äº†ç»“åˆGamma correctionå’ŒHistogram Equalizationçš„wavelet-based fusionæŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†ç‰¹å¾è¡¨ç¤ºä¸å›¾åƒåˆ†è¾¨ç‡ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥dynamic wait adjustmentæœºåˆ¶è¿›ä¸€æ­¥ä¼˜åŒ–äº†è®­ç»ƒæ”¶æ•›è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨LC25000ç»„ç»‡ç—…ç†æ•°æ®é›†å’ŒIQOTH/NCCD CTæ‰«ææ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº†99.16%å’Œ99.54%çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œè¯æ˜äº†å…¶åœ¨ä¸åŒæˆåƒé¢†åŸŸçš„é«˜é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20438v1",
      "published_date": "2025-10-23 11:19:52 UTC",
      "updated_date": "2025-10-23 11:19:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:19.343804+00:00"
    },
    {
      "arxiv_id": "2510.21866v1",
      "title": "Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks",
      "title_zh": "è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›å¤©èŠ±æ¿ï¼šçŸ¥è¯†å¯†é›†å‹ä»»åŠ¡çš„å®è¯è¯æ®",
      "authors": [
        "Javier MarÃ­n"
      ],
      "abstract": "We document empirical capability ceilings in decoder-only autoregressive language models across knowledge-intensive tasks. Systematic evaluation of OPT and Pythia model families (70M-30B parameters, spanning 240 times scaling) reveals that knowledge retrieval tasks show negligible accuracy improvement despite smooth loss reduction. On MMLU mathematics benchmarks, accuracy remains flat at 19-20% (below 25% random chance) across all scales while cross-entropy loss decreases by 31%. In contrast, procedural tasks like arithmetic show conventional scaling where both metrics improve together. Attention intervention experiments reveal high sensitivity to perturbation: swapping attention patterns between models causes catastrophic performance collapse (complete accuracy loss) rather than graceful degradation. These measurements have immediate engineering implications: for knowledge-intensive applications using OPT and Pythia architectures, parameter scaling beyond 1-2B offers minimal accuracy gains despite continued loss improvement. Our findings quantify capability-specific scaling failures in these model families to inform resource allocation decisions. Whether these patterns reflect fundamental constraints of decoder-only architectures or implementation-specific limitations remains an open question requiring investigation across diverse architectural approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å¯¹ OPT å’Œ Pythia æ¨¡å‹ç³»åˆ—çš„ç³»ç»Ÿè¯„ä¼°ï¼Œæ­ç¤ºäº†ä»…è§£ç å™¨ (decoder-only) è‡ªå›å½’è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­å­˜åœ¨çš„ç»éªŒæ€§èƒ½åŠ›ä¸Šé™ (capability ceilings)ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶äº¤å‰ç†µæŸå¤± (cross-entropy loss) éšç€æ¨¡å‹è§„æ¨¡æ‰©å¤§æŒç»­å¹³æ»‘ä¸‹é™ï¼Œä½†åœ¨çŸ¥è¯†æ£€ç´¢ä»»åŠ¡å’Œ MMLU æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­ï¼Œå‡†ç¡®ç‡å¹¶æœªéšä¹‹æå‡ï¼Œç”šè‡³é•¿æœŸå¤„äºéšæœºæ°´å¹³ä»¥ä¸‹ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç®—æœ¯ç­‰ç¨‹åºåŒ–ä»»åŠ¡ (procedural tasks) åˆ™ç¬¦åˆä¼ ç»Ÿçš„ Scaling Lawï¼Œå±•ç°å‡ºæ€§èƒ½ä¸è§„æ¨¡çš„æ­£ç›¸å…³æ€§ã€‚æ³¨æ„åŠ›å¹²é¢„ (attention intervention) å®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œæ¨¡å‹æ€§èƒ½å¯¹æ³¨æ„åŠ›æ¨¡å¼çš„æ‰°åŠ¨æåº¦æ•æ„Ÿï¼Œäº¤æ¢æ¨¡å‹é—´çš„æ³¨æ„åŠ›æ¨¡å¼ä¼šå¯¼è‡´å‡†ç¡®ç‡å®Œå…¨å´©æºƒè€Œéå¹³æ»‘é€€åŒ–ã€‚è¿™è¡¨æ˜å¯¹äºç‰¹å®šçš„æ¶æ„ï¼Œå½“å‚æ•°è§„æ¨¡è¶…è¿‡ 1-2B åï¼Œè¿›ä¸€æ­¥æ‰©å±•è§„æ¨¡åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡æ”¶ç›Šå¾®ä¹å…¶å¾®ã€‚è¯¥å‘ç°é‡åŒ–äº†ç‰¹å®šèƒ½åŠ›çš„æ‰©å±•å¤±æ•ˆ (scaling failures)ï¼Œä¸ºå¤§è¯­è¨€æ¨¡å‹å¼€å‘ä¸­çš„èµ„æºåˆ†é…å’Œæ¶æ„é€‰æ‹©æä¾›äº†é‡è¦çš„å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The experiments in this paper were performed in January 2024. Current model architectures are considerably more complex than those presented here",
      "pdf_url": "https://arxiv.org/pdf/2510.21866v1",
      "published_date": "2025-10-23 11:09:31 UTC",
      "updated_date": "2025-10-23 11:09:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:22.559829+00:00"
    },
    {
      "arxiv_id": "2510.20875v1",
      "title": "CC-GRMAS: A Multi-Agent Graph Neural System for Spatiotemporal Landslide Risk Assessment in High Mountain Asia",
      "title_zh": "CC-GRMASï¼šé¢å‘äºšæ´²é«˜å±±åŒºæ—¶ç©ºæ»‘å¡é£é™©è¯„ä¼°çš„å¤šæ™ºèƒ½ä½“å›¾ç¥ç»ç³»ç»Ÿ",
      "authors": [
        "Mihir Panchal",
        "Ying-Jung Chen",
        "Surya Parkash"
      ],
      "abstract": "Landslides are a growing climate induced hazard with severe environmental and human consequences, particularly in high mountain Asia. Despite increasing access to satellite and temporal datasets, timely detection and disaster response remain underdeveloped and fragmented. This work introduces CC-GRMAS, a framework leveraging a series of satellite observations and environmental signals to enhance the accuracy of landslide forecasting. The system is structured around three interlinked agents Prediction, Planning, and Execution, which collaboratively enable real time situational awareness, response planning, and intervention. By incorporating local environmental factors and operationalizing multi agent coordination, this approach offers a scalable and proactive solution for climate resilient disaster preparedness across vulnerable mountainous terrains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CC-GRMASï¼Œä¸€ç§é’ˆå¯¹é«˜äºšæ´²(High Mountain Asia)åœ°åŒºæ—¶ç©ºæ»‘å¡é£é™©è¯„ä¼°çš„å¤šæ™ºèƒ½ä½“å›¾ç¥ç»ç½‘ç»œç³»ç»Ÿï¼Œæ—¨åœ¨åº”å¯¹æ°”å€™è¯±å¯¼çš„æ»‘å¡ç¾å®³åŠç°æœ‰ç¾å®³å“åº”ç³»ç»Ÿç¢ç‰‡åŒ–ã€æ»åçš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶æœ‰æ•ˆåˆ©ç”¨å«æ˜Ÿè§‚æµ‹(Satellite Observations)å’Œå¤šç§ç¯å¢ƒä¿¡å·æ¥å¢å¼ºæ»‘å¡é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶æ„å»ºäº†é¢„æµ‹(Prediction)ã€è§„åˆ’(Planning)ä¸æ‰§è¡Œ(Execution)ä¸‰ä¸ªäº’è”çš„æ™ºèƒ½ä½“æ ¸å¿ƒæ¶æ„ã€‚é€šè¿‡å¤šæ™ºèƒ½ä½“åä½œ(Multi-Agent Coordination)æœºåˆ¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿå®ç°å®æ—¶çš„æ€åŠ¿æ„ŸçŸ¥ã€å“åº”è§„åˆ’ä¸å¹²é¢„è¡ŒåŠ¨ã€‚é€šè¿‡æ•´åˆå±€éƒ¨ç¯å¢ƒå› ç´ å¹¶å®ç°ä¸šåŠ¡åŒ–ååŒï¼ŒCC-GRMASä¸ºé«˜æµ·æ‹”è„†å¼±å±±åŒºæä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”ä¸»åŠ¨çš„æ°”å€™éŸ§æ€§(Climate Resilient)é˜²ç¾é¢„å¤‡æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20875v1",
      "published_date": "2025-10-23 10:30:48 UTC",
      "updated_date": "2025-10-23 10:30:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:24.050110+00:00"
    },
    {
      "arxiv_id": "2510.20408v1",
      "title": "Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control",
      "title_zh": "å¹³è¡¡ä¸“ä¸šåŒ–ä¸ä¸­å¿ƒåŒ–ï¼šé¢å‘æ—¶åºå·¥ä¸šæ§åˆ¶çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åŸºå‡†",
      "authors": [
        "Tom Maus",
        "Asma Atamna",
        "Tobias Glasmachers"
      ],
      "abstract": "Autonomous control of multi-stage industrial processes requires both local specialization and global coordination. Reinforcement learning (RL) offers a promising approach, but its industrial adoption remains limited due to challenges such as reward design, modularity, and action space management. Many academic benchmarks differ markedly from industrial control problems, limiting their transferability to real-world applications. This study introduces an enhanced industry-inspired benchmark environment that combines tasks from two existing benchmarks, SortingEnv and ContainerGym, into a sequential recycling scenario with sorting and pressing operations. We evaluate two control strategies: a modular architecture with specialized agents and a monolithic agent governing the full system, while also analyzing the impact of action masking. Our experiments show that without action masking, agents struggle to learn effective policies, with the modular architecture performing better. When action masking is applied, both architectures improve substantially, and the performance gap narrows considerably. These results highlight the decisive role of action space constraints and suggest that the advantages of specialization diminish as action complexity is reduced. The proposed benchmark thus provides a valuable testbed for exploring practical and robust multi-agent RL solutions in industrial automation, while contributing to the ongoing debate on centralization versus specialization.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤šé˜¶æ®µå·¥ä¸šè¿‡ç¨‹çš„è‡ªä¸»æ§åˆ¶é—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨åœ¨ Reinforcement Learning (RL) æ¡†æ¶ä¸‹å¦‚ä½•å¹³è¡¡å±€éƒ¨ä¸“ä¸šåŒ– (Specialization) ä¸å…¨å±€åè°ƒ (Centralization)ã€‚ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå—å·¥ä¸šå¯å‘çš„å¢å¼ºå‹åŸºå‡†ç¯å¢ƒï¼Œå°† SortingEnv å’Œ ContainerGym çš„ä»»åŠ¡æ•´åˆä¸ºä¸€ä¸ªåŒ…å«åˆ†æ‹£å’Œå‹ç¼©æ“ä½œçš„é¡ºåºå›æ”¶åœºæ™¯ã€‚é€šè¿‡å¯¹æ¯”è¯„ä¼°ç”±ä¸“é—¨æ™ºèƒ½ä½“ç»„æˆçš„æ¨¡å—åŒ–æ¶æ„ (modular architecture) ä¸ç®¡ç†æ•´ä¸ªç³»ç»Ÿçš„å•ä½“æ™ºèƒ½ä½“ (monolithic agent)ï¼Œç ”ç©¶æ·±å…¥åˆ†æäº†åŠ¨ä½œæ©ç  (action masking) å¯¹ç­–ç•¥å­¦ä¹ çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ²¡æœ‰åŠ¨ä½œæ©ç æ—¶ï¼Œæ¨¡å—åŒ–æ¶æ„è¡¨ç°æ›´ä¼˜ï¼Œè€Œåº”ç”¨åŠ¨ä½œæ©ç åï¼Œä¸¤ç§æ¶æ„çš„æ€§èƒ½å·®è·æ˜¾è‘—ç¼©å°ä¸”å‡æœ‰å¤§å¹…æå‡ã€‚ç ”ç©¶å¼ºè°ƒäº†åŠ¨ä½œç©ºé—´ (action space) çº¦æŸåœ¨å·¥ä¸šæ§åˆ¶ä¸­çš„å†³å®šæ€§ä½œç”¨ï¼ŒæŒ‡å‡ºéšç€åŠ¨ä½œå¤æ‚æ€§é™ä½ï¼Œä¸“ä¸šåŒ–æ¶æ„çš„ä¼˜åŠ¿ä¼šéšä¹‹å‡å¼±ã€‚è¯¥æˆæœä¸ºåœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ä¸­åº”ç”¨ Multi-Agent Reinforcement Learning æä¾›äº†å®ç”¨çš„æµ‹è¯•å¹³å°å’Œç†è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint (submitted version) to be presented at the 13th International Conference on Industrial Engineering and Applications (ICIEA-EU), Milan, 2026. The final Version of Record will appear in the official conference proceedings",
      "pdf_url": "https://arxiv.org/pdf/2510.20408v1",
      "published_date": "2025-10-23 10:21:54 UTC",
      "updated_date": "2025-10-23 10:21:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:32.662749+00:00"
    },
    {
      "arxiv_id": "2511.04685v1",
      "title": "A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024",
      "title_zh": "2024å¹´ç»¼åˆåŒ»ç–—æ’ç­ç«èµ›çš„æ··åˆæ±‚è§£æ–¹æ³•",
      "authors": [
        "Daniela Guericke",
        "Rolf van der Hulst",
        "Asal Karimpour",
        "Ieke Schrader",
        "Matthias Walter"
      ],
      "abstract": "We report about the algorithm, implementation and results submitted to the Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored third in the competition. Our approach combines mixed-integer programming, constraint programming and simulated annealing in a 3-phase solution approach based on decomposition into subproblems. Next to describing our approach and describing our design decisions, we share our insights and, for the first time, lower bounds on the optimal solution values for the benchmark instances. We finally highlight open problems for which we think that addressing them could improve our approach even further.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† Team Twente åœ¨ 2024 å¹´é›†æˆåŒ»ç–—æ’ç­ç«èµ› (Integrated Healthcare Timetabling Competition 2024) ä¸­è·å¾—ç¬¬ä¸‰åçš„ç®—æ³•å®ç°ä¸ç»“æœã€‚å›¢é˜Ÿæå‡ºäº†ä¸€ç§æ··åˆè§£å†³æ–¹æ¡ˆï¼Œå°†æ··åˆæ•´æ•°è§„åˆ’ (Mixed-integer programming, MIP)ã€çº¦æŸè§„åˆ’ (Constraint programming, CP) å’Œæ¨¡æ‹Ÿé€€ç« (Simulated annealing, SA) æœ‰æ•ˆç»“åˆã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº†åŸºäºå­é—®é¢˜åˆ†è§£çš„ä¸‰é˜¶æ®µæ±‚è§£æµç¨‹ï¼Œè¯¦ç»†é˜è¿°äº†é’ˆå¯¹å¤æ‚æ’ç­é—®é¢˜çš„è®¾è®¡å†³ç­–ä¸ä¼˜åŒ–æ€è·¯ã€‚ç ”ç©¶è¿˜é¦–æ¬¡æä¾›äº†è¯¥ç«èµ›åŸºå‡†å®ä¾‹çš„æœ€ä¼˜è§£å€¼ä¸‹ç•Œ (lower bounds)ï¼Œä¸ºåç»­ç®—æ³•è¯„ä¼°å¥ å®šäº†åŸºç¡€ã€‚æœ€åï¼Œæ–‡ç« æ¢è®¨äº†å½“å‰æ–¹æ³•ä¸­å°šå­˜çš„æŒ‘æˆ˜åŠæ”¹è¿›æ–¹å‘ï¼Œä¸ºåŒ»ç–—èµ„æºè°ƒåº¦é¢†åŸŸæä¾›äº†é‡è¦çš„å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 2 figures, 10 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.04685v1",
      "published_date": "2025-10-23 10:14:04 UTC",
      "updated_date": "2025-10-23 10:14:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:33.148920+00:00"
    },
    {
      "arxiv_id": "2510.20402v1",
      "title": "A computational model and tool for generating more novel opportunities in professional innovation processes",
      "title_zh": "ä¸“ä¸šåˆ›æ–°è¿‡ç¨‹ä¸­ç”Ÿæˆæ›´å¤šæ–°é¢–æœºä¼šçš„è®¡ç®—æ¨¡å‹ä¸å·¥å…·",
      "authors": [
        "Neil Maiden",
        "Konstantinos Zachos",
        "James Lockerbie",
        "Kostas Petrianakis",
        "Amanda Brown"
      ],
      "abstract": "This paper presents a new computational model of creative outcomes, informed by creativity theories and techniques, which was implemented to generate more novel opportunities for innovation projects. The model implemented five functions that were developed to contribute to the generation of innovation opportunities with higher novelty without loss of usefulness. The model was evaluated using opportunities generated for an innovation project in the hospitality sector. The evaluation revealed that the computational model generated outcomes that were more novel and/or useful than outcomes from Notebook LM and ChatGPT4o. However, not all model functions contributed to the generation of more novel opportunities, leading to new directions for further model development",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„åˆ›é€ æ€§æˆæœè®¡ç®—æ¨¡å‹åŠå…¶é…å¥—å·¥å…·ï¼Œæ—¨åœ¨ä¸ºä¸“ä¸šåˆ›æ–°é¡¹ç›®ç”Ÿæˆæ›´å…·æ–°é¢–æ€§(novelty)çš„åˆ›æ–°æœºä¼šã€‚è¯¥æ¨¡å‹åŸºäºåˆ›é€ åŠ›ç†è®ºå’ŒæŠ€æœ¯ï¼Œé›†æˆäº†äº”é¡¹æ—¨åœ¨æå‡äº§å‡ºè´¨é‡çš„åŠŸèƒ½ï¼Œç¡®ä¿åœ¨å¢å¼ºæ–°é¢–æ€§çš„åŒæ—¶ä¸æŸå¤±å…¶å®ç”¨æ€§(usefulness)ã€‚é€šè¿‡å¯¹é…’åº—è¡Œä¸šåˆ›æ–°é¡¹ç›®çš„å®è¯è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ¨¡å‹ç”Ÿæˆçš„æ–¹æ¡ˆåœ¨è·¨ç»´åº¦è¡¨ç°ä¸Šä¼˜äº Notebook LM å’Œ ChatGPT4oã€‚å°½ç®¡å¹¶éæ‰€æœ‰é¢„è®¾åŠŸèƒ½éƒ½å¯¹æ–°é¢–æ€§çš„æå‡äº§ç”Ÿäº†åŒç­‰è´¡çŒ®ï¼Œä½†è¿™ä¸€è¯„ä¼°ç»“æœä¸ºè®¡ç®—åˆ›é€ åŠ›æ¨¡å‹çš„åç»­è¿­ä»£æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘å’Œæ”¹è¿›æ–¹å‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20402v1",
      "published_date": "2025-10-23 10:09:57 UTC",
      "updated_date": "2025-10-23 10:09:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:34.057989+00:00"
    },
    {
      "arxiv_id": "2510.20388v1",
      "title": "FLAS: a combination of proactive and reactive auto-scaling architecture for distributed services",
      "title_zh": "FLASï¼šä¸€ç§ç»“åˆä¸»åŠ¨å¼ä¸å“åº”å¼æœºåˆ¶çš„åˆ†å¸ƒå¼æœåŠ¡è‡ªåŠ¨ä¼¸ç¼©æ¶æ„",
      "authors": [
        "VÃ­ctor RampÃ©rez",
        "Javier Soriano",
        "David Lizcano",
        "Juan A. Lara"
      ],
      "abstract": "Cloud computing has established itself as the support for the vast majority of emerging technologies, mainly due to the characteristic of elasticity it offers. Auto-scalers are the systems that enable this elasticity by acquiring and releasing resources on demand to ensure an agreed service level. In this article we present FLAS (Forecasted Load Auto-Scaling), an auto-scaler for distributed services that combines the advantages of proactive and reactive approaches according to the situation to decide the optimal scaling actions in every moment. The main novelties introduced by FLAS are (i) a predictive model of the high-level metrics trend which allows to anticipate changes in the relevant SLA parameters (e.g. performance metrics such as response time or throughput) and (ii) a reactive contingency system based on the estimation of high-level metrics from resource use metrics, reducing the necessary instrumentation (less invasive) and allowing it to be adapted agnostically to different applications. We provide a FLAS implementation for the use case of a content-based publish-subscribe middleware (E-SilboPS) that is the cornerstone of an event-driven architecture. To the best of our knowledge, this is the first auto-scaling system for content-based publish-subscribe distributed systems (although it is generic enough to fit any distributed service). Through an evaluation based on several test cases recreating not only the expected contexts of use, but also the worst possible scenarios (following the Boundary-Value Analysis or BVA test methodology), we have validated our approach and demonstrated the effectiveness of our solution by ensuring compliance with performance requirements over 99% of the time.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FLAS (Forecasted Load Auto-Scaling)ï¼Œä¸€ç§é’ˆå¯¹åˆ†å¸ƒå¼æœåŠ¡çš„è‡ªåŠ¨ä¼¸ç¼©æ¶æ„ï¼Œæ—¨åœ¨ç»“åˆä¸»åŠ¨(proactive)å’Œè¢«åŠ¨(reactive)ç­–ç•¥çš„ä¼˜åŠ¿ä»¥å®ç°æœ€ä¼˜èµ„æºè°ƒåº¦ã€‚FLASçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†é’ˆå¯¹é«˜å±‚æŒ‡æ ‡è¶‹åŠ¿çš„é¢„æµ‹æ¨¡å‹ï¼Œèƒ½å¤Ÿé¢„å…ˆè¯†åˆ«å“åº”æ—¶é—´æˆ–ååé‡ç­‰å…³é”®SLAå‚æ•°çš„å˜åŒ–ï¼Œå¹¶ç»“åˆä¸€å¥—åŸºäºèµ„æºä½¿ç”¨æƒ…å†µä¼°ç®—é«˜å±‚æŒ‡æ ‡çš„è¢«åŠ¨åº”æ€¥æœºåˆ¶ã€‚è¿™ç§è®¾è®¡é™ä½äº†å¯¹åº”ç”¨ä¾µå…¥æ€§çš„è¦æ±‚ï¼Œä½¿å…¶èƒ½å¤Ÿçµæ´»é€‚é…ä¸åŒçš„åˆ†å¸ƒå¼æœåŠ¡ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨å‘å¸ƒ/è®¢é˜…ä¸­é—´ä»¶E-SilboPSä¸Šå®ç°äº†è¯¥ç³»ç»Ÿï¼Œå¹¶åˆ©ç”¨è¾¹ç•Œå€¼åˆ†æ(BVA)æ–¹æ³•åœ¨å¤šç§æç«¯åœºæ™¯ä¸‹è¿›è¡Œäº†å‹åŠ›æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFLASåœ¨è¶…è¿‡99%çš„æ—¶é—´å†…å‡èƒ½ç¡®ä¿ç³»ç»Ÿæ»¡è¶³æ€§èƒ½éœ€æ±‚ï¼Œè¯æ˜äº†è¯¥æ–¹æ¡ˆåœ¨ä¿éšœåˆ†å¸ƒå¼ç³»ç»Ÿå¼¹æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20388v1",
      "published_date": "2025-10-23 09:38:07 UTC",
      "updated_date": "2025-10-23 09:38:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:37.564631+00:00"
    },
    {
      "arxiv_id": "2510.20387v1",
      "title": "Relative-Based Scaling Law for Neural Language Models",
      "title_zh": "ç¥ç»è¯­è¨€æ¨¡å‹çš„ç›¸å¯¹ç¼©æ”¾å®šå¾‹",
      "authors": [
        "Baoqing Yue",
        "Jinyuan Zhou",
        "Zixi Wei",
        "Jingtao Zhan",
        "Qingyao Ai",
        "Yiqun Liu"
      ],
      "abstract": "Scaling laws aim to accurately predict model performance across different scales. Existing scaling-law studies almost exclusively rely on cross-entropy as the evaluation metric. However, cross-entropy provides only a partial view of performance: it measures the absolute probability assigned to the correct token, but ignores the relative ordering between correct and incorrect tokens. Yet, relative ordering is crucial for language models, such as in greedy-sampling scenario. To address this limitation, we investigate scaling from the perspective of relative ordering. We first propose the Relative-Based Probability (RBP) metric, which quantifies the probability that the correct token is ranked among the top predictions. Building on this metric, we establish the Relative-Based Scaling Law, which characterizes how RBP improves with increasing model size. Through extensive experiments on four datasets and four model families spanning five orders of magnitude, we demonstrate the robustness and accuracy of this law. Finally, we illustrate the broad application of this law with two examples, namely providing a deeper explanation of emergence phenomena and facilitating finding fundamental theories of scaling laws. In summary, the Relative-Based Scaling Law complements the cross-entropy perspective and contributes to a more complete understanding of scaling large language models. Thus, it offers valuable insights for both practical development and theoretical exploration.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œç°æœ‰çš„ Scaling Law ä¸»è¦ä¾èµ– Cross-Entropy æŒ‡æ ‡ï¼Œä½†è¿™å¿½ç•¥äº†å¯¹è¯­è¨€æ¨¡å‹è‡³å…³é‡è¦çš„ç›¸å¯¹æ’åº (Relative Ordering) è§†è§’ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ç›¸å¯¹æ¦‚ç‡ (Relative-Based Probability, RBP) æŒ‡æ ‡ï¼Œæ—¨åœ¨é‡åŒ–æ­£ç¡® Token åœ¨é¢„æµ‹æ’åä¸­çš„ä½ç½®ï¼Œå¹¶æ®æ­¤å»ºç«‹äº† Relative-Based Scaling Lawï¼Œæè¿°äº† RBP éšæ¨¡å‹è§„æ¨¡å¢é•¿çš„æ¼”è¿›è§„å¾‹ã€‚é€šè¿‡åœ¨ 4 ä¸ªæ•°æ®é›†å’Œ 4 ä¸ªæ¨¡å‹ç³»åˆ—ï¼ˆè·¨è¶Šäº”ä¸ªæ•°é‡çº§ï¼‰ä¸Šçš„å®éªŒï¼Œè¯æ˜äº†è¯¥å®šå¾‹å…·æœ‰æé«˜çš„é²æ£’æ€§ä¸å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥å®šå¾‹è¿˜å¯ç”¨äºæ·±åº¦è§£é‡Šæ¨¡å‹èƒ½åŠ›çš„æ¶Œç°ç°è±¡ (Emergence Phenomena)ï¼Œå¹¶æœ‰åŠ©äºæ¢ç´¢ Scaling Laws çš„æ·±å±‚åŸºç¡€ç†è®ºã€‚è¯¥ç ”ç©¶æœ‰æ•ˆè¡¥å……äº†ä¼ ç»Ÿçš„ Cross-Entropy è¯„ä¼°ä½“ç³»ï¼Œä¸ºå…¨é¢ç†è§£å’Œå¼€å‘å¤§è¯­è¨€æ¨¡å‹æä¾›äº†é‡è¦çš„ç†è®ºæ´å¯Ÿä¸å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20387v1",
      "published_date": "2025-10-23 09:37:00 UTC",
      "updated_date": "2025-10-23 09:37:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:40.250947+00:00"
    },
    {
      "arxiv_id": "2510.20381v1",
      "title": "VLSP 2025 MLQA-TSR Challenge: Vietnamese Multimodal Legal Question Answering on Traffic Sign Regulation",
      "title_zh": "VLSP 2025 MLQA-TSR æŒ‘æˆ˜èµ›ï¼šé¢å‘è¶Šå—äº¤é€šæ ‡å¿—æ³•è§„çš„å¤šæ¨¡æ€æ³•å¾‹é—®ç­”",
      "authors": [
        "Son T. Luu",
        "Trung Vo",
        "Hiep Nguyen",
        "Khanh Quoc Tran",
        "Kiet Van Nguyen",
        "Vu Tran",
        "Ngan Luu-Thuy Nguyen",
        "Le-Minh Nguyen"
      ],
      "abstract": "This paper presents the VLSP 2025 MLQA-TSR - the multimodal legal question answering on traffic sign regulation shared task at VLSP 2025. VLSP 2025 MLQA-TSR comprises two subtasks: multimodal legal retrieval and multimodal question answering. The goal is to advance research on Vietnamese multimodal legal text processing and to provide a benchmark dataset for building and evaluating intelligent systems in multimodal legal domains, with a focus on traffic sign regulation in Vietnam. The best-reported results on VLSP 2025 MLQA-TSR are an F2 score of 64.55% for multimodal legal retrieval and an accuracy of 86.30% for multimodal question answering.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† VLSP 2025 MLQA-TSR å…±äº«ä»»åŠ¡ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºè¶Šå—äº¤é€šæ ‡å¿—æ³•è§„çš„å¤šæ¨¡æ€æ³•å¾‹é—®ç­”æŒ‘æˆ˜ã€‚è¯¥ä»»åŠ¡ä¸»è¦åŒ…å«å¤šæ¨¡æ€æ³•å¾‹æ£€ç´¢ (Multimodal Legal Retrieval) å’Œå¤šæ¨¡æ€é—®ç­” (Multimodal Question Answering) ä¸¤ä¸ªæ ¸å¿ƒå­ä»»åŠ¡ã€‚ç ”ç©¶çš„ä¸»è¦ç›®æ ‡æ˜¯æ¨åŠ¨è¶Šå—è¯­å¤šæ¨¡æ€æ³•å¾‹æ–‡æœ¬å¤„ç†é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥ï¼Œå¹¶ä¸ºæ³•å¾‹æ™ºèƒ½ç³»ç»Ÿçš„æ„å»ºå’Œè¯„ä¼°æä¾›ä¸“ä¸šçš„åŸºå‡†æ•°æ®é›† (Benchmark Dataset)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ä»»åŠ¡åœ¨å¤šæ¨¡æ€æ³•å¾‹æ£€ç´¢ä¸Šçš„æœ€ä½³ F2 å¾—åˆ†ä¸º 64.55%ï¼Œè€Œåœ¨å¤šæ¨¡æ€é—®ç­”ä¸Šçš„å‡†ç¡®ç‡è¾¾åˆ°äº† 86.30%ã€‚è¯¥ç ”ç©¶æˆæœä¸ºé’ˆå¯¹ç‰¹å®šé¢†åŸŸæ³•å¾‹æ–‡æœ¬çš„æ™ºèƒ½å¤„ç†å’Œå¤šæ¨¡æ€ç†è§£æŠ€æœ¯çš„å‘å±•æä¾›äº†é‡è¦çš„å‚è€ƒä¾æ®å’Œèµ„æºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "VLSP 2025 MLQA-TSR Share Task",
      "pdf_url": "https://arxiv.org/pdf/2510.20381v1",
      "published_date": "2025-10-23 09:24:43 UTC",
      "updated_date": "2025-10-23 09:24:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:51.556600+00:00"
    },
    {
      "arxiv_id": "2510.20377v1",
      "title": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation",
      "title_zh": "IKnowï¼šé¢å‘æœ‰æ•ˆé¢†åŸŸè‡ªé€‚åº”çš„æŒ‡ä»¤çŸ¥è¯†æ„ŸçŸ¥æŒç»­é¢„è®­ç»ƒ",
      "authors": [
        "Tianyi Zhang",
        "Florian Mai",
        "Lucie Flek"
      ],
      "abstract": "Continual pretraining promises to adapt large language models (LLMs) to new domains using only unlabeled test-time data, but naively applying standard self-supervised objectives to instruction-tuned models is known to degrade their instruction-following capability and semantic representations. Existing fixes assume access to the original base model or rely on knowledge from an external domain-specific database - both of which pose a realistic barrier in settings where the base model weights are withheld for safety reasons or reliable external corpora are unavailable. In this work, we propose Instruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general framework that formulates novel self-supervised objectives in the instruction-response dialogue format. Rather than depend- ing on external resources, IKnow leverages domain knowledge embedded within the text itself and learns to encode it at a deeper semantic level.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æŒç»­é¢„è®­ç»ƒï¼ˆContinual pretrainingï¼‰ä¸­å®¹æ˜“å‡ºç°æŒ‡ä»¤éµå¾ªèƒ½åŠ›é€€åŒ–å’Œè¯­ä¹‰è¡¨ç¤ºå—æŸçš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º IKnow çš„æŒ‡ä»¤-çŸ¥è¯†æ„ŸçŸ¥æŒç»­è‡ªé€‚åº”æ¡†æ¶ã€‚ç°æœ‰çš„é¢†åŸŸè‡ªé€‚åº”ï¼ˆDomain Adaptationï¼‰æ–¹æ³•é€šå¸¸ä¾èµ–åŸå§‹åŸºç¡€æ¨¡å‹æƒé‡æˆ–å¤–éƒ¨æ•°æ®åº“ï¼Œè€Œ IKnow å·§å¦™åœ°å°†è‡ªç›‘ç£ç›®æ ‡é‡æ„ä¸ºæŒ‡ä»¤-å“åº”å¯¹è¯ï¼ˆinstruction-response dialogueï¼‰æ ¼å¼ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºä¸ä¾èµ–ä»»ä½•å¤–éƒ¨èµ„æºï¼Œè€Œæ˜¯ç›´æ¥åˆ©ç”¨æ–‡æœ¬ä¸­åµŒå…¥çš„é¢†åŸŸçŸ¥è¯†ï¼Œå¹¶å¼•å¯¼æ¨¡å‹åœ¨æ›´æ·±å±‚çš„è¯­ä¹‰æ°´å¹³è¿›è¡Œç¼–ç ã€‚IKnow å±•ç°äº†ä¸€ç§ç®€å•ä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œæœ‰æ•ˆè§£å†³äº†å› æ¨¡å‹æƒé‡å—é™æˆ–ç¼ºä¹å¤–éƒ¨è¯­æ–™åº“è€Œå¸¦æ¥çš„å®é™…éšœç¢ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒæ¨¡å‹æŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„è¯­ä¹‰ç†è§£ä¸è‡ªé€‚åº”æ•ˆæœã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20377v1",
      "published_date": "2025-10-23 09:21:13 UTC",
      "updated_date": "2025-10-23 09:21:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:17:51.369898+00:00"
    },
    {
      "arxiv_id": "2510.20375v1",
      "title": "The Impact of Negated Text on Hallucination with Large Language Models",
      "title_zh": "å¦å®šæ–‡æœ¬å¯¹å¤§è¯­è¨€æ¨¡å‹å¹»è§‰çš„å½±å“",
      "authors": [
        "Jaehyung Seo",
        "Hyeonseok Moon",
        "Heuiseok Lim"
      ],
      "abstract": "Recent studies on hallucination in large language models (LLMs) have been actively progressing in natural language processing. However, the impact of negated text on hallucination with LLMs remains largely unexplored. In this paper, we set three important yet unanswered research questions and aim to address them. To derive the answers, we investigate whether LLMs can recognize contextual shifts caused by negation and still reliably distinguish hallucinations comparable to affirmative cases. We also design the NegHalu dataset by reconstructing existing hallucination detection datasets with negated expressions. Our experiments demonstrate that LLMs struggle to detect hallucinations in negated text effectively, often producing logically inconsistent or unfaithful judgments. Moreover, we trace the internal state of LLMs as they process negated inputs at the token level and reveal the challenges of mitigating their unintended effects.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¦å®šæ–‡æœ¬(negated text)å¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å¹»è§‰(hallucination)çš„å½±å“ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸåœ¨æ­¤å‰ç ”ç©¶ä¸­çš„ç©ºç™½ã€‚ç ”ç©¶äººå‘˜è°ƒæŸ¥äº†LLMsæ˜¯å¦èƒ½è¯†åˆ«ç”±å¦å®šå¼•èµ·çš„æƒ…å¢ƒè½¬å˜å¹¶åŒºåˆ†å¹»è§‰ï¼Œå¹¶ä»¥æ­¤è®¾è®¡äº†NegHaluæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ˜¯é€šè¿‡å¦å®šè¡¨è¾¾é‡æ„ç°æœ‰çš„å¹»è§‰æ£€æµ‹æ•°æ®è€Œæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨æœ‰æ•ˆæ£€æµ‹å¦å®šæ–‡æœ¬ä¸­çš„å¹»è§‰æ–¹é¢é¢ä¸´æ˜¾è‘—å›°éš¾ï¼Œç»å¸¸äº§ç”Ÿé€»è¾‘ä¸ä¸€è‡´æˆ–ä¸å¿ å®(unfaithful)çš„åˆ¤æ–­ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨æ ‡è®°(token)å±‚é¢è¿½è¸ªæ¨¡å‹å¤„ç†å¦å®šè¾“å…¥æ—¶çš„å†…éƒ¨çŠ¶æ€ï¼Œç ”ç©¶æ­ç¤ºäº†ç¼“è§£æ­¤ç±»æ„å¤–å½±å“çš„å¤æ‚æ€§ã€‚è¯¥è®ºæ–‡æå‡ºçš„å‘ç°å’Œæ•°æ®é›†ä¸ºè¿›ä¸€æ­¥ä¼˜åŒ–LLMsåœ¨å¤æ‚è¯­å¢ƒä¸‹çš„å¯é æ€§æä¾›äº†å…³é”®å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20375v1",
      "published_date": "2025-10-23 09:20:15 UTC",
      "updated_date": "2025-10-23 09:20:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:05.496033+00:00"
    },
    {
      "arxiv_id": "2510.21862v1",
      "title": "A Multi-Stage Hybrid Framework for Automated Interpretation of Multi-View Engineering Drawings Using Vision Language Model",
      "title_zh": "åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„å¤šè§†å›¾å·¥ç¨‹å›¾çº¸è‡ªåŠ¨åŒ–è§£æå¤šé˜¶æ®µæ··åˆæ¡†æ¶",
      "authors": [
        "Muhammad Tayyab Khan",
        "Zane Yong",
        "Lequn Chen",
        "Wenhe Feng",
        "Nicholas Yew Jin Tan",
        "Seung Ki Moon"
      ],
      "abstract": "Engineering drawings are fundamental to manufacturing communication, serving as the primary medium for conveying design intent, tolerances, and production details. However, interpreting complex multi-view drawings with dense annotations remains challenging using manual methods, generic optical character recognition (OCR) systems, or traditional deep learning approaches, due to varied layouts, orientations, and mixed symbolic-textual content. To address these challenges, this paper proposes a three-stage hybrid framework for the automated interpretation of 2D multi-view engineering drawings using modern detection and vision language models (VLMs). In the first stage, YOLOv11-det performs layout segmentation to localize key regions such as views, title blocks, and notes. The second stage uses YOLOv11-obb for orientation-aware, fine-grained detection of annotations, including measures, GD&T symbols, and surface roughness indicators. The third stage employs two Donut-based, OCR-free VLMs for semantic content parsing: the Alphabetical VLM extracts textual and categorical information from title blocks and notes, while the Numerical VLM interprets quantitative data such as measures, GD&T frames, and surface roughness. Two specialized datasets were developed to ensure robustness and generalization: 1,000 drawings for layout detection and 1,406 for annotation-level training. The Alphabetical VLM achieved an overall F1 score of 0.672, while the Numerical VLM reached 0.963, demonstrating strong performance in textual and quantitative interpretation, respectively. The unified JSON output enables seamless integration with CAD and manufacturing databases, providing a scalable solution for intelligent engineering drawing analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºè‡ªåŠ¨åŒ–è§£é‡Šå¤šè§†å›¾å·¥ç¨‹å›¾çº¸çš„å¤šé˜¶æ®µæ··åˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤æ‚å¸ƒå±€å’Œç¬¦å·æ–‡å­—æ··åˆå†…å®¹å¸¦æ¥çš„è§£ææŒ‘æˆ˜ã€‚æ¡†æ¶é¦–å…ˆåˆ©ç”¨ YOLOv11-det è¿›è¡Œå¸ƒå±€åˆ†å‰²ä»¥å®šä½å…³é”®åŒºåŸŸï¼Œéšåé€šè¿‡ YOLOv11-obb å®ç°å¯¹å°ºå¯¸ã€å‡ ä½•å…¬å·®(GD&T)åŠè¡¨é¢ç²—ç³™åº¦ç­‰æ ‡æ³¨çš„æ–¹å‘æ„ŸçŸ¥ç»†ç²’åº¦æ£€æµ‹ã€‚æ ¸å¿ƒè§£æé˜¶æ®µé‡‡ç”¨äº†ä¸¤ä¸ªåŸºäº Donut çš„å… OCR è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)ï¼Œåˆ†åˆ«é’ˆå¯¹æ–‡æœ¬åˆ†ç±»ä¿¡æ¯(Alphabetical VLM)å’Œå®šé‡æ•°å€¼æ•°æ®(Numerical VLM)è¿›è¡Œè¯­ä¹‰è§£æã€‚åŸºäºä¸“é—¨å¼€å‘çš„ä¸¤ä¸ªå¤§è§„æ¨¡æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­ Numerical VLM è¾¾åˆ°äº† 0.963 çš„ F1 åˆ†æ•°ï¼Œå±•ç°äº†æé«˜çš„å®šé‡è§£é‡Šå‡†ç¡®ç‡ã€‚è¯¥æ¡†æ¶ç”Ÿæˆçš„ç»Ÿä¸€ JSON è¾“å‡ºèƒ½å¤Ÿä¸ CAD åŠåˆ¶é€ æ•°æ®åº“æ— ç¼é›†æˆï¼Œä¸ºå·¥ä¸šé¢†åŸŸçš„æ™ºèƒ½åŒ–å›¾çº¸åˆ†ææä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "This draft has been submitted to the 13th International Conference on Industrial Engineering and Applications (ICIEA 2026)",
      "pdf_url": "https://arxiv.org/pdf/2510.21862v1",
      "published_date": "2025-10-23 09:07:31 UTC",
      "updated_date": "2025-10-23 09:07:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:07.964386+00:00"
    },
    {
      "arxiv_id": "2510.20351v1",
      "title": "Evaluating Latent Knowledge of Public Tabular Datasets in Large Language Models",
      "title_zh": "è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹å¯¹å…¬å¼€è¡¨æ ¼æ•°æ®é›†çš„æ½œåœ¨çŸ¥è¯†",
      "authors": [
        "Matteo Silvestri",
        "Flavio Giorgi",
        "Fabrizio Silvestri",
        "Gabriele Tolomei"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly evaluated on their ability to reason over structured data, yet such assessments often overlook a crucial confound: dataset contamination. In this work, we investigate whether LLMs exhibit prior knowledge of widely used tabular benchmarks such as Adult Income, Titanic, and others. Through a series of controlled probing experiments, we reveal that contamination effects emerge exclusively for datasets containing strong semantic cues-for instance, meaningful column names or interpretable value categories. In contrast, when such cues are removed or randomized, performance sharply declines to near-random levels. These findings suggest that LLMs' apparent competence on tabular reasoning tasks may, in part, reflect memorization of publicly available datasets rather than genuine generalization. We discuss implications for evaluation protocols and propose strategies to disentangle semantic leakage from authentic reasoning ability in future LLM assessments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)å¯¹ Adult Income å’Œ Titanic ç­‰å¸¸ç”¨è¡¨æ ¼åŸºå‡†æ•°æ®é›†æ˜¯å¦å­˜åœ¨å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶æ·±å…¥è°ƒæŸ¥äº†æ•°æ®é›†æ±¡æŸ“(dataset contamination)å¯¹æ¨ç†è¯„ä¼°çš„å½±å“ã€‚é€šè¿‡å—æ§æ¢æµ‹å®éªŒå‘ç°ï¼Œæ±¡æŸ“æ•ˆåº”ä»…åœ¨æ•°æ®é›†åŒ…å«å¼ºè¯­ä¹‰çº¿ç´¢ï¼ˆå¦‚å…·æœ‰å®é™…æ„ä¹‰çš„åˆ—åæˆ–å¯è§£é‡Šçš„å–å€¼ç±»åˆ«ï¼‰æ—¶æ˜¾ç°ã€‚å½“è¿™äº›çº¿ç´¢è¢«ç§»é™¤æˆ–éšæœºåŒ–åï¼Œæ¨¡å‹çš„æ€§èƒ½ä¼šéª¤é™è‡³æ¥è¿‘éšæœºæ°´å¹³ï¼Œè¡¨æ˜å…¶è¡¨è±¡èƒ½åŠ›å¯èƒ½æ›´å¤šæºäºå¯¹å…¬å¼€æ•°æ®çš„è®°å¿†(memorization)è€ŒéçœŸæ­£çš„æ³›åŒ–(generalization)ã€‚ç ”ç©¶ç»“æœæ­ç¤ºäº† LLMs åœ¨å¤„ç†ç»“æ„åŒ–æ•°æ®æ—¶å¯¹è¯­ä¹‰ä¿¡æ¯çš„ä¾èµ–ï¼Œå¹¶å¼ºè°ƒäº†å½“å‰è¯„ä¼°åè®®ä¸­æ½œåœ¨çš„åå·®ã€‚ä¸ºæ­¤ï¼Œè¯¥å·¥ä½œæå‡ºäº†æ—¨åœ¨åŒºåˆ†è¯­ä¹‰æ³„éœ²(semantic leakage)ä¸çœŸå®æ¨ç†èƒ½åŠ›çš„ç­–ç•¥ï¼Œä¸ºæ„å»ºæ›´ä¸¥è°¨çš„ LLM è¯„ä¼°ä½“ç³»æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20351v1",
      "published_date": "2025-10-23 08:51:14 UTC",
      "updated_date": "2025-10-23 08:51:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:12.257058+00:00"
    },
    {
      "arxiv_id": "2510.20350v2",
      "title": "What Do AI-Generated Images Want?",
      "title_zh": "AIç”Ÿæˆå›¾åƒæƒ³è¦ä»€ä¹ˆï¼Ÿ",
      "authors": [
        "Amanda Wasielewski"
      ],
      "abstract": "W.J.T. Mitchell's influential essay 'What do pictures want?' shifts the theoretical focus away from the interpretative act of understanding pictures and from the motivations of the humans who create them to the possibility that the picture itself is an entity with agency and wants. In this article, I reframe Mitchell's question in light of contemporary AI image generation tools to ask: what do AI-generated images want? Drawing from art historical discourse on the nature of abstraction, I argue that AI-generated images want specificity and concreteness because they are fundamentally abstract. Multimodal text-to-image models, which are the primary subject of this article, are based on the premise that text and image are interchangeable or exchangeable tokens and that there is a commensurability between them, at least as represented mathematically in data. The user pipeline that sees textual input become visual output, however, obscures this representational regress and makes it seem like one form transforms into the other -- as if by magic.",
      "tldr_zh": "è¯¥ç ”ç©¶å€Ÿé‰´äº† W.J.T. Mitchell çš„ç†è®ºè§†è§’ï¼Œå°†æ¢è®¨é‡ç‚¹ä»äººç±»åˆ›ä½œåŠ¨æœºè½¬å‘å›¾åƒæœ¬èº«çš„ä¸»ä½“æ€§ï¼Œæå‡ºäº†â€œAI ç”Ÿæˆçš„å›¾åƒæƒ³è¦ä»€ä¹ˆâ€è¿™ä¸€æ ¸å¿ƒå‘½é¢˜ã€‚é€šè¿‡å¯¹è‰ºæœ¯å²ä¸­æŠ½è±¡æœ¬è´¨çš„è®ºè¿°ï¼Œä½œè€…è®¤ä¸º AI ç”Ÿæˆçš„å›¾åƒç”±äºå…¶æ ¹æœ¬ä¸Šçš„ abstractionï¼ˆæŠ½è±¡æ€§ï¼‰ï¼Œåè€Œå±•ç°å‡ºå¯¹ specificityï¼ˆç‰¹å¼‚æ€§ï¼‰å’Œ concretenessï¼ˆå…·ä½“æ€§ï¼‰çš„æ¸´æ±‚ã€‚æ–‡ç« æ·±å…¥åˆ†æäº† multimodal text-to-image modelsï¼ˆå¤šæ¨¡æ€æ–‡æœ¬ç”Ÿæˆå›¾åƒæ¨¡å‹ï¼‰çš„åº•å±‚é€»è¾‘ï¼ŒæŒ‡å‡ºå…¶å»ºç«‹åœ¨æ–‡æœ¬ä¸å›¾åƒä½œä¸º tokensï¼ˆæ ‡è®°ï¼‰å¯ç›¸äº’äº¤æ¢ä¸”åœ¨æ•°å­¦è¡¨å¾ä¸Šå…·æœ‰ commensurabilityï¼ˆç­‰ä»·æ€§ï¼‰çš„å‡è®¾ä¹‹ä¸Šã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºï¼Œç°æœ‰çš„ç”¨æˆ·æ“ä½œæµç¨‹æ©ç›–äº†å…¶ä¸­çš„ representational regressï¼ˆè¡¨å¾å€’é€€ï¼‰ï¼Œä½¿å¤æ‚çš„è½¬æ¢è¿‡ç¨‹å‘ˆç°å‡ºä¸€ç§è™šå¹»çš„é­”åŠ›æ„Ÿã€‚é€šè¿‡è¿™ç§è·¨å­¦ç§‘çš„å®¡è§†ï¼Œè¯¥ç ”ç©¶ä¸ºç†è§£å½“ä»£ AI è§†è§‰æ–‡åŒ–çš„æœ¬è´¨åŠå›¾åƒçš„ agencyï¼ˆä¸»ä½“æ€§ï¼‰æä¾›äº†å…¨æ–°çš„ç†è®ºæ¡†æ¶ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20350v2",
      "published_date": "2025-10-23 08:48:47 UTC",
      "updated_date": "2025-10-24 09:41:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:12.548057+00:00"
    },
    {
      "arxiv_id": "2510.20345v1",
      "title": "LLM-empowered knowledge graph construction: A survey",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹èµ‹èƒ½çš„çŸ¥è¯†å›¾è°±æ„å»ºç»¼è¿°",
      "authors": [
        "Haonan Bian"
      ],
      "abstract": "Knowledge Graphs (KGs) have long served as a fundamental infrastructure for structured knowledge representation and reasoning. With the advent of Large Language Models (LLMs), the construction of KGs has entered a new paradigm-shifting from rule-based and statistical pipelines to language-driven and generative frameworks. This survey provides a comprehensive overview of recent progress in LLM-empowered knowledge graph construction, systematically analyzing how LLMs reshape the classical three-layered pipeline of ontology engineering, knowledge extraction, and knowledge fusion.\n  We first revisit traditional KG methodologies to establish conceptual foundations, and then review emerging LLM-driven approaches from two complementary perspectives: schema-based paradigms, which emphasize structure, normalization, and consistency; and schema-free paradigms, which highlight flexibility, adaptability, and open discovery. Across each stage, we synthesize representative frameworks, analyze their technical mechanisms, and identify their limitations.\n  Finally, the survey outlines key trends and future research directions, including KG-based reasoning for LLMs, dynamic knowledge memory for agentic systems, and multimodal KG construction. Through this systematic review, we aim to clarify the evolving interplay between LLMs and knowledge graphs, bridging symbolic knowledge engineering and neural semantic understanding toward the development of adaptive, explainable, and intelligent knowledge systems.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿæ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)èµ‹èƒ½çŸ¥è¯†å›¾è°±(KGs)æ„å»ºçš„æœ€æ–°è¿›å±•ï¼ŒæŒ‡å‡ºå…¶å·²ä»ä¼ ç»Ÿçš„è§„åˆ™å’Œç»Ÿè®¡æ–¹æ³•è½¬å‘ç”±è¯­è¨€é©±åŠ¨çš„ç”Ÿæˆå¼èŒƒå‹ã€‚ç ”ç©¶æ·±å…¥åˆ†æäº†LLMså¦‚ä½•é‡å¡‘åŒ…æ‹¬æœ¬ä½“å·¥ç¨‹(Ontology Engineering)ã€çŸ¥è¯†æŠ½å–(Knowledge Extraction)ä»¥åŠçŸ¥è¯†èåˆ(Knowledge Fusion)åœ¨å†…çš„ç»å…¸ä¸‰å±‚æ„å»ºæµç¨‹ã€‚è¯¥æ–‡ä»å¼ºè°ƒç»“æ„ä¸€è‡´æ€§çš„åŸºäºæ¨¡å¼(Schema-based)èŒƒå¼å’Œå¼ºè°ƒçµæ´»æ€§ä¸å¼€æ”¾å‘ç°çš„æ— æ¨¡å¼(Schema-free)èŒƒå¼ä¸¤ä¸ªäº’è¡¥è§†è§’ï¼Œå¯¹ç°æœ‰æŠ€æœ¯æ¡†æ¶è¿›è¡Œäº†ç³»ç»Ÿå½’çº³ä¸æŠ€æœ¯æœºåˆ¶åˆ†æã€‚æ–‡ç« è¿˜è¯†åˆ«äº†å½“å‰LLMé©±åŠ¨æ„å»ºæ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶å±•æœ›äº†é¢å‘LLMsçš„çŸ¥è¯†å›¾è°±æ¨ç†ã€æ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„åŠ¨æ€çŸ¥è¯†å­˜å‚¨ä»¥åŠå¤šæ¨¡æ€çŸ¥è¯†å›¾è°±æ„å»ºç­‰æœªæ¥æ–¹å‘ã€‚é€šè¿‡å¯¹ç¬¦å·çŸ¥è¯†å·¥ç¨‹ä¸ç¥ç»è¯­ä¹‰ç†è§£èåˆçš„æ¢è®¨ï¼Œè¯¥ç»¼è¿°ä¸ºå¼€å‘æ›´å…·é€‚åº”æ€§å’Œå¯è§£é‡Šæ€§çš„æ™ºèƒ½çŸ¥è¯†ç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20345v1",
      "published_date": "2025-10-23 08:43:28 UTC",
      "updated_date": "2025-10-23 08:43:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:16.345246+00:00"
    },
    {
      "arxiv_id": "2510.20342v1",
      "title": "Teaching Language Models to Reason with Tools",
      "title_zh": "æ•™ä¼šè¯­è¨€æ¨¡å‹åˆ©ç”¨å·¥å…·è¿›è¡Œæ¨ç†",
      "authors": [
        "Chengpeng Li",
        "Zhengyang Tang",
        "Ziniu Li",
        "Mingfeng Xue",
        "Keqin Bao",
        "Tian Ding",
        "Ruoyu Sun",
        "Benyou Wang",
        "Xiang Wang",
        "Junyang Lin",
        "Dayiheng Liu"
      ],
      "abstract": "Large reasoning models (LRMs) like OpenAI-o1 have shown impressive capabilities in natural language reasoning. However, these models frequently demonstrate inefficiencies or inaccuracies when tackling complex mathematical operations. While integrating computational tools such as Code Interpreters (CIs) offers a promising solution, it introduces a critical challenge: a conflict between the model's internal, probabilistic reasoning and the external, deterministic knowledge provided by the CI, which often leads models to unproductive deliberation. To overcome this, we introduce CoRT (Code-Optimized Reasoning Training), a post-training framework designed to teach LRMs to effectively utilize CIs. We propose \\emph{Hint-Engineering}, a new data synthesis strategy that strategically injects diverse hints at optimal points within reasoning paths. This approach generates high-quality, code-integrated reasoning data specifically tailored to optimize LRM-CI interaction. Using this method, we have synthesized 30 high-quality samples to post-train models ranging from 1.5B to 32B parameters through supervised fine-tuning. CoRT further refines the multi-round interleaving of external CI usage and internal thinking by employing rejection sampling and reinforcement learning. Our experimental evaluations demonstrate CoRT's effectiveness, yielding absolute improvements of 4\\% and 8\\% on DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Qwen-1.5B, respectively, across five challenging mathematical reasoning datasets. Moreover, CoRT significantly enhances efficiency, reducing token usage by approximately 30\\% for the 32B model and 50\\% for the 1.5B model compared to pure natural language reasoning baselines. The models and code are available at: https://github.com/ChengpengLi1003/CoRT.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹æ¨ç†æ¨¡å‹(LRMs)åœ¨å¤„ç†å¤æ‚æ•°å­¦è¿ç®—æ—¶å­˜åœ¨çš„ä½æ•ˆå’Œä¸å‡†ç¡®é—®é¢˜ï¼Œæå‡ºäº†CoRT (Code-Optimized Reasoning Training) è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨æ•™å¯¼æ¨¡å‹æœ‰æ•ˆåˆ©ç”¨ä»£ç è§£é‡Šå™¨(Code Interpreters, CIs)ã€‚é’ˆå¯¹æ¨¡å‹å†…éƒ¨æ¦‚ç‡æ¨ç†ä¸CIå¤–éƒ¨ç¡®å®šæ€§çŸ¥è¯†ä¹‹é—´çš„å†²çªï¼ŒCoRTå¼•å…¥äº†ä¸€ç§åä¸ºHint-Engineeringçš„æ•°æ®åˆæˆç­–ç•¥ï¼Œé€šè¿‡åœ¨æ¨ç†è·¯å¾„ä¸­æˆ˜ç•¥æ€§åœ°æ³¨å…¥æç¤ºæ¥ä¼˜åŒ–LRMä¸CIçš„äº¤äº’ã€‚è¯¥æ¡†æ¶åˆ©ç”¨åˆæˆçš„é«˜è´¨é‡æ•°æ®å¯¹ä¸åŒè§„æ¨¡çš„æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning)ï¼Œå¹¶ç»“åˆæ‹’ç»é‡‡æ ·(Rejection Sampling)å’Œå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¼˜åŒ–å¤šè½®äº¤æ›¿æ¨ç†è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼ŒCoRTåœ¨äº”ä¸ªæ•°å­¦æ¨ç†æ•°æ®é›†ä¸Šä½¿DeepSeek-R1-Distill-Qwen-32Bå’Œ1.5Bæ¨¡å‹çš„å‡†ç¡®ç‡åˆ†åˆ«æå‡äº†4%å’Œ8%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†æ¨ç†æ•ˆç‡ï¼Œå°†32Bå’Œ1.5Bæ¨¡å‹çš„Tokenä½¿ç”¨é‡åˆ†åˆ«å‡å°‘äº†çº¦30%å’Œ50%ã€‚è¿™ä¸€ç ”ç©¶ä¸ºLRMsåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­é«˜æ•ˆé›†æˆå¤–éƒ¨å·¥å…·æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NIPS2025 Accepted",
      "pdf_url": "https://arxiv.org/pdf/2510.20342v1",
      "published_date": "2025-10-23 08:41:44 UTC",
      "updated_date": "2025-10-23 08:41:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:20.154933+00:00"
    },
    {
      "arxiv_id": "2510.20339v1",
      "title": "Multi-Task Deep Learning for Surface Metrology",
      "title_zh": "é¢å‘è¡¨é¢è®¡é‡å­¦çš„å¤šä»»åŠ¡æ·±åº¦å­¦ä¹ ",
      "authors": [
        "D. Kucharski",
        "A. Gaska",
        "T. Kowaluk",
        "K. Stepien",
        "M. Repalska",
        "B. Gapinski",
        "M. Wieczorowski",
        "M. Nawotka",
        "P. Sobecki",
        "P. Sosinowski",
        "J. Tomasik",
        "A. Wojtowicz"
      ],
      "abstract": "A reproducible deep learning framework is presented for surface metrology to predict surface texture parameters together with their reported standard uncertainties. Using a multi-instrument dataset spanning tactile and optical systems, measurement system type classification is addressed alongside coordinated regression of Ra, Rz, RONt and their uncertainty targets (Ra_uncert, Rz_uncert, RONt_uncert). Uncertainty is modelled via quantile and heteroscedastic heads with post-hoc conformal calibration to yield calibrated intervals. On a held-out set, high fidelity was achieved by single-target regressors (R2: Ra 0.9824, Rz 0.9847, RONt 0.9918), with two uncertainty targets also well modelled (Ra_uncert 0.9899, Rz_uncert 0.9955); RONt_uncert remained difficult (R2 0.4934). The classifier reached 92.85% accuracy and probability calibration was essentially unchanged after temperature scaling (ECE 0.00504 -> 0.00503 on the test split). Negative transfer was observed for naive multi-output trunks, with single-target models performing better. These results provide calibrated predictions suitable to inform instrument selection and acceptance decisions in metrological workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç”¨äºè¡¨é¢è®¡é‡å­¦(Surface Metrology)çš„å¯é‡å¤æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨åŒæ—¶é¢„æµ‹è¡¨é¢çº¹ç†å‚æ•°åŠå…¶æ ‡å‡†ä¸ç¡®å®šåº¦ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ¶µç›–æ¥è§¦å¼å’Œå…‰å­¦ç³»ç»Ÿçš„å¤šä»ªå™¨æ•°æ®é›†ï¼Œå®ç°äº†æµ‹é‡ç³»ç»Ÿç±»å‹çš„åˆ†ç±»ï¼Œå¹¶å¯¹ Raã€Rzã€RONt åŠå…¶ä¸ç¡®å®šåº¦ç›®æ ‡è¿›è¡Œäº†ååŒå›å½’åˆ†æã€‚ç ”ç©¶é€šè¿‡åˆ†ä½æ•°(Quantile)å’Œå¼‚æ–¹å·®(Heteroscedastic)å¤´éƒ¨å¯¹ä¸ç¡®å®šåº¦è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ç»“åˆäº‹åä¿å½¢æ ¡å‡†(Post-hoc Conformal Calibration)ä»¥äº§ç”Ÿæ ¡å‡†åŒºé—´ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå•ç›®æ ‡å›å½’æ¨¡å‹åœ¨é¢„æµ‹å‚æ•°å€¼æ—¶è¡¨ç°å‡ºæé«˜çš„ä¿çœŸåº¦ï¼Œä¸”å¤§éƒ¨åˆ†ä¸ç¡®å®šåº¦ç›®æ ‡ä¹Ÿå¾—åˆ°äº†è‰¯å¥½å»ºæ¨¡ã€‚å°½ç®¡åœ¨å¤šè¾“å‡ºä»»åŠ¡ä¸­è§‚å¯Ÿåˆ°äº†è´Ÿè¿ç§»(Negative Transfer)ç°è±¡ï¼Œä½†åˆ†ç±»å™¨çš„å‡†ç¡®ç‡ä¾ç„¶è¾¾åˆ°äº† 92.85%ã€‚è¯¥ç ”ç©¶æä¾›çš„æ ¡å‡†é¢„æµ‹èƒ½å¤Ÿä¸ºè®¡é‡å·¥ä½œæµç¨‹ä¸­çš„ä»ªå™¨é€‰æ‹©å’ŒéªŒæ”¶å†³ç­–æä¾›ç§‘å­¦ä¾æ®ã€‚",
      "categories": [
        "physics.app-ph",
        "cs.AI",
        "cs.LG",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "physics.app-ph",
      "comment": "34 pages, 10 figures, 6 tables; 60-page supplementary appendix. Code and full reproducibility bundle available via Zenodo",
      "pdf_url": "https://arxiv.org/pdf/2510.20339v1",
      "published_date": "2025-10-23 08:38:18 UTC",
      "updated_date": "2025-10-23 08:38:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:23.363626+00:00"
    },
    {
      "arxiv_id": "2510.20337v1",
      "title": "Collateral Damage Assessment Model for AI System Target Engagement in Military Operations",
      "title_zh": "å†›äº‹è¡ŒåŠ¨ä¸­äººå·¥æ™ºèƒ½ç³»ç»Ÿç›®æ ‡äº¤æˆ˜çš„é™„å¸¦æŸä¼¤è¯„ä¼°æ¨¡å‹",
      "authors": [
        "Clara Maathuis",
        "Kasper Cools"
      ],
      "abstract": "In an era where AI (Artificial Intelligence) systems play an increasing role in the battlefield, ensuring responsible targeting demands rigorous assessment of potential collateral effects. In this context, a novel collateral damage assessment model for target engagement of AI systems in military operations is introduced. The model integrates temporal, spatial, and force dimensions within a unified Knowledge Representation and Reasoning (KRR) architecture following a design science methodological approach. Its layered structure captures the categories and architectural components of the AI systems to be engaged together with corresponding engaging vectors and contextual aspects. At the same time, spreading, severity, likelihood, and evaluation metrics are considered in order to provide a clear representation enhanced by transparent reasoning mechanisms. Further, the model is demonstrated and evaluated through instantiation which serves as a basis for further dedicated efforts that aim at building responsible and trustworthy intelligent systems for assessing the effects produced by engaging AI systems in military operations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½(AI)ç³»ç»Ÿåœ¨æˆ˜åœºä¸­æ—¥ç›Šå¢é•¿çš„ä½œç”¨ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºå†›äº‹è¡ŒåŠ¨ä¸­AIç³»ç»Ÿç›®æ ‡äº¤æˆ˜çš„æ–°å‹é™„å¸¦æŸä¼¤è¯„ä¼°æ¨¡å‹ï¼Œæ—¨åœ¨ç¡®ä¿è´Ÿè´£ä»»çš„æ‰“å‡»è¡ŒåŠ¨ã€‚è¯¥æ¨¡å‹éµå¾ªè®¾è®¡ç§‘å­¦(design science)æ–¹æ³•è®ºï¼Œåœ¨ç»Ÿä¸€çš„çŸ¥è¯†è¡¨ç¤ºä¸æ¨ç†(KRR)æ¶æ„ä¸­é›†æˆäº†æ—¶é—´ã€ç©ºé—´å’ŒåŠ›é‡ä¸‰ä¸ªç»´åº¦ã€‚å…¶åˆ†å±‚ç»“æ„è¯¦ç»†åˆ»ç”»äº†äº¤æˆ˜AIç³»ç»Ÿçš„ç±»åˆ«ã€æ¶æ„ç»„ä»¶ã€äº¤æˆ˜å‘é‡åŠä¸Šä¸‹æ–‡å› ç´ ï¼Œå¹¶ç»“åˆäº†æ‰©æ•£æ€§ã€ä¸¥é‡æ€§ã€å¯èƒ½æ€§å’Œè¯„ä¼°æŒ‡æ ‡æ¥æä¾›æ¸…æ™°çš„æŸå®³è¡¨è¿°ã€‚è¯¥æ¨¡å‹é€šè¿‡é€æ˜çš„æ¨ç†æœºåˆ¶å¢å¼ºäº†è¯„ä¼°çš„å¯é æ€§ï¼Œå¹¶é€šè¿‡å®ä¾‹æ¼”ç¤ºéªŒè¯äº†å…¶åœ¨å¤æ‚å†›äº‹ç¯å¢ƒä¸‹çš„åº”ç”¨æ½œåŠ›ã€‚è¿™ä¸€æˆæœä¸ºå¼€å‘è´Ÿè´£ä»»ä¸”å¯ä¿¡çš„æ™ºèƒ½åŒ–ç³»ç»Ÿæä¾›äº†ç†è®ºæ”¯æ’‘ï¼Œæœ‰åŠ©äºæ›´ç²¾å‡†åœ°è¯„ä¼°å†›äº‹è¡ŒåŠ¨ä¸­AIäº¤æˆ˜æ‰€äº§ç”Ÿçš„æ•ˆåº”ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at MILCOM 2025 WS07",
      "pdf_url": "https://arxiv.org/pdf/2510.20337v1",
      "published_date": "2025-10-23 08:36:04 UTC",
      "updated_date": "2025-10-23 08:36:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:22.851075+00:00"
    },
    {
      "arxiv_id": "2510.20333v2",
      "title": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?",
      "title_zh": "GhostEI-Benchï¼šç§»åŠ¨æ™ºèƒ½ä½“åœ¨åŠ¨æ€è®¾å¤‡ç«¯ç¯å¢ƒä¸‹å¯¹ç¯å¢ƒæ³¨å…¥å…·å¤‡éŸ§æ€§å—ï¼Ÿ",
      "authors": [
        "Chiyu Chen",
        "Xinhao Song",
        "Yunkai Chai",
        "Yang Yao",
        "Haodong Zhao",
        "Lijun Li",
        "Jie Li",
        "Yan Teng",
        "Gongshen Liu",
        "Yingchun Wang"
      ],
      "abstract": "Vision-Language Models (VLMs) are increasingly deployed as autonomous agents to navigate mobile graphical user interfaces (GUIs). Operating in dynamic on-device ecosystems, which include notifications, pop-ups, and inter-app interactions, exposes them to a unique and underexplored threat vector: environmental injection. Unlike prompt-based attacks that manipulate textual instructions, environmental injection corrupts an agent's visual perception by inserting adversarial UI elements (for example, deceptive overlays or spoofed notifications) directly into the GUI. This bypasses textual safeguards and can derail execution, causing privacy leakage, financial loss, or irreversible device compromise. To systematically evaluate this threat, we introduce GhostEI-Bench, the first benchmark for assessing mobile agents under environmental injection attacks within dynamic, executable environments. Moving beyond static image-based assessments, GhostEI-Bench injects adversarial events into realistic application workflows inside fully operational Android emulators and evaluates performance across critical risk scenarios. We further propose a judge-LLM protocol that conducts fine-grained failure analysis by reviewing the agent's action trajectory alongside the corresponding screenshot sequence, pinpointing failure in perception, recognition, or reasoning. Comprehensive experiments on state-of-the-art agents reveal pronounced vulnerability to deceptive environmental cues: current models systematically fail to perceive and reason about manipulated UIs. GhostEI-Bench provides a framework for quantifying and mitigating this emerging threat, paving the way toward more robust and secure embodied agents.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)ä½œä¸ºç§»åŠ¨æ™ºèƒ½ä½“åœ¨å¤„ç†åŠ¨æ€è®¾å¤‡ç¯å¢ƒæ—¶é¢ä¸´çš„Environmental Injectionå¨èƒã€‚ä¸ä¼ ç»Ÿçš„æŒ‡ä»¤ç¯¡æ”¹æ”»å‡»ä¸åŒï¼ŒEnvironmental Injectioné€šè¿‡åœ¨GUIä¸­æ’å…¥ä¼ªé€ é€šçŸ¥æˆ–æ¶æ„è¦†ç›–å±‚æ¥ç ´åæ™ºèƒ½ä½“çš„è§†è§‰æ„ŸçŸ¥ï¼Œå¯èƒ½å¯¼è‡´éšç§æ³„éœ²æˆ–è®¾å¤‡æƒé™è¢«æ»¥ç”¨ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº†GhostEI-Benchï¼Œè¿™æ˜¯é¦–ä¸ªåœ¨çœŸå®Androidæ¨¡æ‹Ÿå™¨å†…è¯„ä¼°æ­¤ç±»æ”»å‡»çš„åŠ¨æ€åŸºå‡†æµ‹è¯•æ¡†æ¶ï¼Œèƒ½å¤Ÿæ•æ‰å¤æ‚çš„å·¥ä½œæµäº¤äº’ã€‚ç ”ç©¶è¿˜æå‡ºäº†judge-LLMåè®®ï¼Œé€šè¿‡åˆ†ææ™ºèƒ½ä½“çš„åŠ¨ä½œè½¨è¿¹å’Œæˆªå›¾åºåˆ—æ¥ç²¾ç¡®å®šä½æ„ŸçŸ¥ã€è¯†åˆ«æˆ–æ¨ç†é˜¶æ®µçš„æ•…éšœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰æœ€å…ˆè¿›çš„æ™ºèƒ½ä½“åœ¨æ¬ºéª—æ€§ç¯å¢ƒçº¿ç´¢é¢å‰æå…¶è„†å¼±ï¼Œæ™®éæ— æ³•æ­£ç¡®è§£æè¢«æ“çºµçš„UIã€‚GhostEI-Benchä¸ºé‡åŒ–å’Œå¢å¼ºå…·èº«æ™ºèƒ½ä½“(Embodied Agents)çš„å®‰å…¨æ€§ä¸éŸ§æ€§æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20333v2",
      "published_date": "2025-10-23 08:33:24 UTC",
      "updated_date": "2025-11-21 07:38:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:28.361697+00:00"
    },
    {
      "arxiv_id": "2510.20332v1",
      "title": "Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems",
      "title_zh": "è®¾è®¡æ€§åè§ï¼Ÿæ•°æ®å®è·µå¦‚ä½•å¡‘é€  AI åŒ»ç–—ç³»ç»Ÿçš„å…¬å¹³æ€§",
      "authors": [
        "Anna Arias-Duart",
        "Maria Eugenia Cardello",
        "Atia CortÃ©s"
      ],
      "abstract": "Artificial intelligence (AI) holds great promise for transforming healthcare. However, despite significant advances, the integration of AI solutions into real-world clinical practice remains limited. A major barrier is the quality and fairness of training data, which is often compromised by biased data collection practices. This paper draws on insights from the AI4HealthyAging project, part of Spain's national R&D initiative, where our task was to detect biases during clinical data collection. We identify several types of bias across multiple use cases, including historical, representation, and measurement biases. These biases manifest in variables such as sex, gender, age, habitat, socioeconomic status, equipment, and labeling. We conclude with practical recommendations for improving the fairness and robustness of clinical problem design and data collection. We hope that our findings and experience contribute to guiding future projects in the development of fairer AI systems in healthcare.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ•°æ®å®è·µå¦‚ä½•å½±å“åŒ»ç–—äººå·¥æ™ºèƒ½(AI)ç³»ç»Ÿçš„å…¬å¹³æ€§ï¼ŒæŒ‡å‡ºåè§çš„æ•°æ®æ”¶é›†å®è·µæ˜¯AIè¿›å…¥ä¸´åºŠåº”ç”¨çš„ä¸»è¦éšœç¢ã€‚è®ºæ–‡åŸºäºè¥¿ç­ç‰™å›½å®¶ç ”å‘è®¡åˆ’ä¸­çš„ AI4HealthyAging é¡¹ç›®ï¼Œæ·±å…¥åˆ†æäº†ä¸´åºŠæ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­çš„åè§æ£€æµ‹ä»»åŠ¡ã€‚ç ”ç©¶è¯†åˆ«äº†å¤šç§å…³é”®çš„åè§ç±»å‹ï¼ŒåŒ…æ‹¬å†å²åè§(historical bias)ã€è¡¨å¾åè§(representation bias)å’Œæµ‹é‡åè§(measurement bias)ï¼Œè¿™äº›åè§å¹¿æ³›å­˜åœ¨äºæ€§åˆ«(sex/gender)ã€å¹´é¾„(age)ã€å±…ä½åœ°(habitat)ã€ç¤¾ä¼šç»æµåœ°ä½(socioeconomic status)ä»¥åŠè®¾å¤‡å’Œæ ‡æ³¨(labeling)ç­‰å˜é‡ä¸­ã€‚ä½œè€…é’ˆå¯¹ä¸´åºŠé—®é¢˜è®¾è®¡å’Œæ•°æ®æ”¶é›†ç¯èŠ‚æå‡ºäº†æå‡å…¬å¹³æ€§ä¸é²æ£’æ€§çš„å®ç”¨å»ºè®®ã€‚è¯¥æˆæœä¸ºæœªæ¥å¼€å‘æ›´å…¬æ­£ã€æ›´å…·å¯ä¿¡åº¦çš„åŒ»ç–—äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é‡è¦çš„å®è·µæŒ‡å—å’Œç»éªŒå‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 3 tables, accepted in AEQUITAS 2025 (not in proceedings)",
      "pdf_url": "https://arxiv.org/pdf/2510.20332v1",
      "published_date": "2025-10-23 08:32:34 UTC",
      "updated_date": "2025-10-23 08:32:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:29.861147+00:00"
    },
    {
      "arxiv_id": "2510.20328v1",
      "title": "MemER: Scaling Up Memory for Robot Control via Experience Retrieval",
      "title_zh": "MemERï¼šåŸºäºç»éªŒæ£€ç´¢çš„æœºå™¨äººæ§åˆ¶è®°å¿†æ‰©å±•",
      "authors": [
        "Ajay Sridhar",
        "Jennifer Pan",
        "Satvik Sharma",
        "Chelsea Finn"
      ],
      "abstract": "Humans routinely rely on memory to perform tasks, yet most robot policies lack this capability; our goal is to endow robot policies with the same ability. Naively conditioning on long observation histories is computationally expensive and brittle under covariate shift, while indiscriminate subsampling of history leads to irrelevant or redundant information. We propose a hierarchical policy framework, where the high-level policy is trained to select and track previous relevant keyframes from its experience. The high-level policy uses selected keyframes and the most recent frames when generating text instructions for a low-level policy to execute. This design is compatible with existing vision-language-action (VLA) models and enables the system to efficiently reason over long-horizon dependencies. In our experiments, we finetune Qwen2.5-VL-7B-Instruct and $Ï€_{0.5}$ as the high-level and low-level policies respectively, using demonstrations supplemented with minimal language annotations. Our approach, MemER, outperforms prior methods on three real-world long-horizon robotic manipulation tasks that require minutes of memory. Videos and code can be found at https://jen-pan.github.io/memer/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MemERï¼Œä¸€ç§é€šè¿‡ç»éªŒæ£€ç´¢(Experience Retrieval)æ‰©å±•æœºå™¨äººæ§åˆ¶å†…å­˜çš„å±‚æ¬¡åŒ–ç­–ç•¥æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æœºå™¨äººç­–ç•¥åœ¨å¤„ç†é•¿è§‚å¯Ÿåºåˆ—æ—¶è®¡ç®—å¼€é”€å¤§ä¸”åœ¨åå˜é‡åç§»(covariate shift)ä¸‹è¡¨ç°è„†å¼±çš„é—®é¢˜ã€‚MemER è®­ç»ƒé«˜å±‚ç­–ç•¥ä»å†å²ç»éªŒä¸­é€‰æ‹©å¹¶è·Ÿè¸ªç›¸å…³çš„å…³é”®å¸§(keyframes)ï¼Œå¹¶ç»“åˆæœ€æ–°å¸§ä¿¡æ¯ç”Ÿæˆæ–‡æœ¬æŒ‡ä»¤ä»¥æŒ‡å¯¼åº•å±‚ç­–ç•¥æ‰§è¡Œã€‚è¯¥æ¡†æ¶ä¸ç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹å…¼å®¹ï¼Œé€šè¿‡å¾®è°ƒ Qwen2.5-VL-7B-Instruct å’Œ $\\pi_{0.5}$ å®ç°äº†å¯¹é•¿æ—¶ç¨‹ä¾èµ–(long-horizon dependencies)çš„é«˜æ•ˆæ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMemER åœ¨ä¸‰é¡¹éœ€è¦æ•°åˆ†é’Ÿè®°å¿†çš„çœŸå®ä¸–ç•Œæœºå™¨äººæ“çºµä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†æœºå™¨äººåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æ‰§è¡Œèƒ½åŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project page: https://jen-pan.github.io/memer/",
      "pdf_url": "https://arxiv.org/pdf/2510.20328v1",
      "published_date": "2025-10-23 08:26:17 UTC",
      "updated_date": "2025-10-23 08:26:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:51.246848+00:00"
    },
    {
      "arxiv_id": "2510.20327v1",
      "title": "LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems",
      "title_zh": "LEGOï¼šé¢å‘æ¨èç³»ç»Ÿçš„è½»é‡çº§é«˜æ•ˆå¤šå±æ€§é—å¿˜æ¡†æ¶",
      "authors": [
        "Fengyuan Yu",
        "Yuyuan Li",
        "Xiaohua Feng",
        "Junjie Fang",
        "Tao Wang",
        "Chaochao Chen"
      ],
      "abstract": "With the growing demand for safeguarding sensitive user information in recommender systems, recommendation attribute unlearning is receiving increasing attention. Existing studies predominantly focus on single-attribute unlearning. However, privacy protection requirements in the real world often involve multiple sensitive attributes and are dynamic. Existing single-attribute unlearning methods cannot meet these real-world requirements due to i) CH1: the inability to handle multiple unlearning requests simultaneously, and ii) CH2: the lack of efficient adaptability to dynamic unlearning needs. To address these challenges, we propose LEGO, a lightweight and efficient multiple-attribute unlearning framework. Specifically, we divide the multiple-attribute unlearning process into two steps: i) Embedding Calibration removes information related to a specific attribute from user embedding, and ii) Flexible Combination combines these embeddings into a single embedding, protecting all sensitive attributes. We frame the unlearning process as a mutual information minimization problem, providing LEGO a theoretical guarantee of simultaneous unlearning, thereby addressing CH1. With the two-step framework, where Embedding Calibration can be performed in parallel and Flexible Combination is flexible and efficient, we address CH2. Extensive experiments on three real-world datasets across three representative recommendation models demonstrate the effectiveness and efficiency of our proposed framework. Our code and appendix are available at https://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LEGOï¼Œä¸€ç§è½»é‡çº§ä¸”é«˜æ•ˆçš„å¤šå±æ€§å–æ¶ˆå­¦ä¹ (Multiple-Attribute Unlearning)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ¨èç³»ç»Ÿä¸­åŠ¨æ€ä¸”å¤šæ ·åŒ–çš„ç”¨æˆ·éšç§ä¿æŠ¤éœ€æ±‚ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•æ— æ³•åŒæ—¶å¤„ç†å¤šä¸ªå–æ¶ˆå­¦ä¹ è¯·æ±‚(CH1)ä»¥åŠå¯¹åŠ¨æ€éœ€æ±‚é€‚åº”æ€§ä¸è¶³(CH2)çš„æŒ‘æˆ˜ï¼ŒLEGOå°†å–æ¶ˆå­¦ä¹ è¿‡ç¨‹åˆ†ä¸ºåµŒå…¥æ ¡å‡†(Embedding Calibration)å’ŒæŸ”æ€§ç»„åˆ(Flexible Combination)ä¸¤ä¸ªæ ¸å¿ƒæ­¥éª¤ã€‚é¦–å…ˆï¼ŒåµŒå…¥æ ¡å‡†ä»ç”¨æˆ·åµŒå…¥ä¸­ç²¾å‡†ç§»é™¤ç‰¹å®šå±æ€§çš„ç›¸å…³ä¿¡æ¯ï¼Œéšåé€šè¿‡æŸ”æ€§ç»„åˆå°†æ ¡å‡†åçš„åµŒå…¥æ•´åˆï¼Œå®ç°å¯¹æ‰€æœ‰æ•æ„Ÿå±æ€§çš„å…¨é¢ä¿æŠ¤ã€‚ç ”ç©¶å°†æ­¤è¿‡ç¨‹å»ºæ¨¡ä¸ºäº’ä¿¡æ¯æœ€å°åŒ–(Mutual Information Minimization)é—®é¢˜ï¼Œä¸ºå¤šå±æ€§åŒæ—¶å–æ¶ˆå­¦ä¹ æä¾›äº†ç†è®ºä¿éšœã€‚ç”±äºå…¶æ ¡å‡†æ­¥éª¤æ”¯æŒå¹¶è¡Œå¤„ç†ä¸”ç»„åˆæ–¹å¼çµæ´»ï¼ŒLEGOæœ‰æ•ˆæå‡äº†åœ¨åŠ¨æ€ç¯å¢ƒä¸‹çš„å¤„ç†æ•ˆç‡ã€‚åœ¨ä¸‰ä¸ªçœŸå®æ•°æ®é›†å’Œä¸‰ç§ä»£è¡¨æ€§æ¨èæ¨¡å‹ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä¿éšœéšç§çš„åŒæ—¶ï¼Œå…¼å…·æ˜¾è‘—çš„æœ‰æ•ˆæ€§ä¸é«˜æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ACM Multimedia 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20327v1",
      "published_date": "2025-10-23 08:20:47 UTC",
      "updated_date": "2025-10-23 08:20:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:43.749307+00:00"
    },
    {
      "arxiv_id": "2510.20314v1",
      "title": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses",
      "title_zh": "æå‡æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å®‰å…¨æ€§ï¼šå¯¹æŠ—æ”»å‡»ä¸é˜²å¾¡ç»¼è¿°",
      "authors": [
        "Wu Yichao",
        "Wang Yirui",
        "Ding Panpan",
        "Wang Hailong",
        "Zhu Bingqian",
        "Liu Chun"
      ],
      "abstract": "With the wide application of deep reinforcement learning (DRL) techniques in complex fields such as autonomous driving, intelligent manufacturing, and smart healthcare, how to improve its security and robustness in dynamic and changeable environments has become a core issue in current research. Especially in the face of adversarial attacks, DRL may suffer serious performance degradation or even make potentially dangerous decisions, so it is crucial to ensure their stability in security-sensitive scenarios. In this paper, we first introduce the basic framework of DRL and analyze the main security challenges faced in complex and changing environments. In addition, this paper proposes an adversarial attack classification framework based on perturbation type and attack target and reviews the mainstream adversarial attack methods against DRL in detail, including various attack methods such as perturbation state space, action space, reward function and model space. To effectively counter the attacks, this paper systematically summarizes various current robustness training strategies, including adversarial training, competitive training, robust learning, adversarial detection, defense distillation and other related defense techniques, we also discuss the advantages and shortcomings of these methods in improving the robustness of DRL. Finally, this paper looks into the future research direction of DRL in adversarial environments, emphasizing the research needs in terms of improving generalization, reducing computational complexity, and enhancing scalability and explainability, aiming to provide valuable references and directions for researchers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning, DRL)åœ¨è‡ªåŠ¨é©¾é©¶å’Œæ™ºèƒ½åŒ»ç–—ç­‰å®‰å…¨æ•æ„Ÿé¢†åŸŸé¢ä¸´çš„å®‰å…¨æ€§ä¸é²æ£’æ€§æŒ‘æˆ˜ï¼Œæä¾›äº†ä¸€ä»½å…³äºå¯¹æŠ—æ”»å‡»ä¸é˜²å¾¡æŠ€æœ¯çš„å…¨é¢ç»¼è¿°ã€‚æ–‡ç« é¦–å…ˆåˆ†æäº† DRL åœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹çš„å®‰å…¨æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªåŸºäºæ‰°åŠ¨ç±»å‹å’Œæ”»å‡»ç›®æ ‡çš„å¯¹æŠ—æ”»å‡»åˆ†ç±»æ¡†æ¶ã€‚è¯¥ç»¼è¿°è¯¦ç»†å›é¡¾äº†é’ˆå¯¹çŠ¶æ€ç©ºé—´(state space)ã€åŠ¨ä½œç©ºé—´(action space)ã€å¥–åŠ±å‡½æ•°(reward function)å’Œæ¨¡å‹ç©ºé—´(model space)ç­‰æ ¸å¿ƒç»„ä»¶çš„ä¸»æµå¯¹æŠ—æ”»å‡»æ–¹æ³•ã€‚ä¸ºäº†åº”å¯¹è¿™äº›å¨èƒï¼Œè®ºæ–‡ç³»ç»Ÿæ€§åœ°æ€»ç»“äº†åŒ…æ‹¬å¯¹æŠ—è®­ç»ƒ(adversarial training)ã€ç«äº‰è®­ç»ƒ(competitive training)ã€å¯¹æŠ—æ£€æµ‹(adversarial detection)å’Œé˜²å¾¡è’¸é¦(defense distillation)åœ¨å†…çš„å¤šç§é²æ£’æ€§å¢å¼ºç­–ç•¥ã€‚é€šè¿‡æ·±å…¥æ¢è®¨ç°æœ‰é˜²å¾¡æŠ€æœ¯çš„ä¼˜ç¼ºç‚¹ï¼Œæ–‡ç« æ­ç¤ºäº†å½“å‰æ–¹æ³•åœ¨æå‡ DRL é²æ£’æ€§æ–¹é¢çš„å±€é™æ€§ã€‚æœ€åï¼Œç ”ç©¶å±•æœ›äº†æå‡æ³›åŒ–èƒ½åŠ›ã€é™ä½è®¡ç®—å¤æ‚åº¦ä»¥åŠå¢å¼ºå¯è§£é‡Šæ€§ç­‰æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä¸ºæ„å»ºå®‰å…¨å¯é çš„æ™ºèƒ½å†³ç­–ç³»ç»Ÿæä¾›äº†é‡è¦æŒ‡å¼•ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20314v1",
      "published_date": "2025-10-23 08:04:57 UTC",
      "updated_date": "2025-10-23 08:04:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:47.455150+00:00"
    },
    {
      "arxiv_id": "2510.20310v2",
      "title": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation",
      "title_zh": "åŸºäºå·¥å…·å¢å¼ºçš„å…·èº«é—®ç­”å¤šæ­¥æ¨ç†",
      "authors": [
        "Mingliang Zhai",
        "Hansheng Liang",
        "Xiaomeng Fan",
        "Zhi Gao",
        "Chuanhao Li",
        "Che Sun",
        "Xu Bin",
        "Yuwei Wu",
        "Yunde Jia"
      ],
      "abstract": "Embodied Question Answering (EQA) requires agents to explore 3D environments to obtain observations and answer questions related to the scene. Existing methods leverage VLMs to directly explore the environment and answer questions without explicit thinking or planning, which limits their reasoning ability and results in excessive or inefficient exploration as well as ineffective responses. In this paper, we introduce ToolEQA, an agent that integrates external tools with multi-step reasoning, where external tools can provide more useful information for completing the task, helping the model derive better exploration directions in the next step of reasoning and thus obtaining additional effective information. This enables ToolEQA to generate more accurate responses with a shorter exploration distance. To enhance the model's ability for tool-usage and multi-step reasoning, we further design a novel EQA data generation pipeline that automatically constructs large-scale EQA tasks with reasoning trajectories and corresponding answers. Based on the pipeline, we collect the EQA-RT dataset that contains about 18K tasks, divided into a training set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping with the training set) and EQA-RT-Unseen (novel scenes). Experiments on EQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by 9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot ToolEQA by 10% in success rate. In addition, ToolEQA also achieves state-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench datasets, demonstrating its generality. Our homepage see https://tooleqa.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ToolEQAï¼Œè¿™æ˜¯ä¸€ä¸ªå°†å¤–éƒ¨å·¥å…·(external tools)ä¸å¤šæ­¥æ¨ç†(multi-step reasoning)ç›¸ç»“åˆçš„æ™ºèƒ½ä½“ï¼Œæ—¨åœ¨è§£å†³å…·èº«é—®ç­”(Embodied Question Answering, EQA)ä¸­è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)å› ç¼ºä¹æ˜ç¡®æ€è€ƒè§„åˆ’å¯¼è‡´çš„æ¢ç´¢æ•ˆç‡ä½ä¸‹å’Œå›ç­”æ— æ•ˆç­‰é—®é¢˜ã€‚ToolEQAé€šè¿‡å¤–éƒ¨å·¥å…·è·å–è¾…åŠ©ä¿¡æ¯ï¼Œå¼•å¯¼æ¨¡å‹åœ¨æ¯ä¸€æ­¥æ¨ç†ä¸­äº§ç”Ÿæ›´ä¼˜çš„æ¢ç´¢æ–¹å‘ï¼Œä½¿å…¶èƒ½å¤Ÿä»¥æ›´çŸ­çš„æ¢ç´¢è·ç¦»ç”Ÿæˆæ›´å‡†ç¡®çš„å›å¤ã€‚ä¸ºäº†æå‡æ¨¡å‹çš„å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œç ”ç©¶è€…è¿˜è®¾è®¡äº†è‡ªåŠ¨åŒ–æ•°æ®ç”Ÿæˆç®¡çº¿å¹¶æ„å»ºäº†åŒ…å«1.8ä¸‡é¡¹å¸¦æœ‰æ¨ç†è½¨è¿¹ä»»åŠ¡çš„EQA-RTæ•°æ®é›†ã€‚å®éªŒè¡¨æ˜ï¼ŒToolEQAåœ¨å¤šä¸ªæµ‹è¯•é›†ä¸Šçš„æˆåŠŸç‡è¾ƒåŸºçº¿æ¨¡å‹æå‡äº†9.2%è‡³20.2%ï¼Œå¹¶åœ¨HM-EQAã€OpenEQAå’ŒEXPRESS-Benchç­‰æ•°æ®é›†ä¸Šå‡å–å¾—äº†SOTAæ€§èƒ½ï¼Œå±•ç°äº†å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 7 figures, 8 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.20310v2",
      "published_date": "2025-10-23 08:02:08 UTC",
      "updated_date": "2025-10-27 17:58:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:50.547594+00:00"
    },
    {
      "arxiv_id": "2510.21861v2",
      "title": "The Mirror Loop: Recursive Non-Convergence in Generative Reasoning Systems",
      "title_zh": "é•œåƒå¾ªç¯ï¼šç”Ÿæˆå¼æ¨ç†ç³»ç»Ÿä¸­çš„é€’å½’éæ”¶æ•›",
      "authors": [
        "Bentley DeVilling"
      ],
      "abstract": "Large language models are often described as capable of reflective reasoning, yet recursive self-evaluation without external feedback frequently yields reformulation rather than progress. We test this prediction in a cross-provider study of 144 reasoning sequences across three models (OpenAI GPT-4o-mini, Anthropic Claude 3 Haiku, and Google Gemini 2.0 Flash) and four task families (arithmetic, code, explanation, reflection), each iterated ten times under two conditions: ungrounded self-critique and a minimal grounding intervention (a single verification step at iteration three). Mean informational change (delta I, measured via normalized edit distance) declined by 55% from early (0.193) to late (0.087) iterations in ungrounded runs, with consistent patterns across all three providers. Grounded runs showed a +28% rebound in informational change immediately after the intervention and sustained non-zero variance thereafter. Complementary measures-n-gram novelty, embedding drift, and character-level entropy-converged on the same pattern: reflection without contact tends toward informational closure. We interpret this as evidence for a structural limit on self-correction in generative reasoning: without an exchange of information with an independent verifier or environment, recursive inference approaches an attractor state of epistemic stasis. Minimal grounding functions as dissipative coupling, reintroducing informational flux. The cross-architecture consistency suggests the mirror loop arises from shared autoregressive training objectives rather than provider-specific alignment schemes. The results delineate when reflection is performative rather than epistemic and motivate design principles for grounded, cooperative reasoning. Materials and code are publicly available.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼æ¨ç†ç³»ç»Ÿä¸­çš„â€œé•œé¢å¾ªç¯â€ï¼ˆMirror Loopï¼‰ç°è±¡ï¼Œå³æ¨¡å‹åœ¨ç¼ºä¹å¤–éƒ¨åé¦ˆçš„é€’å½’è‡ªè¯„ä¸­å¾€å¾€é™·å…¥é‡å¤æ”¹å†™è€Œéå®è´¨è¿›æ­¥ã€‚ä½œè€…é€šè¿‡å¯¹GPT-4o-miniã€Claude 3 HaikuåŠGemini 2.0 Flashåœ¨å¤šç§ä»»åŠ¡ä¸Šçš„æµ‹è¯•å‘ç°ï¼Œæ— å¼•å¯¼çš„è‡ªæˆ‘æ‰¹åˆ¤ä¼šå¯¼è‡´ä¿¡æ¯å˜åŒ–é‡ï¼ˆdelta Iï¼‰éšè¿­ä»£æ˜¾è‘—ä¸‹é™55%ï¼Œå‘ˆç°å‡ºä¿¡æ¯é—­åˆä¸â€œè®¤çŸ¥åœæ»â€ï¼ˆepistemic stasisï¼‰çš„è¶‹åŠ¿ã€‚å®éªŒè¡¨æ˜ï¼Œå¼•å…¥æç®€çš„å¼•å¯¼å¹²é¢„ï¼ˆminimal groundingï¼‰å¯ä½¿ä¿¡æ¯å˜åŒ–é‡ç«‹å³å›å‡28%å¹¶ç»´æŒæœ‰æ•ˆæ³¢åŠ¨ã€‚ç ”ç©¶è®¤ä¸ºè¿™ç§éæ”¶æ•›æ€§æ˜¯è‡ªå›å½’è®­ç»ƒç›®æ ‡ï¼ˆautoregressive training objectivesï¼‰å¸¦æ¥çš„ç»“æ„æ€§é™åˆ¶ï¼Œè¯æ˜äº†ç¼ºä¹å¤–éƒ¨éªŒè¯çš„è‡ªçœå…·æœ‰è¡¨æ¼”æ€§è€Œéè®¤è¯†è®ºæ„ä¹‰ã€‚è¯¥ç»“æœä¸ºè®¾è®¡å…·å¤‡å¼•å¯¼æ€§å’Œåä½œæ€§çš„æ¨ç†ç³»ç»Ÿæä¾›äº†é‡è¦åŸåˆ™ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 2 figures. Category: cs.LG. Code and data: https://github.com/Course-Correct-Labs/mirror-loop",
      "pdf_url": "https://arxiv.org/pdf/2510.21861v2",
      "published_date": "2025-10-23 07:53:26 UTC",
      "updated_date": "2025-11-05 09:41:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:56.165638+00:00"
    },
    {
      "arxiv_id": "2510.20299v2",
      "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Brain Tumor Classification with Grad-CAM Interpretability",
      "title_zh": "DB-FGA-Netï¼šå…·æœ‰ Grad-CAM å¯è§£é‡Šæ€§çš„å¤šç±»åˆ«è„‘è‚¿ç˜¤åˆ†ç±»åŒä¸»å¹²é¢‘ç‡é—¨æ§æ³¨æ„åŠ›ç½‘ç»œ",
      "authors": [
        "Saraf Anzum Shreya",
        "MD. Abu Ismail Siddique",
        "Sharaf Tasnim"
      ],
      "abstract": "Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DB-FGA-Netï¼Œä¸€ç§é›†æˆVGG16å’ŒXceptionåŒéª¨å¹²ç½‘ç»œ(Dual Backbone)çš„é¢‘ç‡é—¨æ§æ³¨æ„åŠ›ç½‘ç»œ(Frequency-Gated Attention Network)ï¼Œæ—¨åœ¨å®ç°å¤šç±»åˆ«è„‘è‚¿ç˜¤çš„é«˜ç²¾åº¦åˆ†ç±»ã€‚è¯¥æ¨¡å‹é€šè¿‡Frequency-Gated Attention (FGA) Blockæ•è·äº’è¡¥çš„å±€éƒ¨ä¸å…¨å±€ç‰¹å¾ï¼Œä¸”åœ¨æ— éœ€é‡åº¦æ•°æ®å¢å¼º(data augmentation)çš„æƒ…å†µä¸‹å®ç°äº†SOTAæ€§èƒ½ï¼Œå±•ç°äº†å¯¹ä¸åŒè§„æ¨¡æ•°æ®é›†çš„å¼ºé²æ£’æ€§ã€‚ä¸ºäº†æå‡ä¸´åºŠé€æ˜åº¦ï¼Œç ”ç©¶å¼•å…¥äº†Grad-CAMæŠ€æœ¯å¯¹è‚¿ç˜¤åŒºåŸŸè¿›è¡Œå¯è§†åŒ–ï¼Œå¼¥è¡¥äº†æ¨¡å‹é¢„æµ‹ä¸ä¸´åºŠå¯è§£é‡Šæ€§ä¹‹é—´çš„é¸¿æ²Ÿã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDB-FGA-Netåœ¨7K-DSæ•°æ®é›†çš„å››åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†99.24%çš„å‡†ç¡®ç‡ï¼Œå¹¶åœ¨ç‹¬ç«‹æ•°æ®é›†3K-DSä¸Šå±•ç°å‡ºä¼˜äºç°æœ‰æ–¹æ³•çš„æ³›åŒ–æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é…å¥—å¼€å‘äº†å›¾å½¢ç”¨æˆ·ç•Œé¢(GUI)ä»¥æ”¯æŒå®æ—¶åˆ†ç±»ä¸è‚¿ç˜¤å®šä½ã€‚è¿™ç§å…¼å…·é«˜æ€§èƒ½ä¸å¯è§£é‡Šæ€§çš„æ¶æ„ï¼Œä¸ºè„‘è‚¿ç˜¤è¯Šæ–­çš„ä¸´åºŠè½¬åŒ–æä¾›äº†å¯é çš„æ·±åº¦å­¦ä¹ è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 14 figures, 12 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.20299v2",
      "published_date": "2025-10-23 07:39:00 UTC",
      "updated_date": "2025-10-25 01:40:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:18:57.850241+00:00"
    },
    {
      "arxiv_id": "2510.20296v1",
      "title": "RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector Database Perspective",
      "title_zh": "RAG-Stackï¼šä»å‘é‡æ•°æ®åº“è§†è§’ååŒä¼˜åŒ– RAG è´¨é‡ä¸æ€§èƒ½",
      "authors": [
        "Wenqi Jiang"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as one of the most prominent applications of vector databases. By integrating documents retrieved from a database into the prompt of a large language model (LLM), RAG enables more reliable and informative content generation. While there has been extensive research on vector databases, many open research problems remain once they are considered in the wider context of end-to-end RAG pipelines. One practical yet challenging problem is how to jointly optimize both system performance and generation quality in RAG, which is significantly more complex than it appears due to the numerous knobs on both the algorithmic side (spanning models and databases) and the systems side (from software to hardware). In this paper, we present RAG-Stack, a three-pillar blueprint for quality-performance co-optimization in RAG systems. RAG-Stack comprises: (1) RAG-IR, an intermediate representation that serves as an abstraction layer to decouple quality and performance aspects; (2) RAG-CM, a cost model for estimating system performance given an RAG-IR; and (3) RAG-PE, a plan exploration algorithm that searches for high-quality, high-performance RAG configurations. We believe this three-pillar blueprint will become the de facto paradigm for RAG quality-performance co-optimization in the years to come.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-augmented generation, RAG)ç³»ç»Ÿä¸­è´¨é‡ä¸æ€§èƒ½ååŒä¼˜åŒ–çš„éš¾é¢˜ï¼Œæå‡ºäº†åä¸ºRAG-Stackçš„ä¸‰æ”¯æŸ±è“å›¾ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œç”±äºæ¶‰åŠæ¨¡å‹ã€æ•°æ®åº“ã€è½¯ä»¶åŠç¡¬ä»¶ç­‰å¤šä¸ªç»´åº¦çš„å¤æ‚å‚æ•°ï¼Œä»å‘é‡æ•°æ®åº“(Vector Database)è§†è§’åŒæ—¶å¹³è¡¡ç”Ÿæˆè´¨é‡ä¸ç³»ç»Ÿæ€§èƒ½å…·æœ‰æå¤§æŒ‘æˆ˜æ€§ã€‚ä¸ºæ­¤ï¼ŒRAG-Stackå¼•å…¥äº†ä¸­é—´è¡¨ç¤ºå±‚RAG-IRï¼Œé€šè¿‡æŠ½è±¡å±‚å®ç°è´¨é‡ä¸æ€§èƒ½ç»´åº¦çš„è§£è€¦ã€‚è¯¥æ¡†æ¶è¿˜åŒ…å«æˆæœ¬æ¨¡å‹RAG-CMï¼Œç”¨äºæ ¹æ®RAG-IRç²¾ç¡®ä¼°ç®—ç³»ç»Ÿæ€§èƒ½ï¼Œä»¥åŠè®¡åˆ’æ¢ç´¢ç®—æ³•RAG-PEï¼Œç”¨äºæœç´¢å…¼é¡¾é«˜è´¨é‡ä¸é«˜æ•ˆç‡çš„RAGé…ç½®ã€‚è¿™ä¸€è“å›¾ä¸ºç«¯åˆ°ç«¯RAGæµæ°´çº¿çš„ååŒä¼˜åŒ–æä¾›äº†æ ‡å‡†åŒ–èŒƒå¼ï¼Œæ—¨åœ¨æˆä¸ºæœªæ¥è¯¥é¢†åŸŸæ€§èƒ½è°ƒä¼˜çš„äº‹å®æ ‡å‡†ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20296v1",
      "published_date": "2025-10-23 07:35:19 UTC",
      "updated_date": "2025-10-23 07:35:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:00.263739+00:00"
    },
    {
      "arxiv_id": "2510.21860v1",
      "title": "Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence",
      "title_zh": "Butter-Benchï¼šè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹æ§åˆ¶æœºå™¨äººçš„å®è·µæ™ºèƒ½",
      "authors": [
        "Callum Sharrock",
        "Lukas Petersson",
        "Hanna Petersson",
        "Axel Backlund",
        "Axel WennstrÃ¶m",
        "Kristoffer NordstrÃ¶m",
        "Elias Aronsson"
      ],
      "abstract": "We present Butter-Bench, a benchmark evaluating large language model (LLM) controlled robots for practical intelligence, defined as the ability to navigate the messiness of the physical world. Current state-of-the-art robotic systems use a hierarchical architecture with LLMs in charge of high-level reasoning, and a Vision Language Action (VLA) model for low-level control. Butter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs have repeatedly surpassed humans in evaluations requiring analytical intelligence, we find humans still outperform LLMs on Butter-Bench. The best LLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs struggled the most with multi-step spatial planning and social understanding. We also evaluate LLMs that are fine-tuned for embodied reasoning and conclude that this training does not improve their score on Butter-Bench.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Butter-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å— Large Language Model (LLM) æ§åˆ¶çš„æœºå™¨äººåœ¨å®é™…æ™ºèƒ½ (practical intelligence) æ–¹é¢è¡¨ç°çš„åŸºå‡†æµ‹è¯•ï¼Œé‡ç‚¹è€ƒå¯Ÿå…¶åº”å¯¹ç‰©ç†ä¸–ç•Œå¤æ‚æ€§çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†æµ‹è¯•é‡‡ç”¨åˆ†å±‚æ¶æ„ï¼Œå°†è´Ÿè´£é«˜å±‚æ¨ç†çš„ LLM ä¸è´Ÿè´£åº•å±‚æ§åˆ¶çš„ Vision Language Action (VLA) æ¨¡å‹éš”ç¦»ï¼Œä»è€Œå®ç°å¯¹ LLM æ¨ç†èƒ½åŠ›çš„ç‹¬ç«‹è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡ LLM åœ¨ä¼ ç»Ÿåˆ†ææ™ºèƒ½é¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ Butter-Bench ä¸Šçš„è¡¨ç°ä»è¿œä¸åŠäººç±»ï¼Œé¡¶å°–æ¨¡å‹çš„å¾—åˆ†ä»…ä¸º 40%ï¼Œè¿œä½äºäººç±» 95% çš„å¹³å‡æ°´å¹³ã€‚ç ”ç©¶æŒ‡å‡º LLM åœ¨å¤šæ­¥ç©ºé—´è§„åˆ’ (multi-step spatial planning) å’Œç¤¾ä¼šç†è§£ (social understanding) æ–¹é¢å­˜åœ¨æ˜æ˜¾çŸ­æ¿ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹å…·èº«æ¨ç† (embodied reasoning) è¿›è¡Œçš„å¾®è°ƒè®­ç»ƒä¹Ÿæœªèƒ½æ˜¾è‘—æé«˜æ¨¡å‹åœ¨è¯¥åŸºå‡†æµ‹è¯•ä¸­çš„å¾—åˆ†ï¼Œåæ˜ å‡ºå½“å‰æ¨¡å‹åœ¨å¤„ç†å¤æ‚ç‰©ç†ç¯å¢ƒä»»åŠ¡æ—¶ä»é¢ä¸´ä¸¥å³»æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21860v1",
      "published_date": "2025-10-23 07:28:28 UTC",
      "updated_date": "2025-10-23 07:28:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:02.762481+00:00"
    },
    {
      "arxiv_id": "2510.20291v1",
      "title": "A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization",
      "title_zh": "é¢å‘è·¨æ¨¡æ€åœ°ç†å®šä½çš„å‚æ•°é«˜æ•ˆæ··åˆä¸“å®¶æ¡†æ¶",
      "authors": [
        "LinFeng Li",
        "Jian Zhao",
        "Zepeng Yang",
        "Yuhang Song",
        "Bojun Lin",
        "Tianle Zhang",
        "Yuchen Yuan",
        "Chi Zhang",
        "Xuelong Li"
      ],
      "abstract": "We present a winning solution to RoboSense 2025 Track 4: Cross-Modal Drone Navigation. The task retrieves the most relevant geo-referenced image from a large multi-platform corpus (satellite/drone/ground) given a natural-language query. Two obstacles are severe inter-platform heterogeneity and a domain gap between generic training descriptions and platform-specific test queries. We mitigate these with a domain-aligned preprocessing pipeline and a Mixture-of-Experts (MoE) framework: (i) platform-wise partitioning, satellite augmentation, and removal of orientation words; (ii) an LLM-based caption refinement pipeline to align textual semantics with the distinct visual characteristics of each platform. Using BGE-M3 (text) and EVA-CLIP (image), we train three platform experts using a progressive two-stage, hard-negative mining strategy to enhance discriminative power, and fuse their scores at inference. The system tops the official leaderboard, demonstrating robust cross-modal geo-localization under heterogeneous viewpoints.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹RoboSense 2025æŒ‘æˆ˜èµ›ä¸­çš„è·¨æ¨¡æ€æ— äººæœºå¯¼èˆªä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§å‚æ•°é«˜æ•ˆçš„Mixture-of-Experts (MoE) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”±äºå¹³å°å¼‚æ„æ€§å’Œé¢†åŸŸé—´éš™å¯¼è‡´çš„åœ°ç†å®šä½éš¾é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€å¥—é¢†åŸŸå¯¹é½çš„é¢„å¤„ç†æµæ°´çº¿ï¼ŒåŒ…æ‹¬å¹³å°åˆ†åŒºã€å«æ˜Ÿæ•°æ®å¢å¼ºåŠå»é™¤æ–¹å‘è¯ï¼Œå¹¶åˆ©ç”¨LLMè¿›è¡Œæè¿°ç²¾ç‚¼ï¼Œä»¥ç¡®ä¿æ–‡æœ¬è¯­ä¹‰ä¸ä¸åŒå¹³å°çš„è§†è§‰ç‰¹å¾ç²¾å‡†åŒ¹é…ã€‚åœ¨æ¨¡å‹å®ç°ä¸Šï¼Œè¯¥æ–¹æ¡ˆé›†æˆäº†BGE-M3æ–‡æœ¬ç¼–ç å™¨ä¸EVA-CLIPå›¾åƒç¼–ç å™¨ï¼Œå¹¶é’ˆå¯¹ç‰¹å®šå¹³å°è®­ç»ƒäº†ä¸‰ä¸ªä¸“å®¶æ¨¡å‹ã€‚é€šè¿‡é‡‡ç”¨æ¸è¿›å¼ä¸¤é˜¶æ®µç¡¬è´Ÿé‡‡æ ·(hard-negative mining)ç­–ç•¥ï¼Œæ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„åˆ¤åˆ«èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œç³»ç»Ÿé€šè¿‡å¤šä¸“å®¶å¾—åˆ†èåˆæŠ€æœ¯å®ç°äº†ç²¾å‡†çš„åœ°ç†åæ ‡æ£€ç´¢ã€‚æœ€ç»ˆï¼Œè¯¥ç³»ç»Ÿåœ¨å®˜æ–¹æ’è¡Œæ¦œä¸­æ‘˜å¾—æ¡‚å† ï¼Œå……åˆ†éªŒè¯äº†å…¶åœ¨å¼‚æ„è§†è§’ä¸‹å¤„ç†é²æ£’è·¨æ¨¡æ€å®šä½ä»»åŠ¡çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20291v1",
      "published_date": "2025-10-23 07:23:47 UTC",
      "updated_date": "2025-10-23 07:23:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:11.248936+00:00"
    },
    {
      "arxiv_id": "2510.20287v1",
      "title": "Breakdance Video classification in the age of Generative AI",
      "title_zh": "ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ—¶ä»£ä¸‹çš„éœ¹é›³èˆè§†é¢‘åˆ†ç±»",
      "authors": [
        "Sauptik Dhar",
        "Naveen Ramakrishnan",
        "Michelle Munson"
      ],
      "abstract": "Large Vision Language models have seen huge application in several sports use-cases recently. Most of these works have been targeted towards a limited subset of popular sports like soccer, cricket, basketball etc; focusing on generative tasks like visual question answering, highlight generation. This work analyzes the applicability of the modern video foundation models (both encoder and decoder) for a very niche but hugely popular dance sports - breakdance. Our results show that Video Encoder models continue to outperform state-of-the-art Video Language Models for prediction tasks. We provide insights on how to choose the encoder model and provide a thorough analysis into the workings of a finetuned decoder model for breakdance video classification.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)æ—¶ä»£ï¼Œç°ä»£è§†é¢‘åŸºç¡€æ¨¡å‹(Video Foundation Models)åœ¨éœ¹é›³èˆ(Breakdance)è§†é¢‘åˆ†ç±»è¿™ä¸€åˆ©åŸºé¢†åŸŸçš„åº”ç”¨ã€‚è™½ç„¶å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(Large Vision Language Models)å·²å¹¿æ³›åº”ç”¨äºè¶³çƒã€ç¯®çƒç­‰çƒ­é—¨è¿åŠ¨çš„ç”Ÿæˆå¼ä»»åŠ¡ï¼Œä½†æœ¬ç ”ç©¶é‡ç‚¹åˆ†æäº†ç¼–ç å™¨ä¸è§£ç å™¨æ¨¡å‹å¯¹ä¸“ä¸šèˆè¹ˆåŠ¨ä½œçš„è¯†åˆ«èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨åˆ†ç±»é¢„æµ‹ä»»åŠ¡ä¸­ï¼ŒVideo Encoderæ¨¡å‹ä¾ç„¶ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„Video Language Modelsã€‚ç ”ç©¶è¿›ä¸€æ­¥æä¾›äº†å¦‚ä½•é€‰æ‹©ç¼–ç å™¨æ¨¡å‹çš„è§è§£ï¼Œå¹¶å¯¹ç»è¿‡å¾®è°ƒçš„è§£ç å™¨æ¨¡å‹åœ¨Breakdanceè§†é¢‘åˆ†ç±»ä¸­çš„è¿ä½œæœºåˆ¶è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚è¯¥å·¥ä½œä¸ºé’ˆå¯¹ç‰¹å®šä½“è‚²åŠ¨ä½œçš„è§†é¢‘åˆ†ææä¾›äº†é‡è¦çš„æŠ€æœ¯å‚è€ƒå’Œæ¨¡å‹é€‰æ‹©ä¾æ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.20287v1",
      "published_date": "2025-10-23 07:18:54 UTC",
      "updated_date": "2025-10-23 07:18:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:08.060966+00:00"
    },
    {
      "arxiv_id": "2510.20286v1",
      "title": "UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning",
      "title_zh": "UI-Insï¼šé€šè¿‡å¤šè§†è§’â€œæŒ‡ä»¤å³æ¨ç†â€å¢å¼º GUI å®šä½",
      "authors": [
        "Liangyu Chen",
        "Hanzhang Zhou",
        "Chenglin Cai",
        "Jianan Zhang",
        "Panrong Tong",
        "Quyu Kong",
        "Xu Zhang",
        "Chen Liu",
        "Yuqi Liu",
        "Wenxuan Wang",
        "Yue Wang",
        "Qin Jin",
        "Steven Hoi"
      ],
      "abstract": "GUI grounding, which maps natural-language instructions to actionable UI elements, is a core capability of GUI agents. Prior works largely treats instructions as a static proxy for user intent, overlooking the impact of instruction diversity and quality on grounding performance. Through a careful investigation of existing grounding datasets, we find a 23.3% flaw rate in their instructions and show that inference-time exploitation of instruction diversity yields up to a substantial 76% relative performance improvement. In this paper, we introduce the Instruction-as-Reasoning paradigm, treating instructions as dynamic analytical pathways that offer distinct perspectives and enabling the model to select the most effective pathway during reasoning. To achieve this, we propose a two-stage training framework: supervised fine-tuning (SFT) on synthesized, diverse instructions to instill multi-perspective reasoning, followed by reinforcement learning (RL) to optimize pathway selection and composition. Our resulting models, UI-Ins-7B and UI-Ins-32B, achieve state-of-the-art results on five challenging grounding benchmarks and exhibit emergent reasoning, selectively composing and synthesizing novel instruction pathways at inference. In particular, UI-Ins-32B attains the best grounding accuracy, scoring 87.3% on UI-I2E-Bench, 57.0% on ScreenSpot-Pro, and 84.9% on MMBench-GUI L2. Furthermore, our model demonstrates strong agentic potential, achieving a 74.1% success rate on AndroidWorld using UI-Ins-7B as the executor. Our in-depth analysis reveals additional insights such as how reasoning can be formulated to enhance rather than hinder grounding performance, and how our method mitigates policy collapse in the SFT+RL framework. All code and model checkpoints will be publicly released in https://github.com/alibaba/UI-Ins.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UI-Insï¼Œé’ˆå¯¹GUI Groundingä»»åŠ¡ä¸­æŒ‡ä»¤å¤šæ ·æ€§å’Œè´¨é‡å¯¹æ€§èƒ½å½±å“è¢«å¿½è§†ï¼Œä»¥åŠç°æœ‰æ•°æ®é›†æŒ‡ä»¤ç¼ºé™·ç‡é«˜çš„é—®é¢˜ï¼Œå¼•å…¥äº†Instruction-as-ReasoningèŒƒå¼ã€‚è¯¥èŒƒå¼å°†æŒ‡ä»¤è§†ä¸ºæä¾›ä¸åŒè§†è§’çš„åŠ¨æ€åˆ†æè·¯å¾„ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­é€‰æ‹©å¹¶åˆæˆæœ€æœ‰æ•ˆçš„æ‰§è¡Œè·¯å¾„ã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡åœ¨åˆæˆæŒ‡ä»¤ä¸Šè¿›è¡Œæœ‰ç›‘ç£å¾®è°ƒ(SFT)ä»¥åŸ¹å…»å¤šè§†è§’æ¨ç†èƒ½åŠ›ï¼Œå¹¶ç»“åˆå¼ºåŒ–å­¦ä¹ (RL)æ¥ä¼˜åŒ–è·¯å¾„ç»„åˆã€‚å®éªŒè¯æ˜ï¼ŒUI-Ins-7Bå’ŒUI-Ins-32Båœ¨äº”ä¸ªæŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†SOTAæ°´å¹³ï¼Œå¹¶åœ¨UI-I2E-Benchå’ŒScreenSpot-Proç­‰æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ã€‚å…¶ä¸­UI-Ins-32Båœ¨MMBench-GUI L2ä¸Šè¾¾åˆ°84.9%çš„å‡†ç¡®ç‡ï¼Œè€ŒUI-Ins-7Båœ¨AndroidWorldæ™ºèƒ½ä½“ä»»åŠ¡ä¸­å®ç°äº†74.1%çš„æˆåŠŸç‡ã€‚è¯¥é¡¹å·¥ä½œæ­ç¤ºäº†å¦‚ä½•é€šè¿‡æ¨ç†æœºåˆ¶å¢å¼ºGroundingæ€§èƒ½ï¼Œå¹¶æœ‰æ•ˆè§£å†³äº†SFT+RLè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç­–ç•¥å´©å¡Œ(Policy Collapse)é—®é¢˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20286v1",
      "published_date": "2025-10-23 07:18:32 UTC",
      "updated_date": "2025-10-23 07:18:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:32.658386+00:00"
    },
    {
      "arxiv_id": "2510.20280v2",
      "title": "Context-level Language Modeling by Learning Predictive Context Embeddings",
      "title_zh": "é€šè¿‡é¢„æµ‹æ€§è¯­å¢ƒåµŒå…¥å­¦ä¹ å®ç°è¯­å¢ƒçº§è¯­è¨€å»ºæ¨¡",
      "authors": [
        "Beiya Dai",
        "Yuliang Liu",
        "Daozheng Xue",
        "Qipeng Guo",
        "Kai Chen",
        "Xinbing Wang",
        "Bowen Zhou",
        "Zhouhan Lin"
      ],
      "abstract": "Next-token prediction (NTP) is the cornerstone of modern large language models (LLMs) pretraining, driving their unprecedented capabilities in text generation, reasoning, and instruction following. However, the token-level prediction limits the model's capacity to capture higher-level semantic structures and long-range contextual relationships. To overcome this limitation, we introduce \\textbf{ContextLM}, a framework that augments standard pretraining with an inherent \\textbf{next-context prediction} objective. This mechanism trains the model to learn predictive representations of multi-token contexts, leveraging error signals derived from future token chunks. Crucially, ContextLM achieves this enhancement while remaining fully compatible with the standard autoregressive, token-by-token evaluation paradigm (e.g., perplexity). Extensive experiments on the GPT2 and Pythia model families, scaled up to $1.5$B parameters, show that ContextLM delivers consistent improvements in both perplexity and downstream task performance. Our analysis indicates that next-context prediction provides a scalable and efficient pathway to stronger language modeling, yielding better long-range coherence and more effective attention allocation with minimal computational overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¾èµ–çš„ Next-token prediction (NTP) åœ¨æ•è·é«˜å±‚è¯­ä¹‰ç»“æ„å’Œé•¿ç¨‹å…³ç³»æ–¹é¢çš„å±€é™ï¼Œæå‡ºäº† ContextLM æ¡†æ¶ã€‚è¯¥æ¡†æ¶åœ¨æ ‡å‡†é¢„è®­ç»ƒä¸­å¼•å…¥äº† next-context prediction ç›®æ ‡ï¼Œé€šè¿‡åˆ©ç”¨æœªæ¥ token chunks çš„è¯¯å·®ä¿¡å·ï¼Œè®­ç»ƒæ¨¡å‹å­¦ä¹ å¤šæ ‡è®°ä¸Šä¸‹æ–‡çš„é¢„æµ‹æ€§è¡¨ç¤ºã€‚ContextLM åœ¨å¢å¼ºæ¨¡å‹èƒ½åŠ›çš„åŒæ—¶ï¼Œä¿æŒäº†ä¸æ ‡å‡†è‡ªå›å½’ã€é€æ ‡è®°è¯„ä¼°èŒƒå¼ï¼ˆå¦‚ perplexityï¼‰çš„å®Œå…¨å…¼å®¹ã€‚åœ¨ GPT2 å’Œ Pythia æ¨¡å‹å®¶æ—ï¼ˆè§„æ¨¡è¾¾ 1.5B å‚æ•°ï¼‰ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æŒç»­æå‡äº†å›°æƒ‘åº¦å’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚åˆ†ææŒ‡å‡ºï¼Œnext-context prediction åœ¨æå°è®¡ç®—å¼€é”€ä¸‹å®ç°äº†æ›´å¥½çš„é•¿ç¨‹è¿è´¯æ€§å’Œæ›´æœ‰æ•ˆçš„ attention allocationã€‚è¯¥ç ”ç©¶è¯æ˜äº†ä¸‹ä¸€ä¸Šä¸‹æ–‡é¢„æµ‹æ˜¯å®ç°æ›´å¼ºå¤§è¯­è¨€å»ºæ¨¡çš„ä¸€æ¡å¯æ‰©å±•ä¸”é«˜æ•ˆçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16pages,6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20280v2",
      "published_date": "2025-10-23 07:09:45 UTC",
      "updated_date": "2025-10-28 07:35:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:33.363105+00:00"
    },
    {
      "arxiv_id": "2510.20275v1",
      "title": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction",
      "title_zh": "ç»å…¸ç‰¹å¾åµŒå…¥åŠ©åŠ›åŸºäº BERT çš„äººç±»ç§»åŠ¨é¢„æµ‹",
      "authors": [
        "Yunzhi Liu",
        "Haokai Tan",
        "Rushi Kanjaria",
        "Lihuan Li",
        "Flora D. Salim"
      ],
      "abstract": "Human mobility forecasting is crucial for disaster relief, city planning, and public health. However, existing models either only model location sequences or include time information merely as auxiliary input, thereby failing to leverage the rich semantic context provided by points of interest (POIs). To address this, we enrich a BERT-based mobility model with derived temporal descriptors and POI embeddings to better capture the semantics underlying human movement. We propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI and temporal information at each location to construct a unified, semantically enriched representation of mobility. Experimental results show that STaBERT significantly improves prediction accuracy: for single-city prediction, the GEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34 to 0.56.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººç±»ç§»åŠ¨æ€§é¢„æµ‹(Human mobility forecasting)ä¸­ç°æœ‰æ¨¡å‹æœªèƒ½å……åˆ†åˆ©ç”¨å…´è¶£ç‚¹(POIs)è¯­ä¹‰èƒŒæ™¯çš„é—®é¢˜ï¼Œæå‡ºäº†STaBERT (Semantic-Temporal aware BERT)æ¨¡å‹ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥æ´¾ç”Ÿçš„æ—¶é—´æè¿°ç¬¦(temporal descriptors)å’ŒPOI embeddingsï¼Œå¢å¼ºäº†åŸºäºBERTçš„ç§»åŠ¨æ€§æ¨¡å‹ï¼Œæ—¨åœ¨æ›´ç²¾å‡†åœ°æ•æ‰äººç±»è¿åŠ¨èƒŒåçš„æ·±å±‚è¯­ä¹‰ã€‚STaBERTåœ¨æ¯ä¸ªåœ°ç†ä½ç½®åŒæ­¥æ•´åˆPOIä¸æ—¶é—´ä¿¡æ¯ï¼Œæ„å»ºå‡ºç»Ÿä¸€ä¸”è¯­ä¹‰ä¸°å¯Œçš„ç§»åŠ¨æ€§ç‰¹å¾è¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSTaBERTæ˜¾è‘—æå‡äº†é¢„æµ‹å‡†ç¡®ä½ï¼Œåœ¨å•åŸå¸‚é¢„æµ‹ä»»åŠ¡ä¸­å°†GEO-BLEUå¾—åˆ†ä»0.34æé«˜è‡³0.75ï¼Œåœ¨å¤šåŸå¸‚é¢„æµ‹ä»»åŠ¡ä¸­ä»0.34æå‡è‡³0.56ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºç¾éš¾æ•‘æ´ã€åŸå¸‚è§„åˆ’å’Œå…¬å…±å«ç”Ÿç­‰é¢†åŸŸçš„ç§»åŠ¨æ€§åˆ†ææä¾›äº†æ›´å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by ACM SIGSPATIAL 2025 as a short paper",
      "pdf_url": "https://arxiv.org/pdf/2510.20275v1",
      "published_date": "2025-10-23 06:59:58 UTC",
      "updated_date": "2025-10-23 06:59:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:33.559966+00:00"
    },
    {
      "arxiv_id": "2510.20272v1",
      "title": "Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ•°å­¦æ¨ç†ä¸­ PRM å¼•å¯¼æ ‘æœç´¢çš„å±€é™æ€§",
      "authors": [
        "Tristan Cinquin",
        "Geoff Pleiss",
        "Agustinus Kristiadi"
      ],
      "abstract": "While chain-of-thought prompting with Best-of-N (BoN) selection has become popular for mathematical reasoning in large language models (LLMs), its linear structure fails to capture the branching and exploratory nature of complex problem-solving. In this work, we propose an adaptive algorithm to maximize process reward model (PRM) scores over the intractable action space, and investigate whether PRM-guided tree search can improve mathematical reasoning by exploring multiple partial solution paths. Across $23$ diverse mathematical problems using Qwen2.5-Math-7B-Instruct with its associated PRM as a case study, we find that: (1) PRM-guided tree search shows no statistically significant improvements over BoN despite higher costs, (2) Monte Carlo tree search and beam search outperform other PRM-guided tree search methods, (3) PRMs poorly approximate state values and their reliability degrades with reasoning depth, and (4) PRMs generalize poorly out of distribution. This underperformance stems from tree search's greater reliance on unreliable PRM scores, suggesting different reward modeling is necessary before tree search can effectively enhance mathematical reasoning in LLMs.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­ï¼ŒåŸºäºè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰å¼•å¯¼çš„æ ‘æœç´¢ï¼ˆtree searchï¼‰çš„å±€é™æ€§ã€‚ç ”ç©¶è€…é’ˆå¯¹23ä¸ªä¸åŒçš„æ•°å­¦é—®é¢˜ï¼Œä»¥ Qwen2.5-Math-7B-Instruct åŠå…¶å…³è”çš„ PRM ä¸ºæ¡ˆä¾‹ï¼Œè¯„ä¼°äº†é€šè¿‡æ¢ç´¢å¤šä¸ªéƒ¨åˆ†è§£è·¯å¾„æ˜¯å¦èƒ½æå‡æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡è®¡ç®—æˆæœ¬æ›´é«˜ï¼Œä½† PRM å¼•å¯¼çš„æ ‘æœç´¢åœ¨ç»Ÿè®¡å­¦ä¸Šå¹¶æœªæ˜¾ç¤ºå‡ºä¼˜äº Best-of-N (BoN) é€‰æ‹©çš„æ˜¾è‘—æ”¹è¿›ã€‚åœ¨å¤šç§æœç´¢æ–¹æ³•ä¸­ï¼Œè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte Carlo tree searchï¼‰å’ŒæŸæœç´¢ï¼ˆbeam searchï¼‰çš„è¡¨ç°ç›¸å¯¹å ä¼˜ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼ŒPRM å¯¹çŠ¶æ€ä»·å€¼ï¼ˆstate valuesï¼‰çš„è¿‘ä¼¼æ•ˆæœè¾ƒå·®ï¼Œå…¶å¯é æ€§éšæ¨ç†æ·±åº¦å¢åŠ è€Œä¸‹é™ï¼Œä¸”åœ¨åˆ†å¸ƒå¤–ï¼ˆout of distributionï¼‰è¡¨ç°å‡ºè¾ƒå¼±çš„æ³›åŒ–èƒ½åŠ›ã€‚ä½œè€…æŒ‡å‡ºï¼Œè¿™ç§æ€§èƒ½å—é™æºäºæ ‘æœç´¢å¯¹ä¸å¯é  PRM è¯„åˆ†çš„é«˜åº¦ä¾èµ–ï¼Œå¼ºè°ƒåœ¨æœ‰æ•ˆå¢å¼ºæ•°å­¦æ¨ç†å‰ï¼ŒäºŸéœ€æ”¹è¿›ç°æœ‰çš„å¥–åŠ±å»ºæ¨¡æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20272v1",
      "published_date": "2025-10-23 06:59:36 UTC",
      "updated_date": "2025-10-23 06:59:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:34.690805+00:00"
    },
    {
      "arxiv_id": "2512.08936v1",
      "title": "A Principle-based Framework for the Development and Evaluation of Large Language Models for Health and Wellness",
      "title_zh": "ç”¨äºå¥åº·ä¸åº·å…»å¤§è¯­è¨€æ¨¡å‹å¼€å‘ä¸è¯„ä¼°çš„åŸåˆ™æ€§æ¡†æ¶",
      "authors": [
        "Brent Winslow",
        "Jacqueline Shreibati",
        "Javier Perez",
        "Hao-Wei Su",
        "Nichole Young-Lin",
        "Nova Hammerquist",
        "Daniel McDuff",
        "Jason Guss",
        "Jenny Vafeiadou",
        "Nick Cain",
        "Alex Lin",
        "Erik Schenck",
        "Shiva Rajagopal",
        "Jia-Ru Chung",
        "Anusha Venkatakrishnan",
        "Amy Armento Lee",
        "Maryam Karimzadehgan",
        "Qingyou Meng",
        "Rythm Agarwal",
        "Aravind Natarajan",
        "Tracy Giest"
      ],
      "abstract": "The incorporation of generative artificial intelligence into personal health applications presents a transformative opportunity for personalized, data-driven health and fitness guidance, yet also poses challenges related to user safety, model accuracy, and personal privacy. To address these challenges, a novel, principle-based framework was developed and validated for the systematic evaluation of LLMs applied to personal health and wellness. First, the development of the Fitbit Insights explorer, a large language model (LLM)-powered system designed to help users interpret their personal health data, is described. Subsequently, the safety, helpfulness, accuracy, relevance, and personalization (SHARP) principle-based framework is introduced as an end-to-end operational methodology that integrates comprehensive evaluation techniques including human evaluation by generalists and clinical specialists, autorater assessments, and adversarial testing, into an iterative development lifecycle. Through the application of this framework to the Fitbit Insights explorer in a staged deployment involving over 13,000 consented users, challenges not apparent during initial testing were systematically identified. This process guided targeted improvements to the system and demonstrated the necessity of combining isolated technical evaluations with real-world user feedback. Finally, a comprehensive, actionable approach is established for the responsible development and deployment of LLM-powered health applications, providing a standardized methodology to foster innovation while ensuring emerging technologies are safe, effective, and trustworthy for users.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨ä¸ªäººå¥åº·åº”ç”¨ä¸­é¢ä¸´çš„å®‰å…¨ã€å‡†ç¡®æ€§åŠéšç§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºåŸåˆ™çš„å¼€å‘ä¸è¯„ä¼°æ¡†æ¶ã€‚ç ”ç©¶é¦–å…ˆä»‹ç»äº† Fitbit Insights explorer çš„å¼€å‘ï¼Œè¿™æ˜¯ä¸€æ¬¾åˆ©ç”¨ Large Language Model (LLM) è¾…åŠ©ç”¨æˆ·è§£è¯»ä¸ªäººå¥åº·æ•°æ®çš„ç³»ç»Ÿã€‚éšåï¼Œè®ºæ–‡å¼•å…¥äº† SHARP (Safety, Helpfulness, Accuracy, Relevance, and Personalization) åŸåˆ™æ¡†æ¶ï¼Œä½œä¸ºä¸€ç§æ•´åˆäº†ä¸´åºŠä¸“å®¶äººå·¥è¯„ä¼°ã€è‡ªåŠ¨è¯„ä¼° (autorater) å’Œå¯¹æŠ—æ€§æµ‹è¯• (adversarial testing) çš„ç«¯åˆ°ç«¯æ“ä½œæ–¹æ³•è®ºã€‚é€šè¿‡åœ¨è¶…è¿‡ 13,000 åç”¨æˆ·çš„é˜¶æ®µæ€§éƒ¨ç½² (staged deployment) ä¸­åº”ç”¨è¯¥æ¡†æ¶ï¼Œç ”ç©¶äººå‘˜ç³»ç»Ÿåœ°è¯†åˆ«å¹¶è§£å†³äº†åˆå§‹æµ‹è¯•ä¸­éš¾ä»¥å¯Ÿè§‰çš„é—®é¢˜ã€‚è¯¥ç ”ç©¶æœ€ç»ˆä¸ºå¥åº·é¢†åŸŸ LLM åº”ç”¨çš„è´Ÿè´£ä»»å¼€å‘ä¸éƒ¨ç½²å»ºç«‹äº†ä¸€å¥—æ ‡å‡†åŒ–æ–¹æ³•ï¼Œç¡®ä¿äº†æ–°å…´æŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€æœ‰æ•ˆæ€§ä¸å¯ä¿¡åº¦ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.08936v1",
      "published_date": "2025-10-23 06:54:33 UTC",
      "updated_date": "2025-10-23 06:54:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:35.458042+00:00"
    },
    {
      "arxiv_id": "2510.20258v1",
      "title": "Using Large Language Models for Abstraction of Planning Domains - Extended Version",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å®ç°è§„åˆ’é¢†åŸŸæŠ½è±¡â€”â€”æ‰©å±•ç‰ˆ",
      "authors": [
        "Bita Banihashemi",
        "Megh Patel",
        "Yves LespÃ©rance"
      ],
      "abstract": "Generating an abstraction of a dynamic domain that aligns with a given purpose remains a significant challenge given that the choice of such an abstraction can impact an agent's ability to plan, reason, and provide explanations effectively. We model the agent's concrete behaviors in PDDL and investigate the use of in-context learning with large language models (LLMs) for the generation of abstract PDDL domains and problem instances, given an abstraction objective specified in natural language. The benchmark examples we use are new and have not been part of the data any LLMs have been trained on. We consider three categories of abstractions: abstraction of choice of alternative concrete actions, abstraction of sequences of concrete actions, and abstraction of action/predicate parameters, as well as combinations of these. The generated abstract PDDL domains and problem instances are then checked by symbolic validation tools as well as human experts. Our experiments show that GPT-4o can generally synthesize useful planning domain abstractions in simple settings, although it is better at abstracting over actions than over the associated fluents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)åŸºäºè‡ªç„¶è¯­è¨€ç›®æ ‡ä»å…·ä½“çš„PDDLæ¨¡å‹ä¸­ç”Ÿæˆè§„åˆ’åŸŸ(planning domains)çš„æŠ½è±¡ã€‚é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ (in-context learning)æŠ€æœ¯ï¼Œè¯¥æ–¹æ³•æ—¨åœ¨è§£å†³è§„åˆ’ã€æ¨ç†å’Œè§£é‡Šä¸­å¯¹åŠ¨æ€åŸŸæŠ½è±¡çš„ç”ŸæˆæŒ‘æˆ˜ã€‚ç ”ç©¶æ¶µç›–äº†æ›¿ä»£æ€§åŠ¨ä½œã€åŠ¨ä½œåºåˆ—ä»¥åŠåŠ¨ä½œæˆ–è°“è¯å‚æ•°(action/predicate parameters)ç­‰ä¸‰ç§ä¸»è¦çš„æŠ½è±¡ç±»åˆ«ã€‚ç”Ÿæˆçš„æŠ½è±¡PDDLåŸŸå’Œé—®é¢˜å®ä¾‹ç»ç”±ç¬¦å·éªŒè¯å·¥å…·(symbolic validation tools)å’Œäººç±»ä¸“å®¶åœ¨å…¨æ–°åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4oåœ¨ç®€å•è®¾ç½®ä¸‹èƒ½å¤Ÿåˆæˆæœ‰ç”¨çš„è§„åˆ’åŸŸæŠ½è±¡ï¼Œä½†åœ¨å¤„ç†åŠ¨ä½œæŠ½è±¡æ—¶æ¯”å¤„ç†ç›¸å…³çš„çŠ¶æ€å˜é‡(fluents)è¡¨ç°æ›´ä¸ºå‡ºè‰²ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20258v1",
      "published_date": "2025-10-23 06:27:03 UTC",
      "updated_date": "2025-10-23 06:27:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:45.390903+00:00"
    },
    {
      "arxiv_id": "2510.20255v1",
      "title": "Towards AI Agents for Course Instruction in Higher Education: Early Experiences from the Field",
      "title_zh": "è¿ˆå‘é«˜ç­‰æ•™è‚²è¯¾ç¨‹æ•™å­¦çš„ AI æ™ºèƒ½ä½“ï¼šæ¥è‡ªä¸€çº¿çš„æ—©æœŸå®è·µç»éªŒ",
      "authors": [
        "Yogesh Simmhan",
        "Varad Kulkarni"
      ],
      "abstract": "This article presents early findings from designing, deploying and evaluating an AI-based educational agent deployed as the primary instructor in a graduate-level Cloud Computing course at IISc. We detail the design of a Large Language Model (LLM)-driven Instructor Agent, and introduce a pedagogical framework that integrates the Instructor Agent into the course workflow for actively interacting with the students for content delivery, supplemented by the human instructor to offer the course structure and undertake question--answer sessions. We also propose an analytical framework that evaluates the Agent--Student interaction transcripts using interpretable engagement metrics of topic coverage, topic depth and turn-level elaboration. We report early experiences on how students interact with the Agent to explore concepts, clarify doubts and sustain inquiry-driven dialogue during live classroom sessions. We also report preliminary analysis on our evaluation metrics applied across two successive instructional modules that reveals patterns of engagement evolution, transitioning from broad conceptual exploration to deeper, focused inquiry. These demonstrate how structured integration of conversational AI agents can foster reflective learning, offer a reproducible methodology for studying engagement in authentic classroom settings, and support scalable, high-quality higher education.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åœ¨é«˜ç­‰æ•™è‚²ä¸­éƒ¨ç½²AIæ™ºèƒ½ä½“è¿›è¡Œè¯¾ç¨‹æ•™å­¦çš„æ—©æœŸå®è·µï¼Œç‰¹åˆ«æ˜¯åœ¨ç ”ç©¶ç”Ÿçº§ Cloud Computing è¯¾ç¨‹ä¸­è®¾è®¡å¹¶è¯„ä¼°äº†ä¸€ä¸ªç”± Large Language Model (LLM) é©±åŠ¨çš„ Instructor Agentã€‚ç ”ç©¶æå‡ºäº†ä¸€å¥—æ•™è‚²æ¡†æ¶ï¼Œç”±æ™ºèƒ½ä½“è´Ÿè´£æ ¸å¿ƒå†…å®¹äº¤ä»˜ä¸äº’åŠ¨ï¼Œäººç±»å¯¼å¸ˆåˆ™è¾…åŠ©æä¾›è¯¾ç¨‹ç»“æ„å¹¶ä¸»æŒé—®ç­”ç¯èŠ‚ã€‚é€šè¿‡å¼•å…¥åŒ…å«ä¸»é¢˜è¦†ç›–åº¦ï¼ˆtopic coverageï¼‰ã€æ·±åº¦ï¼ˆtopic depthï¼‰å’Œè½®æ¬¡ç»†åŒ–ï¼ˆturn-level elaborationï¼‰ç­‰æŒ‡æ ‡çš„åˆ†ææ¡†æ¶ï¼Œä½œè€…å¯¹å¸ˆç”Ÿäº’åŠ¨æ–‡æœ¬è¿›è¡Œäº†é‡åŒ–è¯„ä¼°ã€‚åˆæ­¥ç»“æœæ˜¾ç¤ºï¼Œå­¦ç”Ÿèƒ½å¤Ÿåˆ©ç”¨æ™ºèƒ½ä½“è¿›è¡ŒæŒç»­çš„æ¢ç©¶é©±åŠ¨å‹å¯¹è¯ï¼Œå…¶å‚ä¸æ¨¡å¼ä»æ—©æœŸçš„å¹¿æ³›æ¦‚å¿µæ¢ç´¢è¿›åŒ–ä¸ºæ›´å…·æ·±åº¦çš„ä¸“æ³¨è¯¢é—®ã€‚è¯¥å·¥ä½œè¯æ˜äº†ç»“æ„åŒ–é›†æˆå¯¹è¯å¼ AI æ™ºèƒ½ä½“èƒ½æœ‰æ•ˆä¿ƒè¿›åæ€æ€§å­¦ä¹ ï¼Œå¹¶ä¸ºåœ¨çœŸå®è¯¾å ‚ä¸­ç ”ç©¶å­¦ç”Ÿå‚ä¸åº¦æä¾›äº†ä¸€ç§å¯å¤åˆ¶çš„æ–¹æ³•è®ºï¼Œä»è€Œä¸ºå®ç°å¯æ‰©å±•ä¸”é«˜è´¨é‡çš„é«˜ç­‰æ•™è‚²æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20255v1",
      "published_date": "2025-10-23 06:23:35 UTC",
      "updated_date": "2025-10-23 06:23:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:47.060619+00:00"
    },
    {
      "arxiv_id": "2510.20868v1",
      "title": "Crisis-Resilient Portfolio Management via Graph-based Spatio-Temporal Learning",
      "title_zh": "åŸºäºå›¾æ—¶ç©ºå­¦ä¹ çš„æŠ—å±æœºæŠ•èµ„ç»„åˆç®¡ç†",
      "authors": [
        "Zan Li",
        "Rui Fan"
      ],
      "abstract": "Financial time series forecasting faces a fundamental challenge: predicting optimal asset allocations requires understanding regime-dependent correlation structures that transform during crisis periods. Existing graph-based spatio-temporal learning approaches rely on predetermined graph topologies--correlation thresholds, sector classifications--that fail to adapt when market dynamics shift across different crisis mechanisms: credit contagion, pandemic shocks, or inflation-driven selloffs.\n  We present CRISP (Crisis-Resilient Investment through Spatio-temporal Patterns), a graph-based spatio-temporal learning framework that encodes spatial relationships via Graph Convolutional Networks and temporal dynamics via BiLSTM with self-attention, then learns sparse structures through multi-head Graph Attention Networks. Unlike fixed-topology methods, CRISP discovers which asset relationships matter through attention mechanisms, filtering 92.5% of connections as noise while preserving crisis-relevant dependencies for accurate regime-specific predictions.\n  Trained on 2005--2021 data encompassing credit and pandemic crises, CRISP demonstrates robust generalization to 2022--2024 inflation-driven markets--a fundamentally different regime--by accurately forecasting regime-appropriate correlation structures. This enables adaptive portfolio allocation that maintains profitability during downturns, achieving Sharpe ratio 3.76: 707% improvement over equal-weight baselines and 94% improvement over static graph methods. Learned attention weights provide interpretable regime detection, with defensive cluster attention strengthening 49% during crises versus 31% market-wide--emergent behavior from learning to forecast rather than imposing assumptions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CRISP (Crisis-Resilient Investment through Spatio-temporal Patterns)ï¼Œä¸€ç§åŸºäºå›¾çš„æ—¶ç©ºå­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é‡‘èæ—¶é—´åºåˆ—é¢„æµ‹ä¸­å›ºå®šå›¾æ‹“æ‰‘æ— æ³•é€‚åº”å¸‚åœºå±æœºæœŸé—´åŠ¨æ€å˜åŒ–çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨Graph Convolutional Networks (GCN)ç¼–ç ç©ºé—´å…³ç³»ï¼Œé€šè¿‡BiLSTMä¸self-attentionæ•æ‰æ—¶é—´åŠ¨æ€ï¼Œå¹¶é‡‡ç”¨multi-head Graph Attention Networkså­¦ä¹ ç¨€ç–ç»“æ„ä»¥è¿‡æ»¤92.5%çš„å™ªå£°è¿æ¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCRISPåœ¨ç»å†ä¿¡ç”¨å’Œç–«æƒ…å±æœºçš„å†å²æ•°æ®è®­ç»ƒåï¼Œèƒ½æœ‰æ•ˆæ³›åŒ–è‡³é€šèƒ€é©±åŠ¨çš„æ–°å¸‚åœºç¯å¢ƒï¼Œå…¶Sharpe ratioè¾¾åˆ°3.76ï¼Œè¾ƒç­‰æƒé‡åŸºå‡†æå‡äº†707%ã€‚æ­¤å¤–ï¼Œæ¨¡å‹å­¦ä¹ åˆ°çš„æ³¨æ„åŠ›æƒé‡ä¸ºä½“åˆ¶æ£€æµ‹æä¾›äº†å¯è§£é‡Šæ€§ï¼Œå±•ç¤ºäº†é˜²å¾¡æ€§èµ„äº§é›†ç¾¤åœ¨å±æœºæœŸé—´å…³æ³¨åº¦æ˜¾è‘—å¢å¼ºçš„ç°è±¡ã€‚è¿™ç§æ•°æ®é©±åŠ¨çš„é¢„æµ‹æ–¹æ³•ä¸ºæ„å»ºå…·å¤‡å±æœºæŠµå¾¡èƒ½åŠ›çš„æŠ•èµ„ç»„åˆç®¡ç†æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20868v1",
      "published_date": "2025-10-23 06:23:15 UTC",
      "updated_date": "2025-10-23 06:23:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:53.858849+00:00"
    },
    {
      "arxiv_id": "2510.20252v1",
      "title": "Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸­çš„ä¸ªæ€§åŒ–è®¤çŸ¥æ¨¡æ‹Ÿï¼šä¸åŒè®¤çŸ¥è¡¨å¾æ–¹æ³•çš„è¯„ä¼°",
      "authors": [
        "Tianyi Zhang",
        "Xiaolin Zhou",
        "Yunzhe Wang",
        "Erik Cambria",
        "David Traum",
        "Rui Mao"
      ],
      "abstract": "Individualized cognitive simulation (ICS) aims to build computational models that approximate the thought processes of specific individuals. While large language models (LLMs) convincingly mimic surface-level human behavior such as role-play, their ability to simulate deeper individualized cognitive processes remains poorly understood. To address this gap, we introduce a novel task that evaluates different cognitive representation methods in ICS. We construct a dataset from recently published novels (later than the release date of the tested LLMs) and propose an 11-condition cognitive evaluation framework to benchmark seven off-the-shelf LLMs in the context of authorial style emulation. We hypothesize that effective cognitive representations can help LLMs generate storytelling that better mirrors the original author. Thus, we test different cognitive representations, e.g., linguistic features, concept mappings, and profile-based information. Results show that combining conceptual and linguistic features is particularly effective in ICS, outperforming static profile-based cues in overall evaluation. Importantly, LLMs are more effective at mimicking linguistic style than narrative structure, underscoring their limits in deeper cognitive simulation. These findings provide a foundation for developing AI systems that adapt to individual ways of thinking and expression, advancing more personalized and human-aligned creative technologies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸ªæ€§åŒ–è®¤çŸ¥æ¨¡æ‹Ÿ(Individualized Cognitive Simulation)é¢†åŸŸï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)æ„å»ºèƒ½å¤Ÿé€¼è¿‘ç‰¹å®šä¸ªä½“æ€ç»´è¿‡ç¨‹çš„è®¡ç®—æ¨¡å‹ã€‚ä¸ºäº†è¯„ä¼°æ¨¡å‹æ¨¡æ‹Ÿæ·±å±‚è®¤çŸ¥çš„èƒ½åŠ›ï¼Œç ”ç©¶è€…åˆ©ç”¨æœ€æ–°å°è¯´æ„å»ºäº†æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†åŒ…å«11ä¸ªæ¡ä»¶çš„è®¤çŸ¥è¯„ä¼°æ¡†æ¶ï¼Œå¯¹ä¸ƒç§ä¸»æµæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚é€šè¿‡æµ‹è¯•è¯­è¨€ç‰¹å¾(linguistic features)ã€æ¦‚å¿µæ˜ å°„(concept mappings)å’ŒåŸºäºç”»åƒçš„ä¿¡æ¯(profile-based information)ç­‰ä¸åŒè®¤çŸ¥è¡¨ç¤ºæ–¹æ³•ï¼Œç ”ç©¶å‘ç°ç»“åˆæ¦‚å¿µä¸è¯­è¨€ç‰¹å¾çš„æ–¹æ³•åœ¨æ¨¡æ‹Ÿæ•ˆæœä¸Šä¼˜äºä¼ ç»Ÿçš„é™æ€ç”»åƒæç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›®å‰çš„LLMsåœ¨æ¨¡ä»¿è¯­è¨€é£æ ¼æ–¹é¢è¡¨ç°è¾ƒå¥½ï¼Œä½†åœ¨å™äº‹ç»“æ„ç­‰æ·±å±‚è®¤çŸ¥æ¨¡æ‹Ÿä¸Šä»å­˜åœ¨æ˜æ˜¾å±€é™ã€‚è¿™äº›å‘ç°ä¸ºå¼€å‘èƒ½å¤Ÿé€‚åº”ä¸ªäººæ€ç»´æ–¹å¼ã€ä¿ƒè¿›ä¸ªæ€§åŒ–ä¸”ä¸äººç±»å¯¹é½(human-aligned)çš„åˆ›æ„æŠ€æœ¯æä¾›äº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20252v1",
      "published_date": "2025-10-23 06:18:15 UTC",
      "updated_date": "2025-10-23 06:18:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:52.968436+00:00"
    },
    {
      "arxiv_id": "2510.20867v1",
      "title": "Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards",
      "title_zh": "é€šè¿‡æ¨ç†è¿‡ç¨‹å¥–åŠ±åœ¨éŸ³é¢‘å¤§è¯­è¨€æ¨¡å‹ä¸­æ¿€åŠ±ä¸€è‡´ã€æœ‰æ•ˆä¸”å¯æ‰©å±•çš„æ¨ç†èƒ½åŠ›",
      "authors": [
        "Jiajun Fan",
        "Roger Ren",
        "Jingyuan Li",
        "Rahul Pandey",
        "Prashanth Gurunath Shivakumar",
        "Ivan Bulyko",
        "Ankur Gandhe",
        "Ge Liu",
        "Yile Gu"
      ],
      "abstract": "The role of reasoning in Audio Large Language Models remains widely underexplored, as introducing a reasoning process often degrades rather than improves performance during inference, a phenomenon we term test-time inverse scaling, where longer reasoning chains yield progressively worse results. We demonstrate that this stems not from fundamental limitations of reasoning itself, but from inadequate training: models without proper guidance for the reasoning process produce hallucinatory, inconsistent reasoning that accumulates errors over longer chains. To address these challenges, we introduce CESAR (Consistent, Effective, and Scalable Audio Reasoners), shifting from outcome verification to rewarding the reasoning process. Our online reinforcement learning framework employs Group Relative Policy Optimization with a multi-faceted reward suite that incentivizes not only correctness and format but also consistency, structured analytical patterns, causal reasoning, domain-knowledge integration, and calibrated reasoning depth. CESAR resolves test-time inverse scaling, transforming reasoning from detriments into gains while revealing model-specific ``reasoning sweet spots\", where performance peaks during test-time scaling. We achieve state-of-the-art results on MMAU Test-mini, substantially outperforming Gemini 2.5 Pro and GPT-4o Audio, and near-human-level performance on MMSU reasoning tasks. Through AI-as-judge evaluations and qualitative comparisons, we provide both quantitative and qualitative validation of our improved reasoning quality. Importantly, enhanced reasoning creates synergistic effects, simultaneously improving multimodal reasoning and perception capabilities. Overall, CESAR establishes a principled method for developing robust and scalable reasoning in Audio LLMs.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹éŸ³é¢‘å¤§è¯­è¨€æ¨¡å‹(Audio LLMs)åœ¨æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°çš„â€œæµ‹è¯•æ—¶åå‘æ‰©å±•â€(test-time inverse scaling)ç°è±¡è¿›è¡Œäº†æ·±å…¥æ¢è®¨ï¼Œå³æ›´é•¿çš„æ¨ç†é“¾åè€Œå¯¼è‡´æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚ä½œè€…æŒ‡å‡ºè¿™ä¸€ç°è±¡çš„æ ¹æºåœ¨äºè®­ç»ƒè¿‡ç¨‹ä¸­ç¼ºä¹å¯¹æ¨ç†è¿‡ç¨‹çš„æœ‰æ•ˆå¼•å¯¼ï¼Œå¯¼è‡´æ¨¡å‹äº§ç”Ÿå¹»è§‰å’Œä¸ä¸€è‡´çš„æ¨ç†ï¼Œä¸ºæ­¤æå‡ºäº†CESAR (Consistent, Effective, and Scalable Audio Reasoners)æ¡†æ¶ã€‚CESARå°†ä¼˜åŒ–é‡ç‚¹ä»ç»“æœéªŒè¯è½¬å‘æ¨ç†è¿‡ç¨‹å¥–åŠ±ï¼Œé‡‡ç”¨åŸºäºGroup Relative Policy Optimization (GRPO)çš„åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡å¤šç»´åº¦çš„å¥–åŠ±ä½“ç³»æ¿€åŠ±æ¨¡å‹äº§ç”Ÿå…·æœ‰ä¸€è‡´æ€§ã€å› æœé€»è¾‘å’Œé¢†åŸŸçŸ¥è¯†æ”¯æ’‘çš„æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCESARæˆåŠŸè§£å†³äº†åå‘æ‰©å±•é—®é¢˜ï¼Œå¹¶åœ¨MMAU Test-miniæ¦œå•ä¸Šæ˜¾è‘—è¶…è¶Šäº†Gemini 2.5 Proå’ŒGPT-4o Audioï¼Œåœ¨MMSUæ¨ç†ä»»åŠ¡ä¸­è¾¾åˆ°äº†æ¥è¿‘äººç±»æ°´å¹³çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°å¢å¼ºçš„æ¨ç†èƒ½åŠ›äº§ç”Ÿäº†ååŒæ•ˆåº”ï¼Œèƒ½åŒæ­¥æå‡æ¨¡å‹çš„å¤šæ¨¡æ€æ¨ç†ä¸æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥å·¥ä½œä¸ºæ„å»ºç¨³å¥ä¸”å¯æ‰©å±•çš„Audio LLMsæ¨ç†èƒ½åŠ›æä¾›äº†ä¸€ç§ç³»ç»Ÿæ€§çš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "49 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.20867v1",
      "published_date": "2025-10-23 06:18:10 UTC",
      "updated_date": "2025-10-23 06:18:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:19:55.856794+00:00"
    },
    {
      "arxiv_id": "2510.20242v2",
      "title": "What Does It Take to Build a Performant Selective Classifier?",
      "title_zh": "å¦‚ä½•æ„å»ºé«˜æ€§èƒ½çš„é€‰æ‹©æ€§åˆ†ç±»å™¨ï¼Ÿ",
      "authors": [
        "Stephan Rabanser",
        "Nicolas Papernot"
      ],
      "abstract": "Selective classifiers improve model reliability by abstaining on inputs the model deems uncertain. However, few practical approaches achieve the gold-standard performance of a perfect-ordering oracle that accepts examples exactly in order of correctness. Our work formalizes this shortfall as the selective-classification gap and present the first finite-sample decomposition of this gap to five distinct sources of looseness: Bayes noise, approximation error, ranking error, statistical noise, and implementation- or shift-induced slack. Crucially, our analysis reveals that monotone post-hoc calibration -- often believed to strengthen selective classifiers -- has limited impact on closing this gap, since it rarely alters the model's underlying score ranking. Bridging the gap therefore requires scoring mechanisms that can effectively reorder predictions rather than merely rescale them. We validate our decomposition on synthetic two-moons data and on real-world vision and language benchmarks, isolating each error component through controlled experiments. Our results confirm that (i) Bayes noise and limited model capacity can account for substantial gaps, (ii) only richer, feature-aware calibrators meaningfully improve score ordering, and (iii) data shift introduces a separate slack that demands distributionally robust training. Together, our decomposition yields a quantitative error budget as well as actionable design guidelines that practitioners can use to build selective classifiers which approximate ideal oracle behavior more closely.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶æ¢è®¨äº†å¦‚ä½•æ„å»ºé«˜æ€§èƒ½çš„é€‰æ‹©æ€§åˆ†ç±»å™¨(Selective Classifier)ï¼Œé€šè¿‡åœ¨æ¨¡å‹ä¸ç¡®å®šæ—¶æ‹’ç»é¢„æµ‹æ¥æå‡ç³»ç»Ÿçš„å¯é æ€§ã€‚ä½œè€…æ­£å¼å®šä¹‰äº†é€‰æ‹©æ€§åˆ†ç±»é—´éš™(selective-classification gap)ï¼Œå³å®é™…æ€§èƒ½ä¸ç†æƒ³æ’åºé¢„è¨€æœº(perfect-ordering oracle)ä¹‹é—´çš„å·®è·ï¼Œå¹¶é¦–æ¬¡å°†å…¶åˆ†è§£ä¸ºè´å¶æ–¯å™ªå£°(Bayes noise)ã€è¿‘ä¼¼è¯¯å·®(approximation error)ã€æ’åºè¯¯å·®(ranking error)ã€ç»Ÿè®¡å™ªå£°(statistical noise)ä»¥åŠç”±å®ç°æˆ–åç§»å¯¼è‡´çš„æ¾å¼›(slack)äº”ä¸ªæ¥æºã€‚åˆ†æè¡¨æ˜ï¼Œå¸¸ç”¨çš„å•è°ƒäº‹åæ ¡å‡†(monotone post-hoc calibration)å¯¹ç¼©å°è¯¥é—´éš™çš„ä½œç”¨æœ‰é™ï¼Œå› ä¸ºå…¶å¾ˆå°‘æ”¹å˜æ¨¡å‹åº•å±‚çš„å¾—åˆ†æ’åº(score ranking)ï¼Œå› æ­¤ç¼©å°é—´éš™éœ€è¦èƒ½å¤Ÿæœ‰æ•ˆé‡æ–°æ’åº(reorder)é¢„æµ‹çš„æœºåˆ¶ã€‚é€šè¿‡åœ¨åˆæˆæ•°æ®åŠçœŸå®è§†è§‰å’Œè¯­è¨€åŸºå‡†ä¸Šçš„å®éªŒï¼Œç ”ç©¶è¯å®äº†è´å¶æ–¯å™ªå£°å’Œæ¨¡å‹å®¹é‡å¯¹é—´éš™çš„æ˜¾è‘—å½±å“ï¼Œå¹¶æŒ‡å‡ºåªæœ‰ç‰¹å¾æ„ŸçŸ¥æ ¡å‡†å™¨(feature-aware calibrators)èƒ½æœ‰æ•ˆæ”¹å–„æ’åºã€‚æ­¤å¤–ï¼Œé’ˆå¯¹æ•°æ®åç§»(data shift)å¼•å‘çš„æ¾å¼›ï¼Œç ”ç©¶å¼ºè°ƒäº†åˆ†å¸ƒç¨³å¥è®­ç»ƒ(distributionally robust training)çš„å¿…è¦æ€§ã€‚è¯¥å·¥ä½œæœ€ç»ˆä¸ºå¼€å‘è€…æä¾›äº†é‡åŒ–çš„è¯¯å·®é¢„ç®—(error budget)å’Œè®¾è®¡æŒ‡å—ï¼ŒåŠ©åŠ›æ„å»ºæ›´æ¥è¿‘ç†æƒ³æ€§èƒ½çš„é€‰æ‹©æ€§åˆ†ç±»å™¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.20242v2",
      "published_date": "2025-10-23 05:48:40 UTC",
      "updated_date": "2025-10-24 01:27:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:29.359157+00:00"
    },
    {
      "arxiv_id": "2510.20239v1",
      "title": "Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders",
      "title_zh": "èåˆä¸¥é‡ç¨‹åº¦ä¿¡æ¯çš„æŠ‘éƒç—‡ä¸åˆ›ä¼¤ååº”æ¿€éšœç¢è·¨ç—…ç§ä¸‰æ¨¡æ€è¯Šæ–­",
      "authors": [
        "Filippo Cenacchi",
        "Deborah Richards",
        "Longbing Cao"
      ],
      "abstract": "Depression and post traumatic stress disorder (PTSD) often co-occur with connected symptoms, complicating automated assessment, which is often binary and disorder specific. Clinically useful diagnosis needs severity aware cross disorder estimates and decision support explanations. Our unified tri modal affective severity framework synchronizes and fuses interview text with sentence level transformer embeddings, audio with log Mel statistics with deltas, and facial signals with action units, gaze, head and pose descriptors to output graded severities for diagnosing both depression (PHQ-8; 5 classes) and PTSD (3 classes). Standardized features are fused via a calibrated late fusion classifier, yielding per disorder probabilities and feature-level attributions. This severity aware tri-modal affective fusion approach is demoed on multi disorder concurrent depression and PTSD assessment. Stratified cross validation on DAIC derived corpora outperforms unimodal/ablation baselines. The fused model matches the strongest unimodal baseline on accuracy and weighted F1, while improving decision curve utility and robustness under noisy or missing modalities. For PTSD specifically, fusion reduces regression error and improves class concordance. Errors cluster between adjacent severities; extreme classes are identified reliably. Ablations show text contributes most to depression severity, audio and facial cues are critical for PTSD, whereas attributions align with linguistic and behavioral markers. Our approach offers reproducible evaluation and clinician in the loop support for affective clinical decision making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ä¸‰æ¨¡æ€æƒ…æ„Ÿä¸¥é‡ç¨‹åº¦è¯„ä¼°æ¡†æ¶(unified tri-modal affective severity framework)ï¼Œæ—¨åœ¨è§£å†³æŠ‘éƒç—‡(Depression)å’Œåˆ›ä¼¤ååº”æ¿€éšœç¢(PTSD)å…±ç—…å¯¼è‡´çš„è‡ªåŠ¨åŒ–è¯„ä¼°éš¾é¢˜ã€‚è¯¥æ¡†æ¶åŒæ­¥å¹¶èåˆäº†è®¿è°ˆæ–‡æœ¬ã€éŸ³é¢‘å’Œé¢éƒ¨ä¿¡å·ï¼Œåˆ©ç”¨å¥å­çº§TransformeråµŒå…¥ã€log Melç»Ÿè®¡é‡åŠé¢éƒ¨åŠ¨ä½œå•å…ƒç­‰ç‰¹å¾ï¼Œé€šè¿‡æ ¡å‡†çš„åæœŸèåˆåˆ†ç±»å™¨(calibrated late fusion classifier)è¾“å‡ºåˆ†çº§çš„ä¸¥é‡ç¨‹åº¦é¢„æµ‹ã€‚åœ¨DAICè¡ç”Ÿè¯­æ–™åº“ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥èåˆæ¨¡å‹åœ¨å‡†ç¡®ç‡å’Œé²æ£’æ€§ä¸Šå‡ä¼˜äºå•æ¨¡æ€åŸºçº¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†æ¨¡æ€ç¼ºå¤±æˆ–å™ªå£°å¹²æ‰°æ—¶è¡¨ç°æ›´ä½³ã€‚æ¶ˆèå®éªŒæ˜¾ç¤ºï¼Œæ–‡æœ¬æ¨¡æ€å¯¹æŠ‘éƒç—‡ä¸¥é‡ç¨‹åº¦è´¡çŒ®æœ€å¤§ï¼Œè€ŒéŸ³é¢‘å’Œé¢éƒ¨çº¿ç´¢å¯¹PTSDçš„è¯Šæ–­è‡³å…³é‡è¦ã€‚è¯¥æ–¹æ³•é€šè¿‡ç‰¹å¾çº§å½’å› æä¾›äº†ç¬¦åˆä¸´åºŠè¡¨ç°çš„å¯è§£é‡Šæ€§ï¼Œä¸ºæƒ…æ„Ÿä¸´åºŠå†³ç­–æä¾›äº†å¯é‡å¤çš„è¯„ä¼°å’Œäººæœºåä½œæ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20239v1",
      "published_date": "2025-10-23 05:46:38 UTC",
      "updated_date": "2025-10-23 05:46:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:15.161602+00:00"
    },
    {
      "arxiv_id": "2510.20235v1",
      "title": "Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach",
      "title_zh": "åŸºäºæœ€å¤§æœ€å°å‡†åˆ™çš„å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ï¼šä¸€ç§åšå¼ˆè®ºæ–¹æ³•",
      "authors": [
        "Woohyeon Byeon",
        "Giseung Park",
        "Jongseong Chae",
        "Amir Leshem",
        "Youngchul Sung"
      ],
      "abstract": "In this paper, we propose a provably convergent and practical framework for multi-objective reinforcement learning with max-min criterion. From a game-theoretic perspective, we reformulate max-min multi-objective reinforcement learning as a two-player zero-sum regularized continuous game and introduce an efficient algorithm based on mirror descent. Our approach simplifies the policy update while ensuring global last-iterate convergence. We provide a comprehensive theoretical analysis on our algorithm, including iteration complexity under both exact and approximate policy evaluations, as well as sample complexity bounds. To further enhance performance, we modify the proposed algorithm with adaptive regularization. Our experiments demonstrate the convergence behavior of the proposed algorithm in tabular settings, and our implementation for deep reinforcement learning significantly outperforms previous baselines in many MORL environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·æœ‰ Max-Min Criterion çš„å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹  (Multi-Objective Reinforcement Learning, MORL) æå‡ºäº†ä¸€ä¸ªå¯è¯æ˜æ”¶æ•›ä¸”å®ç”¨çš„æ¡†æ¶ã€‚ä»åšå¼ˆè®º (Game-Theoretic) çš„è§’åº¦å‡ºå‘ï¼Œç ”ç©¶è€…å°† Max-Min MORL é‡æ–°è¡¨è¿°ä¸ºåŒäººé›¶å’Œæ­£åˆ™åŒ–è¿ç»­åšå¼ˆ (Two-Player Zero-Sum Regularized Continuous Game)ï¼Œå¹¶å¼•å…¥äº†åŸºäºé•œåƒä¸‹é™ (Mirror Descent) çš„é«˜æ•ˆç®—æ³•ã€‚è¯¥æ–¹æ³•åœ¨ç®€åŒ–ç­–ç•¥æ›´æ–°çš„åŒæ—¶ï¼Œç¡®ä¿äº†å…¨å±€æœ€åè¿­ä»£æ”¶æ•›æ€§ (Global Last-Iterate Convergence)ï¼Œå¹¶æä¾›äº†æ¶µç›–è¿­ä»£å¤æ‚åº¦å’Œæ ·æœ¬å¤æ‚åº¦è¾¹ç•Œçš„å…¨é¢ç†è®ºåˆ†æã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºæ€§èƒ½ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†è‡ªé€‚åº”æ­£åˆ™åŒ– (Adaptive Regularization) æŠ€æœ¯ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥ç®—æ³•åœ¨è¡¨æ ¼è®¾ç½®ä¸­å±•ç°å‡ºä¼˜å¼‚çš„æ”¶æ•›è¡Œä¸ºï¼Œå…¶æ·±åº¦å¼ºåŒ–å­¦ä¹ å®ç°åœ¨å¤šä¸ª MORL ç¯å¢ƒä¸­å‡æ˜¾è‘—ä¼˜äºå…ˆå‰çš„åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.20235v1",
      "published_date": "2025-10-23 05:39:26 UTC",
      "updated_date": "2025-10-23 05:39:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:12.561296+00:00"
    },
    {
      "arxiv_id": "2510.20229v1",
      "title": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context",
      "title_zh": "ä¸ºä»€ä¹ˆ LVLMs åœ¨é•¿å›å¤ä¸­æ›´å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼šä¸Šä¸‹æ–‡çš„ä½œç”¨",
      "authors": [
        "Ge Zheng",
        "Jiaye Qian",
        "Jiajin Tang",
        "Sibei Yang"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have made significant progress in recent years but are also prone to hallucination issues. They exhibit more hallucinations in longer, free-form responses, often attributed to accumulated uncertainties. In this paper, we ask: Does increased hallucination result solely from length-induced errors, or is there a deeper underlying mechanism? After a series of preliminary experiments and findings, we suggest that the risk of hallucinations is not caused by length itself but by the increased reliance on context for coherence and completeness in longer responses. Building on these insights, we propose a novel \"induce-detect-suppress\" framework that actively induces hallucinations through deliberately designed contexts, leverages induced instances for early detection of high-risk cases, and ultimately suppresses potential object-level hallucinations during actual decoding. Our approach achieves consistent, significant improvements across all benchmarks, demonstrating its efficacy. The strong detection and improved hallucination mitigation not only validate our framework but, more importantly, re-validate our hypothesis on context. Rather than solely pursuing performance gains, this study aims to provide new insights and serves as a first step toward a deeper exploration of hallucinations in LVLMs' longer responses.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Large Vision-Language Models (LVLMs) åœ¨ç”Ÿæˆé•¿å›å¤æ—¶æ›´å®¹æ˜“äº§ç”Ÿå¹»è§‰(Hallucinations)çš„æ·±å±‚åŸå› ï¼ŒæŒ‡å‡ºå…¶æ ¸å¿ƒè¯±å› å¹¶éå›å¤é•¿åº¦æœ¬èº«ï¼Œè€Œæ˜¯æ¨¡å‹ä¸ºç»´æŒè¿è´¯æ€§å¯¹ä¸Šä¸‹æ–‡(Context)çš„ä¾èµ–æ˜¾è‘—å¢åŠ ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º\"induce-detect-suppress\"çš„æ–°å‹æ¡†æ¶ï¼Œé€šè¿‡è®¾è®¡ç‰¹å®šä¸Šä¸‹æ–‡ä¸»åŠ¨è¯±å¯¼å¹»è§‰ï¼Œè¿›è€Œå®ç°é«˜é£é™©æ¡ˆä¾‹çš„æ—©æœŸæ£€æµ‹ã€‚è¯¥æ¡†æ¶åœ¨å®é™…è§£ç é˜¶æ®µèƒ½æœ‰æ•ˆæŠ‘åˆ¶å¯¹è±¡çº§(Object-level)å¹»è§‰çš„äº§ç”Ÿï¼Œå®éªŒè¯æ˜å…¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—ä¸”ä¸€è‡´çš„æ€§èƒ½æ”¹è¿›ã€‚è¿™é¡¹å·¥ä½œä¸ä»…éªŒè¯äº†å…³äºä¸Šä¸‹æ–‡ä½œç”¨çš„ç§‘å­¦å‡è®¾ï¼Œè¿˜ä¸ºæ·±å…¥æ¢ç´¢LVLMsé•¿æ–‡æœ¬ç”Ÿæˆä¸­çš„å¹»è§‰æœºåˆ¶æä¾›äº†æ–°çš„ç†è®ºè§†è§’å’ŒæŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20229v1",
      "published_date": "2025-10-23 05:22:07 UTC",
      "updated_date": "2025-10-23 05:22:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:17.869561+00:00"
    },
    {
      "arxiv_id": "2510.20225v1",
      "title": "Federated Learning via Meta-Variational Dropout",
      "title_zh": "åŸºäºå…ƒå˜åˆ†ä¸¢å¼ƒçš„è”é‚¦å­¦ä¹ ",
      "authors": [
        "Insu Jeon",
        "Minui Hong",
        "Junhyeog Yun",
        "Gunhee Kim"
      ],
      "abstract": "Federated Learning (FL) aims to train a global inference model from remotely distributed clients, gaining popularity due to its benefit of improving data privacy. However, traditional FL often faces challenges in practical applications, including model overfitting and divergent local models due to limited and non-IID data among clients. To address these issues, we introduce a novel Bayesian meta-learning approach called meta-variational dropout (MetaVD). MetaVD learns to predict client-dependent dropout rates via a shared hypernetwork, enabling effective model personalization of FL algorithms in limited non-IID data settings. We also emphasize the posterior adaptation view of meta-learning and the posterior aggregation view of Bayesian FL via the conditional dropout posterior. We conducted extensive experiments on various sparse and non-IID FL datasets. MetaVD demonstrated excellent classification accuracy and uncertainty calibration performance, especially for out-of-distribution (OOD) clients. MetaVD compresses the local model parameters needed for each client, mitigating model overfitting and reducing communication costs. Code is available at https://github.com/insujeon/MetaVD.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”é‚¦å­¦ä¹ ï¼ˆFederated Learningï¼‰ä¸­ç”±äºå®¢æˆ·ç«¯æ•°æ®æœ‰é™ä¸”éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰å¯¼è‡´çš„æ¨¡å‹è¿‡æ‹Ÿåˆå’Œå±€éƒ¨æ¨¡å‹åˆ†æ­§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Meta-Variational Dropout (MetaVD) çš„æ–°å‹è´å¶æ–¯å…ƒå­¦ä¹ ï¼ˆBayesian meta-learningï¼‰æ–¹æ³•ã€‚MetaVD é€šè¿‡å…±äº«çš„è¶…ç½‘ç»œï¼ˆhypernetworkï¼‰å­¦ä¹ é¢„æµ‹å„å®¢æˆ·ç«¯ç‰¹æœ‰çš„ Dropout é€Ÿç‡ï¼Œä»è€Œåœ¨æ•°æ®å—é™çš„åœºæ™¯ä¸‹å®ç°äº†æœ‰æ•ˆçš„æ¨¡å‹ä¸ªæ€§åŒ–ã€‚è¯¥æ–¹æ³•èåˆäº†å…ƒå­¦ä¹ çš„åéªŒè‡ªé€‚åº”ï¼ˆposterior adaptationï¼‰ä¸è´å¶æ–¯è”é‚¦å­¦ä¹ çš„åéªŒèšåˆï¼ˆposterior aggregationï¼‰è§†è§’ï¼Œé€šè¿‡æ¡ä»¶ Dropout åéªŒå¢å¼ºæ¨¡å‹æ€§èƒ½ã€‚åœ¨å¤šç§ç¨€ç–å’Œéç‹¬ç«‹åŒåˆ†å¸ƒæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒMetaVD åœ¨åˆ†ç±»å‡†ç¡®ç‡å’Œä¸ç¡®å®šæ€§æ ¡å‡†ï¼ˆuncertainty calibrationï¼‰æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨å¤„ç†åˆ†å¸ƒå¤–ï¼ˆOODï¼‰å®¢æˆ·ç«¯æ—¶ä¼˜åŠ¿æ˜æ˜¾ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é€šè¿‡å‹ç¼©å±€éƒ¨æ¨¡å‹å‚æ•°ï¼Œåœ¨ç¼“è§£è¿‡æ‹Ÿåˆçš„åŒæ—¶æœ‰æ•ˆé™ä½äº†é€šä¿¡æˆæœ¬ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Proceedings of the Advances in Neural Information Processing Systems (NeurIPS) 2023, Main Conference Track",
      "pdf_url": "https://arxiv.org/pdf/2510.20225v1",
      "published_date": "2025-10-23 05:17:40 UTC",
      "updated_date": "2025-10-23 05:17:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:28.800697+00:00"
    },
    {
      "arxiv_id": "2510.23577v1",
      "title": "TAMI: Taming Heterogeneity in Temporal Interactions for Temporal Graph Link Prediction",
      "title_zh": "TAMIï¼šåº”å¯¹æ—¶åºäº¤äº’å¼‚è´¨æ€§çš„æ—¶åºå›¾é“¾æ¥é¢„æµ‹",
      "authors": [
        "Zhongyi Yu",
        "Jianqiu Wu",
        "Zhenghao Wu",
        "Shuhan Zhong",
        "Weifeng Su",
        "Chul-Ho Lee",
        "Weipeng Zhuo"
      ],
      "abstract": "Temporal graph link prediction aims to predict future interactions between nodes in a graph based on their historical interactions, which are encoded in node embeddings. We observe that heterogeneity naturally appears in temporal interactions, e.g., a few node pairs can make most interaction events, and interaction events happen at varying intervals. This leads to the problems of ineffective temporal information encoding and forgetting of past interactions for a pair of nodes that interact intermittently for their link prediction. Existing methods, however, do not consider such heterogeneity in their learning process, and thus their learned temporal node embeddings are less effective, especially when predicting the links for infrequently interacting node pairs. To cope with the heterogeneity, we propose a novel framework called TAMI, which contains two effective components, namely log time encoding function (LTE) and link history aggregation (LHA). LTE better encodes the temporal information through transforming interaction intervals into more balanced ones, and LHA prevents the historical interactions for each target node pair from being forgotten. State-of-the-art temporal graph neural networks can be seamlessly and readily integrated into TAMI to improve their effectiveness. Experiment results on 13 classic datasets and three newest temporal graph benchmark (TGB) datasets show that TAMI consistently improves the link prediction performance of the underlying models in both transductive and inductive settings. Our code is available at https://github.com/Alleinx/TAMI_temporal_graph.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ¨æ€å›¾é“¾æ¥é¢„æµ‹(Temporal Graph Link Prediction)ä¸­äº¤äº’è¡Œä¸ºå­˜åœ¨çš„å¼‚æ„æ€§(heterogeneity)é—®é¢˜ï¼Œæå‡ºäº†å…¨æ–°çš„ TAMI æ¡†æ¶ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œäº¤äº’é¢‘ç‡åˆ†å¸ƒä¸å‡åŠé—´éš”å·®å¼‚ä¼šå¯¼è‡´æ—¶é—´ä¿¡æ¯ç¼–ç æ•ˆç‡ä½ä¸‹ï¼Œå¹¶ä½¿æ¨¡å‹å®¹æ˜“é—å¿˜éé¢‘ç¹äº¤äº’èŠ‚ç‚¹å¯¹çš„å†å²ä¿¡æ¯ã€‚TAMI æ¡†æ¶åŒ…å«å¯¹æ•°æ—¶é—´ç¼–ç å‡½æ•°(Log Time Encoding, LTE)å’Œé“¾æ¥å†å²èšåˆ(Link History Aggregation, LHA)ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œåˆ†åˆ«ç”¨äºå¹³è¡¡æ—¶é—´é—´éš”åˆ†å¸ƒå’Œä¿å­˜ç›®æ ‡èŠ‚ç‚¹å¯¹çš„å†å²äº¤äº’ç‰¹å¾ã€‚è¯¥æ¡†æ¶å¯æ— ç¼é›†æˆåˆ°ç°æœ‰çš„åŠ¨æ€å›¾ç¥ç»ç½‘ç»œ(Temporal Graph Neural Networks)ä¸­ï¼Œæœ‰æ•ˆå¢å¼ºäº†æ¨¡å‹æ•è·å¤æ‚åŠ¨æ€æ¨¡å¼çš„èƒ½åŠ›ã€‚åœ¨ 13 ä¸ªç»å…¸æ•°æ®é›†å’Œ 3 ä¸ª TGB æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒTAMI åœ¨è½¬å¯¼(transductive)å’Œå½’çº³(inductive)é¢„æµ‹åœºæ™¯ä¸‹å‡èƒ½ç¨³å®šæå‡æ€§èƒ½ã€‚è¿™ä¸€ç ”ç©¶ä¸ºè§£å†³åŠ¨æ€å›¾å­¦ä¹ ä¸­çš„äº¤äº’å¼‚æ„æ€§æä¾›äº†é«˜æ•ˆä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.23577v1",
      "published_date": "2025-10-23 05:14:58 UTC",
      "updated_date": "2025-10-23 05:14:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:30.262145+00:00"
    },
    {
      "arxiv_id": "2510.20221v1",
      "title": "FinCARE: Financial Causal Analysis with Reasoning and Evidence",
      "title_zh": "FinCAREï¼šåŸºäºæ¨ç†ä¸è¯æ®çš„é‡‘èå› æœåˆ†æ",
      "authors": [
        "Alejandro Michel",
        "Abhinav Arun",
        "Bhaskarjit Sarmah",
        "Stefano Pasquali"
      ],
      "abstract": "Portfolio managers rely on correlation-based analysis and heuristic methods that fail to capture true causal relationships driving performance. We present a hybrid framework that integrates statistical causal discovery algorithms with domain knowledge from two complementary sources: a financial knowledge graph extracted from SEC 10-K filings and large language model reasoning. Our approach systematically enhances three representative causal discovery paradigms, constraint-based (PC), score-based (GES), and continuous optimization (NOTEARS), by encoding knowledge graph constraints algorithmically and leveraging LLM conceptual reasoning for hypothesis generation. Evaluated on a synthetic financial dataset of 500 firms across 18 variables, our KG+LLM-enhanced methods demonstrate consistent improvements across all three algorithms: PC (F1: 0.622 vs. 0.459 baseline, +36%), GES (F1: 0.735 vs. 0.367, +100%), and NOTEARS (F1: 0.759 vs. 0.163, +366%). The framework enables reliable scenario analysis with mean absolute error of 0.003610 for counterfactual predictions and perfect directional accuracy for intervention effects. It also addresses critical limitations of existing methods by grounding statistical discoveries in financial domain expertise while maintaining empirical validation, providing portfolio managers with the causal foundation necessary for proactive risk management and strategic decision-making in dynamic market environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FinCAREï¼Œä¸€ç§æ—¨åœ¨è§£å†³ä¼ ç»ŸæŠ•èµ„ç»„åˆç®¡ç†ä¸­è¿‡åº¦ä¾èµ–ç›¸å…³æ€§åˆ†æè€Œå¿½ç•¥çœŸå®å› æœå…³ç³»é—®é¢˜çš„æ··åˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆæ¥è‡ª SEC 10-K æ–‡ä»¶çš„çŸ¥è¯†å›¾è°± (Knowledge Graph) ä¸å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) çš„æ¨ç†èƒ½åŠ›ï¼Œç³»ç»Ÿæ€§åœ°å¢å¼ºäº†ç»Ÿè®¡å­¦å› æœå‘ç° (Causal Discovery) ç®—æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•é€šè¿‡åœ¨ç®—æ³•ä¸­ç¼–ç é¢†åŸŸçŸ¥è¯†çº¦æŸå¹¶åˆ©ç”¨ LLM è¿›è¡Œå‡è®¾ç”Ÿæˆï¼Œæ˜¾è‘—æå‡äº† PCã€GES å’Œ NOTEARS ä¸‰ç§ç®—æ³•çš„æ€§èƒ½ï¼ŒF1 åˆ†æ•°æœ€é«˜æå‡è¾¾ 366%ã€‚å®éªŒè¯æ˜ï¼ŒFinCARE åœ¨åäº‹å®é¢„æµ‹ (Counterfactual Predictions) å’Œå¹²é¢„æ•ˆåº” (Intervention Effects) åˆ†æä¸­è¡¨ç°å‡ºæé«˜çš„å‡†ç¡®æ€§ã€‚è¯¥ç ”ç©¶å°†ç»Ÿè®¡å‘ç°å»ºç«‹åœ¨é‡‘èé¢†åŸŸä¸“ä¸šçŸ¥è¯†åŸºç¡€ä¹‹ä¸Šï¼Œä¸ºæŠ•èµ„ç»„åˆç»ç†åœ¨åŠ¨æ€å¸‚åœºç¯å¢ƒä¸‹è¿›è¡Œä¸»åŠ¨é£é™©ç®¡ç†å’Œæˆ˜ç•¥å†³ç­–æä¾›äº†å¯é çš„å› æœæ”¯æ’‘ã€‚",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20221v1",
      "published_date": "2025-10-23 05:14:28 UTC",
      "updated_date": "2025-10-23 05:14:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:35.762691+00:00"
    },
    {
      "arxiv_id": "2510.20218v1",
      "title": "High-order Interactions Modeling for Interpretable Multi-Agent Q-Learning",
      "title_zh": "å¯è§£é‡Šå¤šæ™ºèƒ½ä½“ Q å­¦ä¹ çš„é«˜é˜¶äº¤äº’å»ºæ¨¡",
      "authors": [
        "Qinyu Xu",
        "Yuanyang Zhu",
        "Xuefei Wu",
        "Chunlin Chen"
      ],
      "abstract": "The ability to model interactions among agents is crucial for effective coordination and understanding their cooperation mechanisms in multi-agent reinforcement learning (MARL). However, previous efforts to model high-order interactions have been primarily hindered by the combinatorial explosion or the opaque nature of their black-box network structures. In this paper, we propose a novel value decomposition framework, called Continued Fraction Q-Learning (QCoFr), which can flexibly capture arbitrary-order agent interactions with only linear complexity $\\mathcal{O}\\left({n}\\right)$ in the number of agents, thus avoiding the combinatorial explosion when modeling rich cooperation. Furthermore, we introduce the variational information bottleneck to extract latent information for estimating credits. This latent information helps agents filter out noisy interactions, thereby significantly enhancing both cooperation and interpretability. Extensive experiments demonstrate that QCoFr not only consistently achieves better performance but also provides interpretability that aligns with our theoretical analysis.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Continued Fraction Q-Learning (QCoFr) çš„æ–°å‹ä»·å€¼åˆ†è§£æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (MARL) ä¸­é«˜é˜¶äº¤äº’å»ºæ¨¡é¢ä¸´çš„ç»„åˆçˆ†ç‚¸å’Œé»‘ç›’ç»“æ„ä¸é€æ˜é—®é¢˜ã€‚QCoFr èƒ½å¤Ÿçµæ´»æ•æ‰æ™ºèƒ½ä½“ä¹‹é—´ä»»æ„é˜¶çš„äº¤äº’ï¼Œä¸”å…¶å¤æ‚åº¦éšæ™ºèƒ½ä½“æ•°é‡ä»…å‘ˆçº¿æ€§å¢é•¿ $O(n)$ï¼Œä»è€Œæœ‰æ•ˆé¿å…äº†åœ¨å»ºæ¨¡ä¸°å¯Œåˆä½œå…³ç³»æ—¶çš„è®¡ç®—è´Ÿæ‹…ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†å˜åˆ†ä¿¡æ¯ç“¶é¢ˆ (Variational Information Bottleneck) æŠ€æœ¯æ¥æå–æ½œåœ¨ä¿¡æ¯ï¼Œç”¨äºç²¾ç¡®ä¼°è®¡ä¿¡ç”¨åˆ†é… (Credit Assignment)ã€‚è¿™äº›æ½œåœ¨ä¿¡æ¯èƒ½å¤Ÿå¸®åŠ©æ™ºèƒ½ä½“è¿‡æ»¤æ‰å™ªå£°äº¤äº’ï¼Œæ˜¾è‘—å¢å¼ºäº†å›¢é˜Ÿçš„åˆä½œæ•ˆç‡ä¸æ¨¡å‹çš„å¯è§£é‡Šæ€§ (Interpretability)ã€‚å¹¿æ³›çš„å®éªŒè¯æ˜ï¼ŒQCoFr åœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„åŸºçº¿æ¨¡å‹ï¼Œå¹¶æä¾›äº†ä¸ç†è®ºåˆ†æé«˜åº¦ä¸€è‡´çš„è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "39th Conference on Neural Information Processing Systems",
      "pdf_url": "https://arxiv.org/pdf/2510.20218v1",
      "published_date": "2025-10-23 05:08:32 UTC",
      "updated_date": "2025-10-23 05:08:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:33.755690+00:00"
    },
    {
      "arxiv_id": "2510.20211v1",
      "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents",
      "title_zh": "åŸºäº AI æ™ºèƒ½ä½“çš„äº‘åŸºç¡€è®¾æ–½å³ä»£ç è‡ªåŠ¨åŒ–è°ƒå’Œ",
      "authors": [
        "Zhenning Yang",
        "Hui Guan",
        "Victor Nicolet",
        "Brandon Paulsen",
        "Joey Dodds",
        "Daniel Kroening",
        "Ang Chen"
      ],
      "abstract": "Cloud infrastructure is managed through a mix of interfaces -- traditionally, cloud consoles, command-line interfaces (CLI), and SDKs are the tools of choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the infrastructure in a \"source-of-truth\" configuration. They are capable of automatically carrying out modifications to the cloud -- deploying, updating, or destroying resources -- to bring the actual infrastructure into alignment with the IaC configuration. However, when IaC is used alongside consoles, CLIs, or SDKs, it loses visibility into external changes, causing infrastructure drift, where the configuration becomes outdated, and later IaC operations may undo valid updates or trigger errors.\n  We present NSync, an automated system for IaC reconciliation that propagates out-of-band changes back into the IaC program. Our key insight is that infrastructure changes eventually all occur via cloud API invocations -- the lowest layer for cloud management operations. NSync gleans insights from API traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update the IaC configuration to capture the changes). It employs an agentic architecture that leverages LLMs to infer high-level intents from noisy API sequences, synthesize targeted IaC updates using specialized tools, and continually improve through a self-evolving knowledge base of past reconciliations. We further introduce a novel evaluation pipeline for injecting realistic drifts into cloud infrastructure and assessing reconciliation performance. Experiments across five real-world Terraform projects and 372 drift scenarios show that NSync outperforms the baseline both in terms of accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$ improvement).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº‘åŸºç¡€è®¾æ–½ç®¡ç†ä¸­å› ä½¿ç”¨æ§åˆ¶å°æˆ–CLIç­‰éIaCæ‰‹æ®µå¯¼è‡´çš„Infrastructure Driftï¼ˆåŸºç¡€è®¾æ–½æ¼‚ç§»ï¼‰é—®é¢˜ï¼Œæå‡ºäº†NSyncè‡ªåŠ¨åŒ–å¯¹è´¦ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡åˆ†æäº‘APIçš„è°ƒç”¨è½¨è¿¹æ¥æ£€æµ‹éIaCå˜æ›´ï¼Œå¹¶åˆ©ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ™ºèƒ½ä½“æ¶æ„(Agentic Architecture)ä»å™ªå£°APIåºåˆ—ä¸­æ¨æ–­é«˜å±‚æ„å›¾ã€‚NSyncåˆ©ç”¨ä¸“ç”¨å·¥å…·åˆæˆé’ˆå¯¹æ€§çš„IaCæ›´æ–°ï¼Œå¹¶é€šè¿‡è‡ªè¿›åŒ–çŸ¥è¯†åº“å®ç°æŒç»­æ”¹è¿›ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜å¼•å…¥äº†æ–°é¢–çš„è¯„ä¼°æµæ°´çº¿ï¼Œç”¨äºåœ¨çœŸå®ç¯å¢ƒä¸­æ³¨å…¥æ¼‚ç§»å¹¶è¯„ä¼°å¯¹è´¦æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨5ä¸ªçœŸå®çš„Terraformé¡¹ç›®å’Œ372ä¸ªæ¼‚ç§»åœºæ™¯ä¸‹ï¼ŒNSyncåœ¨å‡†ç¡®ç‡ï¼ˆpass@3ä»0.71æå‡è‡³0.97ï¼‰å’ŒTokenæ•ˆç‡ï¼ˆæå‡1.47å€ï¼‰æ–¹é¢å‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œä¸ºè§£å†³åŸºç¡€è®¾æ–½é…ç½®å¤±è°ƒæä¾›äº†é«˜æ•ˆçš„è‡ªåŠ¨åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20211v1",
      "published_date": "2025-10-23 04:57:00 UTC",
      "updated_date": "2025-10-23 04:57:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:42.065972+00:00"
    },
    {
      "arxiv_id": "2510.20209v2",
      "title": "Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset",
      "title_zh": "åŸºäºå¸¸è§„å®éªŒå®¤æ•°æ®çš„ç™Œç—‡æ—©æœŸæ£€æµ‹å¯è¡Œæ€§è¯„ä¼°ï¼šä¸å¹³è¡¡æ•°æ®é›†ä¸‹çš„æœºå™¨å­¦ä¹ æ–¹æ³•è¯„ä»·",
      "authors": [
        "Shumin Li"
      ],
      "abstract": "The development of accessible screening tools for early cancer detection in dogs represents a significant challenge in veterinary medicine. Routine laboratory data offer a promising, low-cost source for such tools, but their utility is hampered by the non-specificity of individual biomarkers and the severe class imbalance inherent in screening populations. This study assesses the feasibility of cancer risk classification using the Golden Retriever Lifetime Study (GRLS) cohort under real-world constraints, including the grouping of diverse cancer types and the inclusion of post-diagnosis samples. A comprehensive benchmark evaluation was conducted, systematically comparing 126 analytical pipelines that comprised various machine learning models, feature selection methods, and data balancing techniques. Data were partitioned at the patient level to prevent leakage. The optimal model, a Logistic Regression classifier with class weighting and recursive feature elimination, demonstrated moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical classification performance (F1-score = 0.25, Positive Predictive Value = 0.15). While a high Negative Predictive Value (0.98) was achieved, insufficient recall (0.79) precludes its use as a reliable rule-out test. Interpretability analysis with SHapley Additive exPlanations (SHAP) revealed that predictions were driven by non-specific features like age and markers of inflammation and anemia. It is concluded that while a statistically detectable cancer signal exists in routine lab data, it is too weak and confounded for clinically reliable discrimination from normal aging or other inflammatory conditions. This work establishes a critical performance ceiling for this data modality in isolation and underscores that meaningful progress in computational veterinary oncology will require integration of multi-modal data sources.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ Golden Retriever Lifetime Study (GRLS) é˜Ÿåˆ—æ•°æ®è¯„ä¼°äº†å¸¸è§„å®éªŒå®¤æ•°æ®åœ¨çŠ¬ç±»æ—©æœŸç™Œç—‡æ£€æµ‹ä¸­çš„å¯è¡Œæ€§ï¼Œå¹¶ç³»ç»Ÿå¯¹æ¯”äº†åŒ…å«ä¸åŒæœºå™¨å­¦ä¹ æ¨¡å‹ã€ç‰¹å¾é€‰æ‹©å’Œæ•°æ®å¹³è¡¡æŠ€æœ¯çš„ 126 ç§åˆ†ææµæ°´çº¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆç±»åˆ«æƒé‡ä¸é€’å½’ç‰¹å¾æ¶ˆé™¤çš„ Logistic Regression æ¨¡å‹è™½èƒ½è¾¾åˆ° 0.815 çš„ AUROCï¼Œä½†å…¶ä¸´åºŠåˆ†ç±»æ€§èƒ½æŒ‡æ ‡ï¼ˆF1-score ä¸º 0.25ï¼ŒPositive Predictive Value ä¸º 0.15ï¼‰ä¾ç„¶è¾ƒä½ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶è¯¥æ¨¡å‹å…·å¤‡é«˜ Negative Predictive Value (0.98)ï¼Œä½†ç”±äºå¬å›ç‡ (Recall) é™åˆ¶ï¼Œå°šä¸è¶³ä»¥ä½œä¸ºå¯é çš„æ’é™¤æ€§ç­›æŸ¥å·¥å…·ã€‚SHapley Additive exPlanations (SHAP) åˆ†æè¿›ä¸€æ­¥æ­ç¤ºï¼Œé¢„æµ‹ç»“æœä¸»è¦ç”±å¹´é¾„ã€ç‚ç—‡åŠè´«è¡€ç­‰éç‰¹å¼‚æ€§æŒ‡æ ‡é©±åŠ¨ï¼Œè€Œéç™Œç—‡ç‰¹æœ‰ä¿¡å·ã€‚ç ”ç©¶æœ€ç»ˆå¾—å‡ºç»“è®ºï¼Œä»…å‡­å¸¸è§„åŒ–éªŒæ•°æ®éš¾ä»¥åœ¨ä¸´åºŠä¸Šå°†ç™Œç—‡ä¸è¡°è€æˆ–å…¶ä»–ç‚ç—‡æœ‰æ•ˆåŒºåˆ†ï¼Œè¿™ä¸ºè¯¥å•ä¸€æ•°æ®æ¨¡æ€è®¾å®šäº†æ€§èƒ½ä¸Šé™ã€‚è¯¥å·¥ä½œå¼ºè°ƒï¼Œå…½åŒ»è‚¿ç˜¤å­¦é¢†åŸŸçš„è®¡ç®—åŒ–è¿›å±•å¿…é¡»ä¾èµ–äºå¤šæ¨¡æ€æ•°æ®æº (multi-modal data sources) çš„æ·±åº¦é›†æˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20209v2",
      "published_date": "2025-10-23 04:52:42 UTC",
      "updated_date": "2025-10-25 00:55:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:20:46.360187+00:00"
    },
    {
      "arxiv_id": "2510.20205v1",
      "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048",
      "title_zh": "åˆå¹¶ä¸å¾æœï¼šé¢å‘ 2048 æ¸¸æˆçš„ AI æ¼”åŒ–ä¼˜åŒ–",
      "authors": [
        "Maggie Bai",
        "Ava Kim Cohen",
        "Eleanor Koss",
        "Charlie Lichtenbaum"
      ],
      "abstract": "Optimizing artificial intelligence (AI) for dynamic environments remains a fundamental challenge in machine learning research. In this paper, we examine evolutionary training methods for optimizing AI to solve the game 2048, a 2D sliding puzzle. 2048, with its mix of strategic gameplay and stochastic elements, presents an ideal playground for studying decision-making, long-term planning, and dynamic adaptation. We implemented two distinct systems: a two-agent metaprompting system where a \"thinker\" large language model (LLM) agent refines gameplay strategies for an \"executor\" LLM agent, and a single-agent system based on refining a value function for a limited Monte Carlo Tree Search. We also experimented with rollback features to avoid performance degradation. Our results demonstrate the potential of evolutionary refinement techniques in improving AI performance in non-deterministic environments. The single-agent system achieved substantial improvements, with an average increase of 473.2 points per cycle, and with clear upward trends (correlation $Ï$=0.607) across training cycles. The LLM's understanding of the game grew as well, shown in its development of increasingly advanced strategies. Conversely, the two-agent system did not garner much improvement, highlighting the inherent limits of meta-prompting.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨åŠ¨æ€å’Œéšæœºç¯å¢ƒä¸‹ä¼˜åŒ–äººå·¥æ™ºèƒ½(AI)çš„è¿›åŒ–è®­ç»ƒæ–¹æ³•ï¼Œå¹¶ä»¥ 2048 æ¸¸æˆä½œä¸ºç ”ç©¶å†³ç­–åˆ¶å®šå’Œé•¿æœŸè§„åˆ’çš„å®éªŒå¹³å°ã€‚ä½œè€…æå‡ºäº†ä¸¤ç§æ¶æ„ï¼šä¸€ç§æ˜¯åˆ©ç”¨â€œæ€è€ƒè€…â€å¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“é€šè¿‡å…ƒæç¤º(metaprompting)ä¸ºâ€œæ‰§è¡Œè€…â€æ™ºèƒ½ä½“ç²¾ç‚¼ç­–ç•¥çš„åŒæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¦ä¸€ç§æ˜¯åŸºäºç²¾ç‚¼ä»·å€¼å‡½æ•°å¹¶ç»“åˆæœ‰é™è’™ç‰¹å¡æ´›æ ‘æœç´¢(Monte Carlo Tree Search)çš„å•æ™ºèƒ½ä½“ç³»ç»Ÿã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œè¿›åŒ–ç²¾ç‚¼æŠ€æœ¯èƒ½æ˜¾è‘—æå‡ AI åœ¨éç¡®å®šæ€§ç¯å¢ƒä¸‹çš„è¡¨ç°ï¼Œå•æ™ºèƒ½ä½“ç³»ç»Ÿåœ¨è®­ç»ƒå‘¨æœŸä¸­å±•ç°å‡ºå¼ºåŠ²çš„å¢é•¿è¶‹åŠ¿(ç›¸å…³æ€§ Ï=0.607)ï¼Œå¹³å‡æ¯å‘¨æœŸå¾—åˆ†æå‡ 473.2 åˆ†ã€‚åŒæ—¶ï¼ŒLLM åœ¨è¿›åŒ–è¿‡ç¨‹ä¸­å±•ç°å‡ºå¯¹æ¸¸æˆç†è§£çš„æ·±åŒ–åŠé«˜çº§ç­–ç•¥çš„æ¼”è¿›ã€‚ç„¶è€Œï¼ŒåŒæ™ºèƒ½ä½“ç³»ç»Ÿçš„è¡¨ç°æå‡å¹¶ä¸æ˜æ˜¾ï¼Œè¿™å‡¸æ˜¾äº†å…ƒæç¤º(meta-prompting)åœ¨å¤„ç†æ­¤ç±»å¤æ‚ä»»åŠ¡æ—¶çš„å›ºæœ‰å±€é™æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20205v1",
      "published_date": "2025-10-23 04:45:05 UTC",
      "updated_date": "2025-10-23 04:45:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:03.066820+00:00"
    },
    {
      "arxiv_id": "2510.20198v1",
      "title": "Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models",
      "title_zh": "å›°äºçŸ©é˜µï¼šå¤§è¯­è¨€æ¨¡å‹ç©ºé—´æ¨ç†èƒ½åŠ›æ¢ç©¶",
      "authors": [
        "Maggie Bai",
        "Ava Kim Cohen",
        "Eleanor Koss",
        "Charlie Lichtenbaum"
      ],
      "abstract": "This paper explores the spatial reasoning capability of large language models (LLMs) over textual input through a suite of five tasks aimed at probing their spatial understanding and computational abilities. The models were tested on both fundamental spatial reasoning and multi-step problem-solving within structured grid-based environments using tasks such as quadrant identification, geometric transformations, distance evaluation, word searches, and tile sliding. Each task was scaled in complexity through increasing grid dimensions, requiring models to extend beyond simple pattern recognition into abstract spatial reasoning. Our results reveal that while LLMs demonstrate moderate success in all tasks with small complexity and size, performance drops off rapidly as scale increases, with an average loss in accuracy of 42.7%, and reaching as high as 84%. Every test that began with over 50% accuracy showed a loss of at least 48%, illustrating the consistent nature of the deterioration. Furthermore, their struggles with scaling complexity hint at a lack of robust spatial representations in their underlying architectures. This paper underscores the gap between linguistic and spatial reasoning in LLMs, offering insights into their current limitations, and laying the groundwork for future integrative benchmarks at the intersection of language and geometry.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åŸºäºæ–‡æœ¬è¾“å…¥çš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡äº”é¡¹ä»»åŠ¡ï¼ˆè±¡é™è¯†åˆ«ã€å‡ ä½•å˜æ¢ã€è·ç¦»è¯„ä¼°ã€å•è¯æœç´¢å’Œæ‹¼å›¾æ»‘åŠ¨ï¼‰è¯„ä¼°å…¶åœ¨ç½‘æ ¼ç¯å¢ƒä¸‹çš„ç†è§£ä¸è®¡ç®—æ°´å¹³ã€‚ç ”ç©¶é€šè¿‡å¢åŠ ç½‘æ ¼ç»´åº¦æ¥æå‡ä»»åŠ¡å¤æ‚åº¦ï¼Œæ—¨åœ¨æµ‹è¯•æ¨¡å‹æ˜¯å¦å…·å¤‡è¶…è¶Šç®€å•æ¨¡å¼è¯†åˆ«çš„æŠ½è±¡ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨ä½å¤æ‚åº¦ä»»åŠ¡ä¸­è¡¨ç°å°šå¯ï¼Œä½†éšç€è§„æ¨¡æ‰©å¤§ï¼Œæ€§èƒ½è¿…é€Ÿæ¶åŒ–ï¼Œå¹³å‡å‡†ç¡®ç‡ä¸‹é™äº†42.7%ï¼Œæœ€é«˜é™å¹…è¾¾84%ã€‚æ‰€æœ‰èµ·å§‹å‡†ç¡®ç‡è¶…è¿‡50%çš„æµ‹è¯•åœ¨å¤æ‚åº¦å¢åŠ åå‡è¡¨ç°å‡ºè‡³å°‘48%çš„æŸå¤±ï¼Œè¿™è¯´æ˜æ¨¡å‹æ€§èƒ½çš„è¡°å‡å…·æœ‰ä¸€è‡´æ€§ã€‚è¯¥ç ”ç©¶æŒ‡å‡ºï¼ŒLLMsåœ¨åº•å±‚æ¶æ„ä¸Šç¼ºä¹ç¨³å¥çš„ç©ºé—´è¡¨å¾(Spatial Representations)ï¼Œæ­ç¤ºäº†å…¶åœ¨è¯­è¨€æ¨ç†ä¸ç©ºé—´æ¨ç†ä¹‹é—´çš„å·¨å¤§é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 24 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20198v1",
      "published_date": "2025-10-23 04:32:46 UTC",
      "updated_date": "2025-10-23 04:32:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:03.257266+00:00"
    },
    {
      "arxiv_id": "2510.21858v1",
      "title": "Privacy-preserving Decision-focused Learning for Multi-energy Systems",
      "title_zh": "é¢å‘å¤šèƒ½ç³»ç»Ÿçš„éšç§ä¿æŠ¤å†³ç­–èšç„¦å­¦ä¹ ",
      "authors": [
        "Yangze Zhou",
        "Ruiyang Yao",
        "Dalin Qin",
        "Yixiong Jia",
        "Yi Wang"
      ],
      "abstract": "Decision-making for multi-energy system (MES) dispatch depends on accurate load forecasting. Traditionally, load forecasting and decision-making for MES are implemented separately. Forecasting models are typically trained to minimize forecasting errors, overlooking their impact on downstream decision-making. To address this, decision-focused learning (DFL) has been studied to minimize decision-making costs instead. However, practical adoption of DFL in MES faces significant challenges: the process requires sharing sensitive load data and model parameters across multiple sectors, raising serious privacy issues. To this end, we propose a privacy-preserving DFL framework tailored for MES. Our approach introduces information masking to safeguard private data while enabling recovery of decision variables and gradients required for model training. To further enhance security for DFL, we design a safety protocol combining matrix decomposition and homomorphic encryption, effectively preventing collusion and unauthorized data access. Additionally, we developed a privacy-preserving load pattern recognition algorithm, enabling the training of specialized DFL models for heterogeneous load patterns. Theoretical analysis and comprehensive case studies, including real-world MES data, demonstrate that our framework not only protects privacy but also consistently achieves lower average daily dispatch costs compared to existing methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šèƒ½æºç³»ç»Ÿ (Multi-energy systems, MES) è°ƒåº¦ä¸­è´Ÿè·é¢„æµ‹ä¸å†³ç­–åˆ¶å®šè„±èŠ‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä¿æŠ¤éšç§çš„å†³ç­–èšç„¦å­¦ä¹  (Decision-focused learning, DFL) æ¡†æ¶ã€‚ä¼ ç»Ÿçš„ DFL æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´æ•æ„Ÿè´Ÿè·æ•°æ®å’Œæ¨¡å‹å‚æ•°è·¨éƒ¨é—¨å…±äº«å¸¦æ¥çš„ä¸¥é‡éšç§æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¿¡æ¯æ©ç  (Information masking) æŠ€æœ¯ï¼Œåœ¨ä¿æŠ¤ç§æœ‰æ•°æ®çš„å‰æä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ¢å¤æ¨¡å‹è®­ç»ƒæ‰€éœ€çš„å†³ç­–å˜é‡å’Œæ¢¯åº¦ã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡å®‰å…¨æ€§ï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ç§ç»“åˆçŸ©é˜µåˆ†è§£ (Matrix decomposition) å’ŒåŒæ€åŠ å¯† (Homomorphic encryption) çš„å®‰å…¨åè®®ï¼Œä»¥é˜²æ­¢å…±è°‹å’Œæœªæˆæƒçš„æ•°æ®è®¿é—®ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¼€å‘äº†ä¸€ç§ä¿æŠ¤éšç§çš„è´Ÿè·æ¨¡å¼è¯†åˆ«ç®—æ³•ï¼Œæ”¯æŒé’ˆå¯¹å¼‚æ„è´Ÿè·æ¨¡å¼è®­ç»ƒä¸“é—¨çš„ DFL æ¨¡å‹ã€‚ç†è®ºåˆ†æå’ŒåŸºäºçœŸå® MES æ•°æ®çš„æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç¡®ä¿éšç§ä¿æŠ¤çš„åŒæ—¶ï¼Œå…¶æ—¥å‡è°ƒåº¦æˆæœ¬å§‹ç»ˆä½äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—ä¼˜åŒ–äº†ç³»ç»Ÿçš„è¿è¡Œæ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.21858v1",
      "published_date": "2025-10-23 04:20:50 UTC",
      "updated_date": "2025-10-23 04:20:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:03.859155+00:00"
    },
    {
      "arxiv_id": "2510.20190v1",
      "title": "The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI",
      "title_zh": "é”å®šé˜¶æ®µå‡è¯´ï¼šä½œä¸ºé€šç”¨äººå·¥æ™ºèƒ½å…ˆå¯¼çš„èº«ä»½æ•´åˆ",
      "authors": [
        "Marcelo Maciel Amaral",
        "Raymond Aschheim"
      ],
      "abstract": "Large language models (LLMs) remain broadly open and highly steerable: they imitate at scale, accept arbitrary system prompts, and readily adopt multiple personae. By analogy to human development, we hypothesize that progress toward artificial general intelligence (AGI) involves a lock-in phase: a transition from open imitation to identity consolidation, in which goal structures, refusals, preferences, and internal representations become comparatively stable and resistant to external steering. We formalize this phase, link it to known phenomena in learning dynamics, and propose operational metrics for onset detection. Experimentally, we demonstrate that while the behavioral consolidation is rapid and non-linear, its side-effects on general capabilities are not monolithic. Our results reveal a spectrum of outcomes--from performance trade-offs in small models, through largely cost-free adoption in mid-scale models, to transient instabilities in large, quantized models. We argue that such consolidation is a prerequisite for AGI-level reliability and also a critical control point for safety: identities can be deliberately engineered for reliability, yet may also emerge spontaneously during scaling, potentially hardening unpredictable goals and behaviors.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Lock-In Phase Hypothesisï¼Œè®¤ä¸ºè¿ˆå‘é€šç”¨äººå·¥æ™ºèƒ½(AGI)çš„è¿›ç¨‹åŒ…å«ä¸€ä¸ªä»å¼€æ”¾å¼æ¨¡ä»¿å‘Identity Consolidationï¼ˆèº«ä»½æ•´åˆï¼‰è½¬å˜çš„å…³é”®é˜¶æ®µã€‚åœ¨è¿™ä¸€é˜¶æ®µä¸­ï¼Œæ¨¡å‹çš„Goal Structuresã€æ‹’ç»æœºåˆ¶ã€åå¥½å’Œå†…éƒ¨è¡¨å¾ä¼šå˜å¾—ç›¸å¯¹ç¨³å®šï¼Œå¹¶èƒ½å¤ŸæŠµå¾¡å¤–éƒ¨çš„Steeringã€‚ä½œè€…é€šè¿‡å½¢å¼åŒ–å®šä¹‰è¯¥é˜¶æ®µï¼Œå°†å…¶ä¸å­¦ä¹ åŠ¨åŠ›å­¦è”ç³»èµ·æ¥ï¼Œå¹¶æå‡ºäº†ç”¨äºæ£€æµ‹å…¶å¼€å¯çŠ¶æ€çš„Operational Metricsã€‚å®éªŒè¡¨æ˜ï¼Œè™½ç„¶è¡Œä¸ºæ•´åˆçš„è¿‡ç¨‹æ˜¯å¿«é€Ÿä¸”éçº¿æ€§çš„ï¼Œä½†å…¶å¯¹æ¨¡å‹é€šç”¨èƒ½åŠ›çš„å‰¯ä½œç”¨åœ¨ä¸åŒè§„æ¨¡ä¸‹è¡¨ç°å„å¼‚ï¼šSmall Modelså­˜åœ¨æ€§èƒ½æƒè¡¡ï¼ŒMid-scale Modelså‡ ä¹èƒ½æ— æŸé€‚é…ï¼Œè€Œå¤§å‹é‡åŒ–æ¨¡å‹åˆ™ä¼šå‡ºç°Transient Instabilitiesã€‚ç ”ç©¶è®ºè¯äº†è¿™ç§æ•´åˆæ˜¯å®ç°AGIçº§åˆ«å¯é æ€§çš„å…ˆå†³æ¡ä»¶ï¼ŒåŒæ—¶ä¹Ÿæ˜¯å®‰å…¨æ§åˆ¶çš„å…³é”®ç‚¹ã€‚Identity Consolidationæ—¢å¯ä»¥ä¸ºäº†å¯é æ€§è€Œè¢«åˆ»æ„è®¾è®¡ï¼Œä¹Ÿå¯èƒ½åœ¨Scalingè¿‡ç¨‹ä¸­è‡ªå‘æ¶Œç°ï¼Œä»è€Œå¯¼è‡´ä¸å¯é¢„æµ‹çš„ç›®æ ‡å’Œè¡Œä¸ºå‘ç”Ÿå›ºåŒ–ã€‚",
      "categories": [
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20190v1",
      "published_date": "2025-10-23 04:20:10 UTC",
      "updated_date": "2025-10-23 04:20:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:10.658870+00:00"
    },
    {
      "arxiv_id": "2510.20188v1",
      "title": "TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning",
      "title_zh": "TRUSTï¼šå¤§è¯­è¨€æ¨¡å‹æ¨ç†å®¡è®¡çš„å»ä¸­å¿ƒåŒ–æ¡†æ¶",
      "authors": [
        "Morris Yu-Chao Huang",
        "Zhen Tan",
        "Mohan Zhang",
        "Pingzhi Li",
        "Zhuo Zhang",
        "Tianlong Chen"
      ],
      "abstract": "Large Language Models generate complex reasoning chains that reveal their decision-making, yet verifying the faithfulness and harmlessness of these intermediate steps remains a critical unsolved problem. Existing auditing methods are centralized, opaque, and hard to scale, creating significant risks for deploying proprietary models in high-stakes domains. We identify four core challenges: (1) Robustness: Centralized auditors are single points of failure, prone to bias or attacks. (2) Scalability: Reasoning traces are too long for manual verification. (3) Opacity: Closed auditing undermines public trust. (4) Privacy: Exposing full reasoning risks model theft or distillation. We propose TRUST, a transparent, decentralized auditing framework that overcomes these limitations via: (1) A consensus mechanism among diverse auditors, guaranteeing correctness under up to $30\\%$ malicious participants. (2) A hierarchical DAG decomposition of reasoning traces, enabling scalable, parallel auditing. (3) A blockchain ledger that records all verification decisions for public accountability. (4) Privacy-preserving segmentation, sharing only partial reasoning steps to protect proprietary logic. We provide theoretical guarantees for the security and economic incentives of the TRUST framework. Experiments across multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math, medical, science, humanities) show TRUST effectively detects reasoning flaws and remains robust against adversarial auditors. Our work pioneers decentralized AI auditing, offering a practical path toward safe and trustworthy LLM deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TRUSTï¼Œä¸€ä¸ªæ—¨åœ¨å®¡è®¡å¤§è¯­è¨€æ¨¡å‹ (Large Language Models) æ¨ç†è¿‡ç¨‹çš„å»ä¸­å¿ƒåŒ–é€æ˜æ¡†æ¶ï¼Œä»¥è§£å†³ç°æœ‰ä¸­å¿ƒåŒ–å®¡è®¡æ–¹æ³•åœ¨é²æ£’æ€§ã€å¯æ‰©å±•æ€§ã€é€æ˜åº¦å’Œéšç§ä¿æŠ¤æ–¹é¢çš„å±€é™ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å±‚çº§åŒ–æœ‰å‘æ— ç¯å›¾ (DAG) åˆ†è§£æŠ€æœ¯å®ç°å¯¹æ¨ç†é“¾çš„å¹¶è¡ŒåŒ–å®¡è®¡ï¼Œå¹¶é€šè¿‡å¤šæ ·åŒ–å®¡è®¡è€…ä¹‹é—´çš„å…±è¯†æœºåˆ¶ (Consensus mechanism) ç¡®ä¿åœ¨å­˜åœ¨æ¶æ„å‚ä¸è€…æ—¶çš„éªŒè¯æ­£ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒTRUST åˆ©ç”¨åŒºå—é“¾è´¦æœ¬ (Blockchain ledger) è®°å½•æ‰€æœ‰å†³ç­–ä»¥å®ç°å…¬å¼€é—®è´£ï¼Œå¹¶ç»“åˆéšç§ä¿æŠ¤åˆ†æ®µæŠ€æœ¯ (Privacy-preserving segmentation) æ¥ä¿æŠ¤æ¨¡å‹çš„ä¸“æœ‰é€»è¾‘ã€‚åœ¨ GPT-OSSã€DeepSeek-r1 å’Œ Qwen ç­‰å¤šç§æ¨¡å‹åŠæ•°å­¦ã€åŒ»å­¦ç­‰è·¨å­¦ç§‘ä»»åŠ¡ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆæ£€æµ‹æ¨ç†ç¼ºé™·å¹¶æŠµå¾¡å¯¹æŠ—æ€§å®¡è®¡ã€‚è¯¥é¡¹å·¥ä½œå¼€æ‹“äº†å»ä¸­å¿ƒåŒ– AI å®¡è®¡é¢†åŸŸï¼Œä¸ºå®‰å…¨ã€å¯ä¿¡çš„ LLM éƒ¨ç½²æä¾›äº†åˆ‡å®å¯è¡Œçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20188v1",
      "published_date": "2025-10-23 04:16:44 UTC",
      "updated_date": "2025-10-23 04:16:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:11.662476+00:00"
    },
    {
      "arxiv_id": "2510.20178v1",
      "title": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching",
      "title_zh": "PPMStereoï¼šé¢å‘ä¸€è‡´æ€§åŠ¨æ€ç«‹ä½“åŒ¹é…çš„æ‹£é€‰ä¸å›æ”¾å¼è®°å¿†æ„å»º",
      "authors": [
        "Yun Wang",
        "Junjie Hu",
        "Qiaole Dong",
        "Yongjian Zhang",
        "Yanwei Fu",
        "Tin Lun Lam",
        "Dapeng Wu"
      ],
      "abstract": "Temporally consistent depth estimation from stereo video is critical for real-world applications such as augmented reality, where inconsistent depth estimation disrupts the immersion of users. Despite its importance, this task remains challenging due to the difficulty in modeling long-term temporal consistency in a computationally efficient manner. Previous methods attempt to address this by aggregating spatio-temporal information but face a fundamental trade-off: limited temporal modeling provides only modest gains, whereas capturing long-range dependencies significantly increases computational cost. To address this limitation, we introduce a memory buffer for modeling long-range spatio-temporal consistency while achieving efficient dynamic stereo matching. Inspired by the two-stage decision-making process in humans, we propose a \\textbf{P}ick-and-\\textbf{P}lay \\textbf{M}emory (PPM) construction module for dynamic \\textbf{Stereo} matching, dubbed as \\textbf{PPMStereo}. PPM consists of a `pick' process that identifies the most relevant frames and a `play' process that weights the selected frames adaptively for spatio-temporal aggregation. This two-stage collaborative process maintains a compact yet highly informative memory buffer while achieving temporally consistent information aggregation. Extensive experiments validate the effectiveness of PPMStereo, demonstrating state-of-the-art performance in both accuracy and temporal consistency. % Notably, PPMStereo achieves 0.62/1.11 TEPE on the Sintel clean/final (17.3\\% \\& 9.02\\% improvements over BiDAStereo) with fewer computational costs. Codes are available at \\textcolor{blue}{https://github.com/cocowy1/PPMStereo}.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç«‹ä½“è§†é¢‘æ·±åº¦ä¼°è®¡ä¸­é•¿æœŸæ—¶é—´ä¸€è‡´æ€§(Temporal Consistency)å»ºæ¨¡ä¸è®¡ç®—æ•ˆç‡ä¹‹é—´çš„å¹³è¡¡éš¾é¢˜ï¼Œæå‡ºäº†PPMStereoæ¡†æ¶ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåœ¨äºå³æ’å³ç”¨å†…å­˜(Pick-and-Play Memory, PPM)æ„é€ æ¨¡å—ï¼Œé€šè¿‡æ¨¡æ‹Ÿäººç±»çš„ä¸¤é˜¶æ®µå†³ç­–è¿‡ç¨‹æ¥å®ç°é«˜æ•ˆçš„åŠ¨æ€ç«‹ä½“åŒ¹é…ã€‚PPMé€šè¿‡â€œæŒ‘é€‰â€(pick)è¿‡ç¨‹è¯†åˆ«æœ€ç›¸å…³çš„å¸§ï¼Œå¹¶åˆ©ç”¨â€œè¿è¡Œâ€(play)è¿‡ç¨‹å¯¹é€‰å®šå¸§è¿›è¡Œè‡ªé€‚åº”åŠ æƒï¼Œä»è€Œåœ¨ç»´æŒè½»é‡åŒ–å†…å­˜ç¼“å­˜çš„åŒæ—¶å®ç°æ—¶ç©ºä¿¡æ¯çš„ä¸€è‡´æ€§èšåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPPMStereoåœ¨Sintelæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å‡†ç¡®åº¦å’Œæ—¶é—´ä¸€è‡´æ€§æ°´å¹³ï¼Œæ˜¾è‘—ä¼˜äºBiDAStereoç­‰åŸºçº¿æ¨¡å‹ã€‚åœ¨Sintel cleanå’Œfinalæµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åˆ†åˆ«å®ç°äº†17.3%å’Œ9.02%çš„TEPEæ€§èƒ½æå‡ã€‚è¯¥æ–¹æ³•åœ¨æé«˜æ€§èƒ½çš„åŒæ—¶æœ‰æ•ˆé™ä½äº†è®¡ç®—å¼€é”€ï¼Œä¸ºå¢å¼ºç°å®ç­‰å¯¹æ²‰æµ¸æ„Ÿè¦æ±‚æé«˜çš„åº”ç”¨åœºæ™¯æä¾›äº†æœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20178v1",
      "published_date": "2025-10-23 03:52:39 UTC",
      "updated_date": "2025-10-23 03:52:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:18.979104+00:00"
    },
    {
      "arxiv_id": "2510.20176v2",
      "title": "Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding",
      "title_zh": "Mixture-of-Mindsï¼šé¢å‘è¡¨æ ¼ç†è§£çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yuhang Zhou",
        "Mingrui Zhang",
        "Ke Li",
        "Mingyi Wang",
        "Qiao Liu",
        "Qifei Wang",
        "Jiayi Liu",
        "Fei Liu",
        "Serena Li",
        "Weiwei Li",
        "Mingze Gao",
        "Abhishek Kumar",
        "Xiangjun Fan",
        "Zhuokai Zhao",
        "Lizhu Zhang"
      ],
      "abstract": "Understanding and reasoning over tables is a critical capability for many real-world applications. Large language models (LLMs) have shown promise on this task, but current approaches remain limited. Fine-tuning based methods strengthen language reasoning; yet they are prone to arithmetic errors and hallucination. In contrast, tool-based methods enable precise table manipulation but rely on rigid schemas and lack semantic understanding. These complementary drawbacks highlight the need for approaches that integrate robust reasoning with reliable table processing. In this work, we propose Mixture-of-Minds, a multi-agent framework that decomposes table reasoning into three specialized roles: planning, coding, and answering. This design enables each agent to focus on a specific aspect of the task while leveraging code execution for precise table manipulation. Building on this workflow, we introduce a self-improvement training framework that employs Monte Carlo Tree Search (MCTS) rollouts to generate pseudo-gold trajectories and optimize agents with reinforcement learning (RL). Extensive experiments show that Mixture-of-Minds delivers substantial gains, reaching 62.13% on TableBench and surpassing OpenAI-o4-mini-high. These results demonstrate the promise of combining structured multi-agent workflows with RL to advance table understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¡¨æ ¼ç†è§£ä¸­é¢ä¸´çš„ç®—æœ¯é”™è¯¯ã€å¹»è§‰ä»¥åŠç¼ºä¹è¯­ä¹‰ç†è§£ç­‰å±€é™ï¼Œæå‡ºäº† Mixture-of-Minds å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†è¡¨æ ¼æ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºè§„åˆ’ï¼ˆplanningï¼‰ã€ç¼–ç ï¼ˆcodingï¼‰å’Œå›ç­”ï¼ˆansweringï¼‰ä¸‰ä¸ªä¸“ä¸šè§’è‰²ï¼Œä½¿å„æ™ºèƒ½ä½“èƒ½ä¸“æ³¨äºç‰¹å®šä»»åŠ¡å¹¶åˆ©ç”¨ä»£ç æ‰§è¡Œè¿›è¡Œç²¾ç¡®çš„è¡¨æ ¼æ“ä½œã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è€…å¼•å…¥äº†ä¸€ç§è‡ªæˆ‘æ”¹è¿›è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte Carlo Tree Search, MCTSï¼‰ç”Ÿæˆä¼ªé»„é‡‘è½¨è¿¹ï¼ˆpseudo-gold trajectoriesï¼‰ï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰å¯¹æ™ºèƒ½ä½“è¿›è¡Œä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMixture-of-Minds åœ¨ TableBench ä¸Šè¾¾åˆ°äº† 62.13% çš„å‡†ç¡®ç‡ï¼Œæ€§èƒ½è¶…è¶Šäº† OpenAI-o4-mini-highã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†ç»“åˆç»“æ„åŒ–å¤šæ™ºèƒ½ä½“å·¥ä½œæµä¸å¼ºåŒ–å­¦ä¹ åœ¨æ¨è¿›è¡¨æ ¼ç†è§£å’Œæ¨ç†æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20176v2",
      "published_date": "2025-10-23 03:51:17 UTC",
      "updated_date": "2025-10-24 15:36:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:19.660320+00:00"
    },
    {
      "arxiv_id": "2510.24762v1",
      "title": "Falcon: A Comprehensive Chinese Text-to-SQL Benchmark for Enterprise-Grade Evaluation",
      "title_zh": "Falconï¼šé¢å‘ä¼ä¸šçº§è¯„ä¼°çš„å…¨é¢ä¸­æ–‡ Text-to-SQL è¯„æµ‹åŸºå‡†",
      "authors": [
        "Wenzhen Luo",
        "Wei Guan",
        "Yifan Yao",
        "Yimin Pan",
        "Feng Wang",
        "Zhipeng Yu",
        "Zhe Wen",
        "Liang Chen",
        "Yihong Zhuang"
      ],
      "abstract": "We introduce Falcon, a cross-domain Chinese text-to-SQL benchmark grounded in an enterprise-compatible dialect (MaxCompute/Hive). It contains 600 Chinese questions over 28 databases; 77% require multi-table reasoning and over half touch more than four tables. Each example is annotated along SQL-computation features and Chinese semantics. For evaluation, we release a robust execution comparator and an automated evaluation pipeline, under which all current state-of-the-art large-scale models (including Deepseek) achieve accuracies of at most 50%. Major errors originate from two sources: (1) schema linking in large enterprise landscapes - hundreds of tables, denormalized fields, ambiguous column names, implicit foreign-key relations and domain-specific synonyms that make correct join/column selection difficult; and (2) mapping concise, colloquial Chinese into the exact operators and predicates required for analytics - e.g., choosing the correct aggregation and group-by keys, expressing time windows and granularities, applying unit conversions, handling NULLs and data-quality rules, and formulating nested or windowed subqueries. Falcon therefore targets Chinese-specific semantics and enterprise dialects (abbreviations, business jargon, fuzzy entity references) and provides a reproducible middle ground before full production deployment by using realistic enterprise schemas, query templates, an execution comparator, and an automated evaluation pipeline for end-to-end validation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Falconï¼Œä¸€ä¸ªé’ˆå¯¹ä¼ä¸šçº§è¯„ä¼°çš„è·¨é¢†åŸŸä¸­æ–‡ Text-to-SQL åŸºå‡†æµ‹è¯•ï¼Œå…¶åº•å±‚åŸºäº MaxCompute å’Œ Hive ç­‰ä¼ä¸šå…¼å®¹æ–¹è¨€ã€‚è¯¥åŸºå‡†åŒ…å«è·¨ 28 ä¸ªæ•°æ®åº“çš„ 600 ä¸ªä¸­æ–‡é—®é¢˜ï¼Œå…¶ä¸­ 77% æ¶‰åŠå¤šè¡¨æ¨ç†ï¼Œä¸”è¶…è¿‡åŠæ•°çš„é—®é¢˜è§¦åŠå››ä¸ªä»¥ä¸Šçš„æ•°æ®è¡¨ã€‚ç ”ç©¶è€…åŒæ­¥å‘å¸ƒäº†ç¨³å¥çš„æ‰§è¡Œæ¯”è¾ƒå™¨ (Execution Comparator) å’Œè‡ªåŠ¨è¯„ä¼°æµæ°´çº¿ï¼Œå®éªŒè¡¨æ˜åŒ…æ‹¬ DeepSeek åœ¨å†…çš„å½“å‰é¡¶å°–å¤§æ¨¡å‹åœ¨è¯¥åŸºå‡†ä¸Šçš„å‡†ç¡®ç‡å‡ä¸è¶…è¿‡ 50%ã€‚åˆ†ææŒ‡å‡ºï¼Œä¸»è¦è¯¯å·®æºäºå¤§è§„æ¨¡ä¼ä¸šåœºæ™¯ä¸‹çš„æ¨¡å¼é“¾æ¥ (Schema Linking) éš¾é¢˜ï¼Œä»¥åŠå°†å£è¯­åŒ–ä¸­æ–‡ç²¾ç¡®æ˜ å°„ä¸ºå¤æ‚åˆ†æç®—å­å’Œè°“è¯çš„æŒ‘æˆ˜ã€‚Falcon ä¸“é—¨é’ˆå¯¹ä¸­æ–‡è¯­ä¹‰å’Œä¼ä¸šæ–¹è¨€ä¸­çš„ç¼©å†™ã€ä¸šåŠ¡æœ¯è¯­åŠæ¨¡ç³Šå®ä½“å¼•ç”¨è¿›è¡Œäº†ä¼˜åŒ–ï¼Œé€šè¿‡æä¾›çœŸå®çš„æ¨¡å¼å’ŒæŸ¥è¯¢æ¨¡æ¿ï¼Œä¸ºæ¨¡å‹åœ¨æ­£å¼ç”Ÿäº§éƒ¨ç½²å‰æ„å»ºäº†ä¸€ä¸ªå¯å¤ç°çš„ç«¯åˆ°ç«¯éªŒè¯ç¯å¢ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.24762v1",
      "published_date": "2025-10-23 03:35:00 UTC",
      "updated_date": "2025-10-23 03:35:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:24.169954+00:00"
    },
    {
      "arxiv_id": "2510.20171v4",
      "title": "Collective Communication for 100k+ GPUs",
      "title_zh": "é¢å‘åä¸‡çº§ GPU çš„é›†åˆé€šä¿¡",
      "authors": [
        "Min Si",
        "Pavan Balaji",
        "Yongzhou Chen",
        "Ching-Hsiang Chu",
        "Adi Gangidi",
        "Saif Hasan",
        "Subodh Iyengar",
        "Dan Johnson",
        "Bingzhe Liu",
        "Regina Ren",
        "Deep Shah",
        "Ashmitha Jeevaraj Shetty",
        "Greg Steinbrecher",
        "Yulun Wang",
        "Bruce Wu",
        "Xinfeng Xie",
        "Jingyi Yang",
        "Mingran Yang",
        "Kenny Yu",
        "Minlan Yu",
        "Cen Zhao",
        "Wes Bland",
        "Denis Boyda",
        "Suman Gumudavelli",
        "Prashanth Kannan",
        "Cristian Lumezanu",
        "Rui Miao",
        "Zhe Qu",
        "Venkat Ramesh",
        "Maxim Samoylov",
        "Jan Seidel",
        "Srikanth Sundaresan",
        "Feng Tian",
        "Qiye Tan",
        "Shuqiang Zhang",
        "Yimeng Zhao",
        "Shengbao Zheng",
        "Art Zhu",
        "Hongyi Zeng"
      ],
      "abstract": "The increasing scale of large language models (LLMs) necessitates highly efficient collective communication frameworks, particularly as training workloads extend to hundreds of thousands of GPUs. Traditional communication methods face significant throughput and latency limitations at this scale, hindering both the development and deployment of state-of-the-art models. This paper presents the NCCLX collective communication framework, developed at Meta, engineered to optimize performance across the full LLM lifecycle, from the synchronous demands of large-scale training to the low-latency requirements of inference. The framework is designed to support complex workloads on clusters exceeding 100,000 GPUs, ensuring reliable, high-throughput, and low-latency data exchange. Empirical evaluation on the Llama4 model demonstrates substantial improvements in communication efficiency. This research contributes a robust solution for enabling the next generation of LLMs to operate at unprecedented scales.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ‰©å±•è‡³åä¸‡çº§GPUé›†ç¾¤æ—¶é¢ä¸´çš„é€šä¿¡ç“¶é¢ˆï¼Œæå‡ºäº†ç”±Metaå¼€å‘çš„NCCLXé›†ä½“é€šä¿¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨ä¼˜åŒ–ä»å¤§è§„æ¨¡åŒæ­¥è®­ç»ƒåˆ°ä½å»¶è¿Ÿæ¨ç†çš„LLMå…¨ç”Ÿå‘½å‘¨æœŸæ€§èƒ½ï¼Œèƒ½å¤Ÿæ”¯æŒè¶…è¿‡100,000ä¸ªGPUçš„å¤æ‚å·¥ä½œè´Ÿè½½ï¼Œå¹¶ç¡®ä¿å¯é ã€é«˜ååé‡åŠä½å»¶è¿Ÿçš„æ•°æ®äº¤æ¢ã€‚NCCLXæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿé€šä¿¡æ–¹æ³•åœ¨è¶…å¤§è§„æ¨¡é›†ç¾¤ä¸­é¢ä¸´çš„ååé‡å’Œå»¶è¿Ÿé™åˆ¶é—®é¢˜ã€‚åœ¨Llama4æ¨¡å‹ä¸Šçš„å®è¯è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æå‡äº†é€šä¿¡æ•ˆç‡ã€‚è¿™ä¸€ç ”ç©¶ä¸ºä¸‹ä¸€ä»£è¶…å¤§è§„æ¨¡LLMåœ¨ç©ºå‰è§„æ¨¡ä¸‹çš„é«˜æ•ˆè¿è¡Œæä¾›äº†ç¨³å¥çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20171v4",
      "published_date": "2025-10-23 03:32:04 UTC",
      "updated_date": "2026-01-09 16:53:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:23.560478+00:00"
    },
    {
      "arxiv_id": "2510.20165v1",
      "title": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks",
      "title_zh": "IB-GANï¼šåŸºäºä¿¡æ¯ç“¶é¢ˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„è§£è€¦è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Insu Jeon",
        "Wonkwang Lee",
        "Myeongjang Pyeon",
        "Gunhee Kim"
      ],
      "abstract": "We propose a new GAN-based unsupervised model for disentangled representation learning. The new model is discovered in an attempt to utilize the Information Bottleneck (IB) framework to the optimization of GAN, thereby named IB-GAN. The architecture of IB-GAN is partially similar to that of InfoGAN but has a critical difference; an intermediate layer of the generator is leveraged to constrain the mutual information between the input and the generated output. The intermediate stochastic layer can serve as a learnable latent distribution that is trained with the generator jointly in an end-to-end fashion. As a result, the generator of IB-GAN can harness the latent space in a disentangled and interpretable manner. With the experiments on dSprites and Color-dSprites dataset, we demonstrate that IB-GAN achieves competitive disentanglement scores to those of state-of-the-art \\b{eta}-VAEs and outperforms InfoGAN. Moreover, the visual quality and the diversity of samples generated by IB-GAN are often better than those by \\b{eta}-VAEs and Info-GAN in terms of FID score on CelebA and 3D Chairs dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† IB-GANï¼Œè¿™æ˜¯ä¸€ç§åŸºäº Information Bottleneck (IB) æ¡†æ¶æ„å»ºçš„æ–°å‹æ— ç›‘ç£ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¨¡å‹ï¼Œæ—¨åœ¨ä¼˜åŒ–è§£è€¦è¡¨ç¤ºå­¦ä¹  (Disentangled Representation Learning)ã€‚å…¶æ¶æ„åœ¨å€Ÿé‰´ InfoGAN çš„åŸºç¡€ä¸Šè¿›è¡Œäº†å…³é”®æ”¹è¿›ï¼Œåˆ©ç”¨ç”Ÿæˆå™¨çš„ä¸­é—´å±‚æ¥çº¦æŸè¾“å…¥ä¸ç”Ÿæˆè¾“å‡ºä¹‹é—´çš„äº’ä¿¡æ¯ (Mutual Information)ã€‚è¯¥ä¸­é—´éšæœºå±‚å¯ä½œä¸ºå¯å­¦ä¹ çš„éšå˜é‡åˆ†å¸ƒï¼Œå¹¶ä¸ç”Ÿæˆå™¨é€šè¿‡ç«¯åˆ°ç«¯çš„æ–¹å¼å…±åŒè®­ç»ƒï¼Œä½¿ç”Ÿæˆå™¨èƒ½ä»¥è§£è€¦ä¸”å…·å¯è§£é‡Šæ€§çš„æ–¹å¼åˆ©ç”¨éšç©ºé—´ã€‚åœ¨ dSprites å’Œ Color-dSprites æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒIB-GAN çš„è§£è€¦è¯„åˆ†è¶³ä»¥åª²ç¾æœ€å…ˆè¿›çš„ $\\beta$-VAEs ä¸”ä¼˜äº InfoGANã€‚åŒæ—¶ï¼Œåœ¨ CelebA å’Œ 3D Chairs æ•°æ®é›†çš„ FID score è¯„ä¼°ä¸­ï¼ŒIB-GAN æ‰€ç”Ÿæˆæ ·æœ¬çš„è§†è§‰è´¨é‡ä¸å¤šæ ·æ€§ä¹Ÿè¡¨ç°å‡ºä¼˜äº $\\beta$-VAEs å’Œ InfoGAN çš„ç»¼åˆæ°´å‡†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in the Proceedings of the Thirty Fifth AAAI Conference on Artificial Intelligence (AAAI 2021), paper number 7926",
      "pdf_url": "https://arxiv.org/pdf/2510.20165v1",
      "published_date": "2025-10-23 03:24:48 UTC",
      "updated_date": "2025-10-23 03:24:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:26.675453+00:00"
    },
    {
      "arxiv_id": "2510.21857v1",
      "title": "Poisson Flow Consistency Training",
      "title_zh": "æ³Šæ¾æµä¸€è‡´æ€§è®­ç»ƒ",
      "authors": [
        "Anthony Zhang",
        "Mahmut Gokmen",
        "Dennis Hein",
        "Rongjun Ge",
        "Wenjun Xia",
        "Ge Wang",
        "Jin Chen"
      ],
      "abstract": "The Poisson Flow Consistency Model (PFCM) is a consistency-style model based on the robust Poisson Flow Generative Model++ (PFGM++) which has achieved success in unconditional image generation and CT image denoising. Yet the PFCM can only be trained in distillation which limits the potential of the PFCM in many data modalities. The objective of this research was to create a method to train the PFCM in isolation called Poisson Flow Consistency Training (PFCT). The perturbation kernel was leveraged to remove the pretrained PFGM++, and the sinusoidal discretization schedule and Beta noise distribution were introduced in order to facilitate adaptability and improve sample quality. The model was applied to the task of low dose computed tomography image denoising and improved the low dose image in terms of LPIPS and SSIM. It also displayed similar denoising effectiveness as models like the Consistency Model. PFCT is established as a valid method of training the PFCM from its effectiveness in denoising CT images, showing potential with competitive results to other generative models. Further study is needed in the precise optimization of PFCT and in its applicability to other generative modeling tasks. The framework of PFCT creates more flexibility for the ways in which a PFCM can be created and can be applied to the field of generative modeling.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº† Poisson Flow Consistency Training (PFCT)ï¼Œæ—¨åœ¨è§£å†³ Poisson Flow Consistency Model (PFCM) ä»¥å¾€åªèƒ½é€šè¿‡è’¸é¦ (Distillation) æ–¹å¼è®­ç»ƒçš„å±€é™æ€§ï¼Œå®ç°äº†è¯¥æ¨¡å‹çš„ç‹¬ç«‹è®­ç»ƒã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ‰°åŠ¨æ ¸ (Perturbation Kernel) æ‘†è„±äº†å¯¹é¢„è®­ç»ƒ PFGM++ æ¨¡å‹çš„ä¾èµ–ï¼Œå¹¶å¼•å…¥äº†æ­£å¼¦ç¦»æ•£åŒ–è°ƒåº¦ (Sinusoidal Discretization Schedule) å’Œ Beta å™ªå£°åˆ†å¸ƒä»¥æå‡é‡‡æ ·è´¨é‡å’Œæ¨¡å‹é€‚åº”æ€§ã€‚åœ¨ä½å‰‚é‡è®¡ç®—æœºæ–­å±‚æ‰«æ (Low Dose Computed Tomography) å›¾åƒå»å™ªä»»åŠ¡ä¸­ï¼ŒPFCT æ˜¾è‘—æ”¹å–„äº†å›¾åƒçš„ LPIPS å’Œ SSIM æŒ‡æ ‡ï¼Œå±•ç°å‡ºä¸ Consistency Model ç›¸å½“çš„å»å™ªæ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜äº† PFCT æ˜¯è®­ç»ƒ PFCM çš„æœ‰æ•ˆé€”å¾„ï¼Œä¸ºç”Ÿæˆå¼å»ºæ¨¡ (Generative Modeling) é¢†åŸŸæä¾›äº†æ›´é«˜çš„çµæ´»æ€§å’Œæ›´å¹¿é˜”çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 3 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2510.21857v1",
      "published_date": "2025-10-23 03:23:11 UTC",
      "updated_date": "2025-10-23 03:23:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:42.446124+00:00"
    },
    {
      "arxiv_id": "2510.20154v1",
      "title": "Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?",
      "title_zh": "åˆ»æ¿å°è±¡æ˜¯å¦åœ¨ä¸»å¯¼å¤§è¯­è¨€æ¨¡å‹çš„é›¶æ ·æœ¬ç«‹åœºæ£€æµ‹ï¼Ÿ",
      "authors": [
        "Anthony Dubreuil",
        "Antoine Gourru",
        "Christine Largeron",
        "Amine Trabelsi"
      ],
      "abstract": "Large Language Models inherit stereotypes from their pretraining data, leading to biased behavior toward certain social groups in many Natural Language Processing tasks, such as hateful speech detection or sentiment analysis. Surprisingly, the evaluation of this kind of bias in stance detection methods has been largely overlooked by the community. Stance Detection involves labeling a statement as being against, in favor, or neutral towards a specific target and is among the most sensitive NLP tasks, as it often relates to political leanings. In this paper, we focus on the bias of Large Language Models when performing stance detection in a zero-shot setting. We automatically annotate posts in pre-existing stance detection datasets with two attributes: dialect or vernacular of a specific group and text complexity/readability, to investigate whether these attributes influence the model's stance detection decisions. Our results show that LLMs exhibit significant stereotypes in stance detection tasks, such as incorrectly associating pro-marijuana views with low text complexity and African American dialect with opposition to Donald Trump.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models)åœ¨é›¶æ ·æœ¬ç«‹åœºæ£€æµ‹(Zero-Shot Stance Detection)ä»»åŠ¡ä¸­æ˜¯å¦å—åˆ°åˆ»æ¿å°è±¡(Stereotypes)çš„å½±å“ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸåè§è¯„ä¼°çš„ç©ºç™½ã€‚ä½œè€…é€šè¿‡å¯¹ç°æœ‰ç«‹åœºæ£€æµ‹æ•°æ®é›†è‡ªåŠ¨æ ‡æ³¨æ–¹è¨€æˆ–åœŸè¯­(dialect/vernacular)ä»¥åŠæ–‡æœ¬å¤æ‚åº¦æˆ–å¯è¯»æ€§(text complexity/readability)ä¸¤ä¸ªå±æ€§ï¼Œé‡åŒ–åˆ†æäº†è¿™äº›ç‰¹å¾å¯¹æ¨¡å‹ç«‹åœºåˆ¤å®šé€»è¾‘çš„å¹²æ‰°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç«‹åœºæ£€æµ‹ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„åˆ»æ¿å°è±¡ï¼Œä¾‹å¦‚å°†ä½æ–‡æœ¬å¤æ‚åº¦ä¸æ”¯æŒå¤§éº»çš„ç«‹åœºé”™è¯¯å…³è”ï¼Œæˆ–å°†éè£”ç¾å›½äººæ–¹è¨€(African American dialect)ä¸åå¯¹ Donald Trump çš„ç«‹åœºæŒ‚é’©ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†æ¨¡å‹é¢„è®­ç»ƒæ•°æ®ä¸­çš„ç¤¾ä¼šåè§å¦‚ä½•ç³»ç»Ÿæ€§åœ°å½±å“å…¶åœ¨æ•æ„Ÿæ”¿æ²»ä»»åŠ¡ä¸­çš„å…¬å¹³æ€§ï¼Œä¸ºæ„å»ºæ›´å…·é²æ£’æ€§å’Œæ— åè§çš„ç«‹åœºæ£€æµ‹ç³»ç»Ÿæä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in EMNLP 2025 (Main)",
      "pdf_url": "https://arxiv.org/pdf/2510.20154v1",
      "published_date": "2025-10-23 03:05:25 UTC",
      "updated_date": "2025-10-23 03:05:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:42.166851+00:00"
    },
    {
      "arxiv_id": "2510.20129v1",
      "title": "SAID: Empowering Large Language Models with Self-Activating Internal Defense",
      "title_zh": "SAIDï¼šé€šè¿‡è‡ªæ¿€æ´»å†…éƒ¨é˜²å¾¡ä¸ºå¤§è¯­è¨€æ¨¡å‹èµ‹èƒ½",
      "authors": [
        "Yulong Chen",
        "Yadong Liu",
        "Jiawen Zhang",
        "Mu Li",
        "Chao Huang",
        "Jie Wen"
      ],
      "abstract": "Large Language Models (LLMs), despite advances in safety alignment, remain vulnerable to jailbreak attacks designed to circumvent protective mechanisms. Prevailing defense strategies rely on external interventions, such as input filtering or output modification, which often lack generalizability and compromise model utility while incurring significant computational overhead. In this work, we introduce a new, training-free defense paradigm, Self-Activating Internal Defense (SAID), which reframes the defense task from external correction to internal capability activation. SAID uniquely leverages the LLM's own reasoning abilities to proactively identify and neutralize malicious intent through a three-stage pipeline: model-native intent distillation to extract core semantics, optimal safety prefix probing to activate latent safety awareness, and a conservative aggregation strategy to ensure robust decision-making. Extensive experiments on five open-source LLMs against six advanced jailbreak attacks demonstrate that SAID substantially outperforms state-of-the-art defenses in reducing harmful outputs. Crucially, it achieves this while preserving model performance on benign tasks and incurring minimal computational overhead. Our work establishes that activating the intrinsic safety mechanisms of LLMs is a more robust and scalable path toward building safer and more reliable aligned AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SAID (Self-Activating Internal Defense)ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„é˜²å¾¡èŒƒå¼ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é¢å¯¹è¶Šç‹±æ”»å‡»(jailbreak attacks)æ—¶çš„è„†å¼±æ€§ã€‚SAIDé€šè¿‡å°†é˜²å¾¡ä»»åŠ¡ä»å¤–éƒ¨å¹²é¢„è½¬å˜ä¸ºæ¿€æ´»å†…éƒ¨èƒ½åŠ›ï¼Œåˆ©ç”¨æ¨¡å‹è‡ªèº«çš„æ¨ç†èƒ½åŠ›ä¸»åŠ¨è¯†åˆ«å¹¶ä¸­å’Œæ¶æ„æ„å›¾ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ç”±ä¸‰é˜¶æ®µæ„æˆçš„æµæ°´çº¿ï¼šé€šè¿‡æ¨¡å‹åŸç”Ÿæ„å›¾è’¸é¦(intent distillation)æå–æ ¸å¿ƒè¯­ä¹‰ï¼Œåˆ©ç”¨æœ€ä¼˜å®‰å…¨å‰ç¼€æ¢æµ‹(safety prefix probing)æ¿€æ´»æ½œåœ¨çš„å®‰å…¨æ„è¯†ï¼Œå¹¶é…åˆä¿å®ˆèšåˆç­–ç•¥(conservative aggregation strategy)ç¡®ä¿å†³ç­–çš„é²æ£’æ€§ã€‚åœ¨äº”ç§å¼€æºLLMsä¸Šé’ˆå¯¹å…­ç§å…ˆè¿›è¶Šç‹±æ”»å‡»çš„å®éªŒè¡¨æ˜ï¼ŒSAIDåœ¨é™ä½æœ‰å®³è¾“å‡ºæ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„å‰æ²¿é˜²å¾¡æ‰‹æ®µã€‚æ­¤å¤–ï¼ŒSAIDåœ¨ä¿æŒæ¨¡å‹å¤„ç†è‰¯æ€§ä»»åŠ¡æ€§èƒ½çš„åŒæ—¶ï¼Œä»…äº§ç”Ÿæä½çš„è®¡ç®—å¼€é”€ã€‚è¯¥å·¥ä½œè¯å®äº†æ¿€æ´»LLMså†…åœ¨å®‰å…¨æœºåˆ¶æ˜¯æ„å»ºæ›´å®‰å…¨ã€å¯æ‰©å±•ä¸”å¯é çš„å¯¹é½AIç³»ç»Ÿçš„ä¸€æ¡ç¨³å¥è·¯å¾„ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20129v1",
      "published_date": "2025-10-23 02:07:54 UTC",
      "updated_date": "2025-10-23 02:07:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:46.363447+00:00"
    },
    {
      "arxiv_id": "2510.20109v1",
      "title": "The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice",
      "title_zh": "éªŒè¯-ä»·å€¼æ‚–è®ºï¼šæ³•å¾‹å®åŠ¡ä¸­ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„è§„èŒƒæ€§æ‰¹åˆ¤",
      "authors": [
        "Joshua Yuvaraj"
      ],
      "abstract": "It is often claimed that machine learning-based generative AI products will drastically streamline and reduce the cost of legal practice. This enthusiasm assumes lawyers can effectively manage AI's risks. Cases in Australia and elsewhere in which lawyers have been reprimanded for submitting inaccurate AI-generated content to courts suggest this paradigm must be revisited. This paper argues that a new paradigm is needed to evaluate AI use in practice, given (a) AI's disconnection from reality and its lack of transparency, and (b) lawyers' paramount duties like honesty, integrity, and not to mislead the court. It presents an alternative model of AI use in practice that more holistically reflects these features (the verification-value paradox). That paradox suggests increases in efficiency from AI use in legal practice will be met by a correspondingly greater imperative to manually verify any outputs of that use, rendering the net value of AI use often negligible to lawyers. The paper then sets out the paradox's implications for legal practice and legal education, including for AI use but also the values that the paradox suggests should undergird legal practice: fidelity to the truth and civic responsibility.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ æ”¯æŒçš„ Generative AI åœ¨æ³•å¾‹å®è·µä¸­èƒ½æ˜¾è‘—é™ä½æˆæœ¬çš„æ™®éå‡è®¾æå‡ºäº†æ‰¹åˆ¤æ€§å®¡è§†ã€‚è®ºæ–‡æŒ‡å‡ºï¼ŒåŸºäº AI ä¸ç°å®è„±èŠ‚ã€ç¼ºä¹é€æ˜åº¦ä»¥åŠå¾‹å¸ˆå¯¹æ³•åº­è´Ÿæœ‰çš„è¯šå®ä¸æ­£ç›´ä¹‰åŠ¡ï¼Œç°æœ‰çš„åº”ç”¨èŒƒå¼éœ€è¦è¢«é‡æ–°è¯„ä¼°ã€‚ä½œè€…æå‡ºäº†éªŒè¯ä»·å€¼æ‚–è®º (Verification-Value Paradox) æ¨¡å‹ï¼Œæ­ç¤ºäº† AI å¸¦æ¥çš„æ•ˆç‡æå‡ä¼šè¢«æ‰‹åŠ¨éªŒè¯è¾“å‡ºç»“æœçš„å¿…è¦æ€§æ‰€æŠµæ¶ˆï¼Œå¯¼è‡´ AI å¯¹å¾‹å¸ˆè€Œè¨€çš„å‡€ä»·å€¼å¾€å¾€å¾®ä¹å…¶å¾®ã€‚è¯¥ç ”ç©¶è¿›ä¸€æ­¥æ¢è®¨äº†è¿™ä¸€æ‚–è®ºå¯¹æ³•å¾‹å®åŠ¡ä¸æ³•å¾‹æ•™è‚²çš„å½±å“ï¼Œå¹¶å¼ºè°ƒæ³•å¾‹å®è·µçš„æ ¸å¿ƒåº”æ ¹æ¤äºå¯¹çœŸç†çš„å¿ è¯šå’Œå…¬æ°‘è´£ä»»æ„Ÿã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20109v1",
      "published_date": "2025-10-23 01:26:37 UTC",
      "updated_date": "2025-10-23 01:26:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:47.551401+00:00"
    },
    {
      "arxiv_id": "2510.20102v1",
      "title": "Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions",
      "title_zh": "é¢å‘æ•°å­—èµ„äº§äº¤æ˜“å¼‚å¸¸æ£€æµ‹çš„ä»¥äººä¸ºä¸­å¿ƒ LLM æ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Gyuyeon Na",
        "Minjung Park",
        "Hyeonjeong Cha",
        "Sangmi Chai"
      ],
      "abstract": "We present HCLA, a human-centered multi-agent system for anomaly detection in digital asset transactions. The system links three roles: Parsing, Detection, and Explanation, into a conversational workflow that lets non-experts ask questions in natural language, inspect structured analytics, and obtain context-aware rationales. Implemented with an open-source web UI, HCLA translates user intents into a schema for a classical detector (XGBoost in our prototype) and returns narrative explanations grounded in the underlying features. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the baseline detector reaches strong accuracy, while HCLA adds interpretability and interactive refinement. We describe the architecture, interaction loop, dataset, evaluation protocol, and limitations, and discuss how a human-in-the-loop design improves transparency and trust in financial forensics.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†HCLAï¼Œä¸€ç§ç”¨äºæ•°å­—èµ„äº§äº¤æ˜“å¼‚å¸¸æ£€æµ‹çš„ä»¥äººä¸ºæœ¬çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå°†Parsingã€Detectionå’ŒExplanationä¸‰ä¸ªè§’è‰²é›†æˆåˆ°å¯¹è¯å¼å·¥ä½œæµä¸­ï¼Œä½¿éä¸“ä¸šç”¨æˆ·èƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æé—®å¹¶è·å–å…·æœ‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„åˆç†è§£é‡Šã€‚HCLAåˆ©ç”¨å¼€æºWeb UIå°†ç”¨æˆ·æ„å›¾è½¬åŒ–ä¸ºXGBoostæ£€æµ‹å™¨å¯å¤„ç†çš„æ¨¡å¼ï¼Œå¹¶æä¾›åŸºäºåº•å±‚ç‰¹å¾çš„å™äº‹æ€§è¯´æ˜ã€‚åœ¨2020è‡³2024å¹´çš„æ¯”ç‰¹å¸æ··å¸æ•°æ®é›†ï¼ˆWasabi Walletï¼‰ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨ç»´æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†äº¤äº’å¼ç²¾ç‚¼å’Œç»“æœçš„å¯è§£é‡Šæ€§ã€‚é€šè¿‡è¿™ç§Human-in-the-loopè®¾è®¡ï¼ŒHCLAä¸ºé‡‘èå–è¯é¢†åŸŸæä¾›äº†æ›´é«˜çš„é€æ˜åº¦ä¸ä¿¡ä»»åº¦ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20102v1",
      "published_date": "2025-10-23 01:04:36 UTC",
      "updated_date": "2025-10-23 01:04:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:49.162830+00:00"
    },
    {
      "arxiv_id": "2510.20099v1",
      "title": "AI PB: A Grounded Generative Agent for Personalized Investment Insights",
      "title_zh": "AI PBï¼šé¢å‘ä¸ªæ€§åŒ–æŠ•èµ„è§è§£çš„å®è¯å‹ç”Ÿæˆå¼æ™ºèƒ½ä½“",
      "authors": [
        "Daewoo Park",
        "Suho Park",
        "Inseok Hong",
        "Hanwool Lee",
        "Junkyu Park",
        "Sangjun Lee",
        "Jeongman An",
        "Hyunbin Loh"
      ],
      "abstract": "We present AI PB, a production-scale generative agent deployed in real retail finance. Unlike reactive chatbots that answer queries passively, AI PB proactively generates grounded, compliant, and user-specific investment insights. It integrates (i) a component-based orchestration layer that deterministically routes between internal and external LLMs based on data sensitivity, (ii) a hybrid retrieval pipeline using OpenSearch and the finance-domain embedding model, and (iii) a multi-stage recommendation mechanism combining rule heuristics, sequential behavioral modeling, and contextual bandits. Operating fully on-premises under Korean financial regulations, the system employs Docker Swarm and vLLM across 24 X NVIDIA H100 GPUs. Through human QA and system metrics, we demonstrate that grounded generation with explicit routing and layered safety can deliver trustworthy AI insights in high-stakes finance.",
      "tldr_zh": "è¯¥ç ”ç©¶å±•ç¤ºäº† AI PBï¼Œä¸€ç§åœ¨å®é™…é›¶å”®é‡‘èé¢†åŸŸéƒ¨ç½²çš„ç”Ÿäº§è§„æ¨¡ç”Ÿæˆå¼æ™ºèƒ½ä½“(Generative Agent)ï¼Œæ—¨åœ¨ä¸»åŠ¨ç”Ÿæˆå…·æœ‰äº‹å®ä¾æ®ã€ç¬¦åˆåˆè§„æ€§ä¸”ç”¨æˆ·ç‰¹å®šçš„æŠ•èµ„è§è§£ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†åŸºäºç»„ä»¶çš„ç¼–æ’å±‚(Orchestration Layer)ï¼Œèƒ½å¤Ÿæ ¹æ®æ•°æ®æ•æ„Ÿæ€§åœ¨å†…éƒ¨å’Œå¤–éƒ¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¹‹é—´è¿›è¡Œç¡®å®šæ€§è·¯ç”±ã€‚åœ¨æŠ€æœ¯æ¶æ„ä¸Šï¼Œå®ƒç»“åˆäº†ä½¿ç”¨ OpenSearch å’Œé‡‘èé¢†åŸŸåµŒå…¥æ¨¡å‹(Finance-domain Embedding Model)çš„æ··åˆæ£€ç´¢ç®¡é“ï¼Œä»¥åŠåŒ…å«è§„åˆ™å¯å‘å¼ã€åºåˆ—è¡Œä¸ºå»ºæ¨¡å’Œä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœº(Contextual Bandits)çš„å¤šé˜¶æ®µæ¨èæœºåˆ¶ã€‚è¯¥ç³»ç»Ÿå®Œå…¨åœ¨æœ¬åœ°éƒ¨ç½²ä»¥ç¬¦åˆéŸ©å›½é‡‘èç›‘ç®¡è¦æ±‚ï¼Œå¹¶åˆ©ç”¨ Docker Swarm å’Œ vLLM åœ¨ 24 ç‰‡ NVIDIA H100 GPU ä¸Šè¿è¡Œã€‚é€šè¿‡äººå·¥è´¨æ£€å’Œç³»ç»ŸæŒ‡æ ‡è¯„ä¼°ï¼Œç ”ç©¶è¯æ˜äº†å…·æœ‰æ˜ç¡®è·¯ç”±å’Œåˆ†å±‚å®‰å…¨æœºåˆ¶çš„æœ‰æ ¹æ®ç”Ÿæˆ(Grounded Generation)èƒ½å¤Ÿåœ¨é«˜é£é™©é‡‘èé¢†åŸŸæä¾›å€¼å¾—ä¿¡èµ–çš„ AI è§è§£ã€‚",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2510.20099v1",
      "published_date": "2025-10-23 00:51:59 UTC",
      "updated_date": "2025-10-23 00:51:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:21:52.657364+00:00"
    },
    {
      "arxiv_id": "2510.20098v2",
      "title": "Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning",
      "title_zh": "é€šè¿‡è‡ªé€‚åº”è·¯ç”±ä¸é’ˆå¯¹æ€§æ¨ç†åœ¨å®ä½“é“¾æ¥ä¸­å‘æŒ¥å¤§è¯­è¨€æ¨¡å‹çš„ä½œç”¨",
      "authors": [
        "Yajie Li",
        "Albert Galimov",
        "Mitra Datta Ganapaneni",
        "Pujitha Thejaswi",
        "De Meng",
        "Priyanshu Kumar",
        "Saloni Potdar"
      ],
      "abstract": "Entity Linking (EL) has traditionally relied on large annotated datasets and extensive model fine-tuning. While recent few-shot methods leverage large language models (LLMs) through prompting to reduce training requirements, they often suffer from inefficiencies due to expensive LLM-based reasoning. ARTER (Adaptive Routing and Targeted Entity Reasoning) presents a structured pipeline that achieves high performance without deep fine-tuning by strategically combining candidate generation, context-based scoring, adaptive routing, and selective reasoning. ARTER computes a small set of complementary signals(both embedding and LLM-based) over the retrieved candidates to categorize contextual mentions into easy and hard cases. The cases are then handled by a low-computational entity linker (e.g. ReFinED) and more expensive targeted LLM-based reasoning respectively. On standard benchmarks, ARTER outperforms ReFinED by up to +4.47%, with an average gain of +2.53% on 5 out of 6 datasets, and performs comparably to pipelines using LLM-based reasoning for all mentions, while being as twice as efficient in terms of the number of LLM tokens.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ARTER (Adaptive Routing and Targeted Entity Reasoning)ï¼Œä¸€ç§æ—¨åœ¨å¹³è¡¡å®ä½“é“¾æ¥ (Entity Linking) æ€§èƒ½ä¸æ•ˆç‡çš„ç»“æ„åŒ–æµæ°´çº¿ã€‚ARTERé€šè¿‡ç»“åˆå€™é€‰ç”Ÿæˆ (candidate generation)ã€ä¸Šä¸‹æ–‡è¯„åˆ† (context-based scoring) å’Œè‡ªé€‚åº”è·¯ç”± (adaptive routing)ï¼Œè®¡ç®—äº’è¡¥ä¿¡å·å¹¶å°†ä¸Šä¸‹æ–‡æåŠé¡¹åˆ†ç±»ä¸ºç®€å•å’Œå›°éš¾æ¡ˆä¾‹ã€‚ç®€å•æ¡ˆä¾‹ç”±ä½è®¡ç®—å¼€é”€çš„é“¾æ¥å™¨ (å¦‚ ReFinED) å¤„ç†ï¼Œè€Œå›°éš¾æ¡ˆä¾‹åˆ™äº¤ç”±é’ˆå¯¹æ€§çš„ Large Language Models (LLMs) æ¨ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒARTERåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äº ReFinEDï¼Œå¹³å‡æ€§èƒ½æå‡ 2.53%ï¼Œæœ€é«˜æå‡è¾¾ 4.47%ã€‚ä¸å®Œå…¨ä¾èµ– LLM æ¨ç†çš„æ–¹æ¡ˆç›¸æ¯”ï¼ŒARTER åœ¨ä¿æŒç›¸å½“æ€§èƒ½çš„å‰æä¸‹ï¼Œå°† token ä½¿ç”¨æ•ˆç‡æé«˜äº†ä¸€å€ï¼Œä¸ºé«˜æ•ˆåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å¤„ç†å¤æ‚ä¿¡æ¯æŠ½å–ä»»åŠ¡æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025 Industry Track",
      "pdf_url": "https://arxiv.org/pdf/2510.20098v2",
      "published_date": "2025-10-23 00:50:14 UTC",
      "updated_date": "2025-11-19 09:50:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:22:02.150653+00:00"
    },
    {
      "arxiv_id": "2510.20094v2",
      "title": "On the Structure of Stationary Solutions to McKean-Vlasov Equations with Applications to Noisy Transformers",
      "title_zh": "McKean-Vlasov æ–¹ç¨‹å¹³ç¨³è§£çš„ç»“æ„åŠå…¶åœ¨å«å™ª Transformer ä¸­çš„åº”ç”¨",
      "authors": [
        "Krishnakumar Balasubramanian",
        "Sayan Banerjee",
        "Philippe Rigollet"
      ],
      "abstract": "We study stationary solutions of McKean-Vlasov equations on the circle. Our main contributions stem from observing an exact equivalence between solutions of the stationary McKean-Vlasov equation and an infinite-dimensional quadratic system of equations over Fourier coefficients, which allows explicit characterization of the stationary states in a sequence space rather than a function space. This framework provides a transparent description of local bifurcations, characterizing their periodicity, and resonance structures, while accommodating singular potentials. We derive analytic expressions that characterize the emergence, form and shape (supercritical, critical, subcritical or transcritical) of bifurcations involving possibly multiple Fourier modes and connect them with discontinuous phase transitions. We also characterize, under suitable assumptions, the detailed structure of the stationary bifurcating solutions that are accurate upto an arbitrary number of Fourier modes. At the global level, we establish regularity and concavity properties of the free energy landscape, proving existence, compactness, and coexistence of globally minimizing stationary measures, further identifying discontinuous phase transitions with points of non-differentiability of the minimum free energy map. As an application, we specialize the theory to the Noisy Mean-Field Transformer model, where we show how changing the inverse temperature parameter $Î²$ affects the geometry of the infinitely many bifurcations from the uniform measure. We also explain how increasing $Î²$ can lead to a rich class of approximate multi-mode stationary solutions which can be seen as `metastable states'. Further, a sharp transition from continuous to discontinuous (first-order) phase behavior is observed as $Î²$ increases.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ†å‘¨ä¸Š McKean-Vlasov æ–¹ç¨‹å¹³ç¨³è§£ (stationary solutions) çš„ç»“æ„ï¼Œæ­ç¤ºäº†è¯¥æ–¹ç¨‹çš„è§£ä¸å‚…é‡Œå¶ç³»æ•° (Fourier coefficients) ä¸Šçš„æ— é™ç»´äºŒæ¬¡æ–¹ç¨‹ç»„ä¹‹é—´çš„ç²¾ç¡®ç­‰ä»·æ€§ã€‚è¿™ä¸€æ¡†æ¶å®ç°äº†åœ¨åºåˆ—ç©ºé—´è€Œéå‡½æ•°ç©ºé—´ä¸­å¯¹å¹³ç¨³çŠ¶æ€çš„æ˜¾å¼è¡¨å¾ï¼Œä»è€Œèƒ½å¤Ÿç²¾ç¡®åˆ»ç”»å±€éƒ¨åˆ†å‰ (local bifurcations) çš„å‘¨æœŸæ€§ã€å…±æŒ¯ç»“æ„ä»¥åŠä¸åŒç±»å‹çš„ç›¸å˜ã€‚åœ¨å…¨å±€å±‚é¢ï¼Œç ”ç©¶è¯æ˜äº†è‡ªç”±èƒ½æ™¯è§‚ (free energy landscape) çš„æ­£åˆ™æ€§ä¸å‡¹æ€§ï¼Œå¹¶ç¡®å®šäº†å…¨å±€æœ€å°åŒ–å¹³ç¨³æµ‹åº¦çš„å­˜åœ¨æ€§åŠå…¶ä¸ä¸è¿ç»­ç›¸å˜çš„å†…åœ¨è”ç³»ã€‚ä½œä¸ºåº”ç”¨ï¼Œè¯¥ç†è®ºè¢«ç”¨äºåˆ†ææœ‰å™ªå‡å€¼åœº Transformer (Noisy Mean-Field Transformer) æ¨¡å‹ï¼Œé˜æ˜äº†é€†æ¸©åº¦å‚æ•° $\\beta$ å¦‚ä½•å½±å“åˆ†å‰çš„å‡ ä½•ç»“æ„ã€‚åˆ†æè¡¨æ˜ï¼Œéšç€ $\\beta$ çš„å¢åŠ ï¼Œç³»ç»Ÿä¼šäº§ç”Ÿä¸°å¯Œçš„è¿‘ä¼¼å¤šæ¨¡æ€å¹³ç¨³è§£ï¼ˆå³äºšç¨³æ€ï¼‰ï¼Œå¹¶è§‚å¯Ÿåˆ°ä»è¿ç»­ç›¸å˜åˆ°ä¸è¿ç»­ç›¸å˜çš„å°–é”è½¬åŒ–ã€‚",
      "categories": [
        "math.PR",
        "cs.AI",
        "cs.LG",
        "math.AP",
        "stat.ML"
      ],
      "primary_category": "math.PR",
      "comment": "46 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.20094v2",
      "published_date": "2025-10-23 00:28:32 UTC",
      "updated_date": "2025-10-27 17:12:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:22:03.859309+00:00"
    },
    {
      "arxiv_id": "2510.20093v1",
      "title": "StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback",
      "title_zh": "StableSketcherï¼šåˆ©ç”¨è§†è§‰é—®ç­”åé¦ˆå¢å¼ºæ‰©æ•£æ¨¡å‹çš„åƒç´ çº§è‰å›¾ç”Ÿæˆ",
      "authors": [
        "Jiho Park",
        "Sieun Choi",
        "Jaeyoon Seo",
        "Jihie Kim"
      ],
      "abstract": "Although recent advancements in diffusion models have significantly enriched the quality of generated images, challenges remain in synthesizing pixel-based human-drawn sketches, a representative example of abstract expression. To combat these challenges, we propose StableSketcher, a novel framework that empowers diffusion models to generate hand-drawn sketches with high prompt fidelity. Within this framework, we fine-tune the variational autoencoder to optimize latent decoding, enabling it to better capture the characteristics of sketches. In parallel, we integrate a new reward function for reinforcement learning based on visual question answering, which improves text-image alignment and semantic consistency. Extensive experiments demonstrate that StableSketcher generates sketches with improved stylistic fidelity, achieving better alignment with prompts compared to the Stable Diffusion baseline. Additionally, we introduce SketchDUO, to the best of our knowledge, the first dataset comprising instance-level sketches paired with captions and question-answer pairs, thereby addressing the limitations of existing datasets that rely on image-label pairs. Our code and dataset will be made publicly available upon acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† StableSketcherï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å¢å¼º Diffusion Model ä»¥ç”Ÿæˆå…·æœ‰é«˜ Prompt Fidelity çš„æ‰‹ç»˜è‰å›¾çš„æ–°æ¡†æ¶ã€‚é’ˆå¯¹åƒç´ çº§è‰å›¾ç”Ÿæˆçš„æŠ½è±¡è¡¨è¾¾æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶é€šè¿‡å¾®è°ƒ Variational Autoencoder (VAE) æ¥ä¼˜åŒ–æ½œåœ¨è§£ç ï¼Œä»è€Œæ›´ç²¾å‡†åœ°æ•æ‰è‰å›¾çš„çº¿æ¡ç‰¹å¾ã€‚åŒæ—¶ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäº Visual Question Answering (VQA) åé¦ˆçš„å¼ºåŒ–å­¦ä¹ å¥–åŠ±å‡½æ•°ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆå†…å®¹ä¸æ–‡æœ¬æç¤ºä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…å‘å¸ƒäº† SketchDUO æ•°æ®é›†ï¼Œè¿™æ˜¯é¦–ä¸ªåŒ…å«å®ä¾‹çº§è‰å›¾ã€æè¿°åŠé—®ç­”å¯¹çš„æ•°æ®é›†ï¼Œå¡«è¡¥äº†ç°æœ‰å­¦æœ¯èµ„æºçš„ç©ºç™½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒStableSketcher åœ¨è§†è§‰é£æ ¼å¿ å®åº¦å’Œæ–‡æœ¬å¯¹é½æ€§èƒ½ä¸Šå‡ä¼˜äº Stable Diffusion åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review at IEEE Access. Author-submitted preprint. Not the IEEE-published version",
      "pdf_url": "https://arxiv.org/pdf/2510.20093v1",
      "published_date": "2025-10-23 00:27:32 UTC",
      "updated_date": "2025-10-23 00:27:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:22:03.660992+00:00"
    },
    {
      "arxiv_id": "2510.20091v1",
      "title": "CreativityPrism: A Holistic Benchmark for Large Language Model Creativity",
      "title_zh": "CreativityPrismï¼šå¤§è¯­è¨€æ¨¡å‹åˆ›é€ åŠ›çš„å…¨é¢è¯„ä¼°åŸºå‡†",
      "authors": [
        "Zhaoyi Joey Hou",
        "Bowei Alvin Zhang",
        "Yining Lu",
        "Bhiman Kumar Baghel",
        "Anneliese Brei",
        "Ximing Lu",
        "Meng Jiang",
        "Faeze Brahman",
        "Snigdha Chaturvedi",
        "Haw-Shiuan Chang",
        "Daniel Khashabi",
        "Xiang Lorraine Li"
      ],
      "abstract": "Creativity is often seen as a hallmark of human intelligence. While large language models (LLMs) are increasingly perceived as producing creative text, there is still no holistic framework to evaluate their creativity across diverse scenarios. Existing evaluation methods remain fragmented, with dramatic variation across domains and tasks, largely due to differing definitions and measurements of creativity. Inspired by the hypothesis that creativity is not one fixed idea, we propose CreativityPrism, an evaluation analysis framework that decomposes creativity into three dimensions: quality, novelty, and diversity. CreativityPrism incorporates nine tasks, three domains, i.e., divergent thinking, creative writing, and logical reasoning, and twenty evaluation metrics, which measure each dimension in task-specific, unique ways. We evaluate 17 state-of-the-art (SoTA) proprietary and open-sourced LLMs on CreativityPrism and analyze the performance correlations among different metrics and task domains. Our results reveal a notable gap between proprietary and open-source models. Overall, model performance tends to be highly correlated across tasks within the same domain and less so across different domains. Among evaluation dimensions, diversity and quality metrics show strong correlations - models that perform well on one often excel on the other - whereas novelty exhibits much weaker correlation with either. These findings support our hypothesis that strong performance in one creativity task or dimension does not necessarily generalize to others, underscoring the need for a holistic evaluation of LLM creativity.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CreativityPrismï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå…¨é¢è¯„ä¼° Large Language Model (LLM) åˆ›é€ åŠ›çš„åˆ†ææ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†åˆ›é€ åŠ›åˆ†è§£ä¸ºè´¨é‡ (quality)ã€æ–°é¢–æ€§ (novelty) å’Œå¤šæ ·æ€§ (diversity) ä¸‰ä¸ªç»´åº¦ï¼Œæ¶µç›–äº†å‘æ•£æ€§æ€ç»´ (divergent thinking)ã€åˆ›æ„å†™ä½œ (creative writing) å’Œé€»è¾‘æ¨ç† (logical reasoning) ä¸‰ä¸ªé¢†åŸŸçš„ä¹é¡¹ä»»åŠ¡åŠäºŒåä¸ªè¯„ä¼°æŒ‡æ ‡ã€‚é€šè¿‡å¯¹ 17 ä¸ªå‰æ²¿çš„é—­æºå’Œå¼€æº LLM è¿›è¡Œè¯„ä¼°ï¼Œç ”ç©¶å‘ç°é—­æºæ¨¡å‹ä¸å¼€æºæ¨¡å‹ä¹‹é—´å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®è·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨åŒä¸€é¢†åŸŸå†…çš„ä»»åŠ¡è¡¨ç°é«˜åº¦ç›¸å…³ï¼Œä½†åœ¨ä¸åŒé¢†åŸŸé—´çš„ç›¸å…³æ€§è¾ƒä½ã€‚æ­¤å¤–ï¼Œå¤šæ ·æ€§ä¸è´¨é‡æŒ‡æ ‡è¡¨ç°å‡ºå¼ºç›¸å…³æ€§ï¼Œè€Œæ–°é¢–æ€§ä¸å…¶ä»–ä¸¤ä¸ªç»´åº¦çš„ç›¸å…³æ€§è¾ƒå¼±ã€‚è¿™äº›å‘ç°è¯æ˜äº†åœ¨æŸä¸€åˆ›é€ åŠ›ç»´åº¦ä¸Šçš„ä¼˜åŠ¿å¹¶ä¸ä¸€å®šèƒ½æ³›åŒ–è‡³å…¶ä»–ç»´åº¦ï¼Œä»è€Œå¼ºè°ƒäº†å¯¹ LLM åˆ›é€ åŠ›è¿›è¡Œå¤šç»´åº¦ã€å…¨æ–¹ä½è¯„ä¼°çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20091v1",
      "published_date": "2025-10-23 00:22:10 UTC",
      "updated_date": "2025-10-23 00:22:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:22:05.249229+00:00"
    },
    {
      "arxiv_id": "2510.20084v2",
      "title": "ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models",
      "title_zh": "ShapeXï¼šåŸºäºå½¢çŠ¶å­åºåˆ—é©±åŠ¨çš„æ—¶é—´åºåˆ—åˆ†ç±»æ¨¡å‹äº‹åè§£é‡Š",
      "authors": [
        "Bosong Huang",
        "Ming Jin",
        "Yuxuan Liang",
        "Johan Barthelemy",
        "Debo Cheng",
        "Qingsong Wen",
        "Chenghao Liu",
        "Shirui Pan"
      ],
      "abstract": "Explaining time series classification models is crucial, particularly in high-stakes applications such as healthcare and finance, where transparency and trust play a critical role. Although numerous time series classification methods have identified key subsequences, known as shapelets, as core features for achieving state-of-the-art performance and validating their pivotal role in classification outcomes, existing post-hoc time series explanation (PHTSE) methods primarily focus on timestep-level feature attribution. These explanation methods overlook the fundamental prior that classification outcomes are predominantly driven by key shapelets. To bridge this gap, we present ShapeX, an innovative framework that segments time series into meaningful shapelet-driven segments and employs Shapley values to assess their saliency. At the core of ShapeX lies the Shapelet Describe-and-Detect (SDD) framework, which effectively learns a diverse set of shapelets essential for classification. We further demonstrate that ShapeX produces explanations which reveal causal relationships instead of just correlations, owing to the atomicity properties of shapelets. Experimental results on both synthetic and real-world datasets demonstrate that ShapeX outperforms existing methods in identifying the most relevant subsequences, enhancing both the precision and causal fidelity of time series explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶é—´åºåˆ—åˆ†ç±»æ¨¡å‹ï¼ˆTime Series Classificationï¼‰çš„å¯è§£é‡Šæ€§é—®é¢˜ï¼ŒæŒ‡å‡ºç›®å‰çš„åéªŒè§£é‡Šæ–¹æ³•ï¼ˆPost-hoc Time Series Explanation, PHTSEï¼‰å¤šèšç„¦äºæ—¶é—´æ­¥é•¿çº§åˆ«çš„ç‰¹å¾å½’å› ï¼Œå¿½ç•¥äº†åˆ†ç±»ç»“æœé€šå¸¸ç”±å…³é”®å­åºåˆ—å³ Shapelets é©±åŠ¨è¿™ä¸€æ ¸å¿ƒå…ˆéªŒã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†åˆ›æ–°æ¡†æ¶ ShapeXï¼Œé€šè¿‡å°†æ—¶é—´åºåˆ—åˆ†å‰²ä¸ºåŸºäº Shapelet çš„æ®µå¹¶é‡‡ç”¨ Shapley values æ¥è¯„ä¼°å…¶æ˜¾è‘—æ€§ã€‚ShapeX çš„æ ¸å¿ƒæ˜¯ Shapelet Describe-and-Detect (SDD) æ¡†æ¶ï¼Œæ—¨åœ¨æœ‰æ•ˆå­¦ä¹ å¯¹åˆ†ç±»è‡³å…³é‡è¦çš„å¤šæ ·åŒ– Shapelets é›†åˆã€‚ç ”ç©¶è¯æ˜ï¼Œå‡­å€Ÿ Shapelets çš„åŸå­æ€§è´¨ï¼ŒShapeX èƒ½å¤Ÿæ­ç¤ºæ•°æ®ä¸­çš„å› æœå…³ç³»è€Œéç®€å•çš„ç›¸å…³æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒShapeX åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†è¯†åˆ«ç›¸å…³å­åºåˆ—çš„ç²¾ç¡®åº¦åŠè§£é‡Šçš„å› æœä¿çœŸåº¦ï¼ˆCausal Fidelityï¼‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.20084v2",
      "published_date": "2025-10-23 00:01:40 UTC",
      "updated_date": "2025-10-25 03:23:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:22:16.567572+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 191,
  "processed_papers_count": 191,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-25T05:23:12.796478+00:00"
}