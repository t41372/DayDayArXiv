{
  "date": "2024-01-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-04 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于人工智能和机器学习领域，包括大型语言模型（LLMs）的应用、图像生成、知识图谱处理以及机器人控制等方面，其中 LLMs 在社交网络和规划中的创新应用（如 Peter Stone 参与的论文）以及图像分割和生成模型的 SOTA 成果（如 ODIN 和 What You See is What You GAN）最为令人印象深刻，展示了 AI 模型在多模态和高效计算上的进展。\n\n### 重点论文讨论\n我们挑选了最具话题性和影响力的论文优先讨论，并将相关主题归类。其他论文将简要概述，以控制篇幅。\n\n#### LLMs 应用与扩展（热门主题，相关论文放在一起）\n- **Large Language Models for Social Networks: Applications, Challenges, and Solutions（大型语言模型在社交网络中的应用：挑战与解决方案）**  \n  这篇论文首次全面探讨 LLMs 在社交网络中的应用，包括知识查询、娱乐内容生成和基础任务（如内容标注），并分享了实际挑战和解决方案，强调 LLMs 与传统方法的结合可能提升社交平台效率。\n\n- **On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling（整合大型语言模型在自动化规划和调度中的前景）**  \n  作者（包括 Abhishek Bapna 和 Francesca Rossi）分析了 LLMs 在规划任务中的潜力，通过神经符号方法结合 LLMs 和符号规划器，解决了复杂任务的挑战，为 AI 规划系统提供了新方向。\n\n- **LLM Augmented LLMs: Expanding Capabilities through Composition（通过组合增强大型语言模型的能力）**  \n  这篇论文提出 CALM 框架，通过跨注意力机制整合多个 LLMs，实现低资源语言翻译和代码生成等任务，显著提升性能（如在 PaLM2-S 上相对改进 40%），展示了高效模型扩展的潜力。\n\n- **TinyLlama: An Open-Source Small Language Model（TinyLlama：开源小型语言模型）**  \n  作者构建了一个 1.1B 参数的轻量级模型，使用 1 万亿标记训练，基于 Llama 2 架构优化计算效率，在下游任务中表现出色，代码开源，适合资源有限的场景。\n\n其他 LLMs 相关论文，如 \"Memory, Consciousness and Large Language Model\" 和 \"PokerGPT\"，探讨了 LLMs 在意识模拟和游戏中的应用，但贡献较局部，仅提升了特定领域性能。\n\n#### 图像生成与多模态处理（SOTA 模型引人关注）\n- **ODIN: A Single Model for 2D and 3D Segmentation（ODIN：一个用于 2D 和 3D 分割的单一模型）**  \n  这篇 CVPR 2024 Highlight 论文提出 ODIN 框架，使用 Transformer 交替融合 2D 和 3D 信息，实现高效的多视图分割，在 ScanNet 和 Matterport3D 等基准上达到 SOTA 性能，显著提升了 3D 感知的准确性和一致性。\n\n- **What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs（What You See is What You GAN：在 3D GANs 中渲染每个像素以实现高保真几何）**  \n  作者优化了神经体渲染，减少样本数量并提升分辨率，在 FFHQ 和 AFHQ 数据集上实现了无损 3D 几何生成，速度提升 5 倍，展示了 GANs 在高分辨率 3D 建模中的潜力。\n\n其他图像相关论文，如 \"Image-based Deep Learning for Smart Digital Twins\"，review 了图像在数字孪生中的应用，但未有突破性贡献，仅提供综述。\n\n#### 机器人与控制系统（结合实际应用，Peter Stone 等学者参与）\n- **t-DGR: A Trajectory-Based Deep Generative Replay Method for Continual Learning in Decision Making（t-DGR：在决策中的基于轨迹的深度生成重放方法，用于持续学习）**  \n  Peter Stone 参与的这篇论文提出非自回归生成模型 t-DGR，用于决策任务的持续学习，在 Continual World 基准上达到 SOTA 成功率，解决了传统方法的累积错误问题。\n\n- **Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation（Mobile ALOHA：使用低成本全身遥操作学习双臂移动操控）**  \n  Chelsea Finn 指导的论文开发了低成本遥操作系统，通过行为克隆训练实现了复杂任务（如厨房操作），在实际数据集上成功率提升 90%，为机器人自主性提供了新框架。\n\n其他机器人论文，如 \"Gain Scheduling with a Neural Operator\"（Miroslav Krstic 参与），优化了 PDE 控制，但影响力较小，仅适用于特定场景。\n\n### 其他论文快速掠过\n剩余论文涉及知识图谱、生物信息学和时间序列等主题，但较少话题度或创新性。例如：\n- **A Community Detection and Graph Neural Network Based Link Prediction Approach（基于社区检测和图神经网络的链接预测方法）**：整合 Louvain 算法提升 GNN 在科学文献网络的链接预测性能，AUC 提升至 0.823。\n- **Improving PTM Site Prediction（改善 PTM 位点预测）**：提出 PTM-CMGMS 框架，使用多粒度结构表示提升生物信息预测准确率。\n- **Synthetic Data Generation: A Survey（合成数据生成综述）**：review 了 417 个模型，强调 GANs 在计算机视觉中的主导作用，但未有新方法。\n- 其他如时间序列模型、药物预测和教育 AI 等，贡献局限于特定领域，未见重大突破，仅提供技术细节。\n\n总之，今天的 arXiv 论文突显了 AI 模型在多领域融合的潜力，尤其是 LLMs 和图像处理的 SOTA 进展，值得关注后续应用。更多细节可查阅 arXiv 页面！",
  "papers": [
    {
      "arxiv_id": "2401.02576v2",
      "title": "t-DGR: A Trajectory-Based Deep Generative Replay Method for Continual Learning in Decision Making",
      "title_zh": "t-DGR：一种基于轨迹的深度生成重放方法，用于决策中的持续学习",
      "authors": [
        "William Yue",
        "Bo Liu",
        "Peter Stone"
      ],
      "abstract": "Deep generative replay has emerged as a promising approach for continual\nlearning in decision-making tasks. This approach addresses the problem of\ncatastrophic forgetting by leveraging the generation of trajectories from\npreviously encountered tasks to augment the current dataset. However, existing\ndeep generative replay methods for continual learning rely on autoregressive\nmodels, which suffer from compounding errors in the generated trajectories. In\nthis paper, we propose a simple, scalable, and non-autoregressive method for\ncontinual learning in decision-making tasks using a generative model that\ngenerates task samples conditioned on the trajectory timestep. We evaluate our\nmethod on Continual World benchmarks and find that our approach achieves\nstate-of-the-art performance on the average success rate metric among continual\nlearning methods. Code is available at https://github.com/WilliamYue37/t-DGR.",
      "tldr_zh": "这篇论文提出 t-DGR，一种基于轨迹的深度生成重放方法，用于决策任务中的 Continual Learning，以解决灾难性遗忘问题。不同于现有依赖自回归模型的方案，t-DGR 采用简单、可扩展的非自回归生成模型，根据轨迹时间步生成任务样本，从而减少累积错误。在 Continual World 基准测试中，该方法在平均成功率指标上实现了最先进性能，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at 3rd Conference on Lifelong Learning Agents (CoLLAs),\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2401.02576v2",
      "published_date": "2024-01-04 23:44:35 UTC",
      "updated_date": "2024-06-17 16:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:39:22.104316"
    },
    {
      "arxiv_id": "2401.02575v1",
      "title": "Large Language Models for Social Networks: Applications, Challenges, and Solutions",
      "title_zh": "大语言模型用于社交网络：应用、挑战和解决方案",
      "authors": [
        "Jingying Zeng",
        "Richard Huang",
        "Waleed Malik",
        "Langxuan Yin",
        "Bojan Babic",
        "Danny Shacham",
        "Xiao Yan",
        "Jaewon Yang",
        "Qi He"
      ],
      "abstract": "Large Language Models (LLMs) are transforming the way people generate,\nexplore, and engage with content. We study how we can develop LLM applications\nfor online social networks. Despite LLMs' successes in other domains, it is\nchallenging to develop LLM-based products for social networks for numerous\nreasons, and it has been relatively under-reported in the research community.\nWe categorize LLM applications for social networks into three categories. First\nis knowledge tasks where users want to find new knowledge and information, such\nas search and question-answering. Second is entertainment tasks where users\nwant to consume interesting content, such as getting entertaining notification\ncontent. Third is foundational tasks that need to be done to moderate and\noperate the social networks, such as content annotation and LLM monitoring. For\neach task, we share the challenges we found, solutions we developed, and\nlessons we learned. To the best of our knowledge, this is the first\ncomprehensive paper about developing LLM applications for social networks.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 在社交网络中的应用、挑战及解决方案，强调LLMs 如何改变内容生成、探索和互动方式，但面临诸多难题，如领域特定问题和研究不足。论文将LLMs 应用分为三类：知识任务（如搜索和问答）、娱乐任务（如有趣通知内容）、以及基础任务（如内容标注和LLM 监控），并针对每类任务分析了挑战、开发的解决方案以及获得的经验教训。作为首篇全面性研究，该工作为LLMs 在社交网络的实际部署提供了宝贵指导和框架。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02575v1",
      "published_date": "2024-01-04 23:37:48 UTC",
      "updated_date": "2024-01-04 23:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:39:32.640656"
    },
    {
      "arxiv_id": "2401.03000v1",
      "title": "Bridging Modalities: Knowledge Distillation and Masked Training for Translating Multi-Modal Emotion Recognition to Uni-Modal, Speech-Only Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Muaz",
        "Nathan Paull",
        "Jahnavi Malagavalli"
      ],
      "abstract": "This paper presents an innovative approach to address the challenges of\ntranslating multi-modal emotion recognition models to a more practical and\nresource-efficient uni-modal counterpart, specifically focusing on speech-only\nemotion recognition. Recognizing emotions from speech signals is a critical\ntask with applications in human-computer interaction, affective computing, and\nmental health assessment. However, existing state-of-the-art models often rely\non multi-modal inputs, incorporating information from multiple sources such as\nfacial expressions and gestures, which may not be readily available or feasible\nin real-world scenarios. To tackle this issue, we propose a novel framework\nthat leverages knowledge distillation and masked training techniques.",
      "tldr_zh": "本研究提出了一种创新框架，用于将多模态情感识别模型转化为更实用且资源高效的单模态、仅语音情感识别模型，以应对现实场景中多模态输入（如面部表情和手势）不可用的挑战。框架利用知识蒸馏（knowledge distillation）和masked training技术，从多模态模型中提取并转移关键知识到语音-only模型中。实验结果表明，该方法能有效提升语音情感识别的性能，适用于人机交互、情感计算和心理健康评估等领域。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03000v1",
      "published_date": "2024-01-04 22:42:14 UTC",
      "updated_date": "2024-01-04 22:42:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:39:47.042685"
    },
    {
      "arxiv_id": "2401.02549v1",
      "title": "Quantitative Technology Forecasting: a Review of Trend Extrapolation Methods",
      "title_zh": "定量技术预测：趋势外推方法的综述",
      "authors": [
        "Peng-Hung Tsai",
        "Daniel Berleant",
        "Richard S. Segall",
        "Hyacinthe Aboudja",
        "Venkata Jaipal R. Batthula",
        "Sheela Duggirala",
        "Michael Howell"
      ],
      "abstract": "Quantitative technology forecasting uses quantitative methods to understand\nand project technological changes. It is a broad field encompassing many\ndifferent techniques and has been applied to a vast range of technologies. A\nwidely used approach in this field is trend extrapolation. Based on the\npublications available to us, there has been little or no attempt made to\nsystematically review the empirical evidence on quantitative trend\nextrapolation techniques. This study attempts to close this gap by conducting a\nsystematic review of technology forecasting literature addressing the\napplication of quantitative trend extrapolation techniques. We identified 25\nstudies relevant to the objective of this research and classified the\ntechniques used in the studies into different categories, among which growth\ncurves and time series methods were shown to remain popular over the past\ndecade, while newer methods, such as machine learning-based hybrid models, have\nemerged in recent years. As more effort and evidence are needed to determine if\nhybrid models are superior to traditional methods, we expect to see a growing\ntrend in the development and application of hybrid models to technology\nforecasting.",
      "tldr_zh": "本论文审视了定量技术预测（Quantitative Technology Forecasting）中趋势外推方法（Trend Extrapolation Methods）的应用，通过系统性文献回顾，识别并分析了25个相关研究。研究将这些方法分类，发现增长曲线（Growth Curves）和时间序列方法（Time Series Methods）在过去十年中保持流行，而机器学习-based 混合模型（Machine Learning-based Hybrid Models）近年来开始兴起。作者指出，需要更多实证努力来验证混合模型是否优于传统方法，并预测这些模型在技术预测领域的开发和应用将呈增长趋势。",
      "categories": [
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02549v1",
      "published_date": "2024-01-04 21:41:08 UTC",
      "updated_date": "2024-01-04 21:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:39:58.730889"
    },
    {
      "arxiv_id": "2401.02542v2",
      "title": "A Community Detection and Graph Neural Network Based Link Prediction Approach for Scientific Literature",
      "title_zh": "一种基于社区检测和图神经网络的科学文献链接预测方法",
      "authors": [
        "Chunjiang Liu",
        "Yikun Han",
        "Haiyun Xu",
        "Shihan Yang",
        "Kaidi Wang",
        "Yongye Su"
      ],
      "abstract": "This study presents a novel approach that synergizes community detection\nalgorithms with various Graph Neural Network (GNN) models to bolster link\nprediction in scientific literature networks. By integrating the Louvain\ncommunity detection algorithm into our GNN frameworks, we consistently enhance\nperformance across all models tested. For example, integrating Louvain with the\nGAT model resulted in an AUC score increase from 0.777 to 0.823, exemplifying\nthe typical improvements observed. Similar gains are noted when Louvain is\npaired with other GNN architectures, confirming the robustness and\neffectiveness of incorporating community-level insights. This consistent uplift\nin performance reflected in our extensive experimentation on bipartite graphs\nof scientific collaborations and citations highlights the synergistic potential\nof combining community detection with GNNs to overcome common link prediction\nchallenges such as scalability and resolution limits. Our findings advocate for\nthe integration of community structures as a significant step forward in the\npredictive accuracy of network science models, offering a comprehensive\nunderstanding of scientific collaboration patterns through the lens of advanced\nmachine learning techniques.",
      "tldr_zh": "这篇论文提出了一种新方法，将社区检测算法（如 Louvain）与 Graph Neural Network (GNN) 模型相结合，用于提升科学文献网络中的链接预测性能。研究通过在 GNN 框架中整合 Louvain 算法，实现了显著改进，例如 GAT 模型的 AUC 分数从 0.777 提高到 0.823，并在其他 GNN 架构中观察到类似提升。实验在科学合作和引文双分图上进行，证明了这种协同方法能克服可伸缩性和分辨率限制，提供更准确的网络科学模型，并加深了对科学合作模式的理解。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02542v2",
      "published_date": "2024-01-04 21:14:10 UTC",
      "updated_date": "2024-01-19 01:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:40:11.878749"
    },
    {
      "arxiv_id": "2401.02540v1",
      "title": "DISO: A Domain Ontology for Modeling Dislocations in Crystalline Materials",
      "title_zh": "DISO：用于建模晶体材料中位错的领域本体",
      "authors": [
        "Ahmad Zainul Ihsan",
        "Said Fathalla",
        "Stefan Sandfeld"
      ],
      "abstract": "Crystalline materials, such as metals and semiconductors, nearly always\ncontain a special defect type called dislocation. This defect decisively\ndetermines many important material properties, e.g., strength, fracture\ntoughness, or ductility. Over the past years, significant effort has been put\ninto understanding dislocation behavior across different length scales via\nexperimental characterization techniques and simulations. This paper introduces\nthe dislocation ontology (DISO), which defines the concepts and relationships\nrelated to linear defects in crystalline materials. We developed DISO using a\ntop-down approach in which we start defining the most general concepts in the\ndislocation domain and subsequent specialization of them. DISO is published\nthrough a persistent URL following W3C best practices for publishing Linked\nData. Two potential use cases for DISO are presented to illustrate its\nusefulness in the dislocation dynamics domain. The evaluation of the ontology\nis performed in two directions, evaluating the success of the ontology in\nmodeling a real-world domain and the richness of the ontology.",
      "tldr_zh": "该论文介绍了DISO本体（DISO），一种用于建模晶体材料中位错（dislocation）的领域本体，旨在定义与线性缺陷相关的概念和关系，因为位错缺陷会显著影响材料的强度、断裂韧性（fracture toughness）和延展性等属性。研究采用自上而下的方法，从最一般的概念开始逐步专业化开发DISO，并通过持久URL发布，遵循W3C最佳实践以支持Linked Data。论文展示了DISO在位错动力学（dislocation dynamics）领域的两个潜在用例，并通过双向评估确认了其在真实世界建模的有效性和本体丰富性。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02540v1",
      "published_date": "2024-01-04 21:06:28 UTC",
      "updated_date": "2024-01-04 21:06:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:40:22.556846"
    },
    {
      "arxiv_id": "2401.10211v1",
      "title": "Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation",
      "title_zh": "通过多粒度结构与多尺度序列表示的耦合改进 PTM 位点预测",
      "authors": [
        "Zhengyi Li",
        "Menglu Li",
        "Lida Zhu",
        "Wen Zhang"
      ],
      "abstract": "Protein post-translational modification (PTM) site prediction is a\nfundamental task in bioinformatics. Several computational methods have been\ndeveloped to predict PTM sites. However, existing methods ignore the structure\ninformation and merely utilize protein sequences. Furthermore, designing a more\nfine-grained structure representation learning method is urgently needed as PTM\nis a biological event that occurs at the atom granularity. In this paper, we\npropose a PTM site prediction method by Coupling of Multi-Granularity structure\nand Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically,\nmultigranularity structure-aware representation learning is designed to learn\nneighborhood structure representations at the amino acid, atom, and whole\nprotein granularity from AlphaFold predicted structures, followed by utilizing\ncontrastive learning to optimize the structure representations.Additionally,\nmulti-scale sequence representation learning is used to extract context\nsequence information, and motif generated by aligning all context sequences of\nPTM sites assists the prediction. Extensive experiments on three datasets show\nthat PTM-CMGMS outperforms the state-of-the-art methods.",
      "tldr_zh": "本研究针对蛋白质翻译后修饰（PTM）位点预测的问题，指出现有方法忽略结构信息并仅依赖序列数据，因此提出了一种新的方法PTM-CMGMS，通过耦合多粒度结构表示（包括氨基酸、原子和整体蛋白质粒度，从AlphaFold预测结构中学习，并使用对比学习优化）和多尺度序列表示（提取上下文序列信息，并利用从PTM位点序列对齐生成的motif辅助预测）。该方法能够更细致地捕捉生物事件细节。实验在三个数据集上表明，PTM-CMGMS优于最先进的方法，显著提升了预测性能。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10211v1",
      "published_date": "2024-01-04 20:49:32 UTC",
      "updated_date": "2024-01-04 20:49:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:40:34.470059"
    },
    {
      "arxiv_id": "2401.02524v2",
      "title": "Comprehensive Exploration of Synthetic Data Generation: A Survey",
      "title_zh": "合成数据生成的全面探索：综述",
      "authors": [
        "André Bauer",
        "Simon Trapp",
        "Michael Stenger",
        "Robert Leppich",
        "Samuel Kounev",
        "Mark Leznik",
        "Kyle Chard",
        "Ian Foster"
      ],
      "abstract": "Recent years have witnessed a surge in the popularity of Machine Learning\n(ML), applied across diverse domains. However, progress is impeded by the\nscarcity of training data due to expensive acquisition and privacy legislation.\nSynthetic data emerges as a solution, but the abundance of released models and\nlimited overview literature pose challenges for decision-making. This work\nsurveys 417 Synthetic Data Generation (SDG) models over the last decade,\nproviding a comprehensive overview of model types, functionality, and\nimprovements. Common attributes are identified, leading to a classification and\ntrend analysis. The findings reveal increased model performance and complexity,\nwith neural network-based approaches prevailing, except for privacy-preserving\ndata generation. Computer vision dominates, with GANs as primary generative\nmodels, while diffusion models, transformers, and RNNs compete. Implications\nfrom our performance evaluation highlight the scarcity of common metrics and\ndatasets, making comparisons challenging. Additionally, the neglect of training\nand computational costs in literature necessitates attention in future\nresearch. This work serves as a guide for SDG model selection and identifies\ncrucial areas for future exploration.",
      "tldr_zh": "这篇论文对过去十年中 417 个 Synthetic Data Generation (SDG) 模型进行了全面调查，旨在解决机器学习中数据稀缺问题的决策挑战。研究通过识别常见属性、分类和趋势分析，发现模型性能和复杂性不断提升，以神经网络为基础的方法（如 GANs）在计算机视觉领域占主导地位，而 diffusion models、transformers 和 RNNs 也在竞争。论文指出，缺乏统一的评估指标和数据集导致模型比较困难，同时文献中忽略了训练和计算成本，这需要未来研究重点关注。该工作为 SDG 模型选择提供实用指导，并标识了关键的未来探索方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Fixed bug in Figure 44",
      "pdf_url": "http://arxiv.org/pdf/2401.02524v2",
      "published_date": "2024-01-04 20:23:51 UTC",
      "updated_date": "2024-02-01 22:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:40:47.728798"
    },
    {
      "arxiv_id": "2401.02523v1",
      "title": "Image-based Deep Learning for Smart Digital Twins: a Review",
      "title_zh": "基于图像的深度学习用于智能数字孪生：综述",
      "authors": [
        "Md Ruman Islam",
        "Mahadevan Subramaniam",
        "Pei-Chi Huang"
      ],
      "abstract": "Smart Digital twins (SDTs) are being increasingly used to virtually replicate\nand predict the behaviors of complex physical systems through continual data\nassimilation enabling the optimization of the performance of these systems by\ncontrolling the actions of systems. Recently, deep learning (DL) models have\nsignificantly enhanced the capabilities of SDTs, particularly for tasks such as\npredictive maintenance, anomaly detection, and optimization. In many domains,\nincluding medicine, engineering, and education, SDTs use image data\n(image-based SDTs) to observe and learn system behaviors and control their\nbehaviors. This paper focuses on various approaches and associated challenges\nin developing image-based SDTs by continually assimilating image data from\nphysical systems. The paper also discusses the challenges involved in designing\nand implementing DL models for SDTs, including data acquisition, processing,\nand interpretation. In addition, insights into the future directions and\nopportunities for developing new image-based DL approaches to develop robust\nSDTs are provided. This includes the potential for using generative models for\ndata augmentation, developing multi-modal DL models, and exploring the\nintegration of DL with other technologies, including 5G, edge computing, and\nIoT. In this paper, we describe the image-based SDTs, which enable broader\nadoption of the digital twin DT paradigms across a broad spectrum of areas and\nthe development of new methods to improve the abilities of SDTs in replicating,\npredicting, and optimizing the behavior of complex systems.",
      "tldr_zh": "这篇综述论文探讨了基于图像的深度学习（Deep Learning, DL）在智能数字孪生（Smart Digital Twins, SDTs）中的应用，强调 DL 模型如何通过持续数据同化提升 SDTs 在预测维护、异常检测和系统优化方面的能力。论文分析了图像-based SDTs 的开发方法及其挑战，包括数据获取、处理和解释，尤其在医学、工程和教育等领域。未来方向包括利用生成模型进行数据增强、开发多模态 DL 模型，以及整合 5G、边缘计算和 IoT，以推动 SDTs 在复制、预测和优化复杂系统行为方面的改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 2 figures, and 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.02523v1",
      "published_date": "2024-01-04 20:17:25 UTC",
      "updated_date": "2024-01-04 20:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:41:00.579845"
    },
    {
      "arxiv_id": "2401.02516v2",
      "title": "Moving-Horizon Estimators for Hyperbolic and Parabolic PDEs in 1-D",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Bhan",
        "Yuanyuan Shi",
        "Iasson Karafyllis",
        "Miroslav Krstic",
        "James B. Rawlings"
      ],
      "abstract": "Observers for PDEs are themselves PDEs. Therefore, producing real time\nestimates with such observers is computationally burdensome. For both\nfinite-dimensional and ODE systems, moving-horizon estimators (MHE) are\noperators whose output is the state estimate, while their inputs are the\ninitial state estimate at the beginning of the horizon as well as the measured\noutput and input signals over the moving time horizon. In this paper we\nintroduce MHEs for PDEs which remove the need for a numerical solution of an\nobserver PDE in real time. We accomplish this using the PDE backstepping method\nwhich, for certain classes of both hyperbolic and parabolic PDEs, produces\nmoving-horizon state estimates explicitly. Precisely, to explicitly produce the\nstate estimates, we employ a backstepping transformation of a hard-to-solve\nobserver PDE into a target observer PDE, which is explicitly solvable. The MHEs\nwe propose are not new observer designs but simply the explicit MHE\nrealizations, over a moving horizon of arbitrary length, of the existing\nbackstepping observers. Our PDE MHEs lack the optimality of the MHEs that arose\nas duals of MPC, but they are given explicitly, even for PDEs. In the paper we\nprovide explicit formulae for MHEs for both hyperbolic and parabolic PDEs, as\nwell as simulation results that illustrate theoretically guaranteed convergence\nof the MHEs.",
      "tldr_zh": "该论文提出了一种移动地平线估计器 (MHEs) 用于一维超声波 (hyperbolic) 和抛物线 (parabolic) PDEs，以避免实时求解观测器 PDE 的计算负担。作者采用 PDE backstepping 方法，将难解的观测器 PDE 通过 backstepping 变换转化为易解的目标观测器 PDE，从而显式生成状态估计。实验结果提供了这些 MHEs 的显式公式，并通过模拟验证了其理论保证的收敛性，尽管这些估计器并非最优。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "math.AP",
        "math.DS",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "6 pages, 1 figure. ACC 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.02516v2",
      "published_date": "2024-01-04 19:55:43 UTC",
      "updated_date": "2024-11-28 07:33:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:41:12.580063"
    },
    {
      "arxiv_id": "2401.02511v1",
      "title": "Gain Scheduling with a Neural Operator for a Transport PDE with Nonlinear Recirculation",
      "title_zh": "翻译失败",
      "authors": [
        "Maxence Lamarque",
        "Luke Bhan",
        "Rafael Vazquez",
        "Miroslav Krstic"
      ],
      "abstract": "To stabilize PDE models, control laws require space-dependent functional\ngains mapped by nonlinear operators from the PDE functional coefficients. When\na PDE is nonlinear and its \"pseudo-coefficient\" functions are state-dependent,\na gain-scheduling (GS) nonlinear design is the simplest approach to the design\nof nonlinear feedback. The GS version of PDE backstepping employs gains\nobtained by solving a PDE at each value of the state. Performing such PDE\ncomputations in real time may be prohibitive. The recently introduced neural\noperators (NO) can be trained to produce the gain functions, rapidly in real\ntime, for each state value, without requiring a PDE solution. In this paper we\nintroduce NOs for GS-PDE backstepping. GS controllers act on the premise that\nthe state change is slow and, as a result, guarantee only local stability, even\nfor ODEs. We establish local stabilization of hyperbolic PDEs with nonlinear\nrecirculation using both a \"full-kernel\" approach and the \"gain-only\" approach\nto gain operator approximation. Numerical simulations illustrate stabilization\nand demonstrate speedup by three orders of magnitude over traditional PDE\ngain-scheduling. Code (Github) for the numerical implementation is published to\nenable exploration.",
      "tldr_zh": "本论文提出了一种使用 neural operators 进行 gain scheduling 的方法，针对带有非线性再循环的 transport PDE 模型，以解决实时计算增益函数的挑战。该方法将 neural operators 训练来快速生成状态相关的增益函数，避免了传统 PDE backstepping 中每次求解 PDE 的高计算开销。论文建立了局部稳定化的理论证明，包括 full-kernel 和 gain-only 两种近似方法。数值模拟结果显示，该方法比传统方法快三个数量级，并提供了 GitHub 代码以便进一步探索。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "math.DS",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "16 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.02511v1",
      "published_date": "2024-01-04 19:45:27 UTC",
      "updated_date": "2024-01-04 19:45:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:41:29.420685"
    },
    {
      "arxiv_id": "2401.02509v2",
      "title": "Memory, Consciousness and Large Language Model",
      "title_zh": "记忆、意识和大型语言模型",
      "authors": [
        "Jitang Li",
        "Jinzheng Li"
      ],
      "abstract": "With the development in cognitive science and Large Language Models (LLMs),\nincreasing connections have come to light between these two distinct fields.\nBuilding upon these connections, we propose a conjecture suggesting the\nexistence of a duality between LLMs and Tulving's theory of memory. We identify\na potential correspondence between Tulving's synergistic ecphory model (SEM) of\nretrieval and the emergent abilities observed in LLMs, serving as supporting\nevidence for our conjecture. Furthermore, we speculate that consciousness may\nbe considered a form of emergent ability based on this duality. We also discuss\nhow other theories of consciousness intersect with our research.",
      "tldr_zh": "本论文探讨了认知科学与 Large Language Models (LLMs) 之间的联系，提出 LLMs 与 Tulving 的记忆理论存在对偶性。\n他们识别了 Tulving 的 Synergistic Ecphory Model (SEM) 与 LLMs 的涌现能力之间的对应关系，作为支持这一猜想的证据。\n此外，论文推测意识可能是一种基于此对偶性的涌现能力，并讨论了其他意识理论如何与之交集。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02509v2",
      "published_date": "2024-01-04 19:44:03 UTC",
      "updated_date": "2024-07-07 14:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:41:40.737380"
    },
    {
      "arxiv_id": "2401.02500v2",
      "title": "On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)",
      "title_zh": "关于在自动化规划和调度（APS）中整合大型语言模型（LLMs）的前景",
      "authors": [
        "Vishal Pallagani",
        "Kaushik Roy",
        "Bharath Muppasani",
        "Francesco Fabiano",
        "Andrea Loreggia",
        "Keerthiram Murugesan",
        "Biplav Srivastava",
        "Francesca Rossi",
        "Lior Horesh",
        "Amit Sheth"
      ],
      "abstract": "Automated Planning and Scheduling is among the growing areas in Artificial\nIntelligence (AI) where mention of LLMs has gained popularity. Based on a\ncomprehensive review of 126 papers, this paper investigates eight categories\nbased on the unique applications of LLMs in addressing various aspects of\nplanning problems: language translation, plan generation, model construction,\nmulti-agent planning, interactive planning, heuristics optimization, tool\nintegration, and brain-inspired planning. For each category, we articulate the\nissues considered and existing gaps. A critical insight resulting from our\nreview is that the true potential of LLMs unfolds when they are integrated with\ntraditional symbolic planners, pointing towards a promising neuro-symbolic\napproach. This approach effectively combines the generative aspects of LLMs\nwith the precision of classical planning methods. By synthesizing insights from\nexisting literature, we underline the potential of this integration to address\ncomplex planning challenges. Our goal is to encourage the ICAPS community to\nrecognize the complementary strengths of LLMs and symbolic planners, advocating\nfor a direction in automated planning that leverages these synergistic\ncapabilities to develop more advanced and intelligent planning systems.",
      "tldr_zh": "这篇论文基于对126篇文献的全面回顾，探讨了Large Language Models (LLMs)在Automated Planning and Scheduling (APS)中的应用前景，将LLMs的应用分为八个类别，包括语言翻译、计划生成、模型构建、多智能体规划、交互式规划、启发式优化、工具集成和脑启发规划。论文分析了每个类别的关键问题和现有空白，并得出关键洞见：LLMs的真正潜力在于与传统符号规划器整合，形成neuro-symbolic approach，从而结合LLMs的生成能力与经典规划的精确性。最终，论文强调这种协同整合有助于解决复杂规划挑战，并鼓励ICAPS社区利用这些互补优势开发更先进的智能规划系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02500v2",
      "published_date": "2024-01-04 19:22:09 UTC",
      "updated_date": "2024-01-20 12:10:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:41:52.713728"
    },
    {
      "arxiv_id": "2401.02416v3",
      "title": "ODIN: A Single Model for 2D and 3D Segmentation",
      "title_zh": "ODIN：一种用于 2D 和 3D 分割的单一模型",
      "authors": [
        "Ayush Jain",
        "Pushkal Katara",
        "Nikolaos Gkanatsios",
        "Adam W. Harley",
        "Gabriel Sarch",
        "Kriti Aggarwal",
        "Vishrav Chaudhary",
        "Katerina Fragkiadaki"
      ],
      "abstract": "State-of-the-art models on contemporary 3D segmentation benchmarks like\nScanNet consume and label dataset-provided 3D point clouds, obtained through\npost processing of sensed multiview RGB-D images. They are typically trained\nin-domain, forego large-scale 2D pre-training and outperform alternatives that\nfeaturize the posed RGB-D multiview images instead. The gap in performance\nbetween methods that consume posed images versus post-processed 3D point clouds\nhas fueled the belief that 2D and 3D perception require distinct model\narchitectures. In this paper, we challenge this view and propose ODIN\n(Omni-Dimensional INstance segmentation), a model that can segment and label\nboth 2D RGB images and 3D point clouds, using a transformer architecture that\nalternates between 2D within-view and 3D cross-view information fusion. Our\nmodel differentiates 2D and 3D feature operations through the positional\nencodings of the tokens involved, which capture pixel coordinates for 2D patch\ntokens and 3D coordinates for 3D feature tokens. ODIN achieves state-of-the-art\nperformance on ScanNet200, Matterport3D and AI2THOR 3D instance segmentation\nbenchmarks, and competitive performance on ScanNet, S3DIS and COCO. It\noutperforms all previous works by a wide margin when the sensed 3D point cloud\nis used in place of the point cloud sampled from 3D mesh. When used as the 3D\nperception engine in an instructable embodied agent architecture, it sets a new\nstate-of-the-art on the TEACh action-from-dialogue benchmark. Our code and\ncheckpoints can be found at the project website (https://odin-seg.github.io).",
      "tldr_zh": "该论文提出ODIN模型，一个统一的Transformer架构，用于同时处理2D RGB图像和3D点云的实例分割，通过交替融合2D内部视图和3D跨视图信息，并使用位置编码（pixel coordinates for 2D和3D coordinates for 3D）区分特征。\nODIN挑战了传统观点，即2D和3D感知需要不同模型架构。\n实验结果显示，ODIN在ScanNet200、Matterport3D和AI2THOR等3D实例分割基准上达到最先进水平，并在ScanNet、S3DIS和COCO上表现出色，尤其在使用感知3D点云时大幅超越现有方法。\n此外，当ODIN作为3D感知引擎应用于TEACh行动对话基准时，它设置了新的state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Camera Ready (CVPR 2024, Highlight)",
      "pdf_url": "http://arxiv.org/pdf/2401.02416v3",
      "published_date": "2024-01-04 18:59:25 UTC",
      "updated_date": "2024-06-25 22:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:42:04.625835"
    },
    {
      "arxiv_id": "2401.02412v1",
      "title": "LLM Augmented LLMs: Expanding Capabilities through Composition",
      "title_zh": "翻译失败",
      "authors": [
        "Rachit Bansal",
        "Bidisha Samanta",
        "Siddharth Dalmia",
        "Nitish Gupta",
        "Shikhar Vashishth",
        "Sriram Ganapathy",
        "Abhishek Bapna",
        "Prateek Jain",
        "Partha Talukdar"
      ],
      "abstract": "Foundational models with billions of parameters which have been trained on\nlarge corpora of data have demonstrated non-trivial skills in a variety of\ndomains. However, due to their monolithic structure, it is challenging and\nexpensive to augment them or impart new skills. On the other hand, due to their\nadaptation abilities, several new instances of these models are being trained\ntowards new domains and tasks. In this work, we study the problem of efficient\nand practical composition of existing foundation models with more specific\nmodels to enable newer capabilities. To this end, we propose CALM --\nComposition to Augment Language Models -- which introduces cross-attention\nbetween models to compose their representations and enable new capabilities.\nSalient features of CALM are: (i) Scales up LLMs on new tasks by 're-using'\nexisting LLMs along with a few additional parameters and data, (ii) Existing\nmodel weights are kept intact, and hence preserves existing capabilities, and\n(iii) Applies to diverse domains and settings. We illustrate that augmenting\nPaLM2-S with a smaller model trained on low-resource languages results in an\nabsolute improvement of up to 13\\% on tasks like translation into English and\narithmetic reasoning for low-resource languages. Similarly, when PaLM2-S is\naugmented with a code-specific model, we see a relative improvement of 40\\%\nover the base model for code generation and explanation tasks -- on-par with\nfully fine-tuned counterparts.",
      "tldr_zh": "该研究探讨了如何通过组合现有的大型语言模型(LLM)来扩展其能力，以应对新任务的挑战，而避免昂贵的重新训练。作者提出了CALM框架，利用cross-attention机制在模型之间组合表示，从而在保留原有模型权重和能力的条件下，仅通过少量额外参数和数据实现新技能的添加。实验结果显示，将PaLM2-S与低资源语言模型结合，可在翻译和算术推理任务上提升高达13%；与代码特定模型结合，则在代码生成和解释任务上相对改善40%，与完全微调的模型相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 2 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.02412v1",
      "published_date": "2024-01-04 18:53:01 UTC",
      "updated_date": "2024-01-04 18:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:42:17.177786"
    },
    {
      "arxiv_id": "2401.02411v1",
      "title": "What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Trevithick",
        "Matthew Chan",
        "Towaki Takikawa",
        "Umar Iqbal",
        "Shalini De Mello",
        "Manmohan Chandraker",
        "Ravi Ramamoorthi",
        "Koki Nagano"
      ],
      "abstract": "3D-aware Generative Adversarial Networks (GANs) have shown remarkable\nprogress in learning to generate multi-view-consistent images and 3D geometries\nof scenes from collections of 2D images via neural volume rendering. Yet, the\nsignificant memory and computational costs of dense sampling in volume\nrendering have forced 3D GANs to adopt patch-based training or employ\nlow-resolution rendering with post-processing 2D super resolution, which\nsacrifices multiview consistency and the quality of resolved geometry.\nConsequently, 3D GANs have not yet been able to fully resolve the rich 3D\ngeometry present in 2D images. In this work, we propose techniques to scale\nneural volume rendering to the much higher resolution of native 2D images,\nthereby resolving fine-grained 3D geometry with unprecedented detail. Our\napproach employs learning-based samplers for accelerating neural rendering for\n3D GAN training using up to 5 times fewer depth samples. This enables us to\nexplicitly \"render every pixel\" of the full-resolution image during training\nand inference without post-processing superresolution in 2D. Together with our\nstrategy to learn high-quality surface geometry, our method synthesizes\nhigh-resolution 3D geometry and strictly view-consistent images while\nmaintaining image quality on par with baselines relying on post-processing\nsuper resolution. We demonstrate state-of-the-art 3D gemetric quality on FFHQ\nand AFHQ, setting a new standard for unsupervised learning of 3D shapes in 3D\nGANs.",
      "tldr_zh": "该论文解决了现有 3D-aware Generative Adversarial Networks (GANs) 在神经体积渲染过程中面临的内存和计算成本问题，导致几何质量和多视图一致性受损。研究提出了一种技术，使用基于学习的采样器加速渲染，减少深度样本数量（最多 5 倍），从而实现全分辨率图像的直接渲染，而无需后处理的 2D 超分辨率。实验结果显示，该方法在 FFHQ 和 AFHQ 数据集上实现了高分辨率的 3D 几何细节和严格视图一致的图像合成，达到了最先进的 3D 几何质量，并与基线模型的图像质量相当，为无监督学习 3D 形状设定了新标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "See our project page: https://research.nvidia.com/labs/nxp/wysiwyg/",
      "pdf_url": "http://arxiv.org/pdf/2401.02411v1",
      "published_date": "2024-01-04 18:50:38 UTC",
      "updated_date": "2024-01-04 18:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:42:28.281691"
    },
    {
      "arxiv_id": "2401.10271v1",
      "title": "Querying Triadic Concepts through Partial or Complete Matching of Triples",
      "title_zh": "通过三元组的部分或完全匹配查询三元概念",
      "authors": [
        "Pedro Henrique B. Ruas",
        "Rokia Missaoui",
        "Mohamed Hamza Ibrahim"
      ],
      "abstract": "In this paper, we introduce a new method for querying triadic concepts\nthrough partial or complete matching of triples using an inverted index, to\nretrieve already computed triadic concepts that contain a set of terms in their\nextent, intent, and/or modus. As opposed to the approximation approach\ndescribed in Ananias, this method (i) does not need to keep the initial triadic\ncontext or its three dyadic counterparts, (ii) avoids the application of\nderivation operators on the triple components through context exploration, and\n(iii) eliminates the requirement for a factorization phase to get triadic\nconcepts as the answer to one-dimensional queries. Additionally, our solution\nintroduces a novel metric for ranking the retrieved triadic concepts based on\ntheir similarity to a given query. Lastly, an empirical study is primarily done\nto illustrate the effectiveness and scalability of our approach against the\napproximation one. Our solution not only showcases superior efficiency, but\nalso highlights a better scalability, making it suitable for big data\nscenarios.",
      "tldr_zh": "这篇论文提出了一种新方法，使用倒排索引(inverted index)通过部分或完全匹配三元组(triples)，来查询三元概念(triadic concepts)，以检索那些在extent、intent和/或modus中包含特定术语的已计算概念。相比Ananias的近似方法，该方法无需保留初始三元上下文或其二元对应物，避免了派生运算符的上下文探索，并省去了因子分解阶段。论文还引入了一种基于相似度的全新度量标准，用于对检索结果进行排名。实证研究表明，该方法在效率和可伸缩性上均优于现有方法，特别适合大数据场景。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10271v1",
      "published_date": "2024-01-04 18:44:12 UTC",
      "updated_date": "2024-01-04 18:44:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:42:40.967070"
    },
    {
      "arxiv_id": "2401.02403v1",
      "title": "Real-Time 2D Temperature Field Prediction in Metal Additive Manufacturing Using Physics-Informed Neural Networks",
      "title_zh": "实时二维温度场预测在金属增材制造中使用基于物理信息的神经网络",
      "authors": [
        "Pouyan Sajadi",
        "Mostafa Rahmani Dehaghani",
        "Yifan Tang",
        "G. Gary Wang"
      ],
      "abstract": "Accurately predicting the temperature field in metal additive manufacturing\n(AM) processes is critical to preventing overheating, adjusting process\nparameters, and ensuring process stability. While physics-based computational\nmodels offer precision, they are often time-consuming and unsuitable for\nreal-time predictions and online control in iterative design scenarios.\nConversely, machine learning models rely heavily on high-quality datasets,\nwhich can be costly and challenging to obtain within the metal AM domain. Our\nwork addresses this by introducing a physics-informed neural network framework\nspecifically designed for temperature field prediction in metal AM. This\nframework incorporates a physics-informed input, physics-informed loss\nfunction, and a Convolutional Long Short-Term Memory (ConvLSTM) architecture.\nUtilizing real-time temperature data from the process, our model predicts 2D\ntemperature fields for future timestamps across diverse geometries, deposition\npatterns, and process parameters. We validate the proposed framework in two\nscenarios: full-field temperature prediction for a thin wall and 2D temperature\nfield prediction for cylinder and cubic parts, demonstrating errors below 3%\nand 1%, respectively. Our proposed framework exhibits the flexibility to be\napplied across diverse scenarios with varying process parameters, geometries,\nand deposition patterns.",
      "tldr_zh": "这篇论文提出了一种基于 Physics-Informed Neural Networks 的框架，用于金属增材制造（AM）过程中的实时 2D 温度场预测，以解决物理模型计算密集和机器学习数据依赖的问题。该框架整合了 physics-informed input、physics-informed loss function 和 ConvLSTM 架构，利用实时温度数据预测未来时间戳的温度场，适用于不同几何形状、沉积模式和过程参数。在验证实验中，该方法在薄壁全场预测中错误率低于 3%，而在圆柱体和立方体零件预测中低于 1%，展示了其灵活性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "42 pages, 13 Figures",
      "pdf_url": "http://arxiv.org/pdf/2401.02403v1",
      "published_date": "2024-01-04 18:42:28 UTC",
      "updated_date": "2024-01-04 18:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:42:52.175158"
    },
    {
      "arxiv_id": "2401.10210v1",
      "title": "Mastery Guided Non-parametric Clustering to Scale-up Strategy Prediction",
      "title_zh": "基于掌握度的非参数聚类用于扩展策略预测",
      "authors": [
        "Anup Shakya",
        "Vasile Rus",
        "Deepak Venugopal"
      ],
      "abstract": "Predicting the strategy (sequence of concepts) that a student is likely to\nuse in problem-solving helps Adaptive Instructional Systems (AISs) better adapt\nthemselves to different types of learners based on their learning abilities.\nThis can lead to a more dynamic, engaging, and personalized experience for\nstudents. To scale up training a prediction model (such as LSTMs) over\nlarge-scale education datasets, we develop a non-parametric approach to cluster\nsymmetric instances in the data. Specifically, we learn a representation based\non Node2Vec that encodes symmetries over mastery or skill level since, to solve\na problem, it is natural that a student's strategy is likely to involve\nconcepts in which they have gained mastery. Using this representation, we use\nDP-Means to group symmetric instances through a coarse-to-fine refinement of\nthe clusters. We apply our model to learn strategies for Math learning from\nlarge-scale datasets from MATHia, a leading AIS for middle-school math\nlearning. Our results illustrate that our approach can consistently achieve\nhigh accuracy using a small sample that is representative of the full dataset.\nFurther, we show that this approach helps us learn strategies with high\naccuracy for students at different skill levels, i.e., leveraging symmetries\nimproves fairness in the prediction model.",
      "tldr_zh": "本文提出了一种基于掌握水平（mastery）的非参数聚类方法，用于扩展学生策略预测模型（如 LSTMs），以帮助适应性教学系统（AISs）根据学习能力个性化适应学生问题解决策略。方法首先使用 Node2Vec 学习表示编码学生的技能对称性，然后通过 DP-Means 算法进行粗到细的聚类精炼。实验在 MATHia 的中学数学数据集上显示，该方法使用小样本即可实现高准确率，并提升了不同技能水平学生的预测公平性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Proceedings of 37th AAAI Conference on Artificial Intelligence\n  Artificial Intelligence for Education. arXiv admin note: substantial text\n  overlap with arXiv:2308.03892",
      "pdf_url": "http://arxiv.org/pdf/2401.10210v1",
      "published_date": "2024-01-04 17:57:21 UTC",
      "updated_date": "2024-01-04 17:57:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:43:03.626666"
    },
    {
      "arxiv_id": "2401.02385v2",
      "title": "TinyLlama: An Open-Source Small Language Model",
      "title_zh": "TinyLlama：开源小型",
      "authors": [
        "Peiyuan Zhang",
        "Guangtao Zeng",
        "Tianduo Wang",
        "Wei Lu"
      ],
      "abstract": "We present TinyLlama, a compact 1.1B language model pretrained on around 1\ntrillion tokens for approximately 3 epochs. Building on the architecture and\ntokenizer of Llama 2, TinyLlama leverages various advances contributed by the\nopen-source community (e.g., FlashAttention and Lit-GPT), achieving better\ncomputational efficiency. Despite its relatively small size, TinyLlama\ndemonstrates remarkable performance in a series of downstream tasks. It\nsignificantly outperforms existing open-source language models with comparable\nsizes. Our model checkpoints and code are publicly available on GitHub at\nhttps://github.com/jzhang38/TinyLlama.",
      "tldr_zh": "我们介绍了 TinyLlama，这是一个开源的 1.1B 参数小型语言模型，基于 Llama 2 的架构和 tokenizer，利用社区贡献如 FlashAttention 和 Lit-GPT 等技术，在约 1 万亿 tokens 上预训练了 3 个 epochs，从而提升了计算效率。  \n尽管模型规模较小，TinyLlama 在一系列下游任务中表现出色，显著优于同等规模的现有开源语言模型。  \n模型检查点和代码已在 GitHub 上公开，供社区使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2401.02385v2",
      "published_date": "2024-01-04 17:54:59 UTC",
      "updated_date": "2024-06-04 02:05:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:43:15.883913"
    },
    {
      "arxiv_id": "2401.02383v2",
      "title": "Survey of 3D Human Body Pose and Shape Estimation Methods for Contemporary Dance Applications",
      "title_zh": "当代舞应用的3D人体姿态和形状估计方法的综述",
      "authors": [
        "Darshan Venkatrayappa",
        "Alain Tremeau",
        "Damien Muselet",
        "Philippe Colantoni"
      ],
      "abstract": "3D human body shape and pose estimation from RGB images is a challenging\nproblem with potential applications in augmented/virtual reality, healthcare\nand fitness technology and virtual retail. Recent solutions have focused on\nthree types of inputs: i) single images, ii) multi-view images and iii) videos.\nIn this study, we surveyed and compared 3D body shape and pose estimation\nmethods for contemporary dance and performing arts, with a special focus on\nhuman body pose and dressing, camera viewpoint, illumination conditions and\nbackground conditions. We demonstrated that multi-frame methods, such as PHALP,\nprovide better results than single-frame method for pose estimation when\ndancers are performing contemporary dances.",
      "tldr_zh": "这篇论文调查了3D Human Body Pose and Shape Estimation方法在当代舞蹈应用中的表现，重点关注从RGB images中估计人体形状和姿态的挑战及其在增强/虚拟现实、健康、健身技术和虚拟零售中的潜力。研究比较了三种输入类型：i) 单张图像，ii) 多视图图像和iii) 视频，并特别分析了人体姿态、穿着、相机视角、照明条件和背景条件的影响。结果表明，多帧方法如PHALP在当代舞蹈表演中比单帧方法提供更准确的姿态估计，为相关领域的应用提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2008.09062 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2401.02383v2",
      "published_date": "2024-01-04 17:51:44 UTC",
      "updated_date": "2024-01-29 21:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:43:32.980957"
    },
    {
      "arxiv_id": "2401.02997v1",
      "title": "Blar-SQL: Faster, Stronger, Smaller NL2SQL",
      "title_zh": "翻译失败",
      "authors": [
        "José Manuel Domínguez",
        "Benjamín Errázuriz",
        "Patricio Daher"
      ],
      "abstract": "Large Language Models (LLMs) have gained considerable notoriety in the field\nof natural language to SQL tasks (NL2SQL). In this study, we show how task\ndecomposition can greatly benefit LLMs in database understanding and query\ngeneration in order to answer human questions with an SQL query.\n  We fined-tuned open source models, specifically Llama-2 and Code Llama, by\ncombining 2 different models each designated to focus on one of two tasks in\norder to leverage each model's core competency to further increase the accuracy\nof the final SQL query.\n  We propose a new framework to divide the schema into chunks in order to fit\nmore information into a limited context. Our results are comparable with those\nobtained by GPT-4 at the same time being 135 times smaller, 90 times faster and\nmore than 100 times cheaper than GPT-4.",
      "tldr_zh": "本研究探讨了任务分解如何提升 Large Language Models (LLMs) 在自然语言到 SQL (NL2SQL) 任务中的数据库理解和查询生成性能，通过微调开源模型如 Llama-2 和 Code Llama，并将它们分别分配到两个特定任务上以发挥各自优势。\n他们提出了一种新框架，将 schema 分块以适应有限上下文，从而提高最终 SQL 查询的准确性。\n实验结果显示，该方法与 GPT-4 性能相当，但模型小 135 倍、快 90 倍，且成本低 100 倍以上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02997v1",
      "published_date": "2024-01-04 16:50:52 UTC",
      "updated_date": "2024-01-04 16:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:43:43.695224"
    },
    {
      "arxiv_id": "2401.02349v2",
      "title": "A Survey Analyzing Generalization in Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ezgi Korkmaz"
      ],
      "abstract": "Reinforcement learning research obtained significant success and attention\nwith the utilization of deep neural networks to solve problems in high\ndimensional state or action spaces. While deep reinforcement learning policies\nare currently being deployed in many different fields from medical applications\nto large language models, there are still ongoing questions the field is trying\nto answer on the generalization capabilities of deep reinforcement learning\npolicies. In this paper, we will formalize and analyze generalization in deep\nreinforcement learning. We will explain the fundamental reasons why deep\nreinforcement learning policies encounter overfitting problems that limit their\ngeneralization capabilities. Furthermore, we will categorize and explain the\nmanifold solution approaches to increase generalization, and overcome\noverfitting in deep reinforcement learning policies. From exploration to\nadversarial analysis and from regularization to robustness our paper provides\nan analysis on a wide range of subfields within deep reinforcement learning\nwith a broad scope and in-depth view. We believe our study can provide a\ncompact guideline for the current advancements in deep reinforcement learning,\nand help to construct robust deep neural policies with higher generalization\nskills.",
      "tldr_zh": "这篇论文对 Deep Reinforcement Learning 中的泛化问题进行了全面调查，形式化分析了深度强化学习策略在高维状态或动作空间中面临的挑战。作者解释了这些策略容易出现 overfitting 的根本原因，从而限制了其在医疗应用和大型语言模型等领域的实际部署。论文还分类并讨论了多种提升泛化能力的解决方案，包括探索、adversarial analysis、正则化和robustness 方法，最终为构建更鲁棒的 DRL 策略提供了实用指南。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02349v2",
      "published_date": "2024-01-04 16:45:01 UTC",
      "updated_date": "2024-10-30 16:18:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:43:55.976027"
    },
    {
      "arxiv_id": "2401.02347v1",
      "title": "Mining Fine-Grained Image-Text Alignment for Zero-Shot Captioning via Text-Only Training",
      "title_zh": "翻译失败",
      "authors": [
        "Longtian Qiu",
        "Shan Ning",
        "Xuming He"
      ],
      "abstract": "Image captioning aims at generating descriptive and meaningful textual\ndescriptions of images, enabling a broad range of vision-language applications.\nPrior works have demonstrated that harnessing the power of Contrastive Image\nLanguage Pre-training (CLIP) offers a promising approach to achieving zero-shot\ncaptioning, eliminating the need for expensive caption annotations. However,\nthe widely observed modality gap in the latent space of CLIP harms the\nperformance of zero-shot captioning by breaking the alignment between paired\nimage-text features. To address this issue, we conduct an analysis on the CLIP\nlatent space which leads to two findings. Firstly, we observe that the CLIP's\nvisual feature of image subregions can achieve closer proximity to the paired\ncaption due to the inherent information loss in text descriptions. In addition,\nwe show that the modality gap between a paired image-text can be empirically\nmodeled as a zero-mean Gaussian distribution. Motivated by the findings, we\npropose a novel zero-shot image captioning framework with text-only training to\nreduce the modality gap. In particular, we introduce a subregion feature\naggregation to leverage local region information, which produces a compact\nvisual representation for matching text representation. Moreover, we\nincorporate a noise injection and CLIP reranking strategy to boost captioning\nperformance. We also extend our framework to build a zero-shot VQA pipeline,\ndemonstrating its generality. Through extensive experiments on common\ncaptioning and VQA datasets such as MSCOCO, Flickr30k and VQAV2, we show that\nour method achieves remarkable performance improvements. Code is available at\nhttps://github.com/Artanic30/MacCap.",
      "tldr_zh": "这篇论文提出了一种基于文本-only 训练的零样本图像字幕方法，通过挖掘细粒度图像-文本对齐来解决 CLIP 模型中模态间差距的问题。研究发现，CLIP 的图像子区域特征更接近配对字幕，且模态间差距可建模为零均值高斯分布，因此引入子区域特征聚合、噪声注入和 CLIP 重新排序策略来生成更精确的字幕。实验结果显示，该框架在 MSCOCO、Flickr30k 和 VQAV2 数据集上显著提升性能，并扩展到零样本视觉问答（VQA）任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2024.Open sourced, Code and Model Available",
      "pdf_url": "http://arxiv.org/pdf/2401.02347v1",
      "published_date": "2024-01-04 16:43:46 UTC",
      "updated_date": "2024-01-04 16:43:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:44:08.001301"
    },
    {
      "arxiv_id": "2401.02290v2",
      "title": "Path-based Explanation for Knowledge Graph Completion",
      "title_zh": "基于路径的知识图谱补全解释",
      "authors": [
        "Heng Chang",
        "Jiangnan Ye",
        "Alejo Lopez Avila",
        "Jinhua Du",
        "Jia Li"
      ],
      "abstract": "Graph Neural Networks (GNNs) have achieved great success in Knowledge Graph\nCompletion (KGC) by modelling how entities and relations interact in recent\nyears. However, the explanation of the predicted facts has not caught the\nnecessary attention. Proper explanations for the results of GNN-based KGC\nmodels increase model transparency and help researchers develop more reliable\nmodels. Existing practices for explaining KGC tasks rely on\ninstance/subgraph-based approaches, while in some scenarios, paths can provide\nmore user-friendly and interpretable explanations. Nonetheless, the methods for\ngenerating path-based explanations for KGs have not been well-explored. To\naddress this gap, we propose Power-Link, the first path-based KGC explainer\nthat explores GNN-based models. We design a novel simplified graph-powering\ntechnique, which enables the generation of path-based explanations with a fully\nparallelisable and memory-efficient training scheme. We further introduce three\nnew metrics for quantitative evaluation of the explanations, together with a\nqualitative human evaluation. Extensive experiments demonstrate that Power-Link\noutperforms the SOTA baselines in interpretability, efficiency, and\nscalability.",
      "tldr_zh": "该研究针对知识图谱补全 (KGC) 中 Graph Neural Networks (GNNs) 的预测结果解释不足的问题，提出了一种基于路径的解释方法，以提升模型透明度和可靠性。研究引入 Power-Link，这是首个针对 GNNs 的路径-based KGC 解释器，利用新型简化 graph-powering 技术实现全并行化和内存高效的路径生成训练。Power-Link 还设计了三个新量化指标以及定性人类评估进行解释评估，实验结果显示其在可解释性、效率和可扩展性上优于现有最先进 (SOTA) 基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.02290v2",
      "published_date": "2024-01-04 14:19:37 UTC",
      "updated_date": "2024-10-18 01:58:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:44:18.469435"
    },
    {
      "arxiv_id": "2401.04732v1",
      "title": "A case study of Generative AI in MSX Sales Copilot: Improving seller productivity with a real-time question-answering system for content recommendation",
      "title_zh": "Generative AI 在 MSX Sales Copilot 中的案例研究：利用实时问答系统改善销售人员生产力以进行内容推荐",
      "authors": [
        "Manpreet Singh",
        "Ravdeep Pasricha",
        "Nitish Singh",
        "Ravi Prasad Kondapalli",
        "Manoj R",
        "Kiran R",
        "Laurent Boué"
      ],
      "abstract": "In this paper, we design a real-time question-answering system specifically\ntargeted for helping sellers get relevant material/documentation they can share\nlive with their customers or refer to during a call. Taking the Seismic content\nrepository as a relatively large scale example of a diverse dataset of sales\nmaterial, we demonstrate how LLM embeddings of sellers' queries can be matched\nwith the relevant content. We achieve this by engineering prompts in an\nelaborate fashion that makes use of the rich set of meta-features available for\ndocuments and sellers. Using a bi-encoder with cross-encoder re-ranker\narchitecture, we show how the solution returns the most relevant content\nrecommendations in just a few seconds even for large datasets. Our recommender\nsystem is deployed as an AML endpoint for real-time inferencing and has been\nintegrated into a Copilot interface that is now deployed in the production\nversion of the Dynamics CRM, known as MSX, used daily by Microsoft sellers.",
      "tldr_zh": "本研究呈现了一个Generative AI在MSX Sales Copilot中的案例应用，旨在通过实时问答系统提升销售人员的生产力，帮助他们快速获取并分享相关内容。系统利用LLM embeddings将卖家查询与Seismic内容库匹配，结合精心设计的提示和丰富的元特征（如文档和卖家数据），并采用bi-encoder与cross-encoder re-ranker架构，实现对大型数据集的快速内容推荐，通常在几秒内完成。最终，该系统已部署为AML endpoint并集成到Dynamics CRM的生产环境中，供Microsoft卖家日常使用，证明了其在实际场景中的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04732v1",
      "published_date": "2024-01-04 13:32:44 UTC",
      "updated_date": "2024-01-04 13:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:44:30.724247"
    },
    {
      "arxiv_id": "2401.06781v1",
      "title": "PokerGPT: An End-to-End Lightweight Solver for Multi-Player Texas Hold'em via Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghao Huang",
        "Yanbo Cao",
        "Yinlong Wen",
        "Tao Zhou",
        "Yanru Zhang"
      ],
      "abstract": "Poker, also known as Texas Hold'em, has always been a typical research target\nwithin imperfect information games (IIGs). IIGs have long served as a measure\nof artificial intelligence (AI) development. Representative prior works, such\nas DeepStack and Libratus heavily rely on counterfactual regret minimization\n(CFR) to tackle heads-up no-limit Poker. However, it is challenging for\nsubsequent researchers to learn CFR from previous models and apply it to other\nreal-world applications due to the expensive computational cost of CFR\niterations. Additionally, CFR is difficult to apply to multi-player games due\nto the exponential growth of the game tree size. In this work, we introduce\nPokerGPT, an end-to-end solver for playing Texas Hold'em with arbitrary number\nof players and gaining high win rates, established on a lightweight large\nlanguage model (LLM). PokerGPT only requires simple textual information of\nPoker games for generating decision-making advice, thus guaranteeing the\nconvenient interaction between AI and humans. We mainly transform a set of\ntextual records acquired from real games into prompts, and use them to\nfine-tune a lightweight pre-trained LLM using reinforcement learning human\nfeedback technique. To improve fine-tuning performance, we conduct prompt\nengineering on raw data, including filtering useful information, selecting\nbehaviors of players with high win rates, and further processing them into\ntextual instruction using multiple prompt engineering techniques. Through the\nexperiments, we demonstrate that PokerGPT outperforms previous approaches in\nterms of win rate, model size, training time, and response speed, indicating\nthe great potential of LLMs in solving IIGs.",
      "tldr_zh": "本文提出 PokerGPT，一种基于轻量级大型语言模型 (LLM) 的端到端解决方案，用于处理多玩家 Texas Hold'em 游戏，实现高胜率。方法包括将真实游戏的文本记录转化为提示，通过 reinforcement learning human feedback 技术对预训练 LLM 进行微调，并采用提示工程（如过滤有用信息和选择高胜率玩家行为）来优化性能。与传统 counterfactual regret minimization (CFR) 方法相比，PokerGPT 在胜率、模型大小、训练时间和响应速度上表现出色，展示了 LLM 在不完美信息游戏 (IIGs) 中的巨大潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06781v1",
      "published_date": "2024-01-04 13:27:50 UTC",
      "updated_date": "2024-01-04 13:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:44:44.172740"
    },
    {
      "arxiv_id": "2401.02258v1",
      "title": "Uncertainty-Aware Deep Attention Recurrent Neural Network for Heterogeneous Time Series Imputation",
      "title_zh": "不确定性感知的深度",
      "authors": [
        "Linglong Qian",
        "Zina Ibrahim",
        "Richard Dobson"
      ],
      "abstract": "Missingness is ubiquitous in multivariate time series and poses an obstacle\nto reliable downstream analysis. Although recurrent network imputation achieved\nthe SOTA, existing models do not scale to deep architectures that can\npotentially alleviate issues arising in complex data. Moreover, imputation\ncarries the risk of biased estimations of the ground truth. Yet, confidence in\nthe imputed values is always unmeasured or computed post hoc from model output.\nWe propose DEep Attention Recurrent Imputation (DEARI), which jointly estimates\nmissing values and their associated uncertainty in heterogeneous multivariate\ntime series. By jointly representing feature-wise correlations and temporal\ndynamics, we adopt a self attention mechanism, along with an effective residual\ncomponent, to achieve a deep recurrent neural network with good imputation\nperformance and stable convergence. We also leverage self-supervised metric\nlearning to boost performance by optimizing sample similarity. Finally, we\ntransform DEARI into a Bayesian neural network through a novel Bayesian\nmarginalization strategy to produce stochastic DEARI, which outperforms its\ndeterministic equivalent. Experiments show that DEARI surpasses the SOTA in\ndiverse imputation tasks using real-world datasets, namely air quality control,\nhealthcare and traffic.",
      "tldr_zh": "本文提出了一种Uncertainty-Aware Deep Attention Recurrent Neural Network，名为DEARI，用于处理异构多变量时间序列的缺失值插值问题。DEARI通过自注意力机制和残差组件联合估计缺失值及其相关不确定性，同时利用自监督度量学习优化样本相似性，并通过新颖的贝叶斯边缘化策略转化为随机贝叶斯神经网络，提升模型鲁棒性。实验结果表明，DEARI在空气质量控制、医疗保健和交通等真实数据集上的插值任务中，超越了现有SOTA方法，展示了显著的性能改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02258v1",
      "published_date": "2024-01-04 13:21:11 UTC",
      "updated_date": "2024-01-04 13:21:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:44:56.010949"
    },
    {
      "arxiv_id": "2401.02244v1",
      "title": "Policy-regularized Offline Multi-objective Reinforcement Learning",
      "title_zh": "策略正则化的离线多目标强化学习",
      "authors": [
        "Qian Lin",
        "Chao Yu",
        "Zongkai Liu",
        "Zifan Wu"
      ],
      "abstract": "In this paper, we aim to utilize only offline trajectory data to train a\npolicy for multi-objective RL. We extend the offline policy-regularized method,\na widely-adopted approach for single-objective offline RL problems, into the\nmulti-objective setting in order to achieve the above goal. However, such\nmethods face a new challenge in offline MORL settings, namely the\npreference-inconsistent demonstration problem. We propose two solutions to this\nproblem: 1) filtering out preference-inconsistent demonstrations via\napproximating behavior preferences, and 2) adopting regularization techniques\nwith high policy expressiveness. Moreover, we integrate the\npreference-conditioned scalarized update method into policy-regularized offline\nRL, in order to simultaneously learn a set of policies using a single policy\nnetwork, thus reducing the computational cost induced by the training of a\nlarge number of individual policies for various preferences. Finally, we\nintroduce Regularization Weight Adaptation to dynamically determine appropriate\nregularization weights for arbitrary target preferences during deployment.\nEmpirical results on various multi-objective datasets demonstrate the\ncapability of our approach in solving offline MORL problems.",
      "tldr_zh": "本研究旨在利用离线轨迹数据训练多目标强化学习（Multi-objective RL, MORL）的策略，通过扩展离线政策正则化方法（offline policy-regularized method）来实现这一目标。论文识别出 MORL 环境中的偏好不一致演示问题（preference-inconsistent demonstration problem），并提出两种解决方案：通过近似行为偏好过滤无效演示，以及采用高策略表达性的正则化技术。同时，作者整合了 preference-conditioned scalarized update 方法，使用单个策略网络学习多组策略，以降低计算成本，并引入 Regularization Weight Adaptation 在部署时动态调整正则化权重。实验结果显示，该方法在各种多目标数据集上表现出色，有效解决了离线 MORL 问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02244v1",
      "published_date": "2024-01-04 12:54:10 UTC",
      "updated_date": "2024-01-04 12:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:45:07.803714"
    },
    {
      "arxiv_id": "2401.02995v1",
      "title": "CANAMRF: An Attention-Based Model for Multimodal Depression Detection",
      "title_zh": "CANAMRF：一种基于注意力的多模态抑郁检测模型",
      "authors": [
        "Yuntao Wei",
        "Yuzhe Zhang",
        "Shuyang Zhang",
        "Hong Zhang"
      ],
      "abstract": "Multimodal depression detection is an important research topic that aims to\npredict human mental states using multimodal data. Previous methods treat\ndifferent modalities equally and fuse each modality by na\\\"ive mathematical\noperations without measuring the relative importance between them, which cannot\nobtain well-performed multimodal representations for downstream depression\ntasks. In order to tackle the aforementioned concern, we present a Cross-modal\nAttention Network with Adaptive Multi-modal Recurrent Fusion (CANAMRF) for\nmultimodal depression detection. CANAMRF is constructed by a multimodal feature\nextractor, an Adaptive Multimodal Recurrent Fusion module, and a Hybrid\nAttention Module. Through experimentation on two benchmark datasets, CANAMRF\ndemonstrates state-of-the-art performance, underscoring the effectiveness of\nour proposed approach.",
      "tldr_zh": "该论文提出了一种基于注意力的模型 CANAMRF，用于多模态抑郁检测，以预测人类心理状态。CANAMRF 通过多模态特征提取器、Adaptive Multimodal Recurrent Fusion 模块和 Hybrid Attention Module 来处理不同模态数据间的相对重要性，实现更有效的跨模态融合。实验在两个基准数据集上显示，该模型达到了最先进性能，显著改善了传统方法的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 3 figures. Pacific Rim International Conference on\n  Artificial Intelligence. Singapore: Springer Nature Singapore, 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.02995v1",
      "published_date": "2024-01-04 12:08:16 UTC",
      "updated_date": "2024-01-04 12:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:45:17.805018"
    },
    {
      "arxiv_id": "2401.02465v1",
      "title": "Interpretable Time Series Models for Wastewater Modeling in Combined Sewer Overflows",
      "title_zh": "翻译失败",
      "authors": [
        "Teodor Chiaburu",
        "Felix Biessmann"
      ],
      "abstract": "Climate change poses increasingly complex challenges to our society. Extreme\nweather events such as floods, wild fires or droughts are becoming more\nfrequent, spontaneous and difficult to foresee or counteract. In this work we\nspecifically address the problem of sewage water polluting surface water bodies\nafter spilling over from rain tanks as a consequence of heavy rain events. We\ninvestigate to what extent state-of-the-art interpretable time series models\ncan help predict such critical water level points, so that the excess can\npromptly be redistributed across the sewage network. Our results indicate that\nmodern time series models can contribute to better waste water management and\nprevention of environmental pollution from sewer systems. All the code and\nexperiments can be found in our repository:\nhttps://github.com/TeodorChiaburu/RIWWER_TimeSeries.",
      "tldr_zh": "本研究针对气候变化引发的极端天气事件（如重雨导致的下水道溢流），探讨了如何使用可解释时间序列模型（interpretable time series models）来预测联合下水道溢流（Combined Sewer Overflows）中的关键水位点，从而及时重新分配多余污水。研究方法包括应用先进的模型来分析污水系统数据，确保预测结果的可解释性和准确性。结果表明，这些模型能显著提升废水管理和环境污染预防效果，所有代码和实验已在GitHub仓库（https://github.com/TeodorChiaburu/RIWWER_TimeSeries）中公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures, 2 tables, presented at iSCSi 2023 Lisbon",
      "pdf_url": "http://arxiv.org/pdf/2401.02465v1",
      "published_date": "2024-01-04 11:48:27 UTC",
      "updated_date": "2024-01-04 11:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:45:33.472763"
    },
    {
      "arxiv_id": "2401.02212v1",
      "title": "Joint Multi-Facts Reasoning Network For Complex Temporal Question Answering Over Knowledge Graph",
      "title_zh": "基于知识图谱的联合多事实推理网络用于复杂时序",
      "authors": [
        "Rikui Huang",
        "Wei Wei",
        "Xiaoye Qu",
        "Wenfeng Xie",
        "Xianling Mao",
        "Dangyang Chen"
      ],
      "abstract": "Temporal Knowledge Graph (TKG) is an extension of regular knowledge graph by\nattaching the time scope. Existing temporal knowledge graph question answering\n(TKGQA) models solely approach simple questions, owing to the prior assumption\nthat each question only contains a single temporal fact with explicit/implicit\ntemporal constraints. Hence, they perform poorly on questions which own\nmultiple temporal facts. In this paper, we propose \\textbf{\\underline{J}}oint\n\\textbf{\\underline{M}}ulti \\textbf{\\underline{F}}acts\n\\textbf{\\underline{R}}easoning \\textbf{\\underline{N}}etwork (JMFRN), to jointly\nreasoning multiple temporal facts for accurately answering \\emph{complex}\ntemporal questions. Specifically, JMFRN first retrieves question-related\ntemporal facts from TKG for each entity of the given complex question. For\njoint reasoning, we design two different attention (\\ie entity-aware and\ntime-aware) modules, which are suitable for universal settings, to aggregate\nentities and timestamps information of retrieved facts. Moreover, to filter\nincorrect type answers, we introduce an additional answer type discrimination\ntask. Extensive experiments demonstrate our proposed method significantly\noutperforms the state-of-art on the well-known complex temporal question\nbenchmark TimeQuestions.",
      "tldr_zh": "本研究针对 Temporal Knowledge Graph (TKG) 的复杂查询问题，提出 Joint Multi-Facts Reasoning Network (JMFRN)，用于联合推理多个时间事实，以解决现有 TKGQA 模型仅处理单一事实的局限性。JMFRN 先从 TKG 中检索问题相关的时间事实，然后通过 entity-aware 和 time-aware attention 模块聚合实体和时间戳信息，并引入 answer type discrimination 任务来过滤错误答案类型。实验结果显示，该方法在 TimeQuestions benchmark 上显著优于最先进模型，证明了其在复杂时间问题回答中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02212v1",
      "published_date": "2024-01-04 11:34:39 UTC",
      "updated_date": "2024-01-04 11:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:45:43.574789"
    },
    {
      "arxiv_id": "2401.02199v1",
      "title": "LADRI: LeArning-based Dynamic Risk Indicator in Automated Driving System",
      "title_zh": "翻译失败",
      "authors": [
        "Anil Ranjitbhai Patel",
        "Peter Liggesmeyer"
      ],
      "abstract": "As the horizon of intelligent transportation expands with the evolution of\nAutomated Driving Systems (ADS), ensuring paramount safety becomes more\nimperative than ever. Traditional risk assessment methodologies, primarily\ncrafted for human-driven vehicles, grapple to adequately adapt to the\nmultifaceted, evolving environments of ADS. This paper introduces a framework\nfor real-time Dynamic Risk Assessment (DRA) in ADS, harnessing the potency of\nArtificial Neural Networks (ANNs).\n  Our proposed solution transcends these limitations, drawing upon ANNs, a\ncornerstone of deep learning, to meticulously analyze and categorize risk\ndimensions using real-time On-board Sensor (OBS) data. This learning-centric\napproach not only elevates the ADS's situational awareness but also enriches\nits understanding of immediate operational contexts. By dissecting OBS data,\nthe system is empowered to pinpoint its current risk profile, thereby enhancing\nsafety prospects for onboard passengers and the broader traffic ecosystem.\n  Through this framework, we chart a direction in risk assessment, bridging the\nconventional voids and enhancing the proficiency of ADS. By utilizing ANNs, our\nmethodology offers a perspective, allowing ADS to adeptly navigate and react to\npotential risk factors, ensuring safer and more informed autonomous journeys.",
      "tldr_zh": "本研究提出LADRI框架，一种基于学习的动态风险评估（Dynamic Risk Assessment, DRA）方法，用于Automated Driving Systems (ADS)，以解决传统风险评估在复杂环境中的适应性不足问题。该框架利用Artificial Neural Networks (ANNs)分析实时On-board Sensor (OBS)数据，提升ADS的情景感知（situational awareness）和对操作环境的理解。通过精确识别当前风险配置文件，LADRI显著增强了乘客安全和整体交通生态的可靠性，为更高效的自主驾驶提供了一个创新方向。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SE",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "2023 IEEE International Test Conference, 8th Edition of Automotive,\n  Reliability, Test & Safety Workshop in Disneyland, Anaheim, CA",
      "pdf_url": "http://arxiv.org/pdf/2401.02199v1",
      "published_date": "2024-01-04 11:09:15 UTC",
      "updated_date": "2024-01-04 11:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:45:55.217147"
    },
    {
      "arxiv_id": "2401.02183v1",
      "title": "FairGridSearch: A Framework to Compare Fairness-Enhancing Models",
      "title_zh": "FairGridSearch：一种用于比较增强公平性模型的框架",
      "authors": [
        "Shih-Chi Ma",
        "Tatiana Ermakova",
        "Benjamin Fabian"
      ],
      "abstract": "Machine learning models are increasingly used in critical decision-making\napplications. However, these models are susceptible to replicating or even\namplifying bias present in real-world data. While there are various bias\nmitigation methods and base estimators in the literature, selecting the optimal\nmodel for a specific application remains challenging.\n  This paper focuses on binary classification and proposes FairGridSearch, a\nnovel framework for comparing fairness-enhancing models. FairGridSearch enables\nexperimentation with different model parameter combinations and recommends the\nbest one. The study applies FairGridSearch to three popular datasets (Adult,\nCOMPAS, and German Credit) and analyzes the impacts of metric selection, base\nestimator choice, and classification threshold on model fairness.\n  The results highlight the significance of selecting appropriate accuracy and\nfairness metrics for model evaluation. Additionally, different base estimators\nand classification threshold values affect the effectiveness of bias mitigation\nmethods and fairness stability respectively, but the effects are not consistent\nacross all datasets. Based on these findings, future research on fairness in\nmachine learning should consider a broader range of factors when building fair\nmodels, going beyond bias mitigation methods alone.",
      "tldr_zh": "本文提出 FairGridSearch 框架，用于比较和选择增强公平性的机器学习模型，针对二元分类任务中数据偏见的问题。该框架允许实验不同参数组合，如指标选择、base estimator 和 classification threshold，并在 Adult、COMPAS 和 German Credit 数据集上进行评估。研究发现，选择合适的准确性和公平性指标至关重要，不同的 base estimator 和 threshold 会影响 bias mitigation 的效果，但这些影响因数据集而异。未来，构建公平模型的研究应考虑更多因素，而非仅限于偏见缓解方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02183v1",
      "published_date": "2024-01-04 10:29:02 UTC",
      "updated_date": "2024-01-04 10:29:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:46:09.215809"
    },
    {
      "arxiv_id": "2401.02173v1",
      "title": "Prompt Decoupling for Text-to-Image Person Re-identification",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Li",
        "Lei Tan",
        "Pingyang Dai",
        "Yan Zhang"
      ],
      "abstract": "Text-to-image person re-identification (TIReID) aims to retrieve the target\nperson from an image gallery via a textual description query. Recently,\npre-trained vision-language models like CLIP have attracted significant\nattention and have been widely utilized for this task due to their robust\ncapacity for semantic concept learning and rich multi-modal knowledge. However,\nrecent CLIP-based TIReID methods commonly rely on direct fine-tuning of the\nentire network to adapt the CLIP model for the TIReID task. Although these\nmethods show competitive performance on this topic, they are suboptimal as they\nnecessitate simultaneous domain adaptation and task adaptation. To address this\nissue, we attempt to decouple these two processes during the training stage.\nSpecifically, we introduce the prompt tuning strategy to enable domain\nadaptation and propose a two-stage training approach to disentangle domain\nadaptation from task adaptation. In the first stage, we freeze the two encoders\nfrom CLIP and solely focus on optimizing the prompts to alleviate domain gap\nbetween the original training data of CLIP and downstream tasks. In the second\nstage, we maintain the fixed prompts and fine-tune the CLIP model to prioritize\ncapturing fine-grained information, which is more suitable for TIReID task.\nFinally, we evaluate the effectiveness of our method on three widely used\ndatasets. Compared to the directly fine-tuned approach, our method achieves\nsignificant improvements.",
      "tldr_zh": "该论文针对文本到图像人物再识别（TIReID）任务，提出了一种提示解耦（Prompt Decoupling）策略，以优化基于预训练视觉语言模型（如 CLIP）的微调过程。传统方法直接微调整个网络，导致领域适应（domain adaptation）和任务适应（task adaptation）同时进行而效率低下；为此，论文采用两阶段训练方法：第一阶段冻结 CLIP 编码器，仅优化提示以减少领域差距；第二阶段固定提示并微调模型，专注于捕捉细粒度信息。实验结果显示，该方法在三个常用数据集上比直接微调方法取得了显著性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02173v1",
      "published_date": "2024-01-04 09:55:15 UTC",
      "updated_date": "2024-01-04 09:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:46:20.379536"
    },
    {
      "arxiv_id": "2401.02158v1",
      "title": "Shayona@SMM4H23: COVID-19 Self diagnosis classification using BERT and LightGBM models",
      "title_zh": "翻译失败",
      "authors": [
        "Rushi Chavda",
        "Darshan Makwana",
        "Vraj Patel",
        "Anupam Shukla"
      ],
      "abstract": "This paper describes approaches and results for shared Task 1 and 4 of\nSMMH4-23 by Team Shayona. Shared Task-1 was binary classification of english\ntweets self-reporting a COVID-19 diagnosis, and Shared Task-4 was Binary\nclassification of English Reddit posts self-reporting a social anxiety disorder\ndiagnosis. Our team has achieved the highest f1-score 0.94 in Task-1 among all\nparticipants. We have leveraged the Transformer model (BERT) in combination\nwith the LightGBM model for both tasks.",
      "tldr_zh": "这篇论文介绍了Shayona团队在SMM4H23共享任务中的方法和结果，专注于使用BERT和LightGBM模型进行COVID-19自报诊断的英语推文二元分类，以及社交焦虑障碍自报诊断的英语Reddit帖子二元分类。\n团队将Transformer模型(BERT)与LightGBM模型结合，构建了高效的分类系统。\n在任务1中，他们取得了最高的F1-score 0.94，展示了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02158v1",
      "published_date": "2024-01-04 09:13:18 UTC",
      "updated_date": "2024-01-04 09:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:46:33.091765"
    },
    {
      "arxiv_id": "2401.02154v1",
      "title": "Disentangle Estimation of Causal Effects from Cross-Silo Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Liu",
        "Haozhao Wang",
        "Shuang Wang",
        "Zhiming He",
        "Wenchao Xu",
        "Jialiang Zhu",
        "Fan Yang"
      ],
      "abstract": "Estimating causal effects among different events is of great importance to\ncritical fields such as drug development. Nevertheless, the data features\nassociated with events may be distributed across various silos and remain\nprivate within respective parties, impeding direct information exchange between\nthem. This, in turn, can result in biased estimations of local causal effects,\nwhich rely on the characteristics of only a subset of the covariates. To tackle\nthis challenge, we introduce an innovative disentangle architecture designed to\nfacilitate the seamless cross-silo transmission of model parameters, enriched\nwith causal mechanisms, through a combination of shared and private branches.\nBesides, we introduce global constraints into the equation to effectively\nmitigate bias within the various missing domains, thereby elevating the\naccuracy of our causal effect estimation. Extensive experiments conducted on\nnew semi-synthetic datasets show that our method outperforms state-of-the-art\nbaselines.",
      "tldr_zh": "该论文解决了从分布在不同数据孤岛（cross-silo data）中的私有数据中估计因果效应（causal effects）的挑战，这些数据无法直接交换导致局部估计偏差。作者提出了一种创新的解耦架构（disentangle architecture），通过共享和私有分支传输包含因果机制的模型参数，并引入全局约束来减少缺失域中的偏差，从而提升估计准确性。在半合成数据集上的广泛实验显示，该方法优于最先进基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.02154v1",
      "published_date": "2024-01-04 09:05:37 UTC",
      "updated_date": "2024-01-04 09:05:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:46:44.759206"
    },
    {
      "arxiv_id": "2401.02153v1",
      "title": "Unit Testing in ASP Revisited: Language and Test-Driven Development Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Amendola",
        "Tobias Berei",
        "Giuseppe Mazzotta",
        "Francesco Ricca"
      ],
      "abstract": "Unit testing frameworks are nowadays considered a best practice, included in\nalmost all modern software development processes, to achieve rapid development\nof correct specifications. Knowledge representation and reasoning paradigms\nsuch as Answer Set Programming (ASP), that have been used in industry-level\napplications, are not an exception. Indeed, the first unit testing\nspecification language for ASP was proposed in 2011 as a feature of the ASPIDE\ndevelopment environment. Later, a more portable unit testing language was\nincluded in the LANA annotation language. In this paper we revisit both\nlanguages and tools for unit testing in ASP. We propose a new unit test\nspecification language that allows one to inline tests within ASP programs, and\nwe identify the computational complexity of the tasks associated with checking\nthe various program-correctness assertions. Test-case specifications are\ntransparent to the traditional evaluation, but can be interpreted by a specific\ntesting tool. Thus, we present a novel environment supporting test driven\ndevelopment of ASP programs.",
      "tldr_zh": "该论文重新审视了 Answer Set Programming (ASP) 中的单元测试框架，回顾了早期的测试语言如 ASPIDE 和 LANA，并强调了这些框架在实现正确规范方面的最佳实践。该研究提出了一种新单元测试规范语言，允许在 ASP 程序中直接内联测试，并分析了检查程序正确性断言的计算复杂度。该语言对传统评估透明，但可通过特定工具解释，最终开发了一个支持 Test-Driven Development (TDD) 的新型环境，以促进 ASP 程序的快速可靠开发。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02153v1",
      "published_date": "2024-01-04 09:04:54 UTC",
      "updated_date": "2024-01-04 09:04:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:46:55.306051"
    },
    {
      "arxiv_id": "2401.02143v1",
      "title": "Graph Neural Networks for Tabular Data Learning: A Survey with Taxonomy and Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng-Te Li",
        "Yu-Che Tsai",
        "Chih-Yao Chen",
        "Jay Chiehen Liao"
      ],
      "abstract": "In this survey, we dive into Tabular Data Learning (TDL) using Graph Neural\nNetworks (GNNs), a domain where deep learning-based approaches have\nincreasingly shown superior performance in both classification and regression\ntasks compared to traditional methods. The survey highlights a critical gap in\ndeep neural TDL methods: the underrepresentation of latent correlations among\ndata instances and feature values. GNNs, with their innate capability to model\nintricate relationships and interactions between diverse elements of tabular\ndata, have garnered significant interest and application across various TDL\ndomains. Our survey provides a systematic review of the methods involved in\ndesigning and implementing GNNs for TDL (GNN4TDL). It encompasses a detailed\ninvestigation into the foundational aspects and an overview of GNN-based TDL\nmethods, offering insights into their evolving landscape. We present a\ncomprehensive taxonomy focused on constructing graph structures and\nrepresentation learning within GNN-based TDL methods. In addition, the survey\nexamines various training plans, emphasizing the integration of auxiliary tasks\nto enhance the effectiveness of instance representations. A critical part of\nour discussion is dedicated to the practical application of GNNs across a\nspectrum of GNN4TDL scenarios, demonstrating their versatility and impact.\nLastly, we discuss the limitations and propose future research directions,\naiming to spur advancements in GNN4TDL. This survey serves as a resource for\nresearchers and practitioners, offering a thorough understanding of GNNs' role\nin revolutionizing TDL and pointing towards future innovations in this\npromising area.",
      "tldr_zh": "本调查系统回顾了 Graph Neural Networks (GNNs) 在 Tabular Data Learning (TDL) 中的应用，强调 GNNs 能够更好地捕捉数据实例和特征值之间的潜在相关性，从而在分类和回归任务中超越传统方法。论文提供了一个全面的分类法，聚焦于图结构构建、表示学习以及整合辅助任务的训练计划，并探讨了 GNNs 在各种 TDL 场景中的实际应用和影响。最终，它分析了现有方法的局限性，并提出未来研究方向，以推动 GNN4TDL 领域的创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review, ongoing work, Github page:\n  https://github.com/Roytsai27/awesome-GNN4TDL",
      "pdf_url": "http://arxiv.org/pdf/2401.02143v1",
      "published_date": "2024-01-04 08:49:10 UTC",
      "updated_date": "2024-01-04 08:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:47:09.573685"
    },
    {
      "arxiv_id": "2401.02137v1",
      "title": "SyCoCa: Symmetrizing Contrastive Captioners with Attentive Masking for Multimodal Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Ziping Ma",
        "Furong Xu",
        "Jian Liu",
        "Ming Yang",
        "Qingpei Guo"
      ],
      "abstract": "Multimodal alignment between language and vision is the fundamental topic in\ncurrent vision-language model research. Contrastive Captioners (CoCa), as a\nrepresentative method, integrates Contrastive Language-Image Pretraining (CLIP)\nand Image Caption (IC) into a unified framework, resulting in impressive\nresults. CLIP imposes a bidirectional constraints on global representation of\nentire images and sentences. Although IC conducts an unidirectional\nimage-to-text generation on local representation, it lacks any constraint on\nlocal text-to-image reconstruction, which limits the ability to understand\nimages at a fine-grained level when aligned with texts. To achieve multimodal\nalignment from both global and local perspectives, this paper proposes\nSymmetrizing Contrastive Captioners (SyCoCa), which introduces bidirectional\ninteractions on images and texts across the global and local representation\nlevels. Specifically, we expand a Text-Guided Masked Image Modeling (TG-MIM)\nhead based on ITC and IC heads. The improved SyCoCa can further leverage\ntextual cues to reconstruct contextual images and visual cues to predict\ntextual contents. When implementing bidirectional local interactions, the local\ncontents of images tend to be cluttered or unrelated to their textual\ndescriptions. Thus, we employ an attentive masking strategy to select effective\nimage patches for interaction. Extensive experiments on five vision-language\ntasks, including image-text retrieval, image-captioning, visual question\nanswering, and zero-shot/finetuned image classification, validate the\neffectiveness of our proposed method.",
      "tldr_zh": "这篇论文针对视觉语言模型中的多模态对齐问题，提出了 SyCoCa 方法，以改进 Contrastive Captioners (CoCa) 的局限性，即其单向图像到文本生成缺乏文本到图像的约束。SyCoCa 通过引入双向交互，包括基于 ITC 和 IC 头的 Text-Guided Masked Image Modeling (TG-MIM) 模块，以及 attentive masking 策略来选择有效的图像 patches，从而在全局和局部表示水平上实现图像和文本的精确对齐。实验结果显示，该方法在图像文本检索、图像描述、视觉问答以及零样本/微调图像分类等五种任务上表现出色，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02137v1",
      "published_date": "2024-01-04 08:42:36 UTC",
      "updated_date": "2024-01-04 08:42:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:47:21.286730"
    },
    {
      "arxiv_id": "2401.02132v1",
      "title": "DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wendi Cui",
        "Jiaxin Zhang",
        "Zhuohang Li",
        "Lopez Damien",
        "Kamalika Das",
        "Bradley Malin",
        "Sricharan Kumar"
      ],
      "abstract": "Evaluating the quality and variability of text generated by Large Language\nModels (LLMs) poses a significant, yet unresolved research challenge.\nTraditional evaluation methods, such as ROUGE and BERTScore, which measure\ntoken similarity, often fail to capture the holistic semantic equivalence. This\nresults in a low correlation with human judgments and intuition, which is\nespecially problematic in high-stakes applications like healthcare and finance\nwhere reliability, safety, and robust decision-making are highly critical. This\nwork proposes DCR, an automated framework for evaluating and improving the\nconsistency of LLM-generated texts using a divide-conquer-reasoning approach.\nUnlike existing LLM-based evaluators that operate at the paragraph level, our\nmethod employs a divide-and-conquer evaluator (DCE) that breaks down the\nparagraph-to-paragraph comparison between two generated responses into\nindividual sentence-to-paragraph comparisons, each evaluated based on\npredefined criteria. To facilitate this approach, we introduce an automatic\nmetric converter (AMC) that translates the output from DCE into an\ninterpretable numeric score. Beyond the consistency evaluation, we further\npresent a reason-assisted improver (RAI) that leverages the analytical reasons\nwith explanations identified by DCE to generate new responses aimed at reducing\nthese inconsistencies. Through comprehensive and systematic empirical analysis,\nwe show that our approach outperforms state-of-the-art methods by a large\nmargin (e.g., +19.3% and +24.3% on the SummEval dataset) in evaluating the\nconsistency of LLM generation across multiple benchmarks in semantic, factual,\nand summarization consistency tasks. Our approach also substantially reduces\nnearly 90% of output inconsistencies, showing promise for effective\nhallucination mitigation.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）生成文本的质量和变异性评估问题，提出DCR框架，利用divide-conquer-reasoning方法，通过Divide-and-Conquer Evaluator (DCE)将段落比较分解为句子级评估，并借助Automatic Metric Converter (AMC)转换为可解释数字分数，以提升评估的语义等价性。框架还包括Reason-Assisted Improver (RAI)，利用DCE的分析原因生成改进响应，显著减少输出不一致性。实验结果显示，DCR在语义、事实和总结一致性任务上大幅优于现有方法（如在SummEval数据集上提升19.3%和24.3%），并能缓解近90%的幻觉问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02132v1",
      "published_date": "2024-01-04 08:34:16 UTC",
      "updated_date": "2024-01-04 08:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:47:40.678547"
    },
    {
      "arxiv_id": "2401.02124v1",
      "title": "ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach",
      "title_zh": "ACP-ESM：一种使用蛋白质导向Transformer方法的新颖抗癌肽分类框架",
      "authors": [
        "Zeynep Hilal Kilimci",
        "Mustafa Yalcin"
      ],
      "abstract": "Anticancer peptides (ACPs) are a class of molecules that have gained\nsignificant attention in the field of cancer research and therapy. ACPs are\nshort chains of amino acids, the building blocks of proteins, and they possess\nthe ability to selectively target and kill cancer cells. One of the key\nadvantages of ACPs is their ability to selectively target cancer cells while\nsparing healthy cells to a greater extent. This selectivity is often attributed\nto differences in the surface properties of cancer cells compared to normal\ncells. That is why ACPs are being investigated as potential candidates for\ncancer therapy. ACPs may be used alone or in combination with other treatment\nmodalities like chemotherapy and radiation therapy. While ACPs hold promise as\na novel approach to cancer treatment, there are challenges to overcome,\nincluding optimizing their stability, improving selectivity, and enhancing\ntheir delivery to cancer cells, continuous increasing in number of peptide\nsequences, developing a reliable and precise prediction model. In this work, we\npropose an efficient transformer-based framework to identify anticancer\npeptides for by performing accurate a reliable and precise prediction model.\nFor this purpose, four different transformer models, namely ESM, ProtBert,\nBioBERT, and SciBERT are employed to detect anticancer peptides from amino acid\nsequences. To demonstrate the contribution of the proposed framework, extensive\nexperiments are carried on widely-used datasets in the literature, two versions\nof AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of\nproposed model enhances classification accuracy when compared to the\nstate-of-the-art studies. The proposed framework, ESM, exhibits 96.45 of\naccuracy for AntiCp2 dataset, 97.66 of accuracy for cACP-DeepGram dataset, and\n88.51 of accuracy for ACP-740 dataset, thence determining new state-of-the-art.",
      "tldr_zh": "该研究提出了一种名为 ACP-ESM 的新框架，利用蛋白质导向的 Transformer 方法（如 ESM、ProtBert、BioBERT 和 SciBERT）来分类抗癌肽（ACPs），以提高预测的准确性和可靠性。框架针对氨基酸序列进行检测，旨在解决 ACPs 在癌症治疗中的稳定性、选择性和递送挑战。实验在 AntiCp2、cACP-DeepGram 和 ACP-740 数据集上显示，ESM 模型分别取得了 96.45%、97.66% 和 88.51% 的准确率，超越了现有最先进方法。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02124v1",
      "published_date": "2024-01-04 08:19:27 UTC",
      "updated_date": "2024-01-04 08:19:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:47:48.409597"
    },
    {
      "arxiv_id": "2401.02458v2",
      "title": "Data-Centric Foundation Models in Computational Healthcare: A Survey",
      "title_zh": "计算医疗保健中的数据为中心的基础模型：一项综述",
      "authors": [
        "Yunkun Zhang",
        "Jin Gao",
        "Zheling Tan",
        "Lingfeng Zhou",
        "Kexin Ding",
        "Mu Zhou",
        "Shaoting Zhang",
        "Dequan Wang"
      ],
      "abstract": "The advent of foundation models (FMs) as an emerging suite of AI techniques\nhas struck a wave of opportunities in computational healthcare. The interactive\nnature of these models, guided by pre-training data and human instructions, has\nignited a data-centric AI paradigm that emphasizes better data\ncharacterization, quality, and scale. In healthcare AI, obtaining and\nprocessing high-quality clinical data records has been a longstanding\nchallenge, ranging from data quantity, annotation, patient privacy, and ethics.\nIn this survey, we investigate a wide range of data-centric approaches in the\nFM era (from model pre-training to inference) towards improving the healthcare\nworkflow. We discuss key perspectives in AI security, assessment, and alignment\nwith human values. Finally, we offer a promising outlook of FM-based analytics\nto enhance the performance of patient outcome and clinical workflow in the\nevolving landscape of healthcare and medicine. We provide an up-to-date list of\nhealthcare-related foundation models and datasets at\nhttps://github.com/Yunkun-Zhang/Data-Centric-FM-Healthcare .",
      "tldr_zh": "这篇调查论文探讨了数据中心型基础模型（Foundation Models, FMs）在计算医疗领域的应用，强调了数据特征化、质量和规模的重要性，以应对医疗AI面临的挑战，如数据量不足、标注难题、患者隐私和伦理问题。该论文系统审视了从模型预训练到推理阶段的各种数据中心方法，包括AI安全、评估和与人类价值观的alignment，以优化医疗工作流程。最终，它展望了FM-based分析如何提升患者结果和临床效率，并提供了相关模型和数据集的GitHub资源列表。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Survey content updated to include recent research work and progress",
      "pdf_url": "http://arxiv.org/pdf/2401.02458v2",
      "published_date": "2024-01-04 08:00:32 UTC",
      "updated_date": "2024-10-07 14:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:47:59.967687"
    },
    {
      "arxiv_id": "2401.02117v1",
      "title": "Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation",
      "title_zh": "Mobile ALOHA",
      "authors": [
        "Zipeng Fu",
        "Tony Z. Zhao",
        "Chelsea Finn"
      ],
      "abstract": "Imitation learning from human demonstrations has shown impressive performance\nin robotics. However, most results focus on table-top manipulation, lacking the\nmobility and dexterity necessary for generally useful tasks. In this work, we\ndevelop a system for imitating mobile manipulation tasks that are bimanual and\nrequire whole-body control. We first present Mobile ALOHA, a low-cost and\nwhole-body teleoperation system for data collection. It augments the ALOHA\nsystem with a mobile base, and a whole-body teleoperation interface. Using data\ncollected with Mobile ALOHA, we then perform supervised behavior cloning and\nfind that co-training with existing static ALOHA datasets boosts performance on\nmobile manipulation tasks. With 50 demonstrations for each task, co-training\ncan increase success rates by up to 90%, allowing Mobile ALOHA to autonomously\ncomplete complex mobile manipulation tasks such as sauteing and serving a piece\nof shrimp, opening a two-door wall cabinet to store heavy cooking pots, calling\nand entering an elevator, and lightly rinsing a used pan using a kitchen\nfaucet. Project website: https://mobile-aloha.github.io",
      "tldr_zh": "这篇论文介绍了 Mobile ALOHA，一种低成本的全身遥操作系统，用于收集双臂移动操作数据，以提升机器人对复杂任务的模仿学习。研究方法结合了监督行为克隆（supervised behavior cloning）和与现有静态 ALOHA 数据集的联合训练，仅需每个任务 50 次演示，就能将成功率提高多达 90%。结果显示，Mobile ALOHA 机器人能够自主完成如炒虾并上菜、打开双门壁柜存储重物、呼叫并进入电梯，以及用厨房水龙头冲洗锅具等实际移动操作任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://mobile-aloha.github.io (Zipeng Fu and Tony\n  Z. Zhao are project co-leads, Chelsea Finn is the advisor)",
      "pdf_url": "http://arxiv.org/pdf/2401.02117v1",
      "published_date": "2024-01-04 07:55:53 UTC",
      "updated_date": "2024-01-04 07:55:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:48:12.842077"
    },
    {
      "arxiv_id": "2401.02994v3",
      "title": "Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoding Lu",
        "Zongyi Liu",
        "Adian Liusie",
        "Vyas Raina",
        "Vineet Mudupalli",
        "Yuwen Zhang",
        "William Beauchamp"
      ],
      "abstract": "In conversational AI research, there's a noticeable trend towards developing\nmodels with a larger number of parameters, exemplified by models like ChatGPT.\nWhile these expansive models tend to generate increasingly better chat\nresponses, they demand significant computational resources and memory. This\nstudy explores a pertinent question: Can a combination of smaller models\ncollaboratively achieve comparable or enhanced performance relative to a\nsingular large model? We introduce an approach termed \"blending\", a\nstraightforward yet effective method of integrating multiple chat AIs. Our\nempirical evidence suggests that when specific smaller models are\nsynergistically blended, they can potentially outperform or match the\ncapabilities of much larger counterparts. For instance, integrating just three\nmodels of moderate size (6B/13B paramaeters) can rival or even surpass the\nperformance metrics of a substantially larger model like ChatGPT (175B+\nparamaters). This hypothesis is rigorously tested using A/B testing\nmethodologies with a large user base on the Chai research platform over a span\nof thirty days. The findings underscore the potential of the \"blending\"\nstrategy as a viable approach for enhancing chat AI efficacy without a\ncorresponding surge in computational demands.",
      "tldr_zh": "本研究探讨了是否可以通过整合多个小型语言模型（LLM）来替代巨型模型（如ChatGPT），以实现更高效的对话AI性能。作者提出“blending”方法，即简单地将几个中等规模模型（6B/13B参数）结合使用，这种协同策略能匹敌或超越大型模型（如175B+参数的ChatGPT）的表现。实验通过A/B测试在Chai平台上进行，涉及大量用户并持续30天，结果显示blending显著提升了聊天AI的效能，同时降低了计算资源需求。该方法为开发更经济实用的AI提供了可行途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02994v3",
      "published_date": "2024-01-04 07:45:49 UTC",
      "updated_date": "2024-01-23 04:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:48:23.235943"
    },
    {
      "arxiv_id": "2401.02993v2",
      "title": "ReFusion: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion",
      "title_zh": "ReFusion：通过计算高效的检索表示融合改进自然语言理解",
      "authors": [
        "Shangyu Wu",
        "Ying Xiong",
        "Yufei Cui",
        "Xue Liu",
        "Buzhou Tang",
        "Tei-Wei Kuo",
        "Chun Jason Xue"
      ],
      "abstract": "Retrieval-based augmentations (RA) incorporating knowledge from an external\ndatabase into language models have greatly succeeded in various\nknowledge-intensive (KI) tasks. However, integrating retrievals in\nnon-knowledge-intensive (NKI) tasks is still challenging. Existing works focus\non concatenating retrievals with inputs to improve model performance.\nUnfortunately, the use of retrieval concatenation-based augmentations causes an\nincrease in the input length, substantially raising the computational demands\nof attention mechanisms. This paper proposes a new paradigm of RA named\n\\textbf{ReFusion}, a computation-efficient Retrieval representation Fusion with\nbi-level optimization. Unlike previous works, ReFusion directly fuses the\nretrieval representations into the hidden states of models. Specifically,\nReFusion leverages an adaptive retrieval integrator to seek the optimal\ncombination of the proposed ranking schemes across different model layers.\nExperimental results demonstrate that the proposed ReFusion can achieve\nsuperior and robust performance in various NKI tasks.",
      "tldr_zh": "本文研究了如何在非知识密集型（NKI）任务中提升自然语言理解，同时解决现有检索增强（RA）技术因输入拼接导致的计算负担问题。论文提出 ReFusion，一种计算高效的检索表示融合方法，通过直接将检索表示融合到模型隐藏状态，并采用自适应检索整合器和双层优化来优化不同层面的排名方案。该方法在实验中展示了优越且稳健的性能，显著提高了 NKI 任务的整体效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02993v2",
      "published_date": "2024-01-04 07:39:26 UTC",
      "updated_date": "2024-05-27 07:04:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:48:36.925849"
    },
    {
      "arxiv_id": "2401.02457v1",
      "title": "eCIL-MU: Embedding based Class Incremental Learning and Machine Unlearning",
      "title_zh": "eCIL-MU：基于嵌入的类别增量学习和机器遗忘",
      "authors": [
        "Zhiwei Zuo",
        "Zhuo Tang",
        "Bin Wang",
        "Kenli Li",
        "Anwitaman Datta"
      ],
      "abstract": "New categories may be introduced over time, or existing categories may need\nto be reclassified. Class incremental learning (CIL) is employed for the\ngradual acquisition of knowledge about new categories while preserving\ninformation about previously learned ones in such dynamic environments. It\nmight also be necessary to also eliminate the influence of related categories\non the model to adapt to reclassification. We thus introduce class-level\nmachine unlearning (MU) within CIL. Typically, MU methods tend to be\ntime-consuming and can potentially harm the model's performance. A continuous\nstream of unlearning requests could lead to catastrophic forgetting. To address\nthese issues, we propose a non-destructive eCIL-MU framework based on embedding\ntechniques to map data into vectors and then be stored in vector databases. Our\napproach exploits the overlap between CIL and MU tasks for acceleration.\nExperiments demonstrate the capability of achieving unlearning effectiveness\nand orders of magnitude (upto $\\sim 278\\times$) of acceleration.",
      "tldr_zh": "本研究提出 eCIL-MU 框架，结合基于 embedding techniques 的 Class Incremental Learning (CIL) 和 Machine Unlearning (MU)，以在动态环境中逐步学习新类别，同时消除特定类别的影響并保留旧知识。\n该框架通过将数据映射到向量数据库中，并利用 CIL 和 MU 任务的重叠，实现非破坏性的处理，解决了传统 MU 方法的耗时问题和潜在性能损害。\n实验结果表明，eCIL-MU 不仅在机器遗忘效果上表现出色，还实现了高达约 278 倍的加速。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02457v1",
      "published_date": "2024-01-04 07:18:32 UTC",
      "updated_date": "2024-01-04 07:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:48:49.332832"
    },
    {
      "arxiv_id": "2401.02092v1",
      "title": "k-Winners-Take-All Ensemble Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Abien Fred Agarap",
        "Arnulfo P. Azcarraga"
      ],
      "abstract": "Ensembling is one approach that improves the performance of a neural network\nby combining a number of independent neural networks, usually by either\naveraging or summing up their individual outputs. We modify this ensembling\napproach by training the sub-networks concurrently instead of independently.\nThis concurrent training of sub-networks leads them to cooperate with each\nother, and we refer to them as \"cooperative ensemble\". Meanwhile, the\nmixture-of-experts approach improves a neural network performance by dividing\nup a given dataset to its sub-networks. It then uses a gating network that\nassigns a specialization to each of its sub-networks called \"experts\". We\nimprove on these aforementioned ways for combining a group of neural networks\nby using a k-Winners-Take-All (kWTA) activation function, that acts as the\ncombination method for the outputs of each sub-network in the ensemble. We\nrefer to this proposed model as \"kWTA ensemble neural networks\" (kWTA-ENN).\nWith the kWTA activation function, the losing neurons of the sub-networks are\ninhibited while the winning neurons are retained. This results in sub-networks\nhaving some form of specialization but also sharing knowledge with one another.\nWe compare our approach with the cooperative ensemble and mixture-of-experts,\nwhere we used a feed-forward neural network with one hidden layer having 100\nneurons as the sub-network architecture. Our approach yields a better\nperformance compared to the baseline models, reaching the following test\naccuracies on benchmark datasets: 98.34% on MNIST, 88.06% on Fashion-MNIST,\n91.56% on KMNIST, and 95.97% on WDBC.",
      "tldr_zh": "本论文提出了一种名为 k-Winners-Take-All Ensemble Neural Network (kWTA-ENN) 的新模型，通过 k-Winners-Take-All (kWTA) 激活函数来组合子网络的输出，实现子网络间的合作和知识共享。不同于传统的集成方法（如 averaging 或 summing）或 mixture-of-experts 方式，该方法采用并发训练子网络，并抑制失败神经元以保留成功神经元，从而增强子网络的专业化和整体性能。在基准数据集上的实验结果显示，kWTA-ENN 优于基线模型，分别在 MNIST、Fashion-MNIST、KMNIST 和 WDBC 上达到 98.34%、88.06%、91.56% 和 95.97% 的测试准确率。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Presented in ICONIP 2021",
      "pdf_url": "http://arxiv.org/pdf/2401.02092v1",
      "published_date": "2024-01-04 06:40:32 UTC",
      "updated_date": "2024-01-04 06:40:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:49:00.811958"
    },
    {
      "arxiv_id": "2401.02992v1",
      "title": "Advanced Unstructured Data Processing for ESG Reports: A Methodology for Structured Transformation and Enhanced Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahui Peng",
        "Jing Gao",
        "Xin Tong",
        "Jing Guo",
        "Hang Yang",
        "Jianchuan Qi",
        "Ruiqiao Li",
        "Nan Li",
        "Ming Xu"
      ],
      "abstract": "In the evolving field of corporate sustainability, analyzing unstructured\nEnvironmental, Social, and Governance (ESG) reports is a complex challenge due\nto their varied formats and intricate content. This study introduces an\ninnovative methodology utilizing the \"Unstructured Core Library\", specifically\ntailored to address these challenges by transforming ESG reports into\nstructured, analyzable formats. Our approach significantly advances the\nexisting research by offering high-precision text cleaning, adept\nidentification and extraction of text from images, and standardization of\ntables within these reports. Emphasizing its capability to handle diverse data\ntypes, including text, images, and tables, the method adeptly manages the\nnuances of differing page layouts and report styles across industries. This\nresearch marks a substantial contribution to the fields of industrial ecology\nand corporate sustainability assessment, paving the way for the application of\nadvanced NLP technologies and large language models in the analysis of\ncorporate governance and sustainability. Our code is available at\nhttps://github.com/linancn/TianGong-AI-Unstructure.git.",
      "tldr_zh": "本研究针对企业可持续性领域的 ESG 报告非结构化数据处理挑战，提出了一种创新方法，利用 Unstructured Core Library 将报告转化为结构化格式，以提升分析效率。该方法包括高精度文本清洗、从图像中提取文本以及表格标准化，能够有效处理文本、图像和表格等多种数据类型，并适应不同行业的页面布局和报告风格。作为工业生态和企业可持续性评估的重要贡献，该方法促进了 NLP 技术和大型语言模型在公司治理分析中的应用，并提供了开源代码（https://github.com/linancn/TianGong-AI-Unstructure.git）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02992v1",
      "published_date": "2024-01-04 06:26:59 UTC",
      "updated_date": "2024-01-04 06:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:49:12.388020"
    },
    {
      "arxiv_id": "2401.02456v1",
      "title": "A comprehensive survey of research towards AI-enabled unmanned aerial systems in pre-, active-, and post-wildfire management",
      "title_zh": "翻译失败",
      "authors": [
        "Sayed Pedram Haeri Boroujeni",
        "Abolfazl Razi",
        "Sahand Khoshdel",
        "Fatemeh Afghah",
        "Janice L. Coen",
        "Leo ONeill",
        "Peter Z. Fule",
        "Adam Watts",
        "Nick-Marios T. Kokolakis",
        "Kyriakos G. Vamvoudakis"
      ],
      "abstract": "Wildfires have emerged as one of the most destructive natural disasters\nworldwide, causing catastrophic losses in both human lives and forest wildlife.\nRecently, the use of Artificial Intelligence (AI) in wildfires, propelled by\nthe integration of Unmanned Aerial Vehicles (UAVs) and deep learning models,\nhas created an unprecedented momentum to implement and develop more effective\nwildfire management. Although some of the existing survey papers have explored\nvarious learning-based approaches, a comprehensive review emphasizing the\napplication of AI-enabled UAV systems and their subsequent impact on\nmulti-stage wildfire management is notably lacking. This survey aims to bridge\nthese gaps by offering a systematic review of the recent state-of-the-art\ntechnologies, highlighting the advancements of UAV systems and AI models from\npre-fire, through the active-fire stage, to post-fire management. To this aim,\nwe provide an extensive analysis of the existing remote sensing systems with a\nparticular focus on the UAV advancements, device specifications, and sensor\ntechnologies relevant to wildfire management. We also examine the pre-fire and\npost-fire management approaches, including fuel monitoring, prevention\nstrategies, as well as evacuation planning, damage assessment, and operation\nstrategies. Additionally, we review and summarize a wide range of computer\nvision techniques in active-fire management, with an emphasis on Machine\nLearning (ML), Reinforcement Learning (RL), and Deep Learning (DL) algorithms\nfor wildfire classification, segmentation, detection, and monitoring tasks.\nUltimately, we underscore the substantial advancement in wildfire modeling\nthrough the integration of cutting-edge AI techniques and UAV-based data,\nproviding novel insights and enhanced predictive capabilities to understand\ndynamic wildfire behavior.",
      "tldr_zh": "本调查对 AI 赋能的无人驾驶航空系统 (UAVs) 在野火管理的预火、活跃火和后火阶段进行全面回顾，旨在填补现有文献的空白。论文分析了 UAV 的技术进展、设备规格和传感器系统，以及预火策略（如燃料监测和预防）和后火策略（如疏散规划、损害评估）。此外，它总结了活跃火管理中的计算机视觉技术，包括 Machine Learning (ML)、Reinforcement Learning (RL) 和 Deep Learning (DL) 算法，用于野火分类、分割、检测和监测，并强调了整合 AI 与 UAV 数据对野火建模的重大进步，提供更精确的预测和洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02456v1",
      "published_date": "2024-01-04 05:09:35 UTC",
      "updated_date": "2024-01-04 05:09:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:49:25.001602"
    },
    {
      "arxiv_id": "2401.04125v1",
      "title": "DeepPhysiNet: Bridging Deep Learning and Atmospheric Physics for Accurate and Continuous Weather Modeling",
      "title_zh": "DeepPhysiNet：桥接",
      "authors": [
        "Wenyuan Li",
        "Zili Liu",
        "Keyan Chen",
        "Hao Chen",
        "Shunlin Liang",
        "Zhengxia Zou",
        "Zhenwei Shi"
      ],
      "abstract": "Accurate weather forecasting holds significant importance to human\nactivities. Currently, there are two paradigms for weather forecasting:\nNumerical Weather Prediction (NWP) and Deep Learning-based Prediction (DLP).\nNWP utilizes atmospheric physics for weather modeling but suffers from poor\ndata utilization and high computational costs, while DLP can learn weather\npatterns from vast amounts of data directly but struggles to incorporate\nphysical laws. Both paradigms possess their respective strengths and\nweaknesses, and are incompatible, because physical laws adopted in NWP describe\nthe relationship between coordinates and meteorological variables, while DLP\ndirectly learns the relationships between meteorological variables without\nconsideration of coordinates. To address these problems, we introduce the\nDeepPhysiNet framework, incorporating physical laws into deep learning models\nfor accurate and continuous weather system modeling. First, we construct\nphysics networks based on multilayer perceptrons (MLPs) for individual\nmeteorological variable, such as temperature, pressure, and wind speed. Physics\nnetworks establish relationships between variables and coordinates by taking\ncoordinates as input and producing variable values as output. The physical laws\nin the form of Partial Differential Equations (PDEs) can be incorporated as a\npart of loss function. Next, we construct hyper-networks based on deep learning\nmethods to directly learn weather patterns from a large amount of\nmeteorological data. The output of hyper-networks constitutes a part of the\nweights for the physics networks. Experimental results demonstrate that, upon\nsuccessful integration of physical laws, DeepPhysiNet can accomplish multiple\ntasks simultaneously, not only enhancing forecast accuracy but also obtaining\ncontinuous spatiotemporal resolution results, which is unattainable by either\nthe NWP or DLP.",
      "tldr_zh": "该研究探讨了天气预报的两大范式：NWP（Numerical Weather Prediction）和DLP（Deep Learning-based Prediction），前者依赖大气物理学但数据利用率低且计算成本高，后者从大量数据中学习模式却无法融入物理定律。针对这些问题，作者提出DeepPhysiNet框架，通过physics networks（基于MLPs的多层感知器）为每个气象变量（如温度、压力和风速）建立变量与坐标的关系，并将物理定律以PDEs（Partial Differential Equations）形式融入损失函数。框架还结合hyper-networks从气象数据中学习天气模式，其输出作为physics networks的部分权重。实验结果显示，DeepPhysiNet不仅提升了预测准确性，还实现了连续的时空分辨率结果，这一点是NWP或DLP单独无法达到的。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "18 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.04125v1",
      "published_date": "2024-01-04 05:05:16 UTC",
      "updated_date": "2024-01-04 05:05:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:49:41.055804"
    },
    {
      "arxiv_id": "2401.02051v3",
      "title": "Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Liu",
        "Xialiang Tong",
        "Mingxuan Yuan",
        "Xi Lin",
        "Fu Luo",
        "Zhenkun Wang",
        "Zhichao Lu",
        "Qingfu Zhang"
      ],
      "abstract": "Heuristics are widely used for dealing with complex search and optimization\nproblems. However, manual design of heuristics can be often very labour\nextensive and requires rich working experience and knowledge. This paper\nproposes Evolution of Heuristic (EoH), a novel evolutionary paradigm that\nleverages both Large Language Models (LLMs) and Evolutionary Computation (EC)\nmethods for Automatic Heuristic Design (AHD). EoH represents the ideas of\nheuristics in natural language, termed thoughts. They are then translated into\nexecutable codes by LLMs. The evolution of both thoughts and codes in an\nevolutionary search framework makes it very effective and efficient for\ngenerating high-performance heuristics. Experiments on three widely studied\ncombinatorial optimization benchmark problems demonstrate that EoH outperforms\ncommonly used handcrafted heuristics and other recent AHD methods including\nFunSearch. Particularly, the heuristic produced by EoH with a low computational\nbudget (in terms of the number of queries to LLMs) significantly outperforms\nwidely-used human hand-crafted baseline algorithms for the online bin packing\nproblem.",
      "tldr_zh": "本文提出 Evolution of Heuristic (EoH)，一种结合 Large Language Models (LLMs) 和 Evolutionary Computation (EC) 的框架，用于 Automatic Heuristic Design (AHD)，以高效自动生成高性能启发式算法。EoH 通过自然语言表示启发式想法（称为 thoughts），由 LLMs 翻译成可执行代码，并在进化搜索框架中演化这些 thoughts 和代码。实验结果显示，在三个组合优化基准问题上，EoH 优于传统手工启发式算法和其他 AHD 方法（如 FunSearch），特别是在在线 bin packing 问题上，即使在低计算预算下也显著超越人类设计的基线算法。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02051v3",
      "published_date": "2024-01-04 04:11:59 UTC",
      "updated_date": "2024-06-01 16:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:49:53.266850"
    },
    {
      "arxiv_id": "2401.04124v3",
      "title": "MobileAgent: enhancing mobile control via human-machine interaction and SOP integration",
      "title_zh": "MobileAgent",
      "authors": [
        "Tinghe Ding"
      ],
      "abstract": "Agents centered around Large Language Models (LLMs) are now capable of\nautomating mobile device operations for users. After fine-tuning to learn a\nuser's mobile operations, these agents can adhere to high-level user\ninstructions online. They execute tasks such as goal decomposition, sequencing\nof sub-goals, and interactive environmental exploration, until the final\nobjective is achieved. However, privacy concerns related to personalized user\ndata arise during mobile operations, requiring user confirmation. Moreover,\nusers' real-world operations are exploratory, with action data being complex\nand redundant, posing challenges for agent learning. To address these issues,\nin our practical application, we have designed interactive tasks between agents\nand humans to identify sensitive information and align with personalized user\nneeds. Additionally, we integrated Standard Operating Procedure (SOP)\ninformation within the model's in-context learning to enhance the agent's\ncomprehension of complex task execution. Our approach is evaluated on the new\ndevice control benchmark AitW, which encompasses 30K unique instructions across\nmulti-step tasks, including application operation, web searching, and web\nshopping. Experimental results show that the SOP-based agent achieves\nstate-of-the-art performance in LLMs without incurring additional inference\ncosts, boasting an overall action success rate of 66.92\\%. The code and data\nexamples are available at https://github.com/alipay/mobile-agent.",
      "tldr_zh": "这篇论文提出了 MobileAgent，一种基于 Large Language Models (LLMs) 的代理系统，用于提升移动设备控制，通过人机互动处理隐私问题和个性化需求，并整合 Standard Operating Procedure (SOP) 到模型的上下文学习中，以应对复杂任务的执行挑战。MobileAgent 能够自动分解目标、排序子目标并探索环境，同时确保用户数据安全。实验在新的 AitW 基准上进行评估，该基准包含 30K 条多步指令，结果显示 SOP 增强的代理在不增加推理成本的情况下，实现了 66.92% 的行动成功率，达到最先进性能。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "agent, mobile control, SOP, human-machine interaction",
      "pdf_url": "http://arxiv.org/pdf/2401.04124v3",
      "published_date": "2024-01-04 03:44:42 UTC",
      "updated_date": "2024-01-17 06:35:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:50:04.411292"
    },
    {
      "arxiv_id": "2401.10268v2",
      "title": "The complementary contributions of academia and industry to AI research",
      "title_zh": "学术界和产业界对人工智能研究的互补贡献",
      "authors": [
        "Lizhen Liang",
        "Han Zhuang",
        "James Zou",
        "Daniel E. Acuna"
      ],
      "abstract": "Artificial intelligence (AI) has seen fast paced development in industry and\nacademia. However, striking recent advances by industry have stunned the field,\ninviting a fresh perspective on the role of academic research on this progress.\nHere, we characterize the impact and type of AI produced by both environments\nover the last 25 years and establish several patterns. We find that articles\npublished by teams consisting exclusively of industry researchers tend to get\ngreater attention, with a higher chance of being highly cited and\ncitation-disruptive, and several times more likely to produce state-of-the-art\nmodels. In contrast, we find that exclusively academic teams publish the bulk\nof AI research and tend to produce higher novelty work, with single papers\nhaving several times higher likelihood of being unconventional and atypical.\nThe respective impact-novelty advantages of industry and academia are robust to\ncontrols for subfield, team size, seniority, and prestige. We find that\nacademic-industry collaborations produce the most impactful work overall but do\nnot have the novelty level of academic teams. Together, our findings identify\nthe unique and nearly irreplaceable contributions that both academia and\nindustry make toward the progress of AI.",
      "tldr_zh": "这项研究分析了过去25年AI领域的学术和工业贡献，发现工业团队发表的论文更易获得高引用、引文破坏性和state-of-the-art模型，而学术团队则主导了大部分研究，并更倾向于产生高创新性的非传统工作。学术-工业合作产生了整体最有影响力的成果，但其新颖性不如纯学术团队。经过控制子领域、团队规模、资历和声望等变量，这些模式依然成立。该研究强调了学术界和工业界在AI进步中的独特且不可替代的互补作用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "35 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10268v2",
      "published_date": "2024-01-04 03:08:13 UTC",
      "updated_date": "2024-09-18 23:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:50:15.248530"
    },
    {
      "arxiv_id": "2401.02452v2",
      "title": "The Compute Divide in Machine Learning: A Threat to Academic Contribution and Scrutiny?",
      "title_zh": "机器学习中的计算鸿沟：对学术贡献和审视的威胁？",
      "authors": [
        "Tamay Besiroglu",
        "Sage Andrus Bergerson",
        "Amelia Michael",
        "Lennart Heim",
        "Xueyun Luo",
        "Neil Thompson"
      ],
      "abstract": "There are pronounced differences in the extent to which industrial and\nacademic AI labs use computing resources. We provide a data-driven survey of\nthe role of the compute divide in shaping machine learning research. We show\nthat a compute divide has coincided with a reduced representation of\nacademic-only research teams in compute intensive research topics, especially\nfoundation models. We argue that, academia will likely play a smaller role in\nadvancing the associated techniques, providing critical evaluation and\nscrutiny, and in the diffusion of such models. Concurrent with this change in\nresearch focus, there is a noticeable shift in academic research towards\nembracing open source, pre-trained models developed within the industry. To\naddress the challenges arising from this trend, especially reduced scrutiny of\ninfluential models, we recommend approaches aimed at thoughtfully expanding\nacademic insights. Nationally-sponsored computing infrastructure coupled with\nopen science initiatives could judiciously boost academic compute access,\nprioritizing research on interpretability, safety and security. Structured\naccess programs and third-party auditing may also allow measured external\nevaluation of industry systems.",
      "tldr_zh": "本研究调查了机器学习领域的计算资源差距（compute divide），即工业和学术AI实验室在资源使用上的显著差异。通过数据驱动分析，发现这一差距导致学术团队在计算密集型主题（如foundation models）中的代表性下降，学术界在技术推进、批判性评估和模型扩散方面的作用可能减小。同时，学术研究正转向采用工业开发的开源预训练模型，以应对此趋势。该论文建议通过国家资助的计算基础设施、开源科学举措、优先支持可解释性、安全性和安全性研究，以及引入结构化访问程序和第三方审计，来增强学术洞察并提升对工业系统的外部评估。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02452v2",
      "published_date": "2024-01-04 01:26:11 UTC",
      "updated_date": "2024-01-08 12:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:50:27.159735"
    },
    {
      "arxiv_id": "2401.10267v4",
      "title": "HyperSense: Hyperdimensional Intelligent Sensing for Energy-Efficient Sparse Data Processing",
      "title_zh": "HyperSense",
      "authors": [
        "Sanggeon Yun",
        "Hanning Chen",
        "Ryozo Masukawa",
        "Hamza Errahmouni Barkam",
        "Andrew Ding",
        "Wenjun Huang",
        "Arghavan Rezvani",
        "Shaahin Angizi",
        "Mohsen Imani"
      ],
      "abstract": "Introducing HyperSense, our co-designed hardware and software system\nefficiently controls Analog-to-Digital Converter (ADC) modules' data generation\nrate based on object presence predictions in sensor data. Addressing challenges\nposed by escalating sensor quantities and data rates, HyperSense reduces\nredundant digital data using energy-efficient low-precision ADC, diminishing\nmachine learning system costs. Leveraging neurally-inspired HyperDimensional\nComputing (HDC), HyperSense analyzes real-time raw low-precision sensor data,\noffering advantages in handling noise, memory-centricity, and real-time\nlearning. Our proposed HyperSense model combines high-performance software for\nobject detection with real-time hardware prediction, introducing the novel\nconcept of Intelligent Sensor Control. Comprehensive software and hardware\nevaluations demonstrate our solution's superior performance, evidenced by the\nhighest Area Under the Curve (AUC) and sharpest Receiver Operating\nCharacteristic (ROC) curve among lightweight models. Hardware-wise, our\nFPGA-based domain-specific accelerator tailored for HyperSense achieves a 5.6x\nspeedup compared to YOLOv4 on NVIDIA Jetson Orin while showing up to 92.1%\nenergy saving compared to the conventional system. These results underscore\nHyperSense's effectiveness and efficiency, positioning it as a promising\nsolution for intelligent sensing and real-time data processing across diverse\napplications.",
      "tldr_zh": "本文提出 HyperSense 系统，这是一个硬件和软件协同设计的框架，用于高效处理稀疏传感器数据，通过基于对象存在预测的智能控制来动态调整 ADC 模块的数据生成率，从而减少冗余数据和能量消耗。系统利用神经灵感的高维计算 (HDC) 分析实时低精度传感器数据，结合高性能软件对象检测和 FPGA 基于的硬件加速器，实现实时学习和噪声处理。实验评估显示，HyperSense 在软件方面获得最高的 AUC 和最锐利的 ROC 曲线，在硬件方面比 YOLOv4 在 NVIDIA Jetson Orin 上实现 5.6 倍速度提升和高达 92.1% 能量节省，为智能感知和实时数据处理提供高效解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10267v4",
      "published_date": "2024-01-04 01:12:33 UTC",
      "updated_date": "2024-10-29 21:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:50:41.302777"
    },
    {
      "arxiv_id": "2401.02015v1",
      "title": "Improving Diffusion-Based Image Synthesis with Context Prediction",
      "title_zh": "通过上下文预测改善基于扩散的图像合成",
      "authors": [
        "Ling Yang",
        "Jingwei Liu",
        "Shenda Hong",
        "Zhilong Zhang",
        "Zhilin Huang",
        "Zheming Cai",
        "Wentao Zhang",
        "Bin Cui"
      ],
      "abstract": "Diffusion models are a new class of generative models, and have dramatically\npromoted image generation with unprecedented quality and diversity. Existing\ndiffusion models mainly try to reconstruct input image from a corrupted one\nwith a pixel-wise or feature-wise constraint along spatial axes. However, such\npoint-based reconstruction may fail to make each predicted pixel/feature fully\npreserve its neighborhood context, impairing diffusion-based image synthesis.\nAs a powerful source of automatic supervisory signal, context has been well\nstudied for learning representations. Inspired by this, we for the first time\npropose ConPreDiff to improve diffusion-based image synthesis with context\nprediction. We explicitly reinforce each point to predict its neighborhood\ncontext (i.e., multi-stride features/tokens/pixels) with a context decoder at\nthe end of diffusion denoising blocks in training stage, and remove the decoder\nfor inference. In this way, each point can better reconstruct itself by\npreserving its semantic connections with neighborhood context. This new\nparadigm of ConPreDiff can generalize to arbitrary discrete and continuous\ndiffusion backbones without introducing extra parameters in sampling procedure.\nExtensive experiments are conducted on unconditional image generation,\ntext-to-image generation and image inpainting tasks. Our ConPreDiff\nconsistently outperforms previous methods and achieves a new SOTA text-to-image\ngeneration results on MS-COCO, with a zero-shot FID score of 6.21.",
      "tldr_zh": "这篇论文针对扩散模型（Diffusion models）在图像合成中的问题，提出了一种名为 ConPreDiff 的新方法，通过预测邻域上下文来改善重建过程，确保每个像素或特征更好地保留其语义连接。方法在训练阶段添加上下文解码器，让模型预测多步幅的特征/像素，而在推理阶段移除解码器，从而适用于任意离散和连续扩散模型 backbone，且不引入额外参数。实验结果显示，ConPreDiff 在无条件图像生成、文本到图像生成和图像修复任务上均优于现有方法，并在 MS-COCO 数据集上实现零样本 FID score 为 6.21 的新 SOTA 成绩。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.02015v1",
      "published_date": "2024-01-04 01:10:56 UTC",
      "updated_date": "2024-01-04 01:10:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:50:52.177768"
    },
    {
      "arxiv_id": "2401.02009v3",
      "title": "Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqi Zhang",
        "Yongliang Shen",
        "Linjuan Wu",
        "Qiuying Peng",
        "Jun Wang",
        "Yueting Zhuang",
        "Weiming Lu"
      ],
      "abstract": "The reflection capacity of Large Language Model (LLM) has garnered extensive\nattention. A post-hoc prompting strategy, e.g., reflexion and self-refine,\nrefines LLM's response based on self-evaluated or external feedback. However,\nrecent research indicates without external feedback, LLM's intrinsic reflection\nis unstable. Our investigation unveils that the key bottleneck is the quality\nof the self-evaluated feedback. We find LLMs often exhibit overconfidence or\nhigh randomness when self-evaluate, offering stubborn or inconsistent feedback,\nwhich causes poor reflection. To remedy this, we advocate Self-Contrast: It\nadaptively explores diverse solving perspectives tailored to the request,\ncontrasts the differences, and summarizes these discrepancies into a checklist\nwhich could be used to re-examine and eliminate discrepancies. Our method\nendows LLM with diverse perspectives to alleviate stubborn biases. Moreover,\ntheir discrepancies indicate potential errors or inherent uncertainties that\nLLM often overlooks. Reflecting upon these can catalyze more accurate and\nstable reflection. Experiments conducted on a series of reasoning and\ntranslation tasks with different LLMs serve to underscore the effectiveness and\ngenerality of our strategy.",
      "tldr_zh": "该研究揭示了Large Language Model (LLM) 在自我反思过程中，由于自我评估反馈的过度自信和高随机性，导致反思不稳定和效果差劲。针对此问题，论文提出Self-Contrast 方法，该方法自适应探索针对特定请求的多样解决视角，对这些视角进行对比，并将差异总结成检查列表，用于重新审视和消除不一致性。这种策略能缓解LLM 的顽固偏差，并通过反思差异来识别潜在错误，提高反思的准确性和稳定性。实验在多种推理和翻译任务上验证了Self-Contrast 的有效性和通用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2401.02009v3",
      "published_date": "2024-01-04 00:32:33 UTC",
      "updated_date": "2024-06-06 18:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:51:03.598151"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 58,
  "processed_papers_count": 58,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T19:51:32.450203"
}