{
  "date": "2025-04-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-26 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文聚焦于 AI 应用创新，特别是大型语言模型（LLM）的代理框架、AI 在医疗和机器人领域的扩展，以及强化学习优化，亮点包括 Markus J. Buehler 的多代理 AI 模型发现蛋白质设计新原则，以及 LLM 安全攻击方法的改进，这些工作展示了 AI 在科学发现和实际应用中的潜力。\n\n### 重点论文讨论\n我将优先讨论最具话题度和影响力的论文，包括 AI 安全、LLM 代理和医疗应用领域的研究。这些论文涉及核心贡献，如算法改进和实际影响。相关论文会放在一起简要分析，其他次要论文（如材料科学或优化算法）则快速掠过，只提核心点。\n\n#### AI 和 LLM 相关：焦点在代理框架和安全增强\n这些论文探讨了 LLM 的扩展和安全问题，突出了代理系统的潜力，但也暴露了风险。\n- **Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs（Graph of Attacks: 改进的黑盒和可解释 LLM 越狱攻击）**  \n  作者：Mohammad Akbar-Tajari 等。  \n  主要贡献：提出 Graph of Attacks (GoAT) 框架，使用图结构优化黑盒攻击，生成更有效的 LLM 越狱提示，能在少量查询下提高成功率达 5 倍，同时保持提示的可读性。发现：提升了 LLM 安全评估的效率，但也强调了模型易受协同攻击的脆弱性。\n  \n- **Sparks: Multi-Agent Artificial Intelligence Model Discovers Protein Design Principles（Sparks: 多代理 AI 模型发现蛋白质设计原则）**  \n  作者：Alireza Ghafarollahi, Markus J. Buehler（知名学者 Buehler 参与）。  \n  主要贡献：开发 Sparks 多模态多代理框架，实现自主假设生成、实验设计和迭代优化，无需人工干预。发现：揭示了蛋白质力学新现象，如 β-折叠肽在特定长度下优于 α-螺旋，并创建了二级结构稳定性图，为蛋白质设计提供新原则。\n\n- **Generative to Agentic AI: Survey, Conceptualization, and Challenges（从生成式到代理式 AI: 调查、概念化和挑战）**  \n  作者：Johannes Schneider。  \n  主要贡献：对比生成式 AI 和代理式 AI，分析代理系统的推理和交互优势，并提出研究议程。发现：代理式 AI 在处理复杂任务时更高效，但面临信任和可扩展性挑战。\n\n这些工作 collectively 推动了 LLM 从生成向代理演进，Buehler 的论文特别引人注目，因为它展示了 AI 在生物科学中的自主发现潜力。其他如 LawFlow（模拟律师思考过程）则快速提一下：它构建了基于 LLM 的法律工作流数据集，提高了任务的自适应性，但细节较 nich。\n\n#### 医疗 AI 应用：提升诊断和设备性能\n医疗领域的论文强调 AI 在实际场景中的鲁棒性，相关工作显示了 AI 在处理不确定性和多模态数据时的进展。\n- **Enhancing Cochlear Implant Signal Coding with Scaled Dot-Product Attention（使用缩放点积注意力增强耳蜗植入信号编码）**  \n  作者：Billel Essaid 等。  \n  主要贡献：引入深度学习模型生成耳蜗植入的电图，使用注意力机制改善信号处理。发现：模型的 STOI 分数达 0.6031，与传统 ACE 策略（0.6126）相当，但提供了更好的灵活性和个性化。\n\n- **Surgeons vs. Computer Vision: A comparative analysis on surgical phase recognition capabilities（外科医生 vs. 计算机视觉: 手术阶段识别能力的比较分析）**  \n  作者：Marco Mezzina 等。  \n  主要贡献：比较人类和 AI 在机器人辅助肾部分切除术中的阶段识别，AI 模型通过时间上下文提升准确性。发现：AI 与专家性能相当，尤其在提供时间信息时，强调了工具和器官作为关键特征。\n\n- **Clinical knowledge in LLMs does not translate to human interactions（LLM 中的临床知识不直接转化为人类交互）**  \n  作者：Andrew M. Bean 等。  \n  主要贡献：测试 LLM 在医疗场景中的用户交互，发现尽管 LLM 单独表现准确（识别症状率 94.9%），但在人类辅助下准确率降至 34.5%，暴露了交互局限。发现：呼吁更多用户测试以提升 LLM 在医疗中的可靠性。\n\n这些论文突出了 AI 在医疗的实际价值，如注意力机制的创新，但也警告了从模型到真实应用的鸿沟，相关工作如 Video CLIP Model（用于心脏超声视频解释）则显示了多视图输入的潜力。\n\n#### 机器人和强化学习：优化控制和效率\n这些论文关注自主系统的改进，强调强化学习在动态环境中的应用。\n- **VISUALCENT: Visual Human Analysis using Dynamic Centroid Representation（VISUALCENT: 使用动态质心表示的视觉人体分析）**  \n  作者：Niaz Ahmad 等。  \n  主要贡献：提出统一框架结合质心检测和实例分割，提高多人姿势分析的准确性和实时性。发现：在 COCO 数据集上，mAP 分数和帧率均优于现有方法。\n\n- **Imitation Learning for Autonomous Driving: Insights from Real-World Testing（模仿学习在自动驾驶中的应用: 来自真实测试的洞见）**  \n  作者：Hidayet Ersin Dursun 等。  \n  主要贡献：使用 CNN-LSTM 等模型进行端到端学习，基于真实 MIT Racecar 测试优化转向控制。发现：CNN-LSTM 在复杂场景下表现最佳，强调迭代设计的重要性。\n\n其他如 Hierarchical Reinforcement Learning（在空间导航中的应用）快速提一下：它通过分层方法提升了强化学习的效率，但整体影响较局限于特定领域。\n\n### 其他快速掠过\n今天还有一些论文涉及材料科学（如 Two-Phase Random Materials 的应力预测）和优化算法（如 Brain Drain Optimization），但这些相对 niche，仅快速提及：它们提供了新方法如物理信息嵌入提升预测准确性（F1-score >80%），但对一般读者吸引力有限。\n\n总之，今天的 arXiv 更新展示了 AI 的多面性，从 LLM 代理的创新到医疗应用的稳健性，值得关注领域从业者跟进。感谢阅读，欢迎明天再来！",
  "papers": [
    {
      "arxiv_id": "2504.19047v1",
      "title": "AI Recommendations and Non-instrumental Image Concerns",
      "title_zh": "翻译失败",
      "authors": [
        "David Almog"
      ],
      "abstract": "There is growing enthusiasm about the potential for humans and AI to\ncollaborate by leveraging their respective strengths. Yet in practice, this\npromise often falls short. This paper uses an online experiment to identify\nnon-instrumental image concerns as a key reason individuals underutilize AI\nrecommendations. I show that concerns about how one is perceived, even when\nthose perceptions carry no monetary consequences, lead participants to\ndisregard AI advice and reduce task performance.",
      "tldr_zh": "这篇论文探讨了人类在利用AI推荐时的问题，强调非工具性形象担忧(non-instrumental image concerns)是导致低利用率的主要原因，即使这些担忧不涉及金钱后果。作者通过在线实验证明，人们出于对他人感知的顾虑而忽略AI建议，从而降低了任务表现。总体而言，该研究揭示了AI与人类合作面临的心理障碍，并为改善AI应用提供了新见解。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.HC",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19047v1",
      "published_date": "2025-04-26 22:52:33 UTC",
      "updated_date": "2025-04-26 22:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:52:38.570361"
    },
    {
      "arxiv_id": "2504.19046v1",
      "title": "Enhancing Cochlear Implant Signal Coding with Scaled Dot-Product Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Billel Essaid",
        "Hamza Kheddar",
        "Noureddine Batel"
      ],
      "abstract": "Cochlear implants (CIs) play a vital role in restoring hearing for\nindividuals with severe to profound sensorineural hearing loss by directly\nstimulating the auditory nerve with electrical signals. While traditional\ncoding strategies, such as the advanced combination encoder (ACE), have proven\neffective, they are constrained by their adaptability and precision. This paper\ninvestigates the use of deep learning (DL) techniques to generate\nelectrodograms for CIs, presenting our model as an advanced alternative. We\ncompared the performance of our model with the ACE strategy by evaluating the\nintelligibility of reconstructed audio signals using the short-time objective\nintelligibility (STOI) metric. The results indicate that our model achieves a\nSTOI score of 0.6031, closely approximating the 0.6126 score of the ACE\nstrategy, and offers potential advantages in flexibility and adaptability. This\nstudy underscores the benefits of incorporating artificial intelligent (AI)\ninto CI technology, such as enhanced personalization and efficiency.",
      "tldr_zh": "本研究旨在通过Scaled Dot-Product Attention增强人工耳蜗（Cochlear implants, CIs）的信号编码策略，以改善对重度感音神经性听力损失患者的听力恢复。论文提出了一种基于深度学习（deep learning, DL）技术的模型，用于生成电图（electrodograms），并与传统高级组合编码器（advanced combination encoder, ACE）策略进行比较。结果显示，该模型的短时客观清晰度（STOI）分数为0.6031，接近ACE的0.6126，同时提供了更高的灵活性和适应性，突显了AI整合在提升CI个性化与效率方面的潜力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19046v1",
      "published_date": "2025-04-26 22:49:08 UTC",
      "updated_date": "2025-04-26 22:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:52:51.990600"
    },
    {
      "arxiv_id": "2504.19042v1",
      "title": "Generative Models for Fast Simulation of Cherenkov Detectors at the Electron-Ion Collider",
      "title_zh": "翻译失败",
      "authors": [
        "James Giroux",
        "Michael Martinez",
        "Cristiano Fanelli"
      ],
      "abstract": "The integration of Deep Learning (DL) into experimental nuclear and particle\nphysics has driven significant progress in simulation and reconstruction\nworkflows. However, traditional simulation frameworks such as Geant4 remain\ncomputationally intensive, especially for Cherenkov detectors, where simulating\noptical photon transport through complex geometries and reflective surfaces\nintroduces a major bottleneck. To address this, we present an open, standalone\nfast simulation tool for Detection of Internally Reflected Cherenkov Light\n(DIRC) detectors, with a focus on the High-Performance DIRC (hpDIRC) at the\nfuture Electron-Ion Collider (EIC). Our framework incorporates a suite of\ngenerative models tailored to accelerate particle identification (PID) tasks by\noffering a scalable, GPU-accelerated alternative to full Geant4-based\nsimulations. Designed with accessibility in mind, our simulation package\nenables both DL researchers and physicists to efficiently generate\nhigh-fidelity large-scale datasets on demand, without relying on complex\ntraditional simulation stacks. This flexibility supports the development and\nbenchmarking of novel DL-driven PID methods. Moreover, this fast simulation\npipeline represents a critical step toward enabling EIC-wide PID strategies\nthat depend on virtually unlimited simulated samples, spanning the full\nacceptance of the hpDIRC.",
      "tldr_zh": "本研究针对核和粒子物理实验中的模拟瓶颈，提出了一种基于生成模型（generative models）的快速模拟工具，用于模拟Cherenkov检测器，特别是未来Electron-Ion Collider (EIC)的High-Performance DIRC (hpDIRC)。该框架利用深度学习（Deep Learning, DL）技术，提供可扩展的GPU加速替代方案，显著减少了传统Geant4模拟中光学光子传输的计算密集问题。实验结果显示，该工具能高效生成高保真大规模数据集，支持粒子识别（PID）任务的开发和基准测试，并为EIC的全面PID策略奠定基础。",
      "categories": [
        "physics.ins-det",
        "cs.AI",
        "cs.LG",
        "hep-ex",
        "nucl-ex"
      ],
      "primary_category": "physics.ins-det",
      "comment": "45 pages, 27 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.19042v1",
      "published_date": "2025-04-26 22:33:08 UTC",
      "updated_date": "2025-04-26 22:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:53:03.905389"
    },
    {
      "arxiv_id": "2504.19040v1",
      "title": "Improved Molecular Generation through Attribute-Driven Integrative Embeddings and GAN Selectivity",
      "title_zh": "通过属性驱动的集成嵌入",
      "authors": [
        "Nandan Joshi",
        "Erhan Guven"
      ],
      "abstract": "The growing demand for molecules with tailored properties in fields such as\ndrug discovery and chemical engineering has driven advancements in\ncomputational methods for molecular design. Machine learning-based approaches\nfor de-novo molecular generation have recently garnered significant attention.\nThis paper introduces a transformer-based vector embedding generator combined\nwith a modified Generative Adversarial Network (GAN) to generate molecules with\ndesired properties. The embedding generator utilizes a novel molecular\ndescriptor, integrating Morgan fingerprints with global molecular attributes,\nenabling the transformer to capture local functional groups and broader\nmolecular characteristics. Modifying the GAN generator loss function ensures\nthe generation of molecules with specific desired properties. The transformer\nachieves a reconversion accuracy of 94% while translating molecular descriptors\nback to SMILES strings, validating the utility of the proposed embeddings for\ngenerative tasks. The approach is validated by generating novel odorant\nmolecules using a labeled dataset of odorant and non-odorant compounds. With\nthe modified range-loss function, the GAN exclusively generates odorant\nmolecules. This work underscores the potential of combining novel vector\nembeddings with transformers and modified GAN architectures to accelerate the\ndiscovery of tailored molecules, offering a robust tool for diverse molecular\ndesign applications.",
      "tldr_zh": "这篇论文提出了一种改进的分子生成方法，通过基于Transformer的向量嵌入生成器和修改后的GAN（Generative Adversarial Network），以生成具有特定属性的分子，如药物发现中的定制化合物。嵌入生成器整合了Morgan fingerprints和全局分子属性，允许Transformer捕捉局部功能群和整体分子特征，同时修改GAN的损失函数（如range-loss）确保只生成目标属性分子。实验结果显示，Transformer在将分子描述符转换回SMILES字符串时达到94%的准确率，并在使用标记数据集生成新型气味分子时表现出色。该方法证明了结合新型嵌入、Transformer和GAN架构的潜力，可加速分子设计应用的创新和发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19040v1",
      "published_date": "2025-04-26 22:15:25 UTC",
      "updated_date": "2025-04-26 22:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:53:16.160945"
    },
    {
      "arxiv_id": "2504.19032v1",
      "title": "VISUALCENT: Visual Human Analysis using Dynamic Centroid Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Niaz Ahmad",
        "Youngmoon Lee",
        "Guanghui Wang"
      ],
      "abstract": "We introduce VISUALCENT, a unified human pose and instance segmentation\nframework to address generalizability and scalability limitations to multi\nperson visual human analysis. VISUALCENT leverages centroid based bottom up\nkeypoint detection paradigm and uses Keypoint Heatmap incorporating Disk\nRepresentation and KeyCentroid to identify the optimal keypoint coordinates.\nFor the unified segmentation task, an explicit keypoint is defined as a dynamic\ncentroid called MaskCentroid to swiftly cluster pixels to specific human\ninstance during rapid changes in human body movement or significantly occluded\nenvironment. Experimental results on COCO and OCHuman datasets demonstrate\nVISUALCENTs accuracy and real time performance advantages, outperforming\nexisting methods in mAP scores and execution frame rate per second. The\nimplementation is available on the project page.",
      "tldr_zh": "我们引入了 VISUALCENT，一种统一的框架，用于多人体视觉分析中的姿势和实例分割，旨在解决泛化性和可扩展性问题。该框架采用基于质心的自下而上关键点检测方法，包括 Keypoint Heatmap incorporating Disk Representation 和 KeyCentroid 来精确识别关键点坐标；同时，使用动态质心 MaskCentroid 来快速聚类像素到特定人体实例，尤其适用于快速运动或严重遮挡的环境。在 COCO 和 OCHuman 数据集上的实验结果表明，VISUALCENT 在 mAP 分数和执行帧率上优于现有方法，实现准确且实时的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19032v1",
      "published_date": "2025-04-26 21:58:56 UTC",
      "updated_date": "2025-04-26 21:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:53:28.853046"
    },
    {
      "arxiv_id": "2504.19030v1",
      "title": "Improving Pretrained YAMNet for Enhanced Speech Command Detection via Transfer Learning",
      "title_zh": "通过迁移学习",
      "authors": [
        "Sidahmed Lachenani",
        "Hamza Kheddar",
        "Mohamed Ouldzmirli"
      ],
      "abstract": "This work addresses the need for enhanced accuracy and efficiency in speech\ncommand recognition systems, a critical component for improving user\ninteraction in various smart applications. Leveraging the robust pretrained\nYAMNet model and transfer learning, this study develops a method that\nsignificantly improves speech command recognition. We adapt and train a YAMNet\ndeep learning model to effectively detect and interpret speech commands from\naudio signals. Using the extensively annotated Speech Commands dataset\n(speech_commands_v0.01), our approach demonstrates the practical application of\ntransfer learning to accurately recognize a predefined set of speech commands.\nThe dataset is meticulously augmented, and features are strategically extracted\nto boost model performance. As a result, the final model achieved a recognition\naccuracy of 95.28%, underscoring the impact of advanced machine learning\ntechniques on speech command recognition. This achievement marks substantial\nprogress in audio processing technologies and establishes a new benchmark for\nfuture research in the field.",
      "tldr_zh": "该研究针对语音命令识别系统的准确性和效率问题，采用迁移学习（transfer learning）对预训练 YAMNet 模型进行改进，以更好地检测和解释音频信号中的语音命令。研究团队使用 Speech Commands 数据集（speech_commands_v0.01），通过数据增强和特征提取策略来优化模型训练，最终实现了95.28%的识别准确率。相比传统方法，这一成果显著提升了音频处理技术的性能，并为智能应用的用户交互和未来研究设立了新基准。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19030v1",
      "published_date": "2025-04-26 21:57:11 UTC",
      "updated_date": "2025-04-26 21:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:53:39.372221"
    },
    {
      "arxiv_id": "2504.19027v1",
      "title": "DiCE-Extended: A Robust Approach to Counterfactual Explanations in Machine Learning",
      "title_zh": "DiCE-Extended：一种针对机器学习的鲁棒反事实解释方法",
      "authors": [
        "Volkan Bakir",
        "Polat Goktas",
        "Sureyya Akyuz"
      ],
      "abstract": "Explainable artificial intelligence (XAI) has become increasingly important\nin decision-critical domains such as healthcare, finance, and law.\nCounterfactual (CF) explanations, a key approach in XAI, provide users with\nactionable insights by suggesting minimal modifications to input features that\nlead to different model outcomes. Despite significant advancements, existing CF\ngeneration methods often struggle to balance proximity, diversity, and\nrobustness, limiting their real-world applicability. A widely adopted\nframework, Diverse Counterfactual Explanations (DiCE), emphasizes diversity but\nlacks robustness, making CF explanations sensitive to perturbations and domain\nconstraints. To address these challenges, we introduce DiCE-Extended, an\nenhanced CF explanation framework that integrates multi-objective optimization\ntechniques to improve robustness while maintaining interpretability. Our\napproach introduces a novel robustness metric based on the Dice-Sorensen\ncoefficient, ensuring stability under small input variations. Additionally, we\nrefine CF generation using weighted loss components (lambda_p, lambda_d,\nlambda_r) to balance proximity, diversity, and robustness. We empirically\nvalidate DiCE-Extended on benchmark datasets (COMPAS, Lending Club, German\nCredit, Adult Income) across multiple ML backends (Scikit-learn, PyTorch,\nTensorFlow). Results demonstrate improved CF validity, stability, and alignment\nwith decision boundaries compared to standard DiCE-generated explanations. Our\nfindings highlight the potential of DiCE-Extended in generating more reliable\nand interpretable CFs for high-stakes applications. Future work will explore\nadaptive optimization techniques and domain-specific constraints to further\nenhance CF generation in real-world scenarios.",
      "tldr_zh": "该论文针对可解释人工智能 (XAI) 中的 Counterfactual (CF) 解释问题，提出 DiCE-Extended 框架，以解决现有方法在接近度 (proximity)、多样性 (diversity) 和鲁棒性 (robustness) 之间平衡的不足。DiCE-Extended 采用多目标优化技术，引入基于 Dice-Sorensen 系数的鲁棒性指标，并通过加权损失组件 (lambda_p, lambda_d, lambda_r) 来优化 CF 生成，确保解释在小输入变化下保持稳定。实验在基准数据集 (COMPAS, Lending Club, German Credit, Adult Income) 和多种机器学习后端 (Scikit-learn, PyTorch, TensorFlow) 上验证，结果显示 DiCE-Extended 显著提升了 CF 的有效性、稳定性和与决策边界的对齐，为高风险应用提供更可靠的解释。未来工作将进一步探索自适应优化技术和领域特定约束。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "I.2; K.4; H.4"
      ],
      "primary_category": "cs.AI",
      "comment": "MCO 2025, 5th International Conference on Modelling, Computation and\n  Optimization in Information Systems and Management Sciences",
      "pdf_url": "http://arxiv.org/pdf/2504.19027v1",
      "published_date": "2025-04-26 21:22:44 UTC",
      "updated_date": "2025-04-26 21:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:53:53.165730"
    },
    {
      "arxiv_id": "2504.19023v1",
      "title": "GLaMoR: Consistency Checking of OWL Ontologies using Graph Language Models",
      "title_zh": "GLaMoR: 利用图语言模型进行 OWL 本体一致性检查",
      "authors": [
        "Justin Mücke",
        "Ansgar Scherp"
      ],
      "abstract": "Semantic reasoning aims to infer new knowledge from existing knowledge, with\nOWL ontologies serving as a standardized framework for organizing information.\nA key challenge in semantic reasoning is verifying ontology consistency.\nHowever, state-of-the-art reasoners are computationally expensive, and their\nefficiency decreases as ontology sizes grow. While classical machine learning\nmodels have been explored for consistency checking, they struggle to capture\ncomplex relationships within ontologies. Large language models (LLMs) have\nshown promising results for simple reasoning tasks but perform poorly on\nstructured reasoning. The recently introduced Graph Language Model (GLM) offers\na way to simultaneously process graph-structured data and text. This paper\nproposes GLaMoR (Graph Language Model for Reasoning), a reasoning pipeline that\ntransforms OWL ontologies into graph-structured data and adapts the GLM\narchitecture for consistency checking. We evaluate GLaMoR on ontologies from\nthe NCBO BioPortal repository, converting them into triples suitable for model\ninput. Our results show that the GLM outperforms all baseline models, achieving\n$95\\%$ accuracy while being 20 times faster than classical reasoners.\n  The Code is accessible under: https://github.com/JustinMuecke/GLaMoR",
      "tldr_zh": "这篇论文提出 GLaMoR，一种基于 Graph Language Models (GLM) 的推理管道，用于检查 OWL Ontologies 的一致性，以解决传统推理器计算开销大和效率低的问题。GLaMoR 将 OWL 本体转化为图结构数据（如 triples），并结合 GLM 架构同时处理图数据和文本，从而更好地捕捉本体中的复杂关系。实验结果显示，在 NCBO BioPortal 仓库的本体上，GLaMoR 比基线模型表现更优，达到 95% 的准确率，同时比经典推理器快 20 倍。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19023v1",
      "published_date": "2025-04-26 21:20:29 UTC",
      "updated_date": "2025-04-26 21:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:54:04.366375"
    },
    {
      "arxiv_id": "2504.19021v1",
      "title": "Advancing Scientific Text Classification: Fine-Tuned Models with Dataset Expansion and Hard-Voting",
      "title_zh": "提升科学文本分类：微调模型结合数据集扩展和硬投票",
      "authors": [
        "Zhyar Rzgar K Rostam",
        "Gábor Kertész"
      ],
      "abstract": "Efficient text classification is essential for handling the increasing volume\nof academic publications. This study explores the use of pre-trained language\nmodels (PLMs), including BERT, SciBERT, BioBERT, and BlueBERT, fine-tuned on\nthe Web of Science (WoS-46985) dataset for scientific text classification. To\nenhance performance, we augment the dataset by executing seven targeted queries\nin the WoS database, retrieving 1,000 articles per category aligned with\nWoS-46985's main classes. PLMs predict labels for this unlabeled data, and a\nhard-voting strategy combines predictions for improved accuracy and confidence.\nFine-tuning on the expanded dataset with dynamic learning rates and early\nstopping significantly boosts classification accuracy, especially in\nspecialized domains. Domain-specific models like SciBERT and BioBERT\nconsistently outperform general-purpose models such as BERT. These findings\nunderscore the efficacy of dataset augmentation, inference-driven label\nprediction, hard-voting, and fine-tuning techniques in creating robust and\nscalable solutions for automated academic text classification.",
      "tldr_zh": "本研究探讨了使用预训练语言模型 (PLMs) 如 BERT、SciBERT、BioBERT 和 BlueBERT 对 Web of Science (WoS-46985) 数据集进行科学文本分类，通过数据集扩充和硬-voting 策略来提升性能。研究者通过执行七个针对性查询扩充数据集，并采用硬-voting 结合预测结果进行微调，辅以动态学习率和提前停止机制。结果显示，扩充数据集显著提高了分类准确率，领域特定模型如 SciBERT 和 BioBERT 优于通用模型 BERT，这些技术证明了在自动化学术文本分类中构建鲁棒、可扩展解决方案的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 1 figure, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.19021v1",
      "published_date": "2025-04-26 21:06:49 UTC",
      "updated_date": "2025-04-26 21:06:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:54:15.614067"
    },
    {
      "arxiv_id": "2504.19019v1",
      "title": "Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Akbar-Tajari",
        "Mohammad Taher Pilehvar",
        "Mohammad Mahmoody"
      ],
      "abstract": "The challenge of ensuring Large Language Models (LLMs) align with societal\nstandards is of increasing interest, as these models are still prone to\nadversarial jailbreaks that bypass their safety mechanisms. Identifying these\nvulnerabilities is crucial for enhancing the robustness of LLMs against such\nexploits. We propose Graph of ATtacks (GoAT), a method for generating\nadversarial prompts to test the robustness of LLM alignment using the Graph of\nThoughts framework [Besta et al., 2024]. GoAT excels at generating highly\neffective jailbreak prompts with fewer queries to the victim model than\nstate-of-the-art attacks, achieving up to five times better jailbreak success\nrate against robust models like Llama. Notably, GoAT creates high-quality,\nhuman-readable prompts without requiring access to the targeted model's\nparameters, making it a black-box attack. Unlike approaches constrained by\ntree-based reasoning, GoAT's reasoning is based on a more intricate graph\nstructure. By making simultaneous attack paths aware of each other's progress,\nthis dynamic framework allows a deeper integration and refinement of reasoning\npaths, significantly enhancing the collaborative exploration of adversarial\nvulnerabilities in LLMs. At a technical level, GoAT starts with a graph\nstructure and iteratively refines it by combining and improving thoughts,\nenabling synergy between different thought paths. The code for our\nimplementation can be found at: https://github.com/GoAT-pydev/Graph_of_Attacks.",
      "tldr_zh": "该研究提出 Graph of Attacks (GoAT) 方法，利用 Graph of Thoughts 框架生成高效的对抗性提示，以测试和攻击 Large Language Models (LLMs) 的安全机制。GoAT 作为一种黑-box 攻击，不需访问模型参数，就能以更少的查询创建高质量、可解释的 jailbreak 提示，并在鲁棒模型如 Llama 上实现高达五倍的成功率提升。不同于树状推理，GoAT 通过图结构实现多个攻击路径的协作和迭代优化，深化了对 LLMs 漏洞的探索，为增强模型的鲁棒性提供了重要工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 1 figure, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.19019v1",
      "published_date": "2025-04-26 21:06:03 UTC",
      "updated_date": "2025-04-26 21:06:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:54:28.326608"
    },
    {
      "arxiv_id": "2504.19017v1",
      "title": "Sparks: Multi-Agent Artificial Intelligence Model Discovers Protein Design Principles",
      "title_zh": "Sparks: 多智能体人工智能模型发现蛋白质设计原则",
      "authors": [
        "Alireza Ghafarollahi",
        "Markus J. Buehler"
      ],
      "abstract": "Advances in artificial intelligence (AI) promise autonomous discovery, yet\nmost systems still resurface knowledge latent in their training data. We\npresent Sparks, a multi-modal multi-agent AI model that executes the entire\ndiscovery cycle that includes hypothesis generation, experiment design and\niterative refinement to develop generalizable principles and a report without\nhuman intervention. Applied to protein science, Sparks uncovered two previously\nunknown phenomena: (i) a length-dependent mechanical crossover whereby\nbeta-sheet-biased peptides surpass alpha-helical ones in unfolding force beyond\n~80 residues, establishing a new design principle for peptide mechanics; and\n(ii) a chain-length/secondary-structure stability map revealing unexpectedly\nrobust beta-sheet-rich architectures and a \"frustration zone\" of high variance\nin mixed alpha/beta folds. These findings emerged from fully self-directed\nreasoning cycles that combined generative sequence design, high-accuracy\nstructure prediction and physics-aware property models, with paired\ngeneration-and-reflection agents enforcing self-correction and reproducibility.\nThe key result is that Sparks can independently conduct rigorous scientific\ninquiry and identify previously unknown scientific principles.",
      "tldr_zh": "该研究介绍了Sparks，一种多模态多智能体AI模型，能够自主执行假设生成、实验设计和迭代优化，从而发现新的科学原则，而非简单重复训练数据。在蛋白科学应用中，Sparks发现了两个新现象：(i) 长度依赖的机械交叉，即beta-sheet-biased peptides在超过约80个残基时，其展开力surpasses alpha-helical ones，提供了一个新的肽力学设计原则；(ii) 一个链长/二级结构稳定性图，显示beta-sheet-rich architectures异常稳健，以及一个\"frustration zone\"在混合alpha/beta folds中高变异。这些发现通过结合生成序列设计、高精度结构预测、物理感知属性模型和自校正代理实现，证明了Sparks能独立进行严格的科学探究。",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cond-mat.soft",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19017v1",
      "published_date": "2025-04-26 20:43:28 UTC",
      "updated_date": "2025-04-26 20:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:54:41.230677"
    },
    {
      "arxiv_id": "2505.03769v1",
      "title": "The Influence of Text Variation on User Engagement in Cross-Platform Content Sharing",
      "title_zh": "翻译失败",
      "authors": [
        "Yibo Hu",
        "Yiqiao Jin",
        "Meng Ye",
        "Ajay Divakaran",
        "Srijan Kumar"
      ],
      "abstract": "In today's cross-platform social media landscape, understanding factors that\ndrive engagement for multimodal content, especially text paired with visuals,\nremains complex. This study investigates how rewriting Reddit post titles\nadapted from YouTube video titles affects user engagement. First, we build and\nanalyze a large dataset of Reddit posts sharing YouTube videos, revealing that\n21% of post titles are minimally modified. Statistical analysis demonstrates\nthat title rewrites measurably improve engagement. Second, we design a\ncontrolled, multi-phase experiment to rigorously isolate the effects of textual\nvariations by neutralizing confounding factors like video popularity, timing,\nand community norms. Comprehensive statistical tests reveal that effective\ntitle rewrites tend to feature emotional resonance, lexical richness, and\nalignment with community-specific norms. Lastly, pairwise ranking prediction\nexperiments using a fine-tuned BERT classifier achieves 74% accuracy,\nsignificantly outperforming near-random baselines, including GPT-4o. These\nresults validate that our controlled dataset effectively minimizes confounding\neffects, allowing advanced models to both learn and demonstrate the impact of\ntextual features on engagement. By bridging quantitative rigor with qualitative\ninsights, this study uncovers engagement dynamics and offers a robust framework\nfor future cross-platform, multimodal content strategies.",
      "tldr_zh": "这篇论文探讨了跨平台社交媒体中，文本变化（如重写Reddit帖子标题）对用户参与度的影响，特别是与视觉内容的结合。研究者构建了一个大型数据集，发现21%的Reddit帖子标题仅微调了YouTube视频标题，并通过统计分析和受控多阶段实验证明，重写标题能显著提升参与度，且有效特征包括情感共鸣、词汇丰富性和社区规范的契合。最终，使用fine-tuned BERT分类器的配对排名预测实验达到了74%的准确率，远超GPT-4o等基线模型，为未来的跨平台多模态内容策略提供了稳健框架。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03769v1",
      "published_date": "2025-04-26 20:38:28 UTC",
      "updated_date": "2025-04-26 20:38:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:54:53.421088"
    },
    {
      "arxiv_id": "2504.19013v3",
      "title": "$PINN - a Domain Decomposition Method for Bayesian Physics-Informed Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Júlia Vicens Figueres",
        "Juliette Vanderhaeghen",
        "Federica Bragone",
        "Kateryna Morozovska",
        "Khemraj Shukla"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) are a novel computational approach\nfor solving partial differential equations (PDEs) with noisy and sparse initial\nand boundary data. Although, efficient quantification of epistemic and\naleatoric uncertainties in big multi-scale problems remains challenging. We\npropose \\$PINN a novel method of computing global uncertainty in PDEs using a\nBayesian framework, by combining local Bayesian Physics-Informed Neural\nNetworks (BPINN) with domain decomposition. The solution continuity across\nsubdomains is obtained by imposing the flux continuity across the interface of\nneighboring subdomains. To demonstrate the effectiveness of \\$PINN, we conduct\na series of computational experiments on PDEs in 1D and 2D spatial domains.\nAlthough we have adopted conservative PINNs (cPINNs), the method can be\nseamlessly extended to other domain decomposition techniques. The results infer\nthat the proposed method recovers the global uncertainty by computing the local\nuncertainty exactly more efficiently as the uncertainty in each subdomain can\nbe computed concurrently. The robustness of \\$PINN is verified by adding\nuncorrelated random noise to the training data up to 15% and testing for\ndifferent domain sizes.",
      "tldr_zh": "本研究提出 $PINN 方法，一种结合域分解 (domain decomposition) 和 Bayesian Physics-Informed Neural Networks (BPINN) 的框架，用于高效计算偏微分方程 (PDEs) 的全局不确定性。$PINN 通过在子域界面施加通量连续性 (flux continuity) 确保解决方案的连续性，并允许并发计算每个子域的不确定性，从而提高计算效率。实验在 1D 和 2D 空间域上验证了该方法的有效性，即使在训练数据中添加高达 15% 的随机噪声时，$PINN 也能准确恢复全局不确定性，并可扩展到其他域分解技术。结果显示，$PINN 比传统方法更高效，为处理多尺度 PDE 问题提供了稳健的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "37 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.19013v3",
      "published_date": "2025-04-26 19:58:21 UTC",
      "updated_date": "2025-05-01 09:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:55:04.611673"
    },
    {
      "arxiv_id": "2504.20099v1",
      "title": "Decoding Latent Spaces: Assessing the Interpretability of Time Series Foundation Models for Visual Analytics",
      "title_zh": "翻译失败",
      "authors": [
        "Inmaculada Santamaria-Valenzuela",
        "Victor Rodriguez-Fernandez",
        "Javier Huertas-Tato",
        "Jong Hyuk Park",
        "David Camacho"
      ],
      "abstract": "The present study explores the interpretability of latent spaces produced by\ntime series foundation models, focusing on their potential for visual analysis\ntasks. Specifically, we evaluate the MOMENT family of models, a set of\ntransformer-based, pre-trained architectures for multivariate time series tasks\nsuch as: imputation, prediction, classification, and anomaly detection. We\nevaluate the capacity of these models on five datasets to capture the\nunderlying structures in time series data within their latent space projection\nand validate whether fine tuning improves the clarity of the resulting\nembedding spaces. Notable performance improvements in terms of loss reduction\nwere observed after fine tuning. Visual analysis shows limited improvement in\nthe interpretability of the embeddings, requiring further work. Results suggest\nthat, although Time Series Foundation Models such as MOMENT are robust, their\nlatent spaces may require additional methodological refinements to be\nadequately interpreted, such as alternative projection techniques, loss\nfunctions, or data preprocessing strategies. Despite the limitations of MOMENT,\nfoundation models supose a big reduction in execution time and so a great\nadvance for interactive visual analytics.",
      "tldr_zh": "本文研究评估了时间序列基础模型的潜在空间（latent spaces）在视觉分析任务中的可解释性，重点考察了基于 Transformer 的 MOMENT 模型家族在 imputation、prediction、classification 和 anomaly detection 等任务上的表现。研究在五个数据集上测试了这些模型捕捉底层数据结构的能力，并发现微调后损失显著减少，但嵌入空间的视觉可解释性改善有限。结果表明，虽然 MOMENT 等模型在执行时间上实现了巨大减少，支持交互式 visual analytics 的发展，但需通过替代投影技术（projection techniques）、损失函数（loss functions）或数据预处理策略进一步提升可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Currently under review at the International Journal of Interactive\n  Multimedia and Artificial Intelligence (IJIMAI)",
      "pdf_url": "http://arxiv.org/pdf/2504.20099v1",
      "published_date": "2025-04-26 17:24:41 UTC",
      "updated_date": "2025-04-26 17:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:55:16.709061"
    },
    {
      "arxiv_id": "2504.18961v1",
      "title": "Feature Fusion Revisited: Multimodal CTR Prediction for MMCTR Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Zhou"
      ],
      "abstract": "With the rapid advancement of Multimodal Large Language Models (MLLMs), an\nincreasing number of researchers are exploring their application in\nrecommendation systems. However, the high latency associated with large models\npresents a significant challenge for such use cases. The EReL@MIR workshop\nprovided a valuable opportunity to experiment with various approaches aimed at\nimproving the efficiency of multimodal representation learning for information\nretrieval tasks. As part of the competition's requirements, participants were\nmandated to submit a technical report detailing their methodologies and\nfindings. Our team was honored to receive the award for Task 2 - Winner\n(Multimodal CTR Prediction). In this technical report, we present our methods\nand key findings. Additionally, we propose several directions for future work,\nparticularly focusing on how to effectively integrate recommendation signals\ninto multimodal representations. The codebase for our implementation is\npublicly available at: https://github.com/Lattice-zjj/MMCTR_Code, and the\ntrained model weights can be accessed at:\nhttps://huggingface.co/FireFlyCourageous/MMCTR_DIN_MicroLens_1M_x1.",
      "tldr_zh": "该论文重新审视了特征融合（Feature Fusion），提出了一种针对 Multimodal CTR Prediction 的方法，旨在解决 Multimodal Large Language Models (MLLs) 在推荐系统中的高延迟问题。研究团队在 EReL@MIR 工作坊的 MMCTR Challenge Task 2 中获胜，通过实验验证了其多模态表示学习方法的效率改进，并公开了代码和模型权重。未来工作重点包括有效整合推荐信号到多模态表示中，以进一步提升系统性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "A technical report for the MMCTR Challenge held by EReL@MIR Workshop\n  at WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18961v1",
      "published_date": "2025-04-26 16:04:33 UTC",
      "updated_date": "2025-04-26 16:04:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:55:27.535345"
    },
    {
      "arxiv_id": "2504.18954v1",
      "title": "Surgeons vs. Computer Vision: A comparative analysis on surgical phase recognition capabilities",
      "title_zh": "外科医生 vs. 计算机视觉：手术阶段识别能力的比较分析",
      "authors": [
        "Marco Mezzina",
        "Pieter De Backer",
        "Tom Vercauteren",
        "Matthew Blaschko",
        "Alexandre Mottrie",
        "Tinne Tuytelaars"
      ],
      "abstract": "Purpose: Automated Surgical Phase Recognition (SPR) uses Artificial\nIntelligence (AI) to segment the surgical workflow into its key events,\nfunctioning as a building block for efficient video review, surgical education\nas well as skill assessment. Previous research has focused on short and linear\nsurgical procedures and has not explored if temporal context influences\nexperts' ability to better classify surgical phases. This research addresses\nthese gaps, focusing on Robot-Assisted Partial Nephrectomy (RAPN) as a highly\nnon-linear procedure. Methods: Urologists of varying expertise were grouped and\ntasked to indicate the surgical phase for RAPN on both single frames and video\nsnippets using a custom-made web platform. Participants reported their\nconfidence levels and the visual landmarks used in their decision-making. AI\narchitectures without and with temporal context as trained and benchmarked on\nthe Cholec80 dataset were subsequently trained on this RAPN dataset. Results:\nVideo snippets and presence of specific visual landmarks improved phase\nclassification accuracy across all groups. Surgeons displayed high confidence\nin their classifications and outperformed novices, who struggled discriminating\nphases. The performance of the AI models is comparable to the surgeons in the\nsurvey, with improvements when temporal context was incorporated in both cases.\nConclusion: SPR is an inherently complex task for expert surgeons and computer\nvision, where both perform equally well when given the same context.\nPerformance increases when temporal information is provided. Surgical tools and\norgans form the key landmarks for human interpretation and are expected to\nshape the future of automated SPR.",
      "tldr_zh": "这篇论文比较了外科医生和计算机视觉在Surgical Phase Recognition (SPR)中的表现，针对Robot-Assisted Partial Nephrectomy (RAPN)这种高度非线性手术程序。研究方法包括让不同经验水平的泌尿外科医生使用单帧和视频片段标识手术阶段，同时训练AI模型（有无temporal context）并进行基准测试。结果显示，视频片段和视觉landmarks（如手术工具和器官）显著提高了分类准确性，外科医生表现出高信心并优于新手，而AI模型的性能与外科医生相当，且temporal context能提升双方的表现。结论强调，SPR对人类和AI都是复杂任务，提供时间信息可改善准确性，并为未来的自动化SPR提供指导。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18954v1",
      "published_date": "2025-04-26 15:37:22 UTC",
      "updated_date": "2025-04-26 15:37:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:55:42.611246"
    },
    {
      "arxiv_id": "2504.18953v1",
      "title": "Application of the Brain Drain Optimization Algorithm to the N-Queens Problem",
      "title_zh": "Brain Drain Optimization Algorithm 在 N-Queens 问题的应用",
      "authors": [
        "Sahar Ramezani Jolfaei",
        "Sepehr Khodadadi Hossein Abadi"
      ],
      "abstract": "This paper introduces the application of the Brain Drain Optimization\nalgorithm -- a swarm-based metaheuristic inspired by the emigration of\nintellectual elites -- to the N-Queens problem. The N-Queens problem, a classic\ncombinatorial optimization problem, serves as a challenge for applying the\nBRADO. A designed cost function guides the search, and the configurations are\ntuned using a TOPSIS-based multicriteria decision making process. BRADO\nconsistently outperforms alternatives in terms of solution quality, achieving\nfewer threats and better objective function values. To assess BRADO's efficacy,\nit is benchmarked against several established metaheuristic algorithms,\nincluding Particle Swarm Optimization (PSO), Genetic Algorithm (GA),\nImperialist Competitive Algorithm (ICA), Iterated Local Search (ILS), and basic\nLocal Search (LS). The study highlights BRADO's potential as a general-purpose\nsolver for combinatorial problems, opening pathways for future applications in\nother domains of artificial intelligence.",
      "tldr_zh": "本研究将Brain Drain Optimization (BRADO)算法——一种受智力精英移民启发的群集元启发式算法——应用于经典的组合优化问题N-Queens问题。通过设计一个成本函数并采用基于TOPSIS的多标准决策过程，BRADO引导搜索并优化配置。实验结果显示，BRADO在解决方案质量上 consistently outperforms其他算法，如Particle Swarm Optimization (PSO)、Genetic Algorithm (GA)、Imperialist Competitive Algorithm (ICA)、Iterated Local Search (ILS)和基本Local Search (LS)，实现了更少的威胁和更好的目标函数值。该研究突出了BRADO作为通用组合问题求解器的潜力，为人工智能其他领域打开了应用途径。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18953v1",
      "published_date": "2025-04-26 15:32:17 UTC",
      "updated_date": "2025-04-26 15:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:55:52.722249"
    },
    {
      "arxiv_id": "2504.18948v1",
      "title": "Use of Metric Learning for the Recognition of Handwritten Digits, and its Application to Increase the Outreach of Voice-based Communication Platforms",
      "title_zh": "度量学习",
      "authors": [
        "Devesh Pant",
        "Dibyendu Talukder",
        "Deepak Kumar",
        "Rachit Pandey",
        "Aaditeshwar Seth",
        "Chetan Arora"
      ],
      "abstract": "Initiation, monitoring, and evaluation of development programmes can involve\nfield-based data collection about project activities. This data collection\nthrough digital devices may not always be feasible though, for reasons such as\nunaffordability of smartphones and tablets by field-based cadre, or shortfalls\nin their training and capacity building. Paper-based data collection has been\nargued to be more appropriate in several contexts, with automated digitization\nof the paper forms through OCR (Optical Character Recognition) and OMR (Optical\nMark Recognition) techniques. We contribute with providing a large dataset of\nhandwritten digits, and deep learning based models and methods built using this\ndata, that are effective in real-world environments. We demonstrate the\ndeployment of these tools in the context of a maternal and child health and\nnutrition awareness project, which uses IVR (Interactive Voice Response)\nsystems to provide awareness information to rural women SHG (Self Help Group)\nmembers in north India. Paper forms were used to collect phone numbers of the\nSHG members at scale, which were digitized using the OCR tools developed by us,\nand used to push almost 4 million phone calls. The data, model, and code have\nbeen released in the open-source domain.",
      "tldr_zh": "这篇论文探讨了使用 Metric Learning 技术来识别手写数字，并将其应用于发展项目的实地数据收集，以解决数字设备不可用或培训不足的问题。研究者提供了一个大型手写数字数据集，以及基于深度学习的模型和方法，这些工具通过 OCR (Optical Character Recognition) 和 OMR (Optical Mark Recognition) 技术实现了纸质表格的自动化数字化。论文展示了这些工具在印度北部一个母婴健康和营养意识项目的实际部署，使用 IVR (Interactive Voice Response) 系统数字化了海量电话号码，成功发送近 400 万通电话，并将数据、模型和代码开源以促进进一步应用。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "10 Pages, 7 Figures, ACM COMPASS 2022",
      "pdf_url": "http://arxiv.org/pdf/2504.18948v1",
      "published_date": "2025-04-26 15:14:47 UTC",
      "updated_date": "2025-04-26 15:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:56:04.898114"
    },
    {
      "arxiv_id": "2504.18943v1",
      "title": "GPU accelerated program synthesis: Enumerate semantics, not syntax!",
      "title_zh": "GPU 加速的程序合成：枚举语义，而非语法！",
      "authors": [
        "Martin Berger",
        "Nathanaël Fijalkow",
        "Mojtaba Valizadeh"
      ],
      "abstract": "Program synthesis is an umbrella term for generating programs and logical\nformulae from specifications. With the remarkable performance improvements that\nGPUs enable for deep learning, a natural question arose: can we also implement\na search-based program synthesiser on GPUs to achieve similar performance\nimprovements? In this article we discuss our insights on this question, based\non recent works~. The goal is to build a synthesiser running on GPUs which\ntakes as input positive and negative example traces and returns a logical\nformula accepting the positive and rejecting the negative traces. With\nGPU-friendly programming techniques -- using the semantics of formulae to\nminimise data movement and reduce data-dependent branching -- our synthesiser\nscales to significantly larger synthesis problems, and operates much faster\nthan the previous CPU-based state-of-the-art. We believe the insights that make\nour approach GPU-friendly have wide potential for enhancing the performance of\nother formal methods (FM) workloads.",
      "tldr_zh": "该论文探讨了使用 GPU 加速程序合成（program synthesis）的潜力，提出了一种基于枚举语义（enumerate semantics）而非语义的方法，以减少数据移动和数据依赖分支。研究开发了一个 GPU 友好的合成器，它从正负例迹（positive and negative example traces）中生成逻辑公式（logical formulae），并实现了比之前 CPU 版本更快的性能和更大的可扩展性。实验结果显示，该方法显著提升了合成问题的处理效率，并为其他形式方法（formal methods）工作负载提供了性能优化见解。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.LO",
        "68",
        "D.3"
      ],
      "primary_category": "cs.PL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.18943v1",
      "published_date": "2025-04-26 15:06:37 UTC",
      "updated_date": "2025-04-26 15:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:56:15.397979"
    },
    {
      "arxiv_id": "2504.18942v1",
      "title": "LawFlow : Collecting and Simulating Lawyers' Thought Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Debarati Das",
        "Khanh Chi Le",
        "Ritik Sachin Parkar",
        "Karin De Langis",
        "Brendan Madson",
        "Chad M. Berryman",
        "Robin M. Willis",
        "Daniel H. Moses",
        "Brett McDonnell",
        "Daniel Schwarcz",
        "Dongyeop Kang"
      ],
      "abstract": "Legal practitioners, particularly those early in their careers, face complex,\nhigh-stakes tasks that require adaptive, context-sensitive reasoning. While AI\nholds promise in supporting legal work, current datasets and models are\nnarrowly focused on isolated subtasks and fail to capture the end-to-end\ndecision-making required in real-world practice. To address this gap, we\nintroduce LawFlow, a dataset of complete end-to-end legal workflows collected\nfrom trained law students, grounded in real-world business entity formation\nscenarios. Unlike prior datasets focused on input-output pairs or linear chains\nof thought, LawFlow captures dynamic, modular, and iterative reasoning\nprocesses that reflect the ambiguity, revision, and client-adaptive strategies\nof legal practice. Using LawFlow, we compare human and LLM-generated workflows,\nrevealing systematic differences in structure, reasoning flexibility, and plan\nexecution. Human workflows tend to be modular and adaptive, while LLM workflows\nare more sequential, exhaustive, and less sensitive to downstream implications.\nOur findings also suggest that legal professionals prefer AI to carry out\nsupportive roles, such as brainstorming, identifying blind spots, and surfacing\nalternatives, rather than executing complex workflows end-to-end. Building on\nthese findings, we propose a set of design suggestions, rooted in empirical\nobservations, that align AI assistance with human goals of clarity,\ncompleteness, creativity, and efficiency, through hybrid planning, adaptive\nexecution, and decision-point support. Our results highlight both the current\nlimitations of LLMs in supporting complex legal workflows and opportunities for\ndeveloping more collaborative, reasoning-aware legal AI systems. All data and\ncode are available on our project page\n(https://minnesotanlp.github.io/LawFlow-website/).",
      "tldr_zh": "该研究针对法律从业者面临的复杂决策挑战，引入LawFlow数据集，该数据集从受训法学生收集的端到端法律工作流中，捕捉动态、模块化和迭代的推理过程，基于真实业务实体形成场景。研究比较了人类和LLM生成的工作流，发现人类工作流更具适应性和模块化，而LLM工作流更倾向于顺序和详尽，但对下游影响不敏感，且法律专业人士更青睐AI在脑力激荡、识别盲点和提供备选方案等支持角色。基于这些发现，论文提出设计建议，包括混合规划、适应性执行和决策点支持，以提升AI在法律领域的协作性和效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "submitted to COLM 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18942v1",
      "published_date": "2025-04-26 15:01:55 UTC",
      "updated_date": "2025-04-26 15:01:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:56:28.301265"
    },
    {
      "arxiv_id": "2504.18932v1",
      "title": "AI Chatbots for Mental Health: Values and Harms from Lived Experiences of Depression",
      "title_zh": "AI 聊天机器人",
      "authors": [
        "Dong Whi Yoo",
        "Jiayue Melissa Shi",
        "Violeta J. Rodriguez",
        "Koustuv Saha"
      ],
      "abstract": "Recent advancements in LLMs enable chatbots to interact with individuals on a\nrange of queries, including sensitive mental health contexts. Despite\nuncertainties about their effectiveness and reliability, the development of\nLLMs in these areas is growing, potentially leading to harms. To better\nidentify and mitigate these harms, it is critical to understand how the values\nof people with lived experiences relate to the harms. In this study, we\ndeveloped a technology probe, a GPT-4o based chatbot called Zenny, enabling\nparticipants to engage with depression self-management scenarios informed by\nprevious research. We used Zenny to interview 17 individuals with lived\nexperiences of depression. Our thematic analysis revealed key values:\ninformational support, emotional support, personalization, privacy, and crisis\nmanagement. This work explores the relationship between lived experience\nvalues, potential harms, and design recommendations for mental health AI\nchatbots, aiming to enhance self-management support while minimizing risks.",
      "tldr_zh": "本研究探讨了LLMs驱动的AI聊天机器人用于心理健康的潜在价值和危害，通过分析抑郁患者的生活经历。研究者开发了一个基于GPT-4o的技术探针——Zenny聊天机器人，并使用它采访了17名有抑郁经历的参与者，以模拟抑郁自管理场景。主题分析揭示了关键价值，包括informational support、emotional support、personalization、privacy和crisis management，并探讨了这些价值与潜在危害的关系。最终，该工作提供了设计推荐，以提升AI聊天机器人在心理健康领域的自管理支持，同时最小化风险。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18932v1",
      "published_date": "2025-04-26 14:17:25 UTC",
      "updated_date": "2025-04-26 14:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:56:41.072436"
    },
    {
      "arxiv_id": "2504.18931v1",
      "title": "Advanced Longitudinal Control and Collision Avoidance for High-Risk Edge Cases in Autonomous Driving",
      "title_zh": "针对自动驾驶中高风险边缘场景的先进纵向控制和碰撞避免",
      "authors": [
        "Dianwei Chen",
        "Yaobang Gong",
        "Xianfeng Yang"
      ],
      "abstract": "Advanced Driver Assistance Systems (ADAS) and Advanced Driving Systems (ADS)\nare key to improving road safety, yet most existing implementations focus\nprimarily on the vehicle ahead, neglecting the behavior of following vehicles.\nThis shortfall often leads to chain reaction collisions in high speed, densely\nspaced traffic particularly when a middle vehicle suddenly brakes and trailing\nvehicles cannot respond in time. To address this critical gap, we propose a\nnovel longitudinal control and collision avoidance algorithm that integrates\nadaptive cruising with emergency braking. Leveraging deep reinforcement\nlearning, our method simultaneously accounts for both leading and following\nvehicles. Through a data preprocessing framework that calibrates real-world\nsensor data, we enhance the robustness and reliability of the training process,\nensuring the learned policy can handle diverse driving conditions. In simulated\nhigh risk scenarios (e.g., emergency braking in dense traffic), the algorithm\neffectively prevents potential pile up collisions, even in situations involving\nheavy duty vehicles. Furthermore, in typical highway scenarios where three\nvehicles decelerate, the proposed DRL approach achieves a 99% success rate far\nsurpassing the standard Federal Highway Administration speed concepts guide,\nwhich reaches only 36.77% success under the same conditions.",
      "tldr_zh": "该研究针对自动驾驶系统（ADAS 和 ADS）在高速密集交通中的缺陷，提出了一种新型纵向控制和碰撞避免算法，该算法整合自适应巡航和紧急制动，同时考虑前车和后车行为，以防止连锁碰撞。\n通过深度强化学习（DRL）和数据预处理框架，该方法校准真实传感器数据，提高算法的鲁棒性和可靠性，适用于多样化的驾驶条件。\n实验结果显示，在模拟高风险场景（如紧急制动）中，该算法有效避免潜在碰撞，并在典型高速公路场景中实现99%的成功率，远超标准联邦公路管理局指南的36.77%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18931v1",
      "published_date": "2025-04-26 14:17:06 UTC",
      "updated_date": "2025-04-26 14:17:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:56:52.181116"
    },
    {
      "arxiv_id": "2505.00027v1",
      "title": "Extracting Abstraction Dimensions by Identifying Syntax Pattern from Texts",
      "title_zh": "通过识别文本中的语法模式提取抽象维度",
      "authors": [
        "Jian Zhou",
        "Jiazheng Li",
        "Sirui Zhuge",
        "Hai Zhuge"
      ],
      "abstract": "This paper proposed an approach to automatically discovering subject\ndimension, action dimension, object dimension and adverbial dimension from\ntexts to efficiently operate texts and support query in natural language. The\nhigh quality of trees guarantees that all subjects, actions, objects and\nadverbials and their subclass relations within texts can be represented. The\nindependency of trees ensures that there is no redundant representation between\ntrees. The expressiveness of trees ensures that the majority of sentences can\nbe accessed from each tree and the rest of sentences can be accessed from at\nleast one tree so that the tree-based search mechanism can support querying in\nnatural language. Experiments show that the average precision, recall and\nF1-score of the abstraction trees constructed by the subclass relations of\nsubject, action, object and adverbial are all greater than 80%. The application\nof the proposed approach to supporting query in natural language demonstrates\nthat different types of question patterns for querying subject or object have\nhigh coverage of texts, and searching multiple trees on subject, action, object\nand adverbial according to the question pattern can quickly reduce search space\nto locate target sentences, which can support precise operation on texts.",
      "tldr_zh": "本论文提出了一种通过识别语法模式（syntax pattern）从文本中自动提取主语维度（subject dimension）、动作维度（action dimension）、宾语维度（object dimension）和状语维度（adverbial dimension）的方法，以支持高效的文本操作和自然语言查询。所构建的抽象树（abstraction trees）确保了这些维度的完整表示、无冗余表达，并具备高表达性，从而覆盖大多数句子并辅助查询。实验结果显示，抽象树的精度、召回率和 F1-score 平均超过 80%，且在自然语言查询应用中，能快速缩小搜索空间，实现精确文本操作。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50 (Primary) 91F20 (Secondary)",
        "I.2.7; I.2.1"
      ],
      "primary_category": "cs.CL",
      "comment": "25pages, 3 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.00027v1",
      "published_date": "2025-04-26 14:04:45 UTC",
      "updated_date": "2025-04-26 14:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:57:03.922087"
    },
    {
      "arxiv_id": "2504.18929v1",
      "title": "Revisiting Transformers through the Lens of Low Entropy and Dynamic Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Ruifeng Ren",
        "Yong Liu"
      ],
      "abstract": "Compression has been a critical lens to understand the success of\nTransformers. In the past, we have typically taken the target distribution as a\ncriterion to evaluate a model's compression performance. Nevertheless,it often\nremains challenging to precisely assess how well the model achieves compression\nand to compare the information content of the learned distribution with that of\nthe target distribution during compression,as the target distribution is\ntypically unknown and entropy computation often incurs exponential cost. In\nthis work, we explore these issues under a controlled experimental setup. We\nfind that Transformers exhibit a unique inductive bias in data compression:\nbeyond approaching the target distribution, they tend to favor learning\nlower-entropy distributions, with this tendency becoming more pronounced as the\nmodel size increases. This preference prevents Transformers from perfectly\naligning with the target distribution, instead further compressing its\ninformation content. Furthermore, we show that the FFN module plays a critical\nrole in driving this bias. In addition, while models remove informational\nredundancy from data during compression, they also exhibit redundancy within\ntheir parameters, which enables compression and can be characterized through\ndynamic sparsity. However, the dynamic sparsity patterns in Transformers,\nparticularly in attention and FFN modules, demand further exploration. As for\nthis, we show that larger Transformers show stronger preferences for bypassing\nattention computations via residual connections and have lower proportion of\nactive neurons. Interestingly, we also find that training instability in larger\nmodels strongly correlates with sudden increases in dead neurons. Our work\ncontributes to a deeper understanding of Transformers from the lens of entropy\nand dynamic sparsity.",
      "tldr_zh": "本研究通过低熵和动态稀疏性的视角重新审视 Transformers 模型的压缩性能，发现 Transformers 不仅趋向于接近目标分布，还偏好学习低熵分布，这种倾向随模型规模增大而增强，导致信息内容进一步压缩，而 FFN module 在驱动这一偏差中发挥关键作用。实验显示，模型在移除数据冗余的同时，自身参数也存在冗余，可通过动态稀疏性表征；此外，较大模型更倾向于通过 residual connections 绕过注意力计算，并表现出较低比例的活跃神经元，与训练不稳定性（如死神经元突然增加）密切相关。该工作加深了对 Transformers 的理解，为模型优化提供新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18929v1",
      "published_date": "2025-04-26 14:02:07 UTC",
      "updated_date": "2025-04-26 14:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:57:16.382594"
    },
    {
      "arxiv_id": "2504.18919v1",
      "title": "Clinical knowledge in LLMs does not translate to human interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew M. Bean",
        "Rebecca Payne",
        "Guy Parsons",
        "Hannah Rose Kirk",
        "Juan Ciro",
        "Rafael Mosquera",
        "Sara Hincapié Monsalve",
        "Aruna S. Ekanayaka",
        "Lionel Tarassenko",
        "Luc Rocher",
        "Adam Mahdi"
      ],
      "abstract": "Global healthcare providers are exploring use of large language models (LLMs)\nto provide medical advice to the public. LLMs now achieve nearly perfect scores\non medical licensing exams, but this does not necessarily translate to accurate\nperformance in real-world settings. We tested if LLMs can assist members of the\npublic in identifying underlying conditions and choosing a course of action\n(disposition) in ten medical scenarios in a controlled study with 1,298\nparticipants. Participants were randomly assigned to receive assistance from an\nLLM (GPT-4o, Llama 3, Command R+) or a source of their choice (control). Tested\nalone, LLMs complete the scenarios accurately, correctly identifying conditions\nin 94.9% of cases and disposition in 56.3% on average. However, participants\nusing the same LLMs identified relevant conditions in less than 34.5% of cases\nand disposition in less than 44.2%, both no better than the control group. We\nidentify user interactions as a challenge to the deployment of LLMs for medical\nadvice. Standard benchmarks for medical knowledge and simulated patient\ninteractions do not predict the failures we find with human participants.\nMoving forward, we recommend systematic human user testing to evaluate\ninteractive capabilities prior to public deployments in healthcare.",
      "tldr_zh": "这篇论文研究发现，大型语言模型（LLMs）在医疗许可考试中表现出色（如近乎完美分数），但在实际人类互动中无法有效提供医疗建议。研究通过一项控制实验，涉及1,298名参与者，让他们使用LLMs（如GPT-4o、Llama 3和Command R+）或自行选择来源来处理十种医疗场景。结果显示，LLMs单独测试时能正确识别条件（94.9%）和处置（56.3%），但参与者使用时准确率降至识别条件不到34.5%和处置不到44.2%，与对照组无显著差异。作者强调，用户互动是LLMs在医疗领域的关键挑战，并推荐在公共部署前进行系统的人类用户测试。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "52 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18919v1",
      "published_date": "2025-04-26 13:32:49 UTC",
      "updated_date": "2025-04-26 13:32:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:57:28.929767"
    },
    {
      "arxiv_id": "2504.18916v2",
      "title": "UnifyFL: Enabling Decentralized Cross-Silo Federated Learning",
      "title_zh": "UnifyFL：实现去中心化跨孤岛联邦学习",
      "authors": [
        "Sarang S",
        "Druva Dhakshinamoorthy",
        "Aditya Shiva Sharma",
        "Yuvraj Singh Bhadauria",
        "Siddharth Chaitra Vivek",
        "Arihant Bansal",
        "Arnab K. Paul"
      ],
      "abstract": "Federated Learning (FL) is a decentralized machine learning (ML) paradigm in\nwhich models are trained on private data across several devices called clients\nand combined at a single node called an aggregator rather than aggregating the\ndata itself. Many organizations employ FL to have better privacy-aware\nML-driven decision-making capabilities. However, organizations often operate\nindependently rather than collaborate to enhance their FL capabilities due to\nthe lack of an effective mechanism for collaboration. The challenge lies in\nbalancing trust and resource efficiency. One approach relies on trusting a\nthird-party aggregator to consolidate models from all organizations (multilevel\nFL), but this requires trusting an entity that may be biased or unreliable.\nAlternatively, organizations can bypass a third party by sharing their local\nmodels directly, which requires significant computational resources for\nvalidation. Both approaches reflect a fundamental trade-off between trust and\nresource constraints, with neither offering an ideal solution. In this work, we\ndevelop a trust-based cross-silo FL framework called UnifyFL, which uses\ndecentralized orchestration and distributed storage. UnifyFL provides\nflexibility to the participating organizations and presents synchronous and\nasynchronous modes to handle stragglers. Our evaluation on a diverse testbed\nshows that UnifyFL achieves a performance comparable to the ideal multilevel\ncentralized FL while allowing trust and optimal use of resources.",
      "tldr_zh": "联邦学习 (FL) 是一种分布式机器学习范式，通过在客户端训练模型并在聚合器合并来保护数据隐私，但组织间协作往往受信任和资源效率的制约。论文提出 UnifyFL 框架，利用去中心化编排和分布式存储，允许组织灵活参与，并提供同步和异步模式来处理延迟问题。该框架在多样化测试床上实现了与理想多级集中式 FL 相当的性能，同时优化了信任机制和资源利用。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "12 pages, 7 figures, 7 tables. Accepted at the 26th ACM/IFIP\n  International Middleware Conference (MIDDLEWARE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.18916v2",
      "published_date": "2025-04-26 13:15:40 UTC",
      "updated_date": "2025-05-06 03:37:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:57:40.068006"
    },
    {
      "arxiv_id": "2504.18910v1",
      "title": "Kinship Verification through a Forest Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Nazari",
        "Mohsen Ebrahimi Moghaddam",
        "Omidreza Borzoei"
      ],
      "abstract": "Early methods used face representations in kinship verification, which are\nless accurate than joint representations of parents' and children's facial\nimages learned from scratch. We propose an approach featuring graph neural\nnetwork concepts to utilize face representations and have comparable results to\njoint representation algorithms. Moreover, we designed the structure of the\nclassification module and introduced a new combination of losses to engage the\ncenter loss gradually in training our network. Additionally, we conducted\nexperiments on KinFaceW-I and II, demonstrating the effectiveness of our\napproach. We achieved the best result on KinFaceW-II, an average improvement of\nnearly 1.6 for all kinship types, and we were near the best on KinFaceW-I. The\ncode is available at https://github.com/ali-nazari/Kinship-Verification",
      "tldr_zh": "这篇论文提出了一种基于 Graph Neural Network 概念的亲缘验证方法，利用面部表示来实现与联合表示算法相当的性能，解决了早期方法准确性不足的问题。作者设计了分类模块的结构，并引入了一种新的损失组合，使 center loss 逐渐参与网络训练，以提升模型效果。在 KinFaceW-I 和 II 数据集上的实验表明，该方法在 KinFaceW-II 上所有亲缘类型平均提高了约 1.6%，在 KinFaceW-I 上接近最佳结果。代码已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18910v1",
      "published_date": "2025-04-26 12:50:12 UTC",
      "updated_date": "2025-04-26 12:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:57:53.988462"
    },
    {
      "arxiv_id": "2504.18902v1",
      "title": "Transformer-Empowered Actor-Critic Reinforcement Learning for Sequence-Aware Service Function Chain Partitioning",
      "title_zh": "翻译失败",
      "authors": [
        "Cyril Shih-Huan Hsu",
        "Anestis Dalgkitsis",
        "Chrysa Papagianni",
        "Paola Grosso"
      ],
      "abstract": "In the forthcoming era of 6G networks, characterized by unprecedented data\nrates, ultra-low latency, and extensive connectivity, effective management of\nVirtualized Network Functions (VNFs) is essential. VNFs are software-based\ncounterparts of traditional hardware devices that facilitate flexible and\nscalable service provisioning. Service Function Chains (SFCs), structured as\nordered sequences of VNFs, are pivotal in orchestrating complex network\nservices. Nevertheless, partitioning SFCs across multi-domain network\ninfrastructures presents substantial challenges due to stringent latency\nconstraints and limited resource availability. Conventional optimization-based\nmethods typically exhibit low scalability, whereas existing data-driven\napproaches often fail to adequately balance computational efficiency with the\ncapability to effectively account for dependencies inherent in SFCs. To\novercome these limitations, we introduce a Transformer-empowered actor-critic\nframework specifically designed for sequence-aware SFC partitioning. By\nutilizing the self-attention mechanism, our approach effectively models complex\ninter-dependencies among VNFs, facilitating coordinated and parallelized\ndecision-making processes. Additionally, we enhance training stability and\nconvergence using $\\epsilon$-LoPe exploration strategy as well as Asymptotic\nReturn Normalization. Comprehensive simulation results demonstrate that the\nproposed methodology outperforms existing state-of-the-art solutions in terms\nof long-term acceptance rates, resource utilization efficiency, and\nscalability, while achieving rapid inference. This study not only advances\nintelligent network orchestration by delivering a scalable and robust solution\nfor SFC partitioning within emerging 6G environments, but also bridging recent\nadvancements in Large Language Models (LLMs) with the optimization of\nnext-generation networks.",
      "tldr_zh": "本研究针对6G网络中Service Function Chains (SFCs)的分区问题，提出了一种基于Transformer增强的actor-critic强化学习框架，以有效处理SFCs的序列依赖和资源约束。框架利用self-attention机制建模VNFs间的复杂互依赖，支持协调并行决策，同时通过ε-LoPe探索策略和Asymptotic Return Normalization提升训练稳定性和收敛速度。实验模拟结果显示，该方法在长期接受率、资源利用效率和可扩展性上优于现有方案，并实现快速推理。该创新不仅为6G网络的智能编排提供可扩展解决方案，还桥接Large Language Models (LLMs)与下一代网络优化。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18902v1",
      "published_date": "2025-04-26 12:18:57 UTC",
      "updated_date": "2025-04-26 12:18:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:58:05.464144"
    },
    {
      "arxiv_id": "2504.18886v1",
      "title": "Exploiting Multiple Representations: 3D Face Biometrics Fusion with Application to Surveillance",
      "title_zh": "翻译失败",
      "authors": [
        "Simone Maurizio La Cava",
        "Roberto Casula",
        "Sara Concas",
        "Giulia Orrù",
        "Ruben Tolosana",
        "Martin Drahansky",
        "Julian Fierrez",
        "Gian Luca Marcialis"
      ],
      "abstract": "3D face reconstruction (3DFR) algorithms are based on specific assumptions\ntailored to the limits and characteristics of the different application\nscenarios. In this study, we investigate how multiple state-of-the-art 3DFR\nalgorithms can be used to generate a better representation of subjects, with\nthe final goal of improving the performance of face recognition systems in\nchallenging uncontrolled scenarios. We also explore how different parametric\nand non-parametric score-level fusion methods can exploit the unique strengths\nof multiple 3DFR algorithms to enhance biometric recognition robustness. With\nthis goal, we propose a comprehensive analysis of several face recognition\nsystems across diverse conditions, such as varying distances and camera setups,\nintra-dataset and cross-dataset, to assess the robustness of the proposed\nensemble method. The results demonstrate that the distinct information provided\nby different 3DFR algorithms can alleviate the problem of generalizing over\nmultiple application scenarios. In addition, the present study highlights the\npotential of advanced fusion strategies to enhance the reliability of\n3DFR-based face recognition systems, providing the research community with key\ninsights to exploit them in real-world applications effectively. Although the\nexperiments are carried out in a specific face verification setup, our proposed\nfusion-based 3DFR methods may be applied to other tasks around face biometrics\nthat are not strictly related to identity recognition.",
      "tldr_zh": "本文研究如何利用多个先进的 3D Face Reconstruction (3DFR) 算法生成更优的面部表示，以提升面部识别系统的性能，尤其在不受控场景中。作者探讨了参数化和非参数化的 score-level fusion 方法，融合各算法的独特优势，并通过全面实验分析（如不同距离、相机设置、intra-dataset 和 cross-dataset 测试）评估其鲁棒性。结果表明，这种 ensemble 方法能缓解多场景泛化问题，提高 3DFR 基于的识别系统可靠性，并为真实世界应用如监控提供关键见解，可扩展到其他面部生物特征任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18886v1",
      "published_date": "2025-04-26 10:21:46 UTC",
      "updated_date": "2025-04-26 10:21:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:58:17.750195"
    },
    {
      "arxiv_id": "2505.00026v1",
      "title": "Theory of Mind in Large Language Models: Assessment and Enhancement",
      "title_zh": "大型语言模型中的心智理论：评估与增强",
      "authors": [
        "Ruirui Chen",
        "Weifeng Jiang",
        "Chengwei Qin",
        "Cheston Tan"
      ],
      "abstract": "Theory of Mind (ToM)-the ability to infer and reason about others' mental\nstates-is fundamental to human social intelligence. As Large Language Models\n(LLMs) become increasingly integrated into daily life, it is crucial to assess\nand enhance their capacity to interpret and respond to human mental states. In\nthis paper, we review LLMs' ToM capabilities by examining both evaluation\nbenchmarks and the strategies designed to improve them. We focus on widely\nadopted story-based benchmarks and provide an in-depth analysis of methods\naimed at enhancing ToM in LLMs. Furthermore, we outline promising future\nresearch directions informed by recent benchmarks and state-of-the-art\napproaches. Our survey serves as a valuable resource for researchers interested\nin advancing LLMs' ToM capabilities.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在 Theory of Mind (ToM) 方面的能力，即推断和推理他人心理状态的核心社会智能要素。作者审视了现有的评估基准（如故事-based 基准）和提升策略，分析了如何改进 LLMs 在解释人类心理状态时的表现。论文总结了未来研究方向，并为相关领域的研究人员提供了宝贵资源，以推动 LLMs 的 ToM 能力发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00026v1",
      "published_date": "2025-04-26 10:17:48 UTC",
      "updated_date": "2025-04-26 10:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:58:28.125779"
    },
    {
      "arxiv_id": "2504.18884v2",
      "title": "A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Junichiro Niimi"
      ],
      "abstract": "With the advance of large language models (LLMs), LLMs have been utilized for\nthe various tasks. However, the issues of variability and reproducibility of\nresults from each trial of LLMs have been largely overlooked in existing\nliterature while actual human annotation uses majority voting to resolve\ndisagreements among annotators. Therefore, this study introduces the\nstraightforward ensemble strategy to a sentiment analysis using LLMs. As the\nresults, we demonstrate that the ensemble of multiple inference using\nmedium-sized LLMs produces more robust and accurate results than using a large\nmodel with a single attempt with reducing RMSE by 18.6%.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在任务中的变异性和再现性问题，提出了一种简单的集成策略（ensemble strategy），旨在提升文本分类的稳定性，特别是应用于情感分析。方法通过多次推理的集成，使用中型 LLMs 生成更可靠的结果，以解决人类标注中常见的投票分歧问题。实验结果显示，这种策略比使用单个大型模型的单次尝试降低了 RMSE 18.6%，从而提高了整体准确性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This manuscript has been accepted for the 30th International\n  Conference on Natural Language \\& Information Systems (NLDB 2025) and will\n  appear in Springer Lecture Notes in Computer Science (LNCS)",
      "pdf_url": "http://arxiv.org/pdf/2504.18884v2",
      "published_date": "2025-04-26 10:10:26 UTC",
      "updated_date": "2025-05-07 11:31:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:58:39.493103"
    },
    {
      "arxiv_id": "2504.18882v1",
      "title": "SPD Learning for Covariance-Based Neuroimaging Analysis: Perspectives, Methods, and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Ce Ju",
        "Reinmar J. Kobler",
        "Antoine Collas",
        "Motoaki Kawanabe",
        "Cuntai Guan",
        "Bertrand Thirion"
      ],
      "abstract": "Neuroimaging provides a critical framework for characterizing brain activity\nby quantifying connectivity patterns and functional architecture across\nmodalities. While modern machine learning has significantly advanced our\nunderstanding of neural processing mechanisms through these datasets, decoding\ntask-specific signatures must contend with inherent neuroimaging constraints,\nfor example, low signal-to-noise ratios in raw electrophysiological recordings,\ncross-session non-stationarity, and limited sample sizes. This review focuses\non machine learning approaches for covariance-based neuroimaging data, where\noften symmetric positive definite (SPD) matrices under full-rank conditions\nencode inter-channel relationships. By equipping the space of SPD matrices with\nRiemannian metrics (e.g., affine-invariant or log-Euclidean), their space forms\na Riemannian manifold enabling geometric analysis. We unify methodologies\noperating on this manifold under the SPD learning framework, which\nsystematically leverages the SPD manifold's geometry to process covariance\nfeatures, thereby advancing brain imaging analytics.",
      "tldr_zh": "这篇综述探讨了基于协方差的神经影像学分析，聚焦于机器学习方法来处理脑部活动和连接模式的量化问题，包括低信噪比、跨会话非平稳性以及样本大小有限等挑战。论文引入 SPD learning 框架，将对称正定 (SPD) 矩阵视为 Riemannian manifold，通过如 affine-invariant 或 log-Euclidean 度量来利用其几何特性，统一处理协方差特征。最终，该框架提升了脑部影像分析的准确性和效率，为神经科学研究提供了新的视角和方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV",
        "q-bio.NC",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 3 figures, 2 tables; This paper has been submitted for\n  possible publication, and currently under review",
      "pdf_url": "http://arxiv.org/pdf/2504.18882v1",
      "published_date": "2025-04-26 10:05:04 UTC",
      "updated_date": "2025-04-26 10:05:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:58:52.719275"
    },
    {
      "arxiv_id": "2504.18880v1",
      "title": "Reshaping MOFs Text Mining with a Dynamic Multi-Agent Framework of Large Language Agents",
      "title_zh": "通过",
      "authors": [
        "Zuhong Lin",
        "Daoyuan Ren",
        "Kai Ran",
        "Sun Jing",
        "Xiaotiang Huang",
        "Haiyang He",
        "Pengxu Pan",
        "Xiaohang Zhang",
        "Ying Fang",
        "Tianying Wang",
        "Minli Wu",
        "Zhanglin Li",
        "Xiaochuan Zhang",
        "Haipu Li",
        "Jingjing Yao"
      ],
      "abstract": "The mining of synthesis conditions for metal-organic frameworks (MOFs) is a\nsignificant focus in materials science. However, identifying the precise\nsynthesis conditions for specific MOFs within the vast array of possibilities\npresents a considerable challenge. Large Language Models (LLMs) offer a\npromising solution to this problem. We leveraged the capabilities of LLMs,\nspecifically gpt-4o-mini, as core agents to integrate various MOF-related\nagents, including synthesis, attribute, and chemical information agents. This\nintegration culminated in the development of MOFh6, an LLM tool designed to\nstreamline the MOF synthesis process. MOFh6 allows users to query in multiple\nformats, such as submitting scientific literature, or inquiring about specific\nMOF codes or structural properties. The tool analyzes these queries to provide\noptimal synthesis conditions and generates model files for density functional\ntheory pre modeling. We believe MOFh6 will enhance efficiency in the MOF\nsynthesis of all researchers.",
      "tldr_zh": "该论文提出了一种动态多代理框架，利用大型语言模型（LLMs，如 gpt-4o-mini）作为核心代理，整合合成、属性和化学信息代理，以重塑金属有机框架（MOFs）的文本挖掘过程。框架开发的 MOFh6 工具支持多种查询格式，包括提交科学文献或查询特定 MOF 代码和结构属性，能够分析查询并提供最佳合成条件，同时生成用于 density functional theory 预建模的模型文件。通过这一创新方法，研究人员有望显著提高 MOFs 合成的效率和准确性。",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18880v1",
      "published_date": "2025-04-26 09:55:04 UTC",
      "updated_date": "2025-04-26 09:55:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:59:05.425009"
    },
    {
      "arxiv_id": "2504.18878v1",
      "title": "TSRM: A Lightweight Temporal Feature Encoding Architecture for Time Series Forecasting and Imputation",
      "title_zh": "TSRM：一种轻量级时间特征编码架构，用于时间序列预测和插值",
      "authors": [
        "Robert Leppich",
        "Michael Stenger",
        "Daniel Grillmeyer",
        "Vanessa Borst",
        "Samuel Kounev"
      ],
      "abstract": "We introduce a temporal feature encoding architecture called Time Series\nRepresentation Model (TSRM) for multivariate time series forecasting and\nimputation. The architecture is structured around CNN-based representation\nlayers, each dedicated to an independent representation learning task and\ndesigned to capture diverse temporal patterns, followed by an attention-based\nfeature extraction layer and a merge layer, designed to aggregate extracted\nfeatures. The architecture is fundamentally based on a configuration that is\ninspired by a Transformer encoder, with self-attention mechanisms at its core.\nThe TSRM architecture outperforms state-of-the-art approaches on most of the\nseven established benchmark datasets considered in our empirical evaluation for\nboth forecasting and imputation tasks. At the same time, it significantly\nreduces complexity in the form of learnable parameters. The source code is\navailable at https://github.com/RobertLeppich/TSRM.",
      "tldr_zh": "本研究提出了一种轻量级时间特征编码架构TSRM，用于多变量时间序列预测和插值。TSRM由基于CNN的表示层组成，每个层专注于独立任务以捕捉多样时间模式，随后通过注意力-based特征提取层和合并层聚合特征，该架构受Transformer编码器启发并以自注意力机制为核心。与现有方法相比，TSRM在七个基准数据集上的预测和插值任务中表现出色，同时显著减少了可学习参数。源代码可在GitHub上获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18878v1",
      "published_date": "2025-04-26 09:53:20 UTC",
      "updated_date": "2025-04-26 09:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:59:16.324838"
    },
    {
      "arxiv_id": "2504.18875v1",
      "title": "Generative to Agentic AI: Survey, Conceptualization, and Challenges",
      "title_zh": "从生成式 AI 到代理式 AI：调查、概念化和挑战",
      "authors": [
        "Johannes Schneider"
      ],
      "abstract": "Agentic Artificial Intelligence (AI) builds upon Generative AI (GenAI). It\nconstitutes the next major step in the evolution of AI with much stronger\nreasoning and interaction capabilities that enable more autonomous behavior to\ntackle complex tasks. Since the initial release of ChatGPT (3.5), Generative AI\nhas seen widespread adoption, giving users firsthand experience. However, the\ndistinction between Agentic AI and GenAI remains less well understood. To\naddress this gap, our survey is structured in two parts. In the first part, we\ncompare GenAI and Agentic AI using existing literature, discussing their key\ncharacteristics, how Agentic AI remedies limitations of GenAI, and the major\nsteps in GenAI's evolution toward Agentic AI. This section is intended for a\nbroad audience, including academics in both social sciences and engineering, as\nwell as industry professionals. It provides the necessary insights to\ncomprehend novel applications that are possible with Agentic AI but not with\nGenAI. In the second part, we deep dive into novel aspects of Agentic AI,\nincluding recent developments and practical concerns such as defining agents.\nFinally, we discuss several challenges that could serve as a future research\nagenda, while cautioning against risks that can emerge when exceeding human\nintelligence.",
      "tldr_zh": "这篇论文调查了 Generative AI 到 Agentic AI 的演变，比较了两者的关键特性，并探讨了 Agentic AI 如何通过更强的推理和交互能力来解决 Generative AI 的局限性，如任务自主性和复杂处理。论文分为两部分：第一部分基于现有文献，为学术和行业受众解释 Agentic AI 的优势和应用可能性；第二部分深入分析 Agentic AI 的最新发展、定义代理以及实际问题。最终，论文提出了未来研究议程，包括潜在挑战和风险，如 AI 超过人类智能带来的隐患。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18875v1",
      "published_date": "2025-04-26 09:47:00 UTC",
      "updated_date": "2025-04-26 09:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:59:28.357071"
    },
    {
      "arxiv_id": "2505.09624v1",
      "title": "Neurophysiologically Realistic Environment for Comparing Adaptive Deep Brain Stimulation Algorithms in Parkinson Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Ekaterina Kuzmina",
        "Dmitrii Kriukov",
        "Mikhail Lebedev",
        "Dmitry V. Dylov"
      ],
      "abstract": "Adaptive deep brain stimulation (aDBS) has emerged as a promising treatment\nfor Parkinson disease (PD). In aDBS, a surgically placed electrode sends\ndynamically altered stimuli to the brain based on neurophysiological feedback:\nan invasive gadget that limits the amount of data one could collect for\noptimizing the control offline. As a consequence, a plethora of synthetic\nmodels of PD and those of the control algorithms have been proposed. Herein, we\nintroduce the first neurophysiologically realistic benchmark for comparing said\nmodels. Specifically, our methodology covers not only conventional basal\nganglia circuit dynamics and pathological oscillations, but also captures 15\npreviously dismissed physiological attributes, such as signal instabilities and\nnoise, neural drift, electrode conductance changes and individual variability -\nall modeled as spatially distributed and temporally registered features via\nbeta-band activity in the brain and a feedback. Furthermore, we purposely built\nour framework as a structured environment for training and evaluating deep\nreinforcement learning (RL) algorithms, opening new possibilities for\noptimizing aDBS control strategies and inviting the machine learning community\nto contribute to the emerging field of intelligent neurostimulation interfaces.",
      "tldr_zh": "本研究引入了一个神经生理上真实的基准环境，用于比较自适应深脑刺激 (aDBS) 算法在帕金森病 (PD) 治疗中的性能。该环境不仅模拟传统的基底神经节电路动态和病理性振荡，还整合了15个之前被忽略的生理属性，如信号不稳定性、噪声、神经漂移、电极电导变化和个体变异，这些通过脑部β波段活动建模为空间分布和时间注册的特征。作为一个结构化的框架，该基准环境支持训练和评估深度强化学习 (RL) 算法，从而优化aDBS控制策略，并邀请机器学习社区参与智能神经刺激接口的发展。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "68T05"
      ],
      "primary_category": "q-bio.NC",
      "comment": "8 pages, 3 figures, submission to KDD",
      "pdf_url": "http://arxiv.org/pdf/2505.09624v1",
      "published_date": "2025-04-26 09:44:44 UTC",
      "updated_date": "2025-04-26 09:44:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:59:40.683969"
    },
    {
      "arxiv_id": "2504.18858v1",
      "title": "Why you shouldn't fully trust ChatGPT: A synthesis of this AI tool's error rates across disciplines and the software engineering lifecycle",
      "title_zh": "翻译失败",
      "authors": [
        "Vahid Garousi"
      ],
      "abstract": "Context: ChatGPT and other large language models (LLMs) are widely used\nacross healthcare, business, economics, engineering, and software engineering\n(SE). Despite their popularity, concerns persist about their reliability,\nespecially their error rates across domains and the software development\nlifecycle (SDLC).\n  Objective: This study synthesizes and quantifies ChatGPT's reported error\nrates across major domains and SE tasks aligned with SDLC phases. It provides\nan evidence-based view of where ChatGPT excels, where it fails, and how\nreliability varies by task, domain, and model version (GPT-3.5, GPT-4,\nGPT-4-turbo, GPT-4o).\n  Method: A Multivocal Literature Review (MLR) was conducted, gathering data\nfrom academic studies, reports, benchmarks, and grey literature up to 2025.\nFactual, reasoning, coding, and interpretive errors were considered. Data were\ngrouped by domain and SE phase and visualized using boxplots to show error\ndistributions.\n  Results: Error rates vary across domains and versions. In healthcare, rates\nranged from 8% to 83%. Business and economics saw error rates drop from ~50%\nwith GPT-3.5 to 15-20% with GPT-4. Engineering tasks averaged 20-30%.\nProgramming success reached 87.5%, though complex debugging still showed over\n50% errors. In SE, requirements and design phases showed lower error rates\n(~5-20%), while coding, testing, and maintenance phases had higher variability\n(10-50%). Upgrades from GPT-3.5 to GPT-4 improved reliability.\n  Conclusion: Despite improvements, ChatGPT still exhibits non-negligible error\nrates varying by domain, task, and SDLC phase. Full reliance without human\noversight remains risky, especially in critical settings. Continuous evaluation\nand critical validation are essential to ensure reliability and\ntrustworthiness.",
      "tldr_zh": "本研究综合分析了 ChatGPT 在医疗、商业、经济、工程和软件工程 (SE) 等领域，以及软件开发生命周期 (SDLC) 各阶段的错误率，旨在提供证据支持评估其可靠性。采用 Multivocal Literature Review (MLR) 方法，收集至 2025 年的学术研究、报告和灰色文献数据，并通过箱线图可视化错误分布，包括事实、推理、编码和解释错误。结果显示，错误率因领域和模型版本（如 GPT-3.5 到 GPT-4）而异，例如医疗领域 8% 到 83%、SE 中需求阶段约 5-20% 而编码阶段 10-50%，升级版本显著改善了表现。尽管 ChatGPT 的可靠性有所提升，但作者强调在关键领域不可完全依赖，需要持续评估和人类监督以确保可信度。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18858v1",
      "published_date": "2025-04-26 08:49:33 UTC",
      "updated_date": "2025-04-26 08:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:59:53.376129"
    },
    {
      "arxiv_id": "2504.18857v1",
      "title": "Effective Length Extrapolation via Dimension-Wise Positional Embeddings Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Lu",
        "Wanxu Zhao",
        "Xin Zhou",
        "Chenxin An",
        "Chenglong Wang",
        "Shuo Li",
        "Yuming Yang",
        "Jun Zhao",
        "Tao Ji",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "Large Language Models (LLMs) often struggle to process and generate coherent\ncontext when the number of input tokens exceeds the pre-trained length. Recent\nadvancements in long-context extension have significantly expanded the context\nwindow of LLMs but require expensive overhead to train the large-scale models\nwith longer context. In this work, we propose Dimension-Wise Positional\nEmbeddings Manipulation (DPE), a training-free framework to extrapolate the\ncontext window of LLMs by diving into RoPE's different hidden dimensions.\nInstead of manipulating all dimensions equally, DPE detects the effective\nlength for every dimension and finds the key dimensions for context extension.\nWe reuse the original position indices with their embeddings from the\npre-trained model and manipulate the key dimensions' position indices to their\nmost effective lengths. In this way, DPE adjusts the pre-trained models with\nminimal modifications while ensuring that each dimension reaches its optimal\nstate for extrapolation. DPE significantly surpasses well-known baselines such\nas YaRN and Self-Extend. DPE enables Llama3-8k 8B to support context windows of\n128k tokens without continual training and integrates seamlessly with Flash\nAttention 2. In addition to its impressive extrapolation capability, DPE also\ndramatically improves the models' performance within training length, such as\nLlama3.1 70B, by over 18 points on popular long-context benchmarks RULER. When\ncompared with commercial models, Llama 3.1 70B with DPE even achieves better\nperformance than GPT-4-128K.",
      "tldr_zh": "该研究提出了一种无需训练的框架——Dimension-Wise Positional Embeddings Manipulation (DPE)，旨在解决Large Language Models (LLMs) 在处理超过预训练长度的输入时出现上下文连贯性问题。DPE 通过分析RoPE的隐藏维度，检测每个维度的有效长度并操纵关键维度的位置索引，从而以最小修改扩展LLMs的上下文窗口。实验结果显示，DPE 显著优于基线如YaRN和Self-Extend，使Llama3-8k 8B 支持128k 标记的上下文窗口，并与Flash Attention 2 无缝集成。此外，DPE 还提升了模型在训练长度内的性能，例如Llama3.1 70B 在RULER 基准上提升超过18点，甚至超越GPT-4-128K 的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18857v1",
      "published_date": "2025-04-26 08:46:10 UTC",
      "updated_date": "2025-04-26 08:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:00:04.510327"
    },
    {
      "arxiv_id": "2504.18854v1",
      "title": "Predicting Stress in Two-phase Random Materials and Super-Resolution Method for Stress Images by Embedding Physical Information",
      "title_zh": "翻译失败",
      "authors": [
        "Tengfei Xing",
        "Xiaodan Ren",
        "Jie Li"
      ],
      "abstract": "Stress analysis is an important part of material design. For materials with\ncomplex microstructures, such as two-phase random materials (TRMs), material\nfailure is often accompanied by stress concentration. Phase interfaces in\ntwo-phase materials are critical for stress concentration. Therefore, the\nprediction error of stress at phase boundaries is crucial. In practical\nengineering, the pixels of the obtained material microstructure images are\nlimited, which limits the resolution of stress images generated by deep\nlearning methods, making it difficult to observe stress concentration regions.\nExisting Image Super-Resolution (ISR) technologies are all based on data-driven\nsupervised learning. However, stress images have natural physical constraints,\nwhich provide new ideas for new ISR technologies. In this study, we constructed\na stress prediction framework for TRMs. First, the framework uses a proposed\nMultiple Compositions U-net (MC U-net) to predict stress in low-resolution\nmaterial microstructures. By considering the phase interface information of the\nmicrostructure, the MC U-net effectively reduces the problem of excessive\nprediction errors at phase boundaries. Secondly, a Mixed Physics-Informed\nNeural Network (MPINN) based method for stress ISR (SRPINN) was proposed. By\nintroducing the constraints of physical information, the new method does not\nrequire paired stress images for training and can increase the resolution of\nstress images to any multiple. This enables a multiscale analysis of the stress\nconcentration regions at phase boundaries. Finally, we performed stress\nanalysis on TRMs with different phase volume fractions and loading states\nthrough transfer learning. The results show the proposed stress prediction\nframework has satisfactory accuracy and generalization ability.",
      "tldr_zh": "该研究针对双相随机材料 (TRMs) 的应力预测问题，提出一个集成框架，以解决应力集中区域分辨率不足和相界面预测误差大的挑战。首先，使用 Multiple Compositions U-net (MC U-net) 模型预测低分辨率材料微观结构的应力，并通过考虑相界面信息有效降低预测错误。其次，开发了基于 Mixed Physics-Informed Neural Network (MPINN) 的 SRPINN 方法，利用物理约束进行应力图像超分辨率 (ISR)，无需配对图像即可实现任意倍数分辨率提升，支持多尺度应力分析。最后，通过迁移学习在不同相体积分数和加载状态的 TRMs 上验证了框架的准确性和泛化能力。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18854v1",
      "published_date": "2025-04-26 08:42:06 UTC",
      "updated_date": "2025-04-26 08:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:00:16.941916"
    },
    {
      "arxiv_id": "2505.01438v1",
      "title": "Global Stress Generation and Spatiotemporal Super-Resolution Physics-Informed Operator under Dynamic Loading for Two-Phase Random Materials",
      "title_zh": "翻译失败",
      "authors": [
        "Tengfei Xing",
        "Xiaodan Ren",
        "Jie Li"
      ],
      "abstract": "Material stress analysis is a critical aspect of material design and\nperformance optimization. Under dynamic loading, the global stress evolution in\nmaterials exhibits complex spatiotemporal characteristics, especially in\ntwo-phase random materials (TRMs). Such kind of material failure is often\nassociated with stress concentration, and the phase boundaries are key\nlocations where stress concentration occurs. In practical engineering\napplications, the spatiotemporal resolution of acquired microstructural data\nand its dynamic stress evolution is often limited. This poses challenges for\ndeep learning methods in generating high-resolution spatiotemporal stress\nfields, particularly for accurately capturing stress concentration regions. In\nthis study, we propose a framework for global stress generation and\nspatiotemporal super-resolution in TRMs under dynamic loading. First, we\nintroduce a diffusion model-based approach, named as Spatiotemporal Stress\nDiffusion (STS-diffusion), for generating global spatiotemporal stress data.\nThis framework incorporates Space-Time U-Net (STU-net), and we systematically\ninvestigate the impact of different attention positions on model accuracy.\nNext, we develop a physics-informed network for spatiotemporal\nsuper-resolution, termed as Spatiotemporal Super-Resolution Physics-Informed\nOperator (ST-SRPINN). The proposed ST-SRPINN is an unsupervised learning\nmethod. The influence of data-driven and physics-informed loss function weights\non model accuracy is explored in detail. Benefiting from physics-based\nconstraints, ST-SRPINN requires only low-resolution stress field data during\ntraining and can upscale the spatiotemporal resolution of stress fields to\narbitrary magnifications.",
      "tldr_zh": "该研究针对动态加载下两相随机材料（TRMs）的应力演变提出一个框架，解决时空分辨率有限导致的应力集中捕捉难题。框架首先引入Spatiotemporal Stress Diffusion (STS-diffusion)模型，基于扩散模型和Space-Time U-Net (STU-net)生成全局时空应力数据，并分析不同注意力位置对模型准确性的影响。其次，开发Spatiotemporal Super-Resolution Physics-Informed Operator (ST-SRPINN)，一个无监督物理信息网络，仅需低分辨率数据即可实现应力场的任意放大倍数，通过优化数据驱动和物理信息损失函数权重提升准确性。该方法显著提高了TRMs应力分析的精确性和实用性，尤其在捕捉相边界应力集中区域方面。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01438v1",
      "published_date": "2025-04-26 08:37:29 UTC",
      "updated_date": "2025-04-26 08:37:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:00:28.794245"
    },
    {
      "arxiv_id": "2504.18847v1",
      "title": "Imitation Learning for Autonomous Driving: Insights from Real-World Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Hidayet Ersin Dursun",
        "Yusuf Güven",
        "Tufan Kumbasar"
      ],
      "abstract": "This work focuses on the design of a deep learning-based autonomous driving\nsystem deployed and tested on the real-world MIT Racecar to assess its\neffectiveness in driving scenarios. The Deep Neural Network (DNN) translates\nraw image inputs into real-time steering commands in an end-to-end learning\nfashion, following the imitation learning framework. The key design challenge\nis to ensure that DNN predictions are accurate and fast enough, at a high\nsampling frequency, and result in smooth vehicle operation under different\noperating conditions. In this study, we design and compare various DNNs, to\nidentify the most effective approach for real-time autonomous driving. In\ndesigning the DNNs, we adopted an incremental design approach that involved\nenhancing the model capacity and dataset to address the challenges of\nreal-world driving scenarios. We designed a PD system, CNN, CNN-LSTM, and\nCNN-NODE, and evaluated their performance on the real-world MIT Racecar. While\nthe PD system handled basic lane following, it struggled with sharp turns and\nlighting variations. The CNN improved steering but lacked temporal awareness,\nwhich the CNN-LSTM addressed as it resulted in smooth driving performance. The\nCNN-NODE performed similarly to the CNN-LSTM in handling driving dynamics, yet\nwith slightly better driving performance. The findings of this research\nhighlight the importance of iterative design processes in developing robust\nDNNs for autonomous driving applications. The experimental video is available\nat https://www.youtube.com/watch?v=FNNYgU--iaY.",
      "tldr_zh": "本研究探讨了Imitation Learning在自动驾驶中的应用，通过在真实世界MIT Racecar上测试一个基于深度神经网络(DNN)的端到端系统，将图像输入转化为实时转向命令。研究采用增量设计方法，比较了多种DNN架构，包括PD系统、CNN、CNN-LSTM和CNN-NODE，以应对不同驾驶场景的挑战，如急转弯和光线变化。结果显示，PD系统适合基本车道跟随，但CNN-LSTM和CNN-NODE在处理动态驾驶方面表现更佳，提供更平滑的操作；这一发现强调了迭代设计过程在开发鲁棒DNN模型中的重要性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "In International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18847v1",
      "published_date": "2025-04-26 08:21:12 UTC",
      "updated_date": "2025-04-26 08:21:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:00:39.725076"
    },
    {
      "arxiv_id": "2504.18845v1",
      "title": "Introducing Interval Neural Networks for Uncertainty-Aware System Identification",
      "title_zh": "引入区间神经网络用于不确定性感知系统辨识",
      "authors": [
        "Mehmet Ali Ferah",
        "Tufan Kumbasar"
      ],
      "abstract": "System Identification (SysID) is crucial for modeling and understanding\ndynamical systems using experimental data. While traditional SysID methods\nemphasize linear models, their inability to fully capture nonlinear dynamics\nhas driven the adoption of Deep Learning (DL) as a more powerful alternative.\nHowever, the lack of uncertainty quantification (UQ) in DL-based models poses\nchallenges for reliability and safety, highlighting the necessity of\nincorporating UQ. This paper introduces a systematic framework for constructing\nand learning Interval Neural Networks (INNs) to perform UQ in SysID tasks. INNs\nare derived by transforming the learnable parameters (LPs) of pre-trained\nneural networks into interval-valued LPs without relying on probabilistic\nassumptions. By employing interval arithmetic throughout the network, INNs can\ngenerate Prediction Intervals (PIs) that capture target coverage effectively.\nWe extend Long Short-Term Memory (LSTM) and Neural Ordinary Differential\nEquations (Neural ODEs) into Interval LSTM (ILSTM) and Interval NODE (INODE)\narchitectures, providing the mathematical foundations for their application in\nSysID. To train INNs, we propose a DL framework that integrates a UQ loss\nfunction and parameterization tricks to handle constraints arising from\ninterval LPs. We introduce novel concept \"elasticity\" for underlying\nuncertainty causes and validate ILSTM and INODE in SysID experiments,\ndemonstrating their effectiveness.",
      "tldr_zh": "这篇论文介绍了 Interval Neural Networks (INNs) 的框架，用于不确定性感知的 System Identification (SysID)，以解决深度学习模型在动态系统建模中缺乏不确定性量化 (UQ) 的问题。INNs 通过将预训练神经网络的参数转化为区间值参数，并应用区间算术生成有效的 Prediction Intervals (PIs)，同时扩展了 Long Short-Term Memory (LSTM) 和 Neural Ordinary Differential Equations (Neural ODEs) 成 Interval LSTM (ILSTM) 和 Interval NODE (INODE)。论文提出了一种深度学习训练框架，包括 UQ 损失函数、参数化技巧和新型“elasticity”概念，并在 SysID 实验中验证了这些方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "In International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18845v1",
      "published_date": "2025-04-26 08:16:46 UTC",
      "updated_date": "2025-04-26 08:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:00:52.897822"
    },
    {
      "arxiv_id": "2504.18827v2",
      "title": "Test It Before You Trust It: Applying Software Testing for Trustworthy In-context Learning",
      "title_zh": "在信任之前测试它：应用软件测试来实现可信的上下文学习",
      "authors": [
        "Teeradaj Racharak",
        "Chaiyong Ragkhitwetsagul",
        "Chommakorn Sontesadisai",
        "Thanwadee Sunetnanta"
      ],
      "abstract": "In-context learning (ICL) has emerged as a powerful capability of large\nlanguage models (LLMs), enabling them to perform new tasks based on a few\nprovided examples without explicit fine-tuning. Despite their impressive\nadaptability, these models remain vulnerable to subtle adversarial\nperturbations and exhibit unpredictable behavior when faced with linguistic\nvariations. Inspired by software testing principles, we introduce a software\ntesting-inspired framework, called MMT4NL, for evaluating the trustworthiness\nof in-context learning by utilizing adversarial perturbations and software\ntesting techniques. It includes diverse evaluation aspects of linguistic\ncapabilities for testing the ICL capabilities of LLMs. MMT4NL is built around\nthe idea of crafting metamorphic adversarial examples from a test set in order\nto quantify and pinpoint bugs in the designed prompts of ICL. Our philosophy is\nto treat any LLM as software and validate its functionalities just like testing\nthe software. Finally, we demonstrate applications of MMT4NL on the sentiment\nanalysis and question-answering tasks. Our experiments could reveal various\nlinguistic bugs in state-of-the-art LLMs.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的In-context learning (ICL)能力提出了一种软件测试启发的框架MMT4NL，以评估其可信度。ICL允许LLMs基于少量示例执行新任务，但容易受adversarial perturbations和语言变体影响，导致不可预测行为。MMT4NL通过创建metamorphic adversarial examples来测试和定位ICL提示中的错误，将LLMs视为软件进行功能验证。实验在情感分析和问答任务上应用该框架，揭示了最先进LLMs中的各种语言错误，从而提升了ICL的可靠性和鲁棒性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18827v2",
      "published_date": "2025-04-26 07:29:12 UTC",
      "updated_date": "2025-05-07 09:29:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:01:04.695825"
    },
    {
      "arxiv_id": "2504.18819v1",
      "title": "Preserving Seasonal and Trend Information: A Variational Autoencoder-Latent Space Arithmetic Based Approach for Non-stationary Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hassan Wasswa",
        "Aziida Nanyonga",
        "Timothy Lynar"
      ],
      "abstract": "AI models have garnered significant research attention towards predictive\ntask automation. However, a stationary training environment is an underlying\nassumption for most models and such models simply do not work on non-stationary\ndata since a stationary relationship is learned. The existing solutions propose\nmaking data stationary prior to model training and evaluation. This leads to\nloss of trend and seasonal patterns which are vital components for learning\ntemporal dependencies of the system under study. This research aims to address\nthis limitation by proposing a method for enforcing stationary behaviour within\nthe latent space while preserving trend and seasonal information. The method\ndeploys techniques including Differencing, Time-series decomposition, and\nLatent Space Arithmetic (LSA), to learn information vital for efficient\napproximation of trend and seasonal information which is then stored as\nembeddings within the latent space of a Variational Autoencoder (VAE). The\napproach's ability to preserve trend and seasonal information was evaluated on\ntwo time-series non-stationary datasets. For predictive performance evaluation,\nfour deep learning models were trained on the latent vector representations of\nthe datasets after application of the proposed method and all models produced\ncompetitive results in comparison with state-of-the-art techniques using RMSE\nas the performance metric.",
      "tldr_zh": "本论文针对AI模型在非平稳数据上的局限性，提出了一种基于Variational Autoencoder (VAE)的方法，通过Differencing、Time-series decomposition和Latent Space Arithmetic (LSA)技术，在潜在空间中强制平稳行为的同时保留趋势和季节性信息。方法将这些关键信息学习并存储为嵌入，从而避免了传统数据平稳化导致的模式丢失。在两个非平稳时间序列数据集上进行评估，结果显示，四种深度学习模型在应用该方法后的潜在向量表示上，使用RMSE作为性能指标，取得了与最先进技术相当的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18819v1",
      "published_date": "2025-04-26 06:29:06 UTC",
      "updated_date": "2025-04-26 06:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:01:17.140217"
    },
    {
      "arxiv_id": "2505.02841v1",
      "title": "Snakemaker: Seamlessly transforming ad-hoc analyses into sustainable Snakemake workflows with generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Masera",
        "Alessandro Leone",
        "Johannes Köster",
        "Ivan Molineris"
      ],
      "abstract": "Reproducibility and sustainability present significant challenges in\nbioinformatics software development, where rapidly evolving tools and complex\nworkflows often result in short-lived or difficult-to-adapt pipelines. This\npaper introduces Snakemaker, a tool that leverages generative AI to facilitate\nresearchers build sustainable data analysis pipelines by converting\nunstructured code into well-defined Snakemake workflows. Snakemaker\nnon-invasively tracks the work performed in the terminal by the researcher,\nanalyzes execution patterns, and generates Snakemake workflows that can be\nintegrated into existing pipelines. Snakemaker also supports the transformation\nof monolithic Ipython Notebooks into modular Snakemake pipelines, resolving the\nglobal state of the notebook into discrete, file-based interactions between\nrules. An integrated chat assistant provides users with fine-grained control\nthrough natural language instructions. Snakemaker generates high-quality\nSnakemake workflows by adhering to the best practices, including Conda\nenvironment tracking, generic rule generation and loop unrolling. By lowering\nthe barrier between prototype and production-quality code, Snakemaker addresses\na critical gap in computational reproducibility for bioinformatics research.",
      "tldr_zh": "本文介绍了 Snakemaker，一种利用 generative AI 的工具，用于将 ad-hoc 分析无缝转换为可持续的 Snakemake 工作流，从而提升生物信息学软件的再现性和可持续性。Snakemaker 通过非侵入式跟踪终端操作、分析执行模式，并支持将 Ipython Notebooks 转换为模块化管道，实现代码结构的优化。工具还集成聊天助手，支持自然语言指令控制，并遵循最佳实践如 Conda 环境跟踪和通用规则生成。通过降低原型代码到生产级代码的门槛，Snakemaker 有效解决了计算可重复性的关键挑战。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02841v1",
      "published_date": "2025-04-26 06:00:05 UTC",
      "updated_date": "2025-04-26 06:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:01:28.897718"
    },
    {
      "arxiv_id": "2504.18814v2",
      "title": "Zero-Day Botnet Attack Detection in IoV: A Modular Approach Using Isolation Forests and Particle Swarm Optimization",
      "title_zh": "IoV 中的零日僵尸网络攻击检测：一种使用隔离森林和粒子群优化的模块化方法",
      "authors": [
        "Abdelaziz Amara Korba",
        "Nour Elislem Karabadji",
        "Yacine Ghamri-Doudane"
      ],
      "abstract": "The Internet of Vehicles (IoV) is transforming transportation by enhancing\nconnectivity and enabling autonomous driving. However, this increased\ninterconnectivity introduces new security vulnerabilities. Bot malware and\ncyberattacks pose significant risks to Connected and Autonomous Vehicles\n(CAVs), as demonstrated by real-world incidents involving remote vehicle system\ncompromise. To address these challenges, we propose an edge-based Intrusion\nDetection System (IDS) that monitors network traffic to and from CAVs. Our\ndetection model is based on a meta-ensemble classifier capable of recognizing\nknown (Nday) attacks and detecting previously unseen (zero-day) attacks. The\napproach involves training multiple Isolation Forest (IF) models on\nMulti-access Edge Computing (MEC) servers, with each IF specialized in\nidentifying a specific type of botnet attack. These IFs, either trained locally\nor shared by other MEC nodes, are then aggregated using a Particle Swarm\nOptimization (PSO) based stacking strategy to construct a robust\nmeta-classifier. The proposed IDS has been evaluated on a vehicular botnet\ndataset, achieving an average detection rate of 92.80% for N-day attacks and\n77.32% for zero-day attacks. These results highlight the effectiveness of our\nsolution in detecting both known and emerging threats, providing a scalable and\nadaptive defense mechanism for CAVs within the IoV ecosystem.",
      "tldr_zh": "该研究针对 Internet of Vehicles (IoV) 中的安全漏洞，提出了一种基于边缘计算的 Intrusion Detection System (IDS)，用于检测已知 (N-day) 和零日 Botnet 攻击。方法采用多个 Isolation Forest (IF) 模型在 Multi-access Edge Computing (MEC) 服务器上训练，每个模型专注于特定类型的 Botnet 攻击，并通过 Particle Swarm Optimization (PSO) 基于 stacking 策略聚合这些模型，形成一个鲁棒的 meta-ensemble 分类器。在 vehicular botnet 数据集上评估，该系统对 N-day 攻击的平均检测率达 92.80%，对零日攻击达 77.32%，证明了其在提供可扩展、适应性防御机制方面的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18814v2",
      "published_date": "2025-04-26 05:57:03 UTC",
      "updated_date": "2025-05-01 20:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:01:41.824716"
    },
    {
      "arxiv_id": "2504.18810v1",
      "title": "Audio-Driven Talking Face Video Generation with Joint Uncertainty Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Xie",
        "Fei Ma",
        "Yi Bin",
        "Ying He",
        "Fei Yu"
      ],
      "abstract": "Talking face video generation with arbitrary speech audio is a significant\nchallenge within the realm of digital human technology. The previous studies\nhave emphasized the significance of audio-lip synchronization and visual\nquality. Currently, limited attention has been given to the learning of visual\nuncertainty, which creates several issues in existing systems, including\ninconsistent visual quality and unreliable performance across different input\nconditions. To address the problem, we propose a Joint Uncertainty Learning\nNetwork (JULNet) for high-quality talking face video generation, which\nincorporates a representation of uncertainty that is directly related to visual\nerror. Specifically, we first design an uncertainty module to individually\npredict the error map and uncertainty map after obtaining the generated image.\nThe error map represents the difference between the generated image and the\nground truth image, while the uncertainty map is used to predict the\nprobability of incorrect estimates. Furthermore, to match the uncertainty\ndistribution with the error distribution through a KL divergence term, we\nintroduce a histogram technique to approximate the distributions. By jointly\noptimizing error and uncertainty, the performance and robustness of our model\ncan be enhanced. Extensive experiments demonstrate that our method achieves\nsuperior high-fidelity and audio-lip synchronization in talking face video\ngeneration compared to previous methods.",
      "tldr_zh": "该论文探讨了基于音频驱动的说话人脸视频生成面临的挑战，特别是音频-唇部同步和视觉质量问题，并强调了视觉不确定性的重要性。作者提出Joint Uncertainty Learning Network (JULNet)，通过设计不确定性模块预测error map和uncertainty map，以量化生成图像与真实图像的差异和错误估计概率。进一步利用直方图技术和KL divergence优化匹配不确定性分布与错误分布，提升模型的鲁棒性和性能。实验结果显示，该方法在高保真度和音频-唇部同步方面优于现有方法，提供更可靠的视频生成效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18810v1",
      "published_date": "2025-04-26 05:45:38 UTC",
      "updated_date": "2025-04-26 05:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:01:52.022706"
    },
    {
      "arxiv_id": "2504.18807v1",
      "title": "Clones in the Machine: A Feminist Critique of Agency in Digital Cloning",
      "title_zh": "翻译失败",
      "authors": [
        "Siân Brooke"
      ],
      "abstract": "This paper critiques digital cloning in academic research, highlighting how\nit exemplifies AI solutionism. Digital clones, which replicate user data to\nsimulate behavior, are often seen as scalable tools for behavioral insights.\nHowever, this framing obscures ethical concerns around consent, agency, and\nrepresentation. Drawing on feminist theories of agency, the paper argues that\ndigital cloning oversimplifies human complexity and risks perpetuating systemic\nbiases. To address these issues, it proposes decentralized data repositories\nand dynamic consent models, promoting ethical, context-aware AI practices that\nchallenge the reductionist logic of AI solutionism",
      "tldr_zh": "本论文批判学术研究中的数字克隆（digital cloning），指出其体现了AI解决方案主义（AI solutionism），将用户数据复制用于行为模拟，却忽略了同意（consent）、代理（agency）和代表性（representation）的伦理问题。基于女权主义代理理论（feminist theories of agency），论文论证数字克隆简化了人类复杂性，并可能加剧系统性偏见（systemic biases）。为应对这些问题，论文提出采用去中心化数据仓库（decentralized data repositories）和动态同意模型（dynamic consent models），以推动伦理的、上下文感知的AI实践，挑战AI解决方案主义的还原主义逻辑。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "ACM CHI Conference on Human Factors in Computing Systems 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18807v1",
      "published_date": "2025-04-26 05:24:35 UTC",
      "updated_date": "2025-04-26 05:24:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:02:03.750291"
    },
    {
      "arxiv_id": "2504.18805v1",
      "title": "Stealing Creator's Workflow: A Creator-Inspired Agentic Framework with Iterative Feedback Loop for Improved Scientific Short-form Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jong Inn Park",
        "Maanas Taneja",
        "Qianwen Wang",
        "Dongyeop Kang"
      ],
      "abstract": "Generating engaging, accurate short-form videos from scientific papers is\nchallenging due to content complexity and the gap between expert authors and\nreaders. Existing end-to-end methods often suffer from factual inaccuracies and\nvisual artifacts, limiting their utility for scientific dissemination. To\naddress these issues, we propose SciTalk, a novel multi-LLM agentic framework,\ngrounding videos in various sources, such as text, figures, visual styles, and\navatars. Inspired by content creators' workflows, SciTalk uses specialized\nagents for content summarization, visual scene planning, and text and layout\nediting, and incorporates an iterative feedback mechanism where video agents\nsimulate user roles to give feedback on generated videos from previous\niterations and refine generation prompts. Experimental evaluations show that\nSciTalk outperforms simple prompting methods in generating scientifically\naccurate and engaging content over the refined loop of video generation.\nAlthough preliminary results are still not yet matching human creators'\nquality, our framework provides valuable insights into the challenges and\nbenefits of feedback-driven video generation. Our code, data, and generated\nvideos will be publicly available.",
      "tldr_zh": "该论文提出SciTalk，一种受内容创建者工作流启发的多LLM agentic框架，用于改善科学短视频生成，通过整合文本、图表、视觉风格和头像等多源数据来解决内容复杂性和准确性问题。框架包括专门的代理负责内容总结、视觉场景规划、文本布局编辑，并采用iterative feedback loop机制，让视频代理模拟用户角色提供反馈以迭代优化生成提示。实验结果显示，SciTalk在科学准确性和吸引力上优于简单提示方法，尽管尚未达到人类创建者水平，但为反馈驱动视频生成提供了宝贵见解，并计划公开代码、数据和生成视频。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project page: https://minnesotanlp.github.io/scitalk-project-page/",
      "pdf_url": "http://arxiv.org/pdf/2504.18805v1",
      "published_date": "2025-04-26 05:22:35 UTC",
      "updated_date": "2025-04-26 05:22:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:02:16.785378"
    },
    {
      "arxiv_id": "2504.18804v1",
      "title": "Can We Enhance Bug Report Quality Using LLMs?: An Empirical Study of LLM-Based Bug Report Generation",
      "title_zh": "使用LLMs能否提升bug",
      "authors": [
        "Jagrit Acharya",
        "Gouri Ginde"
      ],
      "abstract": "Bug reports contain the information developers need to triage and fix\nsoftware bugs. However, unclear, incomplete, or ambiguous information may lead\nto delays and excessive manual effort spent on bug triage and resolution. In\nthis paper, we explore whether Instruction fine-tuned Large Language Models\n(LLMs) can automatically transform casual, unstructured bug reports into\nhigh-quality, structured bug reports adhering to a standard template. We\nevaluate three open-source instruction-tuned LLMs (\\emph{Qwen 2.5, Mistral, and\nLlama 3.2}) against ChatGPT-4o, measuring performance on established metrics\nsuch as CTQRS, ROUGE, METEOR, and SBERT. Our experiments show that fine-tuned\nQwen 2.5 achieves a CTQRS score of \\textbf{77%}, outperforming both fine-tuned\nMistral (\\textbf{71%}), Llama 3.2 (\\textbf{63%}) and ChatGPT in 3-shot learning\n(\\textbf{75%}). Further analysis reveals that Llama 3.2 shows higher accuracy\nof detecting missing fields particularly Expected Behavior and Actual Behavior,\nwhile Qwen 2.5 demonstrates superior performance in capturing\nSteps-to-Reproduce, with an F1 score of 76%. Additional testing of the models\non other popular projects (e.g., Eclipse, GCC) demonstrates that our approach\ngeneralizes well, achieving up to \\textbf{70%} CTQRS in unseen projects' bug\nreports. These findings highlight the potential of instruction fine-tuning in\nautomating structured bug report generation, reducing manual effort for\ndevelopers and streamlining the software maintenance process.",
      "tldr_zh": "本文通过实证研究探讨是否可以使用指令微调的 LLMs（Large Language Models）将非结构化的 bug 报告自动转化为高质量的结构化报告，以减少开发者的手动努力。评估了 Qwen 2.5、Mistral 和 Llama 3.2 等开源模型与 ChatGPT-4o 的性能，使用 CTQRS、ROUGE、METEOR 和 SBERT 等指标，结果显示微调后的 Qwen 2.5 取得 77% 的 CTQRS 分数，优于其他模型。进一步分析发现，Llama 3.2 在检测缺失字段如 Expected Behavior 和 Actual Behavior 方面更准确，而 Qwen 2.5 在 Steps-to-Reproduce 上表现突出（F1 分数 76%）。该方法在其他项目（如 Eclipse 和 GCC）上泛化良好，达到 70% 的 CTQRS 分数，展示了指令微调在自动化 bug 报告生成中的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18804v1",
      "published_date": "2025-04-26 05:15:53 UTC",
      "updated_date": "2025-04-26 05:15:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:02:30.545903"
    },
    {
      "arxiv_id": "2504.18800v1",
      "title": "Video CLIP Model for Multi-View Echocardiography Interpretation",
      "title_zh": "翻译失败",
      "authors": [
        "Ryo Takizawa",
        "Satoshi Kodera",
        "Tempei Kabayama",
        "Ryo Matsuoka",
        "Yuta Ando",
        "Yuto Nakamura",
        "Haruki Settai",
        "Norihiko Takeda"
      ],
      "abstract": "Echocardiography involves recording videos of the heart using ultrasound,\nenabling clinicians to evaluate its condition. Recent advances in large-scale\nvision-language models (VLMs) have garnered attention for automating the\ninterpretation of echocardiographic videos. However, most existing VLMs\nproposed for medical interpretation thus far rely on single-frame (i.e., image)\ninputs. Consequently, these image-based models often exhibit lower diagnostic\naccuracy for conditions identifiable through cardiac motion. Moreover,\nechocardiographic videos are recorded from various views that depend on the\ndirection of ultrasound emission, and certain views are more suitable than\nothers for interpreting specific conditions. Incorporating multiple views could\npotentially yield further improvements in accuracy. In this study, we developed\na video-language model that takes five different views and full video sequences\nas input, training it on pairs of echocardiographic videos and clinical reports\nfrom 60,747 cases. Our experiments demonstrate that this expanded approach\nachieves higher interpretation accuracy than models trained with only\nsingle-view videos or with still images.",
      "tldr_zh": "本研究针对超声心动图（echocardiography）的解释问题，指出现有视觉语言模型（VLMs）依赖单帧图像输入，导致对心脏运动相关条件的诊断准确性较低，且未充分利用多视角信息。该团队开发了Video CLIP Model，一种视频语言模型，输入为五种不同视图的完整视频序列，并使用60,747个病例的视频-临床报告对进行训练。该模型实验结果显示，与仅使用单视角视频或静态图像的模型相比，其解释准确性显著提升，为自动化心动图解读提供了更可靠的方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18800v1",
      "published_date": "2025-04-26 05:11:15 UTC",
      "updated_date": "2025-04-26 05:11:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:02:41.745034"
    },
    {
      "arxiv_id": "2504.18794v2",
      "title": "Hierarchical Reinforcement Learning in Multi-Goal Spatial Navigation with Autonomous Mobile Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Brendon Johnson",
        "Alfredo Weitzenfeld"
      ],
      "abstract": "Hierarchical reinforcement learning (HRL) is hypothesized to be able to take\nadvantage of the inherent hierarchy in robot learning tasks with sparse reward\nschemes, in contrast to more traditional reinforcement learning algorithms. In\nthis research, hierarchical reinforcement learning is evaluated and contrasted\nwith standard reinforcement learning in complex navigation tasks. We evaluate\nunique characteristics of HRL, including their ability to create sub-goals and\nthe termination function. We constructed experiments to test the differences\nbetween PPO and HRL, different ways of creating sub-goals, manual vs automatic\nsub-goal creation, and the effects of the frequency of termination on\nperformance. These experiments highlight the advantages of HRL and how it\nachieves these advantages.",
      "tldr_zh": "本研究评估了分层强化学习 (HRL) 在多目标空间导航任务中的应用，特别是在稀疏奖励方案下，与传统强化学习算法（如 PPO）进行对比，旨在利用 HRL 的层次结构提升自主移动机器人的学习效率。实验设计包括测试 HRL 创建子-goals 的能力、子-goals 的手动 vs 自动生成方式，以及终止 function 频率对任务性能的影响。这些实验突显了 HRL 的优势，例如在复杂导航场景中实现更好的子目标管理和整体表现。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18794v2",
      "published_date": "2025-04-26 04:30:10 UTC",
      "updated_date": "2025-05-05 17:21:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:02:54.362499"
    },
    {
      "arxiv_id": "2504.18793v1",
      "title": "Building Scalable AI-Powered Applications with Cloud Databases: Architectures, Best Practices and Performance Considerations",
      "title_zh": "使用云数据库构建可扩展",
      "authors": [
        "Santosh Bhupathi"
      ],
      "abstract": "The rapid adoption of AI-powered applications demands high-performance,\nscalable, and efficient cloud database solutions, as traditional architectures\noften struggle with AI-driven workloads requiring real-time data access, vector\nsearch, and low-latency queries. This paper explores how cloud-native databases\nenable AI-driven applications by leveraging purpose-built technologies such as\nvector databases (pgvector), graph databases (AWS Neptune), NoSQL stores\n(Amazon DocumentDB, DynamoDB), and relational cloud databases (Aurora MySQL and\nPostgreSQL). It presents architectural patterns for integrating AI workloads\nwith cloud databases, including Retrieval-Augmented Generation (RAG) [1] with\nLLMs, real-time data pipelines, AI-driven query optimization, and\nembeddings-based search. Performance benchmarks, scalability considerations,\nand cost-efficient strategies are evaluated to guide the design of AI-enabled\napplications. Real-world case studies from industries such as healthcare,\nfinance, and customer experience illustrate how enterprises utilize cloud\ndatabases to enhance AI capabilities while ensuring security, governance, and\ncompliance with enterprise and regulatory standards. By providing a\ncomprehensive analysis of AI and cloud database integration, this paper serves\nas a practical guide for researchers, architects, and enterprises to build\nnext-generation AI applications that optimize performance, scalability, and\ncost efficiency in cloud environments.",
      "tldr_zh": "这篇论文探讨了如何利用云数据库构建可扩展的 AI 驱动应用，解决传统架构在实时数据访问、vector search 和低延迟查询方面的挑战。它介绍了云原生数据库技术，如 vector databases (pgvector)、graph databases (AWS Neptune)、NoSQL stores (Amazon DocumentDB, DynamoDB) 和 relational cloud databases (Aurora MySQL and PostgreSQL)，并呈现了架构模式，包括 Retrieval-Augmented Generation (RAG) 与 LLMs 的整合、实时数据管道、AI-driven query optimization 和 embeddings-based search。论文通过性能基准、可扩展性评估和成本效率策略，提供实用指导，并以医疗、金融和客户体验等行业的真实案例研究，展示了如何增强 AI 能力，同时确保安全、治理和合规。最终，这为研究人员和企业构建优化性能的下一代 AI 应用提供了全面分析。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "97P30",
        "I.2.7; H.2.5"
      ],
      "primary_category": "cs.DB",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.18793v1",
      "published_date": "2025-04-26 04:17:46 UTC",
      "updated_date": "2025-04-26 04:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:03:07.147117"
    },
    {
      "arxiv_id": "2504.21030v1",
      "title": "Advancing Multi-Agent Systems Through Model Context Protocol: Architecture, Implementation, and Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Naveen Krishnan"
      ],
      "abstract": "Multi-agent systems represent a significant advancement in artificial\nintelligence, enabling complex problem-solving through coordinated specialized\nagents. However, these systems face fundamental challenges in context\nmanagement, coordination efficiency, and scalable operation. This paper\nintroduces a comprehensive framework for advancing multi-agent systems through\nModel Context Protocol (MCP), addressing these challenges through standardized\ncontext sharing and coordination mechanisms. We extend previous work on AI\nagent architectures by developing a unified theoretical foundation, advanced\ncontext management techniques, and scalable coordination patterns. Through\ndetailed implementation case studies across enterprise knowledge management,\ncollaborative research, and distributed problem-solving domains, we demonstrate\nsignificant performance improvements compared to traditional approaches. Our\nevaluation methodology provides a systematic assessment framework with\nbenchmark tasks and datasets specifically designed for multi-agent systems. We\nidentify current limitations, emerging research opportunities, and potential\ntransformative applications across industries. This work contributes to the\nevolution of more capable, collaborative, and context-aware artificial\nintelligence systems that can effectively address complex real-world\nchallenges.",
      "tldr_zh": "这篇论文提出 Model Context Protocol (MCP) 框架，以解决多智能体系统在上下文管理、协调效率和可扩展性方面的挑战，通过标准化上下文共享和协调机制来扩展现有 AI 代理架构。框架包括统一的理论基础、先进的上下文管理技术和可扩展协调模式，并在企业知识管理、协作研究及分布式问题解决等领域进行案例研究，展示了与传统方法相比的显著性能提升。论文还提供了一个系统评估框架，包括专为多智能体系统设计的基准任务和数据集，并探讨了当前限制、研究机会及在各行业的潜在应用，从而推动更强大、协作和上下文感知的 AI 系统发展。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21030v1",
      "published_date": "2025-04-26 03:43:03 UTC",
      "updated_date": "2025-04-26 03:43:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:03:19.388882"
    },
    {
      "arxiv_id": "2504.18781v1",
      "title": "IoT Botnet Detection: Application of Vision Transformer to Classification of Network Flow Traffic",
      "title_zh": "物联网僵尸网络检测：视觉Transformer在网络流量分类中的应用",
      "authors": [
        "Hassan Wasswa",
        "Timothy Lynar",
        "Aziida Nanyonga",
        "Hussein Abbass"
      ],
      "abstract": "Despite the demonstrated effectiveness of transformer models in NLP, and\nimage and video classification, the available tools for extracting features\nfrom captured IoT network flow packets fail to capture sequential patterns in\naddition to the absence of spatial patterns consequently limiting transformer\nmodel application. This work introduces a novel preprocessing method to adapt\ntransformer models, the vision transformer (ViT) in particular, for IoT botnet\nattack detection using network flow packets. The approach involves feature\nextraction from .pcap files and transforming each instance into a 1-channel 2D\nimage shape, enabling ViT-based classification. Also, the ViT model was\nenhanced to allow use any classifier besides Multilayer Perceptron (MLP) that\nwas deployed in the initial ViT paper. Models including the conventional feed\nforward Deep Neural Network (DNN), LSTM and Bidirectional-LSTM (BLSTM)\ndemonstrated competitive performance in terms of precision, recall, and\nF1-score for multiclass-based attack detection when evaluated on two IoT attack\ndatasets.",
      "tldr_zh": "该研究针对IoT僵尸网络检测问题，提出了一种新颖的预处理方法，将网络流量数据从.pcap文件提取特征并转换为1通道2D图像，从而适配Vision Transformer (ViT)模型进行分类。ViT模型被增强，支持使用除Multilayer Perceptron (MLP)之外的分类器，如Deep Neural Network (DNN)、LSTM和Bidirectional-LSTM (BLSTM)，以更好地捕获顺序和空间模式。实验结果显示，该方法在两个IoT攻击数据集上实现了在精度、召回率和F1分数方面的竞争性能，证明了其在多类攻击检测中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18781v1",
      "published_date": "2025-04-26 03:19:19 UTC",
      "updated_date": "2025-04-26 03:19:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:03:30.478395"
    },
    {
      "arxiv_id": "2504.18777v1",
      "title": "Evaluating AI-Driven Automated Map Digitization in QGIS",
      "title_zh": "在 QGIS 中评估 AI 驱动的自动化地图数字化",
      "authors": [
        "Diana Febrita"
      ],
      "abstract": "Map digitization is an important process that converts maps into digital\nformats that can be used for further analysis. This process typically requires\na deep human involvement because of the need for interpretation and\ndecision-making when translating complex features. With the advancement of\nartificial intelligence, there is an alternative to conducting map digitization\nwith the help of machine learning techniques. Deepness, or Deep Neural Remote\nSensing, is an advanced AI-driven tool designed and integrated as a plugin in\nQGIS application. This research focuses on assessing the effectiveness of\nDeepness in automated digitization. This study analyses AI-generated\ndigitization results from Google Earth imagery and compares them with digitized\noutputs from OpenStreetMap (OSM) to evaluate performance.",
      "tldr_zh": "该研究评估了AI驱动的自动地图数字化工具Deepness，该工具作为QGIS插件，利用机器学习技术处理Google Earth图像，以减少传统数字化过程的人工干预。研究方法包括分析Deepness生成的数字化结果，并将其与OpenStreetMap (OSM)的输出进行比较，以评估其性能。结果显示，此AI方法在自动化数字化方面显示出潜力，有助于提升地图处理的效率和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to 2025 Indiana Geographic Information Council (IGIC)\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2504.18777v1",
      "published_date": "2025-04-26 03:09:54 UTC",
      "updated_date": "2025-04-26 03:09:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:03:41.382006"
    },
    {
      "arxiv_id": "2504.18770v1",
      "title": "PyViT-FUSE: A Foundation Model for Multi-Sensor Earth Observation Data",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Weber",
        "Carly Beneke"
      ],
      "abstract": "We propose PyViT-FUSE, a foundation model for earth observation data\nexplicitly designed to handle multi-modal imagery by learning to fuse an\narbitrary number of mixed-resolution input bands into a single representation\nthrough an attention mechanism. The learned patch tokens are further processed\nby a stack of vision transformers with a novel pyramidal structure. We train\nthe model on a globally sampled dataset in a self-supervised manner, leveraging\ncore concepts of the SwAV algorithm. We show the interpretability of the fusion\nmechanism by visualization of the attention scores and the models applicability\nto downstream tasks.",
      "tldr_zh": "本文提出 PyViT-FUSE，一种专为多传感器地球观测数据设计的 foundation model，能够通过注意力机制融合任意数量的混合分辨率输入波段，并使用 vision transformers 的金字塔结构处理学习后的 patch tokens。模型在全球采样数据集上以自监督方式训练，基于 SwAV 算法的核心概念。实验结果通过可视化注意力分数展示了融合机制的可解释性，并证明了模型在下游任务中的适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 13 figures, Published at ICLR 2025 - Machine Learning for\n  Remote Sensing (ML4RS) Workshop",
      "pdf_url": "http://arxiv.org/pdf/2504.18770v1",
      "published_date": "2025-04-26 02:34:33 UTC",
      "updated_date": "2025-04-26 02:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:03:55.011989"
    },
    {
      "arxiv_id": "2504.18766v1",
      "title": "Dynamic Action Interpolation: A Universal Approach for Accelerating Reinforcement Learning with Expert Guidance",
      "title_zh": "动态动作插值：一种用于通过专家指导加速强化学习的通用方法",
      "authors": [
        "Wenjun Cao"
      ],
      "abstract": "Reinforcement learning (RL) suffers from severe sample inefficiency,\nespecially during early training, requiring extensive environmental\ninteractions to perform competently. Existing methods tend to solve this by\nincorporating prior knowledge, but introduce significant architectural and\nimplementation complexity. We propose Dynamic Action Interpolation (DAI), a\nuniversal yet straightforward framework that interpolates expert and RL actions\nvia a time-varying weight $\\alpha(t)$, integrating into any Actor-Critic\nalgorithm with just a few lines of code and without auxiliary networks or\nadditional losses. Our theoretical analysis shows that DAI reshapes state\nvisitation distributions to accelerate value function learning while preserving\nconvergence guarantees. Empirical evaluations across MuJoCo continuous control\ntasks demonstrate that DAI improves early-stage performance by over 160\\% on\naverage and final performance by more than 50\\%, with the Humanoid task showing\na 4$\\times$ improvement early on and a 2$\\times$ gain at convergence. These\nresults challenge the assumption that complex architectural modifications are\nnecessary for sample-efficient reinforcement learning.",
      "tldr_zh": "该研究针对强化学习(Reinforcement Learning, RL)早期训练的样本效率低问题，提出了一种通用框架Dynamic Action Interpolation (DAI)，通过一个时间变化权重α(t)动态插值专家动作和RL动作，轻松整合到任何Actor-Critic算法中，而无需额外网络或损失函数。理论分析显示，DAI能重新塑造状态访问分布，加速价值函数学习并保持收敛保证。实验结果在MuJoCo连续控制任务中表明，DAI平均提升早期性能超过160%、最终性能超过50%，Humanoid任务甚至实现早期4倍和收敛2倍的改善，从而挑战了复杂架构修改的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18766v1",
      "published_date": "2025-04-26 02:12:02 UTC",
      "updated_date": "2025-04-26 02:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:04:07.176390"
    },
    {
      "arxiv_id": "2504.18765v1",
      "title": "A Vision for Auto Research with LLM Agents",
      "title_zh": "LLM 代理在自动研究中的愿景",
      "authors": [
        "Chengwei Liu",
        "Chong Wang",
        "Jiayue Cao",
        "Jingquan Ge",
        "Kun Wang",
        "Lvye Zhang",
        "Ming-Ming Cheng",
        "Penghai Zhao",
        "Tianlin Li",
        "Xiaojun Jia",
        "Xiang Li",
        "Xinfeng Li",
        "Yang Liu",
        "Yebo Feng",
        "Yihao Huang",
        "Yijia Xu",
        "Yuqiang Sun",
        "Zhenhong Zhou",
        "Zhengzi Xu"
      ],
      "abstract": "This paper introduces Agent-Based Auto Research, a structured multi-agent\nframework designed to automate, coordinate, and optimize the full lifecycle of\nscientific research. Leveraging the capabilities of large language models\n(LLMs) and modular agent collaboration, the system spans all major research\nphases, including literature review, ideation, methodology planning,\nexperimentation, paper writing, peer review response, and dissemination. By\naddressing issues such as fragmented workflows, uneven methodological\nexpertise, and cognitive overload, the framework offers a systematic and\nscalable approach to scientific inquiry. Preliminary explorations demonstrate\nthe feasibility and potential of Auto Research as a promising paradigm for\nself-improving, AI-driven research processes.",
      "tldr_zh": "这篇论文提出 Agent-Based Auto Research，一种结构化的多智能体框架，利用大型语言模型 (LLMs) 和模块化智能体协作，自动化科学研究的整个生命周期，包括文献综述、构思、方法规划、实验、论文写作、回应同行评审和传播。该框架针对碎片化的工作流程、不均匀的方法论专业知识以及认知过载等问题，提供一个系统化和可扩展的解决方案。初步探索显示，Auto Research 作为一种自我改进的 AI 驱动研究范式，具有可行性和巨大潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18765v1",
      "published_date": "2025-04-26 02:06:10 UTC",
      "updated_date": "2025-04-26 02:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:04:18.697871"
    },
    {
      "arxiv_id": "2505.01437v1",
      "title": "Enhancing IoT-Botnet Detection using Variational Auto-encoder and Cost-Sensitive Learning: A Deep Learning Approach for Imbalanced Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Hassan Wasswa",
        "Timothy Lynar",
        "Hussein Abbass"
      ],
      "abstract": "The Internet of Things (IoT) technology has rapidly gained popularity with\napplications widespread across a variety of industries. However, IoT devices\nhave been recently serving as a porous layer for many malicious attacks to both\npersonal and enterprise information systems with the most famous attacks being\nbotnet-related attacks. The work in this study leveraged Variational\nAuto-encoder (VAE) and cost-sensitive learning to develop lightweight, yet\neffective, models for IoT-botnet detection. The aim is to enhance the detection\nof minority class attack traffic instances which are often missed by machine\nlearning models. The proposed approach is evaluated on a multi-class problem\nsetting for the detection of traffic categories on highly imbalanced datasets.\nThe performance of two deep learning models including the standard feed forward\ndeep neural network (DNN), and Bidirectional-LSTM (BLSTM) was evaluated and\nboth recorded commendable results in terms of accuracy, precision, recall and\nF1-score for all traffic classes.",
      "tldr_zh": "本研究针对物联网（IoT）设备易受 botnet 攻击的问题，提出了一种结合 Variational Auto-encoder (VAE) 和 cost-sensitive learning 的深度学习方法，以提升对不平衡数据集中的少数类攻击流量检测能力。方法通过开发轻量级模型，专注于识别易被忽略的恶意流量，并在多类问题设置下进行评估。实验结果显示，标准前馈深度神经网络 (DNN) 和 Bidirectional-LSTM (BLSTM) 模型在准确率、精确率、召回率和 F1 分数方面均表现出色，显著改善了 IoT-botnet 检测的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01437v1",
      "published_date": "2025-04-26 02:04:30 UTC",
      "updated_date": "2025-04-26 02:04:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:04:31.122139"
    },
    {
      "arxiv_id": "2504.21029v1",
      "title": "PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight",
      "title_zh": "PICO：通过鲁棒提示隔离和网络安全监督实现安全的",
      "authors": [
        "Ben Goertzel",
        "Paulos Yibelo"
      ],
      "abstract": "We propose a robust transformer architecture designed to prevent prompt\ninjection attacks and ensure secure, reliable response generation. Our PICO\n(Prompt Isolation and Cybersecurity Oversight) framework structurally separates\ntrusted system instructions from untrusted user inputs through dual channels\nthat are processed independently and merged only by a controlled, gated fusion\nmechanism. In addition, we integrate a specialized Security Expert Agent within\na Mixture-of-Experts (MoE) framework and incorporate a Cybersecurity Knowledge\nGraph (CKG) to supply domain-specific reasoning. Our training design further\nensures that the system prompt branch remains immutable while the rest of the\nnetwork learns to handle adversarial inputs safely. This PICO framework is\npresented via a general mathematical formulation, then elaborated in terms of\nthe specifics of transformer architecture, and fleshed out via hypothetical\ncase studies including Policy Puppetry attacks. While the most effective\nimplementation may involve training transformers in a PICO-based way from\nscratch, we also present a cost-effective fine-tuning approach.",
      "tldr_zh": "本研究提出PICO框架，这是一种安全的Transformer架构，旨在防止提示注入攻击并确保响应生成的安全性和可靠性。PICO通过双通道机制分离受信任的系统指令和不受信任的用户输入，进行独立处理，然后仅通过受控的门控融合机制合并，以减少潜在风险。该框架整合了Security Expert Agent在Mixture-of-Experts (MoE)框架中，并利用Cybersecurity Knowledge Graph (CKG)提供特定领域的推理，同时确保系统提示分支不可变，并设计了从头训练和成本有效的微调方法。通过数学公式、Transformer架构细节和假设案例研究（如Policy Puppetry攻击），PICO为构建鲁棒的AI系统奠定了基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21029v1",
      "published_date": "2025-04-26 00:46:13 UTC",
      "updated_date": "2025-04-26 00:46:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:04:44.303297"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 61,
  "processed_papers_count": 61,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T17:05:05.355340"
}