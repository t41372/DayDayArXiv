{
  "date": "2024-12-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-08 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 57 篇论文，主要聚焦 AI 安全、生成模型优化、多模态学习和医疗应用等领域，其中令人印象深刻的包括 Johann Rehberger 的 AI 安全攻击论文，以及 David Blei 等学者的 LLM 推理研究；这些论文揭示了 LLM 的漏洞并提出改进方法，强调了 AI 模型的鲁棒性和实际应用潜力。\n\n下面，我将挑选并归类重点论文进行简要讨论，先优先聊那些有话题度、学术影响大的文章（如 AI 安全和 LLM 增强），再快速掠过其他较次要的。相关论文按主题分组，以控制篇幅。\n\n### AI 安全和 LLM 优化\n这些论文探讨了大型语言模型（LLMs）的安全漏洞和性能提升，主题紧跟当前热点。\n- **Trust No AI: Prompt Injection Along The CIA Security Triad（中文：别信 AI：针对 CIA 安全三要素的提示注入攻击）**  \n  作者：Johann Rehberger。论文分析了提示注入攻击如何破坏 LLM 的机密性、完整性和可用性，编译了真实案例和漏洞，强调了对 OpenAI 等主流系统的持续风险。主要贡献：提供了实用攻击示例，呼吁加强 AI 安全措施。\n  \n- **KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models（中文：KaSA：基于知识感知奇异值适配的大型语言模型）**  \n  作者：Fan Wang 等。论文提出 KaSA 方法，使用奇异值分解（SVD）动态激活任务相关知识，提升参数高效微调（PEFT）。主要发现：在 16 个基准上超越 14 个基线，适用于自然语言理解和生成任务，展示了 LLM 更高效的知识利用。\n\n- **Taming Sensitive Weights: Noise Perturbation Fine-tuning for Robust LLM Quantization（中文：驯服敏感权重：用于鲁棒 LLM 量化的噪声扰动微调）**  \n  作者：Dongwei Wang 等。论文引入 Noise Perturbation Fine-tuning（NPFT），通过扰动异常权重减少量化误差。主要贡献：提升了 LLM 如 LLaMA 的量化性能，实现了高效推理，同时保持准确性。\n\n- **Prompt Injection Along The CIA Security Triad（相关第 28 篇，PBI-Attack）**  \n  作者：Ruoxi Cheng 等。论文提出 PBI-Attack 方法，通过多模态风险分布策略绕过 LVLMs 的安全防护。主要发现：在多个开源和闭源模型上，攻击成功率达 90%，突显了视觉语言模型的易受攻击性。\n\n其他 LLM 相关论文如第 11 篇（Steering Large Language Models to Evaluate and Amplify Creativity）和第 15 篇（Can Generative AI Solve Your In-Context Learning Problem?，作者包括 David Blei）也值得关注，它们使用马氏过程分析 LLM 的不确定性，但细节较技术化，这里不展开。\n\n### 生成模型和图像处理\n这些论文优化了图像生成和处理技术，关注实际应用效率。\n- **A4-Unet: Deformable Multi-Scale Attention Network for Brain Tumor Segmentation（中文：A4-Unet：用于脑肿瘤分割的可变形多尺度注意力网络）**  \n  作者：Ruoxin Wang 等。论文提出 A4-Unet 框架，结合可变形注意力（DLKA）和空间金字塔池化（SSPP），提升脑部 MRI 图像分割精度。主要贡献：在 BraTS 2020 数据集上达到 94.4% Dice 分数，设定了新基准。\n\n- **Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation（中文：Track4Gen：通过点跟踪提升视频扩散模型的生成质量）**  \n  作者：Hyeonho Jeong 等。论文将点跟踪融入视频扩散模型，减少外观漂移问题。主要发现：生成更稳定的视频，证明了空间监督对生成模型的积极影响。\n\n其他图像生成论文如第 49 篇（Language-Guided Image Tokenization for Generation）使用语言指导图像标记，实现了高效生成，但整体影响较小，这里快速掠过。\n\n### 医疗和生物应用\n医疗相关论文实用性强，快速提炼关键点。\n- **MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training（中文：MG-3D：多粒度知识增强的 3D 医疗视觉语言预训练）**  \n  作者：Xuefeng Ni 等。论文提出多任务预训练框架，处理 3D 医疗图像和报告的语义一致性。主要贡献：在 9 个任务上提升性能，展示了大规模数据在医疗图像分析中的潜力。\n\n其他医疗论文如第 19 篇（LVS-Net: A Lightweight Vessels Segmentation Network for Retinal Image Analysis）和第 33 篇（A4-Unet 的变体）则聚焦轻量模型和分割优化，但非核心热点，故简要提及：它们改善了视网膜血管分割的效率，Dice 分数达 87%，适合资源有限的场景。\n\n### 强化学习和多代理系统\n这些论文探索了 AI 在决策中的应用，快速概述。\n- **Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution（中文：激励共生：人类-代理协同进化的范式）**  \n  作者：Tomer Jordi Chaffer 等。论文提出基于区块链的激励机制，促进人类和 AI 代理的合作。主要发现：为 Web3 和 AI 系统提供新框架，提升信任和协作。\n\n其他如第 42 篇（GL-Fusion）和第 56 篇（Policy-shaped prediction）讨论了 GNN 与 LLM 的融合和不确定性建模，但实验结果中等，这里不深入。\n\n### 其他快速掠过\n剩余论文涉及数学、物理和杂项主题，如第 23 篇（Materials-Discovery Workflows）使用符号回归优化材料发现、第 37 篇（Evolving Algebraic Multigrid Methods）探索网格方法优化，以及第 50 篇（Pre-trained protein language model for codon optimization）在生物学应用中微调模型。这些论文学术价值稳固但较专业或无明显热点，仅提炼核心：它们提供了新算法，但对一般读者影响有限。\n\n总之，今天的 arXiv 论文突显了 AI 安全和模型优化的 urgency，建议关注 LLM 领域的创新以推动实际应用。如果有特定兴趣，读者可查阅这些论文的完整摘要。明天见！",
  "papers": [
    {
      "arxiv_id": "2412.06099v2",
      "title": "DECO: Life-Cycle Management of Enterprise-Grade Copilots",
      "title_zh": "DECO：企业级 Copilots 的",
      "authors": [
        "Yiwen Zhu",
        "Mathieu Demarne",
        "Kai Deng",
        "Wenjing Wang",
        "Nutan Sahoo",
        "Divya Vermareddy",
        "Hannah Lerner",
        "Yunlei Lu",
        "Swati Bararia",
        "Anjali Bhavan",
        "William Zhang",
        "Xia Li",
        "Katherine Lin",
        "Miso Cilimdzic",
        "Subru Krishnan"
      ],
      "abstract": "Software engineers frequently grapple with the challenge of accessing\ndisparate documentation and telemetry data, including TroubleShooting Guides\n(TSGs), incident reports, code repositories, and various internal tools\ndeveloped by multiple stakeholders. While on-call duties are inevitable,\nincident resolution becomes even more daunting due to the obscurity of legacy\nsources and the pressures of strict time constraints. To enhance the efficiency\nof on-call engineers (OCEs) and streamline their daily workflows, we introduced\nDECO-a comprehensive framework for developing, deploying, and managing\nenterprise-grade copilots tailored to improve productivity in engineering\nroutines. This paper details the design and implementation of the DECO\nframework, emphasizing its innovative NL2SearchQuery functionality and a\nlightweight agentic framework. These features support efficient and customized\nretrieval-augmented-generation (RAG) algorithms that not only extract relevant\ninformation from diverse sources but also select the most pertinent skills in\nresponse to user queries. This enables the addressing of complex technical\nquestions and provides seamless, automated access to internal resources.\nAdditionally, DECO incorporates a robust mechanism for converting unstructured\nincident logs into user-friendly, structured guides, effectively bridging the\ndocumentation gap.\n  Since its launch in September 2023, DECO has demonstrated its effectiveness\nthrough widespread adoption, enabling tens of thousands of interactions and\nengaging hundreds of monthly active users (MAU) across dozens of organizations\nwithin the company.",
      "tldr_zh": "软件工程师常常面临访问分散文档和遥测数据（如 TSGs、事件报告和代码仓库）的挑战，尤其在值班时，DECO 框架应运而生，用于开发、部署和管理企业级 copilots 以提升效率。DECO 创新性地引入 NL2SearchQuery 功能和轻量级 agentic 框架，支持高效的 RAG（Retrieval-Augmented Generation）算法，从多样来源提取信息、选择相关技能，并将非结构化事件日志转换为结构化指南。实验结果显示，自 2023 年 9 月推出以来，DECO 已实现广泛采用，累计数万个互动和数百名 MAU（Monthly Active Users），显著改善了工程工作流程。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06099v2",
      "published_date": "2024-12-08 23:00:06 UTC",
      "updated_date": "2025-03-10 05:24:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:33:23.716592"
    },
    {
      "arxiv_id": "2412.06097v2",
      "title": "Order Theory in the Context of Machine Learning",
      "title_zh": "序理论在机器学习中的语境",
      "authors": [
        "Eric Dolores-Cuenca",
        "Aldo Guzman-Saenz",
        "Sangil Kim",
        "Susana Lopez-Moreno",
        "Jose Mendoza-Cortes"
      ],
      "abstract": "The paper ``Tropical Geometry of Deep Neural Networks'' by L. Zhang et al.\nintroduces an equivalence between integer-valued neural networks (IVNN) with\n$\\text{ReLU}_{t}$ and tropical rational functions, which come with a map to\npolytopes. Here, IVNN refers to a network with integer weights but real biases,\nand $\\text{ReLU}_{t}$ is defined as $\\text{ReLU}_{t}(x)=\\max(x,t)$ for\n$t\\in\\mathbb{R}\\cup\\{-\\infty\\}$.\n  For every poset with $n$ points, there exists a corresponding order polytope,\ni.e., a convex polytope in the unit cube $[0,1]^n$ whose coordinates obey the\ninequalities of the poset. We study neural networks whose associated polytope\nis an order polytope. We then explain how posets with four points induce neural\nnetworks that can be interpreted as $2\\times 2$ convolutional filters. These\nposet filters can be added to any neural network, not only IVNN.\n  Similarly to maxout, poset pooling filters update the weights of the neural\nnetwork during backpropagation with more precision than average pooling, max\npooling, or mixed pooling, without the need to train extra parameters. We\nreport experiments that support our statements.\n  We also define the structure of algebra over the operad of posets on poset\nneural networks and tropical polynomials. This formalism allows us to study the\ncomposition of poset neural network arquitectures and the effect on their\ncorresponding Newton polytopes, via the introduction of the generalization of\ntwo operations on polytopes: the Minkowski sum and the convex envelope.",
      "tldr_zh": "这篇论文探讨了序理论（order theory）在机器学习中的应用，特别将部分序（poset）和 order polytope 与神经网络相结合，研究了整数值神经网络（IVNN）与热带有理函数的等价性。作者引入了基于 poset 的 $2\\times 2$ 卷积过滤器和 poset pooling 方法，这些方法在反向传播过程中比平均 pooling、最大 pooling 或混合 pooling 更精确，且无需额外参数。实验结果支持了这些方法的优势，并通过定义 poset 神经网络的代数结构，分析了网络架构组合对 Newton polytopes 的影响，包括 Minkowski sum 和 convex envelope 的推广。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "math.CT",
        "68T07, 06A99, 68T05, 18M60, 52B11, 68Q55, 14T10, 06F99",
        "I.2.6; I.5.1"
      ],
      "primary_category": "cs.CV",
      "comment": "We added experiments with ImageNet 100, and improved the exposition\n  of the theory developed. Added examples. Poster presentation in NeurIPS WIML\n  2024, Talk in JMM 2025 section: Applied category theory II",
      "pdf_url": "http://arxiv.org/pdf/2412.06097v2",
      "published_date": "2024-12-08 22:57:41 UTC",
      "updated_date": "2025-03-04 12:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:33:39.404970"
    },
    {
      "arxiv_id": "2412.06090v1",
      "title": "Trust No AI: Prompt Injection Along The CIA Security Triad",
      "title_zh": "翻译失败",
      "authors": [
        "Johann Rehberger"
      ],
      "abstract": "The CIA security triad - Confidentiality, Integrity, and Availability - is a\ncornerstone of data and cybersecurity. With the emergence of large language\nmodel (LLM) applications, a new class of threat, known as prompt injection, was\nfirst identified in 2022. Since then, numerous real-world vulnerabilities and\nexploits have been documented in production LLM systems, including those from\nleading vendors like OpenAI, Microsoft, Anthropic and Google. This paper\ncompiles real-world exploits and proof-of concept examples, based on the\nresearch conducted and publicly documented by the author, demonstrating how\nprompt injection undermines the CIA triad and poses ongoing risks to\ncybersecurity and AI systems at large.",
      "tldr_zh": "本论文探讨了prompt injection作为一种新兴威胁，如何破坏CIA security triad（机密性、完整性和可用性），特别是在大型语言模型（LLM）应用中。该研究基于作者的公开研究，编译了真实世界的漏洞和proof-of-concept示例，展示了prompt injection在OpenAI、Microsoft等领先系统中的实际影响。结果表明，这种攻击对网络安全和AI系统构成了持续风险，强调了需要加强防护措施以维护CIA三要素的完整性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Based on research presented at Black Hat Europe 2024, Microsoft\n  Bluehat 2024 and publications from embracethered.com",
      "pdf_url": "http://arxiv.org/pdf/2412.06090v1",
      "published_date": "2024-12-08 22:46:30 UTC",
      "updated_date": "2024-12-08 22:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:33:45.359679"
    },
    {
      "arxiv_id": "2412.06088v1",
      "title": "A4-Unet: Deformable Multi-Scale Attention Network for Brain Tumor Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoxin Wang",
        "Tianyi Tang",
        "Haiming Du",
        "Yuxuan Cheng",
        "Yu Wang",
        "Lingjie Yang",
        "Xiaohui Duan",
        "Yunfang Yu",
        "Yu Zhou",
        "Donglong Chen"
      ],
      "abstract": "Brain tumor segmentation models have aided diagnosis in recent years.\nHowever, they face MRI complexity and variability challenges, including\nirregular shapes and unclear boundaries, leading to noise, misclassification,\nand incomplete segmentation, thereby limiting accuracy. To address these\nissues, we adhere to an outstanding Convolutional Neural Networks (CNNs) design\nparadigm and propose a novel network named A4-Unet. In A4-Unet, Deformable\nLarge Kernel Attention (DLKA) is incorporated in the encoder, allowing for\nimproved capture of multi-scale tumors. Swin Spatial Pyramid Pooling (SSPP)\nwith cross-channel attention is employed in a bottleneck further to study\nlong-distance dependencies within images and channel relationships. To enhance\naccuracy, a Combined Attention Module (CAM) with Discrete Cosine Transform\n(DCT) orthogonality for channel weighting and convolutional element-wise\nmultiplication is introduced for spatial weighting in the decoder. Attention\ngates (AG) are added in the skip connection to highlight the foreground while\nsuppressing irrelevant background information. The proposed network is\nevaluated on three authoritative MRI brain tumor benchmarks and a proprietary\ndataset, and it achieves a 94.4% Dice score on the BraTS 2020 dataset, thereby\nestablishing multiple new state-of-the-art benchmarks. The code is available\nhere: https://github.com/WendyWAAAAANG/A4-Unet.",
      "tldr_zh": "该论文针对脑肿瘤分割模型在MRI图像中面临的挑战，如不规则形状和模糊边界导致的噪声、误分类和不完整分割，提出了一种新型网络A4-Unet。A4-Unet在编码器中融入Deformable Large Kernel Attention (DLKA)来捕捉多尺度肿瘤，在瓶颈层使用Swin Spatial Pyramid Pooling (SSPP)结合跨通道注意力分析长距离依赖，并在解码器中添加Combined Attention Module (CAM)利用Discrete Cosine Transform (DCT)进行通道加权，以及Attention Gates (AG)来突出前景信息。实验结果显示，该网络在BraTS 2020数据集上达到94.4%的Dice score，并在多个权威MRI脑肿瘤基准数据集上建立了新的state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 14 figures, IEEE International Conference on Bioinformatics\n  and Biomedicine (BIBM) 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.06088v1",
      "published_date": "2024-12-08 22:28:53 UTC",
      "updated_date": "2024-12-08 22:28:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:34:00.606758"
    },
    {
      "arxiv_id": "2412.06087v1",
      "title": "Ethnography and Machine Learning: Synergies and New Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuofan Li",
        "Corey M. Abramson"
      ],
      "abstract": "Ethnography (social scientific methods that illuminate how people understand,\nnavigate and shape the real world contexts in which they live their lives) and\nmachine learning (computational techniques that use big data and statistical\nlearning models to perform quantifiable tasks) are each core to contemporary\nsocial science. Yet these tools have remained largely separate in practice.\nThis chapter draws on a growing body of scholarship that argues that\nethnography and machine learning can be usefully combined, particularly for\nlarge comparative studies. Specifically, this paper (a) explains the value (and\nchallenges) of using machine learning alongside qualitative field research for\ncertain types of projects, (b) discusses recent methodological trends to this\neffect, (c) provides examples that illustrate workflow drawn from several large\nprojects, and (d) concludes with a roadmap for enabling productive coevolution\nof field methods and machine learning.",
      "tldr_zh": "这篇论文探讨了Ethnography（民族志，作为社会科学方法来揭示人们如何理解、导航和塑造现实世界）和Machine Learning（机器学习，利用大数据和统计学习模型执行量化任务）的协同潜力，尽管它们在实践中通常分离。论文强调将两者结合的价值和挑战，特别是适用于大型比较研究，通过辅助定性实地研究来提升数据分析效率，并讨论了最近的方法趋势和实际工作流程示例。最终，它提供了一个路线图，旨在促进Ethnography和Machine Learning的共同演化，以推动更全面的社会科学研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.06087v1",
      "published_date": "2024-12-08 22:28:05 UTC",
      "updated_date": "2024-12-08 22:28:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:34:10.661714"
    },
    {
      "arxiv_id": "2412.06080v1",
      "title": "GVDepth: Zero-Shot Monocular Depth Estimation for Ground Vehicles based on Probabilistic Cue Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Karlo Koledic",
        "Luka Petrovic",
        "Ivan Markovic",
        "Ivan Petrovic"
      ],
      "abstract": "Generalizing metric monocular depth estimation presents a significant\nchallenge due to its ill-posed nature, while the entanglement between camera\nparameters and depth amplifies issues further, hindering multi-dataset training\nand zero-shot accuracy. This challenge is particularly evident in autonomous\nvehicles and mobile robotics, where data is collected with fixed camera setups,\nlimiting the geometric diversity. Yet, this context also presents an\nopportunity: the fixed relationship between the camera and the ground plane\nimposes additional perspective geometry constraints, enabling depth regression\nvia vertical image positions of objects. However, this cue is highly\nsusceptible to overfitting, thus we propose a novel canonical representation\nthat maintains consistency across varied camera setups, effectively\ndisentangling depth from specific parameters and enhancing generalization\nacross datasets. We also propose a novel architecture that adaptively and\nprobabilistically fuses depths estimated via object size and vertical image\nposition cues. A comprehensive evaluation demonstrates the effectiveness of the\nproposed approach on five autonomous driving datasets, achieving accurate\nmetric depth estimation for varying resolutions, aspect ratios and camera\nsetups. Notably, we achieve comparable accuracy to existing zero-shot methods,\ndespite training on a single dataset with a single-camera setup.",
      "tldr_zh": "该论文解决了单目深度估计的泛化挑战，特别是相机参数与深度纠缠导致的多数据集训练和Zero-Shot准确性问题。作者提出GVDepth框架，利用固定相机与地面的透视几何约束，通过一种新的规范表示(canonical representation)来分离深度与特定参数，提升跨数据集的泛化能力。该框架还引入了自适应概率线索融合(Probabilistic Cue Fusion)架构，融合基于物体大小和垂直图像位置的深度估计。在五个自动驾驶数据集上的全面评估中，GVDepth实现了高精度的度量深度估计，即使在不同分辨率、宽高比和相机设置下，其性能与现有Zero-Shot方法相当，尽管仅在单个数据集和相机设置上训练。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project website: https://gvdepth.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.06080v1",
      "published_date": "2024-12-08 22:04:34 UTC",
      "updated_date": "2024-12-08 22:04:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:34:26.064192"
    },
    {
      "arxiv_id": "2412.06858v2",
      "title": "Taming Sensitive Weights : Noise Perturbation Fine-tuning for Robust LLM Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Dongwei Wang",
        "Huanrui Yang"
      ],
      "abstract": "Quantization is a critical step to enable efficient LLM serving under limited\nresource. However, previous research observes that certain weights in the LLM,\nknown as outliers, are significantly sensitive to quantization noises. Existing\nquantization methods leave these outliers as floating points or higher\nprecisions to retain performance, posting challenges on the efficient hardware\ndeployment of the mixed-precision model. This work investigates an alternative\nway to tame the sensitive weights' impact on the quantization error, by\nreducing the loss Hessian trace with respect to outliers through an efficient\nfine-tuning process. We propose Noise Perturbation Fine-tuning (NPFT), which\nidentifies outlier weights and add random weight perturbations on the outliers\nas the model going through a PEFT optimization. NPFT tames the sensitivity of\noutlier weights so that the quantized model performance can be improved without\nspecial treatment to the outliers. When applied to OPT and LLaMA models, our\nNPFT method achieves stable performance improvements for both uniform and\nnon-uniform quantizers, while also offering better inference efficiency.\nNotably, the simplest RTN can achieve performance on par with GPTQ using our\nNPFT on LLaMA2-7B-4bits benchmark.",
      "tldr_zh": "这篇论文针对大型语言模型(LLM)的量化(Quantization)过程，提出了一种处理敏感权重(Outliers)的新方法，以提升模型鲁棒性和硬件部署效率。作者开发了 Noise Perturbation Fine-tuning (NPFT) 技术，通过在 PEFT 优化过程中对 Outliers 添加随机权重扰动，减少损失 Hessian trace，从而降低这些权重的量化噪声敏感性。实验结果显示，NPFT 在 OPT 和 LLaMA 模型上实现了均匀和非均匀量化器的性能稳定提升，并在 LLaMA2-7B-4bits 基准上，使简单 RTN 的表现可与 GPTQ 相当，同时提高了推理效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as poster by CPAL2025",
      "pdf_url": "http://arxiv.org/pdf/2412.06858v2",
      "published_date": "2024-12-08 21:46:22 UTC",
      "updated_date": "2025-03-15 19:35:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:34:35.495793"
    },
    {
      "arxiv_id": "2412.06071v2",
      "title": "KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models",
      "title_zh": "KaSA：知识感知奇异值适应的大型语言模型",
      "authors": [
        "Fan Wang",
        "Juyong Jiang",
        "Chansung Park",
        "Sunghun Kim",
        "Jing Tang"
      ],
      "abstract": "The increasing sizes of large language models (LLMs) result in significant\ncomputational overhead and memory usage when adapting these models to specific\ntasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have\nbeen devised to mitigate these challenges by training a small set of parameters\nfor the task-specific updates of the model weights. Among PEFT methods, LoRA\nstands out for its simplicity and efficiency, inspiring the development of a\nseries of variants. However, LoRA and its successors disregard the knowledge\nthat is noisy or irrelevant to the targeted task, detrimentally impacting model\nperformance and leading to suboptimality. To address this limitation, we\nintroduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that\nleverages singular value decomposition (SVD) with knowledge-aware singular\nvalues to dynamically activate knowledge based on its relevance to the task at\nhand. We conduct extensive experiments across a range of LLMs on tasks spanning\nnatural language understanding (NLU), generation (NLG), instruction following,\nand commonsense reasoning. The experimental results demonstrate that KaSA\nconsistently outperforms FFT and 14 popular PEFT baselines across 16 benchmarks\nand 4 synthetic datasets, underscoring our method's efficacy and adaptability.\nThe source code of our method is available at\nhttps://github.com/juyongjiang/KaSA.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的适应问题，提出了一种参数高效微调（PEFT）方法KaSA，即知识感知奇异值适应，通过奇异值分解（SVD）和知识感知奇异值，根据任务相关性动态激活相关知识，从而避免LoRA等方法忽略噪声或无关信息的局限性。KaSA在自然语言理解（NLU）、生成（NLG）、指令遵循和常识推理等任务上进行了广泛实验，结果显示它在16个基准和4个合成数据集上 consistently 超越全参数微调（FFT）和14个流行PEFT基线，证明了其高效性和适应性。该方法的源代码已公开，可进一步促进相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "The first three authors contributed equally to this work; Accepted by\n  ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.06071v2",
      "published_date": "2024-12-08 21:26:22 UTC",
      "updated_date": "2025-02-28 05:46:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:34:46.896766"
    },
    {
      "arxiv_id": "2412.06069v1",
      "title": "Fuzzy Norm-Explicit Product Quantization for Recommender Systems",
      "title_zh": "用于推荐系统的模糊范数显式产品量化",
      "authors": [
        "Mohammadreza Jamalifard",
        "Javier Andreu-Perez",
        "Hani Hagras",
        "Luis Martínez López"
      ],
      "abstract": "As the data resources grow, providing recommendations that best meet the\ndemands has become a vital requirement in business and life to overcome the\ninformation overload problem. However, building a system suggesting relevant\nrecommendations has always been a point of debate. One of the most\ncost-efficient techniques in terms of producing relevant recommendations at a\nlow complexity is Product Quantization (PQ). PQ approaches have continued\ndeveloping in recent years. This system's crucial challenge is improving\nproduct quantization performance in terms of recall measures without\ncompromising its complexity. This makes the algorithm suitable for problems\nthat require a greater number of potentially relevant items without\ndisregarding others, at high-speed and low-cost to keep up with traffic. This\nis the case of online shops where the recommendations for the purpose are\nimportant, although customers can be susceptible to scoping other products.\nThis research proposes a fuzzy approach to perform norm-based product\nquantization. Type-2 Fuzzy sets (T2FSs) define the codebook allowing\nsub-vectors (T2FSs) to be associated with more than one element of the\ncodebook, and next, its norm calculus is resolved by means of integration. Our\nmethod finesses the recall measure up, making the algorithm suitable for\nproblems that require querying at most possible potential relevant items\nwithout disregarding others. The proposed method outperforms all PQ approaches\nsuch as NEQ, PQ, and RQ up to +6%, +5%, and +8% by achieving a recall of 94%,\n69%, 59% in Netflix, Audio, Cifar60k datasets, respectively. More and over,\ncomputing time and complexity nearly equals the most computationally efficient\nexisting PQ method in the state-of-the-art.",
      "tldr_zh": "这篇论文针对推荐系统中的信息过载问题，提出了一种模糊规范显式产品量化(Fuzzy Norm-Explicit Product Quantization)方法，使用 Type-2 Fuzzy Sets (T2FSs) 定义代码书，并通过积分计算子向量的规范，以提高召回率，同时保持低复杂度。该方法允许子向量与多个代码书元素关联，从而更好地查询潜在相关项。在 Netflix、Audio 和 Cifar60k 数据集上，该方法比 NEQ、PQ 和 RQ 分别提高了 6%、5% 和 8%，实现 94%、69% 和 59% 的召回率，且计算时间和复杂度与现有最高效的 PQ 方法相当。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "68",
        "I.2; I.1"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06069v1",
      "published_date": "2024-12-08 21:14:57 UTC",
      "updated_date": "2024-12-08 21:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:35:00.003933"
    },
    {
      "arxiv_id": "2412.06061v2",
      "title": "Curse of Attention: A Kernel-Based Perspective for Why Transformers Fail to Generalize on Time Series Forecasting and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Yekun Ke",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song",
        "Chiwun Yang"
      ],
      "abstract": "The application of transformer-based models on time series forecasting (TSF)\ntasks has long been popular to study. However, many of these works fail to beat\nthe simple linear residual model, and the theoretical understanding of this\nissue is still limited. In this work, we propose the first theoretical\nexplanation of the inefficiency of transformers on TSF tasks. We attribute the\nmechanism behind it to {\\bf Asymmetric Learning} in training attention\nnetworks. When the sign of the previous step is inconsistent with the sign of\nthe current step in the next-step-prediction time series, attention fails to\nlearn the residual features. This makes it difficult to generalize on\nout-of-distribution (OOD) data, especially on the sign-inconsistent\nnext-step-prediction data, with the same representation pattern, whereas a\nlinear residual network could easily accomplish it. We hope our theoretical\ninsights provide important necessary conditions for designing the expressive\nand efficient transformer-based architecture for practitioners.",
      "tldr_zh": "这篇论文从核视角（Kernel-Based Perspective）分析了Transformer模型在时间序列预测（TSF）任务上泛化失败的原因，首次提出理论解释归因于注意力网络中的Asymmetric Learning。作者发现，当时间序列中前一步的符号与当前步骤的符号不一致时，注意力机制无法有效学习残差特征，导致模型在分布外（OOD）数据上表现不佳。相比之下，简单的线性残差网络能轻松处理这些情况。该研究为设计更具表现力和高效的Transformer架构提供了关键的必要条件。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "CPAL 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.06061v2",
      "published_date": "2024-12-08 20:29:06 UTC",
      "updated_date": "2025-02-28 20:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:35:11.436795"
    },
    {
      "arxiv_id": "2412.06060v1",
      "title": "Steering Large Language Models to Evaluate and Amplify Creativity",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Lyle Olson",
        "Neale Ratzlaff",
        "Musashi Hinck",
        "Shao-yen Tseng",
        "Vasudev Lal"
      ],
      "abstract": "Although capable of generating creative text, Large Language Models (LLMs)\nare poor judges of what constitutes \"creativity\". In this work, we show that we\ncan leverage this knowledge of how to write creatively in order to better judge\nwhat is creative. We take a mechanistic approach that extracts differences in\nthe internal states of an LLM when prompted to respond \"boringly\" or\n\"creatively\" to provide a robust measure of creativity that corresponds\nstrongly with human judgment. We also show these internal state differences can\nbe applied to enhance the creativity of generated text at inference time.",
      "tldr_zh": "本文研究发现，大型语言模型 (LLMs) 虽能生成创意文本，但对“创意”的判断能力较弱。通过一种机制方法 (mechanistic approach)，作者提取了 LLMs 在被提示“无聊地”或“创造性地”响应时的内部状态差异，从而提供一个稳健的创意度量，与人类判断高度相关。此外，这些差异可应用于推理阶段，以增强生成的文本创意。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "(Spotlight) NeurIPS 2024 Workshop on Creativity & Generative AI.\n  Authors 1 and 2 contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2412.06060v1",
      "published_date": "2024-12-08 20:28:48 UTC",
      "updated_date": "2024-12-08 20:28:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:35:26.068046"
    },
    {
      "arxiv_id": "2412.06855v4",
      "title": "Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution",
      "title_zh": "翻译失败",
      "authors": [
        "Tomer Jordi Chaffer",
        "Justin Goldston",
        "Gemach D. A. T. A. I"
      ],
      "abstract": "Cooperation is vital to our survival and progress. Evolutionary game theory\noffers a lens to understand the structures and incentives that enable\ncooperation to be a successful strategy. As artificial intelligence agents\nbecome integral to human systems, the dynamics of cooperation take on\nunprecedented significance. The convergence of human-agent teaming, contract\ntheory, and decentralized frameworks like Web3, grounded in transparency,\naccountability, and trust, offers a foundation for fostering cooperation by\nestablishing enforceable rules and incentives for humans and AI agents. We\nconceptualize Incentivized Symbiosis as a social contract between humans and\nAI, inspired by Web3 principles and encoded in blockchain technology, to define\nand enforce rules, incentives, and consequences for both parties. By exploring\nthis paradigm, we aim to catalyze new research at the intersection of systems\nthinking in AI, Web3, and society, fostering innovative pathways for\ncooperative human-agent coevolution.",
      "tldr_zh": "本研究探讨了合作在人类生存和发展中的关键作用，通过进化博弈理论(Evolutionary game theory)分析人类和AI代理的互动动态。论文提出Incentivized Symbiosis范式，这是一种基于合同理论(contract theory)和Web3原则的社会契约，利用区块链技术(blockchain technology)定义并执行规则、激励和后果，以促进人类-代理共同演化(human-agent coevolution)。这种框架强调透明、问责性和信任，旨在激发AI、Web3和社会交叉领域的创新研究，推动更高效的合作机制。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06855v4",
      "published_date": "2024-12-08 20:23:48 UTC",
      "updated_date": "2025-04-25 18:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:35:38.005859"
    },
    {
      "arxiv_id": "2412.06044v1",
      "title": "Cloud Platforms for Developing Generative AI Solutions: A Scoping Review of Tools and Services",
      "title_zh": "用于开发生成式 AI 解决方案的云平台：工具和服务范围综述",
      "authors": [
        "Dhavalkumar Patel",
        "Ganesh Raut",
        "Satya Narayan Cheetirala",
        "Girish N Nadkarni",
        "Robert Freeman",
        "Benjamin S. Glicksberg",
        "Eyal Klang",
        "Prem Timsina"
      ],
      "abstract": "Generative AI is transforming enterprise application development by enabling\nmachines to create content, code, and designs. These models, however, demand\nsubstantial computational power and data management. Cloud computing addresses\nthese needs by offering infrastructure to train, deploy, and scale generative\nAI models. This review examines cloud services for generative AI, focusing on\nkey providers like Amazon Web Services (AWS), Microsoft Azure, Google Cloud,\nIBM Cloud, Oracle Cloud, and Alibaba Cloud. It compares their strengths,\nweaknesses, and impact on enterprise growth. We explore the role of\nhigh-performance computing (HPC), serverless architectures, edge computing, and\nstorage in supporting generative AI. We also highlight the significance of data\nmanagement, networking, and AI-specific tools in building and deploying these\nmodels. Additionally, the review addresses security concerns, including data\nprivacy, compliance, and AI model protection. It assesses the performance and\ncost efficiency of various cloud providers and presents case studies from\nhealthcare, finance, and entertainment. We conclude by discussing challenges\nand future directions, such as technical hurdles, vendor lock-in,\nsustainability, and regulatory issues. Put together, this work can serve as a\nguide for practitioners and researchers looking to adopt cloud-based generative\nAI solutions, serving as a valuable guide to navigating the intricacies of this\nevolving field.",
      "tldr_zh": "这篇综述审视了云平台在开发生成式AI（Generative AI）解决方案中的工具和服务，重点比较了Amazon Web Services (AWS)、Microsoft Azure、Google Cloud、IBM Cloud、Oracle Cloud 和 Alibaba Cloud 的优势、劣势及其对企业增长的影响。研究探讨了高性能计算（HPC）、serverless architectures、edge computing 和存储等技术在支持生成式AI模型训练、部署和扩展方面的作用，同时强调了数据管理、网络工具、安全问题（如数据隐私和合规性）的关键性。最终，通过案例研究（涵盖医疗、金融和娱乐领域）和对挑战（如vendor lock-in、可持续性和监管问题）的分析，该工作为从业者和研究者提供了采用云基于生成式AI解决方案的实用指南。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.DC",
      "comment": "65 pages, 10 Figures,and supplementary methods detailing extended\n  technical descriptions, service matrices, SWOT analyses, and detailed\n  provider comparisons",
      "pdf_url": "http://arxiv.org/pdf/2412.06044v1",
      "published_date": "2024-12-08 19:49:07 UTC",
      "updated_date": "2024-12-08 19:49:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:35:50.446680"
    },
    {
      "arxiv_id": "2412.06040v1",
      "title": "The AI Double Standard: Humans Judge All AIs for the Actions of One",
      "title_zh": "翻译失败",
      "authors": [
        "Aikaterina Manoli",
        "Janet V. T. Pauketat",
        "Jacy Reese Anthis"
      ],
      "abstract": "Robots and other artificial intelligence (AI) systems are widely perceived as\nmoral agents responsible for their actions. As AI proliferates, these\nperceptions may become entangled via the moral spillover of attitudes towards\none AI to attitudes towards other AIs. We tested how the seemingly harmful and\nimmoral actions of an AI or human agent spill over to attitudes towards other\nAIs or humans in two preregistered experiments. In Study 1 (N = 720), we\nestablished the moral spillover effect in human-AI interaction by showing that\nimmoral actions increased attributions of negative moral agency (i.e., acting\nimmorally) and decreased attributions of positive moral agency (i.e., acting\nmorally) and moral patiency (i.e., deserving moral concern) to both the agent\n(a chatbot or human assistant) and the group to which they belong (all chatbot\nor human assistants). There was no significant difference in the spillover\neffects between the AI and human contexts. In Study 2 (N = 684), we tested\nwhether spillover persisted when the agent was individuated with a name and\ndescribed as an AI or human, rather than specifically as a chatbot or personal\nassistant. We found that spillover persisted in the AI context but not in the\nhuman context, possibly because AIs were perceived as more homogeneous due to\ntheir outgroup status relative to humans. This asymmetry suggests a double\nstandard whereby AIs are judged more harshly than humans when one agent morally\ntransgresses. With the proliferation of diverse, autonomous AI systems, HCI\nresearch and design should account for the fact that experiences with one AI\ncould easily generalize to perceptions of all AIs and negative HCI outcomes,\nsuch as reduced trust.",
      "tldr_zh": "本研究探讨了人类对AI的道德双重标准，即一个AI的不道德行为如何影响对其他AI的整体看法。研究通过两个预注册实验验证了moral spillover效应：在Study 1 (N=720)中，发现不道德行为会增加对代理（chatbot或人类助理）和其所属群体的负面道德归因，而AI和人类上下文无显著差异；在Study 2 (N=684)中，当代理被个体化后，溢出效应在AI上下文中持续存在，但在人类上下文中消失，可能由于AI被视为更同质的outgroup。结果显示，AI面临更严厉的判断，这突显了HCI研究和设计需考虑负面AI经历可能泛化到所有AI，导致信任降低的风险。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06040v1",
      "published_date": "2024-12-08 19:26:52 UTC",
      "updated_date": "2024-12-08 19:26:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:36:01.989913"
    },
    {
      "arxiv_id": "2412.06033v1",
      "title": "Can Generative AI Solve Your In-Context Learning Problem? A Martingale Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Jesson",
        "Nicolas Beltran-Velez",
        "David Blei"
      ],
      "abstract": "This work is about estimating when a conditional generative model (CGM) can\nsolve an in-context learning (ICL) problem. An in-context learning (ICL)\nproblem comprises a CGM, a dataset, and a prediction task. The CGM could be a\nmulti-modal foundation model; the dataset, a collection of patient histories,\ntest results, and recorded diagnoses; and the prediction task to communicate a\ndiagnosis to a new patient. A Bayesian interpretation of ICL assumes that the\nCGM computes a posterior predictive distribution over an unknown Bayesian model\ndefining a joint distribution over latent explanations and observable data.\nFrom this perspective, Bayesian model criticism is a reasonable approach to\nassess the suitability of a given CGM for an ICL problem. However, such\napproaches -- like posterior predictive checks (PPCs) -- often assume that we\ncan sample from the likelihood and posterior defined by the Bayesian model,\nwhich are not explicitly given for contemporary CGMs. To address this, we show\nwhen ancestral sampling from the predictive distribution of a CGM is equivalent\nto sampling datasets from the posterior predictive of the assumed Bayesian\nmodel. Then we develop the generative predictive $p$-value, which enables PPCs\nand their cousins for contemporary CGMs. The generative predictive $p$-value\ncan then be used in a statistical decision procedure to determine when the\nmodel is appropriate for an ICL problem. Our method only requires generating\nqueries and responses from a CGM and evaluating its response log probability.\nWe empirically evaluate our method on synthetic tabular, imaging, and natural\nlanguage ICL tasks using large language models.",
      "tldr_zh": "这篇论文探讨了条件生成模型(CGM)是否能解决in-context learning(ICL)问题，从贝叶斯视角出发，假设CGM计算后验预测分布。作者引入generative predictive p-value方法，通过证明CGM的祖先采样等价于贝叶斯模型的后验预测采样，实现对现代CGM的后验预测检查(PPCs)。该方法仅需生成查询和响应并评估响应对数概率，即可进行统计决策，评估CGM是否适合特定ICL任务。实验在合成表格、图像和自然语言任务上使用大语言模型进行了验证，展示了其有效性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06033v1",
      "published_date": "2024-12-08 19:03:21 UTC",
      "updated_date": "2024-12-08 19:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:36:15.712968"
    },
    {
      "arxiv_id": "2412.06018v1",
      "title": "Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research",
      "title_zh": "翻译失败",
      "authors": [
        "Akshat Choube",
        "Rahul Majethia",
        "Sohini Bhattacharya",
        "Vedant Das Swain",
        "Jiachen Li",
        "Varun Mishra"
      ],
      "abstract": "Longitudinal passive sensing studies for health and behavior outcomes often\nhave missing and incomplete data. Handling missing data effectively is thus a\ncritical data processing and modeling step. Our formative interviews with\nresearchers working in longitudinal health and behavior passive sensing\nrevealed a recurring theme: most researchers consider imputation a low-priority\nstep in their analysis and inference pipeline, opting to use simple and\noff-the-shelf imputation strategies without comprehensively evaluating its\nimpact on study outcomes. Through this paper, we call attention to the\nimportance of imputation. Using publicly available passive sensing datasets for\ndepression, we show that prioritizing imputation can significantly impact the\nstudy outcomes -- with our proposed imputation strategies resulting in up to\n31% improvement in AUROC to predict depression over the original imputation\nstrategy. We conclude by discussing the challenges and opportunities with\neffective imputation in longitudinal sensing studies.",
      "tldr_zh": "该研究强调了在纵向健康和行为被动感知(longitudinal passive sensing)研究中，数据插补(imputation)这一步骤的重要性，因为研究人员通常低估其影响而采用简单策略。作者通过分析公开的抑郁症数据集，比较了不同插补方法，发现其提出的策略可使预测抑郁症的AUROC提高多达31%。论文讨论了有效插补的挑战和机会，呼吁研究者更全面评估插补对研究结果的影响。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06018v1",
      "published_date": "2024-12-08 18:29:53 UTC",
      "updated_date": "2024-12-08 18:29:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:38:19.016189"
    },
    {
      "arxiv_id": "2412.06016v3",
      "title": "Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeonho Jeong",
        "Chun-Hao Paul Huang",
        "Jong Chul Ye",
        "Niloy Mitra",
        "Duygu Ceylan"
      ],
      "abstract": "While recent foundational video generators produce visually rich output, they\nstill struggle with appearance drift, where objects gradually degrade or change\ninconsistently across frames, breaking visual coherence. We hypothesize that\nthis is because there is no explicit supervision in terms of spatial tracking\nat the feature level. We propose Track4Gen, a spatially aware video generator\nthat combines video diffusion loss with point tracking across frames, providing\nenhanced spatial supervision on the diffusion features. Track4Gen merges the\nvideo generation and point tracking tasks into a single network by making\nminimal changes to existing video generation architectures. Using Stable Video\nDiffusion as a backbone, Track4Gen demonstrates that it is possible to unify\nvideo generation and point tracking, which are typically handled as separate\ntasks. Our extensive evaluations show that Track4Gen effectively reduces\nappearance drift, resulting in temporally stable and visually coherent video\ngeneration. Project page: hyeonho99.github.io/track4gen",
      "tldr_zh": "本文提出 Track4Gen，一种空间感知视频生成器，通过将视频扩散损失与点跟踪任务结合，提供增强的特征级空间监督，以解决现有视频生成模型的appearance drift问题，即对象在帧间逐渐退化或不一致。Track4Gen 通过对现有架构（如Stable Video Diffusion）进行最小改动，将视频生成和点跟踪统一到一个网络中，实现任务整合。该方法显著减少了外观漂移，提高了视频的时序稳定性和视觉连贯性，实验评估证明其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025, Project page: hyeonho99.github.io/track4gen",
      "pdf_url": "http://arxiv.org/pdf/2412.06016v3",
      "published_date": "2024-12-08 18:21:00 UTC",
      "updated_date": "2025-04-07 11:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:36:38.435278"
    },
    {
      "arxiv_id": "2412.05994v3",
      "title": "PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Namgyu Kang",
        "Jaemin Oh",
        "Youngjoon Hong",
        "Eunbyung Park"
      ],
      "abstract": "The numerical approximation of partial differential equations (PDEs) using\nneural networks has seen significant advancements through Physics-Informed\nNeural Networks (PINNs). Despite their straightforward optimization framework\nand flexibility in implementing various PDEs, PINNs often suffer from limited\naccuracy due to the spectral bias of Multi-Layer Perceptrons (MLPs), which\nstruggle to effectively learn high-frequency and nonlinear components.\nRecently, parametric mesh representations in combination with neural networks\nhave been investigated as a promising approach to eliminate the inductive bias\nof MLPs. However, they usually require high-resolution grids and a large number\nof collocation points to achieve high accuracy while avoiding overfitting. In\naddition, the fixed positions of the mesh parameters restrict their\nflexibility, making accurate approximation of complex PDEs challenging. To\novercome these limitations, we propose Physics-Informed Gaussians (PIGs), which\ncombine feature embeddings using Gaussian functions with a lightweight neural\nnetwork. Our approach uses trainable parameters for the mean and variance of\neach Gaussian, allowing for dynamic adjustment of their positions and shapes\nduring training. This adaptability enables our model to optimally approximate\nPDE solutions, unlike models with fixed parameter positions. Furthermore, the\nproposed approach maintains the same optimization framework used in PINNs,\nallowing us to benefit from their excellent properties. Experimental results\nshow the competitive performance of our model across various PDEs,\ndemonstrating its potential as a robust tool for solving complex PDEs. Our\nproject page is available at\nhttps://namgyukang.github.io/Physics-Informed-Gaussians/",
      "tldr_zh": "本研究针对Physics-Informed Neural Networks (PINNs) 在求解偏微分方程 (PDEs) 时因Multi-Layer Perceptrons (MLPs) 的谱偏差而导致的准确性不足问题，提出了一种新的方法Physics-Informed Gaussians (PIGs)。PIGs 通过结合Gaussian函数的特征嵌入和轻量级神经网络，使用可训练的均值和方差参数来动态调整网格位置和形状，从而提升了对高频和非线性成分的近似能力。实验结果显示，PIGs 在各种PDEs 上表现出竞争性的性能，同时保留了PINNs 的优化框架，为高效求解复杂PDEs 提供了稳健工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2025. Project page:\n  https://namgyukang.github.io/Physics-Informed-Gaussians/",
      "pdf_url": "http://arxiv.org/pdf/2412.05994v3",
      "published_date": "2024-12-08 16:58:29 UTC",
      "updated_date": "2025-03-18 14:17:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:36:51.459459"
    },
    {
      "arxiv_id": "2412.05968v1",
      "title": "LVS-Net: A Lightweight Vessels Segmentation Network for Retinal Image Analysis",
      "title_zh": "LVS-Net：一种轻量级视网膜血管分割网络用于图像分析",
      "authors": [
        "Mehwish Mehmood",
        "Shahzaib Iqbal",
        "Tariq Mahmood Khan",
        "Ivor Spence",
        "Muhammad Fahim"
      ],
      "abstract": "The analysis of retinal images for the diagnosis of various diseases is one\nof the emerging areas of research. Recently, the research direction has been\ninclined towards investigating several changes in retinal blood vessels in\nsubjects with many neurological disorders, including dementia. This research\nfocuses on detecting diseases early by improving the performance of models for\nsegmentation of retinal vessels with fewer parameters, which reduces\ncomputational costs and supports faster processing. This paper presents a novel\nlightweight encoder-decoder model that segments retinal vessels to improve the\nefficiency of disease detection. It incorporates multi-scale convolutional\nblocks in the encoder to accurately identify vessels of various sizes and\nthicknesses. The bottleneck of the model integrates the Focal Modulation\nAttention and Spatial Feature Refinement Blocks to refine and enhance essential\nfeatures for efficient segmentation. The decoder upsamples features and\nintegrates them with the corresponding feature in the encoder using skip\nconnections and the spatial feature refinement block at every upsampling stage\nto enhance feature representation at various scales. The estimated computation\ncomplexity of our proposed model is around 29.60 GFLOP with 0.71 million\nparameters and 2.74 MB of memory size, and it is evaluated using public\ndatasets, that is, DRIVE, CHASE\\_DB, and STARE. It outperforms existing models\nwith dice scores of 86.44\\%, 84.22\\%, and 87.88\\%, respectively.",
      "tldr_zh": "本文提出LVS-Net，一种轻量级视网膜血管分割网络，旨在通过减少参数数量（约0.71百万）和计算复杂度（29.60 GFLOP）来提升疾病早期检测效率，特别是针对神经系统疾病如痴呆。模型在编码器中使用多尺度卷积块识别不同大小的血管，并在瓶颈层整合Focal Modulation Attention和Spatial Feature Refinement Blocks来提炼关键特征；解码器则通过跳跃连接和空间特征提炼块增强多尺度特征表示。实验结果显示，在DRIVE、CHASE_DB和STARE数据集上，LVS-Net分别获得86.44%、84.22%和87.88%的Dice分数，优于现有模型。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05968v1",
      "published_date": "2024-12-08 15:21:37 UTC",
      "updated_date": "2024-12-08 15:21:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:37:05.650819"
    },
    {
      "arxiv_id": "2412.06853v3",
      "title": "Tube Loss: A Novel Approach for Prediction Interval Estimation and probabilistic forecasting",
      "title_zh": "Tube Loss：一种用于预测区间估计和概率预测的新颖方法",
      "authors": [
        "Pritam Anand",
        "Tathagata Bandyopadhyay",
        "Suresh Chandra"
      ],
      "abstract": "This paper proposes a novel loss function, called 'Tube Loss', for\nsimultaneous estimation of bounds of a Prediction Interval (PI) in the\nregression setup. The PIs obtained by minimizing the empirical risk based on\nthe Tube Loss are shown to be of better quality than the PIs obtained by the\nexisting methods in the following sense. First, it yields intervals that attain\nthe prespecified confidence level t $\\in$ (0,1) asymptotically. A theoretical\nproof of this fact is given. Secondly, the user is allowed to move the interval\nup or down by controlling the value of a parameter. This helps the user to\nchoose a PI capturing denser regions of the probability distribution of the\nresponse variable inside the interval, and thus, sharpening its width. This is\nshown to be especially useful when the conditional distribution of the response\nvariable is skewed. Further, the Tube Loss based PI estimation method can\ntrade-off between the coverage and the average width by solving a single\noptimization problem. It enables further reduction of the average width of PI\nthrough re-calibration. Also, unlike a few existing PI estimation methods the\ngradient descent (GD) method can be used for minimization of empirical risk.\nThrough extensive experiments, we demonstrate the effectiveness of Tube\nLoss-based PI estimation in both kernel machines and neural networks.\nAdditionally, we show that Tube Loss-based deep probabilistic forecasting\nmodels achieve superior performance compared to existing probabilistic\nforecasting techniques across several benchmark and wind datasets. Finally, we\nempirically validate the advantages of the Tube loss approach within the\nconformal prediction framework. Codes are available at\nhttps://github.com/ltpritamanand/Tube$\\_$loss.",
      "tldr_zh": "本文提出了一种新颖的损失函数 Tube Loss，用于回归设置中预测区间（PI）的边界估计和概率预测。该方法能实现预设置信水平 t（0到1之间）的渐近覆盖，并允许用户通过参数调整来上下移动区间，从而优化宽度、捕捉响应变量概率分布的密集区域，尤其在分布偏斜时效果显著。与现有方法相比，Tube Loss 通过单一优化问题权衡覆盖率和平均宽度，并支持梯度下降最小化。实验验证显示，该方法在核机器、神经网络以及基准和风力数据集上的概率预测中，均优于现有技术，并在保形预测框架中展现出优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06853v3",
      "published_date": "2024-12-08 15:17:53 UTC",
      "updated_date": "2025-05-17 14:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:37:15.465871"
    },
    {
      "arxiv_id": "2412.05967v1",
      "title": "Language hooks: a modular framework for augmenting LLM reasoning that decouples tool usage from the model and its prompt",
      "title_zh": "Language hooks：一种模块化框架，用于增强 LLM 推理，将工具使用从模型及其",
      "authors": [
        "Damien de Mijolla",
        "Wen Yang",
        "Philippa Duckett",
        "Christopher Frye",
        "Mark Worrall"
      ],
      "abstract": "Prompting and fine-tuning have emerged as two competing paradigms for\naugmenting language models with new capabilities, such as the use of tools.\nPrompting approaches are quick to set up but rely on providing explicit\ndemonstrations of each tool's usage in the model's prompt, thus coupling tool\nuse to the task at hand and limiting generalisation. Fine-tuning removes the\nneed for task-specific demonstrations of tool usage at runtime; however, this\nties new capabilities to a single model, thus making already-heavier setup\ncosts a recurring expense. In this paper, we introduce language hooks, a novel\nframework for augmenting language models with new capabilities that is\ndecoupled both from the model's task-specific prompt and from the model itself.\nThe language hook algorithm interleaves text generation by the base model with\nthe execution of modular programs that trigger conditionally based on the\nexisting text and the available capabilities. Upon triggering, programs may\ncall external tools, auxiliary language models (e.g. using tool specific\nprompts), and modify the existing context. We benchmark our method against\nstate-of-the-art baselines, find that it outperforms task-aware approaches, and\ndemonstrate its ability to generalise to novel tasks.",
      "tldr_zh": "本文提出 language hooks，一种模块化框架，用于增强LLM推理，将工具使用从模型及其prompt中解耦，从而克服prompting和fine-tuning方法的局限性。prompting方法依赖任务特定的工具演示，导致耦合和泛化性差，而fine-tuning虽省去运行时演示，却绑定到单一模型增加开销。该框架通过language hooks算法交替文本生成与条件触发的模块化程序，允许程序调用外部工具、辅助语言模型并修改上下文。实验基准测试显示，该方法优于现有基线，并在新型任务上表现出色泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "This work was conducted during Summer 2023. Experimental results and\n  references reflect the state of the field at that time and may not account\n  for subsequent developments",
      "pdf_url": "http://arxiv.org/pdf/2412.05967v1",
      "published_date": "2024-12-08 15:16:17 UTC",
      "updated_date": "2024-12-08 15:16:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:38:33.660300"
    },
    {
      "arxiv_id": "2412.14186v2",
      "title": "Towards AI-$45^{\\circ}$ Law: A Roadmap to Trustworthy AGI",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Yang",
        "Chaochao Lu",
        "Yingchun Wang",
        "Bowen Zhou"
      ],
      "abstract": "Ensuring Artificial General Intelligence (AGI) reliably avoids harmful\nbehaviors is a critical challenge, especially for systems with high autonomy or\nin safety-critical domains. Despite various safety assurance proposals and\nextreme risk warnings, comprehensive guidelines balancing AI safety and\ncapability remain lacking. In this position paper, we propose the\n\\textit{AI-\\textbf{$45^{\\circ}$} Law} as a guiding principle for a balanced\nroadmap toward trustworthy AGI, and introduce the \\textit{Causal Ladder of\nTrustworthy AGI} as a practical framework. This framework provides a systematic\ntaxonomy and hierarchical structure for current AI capability and safety\nresearch, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder\ncomprises three core layers: the Approximate Alignment Layer, the Intervenable\nLayer, and the Reflectable Layer. These layers address the key challenges of\nsafety and trustworthiness in AGI and contemporary AI systems. Building upon\nthis framework, we define five levels of trustworthy AGI: perception,\nreasoning, decision-making, autonomy, and collaboration trustworthiness. These\nlevels represent distinct yet progressive aspects of trustworthy AGI. Finally,\nwe present a series of potential governance measures to support the development\nof trustworthy AGI.",
      "tldr_zh": "这篇论文提出 AI-$45^{\\circ}$ Law 作为平衡人工智能安全性和能力的指导原则，旨在为可信赖的 AGI（Artificial General Intelligence）发展提供路线图。论文引入 Causal Ladder of Trustworthy AGI 框架，受 Judea Pearl's ``Ladder of Causation'' 启发，该框架包括三个核心层：Approximate Alignment Layer、Intervenable Layer 和 Reflectable Layer，以系统化处理 AGI 的安全和可信性挑战。基于此框架，论文定义了五个可信 AGI 级别：perception、reasoning、decision-making、autonomy 和 collaboration trustworthiness，这些级别代表可信 AGI 的渐进方面。最后，论文建议了一系列潜在的治理措施，以支持可信 AGI 的可靠发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14186v2",
      "published_date": "2024-12-08 14:14:16 UTC",
      "updated_date": "2024-12-22 08:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:38:47.041702"
    },
    {
      "arxiv_id": "2412.05947v1",
      "title": "Materials-Discovery Workflows Guided by Symbolic Regression: Identifying Acid-Stable Oxides for Electrocatalysis",
      "title_zh": "翻译失败",
      "authors": [
        "Akhil S. Nair",
        "Lucas Foppa",
        "Matthias Scheffler"
      ],
      "abstract": "The efficiency of active learning (AL) approaches to identify materials with\ndesired properties relies on the knowledge of a few parameters describing the\nproperty. However, these parameters are unknown if the property is governed by\na high intricacy of many atomistic processes. Here, we develop an AL workflow\nbased on the sure-independence screening and sparsifying operator (SISSO)\nsymbolic-regression approach. SISSO identifies the few, key parameters\ncorrelated with a given materials property via analytical expressions, out of\nmany offered primary features. Crucially, we train ensembles of SISSO models in\norder to quantify mean predictions and their uncertainty, enabling the use of\nSISSO in AL. By combining bootstrap sampling to obtain training datasets with\nMonte-Carlo feature dropout, the high prediction errors observed by a single\nSISSO model are improved. Besides, the feature dropout procedure alleviates the\noverconfidence issues observed in the widely used bagging approach. We\ndemonstrate the SISSO-guided AL workflow by identifying acid-stable oxides for\nwater splitting using high-quality DFT-HSE06 calculations. From a pool of 1470\nmaterials, 12 acid-stable materials are identified in only 30 AL iterations.\nThe materials property maps provided by SISSO along with the uncertainty\nestimates reduce the risk of missing promising portions of the materials space\nthat were overlooked in the initial, possibly biased dataset.",
      "tldr_zh": "本研究开发了一种基于 Symbolic Regression 的 Active Learning (AL) 工作流，使用 Sure-Independence Screening and Sparsifying Operator (SISSO) 来识别与材料属性相关的关键参数，从而解决属性由复杂原子过程驱动时的挑战。 通过训练 SISSO 模型集合，结合 bootstrap sampling 和 Monte-Carlo feature dropout，显著改善了预测准确性和不确定性量化，缓解了过自信问题。 该工作流应用于识别酸稳定氧化物用于水分解 electrocatalysis，通过 DFT-HSE06 计算，从 1470 种材料中仅用 30 次 AL 迭代就筛选出 12 种候选材料，并通过属性映射和不确定性估计减少了遗漏有前景材料空间的风险。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.05947v1",
      "published_date": "2024-12-08 14:09:15 UTC",
      "updated_date": "2024-12-08 14:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:38:56.969610"
    },
    {
      "arxiv_id": "2412.05937v1",
      "title": "Accelerating Manufacturing Scale-Up from Material Discovery Using Agentic Web Navigation and Retrieval-Augmented AI for Process Engineering Schematics Design",
      "title_zh": "翻译失败",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Akash Das",
        "Shivam Gupta",
        "Venkataramana Runkana"
      ],
      "abstract": "Process Flow Diagrams (PFDs) and Process and Instrumentation Diagrams (PIDs)\nare critical tools for industrial process design, control, and safety. However,\nthe generation of precise and regulation-compliant diagrams remains a\nsignificant challenge, particularly in scaling breakthroughs from material\ndiscovery to industrial production in an era of automation and digitalization.\nThis paper introduces an autonomous agentic framework to address these\nchallenges through a twostage approach involving knowledge acquisition and\ngeneration. The framework integrates specialized sub-agents for retrieving and\nsynthesizing multimodal data from publicly available online sources and\nconstructs ontological knowledge graphs using a Graph Retrieval-Augmented\nGeneration (Graph RAG) paradigm. These capabilities enable the automation of\ndiagram generation and open-domain question answering (ODQA) tasks with high\ncontextual accuracy. Extensive empirical experiments demonstrate the frameworks\nability to deliver regulation-compliant diagrams with minimal expert\nintervention, highlighting its practical utility for industrial applications.",
      "tldr_zh": "本研究提出了一种自主代理框架，用于加速从材料发现到工业生产的制造规模化过程，针对Process Flow Diagrams (PFDs) 和Process and Instrumentation Diagrams (PIDs) 的生成挑战。该框架采用两阶段方法，包括知识获取（通过子代理检索和合成在线多模态数据）和生成（利用Graph Retrieval-Augmented Generation (Graph RAG)构建本体知识图谱），从而实现自动化图表生成和开放域问答(ODQA)任务，并确保高上下文准确性。实验结果表明，该框架能生成符合法规的图表，显著减少专家干预，提升工业应用的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05937v1",
      "published_date": "2024-12-08 13:36:42 UTC",
      "updated_date": "2024-12-08 13:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:41:02.014779"
    },
    {
      "arxiv_id": "2412.05934v2",
      "title": "Heuristic-Induced Multimodal Risk Distribution Jailbreak Attack for Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ma Teng",
        "Jia Xiaojun",
        "Duan Ranjie",
        "Li Xinfeng",
        "Huang Yihao",
        "Chu Zhixuan",
        "Liu Yang",
        "Ren Wenqi"
      ],
      "abstract": "With the rapid advancement of multimodal large language models (MLLMs),\nconcerns regarding their security have increasingly captured the attention of\nboth academia and industry. Although MLLMs are vulnerable to jailbreak attacks,\ndesigning effective multimodal jailbreak attacks poses unique challenges,\nespecially given the distinct protective measures implemented across various\nmodalities in commercial models. Previous works concentrate risks into a single\nmodality, resulting in limited jailbreak performance. In this paper, we propose\na heuristic-induced multimodal risk distribution jailbreak attack method,\ncalled HIMRD, which consists of two elements: multimodal risk distribution\nstrategy and heuristic-induced search strategy. The multimodal risk\ndistribution strategy is used to segment harmful instructions across multiple\nmodalities to effectively circumvent MLLMs' security protection. The\nheuristic-induced search strategy identifies two types of prompts: the\nunderstanding-enhancing prompt, which helps the MLLM reconstruct the malicious\nprompt, and the inducing prompt, which increases the likelihood of affirmative\noutputs over refusals, enabling a successful jailbreak attack. Extensive\nexperiments demonstrate that this approach effectively uncovers vulnerabilities\nin MLLMs, achieving an average attack success rate of 90% across seven popular\nopen-source MLLMs and an average attack success rate of around 68% in three\npopular closed-source MLLMs. Our code will coming soon. Warning: This paper\ncontains offensive and harmful examples, reader discretion is advised.",
      "tldr_zh": "这篇论文提出了一种针对多模态大语言模型（MLLMs）的启发式诱导多模态风险分布监狱突破攻击方法（HIMRD），旨在解决现有攻击方法集中在单一模态导致的效果有限问题。HIMRD 包括多模态风险分布策略，将有害指令分布到多个模态中以绕过安全保护，以及启发式诱导搜索策略，通过理解增强提示（重构恶意提示）和诱导提示（增加肯定输出概率）来提升攻击效率。实验结果显示，该方法在七个流行开源 MLLMs 上平均攻击成功率达90%，在三个闭源 MLLMs 上约68%，有效暴露了这些模型的漏洞。警告：论文包含 offensive 和 harmful 示例，建议审慎阅读。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05934v2",
      "published_date": "2024-12-08 13:20:45 UTC",
      "updated_date": "2025-01-03 08:54:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:39:24.595553"
    },
    {
      "arxiv_id": "2412.05897v1",
      "title": "Detecting Discrepancies Between AI-Generated and Natural Images Using Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Nie",
        "Yonggang Zhang",
        "Tongliang Liu",
        "Yiu-ming Cheung",
        "Bo Han",
        "Xinmei Tian"
      ],
      "abstract": "In this work, we propose a novel approach for detecting AI-generated images\nby leveraging predictive uncertainty to mitigate misuse and associated risks.\nThe motivation arises from the fundamental assumption regarding the\ndistributional discrepancy between natural and AI-generated images. The\nfeasibility of distinguishing natural images from AI-generated ones is grounded\nin the distribution discrepancy between them. Predictive uncertainty offers an\neffective approach for capturing distribution shifts, thereby providing\ninsights into detecting AI-generated images. Namely, as the distribution shift\nbetween training and testing data increases, model performance typically\ndegrades, often accompanied by increased predictive uncertainty. Therefore, we\npropose to employ predictive uncertainty to reflect the discrepancies between\nAI-generated and natural images. In this context, the challenge lies in\nensuring that the model has been trained over sufficient natural images to\navoid the risk of determining the distribution of natural images as that of\ngenerated images. We propose to leverage large-scale pre-trained models to\ncalculate the uncertainty as the score for detecting AI-generated images. This\nleads to a simple yet effective method for detecting AI-generated images using\nlarge-scale vision models: images that induce high uncertainty are identified\nas AI-generated. Comprehensive experiments across multiple benchmarks\ndemonstrate the effectiveness of our method.",
      "tldr_zh": "本文提出了一种利用预测不确定性（predictive uncertainty）检测 AI 生成图像的新方法，以缓解其滥用风险。该方法基于自然图像和 AI 生成图像之间的分布差异（distribution discrepancy），通过大规模预训练模型计算不确定性分数，将高不确定性图像识别为 AI 生成的。实验结果显示，该方法在多个基准上表现出色，有效捕捉了分布偏移并提升了检测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05897v1",
      "published_date": "2024-12-08 11:32:25 UTC",
      "updated_date": "2024-12-08 11:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:39:31.843909"
    },
    {
      "arxiv_id": "2412.05893v1",
      "title": "doScenes: An Autonomous Driving Dataset with Natural Language Instruction for Human Interaction and Vision-Language Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Parthib Roy",
        "Srinivasa Perisetla",
        "Shashank Shriram",
        "Harsha Krishnaswamy",
        "Aryan Keskar",
        "Ross Greer"
      ],
      "abstract": "Human-interactive robotic systems, particularly autonomous vehicles (AVs),\nmust effectively integrate human instructions into their motion planning. This\npaper introduces doScenes, a novel dataset designed to facilitate research on\nhuman-vehicle instruction interactions, focusing on short-term directives that\ndirectly influence vehicle motion. By annotating multimodal sensor data with\nnatural language instructions and referentiality tags, doScenes bridges the gap\nbetween instruction and driving response, enabling context-aware and adaptive\nplanning. Unlike existing datasets that focus on ranking or scene-level\nreasoning, doScenes emphasizes actionable directives tied to static and dynamic\nscene objects. This framework addresses limitations in prior research, such as\nreliance on simulated data or predefined action sets, by supporting nuanced and\nflexible responses in real-world scenarios. This work lays the foundation for\ndeveloping learning strategies that seamlessly integrate human instructions\ninto autonomous systems, advancing safe and effective human-vehicle\ncollaboration for vision-language navigation. We make our data publicly\navailable at https://www.github.com/rossgreer/doScenes",
      "tldr_zh": "本研究引入了 doScenes 数据集，这是一个专为人类-车辆交互设计的自动驾驶数据集，专注于将自然语言指令整合到运动规划中，以支持视觉语言导航。数据集通过对多模态传感器数据进行标注，包括自然语言指令和参照性标签，从而桥接指令与驾驶响应的关联，并强调与静态和动态场景对象的可操作指令。相较于现有数据集，doScenes 克服了依赖模拟数据或预定义动作集的局限，支持真实场景中的灵活响应，并为开发安全有效的人类-车辆协作学习策略奠定基础。该数据集已公开可用于 GitHub。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05893v1",
      "published_date": "2024-12-08 11:16:47 UTC",
      "updated_date": "2024-12-08 11:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:39:46.071655"
    },
    {
      "arxiv_id": "2412.05892v3",
      "title": "PBI-Attack: Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack for Toxicity Maximization",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoxi Cheng",
        "Yizhong Ding",
        "Shuirong Cao",
        "Ranjie Duan",
        "Xiaoshuang Jia",
        "Shaowei Yuan",
        "Zhiqiang Wang",
        "Xiaojun Jia"
      ],
      "abstract": "Understanding the vulnerabilities of Large Vision Language Models (LVLMs) to\njailbreak attacks is essential for their responsible real-world deployment.\nMost previous work requires access to model gradients, or is based on human\nknowledge (prompt engineering) to complete jailbreak, and they hardly consider\nthe interaction of images and text, resulting in inability to jailbreak in\nblack box scenarios or poor performance. To overcome these limitations, we\npropose a Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack for\ntoxicity maximization, referred to as PBI-Attack. Our method begins by\nextracting malicious features from a harmful corpus using an alternative LVLM\nand embedding these features into a benign image as prior information.\nSubsequently, we enhance these features through bidirectional cross-modal\ninteraction optimization, which iteratively optimizes the bimodal perturbations\nin an alternating manner through greedy search, aiming to maximize the toxicity\nof the generated response. The toxicity level is quantified using a\nwell-trained evaluation model. Experiments demonstrate that PBI-Attack\noutperforms previous state-of-the-art jailbreak methods, achieving an average\nattack success rate of 92.5% across three open-source LVLMs and around 67.3% on\nthree closed-source LVLMs. Disclaimer: This paper contains potentially\ndisturbing and offensive content.",
      "tldr_zh": "这篇论文提出了 PBI-Attack，一种 Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack，旨在最大化 Large Vision Language Models (LVLMs) 的毒性输出，同时克服现有方法对模型梯度依赖或忽略图像和文本交互的局限性。方法首先从有害语料中提取恶意特征并嵌入到 benign image 中作为 prior information，然后通过 bidirectional cross-modal interaction optimization 和贪婪搜索(iteratively optimizes the bimodal perturbations)来增强这些特征，并使用训练好的评估模型量化毒性水平。实验结果显示，PBI-Attack 在三个开源 LVLMs 上平均攻击成功率达 92.5%，在三个闭源 LVLMs 上达 67.3%，显著优于现有最先进方法，并强调了模型在黑盒场景下的易受攻击风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack for\n  Toxicity Maximization",
      "pdf_url": "http://arxiv.org/pdf/2412.05892v3",
      "published_date": "2024-12-08 11:14:16 UTC",
      "updated_date": "2025-02-03 11:44:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:41:50.073859"
    },
    {
      "arxiv_id": "2412.10413v1",
      "title": "Evaluating Robustness of LLMs on Crisis-Related Microblogs across Events, Information Types, and Linguistic Features",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Imran",
        "Abdul Wahab Ziaullah",
        "Kai Chen",
        "Ferda Ofli"
      ],
      "abstract": "The widespread use of microblogging platforms like X (formerly Twitter)\nduring disasters provides real-time information to governments and response\nauthorities. However, the data from these platforms is often noisy, requiring\nautomated methods to filter relevant information. Traditionally, supervised\nmachine learning models have been used, but they lack generalizability. In\ncontrast, Large Language Models (LLMs) show better capabilities in\nunderstanding and processing natural language out of the box. This paper\nprovides a detailed analysis of the performance of six well-known LLMs in\nprocessing disaster-related social media data from a large-set of real-world\nevents. Our findings indicate that while LLMs, particularly GPT-4o and GPT-4,\noffer better generalizability across different disasters and information types,\nmost LLMs face challenges in processing flood-related data, show minimal\nimprovement despite the provision of examples (i.e., shots), and struggle to\nidentify critical information categories like urgent requests and needs.\nAdditionally, we examine how various linguistic features affect model\nperformance and highlight LLMs' vulnerabilities against certain features like\ntypos. Lastly, we provide benchmarking results for all events across both zero-\nand few-shot settings and observe that proprietary models outperform\nopen-source ones in all tasks.",
      "tldr_zh": "这篇论文评估了六种大型语言模型(LLMs)在处理灾害相关微博数据时的鲁棒性，涵盖不同事件、信息类型和语言特征。研究发现，GPT-4o和GPT-4在跨灾害和信息类型的泛化性上表现出色，但大多数LLMs在处理洪水相关数据、识别紧急请求和需求时存在困难，且提供示例（few-shot）后改进有限。论文还突出了语言特征如拼写错误对模型性能的负面影响，并通过基准测试结果表明，专有模型在zero-shot和few-shot设置中优于开源模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 10 figs, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.10413v1",
      "published_date": "2024-12-08 10:30:29 UTC",
      "updated_date": "2024-12-08 10:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:40:12.362736"
    },
    {
      "arxiv_id": "2412.06852v1",
      "title": "EGEAN: An Exposure-Guided Embedding Alignment Network for Post-Click Conversion Estimation",
      "title_zh": "EGEAN：一种基于曝光引导的嵌入对齐网络，用于点击后转化估计",
      "authors": [
        "Huajian Feng",
        "Guoxiao Zhang",
        "Yadong Zhang",
        "Yi We",
        "Qiang Liu"
      ],
      "abstract": "Accurate post-click conversion rate (CVR) estimation is crucial for online\nadvertising systems. Despite significant advances in causal approaches designed\nto address the Sample Selection Bias problem, CVR estimation still faces\nchallenges due to Covariate Shift. Given the intrinsic connection between the\ndistribution of covariates in the click and non-click spaces, this study\nproposes an Exposure-Guided Embedding Alignment Network (EGEAN) to address\nestimation bias caused by covariate shift. Additionally, we propose a Parameter\nVarying Doubly Robust Estimator with steady-state control to handle small\npropensities better. Online A/B tests conducted on the Meituan advertising\nsystem demonstrate that our method significantly outperforms baseline models\nwith respect to CVR and GMV, validating its effectiveness. Code is available:\nhttps://github.com/hydrogen-maker/EGEAN.",
      "tldr_zh": "这篇论文针对在线广告系统的后点击转化率 (CVR) 估计问题，提出了一种 Exposure-Guided Embedding Alignment Network (EGEAN) 方法，以解决协变量偏移 (Covariate Shift) 带来的估计偏差。该方法利用暴露引导的嵌入对齐技术，结合 Parameter Varying Doubly Robust Estimator 来更好地处理小倾向性问题。通过在 Meituan 广告系统的在线 A/B 测试，EGEAN 显著提高了 CVR 和 GMV 指标，验证了其有效性。代码已开源：https://github.com/hydrogen-maker/EGEAN。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.06852v1",
      "published_date": "2024-12-08 10:17:02 UTC",
      "updated_date": "2024-12-08 10:17:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:40:22.024872"
    },
    {
      "arxiv_id": "2412.05882v1",
      "title": "Towards Modeling Data Quality and Machine Learning Model Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Usman Anjum",
        "Chris Trentman",
        "Elrod Caden",
        "Justin Zhan"
      ],
      "abstract": "Understanding the effect of uncertainty and noise in data on machine learning\nmodels (MLM) is crucial in developing trust and measuring performance. In this\npaper, a new model is proposed to quantify uncertainties and noise in data on\nMLMs. Using the concept of signal-to-noise ratio (SNR), a new metric called\ndeterministic-non-deterministic ratio (DDR) is proposed to formulate\nperformance of a model. Using synthetic data in experiments, we show how\naccuracy can change with DDR and how we can use DDR-accuracy curves to\ndetermine performance of a model.",
      "tldr_zh": "该论文探讨了数据中的不确定性和噪声对机器学习模型（MLM）性能的影响，提出一个新模型来量化这些因素。论文引入了确定性-非确定性比率（DDR）指标，基于信号噪声比（SNR）概念，以评估模型的性能。通过合成数据实验，研究者展示了准确率如何随DDR变化，并提出使用DDR-准确率曲线来确定模型的可靠性和表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05882v1",
      "published_date": "2024-12-08 10:15:10 UTC",
      "updated_date": "2024-12-08 10:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:42:03.854056"
    },
    {
      "arxiv_id": "2412.05881v1",
      "title": "3D-Consistent Image Inpainting with Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Leonid Antsfeld",
        "Boris Chidlovskii"
      ],
      "abstract": "We address the problem of 3D inconsistency of image inpainting based on\ndiffusion models. We propose a generative model using image pairs that belong\nto the same scene. To achieve the 3D-consistent and semantically coherent\ninpainting, we modify the generative diffusion model by incorporating an\nalternative point of view of the scene into the denoising process. This creates\nan inductive bias that allows to recover 3D priors while training to denoise in\n2D, without explicit 3D supervision. Training unconditional diffusion models\nwith additional images as in-context guidance allows to harmonize the masked\nand non-masked regions while repainting and ensures the 3D consistency. We\nevaluate our method on one synthetic and three real-world datasets and show\nthat it generates semantically coherent and 3D-consistent inpaintings and\noutperforms the state-of-art methods.",
      "tldr_zh": "本文提出了一种基于diffusion models的3D-consistent图像修复方法，通过使用同一场景的图像对来解决传统修复中的3D不一致性问题。具体而言，该方法在去噪过程中融入场景的另一个视角作为上下文指导，创建归纳偏差以恢复3D先验，而无需显式3D监督，从而确保修复区域与非修复区域的语义连贯和和谐。实验在一个合成数据集和三个真实世界数据集上验证了该方法的有效性，其生成的修复结果在3D一致性和语义质量上均优于现有最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 9 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.05881v1",
      "published_date": "2024-12-08 10:07:07 UTC",
      "updated_date": "2024-12-08 10:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:42:16.055573"
    },
    {
      "arxiv_id": "2412.05876v1",
      "title": "MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training",
      "title_zh": "MG-3D：多粒度知识增强的3D医疗视觉-语言预训练",
      "authors": [
        "Xuefeng Ni",
        "Linshan Wu",
        "Jiaxin Zhuang",
        "Qiong Wang",
        "Mingxiang Wu",
        "Varut Vardhanabhuti",
        "Lihai Zhang",
        "Hanyu Gao",
        "Hao Chen"
      ],
      "abstract": "3D medical image analysis is pivotal in numerous clinical applications.\nHowever, the scarcity of labeled data and limited generalization capabilities\nhinder the advancement of AI-empowered models. Radiology reports are easily\naccessible and can serve as weakly-supervised signals. However, large-scale\nvision-language pre-training (VLP) remains underexplored in 3D medical image\nanalysis. Specifically, the insufficient investigation into multi-grained\nradiology semantics and their correlations across patients leads to\nunderutilization of large-scale volume-report data.\n  Considering intra-patient cross-modal semantic consistency and inter-patient\nsemantic correlations, we propose a multi-task VLP method, MG-3D, pre-trained\non large-scale data (47.1K), addressing the challenges by the following two\naspects: 1) Establishing the correspondence between volume semantics and\nmulti-grained medical knowledge of each patient with cross-modal global\nalignment and complementary modality-guided local reconstruction, ensuring\nintra-patient features of different modalities cohesively represent the same\nsemantic content; 2) Correlating inter-patient visual semantics based on\nfine-grained report correlations across patients, and keeping sensitivity to\nglobal individual differences via contrastive learning, enhancing the\ndiscriminative feature representation. Furthermore, we delve into the scaling\nlaw to explore potential performance improvements. Comprehensive evaluations\nacross nine uni- and cross-modal clinical tasks are carried out to assess model\nefficacy. Extensive experiments on both internal and external datasets\ndemonstrate the superior transferability, scalability, and generalization of\nMG-3D, showcasing its potential in advancing feature representation for 3D\nmedical image analysis. Code will be available:\nhttps://github.com/Xuefeng-Ni/MG-3D.",
      "tldr_zh": "该研究提出 MG-3D，一种多粒度知识增强的 3D 医疗视觉语言预训练（VLP）方法，旨在解决 3D 医疗图像分析中数据标注稀缺和泛化能力有限的问题，通过利用放射学报告作为弱监督信号。MG-3D 通过跨模态全局对齐、互补模态引导的局部重建以及基于患者间细粒度报告相关性的对比学习，建立了患者内语义一致性和患者间视觉语义关联，提升了特征表示的判别性和鲁棒性。实验在九个单模和跨模临床任务上显示，MG-3D 在大规模数据（47.1K）上预训练后，表现出优越的迁移性、可扩展性和泛化性，为 3D 医疗图像分析提供了先进的特征表示框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 Pages",
      "pdf_url": "http://arxiv.org/pdf/2412.05876v1",
      "published_date": "2024-12-08 09:45:59 UTC",
      "updated_date": "2024-12-08 09:45:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:42:30.832757"
    },
    {
      "arxiv_id": "2412.05868v1",
      "title": "Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information",
      "title_zh": "自动提取和创建 FBS 设计推理知识图谱，从缺乏上下文信息的产品目录中结构化数据",
      "authors": [
        "Vijayalaxmi Sahadevan",
        "Sushil Mario",
        "Yash Jaiswal",
        "Divyanshu Bajpai",
        "Vishal Singh",
        "Hiralal Aggarwal",
        "Suhas Suresh",
        "Manjunath Maigur"
      ],
      "abstract": "Ontology-based knowledge graphs (KG) are desirable for effective knowledge\nmanagement and reuse in various decision making scenarios, including design.\nCreating and populating extensive KG based on specific ontological models can\nbe highly labour and time-intensive unless automated processes are developed\nfor knowledge extraction and graph creation. Most research and development on\nautomated extraction and creation of KG is based on extensive unstructured data\nsets that provide contextual information. However, some of the most useful\ninformation about the products and services of a company has traditionally been\nrecorded as structured data. Such structured data sets rarely follow a standard\nontology, do not capture explicit mapping of relationships between the\nentities, and provide no contextual information. Therefore, this research\nreports a method and digital workflow developed to address this gap. The\ndeveloped method and workflow employ rule-based techniques to extract and\ncreate a Function Behaviour-Structure (FBS) ontology-based KG from legacy\nstructured data, especially specification sheets and product catalogues. The\nsolution approach consists of two main components: a process for deriving\ncontext and context-based classification rules for FBS ontology concepts and a\nworkflow for populating and retrieving the FBS ontology-based KG. KG and\nNatural Language Processing (NLP) are used to automate knowledge extraction,\nrepresentation, and retrieval. The workflow's effectiveness is demonstrated via\npilot implementation in an industrial context. Insights gained from the pilot\nstudy are reported regarding the challenges and opportunities, including\ndiscussing the FBS ontology and concepts.",
      "tldr_zh": "本文提出了一种自动化方法和数字工作流，用于从缺乏上下文的结构化数据（如产品目录和规格表）中提取并创建基于Function Behaviour-Structure (FBS)本体论的知识图谱(KG)。该方法采用规则-based技术结合Knowledge Graphs (KG)和Natural Language Processing (NLP)，包括推导上下文规则和填充检索工作流，以实现知识提取、表示和检索的自动化。实验通过工业试点验证了工作流的有效性，并讨论了FBS本体论的应用挑战和机会。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "31 pages, with 17 figures and 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.05868v1",
      "published_date": "2024-12-08 09:20:25 UTC",
      "updated_date": "2024-12-08 09:20:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:42:40.914778"
    },
    {
      "arxiv_id": "2412.05864v1",
      "title": "CardOOD: Robust Query-driven Cardinality Estimation under Out-of-Distribution",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Li",
        "Kangfei Zhao",
        "Jeffrey Xu Yu",
        "Guoren Wang"
      ],
      "abstract": "Query-driven learned estimators are accurate, flexible, and lightweight\nalternatives to traditional estimators in query optimization. However, existing\nquery-driven approaches struggle with the Out-of-distribution (OOD) problem,\nwhere the test workload distribution differs from the training workload,\nleading to performancedegradation. In this paper, we present CardOOD, a general\nlearning framework designed to construct robust query-driven cardinality\nestimators that are resilient against the OOD problem. Our framework focuses on\noffline training algorithms that develop one-off models from a static workload,\nsuitable for model initialization and periodic retraining. In CardOOD, we\nextend classical transfer/robust learning techniques to train query-driven\ncardinalityestimators, and the algorithms fall into three categories:\nrepresentation learning, data manipulation, and new learning strategies. As\nthese learning techniques are originally evaluated in computervision tasks, we\nalso propose a new learning algorithm that exploits the property of cardinality\nestimation. This algorithm, lying in the category of new learning strategy,\nmodels the partial order constraint of cardinalities by a self-supervised\nlearning task. Comprehensive experimental studies demonstrate the efficacy of\nthe algorithms of CardOOD in mitigating the OOD problem to varying extents. We\nfurther integrate CardOOD into PostgreSQL, showcasing its practical utility in\nquery optimization.",
      "tldr_zh": "该论文提出 CardOOD 框架，用于构建对 Out-of-Distribution (OOD) 问题的鲁棒查询驱动基数估计器，以解决现有方法在测试工作负载分布变化时性能下降的问题。\nCardOOD 专注于离线训练算法，扩展了经典转移/鲁棒学习技术，包括表示学习、数据操作和新学习策略（如通过自监督学习任务建模基数的分部顺序约束）。\n实验证明，这些算法在不同程度上缓解了 OOD 问题，并将其集成到 PostgreSQL 中，展示了在查询优化中的实际效用。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05864v1",
      "published_date": "2024-12-08 09:11:11 UTC",
      "updated_date": "2024-12-08 09:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:42:54.482834"
    },
    {
      "arxiv_id": "2501.14731v1",
      "title": "From Critique to Clarity: A Pathway to Faithful and Personalized Code Explanations with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zexing Xu",
        "Zhuang Luo",
        "Yichuan Li",
        "Kyumin Lee",
        "S. Rasoul Etesami"
      ],
      "abstract": "In the realm of software development, providing accurate and personalized\ncode explanations is crucial for both technical professionals and business\nstakeholders. Technical professionals benefit from enhanced understanding and\nimproved problem-solving skills, while business stakeholders gain insights into\nproject alignments and transparency. Despite the potential, generating such\nexplanations is often time-consuming and challenging. This paper presents an\ninnovative approach that leverages the advanced capabilities of large language\nmodels (LLMs) to generate faithful and personalized code explanations. Our\nmethodology integrates prompt enhancement, self-correction mechanisms,\npersonalized content customization, and interaction with external tools,\nfacilitated by collaboration among multiple LLM agents. We evaluate our\napproach using both automatic and human assessments, demonstrating that our\nmethod not only produces accurate explanations but also tailors them to\nindividual user preferences. Our findings suggest that this approach\nsignificantly improves the quality and relevance of code explanations, offering\na valuable tool for developers and stakeholders alike.",
      "tldr_zh": "这篇论文提出了一种创新方法，利用 Large Language Models (LLMs) 生成忠实且个性化的代码解释，以帮助技术专业人士提升理解和问题解决能力，并为商业利益相关者提供项目透明度。方法整合了 prompt enhancement、自校正 mechanisms、个性化内容 customization 以及多个 LLM 代理的协作，包括与外部工具的交互。评估结果显示，该方法通过自动和人工评估显著提高了解释的准确性和相关性，为开发者和利益相关者提供了高效的工具。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14731v1",
      "published_date": "2024-12-08 09:02:04 UTC",
      "updated_date": "2024-12-08 09:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:43:05.321690"
    },
    {
      "arxiv_id": "2412.05852v1",
      "title": "Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming",
      "title_zh": "使用语法引导遗传编程演化代数多重网格方法",
      "authors": [
        "Dinesh Parthasarathy",
        "Wayne Bradford Mitchell",
        "Harald Köstler"
      ],
      "abstract": "Multigrid methods despite being known to be asymptotically optimal\nalgorithms, depend on the careful selection of their individual components for\nefficiency. Also, they are mostly restricted to standard cycle types like V-,\nF-, and W-cycles. We use grammar rules to generate arbitrary-shaped cycles,\nwherein the smoothers and their relaxation weights are chosen independently at\neach step within the cycle. We call this a flexible multigrid cycle. These\nflexible cycles are used in Algebraic Multigrid (AMG) methods with the help of\ngrammar rules and optimized using genetic programming. The flexible AMG methods\nare implemented in the software library of hypre, and the programs are\noptimized separately for two cases: a standalone AMG solver for a 3D\nanisotropic problem and an AMG preconditioner with conjugate gradient for a\nmultiphysics code. We observe that the optimized flexible cycles provide higher\nefficiency and better performance than the standard cycle types.",
      "tldr_zh": "这篇论文使用语法引导的遗传编程来优化代数多网格（AMG）方法，旨在通过生成任意形状的灵活多网格循环来提升算法效率。创新点在于利用语法规则在每个循环步骤独立选择平滑器和松弛权重，超越了传统V-、F-和W-循环的限制。实验结果显示，在hypre软件库中优化后的灵活AMG方法，在3D各向异性问题和多物理代码的场景下，比标准循环提供了更高的效率和更好性能。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05852v1",
      "published_date": "2024-12-08 08:21:35 UTC",
      "updated_date": "2024-12-08 08:21:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:43:20.391900"
    },
    {
      "arxiv_id": "2412.05846v2",
      "title": "Kernel Stochastic Configuration Networks for Nonlinear Regression",
      "title_zh": "核随机配置网络用于非线性回归",
      "authors": [
        "Yongxuan Chen",
        "Dianhui Wang"
      ],
      "abstract": "Stochastic configuration networks (SCNs), as a class of randomized learner\nmodels, are featured by its way of random parameters assignment in the light of\na supervisory mechanism, resulting in the universal approximation property at\nalgorithmic level. This paper presents a kernel version of SCNs, termed KSCNs,\naiming to enhance model's representation learning capability and performance\nstability. The random bases of a built SCN model can be used to span a\nreproducing kernel Hilbert space (RKHS), followed by our proposed algorithm for\nconstructing KSCNs. It is shown that the data distribution in the\nreconstructive space is favorable for regression solving and the proposed KSCN\nlearner models hold the universal approximation property. Three benchmark\ndatasets including two industrial datasets are used in this study for\nperformance evaluation. Experimental results with comparisons against existing\nsolutions clearly demonstrate that the proposed KSCN remarkably outperforms the\noriginal SCNs and some typical kernel methods for resolving nonlinear\nregression problems in terms of the learning performance, the model's stability\nand robustness with respect to the kernel parameter settings.",
      "tldr_zh": "本论文提出了一种名为 Kernel Stochastic Configuration Networks (KSCNs) 的新模型，旨在提升 Stochastic Configuration Networks (SCNs) 在非线性回归任务中的表示学习能力和性能稳定性。KSCNs 通过利用 SCNs 的随机基扩展到 Reproducing Kernel Hilbert Space (RKHS)，并引入一个新算法来构建模型，确保了数据在重构空间中的分布更有利于回归解决，同时保留了普适逼近特性。实验结果显示，在三个基准数据集（包括两个工业数据集）上，KSCNs 显著优于原 SCNs 和其他典型内核方法，在学习性能、模型稳定性和鲁棒性方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 20 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.05846v2",
      "published_date": "2024-12-08 07:54:04 UTC",
      "updated_date": "2024-12-14 13:32:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:43:34.179717"
    },
    {
      "arxiv_id": "2412.05842v1",
      "title": "DREAM: Domain-agnostic Reverse Engineering Attributes of Black-box Model",
      "title_zh": "DREAM：领域无关的黑盒模型属性逆向工程",
      "authors": [
        "Rongqing Li",
        "Jiaqi Yu",
        "Changsheng Li",
        "Wenhan Luo",
        "Ye Yuan",
        "Guoren Wang"
      ],
      "abstract": "Deep learning models are usually black boxes when deployed on machine\nlearning platforms. Prior works have shown that the attributes (e.g., the\nnumber of convolutional layers) of a target black-box model can be exposed\nthrough a sequence of queries. There is a crucial limitation: these works\nassume the training dataset of the target model is known beforehand and\nleverage this dataset for model attribute attack. However, it is difficult to\naccess the training dataset of the target black-box model in reality.\nTherefore, whether the attributes of a target black-box model could be still\nrevealed in this case is doubtful. In this paper, we investigate a new problem\nof black-box reverse engineering, without requiring the availability of the\ntarget model's training dataset. We put forward a general and principled\nframework DREAM, by casting this problem as out-of-distribution (OOD)\ngeneralization. In this way, we can learn a domain-agnostic meta-model to infer\nthe attributes of the target black-box model with unknown training data. This\nmakes our method one of the kinds that can gracefully apply to an arbitrary\ndomain for model attribute reverse engineering with strong generalization\nability. Extensive experimental results demonstrate the superiority of our\nproposed method over the baselines.",
      "tldr_zh": "本论文探讨了在未知训练数据集情况下，反向工程黑盒模型属性的新问题，解决了现有方法对训练数据的依赖。DREAM 框架将此问题转化为 out-of-distribution (OOD) 泛化问题，通过学习一个 domain-agnostic meta-model 来推断黑盒模型的属性（如卷积层数量），从而实现对任意领域的强泛化应用。实验结果显示，DREAM 优于基线方法，证明了其在模型属性逆向工程中的有效性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2307.10997",
      "pdf_url": "http://arxiv.org/pdf/2412.05842v1",
      "published_date": "2024-12-08 07:37:05 UTC",
      "updated_date": "2024-12-08 07:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:43:42.108556"
    },
    {
      "arxiv_id": "2412.05838v1",
      "title": "A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data",
      "title_zh": "一种协作多智能体方法，用于跨越多样化数据的检索增强生成",
      "authors": [
        "Aniruddha Salve",
        "Saba Attar",
        "Mahesh Deshmukh",
        "Sayali Shivpuje",
        "Arnab Mitra Utsab"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by\nincorporating external, domain-specific data into the generative process. While\nLLMs are highly capable, they often rely on static, pre-trained datasets,\nlimiting their ability to integrate dynamic or private data. Traditional RAG\nsystems typically use a single-agent architecture to handle query generation,\ndata retrieval, and response synthesis. However, this approach becomes\ninefficient when dealing with diverse data sources, such as relational\ndatabases, document stores, and graph databases, often leading to performance\nbottlenecks and reduced accuracy. This paper proposes a multi-agent RAG system\nto address these limitations. Specialized agents, each optimized for a specific\ndata source, handle query generation for relational, NoSQL, and document-based\nsystems. These agents collaborate within a modular framework, with query\nexecution delegated to an environment designed for compatibility across various\ndatabase types. This distributed approach enhances query efficiency, reduces\ntoken overhead, and improves response accuracy by ensuring that each agent\nfocuses on its specialized task. The proposed system is scalable and adaptable,\nmaking it ideal for generative AI workflows that require integration with\ndiverse, dynamic, or private data sources. By leveraging specialized agents and\na modular execution environment, the system provides an efficient and robust\nsolution for handling complex, heterogeneous data environments in generative AI\napplications.",
      "tldr_zh": "这篇论文针对 Retrieval-Augmented Generation (RAG) 在处理多样数据源（如关系数据库、NoSQL 和文档存储）时的效率和准确性问题，提出了一种协作多代理系统。系统由针对特定数据源优化的代理组成，这些代理在模块化框架中协作，负责查询生成、数据检索和响应合成，从而减少性能瓶颈和 token overhead。实验结果显示，该方法显著提高了查询效率和响应准确性，使其更适合整合动态或私有数据的生成式 AI 工作流。通过这种分布式设计，论文为处理异构数据环境提供了可扩展、稳健的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 3 figures. This preprint introduces a multi-agent framework\n  for Retrieval-Augmented Generation (RAG), enhancing Large Language Models\n  (LLMs) for efficient integration of diverse data sources. Relevant for\n  researchers in AI, ML, generative AI, and database systems",
      "pdf_url": "http://arxiv.org/pdf/2412.05838v1",
      "published_date": "2024-12-08 07:18:19 UTC",
      "updated_date": "2024-12-08 07:18:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:43:53.198750"
    },
    {
      "arxiv_id": "2412.05830v1",
      "title": "Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks",
      "title_zh": "大语言模型合并用于增强针对图神经网络的链接窃取攻击",
      "authors": [
        "Faqian Guan",
        "Tianqing Zhu",
        "Wenhan Chang",
        "Wei Ren",
        "Wanlei Zhou"
      ],
      "abstract": "Graph Neural Networks (GNNs), specifically designed to process the graph\ndata, have achieved remarkable success in various applications. Link stealing\nattacks on graph data pose a significant privacy threat, as attackers aim to\nextract sensitive relationships between nodes (entities), potentially leading\nto academic misconduct, fraudulent transactions, or other malicious activities.\nPrevious studies have primarily focused on single datasets and did not explore\ncross-dataset attacks, let alone attacks that leverage the combined knowledge\nof multiple attackers. However, we find that an attacker can combine the data\nknowledge of multiple attackers to create a more effective attack model, which\ncan be referred to cross-dataset attacks. Moreover, if knowledge can be\nextracted with the help of Large Language Models (LLMs), the attack capability\nwill be more significant. In this paper, we propose a novel link stealing\nattack method that takes advantage of cross-dataset and Large Language Models\n(LLMs). The LLM is applied to process datasets with different data structures\nin cross-dataset attacks. Each attacker fine-tunes the LLM on their specific\ndataset to generate a tailored attack model. We then introduce a novel model\nmerging method to integrate the parameters of these attacker-specific models\neffectively. The result is a merged attack model with superior generalization\ncapabilities, enabling effective attacks not only on the attackers' datasets\nbut also on previously unseen (out-of-domain) datasets. We conducted extensive\nexperiments in four datasets to demonstrate the effectiveness of our method.\nAdditional experiments with three different GNN and LLM architectures further\nillustrate the generality of our approach.",
      "tldr_zh": "本论文探讨了针对图神经网络(GNNs)的链接窃取攻击，提出了一种新方法，通过跨数据集攻击和大型语言模型(LLMs)合并来提升攻击能力。方法包括每个攻击者在特定数据集上微调LLMs生成定制模型，然后使用新型模型合并技术整合这些参数，创建具有更强泛化能力的攻击模型，从而能有效攻击已知和未知数据集。实验结果显示，该方法在四个数据集上显著提高了攻击性能，并在三种不同GNN和LLM架构上验证了其通用性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Link Stealing Attacks, Large Language Models, Graph Neural Networks,\n  Privacy Attacks, Model Merging",
      "pdf_url": "http://arxiv.org/pdf/2412.05830v1",
      "published_date": "2024-12-08 06:37:05 UTC",
      "updated_date": "2024-12-08 06:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:44:08.948665"
    },
    {
      "arxiv_id": "2412.05823v1",
      "title": "DapperFL: Domain Adaptive Federated Learning with Model Fusion Pruning for Edge Devices",
      "title_zh": "DapperFL：领域自适应联邦学习，带有模型融合修剪，用于边缘设备",
      "authors": [
        "Yongzhe Jia",
        "Xuyun Zhang",
        "Hongsheng Hu",
        "Kim-Kwang Raymond Choo",
        "Lianyong Qi",
        "Xiaolong Xu",
        "Amin Beheshti",
        "Wanchun Dou"
      ],
      "abstract": "Federated learning (FL) has emerged as a prominent machine learning paradigm\nin edge computing environments, enabling edge devices to collaboratively\noptimize a global model without sharing their private data. However, existing\nFL frameworks suffer from efficacy deterioration due to the system\nheterogeneity inherent in edge computing, especially in the presence of domain\nshifts across local data. In this paper, we propose a heterogeneous FL\nframework DapperFL, to enhance model performance across multiple domains. In\nDapperFL, we introduce a dedicated Model Fusion Pruning (MFP) module to produce\npersonalized compact local models for clients to address the system\nheterogeneity challenges. The MFP module prunes local models with fused\nknowledge obtained from both local and remaining domains, ensuring robustness\nto domain shifts. Additionally, we design a Domain Adaptive Regularization\n(DAR) module to further improve the overall performance of DapperFL. The DAR\nmodule employs regularization generated by the pruned model, aiming to learn\nrobust representations across domains. Furthermore, we introduce a specific\naggregation algorithm for aggregating heterogeneous local models with tailored\narchitectures and weights. We implement DapperFL on a realworld FL platform\nwith heterogeneous clients. Experimental results on benchmark datasets with\nmultiple domains demonstrate that DapperFL outperforms several state-of-the-art\nFL frameworks by up to 2.28%, while significantly achieving model volume\nreductions ranging from 20% to 80%. Our code is available at:\nhttps://github.com/jyzgh/DapperFL.",
      "tldr_zh": "该论文提出DapperFL，一种针对边缘设备的领域自适应Federated Learning (FL)框架，旨在解决FL中系统异质性和领域偏移导致的模型性能下降问题。通过引入Model Fusion Pruning (MFP)模块，该框架融合本地和其它领域的知识对本地模型进行剪枝，生成个性化的紧凑模型；同时，Domain Adaptive Regularization (DAR)模块利用剪枝模型生成正则化，以提升跨领域表示的鲁棒性。实验结果显示，DapperFL在基准数据集上比现有FL框架性能提升高达2.28%，并实现20%至80%的模型体积减少，为异质边缘设备下的FL应用提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Oral accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.05823v1",
      "published_date": "2024-12-08 05:50:04 UTC",
      "updated_date": "2024-12-08 05:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:44:21.029950"
    },
    {
      "arxiv_id": "2412.06849v1",
      "title": "GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model",
      "title_zh": "翻译失败",
      "authors": [
        "Haotong Yang",
        "Xiyuan Wang",
        "Qian Tao",
        "Shuxian Hu",
        "Zhouchen Lin",
        "Muhan Zhang"
      ],
      "abstract": "Recent research on integrating Large Language Models (LLMs) with Graph Neural\nNetworks (GNNs) typically follows two approaches: LLM-centered models, which\nconvert graph data into tokens for LLM processing, and GNN-centered models,\nwhich use LLMs to encode text features into node and edge representations for\nGNN input. LLM-centered models often struggle to capture graph structures\neffectively, while GNN-centered models compress variable-length textual data\ninto fixed-size vectors, limiting their ability to understand complex\nsemantics. Additionally, GNN-centered approaches require converting tasks into\na uniform, manually-designed format, restricting them to classification tasks\nand preventing language output. To address these limitations, we introduce a\nnew architecture that deeply integrates GNN with LLM, featuring three key\ninnovations: (1) Structure-Aware Transformers, which incorporate GNN's\nmessage-passing capabilities directly into LLM's transformer layers, allowing\nsimultaneous processing of textual and structural information and generating\noutputs from both GNN and LLM; (2) Graph-Text Cross-Attention, which processes\nfull, uncompressed text from graph nodes and edges, ensuring complete semantic\nintegration; and (3) GNN-LLM Twin Predictor, enabling LLM's flexible\nautoregressive generation alongside GNN's scalable one-pass prediction.\nGL-Fusion achieves outstand performance on various tasks. Notably, it achieves\nstate-of-the-art performance on OGBN-Arxiv and OGBG-Code2.",
      "tldr_zh": "该论文重新审视了Graph Neural Network (GNN) 与Large Language Model (LLM) 的整合问题，指出现有LLM-centered方法难以捕捉图结构，而GNN-centered方法则因文本压缩和任务限制（如仅限于分类）而忽略复杂语义。论文提出GL-Fusion新架构，包括三个创新：Structure-Aware Transformers将GNN的message-passing融入LLM的transformer层，实现文本和结构信息的同步处理；Graph-Text Cross-Attention处理完整的节点和边文本，确保语义完整；GNN-LLM Twin Predictor结合LLM的自回归生成与GNN的一步预测，提升灵活性。实验结果显示，GL-Fusion在OGBN-Arxiv和OGBG-Code2等任务上达到state-of-the-art性能，显著提升了图文本整合的效能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2412.06849v1",
      "published_date": "2024-12-08 05:49:58 UTC",
      "updated_date": "2024-12-08 05:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:44:34.670037"
    },
    {
      "arxiv_id": "2412.05821v2",
      "title": "An Entailment Tree Generation Approach for Multimodal Multi-Hop Question Answering with Mixture-of-Experts and Iterative Feedback Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Qing Zhang",
        "Haocheng Lv",
        "Jie Liu",
        "Zhiyun Chen",
        "Jianyong Duan",
        "Hao Wang",
        "Li He",
        "Mingying Xv"
      ],
      "abstract": "With the rise of large-scale language models (LLMs), it is currently popular\nand effective to convert multimodal information into text descriptions for\nmultimodal multi-hop question answering. However, we argue that the current\nmethods of multi-modal multi-hop question answering still mainly face two\nchallenges: 1) The retrieved evidence containing a large amount of redundant\ninformation, inevitably leads to a significant drop in performance due to\nirrelevant information misleading the prediction. 2) The reasoning process\nwithout interpretable reasoning steps makes the model difficult to discover the\nlogical errors for handling complex questions. To solve these problems, we\npropose a unified LLMs-based approach but without heavily relying on them due\nto the LLM's potential errors, and innovatively treat multimodal multi-hop\nquestion answering as a joint entailment tree generation and question answering\nproblem. Specifically, we design a multi-task learning framework with a focus\non facilitating common knowledge sharing across interpretability and prediction\ntasks while preventing task-specific errors from interfering with each other\nvia mixture of experts. Afterward, we design an iterative feedback mechanism to\nfurther enhance both tasks by feeding back the results of the joint training to\nthe LLM for regenerating entailment trees, aiming to iteratively refine the\npotential answer. Notably, our method has won the first place in the official\nleaderboard of WebQA (since April 10, 2024), and achieves competitive results\non MultimodalQA.",
      "tldr_zh": "本文提出了一种基于大型语言模型 (LLMs) 的方法，用于解决多模态多跳问题回答中的证据冗余和推理不可解释性挑战，通过将任务视为联合蕴涵树生成和问题回答问题来创新性处理。方法采用 Mixture-of-Experts 多任务学习框架，促进任务间知识共享并防止错误干扰，同时引入 Iterative Feedback Mechanism，将训练结果反馈给 LLM 以迭代优化答案。实验结果显示，该方法在 WebQA 官方排行榜上夺得第一名，并在 MultimodalQA 上取得竞争性性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Erratum: We identified an error in the calculation of the F1 score in\n  table 4 reported in a previous version of this work. The performance of the\n  new result is better than the previous one. The corrected values are included\n  in this updated version of the paper. These changes do not alter the primary\n  conclusions of our research",
      "pdf_url": "http://arxiv.org/pdf/2412.05821v2",
      "published_date": "2024-12-08 05:47:55 UTC",
      "updated_date": "2024-12-10 17:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:46:36.712611"
    },
    {
      "arxiv_id": "2412.05818v2",
      "title": "SILMM: Self-Improving Large Multimodal Models for Compositional Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Leigang Qu",
        "Haochuan Li",
        "Wenjie Wang",
        "Xiang Liu",
        "Juncheng Li",
        "Liqiang Nie",
        "Tat-Seng Chua"
      ],
      "abstract": "Large Multimodal Models (LMMs) have demonstrated impressive capabilities in\nmultimodal understanding and generation, pushing forward advancements in\ntext-to-image generation. However, achieving accurate text-image alignment for\nLMMs, particularly in compositional scenarios, remains challenging. Existing\napproaches, such as layout planning for multi-step generation and learning from\nhuman feedback or AI feedback, depend heavily on prompt engineering, costly\nhuman annotations, and continual upgrading, limiting flexibility and\nscalability. In this work, we introduce a model-agnostic iterative\nself-improvement framework (SILMM) that can enable LMMs to provide helpful and\nscalable self-feedback and optimize text-image alignment via Direct Preference\nOptimization (DPO). DPO can readily applied to LMMs that use discrete visual\ntokens as intermediate image representations; while it is less suitable for\nLMMs with continuous visual features, as obtaining generation probabilities is\nchallenging. To adapt SILMM to LMMs with continuous features, we propose a\ndiversity mechanism to obtain diverse representations and a kernel-based\ncontinuous DPO for alignment. Extensive experiments on three compositional\ntext-to-image generation benchmarks validate the effectiveness and superiority\nof SILMM, showing improvements exceeding 30% on T2I-CompBench++ and around 20%\non DPG-Bench.",
      "tldr_zh": "本文提出 SILMM，一种模型无关的迭代自提升框架，用于提升 Large Multimodal Models (LMMs) 在合成文本到图像生成中的文本-图像对齐问题。SILMM 通过 Direct Preference Optimization (DPO) 优化自反馈，对于使用连续视觉特征的 LMMs，引入多样性机制和基于核的连续 DPO，以提高灵活性和可扩展性。在三个合成文本到图像生成基准上进行实验，SILMM 表现出色，在 T2I-CompBench++ 上提升超过 30%，在 DPG-Bench 上约 20%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 Camera-ready. Project page: https://silmm.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.05818v2",
      "published_date": "2024-12-08 05:28:08 UTC",
      "updated_date": "2025-03-24 23:22:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:44:56.912582"
    },
    {
      "arxiv_id": "2412.07801v1",
      "title": "Learning to Correction: Explainable Feedback Generation for Visual Commonsense Reasoning Distractor",
      "title_zh": "学习纠正：视觉常识推理干扰项的可解释反馈生成",
      "authors": [
        "Jiali Chen",
        "Xusen Hei",
        "Yuqi Xue",
        "Yuancheng Wei",
        "Jiayuan Xie",
        "Yi Cai",
        "Qing Li"
      ],
      "abstract": "Large multimodal models (LMMs) have shown remarkable performance in the\nvisual commonsense reasoning (VCR) task, which aims to answer a multiple-choice\nquestion based on visual commonsense within an image. However, the ability of\nLMMs to correct potential visual commonsense errors in the distractor upon\ntheir occurrence is yet under-explored. Drawing inspiration from how a human\nteacher crafts challenging distractors to test students' comprehension of the\nconcepts or skills and assists them in identifying and correcting errors toward\nthe answer, we are the pioneering research for LMMs to simulate this error\ncorrection process. To this end, we employ GPT-4 as a ``teacher'' to collect\nthe explainable feedback dataset VCR-DF for error correction, which serves as a\nbenchmark to evaluate the ability of LMMs to identify misconceptions and\nclarify reasons behind the error in VCR distractors toward final answers. In\naddition, we propose an LMM-based Pedagogical Expert Instructed Feedback\nGeneration (PEIFG) model to incorporate the learnable expert prompts and\nmultimodal instruction as guidance for feedback generation. Experimental\nresults show that our PEIFG significantly outperforms existing LMMs. We believe\nthat our benchmark provides a new direction for evaluating the capabilities of\nLMMs.",
      "tldr_zh": "本文研究了大型多模态模型 (LMMs) 在视觉常识推理 (VCR) 任务中纠正 distractor 错误的能力，灵感来源于人类教师如何创建挑战性干扰项并指导错误纠正。研究者使用 GPT-4 作为“教师”构建了 VCR-DF 数据集，作为基准评估 LMMs 识别误解和解释错误的原因。论文提出 PEIFG (Pedagogical Expert Instructed Feedback Generation) 模型，通过可学习的专家提示和多模态指令生成解释性反馈。实验结果表明，PEIFG 显著优于现有 LMMs，并为评估 LMMs 的能力提供了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.07801v1",
      "published_date": "2024-12-08 03:59:59 UTC",
      "updated_date": "2024-12-08 03:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:47:13.901307"
    },
    {
      "arxiv_id": "2412.06847v2",
      "title": "M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery",
      "title_zh": "M³-20M：大规模多模态分子数据集，用于AI驱动的药物设计和发现",
      "authors": [
        "Siyuan Guo",
        "Lexuan Wang",
        "Chang Jin",
        "Jinxian Wang",
        "Han Peng",
        "Huayang Shi",
        "Wengen Li",
        "Jihong Guan",
        "Shuigeng Zhou"
      ],
      "abstract": "This paper introduces M$^{3}$-20M, a large-scale Multi-Modal Molecule dataset\nthat contains over 20 million molecules, with the data mainly being integrated\nfrom existing databases and partially generated by large language models.\nDesigned to support AI-driven drug design and discovery, M$^{3}$-20M is 71\ntimes more in the number of molecules than the largest existing dataset,\nproviding an unprecedented scale that can highly benefit the training or\nfine-tuning of models, including large language models for drug design and\ndiscovery tasks. This dataset integrates one-dimensional SMILES,\ntwo-dimensional molecular graphs, three-dimensional molecular structures,\nphysicochemical properties, and textual descriptions collected through web\ncrawling and generated using GPT-3.5, offering a comprehensive view of each\nmolecule. To demonstrate the power of M$^{3}$-20M in drug design and discovery,\nwe conduct extensive experiments on two key tasks: molecule generation and\nmolecular property prediction, using large language models including GLM4,\nGPT-3.5, GPT-4, and Llama3-8b. Our experimental results show that M$^{3}$-20M\ncan significantly boost model performance in both tasks. Specifically, it\nenables the models to generate more diverse and valid molecular structures and\nachieve higher property prediction accuracy than existing single-modal\ndatasets, which validates the value and potential of M$^{3}$-20M in supporting\nAI-driven drug design and discovery. The dataset is available at\nhttps://github.com/bz99bz/M-3.",
      "tldr_zh": "本文介绍了M³-20M数据集，这是一个大规模多模态分子数据集，包含超过2000万分子，比现有最大数据集大71倍，主要用于AI驱动的药物设计和发现。数据集整合了SMILES、一维分子图、三维分子结构、理化性质以及通过网络爬取和GPT-3.5生成的文本描述，提供全面的分子视图。通过实验验证，使用GLM4、GPT-3.5、GPT-4和Llama3-8b等模型在分子生成和分子属性预测任务上，M³-20M显著提升了性能，实现了更多样有效的分子结构生成和更高的预测准确率。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06847v2",
      "published_date": "2024-12-08 03:43:07 UTC",
      "updated_date": "2025-03-16 12:37:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:45:21.834804"
    },
    {
      "arxiv_id": "2412.05797v1",
      "title": "Speech Is Not Enough: Interpreting Nonverbal Indicators of Common Knowledge and Engagement",
      "title_zh": "翻译失败",
      "authors": [
        "Derek Palmer",
        "Yifan Zhu",
        "Kenneth Lai",
        "Hannah VanderHoeven",
        "Mariah Bradford",
        "Ibrahim Khebour",
        "Carlos Mabrey",
        "Jack Fitzgerald",
        "Nikhil Krishnaswamy",
        "Martha Palmer",
        "James Pustejovsky"
      ],
      "abstract": "Our goal is to develop an AI Partner that can provide support for group\nproblem solving and social dynamics. In multi-party working group environments,\nmultimodal analytics is crucial for identifying non-verbal interactions of\ngroup members. In conjunction with their verbal participation, this creates an\nholistic understanding of collaboration and engagement that provides necessary\ncontext for the AI Partner. In this demo, we illustrate our present\ncapabilities at detecting and tracking nonverbal behavior in student\ntask-oriented interactions in the classroom, and the implications for tracking\ncommon ground and engagement.",
      "tldr_zh": "本论文旨在开发一个AI Partner，以支持群体问题解决和社会动态，通过多模态分析识别群成员的非语言互动。研究强调，非语言行为与语言参与相结合，能提供对协作和参与的整体理解，从而为AI Partner提供必要上下文。在演示中，展示了检测和跟踪课堂中学生任务导向互动的非语言行为能力，以及这对跟踪共同知识（common ground）和参与（engagement）的含义。实验结果表明，这种方法有助于提升AI在多党工作组环境中的支持效能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "3 pages, 2 figures, appearing at AAAI 2025 Demos Track",
      "pdf_url": "http://arxiv.org/pdf/2412.05797v1",
      "published_date": "2024-12-08 03:26:44 UTC",
      "updated_date": "2024-12-08 03:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:45:30.694871"
    },
    {
      "arxiv_id": "2412.05796v2",
      "title": "Language-Guided Image Tokenization for Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiwen Zha",
        "Lijun Yu",
        "Alireza Fathi",
        "David A. Ross",
        "Cordelia Schmid",
        "Dina Katabi",
        "Xiuye Gu"
      ],
      "abstract": "Image tokenization, the process of transforming raw image pixels into a\ncompact low-dimensional latent representation, has proven crucial for scalable\nand efficient image generation. However, mainstream image tokenization methods\ngenerally have limited compression rates, making high-resolution image\ngeneration computationally expensive. To address this challenge, we propose to\nleverage language for efficient image tokenization, and we call our method\nText-Conditioned Image Tokenization (TexTok). TexTok is a simple yet effective\ntokenization framework that leverages language to provide a compact, high-level\nsemantic representation. By conditioning the tokenization process on\ndescriptive text captions, TexTok simplifies semantic learning, allowing more\nlearning capacity and token space to be allocated to capture fine-grained\nvisual details, leading to enhanced reconstruction quality and higher\ncompression rates. Compared to the conventional tokenizer without text\nconditioning, TexTok achieves average reconstruction FID improvements of 29.2%\nand 48.1% on ImageNet-256 and -512 benchmarks respectively, across varying\nnumbers of tokens. These tokenization improvements consistently translate to\n16.3% and 34.3% average improvements in generation FID. By simply replacing the\ntokenizer in Diffusion Transformer (DiT) with TexTok, our system can achieve a\n93.5x inference speedup while still outperforming the original DiT using only\n32 tokens on ImageNet-512. TexTok with a vanilla DiT generator achieves\nstate-of-the-art FID scores of 1.46 and 1.62 on ImageNet-256 and -512\nrespectively. Furthermore, we demonstrate TexTok's superiority on the\ntext-to-image generation task, effectively utilizing the off-the-shelf text\ncaptions in tokenization. Project page is at:\nhttps://kaiwenzha.github.io/textok/.",
      "tldr_zh": "本文提出 TexTok，一种基于语言指导的图像标记化方法（Text-Conditioned Image Tokenization），旨在解决传统图像标记化压缩率低、生成高分辨率图像计算成本高的挑战。通过利用描述性文本标题作为条件，TexTok 简化语义学习并提升细粒度视觉细节捕获能力。实验结果显示，与传统方法相比，TexTok 在 ImageNet-256 和 -512 上实现重建 FID 平均改善 29.2% 和 48.1%，并在 Diffusion Transformer (DiT) 中提供 93.5x 推理加速，同时达到最先进的生成 FID 分数（1.46 和 1.62）。此外，TexTok 在文本到图像生成任务中表现出色，证明了其在高效图像生成中的优越性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 Oral. Project page: https://kaiwenzha.github.io/textok/",
      "pdf_url": "http://arxiv.org/pdf/2412.05796v2",
      "published_date": "2024-12-08 03:18:17 UTC",
      "updated_date": "2025-04-05 18:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:45:45.779815"
    },
    {
      "arxiv_id": "2412.10411v1",
      "title": "Pre-trained protein language model for codon optimization",
      "title_zh": "预训练蛋白质语言模型用于密码子优化",
      "authors": [
        "Shashank Pathak",
        "Guohui Lin"
      ],
      "abstract": "Motivation: Codon optimization of Open Reading Frame (ORF) sequences is\nessential for enhancing mRNA stability and expression in applications like mRNA\nvaccines, where codon choice can significantly impact protein yield which\ndirectly impacts immune strength. In this work, we investigate the use of a\npre-trained protein language model (PPLM) for getting a rich representation of\namino acids which could be utilized for codon optimization. This leaves us with\na simpler fine-tuning task over PPLM in optimizing ORF sequences.\n  Results: The ORFs generated by our proposed models outperformed their natural\ncounterparts encoding the same proteins on computational metrics for stability\nand expression. They also demonstrated enhanced performance against the\nbenchmark ORFs used in mRNA vaccines for the SARS-CoV-2 viral spike protein and\nthe varicella-zoster virus (VZV). These results highlight the potential of\nadapting PPLM for designing ORFs tailored to encode target antigens in mRNA\nvaccines.",
      "tldr_zh": "本研究旨在通过预训练的蛋白质语言模型（PPLM）优化 Open Reading Frame (ORF) 序列，以提升 mRNA 的稳定性和表达水平，尤其在 mRNA 疫苗应用中，改善蛋白产量并增强免疫响应。研究方法涉及使用 PPLM 获取氨基酸的丰富表示，并进行简单微调来生成优化的 ORF 序列。结果显示，这些序列在计算指标上优于自然对应序列，并在 SARS-CoV-2 病毒刺突蛋白和 varicella-zoster virus (VZV) 的 mRNA 疫苗基准中表现出色，突显了 PPLM 在设计针对性抗原 ORF 方面的潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10411v1",
      "published_date": "2024-12-08 03:01:38 UTC",
      "updated_date": "2024-12-08 03:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:45:56.995825"
    },
    {
      "arxiv_id": "2412.05781v3",
      "title": "Open-Source Acceleration of Stable-Diffusion.cpp Deployable on All Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Jingxu Ng",
        "Cheng Lv",
        "Pu Zhao",
        "Wei Niu",
        "Juyi Lin",
        "Minzhou Pan",
        "Yun Liang",
        "Yanzhi Wang"
      ],
      "abstract": "Stable diffusion plays a crucial role in generating high-quality images.\nHowever, image generation is time-consuming and memory-intensive. To address\nthis, stable-diffusion.cpp (Sdcpp) emerges as an efficient inference framework\nto accelerate the diffusion models. Although it is lightweight, the current\nimplementation of ggml_conv_2d operator in Sdcpp is suboptimal, exhibiting both\nhigh inference latency and massive memory usage. To address this, in this work,\nwe present an optimized version of Sdcpp leveraging the Winograd algorithm to\naccelerate 2D convolution operations, which is the primary bottleneck in the\npipeline. By analyzing both dependent and independent computation graphs, we\nexploit the device's locality and parallelism to achieve substantial\nperformance improvements. Our framework delivers correct end-to-end results\nacross various stable diffusion models, including SDv1.4, v1.5, v2.1, SDXL, and\nSDXL-Turbo. Our evaluation results demonstrate a speedup up to 2.76x for\nindividual convolutional layers and an inference speedup up to 4.79x for the\noverall image generation process, compared with the original Sdcpp on M1 pro.\nHomepage: https://github.com/SealAILab/stable-diffusion-cpp",
      "tldr_zh": "这篇论文针对 Stable Diffusion 图像生成过程的耗时和内存密集问题，优化了开源框架 stable-diffusion.cpp (Sdcpp)。他们通过引入 Winograd 算法加速 ggml_conv_2d 运算符，并利用设备的局部性和并行性，显著降低了推理延迟。实验结果显示，在 M1 Pro 上，单个卷积层加速高达 2.76x，整体图像生成过程加速高达 4.79x，并支持多种模型如 SDv1.4、v1.5、v2.1、SDXL 和 SDXL-Turbo。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05781v3",
      "published_date": "2024-12-08 02:27:17 UTC",
      "updated_date": "2025-01-07 20:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:47:30.036083"
    },
    {
      "arxiv_id": "2412.05780v3",
      "title": "BudgetFusion: Perceptually-Guided Adaptive Diffusion Models",
      "title_zh": "BudgetFusion：感知引导的自适应扩散模型",
      "authors": [
        "Qinchan Li",
        "Kenneth Chen",
        "Changyue Su",
        "Qi Sun"
      ],
      "abstract": "Diffusion models have shown unprecedented success in the task of\ntext-to-image generation. While these models are capable of generating\nhigh-quality and realistic images, the complexity of sequential denoising has\nraised societal concerns regarding high computational demands and energy\nconsumption. In response, various efforts have been made to improve inference\nefficiency. However, most of the existing efforts have taken a fixed approach\nwith neural network simplification or text prompt optimization. Are the quality\nimprovements from all denoising computations equally perceivable to humans? We\nobserved that images from different text prompts may require different\ncomputational efforts given the desired content. The observation motivates us\nto present BudgetFusion, a novel model that suggests the most perceptually\nefficient number of diffusion steps before a diffusion model starts to generate\nan image. This is achieved by predicting multi-level perceptual metrics\nrelative to diffusion steps. With the popular Stable Diffusion as an example,\nwe conduct both numerical analyses and user studies. Our experiments show that\nBudgetFusion saves up to five seconds per prompt without compromising\nperceptual similarity. We hope this work can initiate efforts toward answering\na core question: how much do humans perceptually gain from images created by a\ngenerative model, per watt of energy?",
      "tldr_zh": "本研究针对扩散模型（Diffusion models）在文本到图像生成中的高计算需求和能源消耗问题，提出了一种感知引导的自适应模型BudgetFusion。该模型通过预测与扩散步骤相关的多级感知指标（perceptual metrics），动态确定生成图像所需的最有效步骤数，从而优化计算效率。实验基于Stable Diffusion显示，BudgetFusion可每提示节省高达五秒时间，同时保持感知相似度不变。该工作旨在引发对人类从生成模型中每瓦特能源获得感知收益的核心问题的探讨。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05780v3",
      "published_date": "2024-12-08 02:23:40 UTC",
      "updated_date": "2024-12-23 11:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:47:40.717854"
    },
    {
      "arxiv_id": "2412.05777v1",
      "title": "Strategizing Equitable Transit Evacuations: A Data-Driven Reinforcement Learning Approach",
      "title_zh": "公平交通疏散策略制定：一种数据驱动的强化学习方法",
      "authors": [
        "Fang Tang",
        "Han Wang",
        "Maria Laura Delle Monache"
      ],
      "abstract": "As natural disasters become increasingly frequent, the need for efficient and\nequitable evacuation planning has become more critical. This paper proposes a\ndata-driven, reinforcement learning-based framework to optimize bus-based\nevacuations with an emphasis on improving both efficiency and equity. We model\nthe evacuation problem as a Markov Decision Process solved by reinforcement\nlearning, using real-time transit data from General Transit Feed Specification\nand transportation networks extracted from OpenStreetMap. The reinforcement\nlearning agent dynamically reroutes buses from their scheduled location to\nminimize total passengers' evacuation time while prioritizing equity-priority\ncommunities. Simulations on the San Francisco Bay Area transportation network\nindicate that the proposed framework achieves significant improvements in both\nevacuation efficiency and equitable service distribution compared to\ntraditional rule-based and random strategies. These results highlight the\npotential of reinforcement learning to enhance system performance and urban\nresilience during emergency evacuations, offering a scalable solution for\nreal-world applications in intelligent transportation systems.",
      "tldr_zh": "这篇论文提出了一种数据驱动的强化学习框架，用于优化巴士疏散计划，强调提高疏散效率和公平性。框架将疏散问题建模为Markov Decision Process (MDP)，利用General Transit Feed Specification (GTFS) 和 OpenStreetMap (OSM) 的实时数据，强化学习代理动态 reroute 巴士，以最小化乘客疏散时间并优先服务公平性社区。在旧金山湾区交通网络的模拟中，该方法相较于传统规则和随机策略显著提升了效率和公平服务分布，展示了其在智能交通系统中的可扩展潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.SY",
        "eess.SY",
        "68T05, 90B06",
        "I.2.6; I.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.05777v1",
      "published_date": "2024-12-08 02:17:38 UTC",
      "updated_date": "2024-12-08 02:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:47:56.321822"
    },
    {
      "arxiv_id": "2412.06846v1",
      "title": "Classifier-free guidance in LLMs Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Roman Smirnov"
      ],
      "abstract": "The paper describes LLM unlearning without a retaining dataset, using the\nORPO reinforcement learning method with inference enhanced by modified\nclassifier-free guidance. Significant improvement in unlearning, without\ndegradation of the model, is achieved through direct training on synthetic\nreplacement data in CFG-aware training regime, with classifier-free guidance\napplied during the inference. This article is an extended version of the\nNeurIPS 2024 LLM-PC submission, which was awarded second prize.",
      "tldr_zh": "这篇论文提出了一种在LLM安全领域进行unlearning的方法，使用ORPO强化学习方法结合modified classifier-free guidance，无需保留数据集即可实现模型遗忘。方法通过在CFG-aware训练模式下直接训练合成替换数据，并在推理过程中应用classifier-free guidance，显著提升了unlearning效果，同时避免了模型性能的下降。该研究是NeurIPS 2024 LLM-PC提交的扩展版本，并获得了二等奖，为LLM的安全性提供了可靠的改进路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06846v1",
      "published_date": "2024-12-08 02:11:33 UTC",
      "updated_date": "2024-12-08 02:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:48:06.368112"
    },
    {
      "arxiv_id": "2412.06845v4",
      "title": "7B Fully Open Source Moxin-LLM -- From Pretraining to GRPO-based Reinforcement Learning Enhancement",
      "title_zh": "7B 完全开源 Moxin-LLM —— 从预训练到基于 GRPO 的强化学习增强",
      "authors": [
        "Pu Zhao",
        "Xuan Shen",
        "Zhenglun Kong",
        "Yixin Shen",
        "Sung-En Chang",
        "Timothy Rupprecht",
        "Lei Lu",
        "Enfu Nan",
        "Changdi Yang",
        "Yumei He",
        "Weiyan Shi",
        "Xingchen Xu",
        "Yu Huang",
        "Wei Jiang",
        "Wei Wang",
        "Yue Chen",
        "Yong He",
        "Yanzhi Wang"
      ],
      "abstract": "Recently, Large Language Models (LLMs) have undergone a significant\ntransformation, marked by a rapid rise in both their popularity and\ncapabilities. Leading this evolution are proprietary LLMs like GPT-4 and\nGPT-o1, which have captured widespread attention in the AI community due to\ntheir remarkable performance and versatility. Simultaneously, open-source LLMs,\nsuch as LLaMA, have made great contributions to the ever-increasing popularity\nof LLMs due to the ease to customize and deploy the models across diverse\napplications. Although open-source LLMs present unprecedented opportunities for\ninnovation and research, the commercialization of LLMs has raised concerns\nabout transparency, reproducibility, and safety. Many open-source LLMs fail to\nmeet fundamental transparency requirements by withholding essential components\nlike training code and data, which may hinder further innovations on LLMs. To\nmitigate this issue, we introduce Moxin 7B, a fully open-source LLM developed,\nadhering to principles of open science, open source, open data, and open\naccess. We release the pre-training code and configurations, training and\nfine-tuning datasets, and intermediate and final checkpoints, aiming to make\ncontinuous commitments to fully open-source LLMs. After pre-training and\nobtaining the base model, we finetune the Moxin Base model with SOTA\npost-training framework and instruction data to obtain Moxin Instruct model. To\nimprove the reasoning capability, we further finetune our Instruct model with\nchain-of-thought data distilled from DeepSeek R1, and then use Group Relative\nPolicy Optimization (GRPO), an efficient and effective reinforcement learning\nalgorithm following DeepSeek R1, to finetune our model, leading to the Moxin\nReasoning model. Experiments show that our models achieve superior performance\nin various evaluations such as zero-shot evaluation, few-shot evaluation, and\nCoT evaluation.",
      "tldr_zh": "该研究引入了 Moxin 7B，一款完全开源的大型语言模型（LLMs），从预训练到微调的全过程均公开，包括训练代码、数据集和检查点，以提升模型的透明性和可重复性。研究者首先通过预训练获得基模型，然后使用 SOTA 后训练框架和指令数据微调得到 Moxin Instruct 模型，随后结合 chain-of-thought 数据和 GRPO 算法进行强化学习，优化模型的推理能力。实验结果显示，Moxin 系列模型在零样本、少样本和 CoT 评估中表现出色，超越了现有基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06845v4",
      "published_date": "2024-12-08 02:01:46 UTC",
      "updated_date": "2025-04-23 01:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:48:19.716545"
    },
    {
      "arxiv_id": "2412.05768v1",
      "title": "Uncovering Uncertainty in Transformer Inference",
      "title_zh": "揭示 Transformer 推理中的不确定性",
      "authors": [
        "Greyson Brothers",
        "Willa Mannering",
        "Amber Tien",
        "John Winder"
      ],
      "abstract": "We explore the Iterative Inference Hypothesis (IIH) within the context of\ntransformer-based language models, aiming to understand how a model's latent\nrepresentations are progressively refined and whether observable differences\nare present between correct and incorrect generations. Our findings provide\nempirical support for the IIH, showing that the nth token embedding in the\nresidual stream follows a trajectory of decreasing loss. Additionally, we\nobserve that the rate at which residual embeddings converge to a stable output\nrepresentation reflects uncertainty in the token generation process. Finally,\nwe introduce a method utilizing cross-entropy to detect this uncertainty and\ndemonstrate its potential to distinguish between correct and incorrect token\ngenerations on a dataset of idioms.",
      "tldr_zh": "本文探讨了 Iterative Inference Hypothesis (IIH) 在 transformer-based 语言模型中的应用，旨在分析模型的潜在表示如何逐步完善，以及正确和错误生成之间的差异。研究发现，residual stream 中的第 n 个 token 嵌入损失逐渐减少，且其收敛速度可作为 token 生成不确定性的指标。作者引入了一种基于 cross-entropy 的方法来检测这种不确定性，并在 idioms 数据集上验证其能有效区分正确和错误 token 生成。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50 (Primary), 68T07 (Secondary)",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted poster at the 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024) Workshop on Foundation Model Interventions",
      "pdf_url": "http://arxiv.org/pdf/2412.05768v1",
      "published_date": "2024-12-08 00:46:10 UTC",
      "updated_date": "2024-12-08 00:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:50:30.135942"
    },
    {
      "arxiv_id": "2412.05766v1",
      "title": "Policy-shaped prediction: avoiding distractions in model-based reinforcement learning",
      "title_zh": "策略塑造的预测：避免基于模型的强化学习中的干扰",
      "authors": [
        "Miles Hutson",
        "Isaac Kauvar",
        "Nick Haber"
      ],
      "abstract": "Model-based reinforcement learning (MBRL) is a promising route to\nsample-efficient policy optimization. However, a known vulnerability of\nreconstruction-based MBRL consists of scenarios in which detailed aspects of\nthe world are highly predictable, but irrelevant to learning a good policy.\nSuch scenarios can lead the model to exhaust its capacity on meaningless\ncontent, at the cost of neglecting important environment dynamics. While\nexisting approaches attempt to solve this problem, we highlight its continuing\nimpact on leading MBRL methods -- including DreamerV3 and DreamerPro -- with a\nnovel environment where background distractions are intricate, predictable, and\nuseless for planning future actions. To address this challenge we develop a\nmethod for focusing the capacity of the world model through synergy of a\npretrained segmentation model, a task-aware reconstruction loss, and\nadversarial learning. Our method outperforms a variety of other approaches\ndesigned to reduce the impact of distractors, and is an advance towards robust\nmodel-based reinforcement learning.",
      "tldr_zh": "这篇论文探讨了基于模型的强化学习(MBRL)中一个关键问题：模型可能过度关注高度可预测但无关的细节，从而浪费容量并忽略重要环境动态。作者通过一个新环境展示了这一问题对现有方法如 DreamerV3 和 DreamerPro 的持续影响。针对此，他们提出了一种策略，通过预训练的分割模型、任务感知的重建损失和对抗学习，专注于世界模型的关键部分。实验结果显示，该方法优于其他减少干扰的方法，提升了 MBRL 的鲁棒性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.05766v1",
      "published_date": "2024-12-08 00:21:37 UTC",
      "updated_date": "2024-12-08 00:21:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:48:41.124944"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 57,
  "processed_papers_count": 57,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T09:51:02.749063"
}