[
  {
    "arxiv_id": "2412.06099v2",
    "title": "DECO: Life-Cycle Management of Enterprise-Grade Copilots",
    "authors": [
      "Yiwen Zhu",
      "Mathieu Demarne",
      "Kai Deng",
      "Wenjing Wang",
      "Nutan Sahoo",
      "Divya Vermareddy",
      "Hannah Lerner",
      "Yunlei Lu",
      "Swati Bararia",
      "Anjali Bhavan",
      "William Zhang",
      "Xia Li",
      "Katherine Lin",
      "Miso Cilimdzic",
      "Subru Krishnan"
    ],
    "abstract": "Software engineers frequently grapple with the challenge of accessing\ndisparate documentation and telemetry data, including TroubleShooting Guides\n(TSGs), incident reports, code repositories, and various internal tools\ndeveloped by multiple stakeholders. While on-call duties are inevitable,\nincident resolution becomes even more daunting due to the obscurity of legacy\nsources and the pressures of strict time constraints. To enhance the efficiency\nof on-call engineers (OCEs) and streamline their daily workflows, we introduced\nDECO-a comprehensive framework for developing, deploying, and managing\nenterprise-grade copilots tailored to improve productivity in engineering\nroutines. This paper details the design and implementation of the DECO\nframework, emphasizing its innovative NL2SearchQuery functionality and a\nlightweight agentic framework. These features support efficient and customized\nretrieval-augmented-generation (RAG) algorithms that not only extract relevant\ninformation from diverse sources but also select the most pertinent skills in\nresponse to user queries. This enables the addressing of complex technical\nquestions and provides seamless, automated access to internal resources.\nAdditionally, DECO incorporates a robust mechanism for converting unstructured\nincident logs into user-friendly, structured guides, effectively bridging the\ndocumentation gap.\n  Since its launch in September 2023, DECO has demonstrated its effectiveness\nthrough widespread adoption, enabling tens of thousands of interactions and\nengaging hundreds of monthly active users (MAU) across dozens of organizations\nwithin the company.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06099v2",
    "published_date": "2024-12-08 23:00:06 UTC",
    "updated_date": "2025-03-10 05:24:19 UTC"
  },
  {
    "arxiv_id": "2412.06097v2",
    "title": "Order Theory in the Context of Machine Learning",
    "authors": [
      "Eric Dolores-Cuenca",
      "Aldo Guzman-Saenz",
      "Sangil Kim",
      "Susana Lopez-Moreno",
      "Jose Mendoza-Cortes"
    ],
    "abstract": "The paper ``Tropical Geometry of Deep Neural Networks'' by L. Zhang et al.\nintroduces an equivalence between integer-valued neural networks (IVNN) with\n$\\text{ReLU}_{t}$ and tropical rational functions, which come with a map to\npolytopes. Here, IVNN refers to a network with integer weights but real biases,\nand $\\text{ReLU}_{t}$ is defined as $\\text{ReLU}_{t}(x)=\\max(x,t)$ for\n$t\\in\\mathbb{R}\\cup\\{-\\infty\\}$.\n  For every poset with $n$ points, there exists a corresponding order polytope,\ni.e., a convex polytope in the unit cube $[0,1]^n$ whose coordinates obey the\ninequalities of the poset. We study neural networks whose associated polytope\nis an order polytope. We then explain how posets with four points induce neural\nnetworks that can be interpreted as $2\\times 2$ convolutional filters. These\nposet filters can be added to any neural network, not only IVNN.\n  Similarly to maxout, poset pooling filters update the weights of the neural\nnetwork during backpropagation with more precision than average pooling, max\npooling, or mixed pooling, without the need to train extra parameters. We\nreport experiments that support our statements.\n  We also define the structure of algebra over the operad of posets on poset\nneural networks and tropical polynomials. This formalism allows us to study the\ncomposition of poset neural network arquitectures and the effect on their\ncorresponding Newton polytopes, via the introduction of the generalization of\ntwo operations on polytopes: the Minkowski sum and the convex envelope.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "math.CT",
      "68T07, 06A99, 68T05, 18M60, 52B11, 68Q55, 14T10, 06F99",
      "I.2.6; I.5.1"
    ],
    "primary_category": "cs.CV",
    "comment": "We added experiments with ImageNet 100, and improved the exposition\n  of the theory developed. Added examples. Poster presentation in NeurIPS WIML\n  2024, Talk in JMM 2025 section: Applied category theory II",
    "pdf_url": "http://arxiv.org/pdf/2412.06097v2",
    "published_date": "2024-12-08 22:57:41 UTC",
    "updated_date": "2025-03-04 12:32:31 UTC"
  },
  {
    "arxiv_id": "2412.06090v1",
    "title": "Trust No AI: Prompt Injection Along The CIA Security Triad",
    "authors": [
      "Johann Rehberger"
    ],
    "abstract": "The CIA security triad - Confidentiality, Integrity, and Availability - is a\ncornerstone of data and cybersecurity. With the emergence of large language\nmodel (LLM) applications, a new class of threat, known as prompt injection, was\nfirst identified in 2022. Since then, numerous real-world vulnerabilities and\nexploits have been documented in production LLM systems, including those from\nleading vendors like OpenAI, Microsoft, Anthropic and Google. This paper\ncompiles real-world exploits and proof-of concept examples, based on the\nresearch conducted and publicly documented by the author, demonstrating how\nprompt injection undermines the CIA triad and poses ongoing risks to\ncybersecurity and AI systems at large.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Based on research presented at Black Hat Europe 2024, Microsoft\n  Bluehat 2024 and publications from embracethered.com",
    "pdf_url": "http://arxiv.org/pdf/2412.06090v1",
    "published_date": "2024-12-08 22:46:30 UTC",
    "updated_date": "2024-12-08 22:46:30 UTC"
  },
  {
    "arxiv_id": "2412.06088v1",
    "title": "A4-Unet: Deformable Multi-Scale Attention Network for Brain Tumor Segmentation",
    "authors": [
      "Ruoxin Wang",
      "Tianyi Tang",
      "Haiming Du",
      "Yuxuan Cheng",
      "Yu Wang",
      "Lingjie Yang",
      "Xiaohui Duan",
      "Yunfang Yu",
      "Yu Zhou",
      "Donglong Chen"
    ],
    "abstract": "Brain tumor segmentation models have aided diagnosis in recent years.\nHowever, they face MRI complexity and variability challenges, including\nirregular shapes and unclear boundaries, leading to noise, misclassification,\nand incomplete segmentation, thereby limiting accuracy. To address these\nissues, we adhere to an outstanding Convolutional Neural Networks (CNNs) design\nparadigm and propose a novel network named A4-Unet. In A4-Unet, Deformable\nLarge Kernel Attention (DLKA) is incorporated in the encoder, allowing for\nimproved capture of multi-scale tumors. Swin Spatial Pyramid Pooling (SSPP)\nwith cross-channel attention is employed in a bottleneck further to study\nlong-distance dependencies within images and channel relationships. To enhance\naccuracy, a Combined Attention Module (CAM) with Discrete Cosine Transform\n(DCT) orthogonality for channel weighting and convolutional element-wise\nmultiplication is introduced for spatial weighting in the decoder. Attention\ngates (AG) are added in the skip connection to highlight the foreground while\nsuppressing irrelevant background information. The proposed network is\nevaluated on three authoritative MRI brain tumor benchmarks and a proprietary\ndataset, and it achieves a 94.4% Dice score on the BraTS 2020 dataset, thereby\nestablishing multiple new state-of-the-art benchmarks. The code is available\nhere: https://github.com/WendyWAAAAANG/A4-Unet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 14 figures, IEEE International Conference on Bioinformatics\n  and Biomedicine (BIBM) 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.06088v1",
    "published_date": "2024-12-08 22:28:53 UTC",
    "updated_date": "2024-12-08 22:28:53 UTC"
  },
  {
    "arxiv_id": "2412.06087v1",
    "title": "Ethnography and Machine Learning: Synergies and New Directions",
    "authors": [
      "Zhuofan Li",
      "Corey M. Abramson"
    ],
    "abstract": "Ethnography (social scientific methods that illuminate how people understand,\nnavigate and shape the real world contexts in which they live their lives) and\nmachine learning (computational techniques that use big data and statistical\nlearning models to perform quantifiable tasks) are each core to contemporary\nsocial science. Yet these tools have remained largely separate in practice.\nThis chapter draws on a growing body of scholarship that argues that\nethnography and machine learning can be usefully combined, particularly for\nlarge comparative studies. Specifically, this paper (a) explains the value (and\nchallenges) of using machine learning alongside qualitative field research for\ncertain types of projects, (b) discusses recent methodological trends to this\neffect, (c) provides examples that illustrate workflow drawn from several large\nprojects, and (d) concludes with a roadmap for enabling productive coevolution\nof field methods and machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.06087v1",
    "published_date": "2024-12-08 22:28:05 UTC",
    "updated_date": "2024-12-08 22:28:05 UTC"
  },
  {
    "arxiv_id": "2412.06080v1",
    "title": "GVDepth: Zero-Shot Monocular Depth Estimation for Ground Vehicles based on Probabilistic Cue Fusion",
    "authors": [
      "Karlo Koledic",
      "Luka Petrovic",
      "Ivan Markovic",
      "Ivan Petrovic"
    ],
    "abstract": "Generalizing metric monocular depth estimation presents a significant\nchallenge due to its ill-posed nature, while the entanglement between camera\nparameters and depth amplifies issues further, hindering multi-dataset training\nand zero-shot accuracy. This challenge is particularly evident in autonomous\nvehicles and mobile robotics, where data is collected with fixed camera setups,\nlimiting the geometric diversity. Yet, this context also presents an\nopportunity: the fixed relationship between the camera and the ground plane\nimposes additional perspective geometry constraints, enabling depth regression\nvia vertical image positions of objects. However, this cue is highly\nsusceptible to overfitting, thus we propose a novel canonical representation\nthat maintains consistency across varied camera setups, effectively\ndisentangling depth from specific parameters and enhancing generalization\nacross datasets. We also propose a novel architecture that adaptively and\nprobabilistically fuses depths estimated via object size and vertical image\nposition cues. A comprehensive evaluation demonstrates the effectiveness of the\nproposed approach on five autonomous driving datasets, achieving accurate\nmetric depth estimation for varying resolutions, aspect ratios and camera\nsetups. Notably, we achieve comparable accuracy to existing zero-shot methods,\ndespite training on a single dataset with a single-camera setup.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website: https://gvdepth.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.06080v1",
    "published_date": "2024-12-08 22:04:34 UTC",
    "updated_date": "2024-12-08 22:04:34 UTC"
  },
  {
    "arxiv_id": "2412.06858v2",
    "title": "Taming Sensitive Weights : Noise Perturbation Fine-tuning for Robust LLM Quantization",
    "authors": [
      "Dongwei Wang",
      "Huanrui Yang"
    ],
    "abstract": "Quantization is a critical step to enable efficient LLM serving under limited\nresource. However, previous research observes that certain weights in the LLM,\nknown as outliers, are significantly sensitive to quantization noises. Existing\nquantization methods leave these outliers as floating points or higher\nprecisions to retain performance, posting challenges on the efficient hardware\ndeployment of the mixed-precision model. This work investigates an alternative\nway to tame the sensitive weights' impact on the quantization error, by\nreducing the loss Hessian trace with respect to outliers through an efficient\nfine-tuning process. We propose Noise Perturbation Fine-tuning (NPFT), which\nidentifies outlier weights and add random weight perturbations on the outliers\nas the model going through a PEFT optimization. NPFT tames the sensitivity of\noutlier weights so that the quantized model performance can be improved without\nspecial treatment to the outliers. When applied to OPT and LLaMA models, our\nNPFT method achieves stable performance improvements for both uniform and\nnon-uniform quantizers, while also offering better inference efficiency.\nNotably, the simplest RTN can achieve performance on par with GPTQ using our\nNPFT on LLaMA2-7B-4bits benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as poster by CPAL2025",
    "pdf_url": "http://arxiv.org/pdf/2412.06858v2",
    "published_date": "2024-12-08 21:46:22 UTC",
    "updated_date": "2025-03-15 19:35:05 UTC"
  },
  {
    "arxiv_id": "2412.06071v2",
    "title": "KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models",
    "authors": [
      "Fan Wang",
      "Juyong Jiang",
      "Chansung Park",
      "Sunghun Kim",
      "Jing Tang"
    ],
    "abstract": "The increasing sizes of large language models (LLMs) result in significant\ncomputational overhead and memory usage when adapting these models to specific\ntasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have\nbeen devised to mitigate these challenges by training a small set of parameters\nfor the task-specific updates of the model weights. Among PEFT methods, LoRA\nstands out for its simplicity and efficiency, inspiring the development of a\nseries of variants. However, LoRA and its successors disregard the knowledge\nthat is noisy or irrelevant to the targeted task, detrimentally impacting model\nperformance and leading to suboptimality. To address this limitation, we\nintroduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that\nleverages singular value decomposition (SVD) with knowledge-aware singular\nvalues to dynamically activate knowledge based on its relevance to the task at\nhand. We conduct extensive experiments across a range of LLMs on tasks spanning\nnatural language understanding (NLU), generation (NLG), instruction following,\nand commonsense reasoning. The experimental results demonstrate that KaSA\nconsistently outperforms FFT and 14 popular PEFT baselines across 16 benchmarks\nand 4 synthetic datasets, underscoring our method's efficacy and adaptability.\nThe source code of our method is available at\nhttps://github.com/juyongjiang/KaSA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The first three authors contributed equally to this work; Accepted by\n  ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.06071v2",
    "published_date": "2024-12-08 21:26:22 UTC",
    "updated_date": "2025-02-28 05:46:45 UTC"
  },
  {
    "arxiv_id": "2412.06069v1",
    "title": "Fuzzy Norm-Explicit Product Quantization for Recommender Systems",
    "authors": [
      "Mohammadreza Jamalifard",
      "Javier Andreu-Perez",
      "Hani Hagras",
      "Luis Martínez López"
    ],
    "abstract": "As the data resources grow, providing recommendations that best meet the\ndemands has become a vital requirement in business and life to overcome the\ninformation overload problem. However, building a system suggesting relevant\nrecommendations has always been a point of debate. One of the most\ncost-efficient techniques in terms of producing relevant recommendations at a\nlow complexity is Product Quantization (PQ). PQ approaches have continued\ndeveloping in recent years. This system's crucial challenge is improving\nproduct quantization performance in terms of recall measures without\ncompromising its complexity. This makes the algorithm suitable for problems\nthat require a greater number of potentially relevant items without\ndisregarding others, at high-speed and low-cost to keep up with traffic. This\nis the case of online shops where the recommendations for the purpose are\nimportant, although customers can be susceptible to scoping other products.\nThis research proposes a fuzzy approach to perform norm-based product\nquantization. Type-2 Fuzzy sets (T2FSs) define the codebook allowing\nsub-vectors (T2FSs) to be associated with more than one element of the\ncodebook, and next, its norm calculus is resolved by means of integration. Our\nmethod finesses the recall measure up, making the algorithm suitable for\nproblems that require querying at most possible potential relevant items\nwithout disregarding others. The proposed method outperforms all PQ approaches\nsuch as NEQ, PQ, and RQ up to +6%, +5%, and +8% by achieving a recall of 94%,\n69%, 59% in Netflix, Audio, Cifar60k datasets, respectively. More and over,\ncomputing time and complexity nearly equals the most computationally efficient\nexisting PQ method in the state-of-the-art.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "68",
      "I.2; I.1"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06069v1",
    "published_date": "2024-12-08 21:14:57 UTC",
    "updated_date": "2024-12-08 21:14:57 UTC"
  },
  {
    "arxiv_id": "2412.06061v2",
    "title": "Curse of Attention: A Kernel-Based Perspective for Why Transformers Fail to Generalize on Time Series Forecasting and Beyond",
    "authors": [
      "Yekun Ke",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song",
      "Chiwun Yang"
    ],
    "abstract": "The application of transformer-based models on time series forecasting (TSF)\ntasks has long been popular to study. However, many of these works fail to beat\nthe simple linear residual model, and the theoretical understanding of this\nissue is still limited. In this work, we propose the first theoretical\nexplanation of the inefficiency of transformers on TSF tasks. We attribute the\nmechanism behind it to {\\bf Asymmetric Learning} in training attention\nnetworks. When the sign of the previous step is inconsistent with the sign of\nthe current step in the next-step-prediction time series, attention fails to\nlearn the residual features. This makes it difficult to generalize on\nout-of-distribution (OOD) data, especially on the sign-inconsistent\nnext-step-prediction data, with the same representation pattern, whereas a\nlinear residual network could easily accomplish it. We hope our theoretical\ninsights provide important necessary conditions for designing the expressive\nand efficient transformer-based architecture for practitioners.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CPAL 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.06061v2",
    "published_date": "2024-12-08 20:29:06 UTC",
    "updated_date": "2025-02-28 20:36:37 UTC"
  },
  {
    "arxiv_id": "2412.06060v1",
    "title": "Steering Large Language Models to Evaluate and Amplify Creativity",
    "authors": [
      "Matthew Lyle Olson",
      "Neale Ratzlaff",
      "Musashi Hinck",
      "Shao-yen Tseng",
      "Vasudev Lal"
    ],
    "abstract": "Although capable of generating creative text, Large Language Models (LLMs)\nare poor judges of what constitutes \"creativity\". In this work, we show that we\ncan leverage this knowledge of how to write creatively in order to better judge\nwhat is creative. We take a mechanistic approach that extracts differences in\nthe internal states of an LLM when prompted to respond \"boringly\" or\n\"creatively\" to provide a robust measure of creativity that corresponds\nstrongly with human judgment. We also show these internal state differences can\nbe applied to enhance the creativity of generated text at inference time.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "(Spotlight) NeurIPS 2024 Workshop on Creativity & Generative AI.\n  Authors 1 and 2 contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2412.06060v1",
    "published_date": "2024-12-08 20:28:48 UTC",
    "updated_date": "2024-12-08 20:28:48 UTC"
  },
  {
    "arxiv_id": "2412.06855v4",
    "title": "Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution",
    "authors": [
      "Tomer Jordi Chaffer",
      "Justin Goldston",
      "Gemach D. A. T. A. I"
    ],
    "abstract": "Cooperation is vital to our survival and progress. Evolutionary game theory\noffers a lens to understand the structures and incentives that enable\ncooperation to be a successful strategy. As artificial intelligence agents\nbecome integral to human systems, the dynamics of cooperation take on\nunprecedented significance. The convergence of human-agent teaming, contract\ntheory, and decentralized frameworks like Web3, grounded in transparency,\naccountability, and trust, offers a foundation for fostering cooperation by\nestablishing enforceable rules and incentives for humans and AI agents. We\nconceptualize Incentivized Symbiosis as a social contract between humans and\nAI, inspired by Web3 principles and encoded in blockchain technology, to define\nand enforce rules, incentives, and consequences for both parties. By exploring\nthis paradigm, we aim to catalyze new research at the intersection of systems\nthinking in AI, Web3, and society, fostering innovative pathways for\ncooperative human-agent coevolution.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06855v4",
    "published_date": "2024-12-08 20:23:48 UTC",
    "updated_date": "2025-04-25 18:38:37 UTC"
  },
  {
    "arxiv_id": "2412.06044v1",
    "title": "Cloud Platforms for Developing Generative AI Solutions: A Scoping Review of Tools and Services",
    "authors": [
      "Dhavalkumar Patel",
      "Ganesh Raut",
      "Satya Narayan Cheetirala",
      "Girish N Nadkarni",
      "Robert Freeman",
      "Benjamin S. Glicksberg",
      "Eyal Klang",
      "Prem Timsina"
    ],
    "abstract": "Generative AI is transforming enterprise application development by enabling\nmachines to create content, code, and designs. These models, however, demand\nsubstantial computational power and data management. Cloud computing addresses\nthese needs by offering infrastructure to train, deploy, and scale generative\nAI models. This review examines cloud services for generative AI, focusing on\nkey providers like Amazon Web Services (AWS), Microsoft Azure, Google Cloud,\nIBM Cloud, Oracle Cloud, and Alibaba Cloud. It compares their strengths,\nweaknesses, and impact on enterprise growth. We explore the role of\nhigh-performance computing (HPC), serverless architectures, edge computing, and\nstorage in supporting generative AI. We also highlight the significance of data\nmanagement, networking, and AI-specific tools in building and deploying these\nmodels. Additionally, the review addresses security concerns, including data\nprivacy, compliance, and AI model protection. It assesses the performance and\ncost efficiency of various cloud providers and presents case studies from\nhealthcare, finance, and entertainment. We conclude by discussing challenges\nand future directions, such as technical hurdles, vendor lock-in,\nsustainability, and regulatory issues. Put together, this work can serve as a\nguide for practitioners and researchers looking to adopt cloud-based generative\nAI solutions, serving as a valuable guide to navigating the intricacies of this\nevolving field.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.DC",
    "comment": "65 pages, 10 Figures,and supplementary methods detailing extended\n  technical descriptions, service matrices, SWOT analyses, and detailed\n  provider comparisons",
    "pdf_url": "http://arxiv.org/pdf/2412.06044v1",
    "published_date": "2024-12-08 19:49:07 UTC",
    "updated_date": "2024-12-08 19:49:07 UTC"
  },
  {
    "arxiv_id": "2412.06040v1",
    "title": "The AI Double Standard: Humans Judge All AIs for the Actions of One",
    "authors": [
      "Aikaterina Manoli",
      "Janet V. T. Pauketat",
      "Jacy Reese Anthis"
    ],
    "abstract": "Robots and other artificial intelligence (AI) systems are widely perceived as\nmoral agents responsible for their actions. As AI proliferates, these\nperceptions may become entangled via the moral spillover of attitudes towards\none AI to attitudes towards other AIs. We tested how the seemingly harmful and\nimmoral actions of an AI or human agent spill over to attitudes towards other\nAIs or humans in two preregistered experiments. In Study 1 (N = 720), we\nestablished the moral spillover effect in human-AI interaction by showing that\nimmoral actions increased attributions of negative moral agency (i.e., acting\nimmorally) and decreased attributions of positive moral agency (i.e., acting\nmorally) and moral patiency (i.e., deserving moral concern) to both the agent\n(a chatbot or human assistant) and the group to which they belong (all chatbot\nor human assistants). There was no significant difference in the spillover\neffects between the AI and human contexts. In Study 2 (N = 684), we tested\nwhether spillover persisted when the agent was individuated with a name and\ndescribed as an AI or human, rather than specifically as a chatbot or personal\nassistant. We found that spillover persisted in the AI context but not in the\nhuman context, possibly because AIs were perceived as more homogeneous due to\ntheir outgroup status relative to humans. This asymmetry suggests a double\nstandard whereby AIs are judged more harshly than humans when one agent morally\ntransgresses. With the proliferation of diverse, autonomous AI systems, HCI\nresearch and design should account for the fact that experiences with one AI\ncould easily generalize to perceptions of all AIs and negative HCI outcomes,\nsuch as reduced trust.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06040v1",
    "published_date": "2024-12-08 19:26:52 UTC",
    "updated_date": "2024-12-08 19:26:52 UTC"
  },
  {
    "arxiv_id": "2412.06033v1",
    "title": "Can Generative AI Solve Your In-Context Learning Problem? A Martingale Perspective",
    "authors": [
      "Andrew Jesson",
      "Nicolas Beltran-Velez",
      "David Blei"
    ],
    "abstract": "This work is about estimating when a conditional generative model (CGM) can\nsolve an in-context learning (ICL) problem. An in-context learning (ICL)\nproblem comprises a CGM, a dataset, and a prediction task. The CGM could be a\nmulti-modal foundation model; the dataset, a collection of patient histories,\ntest results, and recorded diagnoses; and the prediction task to communicate a\ndiagnosis to a new patient. A Bayesian interpretation of ICL assumes that the\nCGM computes a posterior predictive distribution over an unknown Bayesian model\ndefining a joint distribution over latent explanations and observable data.\nFrom this perspective, Bayesian model criticism is a reasonable approach to\nassess the suitability of a given CGM for an ICL problem. However, such\napproaches -- like posterior predictive checks (PPCs) -- often assume that we\ncan sample from the likelihood and posterior defined by the Bayesian model,\nwhich are not explicitly given for contemporary CGMs. To address this, we show\nwhen ancestral sampling from the predictive distribution of a CGM is equivalent\nto sampling datasets from the posterior predictive of the assumed Bayesian\nmodel. Then we develop the generative predictive $p$-value, which enables PPCs\nand their cousins for contemporary CGMs. The generative predictive $p$-value\ncan then be used in a statistical decision procedure to determine when the\nmodel is appropriate for an ICL problem. Our method only requires generating\nqueries and responses from a CGM and evaluating its response log probability.\nWe empirically evaluate our method on synthetic tabular, imaging, and natural\nlanguage ICL tasks using large language models.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06033v1",
    "published_date": "2024-12-08 19:03:21 UTC",
    "updated_date": "2024-12-08 19:03:21 UTC"
  },
  {
    "arxiv_id": "2412.06018v1",
    "title": "Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research",
    "authors": [
      "Akshat Choube",
      "Rahul Majethia",
      "Sohini Bhattacharya",
      "Vedant Das Swain",
      "Jiachen Li",
      "Varun Mishra"
    ],
    "abstract": "Longitudinal passive sensing studies for health and behavior outcomes often\nhave missing and incomplete data. Handling missing data effectively is thus a\ncritical data processing and modeling step. Our formative interviews with\nresearchers working in longitudinal health and behavior passive sensing\nrevealed a recurring theme: most researchers consider imputation a low-priority\nstep in their analysis and inference pipeline, opting to use simple and\noff-the-shelf imputation strategies without comprehensively evaluating its\nimpact on study outcomes. Through this paper, we call attention to the\nimportance of imputation. Using publicly available passive sensing datasets for\ndepression, we show that prioritizing imputation can significantly impact the\nstudy outcomes -- with our proposed imputation strategies resulting in up to\n31% improvement in AUROC to predict depression over the original imputation\nstrategy. We conclude by discussing the challenges and opportunities with\neffective imputation in longitudinal sensing studies.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06018v1",
    "published_date": "2024-12-08 18:29:53 UTC",
    "updated_date": "2024-12-08 18:29:53 UTC"
  },
  {
    "arxiv_id": "2412.06016v3",
    "title": "Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation",
    "authors": [
      "Hyeonho Jeong",
      "Chun-Hao Paul Huang",
      "Jong Chul Ye",
      "Niloy Mitra",
      "Duygu Ceylan"
    ],
    "abstract": "While recent foundational video generators produce visually rich output, they\nstill struggle with appearance drift, where objects gradually degrade or change\ninconsistently across frames, breaking visual coherence. We hypothesize that\nthis is because there is no explicit supervision in terms of spatial tracking\nat the feature level. We propose Track4Gen, a spatially aware video generator\nthat combines video diffusion loss with point tracking across frames, providing\nenhanced spatial supervision on the diffusion features. Track4Gen merges the\nvideo generation and point tracking tasks into a single network by making\nminimal changes to existing video generation architectures. Using Stable Video\nDiffusion as a backbone, Track4Gen demonstrates that it is possible to unify\nvideo generation and point tracking, which are typically handled as separate\ntasks. Our extensive evaluations show that Track4Gen effectively reduces\nappearance drift, resulting in temporally stable and visually coherent video\ngeneration. Project page: hyeonho99.github.io/track4gen",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025, Project page: hyeonho99.github.io/track4gen",
    "pdf_url": "http://arxiv.org/pdf/2412.06016v3",
    "published_date": "2024-12-08 18:21:00 UTC",
    "updated_date": "2025-04-07 11:16:47 UTC"
  },
  {
    "arxiv_id": "2412.05994v3",
    "title": "PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations",
    "authors": [
      "Namgyu Kang",
      "Jaemin Oh",
      "Youngjoon Hong",
      "Eunbyung Park"
    ],
    "abstract": "The numerical approximation of partial differential equations (PDEs) using\nneural networks has seen significant advancements through Physics-Informed\nNeural Networks (PINNs). Despite their straightforward optimization framework\nand flexibility in implementing various PDEs, PINNs often suffer from limited\naccuracy due to the spectral bias of Multi-Layer Perceptrons (MLPs), which\nstruggle to effectively learn high-frequency and nonlinear components.\nRecently, parametric mesh representations in combination with neural networks\nhave been investigated as a promising approach to eliminate the inductive bias\nof MLPs. However, they usually require high-resolution grids and a large number\nof collocation points to achieve high accuracy while avoiding overfitting. In\naddition, the fixed positions of the mesh parameters restrict their\nflexibility, making accurate approximation of complex PDEs challenging. To\novercome these limitations, we propose Physics-Informed Gaussians (PIGs), which\ncombine feature embeddings using Gaussian functions with a lightweight neural\nnetwork. Our approach uses trainable parameters for the mean and variance of\neach Gaussian, allowing for dynamic adjustment of their positions and shapes\nduring training. This adaptability enables our model to optimally approximate\nPDE solutions, unlike models with fixed parameter positions. Furthermore, the\nproposed approach maintains the same optimization framework used in PINNs,\nallowing us to benefit from their excellent properties. Experimental results\nshow the competitive performance of our model across various PDEs,\ndemonstrating its potential as a robust tool for solving complex PDEs. Our\nproject page is available at\nhttps://namgyukang.github.io/Physics-Informed-Gaussians/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR 2025. Project page:\n  https://namgyukang.github.io/Physics-Informed-Gaussians/",
    "pdf_url": "http://arxiv.org/pdf/2412.05994v3",
    "published_date": "2024-12-08 16:58:29 UTC",
    "updated_date": "2025-03-18 14:17:32 UTC"
  },
  {
    "arxiv_id": "2412.05968v1",
    "title": "LVS-Net: A Lightweight Vessels Segmentation Network for Retinal Image Analysis",
    "authors": [
      "Mehwish Mehmood",
      "Shahzaib Iqbal",
      "Tariq Mahmood Khan",
      "Ivor Spence",
      "Muhammad Fahim"
    ],
    "abstract": "The analysis of retinal images for the diagnosis of various diseases is one\nof the emerging areas of research. Recently, the research direction has been\ninclined towards investigating several changes in retinal blood vessels in\nsubjects with many neurological disorders, including dementia. This research\nfocuses on detecting diseases early by improving the performance of models for\nsegmentation of retinal vessels with fewer parameters, which reduces\ncomputational costs and supports faster processing. This paper presents a novel\nlightweight encoder-decoder model that segments retinal vessels to improve the\nefficiency of disease detection. It incorporates multi-scale convolutional\nblocks in the encoder to accurately identify vessels of various sizes and\nthicknesses. The bottleneck of the model integrates the Focal Modulation\nAttention and Spatial Feature Refinement Blocks to refine and enhance essential\nfeatures for efficient segmentation. The decoder upsamples features and\nintegrates them with the corresponding feature in the encoder using skip\nconnections and the spatial feature refinement block at every upsampling stage\nto enhance feature representation at various scales. The estimated computation\ncomplexity of our proposed model is around 29.60 GFLOP with 0.71 million\nparameters and 2.74 MB of memory size, and it is evaluated using public\ndatasets, that is, DRIVE, CHASE\\_DB, and STARE. It outperforms existing models\nwith dice scores of 86.44\\%, 84.22\\%, and 87.88\\%, respectively.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05968v1",
    "published_date": "2024-12-08 15:21:37 UTC",
    "updated_date": "2024-12-08 15:21:37 UTC"
  },
  {
    "arxiv_id": "2412.06853v3",
    "title": "Tube Loss: A Novel Approach for Prediction Interval Estimation and probabilistic forecasting",
    "authors": [
      "Pritam Anand",
      "Tathagata Bandyopadhyay",
      "Suresh Chandra"
    ],
    "abstract": "This paper proposes a novel loss function, called 'Tube Loss', for\nsimultaneous estimation of bounds of a Prediction Interval (PI) in the\nregression setup. The PIs obtained by minimizing the empirical risk based on\nthe Tube Loss are shown to be of better quality than the PIs obtained by the\nexisting methods in the following sense. First, it yields intervals that attain\nthe prespecified confidence level t $\\in$ (0,1) asymptotically. A theoretical\nproof of this fact is given. Secondly, the user is allowed to move the interval\nup or down by controlling the value of a parameter. This helps the user to\nchoose a PI capturing denser regions of the probability distribution of the\nresponse variable inside the interval, and thus, sharpening its width. This is\nshown to be especially useful when the conditional distribution of the response\nvariable is skewed. Further, the Tube Loss based PI estimation method can\ntrade-off between the coverage and the average width by solving a single\noptimization problem. It enables further reduction of the average width of PI\nthrough re-calibration. Also, unlike a few existing PI estimation methods the\ngradient descent (GD) method can be used for minimization of empirical risk.\nThrough extensive experiments, we demonstrate the effectiveness of Tube\nLoss-based PI estimation in both kernel machines and neural networks.\nAdditionally, we show that Tube Loss-based deep probabilistic forecasting\nmodels achieve superior performance compared to existing probabilistic\nforecasting techniques across several benchmark and wind datasets. Finally, we\nempirically validate the advantages of the Tube loss approach within the\nconformal prediction framework. Codes are available at\nhttps://github.com/ltpritamanand/Tube$\\_$loss.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06853v3",
    "published_date": "2024-12-08 15:17:53 UTC",
    "updated_date": "2025-05-17 14:41:26 UTC"
  },
  {
    "arxiv_id": "2412.05967v1",
    "title": "Language hooks: a modular framework for augmenting LLM reasoning that decouples tool usage from the model and its prompt",
    "authors": [
      "Damien de Mijolla",
      "Wen Yang",
      "Philippa Duckett",
      "Christopher Frye",
      "Mark Worrall"
    ],
    "abstract": "Prompting and fine-tuning have emerged as two competing paradigms for\naugmenting language models with new capabilities, such as the use of tools.\nPrompting approaches are quick to set up but rely on providing explicit\ndemonstrations of each tool's usage in the model's prompt, thus coupling tool\nuse to the task at hand and limiting generalisation. Fine-tuning removes the\nneed for task-specific demonstrations of tool usage at runtime; however, this\nties new capabilities to a single model, thus making already-heavier setup\ncosts a recurring expense. In this paper, we introduce language hooks, a novel\nframework for augmenting language models with new capabilities that is\ndecoupled both from the model's task-specific prompt and from the model itself.\nThe language hook algorithm interleaves text generation by the base model with\nthe execution of modular programs that trigger conditionally based on the\nexisting text and the available capabilities. Upon triggering, programs may\ncall external tools, auxiliary language models (e.g. using tool specific\nprompts), and modify the existing context. We benchmark our method against\nstate-of-the-art baselines, find that it outperforms task-aware approaches, and\ndemonstrate its ability to generalise to novel tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This work was conducted during Summer 2023. Experimental results and\n  references reflect the state of the field at that time and may not account\n  for subsequent developments",
    "pdf_url": "http://arxiv.org/pdf/2412.05967v1",
    "published_date": "2024-12-08 15:16:17 UTC",
    "updated_date": "2024-12-08 15:16:17 UTC"
  },
  {
    "arxiv_id": "2412.14186v2",
    "title": "Towards AI-$45^{\\circ}$ Law: A Roadmap to Trustworthy AGI",
    "authors": [
      "Chao Yang",
      "Chaochao Lu",
      "Yingchun Wang",
      "Bowen Zhou"
    ],
    "abstract": "Ensuring Artificial General Intelligence (AGI) reliably avoids harmful\nbehaviors is a critical challenge, especially for systems with high autonomy or\nin safety-critical domains. Despite various safety assurance proposals and\nextreme risk warnings, comprehensive guidelines balancing AI safety and\ncapability remain lacking. In this position paper, we propose the\n\\textit{AI-\\textbf{$45^{\\circ}$} Law} as a guiding principle for a balanced\nroadmap toward trustworthy AGI, and introduce the \\textit{Causal Ladder of\nTrustworthy AGI} as a practical framework. This framework provides a systematic\ntaxonomy and hierarchical structure for current AI capability and safety\nresearch, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder\ncomprises three core layers: the Approximate Alignment Layer, the Intervenable\nLayer, and the Reflectable Layer. These layers address the key challenges of\nsafety and trustworthiness in AGI and contemporary AI systems. Building upon\nthis framework, we define five levels of trustworthy AGI: perception,\nreasoning, decision-making, autonomy, and collaboration trustworthiness. These\nlevels represent distinct yet progressive aspects of trustworthy AGI. Finally,\nwe present a series of potential governance measures to support the development\nof trustworthy AGI.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14186v2",
    "published_date": "2024-12-08 14:14:16 UTC",
    "updated_date": "2024-12-22 08:52:15 UTC"
  },
  {
    "arxiv_id": "2412.05947v1",
    "title": "Materials-Discovery Workflows Guided by Symbolic Regression: Identifying Acid-Stable Oxides for Electrocatalysis",
    "authors": [
      "Akhil S. Nair",
      "Lucas Foppa",
      "Matthias Scheffler"
    ],
    "abstract": "The efficiency of active learning (AL) approaches to identify materials with\ndesired properties relies on the knowledge of a few parameters describing the\nproperty. However, these parameters are unknown if the property is governed by\na high intricacy of many atomistic processes. Here, we develop an AL workflow\nbased on the sure-independence screening and sparsifying operator (SISSO)\nsymbolic-regression approach. SISSO identifies the few, key parameters\ncorrelated with a given materials property via analytical expressions, out of\nmany offered primary features. Crucially, we train ensembles of SISSO models in\norder to quantify mean predictions and their uncertainty, enabling the use of\nSISSO in AL. By combining bootstrap sampling to obtain training datasets with\nMonte-Carlo feature dropout, the high prediction errors observed by a single\nSISSO model are improved. Besides, the feature dropout procedure alleviates the\noverconfidence issues observed in the widely used bagging approach. We\ndemonstrate the SISSO-guided AL workflow by identifying acid-stable oxides for\nwater splitting using high-quality DFT-HSE06 calculations. From a pool of 1470\nmaterials, 12 acid-stable materials are identified in only 30 AL iterations.\nThe materials property maps provided by SISSO along with the uncertainty\nestimates reduce the risk of missing promising portions of the materials space\nthat were overlooked in the initial, possibly biased dataset.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05947v1",
    "published_date": "2024-12-08 14:09:15 UTC",
    "updated_date": "2024-12-08 14:09:15 UTC"
  },
  {
    "arxiv_id": "2412.05937v1",
    "title": "Accelerating Manufacturing Scale-Up from Material Discovery Using Agentic Web Navigation and Retrieval-Augmented AI for Process Engineering Schematics Design",
    "authors": [
      "Sakhinana Sagar Srinivas",
      "Akash Das",
      "Shivam Gupta",
      "Venkataramana Runkana"
    ],
    "abstract": "Process Flow Diagrams (PFDs) and Process and Instrumentation Diagrams (PIDs)\nare critical tools for industrial process design, control, and safety. However,\nthe generation of precise and regulation-compliant diagrams remains a\nsignificant challenge, particularly in scaling breakthroughs from material\ndiscovery to industrial production in an era of automation and digitalization.\nThis paper introduces an autonomous agentic framework to address these\nchallenges through a twostage approach involving knowledge acquisition and\ngeneration. The framework integrates specialized sub-agents for retrieving and\nsynthesizing multimodal data from publicly available online sources and\nconstructs ontological knowledge graphs using a Graph Retrieval-Augmented\nGeneration (Graph RAG) paradigm. These capabilities enable the automation of\ndiagram generation and open-domain question answering (ODQA) tasks with high\ncontextual accuracy. Extensive empirical experiments demonstrate the frameworks\nability to deliver regulation-compliant diagrams with minimal expert\nintervention, highlighting its practical utility for industrial applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05937v1",
    "published_date": "2024-12-08 13:36:42 UTC",
    "updated_date": "2024-12-08 13:36:42 UTC"
  },
  {
    "arxiv_id": "2412.05934v2",
    "title": "Heuristic-Induced Multimodal Risk Distribution Jailbreak Attack for Multimodal Large Language Models",
    "authors": [
      "Ma Teng",
      "Jia Xiaojun",
      "Duan Ranjie",
      "Li Xinfeng",
      "Huang Yihao",
      "Chu Zhixuan",
      "Liu Yang",
      "Ren Wenqi"
    ],
    "abstract": "With the rapid advancement of multimodal large language models (MLLMs),\nconcerns regarding their security have increasingly captured the attention of\nboth academia and industry. Although MLLMs are vulnerable to jailbreak attacks,\ndesigning effective multimodal jailbreak attacks poses unique challenges,\nespecially given the distinct protective measures implemented across various\nmodalities in commercial models. Previous works concentrate risks into a single\nmodality, resulting in limited jailbreak performance. In this paper, we propose\na heuristic-induced multimodal risk distribution jailbreak attack method,\ncalled HIMRD, which consists of two elements: multimodal risk distribution\nstrategy and heuristic-induced search strategy. The multimodal risk\ndistribution strategy is used to segment harmful instructions across multiple\nmodalities to effectively circumvent MLLMs' security protection. The\nheuristic-induced search strategy identifies two types of prompts: the\nunderstanding-enhancing prompt, which helps the MLLM reconstruct the malicious\nprompt, and the inducing prompt, which increases the likelihood of affirmative\noutputs over refusals, enabling a successful jailbreak attack. Extensive\nexperiments demonstrate that this approach effectively uncovers vulnerabilities\nin MLLMs, achieving an average attack success rate of 90% across seven popular\nopen-source MLLMs and an average attack success rate of around 68% in three\npopular closed-source MLLMs. Our code will coming soon. Warning: This paper\ncontains offensive and harmful examples, reader discretion is advised.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05934v2",
    "published_date": "2024-12-08 13:20:45 UTC",
    "updated_date": "2025-01-03 08:54:37 UTC"
  },
  {
    "arxiv_id": "2412.05897v1",
    "title": "Detecting Discrepancies Between AI-Generated and Natural Images Using Uncertainty",
    "authors": [
      "Jun Nie",
      "Yonggang Zhang",
      "Tongliang Liu",
      "Yiu-ming Cheung",
      "Bo Han",
      "Xinmei Tian"
    ],
    "abstract": "In this work, we propose a novel approach for detecting AI-generated images\nby leveraging predictive uncertainty to mitigate misuse and associated risks.\nThe motivation arises from the fundamental assumption regarding the\ndistributional discrepancy between natural and AI-generated images. The\nfeasibility of distinguishing natural images from AI-generated ones is grounded\nin the distribution discrepancy between them. Predictive uncertainty offers an\neffective approach for capturing distribution shifts, thereby providing\ninsights into detecting AI-generated images. Namely, as the distribution shift\nbetween training and testing data increases, model performance typically\ndegrades, often accompanied by increased predictive uncertainty. Therefore, we\npropose to employ predictive uncertainty to reflect the discrepancies between\nAI-generated and natural images. In this context, the challenge lies in\nensuring that the model has been trained over sufficient natural images to\navoid the risk of determining the distribution of natural images as that of\ngenerated images. We propose to leverage large-scale pre-trained models to\ncalculate the uncertainty as the score for detecting AI-generated images. This\nleads to a simple yet effective method for detecting AI-generated images using\nlarge-scale vision models: images that induce high uncertainty are identified\nas AI-generated. Comprehensive experiments across multiple benchmarks\ndemonstrate the effectiveness of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05897v1",
    "published_date": "2024-12-08 11:32:25 UTC",
    "updated_date": "2024-12-08 11:32:25 UTC"
  },
  {
    "arxiv_id": "2412.05893v1",
    "title": "doScenes: An Autonomous Driving Dataset with Natural Language Instruction for Human Interaction and Vision-Language Navigation",
    "authors": [
      "Parthib Roy",
      "Srinivasa Perisetla",
      "Shashank Shriram",
      "Harsha Krishnaswamy",
      "Aryan Keskar",
      "Ross Greer"
    ],
    "abstract": "Human-interactive robotic systems, particularly autonomous vehicles (AVs),\nmust effectively integrate human instructions into their motion planning. This\npaper introduces doScenes, a novel dataset designed to facilitate research on\nhuman-vehicle instruction interactions, focusing on short-term directives that\ndirectly influence vehicle motion. By annotating multimodal sensor data with\nnatural language instructions and referentiality tags, doScenes bridges the gap\nbetween instruction and driving response, enabling context-aware and adaptive\nplanning. Unlike existing datasets that focus on ranking or scene-level\nreasoning, doScenes emphasizes actionable directives tied to static and dynamic\nscene objects. This framework addresses limitations in prior research, such as\nreliance on simulated data or predefined action sets, by supporting nuanced and\nflexible responses in real-world scenarios. This work lays the foundation for\ndeveloping learning strategies that seamlessly integrate human instructions\ninto autonomous systems, advancing safe and effective human-vehicle\ncollaboration for vision-language navigation. We make our data publicly\navailable at https://www.github.com/rossgreer/doScenes",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05893v1",
    "published_date": "2024-12-08 11:16:47 UTC",
    "updated_date": "2024-12-08 11:16:47 UTC"
  },
  {
    "arxiv_id": "2412.05892v3",
    "title": "PBI-Attack: Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack for Toxicity Maximization",
    "authors": [
      "Ruoxi Cheng",
      "Yizhong Ding",
      "Shuirong Cao",
      "Ranjie Duan",
      "Xiaoshuang Jia",
      "Shaowei Yuan",
      "Zhiqiang Wang",
      "Xiaojun Jia"
    ],
    "abstract": "Understanding the vulnerabilities of Large Vision Language Models (LVLMs) to\njailbreak attacks is essential for their responsible real-world deployment.\nMost previous work requires access to model gradients, or is based on human\nknowledge (prompt engineering) to complete jailbreak, and they hardly consider\nthe interaction of images and text, resulting in inability to jailbreak in\nblack box scenarios or poor performance. To overcome these limitations, we\npropose a Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack for\ntoxicity maximization, referred to as PBI-Attack. Our method begins by\nextracting malicious features from a harmful corpus using an alternative LVLM\nand embedding these features into a benign image as prior information.\nSubsequently, we enhance these features through bidirectional cross-modal\ninteraction optimization, which iteratively optimizes the bimodal perturbations\nin an alternating manner through greedy search, aiming to maximize the toxicity\nof the generated response. The toxicity level is quantified using a\nwell-trained evaluation model. Experiments demonstrate that PBI-Attack\noutperforms previous state-of-the-art jailbreak methods, achieving an average\nattack success rate of 92.5% across three open-source LVLMs and around 67.3% on\nthree closed-source LVLMs. Disclaimer: This paper contains potentially\ndisturbing and offensive content.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack for\n  Toxicity Maximization",
    "pdf_url": "http://arxiv.org/pdf/2412.05892v3",
    "published_date": "2024-12-08 11:14:16 UTC",
    "updated_date": "2025-02-03 11:44:59 UTC"
  },
  {
    "arxiv_id": "2412.10413v1",
    "title": "Evaluating Robustness of LLMs on Crisis-Related Microblogs across Events, Information Types, and Linguistic Features",
    "authors": [
      "Muhammad Imran",
      "Abdul Wahab Ziaullah",
      "Kai Chen",
      "Ferda Ofli"
    ],
    "abstract": "The widespread use of microblogging platforms like X (formerly Twitter)\nduring disasters provides real-time information to governments and response\nauthorities. However, the data from these platforms is often noisy, requiring\nautomated methods to filter relevant information. Traditionally, supervised\nmachine learning models have been used, but they lack generalizability. In\ncontrast, Large Language Models (LLMs) show better capabilities in\nunderstanding and processing natural language out of the box. This paper\nprovides a detailed analysis of the performance of six well-known LLMs in\nprocessing disaster-related social media data from a large-set of real-world\nevents. Our findings indicate that while LLMs, particularly GPT-4o and GPT-4,\noffer better generalizability across different disasters and information types,\nmost LLMs face challenges in processing flood-related data, show minimal\nimprovement despite the provision of examples (i.e., shots), and struggle to\nidentify critical information categories like urgent requests and needs.\nAdditionally, we examine how various linguistic features affect model\nperformance and highlight LLMs' vulnerabilities against certain features like\ntypos. Lastly, we provide benchmarking results for all events across both zero-\nand few-shot settings and observe that proprietary models outperform\nopen-source ones in all tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 10 figs, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.10413v1",
    "published_date": "2024-12-08 10:30:29 UTC",
    "updated_date": "2024-12-08 10:30:29 UTC"
  },
  {
    "arxiv_id": "2412.06852v1",
    "title": "EGEAN: An Exposure-Guided Embedding Alignment Network for Post-Click Conversion Estimation",
    "authors": [
      "Huajian Feng",
      "Guoxiao Zhang",
      "Yadong Zhang",
      "Yi We",
      "Qiang Liu"
    ],
    "abstract": "Accurate post-click conversion rate (CVR) estimation is crucial for online\nadvertising systems. Despite significant advances in causal approaches designed\nto address the Sample Selection Bias problem, CVR estimation still faces\nchallenges due to Covariate Shift. Given the intrinsic connection between the\ndistribution of covariates in the click and non-click spaces, this study\nproposes an Exposure-Guided Embedding Alignment Network (EGEAN) to address\nestimation bias caused by covariate shift. Additionally, we propose a Parameter\nVarying Doubly Robust Estimator with steady-state control to handle small\npropensities better. Online A/B tests conducted on the Meituan advertising\nsystem demonstrate that our method significantly outperforms baseline models\nwith respect to CVR and GMV, validating its effectiveness. Code is available:\nhttps://github.com/hydrogen-maker/EGEAN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.06852v1",
    "published_date": "2024-12-08 10:17:02 UTC",
    "updated_date": "2024-12-08 10:17:02 UTC"
  },
  {
    "arxiv_id": "2412.05882v1",
    "title": "Towards Modeling Data Quality and Machine Learning Model Performance",
    "authors": [
      "Usman Anjum",
      "Chris Trentman",
      "Elrod Caden",
      "Justin Zhan"
    ],
    "abstract": "Understanding the effect of uncertainty and noise in data on machine learning\nmodels (MLM) is crucial in developing trust and measuring performance. In this\npaper, a new model is proposed to quantify uncertainties and noise in data on\nMLMs. Using the concept of signal-to-noise ratio (SNR), a new metric called\ndeterministic-non-deterministic ratio (DDR) is proposed to formulate\nperformance of a model. Using synthetic data in experiments, we show how\naccuracy can change with DDR and how we can use DDR-accuracy curves to\ndetermine performance of a model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05882v1",
    "published_date": "2024-12-08 10:15:10 UTC",
    "updated_date": "2024-12-08 10:15:10 UTC"
  },
  {
    "arxiv_id": "2412.05881v1",
    "title": "3D-Consistent Image Inpainting with Diffusion Models",
    "authors": [
      "Leonid Antsfeld",
      "Boris Chidlovskii"
    ],
    "abstract": "We address the problem of 3D inconsistency of image inpainting based on\ndiffusion models. We propose a generative model using image pairs that belong\nto the same scene. To achieve the 3D-consistent and semantically coherent\ninpainting, we modify the generative diffusion model by incorporating an\nalternative point of view of the scene into the denoising process. This creates\nan inductive bias that allows to recover 3D priors while training to denoise in\n2D, without explicit 3D supervision. Training unconditional diffusion models\nwith additional images as in-context guidance allows to harmonize the masked\nand non-masked regions while repainting and ensures the 3D consistency. We\nevaluate our method on one synthetic and three real-world datasets and show\nthat it generates semantically coherent and 3D-consistent inpaintings and\noutperforms the state-of-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 9 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.05881v1",
    "published_date": "2024-12-08 10:07:07 UTC",
    "updated_date": "2024-12-08 10:07:07 UTC"
  },
  {
    "arxiv_id": "2412.05876v1",
    "title": "MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training",
    "authors": [
      "Xuefeng Ni",
      "Linshan Wu",
      "Jiaxin Zhuang",
      "Qiong Wang",
      "Mingxiang Wu",
      "Varut Vardhanabhuti",
      "Lihai Zhang",
      "Hanyu Gao",
      "Hao Chen"
    ],
    "abstract": "3D medical image analysis is pivotal in numerous clinical applications.\nHowever, the scarcity of labeled data and limited generalization capabilities\nhinder the advancement of AI-empowered models. Radiology reports are easily\naccessible and can serve as weakly-supervised signals. However, large-scale\nvision-language pre-training (VLP) remains underexplored in 3D medical image\nanalysis. Specifically, the insufficient investigation into multi-grained\nradiology semantics and their correlations across patients leads to\nunderutilization of large-scale volume-report data.\n  Considering intra-patient cross-modal semantic consistency and inter-patient\nsemantic correlations, we propose a multi-task VLP method, MG-3D, pre-trained\non large-scale data (47.1K), addressing the challenges by the following two\naspects: 1) Establishing the correspondence between volume semantics and\nmulti-grained medical knowledge of each patient with cross-modal global\nalignment and complementary modality-guided local reconstruction, ensuring\nintra-patient features of different modalities cohesively represent the same\nsemantic content; 2) Correlating inter-patient visual semantics based on\nfine-grained report correlations across patients, and keeping sensitivity to\nglobal individual differences via contrastive learning, enhancing the\ndiscriminative feature representation. Furthermore, we delve into the scaling\nlaw to explore potential performance improvements. Comprehensive evaluations\nacross nine uni- and cross-modal clinical tasks are carried out to assess model\nefficacy. Extensive experiments on both internal and external datasets\ndemonstrate the superior transferability, scalability, and generalization of\nMG-3D, showcasing its potential in advancing feature representation for 3D\nmedical image analysis. Code will be available:\nhttps://github.com/Xuefeng-Ni/MG-3D.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 Pages",
    "pdf_url": "http://arxiv.org/pdf/2412.05876v1",
    "published_date": "2024-12-08 09:45:59 UTC",
    "updated_date": "2024-12-08 09:45:59 UTC"
  },
  {
    "arxiv_id": "2412.05868v1",
    "title": "Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information",
    "authors": [
      "Vijayalaxmi Sahadevan",
      "Sushil Mario",
      "Yash Jaiswal",
      "Divyanshu Bajpai",
      "Vishal Singh",
      "Hiralal Aggarwal",
      "Suhas Suresh",
      "Manjunath Maigur"
    ],
    "abstract": "Ontology-based knowledge graphs (KG) are desirable for effective knowledge\nmanagement and reuse in various decision making scenarios, including design.\nCreating and populating extensive KG based on specific ontological models can\nbe highly labour and time-intensive unless automated processes are developed\nfor knowledge extraction and graph creation. Most research and development on\nautomated extraction and creation of KG is based on extensive unstructured data\nsets that provide contextual information. However, some of the most useful\ninformation about the products and services of a company has traditionally been\nrecorded as structured data. Such structured data sets rarely follow a standard\nontology, do not capture explicit mapping of relationships between the\nentities, and provide no contextual information. Therefore, this research\nreports a method and digital workflow developed to address this gap. The\ndeveloped method and workflow employ rule-based techniques to extract and\ncreate a Function Behaviour-Structure (FBS) ontology-based KG from legacy\nstructured data, especially specification sheets and product catalogues. The\nsolution approach consists of two main components: a process for deriving\ncontext and context-based classification rules for FBS ontology concepts and a\nworkflow for populating and retrieving the FBS ontology-based KG. KG and\nNatural Language Processing (NLP) are used to automate knowledge extraction,\nrepresentation, and retrieval. The workflow's effectiveness is demonstrated via\npilot implementation in an industrial context. Insights gained from the pilot\nstudy are reported regarding the challenges and opportunities, including\ndiscussing the FBS ontology and concepts.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "31 pages, with 17 figures and 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.05868v1",
    "published_date": "2024-12-08 09:20:25 UTC",
    "updated_date": "2024-12-08 09:20:25 UTC"
  },
  {
    "arxiv_id": "2412.05864v1",
    "title": "CardOOD: Robust Query-driven Cardinality Estimation under Out-of-Distribution",
    "authors": [
      "Rui Li",
      "Kangfei Zhao",
      "Jeffrey Xu Yu",
      "Guoren Wang"
    ],
    "abstract": "Query-driven learned estimators are accurate, flexible, and lightweight\nalternatives to traditional estimators in query optimization. However, existing\nquery-driven approaches struggle with the Out-of-distribution (OOD) problem,\nwhere the test workload distribution differs from the training workload,\nleading to performancedegradation. In this paper, we present CardOOD, a general\nlearning framework designed to construct robust query-driven cardinality\nestimators that are resilient against the OOD problem. Our framework focuses on\noffline training algorithms that develop one-off models from a static workload,\nsuitable for model initialization and periodic retraining. In CardOOD, we\nextend classical transfer/robust learning techniques to train query-driven\ncardinalityestimators, and the algorithms fall into three categories:\nrepresentation learning, data manipulation, and new learning strategies. As\nthese learning techniques are originally evaluated in computervision tasks, we\nalso propose a new learning algorithm that exploits the property of cardinality\nestimation. This algorithm, lying in the category of new learning strategy,\nmodels the partial order constraint of cardinalities by a self-supervised\nlearning task. Comprehensive experimental studies demonstrate the efficacy of\nthe algorithms of CardOOD in mitigating the OOD problem to varying extents. We\nfurther integrate CardOOD into PostgreSQL, showcasing its practical utility in\nquery optimization.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05864v1",
    "published_date": "2024-12-08 09:11:11 UTC",
    "updated_date": "2024-12-08 09:11:11 UTC"
  },
  {
    "arxiv_id": "2501.14731v1",
    "title": "From Critique to Clarity: A Pathway to Faithful and Personalized Code Explanations with Large Language Models",
    "authors": [
      "Zexing Xu",
      "Zhuang Luo",
      "Yichuan Li",
      "Kyumin Lee",
      "S. Rasoul Etesami"
    ],
    "abstract": "In the realm of software development, providing accurate and personalized\ncode explanations is crucial for both technical professionals and business\nstakeholders. Technical professionals benefit from enhanced understanding and\nimproved problem-solving skills, while business stakeholders gain insights into\nproject alignments and transparency. Despite the potential, generating such\nexplanations is often time-consuming and challenging. This paper presents an\ninnovative approach that leverages the advanced capabilities of large language\nmodels (LLMs) to generate faithful and personalized code explanations. Our\nmethodology integrates prompt enhancement, self-correction mechanisms,\npersonalized content customization, and interaction with external tools,\nfacilitated by collaboration among multiple LLM agents. We evaluate our\napproach using both automatic and human assessments, demonstrating that our\nmethod not only produces accurate explanations but also tailors them to\nindividual user preferences. Our findings suggest that this approach\nsignificantly improves the quality and relevance of code explanations, offering\na valuable tool for developers and stakeholders alike.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.14731v1",
    "published_date": "2024-12-08 09:02:04 UTC",
    "updated_date": "2024-12-08 09:02:04 UTC"
  },
  {
    "arxiv_id": "2412.05852v1",
    "title": "Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming",
    "authors": [
      "Dinesh Parthasarathy",
      "Wayne Bradford Mitchell",
      "Harald Köstler"
    ],
    "abstract": "Multigrid methods despite being known to be asymptotically optimal\nalgorithms, depend on the careful selection of their individual components for\nefficiency. Also, they are mostly restricted to standard cycle types like V-,\nF-, and W-cycles. We use grammar rules to generate arbitrary-shaped cycles,\nwherein the smoothers and their relaxation weights are chosen independently at\neach step within the cycle. We call this a flexible multigrid cycle. These\nflexible cycles are used in Algebraic Multigrid (AMG) methods with the help of\ngrammar rules and optimized using genetic programming. The flexible AMG methods\nare implemented in the software library of hypre, and the programs are\noptimized separately for two cases: a standalone AMG solver for a 3D\nanisotropic problem and an AMG preconditioner with conjugate gradient for a\nmultiphysics code. We observe that the optimized flexible cycles provide higher\nefficiency and better performance than the standard cycle types.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05852v1",
    "published_date": "2024-12-08 08:21:35 UTC",
    "updated_date": "2024-12-08 08:21:35 UTC"
  },
  {
    "arxiv_id": "2412.05846v2",
    "title": "Kernel Stochastic Configuration Networks for Nonlinear Regression",
    "authors": [
      "Yongxuan Chen",
      "Dianhui Wang"
    ],
    "abstract": "Stochastic configuration networks (SCNs), as a class of randomized learner\nmodels, are featured by its way of random parameters assignment in the light of\na supervisory mechanism, resulting in the universal approximation property at\nalgorithmic level. This paper presents a kernel version of SCNs, termed KSCNs,\naiming to enhance model's representation learning capability and performance\nstability. The random bases of a built SCN model can be used to span a\nreproducing kernel Hilbert space (RKHS), followed by our proposed algorithm for\nconstructing KSCNs. It is shown that the data distribution in the\nreconstructive space is favorable for regression solving and the proposed KSCN\nlearner models hold the universal approximation property. Three benchmark\ndatasets including two industrial datasets are used in this study for\nperformance evaluation. Experimental results with comparisons against existing\nsolutions clearly demonstrate that the proposed KSCN remarkably outperforms the\noriginal SCNs and some typical kernel methods for resolving nonlinear\nregression problems in terms of the learning performance, the model's stability\nand robustness with respect to the kernel parameter settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05846v2",
    "published_date": "2024-12-08 07:54:04 UTC",
    "updated_date": "2024-12-14 13:32:58 UTC"
  },
  {
    "arxiv_id": "2412.05842v1",
    "title": "DREAM: Domain-agnostic Reverse Engineering Attributes of Black-box Model",
    "authors": [
      "Rongqing Li",
      "Jiaqi Yu",
      "Changsheng Li",
      "Wenhan Luo",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "abstract": "Deep learning models are usually black boxes when deployed on machine\nlearning platforms. Prior works have shown that the attributes (e.g., the\nnumber of convolutional layers) of a target black-box model can be exposed\nthrough a sequence of queries. There is a crucial limitation: these works\nassume the training dataset of the target model is known beforehand and\nleverage this dataset for model attribute attack. However, it is difficult to\naccess the training dataset of the target black-box model in reality.\nTherefore, whether the attributes of a target black-box model could be still\nrevealed in this case is doubtful. In this paper, we investigate a new problem\nof black-box reverse engineering, without requiring the availability of the\ntarget model's training dataset. We put forward a general and principled\nframework DREAM, by casting this problem as out-of-distribution (OOD)\ngeneralization. In this way, we can learn a domain-agnostic meta-model to infer\nthe attributes of the target black-box model with unknown training data. This\nmakes our method one of the kinds that can gracefully apply to an arbitrary\ndomain for model attribute reverse engineering with strong generalization\nability. Extensive experimental results demonstrate the superiority of our\nproposed method over the baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2307.10997",
    "pdf_url": "http://arxiv.org/pdf/2412.05842v1",
    "published_date": "2024-12-08 07:37:05 UTC",
    "updated_date": "2024-12-08 07:37:05 UTC"
  },
  {
    "arxiv_id": "2412.05838v1",
    "title": "A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data",
    "authors": [
      "Aniruddha Salve",
      "Saba Attar",
      "Mahesh Deshmukh",
      "Sayali Shivpuje",
      "Arnab Mitra Utsab"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by\nincorporating external, domain-specific data into the generative process. While\nLLMs are highly capable, they often rely on static, pre-trained datasets,\nlimiting their ability to integrate dynamic or private data. Traditional RAG\nsystems typically use a single-agent architecture to handle query generation,\ndata retrieval, and response synthesis. However, this approach becomes\ninefficient when dealing with diverse data sources, such as relational\ndatabases, document stores, and graph databases, often leading to performance\nbottlenecks and reduced accuracy. This paper proposes a multi-agent RAG system\nto address these limitations. Specialized agents, each optimized for a specific\ndata source, handle query generation for relational, NoSQL, and document-based\nsystems. These agents collaborate within a modular framework, with query\nexecution delegated to an environment designed for compatibility across various\ndatabase types. This distributed approach enhances query efficiency, reduces\ntoken overhead, and improves response accuracy by ensuring that each agent\nfocuses on its specialized task. The proposed system is scalable and adaptable,\nmaking it ideal for generative AI workflows that require integration with\ndiverse, dynamic, or private data sources. By leveraging specialized agents and\na modular execution environment, the system provides an efficient and robust\nsolution for handling complex, heterogeneous data environments in generative AI\napplications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 3 figures. This preprint introduces a multi-agent framework\n  for Retrieval-Augmented Generation (RAG), enhancing Large Language Models\n  (LLMs) for efficient integration of diverse data sources. Relevant for\n  researchers in AI, ML, generative AI, and database systems",
    "pdf_url": "http://arxiv.org/pdf/2412.05838v1",
    "published_date": "2024-12-08 07:18:19 UTC",
    "updated_date": "2024-12-08 07:18:19 UTC"
  },
  {
    "arxiv_id": "2412.05830v1",
    "title": "Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks",
    "authors": [
      "Faqian Guan",
      "Tianqing Zhu",
      "Wenhan Chang",
      "Wei Ren",
      "Wanlei Zhou"
    ],
    "abstract": "Graph Neural Networks (GNNs), specifically designed to process the graph\ndata, have achieved remarkable success in various applications. Link stealing\nattacks on graph data pose a significant privacy threat, as attackers aim to\nextract sensitive relationships between nodes (entities), potentially leading\nto academic misconduct, fraudulent transactions, or other malicious activities.\nPrevious studies have primarily focused on single datasets and did not explore\ncross-dataset attacks, let alone attacks that leverage the combined knowledge\nof multiple attackers. However, we find that an attacker can combine the data\nknowledge of multiple attackers to create a more effective attack model, which\ncan be referred to cross-dataset attacks. Moreover, if knowledge can be\nextracted with the help of Large Language Models (LLMs), the attack capability\nwill be more significant. In this paper, we propose a novel link stealing\nattack method that takes advantage of cross-dataset and Large Language Models\n(LLMs). The LLM is applied to process datasets with different data structures\nin cross-dataset attacks. Each attacker fine-tunes the LLM on their specific\ndataset to generate a tailored attack model. We then introduce a novel model\nmerging method to integrate the parameters of these attacker-specific models\neffectively. The result is a merged attack model with superior generalization\ncapabilities, enabling effective attacks not only on the attackers' datasets\nbut also on previously unseen (out-of-domain) datasets. We conducted extensive\nexperiments in four datasets to demonstrate the effectiveness of our method.\nAdditional experiments with three different GNN and LLM architectures further\nillustrate the generality of our approach.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Link Stealing Attacks, Large Language Models, Graph Neural Networks,\n  Privacy Attacks, Model Merging",
    "pdf_url": "http://arxiv.org/pdf/2412.05830v1",
    "published_date": "2024-12-08 06:37:05 UTC",
    "updated_date": "2024-12-08 06:37:05 UTC"
  },
  {
    "arxiv_id": "2412.05823v1",
    "title": "DapperFL: Domain Adaptive Federated Learning with Model Fusion Pruning for Edge Devices",
    "authors": [
      "Yongzhe Jia",
      "Xuyun Zhang",
      "Hongsheng Hu",
      "Kim-Kwang Raymond Choo",
      "Lianyong Qi",
      "Xiaolong Xu",
      "Amin Beheshti",
      "Wanchun Dou"
    ],
    "abstract": "Federated learning (FL) has emerged as a prominent machine learning paradigm\nin edge computing environments, enabling edge devices to collaboratively\noptimize a global model without sharing their private data. However, existing\nFL frameworks suffer from efficacy deterioration due to the system\nheterogeneity inherent in edge computing, especially in the presence of domain\nshifts across local data. In this paper, we propose a heterogeneous FL\nframework DapperFL, to enhance model performance across multiple domains. In\nDapperFL, we introduce a dedicated Model Fusion Pruning (MFP) module to produce\npersonalized compact local models for clients to address the system\nheterogeneity challenges. The MFP module prunes local models with fused\nknowledge obtained from both local and remaining domains, ensuring robustness\nto domain shifts. Additionally, we design a Domain Adaptive Regularization\n(DAR) module to further improve the overall performance of DapperFL. The DAR\nmodule employs regularization generated by the pruned model, aiming to learn\nrobust representations across domains. Furthermore, we introduce a specific\naggregation algorithm for aggregating heterogeneous local models with tailored\narchitectures and weights. We implement DapperFL on a realworld FL platform\nwith heterogeneous clients. Experimental results on benchmark datasets with\nmultiple domains demonstrate that DapperFL outperforms several state-of-the-art\nFL frameworks by up to 2.28%, while significantly achieving model volume\nreductions ranging from 20% to 80%. Our code is available at:\nhttps://github.com/jyzgh/DapperFL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Oral accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.05823v1",
    "published_date": "2024-12-08 05:50:04 UTC",
    "updated_date": "2024-12-08 05:50:04 UTC"
  },
  {
    "arxiv_id": "2412.06849v1",
    "title": "GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model",
    "authors": [
      "Haotong Yang",
      "Xiyuan Wang",
      "Qian Tao",
      "Shuxian Hu",
      "Zhouchen Lin",
      "Muhan Zhang"
    ],
    "abstract": "Recent research on integrating Large Language Models (LLMs) with Graph Neural\nNetworks (GNNs) typically follows two approaches: LLM-centered models, which\nconvert graph data into tokens for LLM processing, and GNN-centered models,\nwhich use LLMs to encode text features into node and edge representations for\nGNN input. LLM-centered models often struggle to capture graph structures\neffectively, while GNN-centered models compress variable-length textual data\ninto fixed-size vectors, limiting their ability to understand complex\nsemantics. Additionally, GNN-centered approaches require converting tasks into\na uniform, manually-designed format, restricting them to classification tasks\nand preventing language output. To address these limitations, we introduce a\nnew architecture that deeply integrates GNN with LLM, featuring three key\ninnovations: (1) Structure-Aware Transformers, which incorporate GNN's\nmessage-passing capabilities directly into LLM's transformer layers, allowing\nsimultaneous processing of textual and structural information and generating\noutputs from both GNN and LLM; (2) Graph-Text Cross-Attention, which processes\nfull, uncompressed text from graph nodes and edges, ensuring complete semantic\nintegration; and (3) GNN-LLM Twin Predictor, enabling LLM's flexible\nautoregressive generation alongside GNN's scalable one-pass prediction.\nGL-Fusion achieves outstand performance on various tasks. Notably, it achieves\nstate-of-the-art performance on OGBN-Arxiv and OGBG-Code2.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2412.06849v1",
    "published_date": "2024-12-08 05:49:58 UTC",
    "updated_date": "2024-12-08 05:49:58 UTC"
  },
  {
    "arxiv_id": "2412.05821v2",
    "title": "An Entailment Tree Generation Approach for Multimodal Multi-Hop Question Answering with Mixture-of-Experts and Iterative Feedback Mechanism",
    "authors": [
      "Qing Zhang",
      "Haocheng Lv",
      "Jie Liu",
      "Zhiyun Chen",
      "Jianyong Duan",
      "Hao Wang",
      "Li He",
      "Mingying Xv"
    ],
    "abstract": "With the rise of large-scale language models (LLMs), it is currently popular\nand effective to convert multimodal information into text descriptions for\nmultimodal multi-hop question answering. However, we argue that the current\nmethods of multi-modal multi-hop question answering still mainly face two\nchallenges: 1) The retrieved evidence containing a large amount of redundant\ninformation, inevitably leads to a significant drop in performance due to\nirrelevant information misleading the prediction. 2) The reasoning process\nwithout interpretable reasoning steps makes the model difficult to discover the\nlogical errors for handling complex questions. To solve these problems, we\npropose a unified LLMs-based approach but without heavily relying on them due\nto the LLM's potential errors, and innovatively treat multimodal multi-hop\nquestion answering as a joint entailment tree generation and question answering\nproblem. Specifically, we design a multi-task learning framework with a focus\non facilitating common knowledge sharing across interpretability and prediction\ntasks while preventing task-specific errors from interfering with each other\nvia mixture of experts. Afterward, we design an iterative feedback mechanism to\nfurther enhance both tasks by feeding back the results of the joint training to\nthe LLM for regenerating entailment trees, aiming to iteratively refine the\npotential answer. Notably, our method has won the first place in the official\nleaderboard of WebQA (since April 10, 2024), and achieves competitive results\non MultimodalQA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Erratum: We identified an error in the calculation of the F1 score in\n  table 4 reported in a previous version of this work. The performance of the\n  new result is better than the previous one. The corrected values are included\n  in this updated version of the paper. These changes do not alter the primary\n  conclusions of our research",
    "pdf_url": "http://arxiv.org/pdf/2412.05821v2",
    "published_date": "2024-12-08 05:47:55 UTC",
    "updated_date": "2024-12-10 17:42:49 UTC"
  },
  {
    "arxiv_id": "2412.05818v2",
    "title": "SILMM: Self-Improving Large Multimodal Models for Compositional Text-to-Image Generation",
    "authors": [
      "Leigang Qu",
      "Haochuan Li",
      "Wenjie Wang",
      "Xiang Liu",
      "Juncheng Li",
      "Liqiang Nie",
      "Tat-Seng Chua"
    ],
    "abstract": "Large Multimodal Models (LMMs) have demonstrated impressive capabilities in\nmultimodal understanding and generation, pushing forward advancements in\ntext-to-image generation. However, achieving accurate text-image alignment for\nLMMs, particularly in compositional scenarios, remains challenging. Existing\napproaches, such as layout planning for multi-step generation and learning from\nhuman feedback or AI feedback, depend heavily on prompt engineering, costly\nhuman annotations, and continual upgrading, limiting flexibility and\nscalability. In this work, we introduce a model-agnostic iterative\nself-improvement framework (SILMM) that can enable LMMs to provide helpful and\nscalable self-feedback and optimize text-image alignment via Direct Preference\nOptimization (DPO). DPO can readily applied to LMMs that use discrete visual\ntokens as intermediate image representations; while it is less suitable for\nLMMs with continuous visual features, as obtaining generation probabilities is\nchallenging. To adapt SILMM to LMMs with continuous features, we propose a\ndiversity mechanism to obtain diverse representations and a kernel-based\ncontinuous DPO for alignment. Extensive experiments on three compositional\ntext-to-image generation benchmarks validate the effectiveness and superiority\nof SILMM, showing improvements exceeding 30% on T2I-CompBench++ and around 20%\non DPG-Bench.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 Camera-ready. Project page: https://silmm.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.05818v2",
    "published_date": "2024-12-08 05:28:08 UTC",
    "updated_date": "2025-03-24 23:22:02 UTC"
  },
  {
    "arxiv_id": "2412.07801v1",
    "title": "Learning to Correction: Explainable Feedback Generation for Visual Commonsense Reasoning Distractor",
    "authors": [
      "Jiali Chen",
      "Xusen Hei",
      "Yuqi Xue",
      "Yuancheng Wei",
      "Jiayuan Xie",
      "Yi Cai",
      "Qing Li"
    ],
    "abstract": "Large multimodal models (LMMs) have shown remarkable performance in the\nvisual commonsense reasoning (VCR) task, which aims to answer a multiple-choice\nquestion based on visual commonsense within an image. However, the ability of\nLMMs to correct potential visual commonsense errors in the distractor upon\ntheir occurrence is yet under-explored. Drawing inspiration from how a human\nteacher crafts challenging distractors to test students' comprehension of the\nconcepts or skills and assists them in identifying and correcting errors toward\nthe answer, we are the pioneering research for LMMs to simulate this error\ncorrection process. To this end, we employ GPT-4 as a ``teacher'' to collect\nthe explainable feedback dataset VCR-DF for error correction, which serves as a\nbenchmark to evaluate the ability of LMMs to identify misconceptions and\nclarify reasons behind the error in VCR distractors toward final answers. In\naddition, we propose an LMM-based Pedagogical Expert Instructed Feedback\nGeneration (PEIFG) model to incorporate the learnable expert prompts and\nmultimodal instruction as guidance for feedback generation. Experimental\nresults show that our PEIFG significantly outperforms existing LMMs. We believe\nthat our benchmark provides a new direction for evaluating the capabilities of\nLMMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.07801v1",
    "published_date": "2024-12-08 03:59:59 UTC",
    "updated_date": "2024-12-08 03:59:59 UTC"
  },
  {
    "arxiv_id": "2412.06847v2",
    "title": "M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery",
    "authors": [
      "Siyuan Guo",
      "Lexuan Wang",
      "Chang Jin",
      "Jinxian Wang",
      "Han Peng",
      "Huayang Shi",
      "Wengen Li",
      "Jihong Guan",
      "Shuigeng Zhou"
    ],
    "abstract": "This paper introduces M$^{3}$-20M, a large-scale Multi-Modal Molecule dataset\nthat contains over 20 million molecules, with the data mainly being integrated\nfrom existing databases and partially generated by large language models.\nDesigned to support AI-driven drug design and discovery, M$^{3}$-20M is 71\ntimes more in the number of molecules than the largest existing dataset,\nproviding an unprecedented scale that can highly benefit the training or\nfine-tuning of models, including large language models for drug design and\ndiscovery tasks. This dataset integrates one-dimensional SMILES,\ntwo-dimensional molecular graphs, three-dimensional molecular structures,\nphysicochemical properties, and textual descriptions collected through web\ncrawling and generated using GPT-3.5, offering a comprehensive view of each\nmolecule. To demonstrate the power of M$^{3}$-20M in drug design and discovery,\nwe conduct extensive experiments on two key tasks: molecule generation and\nmolecular property prediction, using large language models including GLM4,\nGPT-3.5, GPT-4, and Llama3-8b. Our experimental results show that M$^{3}$-20M\ncan significantly boost model performance in both tasks. Specifically, it\nenables the models to generate more diverse and valid molecular structures and\nachieve higher property prediction accuracy than existing single-modal\ndatasets, which validates the value and potential of M$^{3}$-20M in supporting\nAI-driven drug design and discovery. The dataset is available at\nhttps://github.com/bz99bz/M-3.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06847v2",
    "published_date": "2024-12-08 03:43:07 UTC",
    "updated_date": "2025-03-16 12:37:49 UTC"
  },
  {
    "arxiv_id": "2412.05797v1",
    "title": "Speech Is Not Enough: Interpreting Nonverbal Indicators of Common Knowledge and Engagement",
    "authors": [
      "Derek Palmer",
      "Yifan Zhu",
      "Kenneth Lai",
      "Hannah VanderHoeven",
      "Mariah Bradford",
      "Ibrahim Khebour",
      "Carlos Mabrey",
      "Jack Fitzgerald",
      "Nikhil Krishnaswamy",
      "Martha Palmer",
      "James Pustejovsky"
    ],
    "abstract": "Our goal is to develop an AI Partner that can provide support for group\nproblem solving and social dynamics. In multi-party working group environments,\nmultimodal analytics is crucial for identifying non-verbal interactions of\ngroup members. In conjunction with their verbal participation, this creates an\nholistic understanding of collaboration and engagement that provides necessary\ncontext for the AI Partner. In this demo, we illustrate our present\ncapabilities at detecting and tracking nonverbal behavior in student\ntask-oriented interactions in the classroom, and the implications for tracking\ncommon ground and engagement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "3 pages, 2 figures, appearing at AAAI 2025 Demos Track",
    "pdf_url": "http://arxiv.org/pdf/2412.05797v1",
    "published_date": "2024-12-08 03:26:44 UTC",
    "updated_date": "2024-12-08 03:26:44 UTC"
  },
  {
    "arxiv_id": "2412.05796v2",
    "title": "Language-Guided Image Tokenization for Generation",
    "authors": [
      "Kaiwen Zha",
      "Lijun Yu",
      "Alireza Fathi",
      "David A. Ross",
      "Cordelia Schmid",
      "Dina Katabi",
      "Xiuye Gu"
    ],
    "abstract": "Image tokenization, the process of transforming raw image pixels into a\ncompact low-dimensional latent representation, has proven crucial for scalable\nand efficient image generation. However, mainstream image tokenization methods\ngenerally have limited compression rates, making high-resolution image\ngeneration computationally expensive. To address this challenge, we propose to\nleverage language for efficient image tokenization, and we call our method\nText-Conditioned Image Tokenization (TexTok). TexTok is a simple yet effective\ntokenization framework that leverages language to provide a compact, high-level\nsemantic representation. By conditioning the tokenization process on\ndescriptive text captions, TexTok simplifies semantic learning, allowing more\nlearning capacity and token space to be allocated to capture fine-grained\nvisual details, leading to enhanced reconstruction quality and higher\ncompression rates. Compared to the conventional tokenizer without text\nconditioning, TexTok achieves average reconstruction FID improvements of 29.2%\nand 48.1% on ImageNet-256 and -512 benchmarks respectively, across varying\nnumbers of tokens. These tokenization improvements consistently translate to\n16.3% and 34.3% average improvements in generation FID. By simply replacing the\ntokenizer in Diffusion Transformer (DiT) with TexTok, our system can achieve a\n93.5x inference speedup while still outperforming the original DiT using only\n32 tokens on ImageNet-512. TexTok with a vanilla DiT generator achieves\nstate-of-the-art FID scores of 1.46 and 1.62 on ImageNet-256 and -512\nrespectively. Furthermore, we demonstrate TexTok's superiority on the\ntext-to-image generation task, effectively utilizing the off-the-shelf text\ncaptions in tokenization. Project page is at:\nhttps://kaiwenzha.github.io/textok/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 Oral. Project page: https://kaiwenzha.github.io/textok/",
    "pdf_url": "http://arxiv.org/pdf/2412.05796v2",
    "published_date": "2024-12-08 03:18:17 UTC",
    "updated_date": "2025-04-05 18:15:41 UTC"
  },
  {
    "arxiv_id": "2412.10411v1",
    "title": "Pre-trained protein language model for codon optimization",
    "authors": [
      "Shashank Pathak",
      "Guohui Lin"
    ],
    "abstract": "Motivation: Codon optimization of Open Reading Frame (ORF) sequences is\nessential for enhancing mRNA stability and expression in applications like mRNA\nvaccines, where codon choice can significantly impact protein yield which\ndirectly impacts immune strength. In this work, we investigate the use of a\npre-trained protein language model (PPLM) for getting a rich representation of\namino acids which could be utilized for codon optimization. This leaves us with\na simpler fine-tuning task over PPLM in optimizing ORF sequences.\n  Results: The ORFs generated by our proposed models outperformed their natural\ncounterparts encoding the same proteins on computational metrics for stability\nand expression. They also demonstrated enhanced performance against the\nbenchmark ORFs used in mRNA vaccines for the SARS-CoV-2 viral spike protein and\nthe varicella-zoster virus (VZV). These results highlight the potential of\nadapting PPLM for designing ORFs tailored to encode target antigens in mRNA\nvaccines.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10411v1",
    "published_date": "2024-12-08 03:01:38 UTC",
    "updated_date": "2024-12-08 03:01:38 UTC"
  },
  {
    "arxiv_id": "2412.05781v3",
    "title": "Open-Source Acceleration of Stable-Diffusion.cpp Deployable on All Devices",
    "authors": [
      "Jingxu Ng",
      "Cheng Lv",
      "Pu Zhao",
      "Wei Niu",
      "Juyi Lin",
      "Minzhou Pan",
      "Yun Liang",
      "Yanzhi Wang"
    ],
    "abstract": "Stable diffusion plays a crucial role in generating high-quality images.\nHowever, image generation is time-consuming and memory-intensive. To address\nthis, stable-diffusion.cpp (Sdcpp) emerges as an efficient inference framework\nto accelerate the diffusion models. Although it is lightweight, the current\nimplementation of ggml_conv_2d operator in Sdcpp is suboptimal, exhibiting both\nhigh inference latency and massive memory usage. To address this, in this work,\nwe present an optimized version of Sdcpp leveraging the Winograd algorithm to\naccelerate 2D convolution operations, which is the primary bottleneck in the\npipeline. By analyzing both dependent and independent computation graphs, we\nexploit the device's locality and parallelism to achieve substantial\nperformance improvements. Our framework delivers correct end-to-end results\nacross various stable diffusion models, including SDv1.4, v1.5, v2.1, SDXL, and\nSDXL-Turbo. Our evaluation results demonstrate a speedup up to 2.76x for\nindividual convolutional layers and an inference speedup up to 4.79x for the\noverall image generation process, compared with the original Sdcpp on M1 pro.\nHomepage: https://github.com/SealAILab/stable-diffusion-cpp",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05781v3",
    "published_date": "2024-12-08 02:27:17 UTC",
    "updated_date": "2025-01-07 20:27:09 UTC"
  },
  {
    "arxiv_id": "2412.05780v3",
    "title": "BudgetFusion: Perceptually-Guided Adaptive Diffusion Models",
    "authors": [
      "Qinchan Li",
      "Kenneth Chen",
      "Changyue Su",
      "Qi Sun"
    ],
    "abstract": "Diffusion models have shown unprecedented success in the task of\ntext-to-image generation. While these models are capable of generating\nhigh-quality and realistic images, the complexity of sequential denoising has\nraised societal concerns regarding high computational demands and energy\nconsumption. In response, various efforts have been made to improve inference\nefficiency. However, most of the existing efforts have taken a fixed approach\nwith neural network simplification or text prompt optimization. Are the quality\nimprovements from all denoising computations equally perceivable to humans? We\nobserved that images from different text prompts may require different\ncomputational efforts given the desired content. The observation motivates us\nto present BudgetFusion, a novel model that suggests the most perceptually\nefficient number of diffusion steps before a diffusion model starts to generate\nan image. This is achieved by predicting multi-level perceptual metrics\nrelative to diffusion steps. With the popular Stable Diffusion as an example,\nwe conduct both numerical analyses and user studies. Our experiments show that\nBudgetFusion saves up to five seconds per prompt without compromising\nperceptual similarity. We hope this work can initiate efforts toward answering\na core question: how much do humans perceptually gain from images created by a\ngenerative model, per watt of energy?",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05780v3",
    "published_date": "2024-12-08 02:23:40 UTC",
    "updated_date": "2024-12-23 11:42:18 UTC"
  },
  {
    "arxiv_id": "2412.05777v1",
    "title": "Strategizing Equitable Transit Evacuations: A Data-Driven Reinforcement Learning Approach",
    "authors": [
      "Fang Tang",
      "Han Wang",
      "Maria Laura Delle Monache"
    ],
    "abstract": "As natural disasters become increasingly frequent, the need for efficient and\nequitable evacuation planning has become more critical. This paper proposes a\ndata-driven, reinforcement learning-based framework to optimize bus-based\nevacuations with an emphasis on improving both efficiency and equity. We model\nthe evacuation problem as a Markov Decision Process solved by reinforcement\nlearning, using real-time transit data from General Transit Feed Specification\nand transportation networks extracted from OpenStreetMap. The reinforcement\nlearning agent dynamically reroutes buses from their scheduled location to\nminimize total passengers' evacuation time while prioritizing equity-priority\ncommunities. Simulations on the San Francisco Bay Area transportation network\nindicate that the proposed framework achieves significant improvements in both\nevacuation efficiency and equitable service distribution compared to\ntraditional rule-based and random strategies. These results highlight the\npotential of reinforcement learning to enhance system performance and urban\nresilience during emergency evacuations, offering a scalable solution for\nreal-world applications in intelligent transportation systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.SY",
      "eess.SY",
      "68T05, 90B06",
      "I.2.6; I.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05777v1",
    "published_date": "2024-12-08 02:17:38 UTC",
    "updated_date": "2024-12-08 02:17:38 UTC"
  },
  {
    "arxiv_id": "2412.06846v1",
    "title": "Classifier-free guidance in LLMs Safety",
    "authors": [
      "Roman Smirnov"
    ],
    "abstract": "The paper describes LLM unlearning without a retaining dataset, using the\nORPO reinforcement learning method with inference enhanced by modified\nclassifier-free guidance. Significant improvement in unlearning, without\ndegradation of the model, is achieved through direct training on synthetic\nreplacement data in CFG-aware training regime, with classifier-free guidance\napplied during the inference. This article is an extended version of the\nNeurIPS 2024 LLM-PC submission, which was awarded second prize.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06846v1",
    "published_date": "2024-12-08 02:11:33 UTC",
    "updated_date": "2024-12-08 02:11:33 UTC"
  },
  {
    "arxiv_id": "2412.06845v4",
    "title": "7B Fully Open Source Moxin-LLM -- From Pretraining to GRPO-based Reinforcement Learning Enhancement",
    "authors": [
      "Pu Zhao",
      "Xuan Shen",
      "Zhenglun Kong",
      "Yixin Shen",
      "Sung-En Chang",
      "Timothy Rupprecht",
      "Lei Lu",
      "Enfu Nan",
      "Changdi Yang",
      "Yumei He",
      "Weiyan Shi",
      "Xingchen Xu",
      "Yu Huang",
      "Wei Jiang",
      "Wei Wang",
      "Yue Chen",
      "Yong He",
      "Yanzhi Wang"
    ],
    "abstract": "Recently, Large Language Models (LLMs) have undergone a significant\ntransformation, marked by a rapid rise in both their popularity and\ncapabilities. Leading this evolution are proprietary LLMs like GPT-4 and\nGPT-o1, which have captured widespread attention in the AI community due to\ntheir remarkable performance and versatility. Simultaneously, open-source LLMs,\nsuch as LLaMA, have made great contributions to the ever-increasing popularity\nof LLMs due to the ease to customize and deploy the models across diverse\napplications. Although open-source LLMs present unprecedented opportunities for\ninnovation and research, the commercialization of LLMs has raised concerns\nabout transparency, reproducibility, and safety. Many open-source LLMs fail to\nmeet fundamental transparency requirements by withholding essential components\nlike training code and data, which may hinder further innovations on LLMs. To\nmitigate this issue, we introduce Moxin 7B, a fully open-source LLM developed,\nadhering to principles of open science, open source, open data, and open\naccess. We release the pre-training code and configurations, training and\nfine-tuning datasets, and intermediate and final checkpoints, aiming to make\ncontinuous commitments to fully open-source LLMs. After pre-training and\nobtaining the base model, we finetune the Moxin Base model with SOTA\npost-training framework and instruction data to obtain Moxin Instruct model. To\nimprove the reasoning capability, we further finetune our Instruct model with\nchain-of-thought data distilled from DeepSeek R1, and then use Group Relative\nPolicy Optimization (GRPO), an efficient and effective reinforcement learning\nalgorithm following DeepSeek R1, to finetune our model, leading to the Moxin\nReasoning model. Experiments show that our models achieve superior performance\nin various evaluations such as zero-shot evaluation, few-shot evaluation, and\nCoT evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06845v4",
    "published_date": "2024-12-08 02:01:46 UTC",
    "updated_date": "2025-04-23 01:38:02 UTC"
  },
  {
    "arxiv_id": "2412.05768v1",
    "title": "Uncovering Uncertainty in Transformer Inference",
    "authors": [
      "Greyson Brothers",
      "Willa Mannering",
      "Amber Tien",
      "John Winder"
    ],
    "abstract": "We explore the Iterative Inference Hypothesis (IIH) within the context of\ntransformer-based language models, aiming to understand how a model's latent\nrepresentations are progressively refined and whether observable differences\nare present between correct and incorrect generations. Our findings provide\nempirical support for the IIH, showing that the nth token embedding in the\nresidual stream follows a trajectory of decreasing loss. Additionally, we\nobserve that the rate at which residual embeddings converge to a stable output\nrepresentation reflects uncertainty in the token generation process. Finally,\nwe introduce a method utilizing cross-entropy to detect this uncertainty and\ndemonstrate its potential to distinguish between correct and incorrect token\ngenerations on a dataset of idioms.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50 (Primary), 68T07 (Secondary)",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted poster at the 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024) Workshop on Foundation Model Interventions",
    "pdf_url": "http://arxiv.org/pdf/2412.05768v1",
    "published_date": "2024-12-08 00:46:10 UTC",
    "updated_date": "2024-12-08 00:46:10 UTC"
  },
  {
    "arxiv_id": "2412.05766v1",
    "title": "Policy-shaped prediction: avoiding distractions in model-based reinforcement learning",
    "authors": [
      "Miles Hutson",
      "Isaac Kauvar",
      "Nick Haber"
    ],
    "abstract": "Model-based reinforcement learning (MBRL) is a promising route to\nsample-efficient policy optimization. However, a known vulnerability of\nreconstruction-based MBRL consists of scenarios in which detailed aspects of\nthe world are highly predictable, but irrelevant to learning a good policy.\nSuch scenarios can lead the model to exhaust its capacity on meaningless\ncontent, at the cost of neglecting important environment dynamics. While\nexisting approaches attempt to solve this problem, we highlight its continuing\nimpact on leading MBRL methods -- including DreamerV3 and DreamerPro -- with a\nnovel environment where background distractions are intricate, predictable, and\nuseless for planning future actions. To address this challenge we develop a\nmethod for focusing the capacity of the world model through synergy of a\npretrained segmentation model, a task-aware reconstruction loss, and\nadversarial learning. Our method outperforms a variety of other approaches\ndesigned to reduce the impact of distractors, and is an advance towards robust\nmodel-based reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.05766v1",
    "published_date": "2024-12-08 00:21:37 UTC",
    "updated_date": "2024-12-08 00:21:37 UTC"
  }
]