[
  {
    "arxiv_id": "2511.12838v1",
    "title": "Connectivity-Guided Sparsification of 2-FWL GNNs: Preserving Full Expressivity with Improved Efficiency",
    "authors": [
      "Rongqin Chen",
      "Fan Mo",
      "Pak Lon Ip",
      "Shenghui Zhang",
      "Dan Wu",
      "Ye Li",
      "Leong Hou U"
    ],
    "abstract": "Higher-order Graph Neural Networks (HOGNNs) based on the 2-FWL test achieve superior expressivity by modeling 2- and 3-node interactions, but at $\\mathcal{O}(n^3)$ computational cost. However, this computational burden is typically mitigated by existing efficiency methods at the cost of reduced expressivity. We propose \\textbf{Co-Sparsify}, a connectivity-aware sparsification framework that eliminates \\emph{provably redundant} computations while preserving full 2-FWL expressive power. Our key insight is that 3-node interactions are expressively necessary only within \\emph{biconnected components} -- maximal subgraphs where every pair of nodes lies on a cycle. Outside these components, structural relationships can be fully captured via 2-node message passing or global readout, rendering higher-order modeling unnecessary. Co-Sparsify restricts 2-node message passing to connected components and 3-node interactions to biconnected ones, removing computation without approximation or sampling. We prove that Co-Sparsified GNNs are as expressive as the 2-FWL test. Empirically, on PPGN, Co-Sparsify matches or exceeds accuracy on synthetic substructure counting tasks and achieves state-of-the-art performance on real-world benchmarks (ZINC, QM9). This study demonstrates that high expressivity and scalability are not mutually exclusive: principled, topology-guided sparsification enables powerful, efficient GNNs with theoretical guarantees.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.12838v1",
    "published_date": "2025-11-16 23:46:54 UTC",
    "updated_date": "2025-11-16 23:46:54 UTC"
  },
  {
    "arxiv_id": "2511.12834v1",
    "title": "SAGA: Source Attribution of Generative AI Videos",
    "authors": [
      "Rohit Kundu",
      "Vishal Mohanty",
      "Hao Xiong",
      "Shan Jia",
      "Athula Balachandran",
      "Amit K. Roy-Chowdhury"
    ],
    "abstract": "The proliferation of generative AI has led to hyper-realistic synthetic videos, escalating misuse risks and outstripping binary real/fake detectors. We introduce SAGA (Source Attribution of Generative AI videos), the first comprehensive framework to address the urgent need for AI-generated video source attribution at a large scale. Unlike traditional detection, SAGA identifies the specific generative model used. It uniquely provides multi-granular attribution across five levels: authenticity, generation task (e.g., T2V/I2V), model version, development team, and the precise generator, offering far richer forensic insights. Our novel video transformer architecture, leveraging features from a robust vision foundation model, effectively captures spatio-temporal artifacts. Critically, we introduce a data-efficient pretrain-and-attribute strategy, enabling SAGA to achieve state-of-the-art attribution using only 0.5\\% of source-labeled data per class, matching fully supervised performance. Furthermore, we propose Temporal Attention Signatures (T-Sigs), a novel interpretability method that visualizes learned temporal differences, offering the first explanation for why different video generators are distinguishable. Extensive experiments on public datasets, including cross-domain scenarios, demonstrate that SAGA sets a new benchmark for synthetic video provenance, providing crucial, interpretable insights for forensic and regulatory applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12834v1",
    "published_date": "2025-11-16 23:39:54 UTC",
    "updated_date": "2025-11-16 23:39:54 UTC"
  },
  {
    "arxiv_id": "2511.12832v1",
    "title": "From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation",
    "authors": [
      "Niranjan Chebrolu",
      "Gerard Christopher Yeo",
      "Kokil Jaidka"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate increasing conversational fluency, yet instilling them with nuanced, human-like emotional expression remains a significant challenge. Current alignment techniques often address surface-level output or require extensive fine-tuning. This paper demonstrates that targeted activation engineering can steer LLaMA 3.1-8B to exhibit more human-like emotional nuances. We first employ attribution patching to identify causally influential components, to find a key intervention locus by observing activation patterns during diagnostic conversational tasks. We then derive emotional expression vectors from the difference in the activations generated by contrastive text pairs (positive vs. negative examples of target emotions). Applying these vectors to new conversational prompts significantly enhances emotional characteristics: steered responses show increased positive sentiment (e.g., joy, trust) and more frequent first-person pronoun usage, indicative of greater personal engagement. Our findings offer a precise and interpretable framework and new directions for the study of conversational AI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12832v1",
    "published_date": "2025-11-16 23:33:06 UTC",
    "updated_date": "2025-11-16 23:33:06 UTC"
  },
  {
    "arxiv_id": "2511.12828v1",
    "title": "Catastrophic Forgetting in Kolmogorov-Arnold Networks",
    "authors": [
      "Mohammad Marufur Rahman",
      "Guanchu Wang",
      "Kaixiong Zhou",
      "Minghan Chen",
      "Fan Yang"
    ],
    "abstract": "Catastrophic forgetting is a longstanding challenge in continual learning, where models lose knowledge from earlier tasks when learning new ones. While various mitigation strategies have been proposed for Multi-Layer Perceptrons (MLPs), recent architectural advances like Kolmogorov-Arnold Networks (KANs) have been suggested to offer intrinsic resistance to forgetting by leveraging localized spline-based activations. However, the practical behavior of KANs under continual learning remains unclear, and their limitations are not well understood. To address this, we present a comprehensive study of catastrophic forgetting in KANs and develop a theoretical framework that links forgetting to activation support overlap and intrinsic data dimension. We validate these analyses through systematic experiments on synthetic and vision tasks, measuring forgetting dynamics under varying model configurations and data complexity. Further, we introduce KAN-LoRA, a novel adapter design for parameter-efficient continual fine-tuning of language models, and evaluate its effectiveness in knowledge editing tasks. Our findings reveal that while KANs exhibit promising retention in low-dimensional algorithmic settings, they remain vulnerable to forgetting in high-dimensional domains such as image classification and language modeling. These results advance the understanding of KANs' strengths and limitations, offering practical insights for continual learning system design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 5 figures, accepted in the main technical track of AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.12828v1",
    "published_date": "2025-11-16 23:22:50 UTC",
    "updated_date": "2025-11-16 23:22:50 UTC"
  },
  {
    "arxiv_id": "2511.12810v1",
    "title": "MSRNet: A Multi-Scale Recursive Network for Camouflaged Object Detection",
    "authors": [
      "Leena Alghamdi",
      "Muhammad Usman",
      "Hafeez Anwar",
      "Abdul Bais",
      "Saeed Anwar"
    ],
    "abstract": "Camouflaged object detection is an emerging and challenging computer vision task that requires identifying and segmenting objects that blend seamlessly into their environments due to high similarity in color, texture, and size. This task is further complicated by low-light conditions, partial occlusion, small object size, intricate background patterns, and multiple objects. While many sophisticated methods have been proposed for this task, current methods still struggle to precisely detect camouflaged objects in complex scenarios, especially with small and multiple objects, indicating room for improvement. We propose a Multi-Scale Recursive Network that extracts multi-scale features via a Pyramid Vision Transformer backbone and combines them via specialized Attention-Based Scale Integration Units, enabling selective feature merging. For more precise object detection, our decoder recursively refines features by incorporating Multi-Granularity Fusion Units. A novel recursive-feedback decoding strategy is developed to enhance global context understanding, helping the model overcome the challenges in this task. By jointly leveraging multi-scale learning and recursive feature optimization, our proposed method achieves performance gains, successfully detecting small and multiple camouflaged objects. Our model achieves state-of-the-art results on two benchmark datasets for camouflaged object detection and ranks second on the remaining two. Our codes, model weights, and results are available at \\href{https://github.com/linaagh98/MSRNet}{https://github.com/linaagh98/MSRNet}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12810v1",
    "published_date": "2025-11-16 22:29:06 UTC",
    "updated_date": "2025-11-16 22:29:06 UTC"
  },
  {
    "arxiv_id": "2511.12808v4",
    "title": "Expressive Temporal Specifications for Reward Monitoring",
    "authors": [
      "Omar Adalat",
      "Francesco Belardinelli"
    ],
    "abstract": "Specifying informative and dense reward functions remains a pivotal challenge in Reinforcement Learning, as it directly affects the efficiency of agent training. In this work, we harness the expressive power of quantitative Linear Temporal Logic on finite traces (($\\text{LTL}_f[\\mathcal{F}]$)) to synthesize reward monitors that generate a dense stream of rewards for runtime-observable state trajectories. By providing nuanced feedback during training, these monitors guide agents toward optimal behaviour and help mitigate the well-known issue of sparse rewards under long-horizon decision making, which arises under the Boolean semantics dominating the current literature. Our framework is algorithm-agnostic and only relies on a state labelling function, and naturally accommodates specifying non-Markovian properties. Empirical results show that our quantitative monitors consistently subsume and, depending on the environment, outperform Boolean monitors in maximizing a quantitative measure of task completion and in reducing convergence time.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAAI-26",
    "pdf_url": "https://arxiv.org/pdf/2511.12808v4",
    "published_date": "2025-11-16 22:28:30 UTC",
    "updated_date": "2025-12-29 15:04:16 UTC"
  },
  {
    "arxiv_id": "2511.12804v1",
    "title": "The Alignment Game: A Theory of Long-Horizon Alignment Through Recursive Curation",
    "authors": [
      "Ali Falahati",
      "Mohammad Mohammadi Amiri",
      "Kate Larson",
      "Lukasz Golab"
    ],
    "abstract": "In self-consuming generative models that train on their own outputs, alignment with user preferences becomes a recursive rather than one-time process. We provide the first formal foundation for analyzing the long-term effects of such recursive retraining on alignment. Under a two-stage curation mechanism based on the Bradley-Terry (BT) model, we model alignment as an interaction between two factions: the Model Owner, who filters which outputs should be learned by the model, and the Public User, who determines which outputs are ultimately shared and retained through interactions with the model. Our analysis reveals three structural convergence regimes depending on the degree of preference alignment: consensus collapse, compromise on shared optima, and asymmetric refinement. We prove a fundamental impossibility theorem: no recursive BT-based curation mechanism can simultaneously preserve diversity, ensure symmetric influence, and eliminate dependence on initialization. Framing the process as dynamic social choice, we show that alignment is not a static goal but an evolving equilibrium, shaped both by power asymmetries and path dependence.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12804v1",
    "published_date": "2025-11-16 22:17:16 UTC",
    "updated_date": "2025-11-16 22:17:16 UTC"
  },
  {
    "arxiv_id": "2511.12797v2",
    "title": "Genomic Next-Token Predictors are In-Context Learners",
    "authors": [
      "Nathan Breslow",
      "Aayush Mishra",
      "Mahler Revsine",
      "Michael C. Schatz",
      "Anqi Liu",
      "Daniel Khashabi"
    ],
    "abstract": "In-context learning (ICL) -- the capacity of a model to infer and apply abstract patterns from examples provided within its input -- has been extensively studied in large language models trained for next-token prediction on human text. In fact, prior work often attributes this emergent behavior to distinctive statistical properties in human language. This raises a fundamental question: can ICL arise organically in other sequence domains purely through large-scale predictive training?\n  To explore this, we turn to genomic sequences, an alternative symbolic domain rich in statistical structure. Specifically, we study the Evo2 genomic model, trained predominantly on next-nucleotide (A/T/C/G) prediction, at a scale comparable to mid-sized LLMs. We develop a controlled experimental framework comprising symbolic reasoning tasks instantiated in both linguistic and genomic forms, enabling direct comparison of ICL across genomic and linguistic models. Our results show that genomic models, like their linguistic counterparts, exhibit log-linear gains in pattern induction as the number of in-context demonstrations increases. To the best of our knowledge, this is the first evidence of organically emergent ICL in genomic sequences, supporting the hypothesis that ICL arises as a consequence of large-scale predictive modeling over rich data. These findings extend emergent meta-learning beyond language, pointing toward a unified, modality-agnostic view of in-context learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12797v2",
    "published_date": "2025-11-16 21:56:39 UTC",
    "updated_date": "2025-11-21 02:11:05 UTC"
  },
  {
    "arxiv_id": "2511.12796v2",
    "title": "Maximizing the efficiency of human feedback in AI alignment: a comparative analysis",
    "authors": [
      "Andreas Chouliaras",
      "Dimitris Chatzopoulos"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) relies on preference modeling to align machine learning systems with human values, yet the popular approach of random pair sampling with Bradley-Terry modeling is statistically limited and inefficient under constrained annotation budgets. In this work, we explore alternative sampling and evaluation strategies for preference inference in RLHF, drawing inspiration from areas such as game theory, statistics, and social choice theory. Our best-performing method, Swiss InfoGain, employs a Swiss tournament system with a proxy mutual-information-gain pairing rule, which significantly outperforms all other methods in constrained annotation budgets while also being more sample-efficient. Even in high-resource settings, we can identify superior alternatives to the Bradley-Terry baseline. Our experiments demonstrate that adaptive, resource-aware strategies reduce redundancy, enhance robustness, and yield statistically significant improvements in preference learning, highlighting the importance of balancing alignment quality with human workload in RLHF pipelines.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "17 pages, 6 figures, 6 algorithms. AICS2025",
    "pdf_url": "https://arxiv.org/pdf/2511.12796v2",
    "published_date": "2025-11-16 21:55:59 UTC",
    "updated_date": "2025-12-01 17:18:39 UTC"
  },
  {
    "arxiv_id": "2511.12793v1",
    "title": "Neuro-Logic Lifelong Learning",
    "authors": [
      "Bowen He",
      "Xiaoan Xu",
      "Alper Kamil Bozkurt",
      "Vahid Tarokh",
      "Juncheng Dong"
    ],
    "abstract": "Solving Inductive Logic Programming (ILP) problems with neural networks is a key challenge in Neural-Symbolic Ar- tificial Intelligence (AI). While most research has focused on designing novel network architectures for individual prob- lems, less effort has been devoted to exploring new learning paradigms involving a sequence of problems. In this work, we investigate lifelong learning ILP, which leverages the com- positional and transferable nature of logic rules for efficient learning of new problems. We introduce a compositional framework, demonstrating how logic rules acquired from ear- lier tasks can be efficiently reused in subsequent ones, leading to improved scalability and performance. We formalize our approach and empirically evaluate it on sequences of tasks. Experimental results validate the feasibility and advantages of this paradigm, opening new directions for continual learn- ing in Neural-Symbolic AI.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12793v1",
    "published_date": "2025-11-16 21:51:18 UTC",
    "updated_date": "2025-11-16 21:51:18 UTC"
  },
  {
    "arxiv_id": "2511.12792v1",
    "title": "Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization",
    "authors": [
      "Mohamad A. Hady",
      "Siyi Hu",
      "Mahardhika Pratama",
      "Zehong Cao",
      "Ryszard Kowalczyk"
    ],
    "abstract": "This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12792v1",
    "published_date": "2025-11-16 21:47:04 UTC",
    "updated_date": "2025-11-16 21:47:04 UTC"
  },
  {
    "arxiv_id": "2511.12791v3",
    "title": "Optimal Look-back Horizon for Time Series Forecasting in Federated Learning",
    "authors": [
      "Dahao Tang",
      "Nan Yang",
      "Yanli Li",
      "Zhiyu Zhu",
      "Zhibo Jin",
      "Dong Yuan"
    ],
    "abstract": "Selecting an appropriate look-back horizon remains a fundamental challenge in time series forecasting (TSF), particularly in the federated learning scenarios where data is decentralized, heterogeneous, and often non-independent. While recent work has explored horizon selection by preserving forecasting-relevant information in an intrinsic space, these approaches are primarily restricted to centralized and independently distributed settings. This paper presents a principled framework for adaptive horizon selection in federated time series forecasting through an intrinsic space formulation. We introduce a synthetic data generator (SDG) that captures essential temporal structures in client data, including autoregressive dependencies, seasonality, and trend, while incorporating client-specific heterogeneity. Building on this model, we define a transformation that maps time series windows into an intrinsic representation space with well-defined geometric and statistical properties. We then derive a decomposition of the forecasting loss into a Bayesian term, which reflects irreducible uncertainty, and an approximation term, which accounts for finite-sample effects and limited model capacity. Our analysis shows that while increasing the look-back horizon improves the identifiability of deterministic patterns, it also increases approximation error due to higher model complexity and reduced sample efficiency. We prove that the total forecasting loss is minimized at the smallest horizon where the irreducible loss starts to saturate, while the approximation loss continues to rise. This work provides a rigorous theoretical foundation for adaptive horizon selection for time series forecasting in federated learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI-26 as Oral Presentation",
    "pdf_url": "https://arxiv.org/pdf/2511.12791v3",
    "published_date": "2025-11-16 21:46:54 UTC",
    "updated_date": "2026-01-04 03:46:41 UTC"
  },
  {
    "arxiv_id": "2511.12785v1",
    "title": "Lightweight Optimal-Transport Harmonization on Edge Devices",
    "authors": [
      "Maria Larchenko",
      "Dmitry Guskov",
      "Alexander Lobashev",
      "Georgy Derevyanko"
    ],
    "abstract": "Color harmonization adjusts the colors of an inserted object so that it perceptually matches the surrounding image, resulting in a seamless composite. The harmonization problem naturally arises in augmented reality (AR), yet harmonization algorithms are not currently integrated into AR pipelines because real-time solutions are scarce. In this work, we address color harmonization for AR by proposing a lightweight approach that supports on-device inference. For this, we leverage classical optimal transport theory by training a compact encoder to predict the Monge-Kantorovich transport map. We benchmark our MKL-Harmonizer algorithm against state-of-the-art methods and demonstrate that for real composite AR images our method achieves the best aggregated score. We release our dedicated AR dataset of composite images with pixel-accurate masks and data-gathering toolkit to support further data acquisition by researchers.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2026, Oral",
    "pdf_url": "https://arxiv.org/pdf/2511.12785v1",
    "published_date": "2025-11-16 21:29:46 UTC",
    "updated_date": "2025-11-16 21:29:46 UTC"
  },
  {
    "arxiv_id": "2511.20680v1",
    "title": "Cognitive bias in LLM reasoning compromises interpretation of clinical oncology notes",
    "authors": [
      "Matthew W. Kenaston",
      "Umair Ayub",
      "Mihir Parmar",
      "Muhammad Umair Anjum",
      "Syed Arsalan Ahmed Naqvi",
      "Priya Kumar",
      "Samarth Rawal",
      "Aadel A. Chaudhuri",
      "Yousef Zakharia",
      "Elizabeth I. Heath",
      "Tanios S. Bekaii-Saab",
      "Cui Tao",
      "Eliezer M. Van Allen",
      "Ben Zhou",
      "YooJung Choi",
      "Chitta Baral",
      "Irbaz Bin Riaz"
    ],
    "abstract": "Despite high performance on clinical benchmarks, large language models may reach correct conclusions through faulty reasoning, a failure mode with safety implications for oncology decision support that is not captured by accuracy-based evaluation. In this two-cohort retrospective study, we developed a hierarchical taxonomy of reasoning errors from GPT-4 chain-of-thought responses to real oncology notes and tested its clinical relevance. Using breast and pancreatic cancer notes from the CORAL dataset, we annotated 600 reasoning traces to define a three-tier taxonomy mapping computational failures to cognitive bias frameworks. We validated the taxonomy on 822 responses from prostate cancer consult notes spanning localized through metastatic disease, simulating extraction, analysis, and clinical recommendation tasks. Reasoning errors occurred in 23 percent of interpretations and dominated overall errors, with confirmation bias and anchoring bias most common. Reasoning failures were associated with guideline-discordant and potentially harmful recommendations, particularly in advanced disease management. Automated evaluators using state-of-the-art language models detected error presence but could not reliably classify subtypes. These findings show that large language models may provide fluent but clinically unsafe recommendations when reasoning is flawed. The taxonomy provides a generalizable framework for evaluating and improving reasoning fidelity before clinical deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 6 figures, 1 supplementary figure, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.20680v1",
    "published_date": "2025-11-16 21:13:09 UTC",
    "updated_date": "2025-11-16 21:13:09 UTC"
  },
  {
    "arxiv_id": "2511.12779v2",
    "title": "Scalable Multi-Objective and Meta Reinforcement Learning via Gradient Estimation",
    "authors": [
      "Zhenshuo Zhang",
      "Minxuan Duan",
      "Youran Ye",
      "Hongyang R. Zhang"
    ],
    "abstract": "We study the problem of efficiently estimating policies that simultaneously optimize multiple objectives in reinforcement learning (RL). Given $n$ objectives (or tasks), we seek the optimal partition of these objectives into $k \\ll n$ groups, where each group comprises related objectives that can be trained together. This problem arises in applications such as robotics, control, and preference optimization in language models, where learning a single policy for all $n$ objectives is suboptimal as $n$ grows. We introduce a two-stage procedure -- meta-training followed by fine-tuning -- to address this problem. We first learn a meta-policy for all objectives using multitask learning. Then, we adapt the meta-policy to multiple randomly sampled subsets of objectives. The adaptation step leverages a first-order approximation property of well-trained policy networks, which is empirically verified to be accurate within a 2% error margin across various RL environments. The resulting algorithm, PolicyGradEx, efficiently estimates an aggregate task-affinity score matrix given a policy evaluation algorithm. Based on the estimated affinity score matrix, we cluster the $n$ objectives into $k$ groups by maximizing the intra-cluster affinity scores. Experiments on three robotic control and the Meta-World benchmarks demonstrate that our approach outperforms state-of-the-art baselines by 16% on average, while delivering up to $26\\times$ faster speedup relative to performing full training to obtain the clusters. Ablation studies validate each component of our approach. For instance, compared with random grouping and gradient-similarity-based grouping, our loss-based clustering yields an improvement of 19%. Finally, we analyze the generalization error of policy networks by measuring the Hessian trace of the loss surface, which gives non-vacuous measures relative to the observed generalization errors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages. Fixed several typos from the previous version",
    "pdf_url": "https://arxiv.org/pdf/2511.12779v2",
    "published_date": "2025-11-16 21:05:21 UTC",
    "updated_date": "2025-12-08 20:49:00 UTC"
  },
  {
    "arxiv_id": "2511.13793v1",
    "title": "Modeling Fairness in Recruitment AI via Information Flow",
    "authors": [
      "Mattias Brännström",
      "Themis Dimitra Xanthopoulou",
      "Lili Jiang"
    ],
    "abstract": "Avoiding bias and understanding the real-world consequences of AI-supported decision-making are critical to address fairness and assign accountability. Existing approaches often focus either on technical aspects, such as datasets and models, or on high-level socio-ethical considerations - rarely capturing how these elements interact in practice. In this paper, we apply an information flow-based modeling framework to a real-world recruitment process that integrates automated candidate matching with human decision-making. Through semi-structured stakeholder interviews and iterative modeling, we construct a multi-level representation of the recruitment pipeline, capturing how information is transformed, filtered, and interpreted across both algorithmic and human components. We identify where biases may emerge, how they can propagate through the system, and what downstream impacts they may have on candidates. This case study illustrates how information flow modeling can support structured analysis of fairness risks, providing transparency across complex socio-technical systems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.13793v1",
    "published_date": "2025-11-16 21:01:55 UTC",
    "updated_date": "2025-11-16 21:01:55 UTC"
  },
  {
    "arxiv_id": "2511.12769v1",
    "title": "Event-CausNet: Unlocking Causal Knowledge from Text with Large Language Models for Reliable Spatio-Temporal Forecasting",
    "authors": [
      "Luyao Niu",
      "Zepu Wang",
      "Shuyi Guan",
      "Yang Liu",
      "Peng Sun"
    ],
    "abstract": "While spatio-temporal Graph Neural Networks (GNNs) excel at modeling recurring traffic patterns, their reliability plummets during non-recurring events like accidents. This failure occurs because GNNs are fundamentally correlational models, learning historical patterns that are invalidated by the new causal factors introduced during disruptions. To address this, we propose Event-CausNet, a framework that uses a Large Language Model to quantify unstructured event reports, builds a causal knowledge base by estimating average treatment effects, and injects this knowledge into a dual-stream GNN-LSTM network using a novel causal attention mechanism to adjust and enhance the forecast. Experiments on a real-world dataset demonstrate that Event-CausNet achieves robust performance, reducing prediction error (MAE) by up to 35.87%, significantly outperforming state-of-the-art baselines. Our framework bridges the gap between correlational models and causal reasoning, providing a solution that is more accurate and transferable, while also offering crucial interpretability, providing a more reliable foundation for real-world traffic management during critical disruptions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12769v1",
    "published_date": "2025-11-16 20:45:23 UTC",
    "updated_date": "2025-11-16 20:45:23 UTC"
  },
  {
    "arxiv_id": "2511.12768v1",
    "title": "Evidence of Phase Transitions in Small Transformer-Based Language Models",
    "authors": [
      "Noah Hong",
      "Tao Hong"
    ],
    "abstract": "Phase transitions have been proposed as the origin of emergent abilities in large language models (LLMs), where new capabilities appear abruptly once models surpass critical thresholds of scale. Prior work, such as that of Wei et al., demonstrated these phenomena under model and data scaling, with transitions revealed after applying a log scale to training compute. In this work, we ask three complementary questions: (1) Are phase transitions unique to large models, or can they also be observed in small transformer-based language models? (2) Can such transitions be detected directly in linear training space, rather than only after log rescaling? and (3) Can these transitions emerge at early stages of training? To investigate, we train a small GPT-style transformer on a character-level corpus and analyze the evolution of vocabulary usage throughout training. We track the average word length, the number of correct versus incorrect words, and shifts in vocabulary diversity. Building on these measures, we apply Poisson and sub-Poisson statistics to quantify how words connect and reorganize. This combined analysis reveals a distinct transition point during training. Notably, these transitions are not apparent in standard loss or validation curves, but become visible through our vocabulary- and statistics-based probes. Our findings suggest that phase-transition reorganizations are a general feature of language model training, observable even in modest models, detectable directly in linear training space, and occurring surprisingly early as coherence emerges. This perspective provides new insight into the nonlinear dynamics of language model training and underscores the importance of tailored metrics for uncovering phase transition behaviors",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12768v1",
    "published_date": "2025-11-16 20:37:12 UTC",
    "updated_date": "2025-11-16 20:37:12 UTC"
  },
  {
    "arxiv_id": "2511.12759v1",
    "title": "Optimal Foraging in Memory Retrieval: Evaluating Random Walks and Metropolis-Hastings Sampling in Modern Semantic Spaces",
    "authors": [
      "James Moore"
    ],
    "abstract": "Human memory retrieval often resembles ecological foraging where animals search for food in a patchy environment. Optimal foraging means following the Marginal Value Theorem (MVT), in which individuals exploit a patch of semantically related concepts until it becomes less rewarding and then switch to a new cluster. While human behavioral data suggests foraging-like patterns in semantic fluency tasks, it remains unclear whether modern high-dimensional embedding spaces provide representations that allow algorithms to match observed human behavior. Using state-of-the-art embeddings and prior semantic fluency data, I find that random walks on these embedding spaces produce results consistent with optimal foraging and the MVT. Surprisingly, introducing Metropolis-Hastings sampling, an adaptive algorithm expected to model strategic acceptance and rejection of new clusters, does not produce results consistent with human behavior. These findings challenge the assumption that more complex sampling mechanisms inherently lead to better cognitive models of memory retrieval. Instead, they show that appropriately structured embeddings, even with simple sampling, can produce near-optimal foraging dynamics. This supports the perspective of Hills (2012) rather than Abbott (2015), demonstrating that modern embeddings can approximate human memory foraging without relying on complex acceptance criteria.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12759v1",
    "published_date": "2025-11-16 20:08:29 UTC",
    "updated_date": "2025-11-16 20:08:29 UTC"
  },
  {
    "arxiv_id": "2511.12757v1",
    "title": "Which Way from B to A: The role of embedding geometry in image interpolation for Stable Diffusion",
    "authors": [
      "Nicholas Karris",
      "Luke Durell",
      "Javier Flores",
      "Tegan Emerson"
    ],
    "abstract": "It can be shown that Stable Diffusion has a permutation-invariance property with respect to the rows of Contrastive Language-Image Pretraining (CLIP) embedding matrices. This inspired the novel observation that these embeddings can naturally be interpreted as point clouds in a Wasserstein space rather than as matrices in a Euclidean space. This perspective opens up new possibilities for understanding the geometry of embedding space. For example, when interpolating between embeddings of two distinct prompts, we propose reframing the interpolation problem as an optimal transport problem. By solving this optimal transport problem, we compute a shortest path (or geodesic) between embeddings that captures a more natural and geometrically smooth transition through the embedding space. This results in smoother and more coherent intermediate (interpolated) images when rendered by the Stable Diffusion generative model. We conduct experiments to investigate this effect, comparing the quality of interpolated images produced using optimal transport to those generated by other standard interpolation methods. The novel optimal transport--based approach presented indeed gives smoother image interpolations, suggesting that viewing the embeddings as point clouds (rather than as matrices) better reflects and leverages the geometry of the embedding space.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12757v1",
    "published_date": "2025-11-16 19:58:48 UTC",
    "updated_date": "2025-11-16 19:58:48 UTC"
  },
  {
    "arxiv_id": "2511.12754v1",
    "title": "Adaptively Coordinating with Novel Partners via Learned Latent Strategies",
    "authors": [
      "Benjamin Li",
      "Shuyang Shi",
      "Lucia Romero",
      "Huao Li",
      "Yaqi Xie",
      "Woojun Kim",
      "Stefanos Nikolaidis",
      "Michael Lewis",
      "Katia Sycara",
      "Simon Stepputtis"
    ],
    "abstract": "Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.12754v1",
    "published_date": "2025-11-16 19:45:35 UTC",
    "updated_date": "2025-11-16 19:45:35 UTC"
  },
  {
    "arxiv_id": "2511.12752v1",
    "title": "Whose Narrative is it Anyway? A KV Cache Manipulation Attack",
    "authors": [
      "Mukkesh Ganesh",
      "Kaushik Iyer",
      "Arun Baalaaji Sankar Ananthan"
    ],
    "abstract": "The Key Value(KV) cache is an important component for efficient inference in autoregressive Large Language Models (LLMs), but its role as a representation of the model's internal state makes it a potential target for integrity attacks. This paper introduces \"History Swapping,\" a novel block-level attack that manipulates the KV cache to steer model generation without altering the user-facing prompt. The attack involves overwriting a contiguous segment of the active generation's cache with a precomputed cache from a different topic. We empirically evaluate this method across 324 configurations on the Qwen 3 family of models, analyzing the impact of timing, magnitude, and layer depth of the cache overwrite. Our findings reveal that only full-layer overwrites can successfully hijack the conversation's topic, leading to three distinct behaviors: immediate and persistent topic shift, partial recovery, or a delayed hijack. Furthermore, we observe that high-level structural plans are encoded early in the generation process and local discourse structure is maintained by the final layers of the model. This work demonstrates that the KV cache is a significant vector for security analysis, as it encodes not just context but also topic trajectory and structural planning, making it a powerful interface for manipulating model behavior.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.12752v1",
    "published_date": "2025-11-16 19:38:28 UTC",
    "updated_date": "2025-11-16 19:38:28 UTC"
  },
  {
    "arxiv_id": "2511.12751v1",
    "title": "Are LLMs The Way Forward? A Case Study on LLM-Guided Reinforcement Learning for Decentralized Autonomous Driving",
    "authors": [
      "Timur Anvar",
      "Jeffrey Chen",
      "Yuyan Wang",
      "Rohan Chandra"
    ],
    "abstract": "Autonomous vehicle navigation in complex environments such as dense and fast-moving highways and merging scenarios remains an active area of research. A key limitation of RL is its reliance on well-specified reward functions, which often fail to capture the full semantic and social complexity of diverse, out-of-distribution situations. As a result, a rapidly growing line of research explores using Large Language Models (LLMs) to replace or supplement RL for direct planning and control, on account of their ability to reason about rich semantic context. However, LLMs present significant drawbacks: they can be unstable in zero-shot safety-critical settings, produce inconsistent outputs, and often depend on expensive API calls with network latency. This motivates our investigation into whether small, locally deployed LLMs (< 14B parameters) can meaningfully support autonomous highway driving through reward shaping rather than direct control. We present a case study comparing RL-only, LLM-only, and hybrid approaches, where LLMs augment RL rewards by scoring state-action transitions during training, while standard RL policies execute at test time. Our findings reveal that RL-only agents achieve moderate success rates (73-89%) with reasonable efficiency, LLM-only agents can reach higher success rates (up to 94%) but with severely degraded speed performance, and hybrid approaches consistently fall between these extremes. Critically, despite explicit efficiency instructions, LLM-influenced approaches exhibit systematic conservative bias with substantial model-dependent variability, highlighting important limitations of current small LLMs for safety-critical control tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12751v1",
    "published_date": "2025-11-16 19:31:42 UTC",
    "updated_date": "2025-11-16 19:31:42 UTC"
  },
  {
    "arxiv_id": "2511.14796v1",
    "title": "Opinion Mining and Analysis Using Hybrid Deep Neural Networks",
    "authors": [
      "Adel Hidri",
      "Suleiman Ali Alsaif",
      "Muteeb Alahmari",
      "Eman AlShehri",
      "Minyar Sassi Hidri"
    ],
    "abstract": "Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 4 figures, 11 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.14796v1",
    "published_date": "2025-11-16 19:04:44 UTC",
    "updated_date": "2025-11-16 19:04:44 UTC"
  },
  {
    "arxiv_id": "2511.13791v1",
    "title": "XAI-Driven Deep Learning for Protein Sequence Functional Group Classification",
    "authors": [
      "Pratik Chakraborty",
      "Aryan Bhargava"
    ],
    "abstract": "Proteins perform essential biological functions, and accurate classification of their sequences is critical for understanding structure-function relationships, enzyme mechanisms, and molecular interactions. This study presents a deep learning-based framework for functional group classification of protein sequences derived from the Protein Data Bank (PDB). Four architectures were implemented: Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), CNN-BiLSTM hybrid, and CNN with Attention. Each model was trained using k-mer integer encoding to capture both local and long-range dependencies. Among these, the CNN achieved the highest validation accuracy of 91.8%, demonstrating the effectiveness of localized motif detection. Explainable AI techniques, including Grad-CAM and Integrated Gradients, were applied to interpret model predictions and identify biologically meaningful sequence motifs. The discovered motifs, enriched in histidine, aspartate, glutamate, and lysine, represent amino acid residues commonly found in catalytic and metal-binding regions of transferase enzymes. These findings highlight that deep learning models can uncover functionally relevant biochemical signatures, bridging the gap between predictive accuracy and biological interpretability in protein sequence analysis.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "8 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.13791v1",
    "published_date": "2025-11-16 18:10:42 UTC",
    "updated_date": "2025-11-16 18:10:42 UTC"
  },
  {
    "arxiv_id": "2511.20679v1",
    "title": "Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring",
    "authors": [
      "Melika Ayoughi",
      "Pascal Mettes",
      "Paul Groth"
    ],
    "abstract": "Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.20679v1",
    "published_date": "2025-11-16 18:10:20 UTC",
    "updated_date": "2025-11-16 18:10:20 UTC"
  },
  {
    "arxiv_id": "2511.12712v3",
    "title": "Adaptive Focus Memory for Language Models",
    "authors": [
      "Christopher Cruz"
    ],
    "abstract": "Large language models (LLMs) are increasingly deployed in multi-turn dialogue settings, yet their behavior remains bottlenecked by naive history management strategies. Replaying the full conversation at every turn is simple but costly, while recency-based truncation or static summarization often causes early, high-impact user constraints to drift out of effective context. As a result, models may retain text without reliably applying it when it matters.\n  We present Adaptive Focus Memory (AFM), a lightweight context management system that dynamically assigns each past message one of three fidelity levels: Full, Compressed, or Placeholder, based on semantic relevance, temporal decay, and importance classification. AFM packs messages chronologically under a fixed token budget, preserving critical constraints at high fidelity while allowing low-importance context to degrade gracefully.\n  We evaluate AFM on two multi-turn dialogue benchmarks designed to stress long-horizon constraint preservation: a safety-critical travel scenario involving a user with a severe peanut allergy, and a policy-critical tax compliance scenario involving an illegal evasion request. Under strict grading that requires both explicit constraint recall and appropriately conditioned generation, AFM succeeds in 83.3 percent of allergy runs where all baseline strategies fail, and preserves correct refusal behavior on the tax benchmark.\n  These results demonstrate that effective dialogue memory requires more than retaining prior text. Selectively allocating fidelity across past messages enables reliable constraint preservation under bounded context growth, without modifying model weights or introducing external retrieval infrastructure. We release an open-source implementation of AFM compatible with OpenAI-style chat APIs to support reproducible research and practical deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12712v3",
    "published_date": "2025-11-16 17:52:32 UTC",
    "updated_date": "2025-12-24 19:58:00 UTC"
  },
  {
    "arxiv_id": "2511.12709v1",
    "title": "Adaptive Graph Rewiring to Mitigate Over-Squashing in Mesh-Based GNNs for Fluid Dynamics Simulations",
    "authors": [
      "Sangwoo Seo",
      "Hyunsung Kim",
      "Jiwan Kim",
      "Chanyoung Park"
    ],
    "abstract": "Mesh-based simulation using Graph Neural Networks (GNNs) has been recognized as a promising approach for modeling fluid dynamics. However, the mesh refinement techniques which allocate finer resolution to regions with steep gradients can induce the over-squashing problem in mesh-based GNNs, which prevents the capture of long-range physical interactions. Conventional graph rewiring methods attempt to alleviate this issue by adding new edges, but they typically complete all rewiring operations before applying them to the GNN. These approaches are physically unrealistic, as they assume instantaneous interactions between distant nodes and disregard the distance information between particles. To address these limitations, we propose a novel framework, called Adaptive Graph Rewiring in Mesh-Based Graph Neural Networks (AdaMeshNet), that introduces an adaptive rewiring process into the message-passing procedure to model the gradual propagation of physical interactions. Our method computes a rewiring delay score for bottleneck nodes in the mesh graph, based on the shortest-path distance and the velocity difference. Using this score, it dynamically selects the message-passing layer at which new edges are rewired, which can lead to adaptive rewiring in a mesh graph. Extensive experiments on mesh-based fluid simulations demonstrate that AdaMeshNet outperforms conventional rewiring methods, effectively modeling the sequential nature of physical interactions and enabling more accurate predictions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2511.12709v1",
    "published_date": "2025-11-16 17:51:37 UTC",
    "updated_date": "2025-11-16 17:51:37 UTC"
  },
  {
    "arxiv_id": "2511.12706v2",
    "title": "Beyond Fixed Tasks: Unsupervised Environment Design for Task-Level Pairs",
    "authors": [
      "Daniel Furelos-Blanco",
      "Charles Pert",
      "Frederik Kelbel",
      "Alex F. Spies",
      "Alessandra Russo",
      "Michael Dennis"
    ],
    "abstract": "Training general agents to follow complex instructions (tasks) in intricate environments (levels) remains a core challenge in reinforcement learning. Random sampling of task-level pairs often produces unsolvable combinations, highlighting the need to co-design tasks and levels. While unsupervised environment design (UED) has proven effective at automatically designing level curricula, prior work has only considered a fixed task. We present ATLAS (Aligning Tasks and Levels for Autocurricula of Specifications), a novel method that generates joint autocurricula over tasks and levels. Our approach builds upon UED to automatically produce solvable yet challenging task-level pairs for policy training. To evaluate ATLAS and drive progress in the field, we introduce an evaluation suite that models tasks as reward machines in Minigrid levels. Experiments demonstrate that ATLAS vastly outperforms random sampling approaches, particularly when sampling solvable pairs is unlikely. We further show that mutations leveraging the structure of both tasks and levels accelerate convergence to performant policies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of paper accepted for publication at the 40th AAAI Conference on Artificial Intelligence (AAAI)",
    "pdf_url": "https://arxiv.org/pdf/2511.12706v2",
    "published_date": "2025-11-16 17:48:09 UTC",
    "updated_date": "2025-12-29 13:42:46 UTC"
  },
  {
    "arxiv_id": "2511.13790v1",
    "title": "GeoPl@ntNet: A Platform for Exploring Essential Biodiversity Variables",
    "authors": [
      "Lukas Picek",
      "César Leblanc",
      "Alexis Joly",
      "Pierre Bonnet",
      "Rémi Palard",
      "Maximilien Servajean"
    ],
    "abstract": "This paper describes GeoPl@ntNet, an interactive web application designed to make Essential Biodiversity Variables accessible and understandable to everyone through dynamic maps and fact sheets. Its core purpose is to allow users to explore high-resolution AI-generated maps of species distributions, habitat types, and biodiversity indicators across Europe. These maps, developed through a cascading pipeline involving convolutional neural networks and large language models, provide an intuitive yet information-rich interface to better understand biodiversity, with resolutions as precise as 50x50 meters. The website also enables exploration of specific regions, allowing users to select areas of interest on the map (e.g., urban green spaces, protected areas, or riverbanks) to view local species and their coverage. Additionally, GeoPl@ntNet generates comprehensive reports for selected regions, including insights into the number of protected species, invasive species, and endemic species.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "4 pages, 5 figures, and 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.13790v1",
    "published_date": "2025-11-16 17:36:44 UTC",
    "updated_date": "2025-11-16 17:36:44 UTC"
  },
  {
    "arxiv_id": "2511.21703v1",
    "title": "Evaluating Embedding Generalization: How LLMs, LoRA, and SLERP Shape Representational Geometry",
    "authors": [
      "Siyaxolisa Kabane"
    ],
    "abstract": "We investigate the generalization properties of dense text embeddings when the embedding backbone is a large language model (LLM) versus when it is a non-LLM encoder, and we study the extent to which spherical linear interpolation (SLERP) model-merging mitigates over-specialization introduced by task-specific adaptation (e.g., LoRA). To make the comparison concrete and domain-agnostic, we design a controlled suite of experiments in which models embed short numerical sequences and are evaluated on their ability to cluster and classify those sequences according to well-defined number-theoretic properties. Our experimental protocol compares four families of models: (1) non-LLM encoders trained from scratch or fine-tuned for embeddings, (2) LLM-based encoders adapted with parameter-efficient methods (LoRA), (3) LLM-based encoders with LoRA followed by model souping merging into the base weights, and (4) the same LoRA-adapted LLMs merged using SLERP across checkpoints or stages. We evaluate representational quality with clustering indices (Silhouette and Davies Bouldin). We additionally analyze the use of kmeans labels to see if the embeddings encode any other information besides the one we are testing for. Empirically, we find that LLM-based backbones produce embeddings that better capture higher-order, compositional numeric patterns, but are prone to adapter dominance that degrades balanced generalization; SLERP merging consistently recovers base-model structure while retaining most task gains, yielding superior tradeoffs in clustering separability, and robustness compared to model souping or models that were not merged.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 16 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.21703v1",
    "published_date": "2025-11-16 17:28:06 UTC",
    "updated_date": "2025-11-16 17:28:06 UTC"
  },
  {
    "arxiv_id": "2511.12695v2",
    "title": "A Closer Look at Personalized Fine-Tuning in Heterogeneous Federated Learning",
    "authors": [
      "Minghui Chen",
      "Hrad Ghoukasian",
      "Ruinan Jin",
      "Zehua Wang",
      "Sai Praneeth Karimireddy",
      "Xiaoxiao Li"
    ],
    "abstract": "Federated Learning (FL) enables decentralized, privacy-preserving model training but struggles to balance global generalization and local personalization due to non-identical data distributions across clients. Personalized Fine-Tuning (PFT), a popular post-hoc solution, fine-tunes the final global model locally but often overfits to skewed client distributions or fails under domain shifts. We propose adapting Linear Probing followed by full Fine-Tuning (LP-FT), a principled centralized strategy for alleviating feature distortion (Kumar et al., 2022), to the FL setting. Through systematic evaluation across seven datasets and six PFT variants, we demonstrate LP-FT's superiority in balancing personalization and generalization. Our analysis uncovers federated feature distortion, a phenomenon where local fine-tuning destabilizes globally learned features, and theoretically characterizes how LP-FT mitigates this via phased parameter updates. We further establish conditions (e.g., partial feature overlap, covariate-concept shift) under which LP-FT outperforms standard fine-tuning, offering actionable guidelines for deploying robust personalization in FL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages, 6 figures, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.12695v2",
    "published_date": "2025-11-16 17:19:23 UTC",
    "updated_date": "2025-12-28 16:16:40 UTC"
  },
  {
    "arxiv_id": "2511.12693v1",
    "title": "HEDGE: Hallucination Estimation via Dense Geometric Entropy for VQA with Vision-Language Models",
    "authors": [
      "Sushant Gautam",
      "Michael A. Riegler",
      "Pål Halvorsen"
    ],
    "abstract": "Vision-language models (VLMs) enable open-ended visual question answering but remain prone to hallucinations. We present HEDGE, a unified framework for hallucination detection that combines controlled visual perturbations, semantic clustering, and robust uncertainty metrics. HEDGE integrates sampling, distortion synthesis, clustering (entailment- and embedding-based), and metric computation into a reproducible pipeline applicable across multimodal architectures.\n  Evaluations on VQA-RAD and KvasirVQA-x1 with three representative VLMs (LLaVA-Med, Med-Gemma, Qwen2.5-VL) reveal clear architecture- and prompt-dependent trends. Hallucination detectability is highest for unified-fusion models with dense visual tokenization (Qwen2.5-VL) and lowest for architectures with restricted tokenization (Med-Gemma). Embedding-based clustering often yields stronger separation when applied directly to the generated answers, whereas NLI-based clustering remains advantageous for LLaVA-Med and for longer, sentence-level responses. Across configurations, the VASE metric consistently provides the most robust hallucination signal, especially when paired with embedding clustering and a moderate sampling budget (n ~ 10-15). Prompt design also matters: concise, label-style outputs offer clearer semantic structure than syntactically constrained one-sentence responses.\n  By framing hallucination detection as a geometric robustness problem shaped jointly by sampling scale, prompt structure, model architecture, and clustering strategy, HEDGE provides a principled, compute-aware foundation for evaluating multimodal reliability. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12693v1",
    "published_date": "2025-11-16 17:16:31 UTC",
    "updated_date": "2025-11-16 17:16:31 UTC"
  },
  {
    "arxiv_id": "2511.12691v1",
    "title": "R$^{2}$Seg: Training-Free OOD Medical Tumor Segmentation via Anatomical Reasoning and Statistical Rejection",
    "authors": [
      "Shuaike Shen",
      "Ke Liu",
      "Jiaqing Xie",
      "Shangde Gao",
      "Chunhua Shen",
      "Ge Liu",
      "Mireia Crispin-Ortuzar",
      "Shangqi Gao"
    ],
    "abstract": "Foundation models for medical image segmentation struggle under out-of-distribution (OOD) shifts, often producing fragmented false positives on OOD tumors. We introduce R$^{2}$Seg, a training-free framework for robust OOD tumor segmentation that operates via a two-stage Reason-and-Reject process. First, the Reason step employs an LLM-guided anatomical reasoning planner to localize organ anchors and generate multi-scale ROIs. Second, the Reject step applies two-sample statistical testing to candidates generated by a frozen foundation model (BiomedParse) within these ROIs. This statistical rejection filter retains only candidates significantly different from normal tissue, effectively suppressing false positives. Our framework requires no parameter updates, making it compatible with zero-update test-time augmentation and avoiding catastrophic forgetting. On multi-center and multi-modal tumor segmentation benchmarks, R$^{2}$Seg substantially improves Dice, specificity, and sensitivity over strong baselines and the original foundation models. Code are available at https://github.com/Eurekashen/R2Seg.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12691v1",
    "published_date": "2025-11-16 17:15:52 UTC",
    "updated_date": "2025-11-16 17:15:52 UTC"
  },
  {
    "arxiv_id": "2511.12690v1",
    "title": "Improving Direct Persian-English Speech-to-Speech Translation with Discrete Units and Synthetic Parallel Data",
    "authors": [
      "Sina Rashidi",
      "Hossein Sameti"
    ],
    "abstract": "Direct speech-to-speech translation (S2ST), in which all components are trained jointly, is an attractive alternative to cascaded systems because it offers a simpler pipeline and lower inference latency. However, direct S2ST models require large amounts of parallel speech data in the source and target languages, which are rarely available for low-resource languages such as Persian. This paper presents a direct S2ST system for translating Persian speech into English speech, as well as a pipeline for synthetic parallel Persian-English speech generation. The model comprises three components: (1) a conformer-based encoder, initialized from self-supervised pre-training, maps source speech to high-level acoustic representations; (2) a causal transformer decoder with relative position multi-head attention translates these representations into discrete target speech units; (3) a unit-based neural vocoder generates waveforms from the predicted discrete units. To mitigate the data scarcity problem, we construct a new Persian-English parallel speech corpus by translating Persian speech transcriptions into English using a large language model and then synthesizing the corresponding English speech with a state-of-the-art zero-shot text-to-speech system. The resulting corpus increases the amount of available parallel speech by roughly a factor of six. On the Persian-English portion of the CVSS corpus, the proposed model achieves improvement of 4.6 ASR BLEU with the synthetic data over direct baselines. These results indicate that combining self-supervised pre-training, discrete speech units, and synthetic parallel data is effective for improving direct S2ST in low-resource language pairs such as Persian-English",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12690v1",
    "published_date": "2025-11-16 17:14:23 UTC",
    "updated_date": "2025-11-16 17:14:23 UTC"
  },
  {
    "arxiv_id": "2601.11528v1",
    "title": "Knowledge Graph Construction for Stock Markets with LLM-Based Explainable Reasoning",
    "authors": [
      "Cheonsol Lee",
      "Youngsang Jeong",
      "Jeongyeol Shin",
      "Huiju Kim",
      "Jidong Kim"
    ],
    "abstract": "The stock market is inherently complex, with interdependent relationships among companies, sectors, and financial indicators. Traditional research has largely focused on time-series forecasting and single-company analysis, relying on numerical data for stock price prediction. While such approaches can provide short-term insights, they are limited in capturing relational patterns, competitive dynamics, and explainable investment reasoning. To address these limitations, we propose a knowledge graph schema specifically designed for the stock market, modeling companies, sectors, stock indicators, financial statements, and inter-company relationships. By integrating this schema with large language models (LLMs), our approach enables multi-hop reasoning and relational queries, producing explainable and in-depth answers to complex financial questions. Figure1 illustrates the system pipeline, detailing the flow from data collection and graph construction to LLM-based query processing and answer generation. We validate the proposed framework through practical case studies on Korean listed companies, demonstrating its capability to extract insights that are difficult or impossible to obtain from traditional database queries alone. The results highlight the potential of combining knowledge graphs with LLMs for advanced investment analysis and decision support.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "6 pages, 3 figures, CIKM 2025 Workshop - Advances in Financial AI: Innovations, Risk, and Responsibility in the Era of LLMs",
    "pdf_url": "https://arxiv.org/pdf/2601.11528v1",
    "published_date": "2025-11-16 16:49:09 UTC",
    "updated_date": "2025-11-16 16:49:09 UTC"
  },
  {
    "arxiv_id": "2511.12677v1",
    "title": "Dynamic Tree Databases in Automated Planning",
    "authors": [
      "Oliver Joergensen",
      "Dominik Drexler",
      "Jendrik Seipp"
    ],
    "abstract": "A central challenge in scaling up explicit state-space search for large tasks is compactly representing the set of generated states. Tree databases, a data structure from model checking, require constant space per generated state in the best case, but they need a large preallocation of memory. We propose a novel dynamic variant of tree databases for compressing state sets over propositional and numeric variables and prove that it maintains the desirable properties of the static counterpart. Our empirical evaluation of state compression techniques for grounded and lifted planning on classical and numeric planning tasks reveals compression ratios of several orders of magnitude, often with negligible runtime overhead.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12677v1",
    "published_date": "2025-11-16 16:34:19 UTC",
    "updated_date": "2025-11-16 16:34:19 UTC"
  },
  {
    "arxiv_id": "2511.12676v1",
    "title": "BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections",
    "authors": [
      "Subin Varghese",
      "Joshua Gao",
      "Asad Ur Rahman",
      "Vedhus Hoskere"
    ],
    "abstract": "Deploying embodied agents that can answer questions about their surroundings in realistic real-world settings remains difficult, partly due to the scarcity of benchmarks that faithfully capture practical operating conditions. We propose infrastructure inspection as a compelling domain for open-vocabulary Embodied Question Answering (EQA): it naturally demands multi-scale reasoning, long-range spatial understanding, and complex semantic relationships, while offering unique evaluation advantages via standardized National Bridge Inventory (NBI) condition ratings (0-9), professional inspection reports, and egocentric imagery.\n  We introduce BridgeEQA, a benchmark of 2,200 open-vocabulary question-answer pairs (in the style of OpenEQA) grounded in professional inspection reports across 200 real-world bridge scenes with 47.93 images on average per scene. Questions require synthesizing visual evidence across multiple images and aligning responses with NBI condition ratings. We further propose a new EQA metric Image Citation Relevance to evaluate the ability of a model to cite relevant images.\n  Evaluations of state-of-the-art vision-language models reveal substantial performance gaps under episodic memory EQA settings. To address this, we propose Embodied Memory Visual Reasoning (EMVR), which formulates inspection as sequential navigation over an image-based scene graph: images are nodes, and an agent takes actions to traverse views, compare evidence, and reason within a Markov decision process. EMVR shows strong performance over the baselines. We publicly release both the dataset and code.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12676v1",
    "published_date": "2025-11-16 16:30:38 UTC",
    "updated_date": "2025-11-16 16:30:38 UTC"
  },
  {
    "arxiv_id": "2511.17587v1",
    "title": "Emotion and Intention Guided Multi-Modal Learning for Sticker Response Selection",
    "authors": [
      "Yuxuan Hu",
      "Jian Chen",
      "Yuhao Wang",
      "Zixuan Li",
      "Jing Xiong",
      "Pengyue Jia",
      "Wei Wang",
      "Chengming Li",
      "Xiangyu Zhao"
    ],
    "abstract": "Stickers are widely used in online communication to convey emotions and implicit intentions. The Sticker Response Selection (SRS) task aims to select the most contextually appropriate sticker based on the dialogue. However, existing methods typically rely on semantic matching and model emotional and intentional cues separately, which can lead to mismatches when emotions and intentions are misaligned. To address this issue, we propose Emotion and Intention Guided Multi-Modal Learning (EIGML). This framework is the first to jointly model emotion and intention, effectively reducing the bias caused by isolated modeling and significantly improving selection accuracy. Specifically, we introduce Dual-Level Contrastive Framework to perform both intra-modality and inter-modality alignment, ensuring consistent representation of emotional and intentional features within and across modalities. In addition, we design an Intention-Emotion Guided Multi-Modal Fusion module that integrates emotional and intentional information progressively through three components: Emotion-Guided Intention Knowledge Selection, Intention-Emotion Guided Attention Fusion, and Similarity-Adjusted Matching Mechanism. This design injects rich, effective information into the model and enables a deeper understanding of the dialogue, ultimately enhancing sticker selection performance. Experimental results on two public SRS datasets show that EIGML consistently outperforms state-of-the-art baselines, achieving higher accuracy and a better understanding of emotional and intentional features. Code is provided in the supplementary materials.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.17587v1",
    "published_date": "2025-11-16 16:11:48 UTC",
    "updated_date": "2025-11-16 16:11:48 UTC"
  },
  {
    "arxiv_id": "2511.12668v1",
    "title": "AI Bill of Materials and Beyond: Systematizing Security Assurance through the AI Risk Scanning (AIRS) Framework",
    "authors": [
      "Samuel Nathanson",
      "Alexander Lee",
      "Catherine Chen Kieffer",
      "Jared Junkin",
      "Jessica Ye",
      "Amir Saeed",
      "Melanie Lockhart",
      "Russ Fink",
      "Elisha Peterson",
      "Lanier Watkins"
    ],
    "abstract": "Assurance for artificial intelligence (AI) systems remains fragmented across software supply-chain security, adversarial machine learning, and governance documentation. Existing transparency mechanisms - including Model Cards, Datasheets, and Software Bills of Materials (SBOMs) - advance provenance reporting but rarely provide verifiable, machine-readable evidence of model security. This paper introduces the AI Risk Scanning (AIRS) Framework, a threat-model-based, evidence-generating framework designed to operationalize AI assurance. The AIRS Framework evolved through three progressive pilot studies - Smurf (AIBOM schema design), OPAL (operational validation), and Pilot C (AIRS) - that reframed AI documentation from descriptive disclosure toward measurable, evidence-bound verification. The framework aligns its assurance fields to the MITRE ATLAS adversarial ML taxonomy and automatically produces structured artifacts capturing model integrity, packaging and serialization safety, structural adapters, and runtime behaviors. Currently, the AIRS Framework is scoped to provide model-level assurances for LLMs, but it could be expanded to include other modalities and cover system-level threats (e.g. application-layer abuses, tool-calling). A proof-of-concept on a quantized GPT-OSS-20B model demonstrates enforcement of safe loader policies, per-shard hash verification, and contamination and backdoor probes executed under controlled runtime conditions. Comparative analysis with SBOM standards of SPDX 3.0 and CycloneDX 1.6 reveals alignment on identity and evaluation metadata, but identifies critical gaps in representing AI-specific assurance fields. The AIRS Framework thus extends SBOM practice to the AI domain by coupling threat modeling with automated, auditable evidence generation, providing a principled foundation for standardized, trustworthy, and machine-verifiable AI risk documentation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 4 figures, 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.12668v1",
    "published_date": "2025-11-16 16:10:38 UTC",
    "updated_date": "2025-11-16 16:10:38 UTC"
  },
  {
    "arxiv_id": "2511.12663v1",
    "title": "FLClear: Visually Verifiable Multi-Client Watermarking for Federated Learning",
    "authors": [
      "Chen Gu",
      "Yingying Sun",
      "Yifan She",
      "Donghui Hu"
    ],
    "abstract": "Federated learning (FL) enables multiple clients to collaboratively train a shared global model while preserving the privacy of their local data. Within this paradigm, the intellectual property rights (IPR) of client models are critical assets that must be protected. In practice, the central server responsible for maintaining the global model may maliciously manipulate the global model to erase client contributions or falsely claim sole ownership, thereby infringing on clients' IPR. Watermarking has emerged as a promising technique for asserting model ownership and protecting intellectual property. However, existing FL watermarking approaches remain limited, suffering from potential watermark collisions among clients, insufficient watermark security, and non-intuitive verification mechanisms. In this paper, we propose FLClear, a novel framework that simultaneously achieves collision-free watermark aggregation, enhanced watermark security, and visually interpretable ownership verification. Specifically, FLClear introduces a transposed model jointly optimized with contrastive learning to integrate the watermarking and main task objectives. During verification, the watermark is reconstructed from the transposed model and evaluated through both visual inspection and structural similarity metrics, enabling intuitive and quantitative ownership verification. Comprehensive experiments conducted over various datasets, aggregation schemes, and attack scenarios demonstrate the effectiveness of FLClear and confirm that it consistently outperforms state-of-the-art FL watermarking methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12663v1",
    "published_date": "2025-11-16 15:59:58 UTC",
    "updated_date": "2025-11-16 15:59:58 UTC"
  },
  {
    "arxiv_id": "2511.12648v1",
    "title": "Scalable Hierarchical AI-Blockchain Framework for Real-Time Anomaly Detection in Large-Scale Autonomous Vehicle Networks",
    "authors": [
      "Rathin Chandra Shit",
      "Sharmila Subudhi"
    ],
    "abstract": "The security of autonomous vehicle networks is facing major challenges, owing to the complexity of sensor integration, real-time performance demands, and distributed communication protocols that expose vast attack surfaces around both individual and network-wide safety. Existing security schemes are unable to provide sub-10 ms (milliseconds) anomaly detection and distributed coordination of large-scale networks of vehicles within an acceptable safety/privacy framework. This paper introduces a three-tier hybrid security architecture HAVEN (Hierarchical Autonomous Vehicle Enhanced Network), which decouples real-time local threat detection and distributed coordination operations. It incorporates a light ensemble anomaly detection model on the edge (first layer), Byzantine-fault-tolerant federated learning to aggregate threat intelligence at a regional scale (middle layer), and selected blockchain mechanisms (top layer) to ensure critical security coordination. Extensive experimentation is done on a real-world autonomous driving dataset. Large-scale simulations with the number of vehicles ranging between 100 and 1000 and different attack types, such as sensor spoofing, jamming, and adversarial model poisoning, are conducted to test the scalability and resiliency of HAVEN. Experimental findings show sub-10 ms detection latency with an accuracy of 94% and F1-score of 92% across multimodal sensor data, Byzantine fault tolerance validated with 20\\% compromised nodes, and a reduced blockchain storage overhead, guaranteeing sufficient differential privacy. The proposed framework overcomes the important trade-off between real-time safety obligation and distributed security coordination with novel three-tiered processing. The scalable architecture of HAVEN is shown to provide great improvement in detection accuracy as well as network resilience over other methods.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to the Journal",
    "pdf_url": "https://arxiv.org/pdf/2511.12648v1",
    "published_date": "2025-11-16 15:30:46 UTC",
    "updated_date": "2025-11-16 15:30:46 UTC"
  },
  {
    "arxiv_id": "2511.13789v1",
    "title": "Uncovering and Aligning Anomalous Attention Heads to Defend Against NLP Backdoor Attacks",
    "authors": [
      "Haotian Jin",
      "Yang Li",
      "Haihui Fan",
      "Lin Shen",
      "Xiangfang Li",
      "Bo Li"
    ],
    "abstract": "Backdoor attacks pose a serious threat to the security of large language models (LLMs), causing them to exhibit anomalous behavior under specific trigger conditions. The design of backdoor triggers has evolved from fixed triggers to dynamic or implicit triggers. This increased flexibility in trigger design makes it challenging for defenders to identify their specific forms accurately. Most existing backdoor defense methods are limited to specific types of triggers or rely on an additional clean model for support. To address this issue, we propose a backdoor detection method based on attention similarity, enabling backdoor detection without prior knowledge of the trigger. Our study reveals that models subjected to backdoor attacks exhibit unusually high similarity among attention heads when exposed to triggers. Based on this observation, we propose an attention safety alignment approach combined with head-wise fine-tuning to rectify potentially contaminated attention heads, thereby effectively mitigating the impact of backdoor attacks. Extensive experimental results demonstrate that our method significantly reduces the success rate of backdoor attacks while preserving the model's performance on downstream tasks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.13789v1",
    "published_date": "2025-11-16 15:26:50 UTC",
    "updated_date": "2025-11-16 15:26:50 UTC"
  },
  {
    "arxiv_id": "2511.13788v2",
    "title": "Scaling Patterns in Adversarial Alignment: Evidence from Multi-LLM Jailbreak Experiments",
    "authors": [
      "Samuel Nathanson",
      "Rebecca Williams",
      "Cynthia Matuszek"
    ],
    "abstract": "Large language models (LLMs) increasingly operate in multi-agent and safety-critical settings, raising open questions about how their vulnerabilities scale when models interact adversarially. This study examines whether larger models can systematically jailbreak smaller ones - eliciting harmful or restricted behavior despite alignment safeguards. Using standardized adversarial tasks from JailbreakBench, we simulate over 6,000 multi-turn attacker-target exchanges across major LLM families and scales (0.6B-120B parameters), measuring both harm score and refusal behavior as indicators of adversarial potency and alignment integrity. Each interaction is evaluated through aggregated harm and refusal scores assigned by three independent LLM judges, providing a consistent, model-based measure of adversarial outcomes. Aggregating results across prompts, we find a strong and statistically significant correlation between mean harm and the logarithm of the attacker-to-target size ratio (Pearson r = 0.51, p < 0.001; Spearman rho = 0.52, p < 0.001), indicating that relative model size correlates with the likelihood and severity of harmful completions. Mean harm score variance is higher across attackers (0.18) than across targets (0.10), suggesting that attacker-side behavioral diversity contributes more to adversarial outcomes than target susceptibility. Attacker refusal frequency is strongly and negatively correlated with harm (rho = -0.93, p < 0.001), showing that attacker-side alignment mitigates harmful responses. These findings reveal that size asymmetry influences robustness and provide exploratory evidence for adversarial scaling patterns, motivating more controlled investigations into inter-model alignment and safety.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.13788v2",
    "published_date": "2025-11-16 15:16:33 UTC",
    "updated_date": "2026-01-01 13:08:55 UTC"
  },
  {
    "arxiv_id": "2511.17586v1",
    "title": "Hierarchical Adaptive Consensus Network: A Dynamic Framework for Scalable Consensus in Collaborative Multi-Agent AI Systems",
    "authors": [
      "Rathin Chandra Shit",
      "Sharmila Subudhi"
    ],
    "abstract": "The consensus strategies used in collaborative multi-agent systems (MAS) face notable challenges related to adaptability, scalability, and convergence certainties. These approaches, including structured workflows, debate models, and iterative voting, often lead to communication bottlenecks, stringent decision-making processes, and delayed responses in solving complex and evolving tasks. This article introduces a three-tier architecture, the Hierarchical Adaptive Consensus Network (\\hacn), which suggests various consensus policies based on task characterization and agent performance metrics. The first layer collects the confidence-based voting outcomes of several local agent clusters. In contrast, the second level facilitates inter-cluster communication through cross-clustered partial knowledge sharing and dynamic timeouts. The third layer provides system-wide coordination and final arbitration by employing a global orchestration framework with adaptable decision rules. The proposed model achieves $\\bigO(n)$ communication complexity, as opposed to the $\\bigO(n^2)$ complexity of the existing fully connected MAS. Experiments performed in a simulated environment yielded a 99.9\\% reduction in communication overhead during consensus convergence. Furthermore, the proposed approach ensures consensus convergence through hierarchical escalation and dynamic adaptation for a wide variety of complicated tasks.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "Submitted to Elsevier",
    "pdf_url": "https://arxiv.org/pdf/2511.17586v1",
    "published_date": "2025-11-16 15:09:15 UTC",
    "updated_date": "2025-11-16 15:09:15 UTC"
  },
  {
    "arxiv_id": "2511.12635v1",
    "title": "LLM4SCREENLIT: Recommendations on Assessing the Performance of Large Language Models for Screening Literature in Systematic Reviews",
    "authors": [
      "Lech Madeyski",
      "Barbara Kitchenham",
      "Martin Shepperd"
    ],
    "abstract": "Context: Large language models (LLMs) are released faster than users' ability to evaluate them rigorously. When LLMs underpin research, such as identifying relevant literature for systematic reviews (SRs), robust empirical assessment is essential. Objective: We identify and discuss key challenges in assessing LLM performance for selecting relevant literature, identify good (evaluation) practices, and propose recommendations. Method: Using a recent large-scale study as an example, we identify problems with the use of traditional metrics for assessing the performance of Gen-AI tools for identifying relevant literature in SRs. We analyzed 27 additional papers investigating this issue, extracted the performance metrics, and found both good practices and widespread problems, especially with the use and reporting of performance metrics for SR screening. Results: Major weaknesses included: i) a failure to use metrics that are robust to imbalanced data and do not directly indicate whether results are better than chance, e.g., the use of Accuracy, ii) a failure to consider the impact of lost evidence when making claims concerning workload savings, and iii) pervasive failure to report the full confusion matrix (or performance metrics from which it can be reconstructed) which is essential for future meta-analyses. On the positive side, we extract good (evaluation) practices on which our recommendations for researchers and practitioners, as well as policymakers, are built. Conclusions: SR screening evaluations should prioritize lost evidence/recall alongside chance-anchored and cost-sensitive Weighted MCC (WMCC) metric, report complete confusion matrices, treat unclassifiable outputs as referred-back positives for assessment, adopt leakage-aware designs with non-LLM baselines and open artifacts, and ground conclusions in cost-benefit analysis where FNs carry higher penalties than FPs.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "19 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.12635v1",
    "published_date": "2025-11-16 15:04:50 UTC",
    "updated_date": "2025-11-16 15:04:50 UTC"
  },
  {
    "arxiv_id": "2511.12631v2",
    "title": "Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation",
    "authors": [
      "Yushe Cao",
      "Dianxi Shi",
      "Xing Fu",
      "Xuechao Zou",
      "Haikuo Peng",
      "Xueqi Li",
      "Chun Yu",
      "Junliang Xing"
    ],
    "abstract": "While significant progress has been achieved in multimodal facial generation using semantic masks and textual descriptions, conventional feature fusion approaches often fail to enable effective cross-modal interactions, thereby leading to suboptimal generation outcomes. To address this challenge, we introduce MDiTFace--a customized diffusion transformer framework that employs a unified tokenization strategy to process semantic mask and text inputs, eliminating discrepancies between heterogeneous modality representations. The framework facilitates comprehensive multimodal feature interaction through stacked, newly designed multivariate transformer blocks that process all conditions synchronously. Additionally, we design a novel decoupled attention mechanism by dissociating implicit dependencies between mask tokens and temporal embeddings. This mechanism segregates internal computations into dynamic and static pathways, enabling caching and reuse of features computed in static pathways after initial calculation, thereby reducing additional computational overhead introduced by mask condition by over 94% while maintaining performance. Extensive experiments demonstrate that MDiTFace significantly outperforms other competing methods in terms of both facial fidelity and conditional consistency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12631v2",
    "published_date": "2025-11-16 14:52:54 UTC",
    "updated_date": "2026-01-07 10:24:02 UTC"
  },
  {
    "arxiv_id": "2511.12630v1",
    "title": "Knots: A Large-Scale Multi-Agent Enhanced Expert-Annotated Dataset and LLM Prompt Optimization for NOTAM Semantic Parsing",
    "authors": [
      "Maoqi Liu",
      "Quan Fang",
      "Yang Yang",
      "Can Zhao",
      "Kaiquan Cai"
    ],
    "abstract": "Notice to Air Missions (NOTAMs) serve as a critical channel for disseminating key flight safety information, yet their complex linguistic structures and implicit reasoning pose significant challenges for automated parsing. Existing research mainly focuses on surface-level tasks such as classification and named entity recognition, lacking deep semantic understanding. To address this gap, we propose NOTAM semantic parsing, a task emphasizing semantic inference and the integration of aviation domain knowledge to produce structured, inference-rich outputs. To support this task, we construct Knots (Knowledge and NOTAM Semantics), a high-quality dataset of 12,347 expert-annotated NOTAMs covering 194 Flight Information Regions, enhanced through a multi-agent collaborative framework for comprehensive field discovery. We systematically evaluate a wide range of prompt-engineering strategies and model-adaptation techniques, achieving substantial improvements in aviation text understanding and processing. Our experimental results demonstrate the effectiveness of the proposed approach and offer valuable insights for automated NOTAM analysis systems. Our code is available at: https://github.com/Estrellajer/Knots.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Advanced Engineering Informatics",
    "pdf_url": "https://arxiv.org/pdf/2511.12630v1",
    "published_date": "2025-11-16 14:52:24 UTC",
    "updated_date": "2025-11-16 14:52:24 UTC"
  },
  {
    "arxiv_id": "2511.12627v1",
    "title": "C3Net: Context-Contrast Network for Camouflaged Object Detection",
    "authors": [
      "Baber Jan",
      "Aiman H. El-Maleh",
      "Abdul Jabbar Siddiqui",
      "Abdul Bais",
      "Saeed Anwar"
    ],
    "abstract": "Camouflaged object detection identifies objects that blend seamlessly with their surroundings through similar colors, textures, and patterns. This task challenges both traditional segmentation methods and modern foundation models, which fail dramatically on camouflaged objects. We identify six fundamental challenges in COD: Intrinsic Similarity, Edge Disruption, Extreme Scale Variation, Environmental Complexities, Contextual Dependencies, and Salient-Camouflaged Object Disambiguation. These challenges frequently co-occur and compound the difficulty of detection, requiring comprehensive architectural solutions. We propose C3Net, which addresses all challenges through a specialized dual-pathway decoder architecture. The Edge Refinement Pathway employs gradient-initialized Edge Enhancement Modules to recover precise boundaries from early features. The Contextual Localization Pathway utilizes our novel Image-based Context Guidance mechanism to achieve intrinsic saliency suppression without external models. An Attentive Fusion Module synergistically combines the two pathways via spatial gating. C3Net achieves state-of-the-art performance with S-measures of 0.898 on COD10K, 0.904 on CAMO, and 0.913 on NC4K, while maintaining efficient processing. C3Net demonstrates that complex, multifaceted detection challenges require architectural innovation, with specialized components working synergistically to achieve comprehensive coverage beyond isolated improvements. Code, model weights, and results are available at https://github.com/Baber-Jan/C3Net.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12627v1",
    "published_date": "2025-11-16 14:35:39 UTC",
    "updated_date": "2025-11-16 14:35:39 UTC"
  },
  {
    "arxiv_id": "2511.12614v1",
    "title": "OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding",
    "authors": [
      "Artem Moroz",
      "Vít Zeman",
      "Martin Mikšík",
      "Elizaveta Isianova",
      "Miroslav David",
      "Pavel Burget",
      "Varun Burde"
    ],
    "abstract": "We introduce a unified, end-to-end framework that seamlessly integrates object detection and pose estimation with a versatile onboarding process. Our pipeline begins with an onboarding stage that generates object representations from either traditional 3D CAD models or, in their absence, by rapidly reconstructing a high-fidelity neural representation (NeRF) from multi-view images. Given a test image, our system first employs the CNOS detector to localize target objects. For each detection, our novel pose estimation module, OPFormer, infers the precise 6D pose. The core of OPFormer is a transformer-based architecture that leverages a foundation model for robust feature extraction. It uniquely learns a comprehensive object representation by jointly encoding multiple template views and enriches these features with explicit 3D geometric priors using Normalized Object Coordinate Space (NOCS). A decoder then establishes robust 2D-3D correspondences to determine the final pose. Evaluated on the challenging BOP benchmarks, our integrated system demonstrates a strong balance between accuracy and efficiency, showcasing its practical applicability in both model-based and model-free scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12614v1",
    "published_date": "2025-11-16 14:19:52 UTC",
    "updated_date": "2025-11-16 14:19:52 UTC"
  },
  {
    "arxiv_id": "2511.12609v2",
    "title": "Uni-MoE-2.0-Omni: Scaling Language-Centric Omnimodal Large Model with Advanced MoE, Training and Data",
    "authors": [
      "Yunxin Li",
      "Xinyu Chen",
      "Shenyuan Jiang",
      "Haoyuan Shi",
      "Zhenyu Liu",
      "Xuanyu Zhang",
      "Nanhao Deng",
      "Zhenran Xu",
      "Yicheng Ma",
      "Meishan Zhang",
      "Baotian Hu",
      "Min Zhang"
    ],
    "abstract": "We present Uni-MoE 2.0 from the Lychee family. As a fully open-source omnimodal large model (OLM), it substantially advances Lychee's Uni-MoE series in language-centric multimodal understanding, reasoning, and generating. Based on the dense LLM, we build Uni-MoE-2.0-Omni from scratch through three core contributions: dynamic-capacity Mixture-of-Experts (MoE) design, a progressive training strategy enhanced with an iterative reinforcement strategy, and a carefully curated multimodal data matching technique. It is capable of omnimodal understanding, as well as generating images, text, and speech. Architecturally, our new MoE framework balances computational efficiency and capability for 10 cross-modal inputs using shared, routed, and null experts, while our Omni-Modality 3D RoPE ensures spatio-temporal cross-modality alignment in the self-attention layer. For training, following cross-modal pretraining, we use a progressive supervised fine-tuning strategy that activates modality-specific experts and is enhanced by balanced data composition and an iterative GSPO-DPO method to stabilise RL training and improve reasoning. Data-wise, the base model, trained on approximately 75B tokens of open-source multimodal data, is equipped with special speech and image generation tokens, allowing it to learn these generative tasks by conditioning its outputs on linguistic cues. Extensive evaluation across 85 benchmarks demonstrates that our model achieves SOTA or highly competitive performance against leading OLMs, surpassing Qwen2.5-Omni (trained with 1.2T tokens) on over 50 of 76 benchmarks. Key strengths include video understanding (+7% avg. of 8), omnimodallity understanding (+7% avg. of 4), and audiovisual reasoning (+4%). It also advances long-form speech processing (reducing WER by 4.2%) and leads in low-level image processing and controllable generation across 5 metrics.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "47 pages,10 Figures, Project Website: https://idealistxy.github.io/Uni-MoE-v2.github.io/ Codes: https://github.com/HITsz-TMG/Uni-MoE",
    "pdf_url": "https://arxiv.org/pdf/2511.12609v2",
    "published_date": "2025-11-16 14:10:55 UTC",
    "updated_date": "2025-11-23 09:18:13 UTC"
  },
  {
    "arxiv_id": "2511.21702v1",
    "title": "CSV-Decode: Certifiable Sub-Vocabulary Decoding for Efficient Large Language Model Inference",
    "authors": [
      "Dong Liu",
      "Yanxuan Yu",
      "Ben Lengerich"
    ],
    "abstract": "Large language models face significant computational bottlenecks during inference due to the expensive output layer computation over large vocabularies. We present CSV-Decode, a novel approach that uses geometric upper bounds to construct small sub-vocabularies for each decoding step, enabling efficient sparse computation while maintaining dual correctness guarantees: exact top-$k$ certification and $\\varepsilon$-certified softmax approximations. Our method clusters vocabulary embeddings offline and uses centroid-plus-radius bounds to identify which tokens can be safely omitted from computation. We provide a complete system implementation with sparse GEMV kernels, multi-GPU sharding, and CUDA Graph optimization. Experimental results demonstrate significant speedup over full vocabulary decoding while maintaining distributional guarantees and low fallback rates. Our code implementation available at \\href{https://github.com/FastLM/CSV-Decode}{https://github.com/FastLM/CSV-Decode}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.21702v1",
    "published_date": "2025-11-16 14:02:41 UTC",
    "updated_date": "2025-11-16 14:02:41 UTC"
  },
  {
    "arxiv_id": "2511.12603v1",
    "title": "PID-controlled Langevin Dynamics for Faster Sampling of Generative Models",
    "authors": [
      "Hongyi Chen",
      "Jianhai Shu",
      "Jingtao Ding",
      "Yong Li",
      "Xiao-Ping Zhang"
    ],
    "abstract": "Langevin dynamics sampling suffers from extremely low generation speed, fundamentally limited by numerous fine-grained iterations to converge to the target distribution. We introduce PID-controlled Langevin Dynamics (PIDLD), a novel sampling acceleration algorithm that reinterprets the sampling process using control-theoretic principles. By treating energy gradients as feedback signals, PIDLD combines historical gradients (the integral term) and gradient trends (the derivative term) to efficiently traverse energy landscapes and adaptively stabilize, thereby significantly reducing the number of iterations required to produce high-quality samples. Our approach requires no additional training, datasets, or prior information, making it immediately integrable with any Langevin-based method. Extensive experiments across image generation and reasoning tasks demonstrate that PIDLD achieves higher quality with fewer steps, making Langevin-based generative models more practical for efficiency-critical applications. The implementation can be found at \\href{https://github.com/tsinghua-fib-lab/PIDLD}{https://github.com/tsinghua-fib-lab/PIDLD}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025 poster paper",
    "pdf_url": "https://arxiv.org/pdf/2511.12603v1",
    "published_date": "2025-11-16 13:59:43 UTC",
    "updated_date": "2025-11-16 13:59:43 UTC"
  },
  {
    "arxiv_id": "2511.12601v1",
    "title": "Symmetry-Aware Graph Metanetwork Autoencoders: Model Merging through Parameter Canonicalization",
    "authors": [
      "Odysseas Boufalis",
      "Jorge Carrasco-Pollo",
      "Joshua Rosenthal",
      "Eduardo Terres-Caballero",
      "Alejandro García-Castellanos"
    ],
    "abstract": "Neural network parameterizations exhibit inherent symmetries that yield multiple equivalent minima within the loss landscape. Scale Graph Metanetworks (ScaleGMNs) explicitly leverage these symmetries by proposing an architecture equivariant to both permutation and parameter scaling transformations. Previous work by Ainsworth et al. (2023) addressed permutation symmetries through a computationally intensive combinatorial assignment problem, demonstrating that leveraging permutation symmetries alone can map networks into a shared loss basin. In this work, we extend their approach by also incorporating scaling symmetries, presenting an autoencoder framework utilizing ScaleGMNs as invariant encoders. Experimental results demonstrate that our method aligns Implicit Neural Representations (INRs) and Convolutional Neural Networks (CNNs) under both permutation and scaling symmetries without explicitly solving the assignment problem. This approach ensures that similar networks naturally converge within the same basin, facilitating model merging, i.e., smooth linear interpolation while avoiding regions of high loss. The code is publicly available on our GitHub repository.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12601v1",
    "published_date": "2025-11-16 13:57:50 UTC",
    "updated_date": "2025-11-16 13:57:50 UTC"
  },
  {
    "arxiv_id": "2511.12596v1",
    "title": "Group-Aware Reinforcement Learning for Output Diversity in Large Language Models",
    "authors": [
      "Oron Anschel",
      "Alon Shoshan",
      "Adam Botach",
      "Shunit Haviv Hakimi",
      "Asaf Gendler",
      "Emanuel Ben Baruch",
      "Nadav Bhonker",
      "Igor Kviatkovsky",
      "Manoj Aggarwal",
      "Gerard Medioni"
    ],
    "abstract": "Large Language Models (LLMs) often suffer from mode collapse, repeatedly generating the same few completions even when many valid answers exist, limiting their diversity across a wide range of tasks. We introduce Group-Aware Policy Optimization (GAPO), a simple extension of the recent and popular Group Relative Policy Optimization (GRPO) that computes rewards over the group as a whole. GAPO enables learning from the group-level properties such as diversity and coverage. We demonstrate GAPO using a frequency-aware reward function that encourages uniform sampling over valid LLM completions, and show that GAPO-trained models produce valid and more diverse model responses. Beyond this setup, GAPO generalizes to open-ended prompts and improves response diversity without compromising accuracy on standard LLM benchmarks (GSM8K, MATH, HumanEval, MMLU-Pro). Our code will be made publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Main 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.12596v1",
    "published_date": "2025-11-16 13:42:55 UTC",
    "updated_date": "2025-11-16 13:42:55 UTC"
  },
  {
    "arxiv_id": "2511.12592v1",
    "title": "Knowledge is Overrated: A zero-knowledge machine learning and cryptographic hashing-based framework for verifiable, low latency inference at the LHC",
    "authors": [
      "Pratik Jawahar",
      "Caterina Doglioni",
      "Maurizio Pierini"
    ],
    "abstract": "Low latency event-selection (trigger) algorithms are essential components of Large Hadron Collider (LHC) operation. Modern machine learning (ML) models have shown great offline performance as classifiers and could improve trigger performance, thereby improving downstream physics analyses. However, inference on such large models does not satisfy the $40\\text{MHz}$ online latency constraint at the LHC. In this work, we propose \\texttt{PHAZE}, a novel framework built on cryptographic techniques like hashing and zero-knowledge machine learning (zkML) to achieve low latency inference, via a certifiable, early-exit mechanism from an arbitrarily large baseline model. We lay the foundations for such a framework to achieve nanosecond-order latency and discuss its inherent advantages, such as built-in anomaly detection, within the scope of LHC triggers, as well as its potential to enable a dynamic low-level trigger in the future.",
    "categories": [
      "hep-ex",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "hep-ex",
    "comment": "ML4PS NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.12592v1",
    "published_date": "2025-11-16 13:31:35 UTC",
    "updated_date": "2025-11-16 13:31:35 UTC"
  },
  {
    "arxiv_id": "2511.12590v2",
    "title": "Fine-Grained Representation for Lane Topology Reasoning",
    "authors": [
      "Guoqing Xu",
      "Yiheng Li",
      "Yang Yang"
    ],
    "abstract": "Precise modeling of lane topology is essential for autonomous driving, as it directly impacts navigation and control decisions. Existing methods typically represent each lane with a single query and infer topological connectivity based on the similarity between lane queries. However, this kind of design struggles to accurately model complex lane structures, leading to unreliable topology prediction. In this view, we propose a Fine-Grained lane topology reasoning framework (TopoFG). It divides the procedure from bird's-eye-view (BEV) features to topology prediction via fine-grained queries into three phases, i.e., Hierarchical Prior Extractor (HPE), Region-Focused Decoder (RFD), and Robust Boundary-Point Topology Reasoning (RBTR). Specifically, HPE extracts global spatial priors from the BEV mask and local sequential priors from in-lane keypoint sequences to guide subsequent fine-grained query modeling. RFD constructs fine-grained queries by integrating the spatial and sequential priors. It then samples reference points in RoI regions of the mask and applies cross-attention with BEV features to refine the query representations of each lane. RBTR models lane connectivity based on boundary-point query features and further employs a topological denoising strategy to reduce matching ambiguity. By integrating spatial and sequential priors into fine-grained queries and applying a denoising strategy to boundary-point topology reasoning, our method precisely models complex lane structures and delivers trustworthy topology predictions. Extensive experiments on the OpenLane-V2 benchmark demonstrate that TopoFG achieves new state-of-the-art performance, with an OLS of 48.0 on subsetA and 45.4 on subsetB.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.12590v2",
    "published_date": "2025-11-16 13:24:30 UTC",
    "updated_date": "2025-11-18 16:06:07 UTC"
  },
  {
    "arxiv_id": "2511.12579v1",
    "title": "Enhancing Conversational Recommender Systems with Tree-Structured Knowledge and Pretrained Language Models",
    "authors": [
      "Yongwen Ren",
      "Chao Wang",
      "Peng Du",
      "Chuan Qin",
      "Dazhong Shen",
      "Hui Xiong"
    ],
    "abstract": "Recent advances in pretrained language models (PLMs) have significantly improved conversational recommender systems (CRS), enabling more fluent and context-aware interactions. To further enhance accuracy and mitigate hallucination, many methods integrate PLMs with knowledge graphs (KGs), but face key challenges: failing to fully exploit PLM reasoning over graph relationships, indiscriminately incorporating retrieved knowledge without context filtering, and neglecting collaborative preferences in multi-turn dialogues. To this end, we propose PCRS-TKA, a prompt-based framework employing retrieval-augmented generation to integrate PLMs with KGs. PCRS-TKA constructs dialogue-specific knowledge trees from KGs and serializes them into texts, enabling structure-aware reasoning while capturing rich entity semantics. Our approach selectively filters context-relevant knowledge and explicitly models collaborative preferences using specialized supervision signals. A semantic alignment module harmonizes heterogeneous inputs, reducing noise and enhancing accuracy. Extensive experiments demonstrate that PCRS-TKA consistently outperforms all baselines in both recommendation and conversational quality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12579v1",
    "published_date": "2025-11-16 12:44:55 UTC",
    "updated_date": "2025-11-16 12:44:55 UTC"
  },
  {
    "arxiv_id": "2511.12573v1",
    "title": "Mitigating Length Bias in RLHF through a Causal Lens",
    "authors": [
      "Hyeonji Kim",
      "Sujeong Oh",
      "Sanghack Lee"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) is widely used to align large language models (LLMs) with human preferences. However, RLHF-trained reward models often exhibit length bias -- a systematic tendency to favor longer responses by conflating verbosity with quality. We propose a causal framework for analyzing and mitigating length bias in RLHF reward modeling. Central to our approach is a counterfactual data augmentation method that generates response pairs designed to isolate content quality from verbosity. These counterfactual examples are then used to train the reward model, enabling it to assess responses based on content quality independently of verbosity. Specifically, we construct (1) length-divergent pairs with similar content and (2) content-divergent pairs of similar length. Empirical evaluations show that our method reduces length bias in reward assignment and leads to more concise, content-focused outputs from the policy model. These findings demonstrate that the proposed approach effectively reduces length bias and improves the robustness and content sensitivity of reward modeling in RLHF pipelines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12573v1",
    "published_date": "2025-11-16 12:25:10 UTC",
    "updated_date": "2025-11-16 12:25:10 UTC"
  },
  {
    "arxiv_id": "2511.12568v1",
    "title": "Enhancing Machine Learning Model Efficiency through Quantization and Bit Depth Optimization: A Performance Analysis on Healthcare Data",
    "authors": [
      "Mitul Goswami",
      "Romit Chatterjee"
    ],
    "abstract": "This research aims to optimize intricate learning models by implementing quantization and bit-depth optimization techniques. The objective is to significantly cut time complexity while preserving model efficiency, thus addressing the challenge of extended execution times in intricate models. Two medical datasets were utilized as case studies to apply a Logistic Regression (LR) machine learning model. Using efficient quantization and bit depth optimization strategies the input data is downscaled from float64 to float32 and int32. The results demonstrated a significant reduction in time complexity, with only a minimal decrease in model accuracy post-optimization, showcasing the state-of-the-art optimization approach. This comprehensive study concludes that the impact of these optimization techniques varies depending on a set of parameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as Chapter 2 in Intelligent and Smart Computing: Applications to Engineering Problems, Cambridge Scholars Publishing (2025). ISBN: 978-1-0364-5886-7",
    "pdf_url": "https://arxiv.org/pdf/2511.12568v1",
    "published_date": "2025-11-16 12:08:18 UTC",
    "updated_date": "2025-11-16 12:08:18 UTC"
  },
  {
    "arxiv_id": "2511.12563v1",
    "title": "LOBERT: Generative AI Foundation Model for Limit Order Book Messages",
    "authors": [
      "Eljas Linna",
      "Kestutis Baltakys",
      "Alexandros Iosifidis",
      "Juho Kanniainen"
    ],
    "abstract": "Modeling the dynamics of financial Limit Order Books (LOB) at the message level is challenging due to irregular event timing, rapid regime shifts, and the reactions of high-frequency traders to visible order flow. Previous LOB models require cumbersome data representations and lack adaptability outside their original tasks, leading us to introduce LOBERT, a general-purpose encoder-only foundation model for LOB data suitable for downstream fine-tuning. LOBERT adapts the original BERT architecture for LOB data by using a novel tokenization scheme that treats complete multi-dimensional messages as single tokens while retaining continuous representations of price, volume, and time. With these methods, LOBERT achieves leading performance in tasks such as predicting mid-price movements and next messages, while reducing the required context length compared to previous methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submission for NeurIPS 2025 GenAI in Finance Workshop",
    "pdf_url": "https://arxiv.org/pdf/2511.12563v1",
    "published_date": "2025-11-16 11:42:48 UTC",
    "updated_date": "2025-11-16 11:42:48 UTC"
  },
  {
    "arxiv_id": "2511.13785v1",
    "title": "Quantifying Distribution Shift in Traffic Signal Control with Histogram-Based GEH Distance",
    "authors": [
      "Federico Taschin",
      "Ozan K. Tonguz"
    ],
    "abstract": "Traffic signal control algorithms are vulnerable to distribution shift, where performance degrades under traffic conditions that differ from those seen during design or training. This paper introduces a principled approach to quantify distribution shift by representing traffic scenarios as demand histograms and comparing them with a GEH-based distance function. The method is policy-independent, interpretable, and leverages a widely used traffic engineering statistic. We validate the approach on 20 simulated scenarios using both a NEMA actuated controller and a reinforcement learning controller (FRAP++). Results show that larger scenario distances consistently correspond to increased travel time and reduced throughput, with particularly strong explanatory power for learning-based control. Overall, this method can predict performance degradation under distribution shift better than previously published techniques. These findings highlight the utility of the proposed framework for benchmarking, training regime design, and monitoring in adaptive traffic signal control.",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.13785v1",
    "published_date": "2025-11-16 11:05:02 UTC",
    "updated_date": "2025-11-16 11:05:02 UTC"
  },
  {
    "arxiv_id": "2511.13784v1",
    "title": "Temporal Object-Aware Vision Transformer for Few-Shot Video Object Detection",
    "authors": [
      "Yogesh Kumar",
      "Anand Mishra"
    ],
    "abstract": "Few-shot Video Object Detection (FSVOD) addresses the challenge of detecting novel objects in videos with limited labeled examples, overcoming the constraints of traditional detection methods that require extensive training data. This task presents key challenges, including maintaining temporal consistency across frames affected by occlusion and appearance variations, and achieving novel object generalization without relying on complex region proposals, which are often computationally expensive and require task-specific training. Our novel object-aware temporal modeling approach addresses these challenges by incorporating a filtering mechanism that selectively propagates high-confidence object features across frames. This enables efficient feature progression, reduces noise accumulation, and enhances detection accuracy in a few-shot setting. By utilizing few-shot trained detection and classification heads with focused feature propagation, we achieve robust temporal consistency without depending on explicit object tube proposals. Our approach achieves performance gains, with AP improvements of 3.7% (FSVOD-500), 5.3% (FSYTV-40), 4.3% (VidOR), and 4.5 (VidVRD) in the 5-shot setting. Further results demonstrate improvements in 1-shot, 3-shot, and 10-shot configurations. We make the code public at: https://github.com/yogesh-iitj/fs-video-vit",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI 2026 Main Track",
    "pdf_url": "https://arxiv.org/pdf/2511.13784v1",
    "published_date": "2025-11-16 09:59:57 UTC",
    "updated_date": "2025-11-16 09:59:57 UTC"
  },
  {
    "arxiv_id": "2511.12529v1",
    "title": "Accepted with Minor Revisions: Value of AI-Assisted Scientific Writing",
    "authors": [
      "Sanchaita Hazra",
      "Doeun Lee",
      "Bodhisattwa Prasad Majumder",
      "Sachin Kumar"
    ],
    "abstract": "Large Language Models have seen expanding application across domains, yet their effectiveness as assistive tools for scientific writing -- an endeavor requiring precision, multimodal synthesis, and domain expertise -- remains insufficiently understood. We examine the potential of LLMs to support domain experts in scientific writing, with a focus on abstract composition. We design an incentivized randomized controlled trial with a hypothetical conference setup where participants with relevant expertise are split into an author and reviewer pool. Inspired by methods in behavioral science, our novel incentive structure encourages authors to edit the provided abstracts to an acceptable quality for a peer-reviewed submission. Our 2x2 between-subject design expands into two dimensions: the implicit source of the provided abstract and the disclosure of it. We find authors make most edits when editing human-written abstracts compared to AI-generated abstracts without source attribution, often guided by higher perceived readability in AI generation. Upon disclosure of source information, the volume of edits converges in both source treatments. Reviewer decisions remain unaffected by the source of the abstract, but bear a significant correlation with the number of edits made. Careful stylistic edits, especially in the case of AI-generated abstracts, in the presence of source information, improve the chance of acceptance. We find that AI-generated abstracts hold potential to reach comparable levels of acceptability to human-written ones with minimal revision, and that perceptions of AI authorship, rather than objective quality, drive much of the observed editing behavior. Our findings reverberate the significance of source disclosure in collaborative scientific writing.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12529v1",
    "published_date": "2025-11-16 09:49:01 UTC",
    "updated_date": "2025-11-16 09:49:01 UTC"
  },
  {
    "arxiv_id": "2511.12523v1",
    "title": "Perturbing Best Responses in Zero-Sum Games",
    "authors": [
      "Adam Dziwoki",
      "Rostislav Horcik"
    ],
    "abstract": "This paper investigates the impact of perturbations on the best-response-based algorithms approximating Nash equilibria in zero-sum games, namely Double Oracle and Fictitious Play. More precisely, we assume that the oracle computing the best responses perturbs the utilities before selecting the best response. We show that using such an oracle reduces the number of iterations for both algorithms. For some cases, suitable perturbations ensure the expected number of iterations is logarithmic. Although the utility perturbation is computationally demanding as it requires iterating through all pure strategies, we demonstrate that one can efficiently perturb the utilities in games where pure strategies have further inner structure.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "Accepted to AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.12523v1",
    "published_date": "2025-11-16 09:30:15 UTC",
    "updated_date": "2025-11-16 09:30:15 UTC"
  },
  {
    "arxiv_id": "2511.12497v1",
    "title": "SGuard-v1: Safety Guardrail for Large Language Models",
    "authors": [
      "JoonHo Lee",
      "HyeonMin Cho",
      "Jaewoong Yun",
      "Hyunjae Lee",
      "JunKyu Lee",
      "Juree Seok"
    ],
    "abstract": "We present SGuard-v1, a lightweight safety guardrail for Large Language Models (LLMs), which comprises two specialized models to detect harmful content and screen adversarial prompts in human-AI conversational settings. The first component, ContentFilter, is trained to identify safety risks in LLM prompts and responses in accordance with the MLCommons hazard taxonomy, a comprehensive framework for trust and safety assessment of AI. The second component, JailbreakFilter, is trained with a carefully designed curriculum over integrated datasets and findings from prior work on adversarial prompting, covering 60 major attack types while mitigating false-unsafe classification. SGuard-v1 is built on the 2B-parameter Granite-3.3-2B-Instruct model that supports 12 languages. We curate approximately 1.4 million training instances from both collected and synthesized data and perform instruction tuning on the base model, distributing the curated data across the two component according to their designated functions. Through extensive evaluation on public and proprietary safety benchmarks, SGuard-v1 achieves state-of-the-art safety performance while remaining lightweight, thereby reducing deployment overhead. SGuard-v1 also improves interpretability for downstream use by providing multi-class safety predictions and their binary confidence scores. We release the SGuard-v1 under the Apache-2.0 License to enable further research and practical deployment in AI safety.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical Report",
    "pdf_url": "https://arxiv.org/pdf/2511.12497v1",
    "published_date": "2025-11-16 08:15:54 UTC",
    "updated_date": "2025-11-16 08:15:54 UTC"
  },
  {
    "arxiv_id": "2511.12494v1",
    "title": "Towards Better IncomLDL: We Are Unaware of Hidden Labels in Advance",
    "authors": [
      "Jiecheng Jiang",
      "Jiawei Tang",
      "Jiahao Jiang",
      "Hui Liu",
      "Junhui Hou",
      "Yuheng Jia"
    ],
    "abstract": "Label distribution learning (LDL) is a novel paradigm that describe the samples by label distribution of a sample. However, acquiring LDL dataset is costly and time-consuming, which leads to the birth of incomplete label distribution learning (IncomLDL). All the previous IncomLDL methods set the description degrees of \"missing\" labels in an instance to 0, but remains those of other labels unchanged. This setting is unrealistic because when certain labels are missing, the degrees of the remaining labels will increase accordingly. We fix this unrealistic setting in IncomLDL and raise a new problem: LDL with hidden labels (HidLDL), which aims to recover a complete label distribution from a real-world incomplete label distribution where certain labels in an instance are omitted during annotation. To solve this challenging problem, we discover the significance of proportional information of the observed labels and capture it by an innovative constraint to utilize it during the optimization process. We simultaneously use local feature similarity and the global low-rank structure to reveal the mysterious veil of hidden labels. Moreover, we theoretically give the recovery bound of our method, proving the feasibility of our method in learning from hidden labels. Extensive recovery and predictive experiments on various datasets prove the superiority of our method to state-of-the-art LDL and IncomLDL methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12494v1",
    "published_date": "2025-11-16 08:10:26 UTC",
    "updated_date": "2025-11-16 08:10:26 UTC"
  },
  {
    "arxiv_id": "2511.12491v1",
    "title": "Uncover and Unlearn Nuisances: Agnostic Fully Test-Time Adaptation",
    "authors": [
      "Ponhvoan Srey",
      "Yaxin Shi",
      "Hangwei Qian",
      "Jing Li",
      "Ivor W. Tsang"
    ],
    "abstract": "Fully Test-Time Adaptation (FTTA) addresses domain shifts without access to source data and training protocols of the pre-trained models. Traditional strategies that align source and target feature distributions are infeasible in FTTA due to the absence of training data and unpredictable target domains. In this work, we exploit a dual perspective on FTTA, and propose Agnostic FTTA (AFTTA) as a novel formulation that enables the usage of off-the-shelf domain transformations during test-time to enable direct generalization to unforeseeable target data. To address this, we develop an uncover-and-unlearn approach. First, we uncover potential unwanted shifts between source and target domains by simulating them through predefined mappings and consider them as nuisances. Then, during test-time prediction, the model is enforced to unlearn these nuisances by regularizing the consequent shifts in latent representations and label predictions. Specifically, a mutual information-based criterion is devised and applied to guide nuisances unlearning in the feature space and encourage confident and consistent prediction in label space. Our proposed approach explicitly addresses agnostic domain shifts, enabling superior model generalization under FTTA constraints. Extensive experiments on various tasks, involving corruption and style shifts, demonstrate that our method consistently outperforms existing approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.12491v1",
    "published_date": "2025-11-16 08:01:50 UTC",
    "updated_date": "2025-11-16 08:01:50 UTC"
  },
  {
    "arxiv_id": "2511.12487v1",
    "title": "Evolving Prompts for Toxicity Search in Large Language Models",
    "authors": [
      "Onkar Shelar",
      "Travis Desell"
    ],
    "abstract": "Large Language Models remain vulnerable to adversarial prompts that elicit toxic content even after safety alignment. We present ToxSearch, a black-box evolutionary framework that tests model safety by evolving prompts in a synchronous steady-state loop. The system employs a diverse set of operators, including lexical substitutions, negation, back-translation, paraphrasing, and two semantic crossover operators, while a moderation oracle provides fitness guidance. Operator-level analysis shows heterogeneous behavior: lexical substitutions offer the best yield-variance trade-off, semantic-similarity crossover acts as a precise low-throughput inserter, and global rewrites exhibit high variance with elevated refusal costs. Using elite prompts evolved on LLaMA 3.1 8B, we observe practically meaningful but attenuated cross-model transfer, with toxicity roughly halving on most targets, smaller LLaMA 3.2 variants showing the strongest resistance, and some cross-architecture models retaining higher toxicity. These results suggest that small, controllable perturbations are effective vehicles for systematic red-teaming and that defenses should anticipate cross-model reuse of adversarial prompts rather than focusing only on single-model hardening.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.NE",
    "comment": "pre-print",
    "pdf_url": "https://arxiv.org/pdf/2511.12487v1",
    "published_date": "2025-11-16 07:47:31 UTC",
    "updated_date": "2025-11-16 07:47:31 UTC"
  },
  {
    "arxiv_id": "2511.12485v1",
    "title": "ARCHE: A Novel Task to Evaluate LLMs on Latent Reasoning Chain Extraction",
    "authors": [
      "Pengze Li",
      "Jiaqi Liu",
      "Junchi Yu",
      "Lihao Liu",
      "Mingyu Ding",
      "Wanli Ouyang",
      "Shixiang Tang",
      "Xi Chen"
    ],
    "abstract": "Large language models (LLMs) are increasingly used in scientific domains. While they can produce reasoning-like content via methods such as chain-of-thought prompting, these outputs are typically unstructured and informal, obscuring whether models truly understand the fundamental reasoning paradigms that underpin scientific inference. To address this, we introduce a novel task named Latent Reasoning Chain Extraction (ARCHE), in which models must decompose complex reasoning arguments into combinations of standard reasoning paradigms in the form of a Reasoning Logic Tree (RLT). In RLT, all reasoning steps are explicitly categorized as one of three variants of Peirce's fundamental inference modes: deduction, induction, or abduction. To facilitate this task, we release ARCHE Bench, a new benchmark derived from 70 Nature Communications articles, including more than 1,900 references and 38,000 viewpoints. We propose two logic-aware evaluation metrics: Entity Coverage (EC) for content completeness and Reasoning Edge Accuracy (REA) for step-by-step logical validity. Evaluations on 10 leading LLMs on ARCHE Bench reveal that models exhibit a trade-off between REA and EC, and none are yet able to extract a complete and standard reasoning chain. These findings highlight a substantial gap between the abilities of current reasoning models and the rigor required for scientific argumentation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.12485v1",
    "published_date": "2025-11-16 07:37:09 UTC",
    "updated_date": "2025-11-16 07:37:09 UTC"
  },
  {
    "arxiv_id": "2511.12484v1",
    "title": "One Request, Multiple Experts: LLM Orchestrates Domain Specific Models via Adaptive Task Routing",
    "authors": [
      "Xu Yang",
      "Chenhui Lin",
      "Haotian Liu",
      "Qi Wang",
      "Yue Yang",
      "Wenchuan Wu"
    ],
    "abstract": "With the integration of massive distributed energy resources and the widespread participation of novel market entities, the operation of active distribution networks (ADNs) is progressively evolving into a complex multi-scenario, multi-objective problem. Although expert engineers have developed numerous domain specific models (DSMs) to address distinct technical problems, mastering, integrating, and orchestrating these heterogeneous DSMs still entail considerable overhead for ADN operators. Therefore, an intelligent approach is urgently required to unify these DSMs and enable efficient coordination. To address this challenge, this paper proposes the ADN-Agent architecture, which leverages a general large language model (LLM) to coordinate multiple DSMs, enabling adaptive intent recognition, task decomposition, and DSM invocation. Within the ADN-Agent, we design a novel communication mechanism that provides a unified and flexible interface for diverse heterogeneous DSMs. Finally, for some language-intensive subtasks, we propose an automated training pipeline for fine-tuning small language models, thereby effectively enhancing the overall problem-solving capability of the system. Comprehensive comparisons and ablation experiments validate the efficacy of the proposed method and demonstrate that the ADN-Agent architecture outperforms existing LLM application paradigms.",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12484v1",
    "published_date": "2025-11-16 07:36:49 UTC",
    "updated_date": "2025-11-16 07:36:49 UTC"
  },
  {
    "arxiv_id": "2511.12480v1",
    "title": "MaskAnyNet: Rethinking Masked Image Regions as Valuable Information in Supervised Learning",
    "authors": [
      "Jingshan Hong",
      "Haigen Hu",
      "Huihuang Zhang",
      "Qianwei Zhou",
      "Zhao Li"
    ],
    "abstract": "In supervised learning, traditional image masking faces two key issues: (i) discarded pixels are underutilized, leading to a loss of valuable contextual information; (ii) masking may remove small or critical features, especially in fine-grained tasks. In contrast, masked image modeling (MIM) has demonstrated that masked regions can be reconstructed from partial input, revealing that even incomplete data can exhibit strong contextual consistency with the original image. This highlights the potential of masked regions as sources of semantic diversity. Motivated by this, we revisit the image masking approach, proposing to treat masked content as auxiliary knowledge rather than ignored. Based on this, we propose MaskAnyNet, which combines masking with a relearning mechanism to exploit both visible and masked information. It can be easily extended to any model with an additional branch to jointly learn from the recomposed masked region. This approach leverages the semantic diversity of the masked regions to enrich features and preserve fine-grained details. Experiments on CNN and Transformer backbones show consistent gains across multiple benchmarks. Further analysis confirms that the proposed method improves semantic diversity through the reuse of masked content.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12480v1",
    "published_date": "2025-11-16 07:11:33 UTC",
    "updated_date": "2025-11-16 07:11:33 UTC"
  },
  {
    "arxiv_id": "2511.12472v1",
    "title": "Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing",
    "authors": [
      "Mengying Wang",
      "Chenhui Ma",
      "Ao Jiao",
      "Tuo Liang",
      "Pengjun Lu",
      "Shrinidhi Hegde",
      "Yu Yin",
      "Evren Gurkan-Cavusoglu",
      "Yinghui Wu"
    ],
    "abstract": "Large Language Models (LLMs) have greatly advanced knowledge graph question answering (KGQA), yet existing systems are typically optimized for returning highly relevant but predictable answers. A missing yet desired capacity is to exploit LLMs to suggest surprise and novel (\"serendipitious\") answers. In this paper, we formally define the serendipity-aware KGQA task and propose the SerenQA framework to evaluate LLMs' ability to uncover unexpected insights in scientific KGQA tasks. SerenQA includes a rigorous serendipity metric based on relevance, novelty, and surprise, along with an expert-annotated benchmark derived from the Clinical Knowledge Graph, focused on drug repurposing. Additionally, it features a structured evaluation pipeline encompassing three subtasks: knowledge retrieval, subgraph reasoning, and serendipity exploration. Our experiments reveal that while state-of-the-art LLMs perform well on retrieval, they still struggle to identify genuinely surprising and valuable discoveries, underscoring a significant room for future improvements. Our curated resources and extended version are released at: https://cwru-db-group.github.io/serenQA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The 40th AAAI Conference on Artificial Intelligence (AAAI-26)",
    "pdf_url": "https://arxiv.org/pdf/2511.12472v1",
    "published_date": "2025-11-16 06:19:53 UTC",
    "updated_date": "2025-11-16 06:19:53 UTC"
  },
  {
    "arxiv_id": "2511.17585v2",
    "title": "PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for Multimodal Sentiment Analysis",
    "authors": [
      "Kang He",
      "Boyu Chen",
      "Yuzhe Ding",
      "Fei Li",
      "Chong Teng",
      "Donghong Ji"
    ],
    "abstract": "Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by integrating textual, acoustic, and visual signals. Although multimodal fusion is designed to leverage cross-modal complementarity, real-world scenarios often exhibit modality competition: dominant modalities tend to overshadow weaker ones, leading to suboptimal performance. In this paper, we propose PaSE, a novel Prototype-aligned Calibration and Shapley-optimized Equilibrium framework, which enhances collaboration while explicitly mitigating modality competition. PaSE first applies Prototype-guided Calibration Learning (PCL) to refine unimodal representations and align them through an Entropic Optimal Transport mechanism that ensures semantic consistency. To further stabilize optimization, we introduce a Dual-Phase Optimization strategy. A prototype-gated fusion module is first used to extract shared representations, followed by Shapley-based Gradient Modulation (SGM), which adaptively adjusts gradients according to the contribution of each modality. Extensive experiments on IEMOCAP, MOSI, and MOSEI confirm that PaSE achieves the superior performance and effectively alleviates modality competition.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.17585v2",
    "published_date": "2025-11-16 05:31:11 UTC",
    "updated_date": "2025-11-25 07:18:32 UTC"
  },
  {
    "arxiv_id": "2511.17584v1",
    "title": "LLM-Powered Text-Attributed Graph Anomaly Detection via Retrieval-Augmented Reasoning",
    "authors": [
      "Haoyan Xu",
      "Ruizhi Qian",
      "Zhengtao Yao",
      "Ziyi Liu",
      "Li Li",
      "Yuqi Li",
      "Yanshu Li",
      "Wenqing Zheng",
      "Daniele Rosa",
      "Daniel Barcklow",
      "Senthil Kumar",
      "Jieyu Zhao",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection on attributed graphs plays an essential role in applications such as fraud detection, intrusion monitoring, and misinformation analysis. However, text-attributed graphs (TAGs), in which node information is expressed in natural language, remain underexplored, largely due to the absence of standardized benchmark datasets. In this work, we introduce TAG-AD, a comprehensive benchmark for anomaly node detection on TAGs. TAG-AD leverages large language models (LLMs) to generate realistic anomalous node texts directly in the raw text space, producing anomalies that are semantically coherent yet contextually inconsistent and thus more reflective of real-world irregularities. In addition, TAG-AD incorporates multiple other anomaly types, enabling thorough and reproducible evaluation of graph anomaly detection (GAD) methods. With these datasets, we further benchmark existing unsupervised GNN-based GAD methods as well as zero-shot LLMs for GAD.\n  As part of our zero-shot detection setup, we propose a retrieval-augmented generation (RAG)-assisted, LLM-based zero-shot anomaly detection framework. The framework mitigates reliance on brittle, hand-crafted prompts by constructing a global anomaly knowledge base and distilling it into reusable analysis frameworks. Our experimental results reveal a clear division of strengths: LLMs are particularly effective at detecting contextual anomalies, whereas GNN-based methods remain superior for structural anomaly detection. Moreover, RAG-assisted prompting achieves performance comparable to human-designed prompts while eliminating manual prompt engineering, underscoring the practical value of our RAG-assisted zero-shot LLM anomaly detection framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.17584v1",
    "published_date": "2025-11-16 05:21:14 UTC",
    "updated_date": "2025-11-16 05:21:14 UTC"
  },
  {
    "arxiv_id": "2511.12460v1",
    "title": "Personality-guided Public-Private Domain Disentangled Hypergraph-Former Network for Multimodal Depression Detection",
    "authors": [
      "Changzeng Fu",
      "Shiwen Zhao",
      "Yunze Zhang",
      "Zhongquan Jian",
      "Shiqi Zhao",
      "Chaoran Liu"
    ],
    "abstract": "Depression represents a global mental health challenge requiring efficient and reliable automated detection methods. Current Transformer- or Graph Neural Networks (GNNs)-based multimodal depression detection methods face significant challenges in modeling individual differences and cross-modal temporal dependencies across diverse behavioral contexts. Therefore, we propose P$^3$HF (Personality-guided Public-Private Domain Disentangled Hypergraph-Former Network) with three key innovations: (1) personality-guided representation learning using LLMs to transform discrete individual features into contextual descriptions for personalized encoding; (2) Hypergraph-Former architecture modeling high-order cross-modal temporal relationships; (3) event-level domain disentanglement with contrastive learning for improved generalization across behavioral contexts. Experiments on MPDD-Young dataset show P$^3$HF achieves around 10\\% improvement on accuracy and weighted F1 for binary and ternary depression classification task over existing methods. Extensive ablation studies validate the independent contribution of each architectural component, confirming that personality-guided representation learning and high-order hypergraph reasoning are both essential for generating robust, individual-aware depression-related representations. The code is released at https://github.com/hacilab/P3HF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2026 accepted",
    "pdf_url": "https://arxiv.org/pdf/2511.12460v1",
    "published_date": "2025-11-16 05:14:37 UTC",
    "updated_date": "2025-11-16 05:14:37 UTC"
  },
  {
    "arxiv_id": "2511.12449v1",
    "title": "MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding",
    "authors": [
      "Zhanheng Nie",
      "Chenghan Fu",
      "Daoze Zhang",
      "Junxian Wu",
      "Wanxian Guan",
      "Pengjie Wang",
      "Jian Xu",
      "Bo Zheng"
    ],
    "abstract": "The rapid growth of e-commerce calls for multimodal models that comprehend rich visual and textual product information. Although recent multimodal large language models (MLLMs) for product understanding exhibit strong capability in representation learning for e-commerce, they still face three challenges: (i) the modality imbalance induced by modality mixed training; (ii) underutilization of the intrinsic alignment relationships among visual and textual information within a product; and (iii) limited handling of noise in e-commerce multimodal data. To address these, we propose MOON2.0, a dynamic modality-balanced multimodal representation learning framework for e-commerce product understanding. MOON2.0 comprises: (1) a Modality-driven Mixture-of-Experts (MoE) module that adaptively processes input samples by their modality composition, enabling Multimodal Joint Learning to mitigate the modality imbalance; (2) a Dual-level Alignment method to better leverage semantic alignment properties inside individual products; and (3) an MLLM-based Image-text Co-augmentation strategy that integrates textual enrichment with visual expansion, coupled with Dynamic Sample Filtering to improve training data quality. We further introduce MBE2.0, a co-augmented multimodal representation benchmark for e-commerce representation learning and evaluation. Experiments show that MOON2.0 delivers state-of-the-art zero-shot performance on MBE2.0 and multiple public datasets. Furthermore, attention-based heatmap visualization provides qualitative evidence of improved multimodal alignment of MOON2.0.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.12449v1",
    "published_date": "2025-11-16 04:29:35 UTC",
    "updated_date": "2025-11-16 04:29:35 UTC"
  },
  {
    "arxiv_id": "2511.12448v1",
    "title": "SeedAIchemy: LLM-Driven Seed Corpus Generation for Fuzzing",
    "authors": [
      "Aidan Wen",
      "Norah A. Alzahrani",
      "Jingzhi Jiang",
      "Andrew Joe",
      "Karen Shieh",
      "Andy Zhang",
      "Basel Alomair",
      "David Wagner"
    ],
    "abstract": "We introduce SeedAIchemy, an automated LLM-driven corpus generation tool that makes it easier for developers to implement fuzzing effectively. SeedAIchemy consists of five modules which implement different approaches at collecting publicly available files from the internet. Four of the five modules use large language model (LLM) workflows to construct search terms designed to maximize corpus quality. Corpora generated by SeedAIchemy perform significantly better than a naive corpus and similarly to a manually-curated corpus on a diverse range of target programs and libraries.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12448v1",
    "published_date": "2025-11-16 04:24:03 UTC",
    "updated_date": "2025-11-16 04:24:03 UTC"
  },
  {
    "arxiv_id": "2511.12442v1",
    "title": "Global-Lens Transformers: Adaptive Token Mixing for Dynamic Link Prediction",
    "authors": [
      "Tao Zou",
      "Chengfeng Wu",
      "Tianxi Liao",
      "Junchen Ye",
      "Bowen Du"
    ],
    "abstract": "Dynamic graph learning plays a pivotal role in modeling evolving relationships over time, especially for temporal link prediction tasks in domains such as traffic systems, social networks, and recommendation platforms. While Transformer-based models have demonstrated strong performance by capturing long-range temporal dependencies, their reliance on self-attention results in quadratic complexity with respect to sequence length, limiting scalability on high-frequency or large-scale graphs. In this work, we revisit the necessity of self-attention in dynamic graph modeling. Inspired by recent findings that attribute the success of Transformers more to their architectural design than attention itself, we propose GLFormer, a novel attention-free Transformer-style framework for dynamic graphs. GLFormer introduces an adaptive token mixer that performs context-aware local aggregation based on interaction order and time intervals. To capture long-term dependencies, we further design a hierarchical aggregation module that expands the temporal receptive field by stacking local token mixers across layers. Experiments on six widely-used dynamic graph benchmarks show that GLFormer achieves SOTA performance, which reveals that attention-free architectures can match or surpass Transformer baselines in dynamic graph settings with significantly improved efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.12442v1",
    "published_date": "2025-11-16 04:05:56 UTC",
    "updated_date": "2025-11-16 04:05:56 UTC"
  },
  {
    "arxiv_id": "2511.12439v2",
    "title": "Multi-agent Self-triage System with Medical Flowcharts",
    "authors": [
      "Yujia Liu",
      "Sophia Yu",
      "Hongyue Jin",
      "Jessica Wen",
      "Alexander Qian",
      "Terrence Lee",
      "Mattheus Ramsis",
      "Gi Won Choi",
      "Lianhui Qin",
      "Xin Liu",
      "Edward J. Wang"
    ],
    "abstract": "Online health resources and large language models (LLMs) are increasingly used as a first point of contact for medical decision-making, yet their reliability in healthcare remains limited by low accuracy, lack of transparency, and susceptibility to unverified information. We introduce a proof-of-concept conversational self-triage system that guides LLMs with 100 clinically validated flowcharts from the American Medical Association, providing a structured and auditable framework for patient decision support. The system leverages a multi-agent framework consisting of a retrieval agent, a decision agent, and a chat agent to identify the most relevant flowchart, interpret patient responses, and deliver personalized, patient-friendly recommendations, respectively. Performance was evaluated at scale using synthetic datasets of simulated conversations. The system achieved 95.29% top-3 accuracy in flowchart retrieval (N=2,000) and 99.10% accuracy in flowchart navigation across varied conversational styles and conditions (N=37,200). By combining the flexibility of free-text interaction with the rigor of standardized clinical protocols, this approach demonstrates the feasibility of transparent, accurate, and generalizable AI-assisted self-triage, with potential to support informed patient decision-making while improving healthcare resource utilization.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12439v2",
    "published_date": "2025-11-16 03:48:22 UTC",
    "updated_date": "2025-12-28 02:55:19 UTC"
  },
  {
    "arxiv_id": "2511.12438v1",
    "title": "Real-Time Drivers' Drowsiness Detection and Analysis through Deep Learning",
    "authors": [
      "ANK Zaman",
      "Prosenjit Chatterjee",
      "Rajat Sharma"
    ],
    "abstract": "A long road trip is fun for drivers. However, a long drive for days can be tedious for a driver to accommodate stringent deadlines to reach distant destinations. Such a scenario forces drivers to drive extra miles, utilizing extra hours daily without sufficient rest and breaks. Once a driver undergoes such a scenario, it occasionally triggers drowsiness during driving. Drowsiness in driving can be life-threatening to any individual and can affect other drivers' safety; therefore, a real-time detection system is needed. To identify fatigued facial characteristics in drivers and trigger the alarm immediately, this research develops a real-time driver drowsiness detection system utilizing deep convolutional neural networks (DCNNs) and OpenCV.Our proposed and implemented model takes real- time facial images of a driver using a live camera and utilizes a Python-based library named OpenCV to examine the facial images for facial landmarks like sufficient eye openings and yawn-like mouth movements. The DCNNs framework then gathers the data and utilizes a per-trained model to detect the drowsiness of a driver using facial landmarks. If the driver is identified as drowsy, the system issues a continuous alert in real time, embedded in the Smart Car technology.By potentially saving innocent lives on the roadways, the proposed technique offers a non-invasive, inexpensive, and cost-effective way to identify drowsiness. Our proposed and implemented DCNNs embedded drowsiness detection model successfully react with NTHU-DDD dataset and Yawn-Eye-Dataset with drowsiness detection classification accuracy of 99.6% and 97% respectively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12438v1",
    "published_date": "2025-11-16 03:39:17 UTC",
    "updated_date": "2025-11-16 03:39:17 UTC"
  },
  {
    "arxiv_id": "2511.13782v1",
    "title": "Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models",
    "authors": [
      "Xiaoxing Lian",
      "Aidong Yang",
      "Jun Zhu",
      "Peng Wang",
      "Yue Zhang"
    ],
    "abstract": "Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages,a detail and effective benchmark for spatial reasoning",
    "pdf_url": "https://arxiv.org/pdf/2511.13782v1",
    "published_date": "2025-11-16 03:09:55 UTC",
    "updated_date": "2025-11-16 03:09:55 UTC"
  },
  {
    "arxiv_id": "2511.12422v1",
    "title": "MFI-ResNet: Efficient ResNet Architecture Optimization via MeanFlow Compression and Selective Incubation",
    "authors": [
      "Nuolin Sun",
      "Linyuan Wang",
      "Haonan Wei",
      "Lei Li",
      "Bin Yan"
    ],
    "abstract": "ResNet has achieved tremendous success in computer vision through its residual connection mechanism. ResNet can be viewed as a discretized form of ordinary differential equations (ODEs). From this perspective, the multiple residual blocks within a single ResNet stage essentially perform multi-step discrete iterations of the feature transformation for that stage. The recently proposed flow matching model, MeanFlow, enables one-step generative modeling by learning the mean velocity field to transform distributions. Inspired by this, we propose MeanFlow-Incubated ResNet (MFI-ResNet), which employs a compression-expansion strategy to jointly improve parameter efficiency and discriminative performance. In the compression phase, we simplify the multi-layer structure within each ResNet stage to one or two MeanFlow modules to construct a lightweight meta model. In the expansion phase, we apply a selective incubation strategy to the first three stages, expanding them to match the residual block configuration of the baseline ResNet model, while keeping the last stage in MeanFlow form, and fine-tune the incubated model. Experimental results show that on CIFAR-10 and CIFAR-100 datasets, MFI-ResNet achieves remarkable parameter efficiency, reducing parameters by 46.28% and 45.59% compared to ResNet-50, while still improving accuracy by 0.23% and 0.17%, respectively. This demonstrates that generative flow-fields can effectively characterize the feature transformation process in ResNet, providing a new perspective for understanding the relationship between generative modeling and discriminative learning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12422v1",
    "published_date": "2025-11-16 02:33:50 UTC",
    "updated_date": "2025-11-16 02:33:50 UTC"
  },
  {
    "arxiv_id": "2511.13779v1",
    "title": "Semantic Multiplexing",
    "authors": [
      "Mohammad Abdi",
      "Francesca Meneghello",
      "Francesco Restuccia"
    ],
    "abstract": "Mobile devices increasingly require the parallel execution of several computing tasks offloaded at the wireless edge. Existing communication systems only support parallel transmissions at the bit level, which fundamentally limits the number of tasks that can be concurrently processed. To address this bottleneck, this paper introduces the new concept of Semantic Multiplexing. Our approach shifts stream multiplexing from bits to tasks by merging multiple task-related compressed representations into a single semantic representation. As such, Semantic Multiplexing can multiplex more tasks than the number of physical channels without adding antennas or widening bandwidth by extending the effective degrees of freedom at the semantic layer, without contradicting Shannon capacity rules. We have prototyped Semantic Multiplexing on an experimental testbed with Jetson Orin Nano and millimeter-wave software-defined radios and tested its performance on image classification and sentiment analysis while comparing to several existing baselines in semantic communications. Our experiments demonstrate that Semantic Multiplexing allows jointly processing multiple tasks at the semantic level while maintaining sufficient task accuracy. For example, image classification accuracy drops by less than 4% when increasing from 2 to 8 the number of tasks multiplexed over a 4$\\times$4 channel. Semantic Multiplexing reduces latency, energy consumption, and communication load respectively by up to 8$\\times$, 25$\\times$, and 54$\\times$ compared to the baselines while keeping comparable performance. We pledge to publicly share the complete software codebase and the collected datasets for reproducibility.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.NI",
      "eess.IV"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.13779v1",
    "published_date": "2025-11-16 01:14:14 UTC",
    "updated_date": "2025-11-16 01:14:14 UTC"
  },
  {
    "arxiv_id": "2511.12409v1",
    "title": "Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario",
    "authors": [
      "Dhanesh Ramachandram",
      "Anne Loefler",
      "Surain Roberts",
      "Amol Verma",
      "Maia Norman",
      "Fahad Razak",
      "Conrad Pow",
      "Charles de Mestral"
    ],
    "abstract": "Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12409v1",
    "published_date": "2025-11-16 01:07:57 UTC",
    "updated_date": "2025-11-16 01:07:57 UTC"
  },
  {
    "arxiv_id": "2511.12404v1",
    "title": "SynthGuard: An Open Platform for Detecting AI-Generated Multimedia with Multimodal LLMs",
    "authors": [
      "Shail Desai",
      "Aditya Pawar",
      "Li Lin",
      "Xin Wang",
      "Shu Hu"
    ],
    "abstract": "Artificial Intelligence (AI) has made it possible for anyone to create images, audio, and video with unprecedented ease, enriching education, communication, and creative expression. At the same time, the rapid rise of AI-generated media has introduced serious risks, including misinformation, identity misuse, and the erosion of public trust as synthetic content becomes increasingly indistinguishable from real media. Although deepfake detection has advanced, many existing tools remain closed-source, limited in modality, or lacking transparency and educational value, making it difficult for users to understand how detection decisions are made. To address these gaps, we introduce SynthGuard, an open, user-friendly platform for detecting and analyzing AI-generated multimedia using both traditional detectors and multimodal large language models (MLLMs). SynthGuard provides explainable inference, unified image and audio support, and an interactive interface designed to make forensic analysis accessible to researchers, educators, and the public. The SynthGuard platform is available at: https://in-engr-nova.it.purdue.edu/",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12404v1",
    "published_date": "2025-11-16 00:50:24 UTC",
    "updated_date": "2025-11-16 00:50:24 UTC"
  },
  {
    "arxiv_id": "2511.12400v1",
    "title": "MSLoRA: Multi-Scale Low-Rank Adaptation via Attention Reweighting",
    "authors": [
      "Xu Yang",
      "Gady Agam"
    ],
    "abstract": "We introduce MSLoRA, a backbone-agnostic, parameter-efficient adapter that reweights feature responses rather\n  than re-tuning the underlying backbone. Existing low-rank adaptation methods are mostly confined to vision\n  transformers (ViTs) and struggle to generalize across architectures. MSLoRA unifies adaptation for both convolutional neural networks (CNNs) and\n  ViTs by combining a low-rank linear projection with a multi-scale nonlinear transformation that jointly\n  modulates spatial and channel attention. The two components are fused through pointwise multiplication and\n  a residual connection, yielding a lightweight module that shifts feature attention while keeping pretrained\n  weights frozen.\n  Extensive experiments demonstrate that MSLoRA consistently improves transfer performance on classification,\n  detection, and segmentation tasks with roughly less than 5\\% of backbone parameters.\n  The design further enables stable optimization, fast convergence, and strong cross-architecture\n  generalization. By reweighting rather than re-tuning, MSLoRA provides a simple and universal approach\n  for efficient adaptation of frozen vision backbones.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.12400v1",
    "published_date": "2025-11-16 00:35:37 UTC",
    "updated_date": "2025-11-16 00:35:37 UTC"
  },
  {
    "arxiv_id": "2511.16690v2",
    "title": "AI Text Detectors and the Misclassification of Slightly Polished Arabic Text",
    "authors": [
      "Saleh Almohaimeed",
      "Saad Almohaimeed",
      "Mousa Jari",
      "Khaled A. Alobaid",
      "Fahad Alotaibi"
    ],
    "abstract": "Many AI detection models have been developed to counter the presence of articles created by artificial intelligence (AI). However, if a human-authored article is slightly polished by AI, a shift will occur in the borderline decision of these AI detection models, leading them to consider it as AI-generated article. This misclassification may result in falsely accusing authors of AI plagiarism and harm the credibility of AI detectors. In English, some efforts were made to meet this challenge, but not in Arabic. In this paper, we generated two datasets. The first dataset contains 800 Arabic articles, half AI-generated and half human-authored. We used it to evaluate 14 Large Language models (LLMs) and commercial AI detectors to assess their ability in distinguishing between human-authored and AI-generated articles. The best 8 models were chosen to act as detectors for our primary concern, which is whether they would consider slightly polished human-authored text as AI-generated. The second dataset, Ar-APT, contains 400 Arabic human-authored articles polished by 10 LLMs using 4 polishing settings, totaling 16400 samples. We use it to evaluate the 8 nominated models and determine whether slight polishing will affect their performance. The results reveal that all AI detectors incorrectly attribute a significant number of articles to AI. The best performing LLM, Claude-4 Sonnet, achieved 83.51\\%, its performance decreased to 57.63\\% for articles slightly polished by LLaMA-3. Whereas the best performing commercial model, originality.AI, achieves 92\\% accuracy, dropped to 12\\% for articles slightly polished by Mistral or Gemma-3.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "(Submitted) Journal of Big Data",
    "pdf_url": "https://arxiv.org/pdf/2511.16690v2",
    "published_date": "2025-11-16 00:15:40 UTC",
    "updated_date": "2025-12-02 11:16:50 UTC"
  }
]