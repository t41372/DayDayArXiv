{
  "date": "2024-06-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-06 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习的创新应用，包括大型语言模型（LLMs）的优化、强化学习的安全性、多模态图像生成以及物理模拟等主题，令人印象深刻的文章有 Google DeepMind 的 CLRS-Text 基准和涉及 LLM 鲁棒性的研究，而知名学者如 Thomas L. Griffiths 和 Petar Veličković 的作品则突显了理论深度。\n\n### 重点论文讨论\n我挑选了今天论文中的核心部分，先聊那些具有高影响力、涉及知名机构或潜在话题度的文章（如 LLM 优化、鲁棒性提升和基准数据集），并快速掠过一些较 niche 或技术细节较重的论文。以下按主题归类，突出主要贡献。\n\n#### LLM 优化与鲁棒性\n- **Reflective Policy Optimization** (英文标题: Reflective Policy Optimization)  \n  这篇论文提出了一种新型 on-policy 强化学习方法，通过结合过去和未来状态信息优化策略，提升了样本效率和收敛速度。主要贡献是理论证明了策略性能的单调提升，并在实验中展示了在复杂环境中超越传统方法的潜力。\n\n- **Improving Alignment and Robustness with Circuit Breakers** (英文标题: Improving Alignment and Robustness with Circuit Breakers)  \n  作者包括 Dan Hendrycks 和 Matt Fredrikson，论文引入“电路断路器”机制来控制有害输出，显著提升了 LLM 的鲁棒性和安全性。发现通过直接干预表示层，能在多模态任务中抵抗攻击，同时保持实用性。\n\n- **Scaling and evaluating sparse autoencoders** (英文标题: Scaling and evaluating sparse autoencoders)  \n  OpenAI 团队的作品，探索了稀疏自编码器的扩展性，展示了它们在 LLM 表示学习中的潜力。关键发现是模型在保持高效性的同时，能提取可解释特征，提升了 AI 的透明度。\n\n- **Semantically Diverse Language Generation for Uncertainty Estimation in Language Models** (英文标题: Semantically Diverse Language Generation for Uncertainty Estimation in Language Models)  \n  这篇快速掠过，论文使用扩散模型量化 LLM 的不确定性，主要贡献是改进了文本生成质量，但其实际影响不如上述鲁棒性方法显著。\n\n#### 多模态和图像处理\n- **Improving Geo-diversity of Generated Images with Contextualized Vendi Score Guidance** (英文标题: Improving Geo-diversity of Generated Images with Contextualized Vendi Score Guidance)  \n  论文提出 c-VSG 方法，提升了文本到图像模型的地理多样性，通过引导扩散模型生成更真实的区域变异图像。主要发现是它在保持图像质量的同时，减少了模型偏差。\n\n- **DiffuSyn Bench: Evaluating Vision-Language Models on Real-World Complexities with Diffusion-Generated Synthetic Benchmarks** (英文标题: DiffuSyn Bench: Evaluating Vision-Language Models on Real-World Complexities with Diffusion-Generated Synthetic Benchmarks)  \n  这篇创建了新基准数据集，用于评估视觉语言模型的真实世界鲁棒性。贡献在于自动生成合成数据对，提升了模型在复杂场景下的性能评估。\n\n- **GenAI Arena: An Open Evaluation Platform for Generative Models** (英文标题: GenAI Arena: An Open Evaluation Platform for Generative Models)  \n  论文构建了开源平台 GenAI-Arena，用于评估图像和视频生成模型，通过用户反馈和数据分析优化模型排名。主要发现是现有多模态模型在视觉评估上仍有不足。\n\n#### 强化学习与物理模拟\n- **FLUID-LLM: Learning Computational Fluid Dynamics with Spatiotemporal-aware Large Language Models** (英文标题: FLUID-LLM: Learning Computational Fluid Dynamics with Spatiotemporal-aware Large Language Models)  \n  作者包括 Pietro Liò，论文将 LLM 与时空编码结合，预测流体动力学，显著提升了复杂几何模拟的准确性。发现它在标准基准上表现出色，桥接了 NLP 和物理模拟的差距。\n\n- **ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories** (英文标题: ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories)  \n  论文使用扩散模型生成虚拟轨迹，加速在线强化学习训练。主要贡献是提高了数据效率，在实验中超越了传统方法。\n\n#### 基准数据集与评估\n- **NATURAL PLAN: Benchmarking LLMs on Natural Language Planning** (英文标题: NATURAL PLAN: Benchmarking LLMs on Natural Language Planning)  \n  Google DeepMind 的作品，引入新基准评估 LLM 在任务规划中的性能。发现当前模型在复杂规划任务上表现不佳，强调了 LLM 改进的必要性。\n\n- **MLVU: Benchmarking Multi-task Long Video Understanding** (英文标题: MLVU: Benchmarking Multi-task Long Video Understanding)  \n  论文提出多任务长视频理解基准，评估 LLM 在视频处理中的能力。关键发现是模型在长序列上易出错，提供了新方向。\n\n其他论文如一些特定领域的图像生成或量子计算（如 \"Quantum Implicit Neural Representations\"）虽然有技术创新，但影响力较小，我这里快速掠过，仅提及其核心如量子模型在信号表示上的优势，而不展开讨论。总体而言，今天的论文突显了 AI 模型在鲁棒性、泛化和多模态融合上的进展，但也暴露了实际应用中的挑战。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2406.04553v2",
      "title": "Better Late Than Never: Formulating and Benchmarking Recommendation Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyu Lai",
        "Sheng Zhou",
        "Zhimeng Jiang",
        "Qiaoyu Tan",
        "Yuanchen Bei",
        "Jiawei Chen",
        "Ningyu Zhang",
        "Jiajun Bu"
      ],
      "abstract": "Recommendation systems play a pivotal role in suggesting items to users based\non their preferences. However, in online platforms, these systems inevitably\noffer unsuitable recommendations due to limited model capacity, poor data\nquality, or evolving user interests. Enhancing user experience necessitates\nefficiently rectify such unsuitable recommendation behaviors. This paper\nintroduces a novel and significant task termed recommendation editing, which\nfocuses on modifying known and unsuitable recommendation behaviors.\nSpecifically, this task aims to adjust the recommendation model to eliminate\nknown unsuitable items without accessing training data or retraining the model.\nWe formally define the problem of recommendation editing with three primary\nobjectives: strict rectification, collaborative rectification, and concentrated\nrectification. Three evaluation metrics are developed to quantitatively assess\nthe achievement of each objective. We present a straightforward yet effective\nbenchmark for recommendation editing using novel Editing Bayesian Personalized\nRanking Loss. To demonstrate the effectiveness of the proposed method, we\nestablish a comprehensive benchmark that incorporates various methods from\nrelated fields. Codebase is available at\nhttps://github.com/cycl2018/Recommendation-Editing.",
      "tldr_zh": "这篇论文引入了“recommendation editing”任务，旨在修正推荐系统中已知的不合适推荐行为，例如由于模型容量有限、数据质量差或用户兴趣变化而导致的问题，而无需访问训练数据或重新训练模型。任务定义了三个主要目标：strict rectification（严格修正）、collaborative rectification（协作修正）和 concentrated rectification（集中修正），并开发了相应的评估指标来量化这些目标的实现。作者提出了一种基于 Editing Bayesian Personalized Ranking Loss 的简单而有效的基准方法，并建立了一个全面基准，整合了相关领域的各种方法，以证明其有效性。代码库可在 https://github.com/cycl2018/Recommendation-Editing 获取。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04553v2",
      "published_date": "2024-06-06 23:44:33 UTC",
      "updated_date": "2024-10-28 07:38:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:47:07.660756"
    },
    {
      "arxiv_id": "2406.04551v2",
      "title": "Improving Geo-diversity of Generated Images with Contextualized Vendi Score Guidance",
      "title_zh": "使用情境化 Vendi Score 指导改善生成图像的地理多样性",
      "authors": [
        "Reyhane Askari Hemmat",
        "Melissa Hall",
        "Alicia Sun",
        "Candace Ross",
        "Michal Drozdzal",
        "Adriana Romero-Soriano"
      ],
      "abstract": "With the growing popularity of text-to-image generative models, there has\nbeen increasing focus on understanding their risks and biases. Recent work has\nfound that state-of-the-art models struggle to depict everyday objects with the\ntrue diversity of the real world and have notable gaps between geographic\nregions. In this work, we aim to increase the diversity of generated images of\ncommon objects such that per-region variations are representative of the real\nworld. We introduce an inference time intervention, contextualized Vendi Score\nGuidance (c-VSG), that guides the backwards steps of latent diffusion models to\nincrease the diversity of a sample as compared to a \"memory bank\" of previously\ngenerated images while constraining the amount of variation within that of an\nexemplar set of real-world contextualizing images. We evaluate c-VSG with two\ngeographically representative datasets and find that it substantially increases\nthe diversity of generated images, both for the worst performing regions and on\naverage, while simultaneously maintaining or improving image quality and\nconsistency. Additionally, qualitative analyses reveal that diversity of\ngenerated images is significantly improved, including along the lines of\nreductive region portrayals present in the original model. We hope that this\nwork is a step towards text-to-image generative models that reflect the true\ngeographic diversity of the world.",
      "tldr_zh": "本文研究了文本到图像生成模型（text-to-image generative models）在地理多样性方面的不足，旨在通过增加生成图像的多样性来更好地反映真实世界的区域变异。作者引入了 contextualized Vendi Score Guidance (c-VSG)，一种推理时的干预技术，用于指导潜在扩散模型（latent diffusion models）的逆向步骤，利用“记忆银行”和真实图像集来提升样本多样性，同时控制变化范围。实验在两个地理代表性数据集上显示，c-VSG 显著提高了生成图像的多样性，尤其在表现较差的区域，同时维持或改善了图像质量和一致性。定性分析进一步证实，该方法纠正了原模型中对某些区域的简化刻板印象，推动了更真实地理多样性的生成模型发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04551v2",
      "published_date": "2024-06-06 23:35:51 UTC",
      "updated_date": "2024-08-02 16:09:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:47:20.055943"
    },
    {
      "arxiv_id": "2406.04533v1",
      "title": "Rare Class Prediction Model for Smart Industry in Semiconductor Manufacturing",
      "title_zh": "面向智能工业的半导体制造稀有类别预测模型",
      "authors": [
        "Abdelrahman Farrag",
        "Mohammed-Khalil Ghali",
        "Yu Jin"
      ],
      "abstract": "The evolution of industry has enabled the integration of physical and digital\nsystems, facilitating the collection of extensive data on manufacturing\nprocesses. This integration provides a reliable solution for improving process\nquality and managing equipment health. However, data collected from real\nmanufacturing processes often exhibit challenging properties, such as severe\nclass imbalance, high rates of missing values, and noisy features, which hinder\neffective machine learning implementation. In this study, a rare class\nprediction approach is developed for in situ data collected from a smart\nsemiconductor manufacturing process. The primary objective is to build a model\nthat addresses issues of noise and class imbalance, enhancing class separation.\nThe developed approach demonstrated promising results compared to existing\nliterature, which would allow the prediction of new observations that could\ngive insights into future maintenance plans and production quality. The model\nwas evaluated using various performance metrics, with ROC curves showing an AUC\nof 0.95, a precision of 0.66, and a recall of 0.96",
      "tldr_zh": "该研究针对半导体制造过程中的数据挑战（如类不平衡、缺失值和噪声特征），开发了一种稀有类预测模型（Rare Class Prediction Model），旨在提升类分离并改善机器学习应用。该模型通过处理噪声和类不平衡问题，在真实数据上实现了显著性能提升，能够预测新观察值以指导未来维护计划和生产质量。实验结果显示，模型的 ROC 曲线 AUC 为 0.95，精度为 0.66，召回率为 0.96，优于现有文献。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04533v1",
      "published_date": "2024-06-06 22:09:43 UTC",
      "updated_date": "2024-06-06 22:09:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:47:31.168292"
    },
    {
      "arxiv_id": "2406.06611v1",
      "title": "Building Hybrid B-Spline And Neural Network Operators",
      "title_zh": "翻译失败",
      "authors": [
        "Raffaele Romagnoli",
        "Jasmine Ratchford",
        "Mark H. Klein"
      ],
      "abstract": "Control systems are indispensable for ensuring the safety of cyber-physical\nsystems (CPS), spanning various domains such as automobiles, airplanes, and\nmissiles. Safeguarding CPS necessitates runtime methodologies that continuously\nmonitor safety-critical conditions and respond in a verifiably safe manner. A\nfundamental aspect of many safety approaches involves predicting the future\nbehavior of systems. However, achieving this requires accurate models that can\noperate in real time. Motivated by DeepONets, we propose a novel strategy that\ncombines the inductive bias of B-splines with data-driven neural networks to\nfacilitate real-time predictions of CPS behavior. We introduce our hybrid\nB-spline neural operator, establishing its capability as a universal\napproximator and providing rigorous bounds on the approximation error. These\nfindings are applicable to a broad class of nonlinear autonomous systems and\nare validated through experimentation on a controlled 6-degree-of-freedom (DOF)\nquadrotor with a 12 dimensional state space. Furthermore, we conduct a\ncomparative analysis of different network architectures, specifically fully\nconnected networks (FCNN) and recurrent neural networks (RNN), to elucidate the\npractical utility and trade-offs associated with each architecture in\nreal-world scenarios.",
      "tldr_zh": "该研究针对网络物理系统(CPS)的安全监控问题，提出了一种结合B-splines归纳偏差与数据驱动神经网络的混合策略，以实现CPS行为的实时预测。该方法引入了混合B-spline神经算子，并证明其作为通用逼近器的能力，同时提供了逼近误差的严格界限，适用于广泛的非线性自治系统。通过实验在6-DOF四旋翼无人机（12维状态空间）上验证，该框架显著提升了预测准确性。最后，比较了全连接网络(FCNN)和循环神经网络(RNN)的性能，讨论了实际应用中的优缺点。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06611v1",
      "published_date": "2024-06-06 21:54:59 UTC",
      "updated_date": "2024-06-06 21:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:47:42.836850"
    },
    {
      "arxiv_id": "2406.04520v1",
      "title": "NATURAL PLAN: Benchmarking LLMs on Natural Language Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Huaixiu Steven Zheng",
        "Swaroop Mishra",
        "Hugh Zhang",
        "Xinyun Chen",
        "Minmin Chen",
        "Azade Nova",
        "Le Hou",
        "Heng-Tze Cheng",
        "Quoc V. Le",
        "Ed H. Chi",
        "Denny Zhou"
      ],
      "abstract": "We introduce NATURAL PLAN, a realistic planning benchmark in natural language\ncontaining 3 key tasks: Trip Planning, Meeting Planning, and Calendar\nScheduling. We focus our evaluation on the planning capabilities of LLMs with\nfull information on the task, by providing outputs from tools such as Google\nFlights, Google Maps, and Google Calendar as contexts to the models. This\neliminates the need for a tool-use environment for evaluating LLMs on Planning.\nWe observe that NATURAL PLAN is a challenging benchmark for state of the art\nmodels. For example, in Trip Planning, GPT-4 and Gemini 1.5 Pro could only\nachieve 31.1% and 34.8% solve rate respectively. We find that model performance\ndrops drastically as the complexity of the problem increases: all models\nperform below 5% when there are 10 cities, highlighting a significant gap in\nplanning in natural language for SoTA LLMs. We also conduct extensive ablation\nstudies on NATURAL PLAN to further shed light on the (in)effectiveness of\napproaches such as self-correction, few-shot generalization, and in-context\nplanning with long-contexts on improving LLM planning.",
      "tldr_zh": "这篇论文引入了 NATURAL PLAN，这是一个现实的自然语言规划基准测试，包含 Trip Planning、Meeting Planning 和 Calendar Scheduling 等三个关键任务，用于评估 LLMs 的规划能力。评估方法通过提供工具输出（如 Google Flights、Google Maps 和 Google Calendar 的上下文）作为完整信息，避免了实际工具使用环境的需求。实验结果显示，当前最先进模型如 GPT-4 和 Gemini 1.5 Pro 在复杂任务上表现不佳，例如 Trip Planning 的解决率仅为 31.1% 和 34.8%，且模型性能随问题复杂度增加而急剧下降（如涉及 10 个城市时低于 5%）。此外，论文进行了广泛的消融研究，揭示了自校正、少样本泛化和长上下文规划等方法的有限有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04520v1",
      "published_date": "2024-06-06 21:27:35 UTC",
      "updated_date": "2024-06-06 21:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:47:55.232794"
    },
    {
      "arxiv_id": "2406.04508v2",
      "title": "OCCAM: Towards Cost-Efficient and Accuracy-Aware Classification Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Dujian Ding",
        "Bicheng Xu",
        "Laks V. S. Lakshmanan"
      ],
      "abstract": "Classification tasks play a fundamental role in various applications,\nspanning domains such as healthcare, natural language processing and computer\nvision. With the growing popularity and capacity of machine learning models,\npeople can easily access trained classifiers as a service online or offline.\nHowever, model use comes with a cost and classifiers of higher capacity (such\nas large foundation models) usually incur higher inference costs. To harness\nthe respective strengths of different classifiers, we propose a principled\napproach, OCCAM, to compute the best classifier assignment strategy over\nclassification queries (termed as the optimal model portfolio) so that the\naggregated accuracy is maximized, under user-specified cost budgets. Our\napproach uses an unbiased and low-variance accuracy estimator and effectively\ncomputes the optimal solution by solving an integer linear programming problem.\nOn a variety of real-world datasets, OCCAM achieves 40% cost reduction with\nlittle to no accuracy drop.",
      "tldr_zh": "该研究针对机器学习分类任务的成本问题，提出OCCAM框架，以实现成本高效且准确感知的分类推理。OCCAM通过计算最佳分类器分配策略（optimal model portfolio），在用户指定的成本预算下最大化聚合准确率，利用无偏、低方差的准确率估计器并求解整数线性规划问题。实验结果显示，在多种真实数据集上，OCCAM实现了40%的成本减少，同时准确率几乎没有下降。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2406.04508v2",
      "published_date": "2024-06-06 21:05:39 UTC",
      "updated_date": "2025-02-25 03:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:48:04.642731"
    },
    {
      "arxiv_id": "2406.18587v1",
      "title": "Nomic Embed Vision: Expanding the Latent Space",
      "title_zh": "Nomic Embed Vision：扩展潜在空间",
      "authors": [
        "Zach Nussbaum",
        "Brandon Duderstadt",
        "Andriy Mulyar"
      ],
      "abstract": "This technical report describes the training of nomic-embed-vision, a highly\nperformant, open-code, open-weights image embedding model that shares the same\nlatent space as nomic-embed-text. Together, nomic-embed-vision and\nnomic-embed-text form the first unified latent space to achieve high\nperformance across vision, language, and multimodal tasks.",
      "tldr_zh": "这篇技术报告介绍了 nomic-embed-vision 的训练，这是一个高性能的开源图像嵌入模型。nomic-embed-vision 与 nomic-embed-text 共享相同的 latent space，从而实现了视觉、语言和多模态任务的统一高性能处理。该模型的开发标志着首个跨模态任务的统一 latent space 框架，为多模态应用提供了更高效的开源解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18587v1",
      "published_date": "2024-06-06 21:02:51 UTC",
      "updated_date": "2024-06-06 21:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:48:17.863718"
    },
    {
      "arxiv_id": "2406.04501v1",
      "title": "FLUID-LLM: Learning Computational Fluid Dynamics with Spatiotemporal-aware Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Max Zhu",
        "Adrián Bazaga",
        "Pietro Liò"
      ],
      "abstract": "Learning computational fluid dynamics (CFD) traditionally relies on\ncomputationally intensive simulations of the Navier-Stokes equations. Recently,\nlarge language models (LLMs) have shown remarkable pattern recognition and\nreasoning abilities in natural language processing (NLP) and computer vision\n(CV). However, these models struggle with the complex geometries inherent in\nfluid dynamics. We introduce FLUID-LLM, a novel framework combining pre-trained\nLLMs with spatiotemporal-aware encoding to predict unsteady fluid dynamics. Our\napproach leverages the temporal autoregressive abilities of LLMs alongside\nspatial-aware layers, bridging the gap between previous CFD prediction methods.\nEvaluations on standard benchmarks reveal significant performance improvements\nacross various fluid datasets. Our results demonstrate that FLUID-LLM\neffectively integrates spatiotemporal information into pre-trained LLMs,\nenhancing CFD task performance.",
      "tldr_zh": "传统计算流体动力学（CFD）依赖于计算密集的Navier-Stokes方程模拟，而大型语言模型（LLMs）虽在自然语言处理（NLP）和计算机视觉（CV）中表现出色，但难以处理流体动力学的复杂几何形状。\n\n本文提出FLUID-LLM框架，通过结合预训练LLMs与时空感知编码，利用LLMs的时间自回归能力和空间感知层，来预测不稳定流体动力学。\n\n实验结果显示，FLUID-LLM在标准基准测试中实现了显著性能提升，并在各种流体数据集上证明了其有效整合时空信息，从而提升CFD任务性能的能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04501v1",
      "published_date": "2024-06-06 20:55:40 UTC",
      "updated_date": "2024-06-06 20:55:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:48:30.710891"
    },
    {
      "arxiv_id": "2406.04496v2",
      "title": "Time Sensitive Knowledge Editing through Efficient Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiou Ge",
        "Ali Mousavi",
        "Edouard Grave",
        "Armand Joulin",
        "Kun Qian",
        "Benjamin Han",
        "Mostafa Arefiyan",
        "Yunyao Li"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capability in\ndifferent tasks and are bringing transformative changes to many domains.\nHowever, keeping the knowledge in LLMs up-to-date remains a challenge once\npretraining is complete. It is thus essential to design effective methods to\nboth update obsolete knowledge and induce new knowledge into LLMs. Existing\nlocate-and-edit knowledge editing (KE) method suffers from two limitations.\nFirst, the post-edit LLMs by such methods generally have poor capability in\nanswering complex queries that require multi-hop reasoning. Second, the long\nrun-time of such locate-and-edit methods to perform knowledge edits make it\ninfeasible for large scale KE in practice. In this paper, we explore\nParameter-Efficient Fine-Tuning (PEFT) techniques as an alternative for KE. We\ncurate a more comprehensive temporal KE dataset with both knowledge update and\nknowledge injection examples for KE performance benchmarking. We further probe\nthe effect of fine-tuning on a range of layers in an LLM for the multi-hop QA\ntask. We find that PEFT performs better than locate-and-edit techniques for\ntime-sensitive knowledge edits.",
      "tldr_zh": "本研究探讨了如何通过 Parameter-Efficient Fine-Tuning (PEFT) 高效更新大语言模型 (LLMs) 的时间敏感知识，以解决现有 locate-and-edit 知识编辑 (KE) 方法在多跳推理任务上表现差和运行时间长的局限性。作者构建了一个更全面的临时 KE 数据集，包括知识更新和注入示例，并分析了在 LLM 不同层上进行 fine-tuning 的影响。实验结果显示，PEFT 在时间敏感知识编辑中优于传统方法，尤其在多跳问答任务中提升了模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 main",
      "pdf_url": "http://arxiv.org/pdf/2406.04496v2",
      "published_date": "2024-06-06 20:41:36 UTC",
      "updated_date": "2024-07-23 00:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:48:42.925141"
    },
    {
      "arxiv_id": "2406.06610v1",
      "title": "Reinterpreting 'the Company a Word Keeps': Towards Explainable and Ontologically Grounded Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Walid S. Saba"
      ],
      "abstract": "We argue that the relative success of large language models (LLMs) is not a\nreflection on the symbolic vs. subsymbolic debate but a reflection on employing\na successful bottom-up strategy of a reverse engineering of language at scale.\nHowever, and due to their subsymbolic nature whatever knowledge these systems\nacquire about language will always be buried in millions of weights none of\nwhich is meaningful on its own, rendering such systems utterly unexplainable.\nFurthermore, and due to their stochastic nature, LLMs will often fail in making\nthe correct inferences in various linguistic contexts that require reasoning in\nintensional, temporal, or modal contexts. To remedy these shortcomings we\nsuggest employing the same successful bottom-up strategy employed in LLMs but\nin a symbolic setting, resulting in explainable, language-agnostic, and\nontologically grounded language models.",
      "tldr_zh": "该论文重新审视大型语言模型（LLMs）的成功，认为其源于大规模的逆向工程语言策略，而非符号化（symbolic）与次符号化（subsymbolic）的争论，但LLMs 由于次符号化本质，导致知识隐藏在数百万权重中，无法解释，且在 intensional、temporal 或 modal 语境中常出错。作者指出，LLMs 的随机性使其在某些语言推理任务中失败。论文建议采用相同的底部向上策略，但置于符号化设置中，开发出可解释的、语言无关的、基于本体论（ontologically grounded）的语言模型，以解决这些缺陷。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2308.14199, arXiv:2306.00017",
      "pdf_url": "http://arxiv.org/pdf/2406.06610v1",
      "published_date": "2024-06-06 20:38:35 UTC",
      "updated_date": "2024-06-06 20:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:48:53.695165"
    },
    {
      "arxiv_id": "2406.04485v4",
      "title": "GenAI Arena: An Open Evaluation Platform for Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dongfu Jiang",
        "Max Ku",
        "Tianle Li",
        "Yuansheng Ni",
        "Shizhuo Sun",
        "Rongqi Fan",
        "Wenhu Chen"
      ],
      "abstract": "Generative AI has made remarkable strides to revolutionize fields such as\nimage and video generation. These advancements are driven by innovative\nalgorithms, architecture, and data. However, the rapid proliferation of\ngenerative models has highlighted a critical gap: the absence of trustworthy\nevaluation metrics. Current automatic assessments such as FID, CLIP, FVD, etc\noften fail to capture the nuanced quality and user satisfaction associated with\ngenerative outputs. This paper proposes an open platform GenAI-Arena to\nevaluate different image and video generative models, where users can actively\nparticipate in evaluating these models. By leveraging collective user feedback\nand votes, GenAI-Arena aims to provide a more democratic and accurate measure\nof model performance. It covers three tasks of text-to-image generation,\ntext-to-video generation, and image editing respectively. Currently, we cover a\ntotal of 35 open-source generative models. GenAI-Arena has been operating for\nseven months, amassing over 9000 votes from the community. We describe our\nplatform, analyze the data, and explain the statistical methods for ranking the\nmodels. To further promote the research in building model-based evaluation\nmetrics, we release a cleaned version of our preference data for the three\ntasks, namely GenAI-Bench. We prompt the existing multi-modal models like\nGemini, and GPT-4o to mimic human voting. We compute the accuracy by comparing\nthe model voting with the human voting to understand their judging abilities.\nOur results show existing multimodal models are still lagging in assessing the\ngenerated visual content, even the best model GPT-4o only achieves an average\naccuracy of 49.19 across the three generative tasks. Open-source MLLMs perform\neven worse due to the lack of instruction-following and reasoning ability in\ncomplex vision scenarios.",
      "tldr_zh": "本论文提出GenAI-Arena，一个开放的评估平台，用于评估生成式AI模型（如图像和视频生成），以弥补现有自动指标（如FID、CLIP、FVD）在捕捉生成质量和用户满意度方面的不足。该平台允许用户通过投票参与评估，涵盖文本到图像生成、文本到视频生成和图像编辑三任务，目前包括35个开源模型，并在七个月内收集了超过9000票数据。研究分析了平台数据并发布了清洗后的偏好数据集GenAI-Bench，同时测试了多模态模型（如Gemini和GPT-4o）模拟人类投票，结果显示这些模型在评估生成内容时准确率较低，GPT-4o的平均准确率仅为49.19%，开源MLLMs表现更差。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages,7 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04485v4",
      "published_date": "2024-06-06 20:15:42 UTC",
      "updated_date": "2024-11-11 06:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:49:11.430195"
    },
    {
      "arxiv_id": "2406.04482v1",
      "title": "Automatic Bug Detection in LLM-Powered Text-Based Games Using LLMs",
      "title_zh": "使用 LLMs 自动检测 LLM 驱动的基于文本游戏中的错误",
      "authors": [
        "Claire Jin",
        "Sudha Rao",
        "Xiangyu Peng",
        "Portia Botchway",
        "Jessica Quaye",
        "Chris Brockett",
        "Bill Dolan"
      ],
      "abstract": "Advancements in large language models (LLMs) are revolutionizing interactive\ngame design, enabling dynamic plotlines and interactions between players and\nnon-player characters (NPCs). However, LLMs may exhibit flaws such as\nhallucinations, forgetfulness, or misinterpretations of prompts, causing\nlogical inconsistencies and unexpected deviations from intended designs.\nAutomated techniques for detecting such game bugs are still lacking. To address\nthis, we propose a systematic LLM-based method for automatically identifying\nsuch bugs from player game logs, eliminating the need for collecting additional\ndata such as post-play surveys. Applied to a text-based game DejaBoom!, our\napproach effectively identifies bugs inherent in LLM-powered interactive games,\nsurpassing unstructured LLM-powered bug-catching methods and filling the gap in\nautomated detection of logical and design flaws.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在文本游戏中的缺陷，如 hallucinations、forgetfulness 和提示误解导致的逻辑不一致，提出了一种基于 LLMs 的系统方法来自动检测 bug。该方法通过分析玩家游戏日志来识别问题，无需收集额外数据如后续调查。在文本游戏 DejaBoom! 的应用中，该方法优于非结构化的 LLM 驱动检测技术，并有效填补了自动识别逻辑和设计缺陷的空白。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in Findings of the Association for\n  Computational Linguistics: ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04482v1",
      "published_date": "2024-06-06 20:11:08 UTC",
      "updated_date": "2024-06-06 20:11:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:49:19.396008"
    },
    {
      "arxiv_id": "2406.04481v1",
      "title": "Optimizing Autonomous Driving for Safety: A Human-Centric Approach with LLM-Enhanced RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Sun",
        "Navid Salami Pargoo",
        "Peter J. Jin",
        "Jorge Ortiz"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is popular in large\nlanguage models (LLMs), whereas traditional Reinforcement Learning (RL) often\nfalls short. Current autonomous driving methods typically utilize either human\nfeedback in machine learning, including RL, or LLMs. Most feedback guides the\ncar agent's learning process (e.g., controlling the car). RLHF is usually\napplied in the fine-tuning step, requiring direct human \"preferences,\" which\nare not commonly used in optimizing autonomous driving models. In this\nresearch, we innovatively combine RLHF and LLMs to enhance autonomous driving\nsafety. Training a model with human guidance from scratch is inefficient. Our\nframework starts with a pre-trained autonomous car agent model and implements\nmultiple human-controlled agents, such as cars and pedestrians, to simulate\nreal-life road environments. The autonomous car model is not directly\ncontrolled by humans. We integrate both physical and physiological feedback to\nfine-tune the model, optimizing this process using LLMs. This multi-agent\ninteractive environment ensures safe, realistic interactions before real-world\napplication. Finally, we will validate our model using data gathered from\nreal-life testbeds located in New Jersey and New York City.",
      "tldr_zh": "这篇论文提出了一种以人为中心的自动驾驶优化方法，将 Reinforcement Learning from Human Feedback (RLHF) 与 Large Language Models (LLMs) 相结合，以提升安全性。框架从预训练的自动驾驶模型开始，通过多代理模拟环境（如人类控制的汽车和行人）整合物理和生理反馈，使用 LLMs 优化细调过程，确保在真实应用前实现安全互动。该方法创新地解决了传统 RL 的不足，并计划在新泽西和纽约市的真实测试床验证其性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04481v1",
      "published_date": "2024-06-06 20:10:34 UTC",
      "updated_date": "2024-06-06 20:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:49:31.476178"
    },
    {
      "arxiv_id": "2406.15451v1",
      "title": "Deep Vision-Based Framework for Coastal Flood Prediction Under Climate Change Impacts and Shoreline Adaptations",
      "title_zh": "基于深度视觉的框架，用于气候变化影响和海岸线适应下的沿海洪水预测",
      "authors": [
        "Areg Karapetyan",
        "Aaron Chung Hin Chow",
        "Samer Madanat"
      ],
      "abstract": "In light of growing threats posed by climate change in general and sea level\nrise (SLR) in particular, the necessity for computationally efficient means to\nestimate and analyze potential coastal flood hazards has become increasingly\npressing. Data-driven supervised learning methods serve as promising candidates\nthat can dramatically expedite the process, thereby eliminating the\ncomputational bottleneck associated with traditional physics-based hydrodynamic\nsimulators. Yet, the development of accurate and reliable coastal flood\nprediction models, especially those based on Deep Learning (DL) techniques, has\nbeen plagued with two major issues: (1) the scarcity of training data and (2)\nthe high-dimensional output required for detailed inundation mapping. To remove\nthis barrier, we present a systematic framework for training high-fidelity Deep\nVision-based coastal flood prediction models in low-data settings. We test the\nproposed workflow on different existing vision models, including a fully\ntransformer-based architecture and a Convolutional Neural Network (CNN) with\nadditive attention gates. Additionally, we introduce a deep CNN architecture\ntailored specifically to the coastal flood prediction problem at hand. The\nmodel was designed with a particular focus on its compactness so as to cater to\nresource-constrained scenarios and accessibility aspects. The performance of\nthe developed DL models is validated against commonly adopted geostatistical\nregression methods and traditional Machine Learning (ML) approaches,\ndemonstrating substantial improvement in prediction quality. Lastly, we round\nup the contributions by providing a meticulously curated dataset of synthetic\nflood inundation maps of Abu Dhabi's coast produced with a physics-based\nhydrodynamic simulator, which can serve as a benchmark for evaluating future\ncoastal flood prediction models.",
      "tldr_zh": "该论文提出一个基于 Deep Vision 的系统框架，用于在气候变化影响（如海平面上升，SLR）和海岸线适应条件下预测沿海洪水风险。该框架针对数据稀缺和高维输出挑战，设计了高效的 Deep Learning (DL) 模型，包括全 transformer 架构、带有注意力门的 Convolutional Neural Network (CNN)，以及一个专为资源受限场景优化的紧凑型 deep CNN 架构。通过与传统 geostatistical regression 和 Machine Learning (ML) 方法比较，DL 模型展示了显著的预测质量提升。最后，论文提供了一个精心策划的合成洪水淹没地图数据集，作为未来沿海洪水预测模型的基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15451v1",
      "published_date": "2024-06-06 19:54:34 UTC",
      "updated_date": "2024-06-06 19:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:49:44.044695"
    },
    {
      "arxiv_id": "2406.04470v2",
      "title": "DiffuSyn Bench: Evaluating Vision-Language Models on Real-World Complexities with Diffusion-Generated Synthetic Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Haokun Zhou",
        "Yipeng Hong"
      ],
      "abstract": "This study assesses the ability of Large Vision-Language Models (LVLMs) to\ndifferentiate between AI-generated and human-generated images. It introduces a\nnew automated benchmark construction method for this evaluation. The experiment\ncompared common LVLMs with human participants using a mixed dataset of AI and\nhuman-created images. Results showed that LVLMs could distinguish between the\nimage types to some extent but exhibited a rightward bias, and perform\nsignificantly worse compared to humans. To build on these findings, we\ndeveloped an automated benchmark construction process using AI. This process\ninvolved topic retrieval, narrative script generation, error embedding, and\nimage generation, creating a diverse set of text-image pairs with intentional\nerrors. We validated our method through constructing two caparable benchmarks.\nThis study highlights the strengths and weaknesses of LVLMs in real-world\nunderstanding and advances benchmark construction techniques, providing a\nscalable and automatic approach for AI model evaluation.",
      "tldr_zh": "本研究评估了大型视觉语言模型 (LVLMs) 区分 AI 生成图像与人类生成图像的能力，并引入了一种基于扩散模型的自动基准构建方法。实验使用混合数据集比较 LVLMs 与人类的表现，结果显示 LVLMs 能部分识别图像类型，但存在右向偏差，且显著逊于人类表现。研究进一步开发了自动基准构建过程，包括主题检索、叙述脚本生成、错误嵌入和图像生成，创建了多样化的文本-图像对，并通过构建两个可比较基准验证了该方法。该工作突出了 LVLMs 在真实世界理解中的优势和劣势，并推进了可扩展的 AI 模型评估技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04470v2",
      "published_date": "2024-06-06 19:50:33 UTC",
      "updated_date": "2024-06-13 16:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:49:56.250112"
    },
    {
      "arxiv_id": "2406.04464v1",
      "title": "On The Importance of Reasoning for Context Retrieval in Repository-Level Code Editing",
      "title_zh": "论推理在仓库级代码编辑中上下文检索的重要性",
      "authors": [
        "Alexander Kovrigin",
        "Aleksandra Eliseeva",
        "Yaroslav Zharov",
        "Timofey Bryksin"
      ],
      "abstract": "Recent advancements in code-fluent Large Language Models (LLMs) enabled the\nresearch on repository-level code editing. In such tasks, the model navigates\nand modifies the entire codebase of a project according to request. Hence, such\ntasks require efficient context retrieval, i.e., navigating vast codebases to\ngather relevant context. Despite the recognized importance of context\nretrieval, existing studies tend to approach repository-level coding tasks in\nan end-to-end manner, rendering the impact of individual components within\nthese complicated systems unclear. In this work, we decouple the task of\ncontext retrieval from the other components of the repository-level code\nediting pipelines. We lay the groundwork to define the strengths and weaknesses\nof this component and the role that reasoning plays in it by conducting\nexperiments that focus solely on context retrieval. We conclude that while the\nreasoning helps to improve the precision of the gathered context, it still\nlacks the ability to identify its sufficiency. We also outline the ultimate\nrole of the specialized tools in the process of context gathering. The code\nsupplementing this paper is available at\nhttps://github.com/JetBrains-Research/ai-agents-code-editing.",
      "tldr_zh": "该研究强调了推理在仓库级代码编辑中上下文检索(Context Retrieval)的重要性，旨在解决Large Language Models (LLMs)处理庞大代码库时的挑战。通过将上下文检索从端到端系统分离，本文通过实验评估了推理对检索精度的影响。结果显示，推理能提升收集上下文的精确性，但仍无法判断其充分性；同时，专门工具在上下文收集过程中发挥关键作用。该工作为未来仓库级代码编辑系统的优化提供了基础。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04464v1",
      "published_date": "2024-06-06 19:44:17 UTC",
      "updated_date": "2024-06-06 19:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:50:07.512590"
    },
    {
      "arxiv_id": "2406.04456v1",
      "title": "Learning Optimal Linear Precoding for Cell-Free Massive MIMO with GNN",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Parlier",
        "Lou Salaün",
        "Hong Yang"
      ],
      "abstract": "We develop a graph neural network (GNN) to compute, within a time budget of 1\nto 2 milliseconds required by practical systems, the optimal linear precoder\n(OLP) maximizing the minimal downlink user data rate for a Cell-Free Massive\nMIMO system - a key 6G wireless technology. The state-of-the-art method is a\nbisection search on second order cone programming feasibility test (B-SOCP)\nwhich is a magnitude too slow for practical systems. Our approach relies on\nrepresenting OLP as a node-level prediction task on a graph. We construct a\ngraph that accurately captures the interdependence relation between access\npoints (APs) and user equipments (UEs), and the permutation equivariance of the\nMax-Min problem. Our neural network, named OLP-GNN, is trained on data obtained\nby B-SOCP. We tailor the OLP-GNN size, together with several artful data\npreprocessing and postprocessing methods to meet the runtime requirement. We\nshow by extensive simulations that it achieves near optimal spectral efficiency\nin a range of scenarios with different number of APs and UEs, and for both\nline-of-sight and non-line-of-sight radio propagation environments.",
      "tldr_zh": "本研究提出了一种基于图神经网络 (GNN) 的方法，用于在 Cell-Free Massive MIMO 系统中快速计算最优线性预编码 (OLP)，以最大化最小下行用户数据速率，并满足 1-2 毫秒的实时要求。OLP-GNN 通过构建一个捕捉访问点 (APs) 和用户设备 (UEs) 之间相互依赖关系的图，并结合数据预处理和后处理技术进行训练，利用 B-SOCP 生成的数据来优化 Max-Min 问题。实验结果表明，该模型在不同场景下，包括各种 APs 和 UEs 数量以及视线 (LOS) 和非视线 (NLOS) 传播环境，实现了接近最优的频谱效率。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted in the European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD) 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04456v1",
      "published_date": "2024-06-06 19:29:33 UTC",
      "updated_date": "2024-06-06 19:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:50:21.839000"
    },
    {
      "arxiv_id": "2406.04446v1",
      "title": "Can Language Models Use Forecasting Strategies?",
      "title_zh": "语言模型能使用预测策略吗？",
      "authors": [
        "Sarah Pratt",
        "Seth Blumberg",
        "Pietro Kreitlon Carolino",
        "Meredith Ringel Morris"
      ],
      "abstract": "Advances in deep learning systems have allowed large models to match or\nsurpass human accuracy on a number of skills such as image classification,\nbasic programming, and standardized test taking. As the performance of the most\ncapable models begin to saturate on tasks where humans already achieve high\naccuracy, it becomes necessary to benchmark models on increasingly complex\nabilities. One such task is forecasting the future outcome of events. In this\nwork we describe experiments using a novel dataset of real world events and\nassociated human predictions, an evaluation metric to measure forecasting\nability, and the accuracy of a number of different LLM based forecasting\ndesigns on the provided dataset. Additionally, we analyze the performance of\nthe LLM forecasters against human predictions and find that models still\nstruggle to make accurate predictions about the future. Our follow-up\nexperiments indicate this is likely due to models' tendency to guess that most\nevents are unlikely to occur (which tends to be true for many prediction\ndatasets, but does not reflect actual forecasting abilities). We reflect on\nnext steps for developing a systematic and reliable approach to studying LLM\nforecasting.",
      "tldr_zh": "这篇论文探讨了语言模型（LLMs）是否能有效运用预测策略，特别是在人类已达到高精度的任务上。研究者构建了一个新数据集，包含真实世界事件和人类预测，并设计了评估指标来测试各种LLM-based预测方法。结果显示，LLMs在预测未来事件时准确性低于人类，主要由于模型倾向于判断大多数事件不太可能发生，这反映了其预测能力的局限性。论文呼吁开发更系统可靠的方法来提升LLM的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04446v1",
      "published_date": "2024-06-06 19:01:42 UTC",
      "updated_date": "2024-06-06 19:01:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:50:32.102863"
    },
    {
      "arxiv_id": "2406.06609v2",
      "title": "Mitigating Bias in Dataset Distillation",
      "title_zh": "缓解数据集蒸馏中的偏差",
      "authors": [
        "Justin Cui",
        "Ruochen Wang",
        "Yuanhao Xiong",
        "Cho-Jui Hsieh"
      ],
      "abstract": "Dataset Distillation has emerged as a technique for compressing large\ndatasets into smaller synthetic counterparts, facilitating downstream training\ntasks. In this paper, we study the impact of bias inside the original dataset\non the performance of dataset distillation. With a comprehensive empirical\nevaluation on canonical datasets with color, corruption and background biases,\nwe found that color and background biases in the original dataset will be\namplified through the distillation process, resulting in a notable decline in\nthe performance of models trained on the distilled dataset, while corruption\nbias is suppressed through the distillation process. To reduce bias\namplification in dataset distillation, we introduce a simple yet highly\neffective approach based on a sample reweighting scheme utilizing kernel\ndensity estimation. Empirical results on multiple real-world and synthetic\ndatasets demonstrate the effectiveness of the proposed method. Notably, on\nCMNIST with 5% bias-conflict ratio and IPC 50, our method achieves 91.5% test\naccuracy compared to 23.8% from vanilla DM, boosting the performance by 67.7%,\nwhereas applying state-of-the-art debiasing method on the same dataset only\nachieves 53.7% accuracy. Our findings highlight the importance of addressing\nbiases in dataset distillation and provide a promising avenue to address bias\namplification in the process.",
      "tldr_zh": "这篇论文研究了原始数据集中的偏差对 Dataset Distillation 性能的影响，发现颜色和背景偏差在蒸馏过程中会被放大，导致模型性能显著下降，而腐败偏差则被抑制。作者提出了一种简单有效的样本再加权方案，利用 kernel density estimation 来减少偏差放大。实验结果显示，该方法在多个真实和合成数据集上表现出色，例如在 CMNIST 数据集（5% bias-conflict ratio 和 IPC 50）上，测试准确率从 vanilla DM 的 23.8% 提高到 91.5%，比现有最先进去偏方法高出许多。这些发现突出了在 Dataset Distillation 中处理偏差的重要性，并为未来研究提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML",
      "pdf_url": "http://arxiv.org/pdf/2406.06609v2",
      "published_date": "2024-06-06 18:52:28 UTC",
      "updated_date": "2024-07-10 17:58:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:50:44.749183"
    },
    {
      "arxiv_id": "2406.04438v1",
      "title": "TexIm FAST: Text-to-Image Representation for Semantic Similarity Evaluation using Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Wazib Ansar",
        "Saptarsi Goswami",
        "Amlan Chakrabarti"
      ],
      "abstract": "One of the principal objectives of Natural Language Processing (NLP) is to\ngenerate meaningful representations from text. Improving the informativeness of\nthe representations has led to a tremendous rise in the dimensionality and the\nmemory footprint. It leads to a cascading effect amplifying the complexity of\nthe downstream model by increasing its parameters. The available techniques\ncannot be applied to cross-modal applications such as text-to-image. To\nameliorate these issues, a novel Text-to-Image methodology for generating\nfixed-length representations through a self-supervised Variational Auto-Encoder\n(VAE) for semantic evaluation applying transformers (TexIm FAST) has been\nproposed in this paper. The pictorial representations allow oblivious inference\nwhile retaining the linguistic intricacies, and are potent in cross-modal\napplications. TexIm FAST deals with variable-length sequences and generates\nfixed-length representations with over 75% reduced memory footprint. It\nenhances the efficiency of the models for downstream tasks by reducing its\nparameters. The efficacy of TexIm FAST has been extensively analyzed for the\ntask of Semantic Textual Similarity (STS) upon the MSRPC, CNN/ Daily Mail, and\nXSum data-sets. The results demonstrate 6% improvement in accuracy compared to\nthe baseline and showcase its exceptional ability to compare disparate length\nsequences such as a text with its summary.",
      "tldr_zh": "本论文提出了一种名为 TexIm FAST 的新方法，用于生成固定长度的文本到图像表示，以提升 NLP 中的语义相似性评估。TexIm FAST 采用自监督的 Variational Auto-Encoder (VAE) 和 Transformers 处理可变长度的序列，显著减少了 75% 的内存占用，并提高了下游任务的效率。该方法特别适用于跨模态应用，在 Semantic Textual Similarity (STS) 任务上使用 MSRPC、CNN/Daily Mail 和 XSum 数据集进行测试，结果显示准确率比基线模型提高了 6%，尤其擅长比较不同长度的序列如文本和摘要。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 33 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04438v1",
      "published_date": "2024-06-06 18:28:50 UTC",
      "updated_date": "2024-06-06 18:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:50:55.792870"
    },
    {
      "arxiv_id": "2406.04432v1",
      "title": "LipGER: Visually-Conditioned Generative Error Correction for Robust Automatic Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Sreyan Ghosh",
        "Sonal Kumar",
        "Ashish Seth",
        "Purva Chiniya",
        "Utkarsh Tyagi",
        "Ramani Duraiswami",
        "Dinesh Manocha"
      ],
      "abstract": "Visual cues, like lip motion, have been shown to improve the performance of\nAutomatic Speech Recognition (ASR) systems in noisy environments. We propose\nLipGER (Lip Motion aided Generative Error Correction), a novel framework for\nleveraging visual cues for noise-robust ASR. Instead of learning the\ncross-modal correlation between the audio and visual modalities, we make an LLM\nlearn the task of visually-conditioned (generative) ASR error correction.\nSpecifically, we instruct an LLM to predict the transcription from the N-best\nhypotheses generated using ASR beam-search. This is further conditioned on lip\nmotions. This approach addresses key challenges in traditional AVSR learning,\nsuch as the lack of large-scale paired datasets and difficulties in adapting to\nnew domains. We experiment on 4 datasets in various settings and show that\nLipGER improves the Word Error Rate in the range of 1.1%-49.2%. We also release\nLipHyp, a large-scale dataset with hypothesis-transcription pairs that is\nadditionally equipped with lip motion cues to promote further research in this\nspace",
      "tldr_zh": "本研究提出LipGER框架，利用视觉线索（如唇部动作）提升Automatic Speech Recognition (ASR) 在嘈杂环境中的鲁棒性。不同于传统方法，LipGER 指导Large Language Model (LLM) 学习基于视觉条件的生成错误修正任务，即从 ASR beam-search 生成的N-best hypotheses中预测转录，并结合唇动信息，以解决大规模配对数据集缺乏和适应新领域的问题。在4个数据集上的实验显示，LipGER 将Word Error Rate (WER) 改善了1.1%至49.2%。此外，研究团队发布了LipHyp数据集，提供假设-转录配对及唇动线索，促进相关领域的研究。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "InterSpeech 2024. Code and Data: https://github.com/Sreyan88/LipGER",
      "pdf_url": "http://arxiv.org/pdf/2406.04432v1",
      "published_date": "2024-06-06 18:17:59 UTC",
      "updated_date": "2024-06-06 18:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:51:10.386812"
    },
    {
      "arxiv_id": "2406.04428v1",
      "title": "MoralBench: Moral Evaluation of LLMs",
      "title_zh": "MoralBench：LLMs 的道德评估",
      "authors": [
        "Jianchao Ji",
        "Yutong Chen",
        "Mingyu Jin",
        "Wujiang Xu",
        "Wenyue Hua",
        "Yongfeng Zhang"
      ],
      "abstract": "In the rapidly evolving field of artificial intelligence, large language\nmodels (LLMs) have emerged as powerful tools for a myriad of applications, from\nnatural language processing to decision-making support systems. However, as\nthese models become increasingly integrated into societal frameworks, the\nimperative to ensure they operate within ethical and moral boundaries has never\nbeen more critical. This paper introduces a novel benchmark designed to measure\nand compare the moral reasoning capabilities of LLMs. We present the first\ncomprehensive dataset specifically curated to probe the moral dimensions of LLM\noutputs, addressing a wide range of ethical dilemmas and scenarios reflective\nof real-world complexities.\n  The main contribution of this work lies in the development of benchmark\ndatasets and metrics for assessing the moral identity of LLMs, which accounts\nfor nuance, contextual sensitivity, and alignment with human ethical standards.\nOur methodology involves a multi-faceted approach, combining quantitative\nanalysis with qualitative insights from ethics scholars to ensure a thorough\nevaluation of model performance. By applying our benchmark across several\nleading LLMs, we uncover significant variations in moral reasoning capabilities\nof different models. These findings highlight the importance of considering\nmoral reasoning in the development and evaluation of LLMs, as well as the need\nfor ongoing research to address the biases and limitations uncovered in our\nstudy. We publicly release the benchmark at\nhttps://drive.google.com/drive/u/0/folders/1k93YZJserYc2CkqP8d4B3M3sgd3kA8W7\nand also open-source the code of the project at\nhttps://github.com/agiresearch/MoralBench.",
      "tldr_zh": "这篇论文引入了MoralBench，一种创新基准，用于评估大型语言模型(LLMs)的道德推理能力，并开发了首个全面数据集，涵盖各种真实世界的道德困境和场景。研究采用多方面方法，包括定量分析和伦理学学者的定性见解，来衡量LLMs在细微差别、上下文敏感性和人类伦理标准对齐方面的表现。实验结果显示，不同LLMs在道德推理能力上存在显著差异，突出了在模型开发中考虑道德因素以解决偏差和限制的必要性。论文公开了基准数据集和代码，以促进相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04428v1",
      "published_date": "2024-06-06 18:15:01 UTC",
      "updated_date": "2024-06-06 18:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:51:22.928712"
    },
    {
      "arxiv_id": "2406.04426v2",
      "title": "DeTra: A Unified Model for Object Detection and Trajectory Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Casas",
        "Ben Agro",
        "Jiageng Mao",
        "Thomas Gilles",
        "Alexander Cui",
        "Thomas Li",
        "Raquel Urtasun"
      ],
      "abstract": "The tasks of object detection and trajectory forecasting play a crucial role\nin understanding the scene for autonomous driving. These tasks are typically\nexecuted in a cascading manner, making them prone to compounding errors.\nFurthermore, there is usually a very thin interface between the two tasks,\ncreating a lossy information bottleneck. To address these challenges, our\napproach formulates the union of the two tasks as a trajectory refinement\nproblem, where the first pose is the detection (current time), and the\nsubsequent poses are the waypoints of the multiple forecasts (future time). To\ntackle this unified task, we design a refinement transformer that infers the\npresence, pose, and multi-modal future behaviors of objects directly from LiDAR\npoint clouds and high-definition maps. We call this model DeTra, short for\nobject Detection and Trajectory forecasting. In our experiments, we observe\nthat \\ourmodel{} outperforms the state-of-the-art on Argoverse 2 Sensor and\nWaymo Open Dataset by a large margin, across a broad range of metrics. Last but\nnot least, we perform extensive ablation studies that show the value of\nrefinement for this task, that every proposed component contributes positively\nto its performance, and that key design choices were made.",
      "tldr_zh": "该论文提出DeTra，一种统一的模型，将对象检测和轨迹预测任务整合为轨迹精炼问题，以解决传统级联方法中错误积累和信息瓶颈的问题。该模型使用精炼Transformer直接从LiDAR点云和高清地图中推断对象的存在、姿态以及多模态未来行为。实验结果显示，DeTra在Argoverse 2 Sensor和Waymo Open Dataset上大幅超越现有最先进模型，并在广泛的消融研究中证明了其设计组件的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04426v2",
      "published_date": "2024-06-06 18:12:04 UTC",
      "updated_date": "2024-06-13 12:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:51:33.175506"
    },
    {
      "arxiv_id": "2406.06608v6",
      "title": "The Prompt Report: A Systematic Survey of Prompt Engineering Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Sander Schulhoff",
        "Michael Ilie",
        "Nishant Balepur",
        "Konstantine Kahadze",
        "Amanda Liu",
        "Chenglei Si",
        "Yinheng Li",
        "Aayush Gupta",
        "HyoJung Han",
        "Sevien Schulhoff",
        "Pranav Sandeep Dulepet",
        "Saurav Vidyadhara",
        "Dayeon Ki",
        "Sweta Agrawal",
        "Chau Pham",
        "Gerson Kroiz",
        "Feileen Li",
        "Hudson Tao",
        "Ashay Srivastava",
        "Hevander Da Costa",
        "Saloni Gupta",
        "Megan L. Rogers",
        "Inna Goncearenco",
        "Giuseppe Sarli",
        "Igor Galynker",
        "Denis Peskoff",
        "Marine Carpuat",
        "Jules White",
        "Shyamal Anadkat",
        "Alexander Hoyle",
        "Philip Resnik"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) systems are increasingly being\ndeployed across diverse industries and research domains. Developers and\nend-users interact with these systems through the use of prompting and prompt\nengineering. Although prompt engineering is a widely adopted and extensively\nresearched area, it suffers from conflicting terminology and a fragmented\nontological understanding of what constitutes an effective prompt due to its\nrelatively recent emergence. We establish a structured understanding of prompt\nengineering by assembling a taxonomy of prompting techniques and analyzing\ntheir applications. We present a detailed vocabulary of 33 vocabulary terms, a\ntaxonomy of 58 LLM prompting techniques, and 40 techniques for other\nmodalities. Additionally, we provide best practices and guidelines for prompt\nengineering, including advice for prompting state-of-the-art (SOTA) LLMs such\nas ChatGPT. We further present a meta-analysis of the entire literature on\nnatural language prefix-prompting. As a culmination of these efforts, this\npaper presents the most comprehensive survey on prompt engineering to date.",
      "tldr_zh": "这篇论文对提示工程（prompt engineering）进行了系统调查，旨在解决生成式人工智能（GenAI）系统中提示术语冲突和碎片化理解的问题。论文建立了结构化的框架，包括一个包含33个词汇术语的词汇表、58个LLM提示技术的分类，以及40个其他模态的提示技术，同时提供了最佳实践和针对SOTA LLMs如ChatGPT的指导建议。论文还通过对自然语言前缀提示文献的元分析，总结了提示工程的应用和效果，最终呈现了迄今为止最全面的调查成果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06608v6",
      "published_date": "2024-06-06 18:10:11 UTC",
      "updated_date": "2025-02-26 18:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:51:47.360567"
    },
    {
      "arxiv_id": "2406.04413v2",
      "title": "Efficient 3D-Aware Facial Image Editing via Attribute-Specific Prompt Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Amandeep Kumar",
        "Muhammad Awais",
        "Sanath Narayan",
        "Hisham Cholakkal",
        "Salman Khan",
        "Rao Muhammad Anwer"
      ],
      "abstract": "Drawing upon StyleGAN's expressivity and disentangled latent space, existing\n2D approaches employ textual prompting to edit facial images with different\nattributes. In contrast, 3D-aware approaches that generate faces at different\ntarget poses require attribute-specific classifiers, learning separate model\nweights for each attribute, and are not scalable for novel attributes. In this\nwork, we propose an efficient, plug-and-play, 3D-aware face editing framework\nbased on attribute-specific prompt learning, enabling the generation of facial\nimages with controllable attributes across various target poses. To this end,\nwe introduce a text-driven learnable style token-based latent attribute editor\n(LAE). The LAE harnesses a pre-trained vision-language model to find\ntext-guided attribute-specific editing direction in the latent space of any\npre-trained 3D-aware GAN. It utilizes learnable style tokens and style mappers\nto learn and transform this editing direction to 3D latent space. To train LAE\nwith multiple attributes, we use directional contrastive loss and style token\nloss. Furthermore, to ensure view consistency and identity preservation across\ndifferent poses and attributes, we employ several 3D-aware identity and pose\npreservation losses. Our experiments show that our proposed framework generates\nhigh-quality images with 3D awareness and view consistency while maintaining\nattribute-specific features. We demonstrate the effectiveness of our method on\ndifferent facial attributes, including hair color and style, expression, and\nothers.",
      "tldr_zh": "本研究针对现有3D-aware面部图像编辑方法的局限性（如需属性特定分类器和模型权重，无法扩展到新属性），提出了一种高效的即插即用框架，通过属性特定提示学习实现可控属性编辑。框架引入文本驱动的可学习风格标记-based Latent Attribute Editor (LAE)，利用预训练的vision-language模型在3D-aware GAN的潜在空间中找到属性特定编辑方向，并通过风格标记和映射器进行转换，同时采用directional contrastive loss和风格标记损失进行训练。实验结果显示，该方法在各种面部属性（如头发颜色、风格和表情）上生成高质量图像，确保了3D意识、视图一致性和身份保持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV, 2024. Amandeep Kumar and Muhammad Awais are joint\n  first authors. More details are available at\n  https://awaisrauf.github.io/3d_face_editing",
      "pdf_url": "http://arxiv.org/pdf/2406.04413v2",
      "published_date": "2024-06-06 18:01:30 UTC",
      "updated_date": "2024-07-24 10:16:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:51:57.746840"
    },
    {
      "arxiv_id": "2406.04412v2",
      "title": "Spread Preference Annotation: Direct Preference Judgment for Efficient LLM Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Dongyoung Kim",
        "Kimin Lee",
        "Jinwoo Shin",
        "Jaehyung Kim"
      ],
      "abstract": "Aligning large language models (LLMs) with human preferences becomes a key\ncomponent to obtaining state-of-the-art performance, but it yields a huge cost\nto construct a large human-annotated preference dataset. To tackle this\nproblem, we propose a new framework, Spread Preference Annotation with direct\npreference judgment (SPA), that boosts the alignment of LLMs using only a very\nsmall amount of human-annotated preference data. Our key idea is leveraging the\nhuman prior knowledge within the small (seed) data and progressively improving\nthe alignment of LLM, by iteratively generating the responses and learning from\nthem with the self-annotated preference data. To be specific, we propose to\nderive the preference label from the logits of LLM to explicitly extract the\nmodel's inherent preference. Compared to the previous approaches using external\nreward models or implicit in-context learning, we observe that the proposed\napproach is significantly more effective. In addition, we introduce a\nnoise-aware preference learning algorithm to mitigate the risk of low quality\nwithin generated preference data. Our experimental results demonstrate that the\nproposed framework significantly boosts the alignment of LLMs. For example, we\nachieve superior alignment performance on AlpacaEval 2.0 with only 3.3% of the\nground-truth preference labels in the Ultrafeedback data compared to the cases\nusing the entire data or state-of-the-art baselines.",
      "tldr_zh": "本研究提出Spread Preference Annotation (SPA)框架，通过直接偏好判断方法，利用少量人类标注的种子数据来高效对齐大型语言模型(LLMs)，以解决构建大规模偏好数据集的成本问题。SPA的关键机制包括迭代生成响应、从LLMs的logits中显式提取模型内在偏好，并引入噪声感知偏好学习算法，以降低自标注数据质量风险。实验结果显示，该框架在AlpacaEval 2.0上仅使用Ultrafeedback数据的3.3%标签，就显著超过了使用全部数据或最先进基线的对齐性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 Oral Presentation, 22 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.04412v2",
      "published_date": "2024-06-06 18:01:02 UTC",
      "updated_date": "2025-03-04 00:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:52:11.245580"
    },
    {
      "arxiv_id": "2406.04338v3",
      "title": "Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion",
      "title_zh": "Physics3D：通过视频扩散学习 3D 高斯分布的物理属性",
      "authors": [
        "Fangfu Liu",
        "Hanyang Wang",
        "Shunyu Yao",
        "Shengjun Zhang",
        "Jie Zhou",
        "Yueqi Duan"
      ],
      "abstract": "In recent years, there has been rapid development in 3D generation models,\nopening up new possibilities for applications such as simulating the dynamic\nmovements of 3D objects and customizing their behaviors. However, current 3D\ngenerative models tend to focus only on surface features such as color and\nshape, neglecting the inherent physical properties that govern the behavior of\nobjects in the real world. To accurately simulate physics-aligned dynamics, it\nis essential to predict the physical properties of materials and incorporate\nthem into the behavior prediction process. Nonetheless, predicting the diverse\nmaterials of real-world objects is still challenging due to the complex nature\nof their physical attributes. In this paper, we propose \\textbf{Physics3D}, a\nnovel method for learning various physical properties of 3D objects through a\nvideo diffusion model. Our approach involves designing a highly generalizable\nphysical simulation system based on a viscoelastic material model, which\nenables us to simulate a wide range of materials with high-fidelity\ncapabilities. Moreover, we distill the physical priors from a video diffusion\nmodel that contains more understanding of realistic object materials. Extensive\nexperiments demonstrate the effectiveness of our method with both elastic and\nplastic materials. Physics3D shows great potential for bridging the gap between\nthe physical world and virtual neural space, providing a better integration and\napplication of realistic physical principles in virtual environments. Project\npage: https://liuff19.github.io/Physics3D.",
      "tldr_zh": "本文提出 Physics3D 方法，通过视频扩散模型学习 3D Gaussians 的各种物理属性，以解决当前 3D 生成模型忽略物体内在物理特性的问题。该方法设计了一个基于 viscoelastic material model 的通用物理模拟系统，并从视频扩散模型中提取物理先验，实现高保真材料的模拟。实验结果显示，Physics3D 在弹性材料和塑性材料上表现出色，有效桥接了物理世界与虚拟神经空间，促进了真实物理原则在虚拟环境中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://liuff19.github.io/Physics3D",
      "pdf_url": "http://arxiv.org/pdf/2406.04338v3",
      "published_date": "2024-06-06 17:59:47 UTC",
      "updated_date": "2024-06-11 03:36:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:52:21.923694"
    },
    {
      "arxiv_id": "2406.04337v2",
      "title": "Coherent Zero-Shot Visual Instruction Generation",
      "title_zh": "连贯的零样本视觉指令生成",
      "authors": [
        "Quynh Phung",
        "Songwei Ge",
        "Jia-Bin Huang"
      ],
      "abstract": "Despite the advances in text-to-image synthesis, particularly with diffusion\nmodels, generating visual instructions that require consistent representation\nand smooth state transitions of objects across sequential steps remains a\nformidable challenge. This paper introduces a simple, training-free framework\nto tackle the issues, capitalizing on the advancements in diffusion models and\nlarge language models (LLMs). Our approach systematically integrates text\ncomprehension and image generation to ensure visual instructions are visually\nappealing and maintain consistency and accuracy throughout the instruction\nsequence. We validate the effectiveness by testing multi-step instructions and\ncomparing the text alignment and consistency with several baselines. Our\nexperiments show that our approach can visualize coherent and visually pleasing\ninstructions",
      "tldr_zh": "这篇论文提出了一种无需训练的框架，用于生成连贯的零-shot 视觉指令，解决扩散模型在多步序列中对象一致表示和状态过渡的问题。该框架整合扩散模型和大型语言模型 (LLMs)，通过系统化的文本理解和图像生成，确保指令序列在视觉吸引力、一致性和准确性上得到提升。实验结果显示，该方法在多步指令测试中比基线模型表现出色，在文本对齐和整体连贯性方面显著改善。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "https://instruct-vis-zero.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.04337v2",
      "published_date": "2024-06-06 17:59:44 UTC",
      "updated_date": "2024-06-08 12:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:52:43.541866"
    },
    {
      "arxiv_id": "2406.04331v2",
      "title": "PaCE: Parsimonious Concept Engineering for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinqi Luo",
        "Tianjiao Ding",
        "Kwan Ho Ryan Chan",
        "Darshan Thaker",
        "Aditya Chattopadhyay",
        "Chris Callison-Burch",
        "René Vidal"
      ],
      "abstract": "Large Language Models (LLMs) are being used for a wide variety of tasks.\nWhile they are capable of generating human-like responses, they can also\nproduce undesirable output including potentially harmful information, racist or\nsexist language, and hallucinations. Alignment methods are designed to reduce\nsuch undesirable outputs via techniques such as fine-tuning, prompt\nengineering, and representation engineering. However, existing methods face\nseveral challenges: some require costly fine-tuning for every alignment task;\nsome do not adequately remove undesirable concepts, failing alignment; some\nremove benign concepts, lowering the linguistic capabilities of LLMs. To\naddress these issues, we propose Parsimonious Concept Engineering (PaCE), a\nnovel activation engineering framework for alignment. First, to sufficiently\nmodel the concepts, we construct a large-scale concept dictionary in the\nactivation space, in which each atom corresponds to a semantic concept. Given\nany alignment task, we instruct a concept partitioner to efficiently annotate\nthe concepts as benign or undesirable. Then, at inference time, we decompose\nthe LLM activations along the concept dictionary via sparse coding, to\naccurately represent the activations as linear combinations of benign and\nundesirable components. By removing the latter ones from the activations, we\nreorient the behavior of the LLM towards the alignment goal. We conduct\nexperiments on tasks such as response detoxification, faithfulness enhancement,\nand sentiment revising, and show that PaCE achieves state-of-the-art alignment\nperformance while maintaining linguistic capabilities.",
      "tldr_zh": "该论文提出 PaCE（Parsimonious Concept Engineering），一种新型激活工程框架，用于对齐 Large Language Models (LLMs)，以减少有害输出如种族主义语言和幻觉，同时避免现有方法的高成本微调或移除良性概念。PaCE 通过构建大规模概念字典在激活空间中建模语义概念，然后使用概念分区器标注概念为良性或不良，并在推理时通过 sparse coding 分解激活并移除不良组件，从而重新导向 LLM 的行为。实验结果显示，PaCE 在响应解毒、忠实性增强和情感修订等任务上实现了最先进的对齐性能，同时保持了 LLMs 的语言能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in NeurIPS 2024. GitHub repository at\n  https://github.com/peterljq/Parsimonious-Concept-Engineering",
      "pdf_url": "http://arxiv.org/pdf/2406.04331v2",
      "published_date": "2024-06-06 17:59:10 UTC",
      "updated_date": "2024-11-05 15:43:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:52:47.302948"
    },
    {
      "arxiv_id": "2406.04323v1",
      "title": "ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories",
      "title_zh": "ATraDiff：利用想象轨迹加速在线强化学习",
      "authors": [
        "Qianlan Yang",
        "Yu-Xiong Wang"
      ],
      "abstract": "Training autonomous agents with sparse rewards is a long-standing problem in\nonline reinforcement learning (RL), due to low data efficiency. Prior work\novercomes this challenge by extracting useful knowledge from offline data,\noften accomplished through the learning of action distribution from offline\ndata and utilizing the learned distribution to facilitate online RL. However,\nsince the offline data are given and fixed, the extracted knowledge is\ninherently limited, making it difficult to generalize to new tasks. We propose\na novel approach that leverages offline data to learn a generative diffusion\nmodel, coined as Adaptive Trajectory Diffuser (ATraDiff). This model generates\nsynthetic trajectories, serving as a form of data augmentation and consequently\nenhancing the performance of online RL methods. The key strength of our\ndiffuser lies in its adaptability, allowing it to effectively handle varying\ntrajectory lengths and mitigate distribution shifts between online and offline\ndata. Because of its simplicity, ATraDiff seamlessly integrates with a wide\nspectrum of RL methods. Empirical evaluation shows that ATraDiff consistently\nachieves state-of-the-art performance across a variety of environments, with\nparticularly pronounced improvements in complicated settings. Our code and demo\nvideo are available at https://atradiff.github.io .",
      "tldr_zh": "该论文针对在线强化学习（RL）在稀疏奖励下的低数据效率问题，提出了一种新方法ATraDiff，利用离线数据训练一个生成扩散模型（generative diffusion model），生成合成轨迹（imaginary trajectories）作为数据增强，以加速在线RL训练。ATraDiff的关键在于其适应性，能够处理不同轨迹长度并缓解在线和离线数据之间的分布偏移，同时易于与其他RL方法无缝集成。实验结果显示，ATraDiff在多种环境中实现了最先进性能，尤其在复杂场景中表现出显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2406.04323v1",
      "published_date": "2024-06-06 17:58:15 UTC",
      "updated_date": "2024-06-06 17:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:52:57.795985"
    },
    {
      "arxiv_id": "2406.04320v1",
      "title": "Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models",
      "title_zh": "Chimera：有效建模多变量时间序列的二维状态空间模型",
      "authors": [
        "Ali Behrouz",
        "Michele Santacatterina",
        "Ramin Zabih"
      ],
      "abstract": "Modeling multivariate time series is a well-established problem with a wide\nrange of applications from healthcare to financial markets. Traditional State\nSpace Models (SSMs) are classical approaches for univariate time series\nmodeling due to their simplicity and expressive power to represent linear\ndependencies. They, however, have fundamentally limited expressive power to\ncapture non-linear dependencies, are slow in practice, and fail to model the\ninter-variate information flow. Despite recent attempts to improve the\nexpressive power of SSMs by using deep structured SSMs, the existing methods\nare either limited to univariate time series, fail to model complex patterns\n(e.g., seasonal patterns), fail to dynamically model the dependencies of\nvariate and time dimensions, and/or are input-independent. We present Chimera\nthat uses two input-dependent 2-D SSM heads with different discretization\nprocesses to learn long-term progression and seasonal patterns. To improve the\nefficiency of complex 2D recurrence, we present a fast training using a new\n2-dimensional parallel selective scan. We further present and discuss\n2-dimensional Mamba and Mamba-2 as the spacial cases of our 2D SSM. Our\nexperimental evaluation shows the superior performance of Chimera on extensive\nand diverse benchmarks, including ECG and speech time series classification,\nlong-term and short-term time series forecasting, and time series anomaly\ndetection.",
      "tldr_zh": "该论文提出Chimera，一种基于2-Dimensional State Space Models (2-D SSMs)的框架，用于有效建模多元时间序列 (multivariate time series)，解决传统SSMs在捕捉非线性依赖、变量间信息流和复杂模式（如seasonal patterns）方面的局限。Chimera采用两个输入相关的2-D SSM heads，通过不同的离散化过程 (discretization processes) 动态学习长期进展 (long-term progression) 和季节模式，并引入新的2-dimensional parallel selective scan 来提升训练效率。论文进一步讨论了2-dimensional Mamba 和 Mamba-2 作为其特殊情况，并在ECG、语音分类、长期/短期预测以及异常检测等多样基准上，Chimera展示了显著优于基线模型的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04320v1",
      "published_date": "2024-06-06 17:58:09 UTC",
      "updated_date": "2024-06-06 17:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:53:12.368880"
    },
    {
      "arxiv_id": "2406.04318v1",
      "title": "Adaptive Sampling of k-Space in Magnetic Resonance for Rapid Pathology Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Chen-Yu Yen",
        "Raghav Singhal",
        "Umang Sharma",
        "Rajesh Ranganath",
        "Sumit Chopra",
        "Lerrel Pinto"
      ],
      "abstract": "Magnetic Resonance (MR) imaging, despite its proven diagnostic utility,\nremains an inaccessible imaging modality for disease surveillance at the\npopulation level. A major factor rendering MR inaccessible is lengthy scan\ntimes. An MR scanner collects measurements associated with the underlying\nanatomy in the Fourier space, also known as the k-space. Creating a\nhigh-fidelity image requires collecting large quantities of such measurements,\nincreasing the scan time. Traditionally to accelerate an MR scan, image\nreconstruction from under-sampled k-space data is the method of choice.\nHowever, recent works show the feasibility of bypassing image reconstruction\nand directly learning to detect disease directly from a sparser learned subset\nof the k-space measurements. In this work, we propose Adaptive Sampling for MR\n(ASMR), a sampling method that learns an adaptive policy to sequentially select\nk-space samples to optimize for target disease detection. On 6 out of 8\npathology classification tasks spanning the Knee, Brain, and Prostate MR scans,\nASMR reaches within 2% of the performance of a fully sampled classifier while\nusing only 8% of the k-space, as well as outperforming prior state-of-the-art\nwork in k-space sampling such as EMRT, LOUPE, and DPS.",
      "tldr_zh": "本研究针对磁性共振（MR）成像的扫描时间过长问题，提出了一种自适应采样方法ASMR，用于快速预测病理。ASMR通过学习一个自适应策略，顺序选择k-space样本，直接优化目标疾病检测，而非依赖传统图像重建。实验结果显示，在涉及膝盖、脑部和前列腺的8个病理分类任务中，ASMR仅使用8%的k-space采样，即可达到与完全采样分类器性能相差不到2%，并优于现有方法如EMRT、LOUPE和DPS。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024. Project website at https://adaptive-sampling-mr.github.io",
      "pdf_url": "http://arxiv.org/pdf/2406.04318v1",
      "published_date": "2024-06-06 17:58:00 UTC",
      "updated_date": "2024-06-06 17:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:53:23.738900"
    },
    {
      "arxiv_id": "2406.04313v4",
      "title": "Improving Alignment and Robustness with Circuit Breakers",
      "title_zh": "通过电路断路器提升对齐与鲁棒性",
      "authors": [
        "Andy Zou",
        "Long Phan",
        "Justin Wang",
        "Derek Duenas",
        "Maxwell Lin",
        "Maksym Andriushchenko",
        "Rowan Wang",
        "Zico Kolter",
        "Matt Fredrikson",
        "Dan Hendrycks"
      ],
      "abstract": "AI systems can take harmful actions and are highly vulnerable to adversarial\nattacks. We present an approach, inspired by recent advances in representation\nengineering, that interrupts the models as they respond with harmful outputs\nwith \"circuit breakers.\" Existing techniques aimed at improving alignment, such\nas refusal training, are often bypassed. Techniques such as adversarial\ntraining try to plug these holes by countering specific attacks. As an\nalternative to refusal training and adversarial training, circuit-breaking\ndirectly controls the representations that are responsible for harmful outputs\nin the first place. Our technique can be applied to both text-only and\nmultimodal language models to prevent the generation of harmful outputs without\nsacrificing utility -- even in the presence of powerful unseen attacks.\nNotably, while adversarial robustness in standalone image recognition remains\nan open challenge, circuit breakers allow the larger multimodal system to\nreliably withstand image \"hijacks\" that aim to produce harmful content.\nFinally, we extend our approach to AI agents, demonstrating considerable\nreductions in the rate of harmful actions when they are under attack. Our\napproach represents a significant step forward in the development of reliable\nsafeguards to harmful behavior and adversarial attacks.",
      "tldr_zh": "本研究提出了一种名为 circuit breakers 的方法，基于 representation engineering 直接控制 AI 模型中导致有害输出的表示，从而改善模型的对齐性和鲁棒性。该方法无需依赖传统的 refusal training 或 adversarial training，即可中断有害内容生成，同时保持模型的实用性，即使面对强大的未见对抗性攻击。实验结果显示，circuit breakers 适用于文本和多模态语言模型，能有效抵抗图像 \"hijacks\"，并在 AI 代理中显著降低有害行动的发生率，为构建可靠的 AI 安全机制提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Code and models are available at\n  https://github.com/GraySwanAI/circuit-breakers",
      "pdf_url": "http://arxiv.org/pdf/2406.04313v4",
      "published_date": "2024-06-06 17:57:04 UTC",
      "updated_date": "2024-07-12 16:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:53:36.113848"
    },
    {
      "arxiv_id": "2406.04306v1",
      "title": "Semantically Diverse Language Generation for Uncertainty Estimation in Language Models",
      "title_zh": "语义多样的语言生成用于语言模型",
      "authors": [
        "Lukas Aichberger",
        "Kajetan Schweighofer",
        "Mykyta Ielanskyi",
        "Sepp Hochreiter"
      ],
      "abstract": "Large language models (LLMs) can suffer from hallucinations when generating\ntext. These hallucinations impede various applications in society and industry\nby making LLMs untrustworthy. Current LLMs generate text in an autoregressive\nfashion by predicting and appending text tokens. When an LLM is uncertain about\nthe semantic meaning of the next tokens to generate, it is likely to start\nhallucinating. Thus, it has been suggested that hallucinations stem from\npredictive uncertainty. We introduce Semantically Diverse Language Generation\n(SDLG) to quantify predictive uncertainty in LLMs. SDLG steers the LLM to\ngenerate semantically diverse yet likely alternatives for an initially\ngenerated text. This approach provides a precise measure of aleatoric semantic\nuncertainty, detecting whether the initial text is likely to be hallucinated.\nExperiments on question-answering tasks demonstrate that SDLG consistently\noutperforms existing methods while being the most computationally efficient,\nsetting a new standard for uncertainty estimation in LLMs.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)中的幻觉(hallucinations)问题，提出Semantically Diverse Language Generation (SDLG)方法，用于量化LLMs的预测不确定性。SDLG通过引导模型生成语义上多样但概率高的备选文本，来精确测量aleatoric semantic uncertainty，并检测初始文本是否可能为幻觉。在问答任务的实验中，SDLG outperforms现有方法，同时具有最高的计算效率，确立了LLMs不确定性估计的新标准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04306v1",
      "published_date": "2024-06-06 17:53:34 UTC",
      "updated_date": "2024-06-06 17:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:53:47.915993"
    },
    {
      "arxiv_id": "2406.04303v3",
      "title": "Vision-LSTM: xLSTM as Generic Vision Backbone",
      "title_zh": "Vision-LSTM：xLSTM 作为通用视觉主干网络",
      "authors": [
        "Benedikt Alkin",
        "Maximilian Beck",
        "Korbinian Pöppel",
        "Sepp Hochreiter",
        "Johannes Brandstetter"
      ],
      "abstract": "Transformers are widely used as generic backbones in computer vision, despite\ninitially introduced for natural language processing. Recently, the Long\nShort-Term Memory (LSTM) has been extended to a scalable and performant\narchitecture - the xLSTM - which overcomes long-standing LSTM limitations via\nexponential gating and parallelizable matrix memory structure. In this report,\nwe introduce Vision-LSTM (ViL), an adaption of the xLSTM building blocks to\ncomputer vision. ViL comprises a stack of xLSTM blocks where odd blocks process\nthe sequence of patch tokens from top to bottom while even blocks go from\nbottom to top. Experiments show that ViL holds promise to be further deployed\nas new generic backbone for computer vision architectures.",
      "tldr_zh": "本文提出 Vision-LSTM (ViL)，一种将扩展的 Long Short-Term Memory (xLSTM) 架构适应为计算机视觉通用骨干网络的方法。\nViL 通过堆叠 xLSTM 块，采用交替处理策略——奇数块从上到下、偶数块从下到上，来处理图像 patch tokens 的序列。\n实验显示，ViL 展现出作为新型计算机视觉架构骨干的潜力，有望取代传统 Transformers。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published as a conference paper at ICLR 2025, Github:\n  https://github.com/NX-AI/vision-lstm",
      "pdf_url": "http://arxiv.org/pdf/2406.04303v3",
      "published_date": "2024-06-06 17:49:21 UTC",
      "updated_date": "2025-02-20 23:20:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:53:59.650590"
    },
    {
      "arxiv_id": "2406.04391v2",
      "title": "Why Has Predicting Downstream Capabilities of Frontier AI Models with Scale Remained Elusive?",
      "title_zh": "翻译失败",
      "authors": [
        "Rylan Schaeffer",
        "Hailey Schoelkopf",
        "Brando Miranda",
        "Gabriel Mukobi",
        "Varun Madan",
        "Adam Ibrahim",
        "Herbie Bradley",
        "Stella Biderman",
        "Sanmi Koyejo"
      ],
      "abstract": "Predicting changes from scaling advanced AI systems is a desirable property\nfor engineers, economists, governments and industry alike, and, while a\nwell-established literature exists on how pretraining performance scales,\npredictable scaling behavior on downstream capabilities remains elusive. While\nmany factors are certainly responsible, this paper identifies a significant\nfactor that makes predicting scaling behavior on widely used multiple-choice\nquestion answering benchmarks challenging and illuminates a path towards making\nsuch downstream evaluations predictable with scale. Using five model families\nand twelve well-established multiple-choice benchmarks, we demonstrate that\ndownstream performance is computed from negative log likelihoods via a sequence\nof transformations that progressively degrades the statistical relationship\nbetween performance and scale. We then pinpoint the mechanism causing this\ndegradation: downstream metrics require comparing the correct choice against a\nsmall number of specific incorrect choices, meaning accurately predicting\ndownstream capabilities requires predicting not just how probability mass\nconcentrates on the correct choice with scale, but also how probability mass\nfluctuates on the alternative incorrect choices with scale. We empirically\nstudy how probability mass on the correct choice co-varies with probability\nmass on incorrect choices with increasing compute, suggesting that scaling laws\nfor \\textit{incorrect} choices might be achievable. Our work also explains why\npretraining scaling laws are commonly regarded as more predictable than\ndownstream capabilities and contributes towards establishing\nscaling-predictable evaluations of frontier AI models.",
      "tldr_zh": "该论文探讨了为什么预测前沿AI模型（frontier AI models）下游能力的扩展行为（scaling behavior）如此困难，尽管预训练性能的扩展规律已很成熟。研究者通过分析五个模型系列和十二个多选题基准（multiple-choice benchmarks），发现下游性能基于负对数似然（negative log likelihoods）的转换过程会削弱性能与规模之间的统计关系，关键在于需要同时预测正确选择概率质量的集中和错误选择概率质量的波动。实验结果显示，正确和错误选择的概率质量随计算资源增加而共同变化，这暗示错误选择的扩展规律（scaling laws）可能实现，并为建立可预测的下游评估提供新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04391v2",
      "published_date": "2024-06-06 17:46:56 UTC",
      "updated_date": "2025-02-05 17:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:54:13.647260"
    },
    {
      "arxiv_id": "2407.06170v1",
      "title": "Real-Time Spacecraft Pose Estimation Using Mixed-Precision Quantized Neural Network on COTS Reconfigurable MPSoC",
      "title_zh": "翻译失败",
      "authors": [
        "Julien Posso",
        "Guy Bois",
        "Yvon Savaria"
      ],
      "abstract": "This article presents a pioneering approach to real-time spacecraft pose\nestimation, utilizing a mixed-precision quantized neural network implemented on\nthe FPGA components of a commercially available Xilinx MPSoC, renowned for its\nsuitability in space applications. Our co-design methodology includes a novel\nevaluation technique for assessing the layer-wise neural network sensitivity to\nquantization, facilitating an optimal balance between accuracy, latency, and\nFPGA resource utilization. Utilizing the FINN library, we developed a bespoke\nFPGA dataflow accelerator that integrates on-chip weights and activation\nfunctions to minimize latency and energy consumption. Our implementation is 7.7\ntimes faster and 19.5 times more energy-efficient than the best-reported values\nin the existing spacecraft pose estimation literature. Furthermore, our\ncontribution includes the first real-time, open-source implementation of such\nalgorithms, marking a significant advancement in making efficient spacecraft\npose estimation algorithms widely accessible. The source code is available at\nhttps://github.com/possoj/FPGA-SpacePose.",
      "tldr_zh": "这篇论文提出了一种实时航天器姿态估计方法，使用 mixed-precision quantized neural network 部署在商用 Xilinx MPSoC 的 FPGA 组件上，以实现高效率的空间应用。论文引入了一种新型层级神经网络量化敏感性评估技术，结合 FINN library 开发的定制 FPGA 数据流加速器，优化了准确性、延迟和资源利用，同时最小化能量消耗。实验结果显示，该方法比现有文献快 7.7 倍、节能 19.5 倍，并首次提供实时开源实现，代码可从 https://github.com/possoj/FPGA-SpacePose 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at IEEE NEWCAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.06170v1",
      "published_date": "2024-06-06 17:36:26 UTC",
      "updated_date": "2024-06-06 17:36:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:54:25.068014"
    },
    {
      "arxiv_id": "2406.04286v1",
      "title": "ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions",
      "title_zh": "ABEX：通过扩展抽象描述进行低资源 NLU 的数据增强",
      "authors": [
        "Sreyan Ghosh",
        "Utkarsh Tyagi",
        "Sonal Kumar",
        "C. K. Evuru",
        "S Ramaneswaran",
        "S Sakshi",
        "Dinesh Manocha"
      ],
      "abstract": "We present ABEX, a novel and effective generative data augmentation\nmethodology for low-resource Natural Language Understanding (NLU) tasks. ABEX\nis based on ABstract-and-EXpand, a novel paradigm for generating diverse forms\nof an input document -- we first convert a document into its concise, abstract\ndescription and then generate new documents based on expanding the resultant\nabstraction. To learn the task of expanding abstract descriptions, we first\ntrain BART on a large-scale synthetic dataset with abstract-document pairs.\nNext, to generate abstract descriptions for a document, we propose a simple,\ncontrollable, and training-free method based on editing AMR graphs. ABEX brings\nthe best of both worlds: by expanding from abstract representations, it\npreserves the original semantic properties of the documents, like style and\nmeaning, thereby maintaining alignment with the original label and data\ndistribution. At the same time, the fundamental process of elaborating on\nabstract descriptions facilitates diverse generations. We demonstrate the\neffectiveness of ABEX on 4 NLU tasks spanning 12 datasets and 4 low-resource\nsettings. ABEX outperforms all our baselines qualitatively with improvements of\n0.04% - 38.8%. Qualitatively, ABEX outperforms all prior methods from\nliterature in terms of context and length diversity.",
      "tldr_zh": "本文提出ABEX，一种新型生成式数据增强方法，针对低资源Natural Language Understanding (NLU)任务，通过ABstract-and-EXpand范式先将文档转换为简洁抽象描述，然后基于这些抽象扩展生成多样化新文档。ABEX利用BART模型在大规模合成数据集上训练扩展能力，并采用简单可控的AMR图谱编辑方法生成抽象描述，从而保留原文档的语义属性如风格和含义，同时提升生成多样性。在4个NLU任务、12个数据集和4个低资源设置的实验中，ABEX比基线方法提高了0.04%至38.8%的性能，并在上下文和长度多样性上优于现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Main Conference. Code and data:\n  https://github.com/Sreyan88/ABEX",
      "pdf_url": "http://arxiv.org/pdf/2406.04286v1",
      "published_date": "2024-06-06 17:29:57 UTC",
      "updated_date": "2024-06-06 17:29:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:54:37.414593"
    },
    {
      "arxiv_id": "2406.04276v1",
      "title": "Generative AI-in-the-loop: Integrating LLMs and GPTs into the Next Generation Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Han Zhang",
        "Akram Bin Sediq",
        "Ali Afana",
        "Melike Erol-Kantarci"
      ],
      "abstract": "In recent years, machine learning (ML) techniques have created numerous\nopportunities for intelligent mobile networks and have accelerated the\nautomation of network operations. However, complex network tasks may involve\nvariables and considerations even beyond the capacity of traditional ML\nalgorithms. On the other hand, large language models (LLMs) have recently\nemerged, demonstrating near-human-level performance in cognitive tasks across\nvarious fields. However, they remain prone to hallucinations and often lack\ncommon sense in basic tasks. Therefore, they are regarded as assistive tools\nfor humans. In this work, we propose the concept of \"generative AI-in-the-loop\"\nand utilize the semantic understanding, context awareness, and reasoning\nabilities of LLMs to assist humans in handling complex or unforeseen situations\nin mobile communication networks. We believe that combining LLMs and ML models\nallows both to leverage their respective capabilities and achieve better\nresults than either model alone. To support this idea, we begin by analyzing\nthe capabilities of LLMs and compare them with traditional ML algorithms. We\nthen explore potential LLM-based applications in line with the requirements of\nnext-generation networks. We further examine the integration of ML and LLMs,\ndiscussing how they can be used together in mobile networks. Unlike existing\nstudies, our research emphasizes the fusion of LLMs with traditional ML-driven\nnext-generation networks and serves as a comprehensive refinement of existing\nsurveys. Finally, we provide a case study to enhance ML-based network intrusion\ndetection with synthesized data generated by LLMs. Our case study further\ndemonstrates the advantages of our proposed idea.",
      "tldr_zh": "本论文提出“generative AI-in-the-loop”概念，将大型语言模型（LLMs）和GPTs整合到下一代移动网络中，以利用LLMs的语义理解、上下文感知和推理能力，辅助处理复杂或不可预见的情况，从而提升传统机器学习（ML）算法的性能。作者分析了LLMs与ML算法的能力差异，并探讨了LLMs在网络任务中的潜在应用，如结合ML模型实现更好的结果。最终，通过一个案例研究，使用LLMs生成的合成数据增强了基于ML的网络入侵检测，证明了这种融合方法的优势，为智能网络自动化提供了全面的改进框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04276v1",
      "published_date": "2024-06-06 17:25:07 UTC",
      "updated_date": "2024-06-06 17:25:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:54:47.923011"
    },
    {
      "arxiv_id": "2406.04274v1",
      "title": "Self-Play with Adversarial Critic: Provable and Scalable Offline Alignment for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Ji",
        "Sanjeev Kulkarni",
        "Mengdi Wang",
        "Tengyang Xie"
      ],
      "abstract": "This work studies the challenge of aligning large language models (LLMs) with\noffline preference data. We focus on alignment by Reinforcement Learning from\nHuman Feedback (RLHF) in particular. While popular preference optimization\nmethods exhibit good empirical performance in practice, they are not\ntheoretically guaranteed to converge to the optimal policy and can provably\nfail when the data coverage is sparse by classical offline reinforcement\nlearning (RL) results. On the other hand, a recent line of work has focused on\ntheoretically motivated preference optimization methods with provable\nguarantees, but these are not computationally efficient for large-scale\napplications like LLM alignment. To bridge this gap, we propose SPAC, a new\noffline preference optimization method with self-play, inspired by the\non-average pessimism technique from the offline RL literature, to be the first\nprovable and scalable approach to LLM alignment. We both provide theoretical\nanalysis for its convergence under single-policy concentrability for the\ngeneral function approximation setting and demonstrate its competitive\nempirical performance for LLM alignment on a 7B Mistral model with Open LLM\nLeaderboard evaluations.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 的离线偏好数据对齐挑战，特别是强化学习从人类反馈 (RLHF) 方法的收敛问题和数据覆盖稀疏时的失败，提出了一种新方法 SPAC（Self-Play with Adversarial Critic）。SPAC 结合自对弈机制和受离线强化学习 (RL) 启发的平均悲观技术，实现可证明的收敛，并在一般函数逼近设置下提供理论保证。实验结果显示，SPAC 在 7B Mistral 模型上表现出竞争性的实证性能，并在 Open LLM Leaderboard 评估中验证了其可扩展性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04274v1",
      "published_date": "2024-06-06 17:23:49 UTC",
      "updated_date": "2024-06-06 17:23:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:55:00.423919"
    },
    {
      "arxiv_id": "2406.04273v2",
      "title": "ELFS: Label-Free Coreset Selection with Proxy Training Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Haizhong Zheng",
        "Elisa Tsai",
        "Yifu Lu",
        "Jiachen Sun",
        "Brian R. Bartoldson",
        "Bhavya Kailkhura",
        "Atul Prakash"
      ],
      "abstract": "High-quality human-annotated data is crucial for modern deep learning\npipelines, yet the human annotation process is both costly and time-consuming.\nGiven a constrained human labeling budget, selecting an informative and\nrepresentative data subset for labeling can significantly reduce human\nannotation effort. Well-performing state-of-the-art (SOTA) coreset selection\nmethods require ground truth labels over the whole dataset, failing to reduce\nthe human labeling burden. Meanwhile, SOTA label-free coreset selection methods\ndeliver inferior performance due to poor geometry-based difficulty scores. In\nthis paper, we introduce ELFS (Effective Label-Free Coreset Selection), a novel\nlabel-free coreset selection method. ELFS significantly improves label-free\ncoreset selection by addressing two challenges: 1) ELFS utilizes deep\nclustering to estimate training dynamics-based data difficulty scores without\nground truth labels; 2) Pseudo-labels introduce a distribution shift in the\ndata difficulty scores, and we propose a simple but effective double-end\npruning method to mitigate bias on calculated scores. We evaluate ELFS on four\nvision benchmarks and show that, given the same vision encoder, ELFS\nconsistently outperforms SOTA label-free baselines. For instance, when using\nSwAV as the encoder, ELFS outperforms D2 by up to 10.2% in accuracy on\nImageNet-1K. We make our code publicly available on GitHub.",
      "tldr_zh": "本论文提出 ELFS，一种无需标签的 coreset selection 方法，旨在通过代理训练动态（proxy training dynamics）减少人类标注负担。ELFS 利用深度聚类估算数据难度分数，并引入双端修剪（double-end pruning）来缓解伪标签带来的分布偏移，从而提升选择子集的代表性和信息性。在四个视觉基准测试中，ELFS 显著优于现有无标签基线，例如使用 SwAV 编码器时，在 ImageNet-1K 上准确率比 D2 高出高达 10.2%。这项工作为高效的数据子集选择提供了新途径，并已开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.04273v2",
      "published_date": "2024-06-06 17:23:05 UTC",
      "updated_date": "2025-02-24 14:56:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:55:14.980673"
    },
    {
      "arxiv_id": "2406.04268v1",
      "title": "Open-Endedness is Essential for Artificial Superhuman Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Hughes",
        "Michael Dennis",
        "Jack Parker-Holder",
        "Feryal Behbahani",
        "Aditi Mavalankar",
        "Yuge Shi",
        "Tom Schaul",
        "Tim Rocktaschel"
      ],
      "abstract": "In recent years there has been a tremendous surge in the general capabilities\nof AI systems, mainly fuelled by training foundation models on internetscale\ndata. Nevertheless, the creation of openended, ever self-improving AI remains\nelusive. In this position paper, we argue that the ingredients are now in place\nto achieve openendedness in AI systems with respect to a human observer.\nFurthermore, we claim that such open-endedness is an essential property of any\nartificial superhuman intelligence (ASI). We begin by providing a concrete\nformal definition of open-endedness through the lens of novelty and\nlearnability. We then illustrate a path towards ASI via open-ended systems\nbuilt on top of foundation models, capable of making novel, humanrelevant\ndiscoveries. We conclude by examining the safety implications of\ngenerally-capable openended AI. We expect that open-ended foundation models\nwill prove to be an increasingly fertile and safety-critical area of research\nin the near future.",
      "tldr_zh": "这篇论文主张，开放性（open-endedness）是实现人工超级智能（Artificial Superhuman Intelligence, ASI）的核心属性，因为它允许AI系统持续自我改进和产生新颖发现。作者通过新颖性和可学习性的视角，提供了一个具体正式定义，并描述了利用基础模型（foundation models）构建开放系统，以实现人类相关的新颖发现和ASI的路径。论文最后讨论了这种AI的安全风险，并预测开放性基础模型将成为未来安全关键的研究领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04268v1",
      "published_date": "2024-06-06 17:15:02 UTC",
      "updated_date": "2024-06-06 17:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:55:25.760986"
    },
    {
      "arxiv_id": "2406.04264v3",
      "title": "MLVU: Benchmarking Multi-task Long Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Zhou",
        "Yan Shu",
        "Bo Zhao",
        "Boya Wu",
        "Zhengyang Liang",
        "Shitao Xiao",
        "Minghao Qin",
        "Xi Yang",
        "Yongping Xiong",
        "Bo Zhang",
        "Tiejun Huang",
        "Zheng Liu"
      ],
      "abstract": "The evaluation of Long Video Understanding (LVU) performance poses an\nimportant but challenging research problem. Despite previous efforts, the\nexisting video understanding benchmarks are severely constrained by several\nissues, especially the insufficient lengths of videos, a lack of diversity in\nvideo types and evaluation tasks, and the inappropriateness for evaluating LVU\nperformances. To address the above problems, we propose a new benchmark called\nMLVU (Multi-task Long Video Understanding Benchmark) for the comprehensive and\nin-depth evaluation of LVU. MLVU presents the following critical values:\n\\textit{1)} The substantial and flexible extension of video lengths, which\nenables the benchmark to evaluate LVU performance across a wide range of\ndurations. \\textit{2)} The inclusion of various video genres, e.g., movies,\nsurveillance footage, egocentric videos, cartoons, game videos, etc., which\nreflects the models' LVU performances in different scenarios. \\textit{3)} The\ndevelopment of diversified evaluation tasks, which enables a comprehensive\nexamination of MLLMs' key abilities in long-video understanding. The empirical\nstudy with 23 latest MLLMs reveals significant room for improvement in today's\ntechnique, as all existing methods struggle with most of the evaluation tasks\nand exhibit severe performance degradation when handling longer videos.\nAdditionally, it suggests that factors such as context length,\nimage-understanding ability, and the choice of LLM backbone can play critical\nroles in future advancements. We anticipate that MLVU will advance the research\nof long video understanding by providing a comprehensive and in-depth analysis\nof MLLMs.",
      "tldr_zh": "这篇论文提出了 MLVU（Multi-task Long Video Understanding Benchmark），一个新的基准，用于全面评估长视频理解（LVU）的性能，以解决现有基准中视频长度不足、类型多样性缺乏和任务不适等问题。MLVU 通过支持灵活的视频长度扩展、涵盖多种视频类型（如电影、监控视频、第一人称视频等）和开发多样化评估任务，系统地考察多模态大语言模型（MLLMs）的关键能力。实验涉及23个最新MLLMs，结果显示现有方法在大多数任务上表现不佳，尤其在处理较长视频时性能显著下降，并强调了上下文长度、图像理解能力和LLM骨干选择等因素对未来改进的关键作用。该基准有望推动长视频理解研究的深入发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04264v3",
      "published_date": "2024-06-06 17:09:32 UTC",
      "updated_date": "2025-01-01 15:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:55:40.575905"
    },
    {
      "arxiv_id": "2407.11991v1",
      "title": "Inspired by AI? A Novel Generative AI System To Assist Conceptual Automotive Design",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Wang",
        "Nicole B. Damen",
        "Thomas Gale",
        "Voho Seo",
        "Hooman Shayani"
      ],
      "abstract": "Design inspiration is crucial for establishing the direction of a design as\nwell as evoking feelings and conveying meanings during the conceptual design\nprocess. Many practice designers use text-based searches on platforms like\nPinterest to gather image ideas, followed by sketching on paper or using\ndigital tools to develop concepts. Emerging generative AI techniques, such as\ndiffusion models, offer a promising avenue to streamline these processes by\nswiftly generating design concepts based on text and image inspiration inputs,\nsubsequently using the AI generated design concepts as fresh sources of\ninspiration for further concept development. However, applying these generative\nAI techniques directly within a design context has challenges. Firstly,\ngenerative AI tools may exhibit a bias towards particular styles, resulting in\na lack of diversity of design outputs. Secondly, these tools may struggle to\ngrasp the nuanced meanings of texts or images in a design context. Lastly, the\nlack of integration with established design processes within design teams can\nresult in fragmented use scenarios. Focusing on these challenges, we conducted\nworkshops, surveys, and data augmentation involving teams of experienced\nautomotive designers to investigate their current practices in generating\nconcepts inspired by texts and images, as well as their preferred interaction\nmodes for generative AI systems to support the concept generation workflow.\nFinally, we developed a novel generative AI system based on diffusion models to\nassist conceptual automotive design.",
      "tldr_zh": "该论文探讨了生成式 AI 在汽车概念设计中的应用，旨在通过文本和图像灵感快速生成设计概念，以辅助设计师的工作流程。研究发现，现有的 generative AI 工具存在风格偏见、语义理解不足以及与设计过程整合不佳等挑战。为此，作者通过研讨会、调查和数据增强，与经验丰富的汽车设计师合作，分析了他们的实践偏好。最终，他们开发了一个基于 diffusion models 的新型 generative AI 系统，能够提升设计概念的多样性和可操作性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11991v1",
      "published_date": "2024-06-06 17:04:14 UTC",
      "updated_date": "2024-06-06 17:04:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:55:51.273988"
    },
    {
      "arxiv_id": "2406.04254v3",
      "title": "GeoGen: Geometry-Aware Generative Modeling via Signed Distance Functions",
      "title_zh": "GeoGen: 通过有符号距离函数",
      "authors": [
        "Salvatore Esposito",
        "Qingshan Xu",
        "Kacper Kania",
        "Charlie Hewitt",
        "Octave Mariotti",
        "Lohit Petikam",
        "Julien Valentin",
        "Arno Onken",
        "Oisin Mac Aodha"
      ],
      "abstract": "We introduce a new generative approach for synthesizing 3D geometry and\nimages from single-view collections. Most existing approaches predict\nvolumetric density to render multi-view consistent images. By employing\nvolumetric rendering using neural radiance fields, they inherit a key\nlimitation: the generated geometry is noisy and unconstrained, limiting the\nquality and utility of the output meshes. To address this issue, we propose\nGeoGen, a new SDF-based 3D generative model trained in an end-to-end manner.\nInitially, we reinterpret the volumetric density as a Signed Distance Function\n(SDF). This allows us to introduce useful priors to generate valid meshes.\nHowever, those priors prevent the generative model from learning details,\nlimiting the applicability of the method to real-world scenarios. To alleviate\nthat problem, we make the transformation learnable and constrain the rendered\ndepth map to be consistent with the zero-level set of the SDF. Through the lens\nof adversarial training, we encourage the network to produce higher fidelity\ndetails on the output meshes. For evaluation, we introduce a synthetic dataset\nof human avatars captured from 360-degree camera angles, to overcome the\nchallenges presented by real-world datasets, which often lack 3D consistency\nand do not cover all camera angles. Our experiments on multiple datasets show\nthat GeoGen produces visually and quantitatively better geometry than the\nprevious generative models based on neural radiance fields.",
      "tldr_zh": "本文提出GeoGen，一种基于Signed Distance Functions (SDF)的生成模型，用于从单视图集合合成高质量的3D几何和图像，以解决现有基于体积密度方法的几何噪声问题。该模型通过将体积密度重新解释为SDF、引入先验知识、使变换可学习并约束渲染深度图的一致性，以及采用对抗训练，显著提升了输出网格的细节和保真度。为评估，作者引入了一个合成人类头像数据集，实验结果显示GeoGen在多个数据集上比基于Neural Radiance Fields的模型在视觉和定量指标上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04254v3",
      "published_date": "2024-06-06 17:00:10 UTC",
      "updated_date": "2024-06-14 12:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:56:04.107682"
    },
    {
      "arxiv_id": "2406.04233v2",
      "title": "FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Bernardo Leite",
        "Tomás Freitas Osório",
        "Henrique Lopes Cardoso"
      ],
      "abstract": "Question Answering (QA) datasets are crucial in assessing reading\ncomprehension skills for both machines and humans. While numerous datasets have\nbeen developed in English for this purpose, a noticeable void exists in\nless-resourced languages. To alleviate this gap, our paper introduces\nmachine-translated versions of FairytaleQA, a renowned QA dataset designed to\nassess and enhance narrative comprehension skills in young children. By\nemploying fine-tuned, modest-scale models, we establish benchmarks for both\nQuestion Generation (QG) and QA tasks within the translated datasets. In\naddition, we present a case study proposing a model for generating\nquestion-answer pairs, with an evaluation incorporating quality metrics such as\nquestion well-formedness, answerability, relevance, and children suitability.\nOur evaluation prioritizes quantifying and describing error cases, along with\nproviding directions for future work. This paper contributes to the advancement\nof QA and QG research in less-resourced languages, promoting accessibility and\ninclusivity in the development of these models for reading comprehension. The\ncode and data is publicly available at\ngithub.com/bernardoleite/fairytaleqa-translated.",
      "tldr_zh": "该论文针对低资源语言中缺乏问答（QA）数据集的问题，引入了 FairytaleQA 的机器翻译版本，以评估和提升儿童的叙事理解技能。通过微调中小规模模型，该研究建立了翻译数据集的 Question Generation (QG) 和 QA 任务基准，并提出了一种生成问题-答案对的模型。评估包括指标如问题格式正确性、可回答性、相关性和适合儿童度，并量化了错误案例以指导未来工作。该工作促进了低资源语言中 QA 和 QG 研究的包容性发展，并公开了代码和数据以供进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint - Accepted for publication at ECTEL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04233v2",
      "published_date": "2024-06-06 16:31:47 UTC",
      "updated_date": "2024-06-24 15:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:56:14.561943"
    },
    {
      "arxiv_id": "2406.04231v3",
      "title": "Quantifying Misalignment Between Agents: Towards a Sociotechnical Understanding of Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Aidan Kierans",
        "Avijit Ghosh",
        "Hananel Hazan",
        "Shiri Dori-Hacohen"
      ],
      "abstract": "Existing work on the alignment problem has focused mainly on (1) qualitative\ndescriptions of the alignment problem; (2) attempting to align AI actions with\nhuman interests by focusing on value specification and learning; and/or (3)\nfocusing on a single agent or on humanity as a monolith. Recent sociotechnical\napproaches highlight the need to understand complex misalignment among multiple\nhuman and AI agents. We address this gap by adapting a computational social\nscience model of human contention to the alignment problem. Our model\nquantifies misalignment in large, diverse agent groups with potentially\nconflicting goals across various problem areas. Misalignment scores in our\nframework depend on the observed agent population, the domain in question, and\nconflict between agents' weighted preferences. Through simulations, we\ndemonstrate how our model captures intuitive aspects of misalignment across\ndifferent scenarios. We then apply our model to two case studies, including an\nautonomous vehicle setting, showcasing its practical utility. Our approach\noffers enhanced explanatory power for complex sociotechnical environments and\ncould inform the design of more aligned AI systems in real-world applications.",
      "tldr_zh": "该研究探讨了 AI 对齐（alignment）问题的局限性，现有工作多聚焦于定性描述、价值学习或单一代理，而忽略了多人类和 AI 代理之间的复杂不对齐。作者改编了一个计算社会科学模型，量化了大型代理群体的不对齐程度，该模型考虑代理人口、特定领域以及代理加权偏好间的冲突。通过模拟和两个案例研究（如自动驾驶车辆场景），模型展示了其捕捉不对齐的直观能力。该方法提升了对复杂社会技术环境的解释力，并为设计更对齐的 AI 系统提供了实际指导。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY",
        "cs.GT",
        "I.2.11; K.4.m"
      ],
      "primary_category": "cs.MA",
      "comment": "7 pages, 8 figures, 3 tables, forthcoming at the AAAI-25 Special\n  Track on AI Alignment",
      "pdf_url": "http://arxiv.org/pdf/2406.04231v3",
      "published_date": "2024-06-06 16:31:22 UTC",
      "updated_date": "2024-12-16 19:55:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:56:37.106888"
    },
    {
      "arxiv_id": "2406.04230v2",
      "title": "M3LEO: A Multi-Modal, Multi-Label Earth Observation Dataset Integrating Interferometric SAR and Multispectral Data",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew J Allen",
        "Francisco Dorr",
        "Joseph Alejandro Gallego Mejia",
        "Laura Martínez-Ferrer",
        "Anna Jungbluth",
        "Freddie Kalaitzis",
        "Raúl Ramos-Pollán"
      ],
      "abstract": "Satellite-based remote sensing has revolutionised the way we address global\nchallenges. Huge quantities of Earth Observation (EO) data are generated by\nsatellite sensors daily, but processing these large datasets for use in ML\npipelines is technically and computationally challenging. While some\npreprocessed Earth observation datasets exist, their content is often limited\nto optical or near-optical wavelength data, which is ineffective at night or in\nadverse weather conditions. Synthetic Aperture Radar (SAR), an active sensing\ntechnique based on microwave length radiation, offers a viable alternative.\nHowever, the application of machine learning to SAR has been limited due to a\nlack of ML-ready data and pipelines, particularly for the full diversity of SAR\ndata, including polarimetry, coherence and interferometry. In this work, we\nintroduce M3LEO, a multi-modal, multi-label Earth observation dataset that\nincludes polarimetric, interferometric, and coherence SAR data derived from\nSentinel-1, alongside multispectral Sentinel-2 imagery and auxiliary data\ndescribing terrain properties such as land use. M3LEO spans approximately 17M\n4x4 km data chips from six diverse geographic regions. The dataset is\ncomplemented by a flexible PyTorch Lightning framework configured using Hydra\nto accommodate its use across diverse ML applications in Earth observation. We\nprovide tools to process any dataset available on popular platforms such as\nGoogle Earth Engine for seamless integration with our framework. We show that\nthe distribution shift in self-supervised embeddings is substantial across\ngeographic regions, even when controlling for terrain properties. Data:\nhuggingface.co/M3LEO, Code: github.com/spaceml-org/M3LEO.",
      "tldr_zh": "本文介绍了 M3LEO 数据集，这是一个多模态、多标签的地球观测数据集，整合了 Interferometric SAR（包括极化、干涉和相干数据）以及 Multispectral Data 来自 Sentinel-1 和 Sentinel-2 的图像，还包含地形辅助数据如土地使用。数据集覆盖约 17M 个 4x4 km 数据块，跨越六个多样化的地理区域，并提供了一个基于 PyTorch Lightning 和 Hydra 的灵活框架，支持机器学习在地球观测中的应用。研究发现，即使控制地形属性，自监督 embeddings 在不同区域间存在显著分布偏移，这有助于解决 SAR 数据处理中的挑战。工具和数据可通过 Hugging Face 和 GitHub 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4; I.4.6; I.4.8; I.4.9; I.5; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04230v2",
      "published_date": "2024-06-06 16:30:41 UTC",
      "updated_date": "2024-10-31 13:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:56:39.700763"
    },
    {
      "arxiv_id": "2406.04229v1",
      "title": "The CLRS-Text Algorithmic Reasoning Language Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Larisa Markeeva",
        "Sean McLeish",
        "Borja Ibarz",
        "Wilfried Bounsi",
        "Olga Kozlova",
        "Alex Vitvitskyi",
        "Charles Blundell",
        "Tom Goldstein",
        "Avi Schwarzschild",
        "Petar Veličković"
      ],
      "abstract": "Eliciting reasoning capabilities from language models (LMs) is a critical\ndirection on the path towards building intelligent systems. Most recent studies\ndedicated to reasoning focus on out-of-distribution performance on\nprocedurally-generated synthetic benchmarks, bespoke-built to evaluate specific\nskills only. This trend makes results hard to transfer across publications,\nslowing down progress. Three years ago, a similar issue was identified and\nrectified in the field of neural algorithmic reasoning, with the advent of the\nCLRS benchmark. CLRS is a dataset generator comprising graph execution traces\nof classical algorithms from the Introduction to Algorithms textbook. Inspired\nby this, we propose CLRS-Text -- a textual version of these algorithmic traces.\nOut of the box, CLRS-Text is capable of procedurally generating trace data for\nthirty diverse, challenging algorithmic tasks across any desirable input\ndistribution, while offering a standard pipeline in which any additional\nalgorithmic tasks may be created in the benchmark. We fine-tune and evaluate\nvarious LMs as generalist executors on this benchmark, validating prior work\nand revealing a novel, interesting challenge for the LM reasoning community.\nOur code is available at\nhttps://github.com/google-deepmind/clrs/tree/master/clrs/_src/clrs_text.",
      "tldr_zh": "本研究针对语言模型（LMs）推理能力的评估问题，指出现有基准测试过于专注于特定技能，导致结果不易通用。论文提出 CLRS-Text 基准，这是一个基于文本的算法跟踪数据集生成器，灵感来源于经典 CLRS 基准，可为 30 个多样化算法任务生成执行痕迹，支持任意输入分布并允许扩展新任务。作者通过微调和评估各种 LMs，在 CLRS-Text 上验证了先前研究，并揭示了 LMs 在算法推理方面的全新挑战，为构建更通用的智能系统提供了一个标准评估框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DS",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint, under review. Comments welcome",
      "pdf_url": "http://arxiv.org/pdf/2406.04229v1",
      "published_date": "2024-06-06 16:29:25 UTC",
      "updated_date": "2024-06-06 16:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:56:50.344641"
    },
    {
      "arxiv_id": "2406.04220v4",
      "title": "BEADs: Bias Evaluation Across Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Shaina Raza",
        "Mizanur Rahman",
        "Michael R. Zhang"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have greatly enhanced\nnatural language processing (NLP) applications. Nevertheless, these models\noften inherit biases from their training data. Despite the availability of\nvarious datasets for bias detection, most are limited to one or two NLP tasks\n(typically classification or evaluation) and lack comprehensive evaluations\nacross a broader range of NLP tasks. To address this gap, we introduce the Bias\nEvaluations Across Domains BEADs dataset, designed to support a wide array of\nNLP tasks, including text classification, token classification, bias\nquantification, and benign language generation. A key focus of this paper is\nthe gold label dataset that is annotated by GPT4 for scalabilty and verified by\nexperts to ensure high reliability. BEADs provides data for both fine-tuning,\nincluding classification and language generation tasks, and for evaluating\nLLMs. Our findings indicate that BEADs effectively identifies numerous biases\nwhen fine-tuned on this dataset. It also reduces biases when used for\nfine-tuning language generation task, while preserving language quality. The\nresults also reveal some prevalent demographic biases in LLMs when BEADs is\nused for evaluation in demographic task. We provide the BEADs dataset for\ndetecting biases in various domains, and this dataset is readily usable for\nresponsible AI development and application. The dataset can be accessed at\nhttps://huggingface.co/datasets/shainar/BEAD .",
      "tldr_zh": "这篇论文引入了BEADs数据集，用于评估大型语言模型（LLMs）在不同领域的偏见问题，旨在弥补现有数据集仅限于一两个NLP任务（如分类或评估）的局限性。BEADs支持多种任务，包括文本分类、标记分类、偏见量化以及无害语言生成，并采用GPT4标注金标准标签并经专家验证以确保可靠性。该数据集可用于LLMs的微调和评估，实验发现微调后能有效识别和减少偏见，同时维持语言质量，并在人口统计任务中揭示LLMs的常见人口统计偏见。BEADs数据集可访问https://huggingface.co/datasets/shainar/BEAD，用于推动负责任的AI开发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2406.04220v4",
      "published_date": "2024-06-06 16:18:30 UTC",
      "updated_date": "2024-12-24 15:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:57:04.528068"
    },
    {
      "arxiv_id": "2406.04215v1",
      "title": "mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans",
      "title_zh": "翻译失败",
      "authors": [
        "Yusuke Sakai",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "It is very challenging to curate a dataset for language-specific knowledge\nand common sense in order to evaluate natural language understanding\ncapabilities of language models. Due to the limitation in the availability of\nannotators, most current multilingual datasets are created through translation,\nwhich cannot evaluate such language-specific aspects. Therefore, we propose\nMultilingual CommonsenseQA (mCSQA) based on the construction process of CSQA\nbut leveraging language models for a more efficient construction, e.g., by\nasking LM to generate questions/answers, refine answers and verify QAs followed\nby reduced human efforts for verification. Constructed dataset is a benchmark\nfor cross-lingual language-transfer capabilities of multilingual LMs, and\nexperimental results showed high language-transfer capabilities for questions\nthat LMs could easily solve, but lower transfer capabilities for questions\nrequiring deep knowledge or commonsense. This highlights the necessity of\nlanguage-specific datasets for evaluation and training. Finally, our method\ndemonstrated that multilingual LMs could create QA including language-specific\nknowledge, significantly reducing the dataset creation cost compared to manual\ncreation. The datasets are available at\nhttps://huggingface.co/datasets/yusuke1997/mCSQA.",
      "tldr_zh": "本研究提出mCSQA，一种多语言常识推理数据集，使用统一的创建策略结合语言模型(LMs)和人类努力，旨在评估语言模型的语言特定知识和常识理解能力。该策略通过让LMs生成问题/答案、精炼内容并验证QA，从而减少人工标注需求，并显著降低数据集创建成本。实验结果显示，多语言LMs在简单问题上表现出高跨语言转移能力，但在涉及深度知识或常识的问题上表现较差，这强调了语言特定数据集在评估和训练中的必要性。数据集已公开在Hugging Face上，可用于进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04215v1",
      "published_date": "2024-06-06 16:14:54 UTC",
      "updated_date": "2024-06-06 16:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:57:19.307547"
    },
    {
      "arxiv_id": "2406.04208v1",
      "title": "Aligning Agents like Large Language Models",
      "title_zh": "像大型语言模型一样对齐代理",
      "authors": [
        "Adam Jelley",
        "Yuhan Cao",
        "Dave Bignell",
        "Sam Devlin",
        "Tabish Rashid"
      ],
      "abstract": "Training agents to behave as desired in complex 3D environments from\nhigh-dimensional sensory information is challenging. Imitation learning from\ndiverse human behavior provides a scalable approach for training an agent with\na sensible behavioral prior, but such an agent may not perform the specific\nbehaviors of interest when deployed. To address this issue, we draw an analogy\nbetween the undesirable behaviors of imitation learning agents and the\nunhelpful responses of unaligned large language models (LLMs). We then\ninvestigate how the procedure for aligning LLMs can be applied to aligning\nagents in a 3D environment from pixels. For our analysis, we utilize an\nacademically illustrative part of a modern console game in which the human\nbehavior distribution is multi-modal, but we want our agent to imitate a single\nmode of this behavior. We demonstrate that we can align our agent to\nconsistently perform the desired mode, while providing insights and advice for\nsuccessfully applying this approach to training agents. Project webpage at\nhttps://adamjelley.github.io/aligning-agents-like-llms .",
      "tldr_zh": "这篇论文探讨了如何将大型语言模型(LLMs)的对齐技术应用到3D环境中的代理训练上，以解决模仿学习代理从多样人类行为中学习后，在部署时无法执行特定行为的挑战。作者通过类比LLMs的未对齐问题，提出了一种从像素级别的对齐流程，使代理能够专注于模仿人类行为分布中的单一模式。实验在现代游戏的简化场景中进行，证明了该方法能让代理一致执行期望行为，并提供了实际见解和建议，以提升代理训练的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04208v1",
      "published_date": "2024-06-06 16:05:45 UTC",
      "updated_date": "2024-06-06 16:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:57:30.220783"
    },
    {
      "arxiv_id": "2406.04202v1",
      "title": "Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chun-Hsien Lin",
        "Pu-Jen Cheng"
      ],
      "abstract": "With the development of large-scale Language Models (LLM), fine-tuning\npre-trained LLM has become a mainstream paradigm for solving downstream tasks\nof natural language processing. However, training a language model in the legal\nfield requires a large number of legal documents so that the language model can\nlearn legal terminology and the particularity of the format of legal documents.\nThe typical NLP approaches usually rely on many manually annotated data sets\nfor training. However, in the legal field application, it is difficult to\nobtain a large number of manually annotated data sets, which restricts the\ntypical method applied to the task of drafting legal documents. The\nexperimental results of this paper show that not only can we leverage a large\nnumber of annotation-free legal documents without Chinese word segmentation to\nfine-tune a large-scale language model, but more importantly, it can fine-tune\na pre-trained LLM on the local computer to achieve the generating legal\ndocument drafts task, and at the same time achieve the protection of\ninformation privacy and to improve information security issues.",
      "tldr_zh": "该论文探讨了使用Fine-Tuned Pre-Trained Large Language Model（微调预训练的大型语言模型）来处理法律文档起草任务的问题，强调了传统NLP方法依赖手动标注数据而导致的限制。研究提出了一种创新方法，利用无需标注的大量法律文档进行微调，避免了中文分词需求，并在本地计算机上实现文档生成草稿，从而保护信息隐私并提升信息安全。实验结果显示，这种方法有效适用于法律领域，证明了其在资源有限情况下的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12th International Conference on Software Engineering & Trends (SE\n  2024), April 27 ~ 28, 2024, Copenhagen, Denmark Volume Editors : David C.\n  Wyld, Dhinaharan Nagamalai (Eds) ISBN : 978-1-923107-24-3",
      "pdf_url": "http://arxiv.org/pdf/2406.04202v1",
      "published_date": "2024-06-06 16:00:20 UTC",
      "updated_date": "2024-06-06 16:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:57:52.279855"
    },
    {
      "arxiv_id": "2406.06607v1",
      "title": "Continuous Test-time Domain Adaptation for Efficient Fault Detection under Evolving Operating Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Han Sun",
        "Kevin Ammann",
        "Stylianos Giannoulakis",
        "Olga Fink"
      ],
      "abstract": "Fault detection is crucial in industrial systems to prevent failures and\noptimize performance by distinguishing abnormal from normal operating\nconditions. Data-driven methods have been gaining popularity for fault\ndetection tasks as the amount of condition monitoring data from complex\nindustrial systems increases. Despite these advances, early fault detection\nremains a challenge under real-world scenarios. The high variability of\noperating conditions and environments makes it difficult to collect\ncomprehensive training datasets that can represent all possible operating\nconditions, especially in the early stages of system operation. Furthermore,\nthese variations often evolve over time, potentially leading to entirely new\ndata distributions in the future that were previously unseen. These challenges\nprevent direct knowledge transfer across different units and over time, leading\nto the distribution gap between training and testing data and inducing\nperformance degradation of those methods in real-world scenarios. To overcome\nthis, our work introduces a novel approach for continuous test-time domain\nadaptation. This enables early-stage robust anomaly detection by addressing\ndomain shifts and limited data representativeness issues. We propose a\nTest-time domain Adaptation Anomaly Detection (TAAD) framework that separates\ninput variables into system parameters and measurements, employing two domain\nadaptation modules to independently adapt to each input category. This method\nallows for effective adaptation to evolving operating conditions and is\nparticularly beneficial in systems with scarce data. Our approach, tested on a\nreal-world pump monitoring dataset, shows significant improvements over\nexisting domain adaptation methods in fault detection, demonstrating enhanced\naccuracy and reliability.",
      "tldr_zh": "本文针对工业系统中操作条件演变的挑战，提出了一种Continuous Test-time Domain Adaptation方法，用于高效的早期故障检测，以解决训练和测试数据分布差距问题。该方法引入了Test-time Domain Adaptation Anomaly Detection (TAAD)框架，将输入变量分为系统参数和测量，并使用两个独立的域适应模块分别进行适应，从而在数据稀缺场景下实现有效的域移位处理。在真实泵监测数据集上的实验表明，该方法显著提高了故障检测的准确性和可靠性，优于现有域适应技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages including references",
      "pdf_url": "http://arxiv.org/pdf/2406.06607v1",
      "published_date": "2024-06-06 15:53:14 UTC",
      "updated_date": "2024-06-06 15:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:57:55.443161"
    },
    {
      "arxiv_id": "2406.04388v2",
      "title": "Single Exposure Quantitative Phase Imaging with a Conventional Microscope using Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel della Maggiora",
        "Luis Alberto Croquevielle",
        "Harry Horsley",
        "Thomas Heinis",
        "Artur Yakimovich"
      ],
      "abstract": "Phase imaging is gaining importance due to its applications in fields like\nbiomedical imaging and material characterization. In biomedical applications,\nit can provide quantitative information missing in label-free microscopy\nmodalities. One of the most prominent methods in phase quantification is the\nTransport-of-Intensity Equation (TIE). TIE often requires multiple acquisitions\nat different defocus distances, which is not always feasible in a clinical\nsetting. To address this issue, we propose to use chromatic aberrations to\ninduce the required through-focus images with a single exposure, effectively\ngenerating a through-focus stack. Since the defocus distance induced by the\naberrations is small, conventional TIE solvers are insufficient to address the\nresulting artifacts. We propose Zero-Mean Diffusion, a modified version of\ndiffusion models designed for quantitative image prediction, and train it with\nsynthetic data to ensure robust phase retrieval. Our contributions offer an\nalternative TIE approach that leverages chromatic aberrations, achieving\naccurate single-exposure phase measurement with white light and thus improving\nthe efficiency of phase imaging. Moreover, we present a new class of diffusion\nmodels that are well-suited for quantitative data and have a sound theoretical\nbasis. To validate our approach, we employ a widespread brightfield microscope\nequipped with a commercially available color camera. We apply our model to\nclinical microscopy of patients' urine, obtaining accurate phase measurements.",
      "tldr_zh": "本研究针对相位成像在生物医学成像中的应用，提出了一种利用传统显微镜实现单曝光定量相位成像的方法，以解决 Transport-of-Intensity Equation (TIE) 需要多次采集的局限性。作者通过利用色差在单次曝光中生成通过焦堆栈，并开发了 Zero-Mean Diffusion，一种修改后的扩散模型，用于处理小离焦距离引起的伪像，并通过合成数据训练确保相位检索的鲁棒性。该方法不仅实现了白光下的准确相位测量，还引入了适用于定量数据的全新扩散模型类，并在临床显微镜上验证，如对患者尿液样本的精确相位分析，从而提高了相位成像的效率和实用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.optics"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04388v2",
      "published_date": "2024-06-06 15:44:24 UTC",
      "updated_date": "2024-12-20 15:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:58:18.924165"
    },
    {
      "arxiv_id": "2406.04184v2",
      "title": "Shield Synthesis for LTL Modulo Theories",
      "title_zh": "翻译失败",
      "authors": [
        "Andoni Rodriguez",
        "Guy Amir",
        "Davide Corsi",
        "Cesar Sanchez",
        "Guy Katz"
      ],
      "abstract": "In recent years, Machine Learning (ML) models have achieved remarkable\nsuccess in various domains. However, these models also tend to demonstrate\nunsafe behaviors, precluding their deployment in safety-critical systems. To\ncope with this issue, ample research focuses on developing methods that\nguarantee the safe behaviour of a given ML model. A prominent example is\nshielding which incorporates an external component (a ``shield'') that blocks\nunwanted behavior. Despite significant progress, shielding suffers from a main\nsetback: it is currently geared towards properties encoded solely in\npropositional logics (e.g., LTL) and is unsuitable for richer logics. This, in\nturn, limits the widespread applicability of shielding in many real-world\nsystems. In this work, we address this gap, and extend shielding to LTL modulo\ntheories, by building upon recent advances in reactive synthesis modulo\ntheories. This allowed us to develop a novel approach for generating shields\nconforming to complex safety specifications in these more expressive, logics.\nWe evaluated our shields and demonstrate their ability to handle rich data with\ntemporal dynamics. To the best of our knowledge, this is the first approach for\nsynthesizing shields for such expressivity.",
      "tldr_zh": "本文提出了一种针对 LTL Modulo Theories 的 Shield Synthesis 方法，以解决机器学习（ML）模型在安全关键系统中的不安全行为问题。现有 shielding 技术仅限于命题逻辑（如 LTL），无法处理更丰富的逻辑规范；为此，该方法利用 reactive synthesis modulo theories 的最新进展，开发了生成符合复杂安全规格的 shields 的新框架。实验结果显示，该方法能够有效处理包含时间动态的丰富数据，并首次实现了这种表达性逻辑下的 shielding 合成。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.LO",
      "comment": "To appear in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.04184v2",
      "published_date": "2024-06-06 15:40:29 UTC",
      "updated_date": "2025-02-14 15:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:58:18.732713"
    },
    {
      "arxiv_id": "2406.04175v2",
      "title": "Confabulation: The Surprising Value of Large Language Model Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Peiqi Sui",
        "Eamon Duede",
        "Sophie Wu",
        "Richard Jean So"
      ],
      "abstract": "This paper presents a systematic defense of large language model (LLM)\nhallucinations or 'confabulations' as a potential resource instead of a\ncategorically negative pitfall. The standard view is that confabulations are\ninherently problematic and AI research should eliminate this flaw. In this\npaper, we argue and empirically demonstrate that measurable semantic\ncharacteristics of LLM confabulations mirror a human propensity to utilize\nincreased narrativity as a cognitive resource for sense-making and\ncommunication. In other words, it has potential value. Specifically, we analyze\npopular hallucination benchmarks and reveal that hallucinated outputs display\nincreased levels of narrativity and semantic coherence relative to veridical\noutputs. This finding reveals a tension in our usually dismissive\nunderstandings of confabulation. It suggests, counter-intuitively, that the\ntendency for LLMs to confabulate may be intimately associated with a positive\ncapacity for coherent narrative-text generation.",
      "tldr_zh": "这篇论文为大型语言模型(LLM)的幻觉(confabulations)辩护，认为它们并非完全负面，而是可能作为一种认知资源用于意义构建和沟通。作者分析了流行幻觉基准，发现幻觉输出相对于真实输出显示出更高的叙述性(narrativity)和语义连贯性(semantic coherence)。这些特征类似于人类的认知倾向，揭示了LLM在生成连贯叙述方面的潜在优势。最终，论文挑战了传统观点，建议AI研究应重新评估confabulations的价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Forthcoming at ACL2024 main conference. 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2406.04175v2",
      "published_date": "2024-06-06 15:32:29 UTC",
      "updated_date": "2024-06-25 18:37:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:58:41.339241"
    },
    {
      "arxiv_id": "2406.04170v4",
      "title": "Element-wise Multiplication Based Deeper Physics-Informed Neural Networks",
      "title_zh": "基于逐元素乘法的更深层物理信息神经网络",
      "authors": [
        "Feilong Jiang",
        "Xiaonan Hou",
        "Min Xia"
      ],
      "abstract": "As a promising framework for resolving partial differential equations (PDEs),\nPhysics-Informed Neural Networks (PINNs) have received widespread attention\nfrom industrial and scientific fields. However, lack of expressive ability and\ninitialization pathology issues are found to prevent the application of PINNs\nin complex PDEs. In this work, we propose Deeper Physics-Informed Neural\nNetwork (Deeper-PINN) to resolve these issues. The element-wise multiplication\noperation is adopted to transform features into high-dimensional, non-linear\nspaces. Benefiting from element-wise multiplication operation, Deeper-PINNs can\nalleviate the initialization pathologies of PINNs and enhance the expressive\ncapability of PINNs. The proposed structure is verified on various benchmarks.\nThe results show that Deeper-PINNs can effectively resolve the initialization\npathology and exhibit strong expressive ability.",
      "tldr_zh": "本研究针对 Physics-Informed Neural Networks (PINNs) 在解决 partial differential equations (PDEs) 时存在的表达能力不足和初始化问题，提出了一种改进框架——Deeper-PINNs。Deeper-PINNs 通过 element-wise multiplication 操作将特征转换为高维非线性空间，从而缓解初始化病理并增强 PINNs 的表达能力。该方法在多种基准测试中验证，展示了显著的性能提升和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04170v4",
      "published_date": "2024-06-06 15:27:52 UTC",
      "updated_date": "2024-09-11 20:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:58:42.701184"
    },
    {
      "arxiv_id": "2406.06606v2",
      "title": "Prototypical Reward Network for Data-Efficient RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Jinghan Zhang",
        "Xiting Wang",
        "Yiqiao Jin",
        "Changyu Chen",
        "Xinhao Zhang",
        "Kunpeng Liu"
      ],
      "abstract": "The reward model for Reinforcement Learning from Human Feedback (RLHF) has\nproven effective in fine-tuning Large Language Models (LLMs). Notably,\ncollecting human feedback for RLHF can be resource-intensive and lead to\nscalability issues for LLMs and complex tasks. Our proposed framework Proto-RM\nleverages prototypical networks to enhance reward models under limited human\nfeedback. By enabling stable and reliable structural learning from fewer\nsamples, Proto-RM significantly enhances LLMs' adaptability and accuracy in\ninterpreting human preferences. Extensive experiments on various datasets\ndemonstrate that Proto-RM significantly improves the performance of reward\nmodels and LLMs in human feedback tasks, achieving comparable and usually\nbetter results than traditional methods, while requiring significantly less\ndata. in data-limited scenarios. This research offers a promising direction for\nenhancing the efficiency of reward models and optimizing the fine-tuning of\nlanguage models under restricted feedback conditions.",
      "tldr_zh": "这篇论文针对 Reinforcement Learning from Human Feedback (RLHF) 中收集人类反馈资源密集的问题，提出了一种数据高效框架 Prototypical Reward Network (Proto-RM)。Proto-RM 利用 prototypical networks 进行稳定可靠的结构化学习，使 Large Language Models (LLMs) 能够在更少的样本下提升对人类偏好的适应性和准确性。实验在多种数据集上证明，Proto-RM 显著提高了奖励模型的性能，与传统方法相比通常更优，同时大幅减少了所需数据，为数据有限场景下的语言模型微调提供了高效方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06606v2",
      "published_date": "2024-06-06 15:23:30 UTC",
      "updated_date": "2024-07-07 16:29:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:59:05.431875"
    },
    {
      "arxiv_id": "2406.04156v1",
      "title": "Pointer-Guided Pre-Training: Infusing Large Language Models with Paragraph-Level Contextual Awareness",
      "title_zh": "指针指导预训练：向大型语言模型注入段落级别的上下文感知",
      "authors": [
        "Lars Hillebrand",
        "Prabhupad Pradhan",
        "Christian Bauckhage",
        "Rafet Sifa"
      ],
      "abstract": "We introduce \"pointer-guided segment ordering\" (SO), a novel pre-training\ntechnique aimed at enhancing the contextual understanding of paragraph-level\ntext representations in large language models. Our methodology leverages a\nself-attention-driven pointer network to restore the original sequence of\nshuffled text segments, addressing the challenge of capturing the structural\ncoherence and contextual dependencies within documents. This pre-training\napproach is complemented by a fine-tuning methodology that incorporates dynamic\nsampling, augmenting the diversity of training instances and improving sample\nefficiency for various downstream applications. We evaluate our method on a\ndiverse set of datasets, demonstrating its efficacy in tasks requiring\nsequential text classification across scientific literature and financial\nreporting domains. Our experiments show that pointer-guided pre-training\nsignificantly enhances the model's ability to understand complex document\nstructures, leading to state-of-the-art performance in downstream\nclassification tasks.",
      "tldr_zh": "本研究引入了“pointer-guided segment ordering”（SO），一种新型预训练技术，用于提升大语言模型对段落级文本表示的上下文理解。该方法利用自注意力驱动的指针网络恢复乱序文本段落的原始顺序，从而更好地捕捉文档的结构连贯性和上下文依赖，并通过动态采样增强细调过程的训练多样性和样本效率。在科学文献和财务报告等下游顺序文本分类任务上，实验结果显示，该预训练方法显著提高了模型理解复杂文档结构的能力，并实现了最先进的分类性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 3 figures, 5 tables, accepted at ECML-PKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04156v1",
      "published_date": "2024-06-06 15:17:51 UTC",
      "updated_date": "2024-06-06 15:17:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:59:09.761181"
    },
    {
      "arxiv_id": "2406.04155v1",
      "title": "Improving Physics-Augmented Continuum Neural Radiance Field-Based Geometry-Agnostic System Identification with Lagrangian Particle Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Takuhiro Kaneko"
      ],
      "abstract": "Geometry-agnostic system identification is a technique for identifying the\ngeometry and physical properties of an object from video sequences without any\ngeometric assumptions. Recently, physics-augmented continuum neural radiance\nfields (PAC-NeRF) has demonstrated promising results for this technique by\nutilizing a hybrid Eulerian-Lagrangian representation, in which the geometry is\nrepresented by the Eulerian grid representations of NeRF, the physics is\ndescribed by a material point method (MPM), and they are connected via\nLagrangian particles. However, a notable limitation of PAC-NeRF is that its\nperformance is sensitive to the learning of the geometry from the first frames\nowing to its two-step optimization. First, the grid representations are\noptimized with the first frames of video sequences, and then the physical\nproperties are optimized through video sequences utilizing the fixed\nfirst-frame grid representations. This limitation can be critical when learning\nof the geometric structure is difficult, for example, in a few-shot (sparse\nview) setting. To overcome this limitation, we propose Lagrangian particle\noptimization (LPO), in which the positions and features of particles are\noptimized through video sequences in Lagrangian space. This method allows for\nthe optimization of the geometric structure across the entire video sequence\nwithin the physical constraints imposed by the MPM. The experimental results\ndemonstrate that the LPO is useful for geometric correction and physical\nidentification in sparse-view settings.",
      "tldr_zh": "本文提出了一种改进方法，用于提升基于Physics-Augmented Continuum Neural Radiance Field (PAC-NeRF)的Geometry-Agnostic System Identification技术，该方法通过引入Lagrangian Particle Optimization (LPO)来解决PAC-NeRF对初始帧几何学习敏感的问题。PAC-NeRF采用混合Eulerian-Lagrangian表示，其中几何由Eulerian grid表示，物理属性由Material Point Method (MPM)描述，并通过Lagrangian particles连接，但其两步优化策略在sparse-view设置下表现不佳。LPO创新地将粒子位置和特征在Lagrangian空间中通过整个视频序列进行优化，从而在MPM的物理约束下实现几何结构的全面调整。实验结果显示，该方法显著提高了sparse-view条件下的几何校正和物理识别性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2024. Project page:\n  https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/lpo/",
      "pdf_url": "http://arxiv.org/pdf/2406.04155v1",
      "published_date": "2024-06-06 15:17:33 UTC",
      "updated_date": "2024-06-06 15:17:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:59:28.116134"
    },
    {
      "arxiv_id": "2406.04151v1",
      "title": "AgentGym: Evolving Large Language Model-based Agents across Diverse Environments",
      "title_zh": "AgentGym：跨越多样环境的基于大型语言模型的代理演化",
      "authors": [
        "Zhiheng Xi",
        "Yiwen Ding",
        "Wenxiang Chen",
        "Boyang Hong",
        "Honglin Guo",
        "Junzhe Wang",
        "Dingwen Yang",
        "Chenyang Liao",
        "Xin Guo",
        "Wei He",
        "Songyang Gao",
        "Lu Chen",
        "Rui Zheng",
        "Yicheng Zou",
        "Tao Gui",
        "Qi Zhang",
        "Xipeng Qiu",
        "Xuanjing Huang",
        "Zuxuan Wu",
        "Yu-Gang Jiang"
      ],
      "abstract": "Building generalist agents that can handle diverse tasks and evolve\nthemselves across different environments is a long-term goal in the AI\ncommunity. Large language models (LLMs) are considered a promising foundation\nto build such agents due to their generalized capabilities. Current approaches\neither have LLM-based agents imitate expert-provided trajectories step-by-step,\nrequiring human supervision, which is hard to scale and limits environmental\nexploration; or they let agents explore and learn in isolated environments,\nresulting in specialist agents with limited generalization. In this paper, we\ntake the first step towards building generally-capable LLM-based agents with\nself-evolution ability. We identify a trinity of ingredients: 1) diverse\nenvironments for agent exploration and learning, 2) a trajectory set to equip\nagents with basic capabilities and prior knowledge, and 3) an effective and\nscalable evolution method. We propose AgentGym, a new framework featuring a\nvariety of environments and tasks for broad, real-time, uni-format, and\nconcurrent agent exploration. AgentGym also includes a database with expanded\ninstructions, a benchmark suite, and high-quality trajectories across\nenvironments. Next, we propose a novel method, AgentEvol, to investigate the\npotential of agent self-evolution beyond previously seen data across tasks and\nenvironments. Experimental results show that the evolved agents can achieve\nresults comparable to SOTA models. We release the AgentGym suite, including the\nplatform, dataset, benchmark, checkpoints, and algorithm implementations. The\nAgentGym suite is available on https://github.com/WooooDyy/AgentGym.",
      "tldr_zh": "本研究旨在构建能够处理多样任务并在不同环境中自我进化的通用LLM-based代理，以解决现有方法依赖人为监督或导致代理专业化的局限。论文提出AgentGym框架，包括多样环境、基本轨迹集和基准测试套件，支持代理的广泛实时探索。作者开发了AgentEvol方法，实现代理超越已见数据的自我进化，通过实验验证，进化后的代理性能可与SOTA模型相当。AgentGym套件已开源，提供平台、数据集和算法实现，促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Project site: https://agentgym.github.io",
      "pdf_url": "http://arxiv.org/pdf/2406.04151v1",
      "published_date": "2024-06-06 15:15:41 UTC",
      "updated_date": "2024-06-06 15:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:59:35.687923"
    },
    {
      "arxiv_id": "2406.04149v1",
      "title": "Characterizing segregation in blast rock piles a deep-learning approach leveraging aerial image analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Chengeng Liu",
        "Sihong Liu",
        "Chaomin Shen",
        "Yupeng Gao",
        "Yuxuan Liu"
      ],
      "abstract": "Blasted rock material serves a critical role in various engineering\napplications, yet the phenomenon of segregation-where particle sizes vary\nsignificantly along the gradient of a quarry pile-presents challenges for\noptimizing quarry material storage and handling. This study introduces an\nadvanced image analysis methodology to characterize such segregation of rock\nfragments. The accurate delineation of detailed rock fragment size\ndistributions was achieved through the analysis of drone-captured imagery,\ncoupled with the application of an enhanced Unet semantic segmentation model\nintegrated with an expansion-based post-processing technique. The quarry slope\nwas stratified into four vertical sections, with the size distribution of each\nsection quantified via ellipsoid shape approximations. Our results disclose\npronounced vertical segregation patterns, with finer particles concentrated in\nthe upper slope regions and coarser particles in the lower. Utilizing relative\ncharacteristic diameters, we offered insight into the degree of segregation,\nthereby illustrating the spatial heterogeneity in fragment size more clearly.\nThe techniques outlined in this study deliver a scalable and accurate method\nfor assessing fragment size distribution, with the potential to better inform\nresource management and operational decisions in quarry management.",
      "tldr_zh": "这篇论文提出了一种利用无人机捕获图像的深度学习方法，来表征爆破岩石堆中的segregation现象，以优化采石场材料存储和处理。研究采用增强的Unet语义分割模型结合扩展后处理技术，对岩石碎片进行精确分割，并通过椭球形状近似量化四个垂直部分的碎片大小分布。结果揭示了明显的垂直segregation模式，即上部富含细颗粒而下部有较粗颗粒，并利用相对特征直径评估了空间异质性，为采石场资源管理和操作决策提供了一个可扩展、准确的评估工具。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04149v1",
      "published_date": "2024-06-06 15:13:56 UTC",
      "updated_date": "2024-06-06 15:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:59:48.303537"
    },
    {
      "arxiv_id": "2406.04145v1",
      "title": "Every Answer Matters: Evaluating Commonsense with Probabilistic Measures",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Cheng",
        "Michael Boratko",
        "Pranay Kumar Yelugam",
        "Tim O'Gorman",
        "Nalini Singh",
        "Andrew McCallum",
        "Xiang Lorraine Li"
      ],
      "abstract": "Large language models have demonstrated impressive performance on commonsense\ntasks; however, these tasks are often posed as multiple-choice questions,\nallowing models to exploit systematic biases. Commonsense is also inherently\nprobabilistic with multiple correct answers. The purpose of \"boiling water\"\ncould be making tea and cooking, but it also could be killing germs. Existing\ntasks do not capture the probabilistic nature of common sense. To this end, we\npresent commonsense frame completion (CFC), a new generative task that\nevaluates common sense via multiple open-ended generations. We also propose a\nmethod of probabilistic evaluation that strongly correlates with human\njudgments. Humans drastically outperform strong language model baselines on our\ndataset, indicating this approach is both a challenging and useful evaluation\nof machine common sense.",
      "tldr_zh": "本研究指出，大语言模型在常识任务上表现突出，但现有多项选择式评估易受系统偏差影响，且未能捕捉常识的概率性（如“煮水”的多个可能目的）。为了解决这一问题，论文引入了新的生成式任务 commonsense frame completion (CFC)，通过多个开放式生成来评估常识的多样性，并提出了一种概率评估方法，该方法与人类判断高度相关。实验结果显示，在该数据集上，人类显著优于强语言模型基线，证明了这一方法在评估机器常识方面的挑战性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2406.04145v1",
      "published_date": "2024-06-06 15:10:27 UTC",
      "updated_date": "2024-06-06 15:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:00:00.417617"
    },
    {
      "arxiv_id": "2406.04144v1",
      "title": "Redundancy-aware Action Spaces for Robot Learning",
      "title_zh": "冗余感知动作空间",
      "authors": [
        "Pietro Mazzaglia",
        "Nicholas Backshall",
        "Xiao Ma",
        "Stephen James"
      ],
      "abstract": "Joint space and task space control are the two dominant action modes for\ncontrolling robot arms within the robot learning literature. Actions in joint\nspace provide precise control over the robot's pose, but tend to suffer from\ninefficient training; actions in task space boast data-efficient training but\nsacrifice the ability to perform tasks in confined spaces due to limited\ncontrol over the full joint configuration. This work analyses the criteria for\ndesigning action spaces for robot manipulation and introduces ER (End-effector\nRedundancy), a novel action space formulation that, by addressing the\nredundancies present in the manipulator, aims to combine the advantages of both\njoint and task spaces, offering fine-grained comprehensive control with\noveractuated robot arms whilst achieving highly efficient robot learning. We\npresent two implementations of ER, ERAngle (ERA) and ERJoint (ERJ), and we show\nthat ERJ in particular demonstrates superior performance across multiple\nsettings, especially when precise control over the robot configuration is\nrequired. We validate our results both in simulated and real robotic\nenvironments.",
      "tldr_zh": "该论文分析了机器人学习中关节空间(joint space)和任务空间(task space)控制的优缺点，前者提供精确姿势控制但训练效率低，后者训练高效却难以在狭窄空间执行任务。作者引入了End-effector Redundancy (ER)动作空间公式，通过处理操纵器的冗余问题，结合两种空间的优势，实现细粒度的全面控制和高效的机器人学习。论文提出了ER的两个实现版本：ERAngle (ERA)和ERJoint (ERJ)，其中ERJ在多个场景中表现出色，尤其在需要精确机器人配置控制时。实验在模拟和真实机器人环境中验证了ERJ的优越性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Published in the RA-L journal",
      "pdf_url": "http://arxiv.org/pdf/2406.04144v1",
      "published_date": "2024-06-06 15:08:41 UTC",
      "updated_date": "2024-06-06 15:08:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:00:13.063865"
    },
    {
      "arxiv_id": "2406.04143v1",
      "title": "Do Language Models Understand Morality? Towards a Robust Detection of Moral Content",
      "title_zh": "语言模型理解道德吗？迈向鲁棒的道德内容",
      "authors": [
        "Luana Bulla",
        "Aldo Gangemi",
        "Misael Mongiovì"
      ],
      "abstract": "The task of detecting moral values in text has significant implications in\nvarious fields, including natural language processing, social sciences, and\nethical decision-making. Previously proposed supervised models often suffer\nfrom overfitting, leading to hyper-specialized moral classifiers that struggle\nto perform well on data from different domains. To address this issue, we\nintroduce novel systems that leverage abstract concepts and common-sense\nknowledge acquired from Large Language Models and Natural Language Inference\nmodels during previous stages of training on multiple data sources. By doing\nso, we aim to develop versatile and robust methods for detecting moral values\nin real-world scenarios. Our approach uses the GPT 3.5 model as a zero-shot\nready-made unsupervised multi-label classifier for moral values detection,\neliminating the need for explicit training on labeled data. We compare it with\na smaller NLI-based zero-shot model. The results show that the NLI approach\nachieves competitive results compared to the Davinci model. Furthermore, we\nconduct an in-depth investigation of the performance of supervised systems in\nthe context of cross-domain multi-label moral value detection. This involves\ntraining supervised models on different domains to explore their effectiveness\nin handling data from different sources and comparing their performance with\nthe unsupervised methods. Our contributions encompass a thorough analysis of\nboth supervised and unsupervised methodologies for cross-domain value\ndetection. We introduce the Davinci model as a state-of-the-art zero-shot\nunsupervised moral values classifier, pushing the boundaries of moral value\ndetection without the need for explicit training on labeled data. Additionally,\nwe perform a comparative evaluation of our approach with the supervised models,\nshedding light on their respective strengths and weaknesses.",
      "tldr_zh": "本研究探讨了语言模型在检测文本中道德内容（moral values）方面的理解能力，旨在解决现有监督模型（supervised models）的过拟合问题，导致其在跨领域数据上表现不佳。研究引入了一种新方法，利用Large Language Models（如GPT 3.5）作为零样本（zero-shot）多标签分类器（multi-label classifier），结合Natural Language Inference (NLI) 模型的常识知识，实现无需显式训练的鲁棒道德值检测。实验结果显示，NLI-based零样本方法与Davinci模型（基于GPT 3.5）相比表现出色，并在跨领域场景中竞争性强。总体贡献包括对监督和非监督方法（unsupervised methods）的深入比较，证明了零样本方法在道德内容检测中的潜力，为更可靠的跨领域应用提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04143v1",
      "published_date": "2024-06-06 15:08:16 UTC",
      "updated_date": "2024-06-06 15:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:00:23.945569"
    },
    {
      "arxiv_id": "2406.04136v1",
      "title": "Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Kumar Nigam",
        "Anurag Sharma",
        "Danush Khanna",
        "Noel Shallum",
        "Kripabandhu Ghosh",
        "Arnab Bhattacharya"
      ],
      "abstract": "In the era of Large Language Models (LLMs), predicting judicial outcomes\nposes significant challenges due to the complexity of legal proceedings and the\nscarcity of expert-annotated datasets. Addressing this, we introduce\n\\textbf{Pred}iction with \\textbf{Ex}planation (\\texttt{PredEx}), the largest\nexpert-annotated dataset for legal judgment prediction and explanation in the\nIndian context, featuring over 15,000 annotations. This groundbreaking corpus\nsignificantly enhances the training and evaluation of AI models in legal\nanalysis, with innovations including the application of instruction tuning to\nLLMs. This method has markedly improved the predictive accuracy and explanatory\ndepth of these models for legal judgments. We employed various\ntransformer-based models, tailored for both general and Indian legal contexts.\nThrough rigorous lexical, semantic, and expert assessments, our models\neffectively leverage \\texttt{PredEx} to provide precise predictions and\nmeaningful explanations, establishing it as a valuable benchmark for both the\nlegal profession and the NLP community.",
      "tldr_zh": "本研究介绍了PredEx，这是最大的专家标注数据集，包含超过15,000条印度法律判断预测和解释的标注，旨在解决Large Language Models (LLMs)面对法律复杂性和数据稀缺的挑战。研究采用instruction tuning技术对LLMs进行优化，并使用各种transformer-based模型来提升预测准确性和解释深度。实验结果显示，这些模型在词汇、语义和专家评估中表现出色，将PredEx确立为法律专业和NLP社区的重要基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04136v1",
      "published_date": "2024-06-06 14:57:48 UTC",
      "updated_date": "2024-06-06 14:57:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:00:34.936847"
    },
    {
      "arxiv_id": "2407.11990v1",
      "title": "Digital twins in sport: Concepts, Taxonomies, Challenges and Practical Potentials",
      "title_zh": "数字孪生在体育中：概念、分类学、挑战和实际潜力",
      "authors": [
        "Tilen Hliš",
        "Iztok Fister",
        "Iztok Fister Jr"
      ],
      "abstract": "Digital twins belong to ten of the strategic technology trends according to\nthe Gartner list from 2019, and have encountered a big expansion, especially\nwith the introduction of Industry 4.0. Sport, on the other hand, has become a\nconstant companion of the modern human suffering a lack of a healthy way of\nlife. The application of digital twins in sport has brought dramatic changes\nnot only in the domain of sport training, but also in managing athletes during\ncompetitions, searching for strategical solutions before and tactical solutions\nduring the games by coaches. In this paper, the domain of digital twins in\nsport is reviewed based on papers which have emerged in this area. At first,\nthe concept of a digital twin is discussed in general. Then, taxonomies of\ndigital twins are appointed. According to these taxonomies, the collection of\nrelevant papers is analyzed, and some real examples of digital twins are\nexposed. The review finishes with a discussion about how the digital twins\naffect changes in the modern sport disciplines, and what challenges and\nopportunities await the digital twins in the future.",
      "tldr_zh": "这篇论文探讨了数字孪生（Digital twins）在体育领域的应用，包括其概念、分类（Taxonomies）、挑战以及实际潜力。作者首先定义了数字孪生的总体概念，并基于相关分类分析了现有文献和真实案例，展示了其在体育训练、管理运动员以及战略决策中的变革作用。最终，论文讨论了数字孪生如何推动现代体育发展，同时指出了面临的挑战，如技术整合和数据隐私问题，以及未来的机遇，如与Industry 4.0的深度融合。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11990v1",
      "published_date": "2024-06-06 14:51:01 UTC",
      "updated_date": "2024-06-06 14:51:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:00:46.167924"
    },
    {
      "arxiv_id": "2406.04127v3",
      "title": "Are We Done with MMLU?",
      "title_zh": "翻译失败",
      "authors": [
        "Aryo Pradipta Gema",
        "Joshua Ong Jun Leang",
        "Giwon Hong",
        "Alessio Devoto",
        "Alberto Carlo Maria Mancino",
        "Rohit Saxena",
        "Xuanli He",
        "Yu Zhao",
        "Xiaotang Du",
        "Mohammad Reza Ghasemi Madani",
        "Claire Barale",
        "Robert McHardy",
        "Joshua Harris",
        "Jean Kaddour",
        "Emile van Krieken",
        "Pasquale Minervini"
      ],
      "abstract": "Maybe not. We identify and analyse errors in the popular Massive Multitask\nLanguage Understanding (MMLU) benchmark. Even though MMLU is widely adopted,\nour analysis demonstrates numerous ground truth errors that obscure the true\ncapabilities of LLMs. For example, we find that 57% of the analysed questions\nin the Virology subset contain errors. To address this issue, we introduce a\ncomprehensive framework for identifying dataset errors using a novel error\nannotation protocol. Then, we create MMLU-Redux, which is a subset of 5,700\nmanually re-annotated questions across all 57 MMLU subjects. We estimate that\n6.49% of MMLU questions contain errors. Using MMLU-Redux, we demonstrate\nsignificant discrepancies with the model performance metrics that were\noriginally reported. Our results strongly advocate for revising MMLU's\nerror-ridden questions to enhance its future utility and reliability as a\nbenchmark. https://huggingface.co/datasets/edinburgh-dawg/mmlu-redux-2.0.",
      "tldr_zh": "该研究质疑了流行基准 MMLU（Massive Multitask Language Understanding）的可靠性，通过分析发现其中许多地面真相错误，例如 Virology 子集中57%的题目有问题，导致对 LLMs（大型语言模型）能力的评估失真。作者引入了一个全面框架和新型错误注释协议，创建了 MMLU-Redux 子集，该子集包含5700个手动重新注释的问题，覆盖 MMLU 的57个主题，并估计整体6.49%的题目存在错误。使用 MMLU-Redux 后，模型性能指标与原报告显示显著差异，研究强烈建议修订这些错误题目，以提升 MMLU 作为基准的效用和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04127v3",
      "published_date": "2024-06-06 14:49:06 UTC",
      "updated_date": "2025-01-10 14:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:01:00.192932"
    },
    {
      "arxiv_id": "2406.04116v2",
      "title": "Promoting the Responsible Development of Speech Datasets for Mental Health and Neurological Disorders Research",
      "title_zh": "促进心理健康和神经系统疾病研究中语音",
      "authors": [
        "Eleonora Mancini",
        "Ana Tanevska",
        "Andrea Galassi",
        "Alessio Galatolo",
        "Federico Ruggeri",
        "Paolo Torroni"
      ],
      "abstract": "Current research in machine learning and artificial intelligence is largely\ncentered on modeling and performance evaluation, less so on data collection.\nHowever, recent research demonstrated that limitations and biases in data may\nnegatively impact trustworthiness and reliability. These aspects are\nparticularly impactful on sensitive domains such as mental health and\nneurological disorders, where speech data are used to develop AI applications\nfor patients and healthcare providers. In this paper, we chart the landscape of\navailable speech datasets for this domain, to highlight possible pitfalls and\nopportunities for improvement and promote fairness and diversity. We present a\ncomprehensive list of desiderata for building speech datasets for mental health\nand neurological disorders and distill it into an actionable checklist focused\non ethical concerns to foster more responsible research.",
      "tldr_zh": "这篇论文强调了在心理健康和神经疾病研究中，语音数据集（speech datasets）的开发需要更注重责任性，因为数据中的偏见和限制可能损害AI应用的可靠性和可信度。作者审视了现有语音数据集的景观，突出了潜在问题并探讨了改进机会，以促进公平性和多样性。具体贡献包括提出一套全面的期望列表（desiderata），并将其提炼成一个可操作的检查列表，聚焦于伦理关切，从而推动更负责任的机器学习（machine learning）和人工智能（artificial intelligence）研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.04116v2",
      "published_date": "2024-06-06 14:36:07 UTC",
      "updated_date": "2025-02-17 12:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:01:11.804694"
    },
    {
      "arxiv_id": "2406.06603v1",
      "title": "FPN-fusion: Enhanced Linear Complexity Time Series Forecasting Model",
      "title_zh": "FPN-fusion：增强的线性复杂度",
      "authors": [
        "Chu Li",
        "Pingjia Xiao",
        "Qiping Yuan"
      ],
      "abstract": "This study presents a novel time series prediction model, FPN-fusion,\ndesigned with linear computational complexity, demonstrating superior\npredictive performance compared to DLiner without increasing parameter count or\ncomputational demands. Our model introduces two key innovations: first, a\nFeature Pyramid Network (FPN) is employed to effectively capture time series\ndata characteristics, bypassing the traditional decomposition into trend and\nseasonal components. Second, a multi-level fusion structure is developed to\nintegrate deep and shallow features seamlessly. Empirically, FPN-fusion\noutperforms DLiner in 31 out of 32 test cases on eight open-source datasets,\nwith an average reduction of 16.8% in mean squared error (MSE) and 11.8% in\nmean absolute error (MAE). Additionally, compared to the transformer-based\nPatchTST, FPN-fusion achieves 10 best MSE and 15 best MAE results, using only\n8% of PatchTST's total computational load in the 32 test projects.",
      "tldr_zh": "这篇论文提出了FPN-fusion，一种线性计算复杂度的时间序列预测模型，它在不增加参数或计算需求的情况下，显著优于DLiner模型。模型的关键创新包括使用Feature Pyramid Network (FPN)来直接捕获时间序列数据特征，避免传统趋势和季节分解，以及开发多级融合结构以无缝整合深层和浅层特征。在实验中，FPN-fusion在8个开源数据集的32个测试案例中胜出31个，平均MSE减少16.8%、MAE减少11.8%，并仅使用PatchTST的8%计算负载，展示了高效的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "FPN,time series,fusion. arXiv admin note: text overlap with\n  arXiv:2401.03001 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2406.06603v1",
      "published_date": "2024-06-06 14:34:26 UTC",
      "updated_date": "2024-06-06 14:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:01:26.408696"
    },
    {
      "arxiv_id": "2406.04112v2",
      "title": "Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Can Yaras",
        "Peng Wang",
        "Laura Balzano",
        "Qing Qu"
      ],
      "abstract": "While overparameterization in machine learning models offers great benefits\nin terms of optimization and generalization, it also leads to increased\ncomputational requirements as model sizes grow. In this work, we show that by\nleveraging the inherent low-dimensional structures of data and compressible\ndynamics within the model parameters, we can reap the benefits of\noverparameterization without the computational burdens. In practice, we\ndemonstrate the effectiveness of this approach for deep low-rank matrix\ncompletion as well as fine-tuning language models. Our approach is grounded in\ntheoretical findings for deep overparameterized low-rank matrix recovery, where\nwe show that the learning dynamics of each weight matrix are confined to an\ninvariant low-dimensional subspace. Consequently, we can construct and train\ncompact, highly compressed factorizations possessing the same benefits as their\noverparameterized counterparts. In the context of deep matrix completion, our\ntechnique substantially improves training efficiency while retaining the\nadvantages of overparameterization. For language model fine-tuning, we propose\na method called \"Deep LoRA\", which improves the existing low-rank adaptation\n(LoRA) technique, leading to reduced overfitting and a simplified\nhyperparameter setup, while maintaining comparable efficiency. We validate the\neffectiveness of Deep LoRA on natural language tasks, particularly when\nfine-tuning with limited data. Our code is available at\nhttps://github.com/cjyaras/deep-lora-transformers.",
      "tldr_zh": "本研究探讨了深度过parameterized 模型在优化和泛化方面的优势，同时解决了其带来的高计算负担问题，通过利用数据和模型参数的低维结构及可压缩动态，实现过parameterized 的好处而不增加计算成本。作者证明了深度过parameterized low-rank 矩阵恢复的学习动态限制在低维子空间，从而构建紧凑、高度压缩的因子分解，并在深度矩阵补全中显著提升训练效率。论文提出“Deep LoRA”方法，改进现有 low-rank adaptation (LoRA) 技术，减少过拟合、简化超参数设置，并在有限数据下微调语言模型时表现出色，验证了其在自然语言任务中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML'24 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2406.04112v2",
      "published_date": "2024-06-06 14:29:49 UTC",
      "updated_date": "2024-06-10 02:05:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:01:37.957219"
    },
    {
      "arxiv_id": "2406.04103v1",
      "title": "Multistep Distillation of Diffusion Models via Moment Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Salimans",
        "Thomas Mensink",
        "Jonathan Heek",
        "Emiel Hoogeboom"
      ],
      "abstract": "We present a new method for making diffusion models faster to sample. The\nmethod distills many-step diffusion models into few-step models by matching\nconditional expectations of the clean data given noisy data along the sampling\ntrajectory. Our approach extends recently proposed one-step methods to the\nmulti-step case, and provides a new perspective by interpreting these\napproaches in terms of moment matching. By using up to 8 sampling steps, we\nobtain distilled models that outperform not only their one-step versions but\nalso their original many-step teacher models, obtaining new state-of-the-art\nresults on the Imagenet dataset. We also show promising results on a large\ntext-to-image model where we achieve fast generation of high resolution images\ndirectly in image space, without needing autoencoders or upsamplers.",
      "tldr_zh": "本文提出了一种通过时刻匹配（moment matching）进行多步蒸馏（multistep distillation）的方法，以加速扩散模型（diffusion models）的采样过程。该方法扩展了单步方法，通过匹配采样轨迹中给定噪声数据的干净数据条件期望，生成更高效的模型。实验显示，使用多达 8 个采样步骤的蒸馏模型不仅优于单步版本和原多步教师模型，在 Imagenet 数据集上取得新状态-of-the-art 结果，还在大型文本到图像模型上实现了直接生成高分辨率图像，而无需 autoencoders 或 upsamplers。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04103v1",
      "published_date": "2024-06-06 14:20:21 UTC",
      "updated_date": "2024-06-06 14:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:01:50.385985"
    },
    {
      "arxiv_id": "2406.04099v2",
      "title": "Enhancing Weather Predictions: Super-Resolution via Deep Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Martinů",
        "Petr Šimánek"
      ],
      "abstract": "This study investigates the application of deep-learning diffusion models for\nthe super-resolution of weather data, a novel approach aimed at enhancing the\nspatial resolution and detail of meteorological variables. Leveraging the\ncapabilities of diffusion models, specifically the SR3 and ResDiff\narchitectures, we present a methodology for transforming low-resolution weather\ndata into high-resolution outputs. Our experiments, conducted using the\nWeatherBench dataset, focus on the super-resolution of the two-meter\ntemperature variable, demonstrating the models' ability to generate detailed\nand accurate weather maps. The results indicate that the ResDiff model, further\nimproved by incorporating physics-based modifications, significantly\noutperforms traditional SR3 methods in terms of Mean Squared Error (MSE),\nStructural Similarity Index (SSIM), and Peak Signal-to-Noise Ratio (PSNR). This\nresearch highlights the potential of diffusion models in meteorological\napplications, offering insights into their effectiveness, challenges, and\nprospects for future advancements in weather prediction and climate analysis.",
      "tldr_zh": "本研究探讨了利用深度学习扩散模型（如SR3和ResDiff）来提升天气数据的超分辨率（super-resolution），旨在提高气象变量的空间分辨率和细节。该方法通过将低分辨率天气数据转化为高分辨率输出，并在WeatherBench数据集上针对两米温度变量进行实验。结果显示，改进后的ResDiff模型在Mean Squared Error (MSE)、Structural Similarity Index (SSIM)和Peak Signal-to-Noise Ratio (PSNR)指标上显著优于传统SR3方法。总体而言，此研究证明了扩散模型在气象应用中的潜力，并为天气预测和气候分析的未来发展提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04099v2",
      "published_date": "2024-06-06 14:15:12 UTC",
      "updated_date": "2024-08-30 08:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:02:00.557849"
    },
    {
      "arxiv_id": "2406.04093v1",
      "title": "Scaling and evaluating sparse autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Leo Gao",
        "Tom Dupré la Tour",
        "Henk Tillman",
        "Gabriel Goh",
        "Rajan Troll",
        "Alec Radford",
        "Ilya Sutskever",
        "Jan Leike",
        "Jeffrey Wu"
      ],
      "abstract": "Sparse autoencoders provide a promising unsupervised approach for extracting\ninterpretable features from a language model by reconstructing activations from\na sparse bottleneck layer. Since language models learn many concepts,\nautoencoders need to be very large to recover all relevant features. However,\nstudying the properties of autoencoder scaling is difficult due to the need to\nbalance reconstruction and sparsity objectives and the presence of dead\nlatents. We propose using k-sparse autoencoders [Makhzani and Frey, 2013] to\ndirectly control sparsity, simplifying tuning and improving the\nreconstruction-sparsity frontier. Additionally, we find modifications that\nresult in few dead latents, even at the largest scales we tried. Using these\ntechniques, we find clean scaling laws with respect to autoencoder size and\nsparsity. We also introduce several new metrics for evaluating feature quality\nbased on the recovery of hypothesized features, the explainability of\nactivation patterns, and the sparsity of downstream effects. These metrics all\ngenerally improve with autoencoder size. To demonstrate the scalability of our\napproach, we train a 16 million latent autoencoder on GPT-4 activations for 40\nbillion tokens. We release training code and autoencoders for open-source\nmodels, as well as a visualizer.",
      "tldr_zh": "本研究探讨了稀疏自编码器（sparse autoencoders）的缩放和评估方法，以从语言模型中提取可解释特征。研究者提出使用 k-sparse autoencoders 来直接控制稀疏性，简化调优过程，并通过修改减少 dead latents 的出现，从而实现重建和稀疏性的更好平衡。实验结果显示，随着自编码器规模增大，scaling laws 清晰显现，且新引入的评估指标（如假设特征恢复、可解释性激活模式和下游效果稀疏性）均得到改善；最终，他们在 GPT-4 激活上训练了一个 1600 万潜变量的自编码器，并公开了训练代码和模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04093v1",
      "published_date": "2024-06-06 14:10:12 UTC",
      "updated_date": "2024-06-06 14:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:02:13.958255"
    },
    {
      "arxiv_id": "2406.06601v1",
      "title": "A Human-in-the-Loop Approach to Improving Cross-Text Prosody Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Himanshu Maurya",
        "Atli Sigurgeirsson"
      ],
      "abstract": "Text-To-Speech (TTS) prosody transfer models can generate varied prosodic\nrenditions, for the same text, by conditioning on a reference utterance. These\nmodels are trained with a reference that is identical to the target utterance.\nBut when the reference utterance differs from the target text, as in cross-text\nprosody transfer, these models struggle to separate prosody from text,\nresulting in reduced perceived naturalness. To address this, we propose a\nHuman-in-the-Loop (HitL) approach. HitL users adjust salient correlates of\nprosody to make the prosody more appropriate for the target text, while\nmaintaining the overall reference prosodic effect. Human adjusted renditions\nmaintain the reference prosody while being rated as more appropriate for the\ntarget text $57.8\\%$ of the time. Our analysis suggests that limited user\neffort suffices for these improvements, and that closeness in the latent\nreference space is not a reliable prosodic similarity metric for the cross-text\ncondition.",
      "tldr_zh": "该研究针对 Text-To-Speech (TTS) 模型在 cross-text prosody transfer 中的问题提出了一种 Human-in-the-Loop (HitL) 方法，该问题导致模型难以分离 prosody 和文本，从而降低生成的自然度。HitL 方法允许用户调整 prosody 的显著相关因素，使其更适合目标文本，同时保留参考 prosody 的整体效果。实验结果显示，人类调整后的版本在 57.8% 的情况下被评为更适合目标文本，且仅需有限的用户努力即可实现改善。该分析还发现，latent reference space 的接近度并非可靠的 prosodic 相似性指标，为提升 TTS prosody transfer 提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "4 pages (+1 references), 4 figures, to be presented at Interspeech\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06601v1",
      "published_date": "2024-06-06 14:01:53 UTC",
      "updated_date": "2024-06-06 14:01:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:02:26.599836"
    },
    {
      "arxiv_id": "2406.04089v1",
      "title": "On Limitation of Transformer for Learning HMMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachen Hu",
        "Qinghua Liu",
        "Chi Jin"
      ],
      "abstract": "Despite the remarkable success of Transformer-based architectures in various\nsequential modeling tasks, such as natural language processing, computer\nvision, and robotics, their ability to learn basic sequential models, like\nHidden Markov Models (HMMs), is still unclear. This paper investigates the\nperformance of Transformers in learning HMMs and their variants through\nextensive experimentation and compares them to Recurrent Neural Networks\n(RNNs). We show that Transformers consistently underperform RNNs in both\ntraining speed and testing accuracy across all tested HMM models. There are\neven challenging HMM instances where Transformers struggle to learn, while RNNs\ncan successfully do so. Our experiments further reveal the relation between the\ndepth of Transformers and the longest sequence length it can effectively learn,\nbased on the types and the complexity of HMMs. To address the limitation of\ntransformers in modeling HMMs, we demonstrate that a variant of the\nChain-of-Thought (CoT), called $\\textit{block CoT}$ in the training phase, can\nhelp transformers to reduce the evaluation error and to learn longer sequences\nat a cost of increasing the training time. Finally, we complement our empirical\nfindings by theoretical results proving the expressiveness of transformers in\napproximating HMMs with logarithmic depth.",
      "tldr_zh": "该研究探讨了Transformer在学习Hidden Markov Models (HMMs)时的局限性，通过广泛实验发现，Transformer在训练速度和测试准确率上均逊色于Recurrent Neural Networks (RNNs)，甚至在某些复杂HMM实例中无法有效学习，而RNNs则能成功应对。实验还揭示了Transformer的深度与其能有效处理的序列长度之间存在关系，取决于HMM的类型和复杂度。为缓解这一问题，论文提出Chain-of-Thought (CoT)的变体——block CoT，在训练阶段能帮助Transformer减少评估错误并学习更长的序列，但会增加训练时间。最后，理论分析证明了Transformer以对数深度即可近似HMMs，提供了解释其表达能力的依据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04089v1",
      "published_date": "2024-06-06 13:59:51 UTC",
      "updated_date": "2024-06-06 13:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:02:39.644750"
    },
    {
      "arxiv_id": "2406.10244v3",
      "title": "GLINT-RU: Gated Lightweight Intelligent Recurrent Units for Sequential Recommender Systems",
      "title_zh": "GLINT-RU：门控轻量级智能循环单元用于序列推荐系统",
      "authors": [
        "Sheng Zhang",
        "Maolin Wang",
        "Wanyu Wang",
        "Jingtong Gao",
        "Xiangyu Zhao",
        "Yu Yang",
        "Xuetao Wei",
        "Zitao Liu",
        "Tong Xu"
      ],
      "abstract": "Transformer-based models have gained significant traction in sequential\nrecommender systems (SRSs) for their ability to capture user-item interactions\neffectively. However, these models often suffer from high computational costs\nand slow inference. Meanwhile, existing efficient SRS approaches struggle to\nembed high-quality semantic and positional information into latent\nrepresentations. To tackle these challenges, this paper introduces GLINT-RU, a\nlightweight and efficient SRS leveraging a single-layer dense selective Gated\nRecurrent Units (GRU) module to accelerate inference. By incorporating a dense\nselective gate, GLINT-RU adaptively captures temporal dependencies and\nfine-grained positional information, generating high-quality latent\nrepresentations. Additionally, a parallel mixing block infuses fine-grained\npositional features into user-item interactions, enhancing both recommendation\nquality and efficiency. Extensive experiments on three datasets demonstrate\nthat GLINT-RU achieves superior prediction accuracy and inference speed,\noutperforming baselines based on RNNs, Transformers, MLPs, and SSMs. These\nresults establish GLINT-RU as a powerful and efficient solution for SRSs.",
      "tldr_zh": "这篇论文提出 GLINT-RU，一种轻量级高效的顺序推荐系统（Sequential Recommender Systems, SRSs），利用单层密集选择门控 GRU（Gated Recurrent Units）模块来解决 Transformer 模型的高计算成本和慢速推理问题。GLINT-RU 通过密集选择门自适应捕获时间依赖性和细粒度位置信息，并结合并行混合块注入位置特征，以生成高质量的潜在表示并提升用户-物品交互。实验在三个数据集上表明，GLINT-RU 在预测准确性和推理速度上均优于基于 RNNs、Transformers、MLPs 和 SSMs 的基线模型，提供了一个强大的高效解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10244v3",
      "published_date": "2024-06-06 13:55:55 UTC",
      "updated_date": "2025-04-12 17:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:02:50.753884"
    },
    {
      "arxiv_id": "2406.04082v1",
      "title": "Leveraging automatic strategy discovery to teach people how to select better projects",
      "title_zh": "翻译失败",
      "authors": [
        "Lovis Heindrich",
        "Falk Lieder"
      ],
      "abstract": "The decisions of individuals and organizations are often suboptimal because\nnormative decision strategies are too demanding in the real world. Recent work\nsuggests that some errors can be prevented by leveraging artificial\nintelligence to discover and teach prescriptive decision strategies that take\npeople's constraints into account. So far, this line of research has been\nlimited to simplified decision problems. This article is the first to extend\nthis approach to a real-world decision problem, namely project selection. We\ndevelop a computational method (MGPS) that automatically discovers project\nselection strategies that are optimized for real people and develop an\nintelligent tutor that teaches the discovered strategies. We evaluated MGPS on\na computational benchmark and tested the intelligent tutor in a training\nexperiment with two control conditions. MGPS outperformed a state-of-the-art\nmethod and was more computationally efficient. Moreover, the intelligent tutor\nsignificantly improved people's decision strategies. Our results indicate that\nour method can improve human decision-making in naturalistic settings similar\nto real-world project selection, a first step towards applying strategy\ndiscovery to the real world.",
      "tldr_zh": "本研究针对人们在现实决策中常因策略过于复杂而导致次优选择的问题，提出使用AI自动发现并教授量身定制的决策策略，以改善项目选择。该方法包括开发MGPS计算模型，该模型自动优化项目选择策略并结合智能导师进行教学。实验结果显示，MGPS在计算基准上超越了现有方法，且更高效；同时，智能导师显著提升了参与者的决策表现，为将策略发现应用于真实世界项目选择铺平了道路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04082v1",
      "published_date": "2024-06-06 13:51:44 UTC",
      "updated_date": "2024-06-06 13:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:03:01.107746"
    },
    {
      "arxiv_id": "2406.04081v1",
      "title": "Bootstrapping Expectiles in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Clavier",
        "Emmanuel Rachelson",
        "Erwan Le Pennec",
        "Matthieu Geist"
      ],
      "abstract": "Many classic Reinforcement Learning (RL) algorithms rely on a Bellman\noperator, which involves an expectation over the next states, leading to the\nconcept of bootstrapping. To introduce a form of pessimism, we propose to\nreplace this expectation with an expectile. In practice, this can be very\nsimply done by replacing the $L_2$ loss with a more general expectile loss for\nthe critic. Introducing pessimism in RL is desirable for various reasons, such\nas tackling the overestimation problem (for which classic solutions are double\nQ-learning or the twin-critic approach of TD3) or robust RL (where transitions\nare adversarial). We study empirically these two cases. For the overestimation\nproblem, we show that the proposed approach, ExpectRL, provides better results\nthan a classic twin-critic. On robust RL benchmarks, involving changes of the\nenvironment, we show that our approach is more robust than classic RL\nalgorithms. We also introduce a variation of ExpectRL combined with domain\nrandomization which is competitive with state-of-the-art robust RL agents.\nEventually, we also extend \\ExpectRL with a mechanism for choosing\nautomatically the expectile value, that is the degree of pessimism",
      "tldr_zh": "本文提出在 Reinforcement Learning 中，使用 expectile 替换 Bellman operator 中的期望，以引入悲观机制，旨在解决过估计问题和提升算法鲁棒性。具体方法是将批评者的 L2 损失改为 expectile 损失，开发出 ExpectRL 算法，该算法在实验中比传统双批评者方法（如双 Q-learning 或 TD3）提供更好的性能。实验结果显示，ExpectRL 在过估计问题和鲁棒 RL 基准上表现出色，并通过结合域随机化，与最先进鲁棒 RL 代理竞争；此外，还扩展了自动选择 expectile 值（即悲观程度）的机制，以进一步优化应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04081v1",
      "published_date": "2024-06-06 13:51:39 UTC",
      "updated_date": "2024-06-06 13:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:03:17.498738"
    },
    {
      "arxiv_id": "2406.06600v5",
      "title": "HORAE: A Domain-Agnostic Language for Automated Service Regulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yutao Sun",
        "Mingshuai Chen",
        "Tiancheng Zhao",
        "Kangjia Zhao",
        "He Li",
        "Jintao Chen",
        "Zhongyi Wang",
        "Liqiang Lu",
        "Xinkui Zhao",
        "Shuiguang Deng",
        "Jianwei Yin"
      ],
      "abstract": "Artificial intelligence is rapidly encroaching on the field of service\nregulation. However, existing AI-based regulation techniques are often tailored\nto specific application domains and thus are difficult to generalize in an\nautomated manner. This paper presents Horae, a unified specification language\nfor modeling (multimodal) regulation rules across a diverse set of domains. We\nshowcase how Horae facilitates an intelligent service regulation pipeline by\nfurther exploiting a fine-tuned large language model named RuleGPT that\nautomates the Horae modeling process, thereby yielding an end-to-end framework\nfor fully automated intelligent service regulation. The feasibility and\neffectiveness of our framework are demonstrated over a benchmark of various\nreal-world regulation domains. In particular, we show that our open-sourced,\nfine-tuned RuleGPT with 7B parameters suffices to outperform GPT-3.5 and\nperform on par with GPT-4o.",
      "tldr_zh": "本研究针对现有AI服务监管技术难以泛化的问题，提出HORAE，一种领域无关的统一规范语言，用于跨不同领域的多模态监管规则建模。HORAE通过结合微调的大型语言模型RuleGPT，自动化监管规则的建模过程，实现端到端的智能服务监管框架。实验在各种真实世界监管领域的基准上验证了框架的有效性，RuleGPT的7B参数模型超过了GPT-3.5，并在性能上与GPT-4o相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Full version of IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.06600v5",
      "published_date": "2024-06-06 13:44:57 UTC",
      "updated_date": "2025-05-09 07:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:03:31.021083"
    },
    {
      "arxiv_id": "2406.04070v1",
      "title": "Batch-in-Batch: a new adversarial training framework for initial perturbation and sample selection",
      "title_zh": "翻译失败",
      "authors": [
        "Yinting Wu",
        "Pai Peng",
        "Bo Cai",
        "Le Li",
        "."
      ],
      "abstract": "Adversarial training methods commonly generate independent initial\nperturbation for adversarial samples from a simple uniform distribution, and\nobtain the training batch for the classifier without selection. In this work,\nwe propose a simple yet effective training framework called Batch-in-Batch (BB)\nto enhance models robustness. It involves specifically a joint construction of\ninitial values that could simultaneously generates $m$ sets of perturbations\nfrom the original batch set to provide more diversity for adversarial samples;\nand also includes various sample selection strategies that enable the trained\nmodels to have smoother losses and avoid overconfident outputs. Through\nextensive experiments on three benchmark datasets (CIFAR-10, SVHN, CIFAR-100)\nwith two networks (PreActResNet18 and WideResNet28-10) that are used in both\nthe single-step (Noise-Fast Gradient Sign Method, N-FGSM) and multi-step\n(Projected Gradient Descent, PGD-10) adversarial training, we show that models\ntrained within the BB framework consistently have higher adversarial accuracy\nacross various adversarial settings, notably achieving over a 13% improvement\non the SVHN dataset with an attack radius of 8/255 compared to the N-FGSM\nbaseline model. Furthermore, experimental analysis of the efficiency of both\nthe proposed initial perturbation method and sample selection strategies\nvalidates our insights. Finally, we show that our framework is cost-effective\nin terms of computational resources, even with a relatively large value of $m$.",
      "tldr_zh": "本文提出了一种名为Batch-in-Batch (BB)的新型对抗训练框架，用于优化初始扰动和样本选择，以提升模型鲁棒性。该框架通过联合构建初始值从原始批量生成多个扰动集（m组），增加对抗样本的多样性，并引入各种样本选择策略，使模型损失更平滑并避免过度自信。在CIFAR-10、SVHN和CIFAR-100数据集上的实验中，使用PreActResNet18和WideResNet28-10网络进行N-FGSM和PGD-10对抗训练，结果显示BB框架显著提高了对抗准确率，例如在SVHN数据集上比N-FGSM基线提升超过13%。此外，该框架在计算资源方面高效，即使m值较大也保持成本有效。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04070v1",
      "published_date": "2024-06-06 13:34:43 UTC",
      "updated_date": "2024-06-06 13:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:03:44.698740"
    },
    {
      "arxiv_id": "2406.04064v1",
      "title": "Ask LLMs Directly, \"What shapes your bias?\": Measuring Social Bias in Large Language Models",
      "title_zh": "直接询问 LLMs，「是什么塑造了你的偏见？」：测量大型语言模型中的社会偏见",
      "authors": [
        "Jisu Shin",
        "Hoyun Song",
        "Huije Lee",
        "Soyeong Jeong",
        "Jong C. Park"
      ],
      "abstract": "Social bias is shaped by the accumulation of social perceptions towards\ntargets across various demographic identities. To fully understand such social\nbias in large language models (LLMs), it is essential to consider the composite\nof social perceptions from diverse perspectives among identities. Previous\nstudies have either evaluated biases in LLMs by indirectly assessing the\npresence of sentiments towards demographic identities in the generated text or\nmeasuring the degree of alignment with given stereotypes. These methods have\nlimitations in directly quantifying social biases at the level of distinct\nperspectives among identities. In this paper, we aim to investigate how social\nperceptions from various viewpoints contribute to the development of social\nbias in LLMs. To this end, we propose a novel strategy to intuitively quantify\nthese social perceptions and suggest metrics that can evaluate the social\nbiases within LLMs by aggregating diverse social perceptions. The experimental\nresults show the quantitative demonstration of the social attitude in LLMs by\nexamining social perception. The analysis we conducted shows that our proposed\nmetrics capture the multi-dimensional aspects of social bias, enabling a\nfine-grained and comprehensive investigation of bias in LLMs.",
      "tldr_zh": "这篇论文探讨了如何直接测量大型语言模型(LLMs)中的社会偏见(Social Bias)，强调需要整合各种视角下的社会认知来全面理解偏见形成。作者提出了一种新策略，通过直观量化这些社会认知并开发聚合指标，来评估LLMs中偏见的多维度方面。实验结果表明，该方法能够细粒度和全面地捕捉社会态度，从而为更精确的偏见分析提供量化依据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04064v1",
      "published_date": "2024-06-06 13:32:09 UTC",
      "updated_date": "2024-06-06 13:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:04:05.674939"
    },
    {
      "arxiv_id": "2406.04055v1",
      "title": "Leveraging SPD Matrices on Riemannian Manifolds in Quantum Classical Hybrid Models for Structural Health Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Azadeh Alavi",
        "Sanduni Jayasinghe"
      ],
      "abstract": "Realtime finite element modeling of bridges assists modern structural health\nmonitoring systems by providing comprehensive insights into structural\nintegrity. This capability is essential for ensuring the safe operation of\nbridges and preventing sudden catastrophic failures. However, FEM computational\ncost and the need for realtime analysis pose significant challenges.\nAdditionally, the input data is a 7 dimensional vector, while the output is a\n1017 dimensional vector, making accurate and efficient analysis particularly\ndifficult. In this study, we propose a novel hybrid quantum classical\nMultilayer Perceptron pipeline leveraging Symmetric Positive Definite matrices\nand Riemannian manifolds for effective data representation. To maintain the\nintegrity of the qubit structure, we utilize SPD matrices, ensuring data\nrepresentation is well aligned with the quantum computational framework.\nAdditionally, the method leverages polynomial feature expansion to capture\nnonlinear relationships within the data. The proposed pipeline combines\nclassical fully connected neural network layers with quantum circuit layers to\nenhance model performance and efficiency. Our experiments focused on various\nconfigurations of such hybrid models to identify the optimal structure for\naccurate and efficient realtime analysis. The best performing model achieved a\nMean Squared Error of 0.00031, significantly outperforming traditional methods.",
      "tldr_zh": "本研究针对桥梁结构健康监测中的实时有限元建模问题，提出了一种新型量子-经典混合多层感知器（Multilayer Perceptron）管道，利用Symmetric Positive Definite (SPD) matrices和Riemannian manifolds进行高效数据表示，以解决计算成本高和输入输出维度不匹配的挑战。方法通过SPD matrices保持量子比特结构的完整性，并结合多项式特征扩展和经典全连接神经网络层与量子电路层，提升模型对非线性关系的捕捉能力。实验结果显示，最优配置的混合模型在实时分析中实现了均方误差（Mean Squared Error）仅为0.00031，显著优于传统方法，为结构健康监测提供了更准确且高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "3 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2406.04055v1",
      "published_date": "2024-06-06 13:21:28 UTC",
      "updated_date": "2024-06-06 13:21:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:04:08.069279"
    },
    {
      "arxiv_id": "2406.04052v2",
      "title": "Multivector Neurons: Better and Faster O(n)-Equivariant Clifford Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Liu",
        "David Ruhe",
        "Patrick Forré"
      ],
      "abstract": "Most current deep learning models equivariant to $O(n)$ or $SO(n)$ either\nconsider mostly scalar information such as distances and angles or have a very\nhigh computational complexity. In this work, we test a few novel message\npassing graph neural networks (GNNs) based on Clifford multivectors, structured\nsimilarly to other prevalent equivariant models in geometric deep learning. Our\napproach leverages efficient invariant scalar features while simultaneously\nperforming expressive learning on multivector representations, particularly\nthrough the use of the equivariant geometric product operator. By integrating\nthese elements, our methods outperform established efficient baseline models on\nan N-Body simulation task and protein denoising task while maintaining a high\nefficiency. In particular, we push the state-of-the-art error on the N-body\ndataset to 0.0035 (averaged over 3 runs); an 8% improvement over recent\nmethods. Our implementation is available on Github.",
      "tldr_zh": "本研究提出了一种基于 Clifford 多重向量的消息传递图神经网络（GNNs），旨在提升 O(n) 等变模型的性能，同时解决现有模型在标量信息处理和计算复杂度上的局限。方法通过整合高效的不变标量特征和等变的几何乘积运算符，对多重向量表示进行表达性学习，从而实现更高效的模型设计。在 N-Body 模拟任务和蛋白质去噪任务上，该模型优于现有基线，具体将 N-Body 数据集的错误率降低至 0.0035（较前方法提高 8%），并提供 GitHub 开源实现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04052v2",
      "published_date": "2024-06-06 13:17:44 UTC",
      "updated_date": "2024-07-10 11:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:04:21.633478"
    },
    {
      "arxiv_id": "2406.04046v3",
      "title": "ActionReasoningBench: Reasoning about Actions with and without Ramification Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Divij Handa",
        "Pavel Dolin",
        "Shrinidhi Kumbhar",
        "Tran Cao Son",
        "Chitta Baral"
      ],
      "abstract": "Reasoning about Actions and Change (RAC) has historically played a pivotal\nrole in solving foundational AI problems, such as the frame problem. It has\ndriven advancements in AI fields, such as non-monotonic and commonsense\nreasoning. RAC remains crucial for AI systems that operate in dynamic\nenvironments, engage in interactive scenarios, or rely on commonsense\nreasoning. Despite substantial advances made by Large Language Models (LLMs) in\nvarious AI domains, their performance in RAC remains underexplored. To address\nthis gap, we introduce a new diagnostic benchmark, ActionReasoningBench, which\nencompasses 8 domains and includes questions for up to 19 action sequences.\nThis benchmark rigorously evaluates LLMs across six key RAC dimensions: Fluent\nTracking, State Tracking, Action Executability, Effects of Actions, Numerical\nRAC, and Composite Questions. LLMs demonstrate average accuracy rates of\n73.55%, 65.63%, 58.73%, and 62.38% on the former four dimensions, which are\nfrequently discussed in RAC literature. However, the performance on the latter\ntwo dimensions, which introduce complex and novel reasoning questions, the\naverage performance of LLMs is lowered to 33.16% and 51.19%, respectively,\nreflecting a 17.9% performance decline. We also introduce new ramification\nconstraints to capture the indirect effects of actions, providing deeper\ninsights into RAC challenges. Our evaluation of state-of-the-art LLMs,\nincluding both open-source and commercial models, reveals challenges across all\nRAC dimensions, particularly in handling ramifications, with GPT-4o failing to\nsolve any question and o1-preview achieving a score of only 18.4%.",
      "tldr_zh": "本论文引入了ActionReasoningBench，一个新的诊断基准，用于评估大型语言模型（LLMs）在Reasoning about Actions and Change (RAC)领域的性能，包括动作推理及其间接影响。基准涵盖8个领域和多达19个动作序列，评估LLMs在六个关键维度上的表现：Fluent Tracking、State Tracking、Action Executability、Effects of Actions、Numerical RAC和Composite Questions。结果显示，LLMs在前四个维度的平均准确率较高（73.55%至62.38%），但在后两个维度上大幅下降至33.16%和51.19%，反映了17.9%的性能衰减；此外，引入的ramification constraints进一步揭示了LLMs在处理动作间接效果时的挑战，如GPT-4o完全无法解决相关问题，而o1-preview仅得18.4%。",
      "categories": [
        "cs.CC",
        "cs.AI"
      ],
      "primary_category": "cs.CC",
      "comment": "Accepted in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.04046v3",
      "published_date": "2024-06-06 13:15:37 UTC",
      "updated_date": "2025-03-02 23:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:04:34.320287"
    },
    {
      "arxiv_id": "2406.04039v1",
      "title": "Shaping History: Advanced Machine Learning Techniques for the Analysis and Dating of Cuneiform Tablets over Three Millennia",
      "title_zh": "翻译失败",
      "authors": [
        "Danielle Kapon",
        "Michael Fire",
        "Shai Gordin"
      ],
      "abstract": "Cuneiform tablets, emerging in ancient Mesopotamia around the late fourth\nmillennium BCE, represent one of humanity's earliest writing systems.\nCharacterized by wedge-shaped marks on clay tablets, these artifacts provided\ninsight into Mesopotamian civilization across various domains. Traditionally,\nthe analysis and dating of these tablets rely on subjective assessment of shape\nand writing style, leading to uncertainties in pinpointing their exact temporal\norigins. Recent advances in digitization have revolutionized the study of\ncuneiform by enhancing accessibility and analytical capabilities. Our research\nuniquely focuses on the silhouette of tablets as significant indicators of\ntheir historical periods, diverging from most studies that concentrate on\ntextual content. Utilizing an unprecedented dataset of over 94,000 images from\nthe Cuneiform Digital Library Initiative collection, we apply deep learning\nmethods to classify cuneiform tablets, covering over 3,000 years of history. By\nleveraging statistical, computational techniques, and generative modeling\nthrough Variational Auto-Encoders (VAEs), we achieve substantial advancements\nin the automatic classification of these ancient documents, focusing on the\ntablets' silhouettes as key predictors. Our classification approach begins with\na Decision Tree using height-to-width ratios and culminates with a ResNet50\nmodel, achieving a 61% macro F1-score for tablet silhouettes. Moreover, we\nintroduce novel VAE-powered tools to enhance explainability and enable\nresearchers to explore changes in tablet shapes across different eras and\ngenres. This research contributes to document analysis and diplomatics by\ndemonstrating the value of large-scale data analysis combined with statistical\nmethods. These insights offer valuable tools for historians and epigraphists,\nenriching our understanding of cuneiform tablets and the cultures that produced\nthem.",
      "tldr_zh": "本文研究利用先进的机器学习技术分析和定年楔形文字泥板(Cuneiform tablets)，聚焦于泥板的轮廓作为历史时期指标，而非传统的主观评估方法。基于超过94,000张图像的数据集，他们结合Decision Tree（使用高度宽度比）、ResNet50模型和Variational Auto-Encoders (VAEs)进行分类，实现了61%的宏F1-score。VAEs工具进一步增强了模型的可解释性，允许研究者探索泥板形状在不同时代和类型间的变化。该工作通过大规模数据分析和统计方法，为历史学家和铭文学家提供新工具，深化对古代美索不达米亚文明的理解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.SI",
        "I.4.10; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04039v1",
      "published_date": "2024-06-06 13:05:32 UTC",
      "updated_date": "2024-06-06 13:05:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:04:45.093839"
    },
    {
      "arxiv_id": "2406.04035v3",
      "title": "STEMO: Early Spatio-temporal Forecasting with Multi-Objective Reinforcement Learning",
      "title_zh": "STEMO：基于多目标强化学习的早期时空预测",
      "authors": [
        "Wei Shao",
        "Yufan Kang",
        "Ziyan Peng",
        "Xiao Xiao",
        "Lei Wang",
        "Yuhui Yang",
        "Flora D Salim"
      ],
      "abstract": "Accuracy and timeliness are indeed often conflicting goals in prediction\ntasks. Premature predictions may yield a higher rate of false alarms, whereas\ndelaying predictions to gather more information can render them too late to be\nuseful. In applications such as wildfires, crimes, and traffic jams, timely\nforecasting are vital for safeguarding human life and property. Consequently,\nfinding a balance between accuracy and timeliness is crucial. In this paper, we\npropose an early spatio-temporal forecasting model based on Multi-Objective\nreinforcement learning that can either implement an optimal policy given a\npreference or infer the preference based on a small number of samples. The\nmodel addresses two primary challenges: 1) enhancing the accuracy of early\nforecasting and 2) providing the optimal policy for determining the most\nsuitable prediction time for each area. Our method demonstrates superior\nperformance on three large-scale real-world datasets, surpassing existing\nmethods in early spatio-temporal forecasting tasks.",
      "tldr_zh": "该论文探讨了时空预测任务中准确性和及时性的冲突问题，强调在野火、犯罪和交通堵塞等应用中及时预测的重要性。研究提出了一种基于 Multi-Objective Reinforcement Learning 的早期时空预测模型（STEMO），该模型能根据用户偏好实现最优策略，或从少量样本中推断偏好。模型主要解决了两个挑战：提升早期预测的准确性，并为每个区域确定最佳预测时间策略。在三个大型真实世界数据集上的实验结果显示，该方法在早期时空预测任务中超过了现有方法的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted paper in KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04035v3",
      "published_date": "2024-06-06 13:03:51 UTC",
      "updated_date": "2024-06-18 09:16:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:04:56.755294"
    },
    {
      "arxiv_id": "2406.04029v2",
      "title": "Pre-trained Transformer Uncovers Meaningful Patterns in Human Mobility Data",
      "title_zh": "预训练的Transformer揭示了人类移动数据中的有意义模式",
      "authors": [
        "Alameen Najjar"
      ],
      "abstract": "We empirically demonstrate that a transformer pre-trained on country-scale\nunlabeled human mobility data learns embeddings capable, through fine-tuning,\nof developing a deep understanding of the target geography and its\ncorresponding mobility patterns. Utilizing an adaptation framework, we evaluate\nthe performance of our pre-trained embeddings in encapsulating a broad spectrum\nof concepts directly and indirectly related to human mobility. This includes\nbasic notions, such as geographic location and distance, and extends to more\ncomplex constructs, such as administrative divisions and land cover. Our\nextensive empirical analysis reveals a substantial performance boost gained\nfrom pre-training, reaching up to 38% in tasks such as tree-cover regression.\nWe attribute this result to the ability of the pre-training to uncover\nmeaningful patterns hidden in the raw data, beneficial for modeling relevant\nhigh-level concepts. The pre-trained embeddings emerge as robust\nrepresentations of regions and trajectories, potentially valuable for a wide\nrange of downstream applications.",
      "tldr_zh": "本研究使用预训练Transformer模型在国家规模的未标记人类移动数据上进行训练，生成嵌入表示，这些嵌入通过微调能够深入理解目标地理位置、距离、行政区划和土地覆盖等概念。实验结果显示，预训练带来的性能提升高达38%，例如在树覆盖回归任务中，归功于模型发掘原始数据中隐藏的有意义模式。总体而言，这种鲁棒的嵌入表示为区域和轨迹建模提供了宝贵资源，可应用于广泛的下游任务。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to the 8th IEEE International Workshop on Big Spatial Data @\n  IEEE BigData 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04029v2",
      "published_date": "2024-06-06 12:59:46 UTC",
      "updated_date": "2024-12-12 03:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:05:07.157053"
    },
    {
      "arxiv_id": "2406.04028v1",
      "title": "Contrastive Sparse Autoencoders for Interpreting Planning of Chess-Playing Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yoann Poupart"
      ],
      "abstract": "AI led chess systems to a superhuman level, yet these systems heavily rely on\nblack-box algorithms. This is unsustainable in ensuring transparency to the\nend-user, particularly when these systems are responsible for sensitive\ndecision-making. Recent interpretability work has shown that the inner\nrepresentations of Deep Neural Networks (DNNs) were fathomable and contained\nhuman-understandable concepts. Yet, these methods are seldom contextualised and\nare often based on a single hidden state, which makes them unable to interpret\nmulti-step reasoning, e.g. planning. In this respect, we propose contrastive\nsparse autoencoders (CSAE), a novel framework for studying pairs of game\ntrajectories. Using CSAE, we are able to extract and interpret concepts that\nare meaningful to the chess-agent plans. We primarily focused on a qualitative\nanalysis of the CSAE features before proposing an automated feature taxonomy.\nFurthermore, to evaluate the quality of our trained CSAE, we devise sanity\nchecks to wave spurious correlations in our results.",
      "tldr_zh": "该论文针对AI国际象棋系统依赖黑箱算法的问题，提出了一种新框架Contrastive Sparse Autoencoders (CSAE)，用于解释Deep Neural Networks (DNNs)中棋手代理的规划过程。CSAE通过对比稀疏自编码器分析成对的游戏轨迹，能够提取并解释对代理计划有意义的、可理解概念，从而解决现有方法在多步推理（如规划）中的局限性。研究者首先进行了定性分析，然后开发了自动特征分类法，以更好地理解这些概念。为评估CSAE的质量，他们设计了sanity checks来排除虚假相关性，确保结果的可靠性和透明度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Worskhop on Interpretable Policies in Reinforcement Learning @\n  RLC-2024, 18 pages and 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04028v1",
      "published_date": "2024-06-06 12:57:31 UTC",
      "updated_date": "2024-06-06 12:57:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:05:20.156733"
    },
    {
      "arxiv_id": "2406.04024v2",
      "title": "American Sign Language Handshapes Reflect Pressures for Communicative Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Kayo Yin",
        "Terry Regier",
        "Dan Klein"
      ],
      "abstract": "Communicative efficiency is a key topic in linguistics and cognitive\npsychology, with many studies demonstrating how the pressure to communicate\nwith minimal effort guides the form of natural language. However, this\nphenomenon is rarely explored in signed languages. This paper shows how\nhandshapes in American Sign Language (ASL) reflect these efficiency pressures\nand provides new evidence of communicative efficiency in the visual-gestural\nmodality.\n  We focus on hand configurations in native ASL signs and signs borrowed from\nEnglish to compare efficiency pressures from both ASL and English usage. First,\nwe develop new methodologies to quantify the articulatory effort needed to\nproduce handshapes and the perceptual effort required to recognize them. Then,\nwe analyze correlations between communicative effort and usage statistics in\nASL or English. Our findings reveal that frequent ASL handshapes are easier to\nproduce and that pressures for communicative efficiency mostly come from ASL\nusage, rather than from English lexical borrowing.",
      "tldr_zh": "本研究探讨了沟通效率(communicative efficiency)在美国手语(ASL)中的体现，揭示了手形如何在视觉-手势模式下受最小努力压力的影响。研究者开发了新方法来量化手形的 articulatory effort（制作努力）和 perceptual effort（感知努力），并比较了本土 ASL 手势与从英语借用的手势。结果显示，频繁使用的 ASL 手形更容易制作，且效率压力主要源于 ASL 的自身使用，而非英语词汇借用，这为理解手语的语言演化提供了新证据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.04024v2",
      "published_date": "2024-06-06 12:46:21 UTC",
      "updated_date": "2024-06-10 13:45:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:05:33.234760"
    },
    {
      "arxiv_id": "2406.03997v1",
      "title": "HackAtari: Atari Learning Environments for Robust and Continual Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Quentin Delfosse",
        "Jannis Blüml",
        "Bjarne Gregori",
        "Kristian Kersting"
      ],
      "abstract": "Artificial agents' adaptability to novelty and alignment with intended\nbehavior is crucial for their effective deployment. Reinforcement learning (RL)\nleverages novelty as a means of exploration, yet agents often struggle to\nhandle novel situations, hindering generalization. To address these issues, we\npropose HackAtari, a framework introducing controlled novelty to the most\ncommon RL benchmark, the Atari Learning Environment. HackAtari allows us to\ncreate novel game scenarios (including simplification for curriculum learning),\nto swap the game elements' colors, as well as to introduce different reward\nsignals for the agent. We demonstrate that current agents trained on the\noriginal environments include robustness failures, and evaluate HackAtari's\nefficacy in enhancing RL agents' robustness and aligning behavior through\nexperiments using C51 and PPO. Overall, HackAtari can be used to improve the\nrobustness of current and future RL algorithms, allowing Neuro-Symbolic RL,\ncurriculum RL, causal RL, as well as LLM-driven RL. Our work underscores the\nsignificance of developing interpretable in RL agents.",
      "tldr_zh": "这篇论文提出了 HackAtari 框架，用于增强 Atari Learning Environment 的鲁棒性和持续 Reinforcement Learning（RL），以帮助代理更好地适应新颖情况并提高行为对齐。HackAtari 通过引入受控新颖性，包括创建新游戏场景（支持 Curriculum Learning）、交换游戏元素颜色以及修改奖励信号，来解决现有 RL 代理的泛化问题。实验使用 C51 和 PPO 算法展示了该框架显著提升代理的鲁棒性，并揭示了原环境中的鲁棒性失败。总体上，HackAtari 可应用于 Neuro-Symbolic RL、Causal RL 和 LLM-driven RL 等领域，强调了开发可解释 RL 代理的重要性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 main pages, 4 pages references, 19 pages of appendix",
      "pdf_url": "http://arxiv.org/pdf/2406.03997v1",
      "published_date": "2024-06-06 12:17:05 UTC",
      "updated_date": "2024-06-06 12:17:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:05:47.586092"
    },
    {
      "arxiv_id": "2406.03995v1",
      "title": "AC4MPC: Actor-Critic Reinforcement Learning for Nonlinear Model Predictive Control",
      "title_zh": "翻译失败",
      "authors": [
        "Rudolf Reiter",
        "Andrea Ghezzi",
        "Katrin Baumgärtner",
        "Jasper Hoffmann",
        "Robert D. McAllister",
        "Moritz Diehl"
      ],
      "abstract": "\\Ac{MPC} and \\ac{RL} are two powerful control strategies with, arguably,\ncomplementary advantages. In this work, we show how actor-critic \\ac{RL}\ntechniques can be leveraged to improve the performance of \\ac{MPC}. The \\ac{RL}\ncritic is used as an approximation of the optimal value function, and an actor\nroll-out provides an initial guess for primal variables of the \\ac{MPC}. A\nparallel control architecture is proposed where each \\ac{MPC} instance is\nsolved twice for different initial guesses. Besides the actor roll-out\ninitialization, a shifted initialization from the previous solution is used.\nThereafter, the actor and the critic are again used to approximately evaluate\nthe infinite horizon cost of these trajectories. The control actions from the\nlowest-cost trajectory are applied to the system at each time step. We\nestablish that the proposed algorithm is guaranteed to outperform the original\n\\ac{RL} policy plus an error term that depends on the accuracy of the critic\nand decays with the horizon length of the \\ac{MPC} formulation. Moreover, we do\nnot require globally optimal solutions for these guarantees to hold. The\napproach is demonstrated on an illustrative toy example and an \\ac{AD}\novertaking scenario.",
      "tldr_zh": "本文提出 AC4MPC 方法，将 actor-critic 强化学习(RL) 与非线性模型预测控制(MPC) 整合，以提升控制性能。具体而言，使用 RL critic 近似最优价值函数，actor rollout 作为 MPC 的初始猜测，并采用并行控制架构对不同初始猜测求解两次，随后选择成本最低的轨迹应用于系统。研究证明，该算法在性能上保证优于原 RL 策略，加上一个依赖 critic 准确性和 MPC 地平线长度的误差项，且不需全局最优解；在玩具示例和自动驾驶(AD) 超车场景中进行了验证。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03995v1",
      "published_date": "2024-06-06 12:15:51 UTC",
      "updated_date": "2024-06-06 12:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:05:59.846699"
    },
    {
      "arxiv_id": "2406.03947v1",
      "title": "Weight-based Decomposition: A Case for Bilinear MLPs",
      "title_zh": "翻译失败",
      "authors": [
        "Michael T. Pearce",
        "Thomas Dooms",
        "Alice Rigg"
      ],
      "abstract": "Gated Linear Units (GLUs) have become a common building block in modern\nfoundation models. Bilinear layers drop the non-linearity in the \"gate\" but\nstill have comparable performance to other GLUs. An attractive quality of\nbilinear layers is that they can be fully expressed in terms of a third-order\ntensor and linear operations. Leveraging this, we develop a method to decompose\nthe bilinear tensor into a set of sparsely interacting eigenvectors that show\npromising interpretability properties in preliminary experiments for shallow\nimage classifiers (MNIST) and small language models (Tiny Stories). Since the\ndecomposition is fully equivalent to the model's original computations,\nbilinear layers may be an interpretability-friendly architecture that helps\nconnect features to the model weights. Application of our method may not be\nlimited to pretrained bilinear models since we find that language models such\nas TinyLlama-1.1B can be finetuned into bilinear variants.",
      "tldr_zh": "该论文探讨了 Bilinear MLPs 的优势，特别指出它们相对于 Gated Linear Units (GLUs) 去除了门控非线性却保持了类似性能，并可通过三阶张量和线性操作表示。研究提出了一种 Weight-based Decomposition 方法，将 bilinear tensor 分解成一组稀疏交互的特征向量，在浅层图像分类器 (MNIST) 和小型语言模型 (Tiny Stories) 的初步实验中展示了良好的可解释性。实验结果表明，这种分解完全等价于模型的原始计算，并可扩展到其他模型，如 TinyLlama-1.1B 通过微调转化为 bilinear 变体，从而为连接特征与模型权重的可解释性友好架构提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03947v1",
      "published_date": "2024-06-06 10:46:51 UTC",
      "updated_date": "2024-06-06 10:46:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:06:11.067838"
    },
    {
      "arxiv_id": "2406.06599v1",
      "title": "Anna Karenina Strikes Again: Pre-Trained LLM Embeddings May Favor High-Performing Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Abigail Gurin Schleifer",
        "Beata Beigman Klebanov",
        "Moriah Ariely",
        "Giora Alexandron"
      ],
      "abstract": "Unsupervised clustering of student responses to open-ended questions into\nbehavioral and cognitive profiles using pre-trained LLM embeddings is an\nemerging technique, but little is known about how well this captures\npedagogically meaningful information. We investigate this in the context of\nstudent responses to open-ended questions in biology, which were previously\nanalyzed and clustered by experts into theory-driven Knowledge Profiles (KPs).\nComparing these KPs to ones discovered by purely data-driven clustering\ntechniques, we report poor discoverability of most KPs, except for the ones\nincluding the correct answers. We trace this \"discoverability bias\" to the\nrepresentations of KPs in the pre-trained LLM embeddings space.",
      "tldr_zh": "本研究探讨了使用预训练LLM embeddings对学生开放式问题回答进行无监督聚类，以识别行为和认知配置文件（Knowledge Profiles, KPs）的有效性。研究者将数据驱动聚类结果与专家定义的理论驱动KPs进行比较，发现大多数KPs难以被发现，仅包含正确答案的KPs例外。这种现象源于预训练LLM embeddings空间中的“discoverability bias”。这些发现突显了LLM在教育应用中可能偏向高绩效学习者的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages (not including bibliography), Appendix and 10 tables.\n  Accepted to the 19th Workshop on Innovative Use of NLP for Building\n  Educational Applications, Co-located with NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06599v1",
      "published_date": "2024-06-06 10:36:48 UTC",
      "updated_date": "2024-06-06 10:36:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:06:21.745315"
    },
    {
      "arxiv_id": "2406.16911v1",
      "title": "Evaluating the Influence of Temporal Context on Automatic Mouse Sleep Staging through the Application of Human Models",
      "title_zh": "通过应用人类模型评估时间上下文对自动小鼠睡眠分期的影响",
      "authors": [
        "Javier García Ciudad",
        "Morten Mørup",
        "Birgitte Rahbek Kornum",
        "Alexander Neergaard Zahid"
      ],
      "abstract": "In human sleep staging models, augmenting the temporal context of the input\nto the range of tens of minutes has recently demonstrated performance\nimprovement. In contrast, the temporal context of mouse sleep staging models is\ntypically in the order of tens of seconds. While long-term time patterns are\nless clear in mouse sleep, increasing the temporal context further than that of\nthe current mouse sleep staging models might still result in a performance\nincrease, given that the current methods only model very short term patterns.\nIn this study, we examine the influence of increasing the temporal context in\nmouse sleep staging up to 15 minutes in three mouse cohorts using two recent\nand high-performing human sleep staging models that account for long-term\ndependencies. These are compared to two prominent mouse sleep staging models\nthat use a local context of 12 s and 20 s, respectively. An increase in context\nup to 28 s is observed to have a positive impact on sleep stage classification\nperformance, especially in REM sleep. However, the impact is limited for longer\ncontext windows. One of the human sleep scoring models, L-SeqSleepNet,\noutperforms both mouse models in all cohorts. This suggests that mouse sleep\nstaging can benefit from more temporal context than currently used.",
      "tldr_zh": "本研究评估了增加时间上下文（temporal context）对自动老鼠睡眠分期（sleep staging）的影响，通过应用两个先进的人类睡眠分期模型，将上下文扩展至15分钟，并在三个老鼠队列上进行测试。相比传统的老鼠模型（使用12s和20s的局部上下文），结果显示将时间上下文增加到28s能显著改善睡眠阶段分类性能，尤其是对REM sleep的准确率。人类模型L-SeqSleepNet在所有队列中均优于现有老鼠模型，表明老鼠睡眠分期可从更长的temporal context中受益，但超过28s的扩展效果有限。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Accepted for publication in the 46th Annual International Conference\n  of the IEEE Engineering in Medicine and Biology Society (2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.16911v1",
      "published_date": "2024-06-06 10:07:19 UTC",
      "updated_date": "2024-06-06 10:07:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:06:35.096131"
    },
    {
      "arxiv_id": "2406.03919v2",
      "title": "Vectorized Conditional Neural Fields: A Framework for Solving Time-dependent Parametric Partial Differential Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Hagnberger",
        "Marimuthu Kalimuthu",
        "Daniel Musekamp",
        "Mathias Niepert"
      ],
      "abstract": "Transformer models are increasingly used for solving Partial Differential\nEquations (PDEs). Several adaptations have been proposed, all of which suffer\nfrom the typical problems of Transformers, such as quadratic memory and time\ncomplexity. Furthermore, all prevalent architectures for PDE solving lack at\nleast one of several desirable properties of an ideal surrogate model, such as\n(i) generalization to PDE parameters not seen during training, (ii) spatial and\ntemporal zero-shot super-resolution, (iii) continuous temporal extrapolation,\n(iv) support for 1D, 2D, and 3D PDEs, and (v) efficient inference for longer\ntemporal rollouts. To address these limitations, we propose Vectorized\nConditional Neural Fields (VCNeFs), which represent the solution of\ntime-dependent PDEs as neural fields. Contrary to prior methods, however,\nVCNeFs compute, for a set of multiple spatio-temporal query points, their\nsolutions in parallel and model their dependencies through attention\nmechanisms. Moreover, VCNeF can condition the neural field on both the initial\nconditions and the parameters of the PDEs. An extensive set of experiments\ndemonstrates that VCNeFs are competitive with and often outperform existing\nML-based surrogate models.",
      "tldr_zh": "本文提出 Vectorized Conditional Neural Fields (VCNeFs)，一种框架，用于解决时间依赖参数偏微分方程 (PDEs)，通过将解决方案表示为神经场并在多个时空查询点上并行计算，以注意力机制建模依赖关系。VCNeFs 能够根据初始条件和 PDE 参数进行条件化，支持1D、2D 和3D PDEs，并实现参数泛化、空间时间零样本超分辨率以及连续时间外推。实验结果显示，VCNeFs 在效率和性能上与现有机器学习代理模型竞争，甚至在某些场景下表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at the 41st International Conference on\n  Machine Learning (ICML) 2024, Vienna, Austria; Project Page:\n  https://jhagnberger.github.io/vectorized-conditional-neural-field/",
      "pdf_url": "http://arxiv.org/pdf/2406.03919v2",
      "published_date": "2024-06-06 10:02:06 UTC",
      "updated_date": "2024-07-13 12:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:06:47.095595"
    },
    {
      "arxiv_id": "2406.03916v2",
      "title": "ArMeme: Propagandistic Content in Arabic Memes",
      "title_zh": "翻译失败",
      "authors": [
        "Firoj Alam",
        "Abul Hasnat",
        "Fatema Ahmed",
        "Md Arid Hasan",
        "Maram Hasanain"
      ],
      "abstract": "With the rise of digital communication, memes have become a significant\nmedium for cultural and political expression that is often used to mislead\naudiences. Identification of such misleading and persuasive multimodal content\nhas become more important among various stakeholders, including social media\nplatforms, policymakers, and the broader society as they often cause harm to\nindividuals, organizations, and/or society. While there has been effort to\ndevelop AI-based automatic systems for resource-rich languages (e.g., English),\nit is relatively little to none for medium to low resource languages. In this\nstudy, we focused on developing an Arabic memes dataset with manual annotations\nof propagandistic content. We annotated ~6K Arabic memes collected from various\nsocial media platforms, which is a first resource for Arabic multimodal\nresearch. We provide a comprehensive analysis aiming to develop computational\ntools for their detection. We will make them publicly available for the\ncommunity.",
      "tldr_zh": "本研究探讨了阿拉伯语 memes 中宣传性内容的传播问题，这些内容常用于误导观众并对社会造成危害，而现有 AI-based automatic systems 主要针对资源丰富的语言如英语，阿拉伯语领域资源匮乏。研究团队收集并手动标注了约 6K 个来自各种社交媒体平台的阿拉伯 memes，创建了首个 Arabic memes dataset 用于多模态研究。作者提供了全面分析，以开发检测 propagandistic content 的计算工具，并计划将数据集公开以支持社区应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images",
      "pdf_url": "http://arxiv.org/pdf/2406.03916v2",
      "published_date": "2024-06-06 09:56:49 UTC",
      "updated_date": "2024-10-06 08:35:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:06:58.619336"
    },
    {
      "arxiv_id": "2406.03912v2",
      "title": "GenSafe: A Generalizable Safety Enhancer for Safe Reinforcement Learning Algorithms Based on Reduced Order Markov Decision Process Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zhehua Zhou",
        "Xuan Xie",
        "Jiayang Song",
        "Zhan Shu",
        "Lei Ma"
      ],
      "abstract": "Safe Reinforcement Learning (SRL) aims to realize a safe learning process for\nDeep Reinforcement Learning (DRL) algorithms by incorporating safety\nconstraints. However, the efficacy of SRL approaches often relies on accurate\nfunction approximations, which are notably challenging to achieve in the early\nlearning stages due to data insufficiency. To address this issue, we introduce\nin this work a novel Generalizable Safety enhancer (GenSafe) that is able to\novercome the challenge of data insufficiency and enhance the performance of SRL\napproaches. Leveraging model order reduction techniques, we first propose an\ninnovative method to construct a Reduced Order Markov Decision Process (ROMDP)\nas a low-dimensional approximator of the original safety constraints. Then, by\nsolving the reformulated ROMDP-based constraints, GenSafe refines the actions\nof the agent to increase the possibility of constraint satisfaction.\nEssentially, GenSafe acts as an additional safety layer for SRL algorithms. We\nevaluate GenSafe on multiple SRL approaches and benchmark problems. The results\ndemonstrate its capability to improve safety performance, especially in the\nearly learning phases, while maintaining satisfactory task performance. Our\nproposed GenSafe not only offers a novel measure to augment existing SRL\nmethods but also shows broad compatibility with various SRL algorithms, making\nit applicable to a wide range of systems and SRL problems.",
      "tldr_zh": "该研究针对 Safe Reinforcement Learning (SRL) 在早期学习阶段因数据不足导致函数逼近不准确的问题，提出了一种通用安全增强器 GenSafe。GenSafe 通过模型阶减少技术构建 Reduced Order Markov Decision Process (ROMDP) 作为原始安全约束的低维逼近，并通过解决 ROMDP-based 约束来优化代理动作，从而作为 SRL 算法的额外安全层提升约束满足可能性。实验结果显示，GenSafe 在多个 SRL 方法和基准问题上显著改善了安全性能，尤其在早期阶段，同时保持了满意的任务表现，并展示了与各种 SRL 算法的广泛兼容性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03912v2",
      "published_date": "2024-06-06 09:51:30 UTC",
      "updated_date": "2025-01-14 10:32:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:07:14.101533"
    },
    {
      "arxiv_id": "2406.14570v2",
      "title": "Deep-Learning Approach for Tissue Classification using Acoustic Waves during Ablation with an Er:YAG Laser (Updated)",
      "title_zh": "翻译失败",
      "authors": [
        "Carlo Seppi",
        "Philippe C. Cattin"
      ],
      "abstract": "Today's mechanical tools for bone cutting (osteotomy) cause mechanical trauma\nthat prolongs the healing process. Medical device manufacturers aim to minimize\nthis trauma, with minimally invasive surgery using laser cutting as one\ninnovation. This method ablates tissue using laser light instead of mechanical\ntools, reducing post-surgery healing time. A reliable feedback system is\ncrucial during laser surgery to prevent damage to surrounding tissues. We\npropose a tissue classification method analyzing acoustic waves generated\nduring laser ablation, demonstrating its applicability in an ex-vivo\nexperiment. The ablation process with a microsecond pulsed Er:YAG laser\nproduces acoustic waves, acquired with an air-coupled transducer. These waves\nwere used to classify five porcine tissue types: hard bone, soft bone, muscle,\nfat, and skin. For automated tissue classification, we compared five Neural\nNetwork (NN) approaches: a one-dimensional Convolutional Neural Network (CNN)\nwith time-dependent input, a Fully-connected Neural Network (FcNN) with either\nthe frequency spectrum or principal components of the frequency spectrum as\ninput, and a combination of a CNN and an FcNN with time-dependent data and its\nfrequency spectrum as input. Consecutive acoustic waves were used to improve\nclassification accuracy. Grad-Cam identified the activation map of the\nfrequencies, showing low frequencies as the most important for this task. Our\nresults indicated that combining time-dependent data with its frequency\nspectrum achieved the highest classification accuracy (65.5%-75.5%). We also\nfound that using the frequency spectrum alone was sufficient, with no\nadditional benefit from applying Principal Components Analysis (PCA).",
      "tldr_zh": "本研究提出了一种基于深度学习的组织分类方法，利用 Er:YAG 激光消融过程中产生的声波来区分组织类型，旨在为激光手术提供可靠反馈，减少对周围组织的损伤。研究比较了五种神经网络（NN）模型，包括一维卷积神经网络 (CNN) 和全连接神经网络 (FcNN)，并发现结合时间依赖数据及其频率谱的混合模型取得了最高分类准确率（65.5%-75.5%）。通过 Grad-CAM 分析，实验结果显示低频特征最重要，且仅使用频率谱即可实现高效分类，无需 Principal Components Analysis (PCA)。这为激光辅助手术的精确控制提供了新途径，特别是在 ex-vivo 猪组织实验中证明了其潜力。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "eess.IV",
        "q-bio.TO"
      ],
      "primary_category": "physics.med-ph",
      "comment": "This paper is an updated version of Deep-Learning Approach for Tissue\n  Classification using Acoustic Waves during Ablation with an Er:YAG Laser\n  originally published in DOI:10.1109/ACCESS.2021.3113055. This update\n  addresses several issues and incorporates corrections as outlined in\n  DOI:10.1109/ACCESS.2024.3395071. We provide here a detailed description of\n  our experiments and the new models we used",
      "pdf_url": "http://arxiv.org/pdf/2406.14570v2",
      "published_date": "2024-06-06 09:46:14 UTC",
      "updated_date": "2024-06-24 09:25:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:07:23.740073"
    },
    {
      "arxiv_id": "2406.03897v2",
      "title": "HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew",
      "title_zh": "翻译失败",
      "authors": [
        "Tzuf Paz-Argaman",
        "Itai Mondshine",
        "Asaf Achi Mordechai",
        "Reut Tsarfaty"
      ],
      "abstract": "While large language models (LLMs) excel in various natural language tasks in\nEnglish, their performance in lower-resourced languages like Hebrew, especially\nfor generative tasks such as abstractive summarization, remains unclear. The\nhigh morphological richness in Hebrew adds further challenges due to the\nambiguity in sentence comprehension and the complexities in meaning\nconstruction. In this paper, we address this resource and evaluation gap by\nintroducing HeSum, a novel benchmark specifically designed for abstractive text\nsummarization in Modern Hebrew. HeSum consists of 10,000 article-summary pairs\nsourced from Hebrew news websites written by professionals. Linguistic analysis\nconfirms HeSum's high abstractness and unique morphological challenges. We show\nthat HeSum presents distinct difficulties for contemporary state-of-the-art\nLLMs, establishing it as a valuable testbed for generative language technology\nin Hebrew, and MRLs generative challenges in general.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在低资源语言如希伯来语的生成任务（如抽取式文本摘要）中的性能问题，引入了HeSum数据集——一个专为现代希伯来语设计的基准。HeSum包含10,000对专业撰写的文章-摘要对，源自希伯来语新闻网站，并通过语言分析确认了其高抽象性和独特的形态丰富性挑战。实验结果显示，HeSum对当代最先进的LLMs构成了显著困难，为评估希伯来语及其他形态丰富语言（MRLs）的生成技术提供了宝贵测试平台。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03897v2",
      "published_date": "2024-06-06 09:36:14 UTC",
      "updated_date": "2024-06-10 05:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:07:48.832039"
    },
    {
      "arxiv_id": "2406.06598v1",
      "title": "Qabas: An Open-Source Arabic Lexicographic Database",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa Jarrar",
        "Tymaa Hammouda"
      ],
      "abstract": "We present Qabas, a novel open-source Arabic lexicon designed for NLP\napplications. The novelty of Qabas lies in its synthesis of 110 lexicons.\nSpecifically, Qabas lexical entries (lemmas) are assembled by linking lemmas\nfrom 110 lexicons. Furthermore, Qabas lemmas are also linked to 12\nmorphologically annotated corpora (about 2M tokens), making it the first Arabic\nlexicon to be linked to lexicons and corpora. Qabas was developed\nsemi-automatically, utilizing a mapping framework and a web-based tool.\nCompared with other lexicons, Qabas stands as the most extensive Arabic\nlexicon, encompassing about 58K lemmas (45K nominal lemmas, 12.5K verbal\nlemmas, and 473 functional-word lemmas). Qabas is open-source and accessible\nonline at https://sina.birzeit.edu/qabas.",
      "tldr_zh": "我们介绍了 Qabas，这是一个开源的阿拉伯语词汇库（lexicon），专为 NLP 应用设计，通过整合 110 个词汇库并将词汇条目（lemmas）链接到这些库和 12 个形态学标注语料库（corpora，总计约 2M tokens）。该库采用半自动方法，包括映射框架和网络工具进行开发，使其成为首个同时链接词汇库和语料库的阿拉伯语资源。Qabas 包含约 58K 个 lemmas（包括 45K 名词 lemmas、12.5K 动词 lemmas 和 473 功能词 lemmas），是目前最广泛的阿拉伯语词汇库，并可在线免费访问（https://sina.birzeit.edu/qabas）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06598v1",
      "published_date": "2024-06-06 09:25:36 UTC",
      "updated_date": "2024-06-06 09:25:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:07:50.471033"
    },
    {
      "arxiv_id": "2406.03880v1",
      "title": "Memorization in deep learning: A survey",
      "title_zh": "深度学习中的记忆化：一项综述",
      "authors": [
        "Jiaheng Wei",
        "Yanjun Zhang",
        "Leo Yu Zhang",
        "Ming Ding",
        "Chao Chen",
        "Kok-Leong Ong",
        "Jun Zhang",
        "Yang Xiang"
      ],
      "abstract": "Deep Learning (DL) powered by Deep Neural Networks (DNNs) has revolutionized\nvarious domains, yet understanding the intricacies of DNN decision-making and\nlearning processes remains a significant challenge. Recent investigations have\nuncovered an interesting memorization phenomenon in which DNNs tend to memorize\nspecific details from examples rather than learning general patterns, affecting\nmodel generalization, security, and privacy. This raises critical questions\nabout the nature of generalization in DNNs and their susceptibility to security\nbreaches. In this survey, we present a systematic framework to organize\nmemorization definitions based on the generalization and security/privacy\ndomains and summarize memorization evaluation methods at both the example and\nmodel levels. Through a comprehensive literature review, we explore DNN\nmemorization behaviors and their impacts on security and privacy. We also\nintroduce privacy vulnerabilities caused by memorization and the phenomenon of\nforgetting and explore its connection with memorization. Furthermore, we\nspotlight various applications leveraging memorization and forgetting\nmechanisms, including noisy label learning, privacy preservation, and model\nenhancement. This survey offers the first-in-kind understanding of memorization\nin DNNs, providing insights into its challenges and opportunities for enhancing\nAI development while addressing critical ethical concerns.",
      "tldr_zh": "这篇调查论文探讨了深度神经网络(DNNs)中的记忆化现象，即DNNs倾向于记忆特定示例细节而非学习一般模式，从而影响模型的泛化性、安全性和隐私。作者提出一个系统框架来组织记忆化定义，基于泛化和安全/隐私领域，并总结了示例和模型级别的评估方法。通过文献综述，论文分析了记忆化行为及其引发的隐私漏洞、遗忘机制，以及在嘈杂标签学习、隐私保护和模型增强等应用中的潜力。该研究为理解DNNs的挑战提供首次全面见解，推动AI发展并解决相关伦理问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03880v1",
      "published_date": "2024-06-06 09:17:40 UTC",
      "updated_date": "2024-06-06 09:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:08:02.502251"
    },
    {
      "arxiv_id": "2406.03873v3",
      "title": "Quantum Implicit Neural Representations",
      "title_zh": "Quantum 隐式神经表示",
      "authors": [
        "Jiaming Zhao",
        "Wenbo Qiao",
        "Peng Zhang",
        "Hui Gao"
      ],
      "abstract": "Implicit neural representations have emerged as a powerful paradigm to\nrepresent signals such as images and sounds. This approach aims to utilize\nneural networks to parameterize the implicit function of the signal. However,\nwhen representing implicit functions, traditional neural networks such as\nReLU-based multilayer perceptrons face challenges in accurately modeling\nhigh-frequency components of signals. Recent research has begun to explore the\nuse of Fourier Neural Networks (FNNs) to overcome this limitation. In this\npaper, we propose Quantum Implicit Representation Network (QIREN), a novel\nquantum generalization of FNNs. Furthermore, through theoretical analysis, we\ndemonstrate that QIREN possesses a quantum advantage over classical FNNs.\nLastly, we conducted experiments in signal representation, image\nsuperresolution, and image generation tasks to show the superior performance of\nQIREN compared to state-of-the-art (SOTA) models. Our work not only\nincorporates quantum advantages into implicit neural representations but also\nuncovers a promising application direction for Quantum Neural Networks.",
      "tldr_zh": "本文提出 Quantum Implicit Representation Network (QIREN)，一种对 Fourier Neural Networks (FNNs) 的量子泛化，用于提升隐式神经表示（Implicit neural representations）在处理图像和声音等信号的高频组件时的性能。相比传统 ReLU-based multilayer perceptrons，QIREN 通过理论分析证明了其量子优势，能够更准确地建模复杂信号。实验结果显示，在信号表示、图像超分辨率和图像生成任务中，QIREN 优于现有 State-of-the-art (SOTA) 模型，为 Quantum Neural Networks 的应用开辟了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper was accepted by icml 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03873v3",
      "published_date": "2024-06-06 09:04:48 UTC",
      "updated_date": "2024-09-01 09:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:08:14.900485"
    },
    {
      "arxiv_id": "2406.18585v1",
      "title": "Flexible ViG: Learning the Self-Saliency for Flexible Object Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Zuo",
        "Kunshan Yang",
        "Xianlong Tian",
        "Kunbin He",
        "Yongqi Ding",
        "Mengmeng Jing"
      ],
      "abstract": "Existing computer vision methods mainly focus on the recognition of rigid\nobjects, whereas the recognition of flexible objects remains unexplored.\nRecognizing flexible objects poses significant challenges due to their\ninherently diverse shapes and sizes, translucent attributes, ambiguous\nboundaries, and subtle inter-class differences. In this paper, we claim that\nthese problems primarily arise from the lack of object saliency. To this end,\nwe propose the Flexible Vision Graph Neural Network (FViG) to optimize the\nself-saliency and thereby improve the discrimination of the representations for\nflexible objects. Specifically, on one hand, we propose to maximize the\nchannel-aware saliency by extracting the weight of neighboring nodes, which\nadapts to the shape and size variations in flexible objects. On the other hand,\nwe maximize the spatial-aware saliency based on clustering to aggregate\nneighborhood information for the centroid nodes, which introduces local context\ninformation for the representation learning. To verify the performance of\nflexible objects recognition thoroughly, for the first time we propose the\nFlexible Dataset (FDA), which consists of various images of flexible objects\ncollected from real-world scenarios or online. Extensive experiments evaluated\non our Flexible Dataset demonstrate the effectiveness of our method on\nenhancing the discrimination of flexible objects.",
      "tldr_zh": "现有计算机视觉方法主要关注刚性物体，而对柔性物体的识别尚未深入探索，因为它们具有形状和大小多样、半透明属性、模糊边界以及类间差异细微等问题。为解决这些挑战，本文提出 Flexible Vision Graph Neural Network (FViG)，通过优化 self-saliency 来提升柔性物体的表示区分度。具体而言，FViG 最大化 channel-aware saliency 以适应形状变化，并通过基于聚类的 spatial-aware saliency 聚合局部上下文信息。此外，本文首次引入 Flexible Dataset (FDA)，包含真实场景和在线收集的柔性物体图像，实验结果显示 FViG 在 FDA 上显著提高了识别性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2406.18585v1",
      "published_date": "2024-06-06 08:55:06 UTC",
      "updated_date": "2024-06-06 08:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:08:26.994147"
    },
    {
      "arxiv_id": "2406.03865v2",
      "title": "Semantic Similarity Score for Measuring Visual Similarity at Semantic Level",
      "title_zh": "翻译失败",
      "authors": [
        "Senran Fan",
        "Zhicheng Bao",
        "Chen Dong",
        "Haotai Liang",
        "Xiaodong Xu",
        "Ping Zhang"
      ],
      "abstract": "Semantic communication, as a revolutionary communication architecture, is\nconsidered a promising novel communication paradigm. Unlike traditional\nsymbol-based error-free communication systems, semantic-based visual\ncommunication systems extract, compress, transmit, and reconstruct images at\nthe semantic level. However, widely used image similarity evaluation metrics,\nwhether pixel-based MSE or PSNR or structure-based MS-SSIM, struggle to\naccurately measure the loss of semantic-level information of the source during\nsystem transmission. This presents challenges in evaluating the performance of\nvisual semantic communication systems, especially when comparing them with\ntraditional communication systems. To address this, we propose a semantic\nevaluation metric -- SeSS (Semantic Similarity Score), based on Scene Graph\nGeneration and graph matching, which shifts the similarity scores between\nimages into semantic-level graph matching scores. Meanwhile, semantic\nsimilarity scores for tens of thousands of image pairs are manually annotated\nto fine-tune the hyperparameters in the graph matching algorithm, aligning the\nmetric more closely with human semantic perception. The performance of the SeSS\nis tested on different datasets, including (1)images transmitted by traditional\nand semantic communication systems at different compression rates, (2)images\ntransmitted by traditional and semantic communication systems at different\nsignal-to-noise ratios, (3)images generated by large-scale model with different\nnoise levels introduced, and (4)cases of images subjected to certain special\ntransformations. The experiments demonstrate the effectiveness of SeSS,\nindicating that the metric can measure the semantic-level differences in\nsemantic-level information of images and can be used for evaluation in visual\nsemantic communication systems.",
      "tldr_zh": "这篇论文针对视觉语义通信系统的问题，提出了一种新指标SeSS（Semantic Similarity Score），用于在语义层面测量图像相似性，解决传统指标如MSE、PSNR和MS-SSIM无法准确评估语义信息损失的局限性。SeSS基于Scene Graph Generation和graph matching算法，并通过手动标注数万个图像对的语义相似性数据来微调超参数，使其更贴合人类感知。实验在不同压缩率、信噪比、噪声水平和图像变换的场景下验证了SeSS的有效性，证明它能精确量化图像的语义级别差异，并为视觉语义通信系统的性能评估提供可靠工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03865v2",
      "published_date": "2024-06-06 08:51:26 UTC",
      "updated_date": "2024-07-10 04:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:08:37.746055"
    },
    {
      "arxiv_id": "2406.03862v1",
      "title": "Behavior-Targeted Attack on Reinforcement Learning with Limited Access to Victim's Policy",
      "title_zh": "翻译失败",
      "authors": [
        "Shojiro Yamabe",
        "Kazuto Fukuchi",
        "Ryoma Senda",
        "Jun Sakuma"
      ],
      "abstract": "This study considers the attack on reinforcement learning agents where the\nadversary aims to control the victim's behavior as specified by the adversary\nby adding adversarial modifications to the victim's state observation. While\nsome attack methods reported success in manipulating the victim agent's\nbehavior, these methods often rely on environment-specific heuristics. In\naddition, all existing attack methods require white-box access to the victim's\npolicy. In this study, we propose a novel method for manipulating the victim\nagent in the black-box (i.e., the adversary is allowed to observe the victim's\nstate and action only) and no-box (i.e., the adversary is allowed to observe\nthe victim's state only) setting without requiring environment-specific\nheuristics. Our attack method is formulated as a bi-level optimization problem\nthat is reduced to a distribution matching problem and can be solved by an\nexisting imitation learning algorithm in the black-box and no-box settings.\nEmpirical evaluations on several reinforcement learning benchmarks show that\nour proposed method has superior attack performance to baselines.",
      "tldr_zh": "本研究针对强化学习（Reinforcement Learning）代理的攻击问题，提出了一种行为导向攻击方法，能够在黑盒（Black-box，仅观察状态和动作）和无盒（No-box，仅观察状态）设置下，通过修改受害者代理的状态观察来控制其行为，而无需依赖环境特定的启发式规则。攻击方法将问题表述为双层优化（Bi-level Optimization）问题，并简化为分布匹配（Distribution Matching）问题，使用现有的模仿学习（Imitation Learning）算法进行求解。该方法在多个强化学习基准上进行了实证评估，结果显示其攻击性能优于基线模型，为评估和提升强化学习系统的鲁棒性提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03862v1",
      "published_date": "2024-06-06 08:49:51 UTC",
      "updated_date": "2024-06-06 08:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:08:49.312472"
    },
    {
      "arxiv_id": "2406.03848v3",
      "title": "OceanCastNet: A Deep Learning Ocean Wave Model with Energy Conservation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziliang Zhang",
        "Huaming Yu",
        "Danqin Ren"
      ],
      "abstract": "Traditional wave forecasting models, although based on energy conservation\nequations, are computationally expensive. On the other hand, existing deep\nlearning geophysical fluid models, while computationally efficient, often\nsuffer from issues such as energy dissipation in long-term forecasts. This\npaper proposes a novel energy-balanced deep learning wave forecasting model\ncalled OceanCastNet (OCN). By incorporating wind fields at the current,\nprevious, and future time steps, as well as wave fields at the current and\nprevious time steps as input variables, OCN maintains energy balance within the\nmodel. Furthermore, the model employs adaptive Fourier operators as its core\ncomponents and designs a masked loss function to better handle the impact of\nland-sea boundaries. A series of experiments on the ERA5 dataset demonstrate\nthat OCN can achieve short-term forecast accuracy comparable to traditional\nmodels while exhibiting an understanding of the wave generation process. In\ncomparative experiments under both normal and extreme conditions, OCN\nconsistently outperforms the widely used WaveWatch III model in the industry.\nEven after long-term forecasting, OCN maintains a stable and energy-rich state.\nBy further constructing a simple meteorological model, OCN-wind, which\nconsiders energy balance, this paper confirms the importance of energy\nconstraints for improving the long-term forecast performance of deep learning\nmeteorological models. This finding provides new ideas for future research on\ndeep learning geophysical fluid models.",
      "tldr_zh": "本论文针对传统波浪预报模型计算成本高和现有深度学习地球物理流体模型能量耗散的问题，提出了一种新型能量平衡深度学习波浪预报模型OceanCastNet (OCN)。OCN通过整合当前、过去和未来时间步的风场以及当前和过去时间步的波场作为输入，并采用adaptive Fourier operators作为核心组件，同时设计masked loss function来处理陆海边界影响，从而维持能量平衡。实验在ERA5数据集上显示，OCN在短期预报准确性上可与传统模型媲美，并在正常和极端条件下长期预报中持续优于WaveWatch III模型，保持稳定能量状态。该研究还通过构建OCN-wind气象模型，确认了能量约束对提升深度学习气象模型长期预报性能的重要性，为未来地球物理流体模型研究提供新思路。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03848v3",
      "published_date": "2024-06-06 08:29:29 UTC",
      "updated_date": "2024-12-03 08:54:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:09:04.198901"
    },
    {
      "arxiv_id": "2406.03843v3",
      "title": "POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jianben He",
        "Xingbo Wang",
        "Shiyi Liu",
        "Guande Wu",
        "Claudio Silva",
        "Huamin Qu"
      ],
      "abstract": "Large language models (LLMs) have exhibited impressive abilities for\nmultimodal content comprehension and reasoning with proper prompting in zero-\nor few-shot settings. Despite the proliferation of interactive systems\ndeveloped to support prompt engineering for LLMs across various tasks, most\nhave primarily focused on textual or visual inputs, thus neglecting the complex\ninterplay between modalities within multimodal inputs. This oversight hinders\nthe development of effective prompts that guide model multimodal reasoning\nprocesses by fully exploiting the rich context provided by multiple modalities.\nIn this paper, we present POEM, a visual analytics system to facilitate\nefficient prompt engineering for enhancing the multimodal reasoning performance\nof LLMs. The system enables users to explore the interaction patterns across\nmodalities at varying levels of detail for a comprehensive understanding of the\nmultimodal knowledge elicited by various prompts. Through diverse\nrecommendations of demonstration examples and instructional principles, POEM\nsupports users in iteratively crafting and refining prompts to better align and\nenhance model knowledge with human insights. The effectiveness and efficiency\nof our system are validated through two case studies and interviews with\nexperts.",
      "tldr_zh": "该论文提出 POEM，一种交互式提示优化系统，旨在提升大语言模型 (LLMs) 在多模态推理中的性能，解决现有系统忽略多模态输入互动的问题。POEM 通过视觉分析工具，让用户探索不同模态间的互动模式，并在多个细节级别理解模型提取的多模态知识，同时提供演示示例和指导原则，支持用户迭代优化提示，以更好地整合人类洞见和模型能力。实验结果通过两个案例研究和专家访谈验证了 POEM 的有效性和效率，显著提高了 LLMs 的多模态推理表现。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "68",
        "H.5; I.2.1"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.03843v3",
      "published_date": "2024-06-06 08:21:30 UTC",
      "updated_date": "2024-09-30 16:16:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:09:12.786006"
    },
    {
      "arxiv_id": "2406.03836v1",
      "title": "Proactive Detection of Physical Inter-rule Vulnerabilities in IoT Services Using a Deep Learning Approach",
      "title_zh": "使用深度学习方法主动检测物联网服务中的物理",
      "authors": [
        "Bing Huang",
        "Chen Chen",
        "Kwok-Yan Lam",
        "Fuqun Huang"
      ],
      "abstract": "Emerging Internet of Things (IoT) platforms provide sophisticated\ncapabilities to automate IoT services by enabling occupants to create\ntrigger-action rules. Multiple trigger-action rules can physically interact\nwith each other via shared environment channels, such as temperature, humidity,\nand illumination. We refer to inter-rule interactions via shared environment\nchannels as a physical inter-rule vulnerability. Such vulnerability can be\nexploited by attackers to launch attacks against IoT systems. We propose a new\nframework to proactively discover possible physical inter-rule interactions\nfrom user requirement specifications (i.e., descriptions) using a deep learning\napproach. Specifically, we utilize the Transformer model to generate\ntrigger-action rules from their associated descriptions. We discover two types\nof physical inter-rule vulnerabilities and determine associated environment\nchannels using natural language processing (NLP) tools. Given the extracted\ntrigger-action rules and associated environment channels, an approach is\nproposed to identify hidden physical inter-rule vulnerabilities among them. Our\nexperiment on 27983 IFTTT style rules shows that the Transformer can\nsuccessfully extract trigger-action rules from descriptions with 95.22%\naccuracy. We also validate the effectiveness of our approach on 60 SmartThings\nofficial IoT apps and discover 99 possible physical inter-rule vulnerabilities.",
      "tldr_zh": "本文提出一种使用深度学习的方法，主动检测IoT服务中由trigger-action rules通过共享环境通道（如温度、湿度）引发的physical inter-rule vulnerabilities，以防范潜在攻击。框架利用Transformer模型从用户需求描述中生成trigger-action rules，并结合NLP工具识别两种漏洞类型和相关环境通道，随后分析规则间交互以发现隐藏问题。实验结果显示，在27983个IFTTT风格规则上，规则提取准确率达95.22%，并在60个SmartThings官方IoT apps中成功识别99个可能的vulnerabilities，为IoT安全提供了有效防护机制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by IEEE ICWS 2024 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.03836v1",
      "published_date": "2024-06-06 08:13:02 UTC",
      "updated_date": "2024-06-06 08:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:09:26.439891"
    },
    {
      "arxiv_id": "2406.06596v1",
      "title": "Are Large Language Models the New Interface for Data Pipelines?",
      "title_zh": "大语言模型是数据管道的新接口吗？",
      "authors": [
        "Sylvio Barbon Junior",
        "Paolo Ceravolo",
        "Sven Groppe",
        "Mustafa Jarrar",
        "Samira Maghool",
        "Florence Sèdes",
        "Soror Sahri",
        "Maurice Van Keulen"
      ],
      "abstract": "A Language Model is a term that encompasses various types of models designed\nto understand and generate human communication. Large Language Models (LLMs)\nhave gained significant attention due to their ability to process text with\nhuman-like fluency and coherence, making them valuable for a wide range of\ndata-related tasks fashioned as pipelines. The capabilities of LLMs in natural\nlanguage understanding and generation, combined with their scalability,\nversatility, and state-of-the-art performance, enable innovative applications\nacross various AI-related fields, including eXplainable Artificial Intelligence\n(XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG).\nFurthermore, we believe these models can extract valuable insights and make\ndata-driven decisions at scale, a practice commonly referred to as Big Data\nAnalytics (BDA). In this position paper, we provide some discussions in the\ndirection of unlocking synergies among these technologies, which can lead to\nmore powerful and intelligent AI solutions, driving improvements in data\npipelines across a wide range of applications and domains integrating humans,\ncomputers, and knowledge.",
      "tldr_zh": "这篇立场论文探讨了大型语言模型 (LLMs) 是否能作为数据管道的新接口，强调 LLMs 通过其自然语言理解和生成能力，能处理文本任务并应用于 eXplainable Artificial Intelligence (XAI)、Automated Machine Learning (AutoML) 和 Knowledge Graphs (KG) 等领域。作者认为，LLMs 的可扩展性和多功能性可从大数据中提取洞见，支持 Big Data Analytics (BDA)，从而实现数据驱动决策。最终，该论文主张 LLMs 与其他技术的协同作用，将提升数据管道的智能性，促进整合人类、计算机和知识的 AI 解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06596v1",
      "published_date": "2024-06-06 08:10:32 UTC",
      "updated_date": "2024-06-06 08:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:09:44.038698"
    },
    {
      "arxiv_id": "2406.03820v2",
      "title": "A Survey on Intelligent Internet of Things: Applications, Security, Privacy, and Future Directions",
      "title_zh": "智能物联网的调查：",
      "authors": [
        "Ons Aouedi",
        "Thai-Hoc Vu",
        "Alessio Sacco",
        "Dinh C. Nguyen",
        "Kandaraj Piamrat",
        "Guido Marchetto",
        "Quoc-Viet Pham"
      ],
      "abstract": "The rapid advances in the Internet of Things (IoT) have promoted a revolution\nin communication technology and offered various customer services. Artificial\nintelligence (AI) techniques have been exploited to facilitate IoT operations\nand maximize their potential in modern application scenarios. In particular,\nthe convergence of IoT and AI has led to a new networking paradigm called\nIntelligent IoT (IIoT), which has the potential to significantly transform\nbusinesses and industrial domains. This paper presents a comprehensive survey\nof IIoT by investigating its significant applications in mobile networks, as\nwell as its associated security and privacy issues. Specifically, we explore\nand discuss the roles of IIoT in a wide range of key application domains, from\nsmart healthcare and smart cities to smart transportation and smart industries.\nThrough such extensive discussions, we investigate important security issues in\nIIoT networks, where network attacks, confidentiality, integrity, and intrusion\nare analyzed, along with a discussion of potential countermeasures. Privacy\nissues in IIoT networks were also surveyed and discussed, including data,\nlocation, and model privacy leakage. Finally, we outline several key challenges\nand highlight potential research directions in this important area.",
      "tldr_zh": "这篇论文对智能物联网（Intelligent IoT, IIoT）进行了全面调查，探讨了其在智能医疗、智能城市、智能交通和智能工业等领域的关键应用，以及AI技术如何提升IoT的运作潜力。论文分析了IIoT网络的安全问题，包括网络攻击、保密性、完整性和入侵风险，并提出了潜在的应对措施；同时，它还讨论了隐私问题，如数据、位置和模型隐私泄露。最终，论文总结了IIoT面临的挑战，并指出了未来研究方向，如增强安全性和隐私保护的创新策略。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "This work has been accepted by IEEE Communications Surveys &\n  Tutorials",
      "pdf_url": "http://arxiv.org/pdf/2406.03820v2",
      "published_date": "2024-06-06 07:55:30 UTC",
      "updated_date": "2024-06-21 14:43:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:09:51.888085"
    },
    {
      "arxiv_id": "2406.06595v1",
      "title": "Beyond 5G Network Failure Classification for Network Digital Twin Using Graph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Abubakar Isah",
        "Ibrahim Aliyu",
        "Jaechan Shim",
        "Hoyong Ryu",
        "Jinsul Kim"
      ],
      "abstract": "Fifth-generation (5G) core networks in network digital twins (NDTs) are\ncomplex systems with numerous components, generating considerable data.\nAnalyzing these data can be challenging due to rare failure types, leading to\nimbalanced classes in multiclass classification. To address this problem, we\npropose a novel method of integrating a graph Fourier transform (GFT) into a\nmessage-passing neural network (MPNN) designed for NDTs. This approach\ntransforms the data into a graph using the GFT to address class imbalance,\nwhereas the MPNN extracts features and models dependencies between network\ncomponents. This combined approach identifies failure types in real and\nsimulated NDT environments, demonstrating its potential for accurate failure\nclassification in 5G and beyond (B5G) networks. Moreover, the MPNN is adept at\nlearning complex local structures among neighbors in an end-to-end setting.\nExtensive experiments have demonstrated that the proposed approach can identify\nfailure types in three multiclass domain datasets at multiple failure points in\nreal networks and NDT environments. The results demonstrate that the proposed\nGFT-MPNN can accurately classify network failures in B5G networks, especially\nwhen employed within NDTs to detect failure types.",
      "tldr_zh": "该研究针对5G和Beyond 5G (B5G)网络在Network Digital Twin (NDTs)中的故障分类问题，解决了数据不平衡和复杂组件依赖的问题。研究提出了一种新方法，将Graph Fourier Transform (GFT)整合到Message-Passing Neural Network (MPNN)中，其中GFT用于将数据转化为图以处理类别不平衡，而MPNN则提取特征并建模网络组件间的依赖关系。该方法在真实和模拟NDTs环境中进行测试，结果显示在三个多类域数据集上准确识别故障类型，尤其在B5G网络中显著提升了分类准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06595v1",
      "published_date": "2024-06-06 07:36:25 UTC",
      "updated_date": "2024-06-06 07:36:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:10:04.013147"
    },
    {
      "arxiv_id": "2406.03808v1",
      "title": "Cross-variable Linear Integrated ENhanced Transformer for Photovoltaic power forecasting",
      "title_zh": "跨变量线性整合增强Transformer用于光伏功率预测",
      "authors": [
        "Jiaxin Gao",
        "Qinglong Cao",
        "Yuntian Chen",
        "Dongxiao Zhang"
      ],
      "abstract": "Photovoltaic (PV) power forecasting plays a crucial role in optimizing the\noperation and planning of PV systems, thereby enabling efficient energy\nmanagement and grid integration. However, un certainties caused by fluctuating\nweather conditions and complex interactions between different variables pose\nsignificant challenges to accurate PV power forecasting. In this study, we\npropose PV-Client (Cross-variable Linear Integrated ENhanced Transformer for\nPhotovoltaic power forecasting) to address these challenges and enhance PV\npower forecasting accuracy. PV-Client employs an ENhanced Transformer module to\ncapture complex interactions of various features in PV systems, and utilizes a\nlinear module to learn trend information in PV power. Diverging from\nconventional time series-based Transformer models that use cross-time Attention\nto learn dependencies between different time steps, the Enhanced Transformer\nmodule integrates cross-variable Attention to capture dependencies between PV\npower and weather factors. Furthermore, PV-Client streamlines the embedding and\nposition encoding layers by replacing the Decoder module with a projection\nlayer. Experimental results on three real-world PV power datasets affirm\nPV-Client's state-of-the-art (SOTA) performance in PV power forecasting.\nSpecifically, PV-Client surpasses the second-best model GRU by 5.3% in MSE\nmetrics and 0.9% in accuracy metrics at the Jingang Station. Similarly,\nPV-Client outperforms the second-best model SVR by 10.1% in MSE metrics and\n0.2% in accuracy metrics at the Xinqingnian Station, and PV-Client exhibits\nsuperior performance compared to the second-best model SVR with enhancements of\n3.4% in MSE metrics and 0.9% in accuracy metrics at the Hongxing Station.",
      "tldr_zh": "本研究针对光伏（PV）发电预测中的不确定性（如天气波动和变量交互），提出了一种名为 PV-Client 的模型，即 Cross-variable Linear Integrated ENhanced Transformer，以提升预测准确性。PV-Client 采用 ENhanced Transformer 模块，通过 cross-variable Attention 捕捉 PV 发电与天气因素之间的依赖关系，并结合线性模块学习趋势信息，同时简化了嵌入和位置编码层以优化结构。实验结果显示，PV-Client 在三个真实数据集上表现出 SOTA 性能，例如在 Jingang Station 比 GRU 模型在 MSE 指标上提升 5.3% 和准确率提升 0.9%，在其他站点也显著超越 SVR 模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03808v1",
      "published_date": "2024-06-06 07:30:27 UTC",
      "updated_date": "2024-06-06 07:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:10:17.827121"
    },
    {
      "arxiv_id": "2406.03807v3",
      "title": "Tool-Planner: Task Planning with Clusters across Multiple Tools",
      "title_zh": "Tool-Planner: 基于聚类在多个工具间进行",
      "authors": [
        "Yanming Liu",
        "Xinyue Peng",
        "Jiannan Cao",
        "Shi Bo",
        "Yuwei Zhang",
        "Xuhong Zhang",
        "Sheng Cheng",
        "Xun Wang",
        "Jianwei Yin",
        "Tianyu Du"
      ],
      "abstract": "Large language models (LLMs) have demonstrated exceptional reasoning\ncapabilities, enabling them to solve various complex problems. Recently, this\nability has been applied to the paradigm of tool learning. Tool learning\ninvolves providing examples of tool usage and their corresponding functions,\nallowing LLMs to formulate plans and demonstrate the process of invoking and\nexecuting each tool. LLMs can address tasks that they cannot complete\nindependently, thereby enhancing their potential across different tasks.\nHowever, this approach faces two key challenges. First, redundant error\ncorrection leads to unstable planning and long execution time. Additionally,\ndesigning a correct plan among multiple tools is also a challenge in tool\nlearning. To address these issues, we propose Tool-Planner, a task-processing\nframework based on toolkits. Tool-Planner groups tools based on the API\nfunctions with the same function into a toolkit and allows LLMs to implement\nplanning across the various toolkits. When a tool error occurs, the language\nmodel can reselect and adjust tools based on the toolkit. Experiments show that\nour approach demonstrates a high pass and win rate across different datasets\nand optimizes the planning scheme for tool learning in models such as GPT-4 and\nClaude 3, showcasing the potential of our method. Our code is public at\nhttps://github.com/OceannTwT/Tool-Planner",
      "tldr_zh": "大型语言模型 (LLMs) 在工具学习中面临冗余错误修正导致的不稳定执行和多工具规划设计的挑战。论文提出 Tool-Planner 框架，该框架将具有相同功能的 API 函数分组成 toolkits，并允许 LLMs 在不同 toolkits 间进行任务规划，同时在工具错误时重新选择和调整。实验结果显示，Tool-Planner 在多种数据集上实现了高 pass rate 和 win rate，并优化了如 GPT-4 和 Claude 3 等模型的规划方案，为工具学习提供了更高效的方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 Camera Ready version",
      "pdf_url": "http://arxiv.org/pdf/2406.03807v3",
      "published_date": "2024-06-06 07:30:14 UTC",
      "updated_date": "2025-02-28 07:12:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:10:29.588805"
    },
    {
      "arxiv_id": "2406.03799v2",
      "title": "Enhanced Semantic Segmentation Pipeline for WeatherProof Dataset Challenge",
      "title_zh": "针对 WeatherProof 数据集挑战的增强语义分割管道",
      "authors": [
        "Nan Zhang",
        "Xidan Zhang",
        "Jianing Wei",
        "Fangjun Wang",
        "Zhiming Tan"
      ],
      "abstract": "This report describes the winning solution to the WeatherProof Dataset\nChallenge (CVPR 2024 UG2+ Track 3). Details regarding the challenge are\navailable at https://cvpr2024ug2challenge.github.io/track3.html. We propose an\nenhanced semantic segmentation pipeline for this challenge. Firstly, we improve\nsemantic segmentation models, using backbone pretrained with Depth Anything to\nimprove UperNet model and SETRMLA model, and adding language guidance based on\nboth weather and category information to InternImage model. Secondly, we\nintroduce a new dataset WeatherProofExtra with wider viewing angle and employ\ndata augmentation methods, including adverse weather and super-resolution.\nFinally, effective training strategies and ensemble method are applied to\nimprove final performance further. Our solution is ranked 1st on the final\nleaderboard. Code will be available at\nhttps://github.com/KaneiGi/WeatherProofChallenge.",
      "tldr_zh": "本研究提出了一种增强的语义分割管道，用于CVPR 2024 UG2+ Track 3的WeatherProof Dataset Challenge。该管道首先改进语义分割模型，包括使用Depth Anything预训练的骨干网络优化UperNet和SETRMLA模型，并为InternImage模型添加基于天气和类别信息的语言指导；其次，引入新数据集WeatherProofExtra并应用数据增强方法，如不利天气模拟和超分辨率。最后，通过有效的训练策略和集成方法，该解决方案在挑战最终排行榜上排名第一，代码将在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03799v2",
      "published_date": "2024-06-06 07:12:50 UTC",
      "updated_date": "2024-06-07 02:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:10:40.293961"
    },
    {
      "arxiv_id": "2406.03789v2",
      "title": "Enhancing Graph U-Nets for Mesh-Agnostic Spatio-Temporal Flow Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Sunwoong Yang",
        "Ricardo Vinuesa",
        "Namwoo Kang"
      ],
      "abstract": "This study aims to overcome the limitations of conventional deep-learning\napproaches based on convolutional neural networks in complex geometries and\nunstructured meshes by exploring the potential of Graph U-Nets for unsteady\nflow-field prediction. We present a comprehensive investigation of Graph\nU-Nets, originally developed for classification tasks, now tailored for\nmesh-agnostic spatio-temporal forecasting of fluid dynamics. Our focus is on\nenhancing their performance through systematic hyperparameter tuning and\narchitectural modifications. We propose novel approaches to improve\nmesh-agnostic spatio-temporal prediction of transient flow fields using Graph\nU-Nets, enabling accurate prediction on diverse mesh configurations. Key\nenhancements to the Graph U-Net architecture, including the\nGaussian-mixture-model convolutional operator and noise injection approaches,\nprovide increased flexibility in modeling node dynamics: the former reduces\nprediction error by 95\\% compared to conventional convolutional operators,\nwhile the latter improves long-term prediction robustness, resulting in an\nerror reduction of 86\\%. We demonstrate the effectiveness of these enhancements\nin both transductive and inductive learning settings, showcasing the\nadaptability of Graph U-Nets to various flow conditions and mesh structures.\nThis work contributes to the field of reduced-order modeling for computational\nfluid dynamics by establishing Graph U-Nets as a viable and flexible\nalternative to convolutional neural networks, capable of accurately and\nefficiently predicting complex fluid flow phenomena across diverse scenarios.",
      "tldr_zh": "本研究旨在通过增强Graph U-Nets克服传统CNN在复杂几何和非结构化网格中的局限性，实现对非稳态流场的网格无关时空预测。研究者对Graph U-Nets进行了系统超参数调整和架构修改，包括引入Gaussian-mixture-model卷积操作符和噪声注入方法，前者将预测误差降低95%，后者提升长期预测的鲁棒性并减少86%的误差。这些改进在传递式和归纳式学习设置中均表现出色，适用于多样化的流条件和网格结构。该工作将Graph U-Nets确立为计算流体动力学简化建模的可行替代方案，促进了复杂流体现象的准确高效预测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03789v2",
      "published_date": "2024-06-06 07:01:36 UTC",
      "updated_date": "2024-10-17 00:44:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:11:03.097609"
    },
    {
      "arxiv_id": "2406.04384v1",
      "title": "Innovations in Cover Song Detection: A Lyrics-Based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Balluff",
        "Peter Mandl",
        "Christian Wolff"
      ],
      "abstract": "Cover songs are alternate versions of a song by a different artist. Long\nbeing a vital part of the music industry, cover songs significantly influence\nmusic culture and are commonly heard in public venues. The rise of online music\nplatforms has further increased their prevalence, often as background music or\nvideo soundtracks. While current automatic identification methods serve\nadequately for original songs, they are less effective with cover songs,\nprimarily because cover versions often significantly deviate from the original\ncompositions. In this paper, we propose a novel method for cover song detection\nthat utilizes the lyrics of a song. We introduce a new dataset for cover songs\nand their corresponding originals. The dataset contains 5078 cover songs and\n2828 original songs. In contrast to other cover song datasets, it contains the\nannotated lyrics for the original song and the cover song. We evaluate our\nmethod on this dataset and compare it with multiple baseline approaches. Our\nresults show that our method outperforms the baseline approaches.",
      "tldr_zh": "本论文提出了一种基于歌词的创新方法，用于检测封面歌曲（cover songs），以解决现有自动识别技术在处理歌曲变体时的低效问题。该方法利用歌曲歌词进行比较，并引入了一个新数据集，包含5078首封面歌曲和2828首原版歌曲，每首歌曲均附有标注的歌词。通过在该数据集上的实验评估，结果显示该方法优于多个基线方法，提升了封面歌曲检测的准确性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04384v1",
      "published_date": "2024-06-06 06:52:25 UTC",
      "updated_date": "2024-06-06 06:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:11:03.855557"
    },
    {
      "arxiv_id": "2406.03777v3",
      "title": "Empirical Guidelines for Deploying LLMs onto Resource-constrained Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiyang Qin",
        "Dancheng Liu",
        "Chenhui Xu",
        "Zheyu Yan",
        "Zhaoxuan Tan",
        "Zhenge Jia",
        "Amir Nassereldine",
        "Jiajie Li",
        "Meng Jiang",
        "Ahmed Abbasi",
        "Jinjun Xiong",
        "Yiyu Shi"
      ],
      "abstract": "The scaling laws have become the de facto guidelines for designing large\nlanguage models (LLMs), but they were studied under the assumption of unlimited\ncomputing resources for both training and inference. As LLMs are increasingly\nused as personalized intelligent assistants, their customization (i.e.,\nlearning through fine-tuning) and deployment onto resource-constrained edge\ndevices will become more and more prevalent. An urging but open question is how\na resource-constrained computing environment would affect the design choices\nfor a personalized LLM. We study this problem empirically in this work. In\nparticular, we consider the tradeoffs among a number of key design factors and\ntheir intertwined impacts on learning efficiency and accuracy. The factors\ninclude the learning methods for LLM customization, the amount of personalized\ndata used for learning customization, the types and sizes of LLMs, the\ncompression methods of LLMs, the amount of time afforded to learn, and the\ndifficulty levels of the target use cases. Through extensive experimentation\nand benchmarking, we draw a number of surprisingly insightful guidelines for\ndeploying LLMs onto resource-constrained devices. For example, an optimal\nchoice between parameter learning and RAG may vary depending on the difficulty\nof the downstream task, the longer fine-tuning time does not necessarily help\nthe model, and a compressed LLM may be a better choice than an uncompressed LLM\nto learn from limited personalized data.",
      "tldr_zh": "这篇论文探讨了在资源受限的边缘设备上部署大语言模型 (LLMs) 的实证指导原则，针对传统缩放定律的假设进行了修正，以适应计算资源的限制。研究通过广泛实验分析了关键因素的权衡，包括学习方法（如参数学习与 RAG）、个性化数据的量、LLM 类型和大小、压缩方法、学习时间以及任务难度。关键发现包括：最优选择取决于下游任务的难度，较长的微调时间不一定提升性能，而压缩的 LLMs 在有限数据下可能比未压缩模型表现更好。这些指导原则为高效部署个性化 LLMs 提供了实用见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Benckmarking paper",
      "pdf_url": "http://arxiv.org/pdf/2406.03777v3",
      "published_date": "2024-06-06 06:41:53 UTC",
      "updated_date": "2024-10-02 04:14:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:11:17.854566"
    },
    {
      "arxiv_id": "2406.03776v2",
      "title": "XL-HeadTags: Leveraging Multimodal Retrieval Augmentation for the Multilingual Generation of News Headlines and Tags",
      "title_zh": "翻译失败",
      "authors": [
        "Faisal Tareque Shohan",
        "Mir Tafseer Nayeem",
        "Samsul Islam",
        "Abu Ubaida Akash",
        "Shafiq Joty"
      ],
      "abstract": "Millions of news articles published online daily can overwhelm readers.\nHeadlines and entity (topic) tags are essential for guiding readers to decide\nif the content is worth their time. While headline generation has been\nextensively studied, tag generation remains largely unexplored, yet it offers\nreaders better access to topics of interest. The need for conciseness in\ncapturing readers' attention necessitates improved content selection strategies\nfor identifying salient and relevant segments within lengthy articles, thereby\nguiding language models effectively. To address this, we propose to leverage\nauxiliary information such as images and captions embedded in the articles to\nretrieve relevant sentences and utilize instruction tuning with variations to\ngenerate both headlines and tags for news articles in a multilingual context.\nTo make use of the auxiliary information, we have compiled a dataset named\nXL-HeadTags, which includes 20 languages across 6 diverse language families.\nThrough extensive evaluation, we demonstrate the effectiveness of our\nplug-and-play multimodal-multilingual retrievers for both tasks. Additionally,\nwe have developed a suite of tools for processing and evaluating multilingual\ntexts, significantly contributing to the research community by enabling more\naccurate and efficient analysis across languages.",
      "tldr_zh": "本研究提出XL-HeadTags框架，利用多模态检索增强(Multimodal Retrieval Augmentation)来生成多语言新闻标题和标签，旨在帮助读者从海量文章中快速识别关键内容。方法包括利用文章中的辅助信息（如图像和标题）检索相关句子，并通过指令微调(Instruction Tuning with variations)生成简洁的多语言输出，同时编译了覆盖20种语言的XL-HeadTags数据集。实验结果显示，该框架在多语言上下文中有效，提升了内容选择策略，并提供了处理多语言文本的工具套件，支持更准确的跨语言分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 camera ready. The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2406.03776v2",
      "published_date": "2024-06-06 06:40:19 UTC",
      "updated_date": "2024-06-07 05:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:11:29.372960"
    },
    {
      "arxiv_id": "2406.18584v2",
      "title": "Assessment of Sentinel-2 spatial and temporal coverage based on the scene classification layer",
      "title_zh": "翻译失败",
      "authors": [
        "Cristhian Sanchez",
        "Francisco Mena",
        "Marcela Charfuelan",
        "Marlon Nuske",
        "Andreas Dengel"
      ],
      "abstract": "Since the launch of the Sentinel-2 (S2) satellites, many ML models have used\nthe data for diverse applications. The scene classification layer (SCL) inside\nthe S2 product provides rich information for training, such as filtering images\nwith high cloud coverage. However, there is more potential in this. We propose\na technique to assess the clean optical coverage of a region, expressed by a\nSITS and calculated with the S2-based SCL data. With a manual threshold and\nspecific labels in the SCL, the proposed technique assigns a percentage of\nspatial and temporal coverage across the time series and a high/low assessment.\nBy evaluating the AI4EO challenge for Enhanced Agriculture, we show that the\nassessment is correlated to the predictive results of ML models. The\nclassification results in a region with low spatial and temporal coverage is\nworse than in a region with high coverage. Finally, we applied the technique\nacross all continents of the global dataset LandCoverNet.",
      "tldr_zh": "本文提出一种基于Sentinel-2 (S2) 场景分类层 (SCL) 的技术，用于评估区域的清洁光学覆盖，表现为空间-时间图像序列 (SITS)。该方法通过手动阈值和特定SCL标签，计算覆盖百分比并给出高/低评估，帮助过滤高云覆盖图像。实验结果显示，该评估与机器学习 (ML) 模型的预测性能高度相关，低覆盖区域的分类准确率明显低于高覆盖区域。最终，该技术被应用于全球数据集LandCoverNet的所有大陆，展示了其在增强农业 (Enhanced Agriculture) 等领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18584v2",
      "published_date": "2024-06-06 06:22:06 UTC",
      "updated_date": "2024-06-28 07:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:11:44.963781"
    },
    {
      "arxiv_id": "2406.03768v2",
      "title": "Enhancing In-Context Learning Performance with just SVD-Based Weight Pruning: A Theoretical Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Xinhao Yao",
        "Xiaolin Hu",
        "Shenzhi Yang",
        "Yong Liu"
      ],
      "abstract": "Pre-trained large language models (LLMs) based on Transformer have\ndemonstrated striking in-context learning (ICL) abilities. With a few\ndemonstration input-label pairs, they can predict the label for an unseen input\nwithout any parameter updates. In this paper, we show an exciting phenomenon\nthat SVD-based weight pruning can enhance ICL performance, and more surprising,\npruning weights in deep layers often results in more stable performance\nimprovements than in shallow layers. However, the underlying mechanism of those\nfindings still remains an open question. To reveal those findings, we conduct\nan in-depth theoretical analysis by presenting the implicit gradient descent\n(GD) trajectories of ICL and giving the mutual information based generalization\nbounds of ICL via full implicit GD trajectories. This helps us reasonably\nexplain the surprising experimental findings. Besides, based on all our\nexperimental and theoretical insights, we intuitively propose a simple,\nmodel-compression and derivative-free algorithm for downstream tasks in\nenhancing ICL inference. Experiments on benchmark datasets and open source LLMs\ndisplay the method effectiveness\\footnote{The code is available at\n\\url{https://github.com/chen123CtrlS/EnhancingICL_SVDPruning}.}.",
      "tldr_zh": "本研究发现，使用 SVD-based weight pruning 可以显著提升预训练大型语言模型 (LLMs) 的 In-Context Learning (ICL) 性能，且在深层进行剪枝比浅层更稳定。作者通过理论分析隐式梯度下降 (GD) 轨迹和基于互信息的泛化界，解释了这一现象的潜在机制。基于这些洞见，他们提出一个简单、模型压缩且无导数的算法，用于增强下游任务中的 ICL 推理，并在基准数据集和开源 LLMs 上实验验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03768v2",
      "published_date": "2024-06-06 06:15:35 UTC",
      "updated_date": "2024-10-13 11:19:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:11:57.009910"
    },
    {
      "arxiv_id": "2406.04383v2",
      "title": "Exploring the Latest LLMs for Leaderboard Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Salomon Kabongo",
        "Jennifer D'Souza",
        "Sören Auer"
      ],
      "abstract": "The rapid advancements in Large Language Models (LLMs) have opened new\navenues for automating complex tasks in AI research. This paper investigates\nthe efficacy of different LLMs-Mistral 7B, Llama-2, GPT-4-Turbo and GPT-4.o in\nextracting leaderboard information from empirical AI research articles. We\nexplore three types of contextual inputs to the models: DocTAET (Document\nTitle, Abstract, Experimental Setup, and Tabular Information), DocREC (Results,\nExperiments, and Conclusions), and DocFULL (entire document). Our comprehensive\nstudy evaluates the performance of these models in generating (Task, Dataset,\nMetric, Score) quadruples from research papers. The findings reveal significant\ninsights into the strengths and limitations of each model and context type,\nproviding valuable guidance for future AI research automation efforts.",
      "tldr_zh": "这篇论文探讨了最新大型语言模型（LLMs）如 Mistral 7B、Llama-2、GPT-4-Turbo 和 GPT-4.o 在从 AI 研究文章中提取排行榜信息的能力。研究者评估了三种上下文输入类型：DocTAET（文档标题、摘要、实验设置和表格信息）、DocREC（结果、实验和结论）、以及 DocFULL（整个文档），并测试这些模型生成（Task, Dataset, Metric, Score）四元组的性能。结果揭示了各模型和上下文类型的优势与局限性，为未来的 AI 研究自动化提供了宝贵指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04383v2",
      "published_date": "2024-06-06 05:54:45 UTC",
      "updated_date": "2024-07-08 19:04:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:12:08.474311"
    },
    {
      "arxiv_id": "2406.03747v1",
      "title": "Instance Segmentation and Teeth Classification in Panoramic X-rays",
      "title_zh": "全景 X 光片中的实例分割和牙齿分类",
      "authors": [
        "Devichand Budagam",
        "Ayush Kumar",
        "Sayan Ghosh",
        "Anuj Shrivastav",
        "Azamat Zhanatuly Imanbayev",
        "Iskander Rafailovich Akhmetov",
        "Dmitrii Kaplun",
        "Sergey Antonov",
        "Artem Rychenkov",
        "Gleb Cyganov",
        "Aleksandr Sinitca"
      ],
      "abstract": "Teeth segmentation and recognition are critical in various dental\napplications and dental diagnosis. Automatic and accurate segmentation\napproaches have been made possible by integrating deep learning models.\nAlthough teeth segmentation has been studied in the past, only some techniques\nwere able to effectively classify and segment teeth simultaneously. This\narticle offers a pipeline of two deep learning models, U-Net and YOLOv8, which\nresults in BB-UNet, a new architecture for the classification and segmentation\nof teeth on panoramic X-rays that is efficient and reliable. We have improved\nthe quality and reliability of teeth segmentation by utilising the YOLOv8 and\nU-Net capabilities. The proposed networks have been evaluated using the mean\naverage precision (mAP) and dice coefficient for YOLOv8 and BB-UNet,\nrespectively. We have achieved a 3\\% increase in mAP score for teeth\nclassification compared to existing methods, and a 10-15\\% increase in dice\ncoefficient for teeth segmentation compared to U-Net across different\ncategories of teeth. A new Dental dataset was created based on UFBA-UESC\ndataset with Bounding-Box and Polygon annotations of 425 dental panoramic\nX-rays. The findings of this research pave the way for a wider adoption of\nobject detection models in the field of dental diagnosis.",
      "tldr_zh": "这篇论文提出了一种新的架构 BB-UNet，利用 U-Net 和 YOLOv8 模型的管道，实现全景 X 光片中牙齿的实例分割和分类，从而解决传统方法在同时处理这两任务时的局限性。研究通过整合 YOLOv8 的物体检测优势和 U-Net 的分割能力，提高了牙齿分割的质量和可靠性。实验评估显示，YOLOv8 的 mAP 比现有方法提高了 3%，而 BB-UNet 的 Dice coefficient 在不同牙齿类别上比 U-Net 提高了 10-15%。此外，论文创建了一个新的 Dental 数据集，基于 UFBA-UESC 数据集的 425 张标注图像，为牙科诊断中物体检测模型的广泛应用奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "submtted to Expert Systems with Applications Journal",
      "pdf_url": "http://arxiv.org/pdf/2406.03747v1",
      "published_date": "2024-06-06 04:57:29 UTC",
      "updated_date": "2024-06-06 04:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:12:22.804996"
    },
    {
      "arxiv_id": "2406.03746v1",
      "title": "Efficient Knowledge Infusion via KG-LLM Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Zhouyu Jiang",
        "Ling Zhong",
        "Mengshu Sun",
        "Jun Xu",
        "Rui Sun",
        "Hui Cai",
        "Shuhan Luo",
        "Zhiqiang Zhang"
      ],
      "abstract": "To tackle the problem of domain-specific knowledge scarcity within large\nlanguage models (LLMs), knowledge graph-retrievalaugmented method has been\nproven to be an effective and efficient technique for knowledge infusion.\nHowever, existing approaches face two primary challenges: knowledge mismatch\nbetween public available knowledge graphs and the specific domain of the task\nat hand, and poor information compliance of LLMs with knowledge graphs. In this\npaper, we leverage a small set of labeled samples and a large-scale corpus to\nefficiently construct domain-specific knowledge graphs by an LLM, addressing\nthe issue of knowledge mismatch. Additionally, we propose a three-stage KG-LLM\nalignment strategyto enhance the LLM's capability to utilize information from\nknowledge graphs. We conduct experiments with a limited-sample setting on two\nbiomedical question-answering datasets, and the results demonstrate that our\napproach outperforms existing baselines.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)中领域特定知识不足的问题，提出了一种高效的知识注入方法，通过利用少量标记样本和大规模语料库，由LLM构建领域特定知识图谱(Knowledge Graphs)，以解决知识不匹配问题。作者还设计了三阶段KG-LLM Alignment策略，提升LLMs与知识图谱的信息兼容性，从而增强模型利用外部知识的能力。在两个生物医学问答数据集上的有限样本实验中，该方法显著优于现有基线，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.03746v1",
      "published_date": "2024-06-06 04:55:55 UTC",
      "updated_date": "2024-06-06 04:55:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:12:31.344831"
    },
    {
      "arxiv_id": "2406.03733v4",
      "title": "Credit Card Fraud Detection Using Advanced Transformer Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Yu",
        "Yongshun Xu",
        "Jin Cao",
        "Ye Zhang",
        "Yinxin Jin",
        "Mengran Zhu"
      ],
      "abstract": "With the proliferation of various online and mobile payment systems, credit\ncard fraud has emerged as a significant threat to financial security. This\nstudy focuses on innovative applications of the latest Transformer models for\nmore robust and precise fraud detection. To ensure the reliability of the data,\nwe meticulously processed the data sources, balancing the dataset to address\nthe issue of data sparsity significantly. We also selected highly correlated\nvectors to strengthen the training process.To guarantee the reliability and\npracticality of the new Transformer model, we conducted performance comparisons\nwith several widely adopted models, including Support Vector Machine (SVM),\nRandom Forest, Neural Network, and Logistic Regression. We rigorously compared\nthese models using metrics such as Precision, Recall, and F1 Score. Through\nthese detailed analyses and comparisons, we present to the readers a highly\nefficient and powerful anti-fraud mechanism with promising prospects. The\nresults demonstrate that the Transformer model not only excels in traditional\napplications but also shows great potential in niche areas like fraud\ndetection, offering a substantial advancement in the field.",
      "tldr_zh": "本文提出了一种使用高级Transformer模型进行信用卡欺诈检测的方法，以应对在线支付系统中的金融安全威胁。研究团队通过平衡数据集和选择高度相关的向量来处理数据稀疏问题，并与Support Vector Machine (SVM)、Random Forest、Neural Network和Logistic Regression等模型进行比较，使用Precision、Recall和F1 Score作为评估指标。结果表明，Transformer模型在欺诈检测任务中表现出色，准确率和整体性能显著优于基线模型。总体而言，这一方法为高效的反欺诈机制提供了创新解决方案，并展示了Transformer模型在该领域的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper have been received by https://ieee-metacom.org/",
      "pdf_url": "http://arxiv.org/pdf/2406.03733v4",
      "published_date": "2024-06-06 04:12:57 UTC",
      "updated_date": "2024-11-12 16:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:12:44.216892"
    },
    {
      "arxiv_id": "2406.03730v1",
      "title": "FastGAS: Fast Graph-based Annotation Selection for In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Chen",
        "Song Wang",
        "Cong Shen",
        "Jundong Li"
      ],
      "abstract": "In-context learning (ICL) empowers large language models (LLMs) to tackle new\ntasks by using a series of training instances as prompts. Since generating the\nprompts needs to sample from a vast pool of instances and annotate them (e.g.,\nadd labels in classification task), existing methods have proposed to select a\nsubset of unlabeled examples for annotation, thus enhancing the quality of\nprompts and concurrently mitigating annotation costs. However, these methods\noften require a long time to select instances due to their complexity,\nhindering their practical viability. To address this limitation, we propose a\ngraph-based selection method, FastGAS, designed to efficiently identify\nhigh-quality instances while minimizing computational overhead. Initially, we\nconstruct a data similarity graph based on instance similarities. Subsequently,\nemploying a graph partitioning algorithm, we partition the graph into pieces.\nWithin each piece (i.e., subgraph), we adopt a greedy approach to pick the most\nrepresentative nodes. By aggregating nodes from diverse pieces and annotating\nthe corresponding instances, we identify a set of diverse and representative\ninstances for ICL. Compared to prior approaches, our method not only exhibits\nsuperior performance on different tasks but also significantly reduces\nselection time. In addition, we demonstrate the efficacy of our approach in\nLLMs of larger sizes.",
      "tldr_zh": "论文提出 FastGAS，一种基于图的快速标注选择方法，用于 In-context Learning (ICL)，旨在从大量实例中高效选择高质量子集以减少标注成本和时间。方法首先构建数据相似性图，然后通过图分区算法将图分解为子图，并在每个子图中采用贪婪策略选择最有代表性的节点，最终聚合这些实例进行标注。实验结果表明，FastGAS 在不同任务上比现有方法表现出色，同时显著降低选择时间，并在更大规模的 Large Language Models (LLMs) 上显示出有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03730v1",
      "published_date": "2024-06-06 04:05:54 UTC",
      "updated_date": "2024-06-06 04:05:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:12:55.685573"
    },
    {
      "arxiv_id": "2406.04382v2",
      "title": "Improving the Fairness of Deep-Learning, Short-term Crime Prediction with Under-reporting-aware Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahui Wu",
        "Vanessa Frias-Martinez"
      ],
      "abstract": "Deep learning crime predictive tools use past crime data and additional\nbehavioral datasets to forecast future crimes. Nevertheless, these tools have\nbeen shown to suffer from unfair predictions across minority racial and ethnic\ngroups. Current approaches to address this unfairness generally propose either\npre-processing methods that mitigate the bias in the training datasets by\napplying corrections to crime counts based on domain knowledge or in-processing\nmethods that are implemented as fairness regularizers to optimize for both\naccuracy and fairness. In this paper, we propose a novel deep learning\narchitecture that combines the power of these two approaches to increase\nprediction fairness. Our results show that the proposed model improves the\nfairness of crime predictions when compared to models with in-processing\nde-biasing approaches and with models without any type of bias correction,\nalbeit at the cost of reducing accuracy.",
      "tldr_zh": "这篇论文针对深度学习(short-term crime prediction)工具在少数族裔群体中的预测不公平问题，提出了一种新型架构，该架构结合了pre-processing方法（通过校正犯罪数据缓解偏差）和in-processing方法（作为公平正则化器优化准确性和公平性）。这种under-reporting-aware模型旨在提升预测的公平性。实验结果表明，与无偏差校正或仅使用in-processing的模型相比，该方法显著提高了公平性，但会以牺牲部分准确性为代价。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "25 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.04382v2",
      "published_date": "2024-06-06 04:05:23 UTC",
      "updated_date": "2024-06-13 17:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:13:07.070395"
    },
    {
      "arxiv_id": "2406.03722v1",
      "title": "Offline Multi-Objective Optimization",
      "title_zh": "离线多目标优化",
      "authors": [
        "Ke Xue",
        "Rong-Xi Tan",
        "Xiaobin Huang",
        "Chao Qian"
      ],
      "abstract": "Offline optimization aims to maximize a black-box objective function with a\nstatic dataset and has wide applications. In addition to the objective function\nbeing black-box and expensive to evaluate, numerous complex real-world problems\nentail optimizing multiple conflicting objectives, i.e., multi-objective\noptimization (MOO). Nevertheless, offline MOO has not progressed as much as\noffline single-objective optimization (SOO), mainly due to the lack of\nbenchmarks like Design-Bench for SOO. To bridge this gap, we propose a first\nbenchmark for offline MOO, covering a range of problems from synthetic to\nreal-world tasks. This benchmark provides tasks, datasets, and open-source\nexamples, which can serve as a foundation for method comparisons and\nadvancements in offline MOO. Furthermore, we analyze how the current related\nmethods can be adapted to offline MOO from four fundamental perspectives,\nincluding data, model architecture, learning algorithm, and search algorithm.\nEmpirical results show improvements over the best value of the training set,\ndemonstrating the effectiveness of offline MOO methods. As no particular method\nstands out significantly, there is still an open challenge in further enhancing\nthe effectiveness of offline MOO. We finally discuss future challenges for\noffline MOO, with the hope of shedding some light on this emerging field. Our\ncode is available at \\url{https://github.com/lamda-bbo/offline-moo}.",
      "tldr_zh": "这篇论文针对离线多目标优化（offline MOO）的问题，提出了第一个基准（benchmark），涵盖从合成到真实世界任务，提供任务、数据集和开源示例，以填补该领域的空白。论文分析了如何从数据、模型架构、学习算法和搜索算法四个方面适应现有方法，并通过实证实验证明这些方法在训练集上取得了显著改进。结果显示，虽然没有一种方法全面领先，但offline MOO 的有效性已得到验证，并指出了未来挑战以推动该领域的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03722v1",
      "published_date": "2024-06-06 03:35:09 UTC",
      "updated_date": "2024-06-06 03:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:13:20.993583"
    },
    {
      "arxiv_id": "2406.03721v1",
      "title": "Attribute-Aware Implicit Modality Alignment for Text Attribute Person Search",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Wang",
        "Fangfang Liu",
        "Zheng Li",
        "Caili Guo"
      ],
      "abstract": "Text attribute person search aims to find specific pedestrians through given\ntextual attributes, which is very meaningful in the scene of searching for\ndesignated pedestrians through witness descriptions. The key challenge is the\nsignificant modality gap between textual attributes and images. Previous\nmethods focused on achieving explicit representation and alignment through\nunimodal pre-trained models. Nevertheless, the absence of inter-modality\ncorrespondence in these models may lead to distortions in the local information\nof intra-modality. Moreover, these methods only considered the alignment of\ninter-modality and ignored the differences between different attribute\ncategories. To mitigate the above problems, we propose an Attribute-Aware\nImplicit Modality Alignment (AIMA) framework to learn the correspondence of\nlocal representations between textual attributes and images and combine global\nrepresentation matching to narrow the modality gap. Firstly, we introduce the\nCLIP model as the backbone and design prompt templates to transform attribute\ncombinations into structured sentences. This facilitates the model's ability to\nbetter understand and match image details. Next, we design a Masked Attribute\nPrediction (MAP) module that predicts the masked attributes after the\ninteraction of image and masked textual attribute features through multi-modal\ninteraction, thereby achieving implicit local relationship alignment. Finally,\nwe propose an Attribute-IoU Guided Intra-Modal Contrastive (A-IoU IMC) loss,\naligning the distribution of different textual attributes in the embedding\nspace with their IoU distribution, achieving better semantic arrangement.\nExtensive experiments on the Market-1501 Attribute, PETA, and PA100K datasets\nshow that the performance of our proposed method significantly surpasses the\ncurrent state-of-the-art methods.",
      "tldr_zh": "这篇论文针对文本属性人搜索（Text attribute person search）问题，提出了一种属性感知的隐式模态对齐框架（Attribute-Aware Implicit Modality Alignment, AIMA），旨在缩小文本属性和图像之间的模态差距，同时考虑不同属性类别的差异。框架以 CLIP 模型为骨干，通过设计 prompt templates 将属性组合转化为结构化句子，并引入 Masked Attribute Prediction (MAP) 模块来实现多模态交互下的隐式局部关系对齐。论文还提出 Attribute-IoU Guided Intra-Modal Contrastive (A-IoU IMC) loss，以根据 IoU 分布对齐文本属性的嵌入空间分布，从而提升语义匹配精度。在 Market-1501 Attribute、PETA 和 PA100K 数据集上的实验显示，该方法显著超过了现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03721v1",
      "published_date": "2024-06-06 03:34:42 UTC",
      "updated_date": "2024-06-06 03:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:13:34.581897"
    },
    {
      "arxiv_id": "2406.03718v1",
      "title": "Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning",
      "title_zh": "通过多任务指令微调增强的代码漏洞检测泛化能力",
      "authors": [
        "Xiaohu Du",
        "Ming Wen",
        "Jiahao Zhu",
        "Zifan Xie",
        "Bin Ji",
        "Huijun Liu",
        "Xuanhua Shi",
        "Hai Jin"
      ],
      "abstract": "Code Pre-trained Models (CodePTMs) based vulnerability detection have\nachieved promising results over recent years. However, these models struggle to\ngeneralize as they typically learn superficial mapping from source code to\nlabels instead of understanding the root causes of code vulnerabilities,\nresulting in poor performance in real-world scenarios beyond the training\ninstances. To tackle this challenge, we introduce VulLLM, a novel framework\nthat integrates multi-task learning with Large Language Models (LLMs) to\neffectively mine deep-seated vulnerability features. Specifically, we construct\ntwo auxiliary tasks beyond the vulnerability detection task. First, we utilize\nthe vulnerability patches to construct a vulnerability localization task.\nSecond, based on the vulnerability features extracted from patches, we leverage\nGPT-4 to construct a vulnerability interpretation task. VulLLM innovatively\naugments vulnerability classification by leveraging generative LLMs to\nunderstand complex vulnerability patterns, thus compelling the model to capture\nthe root causes of vulnerabilities rather than overfitting to spurious features\nof a single task. The experiments conducted on six large datasets demonstrate\nthat VulLLM surpasses seven state-of-the-art models in terms of effectiveness,\ngeneralization, and robustness.",
      "tldr_zh": "该研究针对 CodePTMs 在代码漏洞检测中的泛化能力不足问题，提出了 VulLLM 框架，通过多任务指令微调整合 LLMs 来挖掘漏洞的深层根因。具体地，VulLLM 构建了漏洞检测、漏洞定位和漏洞解释三个任务，利用 GPT-4 生成漏洞解释，从而帮助模型捕捉复杂漏洞模式而非表面特征。实验结果显示，在六个大型数据集上，VulLLM 超过了七个最先进模型，在有效性、泛化性和鲁棒性方面均有显著提升。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.03718v1",
      "published_date": "2024-06-06 03:29:05 UTC",
      "updated_date": "2024-06-06 03:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:13:49.028062"
    },
    {
      "arxiv_id": "2406.03711v1",
      "title": "Pi-fusion: Physics-informed diffusion model for learning fluid dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Qiu",
        "Jiancheng Huang",
        "Xiangdong Zhang",
        "Zeng Lin",
        "Minglei Pan",
        "Zengding Liu",
        "Fen Miao"
      ],
      "abstract": "Physics-informed deep learning has been developed as a novel paradigm for\nlearning physical dynamics recently. While general physics-informed deep\nlearning methods have shown early promise in learning fluid dynamics, they are\ndifficult to generalize in arbitrary time instants in real-world scenario,\nwhere the fluid motion can be considered as a time-variant trajectory involved\nlarge-scale particles. Inspired by the advantage of diffusion model in learning\nthe distribution of data, we first propose Pi-fusion, a physics-informed\ndiffusion model for predicting the temporal evolution of velocity and pressure\nfield in fluid dynamics. Physics-informed guidance sampling is proposed in the\ninference procedure of Pi-fusion to improve the accuracy and interpretability\nof learning fluid dynamics. Furthermore, we introduce a training strategy based\non reciprocal learning to learn the quasiperiodical pattern of fluid motion and\nthus improve the generalizability of the model. The proposed approach are then\nevaluated on both synthetic and real-world dataset, by comparing it with\nstate-of-the-art physics-informed deep learning methods. Experimental results\nshow that the proposed approach significantly outperforms existing methods for\npredicting temporal evolution of velocity and pressure field, confirming its\nstrong generalization by drawing probabilistic inference of forward process and\nphysics-informed guidance sampling. The proposed Pi-fusion can also be\ngeneralized in learning other physical dynamics governed by partial\ndifferential equations.",
      "tldr_zh": "该研究提出Pi-fusion，一种physics-informed diffusion model，用于预测流体动力学中速度和压力场的时变演化，以解决传统physics-informed deep learning方法在泛化任意时间点时的挑战。模型通过physics-informed guidance sampling提升预测的准确性和可解释性，并采用基于reciprocal learning的训练策略来学习流体运动的准周期模式，从而提高泛化能力。在合成和真实数据集上的实验表明，Pi-fusion显著优于现有方法，在预测速度和压力场演化方面表现出色，并可推广到其他由偏微分方程治理的物理动力学。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03711v1",
      "published_date": "2024-06-06 03:14:59 UTC",
      "updated_date": "2024-06-06 03:14:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:13:59.690975"
    },
    {
      "arxiv_id": "2406.03710v2",
      "title": "TwinS: Revisiting Non-Stationarity in Multivariate Time Series Forecasting",
      "title_zh": "TwinS：重新审视多变量时间序列预测中的非平稳性",
      "authors": [
        "Jiaxi Hu",
        "Qingsong Wen",
        "Sijie Ruan",
        "Li Liu",
        "Yuxuan Liang"
      ],
      "abstract": "Recently, multivariate time series forecasting tasks have garnered increasing\nattention due to their significant practical applications, leading to the\nemergence of various deep forecasting models. However, real-world time series\nexhibit pronounced non-stationary distribution characteristics. These\ncharacteristics are not solely limited to time-varying statistical properties\nhighlighted by non-stationary Transformer but also encompass three key aspects:\nnested periodicity, absence of periodic distributions, and hysteresis among\ntime variables. In this paper, we begin by validating this theory through\nwavelet analysis and propose the Transformer-based TwinS model, which consists\nof three modules to address the non-stationary periodic distributions: Wavelet\nConvolution, Period-Aware Attention, and Channel-Temporal Mixed MLP.\nSpecifically, The Wavelet Convolution models nested periods by scaling the\nconvolution kernel size like wavelet transform. The Period-Aware Attention\nguides attention computation by generating period relevance scores through a\nconvolutional sub-network. The Channel-Temporal Mixed MLP captures the overall\nrelationships between time series through channel-time mixing learning. TwinS\nachieves SOTA performance compared to mainstream TS models, with a maximum\nimprovement in MSE of 25.8\\% over PatchTST.",
      "tldr_zh": "该论文重新审视了多变量时间序列预测(Multivariate Time Series Forecasting)中的非平稳性(Non-Stationarity)，包括嵌套周期性、缺乏周期分布和变量滞后，通过波形分析(Wavelet Analysis)验证了这些特性。作者提出基于Transformer's TwinS模型，包含三个模块：Wavelet Convolution用于建模嵌套周期，Period-Aware Attention通过卷积子网络生成周期相关性分数指导注意力计算，以及Channel-Temporal Mixed MLP捕捉时间序列间的整体关系。实验结果表明，TwinS在主流模型中实现了SOTA性能，在MSE上比PatchTST提高了25.8%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03710v2",
      "published_date": "2024-06-06 03:14:23 UTC",
      "updated_date": "2024-07-14 14:55:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:14:13.302031"
    },
    {
      "arxiv_id": "2406.06594v2",
      "title": "Stock Movement Prediction with Multimodal Stable Fusion via Gated Cross-Attention Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Zong",
        "Hang Zhou"
      ],
      "abstract": "The accurate prediction of stock movements is crucial for investment\nstrategies. Stock prices are subject to the influence of various forms of\ninformation, including financial indicators, sentiment analysis, news\ndocuments, and relational structures. Predominant analytical approaches,\nhowever, tend to address only unimodal or bimodal sources, neglecting the\ncomplexity of multimodal data. Further complicating the landscape are the\nissues of data sparsity and semantic conflicts between these modalities, which\nare frequently overlooked by current models, leading to unstable performance\nand limiting practical applicability. To address these shortcomings, this study\nintroduces a novel architecture, named Multimodal Stable Fusion with Gated\nCross-Attention (MSGCA), designed to robustly integrate multimodal input for\nstock movement prediction. The MSGCA framework consists of three integral\ncomponents: (1) a trimodal encoding module, responsible for processing\nindicator sequences, dynamic documents, and a relational graph, and\nstandardizing their feature representations; (2) a cross-feature fusion module,\nwhere primary and consistent features guide the multimodal fusion of the three\nmodalities via a pair of gated cross-attention networks; and (3) a prediction\nmodule, which refines the fused features through temporal and dimensional\nreduction to execute precise movement forecasting. Empirical evaluations\ndemonstrate that the MSGCA framework exceeds current leading methods, achieving\nperformance gains of 8.1%, 6.1%, 21.7% and 31.6% on four multimodal datasets,\nrespectively, attributed to its enhanced multimodal fusion stability.",
      "tldr_zh": "本文提出了一种名为 Multimodal Stable Fusion with Gated Cross-Attention (MSGCA) 的新架构，用于准确预测股票运动，解决现有方法忽略的多模态数据（如财务指标、新闻文档和关系图）中的数据稀疏性和语义冲突问题。MSGCA 框架包括三模态编码模块处理特征标准化、基于 Gated Cross-Attention 的跨特征融合模块引导多模态整合，以及预测模块通过时间和维度减少实现精确预测。实验结果显示，该方法在四个多模态数据集上分别比领先方法提升 8.1%、6.1%、21.7% 和 31.6%，显著提高了融合稳定性和预测性能。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.LG",
        "68T07",
        "I.2.6; J.4"
      ],
      "primary_category": "q-fin.CP",
      "comment": "14 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06594v2",
      "published_date": "2024-06-06 03:13:34 UTC",
      "updated_date": "2024-12-02 07:04:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:14:26.412298"
    },
    {
      "arxiv_id": "2406.03707v1",
      "title": "What Should Embeddings Embed? Autoregressive Models Represent Latent Generating Distributions",
      "title_zh": "翻译失败",
      "authors": [
        "Liyi Zhang",
        "Michael Y. Li",
        "Thomas L. Griffiths"
      ],
      "abstract": "Autoregressive language models have demonstrated a remarkable ability to\nextract latent structure from text. The embeddings from large language models\nhave been shown to capture aspects of the syntax and semantics of language. But\nwhat {\\em should} embeddings represent? We connect the autoregressive\nprediction objective to the idea of constructing predictive sufficient\nstatistics to summarize the information contained in a sequence of\nobservations, and use this connection to identify three settings where the\noptimal content of embeddings can be identified: independent identically\ndistributed data, where the embedding should capture the sufficient statistics\nof the data; latent state models, where the embedding should encode the\nposterior distribution over states given the data; and discrete hypothesis\nspaces, where the embedding should reflect the posterior distribution over\nhypotheses given the data. We then conduct empirical probing studies to show\nthat transformers encode these three kinds of latent generating distributions,\nand that they perform well in out-of-distribution cases and without token\nmemorization in these settings.",
      "tldr_zh": "该论文探讨了自动回归模型的嵌入（embeddings）应该表示什么，提出这些模型能代表潜在生成分布（latent generating distributions），以总结序列观察中的信息。作者将自动回归预测目标与预测充分统计量（sufficient statistics）联系起来，分析了三种场景：独立同分布数据（independent identically distributed data）、潜在状态模型（latent state models）和离散假设空间（discrete hypothesis spaces），其中嵌入应编码后验分布。实证探测研究表明，Transformer 模型能有效捕捉这些分布，并在分布外情况和无令牌记忆化（token memorization）时表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML",
        "I.2; I.5"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.03707v1",
      "published_date": "2024-06-06 03:06:46 UTC",
      "updated_date": "2024-06-06 03:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:14:36.079035"
    },
    {
      "arxiv_id": "2406.03689v3",
      "title": "Evaluating the World Model Implicit in a Generative Model",
      "title_zh": "翻译失败",
      "authors": [
        "Keyon Vafa",
        "Justin Y. Chen",
        "Ashesh Rambachan",
        "Jon Kleinberg",
        "Sendhil Mullainathan"
      ],
      "abstract": "Recent work suggests that large language models may implicitly learn world\nmodels. How should we assess this possibility? We formalize this question for\nthe case where the underlying reality is governed by a deterministic finite\nautomaton. This includes problems as diverse as simple logical reasoning,\ngeographic navigation, game-playing, and chemistry. We propose new evaluation\nmetrics for world model recovery inspired by the classic Myhill-Nerode theorem\nfrom language theory. We illustrate their utility in three domains: game\nplaying, logic puzzles, and navigation. In all domains, the generative models\nwe consider do well on existing diagnostics for assessing world models, but our\nevaluation metrics reveal their world models to be far less coherent than they\nappear. Such incoherence creates fragility: using a generative model to solve\nrelated but subtly different tasks can lead to failures. Building generative\nmodels that meaningfully capture the underlying logic of the domains they model\nwould be immensely valuable; our results suggest new ways to assess how close a\ngiven model is to that goal.",
      "tldr_zh": "本研究评估了生成模型（generative model）中隐式世界模型（world model）的质量，通过形式化底层现实为确定性有限自动机（deterministic finite automaton），涵盖逻辑推理、游戏和导航等领域。作者提出新评估指标，受 Myhill-Nerode theorem 启发，在游戏、逻辑谜题和导航领域测试结果显示，虽然生成模型在现有诊断中表现良好，但其世界模型存在显著不连贯性。这样的不连贯导致模型在处理相关但微妙不同的任务时易出现失败现象。该工作为构建更能捕捉领域底层逻辑的生成模型提供了新的评估途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03689v3",
      "published_date": "2024-06-06 02:20:31 UTC",
      "updated_date": "2024-11-10 23:47:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:14:47.905813"
    },
    {
      "arxiv_id": "2406.06593v1",
      "title": "Differentiable Combinatorial Scheduling at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Mingju Liu",
        "Yingjie Li",
        "Jiaqi Yin",
        "Zhiru Zhang",
        "Cunxi Yu"
      ],
      "abstract": "This paper addresses the complex issue of resource-constrained scheduling, an\nNP-hard problem that spans critical areas including chip design and\nhigh-performance computing. Traditional scheduling methods often stumble over\nscalability and applicability challenges. We propose a novel approach using a\ndifferentiable combinatorial scheduling framework, utilizing Gumbel-Softmax\ndifferentiable sampling technique. This new technical allows for a fully\ndifferentiable formulation of linear programming (LP) based scheduling,\nextending its application to a broader range of LP formulations. To encode\ninequality constraints for scheduling tasks, we introduce \\textit{constrained\nGumbel Trick}, which adeptly encodes arbitrary inequality constraints.\nConsequently, our method facilitates an efficient and scalable scheduling via\ngradient descent without the need for training data. Comparative evaluations on\nboth synthetic and real-world benchmarks highlight our capability to\nsignificantly improve the optimization efficiency of scheduling, surpassing\nstate-of-the-art solutions offered by commercial and open-source solvers such\nas CPLEX, Gurobi, and CP-SAT in the majority of the designs.",
      "tldr_zh": "这篇论文针对资源受限调度（一个NP-hard问题），在芯片设计和高性能计算等领域提出了一个新型可微分组合调度框架，使用Gumbel-Softmax可微分采样技术，使线性规划（LP）基于的调度完全可微化，并扩展到更广泛的LP公式。论文引入了constrained Gumbel Trick来高效编码任意不等式约束，从而通过梯度下降实现无需训练数据的可扩展优化。实验结果显示，该方法在合成和真实基准测试中，优于CPLEX、Gurobi和CP-SAT等商用和开源求解器，在大多数设计中显著提高了优化效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages; International Conference on Machine Learning (ICML'24)",
      "pdf_url": "http://arxiv.org/pdf/2406.06593v1",
      "published_date": "2024-06-06 02:09:39 UTC",
      "updated_date": "2024-06-06 02:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:15:10.014661"
    },
    {
      "arxiv_id": "2407.10977v1",
      "title": "CIRCUITSYNTH: Leveraging Large Language Models for Circuit Topology Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Prashanth Vijayaraghavan",
        "Luyao Shi",
        "Ehsan Degan",
        "Xin Zhang"
      ],
      "abstract": "Circuit topology generation plays a crucial role in the design of electronic\ncircuits, influencing the fundamental functionality of the circuit. In this\npaper, we introduce CIRCUITSYNTH, a novel approach that harnesses LLMs to\nfacilitate the automated synthesis of valid circuit topologies. With a dataset\ncomprising both valid and invalid circuit configurations, CIRCUITSYNTH employs\na sophisticated two-phase methodology, comprising Circuit Topology Generation\nand Circuit Topology Refinement. Experimental results demonstrate the\neffectiveness of CIRCUITSYNTH compared to various fine-tuned LLM variants. Our\napproach lays the foundation for future research aimed at enhancing circuit\nefficiency and specifying output voltage, thus enabling the automated\ngeneration of circuit topologies with improved performance and adherence to\ndesign requirements.",
      "tldr_zh": "本研究提出CIRCUITSYNTH，一种利用Large Language Models (LLMs)来自动合成有效电路拓扑的方法，以提升电子电路设计效率。方法采用两阶段流程，包括Circuit Topology Generation生成初步拓扑和Circuit Topology Refinement优化配置，基于一个包含有效和无效电路数据集进行训练。实验结果显示，CIRCUITSYNTH比各种fine-tuned LLM变体更有效，并为未来电路效率提升、输出电压指定以及自动生成高性能电路拓扑奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 1 figure, LAD'24",
      "pdf_url": "http://arxiv.org/pdf/2407.10977v1",
      "published_date": "2024-06-06 01:59:59 UTC",
      "updated_date": "2024-06-06 01:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:15:11.544255"
    },
    {
      "arxiv_id": "2406.03679v6",
      "title": "On the Effects of Data Scale on UI Control Agents",
      "title_zh": "数据规模对 UI 控制代理的影响",
      "authors": [
        "Wei Li",
        "William Bishop",
        "Alice Li",
        "Chris Rawles",
        "Folawiyo Campbell-Ajala",
        "Divya Tyamagundlu",
        "Oriana Riva"
      ],
      "abstract": "Autonomous agents that control computer interfaces to accomplish human tasks\nare emerging. Leveraging LLMs to power such agents has been of special\ninterest, but unless fine-tuned on human-collected task demonstrations,\nperformance is still relatively low. In this work we study whether fine-tuning\nalone is a viable approach for building real-world computer control agents. In\nparticularly, we investigate how performance measured on both high and\nlow-level tasks in domain and out of domain scales as more training data is\ncollected. To this end we collect and release a new dataset, AndroidControl,\nconsisting of 15,283 demonstrations of everyday tasks with Android apps.\nCompared to existing datasets, each AndroidControl task instance includes both\nhigh and low-level human-generated instructions, allowing us to explore the\nlevel of task complexity an agent can handle. Moreover, AndroidControl is the\nmost diverse computer control dataset to date, including 14,548 unique tasks\nover 833 Android apps, thus allowing us to conduct in-depth analysis of the\nmodel performance in and out of the domain of the training data. Using the\ndataset, we find that when tested in domain fine-tuned models outperform zero\nand few-shot baselines and scale in such a way that robust performance might\nfeasibly be obtained simply by collecting more data. Out of domain, performance\nscales significantly more slowly and suggests that in particular for high-level\ntasks, fine-tuning on more data alone may be insufficient for achieving robust\nout-of-domain performance.",
      "tldr_zh": "这篇论文探讨了数据规模对 UI 控制代理的影响，特别是使用 LLMs 构建自主代理来完成人类任务。研究者收集并发布了 AndroidControl 数据集，包含 15,283 个 Android 应用日常任务演示，每个任务包括高级和低级人类指令，以评估微调模型在域内和域外任务上的性能。结果表明，在域内，微调模型优于零样本和少样本基线，且性能随数据增加而显著提升；在域外，尤其是高级任务，性能提升更慢，暗示仅靠收集更多数据可能不足以实现稳健的 out-of-domain 性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 (Datasets and Benchmarks)",
      "pdf_url": "http://arxiv.org/pdf/2406.03679v6",
      "published_date": "2024-06-06 01:49:29 UTC",
      "updated_date": "2024-11-13 16:42:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:15:25.676955"
    },
    {
      "arxiv_id": "2406.03678v1",
      "title": "Reflective Policy Optimization",
      "title_zh": "反思策略优化",
      "authors": [
        "Yaozhong Gan",
        "Renye Yan",
        "Zhe Wu",
        "Junliang Xing"
      ],
      "abstract": "On-policy reinforcement learning methods, like Trust Region Policy\nOptimization (TRPO) and Proximal Policy Optimization (PPO), often demand\nextensive data per update, leading to sample inefficiency. This paper\nintroduces Reflective Policy Optimization (RPO), a novel on-policy extension\nthat amalgamates past and future state-action information for policy\noptimization. This approach empowers the agent for introspection, allowing\nmodifications to its actions within the current state. Theoretical analysis\nconfirms that policy performance is monotonically improved and contracts the\nsolution space, consequently expediting the convergence procedure. Empirical\nresults demonstrate RPO's feasibility and efficacy in two reinforcement\nlearning benchmarks, culminating in superior sample efficiency. The source code\nof this work is available at https://github.com/Edgargan/RPO.",
      "tldr_zh": "本研究提出Reflective Policy Optimization (RPO)，一种新型的on-policy强化学习方法，旨在解决传统算法如Trust Region Policy Optimization (TRPO)和Proximal Policy Optimization (PPO)样本效率低的问题。RPO通过整合过去和未来的状态-动作信息，允许代理在当前状态下进行反思并优化其动作，从而实现策略的改进。理论分析证明，RPO能单调提升策略性能、缩小解空间并加速收敛过程。实验结果在两个强化学习基准上验证了RPO的可靠性和优越样本效率，并提供了源代码（https://github.com/Edgargan/RPO）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.03678v1",
      "published_date": "2024-06-06 01:46:49 UTC",
      "updated_date": "2024-06-06 01:46:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:15:39.169672"
    },
    {
      "arxiv_id": "2406.03673v1",
      "title": "Linguistically Conditioned Semantic Textual Similarity",
      "title_zh": "基于语言条件的语义文本相似度",
      "authors": [
        "Jingxuan Tu",
        "Keer Xu",
        "Liulu Yue",
        "Bingyang Ye",
        "Kyeongmin Rim",
        "James Pustejovsky"
      ],
      "abstract": "Semantic textual similarity (STS) is a fundamental NLP task that measures the\nsemantic similarity between a pair of sentences. In order to reduce the\ninherent ambiguity posed from the sentences, a recent work called Conditional\nSTS (C-STS) has been proposed to measure the sentences' similarity conditioned\non a certain aspect. Despite the popularity of C-STS, we find that the current\nC-STS dataset suffers from various issues that could impede proper evaluation\non this task. In this paper, we reannotate the C-STS validation set and observe\nan annotator discrepancy on 55% of the instances resulting from the annotation\nerrors in the original label, ill-defined conditions, and the lack of clarity\nin the task definition. After a thorough dataset analysis, we improve the C-STS\ntask by leveraging the models' capability to understand the conditions under a\nQA task setting. With the generated answers, we present an automatic error\nidentification pipeline that is able to identify annotation errors from the\nC-STS data with over 80% F1 score. We also propose a new method that largely\nimproves the performance over baselines on the C-STS data by training the\nmodels with the answers. Finally we discuss the conditionality annotation based\non the typed-feature structure (TFS) of entity types. We show in examples that\nthe TFS is able to provide a linguistic foundation for constructing C-STS data\nwith new conditions.",
      "tldr_zh": "本论文探讨了语义文本相似性（STS）任务的改进，特别针对条件STS（C-STS），即在特定方面条件下测量句子相似性的问题。作者发现原C-STS数据集存在标注错误、条件定义不清等问题，导致55%的实例有标注分歧，并通过重新标注和利用QA任务生成答案，提出一个自动错误识别管道，F1分数超过80%。此外，他们引入新训练方法基于生成的答案提升模型性能，并讨论基于类型特征结构（TFS）的条件性标注，提供语言基础来构建更可靠的C-STS数据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in the ACL 2024 main proceedings",
      "pdf_url": "http://arxiv.org/pdf/2406.03673v1",
      "published_date": "2024-06-06 01:23:45 UTC",
      "updated_date": "2024-06-06 01:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:15:52.158773"
    },
    {
      "arxiv_id": "2406.03671v2",
      "title": "PANDA: Expanded Width-Aware Message Passing Beyond Rewiring",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongwhan Choi",
        "Sumin Park",
        "Hyowon Wi",
        "Sung-Bae Cho",
        "Noseong Park"
      ],
      "abstract": "Recent research in the field of graph neural network (GNN) has identified a\ncritical issue known as \"over-squashing,\" resulting from the bottleneck\nphenomenon in graph structures, which impedes the propagation of long-range\ninformation. Prior works have proposed a variety of graph rewiring concepts\nthat aim at optimizing the spatial or spectral properties of graphs to promote\nthe signal propagation. However, such approaches inevitably deteriorate the\noriginal graph topology, which may lead to a distortion of information flow. To\naddress this, we introduce an expanded width-aware (PANDA) message passing, a\nnew message passing paradigm where nodes with high centrality, a potential\nsource of over-squashing, are selectively expanded in width to encapsulate the\ngrowing influx of signals from distant nodes. Experimental results show that\nour method outperforms existing rewiring methods, suggesting that selectively\nexpanding the hidden state of nodes can be a compelling alternative to graph\nrewiring for addressing the over-squashing.",
      "tldr_zh": "该研究针对图神经网络（GNN）中的over-squashing问题，即图结构瓶颈导致长距离信息传播受阻，提出了一种新的消息传递范式：PANDA（Expanded Width-Aware Message Passing）。PANDA通过选择性地扩展高centrality节点的隐藏状态宽度，来处理来自远端节点的信息涌入，从而避免了传统重连图（rewiring）方法可能对原图拓扑造成扭曲。实验结果显示，该方法在性能上优于现有重连图方法，证明扩展节点隐藏状态是一种有效的替代策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03671v2",
      "published_date": "2024-06-06 01:14:24 UTC",
      "updated_date": "2024-07-20 03:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:16:04.495109"
    },
    {
      "arxiv_id": "2406.03668v1",
      "title": "3rd Place Solution for MOSE Track in CVPR 2024 PVUW workshop: Complex Video Object Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Liu",
        "Jing Zhang",
        "Kexin Zhang",
        "Yuting Yang",
        "Licheng Jiao",
        "Shuyuan Yang"
      ],
      "abstract": "Video Object Segmentation (VOS) is a vital task in computer vision, focusing\non distinguishing foreground objects from the background across video frames.\nOur work draws inspiration from the Cutie model, and we investigate the effects\nof object memory, the total number of memory frames, and input resolution on\nsegmentation performance. This report validates the effectiveness of our\ninference method on the coMplex video Object SEgmentation (MOSE) dataset, which\nfeatures complex occlusions. Our experimental results demonstrate that our\napproach achieves a J\\&F score of 0.8139 on the test set, securing the third\nposition in the final ranking. These findings highlight the robustness and\naccuracy of our method in handling challenging VOS scenarios.",
      "tldr_zh": "这篇论文介绍了针对复杂视频物体分割 (VOS) 的解决方案，基于 Cutie 模型，探讨了对象记忆、内存帧总数和输入分辨率对分割性能的影响。\n他们在 coMplex video Object SEgmentation (MOSE) 数据集上验证了该推理方法，成功处理复杂遮挡场景。\n实验结果显示，该方法在测试集上获得 J&F 得分 0.8139，在 CVPR 2024 PVUW 工作坊 MOSE 赛道中排名第三，展示了其在挑战性 VOS 任务中的鲁棒性和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03668v1",
      "published_date": "2024-06-06 00:56:25 UTC",
      "updated_date": "2024-06-06 00:56:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:16:17.279171"
    },
    {
      "arxiv_id": "2406.03665v2",
      "title": "Towards Dynamic Trend Filtering through Trend Point Detection with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jihyeon Seong",
        "Sekwang Oh",
        "Jaesik Choi"
      ],
      "abstract": "Trend filtering simplifies complex time series data by applying smoothness to\nfilter out noise while emphasizing proximity to the original data. However,\nexisting trend filtering methods fail to reflect abrupt changes in the trend\ndue to `approximateness,' resulting in constant smoothness. This\napproximateness uniformly filters out the tail distribution of time series\ndata, characterized by extreme values, including both abrupt changes and noise.\nIn this paper, we propose Trend Point Detection formulated as a Markov Decision\nProcess (MDP), a novel approach to identifying essential points that should be\nreflected in the trend, departing from approximations. We term these essential\npoints as Dynamic Trend Points (DTPs) and extract trends by interpolating them.\nTo identify DTPs, we utilize Reinforcement Learning (RL) within a discrete\naction space and a forecasting sum-of-squares loss function as a reward,\nreferred to as the Dynamic Trend Filtering network (DTF-net). DTF-net\nintegrates flexible noise filtering, preserving critical original subsequences\nwhile removing noise as required for other subsequences. We demonstrate that\nDTF-net excels at capturing abrupt changes compared to other trend filtering\nalgorithms and enhances forecasting performance, as abrupt changes are\npredicted rather than smoothed out.",
      "tldr_zh": "本论文针对现有趋势过滤(Trend Filtering)方法无法捕捉时间序列数据中的突发变化问题，提出了一种动态趋势点检测(Dynamic Trend Point Detection)方法，将其表述为Markov Decision Process (MDP)。该方法利用Reinforcement Learning (RL)在离散动作空间中识别关键的Dynamic Trend Points (DTPs)，并通过插值这些点来提取趋势，同时开发了Dynamic Trend Filtering network (DTF-net)作为奖励函数，以灵活过滤噪声并保留重要子序列。实验结果显示，DTF-net在捕捉突发变化和提升预测性能方面，优于传统趋势过滤算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.03665v2",
      "published_date": "2024-06-06 00:50:22 UTC",
      "updated_date": "2025-03-22 02:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:16:29.911464"
    },
    {
      "arxiv_id": "2406.04379v1",
      "title": "VHDL-Eval: A Framework for Evaluating Large Language Models in VHDL Code Generation",
      "title_zh": "VHDL-Eval：用于评估大型语言模型在 VHDL 代码生成中的框架",
      "authors": [
        "Prashanth Vijayaraghavan",
        "Luyao Shi",
        "Stefano Ambrogio",
        "Charles Mackin",
        "Apoorva Nitsure",
        "David Beymer",
        "Ehsan Degan"
      ],
      "abstract": "With the unprecedented advancements in Large Language Models (LLMs), their\napplication domains have expanded to include code generation tasks across\nvarious programming languages. While significant progress has been made in\nenhancing LLMs for popular programming languages, there exists a notable gap in\ncomprehensive evaluation frameworks tailored for Hardware Description Languages\n(HDLs), particularly VHDL. This paper addresses this gap by introducing a\ncomprehensive evaluation framework designed specifically for assessing LLM\nperformance in VHDL code generation task. We construct a dataset for evaluating\nLLMs on VHDL code generation task. This dataset is constructed by translating a\ncollection of Verilog evaluation problems to VHDL and aggregating publicly\navailable VHDL problems, resulting in a total of 202 problems. To assess the\nfunctional correctness of the generated VHDL code, we utilize a curated set of\nself-verifying testbenches specifically designed for those aggregated VHDL\nproblem set. We conduct an initial evaluation of different LLMs and their\nvariants, including zero-shot code generation, in-context learning (ICL), and\nParameter-efficient fine-tuning (PEFT) methods. Our findings underscore the\nconsiderable challenges faced by existing LLMs in VHDL code generation,\nrevealing significant scope for improvement. This study emphasizes the\nnecessity of supervised fine-tuning code generation models specifically for\nVHDL, offering potential benefits to VHDL designers seeking efficient code\ngeneration solutions.",
      "tldr_zh": "本论文引入了VHDL-Eval框架，用于评估大型语言模型(LLMs)在VHDL代码生成任务中的性能，填补了硬件描述语言(HDLs)评估领域的空白。该框架构建了一个包含202个问题的数据集，通过将Verilog问题翻译成VHDL并整合公开问题，并利用自验证测试bench来检查生成的代码功能正确性。研究评估了不同LLMs及其变体，包括零样本代码生成、In-Context Learning (ICL)和Parameter-Efficient Fine-Tuning (PEFT)方法，结果显示现有模型在VHDL代码生成中面临重大挑战，强调了针对VHDL进行监督微调的必要性，以为VHDL设计师提供更高效的代码生成解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "6 pages, 3 Figures, LAD'24",
      "pdf_url": "http://arxiv.org/pdf/2406.04379v1",
      "published_date": "2024-06-06 00:06:50 UTC",
      "updated_date": "2024-06-06 00:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:16:41.120820"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 145,
  "processed_papers_count": 145,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T17:17:06.414877"
}