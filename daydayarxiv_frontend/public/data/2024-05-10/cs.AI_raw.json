[
  {
    "arxiv_id": "2405.12999v1",
    "title": "An Assessment of Model-On-Model Deception",
    "authors": [
      "Julius Heitkoetter",
      "Michael Gerovitch",
      "Laker Newhouse"
    ],
    "abstract": "The trustworthiness of highly capable language models is put at risk when\nthey are able to produce deceptive outputs. Moreover, when models are\nvulnerable to deception it undermines reliability. In this paper, we introduce\na method to investigate complex, model-on-model deceptive scenarios. We create\na dataset of over 10,000 misleading explanations by asking Llama-2 7B, 13B,\n70B, and GPT-3.5 to justify the wrong answer for questions in the MMLU. We find\nthat, when models read these explanations, they are all significantly deceived.\nWorryingly, models of all capabilities are successful at misleading others,\nwhile more capable models are only slightly better at resisting deception. We\nrecommend the development of techniques to detect and defend against deception.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at Secure and Trustworthy Large Language Models Workshop at\n  ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.12999v1",
    "published_date": "2024-05-10 23:24:18 UTC",
    "updated_date": "2024-05-10 23:24:18 UTC"
  },
  {
    "arxiv_id": "2405.06849v1",
    "title": "GreedyViG: Dynamic Axial Graph Construction for Efficient Vision GNNs",
    "authors": [
      "Mustafa Munir",
      "William Avery",
      "Md Mostafijur Rahman",
      "Radu Marculescu"
    ],
    "abstract": "Vision graph neural networks (ViG) offer a new avenue for exploration in\ncomputer vision. A major bottleneck in ViGs is the inefficient k-nearest\nneighbor (KNN) operation used for graph construction. To solve this issue, we\npropose a new method for designing ViGs, Dynamic Axial Graph Construction\n(DAGC), which is more efficient than KNN as it limits the number of considered\ngraph connections made within an image. Additionally, we propose a novel\nCNN-GNN architecture, GreedyViG, which uses DAGC. Extensive experiments show\nthat GreedyViG beats existing ViG, CNN, and ViT architectures in terms of\naccuracy, GMACs, and parameters on image classification, object detection,\ninstance segmentation, and semantic segmentation tasks. Our smallest model,\nGreedyViG-S, achieves 81.1% top-1 accuracy on ImageNet-1K, 2.9% higher than\nVision GNN and 2.2% higher than Vision HyperGraph Neural Network (ViHGNN), with\nless GMACs and a similar number of parameters. Our largest model, GreedyViG-B\nobtains 83.9% top-1 accuracy, 0.2% higher than Vision GNN, with a 66.6%\ndecrease in parameters and a 69% decrease in GMACs. GreedyViG-B also obtains\nthe same accuracy as ViHGNN with a 67.3% decrease in parameters and a 71.3%\ndecrease in GMACs. Our work shows that hybrid CNN-GNN architectures not only\nprovide a new avenue for designing efficient models, but that they can also\nexceed the performance of current state-of-the-art models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Proceedings of the 2024 IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR)",
    "pdf_url": "http://arxiv.org/pdf/2405.06849v1",
    "published_date": "2024-05-10 23:21:16 UTC",
    "updated_date": "2024-05-10 23:21:16 UTC"
  },
  {
    "arxiv_id": "2405.06848v1",
    "title": "ISR: Invertible Symbolic Regression",
    "authors": [
      "Tony Tohme",
      "Mohammad Javad Khojasteh",
      "Mohsen Sadr",
      "Florian Meyer",
      "Kamal Youcef-Toumi"
    ],
    "abstract": "We introduce an Invertible Symbolic Regression (ISR) method. It is a machine\nlearning technique that generates analytical relationships between inputs and\noutputs of a given dataset via invertible maps (or architectures). The proposed\nISR method naturally combines the principles of Invertible Neural Networks\n(INNs) and Equation Learner (EQL), a neural network-based symbolic architecture\nfor function learning. In particular, we transform the affine coupling blocks\nof INNs into a symbolic framework, resulting in an end-to-end differentiable\nsymbolic invertible architecture that allows for efficient gradient-based\nlearning. The proposed ISR framework also relies on sparsity promoting\nregularization, allowing the discovery of concise and interpretable invertible\nexpressions. We show that ISR can serve as a (symbolic) normalizing flow for\ndensity estimation tasks. Furthermore, we highlight its practical applicability\nin solving inverse problems, including a benchmark inverse kinematics problem,\nand notably, a geoacoustic inversion problem in oceanography aimed at inferring\nposterior distributions of underlying seabed parameters from acoustic signals.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06848v1",
    "published_date": "2024-05-10 23:20:46 UTC",
    "updated_date": "2024-05-10 23:20:46 UTC"
  },
  {
    "arxiv_id": "2405.06846v1",
    "title": "Dominion: A New Frontier for AI Research",
    "authors": [
      "Danny Halawi",
      "Aron Sarmasi",
      "Siena Saltzen",
      "Joshua McCoy"
    ],
    "abstract": "In recent years, machine learning approaches have made dramatic advances,\nreaching superhuman performance in Go, Atari, and poker variants. These games,\nand others before them, have served not only as a testbed but have also helped\nto push the boundaries of AI research. Continuing this tradition, we examine\nthe tabletop game Dominion and discuss the properties that make it well-suited\nto serve as a benchmark for the next generation of reinforcement learning (RL)\nalgorithms. We also present the Dominion Online Dataset, a collection of over\n2,000,000 games of Dominion played by experienced players on the Dominion\nOnline webserver. Finally, we introduce an RL baseline bot that uses existing\ntechniques to beat common heuristic-based bots, and shows competitive\nperformance against the previously strongest bot, Provincial.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06846v1",
    "published_date": "2024-05-10 23:03:02 UTC",
    "updated_date": "2024-05-10 23:03:02 UTC"
  },
  {
    "arxiv_id": "2405.06835v1",
    "title": "Automating Code Adaptation for MLOps -- A Benchmarking Study on LLMs",
    "authors": [
      "Harsh Patel",
      "Buvaneswari A. Ramanan",
      "Manzoor A. Khan",
      "Thomas Williams",
      "Brian Friedman",
      "Lawrence Drabeck"
    ],
    "abstract": "This paper explores the possibilities of the current generation of Large\nLanguage Models for incorporating Machine Learning Operations (MLOps)\nfunctionalities into ML training code bases. We evaluate the performance of\nOpenAI (gpt-3.5-turbo) and WizardCoder (open-source, 15B parameters) models on\nthe automated accomplishment of various MLOps functionalities in different\nsettings. We perform a benchmarking study that assesses the ability of these\nmodels to: (1) adapt existing code samples (Inlining) with component-specific\nMLOps functionality such as MLflow and Weights & Biases for experiment\ntracking, Optuna for hyperparameter optimization etc., and (2) perform the task\nof Translation from one component of an MLOps functionality to another, e.g.,\ntranslating existing GitPython library based version control code to Data\nVersion Control library based. We also propose three different approaches that\ninvolve teaching LLMs to comprehend the API documentation of the components as\na reference while accomplishing the Translation tasks. In our evaluations, the\ngpt-3.5-turbo model significantly outperforms WizardCoder by achieving\nimpressive Pass@3 accuracy in model optimization (55% compared to 0% by\nWizardCoder), experiment tracking (100%, compared to 62.5% by WizardCoder),\nmodel registration (92% compared to 42% by WizardCoder) and hyperparameter\noptimization (83% compared to 58% by WizardCoder) on average, in their best\npossible settings, showcasing its superior code adaptability performance in\ncomplex MLOps tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "The work was completed during 2Q, 3Q of Year 2023, when WizardCoder\n  was the top performing Open source LLM for coding. Newer and better models\n  have emerged since then. The processes and methodologies utilized for this\n  benchmarking can still be utilized for evaluating the current SoTA models",
    "pdf_url": "http://arxiv.org/pdf/2405.06835v1",
    "published_date": "2024-05-10 22:18:43 UTC",
    "updated_date": "2024-05-10 22:18:43 UTC"
  },
  {
    "arxiv_id": "2405.06823v2",
    "title": "PLeak: Prompt Leaking Attacks against Large Language Model Applications",
    "authors": [
      "Bo Hui",
      "Haolin Yuan",
      "Neil Gong",
      "Philippe Burlina",
      "Yinzhi Cao"
    ],
    "abstract": "Large Language Models (LLMs) enable a new ecosystem with many downstream\napplications, called LLM applications, with different natural language\nprocessing tasks. The functionality and performance of an LLM application\nhighly depend on its system prompt, which instructs the backend LLM on what\ntask to perform. Therefore, an LLM application developer often keeps a system\nprompt confidential to protect its intellectual property. As a result, a\nnatural attack, called prompt leaking, is to steal the system prompt from an\nLLM application, which compromises the developer's intellectual property.\nExisting prompt leaking attacks primarily rely on manually crafted queries, and\nthus achieve limited effectiveness.\n  In this paper, we design a novel, closed-box prompt leaking attack framework,\ncalled PLeak, to optimize an adversarial query such that when the attacker\nsends it to a target LLM application, its response reveals its own system\nprompt. We formulate finding such an adversarial query as an optimization\nproblem and solve it with a gradient-based method approximately. Our key idea\nis to break down the optimization goal by optimizing adversary queries for\nsystem prompts incrementally, i.e., starting from the first few tokens of each\nsystem prompt step by step until the entire length of the system prompt.\n  We evaluate PLeak in both offline settings and for real-world LLM\napplications, e.g., those on Poe, a popular platform hosting such applications.\nOur results show that PLeak can effectively leak system prompts and\nsignificantly outperforms not only baselines that manually curate queries but\nalso baselines with optimized queries that are modified and adapted from\nexisting jailbreaking attacks. We responsibly reported the issues to Poe and\nare still waiting for their response. Our implementation is available at this\nrepository: https://github.com/BHui97/PLeak.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "To appear in the Proceedings of The ACM Conference on Computer and\n  Communications Security (CCS), 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06823v2",
    "published_date": "2024-05-10 21:52:34 UTC",
    "updated_date": "2024-05-14 15:03:12 UTC"
  },
  {
    "arxiv_id": "2405.06822v1",
    "title": "MH-pFLID: Model Heterogeneous personalized Federated Learning via Injection and Distillation for Medical Data Analysis",
    "authors": [
      "Luyuan Xie",
      "Manqing Lin",
      "Tianyu Luan",
      "Cong Li",
      "Yuejian Fang",
      "Qingni Shen",
      "Zhonghai Wu"
    ],
    "abstract": "Federated learning is widely used in medical applications for training global\nmodels without needing local data access. However, varying computational\ncapabilities and network architectures (system heterogeneity), across clients\npose significant challenges in effectively aggregating information from\nnon-independently and identically distributed (non-IID) data. Current federated\nlearning methods using knowledge distillation require public datasets, raising\nprivacy and data collection issues. Additionally, these datasets require\nadditional local computing and storage resources, which is a burden for medical\ninstitutions with limited hardware conditions. In this paper, we introduce a\nnovel federated learning paradigm, named Model Heterogeneous personalized\nFederated Learning via Injection and Distillation (MH-pFLID). Our framework\nleverages a lightweight messenger model that carries concentrated information\nto collect the information from each client. We also develop a set of receiver\nand transmitter modules to receive and send information from the messenger\nmodel, so that the information could be injected and distilled with efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper is accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06822v1",
    "published_date": "2024-05-10 21:52:27 UTC",
    "updated_date": "2024-05-10 21:52:27 UTC"
  },
  {
    "arxiv_id": "2405.06808v2",
    "title": "Large Language Model in Financial Regulatory Interpretation",
    "authors": [
      "Zhiyu Cao",
      "Zachary Feinstein"
    ],
    "abstract": "This study explores the innovative use of Large Language Models (LLMs) as\nanalytical tools for interpreting complex financial regulations. The primary\nobjective is to design effective prompts that guide LLMs in distilling verbose\nand intricate regulatory texts, such as the Basel III capital requirement\nregulations, into a concise mathematical framework that can be subsequently\ntranslated into actionable code. This novel approach aims to streamline the\nimplementation of regulatory mandates within the financial reporting and risk\nmanagement systems of global banking institutions. A case study was conducted\nto assess the performance of various LLMs, demonstrating that GPT-4 outperforms\nother models in processing and collecting necessary information, as well as\nexecuting mathematical calculations. The case study utilized numerical\nsimulations with asset holdings -- including fixed income, equities, currency\npairs, and commodities -- to demonstrate how LLMs can effectively implement the\nBasel III capital adequacy requirements.\n  Keywords: Large Language Models, Prompt Engineering, LLMs in Finance, Basel\nIII, Minimum Capital Requirements, LLM Ethics",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06808v2",
    "published_date": "2024-05-10 20:45:40 UTC",
    "updated_date": "2024-07-10 13:31:59 UTC"
  },
  {
    "arxiv_id": "2405.06802v3",
    "title": "Summarizing Radiology Reports Findings into Impressions",
    "authors": [
      "Raul Salles de Padua",
      "Imran Qureshi"
    ],
    "abstract": "Patient hand-off and triage are two fundamental problems in health care.\nOften doctors must painstakingly summarize complex findings to efficiently\ncommunicate with specialists and quickly make decisions on which patients have\nthe most urgent cases. In pursuit of these challenges, we present (1) a model\nwith state-of-art radiology report summarization performance using (2) a novel\nmethod for augmenting medical data, and (3) an analysis of the model\nlimitations and radiology knowledge gain. We also provide a data processing\npipeline for future models developed on the the MIMIC CXR dataset. Our best\nperforming model was a fine-tuned BERT-to-BERT encoder-decoder with 58.75/100\nROUGE-L F1, which outperformed specialized checkpoints with more sophisticated\nattention mechanisms. We investigate these aspects in this work.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This version reverts to the original preprint, following the advice\n  from the Artificial Intelligence in Health editorial office. The published\n  version is peer-reviewed and available in the journal (see external DOI). The\n  preprint remains unchanged to maintain version transparency, as noted in the\n  further disclosure section of the published article",
    "pdf_url": "http://arxiv.org/pdf/2405.06802v3",
    "published_date": "2024-05-10 20:29:25 UTC",
    "updated_date": "2024-09-27 06:13:06 UTC"
  },
  {
    "arxiv_id": "2405.06783v1",
    "title": "BLIP: Facilitating the Exploration of Undesirable Consequences of Digital Technologies",
    "authors": [
      "Rock Yuren Pang",
      "Sebastin Santy",
      "René Just",
      "Katharina Reinecke"
    ],
    "abstract": "Digital technologies have positively transformed society, but they have also\nled to undesirable consequences not anticipated at the time of design or\ndevelopment. We posit that insights into past undesirable consequences can help\nresearchers and practitioners gain awareness and anticipate potential adverse\neffects. To test this assumption, we introduce BLIP, a system that extracts\nreal-world undesirable consequences of technology from online articles,\nsummarizes and categorizes them, and presents them in an interactive, web-based\ninterface. In two user studies with 15 researchers in various computer science\ndisciplines, we found that BLIP substantially increased the number and\ndiversity of undesirable consequences they could list in comparison to relying\non prior knowledge or searching online. Moreover, BLIP helped them identify\nundesirable consequences relevant to their ongoing projects, made them aware of\nundesirable consequences they \"had never considered,\" and inspired them to\nreflect on their own experiences with technology.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "To appear in the Proceedings of the CHI Conference on Human Factors\n  in Computing Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA",
    "pdf_url": "http://arxiv.org/pdf/2405.06783v1",
    "published_date": "2024-05-10 19:21:19 UTC",
    "updated_date": "2024-05-10 19:21:19 UTC"
  },
  {
    "arxiv_id": "2405.06780v1",
    "title": "Deep MMD Gradient Flow without adversarial training",
    "authors": [
      "Alexandre Galashov",
      "Valentin de Bortoli",
      "Arthur Gretton"
    ],
    "abstract": "We propose a gradient flow procedure for generative modeling by transporting\nparticles from an initial source distribution to a target distribution, where\nthe gradient field on the particles is given by a noise-adaptive Wasserstein\nGradient of the Maximum Mean Discrepancy (MMD). The noise-adaptive MMD is\ntrained on data distributions corrupted by increasing levels of noise, obtained\nvia a forward diffusion process, as commonly used in denoising diffusion\nprobabilistic models. The result is a generalization of MMD Gradient Flow,\nwhich we call Diffusion-MMD-Gradient Flow or DMMD. The divergence training\nprocedure is related to discriminator training in Generative Adversarial\nNetworks (GAN), but does not require adversarial training. We obtain\ncompetitive empirical performance in unconditional image generation on CIFAR10,\nMNIST, CELEB-A (64 x64) and LSUN Church (64 x 64). Furthermore, we demonstrate\nthe validity of the approach when MMD is replaced by a lower bound on the KL\ndivergence.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06780v1",
    "published_date": "2024-05-10 19:10:45 UTC",
    "updated_date": "2024-05-10 19:10:45 UTC"
  },
  {
    "arxiv_id": "2405.06772v1",
    "title": "CANAL -- Cyber Activity News Alerting Language Model: Empirical Approach vs. Expensive LLM",
    "authors": [
      "Urjitkumar Patel",
      "Fang-Chun Yeh",
      "Chinmay Gondhalekar"
    ],
    "abstract": "In today's digital landscape, where cyber attacks have become the norm, the\ndetection of cyber attacks and threats is critically imperative across diverse\ndomains. Our research presents a new empirical framework for cyber threat\nmodeling, adept at parsing and categorizing cyber-related information from news\narticles, enhancing real-time vigilance for market stakeholders. At the core of\nthis framework is a fine-tuned BERT model, which we call CANAL - Cyber Activity\nNews Alerting Language Model, tailored for cyber categorization using a novel\nsilver labeling approach powered by Random Forest. We benchmark CANAL against\nlarger, costlier LLMs, including GPT-4, LLaMA, and Zephyr, highlighting their\nzero to few-shot learning in cyber news classification. CANAL demonstrates\nsuperior performance by outperforming all other LLM counterparts in both\naccuracy and cost-effectiveness. Furthermore, we introduce the Cyber Signal\nDiscovery module, a strategic component designed to efficiently detect emerging\ncyber signals from news articles. Collectively, CANAL and Cyber Signal\nDiscovery module equip our framework to provide a robust and cost-effective\nsolution for businesses that require agile responses to cyber intelligence.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "68T50, 68T07 (Primary) 03B65, 91F20 (Secondary)",
      "I.2.7; I.2.1; I.5.1; I.5.2; I.5.4; H.3.3"
    ],
    "primary_category": "cs.CR",
    "comment": "Published in 2024 IEEE 3rd International Conference on AI in\n  Cybersecurity (ICAIC), Conference Date: 07-09 February 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06772v1",
    "published_date": "2024-05-10 18:57:35 UTC",
    "updated_date": "2024-05-10 18:57:35 UTC"
  },
  {
    "arxiv_id": "2405.06760v1",
    "title": "Opportunities for Persian Digital Humanities Research with Artificial Intelligence Language Models; Case Study: Forough Farrokhzad",
    "authors": [
      "Arash Rasti Meymandi",
      "Zahra Hosseini",
      "Sina Davari",
      "Abolfazl Moshiri",
      "Shabnam Rahimi-Golkhandan",
      "Khashayar Namdar",
      "Nikta Feizi",
      "Mohamad Tavakoli-Targhi",
      "Farzad Khalvati"
    ],
    "abstract": "This study explores the integration of advanced Natural Language Processing\n(NLP) and Artificial Intelligence (AI) techniques to analyze and interpret\nPersian literature, focusing on the poetry of Forough Farrokhzad. Utilizing\ncomputational methods, we aim to unveil thematic, stylistic, and linguistic\npatterns in Persian poetry. Specifically, the study employs AI models including\ntransformer-based language models for clustering of the poems in an\nunsupervised framework. This research underscores the potential of AI in\nenhancing our understanding of Persian literary heritage, with Forough\nFarrokhzad's work providing a comprehensive case study. This approach not only\ncontributes to the field of Persian Digital Humanities but also sets a\nprecedent for future research in Persian literary studies using computational\ntechniques.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06760v1",
    "published_date": "2024-05-10 18:24:55 UTC",
    "updated_date": "2024-05-10 18:24:55 UTC"
  },
  {
    "arxiv_id": "2405.08011v3",
    "title": "A Survey of Large Language Models for Graphs",
    "authors": [
      "Xubin Ren",
      "Jiabin Tang",
      "Dawei Yin",
      "Nitesh Chawla",
      "Chao Huang"
    ],
    "abstract": "Graphs are an essential data structure utilized to represent relationships in\nreal-world scenarios. Prior research has established that Graph Neural Networks\n(GNNs) deliver impressive outcomes in graph-centric tasks, such as link\nprediction and node classification. Despite these advancements, challenges like\ndata sparsity and limited generalization capabilities continue to persist.\nRecently, Large Language Models (LLMs) have gained attention in natural\nlanguage processing. They excel in language comprehension and summarization.\nIntegrating LLMs with graph learning techniques has attracted interest as a way\nto enhance performance in graph learning tasks. In this survey, we conduct an\nin-depth review of the latest state-of-the-art LLMs applied in graph learning\nand introduce a novel taxonomy to categorize existing methods based on their\nframework design. We detail four unique designs: i) GNNs as Prefix, ii) LLMs as\nPrefix, iii) LLMs-Graphs Integration, and iv) LLMs-Only, highlighting key\nmethodologies within each category. We explore the strengths and limitations of\neach framework, and emphasize potential avenues for future research, including\novercoming current integration challenges between LLMs and graph learning\ntechniques, and venturing into new application areas. This survey aims to serve\nas a valuable resource for researchers and practitioners eager to leverage\nlarge language models in graph learning, and to inspire continued progress in\nthis dynamic field. We consistently maintain the related open-source materials\nat \\url{https://github.com/HKUDS/Awesome-LLM4Graph-Papers}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a KDD'24 survey paper",
    "pdf_url": "http://arxiv.org/pdf/2405.08011v3",
    "published_date": "2024-05-10 18:05:37 UTC",
    "updated_date": "2024-09-11 07:31:29 UTC"
  },
  {
    "arxiv_id": "2405.06639v1",
    "title": "Value Augmented Sampling for Language Model Alignment and Personalization",
    "authors": [
      "Seungwook Han",
      "Idan Shenfeld",
      "Akash Srivastava",
      "Yoon Kim",
      "Pulkit Agrawal"
    ],
    "abstract": "Aligning Large Language Models (LLMs) to cater to different human\npreferences, learning new skills, and unlearning harmful behavior is an\nimportant problem. Search-based methods, such as Best-of-N or Monte-Carlo Tree\nSearch, are performant, but impractical for LLM adaptation due to their high\ninference cost. On the other hand, using Reinforcement Learning (RL) for\nadaptation is computationally efficient, but performs worse due to the\noptimization challenges in co-training the value function and the policy. We\npresent a new framework for reward optimization, Value Augmented Sampling\n(VAS), that can maximize different reward functions using data sampled from\nonly the initial, frozen LLM. VAS solves for the optimal reward-maximizing\npolicy without co-training the policy and the value function, making the\noptimization stable, outperforming established baselines, such as PPO and DPO,\non standard benchmarks, and achieving comparable results to Best-of-128 with\nlower inference cost. Unlike existing RL methods that require changing the\nweights of the LLM, VAS does not require access to the weights of the\npre-trained LLM. Thus, it can even adapt LLMs (e.g., ChatGPT), which are\navailable only as APIs. In addition, our algorithm unlocks the new capability\nof composing several rewards and controlling the extent of each one during\ndeployment time, paving the road ahead for the future of aligned, personalized\nLLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Website: https://sites.google.com/view/llm-vas",
    "pdf_url": "http://arxiv.org/pdf/2405.06639v1",
    "published_date": "2024-05-10 17:59:04 UTC",
    "updated_date": "2024-05-10 17:59:04 UTC"
  },
  {
    "arxiv_id": "2405.06636v2",
    "title": "Federated Document Visual Question Answering: A Pilot Study",
    "authors": [
      "Khanh Nguyen",
      "Dimosthenis Karatzas"
    ],
    "abstract": "An important handicap of document analysis research is that documents tend to\nbe copyrighted or contain private information, which prohibits their open\npublication and the creation of centralised, large-scale document datasets.\nInstead, documents are scattered in private data silos, making extensive\ntraining over heterogeneous data a tedious task. In this work, we explore the\nuse of a federated learning (FL) scheme as a way to train a shared model on\ndecentralised private document data. We focus on the problem of Document VQA, a\ntask particularly suited to this approach, as the type of reasoning\ncapabilities required from the model can be quite different in diverse domains.\nEnabling training over heterogeneous document datasets can thus substantially\nenrich DocVQA models. We assemble existing DocVQA datasets from diverse domains\nto reflect the data heterogeneity in real-world applications. We explore the\nself-pretraining technique in this multi-modal setting, where the same data is\nused for both pretraining and finetuning, making it relevant for privacy\npreservation. We further propose combining self-pretraining with a Federated\nDocVQA training method using centralized adaptive optimization that outperforms\nthe FedAvg baseline. With extensive experiments, we also present a\nmulti-faceted analysis on training DocVQA models with FL, which provides\ninsights for future research on this task. We show that our pretraining\nstrategies can effectively learn and scale up under federated training with\ndiverse DocVQA datasets and tuning hyperparameters is essential for practical\ndocument tasks under federation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06636v2",
    "published_date": "2024-05-10 17:53:05 UTC",
    "updated_date": "2024-05-22 11:01:22 UTC"
  },
  {
    "arxiv_id": "2405.06634v2",
    "title": "Multimodal LLMs Struggle with Basic Visual Network Analysis: a VNA Benchmark",
    "authors": [
      "Evan M. Williams",
      "Kathleen M. Carley"
    ],
    "abstract": "We evaluate the zero-shot ability of GPT-4 and LLaVa to perform simple Visual\nNetwork Analysis (VNA) tasks on small-scale graphs. We evaluate the Vision\nLanguage Models (VLMs) on 5 tasks related to three foundational network science\nconcepts: identifying nodes of maximal degree on a rendered graph, identifying\nwhether signed triads are balanced or unbalanced, and counting components. The\ntasks are structured to be easy for a human who understands the underlying\ngraph theoretic concepts, and can all be solved by counting the appropriate\nelements in graphs. We find that while GPT-4 consistently outperforms LLaVa,\nboth models struggle with every visual network analysis task we propose. We\npublicly release the first benchmark for the evaluation of VLMs on foundational\nVNA tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.06634v2",
    "published_date": "2024-05-10 17:51:35 UTC",
    "updated_date": "2024-06-10 15:28:16 UTC"
  },
  {
    "arxiv_id": "2405.06627v3",
    "title": "Conformal Validity Guarantees Exist for Any Data Distribution (and How to Find Them)",
    "authors": [
      "Drew Prinster",
      "Samuel Stanton",
      "Anqi Liu",
      "Suchi Saria"
    ],
    "abstract": "As artificial intelligence (AI) / machine learning (ML) gain widespread\nadoption, practitioners are increasingly seeking means to quantify and control\nthe risk these systems incur. This challenge is especially salient when such\nsystems have autonomy to collect their own data, such as in black-box\noptimization and active learning, where their actions induce sequential\nfeedback-loop shifts in the data distribution. Conformal prediction is a\npromising approach to uncertainty and risk quantification, but prior variants'\nvalidity guarantees have assumed some form of ``quasi-exchangeability'' on the\ndata distribution, thereby excluding many types of sequential shifts. In this\npaper we prove that conformal prediction can theoretically be extended to\n\\textit{any} joint data distribution, not just exchangeable or\nquasi-exchangeable ones. Although the most general case is exceedingly\nimpractical to compute, for concrete practical applications we outline a\nprocedure for deriving specific conformal algorithms for any data distribution,\nand we use this procedure to derive tractable algorithms for a series of\nAI/ML-agent-induced covariate shifts. We evaluate the proposed algorithms\nempirically on synthetic black-box optimization and active learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024. Code available at\n  https://github.com/drewprinster/conformal-mfcs",
    "pdf_url": "http://arxiv.org/pdf/2405.06627v3",
    "published_date": "2024-05-10 17:40:24 UTC",
    "updated_date": "2024-06-05 15:49:11 UTC"
  },
  {
    "arxiv_id": "2405.06624v3",
    "title": "Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems",
    "authors": [
      "David \"davidad\" Dalrymple",
      "Joar Skalse",
      "Yoshua Bengio",
      "Stuart Russell",
      "Max Tegmark",
      "Sanjit Seshia",
      "Steve Omohundro",
      "Christian Szegedy",
      "Ben Goldhaber",
      "Nora Ammann",
      "Alessandro Abate",
      "Joe Halpern",
      "Clark Barrett",
      "Ding Zhao",
      "Tan Zhi-Xuan",
      "Jeannette Wing",
      "Joshua Tenenbaum"
    ],
    "abstract": "Ensuring that AI systems reliably and robustly avoid harmful or dangerous\nbehaviours is a crucial challenge, especially for AI systems with a high degree\nof autonomy and general intelligence, or systems used in safety-critical\ncontexts. In this paper, we will introduce and define a family of approaches to\nAI safety, which we will refer to as guaranteed safe (GS) AI. The core feature\nof these approaches is that they aim to produce AI systems which are equipped\nwith high-assurance quantitative safety guarantees. This is achieved by the\ninterplay of three core components: a world model (which provides a\nmathematical description of how the AI system affects the outside world), a\nsafety specification (which is a mathematical description of what effects are\nacceptable), and a verifier (which provides an auditable proof certificate that\nthe AI satisfies the safety specification relative to the world model). We\noutline a number of approaches for creating each of these three core\ncomponents, describe the main technical challenges, and suggest a number of\npotential solutions to them. We also argue for the necessity of this approach\nto AI safety, and for the inadequacy of the main alternative approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06624v3",
    "published_date": "2024-05-10 17:38:32 UTC",
    "updated_date": "2024-07-08 13:35:00 UTC"
  },
  {
    "arxiv_id": "2405.06611v1",
    "title": "\"We are at the mercy of others' opinion\": Supporting Blind People in Recreational Window Shopping with AI-infused Technology",
    "authors": [
      "Rie Kamikubo",
      "Hernisa Kacorri",
      "Chieko Asakawa"
    ],
    "abstract": "Engaging in recreational activities in public spaces poses challenges for\nblind people, often involving dependency on sighted help. Window shopping is a\nkey recreational activity that remains inaccessible. In this paper, we\ninvestigate the information needs, challenges, and current approaches blind\npeople have to recreational window shopping to inform the design of existing\nwayfinding and navigation technology for supporting blind shoppers in\nexploration and serendipitous discovery. We conduct a formative study with a\ntotal of 18 blind participants that include both focus groups (N=8) and\ninterviews for requirements analysis (N=10). We find that there is a desire for\npush notifications of promotional information and pull notifications about\nshops of interest such as the targeted audience of a brand. Information about\nobstacles and points-of-interest required customization depending on one's\nmobility aid as well as presence of a crowd, children, and wheelchair users. We\ntranslate these findings into specific information modalities and rendering in\nthe context of two existing AI-infused assistive applications: NavCog (a\nturn-by-turn navigation app) and Cabot (a navigation robot).",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Preprint, W4A'24, Proceedings of the 21st International Web for All\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2405.06611v1",
    "published_date": "2024-05-10 17:15:24 UTC",
    "updated_date": "2024-05-10 17:15:24 UTC"
  },
  {
    "arxiv_id": "2405.06573v1",
    "title": "An Investigation of Incorporating Mamba for Speech Enhancement",
    "authors": [
      "Rong Chao",
      "Wen-Huang Cheng",
      "Moreno La Quatra",
      "Sabato Marco Siniscalchi",
      "Chao-Han Huck Yang",
      "Szu-Wei Fu",
      "Yu Tsao"
    ],
    "abstract": "This work aims to study a scalable state-space model (SSM), Mamba, for the\nspeech enhancement (SE) task. We exploit a Mamba-based regression model to\ncharacterize speech signals and build an SE system upon Mamba, termed SEMamba.\nWe explore the properties of Mamba by integrating it as the core model in both\nbasic and advanced SE systems, along with utilizing signal-level distances as\nwell as metric-oriented loss functions. SEMamba demonstrates promising results\nand attains a PESQ score of 3.55 on the VoiceBank-DEMAND dataset. When combined\nwith the perceptual contrast stretching technique, the proposed SEMamba yields\na new state-of-the-art PESQ score of 3.69.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06573v1",
    "published_date": "2024-05-10 16:18:49 UTC",
    "updated_date": "2024-05-10 16:18:49 UTC"
  },
  {
    "arxiv_id": "2405.06553v1",
    "title": "Scalable Property Valuation Models via Graph-based Deep Learning",
    "authors": [
      "Enrique Riveros",
      "Carla Vairetti",
      "Christian Wegmann",
      "Santiago Truffa",
      "Sebastián Maldonado"
    ],
    "abstract": "This paper aims to enrich the capabilities of existing deep learning-based\nautomated valuation models through an efficient graph representation of peer\ndependencies, thus capturing intricate spatial relationships. In particular, we\ndevelop two novel graph neural network models that effectively identify\nsequences of neighboring houses with similar features, employing different\nmessage passing algorithms. The first strategy consider standard spatial graph\nconvolutions, while the second one utilizes transformer graph convolutions.\nThis approach confers scalability to the modeling process. The experimental\nevaluation is conducted using a proprietary dataset comprising approximately\n200,000 houses located in Santiago, Chile. We show that employing tailored\ngraph neural networks significantly improves the accuracy of house price\nprediction, especially when utilizing transformer convolutional message passing\nlayers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 3 figures, Submitted to Expert Systems with Applications",
    "pdf_url": "http://arxiv.org/pdf/2405.06553v1",
    "published_date": "2024-05-10 15:54:55 UTC",
    "updated_date": "2024-05-10 15:54:55 UTC"
  },
  {
    "arxiv_id": "2405.06522v1",
    "title": "Heterogeneous Graph Neural Networks with Loss-decrease-aware Curriculum Learning",
    "authors": [
      "Yili Wang"
    ],
    "abstract": "In recent years, heterogeneous graph neural networks (HGNNs) have achieved\nexcellent performance in handling heterogeneous information networks (HINs).\nCurriculum learning is a machine learning strategy where training examples are\npresented to a model in a structured order, starting with easy examples and\ngradually increasing difficulty, aiming to improve learning efficiency and\ngeneralization. To better exploit the rich information in HINs, previous\nmethods have started to explore the use of curriculum learning strategy to\ntrain HGNNs. Specifically, these works utilize the absolute value of the loss\nat each training epoch to evaluate the learning difficulty of each training\nsample. However, the relative loss, rather than the absolute value of loss,\nreveals the learning difficulty. Therefore, we propose a novel\nloss-decrease-aware training schedule (LDTS). LDTS uses the trend of loss\ndecrease between each training epoch to better evaluating the difficulty of\ntraining samples, thereby enhancing the curriculum learning of HGNNs for\ndownstream tasks. Additionally, we propose a sampling strategy to alleviate\ntraining imbalance issues. Our method further demonstrate the efficacy of\ncurriculum learning in enhancing HGNNs capabilities. We call our method\nLoss-decrease-aware Heterogeneous Graph Neural Networks (LDHGNN). The code is\npublic at https://github.com/wangyili00/LDHGNN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.18875 by\n  other authors",
    "pdf_url": "http://arxiv.org/pdf/2405.06522v1",
    "published_date": "2024-05-10 15:06:53 UTC",
    "updated_date": "2024-05-10 15:06:53 UTC"
  },
  {
    "arxiv_id": "2405.06510v1",
    "title": "UniDM: A Unified Framework for Data Manipulation with Large Language Models",
    "authors": [
      "Yichen Qian",
      "Yongyi He",
      "Rong Zhu",
      "Jintao Huang",
      "Zhijian Ma",
      "Haibin Wang",
      "Yaohua Wang",
      "Xiuyu Sun",
      "Defu Lian",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "abstract": "Designing effective data manipulation methods is a long standing problem in\ndata lakes. Traditional methods, which rely on rules or machine learning\nmodels, require extensive human efforts on training data collection and tuning\nmodels. Recent methods apply Large Language Models (LLMs) to resolve multiple\ndata manipulation tasks. They exhibit bright benefits in terms of performance\nbut still require customized designs to fit each specific task. This is very\ncostly and can not catch up with the requirements of big data lake platforms.\nIn this paper, inspired by the cross-task generality of LLMs on NLP tasks, we\npave the first step to design an automatic and general solution to tackle with\ndata manipulation tasks. We propose UniDM, a unified framework which\nestablishes a new paradigm to process data manipulation tasks using LLMs. UniDM\nformalizes a number of data manipulation tasks in a unified form and abstracts\nthree main general steps to solve each task. We develop an automatic context\nretrieval to allow the LLMs to retrieve data from data lakes, potentially\ncontaining evidence and factual information. For each step, we design effective\nprompts to guide LLMs to produce high quality results. By our comprehensive\nevaluation on a variety of benchmarks, our UniDM exhibits great generality and\nstate-of-the-art performance on a wide variety of data manipulation tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "MLSys24",
    "pdf_url": "http://arxiv.org/pdf/2405.06510v1",
    "published_date": "2024-05-10 14:44:04 UTC",
    "updated_date": "2024-05-10 14:44:04 UTC"
  },
  {
    "arxiv_id": "2405.06485v1",
    "title": "Solving Quantified Boolean Formulas with Few Existential Variables",
    "authors": [
      "Leif Eriksson",
      "Victor Lagerkvist",
      "George Osipov",
      "Sebastian Ordyniak",
      "Fahad Panolan",
      "Mateusz Rychlicki"
    ],
    "abstract": "The quantified Boolean formula (QBF) problem is an important decision problem\ngenerally viewed as the archetype for PSPACE-completeness. Many problems of\ncentral interest in AI are in general not included in NP, e.g., planning, model\nchecking, and non-monotonic reasoning, and for such problems QBF has\nsuccessfully been used as a modelling tool. However, solvers for QBF are not as\nadvanced as state of the art SAT solvers, which has prevented QBF from becoming\na universal modelling language for PSPACE-complete problems. A theoretical\nexplanation is that QBF (as well as many other PSPACE-complete problems) lacks\nnatural parameters} guaranteeing fixed-parameter tractability (FPT).\n  In this paper we tackle this problem and consider a simple but overlooked\nparameter: the number of existentially quantified variables. This natural\nparameter is virtually unexplored in the literature which one might find\nsurprising given the general scarcity of FPT algorithms for QBF. Via this\nparameterization we then develop a novel FPT algorithm applicable to QBF\ninstances in conjunctive normal form (CNF) of bounded clause length. We\ncomplement this by a W[1]-hardness result for QBF in CNF of unbounded clause\nlength as well as sharper lower bounds for the bounded arity case under the\n(strong) exponential-time hypothesis.",
    "categories": [
      "cs.CC",
      "cs.AI"
    ],
    "primary_category": "cs.CC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06485v1",
    "published_date": "2024-05-10 14:07:29 UTC",
    "updated_date": "2024-05-10 14:07:29 UTC"
  },
  {
    "arxiv_id": "2405.06478v1",
    "title": "Attention is all they need: Cognitive science and the (techno)political economy of attention in humans and machines",
    "authors": [
      "Pablo González de la Torre",
      "Marta Pérez-Verdugo",
      "Xabier E. Barandiaran"
    ],
    "abstract": "This paper critically analyses the \"attention economy\" within the framework\nof cognitive science and techno-political economics, as applied to both human\nand machine interactions. We explore how current business models, particularly\nin digital platform capitalism, harness user engagement by strategically\nshaping attentional patterns. These platforms utilize advanced AI and massive\ndata analytics to enhance user engagement, creating a cycle of attention\ncapture and data extraction. We review contemporary (neuro)cognitive theories\nof attention and platform engagement design techniques and criticize classical\ncognitivist and behaviourist theories for their inadequacies in addressing the\npotential harms of such engagement on user autonomy and wellbeing. 4E\napproaches to cognitive science, instead, emphasizing the embodied, extended,\nenactive, and ecological aspects of cognition, offer us an intrinsic normative\nstandpoint and a more integrated understanding of how attentional patterns are\nactively constituted by adaptive digital environments. By examining the\nprecarious nature of habit formation in digital contexts, we reveal the\ntechno-economic underpinnings that threaten personal autonomy by disaggregating\nhabits away from the individual, into an AI managed collection of behavioural\npatterns. Our current predicament suggests the necessity of a paradigm shift\ntowards an ecology of attention. This shift aims to foster environments that\nrespect and preserve human cognitive and social capacities, countering the\nexploitative tendencies of cognitive capitalism.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06478v1",
    "published_date": "2024-05-10 13:53:46 UTC",
    "updated_date": "2024-05-10 13:53:46 UTC"
  },
  {
    "arxiv_id": "2405.06725v3",
    "title": "On the Shape of Brainscores for Large Language Models (LLMs)",
    "authors": [
      "Jingkai Li"
    ],
    "abstract": "With the rise of Large Language Models (LLMs), the novel metric \"Brainscore\"\nemerged as a means to evaluate the functional similarity between LLMs and human\nbrain/neural systems. Our efforts were dedicated to mining the meaning of the\nnovel score by constructing topological features derived from both human fMRI\ndata involving 190 subjects, and 39 LLMs plus their untrained counterparts.\nSubsequently, we trained 36 Linear Regression Models and conducted thorough\nstatistical analyses to discern reliable and valid features from our\nconstructed ones. Our findings reveal distinctive feature combinations\nconducive to interpreting existing brainscores across various brain regions of\ninterest (ROIs) and hemispheres, thereby significantly contributing to\nadvancing interpretable machine learning (iML) studies. The study is enriched\nby our further discussions and analyses concerning existing brainscores. To our\nknowledge, this study represents the first attempt to comprehend the novel\nmetric brainscore within this interdisciplinary domain.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "Published as a workshop paper at ICLR AGI Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06725v3",
    "published_date": "2024-05-10 13:22:20 UTC",
    "updated_date": "2024-05-15 02:46:45 UTC"
  },
  {
    "arxiv_id": "2405.06459v4",
    "title": "Are EEG-to-Text Models Working?",
    "authors": [
      "Hyejeong Jo",
      "Yiqian Yang",
      "Juhyeok Han",
      "Yiqun Duan",
      "Hui Xiong",
      "Won Hee Lee"
    ],
    "abstract": "This work critically analyzes existing models for open-vocabulary EEG-to-Text\ntranslation. We identify a crucial limitation: previous studies often employed\nimplicit teacher-forcing during evaluation, artificially inflating performance\nmetrics. Additionally, they lacked a critical benchmark - comparing model\nperformance on pure noise inputs. We propose a methodology to differentiate\nbetween models that truly learn from EEG signals and those that simply memorize\ntraining data. Our analysis reveals that model performance on noise data can be\ncomparable to that on EEG data. These findings highlight the need for stricter\nevaluation practices in EEG-to-Text research, emphasizing transparent reporting\nand rigorous benchmarking with noise inputs. This approach will lead to more\nreliable assessments of model capabilities and pave the way for robust\nEEG-to-Text communication systems. Code is available at\nhttps://github.com/NeuSpeech/EEG-To-Text",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06459v4",
    "published_date": "2024-05-10 13:10:55 UTC",
    "updated_date": "2024-10-26 05:41:51 UTC"
  },
  {
    "arxiv_id": "2405.06424v3",
    "title": "Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation",
    "authors": [
      "JoonHo Lee",
      "Jae Oh Woo",
      "Juree Seok",
      "Parisa Hassanzadeh",
      "Wooseok Jang",
      "JuYoun Son",
      "Sima Didari",
      "Baruch Gutow",
      "Heng Hao",
      "Hankyu Moon",
      "Wenjun Hu",
      "Yeong-Dae Kwon",
      "Taehee Lee",
      "Seungjai Min"
    ],
    "abstract": "Assessing response quality to instructions in language models is vital but\nchallenging due to the complexity of human language across different contexts.\nThis complexity often results in ambiguous or inconsistent interpretations,\nmaking accurate assessment difficult. To address this issue, we propose a novel\nUncertainty-aware Reward Model (URM) that introduces a robust uncertainty\nestimation for the quality of paired responses based on Bayesian approximation.\nTrained with preference datasets, our uncertainty-enabled proxy not only scores\nrewards for responses but also evaluates their inherent uncertainty. Empirical\nresults demonstrate significant benefits of incorporating the proposed proxy\ninto language model training. Our method boosts the instruction following\ncapability of language models by refining data curation for training and\nimproving policy optimization objectives, thereby surpassing existing methods\nby a large margin on benchmarks such as Vicuna and MT-bench. These findings\nhighlight that our proposed approach substantially advances language model\ntraining and paves a new way of harnessing uncertainty within language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06424v3",
    "published_date": "2024-05-10 12:14:11 UTC",
    "updated_date": "2025-01-31 09:26:56 UTC"
  },
  {
    "arxiv_id": "2405.06422v1",
    "title": "Contextual Affordances for Safe Exploration in Robotic Scenarios",
    "authors": [
      "William Z. Ye",
      "Eduardo B. Sandoval",
      "Pamela Carreno-Medrano",
      "Francisco Cru"
    ],
    "abstract": "Robotics has been a popular field of research in the past few decades, with\nmuch success in industrial applications such as manufacturing and logistics.\nThis success is led by clearly defined use cases and controlled operating\nenvironments. However, robotics has yet to make a large impact in domestic\nsettings. This is due in part to the difficulty and complexity of designing\nmass-manufactured robots that can succeed in the variety of homes and\nenvironments that humans live in and that can operate safely in close proximity\nto humans. This paper explores the use of contextual affordances to enable safe\nexploration and learning in robotic scenarios targeted in the home. In\nparticular, we propose a simple state representation that allows us to extend\ncontextual affordances to larger state spaces and showcase how affordances can\nimprove the success and convergence rate of a reinforcement learning algorithm\nin simulation. Our results suggest that after further iterations, it is\npossible to consider the implementation of this approach in a real robot\nmanipulator. Furthermore, in the long term, this work could be the foundation\nfor future explorations of human-robot interactions in complex domestic\nenvironments. This could be possible once state-of-the-art robot manipulators\nachieve the required level of dexterity for the described affordances in this\npaper.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "5 pages, 2 figures. Accepted at the 2nd Workshop on Human-aligned\n  Reinforcement Learning for Autonomous Agents and Robots HARL, at the IEEE\n  International Conference on Robotics and Automation ICRA, Yokohama, Japan,\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06422v1",
    "published_date": "2024-05-10 12:12:38 UTC",
    "updated_date": "2024-05-10 12:12:38 UTC"
  },
  {
    "arxiv_id": "2405.06419v3",
    "title": "Time Evidence Fusion Network: Multi-source View in Long-Term Time Series Forecasting",
    "authors": [
      "Tianxiang Zhan",
      "Yuanpeng He",
      "Yong Deng",
      "Zhen Li",
      "Wenjie Du",
      "Qingsong Wen"
    ],
    "abstract": "In practical scenarios, time series forecasting necessitates not only\naccuracy but also efficiency. Consequently, the exploration of model\narchitectures remains a perennially trending topic in research. To address\nthese challenges, we propose a novel backbone architecture named Time Evidence\nFusion Network (TEFN) from the perspective of information fusion. Specifically,\nwe introduce the Basic Probability Assignment (BPA) Module based on evidence\ntheory to capture the uncertainty of multivariate time series data from both\nchannel and time dimensions. Additionally, we develop a novel multi-source\ninformation fusion method to effectively integrate the two distinct dimensions\nfrom BPA output, leading to improved forecasting accuracy. Lastly, we conduct\nextensive experiments to demonstrate that TEFN achieves performance comparable\nto state-of-the-art methods while maintaining significantly lower complexity\nand reduced training time. Also, our experiments show that TEFN exhibits high\nrobustness, with minimal error fluctuations during hyperparameter selection.\nFurthermore, due to the fact that BPA is derived from fuzzy theory, TEFN offers\na high degree of interpretability. Therefore, the proposed TEFN balances\naccuracy, efficiency, stability, and interpretability, making it a desirable\nsolution for time series forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06419v3",
    "published_date": "2024-05-10 12:10:22 UTC",
    "updated_date": "2024-09-24 12:57:39 UTC"
  },
  {
    "arxiv_id": "2405.06418v2",
    "title": "PAC-Bayesian Generalization Bounds for Knowledge Graph Representation Learning",
    "authors": [
      "Jaejun Lee",
      "Minsung Hwang",
      "Joyce Jiyoung Whang"
    ],
    "abstract": "While a number of knowledge graph representation learning (KGRL) methods have\nbeen proposed over the past decade, very few theoretical analyses have been\nconducted on them. In this paper, we present the first PAC-Bayesian\ngeneralization bounds for KGRL methods. To analyze a broad class of KGRL\nmodels, we propose a generic framework named ReED (Relation-aware\nEncoder-Decoder), which consists of a relation-aware message passing encoder\nand a triplet classification decoder. Our ReED framework can express at least\n15 different existing KGRL models, including not only graph neural\nnetwork-based models such as R-GCN and CompGCN but also shallow-architecture\nmodels such as RotatE and ANALOGY. Our generalization bounds for the ReED\nframework provide theoretical grounds for the commonly used tricks in KGRL,\ne.g., parameter-sharing and weight normalization schemes, and guide desirable\ndesign choices for practical KGRL methods. We empirically show that the\ncritical factors in our generalization bounds can explain actual generalization\nerrors on three real-world knowledge graphs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 3 figures, 4 tables, The 41st International Conference on\n  Machine Learning (ICML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.06418v2",
    "published_date": "2024-05-10 12:03:53 UTC",
    "updated_date": "2024-06-03 14:27:59 UTC"
  },
  {
    "arxiv_id": "2405.06413v1",
    "title": "Multi-level Personalized Federated Learning on Heterogeneous and Long-Tailed Data",
    "authors": [
      "Rongyu Zhang",
      "Yun Chen",
      "Chenrui Wu",
      "Fangxin Wang",
      "Bo Li"
    ],
    "abstract": "Federated learning (FL) offers a privacy-centric distributed learning\nframework, enabling model training on individual clients and central\naggregation without necessitating data exchange. Nonetheless, FL\nimplementations often suffer from non-i.i.d. and long-tailed class\ndistributions across mobile applications, e.g., autonomous vehicles, which\nleads models to overfitting as local training may converge to sub-optimal. In\nour study, we explore the impact of data heterogeneity on model bias and\nintroduce an innovative personalized FL framework, Multi-level Personalized\nFederated Learning (MuPFL), which leverages the hierarchical architecture of FL\nto fully harness computational resources at various levels. This framework\nintegrates three pivotal modules: Biased Activation Value Dropout (BAVD) to\nmitigate overfitting and accelerate training; Adaptive Cluster-based Model\nUpdate (ACMU) to refine local models ensuring coherent global aggregation; and\nPrior Knowledge-assisted Classifier Fine-tuning (PKCF) to bolster\nclassification and personalize models in accord with skewed local data with\nshared knowledge. Extensive experiments on diverse real-world datasets for\nimage classification and semantic segmentation validate that MuPFL consistently\noutperforms state-of-the-art baselines, even under extreme non-i.i.d. and\nlong-tail conditions, which enhances accuracy by as much as 7.39% and\naccelerates training by up to 80% at most, marking significant advancements in\nboth efficiency and effectiveness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.06413v1",
    "published_date": "2024-05-10 11:52:53 UTC",
    "updated_date": "2024-05-10 11:52:53 UTC"
  },
  {
    "arxiv_id": "2405.06409v1",
    "title": "Visualizing Neural Network Imagination",
    "authors": [
      "Nevan Wichers",
      "Victor Tao",
      "Riccardo Volpato",
      "Fazl Barez"
    ],
    "abstract": "In certain situations, neural networks will represent environment states in\ntheir hidden activations. Our goal is to visualize what environment states the\nnetworks are representing. We experiment with a recurrent neural network (RNN)\narchitecture with a decoder network at the end. After training, we apply the\ndecoder to the intermediate representations of the network to visualize what\nthey represent. We define a quantitative interpretability metric and use it to\ndemonstrate that hidden states can be highly interpretable on a simple task. We\nalso develop autoencoder and adversarial techniques and show that benefit\ninterpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06409v1",
    "published_date": "2024-05-10 11:43:35 UTC",
    "updated_date": "2024-05-10 11:43:35 UTC"
  },
  {
    "arxiv_id": "2405.06399v1",
    "title": "Program Synthesis using Inductive Logic Programming for the Abstraction and Reasoning Corpus",
    "authors": [
      "Filipe Marinho Rocha",
      "Inês Dutra",
      "Vítor Santos Costa"
    ],
    "abstract": "The Abstraction and Reasoning Corpus (ARC) is a general artificial\nintelligence benchmark that is currently unsolvable by any Machine Learning\nmethod, including Large Language Models (LLMs). It demands strong\ngeneralization and reasoning capabilities which are known to be weaknesses of\nNeural Network based systems. In this work, we propose a Program Synthesis\nsystem that uses Inductive Logic Programming (ILP), a branch of Symbolic AI, to\nsolve ARC. We have manually defined a simple Domain Specific Language (DSL)\nthat corresponds to a small set of object-centric abstractions relevant to ARC.\nThis is the Background Knowledge used by ILP to create Logic Programs that\nprovide reasoning capabilities to our system. The full system is capable of\ngeneralize to unseen tasks, since ILP can create Logic Program(s) from few\nexamples, in the case of ARC: pairs of Input-Output grids examples for each\ntask. These Logic Programs are able to generate Objects present in the Output\ngrid and the combination of these can form a complete program that transforms\nan Input grid into an Output grid. We randomly chose some tasks from ARC that\ndont require more than the small number of the Object primitives we implemented\nand show that given only these, our system can solve tasks that require each,\nsuch different reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06399v1",
    "published_date": "2024-05-10 11:22:31 UTC",
    "updated_date": "2024-05-10 11:22:31 UTC"
  },
  {
    "arxiv_id": "2405.06394v3",
    "title": "Memory Mosaics",
    "authors": [
      "Jianyu Zhang",
      "Niklas Nolte",
      "Ranajoy Sadhukhan",
      "Beidi Chen",
      "Léon Bottou"
    ],
    "abstract": "Memory Mosaics are networks of associative memories working in concert to\nachieve a prediction task of interest. Like transformers, memory mosaics\npossess compositional capabilities and in-context learning capabilities. Unlike\ntransformers, memory mosaics achieve these capabilities in comparatively\ntransparent way (\"predictive disentanglement\"). We illustrate these\ncapabilities on a toy example and also show that memory mosaics perform as well\nor better than transformers on medium-scale language modeling tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06394v3",
    "published_date": "2024-05-10 11:08:20 UTC",
    "updated_date": "2025-02-27 21:46:01 UTC"
  },
  {
    "arxiv_id": "2405.06389v1",
    "title": "Continual Novel Class Discovery via Feature Enhancement and Adaptation",
    "authors": [
      "Yifan Yu",
      "Shaokun Wang",
      "Yuhang He",
      "Junzhe Chen",
      "Yihong Gong"
    ],
    "abstract": "Continual Novel Class Discovery (CNCD) aims to continually discover novel\nclasses without labels while maintaining the recognition capability for\npreviously learned classes. The main challenges faced by CNCD include the\nfeature-discrepancy problem, the inter-session confusion problem, etc. In this\npaper, we propose a novel Feature Enhancement and Adaptation method for the\nCNCD to tackle the above challenges, which consists of a guide-to-novel\nframework, a centroid-to-samples similarity constraint (CSS), and a\nboundary-aware prototype constraint (BAP). More specifically, the\nguide-to-novel framework is established to continually discover novel classes\nunder the guidance of prior distribution. Afterward, the CSS is designed to\nconstrain the relationship between centroid-to-samples similarities of\ndifferent classes, thereby enhancing the distinctiveness of features among\nnovel classes. Finally, the BAP is proposed to keep novel class features aware\nof the positions of other class prototypes during incremental sessions, and\nbetter adapt novel class features to the shared feature space. Experimental\nresults on three benchmark datasets demonstrate the superiority of our method,\nespecially in more challenging protocols with more incremental sessions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06389v1",
    "published_date": "2024-05-10 10:52:22 UTC",
    "updated_date": "2024-05-10 10:52:22 UTC"
  },
  {
    "arxiv_id": "2405.06373v4",
    "title": "LLM Discussion: Enhancing the Creativity of Large Language Models via Discussion Framework and Role-Play",
    "authors": [
      "Li-Chun Lu",
      "Shou-Jen Chen",
      "Tsung-Min Pai",
      "Chan-Hung Yu",
      "Hung-yi Lee",
      "Shao-Hua Sun"
    ],
    "abstract": "Large language models (LLMs) have shown exceptional proficiency in natural\nlanguage processing but often fall short of generating creative and original\nresponses to open-ended questions. To enhance LLM creativity, our key insight\nis to emulate the human process of inducing collective creativity through\nengaging discussions with participants from diverse backgrounds and\nperspectives. To this end, we propose LLM Discussion, a three-phase discussion\nframework that facilitates vigorous and diverging idea exchanges and ensures\nconvergence to creative answers. Moreover, we adopt a role-playing technique by\nassigning distinct roles to LLMs to combat the homogeneity of LLMs. We evaluate\nthe efficacy of the proposed framework with the Alternative Uses Test,\nSimilarities Test, Instances Test, and Scientific Creativity Test through both\nLLM evaluation and human study. The results show that our proposed framework\noutperforms single-LLM approaches and existing multi-LLM frameworks across\nvarious creativity metrics. The code is available at\nhttps://github.com/lawraa/LLM-Discussion.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "40 pages, 9 figures, COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06373v4",
    "published_date": "2024-05-10 10:19:14 UTC",
    "updated_date": "2024-08-08 04:47:20 UTC"
  },
  {
    "arxiv_id": "2405.06372v1",
    "title": "Intelligent Duty Cycling Management and Wake-up for Energy Harvesting IoT Networks with Correlated Activity",
    "authors": [
      "David E. Ruíz-Guirola",
      "Onel L. A. López",
      "Samuel Montejo-Sánchez",
      "Israel Leyva Mayorga",
      "Zhu Han",
      "Petar Popovski"
    ],
    "abstract": "This paper presents an approach for energy-neutral Internet of Things (IoT)\nscenarios where the IoT devices (IoTDs) rely entirely on their energy\nharvesting capabilities to sustain operation. We use a Markov chain to\nrepresent the operation and transmission states of the IoTDs, a modulated\nPoisson process to model their energy harvesting process, and a discrete-time\nMarkov chain to model their battery state. The aim is to efficiently manage the\nduty cycling of the IoTDs, so as to prolong their battery life and reduce\ninstances of low-energy availability. We propose a duty-cycling management\nbased on K- nearest neighbors, aiming to strike a trade-off between energy\nefficiency and detection accuracy. This is done by incorporating spatial and\ntemporal correlations among IoTDs' activity, as well as their energy harvesting\ncapabilities. We also allow the base station to wake up specific IoTDs if more\ninformation about an event is needed upon initial detection. Our proposed\nscheme shows significant improvements in energy savings and performance, with\nup to 11 times lower misdetection probability and 50\\% lower energy consumption\nfor high-density scenarios compared to a random duty cycling benchmark.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06372v1",
    "published_date": "2024-05-10 10:16:27 UTC",
    "updated_date": "2024-05-10 10:16:27 UTC"
  },
  {
    "arxiv_id": "2405.06363v1",
    "title": "Projection by Convolution: Optimal Sample Complexity for Reinforcement Learning in Continuous-Space MDPs",
    "authors": [
      "Davide Maran",
      "Alberto Maria Metelli",
      "Matteo Papini",
      "Marcello Restelli"
    ],
    "abstract": "We consider the problem of learning an $\\varepsilon$-optimal policy in a\ngeneral class of continuous-space Markov decision processes (MDPs) having\nsmooth Bellman operators. Given access to a generative model, we achieve\nrate-optimal sample complexity by performing a simple, \\emph{perturbed} version\nof least-squares value iteration with orthogonal trigonometric polynomials as\nfeatures. Key to our solution is a novel projection technique based on ideas\nfrom harmonic analysis. Our~$\\widetilde{\\mathcal{O}}(\\epsilon^{-2-d/(\\nu+1)})$\nsample complexity, where $d$ is the dimension of the state-action space and\n$\\nu$ the order of smoothness, recovers the state-of-the-art result of\ndiscretization approaches for the special case of Lipschitz MDPs $(\\nu=0)$. At\nthe same time, for $\\nu\\to\\infty$, it recovers and greatly generalizes the\n$\\mathcal{O}(\\epsilon^{-2})$ rate of low-rank MDPs, which are more amenable to\nregression approaches. In this sense, our result bridges the gap between two\npopular but conflicting perspectives on continuous-space MDPs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06363v1",
    "published_date": "2024-05-10 09:58:47 UTC",
    "updated_date": "2024-05-10 09:58:47 UTC"
  },
  {
    "arxiv_id": "2405.06724v3",
    "title": "Boolean matrix logic programming for active learning of gene functions in genome-scale metabolic network models",
    "authors": [
      "Lun Ai",
      "Stephen H. Muggleton",
      "Shi-Shun Liang",
      "Geoff S. Baldwin"
    ],
    "abstract": "Techniques to autonomously drive research have been prominent in\nComputational Scientific Discovery, while Synthetic Biology is a field of\nscience that focuses on designing and constructing new biological systems for\nuseful purposes. Here we seek to apply logic-based machine learning techniques\nto facilitate cellular engineering and drive biological discovery.\nComprehensive databases of metabolic processes called genome-scale metabolic\nnetwork models (GEMs) are often used to evaluate cellular engineering\nstrategies to optimise target compound production. However, predicted host\nbehaviours are not always correctly described by GEMs, often due to errors in\nthe models. The task of learning the intricate genetic interactions within GEMs\npresents computational and empirical challenges. To address these, we describe\na novel approach called Boolean Matrix Logic Programming (BMLP) by leveraging\nboolean matrices to evaluate large logic programs. We introduce a new system,\n$BMLP_{active}$, which efficiently explores the genomic hypothesis space by\nguiding informative experimentation through active learning. In contrast to\nsub-symbolic methods, $BMLP_{active}$ encodes a state-of-the-art GEM of a\nwidely accepted bacterial host in an interpretable and logical representation\nusing datalog logic programs. Notably, $BMLP_{active}$ can successfully learn\nthe interaction between a gene pair with fewer training examples than random\nexperimentation, overcoming the increase in experimental design space.\n$BMLP_{active}$ enables rapid optimisation of metabolic models to reliably\nengineer biological systems for producing useful compounds. It offers a\nrealistic approach to creating a self-driving lab for microbial engineering.",
    "categories": [
      "q-bio.MN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.MN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06724v3",
    "published_date": "2024-05-10 09:51:06 UTC",
    "updated_date": "2024-08-11 17:54:22 UTC"
  },
  {
    "arxiv_id": "2405.06354v1",
    "title": "KeepOriginalAugment: Single Image-based Better Information-Preserving Data Augmentation Approach",
    "authors": [
      "Teerath Kumar",
      "Alessandra Mileo",
      "Malika Bendechache"
    ],
    "abstract": "Advanced image data augmentation techniques play a pivotal role in enhancing\nthe training of models for diverse computer vision tasks. Notably, SalfMix and\nKeepAugment have emerged as popular strategies, showcasing their efficacy in\nboosting model performance. However, SalfMix reliance on duplicating salient\nfeatures poses a risk of overfitting, potentially compromising the model's\ngeneralization capabilities. Conversely, KeepAugment, which selectively\npreserves salient regions and augments non-salient ones, introduces a domain\nshift that hinders the exchange of crucial contextual information, impeding\noverall model understanding. In response to these challenges, we introduce\nKeepOriginalAugment, a novel data augmentation approach. This method\nintelligently incorporates the most salient region within the non-salient area,\nallowing augmentation to be applied to either region. Striking a balance\nbetween data diversity and information preservation, KeepOriginalAugment\nenables models to leverage both diverse salient and non-salient regions,\nleading to enhanced performance. We explore three strategies for determining\nthe placement of the salient region minimum, maximum, or random and investigate\nswapping perspective strategies to decide which part (salient or non-salient)\nundergoes augmentation. Our experimental evaluations, conducted on\nclassification datasets such as CIFAR-10, CIFAR-100, and TinyImageNet,\ndemonstrate the superior performance of KeepOriginalAugment compared to\nexisting state-of-the-art techniques.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted at 20th International Conference on\n  Artificial Intelligence Applications and Innovations 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06354v1",
    "published_date": "2024-05-10 09:37:36 UTC",
    "updated_date": "2024-05-10 09:37:36 UTC"
  },
  {
    "arxiv_id": "2405.06329v1",
    "title": "ChatGPTest: opportunities and cautionary tales of utilizing AI for questionnaire pretesting",
    "authors": [
      "Francisco Olivos",
      "Minhui Liu"
    ],
    "abstract": "The rapid advancements in generative artificial intelligence have opened up\nnew avenues for enhancing various aspects of research, including the design and\nevaluation of survey questionnaires. However, the recent pioneering\napplications have not considered questionnaire pretesting. This article\nexplores the use of GPT models as a useful tool for pretesting survey\nquestionnaires, particularly in the early stages of survey design. Illustrated\nwith two applications, the article suggests incorporating GPT feedback as an\nadditional stage before human pretesting, potentially reducing successive\niterations. The article also emphasizes the indispensable role of researchers'\njudgment in interpreting and implementing AI-generated feedback.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "11 pages, 2 Figures",
    "pdf_url": "http://arxiv.org/pdf/2405.06329v1",
    "published_date": "2024-05-10 09:01:14 UTC",
    "updated_date": "2024-05-10 09:01:14 UTC"
  },
  {
    "arxiv_id": "2405.06321v2",
    "title": "Correlation Dimension of Natural Language in a Statistical Manifold",
    "authors": [
      "Xin Du",
      "Kumiko Tanaka-Ishii"
    ],
    "abstract": "The correlation dimension of natural language is measured by applying the\nGrassberger-Procaccia algorithm to high-dimensional sequences produced by a\nlarge-scale language model. This method, previously studied only in a Euclidean\nspace, is reformulated in a statistical manifold via the Fisher-Rao distance.\nLanguage exhibits a multifractal, with global self-similarity and a universal\ndimension around 6.5, which is smaller than those of simple discrete random\nsequences and larger than that of a Barab\\'asi-Albert process. Long memory is\nthe key to producing self-similarity. Our method is applicable to any\nprobabilistic model of real-world discrete sequences, and we show an\napplication to music data.",
    "categories": [
      "cs.CL",
      "cond-mat.stat-mech",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at Physical Review Research",
    "pdf_url": "http://arxiv.org/pdf/2405.06321v2",
    "published_date": "2024-05-10 08:48:03 UTC",
    "updated_date": "2024-05-15 07:46:01 UTC"
  },
  {
    "arxiv_id": "2405.06301v1",
    "title": "Learning from String Sequences",
    "authors": [
      "David Lindsay",
      "Sian Lindsay"
    ],
    "abstract": "The Universal Similarity Metric (USM) has been demonstrated to give\npractically useful measures of \"similarity\" between sequence data. Here we have\nused the USM as an alternative distance metric in a K-Nearest Neighbours (K-NN)\nlearner to allow effective pattern recognition of variable length sequence\ndata. We compare this USM approach with the commonly used string-to-word vector\napproach. Our experiments have used two data sets of divergent domains: (1)\nspam email filtering and (2) protein subcellular localization. Our results with\nthis data reveal that the USM-based K-NN learner (1) gives predictions with\nhigher classification accuracy than those output by techniques that use the\nstring-to-word vector approach, and (2) can be used to generate reliable\nprobability forecasts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 1 figure, 4 tables, Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2405.06301v1",
    "published_date": "2024-05-10 08:09:53 UTC",
    "updated_date": "2024-05-10 08:09:53 UTC"
  },
  {
    "arxiv_id": "2405.06299v1",
    "title": "Cross-domain Learning Framework for Tracking Users in RIS-aided Multi-band ISAC Systems with Sparse Labeled Data",
    "authors": [
      "Jingzhi Hu",
      "Dusit Niyato",
      "Jun Luo"
    ],
    "abstract": "Integrated sensing and communications (ISAC) is pivotal for 6G communications\nand is boosted by the rapid development of reconfigurable intelligent surfaces\n(RISs). Using the channel state information (CSI) across multiple frequency\nbands, RIS-aided multi-band ISAC systems can potentially track users' positions\nwith high precision. Though tracking with CSI is desirable as no communication\noverheads are incurred, it faces challenges due to the multi-modalities of CSI\nsamples, irregular and asynchronous data traffic, and sparse labeled data for\nlearning the tracking function. This paper proposes the X2Track framework,\nwhere we model the tracking function by a hierarchical architecture, jointly\nutilizing multi-modal CSI indicators across multiple bands, and optimize it in\na cross-domain manner, tackling the sparsity of labeled data for the target\ndeployment environment (namely, target domain) by adapting the knowledge\nlearned from another environment (namely, source domain). Under X2Track, we\ndesign an efficient deep learning algorithm to minimize tracking errors, based\non transformer neural networks and adversarial learning techniques. Simulation\nresults verify that X2Track achieves decimeter-level axial tracking errors even\nunder scarce UL data traffic and strong interference conditions and can adapt\nto diverse deployment environments with fewer than 5% training data, or\nequivalently, 5 minutes of UE tracks, being labeled.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06299v1",
    "published_date": "2024-05-10 08:04:27 UTC",
    "updated_date": "2024-05-10 08:04:27 UTC"
  },
  {
    "arxiv_id": "2405.06296v1",
    "title": "Fast Evaluation of DNN for Past Dataset in Incremental Learning",
    "authors": [
      "Naoto Sato"
    ],
    "abstract": "During the operation of a system including a deep neural network (DNN), new\ninput values that were not included in the training dataset are given to the\nDNN. In such a case, the DNN may be incrementally trained with the new input\nvalues; however, that training may reduce the accuracy of the DNN in regard to\nthe dataset that was previously obtained and used for the past training. It is\nnecessary to evaluate the effect of the additional training on the accuracy for\nthe past dataset. However, evaluation by testing all the input values included\nin the past dataset takes time. Therefore, we propose a new method to quickly\nevaluate the effect on the accuracy for the past dataset. In the proposed\nmethod, the gradient of the parameter values (such as weight and bias) for the\npast dataset is extracted by running the DNN before the training. Then, after\nthe training, its effect on the accuracy with respect to the past dataset is\ncalculated from the gradient and update differences of the parameter values. To\nshow the usefulness of the proposed method, we present experimental results\nwith several datasets. The results show that the proposed method can estimate\nthe accuracy change by additional training in a constant time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06296v1",
    "published_date": "2024-05-10 07:55:08 UTC",
    "updated_date": "2024-05-10 07:55:08 UTC"
  },
  {
    "arxiv_id": "2405.06295v1",
    "title": "Aspect-oriented Consumer Health Answer Summarization",
    "authors": [
      "Rochana Chaturvedi",
      "Abari Bhattacharya",
      "Shweta Yadav"
    ],
    "abstract": "Community Question-Answering (CQA) forums have revolutionized how people seek\ninformation, especially those related to their healthcare needs, placing their\ntrust in the collective wisdom of the public. However, there can be several\nanswers in response to a single query, which makes it hard to grasp the key\ninformation related to the specific health concern. Typically, CQA forums\nfeature a single top-voted answer as a representative summary for each query.\nHowever, a single answer overlooks the alternative solutions and other\ninformation frequently offered in other responses. Our research focuses on\naspect-based summarization of health answers to address this limitation.\nSummarization of responses under different aspects such as suggestions,\ninformation, personal experiences, and questions can enhance the usability of\nthe platforms. We formalize a multi-stage annotation guideline and contribute a\nunique dataset comprising aspect-based human-written health answer summaries.\nWe build an automated multi-faceted answer summarization pipeline with this\ndataset based on task-specific fine-tuning of several state-of-the-art models.\nThe pipeline leverages question similarity to retrieve relevant answer\nsentences, subsequently classifying them into the appropriate aspect type.\nFollowing this, we employ several recent abstractive summarization models to\ngenerate aspect-based summaries. Finally, we present a comprehensive human\nanalysis and find that our summaries rank high in capturing relevant content\nand a wide range of solutions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "H.4.3; I.2.7; J.3; J.7; K.6.4"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06295v1",
    "published_date": "2024-05-10 07:52:43 UTC",
    "updated_date": "2024-05-10 07:52:43 UTC"
  },
  {
    "arxiv_id": "2405.06289v3",
    "title": "Look Once to Hear: Target Speech Hearing with Noisy Examples",
    "authors": [
      "Bandhav Veluri",
      "Malek Itani",
      "Tuochao Chen",
      "Takuya Yoshioka",
      "Shyamnath Gollakota"
    ],
    "abstract": "In crowded settings, the human brain can focus on speech from a target\nspeaker, given prior knowledge of how they sound. We introduce a novel\nintelligent hearable system that achieves this capability, enabling target\nspeech hearing to ignore all interfering speech and noise, but the target\nspeaker. A naive approach is to require a clean speech example to enroll the\ntarget speaker. This is however not well aligned with the hearable application\ndomain since obtaining a clean example is challenging in real world scenarios,\ncreating a unique user interface problem. We present the first enrollment\ninterface where the wearer looks at the target speaker for a few seconds to\ncapture a single, short, highly noisy, binaural example of the target speaker.\nThis noisy example is used for enrollment and subsequent speech extraction in\nthe presence of interfering speakers and noise. Our system achieves a signal\nquality improvement of 7.01 dB using less than 5 seconds of noisy enrollment\naudio and can process 8 ms of audio chunks in 6.24 ms on an embedded CPU. Our\nuser studies demonstrate generalization to real-world static and mobile\nspeakers in previously unseen indoor and outdoor multipath environments.\nFinally, our enrollment interface for noisy examples does not cause performance\ndegradation compared to clean examples, while being convenient and\nuser-friendly. Taking a step back, this paper takes an important step towards\nenhancing the human auditory perception with artificial intelligence. We\nprovide code and data at: https://github.com/vb000/LookOnceToHear.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Best paper honorable mention at CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06289v3",
    "published_date": "2024-05-10 07:44:18 UTC",
    "updated_date": "2024-05-29 19:00:39 UTC"
  },
  {
    "arxiv_id": "2405.06270v3",
    "title": "XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare",
    "authors": [
      "Fatemeh Nazary",
      "Yashar Deldjoo",
      "Tommaso Di Noia",
      "Eugenio di Sciascio"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into healthcare diagnostics\noffers a promising avenue for clinical decision-making. This study outlines the\ndevelopment of a novel method for zero-shot/few-shot in-context learning (ICL)\nby integrating medical domain knowledge using a multi-layered structured\nprompt. We also explore the efficacy of two communication styles between the\nuser and LLMs: the Numerical Conversational (NC) style, which processes data\nincrementally, and the Natural Language Single-Turn (NL-ST) style, which\nemploys long narrative prompts.\n  Our study systematically evaluates the diagnostic accuracy and risk factors,\nincluding gender bias and false negative rates, using a dataset of 920 patient\nrecords in various few-shot scenarios. Results indicate that traditional\nclinical machine learning (ML) models generally outperform LLMs in zero-shot\nand few-shot settings. However, the performance gap narrows significantly when\nemploying few-shot examples alongside effective explainable AI (XAI) methods as\nsources of domain knowledge. Moreover, with sufficient time and an increased\nnumber of examples, the conversational style (NC) nearly matches the\nperformance of ML models. Most notably, LLMs demonstrate comparable or superior\ncost-sensitive accuracy relative to ML models.\n  This research confirms that, with appropriate domain knowledge and tailored\ncommunication strategies, LLMs can significantly enhance diagnostic processes.\nThe findings highlight the importance of optimizing the number of training\nexamples and communication styles to improve accuracy and reduce biases in LLM\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06270v3",
    "published_date": "2024-05-10 06:52:44 UTC",
    "updated_date": "2024-06-03 16:23:28 UTC"
  },
  {
    "arxiv_id": "2405.06266v1",
    "title": "A Multi-Channel Spatial-Temporal Transformer Model for Traffic Flow Forecasting",
    "authors": [
      "Jianli Xiao",
      "Baichao Long"
    ],
    "abstract": "Traffic flow forecasting is a crucial task in transportation management and\nplanning. The main challenges for traffic flow forecasting are that (1) as the\nlength of prediction time increases, the accuracy of prediction will decrease;\n(2) the predicted results greatly rely on the extraction of temporal and\nspatial dependencies from the road networks. To overcome the challenges\nmentioned above, we propose a multi-channel spatial-temporal transformer model\nfor traffic flow forecasting, which improves the accuracy of the prediction by\nfusing results from different channels of traffic data. Our approach leverages\ngraph convolutional network to extract spatial features from each channel while\nusing a transformer-based architecture to capture temporal dependencies across\nchannels. We introduce an adaptive adjacency matrix to overcome limitations in\nfeature extraction from fixed topological structures. Experimental results on\nsix real-world datasets demonstrate that introducing a multi-channel mechanism\ninto the temporal model enhances performance and our proposed model outperforms\nstate-of-the-art models in terms of accuracy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06266v1",
    "published_date": "2024-05-10 06:37:07 UTC",
    "updated_date": "2024-05-10 06:37:07 UTC"
  },
  {
    "arxiv_id": "2405.06263v2",
    "title": "Learning Latent Dynamic Robust Representations for World Models",
    "authors": [
      "Ruixiang Sun",
      "Hongyu Zang",
      "Xin Li",
      "Riashat Islam"
    ],
    "abstract": "Visual Model-Based Reinforcement Learning (MBRL) promises to encapsulate\nagent's knowledge about the underlying dynamics of the environment, enabling\nlearning a world model as a useful planner. However, top MBRL agents such as\nDreamer often struggle with visual pixel-based inputs in the presence of\nexogenous or irrelevant noise in the observation space, due to failure to\ncapture task-specific features while filtering out irrelevant spatio-temporal\ndetails. To tackle this problem, we apply a spatio-temporal masking strategy, a\nbisimulation principle, combined with latent reconstruction, to capture\nendogenous task-specific aspects of the environment for world models,\neffectively eliminating non-essential information. Joint training of\nrepresentations, dynamics, and policy often leads to instabilities. To further\naddress this issue, we develop a Hybrid Recurrent State-Space Model (HRSSM)\nstructure, enhancing state representation robustness for effective policy\nlearning. Our empirical evaluation demonstrates significant performance\nimprovements over existing methods in a range of visually complex control tasks\nsuch as Maniskill \\cite{gu2023maniskill2} with exogenous distractors from the\nMatterport environment. Our code is avaliable at\nhttps://github.com/bit1029public/HRSSM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06263v2",
    "published_date": "2024-05-10 06:28:42 UTC",
    "updated_date": "2024-05-30 09:40:02 UTC"
  },
  {
    "arxiv_id": "2405.06260v1",
    "title": "Precise Apple Detection and Localization in Orchards using YOLOv5 for Robotic Harvesting Systems",
    "authors": [
      "Jiang Ziyue",
      "Yin Bo",
      "Lu Boyun"
    ],
    "abstract": "The advancement of agricultural robotics holds immense promise for\ntransforming fruit harvesting practices, particularly within the apple\nindustry. The accurate detection and localization of fruits are pivotal for the\nsuccessful implementation of robotic harvesting systems. In this paper, we\npropose a novel approach to apple detection and position estimation utilizing\nan object detection model, YOLOv5. Our primary objective is to develop a robust\nsystem capable of identifying apples in complex orchard environments and\nproviding precise location information. To achieve this, we curated an\nautonomously labeled dataset comprising diverse apple tree images, which was\nutilized for both training and evaluation purposes. Through rigorous\nexperimentation, we compared the performance of our YOLOv5-based system with\nother popular object detection models, including SSD. Our results demonstrate\nthat the YOLOv5 model outperforms its counterparts, achieving an impressive\napple detection accuracy of approximately 85%. We believe that our proposed\nsystem's accurate apple detection and position estimation capabilities\nrepresent a significant advancement in agricultural robotics, laying the\ngroundwork for more efficient and sustainable fruit harvesting practices.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06260v1",
    "published_date": "2024-05-10 06:17:00 UTC",
    "updated_date": "2024-05-10 06:17:00 UTC"
  },
  {
    "arxiv_id": "2405.06721v1",
    "title": "Kolmogorov-Arnold Networks are Radial Basis Function Networks",
    "authors": [
      "Ziyao Li"
    ],
    "abstract": "This short paper is a fast proof-of-concept that the 3-order B-splines used\nin Kolmogorov-Arnold Networks (KANs) can be well approximated by Gaussian\nradial basis functions. Doing so leads to FastKAN, a much faster implementation\nof KAN which is also a radial basis function (RBF) network.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06721v1",
    "published_date": "2024-05-10 06:03:45 UTC",
    "updated_date": "2024-05-10 06:03:45 UTC"
  },
  {
    "arxiv_id": "2405.06247v1",
    "title": "Disttack: Graph Adversarial Attacks Toward Distributed GNN Training",
    "authors": [
      "Yuxiang Zhang",
      "Xin Liu",
      "Meng Wu",
      "Wei Yan",
      "Mingyu Yan",
      "Xiaochun Ye",
      "Dongrui Fan"
    ],
    "abstract": "Graph Neural Networks (GNNs) have emerged as potent models for graph\nlearning. Distributing the training process across multiple computing nodes is\nthe most promising solution to address the challenges of ever-growing\nreal-world graphs. However, current adversarial attack methods on GNNs neglect\nthe characteristics and applications of the distributed scenario, leading to\nsuboptimal performance and inefficiency in attacking distributed GNN training.\n  In this study, we introduce Disttack, the first framework of adversarial\nattacks for distributed GNN training that leverages the characteristics of\nfrequent gradient updates in a distributed system. Specifically, Disttack\ncorrupts distributed GNN training by injecting adversarial attacks into one\nsingle computing node. The attacked subgraphs are precisely perturbed to induce\nan abnormal gradient ascent in backpropagation, disrupting gradient\nsynchronization between computing nodes and thus leading to a significant\nperformance decline of the trained GNN. We evaluate Disttack on four large\nreal-world graphs by attacking five widely adopted GNNs. Compared with the\nstate-of-the-art attack method, experimental results demonstrate that Disttack\namplifies the model accuracy degradation by 2.75$\\times$ and achieves speedup\nby 17.33$\\times$ on average while maintaining unnoticeability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by 30th International European Conference on Parallel and\n  Distributed Computing(Euro-Par 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.06247v1",
    "published_date": "2024-05-10 05:09:59 UTC",
    "updated_date": "2024-05-10 05:09:59 UTC"
  },
  {
    "arxiv_id": "2405.06239v1",
    "title": "SaudiBERT: A Large Language Model Pretrained on Saudi Dialect Corpora",
    "authors": [
      "Faisal Qarah"
    ],
    "abstract": "In this paper, we introduce SaudiBERT, a monodialect Arabic language model\npretrained exclusively on Saudi dialectal text. To demonstrate the model's\neffectiveness, we compared SaudiBERT with six different multidialect Arabic\nlanguage models across 11 evaluation datasets, which are divided into two\ngroups: sentiment analysis and text classification. SaudiBERT achieved average\nF1-scores of 86.15\\% and 87.86\\% in these groups respectively, significantly\noutperforming all other comparative models. Additionally, we present two novel\nSaudi dialectal corpora: the Saudi Tweets Mega Corpus (STMC), which contains\nover 141 million tweets in Saudi dialect, and the Saudi Forums Corpus (SFC),\nwhich includes 15.2 GB of text collected from five Saudi online forums. Both\ncorpora are used in pretraining the proposed model, and they are the largest\nSaudi dialectal corpora ever reported in the literature. The results confirm\nthe effectiveness of SaudiBERT in understanding and analyzing Arabic text\nexpressed in Saudi dialect, achieving state-of-the-art results in most tasks\nand surpassing other language models included in the study. SaudiBERT model is\npublicly available on \\url{https://huggingface.co/faisalq/SaudiBERT}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06239v1",
    "published_date": "2024-05-10 04:22:54 UTC",
    "updated_date": "2024-05-10 04:22:54 UTC"
  },
  {
    "arxiv_id": "2405.06232v1",
    "title": "Learning to Solve Geometry Problems via Simulating Human Dual-Reasoning Process",
    "authors": [
      "Tong Xiao",
      "Jiayu Liu",
      "Zhenya Huang",
      "Jinze Wu",
      "Jing Sha",
      "Shijin Wang",
      "Enhong Chen"
    ],
    "abstract": "Geometry Problem Solving (GPS), which is a classic and challenging math\nproblem, has attracted much attention in recent years. It requires a solver to\ncomprehensively understand both text and diagram, master essential geometry\nknowledge, and appropriately apply it in reasoning. However, existing works\nfollow a paradigm of neural machine translation and only focus on enhancing the\ncapability of encoders, which neglects the essential characteristics of human\ngeometry reasoning. In this paper, inspired by dual-process theory, we propose\na Dual-Reasoning Geometry Solver (DualGeoSolver) to simulate the dual-reasoning\nprocess of humans for GPS. Specifically, we construct two systems in\nDualGeoSolver, namely Knowledge System and Inference System. Knowledge System\ncontrols an implicit reasoning process, which is responsible for providing\ndiagram information and geometry knowledge according to a step-wise reasoning\ngoal generated by Inference System. Inference System conducts an explicit\nreasoning process, which specifies the goal in each reasoning step and applies\nthe knowledge to generate program tokens for resolving it. The two systems\ncarry out the above process iteratively, which behaves more in line with human\ncognition. We conduct extensive experiments on two benchmark datasets, GeoQA\nand GeoQA+. The results demonstrate the superiority of DualGeoSolver in both\nsolving accuracy and robustness from explicitly modeling human reasoning\nprocess and knowledge application.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "IJCAI 2024 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2405.06232v1",
    "published_date": "2024-05-10 03:53:49 UTC",
    "updated_date": "2024-05-10 03:53:49 UTC"
  },
  {
    "arxiv_id": "2405.06719v1",
    "title": "Enhancing Traffic Prediction with Textual Data Using Large Language Models",
    "authors": [
      "Xiannan Huang"
    ],
    "abstract": "Traffic prediction is pivotal for rational transportation supply scheduling\nand allocation. Existing researches into short-term traffic prediction,\nhowever, face challenges in adequately addressing exceptional circumstances and\nintegrating non-numerical contextual information like weather into models.\nWhile, Large language models offer a promising solution due to their inherent\nworld knowledge. However, directly using them for traffic prediction presents\ndrawbacks such as high cost, lack of determinism, and limited mathematical\ncapability. To mitigate these issues, this study proposes a novel approach.\nInstead of directly employing large models for prediction, it utilizes them to\nprocess textual information and obtain embeddings. These embeddings are then\ncombined with historical traffic data and inputted into traditional\nspatiotemporal forecasting models. The study investigates two types of special\nscenarios: regional-level and node-level. For regional-level scenarios, textual\ninformation is represented as a node connected to the entire network. For\nnode-level scenarios, embeddings from the large model represent additional\nnodes connected only to corresponding nodes. This approach shows a significant\nimprovement in prediction accuracy according to our experiment of New York Bike\ndataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06719v1",
    "published_date": "2024-05-10 03:14:26 UTC",
    "updated_date": "2024-05-10 03:14:26 UTC"
  },
  {
    "arxiv_id": "2405.06218v1",
    "title": "Aligning Tutor Discourse Supporting Rigorous Thinking with Tutee Content Mastery for Predicting Math Achievement",
    "authors": [
      "Mark Abdelshiheed",
      "Jennifer K. Jacobs",
      "Sidney K. D'Mello"
    ],
    "abstract": "This work investigates how tutoring discourse interacts with students'\nproximal knowledge to explain and predict students' learning outcomes. Our work\nis conducted in the context of high-dosage human tutoring where 9th-grade\nstudents (N= 1080) attended small group tutorials and individually practiced\nproblems on an Intelligent Tutoring System (ITS). We analyzed whether tutors'\ntalk moves and students' performance on the ITS predicted scores on math\nlearning assessments. We trained Random Forest Classifiers (RFCs) to\ndistinguish high and low assessment scores based on tutor talk moves, student's\nITS performance metrics, and their combination. A decision tree was extracted\nfrom each RFC to yield an interpretable model. We found AUCs of 0.63 for talk\nmoves, 0.66 for ITS, and 0.77 for their combination, suggesting interactivity\namong the two feature sources. Specifically, the best decision tree emerged\nfrom combining the tutor talk moves that encouraged rigorous thinking and\nstudents' ITS mastery. In essence, tutor talk that encouraged mathematical\nreasoning predicted achievement for students who demonstrated high mastery on\nthe ITS, whereas tutors' revoicing of students' mathematical ideas and\ncontributions was predictive for students with low ITS mastery. Implications\nfor practice are discussed.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06218v1",
    "published_date": "2024-05-10 03:04:59 UTC",
    "updated_date": "2024-05-10 03:04:59 UTC"
  },
  {
    "arxiv_id": "2405.06211v3",
    "title": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
    "authors": [
      "Wenqi Fan",
      "Yujuan Ding",
      "Liangbo Ning",
      "Shijie Wang",
      "Hengyun Li",
      "Dawei Yin",
      "Tat-Seng Chua",
      "Qing Li"
    ],
    "abstract": "As one of the most advanced techniques in AI, Retrieval-Augmented Generation\n(RAG) can offer reliable and up-to-date external knowledge, providing huge\nconvenience for numerous tasks. Particularly in the era of AI-Generated Content\n(AIGC), the powerful capacity of retrieval in providing additional knowledge\nenables RAG to assist existing generative AI in producing high-quality outputs.\nRecently, Large Language Models (LLMs) have demonstrated revolutionary\nabilities in language understanding and generation, while still facing inherent\nlimitations, such as hallucinations and out-of-date internal knowledge. Given\nthe powerful abilities of RAG in providing the latest and helpful auxiliary\ninformation, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged\nto harness external and authoritative knowledge bases, rather than solely\nrelying on the model's internal knowledge, to augment the generation quality of\nLLMs. In this survey, we comprehensively review existing research studies in\nRA-LLMs, covering three primary technical perspectives: architectures, training\nstrategies, and applications. As the preliminary knowledge, we briefly\nintroduce the foundations and recent advances of LLMs. Then, to illustrate the\npractical significance of RAG for LLMs, we systematically review mainstream\nrelevant work by their architectures, training strategies, and application\nareas, detailing specifically the challenges of each and the corresponding\ncapabilities of RA-LLMs. Finally, to deliver deeper insights, we discuss\ncurrent limitations and several promising directions for future research.\nUpdated information about this survey can be found at\nhttps://advanced-recommender-systems.github.io/RAG-Meets-LLMs/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "This is the long version of the corresponding survey paper accepted\n  by KDD2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06211v3",
    "published_date": "2024-05-10 02:48:45 UTC",
    "updated_date": "2024-06-17 08:56:38 UTC"
  },
  {
    "arxiv_id": "2405.06206v2",
    "title": "Concealing Backdoor Model Updates in Federated Learning by Trigger-Optimized Data Poisoning",
    "authors": [
      "Yujie Zhang",
      "Neil Gong",
      "Michael K. Reiter"
    ],
    "abstract": "Federated Learning (FL) is a decentralized machine learning method that\nenables participants to collaboratively train a model without sharing their\nprivate data. Despite its privacy and scalability benefits, FL is susceptible\nto backdoor attacks, where adversaries poison the local training data of a\nsubset of clients using a backdoor trigger, aiming to make the aggregated model\nproduce malicious results when the same backdoor condition is met by an\ninference-time input. Existing backdoor attacks in FL suffer from common\ndeficiencies: fixed trigger patterns and reliance on the assistance of model\npoisoning. State-of-the-art defenses based on analyzing clients' model updates\nexhibit a good defense performance on these attacks because of the significant\ndivergence between malicious and benign client model updates. To effectively\nconceal malicious model updates among benign ones, we propose DPOT, a backdoor\nattack strategy in FL that dynamically constructs backdoor objectives by\noptimizing a backdoor trigger, making backdoor data have minimal effect on\nmodel updates. We provide theoretical justifications for DPOT's attacking\nprinciple and display experimental results showing that DPOT, via only a\ndata-poisoning attack, effectively undermines state-of-the-art defenses and\noutperforms existing backdoor attack techniques on various datasets.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06206v2",
    "published_date": "2024-05-10 02:44:25 UTC",
    "updated_date": "2024-09-09 22:11:39 UTC"
  },
  {
    "arxiv_id": "2405.06204v1",
    "title": "HC$^2$L: Hybrid and Cooperative Contrastive Learning for Cross-lingual Spoken Language Understanding",
    "authors": [
      "Bowen Xing",
      "Ivor W. Tsang"
    ],
    "abstract": "State-of-the-art model for zero-shot cross-lingual spoken language\nunderstanding performs cross-lingual unsupervised contrastive learning to\nachieve the label-agnostic semantic alignment between each utterance and its\ncode-switched data. However, it ignores the precious intent/slot labels, whose\nlabel information is promising to help capture the label-aware semantics\nstructure and then leverage supervised contrastive learning to improve both\nsource and target languages' semantics. In this paper, we propose Hybrid and\nCooperative Contrastive Learning to address this problem. Apart from\ncross-lingual unsupervised contrastive learning, we design a holistic approach\nthat exploits source language supervised contrastive learning, cross-lingual\nsupervised contrastive learning and multilingual supervised contrastive\nlearning to perform label-aware semantics alignments in a comprehensive manner.\nEach kind of supervised contrastive learning mechanism includes both\nsingle-task and joint-task scenarios. In our model, one contrastive learning\nmechanism's input is enhanced by others. Thus the total four contrastive\nlearning mechanisms are cooperative to learn more consistent and discriminative\nrepresentations in the virtuous cycle during the training process. Experiments\nshow that our model obtains consistent improvements over 9 languages, achieving\nnew state-of-the-art performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI). arXiv admin note: text overlap with arXiv:2312.03716",
    "pdf_url": "http://arxiv.org/pdf/2405.06204v1",
    "published_date": "2024-05-10 02:40:49 UTC",
    "updated_date": "2024-05-10 02:40:49 UTC"
  },
  {
    "arxiv_id": "2405.06203v1",
    "title": "A First Step in Using Machine Learning Methods to Enhance Interaction Analysis for Embodied Learning Environments",
    "authors": [
      "Joyce Fonteles",
      "Eduardo Davalos",
      "Ashwin T. S.",
      "Yike Zhang",
      "Mengxi Zhou",
      "Efrat Ayalon",
      "Alicia Lane",
      "Selena Steinberg",
      "Gabriella Anton",
      "Joshua Danish",
      "Noel Enyedy",
      "Gautam Biswas"
    ],
    "abstract": "Investigating children's embodied learning in mixed-reality environments,\nwhere they collaboratively simulate scientific processes, requires analyzing\ncomplex multimodal data to interpret their learning and coordination behaviors.\nLearning scientists have developed Interaction Analysis (IA) methodologies for\nanalyzing such data, but this requires researchers to watch hours of videos to\nextract and interpret students' learning patterns. Our study aims to simplify\nresearchers' tasks, using Machine Learning and Multimodal Learning Analytics to\nsupport the IA processes. Our study combines machine learning algorithms and\nmultimodal analyses to support and streamline researcher efforts in developing\na comprehensive understanding of students' scientific engagement through their\nmovements, gaze, and affective responses in a simulated scenario. To facilitate\nan effective researcher-AI partnership, we present an initial case study to\ndetermine the feasibility of visually representing students' states, actions,\ngaze, affect, and movement on a timeline. Our case study focuses on a specific\nscience scenario where students learn about photosynthesis. The timeline allows\nus to investigate the alignment of critical learning moments identified by\nmultimodal and interaction analysis, and uncover insights into students'\ntemporal learning progressions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06203v1",
    "published_date": "2024-05-10 02:40:24 UTC",
    "updated_date": "2024-05-10 02:40:24 UTC"
  },
  {
    "arxiv_id": "2405.06196v2",
    "title": "VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with Lightweight Blocks",
    "authors": [
      "Manish Dhakal",
      "Rabin Adhikari",
      "Safal Thapaliya",
      "Bishesh Khanal"
    ],
    "abstract": "Foundation Vision-Language Models (VLMs) trained using large-scale\nopen-domain images and text pairs have recently been adapted to develop\nVision-Language Segmentation Models (VLSMs) that allow providing text prompts\nduring inference to guide image segmentation. If robust and powerful VLSMs can\nbe built for medical images, it could aid medical professionals in many\nclinical tasks where they must spend substantial time delineating the target\nstructure of interest. VLSMs for medical images resort to fine-tuning base VLM\nor VLSM pretrained on open-domain natural image datasets due to fewer annotated\nmedical image datasets; this fine-tuning is resource-consuming and expensive as\nit usually requires updating all or a significant fraction of the pretrained\nparameters. Recently, lightweight blocks called adapters have been proposed in\nVLMs that keep the pretrained model frozen and only train adapters during\nfine-tuning, substantially reducing the computing resources required. We\nintroduce a novel adapter, VLSM-Adapter, that can fine-tune pretrained\nvision-language segmentation models using transformer encoders. Our experiments\nin widely used CLIP-based segmentation models show that with only 3 million\ntrainable parameters, the VLSM-Adapter outperforms state-of-the-art and is\ncomparable to the upper bound end-to-end fine-tuning. The source code is\navailable at: https://github.com/naamiinepal/vlsm-adapter.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at MICCAI 2024, the 27th International Conference on Medical\n  Image Computing and Computer Assisted Intervention",
    "pdf_url": "http://arxiv.org/pdf/2405.06196v2",
    "published_date": "2024-05-10 02:23:56 UTC",
    "updated_date": "2024-06-27 14:19:56 UTC"
  },
  {
    "arxiv_id": "2405.06192v1",
    "title": "Contrastive Representation for Data Filtering in Cross-Domain Offline Reinforcement Learning",
    "authors": [
      "Xiaoyu Wen",
      "Chenjia Bai",
      "Kang Xu",
      "Xudong Yu",
      "Yang Zhang",
      "Xuelong Li",
      "Zhen Wang"
    ],
    "abstract": "Cross-domain offline reinforcement learning leverages source domain data with\ndiverse transition dynamics to alleviate the data requirement for the target\ndomain. However, simply merging the data of two domains leads to performance\ndegradation due to the dynamics mismatch. Existing methods address this problem\nby measuring the dynamics gap via domain classifiers while relying on the\nassumptions of the transferability of paired domains. In this paper, we propose\na novel representation-based approach to measure the domain gap, where the\nrepresentation is learned through a contrastive objective by sampling\ntransitions from different domains. We show that such an objective recovers the\nmutual-information gap of transition functions in two domains without suffering\nfrom the unbounded issue of the dynamics gap in handling significantly\ndifferent domains. Based on the representations, we introduce a data filtering\nalgorithm that selectively shares transitions from the source domain according\nto the contrastive score functions. Empirical results on various tasks\ndemonstrate that our method achieves superior performance, using only 10% of\nthe target data to achieve 89.2% of the performance on 100% target dataset with\nstate-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06192v1",
    "published_date": "2024-05-10 02:21:42 UTC",
    "updated_date": "2024-05-10 02:21:42 UTC"
  },
  {
    "arxiv_id": "2405.06164v1",
    "title": "Skeet: Towards a Lightweight Serverless Framework Supporting Modern AI-Driven App Development",
    "authors": [
      "Kawasaki Fumitake",
      "Shota Kishi",
      "James Neve"
    ],
    "abstract": "The field of web and mobile software frameworks is relatively mature, with a\nlarge variety of tools in different languages that facilitate traditional app\ndevelopment where data in a relational database is displayed and modified. Our\nposition is that many current frameworks became popular during single server\ndeployment of MVC architecture apps, and do not facilitate modern aspects of\napp development such as cloud computing and the incorporation of emerging\ntechnologies such as AI. We present a novel framework which accomplishes these\npurposes, Skeet, which was recently released to general use, alongside an\ninitial evaluation. Skeet provides an app structure that reflects current\ntrends in architecture, and tool suites that allow developers with minimal\nknowledge of AI internals to easily incorporate such technologies into their\napps and deploy them.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06164v1",
    "published_date": "2024-05-10 01:00:20 UTC",
    "updated_date": "2024-05-10 01:00:20 UTC"
  },
  {
    "arxiv_id": "2405.06149v2",
    "title": "DisBeaNet: A Deep Neural Network to augment Unmanned Surface Vessels for maritime situational awareness",
    "authors": [
      "Srikanth Vemula",
      "Eulises Franco",
      "Michael Frye"
    ],
    "abstract": "Intelligent detection and tracking of the vessels on the sea play a\nsignificant role in conducting traffic avoidance in unmanned surface\nvessels(USV). Current traffic avoidance software relies mainly on Automated\nIdentification System (AIS) and radar to track other vessels to avoid\ncollisions and acts as a typical perception system to detect targets. However,\nin a contested environment, emitting radar energy also presents the\nvulnerability to detection by adversaries. Deactivating these Radiofrequency\ntransmitting sources will increase the threat of detection and degrade the\nUSV's ability to monitor shipping traffic in the vicinity. Therefore, an\nintelligent visual perception system based on an onboard camera with passive\nsensing capabilities that aims to assist USV in addressing this problem is\npresented in this paper. This paper will present a novel low-cost vision\nperception system for detecting and tracking vessels in the maritime\nenvironment. This novel low-cost vision perception system is introduced using\nthe deep learning framework. A neural network, DisBeaNet, can detect vessels,\ntrack, and estimate the vessel's distance and bearing from the monocular\ncamera. The outputs obtained from this neural network are used to determine the\nlatitude and longitude of the identified vessel.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06149v2",
    "published_date": "2024-05-10 00:15:17 UTC",
    "updated_date": "2024-05-17 20:38:24 UTC"
  }
]