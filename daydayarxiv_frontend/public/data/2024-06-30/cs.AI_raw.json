[
  {
    "arxiv_id": "2407.12034v2",
    "title": "Understanding Transformers via N-gram Statistics",
    "authors": [
      "Timothy Nguyen"
    ],
    "abstract": "Transformer based large-language models (LLMs) display extreme proficiency\nwith language yet a precise understanding of how they work remains elusive. One\nway of demystifying transformer predictions would be to describe how they\ndepend on their context in terms of simple template functions. This paper takes\na first step in this direction by considering families of functions (i.e.\nrules) formed out of simple N-gram based statistics of the training data. By\nstudying how well these rulesets approximate transformer predictions, we obtain\na variety of novel discoveries: a simple method to detect overfitting during\ntraining without using a holdout set, a quantitative measure of how\ntransformers progress from learning simple to more complex statistical rules\nover the course of training, a model-variance criterion governing when\ntransformer predictions tend to be described by N-gram rules, and insights into\nhow well transformers can be approximated by N-gram rulesets in the limit where\nthese rulesets become increasingly complex. In this latter direction, we find\nthat for 79% and 68% of LLM next-token distributions on TinyStories and\nWikipedia, respectively, their top-1 predictions agree with those provided by\nour N-gram rulesets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024. Datasets and N-gram statistics open-sourced:\n  https://github.com/google-deepmind/transformer_ngrams",
    "pdf_url": "http://arxiv.org/pdf/2407.12034v2",
    "published_date": "2024-06-30 22:18:49 UTC",
    "updated_date": "2024-11-05 10:24:42 UTC"
  },
  {
    "arxiv_id": "2407.00837v2",
    "title": "Towards Robust Speech Representation Learning for Thousands of Languages",
    "authors": [
      "William Chen",
      "Wangyou Zhang",
      "Yifan Peng",
      "Xinjian Li",
      "Jinchuan Tian",
      "Jiatong Shi",
      "Xuankai Chang",
      "Soumi Maiti",
      "Karen Livescu",
      "Shinji Watanabe"
    ],
    "abstract": "Self-supervised learning (SSL) has helped extend speech technologies to more\nlanguages by reducing the need for labeled data. However, models are still far\nfrom supporting the world's 7000+ languages. We propose XEUS, a Cross-lingual\nEncoder for Universal Speech, trained on over 1 million hours of data across\n4057 languages, extending the language coverage of SSL models 4-fold. We\ncombine 1 million hours of speech from existing publicly accessible corpora\nwith a newly created corpus of 7400+ hours from 4057 languages, which will be\npublicly released. To handle the diverse conditions of multilingual speech\ndata, we augment the typical SSL masked prediction approach with a novel\ndereverberation objective, increasing robustness. We evaluate XEUS on several\nbenchmarks, and show that it consistently outperforms or achieves comparable\nresults to state-of-the-art (SOTA) SSL models across a variety of tasks. XEUS\nsets a new SOTA on the ML-SUPERB benchmark: it outperforms MMS 1B and w2v-BERT\n2.0 v2 by 0.8% and 4.4% respectively, despite having less parameters or\npre-training data. Checkpoints, code, and data are found in\nhttps://www.wavlab.org/activities/2024/xeus/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Updated affiliations; 20 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.00837v2",
    "published_date": "2024-06-30 21:40:26 UTC",
    "updated_date": "2024-07-02 17:23:44 UTC"
  },
  {
    "arxiv_id": "2407.01638v2",
    "title": "LASSI: An LLM-based Automated Self-Correcting Pipeline for Translating Parallel Scientific Codes",
    "authors": [
      "Matthew T. Dearing",
      "Yiheng Tao",
      "Xingfu Wu",
      "Zhiling Lan",
      "Valerie Taylor"
    ],
    "abstract": "This paper addresses the problem of providing a novel approach to sourcing\nsignificant training data for LLMs focused on science and engineering. In\nparticular, a crucial challenge is sourcing parallel scientific codes in the\nranges of millions to billions of codes. To tackle this problem, we propose an\nautomated pipeline framework called LASSI, designed to translate between\nparallel programming languages by bootstrapping existing closed- or open-source\nLLMs. LASSI incorporates autonomous enhancement through self-correcting loops\nwhere errors encountered during the compilation and execution of generated code\nare fed back to the LLM through guided prompting for debugging and refactoring.\nWe highlight the bi-directional translation of existing GPU benchmarks between\nOpenMP target offload and CUDA to validate LASSI. The results of evaluating\nLASSI with different application codes across four LLMs demonstrate the\neffectiveness of LASSI for generating executable parallel codes, with 80% of\nOpenMP to CUDA translations and 85% of CUDA to OpenMP translations producing\nthe expected output. We also observe approximately 78% of OpenMP to CUDA\ntranslations and 62% of CUDA to OpenMP translations execute within 10% of or at\na faster runtime than the original benchmark code in the same language.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DC",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "8 pages, 1 figure, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.01638v2",
    "published_date": "2024-06-30 19:36:04 UTC",
    "updated_date": "2025-05-04 17:21:20 UTC"
  },
  {
    "arxiv_id": "2407.00808v1",
    "title": "Exploring a Physics-Informed Decision Transformer for Distribution System Restoration: Methodology and Performance Analysis",
    "authors": [
      "Hong Zhao",
      "Jin Wei-Kocsis",
      "Adel Heidari Akhijahani",
      "Karen L Butler-Purry"
    ],
    "abstract": "Driven by advancements in sensing and computing, deep reinforcement learning\n(DRL)-based methods have demonstrated significant potential in effectively\ntackling distribution system restoration (DSR) challenges under uncertain\noperational scenarios. However, the data-intensive nature of DRL poses\nobstacles in achieving satisfactory DSR solutions for large-scale, complex\ndistribution systems. Inspired by the transformative impact of emerging\nfoundation models, including large language models (LLMs), across various\ndomains, this paper explores an innovative approach harnessing LLMs' powerful\ncomputing capabilities to address scalability challenges inherent in\nconventional DRL methods for solving DSR. To our knowledge, this study\nrepresents the first exploration of foundation models, including LLMs, in\nrevolutionizing conventional DRL applications in power system operations. Our\ncontributions are twofold: 1) introducing a novel LLM-powered Physics-Informed\nDecision Transformer (PIDT) framework that leverages LLMs to transform\nconventional DRL methods for DSR operations, and 2) conducting comparative\nstudies to assess the performance of the proposed LLM-powered PIDT framework at\nits initial development stage for solving DSR problems. While our primary focus\nin this paper is on DSR operations, the proposed PIDT framework can be\ngeneralized to optimize sequential decision-making across various power system\noperations.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00808v1",
    "published_date": "2024-06-30 19:27:06 UTC",
    "updated_date": "2024-06-30 19:27:06 UTC"
  },
  {
    "arxiv_id": "2407.00805v5",
    "title": "Towards shutdownable agents via stochastic choice",
    "authors": [
      "Elliott Thornley",
      "Alexander Roman",
      "Christos Ziakas",
      "Leyton Ho",
      "Louis Thomson"
    ],
    "abstract": "The Incomplete Preferences Proposal (IPP) is an idea for ensuring that\nadvanced artificial agents never resist shutdown. A key part of the IPP is\nusing a novel `Discounted Reward for Same-Length Trajectories (DReST)' reward\nfunction to train agents to (1) pursue goals effectively conditional on each\ntrajectory-length (be `USEFUL'), and (2) choose stochastically between\ndifferent trajectory-lengths (be `NEUTRAL' about trajectory-lengths). In this\npaper, we propose evaluation metrics for USEFULNESS and NEUTRALITY. We use a\nDReST reward function to train simple agents to navigate gridworlds, and we\nfind that these agents learn to be USEFUL and NEUTRAL. Our results thus provide\nsome initial evidence that DReST reward functions could train advanced agents\nto be USEFUL and NEUTRAL. Our theoretical work suggests that these agents would\nbe useful and shutdownable.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00805v5",
    "published_date": "2024-06-30 19:16:02 UTC",
    "updated_date": "2025-04-01 01:27:34 UTC"
  },
  {
    "arxiv_id": "2407.00803v1",
    "title": "Controlling Face's Frame generation in StyleGAN's latent space operations: Modifying faces to deceive our memory",
    "authors": [
      "Agustín Roca",
      "Nicolás Ignacio Britos"
    ],
    "abstract": "Innocence Project is a non-profitable organization that works in reducing\nwrongful convictions. In collaboration with Laboratorio de Sue\\~no y Memoria\nfrom Instituto Tecnol\\'ogico de Buenos Aires (ITBA), they are studying human\nmemory in the context of face identification. They have a strong hypothesis\nstating that human memory heavily relies in face's frame to recognize faces. If\nthis is proved, it could mean that face recognition in police lineups couldn't\nbe trusted, as they may lead to wrongful convictions. This study uses\nexperiments in order to try to prove this using faces with different\nproperties, such as eyes size, but maintaining its frame as much as possible.\n  In this project, we continue the work from a previous project that provided\nthe basic tool to generate realistic faces using StyleGAN2. We take a deep dive\ninto the internals of this tool to make full use of StyleGAN2 functionalities,\nwhile also adding more features, such as modifying certain of its attributes,\nincluding mouth-opening or eye-opening.\n  As the usage of this tool heavily relies on maintaining the face-frame, we\ndevelop a way to identify the face-frame of each image and a function to\ncompare it to the output of the neural network after applying some operations.\n  We conclude that the face-frame is maintained when modifying eye-opening or\nmouth opening. When modifying vertical face orientation, gender, age and smile,\nhave a considerable impact on its frame variation. And finally, the horizontal\nface orientation shows a major impact on the face-frame. This way, the Lab may\napply some operations being confident that the face-frame won't significantly\nchange, making them viable to be used to deceive subjects' memories.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00803v1",
    "published_date": "2024-06-30 19:10:22 UTC",
    "updated_date": "2024-06-30 19:10:22 UTC"
  },
  {
    "arxiv_id": "2407.00783v1",
    "title": "Diffusion Models and Representation Learning: A Survey",
    "authors": [
      "Michael Fuest",
      "Pingchuan Ma",
      "Ming Gui",
      "Johannes Schusterbauer",
      "Vincent Tao Hu",
      "Bjorn Ommer"
    ],
    "abstract": "Diffusion Models are popular generative modeling methods in various vision\ntasks, attracting significant attention. They can be considered a unique\ninstance of self-supervised learning methods due to their independence from\nlabel annotation. This survey explores the interplay between diffusion models\nand representation learning. It provides an overview of diffusion models'\nessential aspects, including mathematical foundations, popular denoising\nnetwork architectures, and guidance methods. Various approaches related to\ndiffusion models and representation learning are detailed. These include\nframeworks that leverage representations learned from pre-trained diffusion\nmodels for subsequent recognition tasks and methods that utilize advancements\nin representation and self-supervised learning to enhance diffusion models.\nThis survey aims to offer a comprehensive overview of the taxonomy between\ndiffusion models and representation learning, identifying key areas of existing\nconcerns and potential exploration. Github link:\nhttps://github.com/dongzhuoyao/Diffusion-Representation-Learning-Survey-Taxonomy",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Github Repo:\n  https://github.com/dongzhuoyao/Diffusion-Representation-Learning-Survey-Taxonomy",
    "pdf_url": "http://arxiv.org/pdf/2407.00783v1",
    "published_date": "2024-06-30 17:59:58 UTC",
    "updated_date": "2024-06-30 17:59:58 UTC"
  },
  {
    "arxiv_id": "2407.00779v1",
    "title": "Towards Faster Matrix Diagonalization with Graph Isomorphism Networks and the AlphaZero Framework",
    "authors": [
      "Geigh Zollicoffer",
      "Kshitij Bhatta",
      "Manish Bhattarai",
      "Phil Romero",
      "Christian F. A. Negre",
      "Anders M. N. Niklasson",
      "Adetokunbo Adedoyin"
    ],
    "abstract": "In this paper, we introduce innovative approaches for accelerating the Jacobi\nmethod for matrix diagonalization, specifically through the formulation of\nlarge matrix diagonalization as a Semi-Markov Decision Process and small matrix\ndiagonalization as a Markov Decision Process. Furthermore, we examine the\npotential of utilizing scalable architecture between different-sized matrices.\nDuring a short training period, our method discovered a significant reduction\nin the number of steps required for diagonalization and exhibited efficient\ninference capabilities. Importantly, this approach demonstrated possible\nscalability to large-sized matrices, indicating its potential for wide-ranging\napplicability. Upon training completion, we obtain action-state probabilities\nand transition graphs, which depict transitions between different states. These\noutputs not only provide insights into the diagonalization process but also\npave the way for cost savings pertinent to large-scale matrices. The\nadvancements made in this research enhance the efficacy and scalability of\nmatrix diagonalization, pushing for new possibilities for deployment in\npractical applications in scientific and engineering domains.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to Deployable RL: From Research to Practice workshop @ RLC\n  conference",
    "pdf_url": "http://arxiv.org/pdf/2407.00779v1",
    "published_date": "2024-06-30 17:45:01 UTC",
    "updated_date": "2024-06-30 17:45:01 UTC"
  },
  {
    "arxiv_id": "2407.00764v1",
    "title": "Characterizing Stereotypical Bias from Privacy-preserving Pre-Training",
    "authors": [
      "Stefan Arnold",
      "Rene Gröbner",
      "Annika Schreiner"
    ],
    "abstract": "Differential Privacy (DP) can be applied to raw text by exploiting the\nspatial arrangement of words in an embedding space. We investigate the\nimplications of such text privatization on Language Models (LMs) and their\ntendency towards stereotypical associations. Since previous studies documented\nthat linguistic proficiency correlates with stereotypical bias, one could\nassume that techniques for text privatization, which are known to degrade\nlanguage modeling capabilities, would cancel out undesirable biases. By testing\nBERT models trained on texts containing biased statements primed with varying\ndegrees of privacy, our study reveals that while stereotypical bias generally\ndiminishes when privacy is tightened, text privatization does not uniformly\nequate to diminishing bias across all social domains. This highlights the need\nfor careful diagnosis of bias in LMs that undergo text privatization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00764v1",
    "published_date": "2024-06-30 16:54:43 UTC",
    "updated_date": "2024-06-30 16:54:43 UTC"
  },
  {
    "arxiv_id": "2407.13710v2",
    "title": "OxonFair: A Flexible Toolkit for Algorithmic Fairness",
    "authors": [
      "Eoin Delaney",
      "Zihao Fu",
      "Sandra Wachter",
      "Brent Mittelstadt",
      "Chris Russell"
    ],
    "abstract": "We present OxonFair, a new open source toolkit for enforcing fairness in\nbinary classification. Compared to existing toolkits: (i) We support NLP and\nComputer Vision classification as well as standard tabular problems. (ii) We\nsupport enforcing fairness on validation data, making us robust to a wide range\nof overfitting challenges. (iii) Our approach can optimize any measure based on\nTrue Positives, False Positive, False Negatives, and True Negatives. This makes\nit easily extensible and much more expressive than existing toolkits. It\nsupports all 9 and all 10 of the decision-based group metrics of two popular\nreview articles. (iv) We jointly optimize a performance objective alongside\nfairness constraints. This minimizes degradation while enforcing fairness, and\neven improves the performance of inadequately tuned unfair baselines. OxonFair\nis compatible with standard ML toolkits, including sklearn, Autogluon, and\nPyTorch and is available at https://github.com/oxfordinternetinstitute/oxonfair",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13710v2",
    "published_date": "2024-06-30 16:41:28 UTC",
    "updated_date": "2024-11-05 13:59:31 UTC"
  },
  {
    "arxiv_id": "2407.00752v1",
    "title": "Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation",
    "authors": [
      "Peng Huang",
      "Xue Gao",
      "Lihong Huang",
      "Jing Jiao",
      "Xiaokang Li",
      "Yuanyuan Wang",
      "Yi Guo"
    ],
    "abstract": "Text-to-image generation has important implications for generation of diverse\nand controllable images. Several attempts have been made to adapt Stable\nDiffusion (SD) to the medical domain. However, the large distribution\ndifference between medical reports and natural texts, as well as high\ncomputational complexity in common stable diffusion limit the authenticity and\nfeasibility of the generated medical images. To solve above problems, we\npropose a novel light-weight transformer-based diffusion model learning\nframework, Chest-Diffusion, for report-to-CXR generation. Chest-Diffusion\nemploys a domain-specific text encoder to obtain accurate and expressive text\nfeatures to guide image generation, improving the authenticity of the generated\nimages. Meanwhile, we introduce a light-weight transformer architecture as the\ndenoising model, reducing the computational complexity of the diffusion model.\nExperiments demonstrate that our Chest-Diffusion achieves the lowest FID score\n24.456, under the computation budget of 118.918 GFLOPs, which is nearly\none-third of the computational complexity of SD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00752v1",
    "published_date": "2024-06-30 16:19:38 UTC",
    "updated_date": "2024-06-30 16:19:38 UTC"
  },
  {
    "arxiv_id": "2407.00747v1",
    "title": "A Comparative Study of Quality Evaluation Methods for Text Summarization",
    "authors": [
      "Huyen Nguyen",
      "Haihua Chen",
      "Lavanya Pobbathi",
      "Junhua Ding"
    ],
    "abstract": "Evaluating text summarization has been a challenging task in natural language\nprocessing (NLP). Automatic metrics which heavily rely on reference summaries\nare not suitable in many situations, while human evaluation is time-consuming\nand labor-intensive. To bridge this gap, this paper proposes a novel method\nbased on large language models (LLMs) for evaluating text summarization. We\nalso conducts a comparative study on eight automatic metrics, human evaluation,\nand our proposed LLM-based method. Seven different types of state-of-the-art\n(SOTA) summarization models were evaluated. We perform extensive experiments\nand analysis on datasets with patent documents. Our results show that LLMs\nevaluation aligns closely with human evaluation, while widely-used automatic\nmetrics such as ROUGE-2, BERTScore, and SummaC do not and also lack\nconsistency. Based on the empirical comparison, we propose a LLM-powered\nframework for automatically evaluating and improving text summarization, which\nis beneficial and could attract wide attention among the community.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The paper is under review at Empirical Methods in Natural Language\n  Processing (EMNLP) 2024. It has 15 pages and 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00747v1",
    "published_date": "2024-06-30 16:12:37 UTC",
    "updated_date": "2024-06-30 16:12:37 UTC"
  },
  {
    "arxiv_id": "2407.00744v1",
    "title": "Disentangled Representations for Causal Cognition",
    "authors": [
      "Filippo Torresan",
      "Manuel Baltieri"
    ],
    "abstract": "Complex adaptive agents consistently achieve their goals by solving problems\nthat seem to require an understanding of causal information, information\npertaining to the causal relationships that exist among elements of combined\nagent-environment systems. Causal cognition studies and describes the main\ncharacteristics of causal learning and reasoning in human and non-human\nanimals, offering a conceptual framework to discuss cognitive performances\nbased on the level of apparent causal understanding of a task. Despite the use\nof formal intervention-based models of causality, including causal Bayesian\nnetworks, psychological and behavioural research on causal cognition does not\nyet offer a computational account that operationalises how agents acquire a\ncausal understanding of the world. Machine and reinforcement learning research\non causality, especially involving disentanglement as a candidate process to\nbuild causal representations, represent on the one hand a concrete attempt at\ndesigning causal artificial agents that can shed light on the inner workings of\nnatural causal cognition. In this work, we connect these two areas of research\nto build a unifying framework for causal cognition that will offer a\ncomputational perspective on studies of animal cognition, and provide insights\nin the development of new algorithms for causal reinforcement learning in AI.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "49 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00744v1",
    "published_date": "2024-06-30 16:10:17 UTC",
    "updated_date": "2024-06-30 16:10:17 UTC"
  },
  {
    "arxiv_id": "2407.00741v6",
    "title": "Diffusion Models for Offline Multi-agent Reinforcement Learning with Safety Constraints",
    "authors": [
      "Jianuo Huang"
    ],
    "abstract": "In recent advancements in Multi-agent Reinforcement Learning (MARL), its\napplication has extended to various safety-critical scenarios. However, most\nmethods focus on online learning, which presents substantial risks when\ndeployed in real-world settings. Addressing this challenge, we introduce an\ninnovative framework integrating diffusion models within the MARL paradigm.\nThis approach notably enhances the safety of actions taken by multiple agents\nthrough risk mitigation while modeling coordinated action. Our framework is\ngrounded in the Centralized Training with Decentralized Execution (CTDE)\narchitecture, augmented by a Diffusion Model for prediction trajectory\ngeneration. Additionally, we incorporate a specialized algorithm to further\nensure operational safety. We evaluate our model against baselines on the DSRL\nbenchmark. Experiment results demonstrate that our model not only adheres to\nstringent safety constraints but also achieves superior performance compared to\nexisting methodologies. This underscores the potential of our approach in\nadvancing the safety and efficacy of MARL in real-world applications.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "The experiment and method plan are abolished and need to be\n  redesigned",
    "pdf_url": "http://arxiv.org/pdf/2407.00741v6",
    "published_date": "2024-06-30 16:05:31 UTC",
    "updated_date": "2024-09-29 04:24:11 UTC"
  },
  {
    "arxiv_id": "2407.12818v1",
    "title": "\"I understand why I got this grade\": Automatic Short Answer Grading with Feedback",
    "authors": [
      "Dishank Aggarwal",
      "Pushpak Bhattacharyya",
      "Bhaskaran Raman"
    ],
    "abstract": "The demand for efficient and accurate assessment methods has intensified as\neducation systems transition to digital platforms. Providing feedback is\nessential in educational settings and goes beyond simply conveying marks as it\njustifies the assigned marks. In this context, we present a significant\nadvancement in automated grading by introducing Engineering Short Answer\nFeedback (EngSAF) -- a dataset of 5.8k student answers accompanied by reference\nanswers and questions for the Automatic Short Answer Grading (ASAG) task. The\nEngSAF dataset is meticulously curated to cover a diverse range of subjects,\nquestions, and answer patterns from multiple engineering domains. We leverage\nstate-of-the-art large language models' (LLMs) generative capabilities with our\nLabel-Aware Synthetic Feedback Generation (LASFG) strategy to include feedback\nin our dataset. This paper underscores the importance of enhanced feedback in\npractical educational settings, outlines dataset annotation and feedback\ngeneration processes, conducts a thorough EngSAF analysis, and provides\ndifferent LLMs-based zero-shot and finetuned baselines for future comparison.\nAdditionally, we demonstrate the efficiency and effectiveness of the ASAG\nsystem through its deployment in a real-world end-semester exam at the Indian\nInstitute of Technology Bombay (IITB), showcasing its practical viability and\npotential for broader implementation in educational institutions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12818v1",
    "published_date": "2024-06-30 15:42:18 UTC",
    "updated_date": "2024-06-30 15:42:18 UTC"
  },
  {
    "arxiv_id": "2407.00731v2",
    "title": "Large Language Models Struggle in Token-Level Clinical Named Entity Recognition",
    "authors": [
      "Qiuhao Lu",
      "Rui Li",
      "Andrew Wen",
      "Jinlian Wang",
      "Liwei Wang",
      "Hongfang Liu"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized various sectors, including\nhealthcare where they are employed in diverse applications. Their utility is\nparticularly significant in the context of rare diseases, where data scarcity,\ncomplexity, and specificity pose considerable challenges. In the clinical\ndomain, Named Entity Recognition (NER) stands out as an essential task and it\nplays a crucial role in extracting relevant information from clinical texts.\nDespite the promise of LLMs, current research mostly concentrates on\ndocument-level NER, identifying entities in a more general context across\nentire documents, without extracting their precise location. Additionally,\nefforts have been directed towards adapting ChatGPT for token-level NER.\nHowever, there is a significant research gap when it comes to employing\ntoken-level NER for clinical texts, especially with the use of local\nopen-source LLMs. This study aims to bridge this gap by investigating the\neffectiveness of both proprietary and local LLMs in token-level clinical NER.\nEssentially, we delve into the capabilities of these models through a series of\nexperiments involving zero-shot prompting, few-shot prompting,\nretrieval-augmented generation (RAG), and instruction-fine-tuning. Our\nexploration reveals the inherent challenges LLMs face in token-level NER,\nparticularly in the context of rare diseases, and suggests possible\nimprovements for their application in healthcare. This research contributes to\nnarrowing a significant gap in healthcare informatics and offers insights that\ncould lead to a more refined application of LLMs in the healthcare sector.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "AMIA 2024 Annual Symposium Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2407.00731v2",
    "published_date": "2024-06-30 15:38:48 UTC",
    "updated_date": "2024-08-17 00:59:55 UTC"
  },
  {
    "arxiv_id": "2407.00717v2",
    "title": "Learning System Dynamics without Forgetting",
    "authors": [
      "Xikun Zhang",
      "Dongjin Song",
      "Yushan Jiang",
      "Yixin Chen",
      "Dacheng Tao"
    ],
    "abstract": "Observation-based trajectory prediction for systems with unknown dynamics is\nessential in fields such as physics and biology. Most existing approaches are\nlimited to learning within a single system with fixed dynamics patterns.\nHowever, many real-world applications require learning across systems with\nevolving dynamics patterns, a challenge that has been largely overlooked. To\naddress this, we systematically investigate the problem of Continual Dynamics\nLearning (CDL), examining task configurations and evaluating the applicability\nof existing techniques, while identifying key challenges. In response, we\npropose the Mode-switching Graph ODE (MS-GODE) model, which integrates the\nstrengths LG-ODE and sub-network learning with a mode-switching module,\nenabling efficient learning over varying dynamics. Moreover, we construct a\nnovel benchmark of biological dynamic systems for CDL, Bio-CDL, featuring\ndiverse systems with disparate dynamics and significantly enriching the\nresearch field of machine learning for dynamic systems. Our code available at\nhttps://github.com/QueuQ/MS-GODE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00717v2",
    "published_date": "2024-06-30 14:55:18 UTC",
    "updated_date": "2025-02-25 03:14:10 UTC"
  },
  {
    "arxiv_id": "2407.00699v2",
    "title": "Model-based Offline Reinforcement Learning with Lower Expectile Q-Learning",
    "authors": [
      "Kwanyoung Park",
      "Youngwoon Lee"
    ],
    "abstract": "Model-based offline reinforcement learning (RL) is a compelling approach that\naddresses the challenge of learning from limited, static data by generating\nimaginary trajectories using learned models. However, these approaches often\nstruggle with inaccurate value estimation from model rollouts. In this paper,\nwe introduce a novel model-based offline RL method, Lower Expectile Q-learning\n(LEQ), which provides a low-bias model-based value estimation via lower\nexpectile regression of $\\lambda$-returns. Our empirical results show that LEQ\nsignificantly outperforms previous model-based offline RL methods on\nlong-horizon tasks, such as the D4RL AntMaze tasks, matching or surpassing the\nperformance of model-free approaches and sequence modeling approaches.\nFurthermore, LEQ matches the performance of state-of-the-art model-based and\nmodel-free methods in dense-reward environments across both state-based tasks\n(NeoRL and D4RL) and pixel-based tasks (V-D4RL), showing that LEQ works\nrobustly across diverse domains. Our ablation studies demonstrate that lower\nexpectile regression, $\\lambda$-returns, and critic training on offline data\nare all crucial for LEQ.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "https://kwanyoungpark.github.io/LEQ/",
    "pdf_url": "http://arxiv.org/pdf/2407.00699v2",
    "published_date": "2024-06-30 13:44:59 UTC",
    "updated_date": "2024-12-03 03:06:34 UTC"
  },
  {
    "arxiv_id": "2407.00698v1",
    "title": "NourishNet: Proactive Severity State Forecasting of Food Commodity Prices for Global Warning Systems",
    "authors": [
      "Sydney Balboni",
      "Grace Ivey",
      "Brett Storoe",
      "John Cisler",
      "Tyge Plater",
      "Caitlyn Grant",
      "Ella Bruce",
      "Benjamin Paulson"
    ],
    "abstract": "Price volatility in global food commodities is a critical signal indicating\npotential disruptions in the food market. Understanding forthcoming changes in\nthese prices is essential for bolstering food security, particularly for\nnations at risk. The Food and Agriculture Organization of the United Nations\n(FAO) previously developed sophisticated statistical frameworks for the\nproactive prediction of food commodity prices, aiding in the creation of global\nearly warning systems. These frameworks utilize food security indicators to\nproduce accurate forecasts, thereby facilitating preparations against potential\nfood shortages. Our research builds on these foundations by integrating robust\nprice security indicators with cutting-edge deep learning (DL) methodologies to\nreveal complex interdependencies. DL techniques examine intricate dynamics\namong diverse factors affecting food prices. Through sophisticated time-series\nforecasting models coupled with a classification model, our approach enhances\nexisting models to better support communities worldwide in advancing their food\nsecurity initiatives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "econ.GN",
      "math.NA",
      "q-fin.EC"
    ],
    "primary_category": "cs.LG",
    "comment": "MICS 2024 1st Place Paper, MSOE AI-Club Research Group",
    "pdf_url": "http://arxiv.org/pdf/2407.00698v1",
    "published_date": "2024-06-30 13:43:26 UTC",
    "updated_date": "2024-06-30 13:43:26 UTC"
  },
  {
    "arxiv_id": "2407.00697v3",
    "title": "CaFNet: A Confidence-Driven Framework for Radar Camera Depth Estimation",
    "authors": [
      "Huawei Sun",
      "Hao Feng",
      "Julius Ott",
      "Lorenzo Servadei",
      "Robert Wille"
    ],
    "abstract": "Depth estimation is critical in autonomous driving for interpreting 3D scenes\naccurately. Recently, radar-camera depth estimation has become of sufficient\ninterest due to the robustness and low-cost properties of radar. Thus, this\npaper introduces a two-stage, end-to-end trainable Confidence-aware Fusion Net\n(CaFNet) for dense depth estimation, combining RGB imagery with sparse and\nnoisy radar point cloud data. The first stage addresses radar-specific\nchallenges, such as ambiguous elevation and noisy measurements, by predicting a\nradar confidence map and a preliminary coarse depth map. A novel approach is\npresented for generating the ground truth for the confidence map, which\ninvolves associating each radar point with its corresponding object to identify\npotential projection surfaces. These maps, together with the initial radar\ninput, are processed by a second encoder. For the final depth estimation, we\ninnovate a confidence-aware gated fusion mechanism to integrate radar and image\nfeatures effectively, thereby enhancing the reliability of the depth map by\nfiltering out radar noise. Our methodology, evaluated on the nuScenes dataset,\ndemonstrates superior performance, improving upon the current leading model by\n3.2% in Mean Absolute Error (MAE) and 2.7% in Root Mean Square Error (RMSE).\nCode: https://github.com/harborsarah/CaFNet",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IROS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00697v3",
    "published_date": "2024-06-30 13:39:29 UTC",
    "updated_date": "2024-08-30 13:25:50 UTC"
  },
  {
    "arxiv_id": "2407.00695v2",
    "title": "Learning Formal Mathematics From Intrinsic Motivation",
    "authors": [
      "Gabriel Poesia",
      "David Broman",
      "Nick Haber",
      "Noah D. Goodman"
    ],
    "abstract": "How did humanity coax mathematics from the aether? We explore the Platonic\nview that mathematics can be discovered from its axioms - a game of conjecture\nand proof. We describe Minimo (Mathematics from Intrinsic Motivation): an agent\nthat jointly learns to pose challenging problems for itself (conjecturing) and\nsolve them (theorem proving). Given a mathematical domain axiomatized in\ndependent type theory, we first combine methods for constrained decoding and\ntype-directed synthesis to sample valid conjectures from a language model. Our\nmethod guarantees well-formed conjectures by construction, even as we start\nwith a randomly initialized model. We use the same model to represent a policy\nand value function for guiding proof search. Our agent targets generating hard\nbut provable conjectures - a moving target, since its own theorem proving\nability also improves as it trains. We propose novel methods for hindsight\nrelabeling on proof search trees to significantly improve the agent's sample\nefficiency in both tasks. Experiments on 3 axiomatic domains (propositional\nlogic, arithmetic and group theory) demonstrate that our agent can bootstrap\nfrom only the axioms, self-improving in generating true and challenging\nconjectures and in finding proofs.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024 Oral",
    "pdf_url": "http://arxiv.org/pdf/2407.00695v2",
    "published_date": "2024-06-30 13:34:54 UTC",
    "updated_date": "2024-11-05 01:40:45 UTC"
  },
  {
    "arxiv_id": "2407.00693v2",
    "title": "BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization",
    "authors": [
      "Gihun Lee",
      "Minchan Jeong",
      "Yujin Kim",
      "Hojung Jung",
      "Jaehoon Oh",
      "Sangmook Kim",
      "Se-Young Yun"
    ],
    "abstract": "While learning to align Large Language Models (LLMs) with human preferences\nhas shown remarkable success, aligning these models to meet the diverse user\npreferences presents further challenges in preserving previous knowledge. This\npaper examines the impact of personalized preference optimization on LLMs,\nrevealing that the extent of knowledge loss varies significantly with\npreference heterogeneity. Although previous approaches have utilized the KL\nconstraint between the reference model and the policy model, we observe that\nthey fail to maintain general knowledge and alignment when facing personalized\npreferences. To this end, we introduce Base-Anchored Preference Optimization\n(BAPO), a simple yet effective approach that utilizes the initial responses of\nreference model to mitigate forgetting while accommodating personalized\nalignment. BAPO effectively adapts to diverse user preferences while minimally\naffecting global knowledge or general alignment. Our experiments demonstrate\nthe efficacy of BAPO in various setups.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "The 2024 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.00693v2",
    "published_date": "2024-06-30 13:30:04 UTC",
    "updated_date": "2024-09-29 08:50:01 UTC"
  },
  {
    "arxiv_id": "2407.02528v1",
    "title": "Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models",
    "authors": [
      "Romy Fieblinger",
      "Md Tanvirul Alam",
      "Nidhi Rastogi"
    ],
    "abstract": "Cyber threats are constantly evolving. Extracting actionable insights from\nunstructured Cyber Threat Intelligence (CTI) data is essential to guide\ncybersecurity decisions. Increasingly, organizations like Microsoft, Trend\nMicro, and CrowdStrike are using generative AI to facilitate CTI extraction.\nThis paper addresses the challenge of automating the extraction of actionable\nCTI using advancements in Large Language Models (LLMs) and Knowledge Graphs\n(KGs). We explore the application of state-of-the-art open-source LLMs,\nincluding the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting\nmeaningful triples from CTI texts. Our methodology evaluates techniques such as\nprompt engineering, the guidance framework, and fine-tuning to optimize\ninformation extraction and structuring. The extracted data is then utilized to\nconstruct a KG, offering a structured and queryable representation of threat\nintelligence. Experimental results demonstrate the effectiveness of our\napproach in extracting relevant information, with guidance and fine-tuning\nshowing superior performance over prompt engineering. However, while our\nmethods prove effective in small-scale tests, applying LLMs to large-scale data\nfor KG construction and Link Prediction presents ongoing challenges.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "6th Workshop on Attackers and Cyber-Crime Operations, 12 pages, 1\n  figure, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.02528v1",
    "published_date": "2024-06-30 13:02:03 UTC",
    "updated_date": "2024-06-30 13:02:03 UTC"
  },
  {
    "arxiv_id": "2407.00664v2",
    "title": "SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images",
    "authors": [
      "Zekang Yang",
      "Hong Liu",
      "Xiangdong Wang"
    ],
    "abstract": "Cancer survival prediction is a challenging task that involves analyzing of\nthe tumor microenvironment within Whole Slide Image (WSI). Previous methods\ncannot effectively capture the intricate interaction features among instances\nwithin the local area of WSI. Moreover, existing methods for cancer survival\nprediction based on WSI often fail to provide better clinically meaningful\npredictions. To overcome these challenges, we propose a Sparse Context-aware\nMultiple Instance Learning (SCMIL) framework for predicting cancer survival\nprobability distributions. SCMIL innovatively segments patches into various\nclusters based on their morphological features and spatial location\ninformation, subsequently leveraging sparse self-attention to discern the\nrelationships between these patches with a context-aware perspective.\nConsidering many patches are irrelevant to the task, we introduce a learnable\npatch filtering module called SoftFilter, which ensures that only interactions\nbetween task-relevant patches are considered. To enhance the clinical relevance\nof our prediction, we propose a register-based mixture density network to\nforecast the survival probability distribution for individual patients. We\nevaluate SCMIL on two public WSI datasets from the The Cancer Genome Atlas\n(TCGA) specifically focusing on lung adenocarcinom (LUAD) and kidney renal\nclear cell carcinoma (KIRC). Our experimental results indicate that SCMIL\noutperforms current state-of-the-art methods for survival prediction, offering\nmore clinically meaningful and interpretable outcomes. Our code is accessible\nat https://github.com/yang-ze-kang/SCMIL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by MICCAI2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00664v2",
    "published_date": "2024-06-30 11:22:36 UTC",
    "updated_date": "2024-10-22 03:34:43 UTC"
  },
  {
    "arxiv_id": "2407.00662v2",
    "title": "Multi-Agent Training for Pommerman: Curriculum Learning and Population-based Self-Play Approach",
    "authors": [
      "Nhat-Minh Huynh",
      "Hoang-Giang Cao",
      "I-Chen Wu"
    ],
    "abstract": "Pommerman is a multi-agent environment that has received considerable\nattention from researchers in recent years. This environment is an ideal\nbenchmark for multi-agent training, providing a battleground for two teams with\ncommunication capabilities among allied agents. Pommerman presents significant\nchallenges for model-free reinforcement learning due to delayed action effects,\nsparse rewards, and false positives, where opponent players can lose due to\ntheir own mistakes. This study introduces a system designed to train\nmulti-agent systems to play Pommerman using a combination of curriculum\nlearning and population-based self-play. We also tackle two challenging\nproblems when deploying the multi-agent training system for competitive games:\nsparse reward and suitable matchmaking mechanism. Specifically, we propose an\nadaptive annealing factor based on agents' performance to adjust the dense\nexploration reward during training dynamically. Additionally, we implement a\nmatchmaking mechanism utilizing the Elo rating system to pair agents\neffectively. Our experimental results demonstrate that our trained agent can\noutperform top learning agents without requiring communication among allied\nagents.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted at The First Workshop on Game AI Algorithms and Multi-Agent\n  Learning - IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00662v2",
    "published_date": "2024-06-30 11:14:29 UTC",
    "updated_date": "2025-01-08 07:35:31 UTC"
  },
  {
    "arxiv_id": "2407.12032v1",
    "title": "Large Language Models for Behavioral Economics: Internal Validity and Elicitation of Mental Models",
    "authors": [
      "Brian Jabarian"
    ],
    "abstract": "In this article, we explore the transformative potential of integrating\ngenerative AI, particularly Large Language Models (LLMs), into behavioral and\nexperimental economics to enhance internal validity. By leveraging AI tools,\nresearchers can improve adherence to key exclusion restrictions and in\nparticular ensure the internal validity measures of mental models, which often\nrequire human intervention in the incentive mechanism. We present a case study\ndemonstrating how LLMs can enhance experimental design, participant engagement,\nand the validity of measuring mental models.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12032v1",
    "published_date": "2024-06-30 10:58:57 UTC",
    "updated_date": "2024-06-30 10:58:57 UTC"
  },
  {
    "arxiv_id": "2407.01635v7",
    "title": "Commute Graph Neural Networks",
    "authors": [
      "Wei Zhuo",
      "Han Yu",
      "Guang Tan",
      "Xiaoxiao Li"
    ],
    "abstract": "Graph Neural Networks (GNNs) have shown remarkable success in learning from\ngraph-structured data. However, their application to directed graphs (digraphs)\npresents unique challenges, primarily due to the inherent asymmetry in node\nrelationships. Traditional GNNs are adept at capturing unidirectional relations\nbut fall short in encoding the mutual path dependencies between nodes, such as\nasymmetrical shortest paths typically found in digraphs. Recognizing this gap,\nwe introduce Commute Graph Neural Networks (CGNN), an approach that seamlessly\nintegrates node-wise commute time into the message passing scheme. The\ncornerstone of CGNN is an efficient method for computing commute time using a\nnewly formulated digraph Laplacian. Commute time is then integrated into the\nneighborhood aggregation process, with neighbor contributions weighted\naccording to their respective commute time to the central node in each layer.\nIt enables CGNN to directly capture the mutual, asymmetric relationships in\ndigraphs. Extensive experiments on 8 benchmarking datasets confirm the\nsuperiority of CGNN against 13 state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in International Conference on Machine Learning (ICML),\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2407.01635v7",
    "published_date": "2024-06-30 10:53:40 UTC",
    "updated_date": "2025-05-15 05:02:59 UTC"
  },
  {
    "arxiv_id": "2407.00653v1",
    "title": "Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs",
    "authors": [
      "Yifei Zhang",
      "Xintao Wang",
      "Jiaqing Liang",
      "Sirui Xia",
      "Lida Chen",
      "Yanghua Xiao"
    ],
    "abstract": "Large Language Models (LLMs) have exhibited impressive proficiency in various\nnatural language processing (NLP) tasks, which involve increasingly complex\nreasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving\nnew knowledge from existing one.While it has been widely studied in the context\nof knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.\nIn this paper, we introduce Chain-of-Knowledge, a comprehensive framework for\nknowledge reasoning, including methodologies for both dataset construction and\nmodel learning. For dataset construction, we create KnowReason via rule mining\non KGs. For model learning, we observe rule overfitting induced by naive\ntraining. Hence, we enhance CoK with a trial-and-error mechanism that simulates\nthe human process of internal knowledge exploration. We conduct extensive\nexperiments with KnowReason. Our results show the effectiveness of CoK in\nrefining LLMs in not only knowledge reasoning, but also general reasoning\nbenchmarkms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00653v1",
    "published_date": "2024-06-30 10:49:32 UTC",
    "updated_date": "2024-06-30 10:49:32 UTC"
  },
  {
    "arxiv_id": "2407.00641v3",
    "title": "NeuroNAS: Enhancing Efficiency of Neuromorphic In-Memory Computing for Intelligent Mobile Agents through Hardware-Aware Spiking Neural Architecture Search",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Shafique"
    ],
    "abstract": "Intelligent mobile agents (e.g., UGVs and UAVs) typically demand low\npower/energy consumption when solving their machine learning (ML)-based tasks,\nsince they are usually powered by portable batteries with limited capacity. A\npotential solution is employing neuromorphic computing with Spiking Neural\nNetworks (SNNs), which leverages event-based computation to enable ultra-low\npower/energy ML algorithms. To maximize the performance efficiency of SNN\ninference, the In-Memory Computing (IMC)-based hardware accelerators with\nemerging device technologies (e.g., RRAM) can be employed. However, SNN models\nare typically developed without considering constraints from the application\nand the underlying IMC hardware, thereby hindering SNNs from reaching their\nfull potential in performance and efficiency. To address this, we propose\nNeuroNAS, a novel framework for developing energyefficient neuromorphic IMC for\nintelligent mobile agents using hardware-aware spiking neural architecture\nsearch (NAS), i.e., by quickly finding an SNN architecture that offers high\naccuracy under the given constraints (e.g., memory, area, latency, and energy\nconsumption). Its key steps include: optimizing SNN operations to enable\nefficient NAS, employing quantization to minimize the memory footprint,\ndeveloping an SNN architecture that facilitates an effective learning, and\ndevising a systematic hardware-aware search algorithm to meet the constraints.\nCompared to the state-of-the-art techniques, NeuroNAS quickly finds SNN\narchitectures (with 8bit weight precision) that maintain high accuracy by up to\n6.6x search time speed-ups, while achieving up to 92% area savings, 1.2x\nlatency improvements, 84% energy savings across different datasets (i.e.,\nCIFAR-10, CIFAR-100, and TinyImageNet-200); while the state-of-the-art fail to\nmeet all constraints at once.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "9 pages, 14 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.00641v3",
    "published_date": "2024-06-30 09:51:58 UTC",
    "updated_date": "2025-04-18 07:00:39 UTC"
  },
  {
    "arxiv_id": "2407.00631v2",
    "title": "TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets",
    "authors": [
      "Jintai Chen",
      "Yaojun Hu",
      "Yue Wang",
      "Yingzhou Lu",
      "Xu Cao",
      "Miao Lin",
      "Hongxia Xu",
      "Jian Wu",
      "Cao Xiao",
      "Jimeng Sun",
      "Lucas Glass",
      "Kexin Huang",
      "Marinka Zitnik",
      "Tianfan Fu"
    ],
    "abstract": "Clinical trials are pivotal for developing new medical treatments, yet they\ntypically pose some risks such as patient mortality, adverse events, and\nenrollment failure that waste immense efforts spanning over a decade. Applying\nartificial intelligence (AI) to forecast or simulate key events in clinical\ntrials holds great potential for providing insights to guide trial designs.\nHowever, complex data collection and question definition requiring medical\nexpertise and a deep understanding of trial designs have hindered the\ninvolvement of AI thus far. This paper tackles these challenges by presenting a\ncomprehensive suite of meticulously curated AIready datasets covering\nmulti-modal data (e.g., drug molecule, disease code, text,\ncategorical/numerical features) and 8 crucial prediction challenges in clinical\ntrial design, encompassing prediction of trial duration, patient dropout rate,\nserious adverse event, mortality rate, trial approval outcome, trial failure\nreason, drug dose finding, design of eligibility criteria. Furthermore, we\nprovide basic validation methods for each task to ensure the datasets'\nusability and reliability. We anticipate that the availability of such\nopen-access datasets will catalyze the development of advanced AI approaches\nfor clinical trial design, ultimately advancing clinical trial research and\naccelerating medical solution development. The curated dataset, metrics, and\nbasic models are publicly available at\nhttps://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00631v2",
    "published_date": "2024-06-30 09:13:10 UTC",
    "updated_date": "2024-09-03 18:00:29 UTC"
  },
  {
    "arxiv_id": "2407.00626v2",
    "title": "Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with Energy-Based Models",
    "authors": [
      "Sangwoong Yoon",
      "Himchan Hwang",
      "Dohyun Kwon",
      "Yung-Kyun Noh",
      "Frank C. Park"
    ],
    "abstract": "We present a maximum entropy inverse reinforcement learning (IRL) approach\nfor improving the sample quality of diffusion generative models, especially\nwhen the number of generation time steps is small. Similar to how IRL trains a\npolicy based on the reward function learned from expert demonstrations, we\ntrain (or fine-tune) a diffusion model using the log probability density\nestimated from training data. Since we employ an energy-based model (EBM) to\nrepresent the log density, our approach boils down to the joint training of a\ndiffusion model and an EBM. Our IRL formulation, named Diffusion by Maximum\nEntropy IRL (DxMI), is a minimax problem that reaches equilibrium when both\nmodels converge to the data distribution. The entropy maximization plays a key\nrole in DxMI, facilitating the exploration of the diffusion model and ensuring\nthe convergence of the EBM. We also propose Diffusion by Dynamic Programming\n(DxDP), a novel reinforcement learning algorithm for diffusion models, as a\nsubroutine in DxMI. DxDP makes the diffusion model update in DxMI efficient by\ntransforming the original problem into an optimal control formulation where\nvalue functions replace back-propagation in time. Our empirical studies show\nthat diffusion models fine-tuned using DxMI can generate high-quality samples\nin as few as 4 and 10 steps. Additionally, DxMI enables the training of an EBM\nwithout MCMC, stabilizing EBM training dynamics and enhancing anomaly detection\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 Oral Presentation. Code is released at\n  https://github.com/swyoon/Diffusion-by-MaxEntIRL",
    "pdf_url": "http://arxiv.org/pdf/2407.00626v2",
    "published_date": "2024-06-30 08:52:17 UTC",
    "updated_date": "2024-10-31 11:39:25 UTC"
  },
  {
    "arxiv_id": "2407.00617v4",
    "title": "Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning",
    "authors": [
      "Yuheng Zhang",
      "Dian Yu",
      "Baolin Peng",
      "Linfeng Song",
      "Ye Tian",
      "Mingyue Huo",
      "Nan Jiang",
      "Haitao Mi",
      "Dong Yu"
    ],
    "abstract": "Reinforcement Learning with Human Feedback (RLHF) has achieved great success\nin aligning large language models (LLMs) with human preferences. Prevalent RLHF\napproaches are reward-based, following the Bradley-Terry (BT) model assumption,\nwhich may not fully capture the complexity of human preferences. In this paper,\nwe explore RLHF under a general preference framework and approach it from a\ngame-theoretic perspective. Specifically, we formulate the problem as a\ntwo-player game and propose a novel online algorithm, iterative Nash policy\noptimization (INPO). The key idea is to let the policy play against itself via\nno-regret learning, thereby approximating the Nash policy. Unlike previous\nmethods, INPO bypasses the need for estimating the expected win rate for\nindividual responses, which typically incurs high computational or annotation\ncosts. Instead, we introduce a new loss objective that is directly minimized\nover a preference dataset. We provide theoretical analysis for our approach and\ndemonstrate its effectiveness through experiments on various representative\nbenchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 42.6%\nlength-controlled win rate on AlpacaEval 2.0 and a 37.8% win rate on\nArena-Hard, showing substantial improvement over the state-of-the-art online\nRLHF algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00617v4",
    "published_date": "2024-06-30 08:00:34 UTC",
    "updated_date": "2025-03-03 03:41:11 UTC"
  },
  {
    "arxiv_id": "2407.00608v1",
    "title": "Efficient Personalized Text-to-image Generation by Leveraging Textual Subspace",
    "authors": [
      "Shian Du",
      "Xiaotian Cheng",
      "Qi Qian",
      "Henglu Wei",
      "Yi Xu",
      "Xiangyang Ji"
    ],
    "abstract": "Personalized text-to-image generation has attracted unprecedented attention\nin the recent few years due to its unique capability of generating\nhighly-personalized images via using the input concept dataset and novel\ntextual prompt. However, previous methods solely focus on the performance of\nthe reconstruction task, degrading its ability to combine with different\ntextual prompt. Besides, optimizing in the high-dimensional embedding space\nusually leads to unnecessary time-consuming training process and slow\nconvergence. To address these issues, we propose an efficient method to explore\nthe target embedding in a textual subspace, drawing inspiration from the\nself-expressiveness property. Additionally, we propose an efficient selection\nstrategy for determining the basis vectors of the textual subspace. The\nexperimental evaluations demonstrate that the learned embedding can not only\nfaithfully reconstruct input image, but also significantly improves its\nalignment with novel input textual prompt. Furthermore, we observe that\noptimizing in the textual subspace leads to an significant improvement of the\nrobustness to the initial word, relaxing the constraint that requires users to\ninput the most relevant initial word. Our method opens the door to more\nefficient representation learning for personalized text-to-image generation.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00608v1",
    "published_date": "2024-06-30 06:41:21 UTC",
    "updated_date": "2024-06-30 06:41:21 UTC"
  },
  {
    "arxiv_id": "2407.12031v1",
    "title": "Evaluation of Bias Towards Medical Professionals in Large Language Models",
    "authors": [
      "Xi Chen",
      "Yang Xu",
      "MingKe You",
      "Li Wang",
      "WeiZhi Liu",
      "Jian Li"
    ],
    "abstract": "This study evaluates whether large language models (LLMs) exhibit biases\ntowards medical professionals. Fictitious candidate resumes were created to\ncontrol for identity factors while maintaining consistent qualifications. Three\nLLMs (GPT-4, Claude-3-haiku, and Mistral-Large) were tested using a\nstandardized prompt to evaluate resumes for specific residency programs.\nExplicit bias was tested by changing gender and race information, while\nimplicit bias was tested by changing names while hiding race and gender.\nPhysician data from the Association of American Medical Colleges was used to\ncompare with real-world demographics. 900,000 resumes were evaluated. All LLMs\nexhibited significant gender and racial biases across medical specialties.\nGender preferences varied, favoring male candidates in surgery and orthopedics,\nwhile preferring females in dermatology, family medicine, obstetrics and\ngynecology, pediatrics, and psychiatry. Claude-3 and Mistral-Large generally\nfavored Asian candidates, while GPT-4 preferred Black and Hispanic candidates\nin several specialties. Tests revealed strong preferences towards Hispanic\nfemales and Asian males in various specialties. Compared to real-world data,\nLLMs consistently chose higher proportions of female and underrepresented\nracial candidates than their actual representation in the medical workforce.\nGPT-4, Claude-3, and Mistral-Large showed significant gender and racial biases\nwhen evaluating medical professionals for residency selection. These findings\nhighlight the potential for LLMs to perpetuate biases and compromise healthcare\nworkforce diversity if used without proper bias mitigation strategies.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "36 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.12031v1",
    "published_date": "2024-06-30 05:55:55 UTC",
    "updated_date": "2024-06-30 05:55:55 UTC"
  },
  {
    "arxiv_id": "2407.00600v1",
    "title": "GenderBias-\\emph{VL}: Benchmarking Gender Bias in Vision Language Models via Counterfactual Probing",
    "authors": [
      "Yisong Xiao",
      "Aishan Liu",
      "QianJia Cheng",
      "Zhenfei Yin",
      "Siyuan Liang",
      "Jiapeng Li",
      "Jing Shao",
      "Xianglong Liu",
      "Dacheng Tao"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have been widely adopted in various\napplications; however, they exhibit significant gender biases. Existing\nbenchmarks primarily evaluate gender bias at the demographic group level,\nneglecting individual fairness, which emphasizes equal treatment of similar\nindividuals. This research gap limits the detection of discriminatory\nbehaviors, as individual fairness offers a more granular examination of biases\nthat group fairness may overlook. For the first time, this paper introduces the\nGenderBias-\\emph{VL} benchmark to evaluate occupation-related gender bias in\nLVLMs using counterfactual visual questions under individual fairness criteria.\nTo construct this benchmark, we first utilize text-to-image diffusion models to\ngenerate occupation images and their gender counterfactuals. Subsequently, we\ngenerate corresponding textual occupation options by identifying stereotyped\noccupation pairs with high semantic similarity but opposite gender proportions\nin real-world statistics. This method enables the creation of large-scale\nvisual question counterfactuals to expose biases in LVLMs, applicable in both\nmultimodal and unimodal contexts through modifying gender attributes in\nspecific modalities. Overall, our GenderBias-\\emph{VL} benchmark comprises\n34,581 visual question counterfactual pairs, covering 177 occupations. Using\nour benchmark, we extensively evaluate 15 commonly used open-source LVLMs (\\eg,\nLLaVA) and state-of-the-art commercial APIs, including GPT-4o and Gemini-Pro.\nOur findings reveal widespread gender biases in existing LVLMs. Our benchmark\noffers: (1) a comprehensive dataset for occupation-related gender bias\nevaluation; (2) an up-to-date leaderboard on LVLM biases; and (3) a nuanced\nunderstanding of the biases presented by these models. \\footnote{The dataset\nand code are available at the \\href{https://genderbiasvl.github.io/}{website}.}",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00600v1",
    "published_date": "2024-06-30 05:55:15 UTC",
    "updated_date": "2024-06-30 05:55:15 UTC"
  },
  {
    "arxiv_id": "2407.00569v4",
    "title": "Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models",
    "authors": [
      "Weihong Zhong",
      "Xiaocheng Feng",
      "Liang Zhao",
      "Qiming Li",
      "Lei Huang",
      "Yuxuan Gu",
      "Weitao Ma",
      "Yuan Xu",
      "Bing Qin"
    ],
    "abstract": "Though advanced in understanding visual information with human languages,\nLarge Vision-Language Models (LVLMs) still suffer from multimodal\nhallucinations. A natural concern is that during multimodal interaction, the\ngenerated hallucinations could influence the LVLMs' subsequent generation.\nThus, we raise a question: When presented with a query relevant to the\npreviously generated hallucination, will LVLMs be misled and respond\nincorrectly, even though the ground visual information exists? To answer this,\nwe propose a framework called MMHalSnowball to evaluate LVLMs' behaviors when\nencountering generated hallucinations, where LVLMs are required to answer\nspecific visual questions within a curated hallucinatory conversation.\nCrucially, our experiment shows that the performance of open-source LVLMs drops\nby at least $31\\%$, indicating that LVLMs are prone to accept the generated\nhallucinations and make false claims that they would not have supported without\ndistractions. We term this phenomenon Multimodal Hallucination Snowballing. To\nmitigate this, we further propose a training-free method called Residual Visual\nDecoding, where we revise the output distribution of LVLMs with the one derived\nfrom the residual visual input, providing models with direct access to the\nvisual information. Experiments show that our method can mitigate more than\n$24\\%$ of the snowballed multimodal hallucination while maintaining\ncapabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ACL 2024 Main Conference. 21 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00569v4",
    "published_date": "2024-06-30 03:04:11 UTC",
    "updated_date": "2024-08-03 17:52:43 UTC"
  },
  {
    "arxiv_id": "2407.00568v5",
    "title": "Divide And Conquer: Learning Chaotic Dynamical Systems With Multistep Penalty Neural Ordinary Differential Equations",
    "authors": [
      "Dibyajyoti Chakraborty",
      "Seung Whan Chung",
      "Troy Arcomano",
      "Romit Maulik"
    ],
    "abstract": "Forecasting high-dimensional dynamical systems is a fundamental challenge in\nvarious fields, such as geosciences and engineering. Neural Ordinary\nDifferential Equations (NODEs), which combine the power of neural networks and\nnumerical solvers, have emerged as a promising algorithm for forecasting\ncomplex nonlinear dynamical systems. However, classical techniques used for\nNODE training are ineffective for learning chaotic dynamical systems. In this\nwork, we propose a novel NODE-training approach that allows for robust learning\nof chaotic dynamical systems. Our method addresses the challenges of\nnon-convexity and exploding gradients associated with underlying chaotic\ndynamics. Training data trajectories from such systems are split into multiple,\nnon-overlapping time windows. In addition to the deviation from the training\ndata, the optimization loss term further penalizes the discontinuities of the\npredicted trajectory between the time windows. The window size is selected\nbased on the fastest Lyapunov time scale of the system. Multi-step penalty(MP)\nmethod is first demonstrated on Lorenz equation, to illustrate how it improves\nthe loss landscape and thereby accelerates the optimization convergence. MP\nmethod can optimize chaotic systems in a manner similar to least-squares\nshadowing with significantly lower computational costs. Our proposed algorithm,\ndenoted the Multistep Penalty NODE, is applied to chaotic systems such as the\nKuramoto-Sivashinsky equation, the two-dimensional Kolmogorov flow, and ERA5\nreanalysis data for the atmosphere. It is observed that MP-NODE provide viable\nperformance for such chaotic systems, not only for short-term trajectory\npredictions but also for invariant statistics that are hallmarks of the chaotic\nnature of these dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 17 Figures, submitted to Computer Methods in Applied\n  Mechanics and Engineering",
    "pdf_url": "http://arxiv.org/pdf/2407.00568v5",
    "published_date": "2024-06-30 02:50:28 UTC",
    "updated_date": "2024-10-15 17:07:25 UTC"
  },
  {
    "arxiv_id": "2407.00567v1",
    "title": "A Contextual Combinatorial Bandit Approach to Negotiation",
    "authors": [
      "Yexin Li",
      "Zhancun Mu",
      "Siyuan Qi"
    ],
    "abstract": "Learning effective negotiation strategies poses two key challenges: the\nexploration-exploitation dilemma and dealing with large action spaces. However,\nthere is an absence of learning-based approaches that effectively address these\nchallenges in negotiation. This paper introduces a comprehensive formulation to\ntackle various negotiation problems. Our approach leverages contextual\ncombinatorial multi-armed bandits, with the bandits resolving the\nexploration-exploitation dilemma, and the combinatorial nature handles large\naction spaces. Building upon this formulation, we introduce NegUCB, a novel\nmethod that also handles common issues such as partial observations and complex\nreward functions in negotiation. NegUCB is contextual and tailored for\nfull-bandit feedback without constraints on the reward functions. Under mild\nassumptions, it ensures a sub-linear regret upper bound. Experiments conducted\non three negotiation tasks demonstrate the superiority of our approach.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00567v1",
    "published_date": "2024-06-30 02:43:15 UTC",
    "updated_date": "2024-06-30 02:43:15 UTC"
  },
  {
    "arxiv_id": "2407.00553v1",
    "title": "Cooperative Advisory Residual Policies for Congestion Mitigation",
    "authors": [
      "Aamir Hasan",
      "Neeloy Chakraborty",
      "Haonan Chen",
      "Jung-Hoon Cho",
      "Cathy Wu",
      "Katherine Driggs-Campbell"
    ],
    "abstract": "Fleets of autonomous vehicles can mitigate traffic congestion through simple\nactions, thus improving many socioeconomic factors such as commute time and gas\ncosts. However, these approaches are limited in practice as they assume precise\ncontrol over autonomous vehicle fleets, incur extensive installation costs for\na centralized sensor ecosystem, and also fail to account for uncertainty in\ndriver behavior. To this end, we develop a class of learned residual policies\nthat can be used in cooperative advisory systems and only require the use of a\nsingle vehicle with a human driver. Our policies advise drivers to behave in\nways that mitigate traffic congestion while accounting for diverse driver\nbehaviors, particularly drivers' reactions to instructions, to provide an\nimproved user experience. To realize such policies, we introduce an improved\nreward function that explicitly addresses congestion mitigation and driver\nattitudes to advice. We show that our residual policies can be personalized by\nconditioning them on an inferred driver trait that is learned in an\nunsupervised manner with a variational autoencoder. Our policies are trained in\nsimulation with our novel instruction adherence driver model, and evaluated in\nsimulation and through a user study (N=16) to capture the sentiments of human\ndrivers. Our results show that our approaches successfully mitigate congestion\nwhile adapting to different driver behaviors, with up to 20% and 40%\nimprovement as measured by a combination metric of speed and deviations in\nspeed across time over baselines in our simulation tests and user study,\nrespectively. Our user study further shows that our policies are\nhuman-compatible and personalize to drivers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00553v1",
    "published_date": "2024-06-30 01:10:13 UTC",
    "updated_date": "2024-06-30 01:10:13 UTC"
  }
]