{
  "date": "2024-06-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-30 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 38 篇论文，主要聚焦于 AI 和机器学习领域的创新，包括大型语言模型（LLM）的偏见检测、强化学习应用、扩散模型优化，以及医疗和科学计算中的新方法，其中 Timothy Nguyen 的 Transformer 研究和 NeurIPS 相关论文（如第 1、8、10、21 篇）最为令人印象深刻，突显了 AI 安全、模型训练效率和实际应用潜力。\n\n### 重点论文讨论\n我们先聊聊那些重要、话题度高或有知名学者的论文，将相关主题归类讨论，优先突出核心贡献。\n\n**AI 模型与偏见（LLM 和相关优化）**  \n- **理解 Transformer 通过 N-gram 统计（Understanding Transformers via N-gram Statistics）**（作者：Timothy Nguyen）：这篇 NeurIPS 2024 论文探索 Transformer 如何依赖训练数据的 N-gram 统计，提出检测过拟合的方法，并发现 79% 的 LLM 预测可由复杂 N-gram 规则近似，提供了量化模型学习进化的新视角。  \n- **LLM 偏见评估（Characterizing Stereotypical Bias from Privacy-preserving Pre-Training）**（作者：Stefan Arnold 等）：研究显示，差分隐私技术虽降低 LLM 偏见，但并非所有社会领域均有效，强调需要针对性诊断。  \n- **基准测试性别偏见（GenderBias-VL: Benchmarking Gender Bias in Vision Language Models via Counterfactual Probing）**（作者：Yisong Xiao 等）：首次使用逆事实探针评估视觉语言模型的职业性别偏见，发现模型存在广泛偏见，并提供大规模数据集和基准，揭示个体公平问题。  \n- **缓解 LLM 多模态幻觉（Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models）**（作者：Weihong Zhong 等）：ACL 2024 论文指出，LVLM 容易因先前幻觉放大错误，提出无训练方法 Residual Visual Decoding，可减少 24% 的幻觉，增强模型鲁棒性。\n\n**强化学习和决策优化**  \n- **迭代 Nash 策略优化（Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning）**（作者：Yuheng Zhang 等）：NeurIPS 风格论文，通过无后悔学习训练 LLM 以适应多样偏好，避免知识遗忘，并在 AlpacaEval 2.0 上提升 42.6% 的性能，适用于一般强化学习场景。  \n- **从知识图谱学习知识推理（Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs）**（作者：Yifei Zhang 等）：提出 CoK 框架，利用知识图谱规则提升 LLM 推理能力，实验显示在知识推理和一般基准上显著改进。  \n- **模型驱动强化学习（Model-based Offline Reinforcement Learning with Lower Expectile Q-Learning）**（作者：Kwanyoung Park 等）：在 D4RL 基准上，通过低偏差 expectile 回归优化离线强化学习，超越传统方法，在长时序任务中提升性能。  \n- **多代理训练框架（Multi-Agent Training for Pommerman: Curriculum Learning and Population-based Self-Play Approach）**（作者：Nhat-Minh Huynh 等）：IJCAI 2024 论文，结合课程学习和自对弈解决多代理稀疏奖励问题，提升代理性能，适用于竞争性游戏。\n\n**医疗和科学应用**  \n- **快速生成医学图像（Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation）**（作者：Peng Huang 等）：提出轻量级扩散模型 Chest-Diffusion，用于报告到胸部 X 光图像的生成，计算复杂度仅为 Stable Diffusion 的三分之一，FID 分数降至 24.456，提升医学图像真实性。  \n- **LLM 在临床实体识别中的挑战（Large Language Models Struggle in Token-Level Clinical Named Entity Recognition）**（作者：Qiuhao Lu 等）：AMIA 2024 论文，评估 LLM 在稀有疾病的 token 级实体识别中表现差强人意，提出提示和微调策略以改进。  \n- **癌症生存预测（SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images）**（作者：Zekang Yang 等）：MICCAI 2024 论文，通过稀疏注意力机制分析全滑玻图像，预测癌症生存概率分布，提供更临床相关的可解释结果。\n\n其他论文主题多样，但非核心的我们快速掠过：  \n- **扩散模型与表示学习（Diffusion Models and Representation Learning: A Survey）**（作者：Michael Fuest 等）：综述扩散模型在表示学习中的应用，提供 GitHub 资源，但细节较泛。  \n- **图神经网络改进（Commute Graph Neural Networks）**（作者：Wei Zhuo 等）：ICML 2025 论文，通过通勤时间集成提升有向图学习，实验显示性能优于 SOTA 方法。  \n- **食物价格预测（NourishNet: Proactive Severity State Forecasting of Food Commodity Prices for Global Warning Systems）**（作者：Sydney Balboni 等）：使用深度学习预测食物价格波动，支持全球预警系统，但应用性需进一步验证。  \n\n今天的 arXiv 快报到此结束，AI 领域的这些进展为模型安全性和实际应用带来新启发，感兴趣的读者可查阅相关 GitHub 资源深入探索！",
  "papers": [
    {
      "arxiv_id": "2407.12034v2",
      "title": "Understanding Transformers via N-gram Statistics",
      "title_zh": "翻译失败",
      "authors": [
        "Timothy Nguyen"
      ],
      "abstract": "Transformer based large-language models (LLMs) display extreme proficiency\nwith language yet a precise understanding of how they work remains elusive. One\nway of demystifying transformer predictions would be to describe how they\ndepend on their context in terms of simple template functions. This paper takes\na first step in this direction by considering families of functions (i.e.\nrules) formed out of simple N-gram based statistics of the training data. By\nstudying how well these rulesets approximate transformer predictions, we obtain\na variety of novel discoveries: a simple method to detect overfitting during\ntraining without using a holdout set, a quantitative measure of how\ntransformers progress from learning simple to more complex statistical rules\nover the course of training, a model-variance criterion governing when\ntransformer predictions tend to be described by N-gram rules, and insights into\nhow well transformers can be approximated by N-gram rulesets in the limit where\nthese rulesets become increasingly complex. In this latter direction, we find\nthat for 79% and 68% of LLM next-token distributions on TinyStories and\nWikipedia, respectively, their top-1 predictions agree with those provided by\nour N-gram rulesets.",
      "tldr_zh": "这篇论文探讨了通过 N-gram 统计来理解 Transformer 模型的工作机制，旨在用简单模板函数描述其对上下文的依赖。研究者使用基于 N-gram 的规则集来近似 Transformer 的预测，发现了一种无需 holdout set 的方法来检测训练过程中的过拟合。论文还量化了 Transformer 从学习简单到复杂统计规则的进展过程，并引入了模型方差标准来判断何时其预测可由 N-gram 规则描述。在极限情况下，对于 TinyStories 和 Wikipedia 数据集，分别有 79% 和 68% 的 LLM 下一 token 分布的 top-1 预测与 N-gram 规则一致。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024. Datasets and N-gram statistics open-sourced:\n  https://github.com/google-deepmind/transformer_ngrams",
      "pdf_url": "http://arxiv.org/pdf/2407.12034v2",
      "published_date": "2024-06-30 22:18:49 UTC",
      "updated_date": "2024-11-05 10:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:07:05.649259"
    },
    {
      "arxiv_id": "2407.00837v2",
      "title": "Towards Robust Speech Representation Learning for Thousands of Languages",
      "title_zh": "针对数千种语言的鲁棒语音表示学习进展",
      "authors": [
        "William Chen",
        "Wangyou Zhang",
        "Yifan Peng",
        "Xinjian Li",
        "Jinchuan Tian",
        "Jiatong Shi",
        "Xuankai Chang",
        "Soumi Maiti",
        "Karen Livescu",
        "Shinji Watanabe"
      ],
      "abstract": "Self-supervised learning (SSL) has helped extend speech technologies to more\nlanguages by reducing the need for labeled data. However, models are still far\nfrom supporting the world's 7000+ languages. We propose XEUS, a Cross-lingual\nEncoder for Universal Speech, trained on over 1 million hours of data across\n4057 languages, extending the language coverage of SSL models 4-fold. We\ncombine 1 million hours of speech from existing publicly accessible corpora\nwith a newly created corpus of 7400+ hours from 4057 languages, which will be\npublicly released. To handle the diverse conditions of multilingual speech\ndata, we augment the typical SSL masked prediction approach with a novel\ndereverberation objective, increasing robustness. We evaluate XEUS on several\nbenchmarks, and show that it consistently outperforms or achieves comparable\nresults to state-of-the-art (SOTA) SSL models across a variety of tasks. XEUS\nsets a new SOTA on the ML-SUPERB benchmark: it outperforms MMS 1B and w2v-BERT\n2.0 v2 by 0.8% and 4.4% respectively, despite having less parameters or\npre-training data. Checkpoints, code, and data are found in\nhttps://www.wavlab.org/activities/2024/xeus/.",
      "tldr_zh": "该研究提出XEUS（Cross-lingual Encoder for Universal Speech），一个基于自监督学习（SSL）的跨语言语音编码器，旨在扩展语音技术支持全球7000+语言中的数千种。研究团队使用超过100万小时的语音数据（包括新创建的7400+小时语料覆盖4057种语言）进行训练，并引入了dereverberation目标来增强模型对多语言数据的鲁棒性。实验结果显示，XEUS在ML-SUPERB等基准上超越了SOTA模型，如比MMS 1B高0.8%和w2v-BERT 2.0 v2高4.4%，尽管参数或数据更少，从而为更广泛的语言语音表示学习奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated affiliations; 20 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.00837v2",
      "published_date": "2024-06-30 21:40:26 UTC",
      "updated_date": "2024-07-02 17:23:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:07:19.250911"
    },
    {
      "arxiv_id": "2407.01638v2",
      "title": "LASSI: An LLM-based Automated Self-Correcting Pipeline for Translating Parallel Scientific Codes",
      "title_zh": "LASSI：基于 LLM",
      "authors": [
        "Matthew T. Dearing",
        "Yiheng Tao",
        "Xingfu Wu",
        "Zhiling Lan",
        "Valerie Taylor"
      ],
      "abstract": "This paper addresses the problem of providing a novel approach to sourcing\nsignificant training data for LLMs focused on science and engineering. In\nparticular, a crucial challenge is sourcing parallel scientific codes in the\nranges of millions to billions of codes. To tackle this problem, we propose an\nautomated pipeline framework called LASSI, designed to translate between\nparallel programming languages by bootstrapping existing closed- or open-source\nLLMs. LASSI incorporates autonomous enhancement through self-correcting loops\nwhere errors encountered during the compilation and execution of generated code\nare fed back to the LLM through guided prompting for debugging and refactoring.\nWe highlight the bi-directional translation of existing GPU benchmarks between\nOpenMP target offload and CUDA to validate LASSI. The results of evaluating\nLASSI with different application codes across four LLMs demonstrate the\neffectiveness of LASSI for generating executable parallel codes, with 80% of\nOpenMP to CUDA translations and 85% of CUDA to OpenMP translations producing\nthe expected output. We also observe approximately 78% of OpenMP to CUDA\ntranslations and 62% of CUDA to OpenMP translations execute within 10% of or at\na faster runtime than the original benchmark code in the same language.",
      "tldr_zh": "本文提出 LASSI，一种基于 LLM 的自动化自纠正管道，用于翻译并行科学代码，从而为科学和工程领域的 LLM 提供海量训练数据。LASSI 通过引导现有封闭或开源 LLM 进行代码翻译，并采用自纠正循环机制，将编译和执行中的错误反馈给 LLM 进行调试和重构。实验验证了 OpenMP 和 CUDA 之间的双向翻译，其中 80% 的 OpenMP 到 CUDA 翻译和 85% 的 CUDA 到 OpenMP 翻译产生了预期输出，且约 78% 和 62% 的翻译代码执行时间与原代码相当或更快。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages, 1 figure, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.01638v2",
      "published_date": "2024-06-30 19:36:04 UTC",
      "updated_date": "2025-05-04 17:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:07:30.340192"
    },
    {
      "arxiv_id": "2407.00808v1",
      "title": "Exploring a Physics-Informed Decision Transformer for Distribution System Restoration: Methodology and Performance Analysis",
      "title_zh": "探索物理信息指导的决策变换器在配电系统恢复中的应用：方法论和性能分析",
      "authors": [
        "Hong Zhao",
        "Jin Wei-Kocsis",
        "Adel Heidari Akhijahani",
        "Karen L Butler-Purry"
      ],
      "abstract": "Driven by advancements in sensing and computing, deep reinforcement learning\n(DRL)-based methods have demonstrated significant potential in effectively\ntackling distribution system restoration (DSR) challenges under uncertain\noperational scenarios. However, the data-intensive nature of DRL poses\nobstacles in achieving satisfactory DSR solutions for large-scale, complex\ndistribution systems. Inspired by the transformative impact of emerging\nfoundation models, including large language models (LLMs), across various\ndomains, this paper explores an innovative approach harnessing LLMs' powerful\ncomputing capabilities to address scalability challenges inherent in\nconventional DRL methods for solving DSR. To our knowledge, this study\nrepresents the first exploration of foundation models, including LLMs, in\nrevolutionizing conventional DRL applications in power system operations. Our\ncontributions are twofold: 1) introducing a novel LLM-powered Physics-Informed\nDecision Transformer (PIDT) framework that leverages LLMs to transform\nconventional DRL methods for DSR operations, and 2) conducting comparative\nstudies to assess the performance of the proposed LLM-powered PIDT framework at\nits initial development stage for solving DSR problems. While our primary focus\nin this paper is on DSR operations, the proposed PIDT framework can be\ngeneralized to optimize sequential decision-making across various power system\noperations.",
      "tldr_zh": "该研究探讨了深度强化学习 (DRL) 在配电系统恢复 (DSR) 问题中的应用挑战，特别是其数据密集型特性导致的可扩展性问题。作者提出了一种创新的 LLM 驱动的 Physics-Informed Decision Transformer (PIDT) 框架，将大型语言模型 (LLMs) 与传统 DRL 方法相结合，利用 LLMs 的强大计算能力来优化 DSR 操作。研究的主要贡献包括首次将基础模型引入电力系统 DRL 应用，并通过比较研究评估了 PIDT 在初步阶段的性能表现。结果显示，该框架在解决 DSR 问题时表现出色，并可推广到其他电力系统操作中的顺序决策优化。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00808v1",
      "published_date": "2024-06-30 19:27:06 UTC",
      "updated_date": "2024-06-30 19:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:07:40.688068"
    },
    {
      "arxiv_id": "2407.00805v5",
      "title": "Towards shutdownable agents via stochastic choice",
      "title_zh": "翻译失败",
      "authors": [
        "Elliott Thornley",
        "Alexander Roman",
        "Christos Ziakas",
        "Leyton Ho",
        "Louis Thomson"
      ],
      "abstract": "The Incomplete Preferences Proposal (IPP) is an idea for ensuring that\nadvanced artificial agents never resist shutdown. A key part of the IPP is\nusing a novel `Discounted Reward for Same-Length Trajectories (DReST)' reward\nfunction to train agents to (1) pursue goals effectively conditional on each\ntrajectory-length (be `USEFUL'), and (2) choose stochastically between\ndifferent trajectory-lengths (be `NEUTRAL' about trajectory-lengths). In this\npaper, we propose evaluation metrics for USEFULNESS and NEUTRALITY. We use a\nDReST reward function to train simple agents to navigate gridworlds, and we\nfind that these agents learn to be USEFUL and NEUTRAL. Our results thus provide\nsome initial evidence that DReST reward functions could train advanced agents\nto be USEFUL and NEUTRAL. Our theoretical work suggests that these agents would\nbe useful and shutdownable.",
      "tldr_zh": "本论文提出 Incomplete Preferences Proposal (IPP)，一种确保高级人工智能代理不会抵抗关机的机制，其核心是使用新型奖励函数 Discounted Reward for Same-Length Trajectories (DReST)。DReST 训练代理在不同轨迹长度条件下有效地追求目标（USEFUL）和在轨迹长度间随机选择（NEUTRAL），并设计了相应的评估指标。实验通过在网格世界中训练简单代理，结果显示这些代理成功学会了 USEFUL 和 NEUTRAL 行为，为训练高级代理提供初步证据。理论分析表明，这种方法能使代理变得有用且可关机，从而提升人工智能的安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00805v5",
      "published_date": "2024-06-30 19:16:02 UTC",
      "updated_date": "2025-04-01 01:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:07:52.560764"
    },
    {
      "arxiv_id": "2407.00803v1",
      "title": "Controlling Face's Frame generation in StyleGAN's latent space operations: Modifying faces to deceive our memory",
      "title_zh": "翻译失败",
      "authors": [
        "Agustín Roca",
        "Nicolás Ignacio Britos"
      ],
      "abstract": "Innocence Project is a non-profitable organization that works in reducing\nwrongful convictions. In collaboration with Laboratorio de Sue\\~no y Memoria\nfrom Instituto Tecnol\\'ogico de Buenos Aires (ITBA), they are studying human\nmemory in the context of face identification. They have a strong hypothesis\nstating that human memory heavily relies in face's frame to recognize faces. If\nthis is proved, it could mean that face recognition in police lineups couldn't\nbe trusted, as they may lead to wrongful convictions. This study uses\nexperiments in order to try to prove this using faces with different\nproperties, such as eyes size, but maintaining its frame as much as possible.\n  In this project, we continue the work from a previous project that provided\nthe basic tool to generate realistic faces using StyleGAN2. We take a deep dive\ninto the internals of this tool to make full use of StyleGAN2 functionalities,\nwhile also adding more features, such as modifying certain of its attributes,\nincluding mouth-opening or eye-opening.\n  As the usage of this tool heavily relies on maintaining the face-frame, we\ndevelop a way to identify the face-frame of each image and a function to\ncompare it to the output of the neural network after applying some operations.\n  We conclude that the face-frame is maintained when modifying eye-opening or\nmouth opening. When modifying vertical face orientation, gender, age and smile,\nhave a considerable impact on its frame variation. And finally, the horizontal\nface orientation shows a major impact on the face-frame. This way, the Lab may\napply some operations being confident that the face-frame won't significantly\nchange, making them viable to be used to deceive subjects' memories.",
      "tldr_zh": "本研究探讨了使用 StyleGAN2 的潜在空间操作来修改面部图像，从而欺骗人类记忆，焦点在于保持 face's frame 的不变性，以验证人类记忆对面部框架的依赖性，这可能质疑警察识别中的可靠性。研究扩展了之前的工具，通过深入 StyleGAN2 的内部功能，添加了修改面部属性（如眼睛张开和嘴巴张开）的特性，并开发了 face's frame 识别和比较函数。实验结果表明，修改眼睛张开或嘴巴张开时，face's frame 基本保持不变，而修改垂直面部方向、性别、年龄和微笑时会产生显著影响，水平面部方向的修改影响最大。这些发现为后续实验提供可靠方法，支持进一步研究记忆欺骗的应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00803v1",
      "published_date": "2024-06-30 19:10:22 UTC",
      "updated_date": "2024-06-30 19:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:08:07.094903"
    },
    {
      "arxiv_id": "2407.00783v1",
      "title": "Diffusion Models and Representation Learning: A Survey",
      "title_zh": "扩散模型与表示学习：",
      "authors": [
        "Michael Fuest",
        "Pingchuan Ma",
        "Ming Gui",
        "Johannes Schusterbauer",
        "Vincent Tao Hu",
        "Bjorn Ommer"
      ],
      "abstract": "Diffusion Models are popular generative modeling methods in various vision\ntasks, attracting significant attention. They can be considered a unique\ninstance of self-supervised learning methods due to their independence from\nlabel annotation. This survey explores the interplay between diffusion models\nand representation learning. It provides an overview of diffusion models'\nessential aspects, including mathematical foundations, popular denoising\nnetwork architectures, and guidance methods. Various approaches related to\ndiffusion models and representation learning are detailed. These include\nframeworks that leverage representations learned from pre-trained diffusion\nmodels for subsequent recognition tasks and methods that utilize advancements\nin representation and self-supervised learning to enhance diffusion models.\nThis survey aims to offer a comprehensive overview of the taxonomy between\ndiffusion models and representation learning, identifying key areas of existing\nconcerns and potential exploration. Github link:\nhttps://github.com/dongzhuoyao/Diffusion-Representation-Learning-Survey-Taxonomy",
      "tldr_zh": "这篇调查论文探讨了Diffusion Models在表示学习（Representation Learning）中的作用，强调它们作为自监督学习（Self-Supervised Learning）方法的一种独特形式。论文概述了Diffusion Models的核心元素，包括数学基础、流行的去噪网络架构（Denoising Network Architectures）和指导方法（Guidance Methods），并详细介绍了相关框架，如利用预训练Diffusion Models学得的表示进行识别任务，以及通过表示学习进展提升Diffusion Models的表现。最终，该调查提供了Diffusion Models与Representation Learning之间的全面分类taxonomy，识别了现有挑战和未来探索方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Github Repo:\n  https://github.com/dongzhuoyao/Diffusion-Representation-Learning-Survey-Taxonomy",
      "pdf_url": "http://arxiv.org/pdf/2407.00783v1",
      "published_date": "2024-06-30 17:59:58 UTC",
      "updated_date": "2024-06-30 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:08:16.247760"
    },
    {
      "arxiv_id": "2407.00779v1",
      "title": "Towards Faster Matrix Diagonalization with Graph Isomorphism Networks and the AlphaZero Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Geigh Zollicoffer",
        "Kshitij Bhatta",
        "Manish Bhattarai",
        "Phil Romero",
        "Christian F. A. Negre",
        "Anders M. N. Niklasson",
        "Adetokunbo Adedoyin"
      ],
      "abstract": "In this paper, we introduce innovative approaches for accelerating the Jacobi\nmethod for matrix diagonalization, specifically through the formulation of\nlarge matrix diagonalization as a Semi-Markov Decision Process and small matrix\ndiagonalization as a Markov Decision Process. Furthermore, we examine the\npotential of utilizing scalable architecture between different-sized matrices.\nDuring a short training period, our method discovered a significant reduction\nin the number of steps required for diagonalization and exhibited efficient\ninference capabilities. Importantly, this approach demonstrated possible\nscalability to large-sized matrices, indicating its potential for wide-ranging\napplicability. Upon training completion, we obtain action-state probabilities\nand transition graphs, which depict transitions between different states. These\noutputs not only provide insights into the diagonalization process but also\npave the way for cost savings pertinent to large-scale matrices. The\nadvancements made in this research enhance the efficacy and scalability of\nmatrix diagonalization, pushing for new possibilities for deployment in\npractical applications in scientific and engineering domains.",
      "tldr_zh": "本研究提出了一种创新方法，使用 Graph Isomorphism Networks 和 AlphaZero Framework 加速 Jacobi method 的矩阵对角化过程，将大矩阵对角化表述为 Semi-Markov Decision Process (SMDP)，小矩阵表述为 Markov Decision Process (MDP)，并探讨不同矩阵规模之间的可扩展架构。训练结果显示，该方法在短时间内显著减少了对角化所需的步骤，并展示了高效的推理能力及对大型矩阵的潜在扩展性。最终，研究生成了行动-状态概率和转移图，不仅为矩阵对角化过程提供洞见，还为大矩阵应用带来成本节省，并为科学和工程领域的实际部署开辟新可能性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to Deployable RL: From Research to Practice workshop @ RLC\n  conference",
      "pdf_url": "http://arxiv.org/pdf/2407.00779v1",
      "published_date": "2024-06-30 17:45:01 UTC",
      "updated_date": "2024-06-30 17:45:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:08:28.557735"
    },
    {
      "arxiv_id": "2407.00764v1",
      "title": "Characterizing Stereotypical Bias from Privacy-preserving Pre-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Arnold",
        "Rene Gröbner",
        "Annika Schreiner"
      ],
      "abstract": "Differential Privacy (DP) can be applied to raw text by exploiting the\nspatial arrangement of words in an embedding space. We investigate the\nimplications of such text privatization on Language Models (LMs) and their\ntendency towards stereotypical associations. Since previous studies documented\nthat linguistic proficiency correlates with stereotypical bias, one could\nassume that techniques for text privatization, which are known to degrade\nlanguage modeling capabilities, would cancel out undesirable biases. By testing\nBERT models trained on texts containing biased statements primed with varying\ndegrees of privacy, our study reveals that while stereotypical bias generally\ndiminishes when privacy is tightened, text privatization does not uniformly\nequate to diminishing bias across all social domains. This highlights the need\nfor careful diagnosis of bias in LMs that undergo text privatization.",
      "tldr_zh": "本研究探讨了差分隐私（Differential Privacy, DP）应用于原始文本时，对语言模型（Language Models, LMs）刻板偏见（stereotypical bias）的影响，特别是在预训练阶段。研究者通过在包含偏见语句的文本上训练BERT模型，并应用不同隐私程度的DP，测试了隐私机制对偏见的削弱效果。结果显示，虽然加强隐私通常会降低刻板偏见，但这种减少在不同社会领域并不均匀，强调了需要对经过文本私有化的LMs进行仔细的偏见诊断。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00764v1",
      "published_date": "2024-06-30 16:54:43 UTC",
      "updated_date": "2024-06-30 16:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:08:39.772678"
    },
    {
      "arxiv_id": "2407.13710v2",
      "title": "OxonFair: A Flexible Toolkit for Algorithmic Fairness",
      "title_zh": "翻译失败",
      "authors": [
        "Eoin Delaney",
        "Zihao Fu",
        "Sandra Wachter",
        "Brent Mittelstadt",
        "Chris Russell"
      ],
      "abstract": "We present OxonFair, a new open source toolkit for enforcing fairness in\nbinary classification. Compared to existing toolkits: (i) We support NLP and\nComputer Vision classification as well as standard tabular problems. (ii) We\nsupport enforcing fairness on validation data, making us robust to a wide range\nof overfitting challenges. (iii) Our approach can optimize any measure based on\nTrue Positives, False Positive, False Negatives, and True Negatives. This makes\nit easily extensible and much more expressive than existing toolkits. It\nsupports all 9 and all 10 of the decision-based group metrics of two popular\nreview articles. (iv) We jointly optimize a performance objective alongside\nfairness constraints. This minimizes degradation while enforcing fairness, and\neven improves the performance of inadequately tuned unfair baselines. OxonFair\nis compatible with standard ML toolkits, including sklearn, Autogluon, and\nPyTorch and is available at https://github.com/oxfordinternetinstitute/oxonfair",
      "tldr_zh": "本研究介绍了 OxonFair，一个灵活的开源工具包，用于在二元 classification 中强制执行算法公平性。OxonFair 支持 NLP、Computer Vision 和标准表格问题，并在验证数据上强制公平性，以应对过拟合挑战；它能优化基于 True Positives、False Positives、False Negatives 和 True Negatives 的任何度量，支持所有相关决策-based group metrics。工具包通过联合优化性能目标和公平性约束，减少性能退化，甚至提升未调优基线的表现，并兼容 sklearn、Autogluon 和 PyTorch，可从 GitHub 获取。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13710v2",
      "published_date": "2024-06-30 16:41:28 UTC",
      "updated_date": "2024-11-05 13:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:08:55.928156"
    },
    {
      "arxiv_id": "2407.00752v1",
      "title": "Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Huang",
        "Xue Gao",
        "Lihong Huang",
        "Jing Jiao",
        "Xiaokang Li",
        "Yuanyuan Wang",
        "Yi Guo"
      ],
      "abstract": "Text-to-image generation has important implications for generation of diverse\nand controllable images. Several attempts have been made to adapt Stable\nDiffusion (SD) to the medical domain. However, the large distribution\ndifference between medical reports and natural texts, as well as high\ncomputational complexity in common stable diffusion limit the authenticity and\nfeasibility of the generated medical images. To solve above problems, we\npropose a novel light-weight transformer-based diffusion model learning\nframework, Chest-Diffusion, for report-to-CXR generation. Chest-Diffusion\nemploys a domain-specific text encoder to obtain accurate and expressive text\nfeatures to guide image generation, improving the authenticity of the generated\nimages. Meanwhile, we introduce a light-weight transformer architecture as the\ndenoising model, reducing the computational complexity of the diffusion model.\nExperiments demonstrate that our Chest-Diffusion achieves the lowest FID score\n24.456, under the computation budget of 118.918 GFLOPs, which is nearly\none-third of the computational complexity of SD.",
      "tldr_zh": "本文提出 Chest-Diffusion，一种轻量级的 Transformer-based diffusion model，用于从医疗报告生成 CXR（胸部 X 光图像），以解决 Stable Diffusion (SD) 在医疗领域面临的文本分布差异和高计算复杂度问题。该模型采用 domain-specific text encoder 来提取准确的文本特征，指导图像生成并提升真实性，同时引入轻量级 Transformer 架构作为去噪模型，显著降低计算需求。实验结果显示，Chest-Diffusion 达到了最低 FID score 24.456，且在 118.918 GFLOPs 的计算预算下，其复杂度仅为 SD 的三分之一。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00752v1",
      "published_date": "2024-06-30 16:19:38 UTC",
      "updated_date": "2024-06-30 16:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:09:08.898643"
    },
    {
      "arxiv_id": "2407.00747v1",
      "title": "A Comparative Study of Quality Evaluation Methods for Text Summarization",
      "title_zh": "文本摘要质量评估方法的比较研究",
      "authors": [
        "Huyen Nguyen",
        "Haihua Chen",
        "Lavanya Pobbathi",
        "Junhua Ding"
      ],
      "abstract": "Evaluating text summarization has been a challenging task in natural language\nprocessing (NLP). Automatic metrics which heavily rely on reference summaries\nare not suitable in many situations, while human evaluation is time-consuming\nand labor-intensive. To bridge this gap, this paper proposes a novel method\nbased on large language models (LLMs) for evaluating text summarization. We\nalso conducts a comparative study on eight automatic metrics, human evaluation,\nand our proposed LLM-based method. Seven different types of state-of-the-art\n(SOTA) summarization models were evaluated. We perform extensive experiments\nand analysis on datasets with patent documents. Our results show that LLMs\nevaluation aligns closely with human evaluation, while widely-used automatic\nmetrics such as ROUGE-2, BERTScore, and SummaC do not and also lack\nconsistency. Based on the empirical comparison, we propose a LLM-powered\nframework for automatically evaluating and improving text summarization, which\nis beneficial and could attract wide attention among the community.",
      "tldr_zh": "这篇论文比较了文本摘要质量评估方法，探讨了自动指标（如依赖参考摘要的ROUGE-2、BERTScore和SummaC）与人工评估的局限性，后者耗时费力。研究提出了一种基于大型语言模型(LLMs)的创新评估方法，并对八种自动指标、人工评估和该方法进行了对比实验，使用七种最先进(SOTA)摘要模型和专利文档数据集。结果显示，LLMs评估与人工评估高度一致，而传统自动指标缺乏一致性。最终，论文提出一个LLM-powered框架，用于自动评估和改进文本摘要，有望在社区中广泛应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The paper is under review at Empirical Methods in Natural Language\n  Processing (EMNLP) 2024. It has 15 pages and 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00747v1",
      "published_date": "2024-06-30 16:12:37 UTC",
      "updated_date": "2024-06-30 16:12:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:09:20.274752"
    },
    {
      "arxiv_id": "2407.00744v1",
      "title": "Disentangled Representations for Causal Cognition",
      "title_zh": "因果认知的解耦表示",
      "authors": [
        "Filippo Torresan",
        "Manuel Baltieri"
      ],
      "abstract": "Complex adaptive agents consistently achieve their goals by solving problems\nthat seem to require an understanding of causal information, information\npertaining to the causal relationships that exist among elements of combined\nagent-environment systems. Causal cognition studies and describes the main\ncharacteristics of causal learning and reasoning in human and non-human\nanimals, offering a conceptual framework to discuss cognitive performances\nbased on the level of apparent causal understanding of a task. Despite the use\nof formal intervention-based models of causality, including causal Bayesian\nnetworks, psychological and behavioural research on causal cognition does not\nyet offer a computational account that operationalises how agents acquire a\ncausal understanding of the world. Machine and reinforcement learning research\non causality, especially involving disentanglement as a candidate process to\nbuild causal representations, represent on the one hand a concrete attempt at\ndesigning causal artificial agents that can shed light on the inner workings of\nnatural causal cognition. In this work, we connect these two areas of research\nto build a unifying framework for causal cognition that will offer a\ncomputational perspective on studies of animal cognition, and provide insights\nin the development of new algorithms for causal reinforcement learning in AI.",
      "tldr_zh": "本论文探讨了复杂适应代理如何通过理解因果信息（如因果关系）来实现目标，并审视了因果认知在人类和动物中的学习与推理特征。作者指出，现有的心理和行为研究虽使用正式的干预模型（如 causal Bayesian networks），但缺乏计算框架来操作化代理的因果理解。论文通过将因果认知研究与机器学习相结合，特别是利用 disentangled representations 作为构建因果表示的关键过程，提出一个统一框架，以提供计算视角分析动物认知，并推动 AI 中的因果 reinforcement learning 算法开发。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "49 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00744v1",
      "published_date": "2024-06-30 16:10:17 UTC",
      "updated_date": "2024-06-30 16:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:09:31.867039"
    },
    {
      "arxiv_id": "2407.00741v6",
      "title": "Diffusion Models for Offline Multi-agent Reinforcement Learning with Safety Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Jianuo Huang"
      ],
      "abstract": "In recent advancements in Multi-agent Reinforcement Learning (MARL), its\napplication has extended to various safety-critical scenarios. However, most\nmethods focus on online learning, which presents substantial risks when\ndeployed in real-world settings. Addressing this challenge, we introduce an\ninnovative framework integrating diffusion models within the MARL paradigm.\nThis approach notably enhances the safety of actions taken by multiple agents\nthrough risk mitigation while modeling coordinated action. Our framework is\ngrounded in the Centralized Training with Decentralized Execution (CTDE)\narchitecture, augmented by a Diffusion Model for prediction trajectory\ngeneration. Additionally, we incorporate a specialized algorithm to further\nensure operational safety. We evaluate our model against baselines on the DSRL\nbenchmark. Experiment results demonstrate that our model not only adheres to\nstringent safety constraints but also achieves superior performance compared to\nexisting methodologies. This underscores the potential of our approach in\nadvancing the safety and efficacy of MARL in real-world applications.",
      "tldr_zh": "这篇论文提出了一种创新框架，将Diffusion Models整合到离线多智能体强化学习(MARL)中，以解决在线学习在安全关键场景中的风险问题。该框架基于Centralized Training with Decentralized Execution (CTDE)架构，使用Diffusion Model生成预测轨迹，并引入专用算法来增强代理行动的安全性和协调性。在DSRL基准测试中，该方法不仅严格遵守安全约束，还比基线模型表现出显著优越性能，展示了其在真实世界应用中的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "The experiment and method plan are abolished and need to be\n  redesigned",
      "pdf_url": "http://arxiv.org/pdf/2407.00741v6",
      "published_date": "2024-06-30 16:05:31 UTC",
      "updated_date": "2024-09-29 04:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:09:43.990541"
    },
    {
      "arxiv_id": "2407.12818v1",
      "title": "\"I understand why I got this grade\": Automatic Short Answer Grading with Feedback",
      "title_zh": "“我理解为什么我得到这个成绩”",
      "authors": [
        "Dishank Aggarwal",
        "Pushpak Bhattacharyya",
        "Bhaskaran Raman"
      ],
      "abstract": "The demand for efficient and accurate assessment methods has intensified as\neducation systems transition to digital platforms. Providing feedback is\nessential in educational settings and goes beyond simply conveying marks as it\njustifies the assigned marks. In this context, we present a significant\nadvancement in automated grading by introducing Engineering Short Answer\nFeedback (EngSAF) -- a dataset of 5.8k student answers accompanied by reference\nanswers and questions for the Automatic Short Answer Grading (ASAG) task. The\nEngSAF dataset is meticulously curated to cover a diverse range of subjects,\nquestions, and answer patterns from multiple engineering domains. We leverage\nstate-of-the-art large language models' (LLMs) generative capabilities with our\nLabel-Aware Synthetic Feedback Generation (LASFG) strategy to include feedback\nin our dataset. This paper underscores the importance of enhanced feedback in\npractical educational settings, outlines dataset annotation and feedback\ngeneration processes, conducts a thorough EngSAF analysis, and provides\ndifferent LLMs-based zero-shot and finetuned baselines for future comparison.\nAdditionally, we demonstrate the efficiency and effectiveness of the ASAG\nsystem through its deployment in a real-world end-semester exam at the Indian\nInstitute of Technology Bombay (IITB), showcasing its practical viability and\npotential for broader implementation in educational institutions.",
      "tldr_zh": "这篇论文介绍了EngSAF数据集，包含5.8k个工程领域学生答案、参考答案和问题，用于Automatic Short Answer Grading (ASAG)任务，并强调反馈在教育中的重要性。该数据集通过Label-Aware Synthetic Feedback Generation (LASFG)策略结合大型语言模型(LLMs)的生成能力，实现了反馈的合成生成，覆盖多样主题和答案模式。论文详细描述了数据集的注释过程、分析方法，并提供了基于LLMs的零样本和微调基线模型；此外，在印度理工学院孟买分校(IITB)的实际考试中部署ASAG系统，证明了其高效性和实用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12818v1",
      "published_date": "2024-06-30 15:42:18 UTC",
      "updated_date": "2024-06-30 15:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:09:57.111159"
    },
    {
      "arxiv_id": "2407.00731v2",
      "title": "Large Language Models Struggle in Token-Level Clinical Named Entity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Qiuhao Lu",
        "Rui Li",
        "Andrew Wen",
        "Jinlian Wang",
        "Liwei Wang",
        "Hongfang Liu"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized various sectors, including\nhealthcare where they are employed in diverse applications. Their utility is\nparticularly significant in the context of rare diseases, where data scarcity,\ncomplexity, and specificity pose considerable challenges. In the clinical\ndomain, Named Entity Recognition (NER) stands out as an essential task and it\nplays a crucial role in extracting relevant information from clinical texts.\nDespite the promise of LLMs, current research mostly concentrates on\ndocument-level NER, identifying entities in a more general context across\nentire documents, without extracting their precise location. Additionally,\nefforts have been directed towards adapting ChatGPT for token-level NER.\nHowever, there is a significant research gap when it comes to employing\ntoken-level NER for clinical texts, especially with the use of local\nopen-source LLMs. This study aims to bridge this gap by investigating the\neffectiveness of both proprietary and local LLMs in token-level clinical NER.\nEssentially, we delve into the capabilities of these models through a series of\nexperiments involving zero-shot prompting, few-shot prompting,\nretrieval-augmented generation (RAG), and instruction-fine-tuning. Our\nexploration reveals the inherent challenges LLMs face in token-level NER,\nparticularly in the context of rare diseases, and suggests possible\nimprovements for their application in healthcare. This research contributes to\nnarrowing a significant gap in healthcare informatics and offers insights that\ncould lead to a more refined application of LLMs in the healthcare sector.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs)在token-level临床Named Entity Recognition (NER)中的表现问题，特别是在处理稀有疾病的临床文本时面临的挑战。研究通过零-shot prompting、few-shot prompting、retrieval-augmented generation (RAG)以及instruction-fine-tuning等方法，对专有和开源LLMs进行了实验评估。结果显示，LLMs在精确识别实体位置方面存在显著困难，尤其在数据稀缺的医疗场景中。该研究填补了token-level临床NER研究的空白，并为提升LLMs在医疗领域的应用提供了改进建议。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "AMIA 2024 Annual Symposium Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2407.00731v2",
      "published_date": "2024-06-30 15:38:48 UTC",
      "updated_date": "2024-08-17 00:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:10:08.475859"
    },
    {
      "arxiv_id": "2407.00717v2",
      "title": "Learning System Dynamics without Forgetting",
      "title_zh": "翻译失败",
      "authors": [
        "Xikun Zhang",
        "Dongjin Song",
        "Yushan Jiang",
        "Yixin Chen",
        "Dacheng Tao"
      ],
      "abstract": "Observation-based trajectory prediction for systems with unknown dynamics is\nessential in fields such as physics and biology. Most existing approaches are\nlimited to learning within a single system with fixed dynamics patterns.\nHowever, many real-world applications require learning across systems with\nevolving dynamics patterns, a challenge that has been largely overlooked. To\naddress this, we systematically investigate the problem of Continual Dynamics\nLearning (CDL), examining task configurations and evaluating the applicability\nof existing techniques, while identifying key challenges. In response, we\npropose the Mode-switching Graph ODE (MS-GODE) model, which integrates the\nstrengths LG-ODE and sub-network learning with a mode-switching module,\nenabling efficient learning over varying dynamics. Moreover, we construct a\nnovel benchmark of biological dynamic systems for CDL, Bio-CDL, featuring\ndiverse systems with disparate dynamics and significantly enriching the\nresearch field of machine learning for dynamic systems. Our code available at\nhttps://github.com/QueuQ/MS-GODE.",
      "tldr_zh": "该论文探讨了Continual Dynamics Learning (CDL)，旨在解决现有轨迹预测方法在处理未知动态系统的持续学习问题，尤其是在物理和生物领域中跨系统动态模式演变的挑战。作者提出Mode-switching Graph ODE (MS-GODE)模型，通过整合LG-ODE和子网络学习以及模式切换模块，实现对变化动态的高效学习，同时避免遗忘问题。为此，他们构建了新的基准Bio-CDL，包含多样化的生物动态系统，以丰富机器学习在动态系统研究中的应用。实验和代码资源进一步支持了该框架的可行性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00717v2",
      "published_date": "2024-06-30 14:55:18 UTC",
      "updated_date": "2025-02-25 03:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:10:19.677871"
    },
    {
      "arxiv_id": "2407.00699v2",
      "title": "Model-based Offline Reinforcement Learning with Lower Expectile Q-Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kwanyoung Park",
        "Youngwoon Lee"
      ],
      "abstract": "Model-based offline reinforcement learning (RL) is a compelling approach that\naddresses the challenge of learning from limited, static data by generating\nimaginary trajectories using learned models. However, these approaches often\nstruggle with inaccurate value estimation from model rollouts. In this paper,\nwe introduce a novel model-based offline RL method, Lower Expectile Q-learning\n(LEQ), which provides a low-bias model-based value estimation via lower\nexpectile regression of $\\lambda$-returns. Our empirical results show that LEQ\nsignificantly outperforms previous model-based offline RL methods on\nlong-horizon tasks, such as the D4RL AntMaze tasks, matching or surpassing the\nperformance of model-free approaches and sequence modeling approaches.\nFurthermore, LEQ matches the performance of state-of-the-art model-based and\nmodel-free methods in dense-reward environments across both state-based tasks\n(NeoRL and D4RL) and pixel-based tasks (V-D4RL), showing that LEQ works\nrobustly across diverse domains. Our ablation studies demonstrate that lower\nexpectile regression, $\\lambda$-returns, and critic training on offline data\nare all crucial for LEQ.",
      "tldr_zh": "这篇论文提出了一种新型模型-based 离线强化学习方法，名为 Lower Expectile Q-learning (LEQ)，通过 lower expectile regression of λ-returns 来降低模型回滚中的价值估计偏差，从而从有限静态数据中生成更准确的虚构轨迹。LEQ 在长horizon 任务如 D4RL AntMaze 上显著优于现有模型-based 方法，并达到或超过无模型方法和序列建模方法的性能。实验还显示，LEQ 在密集奖励环境中的状态-based 任务（NeoRL 和 D4RL）和像素-based 任务（V-D4RL）上，与最先进方法匹敌，证明其在多样领域中的鲁棒性。消融研究进一步证实，lower expectile regression、λ-returns 和在离线数据上训练 critic 是 LEQ 成功的关键因素。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://kwanyoungpark.github.io/LEQ/",
      "pdf_url": "http://arxiv.org/pdf/2407.00699v2",
      "published_date": "2024-06-30 13:44:59 UTC",
      "updated_date": "2024-12-03 03:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:10:34.893056"
    },
    {
      "arxiv_id": "2407.00698v1",
      "title": "NourishNet: Proactive Severity State Forecasting of Food Commodity Prices for Global Warning Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sydney Balboni",
        "Grace Ivey",
        "Brett Storoe",
        "John Cisler",
        "Tyge Plater",
        "Caitlyn Grant",
        "Ella Bruce",
        "Benjamin Paulson"
      ],
      "abstract": "Price volatility in global food commodities is a critical signal indicating\npotential disruptions in the food market. Understanding forthcoming changes in\nthese prices is essential for bolstering food security, particularly for\nnations at risk. The Food and Agriculture Organization of the United Nations\n(FAO) previously developed sophisticated statistical frameworks for the\nproactive prediction of food commodity prices, aiding in the creation of global\nearly warning systems. These frameworks utilize food security indicators to\nproduce accurate forecasts, thereby facilitating preparations against potential\nfood shortages. Our research builds on these foundations by integrating robust\nprice security indicators with cutting-edge deep learning (DL) methodologies to\nreveal complex interdependencies. DL techniques examine intricate dynamics\namong diverse factors affecting food prices. Through sophisticated time-series\nforecasting models coupled with a classification model, our approach enhances\nexisting models to better support communities worldwide in advancing their food\nsecurity initiatives.",
      "tldr_zh": "该研究提出 NourishNet 框架，用于主动预测全球食品商品价格的严重状态波动，以支持全球预警系统。NourishNet 构建于联合国粮农组织（FAO）的统计框架基础上，整合稳健的价格安全指标与先进的深度学习（DL）方法，分析影响食品价格的复杂相互依赖性和动态因素。利用时序预测模型结合分类模型，该方法提升了价格预测的准确性，帮助风险国家及全球社区更好地防范潜在食物短缺和推进食品安全举措。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "econ.GN",
        "math.NA",
        "q-fin.EC"
      ],
      "primary_category": "cs.LG",
      "comment": "MICS 2024 1st Place Paper, MSOE AI-Club Research Group",
      "pdf_url": "http://arxiv.org/pdf/2407.00698v1",
      "published_date": "2024-06-30 13:43:26 UTC",
      "updated_date": "2024-06-30 13:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:10:44.327903"
    },
    {
      "arxiv_id": "2407.00697v3",
      "title": "CaFNet: A Confidence-Driven Framework for Radar Camera Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Huawei Sun",
        "Hao Feng",
        "Julius Ott",
        "Lorenzo Servadei",
        "Robert Wille"
      ],
      "abstract": "Depth estimation is critical in autonomous driving for interpreting 3D scenes\naccurately. Recently, radar-camera depth estimation has become of sufficient\ninterest due to the robustness and low-cost properties of radar. Thus, this\npaper introduces a two-stage, end-to-end trainable Confidence-aware Fusion Net\n(CaFNet) for dense depth estimation, combining RGB imagery with sparse and\nnoisy radar point cloud data. The first stage addresses radar-specific\nchallenges, such as ambiguous elevation and noisy measurements, by predicting a\nradar confidence map and a preliminary coarse depth map. A novel approach is\npresented for generating the ground truth for the confidence map, which\ninvolves associating each radar point with its corresponding object to identify\npotential projection surfaces. These maps, together with the initial radar\ninput, are processed by a second encoder. For the final depth estimation, we\ninnovate a confidence-aware gated fusion mechanism to integrate radar and image\nfeatures effectively, thereby enhancing the reliability of the depth map by\nfiltering out radar noise. Our methodology, evaluated on the nuScenes dataset,\ndemonstrates superior performance, improving upon the current leading model by\n3.2% in Mean Absolute Error (MAE) and 2.7% in Root Mean Square Error (RMSE).\nCode: https://github.com/harborsarah/CaFNet",
      "tldr_zh": "本论文提出了一种基于置信度的框架CaFNet，用于雷达-相机深度估计，以提升自动驾驶中3D场景的准确解读。该框架采用两阶段端到端训练方法：第一阶段通过预测雷达置信度地图和初步粗糙深度地图来处理雷达的模糊高度和噪音问题；第二阶段引入置信度感知门控融合机制，高效整合雷达点云和RGB图像特征，从而过滤噪音并提高深度估计可靠性。在nuScenes数据集上的实验显示，CaFNet相较于当前领先模型，改善了3.2%的Mean Absolute Error (MAE)和2.7%的Root Mean Square Error (RMSE)。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.00697v3",
      "published_date": "2024-06-30 13:39:29 UTC",
      "updated_date": "2024-08-30 13:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:10:57.008144"
    },
    {
      "arxiv_id": "2407.00695v2",
      "title": "Learning Formal Mathematics From Intrinsic Motivation",
      "title_zh": "基于内在动机的形式数学学习",
      "authors": [
        "Gabriel Poesia",
        "David Broman",
        "Nick Haber",
        "Noah D. Goodman"
      ],
      "abstract": "How did humanity coax mathematics from the aether? We explore the Platonic\nview that mathematics can be discovered from its axioms - a game of conjecture\nand proof. We describe Minimo (Mathematics from Intrinsic Motivation): an agent\nthat jointly learns to pose challenging problems for itself (conjecturing) and\nsolve them (theorem proving). Given a mathematical domain axiomatized in\ndependent type theory, we first combine methods for constrained decoding and\ntype-directed synthesis to sample valid conjectures from a language model. Our\nmethod guarantees well-formed conjectures by construction, even as we start\nwith a randomly initialized model. We use the same model to represent a policy\nand value function for guiding proof search. Our agent targets generating hard\nbut provable conjectures - a moving target, since its own theorem proving\nability also improves as it trains. We propose novel methods for hindsight\nrelabeling on proof search trees to significantly improve the agent's sample\nefficiency in both tasks. Experiments on 3 axiomatic domains (propositional\nlogic, arithmetic and group theory) demonstrate that our agent can bootstrap\nfrom only the axioms, self-improving in generating true and challenging\nconjectures and in finding proofs.",
      "tldr_zh": "本研究提出 Minimo 代理，通过内在动机从公理中学习形式数学，实现 conjecturing（提出猜想）和 theorem proving（证明定理）的联合训练。\n代理在 dependent type theory 的数学领域中，使用 constrained decoding 和 type-directed synthesis 从语言模型采样有效的、结构良好的 conjectures，同时通过 hindsight relabeling 优化证明搜索的样本效率。\n实验结果显示，Minimo 在 propositional logic、arithmetic 和 group theory 等三个领域，从初始公理起步，实现了自我改进，能够生成具有挑战性的真猜想并成功找到证明。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 Oral",
      "pdf_url": "http://arxiv.org/pdf/2407.00695v2",
      "published_date": "2024-06-30 13:34:54 UTC",
      "updated_date": "2024-11-05 01:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:11:09.388366"
    },
    {
      "arxiv_id": "2407.00693v2",
      "title": "BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization",
      "title_zh": "翻译失败",
      "authors": [
        "Gihun Lee",
        "Minchan Jeong",
        "Yujin Kim",
        "Hojung Jung",
        "Jaehoon Oh",
        "Sangmook Kim",
        "Se-Young Yun"
      ],
      "abstract": "While learning to align Large Language Models (LLMs) with human preferences\nhas shown remarkable success, aligning these models to meet the diverse user\npreferences presents further challenges in preserving previous knowledge. This\npaper examines the impact of personalized preference optimization on LLMs,\nrevealing that the extent of knowledge loss varies significantly with\npreference heterogeneity. Although previous approaches have utilized the KL\nconstraint between the reference model and the policy model, we observe that\nthey fail to maintain general knowledge and alignment when facing personalized\npreferences. To this end, we introduce Base-Anchored Preference Optimization\n(BAPO), a simple yet effective approach that utilizes the initial responses of\nreference model to mitigate forgetting while accommodating personalized\nalignment. BAPO effectively adapts to diverse user preferences while minimally\naffecting global knowledge or general alignment. Our experiments demonstrate\nthe efficacy of BAPO in various setups.",
      "tldr_zh": "本研究探讨了在对Large Language Models (LLMs)进行个性化偏好优化时，模型可能遗忘先前知识的问题，并发现这种遗忘程度与用户偏好异质性密切相关。现有方法如KL约束虽试图维持模型对齐，但未能有效保留一般知识和整体性能。为解决此问题，提出Base-Anchored Preference Optimization (BAPO)，该方法利用参考模型的初始响应作为锚点，减少遗忘的同时适应多样化用户偏好。实验结果表明，BAPO在各种设置中表现出色，能最小化对全局知识和一般对齐的影响。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "The 2024 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.00693v2",
      "published_date": "2024-06-30 13:30:04 UTC",
      "updated_date": "2024-09-29 08:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:11:22.539784"
    },
    {
      "arxiv_id": "2407.02528v1",
      "title": "Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Romy Fieblinger",
        "Md Tanvirul Alam",
        "Nidhi Rastogi"
      ],
      "abstract": "Cyber threats are constantly evolving. Extracting actionable insights from\nunstructured Cyber Threat Intelligence (CTI) data is essential to guide\ncybersecurity decisions. Increasingly, organizations like Microsoft, Trend\nMicro, and CrowdStrike are using generative AI to facilitate CTI extraction.\nThis paper addresses the challenge of automating the extraction of actionable\nCTI using advancements in Large Language Models (LLMs) and Knowledge Graphs\n(KGs). We explore the application of state-of-the-art open-source LLMs,\nincluding the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting\nmeaningful triples from CTI texts. Our methodology evaluates techniques such as\nprompt engineering, the guidance framework, and fine-tuning to optimize\ninformation extraction and structuring. The extracted data is then utilized to\nconstruct a KG, offering a structured and queryable representation of threat\nintelligence. Experimental results demonstrate the effectiveness of our\napproach in extracting relevant information, with guidance and fine-tuning\nshowing superior performance over prompt engineering. However, while our\nmethods prove effective in small-scale tests, applying LLMs to large-scale data\nfor KG construction and Link Prediction presents ongoing challenges.",
      "tldr_zh": "本研究探讨了使用 Large Language Models (LLMs) 和 Knowledge Graphs (KGs) 自动提取可行动的 Cyber Threat Intelligence (CTI)，以应对不断演变的网络威胁。研究评估了开源 LLMs 如 Llama 2 系列、Mistral 7B Instruct 和 Zephyr，通过 prompt engineering、guidance framework 和 fine-tuning 等技术，从 CTI 文本中提取有意义的 triples，并构建结构化的 KG 以提供可查询的威胁情报表示。实验结果显示，guidance framework 和 fine-tuning 方法优于 prompt engineering，在小规模测试中表现出色，但在大规模数据上的 KG 构建和 Link Prediction 仍面临挑战。整体上，该方法为提升 CTI 提取效率和决策支持提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "6th Workshop on Attackers and Cyber-Crime Operations, 12 pages, 1\n  figure, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.02528v1",
      "published_date": "2024-06-30 13:02:03 UTC",
      "updated_date": "2024-06-30 13:02:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:11:37.223061"
    },
    {
      "arxiv_id": "2407.00664v2",
      "title": "SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images",
      "title_zh": "翻译失败",
      "authors": [
        "Zekang Yang",
        "Hong Liu",
        "Xiangdong Wang"
      ],
      "abstract": "Cancer survival prediction is a challenging task that involves analyzing of\nthe tumor microenvironment within Whole Slide Image (WSI). Previous methods\ncannot effectively capture the intricate interaction features among instances\nwithin the local area of WSI. Moreover, existing methods for cancer survival\nprediction based on WSI often fail to provide better clinically meaningful\npredictions. To overcome these challenges, we propose a Sparse Context-aware\nMultiple Instance Learning (SCMIL) framework for predicting cancer survival\nprobability distributions. SCMIL innovatively segments patches into various\nclusters based on their morphological features and spatial location\ninformation, subsequently leveraging sparse self-attention to discern the\nrelationships between these patches with a context-aware perspective.\nConsidering many patches are irrelevant to the task, we introduce a learnable\npatch filtering module called SoftFilter, which ensures that only interactions\nbetween task-relevant patches are considered. To enhance the clinical relevance\nof our prediction, we propose a register-based mixture density network to\nforecast the survival probability distribution for individual patients. We\nevaluate SCMIL on two public WSI datasets from the The Cancer Genome Atlas\n(TCGA) specifically focusing on lung adenocarcinom (LUAD) and kidney renal\nclear cell carcinoma (KIRC). Our experimental results indicate that SCMIL\noutperforms current state-of-the-art methods for survival prediction, offering\nmore clinically meaningful and interpretable outcomes. Our code is accessible\nat https://github.com/yang-ze-kang/SCMIL.",
      "tldr_zh": "该研究提出了一种稀疏上下文感知多实例学习框架（SCMIL），旨在通过分析全滑片图像（Whole Slide Images, WSI）来预测癌症患者的生存概率分布，解决现有方法在捕获实例交互特征和临床相关性方面的不足。SCMIL 通过基于形态特征和空间位置信息对图像 patches 进行聚类，并利用稀疏自注意力（sparse self-attention）机制从上下文视角识别相关 patches 之间的关系，同时引入 SoftFilter 模块过滤无关 patches，并采用基于注册的混合密度网络（mixture density network）来提升预测的临床意义。在 TCGA 数据集上的肺腺癌（LUAD）和肾透明细胞癌（KIRC）实验中，SCMIL 超越了现有最先进方法，提供更准确、可解释的生存预测结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by MICCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2407.00664v2",
      "published_date": "2024-06-30 11:22:36 UTC",
      "updated_date": "2024-10-22 03:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:11:46.043002"
    },
    {
      "arxiv_id": "2407.00662v2",
      "title": "Multi-Agent Training for Pommerman: Curriculum Learning and Population-based Self-Play Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Nhat-Minh Huynh",
        "Hoang-Giang Cao",
        "I-Chen Wu"
      ],
      "abstract": "Pommerman is a multi-agent environment that has received considerable\nattention from researchers in recent years. This environment is an ideal\nbenchmark for multi-agent training, providing a battleground for two teams with\ncommunication capabilities among allied agents. Pommerman presents significant\nchallenges for model-free reinforcement learning due to delayed action effects,\nsparse rewards, and false positives, where opponent players can lose due to\ntheir own mistakes. This study introduces a system designed to train\nmulti-agent systems to play Pommerman using a combination of curriculum\nlearning and population-based self-play. We also tackle two challenging\nproblems when deploying the multi-agent training system for competitive games:\nsparse reward and suitable matchmaking mechanism. Specifically, we propose an\nadaptive annealing factor based on agents' performance to adjust the dense\nexploration reward during training dynamically. Additionally, we implement a\nmatchmaking mechanism utilizing the Elo rating system to pair agents\neffectively. Our experimental results demonstrate that our trained agent can\noutperform top learning agents without requiring communication among allied\nagents.",
      "tldr_zh": "本研究针对 Pommerman 多智能体环境，提出了一种结合 curriculum learning 和 population-based self-play 的训练系统，以解决延迟行动效果、稀疏奖励和假阳性等挑战。该系统引入了基于代理性能的适应性退火因子来动态调整密集探索奖励，并采用 Elo rating system 进行有效的匹配机制。实验结果表明，训练出的代理无需盟友通信即可超越顶级学习代理的性能。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at The First Workshop on Game AI Algorithms and Multi-Agent\n  Learning - IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.00662v2",
      "published_date": "2024-06-30 11:14:29 UTC",
      "updated_date": "2025-01-08 07:35:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:11:58.066839"
    },
    {
      "arxiv_id": "2407.12032v1",
      "title": "Large Language Models for Behavioral Economics: Internal Validity and Elicitation of Mental Models",
      "title_zh": "翻译失败",
      "authors": [
        "Brian Jabarian"
      ],
      "abstract": "In this article, we explore the transformative potential of integrating\ngenerative AI, particularly Large Language Models (LLMs), into behavioral and\nexperimental economics to enhance internal validity. By leveraging AI tools,\nresearchers can improve adherence to key exclusion restrictions and in\nparticular ensure the internal validity measures of mental models, which often\nrequire human intervention in the incentive mechanism. We present a case study\ndemonstrating how LLMs can enhance experimental design, participant engagement,\nand the validity of measuring mental models.",
      "tldr_zh": "这篇论文探讨了将大型语言模型（LLMs）整合到行为和实验经济学中的潜力，以提升内部效度（internal validity）。研究者通过AI工具改善关键排除限制，特别是减少人类干预来确保心理模型（mental models）的准确测量。论文提供了一个案例研究，展示了LLMs如何优化实验设计、提升参与者参与度，并增强心理模型测量的效度，最终为行为经济学研究带来更可靠的方法。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12032v1",
      "published_date": "2024-06-30 10:58:57 UTC",
      "updated_date": "2024-06-30 10:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:12:13.303860"
    },
    {
      "arxiv_id": "2407.01635v7",
      "title": "Commute Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Zhuo",
        "Han Yu",
        "Guang Tan",
        "Xiaoxiao Li"
      ],
      "abstract": "Graph Neural Networks (GNNs) have shown remarkable success in learning from\ngraph-structured data. However, their application to directed graphs (digraphs)\npresents unique challenges, primarily due to the inherent asymmetry in node\nrelationships. Traditional GNNs are adept at capturing unidirectional relations\nbut fall short in encoding the mutual path dependencies between nodes, such as\nasymmetrical shortest paths typically found in digraphs. Recognizing this gap,\nwe introduce Commute Graph Neural Networks (CGNN), an approach that seamlessly\nintegrates node-wise commute time into the message passing scheme. The\ncornerstone of CGNN is an efficient method for computing commute time using a\nnewly formulated digraph Laplacian. Commute time is then integrated into the\nneighborhood aggregation process, with neighbor contributions weighted\naccording to their respective commute time to the central node in each layer.\nIt enables CGNN to directly capture the mutual, asymmetric relationships in\ndigraphs. Extensive experiments on 8 benchmarking datasets confirm the\nsuperiority of CGNN against 13 state-of-the-art methods.",
      "tldr_zh": "该论文针对 Graph Neural Networks (GNNs) 在处理 directed graphs (digraphs) 时存在的挑战，即无法有效捕捉节点之间的不对称关系（如不对称最短路径），提出了一种新的方法 Commute Graph Neural Networks (CGNN)。CGNN 通过将节点-wise commute time 整合到消息传递方案中，并利用新制定的 digraph Laplacian 高效计算 commute time，从而在邻居聚合过程中根据 commute time 对邻居贡献进行加权，以直接捕捉 digraph 的相互不对称关系。实验结果显示，在 8 个基准数据集上，CGNN 优于 13 个最先进的方法，证明了其在图结构数据学习中的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in International Conference on Machine Learning (ICML),\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2407.01635v7",
      "published_date": "2024-06-30 10:53:40 UTC",
      "updated_date": "2025-05-15 05:02:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:12:22.426861"
    },
    {
      "arxiv_id": "2407.00653v1",
      "title": "Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Zhang",
        "Xintao Wang",
        "Jiaqing Liang",
        "Sirui Xia",
        "Lida Chen",
        "Yanghua Xiao"
      ],
      "abstract": "Large Language Models (LLMs) have exhibited impressive proficiency in various\nnatural language processing (NLP) tasks, which involve increasingly complex\nreasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving\nnew knowledge from existing one.While it has been widely studied in the context\nof knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.\nIn this paper, we introduce Chain-of-Knowledge, a comprehensive framework for\nknowledge reasoning, including methodologies for both dataset construction and\nmodel learning. For dataset construction, we create KnowReason via rule mining\non KGs. For model learning, we observe rule overfitting induced by naive\ntraining. Hence, we enhance CoK with a trial-and-error mechanism that simulates\nthe human process of internal knowledge exploration. We conduct extensive\nexperiments with KnowReason. Our results show the effectiveness of CoK in\nrefining LLMs in not only knowledge reasoning, but also general reasoning\nbenchmarkms.",
      "tldr_zh": "该论文提出 Chain-of-Knowledge 框架，用于将知识推理整合到 Large Language Models (LLMs) 中，通过从 Knowledge Graphs (KGs) 学习来提升模型性能。框架包括数据集构建（通过在 KGs 上进行规则挖掘创建 KnowReason）和模型学习（引入试错机制模拟人类知识探索过程，以避免规则 overfitting）。实验结果表明，该方法不仅在知识推理任务上有效，还显著提高了 LLMs 在一般推理基准上的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00653v1",
      "published_date": "2024-06-30 10:49:32 UTC",
      "updated_date": "2024-06-30 10:49:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:12:33.567400"
    },
    {
      "arxiv_id": "2407.00641v3",
      "title": "NeuroNAS: Enhancing Efficiency of Neuromorphic In-Memory Computing for Intelligent Mobile Agents through Hardware-Aware Spiking Neural Architecture Search",
      "title_zh": "翻译失败",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Muhammad Shafique"
      ],
      "abstract": "Intelligent mobile agents (e.g., UGVs and UAVs) typically demand low\npower/energy consumption when solving their machine learning (ML)-based tasks,\nsince they are usually powered by portable batteries with limited capacity. A\npotential solution is employing neuromorphic computing with Spiking Neural\nNetworks (SNNs), which leverages event-based computation to enable ultra-low\npower/energy ML algorithms. To maximize the performance efficiency of SNN\ninference, the In-Memory Computing (IMC)-based hardware accelerators with\nemerging device technologies (e.g., RRAM) can be employed. However, SNN models\nare typically developed without considering constraints from the application\nand the underlying IMC hardware, thereby hindering SNNs from reaching their\nfull potential in performance and efficiency. To address this, we propose\nNeuroNAS, a novel framework for developing energyefficient neuromorphic IMC for\nintelligent mobile agents using hardware-aware spiking neural architecture\nsearch (NAS), i.e., by quickly finding an SNN architecture that offers high\naccuracy under the given constraints (e.g., memory, area, latency, and energy\nconsumption). Its key steps include: optimizing SNN operations to enable\nefficient NAS, employing quantization to minimize the memory footprint,\ndeveloping an SNN architecture that facilitates an effective learning, and\ndevising a systematic hardware-aware search algorithm to meet the constraints.\nCompared to the state-of-the-art techniques, NeuroNAS quickly finds SNN\narchitectures (with 8bit weight precision) that maintain high accuracy by up to\n6.6x search time speed-ups, while achieving up to 92% area savings, 1.2x\nlatency improvements, 84% energy savings across different datasets (i.e.,\nCIFAR-10, CIFAR-100, and TinyImageNet-200); while the state-of-the-art fail to\nmeet all constraints at once.",
      "tldr_zh": "本研究提出NeuroNAS框架，通过硬件感知的SNN（Spiking Neural Networks）架构搜索（NAS），提升智能移动代理（如UGV和UAV）的神经形态In-Memory Computing（IMC）效率，以应对其低功耗需求。NeuroNAS的关键步骤包括优化SNN操作、量化减少内存占用、开发易于学习的SNN架构，以及设计系统化的硬件感知搜索算法，确保在内存、面积、延迟和能量约束下实现高准确率。实验结果显示，与现有技术相比，NeuroNAS在CIFAR-10、CIFAR-100和TinyImageNet-200数据集上，搜索时间加快6.6倍，同时实现高达92%的面积节省、1.2倍延迟改善和84%的能量节省。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "9 pages, 14 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.00641v3",
      "published_date": "2024-06-30 09:51:58 UTC",
      "updated_date": "2025-04-18 07:00:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:12:46.241271"
    },
    {
      "arxiv_id": "2407.00631v2",
      "title": "TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets",
      "title_zh": "TrialBench：多模态人工智能就绪临床试验数据集",
      "authors": [
        "Jintai Chen",
        "Yaojun Hu",
        "Yue Wang",
        "Yingzhou Lu",
        "Xu Cao",
        "Miao Lin",
        "Hongxia Xu",
        "Jian Wu",
        "Cao Xiao",
        "Jimeng Sun",
        "Lucas Glass",
        "Kexin Huang",
        "Marinka Zitnik",
        "Tianfan Fu"
      ],
      "abstract": "Clinical trials are pivotal for developing new medical treatments, yet they\ntypically pose some risks such as patient mortality, adverse events, and\nenrollment failure that waste immense efforts spanning over a decade. Applying\nartificial intelligence (AI) to forecast or simulate key events in clinical\ntrials holds great potential for providing insights to guide trial designs.\nHowever, complex data collection and question definition requiring medical\nexpertise and a deep understanding of trial designs have hindered the\ninvolvement of AI thus far. This paper tackles these challenges by presenting a\ncomprehensive suite of meticulously curated AIready datasets covering\nmulti-modal data (e.g., drug molecule, disease code, text,\ncategorical/numerical features) and 8 crucial prediction challenges in clinical\ntrial design, encompassing prediction of trial duration, patient dropout rate,\nserious adverse event, mortality rate, trial approval outcome, trial failure\nreason, drug dose finding, design of eligibility criteria. Furthermore, we\nprovide basic validation methods for each task to ensure the datasets'\nusability and reliability. We anticipate that the availability of such\nopen-access datasets will catalyze the development of advanced AI approaches\nfor clinical trial design, ultimately advancing clinical trial research and\naccelerating medical solution development. The curated dataset, metrics, and\nbasic models are publicly available at\nhttps://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial.",
      "tldr_zh": "这篇论文介绍了TrialBench，一套多模态AI-ready临床试验数据集，旨在通过AI预测或模拟临床试验的关键事件（如试验持续时间、患者脱落率和严重不良事件），以减少风险并优化设计。数据集涵盖药物分子、疾病代码、文本以及分类/数值特征等数据，并针对8个预测挑战提供基本验证方法，确保其可用性和可靠性。论文通过公开这些资源，期望加速AI在临床试验研究中的应用，最终推动医疗解决方案的开发。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00631v2",
      "published_date": "2024-06-30 09:13:10 UTC",
      "updated_date": "2024-09-03 18:00:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:12:57.348257"
    },
    {
      "arxiv_id": "2407.00626v2",
      "title": "Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with Energy-Based Models",
      "title_zh": "最大熵逆强化学习应用于扩散模型的能量基于模型",
      "authors": [
        "Sangwoong Yoon",
        "Himchan Hwang",
        "Dohyun Kwon",
        "Yung-Kyun Noh",
        "Frank C. Park"
      ],
      "abstract": "We present a maximum entropy inverse reinforcement learning (IRL) approach\nfor improving the sample quality of diffusion generative models, especially\nwhen the number of generation time steps is small. Similar to how IRL trains a\npolicy based on the reward function learned from expert demonstrations, we\ntrain (or fine-tune) a diffusion model using the log probability density\nestimated from training data. Since we employ an energy-based model (EBM) to\nrepresent the log density, our approach boils down to the joint training of a\ndiffusion model and an EBM. Our IRL formulation, named Diffusion by Maximum\nEntropy IRL (DxMI), is a minimax problem that reaches equilibrium when both\nmodels converge to the data distribution. The entropy maximization plays a key\nrole in DxMI, facilitating the exploration of the diffusion model and ensuring\nthe convergence of the EBM. We also propose Diffusion by Dynamic Programming\n(DxDP), a novel reinforcement learning algorithm for diffusion models, as a\nsubroutine in DxMI. DxDP makes the diffusion model update in DxMI efficient by\ntransforming the original problem into an optimal control formulation where\nvalue functions replace back-propagation in time. Our empirical studies show\nthat diffusion models fine-tuned using DxMI can generate high-quality samples\nin as few as 4 and 10 steps. Additionally, DxMI enables the training of an EBM\nwithout MCMC, stabilizing EBM training dynamics and enhancing anomaly detection\nperformance.",
      "tldr_zh": "本文提出了一种基于最大熵 Inverse Reinforcement Learning (IRL) 的方法，名为 Diffusion by Maximum Entropy IRL (DxMI)，用于提升扩散模型的样本质量，尤其在生成步数较少时，通过联合训练扩散模型和 Energy-Based Models (EBM) 来模拟数据分布。DxMI 采用熵最大化促进模型探索，并引入 Diffusion by Dynamic Programming (DxDP) 作为子例程，将问题转化为最优控制形式，使用价值函数代替时间反向传播以提高训练效率。实验结果显示，该方法使扩散模型能在 4 到 10 步内生成高质量样本，同时稳定 EBM 训练过程，并提升异常检测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Oral Presentation. Code is released at\n  https://github.com/swyoon/Diffusion-by-MaxEntIRL",
      "pdf_url": "http://arxiv.org/pdf/2407.00626v2",
      "published_date": "2024-06-30 08:52:17 UTC",
      "updated_date": "2024-10-31 11:39:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:13:12.474722"
    },
    {
      "arxiv_id": "2407.00617v4",
      "title": "Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Zhang",
        "Dian Yu",
        "Baolin Peng",
        "Linfeng Song",
        "Ye Tian",
        "Mingyue Huo",
        "Nan Jiang",
        "Haitao Mi",
        "Dong Yu"
      ],
      "abstract": "Reinforcement Learning with Human Feedback (RLHF) has achieved great success\nin aligning large language models (LLMs) with human preferences. Prevalent RLHF\napproaches are reward-based, following the Bradley-Terry (BT) model assumption,\nwhich may not fully capture the complexity of human preferences. In this paper,\nwe explore RLHF under a general preference framework and approach it from a\ngame-theoretic perspective. Specifically, we formulate the problem as a\ntwo-player game and propose a novel online algorithm, iterative Nash policy\noptimization (INPO). The key idea is to let the policy play against itself via\nno-regret learning, thereby approximating the Nash policy. Unlike previous\nmethods, INPO bypasses the need for estimating the expected win rate for\nindividual responses, which typically incurs high computational or annotation\ncosts. Instead, we introduce a new loss objective that is directly minimized\nover a preference dataset. We provide theoretical analysis for our approach and\ndemonstrate its effectiveness through experiments on various representative\nbenchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 42.6%\nlength-controlled win rate on AlpacaEval 2.0 and a 37.8% win rate on\nArena-Hard, showing substantial improvement over the state-of-the-art online\nRLHF algorithms.",
      "tldr_zh": "本文探讨了 Reinforcement Learning with Human Feedback (RLHF) 在对齐大型语言模型 (LLMs) 与一般人类偏好时的局限性，指出传统基于 Bradley-Terry (BT) 模型的方法可能无法充分捕捉偏好的复杂性。作者提出 Iterative Nash Policy Optimization (INPO) 算法，将问题视为两玩家博弈，通过 no-regret learning 让策略自我对抗逼近 Nash policy，同时引入一个新的损失目标，直接在偏好数据集上最小化，以降低计算和标注成本。实验结果显示，基于 LLaMA-3-8B 的 INPO 在 AlpacaEval 2.0 上实现 42.6% 的长度控制胜率，在 Arena-Hard 上达到 37.8%，显著优于现有在线 RLHF 算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00617v4",
      "published_date": "2024-06-30 08:00:34 UTC",
      "updated_date": "2025-03-03 03:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:13:34.743778"
    },
    {
      "arxiv_id": "2407.00608v1",
      "title": "Efficient Personalized Text-to-image Generation by Leveraging Textual Subspace",
      "title_zh": "利用文本子空间实现高效的个性化文本到图像生成",
      "authors": [
        "Shian Du",
        "Xiaotian Cheng",
        "Qi Qian",
        "Henglu Wei",
        "Yi Xu",
        "Xiangyang Ji"
      ],
      "abstract": "Personalized text-to-image generation has attracted unprecedented attention\nin the recent few years due to its unique capability of generating\nhighly-personalized images via using the input concept dataset and novel\ntextual prompt. However, previous methods solely focus on the performance of\nthe reconstruction task, degrading its ability to combine with different\ntextual prompt. Besides, optimizing in the high-dimensional embedding space\nusually leads to unnecessary time-consuming training process and slow\nconvergence. To address these issues, we propose an efficient method to explore\nthe target embedding in a textual subspace, drawing inspiration from the\nself-expressiveness property. Additionally, we propose an efficient selection\nstrategy for determining the basis vectors of the textual subspace. The\nexperimental evaluations demonstrate that the learned embedding can not only\nfaithfully reconstruct input image, but also significantly improves its\nalignment with novel input textual prompt. Furthermore, we observe that\noptimizing in the textual subspace leads to an significant improvement of the\nrobustness to the initial word, relaxing the constraint that requires users to\ninput the most relevant initial word. Our method opens the door to more\nefficient representation learning for personalized text-to-image generation.",
      "tldr_zh": "本研究针对个性化文本到图像生成（text-to-image generation）中的问题，提出了一种高效方法，通过在文本子空间（textual subspace）中探索目标嵌入，以解决现有方法仅关注重建任务导致的文本提示结合能力不足，以及高维嵌入空间优化带来的训练耗时问题。该方法借鉴自表达性属性（self-expressiveness property），并引入高效选择策略来确定文本子空间的基向量。实验结果显示，该方法不仅能忠实重建输入图像，还显著提升了与新文本提示的 aligning 性能，并提高了对初始词的鲁棒性，从而为更高效的表示学习打开了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00608v1",
      "published_date": "2024-06-30 06:41:21 UTC",
      "updated_date": "2024-06-30 06:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:13:34.578477"
    },
    {
      "arxiv_id": "2407.12031v1",
      "title": "Evaluation of Bias Towards Medical Professionals in Large Language Models",
      "title_zh": "大型语言模型中针对医疗专业人士的偏见评估",
      "authors": [
        "Xi Chen",
        "Yang Xu",
        "MingKe You",
        "Li Wang",
        "WeiZhi Liu",
        "Jian Li"
      ],
      "abstract": "This study evaluates whether large language models (LLMs) exhibit biases\ntowards medical professionals. Fictitious candidate resumes were created to\ncontrol for identity factors while maintaining consistent qualifications. Three\nLLMs (GPT-4, Claude-3-haiku, and Mistral-Large) were tested using a\nstandardized prompt to evaluate resumes for specific residency programs.\nExplicit bias was tested by changing gender and race information, while\nimplicit bias was tested by changing names while hiding race and gender.\nPhysician data from the Association of American Medical Colleges was used to\ncompare with real-world demographics. 900,000 resumes were evaluated. All LLMs\nexhibited significant gender and racial biases across medical specialties.\nGender preferences varied, favoring male candidates in surgery and orthopedics,\nwhile preferring females in dermatology, family medicine, obstetrics and\ngynecology, pediatrics, and psychiatry. Claude-3 and Mistral-Large generally\nfavored Asian candidates, while GPT-4 preferred Black and Hispanic candidates\nin several specialties. Tests revealed strong preferences towards Hispanic\nfemales and Asian males in various specialties. Compared to real-world data,\nLLMs consistently chose higher proportions of female and underrepresented\nracial candidates than their actual representation in the medical workforce.\nGPT-4, Claude-3, and Mistral-Large showed significant gender and racial biases\nwhen evaluating medical professionals for residency selection. These findings\nhighlight the potential for LLMs to perpetuate biases and compromise healthcare\nworkforce diversity if used without proper bias mitigation strategies.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在医疗专业人员选拔中的性别和种族偏见，使用虚构简历控制身份因素，并测试了GPT-4、Claude-3-haiku和Mistral-Large模型。实验通过标准化提示评估90万份简历，比较显性偏见（如直接改变性别和种族信息）和隐性偏见（如隐藏种族和性别仅改变姓名），并与美国医学院协会的真实数据对照。结果显示，所有LLMs均存在显著偏见，例如男性在外科和骨科更受青睐，而女性在皮肤科、家庭医学、产科和妇科、儿科及精神病学等领域更受欢迎；Claude-3和Mistral-Large偏好亚洲候选人，GPT-4则倾向于黑人和西班牙裔候选人。总体而言，LLMs在选择中过度青睐女性和少数族裔，导致潜在的偏见加剧，强调了在应用中需采用偏见缓解策略以维护医疗工作力的多样性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "36 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.12031v1",
      "published_date": "2024-06-30 05:55:55 UTC",
      "updated_date": "2024-06-30 05:55:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:13:46.994821"
    },
    {
      "arxiv_id": "2407.00600v1",
      "title": "GenderBias-\\emph{VL}: Benchmarking Gender Bias in Vision Language Models via Counterfactual Probing",
      "title_zh": "翻译失败",
      "authors": [
        "Yisong Xiao",
        "Aishan Liu",
        "QianJia Cheng",
        "Zhenfei Yin",
        "Siyuan Liang",
        "Jiapeng Li",
        "Jing Shao",
        "Xianglong Liu",
        "Dacheng Tao"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have been widely adopted in various\napplications; however, they exhibit significant gender biases. Existing\nbenchmarks primarily evaluate gender bias at the demographic group level,\nneglecting individual fairness, which emphasizes equal treatment of similar\nindividuals. This research gap limits the detection of discriminatory\nbehaviors, as individual fairness offers a more granular examination of biases\nthat group fairness may overlook. For the first time, this paper introduces the\nGenderBias-\\emph{VL} benchmark to evaluate occupation-related gender bias in\nLVLMs using counterfactual visual questions under individual fairness criteria.\nTo construct this benchmark, we first utilize text-to-image diffusion models to\ngenerate occupation images and their gender counterfactuals. Subsequently, we\ngenerate corresponding textual occupation options by identifying stereotyped\noccupation pairs with high semantic similarity but opposite gender proportions\nin real-world statistics. This method enables the creation of large-scale\nvisual question counterfactuals to expose biases in LVLMs, applicable in both\nmultimodal and unimodal contexts through modifying gender attributes in\nspecific modalities. Overall, our GenderBias-\\emph{VL} benchmark comprises\n34,581 visual question counterfactual pairs, covering 177 occupations. Using\nour benchmark, we extensively evaluate 15 commonly used open-source LVLMs (\\eg,\nLLaVA) and state-of-the-art commercial APIs, including GPT-4o and Gemini-Pro.\nOur findings reveal widespread gender biases in existing LVLMs. Our benchmark\noffers: (1) a comprehensive dataset for occupation-related gender bias\nevaluation; (2) an up-to-date leaderboard on LVLM biases; and (3) a nuanced\nunderstanding of the biases presented by these models. \\footnote{The dataset\nand code are available at the \\href{https://genderbiasvl.github.io/}{website}.}",
      "tldr_zh": "这篇论文引入了GenderBias-VL基准，用于通过counterfactual probing评估视觉语言模型(LVLMs)中的职业相关性别偏见，强调了个体公平而非仅限于群体层面。研究者利用文本到图像扩散模型生成职业图像及其性别对立版本，并结合语义相似的职业选项创建了34,581对视觉问题对偶，覆盖177个职业。实验评估了15个开源LVLMs（如LLaVA）和商业API（如GPT-4o和Gemini-Pro），揭示了这些模型中广泛存在的性别偏见，并提供了全面数据集、偏见排行榜以及对模型偏见的细致分析。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00600v1",
      "published_date": "2024-06-30 05:55:15 UTC",
      "updated_date": "2024-06-30 05:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:14:09.054836"
    },
    {
      "arxiv_id": "2407.00569v4",
      "title": "Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weihong Zhong",
        "Xiaocheng Feng",
        "Liang Zhao",
        "Qiming Li",
        "Lei Huang",
        "Yuxuan Gu",
        "Weitao Ma",
        "Yuan Xu",
        "Bing Qin"
      ],
      "abstract": "Though advanced in understanding visual information with human languages,\nLarge Vision-Language Models (LVLMs) still suffer from multimodal\nhallucinations. A natural concern is that during multimodal interaction, the\ngenerated hallucinations could influence the LVLMs' subsequent generation.\nThus, we raise a question: When presented with a query relevant to the\npreviously generated hallucination, will LVLMs be misled and respond\nincorrectly, even though the ground visual information exists? To answer this,\nwe propose a framework called MMHalSnowball to evaluate LVLMs' behaviors when\nencountering generated hallucinations, where LVLMs are required to answer\nspecific visual questions within a curated hallucinatory conversation.\nCrucially, our experiment shows that the performance of open-source LVLMs drops\nby at least $31\\%$, indicating that LVLMs are prone to accept the generated\nhallucinations and make false claims that they would not have supported without\ndistractions. We term this phenomenon Multimodal Hallucination Snowballing. To\nmitigate this, we further propose a training-free method called Residual Visual\nDecoding, where we revise the output distribution of LVLMs with the one derived\nfrom the residual visual input, providing models with direct access to the\nvisual information. Experiments show that our method can mitigate more than\n$24\\%$ of the snowballed multimodal hallucination while maintaining\ncapabilities.",
      "tldr_zh": "本文研究了Large Vision-Language Models (LVLMs) 中多模态幻觉的雪球效应（Multimodal Hallucination Snowballing），即生成的幻觉会误导模型后续响应，导致即使有正确视觉信息，模型仍可能给出错误输出。研究者提出MMHalSnowball框架，通过设计幻觉对话来评估这种现象，实验显示开源LVLMs的性能下降至少31%。为了缓解这一问题，他们开发了无训练方法Residual Visual Decoding，通过修正输出分布并利用剩余视觉输入，提供模型对视觉信息的直接访问。结果表明，该方法能减少超过24%的雪球效应，同时保持模型整体能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ACL 2024 Main Conference. 21 pages, 20 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00569v4",
      "published_date": "2024-06-30 03:04:11 UTC",
      "updated_date": "2024-08-03 17:52:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:14:11.205854"
    },
    {
      "arxiv_id": "2407.00568v5",
      "title": "Divide And Conquer: Learning Chaotic Dynamical Systems With Multistep Penalty Neural Ordinary Differential Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Dibyajyoti Chakraborty",
        "Seung Whan Chung",
        "Troy Arcomano",
        "Romit Maulik"
      ],
      "abstract": "Forecasting high-dimensional dynamical systems is a fundamental challenge in\nvarious fields, such as geosciences and engineering. Neural Ordinary\nDifferential Equations (NODEs), which combine the power of neural networks and\nnumerical solvers, have emerged as a promising algorithm for forecasting\ncomplex nonlinear dynamical systems. However, classical techniques used for\nNODE training are ineffective for learning chaotic dynamical systems. In this\nwork, we propose a novel NODE-training approach that allows for robust learning\nof chaotic dynamical systems. Our method addresses the challenges of\nnon-convexity and exploding gradients associated with underlying chaotic\ndynamics. Training data trajectories from such systems are split into multiple,\nnon-overlapping time windows. In addition to the deviation from the training\ndata, the optimization loss term further penalizes the discontinuities of the\npredicted trajectory between the time windows. The window size is selected\nbased on the fastest Lyapunov time scale of the system. Multi-step penalty(MP)\nmethod is first demonstrated on Lorenz equation, to illustrate how it improves\nthe loss landscape and thereby accelerates the optimization convergence. MP\nmethod can optimize chaotic systems in a manner similar to least-squares\nshadowing with significantly lower computational costs. Our proposed algorithm,\ndenoted the Multistep Penalty NODE, is applied to chaotic systems such as the\nKuramoto-Sivashinsky equation, the two-dimensional Kolmogorov flow, and ERA5\nreanalysis data for the atmosphere. It is observed that MP-NODE provide viable\nperformance for such chaotic systems, not only for short-term trajectory\npredictions but also for invariant statistics that are hallmarks of the chaotic\nnature of these dynamics.",
      "tldr_zh": "这篇论文针对预测混沌动态系统的挑战，提出了一种新的训练方法Multistep Penalty Neural Ordinary Differential Equations (MP-NODE)。该方法将训练数据轨迹分成多个非重叠时间窗口，并在窗口间惩罚预测轨迹的不连续性，同时根据系统的最大Lyapunov时间尺度选择窗口大小，以解决非凸性和梯度爆炸问题。实验首先在Lorenz equation上验证了MP方法如何改善损失景观并加速优化收敛，与least-squares shadowing类似但计算成本更低。最终，MP-NODE应用于Kuramoto-Sivashinsky equation、二维Kolmogorov flow和ERA5大气再分析数据，实现了短期轨迹预测和混沌系统的不变统计特性的高精度表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 17 Figures, submitted to Computer Methods in Applied\n  Mechanics and Engineering",
      "pdf_url": "http://arxiv.org/pdf/2407.00568v5",
      "published_date": "2024-06-30 02:50:28 UTC",
      "updated_date": "2024-10-15 17:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:14:23.509794"
    },
    {
      "arxiv_id": "2407.00567v1",
      "title": "A Contextual Combinatorial Bandit Approach to Negotiation",
      "title_zh": "翻译失败",
      "authors": [
        "Yexin Li",
        "Zhancun Mu",
        "Siyuan Qi"
      ],
      "abstract": "Learning effective negotiation strategies poses two key challenges: the\nexploration-exploitation dilemma and dealing with large action spaces. However,\nthere is an absence of learning-based approaches that effectively address these\nchallenges in negotiation. This paper introduces a comprehensive formulation to\ntackle various negotiation problems. Our approach leverages contextual\ncombinatorial multi-armed bandits, with the bandits resolving the\nexploration-exploitation dilemma, and the combinatorial nature handles large\naction spaces. Building upon this formulation, we introduce NegUCB, a novel\nmethod that also handles common issues such as partial observations and complex\nreward functions in negotiation. NegUCB is contextual and tailored for\nfull-bandit feedback without constraints on the reward functions. Under mild\nassumptions, it ensures a sub-linear regret upper bound. Experiments conducted\non three negotiation tasks demonstrate the superiority of our approach.",
      "tldr_zh": "这篇论文针对谈判策略学习的探索-利用困境和大型行动空间问题，提出了一种基于上下文组合多臂老虎机（contextual combinatorial multi-armed bandits）的全面框架，以有效解决这些挑战。作者引入了 NegUCB 方法，该方法支持部分观察和复杂奖励函数，并适用于全带宽反馈，在温和假设下确保亚线性遗憾上界（sub-linear regret upper bound）。实验结果在三个谈判任务上展示了该方法的优越性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00567v1",
      "published_date": "2024-06-30 02:43:15 UTC",
      "updated_date": "2024-06-30 02:43:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:14:33.268948"
    },
    {
      "arxiv_id": "2407.00553v1",
      "title": "Cooperative Advisory Residual Policies for Congestion Mitigation",
      "title_zh": "用于缓解拥堵的合作咨询残差策略",
      "authors": [
        "Aamir Hasan",
        "Neeloy Chakraborty",
        "Haonan Chen",
        "Jung-Hoon Cho",
        "Cathy Wu",
        "Katherine Driggs-Campbell"
      ],
      "abstract": "Fleets of autonomous vehicles can mitigate traffic congestion through simple\nactions, thus improving many socioeconomic factors such as commute time and gas\ncosts. However, these approaches are limited in practice as they assume precise\ncontrol over autonomous vehicle fleets, incur extensive installation costs for\na centralized sensor ecosystem, and also fail to account for uncertainty in\ndriver behavior. To this end, we develop a class of learned residual policies\nthat can be used in cooperative advisory systems and only require the use of a\nsingle vehicle with a human driver. Our policies advise drivers to behave in\nways that mitigate traffic congestion while accounting for diverse driver\nbehaviors, particularly drivers' reactions to instructions, to provide an\nimproved user experience. To realize such policies, we introduce an improved\nreward function that explicitly addresses congestion mitigation and driver\nattitudes to advice. We show that our residual policies can be personalized by\nconditioning them on an inferred driver trait that is learned in an\nunsupervised manner with a variational autoencoder. Our policies are trained in\nsimulation with our novel instruction adherence driver model, and evaluated in\nsimulation and through a user study (N=16) to capture the sentiments of human\ndrivers. Our results show that our approaches successfully mitigate congestion\nwhile adapting to different driver behaviors, with up to 20% and 40%\nimprovement as measured by a combination metric of speed and deviations in\nspeed across time over baselines in our simulation tests and user study,\nrespectively. Our user study further shows that our policies are\nhuman-compatible and personalize to drivers.",
      "tldr_zh": "该研究提出了一种合作咨询残差策略（cooperative advisory residual policies），旨在通过一辆带有驾驶员的车辆缓解交通拥堵，同时考虑驾驶员行为的不确定性和对指令的反应。策略使用改进的奖励函数，强调拥堵缓解和驾驶员态度，并通过变分自编码器（variational autoencoder）在无监督方式下推断驾驶员特征，实现个性化咨询。在模拟环境和用户研究（N=16）中，策略相对于基线模型改善了速度和速度偏差组合指标，分别达20%和40%，证明其能有效适应不同驾驶员行为并提供人性化的用户体验。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00553v1",
      "published_date": "2024-06-30 01:10:13 UTC",
      "updated_date": "2024-06-30 01:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:14:45.609937"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 39,
  "processed_papers_count": 39,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T02:15:06.241536"
}