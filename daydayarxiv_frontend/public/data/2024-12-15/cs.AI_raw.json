[
  {
    "arxiv_id": "2412.12215v1",
    "title": "Imagined Speech State Classification for Robust Brain-Computer Interface",
    "authors": [
      "Byung-Kwan Ko",
      "Jun-Young Kim",
      "Seo-Hyun Lee"
    ],
    "abstract": "This study examines the effectiveness of traditional machine learning\nclassifiers versus deep learning models for detecting the imagined speech using\nelectroencephalogram data. Specifically, we evaluated conventional machine\nlearning techniques such as CSP-SVM and LDA-SVM classifiers alongside deep\nlearning architectures such as EEGNet, ShallowConvNet, and DeepConvNet. Machine\nlearning classifiers exhibited significantly lower precision and recall,\nindicating limited feature extraction capabilities and poor generalization\nbetween imagined speech and idle states. In contrast, deep learning models,\nparticularly EEGNet, achieved the highest accuracy of 0.7080 and an F1 score of\n0.6718, demonstrating their enhanced ability in automatic feature extraction\nand representation learning, essential for capturing complex neurophysiological\npatterns. These findings highlight the limitations of conventional machine\nlearning approaches in brain-computer interface (BCI) applications and advocate\nfor adopting deep learning methodologies to achieve more precise and reliable\nclassification of detecting imagined speech. This foundational research\ncontributes to the development of imagined speech-based BCI systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12215v1",
    "published_date": "2024-12-15 23:59:55 UTC",
    "updated_date": "2024-12-15 23:59:55 UTC"
  },
  {
    "arxiv_id": "2412.11337v1",
    "title": "Modality-Driven Design for Multi-Step Dexterous Manipulation: Insights from Neuroscience",
    "authors": [
      "Naoki Wake",
      "Atsushi Kanehira",
      "Daichi Saito",
      "Jun Takamatsu",
      "Kazuhiro Sasabuchi",
      "Hideki Koike",
      "Katsushi Ikeuchi"
    ],
    "abstract": "Multi-step dexterous manipulation is a fundamental skill in household\nscenarios, yet remains an underexplored area in robotics. This paper proposes a\nmodular approach, where each step of the manipulation process is addressed with\ndedicated policies based on effective modality input, rather than relying on a\nsingle end-to-end model. To demonstrate this, a dexterous robotic hand performs\na manipulation task involving picking up and rotating a box. Guided by insights\nfrom neuroscience, the task is decomposed into three sub-skills, 1)reaching,\n2)grasping and lifting, and 3)in-hand rotation, based on the dominant sensory\nmodalities employed in the human brain. Each sub-skill is addressed using\ndistinct methods from a practical perspective: a classical controller, a\nVision-Language-Action model, and a reinforcement learning policy with force\nfeedback, respectively. We tested the pipeline on a real robot to demonstrate\nthe feasibility of our approach. The key contribution of this study lies in\npresenting a neuroscience-inspired, modality-driven methodology for multi-step\ndexterous manipulation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 5 figures, 2 tables. Last updated on December 14th, 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.11337v1",
    "published_date": "2024-12-15 23:05:16 UTC",
    "updated_date": "2024-12-15 23:05:16 UTC"
  },
  {
    "arxiv_id": "2412.11333v1",
    "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models",
    "authors": [
      "Xiaochen Zhu",
      "Georgi Karadzhov",
      "Chenxi Whitehouse",
      "Andreas Vlachos"
    ],
    "abstract": "Diffusion models have shown promise in text generation but often struggle\nwith generating long, coherent, and contextually accurate text. Token-level\ndiffusion overlooks word-order dependencies and enforces short output windows,\nwhile passage-level diffusion struggles with learning robust representation for\nlong-form text. To address these challenges, we propose Segment-Level Diffusion\n(SLD), a framework that enhances diffusion-based text generation through text\nsegmentation, robust representation training with adversarial and contrastive\nlearning, and improved latent-space guidance. By segmenting long-form outputs\ninto separate latent representations and decoding them with an autoregressive\ndecoder, SLD simplifies diffusion predictions and improves scalability.\nExperiments on XSum, ROCStories, DialogSum, and DeliData demonstrate that SLD\nachieves competitive or superior performance in fluency, coherence, and\ncontextual compatibility across automatic and human evaluation metrics\ncomparing with other diffusion and autoregressive baselines. Ablation studies\nfurther validate the effectiveness of our segmentation and representation\nlearning strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11333v1",
    "published_date": "2024-12-15 22:47:44 UTC",
    "updated_date": "2024-12-15 22:47:44 UTC"
  },
  {
    "arxiv_id": "2412.19821v1",
    "title": "Nanoscaling Floating-Point (NxFP): NanoMantissa, Adaptive Microexponents, and Code Recycling for Direct-Cast Compression of Large Language Models",
    "authors": [
      "Yun-Chen Lo",
      "Gu-Yeon Wei",
      "David Brooks"
    ],
    "abstract": "As cutting-edge large language models (LLMs) continue to transform various\nindustries, their fast-growing model size and sequence length have led to\nmemory traffic and capacity challenges. Recently, AMD, Arm, Intel, Meta,\nMicrosoft, NVIDIA, and Qualcomm have proposed a Microscaling standard (Mx),\nwhich augments block floating-point with microexponents to achieve promising\nperplexity-to-footprint trade-offs. However, the Microscaling suffers from\nsignificant perplexity degradation on modern LLMs with less than six bits. This\npaper profiles modern LLMs and identifies three main challenges of low-bit\nMicroscaling format, i.e., inaccurate tracking of outliers, vacant quantization\nlevels, and wasted binary code. In response, Nanoscaling (NxFP) proposes three\ntechniques, i.e., NanoMantissa, Adaptive Microexponent, and Code Recycling to\nenable better accuracy and smaller memory footprint than state-of-the-art MxFP.\nExperimental results on direct-cast inference across various modern LLMs\ndemonstrate that our proposed methods outperform state-of-the-art MxFP by up to\n0.64 in perplexity and by up to 30% in accuracy on MMLU benchmarks.\nFurthermore, NxFP reduces memory footprint by up to 16% while achieving\ncomparable perplexity as MxFP.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "I.2.7; E.4"
    ],
    "primary_category": "cs.AR",
    "comment": "12 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.19821v1",
    "published_date": "2024-12-15 22:18:20 UTC",
    "updated_date": "2024-12-15 22:18:20 UTC"
  },
  {
    "arxiv_id": "2412.12212v1",
    "title": "Finding a Wolf in Sheep's Clothing: Combating Adversarial Text-To-Image Prompts with Text Summarization",
    "authors": [
      "Portia Cooper",
      "Harshita Narnoli",
      "Mihai Surdeanu"
    ],
    "abstract": "Text-to-image models are vulnerable to the stepwise \"Divide-and-Conquer\nAttack\" (DACA) that utilize a large language model to obfuscate inappropriate\ncontent in prompts by wrapping sensitive text in a benign narrative. To\nmitigate stepwise DACA attacks, we propose a two-layer method involving text\nsummarization followed by binary classification. We assembled the Adversarial\nText-to-Image Prompt (ATTIP) dataset ($N=940$), which contained DACA-obfuscated\nand non-obfuscated prompts. From the ATTIP dataset, we created two summarized\nversions: one generated by a small encoder model and the other by a large\nlanguage model. Then, we used an encoder classifier and a GPT-4o classifier to\nperform content moderation on the summarized and unsummarized prompts. When\ncompared with a classifier that operated over the unsummarized data, our method\nimproved F1 score performance by 31%. Further, the highest recorded F1 score\nachieved (98%) was produced by the encoder classifier on a summarized ATTIP\nvariant. This study indicates that pre-classification text summarization can\ninoculate content detection models against stepwise DACA obfuscations.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12212v1",
    "published_date": "2024-12-15 22:12:36 UTC",
    "updated_date": "2024-12-15 22:12:36 UTC"
  },
  {
    "arxiv_id": "2412.11318v1",
    "title": "Generics are puzzling. Can language models find the missing piece?",
    "authors": [
      "Gustavo Cilleruelo Calder√≥n",
      "Emily Allaway",
      "Barry Haddow",
      "Alexandra Birch"
    ],
    "abstract": "Generic sentences express generalisations about the world without explicit\nquantification. Although generics are central to everyday communication,\nbuilding a precise semantic framework has proven difficult, in part because\nspeakers use generics to generalise properties with widely different\nstatistical prevalence. In this work, we study the implicit quantification and\ncontext-sensitivity of generics by leveraging language models as models of\nlanguage. We create ConGen, a dataset of 2873 naturally occurring generic and\nquantified sentences in context, and define p-acceptability, a metric based on\nsurprisal that is sensitive to quantification. Our experiments show generics\nare more context-sensitive than determiner quantifiers and about 20% of\nnaturally occurring generics we analyze express weak generalisations. We also\nexplore how human biases in stereotypes can be observed in language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at CoLing 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.11318v1",
    "published_date": "2024-12-15 21:30:21 UTC",
    "updated_date": "2024-12-15 21:30:21 UTC"
  },
  {
    "arxiv_id": "2412.11304v2",
    "title": "An Empirical Study of Fault Localisation Techniques for Deep Learning",
    "authors": [
      "Nargiz Humbatova",
      "Jinhan Kim",
      "Gunel Jahangirova",
      "Shin Yoo",
      "Paolo Tonella"
    ],
    "abstract": "With the increased popularity of Deep Neural Networks (DNNs), increases also\nthe need for tools to assist developers in the DNN implementation, testing and\ndebugging process. Several approaches have been proposed that automatically\nanalyse and localise potential faults in DNNs under test. In this work, we\nevaluate and compare existing state-of-the-art fault localisation techniques,\nwhich operate based on both dynamic and static analysis of the DNN. The\nevaluation is performed on a benchmark consisting of both real faults obtained\nfrom bug reporting platforms and faulty models produced by a mutation tool. Our\nfindings indicate that the usage of a single, specific ground truth (e.g., the\nhuman defined one) for the evaluation of DNN fault localisation tools results\nin pretty low performance (maximum average recall of 0.31 and precision of\n0.23). However, such figures increase when considering alternative, equivalent\npatches that exist for a given faulty DNN. Results indicate that \\dfd is the\nmost effective tool, achieving an average recall of 0.61 and precision of 0.41\non our benchmark.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11304v2",
    "published_date": "2024-12-15 20:47:03 UTC",
    "updated_date": "2024-12-17 10:07:46 UTC"
  },
  {
    "arxiv_id": "2412.11301v1",
    "title": "Semi-Implicit Neural Ordinary Differential Equations",
    "authors": [
      "Hong Zhang",
      "Ying Liu",
      "Romit Maulik"
    ],
    "abstract": "Classical neural ODEs trained with explicit methods are intrinsically limited\nby stability, crippling their efficiency and robustness for stiff learning\nproblems that are common in graph learning and scientific machine learning. We\npresent a semi-implicit neural ODE approach that exploits the partitionable\nstructure of the underlying dynamics. Our technique leads to an implicit neural\nnetwork with significant computational advantages over existing approaches\nbecause of enhanced stability and efficient linear solves during time\nintegration. We show that our approach outperforms existing approaches on a\nvariety of applications including graph classification and learning complex\ndynamical systems. We also demonstrate that our approach can train challenging\nneural ODEs where both explicit methods and fully implicit methods are\nintractable.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "K.3.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11301v1",
    "published_date": "2024-12-15 20:21:02 UTC",
    "updated_date": "2024-12-15 20:21:02 UTC"
  },
  {
    "arxiv_id": "2412.11293v2",
    "title": "A Comparative Study on Dynamic Graph Embedding based on Mamba and Transformers",
    "authors": [
      "Ashish Parmanand Pandey",
      "Alan John Varghese",
      "Sarang Patil",
      "Mengjia Xu"
    ],
    "abstract": "Dynamic graph embedding has emerged as an important technique for modeling\ncomplex time-evolving networks across diverse domains. While transformer-based\nmodels have shown promise in capturing long-range dependencies in temporal\ngraph data, they face scalability challenges due to quadratic computational\ncomplexity. This study presents a comparative analysis of dynamic graph\nembedding approaches using transformers and the recently proposed Mamba\narchitecture, a state-space model with linear complexity. We introduce three\nnovel models: TransformerG2G augment with graph convolutional networks,\n\\mathcal{DG}-Mamba, and \\mathcal{GDG}-Mamba with graph isomorphism network edge\nconvolutions. Our experiments on multiple benchmark datasets demonstrate that\nMamba-based models achieve comparable or superior performance to\ntransformer-based approaches in link prediction tasks while offering\nsignificant computational efficiency gains on longer sequences. Notably,\n\\mathcal{DG}-Mamba variants consistently outperform transformer-based models on\ndatasets with high temporal variability, such as UCI, Bitcoin, and Reality\nMining, while maintaining competitive performance on more stable graphs like\nSBM. We provide insights into the learned temporal dependencies through\nanalysis of attention weights and state matrices, revealing the models' ability\nto capture complex temporal patterns. By effectively combining state-space\nmodels with graph neural networks, our work addresses key limitations of\nprevious approaches and contributes to the growing body of research on\nefficient temporal graph representation learning. These findings offer\npromising directions for scaling dynamic graph embedding to larger, more\ncomplex real-world networks, potentially enabling new applications in areas\nsuch as social network analysis, financial modeling, and biological system\ndynamics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.11293v2",
    "published_date": "2024-12-15 19:56:56 UTC",
    "updated_date": "2025-05-12 17:41:35 UTC"
  },
  {
    "arxiv_id": "2412.15255v1",
    "title": "Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation",
    "authors": [
      "Jonibek Mansurov",
      "Akhmed Sakip",
      "Alham Fikri Aji"
    ],
    "abstract": "In this paper, we show that knowledge distillation can be subverted to\nmanipulate language model benchmark scores, revealing a critical vulnerability\nin current evaluation practices. We introduce \"Data Laundering,\" a three-phase\nprocess analogous to financial money laundering, that enables the covert\ntransfer of benchmark-specific knowledge through seemingly legitimate\nintermediate training steps. Through extensive experiments with a 2-layer BERT\nstudent model, we show how this approach can achieve substantial improvements\nin benchmark accuracy (up to 75\\% on GPQA) without developing genuine reasoning\ncapabilities. Notably, this method can be exploited intentionally or even\nunintentionally, as researchers may inadvertently adopt this method that\ninflates scores using knowledge distillation without realizing the\nimplications. While our findings demonstrate the effectiveness of this\ntechnique, we present them as a cautionary tale highlighting the urgent need\nfor more robust evaluation methods in AI. This work aims to contribute to the\nongoing discussion about evaluation integrity in AI development and the need\nfor benchmarks that more accurately reflect true model capabilities. The code\nis available at \\url{https://github.com/mbzuai-nlp/data_laundering}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.15255v1",
    "published_date": "2024-12-15 19:38:48 UTC",
    "updated_date": "2024-12-15 19:38:48 UTC"
  },
  {
    "arxiv_id": "2412.11286v1",
    "title": "Detecting Daily Living Gait Amid Huntington's Disease Chorea using a Foundation Deep Learning Model",
    "authors": [
      "Dafna Schwartz",
      "Lori Quinn",
      "Nora E. Fritz",
      "Lisa M. Muratori",
      "Jeffery M. Hausdorff",
      "Ran Gilad Bachrach"
    ],
    "abstract": "Wearable sensors offer a non-invasive way to collect physical activity (PA)\ndata, with walking as a key component. Existing models often struggle to detect\ngait bouts in individuals with neurodegenerative diseases (NDDs) involving\ninvoluntary movements. We developed J-Net, a deep learning model inspired by\nU-Net, which uses a pre-trained self-supervised foundation model fine-tuned\nwith Huntington`s disease (HD) in-lab data and paired with a segmentation head\nfor gait detection. J-Net processes wrist-worn accelerometer data to detect\ngait during daily living. We evaluated J-Net on in-lab and daily-living data\nfrom HD, Parkinson`s disease (PD), and controls. J-Net achieved a 10-percentage\npoint improvement in ROC-AUC for HD over existing methods, reaching 0.97 for\nin-lab data. In daily-living environments, J-Net estimates showed no\nsignificant differences in median daily walking time between HD and controls (p\n= 0.23), in contrast to other models, which indicated counterintuitive results\n(p < 0.005). Walking time measured by J-Net correlated with the UHDRS-TMS\nclinical severity score (r=-0.52; p=0.02), confirming its clinical relevance.\nFine-tuning J-Net on PD data also improved gait detection over current methods.\nJ-Net`s architecture effectively addresses the challenges of gait detection in\nsevere chorea and offers robust performance in daily living. The dataset and\nJ-Net model are publicly available, providing a resource for further research\ninto NDD-related gait impairments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11286v1",
    "published_date": "2024-12-15 19:19:39 UTC",
    "updated_date": "2024-12-15 19:19:39 UTC"
  },
  {
    "arxiv_id": "2412.11279v1",
    "title": "VividFace: A Diffusion-Based Hybrid Framework for High-Fidelity Video Face Swapping",
    "authors": [
      "Hao Shao",
      "Shulun Wang",
      "Yang Zhou",
      "Guanglu Song",
      "Dailan He",
      "Shuo Qin",
      "Zhuofan Zong",
      "Bingqi Ma",
      "Yu Liu",
      "Hongsheng Li"
    ],
    "abstract": "Video face swapping is becoming increasingly popular across various\napplications, yet existing methods primarily focus on static images and\nstruggle with video face swapping because of temporal consistency and complex\nscenarios. In this paper, we present the first diffusion-based framework\nspecifically designed for video face swapping. Our approach introduces a novel\nimage-video hybrid training framework that leverages both abundant static image\ndata and temporal video sequences, addressing the inherent limitations of\nvideo-only training. The framework incorporates a specially designed diffusion\nmodel coupled with a VidFaceVAE that effectively processes both types of data\nto better maintain temporal coherence of the generated videos. To further\ndisentangle identity and pose features, we construct the Attribute-Identity\nDisentanglement Triplet (AIDT) Dataset, where each triplet has three face\nimages, with two images sharing the same pose and two sharing the same\nidentity. Enhanced with a comprehensive occlusion augmentation, this dataset\nalso improves robustness against occlusions. Additionally, we integrate 3D\nreconstruction techniques as input conditioning to our network for handling\nlarge pose variations. Extensive experiments demonstrate that our framework\nachieves superior performance in identity preservation, temporal consistency,\nand visual quality compared to existing methods, while requiring fewer\ninference steps. Our approach effectively mitigates key challenges in video\nface swapping, including temporal flickering, identity preservation, and\nrobustness to occlusions and pose variations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "project page: https://hao-shao.com/projects/vividface.html",
    "pdf_url": "http://arxiv.org/pdf/2412.11279v1",
    "published_date": "2024-12-15 18:58:32 UTC",
    "updated_date": "2024-12-15 18:58:32 UTC"
  },
  {
    "arxiv_id": "2412.11277v1",
    "title": "Macro2Micro: Cross-modal Magnetic Resonance Imaging Synthesis Leveraging Multi-scale Brain Structures",
    "authors": [
      "Sooyoung Kim",
      "Joonwoo Kwon",
      "Junbeom Kwon",
      "Sangyoon Bae",
      "Yuewei Lin",
      "Shinjae Yoo",
      "Jiook Cha"
    ],
    "abstract": "Spanning multiple scales-from macroscopic anatomy down to intricate\nmicroscopic architecture-the human brain exemplifies a complex system that\ndemands integrated approaches to fully understand its complexity. Yet, mapping\nnonlinear relationships between these scales remains challenging due to\ntechnical limitations and the high cost of multimodal Magnetic Resonance\nImaging (MRI) acquisition. Here, we introduce Macro2Micro, a deep learning\nframework that predicts brain microstructure from macrostructure using a\nGenerative Adversarial Network (GAN). Grounded in the scale-free, self-similar\nnature of brain organization-where microscale information can be inferred from\nmacroscale patterns-Macro2Micro explicitly encodes multiscale brain\nrepresentations into distinct processing branches. To further enhance image\nfidelity and suppress artifacts, we propose a simple yet effective auxiliary\ndiscriminator and learning objective. Our results show that Macro2Micro\nfaithfully translates T1-weighted MRIs into corresponding Fractional Anisotropy\n(FA) images, achieving a 6.8% improvement in the Structural Similarity Index\nMeasure (SSIM) compared to previous methods, while preserving the individual\nneurobiological characteristics.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "The code will be made available upon acceptance",
    "pdf_url": "http://arxiv.org/pdf/2412.11277v1",
    "published_date": "2024-12-15 18:49:20 UTC",
    "updated_date": "2024-12-15 18:49:20 UTC"
  },
  {
    "arxiv_id": "2412.11276v2",
    "title": "Wearable Accelerometer Foundation Models for Health via Knowledge Distillation",
    "authors": [
      "Salar Abbaspourazad",
      "Anshuman Mishra",
      "Joseph Futoma",
      "Andrew C. Miller",
      "Ian Shapiro"
    ],
    "abstract": "Modern wearable devices can conveniently record various biosignals in the\nmany different environments of daily living, enabling a rich view of individual\nhealth. However, not all biosignals are the same: high-fidelity biosignals,\nsuch as photoplethysmogram (PPG), contain more physiological information, but\nrequire optical sensors with a high power footprint. Alternatively, a\nlower-fidelity biosignal such as accelerometry has a significantly smaller\npower footprint and is available in almost any wearable device. While\naccelerometry is widely used for activity recognition and fitness, it is less\nexplored for health biomarkers and diagnosis. Here, we show that an\naccelerometry foundation model can predict a wide variety of health targets. To\nachieve improved performance, we distill representational knowledge from PPG\nencoders to accelerometery encoders using 20 million minutes of unlabeled data,\ncollected from ~172K participants in the Apple Heart and Movement Study under\ninformed consent. We observe strong cross-modal alignment on unseen data, e.g.,\n99.2% top-1 accuracy for retrieving PPG embeddings from accelerometry\nembeddings. We show that distilled accelerometry encoders have significantly\nmore informative representations compared to self-supervised or supervised\nencoders trained directly on accelerometry data, observed by at least 23%-49%\nimproved performance for predicting heart rate and heart rate variability. We\nalso show that distilled accelerometry encoders are readily predictive of a\nwide array of downstream health targets, i.e., they are generalist foundation\nmodels. We believe accelerometry foundation models for health may unlock new\nopportunities for developing digital biomarkers from any wearable device.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "updated format",
    "pdf_url": "http://arxiv.org/pdf/2412.11276v2",
    "published_date": "2024-12-15 18:48:14 UTC",
    "updated_date": "2025-01-31 17:35:20 UTC"
  },
  {
    "arxiv_id": "2412.11261v1",
    "title": "CATER: Leveraging LLM to Pioneer a Multidimensional, Reference-Independent Paradigm in Translation Quality Evaluation",
    "authors": [
      "Kurando IIDA",
      "Kenjiro MIMURA"
    ],
    "abstract": "This paper introduces the Comprehensive AI-assisted Translation Edit Ratio\n(CATER), a novel and fully prompt-driven framework for evaluating machine\ntranslation (MT) quality. Leveraging large language models (LLMs) via a\ncarefully designed prompt-based protocol, CATER expands beyond traditional\nreference-bound metrics, offering a multidimensional, reference-independent\nevaluation that addresses linguistic accuracy, semantic fidelity, contextual\ncoherence, stylistic appropriateness, and information completeness. CATER's\nunique advantage lies in its immediate implementability: by providing the\nsource and target texts along with a standardized prompt, an LLM can rapidly\nidentify errors, quantify edit effort, and produce category-level and overall\nscores. This approach eliminates the need for pre-computed references or\ndomain-specific resources, enabling instant adaptation to diverse languages,\ngenres, and user priorities through adjustable weights and prompt\nmodifications. CATER's LLM-enabled strategy supports more nuanced assessments,\ncapturing phenomena such as subtle omissions, hallucinations, and\ndiscourse-level shifts that increasingly challenge contemporary MT systems. By\nuniting the conceptual rigor of frameworks like MQM and DQF with the\nscalability and flexibility of LLM-based evaluation, CATER emerges as a\nvaluable tool for researchers, developers, and professional translators\nworldwide. The framework and example prompts are openly available, encouraging\ncommunity-driven refinement and further empirical validation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "17pages,1sample prompt",
    "pdf_url": "http://arxiv.org/pdf/2412.11261v1",
    "published_date": "2024-12-15 17:45:34 UTC",
    "updated_date": "2024-12-15 17:45:34 UTC"
  },
  {
    "arxiv_id": "2412.11258v1",
    "title": "GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs",
    "authors": [
      "Xinli Xu",
      "Wenhang Ge",
      "Dicong Qiu",
      "ZhiFei Chen",
      "Dongyu Yan",
      "Zhuoyun Liu",
      "Haoyu Zhao",
      "Hanfeng Zhao",
      "Shunsi Zhang",
      "Junwei Liang",
      "Ying-Cong Chen"
    ],
    "abstract": "Estimating physical properties for visual data is a crucial task in computer\nvision, graphics, and robotics, underpinning applications such as augmented\nreality, physical simulation, and robotic grasping. However, this area remains\nunder-explored due to the inherent ambiguities in physical property estimation.\nTo address these challenges, we introduce GaussianProperty, a training-free\nframework that assigns physical properties of materials to 3D Gaussians.\nSpecifically, we integrate the segmentation capability of SAM with the\nrecognition capability of GPT-4V(ision) to formulate a global-local physical\nproperty reasoning module for 2D images. Then we project the physical\nproperties from multi-view 2D images to 3D Gaussians using a voting strategy.\nWe demonstrate that 3D Gaussians with physical property annotations enable\napplications in physics-based dynamic simulation and robotic grasping. For\nphysics-based dynamic simulation, we leverage the Material Point Method (MPM)\nfor realistic dynamic simulation. For robot grasping, we develop a grasping\nforce prediction strategy that estimates a safe force range required for object\ngrasping based on the estimated physical properties. Extensive experiments on\nmaterial segmentation, physics-based dynamic simulation, and robotic grasping\nvalidate the effectiveness of our proposed method, highlighting its crucial\nrole in understanding physical properties from visual data. Online demo, code,\nmore cases and annotated datasets are available on\n\\href{https://Gaussian-Property.github.io}{this https URL}.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "17 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.11258v1",
    "published_date": "2024-12-15 17:44:10 UTC",
    "updated_date": "2024-12-15 17:44:10 UTC"
  },
  {
    "arxiv_id": "2412.11255v1",
    "title": "Do Tutors Learn from Equity Training and Can Generative AI Assess It?",
    "authors": [
      "Danielle R. Thomas",
      "Conrad Borchers",
      "Sanjit Kakarla",
      "Jionghao Lin",
      "Shambhavi Bhushan",
      "Boyuan Guo",
      "Erin Gatz",
      "Kenneth R. Koedinger"
    ],
    "abstract": "Equity is a core concern of learning analytics. However, applications that\nteach and assess equity skills, particularly at scale are lacking, often due to\nbarriers in evaluating language. Advances in generative AI via large language\nmodels (LLMs) are being used in a wide range of applications, with this present\nwork assessing its use in the equity domain. We evaluate tutor performance\nwithin an online lesson on enhancing tutors' skills when responding to students\nin potentially inequitable situations. We apply a mixed-method approach to\nanalyze the performance of 81 undergraduate remote tutors. We find marginally\nsignificant learning gains with increases in tutors' self-reported confidence\nin their knowledge in responding to middle school students experiencing\npossible inequities from pretest to posttest. Both GPT-4o and GPT-4-turbo\ndemonstrate proficiency in assessing tutors ability to predict and explain the\nbest approach. Balancing performance, efficiency, and cost, we determine that\nfew-shot learning using GPT-4o is the preferred model. This work makes\navailable a dataset of lesson log data, tutor responses, rubrics for human\nannotation, and generative AI prompts. Future work involves leveling the\ndifficulty among scenarios and enhancing LLM prompts for large-scale grading\nand assessment.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Full research paper accepted to Learning Analytics and Knowledge (LAK\n  2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.11255v1",
    "published_date": "2024-12-15 17:36:40 UTC",
    "updated_date": "2024-12-15 17:36:40 UTC"
  },
  {
    "arxiv_id": "2412.11253v1",
    "title": "Are Expressive Models Truly Necessary for Offline RL?",
    "authors": [
      "Guan Wang",
      "Haoyi Niu",
      "Jianxiong Li",
      "Li Jiang",
      "Jianming Hu",
      "Xianyuan Zhan"
    ],
    "abstract": "Among various branches of offline reinforcement learning (RL) methods,\ngoal-conditioned supervised learning (GCSL) has gained increasing popularity as\nit formulates the offline RL problem as a sequential modeling task, therefore\nbypassing the notoriously difficult credit assignment challenge of value\nlearning in conventional RL paradigm. Sequential modeling, however, requires\ncapturing accurate dynamics across long horizons in trajectory data to ensure\nreasonable policy performance. To meet this requirement, leveraging large,\nexpressive models has become a popular choice in recent literature, which,\nhowever, comes at the cost of significantly increased computation and inference\nlatency. Contradictory yet promising, we reveal that lightweight models as\nsimple as shallow 2-layer MLPs, can also enjoy accurate dynamics consistency\nand significantly reduced sequential modeling errors against large expressive\nmodels by adopting a simple recursive planning scheme: recursively planning\ncoarse-grained future sub-goals based on current and target information, and\nthen executes the action with a goal-conditioned policy learned from data\nrela-beled with these sub-goal ground truths. We term our method Recursive\nSkip-Step Planning (RSP). Simple yet effective, RSP enjoys great efficiency\nimprovements thanks to its lightweight structure, and substantially outperforms\nexisting methods, reaching new SOTA performances on the D4RL benchmark,\nespecially in multi-stage long-horizon tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Instead of relying on expressive models, shallow MLPs can also excel\n  in long sequential decision-making tasks with Recursive Skip-Step Planning\n  (RSP)",
    "pdf_url": "http://arxiv.org/pdf/2412.11253v1",
    "published_date": "2024-12-15 17:33:56 UTC",
    "updated_date": "2024-12-15 17:33:56 UTC"
  },
  {
    "arxiv_id": "2412.11250v1",
    "title": "Beyond Discrete Personas: Personality Modeling Through Journal Intensive Conversations",
    "authors": [
      "Sayantan Pal",
      "Souvik Das",
      "Rohini K. Srihari"
    ],
    "abstract": "Large Language Models (LLMs) have significantly improved personalized\nconversational capabilities. However, existing datasets like Persona Chat,\nSynthetic Persona Chat, and Blended Skill Talk rely on static, predefined\npersonas. This approach often results in dialogues that fail to capture human\npersonalities' fluid and evolving nature. To overcome these limitations, we\nintroduce a novel dataset with around 400,000 dialogues and a framework for\ngenerating personalized conversations using long-form journal entries from\nReddit. Our approach clusters journal entries for each author and filters them\nby selecting the most representative cluster, ensuring that the retained\nentries best reflect the author's personality. We further refine the data by\ncapturing the Big Five personality traits --openness, conscientiousness,\nextraversion, agreeableness, and neuroticism --ensuring that dialogues\nauthentically reflect an individual's personality. Using Llama 3 70B, we\ngenerate high-quality, personality-rich dialogues grounded in these journal\nentries. Fine-tuning models on this dataset leads to an 11% improvement in\ncapturing personality traits on average, outperforming existing approaches in\ngenerating more coherent and personality-driven dialogues.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.11250v1",
    "published_date": "2024-12-15 17:16:08 UTC",
    "updated_date": "2024-12-15 17:16:08 UTC"
  },
  {
    "arxiv_id": "2412.11245v1",
    "title": "Transformer-Based Bearing Fault Detection using Temporal Decomposition Attention Mechanism",
    "authors": [
      "Marzieh Mirzaeibonehkhater",
      "Mohammad Ali Labbaf-Khaniki",
      "Mohammad Manthouri"
    ],
    "abstract": "Bearing fault detection is a critical task in predictive maintenance, where\naccurate and timely fault identification can prevent costly downtime and\nequipment damage. Traditional attention mechanisms in Transformer neural\nnetworks often struggle to capture the complex temporal patterns in bearing\nvibration data, leading to suboptimal performance. To address this limitation,\nwe propose a novel attention mechanism, Temporal Decomposition Attention (TDA),\nwhich combines temporal bias encoding with seasonal-trend decomposition to\ncapture both long-term dependencies and periodic fluctuations in time series\ndata. Additionally, we incorporate the Hull Exponential Moving Average (HEMA)\nfor feature extraction, enabling the model to effectively capture meaningful\ncharacteristics from the data while reducing noise. Our approach integrates TDA\ninto the Transformer architecture, allowing the model to focus separately on\nthe trend and seasonal components of the data. Experimental results on the Case\nWestern Reserve University (CWRU) bearing fault detection dataset demonstrate\nthat our approach outperforms traditional attention mechanisms and achieves\nstate-of-the-art performance in terms of accuracy and interpretability. The\nHEMA-Transformer-TDA model achieves an accuracy of 98.1%, with exceptional\nprecision, recall, and F1-scores, demonstrating its effectiveness in bearing\nfault detection and its potential for application in other time series tasks\nwith seasonal patterns or trends.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11245v1",
    "published_date": "2024-12-15 16:51:31 UTC",
    "updated_date": "2024-12-15 16:51:31 UTC"
  },
  {
    "arxiv_id": "2412.11242v2",
    "title": "TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs",
    "authors": [
      "Lanxiang Hu",
      "Tajana Rosing",
      "Hao Zhang"
    ],
    "abstract": "Specializing large language models (LLMs) for local deployment in\ndomain-specific use cases is necessary for strong performance while meeting\nlatency and privacy constraints. However, conventional task-specific adaptation\napproaches do not show simultaneous memory saving and inference speedup at\ndeployment time. Practical compression techniques like quantization and pruning\nrequire dedicated hardware or kernel support to achieve measured inference\nspeedup. We develop TrimLLM based on the layer-wise specialization phenomenon\nwe empirically observed and verified on contemporary LLMs. TrimLLM reduces the\ndepth of LLMs via progressive layer dropping. We show it retains LLMs' capacity\nin specific domains and achieves inference speedup irrespective of hardware and\ndeep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for\ninference; models adapted on medical, legal, and financial datasets all\ndemonstrate $2.1-5.7\\times$ inference speedup on consumer GPUs and up to\n$3.1\\times$ speedup on A100 when compared to state-of-the-art model compression\nalgorithms, with no loss in accuracy at 50$\\sim$60\\% model compression ratio.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11242v2",
    "published_date": "2024-12-15 16:47:16 UTC",
    "updated_date": "2024-12-19 10:33:13 UTC"
  },
  {
    "arxiv_id": "2412.11239v2",
    "title": "Learning Set Functions with Implicit Differentiation",
    "authors": [
      "G√∂zde √ñzcan",
      "Chengzhi Shi",
      "Stratis Ioannidis"
    ],
    "abstract": "Ou et al. (2022) introduce the problem of learning set functions from data\ngenerated by a so-called optimal subset oracle. Their approach approximates the\nunderlying utility function with an energy-based model, whose parameters are\nestimated via mean-field variational inference. Ou et al. (2022) show this\nreduces to fixed point iterations; however, as the number of iterations\nincreases, automatic differentiation quickly becomes computationally\nprohibitive due to the size of the Jacobians that are stacked during\nbackpropagation. We address this challenge with implicit differentiation and\nexamine the convergence conditions for the fixed-point iterations. We\nempirically demonstrate the efficiency of our method on synthetic and\nreal-world subset selection applications including product recommendation, set\nanomaly detection and compound selection tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 1 figure, extended version of the AAAI 2025 paper with the\n  same title",
    "pdf_url": "http://arxiv.org/pdf/2412.11239v2",
    "published_date": "2024-12-15 16:42:09 UTC",
    "updated_date": "2024-12-17 11:14:52 UTC"
  },
  {
    "arxiv_id": "2412.11228v1",
    "title": "Uni-AdaFocus: Spatial-temporal Dynamic Computation for Video Recognition",
    "authors": [
      "Yulin Wang",
      "Haoji Zhang",
      "Yang Yue",
      "Shiji Song",
      "Chao Deng",
      "Junlan Feng",
      "Gao Huang"
    ],
    "abstract": "This paper presents a comprehensive exploration of the phenomenon of data\nredundancy in video understanding, with the aim to improve computational\nefficiency. Our investigation commences with an examination of spatial\nredundancy, which refers to the observation that the most informative region in\neach video frame usually corresponds to a small image patch, whose shape, size\nand location shift smoothly across frames. Motivated by this phenomenon, we\nformulate the patch localization problem as a dynamic decision task, and\nintroduce a spatially adaptive video recognition approach, termed AdaFocus. In\nspecific, a lightweight encoder is first employed to quickly process the full\nvideo sequence, whose features are then utilized by a policy network to\nidentify the most task-relevant regions. Subsequently, the selected patches are\ninferred by a high-capacity deep network for the final prediction. The full\nmodel can be trained in end-to-end conveniently. Furthermore, AdaFocus can be\nextended by further considering temporal and sample-wise redundancies, i.e.,\nallocating the majority of computation to the most task-relevant frames, and\nminimizing the computation spent on relatively \"easier\" videos. Our resulting\napproach, Uni-AdaFocus, establishes a comprehensive framework that seamlessly\nintegrates spatial, temporal, and sample-wise dynamic computation, while it\npreserves the merits of AdaFocus in terms of efficient end-to-end training and\nhardware friendliness. In addition, Uni-AdaFocus is general and flexible as it\nis compatible with off-the-shelf efficient backbones (e.g., TSM and X3D), which\ncan be readily deployed as our feature extractor, yielding a significantly\nimproved computational efficiency. Empirically, extensive experiments based on\nseven benchmark datasets and three application scenarios substantiate that\nUni-AdaFocus is considerably more efficient than the competitive baselines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IEEE TPAMI. Journal version of arXiv:2105.03245\n  (AdaFocusV1, ICCV 2021 Oral), arXiv:2112.14238 (AdaFocusV2, CVPR 2022), and\n  arXiv:2209.13465 (AdaFocusV3, ECCV 2022). Code and pre-trained models:\n  https://github.com/LeapLabTHU/Uni-AdaFocus",
    "pdf_url": "http://arxiv.org/pdf/2412.11228v1",
    "published_date": "2024-12-15 15:51:44 UTC",
    "updated_date": "2024-12-15 15:51:44 UTC"
  },
  {
    "arxiv_id": "2412.11216v2",
    "title": "Distribution-Consistency-Guided Multi-modal Hashing",
    "authors": [
      "Jin-Yu Liu",
      "Xian-Ling Mao",
      "Tian-Yi Che",
      "Rong-Cheng Tu"
    ],
    "abstract": "Multi-modal hashing methods have gained popularity due to their fast speed\nand low storage requirements. Among them, the supervised methods demonstrate\nbetter performance by utilizing labels as supervisory signals compared with\nunsupervised methods. Currently, for almost all supervised multi-modal hashing\nmethods, there is a hidden assumption that training sets have no noisy labels.\nHowever, labels are often annotated incorrectly due to manual labeling in\nreal-world scenarios, which will greatly harm the retrieval performance. To\naddress this issue, we first discover a significant distribution consistency\npattern through experiments, i.e., the 1-0 distribution of the presence or\nabsence of each category in the label is consistent with the high-low\ndistribution of similarity scores of the hash codes relative to category\ncenters. Then, inspired by this pattern, we propose a novel\nDistribution-Consistency-Guided Multi-modal Hashing (DCGMH), which aims to\nfilter and reconstruct noisy labels to enhance retrieval performance.\nSpecifically, the proposed method first randomly initializes several category\ncenters, which are used to compute the high-low distribution of similarity\nscores; Noisy and clean labels are then separately filtered out via the\ndiscovered distribution consistency pattern to mitigate the impact of noisy\nlabels; Subsequently, a correction strategy, which is indirectly designed via\nthe distribution consistency pattern, is applied to the filtered noisy labels,\ncorrecting high-confidence ones while treating low-confidence ones as unlabeled\nfor unsupervised learning, thereby further enhancing the model's performance.\nExtensive experiments on three widely used datasets demonstrate the superiority\nof the proposed method compared to state-of-the-art baselines in multi-modal\nretrieval tasks. The code is available at\nhttps://github.com/LiuJinyu1229/DCGMH.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11216v2",
    "published_date": "2024-12-15 15:13:14 UTC",
    "updated_date": "2024-12-19 08:32:20 UTC"
  },
  {
    "arxiv_id": "2412.11215v2",
    "title": "Neural Port-Hamiltonian Differential Algebraic Equations for Compositional Learning of Electrical Networks",
    "authors": [
      "Cyrus Neary",
      "Nathan Tsao",
      "Ufuk Topcu"
    ],
    "abstract": "We develop compositional learning algorithms for coupled dynamical systems.\nWhile deep learning has proven effective at modeling complex relationships from\ndata, compositional couplings between system components typically introduce\nalgebraic constraints on state variables, posing challenges to many existing\ndata-driven approaches to modeling dynamical systems. Towards developing deep\nlearning models for constrained dynamical systems, we introduce neural\nport-Hamiltonian differential algebraic equations (N-PHDAEs), which use neural\nnetworks to parametrize unknown terms in both the differential and algebraic\ncomponents of a port-Hamiltonian DAE. To train these models, we propose an\nalgorithm that uses automatic differentiation to perform index reduction,\nautomatically transforming the neural DAE into an equivalent system of neural\nordinary differential equations (N-ODEs), for which established model inference\nand backpropagation methods exist. The proposed compositional modeling\nframework and learning algorithms may be applied broadly to learn\ncontrol-oriented models of dynamical systems in a variety of application areas,\nhowever, in this work, we focus on their application to the modeling of\nelectrical networks. Experiments simulating the dynamics of nonlinear circuits\nexemplify the benefits of our approach: the proposed N-PHDAE model achieves an\norder of magnitude improvement in prediction accuracy and constraint\nsatisfaction when compared to a baseline N-ODE over long prediction time\nhorizons. We also validate the compositional capabilities of our approach\nthrough experiments on a simulated D.C. microgrid: we train individual N-PHDAE\nmodels for separate grid components, before coupling them to accurately predict\nthe behavior of larger-scale networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11215v2",
    "published_date": "2024-12-15 15:13:11 UTC",
    "updated_date": "2025-04-07 22:47:51 UTC"
  },
  {
    "arxiv_id": "2412.11207v1",
    "title": "ProFe: Communication-Efficient Decentralized Federated Learning via Distillation and Prototypes",
    "authors": [
      "Pedro Miguel S√°nchez S√°nchez",
      "Enrique Tom√°s Mart√≠nez Beltr√°n",
      "Miguel Fern√°ndez Llamas",
      "G√©r√¥me Bovet",
      "Gregorio Mart√≠nez P√©rez",
      "Alberto Huertas Celdr√°n"
    ],
    "abstract": "Decentralized Federated Learning (DFL) trains models in a collaborative and\nprivacy-preserving manner while removing model centralization risks and\nimproving communication bottlenecks. However, DFL faces challenges in efficient\ncommunication management and model aggregation within decentralized\nenvironments, especially with heterogeneous data distributions. Thus, this\npaper introduces ProFe, a novel communication optimization algorithm for DFL\nthat combines knowledge distillation, prototype learning, and quantization\ntechniques. ProFe utilizes knowledge from large local models to train smaller\nones for aggregation, incorporates prototypes to better learn unseen classes,\nand applies quantization to reduce data transmitted during communication\nrounds. The performance of ProFe has been validated and compared to the\nliterature by using benchmark datasets like MNIST, CIFAR10, and CIFAR100.\nResults showed that the proposed algorithm reduces communication costs by up to\n~40-50% while maintaining or improving model performance. In addition, it adds\n~20% training time due to increased complexity, generating a trade-off.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11207v1",
    "published_date": "2024-12-15 14:49:29 UTC",
    "updated_date": "2024-12-15 14:49:29 UTC"
  },
  {
    "arxiv_id": "2412.11203v1",
    "title": "Task-Oriented Dialog Systems for the Senegalese Wolof Language",
    "authors": [
      "Derguene Mbaye",
      "Moussa Diallo"
    ],
    "abstract": "In recent years, we are seeing considerable interest in conversational agents\nwith the rise of large language models (LLMs). Although they offer considerable\nadvantages, LLMs also present significant risks, such as hallucination, which\nhinder their widespread deployment in industry. Moreover, low-resource\nlanguages such as African ones are still underrepresented in these systems\nlimiting their performance in these languages. In this paper, we illustrate a\nmore classical approach based on modular architectures of Task-oriented Dialog\nSystems (ToDS) offering better control over outputs. We propose a chatbot\ngeneration engine based on the Rasa framework and a robust methodology for\nprojecting annotations onto the Wolof language using an in-house machine\ntranslation system. After evaluating a generated chatbot trained on the Amazon\nMassive dataset, our Wolof Intent Classifier performs similarly to the one\nobtained for French, which is a resource-rich language. We also show that this\napproach is extensible to other low-resource languages, thanks to the intent\nclassifier's language-agnostic pipeline, simplifying the design of chatbots in\nthese languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 tables, 6 figures, The 31st International Conference on\n  Computational Linguistics (COLING 2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.11203v1",
    "published_date": "2024-12-15 14:35:49 UTC",
    "updated_date": "2024-12-15 14:35:49 UTC"
  },
  {
    "arxiv_id": "2412.11194v1",
    "title": "SoK: On Closing the Applicability Gap in Automated Vulnerability Detection",
    "authors": [
      "Ezzeldin Shereen",
      "Dan Ristea",
      "Sanyam Vyas",
      "Shae McFadden",
      "Madeleine Dwyer",
      "Chris Hicks",
      "Vasilios Mavroudis"
    ],
    "abstract": "The frequent discovery of security vulnerabilities in both open-source and\nproprietary software underscores the urgent need for earlier detection during\nthe development lifecycle. Initiatives such as DARPA's Artificial Intelligence\nCyber Challenge (AIxCC) aim to accelerate Automated Vulnerability Detection\n(AVD), seeking to address this challenge by autonomously analyzing source code\nto identify vulnerabilities.\n  This paper addresses two primary research questions: (RQ1) How is current AVD\nresearch distributed across its core components? (RQ2) What key areas should\nfuture research target to bridge the gap in the practical applicability of AVD\nthroughout software development? To answer these questions, we conduct a\nsystematization over 79 AVD articles and 17 empirical studies, analyzing them\nacross five core components: task formulation and granularity, input\nprogramming languages and representations, detection approaches and key\nsolutions, evaluation metrics and datasets, and reported performance.\n  Our systematization reveals that the narrow focus of AVD research-mainly on\nspecific tasks and programming languages-limits its practical impact and\noverlooks broader areas crucial for effective, real-world vulnerability\ndetection. We identify significant challenges, including the need for\ndiversified problem formulations, varied detection granularities, broader\nlanguage support, better dataset quality, enhanced reproducibility, and\nincreased practical impact. Based on these findings we identify research\ndirections that will enhance the effectiveness and applicability of AVD\nsolutions in software security.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11194v1",
    "published_date": "2024-12-15 14:01:41 UTC",
    "updated_date": "2024-12-15 14:01:41 UTC"
  },
  {
    "arxiv_id": "2412.11192v1",
    "title": "From Votes to Volatility Predicting the Stock Market on Election Day",
    "authors": [
      "Igor L. R. Azevedo",
      "Toyotaro Suzumura"
    ],
    "abstract": "Stock market forecasting has been a topic of extensive research, aiming to\nprovide investors with optimal stock recommendations for higher returns. In\nrecent years, this field has gained even more attention due to the widespread\nadoption of deep learning models. While these models have achieved impressive\naccuracy in predicting stock behavior, tailoring them to specific scenarios has\nbecome increasingly important. Election Day represents one such critical\nscenario, characterized by intensified market volatility, as the winning\ncandidate's policies significantly impact various economic sectors and\ncompanies. To address this challenge, we propose the Election Day Stock Market\nForecasting (EDSMF) Model. Our approach leverages the contextual capabilities\nof large language models alongside specialized agents designed to analyze the\npolitical and economic consequences of elections. By building on a\nstate-of-the-art architecture, we demonstrate that EDSMF improves the\npredictive performance of the S&P 500 during this uniquely volatile day.",
    "categories": [
      "q-fin.CP",
      "cs.AI"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11192v1",
    "published_date": "2024-12-15 13:58:20 UTC",
    "updated_date": "2024-12-15 13:58:20 UTC"
  },
  {
    "arxiv_id": "2412.11189v2",
    "title": "Leveraging Large Language Models for Active Merchant Non-player Characters",
    "authors": [
      "Byungjun Kim",
      "Minju Kim",
      "Dayeon Seo",
      "Bugeun Kim"
    ],
    "abstract": "We highlight two significant issues leading to the passivity of current\nmerchant non-player characters (NPCs): pricing and communication. While\nimmersive interactions have been a focus, negotiations between merchant NPCs\nand players on item prices have not received sufficient attention. First, we\ndefine passive pricing as the limited ability of merchants to modify predefined\nitem prices. Second, passive communication means that merchants can only\ninteract with players in a scripted manner. To tackle these issues and create\nan active merchant NPC, we propose a merchant framework based on large language\nmodels (LLMs), called MART, which consists of an appraiser module and a\nnegotiator module. We conducted two experiments to guide game developers in\nselecting appropriate implementations by comparing different training methods\nand LLM sizes. Our findings indicate that finetuning methods, such as\nsupervised finetuning (SFT) and knowledge distillation (KD), are effective in\nusing smaller LLMs to implement active merchant NPCs. Additionally, we found\nthree irregular cases arising from the responses of LLMs. We expect our\nfindings to guide developers in using LLMs for developing active merchant NPCs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review / Modified the links to code and dataset",
    "pdf_url": "http://arxiv.org/pdf/2412.11189v2",
    "published_date": "2024-12-15 13:48:39 UTC",
    "updated_date": "2025-01-08 11:24:17 UTC"
  },
  {
    "arxiv_id": "2412.11187v1",
    "title": "Analyzing the Attention Heads for Pronoun Disambiguation in Context-aware Machine Translation Models",
    "authors": [
      "Pawe≈Ç MƒÖka",
      "Yusuf Can Semerci",
      "Jan Scholtes",
      "Gerasimos Spanakis"
    ],
    "abstract": "In this paper, we investigate the role of attention heads in Context-aware\nMachine Translation models for pronoun disambiguation in the English-to-German\nand English-to-French language directions. We analyze their influence by both\nobserving and modifying the attention scores corresponding to the plausible\nrelations that could impact a pronoun prediction. Our findings reveal that\nwhile some heads do attend the relations of interest, not all of them influence\nthe models' ability to disambiguate pronouns. We show that certain heads are\nunderutilized by the models, suggesting that model performance could be\nimproved if only the heads would attend one of the relations more strongly.\nFurthermore, we fine-tune the most promising heads and observe the increase in\npronoun disambiguation accuracy of up to 5 percentage points which demonstrates\nthat the improvements in performance can be solidified into the models'\nparameters.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.11187v1",
    "published_date": "2024-12-15 13:42:49 UTC",
    "updated_date": "2024-12-15 13:42:49 UTC"
  },
  {
    "arxiv_id": "2412.11186v1",
    "title": "Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment",
    "authors": [
      "Haisheng Lu",
      "Yujie Fu",
      "Fan Zhang",
      "Le Zhang"
    ],
    "abstract": "Medical image segmentation is a critical component of clinical practice, and\nthe state-of-the-art MedSAM model has significantly advanced this field.\nNevertheless, critiques highlight that MedSAM demands substantial computational\nresources during inference. To address this issue, the CVPR 2024 MedSAM on\nLaptop Challenge was established to find an optimal balance between accuracy\nand processing speed. In this paper, we introduce a quantization-aware training\npipeline designed to efficiently quantize the Segment Anything Model for\nmedical images and deploy it using the OpenVINO inference engine. This pipeline\noptimizes both training time and disk storage. Our experimental results confirm\nthat this approach considerably enhances processing speed over the baseline,\nwhile still achieving an acceptable accuracy level. The training script,\ninference script, and quantized model are publicly accessible at\nhttps://github.com/AVC2-UESTC/QMedSAM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 3 figures, to be published in LNCS",
    "pdf_url": "http://arxiv.org/pdf/2412.11186v1",
    "published_date": "2024-12-15 13:35:07 UTC",
    "updated_date": "2024-12-15 13:35:07 UTC"
  },
  {
    "arxiv_id": "2412.19820v1",
    "title": "GaLore$+$: Boosting Low-Rank Adaptation for LLMs with Cross-Head Projection",
    "authors": [
      "Xutao Liao",
      "Shaohui Li",
      "Yuhui Xu",
      "Zhi Li",
      "Yu Liu",
      "You He"
    ],
    "abstract": "Recent low-rank training methods, such as GaLore, have significantly reduced\nthe memory required to optimize large language models (LLMs). However, these\nmethods often suffer from time-consuming low-rank projection estimations. In\nparticular, the singular value decomposition (SVD) in GaLore can consume more\nthan 80\\% of the total training time. To address this issue, we propose\nGaLore$+$, which uses cross-head low-rank projection to reduce the substantial\ntime consumption in estimating low-rank projections for multi-head attention.\nIn addition, we employ randomized subspace iteration to achieve fast SVD. To\nfurther enhance performance, we propose sparsely coded residuals to reduce the\nerrors caused by low-rank approximation on the first- and second-order moments\nof the optimizers and weight updates. We evaluate GaLore$+$ on arithmetic\nreasoning and natural language generation datasets. Our experiments demonstrate\nthat GaLore$+$ delivers superior performance while achieving approximately\n$4\\times$ fine-tuning speed compared to vanilla GaLore.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19820v1",
    "published_date": "2024-12-15 12:28:13 UTC",
    "updated_date": "2024-12-15 12:28:13 UTC"
  },
  {
    "arxiv_id": "2412.12204v1",
    "title": "SEE: Sememe Entanglement Encoding for Transformer-bases Models Compression",
    "authors": [
      "Jing Zhang",
      "Shuzhen Sun",
      "Peng Zhang",
      "Guangxing Cao",
      "Hui Gao",
      "Xindian Ma",
      "Nan Xu",
      "Yuexian Hou"
    ],
    "abstract": "Transformer-based large language models exhibit groundbreaking capabilities,\nbut their storage and computational costs are prohibitively high, limiting\ntheir application in resource-constrained scenarios. An effective approach is\nto eliminate redundant model parameters and computational costs while\nincorporating efficient expert-derived knowledge structures to achieve a\nbalance between compression and performance. Therefore, we propose the\n\\textit{Sememe Entanglement Encoding (SEE)} algorithm. Guided by expert prior\nknowledge, the model is compressed through the low-rank approximation idea. In\nEntanglement Embedding, basic semantic units such as sememes are represented as\nlow-dimensional vectors, and then reconstructed into high-dimensional word\nembeddings through the combination of generalized quantum entanglement. We\nadapt the Sememe Entanglement Encoding algorithm to transformer-based models of\ndifferent magnitudes. Experimental results indicate that our approach achieves\nstable performance while compressing model parameters and computational costs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12204v1",
    "published_date": "2024-12-15 12:01:43 UTC",
    "updated_date": "2024-12-15 12:01:43 UTC"
  },
  {
    "arxiv_id": "2501.16331v1",
    "title": "Decoding OTC Government Bond Market Liquidity: An ABM Model for Market Dynamics",
    "authors": [
      "Alicia Vidler",
      "Toby Walsh"
    ],
    "abstract": "The over-the-counter (OTC) government bond markets are characterised by their\nbilateral trading structures, which pose unique challenges to understanding and\nensuring market stability and liquidity. In this paper, we develop a bespoke\nABM that simulates market-maker interactions within a stylised government bond\nmarket. The model focuses on the dynamics of liquidity and stability in the\nsecondary trading of government bonds, particularly in concentrated markets\nlike those found in Australia and the UK. Through this simulation, we test key\nhypotheses around improving market stability, focusing on the effects of agent\ndiversity, business costs, and client base size. We demonstrate that greater\nagent diversity enhances market liquidity and that reducing the costs of\nmarket-making can improve overall market stability. The model offers insights\ninto computational finance by simulating trading without price transparency,\nhighlighting how micro-structural elements can affect macro-level market\noutcomes. This research contributes to the evolving field of computational\nfinance by employing computational intelligence techniques to better understand\nthe fundamental mechanics of government bond markets, providing actionable\ninsights for both academics and practitioners.",
    "categories": [
      "q-fin.TR",
      "cs.AI"
    ],
    "primary_category": "q-fin.TR",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.16331v1",
    "published_date": "2024-12-15 11:22:25 UTC",
    "updated_date": "2024-12-15 11:22:25 UTC"
  },
  {
    "arxiv_id": "2412.11155v1",
    "title": "Partial Identifiability in Inverse Reinforcement Learning For Agents With Non-Exponential Discounting",
    "authors": [
      "Joar Skalse",
      "Alessandro Abate"
    ],
    "abstract": "The aim of inverse reinforcement learning (IRL) is to infer an agent's\npreferences from observing their behaviour. Usually, preferences are modelled\nas a reward function, $R$, and behaviour is modelled as a policy, $\\pi$. One of\nthe central difficulties in IRL is that multiple preferences may lead to the\nsame observed behaviour. That is, $R$ is typically underdetermined by $\\pi$,\nwhich means that $R$ is only partially identifiable. Recent work has\ncharacterised the extent of this partial identifiability for different types of\nagents, including optimal and Boltzmann-rational agents. However, work so far\nhas only considered agents that discount future reward exponentially: this is a\nserious limitation, especially given that extensive work in the behavioural\nsciences suggests that humans are better modelled as discounting\nhyperbolically. In this work, we newly characterise partial identifiability in\nIRL for agents with non-exponential discounting: our results are in particular\nrelevant for hyperbolical discounting, but they also more generally apply to\nagents that use other types of (non-exponential) discounting. We significantly\nshow that generally IRL is unable to infer enough information about $R$ to\nidentify the correct optimal policy, which entails that IRL alone can be\ninsufficient to adequately characterise the preferences of such agents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11155v1",
    "published_date": "2024-12-15 11:08:58 UTC",
    "updated_date": "2024-12-15 11:08:58 UTC"
  },
  {
    "arxiv_id": "2412.11142v3",
    "title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection",
    "authors": [
      "Tiankai Yang",
      "Yi Nian",
      "Shawn Li",
      "Ruiyao Xu",
      "Yuangang Li",
      "Jiaqi Li",
      "Zhuo Xiao",
      "Xiyang Hu",
      "Ryan Rossi",
      "Kaize Ding",
      "Xia Hu",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection (AD) is an important machine learning task with many\nreal-world uses, including fraud detection, medical diagnosis, and industrial\nmonitoring. Within natural language processing (NLP), AD helps detect issues\nlike spam, misinformation, and unusual user activity. Although large language\nmodels (LLMs) have had a strong impact on tasks such as text generation and\nsummarization, their potential in AD has not been studied enough. This paper\nintroduces AD-LLM, the first benchmark that evaluates how LLMs can help with\nNLP anomaly detection. We examine three key tasks: (i) zero-shot detection,\nusing LLMs' pre-trained knowledge to perform AD without tasks-specific\ntraining; (ii) data augmentation, generating synthetic data and category\ndescriptions to improve AD models; and (iii) model selection, using LLMs to\nsuggest unsupervised AD models. Through experiments with different datasets, we\nfind that LLMs can work well in zero-shot AD, that carefully designed\naugmentation methods are useful, and that explaining model selection for\nspecific datasets remains challenging. Based on these results, we outline six\nfuture research directions on LLMs for AD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11142v3",
    "published_date": "2024-12-15 10:22:14 UTC",
    "updated_date": "2025-05-15 20:46:39 UTC"
  },
  {
    "arxiv_id": "2412.11139v1",
    "title": "ViSymRe: Vision-guided Multimodal Symbolic Regression",
    "authors": [
      "Da Li",
      "Junping Yin",
      "Jin Xu",
      "Xinxin Li",
      "Juan Zhang"
    ],
    "abstract": "Symbolic regression automatically searches for mathematical equations to\nreveal underlying mechanisms within datasets, offering enhanced\ninterpretability compared to black box models. Traditionally, symbolic\nregression has been considered to be purely numeric-driven, with insufficient\nattention given to the potential contributions of visual information in\naugmenting this process. When dealing with high-dimensional and complex\ndatasets, existing symbolic regression models are often inefficient and tend to\ngenerate overly complex equations, making subsequent mechanism analysis\ncomplicated. In this paper, we propose the vision-guided multimodal symbolic\nregression model, called ViSymRe, that systematically explores how visual\ninformation can improve various metrics of symbolic regression. Compared to\ntraditional models, our proposed model has the following innovations: (1) It\nintegrates three modalities: vision, symbol and numeric to enhance symbolic\nregression, enabling the model to benefit from the strengths of each modality;\n(2) It establishes a meta-learning framework that can learn from historical\nexperiences to efficiently solve new symbolic regression problems; (3) It\nemphasizes the simplicity and structural rationality of the equations rather\nthan merely numerical fitting. Extensive experiments show that our proposed\nmodel exhibits strong generalization capability and noise resistance. The\nequations it generates outperform state-of-the-art numeric-only baselines in\nterms of fitting effect, simplicity and structural accuracy, thus being able to\nfacilitate accurate mechanism analysis and the development of theoretical\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11139v1",
    "published_date": "2024-12-15 10:05:31 UTC",
    "updated_date": "2024-12-15 10:05:31 UTC"
  },
  {
    "arxiv_id": "2412.11138v1",
    "title": "Safe Reinforcement Learning using Finite-Horizon Gradient-based Estimation",
    "authors": [
      "Juntao Dai",
      "Yaodong Yang",
      "Qian Zheng",
      "Gang Pan"
    ],
    "abstract": "A key aspect of Safe Reinforcement Learning (Safe RL) involves estimating the\nconstraint condition for the next policy, which is crucial for guiding the\noptimization of safe policy updates. However, the existing Advantage-based\nEstimation (ABE) method relies on the infinite-horizon discounted advantage\nfunction. This dependence leads to catastrophic errors in finite-horizon\nscenarios with non-discounted constraints, resulting in safety-violation\nupdates. In response, we propose the first estimation method for finite-horizon\nnon-discounted constraints in deep Safe RL, termed Gradient-based Estimation\n(GBE), which relies on the analytic gradient derived along trajectories. Our\ntheoretical and empirical analyses demonstrate that GBE can effectively\nestimate constraint changes over a finite horizon. Constructing a surrogate\noptimization problem with GBE, we developed a novel Safe RL algorithm called\nConstrained Gradient-based Policy Optimization (CGPO). CGPO identifies feasible\noptimal policies by iteratively resolving sub-problems within trust regions.\nOur empirical results reveal that CGPO, unlike baseline algorithms,\nsuccessfully estimates the constraint functions of subsequent policies, thereby\nensuring the efficiency and feasibility of each update.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11138v1",
    "published_date": "2024-12-15 10:05:23 UTC",
    "updated_date": "2024-12-15 10:05:23 UTC"
  },
  {
    "arxiv_id": "2412.11137v1",
    "title": "Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners",
    "authors": [
      "Hezha O. Rasul",
      "Dlzar D. Ghafour",
      "Bakhtyar K. Aziz",
      "Bryar A. Hassan",
      "Tarik A. Rashid",
      "Arif Kivrak"
    ],
    "abstract": "The drug development process is a critical challenge in the pharmaceutical\nindustry due to its time-consuming nature and the need to discover new drug\npotentials to address various ailments. The initial step in drug development,\ndrug target identification, often consumes considerable time. While valid,\ntraditional methods such as in vivo and in vitro approaches are limited in\ntheir ability to analyze vast amounts of data efficiently, leading to wasteful\noutcomes. To expedite and streamline drug development, an increasing reliance\non computer-aided drug design (CADD) approaches has merged. These sophisticated\nin silico methods offer a promising avenue for efficiently identifying viable\ndrug candidates, thus providing pharmaceutical firms with significant\nopportunities to uncover new prospective drug targets. The main goal of this\nwork is to review in silico methods used in the drug development process with a\nfocus on identifying therapeutic targets linked to specific diseases at the\ngenetic or protein level. This article thoroughly discusses A-to-Z in silico\ntechniques, which are essential for identifying the targets of bioactive\ncompounds and their potential therapeutic effects. This review intends to\nimprove drug discovery processes by illuminating the state of these\ncutting-edge approaches, thereby maximizing the effectiveness and duration of\nclinical trials for novel drug target investigation.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "https://link.springer.com/article/10.1007/s12010-024-05110-2",
    "pdf_url": "http://arxiv.org/pdf/2412.11137v1",
    "published_date": "2024-12-15 10:02:38 UTC",
    "updated_date": "2024-12-15 10:02:38 UTC"
  },
  {
    "arxiv_id": "2412.11122v2",
    "title": "Paid with Models: Optimal Contract Design for Collaborative Machine Learning",
    "authors": [
      "Bingchen Wang",
      "Zhaoxuan Wu",
      "Fusheng Liu",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "Collaborative machine learning (CML) provides a promising paradigm for\ndemocratizing advanced technologies by enabling cost-sharing among\nparticipants. However, the potential for rent-seeking behaviors among parties\ncan undermine such collaborations. Contract theory presents a viable solution\nby rewarding participants with models of varying accuracy based on their\ncontributions. However, unlike monetary compensation, using models as rewards\nintroduces unique challenges, particularly due to the stochastic nature of\nthese rewards when contribution costs are privately held information. This\npaper formalizes the optimal contracting problem within CML and proposes a\ntransformation that simplifies the non-convex optimization problem into one\nthat can be solved through convex optimization algorithms. We conduct a\ndetailed analysis of the properties that an optimal contract must satisfy when\nmodels serve as the rewards, and we explore the potential benefits and welfare\nimplications of these contract-driven CML schemes through numerical\nexperiments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "econ.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.11122v2",
    "published_date": "2024-12-15 08:55:16 UTC",
    "updated_date": "2024-12-31 10:00:09 UTC"
  },
  {
    "arxiv_id": "2412.11120v2",
    "title": "Latent Reward: LLM-Empowered Credit Assignment in Episodic Reinforcement Learning",
    "authors": [
      "Yun Qu",
      "Yuhang Jiang",
      "Boyuan Wang",
      "Yixiu Mao",
      "Cheems Wang",
      "Chang Liu",
      "Xiangyang Ji"
    ],
    "abstract": "Reinforcement learning (RL) often encounters delayed and sparse feedback in\nreal-world applications, even with only episodic rewards. Previous approaches\nhave made some progress in reward redistribution for credit assignment but\nstill face challenges, including training difficulties due to redundancy and\nambiguous attributions stemming from overlooking the multifaceted nature of\nmission performance evaluation. Hopefully, Large Language Model (LLM)\nencompasses fruitful decision-making knowledge and provides a plausible tool\nfor reward redistribution. Even so, deploying LLM in this case is non-trivial\ndue to the misalignment between linguistic knowledge and the symbolic form\nrequirement, together with inherent randomness and hallucinations in inference.\nTo tackle these issues, we introduce LaRe, a novel LLM-empowered symbolic-based\ndecision-making framework, to improve credit assignment. Key to LaRe is the\nconcept of the Latent Reward, which works as a multi-dimensional performance\nevaluation, enabling more interpretable goal attainment from various\nperspectives and facilitating more effective reward redistribution. We examine\nthat semantically generated code from LLM can bridge linguistic knowledge and\nsymbolic latent rewards, as it is executable for symbolic objects. Meanwhile,\nwe design latent reward self-verification to increase the stability and\nreliability of LLM inference. Theoretically, reward-irrelevant redundancy\nelimination in the latent reward benefits RL performance from more accurate\nreward estimation. Extensive experimental results witness that LaRe (i)\nachieves superior temporal credit assignment to SOTA methods, (ii) excels in\nallocating contributions among multiple agents, and (iii) outperforms policies\ntrained with ground truth rewards for certain tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11120v2",
    "published_date": "2024-12-15 08:51:14 UTC",
    "updated_date": "2025-01-09 11:39:32 UTC"
  },
  {
    "arxiv_id": "2412.11119v1",
    "title": "Impact of Adversarial Attacks on Deep Learning Model Explainability",
    "authors": [
      "Gazi Nazia Nur",
      "Mohammad Ahnaf Sadat"
    ],
    "abstract": "In this paper, we investigate the impact of adversarial attacks on the\nexplainability of deep learning models, which are commonly criticized for their\nblack-box nature despite their capacity for autonomous feature extraction. This\nblack-box nature can affect the perceived trustworthiness of these models. To\naddress this, explainability techniques such as GradCAM, SmoothGrad, and LIME\nhave been developed to clarify model decision-making processes. Our research\nfocuses on the robustness of these explanations when models are subjected to\nadversarial attacks, specifically those involving subtle image perturbations\nthat are imperceptible to humans but can significantly mislead models. For\nthis, we utilize attack methods like the Fast Gradient Sign Method (FGSM) and\nthe Basic Iterative Method (BIM) and observe their effects on model accuracy\nand explanations. The results reveal a substantial decline in model accuracy,\nwith accuracies dropping from 89.94% to 58.73% and 45.50% under FGSM and BIM\nattacks, respectively. Despite these declines in accuracy, the explanation of\nthe models measured by metrics such as Intersection over Union (IoU) and Root\nMean Square Error (RMSE) shows negligible changes, suggesting that these\nmetrics may not be sensitive enough to detect the presence of adversarial\nperturbations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages with reference included, submitted to a journal",
    "pdf_url": "http://arxiv.org/pdf/2412.11119v1",
    "published_date": "2024-12-15 08:41:37 UTC",
    "updated_date": "2024-12-15 08:41:37 UTC"
  },
  {
    "arxiv_id": "2412.11104v1",
    "title": "ABC3: Active Bayesian Causal Inference with Cohn Criteria in Randomized Experiments",
    "authors": [
      "Taehun Cha",
      "Donghun Lee"
    ],
    "abstract": "In causal inference, randomized experiment is a de facto method to overcome\nvarious theoretical issues in observational study. However, the experimental\ndesign requires expensive costs, so an efficient experimental design is\nnecessary. We propose ABC3, a Bayesian active learning policy for causal\ninference. We show a policy minimizing an estimation error on conditional\naverage treatment effect is equivalent to minimizing an integrated posterior\nvariance, similar to Cohn criteria \\citep{cohn1994active}. We theoretically\nprove ABC3 also minimizes an imbalance between the treatment and control groups\nand the type 1 error probability. Imbalance-minimizing characteristic is\nespecially notable as several works have emphasized the importance of achieving\nbalance. Through extensive experiments on real-world data sets, ABC3 achieves\nthe highest efficiency, while empirically showing the theoretical results hold.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.11104v1",
    "published_date": "2024-12-15 08:00:57 UTC",
    "updated_date": "2024-12-15 08:00:57 UTC"
  },
  {
    "arxiv_id": "2412.11088v1",
    "title": "Seeing the Forest and the Trees: Solving Visual Graph and Tree Based Data Structure Problems using Large Multimodal Models",
    "authors": [
      "Sebastian Gutierrez",
      "Irene Hou",
      "Jihye Lee",
      "Kenneth Angelikas",
      "Owen Man",
      "Sophia Mettille",
      "James Prather",
      "Paul Denny",
      "Stephen MacNeil"
    ],
    "abstract": "Recent advancements in generative AI systems have raised concerns about\nacademic integrity among educators. Beyond excelling at solving programming\nproblems and text-based multiple-choice questions, recent research has also\nfound that large multimodal models (LMMs) can solve Parsons problems based only\non an image. However, such problems are still inherently text-based and rely on\nthe capabilities of the models to convert the images of code blocks to their\ncorresponding text. In this paper, we further investigate the capabilities of\nLMMs to solve graph and tree data structure problems based only on images. To\nachieve this, we computationally construct and evaluate a novel benchmark\ndataset comprising 9,072 samples of diverse graph and tree data structure tasks\nto assess the performance of the GPT-4o, GPT-4v, Gemini 1.5 Pro, Gemini 1.5\nFlash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT-4o and Gemini\n1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved\n87.6% accuracy on tree samples, while Gemini 1.5 Flash, achieved 56.2% accuracy\non graph samples. Our findings highlight the influence of structural and visual\nvariations on model performance. This research not only introduces an LMM\nbenchmark to facilitate replication and further exploration but also\nunderscores the potential of LMMs in solving complex computing problems, with\nimportant implications for pedagogy and assessment practices.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "I.2.10; K.3.2"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 4 figures, to be published in ACE 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.11088v1",
    "published_date": "2024-12-15 07:15:19 UTC",
    "updated_date": "2024-12-15 07:15:19 UTC"
  },
  {
    "arxiv_id": "2412.15252v1",
    "title": "NER- RoBERTa: Fine-Tuning RoBERTa for Named Entity Recognition (NER) within low-resource languages",
    "authors": [
      "Abdulhady Abas Abdullah",
      "Srwa Hasan Abdulla",
      "Dalia Mohammad Toufiq",
      "Halgurd S. Maghdid",
      "Tarik A. Rashid",
      "Pakshan F. Farho",
      "Shadan Sh. Sabr",
      "Akar H. Taher",
      "Darya S. Hamad",
      "Hadi Veisi",
      "Aras T. Asaad"
    ],
    "abstract": "Nowadays, Natural Language Processing (NLP) is an important tool for most\npeople's daily life routines, ranging from understanding speech, translation,\nnamed entity recognition (NER), and text categorization, to generative text\nmodels such as ChatGPT. Due to the existence of big data and consequently large\ncorpora for widely used languages like English, Spanish, Turkish, Persian, and\nmany more, these applications have been developed accurately. However, the\nKurdish language still requires more corpora and large datasets to be included\nin NLP applications. This is because Kurdish has a rich linguistic structure,\nvaried dialects, and a limited dataset, which poses unique challenges for\nKurdish NLP (KNLP) application development. While several studies have been\nconducted in KNLP for various applications, Kurdish NER (KNER) remains a\nchallenge for many KNLP tasks, including text analysis and classification. In\nthis work, we address this limitation by proposing a methodology for\nfine-tuning the pre-trained RoBERTa model for KNER. To this end, we first\ncreate a Kurdish corpus, followed by designing a modified model architecture\nand implementing the training procedures. To evaluate the trained model, a set\nof experiments is conducted to demonstrate the performance of the KNER model\nusing different tokenization methods and trained models. The experimental\nresults show that fine-tuned RoBERTa with the SentencePiece tokenization method\nsubstantially improves KNER performance, achieving a 12.8% improvement in\nF1-score compared to traditional models, and consequently establishes a new\nbenchmark for KNLP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15252v1",
    "published_date": "2024-12-15 07:07:17 UTC",
    "updated_date": "2024-12-15 07:07:17 UTC"
  },
  {
    "arxiv_id": "2412.11085v1",
    "title": "GraphMoRE: Mitigating Topological Heterogeneity via Mixture of Riemannian Experts",
    "authors": [
      "Zihao Guo",
      "Qingyun Sun",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Min Zhou",
      "Yisen Gao",
      "Jianxin Li"
    ],
    "abstract": "Real-world graphs have inherently complex and diverse topological patterns,\nknown as topological heterogeneity. Most existing works learn graph\nrepresentation in a single constant curvature space that is insufficient to\nmatch the complex geometric shapes, resulting in low-quality embeddings with\nhigh distortion. This also constitutes a critical challenge for graph\nfoundation models, which are expected to uniformly handle a wide variety of\ndiverse graph data. Recent studies have indicated that product manifold gains\nthe possibility to address topological heterogeneity. However, the product\nmanifold is still homogeneous, which is inadequate and inflexible for\nrepresenting the mixed heterogeneous topology. In this paper, we propose a\nnovel Graph Mixture of Riemannian Experts (GraphMoRE) framework to effectively\ntackle topological heterogeneity by personalized fine-grained topology geometry\npattern preservation. Specifically, to minimize the embedding distortion, we\npropose a topology-aware gating mechanism to select the optimal embedding space\nfor each node. By fusing the outputs of diverse Riemannian experts with learned\ngating weights, we construct personalized mixed curvature spaces for nodes,\neffectively embedding the graph into a heterogeneous manifold with varying\ncurvatures at different points. Furthermore, to fairly measure pairwise\ndistances between different embedding spaces, we present a concise and\neffective alignment strategy. Extensive experiments on real-world and synthetic\ndatasets demonstrate that our method achieves superior performance with lower\ndistortion, highlighting its potential for modeling complex graphs with\ntopological heterogeneity, and providing a novel architectural perspective for\ngraph foundation models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the Main Technical Track of the 39th Annual AAAI\n  Conference on Artificial Intelligence (AAAI-2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.11085v1",
    "published_date": "2024-12-15 06:52:40 UTC",
    "updated_date": "2024-12-15 06:52:40 UTC"
  },
  {
    "arxiv_id": "2412.11068v1",
    "title": "RecSys Arena: Pair-wise Recommender System Evaluation with Large Language Models",
    "authors": [
      "Zhuo Wu",
      "Qinglin Jia",
      "Chuhan Wu",
      "Zhaocheng Du",
      "Shuai Wang",
      "Zan Wang",
      "Zhenhua Dong"
    ],
    "abstract": "Evaluating the quality of recommender systems is critical for algorithm\ndesign and optimization. Most evaluation methods are computed based on offline\nmetrics for quick algorithm evolution, since online experiments are usually\nrisky and time-consuming. However, offline evaluation usually cannot fully\nreflect users' preference for the outcome of different recommendation\nalgorithms, and the results may not be consistent with online A/B test.\nMoreover, many offline metrics such as AUC do not offer sufficient information\nfor comparing the subtle differences between two competitive recommender\nsystems in different aspects, which may lead to substantial performance\ndifferences in long-term online serving. Fortunately, due to the strong\ncommonsense knowledge and role-play capability of large language models (LLMs),\nit is possible to obtain simulated user feedback on offline recommendation\nresults. Motivated by the idea of LLM Chatbot Arena, in this paper we present\nthe idea of RecSys Arena, where the recommendation results given by two\ndifferent recommender systems in each session are evaluated by an LLM judger to\nobtain fine-grained evaluation feedback. More specifically, for each sample we\nuse LLM to generate a user profile description based on user behavior history\nor off-the-shelf profile features, which is used to guide LLM to play the role\nof this user and evaluate the relative preference for two recommendation\nresults generated by different models. Through extensive experiments on two\nrecommendation datasets in different scenarios, we demonstrate that many\ndifferent LLMs not only provide general evaluation results that are highly\nconsistent with canonical offline metrics, but also provide rich insight in\nmany subjective aspects. Moreover, it can better distinguish different\nalgorithms with comparable performance in terms of AUC and nDCG.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11068v1",
    "published_date": "2024-12-15 05:57:36 UTC",
    "updated_date": "2024-12-15 05:57:36 UTC"
  },
  {
    "arxiv_id": "2412.11063v1",
    "title": "LAW: Legal Agentic Workflows for Custody and Fund Services Contracts",
    "authors": [
      "William Watson",
      "Nicole Cho",
      "Nishan Srishankar",
      "Zhen Zeng",
      "Lucas Cecchi",
      "Daniel Scott",
      "Suchetha Siddagangappa",
      "Rachneet Kaur",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "abstract": "Legal contracts in the custody and fund services domain govern critical\naspects such as key provider responsibilities, fee schedules, and\nindemnification rights. However, it is challenging for an off-the-shelf Large\nLanguage Model (LLM) to ingest these contracts due to the lengthy unstructured\nstreams of text, limited LLM context windows, and complex legal jargon. To\naddress these challenges, we introduce LAW (Legal Agentic Workflows for Custody\nand Fund Services Contracts). LAW features a modular design that responds to\nuser queries by orchestrating a suite of domain-specific tools and text agents.\nOur experiments demonstrate that LAW, by integrating multiple specialized\nagents and tools, significantly outperforms the baseline. LAW excels\nparticularly in complex tasks such as calculating a contract's termination\ndate, surpassing the baseline by 92.9% points. Furthermore, LAW offers a\ncost-effective alternative to traditional fine-tuned legal LLMs by leveraging\nreusable, domain-specific tools.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at The 31st International Conference on Computational\n  Linguistics (COLING 2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.11063v1",
    "published_date": "2024-12-15 05:40:57 UTC",
    "updated_date": "2024-12-15 05:40:57 UTC"
  },
  {
    "arxiv_id": "2412.11057v1",
    "title": "Set-Valued Sensitivity Analysis of Deep Neural Networks",
    "authors": [
      "Xin Wang",
      "Feilong Wang",
      "Xuegang Ban"
    ],
    "abstract": "This paper proposes a sensitivity analysis framework based on set valued\nmapping for deep neural networks (DNN) to understand and compute how the\nsolutions (model weights) of DNN respond to perturbations in the training data.\nAs a DNN may not exhibit a unique solution (minima) and the algorithm of\nsolving a DNN may lead to different solutions with minor perturbations to input\ndata, we focus on the sensitivity of the solution set of DNN, instead of\nstudying a single solution. In particular, we are interested in the expansion\nand contraction of the set in response to data perturbations. If the change of\nsolution set can be bounded by the extent of the data perturbation, the model\nis said to exhibit the Lipschitz like property. This \"set-to-set\" analysis\napproach provides a deeper understanding of the robustness and reliability of\nDNNs during training. Our framework incorporates both isolated and non-isolated\nminima, and critically, does not require the assumption that the Hessian of\nloss function is non-singular. By developing set-level metrics such as distance\nbetween sets, convergence of sets, derivatives of set-valued mapping, and\nstability across the solution set, we prove that the solution set of the Fully\nConnected Neural Network holds Lipschitz-like properties. For general neural\nnetworks (e.g., Resnet), we introduce a graphical-derivative-based method to\nestimate the new solution set following data perturbation without retraining.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11057v1",
    "published_date": "2024-12-15 05:22:38 UTC",
    "updated_date": "2024-12-15 05:22:38 UTC"
  },
  {
    "arxiv_id": "2412.11053v1",
    "title": "NITRO: LLM Inference on Intel Laptop NPUs",
    "authors": [
      "Anthony Fei",
      "Mohamed S. Abdelfattah"
    ],
    "abstract": "Large Language Models (LLMs) have become essential tools in natural language\nprocessing, finding large usage in chatbots such as ChatGPT and Gemini, and are\na central area of research. A particular area of interest includes designing\nhardware specialized for these AI applications, with one such example being the\nneural processing unit (NPU). In 2023, Intel released the Intel Core Ultra\nprocessor with codename Meteor Lake, featuring a CPU, GPU, and NPU\nsystem-on-chip. However, official software support for the NPU through Intel's\nOpenVINO framework is limited to static model inference. The dynamic nature of\nautoregressive token generation in LLMs is therefore not supported out of the\nbox. To address this shortcoming, we present NITRO (NPU Inference for\nTransformers Optimization), a Python-based framework built on top of OpenVINO\nto support text and chat generation on NPUs. In this paper, we discuss in\ndetail the key modifications made to the transformer architecture to enable\ninference, some performance benchmarks, and future steps towards improving the\npackage. The code repository for NITRO can be found here:\nhttps://github.com/abdelfattah-lab/nitro.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.11053v1",
    "published_date": "2024-12-15 05:15:54 UTC",
    "updated_date": "2024-12-15 05:15:54 UTC"
  },
  {
    "arxiv_id": "2412.15251v1",
    "title": "AgentPS: Agentic Process Supervision for Multi-modal Content Quality Assurance through Multi-round QA",
    "authors": [
      "Gorden Liu",
      "Yu Sun",
      "Ruixiao Sun",
      "Xin Dong",
      "Hongyu Xiong"
    ],
    "abstract": "The advanced processing and reasoning capabilities of multimodal large\nlanguage models (MLLMs) have driven substantial progress in vision-language\n(VL) understanding tasks. However, while effective for tasks governed by\nstraightforward logic, MLLMs often encounter challenges when reasoning over\ncomplex, interdependent logic structures. To address this limitation, we\nintroduce \\textit{AgentPS}, a novel framework that integrates Agentic Process\nSupervision into MLLMs via multi-round question answering during fine-tuning.\n\\textit{AgentPS} demonstrates significant performance improvements over\nbaseline MLLMs on proprietary TikTok datasets, due to its integration of\nprocess supervision and structured sequential reasoning. Furthermore, we show\nthat replacing human-annotated labels with LLM-generated labels retains much of\nthe performance gain, highlighting the framework's practical scalability in\nindustrial applications. These results position \\textit{AgentPS} as a highly\neffective and efficient architecture for multimodal classification tasks. Its\nadaptability and scalability, especially when enhanced by automated annotation\ngeneration, make it a powerful tool for handling large-scale, real-world\nchallenges.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.15251v1",
    "published_date": "2024-12-15 04:58:00 UTC",
    "updated_date": "2024-12-15 04:58:00 UTC"
  },
  {
    "arxiv_id": "2412.11050v2",
    "title": "RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous Driving with Vision-Language Models",
    "authors": [
      "Yujin Wang",
      "Quanfeng Liu",
      "Jiaqi Fan",
      "Jinlong Hong",
      "Hongqing Chu",
      "Mengjian Tian",
      "Bingzhao Gao",
      "Hong Chen"
    ],
    "abstract": "Understanding and addressing corner cases is essential for ensuring the\nsafety and reliability of autonomous driving systems. Vision-language models\n(VLMs) play a crucial role in enhancing scenario comprehension, yet they face\nsignificant challenges, such as hallucination and insufficient real-world\ngrounding, which compromise their performance in critical driving scenarios. In\nthis work, RAC3, a novel framework designed to enhance the performance of VLMs\nin corner case comprehension, is proposed. RAC3 integrates a frequency-spatial\nfusion (FSF) image encoder, cross-modal alignment fine-tuning with hard and\nsemi-hard negative mining, and a fast querying pipeline based on KMeans\nclustering and hierarchical navigable small world (HNSW) indexing. A multimodal\nchain-of-thought (CoT) prompting strategy to guide analogical reasoning and\nreduce hallucinations during inference is introduced. Moreover, an update\nmechanism is integrated into RAC3 to ensure continual learning within the\nframework. Extensive experiments on the CODA and NuScenes datasets demonstrate\nthat RAC3 significantly improves corner case comprehension across multiple\ndownstream tasks. Compared to prior state-of-the-art methods, RAC3 achieves the\nhighest final score of 74.46 on the CODA-LM benchmark and shows consistent\nperformance gains when integrated with end-to-end frameworks like DriveLM.\nThese results demonstrate the effectiveness of retrieval-augmented strategies\nand cross-modal alignment for safer and more interpretable autonomous driving.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.11050v2",
    "published_date": "2024-12-15 04:51:30 UTC",
    "updated_date": "2025-04-13 05:30:02 UTC"
  },
  {
    "arxiv_id": "2412.19819v1",
    "title": "ChipAlign: Instruction Alignment in Large Language Models for Chip Design via Geodesic Interpolation",
    "authors": [
      "Chenhui Deng",
      "Yunsheng Bai",
      "Haoxing Ren"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have expanded their\napplication across various domains, including chip design, where domain-adapted\nchip models like ChipNeMo have emerged. However, these models often struggle\nwith instruction alignment, a crucial capability for LLMs that involves\nfollowing explicit human directives. This limitation impedes the practical\napplication of chip LLMs, including serving as assistant chatbots for hardware\ndesign engineers. In this work, we introduce ChipAlign, a novel approach that\nutilizes a training-free model merging strategy, combining the strengths of a\ngeneral instruction-aligned LLM with a chip-specific LLM. By considering the\nunderlying manifold in the weight space, ChipAlign employs geodesic\ninterpolation to effectively fuse the weights of input LLMs, producing a merged\nmodel that inherits strong instruction alignment and chip expertise from the\nrespective instruction and chip LLMs. Our results demonstrate that ChipAlign\nsignificantly enhances instruction-following capabilities of existing chip\nLLMs, achieving up to a 26.6% improvement on the IFEval benchmark, while\nmaintaining comparable expertise in the chip domain. This improvement in\ninstruction alignment also translates to notable gains in instruction-involved\nQA tasks, delivering performance enhancements of 3.9% on the OpenROAD QA\nbenchmark and 8.25% on production-level chip QA benchmarks, surpassing\nstate-of-the-art baselines.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19819v1",
    "published_date": "2024-12-15 04:21:24 UTC",
    "updated_date": "2024-12-15 04:21:24 UTC"
  },
  {
    "arxiv_id": "2412.11047v1",
    "title": "Deployment Pipeline from Rockpool to Xylo for Edge Computing",
    "authors": [
      "Peng Zhou",
      "Dylan R. Muir"
    ],
    "abstract": "Deploying Spiking Neural Networks (SNNs) on the Xylo neuromorphic chip via\nthe Rockpool framework represents a significant advancement in achieving\nultra-low-power consumption and high computational efficiency for edge\napplications. This paper details a novel deployment pipeline, emphasizing the\nintegration of Rockpool's capabilities with Xylo's architecture, and evaluates\nthe system's performance in terms of energy efficiency and accuracy. The unique\nadvantages of the Xylo chip, including its digital spiking architecture and\nevent-driven processing model, are highlighted to demonstrate its suitability\nfor real-time, power-sensitive applications.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11047v1",
    "published_date": "2024-12-15 04:19:10 UTC",
    "updated_date": "2024-12-15 04:19:10 UTC"
  },
  {
    "arxiv_id": "2412.12201v1",
    "title": "Embracing Large Language Models in Traffic Flow Forecasting",
    "authors": [
      "Yusheng Zhao",
      "Xiao Luo",
      "Haomin Wen",
      "Zhiping Xiao",
      "Wei Ju",
      "Ming Zhang"
    ],
    "abstract": "Traffic flow forecasting aims to predict future traffic flows based on the\nhistorical traffic conditions and the road network. It is an important problem\nin intelligent transportation systems, with a plethora of methods been\nproposed. Existing efforts mainly focus on capturing and utilizing\nspatio-temporal dependencies to predict future traffic flows. Though promising,\nthey fall short in adapting to test-time environmental changes of traffic\nconditions. To tackle this challenge, we propose to introduce large language\nmodels (LLMs) to help traffic flow forecasting and design a novel method named\nLarge Language Model Enhanced Traffic Flow Predictor (LEAF). LEAF adopts two\nbranches, capturing different spatio-temporal relations using graph and\nhypergraph structures respectively. The two branches are first pre-trained\nindividually, and during test-time, they yield different predictions. Based on\nthese predictions, a large language model is used to select the most likely\nresult. Then, a ranking loss is applied as the learning objective to enhance\nthe prediction ability of the two branches. Extensive experiments on several\ndatasets demonstrate the effectiveness of the proposed LEAF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12201v1",
    "published_date": "2024-12-15 03:08:28 UTC",
    "updated_date": "2024-12-15 03:08:28 UTC"
  },
  {
    "arxiv_id": "2501.00016v2",
    "title": "Predicting Crack Nucleation and Propagation in Brittle Materials Using Deep Operator Networks with Diverse Trunk Architectures",
    "authors": [
      "Elham Kiyani",
      "Manav Manav",
      "Nikhil Kadivar",
      "Laura De Lorenzis",
      "George Em Karniadakis"
    ],
    "abstract": "Phase-field modeling reformulates fracture problems as energy minimization\nproblems and enables a comprehensive characterization of the fracture process,\nincluding crack nucleation, propagation, merging, and branching, without\nrelying on ad-hoc assumptions. However, the numerical solution of phase-field\nfracture problems is characterized by a high computational cost. To address\nthis challenge, in this paper, we employ a deep neural operator (DeepONet)\nconsisting of a branch network and a trunk network to solve brittle fracture\nproblems. We explore three distinct approaches that vary in their trunk network\nconfigurations. In the first approach, we demonstrate the effectiveness of a\ntwo-step DeepONet, which results in a simplification of the learning task. In\nthe second approach, we employ a physics-informed DeepONet, whereby the\nmathematical expression of the energy is integrated into the trunk network's\nloss to enforce physical consistency. The integration of physics also results\nin a substantially smaller data size needed for training. In the third\napproach, we replace the neural network in the trunk with a Kolmogorov-Arnold\nNetwork and train it without the physics loss. Using these methods, we model\ncrack nucleation in a one-dimensional homogeneous bar under prescribed end\ndisplacements, as well as crack propagation and branching in single\nedge-notched specimens with varying notch lengths subjected to tensile and\nshear loading. We show that the networks predict the solution fields\naccurately, and the error in the predicted fields is localized near the crack.",
    "categories": [
      "physics.comp-ph",
      "cs.AI"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "25 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.00016v2",
    "published_date": "2024-12-15 02:50:30 UTC",
    "updated_date": "2025-04-14 17:01:43 UTC"
  },
  {
    "arxiv_id": "2412.11026v2",
    "title": "SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation",
    "authors": [
      "Hang Zhang",
      "Zhuoling Li",
      "Jun Liu"
    ],
    "abstract": "Dynamic scenes contain intricate spatio-temporal information, crucial for\nmobile robots, UAVs, and autonomous driving systems to make informed decisions.\nParsing these scenes into semantic triplets <Subject-Predicate-Object> for\naccurate Scene Graph Generation (SGG) is highly challenging due to the\nfluctuating spatio-temporal complexity. Inspired by the reasoning capabilities\nof Large Language Models (LLMs), we propose SceneLLM, a novel framework that\nleverages LLMs as powerful scene analyzers for dynamic SGG. Our framework\nintroduces a Video-to-Language (V2L) mapping module that transforms video\nframes into linguistic signals (scene tokens), making the input more\ncomprehensible for LLMs. To better encode spatial information, we devise a\nSpatial Information Aggregation (SIA) scheme, inspired by the structure of\nChinese characters, which encodes spatial data into tokens. Using Optimal\nTransport (OT), we generate an implicit language signal from the frame-level\ntoken sequence that captures the video's spatio-temporal information. To\nfurther improve the LLM's ability to process this implicit linguistic input, we\napply Low-Rank Adaptation (LoRA) to fine-tune the model. Finally, we use a\ntransformer-based SGG predictor to decode the LLM's reasoning and predict\nsemantic triplets. Our method achieves state-of-the-art results on the Action\nGenome (AG) benchmark, and extensive experiments show the effectiveness of\nSceneLLM in understanding and generating accurate dynamic scene graphs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "29 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.11026v2",
    "published_date": "2024-12-15 02:41:31 UTC",
    "updated_date": "2025-05-07 03:14:53 UTC"
  },
  {
    "arxiv_id": "2412.11025v1",
    "title": "From Simple to Professional: A Combinatorial Controllable Image Captioning Agent",
    "authors": [
      "Xinran Wang",
      "Muxi Diao",
      "Baoteng Li",
      "Haiwen Zhang",
      "Kongming Liang",
      "Zhanyu Ma"
    ],
    "abstract": "The Controllable Image Captioning Agent (CapAgent) is an innovative system\ndesigned to bridge the gap between user simplicity and professional-level\noutputs in image captioning tasks. CapAgent automatically transforms\nuser-provided simple instructions into detailed, professional instructions,\nenabling precise and context-aware caption generation. By leveraging multimodal\nlarge language models (MLLMs) and external tools such as object detection tool\nand search engines, the system ensures that captions adhere to specified\nguidelines, including sentiment, keywords, focus, and formatting. CapAgent\ntransparently controls each step of the captioning process, and showcases its\nreasoning and tool usage at every step, fostering user trust and engagement.\nThe project code is available at https://github.com/xin-ran-w/CapAgent.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "A technical report. Project: https://github.com/xin-ran-w/CapAgent",
    "pdf_url": "http://arxiv.org/pdf/2412.11025v1",
    "published_date": "2024-12-15 02:37:20 UTC",
    "updated_date": "2024-12-15 02:37:20 UTC"
  },
  {
    "arxiv_id": "2412.11014v1",
    "title": "PromptV: Leveraging LLM-powered Multi-Agent Prompting for High-quality Verilog Generation",
    "authors": [
      "Zhendong Mi",
      "Renming Zheng",
      "Haowen Zhong",
      "Yue Sun",
      "Shaoyi Huang"
    ],
    "abstract": "Recent advances in agentic LLMs have demonstrated remarkable automated\nVerilog code generation capabilities. However, existing approaches either\ndemand substantial computational resources or rely on LLM-assisted single-agent\nprompt learning techniques, which we observe for the first time has a\ndegeneration issue - characterized by deteriorating generative performance and\ndiminished error detection and correction capabilities. This paper proposes a\nnovel multi-agent prompt learning framework to address these limitations and\nenhance code generation quality. We show for the first time that multi-agent\narchitectures can effectively mitigate the degeneration risk while improving\ncode error correction capabilities, resulting in higher-quality Verilog code\ngeneration. Experimental results show that the proposed method could achieve\n96.4% and 96.5% pass@10 scores on VerilogEval Machine and Human benchmarks,\nrespectively while attaining 100% Syntax and 99.9% Functionality pass@5 metrics\non the RTLLM benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11014v1",
    "published_date": "2024-12-15 01:58:10 UTC",
    "updated_date": "2024-12-15 01:58:10 UTC"
  },
  {
    "arxiv_id": "2412.11009v1",
    "title": "Dual Traits in Probabilistic Reasoning of Large Language Models",
    "authors": [
      "Shenxiong Li",
      "Huaxia Rui"
    ],
    "abstract": "We conducted three experiments to investigate how large language models\n(LLMs) evaluate posterior probabilities. Our results reveal the coexistence of\ntwo modes in posterior judgment among state-of-the-art models: a normative\nmode, which adheres to Bayes' rule, and a representative-based mode, which\nrelies on similarity -- paralleling human System 1 and System 2 thinking.\nAdditionally, we observed that LLMs struggle to recall base rate information\nfrom their memory, and developing prompt engineering strategies to mitigate\nrepresentative-based judgment may be challenging. We further conjecture that\nthe dual modes of judgment may be a result of the contrastive loss function\nemployed in reinforcement learning from human feedback. Our findings underscore\nthe potential direction for reducing cognitive biases in LLMs and the necessity\nfor cautious deployment of LLMs in critical areas.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.11009v1",
    "published_date": "2024-12-15 01:33:45 UTC",
    "updated_date": "2024-12-15 01:33:45 UTC"
  },
  {
    "arxiv_id": "2412.15249v2",
    "title": "LitLLMs, LLMs for Literature Review: Are we there yet?",
    "authors": [
      "Shubham Agarwal",
      "Gaurav Sahu",
      "Abhay Puri",
      "Issam H. Laradji",
      "Krishnamurthy DJ Dvijotham",
      "Jason Stanley",
      "Laurent Charlin",
      "Christopher Pal"
    ],
    "abstract": "Literature reviews are an essential component of scientific research, but\nthey remain time-intensive and challenging to write, especially due to the\nrecent influx of research papers. This paper explores the zero-shot abilities\nof recent Large Language Models (LLMs) in assisting with the writing of\nliterature reviews based on an abstract. We decompose the task into two\ncomponents: 1. Retrieving related works given a query abstract, and 2. Writing\na literature review based on the retrieved results. We analyze how effective\nLLMs are for both components. For retrieval, we introduce a novel two-step\nsearch strategy that first uses an LLM to extract meaningful keywords from the\nabstract of a paper and then retrieves potentially relevant papers by querying\nan external knowledge base. Additionally, we study a prompting-based re-ranking\nmechanism with attribution and show that re-ranking doubles the normalized\nrecall compared to naive search methods, while providing insights into the\nLLM's decision-making process. In the generation phase, we propose a two-step\napproach that first outlines a plan for the review and then executes steps in\nthe plan to generate the actual review. To evaluate different LLM-based\nliterature review methods, we create test sets from arXiv papers using a\nprotocol designed for rolling use with newly released LLMs to avoid test set\ncontamination in zero-shot evaluations. We release this evaluation protocol to\npromote additional research and development in this regard. Our empirical\nresults suggest that LLMs show promising potential for writing literature\nreviews when the task is decomposed into smaller components of retrieval and\nplanning. Our project page including a demonstration system and toolkit can be\naccessed here: https://litllm.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15249v2",
    "published_date": "2024-12-15 01:12:26 UTC",
    "updated_date": "2025-03-21 14:56:58 UTC"
  }
]