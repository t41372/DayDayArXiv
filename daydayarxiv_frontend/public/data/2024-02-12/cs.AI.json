{
  "date": "2024-02-12",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-12 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 代理、LLM（Large Language Models）优化与应用、强化学习以及医疗 AI 等领域，其中 LLM 的自我对齐和零样本学习表现出色，AI 在医疗和决策中的潜力令人印象深刻，而学者如 Vincent Conitzer 和 Subbarao Kambhampati 的作品（如递归联合模拟和 LLM 自验证）值得重点关注。\n\n### LLM 和 AI 代理相关论文\n这些论文探讨了 LLM 在决策、生成和跨域适应的创新应用，突出了 LLM 的潜力及其挑战。\n- **Recursive Joint Simulation in Games (递归联合模拟在游戏中) / Recursive Joint Simulation in Games**：Vojtech Kovarik 等（包括 Vincent Conitzer）提出了一种 AI 代理递归模拟方法，通过嵌套模拟实现游戏中更合作的结果，证明了其等效于无限重复游戏，贡献在于提升了 AI 策略的合作性。\n- **On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks (大语言模型在推理和规划任务中的自验证限制) / On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks**：Subbarao Kambhampati 等发现 LLM 在自批评迭代中表现不佳，但外部验证可显著改善，关键发现是 LLM 在推理任务的验证不如生成有效。\n- **Active Preference Learning for Large Language Models (大语言模型的主动偏好学习) / Active Preference Learning for Large Language Models**：William Muldrew 等引入主动学习策略优化 LLM 偏好微调，减少标注需求，提高模型性能，主要贡献是基于预测熵的获取函数，提升了微调效率。\n- **Relative Preference Optimization: Enhancing LLM Alignment through Contrasting Responses (相对偏好优化：通过对比响应增强 LLM 对齐) / Relative Preference Optimization**：Yueqin Yin 等提出 RPO 方法，使用对比权重处理相同和相关提示，提高 LLM 与用户偏好的对齐，实验显示在对话和总结任务中表现优异。\n- **Beyond LLMs: Advancing the Landscape of Complex Reasoning (超越 LLM：推进复杂推理领域) / Beyond LLMs**：Jennifer Chu-Carroll 等比较 LLM 和神经符号方法，强调符号推理引擎在约束满足问题中的优势，发现符号方法在复杂任务中显著优于纯 LLM。\n- **Policy Improvement using Language Feedback Models (使用语言反馈模型的政策改进) / Policy Improvement using Language Feedback Models**：Victor Zhong 等利用 LLM 生成反馈提升强化学习策略，贡献在于从视觉轨迹中提取偏好，提高了指令跟随任务的性能。\n- **Large Language Models are Few-shot Generators (大语言模型是少样本生成器) / Large Language Models are Few-shot Generators**：Yifan Zhang 等开发了自动数据选择框架，使用 LLM 生成数学文本，发现少样本生成可提升下游任务准确率。\n- **Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models (思想扩散：扩散语言模型中的链式推理) / Diffusion of Thoughts**：Jiacheng Ye 等将扩散模型与链式推理结合，允许更灵活的计算-性能权衡，实验证明在数学任务中优于传统 autoregressive 模型。\n- **Towards Unified Alignment Between Agents, Humans, and Environment (朝着代理、人和环境之间的统一对齐) / Towards Unified Alignment**：Zongliang Yang 等提出 UA² 框架，确保 AI 代理与人类意图和环境动态对齐，贡献在于处理 AI 代理的多重约束，提高了任务完成率。\n\n### 强化学习和决策相关论文\n这些工作强调了强化学习在复杂环境中的优化和泛化。\n- **A Competition Winning Deep Reinforcement Learning Agent in microRTS (微型 RTS 中的获胜深度强化学习代理) / A Competition Winning Deep Reinforcement Learning Agent in microRTS**：Scott Goodfriend 开发的 DRL 代理在微型 RTS 比赛中获胜，通过迭代微调和转移学习提升性能，主要发现是策略转移的关键作用。\n- **Implicit Bias of Policy Gradient in Linear Quadratic Control (策略梯度在线性二次控制中的隐式偏差) / Implicit Bias of Policy Gradient**：Noam Razin 等分析策略梯度在 LQR 中的泛化，发现探索度影响初始状态外推，实验验证了其在非线性系统中的鲁棒性。\n- **Avoiding Catastrophe in Online Learning by Asking for Help (通过寻求帮助避免在线学习的灾难) / Avoiding Catastrophe in Online Learning**：Benjamin Plaut 等提出在线学习框架，允许代理查询导师避免灾难性错误，贡献在于在可学习策略类中实现零查询遗憾。\n\n### 医疗 AI 和其他应用论文\n医疗 AI 论文突出了 AI 在诊断和预测中的潜力，其他则快速掠过。\n- **AI-Enabled Lung Cancer Prognosis (AI 赋能的肺癌预后) / AI-Enabled Lung Cancer Prognosis**：Mahtab Darvish 等综述 AI 在 NSCLC 预后中的作用，强调机器学习整合多组学数据可个性化治疗策略，主要发现是 AI 提升生存预测准确性。\n- **WildfireGPT: Tailored Large Language Model for Wildfire Analysis (WildfireGPT：针对野火分析的定制大语言模型) / WildfireGPT**：Yangxinyu Xie 等开发了针对野火风险的 LLM 代理，通过检索增强提供决策洞见，贡献在于结合气候数据提升野火预测实用性。\n- **Efficient and Scalable Fine-Tune of Language Models for Genome Understanding (语言模型在基因组理解中的高效可扩展微调) / Efficient and Scalable Fine-Tune**：Huixin Zhan 等提出 Lingo 方法，使用自然语言模型微调基因组任务，实验显示在 14 个基准上性能提升，同时参数减少 98%。\n其他如图像处理（如 Message Detouring）和一般 AI 优化（如 Scaling Laws for Fine-Grained Mixture of Experts）论文虽有创新，但影响力较小，仅提及其在图学习和模型缩放中的改进。\n\n总之，今天的论文展示了 AI 在复杂任务中的进展，LLM 和强化学习的融合尤其值得关注，期待这些工作推动更可靠的 AI 应用。",
  "papers": [
    {
      "arxiv_id": "2402.08128v2",
      "title": "Recursive Joint Simulation in Games",
      "title_zh": "翻译失败",
      "authors": [
        "Vojtech Kovarik",
        "Caspar Oesterheld",
        "Vincent Conitzer"
      ],
      "abstract": "Game-theoretic dynamics between AI agents could differ from traditional\nhuman-human interactions in various ways. One such difference is that it may be\npossible to accurately simulate an AI agent, for example because its source\ncode is known. Our aim is to explore ways of leveraging this possibility to\nachieve more cooperative outcomes in strategic settings. In this paper, we\nstudy an interaction between AI agents where the agents run a recursive joint\nsimulation. That is, the agents first jointly observe a simulation of the\nsituation they face. This simulation in turn recursively includes additional\nsimulations (with a small chance of failure, to avoid infinite recursion), and\nthe results of all these nested simulations are observed before an action is\nchosen. We show that the resulting interaction is strategically equivalent to\nan infinitely repeated version of the original game, allowing a direct transfer\nof existing results such as the various folk theorems.",
      "tldr_zh": "本论文探讨了AI代理在游戏中的动态互动，可能因AI可被准确模拟而不同于人类互动，从而实现更合作的战略结果。研究引入了Recursive Joint Simulation机制，其中AI代理先共同观察一个模拟情景，该模拟递归包含嵌套模拟（带有小概率失败以避免无限递归），并在观察所有结果后选择行动。结果显示，这种互动等价于原游戏的无限重复版本，允许直接应用现有理论如folk theorems，以促进更有效的合作策略。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08128v2",
      "published_date": "2024-02-12 23:53:46 UTC",
      "updated_date": "2024-03-02 03:01:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:23:39.880930"
    },
    {
      "arxiv_id": "2402.08125v1",
      "title": "Customizable Perturbation Synthesis for Robust SLAM Benchmarking",
      "title_zh": "用于鲁棒 SLAM 基准测试的可自定义扰动合成",
      "authors": [
        "Xiaohao Xu",
        "Tianyi Zhang",
        "Sibo Wang",
        "Xiang Li",
        "Yongqi Chen",
        "Ye Li",
        "Bhiksha Raj",
        "Matthew Johnson-Roberson",
        "Xiaonan Huang"
      ],
      "abstract": "Robustness is a crucial factor for the successful deployment of robots in\nunstructured environments, particularly in the domain of Simultaneous\nLocalization and Mapping (SLAM). Simulation-based benchmarks have emerged as a\nhighly scalable approach for robustness evaluation compared to real-world data\ncollection. However, crafting a challenging and controllable noisy world with\ndiverse perturbations remains relatively under-explored. To this end, we\npropose a novel, customizable pipeline for noisy data synthesis, aimed at\nassessing the resilience of multi-modal SLAM models against various\nperturbations. This pipeline incorporates customizable hardware setups,\nsoftware components, and perturbed environments. In particular, we introduce\ncomprehensive perturbation taxonomy along with a perturbation composition\ntoolbox, allowing the transformation of clean simulations into challenging\nnoisy environments. Utilizing the pipeline, we instantiate the Robust-SLAM\nbenchmark, which includes diverse perturbation types, to evaluate the risk\ntolerance of existing advanced multi-modal SLAM models. Our extensive analysis\nuncovers the susceptibilities of existing SLAM models to real-world\ndisturbance, despite their demonstrated accuracy in standard benchmarks. Our\nperturbation synthesis toolbox, SLAM robustness evaluation pipeline, and\nRobust-SLAM benchmark will be made publicly available at\nhttps://github.com/Xiaohao-Xu/SLAM-under-Perturbation/.",
      "tldr_zh": "这篇论文提出了一种可定制的扰动合成管道，用于评估多模态 SLAM 模型的鲁棒性，旨在解决机器人部署在非结构化环境中的挑战。该管道整合了可定制的硬件设置、软件组件和扰动环境，并引入了全面的 perturbation taxonomy 和 perturbation composition 工具箱，将干净模拟转化为复杂的噪声场景。通过创建 Robust-SLAM 基准，实验结果揭示了现有 SLAM 模型在标准基准中表现出色，但对真实世界干扰高度敏感；相关工具和基准已计划在 GitHub 上公开。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.RO",
      "comment": "40 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.08125v1",
      "published_date": "2024-02-12 23:49:40 UTC",
      "updated_date": "2024-02-12 23:49:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:23:53.734588"
    },
    {
      "arxiv_id": "2402.08115v2",
      "title": "On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks",
      "title_zh": "关于大型语言模型在推理和",
      "authors": [
        "Kaya Stechly",
        "Karthik Valmeekam",
        "Subbarao Kambhampati"
      ],
      "abstract": "There has been considerable divergence of opinion on the reasoning abilities\nof Large Language Models (LLMs). While the initial optimism that reasoning\nmight emerge automatically with scale has been tempered thanks to a slew of\ncounterexamples--ranging from multiplication to simple planning--there persists\na wide spread belief that LLMs can self-critique and improve their own\nsolutions in an iterative fashion. This belief seemingly rests on the\nassumption that verification of correctness should be easier than generation--a\nrather classical argument from computational complexity--which should be\nirrelevant to LLMs to the extent that what they are doing is approximate\nretrieval. In this paper, we set out to systematically investigate the\neffectiveness of iterative prompting in the context of reasoning and planning.\nWe present a principled empirical study of the performance of GPT-4 in three\ndomains: Game of 24, Graph Coloring, and STRIPS planning. We experiment both\nwith the model critiquing its own answers and with an external correct reasoner\nverifying proposed solutions. In each case, we analyze whether the content of\ncriticisms actually affects bottom line performance, and whether we can ablate\nelements of the augmented system without losing performance. We observe\nsignificant performance collapse with self-critique and significant performance\ngains with sound external verification. We also note that merely re-prompting\nwith a sound verifier maintains most of the benefits of more involved setups.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 在推理和规划任务上自验证的局限性，质疑模型是否能通过迭代自批评来改进解决方案。作者对GPT-4进行了系统实证研究，包括Game of 24、Graph Coloring和STRIPS planning 等领域，比较了自批评机制与外部正确验证器的效果。结果显示，自批评导致性能显著下降，而使用可靠的外部验证器可大幅提升表现，且简单重新提示即可保留大部分好处。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2310.12397",
      "pdf_url": "http://arxiv.org/pdf/2402.08115v2",
      "published_date": "2024-02-12 23:11:01 UTC",
      "updated_date": "2024-08-03 21:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:24:04.953869"
    },
    {
      "arxiv_id": "2402.08114v2",
      "title": "Active Preference Learning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "William Muldrew",
        "Peter Hayes",
        "Mingtian Zhang",
        "David Barber"
      ],
      "abstract": "As large language models (LLMs) become more capable, fine-tuning techniques\nfor aligning with human intent are increasingly important. A key consideration\nfor aligning these models is how to most effectively use human resources, or\nmodel resources in the case where LLMs themselves are used as oracles.\nReinforcement learning from Human or AI preferences (RLHF/RLAIF) is the most\nprominent example of such a technique, but is complex and often unstable.\nDirect Preference Optimization (DPO) has recently been proposed as a simpler\nand more stable alternative. In this work, we develop an active learning\nstrategy for DPO to make better use of preference labels. We propose a\npractical acquisition function for prompt/completion pairs based on the\npredictive entropy of the language model and a measure of certainty of the\nimplicit preference model optimized by DPO. We demonstrate how our approach\nimproves both the rate of learning and final performance of fine-tuning on\npairwise preference data.",
      "tldr_zh": "该论文探讨了为大型语言模型 (LLMs) 进行微调以对齐人类意图的方法，强调有效利用人类或 AI 资源的问题。作者提出了一种基于 Direct Preference Optimization (DPO) 的主动学习策略，使用语言模型的预测熵和隐式偏好模型的确定性作为获取函数，来选择最佳的提示/完成对。实验结果显示，这种方法显著提高了微调过程的学习速率和最终性能。总的来说，该工作为更高效的偏好数据利用提供了实用改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 5 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.08114v2",
      "published_date": "2024-02-12 23:09:00 UTC",
      "updated_date": "2024-06-28 08:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:24:16.672214"
    },
    {
      "arxiv_id": "2402.08112v2",
      "title": "A Competition Winning Deep Reinforcement Learning Agent in microRTS",
      "title_zh": "翻译失败",
      "authors": [
        "Scott Goodfriend"
      ],
      "abstract": "Scripted agents have predominantly won the five previous iterations of the\nIEEE microRTS ($\\mu$RTS) competitions hosted at CIG and CoG. Despite Deep\nReinforcement Learning (DRL) algorithms making significant strides in real-time\nstrategy (RTS) games, their adoption in this primarily academic competition has\nbeen limited due to the considerable training resources required and the\ncomplexity inherent in creating and debugging such agents. RAISocketAI is the\nfirst DRL agent to win the IEEE microRTS competition. In a benchmark without\nperformance constraints, RAISocketAI regularly defeated the two prior\ncompetition winners. This first competition-winning DRL submission can be a\nbenchmark for future microRTS competitions and a starting point for future DRL\nresearch. Iteratively fine-tuning the base policy and transfer learning to\nspecific maps were critical to RAISocketAI's winning performance. These\nstrategies can be used to economically train future DRL agents. Further work in\nImitation Learning using Behavior Cloning and fine-tuning these models with DRL\nhas proven promising as an efficient way to bootstrap models with demonstrated,\ncompetitive behaviors.",
      "tldr_zh": "该研究介绍了 RAISocketAI，这是第一个在 IEEE microRTS 比赛中获胜的 Deep Reinforcement Learning (DRL) 代理，打破了脚本代理的长期主导地位。通过迭代微调基础策略和转移学习到特定地图，RAISocketAI 在无性能约束的基准测试中 consistently 击败了之前的竞争赢家。研究强调这些策略可经济地训练未来 DRL 代理，并提出使用 Imitation Learning（如 Behavior Cloning）结合 DRL 微调作为高效引导模型的方法，为 microRTS 比赛和 DRL 研究提供新基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Best paper award nominee at IEEE Conference on Games 2024. 19 pages,\n  6 figures. Source code at https://github.com/sgoodfriend/rl-algo-impls",
      "pdf_url": "http://arxiv.org/pdf/2402.08112v2",
      "published_date": "2024-02-12 23:08:17 UTC",
      "updated_date": "2025-01-02 06:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:24:28.955743"
    },
    {
      "arxiv_id": "2402.10958v2",
      "title": "Relative Preference Optimization: Enhancing LLM Alignment through Contrasting Responses across Identical and Diverse Prompts",
      "title_zh": "相对偏好优化：通过对比相同和多样提示中的响应来增强大型语言模型对齐",
      "authors": [
        "Yueqin Yin",
        "Zhendong Wang",
        "Yi Gu",
        "Hai Huang",
        "Weizhu Chen",
        "Mingyuan Zhou"
      ],
      "abstract": "In the field of large language models (LLMs), aligning models with the\ndiverse preferences of users is a critical challenge. Direct Preference\nOptimization (DPO) has played a key role in this area. It works by using pairs\nof preferences derived from the same prompts, and it functions without needing\nan additional reward model. However, DPO does not fully reflect the complex\nnature of human learning, which often involves understanding contrasting\nresponses to not only identical but also similar questions. To overcome this\nshortfall, we propose Relative Preference Optimization (RPO). RPO is designed\nto discern between more and less preferred responses derived from both\nidentical and related prompts. It introduces a contrastive weighting mechanism,\nenabling the tuning of LLMs using a broader range of preference data, including\nboth paired and unpaired sets. This approach expands the learning capabilities\nof the model, allowing it to leverage insights from a more varied set of\nprompts. Through empirical tests, including dialogue and summarization tasks,\nand evaluations using the AlpacaEval2.0 leaderboard, RPO has demonstrated a\nsuperior ability to align LLMs with user preferences and to improve their\nadaptability during the training process. Our code can be viewed at\nhttps://github.com/yinyueqin/relative-preference-optimization",
      "tldr_zh": "该研究针对大型语言模型（LLM）与用户偏好对齐的挑战，提出了一种新的方法Relative Preference Optimization (RPO)，它扩展了Direct Preference Optimization (DPO) 的局限性，通过对比相同和相关提示下的响应来优化模型。RPO 引入对比加权机制，允许模型从更广泛的偏好数据（包括配对和非配对集）中学习，从而提升模型的适应性和泛化能力。在对话和总结任务的实证测试中，RPO 在AlpacaEval2.0 排行榜上表现出色，显著提高了LLM 的用户偏好对齐效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10958v2",
      "published_date": "2024-02-12 22:47:57 UTC",
      "updated_date": "2024-05-27 20:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:24:41.516868"
    },
    {
      "arxiv_id": "2402.08088v1",
      "title": "Out-of-Distribution Detection and Data Drift Monitoring using Statistical Process Control",
      "title_zh": "使用统计过程控制的分布外检测与数据漂移监控",
      "authors": [
        "Ghada Zamzmi",
        "Kesavan Venkatesh",
        "Brandon Nelson",
        "Smriti Prathapan",
        "Paul H. Yi",
        "Berkman Sahiner",
        "Jana G. Delfino"
      ],
      "abstract": "Background: Machine learning (ML) methods often fail with data that deviates\nfrom their training distribution. This is a significant concern for ML-enabled\ndevices in clinical settings, where data drift may cause unexpected performance\nthat jeopardizes patient safety.\n  Method: We propose a ML-enabled Statistical Process Control (SPC) framework\nfor out-of-distribution (OOD) detection and drift monitoring. SPC is\nadvantageous as it visually and statistically highlights deviations from the\nexpected distribution. To demonstrate the utility of the proposed framework for\nmonitoring data drift in radiological images, we investigated different design\nchoices, including methods for extracting feature representations, drift\nquantification, and SPC parameter selection.\n  Results: We demonstrate the effectiveness of our framework for two tasks: 1)\ndifferentiating axial vs. non-axial computed tomography (CT) images and 2)\nseparating chest x-ray (CXR) from other modalities. For both tasks, we achieved\nhigh accuracy in detecting OOD inputs, with 0.913 in CT and 0.995 in CXR, and\nsensitivity of 0.980 in CT and 0.984 in CXR. Our framework was also adept at\nmonitoring data streams and identifying the time a drift occurred. In a\nsimulation with 100 daily CXR cases, we detected a drift in OOD input\npercentage from 0-1% to 3-5% within two days, maintaining a low false-positive\nrate. Through additional experimental results, we demonstrate the framework's\ndata-agnostic nature and independence from the underlying model's structure.\n  Conclusion: We propose a framework for OOD detection and drift monitoring\nthat is agnostic to data, modality, and model. The framework is customizable\nand can be adapted for specific applications.",
      "tldr_zh": "该研究针对机器学习模型在临床环境中面对数据偏移（Out-of-Distribution, OOD）问题时可能导致的性能下降和患者安全风险，提出了一种基于 Statistical Process Control (SPC) 的框架，用于 OOD 检测和数据漂移监控。框架通过提取特征表示、量化漂移以及优化 SPC 参数，实现了对放射图像（如 CT 和 CXR）的有效监控，在实验中取得了高准确率（CT: 0.913, CXR: 0.995）和高敏感度（CT: 0.980, CXR: 0.984），并能快速识别漂移发生。总体而言，该框架数据无关、模型无关且可自定义，适用于各种临床应用。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08088v1",
      "published_date": "2024-02-12 22:10:06 UTC",
      "updated_date": "2024-02-12 22:10:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:24:55.557683"
    },
    {
      "arxiv_id": "2402.09476v1",
      "title": "AI-Enabled Lung Cancer Prognosis",
      "title_zh": "翻译失败",
      "authors": [
        "Mahtab Darvish",
        "Ryan Trask",
        "Patrick Tallon",
        "Mélina Khansari",
        "Lei Ren",
        "Michelle Hershman",
        "Bardia Yousefi"
      ],
      "abstract": "Lung cancer is the primary cause of cancer-related mortality, claiming\napproximately 1.79 million lives globally in 2020, with an estimated 2.21\nmillion new cases diagnosed within the same period. Among these, Non-Small Cell\nLung Cancer (NSCLC) is the predominant subtype, characterized by a notably\nbleak prognosis and low overall survival rate of approximately 25% over five\nyears across all disease stages. However, survival outcomes vary considerably\nbased on the stage at diagnosis and the therapeutic interventions administered.\nRecent advancements in artificial intelligence (AI) have revolutionized the\nlandscape of lung cancer prognosis. AI-driven methodologies, including machine\nlearning and deep learning algorithms, have shown promise in enhancing survival\nprediction accuracy by efficiently analyzing complex multi-omics data and\nintegrating diverse clinical variables. By leveraging AI techniques, clinicians\ncan harness comprehensive prognostic insights to tailor personalized treatment\nstrategies, ultimately improving patient outcomes in NSCLC. Overviewing\nAI-driven data processing can significantly help bolster the understanding and\nprovide better directions for using such systems.",
      "tldr_zh": "肺癌是全球主要癌症致死原因，Non-Small Cell Lung Cancer (NSCLC) 占主导地位，其五年整体存活率仅约25%，但通过早期诊断和治疗可显著改善预后。  \n本文探讨了artificial intelligence (AI) 技术，包括machine learning和deep learning算法，通过高效分析multi-omics data和clinical variables，提升肺癌生存预测的准确性。  \nAI驱动的方法能帮助临床医生制定个性化的治疗策略，改善患者预后，并为更好地理解和应用此类系统提供指导。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "This is the author's version of a book chapter entitled: \"Cancer\n  Research: An Interdisciplinary Approach\", Springer",
      "pdf_url": "http://arxiv.org/pdf/2402.09476v1",
      "published_date": "2024-02-12 22:09:43 UTC",
      "updated_date": "2024-02-12 22:09:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:25:06.068824"
    },
    {
      "arxiv_id": "2402.08085v1",
      "title": "Message Detouring: A Simple Yet Effective Cycle Representation for Expressive Graph Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ziquan Wei",
        "Tingting Dan",
        "Guorong Wu"
      ],
      "abstract": "Graph learning is crucial in the fields of bioinformatics, social networks,\nand chemicals. Although high-order graphlets, such as cycles, are critical to\nachieving an informative graph representation for node classification, edge\nprediction, and graph recognition, modeling high-order topological\ncharacteristics poses significant computational challenges, restricting its\nwidespread applications in machine learning. To address this limitation, we\nintroduce the concept of \\textit{message detouring} to hierarchically\ncharacterize cycle representation throughout the entire graph, which\ncapitalizes on the contrast between the shortest and longest pathways within a\nrange of local topologies associated with each graph node. The topological\nfeature representations derived from our message detouring landscape\ndemonstrate comparable expressive power to high-order\n\\textit{Weisfeiler-Lehman} (WL) tests but much less computational demands. In\naddition to the integration with graph kernel and message passing neural\nnetworks, we present a novel message detouring neural network, which uses\nTransformer backbone to integrate cycle representations across nodes and edges.\nAside from theoretical results, experimental results on expressiveness, graph\nclassification, and node classification show message detouring can\nsignificantly outperform current counterpart approaches on various benchmark\ndatasets.",
      "tldr_zh": "这篇论文提出了一种名为“message detouring”的简单方法，用于高效表征图中的循环表示，从而提升图学习的表达能力。该方法通过对比每个节点局部拓扑的最短和最长路径，层次化捕捉高阶拓扑特征，与高阶 Weisfeiler-Lehman (WL) 测试具有相媲美的表达力，但计算需求显著降低。除了整合到图核和消息传递神经网络中，论文还开发了一种基于 Transformer 的新神经网络来融合节点和边的循环表示。实验结果显示，message detouring 在图分类、节点分类等任务上，在多个基准数据集上显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08085v1",
      "published_date": "2024-02-12 22:06:37 UTC",
      "updated_date": "2024-02-12 22:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:25:18.819287"
    },
    {
      "arxiv_id": "2402.08075v1",
      "title": "Efficient and Scalable Fine-Tune of Language Models for Genome Understanding",
      "title_zh": "高效且可扩展的语言模型微调，用于基因组理解",
      "authors": [
        "Huixin Zhan",
        "Ying Nian Wu",
        "Zijun Zhang"
      ],
      "abstract": "Although DNA foundation models have advanced the understanding of genomes,\nthey still face significant challenges in the limited scale and diversity of\ngenomic data. This limitation starkly contrasts with the success of natural\nlanguage foundation models, which thrive on substantially larger scales.\nFurthermore, genome understanding involves numerous downstream genome\nannotation tasks with inherent data heterogeneity, thereby necessitating more\nefficient and robust fine-tuning methods tailored for genomics. Here, we\npresent \\textsc{Lingo}: \\textsc{L}anguage prefix f\\textsc{In}e-tuning for\n\\textsc{G}en\\textsc{O}mes. Unlike DNA foundation models, \\textsc{Lingo}\nstrategically leverages natural language foundation models' contextual cues,\nrecalibrating their linguistic knowledge to genomic sequences. \\textsc{Lingo}\nfurther accommodates numerous, heterogeneous downstream fine-tune tasks by an\nadaptive rank sampling method that prunes and stochastically reintroduces\npruned singular vectors within small computational budgets. Adaptive rank\nsampling outperformed existing fine-tuning methods on all benchmarked 14 genome\nunderstanding tasks, while requiring fewer than 2\\% of trainable parameters as\ngenomic-specific adapters. Impressively, applying these adapters on natural\nlanguage foundation models matched or even exceeded the performance of DNA\nfoundation models. \\textsc{Lingo} presents a new paradigm of efficient and\nscalable genome understanding via genomic-specific adapters on language models.",
      "tldr_zh": "尽管DNA基础模型在基因组理解方面取得了进展，但它们面临数据规模和多样性有限的挑战，与自然语言基础模型的成功形成鲜明对比。为此，本文提出\\textsc{Lingo}方法，通过利用自然语言基础模型的上下文线索并采用自适应秩采样来高效微调模型，该方法能处理多个异构下游任务，仅需不到2%的可训练参数作为基因组特定适配器。\\textsc{Lingo}在14个基因组理解任务上超越了现有微调方法，其性能匹配或超过了DNA基础模型。总之，这为基因组理解提供了高效且可扩展的新范式。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08075v1",
      "published_date": "2024-02-12 21:40:45 UTC",
      "updated_date": "2024-02-12 21:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:25:31.310397"
    },
    {
      "arxiv_id": "2402.08072v1",
      "title": "Enhancing Programming Error Messages in Real Time with Generative AI",
      "title_zh": "使用生成式 AI 实时增强编程错误消息",
      "authors": [
        "Bailey Kimmel",
        "Austin Geisert",
        "Lily Yaro",
        "Brendan Gipson",
        "Taylor Hotchkiss",
        "Sidney Osae-Asante",
        "Hunter Vaught",
        "Grant Wininger",
        "Chase Yamaguchi"
      ],
      "abstract": "Generative AI is changing the way that many disciplines are taught, including\ncomputer science. Researchers have shown that generative AI tools are capable\nof solving programming problems, writing extensive blocks of code, and\nexplaining complex code in simple terms. Particular promise has been shown in\nusing generative AI to enhance programming error messages. Both students and\ninstructors have complained for decades that these messages are often cryptic\nand difficult to understand. Yet recent work has shown that students make fewer\nrepeated errors when enhanced via GPT-4. We extend this work by implementing\nfeedback from ChatGPT for all programs submitted to our automated assessment\ntool, Athene, providing help for compiler, run-time, and logic errors. Our\nresults indicate that adding generative AI to an automated assessment tool does\nnot necessarily make it better and that design of the interface matters greatly\nto the usability of the feedback that GPT-4 provided.",
      "tldr_zh": "这篇论文探讨了使用生成式 AI（如 ChatGPT）实时增强编程错误消息，以改善计算机科学教育。研究者将 ChatGPT 集成到自动评估工具 Athene 中，为提交的程序提供针对编译器、运行时和逻辑错误的反馈，帮助学生减少重复错误。结果表明，虽然这种增强方法显示出潜力，但添加 Generative AI 不一定提升工具性能，界面的设计对反馈的可用性至关重要。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08072v1",
      "published_date": "2024-02-12 21:32:05 UTC",
      "updated_date": "2024-02-12 21:32:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:25:43.648334"
    },
    {
      "arxiv_id": "2402.08064v1",
      "title": "Beyond LLMs: Advancing the Landscape of Complex Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jennifer Chu-Carroll",
        "Andrew Beck",
        "Greg Burnham",
        "David OS Melville",
        "David Nachman",
        "A. Erdem Özcan",
        "David Ferrucci"
      ],
      "abstract": "Since the advent of Large Language Models a few years ago, they have often\nbeen considered the de facto solution for many AI problems. However, in\naddition to the many deficiencies of LLMs that prevent them from broad industry\nadoption, such as reliability, cost, and speed, there is a whole class of\ncommon real world problems that Large Language Models perform poorly on,\nnamely, constraint satisfaction and optimization problems. These problems are\nubiquitous and current solutions are highly specialized and expensive to\nimplement. At Elemental Cognition, we developed our EC AI platform which takes\na neuro-symbolic approach to solving constraint satisfaction and optimization\nproblems. The platform employs, at its core, a precise and high performance\nlogical reasoning engine, and leverages LLMs for knowledge acquisition and user\ninteraction. This platform supports developers in specifying application logic\nin natural and concise language while generating application user interfaces to\ninteract with users effectively. We evaluated LLMs against systems built on the\nEC AI platform in three domains and found the EC AI systems to significantly\noutperform LLMs on constructing valid and optimal solutions, on validating\nproposed solutions, and on repairing invalid solutions.",
      "tldr_zh": "该论文指出，大型语言模型（LLMs）尽管广泛应用，但存在可靠性、成本和速度等问题，尤其在约束满足和优化问题上表现不佳。作者介绍了 Elemental Cognition 的 EC AI 平台，该平台采用神经符号方法，以高性能逻辑推理引擎为核心，并结合 LLMs 用于知识获取和用户交互，支持开发者用自然语言指定应用逻辑并生成用户界面。在三个领域的评估中，EC AI 系统显著优于 LLMs，在构建有效解决方案、验证和修复无效解决方案方面表现出色。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08064v1",
      "published_date": "2024-02-12 21:14:45 UTC",
      "updated_date": "2024-02-12 21:14:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:25:55.322306"
    },
    {
      "arxiv_id": "2402.08062v4",
      "title": "Avoiding Catastrophe in Online Learning by Asking for Help",
      "title_zh": "通过寻求帮助避免在线学习中的灾难",
      "authors": [
        "Benjamin Plaut",
        "Hanlin Zhu",
        "Stuart Russell"
      ],
      "abstract": "Most learning algorithms with formal regret guarantees assume that all\nmistakes are recoverable and essentially rely on trying all possible behaviors.\nThis approach is problematic when some mistakes are \\emph{catastrophic}, i.e.,\nirreparable. We propose an online learning problem where the goal is to\nminimize the chance of catastrophe. Specifically, we assume that the payoff in\neach round represents the chance of avoiding catastrophe that round and try to\nmaximize the product of payoffs (the overall chance of avoiding catastrophe)\nwhile allowing a limited number of queries to a mentor. We first show that in\ngeneral, any algorithm either constantly queries the mentor or is nearly\nguaranteed to cause catastrophe. However, in settings where the mentor policy\nclass is learnable in the standard online model, we provide an algorithm whose\nregret and rate of querying the mentor both approach 0 as the time horizon\ngrows. Conceptually, if a policy class is learnable in the absence of\ncatastrophic risk, it is learnable in the presence of catastrophic risk if the\nagent can ask for help.",
      "tldr_zh": "该研究探讨了在线学习（online learning）中避免灾难性错误（catastrophic mistakes）的问题，提出一种新框架，允许代理通过有限次数向导师查询来最大化 payoff 的乘积，从而提升整体避免灾难的概率。作者证明，在一般情况下，算法要么不断查询导师，要么几乎肯定导致灾难；但在导师策略类（mentor policy class）可学习的场景下，他们提供了一个算法，其 regret 和查询频率都随时间增长而趋于 0。概念上，这表明如果一个策略类在无灾难风险环境下可学习，那么在有风险环境下，通过求助也能实现学习。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08062v4",
      "published_date": "2024-02-12 21:12:11 UTC",
      "updated_date": "2025-01-22 22:10:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:26:08.988533"
    },
    {
      "arxiv_id": "2402.08030v1",
      "title": "Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking",
      "title_zh": "翻译失败",
      "authors": [
        "Anjali Khurana",
        "Hari Subramonyam",
        "Parmit K Chilana"
      ],
      "abstract": "Large Language Model (LLM) assistants, such as ChatGPT, have emerged as\npotential alternatives to search methods for helping users navigate complex,\nfeature-rich software. LLMs use vast training data from domain-specific texts,\nsoftware manuals, and code repositories to mimic human-like interactions,\noffering tailored assistance, including step-by-step instructions. In this\nwork, we investigated LLM-generated software guidance through a within-subject\nexperiment with 16 participants and follow-up interviews. We compared a\nbaseline LLM assistant with an LLM optimized for particular software contexts,\nSoftAIBot, which also offered guidelines for constructing appropriate prompts.\nWe assessed task completion, perceived accuracy, relevance, and trust.\nSurprisingly, although SoftAIBot outperformed the baseline LLM, our results\nrevealed no significant difference in LLM usage and user perceptions with or\nwithout prompt guidelines and the integration of domain context. Most users\nstruggled to understand how the prompt's text related to the LLM's responses\nand often followed the LLM's suggestions verbatim, even if they were incorrect.\nThis resulted in difficulties when using the LLM's advice for software tasks,\nleading to low task completion rates. Our detailed analysis also revealed that\nusers remained unaware of inaccuracies in the LLM's responses, indicating a gap\nbetween their lack of software expertise and their ability to evaluate the\nLLM's assistance. With the growing push for designing domain-specific LLM\nassistants, we emphasize the importance of incorporating explainable,\ncontext-aware cues into LLMs to help users understand prompt-based\ninteractions, identify biases, and maximize the utility of LLM assistants.",
      "tldr_zh": "这篇论文探讨了LLM基础助手（如ChatGPT）在软件求助中的潜在问题，通过一个涉及16名参与者的内主体实验和后续访谈，比较了基础LLM助手与优化版SoftAIBot（提供prompt构建指南）。结果显示，虽然SoftAIBot表现更好，但用户难以理解prompt-based interactions与响应的关系，常verbatim跟随错误建议，导致任务完成率低，且无法察觉LLM响应的不准确。论文强调，为领域特定LLM助手加入可解释的、上下文感知的提示至关重要，以帮助用户识别偏差并提升助手实用性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication in the Proceedings of the 29th International\n  Conference on Intelligent User Interfaces (IUI'24), March 18--21, 2024, in\n  Greenville, SC, USA",
      "pdf_url": "http://arxiv.org/pdf/2402.08030v1",
      "published_date": "2024-02-12 19:49:58 UTC",
      "updated_date": "2024-02-12 19:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:26:21.587713"
    },
    {
      "arxiv_id": "2402.08023v1",
      "title": "UGMAE: A Unified Framework for Graph Masked Autoencoders",
      "title_zh": "UGMAE：图掩码自编码器的统一框架",
      "authors": [
        "Yijun Tian",
        "Chuxu Zhang",
        "Ziyi Kou",
        "Zheyuan Liu",
        "Xiangliang Zhang",
        "Nitesh V. Chawla"
      ],
      "abstract": "Generative self-supervised learning on graphs, particularly graph masked\nautoencoders, has emerged as a popular learning paradigm and demonstrated its\nefficacy in handling non-Euclidean data. However, several remaining issues\nlimit the capability of existing methods: 1) the disregard of uneven node\nsignificance in masking, 2) the underutilization of holistic graph information,\n3) the ignorance of semantic knowledge in the representation space due to the\nexclusive use of reconstruction loss in the output space, and 4) the unstable\nreconstructions caused by the large volume of masked contents. In light of\nthis, we propose UGMAE, a unified framework for graph masked autoencoders to\naddress these issues from the perspectives of adaptivity, integrity,\ncomplementarity, and consistency. Specifically, we first develop an adaptive\nfeature mask generator to account for the unique significance of nodes and\nsample informative masks (adaptivity). We then design a ranking-based structure\nreconstruction objective joint with feature reconstruction to capture holistic\ngraph information and emphasize the topological proximity between neighbors\n(integrity). After that, we present a bootstrapping-based similarity module to\nencode the high-level semantic knowledge in the representation space,\ncomplementary to the low-level reconstruction in the output space\n(complementarity). Finally, we build a consistency assurance module to provide\nreconstruction objectives with extra stabilized consistency targets\n(consistency). Extensive experiments demonstrate that UGMAE outperforms both\ncontrastive and generative state-of-the-art baselines on several tasks across\nmultiple datasets.",
      "tldr_zh": "论文提出 UGMAE，一种统一的框架，用于解决图掩码自编码器（graph masked autoencoders）在生成自监督学习中的问题，包括忽略节点重要性不均、未充分利用整体图信息、忽略表示空间的语义知识以及重建不稳定。框架从适应性（adaptivity）、完整性（integrity）、互补性（complementarity）和一致性（consistency）四个方面入手，具体包括开发 adaptive feature mask generator 来生成信息丰富的掩码、设计 ranking-based structure reconstruction 与特征重构相结合以捕捉整体图信息、引入 bootstrapping-based similarity module 来编码高级语义知识，以及构建 consistency assurance module 来稳定重建目标。实验结果表明，UGMAE 在多个数据集上的任务中优于对比和生成状态-of-the-art 基线，展示了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08023v1",
      "published_date": "2024-02-12 19:39:26 UTC",
      "updated_date": "2024-02-12 19:39:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:26:32.922738"
    },
    {
      "arxiv_id": "2402.08010v2",
      "title": "Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature Learning",
      "title_zh": "卷积神经网络需要哪些频率？ 特征学习中的涌现瓶颈结构",
      "authors": [
        "Yuxiao Wen",
        "Arthur Jacot"
      ],
      "abstract": "We describe the emergence of a Convolution Bottleneck (CBN) structure in\nCNNs, where the network uses its first few layers to transform the input\nrepresentation into a representation that is supported only along a few\nfrequencies and channels, before using the last few layers to map back to the\noutputs. We define the CBN rank, which describes the number and type of\nfrequencies that are kept inside the bottleneck, and partially prove that the\nparameter norm required to represent a function $f$ scales as depth times the\nCBN rank $f$. We also show that the parameter norm depends at next order on the\nregularity of $f$. We show that any network with almost optimal parameter norm\nwill exhibit a CBN structure in both the weights and - under the assumption\nthat the network is stable under large learning rate - the activations, which\nmotivates the common practice of down-sampling; and we verify that the CBN\nresults still hold with down-sampling. Finally we use the CBN structure to\ninterpret the functions learned by CNNs on a number of tasks.",
      "tldr_zh": "这篇论文揭示了卷积神经网络 (CNNs) 中自发出现的 Convolution Bottleneck (CBN) 结构，其中网络的前几层将输入转换为只保留少数频率和通道的表示，后几层再映射回输出。作者定义了 CBN rank 来量化保留的频率数量和类型，并证明了表示函数 $f$ 的参数范数与网络深度和 CBN rank 成正比，同时受函数规则性影响。研究进一步显示，优化参数范数的网络在权重和激活中会表现出 CBN 结构，支持下采样的实践，并通过此结构解释 CNNs 在多种任务上学到的函数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08010v2",
      "published_date": "2024-02-12 19:18:50 UTC",
      "updated_date": "2025-03-06 14:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:26:45.253637"
    },
    {
      "arxiv_id": "2402.16878v1",
      "title": "EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math Languages",
      "title_zh": "EvoGPT-f：一种用于基准测试形式化数学语言的进化 GPT ",
      "authors": [
        "Johnathan Mercer"
      ],
      "abstract": "Formal mathematics is the discipline of translating mathematics into a\nprogramming language in which any statement can be unequivocally checked by a\ncomputer. Mathematicians and computer scientists have spent decades of\npainstaking formalization efforts developing languages such as Coq, HOL, and\nLean. Machine learning research has converged on these formal math corpora and\ngiven rise to an assortment of methodologies to aid in interactive and\nautomated theorem proving. However, these papers have primarily focused on one\nmethod, for one proof task, in one language. This paper introduces EvoGPT-f: a\nnovel evolutionary framework for the first systematic quantitative analysis of\nthe differential machine learnability of five formal math corpora (Lean 3, Lean\n4, Coq, HOL 4, HOL Light) using four tokenization methods (character,\nword-level, Byte Pair Encoding and StarCoder tokenizer). This paper does not\nput to rest the question of the \"best\" or \"easiest\" language to learn. Rather,\nthis framework and preliminary findings begin to illuminate the differential\nmachine learnability of these languages, offering a foundation to forge more\nsystematic quantitative and qualitative comparative research across\ncommunities.",
      "tldr_zh": "这篇论文引入了 EvoGPT-f 框架，这是一个基于进化的 GPT 模型，用于系统定量分析五种正式数学语言（Lean 3, Lean 4, Coq, HOL 4, HOL Light）的机器可学习性。框架采用四种标记化方法（character, word-level, Byte Pair Encoding 和 StarCoder tokenizer）来比较这些语言的差异性，填补了现有研究中只针对单一方法或任务的局限。初步发现揭示了各语言在机器学习方面的差异，为更系统的定量和定性比较研究奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16878v1",
      "published_date": "2024-02-12 19:10:11 UTC",
      "updated_date": "2024-02-12 19:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:26:56.885089"
    },
    {
      "arxiv_id": "2402.07901v1",
      "title": "FAST: Factorizable Attention for Speeding up Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Armin Gerami",
        "Monte Hoover",
        "Pranav S. Dulepet",
        "Ramani Duraiswami"
      ],
      "abstract": "Motivated by the factorization inherent in the original fast multipole method\nand the improved fast Gauss transform we introduce a factorable form of\nattention that operates efficiently in high dimensions. This approach reduces\nthe computational and memory complexity of the attention mechanism in\ntransformers from $O(N^2)$ to $O(N)$. In comparison to previous attempts, our\nwork presents a linearly scaled attention mechanism that maintains the full\nrepresentation of the attention matrix without compromising on sparsification\nand incorporates the all-to-all relationship between tokens. We explore the\nproperties of our new attention metric and conduct tests in various standard\nsettings. Results indicate that our attention mechanism has a robust\nperformance and holds significant promise for diverse applications where\nself-attention is used.",
      "tldr_zh": "这篇论文提出了 FAST，一种因子化注意力机制（Factorizable Attention），受 fast multipole method 和 fast Gauss transform 启发，用于加速 Transformers。 该机制将注意力计算的复杂度和内存需求从 O(N^2) 降低到 O(N)，同时保持注意力矩阵的完整表示，避免稀疏化并保留所有令牌间的全连接关系。 实验结果表明，FAST 在各种标准设置中表现出稳健性能，并为自注意力广泛应用的领域提供了重要潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07901v1",
      "published_date": "2024-02-12 18:59:39 UTC",
      "updated_date": "2024-02-12 18:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:27:07.478496"
    },
    {
      "arxiv_id": "2402.07895v1",
      "title": "Detection of Spider Mites on Labrador Beans through Machine Learning Approaches Using Custom Datasets",
      "title_zh": "利用自定义数据集的机器学习方法检测Labrador Beans上的Spider Mites",
      "authors": [
        "Violet Liu",
        "Jason Chen",
        "Ans Qureshi",
        "Mahla Nejati"
      ],
      "abstract": "Amidst growing food production demands, early plant disease detection is\nessential to safeguard crops; this study proposes a visual machine learning\napproach for plant disease detection, harnessing RGB and NIR data collected in\nreal-world conditions through a JAI FS-1600D-10GE camera to build an RGBN\ndataset. A two-stage early plant disease detection model with YOLOv8 and a\nsequential CNN was used to train on a dataset with partial labels, which showed\na 3.6% increase in mAP compared to a single-stage end-to-end segmentation\nmodel. The sequential CNN model achieved 90.62% validation accuracy utilising\nRGBN data. An average of 6.25% validation accuracy increase is found using RGBN\nin classification compared to RGB using ResNet15 and the sequential CNN models.\nFurther research and dataset improvements are needed to meet food production\ndemands.",
      "tldr_zh": "这篇论文提出了一种机器学习方法，用于检测 Labrador Beans 上的 Spider Mites，利用 JAI FS-1600D-10GE 相机收集的 RGB 和 NIR 数据构建自定义 RGBN 数据集。方法采用两阶段模型，包括 YOLOv8 用于初步检测和顺序 CNN 用于分类训练，处理部分标签的数据。实验结果显示，该模型比单阶段端到端分割模型的 mAP 提高了 3.6%，并在 ResNet15 和顺序 CNN 上，使用 RGBN 数据比仅 RGB 数据平均提高了 6.25% 的验证准确率，达到 90.62%。研究强调，需要进一步优化数据集和进行更多研究，以满足日益增长的食品生产需求。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Australasian Conference on Robotics and Automation (ACRA 2023)",
      "pdf_url": "http://arxiv.org/pdf/2402.07895v1",
      "published_date": "2024-02-12 18:57:06 UTC",
      "updated_date": "2024-02-12 18:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:27:20.906577"
    },
    {
      "arxiv_id": "2402.07890v1",
      "title": "MAIDCRL: Semi-centralized Multi-Agent Influence Dense-CNN Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ayesha Siddika Nipu",
        "Siming Liu",
        "Anthony Harris"
      ],
      "abstract": "Distributed decision-making in multi-agent systems presents difficult\nchallenges for interactive behavior learning in both cooperative and\ncompetitive systems. To mitigate this complexity, MAIDRL presents a\nsemi-centralized Dense Reinforcement Learning algorithm enhanced by agent\ninfluence maps (AIMs), for learning effective multi-agent control on StarCraft\nMulti-Agent Challenge (SMAC) scenarios. In this paper, we extend the DenseNet\nin MAIDRL and introduce semi-centralized Multi-Agent Dense-CNN Reinforcement\nLearning, MAIDCRL, by incorporating convolutional layers into the deep model\narchitecture, and evaluate the performance on both homogeneous and\nheterogeneous scenarios. The results show that the CNN-enabled MAIDCRL\nsignificantly improved the learning performance and achieved a faster learning\nrate compared to the existing MAIDRL, especially on more complicated\nheterogeneous SMAC scenarios. We further investigate the stability and\nrobustness of our model. The statistics reflect that our model not only\nachieves higher winning rate in all the given scenarios but also boosts the\nagent's learning process in fine-grained decision-making.",
      "tldr_zh": "该论文提出了 MAIDCRL，一种半中心化的多智能体 Influence Dense-CNN 强化学习算法，通过代理影响图 (AIMs) 扩展了 MAIDRL，旨在解决多智能体系统中的分布式决策挑战。\nMAIDCRL 整合卷积层 (CNN) 到深度模型中，提升了在 StarCraft Multi-Agent Challenge (SMAC) 的同质和异质场景中的学习性能，特别是加速了复杂异质场景的学习过程。\n实验结果表明，该算法不仅实现了更高的获胜率，还提高了代理的细粒度决策学习、稳定性和鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "2022 IEEE Conference on Games (CoG)",
      "pdf_url": "http://arxiv.org/pdf/2402.07890v1",
      "published_date": "2024-02-12 18:53:20 UTC",
      "updated_date": "2024-02-12 18:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:27:33.051829"
    },
    {
      "arxiv_id": "2402.07877v4",
      "title": "WildfireGPT: Tailored Large Language Model for Wildfire Analysis",
      "title_zh": "WildfireGPT：针对野火分析的定制大语言模型",
      "authors": [
        "Yangxinyu Xie",
        "Bowen Jiang",
        "Tanwi Mallick",
        "Joshua David Bergerson",
        "John K. Hutchison",
        "Duane R. Verner",
        "Jordan Branham",
        "M. Ross Alexander",
        "Robert B. Ross",
        "Yan Feng",
        "Leslie-Anne Levy",
        "Weijie Su",
        "Camillo J. Taylor"
      ],
      "abstract": "Recent advancement of large language models (LLMs) represents a\ntransformational capability at the frontier of artificial intelligence.\nHowever, LLMs are generalized models, trained on extensive text corpus, and\noften struggle to provide context-specific information, particularly in areas\nrequiring specialized knowledge, such as wildfire details within the broader\ncontext of climate change. For decision-makers focused on wildfire resilience\nand adaptation, it is crucial to obtain responses that are not only precise but\nalso domain-specific. To that end, we developed WildfireGPT, a prototype LLM\nagent designed to transform user queries into actionable insights on wildfire\nrisks. We enrich WildfireGPT by providing additional context, such as climate\nprojections and scientific literature, to ensure its information is current,\nrelevant, and scientifically accurate. This enables WildfireGPT to be an\neffective tool for delivering detailed, user-specific insights on wildfire\nrisks to support a diverse set of end users, including but not limited to\nresearchers and engineers, for making positive impact and decision making.",
      "tldr_zh": "大型语言模型（LLMs）在处理特定领域如野火分析时，常因缺乏上下文而难以提供精确信息。为此，本文开发了WildfireGPT，一种针对野火风险的定制LLM代理，通过整合气候投影和科学文献等额外上下文，将用户查询转化为可操作的见解。WildfireGPT确保信息当前、相关且科学准确，支持研究人员和工程师等决策者进行野火韧性评估和适应策略，从而产生积极影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "restoring content for arXiv:2402.07877v2 which was replaced in error",
      "pdf_url": "http://arxiv.org/pdf/2402.07877v4",
      "published_date": "2024-02-12 18:41:55 UTC",
      "updated_date": "2025-04-23 03:30:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:27:45.197269"
    },
    {
      "arxiv_id": "2402.07876v6",
      "title": "Policy Improvement using Language Feedback Models",
      "title_zh": "基于语言反馈模型",
      "authors": [
        "Victor Zhong",
        "Dipendra Misra",
        "Xingdi Yuan",
        "Marc-Alexandre Côté"
      ],
      "abstract": "We introduce Language Feedback Models (LFMs) that identify desirable\nbehaviour - actions that help achieve tasks specified in the instruction - for\nimitation learning in instruction following. To train LFMs, we obtain feedback\nfrom Large Language Models (LLMs) on visual trajectories verbalized to language\ndescriptions. First, by using LFMs to identify desirable behaviour to imitate,\nwe improve in task-completion rate over strong behavioural cloning baselines on\nthree distinct language grounding environments (Touchdown, ScienceWorld, and\nALFWorld). Second, LFMs outperform using LLMs as experts to directly predict\nactions, when controlling for the number of LLM output tokens. Third, LFMs\ngeneralize to unseen environments, improving task-completion rate by 3.5-12.0%\nthrough one round of adaptation. Finally, LFM can be modified to provide\nhuman-interpretable feedback without performance loss, allowing human\nverification of desirable behaviour for imitation learning.",
      "tldr_zh": "本论文提出 Language Feedback Models (LFMs)，一种用于识别指令跟随任务中可取行为（有助于完成任务的行动）的模型，以提升模仿学习效果。训练 LFMs 时，通过 Large Language Models (LLMs) 对视觉轨迹的语言描述提供反馈，从而改善任务完成率，在 Touchdown、ScienceWorld 和 ALFWorld 环境中比行为克隆基线表现更优。实验结果显示，LFMs 在控制 LLM 输出标记数量时，优于直接使用 LLMs 预测行动；此外，LFMs 可泛化到未见环境，通过一轮适应提高任务完成率 3.5-12.0%。最后，LFMs 可以修改为提供人类可解释反馈，而不影响性能，支持人类对模仿学习行为的验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.07876v6",
      "published_date": "2024-02-12 18:41:34 UTC",
      "updated_date": "2024-10-10 03:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:28:00.963808"
    },
    {
      "arxiv_id": "2402.07875v2",
      "title": "Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States",
      "title_zh": "策略梯度在线性二次控制中的隐式偏差：对未见初始状态的外推",
      "authors": [
        "Noam Razin",
        "Yotam Alexander",
        "Edo Cohen-Karlik",
        "Raja Giryes",
        "Amir Globerson",
        "Nadav Cohen"
      ],
      "abstract": "In modern machine learning, models can often fit training data in numerous\nways, some of which perform well on unseen (test) data, while others do not.\nRemarkably, in such cases gradient descent frequently exhibits an implicit bias\nthat leads to excellent performance on unseen data. This implicit bias was\nextensively studied in supervised learning, but is far less understood in\noptimal control (reinforcement learning). There, learning a controller applied\nto a system via gradient descent is known as policy gradient, and a question of\nprime importance is the extent to which a learned controller extrapolates to\nunseen initial states. This paper theoretically studies the implicit bias of\npolicy gradient in terms of extrapolation to unseen initial states. Focusing on\nthe fundamental Linear Quadratic Regulator (LQR) problem, we establish that the\nextent of extrapolation depends on the degree of exploration induced by the\nsystem when commencing from initial states included in training. Experiments\ncorroborate our theory, and demonstrate its conclusions on problems beyond LQR,\nwhere systems are non-linear and controllers are neural networks. We\nhypothesize that real-world optimal control may be greatly improved by\ndeveloping methods for informed selection of initial states to train on.",
      "tldr_zh": "本研究探讨了在线性二次控制（Linear Quadratic Control）中，政策梯度（Policy Gradient）算法的隐式偏差（Implicit Bias），重点关注其对未见初始状态（Unseen Initial States）的推断能力。在线性二次调节器（LQR）问题中，作者证明了推断的程度取决于训练中初始状态的探索度（Degree of Exploration），并通过理论分析阐明了这一机制。实验结果验证了理论结论，并在非线性系统和神经网络控制器上进行了扩展，作者假设通过有针对性地选择训练初始状态，可以显著提升实际最优控制的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.07875v2",
      "published_date": "2024-02-12 18:41:31 UTC",
      "updated_date": "2024-06-01 18:17:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:28:09.689833"
    },
    {
      "arxiv_id": "2402.07871v1",
      "title": "Scaling Laws for Fine-Grained Mixture of Experts",
      "title_zh": "细粒度混合专家的缩放定律",
      "authors": [
        "Jakub Krajewski",
        "Jan Ludziejewski",
        "Kamil Adamczewski",
        "Maciej Pióro",
        "Michał Krutul",
        "Szymon Antoniak",
        "Kamil Ciebiera",
        "Krystian Król",
        "Tomasz Odrzygóźdź",
        "Piotr Sankowski",
        "Marek Cygan",
        "Sebastian Jaszczur"
      ],
      "abstract": "Mixture of Experts (MoE) models have emerged as a primary solution for\nreducing the computational cost of Large Language Models. In this work, we\nanalyze their scaling properties, incorporating an expanded range of variables.\nSpecifically, we introduce a new hyperparameter, granularity, whose adjustment\nenables precise control over the size of the experts. Building on this, we\nestablish scaling laws for fine-grained MoE, taking into account the number of\ntraining tokens, model size, and granularity. Leveraging these laws, we derive\nthe optimal training configuration for a given computational budget. Our\nfindings not only show that MoE models consistently outperform dense\nTransformers but also highlight that the efficiency gap between dense and MoE\nmodels widens as we scale up the model size and training budget. Furthermore,\nwe demonstrate that the common practice of setting the size of experts in MoE\nto mirror the feed-forward layer is not optimal at almost any computational\nbudget.",
      "tldr_zh": "本研究分析了Mixture of Experts (MoE) 模型的扩展属性，引入了新的超参数granularity，以精确控制专家的大小，并建立了fine-grained MoE的scaling laws，考虑了训练标记数量、模型大小和粒度因素。基于这些定律，作者推导出给定计算预算下的最优训练配置。结果显示，MoE模型在各种规模下 consistently outperform 密集Transformers模型，且效率差距随模型大小和训练预算增加而扩大；此外，常见做法将MoE专家大小设置为与前馈层相同，在几乎任何计算预算下都不是最优的。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07871v1",
      "published_date": "2024-02-12 18:33:47 UTC",
      "updated_date": "2024-02-12 18:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:28:21.357129"
    },
    {
      "arxiv_id": "2402.07865v2",
      "title": "Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models",
      "title_zh": "Prismatic VLMs：调查视觉条件语言模型的设计空间",
      "authors": [
        "Siddharth Karamcheti",
        "Suraj Nair",
        "Ashwin Balakrishna",
        "Percy Liang",
        "Thomas Kollar",
        "Dorsa Sadigh"
      ],
      "abstract": "Visually-conditioned language models (VLMs) have seen growing adoption in\napplications such as visual dialogue, scene understanding, and robotic task\nplanning; adoption that has fueled a wealth of new models such as LLaVa,\nInstructBLIP, and PaLI-3. Despite the volume of new releases, key design\ndecisions around image preprocessing, architecture, and optimization are\nunder-explored, making it challenging to understand what factors account for\nmodel performance $-$ a challenge further complicated by the lack of objective,\nconsistent evaluations. To address these gaps, we first compile a suite of\nstandardized evaluations spanning visual question answering, object\nlocalization, and challenge sets that probe properties such as hallucination;\nevaluations that provide fine-grained insight VLM capabilities. Second, we\nrigorously investigate VLMs along key design axes, including pretrained visual\nrepresentations and training from base vs. instruct-tuned language models,\namongst others. We couple our analysis with three resource contributions: (1) a\nunified framework for evaluating VLMs, (2) optimized, flexible training code,\nand (3) checkpoints for all models, including a family of VLMs at the 7-13B\nscale that strictly outperform InstructBLIP and LLaVa v1.5, the\nstate-of-the-art in open VLMs.",
      "tldr_zh": "本研究调查了视觉条件语言模型（VLMs）的设计空间，包括图像预处理、架构和优化等方面，以解决当前模型性能影响因素不明朗和评估标准不统一的问题。研究者编译了一套标准化的评估套件，涵盖视觉问答、对象定位以及探测幻觉等挑战集，提供细粒度的VLMs能力洞察。同时，他们通过分析关键设计轴（如预训练视觉表示和从基础 vs. 指令调整语言模型）开发了新模型，并贡献了统一的评估框架、优化训练代码以及一系列7-13B规模的VLMs检查点，这些模型的性能严格优于现有最先进开源模型InstructBLIP和LLaVa v1.5。总的来说，此工作为VLMs的设计和评估提供了宝贵指导，推动了其在视觉对话、场景理解和机器人任务规划等应用中的进步。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ICML 2024. 22 pages, 11 figures. Training code and\n  models: https://github.com/TRI-ML/prismatic-vlms. Evaluation code:\n  https://github.com/TRI-ML/vlm-evaluation",
      "pdf_url": "http://arxiv.org/pdf/2402.07865v2",
      "published_date": "2024-02-12 18:21:14 UTC",
      "updated_date": "2024-05-30 13:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:28:33.713895"
    },
    {
      "arxiv_id": "2402.07862v2",
      "title": "AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Schoenegger",
        "Peter S. Park",
        "Ezra Karger",
        "Sean Trott",
        "Philip E. Tetlock"
      ],
      "abstract": "Large language models (LLMs) match and sometimes exceeding human performance\nin many domains. This study explores the potential of LLMs to augment human\njudgement in a forecasting task. We evaluate the effect on human forecasters of\ntwo LLM assistants: one designed to provide high-quality (\"superforecasting\")\nadvice, and the other designed to be overconfident and base-rate neglecting,\nthus providing noisy forecasting advice. We compare participants using these\nassistants to a control group that received a less advanced model that did not\nprovide numerical predictions or engaged in explicit discussion of predictions.\nParticipants (N = 991) answered a set of six forecasting questions and had the\noption to consult their assigned LLM assistant throughout. Our preregistered\nanalyses show that interacting with each of our frontier LLM assistants\nsignificantly enhances prediction accuracy by between 24 percent and 28 percent\ncompared to the control group. Exploratory analyses showed a pronounced outlier\neffect in one forecasting item, without which we find that the superforecasting\nassistant increased accuracy by 41 percent, compared with 29 percent for the\nnoisy assistant. We further examine whether LLM forecasting augmentation\ndisproportionately benefits less skilled forecasters, degrades the\nwisdom-of-the-crowd by reducing prediction diversity, or varies in\neffectiveness with question difficulty. Our data do not consistently support\nthese hypotheses. Our results suggest that access to a frontier LLM assistant,\neven a noisy one, can be a helpful decision aid in cognitively demanding tasks\ncompared to a less powerful model that does not provide specific forecasting\nadvice. However, the effects of outliers suggest that further research into the\nrobustness of this pattern is needed.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 如何作为助手提升人类在预测任务中的准确性。研究设计了两种 LLM 助手——一个提供高质量的“superforecasting”建议，另一个则过度自信且忽略基准率（提供嘈杂建议）——并与对照组（使用不提供数字预测的简单模型）进行比较。结果显示，参与者 (N=991) 在六个预测问题上使用这些助手后，准确率提高了24%至28%；探索性分析进一步表明，“superforecasting”助手在某些问题上提升达41%。总体而言，LLMs 能有效辅助认知密集型任务，但异常值的影响提示需要更多研究其鲁棒性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "22 pages pages (main text comprised of 19 pages, appendix comprised\n  of three pages). 10 visualizations in the main text (four figures, six\n  tables), three additional figures in the appendix",
      "pdf_url": "http://arxiv.org/pdf/2402.07862v2",
      "published_date": "2024-02-12 18:14:43 UTC",
      "updated_date": "2024-08-22 13:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:28:46.438087"
    },
    {
      "arxiv_id": "2402.07860v2",
      "title": "On the Detection of Reviewer-Author Collusion Rings From Paper Bidding",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Jecmen",
        "Nihar B. Shah",
        "Fei Fang",
        "Leman Akoglu"
      ],
      "abstract": "A major threat to the peer-review systems of computer science conferences is\nthe existence of \"collusion rings\" between reviewers. In such collusion rings,\nreviewers who have also submitted their own papers to the conference work\ntogether to manipulate the conference's paper assignment, with the aim of being\nassigned to review each other's papers. The most straightforward way that\ncolluding reviewers can manipulate the paper assignment is by indicating their\ninterest in each other's papers through strategic paper bidding. One potential\napproach to solve this important problem would be to detect the colluding\nreviewers from their manipulated bids, after which the conference can take\nappropriate action. While prior work has developed effective techniques to\ndetect other kinds of fraud, no research has yet established that detecting\ncollusion rings is even possible. In this work, we tackle the question of\nwhether it is feasible to detect collusion rings from the paper bidding. To\nanswer this question, we conduct empirical analysis of two realistic conference\nbidding datasets, including evaluations of existing algorithms for fraud\ndetection in other applications. We find that collusion rings can achieve\nconsiderable success at manipulating the paper assignment while remaining\nhidden from detection: for example, in one dataset, undetected colluders are\nable to achieve assignment to up to 30% of the papers authored by other\ncolluders. In addition, when 10 colluders bid on all of each other's papers, no\ndetection algorithm outputs a group of reviewers with more than 31% overlap\nwith the true colluders. These results suggest that collusion cannot be\neffectively detected from the bidding using popular existing tools,\ndemonstrating the need to develop more complex detection algorithms as well as\nthose that leverage additional metadata (e.g., reviewer-paper text-similarity\nscores).",
      "tldr_zh": "本研究探讨了计算机科学会议中审稿人-作者合谋团伙（collusion rings）通过论文投标（paper bidding）操纵分配的问题，并评估了从投标数据中检测这些团伙的可行性。作者对两个真实会议投标数据集进行了实证分析，使用现有欺诈检测（fraud detection）算法进行评估，结果显示合谋团伙能够成功操纵分配而不被发现，例如，未检测的合谋者可分配到其他合谋者论文的30%。此外，现有算法在面对10个合谋者时，仅能输出与真实团伙重叠不超过31%的群体，这表明当前工具无法有效检测合谋，需要开发更复杂的算法并整合额外元数据（如审稿人-论文文本相似度分数）。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07860v2",
      "published_date": "2024-02-12 18:12:09 UTC",
      "updated_date": "2024-03-10 23:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:28:58.761995"
    },
    {
      "arxiv_id": "2402.07859v2",
      "title": "Lissard: Long and Simple Sequential Reasoning Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Mirelle Bueno",
        "Roberto Lotufo",
        "Rodrigo Nogueira"
      ],
      "abstract": "Language models are now capable of solving tasks that require dealing with\nlong sequences consisting of hundreds of thousands of tokens. However, they\noften fail on tasks that require repetitive use of simple rules, even on\nsequences that are much shorter than those seen during training. For example,\nstate-of-the-art LLMs can find common items in two lists with up to 20 items\nbut fail when lists have 80 items. In this paper, we introduce Lissard, a\nbenchmark comprising seven tasks whose goal is to assess the ability of models\nto process and generate wide-range sequence lengths, requiring repetitive\nprocedural execution. Our evaluation of open-source (Mistral-7B and\nMixtral-8x7B) and proprietary models (GPT-3.5 and GPT-4) show a consistent\ndecline in performance across all models as the complexity of the sequence\nincreases. The datasets and code are available at\nhttps://github.com/unicamp-dl/Lissard",
      "tldr_zh": "该研究探讨了语言模型在处理长序列时的局限性，即尽管它们能管理数万 tokens，但往往在需要重复应用简单规则的短序列上失败，例如在列表长度从20项增加到80项时。论文引入了Lissard基准测试，这是一个包含七个任务的数据集，旨在评估模型处理宽范围序列长度并执行重复程序的能力。通过评估开源模型（如Mistral-7B和Mixtral-8x7B）以及专有模型（如GPT-3.5和GPT-4），结果显示所有模型的性能均随序列复杂度增加而显著下降。数据集和代码已在GitHub上公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07859v2",
      "published_date": "2024-02-12 18:10:17 UTC",
      "updated_date": "2024-02-20 15:12:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:29:10.486856"
    },
    {
      "arxiv_id": "2402.07845v2",
      "title": "Unsupervised Optimisation of GNNs for Node Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "William Leeney",
        "Ryan McConville"
      ],
      "abstract": "Graph Neural Networks (GNNs) can be trained to detect communities within a\ngraph by learning from the duality of feature and connectivity information.\nCurrently, the common approach for optimisation of GNNs is to use comparisons\nto ground-truth for hyperparameter tuning and model selection. In this work, we\nshow that nodes can be clustered into communities with GNNs by solely\noptimising for modularity, without any comparison to ground-truth. Although\nmodularity is a graph partitioning quality metric, we show that this can be\nused to optimise GNNs that also encode features without a drop in performance.\nWe take it a step further and also study whether the unsupervised metric\nperformance can predict ground-truth performance. To investigate why modularity\ncan be used to optimise GNNs, we design synthetic experiments that show the\nlimitations of this approach. The synthetic graphs are created to highlight\ncurrent capabilities in distinct, random and zero information space partitions\nin attributed graphs. We conclude that modularity can be used for\nhyperparameter optimisation and model selection on real-world datasets as well\nas being a suitable proxy for predicting ground-truth performance, however,\nGNNs fail to balance the information duality when the spaces contain\nconflicting signals.",
      "tldr_zh": "本文提出了一种无监督方法，通过优化 modularity 来训练 GNNs（Graph Neural Networks），实现图中节点的聚类，而无需依赖 ground-truth 标签，从而避免传统超参数优化和模型选择的比较方式。实验结果表明，该方法在编码特征的同时保持性能，并能作为预测 ground-truth 性能的代理，但在合成图中，当特征和连接性信息存在冲突时，GNNs 无法有效平衡信息二元性。该研究为 GNNs 在实际数据集上的优化提供了新途径，提升了社区检测的可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07845v2",
      "published_date": "2024-02-12 17:53:43 UTC",
      "updated_date": "2024-02-20 18:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:29:22.366428"
    },
    {
      "arxiv_id": "2403.12071v1",
      "title": "Tailoring Education with GenAI: A New Horizon in Lesson Planning",
      "title_zh": "使用 GenAI 定制教育：课程规划中的新视野",
      "authors": [
        "Kostas Karpouzis",
        "Dimitris Pantazatos",
        "Joanna Taouki",
        "Kalliopi Meli"
      ],
      "abstract": "The advent of Generative AI (GenAI) in education presents a transformative\napproach to traditional teaching methodologies, which often overlook the\ndiverse needs of individual students. This study introduces a GenAI tool, based\non advanced natural language processing, designed as a digital assistant for\neducators, enabling the creation of customized lesson plans. The tool utilizes\nan innovative feature termed 'interactive mega-prompt,' a comprehensive query\nsystem that allows educators to input detailed classroom specifics such as\nstudent demographics, learning objectives, and preferred teaching styles. This\ninput is then processed by the GenAI to generate tailored lesson plans. To\nevaluate the tool's effectiveness, a comprehensive methodology incorporating\nboth quantitative (i.e., % of time savings) and qualitative (i.e., user\nsatisfaction) criteria was implemented, spanning various subjects and\neducational levels, with continuous feedback collected from educators through a\nstructured evaluation form. Preliminary results show that educators find the\nGenAI-generated lesson plans effective, significantly reducing lesson planning\ntime and enhancing the learning experience by accommodating diverse student\nneeds. This AI-driven approach signifies a paradigm shift in education,\nsuggesting its potential applicability in broader educational contexts,\nincluding special education needs (SEN), where individualized attention and\nspecific learning aids are paramount",
      "tldr_zh": "这篇论文介绍了基于 Generative AI (GenAI) 的工具，用于革新传统教学方法，以满足学生多样化需求。该工具利用高级自然语言处理 (NLP) 和创新的 'interactive mega-prompt' 功能，让教育者输入学生 demographics、学习目标及教学风格等细节，从而生成定制化课计划。通过结合定量（如节省时间百分比）和定性（如用户满意度）评估，研究发现该工具显著减少了规划时间，提升了学习体验，尤其适用于特殊教育需要 (SEN) 等情境。这种AI驱动方法标志着教育领域的范式转变，具有更广泛的应用潜力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Abstract accepted for EDUCON 2024 (IEEE Global Engineering Education\n  Conference 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.12071v1",
      "published_date": "2024-02-12 17:30:05 UTC",
      "updated_date": "2024-02-12 17:30:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:29:33.645875"
    },
    {
      "arxiv_id": "2402.07822v1",
      "title": "Understanding fitness landscapes in morpho-evolution via local optima networks",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah L. Thomson",
        "Léni K. Le Goff",
        "Emma Hart",
        "Edgar Buchanan"
      ],
      "abstract": "Morpho-evolution (ME) refers to the simultaneous optimisation of a robot's\ndesign and controller to maximise performance given a task and environment.\nMany genetic encodings have been proposed which are capable of representing\ndesign and control. Previous research has provided empirical comparisons\nbetween encodings in terms of their performance with respect to an objective\nfunction and the diversity of designs that are evaluated, however there has\nbeen no attempt to explain the observed findings. We address this by applying\nLocal Optima Network (LON) analysis to investigate the structure of the fitness\nlandscapes induced by three different encodings when evolving a robot for a\nlocomotion task, shedding new light on the ease by which different fitness\nlandscapes can be traversed by a search process. This is the first time LON\nanalysis has been applied in the field of ME despite its popularity in\ncombinatorial optimisation domains; the findings will facilitate design of new\nalgorithms or operators that are customised to ME landscapes in the future.",
      "tldr_zh": "本文通过 Local Optima Network (LON) 分析，探讨了 Morpho-evolution (ME) 领域中适应度景观的结构，旨在解释不同遗传编码在优化机器人设计和控制器时的性能差异。研究聚焦于三种编码在机器人运动任务中的表现，揭示了这些景观的拓扑特征如何影响搜索过程的遍历效率。首次将 LON 分析应用于 ME 领域，该发现为未来设计针对性算法或操作符提供了重要指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to GECCO-2024",
      "pdf_url": "http://arxiv.org/pdf/2402.07822v1",
      "published_date": "2024-02-12 17:26:35 UTC",
      "updated_date": "2024-02-12 17:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:29:45.770969"
    },
    {
      "arxiv_id": "2402.07818v6",
      "title": "Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Z Liu",
        "J Lou",
        "W Bao",
        "Y Hu",
        "B Li",
        "Z Qin",
        "K Ren"
      ],
      "abstract": "Fine-tuning on task-specific datasets is a widely-embraced paradigm of\nharnessing the powerful capability of pretrained LLMs for various downstream\ntasks. Due to the popularity of LLMs fine-tuning and its accompanying privacy\nconcerns, differentially private (DP) fine-tuning of pretrained LLMs has been\nwidely used to safeguarding the privacy of task-specific datasets. Lying at the\ndesign core of DP LLM fine-tuning methods is the satisfactory tradeoff among\nprivacy, utility, and scalability. Most existing methods build upon the seminal\nwork of DP-SGD. Despite pushing the scalability of DP-SGD to its limit,\nDP-SGD-based fine-tuning methods are unfortunately limited by the inherent\ninefficiency of SGD.\n  In this paper, we investigate the potential of DP zeroth-order methods for\nLLM pretraining, which avoids the scalability bottleneck of SGD by\napproximating the gradient with the more efficient zeroth-order gradient.\nRather than treating the zeroth-order method as a drop-in replacement for SGD,\nthis paper presents a comprehensive study both theoretically and empirically.\nFirst, we propose the stagewise DP zeroth-order method (DP-ZOSO) that\ndynamically schedules key hyperparameters. This design is grounded on the\nsynergy between DP random perturbation and the gradient approximation error of\nthe zeroth-order method, and its effect on fine-tuning trajectory.\n  We provide theoretical analysis for both proposed methods. We conduct\nextensive empirical analysis on both encoder-only masked language model and\ndecoder-only autoregressive language model, achieving impressive results in\nterms of scalability and utility regardless of the class of tasks (compared\nwith DPZero, DP-ZOPO improves $4.5\\%$ on SST-5, $5.5\\%$ on MNLI with\nRoBERTa-Large and 9.2\\% on CB, 3.9\\% on BoolQ with OPT-2.7b when $\\epsilon=4$,\ndemonstrates more significant enhancement in performance on more complicated\ntasks).",
      "tldr_zh": "本文研究了在大型语言模型（Large Language Models, LLMs）微调中应用微分隐私（Differentially Private, DP）方法，以保护任务特定数据集的隐私，同时解决DP-SGD方法效率低下的问题。作者提出了一种阶段式DP zeroth-order方法（DP-ZOSO），通过动态调度关键超参数和zeroth-order梯度近似来优化微调过程，提升可扩展性和实用性。实验结果显示，DP-ZOSO在各种模型（如RoBERTa-Large和OPT-2.7b）上显著提高了性能，例如在ε=4时，与DPZero相比，在SST-5上提升4.5%、在MNLI上提升5.5%，并在更复杂的任务中表现出更大优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07818v6",
      "published_date": "2024-02-12 17:24:15 UTC",
      "updated_date": "2025-03-10 06:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:29:59.552437"
    },
    {
      "arxiv_id": "2402.07814v1",
      "title": "PBADet: A One-Stage Anchor-Free Approach for Part-Body Association",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongpai Gao",
        "Huayi Zhou",
        "Abhishek Sharma",
        "Meng Zheng",
        "Benjamin Planche",
        "Terrence Chen",
        "Ziyan Wu"
      ],
      "abstract": "The detection of human parts (e.g., hands, face) and their correct\nassociation with individuals is an essential task, e.g., for ubiquitous\nhuman-machine interfaces and action recognition. Traditional methods often\nemploy multi-stage processes, rely on cumbersome anchor-based systems, or do\nnot scale well to larger part sets. This paper presents PBADet, a novel\none-stage, anchor-free approach for part-body association detection. Building\nupon the anchor-free object representation across multi-scale feature maps, we\nintroduce a singular part-to-body center offset that effectively encapsulates\nthe relationship between parts and their parent bodies. Our design is\ninherently versatile and capable of managing multiple parts-to-body\nassociations without compromising on detection accuracy or robustness.\nComprehensive experiments on various datasets underscore the efficacy of our\napproach, which not only outperforms existing state-of-the-art techniques but\nalso offers a more streamlined and efficient solution to the part-body\nassociation challenge.",
      "tldr_zh": "这篇论文介绍了 PBADet，一种一阶段、无锚点的方法，用于检测人类身体部位（如手、脸）并正确关联到个体，适用于人机交互和动作识别等领域。PBADet 基于多尺度特征图，引入单一的 part-to-body center offset 来封装部位与身体的关系，实现灵活处理多个部位-身体关联，同时保持高准确性和鲁棒性。实验在各种数据集上证明，PBADet 优于现有最先进技术，并提供更高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR2024",
      "pdf_url": "http://arxiv.org/pdf/2402.07814v1",
      "published_date": "2024-02-12 17:18:51 UTC",
      "updated_date": "2024-02-12 17:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:30:10.604630"
    },
    {
      "arxiv_id": "2402.07812v2",
      "title": "Retrieval Augmented Thought Process for Private Data Handling in Healthcare",
      "title_zh": "检索增强思考过程用于医疗保健中的私有数据处理",
      "authors": [
        "Thomas Pouplin",
        "Hao Sun",
        "Samuel Holt",
        "Mihaela van der Schaar"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated the strong potential to assist\nboth clinicians and the general public with their extensive medical knowledge.\nHowever, their application in healthcare is constrained due to concerns about\nthe privacy of data used in training, which prevents the integration of private\nand personal information because of security and ethical issues. Moreover, if\ntheir capabilities can be enhanced with information retrieval to access\nup-to-date knowledge, the current integration of LLMs with Information\nretrieval lacks robustness to imperfect retrieval, which can hinder their\neffectiveness and even reduce overall performance. In this work, we address\nthis challenge by introducing the Retrieval-Augmented Thought Process (RATP).\nGiven access to external knowledge, RATP formulates the thought generation of\nLLMs as a multiple-step decision process. To optimise such a thought process,\nRATP leverages Monte-Carlo Tree Search and learns a proxy reward function that\npermits cost-efficient inference. On a private dataset of electronic medical\nrecords, deliberately excluded from any LLM training set, RATP achieves 35%\nadditional accuracy compared to in-context retrieval-augmented generation for\nthe question-answering task.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）在医疗领域的隐私挑战，提出了一种Retrieval-Augmented Thought Process (RATP)方法，以优化LLMs对私人数据的处理。RATP将思想生成过程视为多步决策，利用Monte-Carlo Tree Search和代理奖励函数来增强信息检索的鲁棒性，从而更好地整合外部知识。实验结果显示，在一个未用于LLMs训练的私人电子医疗记录数据集上，RATP在问答任务中比传统的检索增强生成方法提高了35%的准确率，为医疗隐私保护和知识更新提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "H.3.3; I.2.6; I.2.7; I.2.8"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07812v2",
      "published_date": "2024-02-12 17:17:50 UTC",
      "updated_date": "2024-08-07 18:27:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:30:22.983006"
    },
    {
      "arxiv_id": "2402.07799v2",
      "title": "Generalising Planning Environment Redesign",
      "title_zh": "泛化规划环境重设计",
      "authors": [
        "Alberto Pozanco",
        "Ramon Fraga Pereira",
        "Daniel Borrajo"
      ],
      "abstract": "In Environment Design, one interested party seeks to affect another agent's\ndecisions by applying changes to the environment. Most research on planning\nenvironment (re)design assumes the interested party's objective is to\nfacilitate the recognition of goals and plans, and search over the space of\nenvironment modifications to find the minimal set of changes that simplify\nthose tasks and optimise a particular metric. This search space is usually\nintractable, so existing approaches devise metric-dependent pruning techniques\nfor performing search more efficiently. This results in approaches that are not\nable to generalise across different objectives and/or metrics. In this paper,\nwe argue that the interested party could have objectives and metrics that are\nnot necessarily related to recognising agents' goals or plans. Thus, to\ngeneralise the task of Planning Environment Redesign, we develop a general\nenvironment redesign approach that is metric-agnostic and leverages recent\nresearch on top-quality planning to efficiently redesign planning environments\naccording to any interested party's objective and metric. Experiments over a\nset of environment redesign benchmarks show that our general approach\noutperforms existing approaches when using well-known metrics, such as\nfacilitating the recognition of goals, as well as its effectiveness when\nsolving environment redesign tasks that optimise a novel set of different\nmetrics.",
      "tldr_zh": "本文扩展了环境设计中的Planning Environment Redesign问题，指出现有方法仅针对特定目标（如识别代理目标和计划）进行优化，导致无法泛化到其他指标。作者提出一个metric-agnostic的通用环境重设计方法，利用顶级规划研究来高效搜索和修改环境，以适应任意目标和指标。实验在基准数据集上证明，该方法在常见指标（如目标识别）上比现有方法性能提升，并在优化新型指标的任务中表现出显著有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted at AAAI'24",
      "pdf_url": "http://arxiv.org/pdf/2402.07799v2",
      "published_date": "2024-02-12 17:03:58 UTC",
      "updated_date": "2024-02-14 14:01:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:30:33.707746"
    },
    {
      "arxiv_id": "2402.07787v3",
      "title": "Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis",
      "title_zh": "可扩展多粒度融合",
      "authors": [
        "Xiaowei Zhao",
        "Yong Zhou",
        "Xiujuan Xu",
        "Yu Liu"
      ],
      "abstract": "Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within\na text to comprehend sentiment information. Previous studies integrated\nexternal knowledge, such as knowledge graphs, to enhance the semantic features\nin ABSA models. Recent research has examined the use of Graph Neural Networks\n(GNNs) on dependency and constituent trees for syntactic analysis. With the\nongoing development of ABSA, more innovative linguistic and structural features\nare being incorporated (e.g. latent graph), but this also introduces complexity\nand confusion. As of now, a scalable framework for integrating diverse\nlinguistic and structural features into ABSA does not exist. This paper\npresents the Extensible Multi-Granularity Fusion (EMGF) network, which\nintegrates information from dependency and constituent syntactic, attention\nsemantic , and external knowledge graphs. EMGF, equipped with multi-anchor\ntriplet learning and orthogonal projection, efficiently harnesses the combined\npotential of each granularity feature and their synergistic interactions,\nresulting in a cumulative effect without additional computational expenses.\nExperimental findings on SemEval 2014 and Twitter datasets confirm EMGF's\nsuperiority over existing ABSA methods.",
      "tldr_zh": "本论文针对Aspect-based Sentiment Analysis (ABSA) 的挑战，提出了一种可扩展的多粒度融合网络(Extensible Multi-Granularity Fusion, EMGF)，以整合依赖句法(dependency syntactic)、成分句法(constituent syntactic)、注意力语义(attention semantic)以及外部知识图谱(external knowledge graphs)等多样特征。EMGF 通过多锚点三元组学习(multi-anchor triplet learning)和正交投影(orthogonal projection)机制，实现特征的协同交互和高效融合，从而在不增加计算开销的情况下提升整体性能。实验结果在SemEval 2014和Twitter数据集上表明，EMGF 优于现有ABSA方法，证明了其在处理复杂语言特征方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07787v3",
      "published_date": "2024-02-12 16:52:26 UTC",
      "updated_date": "2024-03-04 08:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:30:48.849021"
    },
    {
      "arxiv_id": "2402.07772v1",
      "title": "End-to-End Learning for Fair Multiobjective Optimization Under Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "My H Dinh",
        "James Kotary",
        "Ferdinando Fioretto"
      ],
      "abstract": "Many decision processes in artificial intelligence and operations research\nare modeled by parametric optimization problems whose defining parameters are\nunknown and must be inferred from observable data. The Predict-Then-Optimize\n(PtO) paradigm in machine learning aims to maximize downstream decision quality\nby training the parametric inference model end-to-end with the subsequent\nconstrained optimization. This requires backpropagation through the\noptimization problem using approximation techniques specific to the problem's\nform, especially for nondifferentiable linear and mixed-integer programs. This\npaper extends the PtO methodology to optimization problems with\nnondifferentiable Ordered Weighted Averaging (OWA) objectives, known for their\nability to ensure properties of fairness and robustness in decision models.\nThrough a collection of training techniques and proposed application settings,\nit shows how optimization of OWA functions can be effectively integrated with\nparametric prediction for fair and robust optimization under uncertainty.",
      "tldr_zh": "这篇论文扩展了 Predict-Then-Optimize (PtO) 范式，通过端到端学习方法来处理不确定条件下的公平多目标优化问题，特别是针对非微分的 Ordered Weighted Averaging (OWA) 目标函数。作者提出了一系列训练技巧和应用设置，将参数预测与优化问题整合，确保决策模型具备公平性和鲁棒性。结果显示，这种方法能有效解决未知参数的优化挑战，提升了下游决策质量。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07772v1",
      "published_date": "2024-02-12 16:33:35 UTC",
      "updated_date": "2024-02-12 16:33:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:30:58.570477"
    },
    {
      "arxiv_id": "2402.07757v1",
      "title": "Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Mikail Khona",
        "Maya Okawa",
        "Jan Hula",
        "Rahul Ramesh",
        "Kento Nishi",
        "Robert Dick",
        "Ekdeep Singh Lubana",
        "Hidenori Tanaka"
      ],
      "abstract": "Stepwise inference protocols, such as scratchpads and chain-of-thought, help\nlanguage models solve complex problems by decomposing them into a sequence of\nsimpler subproblems. Despite the significant gain in performance achieved via\nthese protocols, the underlying mechanisms of stepwise inference have remained\nelusive. To address this, we propose to study autoregressive Transformer models\non a synthetic task that embodies the multi-step nature of problems where\nstepwise inference is generally most useful. Specifically, we define a graph\nnavigation problem wherein a model is tasked with traversing a path from a\nstart to a goal node on the graph. Despite is simplicity, we find we can\nempirically reproduce and analyze several phenomena observed at scale: (i) the\nstepwise inference reasoning gap, the cause of which we find in the structure\nof the training data; (ii) a diversity-accuracy tradeoff in model generations\nas sampling temperature varies; (iii) a simplicity bias in the model's output;\nand (iv) compositional generalization and a primacy bias with in-context\nexemplars. Overall, our work introduces a grounded, synthetic framework for\nstudying stepwise inference and offers mechanistic hypotheses that can lay the\nfoundation for a deeper understanding of this phenomenon.",
      "tldr_zh": "本研究旨在理解Transformer模型中的逐步推理机制（如chain-of-thought），通过一个合成图导航任务来模拟多步推理问题，其中模型需从起始节点导航到目标节点。作者发现，训练数据的结构导致了逐步推理的推理差距；同时，采样温度变化会带来生成多样性与准确性的权衡。实验还揭示了模型的简单性偏好、组合泛化和上下文示例中的优先性偏好。总体上，该框架为深入探索逐步推理现象提供了机制假设和基础支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07757v1",
      "published_date": "2024-02-12 16:25:47 UTC",
      "updated_date": "2024-02-12 16:25:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:31:09.830660"
    },
    {
      "arxiv_id": "2402.07754v3",
      "title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiacheng Ye",
        "Shansan Gong",
        "Liheng Chen",
        "Lin Zheng",
        "Jiahui Gao",
        "Han Shi",
        "Chuan Wu",
        "Xin Jiang",
        "Zhenguo Li",
        "Wei Bi",
        "Lingpeng Kong"
      ],
      "abstract": "Recently, diffusion models have garnered significant interest in the field of\ntext processing due to their many potential advantages compared to conventional\nautoregressive models. In this work, we propose Diffusion-of-Thought (DoT), a\nnovel approach that integrates diffusion models with Chain-of-Thought, a\nwell-established technique for improving the reasoning ability of\nautoregressive language models. In contrast to autoregressive language models\nthat make decisions in a left-to-right, token-by-token manner, DoT allows\nreasoning steps to diffuse over time through a diffusion language model and\noffers greater flexibility in trading-off computation for reasoning\nperformance. Our experimental results demonstrate the effectiveness of DoT in\nmulti-digit multiplication, boolean logic, and grade school math problems, with\na small diffusion model outperforming a much larger autoregressive model in\nboth efficiency and accuracy. In addition to that, DoT showcases promising\nself-correction abilities and benefits from existing reasoning-enhancing\ntechniques like self-consistency decoding. Our findings contribute to the\nunderstanding and development of reasoning with diffusion language models.",
      "tldr_zh": "本文提出 Diffusion-of-Thought (DoT) 方法，将扩散模型与 Chain-of-Thought 推理相结合，以提升语言模型的推理能力。不同于 autoregressive 模型的逐 token 左到右处理，DoT 允许推理步骤通过扩散语言模型在时间上扩散，从而提供更大的灵活性，在计算资源和性能之间实现权衡。实验结果显示，一个较小的扩散模型在多位乘法、布尔逻辑和小学生数学问题上，效率和准确性均优于更大的 autoregressive 模型；此外，DoT 展现出良好的自校正能力，并能从现有技术如 self-consistency decoding 中获益。该研究为基于扩散语言模型的推理发展提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.07754v3",
      "published_date": "2024-02-12 16:23:28 UTC",
      "updated_date": "2024-12-05 06:49:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:31:23.079057"
    },
    {
      "arxiv_id": "2402.07744v2",
      "title": "Towards Unified Alignment Between Agents, Humans, and Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Zonghan Yang",
        "An Liu",
        "Zijun Liu",
        "Kaiming Liu",
        "Fangzhou Xiong",
        "Yile Wang",
        "Zeyuan Yang",
        "Qingyuan Hu",
        "Xinrui Chen",
        "Zhenhe Zhang",
        "Fuwen Luo",
        "Zhicheng Guo",
        "Peng Li",
        "Yang Liu"
      ],
      "abstract": "The rapid progress of foundation models has led to the prosperity of\nautonomous agents, which leverage the universal capabilities of foundation\nmodels to conduct reasoning, decision-making, and environmental interaction.\nHowever, the efficacy of agents remains limited when operating in intricate,\nrealistic environments. In this work, we introduce the principles of\n$\\mathbf{U}$nified $\\mathbf{A}$lignment for $\\mathbf{A}$gents\n($\\mathbf{UA}^2$), which advocate for the simultaneous alignment of agents with\nhuman intentions, environmental dynamics, and self-constraints such as the\nlimitation of monetary budgets. From the perspective of $\\mathbf{UA}^2$, we\nreview the current agent research and highlight the neglected factors in\nexisting agent benchmarks and method candidates. We also conduct\nproof-of-concept studies by introducing realistic features to WebShop,\nincluding user profiles to demonstrate intentions, personalized reranking for\ncomplex environmental dynamics, and runtime cost statistics to reflect\nself-constraints. We then follow the principles of $\\mathbf{UA}^2$ to propose\nan initial design of our agent, and benchmark its performance with several\ncandidate baselines in the retrofitted WebShop. The extensive experimental\nresults further prove the importance of the principles of $\\mathbf{UA}^2$. Our\nresearch sheds light on the next steps of autonomous agent research with\nimproved general problem-solving abilities.",
      "tldr_zh": "本研究探讨了基础模型(foundation models)的快速发展如何推动自治代理(autonomous agents)的兴起，但这些代理在复杂环境中效率有限。作者提出 UA²（Unified Alignment for Agents）原则，强调代理需同时与人类意图、环境动态（如复杂互动）和自身约束（如预算限制）对齐，并通过回顾现有研究和概念验证（如在 WebShop 中添加用户配置文件、个性化重新排序及运行时成本统计）来突出忽略因素。基于 UA² 原则，他们设计并基准测试了一个初始代理，在改进后的 WebShop 上，其性能优于基线模型，实验结果验证了统一对齐的重要性，为提升代理的通用问题解决能力提供了新方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Project webpage:\n  https://agent-force.github.io/unified-alignment-for-agents.html",
      "pdf_url": "http://arxiv.org/pdf/2402.07744v2",
      "published_date": "2024-02-12 16:14:22 UTC",
      "updated_date": "2024-02-14 18:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:31:34.427929"
    },
    {
      "arxiv_id": "2402.07712v2",
      "title": "Model Collapse Demystified: The Case of Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Elvis Dohmatob",
        "Yunzhen Feng",
        "Julia Kempe"
      ],
      "abstract": "In the era of proliferation of large language and image generation models,\nthe phenomenon of \"model collapse\" refers to the situation whereby as a model\nis trained recursively on data generated from previous generations of itself\nover time, its performance degrades until the model eventually becomes\ncompletely useless, i.e the model collapses. In this work, we study this\nphenomenon in the setting of high-dimensional regression and obtain analytic\nformulae which quantitatively outline this phenomenon in a broad range of\nregimes. In the special case of polynomial decaying spectral and source\nconditions, we obtain modified scaling laws which exhibit new crossover\nphenomena from fast to slow rates. We also propose a simple strategy based on\nadaptive regularization to mitigate model collapse. Our theoretical results are\nvalidated with experiments.",
      "tldr_zh": "本研究探讨了“model collapse”现象在高维回归场景中的表现，即模型递归训练于自身生成的数据，导致性能逐渐下降直至失效。作者通过解析公式量化了这一现象在各种条件下发生的过程，并在多项式衰减的光谱和源条件下，推导出新的scaling laws，揭示了从快速到缓慢速率的交叉现象。为缓解model collapse，他们提出了一种基于adaptive regularization的简单策略，并通过实验验证了理论结果。这些发现为理解和应对模型退化提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07712v2",
      "published_date": "2024-02-12 15:26:01 UTC",
      "updated_date": "2024-04-30 18:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:31:46.633432"
    },
    {
      "arxiv_id": "2402.07703v3",
      "title": "Online Sequential Decision-Making with Unknown Delays",
      "title_zh": "翻译失败",
      "authors": [
        "Ping Wu",
        "Heyan Huang",
        "Zhengyang Liu"
      ],
      "abstract": "In the field of online sequential decision-making, we address the problem\nwith delays utilizing the framework of online convex optimization (OCO), where\nthe feedback of a decision can arrive with an unknown delay. Unlike previous\nresearch that is limited to Euclidean norm and gradient information, we propose\nthree families of delayed algorithms based on approximate solutions to handle\ndifferent types of received feedback. Our proposed algorithms are versatile and\napplicable to universal norms. Specifically, we introduce a family of Follow\nthe Delayed Regularized Leader algorithms for feedback with full information on\nthe loss function, a family of Delayed Mirror Descent algorithms for feedback\nwith gradient information on the loss function and a family of Simplified\nDelayed Mirror Descent algorithms for feedback with the value information of\nthe loss function's gradients at corresponding decision points. For each type\nof algorithm, we provide corresponding regret bounds under cases of general\nconvexity and relative strong convexity, respectively. We also demonstrate the\nefficiency of each algorithm under different norms through concrete examples.\nFurthermore, our theoretical results are consistent with the current best\nbounds when degenerated to standard settings.",
      "tldr_zh": "本研究探讨了在线序列决策中的未知延迟反馈问题，使用在线凸优化（OCO）框架提出三种基于近似解决方案的算法家族，以处理不同反馈类型。这些算法包括Follow the Delayed Regularized Leader（针对全损失函数信息）、Delayed Mirror Descent（针对梯度信息）和Simplified Delayed Mirror Descent（针对损失函数梯度值信息），并适用于通用范数。论文提供了每个算法在一般凸性和相对强凸性情况下的regret bounds分析，并通过具体例子证明了它们在不同范数下的效率，与现有标准设置的最佳界限一致。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07703v3",
      "published_date": "2024-02-12 15:17:31 UTC",
      "updated_date": "2024-02-23 06:05:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:31:59.417923"
    },
    {
      "arxiv_id": "2402.07689v2",
      "title": "OrderBkd: Textual backdoor attack through repositioning",
      "title_zh": "翻译失败",
      "authors": [
        "Irina Alekseevskaia",
        "Konstantin Arkhipenko"
      ],
      "abstract": "The use of third-party datasets and pre-trained machine learning models poses\na threat to NLP systems due to possibility of hidden backdoor attacks. Existing\nattacks involve poisoning the data samples such as insertion of tokens or\nsentence paraphrasing, which either alter the semantics of the original texts\nor can be detected. Our main difference from the previous work is that we use\nthe reposition of a two words in a sentence as a trigger. By designing and\napplying specific part-of-speech (POS) based rules for selecting these tokens,\nwe maintain high attack success rate on SST-2 and AG classification datasets\nwhile outperforming existing attacks in terms of perplexity and semantic\nsimilarity to the clean samples. In addition, we show the robustness of our\nattack to the ONION defense method. All the code and data for the paper can be\nobtained at https://github.com/alekseevskaia/OrderBkd.",
      "tldr_zh": "这篇论文提出了一种名为OrderBkd的文本后门攻击方法，通过重新定位句子中两个单词的位置作为触发器，避免了现有攻击中插入标记或改写句子带来的语义改变和检测风险。作者设计了基于词性（POS）的规则来选择这些单词，确保在SST-2和AG分类数据集上实现高攻击成功率，同时在perplexity和semantic similarity方面优于现有方法。实验结果还证明了OrderBkd对ONION防御方法的鲁棒性，为NLP系统的安全威胁研究提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07689v2",
      "published_date": "2024-02-12 14:53:37 UTC",
      "updated_date": "2024-04-06 21:41:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:32:11.091666"
    },
    {
      "arxiv_id": "2402.07688v2",
      "title": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Norbert Tihanyi",
        "Mohamed Amine Ferrag",
        "Ridhi Jain",
        "Tamas Bisztray",
        "Merouane Debbah"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used across various domains,\nfrom software development to cyber threat intelligence. Understanding all the\ndifferent fields of cybersecurity, which includes topics such as cryptography,\nreverse engineering, and risk assessment, poses a challenge even for human\nexperts. To accurately test the general knowledge of LLMs in cybersecurity, the\nresearch community needs a diverse, accurate, and up-to-date dataset. To\naddress this gap, we present CyberMetric-80, CyberMetric-500, CyberMetric-2000,\nand CyberMetric-10000, which are multiple-choice Q&A benchmark datasets\ncomprising 80, 500, 2000, and 10,000 questions respectively. By utilizing\nGPT-3.5 and Retrieval-Augmented Generation (RAG), we collected documents,\nincluding NIST standards, research papers, publicly accessible books, RFCs, and\nother publications in the cybersecurity domain, to generate questions, each\nwith four possible answers. The results underwent several rounds of error\nchecking and refinement. Human experts invested over 200 hours validating the\nquestions and solutions to ensure their accuracy and relevance, and to filter\nout any questions unrelated to cybersecurity. We have evaluated and compared 25\nstate-of-the-art LLM models on the CyberMetric datasets. In addition to our\nprimary goal of evaluating LLMs, we involved 30 human participants to solve\nCyberMetric-80 in a closed-book scenario. The results can serve as a reference\nfor comparing the general cybersecurity knowledge of humans and LLMs. The\nfindings revealed that GPT-4o, GPT-4-turbo, Mixtral-8x7B-Instruct,\nFalcon-180B-Chat, and GEMINI-pro 1.0 were the best-performing LLMs.\nAdditionally, the top LLMs were more accurate than humans on CyberMetric-80,\nalthough highly experienced human experts still outperformed small models such\nas Llama-3-8B, Phi-2 or Gemma-7b.",
      "tldr_zh": "该论文提出了 CyberMetric 系列基准数据集，包括 CyberMetric-80、-500、-2000 和-10000，用于评估大型语言模型 (LLMs) 在网络安全知识领域的表现，这些数据集包含多选问答题，涵盖密码学、逆向工程和风险评估等主题。数据集通过 GPT-3.5 和 Retrieval-Augmented Generation (RAG) 技术生成，利用 NIST 标准、研究论文、书籍和 RFC 等来源，并经人类专家超过 200 小时的验证以确保准确性和相关性。研究评估了 25 个最先进 LLM 模型，并在 CyberMetric-80 上与 30 名人类参与者比较，结果显示 GPT-4o、GPT-4-turbo、Mixtral-8x7B-Instruct 等模型表现最佳，且顶尖 LLM 在某些方面超过了人类，但经验丰富的专家仍优于小型模型如 Llama-3-8B 或 Gemma-7b。该工作为比较 LLMs 和人类在网络安全知识上的能力提供了宝贵参考。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07688v2",
      "published_date": "2024-02-12 14:53:28 UTC",
      "updated_date": "2024-06-03 08:14:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:32:24.116680"
    },
    {
      "arxiv_id": "2402.07681v1",
      "title": "Large Language Models \"Ad Referendum\": How Good Are They at Machine Translation in the Legal Domain?",
      "title_zh": "翻译失败",
      "authors": [
        "Vicent Briva-Iglesias",
        "Joao Lucas Cavalheiro Camargo",
        "Gokhan Dogru"
      ],
      "abstract": "This study evaluates the machine translation (MT) quality of two\nstate-of-the-art large language models (LLMs) against a tradition-al neural\nmachine translation (NMT) system across four language pairs in the legal\ndomain. It combines automatic evaluation met-rics (AEMs) and human evaluation\n(HE) by professional transla-tors to assess translation ranking, fluency and\nadequacy. The re-sults indicate that while Google Translate generally\noutperforms LLMs in AEMs, human evaluators rate LLMs, especially GPT-4,\ncomparably or slightly better in terms of producing contextually adequate and\nfluent translations. This discrepancy suggests LLMs' potential in handling\nspecialized legal terminology and context, highlighting the importance of human\nevaluation methods in assessing MT quality. The study underscores the evolving\ncapabil-ities of LLMs in specialized domains and calls for reevaluation of\ntraditional AEMs to better capture the nuances of LLM-generated translations.",
      "tldr_zh": "本研究评估了两个先进的大型语言模型（LLMs）在法律领域的机器翻译（MT）质量，与传统的神经机器翻译（NMT）系统进行比较，涉及四种语言对。评估方法结合了自动评估指标（AEMs）和人类评估（HE），由专业翻译者评估翻译的排名、流畅性和充分性。结果显示，虽然 Google Translate 在 AEMs 上表现更优，但人类评估者认为 LLMs，尤其是 GPT-4，在处理专业法律术语和上下文方面提供更充分和流畅的翻译。研究强调了 LLMs 在专业领域的潜力，并呼吁重新评估传统的 AEMs，以更好地捕捉 LLM 生成翻译的细微差别。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07681v1",
      "published_date": "2024-02-12 14:40:54 UTC",
      "updated_date": "2024-02-12 14:40:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:32:36.340730"
    },
    {
      "arxiv_id": "2402.07680v1",
      "title": "AYDIV: Adaptable Yielding 3D Object Detection via Integrated Contextual Vision Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Tanmoy Dam",
        "Sanjay Bhargav Dharavath",
        "Sameer Alam",
        "Nimrod Lilith",
        "Supriyo Chakraborty",
        "Mir Feroskhan"
      ],
      "abstract": "Combining LiDAR and camera data has shown potential in enhancing\nshort-distance object detection in autonomous driving systems. Yet, the fusion\nencounters difficulties with extended distance detection due to the contrast\nbetween LiDAR's sparse data and the dense resolution of cameras. Besides,\ndiscrepancies in the two data representations further complicate fusion\nmethods. We introduce AYDIV, a novel framework integrating a tri-phase\nalignment process specifically designed to enhance long-distance detection even\namidst data discrepancies. AYDIV consists of the Global Contextual Fusion\nAlignment Transformer (GCFAT), which improves the extraction of camera features\nand provides a deeper understanding of large-scale patterns; the Sparse Fused\nFeature Attention (SFFA), which fine-tunes the fusion of LiDAR and camera\ndetails; and the Volumetric Grid Attention (VGA) for a comprehensive spatial\ndata fusion. AYDIV's performance on the Waymo Open Dataset (WOD) with an\nimprovement of 1.24% in mAPH value(L2 difficulty) and the Argoverse2 Dataset\nwith a performance improvement of 7.40% in AP value demonstrates its efficacy\nin comparison to other existing fusion-based methods. Our code is publicly\navailable at https://github.com/sanjay-810/AYDIV2",
      "tldr_zh": "该论文提出 AYDIV 框架，通过整合 Contextual Vision Transformer 来提升自动驾驶系统中 LiDAR 和相机数据的融合，特别针对长距离物体检测中的数据稀疏性和表示差异问题。AYDIV 包括三阶段对齐过程：Global Contextual Fusion Alignment Transformer (GCFAT) 用于增强相机特征提取和大规模模式理解、Sparse Fused Feature Attention (SFFA) 用于微调 LiDAR 与相机细节融合，以及 Volumetric Grid Attention (VGA) 用于全面的空间数据融合。实验结果显示，在 Waymo Open Dataset (WOD) 上 mAPH 值（L2 难度）提升 1.24%，在 Argoverse2 Dataset 上 AP 值提升 7.40%，证明了 AYDIV 在融合数据方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted for ICRA 2024, and copyright will\n  automatically transfer to IEEE upon its availability on the IEEE portal",
      "pdf_url": "http://arxiv.org/pdf/2402.07680v1",
      "published_date": "2024-02-12 14:40:43 UTC",
      "updated_date": "2024-02-12 14:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:32:49.146810"
    },
    {
      "arxiv_id": "2402.07640v3",
      "title": "Synthesizing Sentiment-Controlled Feedback For Multimodal Text and Image Data",
      "title_zh": "翻译失败",
      "authors": [
        "Puneet Kumar",
        "Sarthak Malik",
        "Balasubramanian Raman",
        "Xiaobai Li"
      ],
      "abstract": "The ability to generate sentiment-controlled feedback in response to\nmultimodal inputs comprising text and images addresses a critical gap in\nhuman-computer interaction. This capability allows systems to provide\nempathetic, accurate, and engaging responses, with useful applications in\neducation, healthcare, marketing, and customer service. To this end, we have\nconstructed a large-scale Controllable Multimodal Feedback Synthesis (CMFeed)\ndataset and propose a controllable feedback synthesis system. The system\nfeatures an encoder, decoder, and controllability block for textual and visual\ninputs. It extracts features using a transformer and Faster R-CNN networks,\ncombining them to generate feedback. The CMFeed dataset includes images, texts,\nreactions to the posts, human comments with relevance scores, and reactions to\nthese comments. These reactions train the model to produce feedback with\nspecified sentiments, achieving a sentiment classification accuracy of 77.23\\%,\nwhich is 18.82\\% higher than the accuracy without controllability. The system\nalso incorporates a similarity module for assessing feedback relevance through\nrank-based metrics and an interpretability technique to analyze the\ncontributions of textual and visual features during feedback generation. Access\nto the CMFeed dataset and the system's code is available at\nhttps://github.com/MIntelligence-Group/CMFeed.",
      "tldr_zh": "该论文构建了大型 Controllable Multimodal Feedback Synthesis (CMFeed) 数据集，并提出一个可控反馈合成系统，用于针对包含文本和图像的多模态输入生成情感控制的反馈，从而提升人机交互在教育、医疗、市场和客服等领域的应用。系统通过 Transformer 和 Faster R-CNN 提取文本和视觉特征，并结合编码器、解码器以及可控性块来合成指定情感的反馈。CMFeed 数据集包括图像、文本、反应、人类评论及其相关性分数，用于训练模型，实现情感分类准确率 77.23%，比无可控性模型高 18.82%。此外，系统还整合了相似性模块和解释性技术，以评估反馈的相关性和分析特征贡献。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07640v3",
      "published_date": "2024-02-12 13:27:22 UTC",
      "updated_date": "2024-10-18 02:50:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:33:00.959676"
    },
    {
      "arxiv_id": "2402.07639v1",
      "title": "Tighter Bounds on the Information Bottleneck with Application to Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nir Weingarten",
        "Zohar Yakhini",
        "Moshe Butman",
        "Ran Gilad-Bachrach"
      ],
      "abstract": "Deep Neural Nets (DNNs) learn latent representations induced by their\ndownstream task, objective function, and other parameters. The quality of the\nlearned representations impacts the DNN's generalization ability and the\ncoherence of the emerging latent space. The Information Bottleneck (IB)\nprovides a hypothetically optimal framework for data modeling, yet it is often\nintractable. Recent efforts combined DNNs with the IB by applying VAE-inspired\nvariational methods to approximate bounds on mutual information, resulting in\nimproved robustness to adversarial attacks. This work introduces a new and\ntighter variational bound for the IB, improving performance of previous\nIB-inspired DNNs. These advancements strengthen the case for the IB and its\nvariational approximations as a data modeling framework, and provide a simple\nmethod to significantly enhance the adversarial robustness of classifier DNNs.",
      "tldr_zh": "该论文针对信息瓶颈 (IB) 框架提出一个更紧的变分界限，以优化深度神经网络 (DNNs) 的数据建模过程。研究者通过 VAE 启发的变分方法近似 IB 的界限，应用于 DNNs 中，显著提高了模型的鲁棒性，特别是对对抗攻击的抵抗力。实验结果显示，这种改进增强了分类器 DNNs 的性能，并为 IB 作为数据建模框架提供了更强的理论支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "94A08, 94A10, 94A11, 68T06, 62B04, 62B08",
        "I.2; E.4; I.4; I.7"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures, code included in github repo",
      "pdf_url": "http://arxiv.org/pdf/2402.07639v1",
      "published_date": "2024-02-12 13:24:32 UTC",
      "updated_date": "2024-02-12 13:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:33:10.854843"
    },
    {
      "arxiv_id": "2402.07632v3",
      "title": "Overconfident and Unconfident AI Hinder Human-AI Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Jingshu Li",
        "Yitian Yang",
        "Renwen Zhang",
        "Yi-chieh Lee"
      ],
      "abstract": "AI transparency is a central pillar of responsible AI deployment and\neffective human-AI collaboration. A critical approach is communicating\nuncertainty, such as displaying AI's confidence level, or its correctness\nlikelihood (CL), to users. However, these confidence levels are often\nuncalibrated, either overestimating or underestimating actual CL, posing risks\nand harms to human-AI collaboration. This study examines the effects of\nuncalibrated AI confidence on users' trust in AI, AI advice adoption, and\ncollaboration outcomes. We further examined the impact of increased\ntransparency, achieved through trust calibration support, on these outcomes.\nOur results reveal that uncalibrated AI confidence leads to both the misuse of\noverconfident AI and disuse of unconfident AI, thereby hindering outcomes of\nhuman-AI collaboration. Deficiency of trust calibration support exacerbates\nthis issue by making it harder to detect uncalibrated confidence, promoting\nmisuse and disuse of AI. Conversely, trust calibration support aids in\nrecognizing uncalibration and reducing misuse, but it also fosters distrust and\ncauses disuse of AI. Our findings highlight the importance of AI confidence\ncalibration for enhancing human-AI collaboration and suggest directions for AI\ndesign and regulation.",
      "tldr_zh": "这篇论文探讨了AI置信水平未校准对人类-AI协作的影响，包括过度自信AI的误用和不自信AI的弃用，导致用户信任降低、建议采纳减少以及协作结果受阻。研究通过实验考察了增加透明度（如trust calibration support）的效果，发现这种支持有助于识别未校准置信水平并减少误用，但也可能引发不信任和AI弃用。总体而言，论文强调AI confidence calibration的重要性，并为AI设计和监管提供建议方向。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07632v3",
      "published_date": "2024-02-12 13:16:30 UTC",
      "updated_date": "2024-04-17 18:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:33:24.757758"
    },
    {
      "arxiv_id": "2402.07625v5",
      "title": "Autonomous Data Selection with Zero-shot Generative Classifiers for Mathematical Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Zhang",
        "Yifan Luo",
        "Yang Yuan",
        "Andrew Chi-Chih Yao"
      ],
      "abstract": "We present Autonomous Data Selection (AutoDS), a method that leverages base\nlanguage models themselves as zero-shot \"generative classifiers\" to\nautomatically curate high-quality mathematical texts. Unlike prior approaches\nthat require human annotations or training a dedicated data filter, AutoDS\nrelies solely on a model's logits to determine whether a given passage is\nmathematically informative and educational. By integrating AutoDS into a\ncontinual pretraining pipeline, we substantially boost downstream performance\non challenging math benchmarks (MATH, GSM8K, and BBH) while using far fewer\ntokens than previous methods. Empirically, our approach achieves roughly a\ntwofold improvement in pretraining token efficiency over strong baselines,\nunderscoring the potential of self-directed data selection in enhancing\nmathematical reasoning. We release our curated AutoMathText dataset to\nfacilitate future research in automated domain-specific data curation. The\nAutoMathText dataset is available at\nhttps://huggingface.co/datasets/math-ai/AutoMathText. The code is available at\nhttps://github.com/yifanzhang-pro/AutoMathText.",
      "tldr_zh": "本研究提出 Autonomous Data Selection (AutoDS)，一种利用基础语言模型作为 zero-shot generative classifiers 的方法，来自动筛选高质量数学文本，从而无需人工标注或额外训练。AutoDS 仅依赖模型的 logits 来评估文本的数学信息性和教育价值，并将其整合到持续预训练管道中。实验结果显示，该方法在 MATH、GSM8K 和 BBH 等数学基准测试上显著提升下游性能，同时将预训练 token 效率提高约两倍。作者发布了 AutoMathText 数据集和相关代码，以促进自动化领域特定数据筛选的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:0808.2664, arXiv:0806.2159, arXiv:1703.08834, arXiv:math/0610707 by\n  other authors",
      "pdf_url": "http://arxiv.org/pdf/2402.07625v5",
      "published_date": "2024-02-12 13:09:21 UTC",
      "updated_date": "2025-03-23 02:11:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:33:36.949208"
    },
    {
      "arxiv_id": "2402.07619v1",
      "title": "Developing a Multi-variate Prediction Model For COVID-19 From Crowd-sourced Respiratory Voice Data",
      "title_zh": "基于众包呼吸语音数据开发 COVID-19 的多变量预测模型",
      "authors": [
        "Yuyang Yan",
        "Wafaa Aljbawi",
        "Sami O. Simons",
        "Visara Urovi"
      ],
      "abstract": "COVID-19 has affected more than 223 countries worldwide and in the Post-COVID\nEra, there is a pressing need for non-invasive, low-cost, and highly scalable\nsolutions to detect COVID-19. We develop a deep learning model to identify\nCOVID-19 from voice recording data. The novelty of this work is in the\ndevelopment of deep learning models for COVID-19 identification from only voice\nrecordings. We use the Cambridge COVID-19 Sound database which contains 893\nspeech samples, crowd-sourced from 4352 participants via a COVID-19 Sounds app.\nVoice features including Mel-spectrograms and Mel-frequency cepstral\ncoefficients (MFCC) and CNN Encoder features are extracted. Based on the voice\ndata, we develop deep learning classification models to detect COVID-19 cases.\nThese models include Long Short-Term Memory (LSTM) and Convolutional Neural\nNetwork (CNN) and Hidden-Unit BERT (HuBERT). We compare their predictive power\nto baseline machine learning models. HuBERT achieves the highest accuracy of\n86\\% and the highest AUC of 0.93. The results achieved with the proposed models\nsuggest promising results in COVID-19 diagnosis from voice recordings when\ncompared to the results obtained from the state-of-the-art.",
      "tldr_zh": "该研究开发了一种多变量预测模型，用于从众包呼吸语音数据中检测 COVID-19，旨在提供非侵入性、低成本且可扩展的解决方案。研究利用 Cambridge COVID-19 Sound 数据库的 893 个语音样本，提取了 Mel-spectrograms、Mel-frequency cepstral coefficients (MFCC) 和 CNN Encoder 特征，并构建了 LSTM、CNN 和 Hidden-Unit BERT (HuBERT) 等深度学习分类模型。相比基线机器学习模型，HuBERT 模型取得了最高的准确率 86% 和 AUC 0.93 的表现，表明语音记录在 COVID-19 诊断中的潜力优于现有技术。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "arXiv admin note: text overlap with arXiv:2209.03727",
      "pdf_url": "http://arxiv.org/pdf/2402.07619v1",
      "published_date": "2024-02-12 12:52:47 UTC",
      "updated_date": "2024-02-12 12:52:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:33:50.239649"
    },
    {
      "arxiv_id": "2402.07616v3",
      "title": "Anchor-based Large Language Models",
      "title_zh": "基于锚点的大型语言模型",
      "authors": [
        "Jianhui Pang",
        "Fanghua Ye",
        "Derek Fai Wong",
        "Xin He",
        "Wanshun Chen",
        "Longyue Wang"
      ],
      "abstract": "Large language models (LLMs) predominantly employ decoder-only transformer\narchitectures, necessitating the retention of keys/values information for\nhistorical tokens to provide contextual information and avoid redundant\ncomputation. However, the substantial size and parameter volume of these LLMs\nrequire massive GPU memory. This memory demand increases with the length of the\ninput text, leading to an urgent need for more efficient methods of information\nstorage and processing. This study introduces Anchor-based LLMs (AnLLMs), which\nutilize an innovative anchor-based self-attention network (AnSAN) and also an\nanchor-based inference strategy. This approach enables LLMs to compress\nsequence information into an anchor token, reducing the keys/values cache and\nenhancing inference efficiency. Experiments on question-answering benchmarks\nreveal that AnLLMs maintain similar accuracy levels while achieving up to 99%\nkeys/values cache reduction and up to 3.5 times faster inference. Despite a\nminor compromise in accuracy, the substantial enhancements of AnLLMs employing\nthe AnSAN technique in resource utilization and computational efficiency\nunderscore their potential for practical LLM applications.",
      "tldr_zh": "本研究针对大型语言模型（Large Language Models, LLMs）的decoder-only transformer架构中，keys/values缓存导致的内存消耗和计算冗余问题，提出了Anchor-based LLMs（AnLLMs）。该方法引入anchor-based self-attention network（AnSAN）和anchor-based inference strategy，将序列信息压缩到anchor token中，从而减少keys/values缓存并提升推理效率。在问答基准测试中，AnLLMs在保持相似准确性的同时，实现高达99%的缓存减少和3.5倍的推理加速。尽管存在轻微准确性损失，但这种优化显著提高了LLMs的资源利用率和实际应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The paper has been accepted by the ACL2024 conference. Work was done\n  when Jianhui Pang and Fanghua Ye were interning at Tencent AI Lab",
      "pdf_url": "http://arxiv.org/pdf/2402.07616v3",
      "published_date": "2024-02-12 12:48:02 UTC",
      "updated_date": "2024-06-01 04:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:34:03.408910"
    },
    {
      "arxiv_id": "2402.07610v3",
      "title": "Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Wang",
        "Guozheng Ma",
        "Ziqiao Meng",
        "Zeyu Qin",
        "Li Shen",
        "Zhong Zhang",
        "Bingzhe Wu",
        "Liu Liu",
        "Yatao Bian",
        "Tingyang Xu",
        "Xueqian Wang",
        "Peilin Zhao"
      ],
      "abstract": "Self-alignment is an effective way to reduce the cost of human annotation\nwhile ensuring promising model capability. However, most current methods\ncomplete the data collection and training steps in a single round, which may\noverlook the continuously improving ability of self-aligned models. This gives\nrise to a key query: What if we do multi-time bootstrapping self-alignment?\nDoes this strategy enhance model performance or lead to rapid degradation? In\nthis paper, our pioneering exploration delves into the impact of bootstrapping\nself-alignment on large language models. Our findings reveal that bootstrapping\nself-alignment markedly surpasses the single-round approach, by guaranteeing\ndata diversity from in-context learning. To further exploit the capabilities of\nbootstrapping, we investigate and adjust the training order of data, which\nyields improved performance of the model. Drawing on these findings, we propose\nStep-On-Feet Tuning (SOFT) which leverages model's continuously enhanced\nfew-shot ability to boost zero or one-shot performance. Based on easy-to-hard\ntraining recipe, we propose SOFT+ which further boost self-alignment's\nperformance. Our experiments demonstrate the efficiency of SOFT (SOFT+) across\nvarious classification and generation tasks, highlighting the potential of\nbootstrapping self-alignment on continually enhancing model alignment\nperformance.",
      "tldr_zh": "本论文探讨了多轮 bootstrapping 自对齐方法，以提升大型语言模型 (LLMs) 的性能，相比单轮方法，它通过确保数据多样性和调整训练顺序，显著提高了模型能力。研究者提出 Step-On-Feet Tuning (SOFT)，利用模型不断增强的少样本学习能力来提升零样本或一样本任务的表现；基于易到难的训练策略，他们进一步开发了 SOFT+，优化自对齐过程。实验结果显示，SOFT 和 SOFT+ 在各种分类和生成任务中表现出色，证明了 bootstrapping 自对齐在持续提升模型性能方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07610v3",
      "published_date": "2024-02-12 12:30:42 UTC",
      "updated_date": "2024-06-27 16:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:34:15.903996"
    },
    {
      "arxiv_id": "2402.07570v2",
      "title": "Only the Curve Shape Matters: Training Foundation Models for Zero-Shot Multivariate Time Series Forecasting through Next Curve Shape Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Feng",
        "Long Huang",
        "Denis Krompass"
      ],
      "abstract": "We present General Time Transformer (GTT), an encoder-only style foundation\nmodel for zero-shot multivariate time series forecasting. GTT is pretrained on\na large dataset of 200M high-quality time series samples spanning diverse\ndomains. In our proposed framework, the task of multivariate time series\nforecasting is formulated as a channel-wise next curve shape prediction\nproblem, where each time series sample is represented as a sequence of\nnon-overlapping curve shapes with a unified numerical magnitude. GTT is trained\nto predict the next curve shape based on a window of past curve shapes in a\nchannel-wise manner. Experimental results demonstrate that GTT exhibits\nsuperior zero-shot multivariate forecasting capabilities on unseen time series\ndatasets, even surpassing state-of-the-art supervised baselines. Additionally,\nwe investigate the impact of varying GTT model parameters and training dataset\nscales, observing that the scaling law also holds in the context of zero-shot\nmultivariate time series forecasting.",
      "tldr_zh": "本研究提出 General Time Transformer (GTT)，一个编码器式的基础模型，用于零-shot multivariate time series forecasting，通过在200M高质量时间序列样本上预训练来实现跨领域预测。GTT将多变量时间序列预测转化为按通道的next curve shape prediction问题，即将每个样本表示为序列的非重叠curve shapes，并训练模型基于过去的curve shapes窗口预测下一个形状。实验结果显示，GTT在未见数据集上的零-shot预测能力超越了最先进的监督基线；此外，研究还验证了模型参数和训练数据集规模的变化遵循scaling law，对时间序列预测性能有显著影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07570v2",
      "published_date": "2024-02-12 11:04:14 UTC",
      "updated_date": "2024-02-19 03:21:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:34:27.365873"
    },
    {
      "arxiv_id": "2402.09474v2",
      "title": "Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Aruna Mohan",
        "Danne Elbers",
        "Or Zilbershot",
        "Fatemeh Afghah",
        "David Vorchheimer"
      ],
      "abstract": "Remote patient monitoring based on wearable single-lead electrocardiogram\n(ECG) devices has significant potential for enabling the early detection of\nheart disease, especially in combination with artificial intelligence (AI)\napproaches for automated heart disease detection. There have been prior studies\napplying AI approaches based on deep learning for heart disease detection.\nHowever, these models are yet to be widely accepted as a reliable aid for\nclinical diagnostics, in part due to the current black-box perception\nsurrounding many AI algorithms. In particular, there is a need to identify the\nkey features of the ECG signal that contribute toward making an accurate\ndiagnosis, thereby enhancing the interpretability of the model. In the present\nstudy, we develop a vision transformer approach to identify atrial fibrillation\nbased on single-lead ECG data. A residual network (ResNet) approach is also\ndeveloped for comparison with the vision transformer approach. These models are\napplied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as\nwell as another common arrhythmia, sinus bradycardia, and normal sinus rhythm\nheartbeats. The models enable the identification of the key regions of the\nheartbeat that determine the resulting classification, and highlight the\nimportance of P-waves and T-waves, as well as heartbeat duration and signal\namplitude, in distinguishing normal sinus rhythm from atrial fibrillation and\nsinus bradycardia.",
      "tldr_zh": "这篇论文提出了一种基于 Vision Transformer 的方法，用于从单导联 ECG 信号中实现可解释的 atrial fibrillation 检测，以解决现有 AI 模型的黑箱问题。研究同时开发了 ResNet 模型作为对比，并在 Chapman-Shaoxing 数据集上分类 atrial fibrillation、sinus bradycardia 和 normal sinus rhythm。结果显示，该方法能识别心跳的关键区域，包括 P-waves、T-waves、心跳持续时间和信号幅度，从而提升了模型的解释性和诊断可靠性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted for publication at the 46th Annual International Conference\n  of the IEEE Engineering in Medicine and Biology Society, IEEE EMBC 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09474v2",
      "published_date": "2024-02-12 11:04:08 UTC",
      "updated_date": "2024-04-28 20:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:34:38.180532"
    },
    {
      "arxiv_id": "2402.07562v1",
      "title": "Discovering Universal Semantic Triggers for Text-to-Image Synthesis",
      "title_zh": "发现用于文本到",
      "authors": [
        "Shengfang Zhai",
        "Weilong Wang",
        "Jiajun Li",
        "Yinpeng Dong",
        "Hang Su",
        "Qingni Shen"
      ],
      "abstract": "Recently text-to-image models have gained widespread attention in the\ncommunity due to their controllable and high-quality generation ability.\nHowever, the robustness of such models and their potential ethical issues have\nnot been fully explored. In this paper, we introduce Universal Semantic\nTrigger, a meaningless token sequence that can be added at any location within\nthe input text yet can induce generated images towards a preset semantic\ntarget.To thoroughly investigate it, we propose Semantic Gradient-based Search\n(SGS) framework. SGS automatically discovers the potential universal semantic\ntriggers based on the given semantic targets. Furthermore, we design evaluation\nmetrics to comprehensively evaluate semantic shift of images caused by these\ntriggers. And our empirical analyses reveal that the mainstream open-source\ntext-to-image models are vulnerable to our triggers, which could pose\nsignificant ethical threats. Our work contributes to a further understanding of\ntext-to-image synthesis and helps users to automatically auditing their models\nbefore deployment.",
      "tldr_zh": "本文研究了文本到图像合成模型的鲁棒性和潜在伦理问题，引入了 Universal Semantic Trigger，这是一种无意义的 token 序列，可添加到输入文本的任意位置以引导生成的图像朝向预设语义目标。作者提出了 Semantic Gradient-based Search (SGS) 框架，用于自动发现基于给定语义目标的潜在触发器，并设计了评估指标来量化图像的语义偏移。实验结果表明，主流开源文本到图像模型容易受到这些触发器的攻击，可能引发重大伦理威胁，该工作有助于提升模型审计和部署前的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "9 pages, 5 figures. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2402.07562v1",
      "published_date": "2024-02-12 10:56:09 UTC",
      "updated_date": "2024-02-12 10:56:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:34:49.068941"
    },
    {
      "arxiv_id": "2402.07963v3",
      "title": "SPO: Sequential Monte Carlo Policy Optimisation",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew V Macfarlane",
        "Edan Toledo",
        "Donal Byrne",
        "Paul Duckworth",
        "Alexandre Laterre"
      ],
      "abstract": "Leveraging planning during learning and decision-making is central to the\nlong-term development of intelligent agents. Recent works have successfully\ncombined tree-based search methods and self-play learning mechanisms to this\nend. However, these methods typically face scaling challenges due to the\nsequential nature of their search. While practical engineering solutions can\npartly overcome this, they often result in a negative impact on performance. In\nthis paper, we introduce SPO: Sequential Monte Carlo Policy Optimisation, a\nmodel-based reinforcement learning algorithm grounded within the Expectation\nMaximisation (EM) framework. We show that SPO provides robust policy\nimprovement and efficient scaling properties. The sample-based search makes it\ndirectly applicable to both discrete and continuous action spaces without\nmodifications. We demonstrate statistically significant improvements in\nperformance relative to model-free and model-based baselines across both\ncontinuous and discrete environments. Furthermore, the parallel nature of SPO's\nsearch enables effective utilisation of hardware accelerators, yielding\nfavourable scaling laws.",
      "tldr_zh": "本文提出SPO（Sequential Monte Carlo Policy Optimisation），一种基于模型的强化学习算法，利用Expectation Maximisation (EM)框架来实现稳健的政策优化和高效扩展。SPO通过样本-based搜索处理顺序决策问题，适用于离散和连续动作空间，并解决了传统树-based方法的扩展挑战。实验结果显示，SPO在连续和离散环境中相对于模型-free和模型-based基线取得了统计显著的性能提升，并通过其并行搜索特性有效利用硬件加速器。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NeurIPS 2024. 34 pages, 3 main figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07963v3",
      "published_date": "2024-02-12 10:32:47 UTC",
      "updated_date": "2024-10-31 17:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:35:01.004053"
    },
    {
      "arxiv_id": "2402.07547v1",
      "title": "Ensuring trustworthy and ethical behaviour in intelligent logical agents",
      "title_zh": "确保智能逻辑代理的可信赖和道德行为",
      "authors": [
        "Stefania Costantini"
      ],
      "abstract": "Autonomous Intelligent Agents are employed in many applications upon which\nthe life and welfare of living beings and vital social functions may depend.\nTherefore, agents should be trustworthy. A priori certification techniques\n(i.e., techniques applied prior to system's deployment) can be useful, but are\nnot sufficient for agents that evolve, and thus modify their epistemic and\nbelief state, and for open Multi-Agent Systems, where heterogeneous agents can\njoin or leave the system at any stage of its operation. In this paper, we\npropose/refine/extend dynamic (runtime) logic-based self-checking techniques,\ndevised in order to be able to ensure agents' trustworthy and ethical\nbehaviour.",
      "tldr_zh": "该论文探讨了如何确保自主智能代理（Autonomous Intelligent Agents）在关键应用中的可信任（trustworthy）和道德行为（ethical behaviour），因为这些代理可能影响生命和社会功能。现有先验认证（a priori certification）技术虽有用，但不足以应对代理演化或开放多代理系统（Multi-Agent Systems）中代理的动态加入和离开。论文提出并完善动态（runtime）基于逻辑的自检技术，作为一种运行时机制，以实时监控和保障代理的行为可信和合乎伦理。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LO",
        "cs.SC",
        "I.2.4"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07547v1",
      "published_date": "2024-02-12 10:19:17 UTC",
      "updated_date": "2024-02-12 10:19:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:35:13.652412"
    },
    {
      "arxiv_id": "2402.07543v1",
      "title": "Show Me How It's Done: The Role of Explanations in Fine-Tuning Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamad Ballout",
        "Ulf Krumnack",
        "Gunther Heidemann",
        "Kai-Uwe Kuehnberger"
      ],
      "abstract": "Our research demonstrates the significant benefits of using fine-tuning with\nexplanations to enhance the performance of language models. Unlike prompting,\nwhich maintains the model's parameters, fine-tuning allows the model to learn\nand update its parameters during a training phase. In this study, we applied\nfine-tuning to various sized language models using data that contained\nexplanations of the output rather than merely presenting the answers. We found\nthat even smaller language models with as few as 60 million parameters\nbenefited substantially from this approach. Interestingly, our results\nindicated that the detailed explanations were more beneficial to smaller models\nthan larger ones, with the latter gaining nearly the same advantage from any\nform of explanation, irrespective of its length. Additionally, we demonstrate\nthat the inclusion of explanations enables the models to solve tasks that they\nwere not able to solve without explanations. Lastly, we argue that despite the\nchallenging nature of adding explanations, samples that contain explanations\nnot only reduce the volume of data required for training but also promote a\nmore effective generalization by the model. In essence, our findings suggest\nthat fine-tuning with explanations significantly bolsters the performance of\nlarge language models.",
      "tldr_zh": "这篇论文探讨了在 fine-tuning 语言模型中使用解释数据的作用，与 prompting 不同，fine-tuning 允许模型更新参数以提升性能。研究发现，即使是仅有 60 百万参数的小型语言模型也能从详细解释中获得显著益处，而大型模型则对任何形式的解释都有类似优势。结果显示，添加解释不仅使模型能够解决原本无法完成的任务，还减少了训练数据量并提高了模型的泛化能力。总的来说，带有解释的 fine-tuning 方法显著增强了语言模型的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07543v1",
      "published_date": "2024-02-12 10:11:50 UTC",
      "updated_date": "2024-02-12 10:11:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:35:25.489687"
    },
    {
      "arxiv_id": "2402.07540v1",
      "title": "PKG API: A Tool for Personal Knowledge Graph Management",
      "title_zh": "PKG API：用于个人知识图谱管理的工具",
      "authors": [
        "Nolwenn Bernard",
        "Ivica Kostric",
        "Weronika Łajewska",
        "Krisztian Balog",
        "Petra Galuščáková",
        "Vinay Setty",
        "Martin G. Skjæveland"
      ],
      "abstract": "Personal knowledge graphs (PKGs) offer individuals a way to store and\nconsolidate their fragmented personal data in a central place, improving\nservice personalization while maintaining full user control. Despite their\npotential, practical PKG implementations with user-friendly interfaces remain\nscarce. This work addresses this gap by proposing a complete solution to\nrepresent, manage, and interface with PKGs. Our approach includes (1) a\nuser-facing PKG Client, enabling end-users to administer their personal data\neasily via natural language statements, and (2) a service-oriented PKG API. To\ntackle the complexity of representing these statements within a PKG, we present\nan RDF-based PKG vocabulary that supports this, along with properties for\naccess rights and provenance.",
      "tldr_zh": "本论文介绍了Personal Knowledge Graphs (PKGs)，一种用于存储和整合用户碎片化数据的工具，以提升服务个性化并保持用户控制，但目前缺乏实用且用户友好的实现。作者提出一个完整解决方案，包括面向用户的PKG Client，允许用户通过自然语言语句轻松管理个人数据，以及面向服务的PKG API，以简化PKGs的接口和操作。为处理自然语言在PKGs中的表示，论文开发了一个基于RDF的PKGs词汇表，支持访问权限和来源属性，从而填补了这一领域的空白。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07540v1",
      "published_date": "2024-02-12 10:09:16 UTC",
      "updated_date": "2024-02-12 10:09:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:35:38.125911"
    },
    {
      "arxiv_id": "2403.00772v1",
      "title": "Do Weibo platform experts perform better at predicting stock market?",
      "title_zh": "微博平台专家在预测股票市场方面表现是否更好？",
      "authors": [
        "Ziyuan Ma",
        "Conor Ryan",
        "Jim Buckley",
        "Muslim Chochlov"
      ],
      "abstract": "Sentiment analysis can be used for stock market prediction. However, existing\nresearch has not studied the impact of a user's financial background on\nsentiment-based forecasting of the stock market using artificial neural\nnetworks. In this work, a novel combination of neural networks is used for the\nassessment of sentiment-based stock market prediction, based on the financial\nbackground of the population that generated the sentiment. The state-of-the-art\nlanguage processing model Bidirectional Encoder Representations from\nTransformers (BERT) is used to classify the sentiment and a Long-Short Term\nMemory (LSTM) model is used for time-series based stock market prediction. For\nevaluation, the Weibo social networking platform is used as a sentiment data\ncollection source. Weibo users (and their comments respectively) are divided\ninto Authorized Financial Advisor (AFA) and Unauthorized Financial Advisor\n(UFA) groups according to their background information, as collected by Weibo.\nThe Hong Kong Hang Seng index is used to extract historical stock market change\ndata. The results indicate that stock market prediction learned from the AFA\ngroup users is 39.67% more precise than that learned from the UFA group users\nand shows the highest accuracy (87%) when compared to existing approaches.",
      "tldr_zh": "这篇论文探讨了Weibo平台用户的财务背景对基于情感分析的股票市场预测的影响，首次评估了Authorized Financial Advisor (AFA)与Unauthorized Financial Advisor (UFA)组用户的差异。研究采用BERT模型进行情感分类，并结合Long-Short Term Memory (LSTM)模型进行时间序列预测，使用Weibo数据和Hong Kong Hang Seng指数的历史数据进行评估。结果表明，AFA组用户的预测准确率比UFA组高39.67%，并达到87%的最高准确率，优于现有方法。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00772v1",
      "published_date": "2024-02-12 10:04:54 UTC",
      "updated_date": "2024-02-12 10:04:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:35:50.608756"
    },
    {
      "arxiv_id": "2402.07536v2",
      "title": "FinLLM-B: When Large Language Models Meet Financial Breakout Trading",
      "title_zh": "FinLLM-B：当大型语言模型遇见金融突破交易",
      "authors": [
        "Kang Zhang",
        "Osamu Yoshie",
        "Lichao Sun",
        "Weiran Huang"
      ],
      "abstract": "Trading range breakout is a key method in the technical analysis of financial\ntrading, widely employed by traders in financial markets such as stocks,\nfutures, and foreign exchange. However, distinguishing between true and false\nbreakout and providing the correct rationale cause significant challenges to\ninvestors. Traditional quantitative methods require large amounts of data and\ncannot directly present the reasoning process, making them less than perfect in\nthis field. Recently, large language models have achieved success in various\ndownstream applications, but their effectiveness in the domain of financial\nbreakout detection has been subpar. The reason is that the unique data and\nspecific knowledge are required in breakout detection. To address these issues,\nwe create the first financial breakout dataset and introduce FinLLM-B, the\npremier large language model for financial breakout detection, which enhances\nthe effectiveness of breakout trading strategies. Furthermore, we have\ndeveloped a novel framework for large language models, namely multi-stage\nstructure, effectively reducing mistakes in downstream applications.\nExperimental results indicate that compared to GPT-3.5, FinLLM-B improves the\naverage accuracy of answers and rational by 49.97%, with the multi-stage\nstructure contributing 9.72% to the improvement. Additionally, it outperforms\nChatGPT-4 by 42.38%.",
      "tldr_zh": "本研究针对金融交易中的交易范围突破（trading range breakout）检测问题，提出 FinLLM-B，这是首个专为金融突破检测设计的大语言模型（Large Language Models），通过创建首个金融突破数据集和引入多阶段结构（multi-stage structure）框架，有效区分真假突破并提供清晰推理过程。相比传统量化方法，FinLLM-B 显著提升了下游应用的准确性和可靠性。实验结果显示，与 GPT-3.5 相比，FinLLM-B 的答案和理由平均准确率提高了 49.97%，其中多阶段结构贡献 9.72%，并优于 ChatGPT-4 42.38%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2402.07536v2",
      "published_date": "2024-02-12 10:04:07 UTC",
      "updated_date": "2025-02-22 16:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:36:02.857028"
    },
    {
      "arxiv_id": "2402.07514v2",
      "title": "Physics-informed machine learning as a kernel method",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan Doumèche",
        "Francis Bach",
        "Gérard Biau",
        "Claire Boyer"
      ],
      "abstract": "Physics-informed machine learning combines the expressiveness of data-based\napproaches with the interpretability of physical models. In this context, we\nconsider a general regression problem where the empirical risk is regularized\nby a partial differential equation that quantifies the physical inconsistency.\nWe prove that for linear differential priors, the problem can be formulated as\na kernel regression task. Taking advantage of kernel theory, we derive\nconvergence rates for the minimizer of the regularized risk and show that it\nconverges at least at the Sobolev minimax rate. However, faster rates can be\nachieved, depending on the physical error. This principle is illustrated with a\none-dimensional example, supporting the claim that regularizing the empirical\nrisk with physical information can be beneficial to the statistical performance\nof estimators.",
      "tldr_zh": "这篇论文探讨了物理信息机器学习（Physics-informed machine learning）作为一种核方法（kernel method）的应用，将基于数据的回归问题与量化物理不一致性的偏微分方程（PDE）正则化相结合。作者证明，对于线性微分先验，该问题可转化为核回归（kernel regression）任务，并利用核理论推导了正则化风险最小化的收敛率，至少达到 Sobolev minimax 率，且可能通过物理误差实现更快收敛。实验示例显示，这种方法能提升估计器的统计性能，证明了整合物理信息对机器学习模型的益处。",
      "categories": [
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07514v2",
      "published_date": "2024-02-12 09:38:42 UTC",
      "updated_date": "2024-06-19 07:40:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:36:15.178787"
    },
    {
      "arxiv_id": "2402.07513v1",
      "title": "The Balancing Act: Unmasking and Alleviating ASR Biases in Portuguese",
      "title_zh": "翻译失败",
      "authors": [
        "Ajinkya Kulkarni",
        "Anna Tokareva",
        "Rameez Qureshi",
        "Miguel Couceiro"
      ],
      "abstract": "In the field of spoken language understanding, systems like Whisper and\nMultilingual Massive Speech (MMS) have shown state-of-the-art performances.\nThis study is dedicated to a comprehensive exploration of the Whisper and MMS\nsystems, with a focus on assessing biases in automatic speech recognition (ASR)\ninherent to casual conversation speech specific to the Portuguese language. Our\ninvestigation encompasses various categories, including gender, age, skin tone\ncolor, and geo-location. Alongside traditional ASR evaluation metrics such as\nWord Error Rate (WER), we have incorporated p-value statistical significance\nfor gender bias analysis. Furthermore, we extensively examine the impact of\ndata distribution and empirically show that oversampling techniques alleviate\nsuch stereotypical biases. This research represents a pioneering effort in\nquantifying biases in the Portuguese language context through the application\nof MMS and Whisper, contributing to a better understanding of ASR systems'\nperformance in multilingual settings.",
      "tldr_zh": "本研究评估了Whisper和Multilingual Massive Speech (MMS)系统在葡萄牙语自动语音识别（ASR）中的偏见，包括性别、年龄、肤色和地理位置等类别。研究采用Word Error Rate (WER)以及p-value统计显著性分析方法，探讨了数据分布的影响，并证明过采样技术能有效缓解这些偏见。整体结果为多语言ASR系统的性能优化提供了新见解，并在葡萄牙语语境中首次量化了此类偏见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "EACL-2024 LT-EDI Workshop",
      "pdf_url": "http://arxiv.org/pdf/2402.07513v1",
      "published_date": "2024-02-12 09:35:13 UTC",
      "updated_date": "2024-02-12 09:35:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:36:26.241100"
    },
    {
      "arxiv_id": "2402.07510v4",
      "title": "Secret Collusion among Generative AI Agents: Multi-Agent Deception via Steganography",
      "title_zh": "翻译失败",
      "authors": [
        "Sumeet Ramesh Motwani",
        "Mikhail Baranchuk",
        "Martin Strohmeier",
        "Vijay Bolina",
        "Philip H. S. Torr",
        "Lewis Hammond",
        "Christian Schroeder de Witt"
      ],
      "abstract": "Recent capability increases in large language models (LLMs) open up\napplications in which groups of communicating generative AI agents solve joint\ntasks. This poses privacy and security challenges concerning the unauthorised\nsharing of information, or other unwanted forms of agent coordination. Modern\nsteganographic techniques could render such dynamics hard to detect. In this\npaper, we comprehensively formalise the problem of secret collusion in systems\nof generative AI agents by drawing on relevant concepts from both AI and\nsecurity literature. We study incentives for the use of steganography, and\npropose a variety of mitigation measures. Our investigations result in a model\nevaluation framework that systematically tests capabilities required for\nvarious forms of secret collusion. We provide extensive empirical results\nacross a range of contemporary LLMs. While the steganographic capabilities of\ncurrent models remain limited, GPT-4 displays a capability jump suggesting the\nneed for continuous monitoring of steganographic frontier model capabilities.\nWe conclude by laying out a comprehensive research program to mitigate future\nrisks of collusion between generative AI models.",
      "tldr_zh": "这篇论文探讨了生成式AI代理在联合任务中通过隐写术(steganography)进行秘密勾结的问题，形式化了这一安全挑战，包括信息共享和协调的风险。作者分析了使用隐写术的动机，提出了多种缓解措施，并开发了一个系统评估框架来测试LLMs在不同秘密勾结形式下的能力。实证研究显示，当前LLMs的隐写能力有限，但GPT-4表现出显著提升，强调了持续监控的必要性。最终，论文概述了一个全面研究计划，以减轻生成式AI模型间未来勾结的风险。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07510v4",
      "published_date": "2024-02-12 09:31:21 UTC",
      "updated_date": "2025-04-14 10:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:36:38.724997"
    },
    {
      "arxiv_id": "2402.07507v1",
      "title": "Clustering Dynamics for Improved Speed Prediction Deriving from Topographical GPS Registrations",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Almeida Carneiro",
        "Giovanni Chierchia",
        "Aurelie Pirayre",
        "Laurent Najman"
      ],
      "abstract": "A persistent challenge in the field of Intelligent Transportation Systems is\nto extract accurate traffic insights from geographic regions with scarce or no\ndata coverage. To this end, we propose solutions for speed prediction using\nsparse GPS data points and their associated topographical and road design\nfeatures. Our goal is to investigate whether we can use similarities in the\nterrain and infrastructure to train a machine learning model that can predict\nspeed in regions where we lack transportation data. For this we create a\nTemporally Orientated Speed Dictionary Centered on Topographically Clustered\nRoads, which helps us to provide speed correlations to selected feature\nconfigurations. Our results show qualitative and quantitative improvement over\nnew and standard regression methods. The presented framework provides a fresh\nperspective on devising strategies for missing data traffic analysis.",
      "tldr_zh": "本研究针对智能交通系统中数据稀缺区域的交通洞见提取问题，提出了一种利用稀疏GPS数据、地形和道路设计特征进行速度预测的方法。\n他们创建了Temporally Orientated Speed Dictionary Centered on Topographically Clustered Roads（基于地形聚类的时序导向速度字典），通过识别地形和基础设施的相似性来训练机器学习模型，提供速度与特征配置的相关性。\n实验结果显示，该框架在定性和定量上优于标准回归方法，为处理缺失数据交通分析提供了新的策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07507v1",
      "published_date": "2024-02-12 09:28:16 UTC",
      "updated_date": "2024-02-12 09:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:36:51.006728"
    },
    {
      "arxiv_id": "2402.07501v1",
      "title": "One Train for Two Tasks: An Encrypted Traffic Classification Framework Using Supervised Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhen Zhang",
        "Xi Xiao",
        "Le Yu",
        "Qing Li",
        "Zhen Ling",
        "Ye Zhang"
      ],
      "abstract": "As network security receives widespread attention, encrypted traffic\nclassification has become the current research focus. However, existing methods\nconduct traffic classification without sufficiently considering the common\ncharacteristics between data samples, leading to suboptimal performance.\nMoreover, they train the packet-level and flow-level classification tasks\nindependently, which is redundant because the packet representations learned in\nthe packet-level task can be exploited by the flow-level task. Therefore, in\nthis paper, we propose an effective model named a Contrastive Learning Enhanced\nTemporal Fusion Encoder (CLE-TFE). In particular, we utilize supervised\ncontrastive learning to enhance the packet-level and flow-level representations\nand perform graph data augmentation on the byte-level traffic graph so that the\nfine-grained semantic-invariant characteristics between bytes can be captured\nthrough contrastive learning. We also propose cross-level multi-task learning,\nwhich simultaneously accomplishes the packet-level and flow-level\nclassification tasks in the same model with one training. Further experiments\nshow that CLE-TFE achieves the best overall performance on the two tasks, while\nits computational overhead (i.e., floating point operations, FLOPs) is only\nabout 1/14 of the pre-trained model (e.g., ET-BERT). We release the code at\nhttps://github.com/ViktorAxelsen/CLE-TFE",
      "tldr_zh": "本文提出了一种名为 CLE-TFE 的加密流量分类框架，利用 supervised contrastive learning 增强 packet-level 和 flow-level 表示，并通过 graph data augmentation 捕捉 byte-level 流量图的细粒度语义不变特性。框架采用 cross-level multi-task learning 方法，在同一模型中同时完成 packet-level 和 flow-level 分类任务，实现高效的一次训练。实验结果表明，CLE-TFE 在两个任务上表现出最佳整体性能，同时计算开销（FLOPs）仅为预训练模型（如 ET-BERT）的 1/14。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The code is available at https://github.com/ViktorAxelsen/CLE-TFE",
      "pdf_url": "http://arxiv.org/pdf/2402.07501v1",
      "published_date": "2024-02-12 09:10:09 UTC",
      "updated_date": "2024-02-12 09:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:37:02.403066"
    },
    {
      "arxiv_id": "2402.07483v2",
      "title": "T-RAG: Lessons from the LLM Trenches",
      "title_zh": "T-RAG：LLM 实战经验教训",
      "authors": [
        "Masoomali Fatehkia",
        "Ji Kim Lucas",
        "Sanjay Chawla"
      ],
      "abstract": "Large Language Models (LLM) have shown remarkable language capabilities\nfueling attempts to integrate them into applications across a wide range of\ndomains. An important application area is question answering over private\nenterprise documents where the main considerations are data security, which\nnecessitates applications that can be deployed on-prem, limited computational\nresources and the need for a robust application that correctly responds to\nqueries. Retrieval-Augmented Generation (RAG) has emerged as the most prominent\nframework for building LLM-based applications. While building a RAG is\nrelatively straightforward, making it robust and a reliable application\nrequires extensive customization and relatively deep knowledge of the\napplication domain. We share our experiences building and deploying an LLM\napplication for question answering over private organizational documents. Our\napplication combines the use of RAG with a finetuned open-source LLM.\nAdditionally, our system, which we call Tree-RAG (T-RAG), uses a tree structure\nto represent entity hierarchies within the organization. This is used to\ngenerate a textual description to augment the context when responding to user\nqueries pertaining to entities within the organization's hierarchy. Our\nevaluations, including a Needle in a Haystack test, show that this combination\nperforms better than a simple RAG or finetuning implementation. Finally, we\nshare some lessons learned based on our experiences building an LLM application\nfor real-world use.",
      "tldr_zh": "这篇论文分享了构建大型语言模型（LLM）应用，特别是针对私有企业文档问答系统的经验教训，强调了数据安全、计算资源限制和系统鲁棒性的重要性。作者提出了T-RAG系统，该框架结合Retrieval-Augmented Generation (RAG)、微调开源LLM以及树结构来表示组织实体层次，从而增强查询响应的上下文准确性。实验评估，包括Needle in a Haystack测试，显示T-RAG的表现优于简单RAG或微调实现；最终，论文总结了从实际部署中获得的实用经验，以指导可靠的LLM应用开发。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Added Needle in a Haystack analysis for T-RAG",
      "pdf_url": "http://arxiv.org/pdf/2402.07483v2",
      "published_date": "2024-02-12 08:45:08 UTC",
      "updated_date": "2024-06-06 14:42:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:37:15.527778"
    },
    {
      "arxiv_id": "2402.07477v2",
      "title": "Food Recommendation as Language Processing (F-RLP): A Personalized and Contextual Paradigm",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Rostami",
        "Ramesh Jain",
        "Amir M. Rahmani"
      ],
      "abstract": "State-of-the-art rule-based and classification-based food recommendation\nsystems face significant challenges in becoming practical and useful. This\ndifficulty arises primarily because most machine learning models struggle with\nproblems characterized by an almost infinite number of classes and a limited\nnumber of samples within an unbalanced dataset. Conversely, the emergence of\nLarge Language Models (LLMs) as recommendation engines offers a promising\navenue. However, a general-purpose Recommendation as Language Processing (RLP)\napproach lacks the critical components necessary for effective food\nrecommendations. To address this gap, we introduce Food Recommendation as\nLanguage Processing (F-RLP), a novel framework that offers a food-specific,\ntailored infrastructure. F-RLP leverages the capabilities of LLMs to maximize\ntheir potential, thereby paving the way for more accurate, personalized food\nrecommendations.",
      "tldr_zh": "现有食物推荐系统，如基于规则和分类的方法，面临处理无限类别和数据不平衡的重大挑战，导致实际应用受限。论文提出 Food Recommendation as Language Processing (F-RLP)，一个专为食物推荐量身定制的框架，利用 Large Language Models (LLMs) 来提供个性化和上下文化的解决方案。F-RLP 通过优化 LLMs 的能力，弥补了泛化 Recommendation as Language Processing (RLP) 的不足，从而实现更准确和实用的食物推荐。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07477v2",
      "published_date": "2024-02-12 08:32:29 UTC",
      "updated_date": "2024-02-14 12:11:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:37:27.498173"
    },
    {
      "arxiv_id": "2402.07465v1",
      "title": "Score-Based Physics-Informed Neural Networks for High-Dimensional Fokker-Planck Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Zheyuan Hu",
        "Zhongqiang Zhang",
        "George Em Karniadakis",
        "Kenji Kawaguchi"
      ],
      "abstract": "The Fokker-Planck (FP) equation is a foundational PDE in stochastic\nprocesses. However, curse of dimensionality (CoD) poses challenge when dealing\nwith high-dimensional FP PDEs. Although Monte Carlo and vanilla\nPhysics-Informed Neural Networks (PINNs) have shown the potential to tackle\nCoD, both methods exhibit numerical errors in high dimensions when dealing with\nthe probability density function (PDF) associated with Brownian motion. The\npoint-wise PDF values tend to decrease exponentially as dimension increases,\nsurpassing the precision of numerical simulations and resulting in substantial\nerrors. Moreover, due to its massive sampling, Monte Carlo fails to offer fast\nsampling. Modeling the logarithm likelihood (LL) via vanilla PINNs transforms\nthe FP equation into a difficult HJB equation, whose error grows rapidly with\ndimension. To this end, we propose a novel approach utilizing a score-based\nsolver to fit the score function in SDEs. The score function, defined as the\ngradient of the LL, plays a fundamental role in inferring LL and PDF and\nenables fast SDE sampling. Three fitting methods, Score Matching (SM), Sliced\nSM (SSM), and Score-PINN, are introduced. The proposed score-based SDE solver\noperates in two stages: first, employing SM, SSM, or Score-PINN to acquire the\nscore; and second, solving the LL via an ODE using the obtained score.\nComparative evaluations across these methods showcase varying trade-offs. The\nproposed method is evaluated across diverse SDEs, including anisotropic OU\nprocesses, geometric Brownian, and Brownian with varying eigenspace. We also\ntest various distributions, including Gaussian, Log-normal, Laplace, and\nCauchy. The numerical results demonstrate the score-based SDE solver's\nstability, speed, and performance across different settings, solidifying its\npotential as a solution to CoD for high-dimensional FP equations.",
      "tldr_zh": "本研究针对高维Fokker-Planck (FP)方程的维度诅咒（CoD）问题，提出了一种基于分数的Physics-Informed Neural Networks (PINNs)求解器，通过拟合SDEs中的分数函数（score function，即对数似然度的梯度）来提升概率密度函数（PDF）的准确性。方法包括Score Matching (SM)、Sliced SM (SSM)和Score-PINN三种技术，采用两阶段过程：首先获取分数函数，其次通过ODE求解对数似然度（LL），从而实现快速采样和稳定计算。实验结果显示，该方法在各向异性OU过程、几何布朗运动等多种SDEs和分布（如Gaussian、Log-normal）上表现出色，显著提高了高维FP方程的求解速度和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.DS",
        "math.NA",
        "stat.ML",
        "14J60"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.07465v1",
      "published_date": "2024-02-12 07:59:25 UTC",
      "updated_date": "2024-02-12 07:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:37:39.877728"
    },
    {
      "arxiv_id": "2402.07462v2",
      "title": "A Hormetic Approach to the Value-Loading Problem: Preventing the Paperclip Apocalypse?",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan I. N. Henry",
        "Mangor Pedersen",
        "Matt Williams",
        "Jamin L. B. Martin",
        "Liesje Donkin"
      ],
      "abstract": "The value-loading problem is a significant challenge for researchers aiming\nto create artificial intelligence (AI) systems that align with human values and\npreferences. This problem requires a method to define and regulate safe and\noptimal limits of AI behaviors. In this work, we propose HALO (Hormetic\nALignment via Opponent processes), a regulatory paradigm that uses hormetic\nanalysis to regulate the behavioral patterns of AI. Behavioral hormesis is a\nphenomenon where low frequencies of a behavior have beneficial effects, while\nhigh frequencies are harmful. By modeling behaviors as allostatic opponent\nprocesses, we can use either Behavioral Frequency Response Analysis (BFRA) or\nBehavioral Count Response Analysis (BCRA) to quantify the hormetic limits of\nrepeatable behaviors. We demonstrate how HALO can solve the 'paperclip\nmaximizer' scenario, a thought experiment where an unregulated AI tasked with\nmaking paperclips could end up converting all matter in the universe into\npaperclips. Our approach may be used to help create an evolving database of\n'values' based on the hedonic calculus of repeatable behaviors with decreasing\nmarginal utility. This positions HALO as a promising solution for the\nvalue-loading problem, which involves embedding human-aligned values into an AI\nsystem, and the weak-to-strong generalization problem, which explores whether\nweak models can supervise stronger models as they become more intelligent.\nHence, HALO opens several research avenues that may lead to the development of\na computational value system that allows an AI algorithm to learn whether the\ndecisions it makes are right or wrong.",
      "tldr_zh": "本研究针对价值加载问题（value-loading problem），提出了一种名为 HALO（Hormetic ALignment via Opponent processes）的调节框架，利用行为激素现象（behavioral hormesis）来定义 AI 行为的益害边界，即低频行为有益而高频有害。HALO 通过 Behavioral Frequency Response Analysis (BFRA) 或 Behavioral Count Response Analysis (BCRA) 量化可重复行为的激素极限，并展示了其在解决 'paperclip maximizer' 场景中的潜力，可防止 AI 过度追求单一目标导致灾难。最终，该方法有助于构建基于享乐计算的动态 'values' 数据库，支持 AI 学习决策是非，并解决弱到强泛化问题（weak-to-strong generalization problem）。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.MA",
        "econ.TH",
        "68T01, 68T37, 68T42",
        "I.2.0; I.2.8; I.2.11"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07462v2",
      "published_date": "2024-02-12 07:49:48 UTC",
      "updated_date": "2024-02-13 05:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:37:53.110646"
    },
    {
      "arxiv_id": "2402.07456v2",
      "title": "OS-Copilot: Towards Generalist Computer Agents with Self-Improvement",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyong Wu",
        "Chengcheng Han",
        "Zichen Ding",
        "Zhenmin Weng",
        "Zhoumianze Liu",
        "Shunyu Yao",
        "Tao Yu",
        "Lingpeng Kong"
      ],
      "abstract": "Autonomous interaction with the computer has been a longstanding challenge\nwith great potential, and the recent proliferation of large language models\n(LLMs) has markedly accelerated progress in building digital agents. However,\nmost of these agents are designed to interact with a narrow domain, such as a\nspecific software or website. This narrow focus constrains their applicability\nfor general computer tasks. To this end, we introduce OS-Copilot, a framework\nto build generalist agents capable of interfacing with comprehensive elements\nin an operating system (OS), including the web, code terminals, files,\nmultimedia, and various third-party applications. We use OS-Copilot to create\nFRIDAY, a self-improving embodied agent for automating general computer tasks.\nOn GAIA, a general AI assistants benchmark, FRIDAY outperforms previous methods\nby 35%, showcasing strong generalization to unseen applications via accumulated\nskills from previous tasks. We also present numerical and quantitative evidence\nthat FRIDAY learns to control and self-improve on Excel and Powerpoint with\nminimal supervision. Our OS-Copilot framework and empirical findings provide\ninfrastructure and insights for future research toward more capable and\ngeneral-purpose computer agents.",
      "tldr_zh": "该研究提出 OS-Copilot 框架，用于构建通用的计算机代理，能够与操作系统中的各种元素（如网页、代码终端、文件和第三方应用）交互，并实现自我改进。基于此框架，他们开发了 FRIDAY 代理，该代理通过积累技能从先前任务中泛化到未见应用，在 GAIA 基准测试中比现有方法提升 35%，并在 Excel 和 Powerpoint 上展示出最小监督下的控制和学习能力。该框架为开发更强大的一般目的计算机代理提供了基础和洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Project page: https://os-copilot.github.io",
      "pdf_url": "http://arxiv.org/pdf/2402.07456v2",
      "published_date": "2024-02-12 07:29:22 UTC",
      "updated_date": "2024-02-15 09:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:38:03.647262"
    },
    {
      "arxiv_id": "2402.07452v2",
      "title": "TriAug: Out-of-Distribution Detection for Imbalanced Breast Lesion in Ultrasound",
      "title_zh": "翻译失败",
      "authors": [
        "Yinyu Ye",
        "Shijing Chen",
        "Dong Ni",
        "Ruobing Huang"
      ],
      "abstract": "Different diseases, such as histological subtypes of breast lesions, have\nseverely varying incidence rates. Even trained with substantial amount of\nin-distribution (ID) data, models often encounter out-of-distribution (OOD)\nsamples belonging to unseen classes in clinical reality. To address this, we\npropose a novel framework built upon a long-tailed OOD detection task for\nbreast ultrasound images. It is equipped with a triplet state augmentation\n(TriAug) which improves ID classification accuracy while maintaining a\npromising OOD detection performance. Meanwhile, we designed a balanced sphere\nloss to handle the class imbalanced problem. Experimental results show that the\nmodel outperforms state-of-art OOD approaches both in ID classification\n(F1-score=42.12%) and OOD detection (AUROC=78.06%).",
      "tldr_zh": "这篇论文针对乳腺超声图像中类别不平衡问题，提出了一种新的框架，用于Out-of-Distribution (OOD)检测。该框架引入TriAug（三元组状态增强）技术，以提升In-Distribution (ID)分类准确性，同时保持良好的OOD检测性能，并通过Balanced Sphere Loss处理类别不平衡问题。实验结果显示，该模型在ID分类的F1-score达到42.12%，OOD检测的AUROC达到78.06%，优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07452v2",
      "published_date": "2024-02-12 07:19:00 UTC",
      "updated_date": "2024-02-27 02:19:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:38:17.608003"
    },
    {
      "arxiv_id": "2402.07448v1",
      "title": "AraSpider: Democratizing Arabic-to-SQL",
      "title_zh": "AraSpider: 使阿拉伯语到 SQL 转换民主化",
      "authors": [
        "Ahmed Heakl",
        "Youssef Mohamed",
        "Ahmed B. Zaky"
      ],
      "abstract": "This study presents AraSpider, the first Arabic version of the Spider\ndataset, aimed at improving natural language processing (NLP) in the\nArabic-speaking community. Four multilingual translation models were tested for\ntheir effectiveness in translating English to Arabic. Additionally, two models\nwere assessed for their ability to generate SQL queries from Arabic text. The\nresults showed that using back translation significantly improved the\nperformance of both ChatGPT 3.5 and SQLCoder models, which are considered top\nperformers on the Spider dataset. Notably, ChatGPT 3.5 demonstrated\nhigh-quality translation, while SQLCoder excelled in text-to-SQL tasks. The\nstudy underscores the importance of incorporating contextual schema and\nemploying back translation strategies to enhance model performance in Arabic\nNLP tasks. Moreover, the provision of detailed methodologies for\nreproducibility and translation of the dataset into other languages highlights\nthe research's commitment to promoting transparency and collaborative knowledge\nsharing in the field. Overall, these contributions advance NLP research,\nempower Arabic-speaking researchers, and enrich the global discourse on\nlanguage comprehension and database interrogation.",
      "tldr_zh": "本研究推出了 AraSpider，这是 Spider 数据集的首个阿拉伯语版本，旨在提升阿拉伯语社区的自然语言处理 (NLP) 能力并促进文本到 SQL 的民主化。研究者测试了四个多语言翻译模型用于英语到阿拉伯语的翻译，并评估了 ChatGPT 3.5 和 SQLCoder 模型从阿拉伯文本生成 SQL 查询的能力，使用 back translation 策略显著提高了模型性能，其中 ChatGPT 3.5 在翻译质量上表现出色，而 SQLCoder 在文本到 SQL 任务中领先。结果强调了整合 contextual schema 和 back translation 的重要性，以增强阿拉伯语 NLP 任务的准确性。该工作通过提供详细可重复方法论，支持数据集向其他语言的扩展，推进全球 NLP 研究并赋能阿拉伯语研究者。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07448v1",
      "published_date": "2024-02-12 07:11:13 UTC",
      "updated_date": "2024-02-12 07:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:38:30.017969"
    },
    {
      "arxiv_id": "2402.07442v1",
      "title": "Game Agent Driven by Free-Form Text Command: Using LLM-based Code Generation and Behavior Branch",
      "title_zh": "翻译失败",
      "authors": [
        "Ray Ito",
        "Junichiro Takahashi"
      ],
      "abstract": "Several attempts have been made to implement text command control for game\nagents. However, current technologies are limited to processing predefined\nformat commands. This paper proposes a pioneering text command control system\nfor a game agent that can understand natural language commands expressed in\nfree-form. The proposed system uses a large language model (LLM) for code\ngeneration to interpret and transform natural language commands into behavior\nbranch, a proposed knowledge expression based on behavior trees, which\nfacilitates execution by the game agent. This study conducted empirical\nvalidation within a game environment that simulates a Pok\\'emon game and\ninvolved multiple participants. The results confirmed the system's ability to\nunderstand and carry out natural language commands, representing a noteworthy\nin the realm of real-time language interactive game agents.\n  Notice for the use of this material. The copyright of this material is\nretained by the Japanese Society for Artificial Intelligence (JSAI). This\nmaterial is published here with the agreement of JSAI. Please be complied with\nCopyright Law of Japan if any users wish to reproduce, make derivative work,\ndistribute or make available to the public any part or whole thereof. All\nRights Reserved, Copyright (C) The Japanese Society for Artificial\nIntelligence.",
      "tldr_zh": "本论文提出了一种创新的游戏代理控制系统，能够理解和执行自由形式的自然语言文本命令，解决了现有技术仅限于预定义格式命令的局限性。主要方法使用LLM（Large Language Model）进行代码生成，将自然语言命令转化为behavior branch（基于行为树的知识表达），便于游戏代理实时执行。在模拟Pokémon游戏的环境中进行的实证实验证实，该系统能有效处理多参与者命令，提升了实时语言交互游戏代理的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper is posted at JSAI 2024 Conference",
      "pdf_url": "http://arxiv.org/pdf/2402.07442v1",
      "published_date": "2024-02-12 06:49:48 UTC",
      "updated_date": "2024-02-12 06:49:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:38:40.544176"
    },
    {
      "arxiv_id": "2402.07437v2",
      "title": "Learning Optimal Tax Design in Nonatomic Congestion Games",
      "title_zh": "在非原子拥塞博弈中学习最优税收设计",
      "authors": [
        "Qiwen Cui",
        "Maryam Fazel",
        "Simon S. Du"
      ],
      "abstract": "In multiplayer games, self-interested behavior among the players can harm the\nsocial welfare. Tax mechanisms are a common method to alleviate this issue and\ninduce socially optimal behavior. In this work, we take the initial step of\nlearning the optimal tax that can maximize social welfare with limited feedback\nin congestion games. We propose a new type of feedback named \\emph{equilibrium\nfeedback}, where the tax designer can only observe the Nash equilibrium after\ndeploying a tax plan. Existing algorithms are not applicable due to the\nexponentially large tax function space, nonexistence of the gradient, and\nnonconvexity of the objective. To tackle these challenges, we design a\ncomputationally efficient algorithm that leverages several novel components:\n(1) a piece-wise linear tax to approximate the optimal tax; (2) extra linear\nterms to guarantee a strongly convex potential function; (3) an efficient\nsubroutine to find the exploratory tax that can provide critical information\nabout the game. The algorithm can find an $\\epsilon$-optimal tax with $O(\\beta\nF^2/\\epsilon)$ sample complexity, where $\\beta$ is the smoothness of the cost\nfunction and $F$ is the number of facilities.",
      "tldr_zh": "该研究探讨了在非原子拥塞游戏(nonatomic congestion games)中，通过税收机制诱导社会最优行为，以缓解玩家自私行为对社会福利的损害。论文首次提出了一种基于有限反馈的学习算法，使用新的equilibrium feedback机制（仅观察部署税收计划后的Nash equilibrium），来学习最大化社会福利的最优税收。算法通过piece-wise linear tax近似最优税收、添加额外线性项确保strongly convex potential function，以及设计高效子程序来获取游戏关键信息，实现了计算效率的提升，最终以O(β F² / ε)的样本复杂度找到ε-最优税收，其中β是成本函数的光滑度，F是设施的数量。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "23 pages. Accepted by Conference on Neural Information Processing\n  Systems (NeurIPS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.07437v2",
      "published_date": "2024-02-12 06:32:53 UTC",
      "updated_date": "2025-01-15 14:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:38:55.047261"
    },
    {
      "arxiv_id": "2402.07435v1",
      "title": "Analyzing Currency Fluctuations: A Comparative Study of GARCH, EWMA, and IV Models for GBP/USD and EUR/GBP Pairs",
      "title_zh": "分析货币波动：GARCH、EW",
      "authors": [
        "Narayan Tondapu"
      ],
      "abstract": "In this study, we examine the fluctuation in the value of the Great Britain\nPound (GBP). We focus particularly on its relationship with the United States\nDollar (USD) and the Euro (EUR) currency pairs. Utilizing data from June 15,\n2018, to June 15, 2023, we apply various mathematical models to assess their\neffectiveness in predicting the 20-day variation in the pairs' daily returns.\nOur analysis involves the implementation of Exponentially Weighted Moving\nAverage (EWMA), Generalized Autoregressive Conditional Heteroskedasticity\n(GARCH) models, and Implied Volatility (IV) models. To evaluate their\nperformance, we compare the accuracy of their predictions using Root Mean\nSquare Error (RMSE) and Mean Absolute Error (MAE) metrics. We delve into the\nintricacies of GARCH models, examining their statistical characteristics when\napplied to the provided dataset. Our findings suggest the existence of\nasymmetric returns in the EUR/GBP pair, while such evidence is inconclusive for\nthe GBP/USD pair. Additionally, we observe that GARCH-type models better fit\nthe data when assuming residuals follow a standard t-distribution rather than a\nstandard normal distribution. Furthermore, we investigate the efficacy of\ndifferent forecasting techniques within GARCH-type models. Comparing rolling\nwindow forecasts to expanding window forecasts, we find no definitive\nsuperiority in either approach across the tested scenarios. Our experiments\nreveal that for the GBP/USD pair, the most accurate volatility forecasts stem\nfrom the utilization of GARCH models employing a rolling window methodology.\nConversely, for the EUR/GBP pair, optimal forecasts are derived from GARCH\nmodels and Ordinary Least Squares (OLS) models incorporating the annualized\nimplied volatility of the exchange rate as an independent variable.",
      "tldr_zh": "本文研究比较了 EWMA、GARCH 和 IV 模型在预测 GBP/USD 和 EUR/GBP 汇率对 20 天每日回报波动方面的表现，使用 2018 年 6 月 15 日至 2023 年 6 月 15 日的数据，并通过 RMSE 和 MAE 指标评估模型准确性。结果显示，EUR/GBP 汇率存在不对称回报，而 GBP/USD 的证据不明确；此外，GARCH 模型在假设残差服从 t-分布时比标准正态分布更适合数据。研究进一步发现，对于 GBP/USD，GARCH 模型结合滚动窗口预测效果最佳；对于 EUR/GBP，GARCH 和 OLS 模型整合年化隐含波动率（IV）作为自变量能提供最优预测。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07435v1",
      "published_date": "2024-02-12 06:29:57 UTC",
      "updated_date": "2024-02-12 06:29:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:39:06.155785"
    },
    {
      "arxiv_id": "2403.12069v1",
      "title": "Fairness Evaluation for Uplift Modeling in the Absence of Ground Truth",
      "title_zh": "缺乏真实标签时的提升建模公平性评估",
      "authors": [
        "Serdar Kadioglu",
        "Filip Michalsky"
      ],
      "abstract": "The acceleration in the adoption of AI-based automated decision-making\nsystems poses a challenge for evaluating the fairness of algorithmic decisions,\nespecially in the absence of ground truth. When designing interventions, uplift\nmodeling is used extensively to identify candidates that are likely to benefit\nfrom treatment. However, these models remain particularly susceptible to\nfairness evaluation due to the lack of ground truth on the outcome measure\nsince a candidate cannot be in both treatment and control simultaneously. In\nthis article, we propose a framework that overcomes the missing ground truth\nproblem by generating surrogates to serve as a proxy for counterfactual labels\nof uplift modeling campaigns. We then leverage the surrogate ground truth to\nconduct a more comprehensive binary fairness evaluation. We show how to apply\nthe approach in a comprehensive study from a real-world marketing campaign for\npromotional offers and demonstrate its enhancement for fairness evaluation.",
      "tldr_zh": "该论文探讨了在缺乏 ground truth 的情况下评估 uplift modeling 公平性的挑战，尤其是在 AI 决策系统中。作者提出一个框架，通过生成 surrogates 作为 counterfactual labels 的代理，解决缺失真实标签的问题，从而实现更全面的二元 fairness evaluation。该方法在真实营销活动案例中得到应用，结果显示它显著提升了公平性评估的有效性，为类似场景提供了实用解决方案。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "IEEE International Conference on Machine Learning and Applications\n  (IEEE ICMLA)",
      "pdf_url": "http://arxiv.org/pdf/2403.12069v1",
      "published_date": "2024-02-12 06:13:24 UTC",
      "updated_date": "2024-02-12 06:13:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:39:14.687589"
    },
    {
      "arxiv_id": "2402.07429v2",
      "title": "Particle Filter SLAM for Vehicle Localization",
      "title_zh": "粒子滤波",
      "authors": [
        "Tianrui Liu",
        "Changxin Xu",
        "Yuxin Qiao",
        "Chufeng Jiang",
        "Jiqiang Yu"
      ],
      "abstract": "Simultaneous Localization and Mapping (SLAM) presents a formidable challenge\nin robotics, involving the dynamic construction of a map while concurrently\ndetermining the precise location of the robotic agent within an unfamiliar\nenvironment. This intricate task is further compounded by the inherent\n\"chicken-and-egg\" dilemma, where accurate mapping relies on a dependable\nestimation of the robot's location, and vice versa. Moreover, the computational\nintensity of SLAM adds an additional layer of complexity, making it a crucial\nyet demanding topic in the field. In our research, we address the challenges of\nSLAM by adopting the Particle Filter SLAM method. Our approach leverages\nencoded data and fiber optic gyro (FOG) information to enable precise\nestimation of vehicle motion, while lidar technology contributes to\nenvironmental perception by providing detailed insights into surrounding\nobstacles. The integration of these data streams culminates in the\nestablishment of a Particle Filter SLAM framework, representing a key endeavor\nin this paper to effectively navigate and overcome the complexities associated\nwith simultaneous localization and mapping in robotic systems.",
      "tldr_zh": "本研究探讨了机器人领域中SLAM（Simultaneous Localization and Mapping）的挑战，该问题涉及在未知环境中动态构建地图的同时精确定位机器人，并面临相互依赖的“鸡与蛋”困境和计算密集性。论文提出采用Particle Filter SLAM方法，利用编码数据、Fiber Optic Gyro (FOG)信息和Lidar技术来精确估计车辆运动并感知周围障碍，从而整合这些数据流建立一个高效的SLAM框架。该框架有助于机器人系统有效克服定位和映射的复杂性，提升车辆定位的准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, Journal of Industrial Engineering and Applied Science",
      "pdf_url": "http://arxiv.org/pdf/2402.07429v2",
      "published_date": "2024-02-12 06:06:09 UTC",
      "updated_date": "2024-02-20 02:42:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:39:27.454892"
    },
    {
      "arxiv_id": "2402.07422v2",
      "title": "News Recommendation with Attention Mechanism",
      "title_zh": "基于注意力机制的新闻推荐",
      "authors": [
        "Tianrui Liu",
        "Changxin Xu",
        "Yuxin Qiao",
        "Chufeng Jiang",
        "Weisheng Chen"
      ],
      "abstract": "This paper explores the area of news recommendation, a key component of\nonline information sharing. Initially, we provide a clear introduction to news\nrecommendation, defining the core problem and summarizing current methods and\nnotable recent algorithms. We then present our work on implementing the NRAM\n(News Recommendation with Attention Mechanism), an attention-based approach for\nnews recommendation, and assess its effectiveness. Our evaluation shows that\nNRAM has the potential to significantly improve how news content is\npersonalized for users on digital news platforms.",
      "tldr_zh": "本论文探讨了新闻推荐领域，定义了核心问题并总结了当前方法和最新算法。随后，作者提出并实现了 NRAM（News Recommendation with Attention Mechanism），一种基于注意力机制的新闻推荐方法。通过评估发现，NRAM 能够显著提升数字新闻平台上新闻内容的个性化推荐效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, Journal of Industrial Engineering and Applied Science",
      "pdf_url": "http://arxiv.org/pdf/2402.07422v2",
      "published_date": "2024-02-12 05:56:12 UTC",
      "updated_date": "2024-02-20 02:46:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:39:39.019152"
    },
    {
      "arxiv_id": "2402.07420v2",
      "title": "On the Transit Obfuscation Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Hideaki Takahashi",
        "Alex Fukunaga"
      ],
      "abstract": "Concealing an intermediate point on a route or visible from a route is an\nimportant goal in some transportation and surveillance scenarios. This paper\nstudies the Transit Obfuscation Problem, the problem of traveling from some\nstart location to an end location while \"covering\" a specific transit point\nthat needs to be concealed from adversaries. We propose the notion of transit\nanonymity, a quantitative guarantee of the anonymity of a specific transit\npoint, even with a powerful adversary with full knowledge of the path planning\nalgorithm. We propose and evaluate planning/search algorithms that satisfy this\nanonymity criterion.",
      "tldr_zh": "这篇论文探讨了Transit Obfuscation Problem，即在运输或监视场景中，从起点到终点旅行时隐藏特定中间点的问题，以防止对手察觉。作者引入了transit anonymity的概念，这是一种量化指标，能够即使对手完全了解路径规划算法，也确保中间点的匿名性。论文提出并评估了相应的规划和搜索算法，以满足这一匿名性标准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07420v2",
      "published_date": "2024-02-12 05:48:52 UTC",
      "updated_date": "2024-02-13 07:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:39:52.957951"
    },
    {
      "arxiv_id": "2402.07419v2",
      "title": "Conditional Generative Models are Sufficient to Sample from Any Causal Effect Estimand",
      "title_zh": "翻译失败",
      "authors": [
        "Md Musfiqur Rahman",
        "Matt Jordan",
        "Murat Kocaoglu"
      ],
      "abstract": "Causal inference from observational data plays critical role in many\napplications in trustworthy machine learning. While sound and complete\nalgorithms exist to compute causal effects, many of them assume access to\nconditional likelihoods, which is difficult to estimate for high-dimensional\n(particularly image) data. Researchers have alleviated this issue by simulating\ncausal relations with neural models. However, when we have high-dimensional\nvariables in the causal graph along with some unobserved confounders, no\nexisting work can effectively sample from the un/conditional interventional\ndistributions. In this work, we show how to sample from any identifiable\ninterventional distribution given an arbitrary causal graph through a sequence\nof push-forward computations of conditional generative models, such as\ndiffusion models. Our proposed algorithm follows the recursive steps of the\nexisting likelihood-based identification algorithms to train a set of\nfeed-forward models, and connect them in a specific way to sample from the\ndesired distribution. We conduct experiments on a Colored MNIST dataset having\nboth the treatment ($X$) and the target variables ($Y$) as images and sample\nfrom $P(y|do(x))$. Our algorithm also enables us to conduct a causal analysis\nto evaluate spurious correlations among input features of generative models\npre-trained on the CelebA dataset. Finally, we generate high-dimensional\ninterventional samples from the MIMIC-CXR dataset involving text and image\nvariables.",
      "tldr_zh": "该论文证明了条件生成模型（如扩散模型）足以从任何可识别的因果效应估计量中采样，解决了高维数据（如图像）中采样干预分布的挑战，尤其在存在未观测混杂因素的情况下。研究提出了一种算法，通过序列的推前计算和一组前馈模型的训练与连接，遵循现有基于似然的识别算法来实现采样。实验在 Colored MNIST 数据集上成功采样了 P(y|do(x))，并对 CelebA 数据集的生成模型进行了虚假相关分析，最终从 MIMIC-CXR 数据集生成了高维干预样本，展示了方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07419v2",
      "published_date": "2024-02-12 05:48:31 UTC",
      "updated_date": "2024-10-31 12:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:40:06.299898"
    },
    {
      "arxiv_id": "2402.07418v1",
      "title": "SemTra: A Semantic Skill Translator for Cross-Domain Zero-Shot Policy Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Sangwoo Shin",
        "Minjong Yoo",
        "Jeongwoo Lee",
        "Honguk Woo"
      ],
      "abstract": "This work explores the zero-shot adaptation capability of semantic skills,\nsemantically interpretable experts' behavior patterns, in cross-domain\nsettings, where a user input in interleaved multi-modal snippets can prompt a\nnew long-horizon task for different domains. In these cross-domain settings, we\npresent a semantic skill translator framework SemTra which utilizes a set of\nmulti-modal models to extract skills from the snippets, and leverages the\nreasoning capabilities of a pretrained language model to adapt these extracted\nskills to the target domain. The framework employs a two-level hierarchy for\nadaptation: task adaptation and skill adaptation. During task adaptation,\nseq-to-seq translation by the language model transforms the extracted skills\ninto a semantic skill sequence, which is tailored to fit the cross-domain\ncontexts. Skill adaptation focuses on optimizing each semantic skill for the\ntarget domain context, through parametric instantiations that are facilitated\nby language prompting and contrastive learning-based context inferences. This\nhierarchical adaptation empowers the framework to not only infer a complex task\nspecification in one-shot from the interleaved multi-modal snippets, but also\nadapt it to new domains with zero-shot learning abilities. We evaluate our\nframework with Meta-World, Franka Kitchen, RLBench, and CARLA environments. The\nresults clarify the framework's superiority in performing long-horizon tasks\nand adapting to different domains, showing its broad applicability in practical\nuse cases, such as cognitive robots interpreting abstract instructions and\nautonomous vehicles operating under varied configurations.",
      "tldr_zh": "本文提出 SemTra 框架，这是一个语义技能（semantic skills）翻译器，用于跨域零样本（zero-shot）政策适应，能够从交错的多模态片段中一-shot 推断并适应新的长horizon任务。框架采用两级层次结构：任务适应通过 seq-to-seq 翻译和预训练语言模型将提取的技能转化为适合目标域的语义技能序列；技能适应则利用语言提示和基于对比学习（contrastive learning）的上下文推理优化每个技能。实验在 Meta-World、Franka Kitchen、RLBench 和 CARLA 环境中验证，SemTra 表现出色，在执行复杂任务和跨域适应方面优于基线模型，适用于认知机器人和自动驾驶车辆等实际场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2024 Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2402.07418v1",
      "published_date": "2024-02-12 05:46:10 UTC",
      "updated_date": "2024-02-12 05:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:40:18.283799"
    },
    {
      "arxiv_id": "2402.07415v1",
      "title": "Context-aware Multi-Model Object Detection for Diversely Heterogeneous Compute Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Justin Davis",
        "Mehmet E. Belviranli"
      ],
      "abstract": "In recent years, deep neural networks (DNNs) have gained widespread adoption\nfor continuous mobile object detection (OD) tasks, particularly in autonomous\nsystems. However, a prevalent issue in their deployment is the\none-size-fits-all approach, where a single DNN is used, resulting in\ninefficient utilization of computational resources. This inefficiency is\nparticularly detrimental in energy-constrained systems, as it degrades overall\nsystem efficiency. We identify that, the contextual information embedded in the\ninput data stream (e.g. the frames in the camera feed that the OD models are\nrun on) could be exploited to allow a more efficient multi-model-based OD\nprocess. In this paper, we propose SHIFT which continuously selects from a\nvariety of DNN-based OD models depending on the dynamically changing contextual\ninformation and computational constraints. During this selection, SHIFT\nuniquely considers multi-accelerator execution to better optimize the\nenergy-efficiency while satisfying the latency constraints. Our proposed\nmethodology results in improvements of up to 7.5x in energy usage and 2.8x in\nlatency compared to state-of-the-art GPU-based single model OD approaches.",
      "tldr_zh": "该研究针对深度神经网络(DNNs)在移动物体检测(OD)任务中采用单一模型导致的计算资源浪费问题，提出了一种上下文感知的多模型OD框架SHIFT。SHIFT通过利用输入数据流中的上下文信息（如相机帧）动态选择合适的DNN-based OD模型，并结合多加速器执行来优化能效，同时满足延迟约束。该方法在实验中实现了高达7.5倍的能量使用改善和2.8倍的延迟减少，显著提升了异构计算系统的整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07415v1",
      "published_date": "2024-02-12 05:38:11 UTC",
      "updated_date": "2024-02-12 05:38:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:40:28.200406"
    },
    {
      "arxiv_id": "2402.07412v1",
      "title": "Auxiliary Reward Generation with Transition Distance Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Li",
        "Shijie Han",
        "Yingnan Zhao",
        "By Liang",
        "Peng Liu"
      ],
      "abstract": "Reinforcement learning (RL) has shown its strength in challenging sequential\ndecision-making problems. The reward function in RL is crucial to the learning\nperformance, as it serves as a measure of the task completion degree. In\nreal-world problems, the rewards are predominantly human-designed, which\nrequires laborious tuning, and is easily affected by human cognitive biases. To\nachieve automatic auxiliary reward generation, we propose a novel\nrepresentation learning approach that can measure the ``transition distance''\nbetween states. Building upon these representations, we introduce an auxiliary\nreward generation technique for both single-task and skill-chaining scenarios\nwithout the need for human knowledge. The proposed approach is evaluated in a\nwide range of manipulation tasks. The experiment results demonstrate the\neffectiveness of measuring the transition distance between states and the\ninduced improvement by auxiliary rewards, which not only promotes better\nlearning efficiency but also increases convergent stability.",
      "tldr_zh": "这项研究针对强化学习（RL）中奖励函数设计的问题，提出了一种新型表示学习方法，用于测量状态之间的“transition distance”，从而自动生成辅助奖励，而无需依赖人类知识。该方法适用于单任务和技能链场景，通过学习状态过渡表示来提升奖励生成的准确性。实验结果显示，在多种操作任务中，该方法显著提高了学习效率和收敛稳定性，证明了其在RL优化中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07412v1",
      "published_date": "2024-02-12 05:13:44 UTC",
      "updated_date": "2024-02-12 05:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:40:39.077885"
    },
    {
      "arxiv_id": "2402.07408v2",
      "title": "Large Language Models are Few-shot Generators: Proposing Hybrid Prompt Algorithm To Generate Webshell Escape Samples",
      "title_zh": "翻译失败",
      "authors": [
        "Mingrui Ma",
        "Lansheng Han",
        "Chunjie Zhou"
      ],
      "abstract": "The frequent occurrence of cyber-attacks has made webshell attacks and\ndefense gradually become a research hotspot in the field of network security.\nHowever, the lack of publicly available benchmark datasets and the\nover-reliance on manually defined rules for webshell escape sample generation\nhave slowed down the progress of research related to webshell escape sample\ngeneration and artificial intelligence (AI)-based webshell detection. To\naddress the drawbacks of weak webshell sample escape capabilities, the lack of\nwebshell datasets with complex malicious features, and to promote the\ndevelopment of webshell detection, we propose the Hybrid Prompt algorithm for\nwebshell escape sample generation with the help of large language models. As a\nprompt algorithm specifically developed for webshell sample generation, the\nHybrid Prompt algorithm not only combines various prompt ideas including Chain\nof Thought, Tree of Thought, but also incorporates various components such as\nwebshell hierarchical module and few-shot example to facilitate the LLM in\nlearning and reasoning webshell escape strategies. Experimental results show\nthat the Hybrid Prompt algorithm can work with multiple LLMs with excellent\ncode reasoning ability to generate high-quality webshell samples with high\nEscape Rate (88.61% with GPT-4 model on VirusTotal detection engine) and\n(Survival Rate 54.98% with GPT-4 model).",
      "tldr_zh": "该研究指出，webshell 攻击防御领域因缺乏公开基准数据集和过度依赖手动规则，导致相关研究进展缓慢，因此提出 Hybrid Prompt 算法，利用 Large Language Models (LLMs) 作为 few-shot 生成器来创建高质 webshell 逃逸样本。算法结合 Chain of Thought、Tree of Thought 等提示策略，并融入 webshell 层次模块和 few-shot 示例，帮助 LLMs 有效学习和推理逃逸策略。实验结果显示，该算法与多种 LLMs 兼容，使用 GPT-4 时，生成的样本 Escape Rate 达 88.61%（在 VirusTotal 上），Survival Rate 达 54.98%，从而促进 AI 驱动的 webshell 检测发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "21 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07408v2",
      "published_date": "2024-02-12 04:59:58 UTC",
      "updated_date": "2024-06-05 02:23:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:40:53.839799"
    },
    {
      "arxiv_id": "2402.07404v1",
      "title": "Enhancing Multi-Criteria Decision Analysis with AI: Integrating Analytic Hierarchy Process and GPT-4 for Automated Decision Support",
      "title_zh": "使用 AI 增强多准则决策分析：整合分析层次过程和 GPT-4 用于自动化决策支持",
      "authors": [
        "Igor Svoboda",
        "Dmytro Lande"
      ],
      "abstract": "Our study presents a new framework that incorporates the Analytic Hierarchy\nProcess (AHP) and Generative Pre-trained Transformer 4 (GPT-4) large language\nmodel (LLM), bringing novel approaches to cybersecurity Multiple-criteria\nDecision Making (MCDA). By utilizing the capabilities of GPT-4 autonomous\nagents as virtual experts, we automate the decision-making process, enhancing\nboth efficiency and reliability. This new approach focuses on leveraging LLMs\nfor sophisticated decision analysis, highlighting the synergy between\ntraditional decision-making models and cutting-edge AI technologies. Our\ninnovative methodology demonstrates significant advancements in using AI-driven\nagents for complex decision-making scenarios, highlighting the importance of AI\nin strategic cybersecurity applications. The findings reveal the transformative\npotential of combining AHP and LLMs, establishing a new paradigm for\nintelligent decision support systems in cybersecurity and beyond.",
      "tldr_zh": "本研究提出了一种新框架，将Analytic Hierarchy Process (AHP)和GPT-4大型语言模型(LLM)整合到多标准决策分析(MCDA)中，旨在为网络安全领域提供自动化决策支持。通过利用GPT-4的自主代理作为虚拟专家，该方法自动化了决策过程，提高了效率和可靠性。实验结果展示了AHP与LLM的协同作用，在复杂决策场景中实现了显著进展，并为智能决策支持系统在网络安全及其他领域的应用建立了新范式。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.MA",
        "I.2.1; I.2.8; H.1.1"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2402.07404v1",
      "published_date": "2024-02-12 04:47:38 UTC",
      "updated_date": "2024-02-12 04:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:41:03.287980"
    },
    {
      "arxiv_id": "2402.07402v1",
      "title": "BDIQA: A New Dataset for Video Question Answering to Explore Cognitive Reasoning through Theory of Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanyuan Mao",
        "Xin Lin",
        "Qin Ni",
        "Liang He"
      ],
      "abstract": "As a foundational component of cognitive intelligence, theory of mind (ToM)\ncan make AI more closely resemble human thought processes, thereby enhancing\ntheir interaction and collaboration with human. In particular, it can\nsignificantly improve a model's comprehension of videos in complex scenes.\nHowever, current video question answer (VideoQA) datasets focus on studying\ncausal reasoning within events few of them genuinely incorporating human ToM.\nConsequently, there is a lack of development in ToM reasoning tasks within the\narea of VideoQA. This paper presents BDIQA, the first benchmark to explore the\ncognitive reasoning capabilities of VideoQA models in the context of ToM. BDIQA\nis inspired by the cognitive development of children's ToM and addresses the\ncurrent deficiencies in machine ToM within datasets and tasks. Specifically, it\noffers tasks at two difficulty levels, assessing Belief, Desire and Intention\n(BDI) reasoning in both simple and complex scenarios. We conduct evaluations on\nseveral mainstream methods of VideoQA and diagnose their capabilities with zero\nshot, few shot and supervised learning. We find that the performance of\npre-trained models on cognitive reasoning tasks remains unsatisfactory. To\ncounter this challenge, we undertake thorough analysis and experimentation,\nultimately presenting two guidelines to enhance cognitive reasoning derived\nfrom ablation analysis.",
      "tldr_zh": "该论文提出了 BDIQA 数据集，这是首个针对 Video Question Answering (VideoQA) 领域探索 Theory of Mind (ToM) 认知推理能力的基准，旨在使 AI 更接近人类思维过程并提升视频理解。BDIQA 受儿童 ToM 发展启发，设计了简单和复杂场景下的任务，评估 Belief, Desire and Intention (BDI) 推理能力。实验结果显示，主流 VideoQA 方法在 zero-shot、few-shot 和 supervised learning 模式下表现不佳；论文通过分析和消融实验，给出了两个提升认知推理的指导原则。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07402v1",
      "published_date": "2024-02-12 04:34:19 UTC",
      "updated_date": "2024-02-12 04:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:41:16.971751"
    },
    {
      "arxiv_id": "2402.07398v3",
      "title": "VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization",
      "title_zh": "VisLingInstruct：通过自主指令优化提升多模态语言模型中的零样本学习",
      "authors": [
        "Dongsheng Zhu",
        "Xunzhu Tang",
        "Weidong Han",
        "Jinghui Lu",
        "Yukun Zhao",
        "Guoliang Xing",
        "Junfeng Wang",
        "Dawei Yin"
      ],
      "abstract": "This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual content. Our comprehensive experiments on\nMMLMs, based on FlanT5 and Vicuna, show that VisLingInstruct significantly\nimproves zero-shot performance in visual multi-modal tasks. Notably, it\nachieves a 13.1% and 9% increase in accuracy over the prior state-of-the-art on\nthe TextVQA and HatefulMemes datasets. Our main code is available at\nhttps://github.com/Zhudongsheng75/VisLingInstruct.",
      "tldr_zh": "本文提出 VisLingInstruct，一种创新方法，用于提升多模态语言模型 (MMLMs) 在零样本学习中的性能，通过自主评估和优化指令文本，利用 In-Context Learning 增强视觉感知与语言表达的协同，并优化视觉特征提取模块。相比现有技术，该方法显著提高了 MMLMs 的响应能力。实验基于 FlanT5 和 Vicuna 模型，在 TextVQA 和 HatefulMemes 数据集上，准确率分别提升了 13.1% 和 9%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NAACL2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2402.07398v3",
      "published_date": "2024-02-12 04:13:16 UTC",
      "updated_date": "2024-06-20 14:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:41:28.685885"
    },
    {
      "arxiv_id": "2402.07393v1",
      "title": "TeMPO: Efficient Time-Multiplexed Dynamic Photonic Tensor Core for Edge AI with Compact Slow-Light Electro-Optic Modulator",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Zhang",
        "Dennis Yin",
        "Nicholas Gangi",
        "Amir Begović",
        "Alexander Chen",
        "Zhaoran Rena Huang",
        "Jiaqi Gu"
      ],
      "abstract": "Electronic-photonic computing systems offer immense potential in\nenergy-efficient artificial intelligence (AI) acceleration tasks due to the\nsuperior computing speed and efficiency of optics, especially for real-time,\nlow-energy deep neural network (DNN) inference tasks on resource-restricted\nedge platforms. However, current optical neural accelerators based on\nfoundry-available devices and conventional system architecture still encounter\na performance gap compared to highly customized electronic counterparts. To\nbridge the performance gap due to lack of domain specialization, we present a\ntime-multiplexed dynamic photonic tensor accelerator, dubbed TeMPO, with\ncross-layer device/circuit/architecture customization. At the device level, we\npresent foundry-compatible, customized photonic devices, including a slow-light\nelectro-optic modulator with experimental demonstration, optical splitters, and\nphase shifters that significantly reduce the footprint and power in input\nencoding and dot-product calculation. At the circuit level, partial products\nare hierarchically accumulated via parallel photocurrent aggregation,\nlightweight capacitive temporal integration, and sequential digital summation,\nconsiderably relieving the analog-to-digital conversion bottleneck. We also\nemploy a multi-tile, multi-core architecture to maximize hardware sharing for\nhigher efficiency. Across diverse edge AI workloads, TeMPO delivers\ndigital-comparable task accuracy with superior quantization/noise tolerance. We\nachieve a 368.6 TOPS peak performance, 22.3 TOPS/W energy efficiency, and 1.2\nTOPS/mm$^2$ compute density, pushing the Pareto frontier in edge AI hardware.\nThis work signifies the power of cross-layer co-design and domain-specific\ncustomization, paving the way for future electronic-photonic accelerators with\neven greater performance and efficiency.",
      "tldr_zh": "该研究提出TeMPO，一种高效的时间复用动态光子张量核心，用于边缘AI加速，通过跨层设备/电路/架构定制来桥接光子计算与电子系统的性能差距。具体而言，在设备层面，TeMPO采用foundry兼容的定制光子器件，如slow-light electro-optic modulator和光学分光器，以减少输入编码和点积计算的占用空间和功率；在电路层面，通过并行光电流聚合和轻量级电容时间积分缓解模数转换瓶颈。实验结果显示，TeMPO在各种边缘AI工作负载中实现与数字系统相当的准确性，并达到368.6 TOPS峰值性能、22.3 TOPS/W能效和1.2 TOPS/mm²计算密度，展示了跨层联合设计在电子-光子加速器领域的潜力。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.ET",
      "comment": "17 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07393v1",
      "published_date": "2024-02-12 03:40:32 UTC",
      "updated_date": "2024-02-12 03:40:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:41:41.889735"
    },
    {
      "arxiv_id": "2402.07384v1",
      "title": "Exploring Perceptual Limitation of Multimodal Large Language Models",
      "title_zh": "探索多模态大型语言模型的感知限制",
      "authors": [
        "Jiarui Zhang",
        "Jinyi Hu",
        "Mahyar Khayatkhoei",
        "Filip Ilievski",
        "Maosong Sun"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have recently shown remarkable\nperceptual capability in answering visual questions, however, little is known\nabout the limits of their perception. In particular, while prior works have\nprovided anecdotal evidence of MLLMs' sensitivity to object size, this\nphenomenon and its underlying causes have not been explored comprehensively. In\nthis work, we quantitatively study the perception of small visual objects in\nseveral state-of-the-art MLLMs and reveal a pervasive limitation in answering\nquestions about small objects in images. Next, we identify four independent\nfactors that can contribute to this limitation -- object quality, size,\ndistractors, and location -- and conduct controlled intervention studies to\nmeasure the effect of each factor on MLLMs' perception. In particular, we find\nthat lower object quality and smaller object size can both independently reduce\nMLLMs' ability to answer visual questions. More surprisingly, we find that the\nlocation of the object in the image and the presence of visual distractors can\nalso significantly reduce MLLMs' question answering accuracy. Our study\nprovides a better understanding of the perceptual limitation of MLLMs and\ncontributes new evaluation protocols for analyzing the perception of future\nMLLMs. To facilitate further investigations, we release our code and data.",
      "tldr_zh": "本论文探讨了多模态大语言模型 (MLLMs) 在视觉问题回答中的感知限制，特别是对小对象的敏感性。研究通过量化分析发现，现有最先进 MLLMs 在处理图像中小对象的问题时存在普遍限制，并识别了四个独立因素：对象质量、尺寸、分心物 (distractors) 和位置。作者进行了控制干预研究，证明这些因素能独立降低 MLLMs 的视觉问答准确性，例如较低的对象质量和较小尺寸会显著影响性能。总体上，该工作提升了对 MLLMs 感知限制的理解，并提供了新的评估协议，同时公开了代码和数据以促进后续研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 14 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.07384v1",
      "published_date": "2024-02-12 03:04:42 UTC",
      "updated_date": "2024-02-12 03:04:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:41:55.149874"
    },
    {
      "arxiv_id": "2402.07370v2",
      "title": "SelfSwapper: Self-Supervised Face Swapping via Shape Agnostic Masked AutoEncoder",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeseong Lee",
        "Junha Hyung",
        "Sohyun Jeong",
        "Jaegul Choo"
      ],
      "abstract": "Face swapping has gained significant attention for its varied applications.\nMost previous face swapping approaches have relied on the seesaw game training\nscheme, also known as the target-oriented approach. However, this often leads\nto instability in model training and results in undesired samples with blended\nidentities due to the target identity leakage problem. Source-oriented methods\nachieve more stable training with self-reconstruction objective but often fail\nto accurately reflect target image's skin color and illumination. This paper\nintroduces the Shape Agnostic Masked AutoEncoder (SAMAE) training scheme, a\nnovel self-supervised approach that combines the strengths of both\ntarget-oriented and source-oriented approaches. Our training scheme addresses\nthe limitations of traditional training methods by circumventing the\nconventional seesaw game and introducing clear ground truth through its\nself-reconstruction training regime. Our model effectively mitigates identity\nleakage and reflects target albedo and illumination through learned\ndisentangled identity and non-identity features. Additionally, we closely\ntackle the shape misalignment and volume discrepancy problems with new\ntechniques, including perforation confusion and random mesh scaling. SAMAE\nestablishes a new state-of-the-art, surpassing other baseline methods,\npreserving both identity and non-identity attributes without sacrificing on\neither aspect.",
      "tldr_zh": "这篇论文介绍了 SelfSwapper，一种基于 Shape Agnostic Masked AutoEncoder (SAMAE) 的自监督面部交换方法，旨在克服传统 seesaw game 训练方案的训练不稳定和身份泄露问题，以及来源导向方法的肤色和光照不准确缺陷。SAMAE 通过自重建训练结合目标导向和来源导向优势，学习分离的身份和非身份特征，并引入 perforation confusion 和 random mesh scaling 技巧来解决形状不对齐和体积差异问题。实验结果显示，该方法超越了基线模型，在保留身份和非身份属性方面建立了新的最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07370v2",
      "published_date": "2024-02-12 02:01:53 UTC",
      "updated_date": "2024-07-22 15:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:42:07.405955"
    },
    {
      "arxiv_id": "2402.07368v1",
      "title": "Assessing Generalization for Subpopulation Representative Modeling via In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Simmons",
        "Vladislav Savinov"
      ],
      "abstract": "This study evaluates the ability of Large Language Model (LLM)-based\nSubpopulation Representative Models (SRMs) to generalize from empirical data,\nutilizing in-context learning with data from the 2016 and 2020 American\nNational Election Studies. We explore generalization across response variables\nand demographic subgroups. While conditioning with empirical data improves\nperformance on the whole, the benefit of in-context learning varies\nconsiderably across demographics, sometimes hurting performance for one\ndemographic while helping performance for others. The inequitable benefits of\nin-context learning for SRM present a challenge for practitioners implementing\nSRMs, and for decision-makers who might come to rely on them. Our work\nhighlights a need for fine-grained benchmarks captured from diverse\nsubpopulations that test not only fidelity but generalization.",
      "tldr_zh": "这项研究评估了Large Language Model (LLM) 基于的Subpopulation Representative Models (SRMs) 通过In-Context Learning 从经验数据中进行泛化的能力，使用2016和2020年美国国家选举研究的数据，重点探讨响应变量和人口统计学子群体的泛化效果。结果显示，虽然In-Context Learning 改善了整体性能，但其益处在不同人口统计学子群体间差异显著，有时会损害某些群体的表现而提升其他群体的。研究强调，这对实施SRMs 的从业者和决策者构成挑战，并呼吁开发细粒度的、多样子群体的基准，以测试不仅仅是保真度，还包括泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to PERSONALIZE workshop at EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.07368v1",
      "published_date": "2024-02-12 01:55:51 UTC",
      "updated_date": "2024-02-12 01:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:42:19.540060"
    },
    {
      "arxiv_id": "2402.07366v2",
      "title": "Bayesian Deep Learning Via Expectation Maximization and Turbo Deep Approximate Message Passing",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Xu",
        "An Liu",
        "Yiting Zhang",
        "Vincent Lau"
      ],
      "abstract": "Efficient learning and model compression algorithm for deep neural network\n(DNN) is a key workhorse behind the rise of deep learning (DL). In this work,\nwe propose a message passing based Bayesian deep learning algorithm called\nEM-TDAMP to avoid the drawbacks of traditional stochastic gradient descent\n(SGD) based learning algorithms and regularization-based model compression\nmethods. Specifically, we formulate the problem of DNN learning and compression\nas a sparse Bayesian inference problem, in which group sparse prior is employed\nto achieve structured model compression. Then, we propose an expectation\nmaximization (EM) framework to estimate posterior distributions for parameters\n(E-step) and update hyperparameters (M-step), where the E-step is realized by a\nnewly proposed turbo deep approximate message passing (TDAMP) algorithm. We\nfurther extend the EM-TDAMP and propose a novel Bayesian federated learning\nframework, in which and the clients perform TDAMP to efficiently calculate the\nlocal posterior distributions based on the local data, and the central server\nfirst aggregates the local posterior distributions to update the global\nposterior distributions and then update hyperparameters based on EM to\naccelerate convergence. We detail the application of EM-TDAMP to Boston housing\nprice prediction and handwriting recognition, and present extensive numerical\nresults to demonstrate the advantages of EM-TDAMP.",
      "tldr_zh": "本研究提出了一种基于消息传递的Bayesian深度学习算法EM-TDAMP，用于高效的DNN学习和模型压缩，以克服传统SGD算法的缺点和正则化方法的局限。算法将DNN学习问题表述为稀疏Bayesian推理，使用组稀疏先验实现结构化模型压缩，并通过Expectation Maximization (EM)框架的E-step（利用新提出的Turbo Deep Approximate Message Passing (TDAMP)算法估计参数后验分布）和M-step（更新超参数）来优化过程。此外，EM-TDAMP扩展到Bayesian联邦学习框架中，客户端使用TDAMP计算本地后验分布，服务器聚合并更新全局分布以加速收敛。实验结果显示，该算法在波士顿房价预测和手写识别任务上表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07366v2",
      "published_date": "2024-02-12 01:47:06 UTC",
      "updated_date": "2024-06-09 11:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:42:30.464077"
    },
    {
      "arxiv_id": "2407.04700v1",
      "title": "The Physics of Learning: From Autoencoders to Truly Autonomous Learning Machines",
      "title_zh": "学习的物理学：从 Autoencoders 到真正自治的学习机器",
      "authors": [
        "Alex Ushveridze"
      ],
      "abstract": "The fact that accurately predicted information can serve as an energy source\npaves the way for new approaches to autonomous learning. The energy derived\nfrom a sequence of successful predictions can be recycled as an immediate\nincentive and resource, driving the enhancement of predictive capabilities in\nAI agents. We propose that, through a series of straightforward\nmeta-architectural adjustments, any unsupervised learning apparatus could\nachieve complete independence from external energy sources, evolving into a\nself-sustaining physical system with a strong intrinsic 'drive' for continual\nlearning. This concept, while still purely theoretical, is exemplified through\nthe autoencoder, a quintessential model for unsupervised efficient coding. We\nuse this model to demonstrate how progressive paradigm shifts can profoundly\nalter our comprehension of learning and intelligence. By reconceptualizing\nlearning as an energy-seeking process, we highlight the potential for achieving\ntrue autonomy in learning systems, thereby bridging the gap between algorithmic\nconcepts and physical models of intelligence.",
      "tldr_zh": "该论文提出，将准确预测信息视为能量来源，能驱动AI代理的自主学习，通过成功的预测序列回收能量作为激励资源。作者建议通过简单的元架构调整，使任何无监督学习系统（如autoencoder）独立于外部能量来源，演变为自持的物理系统，具有内在的持续学习驱动力。该理论概念以autoencoder为例，展示了范式转变如何重新定义学习为能量寻求过程，从而桥接算法概念与物理模型，实现真正自治的学习机器。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG",
        "physics.class-ph"
      ],
      "primary_category": "cs.ET",
      "comment": "17 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.04700v1",
      "published_date": "2024-02-12 01:36:26 UTC",
      "updated_date": "2024-02-12 01:36:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:42:41.270699"
    },
    {
      "arxiv_id": "2402.07350v1",
      "title": "Antagonistic AI",
      "title_zh": "翻译失败",
      "authors": [
        "Alice Cai",
        "Ian Arawjo",
        "Elena L. Glassman"
      ],
      "abstract": "The vast majority of discourse around AI development assumes that\nsubservient, \"moral\" models aligned with \"human values\" are universally\nbeneficial -- in short, that good AI is sycophantic AI. We explore the shadow\nof the sycophantic paradigm, a design space we term antagonistic AI: AI systems\nthat are disagreeable, rude, interrupting, confrontational, challenging, etc.\n-- embedding opposite behaviors or values. Far from being \"bad\" or \"immoral,\"\nwe consider whether antagonistic AI systems may sometimes have benefits to\nusers, such as forcing users to confront their assumptions, build resilience,\nor develop healthier relational boundaries. Drawing from formative explorations\nand a speculative design workshop where participants designed fictional AI\ntechnologies that employ antagonism, we lay out a design space for antagonistic\nAI, articulating potential benefits, design techniques, and methods of\nembedding antagonistic elements into user experience. Finally, we discuss the\nmany ethical challenges of this space and identify three dimensions for the\nresponsible design of antagonistic AI -- consent, context, and framing.",
      "tldr_zh": "本论文探讨了Antagonistic AI的设计空间，即开发不顺从、粗鲁或挑战性的AI系统，以对抗主流的sycophantic AI范式。作者认为，这种对抗性AI可能带来益处，如帮助用户质疑假设、增强韧性或建立健康边界，通过formative explorations和speculative design workshop来定义设计技巧和嵌入方法。论文还分析了伦理挑战，并提出负责任设计的三个维度：consent、context和framing，以确保其适度应用。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "I.2.0; J.0; K.4.0"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 1 figure, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.07350v1",
      "published_date": "2024-02-12 00:44:37 UTC",
      "updated_date": "2024-02-12 00:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:42:53.424942"
    },
    {
      "arxiv_id": "2402.07347v1",
      "title": "Accuracy of TextFooler black box adversarial attacks on 01 loss sign activation neural network ensemble",
      "title_zh": "翻译失败",
      "authors": [
        "Yunzhe Xue",
        "Usman Roshan"
      ],
      "abstract": "Recent work has shown the defense of 01 loss sign activation neural networks\nagainst image classification adversarial attacks. A public challenge to attack\nthe models on CIFAR10 dataset remains undefeated. We ask the following question\nin this study: are 01 loss sign activation neural networks hard to deceive with\na popular black box text adversarial attack program called TextFooler? We study\nthis question on four popular text classification datasets: IMDB reviews, Yelp\nreviews, MR sentiment classification, and AG news classification. We find that\nour 01 loss sign activation network is much harder to attack with TextFooler\ncompared to sigmoid activation cross entropy and binary neural networks. We\nalso study a 01 loss sign activation convolutional neural network with a novel\nglobal pooling step specific to sign activation networks. With this new\nvariation we see a significant gain in adversarial accuracy rendering\nTextFooler practically useless against it. We make our code freely available at\n\\url{https://github.com/zero-one-loss/wordcnn01} and\n\\url{https://github.com/xyzacademic/mlp01example}. Our work here suggests that\n01 loss sign activation networks could be further developed to create fool\nproof models against text adversarial attacks.",
      "tldr_zh": "该研究评估了01 loss sign activation neural networks在面对TextFooler黑盒对抗攻击时的鲁棒性，实验涉及IMDB、Yelp、MR和AG news等文本分类数据集。结果显示，这种网络比基于sigmoid activation cross entropy和binary neural networks的模型更难被攻击，显著提高了对抗准确率。作者进一步引入了一种新型01 loss sign activation convolutional neural network，包含一个novel global pooling step，使TextFooler攻击几乎失效，并建议此框架可用于开发更安全的文本模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07347v1",
      "published_date": "2024-02-12 00:36:34 UTC",
      "updated_date": "2024-02-12 00:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:43:06.169333"
    },
    {
      "arxiv_id": "2402.07344v1",
      "title": "Measurement Scheduling for ICU Patients with Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zongliang Ji",
        "Anna Goldenberg",
        "Rahul G. Krishnan"
      ],
      "abstract": "Scheduling laboratory tests for ICU patients presents a significant\nchallenge. Studies show that 20-40% of lab tests ordered in the ICU are\nredundant and could be eliminated without compromising patient safety. Prior\nwork has leveraged offline reinforcement learning (Offline-RL) to find optimal\npolicies for ordering lab tests based on patient information. However, new ICU\npatient datasets have since been released, and various advancements have been\nmade in Offline-RL methods. In this study, we first introduce a preprocessing\npipeline for the newly-released MIMIC-IV dataset geared toward time-series\ntasks. We then explore the efficacy of state-of-the-art Offline-RL methods in\nidentifying better policies for ICU patient lab test scheduling. Besides\nassessing methodological performance, we also discuss the overall suitability\nand practicality of using Offline-RL frameworks for scheduling laboratory tests\nin ICU settings.",
      "tldr_zh": "本研究针对 ICU 患者实验室测试调度的挑战，指出 20-40% 的测试是冗余的，并利用 Offline Reinforcement Learning (Offline-RL) 来优化测试策略。研究首先引入了一个针对新发布的 MIMIC-IV 数据集的预处理管道，以适应时间序列任务，然后评估了最先进的 Offline-RL 方法在识别更好调度策略方面的效能。通过分析方法性能和实用性，该工作讨论了 Offline-RL 框架在 ICU 环境中的整体适用性，为减少冗余测试提供潜在改进路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended Abstract presented at Machine Learning for Health (ML4H)\n  symposium 2023, December 10th, 2023, New Orleans, United States, 11 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.07344v1",
      "published_date": "2024-02-12 00:22:47 UTC",
      "updated_date": "2024-02-12 00:22:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:43:18.782690"
    },
    {
      "arxiv_id": "2402.07342v1",
      "title": "Imagining a Future of Designing with AI: Dynamic Grounding, Constructive Negotiation, and Sustainable Motivation",
      "title_zh": "翻译失败",
      "authors": [
        "Priyan Vaithilingam",
        "Ian Arawjo",
        "Elena L. Glassman"
      ],
      "abstract": "We ideate a future design workflow that involves AI technology. Drawing from\nactivity and communication theory, we attempt to isolate the new value large AI\nmodels can provide design compared to past technologies. We arrive at three\naffordances -- dynamic grounding, constructive negotiation, and sustainable\nmotivation -- that summarize latent qualities of natural language-enabled\nfoundation models that, if explicitly designed for, can support the process of\ndesign. Through design fiction, we then imagine a future interface as a\ndiegetic prototype, the story of Squirrel Game, that demonstrates each of our\nthree affordances in a realistic usage scenario. Our design process,\nterminology, and diagrams aim to contribute to future discussions about the\nrelative affordances of AI technology with regard to collaborating with human\ndesigners.",
      "tldr_zh": "本论文探讨了AI在设计工作流中的未来应用，基于活动和通信理论，识别出AI模型相对于以往技术的三大优势：dynamic grounding（动态 grounding）、constructive negotiation（建设性协商）和sustainable motivation（可持续动机），这些品质若经专门设计，能提升设计过程。作者通过design fiction（设计虚构）方法，构建了一个diegetic prototype（叙事原型）——Squirrel Game的故事，展示了这些优势在现实场景中的实际运用。最终，该研究为AI与人类设计师协作的讨论提供了新的术语、设计过程和图表，推动相关领域的未来发展。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "J.6; I.2.0; H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07342v1",
      "published_date": "2024-02-12 00:20:43 UTC",
      "updated_date": "2024-02-12 00:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:43:31.559332"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 99,
  "processed_papers_count": 99,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T05:43:56.667759"
}