[
  {
    "arxiv_id": "2402.08128v2",
    "title": "Recursive Joint Simulation in Games",
    "authors": [
      "Vojtech Kovarik",
      "Caspar Oesterheld",
      "Vincent Conitzer"
    ],
    "abstract": "Game-theoretic dynamics between AI agents could differ from traditional\nhuman-human interactions in various ways. One such difference is that it may be\npossible to accurately simulate an AI agent, for example because its source\ncode is known. Our aim is to explore ways of leveraging this possibility to\nachieve more cooperative outcomes in strategic settings. In this paper, we\nstudy an interaction between AI agents where the agents run a recursive joint\nsimulation. That is, the agents first jointly observe a simulation of the\nsituation they face. This simulation in turn recursively includes additional\nsimulations (with a small chance of failure, to avoid infinite recursion), and\nthe results of all these nested simulations are observed before an action is\nchosen. We show that the resulting interaction is strategically equivalent to\nan infinitely repeated version of the original game, allowing a direct transfer\nof existing results such as the various folk theorems.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08128v2",
    "published_date": "2024-02-12 23:53:46 UTC",
    "updated_date": "2024-03-02 03:01:57 UTC"
  },
  {
    "arxiv_id": "2402.08125v1",
    "title": "Customizable Perturbation Synthesis for Robust SLAM Benchmarking",
    "authors": [
      "Xiaohao Xu",
      "Tianyi Zhang",
      "Sibo Wang",
      "Xiang Li",
      "Yongqi Chen",
      "Ye Li",
      "Bhiksha Raj",
      "Matthew Johnson-Roberson",
      "Xiaonan Huang"
    ],
    "abstract": "Robustness is a crucial factor for the successful deployment of robots in\nunstructured environments, particularly in the domain of Simultaneous\nLocalization and Mapping (SLAM). Simulation-based benchmarks have emerged as a\nhighly scalable approach for robustness evaluation compared to real-world data\ncollection. However, crafting a challenging and controllable noisy world with\ndiverse perturbations remains relatively under-explored. To this end, we\npropose a novel, customizable pipeline for noisy data synthesis, aimed at\nassessing the resilience of multi-modal SLAM models against various\nperturbations. This pipeline incorporates customizable hardware setups,\nsoftware components, and perturbed environments. In particular, we introduce\ncomprehensive perturbation taxonomy along with a perturbation composition\ntoolbox, allowing the transformation of clean simulations into challenging\nnoisy environments. Utilizing the pipeline, we instantiate the Robust-SLAM\nbenchmark, which includes diverse perturbation types, to evaluate the risk\ntolerance of existing advanced multi-modal SLAM models. Our extensive analysis\nuncovers the susceptibilities of existing SLAM models to real-world\ndisturbance, despite their demonstrated accuracy in standard benchmarks. Our\nperturbation synthesis toolbox, SLAM robustness evaluation pipeline, and\nRobust-SLAM benchmark will be made publicly available at\nhttps://github.com/Xiaohao-Xu/SLAM-under-Perturbation/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.RO",
    "comment": "40 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.08125v1",
    "published_date": "2024-02-12 23:49:40 UTC",
    "updated_date": "2024-02-12 23:49:40 UTC"
  },
  {
    "arxiv_id": "2402.08115v2",
    "title": "On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks",
    "authors": [
      "Kaya Stechly",
      "Karthik Valmeekam",
      "Subbarao Kambhampati"
    ],
    "abstract": "There has been considerable divergence of opinion on the reasoning abilities\nof Large Language Models (LLMs). While the initial optimism that reasoning\nmight emerge automatically with scale has been tempered thanks to a slew of\ncounterexamples--ranging from multiplication to simple planning--there persists\na wide spread belief that LLMs can self-critique and improve their own\nsolutions in an iterative fashion. This belief seemingly rests on the\nassumption that verification of correctness should be easier than generation--a\nrather classical argument from computational complexity--which should be\nirrelevant to LLMs to the extent that what they are doing is approximate\nretrieval. In this paper, we set out to systematically investigate the\neffectiveness of iterative prompting in the context of reasoning and planning.\nWe present a principled empirical study of the performance of GPT-4 in three\ndomains: Game of 24, Graph Coloring, and STRIPS planning. We experiment both\nwith the model critiquing its own answers and with an external correct reasoner\nverifying proposed solutions. In each case, we analyze whether the content of\ncriticisms actually affects bottom line performance, and whether we can ablate\nelements of the augmented system without losing performance. We observe\nsignificant performance collapse with self-critique and significant performance\ngains with sound external verification. We also note that merely re-prompting\nwith a sound verifier maintains most of the benefits of more involved setups.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2310.12397",
    "pdf_url": "http://arxiv.org/pdf/2402.08115v2",
    "published_date": "2024-02-12 23:11:01 UTC",
    "updated_date": "2024-08-03 21:25:31 UTC"
  },
  {
    "arxiv_id": "2402.08114v2",
    "title": "Active Preference Learning for Large Language Models",
    "authors": [
      "William Muldrew",
      "Peter Hayes",
      "Mingtian Zhang",
      "David Barber"
    ],
    "abstract": "As large language models (LLMs) become more capable, fine-tuning techniques\nfor aligning with human intent are increasingly important. A key consideration\nfor aligning these models is how to most effectively use human resources, or\nmodel resources in the case where LLMs themselves are used as oracles.\nReinforcement learning from Human or AI preferences (RLHF/RLAIF) is the most\nprominent example of such a technique, but is complex and often unstable.\nDirect Preference Optimization (DPO) has recently been proposed as a simpler\nand more stable alternative. In this work, we develop an active learning\nstrategy for DPO to make better use of preference labels. We propose a\npractical acquisition function for prompt/completion pairs based on the\npredictive entropy of the language model and a measure of certainty of the\nimplicit preference model optimized by DPO. We demonstrate how our approach\nimproves both the rate of learning and final performance of fine-tuning on\npairwise preference data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 5 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.08114v2",
    "published_date": "2024-02-12 23:09:00 UTC",
    "updated_date": "2024-06-28 08:22:01 UTC"
  },
  {
    "arxiv_id": "2402.08112v2",
    "title": "A Competition Winning Deep Reinforcement Learning Agent in microRTS",
    "authors": [
      "Scott Goodfriend"
    ],
    "abstract": "Scripted agents have predominantly won the five previous iterations of the\nIEEE microRTS ($\\mu$RTS) competitions hosted at CIG and CoG. Despite Deep\nReinforcement Learning (DRL) algorithms making significant strides in real-time\nstrategy (RTS) games, their adoption in this primarily academic competition has\nbeen limited due to the considerable training resources required and the\ncomplexity inherent in creating and debugging such agents. RAISocketAI is the\nfirst DRL agent to win the IEEE microRTS competition. In a benchmark without\nperformance constraints, RAISocketAI regularly defeated the two prior\ncompetition winners. This first competition-winning DRL submission can be a\nbenchmark for future microRTS competitions and a starting point for future DRL\nresearch. Iteratively fine-tuning the base policy and transfer learning to\nspecific maps were critical to RAISocketAI's winning performance. These\nstrategies can be used to economically train future DRL agents. Further work in\nImitation Learning using Behavior Cloning and fine-tuning these models with DRL\nhas proven promising as an efficient way to bootstrap models with demonstrated,\ncompetitive behaviors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Best paper award nominee at IEEE Conference on Games 2024. 19 pages,\n  6 figures. Source code at https://github.com/sgoodfriend/rl-algo-impls",
    "pdf_url": "http://arxiv.org/pdf/2402.08112v2",
    "published_date": "2024-02-12 23:08:17 UTC",
    "updated_date": "2025-01-02 06:50:23 UTC"
  },
  {
    "arxiv_id": "2402.10958v2",
    "title": "Relative Preference Optimization: Enhancing LLM Alignment through Contrasting Responses across Identical and Diverse Prompts",
    "authors": [
      "Yueqin Yin",
      "Zhendong Wang",
      "Yi Gu",
      "Hai Huang",
      "Weizhu Chen",
      "Mingyuan Zhou"
    ],
    "abstract": "In the field of large language models (LLMs), aligning models with the\ndiverse preferences of users is a critical challenge. Direct Preference\nOptimization (DPO) has played a key role in this area. It works by using pairs\nof preferences derived from the same prompts, and it functions without needing\nan additional reward model. However, DPO does not fully reflect the complex\nnature of human learning, which often involves understanding contrasting\nresponses to not only identical but also similar questions. To overcome this\nshortfall, we propose Relative Preference Optimization (RPO). RPO is designed\nto discern between more and less preferred responses derived from both\nidentical and related prompts. It introduces a contrastive weighting mechanism,\nenabling the tuning of LLMs using a broader range of preference data, including\nboth paired and unpaired sets. This approach expands the learning capabilities\nof the model, allowing it to leverage insights from a more varied set of\nprompts. Through empirical tests, including dialogue and summarization tasks,\nand evaluations using the AlpacaEval2.0 leaderboard, RPO has demonstrated a\nsuperior ability to align LLMs with user preferences and to improve their\nadaptability during the training process. Our code can be viewed at\nhttps://github.com/yinyueqin/relative-preference-optimization",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10958v2",
    "published_date": "2024-02-12 22:47:57 UTC",
    "updated_date": "2024-05-27 20:05:03 UTC"
  },
  {
    "arxiv_id": "2402.08088v1",
    "title": "Out-of-Distribution Detection and Data Drift Monitoring using Statistical Process Control",
    "authors": [
      "Ghada Zamzmi",
      "Kesavan Venkatesh",
      "Brandon Nelson",
      "Smriti Prathapan",
      "Paul H. Yi",
      "Berkman Sahiner",
      "Jana G. Delfino"
    ],
    "abstract": "Background: Machine learning (ML) methods often fail with data that deviates\nfrom their training distribution. This is a significant concern for ML-enabled\ndevices in clinical settings, where data drift may cause unexpected performance\nthat jeopardizes patient safety.\n  Method: We propose a ML-enabled Statistical Process Control (SPC) framework\nfor out-of-distribution (OOD) detection and drift monitoring. SPC is\nadvantageous as it visually and statistically highlights deviations from the\nexpected distribution. To demonstrate the utility of the proposed framework for\nmonitoring data drift in radiological images, we investigated different design\nchoices, including methods for extracting feature representations, drift\nquantification, and SPC parameter selection.\n  Results: We demonstrate the effectiveness of our framework for two tasks: 1)\ndifferentiating axial vs. non-axial computed tomography (CT) images and 2)\nseparating chest x-ray (CXR) from other modalities. For both tasks, we achieved\nhigh accuracy in detecting OOD inputs, with 0.913 in CT and 0.995 in CXR, and\nsensitivity of 0.980 in CT and 0.984 in CXR. Our framework was also adept at\nmonitoring data streams and identifying the time a drift occurred. In a\nsimulation with 100 daily CXR cases, we detected a drift in OOD input\npercentage from 0-1% to 3-5% within two days, maintaining a low false-positive\nrate. Through additional experimental results, we demonstrate the framework's\ndata-agnostic nature and independence from the underlying model's structure.\n  Conclusion: We propose a framework for OOD detection and drift monitoring\nthat is agnostic to data, modality, and model. The framework is customizable\nand can be adapted for specific applications.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08088v1",
    "published_date": "2024-02-12 22:10:06 UTC",
    "updated_date": "2024-02-12 22:10:06 UTC"
  },
  {
    "arxiv_id": "2402.09476v1",
    "title": "AI-Enabled Lung Cancer Prognosis",
    "authors": [
      "Mahtab Darvish",
      "Ryan Trask",
      "Patrick Tallon",
      "Mélina Khansari",
      "Lei Ren",
      "Michelle Hershman",
      "Bardia Yousefi"
    ],
    "abstract": "Lung cancer is the primary cause of cancer-related mortality, claiming\napproximately 1.79 million lives globally in 2020, with an estimated 2.21\nmillion new cases diagnosed within the same period. Among these, Non-Small Cell\nLung Cancer (NSCLC) is the predominant subtype, characterized by a notably\nbleak prognosis and low overall survival rate of approximately 25% over five\nyears across all disease stages. However, survival outcomes vary considerably\nbased on the stage at diagnosis and the therapeutic interventions administered.\nRecent advancements in artificial intelligence (AI) have revolutionized the\nlandscape of lung cancer prognosis. AI-driven methodologies, including machine\nlearning and deep learning algorithms, have shown promise in enhancing survival\nprediction accuracy by efficiently analyzing complex multi-omics data and\nintegrating diverse clinical variables. By leveraging AI techniques, clinicians\ncan harness comprehensive prognostic insights to tailor personalized treatment\nstrategies, ultimately improving patient outcomes in NSCLC. Overviewing\nAI-driven data processing can significantly help bolster the understanding and\nprovide better directions for using such systems.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "q-bio.QM",
    "comment": "This is the author's version of a book chapter entitled: \"Cancer\n  Research: An Interdisciplinary Approach\", Springer",
    "pdf_url": "http://arxiv.org/pdf/2402.09476v1",
    "published_date": "2024-02-12 22:09:43 UTC",
    "updated_date": "2024-02-12 22:09:43 UTC"
  },
  {
    "arxiv_id": "2402.08085v1",
    "title": "Message Detouring: A Simple Yet Effective Cycle Representation for Expressive Graph Learning",
    "authors": [
      "Ziquan Wei",
      "Tingting Dan",
      "Guorong Wu"
    ],
    "abstract": "Graph learning is crucial in the fields of bioinformatics, social networks,\nand chemicals. Although high-order graphlets, such as cycles, are critical to\nachieving an informative graph representation for node classification, edge\nprediction, and graph recognition, modeling high-order topological\ncharacteristics poses significant computational challenges, restricting its\nwidespread applications in machine learning. To address this limitation, we\nintroduce the concept of \\textit{message detouring} to hierarchically\ncharacterize cycle representation throughout the entire graph, which\ncapitalizes on the contrast between the shortest and longest pathways within a\nrange of local topologies associated with each graph node. The topological\nfeature representations derived from our message detouring landscape\ndemonstrate comparable expressive power to high-order\n\\textit{Weisfeiler-Lehman} (WL) tests but much less computational demands. In\naddition to the integration with graph kernel and message passing neural\nnetworks, we present a novel message detouring neural network, which uses\nTransformer backbone to integrate cycle representations across nodes and edges.\nAside from theoretical results, experimental results on expressiveness, graph\nclassification, and node classification show message detouring can\nsignificantly outperform current counterpart approaches on various benchmark\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.08085v1",
    "published_date": "2024-02-12 22:06:37 UTC",
    "updated_date": "2024-02-12 22:06:37 UTC"
  },
  {
    "arxiv_id": "2402.08075v1",
    "title": "Efficient and Scalable Fine-Tune of Language Models for Genome Understanding",
    "authors": [
      "Huixin Zhan",
      "Ying Nian Wu",
      "Zijun Zhang"
    ],
    "abstract": "Although DNA foundation models have advanced the understanding of genomes,\nthey still face significant challenges in the limited scale and diversity of\ngenomic data. This limitation starkly contrasts with the success of natural\nlanguage foundation models, which thrive on substantially larger scales.\nFurthermore, genome understanding involves numerous downstream genome\nannotation tasks with inherent data heterogeneity, thereby necessitating more\nefficient and robust fine-tuning methods tailored for genomics. Here, we\npresent \\textsc{Lingo}: \\textsc{L}anguage prefix f\\textsc{In}e-tuning for\n\\textsc{G}en\\textsc{O}mes. Unlike DNA foundation models, \\textsc{Lingo}\nstrategically leverages natural language foundation models' contextual cues,\nrecalibrating their linguistic knowledge to genomic sequences. \\textsc{Lingo}\nfurther accommodates numerous, heterogeneous downstream fine-tune tasks by an\nadaptive rank sampling method that prunes and stochastically reintroduces\npruned singular vectors within small computational budgets. Adaptive rank\nsampling outperformed existing fine-tuning methods on all benchmarked 14 genome\nunderstanding tasks, while requiring fewer than 2\\% of trainable parameters as\ngenomic-specific adapters. Impressively, applying these adapters on natural\nlanguage foundation models matched or even exceeded the performance of DNA\nfoundation models. \\textsc{Lingo} presents a new paradigm of efficient and\nscalable genome understanding via genomic-specific adapters on language models.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08075v1",
    "published_date": "2024-02-12 21:40:45 UTC",
    "updated_date": "2024-02-12 21:40:45 UTC"
  },
  {
    "arxiv_id": "2402.08072v1",
    "title": "Enhancing Programming Error Messages in Real Time with Generative AI",
    "authors": [
      "Bailey Kimmel",
      "Austin Geisert",
      "Lily Yaro",
      "Brendan Gipson",
      "Taylor Hotchkiss",
      "Sidney Osae-Asante",
      "Hunter Vaught",
      "Grant Wininger",
      "Chase Yamaguchi"
    ],
    "abstract": "Generative AI is changing the way that many disciplines are taught, including\ncomputer science. Researchers have shown that generative AI tools are capable\nof solving programming problems, writing extensive blocks of code, and\nexplaining complex code in simple terms. Particular promise has been shown in\nusing generative AI to enhance programming error messages. Both students and\ninstructors have complained for decades that these messages are often cryptic\nand difficult to understand. Yet recent work has shown that students make fewer\nrepeated errors when enhanced via GPT-4. We extend this work by implementing\nfeedback from ChatGPT for all programs submitted to our automated assessment\ntool, Athene, providing help for compiler, run-time, and logic errors. Our\nresults indicate that adding generative AI to an automated assessment tool does\nnot necessarily make it better and that design of the interface matters greatly\nto the usability of the feedback that GPT-4 provided.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.08072v1",
    "published_date": "2024-02-12 21:32:05 UTC",
    "updated_date": "2024-02-12 21:32:05 UTC"
  },
  {
    "arxiv_id": "2402.08064v1",
    "title": "Beyond LLMs: Advancing the Landscape of Complex Reasoning",
    "authors": [
      "Jennifer Chu-Carroll",
      "Andrew Beck",
      "Greg Burnham",
      "David OS Melville",
      "David Nachman",
      "A. Erdem Özcan",
      "David Ferrucci"
    ],
    "abstract": "Since the advent of Large Language Models a few years ago, they have often\nbeen considered the de facto solution for many AI problems. However, in\naddition to the many deficiencies of LLMs that prevent them from broad industry\nadoption, such as reliability, cost, and speed, there is a whole class of\ncommon real world problems that Large Language Models perform poorly on,\nnamely, constraint satisfaction and optimization problems. These problems are\nubiquitous and current solutions are highly specialized and expensive to\nimplement. At Elemental Cognition, we developed our EC AI platform which takes\na neuro-symbolic approach to solving constraint satisfaction and optimization\nproblems. The platform employs, at its core, a precise and high performance\nlogical reasoning engine, and leverages LLMs for knowledge acquisition and user\ninteraction. This platform supports developers in specifying application logic\nin natural and concise language while generating application user interfaces to\ninteract with users effectively. We evaluated LLMs against systems built on the\nEC AI platform in three domains and found the EC AI systems to significantly\noutperform LLMs on constructing valid and optimal solutions, on validating\nproposed solutions, and on repairing invalid solutions.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08064v1",
    "published_date": "2024-02-12 21:14:45 UTC",
    "updated_date": "2024-02-12 21:14:45 UTC"
  },
  {
    "arxiv_id": "2402.08062v4",
    "title": "Avoiding Catastrophe in Online Learning by Asking for Help",
    "authors": [
      "Benjamin Plaut",
      "Hanlin Zhu",
      "Stuart Russell"
    ],
    "abstract": "Most learning algorithms with formal regret guarantees assume that all\nmistakes are recoverable and essentially rely on trying all possible behaviors.\nThis approach is problematic when some mistakes are \\emph{catastrophic}, i.e.,\nirreparable. We propose an online learning problem where the goal is to\nminimize the chance of catastrophe. Specifically, we assume that the payoff in\neach round represents the chance of avoiding catastrophe that round and try to\nmaximize the product of payoffs (the overall chance of avoiding catastrophe)\nwhile allowing a limited number of queries to a mentor. We first show that in\ngeneral, any algorithm either constantly queries the mentor or is nearly\nguaranteed to cause catastrophe. However, in settings where the mentor policy\nclass is learnable in the standard online model, we provide an algorithm whose\nregret and rate of querying the mentor both approach 0 as the time horizon\ngrows. Conceptually, if a policy class is learnable in the absence of\ncatastrophic risk, it is learnable in the presence of catastrophic risk if the\nagent can ask for help.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08062v4",
    "published_date": "2024-02-12 21:12:11 UTC",
    "updated_date": "2025-01-22 22:10:55 UTC"
  },
  {
    "arxiv_id": "2402.08030v1",
    "title": "Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking",
    "authors": [
      "Anjali Khurana",
      "Hari Subramonyam",
      "Parmit K Chilana"
    ],
    "abstract": "Large Language Model (LLM) assistants, such as ChatGPT, have emerged as\npotential alternatives to search methods for helping users navigate complex,\nfeature-rich software. LLMs use vast training data from domain-specific texts,\nsoftware manuals, and code repositories to mimic human-like interactions,\noffering tailored assistance, including step-by-step instructions. In this\nwork, we investigated LLM-generated software guidance through a within-subject\nexperiment with 16 participants and follow-up interviews. We compared a\nbaseline LLM assistant with an LLM optimized for particular software contexts,\nSoftAIBot, which also offered guidelines for constructing appropriate prompts.\nWe assessed task completion, perceived accuracy, relevance, and trust.\nSurprisingly, although SoftAIBot outperformed the baseline LLM, our results\nrevealed no significant difference in LLM usage and user perceptions with or\nwithout prompt guidelines and the integration of domain context. Most users\nstruggled to understand how the prompt's text related to the LLM's responses\nand often followed the LLM's suggestions verbatim, even if they were incorrect.\nThis resulted in difficulties when using the LLM's advice for software tasks,\nleading to low task completion rates. Our detailed analysis also revealed that\nusers remained unaware of inaccuracies in the LLM's responses, indicating a gap\nbetween their lack of software expertise and their ability to evaluate the\nLLM's assistance. With the growing push for designing domain-specific LLM\nassistants, we emphasize the importance of incorporating explainable,\ncontext-aware cues into LLMs to help users understand prompt-based\ninteractions, identify biases, and maximize the utility of LLM assistants.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for publication in the Proceedings of the 29th International\n  Conference on Intelligent User Interfaces (IUI'24), March 18--21, 2024, in\n  Greenville, SC, USA",
    "pdf_url": "http://arxiv.org/pdf/2402.08030v1",
    "published_date": "2024-02-12 19:49:58 UTC",
    "updated_date": "2024-02-12 19:49:58 UTC"
  },
  {
    "arxiv_id": "2402.08023v1",
    "title": "UGMAE: A Unified Framework for Graph Masked Autoencoders",
    "authors": [
      "Yijun Tian",
      "Chuxu Zhang",
      "Ziyi Kou",
      "Zheyuan Liu",
      "Xiangliang Zhang",
      "Nitesh V. Chawla"
    ],
    "abstract": "Generative self-supervised learning on graphs, particularly graph masked\nautoencoders, has emerged as a popular learning paradigm and demonstrated its\nefficacy in handling non-Euclidean data. However, several remaining issues\nlimit the capability of existing methods: 1) the disregard of uneven node\nsignificance in masking, 2) the underutilization of holistic graph information,\n3) the ignorance of semantic knowledge in the representation space due to the\nexclusive use of reconstruction loss in the output space, and 4) the unstable\nreconstructions caused by the large volume of masked contents. In light of\nthis, we propose UGMAE, a unified framework for graph masked autoencoders to\naddress these issues from the perspectives of adaptivity, integrity,\ncomplementarity, and consistency. Specifically, we first develop an adaptive\nfeature mask generator to account for the unique significance of nodes and\nsample informative masks (adaptivity). We then design a ranking-based structure\nreconstruction objective joint with feature reconstruction to capture holistic\ngraph information and emphasize the topological proximity between neighbors\n(integrity). After that, we present a bootstrapping-based similarity module to\nencode the high-level semantic knowledge in the representation space,\ncomplementary to the low-level reconstruction in the output space\n(complementarity). Finally, we build a consistency assurance module to provide\nreconstruction objectives with extra stabilized consistency targets\n(consistency). Extensive experiments demonstrate that UGMAE outperforms both\ncontrastive and generative state-of-the-art baselines on several tasks across\nmultiple datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08023v1",
    "published_date": "2024-02-12 19:39:26 UTC",
    "updated_date": "2024-02-12 19:39:26 UTC"
  },
  {
    "arxiv_id": "2402.08010v2",
    "title": "Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature Learning",
    "authors": [
      "Yuxiao Wen",
      "Arthur Jacot"
    ],
    "abstract": "We describe the emergence of a Convolution Bottleneck (CBN) structure in\nCNNs, where the network uses its first few layers to transform the input\nrepresentation into a representation that is supported only along a few\nfrequencies and channels, before using the last few layers to map back to the\noutputs. We define the CBN rank, which describes the number and type of\nfrequencies that are kept inside the bottleneck, and partially prove that the\nparameter norm required to represent a function $f$ scales as depth times the\nCBN rank $f$. We also show that the parameter norm depends at next order on the\nregularity of $f$. We show that any network with almost optimal parameter norm\nwill exhibit a CBN structure in both the weights and - under the assumption\nthat the network is stable under large learning rate - the activations, which\nmotivates the common practice of down-sampling; and we verify that the CBN\nresults still hold with down-sampling. Finally we use the CBN structure to\ninterpret the functions learned by CNNs on a number of tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.08010v2",
    "published_date": "2024-02-12 19:18:50 UTC",
    "updated_date": "2025-03-06 14:01:48 UTC"
  },
  {
    "arxiv_id": "2402.16878v1",
    "title": "EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math Languages",
    "authors": [
      "Johnathan Mercer"
    ],
    "abstract": "Formal mathematics is the discipline of translating mathematics into a\nprogramming language in which any statement can be unequivocally checked by a\ncomputer. Mathematicians and computer scientists have spent decades of\npainstaking formalization efforts developing languages such as Coq, HOL, and\nLean. Machine learning research has converged on these formal math corpora and\ngiven rise to an assortment of methodologies to aid in interactive and\nautomated theorem proving. However, these papers have primarily focused on one\nmethod, for one proof task, in one language. This paper introduces EvoGPT-f: a\nnovel evolutionary framework for the first systematic quantitative analysis of\nthe differential machine learnability of five formal math corpora (Lean 3, Lean\n4, Coq, HOL 4, HOL Light) using four tokenization methods (character,\nword-level, Byte Pair Encoding and StarCoder tokenizer). This paper does not\nput to rest the question of the \"best\" or \"easiest\" language to learn. Rather,\nthis framework and preliminary findings begin to illuminate the differential\nmachine learnability of these languages, offering a foundation to forge more\nsystematic quantitative and qualitative comparative research across\ncommunities.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16878v1",
    "published_date": "2024-02-12 19:10:11 UTC",
    "updated_date": "2024-02-12 19:10:11 UTC"
  },
  {
    "arxiv_id": "2402.07901v1",
    "title": "FAST: Factorizable Attention for Speeding up Transformers",
    "authors": [
      "Armin Gerami",
      "Monte Hoover",
      "Pranav S. Dulepet",
      "Ramani Duraiswami"
    ],
    "abstract": "Motivated by the factorization inherent in the original fast multipole method\nand the improved fast Gauss transform we introduce a factorable form of\nattention that operates efficiently in high dimensions. This approach reduces\nthe computational and memory complexity of the attention mechanism in\ntransformers from $O(N^2)$ to $O(N)$. In comparison to previous attempts, our\nwork presents a linearly scaled attention mechanism that maintains the full\nrepresentation of the attention matrix without compromising on sparsification\nand incorporates the all-to-all relationship between tokens. We explore the\nproperties of our new attention metric and conduct tests in various standard\nsettings. Results indicate that our attention mechanism has a robust\nperformance and holds significant promise for diverse applications where\nself-attention is used.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07901v1",
    "published_date": "2024-02-12 18:59:39 UTC",
    "updated_date": "2024-02-12 18:59:39 UTC"
  },
  {
    "arxiv_id": "2402.07895v1",
    "title": "Detection of Spider Mites on Labrador Beans through Machine Learning Approaches Using Custom Datasets",
    "authors": [
      "Violet Liu",
      "Jason Chen",
      "Ans Qureshi",
      "Mahla Nejati"
    ],
    "abstract": "Amidst growing food production demands, early plant disease detection is\nessential to safeguard crops; this study proposes a visual machine learning\napproach for plant disease detection, harnessing RGB and NIR data collected in\nreal-world conditions through a JAI FS-1600D-10GE camera to build an RGBN\ndataset. A two-stage early plant disease detection model with YOLOv8 and a\nsequential CNN was used to train on a dataset with partial labels, which showed\na 3.6% increase in mAP compared to a single-stage end-to-end segmentation\nmodel. The sequential CNN model achieved 90.62% validation accuracy utilising\nRGBN data. An average of 6.25% validation accuracy increase is found using RGBN\nin classification compared to RGB using ResNet15 and the sequential CNN models.\nFurther research and dataset improvements are needed to meet food production\ndemands.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Australasian Conference on Robotics and Automation (ACRA 2023)",
    "pdf_url": "http://arxiv.org/pdf/2402.07895v1",
    "published_date": "2024-02-12 18:57:06 UTC",
    "updated_date": "2024-02-12 18:57:06 UTC"
  },
  {
    "arxiv_id": "2402.07890v1",
    "title": "MAIDCRL: Semi-centralized Multi-Agent Influence Dense-CNN Reinforcement Learning",
    "authors": [
      "Ayesha Siddika Nipu",
      "Siming Liu",
      "Anthony Harris"
    ],
    "abstract": "Distributed decision-making in multi-agent systems presents difficult\nchallenges for interactive behavior learning in both cooperative and\ncompetitive systems. To mitigate this complexity, MAIDRL presents a\nsemi-centralized Dense Reinforcement Learning algorithm enhanced by agent\ninfluence maps (AIMs), for learning effective multi-agent control on StarCraft\nMulti-Agent Challenge (SMAC) scenarios. In this paper, we extend the DenseNet\nin MAIDRL and introduce semi-centralized Multi-Agent Dense-CNN Reinforcement\nLearning, MAIDCRL, by incorporating convolutional layers into the deep model\narchitecture, and evaluate the performance on both homogeneous and\nheterogeneous scenarios. The results show that the CNN-enabled MAIDCRL\nsignificantly improved the learning performance and achieved a faster learning\nrate compared to the existing MAIDRL, especially on more complicated\nheterogeneous SMAC scenarios. We further investigate the stability and\nrobustness of our model. The statistics reflect that our model not only\nachieves higher winning rate in all the given scenarios but also boosts the\nagent's learning process in fine-grained decision-making.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "2022 IEEE Conference on Games (CoG)",
    "pdf_url": "http://arxiv.org/pdf/2402.07890v1",
    "published_date": "2024-02-12 18:53:20 UTC",
    "updated_date": "2024-02-12 18:53:20 UTC"
  },
  {
    "arxiv_id": "2402.07877v4",
    "title": "WildfireGPT: Tailored Large Language Model for Wildfire Analysis",
    "authors": [
      "Yangxinyu Xie",
      "Bowen Jiang",
      "Tanwi Mallick",
      "Joshua David Bergerson",
      "John K. Hutchison",
      "Duane R. Verner",
      "Jordan Branham",
      "M. Ross Alexander",
      "Robert B. Ross",
      "Yan Feng",
      "Leslie-Anne Levy",
      "Weijie Su",
      "Camillo J. Taylor"
    ],
    "abstract": "Recent advancement of large language models (LLMs) represents a\ntransformational capability at the frontier of artificial intelligence.\nHowever, LLMs are generalized models, trained on extensive text corpus, and\noften struggle to provide context-specific information, particularly in areas\nrequiring specialized knowledge, such as wildfire details within the broader\ncontext of climate change. For decision-makers focused on wildfire resilience\nand adaptation, it is crucial to obtain responses that are not only precise but\nalso domain-specific. To that end, we developed WildfireGPT, a prototype LLM\nagent designed to transform user queries into actionable insights on wildfire\nrisks. We enrich WildfireGPT by providing additional context, such as climate\nprojections and scientific literature, to ensure its information is current,\nrelevant, and scientifically accurate. This enables WildfireGPT to be an\neffective tool for delivering detailed, user-specific insights on wildfire\nrisks to support a diverse set of end users, including but not limited to\nresearchers and engineers, for making positive impact and decision making.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "restoring content for arXiv:2402.07877v2 which was replaced in error",
    "pdf_url": "http://arxiv.org/pdf/2402.07877v4",
    "published_date": "2024-02-12 18:41:55 UTC",
    "updated_date": "2025-04-23 03:30:33 UTC"
  },
  {
    "arxiv_id": "2402.07876v6",
    "title": "Policy Improvement using Language Feedback Models",
    "authors": [
      "Victor Zhong",
      "Dipendra Misra",
      "Xingdi Yuan",
      "Marc-Alexandre Côté"
    ],
    "abstract": "We introduce Language Feedback Models (LFMs) that identify desirable\nbehaviour - actions that help achieve tasks specified in the instruction - for\nimitation learning in instruction following. To train LFMs, we obtain feedback\nfrom Large Language Models (LLMs) on visual trajectories verbalized to language\ndescriptions. First, by using LFMs to identify desirable behaviour to imitate,\nwe improve in task-completion rate over strong behavioural cloning baselines on\nthree distinct language grounding environments (Touchdown, ScienceWorld, and\nALFWorld). Second, LFMs outperform using LLMs as experts to directly predict\nactions, when controlling for the number of LLM output tokens. Third, LFMs\ngeneralize to unseen environments, improving task-completion rate by 3.5-12.0%\nthrough one round of adaptation. Finally, LFM can be modified to provide\nhuman-interpretable feedback without performance loss, allowing human\nverification of desirable behaviour for imitation learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.07876v6",
    "published_date": "2024-02-12 18:41:34 UTC",
    "updated_date": "2024-10-10 03:23:41 UTC"
  },
  {
    "arxiv_id": "2402.07875v2",
    "title": "Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States",
    "authors": [
      "Noam Razin",
      "Yotam Alexander",
      "Edo Cohen-Karlik",
      "Raja Giryes",
      "Amir Globerson",
      "Nadav Cohen"
    ],
    "abstract": "In modern machine learning, models can often fit training data in numerous\nways, some of which perform well on unseen (test) data, while others do not.\nRemarkably, in such cases gradient descent frequently exhibits an implicit bias\nthat leads to excellent performance on unseen data. This implicit bias was\nextensively studied in supervised learning, but is far less understood in\noptimal control (reinforcement learning). There, learning a controller applied\nto a system via gradient descent is known as policy gradient, and a question of\nprime importance is the extent to which a learned controller extrapolates to\nunseen initial states. This paper theoretically studies the implicit bias of\npolicy gradient in terms of extrapolation to unseen initial states. Focusing on\nthe fundamental Linear Quadratic Regulator (LQR) problem, we establish that the\nextent of extrapolation depends on the degree of exploration induced by the\nsystem when commencing from initial states included in training. Experiments\ncorroborate our theory, and demonstrate its conclusions on problems beyond LQR,\nwhere systems are non-linear and controllers are neural networks. We\nhypothesize that real-world optimal control may be greatly improved by\ndeveloping methods for informed selection of initial states to train on.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.07875v2",
    "published_date": "2024-02-12 18:41:31 UTC",
    "updated_date": "2024-06-01 18:17:12 UTC"
  },
  {
    "arxiv_id": "2402.07871v1",
    "title": "Scaling Laws for Fine-Grained Mixture of Experts",
    "authors": [
      "Jakub Krajewski",
      "Jan Ludziejewski",
      "Kamil Adamczewski",
      "Maciej Pióro",
      "Michał Krutul",
      "Szymon Antoniak",
      "Kamil Ciebiera",
      "Krystian Król",
      "Tomasz Odrzygóźdź",
      "Piotr Sankowski",
      "Marek Cygan",
      "Sebastian Jaszczur"
    ],
    "abstract": "Mixture of Experts (MoE) models have emerged as a primary solution for\nreducing the computational cost of Large Language Models. In this work, we\nanalyze their scaling properties, incorporating an expanded range of variables.\nSpecifically, we introduce a new hyperparameter, granularity, whose adjustment\nenables precise control over the size of the experts. Building on this, we\nestablish scaling laws for fine-grained MoE, taking into account the number of\ntraining tokens, model size, and granularity. Leveraging these laws, we derive\nthe optimal training configuration for a given computational budget. Our\nfindings not only show that MoE models consistently outperform dense\nTransformers but also highlight that the efficiency gap between dense and MoE\nmodels widens as we scale up the model size and training budget. Furthermore,\nwe demonstrate that the common practice of setting the size of experts in MoE\nto mirror the feed-forward layer is not optimal at almost any computational\nbudget.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07871v1",
    "published_date": "2024-02-12 18:33:47 UTC",
    "updated_date": "2024-02-12 18:33:47 UTC"
  },
  {
    "arxiv_id": "2402.07865v2",
    "title": "Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models",
    "authors": [
      "Siddharth Karamcheti",
      "Suraj Nair",
      "Ashwin Balakrishna",
      "Percy Liang",
      "Thomas Kollar",
      "Dorsa Sadigh"
    ],
    "abstract": "Visually-conditioned language models (VLMs) have seen growing adoption in\napplications such as visual dialogue, scene understanding, and robotic task\nplanning; adoption that has fueled a wealth of new models such as LLaVa,\nInstructBLIP, and PaLI-3. Despite the volume of new releases, key design\ndecisions around image preprocessing, architecture, and optimization are\nunder-explored, making it challenging to understand what factors account for\nmodel performance $-$ a challenge further complicated by the lack of objective,\nconsistent evaluations. To address these gaps, we first compile a suite of\nstandardized evaluations spanning visual question answering, object\nlocalization, and challenge sets that probe properties such as hallucination;\nevaluations that provide fine-grained insight VLM capabilities. Second, we\nrigorously investigate VLMs along key design axes, including pretrained visual\nrepresentations and training from base vs. instruct-tuned language models,\namongst others. We couple our analysis with three resource contributions: (1) a\nunified framework for evaluating VLMs, (2) optimized, flexible training code,\nand (3) checkpoints for all models, including a family of VLMs at the 7-13B\nscale that strictly outperform InstructBLIP and LLaVa v1.5, the\nstate-of-the-art in open VLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at ICML 2024. 22 pages, 11 figures. Training code and\n  models: https://github.com/TRI-ML/prismatic-vlms. Evaluation code:\n  https://github.com/TRI-ML/vlm-evaluation",
    "pdf_url": "http://arxiv.org/pdf/2402.07865v2",
    "published_date": "2024-02-12 18:21:14 UTC",
    "updated_date": "2024-05-30 13:08:48 UTC"
  },
  {
    "arxiv_id": "2402.07862v2",
    "title": "AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy",
    "authors": [
      "Philipp Schoenegger",
      "Peter S. Park",
      "Ezra Karger",
      "Sean Trott",
      "Philip E. Tetlock"
    ],
    "abstract": "Large language models (LLMs) match and sometimes exceeding human performance\nin many domains. This study explores the potential of LLMs to augment human\njudgement in a forecasting task. We evaluate the effect on human forecasters of\ntwo LLM assistants: one designed to provide high-quality (\"superforecasting\")\nadvice, and the other designed to be overconfident and base-rate neglecting,\nthus providing noisy forecasting advice. We compare participants using these\nassistants to a control group that received a less advanced model that did not\nprovide numerical predictions or engaged in explicit discussion of predictions.\nParticipants (N = 991) answered a set of six forecasting questions and had the\noption to consult their assigned LLM assistant throughout. Our preregistered\nanalyses show that interacting with each of our frontier LLM assistants\nsignificantly enhances prediction accuracy by between 24 percent and 28 percent\ncompared to the control group. Exploratory analyses showed a pronounced outlier\neffect in one forecasting item, without which we find that the superforecasting\nassistant increased accuracy by 41 percent, compared with 29 percent for the\nnoisy assistant. We further examine whether LLM forecasting augmentation\ndisproportionately benefits less skilled forecasters, degrades the\nwisdom-of-the-crowd by reducing prediction diversity, or varies in\neffectiveness with question difficulty. Our data do not consistently support\nthese hypotheses. Our results suggest that access to a frontier LLM assistant,\neven a noisy one, can be a helpful decision aid in cognitively demanding tasks\ncompared to a less powerful model that does not provide specific forecasting\nadvice. However, the effects of outliers suggest that further research into the\nrobustness of this pattern is needed.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "22 pages pages (main text comprised of 19 pages, appendix comprised\n  of three pages). 10 visualizations in the main text (four figures, six\n  tables), three additional figures in the appendix",
    "pdf_url": "http://arxiv.org/pdf/2402.07862v2",
    "published_date": "2024-02-12 18:14:43 UTC",
    "updated_date": "2024-08-22 13:57:30 UTC"
  },
  {
    "arxiv_id": "2402.07860v2",
    "title": "On the Detection of Reviewer-Author Collusion Rings From Paper Bidding",
    "authors": [
      "Steven Jecmen",
      "Nihar B. Shah",
      "Fei Fang",
      "Leman Akoglu"
    ],
    "abstract": "A major threat to the peer-review systems of computer science conferences is\nthe existence of \"collusion rings\" between reviewers. In such collusion rings,\nreviewers who have also submitted their own papers to the conference work\ntogether to manipulate the conference's paper assignment, with the aim of being\nassigned to review each other's papers. The most straightforward way that\ncolluding reviewers can manipulate the paper assignment is by indicating their\ninterest in each other's papers through strategic paper bidding. One potential\napproach to solve this important problem would be to detect the colluding\nreviewers from their manipulated bids, after which the conference can take\nappropriate action. While prior work has developed effective techniques to\ndetect other kinds of fraud, no research has yet established that detecting\ncollusion rings is even possible. In this work, we tackle the question of\nwhether it is feasible to detect collusion rings from the paper bidding. To\nanswer this question, we conduct empirical analysis of two realistic conference\nbidding datasets, including evaluations of existing algorithms for fraud\ndetection in other applications. We find that collusion rings can achieve\nconsiderable success at manipulating the paper assignment while remaining\nhidden from detection: for example, in one dataset, undetected colluders are\nable to achieve assignment to up to 30% of the papers authored by other\ncolluders. In addition, when 10 colluders bid on all of each other's papers, no\ndetection algorithm outputs a group of reviewers with more than 31% overlap\nwith the true colluders. These results suggest that collusion cannot be\neffectively detected from the bidding using popular existing tools,\ndemonstrating the need to develop more complex detection algorithms as well as\nthose that leverage additional metadata (e.g., reviewer-paper text-similarity\nscores).",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07860v2",
    "published_date": "2024-02-12 18:12:09 UTC",
    "updated_date": "2024-03-10 23:46:41 UTC"
  },
  {
    "arxiv_id": "2402.07859v2",
    "title": "Lissard: Long and Simple Sequential Reasoning Datasets",
    "authors": [
      "Mirelle Bueno",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "abstract": "Language models are now capable of solving tasks that require dealing with\nlong sequences consisting of hundreds of thousands of tokens. However, they\noften fail on tasks that require repetitive use of simple rules, even on\nsequences that are much shorter than those seen during training. For example,\nstate-of-the-art LLMs can find common items in two lists with up to 20 items\nbut fail when lists have 80 items. In this paper, we introduce Lissard, a\nbenchmark comprising seven tasks whose goal is to assess the ability of models\nto process and generate wide-range sequence lengths, requiring repetitive\nprocedural execution. Our evaluation of open-source (Mistral-7B and\nMixtral-8x7B) and proprietary models (GPT-3.5 and GPT-4) show a consistent\ndecline in performance across all models as the complexity of the sequence\nincreases. The datasets and code are available at\nhttps://github.com/unicamp-dl/Lissard",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07859v2",
    "published_date": "2024-02-12 18:10:17 UTC",
    "updated_date": "2024-02-20 15:12:13 UTC"
  },
  {
    "arxiv_id": "2402.07845v2",
    "title": "Unsupervised Optimisation of GNNs for Node Clustering",
    "authors": [
      "William Leeney",
      "Ryan McConville"
    ],
    "abstract": "Graph Neural Networks (GNNs) can be trained to detect communities within a\ngraph by learning from the duality of feature and connectivity information.\nCurrently, the common approach for optimisation of GNNs is to use comparisons\nto ground-truth for hyperparameter tuning and model selection. In this work, we\nshow that nodes can be clustered into communities with GNNs by solely\noptimising for modularity, without any comparison to ground-truth. Although\nmodularity is a graph partitioning quality metric, we show that this can be\nused to optimise GNNs that also encode features without a drop in performance.\nWe take it a step further and also study whether the unsupervised metric\nperformance can predict ground-truth performance. To investigate why modularity\ncan be used to optimise GNNs, we design synthetic experiments that show the\nlimitations of this approach. The synthetic graphs are created to highlight\ncurrent capabilities in distinct, random and zero information space partitions\nin attributed graphs. We conclude that modularity can be used for\nhyperparameter optimisation and model selection on real-world datasets as well\nas being a suitable proxy for predicting ground-truth performance, however,\nGNNs fail to balance the information duality when the spaces contain\nconflicting signals.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07845v2",
    "published_date": "2024-02-12 17:53:43 UTC",
    "updated_date": "2024-02-20 18:46:04 UTC"
  },
  {
    "arxiv_id": "2403.12071v1",
    "title": "Tailoring Education with GenAI: A New Horizon in Lesson Planning",
    "authors": [
      "Kostas Karpouzis",
      "Dimitris Pantazatos",
      "Joanna Taouki",
      "Kalliopi Meli"
    ],
    "abstract": "The advent of Generative AI (GenAI) in education presents a transformative\napproach to traditional teaching methodologies, which often overlook the\ndiverse needs of individual students. This study introduces a GenAI tool, based\non advanced natural language processing, designed as a digital assistant for\neducators, enabling the creation of customized lesson plans. The tool utilizes\nan innovative feature termed 'interactive mega-prompt,' a comprehensive query\nsystem that allows educators to input detailed classroom specifics such as\nstudent demographics, learning objectives, and preferred teaching styles. This\ninput is then processed by the GenAI to generate tailored lesson plans. To\nevaluate the tool's effectiveness, a comprehensive methodology incorporating\nboth quantitative (i.e., % of time savings) and qualitative (i.e., user\nsatisfaction) criteria was implemented, spanning various subjects and\neducational levels, with continuous feedback collected from educators through a\nstructured evaluation form. Preliminary results show that educators find the\nGenAI-generated lesson plans effective, significantly reducing lesson planning\ntime and enhancing the learning experience by accommodating diverse student\nneeds. This AI-driven approach signifies a paradigm shift in education,\nsuggesting its potential applicability in broader educational contexts,\nincluding special education needs (SEN), where individualized attention and\nspecific learning aids are paramount",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Abstract accepted for EDUCON 2024 (IEEE Global Engineering Education\n  Conference 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.12071v1",
    "published_date": "2024-02-12 17:30:05 UTC",
    "updated_date": "2024-02-12 17:30:05 UTC"
  },
  {
    "arxiv_id": "2402.07822v1",
    "title": "Understanding fitness landscapes in morpho-evolution via local optima networks",
    "authors": [
      "Sarah L. Thomson",
      "Léni K. Le Goff",
      "Emma Hart",
      "Edgar Buchanan"
    ],
    "abstract": "Morpho-evolution (ME) refers to the simultaneous optimisation of a robot's\ndesign and controller to maximise performance given a task and environment.\nMany genetic encodings have been proposed which are capable of representing\ndesign and control. Previous research has provided empirical comparisons\nbetween encodings in terms of their performance with respect to an objective\nfunction and the diversity of designs that are evaluated, however there has\nbeen no attempt to explain the observed findings. We address this by applying\nLocal Optima Network (LON) analysis to investigate the structure of the fitness\nlandscapes induced by three different encodings when evolving a robot for a\nlocomotion task, shedding new light on the ease by which different fitness\nlandscapes can be traversed by a search process. This is the first time LON\nanalysis has been applied in the field of ME despite its popularity in\ncombinatorial optimisation domains; the findings will facilitate design of new\nalgorithms or operators that are customised to ME landscapes in the future.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to GECCO-2024",
    "pdf_url": "http://arxiv.org/pdf/2402.07822v1",
    "published_date": "2024-02-12 17:26:35 UTC",
    "updated_date": "2024-02-12 17:26:35 UTC"
  },
  {
    "arxiv_id": "2402.07818v6",
    "title": "Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning",
    "authors": [
      "Z Liu",
      "J Lou",
      "W Bao",
      "Y Hu",
      "B Li",
      "Z Qin",
      "K Ren"
    ],
    "abstract": "Fine-tuning on task-specific datasets is a widely-embraced paradigm of\nharnessing the powerful capability of pretrained LLMs for various downstream\ntasks. Due to the popularity of LLMs fine-tuning and its accompanying privacy\nconcerns, differentially private (DP) fine-tuning of pretrained LLMs has been\nwidely used to safeguarding the privacy of task-specific datasets. Lying at the\ndesign core of DP LLM fine-tuning methods is the satisfactory tradeoff among\nprivacy, utility, and scalability. Most existing methods build upon the seminal\nwork of DP-SGD. Despite pushing the scalability of DP-SGD to its limit,\nDP-SGD-based fine-tuning methods are unfortunately limited by the inherent\ninefficiency of SGD.\n  In this paper, we investigate the potential of DP zeroth-order methods for\nLLM pretraining, which avoids the scalability bottleneck of SGD by\napproximating the gradient with the more efficient zeroth-order gradient.\nRather than treating the zeroth-order method as a drop-in replacement for SGD,\nthis paper presents a comprehensive study both theoretically and empirically.\nFirst, we propose the stagewise DP zeroth-order method (DP-ZOSO) that\ndynamically schedules key hyperparameters. This design is grounded on the\nsynergy between DP random perturbation and the gradient approximation error of\nthe zeroth-order method, and its effect on fine-tuning trajectory.\n  We provide theoretical analysis for both proposed methods. We conduct\nextensive empirical analysis on both encoder-only masked language model and\ndecoder-only autoregressive language model, achieving impressive results in\nterms of scalability and utility regardless of the class of tasks (compared\nwith DPZero, DP-ZOPO improves $4.5\\%$ on SST-5, $5.5\\%$ on MNLI with\nRoBERTa-Large and 9.2\\% on CB, 3.9\\% on BoolQ with OPT-2.7b when $\\epsilon=4$,\ndemonstrates more significant enhancement in performance on more complicated\ntasks).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07818v6",
    "published_date": "2024-02-12 17:24:15 UTC",
    "updated_date": "2025-03-10 06:52:03 UTC"
  },
  {
    "arxiv_id": "2402.07814v1",
    "title": "PBADet: A One-Stage Anchor-Free Approach for Part-Body Association",
    "authors": [
      "Zhongpai Gao",
      "Huayi Zhou",
      "Abhishek Sharma",
      "Meng Zheng",
      "Benjamin Planche",
      "Terrence Chen",
      "Ziyan Wu"
    ],
    "abstract": "The detection of human parts (e.g., hands, face) and their correct\nassociation with individuals is an essential task, e.g., for ubiquitous\nhuman-machine interfaces and action recognition. Traditional methods often\nemploy multi-stage processes, rely on cumbersome anchor-based systems, or do\nnot scale well to larger part sets. This paper presents PBADet, a novel\none-stage, anchor-free approach for part-body association detection. Building\nupon the anchor-free object representation across multi-scale feature maps, we\nintroduce a singular part-to-body center offset that effectively encapsulates\nthe relationship between parts and their parent bodies. Our design is\ninherently versatile and capable of managing multiple parts-to-body\nassociations without compromising on detection accuracy or robustness.\nComprehensive experiments on various datasets underscore the efficacy of our\napproach, which not only outperforms existing state-of-the-art techniques but\nalso offers a more streamlined and efficient solution to the part-body\nassociation challenge.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR2024",
    "pdf_url": "http://arxiv.org/pdf/2402.07814v1",
    "published_date": "2024-02-12 17:18:51 UTC",
    "updated_date": "2024-02-12 17:18:51 UTC"
  },
  {
    "arxiv_id": "2402.07812v2",
    "title": "Retrieval Augmented Thought Process for Private Data Handling in Healthcare",
    "authors": [
      "Thomas Pouplin",
      "Hao Sun",
      "Samuel Holt",
      "Mihaela van der Schaar"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated the strong potential to assist\nboth clinicians and the general public with their extensive medical knowledge.\nHowever, their application in healthcare is constrained due to concerns about\nthe privacy of data used in training, which prevents the integration of private\nand personal information because of security and ethical issues. Moreover, if\ntheir capabilities can be enhanced with information retrieval to access\nup-to-date knowledge, the current integration of LLMs with Information\nretrieval lacks robustness to imperfect retrieval, which can hinder their\neffectiveness and even reduce overall performance. In this work, we address\nthis challenge by introducing the Retrieval-Augmented Thought Process (RATP).\nGiven access to external knowledge, RATP formulates the thought generation of\nLLMs as a multiple-step decision process. To optimise such a thought process,\nRATP leverages Monte-Carlo Tree Search and learns a proxy reward function that\npermits cost-efficient inference. On a private dataset of electronic medical\nrecords, deliberately excluded from any LLM training set, RATP achieves 35%\nadditional accuracy compared to in-context retrieval-augmented generation for\nthe question-answering task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "H.3.3; I.2.6; I.2.7; I.2.8"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07812v2",
    "published_date": "2024-02-12 17:17:50 UTC",
    "updated_date": "2024-08-07 18:27:59 UTC"
  },
  {
    "arxiv_id": "2402.07799v2",
    "title": "Generalising Planning Environment Redesign",
    "authors": [
      "Alberto Pozanco",
      "Ramon Fraga Pereira",
      "Daniel Borrajo"
    ],
    "abstract": "In Environment Design, one interested party seeks to affect another agent's\ndecisions by applying changes to the environment. Most research on planning\nenvironment (re)design assumes the interested party's objective is to\nfacilitate the recognition of goals and plans, and search over the space of\nenvironment modifications to find the minimal set of changes that simplify\nthose tasks and optimise a particular metric. This search space is usually\nintractable, so existing approaches devise metric-dependent pruning techniques\nfor performing search more efficiently. This results in approaches that are not\nable to generalise across different objectives and/or metrics. In this paper,\nwe argue that the interested party could have objectives and metrics that are\nnot necessarily related to recognising agents' goals or plans. Thus, to\ngeneralise the task of Planning Environment Redesign, we develop a general\nenvironment redesign approach that is metric-agnostic and leverages recent\nresearch on top-quality planning to efficiently redesign planning environments\naccording to any interested party's objective and metric. Experiments over a\nset of environment redesign benchmarks show that our general approach\noutperforms existing approaches when using well-known metrics, such as\nfacilitating the recognition of goals, as well as its effectiveness when\nsolving environment redesign tasks that optimise a novel set of different\nmetrics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper accepted at AAAI'24",
    "pdf_url": "http://arxiv.org/pdf/2402.07799v2",
    "published_date": "2024-02-12 17:03:58 UTC",
    "updated_date": "2024-02-14 14:01:55 UTC"
  },
  {
    "arxiv_id": "2402.07787v3",
    "title": "Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis",
    "authors": [
      "Xiaowei Zhao",
      "Yong Zhou",
      "Xiujuan Xu",
      "Yu Liu"
    ],
    "abstract": "Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within\na text to comprehend sentiment information. Previous studies integrated\nexternal knowledge, such as knowledge graphs, to enhance the semantic features\nin ABSA models. Recent research has examined the use of Graph Neural Networks\n(GNNs) on dependency and constituent trees for syntactic analysis. With the\nongoing development of ABSA, more innovative linguistic and structural features\nare being incorporated (e.g. latent graph), but this also introduces complexity\nand confusion. As of now, a scalable framework for integrating diverse\nlinguistic and structural features into ABSA does not exist. This paper\npresents the Extensible Multi-Granularity Fusion (EMGF) network, which\nintegrates information from dependency and constituent syntactic, attention\nsemantic , and external knowledge graphs. EMGF, equipped with multi-anchor\ntriplet learning and orthogonal projection, efficiently harnesses the combined\npotential of each granularity feature and their synergistic interactions,\nresulting in a cumulative effect without additional computational expenses.\nExperimental findings on SemEval 2014 and Twitter datasets confirm EMGF's\nsuperiority over existing ABSA methods.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07787v3",
    "published_date": "2024-02-12 16:52:26 UTC",
    "updated_date": "2024-03-04 08:42:32 UTC"
  },
  {
    "arxiv_id": "2402.07772v1",
    "title": "End-to-End Learning for Fair Multiobjective Optimization Under Uncertainty",
    "authors": [
      "My H Dinh",
      "James Kotary",
      "Ferdinando Fioretto"
    ],
    "abstract": "Many decision processes in artificial intelligence and operations research\nare modeled by parametric optimization problems whose defining parameters are\nunknown and must be inferred from observable data. The Predict-Then-Optimize\n(PtO) paradigm in machine learning aims to maximize downstream decision quality\nby training the parametric inference model end-to-end with the subsequent\nconstrained optimization. This requires backpropagation through the\noptimization problem using approximation techniques specific to the problem's\nform, especially for nondifferentiable linear and mixed-integer programs. This\npaper extends the PtO methodology to optimization problems with\nnondifferentiable Ordered Weighted Averaging (OWA) objectives, known for their\nability to ensure properties of fairness and robustness in decision models.\nThrough a collection of training techniques and proposed application settings,\nit shows how optimization of OWA functions can be effectively integrated with\nparametric prediction for fair and robust optimization under uncertainty.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07772v1",
    "published_date": "2024-02-12 16:33:35 UTC",
    "updated_date": "2024-02-12 16:33:35 UTC"
  },
  {
    "arxiv_id": "2402.07757v1",
    "title": "Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model",
    "authors": [
      "Mikail Khona",
      "Maya Okawa",
      "Jan Hula",
      "Rahul Ramesh",
      "Kento Nishi",
      "Robert Dick",
      "Ekdeep Singh Lubana",
      "Hidenori Tanaka"
    ],
    "abstract": "Stepwise inference protocols, such as scratchpads and chain-of-thought, help\nlanguage models solve complex problems by decomposing them into a sequence of\nsimpler subproblems. Despite the significant gain in performance achieved via\nthese protocols, the underlying mechanisms of stepwise inference have remained\nelusive. To address this, we propose to study autoregressive Transformer models\non a synthetic task that embodies the multi-step nature of problems where\nstepwise inference is generally most useful. Specifically, we define a graph\nnavigation problem wherein a model is tasked with traversing a path from a\nstart to a goal node on the graph. Despite is simplicity, we find we can\nempirically reproduce and analyze several phenomena observed at scale: (i) the\nstepwise inference reasoning gap, the cause of which we find in the structure\nof the training data; (ii) a diversity-accuracy tradeoff in model generations\nas sampling temperature varies; (iii) a simplicity bias in the model's output;\nand (iv) compositional generalization and a primacy bias with in-context\nexemplars. Overall, our work introduces a grounded, synthetic framework for\nstudying stepwise inference and offers mechanistic hypotheses that can lay the\nfoundation for a deeper understanding of this phenomenon.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07757v1",
    "published_date": "2024-02-12 16:25:47 UTC",
    "updated_date": "2024-02-12 16:25:47 UTC"
  },
  {
    "arxiv_id": "2402.07754v3",
    "title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
    "authors": [
      "Jiacheng Ye",
      "Shansan Gong",
      "Liheng Chen",
      "Lin Zheng",
      "Jiahui Gao",
      "Han Shi",
      "Chuan Wu",
      "Xin Jiang",
      "Zhenguo Li",
      "Wei Bi",
      "Lingpeng Kong"
    ],
    "abstract": "Recently, diffusion models have garnered significant interest in the field of\ntext processing due to their many potential advantages compared to conventional\nautoregressive models. In this work, we propose Diffusion-of-Thought (DoT), a\nnovel approach that integrates diffusion models with Chain-of-Thought, a\nwell-established technique for improving the reasoning ability of\nautoregressive language models. In contrast to autoregressive language models\nthat make decisions in a left-to-right, token-by-token manner, DoT allows\nreasoning steps to diffuse over time through a diffusion language model and\noffers greater flexibility in trading-off computation for reasoning\nperformance. Our experimental results demonstrate the effectiveness of DoT in\nmulti-digit multiplication, boolean logic, and grade school math problems, with\na small diffusion model outperforming a much larger autoregressive model in\nboth efficiency and accuracy. In addition to that, DoT showcases promising\nself-correction abilities and benefits from existing reasoning-enhancing\ntechniques like self-consistency decoding. Our findings contribute to the\nunderstanding and development of reasoning with diffusion language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.07754v3",
    "published_date": "2024-02-12 16:23:28 UTC",
    "updated_date": "2024-12-05 06:49:06 UTC"
  },
  {
    "arxiv_id": "2402.07744v2",
    "title": "Towards Unified Alignment Between Agents, Humans, and Environment",
    "authors": [
      "Zonghan Yang",
      "An Liu",
      "Zijun Liu",
      "Kaiming Liu",
      "Fangzhou Xiong",
      "Yile Wang",
      "Zeyuan Yang",
      "Qingyuan Hu",
      "Xinrui Chen",
      "Zhenhe Zhang",
      "Fuwen Luo",
      "Zhicheng Guo",
      "Peng Li",
      "Yang Liu"
    ],
    "abstract": "The rapid progress of foundation models has led to the prosperity of\nautonomous agents, which leverage the universal capabilities of foundation\nmodels to conduct reasoning, decision-making, and environmental interaction.\nHowever, the efficacy of agents remains limited when operating in intricate,\nrealistic environments. In this work, we introduce the principles of\n$\\mathbf{U}$nified $\\mathbf{A}$lignment for $\\mathbf{A}$gents\n($\\mathbf{UA}^2$), which advocate for the simultaneous alignment of agents with\nhuman intentions, environmental dynamics, and self-constraints such as the\nlimitation of monetary budgets. From the perspective of $\\mathbf{UA}^2$, we\nreview the current agent research and highlight the neglected factors in\nexisting agent benchmarks and method candidates. We also conduct\nproof-of-concept studies by introducing realistic features to WebShop,\nincluding user profiles to demonstrate intentions, personalized reranking for\ncomplex environmental dynamics, and runtime cost statistics to reflect\nself-constraints. We then follow the principles of $\\mathbf{UA}^2$ to propose\nan initial design of our agent, and benchmark its performance with several\ncandidate baselines in the retrofitted WebShop. The extensive experimental\nresults further prove the importance of the principles of $\\mathbf{UA}^2$. Our\nresearch sheds light on the next steps of autonomous agent research with\nimproved general problem-solving abilities.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Project webpage:\n  https://agent-force.github.io/unified-alignment-for-agents.html",
    "pdf_url": "http://arxiv.org/pdf/2402.07744v2",
    "published_date": "2024-02-12 16:14:22 UTC",
    "updated_date": "2024-02-14 18:43:54 UTC"
  },
  {
    "arxiv_id": "2402.07712v2",
    "title": "Model Collapse Demystified: The Case of Regression",
    "authors": [
      "Elvis Dohmatob",
      "Yunzhen Feng",
      "Julia Kempe"
    ],
    "abstract": "In the era of proliferation of large language and image generation models,\nthe phenomenon of \"model collapse\" refers to the situation whereby as a model\nis trained recursively on data generated from previous generations of itself\nover time, its performance degrades until the model eventually becomes\ncompletely useless, i.e the model collapses. In this work, we study this\nphenomenon in the setting of high-dimensional regression and obtain analytic\nformulae which quantitatively outline this phenomenon in a broad range of\nregimes. In the special case of polynomial decaying spectral and source\nconditions, we obtain modified scaling laws which exhibit new crossover\nphenomena from fast to slow rates. We also propose a simple strategy based on\nadaptive regularization to mitigate model collapse. Our theoretical results are\nvalidated with experiments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07712v2",
    "published_date": "2024-02-12 15:26:01 UTC",
    "updated_date": "2024-04-30 18:03:13 UTC"
  },
  {
    "arxiv_id": "2402.07703v3",
    "title": "Online Sequential Decision-Making with Unknown Delays",
    "authors": [
      "Ping Wu",
      "Heyan Huang",
      "Zhengyang Liu"
    ],
    "abstract": "In the field of online sequential decision-making, we address the problem\nwith delays utilizing the framework of online convex optimization (OCO), where\nthe feedback of a decision can arrive with an unknown delay. Unlike previous\nresearch that is limited to Euclidean norm and gradient information, we propose\nthree families of delayed algorithms based on approximate solutions to handle\ndifferent types of received feedback. Our proposed algorithms are versatile and\napplicable to universal norms. Specifically, we introduce a family of Follow\nthe Delayed Regularized Leader algorithms for feedback with full information on\nthe loss function, a family of Delayed Mirror Descent algorithms for feedback\nwith gradient information on the loss function and a family of Simplified\nDelayed Mirror Descent algorithms for feedback with the value information of\nthe loss function's gradients at corresponding decision points. For each type\nof algorithm, we provide corresponding regret bounds under cases of general\nconvexity and relative strong convexity, respectively. We also demonstrate the\nefficiency of each algorithm under different norms through concrete examples.\nFurthermore, our theoretical results are consistent with the current best\nbounds when degenerated to standard settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07703v3",
    "published_date": "2024-02-12 15:17:31 UTC",
    "updated_date": "2024-02-23 06:05:19 UTC"
  },
  {
    "arxiv_id": "2402.07689v2",
    "title": "OrderBkd: Textual backdoor attack through repositioning",
    "authors": [
      "Irina Alekseevskaia",
      "Konstantin Arkhipenko"
    ],
    "abstract": "The use of third-party datasets and pre-trained machine learning models poses\na threat to NLP systems due to possibility of hidden backdoor attacks. Existing\nattacks involve poisoning the data samples such as insertion of tokens or\nsentence paraphrasing, which either alter the semantics of the original texts\nor can be detected. Our main difference from the previous work is that we use\nthe reposition of a two words in a sentence as a trigger. By designing and\napplying specific part-of-speech (POS) based rules for selecting these tokens,\nwe maintain high attack success rate on SST-2 and AG classification datasets\nwhile outperforming existing attacks in terms of perplexity and semantic\nsimilarity to the clean samples. In addition, we show the robustness of our\nattack to the ONION defense method. All the code and data for the paper can be\nobtained at https://github.com/alekseevskaia/OrderBkd.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07689v2",
    "published_date": "2024-02-12 14:53:37 UTC",
    "updated_date": "2024-04-06 21:41:10 UTC"
  },
  {
    "arxiv_id": "2402.07688v2",
    "title": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
    "authors": [
      "Norbert Tihanyi",
      "Mohamed Amine Ferrag",
      "Ridhi Jain",
      "Tamas Bisztray",
      "Merouane Debbah"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used across various domains,\nfrom software development to cyber threat intelligence. Understanding all the\ndifferent fields of cybersecurity, which includes topics such as cryptography,\nreverse engineering, and risk assessment, poses a challenge even for human\nexperts. To accurately test the general knowledge of LLMs in cybersecurity, the\nresearch community needs a diverse, accurate, and up-to-date dataset. To\naddress this gap, we present CyberMetric-80, CyberMetric-500, CyberMetric-2000,\nand CyberMetric-10000, which are multiple-choice Q&A benchmark datasets\ncomprising 80, 500, 2000, and 10,000 questions respectively. By utilizing\nGPT-3.5 and Retrieval-Augmented Generation (RAG), we collected documents,\nincluding NIST standards, research papers, publicly accessible books, RFCs, and\nother publications in the cybersecurity domain, to generate questions, each\nwith four possible answers. The results underwent several rounds of error\nchecking and refinement. Human experts invested over 200 hours validating the\nquestions and solutions to ensure their accuracy and relevance, and to filter\nout any questions unrelated to cybersecurity. We have evaluated and compared 25\nstate-of-the-art LLM models on the CyberMetric datasets. In addition to our\nprimary goal of evaluating LLMs, we involved 30 human participants to solve\nCyberMetric-80 in a closed-book scenario. The results can serve as a reference\nfor comparing the general cybersecurity knowledge of humans and LLMs. The\nfindings revealed that GPT-4o, GPT-4-turbo, Mixtral-8x7B-Instruct,\nFalcon-180B-Chat, and GEMINI-pro 1.0 were the best-performing LLMs.\nAdditionally, the top LLMs were more accurate than humans on CyberMetric-80,\nalthough highly experienced human experts still outperformed small models such\nas Llama-3-8B, Phi-2 or Gemma-7b.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07688v2",
    "published_date": "2024-02-12 14:53:28 UTC",
    "updated_date": "2024-06-03 08:14:45 UTC"
  },
  {
    "arxiv_id": "2402.07681v1",
    "title": "Large Language Models \"Ad Referendum\": How Good Are They at Machine Translation in the Legal Domain?",
    "authors": [
      "Vicent Briva-Iglesias",
      "Joao Lucas Cavalheiro Camargo",
      "Gokhan Dogru"
    ],
    "abstract": "This study evaluates the machine translation (MT) quality of two\nstate-of-the-art large language models (LLMs) against a tradition-al neural\nmachine translation (NMT) system across four language pairs in the legal\ndomain. It combines automatic evaluation met-rics (AEMs) and human evaluation\n(HE) by professional transla-tors to assess translation ranking, fluency and\nadequacy. The re-sults indicate that while Google Translate generally\noutperforms LLMs in AEMs, human evaluators rate LLMs, especially GPT-4,\ncomparably or slightly better in terms of producing contextually adequate and\nfluent translations. This discrepancy suggests LLMs' potential in handling\nspecialized legal terminology and context, highlighting the importance of human\nevaluation methods in assessing MT quality. The study underscores the evolving\ncapabil-ities of LLMs in specialized domains and calls for reevaluation of\ntraditional AEMs to better capture the nuances of LLM-generated translations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07681v1",
    "published_date": "2024-02-12 14:40:54 UTC",
    "updated_date": "2024-02-12 14:40:54 UTC"
  },
  {
    "arxiv_id": "2402.07680v1",
    "title": "AYDIV: Adaptable Yielding 3D Object Detection via Integrated Contextual Vision Transformer",
    "authors": [
      "Tanmoy Dam",
      "Sanjay Bhargav Dharavath",
      "Sameer Alam",
      "Nimrod Lilith",
      "Supriyo Chakraborty",
      "Mir Feroskhan"
    ],
    "abstract": "Combining LiDAR and camera data has shown potential in enhancing\nshort-distance object detection in autonomous driving systems. Yet, the fusion\nencounters difficulties with extended distance detection due to the contrast\nbetween LiDAR's sparse data and the dense resolution of cameras. Besides,\ndiscrepancies in the two data representations further complicate fusion\nmethods. We introduce AYDIV, a novel framework integrating a tri-phase\nalignment process specifically designed to enhance long-distance detection even\namidst data discrepancies. AYDIV consists of the Global Contextual Fusion\nAlignment Transformer (GCFAT), which improves the extraction of camera features\nand provides a deeper understanding of large-scale patterns; the Sparse Fused\nFeature Attention (SFFA), which fine-tunes the fusion of LiDAR and camera\ndetails; and the Volumetric Grid Attention (VGA) for a comprehensive spatial\ndata fusion. AYDIV's performance on the Waymo Open Dataset (WOD) with an\nimprovement of 1.24% in mAPH value(L2 difficulty) and the Argoverse2 Dataset\nwith a performance improvement of 7.40% in AP value demonstrates its efficacy\nin comparison to other existing fusion-based methods. Our code is publicly\navailable at https://github.com/sanjay-810/AYDIV2",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted for ICRA 2024, and copyright will\n  automatically transfer to IEEE upon its availability on the IEEE portal",
    "pdf_url": "http://arxiv.org/pdf/2402.07680v1",
    "published_date": "2024-02-12 14:40:43 UTC",
    "updated_date": "2024-02-12 14:40:43 UTC"
  },
  {
    "arxiv_id": "2402.07640v3",
    "title": "Synthesizing Sentiment-Controlled Feedback For Multimodal Text and Image Data",
    "authors": [
      "Puneet Kumar",
      "Sarthak Malik",
      "Balasubramanian Raman",
      "Xiaobai Li"
    ],
    "abstract": "The ability to generate sentiment-controlled feedback in response to\nmultimodal inputs comprising text and images addresses a critical gap in\nhuman-computer interaction. This capability allows systems to provide\nempathetic, accurate, and engaging responses, with useful applications in\neducation, healthcare, marketing, and customer service. To this end, we have\nconstructed a large-scale Controllable Multimodal Feedback Synthesis (CMFeed)\ndataset and propose a controllable feedback synthesis system. The system\nfeatures an encoder, decoder, and controllability block for textual and visual\ninputs. It extracts features using a transformer and Faster R-CNN networks,\ncombining them to generate feedback. The CMFeed dataset includes images, texts,\nreactions to the posts, human comments with relevance scores, and reactions to\nthese comments. These reactions train the model to produce feedback with\nspecified sentiments, achieving a sentiment classification accuracy of 77.23\\%,\nwhich is 18.82\\% higher than the accuracy without controllability. The system\nalso incorporates a similarity module for assessing feedback relevance through\nrank-based metrics and an interpretability technique to analyze the\ncontributions of textual and visual features during feedback generation. Access\nto the CMFeed dataset and the system's code is available at\nhttps://github.com/MIntelligence-Group/CMFeed.",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07640v3",
    "published_date": "2024-02-12 13:27:22 UTC",
    "updated_date": "2024-10-18 02:50:53 UTC"
  },
  {
    "arxiv_id": "2402.07639v1",
    "title": "Tighter Bounds on the Information Bottleneck with Application to Deep Learning",
    "authors": [
      "Nir Weingarten",
      "Zohar Yakhini",
      "Moshe Butman",
      "Ran Gilad-Bachrach"
    ],
    "abstract": "Deep Neural Nets (DNNs) learn latent representations induced by their\ndownstream task, objective function, and other parameters. The quality of the\nlearned representations impacts the DNN's generalization ability and the\ncoherence of the emerging latent space. The Information Bottleneck (IB)\nprovides a hypothetically optimal framework for data modeling, yet it is often\nintractable. Recent efforts combined DNNs with the IB by applying VAE-inspired\nvariational methods to approximate bounds on mutual information, resulting in\nimproved robustness to adversarial attacks. This work introduces a new and\ntighter variational bound for the IB, improving performance of previous\nIB-inspired DNNs. These advancements strengthen the case for the IB and its\nvariational approximations as a data modeling framework, and provide a simple\nmethod to significantly enhance the adversarial robustness of classifier DNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "94A08, 94A10, 94A11, 68T06, 62B04, 62B08",
      "I.2; E.4; I.4; I.7"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 5 figures, code included in github repo",
    "pdf_url": "http://arxiv.org/pdf/2402.07639v1",
    "published_date": "2024-02-12 13:24:32 UTC",
    "updated_date": "2024-02-12 13:24:32 UTC"
  },
  {
    "arxiv_id": "2402.07632v3",
    "title": "Overconfident and Unconfident AI Hinder Human-AI Collaboration",
    "authors": [
      "Jingshu Li",
      "Yitian Yang",
      "Renwen Zhang",
      "Yi-chieh Lee"
    ],
    "abstract": "AI transparency is a central pillar of responsible AI deployment and\neffective human-AI collaboration. A critical approach is communicating\nuncertainty, such as displaying AI's confidence level, or its correctness\nlikelihood (CL), to users. However, these confidence levels are often\nuncalibrated, either overestimating or underestimating actual CL, posing risks\nand harms to human-AI collaboration. This study examines the effects of\nuncalibrated AI confidence on users' trust in AI, AI advice adoption, and\ncollaboration outcomes. We further examined the impact of increased\ntransparency, achieved through trust calibration support, on these outcomes.\nOur results reveal that uncalibrated AI confidence leads to both the misuse of\noverconfident AI and disuse of unconfident AI, thereby hindering outcomes of\nhuman-AI collaboration. Deficiency of trust calibration support exacerbates\nthis issue by making it harder to detect uncalibrated confidence, promoting\nmisuse and disuse of AI. Conversely, trust calibration support aids in\nrecognizing uncalibration and reducing misuse, but it also fosters distrust and\ncauses disuse of AI. Our findings highlight the importance of AI confidence\ncalibration for enhancing human-AI collaboration and suggest directions for AI\ndesign and regulation.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07632v3",
    "published_date": "2024-02-12 13:16:30 UTC",
    "updated_date": "2024-04-17 18:37:12 UTC"
  },
  {
    "arxiv_id": "2402.07625v5",
    "title": "Autonomous Data Selection with Zero-shot Generative Classifiers for Mathematical Texts",
    "authors": [
      "Yifan Zhang",
      "Yifan Luo",
      "Yang Yuan",
      "Andrew Chi-Chih Yao"
    ],
    "abstract": "We present Autonomous Data Selection (AutoDS), a method that leverages base\nlanguage models themselves as zero-shot \"generative classifiers\" to\nautomatically curate high-quality mathematical texts. Unlike prior approaches\nthat require human annotations or training a dedicated data filter, AutoDS\nrelies solely on a model's logits to determine whether a given passage is\nmathematically informative and educational. By integrating AutoDS into a\ncontinual pretraining pipeline, we substantially boost downstream performance\non challenging math benchmarks (MATH, GSM8K, and BBH) while using far fewer\ntokens than previous methods. Empirically, our approach achieves roughly a\ntwofold improvement in pretraining token efficiency over strong baselines,\nunderscoring the potential of self-directed data selection in enhancing\nmathematical reasoning. We release our curated AutoMathText dataset to\nfacilitate future research in automated domain-specific data curation. The\nAutoMathText dataset is available at\nhttps://huggingface.co/datasets/math-ai/AutoMathText. The code is available at\nhttps://github.com/yifanzhang-pro/AutoMathText.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:0808.2664, arXiv:0806.2159, arXiv:1703.08834, arXiv:math/0610707 by\n  other authors",
    "pdf_url": "http://arxiv.org/pdf/2402.07625v5",
    "published_date": "2024-02-12 13:09:21 UTC",
    "updated_date": "2025-03-23 02:11:03 UTC"
  },
  {
    "arxiv_id": "2402.07619v1",
    "title": "Developing a Multi-variate Prediction Model For COVID-19 From Crowd-sourced Respiratory Voice Data",
    "authors": [
      "Yuyang Yan",
      "Wafaa Aljbawi",
      "Sami O. Simons",
      "Visara Urovi"
    ],
    "abstract": "COVID-19 has affected more than 223 countries worldwide and in the Post-COVID\nEra, there is a pressing need for non-invasive, low-cost, and highly scalable\nsolutions to detect COVID-19. We develop a deep learning model to identify\nCOVID-19 from voice recording data. The novelty of this work is in the\ndevelopment of deep learning models for COVID-19 identification from only voice\nrecordings. We use the Cambridge COVID-19 Sound database which contains 893\nspeech samples, crowd-sourced from 4352 participants via a COVID-19 Sounds app.\nVoice features including Mel-spectrograms and Mel-frequency cepstral\ncoefficients (MFCC) and CNN Encoder features are extracted. Based on the voice\ndata, we develop deep learning classification models to detect COVID-19 cases.\nThese models include Long Short-Term Memory (LSTM) and Convolutional Neural\nNetwork (CNN) and Hidden-Unit BERT (HuBERT). We compare their predictive power\nto baseline machine learning models. HuBERT achieves the highest accuracy of\n86\\% and the highest AUC of 0.93. The results achieved with the proposed models\nsuggest promising results in COVID-19 diagnosis from voice recordings when\ncompared to the results obtained from the state-of-the-art.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "arXiv admin note: text overlap with arXiv:2209.03727",
    "pdf_url": "http://arxiv.org/pdf/2402.07619v1",
    "published_date": "2024-02-12 12:52:47 UTC",
    "updated_date": "2024-02-12 12:52:47 UTC"
  },
  {
    "arxiv_id": "2402.07616v3",
    "title": "Anchor-based Large Language Models",
    "authors": [
      "Jianhui Pang",
      "Fanghua Ye",
      "Derek Fai Wong",
      "Xin He",
      "Wanshun Chen",
      "Longyue Wang"
    ],
    "abstract": "Large language models (LLMs) predominantly employ decoder-only transformer\narchitectures, necessitating the retention of keys/values information for\nhistorical tokens to provide contextual information and avoid redundant\ncomputation. However, the substantial size and parameter volume of these LLMs\nrequire massive GPU memory. This memory demand increases with the length of the\ninput text, leading to an urgent need for more efficient methods of information\nstorage and processing. This study introduces Anchor-based LLMs (AnLLMs), which\nutilize an innovative anchor-based self-attention network (AnSAN) and also an\nanchor-based inference strategy. This approach enables LLMs to compress\nsequence information into an anchor token, reducing the keys/values cache and\nenhancing inference efficiency. Experiments on question-answering benchmarks\nreveal that AnLLMs maintain similar accuracy levels while achieving up to 99%\nkeys/values cache reduction and up to 3.5 times faster inference. Despite a\nminor compromise in accuracy, the substantial enhancements of AnLLMs employing\nthe AnSAN technique in resource utilization and computational efficiency\nunderscore their potential for practical LLM applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The paper has been accepted by the ACL2024 conference. Work was done\n  when Jianhui Pang and Fanghua Ye were interning at Tencent AI Lab",
    "pdf_url": "http://arxiv.org/pdf/2402.07616v3",
    "published_date": "2024-02-12 12:48:02 UTC",
    "updated_date": "2024-06-01 04:52:17 UTC"
  },
  {
    "arxiv_id": "2402.07610v3",
    "title": "Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping",
    "authors": [
      "Haoyu Wang",
      "Guozheng Ma",
      "Ziqiao Meng",
      "Zeyu Qin",
      "Li Shen",
      "Zhong Zhang",
      "Bingzhe Wu",
      "Liu Liu",
      "Yatao Bian",
      "Tingyang Xu",
      "Xueqian Wang",
      "Peilin Zhao"
    ],
    "abstract": "Self-alignment is an effective way to reduce the cost of human annotation\nwhile ensuring promising model capability. However, most current methods\ncomplete the data collection and training steps in a single round, which may\noverlook the continuously improving ability of self-aligned models. This gives\nrise to a key query: What if we do multi-time bootstrapping self-alignment?\nDoes this strategy enhance model performance or lead to rapid degradation? In\nthis paper, our pioneering exploration delves into the impact of bootstrapping\nself-alignment on large language models. Our findings reveal that bootstrapping\nself-alignment markedly surpasses the single-round approach, by guaranteeing\ndata diversity from in-context learning. To further exploit the capabilities of\nbootstrapping, we investigate and adjust the training order of data, which\nyields improved performance of the model. Drawing on these findings, we propose\nStep-On-Feet Tuning (SOFT) which leverages model's continuously enhanced\nfew-shot ability to boost zero or one-shot performance. Based on easy-to-hard\ntraining recipe, we propose SOFT+ which further boost self-alignment's\nperformance. Our experiments demonstrate the efficiency of SOFT (SOFT+) across\nvarious classification and generation tasks, highlighting the potential of\nbootstrapping self-alignment on continually enhancing model alignment\nperformance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07610v3",
    "published_date": "2024-02-12 12:30:42 UTC",
    "updated_date": "2024-06-27 16:38:35 UTC"
  },
  {
    "arxiv_id": "2402.07570v2",
    "title": "Only the Curve Shape Matters: Training Foundation Models for Zero-Shot Multivariate Time Series Forecasting through Next Curve Shape Prediction",
    "authors": [
      "Cheng Feng",
      "Long Huang",
      "Denis Krompass"
    ],
    "abstract": "We present General Time Transformer (GTT), an encoder-only style foundation\nmodel for zero-shot multivariate time series forecasting. GTT is pretrained on\na large dataset of 200M high-quality time series samples spanning diverse\ndomains. In our proposed framework, the task of multivariate time series\nforecasting is formulated as a channel-wise next curve shape prediction\nproblem, where each time series sample is represented as a sequence of\nnon-overlapping curve shapes with a unified numerical magnitude. GTT is trained\nto predict the next curve shape based on a window of past curve shapes in a\nchannel-wise manner. Experimental results demonstrate that GTT exhibits\nsuperior zero-shot multivariate forecasting capabilities on unseen time series\ndatasets, even surpassing state-of-the-art supervised baselines. Additionally,\nwe investigate the impact of varying GTT model parameters and training dataset\nscales, observing that the scaling law also holds in the context of zero-shot\nmultivariate time series forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07570v2",
    "published_date": "2024-02-12 11:04:14 UTC",
    "updated_date": "2024-02-19 03:21:01 UTC"
  },
  {
    "arxiv_id": "2402.09474v2",
    "title": "Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals",
    "authors": [
      "Aruna Mohan",
      "Danne Elbers",
      "Or Zilbershot",
      "Fatemeh Afghah",
      "David Vorchheimer"
    ],
    "abstract": "Remote patient monitoring based on wearable single-lead electrocardiogram\n(ECG) devices has significant potential for enabling the early detection of\nheart disease, especially in combination with artificial intelligence (AI)\napproaches for automated heart disease detection. There have been prior studies\napplying AI approaches based on deep learning for heart disease detection.\nHowever, these models are yet to be widely accepted as a reliable aid for\nclinical diagnostics, in part due to the current black-box perception\nsurrounding many AI algorithms. In particular, there is a need to identify the\nkey features of the ECG signal that contribute toward making an accurate\ndiagnosis, thereby enhancing the interpretability of the model. In the present\nstudy, we develop a vision transformer approach to identify atrial fibrillation\nbased on single-lead ECG data. A residual network (ResNet) approach is also\ndeveloped for comparison with the vision transformer approach. These models are\napplied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as\nwell as another common arrhythmia, sinus bradycardia, and normal sinus rhythm\nheartbeats. The models enable the identification of the key regions of the\nheartbeat that determine the resulting classification, and highlight the\nimportance of P-waves and T-waves, as well as heartbeat duration and signal\namplitude, in distinguishing normal sinus rhythm from atrial fibrillation and\nsinus bradycardia.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted for publication at the 46th Annual International Conference\n  of the IEEE Engineering in Medicine and Biology Society, IEEE EMBC 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.09474v2",
    "published_date": "2024-02-12 11:04:08 UTC",
    "updated_date": "2024-04-28 20:05:45 UTC"
  },
  {
    "arxiv_id": "2402.07562v1",
    "title": "Discovering Universal Semantic Triggers for Text-to-Image Synthesis",
    "authors": [
      "Shengfang Zhai",
      "Weilong Wang",
      "Jiajun Li",
      "Yinpeng Dong",
      "Hang Su",
      "Qingni Shen"
    ],
    "abstract": "Recently text-to-image models have gained widespread attention in the\ncommunity due to their controllable and high-quality generation ability.\nHowever, the robustness of such models and their potential ethical issues have\nnot been fully explored. In this paper, we introduce Universal Semantic\nTrigger, a meaningless token sequence that can be added at any location within\nthe input text yet can induce generated images towards a preset semantic\ntarget.To thoroughly investigate it, we propose Semantic Gradient-based Search\n(SGS) framework. SGS automatically discovers the potential universal semantic\ntriggers based on the given semantic targets. Furthermore, we design evaluation\nmetrics to comprehensively evaluate semantic shift of images caused by these\ntriggers. And our empirical analyses reveal that the mainstream open-source\ntext-to-image models are vulnerable to our triggers, which could pose\nsignificant ethical threats. Our work contributes to a further understanding of\ntext-to-image synthesis and helps users to automatically auditing their models\nbefore deployment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "9 pages, 5 figures. Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2402.07562v1",
    "published_date": "2024-02-12 10:56:09 UTC",
    "updated_date": "2024-02-12 10:56:09 UTC"
  },
  {
    "arxiv_id": "2402.07963v3",
    "title": "SPO: Sequential Monte Carlo Policy Optimisation",
    "authors": [
      "Matthew V Macfarlane",
      "Edan Toledo",
      "Donal Byrne",
      "Paul Duckworth",
      "Alexandre Laterre"
    ],
    "abstract": "Leveraging planning during learning and decision-making is central to the\nlong-term development of intelligent agents. Recent works have successfully\ncombined tree-based search methods and self-play learning mechanisms to this\nend. However, these methods typically face scaling challenges due to the\nsequential nature of their search. While practical engineering solutions can\npartly overcome this, they often result in a negative impact on performance. In\nthis paper, we introduce SPO: Sequential Monte Carlo Policy Optimisation, a\nmodel-based reinforcement learning algorithm grounded within the Expectation\nMaximisation (EM) framework. We show that SPO provides robust policy\nimprovement and efficient scaling properties. The sample-based search makes it\ndirectly applicable to both discrete and continuous action spaces without\nmodifications. We demonstrate statistically significant improvements in\nperformance relative to model-free and model-based baselines across both\ncontinuous and discrete environments. Furthermore, the parallel nature of SPO's\nsearch enables effective utilisation of hardware accelerators, yielding\nfavourable scaling laws.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NeurIPS 2024. 34 pages, 3 main figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07963v3",
    "published_date": "2024-02-12 10:32:47 UTC",
    "updated_date": "2024-10-31 17:05:49 UTC"
  },
  {
    "arxiv_id": "2402.07547v1",
    "title": "Ensuring trustworthy and ethical behaviour in intelligent logical agents",
    "authors": [
      "Stefania Costantini"
    ],
    "abstract": "Autonomous Intelligent Agents are employed in many applications upon which\nthe life and welfare of living beings and vital social functions may depend.\nTherefore, agents should be trustworthy. A priori certification techniques\n(i.e., techniques applied prior to system's deployment) can be useful, but are\nnot sufficient for agents that evolve, and thus modify their epistemic and\nbelief state, and for open Multi-Agent Systems, where heterogeneous agents can\njoin or leave the system at any stage of its operation. In this paper, we\npropose/refine/extend dynamic (runtime) logic-based self-checking techniques,\ndevised in order to be able to ensure agents' trustworthy and ethical\nbehaviour.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LO",
      "cs.SC",
      "I.2.4"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07547v1",
    "published_date": "2024-02-12 10:19:17 UTC",
    "updated_date": "2024-02-12 10:19:17 UTC"
  },
  {
    "arxiv_id": "2402.07543v1",
    "title": "Show Me How It's Done: The Role of Explanations in Fine-Tuning Language Models",
    "authors": [
      "Mohamad Ballout",
      "Ulf Krumnack",
      "Gunther Heidemann",
      "Kai-Uwe Kuehnberger"
    ],
    "abstract": "Our research demonstrates the significant benefits of using fine-tuning with\nexplanations to enhance the performance of language models. Unlike prompting,\nwhich maintains the model's parameters, fine-tuning allows the model to learn\nand update its parameters during a training phase. In this study, we applied\nfine-tuning to various sized language models using data that contained\nexplanations of the output rather than merely presenting the answers. We found\nthat even smaller language models with as few as 60 million parameters\nbenefited substantially from this approach. Interestingly, our results\nindicated that the detailed explanations were more beneficial to smaller models\nthan larger ones, with the latter gaining nearly the same advantage from any\nform of explanation, irrespective of its length. Additionally, we demonstrate\nthat the inclusion of explanations enables the models to solve tasks that they\nwere not able to solve without explanations. Lastly, we argue that despite the\nchallenging nature of adding explanations, samples that contain explanations\nnot only reduce the volume of data required for training but also promote a\nmore effective generalization by the model. In essence, our findings suggest\nthat fine-tuning with explanations significantly bolsters the performance of\nlarge language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07543v1",
    "published_date": "2024-02-12 10:11:50 UTC",
    "updated_date": "2024-02-12 10:11:50 UTC"
  },
  {
    "arxiv_id": "2402.07540v1",
    "title": "PKG API: A Tool for Personal Knowledge Graph Management",
    "authors": [
      "Nolwenn Bernard",
      "Ivica Kostric",
      "Weronika Łajewska",
      "Krisztian Balog",
      "Petra Galuščáková",
      "Vinay Setty",
      "Martin G. Skjæveland"
    ],
    "abstract": "Personal knowledge graphs (PKGs) offer individuals a way to store and\nconsolidate their fragmented personal data in a central place, improving\nservice personalization while maintaining full user control. Despite their\npotential, practical PKG implementations with user-friendly interfaces remain\nscarce. This work addresses this gap by proposing a complete solution to\nrepresent, manage, and interface with PKGs. Our approach includes (1) a\nuser-facing PKG Client, enabling end-users to administer their personal data\neasily via natural language statements, and (2) a service-oriented PKG API. To\ntackle the complexity of representing these statements within a PKG, we present\nan RDF-based PKG vocabulary that supports this, along with properties for\naccess rights and provenance.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07540v1",
    "published_date": "2024-02-12 10:09:16 UTC",
    "updated_date": "2024-02-12 10:09:16 UTC"
  },
  {
    "arxiv_id": "2403.00772v1",
    "title": "Do Weibo platform experts perform better at predicting stock market?",
    "authors": [
      "Ziyuan Ma",
      "Conor Ryan",
      "Jim Buckley",
      "Muslim Chochlov"
    ],
    "abstract": "Sentiment analysis can be used for stock market prediction. However, existing\nresearch has not studied the impact of a user's financial background on\nsentiment-based forecasting of the stock market using artificial neural\nnetworks. In this work, a novel combination of neural networks is used for the\nassessment of sentiment-based stock market prediction, based on the financial\nbackground of the population that generated the sentiment. The state-of-the-art\nlanguage processing model Bidirectional Encoder Representations from\nTransformers (BERT) is used to classify the sentiment and a Long-Short Term\nMemory (LSTM) model is used for time-series based stock market prediction. For\nevaluation, the Weibo social networking platform is used as a sentiment data\ncollection source. Weibo users (and their comments respectively) are divided\ninto Authorized Financial Advisor (AFA) and Unauthorized Financial Advisor\n(UFA) groups according to their background information, as collected by Weibo.\nThe Hong Kong Hang Seng index is used to extract historical stock market change\ndata. The results indicate that stock market prediction learned from the AFA\ngroup users is 39.67% more precise than that learned from the UFA group users\nand shows the highest accuracy (87%) when compared to existing approaches.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00772v1",
    "published_date": "2024-02-12 10:04:54 UTC",
    "updated_date": "2024-02-12 10:04:54 UTC"
  },
  {
    "arxiv_id": "2402.07536v2",
    "title": "FinLLM-B: When Large Language Models Meet Financial Breakout Trading",
    "authors": [
      "Kang Zhang",
      "Osamu Yoshie",
      "Lichao Sun",
      "Weiran Huang"
    ],
    "abstract": "Trading range breakout is a key method in the technical analysis of financial\ntrading, widely employed by traders in financial markets such as stocks,\nfutures, and foreign exchange. However, distinguishing between true and false\nbreakout and providing the correct rationale cause significant challenges to\ninvestors. Traditional quantitative methods require large amounts of data and\ncannot directly present the reasoning process, making them less than perfect in\nthis field. Recently, large language models have achieved success in various\ndownstream applications, but their effectiveness in the domain of financial\nbreakout detection has been subpar. The reason is that the unique data and\nspecific knowledge are required in breakout detection. To address these issues,\nwe create the first financial breakout dataset and introduce FinLLM-B, the\npremier large language model for financial breakout detection, which enhances\nthe effectiveness of breakout trading strategies. Furthermore, we have\ndeveloped a novel framework for large language models, namely multi-stage\nstructure, effectively reducing mistakes in downstream applications.\nExperimental results indicate that compared to GPT-3.5, FinLLM-B improves the\naverage accuracy of answers and rational by 49.97%, with the multi-stage\nstructure contributing 9.72% to the improvement. Additionally, it outperforms\nChatGPT-4 by 42.38%.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.07536v2",
    "published_date": "2024-02-12 10:04:07 UTC",
    "updated_date": "2025-02-22 16:36:08 UTC"
  },
  {
    "arxiv_id": "2402.07514v2",
    "title": "Physics-informed machine learning as a kernel method",
    "authors": [
      "Nathan Doumèche",
      "Francis Bach",
      "Gérard Biau",
      "Claire Boyer"
    ],
    "abstract": "Physics-informed machine learning combines the expressiveness of data-based\napproaches with the interpretability of physical models. In this context, we\nconsider a general regression problem where the empirical risk is regularized\nby a partial differential equation that quantifies the physical inconsistency.\nWe prove that for linear differential priors, the problem can be formulated as\na kernel regression task. Taking advantage of kernel theory, we derive\nconvergence rates for the minimizer of the regularized risk and show that it\nconverges at least at the Sobolev minimax rate. However, faster rates can be\nachieved, depending on the physical error. This principle is illustrated with a\none-dimensional example, supporting the claim that regularizing the empirical\nrisk with physical information can be beneficial to the statistical performance\nof estimators.",
    "categories": [
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07514v2",
    "published_date": "2024-02-12 09:38:42 UTC",
    "updated_date": "2024-06-19 07:40:56 UTC"
  },
  {
    "arxiv_id": "2402.07513v1",
    "title": "The Balancing Act: Unmasking and Alleviating ASR Biases in Portuguese",
    "authors": [
      "Ajinkya Kulkarni",
      "Anna Tokareva",
      "Rameez Qureshi",
      "Miguel Couceiro"
    ],
    "abstract": "In the field of spoken language understanding, systems like Whisper and\nMultilingual Massive Speech (MMS) have shown state-of-the-art performances.\nThis study is dedicated to a comprehensive exploration of the Whisper and MMS\nsystems, with a focus on assessing biases in automatic speech recognition (ASR)\ninherent to casual conversation speech specific to the Portuguese language. Our\ninvestigation encompasses various categories, including gender, age, skin tone\ncolor, and geo-location. Alongside traditional ASR evaluation metrics such as\nWord Error Rate (WER), we have incorporated p-value statistical significance\nfor gender bias analysis. Furthermore, we extensively examine the impact of\ndata distribution and empirically show that oversampling techniques alleviate\nsuch stereotypical biases. This research represents a pioneering effort in\nquantifying biases in the Portuguese language context through the application\nof MMS and Whisper, contributing to a better understanding of ASR systems'\nperformance in multilingual settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL-2024 LT-EDI Workshop",
    "pdf_url": "http://arxiv.org/pdf/2402.07513v1",
    "published_date": "2024-02-12 09:35:13 UTC",
    "updated_date": "2024-02-12 09:35:13 UTC"
  },
  {
    "arxiv_id": "2402.07510v4",
    "title": "Secret Collusion among Generative AI Agents: Multi-Agent Deception via Steganography",
    "authors": [
      "Sumeet Ramesh Motwani",
      "Mikhail Baranchuk",
      "Martin Strohmeier",
      "Vijay Bolina",
      "Philip H. S. Torr",
      "Lewis Hammond",
      "Christian Schroeder de Witt"
    ],
    "abstract": "Recent capability increases in large language models (LLMs) open up\napplications in which groups of communicating generative AI agents solve joint\ntasks. This poses privacy and security challenges concerning the unauthorised\nsharing of information, or other unwanted forms of agent coordination. Modern\nsteganographic techniques could render such dynamics hard to detect. In this\npaper, we comprehensively formalise the problem of secret collusion in systems\nof generative AI agents by drawing on relevant concepts from both AI and\nsecurity literature. We study incentives for the use of steganography, and\npropose a variety of mitigation measures. Our investigations result in a model\nevaluation framework that systematically tests capabilities required for\nvarious forms of secret collusion. We provide extensive empirical results\nacross a range of contemporary LLMs. While the steganographic capabilities of\ncurrent models remain limited, GPT-4 displays a capability jump suggesting the\nneed for continuous monitoring of steganographic frontier model capabilities.\nWe conclude by laying out a comprehensive research program to mitigate future\nrisks of collusion between generative AI models.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07510v4",
    "published_date": "2024-02-12 09:31:21 UTC",
    "updated_date": "2025-04-14 10:17:38 UTC"
  },
  {
    "arxiv_id": "2402.07507v1",
    "title": "Clustering Dynamics for Improved Speed Prediction Deriving from Topographical GPS Registrations",
    "authors": [
      "Sarah Almeida Carneiro",
      "Giovanni Chierchia",
      "Aurelie Pirayre",
      "Laurent Najman"
    ],
    "abstract": "A persistent challenge in the field of Intelligent Transportation Systems is\nto extract accurate traffic insights from geographic regions with scarce or no\ndata coverage. To this end, we propose solutions for speed prediction using\nsparse GPS data points and their associated topographical and road design\nfeatures. Our goal is to investigate whether we can use similarities in the\nterrain and infrastructure to train a machine learning model that can predict\nspeed in regions where we lack transportation data. For this we create a\nTemporally Orientated Speed Dictionary Centered on Topographically Clustered\nRoads, which helps us to provide speed correlations to selected feature\nconfigurations. Our results show qualitative and quantitative improvement over\nnew and standard regression methods. The presented framework provides a fresh\nperspective on devising strategies for missing data traffic analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07507v1",
    "published_date": "2024-02-12 09:28:16 UTC",
    "updated_date": "2024-02-12 09:28:16 UTC"
  },
  {
    "arxiv_id": "2402.07501v1",
    "title": "One Train for Two Tasks: An Encrypted Traffic Classification Framework Using Supervised Contrastive Learning",
    "authors": [
      "Haozhen Zhang",
      "Xi Xiao",
      "Le Yu",
      "Qing Li",
      "Zhen Ling",
      "Ye Zhang"
    ],
    "abstract": "As network security receives widespread attention, encrypted traffic\nclassification has become the current research focus. However, existing methods\nconduct traffic classification without sufficiently considering the common\ncharacteristics between data samples, leading to suboptimal performance.\nMoreover, they train the packet-level and flow-level classification tasks\nindependently, which is redundant because the packet representations learned in\nthe packet-level task can be exploited by the flow-level task. Therefore, in\nthis paper, we propose an effective model named a Contrastive Learning Enhanced\nTemporal Fusion Encoder (CLE-TFE). In particular, we utilize supervised\ncontrastive learning to enhance the packet-level and flow-level representations\nand perform graph data augmentation on the byte-level traffic graph so that the\nfine-grained semantic-invariant characteristics between bytes can be captured\nthrough contrastive learning. We also propose cross-level multi-task learning,\nwhich simultaneously accomplishes the packet-level and flow-level\nclassification tasks in the same model with one training. Further experiments\nshow that CLE-TFE achieves the best overall performance on the two tasks, while\nits computational overhead (i.e., floating point operations, FLOPs) is only\nabout 1/14 of the pre-trained model (e.g., ET-BERT). We release the code at\nhttps://github.com/ViktorAxelsen/CLE-TFE",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The code is available at https://github.com/ViktorAxelsen/CLE-TFE",
    "pdf_url": "http://arxiv.org/pdf/2402.07501v1",
    "published_date": "2024-02-12 09:10:09 UTC",
    "updated_date": "2024-02-12 09:10:09 UTC"
  },
  {
    "arxiv_id": "2402.07483v2",
    "title": "T-RAG: Lessons from the LLM Trenches",
    "authors": [
      "Masoomali Fatehkia",
      "Ji Kim Lucas",
      "Sanjay Chawla"
    ],
    "abstract": "Large Language Models (LLM) have shown remarkable language capabilities\nfueling attempts to integrate them into applications across a wide range of\ndomains. An important application area is question answering over private\nenterprise documents where the main considerations are data security, which\nnecessitates applications that can be deployed on-prem, limited computational\nresources and the need for a robust application that correctly responds to\nqueries. Retrieval-Augmented Generation (RAG) has emerged as the most prominent\nframework for building LLM-based applications. While building a RAG is\nrelatively straightforward, making it robust and a reliable application\nrequires extensive customization and relatively deep knowledge of the\napplication domain. We share our experiences building and deploying an LLM\napplication for question answering over private organizational documents. Our\napplication combines the use of RAG with a finetuned open-source LLM.\nAdditionally, our system, which we call Tree-RAG (T-RAG), uses a tree structure\nto represent entity hierarchies within the organization. This is used to\ngenerate a textual description to augment the context when responding to user\nqueries pertaining to entities within the organization's hierarchy. Our\nevaluations, including a Needle in a Haystack test, show that this combination\nperforms better than a simple RAG or finetuning implementation. Finally, we\nshare some lessons learned based on our experiences building an LLM application\nfor real-world use.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Added Needle in a Haystack analysis for T-RAG",
    "pdf_url": "http://arxiv.org/pdf/2402.07483v2",
    "published_date": "2024-02-12 08:45:08 UTC",
    "updated_date": "2024-06-06 14:42:47 UTC"
  },
  {
    "arxiv_id": "2402.07477v2",
    "title": "Food Recommendation as Language Processing (F-RLP): A Personalized and Contextual Paradigm",
    "authors": [
      "Ali Rostami",
      "Ramesh Jain",
      "Amir M. Rahmani"
    ],
    "abstract": "State-of-the-art rule-based and classification-based food recommendation\nsystems face significant challenges in becoming practical and useful. This\ndifficulty arises primarily because most machine learning models struggle with\nproblems characterized by an almost infinite number of classes and a limited\nnumber of samples within an unbalanced dataset. Conversely, the emergence of\nLarge Language Models (LLMs) as recommendation engines offers a promising\navenue. However, a general-purpose Recommendation as Language Processing (RLP)\napproach lacks the critical components necessary for effective food\nrecommendations. To address this gap, we introduce Food Recommendation as\nLanguage Processing (F-RLP), a novel framework that offers a food-specific,\ntailored infrastructure. F-RLP leverages the capabilities of LLMs to maximize\ntheir potential, thereby paving the way for more accurate, personalized food\nrecommendations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07477v2",
    "published_date": "2024-02-12 08:32:29 UTC",
    "updated_date": "2024-02-14 12:11:44 UTC"
  },
  {
    "arxiv_id": "2402.07465v1",
    "title": "Score-Based Physics-Informed Neural Networks for High-Dimensional Fokker-Planck Equations",
    "authors": [
      "Zheyuan Hu",
      "Zhongqiang Zhang",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "abstract": "The Fokker-Planck (FP) equation is a foundational PDE in stochastic\nprocesses. However, curse of dimensionality (CoD) poses challenge when dealing\nwith high-dimensional FP PDEs. Although Monte Carlo and vanilla\nPhysics-Informed Neural Networks (PINNs) have shown the potential to tackle\nCoD, both methods exhibit numerical errors in high dimensions when dealing with\nthe probability density function (PDF) associated with Brownian motion. The\npoint-wise PDF values tend to decrease exponentially as dimension increases,\nsurpassing the precision of numerical simulations and resulting in substantial\nerrors. Moreover, due to its massive sampling, Monte Carlo fails to offer fast\nsampling. Modeling the logarithm likelihood (LL) via vanilla PINNs transforms\nthe FP equation into a difficult HJB equation, whose error grows rapidly with\ndimension. To this end, we propose a novel approach utilizing a score-based\nsolver to fit the score function in SDEs. The score function, defined as the\ngradient of the LL, plays a fundamental role in inferring LL and PDF and\nenables fast SDE sampling. Three fitting methods, Score Matching (SM), Sliced\nSM (SSM), and Score-PINN, are introduced. The proposed score-based SDE solver\noperates in two stages: first, employing SM, SSM, or Score-PINN to acquire the\nscore; and second, solving the LL via an ODE using the obtained score.\nComparative evaluations across these methods showcase varying trade-offs. The\nproposed method is evaluated across diverse SDEs, including anisotropic OU\nprocesses, geometric Brownian, and Brownian with varying eigenspace. We also\ntest various distributions, including Gaussian, Log-normal, Laplace, and\nCauchy. The numerical results demonstrate the score-based SDE solver's\nstability, speed, and performance across different settings, solidifying its\npotential as a solution to CoD for high-dimensional FP equations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.DS",
      "math.NA",
      "stat.ML",
      "14J60"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.07465v1",
    "published_date": "2024-02-12 07:59:25 UTC",
    "updated_date": "2024-02-12 07:59:25 UTC"
  },
  {
    "arxiv_id": "2402.07462v2",
    "title": "A Hormetic Approach to the Value-Loading Problem: Preventing the Paperclip Apocalypse?",
    "authors": [
      "Nathan I. N. Henry",
      "Mangor Pedersen",
      "Matt Williams",
      "Jamin L. B. Martin",
      "Liesje Donkin"
    ],
    "abstract": "The value-loading problem is a significant challenge for researchers aiming\nto create artificial intelligence (AI) systems that align with human values and\npreferences. This problem requires a method to define and regulate safe and\noptimal limits of AI behaviors. In this work, we propose HALO (Hormetic\nALignment via Opponent processes), a regulatory paradigm that uses hormetic\nanalysis to regulate the behavioral patterns of AI. Behavioral hormesis is a\nphenomenon where low frequencies of a behavior have beneficial effects, while\nhigh frequencies are harmful. By modeling behaviors as allostatic opponent\nprocesses, we can use either Behavioral Frequency Response Analysis (BFRA) or\nBehavioral Count Response Analysis (BCRA) to quantify the hormetic limits of\nrepeatable behaviors. We demonstrate how HALO can solve the 'paperclip\nmaximizer' scenario, a thought experiment where an unregulated AI tasked with\nmaking paperclips could end up converting all matter in the universe into\npaperclips. Our approach may be used to help create an evolving database of\n'values' based on the hedonic calculus of repeatable behaviors with decreasing\nmarginal utility. This positions HALO as a promising solution for the\nvalue-loading problem, which involves embedding human-aligned values into an AI\nsystem, and the weak-to-strong generalization problem, which explores whether\nweak models can supervise stronger models as they become more intelligent.\nHence, HALO opens several research avenues that may lead to the development of\na computational value system that allows an AI algorithm to learn whether the\ndecisions it makes are right or wrong.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.MA",
      "econ.TH",
      "68T01, 68T37, 68T42",
      "I.2.0; I.2.8; I.2.11"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07462v2",
    "published_date": "2024-02-12 07:49:48 UTC",
    "updated_date": "2024-02-13 05:21:40 UTC"
  },
  {
    "arxiv_id": "2402.07456v2",
    "title": "OS-Copilot: Towards Generalist Computer Agents with Self-Improvement",
    "authors": [
      "Zhiyong Wu",
      "Chengcheng Han",
      "Zichen Ding",
      "Zhenmin Weng",
      "Zhoumianze Liu",
      "Shunyu Yao",
      "Tao Yu",
      "Lingpeng Kong"
    ],
    "abstract": "Autonomous interaction with the computer has been a longstanding challenge\nwith great potential, and the recent proliferation of large language models\n(LLMs) has markedly accelerated progress in building digital agents. However,\nmost of these agents are designed to interact with a narrow domain, such as a\nspecific software or website. This narrow focus constrains their applicability\nfor general computer tasks. To this end, we introduce OS-Copilot, a framework\nto build generalist agents capable of interfacing with comprehensive elements\nin an operating system (OS), including the web, code terminals, files,\nmultimedia, and various third-party applications. We use OS-Copilot to create\nFRIDAY, a self-improving embodied agent for automating general computer tasks.\nOn GAIA, a general AI assistants benchmark, FRIDAY outperforms previous methods\nby 35%, showcasing strong generalization to unseen applications via accumulated\nskills from previous tasks. We also present numerical and quantitative evidence\nthat FRIDAY learns to control and self-improve on Excel and Powerpoint with\nminimal supervision. Our OS-Copilot framework and empirical findings provide\ninfrastructure and insights for future research toward more capable and\ngeneral-purpose computer agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Project page: https://os-copilot.github.io",
    "pdf_url": "http://arxiv.org/pdf/2402.07456v2",
    "published_date": "2024-02-12 07:29:22 UTC",
    "updated_date": "2024-02-15 09:30:48 UTC"
  },
  {
    "arxiv_id": "2402.07452v2",
    "title": "TriAug: Out-of-Distribution Detection for Imbalanced Breast Lesion in Ultrasound",
    "authors": [
      "Yinyu Ye",
      "Shijing Chen",
      "Dong Ni",
      "Ruobing Huang"
    ],
    "abstract": "Different diseases, such as histological subtypes of breast lesions, have\nseverely varying incidence rates. Even trained with substantial amount of\nin-distribution (ID) data, models often encounter out-of-distribution (OOD)\nsamples belonging to unseen classes in clinical reality. To address this, we\npropose a novel framework built upon a long-tailed OOD detection task for\nbreast ultrasound images. It is equipped with a triplet state augmentation\n(TriAug) which improves ID classification accuracy while maintaining a\npromising OOD detection performance. Meanwhile, we designed a balanced sphere\nloss to handle the class imbalanced problem. Experimental results show that the\nmodel outperforms state-of-art OOD approaches both in ID classification\n(F1-score=42.12%) and OOD detection (AUROC=78.06%).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07452v2",
    "published_date": "2024-02-12 07:19:00 UTC",
    "updated_date": "2024-02-27 02:19:54 UTC"
  },
  {
    "arxiv_id": "2402.07448v1",
    "title": "AraSpider: Democratizing Arabic-to-SQL",
    "authors": [
      "Ahmed Heakl",
      "Youssef Mohamed",
      "Ahmed B. Zaky"
    ],
    "abstract": "This study presents AraSpider, the first Arabic version of the Spider\ndataset, aimed at improving natural language processing (NLP) in the\nArabic-speaking community. Four multilingual translation models were tested for\ntheir effectiveness in translating English to Arabic. Additionally, two models\nwere assessed for their ability to generate SQL queries from Arabic text. The\nresults showed that using back translation significantly improved the\nperformance of both ChatGPT 3.5 and SQLCoder models, which are considered top\nperformers on the Spider dataset. Notably, ChatGPT 3.5 demonstrated\nhigh-quality translation, while SQLCoder excelled in text-to-SQL tasks. The\nstudy underscores the importance of incorporating contextual schema and\nemploying back translation strategies to enhance model performance in Arabic\nNLP tasks. Moreover, the provision of detailed methodologies for\nreproducibility and translation of the dataset into other languages highlights\nthe research's commitment to promoting transparency and collaborative knowledge\nsharing in the field. Overall, these contributions advance NLP research,\nempower Arabic-speaking researchers, and enrich the global discourse on\nlanguage comprehension and database interrogation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07448v1",
    "published_date": "2024-02-12 07:11:13 UTC",
    "updated_date": "2024-02-12 07:11:13 UTC"
  },
  {
    "arxiv_id": "2402.07442v1",
    "title": "Game Agent Driven by Free-Form Text Command: Using LLM-based Code Generation and Behavior Branch",
    "authors": [
      "Ray Ito",
      "Junichiro Takahashi"
    ],
    "abstract": "Several attempts have been made to implement text command control for game\nagents. However, current technologies are limited to processing predefined\nformat commands. This paper proposes a pioneering text command control system\nfor a game agent that can understand natural language commands expressed in\nfree-form. The proposed system uses a large language model (LLM) for code\ngeneration to interpret and transform natural language commands into behavior\nbranch, a proposed knowledge expression based on behavior trees, which\nfacilitates execution by the game agent. This study conducted empirical\nvalidation within a game environment that simulates a Pok\\'emon game and\ninvolved multiple participants. The results confirmed the system's ability to\nunderstand and carry out natural language commands, representing a noteworthy\nin the realm of real-time language interactive game agents.\n  Notice for the use of this material. The copyright of this material is\nretained by the Japanese Society for Artificial Intelligence (JSAI). This\nmaterial is published here with the agreement of JSAI. Please be complied with\nCopyright Law of Japan if any users wish to reproduce, make derivative work,\ndistribute or make available to the public any part or whole thereof. All\nRights Reserved, Copyright (C) The Japanese Society for Artificial\nIntelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper is posted at JSAI 2024 Conference",
    "pdf_url": "http://arxiv.org/pdf/2402.07442v1",
    "published_date": "2024-02-12 06:49:48 UTC",
    "updated_date": "2024-02-12 06:49:48 UTC"
  },
  {
    "arxiv_id": "2402.07437v2",
    "title": "Learning Optimal Tax Design in Nonatomic Congestion Games",
    "authors": [
      "Qiwen Cui",
      "Maryam Fazel",
      "Simon S. Du"
    ],
    "abstract": "In multiplayer games, self-interested behavior among the players can harm the\nsocial welfare. Tax mechanisms are a common method to alleviate this issue and\ninduce socially optimal behavior. In this work, we take the initial step of\nlearning the optimal tax that can maximize social welfare with limited feedback\nin congestion games. We propose a new type of feedback named \\emph{equilibrium\nfeedback}, where the tax designer can only observe the Nash equilibrium after\ndeploying a tax plan. Existing algorithms are not applicable due to the\nexponentially large tax function space, nonexistence of the gradient, and\nnonconvexity of the objective. To tackle these challenges, we design a\ncomputationally efficient algorithm that leverages several novel components:\n(1) a piece-wise linear tax to approximate the optimal tax; (2) extra linear\nterms to guarantee a strongly convex potential function; (3) an efficient\nsubroutine to find the exploratory tax that can provide critical information\nabout the game. The algorithm can find an $\\epsilon$-optimal tax with $O(\\beta\nF^2/\\epsilon)$ sample complexity, where $\\beta$ is the smoothness of the cost\nfunction and $F$ is the number of facilities.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "23 pages. Accepted by Conference on Neural Information Processing\n  Systems (NeurIPS) 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.07437v2",
    "published_date": "2024-02-12 06:32:53 UTC",
    "updated_date": "2025-01-15 14:02:51 UTC"
  },
  {
    "arxiv_id": "2402.07435v1",
    "title": "Analyzing Currency Fluctuations: A Comparative Study of GARCH, EWMA, and IV Models for GBP/USD and EUR/GBP Pairs",
    "authors": [
      "Narayan Tondapu"
    ],
    "abstract": "In this study, we examine the fluctuation in the value of the Great Britain\nPound (GBP). We focus particularly on its relationship with the United States\nDollar (USD) and the Euro (EUR) currency pairs. Utilizing data from June 15,\n2018, to June 15, 2023, we apply various mathematical models to assess their\neffectiveness in predicting the 20-day variation in the pairs' daily returns.\nOur analysis involves the implementation of Exponentially Weighted Moving\nAverage (EWMA), Generalized Autoregressive Conditional Heteroskedasticity\n(GARCH) models, and Implied Volatility (IV) models. To evaluate their\nperformance, we compare the accuracy of their predictions using Root Mean\nSquare Error (RMSE) and Mean Absolute Error (MAE) metrics. We delve into the\nintricacies of GARCH models, examining their statistical characteristics when\napplied to the provided dataset. Our findings suggest the existence of\nasymmetric returns in the EUR/GBP pair, while such evidence is inconclusive for\nthe GBP/USD pair. Additionally, we observe that GARCH-type models better fit\nthe data when assuming residuals follow a standard t-distribution rather than a\nstandard normal distribution. Furthermore, we investigate the efficacy of\ndifferent forecasting techniques within GARCH-type models. Comparing rolling\nwindow forecasts to expanding window forecasts, we find no definitive\nsuperiority in either approach across the tested scenarios. Our experiments\nreveal that for the GBP/USD pair, the most accurate volatility forecasts stem\nfrom the utilization of GARCH models employing a rolling window methodology.\nConversely, for the EUR/GBP pair, optimal forecasts are derived from GARCH\nmodels and Ordinary Least Squares (OLS) models incorporating the annualized\nimplied volatility of the exchange rate as an independent variable.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07435v1",
    "published_date": "2024-02-12 06:29:57 UTC",
    "updated_date": "2024-02-12 06:29:57 UTC"
  },
  {
    "arxiv_id": "2403.12069v1",
    "title": "Fairness Evaluation for Uplift Modeling in the Absence of Ground Truth",
    "authors": [
      "Serdar Kadioglu",
      "Filip Michalsky"
    ],
    "abstract": "The acceleration in the adoption of AI-based automated decision-making\nsystems poses a challenge for evaluating the fairness of algorithmic decisions,\nespecially in the absence of ground truth. When designing interventions, uplift\nmodeling is used extensively to identify candidates that are likely to benefit\nfrom treatment. However, these models remain particularly susceptible to\nfairness evaluation due to the lack of ground truth on the outcome measure\nsince a candidate cannot be in both treatment and control simultaneously. In\nthis article, we propose a framework that overcomes the missing ground truth\nproblem by generating surrogates to serve as a proxy for counterfactual labels\nof uplift modeling campaigns. We then leverage the surrogate ground truth to\nconduct a more comprehensive binary fairness evaluation. We show how to apply\nthe approach in a comprehensive study from a real-world marketing campaign for\npromotional offers and demonstrate its enhancement for fairness evaluation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "IEEE International Conference on Machine Learning and Applications\n  (IEEE ICMLA)",
    "pdf_url": "http://arxiv.org/pdf/2403.12069v1",
    "published_date": "2024-02-12 06:13:24 UTC",
    "updated_date": "2024-02-12 06:13:24 UTC"
  },
  {
    "arxiv_id": "2402.07429v2",
    "title": "Particle Filter SLAM for Vehicle Localization",
    "authors": [
      "Tianrui Liu",
      "Changxin Xu",
      "Yuxin Qiao",
      "Chufeng Jiang",
      "Jiqiang Yu"
    ],
    "abstract": "Simultaneous Localization and Mapping (SLAM) presents a formidable challenge\nin robotics, involving the dynamic construction of a map while concurrently\ndetermining the precise location of the robotic agent within an unfamiliar\nenvironment. This intricate task is further compounded by the inherent\n\"chicken-and-egg\" dilemma, where accurate mapping relies on a dependable\nestimation of the robot's location, and vice versa. Moreover, the computational\nintensity of SLAM adds an additional layer of complexity, making it a crucial\nyet demanding topic in the field. In our research, we address the challenges of\nSLAM by adopting the Particle Filter SLAM method. Our approach leverages\nencoded data and fiber optic gyro (FOG) information to enable precise\nestimation of vehicle motion, while lidar technology contributes to\nenvironmental perception by providing detailed insights into surrounding\nobstacles. The integration of these data streams culminates in the\nestablishment of a Particle Filter SLAM framework, representing a key endeavor\nin this paper to effectively navigate and overcome the complexities associated\nwith simultaneous localization and mapping in robotic systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, Journal of Industrial Engineering and Applied Science",
    "pdf_url": "http://arxiv.org/pdf/2402.07429v2",
    "published_date": "2024-02-12 06:06:09 UTC",
    "updated_date": "2024-02-20 02:42:33 UTC"
  },
  {
    "arxiv_id": "2402.07422v2",
    "title": "News Recommendation with Attention Mechanism",
    "authors": [
      "Tianrui Liu",
      "Changxin Xu",
      "Yuxin Qiao",
      "Chufeng Jiang",
      "Weisheng Chen"
    ],
    "abstract": "This paper explores the area of news recommendation, a key component of\nonline information sharing. Initially, we provide a clear introduction to news\nrecommendation, defining the core problem and summarizing current methods and\nnotable recent algorithms. We then present our work on implementing the NRAM\n(News Recommendation with Attention Mechanism), an attention-based approach for\nnews recommendation, and assess its effectiveness. Our evaluation shows that\nNRAM has the potential to significantly improve how news content is\npersonalized for users on digital news platforms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, Journal of Industrial Engineering and Applied Science",
    "pdf_url": "http://arxiv.org/pdf/2402.07422v2",
    "published_date": "2024-02-12 05:56:12 UTC",
    "updated_date": "2024-02-20 02:46:17 UTC"
  },
  {
    "arxiv_id": "2402.07420v2",
    "title": "On the Transit Obfuscation Problem",
    "authors": [
      "Hideaki Takahashi",
      "Alex Fukunaga"
    ],
    "abstract": "Concealing an intermediate point on a route or visible from a route is an\nimportant goal in some transportation and surveillance scenarios. This paper\nstudies the Transit Obfuscation Problem, the problem of traveling from some\nstart location to an end location while \"covering\" a specific transit point\nthat needs to be concealed from adversaries. We propose the notion of transit\nanonymity, a quantitative guarantee of the anonymity of a specific transit\npoint, even with a powerful adversary with full knowledge of the path planning\nalgorithm. We propose and evaluate planning/search algorithms that satisfy this\nanonymity criterion.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07420v2",
    "published_date": "2024-02-12 05:48:52 UTC",
    "updated_date": "2024-02-13 07:02:05 UTC"
  },
  {
    "arxiv_id": "2402.07419v2",
    "title": "Conditional Generative Models are Sufficient to Sample from Any Causal Effect Estimand",
    "authors": [
      "Md Musfiqur Rahman",
      "Matt Jordan",
      "Murat Kocaoglu"
    ],
    "abstract": "Causal inference from observational data plays critical role in many\napplications in trustworthy machine learning. While sound and complete\nalgorithms exist to compute causal effects, many of them assume access to\nconditional likelihoods, which is difficult to estimate for high-dimensional\n(particularly image) data. Researchers have alleviated this issue by simulating\ncausal relations with neural models. However, when we have high-dimensional\nvariables in the causal graph along with some unobserved confounders, no\nexisting work can effectively sample from the un/conditional interventional\ndistributions. In this work, we show how to sample from any identifiable\ninterventional distribution given an arbitrary causal graph through a sequence\nof push-forward computations of conditional generative models, such as\ndiffusion models. Our proposed algorithm follows the recursive steps of the\nexisting likelihood-based identification algorithms to train a set of\nfeed-forward models, and connect them in a specific way to sample from the\ndesired distribution. We conduct experiments on a Colored MNIST dataset having\nboth the treatment ($X$) and the target variables ($Y$) as images and sample\nfrom $P(y|do(x))$. Our algorithm also enables us to conduct a causal analysis\nto evaluate spurious correlations among input features of generative models\npre-trained on the CelebA dataset. Finally, we generate high-dimensional\ninterventional samples from the MIMIC-CXR dataset involving text and image\nvariables.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07419v2",
    "published_date": "2024-02-12 05:48:31 UTC",
    "updated_date": "2024-10-31 12:16:44 UTC"
  },
  {
    "arxiv_id": "2402.07418v1",
    "title": "SemTra: A Semantic Skill Translator for Cross-Domain Zero-Shot Policy Adaptation",
    "authors": [
      "Sangwoo Shin",
      "Minjong Yoo",
      "Jeongwoo Lee",
      "Honguk Woo"
    ],
    "abstract": "This work explores the zero-shot adaptation capability of semantic skills,\nsemantically interpretable experts' behavior patterns, in cross-domain\nsettings, where a user input in interleaved multi-modal snippets can prompt a\nnew long-horizon task for different domains. In these cross-domain settings, we\npresent a semantic skill translator framework SemTra which utilizes a set of\nmulti-modal models to extract skills from the snippets, and leverages the\nreasoning capabilities of a pretrained language model to adapt these extracted\nskills to the target domain. The framework employs a two-level hierarchy for\nadaptation: task adaptation and skill adaptation. During task adaptation,\nseq-to-seq translation by the language model transforms the extracted skills\ninto a semantic skill sequence, which is tailored to fit the cross-domain\ncontexts. Skill adaptation focuses on optimizing each semantic skill for the\ntarget domain context, through parametric instantiations that are facilitated\nby language prompting and contrastive learning-based context inferences. This\nhierarchical adaptation empowers the framework to not only infer a complex task\nspecification in one-shot from the interleaved multi-modal snippets, but also\nadapt it to new domains with zero-shot learning abilities. We evaluate our\nframework with Meta-World, Franka Kitchen, RLBench, and CARLA environments. The\nresults clarify the framework's superiority in performing long-horizon tasks\nand adapting to different domains, showing its broad applicability in practical\nuse cases, such as cognitive robots interpreting abstract instructions and\nautonomous vehicles operating under varied configurations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI 2024 Camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2402.07418v1",
    "published_date": "2024-02-12 05:46:10 UTC",
    "updated_date": "2024-02-12 05:46:10 UTC"
  },
  {
    "arxiv_id": "2402.07415v1",
    "title": "Context-aware Multi-Model Object Detection for Diversely Heterogeneous Compute Systems",
    "authors": [
      "Justin Davis",
      "Mehmet E. Belviranli"
    ],
    "abstract": "In recent years, deep neural networks (DNNs) have gained widespread adoption\nfor continuous mobile object detection (OD) tasks, particularly in autonomous\nsystems. However, a prevalent issue in their deployment is the\none-size-fits-all approach, where a single DNN is used, resulting in\ninefficient utilization of computational resources. This inefficiency is\nparticularly detrimental in energy-constrained systems, as it degrades overall\nsystem efficiency. We identify that, the contextual information embedded in the\ninput data stream (e.g. the frames in the camera feed that the OD models are\nrun on) could be exploited to allow a more efficient multi-model-based OD\nprocess. In this paper, we propose SHIFT which continuously selects from a\nvariety of DNN-based OD models depending on the dynamically changing contextual\ninformation and computational constraints. During this selection, SHIFT\nuniquely considers multi-accelerator execution to better optimize the\nenergy-efficiency while satisfying the latency constraints. Our proposed\nmethodology results in improvements of up to 7.5x in energy usage and 2.8x in\nlatency compared to state-of-the-art GPU-based single model OD approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07415v1",
    "published_date": "2024-02-12 05:38:11 UTC",
    "updated_date": "2024-02-12 05:38:11 UTC"
  },
  {
    "arxiv_id": "2402.07412v1",
    "title": "Auxiliary Reward Generation with Transition Distance Representation Learning",
    "authors": [
      "Siyuan Li",
      "Shijie Han",
      "Yingnan Zhao",
      "By Liang",
      "Peng Liu"
    ],
    "abstract": "Reinforcement learning (RL) has shown its strength in challenging sequential\ndecision-making problems. The reward function in RL is crucial to the learning\nperformance, as it serves as a measure of the task completion degree. In\nreal-world problems, the rewards are predominantly human-designed, which\nrequires laborious tuning, and is easily affected by human cognitive biases. To\nachieve automatic auxiliary reward generation, we propose a novel\nrepresentation learning approach that can measure the ``transition distance''\nbetween states. Building upon these representations, we introduce an auxiliary\nreward generation technique for both single-task and skill-chaining scenarios\nwithout the need for human knowledge. The proposed approach is evaluated in a\nwide range of manipulation tasks. The experiment results demonstrate the\neffectiveness of measuring the transition distance between states and the\ninduced improvement by auxiliary rewards, which not only promotes better\nlearning efficiency but also increases convergent stability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07412v1",
    "published_date": "2024-02-12 05:13:44 UTC",
    "updated_date": "2024-02-12 05:13:44 UTC"
  },
  {
    "arxiv_id": "2402.07408v2",
    "title": "Large Language Models are Few-shot Generators: Proposing Hybrid Prompt Algorithm To Generate Webshell Escape Samples",
    "authors": [
      "Mingrui Ma",
      "Lansheng Han",
      "Chunjie Zhou"
    ],
    "abstract": "The frequent occurrence of cyber-attacks has made webshell attacks and\ndefense gradually become a research hotspot in the field of network security.\nHowever, the lack of publicly available benchmark datasets and the\nover-reliance on manually defined rules for webshell escape sample generation\nhave slowed down the progress of research related to webshell escape sample\ngeneration and artificial intelligence (AI)-based webshell detection. To\naddress the drawbacks of weak webshell sample escape capabilities, the lack of\nwebshell datasets with complex malicious features, and to promote the\ndevelopment of webshell detection, we propose the Hybrid Prompt algorithm for\nwebshell escape sample generation with the help of large language models. As a\nprompt algorithm specifically developed for webshell sample generation, the\nHybrid Prompt algorithm not only combines various prompt ideas including Chain\nof Thought, Tree of Thought, but also incorporates various components such as\nwebshell hierarchical module and few-shot example to facilitate the LLM in\nlearning and reasoning webshell escape strategies. Experimental results show\nthat the Hybrid Prompt algorithm can work with multiple LLMs with excellent\ncode reasoning ability to generate high-quality webshell samples with high\nEscape Rate (88.61% with GPT-4 model on VirusTotal detection engine) and\n(Survival Rate 54.98% with GPT-4 model).",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "21 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07408v2",
    "published_date": "2024-02-12 04:59:58 UTC",
    "updated_date": "2024-06-05 02:23:48 UTC"
  },
  {
    "arxiv_id": "2402.07404v1",
    "title": "Enhancing Multi-Criteria Decision Analysis with AI: Integrating Analytic Hierarchy Process and GPT-4 for Automated Decision Support",
    "authors": [
      "Igor Svoboda",
      "Dmytro Lande"
    ],
    "abstract": "Our study presents a new framework that incorporates the Analytic Hierarchy\nProcess (AHP) and Generative Pre-trained Transformer 4 (GPT-4) large language\nmodel (LLM), bringing novel approaches to cybersecurity Multiple-criteria\nDecision Making (MCDA). By utilizing the capabilities of GPT-4 autonomous\nagents as virtual experts, we automate the decision-making process, enhancing\nboth efficiency and reliability. This new approach focuses on leveraging LLMs\nfor sophisticated decision analysis, highlighting the synergy between\ntraditional decision-making models and cutting-edge AI technologies. Our\ninnovative methodology demonstrates significant advancements in using AI-driven\nagents for complex decision-making scenarios, highlighting the importance of AI\nin strategic cybersecurity applications. The findings reveal the transformative\npotential of combining AHP and LLMs, establishing a new paradigm for\nintelligent decision support systems in cybersecurity and beyond.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.MA",
      "I.2.1; I.2.8; H.1.1"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2402.07404v1",
    "published_date": "2024-02-12 04:47:38 UTC",
    "updated_date": "2024-02-12 04:47:38 UTC"
  },
  {
    "arxiv_id": "2402.07402v1",
    "title": "BDIQA: A New Dataset for Video Question Answering to Explore Cognitive Reasoning through Theory of Mind",
    "authors": [
      "Yuanyuan Mao",
      "Xin Lin",
      "Qin Ni",
      "Liang He"
    ],
    "abstract": "As a foundational component of cognitive intelligence, theory of mind (ToM)\ncan make AI more closely resemble human thought processes, thereby enhancing\ntheir interaction and collaboration with human. In particular, it can\nsignificantly improve a model's comprehension of videos in complex scenes.\nHowever, current video question answer (VideoQA) datasets focus on studying\ncausal reasoning within events few of them genuinely incorporating human ToM.\nConsequently, there is a lack of development in ToM reasoning tasks within the\narea of VideoQA. This paper presents BDIQA, the first benchmark to explore the\ncognitive reasoning capabilities of VideoQA models in the context of ToM. BDIQA\nis inspired by the cognitive development of children's ToM and addresses the\ncurrent deficiencies in machine ToM within datasets and tasks. Specifically, it\noffers tasks at two difficulty levels, assessing Belief, Desire and Intention\n(BDI) reasoning in both simple and complex scenarios. We conduct evaluations on\nseveral mainstream methods of VideoQA and diagnose their capabilities with zero\nshot, few shot and supervised learning. We find that the performance of\npre-trained models on cognitive reasoning tasks remains unsatisfactory. To\ncounter this challenge, we undertake thorough analysis and experimentation,\nultimately presenting two guidelines to enhance cognitive reasoning derived\nfrom ablation analysis.",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07402v1",
    "published_date": "2024-02-12 04:34:19 UTC",
    "updated_date": "2024-02-12 04:34:19 UTC"
  },
  {
    "arxiv_id": "2402.07398v3",
    "title": "VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization",
    "authors": [
      "Dongsheng Zhu",
      "Xunzhu Tang",
      "Weidong Han",
      "Jinghui Lu",
      "Yukun Zhao",
      "Guoliang Xing",
      "Junfeng Wang",
      "Dawei Yin"
    ],
    "abstract": "This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual content. Our comprehensive experiments on\nMMLMs, based on FlanT5 and Vicuna, show that VisLingInstruct significantly\nimproves zero-shot performance in visual multi-modal tasks. Notably, it\nachieves a 13.1% and 9% increase in accuracy over the prior state-of-the-art on\nthe TextVQA and HatefulMemes datasets. Our main code is available at\nhttps://github.com/Zhudongsheng75/VisLingInstruct.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NAACL2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2402.07398v3",
    "published_date": "2024-02-12 04:13:16 UTC",
    "updated_date": "2024-06-20 14:44:14 UTC"
  },
  {
    "arxiv_id": "2402.07393v1",
    "title": "TeMPO: Efficient Time-Multiplexed Dynamic Photonic Tensor Core for Edge AI with Compact Slow-Light Electro-Optic Modulator",
    "authors": [
      "Meng Zhang",
      "Dennis Yin",
      "Nicholas Gangi",
      "Amir Begović",
      "Alexander Chen",
      "Zhaoran Rena Huang",
      "Jiaqi Gu"
    ],
    "abstract": "Electronic-photonic computing systems offer immense potential in\nenergy-efficient artificial intelligence (AI) acceleration tasks due to the\nsuperior computing speed and efficiency of optics, especially for real-time,\nlow-energy deep neural network (DNN) inference tasks on resource-restricted\nedge platforms. However, current optical neural accelerators based on\nfoundry-available devices and conventional system architecture still encounter\na performance gap compared to highly customized electronic counterparts. To\nbridge the performance gap due to lack of domain specialization, we present a\ntime-multiplexed dynamic photonic tensor accelerator, dubbed TeMPO, with\ncross-layer device/circuit/architecture customization. At the device level, we\npresent foundry-compatible, customized photonic devices, including a slow-light\nelectro-optic modulator with experimental demonstration, optical splitters, and\nphase shifters that significantly reduce the footprint and power in input\nencoding and dot-product calculation. At the circuit level, partial products\nare hierarchically accumulated via parallel photocurrent aggregation,\nlightweight capacitive temporal integration, and sequential digital summation,\nconsiderably relieving the analog-to-digital conversion bottleneck. We also\nemploy a multi-tile, multi-core architecture to maximize hardware sharing for\nhigher efficiency. Across diverse edge AI workloads, TeMPO delivers\ndigital-comparable task accuracy with superior quantization/noise tolerance. We\nachieve a 368.6 TOPS peak performance, 22.3 TOPS/W energy efficiency, and 1.2\nTOPS/mm$^2$ compute density, pushing the Pareto frontier in edge AI hardware.\nThis work signifies the power of cross-layer co-design and domain-specific\ncustomization, paving the way for future electronic-photonic accelerators with\neven greater performance and efficiency.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.ET",
    "comment": "17 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07393v1",
    "published_date": "2024-02-12 03:40:32 UTC",
    "updated_date": "2024-02-12 03:40:32 UTC"
  },
  {
    "arxiv_id": "2402.07384v1",
    "title": "Exploring Perceptual Limitation of Multimodal Large Language Models",
    "authors": [
      "Jiarui Zhang",
      "Jinyi Hu",
      "Mahyar Khayatkhoei",
      "Filip Ilievski",
      "Maosong Sun"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have recently shown remarkable\nperceptual capability in answering visual questions, however, little is known\nabout the limits of their perception. In particular, while prior works have\nprovided anecdotal evidence of MLLMs' sensitivity to object size, this\nphenomenon and its underlying causes have not been explored comprehensively. In\nthis work, we quantitatively study the perception of small visual objects in\nseveral state-of-the-art MLLMs and reveal a pervasive limitation in answering\nquestions about small objects in images. Next, we identify four independent\nfactors that can contribute to this limitation -- object quality, size,\ndistractors, and location -- and conduct controlled intervention studies to\nmeasure the effect of each factor on MLLMs' perception. In particular, we find\nthat lower object quality and smaller object size can both independently reduce\nMLLMs' ability to answer visual questions. More surprisingly, we find that the\nlocation of the object in the image and the presence of visual distractors can\nalso significantly reduce MLLMs' question answering accuracy. Our study\nprovides a better understanding of the perceptual limitation of MLLMs and\ncontributes new evaluation protocols for analyzing the perception of future\nMLLMs. To facilitate further investigations, we release our code and data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 14 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.07384v1",
    "published_date": "2024-02-12 03:04:42 UTC",
    "updated_date": "2024-02-12 03:04:42 UTC"
  },
  {
    "arxiv_id": "2402.07370v2",
    "title": "SelfSwapper: Self-Supervised Face Swapping via Shape Agnostic Masked AutoEncoder",
    "authors": [
      "Jaeseong Lee",
      "Junha Hyung",
      "Sohyun Jeong",
      "Jaegul Choo"
    ],
    "abstract": "Face swapping has gained significant attention for its varied applications.\nMost previous face swapping approaches have relied on the seesaw game training\nscheme, also known as the target-oriented approach. However, this often leads\nto instability in model training and results in undesired samples with blended\nidentities due to the target identity leakage problem. Source-oriented methods\nachieve more stable training with self-reconstruction objective but often fail\nto accurately reflect target image's skin color and illumination. This paper\nintroduces the Shape Agnostic Masked AutoEncoder (SAMAE) training scheme, a\nnovel self-supervised approach that combines the strengths of both\ntarget-oriented and source-oriented approaches. Our training scheme addresses\nthe limitations of traditional training methods by circumventing the\nconventional seesaw game and introducing clear ground truth through its\nself-reconstruction training regime. Our model effectively mitigates identity\nleakage and reflects target albedo and illumination through learned\ndisentangled identity and non-identity features. Additionally, we closely\ntackle the shape misalignment and volume discrepancy problems with new\ntechniques, including perforation confusion and random mesh scaling. SAMAE\nestablishes a new state-of-the-art, surpassing other baseline methods,\npreserving both identity and non-identity attributes without sacrificing on\neither aspect.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07370v2",
    "published_date": "2024-02-12 02:01:53 UTC",
    "updated_date": "2024-07-22 15:32:36 UTC"
  },
  {
    "arxiv_id": "2402.07368v1",
    "title": "Assessing Generalization for Subpopulation Representative Modeling via In-Context Learning",
    "authors": [
      "Gabriel Simmons",
      "Vladislav Savinov"
    ],
    "abstract": "This study evaluates the ability of Large Language Model (LLM)-based\nSubpopulation Representative Models (SRMs) to generalize from empirical data,\nutilizing in-context learning with data from the 2016 and 2020 American\nNational Election Studies. We explore generalization across response variables\nand demographic subgroups. While conditioning with empirical data improves\nperformance on the whole, the benefit of in-context learning varies\nconsiderably across demographics, sometimes hurting performance for one\ndemographic while helping performance for others. The inequitable benefits of\nin-context learning for SRM present a challenge for practitioners implementing\nSRMs, and for decision-makers who might come to rely on them. Our work\nhighlights a need for fine-grained benchmarks captured from diverse\nsubpopulations that test not only fidelity but generalization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to PERSONALIZE workshop at EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.07368v1",
    "published_date": "2024-02-12 01:55:51 UTC",
    "updated_date": "2024-02-12 01:55:51 UTC"
  },
  {
    "arxiv_id": "2402.07366v2",
    "title": "Bayesian Deep Learning Via Expectation Maximization and Turbo Deep Approximate Message Passing",
    "authors": [
      "Wei Xu",
      "An Liu",
      "Yiting Zhang",
      "Vincent Lau"
    ],
    "abstract": "Efficient learning and model compression algorithm for deep neural network\n(DNN) is a key workhorse behind the rise of deep learning (DL). In this work,\nwe propose a message passing based Bayesian deep learning algorithm called\nEM-TDAMP to avoid the drawbacks of traditional stochastic gradient descent\n(SGD) based learning algorithms and regularization-based model compression\nmethods. Specifically, we formulate the problem of DNN learning and compression\nas a sparse Bayesian inference problem, in which group sparse prior is employed\nto achieve structured model compression. Then, we propose an expectation\nmaximization (EM) framework to estimate posterior distributions for parameters\n(E-step) and update hyperparameters (M-step), where the E-step is realized by a\nnewly proposed turbo deep approximate message passing (TDAMP) algorithm. We\nfurther extend the EM-TDAMP and propose a novel Bayesian federated learning\nframework, in which and the clients perform TDAMP to efficiently calculate the\nlocal posterior distributions based on the local data, and the central server\nfirst aggregates the local posterior distributions to update the global\nposterior distributions and then update hyperparameters based on EM to\naccelerate convergence. We detail the application of EM-TDAMP to Boston housing\nprice prediction and handwriting recognition, and present extensive numerical\nresults to demonstrate the advantages of EM-TDAMP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07366v2",
    "published_date": "2024-02-12 01:47:06 UTC",
    "updated_date": "2024-06-09 11:44:16 UTC"
  },
  {
    "arxiv_id": "2407.04700v1",
    "title": "The Physics of Learning: From Autoencoders to Truly Autonomous Learning Machines",
    "authors": [
      "Alex Ushveridze"
    ],
    "abstract": "The fact that accurately predicted information can serve as an energy source\npaves the way for new approaches to autonomous learning. The energy derived\nfrom a sequence of successful predictions can be recycled as an immediate\nincentive and resource, driving the enhancement of predictive capabilities in\nAI agents. We propose that, through a series of straightforward\nmeta-architectural adjustments, any unsupervised learning apparatus could\nachieve complete independence from external energy sources, evolving into a\nself-sustaining physical system with a strong intrinsic 'drive' for continual\nlearning. This concept, while still purely theoretical, is exemplified through\nthe autoencoder, a quintessential model for unsupervised efficient coding. We\nuse this model to demonstrate how progressive paradigm shifts can profoundly\nalter our comprehension of learning and intelligence. By reconceptualizing\nlearning as an energy-seeking process, we highlight the potential for achieving\ntrue autonomy in learning systems, thereby bridging the gap between algorithmic\nconcepts and physical models of intelligence.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.LG",
      "physics.class-ph"
    ],
    "primary_category": "cs.ET",
    "comment": "17 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.04700v1",
    "published_date": "2024-02-12 01:36:26 UTC",
    "updated_date": "2024-02-12 01:36:26 UTC"
  },
  {
    "arxiv_id": "2402.07350v1",
    "title": "Antagonistic AI",
    "authors": [
      "Alice Cai",
      "Ian Arawjo",
      "Elena L. Glassman"
    ],
    "abstract": "The vast majority of discourse around AI development assumes that\nsubservient, \"moral\" models aligned with \"human values\" are universally\nbeneficial -- in short, that good AI is sycophantic AI. We explore the shadow\nof the sycophantic paradigm, a design space we term antagonistic AI: AI systems\nthat are disagreeable, rude, interrupting, confrontational, challenging, etc.\n-- embedding opposite behaviors or values. Far from being \"bad\" or \"immoral,\"\nwe consider whether antagonistic AI systems may sometimes have benefits to\nusers, such as forcing users to confront their assumptions, build resilience,\nor develop healthier relational boundaries. Drawing from formative explorations\nand a speculative design workshop where participants designed fictional AI\ntechnologies that employ antagonism, we lay out a design space for antagonistic\nAI, articulating potential benefits, design techniques, and methods of\nembedding antagonistic elements into user experience. Finally, we discuss the\nmany ethical challenges of this space and identify three dimensions for the\nresponsible design of antagonistic AI -- consent, context, and framing.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "I.2.0; J.0; K.4.0"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 1 figure, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.07350v1",
    "published_date": "2024-02-12 00:44:37 UTC",
    "updated_date": "2024-02-12 00:44:37 UTC"
  },
  {
    "arxiv_id": "2402.07347v1",
    "title": "Accuracy of TextFooler black box adversarial attacks on 01 loss sign activation neural network ensemble",
    "authors": [
      "Yunzhe Xue",
      "Usman Roshan"
    ],
    "abstract": "Recent work has shown the defense of 01 loss sign activation neural networks\nagainst image classification adversarial attacks. A public challenge to attack\nthe models on CIFAR10 dataset remains undefeated. We ask the following question\nin this study: are 01 loss sign activation neural networks hard to deceive with\na popular black box text adversarial attack program called TextFooler? We study\nthis question on four popular text classification datasets: IMDB reviews, Yelp\nreviews, MR sentiment classification, and AG news classification. We find that\nour 01 loss sign activation network is much harder to attack with TextFooler\ncompared to sigmoid activation cross entropy and binary neural networks. We\nalso study a 01 loss sign activation convolutional neural network with a novel\nglobal pooling step specific to sign activation networks. With this new\nvariation we see a significant gain in adversarial accuracy rendering\nTextFooler practically useless against it. We make our code freely available at\n\\url{https://github.com/zero-one-loss/wordcnn01} and\n\\url{https://github.com/xyzacademic/mlp01example}. Our work here suggests that\n01 loss sign activation networks could be further developed to create fool\nproof models against text adversarial attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07347v1",
    "published_date": "2024-02-12 00:36:34 UTC",
    "updated_date": "2024-02-12 00:36:34 UTC"
  },
  {
    "arxiv_id": "2402.07344v1",
    "title": "Measurement Scheduling for ICU Patients with Offline Reinforcement Learning",
    "authors": [
      "Zongliang Ji",
      "Anna Goldenberg",
      "Rahul G. Krishnan"
    ],
    "abstract": "Scheduling laboratory tests for ICU patients presents a significant\nchallenge. Studies show that 20-40% of lab tests ordered in the ICU are\nredundant and could be eliminated without compromising patient safety. Prior\nwork has leveraged offline reinforcement learning (Offline-RL) to find optimal\npolicies for ordering lab tests based on patient information. However, new ICU\npatient datasets have since been released, and various advancements have been\nmade in Offline-RL methods. In this study, we first introduce a preprocessing\npipeline for the newly-released MIMIC-IV dataset geared toward time-series\ntasks. We then explore the efficacy of state-of-the-art Offline-RL methods in\nidentifying better policies for ICU patient lab test scheduling. Besides\nassessing methodological performance, we also discuss the overall suitability\nand practicality of using Offline-RL frameworks for scheduling laboratory tests\nin ICU settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended Abstract presented at Machine Learning for Health (ML4H)\n  symposium 2023, December 10th, 2023, New Orleans, United States, 11 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.07344v1",
    "published_date": "2024-02-12 00:22:47 UTC",
    "updated_date": "2024-02-12 00:22:47 UTC"
  },
  {
    "arxiv_id": "2402.07342v1",
    "title": "Imagining a Future of Designing with AI: Dynamic Grounding, Constructive Negotiation, and Sustainable Motivation",
    "authors": [
      "Priyan Vaithilingam",
      "Ian Arawjo",
      "Elena L. Glassman"
    ],
    "abstract": "We ideate a future design workflow that involves AI technology. Drawing from\nactivity and communication theory, we attempt to isolate the new value large AI\nmodels can provide design compared to past technologies. We arrive at three\naffordances -- dynamic grounding, constructive negotiation, and sustainable\nmotivation -- that summarize latent qualities of natural language-enabled\nfoundation models that, if explicitly designed for, can support the process of\ndesign. Through design fiction, we then imagine a future interface as a\ndiegetic prototype, the story of Squirrel Game, that demonstrates each of our\nthree affordances in a realistic usage scenario. Our design process,\nterminology, and diagrams aim to contribute to future discussions about the\nrelative affordances of AI technology with regard to collaborating with human\ndesigners.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "J.6; I.2.0; H.5.2"
    ],
    "primary_category": "cs.HC",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.07342v1",
    "published_date": "2024-02-12 00:20:43 UTC",
    "updated_date": "2024-02-12 00:20:43 UTC"
  }
]