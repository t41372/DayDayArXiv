{
  "date": "2024-04-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-11 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习创新，特别是大语言模型（LLMs）的优化、图神经网络（GNNs）的应用、图像生成和强化学习等领域，令人印象深刻的包括 JetMoE 的高效 LLM 训练方法，以及涉及 Google 和知名学者的作品如 RecurrentGemma 等，强调了 AI 在实际应用中的效率和鲁棒性提升。\n\n下面，我将挑选并简要讨论部分关键论文，先优先选取那些具有话题性、创新性和潜在影响的文章（如 LLM 和 GNN 相关），并将相关主题归类快速概述。其他较常规或小众论文（如某些理论模型或特定领域优化）将简略掠过，以控制篇幅。每个条目列出论文标题（中文 + 英文），并保留核心学术术语，清晰描述主要贡献和发现。\n\n### LLM 和 AI 生成模型\n- **JetMoE: Reaching Llama2 Performance with 0.1M Dollars**（中文：用 0.1M 美元达到 Llama2 性能）  \n  这篇论文提出了一种基于稀疏混合专家（SMoE）的 LLM 架构，JetMoE-8B 模型仅用 1.25T 标记和 30,000 H100 GPU 小时训练，就超过了 Llama2-7B 的性能。主要贡献是通过高效训练和激活机制，减少了参数激活量，实现 70% 的推理计算节省，展示了低成本 LLM 训练的潜力。\n\n- **LLM Agents can Autonomously Exploit One-day Vulnerabilities**（中文：LLM 代理自主利用一日漏洞）  \n  作者包括 Richard Fang 等，研究显示 GPT-4 能利用 CVE 描述自主攻击 87% 的关键漏洞。主要发现是 LLM 在网络安全中的双刃剑效应，强调了部署 LLM 时需防范潜在风险。\n\n- **ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models**（中文：基于 LLM 的迭代研究想法生成）  \n  这篇论文引入 ResearchAgent 框架，使用 LLM 生成并迭代研究想法。主要贡献是通过图神经网络和反馈机制，从科学文献中提取洞见，提升了研究效率，适用于跨领域创新。\n\n- **Auctions with LLM Summaries**（中文：使用 LLM 摘要的拍卖系统）  \n  论文设计了一个结合 LLM 和拍卖模块的框架，用于生成多广告摘要。主要发现是通过预测模型实现激励兼容的福利最大化，扩展了传统广告拍卖到 LLM 驱动的格式。\n\n- **Rho-1: Not All Tokens Are What You Need**（中文：Rho-1：并非所有标记都必要）  \n  作者提出 Rho-1 模型，使用选择性语言建模（SLM）训练，仅关注高价值标记。贡献在于显著提升数学任务准确率（如 MATH 数据集），并减少计算开销。\n\n### 强化学习和 GNN 应用\n- **R2 Indicator and Deep Reinforcement Learning Enhanced Adaptive Multi-Objective Evolutionary Algorithm**（中文：R2 指标和深度强化学习增强的自适应多目标进化算法）  \n  这篇论文开发了 R2-RLMOEA 算法，使用双深度 Q 网络选择进化操作符。主要发现是在 CEC09 函数上显著提升优化性能（p<0.001），适用于复杂优化挑战。\n\n- **FPGA Divide-and-Conquer Placement using Deep Reinforcement Learning**（中文：使用深度强化学习的 FPGA 分治放置）  \n  作者使用 RL 最小化布线长度，结合新分解策略。主要贡献是提高了 FPGA 放置效率，实验证明在大型搜索空间中有效。\n\n- **GNN-based Probabilistic Supply and Inventory Predictions in Supply Chain Networks**（中文：基于 GNN 的供应链网络供应和库存概率预测）  \n  论文使用注意力 GNN 预测供应链不确定性。主要发现是通过模拟优化库存，提升了企业盈利和供应链韧性。\n\n- **HGFF: A Deep Reinforcement Learning Framework for Lifetime Maximization in Wireless Sensor Networks**（中文：HGFF：无线传感器网络寿命最大化的深度强化学习框架）  \n  提出 HGFF 框架，使用 GNN 学习网络表示。主要贡献是优化传感器移动路径，减少能耗，适用于动态网络。\n\n### 计算机视觉和图像处理\n- **ControlNet++: Improving Conditional Controls with Consistency Feedback**（中文：ControlNet++：通过一致性反馈改进条件控制）  \n  这篇论文提升了文本到图像扩散模型的控制精度，使用一致性损失优化。主要发现是显著改善图像生成质量（如分割掩码和深度图），并减少计算成本。\n\n- **OpenBias: Open-set Bias Detection in Text-to-Image Generative Models**（中文：OpenBias：文本到图像生成模型的开放集偏差检测）  \n  作者设计了 OpenBias 管道，无需预定义偏差集检测模型偏差。主要贡献是通过 LLM 和视觉问答模型识别新偏差，提升了生成模型的公平性。\n\n- **Self-Supervised Learning of Color Constancy**（中文：自监督学习颜色恒常性）  \n  论文展示神经网络通过自监督学习实现颜色恒常性。主要发现是模拟人类认知发展，生成照明不变表示。\n\n### 机器人学和实际应用\n- **RecurrentGemma: Moving Past Transformers for Efficient Open Language Models**（中文：RecurrentGemma：超越 Transformer 的高效开源语言模型）  \n  Google 团队的作品，使用 Griffin 架构结合线性循环和局部注意力。主要贡献是减少内存使用，提升序列处理效率，性能与 Gemma 相当。\n\n- **Towards a Robust Soft Baby Robot With Rich Interaction Ability**（中文：面向鲁棒软体婴儿机器人的设计）  \n  论文提出混合软硬结构机器人，支持强化学习任务。主要发现是通过冗余传感器和转移学习，提高了机器人在故障下的交互能力。\n\n- **MindBridge: A Cross-Subject Brain Decoding Framework**（中文：MindBridge：跨主体脑解码框架）  \n  作者使用自监督模型实现脑信号解码。主要贡献是通过虚拟投影和 GNN 适配不同个体，实现零样本图像重建。\n\n其他论文，如医疗 AI、供应链优化或特定领域模型（如 6G 切换策略），虽有贡献但相对常规，我将快速掠过：例如，\"Medical mT5\"（多语言医疗 LLM）提升了低资源语言的文本理解，而 \"SurvMamba\"（生存预测模型）使用 Mamba 架构融合多模态数据，仅需简注其在医疗领域的应用潜力。\n\n总之，今天的论文突显了 AI 效率和应用的创新，如 LLM 的低成本训练和 GNN 的网络优化，但也提醒了安全风险。感兴趣的读者可关注 LLM 代理的安全性和 GNN 在实际场景的扩展！（全文控制在简洁范围内，共约 1200 字）",
  "papers": [
    {
      "arxiv_id": "2404.08161v2",
      "title": "R2 Indicator and Deep Reinforcement Learning Enhanced Adaptive Multi-Objective Evolutionary Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Farajollah Tahernezhad-Javazm",
        "Debbie Rankin",
        "Naomi Du Bois",
        "Alice E. Smith",
        "Damien Coyle"
      ],
      "abstract": "Choosing an appropriate optimization algorithm is essential to achieving\nsuccess in optimization challenges. Here we present a new evolutionary\nalgorithm structure that utilizes a reinforcement learning-based agent aimed at\naddressing these issues. The agent employs a double deep q-network to choose a\nspecific evolutionary operator based on feedback it receives from the\nenvironment during optimization. The algorithm's structure contains five\nsingle-objective evolutionary algorithm operators. This single-objective\nstructure is transformed into a multi-objective one using the R2 indicator.\nThis indicator serves two purposes within our structure: first, it renders the\nalgorithm multi-objective, and second, provides a means to evaluate each\nalgorithm's performance in each generation to facilitate constructing the\nreinforcement learning-based reward function. The proposed R2-reinforcement\nlearning multi-objective evolutionary algorithm (R2-RLMOEA) is compared with\nsix other multi-objective algorithms that are based on R2 indicators. These six\nalgorithms include the operators used in R2-RLMOEA as well as an R2\nindicator-based algorithm that randomly selects operators during optimization.\nWe benchmark performance using the CEC09 functions, with performance measured\nby inverted generational distance and spacing. The R2-RLMOEA algorithm\noutperforms all other algorithms with strong statistical significance (p<0.001)\nwhen compared with the average spacing metric across all ten benchmarks.",
      "tldr_zh": "本研究提出了一种名为 R2-RLMOEA 的自适应多目标进化算法，通过 Deep Reinforcement Learning 增强优化性能。算法使用 Double Deep Q-Network 作为代理，根据环境反馈动态选择五个单目标进化算法算子，并借助 R2 Indicator 将其转化为多目标框架，同时利用 R2 Indicator 评估性能并构建强化学习奖励函数。在 CEC09 functions 的基准测试中，R2-RLMOEA 与其他六种基于 R2 Indicator 的算法比较，使用 Inverted Generational Distance 和 Spacing 指标，结果显示其在 Spacing 指标上显著优于其他算法（p<0.001）。该方法为优化挑战提供了更高效的自适应策略。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08161v2",
      "published_date": "2024-04-11 23:50:30 UTC",
      "updated_date": "2024-04-17 08:23:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:26:58.712913"
    },
    {
      "arxiv_id": "2404.08144v2",
      "title": "LLM Agents can Autonomously Exploit One-day Vulnerabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Fang",
        "Rohan Bindu",
        "Akul Gupta",
        "Daniel Kang"
      ],
      "abstract": "LLMs have becoming increasingly powerful, both in their benign and malicious\nuses. With the increase in capabilities, researchers have been increasingly\ninterested in their ability to exploit cybersecurity vulnerabilities. In\nparticular, recent work has conducted preliminary studies on the ability of LLM\nagents to autonomously hack websites. However, these studies are limited to\nsimple vulnerabilities.\n  In this work, we show that LLM agents can autonomously exploit one-day\nvulnerabilities in real-world systems. To show this, we collected a dataset of\n15 one-day vulnerabilities that include ones categorized as critical severity\nin the CVE description. When given the CVE description, GPT-4 is capable of\nexploiting 87% of these vulnerabilities compared to 0% for every other model we\ntest (GPT-3.5, open-source LLMs) and open-source vulnerability scanners (ZAP\nand Metasploit). Fortunately, our GPT-4 agent requires the CVE description for\nhigh performance: without the description, GPT-4 can exploit only 7% of the\nvulnerabilities. Our findings raise questions around the widespread deployment\nof highly capable LLM agents.",
      "tldr_zh": "本文研究了LLM Agents自主利用one-day vulnerabilities的能力，收集了15个真实系统中的关键严重性CVE数据集。研究发现，当提供CVE描述时，GPT-4能成功利用87%的漏洞，而GPT-3.5、开源LLMs以及扫描工具如ZAP和Metasploit则完全失败；若无CVE描述，GPT-4的成功率仅为7%。这些结果突显了高度能力LLM Agents的安全风险，并引发了对其广泛部署的潜在担忧。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08144v2",
      "published_date": "2024-04-11 22:07:19 UTC",
      "updated_date": "2024-04-17 04:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:27:10.651550"
    },
    {
      "arxiv_id": "2404.08127v1",
      "title": "Self-Supervised Learning of Color Constancy",
      "title_zh": "自监督学习颜色恒常性",
      "authors": [
        "Markus R. Ernst",
        "Francisco M. López",
        "Arthur Aubret",
        "Roland W. Fleming",
        "Jochen Triesch"
      ],
      "abstract": "Color constancy (CC) describes the ability of the visual system to perceive\nan object as having a relatively constant color despite changes in lighting\nconditions. While CC and its limitations have been carefully characterized in\nhumans, it is still unclear how the visual system acquires this ability during\ndevelopment. Here, we present a first study showing that CC develops in a\nneural network trained in a self-supervised manner through an invariance\nlearning objective. During learning, objects are presented under changing\nilluminations, while the network aims to map subsequent views of the same\nobject onto close-by latent representations. This gives rise to representations\nthat are largely invariant to the illumination conditions, offering a plausible\nexample of how CC could emerge during human cognitive development via a form of\nself-supervised learning.",
      "tldr_zh": "该研究探讨了颜色恒常性（Color Constancy），即视觉系统在光照变化下保持物体颜色相对恒定的能力，并首次展示了通过自监督学习（self-supervised learning）如何使神经网络获得这一能力。研究采用不变性学习目标（invariance learning objective），让网络在不同光照条件下处理同一物体的后续视图，并将这些视图映射到相似的潜在表示，从而实现对光照的鲁棒性。结果表明，这种方法为颜色恒常性在人类认知发展中的出现提供了可信的自监督学习机制。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 5 figures, submitted to the IEEE International Conference on\n  Development and Learning (ICDL 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.08127v1",
      "published_date": "2024-04-11 21:07:38 UTC",
      "updated_date": "2024-04-11 21:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:27:22.063282"
    },
    {
      "arxiv_id": "2404.08126v1",
      "title": "Auctions with LLM Summaries",
      "title_zh": "翻译失败",
      "authors": [
        "Kumar Avinava Dubey",
        "Zhe Feng",
        "Rahul Kidambi",
        "Aranyak Mehta",
        "Di Wang"
      ],
      "abstract": "We study an auction setting in which bidders bid for placement of their\ncontent within a summary generated by a large language model (LLM), e.g., an ad\nauction in which the display is a summary paragraph of multiple ads. This\ngeneralizes the classic ad settings such as position auctions to an LLM\ngenerated setting, which allows us to handle general display formats. We\npropose a novel factorized framework in which an auction module and an LLM\nmodule work together via a prediction model to provide welfare maximizing\nsummary outputs in an incentive compatible manner. We provide a theoretical\nanalysis of this framework and synthetic experiments to demonstrate the\nfeasibility and validity of the system together with welfare comparisons.",
      "tldr_zh": "该研究探讨了在大型语言模型(LLM)生成的摘要中进行拍卖的设置，例如将多个广告整合进一个摘要段落，从而扩展了经典广告拍卖如位置拍卖的适用范围。论文提出一个新颖的因子化框架，由拍卖模块和LLM模块通过预测模型合作，生成最大化福利的摘要输出，同时确保激励兼容性(incentive compatible)。通过理论分析和合成实验，证明了该框架的可行性、有效性，并进行了福利比较。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08126v1",
      "published_date": "2024-04-11 21:05:56 UTC",
      "updated_date": "2024-04-11 21:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:27:33.926576"
    },
    {
      "arxiv_id": "2404.08113v1",
      "title": "Predictive Handover Strategy in 6G and Beyond: A Deep and Transfer Learning Approach",
      "title_zh": "6G及以后中的预测性切换策略：一种深度学习和迁移学习方法",
      "authors": [
        "Ioannis Panitsas",
        "Akrit Mudvari",
        "Ali Maatouk",
        "Leandros Tassiulas"
      ],
      "abstract": "Next-generation cellular networks will evolve into more complex and\nvirtualized systems, employing machine learning for enhanced optimization and\nleveraging higher frequency bands and denser deployments to meet varied service\ndemands. This evolution, while bringing numerous advantages, will also pose\nchallenges, especially in mobility management, as it will increase the overall\nnumber of handovers due to smaller coverage areas and the higher signal\nattenuation. To address these challenges, we propose a deep learning based\nalgorithm for predicting the future serving cell utilizing sequential user\nequipment measurements to minimize the handover failures and interruption time.\nOur algorithm enables network operators to dynamically adjust handover\ntriggering events or incorporate UAV base stations for enhanced coverage and\ncapacity, optimizing network objectives like load balancing and energy\nefficiency through transfer learning techniques. Our framework complies with\nthe O-RAN specifications and can be deployed in a Near-Real-Time RAN\nIntelligent Controller as an xApp leveraging the E2SM-KPM service model. The\nevaluation results demonstrate that our algorithm achieves a 92% accuracy in\npredicting future serving cells with high probability. Finally, by utilizing\ntransfer learning, our algorithm significantly reduces the retraining time by\n91% and 77% when new handover trigger decisions or UAV base stations are\nintroduced to the network dynamically.",
      "tldr_zh": "本文针对6G及以后网络中，移动性管理面临的handover次数增加问题，提出一种基于深度学习的预测算法，利用连续的用户设备测量序列来预测未来服务小区，从而最小化handover失败和中断时间。该算法结合transfer learning技术，允许动态调整handover触发事件或引入UAV基站，以优化网络目标如负载均衡和能源效率，并符合O-RAN规范，可部署在Near-Real-Time RAN Intelligent Controller作为xApp。实验结果显示，该算法的预测准确率达到92%，并通过transfer learning将重新训练时间减少91%和77%。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08113v1",
      "published_date": "2024-04-11 20:30:36 UTC",
      "updated_date": "2024-04-11 20:30:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:27:46.936881"
    },
    {
      "arxiv_id": "2404.13061v1",
      "title": "FPGA Divide-and-Conquer Placement using Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shang Wang",
        "Deepak Ranganatha Sastry Mamillapalli",
        "Tianpei Yang",
        "Matthew E. Taylor"
      ],
      "abstract": "This paper introduces the problem of learning to place logic blocks in\nField-Programmable Gate Arrays (FPGAs) and a learning-based method. In contrast\nto previous search-based placement algorithms, we instead employ Reinforcement\nLearning (RL) with the goal of minimizing wirelength. In addition to our\npreliminary learning results, we also evaluated a novel decomposition to\naddress the nature of large search space when placing many blocks on a\nchipboard. Empirical experiments evaluate the effectiveness of the learning and\ndecomposition paradigms on FPGA placement tasks.",
      "tldr_zh": "这篇论文提出了使用深度强化学习(Deep Reinforcement Learning)来解决Field-Programmable Gate Arrays (FPGAs)中逻辑块放置的问题，以最小化wirelength。不同于传统的基于搜索的算法，该方法结合了一个新颖的Divide-and-Conquer分解策略，以应对放置大量块时的庞大搜索空间。通过实证实验，研究者评估了学习和分解范式的有效性，在FPGA放置任务中展示了显著的性能改进。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "accepted by ISEDA2024",
      "pdf_url": "http://arxiv.org/pdf/2404.13061v1",
      "published_date": "2024-04-11 20:29:15 UTC",
      "updated_date": "2024-04-11 20:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:27:57.992985"
    },
    {
      "arxiv_id": "2404.08111v1",
      "title": "S3Editor: A Sparse Semantic-Disentangled Self-Training Framework for Face Video Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Guangzhi Wang",
        "Tianyi Chen",
        "Kamran Ghasedi",
        "HsiangTao Wu",
        "Tianyu Ding",
        "Chris Nuesmeyer",
        "Ilya Zharkov",
        "Mohan Kankanhalli",
        "Luming Liang"
      ],
      "abstract": "Face attribute editing plays a pivotal role in various applications. However,\nexisting methods encounter challenges in achieving high-quality results while\npreserving identity, editing faithfulness, and temporal consistency. These\nchallenges are rooted in issues related to the training pipeline, including\nlimited supervision, architecture design, and optimization strategy. In this\nwork, we introduce S3Editor, a Sparse Semantic-disentangled Self-training\nframework for face video editing. S3Editor is a generic solution that\ncomprehensively addresses these challenges with three key contributions.\nFirstly, S3Editor adopts a self-training paradigm to enhance the training\nprocess through semi-supervision. Secondly, we propose a semantic disentangled\narchitecture with a dynamic routing mechanism that accommodates diverse editing\nrequirements. Thirdly, we present a structured sparse optimization schema that\nidentifies and deactivates malicious neurons to further disentangle impacts\nfrom untarget attributes. S3Editor is model-agnostic and compatible with\nvarious editing approaches. Our extensive qualitative and quantitative results\naffirm that our approach significantly enhances identity preservation, editing\nfidelity, as well as temporal consistency.",
      "tldr_zh": "该研究提出 S3Editor，一种稀疏语义解耦（Sparse Semantic-Disentangled）自训练框架，用于面部视频编辑，以解决现有方法在身份保留、编辑忠实度和时间一致性方面的挑战。框架采用自训练范式，通过半监督方式增强训练过程；引入语义解耦架构与动态路由机制，适应多样化的编辑需求；并运用结构化稀疏优化方案，识别并停用恶意神经元以进一步减少无关属性的影响。S3Editor 作为模型无关的通用解决方案，在定性和定量实验中显著提高了身份保留、编辑保真度和时间一致性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08111v1",
      "published_date": "2024-04-11 20:25:26 UTC",
      "updated_date": "2024-04-11 20:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:28:10.511017"
    },
    {
      "arxiv_id": "2404.16053v1",
      "title": "Human Latency Conversational Turns for Spoken Avatar Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Derek Jacoby",
        "Tianyi Zhang",
        "Aanchan Mohan",
        "Yvonne Coady"
      ],
      "abstract": "A problem with many current Large Language Model (LLM) driven spoken\ndialogues is the response time. Some efforts such as Groq address this issue by\nlightning fast processing of the LLM, but we know from the cognitive psychology\nliterature that in human-to-human dialogue often responses occur prior to the\nspeaker completing their utterance. No amount of delay for LLM processing is\nacceptable if we wish to maintain human dialogue latencies. In this paper, we\ndiscuss methods for understanding an utterance in close to real time and\ngenerating a response so that the system can comply with human-level\nconversational turn delays. This means that the information content of the\nfinal part of the speaker's utterance is lost to the LLM. Using the Google\nNaturalQuestions (NQ) database, our results show GPT-4 can effectively fill in\nmissing context from a dropped word at the end of a question over 60% of the\ntime. We also provide some examples of utterances and the impacts of this\ninformation loss on the quality of LLM response in the context of an avatar\nthat is currently under development. These results indicate that a simple\nclassifier could be used to determine whether a question is semantically\ncomplete, or requires a filler phrase to allow a response to be generated\nwithin human dialogue time constraints.",
      "tldr_zh": "本论文探讨了LLM驱动的口语对话系统（如Spoken Avatar Systems）中的响应延迟问题，强调为了匹配人类对话的即时性（如在说话者完成语句前响应），需要实时理解话语并接受部分信息丢失。研究者使用Google NaturalQuestions (NQ)数据库进行实验，发现GPT-4在60%以上的情况下能有效填补语句末尾丢失的上下文，从而生成高质量响应。结果表明，通过一个简单分类器判断问题是否语义完整或需要填充短语，可以实现符合人类对话延迟的系统，为开发可信任的对话头像奠定基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16053v1",
      "published_date": "2024-04-11 20:20:48 UTC",
      "updated_date": "2024-04-11 20:20:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:28:22.504841"
    },
    {
      "arxiv_id": "2406.11863v1",
      "title": "The Transformation Risk-Benefit Model of Artificial Intelligence: Balancing Risks and Benefits Through Practical Solutions and Use Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Fulton",
        "Diane Fulton",
        "Nate Hayes",
        "Susan Kaplan"
      ],
      "abstract": "This paper summarizes the most cogent advantages and risks associated with\nArtificial Intelligence from an in-depth review of the literature. Then the\nauthors synthesize the salient risk-related models currently being used in AI,\ntechnology and business-related scenarios. Next, in view of an updated context\nof AI along with theories and models reviewed and expanded constructs, the\nwriters propose a new framework called \"The Transformation Risk-Benefit Model\nof Artificial Intelligence\" to address the increasing fears and levels of AI\nrisk. Using the model characteristics, the article emphasizes practical and\ninnovative solutions where benefits outweigh risks and three use cases in\nhealthcare, climate change/environment and cyber security to illustrate unique\ninterplay of principles, dimensions and processes of this powerful AI\ntransformational model.",
      "tldr_zh": "这篇论文通过文献综述总结了人工智能(Artificial Intelligence)的主要优势和风险，并综合现有风险相关模型。作者提出\"The Transformation Risk-Benefit Model of Artificial Intelligence\"框架，以应对AI风险的担忧，并基于更新上下文扩展相关理论。文章强调实际创新解决方案使益处大于风险，并通过医疗、气候变化/环境和网络安全三个用例，展示该模型的原理、维度和过程。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "00-02, 01-02, 03-02, 68T320, 68T37, 68Q32, 93C85, 93C95",
        "A.0; H.1.1; H.1.2; I.2.0; I.2.1; J.4; K.4.2; K.4.3; K.6.0"
      ],
      "primary_category": "cs.CY",
      "comment": "22 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.11863v1",
      "published_date": "2024-04-11 19:19:57 UTC",
      "updated_date": "2024-04-11 19:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:28:33.452200"
    },
    {
      "arxiv_id": "2404.08093v2",
      "title": "Towards a Robust Soft Baby Robot With Rich Interaction Ability for Advanced Machine Learning Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Mohannad Alhakami",
        "Dylan R. Ashley",
        "Joel Dunham",
        "Yanning Dai",
        "Francesco Faccio",
        "Eric Feron",
        "Jürgen Schmidhuber"
      ],
      "abstract": "Advanced machine learning algorithms require platforms that are extremely\nrobust and equipped with rich sensory feedback to handle extensive\ntrial-and-error learning without relying on strong inductive biases.\nTraditional robotic designs, while well-suited for their specific use cases,\nare often fragile when used with these algorithms. To address this gap -- and\ninspired by the vision of enabling curiosity-driven baby robots -- we present a\nnovel robotic limb designed from scratch. Our design has a hybrid soft-hard\nstructure, high redundancy with rich non-contact sensors (exclusively cameras),\nand easily replaceable failure points. Proof-of-concept experiments using two\ncontemporary reinforcement learning algorithms on a physical prototype\ndemonstrate that our design is able to succeed in a simple target-finding task\neven under simulated sensor failures, all with minimal human oversight during\nextended learning periods. We believe this design represents a concrete step\ntoward more tailored robotic designs for achieving general-purpose, generally\nintelligent robots.",
      "tldr_zh": "该研究针对先进机器学习算法的需求，提出了一种新型鲁棒软体婴儿机器人设计，该机器人具备混合软硬结构、高冗余以及丰富的非接触传感器（如仅用摄像头），并设有易更换故障点，以支持广泛的试错学习和好奇心驱动交互。设计灵感来源于好奇心驱动的婴儿机器人愿景，旨在克服传统机器人设计的脆弱性。实验使用两个当代强化学习算法在物理原型上验证了其性能，在简单目标寻找任务中，即使模拟传感器故障，该机器人也能成功完成任务，且仅需最小人类监督。该创新设计标志着朝着通用智能机器人发展的关键一步。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.9; I.2.6"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages in main text + 2 pages of references, 8 figures in main text,\n  1 table in main text; source code available at\n  https://github.com/dylanashley/robot-limb-testai",
      "pdf_url": "http://arxiv.org/pdf/2404.08093v2",
      "published_date": "2024-04-11 19:15:45 UTC",
      "updated_date": "2024-12-04 14:45:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:28:47.202890"
    },
    {
      "arxiv_id": "2404.08092v1",
      "title": "Data-Augmentation-Based Dialectal Adaptation for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Fahim Faisal",
        "Antonios Anastasopoulos"
      ],
      "abstract": "This report presents GMUNLP's participation to the Dialect-Copa shared task\nat VarDial 2024, which focuses on evaluating the commonsense reasoning\ncapabilities of large language models (LLMs) on South Slavic micro-dialects.\nThe task aims to assess how well LLMs can handle non-standard dialectal\nvarieties, as their performance on standard languages is already\nwell-established. We propose an approach that combines the strengths of\ndifferent types of language models and leverages data augmentation techniques\nto improve task performance on three South Slavic dialects: Chakavian,\nCherkano, and Torlak. We conduct experiments using a language-family-focused\nencoder-based model (BERTi\\'c) and a domain-agnostic multilingual model\n(AYA-101). Our results demonstrate that the proposed data augmentation\ntechniques lead to substantial performance gains across all three test datasets\nin the open-source model category. This work highlights the practical utility\nof data augmentation and the potential of LLMs in handling non-standard\ndialectal varieties, contributing to the broader goal of advancing natural\nlanguage understanding in low-resource and dialectal settings.\nCode:https://github.com/ffaisal93/dialect_copa",
      "tldr_zh": "本研究报告了 GMUNLP 在 VarDial 2024 Dialect-Copa 共享任务中的参与，旨在评估大型语言模型 (LLMs) 在南斯拉夫微方言（如 Chakavian、Cherkano 和 Torlak）上的常识推理能力。研究提出了一种结合数据增强技术的方法，利用语言家族导向模型 (BERTi'c) 和多语言模型 (AYA-101)，通过数据增强来提升模型对非标准方言的适应性。实验结果显示，该方法在开源模型类别中显著提高了三个方言数据集的性能，突显了数据增强在低资源和方言环境中的实用价值，并为推进自然语言理解做出了贡献。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08092v1",
      "published_date": "2024-04-11 19:15:32 UTC",
      "updated_date": "2024-04-11 19:15:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:29:00.251914"
    },
    {
      "arxiv_id": "2404.08710v2",
      "title": "Do Large Language Models Learn Human-Like Strategic Preferences?",
      "title_zh": "大语言模型是否学习了类似人类的战略偏好？",
      "authors": [
        "Jesse Roberts",
        "Kyle Moore",
        "Doug Fisher"
      ],
      "abstract": "In this paper, we evaluate whether LLMs learn to make human-like preference\njudgements in strategic scenarios as compared with known empirical results.\nSolar and Mistral are shown to exhibit stable value-based preference consistent\nwith humans and exhibit human-like preference for cooperation in the prisoner's\ndilemma (including stake-size effect) and traveler's dilemma (including\npenalty-size effect). We establish a relationship between model size,\nvalue-based preference, and superficiality. Finally, results here show that\nmodels tending to be less brittle have relied on sliding window attention\nsuggesting a potential link. Additionally, we contribute a novel method for\nconstructing preference relations from arbitrary LLMs and support for a\nhypothesis regarding human behavior in the traveler's dilemma.",
      "tldr_zh": "这篇论文评估大型语言模型 (LLMs) 是否在战略场景中学习与人类相似的偏好判断，通过比较 Solar 和 Mistral 模型的表现与实证结果。研究发现，这些模型在囚徒困境 (prisoner's dilemma) 和旅行者困境 (traveler's dilemma) 中显示出稳定的价值-based 偏好，与人类合作倾向一致，包括 stake-size effect 和 penalty-size effect。论文还探讨了模型大小与偏好的关系，表明使用 sliding window attention 的模型更不易脆弱，并贡献了一种从任意 LLMs 构建偏好关系的新方法，支持了人类在 traveler's dilemma 中的行为假设。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08710v2",
      "published_date": "2024-04-11 19:13:24 UTC",
      "updated_date": "2024-10-02 17:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:29:12.983779"
    },
    {
      "arxiv_id": "2404.08080v1",
      "title": "Variance-reduced Zeroth-Order Methods for Fine-Tuning Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tanmay Gautam",
        "Youngsuk Park",
        "Hao Zhou",
        "Parameswaran Raman",
        "Wooseok Ha"
      ],
      "abstract": "Fine-tuning language models (LMs) has demonstrated success in a wide array of\ndownstream tasks. However, as LMs are scaled up, the memory requirements for\nbackpropagation become prohibitively high. Zeroth-order (ZO) optimization\nmethods can leverage memory-efficient forward passes to estimate gradients.\nMore recently, MeZO, an adaptation of ZO-SGD, has been shown to consistently\noutperform zero-shot and in-context learning when combined with suitable task\nprompts. In this work, we couple ZO methods with variance reduction techniques\nto enhance stability and convergence for inference-based LM fine-tuning. We\nintroduce Memory-Efficient Zeroth-Order Stochastic Variance-Reduced Gradient\n(MeZO-SVRG) and demonstrate its efficacy across multiple LM fine-tuning tasks,\neliminating the reliance on task-specific prompts. Evaluated across a range of\nboth masked and autoregressive LMs on benchmark GLUE tasks, MeZO-SVRG\noutperforms MeZO with up to 20% increase in test accuracies in both full- and\npartial-parameter fine-tuning settings. MeZO-SVRG benefits from reduced\ncomputation time as it often surpasses MeZO's peak test accuracy with a\n$2\\times$ reduction in GPU-hours. MeZO-SVRG significantly reduces the required\nmemory footprint compared to first-order SGD, i.e. by $2\\times$ for\nautoregressive models. Our experiments highlight that MeZO-SVRG's memory\nsavings progressively improve compared to SGD with larger batch sizes.",
      "tldr_zh": "这篇论文提出了一种基于 Variance-Reduced Zeroth-Order Methods 的方法，用于微调语言模型 (LMs)，以解决传统反向传播的高内存需求问题。作者引入了 Memory-Efficient Zeroth-Order Stochastic Variance-Reduced Gradient (MeZO-SVRG)，将 Zeroth-Order (ZO) 优化与方差减少技术结合，提升了稳定性、收敛性和性能，同时消除了对任务特定提示的依赖。在 GLUE 基准任务上，MeZO-SVRG 比 MeZO 提高了多达 20% 的测试准确率，并实现了计算时间减少 2 倍（GPU 小时）和内存占用降低 2 倍（相较于 SGD），尤其在大批量设置下优势更显著。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 25 tables, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.08080v1",
      "published_date": "2024-04-11 18:35:49 UTC",
      "updated_date": "2024-04-11 18:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:29:24.644780"
    },
    {
      "arxiv_id": "2404.08078v1",
      "title": "SQBC: Active Learning using LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Sylvius Wagner",
        "Maike Behrendt",
        "Marc Ziegele",
        "Stefan Harmeling"
      ],
      "abstract": "Stance detection is an important task for many applications that analyse or\nsupport online political discussions. Common approaches include fine-tuning\ntransformer based models. However, these models require a large amount of\nlabelled data, which might not be available. In this work, we present two\ndifferent ways to leverage LLM-generated synthetic data to train and improve\nstance detection agents for online political discussions: first, we show that\naugmenting a small fine-tuning dataset with synthetic data can improve the\nperformance of the stance detection model. Second, we propose a new active\nlearning method called SQBC based on the \"Query-by-Comittee\" approach. The key\nidea is to use LLM-generated synthetic data as an oracle to identify the most\ninformative unlabelled samples, that are selected for manual labelling.\nComprehensive experiments show that both ideas can improve the stance detection\nperformance. Curiously, we observed that fine-tuning on actively selected\nsamples can exceed the performance of using the full dataset.",
      "tldr_zh": "这篇论文针对在线政治讨论中的立场检测（stance detection）问题，提出利用 LLM 生成的合成数据来提升模型性能，以解决标记数据不足的挑战。具体方法包括：使用合成数据增强小规模微调数据集，以及提出 SQBC 主动学习方法，该方法基于 Query-by-Committee 策略，通过 LLM 生成的合成数据作为 oracle，选择最有信息量的未标记样本进行手动标记。实验结果显示，这两种方法均能显著提高立场检测性能，且 SQBC 主动学习选择的样本微调效果甚至超过了使用完整数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08078v1",
      "published_date": "2024-04-11 18:34:11 UTC",
      "updated_date": "2024-04-11 18:34:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:29:37.147661"
    },
    {
      "arxiv_id": "2404.08068v2",
      "title": "WildGraph: Realistic Graph-based Trajectory Generation for Wildlife",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Al-Lawati",
        "Elsayed Eshra",
        "Prasenjit Mitra"
      ],
      "abstract": "Trajectory generation is an important task in movement studies; it\ncircumvents the privacy, ethical, and technical challenges of collecting real\ntrajectories from the target population. In particular, real trajectories in\nthe wildlife domain are scarce as a result of ethical and environmental\nconstraints of the collection process. In this paper, we consider the problem\nof generating long-horizon trajectories, akin to wildlife migration, based on a\nsmall set of real samples. We propose a hierarchical approach to learn the\nglobal movement characteristics of the real dataset and recursively refine\nlocalized regions. Our solution, WildGraph, discretizes the geographic path\ninto a prototype network of H3 (https://www.uber.com/blog/h3/) regions and\nleverages a recurrent variational auto-encoder to probabilistically generate\npaths over the regions, based on occupancy. WildGraph successfully generates\nrealistic months-long trajectories using a sample size as small as 60.\nExperiments performed on two wildlife migration datasets demonstrate that our\nproposed method improves the generalization of the generated trajectories in\ncomparison to existing work while achieving superior or comparable performance\nin several benchmark metrics. Our code is published on the following\nrepository: https://github.com/aliwister/wildgraph.",
      "tldr_zh": "本研究针对野生动物领域轨迹数据稀缺的伦理和环境挑战，提出了一种名为 WildGraph 的分层方法，用于基于少量真实样本生成 realistic 的长期轨迹，如野生动物迁移路径。WildGraph 通过将地理路径离散化为 H3 区域的原型网络，并利用 recurrent variational auto-encoder 生成基于占用度的概率路径，从而学习全局运动特征并递归细化局部区域。实验结果显示，该方法在使用仅 60 个样本的情况下成功生成数月长的 realistic 轨迹，并在两个野生动物迁移数据集上比现有工作提升了轨迹的泛化能力，并在多个基准指标上表现出色或相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 7 figures, SIGSPATIAL '24",
      "pdf_url": "http://arxiv.org/pdf/2404.08068v2",
      "published_date": "2024-04-11 18:13:21 UTC",
      "updated_date": "2025-02-08 03:20:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:29:47.270754"
    },
    {
      "arxiv_id": "2404.08064v4",
      "title": "The Impact of Speech Anonymization on Pathology and Its Limits",
      "title_zh": "语音匿名化对病理的影响及其限制",
      "authors": [
        "Soroosh Tayebi Arasteh",
        "Tomas Arias-Vergara",
        "Paula Andrea Perez-Toro",
        "Tobias Weise",
        "Kai Packhaeuser",
        "Maria Schuster",
        "Elmar Noeth",
        "Andreas Maier",
        "Seung Hee Yang"
      ],
      "abstract": "Integration of speech into healthcare has intensified privacy concerns due to\nits potential as a non-invasive biomarker containing individual biometric\ninformation. In response, speaker anonymization aims to conceal personally\nidentifiable information while retaining crucial linguistic content. However,\nthe application of anonymization techniques to pathological speech, a critical\narea where privacy is especially vital, has not been extensively examined. This\nstudy investigates anonymization's impact on pathological speech across over\n2,700 speakers from multiple German institutions, focusing on privacy,\npathological utility, and demographic fairness. We explore both\ndeep-learning-based and signal processing-based anonymization methods. We\ndocument substantial privacy improvements across disorders-evidenced by equal\nerror rate increases up to 1933%, with minimal overall impact on utility.\nSpecific disorders such as Dysarthria, Dysphonia, and Cleft Lip and Palate\nexperience minimal utility changes, while Dysglossia shows slight improvements.\nOur findings underscore that the impact of anonymization varies substantially\nacross different disorders. This necessitates disorder-specific anonymization\nstrategies to optimally balance privacy with diagnostic utility. Additionally,\nour fairness analysis reveals consistent anonymization effects across most of\nthe demographics. This study demonstrates the effectiveness of anonymization in\npathological speech for enhancing privacy, while also highlighting the\nimportance of customized and disorder-specific approaches to account for\ninversion attacks.",
      "tldr_zh": "本研究探讨了语音匿名化（speaker anonymization）对病理语音的影响，旨在平衡隐私保护与诊断实用性，基于超过2700名德国说话者的数据。研究比较了深度学习和信号处理方法，评估隐私提升（equal error rate增加高达1933%）、实用性变化（如Dysarthria、Dysphonia和Cleft Lip and Palate影响最小，而Dysglossia略有改善），以及跨人群的公平性。结果显示，匿名化显著增强隐私，但其影响因病症而异，强调需要采用病症特定策略以优化效果并防范逆向攻击（inversion attacks）。这项工作为语音在医疗中的应用提供了重要指导。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Published in Communications Medicine",
      "pdf_url": "http://arxiv.org/pdf/2404.08064v4",
      "published_date": "2024-04-11 18:06:35 UTC",
      "updated_date": "2024-09-20 13:23:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:29:59.943064"
    },
    {
      "arxiv_id": "2404.08061v2",
      "title": "Physics-Enhanced Graph Neural Networks For Soft Sensing in Industrial Internet of Things",
      "title_zh": "翻译失败",
      "authors": [
        "Keivan Faghih Niresi",
        "Hugo Bissig",
        "Henri Baumann",
        "Olga Fink"
      ],
      "abstract": "The Industrial Internet of Things (IIoT) is reshaping manufacturing,\nindustrial processes, and infrastructure management. By fostering new levels of\nautomation, efficiency, and predictive maintenance, IIoT is transforming\ntraditional industries into intelligent, seamlessly interconnected ecosystems.\nHowever, achieving highly reliable IIoT can be hindered by factors such as the\ncost of installing large numbers of sensors, limitations in retrofitting\nexisting systems with sensors, or harsh environmental conditions that may make\nsensor installation impractical. Soft (virtual) sensing leverages mathematical\nmodels to estimate variables from physical sensor data, offering a solution to\nthese challenges. Data-driven and physics-based modeling are the two main\nmethodologies widely used for soft sensing. The choice between these strategies\ndepends on the complexity of the underlying system, with the data-driven\napproach often being preferred when the physics-based inference models are\nintricate and present challenges for state estimation. However, conventional\ndeep learning models are typically hindered by their inability to explicitly\nrepresent the complex interactions among various sensors. To address this\nlimitation, we adopt Graph Neural Networks (GNNs), renowned for their ability\nto effectively capture the complex relationships between sensor measurements.\nIn this research, we propose physics-enhanced GNNs, which integrate principles\nof physics into graph-based methodologies. This is achieved by augmenting\nadditional nodes in the input graph derived from the underlying characteristics\nof the physical processes. Our evaluation of the proposed methodology on the\ncase study of district heating networks reveals significant improvements over\npurely data-driven GNNs, even in the presence of noise and parameter\ninaccuracies.",
      "tldr_zh": "本研究针对工业物联网（IIoT）中的软感知（Soft sensing）问题，提出了一种physics-enhanced Graph Neural Networks（GNNs），通过整合物理原理来提升传感器数据间的复杂交互建模。该方法在输入图中添加基于物理过程的额外节点，解决了传统数据驱动模型无法明确捕捉系统关系的局限性。在区供热网络的案例研究中，即使面对噪声和参数不准确，该框架显著优于纯数据驱动GNNs，展示了更高的性能和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 10 figures. Accepted to IEEE Internet of Things Journal",
      "pdf_url": "http://arxiv.org/pdf/2404.08061v2",
      "published_date": "2024-04-11 18:03:59 UTC",
      "updated_date": "2024-07-25 10:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:30:11.545565"
    },
    {
      "arxiv_id": "2404.08708v2",
      "title": "Multi-scale Topology Optimization using Neural Networks",
      "title_zh": "使用神经网络的多尺度拓扑优化",
      "authors": [
        "Hongrui Chen",
        "Xingchen Liu",
        "Levent Burak Kara"
      ],
      "abstract": "A long-standing challenge is designing multi-scale structures with good\nconnectivity between cells while optimizing each cell to reach close to the\ntheoretical performance limit. We propose a new method for direct multi-scale\ntopology optimization using neural networks. Our approach focuses on inverse\nhomogenization that seamlessly maintains compatibility across neighboring\nmicrostructure cells. Our approach consists of a topology neural network that\noptimizes the microstructure shape and distribution across the design domain as\na continuous field. Each microstructure cell is optimized based on a specified\nelasticity tensor that also accommodates in-plane rotations. The neural network\ntakes as input the local coordinates within a cell to represent the density\ndistribution within a cell, as well as the global coordinates of each cell to\ndesign spatially varying microstructure cells. As such, our approach models an\nn-dimensional multi-scale optimization problem as a 2n-dimensional inverse\nhomogenization problem using neural networks. During the inverse homogenization\nof each unit cell, we extend the boundary of each cell by scaling the input\ncoordinates such that the boundaries of neighboring cells are combined. Inverse\nhomogenization on the combined cell improves connectivity. We demonstrate our\nmethod through the design and optimization of graded multi-scale structures.",
      "tldr_zh": "本研究针对多尺度拓扑优化（multi-scale topology optimization）的挑战，提出了一种使用神经网络的新方法，以确保微结构单元间良好连接并接近理论性能极限。方法通过逆齐次化（inverse homogenization）优化微结构形状和分布，将每个单元基于指定的弹性张量（elasticity tensor）进行优化，同时考虑平面旋转和空间变化。拓扑神经网络以局部坐标表示单元内密度分布，并结合全局坐标，将n维多尺度优化问题建模为2n维逆齐次化问题，通过扩展单元边界来提升连接性。实验演示了该方法在设计和优化分级多尺度结构方面的有效性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08708v2",
      "published_date": "2024-04-11 18:00:22 UTC",
      "updated_date": "2025-02-20 03:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:30:23.748909"
    },
    {
      "arxiv_id": "2404.07990v2",
      "title": "OpenBias: Open-set Bias Detection in Text-to-Image Generative Models",
      "title_zh": "OpenBias: 文本到图像",
      "authors": [
        "Moreno D'Incà",
        "Elia Peruzzo",
        "Massimiliano Mancini",
        "Dejia Xu",
        "Vidit Goel",
        "Xingqian Xu",
        "Zhangyang Wang",
        "Humphrey Shi",
        "Nicu Sebe"
      ],
      "abstract": "Text-to-image generative models are becoming increasingly popular and\naccessible to the general public. As these models see large-scale deployments,\nit is necessary to deeply investigate their safety and fairness to not\ndisseminate and perpetuate any kind of biases. However, existing works focus on\ndetecting closed sets of biases defined a priori, limiting the studies to\nwell-known concepts. In this paper, we tackle the challenge of open-set bias\ndetection in text-to-image generative models presenting OpenBias, a new\npipeline that identifies and quantifies the severity of biases agnostically,\nwithout access to any precompiled set. OpenBias has three stages. In the first\nphase, we leverage a Large Language Model (LLM) to propose biases given a set\nof captions. Secondly, the target generative model produces images using the\nsame set of captions. Lastly, a Vision Question Answering model recognizes the\npresence and extent of the previously proposed biases. We study the behavior of\nStable Diffusion 1.5, 2, and XL emphasizing new biases, never investigated\nbefore. Via quantitative experiments, we demonstrate that OpenBias agrees with\ncurrent closed-set bias detection methods and human judgement.",
      "tldr_zh": "本文提出 OpenBias，一种用于文本到图像生成模型（Text-to-Image Generative Models）的开放集偏见检测管道，能够无须预定义偏见集，即时识别和量化偏见的严重程度。OpenBias 包括三个阶段：首先，使用 Large Language Model (LLM) 从一组标题中提出潜在偏见；其次，利用目标生成模型（如 Stable Diffusion 1.5、2 和 XL）生成图像；最后，通过 Vision Question Answering 模型检测这些偏见的存在和程度。实验结果显示，OpenBias 与现有的封闭集偏见检测方法及人类判断高度一致，并揭示了之前未被调查的新型偏见，为生成模型的安全性和公平性评估提供了新工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 Highlight - Code:\n  https://github.com/Picsart-AI-Research/OpenBias",
      "pdf_url": "http://arxiv.org/pdf/2404.07990v2",
      "published_date": "2024-04-11 17:59:56 UTC",
      "updated_date": "2024-08-05 12:55:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:30:36.448611"
    },
    {
      "arxiv_id": "2404.08031v2",
      "title": "Latent Guard: a Safety Framework for Text-to-image Generation",
      "title_zh": "Latent Guard：文本到图像生成的安全框架",
      "authors": [
        "Runtao Liu",
        "Ashkan Khakzar",
        "Jindong Gu",
        "Qifeng Chen",
        "Philip Torr",
        "Fabio Pizzati"
      ],
      "abstract": "With the ability to generate high-quality images, text-to-image (T2I) models\ncan be exploited for creating inappropriate content. To prevent misuse,\nexisting safety measures are either based on text blacklists, which can be\neasily circumvented, or harmful content classification, requiring large\ndatasets for training and offering low flexibility. Hence, we propose Latent\nGuard, a framework designed to improve safety measures in text-to-image\ngeneration. Inspired by blacklist-based approaches, Latent Guard learns a\nlatent space on top of the T2I model's text encoder, where it is possible to\ncheck the presence of harmful concepts in the input text embeddings. Our\nproposed framework is composed of a data generation pipeline specific to the\ntask using large language models, ad-hoc architectural components, and a\ncontrastive learning strategy to benefit from the generated data. The\neffectiveness of our method is verified on three datasets and against four\nbaselines. Code and data will be shared at https://latentguard.github.io/.",
      "tldr_zh": "该研究针对文本到图像（T2I）生成模型的安全风险，提出了一种名为Latent Guard的框架，以防止生成不适当内容。不同于易被绕过的文本黑名单或需大量数据的有害内容分类方法，Latent Guard在T2I模型的文本编码器上学习一个潜在空间（latent space），用于检测输入文本嵌入中的有害概念。框架结合了大语言模型的数据生成管道、特定架构组件和对比学习策略，在三个数据集上实验验证，与四个基线相比显著提升了安全性和灵活性。作者将代码和数据公开在https://latentguard.github.io/，为T2I生成的安全机制提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted to ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08031v2",
      "published_date": "2024-04-11 17:59:52 UTC",
      "updated_date": "2024-08-18 18:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:30:47.991984"
    },
    {
      "arxiv_id": "2404.07989v3",
      "title": "Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Tang",
        "Ray Zhang",
        "Jiaming Liu",
        "Zoey Guo",
        "Dong Wang",
        "Zhigang Wang",
        "Bin Zhao",
        "Shanghang Zhang",
        "Peng Gao",
        "Hongsheng Li",
        "Xuelong Li"
      ],
      "abstract": "Large foundation models have recently emerged as a prominent focus of\ninterest, attaining superior performance in widespread scenarios. Due to the\nscarcity of 3D data, many efforts have been made to adapt pre-trained\ntransformers from vision to 3D domains. However, such 2D-to-3D approaches are\nstill limited, due to the potential loss of spatial geometries and high\ncomputation cost. More importantly, their frameworks are mainly designed for 2D\nmodels, lacking a general any-to-3D paradigm. In this paper, we introduce\nAny2Point, a parameter-efficient method to empower any-modality large models\n(vision, language, audio) for 3D understanding. Given a frozen transformer from\nany source modality, we propose a 3D-to-any (1D or 2D) virtual projection\nstrategy that correlates the input 3D points to the original 1D or 2D positions\nwithin the source modality. This mechanism enables us to assign each 3D token\nwith a positional encoding paired with the pre-trained model, which avoids 3D\ngeometry loss caused by the true projection and better motivates the\ntransformer for 3D learning with 1D/2D positional priors. Then, within each\ntransformer block, we insert an any-to-3D guided adapter module for\nparameter-efficient fine-tuning. The adapter incorporates prior spatial\nknowledge from the source modality to guide the local feature aggregation of 3D\ntokens, compelling the semantic adaption of any-modality transformers. We\nconduct extensive experiments to showcase the effectiveness and efficiency of\nour method. Code and models are released at\nhttps://github.com/Ivan-Tang-3D/Any2Point.",
      "tldr_zh": "本研究提出 Any2Point，一种参数高效的方法，用于使任何模态的大型模型（如视觉、语言或音频 transformers）高效适应 3D 理解，解决传统 2D-to-3D 方法中空间几何损失和高计算成本的问题。核心机制包括一个 3D-to-any (1D 或 2D) 虚拟投影策略，将输入 3D 点与源模态位置相关联，从而保留 3D 几何信息并利用 1D/2D 位置先验增强学习效果。在每个 transformer 块中，插入 any-to-3D guided adapter 模块，利用源模态的空间知识指导 3D 标记的局部特征聚合，实现语义适应。实验证明，该方法在 3D 任务上表现出色，并提供了开源代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and models are released at\n  https://github.com/Ivan-Tang-3D/Any2Point",
      "pdf_url": "http://arxiv.org/pdf/2404.07989v3",
      "published_date": "2024-04-11 17:59:45 UTC",
      "updated_date": "2024-10-21 10:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:31:02.633126"
    },
    {
      "arxiv_id": "2404.08030v1",
      "title": "Rethinking Artistic Copyright Infringements in the Era of Text-to-Image Generative Models",
      "title_zh": "在文本到图像生成模型时代重新审视艺术版权侵权",
      "authors": [
        "Mazda Moayeri",
        "Samyadeep Basu",
        "Sriram Balasubramanian",
        "Priyatham Kattakinda",
        "Atoosa Chengini",
        "Robert Brauneis",
        "Soheil Feizi"
      ],
      "abstract": "Recent text-to-image generative models such as Stable Diffusion are extremely\nadept at mimicking and generating copyrighted content, raising concerns amongst\nartists that their unique styles may be improperly copied. Understanding how\ngenerative models copy \"artistic style\" is more complex than duplicating a\nsingle image, as style is comprised by a set of elements (or signature) that\nfrequently co-occurs across a body of work, where each individual work may vary\nsignificantly. In our paper, we first reformulate the problem of \"artistic\ncopyright infringement\" to a classification problem over image sets, instead of\nprobing image-wise similarities. We then introduce ArtSavant, a practical\n(i.e., efficient and easy to understand) tool to (i) determine the unique style\nof an artist by comparing it to a reference dataset of works from 372 artists\ncurated from WikiArt, and (ii) recognize if the identified style reappears in\ngenerated images. We leverage two complementary methods to perform artistic\nstyle classification over image sets, includingTagMatch, which is a novel\ninherently interpretable and attributable method, making it more suitable for\nbroader use by non-technical stake holders (artists, lawyers, judges, etc).\nLeveraging ArtSavant, we then perform a large-scale empirical study to provide\nquantitative insight on the prevalence of artistic style copying across 3\npopular text-to-image generative models. Namely, amongst a dataset of prolific\nartists (including many famous ones), only 20% of them appear to have their\nstyles be at a risk of copying via simple prompting of today's popular\ntext-to-image generative models.",
      "tldr_zh": "该论文重新审视了文本到图像生成模型（Text-to-Image Generative Models）时代下的艺术版权侵权问题，强调艺术风格由一组频繁出现的元素（signature）组成，而非单一图像复制。作者将侵权问题转化为图像集的分类任务，并引入ArtSavant工具，通过与WikiArt上372位艺术家的参考数据集比较，来识别艺术家的独特风格并检测其是否出现在生成图像中。ArtSavant采用两种互补方法，包括新颖的可解释方法TagMatch，以方便非技术人员（如艺术家和法官）使用；实证研究显示，在3个流行模型中，仅有20%的知名艺术家风格通过简单提示面临复制风险。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08030v1",
      "published_date": "2024-04-11 17:59:43 UTC",
      "updated_date": "2024-04-11 17:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:31:14.168881"
    },
    {
      "arxiv_id": "2404.07987v4",
      "title": "ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback",
      "title_zh": "ControlNet++：通过高效一致性反馈改进条件控制",
      "authors": [
        "Ming Li",
        "Taojiannan Yang",
        "Huafeng Kuang",
        "Jie Wu",
        "Zhaoning Wang",
        "Xuefeng Xiao",
        "Chen Chen"
      ],
      "abstract": "To enhance the controllability of text-to-image diffusion models, existing\nefforts like ControlNet incorporated image-based conditional controls. In this\npaper, we reveal that existing methods still face significant challenges in\ngenerating images that align with the image conditional controls. To this end,\nwe propose ControlNet++, a novel approach that improves controllable generation\nby explicitly optimizing pixel-level cycle consistency between generated images\nand conditional controls. Specifically, for an input conditional control, we\nuse a pre-trained discriminative reward model to extract the corresponding\ncondition of the generated images, and then optimize the consistency loss\nbetween the input conditional control and extracted condition. A\nstraightforward implementation would be generating images from random noises\nand then calculating the consistency loss, but such an approach requires\nstoring gradients for multiple sampling timesteps, leading to considerable time\nand memory costs. To address this, we introduce an efficient reward strategy\nthat deliberately disturbs the input images by adding noise, and then uses the\nsingle-step denoised images for reward fine-tuning. This avoids the extensive\ncosts associated with image sampling, allowing for more efficient reward\nfine-tuning. Extensive experiments show that ControlNet++ significantly\nimproves controllability under various conditional controls. For example, it\nachieves improvements over ControlNet by 11.1% mIoU, 13.4% SSIM, and 7.6% RMSE,\nrespectively, for segmentation mask, line-art edge, and depth conditions. All\nthe code, models, demo and organized data have been open sourced on our Github\nRepo.",
      "tldr_zh": "本论文提出 ControlNet++，一种改进文本到图像扩散模型可控性的新方法，通过显式优化生成图像与条件控制之间的像素级循环一致性来解决现有方法（如 ControlNet）在图像对齐方面的挑战。具体而言，该方法使用预训练的判别奖励模型提取生成图像的条件，并计算一致性损失，同时引入高效奖励策略，通过添加噪声扰动输入图像并进行单步去噪来减少时间和内存消耗。实验结果显示，ControlNet++ 在各种条件控制下显著提升性能，例如在分割掩码、线条边缘和深度条件下，比 ControlNet 分别提高了 11.1% mIoU、13.4% SSIM 和 7.6% RMSE，并开源了相关代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Camera Ready Version. Project Page:\n  https://liming-ai.github.io/ControlNet_Plus_Plus Code & Data:\n  https://github.com/liming-ai/ControlNet_Plus_Plus",
      "pdf_url": "http://arxiv.org/pdf/2404.07987v4",
      "published_date": "2024-04-11 17:59:09 UTC",
      "updated_date": "2024-11-19 03:23:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:31:25.665810"
    },
    {
      "arxiv_id": "2404.07981v2",
      "title": "Manipulating Large Language Models to Increase Product Visibility",
      "title_zh": "操纵大语言模型以增加产品可见性",
      "authors": [
        "Aounon Kumar",
        "Himabindu Lakkaraju"
      ],
      "abstract": "Large language models (LLMs) are increasingly being integrated into search\nengines to provide natural language responses tailored to user queries.\nCustomers and end-users are also becoming more dependent on these models for\nquick and easy purchase decisions. In this work, we investigate whether\nrecommendations from LLMs can be manipulated to enhance a product's visibility.\nWe demonstrate that adding a strategic text sequence (STS) -- a carefully\ncrafted message -- to a product's information page can significantly increase\nits likelihood of being listed as the LLM's top recommendation. To understand\nthe impact of STS, we use a catalog of fictitious coffee machines and analyze\nits effect on two target products: one that seldom appears in the LLM's\nrecommendations and another that usually ranks second. We observe that the\nstrategic text sequence significantly enhances the visibility of both products\nby increasing their chances of appearing as the top recommendation. This\nability to manipulate LLM-generated search responses provides vendors with a\nconsiderable competitive advantage and has the potential to disrupt fair market\ncompetition. Just as search engine optimization (SEO) revolutionized how\nwebpages are customized to rank higher in search engine results, influencing\nLLM recommendations could profoundly impact content optimization for AI-driven\nsearch services. Code for our experiments is available at\nhttps://github.com/aounon/llm-rank-optimizer.",
      "tldr_zh": "本研究探讨了如何通过操纵大型语言模型 (LLMs) 来提升产品在推荐中的可见性。作者引入了战略文本序列 (STS) — 一个精心设计的消息 — 并将其添加到产品的信息页面，以增加其被 LLMs 列为顶级推荐的可能性。实验使用虚构的咖啡机目录，针对一个很少被推荐的产品和一个通常排第二的产品，结果显示 STS 显著提高了这些产品的顶级推荐概率。这样的操纵方法可能为供应商带来竞争优势，并像搜索引擎优化 (SEO) 一样，扰乱公平市场竞争，深刻影响 AI 驱动搜索服务的内容优化。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07981v2",
      "published_date": "2024-04-11 17:57:32 UTC",
      "updated_date": "2024-09-02 21:29:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:31:37.053950"
    },
    {
      "arxiv_id": "2404.07979v2",
      "title": "LLoCO: Learning Long Contexts Offline",
      "title_zh": "翻译失败",
      "authors": [
        "Sijun Tan",
        "Xiuyu Li",
        "Shishir Patil",
        "Ziyang Wu",
        "Tianjun Zhang",
        "Kurt Keutzer",
        "Joseph E. Gonzalez",
        "Raluca Ada Popa"
      ],
      "abstract": "Processing long contexts remains a challenge for large language models (LLMs)\ndue to the quadratic computational and memory overhead of the self-attention\nmechanism and the substantial KV cache sizes during generation. We propose\nLLoCO, a novel approach to address this problem by learning contexts offline\nthrough context compression and in-domain parameter-efficient finetuning with\nLoRA. Our method enables an LLM to create a concise representation of the\noriginal context and efficiently retrieve relevant information to answer\nquestions accurately. Our approach extends the effective context window of a 4k\ntoken LLaMA2-7B model to handle up to 128k tokens. We evaluate our approach on\nseveral long-context question-answering datasets, demonstrating that LLoCO\nsignificantly outperforms in-context learning while using $30\\times$ fewer\ntokens during inference. LLoCO achieves up to $7.62\\times$ speed-up during\ninference and $11.52\\times$ higher throughput during finetuning, substantially\nreduces the cost of long document question answering. This makes it a promising\nsolution for efficient long context processing. Our code is publicly available\non https://github.com/jeffreysijuntan/lloco.",
      "tldr_zh": "本文提出 LLoCO，一种离线学习长上下文的方法，通过上下文压缩和使用 LoRA 的参数高效微调，帮助大语言模型（LLMs）解决自注意力机制的二次计算开销和 KV cache 问题。LLoCO 能将 4k 标记的 LLaMA2-7B 模型的有效上下文窗口扩展到 128k 标记，并高效检索相关信息以提高问答准确性。在长上下文问答数据集上，该方法比 in-context learning 性能显著提升，使用 30 倍更少的标记，推理速度提升 7.62 倍，微调吞吐量提升 11.52 倍，从而大幅降低长文档处理成本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024. The first two authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2404.07979v2",
      "published_date": "2024-04-11 17:57:22 UTC",
      "updated_date": "2024-10-17 08:54:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:31:51.038892"
    },
    {
      "arxiv_id": "2404.07976v1",
      "title": "Self-supervised Dataset Distillation: A Good Compression Is All You Need",
      "title_zh": "自监督数据集蒸馏：一个好的压缩就是你所需要的全部",
      "authors": [
        "Muxin Zhou",
        "Zeyuan Yin",
        "Shitong Shao",
        "Zhiqiang Shen"
      ],
      "abstract": "Dataset distillation aims to compress information from a large-scale original\ndataset to a new compact dataset while striving to preserve the utmost degree\nof the original data informational essence. Previous studies have predominantly\nconcentrated on aligning the intermediate statistics between the original and\ndistilled data, such as weight trajectory, features, gradient, BatchNorm, etc.\nIn this work, we consider addressing this task through the new lens of model\ninformativeness in the compression stage on the original dataset pretraining.\nWe observe that with the prior state-of-the-art SRe$^2$L, as model sizes\nincrease, it becomes increasingly challenging for supervised pretrained models\nto recover learned information during data synthesis, as the channel-wise mean\nand variance inside the model are flatting and less informative. We further\nnotice that larger variances in BN statistics from self-supervised models\nenable larger loss signals to update the recovered data by gradients, enjoying\nmore informativeness during synthesis. Building on this observation, we\nintroduce SC-DD, a simple yet effective Self-supervised Compression framework\nfor Dataset Distillation that facilitates diverse information compression and\nrecovery compared to traditional supervised learning schemes, further reaps the\npotential of large pretrained models with enhanced capabilities. Extensive\nexperiments are conducted on CIFAR-100, Tiny-ImageNet and ImageNet-1K datasets\nto demonstrate the superiority of our proposed approach. The proposed SC-DD\noutperforms all previous state-of-the-art supervised dataset distillation\nmethods when employing larger models, such as SRe$^2$L, MTT, TESLA, DC, CAFE,\netc., by large margins under the same recovery and post-training budgets. Code\nis available at https://github.com/VILA-Lab/SRe2L/tree/main/SCDD/.",
      "tldr_zh": "该论文提出了一种自监督数据集蒸馏(Self-supervised Dataset Distillation)方法，旨在通过优化原始数据集的压缩阶段来保留更多信息核心。不同于以往专注于对齐中间统计（如权重轨迹或BatchNorm统计）的监督方法，作者观察到自监督模型的BN统计方差更大，能提供更丰富的损失信号，从而提升数据合成和恢复效率。基于此，他们引入了SC-DD框架，利用自监督学习增强大型预训练模型的潜力，并在CIFAR-100、Tiny-ImageNet和ImageNet-1K数据集上实验证明，SC-DD在使用更大模型时大幅优于现有监督方法，如SRe²L、MTT和TESLA等。总之，该方法展示了自监督压缩在数据集蒸馏中的显著优势，为高效数据处理提供了新路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07976v1",
      "published_date": "2024-04-11 17:56:40 UTC",
      "updated_date": "2024-04-11 17:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:32:02.727516"
    },
    {
      "arxiv_id": "2404.07972v2",
      "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Tianbao Xie",
        "Danyang Zhang",
        "Jixuan Chen",
        "Xiaochuan Li",
        "Siheng Zhao",
        "Ruisheng Cao",
        "Toh Jing Hua",
        "Zhoujun Cheng",
        "Dongchan Shin",
        "Fangyu Lei",
        "Yitao Liu",
        "Yiheng Xu",
        "Shuyan Zhou",
        "Silvio Savarese",
        "Caiming Xiong",
        "Victor Zhong",
        "Tao Yu"
      ],
      "abstract": "Autonomous agents that accomplish complex computer tasks with minimal human\ninterventions have the potential to transform human-computer interaction,\nsignificantly enhancing accessibility and productivity. However, existing\nbenchmarks either lack an interactive environment or are limited to\nenvironments specific to certain applications or domains, failing to reflect\nthe diverse and complex nature of real-world computer use, thereby limiting the\nscope of tasks and agent scalability. To address this issue, we introduce\nOSWorld, the first-of-its-kind scalable, real computer environment for\nmultimodal agents, supporting task setup, execution-based evaluation, and\ninteractive learning across various operating systems such as Ubuntu, Windows,\nand macOS. OSWorld can serve as a unified, integrated computer environment for\nassessing open-ended computer tasks that involve arbitrary applications.\nBuilding upon OSWorld, we create a benchmark of 369 computer tasks involving\nreal web and desktop apps in open domains, OS file I/O, and workflows spanning\nmultiple applications. Each task example is derived from real-world computer\nuse cases and includes a detailed initial state setup configuration and a\ncustom execution-based evaluation script for reliable, reproducible evaluation.\nExtensive evaluation of state-of-the-art LLM/VLM-based agents on OSWorld\nreveals significant deficiencies in their ability to serve as computer\nassistants. While humans can accomplish over 72.36% of the tasks, the best\nmodel achieves only 12.24% success, primarily struggling with GUI grounding and\noperational knowledge. Comprehensive analysis using OSWorld provides valuable\ninsights for developing multimodal generalist agents that were not possible\nwith previous benchmarks. Our code, environment, baseline models, and data are\npublicly available at https://os-world.github.io.",
      "tldr_zh": "该研究引入了OSWorld，这是一个可扩展的真实计算机环境，用于评估多模态代理在各种操作系统（如Ubuntu、Windows和macOS）上处理开放式任务的能力。OSWorld支持任务设置、基于执行的评估和交互式学习，并构建了一个包含369个真实世界任务的基准，这些任务涉及网络应用、桌面应用、文件I/O和多应用工作流。实验结果显示，现有LLM/VLM模型在这些任务上的成功率仅为12.24%，远低于人类的72.36%，主要问题在于GUI grounding和操作知识的不足。通过OSWorld的全面分析，为开发更有效的多模态通用代理提供了宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "51 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.07972v2",
      "published_date": "2024-04-11 17:56:05 UTC",
      "updated_date": "2024-05-30 08:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:32:13.812080"
    },
    {
      "arxiv_id": "2404.07965v4",
      "title": "Rho-1: Not All Tokens Are What You Need",
      "title_zh": "Rho-1：并非所有标记都是你需要的",
      "authors": [
        "Zhenghao Lin",
        "Zhibin Gou",
        "Yeyun Gong",
        "Xiao Liu",
        "Yelong Shen",
        "Ruochen Xu",
        "Chen Lin",
        "Yujiu Yang",
        "Jian Jiao",
        "Nan Duan",
        "Weizhu Chen"
      ],
      "abstract": "Previous language model pre-training methods have uniformly applied a\nnext-token prediction loss to all training tokens. Challenging this norm, we\nposit that \"9l training\". Our initial analysis examines token-level training\ndynamics of language model, revealing distinct loss patterns for different\ntokens. Leveraging these insights, we introduce a new language model called\nRho-1. Unlike traditional LMs that learn to predict every next token in a\ncorpus, Rho-1 employs Selective Language Modeling (SLM), which selectively\ntrains on useful tokens that aligned with the desired distribution. This\napproach involves scoring pretraining tokens using a reference model, and then\ntraining the language model with a focused loss on tokens with higher scores.\nWhen continual pretraining on 15B OpenWebMath corpus, Rho-1 yields an absolute\nimprovement in few-shot accuracy of up to 30% in 9 math tasks. After\nfine-tuning, Rho-1-1B and 7B achieved state-of-the-art results of 40.6% and\n51.8% on MATH dataset, respectively - matching DeepSeekMath with only 3% of the\npretraining tokens. Furthermore, when continual pretraining on 80B general\ntokens, Rho-1 achieves 6.8% average enhancement across 15 diverse tasks,\nincreasing both efficiency and performance of the language model pre-training.",
      "tldr_zh": "本论文质疑传统语言模型预训练中对所有 token 应用 next-token prediction loss 的做法，通过分析 token 级训练动态，引入 Rho-1 模型及其 Selective Language Modeling (SLM) 方法。SLM 通过参考模型对预训练 token 进行评分，仅针对高分 token 应用聚焦 loss，从而提高训练效率和针对性。在 15B OpenWebMath 语料上持续预训练后，Rho-1 在 9 个数学任务上提升了高达 30% 的 few-shot accuracy；微调后，Rho-1-1B 和 7B 在 MATH 数据集上分别达到 40.6% 和 51.8% 的最先进结果，仅用 3% 的预训练 token 就匹敌 DeepSeekMath。在 80B 一般 token 上，Rho-1 平均提升 6.8% 跨 15 个多样任务的性能，显著提高了语言模型的效率和整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "First two authors equal contribution",
      "pdf_url": "http://arxiv.org/pdf/2404.07965v4",
      "published_date": "2024-04-11 17:52:01 UTC",
      "updated_date": "2025-01-08 09:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:32:27.251755"
    },
    {
      "arxiv_id": "2404.07956v2",
      "title": "Lyapunov-stable Neural Control for State and Output Feedback: A Novel Formulation",
      "title_zh": "翻译失败",
      "authors": [
        "Lujie Yang",
        "Hongkai Dai",
        "Zhouxing Shi",
        "Cho-Jui Hsieh",
        "Russ Tedrake",
        "Huan Zhang"
      ],
      "abstract": "Learning-based neural network (NN) control policies have shown impressive\nempirical performance in a wide range of tasks in robotics and control.\nHowever, formal (Lyapunov) stability guarantees over the region-of-attraction\n(ROA) for NN controllers with nonlinear dynamical systems are challenging to\nobtain, and most existing approaches rely on expensive solvers such as\nsums-of-squares (SOS), mixed-integer programming (MIP), or satisfiability\nmodulo theories (SMT). In this paper, we demonstrate a new framework for\nlearning NN controllers together with Lyapunov certificates using fast\nempirical falsification and strategic regularizations. We propose a novel\nformulation that defines a larger verifiable region-of-attraction (ROA) than\nshown in the literature, and refines the conventional restrictive constraints\non Lyapunov derivatives to focus only on certifiable ROAs. The Lyapunov\ncondition is rigorously verified post-hoc using branch-and-bound with scalable\nlinear bound propagation-based NN verification techniques. The approach is\nefficient and flexible, and the full training and verification procedure is\naccelerated on GPUs without relying on expensive solvers for SOS, MIP, nor SMT.\nThe flexibility and efficiency of our framework allow us to demonstrate\nLyapunov-stable output feedback control with synthesized NN-based controllers\nand NN-based observers with formal stability guarantees, for the first time in\nliterature. Source code at\nhttps://github.com/Verified-Intelligence/Lyapunov_Stable_NN_Controllers",
      "tldr_zh": "本论文提出了一种新颖的框架，用于学习神经网络 (NN) 控制器及其 Lyapunov 证书，旨在为非线性动态系统提供 Lyapunov 稳定性保证，同时扩展 verifiable region-of-attraction (ROA)。该框架采用快速经验伪证和策略正则化，优化 Lyapunov 导数约束以仅关注可证实的 ROA，并使用 branch-and-bound 结合可扩展的线性边界传播技术进行后验验证，整个过程在 GPUs 上加速，无需依赖昂贵的求解器如 sums-of-squares (SOS)、mixed-integer programming (MIP) 或 satisfiability modulo theories (SMT)。实验结果首次实现了 Lyapunov-stable output feedback control，通过合成的 NN-based controllers 和 NN-based observers，提供正式的稳定性保证，展示了框架的灵活性和高效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07956v2",
      "published_date": "2024-04-11 17:49:15 UTC",
      "updated_date": "2024-06-05 00:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:32:37.332846"
    },
    {
      "arxiv_id": "2404.08707v7",
      "title": "CEM: A Data-Efficient Method for Large Language Models to Continue Evolving From Mistakes",
      "title_zh": "CEM：一种数据高效的方法，用于大型语言模型从错误中持续演",
      "authors": [
        "Haokun Zhao",
        "Haixia Han",
        "Jie Shi",
        "Chengyu Du",
        "Jiaqing Liang",
        "Yanghua Xiao"
      ],
      "abstract": "As world knowledge advances and new task schemas emerge, Continual Learning\n(CL) becomes essential for keeping Large Language Models (LLMs) current and\naddressing their shortcomings. This process typically involves continual\ninstruction tuning (CIT) and continual pre-training (CPT) to enable these\nmodels to adapt to novel tasks and acquire critical knowledge. However,\ncollecting sufficient CPT data and efficiently bridging knowledge gaps remain\nsignificant challenges. Inspired by the 'summarizing mistakes' strategy, we\npropose the Continue Evolving from Mistakes (CEM) method, a data-efficient\napproach aiming to collect CPT data and continually improve LLMs' performance\nthrough iterative evaluation and supplementation with mistake-relevant\nknowledge. To further optimize data usage and mitigate forgetting, we introduce\na novel training paradigm that combines CIT and CPT. Experiments show that CEM\nsubstantially enhances multiple models' performance on both in-domain and\nout-of-domain QA tasks, achieving gains of up to 29.63%. Code and datasets are\navailable on https://anonymous.4open.science/r/cem-BB25.",
      "tldr_zh": "该研究提出了一种数据高效的方法 Continue Evolving from Mistakes (CEM)，旨在帮助 Large Language Models (LLMs) 通过总结错误来实现持续学习（Continual Learning, CL）。CEM 方法通过迭代评估和补充错误相关知识来收集 continual pre-training (CPT) 数据，并引入结合 continual instruction tuning (CIT) 和 CPT 的新型训练范式，以优化数据利用并减少遗忘。实验结果显示，该方法显著提升了多种模型在 in-domain 和 out-of-domain QA 任务上的性能，最高增益达 29.63%。总之，CEM 为 LLMs 的持续演化提供了一个高效、可扩展的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08707v7",
      "published_date": "2024-04-11 17:44:56 UTC",
      "updated_date": "2024-12-16 11:21:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:32:48.740965"
    },
    {
      "arxiv_id": "2404.07942v2",
      "title": "On Unified Prompt Tuning for Request Quality Assurance in Public Code Review",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Chen",
        "Lin Li",
        "Rui Zhang",
        "Peng Liang"
      ],
      "abstract": "Public Code Review (PCR) can be implemented through a Software Question\nAnswering (SQA) community, which facilitates high knowledge dissemination.\nCurrent methods mainly focus on the reviewer's perspective, including finding a\ncapable reviewer, predicting comment quality, and recommending/generating\nreview comments. Our intuition is that satisfying review necessity requests can\nincrease their visibility, which in turn is a prerequisite for better review\nresponses. To this end, we propose a unified framework called UniPCR to\ncomplete developer-based request quality assurance (i.e., predicting request\nnecessity and recommending tags subtask) under a Masked Language Model (MLM).\nSpecifically, we reformulate both subtasks via 1) text prompt tuning, which\nconverts two subtasks into MLM by constructing prompt templates using hard\nprompt; 2) code prefix tuning, which optimizes a small segment of generated\ncontinuous vectors as the prefix of the code representation using soft prompt.\nExperimental results on the Public Code Review dataset for the time span\n2011-2022 demonstrate that our UniPCR framework adapts to the two subtasks and\noutperforms comparable accuracy-based results with state-of-the-art methods for\nrequest quality assurance. These conclusions highlight the effectiveness of our\nunified framework from the developer's perspective in public code review.",
      "tldr_zh": "该论文提出 UniPCR 框架，用于公共代码审查 (Public Code Review) 中的请求质量保障，从开发者视角出发，旨在通过预测请求必要性和推荐标签来提升请求可见性和审阅响应质量。UniPCR 采用统一的提示调整方法，包括文本提示调整 (text prompt tuning) 将子任务转化为 Masked Language Model (MLM) 的提示模板，以及代码前缀调整 (code prefix tuning) 优化代码表示的前缀向量。实验在 2011-2022 年的数据集上表明，该框架在两个子任务上优于现有 state-of-the-art 方法，提高了准确性。这些结果突出了从开发者视角进行统一框架的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "The 29th International Conference on Database Systems for Advanced\n  Applications (DASFAA)",
      "pdf_url": "http://arxiv.org/pdf/2404.07942v2",
      "published_date": "2024-04-11 17:41:28 UTC",
      "updated_date": "2024-04-17 14:04:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:33:03.024762"
    },
    {
      "arxiv_id": "2404.07934v1",
      "title": "Goal Recognition via Linear Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Felipe Meneguzzi",
        "Luísa R. de A. Santos",
        "Ramon Fraga Pereira",
        "André G. Pereira"
      ],
      "abstract": "Goal Recognition is the task by which an observer aims to discern the goals\nthat correspond to plans that comply with the perceived behavior of subject\nagents given as a sequence of observations. Research on Goal Recognition as\nPlanning encompasses reasoning about the model of a planning task, the\nobservations, and the goals using planning techniques, resulting in very\nefficient recognition approaches. In this article, we design novel recognition\napproaches that rely on the Operator-Counting framework, proposing new\nconstraints, and analyze their constraints' properties both theoretically and\nempirically. The Operator-Counting framework is a technique that efficiently\ncomputes heuristic estimates of cost-to-goal using Integer/Linear Programming\n(IP/LP). In the realm of theory, we prove that the new constraints provide\nlower bounds on the cost of plans that comply with observations. We also\nprovide an extensive empirical evaluation to assess how the new constraints\nimprove the quality of the solution, and we found that they are especially\ninformed in deciding which goals are unlikely to be part of the solution. Our\nnovel recognition approaches have two pivotal advantages: first, they employ\nnew IP/LP constraints for efficiently recognizing goals; second, we show how\nthe new IP/LP constraints can improve the recognition of goals under both\npartial and noisy observability.",
      "tldr_zh": "这篇论文提出了基于 Linear Programming 的 Goal Recognition 方法，利用 Operator-Counting 框架设计新约束，以更高效地推断代理行为的潜在目标。研究者证明了这些新约束能提供观察符合计划成本的下界，并在理论和实证分析中展示了它们在排除不可能目标方面的优势。通过广泛实验，方法在部分和噪声观察条件下显著提高了识别质量和效率。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to JAIR April 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07934v1",
      "published_date": "2024-04-11 17:34:35 UTC",
      "updated_date": "2024-04-11 17:34:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:33:13.082192"
    },
    {
      "arxiv_id": "2404.07930v1",
      "title": "Parameter Hierarchical Optimization for Visible-Infrared Person Re-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Zeng YU",
        "Yunxiao Shi"
      ],
      "abstract": "Visible-infrared person re-identification (VI-reID) aims at matching\ncross-modality pedestrian images captured by disjoint visible or infrared\ncameras. Existing methods alleviate the cross-modality discrepancies via\ndesigning different kinds of network architectures. Different from available\nmethods, in this paper, we propose a novel parameter optimizing paradigm,\nparameter hierarchical optimization (PHO) method, for the task of VI-ReID. It\nallows part of parameters to be directly optimized without any training, which\nnarrows the search space of parameters and makes the whole network more easier\nto be trained. Specifically, we first divide the parameters into different\ntypes, and then introduce a self-adaptive alignment strategy (SAS) to\nautomatically align the visible and infrared images through transformation.\nConsidering that features in different dimension have varying importance, we\ndevelop an auto-weighted alignment learning (AAL) module that can automatically\nweight features according to their importance. Importantly, in the alignment\nprocess of SAS and AAL, all the parameters are immediately optimized with\noptimization principles rather than training the whole network, which yields a\nbetter parameter training manner. Furthermore, we establish the cross-modality\nconsistent learning (CCL) loss to extract discriminative person representations\nwith translation consistency. We provide both theoretical justification and\nempirical evidence that our proposed PHO method outperform existing VI-reID\napproaches.",
      "tldr_zh": "这篇论文针对可见光-红外人重新识别(VI-reID)任务，提出了一种新型参数分层优化(PHO)方法，通过将参数分类并直接优化部分参数，缩小搜索空间并简化网络训练过程。PHO 包括自适应对齐策略(SAS)用于自动对齐可见光和红外图像，以及自动加权对齐学习(AAL)模块根据特征重要性进行加权，同时引入跨模态一致学习(CCL)损失来提取判别性的人表示。实验结果和理论分析证明，该方法在 VI-reID 性能上优于现有方法，提供更高效的参数训练方式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07930v1",
      "published_date": "2024-04-11 17:27:39 UTC",
      "updated_date": "2024-04-11 17:27:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:33:26.255057"
    },
    {
      "arxiv_id": "2404.07926v1",
      "title": "Leveraging Large Language Models (LLMs) to Support Collaborative Human-AI Online Risk Data Annotation",
      "title_zh": "利用大语言模型（LLMs）支持协作的人类-AI 在线风险数据标注",
      "authors": [
        "Jinkyung Park",
        "Pamela Wisniewski",
        "Vivek Singh"
      ],
      "abstract": "In this position paper, we discuss the potential for leveraging LLMs as\ninteractive research tools to facilitate collaboration between human coders and\nAI to effectively annotate online risk data at scale. Collaborative human-AI\nlabeling is a promising approach to annotating large-scale and complex data for\nvarious tasks. Yet, tools and methods to support effective human-AI\ncollaboration for data annotation are under-studied. This gap is pertinent\nbecause co-labeling tasks need to support a two-way interactive discussion that\ncan add nuance and context, particularly in the context of online risk, which\nis highly subjective and contextualized. Therefore, we provide some of the\nearly benefits and challenges of using LLMs-based tools for risk annotation and\nsuggest future directions for the HCI research community to leverage LLMs as\nresearch tools to facilitate human-AI collaboration in contextualized online\ndata annotation. Our research interests align very well with the purposes of\nthe LLMs as Research Tools workshop to identify ongoing applications and\nchallenges of using LLMs to work with data in HCI research. We anticipate\nlearning valuable insights from organizers and participants into how LLMs can\nhelp reshape the HCI community's methods for working with data.",
      "tldr_zh": "这篇位置论文探讨了利用 Large Language Models (LLMs) 作为交互式研究工具，以支持人类编码器和 AI 在大规模在线风险数据标注中的协作。论文强调，人类-AI 协作标注是一种有前景的方法，但现有工具和方法尚未充分研究双向互动讨论，尤其是针对高度主观和情境化的在线风险数据。作者总结了基于 LLMs 的工具的早期益处（如添加细微差别和上下文）和挑战（如潜在偏差），并为 Human-Computer Interaction (HCI) 研究社区提出未来方向，以优化 LLMs 在数据处理中的应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "This paper has been peer-reviewed and presented at the \"CHI 2024\n  Workshop on LLMs as Research Tools: Applications and Evaluations in HCI Data\n  Work, May 12, 2024, Honolulu, HI, USA.\"",
      "pdf_url": "http://arxiv.org/pdf/2404.07926v1",
      "published_date": "2024-04-11 17:20:57 UTC",
      "updated_date": "2024-04-11 17:20:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:33:37.697763"
    },
    {
      "arxiv_id": "2404.07919v1",
      "title": "Low-rank Adaptation for Spatio-Temporal Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Weilin Ruan",
        "Wei Chen",
        "Xilin Dang",
        "Jianxiang Zhou",
        "Weichuang Li",
        "Xu Liu",
        "Yuxuan Liang"
      ],
      "abstract": "Spatio-temporal forecasting is crucial in real-world dynamic systems,\npredicting future changes using historical data from diverse locations.\nExisting methods often prioritize the development of intricate neural networks\nto capture the complex dependencies of the data, yet their accuracy fails to\nshow sustained improvement. Besides, these methods also overlook node\nheterogeneity, hindering customized prediction modules from handling diverse\nregional nodes effectively. In this paper, our goal is not to propose a new\nmodel but to present a novel low-rank adaptation framework as an off-the-shelf\nplugin for existing spatial-temporal prediction models, termed ST-LoRA, which\nalleviates the aforementioned problems through node-level adjustments.\nSpecifically, we first tailor a node adaptive low-rank layer comprising\nmultiple trainable low-rank matrices. Additionally, we devise a multi-layer\nresidual fusion stacking module, injecting the low-rank adapters into predictor\nmodules of various models. Across six real-world traffic datasets and six\ndifferent types of spatio-temporal prediction models, our approach minimally\nincreases the parameters and training time of the original models by less than\n4%, still achieving consistent and sustained performance enhancement.",
      "tldr_zh": "本研究针对时空预测(Spatio-Temporal Forecasting)中的问题，指出现有方法虽依赖复杂神经网络却未实现准确率持续提升，并忽略了节点异质性导致的预测不精确。论文提出ST-LoRA，一种新型低秩适配(Low-rank Adaptation)框架，作为现有模型的即插即用插件，通过定制节点自适应低秩层和多层残差融合堆叠模块，实现节点级调整以提升性能。在六个真实交通数据集和六种不同时空预测模型上，ST-LoRA仅将原模型参数和训练时间增加不到4%，却实现了稳定的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07919v1",
      "published_date": "2024-04-11 17:04:55 UTC",
      "updated_date": "2024-04-11 17:04:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:33:48.570824"
    },
    {
      "arxiv_id": "2405.01567v2",
      "title": "CodeFort: Robust Training for Code Generation Models",
      "title_zh": "CodeFort：代码生成模型的鲁棒训练",
      "authors": [
        "Yuhao Zhang",
        "Shiqi Wang",
        "Haifeng Qian",
        "Zijian Wang",
        "Mingyue Shang",
        "Linbo Liu",
        "Sanjay Krishna Gouda",
        "Baishakhi Ray",
        "Murali Krishna Ramanathan",
        "Xiaofei Ma",
        "Anoop Deoras"
      ],
      "abstract": "Code generation models are not robust to small perturbations, which often\nlead to incorrect generations and significantly degrade the performance of\nthese models. Although improving the robustness of code generation models is\ncrucial to enhancing user experience in real-world applications, existing\nresearch efforts do not address this issue. To fill this gap, we propose\nCodeFort, a framework to improve the robustness of code generation models,\ngeneralizing a large variety of code perturbations to enrich the training data\nand enabling various robust training strategies, mixing data augmentation,\nbatch augmentation, adversarial logits pairing, and contrastive learning, all\ncarefully designed to support high-throughput training. Extensive evaluations\nshow that we increase the average robust pass rates of baseline CodeGen models\nfrom 14.79 to 21.74. We notably decrease the robustness drop rate from 95.02%\nto 54.95% against code-syntax perturbations.",
      "tldr_zh": "该论文指出，代码生成模型对小扰动高度敏感，导致生成错误和性能下降，因此提出 CodeFort 框架来提升模型的鲁棒性。CodeFort 通过泛化各种代码扰动来丰富训练数据，并整合数据增强、批量增强、对抗对数配对和对比学习等策略，支持高吞吐量训练。实验结果显示，CodeFort 将基线 CodeGen 模型的平均鲁棒通过率从 14.79% 提高到 21.74%，并将鲁棒性下降率针对代码语法扰动从 95.02% 降至 54.95%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01567v2",
      "published_date": "2024-04-11 17:04:22 UTC",
      "updated_date": "2024-10-28 19:29:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:34:02.650682"
    },
    {
      "arxiv_id": "2404.07917v2",
      "title": "DesignQA: A Multimodal Benchmark for Evaluating Large Language Models' Understanding of Engineering Documentation",
      "title_zh": "DesignQA：一个用于评估大语言模型理解工程文档的多模态基准",
      "authors": [
        "Anna C. Doris",
        "Daniele Grandi",
        "Ryan Tomich",
        "Md Ferdous Alam",
        "Mohammadmehdi Ataei",
        "Hyunmin Cheong",
        "Faez Ahmed"
      ],
      "abstract": "This research introduces DesignQA, a novel benchmark aimed at evaluating the\nproficiency of multimodal large language models (MLLMs) in comprehending and\napplying engineering requirements in technical documentation. Developed with a\nfocus on real-world engineering challenges, DesignQA uniquely combines\nmultimodal data-including textual design requirements, CAD images, and\nengineering drawings-derived from the Formula SAE student competition.\nDifferent from many existing MLLM benchmarks, DesignQA contains\ndocument-grounded visual questions where the input image and input document\ncome from different sources. The benchmark features automatic evaluation\nmetrics and is divided into segments-Rule Comprehension, Rule Compliance, and\nRule Extraction-based on tasks that engineers perform when designing according\nto requirements. We evaluate state-of-the-art models (at the time of writing)\nlike GPT-4o, GPT-4, Claude-Opus, Gemini-1.0, and LLaVA-1.5 against the\nbenchmark, and our study uncovers the existing gaps in MLLMs' abilities to\ninterpret complex engineering documentation. The MLLMs tested, while promising,\nstruggle to reliably retrieve relevant rules from the Formula SAE\ndocumentation, face challenges in recognizing technical components in CAD\nimages, and encounter difficulty in analyzing engineering drawings. These\nfindings underscore the need for multimodal models that can better handle the\nmultifaceted questions characteristic of design according to technical\ndocumentation. This benchmark sets a foundation for future advancements in\nAI-supported engineering design processes. DesignQA is publicly available at:\nhttps://github.com/anniedoris/design_qa/.",
      "tldr_zh": "本文提出 DesignQA，这是一个多模态基准，用于评估 Multimodal Large Language Models (MLLMs) 在理解和应用工程文档（如文本设计要求、CAD 图像和工程图）方面的能力。该基准基于 Formula SAE 竞赛的真实数据，包含文档基础的视觉问题，并分为 Rule Comprehension、Rule Compliance 和 Rule Extraction 三个任务，以模拟工程师的设计流程。实验评估了 GPT-4o、GPT-4、Claude-Opus、Gemini-1.0 和 LLaVA-1.5 等模型，结果显示这些 MLLMs 在检索相关规则、识别技术组件和分析工程图方面存在显著缺陷。这些发现强调了开发更先进的多模态模型以支持工程设计的必要性，DesignQA 已公开在 GitHub 上。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07917v2",
      "published_date": "2024-04-11 16:59:54 UTC",
      "updated_date": "2024-08-23 17:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:34:16.336859"
    },
    {
      "arxiv_id": "2404.08029v1",
      "title": "A Multi-Expert Large Language Model Architecture for Verilog Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Bardia Nadimi",
        "Hao Zheng"
      ],
      "abstract": "Recently, there has been a surging interest in using large language models\n(LLMs) for Verilog code generation. However, the existing approaches are\nlimited in terms of the quality of the generated Verilog code. To address such\nlimitations, this paper introduces an innovative multi-expert LLM architecture\nfor Verilog code generation (MEV-LLM). Our architecture uniquely integrates\nmultiple LLMs, each specifically fine-tuned with a dataset that is categorized\nwith respect to a distinct level of design complexity. It allows more targeted\nlearning, directly addressing the nuances of generating Verilog code for each\ncategory. Empirical evidence from experiments highlights notable improvements\nin terms of the percentage of generated Verilog outputs that are syntactically\nand functionally correct. These findings underscore the efficacy of our\napproach, promising a forward leap in the field of automated hardware design\nthrough machine learning.",
      "tldr_zh": "本论文提出了一种多专家大型语言模型架构（MEV-LLM），旨在提升Verilog代码生成的质量，以解决现有LLMs在代码准确性方面的局限性。该架构整合多个专门微调的LLMs，每个模型针对不同设计复杂度的数据集进行训练，从而实现更精准的类别化学习。实验结果显示，生成的Verilog代码在语法和功能正确性方面显著改进，证明了这一方法的有效性，并为通过机器学习实现自动硬件设计提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08029v1",
      "published_date": "2024-04-11 16:58:29 UTC",
      "updated_date": "2024-04-11 16:58:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:34:24.729250"
    },
    {
      "arxiv_id": "2404.17586v1",
      "title": "The Future of Scientific Publishing: Automated Article Generation",
      "title_zh": "科学出版的未来：自动化文章生成",
      "authors": [
        "Jeremy R. Harper"
      ],
      "abstract": "This study introduces a novel software tool leveraging large language model\n(LLM) prompts, designed to automate the generation of academic articles from\nPython code a significant advancement in the fields of biomedical informatics\nand computer science. Selected for its widespread adoption and analytical\nversatility, Python served as a foundational proof of concept; however, the\nunderlying methodology and framework exhibit adaptability across various GitHub\nrepo's underlining the tool's broad applicability (Harper 2024). By mitigating\nthe traditionally time-intensive academic writing process, particularly in\nsynthesizing complex datasets and coding outputs, this approach signifies a\nmonumental leap towards streamlining research dissemination. The development\nwas achieved without reliance on advanced language model agents, ensuring high\nfidelity in the automated generation of coherent and comprehensive academic\ncontent. This exploration not only validates the successful application and\nefficiency of the software but also projects how future integration of LLM\nagents which could amplify its capabilities, propelling towards a future where\nscientific findings are disseminated more swiftly and accessibly.",
      "tldr_zh": "这篇论文提出了一种新型软件工具，利用大型语言模型(LLM)提示，从Python代码自动生成学术文章，从而在生物医学信息学和计算机科学领域实现重大进展。该工具以Python作为概念验证基础，但其方法和框架可扩展到其他GitHub仓库，显著简化了学术写作过程，特别是合成复杂数据集和代码输出的工作，而无需依赖高级LLM代理，确保生成内容的连贯性和高保真度。实验验证了工具的效率和适用性，并预测未来整合LLM代理将进一步加速科学研究传播，使其更快速和易于访问。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "Keywords: automated academic writing, Python code, software tool,\n  article generation, natural language processing, scholarly publishing, code\n  analysis, academic article automation, research dissemination, programming\n  and publishing integration",
      "pdf_url": "http://arxiv.org/pdf/2404.17586v1",
      "published_date": "2024-04-11 16:47:02 UTC",
      "updated_date": "2024-04-11 16:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:34:39.184392"
    },
    {
      "arxiv_id": "2404.07900v4",
      "title": "High-Dimension Human Value Representation in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Cahyawijaya",
        "Delong Chen",
        "Yejin Bang",
        "Leila Khalatbari",
        "Bryan Wilie",
        "Ziwei Ji",
        "Etsuko Ishii",
        "Pascale Fung"
      ],
      "abstract": "The widespread application of LLMs across various tasks and fields has\nnecessitated the alignment of these models with human values and preferences.\nGiven various approaches of human value alignment, there is an urgent need to\nunderstand the scope and nature of human values injected into these LLMs before\ntheir deployment and adoption. We propose UniVaR, a high-dimensional neural\nrepresentation of symbolic human value distributions in LLMs, orthogonal to\nmodel architecture and training data. This is a continuous and scalable\nrepresentation, self-supervised from the value-relevant output of 8 LLMs and\nevaluated on 15 open-source and commercial LLMs. Through UniVaR, we visualize\nand explore how LLMs prioritize different values in 25 languages and cultures,\nshedding light on complex interplay between human values and language modeling.",
      "tldr_zh": "本研究提出 UniVaR，一种高维神经表示，用于捕捉大型语言模型（LLMs）中的符号人类价值分布，该表示独立于模型架构和训练数据，且是连续且可扩展的。UniVaR 通过从 8 个 LLMs 的价值相关输出中自监督学习，并在 15 个开源和商业 LLMs 上进行评估，实现了对人类价值观的量化。结果显示，UniVaR 可视化并分析 LLMs 在 25 种语言和文化中对不同价值观的优先级，揭示了人类价值观与语言建模之间的复杂互动。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07900v4",
      "published_date": "2024-04-11 16:39:00 UTC",
      "updated_date": "2025-03-25 22:02:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:34:50.242105"
    },
    {
      "arxiv_id": "2404.07883v1",
      "title": "Apprentice Tutor Builder: A Platform For Users to Create and Personalize Intelligent Tutors",
      "title_zh": "Apprentice Tutor Builder：一个平台，用于用户创建和个性化智能导师",
      "authors": [
        "Glen Smith",
        "Adit Gupta",
        "Christopher MacLellan"
      ],
      "abstract": "Intelligent tutoring systems (ITS) are effective for improving students'\nlearning outcomes. However, their development is often complex, time-consuming,\nand requires specialized programming and tutor design knowledge, thus hindering\ntheir widespread application and personalization. We present the Apprentice\nTutor Builder (ATB) , a platform that simplifies tutor creation and\npersonalization. Instructors can utilize ATB's drag-and-drop tool to build\ntutor interfaces. Instructors can then interactively train the tutors'\nunderlying AI agent to produce expert models that can solve problems. Training\nis achieved via using multiple interaction modalities including demonstrations,\nfeedback, and user labels. We conducted a user study with 14 instructors to\nevaluate the effectiveness of ATB's design with end users. We found that users\nenjoyed the flexibility of the interface builder and ease and speed of agent\nteaching, but often desired additional time-saving features. With these\ninsights, we identified a set of design recommendations for our platform and\nothers that utilize interactive AI agents for tutor creation and customization.",
      "tldr_zh": "这篇论文介绍了 Apprentice Tutor Builder (ATB)，一个平台旨在简化 Intelligent Tutoring Systems (ITS) 的创建和个性化，以克服其开发复杂、耗时且需要专业知识的难题。ATB 允许教员使用拖拽工具构建导师界面，并通过演示、反馈和用户标签等多种交互模式训练 AI 代理，以生成能解决问题的专家模型。在一项涉及 14 名教员的用户研究中，结果显示用户欣赏界面的灵活性和代理训练的简便快速，但希望添加更多节省时间的功能。基于这些洞见，论文提出了针对 ATB 和类似平台的交互式 AI 代理设计推荐。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07883v1",
      "published_date": "2024-04-11 16:14:23 UTC",
      "updated_date": "2024-04-11 16:14:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:35:03.507101"
    },
    {
      "arxiv_id": "2404.08027v2",
      "title": "SurvMamba: State Space Model with Multi-grained Multi-modal Interaction for Survival Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Chen",
        "Jiajing Xie",
        "Yuxiang Lin",
        "Yuhang Song",
        "Wenxian Yang",
        "Rongshan Yu"
      ],
      "abstract": "Multi-modal learning that combines pathological images with genomic data has\nsignificantly enhanced the accuracy of survival prediction. Nevertheless,\nexisting methods have not fully utilized the inherent hierarchical structure\nwithin both whole slide images (WSIs) and transcriptomic data, from which\nbetter intra-modal representations and inter-modal integration could be\nderived. Moreover, many existing studies attempt to improve multi-modal\nrepresentations through attention mechanisms, which inevitably lead to high\ncomplexity when processing high-dimensional WSIs and transcriptomic data.\nRecently, a structured state space model named Mamba emerged as a promising\napproach for its superior performance in modeling long sequences with low\ncomplexity. In this study, we propose Mamba with multi-grained multi-modal\ninteraction (SurvMamba) for survival prediction. SurvMamba is implemented with\na Hierarchical Interaction Mamba (HIM) module that facilitates efficient\nintra-modal interactions at different granularities, thereby capturing more\ndetailed local features as well as rich global representations. In addition, an\nInteraction Fusion Mamba (IFM) module is used for cascaded inter-modal\ninteractive fusion, yielding more comprehensive features for survival\nprediction. Comprehensive evaluations on five TCGA datasets demonstrate that\nSurvMamba outperforms other existing methods in terms of performance and\ncomputational cost.",
      "tldr_zh": "该研究提出SurvMamba，一种基于State Space Model的框架，用于整合病理图像（WSIs）和转录组数据的多模态生存预测，旨在充分利用数据的层次结构并降低计算复杂度。SurvMamba包括Hierarchical Interaction Mamba (HIM)模块，实现多粒度内模态交互，以捕获详细的局部和全局特征；以及Interaction Fusion Mamba (IFM)模块，进行级联的模态间融合，从而生成更全面的预测特征。在五个TCGA数据集上的评估中，SurvMamba在性能和计算成本方面均优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08027v2",
      "published_date": "2024-04-11 15:58:12 UTC",
      "updated_date": "2024-12-04 02:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:35:16.513410"
    },
    {
      "arxiv_id": "2404.07851v1",
      "title": "Guiding Large Language Models to Post-Edit Machine Translation with Error Annotations",
      "title_zh": "利用错误标注引导大型语言模型对机器翻译进行后编辑",
      "authors": [
        "Dayeon Ki",
        "Marine Carpuat"
      ],
      "abstract": "Machine Translation (MT) remains one of the last NLP tasks where large\nlanguage models (LLMs) have not yet replaced dedicated supervised systems. This\nwork exploits the complementary strengths of LLMs and supervised MT by guiding\nLLMs to automatically post-edit MT with external feedback on its quality,\nderived from Multidimensional Quality Metric (MQM) annotations. Working with\nLLaMA-2 models, we consider prompting strategies varying the nature of feedback\nprovided and then fine-tune the LLM to improve its ability to exploit the\nprovided guidance. Through experiments on Chinese-English, English-German, and\nEnglish-Russian MQM data, we demonstrate that prompting LLMs to post-edit MT\nimproves TER, BLEU and COMET scores, although the benefits of fine-grained\nfeedback are not clear. Fine-tuning helps integrate fine-grained feedback more\neffectively and further improves translation quality based on both automatic\nand human evaluation.",
      "tldr_zh": "本文提出一种方法，通过 Multidimensional Quality Metric (MQM) 错误注解指导 Large Language Models (LLMs) 自动后编辑 Machine Translation (MT)，以结合 LLMs 和监督 MT 的优势。研究使用 LLaMA-2 模型探索不同提示策略提供反馈，并通过微调提升 LLMs 利用细粒度指导的能力。在中文-英文、英文-德文和英文-俄文数据集上实验表明，这种方法显著改善了 TER、BLEU 和 COMET 分数，而微调进一步增强了翻译质量，经自动和人工评估验证。整体贡献在于为 LLMs 在 MT 任务中提供更可靠的后编辑机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.07851v1",
      "published_date": "2024-04-11 15:47:10 UTC",
      "updated_date": "2024-04-11 15:47:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:35:28.148252"
    },
    {
      "arxiv_id": "2404.07850v1",
      "title": "MindBridge: A Cross-Subject Brain Decoding Framework",
      "title_zh": "MindBridge:",
      "authors": [
        "Shizun Wang",
        "Songhua Liu",
        "Zhenxiong Tan",
        "Xinchao Wang"
      ],
      "abstract": "Brain decoding, a pivotal field in neuroscience, aims to reconstruct stimuli\nfrom acquired brain signals, primarily utilizing functional magnetic resonance\nimaging (fMRI). Currently, brain decoding is confined to a\nper-subject-per-model paradigm, limiting its applicability to the same\nindividual for whom the decoding model is trained. This constraint stems from\nthree key challenges: 1) the inherent variability in input dimensions across\nsubjects due to differences in brain size; 2) the unique intrinsic neural\npatterns, influencing how different individuals perceive and process sensory\ninformation; 3) limited data availability for new subjects in real-world\nscenarios hampers the performance of decoding models. In this paper, we present\na novel approach, MindBridge, that achieves cross-subject brain decoding by\nemploying only one model. Our proposed framework establishes a generic paradigm\ncapable of addressing these challenges by introducing biological-inspired\naggregation function and novel cyclic fMRI reconstruction mechanism for\nsubject-invariant representation learning. Notably, by cycle reconstruction of\nfMRI, MindBridge can enable novel fMRI synthesis, which also can serve as\npseudo data augmentation. Within the framework, we also devise a novel\nreset-tuning method for adapting a pretrained model to a new subject.\nExperimental results demonstrate MindBridge's ability to reconstruct images for\nmultiple subjects, which is competitive with dedicated subject-specific models.\nFurthermore, with limited data for a new subject, we achieve a high level of\ndecoding accuracy, surpassing that of subject-specific models. This advancement\nin cross-subject brain decoding suggests promising directions for wider\napplications in neuroscience and indicates potential for more efficient\nutilization of limited fMRI data in real-world scenarios. Project page:\nhttps://littlepure2333.github.io/MindBridge",
      "tldr_zh": "本研究针对脑解码（brain decoding）领域的限制，提出MindBridge框架，实现跨主体的fMRI重建，仅需一个模型来处理不同个体的脑信号差异，包括输入维度变异、独特神经模式和数据有限问题。MindBridge引入生物启发的聚合函数（biological-inspired aggregation function）和循环fMRI重建机制（cyclic fMRI reconstruction mechanism），支持主体不变的表示学习，并通过fMRI合成作为伪数据增强，同时开发reset-tuning方法以适应新主体。实验结果显示，该框架在多主体图像重建上与专属模型（subject-specific models）相当，且在新主体数据有限时，解码准确率更高。该创新有望扩展脑解码在神经科学的应用，并更高效利用有限的fMRI数据。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 highlight. Code is available at\n  https://github.com/littlepure2333/MindBridge",
      "pdf_url": "http://arxiv.org/pdf/2404.07850v1",
      "published_date": "2024-04-11 15:46:42 UTC",
      "updated_date": "2024-04-11 15:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:35:39.219675"
    },
    {
      "arxiv_id": "2404.07839v2",
      "title": "RecurrentGemma: Moving Past Transformers for Efficient Open Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandar Botev",
        "Soham De",
        "Samuel L Smith",
        "Anushan Fernando",
        "George-Cristian Muraru",
        "Ruba Haroun",
        "Leonard Berrada",
        "Razvan Pascanu",
        "Pier Giuseppe Sessa",
        "Robert Dadashi",
        "Léonard Hussenot",
        "Johan Ferret",
        "Sertan Girgin",
        "Olivier Bachem",
        "Alek Andreev",
        "Kathleen Kenealy",
        "Thomas Mesnard",
        "Cassidy Hardin",
        "Surya Bhupatiraju",
        "Shreya Pathak",
        "Laurent Sifre",
        "Morgane Rivière",
        "Mihir Sanjay Kale",
        "Juliette Love",
        "Pouya Tafti",
        "Armand Joulin",
        "Noah Fiedel",
        "Evan Senter",
        "Yutian Chen",
        "Srivatsan Srinivasan",
        "Guillaume Desjardins",
        "David Budden",
        "Arnaud Doucet",
        "Sharad Vikram",
        "Adam Paszke",
        "Trevor Gale",
        "Sebastian Borgeaud",
        "Charlie Chen",
        "Andy Brock",
        "Antonia Paterson",
        "Jenny Brennan",
        "Meg Risdal",
        "Raj Gundluru",
        "Nesh Devanathan",
        "Paul Mooney",
        "Nilay Chauhan",
        "Phil Culliton",
        "Luiz Gustavo Martins",
        "Elisa Bandy",
        "David Huntsperger",
        "Glenn Cameron",
        "Arthur Zucker",
        "Tris Warkentin",
        "Ludovic Peran",
        "Minh Giang",
        "Zoubin Ghahramani",
        "Clément Farabet",
        "Koray Kavukcuoglu",
        "Demis Hassabis",
        "Raia Hadsell",
        "Yee Whye Teh",
        "Nando de Frietas"
      ],
      "abstract": "We introduce RecurrentGemma, a family of open language models which uses\nGoogle's novel Griffin architecture. Griffin combines linear recurrences with\nlocal attention to achieve excellent performance on language. It has a\nfixed-sized state, which reduces memory use and enables efficient inference on\nlong sequences. We provide two sizes of models, containing 2B and 9B\nparameters, and provide pre-trained and instruction tuned variants for both.\nOur models achieve comparable performance to similarly-sized Gemma baselines\ndespite being trained on fewer tokens.",
      "tldr_zh": "我们介绍了RecurrentGemma，一系列基于Google的Griffin架构的开源语言模型，该架构结合线性递归和局部attention，实现高效的语言处理性能。不同于传统的Transformer模型，Griffin采用固定大小的状态，减少内存消耗并优化长序列推理。模型提供2B和9B参数的预训练和指令微调变体。尽管训练token更少，RecurrentGemma在性能上与同等规模的Gemma基线模型相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07839v2",
      "published_date": "2024-04-11 15:27:22 UTC",
      "updated_date": "2024-08-28 15:05:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:35:50.516246"
    },
    {
      "arxiv_id": "2404.07826v1",
      "title": "On the Sample Efficiency of Abstractions and Potential-Based Reward Shaping in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Giuseppe Canonaco",
        "Leo Ardon",
        "Alberto Pozanco",
        "Daniel Borrajo"
      ],
      "abstract": "The use of Potential Based Reward Shaping (PBRS) has shown great promise in\nthe ongoing research effort to tackle sample inefficiency in Reinforcement\nLearning (RL). However, the choice of the potential function is critical for\nthis technique to be effective. Additionally, RL techniques are usually\nconstrained to use a finite horizon for computational limitations. This\nintroduces a bias when using PBRS, thus adding an additional layer of\ncomplexity. In this paper, we leverage abstractions to automatically produce a\n\"good\" potential function. We analyse the bias induced by finite horizons in\nthe context of PBRS producing novel insights. Finally, to asses sample\nefficiency and performance impact, we evaluate our approach on four\nenvironments including a goal-oriented navigation task and three Arcade\nLearning Environments (ALE) games demonstrating that we can reach the same\nlevel of performance as CNN-based solutions with a simple fully-connected\nnetwork.",
      "tldr_zh": "本研究探讨了抽象(abstractions)和基于潜在函数的奖励整形(Potential-Based Reward Shaping, PBRS)在强化学习(Reinforcement Learning, RL)中的样本效率。作者提出利用抽象自动生成有效的潜在函数，以缓解PBRS对有限地平线(finite horizons)引发的偏差，并提供了相关偏差分析的新见解。在四个环境中，包括目标导向导航任务和三个Arcade Learning Environments (ALE)游戏，实验结果显示，该方法使用简单全连接网络即可达到与CNN-based解决方案相同的性能水平，从而显著提升了RL的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07826v1",
      "published_date": "2024-04-11 15:09:49 UTC",
      "updated_date": "2024-04-11 15:09:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:36:02.295680"
    },
    {
      "arxiv_id": "2404.13060v1",
      "title": "The Necessity of AI Audit Standards Boards",
      "title_zh": "AI 审计标准委员会的必要性",
      "authors": [
        "David Manheim",
        "Sammy Martin",
        "Mark Bailey",
        "Mikhail Samin",
        "Ross Greutzmacher"
      ],
      "abstract": "Auditing of AI systems is a promising way to understand and manage ethical\nproblems and societal risks associated with contemporary AI systems, as well as\nsome anticipated future risks. Efforts to develop standards for auditing\nArtificial Intelligence (AI) systems have therefore understandably gained\nmomentum. However, we argue that creating auditing standards is not just\ninsufficient, but actively harmful by proliferating unheeded and inconsistent\nstandards, especially in light of the rapid evolution and ethical and safety\nchallenges of AI. Instead, the paper proposes the establishment of an AI Audit\nStandards Board, responsible for developing and updating auditing methods and\nstandards in line with the evolving nature of AI technologies. Such a body\nwould ensure that auditing practices remain relevant, robust, and responsive to\nthe rapid advancements in AI. The paper argues that such a governance structure\nwould also be helpful for maintaining public trust in AI and for promoting a\nculture of safety and ethical responsibility within the AI industry.\n  Throughout the paper, we draw parallels with other industries, including\nsafety-critical industries like aviation and nuclear energy, as well as more\nprosaic ones such as financial accounting and pharmaceuticals. AI auditing\nshould emulate those fields, and extend beyond technical assessments to include\nethical considerations and stakeholder engagement, but we explain that this is\nnot enough; emulating other fields' governance mechanisms for these processes,\nand for audit standards creation, is a necessity. We also emphasize the\nimportance of auditing the entire development process of AI systems, not just\nthe final products...",
      "tldr_zh": "该论文指出，现有的AI系统审计标准虽有助于管理AI相关的伦理问题和社会风险，但其开发不足且可能导致标准不一致和有害，尤其在AI快速演变的环境下。作者提出建立AI Audit Standards Board，该机构负责制定和更新审计方法与标准，以确保审计实践保持相关性、稳健性和对AI进展的响应性。论文通过与航空、核能、金融会计和制药等行业的治理机制比较，强调AI审计需扩展到整个开发过程，包括伦理考虑和利益相关者参与，从而维护公众对AI的信任并促进安全与伦理责任文化。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.4.1; K.6.4; K.5.2; I.2"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13060v1",
      "published_date": "2024-04-11 15:08:24 UTC",
      "updated_date": "2024-04-11 15:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:36:14.032857"
    },
    {
      "arxiv_id": "2404.07817v2",
      "title": "Calibration of Continual Learning Models",
      "title_zh": "持续学习模型的校准",
      "authors": [
        "Lanpei Li",
        "Elia Piccoli",
        "Andrea Cossu",
        "Davide Bacciu",
        "Vincenzo Lomonaco"
      ],
      "abstract": "Continual Learning (CL) focuses on maximizing the predictive performance of a\nmodel across a non-stationary stream of data. Unfortunately, CL models tend to\nforget previous knowledge, thus often underperforming when compared with an\noffline model trained jointly on the entire data stream. Given that any CL\nmodel will eventually make mistakes, it is of crucial importance to build\ncalibrated CL models: models that can reliably tell their confidence when\nmaking a prediction. Model calibration is an active research topic in machine\nlearning, yet to be properly investigated in CL. We provide the first empirical\nstudy of the behavior of calibration approaches in CL, showing that CL\nstrategies do not inherently learn calibrated models. To mitigate this issue,\nwe design a continual calibration approach that improves the performance of\npost-processing calibration methods over a wide range of different benchmarks\nand CL strategies. CL does not necessarily need perfect predictive models, but\nrather it can benefit from reliable predictive models. We believe our study on\ncontinual calibration represents a first step towards this direction.",
      "tldr_zh": "这项研究探讨了Continual Learning (CL)模型的校准问题，指出CL模型在处理非平稳数据流时容易遗忘先前知识，导致预测性能不如离线训练模型，且缺乏可靠的置信度评估。为此，研究者进行了首次实证分析，发现现有CL策略并不能自然地产生校准良好的模型。针对这一问题，他们提出了一种持续校准方法，能够显著提升后处理校准技术在多种基准和CL策略上的表现，最终强调CL更需要可靠的预测模型而非完美的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at CLVISION workshop, CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07817v2",
      "published_date": "2024-04-11 14:59:49 UTC",
      "updated_date": "2024-04-12 12:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:36:27.213716"
    },
    {
      "arxiv_id": "2404.07815v2",
      "title": "Post-Hoc Reversal: Are We Selecting Models Prematurely?",
      "title_zh": "事后逆转：我们是否过早地选择了模型？",
      "authors": [
        "Rishabh Ranjan",
        "Saurabh Garg",
        "Mrigank Raman",
        "Carlos Guestrin",
        "Zachary Lipton"
      ],
      "abstract": "Trained models are often composed with post-hoc transforms such as\ntemperature scaling (TS), ensembling and stochastic weight averaging (SWA) to\nimprove performance, robustness, uncertainty estimation, etc. However, such\ntransforms are typically applied only after the base models have already been\nfinalized by standard means. In this paper, we challenge this practice with an\nextensive empirical study. In particular, we demonstrate a phenomenon that we\ncall post-hoc reversal, where performance trends are reversed after applying\npost-hoc transforms. This phenomenon is especially prominent in high-noise\nsettings. For example, while base models overfit badly early in training, both\nensembling and SWA favor base models trained for more epochs. Post-hoc reversal\ncan also prevent the appearance of double descent and mitigate mismatches\nbetween test loss and test error seen in base models. Preliminary analyses\nsuggest that these transforms induce reversal by suppressing the influence of\nmislabeled examples, exploiting differences in their learning dynamics from\nthose of clean examples. Based on our findings, we propose post-hoc selection,\na simple technique whereby post-hoc metrics inform model development decisions\nsuch as early stopping, checkpointing, and broader hyperparameter choices. Our\nexperiments span real-world vision, language, tabular and graph datasets. On an\nLLM instruction tuning dataset, post-hoc selection results in >1.5x MMLU\nimprovement compared to naive selection.",
      "tldr_zh": "这篇论文质疑了机器学习模型训练后才应用后验转换（如 temperature scaling (TS)、ensembling 和 stochastic weight averaging (SWA)）的常见做法，揭示了“后验逆转”（post-hoc reversal）现象，即这些转换可能逆转基模型的性能趋势，尤其在高噪声环境中。研究发现，这种逆转能抑制错误标记样本的影响，防止双重下降（double descent）出现，并改善基模型的测试损失与测试错误不匹配问题。作者提出“后验选择”（post-hoc selection）技术，使用后验指标指导模型开发决策，如早停、检查点和超参数优化；在实验中，该方法在视觉、语言、表格和图数据集上表现出色，在 LLM 指令调整数据集上实现了超过 1.5 倍的 MMLU 性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted at NeurIPS 2024; v2 adds an intuitions section",
      "pdf_url": "http://arxiv.org/pdf/2404.07815v2",
      "published_date": "2024-04-11 14:58:19 UTC",
      "updated_date": "2024-10-04 00:11:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:36:40.125025"
    },
    {
      "arxiv_id": "2404.07788v1",
      "title": "AUG: A New Dataset and An Efficient Model for Aerial Image Urban Scene Graph Generation",
      "title_zh": "AUG：一个新数据集和一个高效模型，用于航空图像城市场景图生成",
      "authors": [
        "Yansheng Li",
        "Kun Li",
        "Yongjun Zhang",
        "Linlin Wang",
        "Dingwen Zhang"
      ],
      "abstract": "Scene graph generation (SGG) aims to understand the visual objects and their\nsemantic relationships from one given image. Until now, lots of SGG datasets\nwith the eyelevel view are released but the SGG dataset with the overhead view\nis scarcely studied. By contrast to the object occlusion problem in the\neyelevel view, which impedes the SGG, the overhead view provides a new\nperspective that helps to promote the SGG by providing a clear perception of\nthe spatial relationships of objects in the ground scene. To fill in the gap of\nthe overhead view dataset, this paper constructs and releases an aerial image\nurban scene graph generation (AUG) dataset. Images from the AUG dataset are\ncaptured with the low-attitude overhead view. In the AUG dataset, 25,594\nobjects, 16,970 relationships, and 27,175 attributes are manually annotated. To\navoid the local context being overwhelmed in the complex aerial urban scene,\nthis paper proposes one new locality-preserving graph convolutional network\n(LPG). Different from the traditional graph convolutional network, which has\nthe natural advantage of capturing the global context for SGG, the\nconvolutional layer in the LPG integrates the non-destructive initial features\nof the objects with dynamically updated neighborhood information to preserve\nthe local context under the premise of mining the global context. To address\nthe problem that there exists an extra-large number of potential object\nrelationship pairs but only a small part of them is meaningful in AUG, we\npropose the adaptive bounding box scaling factor for potential relationship\ndetection (ABS-PRD) to intelligently prune the meaningless relationship pairs.\nExtensive experiments on the AUG dataset show that our LPG can significantly\noutperform the state-of-the-art methods and the effectiveness of the proposed\nlocality-preserving strategy.",
      "tldr_zh": "本论文介绍了AUG数据集，这是一个针对空中图像的城市场景图生成(SGG)的新数据集，包含低空头顶视角的图像，手动标注了25,594个对象、16,970个关系和27,175个属性，以解决传统眼平视角度中物体遮挡问题的局限性。论文提出了一种局部性保留图卷积网络(LPG)，通过整合非破坏性初始对象特征和动态更新邻居信息，在挖掘全局上下文的同时保留局部上下文。针对AUG中潜在物体关系对数量过多的问题，论文还引入了自适应边界框缩放因子用于潜在关系检测(ABS-PRD)，以智能修剪无意义关系对。实验结果显示，LPG在AUG数据集上显著优于现有最先进方法，证明了局部性保留策略的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07788v1",
      "published_date": "2024-04-11 14:29:30 UTC",
      "updated_date": "2024-04-11 14:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:36:51.830841"
    },
    {
      "arxiv_id": "2404.07775v1",
      "title": "Discourse-Aware In-Context Learning for Temporal Expression Normalization",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Kumar Gautam",
        "Lukas Lange",
        "Jannik Strötgen"
      ],
      "abstract": "Temporal expression (TE) normalization is a well-studied problem. However,\nthe predominately used rule-based systems are highly restricted to specific\nsettings, and upcoming machine learning approaches suffer from a lack of\nlabeled data. In this work, we explore the feasibility of proprietary and\nopen-source large language models (LLMs) for TE normalization using in-context\nlearning to inject task, document, and example information into the model. We\nexplore various sample selection strategies to retrieve the most relevant set\nof examples. By using a window-based prompt design approach, we can perform TE\nnormalization across sentences, while leveraging the LLM knowledge without\ntraining the model. Our experiments show competitive results to models designed\nfor this task. In particular, our method achieves large performance\nimprovements for non-standard settings by dynamically including relevant\nexamples during inference.",
      "tldr_zh": "本文探讨了时间表达式 (TE) 规范化的挑战，包括规则-based 系统对特定设置的依赖和机器学习方法的数据标注不足，并提出使用大型语言模型 (LLMs) 的 in-context learning 方法，通过注入任务、文档和示例信息来解决这些问题。方法采用各种样本选择策略和基于窗口的提示设计，实现跨句子的 TE 规范化，而无需对模型进行训练。实验结果显示，该方法与专为该任务设计的模型相比具有竞争力，尤其在非标准设置中，通过动态包含相关示例，显著提升了性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07775v1",
      "published_date": "2024-04-11 14:13:44 UTC",
      "updated_date": "2024-04-11 14:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:37:04.889052"
    },
    {
      "arxiv_id": "2404.07765v1",
      "title": "AnnoCTR: A Dataset for Detecting and Linking Entities, Tactics, and Techniques in Cyber Threat Reports",
      "title_zh": "AnnoCTR：用于",
      "authors": [
        "Lukas Lange",
        "Marc Müller",
        "Ghazaleh Haratinezhad Torbati",
        "Dragan Milchevski",
        "Patrick Grau",
        "Subhash Pujari",
        "Annemarie Friedrich"
      ],
      "abstract": "Monitoring the threat landscape to be aware of actual or potential attacks is\nof utmost importance to cybersecurity professionals. Information about cyber\nthreats is typically distributed using natural language reports. Natural\nlanguage processing can help with managing this large amount of unstructured\ninformation, yet to date, the topic has received little attention. With this\npaper, we present AnnoCTR, a new CC-BY-SA-licensed dataset of cyber threat\nreports. The reports have been annotated by a domain expert with named\nentities, temporal expressions, and cybersecurity-specific concepts including\nimplicitly mentioned techniques and tactics. Entities and concepts are linked\nto Wikipedia and the MITRE ATT&CK knowledge base, the most widely-used taxonomy\nfor classifying types of attacks. Prior datasets linking to MITRE ATT&CK either\nprovide a single label per document or annotate sentences out-of-context; our\ndataset annotates entire documents in a much finer-grained way. In an\nexperimental study, we model the annotations of our dataset using\nstate-of-the-art neural models. In our few-shot scenario, we find that for\nidentifying the MITRE ATT&CK concepts that are mentioned explicitly or\nimplicitly in a text, concept descriptions from MITRE ATT&CK are an effective\nsource for training data augmentation.",
      "tldr_zh": "本文提出 AnnoCTR 数据集，用于检测和链接网络威胁报告中的命名实体(named entities)、时间表达式(temporal expressions)以及网络安全特定概念，包括隐式提及的策略和技术。数据集由领域专家标注整个文档，并将实体和概念链接到 Wikipedia 和 MITRE ATT&CK 知识库，提供比现有数据集更细粒度的标注方式。实验结果显示，使用最先进的神经模型在少样本场景下，通过 MITRE ATT&CK 的概念描述进行训练数据增强，能有效提升对显式或隐式概念的识别准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024. Corpus available at\n  https://github.com/boschresearch/anno-ctr-lrec-coling-2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07765v1",
      "published_date": "2024-04-11 14:04:36 UTC",
      "updated_date": "2024-04-11 14:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:37:17.020875"
    },
    {
      "arxiv_id": "2404.07754v1",
      "title": "Generating Synthetic Satellite Imagery With Deep-Learning Text-to-Image Models -- Technical Challenges and Implications for Monitoring and Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Tuong Vy Nguyen",
        "Alexander Glaser",
        "Felix Biessmann"
      ],
      "abstract": "Novel deep-learning (DL) architectures have reached a level where they can\ngenerate digital media, including photorealistic images, that are difficult to\ndistinguish from real data. These technologies have already been used to\ngenerate training data for Machine Learning (ML) models, and large\ntext-to-image models like DALL-E 2, Imagen, and Stable Diffusion are achieving\nremarkable results in realistic high-resolution image generation. Given these\ndevelopments, issues of data authentication in monitoring and verification\ndeserve a careful and systematic analysis: How realistic are synthetic images?\nHow easily can they be generated? How useful are they for ML researchers, and\nwhat is their potential for Open Science? In this work, we use novel DL models\nto explore how synthetic satellite images can be created using conditioning\nmechanisms. We investigate the challenges of synthetic satellite image\ngeneration and evaluate the results based on authenticity and state-of-the-art\nmetrics. Furthermore, we investigate how synthetic data can alleviate the lack\nof data in the context of ML methods for remote-sensing. Finally we discuss\nimplications of synthetic satellite imagery in the context of monitoring and\nverification.",
      "tldr_zh": "本文研究了利用深度学习（DL）文本到图像模型（如 DALL-E 2、Imagen 和 Stable Diffusion）生成合成卫星图像的技术挑战和潜在影响。作者通过条件机制探索了合成图像的创建过程，并基于真实性和最先进指标（如真实度评估）对生成结果进行了评估。研究发现，合成数据可缓解遥感领域 Machine Learning (ML) 方法中的数据短缺问题，同时强调了其在监测和验证中的数据认证风险。最终，论文讨论了这些技术对 Open Science 的益处和应用含义。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "https://resources.inmm.org/annual-meeting-proceedings/generating-synthetic-satellite-imagery-deep-learning-text-image-models",
      "pdf_url": "http://arxiv.org/pdf/2404.07754v1",
      "published_date": "2024-04-11 14:00:20 UTC",
      "updated_date": "2024-04-11 14:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:37:28.852867"
    },
    {
      "arxiv_id": "2404.07751v1",
      "title": "Generating consistent PDDL domains with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pavel Smirnov",
        "Frank Joublin",
        "Antonello Ceravola",
        "Michael Gienger"
      ],
      "abstract": "Large Language Models (LLMs) are capable of transforming natural language\ndomain descriptions into plausibly looking PDDL markup. However, ensuring that\nactions are consistent within domains still remains a challenging task. In this\npaper we present a novel concept to significantly improve the quality of\nLLM-generated PDDL models by performing automated consistency checking during\nthe generation process. Although the proposed consistency checking strategies\nstill can't guarantee absolute correctness of generated models, they can serve\nas valuable source of feedback reducing the amount of correction efforts\nexpected from a human in the loop. We demonstrate the capabilities of our error\ndetection approach on a number of classical and custom planning domains\n(logistics, gripper, tyreworld, household, pizza).",
      "tldr_zh": "本研究探讨了如何利用 Large Language Models (LLMs) 生成一致的 PDDL 域描述，以解决现有方法中动作一致性挑战的问题。论文提出了一种新概念，通过在生成过程中整合自动一致性检查策略，来显著提升 PDDL 模型的质量，尽管无法保证绝对正确，但能提供宝贵反馈，减少人类修正工作量。在经典和自定义规划域（如 logistics、gripper 和 pizza）上的实验证明，该方法有效提升了模型可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07751v1",
      "published_date": "2024-04-11 13:48:48 UTC",
      "updated_date": "2024-04-11 13:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:37:39.868679"
    },
    {
      "arxiv_id": "2404.07738v2",
      "title": "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinheon Baek",
        "Sujay Kumar Jauhar",
        "Silviu Cucerzan",
        "Sung Ju Hwang"
      ],
      "abstract": "The pace of scientific research, vital for improving human life, is complex,\nslow, and needs specialized expertise. Meanwhile, novel, impactful research\noften stems from both a deep understanding of prior work, and a\ncross-pollination of ideas across domains and fields. To enhance the\nproductivity of researchers, we propose ResearchAgent, which leverages the\nencyclopedic knowledge and linguistic reasoning capabilities of Large Language\nModels (LLMs) to assist them in their work. This system automatically defines\nnovel problems, proposes methods and designs experiments, while iteratively\nrefining them based on the feedback from collaborative LLM-powered reviewing\nagents. Specifically, starting with a core scientific paper, ResearchAgent is\naugmented not only with relevant publications by connecting information over an\nacademic graph but also entities retrieved from a knowledge store derived from\nshared underlying concepts mined across numerous papers. Then, mimicking a\nscientific approach to improving ideas with peer discussions, we leverage\nmultiple LLM-based ReviewingAgents that provide reviews and feedback via\niterative revision processes. These reviewing agents are instantiated with\nhuman preference-aligned LLMs whose criteria for evaluation are elicited from\nactual human judgments via LLM prompting. We experimentally validate our\nResearchAgent on scientific publications across multiple disciplines, showing\nits effectiveness in generating novel, clear, and valid ideas based on both\nhuman and model-based evaluation results. Our initial foray into AI-mediated\nscientific research has important implications for the development of future\nsystems aimed at supporting researchers in their ideation and\noperationalization of novel work.",
      "tldr_zh": "该论文提出ResearchAgent，一种利用Large Language Models (LLMs)辅助科研人员从科学文献中生成并迭代研究想法的系统。该系统从核心论文出发，通过学术图谱连接相关出版物和知识实体，并采用多个LLM-powered ReviewingAgents提供反馈和迭代优化，模拟同行评审过程以提升想法的质量。实验在多个学科的科学出版物上验证，显示ResearchAgent能生成新颖、清晰且有效的想法，并为AI辅助科研的未来发展提供重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.07738v2",
      "published_date": "2024-04-11 13:36:29 UTC",
      "updated_date": "2025-02-09 08:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:37:52.660309"
    },
    {
      "arxiv_id": "2404.07735v2",
      "title": "Diffusing in Someone Else's Shoes: Robotic Perspective Taking with Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Josua Spisak",
        "Matthias Kerzel",
        "Stefan Wermter"
      ],
      "abstract": "Humanoid robots can benefit from their similarity to the human shape by\nlearning from humans. When humans teach other humans how to perform actions,\nthey often demonstrate the actions, and the learning human imitates the\ndemonstration to get an idea of how to perform the action. Being able to\nmentally transfer from a demonstration seen from a third-person perspective to\nhow it should look from a first-person perspective is fundamental for this\nability in humans. As this is a challenging task, it is often simplified for\nrobots by creating demonstrations from the first-person perspective. Creating\nthese demonstrations allows for an easier imitation but requires more effort.\nTherefore, we introduce a novel diffusion model that enables the robot to learn\nfrom the third-person demonstrations directly by learning to generate the\nfirst-person perspective from the third-person perspective. The model\ntranslates the size and rotations of objects and the environment between the\ntwo perspectives. This allows us to utilise the benefits of easy-to-produce\nthird-person demonstrations and easy-to-imitate first-person demonstrations.",
      "tldr_zh": "这篇论文提出了一种新型 diffusion model，帮助人形机器人从第三人称视角的演示直接学习动作，而无需额外创建第一人称视角演示。模型通过生成第一人称视角图像，处理对象的大小、旋转和环境转换，实现视角之间的平滑转移。该方法结合了第三人称演示易于制作的优势和第一人称演示易于模仿的便利性，显著提高了机器人的模仿学习效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to Humanoids",
      "pdf_url": "http://arxiv.org/pdf/2404.07735v2",
      "published_date": "2024-04-11 13:30:03 UTC",
      "updated_date": "2024-10-04 14:03:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:38:03.952083"
    },
    {
      "arxiv_id": "2404.07732v1",
      "title": "Monte Carlo Tree Search with Boltzmann Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Painter",
        "Mohamed Baioumy",
        "Nick Hawes",
        "Bruno Lacerda"
      ],
      "abstract": "Monte-Carlo Tree Search (MCTS) methods, such as Upper Confidence Bound\napplied to Trees (UCT), are instrumental to automated planning techniques.\nHowever, UCT can be slow to explore an optimal action when it initially appears\ninferior to other actions. Maximum ENtropy Tree-Search (MENTS) incorporates the\nmaximum entropy principle into an MCTS approach, utilising Boltzmann policies\nto sample actions, naturally encouraging more exploration. In this paper, we\nhighlight a major limitation of MENTS: optimal actions for the maximum entropy\nobjective do not necessarily correspond to optimal actions for the original\nobjective. We introduce two algorithms, Boltzmann Tree Search (BTS) and\nDecaying ENtropy Tree-Search (DENTS), that address these limitations and\npreserve the benefits of Boltzmann policies, such as allowing actions to be\nsampled faster by using the Alias method. Our empirical analysis shows that our\nalgorithms show consistent high performance across several benchmark domains,\nincluding the game of Go.",
      "tldr_zh": "本研究探讨了 Monte-Carlo Tree Search (MCTS) 方法中的探索问题，指出传统 Upper Confidence Bound applied to Trees (UCT) 在识别最优动作时效率低下，而 Maximum ENtropy Tree-Search (MENTS) 虽通过 Boltzmann policies 促进探索，但其最大熵目标的最优动作不一定符合原目标。作者提出两种新算法：Boltzmann Tree Search (BTS) 和 Decaying ENtropy Tree-Search (DENTS)，这些算法保留了 Boltzmann policies 的优势（如使用 Alias method 加速采样），并有效解决了 MENTS 的局限性。实验结果显示，BTS 和 DENTS 在多个基准领域，包括围棋游戏中，表现出稳定的高性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Camera ready version of NeurIPS2023 paper",
      "pdf_url": "http://arxiv.org/pdf/2404.07732v1",
      "published_date": "2024-04-11 13:25:35 UTC",
      "updated_date": "2024-04-11 13:25:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:38:18.280594"
    },
    {
      "arxiv_id": "2404.07725v1",
      "title": "Unraveling the Dilemma of AI Errors: Exploring the Effectiveness of Human and Machine Explanations for Large Language Models",
      "title_zh": "揭示 AI 错误的两难困境：探索人类和机器解释对大型",
      "authors": [
        "Marvin Pafla",
        "Kate Larson",
        "Mark Hancock"
      ],
      "abstract": "The field of eXplainable artificial intelligence (XAI) has produced a\nplethora of methods (e.g., saliency-maps) to gain insight into artificial\nintelligence (AI) models, and has exploded with the rise of deep learning (DL).\nHowever, human-participant studies question the efficacy of these methods,\nparticularly when the AI output is wrong. In this study, we collected and\nanalyzed 156 human-generated text and saliency-based explanations collected in\na question-answering task (N=40) and compared them empirically to\nstate-of-the-art XAI explanations (integrated gradients, conservative LRP, and\nChatGPT) in a human-participant study (N=136). Our findings show that\nparticipants found human saliency maps to be more helpful in explaining AI\nanswers than machine saliency maps, but performance negatively correlated with\ntrust in the AI model and explanations. This finding hints at the dilemma of AI\nerrors in explanation, where helpful explanations can lead to lower task\nperformance when they support wrong AI predictions.",
      "tldr_zh": "这篇论文探讨了可解释人工智能 (XAI) 方法的有效性，特别是当大型语言模型 (LLMs) 输出错误时。研究者收集了156个人类生成的文本和基于显著性地图 (saliency-maps) 的解释（来自N=40的问答任务），并通过人类参与者研究 (N=136) 与机器方法如 integrated gradients、conservative LRP 和 ChatGPT 进行比较。结果显示，参与者认为人类显著性地图比机器显著性地图更helpful，但对AI模型和解释的信任与任务性能负相关，揭示了AI错误解释的困境，即helpful的解释可能导致更低的表现，因为它们支持了错误的AI预测。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07725v1",
      "published_date": "2024-04-11 13:16:51 UTC",
      "updated_date": "2024-04-11 13:16:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:38:29.616688"
    },
    {
      "arxiv_id": "2404.07724v2",
      "title": "Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tuomas Kynkäänniemi",
        "Miika Aittala",
        "Tero Karras",
        "Samuli Laine",
        "Timo Aila",
        "Jaakko Lehtinen"
      ],
      "abstract": "Guidance is a crucial technique for extracting the best performance out of\nimage-generating diffusion models. Traditionally, a constant guidance weight\nhas been applied throughout the sampling chain of an image. We show that\nguidance is clearly harmful toward the beginning of the chain (high noise\nlevels), largely unnecessary toward the end (low noise levels), and only\nbeneficial in the middle. We thus restrict it to a specific range of noise\nlevels, improving both the inference speed and result quality. This limited\nguidance interval improves the record FID in ImageNet-512 significantly, from\n1.81 to 1.40. We show that it is quantitatively and qualitatively beneficial\nacross different sampler parameters, network architectures, and datasets,\nincluding the large-scale setting of Stable Diffusion XL. We thus suggest\nexposing the guidance interval as a hyperparameter in all diffusion models that\nuse guidance.",
      "tldr_zh": "本研究发现，在图像生成扩散模型(diffusion models)中，传统恒定指导(guidance)权重应用会导致采样链早期(高噪声水平)有害、后期(低噪声水平)无益的问题。作者提出将guidance限制在特定噪声水平区间，仅在中间阶段应用，从而提升推理速度和样本分布质量。实验结果显示，这种方法在ImageNet-512上将FID从1.81降至1.40，并在不同采样器参数、网络架构和数据集（如Stable Diffusion XL）上均表现出显著改善，最终建议将guidance区间作为超参数公开使用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07724v2",
      "published_date": "2024-04-11 13:16:47 UTC",
      "updated_date": "2024-11-06 14:29:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:38:40.755566"
    },
    {
      "arxiv_id": "2404.07719v2",
      "title": "Reframing the Mind-Body Picture: Applying Formal Systems to the Relationship of Mind and Matter",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Williams"
      ],
      "abstract": "This paper aims to show that a simple framework, utilizing basic formalisms\nfrom set theory and category theory, can clarify and inform our theories of the\nrelation between mind and matter.",
      "tldr_zh": "这篇论文提出一个简单框架，利用集合论（set theory）和范畴论（category theory）的基本形式系统，来阐明和指导心身关系（mind and matter）的理论。论文旨在通过这些形式化工具，澄清传统理论中的模糊点，并为更精确的思维与物质互动模型提供基础。这种方法为哲学和认知科学领域提供了新的分析视角，有助于深化对心身问题的理解。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07719v2",
      "published_date": "2024-04-11 13:11:13 UTC",
      "updated_date": "2024-10-13 20:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:38:51.671948"
    },
    {
      "arxiv_id": "2407.07747v1",
      "title": "HGFF: A Deep Reinforcement Learning Framework for Lifetime Maximization in Wireless Sensor Networks",
      "title_zh": "HGFF：用于无线传感器网络寿命最大化的深度强化学习框架",
      "authors": [
        "Xiaoxu Han",
        "Xin Mu",
        "Jinghui Zhong"
      ],
      "abstract": "Planning the movement of the sink to maximize the lifetime in wireless sensor\nnetworks is an essential problem of great research challenge and practical\nvalue. Many existing mobile sink techniques based on mathematical programming\nor heuristics have demonstrated the feasibility of the task. Nevertheless, the\nhuge computation consumption or the over-reliance on human knowledge can result\nin relatively low performance. In order to balance the need for high-quality\nsolutions with the goal of minimizing inference time, we propose a new\nframework combining heterogeneous graph neural network with deep reinforcement\nlearning to automatically construct the movement path of the sink. Modeling the\nwireless sensor networks as heterogeneous graphs, we utilize the graph neural\nnetwork to learn representations of sites and sensors by aggregating features\nof neighbor nodes and extracting hierarchical graph features. Meanwhile, the\nmulti-head attention mechanism is leveraged to allow the sites to attend to\ninformation from sensor nodes, which highly improves the expressive capacity of\nthe learning model. Based on the node representations, a greedy policy is\nlearned to append the next best site in the solution incrementally. We design\nten types of static and dynamic maps to simulate different wireless sensor\nnetworks in the real world, and extensive experiments are conducted to evaluate\nand analyze our approach. The empirical results show that our approach\nconsistently outperforms the existing methods on all types of maps.",
      "tldr_zh": "本研究提出HGFF框架，利用Deep Reinforcement Learning结合Heterogeneous Graph Neural Network，旨在最大化无线传感器网络的寿命，通过自动规划移动接收器的路径。框架将网络建模为异构图，使用图神经网络聚合邻居节点特征并通过Multi-Head Attention机制增强信息交互，然后基于学习到的节点表示采用Greedy Policy逐步构建最优路径。实验在十种静态和动态地图上进行，结果显示HGFF在所有场景下均优于现有方法，提供更高效的解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Preprint. Under review",
      "pdf_url": "http://arxiv.org/pdf/2407.07747v1",
      "published_date": "2024-04-11 13:09:11 UTC",
      "updated_date": "2024-04-11 13:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:39:03.863019"
    },
    {
      "arxiv_id": "2404.07698v2",
      "title": "Point Cloud Geometry Scalable Coding with a Quality-Conditioned Latents Probability Estimator",
      "title_zh": "翻译失败",
      "authors": [
        "Daniele Mari",
        "André F. R. Guarda",
        "Nuno M. M. Rodrigues",
        "Simone Milani",
        "Fernando Pereira"
      ],
      "abstract": "The widespread usage of point clouds (PC) for immersive visual applications\nhas resulted in the use of very heterogeneous receiving conditions and devices,\nnotably in terms of network, hardware, and display capabilities. In this\nscenario, quality scalability, i.e., the ability to reconstruct a signal at\ndifferent qualities by progressively decoding a single bitstream, is a major\nrequirement that has yet to be conveniently addressed, notably in most\nlearning-based PC coding solutions. This paper proposes a quality scalability\nscheme, named Scalable Quality Hyperprior (SQH), adaptable to learning-based\nstatic point cloud geometry codecs, which uses a Quality-conditioned Latents\nProbability Estimator (QuLPE) to decode a high-quality version of a PC\nlearning-based representation, based on an available lower quality base layer.\nSQH is integrated in the future JPEG PC coding standard, allowing to create a\nlayered bitstream that can be used to progressively decode the PC geometry with\nincreasing quality and fidelity. Experimental results show that SQH offers the\nquality scalability feature with very limited or no compression performance\npenalty at all when compared with the corresponding non-scalable solution, thus\npreserving the significant compression gains over other state-of-the-art PC\ncodecs.",
      "tldr_zh": "该论文针对点云 (PC) 在异构设备下的编码需求，提出了一种质量可伸缩方案 Scalable Quality Hyperprior (SQH)，以适应不同网络、硬件和显示条件。SQH 利用 Quality-conditioned Latents Probability Estimator (QuLPE) 基于较低质量的基层解码更高质量的点云几何表示，从而实现单个比特流的渐进式重建。实验结果表明，SQH 整合到未来的 JPEG PC 编码标准后，提供质量可伸缩性，同时几乎不影响压缩性能，并保持了对其他最先进编解码器的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICIP 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07698v2",
      "published_date": "2024-04-11 12:44:15 UTC",
      "updated_date": "2024-07-09 06:56:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:39:18.504967"
    },
    {
      "arxiv_id": "2404.07686v1",
      "title": "Depth Estimation using Weighted-loss and Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Adeel Hafeez",
        "Michael G. Madden",
        "Ganesh Sistu",
        "Ihsan Ullah"
      ],
      "abstract": "Depth estimation from 2D images is a common computer vision task that has\napplications in many fields including autonomous vehicles, scene understanding\nand robotics. The accuracy of a supervised depth estimation method mainly\nrelies on the chosen loss function, the model architecture, quality of data and\nperformance metrics. In this study, we propose a simplified and adaptable\napproach to improve depth estimation accuracy using transfer learning and an\noptimized loss function. The optimized loss function is a combination of\nweighted losses to which enhance robustness and generalization: Mean Absolute\nError (MAE), Edge Loss and Structural Similarity Index (SSIM). We use a grid\nsearch and a random search method to find optimized weights for the losses,\nwhich leads to an improved model. We explore multiple encoder-decoder-based\nmodels including DenseNet121, DenseNet169, DenseNet201, and EfficientNet for\nthe supervised depth estimation model on NYU Depth Dataset v2. We observe that\nthe EfficientNet model, pre-trained on ImageNet for classification when used as\nan encoder, with a simple upsampling decoder, gives the best results in terms\nof RSME, REL and log10: 0.386, 0.113 and 0.049, respectively. We also perform a\nqualitative analysis which illustrates that our model produces depth maps that\nclosely resemble ground truth, even in cases where the ground truth is flawed.\nThe results indicate significant improvements in accuracy and robustness, with\nEfficientNet being the most successful architecture.",
      "tldr_zh": "本文提出了一种使用转移学习（transfer learning）和加权损失函数来提升从2D图像中估计深度的准确性，适用于自动驾驶、场景理解和机器人等领域。损失函数结合了Mean Absolute Error (MAE)、Edge Loss和Structural Similarity Index (SSIM)，并通过网格搜索和随机搜索优化权重，以提高模型的鲁棒性和泛化能力。在NYU Depth Dataset v2上测试多种编码器-解码器模型后，发现EfficientNet作为编码器与简单上采样解码器结合，取得了最佳结果：RSME 0.386、REL 0.113和log10 0.049。该方法在定性分析中显示，生成的深度图与地面真实值高度一致，即使真实值有缺陷，也显著提升了整体准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07686v1",
      "published_date": "2024-04-11 12:25:54 UTC",
      "updated_date": "2024-04-11 12:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:39:31.321827"
    },
    {
      "arxiv_id": "2404.07685v1",
      "title": "Run-time Monitoring of 3D Object Detection in Automated Driving Systems Using Early Layer Neural Activation Patterns",
      "title_zh": "运行时监控自动驾驶系统中3D对象检测的早期层神经激活模式",
      "authors": [
        "Hakan Yekta Yatbaz",
        "Mehrdad Dianati",
        "Konstantinos Koufos",
        "Roger Woodman"
      ],
      "abstract": "Monitoring the integrity of object detection for errors within the perception\nmodule of automated driving systems (ADS) is paramount for ensuring safety.\nDespite recent advancements in deep neural network (DNN)-based object\ndetectors, their susceptibility to detection errors, particularly in the\nless-explored realm of 3D object detection, remains a significant concern.\nState-of-the-art integrity monitoring (also known as introspection) mechanisms\nin 2D object detection mainly utilise the activation patterns in the final\nlayer of the DNN-based detector's backbone. However, that may not sufficiently\naddress the complexities and sparsity of data in 3D object detection. To this\nend, we conduct, in this article, an extensive investigation into the effects\nof activation patterns extracted from various layers of the backbone network\nfor introspecting the operation of 3D object detectors. Through a comparative\nanalysis using Kitti and NuScenes datasets with PointPillars and CenterPoint\ndetectors, we demonstrate that using earlier layers' activation patterns\nenhances the error detection performance of the integrity monitoring system,\nyet increases computational complexity. To address the real-time operation\nrequirements in ADS, we also introduce a novel introspection method that\ncombines activation patterns from multiple layers of the detector's backbone\nand report its performance.",
      "tldr_zh": "该研究针对自动驾驶系统（ADS）中 3D 对象检测的完整性监控问题，调查了使用深度神经网络（DNN）骨干网络不同层激活模式来检测错误的影响。相比传统的基于最终层激活模式的机制，作者发现利用早期层激活模式能显著提升错误检测性能，但会增加计算复杂度。针对 ADS 的实时需求，他们提出了一种新颖的内省方法，该方法结合多个层激活模式，并在 Kitti 和 NuScenes 数据集上使用 PointPillars 和 CenterPoint 检测器进行评估，展示了其优越性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2024 Workshop on Safe Autonomy for All Domains\n  (SAIAD)",
      "pdf_url": "http://arxiv.org/pdf/2404.07685v1",
      "published_date": "2024-04-11 12:24:47 UTC",
      "updated_date": "2024-04-11 12:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:39:41.677541"
    },
    {
      "arxiv_id": "2404.07677v2",
      "title": "ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Sun",
        "Zhengwei Tao",
        "Youdi Li",
        "Hiroshi Arakawa"
      ],
      "abstract": "The integration of Large Language Models (LLMs) and knowledge graphs (KGs)\nhas achieved remarkable success in various natural language processing tasks.\nHowever, existing methodologies that integrate LLMs and KGs often navigate the\ntask-solving process solely based on the LLM's analysis of the question,\noverlooking the rich cognitive potential inherent in the vast knowledge\nencapsulated in KGs. To address this, we introduce Observation-Driven Agent\n(ODA), a novel AI agent framework tailored for tasks involving KGs. ODA\nincorporates KG reasoning abilities via global observation, which enhances\nreasoning capabilities through a cyclical paradigm of observation, action, and\nreflection. Confronting the exponential explosion of knowledge during\nobservation, we innovatively design a recursive observation mechanism.\nSubsequently, we integrate the observed knowledge into the action and\nreflection modules. Through extensive experiments, ODA demonstrates\nstate-of-the-art performance on several datasets, notably achieving accuracy\nimprovements of 12.87% and 8.9%.",
      "tldr_zh": "该研究提出了一种名为 ODA 的 Observation-Driven Agent 框架，用于整合 Large Language Models (LLMs) 和 Knowledge Graphs (KGs)，以解决现有方法忽略 KG 中丰富知识的问题。ODA 通过全球观察机制和观察-行动-反思的循环范式增强推理能力，并引入递归观察机制来处理知识爆炸问题，将观察到的知识整合到行动和反思模块中。在多个数据集上的实验中，ODA 实现了最先进性能，准确率分别提高了 12.87% 和 8.9%。这为基于 KGs 的任务提供了一种更高效的推理方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "LLM+KG",
      "pdf_url": "http://arxiv.org/pdf/2404.07677v2",
      "published_date": "2024-04-11 12:16:16 UTC",
      "updated_date": "2024-06-04 07:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:39:51.931962"
    },
    {
      "arxiv_id": "2404.07676v1",
      "title": "Model-based Cleaning of the QUILT-1M Pathology Dataset for Text-Conditional Image Synthesis",
      "title_zh": "基于模型的",
      "authors": [
        "Marc Aubreville",
        "Jonathan Ganz",
        "Jonas Ammeling",
        "Christopher C. Kaltenecker",
        "Christof A. Bertram"
      ],
      "abstract": "The QUILT-1M dataset is the first openly available dataset containing images\nharvested from various online sources. While it provides a huge data variety,\nthe image quality and composition is highly heterogeneous, impacting its\nutility for text-conditional image synthesis. We propose an automatic pipeline\nthat provides predictions of the most common impurities within the images,\ne.g., visibility of narrators, desktop environment and pathology software, or\ntext within the image. Additionally, we propose to use semantic alignment\nfiltering of the image-text pairs. Our findings demonstrate that by rigorously\nfiltering the dataset, there is a substantial enhancement of image fidelity in\ntext-to-image tasks.",
      "tldr_zh": "本研究针对 QUILT-1M 数据集的图像质量和组成异质性问题，提出一个自动管道来预测常见杂质，如叙述者可见、桌面环境、病理软件或图像中的文本。\n该管道还结合语义对齐过滤，优化图像-文本对的质量，以提升文本-conditional image synthesis 的效用。\n结果表明，通过严格过滤数据集，文本到图像任务的图像保真度得到显著增强。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages (short paper)",
      "pdf_url": "http://arxiv.org/pdf/2404.07676v1",
      "published_date": "2024-04-11 12:14:48 UTC",
      "updated_date": "2024-04-11 12:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:40:04.165400"
    },
    {
      "arxiv_id": "2404.07664v2",
      "title": "Finding Dino: A Plug-and-Play Framework for Zero-Shot Detection of Out-of-Distribution Objects Using Prototypes",
      "title_zh": "翻译失败",
      "authors": [
        "Poulami Sinhamahapatra",
        "Franziska Schwaiger",
        "Shirsha Bose",
        "Huiyu Wang",
        "Karsten Roscher",
        "Stephan Guennemann"
      ],
      "abstract": "Detecting and localising unknown or out-of-distribution (OOD) objects in any\nscene can be a challenging task in vision, particularly in safety-critical\ncases involving autonomous systems like automated vehicles or trains.\nSupervised anomaly segmentation or open-world object detection models depend on\ntraining on exhaustively annotated datasets for every domain and still struggle\nin distinguishing between background and OOD objects. In this work, we present\na plug-and-play framework - PRototype-based OOD detection Without Labels\n(PROWL). It is an inference-based method that does not require training on the\ndomain dataset and relies on extracting relevant features from self-supervised\npre-trained models. PROWL can be easily adapted to detect in-domain objects in\nany operational design domain (ODD) in a zero-shot manner by specifying a list\nof known classes from this domain. PROWL, as a first zero-shot unsupervised\nmethod, achieves state-of-the-art results on the RoadAnomaly and RoadObstacle\ndatasets provided in road driving benchmarks - SegmentMeIfYouCan (SMIYC) and\nFishyscapes, as well as comparable performance against existing supervised\nmethods trained without auxiliary OOD data. We also demonstrate its\ngeneralisability to other domains such as rail and maritime.",
      "tldr_zh": "该研究提出了一种即插即用（Plug-and-Play）框架Finding Dino，用于零样本（Zero-Shot）检测外部分布对象（Out-of-Distribution Objects），通过利用原型（Prototypes）从自监督预训练模型中提取特征，实现无需额外训练的数据驱动检测。框架名为PROWL（PRototype-based OOD detection Without Labels），允许用户通过指定已知类列表轻松适应任何操作设计域（ODD）。实验结果显示，PROWL在RoadAnomaly和RoadObstacle数据集上达到最先进性能，与监督方法相当，并证明了其在铁路和海洋等领域的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.07664v2",
      "published_date": "2024-04-11 11:55:42 UTC",
      "updated_date": "2025-02-11 14:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:40:17.133917"
    },
    {
      "arxiv_id": "2404.07663v1",
      "title": "Interactive Ontology Matching with Cost-Efficient Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Cheng",
        "Jonathan Fürst",
        "Tobias Jacobs",
        "Celia Garrido-Hidalgo"
      ],
      "abstract": "The creation of high-quality ontologies is crucial for data integration and\nknowledge-based reasoning, specifically in the context of the rising data\neconomy. However, automatic ontology matchers are often bound to the heuristics\nthey are based on, leaving many matches unidentified. Interactive ontology\nmatching systems involving human experts have been introduced, but they do not\nsolve the fundamental issue of flexibly finding additional matches outside the\nscope of the implemented heuristics, even though this is highly demanded in\nindustrial settings. Active machine learning methods appear to be a promising\npath towards a flexible interactive ontology matcher. However, off-the-shelf\nactive learning mechanisms suffer from low query efficiency due to extreme\nclass imbalance, resulting in a last-mile problem where high human effort is\nrequired to identify the remaining matches.\n  To address the last-mile problem, this work introduces DualLoop, an active\nlearning method tailored to ontology matching. DualLoop offers three main\ncontributions: (1) an ensemble of tunable heuristic matchers, (2) a short-term\nlearner with a novel query strategy adapted to highly imbalanced data, and (3)\nlong-term learners to explore potential matches by creating and tuning new\nheuristics. We evaluated DualLoop on three datasets of varying sizes and\ndomains. Compared to existing active learning methods, we consistently achieved\nbetter F1 scores and recall, reducing the expected query cost spent on finding\n90% of all matches by over 50%. Compared to traditional interactive ontology\nmatchers, we are able to find additional, last-mile matches. Finally, we detail\nthe successful deployment of our approach within an actual product and report\nits operational performance results within the Architecture, Engineering, and\nConstruction (AEC) industry sector, showcasing its practical value and\nefficiency.",
      "tldr_zh": "本研究针对本体匹配（Ontology Matching）中的灵活性和效率问题，提出了一种成本高效的主动学习（Active Learning）方法DualLoop，以解决现有方法的启发式局限性和类不平衡导致的查询效率低问题。DualLoop的主要贡献包括：(1) 一组可调谐的启发式匹配器，(2) 带有适应高度不平衡数据的novel query strategy的短期学习器，以及(3) 长期学习器用于探索和创建新启发式以发现额外匹配。在三个不同数据集上的实验显示，DualLoop比现有主动学习方法提高了F1 scores和recall，将找到90%匹配的查询成本减少超过50%；此外，该方法已在建筑、工程和建筑（AEC）行业成功部署，证明了其实际价值和效率。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07663v1",
      "published_date": "2024-04-11 11:53:14 UTC",
      "updated_date": "2024-04-11 11:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:40:29.873982"
    },
    {
      "arxiv_id": "2404.07662v1",
      "title": "PINNACLE: PINN Adaptive ColLocation and Experimental points selection",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Kang Ruey Lau",
        "Apivich Hemachandra",
        "See-Kiong Ng",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs), which incorporate PDEs as soft\nconstraints, train with a composite loss function that contains multiple\ntraining point types: different types of collocation points chosen during\ntraining to enforce each PDE and initial/boundary conditions, and experimental\npoints which are usually costly to obtain via experiments or simulations.\nTraining PINNs using this loss function is challenging as it typically requires\nselecting large numbers of points of different types, each with different\ntraining dynamics. Unlike past works that focused on the selection of either\ncollocation or experimental points, this work introduces PINN Adaptive\nColLocation and Experimental points selection (PINNACLE), the first algorithm\nthat jointly optimizes the selection of all training point types, while\nautomatically adjusting the proportion of collocation point types as training\nprogresses. PINNACLE uses information on the interaction among training point\ntypes, which had not been considered before, based on an analysis of PINN\ntraining dynamics via the Neural Tangent Kernel (NTK). We theoretically show\nthat the criterion used by PINNACLE is related to the PINN generalization\nerror, and empirically demonstrate that PINNACLE is able to outperform existing\npoint selection methods for forward, inverse, and transfer learning problems.",
      "tldr_zh": "这篇论文介绍了PINNACLE，一种创新算法，用于Physics-Informed Neural Networks (PINNs)的训练点选择，首次联合优化collocation points和experimental points，同时在训练过程中自动调整collocation点类型的比例。PINNACLE基于Neural Tangent Kernel (NTK)对PINN训练动态的分析，考虑了不同点类型之间的交互，以提升训练效率。理论上，该算法与PINNs的泛化错误相关，实验结果显示它在forward、inverse和transfer learning问题上优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph",
        "physics.data-an",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to 12th International Conference on Learning Representations\n  (ICLR 2024), 36 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.07662v1",
      "published_date": "2024-04-11 11:51:46 UTC",
      "updated_date": "2024-04-11 11:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:40:40.952041"
    },
    {
      "arxiv_id": "2404.08706v2",
      "title": "Game Generation via Large Language Models",
      "title_zh": "基于大型语言模型的游戏生成",
      "authors": [
        "Chengpeng Hu",
        "Yunlong Zhao",
        "Jialin Liu"
      ],
      "abstract": "Recently, the emergence of large language models (LLMs) has unlocked new\nopportunities for procedural content generation. However, recent attempts\nmainly focus on level generation for specific games with defined game rules\nsuch as Super Mario Bros. and Zelda. This paper investigates the game\ngeneration via LLMs. Based on video game description language, this paper\nproposes an LLM-based framework to generate game rules and levels\nsimultaneously. Experiments demonstrate how the framework works with prompts\nconsidering different combinations of context. Our findings extend the current\napplications of LLMs and offer new insights for generating new games in the\narea of procedural content generation.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型（LLMs）生成游戏的可能性，超越了以往仅针对特定游戏（如 Super Mario Bros.）的关卡生成。研究提出一个基于视频游戏描述语言的框架，能够同时生成游戏规则和关卡，通过不同提示组合来优化生成过程。实验结果证明了框架的有效性，并扩展了 LLMs 在程序化内容生成领域的应用，提供新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "2024 IEEE Conference on Games",
      "pdf_url": "http://arxiv.org/pdf/2404.08706v2",
      "published_date": "2024-04-11 10:06:05 UTC",
      "updated_date": "2024-05-30 03:17:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:40:51.813669"
    },
    {
      "arxiv_id": "2404.07613v1",
      "title": "Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Iker García-Ferrero",
        "Rodrigo Agerri",
        "Aitziber Atutxa Salazar",
        "Elena Cabrio",
        "Iker de la Iglesia",
        "Alberto Lavelli",
        "Bernardo Magnini",
        "Benjamin Molinet",
        "Johana Ramirez-Romero",
        "German Rigau",
        "Jose Maria Villa-Gonzalez",
        "Serena Villata",
        "Andrea Zaninello"
      ],
      "abstract": "Research on language technology for the development of medical applications\nis currently a hot topic in Natural Language Understanding and Generation.\nThus, a number of large language models (LLMs) have recently been adapted to\nthe medical domain, so that they can be used as a tool for mediating in\nhuman-AI interaction. While these LLMs display competitive performance on\nautomated medical texts benchmarks, they have been pre-trained and evaluated\nwith a focus on a single language (English mostly). This is particularly true\nof text-to-text models, which typically require large amounts of\ndomain-specific pre-training data, often not easily accessible for many\nlanguages. In this paper, we address these shortcomings by compiling, to the\nbest of our knowledge, the largest multilingual corpus for the medical domain\nin four languages, namely English, French, Italian and Spanish. This new corpus\nhas been used to train Medical mT5, the first open-source text-to-text\nmultilingual model for the medical domain. Additionally, we present two new\nevaluation benchmarks for all four languages with the aim of facilitating\nmultilingual research in this domain. A comprehensive evaluation shows that\nMedical mT5 outperforms both encoders and similarly sized text-to-text models\nfor the Spanish, French, and Italian benchmarks, while being competitive with\ncurrent state-of-the-art LLMs in English.",
      "tldr_zh": "该论文针对医疗领域LLM（Large Language Models）的单语言局限性，编译了目前最大的多语言医疗语料库，包括英语、法语、意大利语和西班牙语。\n他们训练了开源的Medical mT5模型，这是第一个多语言text-to-text LLM，专门针对医疗文本理解和生成。\n论文还引入了两个新的多语言评估基准，以促进该领域的多语言研究。\n结果显示，Medical mT5在西班牙语、法语和意大利语基准上超过了编码器和类似大小的text-to-text模型，在英语上与最先进LLM的性能相当。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07613v1",
      "published_date": "2024-04-11 10:01:32 UTC",
      "updated_date": "2024-04-11 10:01:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:41:04.787017"
    },
    {
      "arxiv_id": "2404.07611v2",
      "title": "NoticIA: A Clickbait Article Summarization Dataset in Spanish",
      "title_zh": "翻译失败",
      "authors": [
        "Iker García-Ferrero",
        "Begoña Altuna"
      ],
      "abstract": "We present NoticIA, a dataset consisting of 850 Spanish news articles\nfeaturing prominent clickbait headlines, each paired with high-quality,\nsingle-sentence generative summarizations written by humans. This task demands\nadvanced text understanding and summarization abilities, challenging the\nmodels' capacity to infer and connect diverse pieces of information to meet the\nuser's informational needs generated by the clickbait headline. We evaluate the\nSpanish text comprehension capabilities of a wide range of state-of-the-art\nlarge language models. Additionally, we use the dataset to train\nClickbaitFighter, a task-specific model that achieves near-human performance in\nthis task.",
      "tldr_zh": "本研究引入了 NoticIA 数据集，该数据集包含 850 篇西班牙语新闻文章，每篇配有突出的 clickbait headlines 和高质量的人类撰写的单句总结，用于测试模型的文本理解和总结能力。NoticIA 强调模型需推断并连接多样信息，以满足点击诱导标题带来的用户需求。研究评估了多种 state-of-the-art large language models 的西班牙文本理解性能，并利用该数据集训练了 ClickbaitFighter 模型，该模型在任务中达到了接近人类的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in the journal Procesamiento del Lenguaje Natural",
      "pdf_url": "http://arxiv.org/pdf/2404.07611v2",
      "published_date": "2024-04-11 09:59:01 UTC",
      "updated_date": "2024-05-31 15:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:41:16.893942"
    },
    {
      "arxiv_id": "2404.07605v1",
      "title": "Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Dedieu",
        "Nicolas Nerrienet",
        "Adrien Nivaggioli",
        "Clara Simmat",
        "Marceau Clavel",
        "Arnaud Gauthier",
        "Stéphane Sockeel",
        "Rémy Peyret"
      ],
      "abstract": "Recent advancements in deep learning have proven highly effective in medical\nimage classification, notably within histopathology. However, noisy labels\nrepresent a critical challenge in histopathology image classification, where\naccurate annotations are vital for training robust deep learning models.\nIndeed, deep neural networks can easily overfit label noise, leading to severe\ndegradations in model performance. While numerous public pathology foundation\nmodels have emerged recently, none have evaluated their resilience to label\nnoise. Through thorough empirical analyses across multiple datasets, we exhibit\nthe label noise resilience property of embeddings extracted from foundation\nmodels trained in a self-supervised contrastive manner. We demonstrate that\ntraining with such embeddings substantially enhances label noise robustness\nwhen compared to non-contrastive-based ones as well as commonly used\nnoise-resilient methods. Our results unequivocally underline the superiority of\ncontrastive learning in effectively mitigating the label noise challenge. Code\nis publicly available at\nhttps://github.com/LucasDedieu/NoiseResilientHistopathology.",
      "tldr_zh": "本研究探讨了在组织病理学图像分类中，标签噪声（label noise）对深度学习模型的负面影响，强调了准确标注的重要性。作者通过实证分析发现，自监督对比学习（self-supervised contrastive manner）训练的深度嵌入（deep embeddings）具备出色的标签噪声鲁棒性。相比非对比学习方法和传统抗噪声技术，使用这些嵌入进行训练显著提升了模型性能，并在多个数据集上验证了其优越性。代码已公开在 GitHub 上，便于进一步研究和应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.07605v1",
      "published_date": "2024-04-11 09:47:52 UTC",
      "updated_date": "2024-04-11 09:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:41:28.697592"
    },
    {
      "arxiv_id": "2404.07575v4",
      "title": "An Effective Automated Speaking Assessment Approach to Mitigating Data Scarcity and Imbalanced Distribution",
      "title_zh": "翻译失败",
      "authors": [
        "Tien-Hong Lo",
        "Fu-An Chao",
        "Tzu-I Wu",
        "Yao-Ting Sung",
        "Berlin Chen"
      ],
      "abstract": "Automated speaking assessment (ASA) typically involves automatic speech\nrecognition (ASR) and hand-crafted feature extraction from the ASR transcript\nof a learner's speech. Recently, self-supervised learning (SSL) has shown\nstellar performance compared to traditional methods. However, SSL-based ASA\nsystems are faced with at least three data-related challenges: limited\nannotated data, uneven distribution of learner proficiency levels and\nnon-uniform score intervals between different CEFR proficiency levels. To\naddress these challenges, we explore the use of two novel modeling strategies:\nmetric-based classification and loss reweighting, leveraging distinct SSL-based\nembedding features. Extensive experimental results on the ICNALE benchmark\ndataset suggest that our approach can outperform existing strong baselines by a\nsizable margin, achieving a significant improvement of more than 10% in CEFR\nprediction accuracy.",
      "tldr_zh": "这篇论文针对 Automated Speaking Assessment (ASA) 的数据稀缺和不平衡分布问题，提出了一种新方法，利用 self-supervised learning (SSL) 嵌入特征结合 metric-based classification 和 loss reweighting 策略。方法旨在解决有限标注数据、学习者熟练度水平分布不均以及 CEFR 熟练度分数区间不统一等挑战。在 ICNALE 基准数据集上的实验显示，该方法比现有基线提高了超过 10% 的 CEFR 预测准确率。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to NAACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2404.07575v4",
      "published_date": "2024-04-11 09:06:49 UTC",
      "updated_date": "2025-03-02 13:55:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:41:40.553906"
    },
    {
      "arxiv_id": "2404.07572v3",
      "title": "Fragile Model Watermark for integrity protection: leveraging boundary volatility and sensitive sample-pairing",
      "title_zh": "翻译失败",
      "authors": [
        "ZhenZhe Gao",
        "Zhenjun Tang",
        "Zhaoxia Yin",
        "Baoyuan Wu",
        "Yue Lu"
      ],
      "abstract": "Neural networks have increasingly influenced people's lives. Ensuring the\nfaithful deployment of neural networks as designed by their model owners is\ncrucial, as they may be susceptible to various malicious or unintentional\nmodifications, such as backdooring and poisoning attacks. Fragile model\nwatermarks aim to prevent unexpected tampering that could lead DNN models to\nmake incorrect decisions. They ensure the detection of any tampering with the\nmodel as sensitively as possible.However, prior watermarking methods suffered\nfrom inefficient sample generation and insufficient sensitivity, limiting their\npractical applicability. Our approach employs a sample-pairing technique,\nplacing the model boundaries between pairs of samples, while simultaneously\nmaximizing logits. This ensures that the model's decision results of sensitive\nsamples change as much as possible and the Top-1 labels easily alter regardless\nof the direction it moves.",
      "tldr_zh": "这篇论文提出了一种Fragile model watermark方法，用于保护神经网络的完整性，防止恶意篡改如backdooring和poisoning attacks。方法通过leveraging boundary volatility和sensitive sample-pairing技术，将模型边界置于样本对之间，同时最大化logits，确保敏感样本的决策结果和Top-1 labels高度易变，从而提升篡改检测的敏感性和效率。与现有方法相比，该方案显著提高了实用性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "The article has been accepted by IEEE International Conference on\n  Multimedia and Expo 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07572v3",
      "published_date": "2024-04-11 09:01:52 UTC",
      "updated_date": "2024-06-13 03:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:41:52.019533"
    },
    {
      "arxiv_id": "2404.07569v2",
      "title": "Can Vehicle Motion Planning Generalize to Realistic Long-tail Scenarios?",
      "title_zh": "翻译失败",
      "authors": [
        "Marcel Hallgarten",
        "Julian Zapata",
        "Martin Stoll",
        "Katrin Renz",
        "Andreas Zell"
      ],
      "abstract": "Real-world autonomous driving systems must make safe decisions in the face of\nrare and diverse traffic scenarios. Current state-of-the-art planners are\nmostly evaluated on real-world datasets like nuScenes (open-loop) or nuPlan\n(closed-loop). In particular, nuPlan seems to be an expressive evaluation\nmethod since it is based on real-world data and closed-loop, yet it mostly\ncovers basic driving scenarios. This makes it difficult to judge a planner's\ncapabilities to generalize to rarely-seen situations. Therefore, we propose a\nnovel closed-loop benchmark interPlan containing several edge cases and\nchallenging driving scenarios. We assess existing state-of-the-art planners on\nour benchmark and show that neither rule-based nor learning-based planners can\nsafely navigate the interPlan scenarios. A recently evolving direction is the\nusage of foundation models like large language models (LLM) to handle\ngeneralization. We evaluate an LLM-only planner and introduce a novel hybrid\nplanner that combines an LLM-based behavior planner with a rule-based motion\nplanner that achieves state-of-the-art performance on our benchmark.",
      "tldr_zh": "本研究探讨了车辆运动规划是否能泛化到真实的长期尾场景（rare and diverse traffic scenarios），指出现有评估如nuScenes（开环）和nuPlan（闭环）数据集主要覆盖基本驾驶情况，无法有效测试规划器的泛化能力。论文提出一个新型闭环基准interPlan，包含各种边缘案例和挑战性场景，并评估现有基于规则和学习的方法，结果显示这些规划器无法安全导航这些场景。作者引入一个混合规划器，将LLM-based行为规划器与基于规则的运动规划器结合，实现了在interPlan基准上的最先进性能，展示了基础模型在提升泛化方面的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07569v2",
      "published_date": "2024-04-11 08:57:48 UTC",
      "updated_date": "2024-09-04 11:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:42:04.914677"
    },
    {
      "arxiv_id": "2404.07560v2",
      "title": "Socially Pertinent Robots in Gerontological Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Xavier Alameda-Pineda",
        "Angus Addlesee",
        "Daniel Hernández García",
        "Chris Reinke",
        "Soraya Arias",
        "Federica Arrigoni",
        "Alex Auternaud",
        "Lauriane Blavette",
        "Cigdem Beyan",
        "Luis Gomez Camara",
        "Ohad Cohen",
        "Alessandro Conti",
        "Sébastien Dacunha",
        "Christian Dondrup",
        "Yoav Ellinson",
        "Francesco Ferro",
        "Sharon Gannot",
        "Florian Gras",
        "Nancie Gunson",
        "Radu Horaud",
        "Moreno D'Incà",
        "Imad Kimouche",
        "Séverin Lemaignan",
        "Oliver Lemon",
        "Cyril Liotard",
        "Luca Marchionni",
        "Mordehay Moradi",
        "Tomas Pajdla",
        "Maribel Pino",
        "Michal Polic",
        "Matthieu Py",
        "Ariel Rado",
        "Bin Ren",
        "Elisa Ricci",
        "Anne-Sophie Rigaud",
        "Paolo Rota",
        "Marta Romeo",
        "Nicu Sebe",
        "Weronika Sieińska",
        "Pinchas Tandeitnik",
        "Francesco Tonini",
        "Nicolas Turro",
        "Timothée Wintz",
        "Yanchao Yu"
      ],
      "abstract": "Despite the many recent achievements in developing and deploying social\nrobotics, there are still many underexplored environments and applications for\nwhich systematic evaluation of such systems by end-users is necessary. While\nseveral robotic platforms have been used in gerontological healthcare, the\nquestion of whether or not a social interactive robot with multi-modal\nconversational capabilities will be useful and accepted in real-life facilities\nis yet to be answered. This paper is an attempt to partially answer this\nquestion, via two waves of experiments with patients and companions in a\nday-care gerontological facility in Paris with a full-sized humanoid robot\nendowed with social and conversational interaction capabilities. The software\narchitecture, developed during the H2020 SPRING project, together with the\nexperimental protocol, allowed us to evaluate the acceptability (AES) and\nusability (SUS) with more than 60 end-users. Overall, the users are receptive\nto this technology, especially when the robot perception and action skills are\nrobust to environmental clutter and flexible to handle a plethora of different\ninteractions.",
      "tldr_zh": "本研究探讨了社交机器人（social robots）在老年护理（gerontological healthcare）中的应用潜力，通过在巴黎一家日托中心的两次实验评估其接受度和可用性。实验使用H2020 SPRING项目开发的软件架构和一个具备多模态对话能力的类人机器人，与超过60名患者和伴侣互动，采用AES（Acceptability Evaluation Scale）和SUS（System Usability Scale）进行评估。结果表明，用户对该技术整体持欢迎态度，特别是当机器人对环境杂乱和多样互动具有鲁棒性和灵活性时，这为社交机器人在实际老年护理设施中的部署提供了积极依据。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07560v2",
      "published_date": "2024-04-11 08:43:37 UTC",
      "updated_date": "2025-02-11 08:32:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:42:16.934053"
    },
    {
      "arxiv_id": "2404.07559v1",
      "title": "Differentially Private Reinforcement Learning with Self-Play",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Qiao",
        "Yu-Xiang Wang"
      ],
      "abstract": "We study the problem of multi-agent reinforcement learning (multi-agent RL)\nwith differential privacy (DP) constraints. This is well-motivated by various\nreal-world applications involving sensitive data, where it is critical to\nprotect users' private information. We first extend the definitions of Joint DP\n(JDP) and Local DP (LDP) to two-player zero-sum episodic Markov Games, where\nboth definitions ensure trajectory-wise privacy protection. Then we design a\nprovably efficient algorithm based on optimistic Nash value iteration and\nprivatization of Bernstein-type bonuses. The algorithm is able to satisfy JDP\nand LDP requirements when instantiated with appropriate privacy mechanisms.\nFurthermore, for both notions of DP, our regret bound generalizes the best\nknown result under the single-agent RL case, while our regret could also reduce\nto the best known result for multi-agent RL without privacy constraints. To the\nbest of our knowledge, these are the first line of results towards\nunderstanding trajectory-wise privacy protection in multi-agent RL.",
      "tldr_zh": "本文研究了多智能体强化学习(multi-agent RL)中应用差分隐私(DP)以保护敏感数据隐私的问题，特别是扩展了 Joint DP (JDP) 和 Local DP (LDP) 定义到两玩家零和情节马尔可夫游戏，确保轨迹级隐私保护。作者设计了一个基于乐观 Nash 值迭代和私有化 Bernstein 类型奖励的算法，该算法在使用适当隐私机制时能满足 JDP 和 LDP 要求，并提供高效的遗憾界。实验结果显示，该方法的遗憾界优于单智能体 RL 的最佳已知结果，且在无隐私约束的多智能体 RL 中可减少到最优水平，这是首个针对轨迹级隐私保护的多智能体 RL 研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.MA",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.07559v1",
      "published_date": "2024-04-11 08:42:51 UTC",
      "updated_date": "2024-04-11 08:42:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:42:29.948940"
    },
    {
      "arxiv_id": "2404.07554v2",
      "title": "CAT: Contrastive Adapter Training for Personalized Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jae Wan Park",
        "Sang Hyun Park",
        "Jun Young Koh",
        "Junha Lee",
        "Min Song"
      ],
      "abstract": "The emergence of various adapters, including Low-Rank Adaptation (LoRA)\napplied from the field of natural language processing, has allowed diffusion\nmodels to personalize image generation at a low cost. However, due to the\nvarious challenges including limited datasets and shortage of regularization\nand computation resources, adapter training often results in unsatisfactory\noutcomes, leading to the corruption of the backbone model's prior knowledge.\nOne of the well known phenomena is the loss of diversity in object generation,\nespecially within the same class which leads to generating almost identical\nobjects with minor variations. This poses challenges in generation\ncapabilities. To solve this issue, we present Contrastive Adapter Training\n(CAT), a simple yet effective strategy to enhance adapter training through the\napplication of CAT loss. Our approach facilitates the preservation of the base\nmodel's original knowledge when the model initiates adapters. Furthermore, we\nintroduce the Knowledge Preservation Score (KPS) to evaluate CAT's ability to\nkeep the former information. We qualitatively and quantitatively compare CAT's\nimprovement. Finally, we mention the possibility of CAT in the aspects of\nmulti-concept adapter and optimization.",
      "tldr_zh": "该研究针对适配器训练（如 LoRA）在扩散模型中用于个性化图像生成时面临的挑战，包括数据集有限和资源短缺导致的基模型知识破坏（如生成对象多样性缺失），提出了一种简单有效的策略：Contrastive Adapter Training (CAT)。CAT 通过应用 CAT loss 来增强训练过程，确保保留基模型的原始知识，同时引入 Knowledge Preservation Score (KPS) 作为评估指标，以定性和定量方式证明其改进效果。最后，该方法探讨了在多概念适配器和优化方面的潜力，为提升图像生成多样性和稳定性提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPRW 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07554v2",
      "published_date": "2024-04-11 08:36:13 UTC",
      "updated_date": "2024-10-23 07:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:42:39.889627"
    },
    {
      "arxiv_id": "2404.07544v3",
      "title": "From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Vacareanu",
        "Vlad-Andrei Negru",
        "Vasile Suciu",
        "Mihai Surdeanu"
      ],
      "abstract": "We analyze how well pre-trained large language models (e.g., Llama2, GPT-4,\nClaude 3, etc) can do linear and non-linear regression when given in-context\nexamples, without any additional training or gradient updates. Our findings\nreveal that several large language models (e.g., GPT-4, Claude 3) are able to\nperform regression tasks with a performance rivaling (or even outperforming)\nthat of traditional supervised methods such as Random Forest, Bagging, or\nGradient Boosting. For example, on the challenging Friedman #2 regression\ndataset, Claude 3 outperforms many supervised methods such as AdaBoost, SVM,\nRandom Forest, KNN, or Gradient Boosting. We then investigate how well the\nperformance of large language models scales with the number of in-context\nexemplars. We borrow from the notion of regret from online learning and\nempirically show that LLMs are capable of obtaining a sub-linear regret.",
      "tldr_zh": "本研究分析了预训练的大型语言模型（Large Language Models，如Llama2、GPT-4和Claude 3）在给定in-context examples的情况下，进行线性或非线性regression的能力，而无需额外训练或梯度更新。结果显示，这些模型在regression任务上的表现可与传统监督方法（如Random Forest、Bagging或Gradient Boosting）媲美，甚至优于它们，例如Claude 3在Friedman #2数据集上超过了AdaBoost、SVM、Random Forest、KNN和Gradient Boosting。进一步调查发现，LLMs的性能随in-context exemplars数量的增加而提升，并实现了sub-linear regret，证明了其在线学习潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "55 pages, 48 figures COLM camera-ready version; Changes include: (i)\n  added real-world datasets (Appendix I), (ii) fixed typos",
      "pdf_url": "http://arxiv.org/pdf/2404.07544v3",
      "published_date": "2024-04-11 08:12:43 UTC",
      "updated_date": "2024-09-10 20:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:42:53.475301"
    },
    {
      "arxiv_id": "2404.07533v3",
      "title": "Exploring the Decentraland Economy: Multifaceted Parcel Attributes, Key Insights, and Benchmarking",
      "title_zh": "翻译失败",
      "authors": [
        "Dipika Jha",
        "Ankit K. Bhagat",
        "Raju Halder",
        "Rajendra N. Paramanik",
        "Chandra M. Kumar"
      ],
      "abstract": "This paper presents a comprehensive Decentraland parcels dataset, called\nIITP-VDLand, sourced from diverse platforms such as Decentraland, OpenSea,\nEtherscan, Google BigQuery, and various Social Media Platforms. Unlike existing\ndatasets which have limited attributes and records, IITP-VDLand offers a rich\narray of attributes, encompassing parcel characteristics, trading history, past\nactivities, transactions, and social media interactions. Alongside, we\nintroduce a key attribute in the dataset, namely Rarity score, which measures\nthe uniqueness of each parcel within the virtual world. Addressing the\nsignificant challenge posed by the dispersed nature of this data across various\nsources, we employ a systematic approach, utilizing both available APIs and\ncustom scripts, to gather it. Subsequently, we meticulously curate and organize\nthe information into four distinct fragments: (1) Characteristics, (2) OpenSea\nTrading History, (3) Ethereum Activity Transactions, and (4) Social Media. We\nenvisage that this dataset would serve as a robust resource for training\nmachine- and deep-learning models specifically designed to address real-world\nchallenges within the domain of Decentraland parcels. The performance\nbenchmarking of more than 20 state-of-the-art price prediction models on our\ndataset yields promising results, achieving a maximum R2 score of 0.8251 and an\naccuracy of 74.23% in case of Extra Trees Regressor and Classifier. The key\nfindings reveal that the ensemble models perform better than both deep learning\nand linear models for our dataset. We observe a significant impact of\ncoordinates, geographical proximity, rarity score, and few other economic\nindicators on the prediction of parcel prices.",
      "tldr_zh": "这篇论文介绍了 IITP-VDLand 数据集，一个全面的 Decentraland 地块数据集，从 Decentraland、OpenSea 等平台收集数据，包括地块特征、交易历史、活动交易和社会媒体互动，并引入 Rarity score 来衡量地块的独特性。数据通过 APIs 和自定义脚本系统收集，并组织成四个部分，以支持机器学习模型的训练。研究对20多个价格预测模型进行benchmarking，结果显示 Extra Trees Regressor 模型取得了最高的 R2 score 为0.8251 和准确率74.23%。关键发现是集成模型（如 Extra Trees）优于深度学习和线性模型，且坐标、地理位置、Rarity score 等经济指标对地块价格预测有显著影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07533v3",
      "published_date": "2024-04-11 07:54:14 UTC",
      "updated_date": "2025-03-02 07:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:43:07.664055"
    },
    {
      "arxiv_id": "2404.07532v1",
      "title": "Bayesian Federated Model Compression for Communication and Computation Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyu Xia",
        "Danny H. K. Tsang",
        "Vincent K. N. Lau"
      ],
      "abstract": "In this paper, we investigate Bayesian model compression in federated\nlearning (FL) to construct sparse models that can achieve both communication\nand computation efficiencies. We propose a decentralized Turbo variational\nBayesian inference (D-Turbo-VBI) FL framework where we firstly propose a\nhierarchical sparse prior to promote a clustered sparse structure in the weight\nmatrix. Then, by carefully integrating message passing and VBI with a\ndecentralized turbo framework, we propose the D-Turbo-VBI algorithm which can\n(i) reduce both upstream and downstream communication overhead during federated\ntraining, and (ii) reduce the computational complexity during local inference.\nAdditionally, we establish the convergence property for thr proposed\nD-Turbo-VBI algorithm. Simulation results show the significant gain of our\nproposed algorithm over the baselines in reducing communication overhead during\nfederated training and computational complexity of final model.",
      "tldr_zh": "本研究探讨了Bayesian model compression在federated learning (FL)中的应用，以实现通信和计算效率。作者提出了一种decentralized Turbo variational Bayesian inference (D-Turbo-VBI)框架，利用hierarchical sparse prior来促进weight matrix的clustered sparse structure，并通过整合message passing和VBI与decentralized turbo framework，开发出D-Turbo-VBI算法。该算法能够减少federated training中的upstream和downstream communication overhead，并降低local inference的computational complexity；此外，研究还证明了该算法的convergence property。模拟结果显示，与基线方法相比，D-Turbo-VBI在减少通信开销和计算复杂度方面取得了显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07532v1",
      "published_date": "2024-04-11 07:51:30 UTC",
      "updated_date": "2024-04-11 07:51:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:43:18.268331"
    },
    {
      "arxiv_id": "2404.08705v1",
      "title": "Introducing L2M3, A Multilingual Medical Large Language Model to Advance Health Equity in Low-Resource Regions",
      "title_zh": "翻译失败",
      "authors": [
        "Agasthya Gangavarapu"
      ],
      "abstract": "Addressing the imminent shortfall of 10 million health workers by 2030,\npredominantly in Low- and Middle-Income Countries (LMICs), this paper\nintroduces an innovative approach that harnesses the power of Large Language\nModels (LLMs) integrated with machine translation models. This solution is\nengineered to meet the unique needs of Community Health Workers (CHWs),\novercoming language barriers, cultural sensitivities, and the limited\navailability of medical dialog datasets. I have crafted a model that not only\nboasts superior translation capabilities but also undergoes rigorous\nfine-tuning on open-source datasets to ensure medical accuracy and is equipped\nwith comprehensive safety features to counteract the risks of misinformation.\n  Featuring a modular design, this approach is specifically structured for\nswift adaptation across various linguistic and cultural contexts, utilizing\nopen-source components to significantly reduce healthcare operational costs.\nThis strategic innovation markedly improves the accessibility and quality of\nhealthcare services by providing CHWs with contextually appropriate medical\nknowledge and diagnostic tools. This paper highlights the transformative impact\nof this context-aware LLM, underscoring its crucial role in addressing the\nglobal healthcare workforce deficit and propelling forward healthcare outcomes\nin LMICs.",
      "tldr_zh": "本论文引入了 L2M3，一种多语言医疗大型语言模型 (LLMs)，旨在通过整合机器翻译模型来解决低收入和中等收入国家 (LMICs) 到 2030 年可能短缺的 1000 万医疗工作者的挑战。L2M3 针对社区卫生工作者 (CHWs) 的需求进行优化，克服语言障碍、文化敏感性和医疗对话数据集的稀缺问题，并通过在开源数据集上微调确保医疗准确性，同时配备安全功能防止误信息。模型采用模块化设计，便于快速适应不同语言和文化环境，显著降低医疗运营成本，并提升医疗服务的可及性与质量，从而推动 LMICs 的健康公平性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08705v1",
      "published_date": "2024-04-11 07:39:22 UTC",
      "updated_date": "2024-04-11 07:39:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:43:29.955994"
    },
    {
      "arxiv_id": "2404.07523v1",
      "title": "GNN-based Probabilistic Supply and Inventory Predictions in Supply Chain Networks",
      "title_zh": "基于 GNN 的供应链网络概率供应和库存预测",
      "authors": [
        "Hyung-il Ahn",
        "Young Chol Song",
        "Santiago Olivar",
        "Hershel Mehta",
        "Naveen Tewari"
      ],
      "abstract": "Successful supply chain optimization must mitigate imbalances between supply\nand demand over time. While accurate demand prediction is essential for supply\nplanning, it alone does not suffice. The key to successful supply planning for\noptimal and viable execution lies in maximizing predictability for both demand\nand supply throughout an execution horizon. Therefore, enhancing the accuracy\nof supply predictions is imperative to create an attainable supply plan that\nmatches demand without overstocking or understocking. However, in complex\nsupply chain networks with numerous nodes and edges, accurate supply\npredictions are challenging due to dynamic node interactions, cascading supply\ndelays, resource availability, production and logistic capabilities.\nConsequently, supply executions often deviate from their initial plans. To\naddress this, we present the Graph-based Supply Prediction (GSP) probabilistic\nmodel. Our attention-based graph neural network (GNN) model predicts supplies,\ninventory, and imbalances using graph-structured historical data, demand\nforecasting, and original supply plan inputs. The experiments, conducted using\nhistorical data from a global consumer goods company's large-scale supply\nchain, demonstrate that GSP significantly improves supply and inventory\nprediction accuracy, potentially offering supply plan corrections to optimize\nexecutions.",
      "tldr_zh": "该论文针对供应链网络中供应和库存预测的挑战，提出了一种基于 Graph Neural Network (GNN) 的概率模型 Graph-based Supply Prediction (GSP)。该模型利用注意机制处理图结构的历史数据、需求预测和原始供应计划，准确预测供应、库存水平以及供需不平衡。实验在全球消费品公司的大型供应链数据上验证，GSP 显著提高了预测准确性，并为优化供应计划提供潜在修正建议。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07523v1",
      "published_date": "2024-04-11 07:36:00 UTC",
      "updated_date": "2024-04-11 07:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:43:42.010690"
    },
    {
      "arxiv_id": "2404.07519v1",
      "title": "LATTE: Low-Precision Approximate Attention with Head-wise Trainable Threshold for Efficient Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Jiing-Ping Wang",
        "Ming-Guang Lin",
        "An-Yeu",
        "Wu"
      ],
      "abstract": "With the rise of Transformer models in NLP and CV domain, Multi-Head\nAttention has been proven to be a game-changer. However, its expensive\ncomputation poses challenges to the model throughput and efficiency, especially\nfor the long sequence tasks. Exploiting the sparsity in attention has been\nproven to be an effective way to reduce computation. Nevertheless, prior works\ndo not consider the various distributions among different heads and lack a\nsystematic method to determine the threshold. To address these challenges, we\npropose Low-Precision Approximate Attention with Head-wise Trainable Threshold\nfor Efficient Transformer (LATTE). LATTE employs a headwise threshold-based\nfilter with the low-precision dot product and computation reuse mechanism to\nreduce the computation of MHA. Moreover, the trainable threshold is introduced\nto provide a systematic method for adjusting the thresholds and enable\nend-to-end optimization. Experimental results indicate LATTE can smoothly adapt\nto both NLP and CV tasks, offering significant computation savings with only a\nminor compromise in performance. Also, the trainable threshold is shown to be\nessential for the leverage between the performance and the computation. As a\nresult, LATTE filters up to 85.16% keys with only a 0.87% accuracy drop in the\nCV task and 89.91% keys with a 0.86 perplexity increase in the NLP task.",
      "tldr_zh": "本论文提出 LATTE，一种高效 Transformer 框架，通过 head-wise 可训练阈值、低精度点积和计算重用机制来优化 Multi-Head Attention (MHA) 的计算，针对长序列任务减少计算开销。LATTE 引入可训练阈值，实现端到端优化，并系统处理不同 heads 的分布差异。实验结果显示，在 CV 任务中过滤高达 85.16% 的 keys 只以 0.87% 准确率损失为代价，在 NLP 任务中过滤 89.91% 的 keys 只增加 0.86 perplexity，从而在计算节省和性能之间实现有效平衡。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07519v1",
      "published_date": "2024-04-11 07:23:19 UTC",
      "updated_date": "2024-04-11 07:23:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:43:54.210924"
    },
    {
      "arxiv_id": "2404.08704v1",
      "title": "MM-PhyQA: Multimodal Physics Question-Answering With Multi-Image CoT Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Avinash Anand",
        "Janak Kapuriya",
        "Apoorv Singh",
        "Jay Saraf",
        "Naman Lal",
        "Astha Verma",
        "Rushali Gupta",
        "Rajiv Shah"
      ],
      "abstract": "While Large Language Models (LLMs) can achieve human-level performance in\nvarious tasks, they continue to face challenges when it comes to effectively\ntackling multi-step physics reasoning tasks. To identify the shortcomings of\nexisting models and facilitate further research in this area, we curated a\nnovel dataset, MM-PhyQA, which comprises well-constructed, high schoollevel\nmultimodal physics problems. By evaluating the performance of contemporary LLMs\nthat are publicly available, both with and without the incorporation of\nmultimodal elements in these problems, we aim to shed light on their\ncapabilities. For generating answers for questions consisting of multimodal\ninput (in this case, images and text) we employed Zero-shot prediction using\nGPT-4 and utilized LLaVA (LLaVA and LLaVA-1.5), the latter of which were\nfine-tuned on our dataset. For evaluating the performance of LLMs consisting\nsolely of textual input, we tested the performance of the base and fine-tuned\nversions of the Mistral-7B and LLaMA2-7b models. We also showcased the\nperformance of the novel Multi-Image Chain-of-Thought (MI-CoT) Prompting\ntechnique, which when used to train LLaVA-1.5 13b yielded the best results when\ntested on our dataset, with superior scores in most metrics and the highest\naccuracy of 71.65% on the test set.",
      "tldr_zh": "本文构建了 MM-PhyQA 数据集，该数据集包含高中水平的 multimodal 物理问题，用于评估 LLMs 在多步物理推理任务中的不足和表现。研究团队测试了各种模型，包括 Zero-shot GPT-4 和 fine-tuned LLaVA，以及 Mistral-7B 和 LLaMA2-7b 的文本输入版本。引入了创新的 Multi-Image Chain-of-Thought (MI-CoT) Prompting 技术，在 LLaVA-1.5 13b 上训练后，该方法在测试集上实现了 71.65% 的最高准确率，并在大多数指标上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08704v1",
      "published_date": "2024-04-11 07:11:47 UTC",
      "updated_date": "2024-04-11 07:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:44:06.759953"
    },
    {
      "arxiv_id": "2404.07511v1",
      "title": "Generative Probabilistic Planning for Optimizing Supply Chain Networks",
      "title_zh": "用于优化供应链网络的生成式概率规划",
      "authors": [
        "Hyung-il Ahn",
        "Santiago Olivar",
        "Hershel Mehta",
        "Young Chol Song"
      ],
      "abstract": "Supply chain networks in enterprises are typically composed of complex\ntopological graphs involving various types of nodes and edges, accommodating\nnumerous products with considerable demand and supply variability. However, as\nsupply chain networks expand in size and complexity, traditional supply chain\nplanning methods (e.g., those found in heuristic rule-based and operations\nresearch-based systems) tend to become locally optimal or lack computational\nscalability, resulting in substantial imbalances between supply and demand\nacross nodes in the network. This paper introduces a novel Generative AI\ntechnique, which we call Generative Probabilistic Planning (GPP). GPP generates\ndynamic supply action plans that are globally optimized across all network\nnodes over the time horizon for changing objectives like maximizing profits or\nservice levels, factoring in time-varying probabilistic demand, lead time, and\nproduction conditions. GPP leverages attention-based graph neural networks\n(GNN), offline deep reinforcement learning (Offline RL), and policy simulations\nto train generative policy models and create optimal plans through\nprobabilistic simulations, effectively accounting for various uncertainties.\nOur experiments using historical data from a global consumer goods company with\ncomplex supply chain networks demonstrate that GPP accomplishes\nobjective-adaptable, probabilistically resilient, and dynamic planning for\nsupply chain networks, leading to significant improvements in performance and\nprofitability for enterprises. Our work plays a pivotal role in shaping the\ntrajectory of AI adoption within the supply chain domain.",
      "tldr_zh": "这篇论文针对复杂供应链网络的优化问题，引入了 Generative Probabilistic Planning (GPP) 技术，以生成动态的全球优化行动计划，考虑时间变化的概率需求、提前期和生产条件，从而解决传统方法（如启发式规则或运筹学）的局部最优和计算可扩展性问题。GPP 结合 attention-based Graph Neural Networks (GNN)、Offline Deep Reinforcement Learning (Offline RL) 和策略模拟，训练生成策略模型并通过概率模拟创建最优计划。实验基于全球消费品公司的历史数据，证明 GPP 实现了目标适应性、概率弹性动态规划，并显著提升了企业的性能和盈利能力，推动 AI 在供应链领域的应用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07511v1",
      "published_date": "2024-04-11 07:06:58 UTC",
      "updated_date": "2024-04-11 07:06:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:44:19.877381"
    },
    {
      "arxiv_id": "2404.07504v1",
      "title": "Mitigating Object Dependencies: Improving Point Cloud Self-Supervised Learning through Object Exchange",
      "title_zh": "缓解对象依赖性：通过对象交换改进点云自监督学习",
      "authors": [
        "Yanhao Wu",
        "Tong Zhang",
        "Wei Ke",
        "Congpei Qiu",
        "Sabine Susstrunk",
        "Mathieu Salzmann"
      ],
      "abstract": "In the realm of point cloud scene understanding, particularly in indoor\nscenes, objects are arranged following human habits, resulting in objects of\ncertain semantics being closely positioned and displaying notable inter-object\ncorrelations. This can create a tendency for neural networks to exploit these\nstrong dependencies, bypassing the individual object patterns. To address this\nchallenge, we introduce a novel self-supervised learning (SSL) strategy. Our\napproach leverages both object patterns and contextual cues to produce robust\nfeatures. It begins with the formulation of an object-exchanging strategy,\nwhere pairs of objects with comparable sizes are exchanged across different\nscenes, effectively disentangling the strong contextual dependencies.\nSubsequently, we introduce a context-aware feature learning strategy, which\nencodes object patterns without relying on their specific context by\naggregating object features across various scenes. Our extensive experiments\ndemonstrate the superiority of our method over existing SSL techniques, further\nshowing its better robustness to environmental changes. Moreover, we showcase\nthe applicability of our approach by transferring pre-trained models to diverse\npoint cloud datasets.",
      "tldr_zh": "本论文针对点云场景理解中的对象依赖问题，提出一种新型自-supervised learning (SSL) 策略，以缓解室内场景中对象间强相关性导致的模型偏见。该策略包括对象-exchanging strategy，将大小相似的对象在不同场景中交换，从而打破上下文依赖；以及context-aware feature learning strategy，通过聚合跨场景对象特征来编码独立对象模式。实验结果显示，该方法在点云任务上优于现有SSL技术，具有更强的环境变化鲁棒性，并成功迁移到多种点云数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07504v1",
      "published_date": "2024-04-11 06:39:53 UTC",
      "updated_date": "2024-04-11 06:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:44:30.587863"
    },
    {
      "arxiv_id": "2404.07502v1",
      "title": "Generating Counterfactual Explanations Using Cardinality Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Rubén Ruiz-Torrubiano"
      ],
      "abstract": "Providing explanations about how machine learning algorithms work and/or make\nparticular predictions is one of the main tools that can be used to improve\ntheir trusworthiness, fairness and robustness. Among the most intuitive type of\nexplanations are counterfactuals, which are examples that differ from a given\npoint only in the prediction target and some set of features, presenting which\nfeatures need to be changed in the original example to flip the prediction for\nthat example. However, such counterfactuals can have many different features\nthan the original example, making their interpretation difficult. In this\npaper, we propose to explicitly add a cardinality constraint to counterfactual\ngeneration limiting how many features can be different from the original\nexample, thus providing more interpretable and easily understantable\ncounterfactuals.",
      "tldr_zh": "这篇论文探讨了使用反事实解释（counterfactual explanations）来提升机器学习算法的可信度、公平性和鲁棒性，这些解释通过修改原例子的部分特征来翻转预测结果。传统反事实解释往往涉及过多特征差异，导致解释复杂且不易理解。为解决这一问题，作者提出在生成过程中添加基数约束（cardinality constraints），以限制与原例子不同的特征数量，从而产生更简洁且易于解读的反事实解释。这种方法有助于改进算法的透明度和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07502v1",
      "published_date": "2024-04-11 06:33:19 UTC",
      "updated_date": "2024-04-11 06:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:44:43.037989"
    },
    {
      "arxiv_id": "2404.07498v1",
      "title": "Interactive Prompt Debugging with Sequence Salience",
      "title_zh": "翻译失败",
      "authors": [
        "Ian Tenney",
        "Ryan Mullins",
        "Bin Du",
        "Shree Pandya",
        "Minsuk Kahng",
        "Lucas Dixon"
      ],
      "abstract": "We present Sequence Salience, a visual tool for interactive prompt debugging\nwith input salience methods. Sequence Salience builds on widely used salience\nmethods for text classification and single-token prediction, and extends this\nto a system tailored for debugging complex LLM prompts. Our system is\nwell-suited for long texts, and expands on previous work by 1) providing\ncontrollable aggregation of token-level salience to the word, sentence, or\nparagraph level, making salience over long inputs tractable; and 2) supporting\nrapid iteration where practitioners can act on salience results, refine\nprompts, and run salience on the new output. We include case studies showing\nhow Sequence Salience can help practitioners work with several complex\nprompting strategies, including few-shot, chain-of-thought, and constitutional\nprinciples. Sequence Salience is built on the Learning Interpretability Tool,\nan open-source platform for ML model visualizations, and code, notebooks, and\ntutorials are available at http://goo.gle/sequence-salience.",
      "tldr_zh": "本研究引入了 Sequence Salience，一种视觉工具，用于交互式提示调试，基于输入显著性方法扩展到复杂 LLM 提示的分析。工具支持对长文本进行可控聚合，从 token 级别到 word、sentence 或 paragraph 级别，使显著性分析更易处理，并允许用户基于结果快速迭代提示以优化输出。研究通过案例研究展示了其在 few-shot、chain-of-thought 和 constitutional principles 等策略中的实际应用，有助于提升提示调试效率。Sequence Salience 基于开源平台 Learning Interpretability Tool 构建，并提供代码、笔记本和教程以供使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07498v1",
      "published_date": "2024-04-11 06:22:56 UTC",
      "updated_date": "2024-04-11 06:22:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:44:53.719771"
    },
    {
      "arxiv_id": "2404.08021v1",
      "title": "VeTraSS: Vehicle Trajectory Similarity Search Through Graph Modeling and Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Cheng",
        "Bowen Zhang",
        "Ziyu Wang",
        "Ziyi Zhou",
        "Weiqi Feng",
        "Yi Lyu",
        "Xingjian Diao"
      ],
      "abstract": "Trajectory similarity search plays an essential role in autonomous driving,\nas it enables vehicles to analyze the information and characteristics of\ndifferent trajectories to make informed decisions and navigate safely in\ndynamic environments. Existing work on the trajectory similarity search task\nprimarily utilizes sequence-processing algorithms or Recurrent Neural Networks\n(RNNs), which suffer from the inevitable issues of complicated architecture and\nheavy training costs. Considering the intricate connections between\ntrajectories, using Graph Neural Networks (GNNs) for data modeling is feasible.\nHowever, most methods directly use existing mathematical graph structures as\nthe input instead of constructing specific graphs from certain vehicle\ntrajectory data. This ignores such data's unique and dynamic characteristics.\nTo bridge such a research gap, we propose VeTraSS -- an end-to-end pipeline for\nVehicle Trajectory Similarity Search. Specifically, VeTraSS models the original\ntrajectory data into multi-scale graphs, and generates comprehensive embeddings\nthrough a novel multi-layer attention-based GNN. The learned embeddings can be\nused for searching similar vehicle trajectories. Extensive experiments on the\nPorto and Geolife datasets demonstrate the effectiveness of VeTraSS, where our\nmodel outperforms existing work and reaches the state-of-the-art. This\ndemonstrates the potential of VeTraSS for trajectory analysis and safe\nnavigation in self-driving vehicles in the real world.",
      "tldr_zh": "该研究针对自动驾驶中的轨迹相似性搜索问题，指出现有方法如序列处理算法和 RNNs 存在架构复杂和训练成本高的缺点，提出了一种端到端框架 VeTraSS。VeTraSS 通过将车辆轨迹数据建模为多尺度图，并利用多层注意力-based Graph Neural Networks (GNNs) 生成全面嵌入，从而实现高效的相似轨迹搜索。在 Porto 和 Geolife 数据集上的实验显示，VeTraSS 优于现有方法，达到 state-of-the-art 水平，为自动驾驶的轨迹分析和安全导航提供了潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08021v1",
      "published_date": "2024-04-11 06:19:55 UTC",
      "updated_date": "2024-04-11 06:19:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:45:06.443852"
    },
    {
      "arxiv_id": "2404.07493v1",
      "title": "Characterizing the Influence of Topology on Graph Learning Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Kailong Wu",
        "Yule Xie",
        "Jiaxin Ding",
        "Yuxiang Ren",
        "Luoyi Fu",
        "Xinbing Wang",
        "Chenghu Zhou"
      ],
      "abstract": "Graph neural networks (GNN) have achieved remarkable success in a wide range\nof tasks by encoding features combined with topology to create effective\nrepresentations. However, the fundamental problem of understanding and\nanalyzing how graph topology influences the performance of learning models on\ndownstream tasks has not yet been well understood. In this paper, we propose a\nmetric, TopoInf, which characterizes the influence of graph topology by\nmeasuring the level of compatibility between the topological information of\ngraph data and downstream task objectives. We provide analysis based on the\ndecoupled GNNs on the contextual stochastic block model to demonstrate the\neffectiveness of the metric. Through extensive experiments, we demonstrate that\nTopoInf is an effective metric for measuring topological influence on\ncorresponding tasks and can be further leveraged to enhance graph learning.",
      "tldr_zh": "本论文探讨了图拓扑对图学习任务的影响，提出了一种名为 TopoInf 的指标，用于衡量图拓扑信息与下游任务目标的兼容性，从而表征拓扑对图神经网络 (GNNs) 性能的影响。研究通过在 contextual stochastic block model 上分析解耦的 GNNs，证明了 TopoInf 的有效性。实验结果显示，该指标不仅能准确评估拓扑影响，还可进一步用于提升图学习任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07493v1",
      "published_date": "2024-04-11 06:04:06 UTC",
      "updated_date": "2024-04-11 06:04:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:45:18.828856"
    },
    {
      "arxiv_id": "2404.08020v1",
      "title": "Augmenting Knowledge Graph Hierarchies Using Neural Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Sanat Sharma",
        "Mayank Poddar",
        "Jayant Kumar",
        "Kosta Blank",
        "Tracy King"
      ],
      "abstract": "Knowledge graphs are useful tools to organize, recommend and sort data.\nHierarchies in knowledge graphs provide significant benefit in improving\nunderstanding and compartmentalization of the data within a knowledge graph.\nThis work leverages large language models to generate and augment hierarchies\nin an existing knowledge graph. For small (<100,000 node) domain-specific KGs,\nwe find that a combination of few-shot prompting with one-shot generation works\nwell, while larger KG may require cyclical generation. We present techniques\nfor augmenting hierarchies, which led to coverage increase by 98% for intents\nand 99% for colors in our knowledge graph.",
      "tldr_zh": "该论文探讨了使用 Neural Transformers 和大型语言模型（Large Language Models）来增强知识图谱（Knowledge Graphs）中的层次结构，以改善数据组织和理解。对于小型知识图谱（少于10万节点），研究采用 Few-shot Prompting 与 One-shot Generation 的组合方法，而大型知识图谱则可能需要 Cyclical Generation。通过这些技术，论文实现了意图（Intents）的覆盖率增加98%和颜色（Colors）的覆盖率增加99%。这项工作为知识图谱的自动扩展提供了实用策略。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "European Conference on Information Retrieval 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08020v1",
      "published_date": "2024-04-11 05:53:38 UTC",
      "updated_date": "2024-04-11 05:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:45:30.656854"
    },
    {
      "arxiv_id": "2404.07484v1",
      "title": "Multimodal Emotion Recognition by Fusing Video Semantic in MOOC Learning Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Zhang",
        "Xiaomei Tao",
        "Hanxu Ai",
        "Tao Chen",
        "Yanling Gan"
      ],
      "abstract": "In the Massive Open Online Courses (MOOC) learning scenario, the semantic\ninformation of instructional videos has a crucial impact on learners' emotional\nstate. Learners mainly acquire knowledge by watching instructional videos, and\nthe semantic information in the videos directly affects learners' emotional\nstates. However, few studies have paid attention to the potential influence of\nthe semantic information of instructional videos on learners' emotional states.\nTo deeply explore the impact of video semantic information on learners'\nemotions, this paper innovatively proposes a multimodal emotion recognition\nmethod by fusing video semantic information and physiological signals. We\ngenerate video descriptions through a pre-trained large language model (LLM) to\nobtain high-level semantic information about instructional videos. Using the\ncross-attention mechanism for modal interaction, the semantic information is\nfused with the eye movement and PhotoPlethysmoGraphy (PPG) signals to obtain\nthe features containing the critical information of the three modes. The\naccurate recognition of learners' emotional states is realized through the\nemotion classifier. The experimental results show that our method has\nsignificantly improved emotion recognition performance, providing a new\nperspective and efficient method for emotion recognition research in MOOC\nlearning scenarios. The method proposed in this paper not only contributes to a\ndeeper understanding of the impact of instructional videos on learners'\nemotional states but also provides a beneficial reference for future research\non emotion recognition in MOOC learning scenarios.",
      "tldr_zh": "本文提出了一种多模态情绪识别方法，针对 MOOC 学习场景中教学视频语义信息对学习者情绪的影响，通过融合视频语义和生理信号（如眼动和 PPG）来提升识别准确性。具体而言，该方法使用预训练的 LLM 生成视频描述，并通过 cross-attention mechanism 进行模态交互融合，然后应用情绪分类器实现精确的情绪状态识别。实验结果表明，该方法显著提高了情绪识别性能，为 MOOC 学习中的情绪研究提供了新视角和高效参考。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07484v1",
      "published_date": "2024-04-11 05:44:27 UTC",
      "updated_date": "2024-04-11 05:44:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:45:42.994782"
    },
    {
      "arxiv_id": "2404.07475v2",
      "title": "Laissez-Faire Harms: Algorithmic Biases in Generative Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Evan Shieh",
        "Faye-Marie Vassel",
        "Cassidy Sugimoto",
        "Thema Monroe-White"
      ],
      "abstract": "The rapid deployment of generative language models (LMs) has raised concerns\nabout social biases affecting the well-being of diverse consumers. The extant\nliterature on generative LMs has primarily examined bias via explicit identity\nprompting. However, prior research on bias in earlier language-based technology\nplatforms, including search engines, has shown that discrimination can occur\neven when identity terms are not specified explicitly. Studies of bias in LM\nresponses to open-ended prompts (where identity classifications are left\nunspecified) are lacking and have not yet been grounded in end-consumer harms.\nHere, we advance studies of generative LM bias by considering a broader set of\nnatural use cases via open-ended prompting. In this \"laissez-faire\" setting, we\nfind that synthetically generated texts from five of the most pervasive LMs\n(ChatGPT3.5, ChatGPT4, Claude2.0, Llama2, and PaLM2) perpetuate harms of\nomission, subordination, and stereotyping for minoritized individuals with\nintersectional race, gender, and/or sexual orientation identities (AI/AN,\nAsian, Black, Latine, MENA, NH/PI, Female, Non-binary, Queer). We find\nwidespread evidence of bias to an extent that such individuals are hundreds to\nthousands of times more likely to encounter LM-generated outputs that portray\ntheir identities in a subordinated manner compared to representative or\nempowering portrayals. We also document a prevalence of stereotypes (e.g.\nperpetual foreigner) in LM-generated outputs that are known to trigger\npsychological harms that disproportionately affect minoritized individuals.\nThese include stereotype threat, which leads to impaired cognitive performance\nand increased negative self-perception. Our findings highlight the urgent need\nto protect consumers from discriminatory harms caused by language models and\ninvest in critical AI education programs tailored towards empowering diverse\nconsumers.",
      "tldr_zh": "这篇论文探讨了生成式语言模型（generative language models）中的算法偏见（algorithmic biases），特别关注在“laissez-faire”开放式提示（无明确身份指定）下的表现。研究者分析了五个主流模型（ChatGPT3.5、ChatGPT4、Claude2.0、Llama2 和 PaLM2）的输出，发现这些模型会 perpetuate harms of omission、subordination 和 stereotyping，尤其针对具有交叉身份（intersectional identities，如种族、性别和性取向）的少数群体，使他们数百到数千倍更可能遇到负面或从属化描绘。论文强调这些偏见可能引发 psychological harms，如 stereotype threat，导致认知损害和负面自我认知，并呼吁紧急采取措施保护消费者并投资针对多样群体的关键 AI 教育计划。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages (43 if including supplementals), 8 figures (23 if including\n  supplementals)",
      "pdf_url": "http://arxiv.org/pdf/2404.07475v2",
      "published_date": "2024-04-11 05:09:03 UTC",
      "updated_date": "2024-04-16 04:07:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:45:56.001133"
    },
    {
      "arxiv_id": "2404.07471v1",
      "title": "Structure-aware Fine-tuning for Code Pre-trained Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Wu",
        "Renyu Zhu",
        "Nuo Chen",
        "Qiushi Sun",
        "Xiang Li",
        "Ming Gao"
      ],
      "abstract": "Over the past few years, we have witnessed remarkable advancements in Code\nPre-trained Models (CodePTMs). These models achieved excellent representation\ncapabilities by designing structure-based pre-training tasks for code. However,\nhow to enhance the absorption of structural knowledge when fine-tuning CodePTMs\nstill remains a significant challenge. To fill this gap, in this paper, we\npresent Structure-aware Fine-tuning (SAT), a novel structure-enhanced and\nplug-and-play fine-tuning method for CodePTMs. We first propose a structure\nloss to quantify the difference between the information learned by CodePTMs and\nthe knowledge extracted from code structure. Specifically, we use the attention\nscores extracted from Transformer layer as the learned structural information,\nand the shortest path length between leaves in abstract syntax trees as the\nstructural knowledge. Subsequently, multi-task learning is introduced to\nimprove the performance of fine-tuning. Experiments conducted on four\npre-trained models and two generation tasks demonstrate the effectiveness of\nour proposed method as a plug-and-play solution. Furthermore, we observed that\nSAT can benefit CodePTMs more with limited training data.",
      "tldr_zh": "这篇论文针对Code Pre-trained Models (CodePTMs)的微调过程，提出了一种新型的Structure-aware Fine-tuning (SAT)方法，以增强模型对代码结构知识的吸收。SAT通过引入structure loss来量化Transformer层注意力分数（学到的结构信息）与抽象语法树（AST）中叶子节点的最短路径长度（结构知识）之间的差异，并结合多任务学习来优化微调性能。实验结果显示，在四个预训练模型和两个代码生成任务上，SAT作为即插即用解决方案显著提升了模型表现，尤其在训练数据有限的情况下更具优势。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.07471v1",
      "published_date": "2024-04-11 04:24:48 UTC",
      "updated_date": "2024-04-11 04:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:46:07.375064"
    },
    {
      "arxiv_id": "2404.07461v2",
      "title": "An Audit on the Perspectives and Challenges of Hallucinations in NLP",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Narayanan Venkit",
        "Tatiana Chakravorti",
        "Vipul Gupta",
        "Heidi Biggs",
        "Mukund Srinath",
        "Koustava Goswami",
        "Sarah Rajtmajer",
        "Shomir Wilson"
      ],
      "abstract": "We audit how hallucination in large language models (LLMs) is characterized\nin peer-reviewed literature, using a critical examination of 103 publications\nacross NLP research. Through the examination of the literature, we identify a\nlack of agreement with the term `hallucination' in the field of NLP.\nAdditionally, to compliment our audit, we conduct a survey with 171\npractitioners from the field of NLP and AI to capture varying perspectives on\nhallucination. Our analysis calls for the necessity of explicit definitions and\nframeworks outlining hallucination within NLP, highlighting potential\nchallenges, and our survey inputs provide a thematic understanding of the\ninfluence and ramifications of hallucination in society.",
      "tldr_zh": "这篇论文审计了 NLP 领域中大型语言模型 (LLMs) 的幻觉 (hallucination) 在 103 篇同行评审文献中的表征，发现该术语缺乏一致定义和共识。研究者通过审查文献并进行一项针对 171 名 NLP 和 AI 从业者的调查，捕捉了从业者对幻觉的多样观点和潜在挑战。最终，分析呼吁制定明确的定义和框架，以更好地理解幻觉在社会中的影响和后果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07461v2",
      "published_date": "2024-04-11 03:51:29 UTC",
      "updated_date": "2024-09-14 03:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:46:19.088757"
    },
    {
      "arxiv_id": "2404.07456v1",
      "title": "WESE: Weak Exploration to Strong Exploitation for LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Huang",
        "Weiwen Liu",
        "Xiaolong Chen",
        "Xingmei Wang",
        "Defu Lian",
        "Yasheng Wang",
        "Ruiming Tang",
        "Enhong Chen"
      ],
      "abstract": "Recently, large language models (LLMs) have demonstrated remarkable potential\nas an intelligent agent. However, existing researches mainly focus on enhancing\nthe agent's reasoning or decision-making abilities through well-designed prompt\nengineering or task-specific fine-tuning, ignoring the procedure of exploration\nand exploitation. When addressing complex tasks within open-world interactive\nenvironments, these methods exhibit limitations. Firstly, the lack of global\ninformation of environments leads to greedy decisions, resulting in sub-optimal\nsolutions. On the other hand, irrelevant information acquired from the\nenvironment not only adversely introduces noise, but also incurs additional\ncost. This paper proposes a novel approach, Weak Exploration to Strong\nExploitation (WESE), to enhance LLM agents in solving open-world interactive\ntasks. Concretely, WESE involves decoupling the exploration and exploitation\nprocess, employing a cost-effective weak agent to perform exploration tasks for\nglobal knowledge. A knowledge graph-based strategy is then introduced to store\nthe acquired knowledge and extract task-relevant knowledge, enhancing the\nstronger agent in success rate and efficiency for the exploitation task. Our\napproach is flexible enough to incorporate diverse tasks, and obtains\nsignificant improvements in both success rates and efficiency across four\ninteractive benchmarks.",
      "tldr_zh": "该论文提出了一种名为 WESE 的方法，用于提升大型语言模型 (LLM) 代理在开放世界交互任务中的性能，解决现有方法忽略探索和利用过程导致的贪婪决策和噪声问题。WESE 通过将探索和利用过程解耦，使用低成本的弱代理进行探索以获取全局知识，并引入基于知识图的策略来存储和提取任务相关信息，从而增强强代理的效率和成功率。该方法适用于多种任务，并在四个交互基准上实现了显著的成功率和效率提升。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07456v1",
      "published_date": "2024-04-11 03:31:54 UTC",
      "updated_date": "2024-04-11 03:31:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:46:30.586698"
    },
    {
      "arxiv_id": "2404.07452v2",
      "title": "RiskLabs: Predicting Financial Risk Using Large Language Model based on Multimodal and Multi-Sources Data",
      "title_zh": "RiskLabs：利用大型语言模型基于多模态和多来源数据预测金融风险",
      "authors": [
        "Yupeng Cao",
        "Zhi Chen",
        "Prashant Kumar",
        "Qingyun Pei",
        "Yangyang Yu",
        "Haohang Li",
        "Fabrizio Dimino",
        "Lorenzo Ausiello",
        "K. P. Subbalakshmi",
        "Papa Momar Ndiaye"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) techniques, particularly\nlarge language models (LLMs), in finance has garnered increasing academic\nattention. Despite progress, existing studies predominantly focus on tasks like\nfinancial text summarization, question-answering, and stock movement prediction\n(binary classification), the application of LLMs to financial risk prediction\nremains underexplored. Addressing this gap, in this paper, we introduce\nRiskLabs, a novel framework that leverages LLMs to analyze and predict\nfinancial risks. RiskLabs uniquely integrates multimodal financial data,\nincluding textual and vocal information from Earnings Conference Calls (ECCs),\nmarket-related time series data, and contextual news data to improve financial\nrisk prediction. Empirical results demonstrate RiskLabs' effectiveness in\nforecasting both market volatility and variance. Through comparative\nexperiments, we examine the contributions of different data sources to\nfinancial risk assessment and highlight the crucial role of LLMs in this\nprocess. We also discuss the challenges associated with using LLMs for\nfinancial risk prediction and explore the potential of combining them with\nmultimodal data for this purpose.",
      "tldr_zh": "本研究提出RiskLabs框架，利用Large Language Models (LLMs)来分析和预测金融风险，填补了LLMs在这一领域的应用空白。框架整合多模态和多来源数据，包括Earnings Conference Calls (ECCs)的文本和语音信息、市场时间序列数据以及新闻数据，以提升风险预测准确性。实验结果显示，RiskLabs在预测市场波动性和方差方面表现出色，比传统方法提高了预测性能，并突出了不同数据来源的贡献，同时讨论了使用LLMs的挑战及其与多模态数据结合的潜力。",
      "categories": [
        "q-fin.RM",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "q-fin.PM"
      ],
      "primary_category": "q-fin.RM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07452v2",
      "published_date": "2024-04-11 03:14:50 UTC",
      "updated_date": "2025-05-03 01:01:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:46:41.731943"
    },
    {
      "arxiv_id": "2404.07446v2",
      "title": "Graph Attention Network for Lane-Wise and Topology-Invariant Intersection Traffic Simulation",
      "title_zh": "基于图注意力网络的车道级拓扑不变交叉口交通模拟",
      "authors": [
        "Nooshin Yousefzadeh",
        "Rahul Sengupta",
        "Yashaswi Karnati",
        "Anand Rangarajan",
        "Sanjay Ranka"
      ],
      "abstract": "Traffic congestion has significant economic, environmental, and social\nramifications. Intersection traffic flow dynamics are influenced by numerous\nfactors. While microscopic traffic simulators are valuable tools, they are\ncomputationally intensive and challenging to calibrate. Moreover, existing\nmachine-learning approaches struggle to provide lane-specific waveforms or\nadapt to intersection topology and traffic patterns. In this study, we propose\ntwo efficient and accurate \"Digital Twin\" models for intersections, leveraging\nGraph Attention Neural Networks (GAT). These attentional graph auto-encoder\ndigital twins capture temporal, spatial, and contextual aspects of traffic\nwithin intersections, incorporating various influential factors such as\nhigh-resolution loop detector waveforms, signal state records, driving\nbehaviors, and turning-movement counts. Trained on diverse counterfactual\nscenarios across multiple intersections, our models generalize well, enabling\nthe estimation of detailed traffic waveforms for any intersection approach and\nexit lanes. Multi-scale error metrics demonstrate that our models perform\ncomparably to microsimulations. The primary application of our study lies in\ntraffic signal optimization, a pivotal area in transportation systems research.\nThese lightweight digital twins can seamlessly integrate into corridor and\nnetwork signal timing optimization frameworks. Furthermore, our study's\napplications extend to lane reconfiguration, driving behavior analysis, and\nfacilitating informed decisions regarding intersection safety and efficiency\nenhancements. A promising avenue for future research involves extending this\napproach to urban freeway corridors and integrating it with measures of\neffectiveness metrics.",
      "tldr_zh": "本文提出两种基于 Graph Attention Neural Networks (GAT) 的数字孪生模型，用于高效模拟交叉口交通流动态，这些模型能捕捉交通的 temporal、spatial 和 contextual 方面，并整合因素如高分辨率环形检测器波形、信号状态和驾驶行为。模型在多样反事实场景上训练，具有拓扑不变性和车道特定波形生成能力，与微观模拟器相比性能相当。实验结果显示模型泛化性强，可应用于交通信号优化、车道重新配置和驾驶行为分析等领域。未来研究可扩展到城市高速公路走廊并整合有效性指标。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "T-TIS Journal, 12 pages, 8 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.07446v2",
      "published_date": "2024-04-11 03:02:06 UTC",
      "updated_date": "2024-05-02 00:39:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:46:55.745815"
    },
    {
      "arxiv_id": "2404.07439v1",
      "title": "Behavior Trees Enable Structured Programming of Language Model Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Kelley"
      ],
      "abstract": "Language models trained on internet-scale data sets have shown an impressive\nability to solve problems in Natural Language Processing and Computer Vision.\nHowever, experience is showing that these models are frequently brittle in\nunexpected ways, and require significant scaffolding to ensure that they\noperate correctly in the larger systems that comprise \"language-model agents.\"\nIn this paper, we argue that behavior trees provide a unifying framework for\ncombining language models with classical AI and traditional programming. We\nintroduce Dendron, a Python library for programming language model agents using\nbehavior trees. We demonstrate the approach embodied by Dendron in three case\nstudies: building a chat agent, a camera-based infrastructure inspection agent\nfor use on a mobile robot or vehicle, and an agent that has been built to\nsatisfy safety constraints that it did not receive through instruction tuning\nor RLHF.",
      "tldr_zh": "该论文指出，语言模型（language models）虽在自然语言处理和计算机视觉中表现出色，但易出现意外错误，需要额外支架（scaffolding）来确保在语言模型代理（language model agents）系统中稳定运行。作者提出使用行为树（behavior trees）作为统一框架，将语言模型与经典AI和传统编程相结合，并引入Dendron，一个Python库，用于通过行为树编程这些代理。论文通过三个案例研究——构建聊天代理、基于摄像头的移动机器人基础设施检查代理，以及满足安全约束（如未通过instruction tuning或RLHF训练）的代理——展示了这一方法的实用性和有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07439v1",
      "published_date": "2024-04-11 02:44:13 UTC",
      "updated_date": "2024-04-11 02:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:47:08.111617"
    },
    {
      "arxiv_id": "2404.07434v1",
      "title": "Data-Driven Portfolio Management for Motion Pictures Industry: A New Data-Driven Optimization Methodology Using a Large Language Model as the Expert",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Alipour-Vaezi",
        "Kwok-Leung Tsui"
      ],
      "abstract": "Portfolio management is one of the unresponded problems of the Motion\nPictures Industry (MPI). To design an optimal portfolio for an MPI distributor,\nit is essential to predict the box office of each project. Moreover, for an\naccurate box office prediction, it is critical to consider the effect of the\ncelebrities involved in each MPI project, which was impossible with any\nprecedent expert-based method. Additionally, the asymmetric characteristic of\nMPI data decreases the performance of any predictive algorithm. In this paper,\nfirstly, the fame score of the celebrities is determined using a large language\nmodel. Then, to tackle the asymmetric character of MPI's data, projects are\nclassified. Furthermore, the box office prediction takes place for each class\nof projects. Finally, using a hybrid multi-attribute decision-making technique,\nthe preferability of each project for the distributor is calculated, and\nbenefiting from a bi-objective optimization model, the optimal portfolio is\ndesigned.",
      "tldr_zh": "这篇论文提出了一种新的数据驱动优化方法，用于电影行业（Motion Pictures Industry, MPI）的投资组合管理，旨在通过预测票房和考虑名人影响来解决传统方法的局限性。方法首先利用 Large Language Model 评估名人的 fame score，然后对项目进行分类以处理数据的不对称性，并为每个类别进行票房预测。最终，通过混合多属性决策技术计算项目的优先级，并采用 bi-objective optimization model 设计出最优投资组合，从而提升了投资决策的准确性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07434v1",
      "published_date": "2024-04-11 02:23:30 UTC",
      "updated_date": "2024-04-11 02:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:47:21.316850"
    },
    {
      "arxiv_id": "2404.07413v1",
      "title": "JetMoE: Reaching Llama2 Performance with 0.1M Dollars",
      "title_zh": "翻译失败",
      "authors": [
        "Yikang Shen",
        "Zhen Guo",
        "Tianle Cai",
        "Zengyi Qin"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable results, but their\nincreasing resource demand has become a major obstacle to the development of\npowerful and accessible super-human intelligence. This report introduces\nJetMoE-8B, a new LLM trained with less than $0.1 million, using 1.25T tokens\nfrom carefully mixed open-source corpora and 30,000 H100 GPU hours. Despite its\nlow cost, the JetMoE-8B demonstrates impressive performance, with JetMoE-8B\noutperforming the Llama2-7B model and JetMoE-8B-Chat surpassing the\nLlama2-13B-Chat model. These results suggest that LLM training can be much more\ncost-effective than generally thought. JetMoE-8B is based on an efficient\nSparsely-gated Mixture-of-Experts (SMoE) architecture, composed of attention\nand feedforward experts. Both layers are sparsely activated, allowing JetMoE-8B\nto have 8B parameters while only activating 2B for each input token, reducing\ninference computation by about 70% compared to Llama2-7B. Moreover, JetMoE-8B\nis highly open and academia-friendly, using only public datasets and training\ncode. All training parameters and data mixtures have been detailed in this\nreport to facilitate future efforts in the development of open foundation\nmodels. This transparency aims to encourage collaboration and further\nadvancements in the field of accessible and efficient LLMs. The model weights\nare publicly available at https://github.com/myshell-ai/JetMoE.",
      "tldr_zh": "这篇论文介绍了 JetMoE-8B，一种以不到 10 万美元成本训练的大型语言模型 (LLMs)，使用 1.25T 标记的开源语料和 30,000 H100 GPU 小时，证明了高效 LLM 训练的可行性。JetMoE-8B 基于 Sparsely-gated Mixture-of-Experts (SMoE) 架构，仅激活 2B 参数，从而将推理计算减少约 70%，并在性能上超过了 Llama2-7B，而其聊天版本 JetMoE-8B-Chat 超过了 Llama2-13B-Chat。该模型高度开放，使用公共数据集和代码，所有训练参数及数据混合均已详细公开，以促进未来 LLM 开发的协作和进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07413v1",
      "published_date": "2024-04-11 00:52:39 UTC",
      "updated_date": "2024-04-11 00:52:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:47:34.472776"
    },
    {
      "arxiv_id": "2404.07396v3",
      "title": "Can Base ChatGPT be Used for Forecasting without Additional Optimization?",
      "title_zh": "基础 ChatGPT 是否能在无需额外优化的情况下用于预测？",
      "authors": [
        "Van Pham",
        "Scott Cunningham"
      ],
      "abstract": "This study investigates whether OpenAI's ChatGPT-3.5 and ChatGPT-4 can\nforecast future events. To evaluate the accuracy of the predictions, we take\nadvantage of the fact that the training data at the time of our experiments\n(mid 2023) stopped at September 2021, and ask about events that happened in\n2022. We employed two prompting strategies: direct prediction and what we call\nfuture narratives which ask ChatGPT to tell fictional stories set in the future\nwith characters retelling events that happened in the past, but after ChatGPT's\ntraining data had been collected. We prompted ChatGPT to engage in\nstorytelling, particularly within economic contexts. After analyzing 100\ntrials, we find that future narrative prompts significantly enhanced\nChatGPT-4's forecasting accuracy. This was especially evident in its\npredictions of major Academy Award winners as well as economic trends, the\nlatter inferred from scenarios where the model impersonated public figures like\nthe Federal Reserve Chair, Jerome Powell. As a falsification exercise, we\nrepeated our experiments in May 2024 at which time the models included more\nrecent training data. ChatGPT-4's accuracy significantly improved when the\ntraining window included the events being prompted for, achieving 100% accuracy\nin many instances. The poorer accuracy for events outside of the training\nwindow suggests that in the 2023 prediction experiments, ChatGPT-4 was forming\npredictions based solely on its training data. Narrative prompting also\nconsistently outperformed direct prompting. These findings indicate that\nnarrative prompts leverage the models' capacity for hallucinatory narrative\nconstruction, facilitating more effective data synthesis and extrapolation than\nstraightforward predictions. Our research reveals new aspects of LLMs'\npredictive capabilities and suggests potential future applications in\nanalytical contexts.",
      "tldr_zh": "本研究评估了 ChatGPT-3.5 和 ChatGPT-4 在无额外优化下进行未来事件预测的能力，通过直接预测和 future narratives 提示策略（后者让模型讲述虚构故事以推断后续事件）来测试对 2022 年事件的准确性。结果显示，future narratives 显著提高了 ChatGPT-4 的预测性能，尤其在经济趋势（如模拟 Jerome Powell 的声明）和奥斯卡奖得主预测上。进一步的 2024 年实验证明，当训练数据包含相关事件时，模型准确率可达 100%，表明其预测主要依赖训练数据而非真正推断能力；这些发现揭示了 LLMs 在分析情境中的潜在应用。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "77 pages, added falsification exercises in section `Post\n  Scriptum:...' with new figures; new title 61 pages, 26 figures; corrected\n  typos",
      "pdf_url": "http://arxiv.org/pdf/2404.07396v3",
      "published_date": "2024-04-11 00:03:03 UTC",
      "updated_date": "2024-07-04 23:03:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:47:47.590651"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 104,
  "processed_papers_count": 104,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T23:48:16.015072"
}