[
  {
    "arxiv_id": "2404.08161v2",
    "title": "R2 Indicator and Deep Reinforcement Learning Enhanced Adaptive Multi-Objective Evolutionary Algorithm",
    "authors": [
      "Farajollah Tahernezhad-Javazm",
      "Debbie Rankin",
      "Naomi Du Bois",
      "Alice E. Smith",
      "Damien Coyle"
    ],
    "abstract": "Choosing an appropriate optimization algorithm is essential to achieving\nsuccess in optimization challenges. Here we present a new evolutionary\nalgorithm structure that utilizes a reinforcement learning-based agent aimed at\naddressing these issues. The agent employs a double deep q-network to choose a\nspecific evolutionary operator based on feedback it receives from the\nenvironment during optimization. The algorithm's structure contains five\nsingle-objective evolutionary algorithm operators. This single-objective\nstructure is transformed into a multi-objective one using the R2 indicator.\nThis indicator serves two purposes within our structure: first, it renders the\nalgorithm multi-objective, and second, provides a means to evaluate each\nalgorithm's performance in each generation to facilitate constructing the\nreinforcement learning-based reward function. The proposed R2-reinforcement\nlearning multi-objective evolutionary algorithm (R2-RLMOEA) is compared with\nsix other multi-objective algorithms that are based on R2 indicators. These six\nalgorithms include the operators used in R2-RLMOEA as well as an R2\nindicator-based algorithm that randomly selects operators during optimization.\nWe benchmark performance using the CEC09 functions, with performance measured\nby inverted generational distance and spacing. The R2-RLMOEA algorithm\noutperforms all other algorithms with strong statistical significance (p<0.001)\nwhen compared with the average spacing metric across all ten benchmarks.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08161v2",
    "published_date": "2024-04-11 23:50:30 UTC",
    "updated_date": "2024-04-17 08:23:23 UTC"
  },
  {
    "arxiv_id": "2404.08144v2",
    "title": "LLM Agents can Autonomously Exploit One-day Vulnerabilities",
    "authors": [
      "Richard Fang",
      "Rohan Bindu",
      "Akul Gupta",
      "Daniel Kang"
    ],
    "abstract": "LLMs have becoming increasingly powerful, both in their benign and malicious\nuses. With the increase in capabilities, researchers have been increasingly\ninterested in their ability to exploit cybersecurity vulnerabilities. In\nparticular, recent work has conducted preliminary studies on the ability of LLM\nagents to autonomously hack websites. However, these studies are limited to\nsimple vulnerabilities.\n  In this work, we show that LLM agents can autonomously exploit one-day\nvulnerabilities in real-world systems. To show this, we collected a dataset of\n15 one-day vulnerabilities that include ones categorized as critical severity\nin the CVE description. When given the CVE description, GPT-4 is capable of\nexploiting 87% of these vulnerabilities compared to 0% for every other model we\ntest (GPT-3.5, open-source LLMs) and open-source vulnerability scanners (ZAP\nand Metasploit). Fortunately, our GPT-4 agent requires the CVE description for\nhigh performance: without the description, GPT-4 can exploit only 7% of the\nvulnerabilities. Our findings raise questions around the widespread deployment\nof highly capable LLM agents.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08144v2",
    "published_date": "2024-04-11 22:07:19 UTC",
    "updated_date": "2024-04-17 04:34:39 UTC"
  },
  {
    "arxiv_id": "2404.08127v1",
    "title": "Self-Supervised Learning of Color Constancy",
    "authors": [
      "Markus R. Ernst",
      "Francisco M. López",
      "Arthur Aubret",
      "Roland W. Fleming",
      "Jochen Triesch"
    ],
    "abstract": "Color constancy (CC) describes the ability of the visual system to perceive\nan object as having a relatively constant color despite changes in lighting\nconditions. While CC and its limitations have been carefully characterized in\nhumans, it is still unclear how the visual system acquires this ability during\ndevelopment. Here, we present a first study showing that CC develops in a\nneural network trained in a self-supervised manner through an invariance\nlearning objective. During learning, objects are presented under changing\nilluminations, while the network aims to map subsequent views of the same\nobject onto close-by latent representations. This gives rise to representations\nthat are largely invariant to the illumination conditions, offering a plausible\nexample of how CC could emerge during human cognitive development via a form of\nself-supervised learning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 5 figures, submitted to the IEEE International Conference on\n  Development and Learning (ICDL 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.08127v1",
    "published_date": "2024-04-11 21:07:38 UTC",
    "updated_date": "2024-04-11 21:07:38 UTC"
  },
  {
    "arxiv_id": "2404.08126v1",
    "title": "Auctions with LLM Summaries",
    "authors": [
      "Kumar Avinava Dubey",
      "Zhe Feng",
      "Rahul Kidambi",
      "Aranyak Mehta",
      "Di Wang"
    ],
    "abstract": "We study an auction setting in which bidders bid for placement of their\ncontent within a summary generated by a large language model (LLM), e.g., an ad\nauction in which the display is a summary paragraph of multiple ads. This\ngeneralizes the classic ad settings such as position auctions to an LLM\ngenerated setting, which allows us to handle general display formats. We\npropose a novel factorized framework in which an auction module and an LLM\nmodule work together via a prediction model to provide welfare maximizing\nsummary outputs in an incentive compatible manner. We provide a theoretical\nanalysis of this framework and synthetic experiments to demonstrate the\nfeasibility and validity of the system together with welfare comparisons.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08126v1",
    "published_date": "2024-04-11 21:05:56 UTC",
    "updated_date": "2024-04-11 21:05:56 UTC"
  },
  {
    "arxiv_id": "2404.08113v1",
    "title": "Predictive Handover Strategy in 6G and Beyond: A Deep and Transfer Learning Approach",
    "authors": [
      "Ioannis Panitsas",
      "Akrit Mudvari",
      "Ali Maatouk",
      "Leandros Tassiulas"
    ],
    "abstract": "Next-generation cellular networks will evolve into more complex and\nvirtualized systems, employing machine learning for enhanced optimization and\nleveraging higher frequency bands and denser deployments to meet varied service\ndemands. This evolution, while bringing numerous advantages, will also pose\nchallenges, especially in mobility management, as it will increase the overall\nnumber of handovers due to smaller coverage areas and the higher signal\nattenuation. To address these challenges, we propose a deep learning based\nalgorithm for predicting the future serving cell utilizing sequential user\nequipment measurements to minimize the handover failures and interruption time.\nOur algorithm enables network operators to dynamically adjust handover\ntriggering events or incorporate UAV base stations for enhanced coverage and\ncapacity, optimizing network objectives like load balancing and energy\nefficiency through transfer learning techniques. Our framework complies with\nthe O-RAN specifications and can be deployed in a Near-Real-Time RAN\nIntelligent Controller as an xApp leveraging the E2SM-KPM service model. The\nevaluation results demonstrate that our algorithm achieves a 92% accuracy in\npredicting future serving cells with high probability. Finally, by utilizing\ntransfer learning, our algorithm significantly reduces the retraining time by\n91% and 77% when new handover trigger decisions or UAV base stations are\nintroduced to the network dynamically.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08113v1",
    "published_date": "2024-04-11 20:30:36 UTC",
    "updated_date": "2024-04-11 20:30:36 UTC"
  },
  {
    "arxiv_id": "2404.13061v1",
    "title": "FPGA Divide-and-Conquer Placement using Deep Reinforcement Learning",
    "authors": [
      "Shang Wang",
      "Deepak Ranganatha Sastry Mamillapalli",
      "Tianpei Yang",
      "Matthew E. Taylor"
    ],
    "abstract": "This paper introduces the problem of learning to place logic blocks in\nField-Programmable Gate Arrays (FPGAs) and a learning-based method. In contrast\nto previous search-based placement algorithms, we instead employ Reinforcement\nLearning (RL) with the goal of minimizing wirelength. In addition to our\npreliminary learning results, we also evaluated a novel decomposition to\naddress the nature of large search space when placing many blocks on a\nchipboard. Empirical experiments evaluate the effectiveness of the learning and\ndecomposition paradigms on FPGA placement tasks.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "accepted by ISEDA2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13061v1",
    "published_date": "2024-04-11 20:29:15 UTC",
    "updated_date": "2024-04-11 20:29:15 UTC"
  },
  {
    "arxiv_id": "2404.08111v1",
    "title": "S3Editor: A Sparse Semantic-Disentangled Self-Training Framework for Face Video Editing",
    "authors": [
      "Guangzhi Wang",
      "Tianyi Chen",
      "Kamran Ghasedi",
      "HsiangTao Wu",
      "Tianyu Ding",
      "Chris Nuesmeyer",
      "Ilya Zharkov",
      "Mohan Kankanhalli",
      "Luming Liang"
    ],
    "abstract": "Face attribute editing plays a pivotal role in various applications. However,\nexisting methods encounter challenges in achieving high-quality results while\npreserving identity, editing faithfulness, and temporal consistency. These\nchallenges are rooted in issues related to the training pipeline, including\nlimited supervision, architecture design, and optimization strategy. In this\nwork, we introduce S3Editor, a Sparse Semantic-disentangled Self-training\nframework for face video editing. S3Editor is a generic solution that\ncomprehensively addresses these challenges with three key contributions.\nFirstly, S3Editor adopts a self-training paradigm to enhance the training\nprocess through semi-supervision. Secondly, we propose a semantic disentangled\narchitecture with a dynamic routing mechanism that accommodates diverse editing\nrequirements. Thirdly, we present a structured sparse optimization schema that\nidentifies and deactivates malicious neurons to further disentangle impacts\nfrom untarget attributes. S3Editor is model-agnostic and compatible with\nvarious editing approaches. Our extensive qualitative and quantitative results\naffirm that our approach significantly enhances identity preservation, editing\nfidelity, as well as temporal consistency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08111v1",
    "published_date": "2024-04-11 20:25:26 UTC",
    "updated_date": "2024-04-11 20:25:26 UTC"
  },
  {
    "arxiv_id": "2404.16053v1",
    "title": "Human Latency Conversational Turns for Spoken Avatar Systems",
    "authors": [
      "Derek Jacoby",
      "Tianyi Zhang",
      "Aanchan Mohan",
      "Yvonne Coady"
    ],
    "abstract": "A problem with many current Large Language Model (LLM) driven spoken\ndialogues is the response time. Some efforts such as Groq address this issue by\nlightning fast processing of the LLM, but we know from the cognitive psychology\nliterature that in human-to-human dialogue often responses occur prior to the\nspeaker completing their utterance. No amount of delay for LLM processing is\nacceptable if we wish to maintain human dialogue latencies. In this paper, we\ndiscuss methods for understanding an utterance in close to real time and\ngenerating a response so that the system can comply with human-level\nconversational turn delays. This means that the information content of the\nfinal part of the speaker's utterance is lost to the LLM. Using the Google\nNaturalQuestions (NQ) database, our results show GPT-4 can effectively fill in\nmissing context from a dropped word at the end of a question over 60% of the\ntime. We also provide some examples of utterances and the impacts of this\ninformation loss on the quality of LLM response in the context of an avatar\nthat is currently under development. These results indicate that a simple\nclassifier could be used to determine whether a question is semantically\ncomplete, or requires a filler phrase to allow a response to be generated\nwithin human dialogue time constraints.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16053v1",
    "published_date": "2024-04-11 20:20:48 UTC",
    "updated_date": "2024-04-11 20:20:48 UTC"
  },
  {
    "arxiv_id": "2406.11863v1",
    "title": "The Transformation Risk-Benefit Model of Artificial Intelligence: Balancing Risks and Benefits Through Practical Solutions and Use Cases",
    "authors": [
      "Richard Fulton",
      "Diane Fulton",
      "Nate Hayes",
      "Susan Kaplan"
    ],
    "abstract": "This paper summarizes the most cogent advantages and risks associated with\nArtificial Intelligence from an in-depth review of the literature. Then the\nauthors synthesize the salient risk-related models currently being used in AI,\ntechnology and business-related scenarios. Next, in view of an updated context\nof AI along with theories and models reviewed and expanded constructs, the\nwriters propose a new framework called \"The Transformation Risk-Benefit Model\nof Artificial Intelligence\" to address the increasing fears and levels of AI\nrisk. Using the model characteristics, the article emphasizes practical and\ninnovative solutions where benefits outweigh risks and three use cases in\nhealthcare, climate change/environment and cyber security to illustrate unique\ninterplay of principles, dimensions and processes of this powerful AI\ntransformational model.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "00-02, 01-02, 03-02, 68T320, 68T37, 68Q32, 93C85, 93C95",
      "A.0; H.1.1; H.1.2; I.2.0; I.2.1; J.4; K.4.2; K.4.3; K.6.0"
    ],
    "primary_category": "cs.CY",
    "comment": "22 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.11863v1",
    "published_date": "2024-04-11 19:19:57 UTC",
    "updated_date": "2024-04-11 19:19:57 UTC"
  },
  {
    "arxiv_id": "2404.08093v2",
    "title": "Towards a Robust Soft Baby Robot With Rich Interaction Ability for Advanced Machine Learning Algorithms",
    "authors": [
      "Mohannad Alhakami",
      "Dylan R. Ashley",
      "Joel Dunham",
      "Yanning Dai",
      "Francesco Faccio",
      "Eric Feron",
      "Jürgen Schmidhuber"
    ],
    "abstract": "Advanced machine learning algorithms require platforms that are extremely\nrobust and equipped with rich sensory feedback to handle extensive\ntrial-and-error learning without relying on strong inductive biases.\nTraditional robotic designs, while well-suited for their specific use cases,\nare often fragile when used with these algorithms. To address this gap -- and\ninspired by the vision of enabling curiosity-driven baby robots -- we present a\nnovel robotic limb designed from scratch. Our design has a hybrid soft-hard\nstructure, high redundancy with rich non-contact sensors (exclusively cameras),\nand easily replaceable failure points. Proof-of-concept experiments using two\ncontemporary reinforcement learning algorithms on a physical prototype\ndemonstrate that our design is able to succeed in a simple target-finding task\neven under simulated sensor failures, all with minimal human oversight during\nextended learning periods. We believe this design represents a concrete step\ntoward more tailored robotic designs for achieving general-purpose, generally\nintelligent robots.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "I.2.9; I.2.6"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages in main text + 2 pages of references, 8 figures in main text,\n  1 table in main text; source code available at\n  https://github.com/dylanashley/robot-limb-testai",
    "pdf_url": "http://arxiv.org/pdf/2404.08093v2",
    "published_date": "2024-04-11 19:15:45 UTC",
    "updated_date": "2024-12-04 14:45:23 UTC"
  },
  {
    "arxiv_id": "2404.08092v1",
    "title": "Data-Augmentation-Based Dialectal Adaptation for LLMs",
    "authors": [
      "Fahim Faisal",
      "Antonios Anastasopoulos"
    ],
    "abstract": "This report presents GMUNLP's participation to the Dialect-Copa shared task\nat VarDial 2024, which focuses on evaluating the commonsense reasoning\ncapabilities of large language models (LLMs) on South Slavic micro-dialects.\nThe task aims to assess how well LLMs can handle non-standard dialectal\nvarieties, as their performance on standard languages is already\nwell-established. We propose an approach that combines the strengths of\ndifferent types of language models and leverages data augmentation techniques\nto improve task performance on three South Slavic dialects: Chakavian,\nCherkano, and Torlak. We conduct experiments using a language-family-focused\nencoder-based model (BERTi\\'c) and a domain-agnostic multilingual model\n(AYA-101). Our results demonstrate that the proposed data augmentation\ntechniques lead to substantial performance gains across all three test datasets\nin the open-source model category. This work highlights the practical utility\nof data augmentation and the potential of LLMs in handling non-standard\ndialectal varieties, contributing to the broader goal of advancing natural\nlanguage understanding in low-resource and dialectal settings.\nCode:https://github.com/ffaisal93/dialect_copa",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08092v1",
    "published_date": "2024-04-11 19:15:32 UTC",
    "updated_date": "2024-04-11 19:15:32 UTC"
  },
  {
    "arxiv_id": "2404.08710v2",
    "title": "Do Large Language Models Learn Human-Like Strategic Preferences?",
    "authors": [
      "Jesse Roberts",
      "Kyle Moore",
      "Doug Fisher"
    ],
    "abstract": "In this paper, we evaluate whether LLMs learn to make human-like preference\njudgements in strategic scenarios as compared with known empirical results.\nSolar and Mistral are shown to exhibit stable value-based preference consistent\nwith humans and exhibit human-like preference for cooperation in the prisoner's\ndilemma (including stake-size effect) and traveler's dilemma (including\npenalty-size effect). We establish a relationship between model size,\nvalue-based preference, and superficiality. Finally, results here show that\nmodels tending to be less brittle have relied on sliding window attention\nsuggesting a potential link. Additionally, we contribute a novel method for\nconstructing preference relations from arbitrary LLMs and support for a\nhypothesis regarding human behavior in the traveler's dilemma.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08710v2",
    "published_date": "2024-04-11 19:13:24 UTC",
    "updated_date": "2024-10-02 17:54:17 UTC"
  },
  {
    "arxiv_id": "2404.08080v1",
    "title": "Variance-reduced Zeroth-Order Methods for Fine-Tuning Language Models",
    "authors": [
      "Tanmay Gautam",
      "Youngsuk Park",
      "Hao Zhou",
      "Parameswaran Raman",
      "Wooseok Ha"
    ],
    "abstract": "Fine-tuning language models (LMs) has demonstrated success in a wide array of\ndownstream tasks. However, as LMs are scaled up, the memory requirements for\nbackpropagation become prohibitively high. Zeroth-order (ZO) optimization\nmethods can leverage memory-efficient forward passes to estimate gradients.\nMore recently, MeZO, an adaptation of ZO-SGD, has been shown to consistently\noutperform zero-shot and in-context learning when combined with suitable task\nprompts. In this work, we couple ZO methods with variance reduction techniques\nto enhance stability and convergence for inference-based LM fine-tuning. We\nintroduce Memory-Efficient Zeroth-Order Stochastic Variance-Reduced Gradient\n(MeZO-SVRG) and demonstrate its efficacy across multiple LM fine-tuning tasks,\neliminating the reliance on task-specific prompts. Evaluated across a range of\nboth masked and autoregressive LMs on benchmark GLUE tasks, MeZO-SVRG\noutperforms MeZO with up to 20% increase in test accuracies in both full- and\npartial-parameter fine-tuning settings. MeZO-SVRG benefits from reduced\ncomputation time as it often surpasses MeZO's peak test accuracy with a\n$2\\times$ reduction in GPU-hours. MeZO-SVRG significantly reduces the required\nmemory footprint compared to first-order SGD, i.e. by $2\\times$ for\nautoregressive models. Our experiments highlight that MeZO-SVRG's memory\nsavings progressively improve compared to SGD with larger batch sizes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 25 tables, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.08080v1",
    "published_date": "2024-04-11 18:35:49 UTC",
    "updated_date": "2024-04-11 18:35:49 UTC"
  },
  {
    "arxiv_id": "2404.08078v1",
    "title": "SQBC: Active Learning using LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions",
    "authors": [
      "Stefan Sylvius Wagner",
      "Maike Behrendt",
      "Marc Ziegele",
      "Stefan Harmeling"
    ],
    "abstract": "Stance detection is an important task for many applications that analyse or\nsupport online political discussions. Common approaches include fine-tuning\ntransformer based models. However, these models require a large amount of\nlabelled data, which might not be available. In this work, we present two\ndifferent ways to leverage LLM-generated synthetic data to train and improve\nstance detection agents for online political discussions: first, we show that\naugmenting a small fine-tuning dataset with synthetic data can improve the\nperformance of the stance detection model. Second, we propose a new active\nlearning method called SQBC based on the \"Query-by-Comittee\" approach. The key\nidea is to use LLM-generated synthetic data as an oracle to identify the most\ninformative unlabelled samples, that are selected for manual labelling.\nComprehensive experiments show that both ideas can improve the stance detection\nperformance. Curiously, we observed that fine-tuning on actively selected\nsamples can exceed the performance of using the full dataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08078v1",
    "published_date": "2024-04-11 18:34:11 UTC",
    "updated_date": "2024-04-11 18:34:11 UTC"
  },
  {
    "arxiv_id": "2404.08068v2",
    "title": "WildGraph: Realistic Graph-based Trajectory Generation for Wildlife",
    "authors": [
      "Ali Al-Lawati",
      "Elsayed Eshra",
      "Prasenjit Mitra"
    ],
    "abstract": "Trajectory generation is an important task in movement studies; it\ncircumvents the privacy, ethical, and technical challenges of collecting real\ntrajectories from the target population. In particular, real trajectories in\nthe wildlife domain are scarce as a result of ethical and environmental\nconstraints of the collection process. In this paper, we consider the problem\nof generating long-horizon trajectories, akin to wildlife migration, based on a\nsmall set of real samples. We propose a hierarchical approach to learn the\nglobal movement characteristics of the real dataset and recursively refine\nlocalized regions. Our solution, WildGraph, discretizes the geographic path\ninto a prototype network of H3 (https://www.uber.com/blog/h3/) regions and\nleverages a recurrent variational auto-encoder to probabilistically generate\npaths over the regions, based on occupancy. WildGraph successfully generates\nrealistic months-long trajectories using a sample size as small as 60.\nExperiments performed on two wildlife migration datasets demonstrate that our\nproposed method improves the generalization of the generated trajectories in\ncomparison to existing work while achieving superior or comparable performance\nin several benchmark metrics. Our code is published on the following\nrepository: https://github.com/aliwister/wildgraph.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 7 figures, SIGSPATIAL '24",
    "pdf_url": "http://arxiv.org/pdf/2404.08068v2",
    "published_date": "2024-04-11 18:13:21 UTC",
    "updated_date": "2025-02-08 03:20:40 UTC"
  },
  {
    "arxiv_id": "2404.08064v4",
    "title": "The Impact of Speech Anonymization on Pathology and Its Limits",
    "authors": [
      "Soroosh Tayebi Arasteh",
      "Tomas Arias-Vergara",
      "Paula Andrea Perez-Toro",
      "Tobias Weise",
      "Kai Packhaeuser",
      "Maria Schuster",
      "Elmar Noeth",
      "Andreas Maier",
      "Seung Hee Yang"
    ],
    "abstract": "Integration of speech into healthcare has intensified privacy concerns due to\nits potential as a non-invasive biomarker containing individual biometric\ninformation. In response, speaker anonymization aims to conceal personally\nidentifiable information while retaining crucial linguistic content. However,\nthe application of anonymization techniques to pathological speech, a critical\narea where privacy is especially vital, has not been extensively examined. This\nstudy investigates anonymization's impact on pathological speech across over\n2,700 speakers from multiple German institutions, focusing on privacy,\npathological utility, and demographic fairness. We explore both\ndeep-learning-based and signal processing-based anonymization methods. We\ndocument substantial privacy improvements across disorders-evidenced by equal\nerror rate increases up to 1933%, with minimal overall impact on utility.\nSpecific disorders such as Dysarthria, Dysphonia, and Cleft Lip and Palate\nexperience minimal utility changes, while Dysglossia shows slight improvements.\nOur findings underscore that the impact of anonymization varies substantially\nacross different disorders. This necessitates disorder-specific anonymization\nstrategies to optimally balance privacy with diagnostic utility. Additionally,\nour fairness analysis reveals consistent anonymization effects across most of\nthe demographics. This study demonstrates the effectiveness of anonymization in\npathological speech for enhancing privacy, while also highlighting the\nimportance of customized and disorder-specific approaches to account for\ninversion attacks.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "Published in Communications Medicine",
    "pdf_url": "http://arxiv.org/pdf/2404.08064v4",
    "published_date": "2024-04-11 18:06:35 UTC",
    "updated_date": "2024-09-20 13:23:49 UTC"
  },
  {
    "arxiv_id": "2404.08061v2",
    "title": "Physics-Enhanced Graph Neural Networks For Soft Sensing in Industrial Internet of Things",
    "authors": [
      "Keivan Faghih Niresi",
      "Hugo Bissig",
      "Henri Baumann",
      "Olga Fink"
    ],
    "abstract": "The Industrial Internet of Things (IIoT) is reshaping manufacturing,\nindustrial processes, and infrastructure management. By fostering new levels of\nautomation, efficiency, and predictive maintenance, IIoT is transforming\ntraditional industries into intelligent, seamlessly interconnected ecosystems.\nHowever, achieving highly reliable IIoT can be hindered by factors such as the\ncost of installing large numbers of sensors, limitations in retrofitting\nexisting systems with sensors, or harsh environmental conditions that may make\nsensor installation impractical. Soft (virtual) sensing leverages mathematical\nmodels to estimate variables from physical sensor data, offering a solution to\nthese challenges. Data-driven and physics-based modeling are the two main\nmethodologies widely used for soft sensing. The choice between these strategies\ndepends on the complexity of the underlying system, with the data-driven\napproach often being preferred when the physics-based inference models are\nintricate and present challenges for state estimation. However, conventional\ndeep learning models are typically hindered by their inability to explicitly\nrepresent the complex interactions among various sensors. To address this\nlimitation, we adopt Graph Neural Networks (GNNs), renowned for their ability\nto effectively capture the complex relationships between sensor measurements.\nIn this research, we propose physics-enhanced GNNs, which integrate principles\nof physics into graph-based methodologies. This is achieved by augmenting\nadditional nodes in the input graph derived from the underlying characteristics\nof the physical processes. Our evaluation of the proposed methodology on the\ncase study of district heating networks reveals significant improvements over\npurely data-driven GNNs, even in the presence of noise and parameter\ninaccuracies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 10 figures. Accepted to IEEE Internet of Things Journal",
    "pdf_url": "http://arxiv.org/pdf/2404.08061v2",
    "published_date": "2024-04-11 18:03:59 UTC",
    "updated_date": "2024-07-25 10:52:26 UTC"
  },
  {
    "arxiv_id": "2404.08708v2",
    "title": "Multi-scale Topology Optimization using Neural Networks",
    "authors": [
      "Hongrui Chen",
      "Xingchen Liu",
      "Levent Burak Kara"
    ],
    "abstract": "A long-standing challenge is designing multi-scale structures with good\nconnectivity between cells while optimizing each cell to reach close to the\ntheoretical performance limit. We propose a new method for direct multi-scale\ntopology optimization using neural networks. Our approach focuses on inverse\nhomogenization that seamlessly maintains compatibility across neighboring\nmicrostructure cells. Our approach consists of a topology neural network that\noptimizes the microstructure shape and distribution across the design domain as\na continuous field. Each microstructure cell is optimized based on a specified\nelasticity tensor that also accommodates in-plane rotations. The neural network\ntakes as input the local coordinates within a cell to represent the density\ndistribution within a cell, as well as the global coordinates of each cell to\ndesign spatially varying microstructure cells. As such, our approach models an\nn-dimensional multi-scale optimization problem as a 2n-dimensional inverse\nhomogenization problem using neural networks. During the inverse homogenization\nof each unit cell, we extend the boundary of each cell by scaling the input\ncoordinates such that the boundaries of neighboring cells are combined. Inverse\nhomogenization on the combined cell improves connectivity. We demonstrate our\nmethod through the design and optimization of graded multi-scale structures.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08708v2",
    "published_date": "2024-04-11 18:00:22 UTC",
    "updated_date": "2025-02-20 03:25:27 UTC"
  },
  {
    "arxiv_id": "2404.07990v2",
    "title": "OpenBias: Open-set Bias Detection in Text-to-Image Generative Models",
    "authors": [
      "Moreno D'Incà",
      "Elia Peruzzo",
      "Massimiliano Mancini",
      "Dejia Xu",
      "Vidit Goel",
      "Xingqian Xu",
      "Zhangyang Wang",
      "Humphrey Shi",
      "Nicu Sebe"
    ],
    "abstract": "Text-to-image generative models are becoming increasingly popular and\naccessible to the general public. As these models see large-scale deployments,\nit is necessary to deeply investigate their safety and fairness to not\ndisseminate and perpetuate any kind of biases. However, existing works focus on\ndetecting closed sets of biases defined a priori, limiting the studies to\nwell-known concepts. In this paper, we tackle the challenge of open-set bias\ndetection in text-to-image generative models presenting OpenBias, a new\npipeline that identifies and quantifies the severity of biases agnostically,\nwithout access to any precompiled set. OpenBias has three stages. In the first\nphase, we leverage a Large Language Model (LLM) to propose biases given a set\nof captions. Secondly, the target generative model produces images using the\nsame set of captions. Lastly, a Vision Question Answering model recognizes the\npresence and extent of the previously proposed biases. We study the behavior of\nStable Diffusion 1.5, 2, and XL emphasizing new biases, never investigated\nbefore. Via quantitative experiments, we demonstrate that OpenBias agrees with\ncurrent closed-set bias detection methods and human judgement.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024 Highlight - Code:\n  https://github.com/Picsart-AI-Research/OpenBias",
    "pdf_url": "http://arxiv.org/pdf/2404.07990v2",
    "published_date": "2024-04-11 17:59:56 UTC",
    "updated_date": "2024-08-05 12:55:47 UTC"
  },
  {
    "arxiv_id": "2404.08031v2",
    "title": "Latent Guard: a Safety Framework for Text-to-image Generation",
    "authors": [
      "Runtao Liu",
      "Ashkan Khakzar",
      "Jindong Gu",
      "Qifeng Chen",
      "Philip Torr",
      "Fabio Pizzati"
    ],
    "abstract": "With the ability to generate high-quality images, text-to-image (T2I) models\ncan be exploited for creating inappropriate content. To prevent misuse,\nexisting safety measures are either based on text blacklists, which can be\neasily circumvented, or harmful content classification, requiring large\ndatasets for training and offering low flexibility. Hence, we propose Latent\nGuard, a framework designed to improve safety measures in text-to-image\ngeneration. Inspired by blacklist-based approaches, Latent Guard learns a\nlatent space on top of the T2I model's text encoder, where it is possible to\ncheck the presence of harmful concepts in the input text embeddings. Our\nproposed framework is composed of a data generation pipeline specific to the\ntask using large language models, ad-hoc architectural components, and a\ncontrastive learning strategy to benefit from the generated data. The\neffectiveness of our method is verified on three datasets and against four\nbaselines. Code and data will be shared at https://latentguard.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted to ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.08031v2",
    "published_date": "2024-04-11 17:59:52 UTC",
    "updated_date": "2024-08-18 18:53:16 UTC"
  },
  {
    "arxiv_id": "2404.07989v3",
    "title": "Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding",
    "authors": [
      "Yiwen Tang",
      "Ray Zhang",
      "Jiaming Liu",
      "Zoey Guo",
      "Dong Wang",
      "Zhigang Wang",
      "Bin Zhao",
      "Shanghang Zhang",
      "Peng Gao",
      "Hongsheng Li",
      "Xuelong Li"
    ],
    "abstract": "Large foundation models have recently emerged as a prominent focus of\ninterest, attaining superior performance in widespread scenarios. Due to the\nscarcity of 3D data, many efforts have been made to adapt pre-trained\ntransformers from vision to 3D domains. However, such 2D-to-3D approaches are\nstill limited, due to the potential loss of spatial geometries and high\ncomputation cost. More importantly, their frameworks are mainly designed for 2D\nmodels, lacking a general any-to-3D paradigm. In this paper, we introduce\nAny2Point, a parameter-efficient method to empower any-modality large models\n(vision, language, audio) for 3D understanding. Given a frozen transformer from\nany source modality, we propose a 3D-to-any (1D or 2D) virtual projection\nstrategy that correlates the input 3D points to the original 1D or 2D positions\nwithin the source modality. This mechanism enables us to assign each 3D token\nwith a positional encoding paired with the pre-trained model, which avoids 3D\ngeometry loss caused by the true projection and better motivates the\ntransformer for 3D learning with 1D/2D positional priors. Then, within each\ntransformer block, we insert an any-to-3D guided adapter module for\nparameter-efficient fine-tuning. The adapter incorporates prior spatial\nknowledge from the source modality to guide the local feature aggregation of 3D\ntokens, compelling the semantic adaption of any-modality transformers. We\nconduct extensive experiments to showcase the effectiveness and efficiency of\nour method. Code and models are released at\nhttps://github.com/Ivan-Tang-3D/Any2Point.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "Code and models are released at\n  https://github.com/Ivan-Tang-3D/Any2Point",
    "pdf_url": "http://arxiv.org/pdf/2404.07989v3",
    "published_date": "2024-04-11 17:59:45 UTC",
    "updated_date": "2024-10-21 10:54:55 UTC"
  },
  {
    "arxiv_id": "2404.08030v1",
    "title": "Rethinking Artistic Copyright Infringements in the Era of Text-to-Image Generative Models",
    "authors": [
      "Mazda Moayeri",
      "Samyadeep Basu",
      "Sriram Balasubramanian",
      "Priyatham Kattakinda",
      "Atoosa Chengini",
      "Robert Brauneis",
      "Soheil Feizi"
    ],
    "abstract": "Recent text-to-image generative models such as Stable Diffusion are extremely\nadept at mimicking and generating copyrighted content, raising concerns amongst\nartists that their unique styles may be improperly copied. Understanding how\ngenerative models copy \"artistic style\" is more complex than duplicating a\nsingle image, as style is comprised by a set of elements (or signature) that\nfrequently co-occurs across a body of work, where each individual work may vary\nsignificantly. In our paper, we first reformulate the problem of \"artistic\ncopyright infringement\" to a classification problem over image sets, instead of\nprobing image-wise similarities. We then introduce ArtSavant, a practical\n(i.e., efficient and easy to understand) tool to (i) determine the unique style\nof an artist by comparing it to a reference dataset of works from 372 artists\ncurated from WikiArt, and (ii) recognize if the identified style reappears in\ngenerated images. We leverage two complementary methods to perform artistic\nstyle classification over image sets, includingTagMatch, which is a novel\ninherently interpretable and attributable method, making it more suitable for\nbroader use by non-technical stake holders (artists, lawyers, judges, etc).\nLeveraging ArtSavant, we then perform a large-scale empirical study to provide\nquantitative insight on the prevalence of artistic style copying across 3\npopular text-to-image generative models. Namely, amongst a dataset of prolific\nartists (including many famous ones), only 20% of them appear to have their\nstyles be at a risk of copying via simple prompting of today's popular\ntext-to-image generative models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08030v1",
    "published_date": "2024-04-11 17:59:43 UTC",
    "updated_date": "2024-04-11 17:59:43 UTC"
  },
  {
    "arxiv_id": "2404.07987v4",
    "title": "ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback",
    "authors": [
      "Ming Li",
      "Taojiannan Yang",
      "Huafeng Kuang",
      "Jie Wu",
      "Zhaoning Wang",
      "Xuefeng Xiao",
      "Chen Chen"
    ],
    "abstract": "To enhance the controllability of text-to-image diffusion models, existing\nefforts like ControlNet incorporated image-based conditional controls. In this\npaper, we reveal that existing methods still face significant challenges in\ngenerating images that align with the image conditional controls. To this end,\nwe propose ControlNet++, a novel approach that improves controllable generation\nby explicitly optimizing pixel-level cycle consistency between generated images\nand conditional controls. Specifically, for an input conditional control, we\nuse a pre-trained discriminative reward model to extract the corresponding\ncondition of the generated images, and then optimize the consistency loss\nbetween the input conditional control and extracted condition. A\nstraightforward implementation would be generating images from random noises\nand then calculating the consistency loss, but such an approach requires\nstoring gradients for multiple sampling timesteps, leading to considerable time\nand memory costs. To address this, we introduce an efficient reward strategy\nthat deliberately disturbs the input images by adding noise, and then uses the\nsingle-step denoised images for reward fine-tuning. This avoids the extensive\ncosts associated with image sampling, allowing for more efficient reward\nfine-tuning. Extensive experiments show that ControlNet++ significantly\nimproves controllability under various conditional controls. For example, it\nachieves improvements over ControlNet by 11.1% mIoU, 13.4% SSIM, and 7.6% RMSE,\nrespectively, for segmentation mask, line-art edge, and depth conditions. All\nthe code, models, demo and organized data have been open sourced on our Github\nRepo.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Camera Ready Version. Project Page:\n  https://liming-ai.github.io/ControlNet_Plus_Plus Code & Data:\n  https://github.com/liming-ai/ControlNet_Plus_Plus",
    "pdf_url": "http://arxiv.org/pdf/2404.07987v4",
    "published_date": "2024-04-11 17:59:09 UTC",
    "updated_date": "2024-11-19 03:23:20 UTC"
  },
  {
    "arxiv_id": "2404.07981v2",
    "title": "Manipulating Large Language Models to Increase Product Visibility",
    "authors": [
      "Aounon Kumar",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Large language models (LLMs) are increasingly being integrated into search\nengines to provide natural language responses tailored to user queries.\nCustomers and end-users are also becoming more dependent on these models for\nquick and easy purchase decisions. In this work, we investigate whether\nrecommendations from LLMs can be manipulated to enhance a product's visibility.\nWe demonstrate that adding a strategic text sequence (STS) -- a carefully\ncrafted message -- to a product's information page can significantly increase\nits likelihood of being listed as the LLM's top recommendation. To understand\nthe impact of STS, we use a catalog of fictitious coffee machines and analyze\nits effect on two target products: one that seldom appears in the LLM's\nrecommendations and another that usually ranks second. We observe that the\nstrategic text sequence significantly enhances the visibility of both products\nby increasing their chances of appearing as the top recommendation. This\nability to manipulate LLM-generated search responses provides vendors with a\nconsiderable competitive advantage and has the potential to disrupt fair market\ncompetition. Just as search engine optimization (SEO) revolutionized how\nwebpages are customized to rank higher in search engine results, influencing\nLLM recommendations could profoundly impact content optimization for AI-driven\nsearch services. Code for our experiments is available at\nhttps://github.com/aounon/llm-rank-optimizer.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07981v2",
    "published_date": "2024-04-11 17:57:32 UTC",
    "updated_date": "2024-09-02 21:29:04 UTC"
  },
  {
    "arxiv_id": "2404.07979v2",
    "title": "LLoCO: Learning Long Contexts Offline",
    "authors": [
      "Sijun Tan",
      "Xiuyu Li",
      "Shishir Patil",
      "Ziyang Wu",
      "Tianjun Zhang",
      "Kurt Keutzer",
      "Joseph E. Gonzalez",
      "Raluca Ada Popa"
    ],
    "abstract": "Processing long contexts remains a challenge for large language models (LLMs)\ndue to the quadratic computational and memory overhead of the self-attention\nmechanism and the substantial KV cache sizes during generation. We propose\nLLoCO, a novel approach to address this problem by learning contexts offline\nthrough context compression and in-domain parameter-efficient finetuning with\nLoRA. Our method enables an LLM to create a concise representation of the\noriginal context and efficiently retrieve relevant information to answer\nquestions accurately. Our approach extends the effective context window of a 4k\ntoken LLaMA2-7B model to handle up to 128k tokens. We evaluate our approach on\nseveral long-context question-answering datasets, demonstrating that LLoCO\nsignificantly outperforms in-context learning while using $30\\times$ fewer\ntokens during inference. LLoCO achieves up to $7.62\\times$ speed-up during\ninference and $11.52\\times$ higher throughput during finetuning, substantially\nreduces the cost of long document question answering. This makes it a promising\nsolution for efficient long context processing. Our code is publicly available\non https://github.com/jeffreysijuntan/lloco.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024. The first two authors contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2404.07979v2",
    "published_date": "2024-04-11 17:57:22 UTC",
    "updated_date": "2024-10-17 08:54:37 UTC"
  },
  {
    "arxiv_id": "2404.07976v1",
    "title": "Self-supervised Dataset Distillation: A Good Compression Is All You Need",
    "authors": [
      "Muxin Zhou",
      "Zeyuan Yin",
      "Shitong Shao",
      "Zhiqiang Shen"
    ],
    "abstract": "Dataset distillation aims to compress information from a large-scale original\ndataset to a new compact dataset while striving to preserve the utmost degree\nof the original data informational essence. Previous studies have predominantly\nconcentrated on aligning the intermediate statistics between the original and\ndistilled data, such as weight trajectory, features, gradient, BatchNorm, etc.\nIn this work, we consider addressing this task through the new lens of model\ninformativeness in the compression stage on the original dataset pretraining.\nWe observe that with the prior state-of-the-art SRe$^2$L, as model sizes\nincrease, it becomes increasingly challenging for supervised pretrained models\nto recover learned information during data synthesis, as the channel-wise mean\nand variance inside the model are flatting and less informative. We further\nnotice that larger variances in BN statistics from self-supervised models\nenable larger loss signals to update the recovered data by gradients, enjoying\nmore informativeness during synthesis. Building on this observation, we\nintroduce SC-DD, a simple yet effective Self-supervised Compression framework\nfor Dataset Distillation that facilitates diverse information compression and\nrecovery compared to traditional supervised learning schemes, further reaps the\npotential of large pretrained models with enhanced capabilities. Extensive\nexperiments are conducted on CIFAR-100, Tiny-ImageNet and ImageNet-1K datasets\nto demonstrate the superiority of our proposed approach. The proposed SC-DD\noutperforms all previous state-of-the-art supervised dataset distillation\nmethods when employing larger models, such as SRe$^2$L, MTT, TESLA, DC, CAFE,\netc., by large margins under the same recovery and post-training budgets. Code\nis available at https://github.com/VILA-Lab/SRe2L/tree/main/SCDD/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07976v1",
    "published_date": "2024-04-11 17:56:40 UTC",
    "updated_date": "2024-04-11 17:56:40 UTC"
  },
  {
    "arxiv_id": "2404.07972v2",
    "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
    "authors": [
      "Tianbao Xie",
      "Danyang Zhang",
      "Jixuan Chen",
      "Xiaochuan Li",
      "Siheng Zhao",
      "Ruisheng Cao",
      "Toh Jing Hua",
      "Zhoujun Cheng",
      "Dongchan Shin",
      "Fangyu Lei",
      "Yitao Liu",
      "Yiheng Xu",
      "Shuyan Zhou",
      "Silvio Savarese",
      "Caiming Xiong",
      "Victor Zhong",
      "Tao Yu"
    ],
    "abstract": "Autonomous agents that accomplish complex computer tasks with minimal human\ninterventions have the potential to transform human-computer interaction,\nsignificantly enhancing accessibility and productivity. However, existing\nbenchmarks either lack an interactive environment or are limited to\nenvironments specific to certain applications or domains, failing to reflect\nthe diverse and complex nature of real-world computer use, thereby limiting the\nscope of tasks and agent scalability. To address this issue, we introduce\nOSWorld, the first-of-its-kind scalable, real computer environment for\nmultimodal agents, supporting task setup, execution-based evaluation, and\ninteractive learning across various operating systems such as Ubuntu, Windows,\nand macOS. OSWorld can serve as a unified, integrated computer environment for\nassessing open-ended computer tasks that involve arbitrary applications.\nBuilding upon OSWorld, we create a benchmark of 369 computer tasks involving\nreal web and desktop apps in open domains, OS file I/O, and workflows spanning\nmultiple applications. Each task example is derived from real-world computer\nuse cases and includes a detailed initial state setup configuration and a\ncustom execution-based evaluation script for reliable, reproducible evaluation.\nExtensive evaluation of state-of-the-art LLM/VLM-based agents on OSWorld\nreveals significant deficiencies in their ability to serve as computer\nassistants. While humans can accomplish over 72.36% of the tasks, the best\nmodel achieves only 12.24% success, primarily struggling with GUI grounding and\noperational knowledge. Comprehensive analysis using OSWorld provides valuable\ninsights for developing multimodal generalist agents that were not possible\nwith previous benchmarks. Our code, environment, baseline models, and data are\npublicly available at https://os-world.github.io.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "51 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.07972v2",
    "published_date": "2024-04-11 17:56:05 UTC",
    "updated_date": "2024-05-30 08:55:12 UTC"
  },
  {
    "arxiv_id": "2404.07965v4",
    "title": "Rho-1: Not All Tokens Are What You Need",
    "authors": [
      "Zhenghao Lin",
      "Zhibin Gou",
      "Yeyun Gong",
      "Xiao Liu",
      "Yelong Shen",
      "Ruochen Xu",
      "Chen Lin",
      "Yujiu Yang",
      "Jian Jiao",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "abstract": "Previous language model pre-training methods have uniformly applied a\nnext-token prediction loss to all training tokens. Challenging this norm, we\nposit that \"9l training\". Our initial analysis examines token-level training\ndynamics of language model, revealing distinct loss patterns for different\ntokens. Leveraging these insights, we introduce a new language model called\nRho-1. Unlike traditional LMs that learn to predict every next token in a\ncorpus, Rho-1 employs Selective Language Modeling (SLM), which selectively\ntrains on useful tokens that aligned with the desired distribution. This\napproach involves scoring pretraining tokens using a reference model, and then\ntraining the language model with a focused loss on tokens with higher scores.\nWhen continual pretraining on 15B OpenWebMath corpus, Rho-1 yields an absolute\nimprovement in few-shot accuracy of up to 30% in 9 math tasks. After\nfine-tuning, Rho-1-1B and 7B achieved state-of-the-art results of 40.6% and\n51.8% on MATH dataset, respectively - matching DeepSeekMath with only 3% of the\npretraining tokens. Furthermore, when continual pretraining on 80B general\ntokens, Rho-1 achieves 6.8% average enhancement across 15 diverse tasks,\nincreasing both efficiency and performance of the language model pre-training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "First two authors equal contribution",
    "pdf_url": "http://arxiv.org/pdf/2404.07965v4",
    "published_date": "2024-04-11 17:52:01 UTC",
    "updated_date": "2025-01-08 09:07:54 UTC"
  },
  {
    "arxiv_id": "2404.07956v2",
    "title": "Lyapunov-stable Neural Control for State and Output Feedback: A Novel Formulation",
    "authors": [
      "Lujie Yang",
      "Hongkai Dai",
      "Zhouxing Shi",
      "Cho-Jui Hsieh",
      "Russ Tedrake",
      "Huan Zhang"
    ],
    "abstract": "Learning-based neural network (NN) control policies have shown impressive\nempirical performance in a wide range of tasks in robotics and control.\nHowever, formal (Lyapunov) stability guarantees over the region-of-attraction\n(ROA) for NN controllers with nonlinear dynamical systems are challenging to\nobtain, and most existing approaches rely on expensive solvers such as\nsums-of-squares (SOS), mixed-integer programming (MIP), or satisfiability\nmodulo theories (SMT). In this paper, we demonstrate a new framework for\nlearning NN controllers together with Lyapunov certificates using fast\nempirical falsification and strategic regularizations. We propose a novel\nformulation that defines a larger verifiable region-of-attraction (ROA) than\nshown in the literature, and refines the conventional restrictive constraints\non Lyapunov derivatives to focus only on certifiable ROAs. The Lyapunov\ncondition is rigorously verified post-hoc using branch-and-bound with scalable\nlinear bound propagation-based NN verification techniques. The approach is\nefficient and flexible, and the full training and verification procedure is\naccelerated on GPUs without relying on expensive solvers for SOS, MIP, nor SMT.\nThe flexibility and efficiency of our framework allow us to demonstrate\nLyapunov-stable output feedback control with synthesized NN-based controllers\nand NN-based observers with formal stability guarantees, for the first time in\nliterature. Source code at\nhttps://github.com/Verified-Intelligence/Lyapunov_Stable_NN_Controllers",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07956v2",
    "published_date": "2024-04-11 17:49:15 UTC",
    "updated_date": "2024-06-05 00:30:57 UTC"
  },
  {
    "arxiv_id": "2404.08707v7",
    "title": "CEM: A Data-Efficient Method for Large Language Models to Continue Evolving From Mistakes",
    "authors": [
      "Haokun Zhao",
      "Haixia Han",
      "Jie Shi",
      "Chengyu Du",
      "Jiaqing Liang",
      "Yanghua Xiao"
    ],
    "abstract": "As world knowledge advances and new task schemas emerge, Continual Learning\n(CL) becomes essential for keeping Large Language Models (LLMs) current and\naddressing their shortcomings. This process typically involves continual\ninstruction tuning (CIT) and continual pre-training (CPT) to enable these\nmodels to adapt to novel tasks and acquire critical knowledge. However,\ncollecting sufficient CPT data and efficiently bridging knowledge gaps remain\nsignificant challenges. Inspired by the 'summarizing mistakes' strategy, we\npropose the Continue Evolving from Mistakes (CEM) method, a data-efficient\napproach aiming to collect CPT data and continually improve LLMs' performance\nthrough iterative evaluation and supplementation with mistake-relevant\nknowledge. To further optimize data usage and mitigate forgetting, we introduce\na novel training paradigm that combines CIT and CPT. Experiments show that CEM\nsubstantially enhances multiple models' performance on both in-domain and\nout-of-domain QA tasks, achieving gains of up to 29.63%. Code and datasets are\navailable on https://anonymous.4open.science/r/cem-BB25.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08707v7",
    "published_date": "2024-04-11 17:44:56 UTC",
    "updated_date": "2024-12-16 11:21:30 UTC"
  },
  {
    "arxiv_id": "2404.07942v2",
    "title": "On Unified Prompt Tuning for Request Quality Assurance in Public Code Review",
    "authors": [
      "Xinyu Chen",
      "Lin Li",
      "Rui Zhang",
      "Peng Liang"
    ],
    "abstract": "Public Code Review (PCR) can be implemented through a Software Question\nAnswering (SQA) community, which facilitates high knowledge dissemination.\nCurrent methods mainly focus on the reviewer's perspective, including finding a\ncapable reviewer, predicting comment quality, and recommending/generating\nreview comments. Our intuition is that satisfying review necessity requests can\nincrease their visibility, which in turn is a prerequisite for better review\nresponses. To this end, we propose a unified framework called UniPCR to\ncomplete developer-based request quality assurance (i.e., predicting request\nnecessity and recommending tags subtask) under a Masked Language Model (MLM).\nSpecifically, we reformulate both subtasks via 1) text prompt tuning, which\nconverts two subtasks into MLM by constructing prompt templates using hard\nprompt; 2) code prefix tuning, which optimizes a small segment of generated\ncontinuous vectors as the prefix of the code representation using soft prompt.\nExperimental results on the Public Code Review dataset for the time span\n2011-2022 demonstrate that our UniPCR framework adapts to the two subtasks and\noutperforms comparable accuracy-based results with state-of-the-art methods for\nrequest quality assurance. These conclusions highlight the effectiveness of our\nunified framework from the developer's perspective in public code review.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "The 29th International Conference on Database Systems for Advanced\n  Applications (DASFAA)",
    "pdf_url": "http://arxiv.org/pdf/2404.07942v2",
    "published_date": "2024-04-11 17:41:28 UTC",
    "updated_date": "2024-04-17 14:04:50 UTC"
  },
  {
    "arxiv_id": "2404.07934v1",
    "title": "Goal Recognition via Linear Programming",
    "authors": [
      "Felipe Meneguzzi",
      "Luísa R. de A. Santos",
      "Ramon Fraga Pereira",
      "André G. Pereira"
    ],
    "abstract": "Goal Recognition is the task by which an observer aims to discern the goals\nthat correspond to plans that comply with the perceived behavior of subject\nagents given as a sequence of observations. Research on Goal Recognition as\nPlanning encompasses reasoning about the model of a planning task, the\nobservations, and the goals using planning techniques, resulting in very\nefficient recognition approaches. In this article, we design novel recognition\napproaches that rely on the Operator-Counting framework, proposing new\nconstraints, and analyze their constraints' properties both theoretically and\nempirically. The Operator-Counting framework is a technique that efficiently\ncomputes heuristic estimates of cost-to-goal using Integer/Linear Programming\n(IP/LP). In the realm of theory, we prove that the new constraints provide\nlower bounds on the cost of plans that comply with observations. We also\nprovide an extensive empirical evaluation to assess how the new constraints\nimprove the quality of the solution, and we found that they are especially\ninformed in deciding which goals are unlikely to be part of the solution. Our\nnovel recognition approaches have two pivotal advantages: first, they employ\nnew IP/LP constraints for efficiently recognizing goals; second, we show how\nthe new IP/LP constraints can improve the recognition of goals under both\npartial and noisy observability.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to JAIR April 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07934v1",
    "published_date": "2024-04-11 17:34:35 UTC",
    "updated_date": "2024-04-11 17:34:35 UTC"
  },
  {
    "arxiv_id": "2404.07930v1",
    "title": "Parameter Hierarchical Optimization for Visible-Infrared Person Re-Identification",
    "authors": [
      "Zeng YU",
      "Yunxiao Shi"
    ],
    "abstract": "Visible-infrared person re-identification (VI-reID) aims at matching\ncross-modality pedestrian images captured by disjoint visible or infrared\ncameras. Existing methods alleviate the cross-modality discrepancies via\ndesigning different kinds of network architectures. Different from available\nmethods, in this paper, we propose a novel parameter optimizing paradigm,\nparameter hierarchical optimization (PHO) method, for the task of VI-ReID. It\nallows part of parameters to be directly optimized without any training, which\nnarrows the search space of parameters and makes the whole network more easier\nto be trained. Specifically, we first divide the parameters into different\ntypes, and then introduce a self-adaptive alignment strategy (SAS) to\nautomatically align the visible and infrared images through transformation.\nConsidering that features in different dimension have varying importance, we\ndevelop an auto-weighted alignment learning (AAL) module that can automatically\nweight features according to their importance. Importantly, in the alignment\nprocess of SAS and AAL, all the parameters are immediately optimized with\noptimization principles rather than training the whole network, which yields a\nbetter parameter training manner. Furthermore, we establish the cross-modality\nconsistent learning (CCL) loss to extract discriminative person representations\nwith translation consistency. We provide both theoretical justification and\nempirical evidence that our proposed PHO method outperform existing VI-reID\napproaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07930v1",
    "published_date": "2024-04-11 17:27:39 UTC",
    "updated_date": "2024-04-11 17:27:39 UTC"
  },
  {
    "arxiv_id": "2404.07926v1",
    "title": "Leveraging Large Language Models (LLMs) to Support Collaborative Human-AI Online Risk Data Annotation",
    "authors": [
      "Jinkyung Park",
      "Pamela Wisniewski",
      "Vivek Singh"
    ],
    "abstract": "In this position paper, we discuss the potential for leveraging LLMs as\ninteractive research tools to facilitate collaboration between human coders and\nAI to effectively annotate online risk data at scale. Collaborative human-AI\nlabeling is a promising approach to annotating large-scale and complex data for\nvarious tasks. Yet, tools and methods to support effective human-AI\ncollaboration for data annotation are under-studied. This gap is pertinent\nbecause co-labeling tasks need to support a two-way interactive discussion that\ncan add nuance and context, particularly in the context of online risk, which\nis highly subjective and contextualized. Therefore, we provide some of the\nearly benefits and challenges of using LLMs-based tools for risk annotation and\nsuggest future directions for the HCI research community to leverage LLMs as\nresearch tools to facilitate human-AI collaboration in contextualized online\ndata annotation. Our research interests align very well with the purposes of\nthe LLMs as Research Tools workshop to identify ongoing applications and\nchallenges of using LLMs to work with data in HCI research. We anticipate\nlearning valuable insights from organizers and participants into how LLMs can\nhelp reshape the HCI community's methods for working with data.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "This paper has been peer-reviewed and presented at the \"CHI 2024\n  Workshop on LLMs as Research Tools: Applications and Evaluations in HCI Data\n  Work, May 12, 2024, Honolulu, HI, USA.\"",
    "pdf_url": "http://arxiv.org/pdf/2404.07926v1",
    "published_date": "2024-04-11 17:20:57 UTC",
    "updated_date": "2024-04-11 17:20:57 UTC"
  },
  {
    "arxiv_id": "2404.07919v1",
    "title": "Low-rank Adaptation for Spatio-Temporal Forecasting",
    "authors": [
      "Weilin Ruan",
      "Wei Chen",
      "Xilin Dang",
      "Jianxiang Zhou",
      "Weichuang Li",
      "Xu Liu",
      "Yuxuan Liang"
    ],
    "abstract": "Spatio-temporal forecasting is crucial in real-world dynamic systems,\npredicting future changes using historical data from diverse locations.\nExisting methods often prioritize the development of intricate neural networks\nto capture the complex dependencies of the data, yet their accuracy fails to\nshow sustained improvement. Besides, these methods also overlook node\nheterogeneity, hindering customized prediction modules from handling diverse\nregional nodes effectively. In this paper, our goal is not to propose a new\nmodel but to present a novel low-rank adaptation framework as an off-the-shelf\nplugin for existing spatial-temporal prediction models, termed ST-LoRA, which\nalleviates the aforementioned problems through node-level adjustments.\nSpecifically, we first tailor a node adaptive low-rank layer comprising\nmultiple trainable low-rank matrices. Additionally, we devise a multi-layer\nresidual fusion stacking module, injecting the low-rank adapters into predictor\nmodules of various models. Across six real-world traffic datasets and six\ndifferent types of spatio-temporal prediction models, our approach minimally\nincreases the parameters and training time of the original models by less than\n4%, still achieving consistent and sustained performance enhancement.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07919v1",
    "published_date": "2024-04-11 17:04:55 UTC",
    "updated_date": "2024-04-11 17:04:55 UTC"
  },
  {
    "arxiv_id": "2405.01567v2",
    "title": "CodeFort: Robust Training for Code Generation Models",
    "authors": [
      "Yuhao Zhang",
      "Shiqi Wang",
      "Haifeng Qian",
      "Zijian Wang",
      "Mingyue Shang",
      "Linbo Liu",
      "Sanjay Krishna Gouda",
      "Baishakhi Ray",
      "Murali Krishna Ramanathan",
      "Xiaofei Ma",
      "Anoop Deoras"
    ],
    "abstract": "Code generation models are not robust to small perturbations, which often\nlead to incorrect generations and significantly degrade the performance of\nthese models. Although improving the robustness of code generation models is\ncrucial to enhancing user experience in real-world applications, existing\nresearch efforts do not address this issue. To fill this gap, we propose\nCodeFort, a framework to improve the robustness of code generation models,\ngeneralizing a large variety of code perturbations to enrich the training data\nand enabling various robust training strategies, mixing data augmentation,\nbatch augmentation, adversarial logits pairing, and contrastive learning, all\ncarefully designed to support high-throughput training. Extensive evaluations\nshow that we increase the average robust pass rates of baseline CodeGen models\nfrom 14.79 to 21.74. We notably decrease the robustness drop rate from 95.02%\nto 54.95% against code-syntax perturbations.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.01567v2",
    "published_date": "2024-04-11 17:04:22 UTC",
    "updated_date": "2024-10-28 19:29:57 UTC"
  },
  {
    "arxiv_id": "2404.07917v2",
    "title": "DesignQA: A Multimodal Benchmark for Evaluating Large Language Models' Understanding of Engineering Documentation",
    "authors": [
      "Anna C. Doris",
      "Daniele Grandi",
      "Ryan Tomich",
      "Md Ferdous Alam",
      "Mohammadmehdi Ataei",
      "Hyunmin Cheong",
      "Faez Ahmed"
    ],
    "abstract": "This research introduces DesignQA, a novel benchmark aimed at evaluating the\nproficiency of multimodal large language models (MLLMs) in comprehending and\napplying engineering requirements in technical documentation. Developed with a\nfocus on real-world engineering challenges, DesignQA uniquely combines\nmultimodal data-including textual design requirements, CAD images, and\nengineering drawings-derived from the Formula SAE student competition.\nDifferent from many existing MLLM benchmarks, DesignQA contains\ndocument-grounded visual questions where the input image and input document\ncome from different sources. The benchmark features automatic evaluation\nmetrics and is divided into segments-Rule Comprehension, Rule Compliance, and\nRule Extraction-based on tasks that engineers perform when designing according\nto requirements. We evaluate state-of-the-art models (at the time of writing)\nlike GPT-4o, GPT-4, Claude-Opus, Gemini-1.0, and LLaVA-1.5 against the\nbenchmark, and our study uncovers the existing gaps in MLLMs' abilities to\ninterpret complex engineering documentation. The MLLMs tested, while promising,\nstruggle to reliably retrieve relevant rules from the Formula SAE\ndocumentation, face challenges in recognizing technical components in CAD\nimages, and encounter difficulty in analyzing engineering drawings. These\nfindings underscore the need for multimodal models that can better handle the\nmultifaceted questions characteristic of design according to technical\ndocumentation. This benchmark sets a foundation for future advancements in\nAI-supported engineering design processes. DesignQA is publicly available at:\nhttps://github.com/anniedoris/design_qa/.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07917v2",
    "published_date": "2024-04-11 16:59:54 UTC",
    "updated_date": "2024-08-23 17:19:18 UTC"
  },
  {
    "arxiv_id": "2404.08029v1",
    "title": "A Multi-Expert Large Language Model Architecture for Verilog Code Generation",
    "authors": [
      "Bardia Nadimi",
      "Hao Zheng"
    ],
    "abstract": "Recently, there has been a surging interest in using large language models\n(LLMs) for Verilog code generation. However, the existing approaches are\nlimited in terms of the quality of the generated Verilog code. To address such\nlimitations, this paper introduces an innovative multi-expert LLM architecture\nfor Verilog code generation (MEV-LLM). Our architecture uniquely integrates\nmultiple LLMs, each specifically fine-tuned with a dataset that is categorized\nwith respect to a distinct level of design complexity. It allows more targeted\nlearning, directly addressing the nuances of generating Verilog code for each\ncategory. Empirical evidence from experiments highlights notable improvements\nin terms of the percentage of generated Verilog outputs that are syntactically\nand functionally correct. These findings underscore the efficacy of our\napproach, promising a forward leap in the field of automated hardware design\nthrough machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08029v1",
    "published_date": "2024-04-11 16:58:29 UTC",
    "updated_date": "2024-04-11 16:58:29 UTC"
  },
  {
    "arxiv_id": "2404.17586v1",
    "title": "The Future of Scientific Publishing: Automated Article Generation",
    "authors": [
      "Jeremy R. Harper"
    ],
    "abstract": "This study introduces a novel software tool leveraging large language model\n(LLM) prompts, designed to automate the generation of academic articles from\nPython code a significant advancement in the fields of biomedical informatics\nand computer science. Selected for its widespread adoption and analytical\nversatility, Python served as a foundational proof of concept; however, the\nunderlying methodology and framework exhibit adaptability across various GitHub\nrepo's underlining the tool's broad applicability (Harper 2024). By mitigating\nthe traditionally time-intensive academic writing process, particularly in\nsynthesizing complex datasets and coding outputs, this approach signifies a\nmonumental leap towards streamlining research dissemination. The development\nwas achieved without reliance on advanced language model agents, ensuring high\nfidelity in the automated generation of coherent and comprehensive academic\ncontent. This exploration not only validates the successful application and\nefficiency of the software but also projects how future integration of LLM\nagents which could amplify its capabilities, propelling towards a future where\nscientific findings are disseminated more swiftly and accessibly.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "Keywords: automated academic writing, Python code, software tool,\n  article generation, natural language processing, scholarly publishing, code\n  analysis, academic article automation, research dissemination, programming\n  and publishing integration",
    "pdf_url": "http://arxiv.org/pdf/2404.17586v1",
    "published_date": "2024-04-11 16:47:02 UTC",
    "updated_date": "2024-04-11 16:47:02 UTC"
  },
  {
    "arxiv_id": "2404.07900v4",
    "title": "High-Dimension Human Value Representation in Large Language Models",
    "authors": [
      "Samuel Cahyawijaya",
      "Delong Chen",
      "Yejin Bang",
      "Leila Khalatbari",
      "Bryan Wilie",
      "Ziwei Ji",
      "Etsuko Ishii",
      "Pascale Fung"
    ],
    "abstract": "The widespread application of LLMs across various tasks and fields has\nnecessitated the alignment of these models with human values and preferences.\nGiven various approaches of human value alignment, there is an urgent need to\nunderstand the scope and nature of human values injected into these LLMs before\ntheir deployment and adoption. We propose UniVaR, a high-dimensional neural\nrepresentation of symbolic human value distributions in LLMs, orthogonal to\nmodel architecture and training data. This is a continuous and scalable\nrepresentation, self-supervised from the value-relevant output of 8 LLMs and\nevaluated on 15 open-source and commercial LLMs. Through UniVaR, we visualize\nand explore how LLMs prioritize different values in 25 languages and cultures,\nshedding light on complex interplay between human values and language modeling.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07900v4",
    "published_date": "2024-04-11 16:39:00 UTC",
    "updated_date": "2025-03-25 22:02:36 UTC"
  },
  {
    "arxiv_id": "2404.07883v1",
    "title": "Apprentice Tutor Builder: A Platform For Users to Create and Personalize Intelligent Tutors",
    "authors": [
      "Glen Smith",
      "Adit Gupta",
      "Christopher MacLellan"
    ],
    "abstract": "Intelligent tutoring systems (ITS) are effective for improving students'\nlearning outcomes. However, their development is often complex, time-consuming,\nand requires specialized programming and tutor design knowledge, thus hindering\ntheir widespread application and personalization. We present the Apprentice\nTutor Builder (ATB) , a platform that simplifies tutor creation and\npersonalization. Instructors can utilize ATB's drag-and-drop tool to build\ntutor interfaces. Instructors can then interactively train the tutors'\nunderlying AI agent to produce expert models that can solve problems. Training\nis achieved via using multiple interaction modalities including demonstrations,\nfeedback, and user labels. We conducted a user study with 14 instructors to\nevaluate the effectiveness of ATB's design with end users. We found that users\nenjoyed the flexibility of the interface builder and ease and speed of agent\nteaching, but often desired additional time-saving features. With these\ninsights, we identified a set of design recommendations for our platform and\nothers that utilize interactive AI agents for tutor creation and customization.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07883v1",
    "published_date": "2024-04-11 16:14:23 UTC",
    "updated_date": "2024-04-11 16:14:23 UTC"
  },
  {
    "arxiv_id": "2404.08027v2",
    "title": "SurvMamba: State Space Model with Multi-grained Multi-modal Interaction for Survival Prediction",
    "authors": [
      "Ying Chen",
      "Jiajing Xie",
      "Yuxiang Lin",
      "Yuhang Song",
      "Wenxian Yang",
      "Rongshan Yu"
    ],
    "abstract": "Multi-modal learning that combines pathological images with genomic data has\nsignificantly enhanced the accuracy of survival prediction. Nevertheless,\nexisting methods have not fully utilized the inherent hierarchical structure\nwithin both whole slide images (WSIs) and transcriptomic data, from which\nbetter intra-modal representations and inter-modal integration could be\nderived. Moreover, many existing studies attempt to improve multi-modal\nrepresentations through attention mechanisms, which inevitably lead to high\ncomplexity when processing high-dimensional WSIs and transcriptomic data.\nRecently, a structured state space model named Mamba emerged as a promising\napproach for its superior performance in modeling long sequences with low\ncomplexity. In this study, we propose Mamba with multi-grained multi-modal\ninteraction (SurvMamba) for survival prediction. SurvMamba is implemented with\na Hierarchical Interaction Mamba (HIM) module that facilitates efficient\nintra-modal interactions at different granularities, thereby capturing more\ndetailed local features as well as rich global representations. In addition, an\nInteraction Fusion Mamba (IFM) module is used for cascaded inter-modal\ninteractive fusion, yielding more comprehensive features for survival\nprediction. Comprehensive evaluations on five TCGA datasets demonstrate that\nSurvMamba outperforms other existing methods in terms of performance and\ncomputational cost.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08027v2",
    "published_date": "2024-04-11 15:58:12 UTC",
    "updated_date": "2024-12-04 02:57:03 UTC"
  },
  {
    "arxiv_id": "2404.07851v1",
    "title": "Guiding Large Language Models to Post-Edit Machine Translation with Error Annotations",
    "authors": [
      "Dayeon Ki",
      "Marine Carpuat"
    ],
    "abstract": "Machine Translation (MT) remains one of the last NLP tasks where large\nlanguage models (LLMs) have not yet replaced dedicated supervised systems. This\nwork exploits the complementary strengths of LLMs and supervised MT by guiding\nLLMs to automatically post-edit MT with external feedback on its quality,\nderived from Multidimensional Quality Metric (MQM) annotations. Working with\nLLaMA-2 models, we consider prompting strategies varying the nature of feedback\nprovided and then fine-tune the LLM to improve its ability to exploit the\nprovided guidance. Through experiments on Chinese-English, English-German, and\nEnglish-Russian MQM data, we demonstrate that prompting LLMs to post-edit MT\nimproves TER, BLEU and COMET scores, although the benefits of fine-grained\nfeedback are not clear. Fine-tuning helps integrate fine-grained feedback more\neffectively and further improves translation quality based on both automatic\nand human evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.07851v1",
    "published_date": "2024-04-11 15:47:10 UTC",
    "updated_date": "2024-04-11 15:47:10 UTC"
  },
  {
    "arxiv_id": "2404.07850v1",
    "title": "MindBridge: A Cross-Subject Brain Decoding Framework",
    "authors": [
      "Shizun Wang",
      "Songhua Liu",
      "Zhenxiong Tan",
      "Xinchao Wang"
    ],
    "abstract": "Brain decoding, a pivotal field in neuroscience, aims to reconstruct stimuli\nfrom acquired brain signals, primarily utilizing functional magnetic resonance\nimaging (fMRI). Currently, brain decoding is confined to a\nper-subject-per-model paradigm, limiting its applicability to the same\nindividual for whom the decoding model is trained. This constraint stems from\nthree key challenges: 1) the inherent variability in input dimensions across\nsubjects due to differences in brain size; 2) the unique intrinsic neural\npatterns, influencing how different individuals perceive and process sensory\ninformation; 3) limited data availability for new subjects in real-world\nscenarios hampers the performance of decoding models. In this paper, we present\na novel approach, MindBridge, that achieves cross-subject brain decoding by\nemploying only one model. Our proposed framework establishes a generic paradigm\ncapable of addressing these challenges by introducing biological-inspired\naggregation function and novel cyclic fMRI reconstruction mechanism for\nsubject-invariant representation learning. Notably, by cycle reconstruction of\nfMRI, MindBridge can enable novel fMRI synthesis, which also can serve as\npseudo data augmentation. Within the framework, we also devise a novel\nreset-tuning method for adapting a pretrained model to a new subject.\nExperimental results demonstrate MindBridge's ability to reconstruct images for\nmultiple subjects, which is competitive with dedicated subject-specific models.\nFurthermore, with limited data for a new subject, we achieve a high level of\ndecoding accuracy, surpassing that of subject-specific models. This advancement\nin cross-subject brain decoding suggests promising directions for wider\napplications in neuroscience and indicates potential for more efficient\nutilization of limited fMRI data in real-world scenarios. Project page:\nhttps://littlepure2333.github.io/MindBridge",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024 highlight. Code is available at\n  https://github.com/littlepure2333/MindBridge",
    "pdf_url": "http://arxiv.org/pdf/2404.07850v1",
    "published_date": "2024-04-11 15:46:42 UTC",
    "updated_date": "2024-04-11 15:46:42 UTC"
  },
  {
    "arxiv_id": "2404.07839v2",
    "title": "RecurrentGemma: Moving Past Transformers for Efficient Open Language Models",
    "authors": [
      "Aleksandar Botev",
      "Soham De",
      "Samuel L Smith",
      "Anushan Fernando",
      "George-Cristian Muraru",
      "Ruba Haroun",
      "Leonard Berrada",
      "Razvan Pascanu",
      "Pier Giuseppe Sessa",
      "Robert Dadashi",
      "Léonard Hussenot",
      "Johan Ferret",
      "Sertan Girgin",
      "Olivier Bachem",
      "Alek Andreev",
      "Kathleen Kenealy",
      "Thomas Mesnard",
      "Cassidy Hardin",
      "Surya Bhupatiraju",
      "Shreya Pathak",
      "Laurent Sifre",
      "Morgane Rivière",
      "Mihir Sanjay Kale",
      "Juliette Love",
      "Pouya Tafti",
      "Armand Joulin",
      "Noah Fiedel",
      "Evan Senter",
      "Yutian Chen",
      "Srivatsan Srinivasan",
      "Guillaume Desjardins",
      "David Budden",
      "Arnaud Doucet",
      "Sharad Vikram",
      "Adam Paszke",
      "Trevor Gale",
      "Sebastian Borgeaud",
      "Charlie Chen",
      "Andy Brock",
      "Antonia Paterson",
      "Jenny Brennan",
      "Meg Risdal",
      "Raj Gundluru",
      "Nesh Devanathan",
      "Paul Mooney",
      "Nilay Chauhan",
      "Phil Culliton",
      "Luiz Gustavo Martins",
      "Elisa Bandy",
      "David Huntsperger",
      "Glenn Cameron",
      "Arthur Zucker",
      "Tris Warkentin",
      "Ludovic Peran",
      "Minh Giang",
      "Zoubin Ghahramani",
      "Clément Farabet",
      "Koray Kavukcuoglu",
      "Demis Hassabis",
      "Raia Hadsell",
      "Yee Whye Teh",
      "Nando de Frietas"
    ],
    "abstract": "We introduce RecurrentGemma, a family of open language models which uses\nGoogle's novel Griffin architecture. Griffin combines linear recurrences with\nlocal attention to achieve excellent performance on language. It has a\nfixed-sized state, which reduces memory use and enables efficient inference on\nlong sequences. We provide two sizes of models, containing 2B and 9B\nparameters, and provide pre-trained and instruction tuned variants for both.\nOur models achieve comparable performance to similarly-sized Gemma baselines\ndespite being trained on fewer tokens.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07839v2",
    "published_date": "2024-04-11 15:27:22 UTC",
    "updated_date": "2024-08-28 15:05:42 UTC"
  },
  {
    "arxiv_id": "2404.07826v1",
    "title": "On the Sample Efficiency of Abstractions and Potential-Based Reward Shaping in Reinforcement Learning",
    "authors": [
      "Giuseppe Canonaco",
      "Leo Ardon",
      "Alberto Pozanco",
      "Daniel Borrajo"
    ],
    "abstract": "The use of Potential Based Reward Shaping (PBRS) has shown great promise in\nthe ongoing research effort to tackle sample inefficiency in Reinforcement\nLearning (RL). However, the choice of the potential function is critical for\nthis technique to be effective. Additionally, RL techniques are usually\nconstrained to use a finite horizon for computational limitations. This\nintroduces a bias when using PBRS, thus adding an additional layer of\ncomplexity. In this paper, we leverage abstractions to automatically produce a\n\"good\" potential function. We analyse the bias induced by finite horizons in\nthe context of PBRS producing novel insights. Finally, to asses sample\nefficiency and performance impact, we evaluate our approach on four\nenvironments including a goal-oriented navigation task and three Arcade\nLearning Environments (ALE) games demonstrating that we can reach the same\nlevel of performance as CNN-based solutions with a simple fully-connected\nnetwork.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07826v1",
    "published_date": "2024-04-11 15:09:49 UTC",
    "updated_date": "2024-04-11 15:09:49 UTC"
  },
  {
    "arxiv_id": "2404.13060v1",
    "title": "The Necessity of AI Audit Standards Boards",
    "authors": [
      "David Manheim",
      "Sammy Martin",
      "Mark Bailey",
      "Mikhail Samin",
      "Ross Greutzmacher"
    ],
    "abstract": "Auditing of AI systems is a promising way to understand and manage ethical\nproblems and societal risks associated with contemporary AI systems, as well as\nsome anticipated future risks. Efforts to develop standards for auditing\nArtificial Intelligence (AI) systems have therefore understandably gained\nmomentum. However, we argue that creating auditing standards is not just\ninsufficient, but actively harmful by proliferating unheeded and inconsistent\nstandards, especially in light of the rapid evolution and ethical and safety\nchallenges of AI. Instead, the paper proposes the establishment of an AI Audit\nStandards Board, responsible for developing and updating auditing methods and\nstandards in line with the evolving nature of AI technologies. Such a body\nwould ensure that auditing practices remain relevant, robust, and responsive to\nthe rapid advancements in AI. The paper argues that such a governance structure\nwould also be helpful for maintaining public trust in AI and for promoting a\nculture of safety and ethical responsibility within the AI industry.\n  Throughout the paper, we draw parallels with other industries, including\nsafety-critical industries like aviation and nuclear energy, as well as more\nprosaic ones such as financial accounting and pharmaceuticals. AI auditing\nshould emulate those fields, and extend beyond technical assessments to include\nethical considerations and stakeholder engagement, but we explain that this is\nnot enough; emulating other fields' governance mechanisms for these processes,\nand for audit standards creation, is a necessity. We also emphasize the\nimportance of auditing the entire development process of AI systems, not just\nthe final products...",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4.1; K.6.4; K.5.2; I.2"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13060v1",
    "published_date": "2024-04-11 15:08:24 UTC",
    "updated_date": "2024-04-11 15:08:24 UTC"
  },
  {
    "arxiv_id": "2404.07817v2",
    "title": "Calibration of Continual Learning Models",
    "authors": [
      "Lanpei Li",
      "Elia Piccoli",
      "Andrea Cossu",
      "Davide Bacciu",
      "Vincenzo Lomonaco"
    ],
    "abstract": "Continual Learning (CL) focuses on maximizing the predictive performance of a\nmodel across a non-stationary stream of data. Unfortunately, CL models tend to\nforget previous knowledge, thus often underperforming when compared with an\noffline model trained jointly on the entire data stream. Given that any CL\nmodel will eventually make mistakes, it is of crucial importance to build\ncalibrated CL models: models that can reliably tell their confidence when\nmaking a prediction. Model calibration is an active research topic in machine\nlearning, yet to be properly investigated in CL. We provide the first empirical\nstudy of the behavior of calibration approaches in CL, showing that CL\nstrategies do not inherently learn calibrated models. To mitigate this issue,\nwe design a continual calibration approach that improves the performance of\npost-processing calibration methods over a wide range of different benchmarks\nand CL strategies. CL does not necessarily need perfect predictive models, but\nrather it can benefit from reliable predictive models. We believe our study on\ncontinual calibration represents a first step towards this direction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at CLVISION workshop, CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07817v2",
    "published_date": "2024-04-11 14:59:49 UTC",
    "updated_date": "2024-04-12 12:33:26 UTC"
  },
  {
    "arxiv_id": "2404.07815v2",
    "title": "Post-Hoc Reversal: Are We Selecting Models Prematurely?",
    "authors": [
      "Rishabh Ranjan",
      "Saurabh Garg",
      "Mrigank Raman",
      "Carlos Guestrin",
      "Zachary Lipton"
    ],
    "abstract": "Trained models are often composed with post-hoc transforms such as\ntemperature scaling (TS), ensembling and stochastic weight averaging (SWA) to\nimprove performance, robustness, uncertainty estimation, etc. However, such\ntransforms are typically applied only after the base models have already been\nfinalized by standard means. In this paper, we challenge this practice with an\nextensive empirical study. In particular, we demonstrate a phenomenon that we\ncall post-hoc reversal, where performance trends are reversed after applying\npost-hoc transforms. This phenomenon is especially prominent in high-noise\nsettings. For example, while base models overfit badly early in training, both\nensembling and SWA favor base models trained for more epochs. Post-hoc reversal\ncan also prevent the appearance of double descent and mitigate mismatches\nbetween test loss and test error seen in base models. Preliminary analyses\nsuggest that these transforms induce reversal by suppressing the influence of\nmislabeled examples, exploiting differences in their learning dynamics from\nthose of clean examples. Based on our findings, we propose post-hoc selection,\na simple technique whereby post-hoc metrics inform model development decisions\nsuch as early stopping, checkpointing, and broader hyperparameter choices. Our\nexperiments span real-world vision, language, tabular and graph datasets. On an\nLLM instruction tuning dataset, post-hoc selection results in >1.5x MMLU\nimprovement compared to naive selection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted at NeurIPS 2024; v2 adds an intuitions section",
    "pdf_url": "http://arxiv.org/pdf/2404.07815v2",
    "published_date": "2024-04-11 14:58:19 UTC",
    "updated_date": "2024-10-04 00:11:05 UTC"
  },
  {
    "arxiv_id": "2404.07788v1",
    "title": "AUG: A New Dataset and An Efficient Model for Aerial Image Urban Scene Graph Generation",
    "authors": [
      "Yansheng Li",
      "Kun Li",
      "Yongjun Zhang",
      "Linlin Wang",
      "Dingwen Zhang"
    ],
    "abstract": "Scene graph generation (SGG) aims to understand the visual objects and their\nsemantic relationships from one given image. Until now, lots of SGG datasets\nwith the eyelevel view are released but the SGG dataset with the overhead view\nis scarcely studied. By contrast to the object occlusion problem in the\neyelevel view, which impedes the SGG, the overhead view provides a new\nperspective that helps to promote the SGG by providing a clear perception of\nthe spatial relationships of objects in the ground scene. To fill in the gap of\nthe overhead view dataset, this paper constructs and releases an aerial image\nurban scene graph generation (AUG) dataset. Images from the AUG dataset are\ncaptured with the low-attitude overhead view. In the AUG dataset, 25,594\nobjects, 16,970 relationships, and 27,175 attributes are manually annotated. To\navoid the local context being overwhelmed in the complex aerial urban scene,\nthis paper proposes one new locality-preserving graph convolutional network\n(LPG). Different from the traditional graph convolutional network, which has\nthe natural advantage of capturing the global context for SGG, the\nconvolutional layer in the LPG integrates the non-destructive initial features\nof the objects with dynamically updated neighborhood information to preserve\nthe local context under the premise of mining the global context. To address\nthe problem that there exists an extra-large number of potential object\nrelationship pairs but only a small part of them is meaningful in AUG, we\npropose the adaptive bounding box scaling factor for potential relationship\ndetection (ABS-PRD) to intelligently prune the meaningless relationship pairs.\nExtensive experiments on the AUG dataset show that our LPG can significantly\noutperform the state-of-the-art methods and the effectiveness of the proposed\nlocality-preserving strategy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07788v1",
    "published_date": "2024-04-11 14:29:30 UTC",
    "updated_date": "2024-04-11 14:29:30 UTC"
  },
  {
    "arxiv_id": "2404.07775v1",
    "title": "Discourse-Aware In-Context Learning for Temporal Expression Normalization",
    "authors": [
      "Akash Kumar Gautam",
      "Lukas Lange",
      "Jannik Strötgen"
    ],
    "abstract": "Temporal expression (TE) normalization is a well-studied problem. However,\nthe predominately used rule-based systems are highly restricted to specific\nsettings, and upcoming machine learning approaches suffer from a lack of\nlabeled data. In this work, we explore the feasibility of proprietary and\nopen-source large language models (LLMs) for TE normalization using in-context\nlearning to inject task, document, and example information into the model. We\nexplore various sample selection strategies to retrieve the most relevant set\nof examples. By using a window-based prompt design approach, we can perform TE\nnormalization across sentences, while leveraging the LLM knowledge without\ntraining the model. Our experiments show competitive results to models designed\nfor this task. In particular, our method achieves large performance\nimprovements for non-standard settings by dynamically including relevant\nexamples during inference.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07775v1",
    "published_date": "2024-04-11 14:13:44 UTC",
    "updated_date": "2024-04-11 14:13:44 UTC"
  },
  {
    "arxiv_id": "2404.07765v1",
    "title": "AnnoCTR: A Dataset for Detecting and Linking Entities, Tactics, and Techniques in Cyber Threat Reports",
    "authors": [
      "Lukas Lange",
      "Marc Müller",
      "Ghazaleh Haratinezhad Torbati",
      "Dragan Milchevski",
      "Patrick Grau",
      "Subhash Pujari",
      "Annemarie Friedrich"
    ],
    "abstract": "Monitoring the threat landscape to be aware of actual or potential attacks is\nof utmost importance to cybersecurity professionals. Information about cyber\nthreats is typically distributed using natural language reports. Natural\nlanguage processing can help with managing this large amount of unstructured\ninformation, yet to date, the topic has received little attention. With this\npaper, we present AnnoCTR, a new CC-BY-SA-licensed dataset of cyber threat\nreports. The reports have been annotated by a domain expert with named\nentities, temporal expressions, and cybersecurity-specific concepts including\nimplicitly mentioned techniques and tactics. Entities and concepts are linked\nto Wikipedia and the MITRE ATT&CK knowledge base, the most widely-used taxonomy\nfor classifying types of attacks. Prior datasets linking to MITRE ATT&CK either\nprovide a single label per document or annotate sentences out-of-context; our\ndataset annotates entire documents in a much finer-grained way. In an\nexperimental study, we model the annotations of our dataset using\nstate-of-the-art neural models. In our few-shot scenario, we find that for\nidentifying the MITRE ATT&CK concepts that are mentioned explicitly or\nimplicitly in a text, concept descriptions from MITRE ATT&CK are an effective\nsource for training data augmentation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024. Corpus available at\n  https://github.com/boschresearch/anno-ctr-lrec-coling-2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07765v1",
    "published_date": "2024-04-11 14:04:36 UTC",
    "updated_date": "2024-04-11 14:04:36 UTC"
  },
  {
    "arxiv_id": "2404.07754v1",
    "title": "Generating Synthetic Satellite Imagery With Deep-Learning Text-to-Image Models -- Technical Challenges and Implications for Monitoring and Verification",
    "authors": [
      "Tuong Vy Nguyen",
      "Alexander Glaser",
      "Felix Biessmann"
    ],
    "abstract": "Novel deep-learning (DL) architectures have reached a level where they can\ngenerate digital media, including photorealistic images, that are difficult to\ndistinguish from real data. These technologies have already been used to\ngenerate training data for Machine Learning (ML) models, and large\ntext-to-image models like DALL-E 2, Imagen, and Stable Diffusion are achieving\nremarkable results in realistic high-resolution image generation. Given these\ndevelopments, issues of data authentication in monitoring and verification\ndeserve a careful and systematic analysis: How realistic are synthetic images?\nHow easily can they be generated? How useful are they for ML researchers, and\nwhat is their potential for Open Science? In this work, we use novel DL models\nto explore how synthetic satellite images can be created using conditioning\nmechanisms. We investigate the challenges of synthetic satellite image\ngeneration and evaluate the results based on authenticity and state-of-the-art\nmetrics. Furthermore, we investigate how synthetic data can alleviate the lack\nof data in the context of ML methods for remote-sensing. Finally we discuss\nimplications of synthetic satellite imagery in the context of monitoring and\nverification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "https://resources.inmm.org/annual-meeting-proceedings/generating-synthetic-satellite-imagery-deep-learning-text-image-models",
    "pdf_url": "http://arxiv.org/pdf/2404.07754v1",
    "published_date": "2024-04-11 14:00:20 UTC",
    "updated_date": "2024-04-11 14:00:20 UTC"
  },
  {
    "arxiv_id": "2404.07751v1",
    "title": "Generating consistent PDDL domains with Large Language Models",
    "authors": [
      "Pavel Smirnov",
      "Frank Joublin",
      "Antonello Ceravola",
      "Michael Gienger"
    ],
    "abstract": "Large Language Models (LLMs) are capable of transforming natural language\ndomain descriptions into plausibly looking PDDL markup. However, ensuring that\nactions are consistent within domains still remains a challenging task. In this\npaper we present a novel concept to significantly improve the quality of\nLLM-generated PDDL models by performing automated consistency checking during\nthe generation process. Although the proposed consistency checking strategies\nstill can't guarantee absolute correctness of generated models, they can serve\nas valuable source of feedback reducing the amount of correction efforts\nexpected from a human in the loop. We demonstrate the capabilities of our error\ndetection approach on a number of classical and custom planning domains\n(logistics, gripper, tyreworld, household, pizza).",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07751v1",
    "published_date": "2024-04-11 13:48:48 UTC",
    "updated_date": "2024-04-11 13:48:48 UTC"
  },
  {
    "arxiv_id": "2404.07738v2",
    "title": "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models",
    "authors": [
      "Jinheon Baek",
      "Sujay Kumar Jauhar",
      "Silviu Cucerzan",
      "Sung Ju Hwang"
    ],
    "abstract": "The pace of scientific research, vital for improving human life, is complex,\nslow, and needs specialized expertise. Meanwhile, novel, impactful research\noften stems from both a deep understanding of prior work, and a\ncross-pollination of ideas across domains and fields. To enhance the\nproductivity of researchers, we propose ResearchAgent, which leverages the\nencyclopedic knowledge and linguistic reasoning capabilities of Large Language\nModels (LLMs) to assist them in their work. This system automatically defines\nnovel problems, proposes methods and designs experiments, while iteratively\nrefining them based on the feedback from collaborative LLM-powered reviewing\nagents. Specifically, starting with a core scientific paper, ResearchAgent is\naugmented not only with relevant publications by connecting information over an\nacademic graph but also entities retrieved from a knowledge store derived from\nshared underlying concepts mined across numerous papers. Then, mimicking a\nscientific approach to improving ideas with peer discussions, we leverage\nmultiple LLM-based ReviewingAgents that provide reviews and feedback via\niterative revision processes. These reviewing agents are instantiated with\nhuman preference-aligned LLMs whose criteria for evaluation are elicited from\nactual human judgments via LLM prompting. We experimentally validate our\nResearchAgent on scientific publications across multiple disciplines, showing\nits effectiveness in generating novel, clear, and valid ideas based on both\nhuman and model-based evaluation results. Our initial foray into AI-mediated\nscientific research has important implications for the development of future\nsystems aimed at supporting researchers in their ideation and\noperationalization of novel work.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.07738v2",
    "published_date": "2024-04-11 13:36:29 UTC",
    "updated_date": "2025-02-09 08:15:44 UTC"
  },
  {
    "arxiv_id": "2404.07735v2",
    "title": "Diffusing in Someone Else's Shoes: Robotic Perspective Taking with Diffusion",
    "authors": [
      "Josua Spisak",
      "Matthias Kerzel",
      "Stefan Wermter"
    ],
    "abstract": "Humanoid robots can benefit from their similarity to the human shape by\nlearning from humans. When humans teach other humans how to perform actions,\nthey often demonstrate the actions, and the learning human imitates the\ndemonstration to get an idea of how to perform the action. Being able to\nmentally transfer from a demonstration seen from a third-person perspective to\nhow it should look from a first-person perspective is fundamental for this\nability in humans. As this is a challenging task, it is often simplified for\nrobots by creating demonstrations from the first-person perspective. Creating\nthese demonstrations allows for an easier imitation but requires more effort.\nTherefore, we introduce a novel diffusion model that enables the robot to learn\nfrom the third-person demonstrations directly by learning to generate the\nfirst-person perspective from the third-person perspective. The model\ntranslates the size and rotations of objects and the environment between the\ntwo perspectives. This allows us to utilise the benefits of easy-to-produce\nthird-person demonstrations and easy-to-imitate first-person demonstrations.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to Humanoids",
    "pdf_url": "http://arxiv.org/pdf/2404.07735v2",
    "published_date": "2024-04-11 13:30:03 UTC",
    "updated_date": "2024-10-04 14:03:45 UTC"
  },
  {
    "arxiv_id": "2404.07732v1",
    "title": "Monte Carlo Tree Search with Boltzmann Exploration",
    "authors": [
      "Michael Painter",
      "Mohamed Baioumy",
      "Nick Hawes",
      "Bruno Lacerda"
    ],
    "abstract": "Monte-Carlo Tree Search (MCTS) methods, such as Upper Confidence Bound\napplied to Trees (UCT), are instrumental to automated planning techniques.\nHowever, UCT can be slow to explore an optimal action when it initially appears\ninferior to other actions. Maximum ENtropy Tree-Search (MENTS) incorporates the\nmaximum entropy principle into an MCTS approach, utilising Boltzmann policies\nto sample actions, naturally encouraging more exploration. In this paper, we\nhighlight a major limitation of MENTS: optimal actions for the maximum entropy\nobjective do not necessarily correspond to optimal actions for the original\nobjective. We introduce two algorithms, Boltzmann Tree Search (BTS) and\nDecaying ENtropy Tree-Search (DENTS), that address these limitations and\npreserve the benefits of Boltzmann policies, such as allowing actions to be\nsampled faster by using the Alias method. Our empirical analysis shows that our\nalgorithms show consistent high performance across several benchmark domains,\nincluding the game of Go.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Camera ready version of NeurIPS2023 paper",
    "pdf_url": "http://arxiv.org/pdf/2404.07732v1",
    "published_date": "2024-04-11 13:25:35 UTC",
    "updated_date": "2024-04-11 13:25:35 UTC"
  },
  {
    "arxiv_id": "2404.07725v1",
    "title": "Unraveling the Dilemma of AI Errors: Exploring the Effectiveness of Human and Machine Explanations for Large Language Models",
    "authors": [
      "Marvin Pafla",
      "Kate Larson",
      "Mark Hancock"
    ],
    "abstract": "The field of eXplainable artificial intelligence (XAI) has produced a\nplethora of methods (e.g., saliency-maps) to gain insight into artificial\nintelligence (AI) models, and has exploded with the rise of deep learning (DL).\nHowever, human-participant studies question the efficacy of these methods,\nparticularly when the AI output is wrong. In this study, we collected and\nanalyzed 156 human-generated text and saliency-based explanations collected in\na question-answering task (N=40) and compared them empirically to\nstate-of-the-art XAI explanations (integrated gradients, conservative LRP, and\nChatGPT) in a human-participant study (N=136). Our findings show that\nparticipants found human saliency maps to be more helpful in explaining AI\nanswers than machine saliency maps, but performance negatively correlated with\ntrust in the AI model and explanations. This finding hints at the dilemma of AI\nerrors in explanation, where helpful explanations can lead to lower task\nperformance when they support wrong AI predictions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07725v1",
    "published_date": "2024-04-11 13:16:51 UTC",
    "updated_date": "2024-04-11 13:16:51 UTC"
  },
  {
    "arxiv_id": "2404.07724v2",
    "title": "Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models",
    "authors": [
      "Tuomas Kynkäänniemi",
      "Miika Aittala",
      "Tero Karras",
      "Samuli Laine",
      "Timo Aila",
      "Jaakko Lehtinen"
    ],
    "abstract": "Guidance is a crucial technique for extracting the best performance out of\nimage-generating diffusion models. Traditionally, a constant guidance weight\nhas been applied throughout the sampling chain of an image. We show that\nguidance is clearly harmful toward the beginning of the chain (high noise\nlevels), largely unnecessary toward the end (low noise levels), and only\nbeneficial in the middle. We thus restrict it to a specific range of noise\nlevels, improving both the inference speed and result quality. This limited\nguidance interval improves the record FID in ImageNet-512 significantly, from\n1.81 to 1.40. We show that it is quantitatively and qualitatively beneficial\nacross different sampler parameters, network architectures, and datasets,\nincluding the large-scale setting of Stable Diffusion XL. We thus suggest\nexposing the guidance interval as a hyperparameter in all diffusion models that\nuse guidance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07724v2",
    "published_date": "2024-04-11 13:16:47 UTC",
    "updated_date": "2024-11-06 14:29:36 UTC"
  },
  {
    "arxiv_id": "2404.07719v2",
    "title": "Reframing the Mind-Body Picture: Applying Formal Systems to the Relationship of Mind and Matter",
    "authors": [
      "Ryan Williams"
    ],
    "abstract": "This paper aims to show that a simple framework, utilizing basic formalisms\nfrom set theory and category theory, can clarify and inform our theories of the\nrelation between mind and matter.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07719v2",
    "published_date": "2024-04-11 13:11:13 UTC",
    "updated_date": "2024-10-13 20:55:14 UTC"
  },
  {
    "arxiv_id": "2407.07747v1",
    "title": "HGFF: A Deep Reinforcement Learning Framework for Lifetime Maximization in Wireless Sensor Networks",
    "authors": [
      "Xiaoxu Han",
      "Xin Mu",
      "Jinghui Zhong"
    ],
    "abstract": "Planning the movement of the sink to maximize the lifetime in wireless sensor\nnetworks is an essential problem of great research challenge and practical\nvalue. Many existing mobile sink techniques based on mathematical programming\nor heuristics have demonstrated the feasibility of the task. Nevertheless, the\nhuge computation consumption or the over-reliance on human knowledge can result\nin relatively low performance. In order to balance the need for high-quality\nsolutions with the goal of minimizing inference time, we propose a new\nframework combining heterogeneous graph neural network with deep reinforcement\nlearning to automatically construct the movement path of the sink. Modeling the\nwireless sensor networks as heterogeneous graphs, we utilize the graph neural\nnetwork to learn representations of sites and sensors by aggregating features\nof neighbor nodes and extracting hierarchical graph features. Meanwhile, the\nmulti-head attention mechanism is leveraged to allow the sites to attend to\ninformation from sensor nodes, which highly improves the expressive capacity of\nthe learning model. Based on the node representations, a greedy policy is\nlearned to append the next best site in the solution incrementally. We design\nten types of static and dynamic maps to simulate different wireless sensor\nnetworks in the real world, and extensive experiments are conducted to evaluate\nand analyze our approach. The empirical results show that our approach\nconsistently outperforms the existing methods on all types of maps.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Preprint. Under review",
    "pdf_url": "http://arxiv.org/pdf/2407.07747v1",
    "published_date": "2024-04-11 13:09:11 UTC",
    "updated_date": "2024-04-11 13:09:11 UTC"
  },
  {
    "arxiv_id": "2404.07698v2",
    "title": "Point Cloud Geometry Scalable Coding with a Quality-Conditioned Latents Probability Estimator",
    "authors": [
      "Daniele Mari",
      "André F. R. Guarda",
      "Nuno M. M. Rodrigues",
      "Simone Milani",
      "Fernando Pereira"
    ],
    "abstract": "The widespread usage of point clouds (PC) for immersive visual applications\nhas resulted in the use of very heterogeneous receiving conditions and devices,\nnotably in terms of network, hardware, and display capabilities. In this\nscenario, quality scalability, i.e., the ability to reconstruct a signal at\ndifferent qualities by progressively decoding a single bitstream, is a major\nrequirement that has yet to be conveniently addressed, notably in most\nlearning-based PC coding solutions. This paper proposes a quality scalability\nscheme, named Scalable Quality Hyperprior (SQH), adaptable to learning-based\nstatic point cloud geometry codecs, which uses a Quality-conditioned Latents\nProbability Estimator (QuLPE) to decode a high-quality version of a PC\nlearning-based representation, based on an available lower quality base layer.\nSQH is integrated in the future JPEG PC coding standard, allowing to create a\nlayered bitstream that can be used to progressively decode the PC geometry with\nincreasing quality and fidelity. Experimental results show that SQH offers the\nquality scalability feature with very limited or no compression performance\npenalty at all when compared with the corresponding non-scalable solution, thus\npreserving the significant compression gains over other state-of-the-art PC\ncodecs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICIP 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07698v2",
    "published_date": "2024-04-11 12:44:15 UTC",
    "updated_date": "2024-07-09 06:56:06 UTC"
  },
  {
    "arxiv_id": "2404.07686v1",
    "title": "Depth Estimation using Weighted-loss and Transfer Learning",
    "authors": [
      "Muhammad Adeel Hafeez",
      "Michael G. Madden",
      "Ganesh Sistu",
      "Ihsan Ullah"
    ],
    "abstract": "Depth estimation from 2D images is a common computer vision task that has\napplications in many fields including autonomous vehicles, scene understanding\nand robotics. The accuracy of a supervised depth estimation method mainly\nrelies on the chosen loss function, the model architecture, quality of data and\nperformance metrics. In this study, we propose a simplified and adaptable\napproach to improve depth estimation accuracy using transfer learning and an\noptimized loss function. The optimized loss function is a combination of\nweighted losses to which enhance robustness and generalization: Mean Absolute\nError (MAE), Edge Loss and Structural Similarity Index (SSIM). We use a grid\nsearch and a random search method to find optimized weights for the losses,\nwhich leads to an improved model. We explore multiple encoder-decoder-based\nmodels including DenseNet121, DenseNet169, DenseNet201, and EfficientNet for\nthe supervised depth estimation model on NYU Depth Dataset v2. We observe that\nthe EfficientNet model, pre-trained on ImageNet for classification when used as\nan encoder, with a simple upsampling decoder, gives the best results in terms\nof RSME, REL and log10: 0.386, 0.113 and 0.049, respectively. We also perform a\nqualitative analysis which illustrates that our model produces depth maps that\nclosely resemble ground truth, even in cases where the ground truth is flawed.\nThe results indicate significant improvements in accuracy and robustness, with\nEfficientNet being the most successful architecture.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07686v1",
    "published_date": "2024-04-11 12:25:54 UTC",
    "updated_date": "2024-04-11 12:25:54 UTC"
  },
  {
    "arxiv_id": "2404.07685v1",
    "title": "Run-time Monitoring of 3D Object Detection in Automated Driving Systems Using Early Layer Neural Activation Patterns",
    "authors": [
      "Hakan Yekta Yatbaz",
      "Mehrdad Dianati",
      "Konstantinos Koufos",
      "Roger Woodman"
    ],
    "abstract": "Monitoring the integrity of object detection for errors within the perception\nmodule of automated driving systems (ADS) is paramount for ensuring safety.\nDespite recent advancements in deep neural network (DNN)-based object\ndetectors, their susceptibility to detection errors, particularly in the\nless-explored realm of 3D object detection, remains a significant concern.\nState-of-the-art integrity monitoring (also known as introspection) mechanisms\nin 2D object detection mainly utilise the activation patterns in the final\nlayer of the DNN-based detector's backbone. However, that may not sufficiently\naddress the complexities and sparsity of data in 3D object detection. To this\nend, we conduct, in this article, an extensive investigation into the effects\nof activation patterns extracted from various layers of the backbone network\nfor introspecting the operation of 3D object detectors. Through a comparative\nanalysis using Kitti and NuScenes datasets with PointPillars and CenterPoint\ndetectors, we demonstrate that using earlier layers' activation patterns\nenhances the error detection performance of the integrity monitoring system,\nyet increases computational complexity. To address the real-time operation\nrequirements in ADS, we also introduce a novel introspection method that\ncombines activation patterns from multiple layers of the detector's backbone\nand report its performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2024 Workshop on Safe Autonomy for All Domains\n  (SAIAD)",
    "pdf_url": "http://arxiv.org/pdf/2404.07685v1",
    "published_date": "2024-04-11 12:24:47 UTC",
    "updated_date": "2024-04-11 12:24:47 UTC"
  },
  {
    "arxiv_id": "2404.07677v2",
    "title": "ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs",
    "authors": [
      "Lei Sun",
      "Zhengwei Tao",
      "Youdi Li",
      "Hiroshi Arakawa"
    ],
    "abstract": "The integration of Large Language Models (LLMs) and knowledge graphs (KGs)\nhas achieved remarkable success in various natural language processing tasks.\nHowever, existing methodologies that integrate LLMs and KGs often navigate the\ntask-solving process solely based on the LLM's analysis of the question,\noverlooking the rich cognitive potential inherent in the vast knowledge\nencapsulated in KGs. To address this, we introduce Observation-Driven Agent\n(ODA), a novel AI agent framework tailored for tasks involving KGs. ODA\nincorporates KG reasoning abilities via global observation, which enhances\nreasoning capabilities through a cyclical paradigm of observation, action, and\nreflection. Confronting the exponential explosion of knowledge during\nobservation, we innovatively design a recursive observation mechanism.\nSubsequently, we integrate the observed knowledge into the action and\nreflection modules. Through extensive experiments, ODA demonstrates\nstate-of-the-art performance on several datasets, notably achieving accuracy\nimprovements of 12.87% and 8.9%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "LLM+KG",
    "pdf_url": "http://arxiv.org/pdf/2404.07677v2",
    "published_date": "2024-04-11 12:16:16 UTC",
    "updated_date": "2024-06-04 07:16:14 UTC"
  },
  {
    "arxiv_id": "2404.07676v1",
    "title": "Model-based Cleaning of the QUILT-1M Pathology Dataset for Text-Conditional Image Synthesis",
    "authors": [
      "Marc Aubreville",
      "Jonathan Ganz",
      "Jonas Ammeling",
      "Christopher C. Kaltenecker",
      "Christof A. Bertram"
    ],
    "abstract": "The QUILT-1M dataset is the first openly available dataset containing images\nharvested from various online sources. While it provides a huge data variety,\nthe image quality and composition is highly heterogeneous, impacting its\nutility for text-conditional image synthesis. We propose an automatic pipeline\nthat provides predictions of the most common impurities within the images,\ne.g., visibility of narrators, desktop environment and pathology software, or\ntext within the image. Additionally, we propose to use semantic alignment\nfiltering of the image-text pairs. Our findings demonstrate that by rigorously\nfiltering the dataset, there is a substantial enhancement of image fidelity in\ntext-to-image tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages (short paper)",
    "pdf_url": "http://arxiv.org/pdf/2404.07676v1",
    "published_date": "2024-04-11 12:14:48 UTC",
    "updated_date": "2024-04-11 12:14:48 UTC"
  },
  {
    "arxiv_id": "2404.07664v2",
    "title": "Finding Dino: A Plug-and-Play Framework for Zero-Shot Detection of Out-of-Distribution Objects Using Prototypes",
    "authors": [
      "Poulami Sinhamahapatra",
      "Franziska Schwaiger",
      "Shirsha Bose",
      "Huiyu Wang",
      "Karsten Roscher",
      "Stephan Guennemann"
    ],
    "abstract": "Detecting and localising unknown or out-of-distribution (OOD) objects in any\nscene can be a challenging task in vision, particularly in safety-critical\ncases involving autonomous systems like automated vehicles or trains.\nSupervised anomaly segmentation or open-world object detection models depend on\ntraining on exhaustively annotated datasets for every domain and still struggle\nin distinguishing between background and OOD objects. In this work, we present\na plug-and-play framework - PRototype-based OOD detection Without Labels\n(PROWL). It is an inference-based method that does not require training on the\ndomain dataset and relies on extracting relevant features from self-supervised\npre-trained models. PROWL can be easily adapted to detect in-domain objects in\nany operational design domain (ODD) in a zero-shot manner by specifying a list\nof known classes from this domain. PROWL, as a first zero-shot unsupervised\nmethod, achieves state-of-the-art results on the RoadAnomaly and RoadObstacle\ndatasets provided in road driving benchmarks - SegmentMeIfYouCan (SMIYC) and\nFishyscapes, as well as comparable performance against existing supervised\nmethods trained without auxiliary OOD data. We also demonstrate its\ngeneralisability to other domains such as rail and maritime.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.07664v2",
    "published_date": "2024-04-11 11:55:42 UTC",
    "updated_date": "2025-02-11 14:05:29 UTC"
  },
  {
    "arxiv_id": "2404.07663v1",
    "title": "Interactive Ontology Matching with Cost-Efficient Learning",
    "authors": [
      "Bin Cheng",
      "Jonathan Fürst",
      "Tobias Jacobs",
      "Celia Garrido-Hidalgo"
    ],
    "abstract": "The creation of high-quality ontologies is crucial for data integration and\nknowledge-based reasoning, specifically in the context of the rising data\neconomy. However, automatic ontology matchers are often bound to the heuristics\nthey are based on, leaving many matches unidentified. Interactive ontology\nmatching systems involving human experts have been introduced, but they do not\nsolve the fundamental issue of flexibly finding additional matches outside the\nscope of the implemented heuristics, even though this is highly demanded in\nindustrial settings. Active machine learning methods appear to be a promising\npath towards a flexible interactive ontology matcher. However, off-the-shelf\nactive learning mechanisms suffer from low query efficiency due to extreme\nclass imbalance, resulting in a last-mile problem where high human effort is\nrequired to identify the remaining matches.\n  To address the last-mile problem, this work introduces DualLoop, an active\nlearning method tailored to ontology matching. DualLoop offers three main\ncontributions: (1) an ensemble of tunable heuristic matchers, (2) a short-term\nlearner with a novel query strategy adapted to highly imbalanced data, and (3)\nlong-term learners to explore potential matches by creating and tuning new\nheuristics. We evaluated DualLoop on three datasets of varying sizes and\ndomains. Compared to existing active learning methods, we consistently achieved\nbetter F1 scores and recall, reducing the expected query cost spent on finding\n90% of all matches by over 50%. Compared to traditional interactive ontology\nmatchers, we are able to find additional, last-mile matches. Finally, we detail\nthe successful deployment of our approach within an actual product and report\nits operational performance results within the Architecture, Engineering, and\nConstruction (AEC) industry sector, showcasing its practical value and\nefficiency.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07663v1",
    "published_date": "2024-04-11 11:53:14 UTC",
    "updated_date": "2024-04-11 11:53:14 UTC"
  },
  {
    "arxiv_id": "2404.07662v1",
    "title": "PINNACLE: PINN Adaptive ColLocation and Experimental points selection",
    "authors": [
      "Gregory Kang Ruey Lau",
      "Apivich Hemachandra",
      "See-Kiong Ng",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs), which incorporate PDEs as soft\nconstraints, train with a composite loss function that contains multiple\ntraining point types: different types of collocation points chosen during\ntraining to enforce each PDE and initial/boundary conditions, and experimental\npoints which are usually costly to obtain via experiments or simulations.\nTraining PINNs using this loss function is challenging as it typically requires\nselecting large numbers of points of different types, each with different\ntraining dynamics. Unlike past works that focused on the selection of either\ncollocation or experimental points, this work introduces PINN Adaptive\nColLocation and Experimental points selection (PINNACLE), the first algorithm\nthat jointly optimizes the selection of all training point types, while\nautomatically adjusting the proportion of collocation point types as training\nprogresses. PINNACLE uses information on the interaction among training point\ntypes, which had not been considered before, based on an analysis of PINN\ntraining dynamics via the Neural Tangent Kernel (NTK). We theoretically show\nthat the criterion used by PINNACLE is related to the PINN generalization\nerror, and empirically demonstrate that PINNACLE is able to outperform existing\npoint selection methods for forward, inverse, and transfer learning problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to 12th International Conference on Learning Representations\n  (ICLR 2024), 36 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.07662v1",
    "published_date": "2024-04-11 11:51:46 UTC",
    "updated_date": "2024-04-11 11:51:46 UTC"
  },
  {
    "arxiv_id": "2404.08706v2",
    "title": "Game Generation via Large Language Models",
    "authors": [
      "Chengpeng Hu",
      "Yunlong Zhao",
      "Jialin Liu"
    ],
    "abstract": "Recently, the emergence of large language models (LLMs) has unlocked new\nopportunities for procedural content generation. However, recent attempts\nmainly focus on level generation for specific games with defined game rules\nsuch as Super Mario Bros. and Zelda. This paper investigates the game\ngeneration via LLMs. Based on video game description language, this paper\nproposes an LLM-based framework to generate game rules and levels\nsimultaneously. Experiments demonstrate how the framework works with prompts\nconsidering different combinations of context. Our findings extend the current\napplications of LLMs and offer new insights for generating new games in the\narea of procedural content generation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "2024 IEEE Conference on Games",
    "pdf_url": "http://arxiv.org/pdf/2404.08706v2",
    "published_date": "2024-04-11 10:06:05 UTC",
    "updated_date": "2024-05-30 03:17:00 UTC"
  },
  {
    "arxiv_id": "2404.07613v1",
    "title": "Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain",
    "authors": [
      "Iker García-Ferrero",
      "Rodrigo Agerri",
      "Aitziber Atutxa Salazar",
      "Elena Cabrio",
      "Iker de la Iglesia",
      "Alberto Lavelli",
      "Bernardo Magnini",
      "Benjamin Molinet",
      "Johana Ramirez-Romero",
      "German Rigau",
      "Jose Maria Villa-Gonzalez",
      "Serena Villata",
      "Andrea Zaninello"
    ],
    "abstract": "Research on language technology for the development of medical applications\nis currently a hot topic in Natural Language Understanding and Generation.\nThus, a number of large language models (LLMs) have recently been adapted to\nthe medical domain, so that they can be used as a tool for mediating in\nhuman-AI interaction. While these LLMs display competitive performance on\nautomated medical texts benchmarks, they have been pre-trained and evaluated\nwith a focus on a single language (English mostly). This is particularly true\nof text-to-text models, which typically require large amounts of\ndomain-specific pre-training data, often not easily accessible for many\nlanguages. In this paper, we address these shortcomings by compiling, to the\nbest of our knowledge, the largest multilingual corpus for the medical domain\nin four languages, namely English, French, Italian and Spanish. This new corpus\nhas been used to train Medical mT5, the first open-source text-to-text\nmultilingual model for the medical domain. Additionally, we present two new\nevaluation benchmarks for all four languages with the aim of facilitating\nmultilingual research in this domain. A comprehensive evaluation shows that\nMedical mT5 outperforms both encoders and similarly sized text-to-text models\nfor the Spanish, French, and Italian benchmarks, while being competitive with\ncurrent state-of-the-art LLMs in English.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07613v1",
    "published_date": "2024-04-11 10:01:32 UTC",
    "updated_date": "2024-04-11 10:01:32 UTC"
  },
  {
    "arxiv_id": "2404.07611v2",
    "title": "NoticIA: A Clickbait Article Summarization Dataset in Spanish",
    "authors": [
      "Iker García-Ferrero",
      "Begoña Altuna"
    ],
    "abstract": "We present NoticIA, a dataset consisting of 850 Spanish news articles\nfeaturing prominent clickbait headlines, each paired with high-quality,\nsingle-sentence generative summarizations written by humans. This task demands\nadvanced text understanding and summarization abilities, challenging the\nmodels' capacity to infer and connect diverse pieces of information to meet the\nuser's informational needs generated by the clickbait headline. We evaluate the\nSpanish text comprehension capabilities of a wide range of state-of-the-art\nlarge language models. Additionally, we use the dataset to train\nClickbaitFighter, a task-specific model that achieves near-human performance in\nthis task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in the journal Procesamiento del Lenguaje Natural",
    "pdf_url": "http://arxiv.org/pdf/2404.07611v2",
    "published_date": "2024-04-11 09:59:01 UTC",
    "updated_date": "2024-05-31 15:19:18 UTC"
  },
  {
    "arxiv_id": "2404.07605v1",
    "title": "Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology Image Classification",
    "authors": [
      "Lucas Dedieu",
      "Nicolas Nerrienet",
      "Adrien Nivaggioli",
      "Clara Simmat",
      "Marceau Clavel",
      "Arnaud Gauthier",
      "Stéphane Sockeel",
      "Rémy Peyret"
    ],
    "abstract": "Recent advancements in deep learning have proven highly effective in medical\nimage classification, notably within histopathology. However, noisy labels\nrepresent a critical challenge in histopathology image classification, where\naccurate annotations are vital for training robust deep learning models.\nIndeed, deep neural networks can easily overfit label noise, leading to severe\ndegradations in model performance. While numerous public pathology foundation\nmodels have emerged recently, none have evaluated their resilience to label\nnoise. Through thorough empirical analyses across multiple datasets, we exhibit\nthe label noise resilience property of embeddings extracted from foundation\nmodels trained in a self-supervised contrastive manner. We demonstrate that\ntraining with such embeddings substantially enhances label noise robustness\nwhen compared to non-contrastive-based ones as well as commonly used\nnoise-resilient methods. Our results unequivocally underline the superiority of\ncontrastive learning in effectively mitigating the label noise challenge. Code\nis publicly available at\nhttps://github.com/LucasDedieu/NoiseResilientHistopathology.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.07605v1",
    "published_date": "2024-04-11 09:47:52 UTC",
    "updated_date": "2024-04-11 09:47:52 UTC"
  },
  {
    "arxiv_id": "2404.07575v4",
    "title": "An Effective Automated Speaking Assessment Approach to Mitigating Data Scarcity and Imbalanced Distribution",
    "authors": [
      "Tien-Hong Lo",
      "Fu-An Chao",
      "Tzu-I Wu",
      "Yao-Ting Sung",
      "Berlin Chen"
    ],
    "abstract": "Automated speaking assessment (ASA) typically involves automatic speech\nrecognition (ASR) and hand-crafted feature extraction from the ASR transcript\nof a learner's speech. Recently, self-supervised learning (SSL) has shown\nstellar performance compared to traditional methods. However, SSL-based ASA\nsystems are faced with at least three data-related challenges: limited\nannotated data, uneven distribution of learner proficiency levels and\nnon-uniform score intervals between different CEFR proficiency levels. To\naddress these challenges, we explore the use of two novel modeling strategies:\nmetric-based classification and loss reweighting, leveraging distinct SSL-based\nembedding features. Extensive experimental results on the ICNALE benchmark\ndataset suggest that our approach can outperform existing strong baselines by a\nsizable margin, achieving a significant improvement of more than 10% in CEFR\nprediction accuracy.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to NAACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2404.07575v4",
    "published_date": "2024-04-11 09:06:49 UTC",
    "updated_date": "2025-03-02 13:55:52 UTC"
  },
  {
    "arxiv_id": "2404.07572v3",
    "title": "Fragile Model Watermark for integrity protection: leveraging boundary volatility and sensitive sample-pairing",
    "authors": [
      "ZhenZhe Gao",
      "Zhenjun Tang",
      "Zhaoxia Yin",
      "Baoyuan Wu",
      "Yue Lu"
    ],
    "abstract": "Neural networks have increasingly influenced people's lives. Ensuring the\nfaithful deployment of neural networks as designed by their model owners is\ncrucial, as they may be susceptible to various malicious or unintentional\nmodifications, such as backdooring and poisoning attacks. Fragile model\nwatermarks aim to prevent unexpected tampering that could lead DNN models to\nmake incorrect decisions. They ensure the detection of any tampering with the\nmodel as sensitively as possible.However, prior watermarking methods suffered\nfrom inefficient sample generation and insufficient sensitivity, limiting their\npractical applicability. Our approach employs a sample-pairing technique,\nplacing the model boundaries between pairs of samples, while simultaneously\nmaximizing logits. This ensures that the model's decision results of sensitive\nsamples change as much as possible and the Top-1 labels easily alter regardless\nof the direction it moves.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "The article has been accepted by IEEE International Conference on\n  Multimedia and Expo 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07572v3",
    "published_date": "2024-04-11 09:01:52 UTC",
    "updated_date": "2024-06-13 03:29:37 UTC"
  },
  {
    "arxiv_id": "2404.07569v2",
    "title": "Can Vehicle Motion Planning Generalize to Realistic Long-tail Scenarios?",
    "authors": [
      "Marcel Hallgarten",
      "Julian Zapata",
      "Martin Stoll",
      "Katrin Renz",
      "Andreas Zell"
    ],
    "abstract": "Real-world autonomous driving systems must make safe decisions in the face of\nrare and diverse traffic scenarios. Current state-of-the-art planners are\nmostly evaluated on real-world datasets like nuScenes (open-loop) or nuPlan\n(closed-loop). In particular, nuPlan seems to be an expressive evaluation\nmethod since it is based on real-world data and closed-loop, yet it mostly\ncovers basic driving scenarios. This makes it difficult to judge a planner's\ncapabilities to generalize to rarely-seen situations. Therefore, we propose a\nnovel closed-loop benchmark interPlan containing several edge cases and\nchallenging driving scenarios. We assess existing state-of-the-art planners on\nour benchmark and show that neither rule-based nor learning-based planners can\nsafely navigate the interPlan scenarios. A recently evolving direction is the\nusage of foundation models like large language models (LLM) to handle\ngeneralization. We evaluate an LLM-only planner and introduce a novel hybrid\nplanner that combines an LLM-based behavior planner with a rule-based motion\nplanner that achieves state-of-the-art performance on our benchmark.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07569v2",
    "published_date": "2024-04-11 08:57:48 UTC",
    "updated_date": "2024-09-04 11:34:33 UTC"
  },
  {
    "arxiv_id": "2404.07560v2",
    "title": "Socially Pertinent Robots in Gerontological Healthcare",
    "authors": [
      "Xavier Alameda-Pineda",
      "Angus Addlesee",
      "Daniel Hernández García",
      "Chris Reinke",
      "Soraya Arias",
      "Federica Arrigoni",
      "Alex Auternaud",
      "Lauriane Blavette",
      "Cigdem Beyan",
      "Luis Gomez Camara",
      "Ohad Cohen",
      "Alessandro Conti",
      "Sébastien Dacunha",
      "Christian Dondrup",
      "Yoav Ellinson",
      "Francesco Ferro",
      "Sharon Gannot",
      "Florian Gras",
      "Nancie Gunson",
      "Radu Horaud",
      "Moreno D'Incà",
      "Imad Kimouche",
      "Séverin Lemaignan",
      "Oliver Lemon",
      "Cyril Liotard",
      "Luca Marchionni",
      "Mordehay Moradi",
      "Tomas Pajdla",
      "Maribel Pino",
      "Michal Polic",
      "Matthieu Py",
      "Ariel Rado",
      "Bin Ren",
      "Elisa Ricci",
      "Anne-Sophie Rigaud",
      "Paolo Rota",
      "Marta Romeo",
      "Nicu Sebe",
      "Weronika Sieińska",
      "Pinchas Tandeitnik",
      "Francesco Tonini",
      "Nicolas Turro",
      "Timothée Wintz",
      "Yanchao Yu"
    ],
    "abstract": "Despite the many recent achievements in developing and deploying social\nrobotics, there are still many underexplored environments and applications for\nwhich systematic evaluation of such systems by end-users is necessary. While\nseveral robotic platforms have been used in gerontological healthcare, the\nquestion of whether or not a social interactive robot with multi-modal\nconversational capabilities will be useful and accepted in real-life facilities\nis yet to be answered. This paper is an attempt to partially answer this\nquestion, via two waves of experiments with patients and companions in a\nday-care gerontological facility in Paris with a full-sized humanoid robot\nendowed with social and conversational interaction capabilities. The software\narchitecture, developed during the H2020 SPRING project, together with the\nexperimental protocol, allowed us to evaluate the acceptability (AES) and\nusability (SUS) with more than 60 end-users. Overall, the users are receptive\nto this technology, especially when the robot perception and action skills are\nrobust to environmental clutter and flexible to handle a plethora of different\ninteractions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07560v2",
    "published_date": "2024-04-11 08:43:37 UTC",
    "updated_date": "2025-02-11 08:32:11 UTC"
  },
  {
    "arxiv_id": "2404.07559v1",
    "title": "Differentially Private Reinforcement Learning with Self-Play",
    "authors": [
      "Dan Qiao",
      "Yu-Xiang Wang"
    ],
    "abstract": "We study the problem of multi-agent reinforcement learning (multi-agent RL)\nwith differential privacy (DP) constraints. This is well-motivated by various\nreal-world applications involving sensitive data, where it is critical to\nprotect users' private information. We first extend the definitions of Joint DP\n(JDP) and Local DP (LDP) to two-player zero-sum episodic Markov Games, where\nboth definitions ensure trajectory-wise privacy protection. Then we design a\nprovably efficient algorithm based on optimistic Nash value iteration and\nprivatization of Bernstein-type bonuses. The algorithm is able to satisfy JDP\nand LDP requirements when instantiated with appropriate privacy mechanisms.\nFurthermore, for both notions of DP, our regret bound generalizes the best\nknown result under the single-agent RL case, while our regret could also reduce\nto the best known result for multi-agent RL without privacy constraints. To the\nbest of our knowledge, these are the first line of results towards\nunderstanding trajectory-wise privacy protection in multi-agent RL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.MA",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.07559v1",
    "published_date": "2024-04-11 08:42:51 UTC",
    "updated_date": "2024-04-11 08:42:51 UTC"
  },
  {
    "arxiv_id": "2404.07554v2",
    "title": "CAT: Contrastive Adapter Training for Personalized Image Generation",
    "authors": [
      "Jae Wan Park",
      "Sang Hyun Park",
      "Jun Young Koh",
      "Junha Lee",
      "Min Song"
    ],
    "abstract": "The emergence of various adapters, including Low-Rank Adaptation (LoRA)\napplied from the field of natural language processing, has allowed diffusion\nmodels to personalize image generation at a low cost. However, due to the\nvarious challenges including limited datasets and shortage of regularization\nand computation resources, adapter training often results in unsatisfactory\noutcomes, leading to the corruption of the backbone model's prior knowledge.\nOne of the well known phenomena is the loss of diversity in object generation,\nespecially within the same class which leads to generating almost identical\nobjects with minor variations. This poses challenges in generation\ncapabilities. To solve this issue, we present Contrastive Adapter Training\n(CAT), a simple yet effective strategy to enhance adapter training through the\napplication of CAT loss. Our approach facilitates the preservation of the base\nmodel's original knowledge when the model initiates adapters. Furthermore, we\nintroduce the Knowledge Preservation Score (KPS) to evaluate CAT's ability to\nkeep the former information. We qualitatively and quantitatively compare CAT's\nimprovement. Finally, we mention the possibility of CAT in the aspects of\nmulti-concept adapter and optimization.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPRW 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07554v2",
    "published_date": "2024-04-11 08:36:13 UTC",
    "updated_date": "2024-10-23 07:16:42 UTC"
  },
  {
    "arxiv_id": "2404.07544v3",
    "title": "From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples",
    "authors": [
      "Robert Vacareanu",
      "Vlad-Andrei Negru",
      "Vasile Suciu",
      "Mihai Surdeanu"
    ],
    "abstract": "We analyze how well pre-trained large language models (e.g., Llama2, GPT-4,\nClaude 3, etc) can do linear and non-linear regression when given in-context\nexamples, without any additional training or gradient updates. Our findings\nreveal that several large language models (e.g., GPT-4, Claude 3) are able to\nperform regression tasks with a performance rivaling (or even outperforming)\nthat of traditional supervised methods such as Random Forest, Bagging, or\nGradient Boosting. For example, on the challenging Friedman #2 regression\ndataset, Claude 3 outperforms many supervised methods such as AdaBoost, SVM,\nRandom Forest, KNN, or Gradient Boosting. We then investigate how well the\nperformance of large language models scales with the number of in-context\nexemplars. We borrow from the notion of regret from online learning and\nempirically show that LLMs are capable of obtaining a sub-linear regret.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "55 pages, 48 figures COLM camera-ready version; Changes include: (i)\n  added real-world datasets (Appendix I), (ii) fixed typos",
    "pdf_url": "http://arxiv.org/pdf/2404.07544v3",
    "published_date": "2024-04-11 08:12:43 UTC",
    "updated_date": "2024-09-10 20:35:25 UTC"
  },
  {
    "arxiv_id": "2404.07533v3",
    "title": "Exploring the Decentraland Economy: Multifaceted Parcel Attributes, Key Insights, and Benchmarking",
    "authors": [
      "Dipika Jha",
      "Ankit K. Bhagat",
      "Raju Halder",
      "Rajendra N. Paramanik",
      "Chandra M. Kumar"
    ],
    "abstract": "This paper presents a comprehensive Decentraland parcels dataset, called\nIITP-VDLand, sourced from diverse platforms such as Decentraland, OpenSea,\nEtherscan, Google BigQuery, and various Social Media Platforms. Unlike existing\ndatasets which have limited attributes and records, IITP-VDLand offers a rich\narray of attributes, encompassing parcel characteristics, trading history, past\nactivities, transactions, and social media interactions. Alongside, we\nintroduce a key attribute in the dataset, namely Rarity score, which measures\nthe uniqueness of each parcel within the virtual world. Addressing the\nsignificant challenge posed by the dispersed nature of this data across various\nsources, we employ a systematic approach, utilizing both available APIs and\ncustom scripts, to gather it. Subsequently, we meticulously curate and organize\nthe information into four distinct fragments: (1) Characteristics, (2) OpenSea\nTrading History, (3) Ethereum Activity Transactions, and (4) Social Media. We\nenvisage that this dataset would serve as a robust resource for training\nmachine- and deep-learning models specifically designed to address real-world\nchallenges within the domain of Decentraland parcels. The performance\nbenchmarking of more than 20 state-of-the-art price prediction models on our\ndataset yields promising results, achieving a maximum R2 score of 0.8251 and an\naccuracy of 74.23% in case of Extra Trees Regressor and Classifier. The key\nfindings reveal that the ensemble models perform better than both deep learning\nand linear models for our dataset. We observe a significant impact of\ncoordinates, geographical proximity, rarity score, and few other economic\nindicators on the prediction of parcel prices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07533v3",
    "published_date": "2024-04-11 07:54:14 UTC",
    "updated_date": "2025-03-02 07:59:30 UTC"
  },
  {
    "arxiv_id": "2404.07532v1",
    "title": "Bayesian Federated Model Compression for Communication and Computation Efficiency",
    "authors": [
      "Chengyu Xia",
      "Danny H. K. Tsang",
      "Vincent K. N. Lau"
    ],
    "abstract": "In this paper, we investigate Bayesian model compression in federated\nlearning (FL) to construct sparse models that can achieve both communication\nand computation efficiencies. We propose a decentralized Turbo variational\nBayesian inference (D-Turbo-VBI) FL framework where we firstly propose a\nhierarchical sparse prior to promote a clustered sparse structure in the weight\nmatrix. Then, by carefully integrating message passing and VBI with a\ndecentralized turbo framework, we propose the D-Turbo-VBI algorithm which can\n(i) reduce both upstream and downstream communication overhead during federated\ntraining, and (ii) reduce the computational complexity during local inference.\nAdditionally, we establish the convergence property for thr proposed\nD-Turbo-VBI algorithm. Simulation results show the significant gain of our\nproposed algorithm over the baselines in reducing communication overhead during\nfederated training and computational complexity of final model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07532v1",
    "published_date": "2024-04-11 07:51:30 UTC",
    "updated_date": "2024-04-11 07:51:30 UTC"
  },
  {
    "arxiv_id": "2404.08705v1",
    "title": "Introducing L2M3, A Multilingual Medical Large Language Model to Advance Health Equity in Low-Resource Regions",
    "authors": [
      "Agasthya Gangavarapu"
    ],
    "abstract": "Addressing the imminent shortfall of 10 million health workers by 2030,\npredominantly in Low- and Middle-Income Countries (LMICs), this paper\nintroduces an innovative approach that harnesses the power of Large Language\nModels (LLMs) integrated with machine translation models. This solution is\nengineered to meet the unique needs of Community Health Workers (CHWs),\novercoming language barriers, cultural sensitivities, and the limited\navailability of medical dialog datasets. I have crafted a model that not only\nboasts superior translation capabilities but also undergoes rigorous\nfine-tuning on open-source datasets to ensure medical accuracy and is equipped\nwith comprehensive safety features to counteract the risks of misinformation.\n  Featuring a modular design, this approach is specifically structured for\nswift adaptation across various linguistic and cultural contexts, utilizing\nopen-source components to significantly reduce healthcare operational costs.\nThis strategic innovation markedly improves the accessibility and quality of\nhealthcare services by providing CHWs with contextually appropriate medical\nknowledge and diagnostic tools. This paper highlights the transformative impact\nof this context-aware LLM, underscoring its crucial role in addressing the\nglobal healthcare workforce deficit and propelling forward healthcare outcomes\nin LMICs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08705v1",
    "published_date": "2024-04-11 07:39:22 UTC",
    "updated_date": "2024-04-11 07:39:22 UTC"
  },
  {
    "arxiv_id": "2404.07523v1",
    "title": "GNN-based Probabilistic Supply and Inventory Predictions in Supply Chain Networks",
    "authors": [
      "Hyung-il Ahn",
      "Young Chol Song",
      "Santiago Olivar",
      "Hershel Mehta",
      "Naveen Tewari"
    ],
    "abstract": "Successful supply chain optimization must mitigate imbalances between supply\nand demand over time. While accurate demand prediction is essential for supply\nplanning, it alone does not suffice. The key to successful supply planning for\noptimal and viable execution lies in maximizing predictability for both demand\nand supply throughout an execution horizon. Therefore, enhancing the accuracy\nof supply predictions is imperative to create an attainable supply plan that\nmatches demand without overstocking or understocking. However, in complex\nsupply chain networks with numerous nodes and edges, accurate supply\npredictions are challenging due to dynamic node interactions, cascading supply\ndelays, resource availability, production and logistic capabilities.\nConsequently, supply executions often deviate from their initial plans. To\naddress this, we present the Graph-based Supply Prediction (GSP) probabilistic\nmodel. Our attention-based graph neural network (GNN) model predicts supplies,\ninventory, and imbalances using graph-structured historical data, demand\nforecasting, and original supply plan inputs. The experiments, conducted using\nhistorical data from a global consumer goods company's large-scale supply\nchain, demonstrate that GSP significantly improves supply and inventory\nprediction accuracy, potentially offering supply plan corrections to optimize\nexecutions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07523v1",
    "published_date": "2024-04-11 07:36:00 UTC",
    "updated_date": "2024-04-11 07:36:00 UTC"
  },
  {
    "arxiv_id": "2404.07519v1",
    "title": "LATTE: Low-Precision Approximate Attention with Head-wise Trainable Threshold for Efficient Transformer",
    "authors": [
      "Jiing-Ping Wang",
      "Ming-Guang Lin",
      "An-Yeu",
      "Wu"
    ],
    "abstract": "With the rise of Transformer models in NLP and CV domain, Multi-Head\nAttention has been proven to be a game-changer. However, its expensive\ncomputation poses challenges to the model throughput and efficiency, especially\nfor the long sequence tasks. Exploiting the sparsity in attention has been\nproven to be an effective way to reduce computation. Nevertheless, prior works\ndo not consider the various distributions among different heads and lack a\nsystematic method to determine the threshold. To address these challenges, we\npropose Low-Precision Approximate Attention with Head-wise Trainable Threshold\nfor Efficient Transformer (LATTE). LATTE employs a headwise threshold-based\nfilter with the low-precision dot product and computation reuse mechanism to\nreduce the computation of MHA. Moreover, the trainable threshold is introduced\nto provide a systematic method for adjusting the thresholds and enable\nend-to-end optimization. Experimental results indicate LATTE can smoothly adapt\nto both NLP and CV tasks, offering significant computation savings with only a\nminor compromise in performance. Also, the trainable threshold is shown to be\nessential for the leverage between the performance and the computation. As a\nresult, LATTE filters up to 85.16% keys with only a 0.87% accuracy drop in the\nCV task and 89.91% keys with a 0.86 perplexity increase in the NLP task.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07519v1",
    "published_date": "2024-04-11 07:23:19 UTC",
    "updated_date": "2024-04-11 07:23:19 UTC"
  },
  {
    "arxiv_id": "2404.08704v1",
    "title": "MM-PhyQA: Multimodal Physics Question-Answering With Multi-Image CoT Prompting",
    "authors": [
      "Avinash Anand",
      "Janak Kapuriya",
      "Apoorv Singh",
      "Jay Saraf",
      "Naman Lal",
      "Astha Verma",
      "Rushali Gupta",
      "Rajiv Shah"
    ],
    "abstract": "While Large Language Models (LLMs) can achieve human-level performance in\nvarious tasks, they continue to face challenges when it comes to effectively\ntackling multi-step physics reasoning tasks. To identify the shortcomings of\nexisting models and facilitate further research in this area, we curated a\nnovel dataset, MM-PhyQA, which comprises well-constructed, high schoollevel\nmultimodal physics problems. By evaluating the performance of contemporary LLMs\nthat are publicly available, both with and without the incorporation of\nmultimodal elements in these problems, we aim to shed light on their\ncapabilities. For generating answers for questions consisting of multimodal\ninput (in this case, images and text) we employed Zero-shot prediction using\nGPT-4 and utilized LLaVA (LLaVA and LLaVA-1.5), the latter of which were\nfine-tuned on our dataset. For evaluating the performance of LLMs consisting\nsolely of textual input, we tested the performance of the base and fine-tuned\nversions of the Mistral-7B and LLaMA2-7b models. We also showcased the\nperformance of the novel Multi-Image Chain-of-Thought (MI-CoT) Prompting\ntechnique, which when used to train LLaVA-1.5 13b yielded the best results when\ntested on our dataset, with superior scores in most metrics and the highest\naccuracy of 71.65% on the test set.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08704v1",
    "published_date": "2024-04-11 07:11:47 UTC",
    "updated_date": "2024-04-11 07:11:47 UTC"
  },
  {
    "arxiv_id": "2404.07511v1",
    "title": "Generative Probabilistic Planning for Optimizing Supply Chain Networks",
    "authors": [
      "Hyung-il Ahn",
      "Santiago Olivar",
      "Hershel Mehta",
      "Young Chol Song"
    ],
    "abstract": "Supply chain networks in enterprises are typically composed of complex\ntopological graphs involving various types of nodes and edges, accommodating\nnumerous products with considerable demand and supply variability. However, as\nsupply chain networks expand in size and complexity, traditional supply chain\nplanning methods (e.g., those found in heuristic rule-based and operations\nresearch-based systems) tend to become locally optimal or lack computational\nscalability, resulting in substantial imbalances between supply and demand\nacross nodes in the network. This paper introduces a novel Generative AI\ntechnique, which we call Generative Probabilistic Planning (GPP). GPP generates\ndynamic supply action plans that are globally optimized across all network\nnodes over the time horizon for changing objectives like maximizing profits or\nservice levels, factoring in time-varying probabilistic demand, lead time, and\nproduction conditions. GPP leverages attention-based graph neural networks\n(GNN), offline deep reinforcement learning (Offline RL), and policy simulations\nto train generative policy models and create optimal plans through\nprobabilistic simulations, effectively accounting for various uncertainties.\nOur experiments using historical data from a global consumer goods company with\ncomplex supply chain networks demonstrate that GPP accomplishes\nobjective-adaptable, probabilistically resilient, and dynamic planning for\nsupply chain networks, leading to significant improvements in performance and\nprofitability for enterprises. Our work plays a pivotal role in shaping the\ntrajectory of AI adoption within the supply chain domain.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07511v1",
    "published_date": "2024-04-11 07:06:58 UTC",
    "updated_date": "2024-04-11 07:06:58 UTC"
  },
  {
    "arxiv_id": "2404.07504v1",
    "title": "Mitigating Object Dependencies: Improving Point Cloud Self-Supervised Learning through Object Exchange",
    "authors": [
      "Yanhao Wu",
      "Tong Zhang",
      "Wei Ke",
      "Congpei Qiu",
      "Sabine Susstrunk",
      "Mathieu Salzmann"
    ],
    "abstract": "In the realm of point cloud scene understanding, particularly in indoor\nscenes, objects are arranged following human habits, resulting in objects of\ncertain semantics being closely positioned and displaying notable inter-object\ncorrelations. This can create a tendency for neural networks to exploit these\nstrong dependencies, bypassing the individual object patterns. To address this\nchallenge, we introduce a novel self-supervised learning (SSL) strategy. Our\napproach leverages both object patterns and contextual cues to produce robust\nfeatures. It begins with the formulation of an object-exchanging strategy,\nwhere pairs of objects with comparable sizes are exchanged across different\nscenes, effectively disentangling the strong contextual dependencies.\nSubsequently, we introduce a context-aware feature learning strategy, which\nencodes object patterns without relying on their specific context by\naggregating object features across various scenes. Our extensive experiments\ndemonstrate the superiority of our method over existing SSL techniques, further\nshowing its better robustness to environmental changes. Moreover, we showcase\nthe applicability of our approach by transferring pre-trained models to diverse\npoint cloud datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07504v1",
    "published_date": "2024-04-11 06:39:53 UTC",
    "updated_date": "2024-04-11 06:39:53 UTC"
  },
  {
    "arxiv_id": "2404.07502v1",
    "title": "Generating Counterfactual Explanations Using Cardinality Constraints",
    "authors": [
      "Rubén Ruiz-Torrubiano"
    ],
    "abstract": "Providing explanations about how machine learning algorithms work and/or make\nparticular predictions is one of the main tools that can be used to improve\ntheir trusworthiness, fairness and robustness. Among the most intuitive type of\nexplanations are counterfactuals, which are examples that differ from a given\npoint only in the prediction target and some set of features, presenting which\nfeatures need to be changed in the original example to flip the prediction for\nthat example. However, such counterfactuals can have many different features\nthan the original example, making their interpretation difficult. In this\npaper, we propose to explicitly add a cardinality constraint to counterfactual\ngeneration limiting how many features can be different from the original\nexample, thus providing more interpretable and easily understantable\ncounterfactuals.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07502v1",
    "published_date": "2024-04-11 06:33:19 UTC",
    "updated_date": "2024-04-11 06:33:19 UTC"
  },
  {
    "arxiv_id": "2404.07498v1",
    "title": "Interactive Prompt Debugging with Sequence Salience",
    "authors": [
      "Ian Tenney",
      "Ryan Mullins",
      "Bin Du",
      "Shree Pandya",
      "Minsuk Kahng",
      "Lucas Dixon"
    ],
    "abstract": "We present Sequence Salience, a visual tool for interactive prompt debugging\nwith input salience methods. Sequence Salience builds on widely used salience\nmethods for text classification and single-token prediction, and extends this\nto a system tailored for debugging complex LLM prompts. Our system is\nwell-suited for long texts, and expands on previous work by 1) providing\ncontrollable aggregation of token-level salience to the word, sentence, or\nparagraph level, making salience over long inputs tractable; and 2) supporting\nrapid iteration where practitioners can act on salience results, refine\nprompts, and run salience on the new output. We include case studies showing\nhow Sequence Salience can help practitioners work with several complex\nprompting strategies, including few-shot, chain-of-thought, and constitutional\nprinciples. Sequence Salience is built on the Learning Interpretability Tool,\nan open-source platform for ML model visualizations, and code, notebooks, and\ntutorials are available at http://goo.gle/sequence-salience.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07498v1",
    "published_date": "2024-04-11 06:22:56 UTC",
    "updated_date": "2024-04-11 06:22:56 UTC"
  },
  {
    "arxiv_id": "2404.08021v1",
    "title": "VeTraSS: Vehicle Trajectory Similarity Search Through Graph Modeling and Representation Learning",
    "authors": [
      "Ming Cheng",
      "Bowen Zhang",
      "Ziyu Wang",
      "Ziyi Zhou",
      "Weiqi Feng",
      "Yi Lyu",
      "Xingjian Diao"
    ],
    "abstract": "Trajectory similarity search plays an essential role in autonomous driving,\nas it enables vehicles to analyze the information and characteristics of\ndifferent trajectories to make informed decisions and navigate safely in\ndynamic environments. Existing work on the trajectory similarity search task\nprimarily utilizes sequence-processing algorithms or Recurrent Neural Networks\n(RNNs), which suffer from the inevitable issues of complicated architecture and\nheavy training costs. Considering the intricate connections between\ntrajectories, using Graph Neural Networks (GNNs) for data modeling is feasible.\nHowever, most methods directly use existing mathematical graph structures as\nthe input instead of constructing specific graphs from certain vehicle\ntrajectory data. This ignores such data's unique and dynamic characteristics.\nTo bridge such a research gap, we propose VeTraSS -- an end-to-end pipeline for\nVehicle Trajectory Similarity Search. Specifically, VeTraSS models the original\ntrajectory data into multi-scale graphs, and generates comprehensive embeddings\nthrough a novel multi-layer attention-based GNN. The learned embeddings can be\nused for searching similar vehicle trajectories. Extensive experiments on the\nPorto and Geolife datasets demonstrate the effectiveness of VeTraSS, where our\nmodel outperforms existing work and reaches the state-of-the-art. This\ndemonstrates the potential of VeTraSS for trajectory analysis and safe\nnavigation in self-driving vehicles in the real world.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08021v1",
    "published_date": "2024-04-11 06:19:55 UTC",
    "updated_date": "2024-04-11 06:19:55 UTC"
  },
  {
    "arxiv_id": "2404.07493v1",
    "title": "Characterizing the Influence of Topology on Graph Learning Tasks",
    "authors": [
      "Kailong Wu",
      "Yule Xie",
      "Jiaxin Ding",
      "Yuxiang Ren",
      "Luoyi Fu",
      "Xinbing Wang",
      "Chenghu Zhou"
    ],
    "abstract": "Graph neural networks (GNN) have achieved remarkable success in a wide range\nof tasks by encoding features combined with topology to create effective\nrepresentations. However, the fundamental problem of understanding and\nanalyzing how graph topology influences the performance of learning models on\ndownstream tasks has not yet been well understood. In this paper, we propose a\nmetric, TopoInf, which characterizes the influence of graph topology by\nmeasuring the level of compatibility between the topological information of\ngraph data and downstream task objectives. We provide analysis based on the\ndecoupled GNNs on the contextual stochastic block model to demonstrate the\neffectiveness of the metric. Through extensive experiments, we demonstrate that\nTopoInf is an effective metric for measuring topological influence on\ncorresponding tasks and can be further leveraged to enhance graph learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07493v1",
    "published_date": "2024-04-11 06:04:06 UTC",
    "updated_date": "2024-04-11 06:04:06 UTC"
  },
  {
    "arxiv_id": "2404.08020v1",
    "title": "Augmenting Knowledge Graph Hierarchies Using Neural Transformers",
    "authors": [
      "Sanat Sharma",
      "Mayank Poddar",
      "Jayant Kumar",
      "Kosta Blank",
      "Tracy King"
    ],
    "abstract": "Knowledge graphs are useful tools to organize, recommend and sort data.\nHierarchies in knowledge graphs provide significant benefit in improving\nunderstanding and compartmentalization of the data within a knowledge graph.\nThis work leverages large language models to generate and augment hierarchies\nin an existing knowledge graph. For small (<100,000 node) domain-specific KGs,\nwe find that a combination of few-shot prompting with one-shot generation works\nwell, while larger KG may require cyclical generation. We present techniques\nfor augmenting hierarchies, which led to coverage increase by 98% for intents\nand 99% for colors in our knowledge graph.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "European Conference on Information Retrieval 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.08020v1",
    "published_date": "2024-04-11 05:53:38 UTC",
    "updated_date": "2024-04-11 05:53:38 UTC"
  },
  {
    "arxiv_id": "2404.07484v1",
    "title": "Multimodal Emotion Recognition by Fusing Video Semantic in MOOC Learning Scenarios",
    "authors": [
      "Yuan Zhang",
      "Xiaomei Tao",
      "Hanxu Ai",
      "Tao Chen",
      "Yanling Gan"
    ],
    "abstract": "In the Massive Open Online Courses (MOOC) learning scenario, the semantic\ninformation of instructional videos has a crucial impact on learners' emotional\nstate. Learners mainly acquire knowledge by watching instructional videos, and\nthe semantic information in the videos directly affects learners' emotional\nstates. However, few studies have paid attention to the potential influence of\nthe semantic information of instructional videos on learners' emotional states.\nTo deeply explore the impact of video semantic information on learners'\nemotions, this paper innovatively proposes a multimodal emotion recognition\nmethod by fusing video semantic information and physiological signals. We\ngenerate video descriptions through a pre-trained large language model (LLM) to\nobtain high-level semantic information about instructional videos. Using the\ncross-attention mechanism for modal interaction, the semantic information is\nfused with the eye movement and PhotoPlethysmoGraphy (PPG) signals to obtain\nthe features containing the critical information of the three modes. The\naccurate recognition of learners' emotional states is realized through the\nemotion classifier. The experimental results show that our method has\nsignificantly improved emotion recognition performance, providing a new\nperspective and efficient method for emotion recognition research in MOOC\nlearning scenarios. The method proposed in this paper not only contributes to a\ndeeper understanding of the impact of instructional videos on learners'\nemotional states but also provides a beneficial reference for future research\non emotion recognition in MOOC learning scenarios.",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07484v1",
    "published_date": "2024-04-11 05:44:27 UTC",
    "updated_date": "2024-04-11 05:44:27 UTC"
  },
  {
    "arxiv_id": "2404.07475v2",
    "title": "Laissez-Faire Harms: Algorithmic Biases in Generative Language Models",
    "authors": [
      "Evan Shieh",
      "Faye-Marie Vassel",
      "Cassidy Sugimoto",
      "Thema Monroe-White"
    ],
    "abstract": "The rapid deployment of generative language models (LMs) has raised concerns\nabout social biases affecting the well-being of diverse consumers. The extant\nliterature on generative LMs has primarily examined bias via explicit identity\nprompting. However, prior research on bias in earlier language-based technology\nplatforms, including search engines, has shown that discrimination can occur\neven when identity terms are not specified explicitly. Studies of bias in LM\nresponses to open-ended prompts (where identity classifications are left\nunspecified) are lacking and have not yet been grounded in end-consumer harms.\nHere, we advance studies of generative LM bias by considering a broader set of\nnatural use cases via open-ended prompting. In this \"laissez-faire\" setting, we\nfind that synthetically generated texts from five of the most pervasive LMs\n(ChatGPT3.5, ChatGPT4, Claude2.0, Llama2, and PaLM2) perpetuate harms of\nomission, subordination, and stereotyping for minoritized individuals with\nintersectional race, gender, and/or sexual orientation identities (AI/AN,\nAsian, Black, Latine, MENA, NH/PI, Female, Non-binary, Queer). We find\nwidespread evidence of bias to an extent that such individuals are hundreds to\nthousands of times more likely to encounter LM-generated outputs that portray\ntheir identities in a subordinated manner compared to representative or\nempowering portrayals. We also document a prevalence of stereotypes (e.g.\nperpetual foreigner) in LM-generated outputs that are known to trigger\npsychological harms that disproportionately affect minoritized individuals.\nThese include stereotype threat, which leads to impaired cognitive performance\nand increased negative self-perception. Our findings highlight the urgent need\nto protect consumers from discriminatory harms caused by language models and\ninvest in critical AI education programs tailored towards empowering diverse\nconsumers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages (43 if including supplementals), 8 figures (23 if including\n  supplementals)",
    "pdf_url": "http://arxiv.org/pdf/2404.07475v2",
    "published_date": "2024-04-11 05:09:03 UTC",
    "updated_date": "2024-04-16 04:07:42 UTC"
  },
  {
    "arxiv_id": "2404.07471v1",
    "title": "Structure-aware Fine-tuning for Code Pre-trained Models",
    "authors": [
      "Jiayi Wu",
      "Renyu Zhu",
      "Nuo Chen",
      "Qiushi Sun",
      "Xiang Li",
      "Ming Gao"
    ],
    "abstract": "Over the past few years, we have witnessed remarkable advancements in Code\nPre-trained Models (CodePTMs). These models achieved excellent representation\ncapabilities by designing structure-based pre-training tasks for code. However,\nhow to enhance the absorption of structural knowledge when fine-tuning CodePTMs\nstill remains a significant challenge. To fill this gap, in this paper, we\npresent Structure-aware Fine-tuning (SAT), a novel structure-enhanced and\nplug-and-play fine-tuning method for CodePTMs. We first propose a structure\nloss to quantify the difference between the information learned by CodePTMs and\nthe knowledge extracted from code structure. Specifically, we use the attention\nscores extracted from Transformer layer as the learned structural information,\nand the shortest path length between leaves in abstract syntax trees as the\nstructural knowledge. Subsequently, multi-task learning is introduced to\nimprove the performance of fine-tuning. Experiments conducted on four\npre-trained models and two generation tasks demonstrate the effectiveness of\nour proposed method as a plug-and-play solution. Furthermore, we observed that\nSAT can benefit CodePTMs more with limited training data.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.07471v1",
    "published_date": "2024-04-11 04:24:48 UTC",
    "updated_date": "2024-04-11 04:24:48 UTC"
  },
  {
    "arxiv_id": "2404.07461v2",
    "title": "An Audit on the Perspectives and Challenges of Hallucinations in NLP",
    "authors": [
      "Pranav Narayanan Venkit",
      "Tatiana Chakravorti",
      "Vipul Gupta",
      "Heidi Biggs",
      "Mukund Srinath",
      "Koustava Goswami",
      "Sarah Rajtmajer",
      "Shomir Wilson"
    ],
    "abstract": "We audit how hallucination in large language models (LLMs) is characterized\nin peer-reviewed literature, using a critical examination of 103 publications\nacross NLP research. Through the examination of the literature, we identify a\nlack of agreement with the term `hallucination' in the field of NLP.\nAdditionally, to compliment our audit, we conduct a survey with 171\npractitioners from the field of NLP and AI to capture varying perspectives on\nhallucination. Our analysis calls for the necessity of explicit definitions and\nframeworks outlining hallucination within NLP, highlighting potential\nchallenges, and our survey inputs provide a thematic understanding of the\ninfluence and ramifications of hallucination in society.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07461v2",
    "published_date": "2024-04-11 03:51:29 UTC",
    "updated_date": "2024-09-14 03:14:09 UTC"
  },
  {
    "arxiv_id": "2404.07456v1",
    "title": "WESE: Weak Exploration to Strong Exploitation for LLM Agents",
    "authors": [
      "Xu Huang",
      "Weiwen Liu",
      "Xiaolong Chen",
      "Xingmei Wang",
      "Defu Lian",
      "Yasheng Wang",
      "Ruiming Tang",
      "Enhong Chen"
    ],
    "abstract": "Recently, large language models (LLMs) have demonstrated remarkable potential\nas an intelligent agent. However, existing researches mainly focus on enhancing\nthe agent's reasoning or decision-making abilities through well-designed prompt\nengineering or task-specific fine-tuning, ignoring the procedure of exploration\nand exploitation. When addressing complex tasks within open-world interactive\nenvironments, these methods exhibit limitations. Firstly, the lack of global\ninformation of environments leads to greedy decisions, resulting in sub-optimal\nsolutions. On the other hand, irrelevant information acquired from the\nenvironment not only adversely introduces noise, but also incurs additional\ncost. This paper proposes a novel approach, Weak Exploration to Strong\nExploitation (WESE), to enhance LLM agents in solving open-world interactive\ntasks. Concretely, WESE involves decoupling the exploration and exploitation\nprocess, employing a cost-effective weak agent to perform exploration tasks for\nglobal knowledge. A knowledge graph-based strategy is then introduced to store\nthe acquired knowledge and extract task-relevant knowledge, enhancing the\nstronger agent in success rate and efficiency for the exploitation task. Our\napproach is flexible enough to incorporate diverse tasks, and obtains\nsignificant improvements in both success rates and efficiency across four\ninteractive benchmarks.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07456v1",
    "published_date": "2024-04-11 03:31:54 UTC",
    "updated_date": "2024-04-11 03:31:54 UTC"
  },
  {
    "arxiv_id": "2404.07452v2",
    "title": "RiskLabs: Predicting Financial Risk Using Large Language Model based on Multimodal and Multi-Sources Data",
    "authors": [
      "Yupeng Cao",
      "Zhi Chen",
      "Prashant Kumar",
      "Qingyun Pei",
      "Yangyang Yu",
      "Haohang Li",
      "Fabrizio Dimino",
      "Lorenzo Ausiello",
      "K. P. Subbalakshmi",
      "Papa Momar Ndiaye"
    ],
    "abstract": "The integration of Artificial Intelligence (AI) techniques, particularly\nlarge language models (LLMs), in finance has garnered increasing academic\nattention. Despite progress, existing studies predominantly focus on tasks like\nfinancial text summarization, question-answering, and stock movement prediction\n(binary classification), the application of LLMs to financial risk prediction\nremains underexplored. Addressing this gap, in this paper, we introduce\nRiskLabs, a novel framework that leverages LLMs to analyze and predict\nfinancial risks. RiskLabs uniquely integrates multimodal financial data,\nincluding textual and vocal information from Earnings Conference Calls (ECCs),\nmarket-related time series data, and contextual news data to improve financial\nrisk prediction. Empirical results demonstrate RiskLabs' effectiveness in\nforecasting both market volatility and variance. Through comparative\nexperiments, we examine the contributions of different data sources to\nfinancial risk assessment and highlight the crucial role of LLMs in this\nprocess. We also discuss the challenges associated with using LLMs for\nfinancial risk prediction and explore the potential of combining them with\nmultimodal data for this purpose.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "q-fin.PM"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07452v2",
    "published_date": "2024-04-11 03:14:50 UTC",
    "updated_date": "2025-05-03 01:01:19 UTC"
  },
  {
    "arxiv_id": "2404.07446v2",
    "title": "Graph Attention Network for Lane-Wise and Topology-Invariant Intersection Traffic Simulation",
    "authors": [
      "Nooshin Yousefzadeh",
      "Rahul Sengupta",
      "Yashaswi Karnati",
      "Anand Rangarajan",
      "Sanjay Ranka"
    ],
    "abstract": "Traffic congestion has significant economic, environmental, and social\nramifications. Intersection traffic flow dynamics are influenced by numerous\nfactors. While microscopic traffic simulators are valuable tools, they are\ncomputationally intensive and challenging to calibrate. Moreover, existing\nmachine-learning approaches struggle to provide lane-specific waveforms or\nadapt to intersection topology and traffic patterns. In this study, we propose\ntwo efficient and accurate \"Digital Twin\" models for intersections, leveraging\nGraph Attention Neural Networks (GAT). These attentional graph auto-encoder\ndigital twins capture temporal, spatial, and contextual aspects of traffic\nwithin intersections, incorporating various influential factors such as\nhigh-resolution loop detector waveforms, signal state records, driving\nbehaviors, and turning-movement counts. Trained on diverse counterfactual\nscenarios across multiple intersections, our models generalize well, enabling\nthe estimation of detailed traffic waveforms for any intersection approach and\nexit lanes. Multi-scale error metrics demonstrate that our models perform\ncomparably to microsimulations. The primary application of our study lies in\ntraffic signal optimization, a pivotal area in transportation systems research.\nThese lightweight digital twins can seamlessly integrate into corridor and\nnetwork signal timing optimization frameworks. Furthermore, our study's\napplications extend to lane reconfiguration, driving behavior analysis, and\nfacilitating informed decisions regarding intersection safety and efficiency\nenhancements. A promising avenue for future research involves extending this\napproach to urban freeway corridors and integrating it with measures of\neffectiveness metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "T-TIS Journal, 12 pages, 8 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.07446v2",
    "published_date": "2024-04-11 03:02:06 UTC",
    "updated_date": "2024-05-02 00:39:01 UTC"
  },
  {
    "arxiv_id": "2404.07439v1",
    "title": "Behavior Trees Enable Structured Programming of Language Model Agents",
    "authors": [
      "Richard Kelley"
    ],
    "abstract": "Language models trained on internet-scale data sets have shown an impressive\nability to solve problems in Natural Language Processing and Computer Vision.\nHowever, experience is showing that these models are frequently brittle in\nunexpected ways, and require significant scaffolding to ensure that they\noperate correctly in the larger systems that comprise \"language-model agents.\"\nIn this paper, we argue that behavior trees provide a unifying framework for\ncombining language models with classical AI and traditional programming. We\nintroduce Dendron, a Python library for programming language model agents using\nbehavior trees. We demonstrate the approach embodied by Dendron in three case\nstudies: building a chat agent, a camera-based infrastructure inspection agent\nfor use on a mobile robot or vehicle, and an agent that has been built to\nsatisfy safety constraints that it did not receive through instruction tuning\nor RLHF.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07439v1",
    "published_date": "2024-04-11 02:44:13 UTC",
    "updated_date": "2024-04-11 02:44:13 UTC"
  },
  {
    "arxiv_id": "2404.07434v1",
    "title": "Data-Driven Portfolio Management for Motion Pictures Industry: A New Data-Driven Optimization Methodology Using a Large Language Model as the Expert",
    "authors": [
      "Mohammad Alipour-Vaezi",
      "Kwok-Leung Tsui"
    ],
    "abstract": "Portfolio management is one of the unresponded problems of the Motion\nPictures Industry (MPI). To design an optimal portfolio for an MPI distributor,\nit is essential to predict the box office of each project. Moreover, for an\naccurate box office prediction, it is critical to consider the effect of the\ncelebrities involved in each MPI project, which was impossible with any\nprecedent expert-based method. Additionally, the asymmetric characteristic of\nMPI data decreases the performance of any predictive algorithm. In this paper,\nfirstly, the fame score of the celebrities is determined using a large language\nmodel. Then, to tackle the asymmetric character of MPI's data, projects are\nclassified. Furthermore, the box office prediction takes place for each class\nof projects. Finally, using a hybrid multi-attribute decision-making technique,\nthe preferability of each project for the distributor is calculated, and\nbenefiting from a bi-objective optimization model, the optimal portfolio is\ndesigned.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07434v1",
    "published_date": "2024-04-11 02:23:30 UTC",
    "updated_date": "2024-04-11 02:23:30 UTC"
  },
  {
    "arxiv_id": "2404.07413v1",
    "title": "JetMoE: Reaching Llama2 Performance with 0.1M Dollars",
    "authors": [
      "Yikang Shen",
      "Zhen Guo",
      "Tianle Cai",
      "Zengyi Qin"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable results, but their\nincreasing resource demand has become a major obstacle to the development of\npowerful and accessible super-human intelligence. This report introduces\nJetMoE-8B, a new LLM trained with less than $0.1 million, using 1.25T tokens\nfrom carefully mixed open-source corpora and 30,000 H100 GPU hours. Despite its\nlow cost, the JetMoE-8B demonstrates impressive performance, with JetMoE-8B\noutperforming the Llama2-7B model and JetMoE-8B-Chat surpassing the\nLlama2-13B-Chat model. These results suggest that LLM training can be much more\ncost-effective than generally thought. JetMoE-8B is based on an efficient\nSparsely-gated Mixture-of-Experts (SMoE) architecture, composed of attention\nand feedforward experts. Both layers are sparsely activated, allowing JetMoE-8B\nto have 8B parameters while only activating 2B for each input token, reducing\ninference computation by about 70% compared to Llama2-7B. Moreover, JetMoE-8B\nis highly open and academia-friendly, using only public datasets and training\ncode. All training parameters and data mixtures have been detailed in this\nreport to facilitate future efforts in the development of open foundation\nmodels. This transparency aims to encourage collaboration and further\nadvancements in the field of accessible and efficient LLMs. The model weights\nare publicly available at https://github.com/myshell-ai/JetMoE.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07413v1",
    "published_date": "2024-04-11 00:52:39 UTC",
    "updated_date": "2024-04-11 00:52:39 UTC"
  },
  {
    "arxiv_id": "2404.07396v3",
    "title": "Can Base ChatGPT be Used for Forecasting without Additional Optimization?",
    "authors": [
      "Van Pham",
      "Scott Cunningham"
    ],
    "abstract": "This study investigates whether OpenAI's ChatGPT-3.5 and ChatGPT-4 can\nforecast future events. To evaluate the accuracy of the predictions, we take\nadvantage of the fact that the training data at the time of our experiments\n(mid 2023) stopped at September 2021, and ask about events that happened in\n2022. We employed two prompting strategies: direct prediction and what we call\nfuture narratives which ask ChatGPT to tell fictional stories set in the future\nwith characters retelling events that happened in the past, but after ChatGPT's\ntraining data had been collected. We prompted ChatGPT to engage in\nstorytelling, particularly within economic contexts. After analyzing 100\ntrials, we find that future narrative prompts significantly enhanced\nChatGPT-4's forecasting accuracy. This was especially evident in its\npredictions of major Academy Award winners as well as economic trends, the\nlatter inferred from scenarios where the model impersonated public figures like\nthe Federal Reserve Chair, Jerome Powell. As a falsification exercise, we\nrepeated our experiments in May 2024 at which time the models included more\nrecent training data. ChatGPT-4's accuracy significantly improved when the\ntraining window included the events being prompted for, achieving 100% accuracy\nin many instances. The poorer accuracy for events outside of the training\nwindow suggests that in the 2023 prediction experiments, ChatGPT-4 was forming\npredictions based solely on its training data. Narrative prompting also\nconsistently outperformed direct prompting. These findings indicate that\nnarrative prompts leverage the models' capacity for hallucinatory narrative\nconstruction, facilitating more effective data synthesis and extrapolation than\nstraightforward predictions. Our research reveals new aspects of LLMs'\npredictive capabilities and suggests potential future applications in\nanalytical contexts.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "77 pages, added falsification exercises in section `Post\n  Scriptum:...' with new figures; new title 61 pages, 26 figures; corrected\n  typos",
    "pdf_url": "http://arxiv.org/pdf/2404.07396v3",
    "published_date": "2024-04-11 00:03:03 UTC",
    "updated_date": "2024-07-04 23:03:45 UTC"
  }
]