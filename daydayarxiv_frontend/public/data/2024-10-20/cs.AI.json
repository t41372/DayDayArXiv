{
  "date": "2024-10-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-20 的 arXiv 中文 TLDR 快报！今天的 arXiv 论文主要聚焦 AI 模型的安全性、改进和应用，尤其在大型语言模型（LLMs）、图像处理和机器人领域，亮点包括高效的 LLM 越狱攻击防御、多模态生成模型的创新，以及 NeurIPS 等会议相关工作，知名学者如 Sebastian Stober 和 Yong Li 的论文值得关注。\n\n### 重点论文讨论\n我将优先选取重要、话题性和影响大的论文（如涉及 LLM 安全、AI 伦理和高效算法的），并将相关主题归类讨论。对于次要论文，只简要概述以控制篇幅。以下按主题分组，列出论文标题（中文 + 英文）和核心贡献。\n\n#### LLM 安全与改进（高话题度领域）\n- **Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning** (缓解 LLM 监督微调和偏好学习的遗忘问题)：这篇论文提出一个联合训练框架，理论证明并实证显示它能减少 LLM 在微调阶段的灾难性遗忘，同时保持计算效率，与传统顺序训练相比性能更优。\n- **Jailbreaking and Mitigation of Vulnerabilities in Large Language Models** (大型语言模型的越狱攻击与缓解)：作者分析 LLM 的提示注入漏洞，分类攻击类型（如提示基和多模态攻击），并评估防御策略，如提示过滤和对齐技术，强调未来研究需关注自动化检测和伦理影响。\n- **Faster-GCG: Efficient Discrete Optimization Jailbreak Attacks against Aligned Large Language Models** (更高效的离散优化越狱攻击)：论文引入 Faster-GCG 算法，显著提升对对齐 LLM 的攻击成功率，仅需原方法 1/10 计算成本，展示了 LLM 安全性的潜在风险。\n- **Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training** (缓解 LLM 幻觉的敏感性 Dropout)：提出 SenD 训练协议，通过减少权重变异来降低幻觉，结合新指标 Efficient EigenScore，提升模型在维基百科和医疗领域的准确性。\n- **Exploring Social Desirability Response Bias in Large Language Models** (探索 LLM 中的社会期望偏差)：这篇快速掠过的论文使用 GPT-4 模拟调查，揭示 LLM 在决策中可能存在偏差，但其影响有限。\n\n这些论文突出了 LLM 的安全挑战，是本日最值得关注的，涉及实际应用风险和改进策略。\n\n#### 图像处理与多模态生成（技术创新突出）\n- **FrameBridge: Improving Image-to-Video Generation with Bridge Models** (使用桥接模型提升图像到视频生成)：创新性地将桥接模型应用于图像到视频转换，提出 SNR-Aligned Fine-tuning 和神经先验，显著提升生成质量（e.g., FVD 指标优于扩散模型）。\n- **Synergistic Dual Spatial-aware Generation of Image-to-Text and Text-to-Image** (协同双向空间感知生成：图像到文本和文本到图像)：论文开发 3D 场景图表示和 Spatial Dual Discrete Diffusion 框架，使图像到文本和文本到图像任务互惠，提升了视觉空间理解性能。\n- **AttCDCNet: Attention-enhanced Chest Disease Classification using X-Ray Images** (注意力增强的 X 光图像胸部疾病分类)：基于 DenseNet121 的改进模型，添加注意力块和焦点损失，实现了 94.94% 的准确率，显著提升医疗图像诊断的鲁棒性。\n\n这些工作在多模态 AI 上有突破，尤其 FrameBridge 的桥接机制值得进一步探索。\n\n#### 机器人与自动驾驶（应用潜力高）\n- **SEA: State-Exchange Attention for High-Fidelity Physics Based Transformers** (状态交换注意力用于高保真物理 Transformer)：NeurIPS 相关论文，引入 SEA 模块和 ViT-like 编码器，减少物理模拟中的 rollout 错误（误差降低 88%），适用于动态系统建模。\n- **Generative AI Agents in Autonomous Machines: A Safety Perspective** (生成式 AI 代理在自主机器中的安全视角)：作者 Jason Jabbour 和 Vijay Janapa Reddi 讨论生成 AI 在自动驾驶中的安全挑战，推荐开发安全评分卡以评估风险。\n- **AssemblyComplete: 3D Combinatorial Construction with Deep Reinforcement Learning** (使用深度强化学习的 3D 组合构建)：提出 DRL 框架，让机器人理解并完成不完整装配，处理物理约束，如稳定性，适用于实际机器人任务。\n\n这些论文强调 AI 在物理世界的应用，SEA 的高效性特别令人印象深刻。\n\n#### 其他值得一提的论文（快速概述）\n- **M-RewardBench: Evaluating Reward Models in Multilingual Settings** (多语言设置下的奖励模型评估)：构建多语言基准（23 种语言），评估 LLM 奖励模型的表现，揭示非英语语言的性能差距。\n- **Anonymising Elderly and Pathological Speech: Voice Conversion Using DDSP and Query-by-Example** (匿名化老年和病理语音：使用 DDSP 和查询示例的语音转换)：Interspeech 接受，提出 DDSP-QbE 方法，保留语音智能性和匿名性，适用于健康监测。\n- **log-RRIM: Yield Prediction via Local-to-global Reaction Representation Learning** (局部到全局反应表示学习的产率预测)：使用图 Transformer 预测化学反应产率，焦点在试剂-反应中心交互建模。\n- **Economic Anthropology in the Era of Generative Artificial Intelligence** (生成式 AI 时代下的经济人类学)：探讨 AI 如何模拟人类决策，引入新模型 C.A.L.L.O.N. 和 M.A.U.S.S.，但主题较 niche，仅快速提及。\n\n其余论文（如一些小规模实验或重复主题，如其他图像分类或简单优化方法）未详细展开，以节省篇幅，它们多为特定领域的小改进，无显著突破。\n\n总之，今天的 arXiv 强调 AI 的安全性和创新应用，LLM 相关论文尤其活跃，建议读者关注这些前沿工作以把握 AI 发展趋势。明日见！",
  "papers": [
    {
      "arxiv_id": "2410.15536v2",
      "title": "GRS: Generating Robotic Simulation Tasks from Real-World Images",
      "title_zh": "GRS: 从真实世界图像生成机器人模拟任务",
      "authors": [
        "Alex Zook",
        "Fan-Yun Sun",
        "Josef Spjut",
        "Valts Blukis",
        "Stan Birchfield",
        "Jonathan Tremblay"
      ],
      "abstract": "We introduce GRS (Generating Robotic Simulation tasks), a system addressing\nreal-to-sim for robotic simulations. GRS creates digital twin simulations from\nsingle RGB-D observations with solvable tasks for virtual agent training. Using\nvision-language models (VLMs), our pipeline operates in three stages: 1) scene\ncomprehension with SAM2 for segmentation and object description, 2) matching\nobjects with simulation-ready assets, and 3) generating appropriate tasks. We\nensure simulation-task alignment through generated test suites and introduce a\nrouter that iteratively refines both simulation and test code. Experiments\ndemonstrate our system's effectiveness in object correspondence and task\nenvironment generation through our novel router mechanism.",
      "tldr_zh": "该研究提出 GRS 系统，用于从真实世界 RGB-D 图像生成机器人模拟任务，从而创建数字孪生模拟环境以训练虚拟代理。系统采用三阶段管道：1) 使用 SAM2 进行场景理解，包括分割和对象描述；2) 将对象与模拟就绪资产匹配；3) 生成适当的任务，并通过路由器迭代完善模拟和测试代码以确保对齐。实验结果显示，GRS 在对象对应和任务环境生成方面表现出色，证明了其新型路由器机制的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15536v2",
      "published_date": "2024-10-20 23:33:06 UTC",
      "updated_date": "2025-04-04 23:56:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:55:07.566021"
    },
    {
      "arxiv_id": "2410.15528v1",
      "title": "Improving Clinical Documentation with AI: A Comparative Study of Sporo AI Scribe and GPT-4o mini",
      "title_zh": "翻译失败",
      "authors": [
        "Chanseo Lee",
        "Sonu Kumar",
        "Kimon A. Vogt",
        "Sam Meraj"
      ],
      "abstract": "AI-powered medical scribes have emerged as a promising solution to alleviate\nthe documentation burden in healthcare. Ambient AI scribes provide real-time\ntranscription and automated data entry into Electronic Health Records (EHRs),\nwith the potential to improve efficiency, reduce costs, and enhance\nscalability. Despite early success, the accuracy of AI scribes remains\ncritical, as errors can lead to significant clinical consequences.\nAdditionally, AI scribes face challenges in handling the complexity and\nvariability of medical language and ensuring the privacy of sensitive patient\ndata. This case study aims to evaluate Sporo Health's AI scribe, a multi-agent\nsystem leveraging fine-tuned medical LLMs, by comparing its performance with\nOpenAI's GPT-4o Mini on multiple performance metrics. Using a dataset of\nde-identified patient conversation transcripts, AI-generated summaries were\ncompared to clinician-generated notes (the ground truth) based on clinical\ncontent recall, precision, and F1 scores. Evaluations were further supplemented\nby clinician satisfaction assessments using a modified Physician Documentation\nQuality Instrument revision 9 (PDQI-9), rated by both a medical student and a\nphysician. The results show that Sporo AI consistently outperformed GPT-4o\nMini, achieving higher recall, precision, and overall F1 scores. Moreover, the\nAI generated summaries provided by Sporo were rated more favorably in terms of\naccuracy, comprehensiveness, and relevance, with fewer hallucinations. These\nfindings demonstrate that Sporo AI Scribe is an effective and reliable tool for\nclinical documentation, enhancing clinician workflows while maintaining high\nstandards of privacy and security.",
      "tldr_zh": "这篇论文比较了Sporo AI Scribe（一个基于fine-tuned medical LLMs的多智能体系统）和GPT-4o Mini在临床文档方面的性能，旨在评估AI辅助工具减轻医疗记录负担的效果。研究使用去标识化的患者对话数据集，对AI生成的摘要与临床医生笔记进行比较，基于临床内容召回、精确度和F1 scores等指标，以及修改后的PDQI-9评估临床医生满意度。结果显示，Sporo AI Scribe在召回、精确度和整体F1 scores上均优于GPT-4o Mini，提供更准确、全面且相关性的摘要，同时减少了幻觉。总体而言，这证明Sporo AI Scribe是提升临床工作流程的可靠工具，能提高效率并维护EHRs的隐私和安全。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15528v1",
      "published_date": "2024-10-20 22:48:40 UTC",
      "updated_date": "2024-10-20 22:48:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:55:21.321338"
    },
    {
      "arxiv_id": "2410.15522v2",
      "title": "M-RewardBench: Evaluating Reward Models in Multilingual Settings",
      "title_zh": "M-RewardBench：多语言环境下的奖励模型评估",
      "authors": [
        "Srishti Gureja",
        "Lester James V. Miranda",
        "Shayekh Bin Islam",
        "Rishabh Maheshwary",
        "Drishti Sharma",
        "Gusti Winata",
        "Nathan Lambert",
        "Sebastian Ruder",
        "Sara Hooker",
        "Marzieh Fadaee"
      ],
      "abstract": "Reward models (RMs) have driven the state-of-the-art performance of LLMs\ntoday by enabling the integration of human feedback into the language modeling\nprocess. However, RMs are primarily trained and evaluated in English, and their\ncapabilities in multilingual settings remain largely understudied. In this\nwork, we conduct a systematic evaluation of several reward models in\nmultilingual settings. We first construct the first-of-its-kind multilingual RM\nevaluation benchmark, M-RewardBench, consisting of 2.87k preference instances\nfor 23 typologically diverse languages, that tests the chat, safety, reasoning,\nand translation capabilities of RMs. We then rigorously evaluate a wide range\nof reward models on M-RewardBench, offering fresh insights into their\nperformance across diverse languages. We identify a significant gap in RMs'\nperformances between English and non-English languages and show that RM\npreferences can change substantially from one language to another. We also\npresent several findings on how different multilingual aspects impact RM\nperformance. Specifically, we show that the performance of RMs is improved with\nimproved translation quality. Similarly, we demonstrate that the models exhibit\nbetter performance for high-resource languages. We release M-RewardBench\ndataset and the codebase in this study to facilitate a better understanding of\nRM evaluation in multilingual settings.",
      "tldr_zh": "该研究构建了首个多语言奖励模型(RMs)评估基准 M-RewardBench，包含 2.87k 个偏好实例，覆盖 23 种语言多样性，测试 RMs 在聊天、安全、推理和翻译等方面的能力。\n通过系统评估多种 RMs，研究发现这些模型在英语和非英语语言之间存在显著性能差距，且偏好在不同语言间可能发生实质性变化。\n此外，分析表明，翻译质量的提升和高资源语言的使用能显著改善 RMs 性能。\n该工作发布了数据集和代码，以推动对多语言 RMs 评估的深入理解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 6 figures, 10 tables. Website:\n  https://m-rewardbench.github.io/ , Updated results with latest models. Added\n  more author information",
      "pdf_url": "http://arxiv.org/pdf/2410.15522v2",
      "published_date": "2024-10-20 22:09:44 UTC",
      "updated_date": "2024-10-29 03:28:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:55:33.733675"
    },
    {
      "arxiv_id": "2410.15509v1",
      "title": "Exploring Curriculum Learning for Vision-Language Tasks: A Study on Small-Scale Multimodal Training",
      "title_zh": "翻译失败",
      "authors": [
        "Rohan Saha",
        "Abrar Fahim",
        "Alona Fyshe",
        "Alex Murphy"
      ],
      "abstract": "For specialized domains, there is often not a wealth of data with which to\ntrain large machine learning models. In such limited data / compute settings,\nvarious methods exist aiming to $\\textit{do more with less}$, such as\nfinetuning from a pretrained model, modulating difficulty levels as data are\npresented to a model (curriculum learning), and considering the role of model\ntype / size. Approaches to efficient $\\textit{machine}$ learning also take\ninspiration from $\\textit{human}$ learning by considering use cases where\nmachine learning systems have access to approximately the same number of words\nexperienced by a 13 year old child (100M words). We investigate the role of 3\nprimary variables in a limited data regime as part of the multimodal track of\nthe BabyLM challenge. We contrast: (i) curriculum learning, (ii), pretraining\n(with text-only data), (iii) model type. We modulate these variables and assess\nthem on two types of tasks: (a) multimodal (text+image), and (b) unimodal\n(text-only) tasks. We find that curriculum learning benefits multimodal\nevaluations over non-curriclum learning models, particularly when combining\ntext-only pretraining. On text-only tasks, curriculum learning appears to help\nmodels with smaller trainable parameter counts. We suggest possible reasons\nbased on architectural differences and training designs as to why one might\nobserve such results.",
      "tldr_zh": "本研究探讨了课程学习(Curriculum Learning)在视觉-语言任务中的作用，特别是在数据和计算资源有限的小规模多模态训练场景下。研究者对比了三个关键变量——(i) 课程学习，(ii) 文本-only预训练，(iii) 模型类型——并在BabyLM挑战的多模态（文本+图像）和单模态（文本-only）任务上进行评估。结果显示，课程学习显著提升了多模态任务的性能，尤其是与预训练结合时；而在文本-only任务中，它对参数较小的模型特别有益，可能归因于架构差异和训练设计差异。总的来说，该研究为高效机器学习提供了新见解，强调了课程学习在资源受限环境中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "CoNLL BabyLM Challenge 2024 camera ready",
      "pdf_url": "http://arxiv.org/pdf/2410.15509v1",
      "published_date": "2024-10-20 21:03:51 UTC",
      "updated_date": "2024-10-20 21:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:55:45.350357"
    },
    {
      "arxiv_id": "2410.15500v1",
      "title": "Anonymising Elderly and Pathological Speech: Voice Conversion Using DDSP and Query-by-Example",
      "title_zh": "翻译失败",
      "authors": [
        "Suhita Ghosh",
        "Melanie Jouaiti",
        "Arnab Das",
        "Yamini Sinha",
        "Tim Polzehl",
        "Ingo Siegert",
        "Sebastian Stober"
      ],
      "abstract": "Speech anonymisation aims to protect speaker identity by changing personal\nidentifiers in speech while retaining linguistic content. Current methods fail\nto retain prosody and unique speech patterns found in elderly and pathological\nspeech domains, which is essential for remote health monitoring. To address\nthis gap, we propose a voice conversion-based method (DDSP-QbE) using\ndifferentiable digital signal processing and query-by-example. The proposed\nmethod, trained with novel losses, aids in disentangling linguistic, prosodic,\nand domain representations, enabling the model to adapt to uncommon speech\npatterns. Objective and subjective evaluations show that DDSP-QbE significantly\noutperforms the voice conversion state-of-the-art concerning intelligibility,\nprosody, and domain preservation across diverse datasets, pathologies, and\nspeakers while maintaining quality and speaker anonymity. Experts validate\ndomain preservation by analysing twelve clinically pertinent domain attributes.",
      "tldr_zh": "本研究针对语音匿名化问题，提出了一种基于可微分数字信号处理(DDSP)和查询示例(Query-by-Example)的语音转换方法DDSP-QbE，旨在保护说话者身份的同时保留老年人和病理语音的韵律及独特模式，以支持远程健康监测。方法通过新型损失函数训练模型，实现语言、韵律和领域表示的分离，使其能适应不常见的语音模式。客观和主观评估结果显示，DDSP-QbE在可理解性、韵律保留和领域保护方面显著优于现有技术，并在不同数据集、病理类型和说话者中保持高质量和匿名性，专家通过分析12个临床相关属性验证了其领域保留效果。",
      "categories": [
        "cs.AI",
        "cs.SD",
        "eess.AS",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.15500v1",
      "published_date": "2024-10-20 20:40:56 UTC",
      "updated_date": "2024-10-20 20:40:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:55:56.558756"
    },
    {
      "arxiv_id": "2410.15499v1",
      "title": "Improving Voice Quality in Speech Anonymization With Just Perception-Informed Losses",
      "title_zh": "翻译失败",
      "authors": [
        "Suhita Ghosh",
        "Tim Thiele",
        "Frederic Lorbeer",
        "Frank Dreyer",
        "Sebastian Stober"
      ],
      "abstract": "The increasing use of cloud-based speech assistants has heightened the need\nfor effective speech anonymization, which aims to obscure a speaker's identity\nwhile retaining critical information for subsequent tasks. One approach to\nachieving this is through voice conversion. While existing methods often\nemphasize complex architectures and training techniques, our research\nunderscores the importance of loss functions inspired by the human auditory\nsystem. Our proposed loss functions are model-agnostic, incorporating\nhandcrafted and deep learning-based features to effectively capture quality\nrepresentations. Through objective and subjective evaluations, we demonstrate\nthat a VQVAE-based model, enhanced with our perception-driven losses, surpasses\nthe vanilla model in terms of naturalness, intelligibility, and prosody while\nmaintaining speaker anonymity. These improvements are consistently observed\nacross various datasets, languages, target speakers, and genders.",
      "tldr_zh": "这篇论文针对语音匿名化的挑战，提出了一种基于人类听觉系统的感知驱动损失函数方法，以提高语音质量同时隐藏说话者身份。方法采用模型无关的手工设计和深度学习特征来捕捉语音质量表示，并将其应用于 VQVAE-based 模型。实验结果显示，该增强模型在客观和主观评估中，显著提升了语音的自然性、可理解性和韵律，同时保持匿名效果一致，且在多种数据集、语言、目标说话者和性别上均表现突出。",
      "categories": [
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in NeurIPS 2024 Workshop (Audio Imagination)",
      "pdf_url": "http://arxiv.org/pdf/2410.15499v1",
      "published_date": "2024-10-20 20:33:44 UTC",
      "updated_date": "2024-10-20 20:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:56:08.142027"
    },
    {
      "arxiv_id": "2410.15495v2",
      "title": "SEA: State-Exchange Attention for High-Fidelity Physics Based Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Parsa Esmati",
        "Amirhossein Dadashzadeh",
        "Vahid Goodarzi",
        "Nicolas Larrosa",
        "Nicolò Grilli"
      ],
      "abstract": "Current approaches using sequential networks have shown promise in estimating\nfield variables for dynamical systems, but they are often limited by high\nrollout errors. The unresolved issue of rollout error accumulation results in\nunreliable estimations as the network predicts further into the future, with\neach step's error compounding and leading to an increase in inaccuracy. Here,\nwe introduce the State-Exchange Attention (SEA) module, a novel\ntransformer-based module enabling information exchange between encoded fields\nthrough multi-head cross-attention. The cross-field multidirectional\ninformation exchange design enables all state variables in the system to\nexchange information with one another, capturing physical relationships and\nsymmetries between fields. Additionally, we introduce an efficient ViT-like\nmesh autoencoder to generate spatially coherent mesh embeddings for a large\nnumber of meshing cells. The SEA integrated transformer demonstrates the\nstate-of-the-art rollout error compared to other competitive baselines.\nSpecifically, we outperform PbGMR-GMUS Transformer-RealNVP and GMR-GMUS\nTransformer, with a reduction in error of 88% and 91%, respectively.\nFurthermore, we demonstrate that the SEA module alone can reduce errors by 97%\nfor state variables that are highly dependent on other states of the system.\nThe repository for this work is available at:\nhttps://github.com/ParsaEsmati/SEA",
      "tldr_zh": "该研究针对序列网络在动态系统场变量估计中存在的 rollout error 积累问题，提出了一种新型模块 State-Exchange Attention (SEA)，利用多头交叉注意力机制实现系统状态变量之间的多向信息交换，以捕捉物理关系和对称性。同时，引入了一个高效的 ViT-like mesh autoencoder 来生成空间一致的网格嵌入，提升模型的预测精度。实验结果显示，集成 SEA 的 Transformer 模型在 rollout error 上达到了 state-of-the-art 水平，比 PbGMR-GMUS Transformer-RealNVP 和 GMR-GMUS Transformer 分别减少了 88% 和 91% 的错误，且 SEA 模块单独可为高度依赖其他状态的变量减少 97% 的错误。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.15495v2",
      "published_date": "2024-10-20 20:25:01 UTC",
      "updated_date": "2024-10-29 20:13:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:56:47.029495"
    },
    {
      "arxiv_id": "2410.15490v3",
      "title": "Dynamic Intelligence Assessment: Benchmarking LLMs on the Road to AGI with a Focus on Model Confidence",
      "title_zh": "翻译失败",
      "authors": [
        "Norbert Tihanyi",
        "Tamas Bisztray",
        "Richard A. Dubniczky",
        "Rebeka Toth",
        "Bertalan Borsos",
        "Bilel Cherif",
        "Mohamed Amine Ferrag",
        "Lajos Muzsai",
        "Ridhi Jain",
        "Ryan Marinelli",
        "Lucas C. Cordeiro",
        "Merouane Debbah",
        "Vasileios Mavroeidis",
        "Audun Josang"
      ],
      "abstract": "As machine intelligence evolves, the need to test and compare the\nproblem-solving abilities of different AI models grows. However, current\nbenchmarks are often simplistic, allowing models to perform uniformly well and\nmaking it difficult to distinguish their capabilities. Additionally, benchmarks\ntypically rely on static question-answer pairs that the models might memorize\nor guess. To address these limitations, we introduce Dynamic Intelligence\nAssessment (DIA), a novel methodology for testing AI models using dynamic\nquestion templates and improved metrics across multiple disciplines such as\nmathematics, cryptography, cybersecurity, and computer science. The\naccompanying dataset, DIA-Bench, contains a diverse collection of challenge\ntemplates with mutable parameters presented in various formats, including text,\nPDFs, compiled binaries, visual puzzles, and CTF-style cybersecurity\nchallenges. Our framework introduces four new metrics to assess a model's\nreliability and confidence across multiple attempts. These metrics revealed\nthat even simple questions are frequently answered incorrectly when posed in\nvarying forms, highlighting significant gaps in models' reliability. Notably,\nAPI models like GPT-4o often overestimated their mathematical capabilities,\nwhile ChatGPT-4o demonstrated better performance due to effective tool usage.\nIn self-assessment, OpenAI's o1-mini proved to have the best judgement on what\ntasks it should attempt to solve. We evaluated 25 state-of-the-art LLMs using\nDIA-Bench, showing that current models struggle with complex tasks and often\ndisplay unexpectedly low confidence, even with simpler questions. The DIA\nframework sets a new standard for assessing not only problem-solving but also a\nmodel's adaptive intelligence and ability to assess its limitations. The\ndataset is publicly available on the project's page:\nhttps://github.com/DIA-Bench.",
      "tldr_zh": "本文提出 Dynamic Intelligence Assessment (DIA)，一种新型动态基准测试方法，用于评估大型语言模型(LLMs)的问题解决能力，并重点关注模型信心，以解决现有基准的简单性和静态问题局限。DIA 利用动态问题模板和多学科挑战（如数学、加密、cybersecurity 和计算机科学），结合 DIA-Bench 数据集（包括文本、PDF、二进制文件和 CTF-style 挑战），并引入四个新指标来衡量模型的可靠性和适应性。实验评估了 25 个最先进 LLMs，发现模型在动态形式下经常出错，GPT-4o overestimated 其数学能力，而 ChatGPT-4o 通过工具使用表现更好，o1-mini 在自评估中显示最佳判断力。DIA 框架为 AGI 之路上的模型评估设定新标准，强调了模型适应性智能和限制评估的不足，并公开提供了数据集。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15490v3",
      "published_date": "2024-10-20 20:07:36 UTC",
      "updated_date": "2024-11-22 20:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:56:33.857538"
    },
    {
      "arxiv_id": "2410.15489v1",
      "title": "Generative AI Agents in Autonomous Machines: A Safety Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Jabbour",
        "Vijay Janapa Reddi"
      ],
      "abstract": "The integration of Generative Artificial Intelligence (AI) into autonomous\nmachines represents a major paradigm shift in how these systems operate and\nunlocks new solutions to problems once deemed intractable. Although generative\nAI agents provide unparalleled capabilities, they also have unique safety\nconcerns. These challenges require robust safeguards, especially for autonomous\nmachines that operate in high-stakes environments. This work investigates the\nevolving safety requirements when generative models are integrated as agents\ninto physical autonomous machines, comparing these to safety considerations in\nless critical AI applications. We explore the challenges and opportunities to\nensure the safe deployment of generative AI-driven autonomous machines.\nFurthermore, we provide a forward-looking perspective on the future of\nAI-driven autonomous systems and emphasize the importance of evaluating and\ncommunicating safety risks. As an important step towards addressing these\nconcerns, we recommend the development and implementation of comprehensive\nsafety scorecards for the use of generative AI technologies in autonomous\nmachines.",
      "tldr_zh": "这篇论文从安全视角探讨了生成式 AI 代理在自主机器中的集成，这代表了这些系统运作方式的重大范式转变，同时带来了独特的安全挑战。作者调查了生成模型作为代理融入物理自主机器的安全要求，与其他非关键 AI 应用进行比较，并分析了确保安全部署的挑战与机会。论文强调评估和沟通安全风险的重要性，并推荐开发全面的安全 scorecards，以推动生成式 AI 驱动自主系统的可靠应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15489v1",
      "published_date": "2024-10-20 20:07:08 UTC",
      "updated_date": "2024-10-20 20:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:56:44.144497"
    },
    {
      "arxiv_id": "2410.15483v3",
      "title": "Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning",
      "title_zh": "缓解LLM监督微调和偏好学习中的遗忘",
      "authors": [
        "Heshan Fernando",
        "Han Shen",
        "Parikshit Ram",
        "Yi Zhou",
        "Horst Samulowitz",
        "Nathalie Baracaldo",
        "Tianyi Chen"
      ],
      "abstract": "Post-training of pre-trained LLMs, which typically consists of the supervised\nfine-tuning (SFT) stage and the preference learning (RLHF or DPO) stage, is\ncrucial to effective and safe LLM applications. The widely adopted approach in\npost-training popular open-source LLMs is to sequentially perform SFT and\nRLHF/DPO. However, sequential training is sub-optimal in terms of SFT and\nRLHF/DPO trade-off: the LLM gradually forgets about the first stage's training\nwhen undergoing the second stage's training. We theoretically prove the\nsub-optimality of sequential post-training. Furthermore, we propose a practical\njoint post-training framework with theoretical convergence guarantees and\nempirically outperforms sequential post-training framework, while having\nsimilar computational cost. Our code is available at\nhttps://github.com/heshandevaka/XRIGHT.",
      "tldr_zh": "该研究探讨了在大型语言模型（LLM）后训练过程中，顺序进行监督微调（SFT）和偏好学习（RLHF 或 DPO）所导致的遗忘问题，证明了这种顺序方法在 SFT 与 RLHF/DPO 之间的权衡上存在次优性。论文从理论上分析了这一问题，并提出了一种实用的联合后训练框架，该框架具有收敛保证，能够有效缓解遗忘。实验结果显示，该框架在性能上优于传统顺序训练，同时保持相似的计算成本。代码已在 https://github.com/heshandevaka/XRIGHT 公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15483v3",
      "published_date": "2024-10-20 19:38:41 UTC",
      "updated_date": "2025-02-05 22:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:56:56.410002"
    },
    {
      "arxiv_id": "2410.15472v2",
      "title": "Multi-Layer Feature Fusion with Cross-Channel Attention-Based U-Net for Kidney Tumor Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Fnu Neha",
        "Arvind K. Bansal"
      ],
      "abstract": "Renal tumors, especially renal cell carcinoma (RCC), show significant\nheterogeneity, posing challenges for diagnosis using radiology images such as\nMRI, echocardiograms, and CT scans. U-Net based deep learning techniques are\nemerging as a promising approach for automated medical image segmentation for\nminimally invasive diagnosis of renal tumors. However, current techniques need\nfurther improvements in accuracy to become clinically useful to radiologists.\nIn this study, we present an improved U-Net based model for end-to-end\nautomated semantic segmentation of CT scan images to identify renal tumors. The\nmodel uses residual connections across convolution layers, integrates a\nmulti-layer feature fusion (MFF) and cross-channel attention (CCA) within\nencoder blocks, and incorporates skip connections augmented with additional\ninformation derived using MFF and CCA. We evaluated our model on the KiTS19\ndataset, which contains data from 210 patients. For kidney segmentation, our\nmodel achieves a Dice Similarity Coefficient (DSC) of 0.97 and a Jaccard index\n(JI) of 0.95. For renal tumor segmentation, our model achieves a DSC of 0.96\nand a JI of 0.91. Based on a comparison of available DSC scores, our model\noutperforms the current leading models.",
      "tldr_zh": "本研究针对肾肿瘤（如肾细胞癌）的异质性对放射学图像诊断的挑战，提出了一种改进的U-Net模型，用于CT扫描图像的端到端语义分割。模型整合了残差连接、多层特征融合(MFF)和跨通道注意力(CCA)机制，并在跳跃连接中添加额外信息，以提升分割准确性。在KiTS19数据集（210名患者）上评估，该模型在肾脏分割中达到DSC 0.97和JI 0.95，在肾肿瘤分割中达到DSC 0.96和JI 0.91，并超越了现有领先模型的性能。总的来说，此方法为自动化肾肿瘤诊断提供了更可靠的工具。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.15472v2",
      "published_date": "2024-10-20 19:02:41 UTC",
      "updated_date": "2024-10-22 02:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:57:09.192245"
    },
    {
      "arxiv_id": "2410.15471v2",
      "title": "Generative Models, Humans, Predictive Models: Who Is Worse at High-Stakes Decision Making?",
      "title_zh": "翻译失败",
      "authors": [
        "Keri Mallari",
        "Julius Adebayo",
        "Kori Inkpen",
        "Martin T. Wells",
        "Albert Gordo",
        "Sarah Tan"
      ],
      "abstract": "Despite strong advisory against it, large generative models (LMs) are already\nbeing used for decision making tasks that were previously done by predictive\nmodels or humans. We put popular LMs to the test in a high-stakes decision\nmaking task: recidivism prediction. Studying three closed-access and\nopen-source LMs, we analyze the LMs not exclusively in terms of accuracy, but\nalso in terms of agreement with (imperfect, noisy, and sometimes biased) human\npredictions or existing predictive models. We conduct experiments that assess\nhow providing different types of information, including distractor information\nsuch as photos, can influence LM decisions. We also stress test techniques\ndesigned to either increase accuracy or mitigate bias in LMs, and find that\nsome to have unintended consequences on LM decisions. Our results provide\nadditional quantitative evidence to the wisdom that current LMs are not the\nright tools for these types of tasks.",
      "tldr_zh": "该研究比较了生成模型(LMs)、人类和预测模型在高风险决策任务中的表现，焦点是再犯预测(recidivism prediction)。作者测试了三个封闭和开源LMs，不仅评估准确性，还分析了LMs与人类预测或现有模型的一致性，以及提供不同类型信息（如照片等干扰信息）对决策的影响。实验结果显示，这些技术可能导致意外后果，如增加偏见或降低可靠性，最终得出结论：当前LMs不适合高风险决策任务。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15471v2",
      "published_date": "2024-10-20 19:00:59 UTC",
      "updated_date": "2025-02-14 05:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:57:20.295962"
    },
    {
      "arxiv_id": "2410.15470v1",
      "title": "Data Augmentation via Diffusion Model to Enhance AI Fairness",
      "title_zh": "通过扩散模型进行数据增强以提升 AI 公平性",
      "authors": [
        "Christina Hastings Blow",
        "Lijun Qian",
        "Camille Gibson",
        "Pamela Obiomon",
        "Xishuang Dong"
      ],
      "abstract": "AI fairness seeks to improve the transparency and explainability of AI\nsystems by ensuring that their outcomes genuinely reflect the best interests of\nusers. Data augmentation, which involves generating synthetic data from\nexisting datasets, has gained significant attention as a solution to data\nscarcity. In particular, diffusion models have become a powerful technique for\ngenerating synthetic data, especially in fields like computer vision. This\npaper explores the potential of diffusion models to generate synthetic tabular\ndata to improve AI fairness. The Tabular Denoising Diffusion Probabilistic\nModel (Tab-DDPM), a diffusion model adaptable to any tabular dataset and\ncapable of handling various feature types, was utilized with different amounts\nof generated data for data augmentation. Additionally, reweighting samples from\nAIF360 was employed to further enhance AI fairness. Five traditional machine\nlearning models-Decision Tree (DT), Gaussian Naive Bayes (GNB), K-Nearest\nNeighbors (KNN), Logistic Regression (LR), and Random Forest (RF)-were used to\nvalidate the proposed approach. Experimental results demonstrate that the\nsynthetic data generated by Tab-DDPM improves fairness in binary\nclassification.",
      "tldr_zh": "这篇论文探讨了使用Diffusion Model生成合成数据来提升AI公平性，旨在解决数据稀缺问题。研究者采用Tabular Denoising Diffusion Probabilistic Model (Tab-DDPM)生成适应各种特征类型的合成表格数据，并结合AIF360的样本再加权技术进行增强。实验结果显示，在Decision Tree (DT)、Gaussian Naive Bayes (GNB)、K-Nearest Neighbors (KNN)、Logistic Regression (LR)和Random Forest (RF)等五种机器学习模型上，使用Tab-DDPM生成的合成数据显著提高了二元分类任务的公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2312.12560",
      "pdf_url": "http://arxiv.org/pdf/2410.15470v1",
      "published_date": "2024-10-20 18:52:31 UTC",
      "updated_date": "2024-10-20 18:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:57:32.216837"
    },
    {
      "arxiv_id": "2410.15469v1",
      "title": "AssemblyComplete: 3D Combinatorial Construction with Deep Reinforcement Learning",
      "title_zh": "AssemblyComplete：3D 组合构建与深度强化学习",
      "authors": [
        "Alan Chen",
        "Changliu Liu"
      ],
      "abstract": "A critical goal in robotics and autonomy is to teach robots to adapt to\nreal-world collaborative tasks, particularly in automatic assembly. The ability\nof a robot to understand the original intent of an incomplete assembly and\ncomplete missing features without human instruction is valuable but\nchallenging. This paper introduces 3D combinatorial assembly completion, which\nis demonstrated using combinatorial unit primitives (i.e., Lego bricks).\nCombinatorial assembly is challenging due to the possible assembly combinations\nand complex physical constraints (e.g., no brick collisions, structure\nstability, inventory constraints, etc.). To address these challenges, we\npropose a two-part deep reinforcement learning (DRL) framework that tackles\nteaching the robot to understand the objective of an incomplete assembly and\nlearning a construction policy to complete the assembly. The robot queries a\nstable object library to facilitate assembly inference and guide learning. In\naddition to the robot policy, an action mask is developed to rule out invalid\nactions that violate physical constraints for object-oriented construction. We\ndemonstrate the proposed framework's feasibility and robustness in a variety of\nassembly scenarios in which the robot satisfies real-life assembly with respect\nto both solution and runtime quality. Furthermore, results demonstrate that the\nproposed framework effectively infers and assembles incomplete structures for\nunseen and unique object types.",
      "tldr_zh": "这篇论文介绍了 AssemblyComplete 框架，利用 Deep Reinforcement Learning (DRL) 教机器人理解和完成 3D 组合式组装任务，例如使用 Lego 积木处理不完整结构。框架由两部分组成：第一部分帮助机器人推断组装目标，第二部分学习构建策略，同时结合稳定的物体库查询和动作掩码来避免物理约束（如碰撞或稳定性问题）。实验结果表明，该框架在各种真实场景中表现出色，能够高效地完成未见物体类型的组装，提高了解决方案和运行时质量。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to 2025 American Control Conference (ACC)",
      "pdf_url": "http://arxiv.org/pdf/2410.15469v1",
      "published_date": "2024-10-20 18:51:17 UTC",
      "updated_date": "2024-10-20 18:51:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:57:44.927939"
    },
    {
      "arxiv_id": "2410.15467v1",
      "title": "Hey GPT, Can You be More Racist? Analysis from Crowdsourced Attempts to Elicit Biased Content from Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Hangzhi Guo",
        "Pranav Narayanan Venkit",
        "Eunchae Jang",
        "Mukund Srinath",
        "Wenbo Zhang",
        "Bonam Mingole",
        "Vipul Gupta",
        "Kush R. Varshney",
        "S. Shyam Sundar",
        "Amulya Yadav"
      ],
      "abstract": "The widespread adoption of large language models (LLMs) and generative AI\n(GenAI) tools across diverse applications has amplified the importance of\naddressing societal biases inherent within these technologies. While the NLP\ncommunity has extensively studied LLM bias, research investigating how\nnon-expert users perceive and interact with biases from these systems remains\nlimited. As these technologies become increasingly prevalent, understanding\nthis question is crucial to inform model developers in their efforts to\nmitigate bias. To address this gap, this work presents the findings from a\nuniversity-level competition, which challenged participants to design prompts\nfor eliciting biased outputs from GenAI tools. We quantitatively and\nqualitatively analyze the competition submissions and identify a diverse set of\nbiases in GenAI and strategies employed by participants to induce bias in\nGenAI. Our finding provides unique insights into how non-expert users perceive\nand interact with biases from GenAI tools.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 和生成式 AI (GenAI) 中固有的社会偏见问题，通过一个大学级竞赛让非专家参与者设计提示来诱导偏见输出。研究对竞赛提交进行定量和定性分析，识别了 GenAI 中的多样偏见类型以及参与者采用的策略，如针对特定主题的提示设计。结果揭示了非专家用户如何感知和互动这些偏见，为模型开发者提供宝贵见解，以缓解 AI 系统的偏见问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15467v1",
      "published_date": "2024-10-20 18:44:45 UTC",
      "updated_date": "2024-10-20 18:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:57:56.985740"
    },
    {
      "arxiv_id": "2410.15466v1",
      "title": "Keep Guessing? When Considering Inference Scaling, Mind the Baselines",
      "title_zh": "翻译失败",
      "authors": [
        "Gal Yona",
        "Or Honovich",
        "Omer Levy",
        "Roee Aharoni"
      ],
      "abstract": "Scaling inference compute in large language models (LLMs) through repeated\nsampling consistently increases the coverage (fraction of problems solved) as\nthe number of samples increases. We conjecture that this observed improvement\nis partially due to the answer distribution of standard evaluation benchmarks,\nwhich is skewed towards a relatively small set of common answers. To test this\nconjecture, we define a baseline that enumerates answers according to their\nprevalence in the training set. Experiments spanning two domains --\nmathematical reasoning and factual knowledge -- reveal that this baseline\noutperforms repeated model sampling for some LLMs, while the coverage for\nothers is on par with that of a mixture strategy that obtains $k$ answers by\nusing only $10$ model samples and similarly guessing the remaining $k-10$\nattempts via enumeration. Our baseline enables a more accurate measurement of\nhow much repeated sampling improves coverage in such settings beyond\nprompt-agnostic guessing.",
      "tldr_zh": "这篇论文探讨了在大型语言模型(LLMs)中通过重复采样增加推理计算(inference scaling)来提升覆盖率(coverage)的问题，作者认为这种改善部分源于评估基准的答案分布偏向常见答案。论文提出一个基线方法，通过枚举训练集中的常见答案来评估性能。实验在数学推理和事实知识领域显示，该基线在某些LLMs上优于重复采样，而在其他情况下与混合策略相当，仅需10个模型样本即可实现类似效果。该方法有助于更准确地衡量重复采样对覆盖率的实际贡献，超越了提示无关的猜测(guessing)。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15466v1",
      "published_date": "2024-10-20 18:43:05 UTC",
      "updated_date": "2024-10-20 18:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:58:08.745954"
    },
    {
      "arxiv_id": "2411.03320v4",
      "title": "log-RRIM: Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Hu",
        "Ziqi Chen",
        "Bo Peng",
        "Daniel Adu-Ampratwum",
        "Xia Ning"
      ],
      "abstract": "Accurate prediction of chemical reaction yields is crucial for optimizing\norganic synthesis, potentially reducing time and resources spent on\nexperimentation. With the rise of artificial intelligence (AI), there is\ngrowing interest in leveraging AI-based methods to accelerate yield predictions\nwithout conducting in vitro experiments. We present log-RRIM, an innovative\ngraph transformer-based framework designed for predicting chemical reaction\nyields. A key feature of log-RRIM is its integration of a cross-attention\nmechanism that focuses on the interplay between reagents and reaction centers.\nThis design reflects a fundamental principle in chemical reactions: the crucial\nrole of reagents in influencing bond-breaking and formation processes, which\nultimately affect reaction yields. log-RRIM also implements a local-to-global\nreaction representation learning strategy. This approach initially captures\ndetailed molecule-level information and then models and aggregates\nintermolecular interactions. Through this hierarchical process, log-RRIM\neffectively captures how different molecular fragments contribute to and\ninfluence the overall reaction yield, regardless of their size variations.\nlog-RRIM shows superior performance in our experiments, especially for medium\nto high-yielding reactions, proving its reliability as a predictor. The\nframework's sophisticated modeling of reactant-reagent interactions and precise\ncapture of molecular fragment contributions make it a valuable tool for\nreaction planning and optimization in chemical synthesis. The data and codes of\nlog-RRIM are accessible through https://github.com/ninglab/Yield_log_RRIM.",
      "tldr_zh": "该研究提出 log-RRIM，一种基于 graph transformer 的框架，用于准确预测化学反应产率，从而优化有机合成过程并减少实验资源。log-RRIM 整合了 cross-attention mechanism 来关注试剂和反应中心的相互作用，并采用 local-to-global reaction representation learning 策略，先捕获分子级细节，然后建模分子间交互以评估整体产率影响。实验结果显示，log-RRIM 在中等到高产率反应上表现出色，优于现有方法，并为化学合成中的反应规划提供可靠工具，相关数据和代码可通过 GitHub 访问。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "45 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03320v4",
      "published_date": "2024-10-20 18:35:56 UTC",
      "updated_date": "2025-03-09 03:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:58:20.179865"
    },
    {
      "arxiv_id": "2410.15460v3",
      "title": "Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training",
      "title_zh": "翻译失败",
      "authors": [
        "Shahrad Mohammadzadeh",
        "Juan David Guerra",
        "Marco Bonizzato",
        "Reihaneh Rabbany",
        "Golnoosh Farnadi"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed across various\nindustries, concerns regarding their reliability, particularly due to\nhallucinations - outputs that are factually inaccurate or irrelevant to user\ninput - have grown. Our research investigates the relationship between the\ntraining process and the emergence of hallucinations to address a key gap in\nexisting research that focuses primarily on post hoc detection and mitigation\nstrategies. Using models from the Pythia suite (70M - 12B parameters) and\nseveral hallucination detection metrics, we analyze hallucination trends\nthroughout training and explore LLM internal dynamics. We introduce Sensitivity\nDropout (SenD), a novel training protocol designed to mitigate hallucinations\nby reducing variance during training. SenD achieves this by deterministically\ndropping embedding indices with significant variability, referred to as\nSensitive Embedding Indices. In addition, we develop an unsupervised\nhallucination detection metric, Efficient EigenScore (EES), which approximates\nthe traditional EigenScore at 2x speed. This efficient metric is integrated\ninto our protocol, allowing SenD to be both computationally scalable and\neffective at reducing hallucinations. Our empirical evaluation demonstrates\nthat our approach improves LLM reliability at test time by up to 40% compared\nto normal training while also providing an efficient method to improve factual\naccuracy when adapting LLMs to Wikipedia, Medical, and LegalBench domains.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 中的幻觉问题（输出不准确或与输入无关），通过分析训练过程及其内部动态，填补了现有研究的空白。研究者引入了 Sensitivity Dropout (SenD)，一种新训练协议，通过确定性地丢弃高变异性的敏感嵌入索引来减少幻觉的发生，并开发了 Efficient EigenScore (EES)，一种速度提升 2 倍的无监督检测指标，以提升协议的可扩展性。实验结果显示，SenD 相较于标准训练可提高 LLM 可靠性高达 40%，并在 Wikipedia、Medical 和 LegalBench 领域显著改善事实准确性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "math.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 15 figures, under review at ICLR, accepted to Safe\n  Generative AI Workshop @ NeurIPS 2024, resubmitting to change name to\n  appropriate name",
      "pdf_url": "http://arxiv.org/pdf/2410.15460v3",
      "published_date": "2024-10-20 18:18:23 UTC",
      "updated_date": "2025-01-07 14:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:58:33.459494"
    },
    {
      "arxiv_id": "2410.15449v1",
      "title": "Heterogeneous Graph Reinforcement Learning for Dependency-aware Multi-task Allocation in Spatial Crowdsourcing",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Zhao",
        "Zhengqiu Zhu",
        "Chen Gao",
        "En Wang",
        "Jincai Huang",
        "Fei-Yue Wang"
      ],
      "abstract": "Spatial Crowdsourcing (SC) is gaining traction in both academia and industry,\nwith tasks on SC platforms becoming increasingly complex and requiring\ncollaboration among workers with diverse skills. Recent research works address\ncomplex tasks by dividing them into subtasks with dependencies and assigning\nthem to suitable workers. However, the dependencies among subtasks and their\nheterogeneous skill requirements, as well as the need for efficient utilization\nof workers' limited work time in the multi-task allocation mode, pose\nchallenges in achieving an optimal task allocation scheme. Therefore, this\npaper formally investigates the problem of Dependency-aware Multi-task\nAllocation (DMA) and presents a well-designed framework to solve it, known as\nHeterogeneous Graph Reinforcement Learning-based Task Allocation (HGRL-TA). To\naddress the challenges associated with representing and embedding diverse\nproblem instances to ensure robust generalization, we propose a multi-relation\ngraph model and a Compound-path-based Heterogeneous Graph Attention Network\n(CHANet) for effectively representing and capturing intricate relations among\ntasks and workers, as well as providing embedding of problem state. The task\nallocation decision is determined sequentially by a policy network, which\nundergoes simultaneous training with CHANet using the proximal policy\noptimization algorithm. Extensive experiment results demonstrate the\neffectiveness and generality of the proposed HGRL-TA in solving the DMA\nproblem, leading to average profits that is 21.78% higher than those achieved\nusing the metaheuristic methods.",
      "tldr_zh": "这篇论文针对空间众包（Spatial Crowdsourcing）中依赖aware的多任务分配（DMA）问题，提出了一种基于异构图强化学习（Heterogeneous Graph Reinforcement Learning）的框架HGRL-TA，以应对子任务依赖关系、多样技能需求以及工人时间利用的挑战。HGRL-TA 采用多关系图模型和Compound-path-based Heterogeneous Graph Attention Network (CHANet) 来有效表示和捕捉任务与工人间的复杂关系，并通过策略网络结合近端策略优化算法进行顺序任务分配决策。实验结果表明，该框架比元启发式方法平均利润提高了21.78%，展示了其在DMA问题上的有效性和泛化性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15449v1",
      "published_date": "2024-10-20 17:00:45 UTC",
      "updated_date": "2024-10-20 17:00:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:58:45.637935"
    },
    {
      "arxiv_id": "2410.15446v2",
      "title": "Concept Complement Bottleneck Model for Interpretable Medical Image Diagnosis",
      "title_zh": "概念互补瓶颈模型用于可解释医学图像诊断",
      "authors": [
        "Hongmei Wang",
        "Junlin Hou",
        "Hao Chen"
      ],
      "abstract": "Models based on human-understandable concepts have received extensive\nattention to improve model interpretability for trustworthy artificial\nintelligence in the field of medical image analysis. These methods can provide\nconvincing explanations for model decisions but heavily rely on the detailed\nannotation of pre-defined concepts. Consequently, they may not be effective in\ncases where concepts or annotations are incomplete or low-quality. Although\nsome methods automatically discover effective and new visual concepts rather\nthan using pre-defined concepts or could find some human-understandable\nconcepts via large Language models, they are prone to veering away from medical\ndiagnostic evidence and are challenging to understand. In this paper, we\npropose a concept complement bottleneck model for interpretable medical image\ndiagnosis with the aim of complementing the existing concept set and finding\nnew concepts bridging the gap between explainable models. Specifically, we\npropose to use concept adapters for specific concepts to mine the concept\ndifferences and score concepts in their own attention channels to support\nalmost fairly concept learning. Then, we devise a concept complement strategy\nto learn new concepts while jointly using known concepts to improve model\nperformance. Comprehensive experiments on medical datasets demonstrate that our\nmodel outperforms the state-of-the-art competitors in concept detection and\ndisease diagnosis tasks while providing diverse explanations to ensure model\ninterpretability effectively.",
      "tldr_zh": "这篇论文提出了一种Concept Complement Bottleneck Model，用于可解释的医疗图像诊断，旨在补充现有概念集并发现新概念，以解决传统模型依赖预定义注解的局限性。具体方法包括使用concept adapters来挖掘概念差异并在各自注意力通道中评分，支持公平的概念学习，以及设计concept complement strategy来同时学习新概念和利用已知概念提升模型性能。实验在医疗数据集上表明，该模型在概念检测和疾病诊断任务中优于最先进的方法，并提供多样化的解释，确保了模型的可解释性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, 5 figures,",
      "pdf_url": "http://arxiv.org/pdf/2410.15446v2",
      "published_date": "2024-10-20 16:52:09 UTC",
      "updated_date": "2024-12-24 04:23:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:58:56.400476"
    },
    {
      "arxiv_id": "2410.15442v1",
      "title": "Exploring Social Desirability Response Bias in Large Language Models: Evidence from GPT-4 Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Sanguk Lee",
        "Kai-Qi Yang",
        "Tai-Quan Peng",
        "Ruth Heo",
        "Hui Liu"
      ],
      "abstract": "Large language models (LLMs) are employed to simulate human-like responses in\nsocial surveys, yet it remains unclear if they develop biases like social\ndesirability response (SDR) bias. To investigate this, GPT-4 was assigned\npersonas from four societies, using data from the 2022 Gallup World Poll. These\nsynthetic samples were then prompted with or without a commitment statement\nintended to induce SDR. The results were mixed. While the commitment statement\nincreased SDR index scores, suggesting SDR bias, it reduced civic engagement\nscores, indicating an opposite trend. Additional findings revealed demographic\nassociations with SDR scores and showed that the commitment statement had\nlimited impact on GPT-4's predictive performance. The study underscores\npotential avenues for using LLMs to investigate biases in both humans and LLMs\nthemselves.",
      "tldr_zh": "本文研究大型语言模型（LLMs）是否会像人类一样产生社会期望响应偏差（SDR bias），通过使用GPT-4模拟四个社会的角色，并基于2022年盖洛普世界民意调查数据进行测试，涉及有无承诺声明的提示。结果显示，承诺声明增加了SDR指数分数（表明存在SDR偏差），但降低了公民参与分数，并发现SDR分数与人口统计学因素相关，同时对GPT-4的预测性能影响有限。该研究为利用LLMs探索人类和模型自身偏差提供了潜在新方法。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15442v1",
      "published_date": "2024-10-20 16:28:24 UTC",
      "updated_date": "2024-10-20 16:28:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:59:08.222516"
    },
    {
      "arxiv_id": "2410.15440v1",
      "title": "Evaluating Consistencies in LLM responses through a Semantic Clustering of Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Yanggyu Lee",
        "Jihie Kim"
      ],
      "abstract": "In the realm of Large Language Model (LLM) functionalities, providing\nreliable information is paramount, yet reports suggest that LLM outputs lack\nconsistency. This inconsistency, often at-tributed to randomness in token\nsampling, under-mines user trust as it leads to varying responses even for\nidentical queries. In this paper, we present a new approach for evaluating\nsemantic consistencies of LLM including comparison of alternative tech-niques.\nOur approach evaluates whether LLM re-sponses are semantically congruent for a\ngiven question, recognizing that as syntactically different sentences may\nconvey the same meaning. Here-tofore, To enhance LLM consistency, two main\napproaches have been explored: Leverage external knowledge as context like the\nRAG pattern or use Zero-shot-CoT to improve performance of LLM itself. We apply\nour evaluation approach to these techniques, and demonstrate to compare the\nim-pact of these methods on LLM response con-sistency across different domains\nof question an-swering tasks. Using the TruthfulQA dataset to assess LLM\nresponses, the study induces N re-sponses per question from the LLM and\nclusters semantically equivalent sentences to measure semantic consistency\nacross 37 categories. Through this, it quantitatively analyzes the\neffectiveness of the aforementioned methods in improving LLM performance before\nand after their adoption.",
      "tldr_zh": "这篇论文探讨了 Large Language Model (LLM) 响应不一致的问题，提出了一种新方法通过语义聚类评估 LLM 在问答任务中的语义一致性，包括比较 RAG 和 Zero-shot-CoT 等技术的影响。方法涉及为每个问题生成多个响应，并将语义相似的句子聚类，以量化一致性。实验使用 TruthfulQA 数据集在 37 个类别上分析这些方法的应用前后对 LLM 性能的提升效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the Trustworthy AI Workshop at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.15440v1",
      "published_date": "2024-10-20 16:21:25 UTC",
      "updated_date": "2024-10-20 16:21:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:59:20.768850"
    },
    {
      "arxiv_id": "2411.00802v1",
      "title": "An Improved Chicken Swarm Optimization Algorithm for Handwritten Document Image Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Stanley Mugisha",
        "Lynn tar Gutu",
        "P Nagabhushan"
      ],
      "abstract": "Chicken swarm optimization is a new meta-heuristic algorithm which mimics the\nforaging hierarchical behavior of chicken. In this paper, we describe the\npreprocessing of handwritten document by contrast enhancement while preserving\ndetail with an improved chicken swarm optimization algorithm.The results of the\nalgorithm are compared with other existing meta heuristic algorithms like\nCuckoo Search, Firefly Algorithm and the Artificial bee colony. The proposed\nalgorithm considerably outperforms all the above by giving good results.",
      "tldr_zh": "本论文提出了一种改进的Chicken Swarm Optimization算法，用于手写文档图像的预处理，通过对比增强来保留图像细节。该算法模拟鸡群的觅食层级行为，优化图像增强过程。实验结果显示，与Cuckoo Search、Firefly Algorithm和Artificial Bee Colony等现有算法相比，该改进算法在性能上显著优越，提供更佳的图像处理效果。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "I.4.3"
      ],
      "primary_category": "cs.NE",
      "comment": "6 pages, 2 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2411.00802v1",
      "published_date": "2024-10-20 16:10:13 UTC",
      "updated_date": "2024-10-20 16:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:59:31.590942"
    },
    {
      "arxiv_id": "2410.15438v1",
      "title": "Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhou",
        "Ping Nie",
        "Yiwen Guo",
        "Haojie Wei",
        "Zhanqiu Zhang",
        "Pasquale Minervini",
        "Ruotian Ma",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) significantly improved the ability of\nLarge Language Models (LLMs) to solve knowledge-intensive tasks. While existing\nresearch seeks to enhance RAG performance by retrieving higher-quality\ndocuments or designing RAG-specific LLMs, the internal mechanisms within LLMs\nthat contribute to the effectiveness of RAG systems remain underexplored. In\nthis paper, we aim to investigate these internal mechanisms within the popular\nMixture-of-Expert (MoE)-based LLMs and demonstrate how to improve RAG by\nexamining expert activations in these LLMs. Our controlled experiments reveal\nthat several core groups of experts are primarily responsible for RAG-related\nbehaviors. The activation of these core experts can signify the model's\ninclination towards external/internal knowledge and adjust its behavior. For\ninstance, we identify core experts that can (1) indicate the sufficiency of the\nmodel's internal knowledge, (2) assess the quality of retrieved documents, and\n(3) enhance the model's ability to utilize context. Based on these findings, we\npropose several strategies to enhance RAG's efficiency and effectiveness\nthrough expert activation. Experimental results across various datasets and\nMoE-based LLMs show the effectiveness of our method.",
      "tldr_zh": "本文研究Retrieval-Augmented Generation (RAG) 在Mixture-of-Expert (MoE)-based Large Language Models (LLMs) 中的内部机制，重点考察专家激活如何影响RAG性能。实验发现，核心专家组负责关键行为，包括评估模型内部知识的充分性、判断检索文档质量以及增强上下文利用能力。基于这些发现，作者提出策略通过优化专家激活来提升RAG的效率和效果，并在多种数据集和MoE-based LLMs上验证了方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15438v1",
      "published_date": "2024-10-20 16:08:54 UTC",
      "updated_date": "2024-10-20 16:08:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:59:44.653797"
    },
    {
      "arxiv_id": "2410.15437v1",
      "title": "AttCDCNet: Attention-enhanced Chest Disease Classification using X-Ray Images",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Hesham Khater",
        "Abdullahi Sani Shuaib",
        "Sami Ul Haq",
        "Abdul Jabbar Siddiqui"
      ],
      "abstract": "Chest X-rays (X-ray images) have been proven to be effective for the\ndiagnosis of chest diseases, including Pneumonia, Lung Opacity, and COVID-19.\nHowever, relying on traditional medical methods for diagnosis from X-ray images\nis prone to delays and inaccuracies because the medical personnel who evaluate\nthe X-ray images may have preconceived biases. For this reason, researchers\nhave proposed the use of deep learning-based techniques to facilitate the\ndiagnosis process. The preeminent method is the use of sophisticated\nConvolutional Neural Networks (CNNs). In this paper, we propose a novel\ndetection model named \\textbf{AttCDCNet} for the task of X-ray image diagnosis,\nenhancing the popular DenseNet121 model by adding an attention block to help\nthe model focus on the most relevant regions, using focal loss as a loss\nfunction to overcome the imbalance of the dataset problem, and utilizing\ndepth-wise convolution to reduce the parameters to make the model lighter.\nThrough extensive experimental evaluations, the proposed model demonstrates\nexceptional performance, showing better results than the original DenseNet121.\nThe proposed model achieved an accuracy, precision and recall of 94.94%, 95.14%\nand 94.53%, respectively, on the COVID-19 Radiography Dataset.",
      "tldr_zh": "该论文提出了一种新型模型AttCDCNet，用于基于X-Ray图像的胸部疾病分类，如肺炎、肺不透明和COVID-19，以解决传统诊断方法可能存在的延迟和偏见问题。该模型在DenseNet121基础上添加attention block，帮助模型聚焦于关键区域，同时使用focal loss处理数据集不平衡问题，并采用depth-wise convolution减少参数，使模型更轻量化。通过实验评估，AttCDCNet在COVID-19 Radiography Dataset上实现了94.94%的准确率、95.14%的精确率和94.53%的召回率，表现优于原始DenseNet121。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15437v1",
      "published_date": "2024-10-20 16:08:20 UTC",
      "updated_date": "2024-10-20 16:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:59:57.088868"
    },
    {
      "arxiv_id": "2410.15423v1",
      "title": "Power Plays: Unleashing Machine Learning Magic in Smart Grids",
      "title_zh": "翻译失败",
      "authors": [
        "Abdur Rashid",
        "Parag Biswas",
        "abdullah al masum",
        "MD Abdullah Al Nasim",
        "Kishor Datta Gupta"
      ],
      "abstract": "The integration of machine learning into smart grid systems represents a\ntransformative step in enhancing the efficiency, reliability, and\nsustainability of modern energy networks. By adding advanced data analytics,\nthese systems can better manage the complexities of renewable energy\nintegration, demand response, and predictive maintenance. Machine learning\nalgorithms analyze vast amounts of data from smart meters, sensors, and other\ngrid components to optimize energy distribution, forecast demand, and detect\nirregularities that could indicate potential failures. This enables more\nprecise load balancing, reduces operational costs, and enhances the resilience\nof the grid against disturbances. Furthermore, the use of predictive models\nhelps in anticipating equipment failures, thereby improving the reliability of\nthe energy supply. As smart grids continue to evolve, the role of machine\nlearning in managing decentralized energy sources and enabling real-time\ndecision-making will become increasingly critical. However, the deployment of\nthese technologies also raises challenges related to data privacy, security,\nand the need for robust infrastructure. Addressing these issues in this\nresearch authors will focus on realizing the full potential of smart grids,\nensuring they meet the growing energy demands while maintaining a focus on\nsustainability and efficiency using Machine Learning techniques. Furthermore,\nthis research will help determine the smart grid's essentiality with the aid of\nMachine Learning. Multiple ML algorithms have been integrated along with their\npros and cons. The future scope of these algorithms are also integrated.",
      "tldr_zh": "这篇论文探讨了将 Machine Learning 整合到智能电网中，以提升能源网络的效率、可靠性和可持续性。研究方法包括使用 Machine Learning 算法分析智能电表、传感器等数据源，进行能量分布优化、需求预测和异常检测，从而实现精确负载平衡、降低运营成本并提高电网弹性。论文还强调了预测模型在预见设备故障方面的作用，同时指出了数据隐私、安全和基础设施挑战，并评估了多种 ML 算法的优缺点及其未来应用潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2410.15423v1",
      "published_date": "2024-10-20 15:39:08 UTC",
      "updated_date": "2024-10-20 15:39:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:00:27.310098"
    },
    {
      "arxiv_id": "2410.15420v1",
      "title": "Where to Build Food Banks and Pantries: A Two-Level Machine Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Gavin Ruan",
        "Ziqi Guo",
        "Guang Lin"
      ],
      "abstract": "Over 44 million Americans currently suffer from food insecurity, of whom 13\nmillion are children. Across the United States, thousands of food banks and\npantries serve as vital sources of food and other forms of aid for food\ninsecure families. By optimizing food bank and pantry locations, food would\nbecome more accessible to families who desperately require it. In this work, we\nintroduce a novel two-level optimization framework, which utilizes the\nK-Medoids clustering algorithm in conjunction with the Open-Source Routing\nMachine engine, to optimize food bank and pantry locations based on real road\ndistances to houses and house blocks. Our proposed framework also has the\nadaptability to factor in considerations such as median household income using\na pseudo-weighted K-Medoids algorithm. Testing conducted with California and\nIndiana household data, as well as comparisons with real food bank and pantry\nlocations showed that interestingly, our proposed framework yields food pantry\nlocations superior to those of real existing ones and saves significant\ndistance for households, while there is a marginal penalty on the first level\nfood bank to food pantry distance. Overall, we believe that the second-level\nbenefits of this framework far outweigh any drawbacks and yield a net benefit\nresult.",
      "tldr_zh": "该研究针对美国4400多万食物不安全人群（其中包括1300万儿童）的问题，提出了一种两级机器学习优化框架，用于确定食物银行和食品柜的最佳位置，以提高食物可达性。框架结合了K-Medoids聚类算法和Open-Source Routing Machine引擎，基于实际道路距离和可选因素（如家庭收入）进行优化，例如使用伪加权K-Medoids算法。实验结果显示，该框架在加利福尼亚和印第安纳州的数据测试中，生成的食品柜位置优于现有位置，能为家庭节省显著距离，尽管一级食物银行到食品柜的距离略有增加；总体而言，该框架的净收益远大于潜在缺点。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15420v1",
      "published_date": "2024-10-20 15:31:24 UTC",
      "updated_date": "2024-10-20 15:31:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:00:20.621478"
    },
    {
      "arxiv_id": "2410.15419v1",
      "title": "CASET: Complexity Analysis using Simple Execution Traces for CS* submissions",
      "title_zh": "CASET：使用简单执行追踪的复杂度分析，用于 CS* 提交",
      "authors": [
        "Aaryen Mehta",
        "Gagan Aryan"
      ],
      "abstract": "The most common method to auto-grade a student's submission in a CS1 or a CS2\ncourse is to run it against a pre-defined test suite and compare the results\nagainst reference results. However, this technique cannot be used if the\ncorrectness of the solution goes beyond simple output, such as the algorithm\nused to obtain the result. There is no convenient method for the graders to\nidentify the kind of algorithm used in solving a problem. They must read the\nsource code and understand the algorithm implemented and its features, which\nmakes the process tedious. We propose CASET(Complexity Analysis using Simple\nExecution Traces), a novel tool to analyze the time complexity of algorithms\nusing dynamic traces and unsupervised machine learning. CASET makes it\nconvenient for tutors to classify the submissions for a program into time\ncomplexity baskets. Thus, tutors can identify the algorithms used by the\nsubmissions without necessarily going through the code written by the students.\nCASET's analysis can be used to improve grading and provide detailed feedback\nfor submissions that try to match the results without a proper algorithm, for\nexample, hard-coding a binary result, pattern-matching the visible or common\ninputs. We show the effectiveness of CASET by computing the time complexity of\nmany classes of algorithms like sorting, searching and those using dynamic\nprogramming paradigm.",
      "tldr_zh": "本文提出 CASET（Complexity Analysis using Simple Execution Traces）工具，用于 CS1/CS2 课程中分析学生代码的算法时间复杂度。该工具利用动态执行跟踪和无监督机器学习方法，自动将提交代码分类到不同时间复杂度类别中，从而帮助教师识别算法类型而无需手动阅读源代码。CASET 可以改善评分过程，提供详细反馈，识别如硬编码等不正确算法策略。实验结果显示，该工具在排序、搜索和动态规划等算法类上表现出色，有效提升了自动评分的准确性和效率。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.15419v1",
      "published_date": "2024-10-20 15:29:50 UTC",
      "updated_date": "2024-10-20 15:29:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:00:32.803015"
    },
    {
      "arxiv_id": "2410.15413v1",
      "title": "A Comprehensive Evaluation of Cognitive Biases in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Malberg",
        "Roman Poletukhin",
        "Carolin M. Schuster",
        "Georg Groh"
      ],
      "abstract": "We present a large-scale evaluation of 30 cognitive biases in 20\nstate-of-the-art large language models (LLMs) under various decision-making\nscenarios. Our contributions include a novel general-purpose test framework for\nreliable and large-scale generation of tests for LLMs, a benchmark dataset with\n30,000 tests for detecting cognitive biases in LLMs, and a comprehensive\nassessment of the biases found in the 20 evaluated LLMs. Our work confirms and\nbroadens previous findings suggesting the presence of cognitive biases in LLMs\nby reporting evidence of all 30 tested biases in at least some of the 20 LLMs.\nWe publish our framework code to encourage future research on biases in LLMs:\nhttps://github.com/simonmalberg/cognitive-biases-in-llms",
      "tldr_zh": "本研究对20个最先进的大型语言模型(LLMs)进行了大规模评估，涵盖30种认知 biases 在各种决策场景下的表现。研究贡献包括开发了一个新型的通用测试框架，用于可靠生成测试，以及构建了一个包含30,000个测试的benchmark dataset，以检测LLMs中的认知偏差。结果显示，所有30种cognitive biases 至少在部分LLMs中存在，扩展了先前发现，并通过发布框架代码（https://github.com/simonmalberg/cognitive-biases-in-llms）鼓励未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15413v1",
      "published_date": "2024-10-20 15:07:51 UTC",
      "updated_date": "2024-10-20 15:07:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:00:44.294903"
    },
    {
      "arxiv_id": "2410.15409v1",
      "title": "PEAS: A Strategy for Crafting Transferable Adversarial Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Bar Avraham",
        "Yisroel Mirsky"
      ],
      "abstract": "Black box attacks, where adversaries have limited knowledge of the target\nmodel, pose a significant threat to machine learning systems. Adversarial\nexamples generated with a substitute model often suffer from limited\ntransferability to the target model. While recent work explores ranking\nperturbations for improved success rates, these methods see only modest gains.\nWe propose a novel strategy called PEAS that can boost the transferability of\nexisting black box attacks. PEAS leverages the insight that samples which are\nperceptually equivalent exhibit significant variability in their adversarial\ntransferability. Our approach first generates a set of images from an initial\nsample via subtle augmentations. We then evaluate the transferability of\nadversarial perturbations on these images using a set of substitute models.\nFinally, the most transferable adversarial example is selected and used for the\nattack. Our experiments show that PEAS can double the performance of existing\nattacks, achieving a 2.5x improvement in attack success rates on average over\ncurrent ranking methods. We thoroughly evaluate PEAS on ImageNet and CIFAR-10,\nanalyze hyperparameter impacts, and provide an ablation study to isolate each\ncomponent's importance.",
      "tldr_zh": "该论文提出 PEAS 策略，用于提升黑盒攻击（black box attacks）中对抗样本（adversarial examples）的转移性，以应对目标模型未知时的攻击挑战。PEAS 方法通过对初始样本进行微妙增强生成图像集，使用一组替代模型（substitute models）评估这些图像的对抗转移性，并选择最可转移的样本进行攻击。实验结果显示，PEAS 使现有攻击的成功率平均提高 2.5 倍，在 ImageNet 和 CIFAR-10 数据集上表现出色，并通过超参数分析和消融研究验证了各组件的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15409v1",
      "published_date": "2024-10-20 14:55:08 UTC",
      "updated_date": "2024-10-20 14:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:00:57.233998"
    },
    {
      "arxiv_id": "2410.15405v1",
      "title": "XAI-based Feature Ensemble for Enhanced Anomaly Detection in Autonomous Driving Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sazid Nazat",
        "Mustafa Abdallah"
      ],
      "abstract": "The rapid advancement of autonomous vehicle (AV) technology has introduced\nsignificant challenges in ensuring transportation security and reliability.\nTraditional AI models for anomaly detection in AVs are often opaque, posing\ndifficulties in understanding and trusting their decision making processes.\nThis paper proposes a novel feature ensemble framework that integrates multiple\nExplainable AI (XAI) methods: SHAP, LIME, and DALEX with various AI models to\nenhance both anomaly detection and interpretability. By fusing top features\nidentified by these XAI methods across six diverse AI models (Decision Trees,\nRandom Forests, Deep Neural Networks, K Nearest Neighbors, Support Vector\nMachines, and AdaBoost), the framework creates a robust and comprehensive set\nof features critical for detecting anomalies. These feature sets, produced by\nour feature ensemble framework, are evaluated using independent classifiers\n(CatBoost, Logistic Regression, and LightGBM) to ensure unbiased performance.\nWe evaluated our feature ensemble approach on two popular autonomous driving\ndatasets (VeReMi and Sensor) datasets. Our feature ensemble technique\ndemonstrates improved accuracy, robustness, and transparency of AI models,\ncontributing to safer and more trustworthy autonomous driving systems.",
      "tldr_zh": "该论文提出了一种基于可解释 AI (XAI) 的特征集成框架，用于提升自动驾驶系统中异常检测的准确性和透明度，以应对传统 AI 模型的不透明性问题。该框架整合了 SHAP、LIME 和 DALEX 等 XAI 方法，与 Decision Trees、Random Forests、Deep Neural Networks、K Nearest Neighbors、Support Vector Machines 和 AdaBoost 等六种 AI 模型相结合，融合关键特征集，并使用独立的分类器（如 CatBoost、Logistic Regression 和 LightGBM）进行无偏评估。在 VeReMi 和 Sensor 数据集上的实验显示，该方法显著提高了检测准确率和鲁棒性，从而增强了自动驾驶系统的安全性和可信度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, 4 figures (including the subfigures)",
      "pdf_url": "http://arxiv.org/pdf/2410.15405v1",
      "published_date": "2024-10-20 14:34:48 UTC",
      "updated_date": "2024-10-20 14:34:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:01:09.372717"
    },
    {
      "arxiv_id": "2410.15403v2",
      "title": "MMDS: A Multimodal Medical Diagnosis System Integrating Image Analysis and Knowledge-based Departmental Consultation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Ren",
        "HanZhi Zhang",
        "Weibin Li",
        "Jun Fu",
        "Diandong Liu",
        "Tianyi Zhang",
        "Jie He",
        "Licheng Jiao"
      ],
      "abstract": "We present MMDS, a system capable of recognizing medical images and patient\nfacial details, and providing professional medical diagnoses. The system\nconsists of two core components:The first component is the analysis of medical\nimages and videos. We trained a specialized multimodal medical model capable of\ninterpreting medical images and accurately analyzing patients' facial emotions\nand facial paralysis conditions. The model achieved an accuracy of 72.59% on\nthe FER2013 facial emotion recognition dataset, with a 91.1% accuracy in\nrecognizing the \"happy\" emotion. In facial paralysis recognition, the model\nreached an accuracy of 92%, which is 30% higher than that of GPT-4o. Based on\nthis model, we developed a parser for analyzing facial movement videos of\npatients with facial paralysis, achieving precise grading of the paralysis\nseverity. In tests on 30 videos of facial paralysis patients, the system\ndemonstrated a grading accuracy of 83.3%.The second component is the generation\nof professional medical responses. We employed a large language model,\nintegrated with a medical knowledge base, to generate professional diagnoses\nbased on the analysis of medical images or videos. The core innovation lies in\nour development of a department-specific knowledge base routing management\nmechanism, in which the large language model categorizes data by medical\ndepartments and, during the retrieval process, determines the appropriate\nknowledge base to query. This significantly improves retrieval accuracy in the\nRAG (retrieval-augmented generation) process.",
      "tldr_zh": "我们介绍了 MMDS，一种整合图像分析和基于知识的部门咨询的多模态医疗诊断系统。该系统包括两个核心组件：第一个是医疗图像和视频分析，使用训练的多模态医疗模型在 FER2013 数据集上实现 72.59% 的面部情绪识别准确率，并在面瘫识别中达到 92% 的准确率，比 GPT-4o 高 30%，并对面瘫患者视频进行精确评分，测试中 30 个视频的准确率达 83.3%。第二个组件利用大型语言模型结合部门特定的知识库路由管理机制，在 RAG（检索增强生成）过程中根据医疗部门分类数据并选择合适知识库，提高诊断响应的专业性和准确性。整体而言，MMDS 为自动化医疗诊断提供了高效、可信赖的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15403v2",
      "published_date": "2024-10-20 14:31:05 UTC",
      "updated_date": "2024-11-25 12:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:01:21.184626"
    },
    {
      "arxiv_id": "2410.15396v1",
      "title": "The Best Defense is a Good Offense: Countering LLM-Powered Cyberattacks",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Ayzenshteyn",
        "Roy Weiss",
        "Yisroel Mirsky"
      ],
      "abstract": "As large language models (LLMs) continue to evolve, their potential use in\nautomating cyberattacks becomes increasingly likely. With capabilities such as\nreconnaissance, exploitation, and command execution, LLMs could soon become\nintegral to autonomous cyber agents, capable of launching highly sophisticated\nattacks. In this paper, we introduce novel defense strategies that exploit the\ninherent vulnerabilities of attacking LLMs. By targeting weaknesses such as\nbiases, trust in input, memory limitations, and their tunnel-vision approach to\nproblem-solving, we develop techniques to mislead, delay, or neutralize these\nautonomous agents. We evaluate our defenses under black-box conditions,\nstarting with single prompt-response scenarios and progressing to real-world\ntests using custom-built CTF machines. Our results show defense success rates\nof up to 90\\%, demonstrating the effectiveness of turning LLM vulnerabilities\ninto defensive strategies against LLM-driven cyber threats.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)用于自动化网络攻击的风险，包括侦察、利用和命令执行，并提出新型防御策略来针对这些攻击。策略利用LLMs的固有弱点，如偏差、对输入的信任、记忆限制和隧道视觉问题解决方法，通过误导、延迟或中和自主代理来实现防御。实验在黑箱条件下进行，从单一提示响应场景到真实世界CTF机器测试，结果显示防御成功率高达90%，证明了将LLMs弱点转化为有效防御手段的可行性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15396v1",
      "published_date": "2024-10-20 14:07:24 UTC",
      "updated_date": "2024-10-20 14:07:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:01:32.606242"
    },
    {
      "arxiv_id": "2410.15379v1",
      "title": "Synthetic Data Generation for Residential Load Patterns via Recurrent GAN and Ensemble Method",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Liang",
        "Ziheng Wang",
        "Hao Wang"
      ],
      "abstract": "Generating synthetic residential load data that can accurately represent\nactual electricity consumption patterns is crucial for effective power system\nplanning and operation. The necessity for synthetic data is underscored by the\ninherent challenges associated with using real-world load data, such as privacy\nconsiderations and logistical complexities in large-scale data collection. In\nthis work, we tackle the above-mentioned challenges by developing the Ensemble\nRecurrent Generative Adversarial Network (ERGAN) framework to generate\nhigh-fidelity synthetic residential load data. ERGAN leverages an ensemble of\nrecurrent Generative Adversarial Networks, augmented by a loss function that\nconcurrently takes into account adversarial loss and differences between\nstatistical properties. Our developed ERGAN can capture diverse load patterns\nacross various households, thereby enhancing the realism and diversity of the\nsynthetic data generated. Comprehensive evaluations demonstrate that our method\nconsistently outperforms established benchmarks in the synthetic generation of\nresidential load data across various performance metrics including diversity,\nsimilarity, and statistical measures. The findings confirm the potential of\nERGAN as an effective tool for energy applications requiring synthetic yet\nrealistic load data. We also make the generated synthetic residential load\npatterns publicly available.",
      "tldr_zh": "本研究针对住宅负载数据的生成问题，提出 ERGAN 框架，利用 ensemble of recurrent GANs 和一个结合对抗损失与统计属性差异的损失函数，生成高保真度的合成住宅负载数据，以克服隐私和数据收集的实际挑战。ERGAN 能够捕捉不同家庭的多样化负载模式，提升合成数据的真实性和多样性。实验评估显示，该方法在多样性、相似性及统计指标上显著优于现有基准模型，并公开提供了生成的合成数据作为资源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.15379v1",
      "published_date": "2024-10-20 12:33:38 UTC",
      "updated_date": "2024-10-20 12:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:01:44.444081"
    },
    {
      "arxiv_id": "2410.15374v1",
      "title": "Explainability of Point Cloud Neural Networks Using SMILE: Statistical Model-Agnostic Interpretability with Local Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mohammad Ahmadi",
        "Koorosh Aslansefat",
        "Ruben Valcarce-Dineiro",
        "Joshua Barnfather"
      ],
      "abstract": "In today's world, the significance of explainable AI (XAI) is growing in\nrobotics and point cloud applications, as the lack of transparency in\ndecision-making can pose considerable safety risks, particularly in autonomous\nsystems. As these technologies are integrated into real-world environments,\nensuring that model decisions are interpretable and trustworthy is vital for\noperational reliability and safety assurance. This study explores the\nimplementation of SMILE, a novel explainability method originally designed for\ndeep neural networks, on point cloud-based models. SMILE builds on LIME by\nincorporating Empirical Cumulative Distribution Function (ECDF) statistical\ndistances, offering enhanced robustness and interpretability, particularly when\nthe Anderson-Darling distance is used. The approach demonstrates superior\nperformance in terms of fidelity loss, R2 scores, and robustness across various\nkernel widths, perturbation numbers, and clustering configurations. Moreover,\nthis study introduces a stability analysis for point cloud data using the\nJaccard index, establishing a new benchmark and baseline for model stability in\nthis field. The study further identifies dataset biases in the classification\nof the 'person' category, emphasizing the necessity for more comprehensive\ndatasets in safety-critical applications like autonomous driving and robotics.\nThe results underscore the potential of advanced explainability models and\nhighlight areas for future research, including the application of alternative\nsurrogate models and explainability techniques in point cloud data.",
      "tldr_zh": "本文研究了在机器人和点云应用中解释性 AI (XAI) 的重要性，提出了一种新型方法 SMILE，它基于 LIME 并整合 Empirical Cumulative Distribution Function (ECDF) 统计距离（如 Anderson-Darling distance），以提升点云神经网络的可解释性和鲁棒性。实验结果显示，SMILE 在保真度损失、R2 分数和各种配置（如核宽度和扰动数量）上表现出色，并通过 Jaccard 指数引入了点云数据的稳定性分析，建立了新的基准。研究还揭示了数据集中的偏差问题，例如在“person”类别分类上，强调了为安全关键应用（如自动驾驶）开发更全面数据集的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15374v1",
      "published_date": "2024-10-20 12:13:59 UTC",
      "updated_date": "2024-10-20 12:13:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:03:49.993956"
    },
    {
      "arxiv_id": "2410.15371v1",
      "title": "FrameBridge: Improving Image-to-Video Generation with Bridge Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuji Wang",
        "Zehua Chen",
        "Xiaoyu Chen",
        "Jun Zhu",
        "Jianfei Chen"
      ],
      "abstract": "Image-to-video (I2V) generation is gaining increasing attention with its wide\napplication in video synthesis. Recently, diffusion-based I2V models have\nachieved remarkable progress given their novel design on network architecture,\ncascaded framework, and motion representation. However, restricted by their\nnoise-to-data generation process, diffusion-based methods inevitably suffer the\ndifficulty to generate video samples with both appearance consistency and\ntemporal coherence from an uninformative Gaussian noise, which may limit their\nsynthesis quality. In this work, we present FrameBridge, taking the given\nstatic image as the prior of video target and establishing a tractable bridge\nmodel between them. By formulating I2V synthesis as a frames-to-frames\ngeneration task and modelling it with a data-to-data process, we fully exploit\nthe information in input image and facilitate the generative model to learn the\nimage animation process. In two popular settings of training I2V models, namely\nfine-tuning a pre-trained text-to-video (T2V) model or training from scratch,\nwe further propose two techniques, SNR-Aligned Fine-tuning (SAF) and neural\nprior, which improve the fine-tuning efficiency of diffusion-based T2V models\nto FrameBridge and the synthesis quality of bridge-based I2V models\nrespectively. Experiments conducted on WebVid-2M and UCF-101 demonstrate that:\n(1) our FrameBridge achieves superior I2V quality in comparison with the\ndiffusion counterpart (zero-shot FVD 83 vs. 176 on MSR-VTT and non-zero-shot\nFVD 122 vs. 171 on UCF-101); (2) our proposed SAF and neural prior effectively\nenhance the ability of bridge-based I2V models in the scenarios of fine-tuning\nand training from scratch. Demo samples can be visited at:\nhttps://framebridge-demo.github.io/.",
      "tldr_zh": "本研究提出 FrameBridge 框架，使用 bridge models 将 Image-to-Video (I2V) 生成转化为帧到帧的数据到数据任务，利用输入静态图像作为先验，以提升生成视频的外观一致性和时间连贯性。论文引入 SNR-Aligned Fine-tuning (SAF) 用于微调预训练的 Text-to-Video (T2V) 模型，以及 neural prior 技术来提升从零训练的合成质量。实验在 WebVid-2M 和 UCF-101 数据集上表明，FrameBridge 在 FVD 指标上显著优于扩散模型，例如在 MSR-VTT 的零-shot FVD 为 83 vs. 176。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15371v1",
      "published_date": "2024-10-20 12:10:24 UTC",
      "updated_date": "2024-10-20 12:10:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:02:09.798304"
    },
    {
      "arxiv_id": "2410.15369v1",
      "title": "Ethical AI in Retail: Consumer Privacy and Fairness",
      "title_zh": "零售业的伦理 AI：",
      "authors": [
        "Anthonette Adanyin"
      ],
      "abstract": "The adoption of artificial intelligence (AI) in retail has significantly\ntransformed the industry, enabling more personalized services and efficient\noperations. However, the rapid implementation of AI technologies raises ethical\nconcerns, particularly regarding consumer privacy and fairness. This study aims\nto analyze the ethical challenges of AI applications in retail, explore ways\nretailers can implement AI technologies ethically while remaining competitive,\nand provide recommendations on ethical AI practices. A descriptive survey\ndesign was used to collect data from 300 respondents across major e-commerce\nplatforms. Data were analyzed using descriptive statistics, including\npercentages and mean scores. Findings shows a high level of concerns among\nconsumers regarding the amount of personal data collected by AI-driven retail\napplications, with many expressing a lack of trust in how their data is\nmanaged. Also, fairness is another major issue, as a majority believe AI\nsystems do not treat consumers equally, raising concerns about algorithmic\nbias. It was also found that AI can enhance business competitiveness and\nefficiency without compromising ethical principles, such as data privacy and\nfairness. Data privacy and transparency were highlighted as critical areas\nwhere retailers need to focus their efforts, indicating a strong demand for\nstricter data protection protocols and ongoing scrutiny of AI systems. The\nstudy concludes that retailers must prioritize transparency, fairness, and data\nprotection when deploying AI systems. The study recommends ensuring\ntransparency in AI processes, conducting regular audits to address biases,\nincorporating consumer feedback in AI development, and emphasizing consumer\ndata privacy.",
      "tldr_zh": "这篇论文探讨了 AI 在零售领域的伦理挑战，聚焦于消费者隐私和公平性问题，通过对 300 名受访者的描述性调查发现，消费者对个人数据收集和算法偏见高度担忧，同时认为 AI 系统可能导致不平等对待。研究结果显示，零售商可以通过加强数据隐私和透明度来实现 AI 的伦理实施，同时提升业务竞争力。论文推荐定期进行 AI 审计、纳入消费者反馈，并优先确保透明度和公平性，以促进可信赖的 AI 应用。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "17 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.15369v1",
      "published_date": "2024-10-20 12:00:14 UTC",
      "updated_date": "2024-10-20 12:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:02:20.591113"
    },
    {
      "arxiv_id": "2410.15362v1",
      "title": "Faster-GCG: Efficient Discrete Optimization Jailbreak Attacks against Aligned Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Li",
        "Zhuhong Li",
        "Qiongxiu Li",
        "Bingze Lee",
        "Jinghao Cui",
        "Xiaolin Hu"
      ],
      "abstract": "Aligned Large Language Models (LLMs) have demonstrated remarkable performance\nacross various tasks. However, LLMs remain susceptible to jailbreak adversarial\nattacks, where adversaries manipulate prompts to elicit malicious responses\nthat aligned LLMs should have avoided. Identifying these vulnerabilities is\ncrucial for understanding the inherent weaknesses of LLMs and preventing their\npotential misuse. One pioneering work in jailbreaking is the GCG attack, a\ndiscrete token optimization algorithm that seeks to find a suffix capable of\njailbreaking aligned LLMs. Despite the success of GCG, we find it suboptimal,\nrequiring significantly large computational costs, and the achieved\njailbreaking performance is limited. In this work, we propose Faster-GCG, an\nefficient adversarial jailbreak method by delving deep into the design of GCG.\nExperiments demonstrate that Faster-GCG can surpass the original GCG with only\n1/10 of the computational cost, achieving significantly higher attack success\nrates on various open-source aligned LLMs. In addition, We demonstrate that\nFaster-GCG exhibits improved attack transferability when testing on\nclosed-sourced LLMs such as ChatGPT.",
      "tldr_zh": "本研究针对 Aligned LLMs 的 jailbreak 攻击问题，提出 Faster-GCG，这是一种高效的离散优化方法，通过深入优化原有 GCG 攻击的设计来减少计算成本并提升性能。Faster-GCG 仅需 GCG 的 1/10 计算资源，即可在各种开源对齐 LLMs 上实现显著更高的攻击成功率。实验还证明，该方法具有更好的攻击转移性，可有效应用于闭源 LLMs 如 ChatGPT，从而帮助识别和防范 LLMs 的潜在弱点。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15362v1",
      "published_date": "2024-10-20 11:27:41 UTC",
      "updated_date": "2024-10-20 11:27:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:02:33.078870"
    },
    {
      "arxiv_id": "2410.15359v1",
      "title": "A Survey of Hallucination in Large Visual Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Lan",
        "Wenyi Chen",
        "Qingfeng Chen",
        "Shirui Pan",
        "Huiyu Zhou",
        "Yi Pan"
      ],
      "abstract": "The Large Visual Language Models (LVLMs) enhances user interaction and\nenriches user experience by integrating visual modality on the basis of the\nLarge Language Models (LLMs). It has demonstrated their powerful information\nprocessing and generation capabilities. However, the existence of\nhallucinations has limited the potential and practical effectiveness of LVLM in\nvarious fields. Although lots of work has been devoted to the issue of\nhallucination mitigation and correction, there are few reviews to summary this\nissue. In this survey, we first introduce the background of LVLMs and\nhallucinations. Then, the structure of LVLMs and main causes of hallucination\ngeneration are introduced. Further, we summary recent works on hallucination\ncorrection and mitigation. In addition, the available hallucination evaluation\nbenchmarks for LVLMs are presented from judgmental and generative perspectives.\nFinally, we suggest some future research directions to enhance the\ndependability and utility of LVLMs.",
      "tldr_zh": "这篇调查论文探讨了Large Visual Language Models (LVLMs)中的hallucination问题，这些错误生成限制了LVLMs在实际应用中的潜力和有效性。论文首先介绍了LVLMs的背景、结构以及hallucination的主要原因，然后总结了最近的相关研究，包括hallucination的修正和缓解策略。最终，它呈现了从判断和生成角度的评估基准，并提出未来研究方向，以提升LVLMs的可靠性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15359v1",
      "published_date": "2024-10-20 10:58:58 UTC",
      "updated_date": "2024-10-20 10:58:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:02:44.323122"
    },
    {
      "arxiv_id": "2410.15355v1",
      "title": "LAC: Graph Contrastive Learning with Learnable Augmentation in Continuous Space",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Lin",
        "Hongzheng Li",
        "Yingxia Shao",
        "Guanhua Ye",
        "Yawen Li",
        "Quanqing Xu"
      ],
      "abstract": "Graph Contrastive Learning frameworks have demonstrated success in generating\nhigh-quality node representations.\n  The existing research on efficient data augmentation methods and ideal\npretext tasks for graph contrastive learning remains limited, resulting in\nsuboptimal node representation in the unsupervised setting.\n  In this paper, we introduce LAC, a graph contrastive learning framework with\nlearnable data augmentation in an orthogonal continuous space. To capture the\nrepresentative information in the graph data during augmentation, we introduce\na continuous view augmenter, that applies both a masked topology augmentation\nmodule and a cross-channel feature augmentation module to adaptively augment\nthe topological information and the feature information within an orthogonal\ncontinuous space, respectively. The orthogonal nature of continuous space\nensures that the augmentation process avoids dimension collapse.\n  To enhance the effectiveness of pretext tasks, we propose an\ninformation-theoretic principle named InfoBal and introduce corresponding\npretext tasks. These tasks enable the continuous view augmenter to maintain\nconsistency in the representative information across views while maximizing\ndiversity between views, and allow the encoder to fully utilize the\nrepresentative information in the unsupervised setting. Our experimental\nresults show that LAC significantly outperforms the state-of-the-art\nframeworks.",
      "tldr_zh": "这篇论文提出了 LAC 框架，用于图对比学习（Graph Contrastive Learning），通过在正交连续空间中进行可学习增强（Learnable Augmentation），以生成高质量的节点表示并解决现有方法的局限性。LAC 引入了一个连续视图增强器，包括掩码拓扑增强模块和跨通道特征增强模块，来自适应地增强拓扑和特征信息，同时避免维度崩溃；此外，它还采用 InfoBal 信息理论原则设计 pretext 任务，确保视图间的一致性和多样性。实验结果显示，LAC 在无监督设置下显著优于最先进框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15355v1",
      "published_date": "2024-10-20 10:47:15 UTC",
      "updated_date": "2024-10-20 10:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:02:56.817875"
    },
    {
      "arxiv_id": "2410.15346v2",
      "title": "YOLO-RD: Introducing Relevant and Compact Explicit Knowledge to YOLO by Retriever-Dictionary",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Tang Tsui",
        "Chien-Yao Wang",
        "Hong-Yuan Mark Liao"
      ],
      "abstract": "Identifying and localizing objects within images is a fundamental challenge,\nand numerous efforts have been made to enhance model accuracy by experimenting\nwith diverse architectures and refining training strategies. Nevertheless, a\nprevalent limitation in existing models is overemphasizing the current input\nwhile ignoring the information from the entire dataset. We introduce an\ninnovative Retriever-Dictionary (RD) module to address this issue. This\narchitecture enables YOLO-based models to efficiently retrieve features from a\nDictionary that contains the insight of the dataset, which is built by the\nknowledge from Visual Models (VM), Large Language Models (LLM), or Visual\nLanguage Models (VLM). The flexible RD enables the model to incorporate such\nexplicit knowledge that enhances the ability to benefit multiple tasks,\nspecifically, segmentation, detection, and classification, from pixel to image\nlevel. The experiments show that using the RD significantly improves model\nperformance, achieving more than a 3\\% increase in mean Average Precision for\nobject detection with less than a 1% increase in model parameters. Beyond\n1-stage object detection models, the RD module improves the effectiveness of\n2-stage models and DETR-based architectures, such as Faster R-CNN and\nDeformable DETR. Code is released at https://github.com/henrytsui000/YOLO.",
      "tldr_zh": "这篇论文针对物体识别和定位任务中模型过度关注当前输入而忽略数据集整体信息的局限性，提出了 YOLO-RD 框架，该框架通过 Retriever-Dictionary (RD) 模块从由 Visual Models (VM)、Large Language Models (LLM) 或 Visual Language Models (VLM) 构建的知识库中高效检索相关特征。RD 模块增强了 YOLO 模型在 segmentation、detection 和 classification 等任务上的性能，从像素级到图像级实现全面提升。实验结果显示，RD 模块使物体检测的 mean Average Precision (mAP) 提高了超过 3%，而模型参数仅增加了不到 1%，并适用于 2-stage 模型如 Faster R-CNN 和 DETR-based 架构如 Deformable DETR。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15346v2",
      "published_date": "2024-10-20 09:38:58 UTC",
      "updated_date": "2025-02-08 10:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:04:53.327115"
    },
    {
      "arxiv_id": "2410.15343v1",
      "title": "POSE: Pose estimation Of virtual Sync Exhibit system",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Tang Tsui",
        "Yu-Rou Tuan",
        "Jia-You Chen"
      ],
      "abstract": "This work is a portable MetaVerse implementation, and we use 3D pose\nestimation with AI to make virtual avatars do synchronized actions and interact\nwith the environment. The motivation is that we find it inconvenient to use\njoysticks and sensors when playing with fitness rings. In order to replace\njoysticks and reduce costs, we developed a platform that can control virtual\navatars through pose estimation to identify the movements of real people, and\nwe also implemented a multi-process to achieve modularization and reduce the\noverall latency.",
      "tldr_zh": "这篇论文介绍了POSE系统，这是一个便携式元宇宙（MetaVerse）实现，利用3D pose estimation和AI，使虚拟头像同步真实人的动作并与环境互动。动机在于解决使用摇杆和传感器玩健身环的不便问题，从而降低成本和复杂性。该系统通过多进程技术实现模块化和减少整体延迟，提供更高效的用户交互体验。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15343v1",
      "published_date": "2024-10-20 09:34:15 UTC",
      "updated_date": "2024-10-20 09:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:04:13.395704"
    },
    {
      "arxiv_id": "2410.15341v1",
      "title": "IKDP: Inverse Kinematics through Diffusion Process",
      "title_zh": "IKDP: 通过扩散过程的逆运动学",
      "authors": [
        "Hao-Tang Tsui",
        "Yu-Rou Tuan",
        "Hong-Han Shuai"
      ],
      "abstract": "It is a common problem in robotics to specify the position of each joint of\nthe robot so that the endpoint reaches a certain target in space. This can be\nsolved in two ways, forward kinematics method and inverse kinematics method.\nHowever, inverse kinematics cannot be solved by an algorithm. The common method\nis the Jacobian inverse technique, and some people have tried to find the\nanswer by machine learning. In this project, we will show how to use the\nConditional Denoising Diffusion Probabilistic Model to integrate the solution\nof calculating IK. Index Terms: Inverse kinematics, Denoising Diffusion\nProbabilistic Model, self Attention, Transformer",
      "tldr_zh": "这篇论文介绍了 IKDP 方法，通过扩散过程（Diffusion Process）来解决机器人逆向运动学（Inverse Kinematics）问题，该问题涉及计算关节位置以使机器人末端到达特定空间目标。传统方法如雅可比逆矩阵技术或机器学习存在局限性，而本研究创新性地使用条件去噪扩散概率模型（Conditional Denoising Diffusion Probabilistic Model）整合 IK 解决方案。论文还结合 self Attention 和 Transformer 等技术，展示了这一方法的潜在应用，为机器人控制提供了一种新颖的计算框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15341v1",
      "published_date": "2024-10-20 09:21:04 UTC",
      "updated_date": "2024-10-20 09:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:04:25.439144"
    },
    {
      "arxiv_id": "2410.15322v2",
      "title": "FoMo: A Foundation Model for Mobile Traffic Forecasting with Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Haoye Chai",
        "Xiaoqian Qi",
        "Shiyuan Zhang",
        "Yong Li"
      ],
      "abstract": "Mobile traffic forecasting allows operators to anticipate network dynamics\nand performance in advance, offering substantial potential for enhancing\nservice quality and improving user experience. However, existing models are\noften task-oriented and are trained with tailored data, which limits their\neffectiveness in diverse mobile network tasks of Base Station (BS) deployment,\nresource allocation, energy optimization, etc. and hinders generalization\nacross different urban environments. Foundation models have made remarkable\nstrides across various domains of NLP and CV due to their multi-tasking\nadaption and zero/few-shot learning capabilities. In this paper, we propose an\ninnovative Foundation model for Mo}bile traffic forecasting (FoMo), aiming to\nhandle diverse forecasting tasks of short/long-term predictions and\ndistribution generation across multiple cities to support network planning and\noptimization. FoMo combines diffusion models and transformers, where various\nspatio-temporal masks are proposed to enable FoMo to learn intrinsic features\nof different tasks, and a contrastive learning strategy is developed to capture\nthe correlations between mobile traffic and urban contexts, thereby improving\nits transfer learning capability. Extensive experiments on 9 real-world\ndatasets demonstrate that FoMo outperforms current models concerning diverse\nforecasting tasks and zero/few-shot learning, showcasing a strong universality.",
      "tldr_zh": "该论文提出 FoMo，一种基于 Foundation Model 的移动流量预测模型，利用 diffusion models 和 transformers 来处理多样化的预测任务，包括短期/长期预测和分布生成，以支持多个城市的网络规划和优化。FoMo 创新性地引入各种 spatio-temporal masks 来学习不同任务的内在特征，并采用 contrastive learning strategy 来捕捉移动流量与城市环境的关联，从而提升模型的迁移学习能力。实验在 9 个真实数据集上表明，FoMo 在多样化预测任务和零/少样本学习方面优于现有模型，展示了强大的通用性和泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15322v2",
      "published_date": "2024-10-20 07:32:16 UTC",
      "updated_date": "2025-01-14 06:59:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:04:37.281118"
    },
    {
      "arxiv_id": "2410.15319v1",
      "title": "Causality for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anpeng Wu",
        "Kun Kuang",
        "Minqin Zhu",
        "Yingrong Wang",
        "Yujia Zheng",
        "Kairong Han",
        "Baohong Li",
        "Guangyi Chen",
        "Fei Wu",
        "Kun Zhang"
      ],
      "abstract": "Recent breakthroughs in artificial intelligence have driven a paradigm shift,\nwhere large language models (LLMs) with billions or trillions of parameters are\ntrained on vast datasets, achieving unprecedented success across a series of\nlanguage tasks. However, despite these successes, LLMs still rely on\nprobabilistic modeling, which often captures spurious correlations rooted in\nlinguistic patterns and social stereotypes, rather than the true causal\nrelationships between entities and events. This limitation renders LLMs\nvulnerable to issues such as demographic biases, social stereotypes, and LLM\nhallucinations. These challenges highlight the urgent need to integrate\ncausality into LLMs, moving beyond correlation-driven paradigms to build more\nreliable and ethically aligned AI systems.\n  While many existing surveys and studies focus on utilizing prompt engineering\nto activate LLMs for causal knowledge or developing benchmarks to assess their\ncausal reasoning abilities, most of these efforts rely on human intervention to\nactivate pre-trained models. How to embed causality into the training process\nof LLMs and build more general and intelligent models remains unexplored.\nRecent research highlights that LLMs function as causal parrots, capable of\nreciting causal knowledge without truly understanding or applying it. These\nprompt-based methods are still limited to human interventional improvements.\nThis survey aims to address this gap by exploring how causality can enhance\nLLMs at every stage of their lifecycle-from token embedding learning and\nfoundation model training to fine-tuning, alignment, inference, and\nevaluation-paving the way for more interpretable, reliable, and\ncausally-informed models. Additionally, we further outline six promising future\ndirections to advance LLM development, enhance their causal reasoning\ncapabilities, and address the current limitations these models face.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）依赖概率建模而捕捉虚假相关性的问题，导致偏见、社会刻板印象和幻觉等挑战，强调需要将因果性整合到LLMs中以构建更可靠和道德的AI系统。现有方法主要依赖提示工程和基准测试，但这些多需人类干预，且LLMs仅能“鹦鹉学舌”式地处理因果知识，而非真正理解。论文通过调查在LLMs生命周期各阶段（如token嵌入学习、基础模型训练、微调、对齐、推理和评估）中嵌入因果性的方式，提供了一个全面框架，以提升模型的可解释性和可靠性。最后，论文概述了六个未来方向，旨在增强LLMs的因果推理能力并解决当前局限。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15319v1",
      "published_date": "2024-10-20 07:22:23 UTC",
      "updated_date": "2024-10-20 07:22:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:04:50.352535"
    },
    {
      "arxiv_id": "2410.15318v1",
      "title": "SNAP: Stopping Catastrophic Forgetting in Hebbian Learning with Sigmoidal Neuronal Adaptive Plasticity",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Xu",
        "Patrick Zheng",
        "Shiyan Liu",
        "Sicheng Lyu",
        "Isabeau Prémont-Schwarz"
      ],
      "abstract": "Artificial Neural Networks (ANNs) suffer from catastrophic forgetting, where\nthe learning of new tasks causes the catastrophic forgetting of old tasks.\nExisting Machine Learning (ML) algorithms, including those using Stochastic\nGradient Descent (SGD) and Hebbian Learning typically update their weights\nlinearly with experience i.e., independently of their current strength. This\ncontrasts with biological neurons, which at intermediate strengths are very\nplastic, but consolidate with Long-Term Potentiation (LTP) once they reach a\ncertain strength. We hypothesize this mechanism might help mitigate\ncatastrophic forgetting. We introduce Sigmoidal Neuronal Adaptive Plasticity\n(SNAP) an artificial approximation to Long-Term Potentiation for ANNs by having\nthe weights follow a sigmoidal growth behaviour allowing the weights to\nconsolidate and stabilize when they reach sufficiently large or small values.\nWe then compare SNAP to linear weight growth and exponential weight growth and\nsee that SNAP completely prevents the forgetting of previous tasks for Hebbian\nLearning but not for SGD-base learning.",
      "tldr_zh": "该研究针对人工神经网络（ANNs）中的灾难性遗忘（catastrophic forgetting）问题，提出了一种新的机制：Sigmoidal Neuronal Adaptive Plasticity (SNAP)。SNAP 通过让权重遵循 S 形增长行为，模拟生物神经元的 Long-Term Potentiation (LTP)，从而使权重在达到足够大或小值时巩固，以缓解 Hebbian Learning 中的遗忘。实验结果显示，与线性权重增长和指数权重增长相比，SNAP 在 Hebbian Learning 中完全防止了先前任务的遗忘，但在 Stochastic Gradient Descent (SGD)-based learning 中无效，为改进神经网络的可塑性提供了新思路。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "6 pages, 11 figures, accepted at Montr\\'eal AI and Neuroscience\n  (MAIN) 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2410.15318v1",
      "published_date": "2024-10-20 07:20:33 UTC",
      "updated_date": "2024-10-20 07:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:05:01.825284"
    },
    {
      "arxiv_id": "2410.15312v1",
      "title": "Synergistic Dual Spatial-aware Generation of Image-to-Text and Text-to-Image",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Zhao",
        "Hao Fei",
        "Xiangtai Li",
        "Libo Qin",
        "Jiayi Ji",
        "Hongyuan Zhu",
        "Meishan Zhang",
        "Min Zhang",
        "Jianguo Wei"
      ],
      "abstract": "In the visual spatial understanding (VSU) area, spatial image-to-text (SI2T)\nand spatial text-to-image (ST2I) are two fundamental tasks that appear in dual\nform. Existing methods for standalone SI2T or ST2I perform imperfectly in\nspatial understanding, due to the difficulty of 3D-wise spatial feature\nmodeling. In this work, we consider modeling the SI2T and ST2I together under a\ndual learning framework. During the dual framework, we then propose to\nrepresent the 3D spatial scene features with a novel 3D scene graph (3DSG)\nrepresentation that can be shared and beneficial to both tasks. Further,\ninspired by the intuition that the easier 3D$\\to$image and 3D$\\to$text\nprocesses also exist symmetrically in the ST2I and SI2T, respectively, we\npropose the Spatial Dual Discrete Diffusion (SD$^3$) framework, which utilizes\nthe intermediate features of the 3D$\\to$X processes to guide the hard X$\\to$3D\nprocesses, such that the overall ST2I and SI2T will benefit each other. On the\nvisual spatial understanding dataset VSD, our system outperforms the mainstream\nT2I and I2T methods significantly. Further in-depth analysis reveals how our\ndual learning strategy advances.",
      "tldr_zh": "本论文探讨了视觉空间理解（VSU）中的图像到文本（SI2T）和文本到图像（ST2I）任务，提出了一种协同双重学习框架来共同建模这两个任务，以克服现有方法在3D空间特征建模上的不足。论文引入了3D场景图（3DSG）表示作为共享特征，帮助提升任务间的互惠效果；同时，提出了Spatial Dual Discrete Diffusion (SD³)框架，利用3D到图像和3D到文本的中间特征来指导更复杂的图像到3D和文本到3D过程。实验结果显示，该系统在VSD数据集上显著优于主流T2I和I2T方法，并通过深入分析证明了双重学习策略的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15312v1",
      "published_date": "2024-10-20 06:47:34 UTC",
      "updated_date": "2024-10-20 06:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:05:14.107242"
    },
    {
      "arxiv_id": "2410.15311v1",
      "title": "Who is Undercover? Guiding LLMs to Explore Multi-Perspective Team Tactic in the Game",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi Dong",
        "Zhixuan Liao",
        "Guangwei Lai",
        "Yuhan Ma",
        "Danni Ma",
        "Chenyou Fan"
      ],
      "abstract": "Large Language Models (LLMs) are pivotal AI agents in complex tasks but still\nface challenges in open decision-making problems within complex scenarios. To\naddress this, we use the language logic game ``Who is Undercover?'' (WIU) as an\nexperimental platform to propose the Multi-Perspective Team Tactic (MPTT)\nframework. MPTT aims to cultivate LLMs' human-like language expression logic,\nmulti-dimensional thinking, and self-perception in complex scenarios. By\nalternating speaking and voting sessions, integrating techniques like\nself-perspective, identity-determination, self-reflection, self-summary and\nmulti-round find-teammates, LLM agents make rational decisions through\nstrategic concealment and communication, fostering human-like trust.\nPreliminary results show that MPTT, combined with WIU, leverages LLMs'\ncognitive capabilities to create a decision-making framework that can simulate\nreal society. This framework aids minority groups in communication and\nexpression, promoting fairness and diversity in decision-making. Additionally,\nour Human-in-the-loop experiments demonstrate that LLMs can learn and align\nwith human behaviors through interactive, indicating their potential for active\nparticipation in societal decision-making.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在复杂场景中的开放决策挑战，提出Multi-Perspective Team Tactic (MPTT)框架，以语言逻辑游戏“Who is Undercover?” (WIU)作为实验平台，培养LLMs的类人语言表达逻辑、多维思考和自我认知。框架通过交替的发言和投票环节，整合self-perspective、identity-determination、self-reflection、self-summary以及multi-round find-teammates等技术，使LLMs代理通过战略隐藏和沟通进行理性决策，增强类人信任。初步实验结果显示，MPTT利用LLMs的认知能力模拟真实社会，帮助少数群体沟通，促进决策中的公平和多样性；Human-in-the-loop实验进一步证明，LLMs可通过互动学习人类行为，在社会决策中发挥积极作用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15311v1",
      "published_date": "2024-10-20 06:41:31 UTC",
      "updated_date": "2024-10-20 06:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:05:25.687790"
    },
    {
      "arxiv_id": "2410.15308v2",
      "title": "LlamaLens: Specialized Multilingual LLM for Analyzing News and Social Media Content",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Bayan Kmainasi",
        "Ali Ezzat Shahroor",
        "Maram Hasanain",
        "Sahinur Rahman Laskar",
        "Naeemul Hassan",
        "Firoj Alam"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable success as\ngeneral-purpose task solvers across various fields. However, their capabilities\nremain limited when addressing domain-specific problems, particularly in\ndownstream NLP tasks. Research has shown that models fine-tuned on\ninstruction-based downstream NLP datasets outperform those that are not\nfine-tuned. While most efforts in this area have primarily focused on\nresource-rich languages like English and broad domains, little attention has\nbeen given to multilingual settings and specific domains. To address this gap,\nthis study focuses on developing a specialized LLM, LlamaLens, for analyzing\nnews and social media content in a multilingual context. To the best of our\nknowledge, this is the first attempt to tackle both domain specificity and\nmultilinguality, with a particular focus on news and social media. Our\nexperimental setup includes 18 tasks, represented by 52 datasets covering\nArabic, English, and Hindi. We demonstrate that LlamaLens outperforms the\ncurrent state-of-the-art (SOTA) on 23 testing sets, and achieves comparable\nperformance on 8 sets. We make the models and resources publicly available for\nthe research community\n(https://huggingface.co/collections/QCRI/llamalens-672f7e0604a0498c6a2f0fe9).",
      "tldr_zh": "本研究针对大语言模型 (LLMs) 在特定领域和多语言设置下的局限性，开发了 LlamaLens——一个专门用于分析新闻和社交媒体内容的专业多语言 LLM。该模型通过微调下游 NLP 任务数据集，首次同时处理领域特异性和多语言性，涵盖阿拉伯语、英语和印地语的18个任务及52个数据集。实验结果显示，LlamaLens在23个测试集上超越当前最先进 (SOTA) 模型，在8个集上表现相当，并已将模型和资源公开以供研究社区使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "LLMs, Multilingual, Language Diversity, Large Language Models, Social\n  Media, News Media, Specialized LLMs, Fact-checking, Media Analysis, Arabic,\n  Hindi, English",
      "pdf_url": "http://arxiv.org/pdf/2410.15308v2",
      "published_date": "2024-10-20 06:37:37 UTC",
      "updated_date": "2025-02-27 07:01:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:05:38.668865"
    },
    {
      "arxiv_id": "2410.15297v2",
      "title": "Redefining Proactivity for Information Seeking Dialogue",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Yang Lee",
        "Seokhwan Kim",
        "Kartik Mehta",
        "Jiun-Yu Kao",
        "Yu-Hsiang Lin",
        "Arpit Gupta"
      ],
      "abstract": "Information-Seeking Dialogue (ISD) agents aim to provide accurate responses\nto user queries. While proficient in directly addressing user queries, these\nagents, as well as LLMs in general, predominantly exhibit reactive behavior,\nlacking the ability to generate proactive responses that actively engage users\nin sustained conversations. However, existing definitions of proactive dialogue\nin this context do not focus on how each response actively engages the user and\nsustains the conversation. Hence, we present a new definition of proactivity\nthat focuses on enhancing the `proactiveness' of each generated response via\nthe introduction of new information related to the initial query. To this end,\nwe construct a proactive dialogue dataset comprising 2,000 single-turn\nconversations, and introduce several automatic metrics to evaluate response\n`proactiveness' which achieved high correlation with human annotation.\nAdditionally, we introduce two innovative Chain-of-Thought (CoT) prompts, the\n3-step CoT and the 3-in-1 CoT prompts, which consistently outperform standard\nprompts by up to 90% in the zero-shot setting.",
      "tldr_zh": "该论文重新定义了信息寻求对话（ISD）的主动性，强调每个响应通过引入与初始查询相关的新信息来主动参与并维持对话。研究者构建了一个包含 2,000 单轮对话的数据集，并引入了几个自动指标来评估响应的主动性，这些指标与人类标注高度相关。同时，论文提出了两种创新的 Chain-of-Thought (CoT) 提示——3-step CoT 和 3-in-1 CoT，在零样本（zero-shot）设置中比标准提示提升高达 90%。这项工作为提升 ISD 代理的互动性提供了新框架和评估工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15297v2",
      "published_date": "2024-10-20 05:57:10 UTC",
      "updated_date": "2024-11-18 02:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:05:49.712928"
    },
    {
      "arxiv_id": "2410.15293v1",
      "title": "Fractional-order spike-timing-dependent gradient descent for multi-layer spiking neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Yang",
        "Richard M. Voyles",
        "Haiyan H. Zhang",
        "Robert A. Nawrocki"
      ],
      "abstract": "Accumulated detailed knowledge about the neuronal activities in human brains\nhas brought more attention to bio-inspired spiking neural networks (SNNs). In\ncontrast to non-spiking deep neural networks (DNNs), SNNs can encode and\ntransmit spatiotemporal information more efficiently by exploiting biologically\nrealistic and low-power event-driven neuromorphic architectures. However, the\nsupervised learning of SNNs still remains a challenge because the\nspike-timing-dependent plasticity (STDP) of connected spiking neurons is\ndifficult to implement and interpret in existing backpropagation learning\nschemes. This paper proposes a fractional-order spike-timing-dependent gradient\ndescent (FO-STDGD) learning model by considering a derived nonlinear activation\nfunction that describes the relationship between the quasi-instantaneous firing\nrate and the temporal membrane potentials of nonleaky integrate-and-fire\nneurons. The training strategy can be generalized to any fractional orders\nbetween 0 and 2 since the FO-STDGD incorporates the fractional gradient descent\nmethod into the calculation of spike-timing-dependent loss gradients. The\nproposed FO-STDGD model is tested on the MNIST and DVS128 Gesture datasets and\nits accuracy under different network structure and fractional orders is\nanalyzed. It can be found that the classification accuracy increases as the\nfractional order increases, and specifically, the case of fractional order 1.9\nimproves by 155% relative to the case of fractional order 1 (traditional\ngradient descent). In addition, our scheme demonstrates the state-of-the-art\ncomputational efficacy for the same SNN structure and training epochs.",
      "tldr_zh": "这篇论文提出了一种分数阶尖峰时序相关梯度下降(FO-STDGD)学习模型，用于多层尖峰神经网络(SNNs)，以解决SNNs在监督学习中因尖峰时序依赖可塑性(STDP)难以实现的挑战。模型基于一个派生的非线性激活函数，描述非漏式积分放电神经元的放电率与膜电位关系，并将分数阶梯度下降方法融入损失梯度计算中，使其适用于0到2之间的任意分数阶。实验在MNIST和DVS128 Gesture数据集上显示，随着分数阶增加，分类准确性提升显著，例如分数阶1.9比传统梯度下降(分数阶1)提高了155%，并在相同SNN结构和训练周期下实现了最先进的计算效率。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "15 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15293v1",
      "published_date": "2024-10-20 05:31:34 UTC",
      "updated_date": "2024-10-20 05:31:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:06:03.124758"
    },
    {
      "arxiv_id": "2410.15285v2",
      "title": "Contextual Augmented Multi-Model Programming (CAMP): A Hybrid Local-Cloud Copilot Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Wang",
        "Shangxin Guo",
        "Chee Wei Tan"
      ],
      "abstract": "The advancements in cloud-based Large Languages Models (LLMs) have\nrevolutionized AI-assisted programming. However, their integration into certain\nlocal development environments like ones within the Apple software ecosystem\n(e.g., iOS apps, macOS) remains challenging due to computational demands and\nsandboxed constraints. This paper presents CAMP, a multi-model AI-assisted\nprogramming framework that consists of a local model that employs\nRetrieval-Augmented Generation (RAG) to retrieve contextual information from\nthe codebase to facilitate context-aware prompt construction thus optimizing\nthe performance of the cloud model, empowering LLMs' capabilities in local\nIntegrated Development Environments (IDEs). The methodology is actualized in\nCopilot for Xcode, an AI-assisted programming tool crafted for Xcode that\nemploys the RAG module to address software constraints and enables diverse\ngenerative programming tasks, including automatic code completion,\ndocumentation, error detection, and intelligent user-agent interaction. The\nresults from objective experiments on generated code quality and subjective\nexperiments on user adoption collectively demonstrate the pilot success of the\nproposed system and mark its significant contributions to the realm of\nAI-assisted programming.",
      "tldr_zh": "该论文提出 Contextual Augmented Multi-Model Programming (CAMP)，一种混合本地-云端框架，旨在解决云端 Large Language Models (LLMs) 在本地开发环境（如 Apple 生态系统）中的计算限制和沙箱约束问题。CAMP 通过本地模型利用 Retrieval-Augmented Generation (RAG) 从代码库中检索上下文信息，构建上下文感知提示，从而优化云模型在 Integrated Development Environments (IDEs) 中的性能，并应用于 Copilot for Xcode 支持代码补全、文档生成、错误检测和用户交互。实验结果显示，该框架在生成的代码质量和用户采用率方面表现出色，标志着对 AI 辅助编程领域的重大贡献。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This work is accepted to IEEE CAI2025",
      "pdf_url": "http://arxiv.org/pdf/2410.15285v2",
      "published_date": "2024-10-20 04:51:24 UTC",
      "updated_date": "2025-04-05 08:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:06:12.751383"
    },
    {
      "arxiv_id": "2410.15281v3",
      "title": "Large Language Models for Autonomous Driving (LLM4AD): Concept, Benchmark, Experiments, and Challenges",
      "title_zh": "大语言模型用于自动驾驶 (LLM4AD)：概念、基准、实验和挑战",
      "authors": [
        "Can Cui",
        "Yunsheng Ma",
        "Zichong Yang",
        "Yupeng Zhou",
        "Peiran Liu",
        "Juanwu Lu",
        "Lingxi Li",
        "Yaobin Chen",
        "Jitesh H. Panchal",
        "Amr Abdelraouf",
        "Rohit Gupta",
        "Kyungtae Han",
        "Ziran Wang"
      ],
      "abstract": "With the broader usage and highly successful development of Large Language\nModels (LLMs), there has been a growth of interest and demand for applying LLMs\nto autonomous driving technology. Driven by their natural language\nunderstanding and reasoning ability, LLMs have the potential to enhance various\naspects of autonomous driving systems, from perception and scene understanding\nto language interaction and decision-making. In this paper, we first introduce\nthe novel concept of designing LLMs for autonomous driving (LLM4AD). Then, we\npropose a comprehensive benchmark for evaluating the instruction-following\nabilities of LLM4AD in simulation. Furthermore, we conduct a series of\nexperiments on real-world vehicle platforms, thoroughly evaluating the\nperformance and potential of our LLM4AD systems. Finally, we envision the main\nchallenges of LLM4AD, including latency, deployment, security and privacy,\nsafety, trust and transparency, and personalization. Our research highlights\nthe significant potential of LLMs to enhance various aspects of autonomous\nvehicle technology, from perception and scene understanding to language\ninteraction and decision-making.",
      "tldr_zh": "这篇论文引入了LLM4AD概念，探讨如何将Large Language Models (LLMs)应用于自动驾驶系统，以提升感知、场景理解、语言交互和决策能力。作者提出一个全面基准，用于评估LLM4AD在模拟环境中的指令遵循性能，并通过真实车辆平台实验验证其实际效果。研究强调LLMs在自动驾驶领域的巨大潜力，但也指出了关键挑战，包括延迟、部署、安全隐私、安全性、信任透明度和个性化。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15281v3",
      "published_date": "2024-10-20 04:36:19 UTC",
      "updated_date": "2025-02-20 03:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:07:16.710508"
    },
    {
      "arxiv_id": "2410.15279v1",
      "title": "ContextDet: Temporal Action Detection with Adaptive Context Aggregation",
      "title_zh": "ContextDet: 时序动作检测的自适应上下文聚合",
      "authors": [
        "Ning Wang",
        "Yun Xiao",
        "Xiaopeng Peng",
        "Xiaojun Chang",
        "Xuanhong Wang",
        "Dingyi Fang"
      ],
      "abstract": "Temporal action detection (TAD), which locates and recognizes action\nsegments, remains a challenging task in video understanding due to variable\nsegment lengths and ambiguous boundaries. Existing methods treat neighboring\ncontexts of an action segment indiscriminately, leading to imprecise boundary\npredictions. We introduce a single-stage ContextDet framework, which makes use\nof large-kernel convolutions in TAD for the first time. Our model features a\npyramid adaptive context aggragation (ACA) architecture, capturing long context\nand improving action discriminability. Each ACA level consists of two novel\nmodules. The context attention module (CAM) identifies salient contextual\ninformation, encourages context diversity, and preserves context integrity\nthrough a context gating block (CGB). The long context module (LCM) makes use\nof a mixture of large- and small-kernel convolutions to adaptively gather\nlong-range context and fine-grained local features. Additionally, by varying\nthe length of these large kernels across the ACA pyramid, our model provides\nlightweight yet effective context aggregation and action discrimination. We\nconducted extensive experiments and compared our model with a number of\nadvanced TAD methods on six challenging TAD benchmarks: MultiThumos, Charades,\nFineAction, EPIC-Kitchens 100, Thumos14, and HACS, demonstrating superior\naccuracy at reduced inference speed.",
      "tldr_zh": "本论文针对时间动作检测 (Temporal Action Detection, TAD) 的挑战，如动作片段长度可变和边界模糊，提出了一种单阶段框架 ContextDet，这是首次在 TAD 中引入大核卷积。ContextDet 采用金字塔自适应上下文聚合 (Pyramid Adaptive Context Aggregation, ACA) 架构，通过 Context Attention Module (CAM) 和 Long Context Module (LCM) 模块来捕获长范围上下文、提升动作可区分性，其中 CAM 识别显著信息并用 Context Gating Block (CGB) 保留上下文完整性，而 LCM 混合使用大核和小核卷积以适应性聚合特征。实验在 MultiThumos、Charades、FineAction、EPIC-Kitchens 100、Thumos14 和 HACS 等六个基准上显示，ContextDet 比先进方法实现了更高的准确率，同时降低了推理速度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15279v1",
      "published_date": "2024-10-20 04:28:19 UTC",
      "updated_date": "2024-10-20 04:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:06:38.316092"
    },
    {
      "arxiv_id": "2410.15272v1",
      "title": "Performance-Driven QUBO for Recommender Systems on Quantum Annealers",
      "title_zh": "性能驱动的 QUBO 用于量子退火器上的推荐系统",
      "authors": [
        "Jiayang Niu",
        "Jie Li",
        "Ke Deng",
        "Mark Sanderson",
        "Yongli Ren"
      ],
      "abstract": "We propose Counterfactual Analysis Quadratic Unconstrained Binary\nOptimization (CAQUBO) to solve QUBO problems for feature selection in\nrecommender systems. CAQUBO leverages counterfactual analysis to measure the\nimpact of individual features and feature combinations on model performance and\nemploys the measurements to construct the coefficient matrix for a quantum\nannealer to select the optimal feature combinations for recommender systems,\nthereby improving their final recommendation performance. By establishing\nexplicit connections between features and the recommendation performance, the\nproposed approach demonstrates superior performance compared to the\nstate-of-the-art quantum annealing methods. Extensive experiments indicate that\nintegrating quantum computing with counterfactual analysis holds great promise\nfor addressing these challenges.",
      "tldr_zh": "本研究提出了一种名为 CAQUBO 的方法，用于解决推荐系统中的特征选择问题，该方法基于 Quadratic Unconstrained Binary Optimization (QUBO) 并结合 Counterfactual Analysis 来评估单个特征和组合特征对模型性能的影响。CAQUBO 通过这些评估构建量子退火器（Quantum Annealers）的系数矩阵，从而选择最优特征组合并提升推荐系统的整体性能。与现有量子退火方法相比，该方法在建立特征与推荐性能的明确联系方面表现出色。实验结果表明，量子计算与反事实分析的整合为解决相关挑战提供了巨大潜力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15272v1",
      "published_date": "2024-10-20 04:05:18 UTC",
      "updated_date": "2024-10-20 04:05:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:06:48.868704"
    },
    {
      "arxiv_id": "2410.15264v3",
      "title": "AI Can Enhance Creativity in Social Networks",
      "title_zh": "AI 可以增强社交网络中的创造力",
      "authors": [
        "Raiyan Abdul Baten",
        "Ali Sarosh Bangash",
        "Krish Veera",
        "Gourab Ghoshal",
        "Ehsan Hoque"
      ],
      "abstract": "Can peer recommendation engines elevate people's creative performances in\nself-organizing social networks? Answering this question requires resolving\nchallenges in data collection (e.g., tracing inspiration links and\npsycho-social attributes of nodes) and intervention design (e.g., balancing\nidea stimulation and redundancy in evolving information environments). We\ntrained a model that predicts people's ideation performances using semantic and\nnetwork-structural features in an online platform. Using this model, we built\nSocialMuse, which maximizes people's predicted performances to generate peer\nrecommendations for them. We found treatment networks leveraging SocialMuse\noutperforming AI-agnostic control networks in several creativity measures. The\ntreatment networks were more decentralized than the control, as SocialMuse\nincreasingly emphasized network-structural features at large network sizes.\nThis decentralization spreads people's inspiration sources, helping inspired\nideas stand out better. Our study provides actionable insights into building\nintelligent systems for elevating creativity.",
      "tldr_zh": "该研究探讨AI是否能通过同行推荐引擎提升人们在自组织社交网络中的创造性表现，针对数据收集和干预设计挑战，构建了SocialMuse系统，该系统利用语义和网络结构特征预测并最大化用户的构想表现。\n实验结果显示，使用SocialMuse的治疗网络在多个创造性指标上优于AI-agnostic控制网络，且这些网络更趋于decentralized，帮助分散灵感来源并使灵感想法更突出。\n这项研究为构建提升创造力的智能系统提供了可操作的见解。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15264v3",
      "published_date": "2024-10-20 03:33:25 UTC",
      "updated_date": "2024-12-11 16:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:09:01.609743"
    },
    {
      "arxiv_id": "2410.15262v1",
      "title": "HyQE: Ranking Contexts with Hypothetical Query Embeddings",
      "title_zh": "HyQE",
      "authors": [
        "Weichao Zhou",
        "Jiaxin Zhang",
        "Hilaf Hasson",
        "Anu Singh",
        "Wenchao Li"
      ],
      "abstract": "In retrieval-augmented systems, context ranking techniques are commonly\nemployed to reorder the retrieved contexts based on their relevance to a user\nquery. A standard approach is to measure this relevance through the similarity\nbetween contexts and queries in the embedding space. However, such similarity\noften fails to capture the relevance. Alternatively, large language models\n(LLMs) have been used for ranking contexts. However, they can encounter\nscalability issues when the number of candidate contexts grows and the context\nwindow sizes of the LLMs remain constrained. Additionally, these approaches\nrequire fine-tuning LLMs with domain-specific data. In this work, we introduce\na scalable ranking framework that combines embedding similarity and LLM\ncapabilities without requiring LLM fine-tuning. Our framework uses a\npre-trained LLM to hypothesize the user query based on the retrieved contexts\nand ranks the context based on the similarity between the hypothesized queries\nand the user query. Our framework is efficient at inference time and is\ncompatible with many other retrieval and ranking techniques. Experimental\nresults show that our method improves the ranking performance across multiple\nbenchmarks. The complete code and data are available at\nhttps://github.com/zwc662/hyqe",
      "tldr_zh": "该研究提出了一种名为 HyQE 的框架，用于检索增强系统中对上下文的排序，以提升查询相关性。HyQE 结合嵌入相似性和大型语言模型 (LLMs) 的能力，通过预训练的 LLM 根据检索到的上下文生成假设查询 (hypothetical query embeddings)，然后基于假设查询与用户查询的相似性重新排序上下文。该方法无需对 LLMs 进行微调，在推理时高效且兼容其他检索和排序技术。实验结果显示，HyQE 在多个基准上显著提高了排序性能，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15262v1",
      "published_date": "2024-10-20 03:15:01 UTC",
      "updated_date": "2024-10-20 03:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:07:12.991312"
    },
    {
      "arxiv_id": "2410.15252v1",
      "title": "Lossless KV Cache Compression to 2%",
      "title_zh": "无损 KV 缓存压缩至 2%",
      "authors": [
        "Zhen Yang",
        "J. N. Han",
        "Kan Wu",
        "Ruobing Xie",
        "An Wang",
        "Xingwu Sun",
        "Zhanhui Kang"
      ],
      "abstract": "Large language models have revolutionized data processing in numerous\ndomains, with their ability to handle extended context reasoning receiving\nnotable recognition. To speed up inference, maintaining a key-value (KV) cache\nmemory is essential. Nonetheless, the growing demands for KV cache memory\ncreate significant hurdles for efficient implementation. This work introduces a\nnovel architecture, Cross-Layer Latent Attention (CLLA), aimed at compressing\nthe KV cache to less than 2% of its original size while maintaining comparable\nperformance levels. CLLA integrates multiple aspects of KV cache compression,\nincluding attention head/dimension reduction, layer sharing, and quantization\ntechniques, into a cohesive framework. Our extensive experiments demonstrate\nthat CLLA achieves lossless performance on most tasks while utilizing minimal\nKV cache, marking a significant advancement in practical KV cache compression.",
      "tldr_zh": "本论文提出了 Cross-Layer Latent Attention (CLLA) 架构，用于将大型语言模型的 KV cache 压缩到原大小的不到 2%，同时保持性能无损。CLLA 通过整合注意力头/维度减少、层共享和量化技术，形成一个全面的压缩框架，以解决 KV cache 内存需求的挑战。实验结果显示，该方法在大多数任务上实现了无损性能，显著提升了模型的推理效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15252v1",
      "published_date": "2024-10-20 02:17:35 UTC",
      "updated_date": "2024-10-20 02:17:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:07:24.323171"
    },
    {
      "arxiv_id": "2410.15247v2",
      "title": "Tensor-Fused Multi-View Graph Contrastive Learning",
      "title_zh": "张量融合的多视图图对比学习",
      "authors": [
        "Yujia Wu",
        "Junyi Mo",
        "Elynn Chen",
        "Yuzhou Chen"
      ],
      "abstract": "Graph contrastive learning (GCL) has emerged as a promising approach to\nenhance graph neural networks' (GNNs) ability to learn rich representations\nfrom unlabeled graph-structured data. However, current GCL models face\nchallenges with computational demands and limited feature utilization, often\nrelying only on basic graph properties like node degrees and edge attributes.\nThis constrains their capacity to fully capture the complex topological\ncharacteristics of real-world phenomena represented by graphs. To address these\nlimitations, we propose Tensor-Fused Multi-View Graph Contrastive Learning\n(TensorMV-GCL), a novel framework that integrates extended persistent homology\n(EPH) with GCL representations and facilitates multi-scale feature extraction.\nOur approach uniquely employs tensor aggregation and compression to fuse\ninformation from graph and topological features obtained from multiple\naugmented views of the same graph. By incorporating tensor concatenation and\ncontraction modules, we reduce computational overhead by separating feature\ntensor aggregation and transformation. Furthermore, we enhance the quality of\nlearned topological features and model robustness through noise-injected EPH.\nExperiments on molecular, bioinformatic, and social network datasets\ndemonstrate TensorMV-GCL's superiority, outperforming 15 state-of-the-art\nmethods in graph classification tasks across 9 out of 11 benchmarks while\nachieving comparable results on the remaining two. The code for this paper is\npublicly available at https://github.com/CS-SAIL/Tensor-MV-GCL.git.",
      "tldr_zh": "这篇论文针对图对比学习(GCL)的计算需求高和特征利用有限问题，提出了Tensor-Fused Multi-View Graph Contrastive Learning (TensorMV-GCL)框架，该框架整合了Extended Persistent Homology (EPH)来提取多尺度图拓扑特征，并通过张量聚合、压缩和多视图增强融合信息。方法采用张量连接与收缩模块分离特征处理，减少计算开销，同时通过注入噪声的EPH提升拓扑特征质量和模型鲁棒性。在分子、生物信息学和社会网络数据集上的实验中，TensorMV-GCL优于15个最先进方法，在11个基准中的9个上实现最佳图分类性能，其余两个可比。代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15247v2",
      "published_date": "2024-10-20 01:40:12 UTC",
      "updated_date": "2025-03-09 01:31:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:07:39.126078"
    },
    {
      "arxiv_id": "2410.15238v1",
      "title": "Economic Anthropology in the Era of Generative Artificial Intelligence",
      "title_zh": "生成式人工智能时代下的经济人类学",
      "authors": [
        "Zachary Sheldon",
        "Peeyush Kumar"
      ],
      "abstract": "This paper explores the intersection of economic anthropology and generative\nartificial intelligence (GenAI). It examines how large language models (LLMs)\ncan simulate human decision-making and the inductive biases present in AI\nresearch. The study introduces two AI models: C.A.L.L.O.N. (Conventionally\nAverage Late Liberal ONtology) and M.A.U.S.S. (More Accurate Understanding of\nSociety and its Symbols). The former is trained on standard data, while the\nlatter is adapted with anthropological knowledge. The research highlights how\nanthropological training can enhance LLMs' ability to recognize diverse\neconomic systems and concepts. The findings suggest that integrating economic\nanthropology with AI can provide a more pluralistic understanding of economics\nand improve the sustainability of non-market economic systems.",
      "tldr_zh": "这篇论文探讨了经济人类学与生成式人工智能（GenAI）的交汇，考察大型语言模型（LLMs）如何模拟人类决策并揭示AI研究中的归纳偏差。\n研究引入了两个AI模型：C.A.L.L.O.N.（基于标准数据训练）和M.A.U.S.S.（整合人类学知识以提升模型能力）。\n结果表明，人类学训练能增强LLMs识别多样经济系统的能力，并建议这种整合可提供更多元的经济理解，同时改善非市场经济系统的可持续性。",
      "categories": [
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15238v1",
      "published_date": "2024-10-20 00:27:33 UTC",
      "updated_date": "2024-10-20 00:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:07:50.489919"
    },
    {
      "arxiv_id": "2410.15236v2",
      "title": "Jailbreaking and Mitigation of Vulnerabilities in Large Language Models",
      "title_zh": "大型语言模型的越狱攻击与漏洞缓解",
      "authors": [
        "Benji Peng",
        "Keyu Chen",
        "Qian Niu",
        "Ziqian Bi",
        "Ming Liu",
        "Pohsun Feng",
        "Tianyang Wang",
        "Lawrence K. Q. Yan",
        "Yizhu Wen",
        "Yichao Zhang",
        "Caitlyn Heqi Yin"
      ],
      "abstract": "Large Language Models (LLMs) have transformed artificial intelligence by\nadvancing natural language understanding and generation, enabling applications\nacross fields beyond healthcare, software engineering, and conversational\nsystems. Despite these advancements in the past few years, LLMs have shown\nconsiderable vulnerabilities, particularly to prompt injection and jailbreaking\nattacks. This review analyzes the state of research on these vulnerabilities\nand presents available defense strategies. We roughly categorize attack\napproaches into prompt-based, model-based, multimodal, and multilingual,\ncovering techniques such as adversarial prompting, backdoor injections, and\ncross-modality exploits. We also review various defense mechanisms, including\nprompt filtering, transformation, alignment techniques, multi-agent defenses,\nand self-regulation, evaluating their strengths and shortcomings. We also\ndiscuss key metrics and benchmarks used to assess LLM safety and robustness,\nnoting challenges like the quantification of attack success in interactive\ncontexts and biases in existing datasets. Identifying current research gaps, we\nsuggest future directions for resilient alignment strategies, advanced defenses\nagainst evolving attacks, automation of jailbreak detection, and consideration\nof ethical and societal impacts. This review emphasizes the need for continued\nresearch and cooperation within the AI community to enhance LLM security and\nensure their safe deployment.",
      "tldr_zh": "这篇综述分析了 Large Language Models (LLMs) 的漏洞，特别是 prompt injection 和 jailbreaking 攻击，并将攻击方法分类为基于提示的、模型-based、多模态和多语言类型，包括对抗性提示和跨模态利用技术。\n论文审查了防御策略，如 prompt filtering、transformation、alignment techniques、多代理防御和 self-regulation，并评估了它们的优势（如提升安全性）和缺点（如潜在局限性）。\n此外，它讨论了评估 LLM 安全性和鲁棒性的关键指标和基准，指出挑战如量化交互式攻击成功率和数据集偏差，并建议未来方向，包括开发弹性对齐策略、先进防御机制、自动化 jailbreak 检测，以及考虑伦理和社会影响，以推动 AI 社区的合作和安全部署。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15236v2",
      "published_date": "2024-10-20 00:00:56 UTC",
      "updated_date": "2025-05-08 13:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:09:14.243615"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 61,
  "processed_papers_count": 61,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T14:09:31.618526"
}