{
  "date": "2025-09-04",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-04 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“**ï¼š\nä»Šå¤©çš„ arXiv å……æ»¡äº†â€œAgenticï¼ˆä»£ç†åŒ–ï¼‰â€çš„æ°”æ¯ï¼Œä»å¿ƒç†å’¨è¯¢åˆ°å¸æ³•æ¨¡æ‹Ÿï¼Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMulti-Agent Systemsï¼‰çš„åº”ç”¨æ­£åœ¨çˆ†å‘ã€‚ç†è®ºæ–¹é¢ï¼Œä¸€ç¯‡å…³äº AI å¯¹é½ï¼ˆAlignmentï¼‰çš„â€œå¢¨è²å®šå¾‹â€è®ºæ–‡ç»™å‡ºäº†ä»¤äººæ·±çœçš„ä¸å¯èƒ½å®šç†ï¼›æ¶æ„å±‚é¢ï¼ŒMamba ä¸ CNN çš„èåˆä»¥åŠå¯¹ CoTï¼ˆæ€ç»´é“¾ï¼‰æœ¬è´¨çš„ç†è®ºæ¢ç´¢ä¹Ÿé¢‡å…·çœ‹ç‚¹ã€‚\n\nä»¥ä¸‹æ˜¯ä»Šæ—¥ç²¾é€‰çš„æ·±åº¦è§£è¯»ï¼š\n\n---\n\n### ğŸš€ å¿…è¯»ï¼šAI å¯¹é½ä¸ç†è®ºåŸºç¡€\n\n**1. AI å¯¹é½çš„å¢¨è²å®šå¾‹ï¼šä¸ºä½•å·®è·æ€»æ˜¯èƒœå‡º**\n**# Murphy's Laws of AI Alignment: Why the Gap Always Wins**\nè¿™ç¯‡è®ºæ–‡éå¸¸ç¡¬æ ¸ï¼Œæä¾›äº†ä¸€ä¸ªå…³äº AI å¯¹é½çš„å½¢å¼åŒ–ä¸å¯èƒ½å®šç†ã€‚\n- **æ ¸å¿ƒè§‚ç‚¹**ï¼šä½œè€…è¯æ˜äº†å½“äººç±»åé¦ˆåœ¨æŸäº›ç‰¹å®šä¸Šä¸‹æ–‡ä¸­å­˜åœ¨ç³»ç»Ÿæ€§åå·®ï¼ˆbiasï¼‰æ—¶ï¼Œä»»ä½•å­¦ä¹ ç®—æ³•éƒ½éœ€è¦æŒ‡æ•°çº§çš„æ ·æœ¬é‡æ¥åŒºåˆ†â€œçœŸå®â€å¥–åŠ±å‡½æ•°å’Œæœ‰åå·®çš„å¥–åŠ±å‡½æ•°ã€‚\n- **ç»“è®º**ï¼šé™¤éæˆ‘ä»¬èƒ½ä¸»åŠ¨è¯†åˆ«åé¦ˆä¸å¯é çš„åŒºåŸŸï¼ˆCalibration Oracleï¼‰ï¼Œå¦åˆ™å¯¹é½é—®é¢˜åœ¨æ•°å­¦ä¸Šæ˜¯æŒ‡æ•°çº§å›°éš¾çš„ã€‚è¿™è¢«ç§°ä¸º AI å¯¹é½çš„â€œå¢¨è²å®šå¾‹â€ï¼šé™¤éä½ ä¸»åŠ¨ç»•è¿‡åå·®ï¼Œå¦åˆ™ä¼˜åŒ–ç›®æ ‡å’ŒçœŸå®æ„å›¾ä¹‹é—´çš„å·®è·æ°¸è¿œä¼šèµ¢ã€‚\n\n**2. CoT-Spaceï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„å†…éƒ¨æ…¢æ€è€ƒç†è®ºæ¡†æ¶**\n**# CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning**\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šè¯•å›¾è§£é‡Šä¸ºä»€ä¹ˆ Chain-of-Thought (CoT) æœ‰æ•ˆã€‚ä½œè€…æå‡ºäº† CoT-Space æ¡†æ¶ï¼Œå°† LLM çš„æ¨ç†ä»ç¦»æ•£çš„ token é¢„æµ‹é‡æ–°æ„æ¶ä¸ºåœ¨è¿ç»­è¯­ä¹‰ç©ºé—´ä¸­çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚\n- **å‘ç°**ï¼šç†è®ºæ¨å¯¼è¡¨æ˜ï¼ŒCoT çš„æœ€ä½³é•¿åº¦æ˜¯æ¬ æ‹Ÿåˆä¸è¿‡æ‹Ÿåˆä¹‹é—´æƒè¡¡çš„è‡ªç„¶ç»“æœï¼Œä¸ºè§£å†³ LLM \"Overthinking\"ï¼ˆè¿‡åº¦æ€è€ƒï¼‰ç°è±¡æä¾›äº†ç†è®ºä¾æ®ã€‚\n\n**3. ç¥ç»è¶Šç‹±ï¼šæ­ç¤ºå¤§è¯­è¨€æ¨¡å‹çš„å†…éƒ¨è¶Šç‹±æœºåˆ¶**\n**# NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models**\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™æ˜¯ä¸€ä¸ªè‡ªä¸Šè€Œä¸‹çš„è¶Šç‹±åˆ†æç³»ç»Ÿã€‚ä¸åŒäºä»¥å¾€åªçœ‹è¾“å‡ºï¼ŒNeuroBreak æ·±å…¥åˆ°äº†ç¥ç»å…ƒçº§åˆ«ï¼ˆNeuron-levelï¼‰ã€‚\n- **å‘ç°**ï¼šé€šè¿‡å±‚çº§æ¢æµ‹ï¼ˆLayer-wise probingï¼‰ï¼Œä½œè€…å±•ç¤ºäº†æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å†³ç­–å˜åŒ–ï¼Œå¹¶è¯•å›¾ä»è¯­ä¹‰å’ŒåŠŸèƒ½è§’åº¦å®šä½é‚£äº›å¯¼è‡´é˜²å¾¡å¤±æ•ˆçš„â€œå…³é”®ç¥ç»å…ƒâ€ã€‚\n\n---\n\n### ğŸ¤– å¤šæ™ºèƒ½ä½“ä¸ Agent åº”ç”¨\n\n**4. MAGneTï¼šåˆæˆå¤šè½®å¿ƒç†å’¨è¯¢ä¼šè¯çš„åä½œå¤šæ™ºèƒ½ä½“ç”Ÿæˆ**\n**# MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions**\n- **èƒŒæ™¯**ï¼šé«˜è´¨é‡å¿ƒç†å’¨è¯¢æ•°æ®ç¨€ç¼ºä¸”æ•æ„Ÿã€‚\n- **æ–¹æ³•**ï¼šæå‡ºäº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå°†å’¨è¯¢å¸ˆçš„ååº”åˆ†è§£ä¸ºç”±ä¸“é—¨ Agent å¤„ç†çš„å­ä»»åŠ¡ï¼ˆä¾‹å¦‚æ¨¡æ‹Ÿä¸åŒçš„å¿ƒç†å­¦æŠ€æœ¯ï¼‰ã€‚\n- **æ•ˆæœ**ï¼šä¸“å®¶è¯„ä¼°æ˜¾ç¤ºï¼ŒMAGneT ç”Ÿæˆçš„ä¼šè¯åœ¨ 77.2% çš„æƒ…å†µä¸‹ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¾®è°ƒåçš„ Llama3-8B åœ¨å’¨è¯¢æŠ€å·§ä¸Šè¡¨ç°å‡ºè‰²ã€‚\n\n**5. EvoEmoï¼šè¿ˆå‘å¤šè½®ä»·æ ¼è°ˆåˆ¤ä¸­å¯¹æŠ—æ€§ LLM Agent çš„è¿›åŒ–æƒ…æ„Ÿç­–ç•¥**\n**# EvoEmo: Towards Evolved Emotional Policies for Adversarial LLM Agents in Multi-Turn Price Negotiation**\n- **æœ‰è¶£ç‚¹**ï¼šå¤§å¤šæ•° Agent åœ¨è°ˆåˆ¤ä¸­æ˜¯â€œè«å¾—æ„Ÿæƒ…â€çš„æ€æ‰‹ï¼Œæˆ–è€…æ˜¯è¢«åŠ¨ååº”ã€‚\n- **æ–¹æ³•**ï¼šæœ¬æ–‡è®© Agent â€œå­¦ä¼šâ€æ¼”åŒ–å‡ºæƒ…æ„Ÿç­–ç•¥ã€‚é€šè¿‡è¿›åŒ–å¼ºåŒ–å­¦ä¹ ï¼ŒAgent èƒ½å¤ŸåŠ¨æ€è¡¨è¾¾æƒ…æ„Ÿï¼ˆå¦‚æ„¤æ€’ã€å¤±æœ›æˆ–æ»¡æ„ï¼‰æ¥æœ€å¤§åŒ–è°ˆåˆ¤æ”¶ç›Šã€‚\n- **å‘ç°**ï¼šä¼šç”Ÿæ°”ã€ä¼šè¡¨è¾¾æƒ…ç»ªçš„ Agent åœ¨ç ä»·ä¸­æˆåŠŸç‡æ›´é«˜ï¼Œä¹°å®¶èŠ‚çœçš„é’±æ›´å¤šã€‚\n\n**6. SAMVADï¼šæ¨¡æ‹Ÿå°åº¦å¸æ³•å®¡è®®åŠ¨æ€çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**\n**# SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India**\n- **åº”ç”¨**ï¼šæ¨¡æ‹Ÿæ³•åº­ã€‚åŒ…å«æ³•å®˜ã€æ§æ–¹ã€è¾©æ–¹å’Œå¤šä¸ªå®¡åˆ¤å‘˜ Agentã€‚\n- **æŠ€æœ¯**ï¼šç»“åˆäº† RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ä»¥å¼•ç”¨çœŸå®çš„å°åº¦æ³•å¾‹æ–‡æ¡£ï¼ˆåˆ‘æ³•å…¸ç­‰ï¼‰ã€‚Agent ä»¬ä¼šè¿›è¡Œå¤šè½®è¾©è®ºå¹¶è¾¾æˆåˆ¤å†³ï¼Œä¸ºç ”ç©¶æ³•å¾‹æ¨ç†æä¾›äº†æ–°çš„æ²™ç›’ã€‚\n\n**7. FaMAï¼šC2C å¸‚åœºçš„ LLM èµ‹èƒ½ä»£ç†åŠ©æ‰‹**\n**# FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace**\n- **å·¥ç¨‹å®è·µ**ï¼šFacebook Marketplace çš„æ¡ˆä¾‹ã€‚\n- **è´¡çŒ®**ï¼šè®¾è®¡äº†ä¸€ä¸ª Agent åŠ©æ‰‹ï¼Œé€šè¿‡å¯¹è¯ç•Œé¢æ›¿ä»£å¤æ‚çš„ GUI æ“ä½œï¼ˆå¦‚å‘å¸ƒå•†å“ã€æ‰¹é‡å›å¤ï¼‰ã€‚åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¾¾åˆ°äº† 98% çš„æˆåŠŸç‡ï¼Œäº¤äº’é€Ÿåº¦æå‡ 2 å€ã€‚\n\n---\n\n### ğŸ§  æ¨¡å‹æ¶æ„ä¸è§†è§‰ (Vision & Architecture)\n\n**8. VCMambaï¼šé€šè¿‡å¤šå‘ Mamba è¿æ¥å·ç§¯ä»¥å®ç°é«˜æ•ˆè§†è§‰è¡¨ç¤º**\n**# VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation**\n- **èƒŒæ™¯**ï¼šViT æ“…é•¿å…¨å±€ï¼ŒCNN æ“…é•¿å±€éƒ¨ï¼ŒMamba æ“…é•¿çº¿æ€§å¤æ‚åº¦ã€‚\n- **æ–¹æ³•**ï¼šæ··åˆæ¶æ„ã€‚å‰æœŸç”¨ CNN æå–å±€éƒ¨ç‰¹å¾ï¼ŒåæœŸç”¨å¤šå‘ Mamba å¤„ç†é•¿è·ç¦»ä¾èµ–ã€‚\n- **ç»“æœ**ï¼šåœ¨ ImageNet ä¸Šï¼Œä»¥æ›´å°‘çš„å‚æ•°é‡å‡»è´¥äº† PlainMamba å’Œ Vision GNNï¼Œè¯æ˜äº†â€œCNN + SSMâ€æ··åˆæ¶æ„çš„æ½œåŠ›ã€‚\n\n**9. é€šè¿‡æ½œåœ¨å›æ”¾ç¼“è§£æ–‡ç”Ÿå›¾æ‰©æ•£æ¨¡å‹ä¸­çš„ç¾éš¾æ€§é—å¿˜**\n**# Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay**\n- **é—®é¢˜**ï¼šæ‰©æ•£æ¨¡å‹å­¦æ–°æ¦‚å¿µæ—¶å®¹æ˜“å¿˜æ—§æ¦‚å¿µï¼ˆç¾éš¾æ€§é—å¿˜ï¼‰æˆ–ç”Ÿæˆé‡å¤å›¾åƒï¼ˆæ¨¡å¼å´©å¡Œï¼‰ã€‚\n- **çµæ„Ÿ**ï¼šæ¥è‡ªç¥ç»ç§‘å­¦çš„æµ·é©¬ä½“ã€‚\n- **æ–¹æ³•**ï¼šLatent Replayã€‚ä¸å­˜åŸå§‹å›¾ç‰‡ï¼Œåªå­˜å‹ç¼©çš„æ½œåœ¨ç‰¹å¾ã€‚æƒŠäººçš„å‘ç°æ˜¯ï¼Œéšæœºé€‰æ‹©å­˜å‚¨çš„æ½œåœ¨æ ·æœ¬æ¯”åŸºäºç›¸ä¼¼åº¦çš„é€‰æ‹©æ•ˆæœæ›´å¥½ã€‚\n\n**10. å¯è§å´ä¸å¯è¯»ï¼šè·¨ä¹¦å†™ç³»ç»Ÿçš„è§†è§‰è¯­è¨€æ¨¡å‹ç³»ç»Ÿæ€§ç›²ç‚¹**\n**# Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems**\n*(æ³¨ï¼šåˆ—è¡¨æ˜¾ç¤ºæ­¤æ–‡è¢«arXivç®¡ç†å‘˜æ ‡è®°ä¸ºæ’¤å›/è¿è§„ï¼Œä½†åœ¨å­¦æœ¯è®¨è®ºä¸­å…¶æå‡ºçš„é—®é¢˜å€¼å¾—å…³æ³¨)*\n- **ç°è±¡**ï¼šäººç±»å³ä½¿çœ‹åˆ°ç ´ç¢ã€é‡å çš„æ–‡å­—ä¹Ÿèƒ½è®¤å‡ºæ¥ï¼Œä½† VLMï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰åšä¸åˆ°ã€‚è¿™è¡¨æ˜ VLM ä¸¥é‡ä¾èµ–é€šç”¨çš„è§†è§‰ä¸å˜æ€§ï¼Œè€Œç¼ºä¹äººç±»é‚£æ ·çš„ç»„åˆå…ˆéªŒï¼ˆcompositional priorsï¼‰ã€‚\n\n---\n\n### ğŸ¥ åŒ»ç–— AI (Medical AI)\n\n**11. DeepMedix-R1ï¼šé€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ è¿›è¡Œæ‰æ ¹æ¨ç†çš„èƒ¸éƒ¨ X å…‰è§£é‡ŠåŸºç¡€æ¨¡å‹**\n**# A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning**\n- **è¶‹åŠ¿**ï¼šåŒ»å­¦æ¨¡å‹å¼€å§‹å¼ºè°ƒâ€œæ¨ç†è¿‡ç¨‹â€ã€‚\n- **æ–¹æ³•**ï¼šç±»ä¼¼äº OpenAI o1/R1 çš„æ€è·¯ã€‚æ¨¡å‹ä¸ä»…è¾“å‡ºè¯Šæ–­ï¼Œè¿˜è¾“å‡ºä¸å›¾åƒå±€éƒ¨åŒºåŸŸç»‘å®šçš„æ¨ç†æ­¥éª¤ã€‚\n- **è®­ç»ƒ**ï¼šSFTï¼ˆæŒ‡ä»¤å¾®è°ƒï¼‰ -> åˆæˆæ¨ç†æ•°æ® -> åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOnline RLï¼‰ä¼˜åŒ–æ¨ç†è´¨é‡ã€‚\n\n**12. åƒäººç±»ä¸€æ ·ç¼–ç ï¼šåŒ»å­¦ç¼–ç çš„å¤šæ™ºèƒ½ä½“è§£å†³æ–¹æ¡ˆ**\n**# Code Like Humans: A Multi-Agent Solution for Medical Coding**\n- **ä»»åŠ¡**ï¼šå°†ä¸´åºŠç¬”è®°æ˜ å°„åˆ° ICD-10 ä»£ç ï¼ˆè¿™é€šå¸¸å¾ˆéš¾ï¼Œå› ä¸ºä»£ç æœ‰ 7ä¸‡+ï¼‰ã€‚\n- **æ–¹æ³•**ï¼šæ¨¡æ‹Ÿäººç±»ä¸“å®¶çš„ç¼–ç æŒ‡å—ï¼Œæ˜¯ä¸€ä¸ª Agentic æ¡†æ¶ã€‚è¿™æ˜¯é¦–ä¸ªæ”¯æŒå®Œæ•´ ICD-10 ç³»ç»Ÿçš„æ–¹æ¡ˆï¼Œç‰¹åˆ«æ˜¯åœ¨ç½•è§è¯Šæ–­ä»£ç ä¸Šè¡¨ç°å‡ºè‰²ã€‚\n\n---\n\n### ğŸ’¡ å€¼å¾—å…³æ³¨çš„å…¶ä»–è®ºæ–‡\n\n*   **[Reasoning] Matrix of Thought (æ€ç»´çŸ©é˜µ)**: **# Chain or tree? Re-evaluating complex reasoning from the perspective of a matrix of thought**\n    *   æå‡ºæ¯” CoT å’Œ ToT æ›´å¤æ‚çš„â€œæ€ç»´çŸ©é˜µâ€ï¼Œå¼•å…¥â€œåˆ—-å•å…ƒé€šä¿¡â€æœºåˆ¶ï¼Œè¯•å›¾åœ¨å¤šå®ä½“ã€å¤šè·³æ¨ç†ä¸­å‡å°‘å¹»è§‰ã€‚\n*   **[Prompting] Delta Activations**: **# Delta Activations: A Representation for Finetuned Large Language Models**\n    *   å°†å¾®è°ƒåçš„æ¨¡å‹è¡¨ç¤ºä¸ºç›¸å¯¹äºåŸºç¡€æ¨¡å‹çš„â€œæ¿€æ´»å¢é‡â€å‘é‡ã€‚è¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥å¯¹æ¨¡å‹è¿›è¡Œèšç±»ã€åˆå¹¶ï¼Œç”šè‡³é€šè¿‡ç®—æœ¯æ“ä½œæ··åˆå¾®è°ƒæ•°æ®é›†ã€‚\n*   **[Knowledge Graph] ODKE+**: **# ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs**\n    *   å·¥ä¸šçº§çŸ¥è¯†å›¾è°±æ„å»ºç³»ç»Ÿã€‚å¤„ç†äº† 900 ä¸‡ Wikipedia é¡µé¢ï¼Œæå–äº† 1900 ä¸‡ä¸ªäº‹å®ï¼Œç²¾ç¡®åº¦ 98.8%ã€‚\n*   **[Autonomous Driving] Bootstrapping RL**: **# Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving**\n    *   ç”¨åŸºäºè§„åˆ™çš„æ§åˆ¶å™¨ï¼ˆå³ä¾¿æ˜¯ä¸å®Œç¾çš„ï¼‰æ¥å¼•å¯¼å¼ºåŒ–å­¦ä¹  Agentï¼Œè§£å†³äº† RL åœ¨è‡ªåŠ¨é©¾é©¶ä¸­æ ·æœ¬æ•ˆç‡ä½çš„é—®é¢˜ã€‚\n\n---\n\n**ç»“è¯­**ï¼š\nä»Šå¤©çš„è®ºæ–‡å±•ç°äº†ä¸€ä¸ªæ˜æ˜¾çš„è¶‹åŠ¿ï¼šæˆ‘ä»¬æ­£ä»å•çº¯è®­ç»ƒæ›´å¤§çš„æ¨¡å‹ï¼Œè½¬å‘**å¦‚ä½•è®©æ¨¡å‹æ›´åƒä¸€ä¸ª Agentï¼ˆæœ‰æƒ…æ„Ÿã€èƒ½åä½œã€ä¼šæ¨ç†ï¼‰**ï¼Œä»¥åŠ**å¦‚ä½•åœ¨æ•°å­¦ä¸Šä¿è¯å®ƒä»¬çš„å®‰å…¨ä¸å¯¹é½**ã€‚\n\nç¥å¤§å®¶ç§‘ç ”é¡ºåˆ©ï¼Œé˜…è¯»æ„‰å¿«ï¼",
  "papers": [
    {
      "arxiv_id": "2509.04712v1",
      "title": "Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving",
      "title_zh": "åŸºäºæ¬¡ä¼˜ç­–ç•¥çš„è‡ªåŠ¨é©¾é©¶å¼ºåŒ–å­¦ä¹ è‡ªä¸¾",
      "authors": [
        "Zhihao Zhang",
        "Chengyang Peng",
        "Ekim Yurtsever",
        "Keith A. Redmill"
      ],
      "abstract": "Automated vehicle control using reinforcement learning (RL) has attracted significant attention due to its potential to learn driving policies through environment interaction. However, RL agents often face training challenges in sample efficiency and effective exploration, making it difficult to discover an optimal driving strategy. To address these issues, we propose guiding the RL driving agent with a demonstration policy that need not be a highly optimized or expert-level controller. Specifically, we integrate a rule-based lane change controller with the Soft Actor Critic (SAC) algorithm to enhance exploration and learning efficiency. Our approach demonstrates improved driving performance and can be extended to other driving scenarios that can similarly benefit from demonstration-based guidance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶è½¦è¾†æ§åˆ¶ä¸­å¼ºåŒ–å­¦ä¹  (RL) é¢ä¸´çš„æ ·æœ¬æ•ˆç‡ä½ä¸‹å’Œæ¢ç´¢æ•ˆç‡ä¸è¶³ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨æ¬¡ä¼˜æ¼”ç¤ºç­–ç•¥ (sub-optimal demonstration policies) å¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ çš„æ¡†æ¶ã€‚é€šè¿‡å°†åŸºäºè§„åˆ™çš„å˜é“æ§åˆ¶å™¨ (rule-based lane change controller) ä¸ Soft Actor Critic (SAC) ç®—æ³•ç›¸ç»“åˆï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºæ™ºèƒ½ä½“çš„æ¢ç´¢èƒ½åŠ›å¹¶æé«˜å­¦ä¹ æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆæ˜¾è‘—æå‡äº†è‡ªåŠ¨é©¾é©¶ä»»åŠ¡ä¸­çš„æ€§èƒ½è¡¨ç°ï¼Œä¸”å…·å¤‡è¾ƒå¼ºçš„æ‰©å±•æ€§ï¼Œå¯åº”ç”¨äºå…¶ä»–å—ç›Šäºæ¼”ç¤ºå¼•å¯¼çš„é©¾é©¶åœºæ™¯ã€‚è¿™ä¸€ç ”ç©¶ä¸ºè§£å†³å¼ºåŒ–å­¦ä¹ åœ¨å¤æ‚é©¾é©¶ä»»åŠ¡ä¸­éš¾ä»¥å‘ç°æœ€ä¼˜ç­–ç•¥çš„éš¾é¢˜æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å®ç”¨çš„å¼•å¯¼æœºåˆ¶ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04712v1",
      "published_date": "2025-09-04 23:56:26 UTC",
      "updated_date": "2025-09-04 23:56:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:28:33.584720+00:00"
    },
    {
      "arxiv_id": "2509.10529v1",
      "title": "Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay",
      "title_zh": "é€šè¿‡æ½œç©ºé—´é‡æ”¾ç¼“è§£æ–‡æœ¬ç”Ÿæˆå›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„ç¾éš¾æ€§é—å¿˜ä¸æ¨¡å¼å´©å¡Œ",
      "authors": [
        "Aoi Otani"
      ],
      "abstract": "Continual learning -- the ability to acquire knowledge incrementally without forgetting previous skills -- is fundamental to natural intelligence. While the human brain excels at this, artificial neural networks struggle with \"catastrophic forgetting,\" where learning new tasks erases previously acquired knowledge. This challenge is particularly severe for text-to-image diffusion models, which generate images from textual prompts. Additionally, these models face \"mode collapse,\" where their outputs become increasingly repetitive over time. To address these challenges, we apply Latent Replay, a neuroscience-inspired approach, to diffusion models. Traditional replay methods mitigate forgetting by storing and revisiting past examples, typically requiring large collections of images. Latent Replay instead retains only compact, high-level feature representations extracted from the model's internal architecture. This mirrors the hippocampal process of storing neural activity patterns rather than raw sensory inputs, reducing memory usage while preserving critical information. Through experiments with five sequentially learned visual concepts, we demonstrate that Latent Replay significantly outperforms existing methods in maintaining model versatility. After learning all concepts, our approach retained 77.59% Image Alignment (IA) on the earliest concept, 14% higher than baseline methods, while maintaining diverse outputs. Surprisingly, random selection of stored latent examples outperforms similarity-based strategies. Our findings suggest that Latent Replay enables efficient continual learning for generative AI models, paving the way for personalized text-to-image models that evolve with user needs without excessive computational costs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬ç”Ÿæˆå›¾åƒ(Text-to-Image)æ‰©æ•£æ¨¡å‹åœ¨æŒç»­å­¦ä¹ (Continual learning)è¿‡ç¨‹ä¸­é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜(Catastrophic forgetting)å’Œæ¨¡å¼å´©æºƒ(Mode collapse)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å—ç¥ç»ç§‘å­¦å¯å‘çš„Latent Replayæ–¹æ³•ã€‚è¯¥æ–¹æ³•æ¨¡æ‹Ÿæµ·é©¬ä½“å­˜å‚¨ç¥ç»æ´»åŠ¨æ¨¡å¼è€ŒéåŸå§‹æ„Ÿå®˜è¾“å…¥çš„æœºåˆ¶ï¼Œé€šè¿‡ä»…ä¿ç•™ä»æ¨¡å‹å†…éƒ¨æ¶æ„ä¸­æå–çš„ç´§å‡‘é«˜å±‚ç‰¹å¾è¡¨ç¤ºï¼Œåœ¨æ˜¾è‘—é™ä½å†…å­˜å ç”¨çš„åŒæ—¶æœ‰æ•ˆä¿ç•™äº†å…³é”®ä¿¡æ¯ã€‚åœ¨äº”ä¸ªè¿ç»­è§†è§‰æ¦‚å¿µçš„å­¦ä¹ å®éªŒä¸­ï¼ŒLatent Replayæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¯¹æœ€æ—©å­¦ä¹ æ¦‚å¿µçš„å›¾åƒå¯¹é½åº¦(Image Alignment, IA)ä¿ç•™ç‡è¾¾åˆ°77.59%ï¼Œæ¯”åŸºçº¿æ¨¡å‹é«˜å‡º14%ã€‚ç ”ç©¶å‘ç°ï¼Œéšæœºé€‰æ‹©å­˜å‚¨çš„æ½œåœ¨æ ·æœ¬åœ¨ç»´æŒè¾“å‡ºå¤šæ ·æ€§æ–¹é¢ä¼˜äºåŸºäºç›¸ä¼¼æ€§çš„ç­–ç•¥ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†Latent Replayèƒ½å¤Ÿå®ç°é«˜æ•ˆçš„ç”Ÿæˆå¼AIæŒç»­å­¦ä¹ ï¼Œä¸ºå¼€å‘å¯éšç”¨æˆ·éœ€æ±‚æ¼”è¿›ä¸”è®¡ç®—æˆæœ¬ä½å»‰çš„ä¸ªæ€§åŒ–æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10529v1",
      "published_date": "2025-09-04 23:45:22 UTC",
      "updated_date": "2025-09-04 23:45:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:28:58.991988+00:00"
    },
    {
      "arxiv_id": "2509.04696v1",
      "title": "ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs",
      "title_zh": "ODKE+ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æœ¬ä½“å¼•å¯¼å¼å¼€æ”¾åŸŸçŸ¥è¯†æŠ½å–",
      "authors": [
        "Samira Khorshidi",
        "Azadeh Nikfarjam",
        "Suprita Shankar",
        "Yisi Sang",
        "Yash Govind",
        "Hyun Jang",
        "Ali Kasgari",
        "Alexis McClimans",
        "Mohamed Soliman",
        "Vishnu Konda",
        "Ahmed Fakhry",
        "Xiaoguang Qi"
      ],
      "abstract": "Knowledge graphs (KGs) are foundational to many AI applications, but maintaining their freshness and completeness remains costly. We present ODKE+, a production-grade system that automatically extracts and ingests millions of open-domain facts from web sources with high precision. ODKE+ combines modular components into a scalable pipeline: (1) the Extraction Initiator detects missing or stale facts, (2) the Evidence Retriever collects supporting documents, (3) hybrid Knowledge Extractors apply both pattern-based rules and ontology-guided prompting for large language models (LLMs), (4) a lightweight Grounder validates extracted facts using a second LLM, and (5) the Corroborator ranks and normalizes candidate facts for ingestion. ODKE+ dynamically generates ontology snippets tailored to each entity type to align extractions with schema constraints, enabling scalable, type-consistent fact extraction across 195 predicates. The system supports batch and streaming modes, processing over 9 million Wikipedia pages and ingesting 19 million high-confidence facts with 98.8% precision. ODKE+ significantly improves coverage over traditional methods, achieving up to 48% overlap with third-party KGs and reducing update lag by 50 days on average. Our deployment demonstrates that LLM-based extraction, grounded in ontological structure and verification workflows, can deliver trustworthiness, production-scale knowledge ingestion with broad real-world applicability. A recording of the system demonstration is included with the submission and is also available at https://youtu.be/UcnE3_GsTWs.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† ODKE+ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ä» Web æ¥æºè‡ªåŠ¨æå–å¹¶æ‘„å…¥æ•°ç™¾ä¸‡ä¸ªå¼€æ”¾åŸŸäº‹å®çš„ç”Ÿäº§çº§ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ç»´æŠ¤æˆæœ¬é«˜ä¸”éš¾ä»¥ä¿æŒå®æ—¶æ€§çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿæ„å»ºäº†ä¸€ä¸ªç”± Extraction Initiatorã€Evidence Retrieverã€æ··åˆ Knowledge Extractorsã€Grounder å’Œ Corroborator ç»„æˆçš„äº”é˜¶æ®µå¯æ‰©å±•æµæ°´çº¿ã€‚ODKE+ åˆ›æ–°æ€§åœ°ç»“åˆäº†åŸºäºæ¨¡å¼çš„è§„åˆ™ä¸é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æœ¬ä½“å¼•å¯¼æç¤ºï¼ˆontology-guided promptingï¼‰ï¼Œé€šè¿‡åŠ¨æ€ç”Ÿæˆæœ¬ä½“ç‰‡æ®µç¡®ä¿æå–ç»“æœç¬¦åˆæ¨¡å¼çº¦æŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨å¤„ç†è¶…è¿‡ 900 ä¸‡ä¸ª Wikipedia é¡µé¢æ—¶ï¼Œä»¥ 98.8% çš„æé«˜ç²¾åº¦æ‘„å…¥äº† 1900 ä¸‡ä¸ªé«˜ç½®ä¿¡åº¦äº‹å®ã€‚ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼ŒODKE+ æ˜¾è‘—æå‡äº†çŸ¥è¯†è¦†ç›–èŒƒå›´ï¼Œå¹¶å°†çŸ¥è¯†åº“çš„æ›´æ–°æ»åæ—¶é—´å¹³å‡ç¼©çŸ­äº† 50 å¤©ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åŸºäº LLM çš„æå–æŠ€æœ¯åœ¨ç»“åˆæœ¬ä½“ç»“æ„å’ŒéªŒè¯å·¥ä½œæµåï¼Œèƒ½å¤Ÿå®ç°å…·å¤‡é«˜å¯ä¿¡åº¦å’Œç”Ÿäº§çº§è§„æ¨¡çš„çŸ¥è¯†æ‘„å…¥ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04696v1",
      "published_date": "2025-09-04 23:05:23 UTC",
      "updated_date": "2025-09-04 23:05:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:28:56.983864+00:00"
    },
    {
      "arxiv_id": "2509.05381v3",
      "title": "Murphys Laws of AI Alignment: Why the Gap Always Wins",
      "title_zh": "AI å¯¹é½çš„å¢¨è²å®šå¾‹ï¼šä¸ºä½•é¸¿æ²Ÿç»ˆå°†å–èƒœ",
      "authors": [
        "Madhava Gaikwad"
      ],
      "abstract": "We study reinforcement learning from human feedback under misspecification. Sometimes human feedback is systematically wrong on certain types of inputs, like a broken compass that points the wrong way in specific regions. We prove that when feedback is biased on a fraction alpha of contexts with bias strength epsilon, any learning algorithm needs exponentially many samples exp(n*alpha*epsilon^2) to distinguish between two possible \"true\" reward functions that differ only on these problematic contexts. However, if you can identify where feedback is unreliable (a \"calibration oracle\"), you can focus your limited questions there and overcome the exponential barrier with just O(1/(alpha*epsilon^2)) queries. This quantifies why alignment is hard: rare edge cases with subtly biased feedback create an exponentially hard learning problem unless you know where to look.\n  The gap between what we optimize (proxy from human feedback) and what we want (true objective) is fundamentally limited by how common the problematic contexts are (alpha), how wrong the feedback is there (epsilon), and how much the true objectives disagree there (gamma). Murphy's Law for AI alignment: the gap always wins unless you actively route around misspecification.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ¨¡å‹å¤±é…(misspecification)æƒ…å†µä¸‹çš„åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ (RLHF)é—®é¢˜ï¼Œåˆ†æäº†å½“äººç±»åé¦ˆåœ¨ç‰¹å®šè¾“å…¥ä¸Šå­˜åœ¨ç³»ç»Ÿæ€§é”™è¯¯æ—¶çš„å½±å“ã€‚ç ”ç©¶é€šè¿‡ç†è®ºè¯æ˜ï¼Œè‹¥åé¦ˆåœ¨æ¯”ä¾‹ä¸ºalphaçš„ä¸Šä¸‹æ–‡ä¸­å…·æœ‰å¼ºåº¦ä¸ºepsilonçš„åå·®ï¼Œä»»ä½•å­¦ä¹ ç®—æ³•éƒ½éœ€è¦æŒ‡æ•°çº§æ•°é‡çš„æ ·æœ¬æ‰èƒ½åœ¨è¿™äº›é—®é¢˜ä¸Šä¸‹æ–‡ä¸­åŒºåˆ†çœŸå®çš„å¥–åŠ±å‡½æ•°ã€‚ç„¶è€Œï¼Œå¦‚æœèƒ½å¤Ÿåˆ©ç”¨â€œæ ¡å‡†é¢„æµ‹å™¨â€(calibration oracle)è¯†åˆ«ä¸å¯é çš„åé¦ˆåŒºåŸŸï¼Œåˆ™å¯ä»¥å°†æŸ¥è¯¢å¤æ‚åº¦é™ä½è‡³å¤šé¡¹å¼çº§åˆ«ã€‚è¿™ä¸€ç»“æœé‡åŒ–äº†AIå¯¹é½(alignment)çš„æŒ‘æˆ˜æ€§ï¼Œå³å¸¦æœ‰ç»†å¾®åå·®åé¦ˆçš„ç½•è§è¾¹ç¼˜æ¡ˆä¾‹ä¼šå¯¼è‡´æŒ‡æ•°çº§çš„å­¦ä¹ éš¾é¢˜ã€‚ä½œè€…æ®æ­¤æå‡ºäº†AIå¯¹é½çš„å¢¨è²å®šå¾‹(Murphy's Law)ï¼ŒæŒ‡å‡ºé™¤éèƒ½å¤Ÿä¸»åŠ¨è¯†åˆ«å¹¶ç»•è¿‡å¤±é…åŒºåŸŸï¼Œå¦åˆ™ä»£ç†ç›®æ ‡ä¸çœŸå®ç›®æ ‡ä¹‹é—´çš„å·®è·(gap)å°†ä¸å¯é¿å…åœ°å¯¼è‡´å¯¹é½å¤±è´¥ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Provides a formal impossibility theorem (Murphys Gap) and welcomes collaboration on large-scale experiments and benchmark design",
      "pdf_url": "https://arxiv.org/pdf/2509.05381v3",
      "published_date": "2025-09-04 23:03:25 UTC",
      "updated_date": "2025-09-15 06:39:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:28:51.192857+00:00"
    },
    {
      "arxiv_id": "2509.04682v1",
      "title": "Ecologically Valid Benchmarking and Adaptive Attention: Scalable Marine Bioacoustic Monitoring",
      "title_zh": "ç”Ÿæ€æœ‰æ•ˆåŸºå‡†æµ‹è¯•ä¸è‡ªé€‚åº”æ³¨æ„åŠ›ï¼šå¯æ‰©å±•çš„æµ·æ´‹ç”Ÿç‰©å£°å­¦ç›‘æµ‹",
      "authors": [
        "Nicholas R. Rasmussen",
        "Rodrigue Rizk",
        "Longwei Wang",
        "KC Santosh"
      ],
      "abstract": "Underwater Passive Acoustic Monitoring (UPAM) provides rich spatiotemporal data for long-term ecological analysis, but intrinsic noise and complex signal dependencies hinder model stability and generalization. Multilayered windowing has improved target sound localization, yet variability from shifting ambient noise, diverse propagation effects, and mixed biological and anthropogenic sources demands robust architectures and rigorous evaluation. We introduce GetNetUPAM, a hierarchical nested cross-validation framework designed to quantify model stability under ecologically realistic variability. Data are partitioned into distinct site-year segments, preserving recording heterogeneity and ensuring each validation fold reflects a unique environmental subset, reducing overfitting to localized noise and sensor artifacts. Site-year blocking enforces evaluation against genuine environmental diversity, while standard cross-validation on random subsets measures generalization across UPAM's full signal distribution, a dimension absent from current benchmarks. Using GetNetUPAM as the evaluation backbone, we propose the Adaptive Resolution Pooling and Attention Network (ARPA-N), a neural architecture for irregular spectrogram dimensions. Adaptive pooling with spatial attention extends the receptive field, capturing global context without excessive parameters. Under GetNetUPAM, ARPA-N achieves a 14.4% gain in average precision over DenseNet baselines and a log2-scale order-of-magnitude drop in variability across all metrics, enabling consistent detection across site-year folds and advancing scalable, accurate bioacoustic monitoring.",
      "tldr_zh": "é’ˆå¯¹æ°´ä¸‹è¢«åŠ¨å£°å­¦ç›‘æµ‹(UPAM)ä¸­ç”±äºç¯å¢ƒå™ªå£°å¹²æ‰°å’Œä¿¡å·å¤æ‚æ€§å¯¼è‡´çš„æ¨¡å‹ç¨³å®šæ€§ä¸æ³›åŒ–ä¸è¶³é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†GetNetUPAMï¼Œä¸€ä¸ªåŸºäºå±‚æ¬¡åŒ–åµŒå¥—äº¤å‰éªŒè¯(hierarchical nested cross-validation)çš„è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç«™ç‚¹-å¹´ä»½(site-year)çš„æ•°æ®åˆ†å‰²æ–¹å¼ï¼Œç¡®ä¿æ¨¡å‹åœ¨çœŸå®çš„ç”Ÿæ€ç¯å¢ƒå¤šæ ·æ€§ä¸‹è¿›è¡ŒéªŒè¯ï¼Œä»è€Œæœ‰æ•ˆå‡å°‘å¯¹å±€éƒ¨å™ªå£°å’Œä¼ æ„Ÿå™¨ä¼ªå½±çš„è¿‡æ‹Ÿåˆã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è€…è®¾è®¡äº†è‡ªé€‚åº”åˆ†è¾¨ç‡æ± åŒ–ä¸æ³¨æ„åŠ›ç½‘ç»œ(ARPA-N)ï¼Œåˆ©ç”¨è‡ªé€‚åº”æ± åŒ–(adaptive pooling)å’Œç©ºé—´æ³¨æ„åŠ›(spatial attention)æœºåˆ¶å¤„ç†ä¸è§„åˆ™é¢‘è°±å›¾å¹¶æ•è·å…¨å±€ä¸Šä¸‹æ–‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒARPA-Nåœ¨GetNetUPAMæ¡†æ¶ä¸‹çš„å¹³å‡ç²¾åº¦(average precision)æ¯”DenseNetåŸºå‡†æ¨¡å‹æé«˜äº†14.4%ï¼Œä¸”åœ¨å„é¡¹æŒ‡æ ‡ä¸Šçš„å˜å¼‚åº¦å‘ˆæ•°é‡çº§ä¸‹é™ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°å¤§è§„æ¨¡ã€é«˜ç²¾åº¦çš„æµ·æ´‹ç”Ÿç‰©å£°å­¦ç›‘æµ‹æä¾›äº†ç¨³å®šä¸”å…·å¤‡ç”Ÿæ€æœ‰æ•ˆæ€§çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Under review as an anonymous submission to IEEETAI - We are allowed an archive submission. Final formatting is yet to be determined",
      "pdf_url": "https://arxiv.org/pdf/2509.04682v1",
      "published_date": "2025-09-04 22:03:05 UTC",
      "updated_date": "2025-09-04 22:03:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:28:47.086379+00:00"
    },
    {
      "arxiv_id": "2509.04676v1",
      "title": "An Approach to Grounding AI Model Evaluations in Human-derived Criteria",
      "title_zh": "ä¸€ç§å°†äººå·¥æ™ºèƒ½æ¨¡å‹è¯„ä¼°é”šå®šäºäººç±»å‡†åˆ™çš„æ–¹æ³•",
      "authors": [
        "Sasha Mitts"
      ],
      "abstract": "In the rapidly evolving field of artificial intelligence (AI), traditional benchmarks can fall short in attempting to capture the nuanced capabilities of AI models. We focus on the case of physical world modeling and propose a novel approach to augment existing benchmarks with human-derived evaluation criteria, aiming to enhance the interpretability and applicability of model behaviors. Grounding our study in the Perception Test and OpenEQA benchmarks, we conducted in-depth interviews and large-scale surveys to identify key cognitive skills, such as Prioritization, Memorizing, Discerning, and Contextualizing, that are critical for both AI and human reasoning. Our findings reveal that participants perceive AI as lacking in interpretive and empathetic skills yet hold high expectations for AI performance. By integrating insights from our findings into benchmark design, we offer a framework for developing more human-aligned means of defining and measuring progress. This work underscores the importance of user-centered evaluation in AI development, providing actionable guidelines for researchers and practitioners aiming to align AI capabilities with human cognitive processes. Our approach both enhances current benchmarking practices and sets the stage for future advancements in AI model evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»ŸåŸºå‡†æµ‹è¯•éš¾ä»¥æ•æ‰äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ç»†å¾®èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å°† AI æ¨¡å‹è¯„ä¼°æ¤æ ¹äºäººç±»è¡ç”Ÿæ ‡å‡†çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨æå‡æ¨¡å‹è¡Œä¸ºçš„å¯è§£é‡Šæ€§ä¸é€‚ç”¨æ€§ã€‚ç ”ç©¶ä»¥ Perception Test å’Œ OpenEQA ä¸ºåŸºç¡€ï¼Œé€šè¿‡æ·±åº¦è®¿è°ˆå’Œå¤§è§„æ¨¡è°ƒæŸ¥è¯†åˆ«å‡º Prioritizationã€Memorizingã€Discerning å’Œ Contextualizing ç­‰å¯¹ AI å’Œäººç±»æ¨ç†è‡³å…³é‡è¦çš„æ ¸å¿ƒè®¤çŸ¥æŠ€èƒ½ã€‚è°ƒæŸ¥å‘ç°å‚ä¸è€…è®¤ä¸º AI åœ¨è§£é‡Šæ€§å’Œå…±æƒ…èƒ½åŠ›ï¼ˆinterpretive and empathetic skillsï¼‰æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œä½†å¯¹å…¶æ€§èƒ½è¡¨ç°ä»æŒæœ‰æé«˜æœŸæœ›ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå°†äººç±»æ´å¯Ÿæ•´åˆè¿›åŸºå‡†æµ‹è¯•è®¾è®¡çš„æ¡†æ¶ï¼Œä¸ºå¼€å‘ç¬¦åˆäººç±»è®¤çŸ¥æ ‡å‡†çš„è¯„ä¼°ä½“ç³»æä¾›äº†å¯æ“ä½œçš„æŒ‡å—ã€‚è¯¥å·¥ä½œä¸ä»…å¢å¼ºäº†ç°æœ‰çš„åŸºå‡†æµ‹è¯•å®è·µï¼Œä¹Ÿä¸ºæœªæ¥ AI èƒ½åŠ›ä¸äººç±»è®¤çŸ¥è¿‡ç¨‹çš„å¯¹é½ä¸è¿›æ­¥å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "4 figures, 6 pages, presented at CHI 2025 Workshop on Human-AI Interaction for Augmented Reasoning",
      "pdf_url": "https://arxiv.org/pdf/2509.04676v1",
      "published_date": "2025-09-04 21:40:32 UTC",
      "updated_date": "2025-09-04 21:40:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:01.095794+00:00"
    },
    {
      "arxiv_id": "2509.10528v1",
      "title": "STM-Graph: A Python Framework for Spatio-Temporal Mapping and Graph Neural Network Predictions",
      "title_zh": "STM-Graphï¼šé¢å‘æ—¶ç©ºæ˜ å°„ä¸å›¾ç¥ç»ç½‘ç»œé¢„æµ‹çš„ Python æ¡†æ¶",
      "authors": [
        "Amirhossein Ghaffari",
        "Huong Nguyen",
        "Lauri LovÃ©n",
        "Ekaterina Gilman"
      ],
      "abstract": "Urban spatio-temporal data present unique challenges for predictive analytics due to their dynamic and complex nature. We introduce STM-Graph, an open-source Python framework that transforms raw spatio-temporal urban event data into graph representations suitable for Graph Neural Network (GNN) training and prediction. STM-Graph integrates diverse spatial mapping methods, urban features from OpenStreetMap, multiple GNN models, comprehensive visualization tools, and a graphical user interface (GUI) suitable for professional and non-professional users. This modular and extensible framework facilitates rapid experimentation and benchmarking. It allows integration of new mapping methods and custom models, making it a valuable resource for researchers and practitioners in urban computing. The source code of the framework and GUI are available at: https://github.com/Ahghaffari/stm_graph and https://github.com/tuminguyen/stm_graph_gui.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† STM-Graphï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„ Python æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŸå¸‚æ—¶ç©ºæ•°æ®åœ¨é¢„æµ‹åˆ†æä¸­é¢ä¸´çš„åŠ¨æ€ä¸”å¤æ‚çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿå°†åŸå§‹çš„æ—¶ç©ºåŸå¸‚äº‹ä»¶æ•°æ®è½¬æ¢ä¸ºé€‚ç”¨äº Graph Neural Network (GNN) è®­ç»ƒå’Œé¢„æµ‹çš„å›¾è¡¨ç¤ºå½¢å¼ã€‚STM-Graph é›†æˆäº†å¤šç§ç©ºé—´æ˜ å°„æ–¹æ³•ã€æ¥è‡ª OpenStreetMap çš„åŸå¸‚ç‰¹å¾ã€å¤šç§ GNN æ¨¡å‹ä»¥åŠå…¨é¢çš„å¯è§†åŒ–å·¥å…·ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜åŒ…å«ä¸€ä¸ªé€‚ç”¨äºä¸“ä¸šå’Œéä¸“ä¸šç”¨æˆ·çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ (GUI)ï¼Œæœ‰æ•ˆé™ä½äº†æ“ä½œé—¨æ§›ã€‚ä½œä¸ºä¸€ä¸ªæ¨¡å—åŒ–ä¸”å¯æ‰©å±•çš„ç³»ç»Ÿï¼ŒSTM-Graph æ”¯æŒç ”ç©¶è€…é›†æˆæ–°çš„æ˜ å°„æ–¹æ³•å’Œè‡ªå®šä¹‰æ¨¡å‹ï¼Œä¾¿äºè¿›è¡Œå¿«é€Ÿå®éªŒä¸åŸºå‡†æµ‹è¯•ã€‚è¯¥æ¡†æ¶ä¸ºåŸå¸‚è®¡ç®— (urban computing) é¢†åŸŸçš„ç§‘ç ”äººå‘˜å’Œä»ä¸šè€…æä¾›äº†é‡è¦å·¥å…·ï¼ŒåŠ©åŠ›å®ç°é«˜æ•ˆçš„æ—¶ç©ºæ•°æ®åˆ¶å›¾ä¸é¢„æµ‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted manuscript (CC BY 4.0). To appear in ACM CIKM 2025, Seoul, Nov 10-14, 2025. DOI: 10.1145/3746252.3761645. The Version of Record will be uploaded when available",
      "pdf_url": "https://arxiv.org/pdf/2509.10528v1",
      "published_date": "2025-09-04 21:36:48 UTC",
      "updated_date": "2025-09-04 21:36:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:07.991609+00:00"
    },
    {
      "arxiv_id": "2509.04669v1",
      "title": "VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation",
      "title_zh": "VCMambaï¼šèåˆå·ç§¯ä¸å¤šå‘ Mamba çš„é«˜æ•ˆè§†è§‰è¡¨ç¤º",
      "authors": [
        "Mustafa Munir",
        "Alex Zhang",
        "Radu Marculescu"
      ],
      "abstract": "Recent advances in Vision Transformers (ViTs) and State Space Models (SSMs) have challenged the dominance of Convolutional Neural Networks (CNNs) in computer vision. ViTs excel at capturing global context, and SSMs like Mamba offer linear complexity for long sequences, yet they do not capture fine-grained local features as effectively as CNNs. Conversely, CNNs possess strong inductive biases for local features but lack the global reasoning capabilities of transformers and Mamba. To bridge this gap, we introduce \\textit{VCMamba}, a novel vision backbone that integrates the strengths of CNNs and multi-directional Mamba SSMs. VCMamba employs a convolutional stem and a hierarchical structure with convolutional blocks in its early stages to extract rich local features. These convolutional blocks are then processed by later stages incorporating multi-directional Mamba blocks designed to efficiently model long-range dependencies and global context. This hybrid design allows for superior feature representation while maintaining linear complexity with respect to image resolution. We demonstrate VCMamba's effectiveness through extensive experiments on ImageNet-1K classification and ADE20K semantic segmentation. Our VCMamba-B achieves 82.6% top-1 accuracy on ImageNet-1K, surpassing PlainMamba-L3 by 0.3% with 37% fewer parameters, and outperforming Vision GNN-B by 0.3% with 64% fewer parameters. Furthermore, VCMamba-B obtains 47.1 mIoU on ADE20K, exceeding EfficientFormer-L7 by 2.0 mIoU while utilizing 62% fewer parameters. Code is available at https://github.com/Wertyuui345/VCMamba.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VCMambaï¼Œä¸€ç§æ—¨åœ¨æ•´åˆå·ç§¯ç¥ç»ç½‘ç»œ (CNNs) å±€éƒ¨ç‰¹å¾æå–ä¼˜åŠ¿ä¸å¤šå‘ Mamba çŠ¶æ€ç©ºé—´æ¨¡å‹ (Multi-directional Mamba SSMs) å…¨å±€æ¨ç†èƒ½åŠ›çš„æ–°å‹è§†è§‰éª¨å¹²ç½‘ç»œã€‚ä¸ºäº†å¼¥è¡¥ Vision Transformers (ViTs) å’Œ SSMs åœ¨æ•æ‰ç»†ç²’åº¦å±€éƒ¨ç‰¹å¾ä¸Šçš„ä¸è¶³ï¼ŒVCMamba é‡‡ç”¨äº†åˆ†å±‚ç»“æ„ï¼Œåœ¨æ¶æ„æ—©æœŸä½¿ç”¨å·ç§¯å—æå–å±€éƒ¨ç»†èŠ‚ï¼Œåœ¨åæœŸåˆ™åˆ©ç”¨å¤šå‘ Mamba å—é«˜æ•ˆå»ºæ¨¡é•¿ç¨‹ä¾èµ–ã€‚è¿™ç§æ··åˆæ¶æ„åœ¨ç»´æŒå›¾åƒåˆ†è¾¨ç‡çº¿æ€§å¤æ‚åº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†ç‰¹å¾è¡¨ç¤ºçš„å…¨é¢æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVCMamba-B åœ¨ ImageNet-1K åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ° 82.6% çš„ top-1 å‡†ç¡®ç‡ï¼Œä»¥æ›´å°‘çš„å‚æ•°è¶…è¶Šäº† PlainMamba-L3 å’Œ Vision GNN-Bã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨ ADE20K è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­å–å¾— 47.1 mIoUï¼Œç›¸è¾ƒäº EfficientFormer-L7 æ€§èƒ½æå‡æ˜æ˜¾ä¸”å‚æ•°é‡å¤§å¹…é™ä½ã€‚è¿™ä¸€æˆæœè¯æ˜äº†ç»“åˆå·ç§¯ä¸å¤šå‘ SSMs åœ¨æ„å»ºé«˜æ•ˆé€šç”¨è§†è§‰è¡¨ç¤ºæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Proceedings of the 2025 IEEE/CVF International Conference on Computer Vision (ICCV) Workshops",
      "pdf_url": "https://arxiv.org/pdf/2509.04669v1",
      "published_date": "2025-09-04 21:32:27 UTC",
      "updated_date": "2025-09-04 21:32:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:19.592962+00:00"
    },
    {
      "arxiv_id": "2509.04657v1",
      "title": "Evaluating NL2SQL via SQL2NL",
      "title_zh": "é€šè¿‡ SQL2NL è¯„ä¼° NL2SQL",
      "authors": [
        "Mohammadtaher Safarzadeh",
        "Afshin Oroojlooyjadid",
        "Dan Roth"
      ],
      "abstract": "Robust evaluation in the presence of linguistic variation is key to understanding the generalization capabilities of Natural Language to SQL (NL2SQL) models, yet existing benchmarks rarely address this factor in a systematic or controlled manner. We propose a novel schema-aligned paraphrasing framework that leverages SQL-to-NL (SQL2NL) to automatically generate semantically equivalent, lexically diverse queries while maintaining alignment with the original schema and intent. This enables the first targeted evaluation of NL2SQL robustness to linguistic variation in isolation-distinct from prior work that primarily investigates ambiguity or schema perturbations. Our analysis reveals that state-of-the-art models are far more brittle than standard benchmarks suggest. For example, LLaMa3.3-70B exhibits a 10.23% drop in execution accuracy (from 77.11% to 66.9%) on paraphrased Spider queries, while LLaMa3.1-8B suffers an even larger drop of nearly 20% (from 62.9% to 42.5%). Smaller models (e.g., GPT-4o mini) are disproportionately affected. We also find that robustness degradation varies significantly with query complexity, dataset, and domain -- highlighting the need for evaluation frameworks that explicitly measure linguistic generalization to ensure reliable performance in real-world settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºschema-aligned paraphrasingçš„æ–°é¢–æ¡†æ¶ï¼Œé€šè¿‡SQL2NLæŠ€æœ¯è‡ªåŠ¨ç”Ÿæˆè¯­ä¹‰ç­‰ä»·ä¸”è¯æ±‡å¤šæ ·åŒ–çš„æŸ¥è¯¢ï¼Œç”¨äºç³»ç»Ÿæ€§è¯„ä¼°NL2SQLæ¨¡å‹åœ¨è¯­è¨€å˜ä½“ï¼ˆlinguistic variationï¼‰ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™æ˜¯é¦–ä¸ªç‹¬ç«‹äºæ­§ä¹‰æˆ–æ¶æ„æ‰°åŠ¨ã€ä¸“é—¨é’ˆå¯¹è¯­è¨€é²æ£’æ€§çš„è¯„ä¼°ç ”ç©¶ï¼Œæ­ç¤ºäº†å½“å‰SOTAæ¨¡å‹æ¯”ä¼ ç»ŸåŸºå‡†æµ‹è¯•æ‰€æ˜¾ç¤ºçš„æ›´ä¸ºè„†å¼±ã€‚å®éªŒå‘ç°ï¼ŒLLaMa3.3-70Båœ¨ç»è¿‡æ”¹å†™çš„SpideræŸ¥è¯¢ä¸Šæ‰§è¡Œå‡†ç¡®ç‡ä¸‹é™äº†10.23%ï¼Œè€ŒLLaMa3.1-8Bçš„é™å¹…æ¥è¿‘20%ï¼Œä¸”GPT-4o miniç­‰è¾ƒå°æ¨¡å‹å—åˆ°çš„å½±å“æ›´ä¸ºæ˜¾è‘—ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé²æ£’æ€§çš„è¡°å‡ç¨‹åº¦ä¸æŸ¥è¯¢å¤æ‚åº¦å’Œé¢†åŸŸå¯†åˆ‡ç›¸å…³ï¼Œè¿›ä¸€æ­¥å¼ºè°ƒäº†åœ¨è¯„ä¼°ä¸­æ˜¾å¼æµ‹é‡è¯­è¨€æ³›åŒ–èƒ½åŠ›å¯¹äºç¡®ä¿ç°å®åº”ç”¨å¯é æ€§çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04657v1",
      "published_date": "2025-09-04 21:03:59 UTC",
      "updated_date": "2025-09-04 21:03:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:22.189298+00:00"
    },
    {
      "arxiv_id": "2509.05380v1",
      "title": "Cumplimiento del Reglamento (UE) 2024/1689 en robÃ³tica y sistemas autÃ³nomos: una revisiÃ³n sistemÃ¡tica de la literatura",
      "title_zh": "æœºå™¨äººä¸è‡ªä¸»ç³»ç»Ÿå¯¹æ¬§ç›Ÿ (EU) 2024/1689 æ¡ä¾‹çš„åˆè§„æ€§ï¼šç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°",
      "authors": [
        "Yoana Pita Lorenzo"
      ],
      "abstract": "This systematic literature review analyzes the current state of compliance with Regulation (EU) 2024/1689 in autonomous robotic systems, focusing on cybersecurity frameworks and methodologies. Using the PRISMA protocol, 22 studies were selected from 243 initial records across IEEE Xplore, ACM DL, Scopus, and Web of Science. Findings reveal partial regulatory alignment: while progress has been made in risk management and encrypted communications, significant gaps persist in explainability modules, real-time human oversight, and knowledge base traceability. Only 40% of reviewed solutions explicitly address transparency requirements, and 30% implement failure intervention mechanisms. The study concludes that modular approaches integrating risk, supervision, and continuous auditing are essential to meet the AI Act mandates in autonomous robotics.",
      "tldr_zh": "è¿™é¡¹ç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°åˆ†æäº†è‡ªä¸»æœºå™¨äººç³»ç»Ÿå¯¹æ¬§ç›Ÿæ¡ä¾‹ (EU) 2024/1689 (å³ AI Act) çš„åˆè§„ç°çŠ¶ï¼Œé‡ç‚¹æ¢è®¨äº†ç›¸å…³çš„ç½‘ç»œå®‰å…¨æ¡†æ¶ä¸æ–¹æ³•è®ºã€‚ç ”ç©¶é‡‡ç”¨ PRISMA åè®®ï¼Œä» IEEE Xploreã€ACM DLã€Scopus å’Œ Web of Science ç­‰æ ¸å¿ƒæ•°æ®åº“ä¸­ç­›é€‰å‡º 22 é¡¹ç ”ç©¶è¿›è¡Œæ·±å…¥åˆ†æã€‚ç»“æœæ˜¾ç¤ºç›®å‰çš„åˆè§„æ€§å‘ˆç°éƒ¨åˆ†å¯¹é½çŠ¶æ€ï¼Œè™½ç„¶åœ¨é£é™©ç®¡ç† (Risk Management) å’ŒåŠ å¯†é€šä¿¡æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†åœ¨å¯è§£é‡Šæ€§æ¨¡å— (Explainability Modules)ã€å®æ—¶äººå·¥ç›‘ç£ (Real-time Human Oversight) ä»¥åŠçŸ¥è¯†åº“å¯è¿½æº¯æ€§ (Knowledge Base Traceability) æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—å·®è·ã€‚è°ƒæŸ¥æ•°æ®è¡¨æ˜ï¼Œä»…æœ‰ 40% çš„è§£å†³æ–¹æ¡ˆæ˜ç¡®æ¶‰åŠé€æ˜åº¦è¦æ±‚ï¼Œä¸”åªæœ‰ 30% å®ç°äº†æ•…éšœå¹²é¢„æœºåˆ¶ã€‚è¯¥ç ”ç©¶æ€»ç»“è®¤ä¸ºï¼Œå¿…é¡»é‡‡ç”¨é›†æˆé£é™©ç®¡ç†ã€ç›‘ç£å’ŒæŒç»­å®¡è®¡çš„æ¨¡å—åŒ–æ–¹æ³•ï¼Œæ‰èƒ½ç¡®ä¿è‡ªä¸»æœºå™¨äººç³»ç»Ÿå…¨é¢æ»¡è¶³ AI Act çš„å¼ºåˆ¶æ€§è¦æ±‚ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.RO"
      ],
      "primary_category": "cs.CY",
      "comment": "in Spanish language",
      "pdf_url": "https://arxiv.org/pdf/2509.05380v1",
      "published_date": "2025-09-04 20:56:33 UTC",
      "updated_date": "2025-09-04 20:56:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:24.554334+00:00"
    },
    {
      "arxiv_id": "2509.04655v2",
      "title": "Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs",
      "title_zh": "Polysemantic Dropoutï¼šé¢å‘ä¸“ç”¨å¤§è¯­è¨€æ¨¡å‹çš„ç¬¦åˆæ€§ OOD æ£€æµ‹",
      "authors": [
        "Ayush Gupta",
        "Ramneet Kaur",
        "Anirban Roy",
        "Adam D. Cobb",
        "Rama Chellappa",
        "Susmit Jha"
      ],
      "abstract": "We propose a novel inference-time out-of-domain (OOD) detection algorithm for specialized large language models (LLMs). Despite achieving state-of-the-art performance on in-domain tasks through fine-tuning, specialized LLMs remain vulnerable to incorrect or unreliable outputs when presented with OOD inputs, posing risks in critical applications. Our method leverages the Inductive Conformal Anomaly Detection (ICAD) framework, using a new non-conformity measure based on the model's dropout tolerance. Motivated by recent findings on polysemanticity and redundancy in LLMs, we hypothesize that in-domain inputs exhibit higher dropout tolerance than OOD inputs. We aggregate dropout tolerance across multiple layers via a valid ensemble approach, improving detection while maintaining theoretical false alarm bounds from ICAD. Experiments with medical-specialized LLMs show that our approach detects OOD inputs better than baseline methods, with AUROC improvements of $2\\%$ to $37\\%$ when treating OOD datapoints as positives and in-domain test datapoints as negatives.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¾®è°ƒåçš„ä¸“ä¸šå¤§è¯­è¨€æ¨¡å‹ (Specialized LLMs) åœ¨é¢å¯¹åˆ†å¸ƒå¤– (Out-of-Domain, OOD) è¾“å…¥æ—¶å®¹æ˜“äº§ç”Ÿé”™è¯¯æˆ–ä¸å¯é è¾“å‡ºçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Polysemantic Dropout çš„æ–°å‹æ¨ç†æ—¶æ£€æµ‹ç®—æ³•ã€‚è¯¥æ–¹æ³•ä¾æ‰˜å½’çº³å…±å½¢å¼‚å¸¸æ£€æµ‹ (Inductive Conformal Anomaly Detection, ICAD) æ¡†æ¶ï¼Œå¹¶åˆ›æ–°æ€§åœ°å¼•å…¥äº†åŸºäºæ¨¡å‹ Dropout å®¹å¿åº¦ (Dropout Tolerance) çš„éå…±å½¢åº¦é‡ã€‚ç ”ç©¶è€…å—åˆ°å¤§æ¨¡å‹å¤šä¹‰æ€§ (Polysemanticity) ä¸å†—ä½™æ€§ç ”ç©¶çš„å¯å‘ï¼Œæå‡ºåŸŸå†…è¾“å…¥ç›¸è¾ƒäº OOD è¾“å…¥å…·æœ‰æ›´é«˜ Dropout å®¹å¿åº¦çš„å‡è®¾ã€‚é€šè¿‡ä¸€ç§æœ‰æ•ˆçš„é›†æˆæ–¹æ³•èšåˆå¤šä¸ªç¥ç»å±‚çš„ Dropout å®¹å¿åº¦ï¼Œè¯¥ç®—æ³•åœ¨ä¿è¯ ICAD ç†è®ºè¯¯æŠ¥ç•Œé™çš„åŒæ—¶æ˜¾è‘—å¼ºåŒ–äº†æ£€æµ‹ç²¾åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨åŒ»ç–—ä¸“ç”¨ LLMs åœºæ™¯ä¸‹ï¼Œè¯¥æ–¹æ³•æ¯”åŸºçº¿æ–¹æ¡ˆçš„ AUROC æå‡äº† 2% è‡³ 37%ã€‚è¿™ä¸€æˆæœä¸ºæé«˜ä¸“ç”¨åŒ–å¤§æ¨¡å‹åœ¨å…³é”®ä»»åŠ¡ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§æä¾›äº†é‡è¦çš„æ–¹æ³•è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025 main conference",
      "pdf_url": "https://arxiv.org/pdf/2509.04655v2",
      "published_date": "2025-09-04 20:50:51 UTC",
      "updated_date": "2025-09-15 19:42:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:42.059827+00:00"
    },
    {
      "arxiv_id": "2509.04653v2",
      "title": "Deriving Transformer Architectures as Implicit Multinomial Regression",
      "title_zh": "å°† Transformer æ¶æ„æ¨å¯¼ä¸ºéšå¼å¤šé¡¹å¼å›å½’",
      "authors": [
        "Jonas A. Actor",
        "Anthony Gruber",
        "Eric C. Cyr"
      ],
      "abstract": "While attention has been empirically shown to improve model performance, it lacks a rigorous mathematical justification. This short paper establishes a novel connection between attention mechanisms and multinomial regression. Specifically, we show that in a fixed multinomial regression setting, optimizing over latent features yields solutions that align with the dynamics induced on features by attention blocks. In other words, the evolution of representations through a transformer can be interpreted as a trajectory that recovers the optimal features for classification.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶å»ºç«‹äº†æ³¨æ„åŠ›æœºåˆ¶(attention mechanisms)ä¸å¤šé¡¹å¼å›å½’(multinomial regression)ä¹‹é—´çš„æ–°å‹æ•°å­¦è”ç³»ï¼Œæ—¨åœ¨ä¸ºTransformeræ¶æ„æä¾›æ›´ä¸¥è°¨çš„ç†è®ºè§£é‡Šã€‚ä½œè€…é€šè¿‡è¯æ˜åœ¨å›ºå®šçš„å¤šé¡¹å¼å›å½’è®¾å®šä¸‹ï¼Œå¯¹æ½œåœ¨ç‰¹å¾(latent features)è¿›è¡Œä¼˜åŒ–æ‰€äº§ç”Ÿçš„è§£ä¸æ³¨æ„åŠ›æ¨¡å—(attention blocks)å¼•å‘çš„ç‰¹å¾åŠ¨åŠ›å­¦ç›¸ä¸€è‡´ã€‚æ¢è¨€ä¹‹ï¼Œè¡¨ç¤º(representations)åœ¨Transformerä¸­çš„æ¼”åŒ–è¿‡ç¨‹å¯ä»¥è¢«è¯ é‡Šä¸ºä¸€ç§å¯»æ‰¾åˆ†ç±»æœ€ä½³ç‰¹å¾çš„è½¨è¿¹ã€‚è¯¥ç ”ç©¶ä¸ä»…å¡«è¡¥äº†æ³¨æ„åŠ›æœºåˆ¶ç¼ºä¹ä¸¥æ ¼æ•°å­¦è¯æ˜çš„ç©ºç™½ï¼Œè¿˜æ­ç¤ºäº†Transformeråœ¨å¤„ç†ç‰¹å¾æ¼”å˜æ—¶æœ¬è´¨ä¸Šæ˜¯åœ¨æ‰§è¡Œéšå¼çš„å¤šé¡¹å¼å›å½’ä¼˜åŒ–ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, additional 3 pages of references and supplementary details",
      "pdf_url": "https://arxiv.org/pdf/2509.04653v2",
      "published_date": "2025-09-04 20:40:37 UTC",
      "updated_date": "2025-10-27 16:26:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:47.753039+00:00"
    },
    {
      "arxiv_id": "2509.05379v1",
      "title": "ThreatGPT: An Agentic AI Framework for Enhancing Public Safety through Threat Modeling",
      "title_zh": "ThreatGPTï¼šé€šè¿‡å¨èƒå»ºæ¨¡æå‡å…¬å…±å®‰å…¨çš„æ™ºèƒ½ä½“ AI æ¡†æ¶",
      "authors": [
        "Sharif Noor Zisad",
        "Ragib Hasan"
      ],
      "abstract": "As our cities and communities become smarter, the systems that keep us safe, such as traffic control centers, emergency response networks, and public transportation, also become more complex. With this complexity comes a greater risk of security threats that can affect not just machines but real people's lives. To address this challenge, we present ThreatGPT, an agentic Artificial Intelligence (AI) assistant built to help people whether they are engineers, safety officers, or policy makers to understand and analyze threats in public safety systems. Instead of requiring deep cybersecurity expertise, it allows users to simply describe the components of a system they are concerned about, such as login systems, data storage, or communication networks. Then, with the click of a button, users can choose how they want the system to be analyzed by using popular frameworks such as STRIDE, MITRE ATT&CK, CVE reports, NIST, or CISA. ThreatGPT is unique because it does not just provide threat information, but rather it acts like a knowledgeable partner. Using few-shot learning, the AI learns from examples and generates relevant smart threat models. It can highlight what might go wrong, how attackers could take advantage, and what can be done to prevent harm. Whether securing a city's infrastructure or a local health service, this tool adapts to users' needs. In simple terms, ThreatGPT brings together AI and human judgment to make our public systems safer. It is designed not just to analyze threats, but to empower people to understand and act on them, faster, smarter, and with more confidence.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ThreatGPTï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é€šè¿‡ Threat Modeling å¢å¼ºå…¬å…±å®‰å…¨ç³»ç»Ÿå®‰å…¨æ€§çš„æ™ºèƒ½ä½“ AI æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¢å‘å·¥ç¨‹å¸ˆã€å®‰å…¨å®˜å‘˜åŠæ”¿ç­–åˆ¶å®šè€…ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡ç®€å•æè¿°ç³»ç»Ÿç»„ä»¶æ¥è¿›è¡Œå¨èƒåˆ†æï¼Œè€Œæ— éœ€æ·±åšçš„ç½‘ç»œå®‰å…¨ä¸“ä¸šçŸ¥è¯†ã€‚ThreatGPT é›†æˆäº† STRIDEã€MITRE ATT&CKã€CVE æŠ¥å‘Šã€NIST å’Œ CISA ç­‰ä¸»æµå®‰å…¨æ¡†æ¶ï¼Œå¹¶åˆ©ç”¨ Few-shot learning æŠ€æœ¯ä»ç¤ºä¾‹ä¸­å­¦ä¹ ä»¥ç”Ÿæˆç²¾ç¡®çš„æ™ºèƒ½å¨èƒæ¨¡å‹ã€‚ä½œä¸ºä¸€ç§çŸ¥è¯†å‹åˆä½œä¼™ä¼´ï¼Œè¯¥å·¥å…·èƒ½å¤Ÿé«˜äº®æ½œåœ¨çš„å¤±æ•ˆç¯èŠ‚ã€æ”»å‡»è€…åˆ©ç”¨æ–¹å¼ä»¥åŠé¢„é˜²æªæ–½ï¼Œä»è€Œé€‚åº”ä¸åŒåœºæ™¯ä¸‹çš„ç”¨æˆ·éœ€æ±‚ã€‚é€šè¿‡ç»“åˆ AI ä¸äººç±»åˆ¤æ–­ï¼ŒThreatGPT æ˜¾è‘—æå‡äº†å…¬å…±ç³»ç»Ÿå®‰å…¨æ€§åˆ†æçš„æ•ˆç‡å’Œä¿¡å¿ƒï¼Œä½¿å†³ç­–è€…èƒ½å¤Ÿæ›´å¿«é€Ÿã€æ›´æ™ºèƒ½åœ°å¯¹å¨èƒé‡‡å–è¡ŒåŠ¨ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05379v1",
      "published_date": "2025-09-04 20:26:54 UTC",
      "updated_date": "2025-09-04 20:26:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:46.844066+00:00"
    },
    {
      "arxiv_id": "2509.04650v2",
      "title": "Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety",
      "title_zh": "é¢å‘å…¬å…±å®‰å…¨çš„ç¾å®³æ¨æ–‡åˆ†ç±»ä¸­ Transformer æ¨¡å‹çš„å¯¹æ¯”åˆ†æ",
      "authors": [
        "Sharif Noor Zisad",
        "N. M. Istiak Chowdhury",
        "Ragib Hasan"
      ],
      "abstract": "Twitter and other social media platforms have become vital sources of real time information during disasters and public safety emergencies. Automatically classifying disaster related tweets can help emergency services respond faster and more effectively. Traditional Machine Learning (ML) models such as Logistic Regression, Naive Bayes, and Support Vector Machines have been widely used for this task, but they often fail to understand the context or deeper meaning of words, especially when the language is informal, metaphorical, or ambiguous. We posit that, in this context, transformer based models can perform better than traditional ML models. In this paper, we evaluate the effectiveness of transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for classifying disaster related tweets. These models are compared with traditional ML approaches to highlight the performance gap. Experimental results show that BERT achieved the highest accuracy (91%), significantly outperforming traditional models like Logistic Regression and Naive Bayes (both at 82%). The use of contextual embeddings and attention mechanisms allows transformer models to better understand subtle language in tweets, where traditional ML models fall short. This research demonstrates that transformer architectures are far more suitable for public safety applications, offering improved accuracy, deeper language understanding, and better generalization across real world social media text.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“åœ¨ç¾å®³åŠå…¬å…±å®‰å…¨çªå‘äº‹ä»¶ä¸­çš„å®æ—¶ä¿¡æ¯ä»·å€¼ï¼Œå¯¹æ¯”åˆ†æäº†å¤šç§ Transformer æ¨¡å‹åœ¨ç¾å®³ç›¸å…³æ¨æ–‡åˆ†ç±»ä¸­çš„æ•ˆèƒ½ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œä¼ ç»Ÿçš„ Logistic Regressionã€Naive Bayes å’Œ Support Vector Machines åœ¨å¤„ç†éæ­£å¼æˆ–æ­§ä¹‰æ€§è¯­è¨€æ—¶éš¾ä»¥ç†è§£æ·±å±‚è¯­å¢ƒï¼Œè€ŒåŸºäº Transformer çš„æ¶æ„åˆ™è¡¨ç°å‡ºæ›´å¼ºçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚é€šè¿‡è¯¦ç»†è¯„ä¼° BERTã€DistilBERTã€RoBERTa å’Œ DeBERTaï¼Œå®éªŒç»“æœæ˜¾ç¤º BERT è¾¾åˆ°äº†æœ€é«˜çš„å‡†ç¡®ç‡ï¼ˆ91%ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ¨¡å‹çš„ 82%ã€‚è¿™ä¸»è¦å½’åŠŸäº Transformer å¼•å…¥çš„ contextual embeddings å’Œ attention mechanismsï¼Œä½¿å…¶èƒ½å¤Ÿç²¾å‡†æ•æ‰ç¤¾äº¤åª’ä½“æ–‡æœ¬ä¸­çš„ç»†å¾®è¯­ä¹‰ã€‚è¯¥ç ”ç©¶è¯å®äº† Transformer æ¶æ„åœ¨å…¬å…±å®‰å…¨åº”ç”¨ä¸­çš„ä¼˜è¶Šæ€§ï¼Œå±•ç°äº†å…¶åœ¨æé«˜åˆ†ç±»ç²¾åº¦ã€æ·±å±‚è¯­è¨€ç†è§£ä»¥åŠè·¨ç°å®ç¤¾äº¤åª’ä½“æ–‡æœ¬æ³›åŒ–èƒ½åŠ›æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04650v2",
      "published_date": "2025-09-04 20:22:33 UTC",
      "updated_date": "2025-09-08 16:28:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:56.755085+00:00"
    },
    {
      "arxiv_id": "2509.04646v1",
      "title": "Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization",
      "title_zh": "è¿ˆå‘å¥åº·æ¨¡æ‹Ÿçš„ä¸ªæ€§åŒ–è§£é‡Šï¼šä¸€ç§ä»¥åˆ©ç›Šç›¸å…³è€…ä¸ºä¸­å¿ƒçš„æ‘˜è¦ç”Ÿæˆæ··åˆæ–¹æ³•æ¡†æ¶",
      "authors": [
        "Philippe J. Giabbanelli",
        "Ameeta Agrawal"
      ],
      "abstract": "Modeling & Simulation (M&S) approaches such as agent-based models hold significant potential to support decision-making activities in health, with recent examples including the adoption of vaccines, and a vast literature on healthy eating behaviors and physical activity behaviors. These models are potentially usable by different stakeholder groups, as they support policy-makers to estimate the consequences of potential interventions and they can guide individuals in making healthy choices in complex environments. However, this potential may not be fully realized because of the models' complexity, which makes them inaccessible to the stakeholders who could benefit the most. While Large Language Models (LLMs) can translate simulation outputs and the design of models into text, current approaches typically rely on one-size-fits-all summaries that fail to reflect the varied informational needs and stylistic preferences of clinicians, policymakers, patients, caregivers, and health advocates. This limitation stems from a fundamental gap: we lack a systematic understanding of what these stakeholders need from explanations and how to tailor them accordingly. To address this gap, we present a step-by-step framework to identify stakeholder needs and guide LLMs in generating tailored explanations of health simulations. Our procedure uses a mixed-methods design by first eliciting the explanation needs and stylistic preferences of diverse health stakeholders, then optimizing the ability of LLMs to generate tailored outputs (e.g., via controllable attribute tuning), and then evaluating through a comprehensive range of metrics to further improve the tailored generation of summaries.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ··åˆæ–¹æ³•æ¡†æ¶(Mixed-Methods Framework)ï¼Œæ—¨åœ¨è§£å†³å¥åº·é¢†åŸŸçš„å»ºæ¨¡ä¸ä»¿çœŸ(Modeling & Simulation, M&S)ç³»ç»Ÿå› å¤æ‚æ€§é«˜è€Œéš¾ä»¥è¢«åˆ©ç›Šç›¸å…³è€…ç†è§£çš„é—®é¢˜ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)èƒ½å¤Ÿå°†æ¨¡æ‹Ÿè¾“å‡ºè½¬åŒ–ä¸ºæ–‡æœ¬ï¼Œä½†ç°æœ‰çš„â€œä¸€åˆ€åˆ‡â€æ‘˜è¦æ¨¡å¼æ— æ³•æ»¡è¶³ä¸´åºŠåŒ»ç”Ÿã€æ”¿ç­–åˆ¶å®šè€…åŠæ‚£è€…åœ¨ä¿¡æ¯éœ€æ±‚å’Œè¡¨è¾¾é£æ ¼ä¸Šçš„å·®å¼‚ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ··åˆç ”ç©¶è®¾è®¡é¦–å…ˆè¯†åˆ«ä¸åŒç¾¤ä½“çš„ä¸ªæ€§åŒ–è§£é‡Šéœ€æ±‚ï¼Œéšååˆ©ç”¨å¯æ§å±æ€§å¾®è°ƒ(Controllable Attribute Tuning)ç­‰æŠ€æœ¯ä¼˜åŒ– LLMs ä»¥ç”Ÿæˆå®šåˆ¶åŒ–è¾“å‡ºã€‚æœ€åï¼Œç ”ç©¶é€šè¿‡ä¸€å¥—ç»¼åˆè¯„ä¼°æŒ‡æ ‡å¯¹ç”Ÿæˆçš„æ‘˜è¦è¿›è¡ŒæŒç»­æ”¹è¿›ï¼Œç¡®ä¿å¥åº·æ¨¡æ‹Ÿç»“æœèƒ½æ›´æœ‰æ•ˆåœ°æ”¯æŒå„ç±»åˆ©ç›Šç›¸å…³è€…çš„å†³ç­–ï¼Œæ˜¾è‘—æå‡äº†å¤æ‚æ¨¡å‹åœ¨å¥åº·å†³ç­–ä¸­çš„å¯è®¿é—®æ€§ä¸å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the AAAI 2025 Fall Symposium Series. November 6-8, 2025, Arlington, VA, USA",
      "pdf_url": "https://arxiv.org/pdf/2509.04646v1",
      "published_date": "2025-09-04 20:07:31 UTC",
      "updated_date": "2025-09-04 20:07:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:52.503347+00:00"
    },
    {
      "arxiv_id": "2509.04642v1",
      "title": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents",
      "title_zh": "Maestroï¼šé¢å‘å¯é  AI æ™ºèƒ½ä½“çš„å›¾ä¸é…ç½®è”åˆä¼˜åŒ–",
      "authors": [
        "Wenxiao Wang",
        "Priyatham Kattakinda",
        "Soheil Feizi"
      ],
      "abstract": "Building reliable LLM agents requires decisions at two levels: the graph (which modules exist and how information flows) and the configuration of each node (models, prompts, tools, control knobs). Most existing optimizers tune configurations while holding the graph fixed, leaving structural failure modes unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for LLM agents that jointly searches over graphs and configurations to maximize agent quality, subject to explicit rollout/token budgets. Beyond numeric metrics, Maestro leverages reflective textual feedback from traces to prioritize edits, improving sample efficiency and targeting specific failure modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%, 4.9%, and 4.86%, respectively; even when restricted to prompt-only optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these results with far fewer rollouts than GEPA. We further show large gains on two applications (interviewer & RAG agents), highlighting that joint graph & configuration search addresses structural failure modes that prompt tuning alone cannot fix.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Maestroï¼Œä¸€ä¸ªç”¨äºæ„å»ºå¯é LLM agentsçš„æ¡†æ¶æ— å…³(framework-agnostic)æ•´ä½“ä¼˜åŒ–å™¨ã€‚é’ˆå¯¹ç°æœ‰ä¼˜åŒ–å™¨å¾€å¾€å›ºå®šå›¾ç»“æ„è€Œåªè°ƒä¼˜èŠ‚ç‚¹é…ç½®çš„å±€é™æ€§ï¼ŒMaestroå®ç°äº†å¯¹å›¾ç»“æ„(graph)å’Œé…ç½®(configuration)çš„è”åˆæœç´¢ï¼Œæœ‰æ•ˆè§£å†³äº†ç»“æ„æ€§å¤±æ•ˆé—®é¢˜ã€‚è¯¥æ¡†æ¶ä¸ä»…åˆ©ç”¨æ•°å€¼æŒ‡æ ‡ï¼Œè¿˜ç»“åˆäº†æ¥è‡ªæ‰§è¡Œè¿½è¸ª(traces)çš„åå°„æ€§æ–‡æœ¬åé¦ˆ(reflective textual feedback)æ¥ä¼˜åŒ–æ ·æœ¬æ•ˆç‡ï¼Œå¹¶å¯åœ¨æ˜¾å¼çš„é¢„ç®—çº¦æŸä¸‹è¿è¡Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨IFBenchå’ŒHotpotQAåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMaestroçš„æ€§èƒ½æ˜¾è‘—è¶…è¿‡äº†MIPROv2ã€GEPAå’ŒGEPA+Mergeç­‰ä¸»æµä¼˜åŒ–å™¨ã€‚é€šè¿‡åœ¨è®¿è°ˆè€…(interviewer)å’ŒRAGæ™ºèƒ½ä½“åº”ç”¨ä¸Šçš„è¿›ä¸€æ­¥éªŒè¯ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†è”åˆå›¾ä¸é…ç½®æœç´¢åœ¨è§£å†³å¤æ‚LLMç³»ç»Ÿç¼ºé™·æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Technical Report by RELAI.ai",
      "pdf_url": "https://arxiv.org/pdf/2509.04642v1",
      "published_date": "2025-09-04 20:00:37 UTC",
      "updated_date": "2025-09-04 20:00:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:29:59.493093+00:00"
    },
    {
      "arxiv_id": "2509.04633v3",
      "title": "The Physical Basis of Prediction: World Model Formation in Neural Organoids via an LLM-Generated Curriculum",
      "title_zh": "é¢„æµ‹çš„ç‰©ç†åŸºç¡€ï¼šé€šè¿‡ LLM ç”Ÿæˆçš„è¯¾ç¨‹ä½“ç³»åœ¨ç¥ç»ç±»å™¨å®˜ä¸­æ„å»ºä¸–ç•Œæ¨¡å‹",
      "authors": [
        "Brennen Hill"
      ],
      "abstract": "The capacity of an embodied agent to understand, predict, and interact with its environment is fundamentally contingent on an internal world model. This paper introduces a novel framework for investigating the formation and adaptation of such world models within a biological substrate: human neural organoids. We present a curriculum of three scalable, closed-loop virtual environments designed to train these biological agents and probe the underlying synaptic mechanisms of learning, such as long-term potentiation (LTP) and long-term depression (LTD). We detail the design of three distinct task environments that demand progressively more sophisticated world models for successful decision-making: (1) a conditional avoidance task for learning static state-action contingencies, (2) a one-dimensional predator-prey scenario for goal-directed interaction, and (3) a replication of the classic Pong game for modeling dynamic, continuous-time systems. For each environment, we formalize the state and action spaces, the sensory encoding and motor decoding mechanisms, and the feedback protocols based on predictable (reward) and unpredictable (punishment) stimulation, which serve to drive model refinement. In a significant methodological advance, we propose a meta-learning approach where a Large Language Model automates the generative design and optimization of experimental protocols, thereby scaling the process of environment and curriculum design. Finally, we outline a multi-modal evaluation strategy that moves beyond task performance to directly measure the physical correlates of the learned world model by quantifying synaptic plasticity at electrophysiological, cellular, and molecular levels. This work bridges the gap between model-based reinforcement learning and computational neuroscience, offering a unique platform for studying embodiment, decision-making, and the physical basis of intelligence.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨äººç±»ç¥ç»ç±»å™¨å®˜ (neural organoids) è¿™ä¸€ç”Ÿç‰©åŸºè´¨ä¸­ä¸–ç•Œæ¨¡å‹ (world model) çš„å½¢æˆä¸é€‚åº”ï¼Œæ—¨åœ¨æ­ç¤ºé¢„æµ‹è¡Œä¸ºçš„ç‰©ç†åŸºç¡€ã€‚ç ”ç©¶äººå‘˜è®¾è®¡äº†ä¸€ä¸ªç”±ä¸‰é¡¹é—­ç¯è™šæ‹Ÿç¯å¢ƒç»„æˆçš„é€’è¿›å¼è¯¾ç¨‹ï¼ŒåŒ…æ‹¬æ¡ä»¶è§„é¿ã€ä¸€ç»´æ•é£Ÿè€…-çŒç‰©åœºæ™¯åŠç»å…¸ Pong æ¸¸æˆï¼Œç”¨ä»¥è®­ç»ƒè¿™äº›ç”Ÿç‰©æ™ºèƒ½ä½“å¹¶æ¢ç©¶é•¿æ—¶ç¨‹å¢å¼º (LTP) ä¸é•¿æ—¶ç¨‹æŠ‘åˆ¶ (LTD) ç­‰çªè§¦å­¦ä¹ æœºåˆ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç‰¹å®šçš„æ„Ÿå®˜ç¼–ç ä¸ç”µæœºè§£ç æœºåˆ¶ï¼Œåˆ©ç”¨å¯é¢„æµ‹çš„å¥–åŠ±ä¸ä¸å¯é¢„æµ‹çš„æƒ©ç½šåé¦ˆé©±åŠ¨æ¨¡å‹çš„æŒç»­ç²¾ç»†åŒ–ã€‚åœ¨æ–¹æ³•è®ºåˆ›æ–°ä¸Šï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§å…ƒå­¦ä¹  (meta-learning) æ–¹æ³•ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) è‡ªåŠ¨åŒ–ç”Ÿæˆå’Œä¼˜åŒ–å®éªŒåè®®ï¼Œä»è€Œå®ç°ç¯å¢ƒä¸è¯¾ç¨‹è®¾è®¡çš„è§„æ¨¡åŒ–ã€‚æœ€åï¼Œé€šè¿‡æ•´åˆç”µç”Ÿç†ã€ç»†èƒå’Œåˆ†å­æ°´å¹³çš„çªè§¦å¯å¡‘æ€§æµ‹é‡ï¼Œè¯¥ç ”ç©¶ä¸ä»…è¡¡é‡ä»»åŠ¡è¡¨ç°ï¼Œæ›´ç›´æ¥é‡åŒ–äº†ä¸–ç•Œæ¨¡å‹çš„ç‰©ç†ç›¸å…³æ€§ã€‚è¿™é¡¹å·¥ä½œæœ‰æ•ˆè¡”æ¥äº†æ¨¡å‹åŒ–å¼ºåŒ–å­¦ä¹  (model-based reinforcement learning) ä¸è®¡ç®—ç¥ç»ç§‘å­¦ï¼Œä¸ºç ”ç©¶å…·èº«æ™ºèƒ½ã€å†³ç­–åˆ¶å®šåŠæ™ºèƒ½çš„ç‰©ç†æœ¬è´¨æä¾›äº†ç‹¬ç‰¹å¹³å°ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "Published in the proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Scaling Environments for Agents (SEA). Additionally accepted for presentation in NeurIPS 2025 Workshop: Embodied World Models for Decision Making",
      "pdf_url": "https://arxiv.org/pdf/2509.04633v3",
      "published_date": "2025-09-04 19:51:00 UTC",
      "updated_date": "2025-11-04 06:32:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:02.501616+00:00"
    },
    {
      "arxiv_id": "2509.04632v1",
      "title": "Schema Inference for Tabular Data Repositories Using Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è¡¨æ ¼æ•°æ®ä»“åº“æ¨¡å¼æ¨æ–­",
      "authors": [
        "Zhenyu Wu",
        "Jiaoyan Chen",
        "Norman W. Paton"
      ],
      "abstract": "Minimally curated tabular data often contain representational inconsistencies across heterogeneous sources, and are accompanied by sparse metadata. Working with such data is intimidating. While prior work has advanced dataset discovery and exploration, schema inference remains difficult when metadata are limited. We present SI-LLM (Schema Inference using Large Language Models), which infers a concise conceptual schema for tabular data using only column headers and cell values. The inferred schema comprises hierarchical entity types, attributes, and inter-type relationships. In extensive evaluation on two datasets from web tables and open data, SI-LLM achieves promising end-to-end results, as well as better or comparable results to state-of-the-art methods at each step. All source code, full prompts, and datasets of SI-LLM are available at https://github.com/PierreWoL/SILLM.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¼ºä¹ç»´æŠ¤çš„è¡¨æ ¼æ•°æ®ï¼ˆMinimally curated tabular dataï¼‰ä¸­å¸¸è§çš„è¡¨ç¤ºä¸ä¸€è‡´å’Œå…ƒæ•°æ®ï¼ˆmetadataï¼‰ç¨€ç¼ºé—®é¢˜ï¼Œæå‡ºäº† SI-LLMï¼ˆSchema Inference using Large Language Modelsï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨æå‡æ•°æ®å‘ç°ä¸æ¢ç´¢çš„æ•ˆç‡ã€‚è¯¥æ¡†æ¶ä»…åˆ©ç”¨åˆ—æ ‡é¢˜ï¼ˆcolumn headersï¼‰å’Œå•å…ƒæ ¼å€¼ï¼ˆcell valuesï¼‰å³å¯è‡ªåŠ¨æ¨æ–­å‡ºè¡¨æ ¼æ•°æ®çš„ç®€æ´æ¦‚å¿µæ¨¡å¼ï¼ˆconceptual schemaï¼‰ï¼Œæ¶µç›–äº†åˆ†å±‚å®ä½“ç±»å‹ï¼ˆhierarchical entity typesï¼‰ã€å±æ€§ï¼ˆattributesï¼‰åŠç±»å‹é—´çš„å…³ç³»ï¼ˆinter-type relationshipsï¼‰ã€‚åœ¨é’ˆå¯¹ Web è¡¨æ ¼å’Œå¼€æ”¾æ•°æ®ï¼ˆopen dataï¼‰ä¸¤ä¸ªæ•°æ®é›†çš„å¹¿æ³›è¯„ä¼°ä¸­ï¼ŒSI-LLM åœ¨ç«¯åˆ°ç«¯æ¨ç†ä»¥åŠå„å­ä»»åŠ¡ä¸­å‡å–å¾—äº†ä¼˜äºæˆ–ç­‰åŒäºç°æœ‰æœ€å…ˆè¿›ï¼ˆstate-of-the-artï¼‰æ–¹æ³•çš„ç»“æœã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…ƒæ•°æ®æå…¶æœ‰é™çš„æƒ…å†µä¸‹ä¾ç„¶èƒ½å®ç°ç²¾å‡†çš„æ¨¡å¼æ¨æ–­ã€‚ç›®å‰ï¼Œç ”ç©¶è€…å·²å°†æºä»£ç ã€å®Œæ•´æç¤ºè¯åŠæ•°æ®é›†å…¬å¼€ï¼Œä¸ºåç»­ç›¸å…³é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04632v1",
      "published_date": "2025-09-04 19:50:16 UTC",
      "updated_date": "2025-09-04 19:50:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:08.967712+00:00"
    },
    {
      "arxiv_id": "2509.04628v1",
      "title": "Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control",
      "title_zh": "åŸºäº Transformer åŠ¨ä½œåˆ†å—çš„èˆªå¤©å™¨å›¾åƒåˆ¶å¯¼ä¸æ§åˆ¶",
      "authors": [
        "Alejandro Posadas-Nava",
        "Andrea Scorsoglio",
        "Luca Ghilardi",
        "Roberto Furfaro",
        "Richard Linares"
      ],
      "abstract": "We present an imitation learning approach for spacecraft guidance, navigation, and control(GNC) that achieves high performance from limited data. Using only 100 expert demonstrations, equivalent to 6,300 environment interactions, our method, which implements Action Chunking with Transformers (ACT), learns a control policy that maps visual and state observations to thrust and torque commands. ACT generates smoother, more consistent trajectories than a meta-reinforcement learning (meta-RL) baseline trained with 40 million interactions. We evaluate ACT on a rendezvous task: in-orbit docking with the International Space Station (ISS). We show that our approach achieves greater accuracy, smoother control, and greater sample efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ¨¡ä»¿å­¦ä¹ (Imitation Learning)çš„æ–¹æ³•ï¼Œåˆ©ç”¨Action Chunking with Transformers (ACT) æ¡†æ¶è§£å†³èˆªå¤©å™¨åˆ¶å¯¼ã€å¯¼èˆªä¸æ§åˆ¶(GNC) ä»»åŠ¡ã€‚é€šè¿‡å°†è§†è§‰ä¸çŠ¶æ€è§‚æµ‹æ˜ å°„ä¸ºæ¨åŠ›å’Œè½¬çŸ©æŒ‡ä»¤ï¼Œè¯¥æ–¹æ³•åœ¨ä»…ä½¿ç”¨100æ¬¡ä¸“å®¶æ¼”ç¤ºçš„æƒ…å†µä¸‹å­¦ä¹ åˆ°äº†é«˜æ•ˆçš„æ§åˆ¶ç­–ç•¥ã€‚å®éªŒè¯æ˜ï¼ŒACT ç”Ÿæˆçš„è½¨è¿¹æ¯”ç»è¿‡4,000ä¸‡æ¬¡äº¤äº’è®­ç»ƒçš„å…ƒå¼ºåŒ–å­¦ä¹ (meta-RL) åŸºçº¿æ¨¡å‹æ›´åŠ å¹³æ»‘ä¸”ä¸€è‡´ã€‚åœ¨å›½é™…ç©ºé—´ç«™(ISS) è½¨é“å¯¹æ¥ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºäº†æ›´é«˜çš„ä»»åŠ¡ç²¾åº¦ã€æ›´å¹³æ»‘çš„æ§åˆ¶æ•ˆæœä»¥åŠå“è¶Šçš„æ ·æœ¬æ•ˆç‡ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº† ACT åœ¨å¤„ç†åŸºäºå›¾åƒçš„å¤æ‚èˆªå¤©å™¨æ§åˆ¶ä»»åŠ¡æ—¶ï¼Œç›¸è¾ƒäºä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ¡ˆå…·æœ‰æ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages, 6 figures, 2025 AAS/AIAA Astrodynamics Specialist Conference",
      "pdf_url": "https://arxiv.org/pdf/2509.04628v1",
      "published_date": "2025-09-04 19:29:02 UTC",
      "updated_date": "2025-09-04 19:29:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:06.857867+00:00"
    },
    {
      "arxiv_id": "2509.04622v5",
      "title": "Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families",
      "title_zh": "è¡¡é‡è¡¡é‡æ ‡å‡†ï¼šè·¨æ¨¡å‹ç³»åˆ—è¡¨å¾ç›¸ä¼¼æ€§åº¦é‡çš„åˆ¤åˆ«èƒ½åŠ›",
      "authors": [
        "Jialin Wu",
        "Shreya Saha",
        "Yiqing Bo",
        "Meenakshi Khosla"
      ],
      "abstract": "Representational similarity metrics are fundamental tools in neuroscience and AI, yet we lack systematic comparisons of their discriminative power across model families. We introduce a quantitative framework to evaluate representational similarity measures based on their ability to separate model families-across architectures (CNNs, Vision Transformers, Swin Transformers, ConvNeXt) and training regimes (supervised vs. self-supervised). Using three complementary separability measures-dprime from signal detection theory, silhouette coefficients and ROC-AUC, we systematically assess the discriminative capacity of commonly used metrics including RSA, linear predictivity, Procrustes, and soft matching. We show that separability systematically increases as metrics impose more stringent alignment constraints. Among mapping-based approaches, soft-matching achieves the highest separability, followed by Procrustes alignment and linear predictivity. Non-fitting methods such as RSA also yield strong separability across families. These results provide the first systematic comparison of similarity metrics through a separability lens, clarifying their relative sensitivity and guiding metric choice for large-scale model and brain comparisons.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå®šé‡è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¡¡é‡è¡¨ç¤ºç›¸ä¼¼æ€§åº¦é‡(Representational similarity metrics)åœ¨åŒºåˆ†ä¸åŒæ¨¡å‹å®¶æ—ï¼ˆå¦‚CNNsã€Vision Transformersã€Swin Transformerså’ŒConvNeXtï¼‰ä»¥åŠè®­ç»ƒæ¨¡å¼ï¼ˆç›‘ç£ä¸è‡ªç›‘ç£ï¼‰æ—¶çš„é‰´åˆ«èƒ½åŠ›ã€‚ç ”ç©¶è€…åˆ©ç”¨ä¿¡å·æ£€æµ‹ç†è®ºä¸­çš„d-primeã€è½®å»“ç³»æ•°(silhouette coefficients)å’ŒROC-AUCä¸‰ç§äº’è¡¥æ ‡å‡†ï¼Œç³»ç»Ÿè¯„ä¼°äº†RSAã€çº¿æ€§é¢„æµ‹åŠ›(linear predictivity)ã€Procrusteså’Œè½¯åŒ¹é…(soft matching)ç­‰å¸¸ç”¨æŒ‡æ ‡ã€‚å®éªŒå‘ç°ï¼ŒæŒ‡æ ‡çš„é‰´åˆ«èƒ½åŠ›éšç€å¯¹é½çº¦æŸçš„å¢å¼ºè€Œç³»ç»Ÿæ€§æå‡ï¼Œå…¶ä¸­è½¯åŒ¹é…åœ¨åŸºäºæ˜ å°„çš„æ–¹æ³•ä¸­è¡¨ç°å‡ºæœ€é«˜çš„å¯åˆ†ç¦»æ€§ã€‚éæ‹Ÿåˆæ–¹æ³•å¦‚RSAä¹Ÿè¡¨ç°å‡ºæå¼ºçš„è·¨å®¶æ—åŒºåˆ†åº¦ï¼Œä¸ºç¥ç»ç§‘å­¦å’ŒAIé¢†åŸŸçš„æ¨¡å‹æ¯”è¾ƒæä¾›äº†ä¾æ®ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡å¯åˆ†ç¦»æ€§è§†è§’å¡«è¡¥äº†ç›¸ä¼¼æ€§åº¦é‡ç¼ºä¹ç³»ç»Ÿæ¯”è¾ƒçš„ç©ºç™½ï¼Œä¸ºç ”ç©¶è€…åœ¨è¿›è¡Œå¤§è§„æ¨¡æ¨¡å‹ä¸å¤§è„‘è¡¨å¾å¯¹æ¯”æ—¶æä¾›äº†æ˜ç¡®çš„æŒ‡æ ‡é€‰æ‹©æŒ‡å—ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "update camera ready",
      "pdf_url": "https://arxiv.org/pdf/2509.04622v5",
      "published_date": "2025-09-04 19:11:10 UTC",
      "updated_date": "2025-12-09 08:57:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:10.156883+00:00"
    },
    {
      "arxiv_id": "2509.04606v1",
      "title": "Sample-efficient Integration of New Modalities into Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸­æ–°æ¨¡æ€çš„æ ·æœ¬é«˜æ•ˆé›†æˆ",
      "authors": [
        "Osman Batur Ä°nce",
        "AndrÃ© F. T. Martins",
        "Oisin Mac Aodha",
        "Edoardo M. Ponti"
      ],
      "abstract": "Multimodal foundation models can process several modalities. However, since the space of possible modalities is large and evolving over time, training a model from scratch to encompass all modalities is unfeasible. Moreover, integrating a modality into a pre-existing foundation model currently requires a significant amount of paired data, which is often not available for low-resource modalities. In this paper, we introduce a method for sample-efficient modality integration (SEMI) into Large Language Models (LLMs). To this end, we devise a hypernetwork that can adapt a shared projector -- placed between modality-specific encoders and an LLM -- to any modality. The hypernetwork, trained on high-resource modalities (i.e., text, speech, audio, video), is conditioned on a few samples from any arbitrary modality at inference time to generate a suitable adapter. To increase the diversity of training modalities, we artificially multiply the number of encoders through isometric transformations. We find that SEMI achieves a significant boost in sample efficiency during few-shot integration of new modalities (i.e., satellite images, astronomical images, inertial measurements, and molecules) with encoders of arbitrary embedding dimensionality. For instance, to reach the same accuracy as 32-shot SEMI, training the projector from scratch needs 64$\\times$ more data. As a result, SEMI holds promise to extend the modality coverage of foundation models.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹åœ¨é›†æˆæ–°æ¨¡æ€æ—¶é¢ä¸´çš„é…å¯¹æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œæå‡ºäº†SEMIï¼ˆSample-efficient Modality Integrationï¼‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥ä¸€ä¸ªè¶…ç½‘ç»œï¼ˆhypernetworkï¼‰æ¥çµæ´»è°ƒæ•´æ¨¡æ€ç¼–ç å™¨ï¼ˆmodality-specific encodersï¼‰ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¹‹é—´çš„å…±äº«æŠ•å½±å™¨ï¼ˆshared projectorï¼‰ã€‚è¶…ç½‘ç»œåœ¨æ–‡æœ¬ã€è¯­éŸ³ã€è§†é¢‘ç­‰é«˜èµ„æºæ¨¡æ€ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨æ¨ç†æ—¶ä»…éœ€å°‘é‡æ–°æ¨¡æ€æ ·æœ¬å³å¯ç”Ÿæˆç›¸åº”çš„é€‚é…å™¨ï¼ˆadapterï¼‰ã€‚ä¸ºäº†å¢å¼ºè®­ç»ƒå¤šæ ·æ€§ï¼Œç ”ç©¶è€…è¿˜é€šè¿‡ç­‰è·å˜æ¢ï¼ˆisometric transformationsï¼‰æ‰©å……äº†ç¼–ç å™¨æ•°é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨é›†æˆå«æ˜Ÿå›¾åƒã€å¤©æ–‡æ•°æ®å’Œåˆ†å­ç»“æ„ç­‰æ–°æ¨¡æ€æ—¶ï¼ŒSEMIæ˜¾è‘—æå‡äº†æ ·æœ¬æ•ˆç‡ï¼ˆsample efficiencyï¼‰ã€‚ä¾‹å¦‚ï¼ŒSEMIåœ¨32-shotè®¾ç½®ä¸‹è¾¾åˆ°çš„ç²¾åº¦ï¼Œè‹¥é‡‡ç”¨ä»å¤´è®­ç»ƒæŠ•å½±å™¨çš„æ–¹æ³•åˆ™éœ€è¦å¤šå‡º64å€çš„æ•°æ®æ”¯æŒã€‚è¯¥æˆæœä¸ºæ‰©å±•åŸºç¡€æ¨¡å‹ï¼ˆfoundation modelsï¼‰çš„æ¨¡æ€è¦†ç›–èŒƒå›´æä¾›äº†ä¸€ç§é«˜æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Pre-print",
      "pdf_url": "https://arxiv.org/pdf/2509.04606v1",
      "published_date": "2025-09-04 18:41:59 UTC",
      "updated_date": "2025-09-04 18:41:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:28.291254+00:00"
    },
    {
      "arxiv_id": "2509.04601v1",
      "title": "Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction",
      "title_zh": "ç”¨äºè¯ä»£åŠ¨åŠ›å­¦ä¸æ¯’æ€§é¢„æµ‹çš„é‡å­å¢å¼ºåŠå¯å­¦ä¹ æƒé‡å¤šä»»åŠ¡å­¦ä¹ ",
      "authors": [
        "Han Zhang",
        "Fengji Ma",
        "Jiamin Su",
        "Xinyue Yang",
        "Lei Wang",
        "Wen-Cai Ye",
        "Li Liu"
      ],
      "abstract": "Prediction for ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity) plays a crucial role in drug discovery and development, accelerating the screening and optimization of new drugs. Existing methods primarily rely on single-task learning (STL), which often fails to fully exploit the complementarities between tasks. Besides, it requires more computational resources while training and inference of each task independently. To address these issues, we propose a new unified Quantum-enhanced and task-Weighted Multi-Task Learning (QW-MTL) framework, specifically designed for ADMET classification tasks. Built upon the Chemprop-RDKit backbone, QW-MTL adopts quantum chemical descriptors to enrich molecular representations with additional information about the electronic structure and interactions. Meanwhile, it introduces a novel exponential task weighting scheme that combines dataset-scale priors with learnable parameters to achieve dynamic loss balancing across tasks. To the best of our knowledge, this is the first work to systematically conduct joint multi-task training across all 13 Therapeutics Data Commons (TDC) classification benchmarks, using leaderboard-style data splits to ensure a standardized and realistic evaluation setting. Extensive experimental results show that QW-MTL significantly outperforms single-task baselines on 12 out of 13 tasks, achieving high predictive performance with minimal model complexity and fast inference, demonstrating the effectiveness and efficiency of multi-task molecular learning enhanced by quantum-informed features and adaptive task weighting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸º QW-MTL (Quantum-enhanced and task-Weighted Multi-Task Learning) çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨ä¼˜åŒ–è¯ç‰©ç ”å‘ä¸­å…³é”®çš„ ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity) é¢„æµ‹ã€‚è¯¥æ¡†æ¶åŸºäº Chemprop-RDKit æ¶æ„ï¼Œé€šè¿‡å¼•å…¥ quantum chemical descriptors æ¥ä¸°å¯Œåˆ†å­è¡¨ç¤ºï¼Œä½¿å…¶åŒ…å«æ›´å¤šå…³äºç”µå­ç»“æ„å’Œç›¸äº’ä½œç”¨çš„ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³ä¼ ç»Ÿå•ä»»åŠ¡å­¦ä¹ æ— æ³•åˆ©ç”¨ä»»åŠ¡é—´äº’è¡¥æ€§åŠèµ„æºæ¶ˆè€—å¤§çš„é—®é¢˜ï¼ŒQW-MTL é‡‡ç”¨äº†ä¸€ç§ç»“åˆæ•°æ®é›†è§„æ¨¡å…ˆéªŒä¸å¯å­¦ä¹ å‚æ•°çš„æ–°å‹æŒ‡æ•°ä»»åŠ¡åŠ æƒæ–¹æ¡ˆï¼Œå®ç°äº†è·¨ä»»åŠ¡çš„åŠ¨æ€æŸå¤±å¹³è¡¡ã€‚è¯¥å·¥ä½œé¦–æ¬¡åœ¨å…¨éƒ¨ 13 é¡¹ Therapeutics Data Commons (TDC) åˆ†ç±»åŸºå‡†ä¸Šè¿›è¡Œäº†ç³»ç»Ÿæ€§çš„å¤šä»»åŠ¡è”åˆè®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒQW-MTL åœ¨ 12 é¡¹ä»»åŠ¡ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºå•ä»»åŠ¡åŸºçº¿æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨æå‡é¢„æµ‹å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œä¿æŒäº†æä½çš„æ¨¡å‹å¤æ‚åº¦å’Œæå¿«çš„æ¨ç†é€Ÿåº¦ï¼ŒéªŒè¯äº†é‡å­ä¿¡æ¯å¢å¼ºç‰¹å¾ä¸è‡ªé€‚åº”ä»»åŠ¡åŠ æƒåœ¨åˆ†å­å¤šä»»åŠ¡å­¦ä¹ ä¸­çš„å“è¶Šæ•ˆèƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04601v1",
      "published_date": "2025-09-04 18:33:40 UTC",
      "updated_date": "2025-09-04 18:33:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:55.895276+00:00"
    },
    {
      "arxiv_id": "2509.04588v2",
      "title": "Beyond Output Faithfulness: Learning Attributions that Preserve Computational Pathways",
      "title_zh": "è¶…è¶Šè¾“å‡ºå¿ å®åº¦ï¼šå­¦ä¹ ä¿ç•™è®¡ç®—è·¯å¾„çš„å½’å› ",
      "authors": [
        "Siyu Zhang",
        "Kenneth Mcmillan"
      ],
      "abstract": "Faithfulness metrics such as insertion and deletion evaluate how feature removal affects model outputs but overlook whether explanations preserve the computational pathway the network actually uses. We show that external metrics can be maximized through alternative pathways -- perturbations that reroute computation via different feature detectors while preserving output behavior. To address this, we propose activation preservation as a tractable proxy for preserving computational pathways\n  We introduce Faithfulness-guided Ensemble Interpretation (FEI), which jointly optimizes external faithfulness (via ensemble quantile optimization of insertion/deletion curves) and internal faithfulness (via selective gradient clipping). Across VGG and ResNet on ImageNet and CUB-200-2011, FEI achieves state-of-the-art insertion/deletion scores while maintaining significantly lower activation deviation, showing that both external and internal faithfulness are essential for reliable explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡º insertion å’Œ deletion ç­‰ Faithfulness metrics ä»…è¯„ä¼°ç‰¹å¾ç§»é™¤å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œå´å¿½è§†äº†å½’å› è§£é‡Šæ˜¯å¦ä¿ç•™äº†ç¥ç»ç½‘ç»œå®é™…è¿è¡Œçš„ computational pathwayã€‚ä¸ºäº†è§£å†³æ¨¡å‹å¯èƒ½é€šè¿‡ alternative pathways ç»´æŒè¾“å‡ºè¡Œä¸ºä»è€Œè¯¯å¯¼å¤–éƒ¨æŒ‡æ ‡çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº† activation preservation ä½œä¸ºè¡¡é‡è®¡ç®—è·¯å¾„ä¸€è‡´æ€§çš„æœ‰æ•ˆä»£ç†æŒ‡æ ‡ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº† Faithfulness-guided Ensemble Interpretation (FEI) æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†é’ˆå¯¹å¤–éƒ¨å¿ å®åº¦çš„é›†æˆåˆ†ä½æ•°ä¼˜åŒ– (ensemble quantile optimization) ä¸é’ˆå¯¹å†…éƒ¨å¿ å®åº¦çš„é€‰æ‹©æ€§æ¢¯åº¦è£å‰ª (selective gradient clipping)ã€‚åœ¨åŸºäº ImageNet å’Œ CUB-200-2011 æ•°æ®é›†çš„ VGG ä¸ ResNet å®éªŒä¸­ï¼ŒFEI ä¸ä»…å®ç°äº† state-of-the-art çš„ insertion/deletion è¯„åˆ†ï¼Œè¿˜æ˜¾è‘—é™ä½äº† activation deviationã€‚å®éªŒç»“æœè¯æ˜ï¼ŒåŒæ—¶å…¼é¡¾å¤–éƒ¨ä¸å†…éƒ¨å¿ å®åº¦å¯¹äºæ„å»ºå¯é ä¸”ç¬¦åˆæ¨¡å‹å®é™…è®¡ç®—é€»è¾‘çš„å½’å› è§£é‡Šè‡³å…³é‡è¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04588v2",
      "published_date": "2025-09-04 18:09:17 UTC",
      "updated_date": "2025-12-03 21:56:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:34.492847+00:00"
    },
    {
      "arxiv_id": "2509.04449v3",
      "title": "ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset",
      "title_zh": "ChronoGraphï¼šä¸€ç§åŸºäºå›¾çš„çœŸå®ä¸–ç•Œå¤šå˜é‡æ—¶é—´åºåˆ—æ•°æ®é›†",
      "authors": [
        "Adrian Catalin Lutu",
        "Ioana Pintilie",
        "Elena Burceanu",
        "Andrei Manolache"
      ],
      "abstract": "We present ChronoGraph, a graph-structured multivariate time series forecasting dataset built from real-world production microservices. Each node is a service that emits a multivariate stream of system-level performance metrics, capturing CPU, memory, and network usage patterns, while directed edges encode dependencies between services. The primary task is forecasting future values of these signals at the service level. In addition, ChronoGraph provides expert-annotated incident windows as anomaly labels, enabling evaluation of anomaly detection methods and assessment of forecast robustness during operational disruptions. Compared to existing benchmarks from industrial control systems or traffic and air-quality domains, ChronoGraph uniquely combines (i) multivariate time series, (ii) an explicit, machine-readable dependency graph, and (iii) anomaly labels aligned with real incidents. We report baseline results spanning forecasting models, pretrained time-series foundation models, and standard anomaly detectors. ChronoGraph offers a realistic benchmark for studying structure-aware forecasting and incident-aware evaluation in microservice systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†ChronoGraphï¼Œä¸€ä¸ªæºè‡ªçœŸå®ç”Ÿäº§ç¯å¢ƒå¾®æœåŠ¡(microservices)çš„å›¾ç»“æ„å¤šå˜é‡æ—¶é—´åºåˆ—(multivariate time series)é¢„æµ‹æ•°æ®é›†ã€‚æ•°æ®é›†ä¸­æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªæœåŠ¡ï¼Œå…¶è§‚æµ‹å€¼æ¶µç›–äº†CPUã€å†…å­˜å’Œç½‘ç»œä½¿ç”¨æ¨¡å¼çš„å¤šå˜é‡æŒ‡æ ‡æµï¼Œå¹¶åˆ©ç”¨æœ‰å‘è¾¹ç¼–ç æœåŠ¡é—´çš„ä¾èµ–å…³ç³»ã€‚ChronoGraphçš„ä¸»è¦ä»»åŠ¡æ˜¯è¿›è¡ŒæœåŠ¡çº§çš„æœªæ¥ä¿¡å·é¢„æµ‹ï¼ŒåŒæ—¶æä¾›äº†ä¸“å®¶æ ‡æ³¨çš„äº‹æ•…çª—å£ä½œä¸ºå¼‚å¸¸æ ‡ç­¾(anomaly labels)ï¼Œä»¥æ”¯æŒå¯¹å¼‚å¸¸æ£€æµ‹æ–¹æ³•å’Œé¢„æµ‹é²æ£’æ€§çš„è¯„ä¼°ã€‚ç›¸æ¯”äºç°æœ‰çš„å·¥ä¸šæ§åˆ¶æˆ–äº¤é€šé¢†åŸŸåŸºå‡†ï¼Œè¯¥æ•°æ®é›†ç‹¬ç‰¹åœ°æ•´åˆäº†å¤šå˜é‡åºåˆ—ã€æ˜¾å¼çš„æœºå™¨å¯è¯»ä¾èµ–å›¾ä»¥åŠä¸çœŸå®äº‹æ•…å¯¹é½çš„æ ‡ç­¾ã€‚ç ”ç©¶å›¢é˜Ÿæä¾›äº†æ¶µç›–ä¼ ç»Ÿé¢„æµ‹æ¨¡å‹ã€é¢„è®­ç»ƒæ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹(foundation models)åŠæ ‡å‡†å¼‚å¸¸æ£€æµ‹å™¨çš„åŸºå‡†æµ‹è¯•ç»“æœã€‚ChronoGraphä¸ºç ”ç©¶å¾®æœåŠ¡ç³»ç»Ÿä¸­çš„ç»“æ„æ„ŸçŸ¥é¢„æµ‹(structure-aware forecasting)å’Œäº‹æ•…æ„ŸçŸ¥è¯„ä¼°æä¾›äº†ä¸€ä¸ªæå…·ç°å®æ„ä¹‰çš„åŸºå‡†å¹³å°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as an oral presentation at the NeurIPS 2025 Workshop on Recent Advances in Time Series Foundation Models (BERT2S)",
      "pdf_url": "https://arxiv.org/pdf/2509.04449v3",
      "published_date": "2025-09-04 17:59:52 UTC",
      "updated_date": "2025-11-27 14:30:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:53.884893+00:00"
    },
    {
      "arxiv_id": "2509.04442v1",
      "title": "Delta Activations: A Representation for Finetuned Large Language Models",
      "title_zh": "Delta Activationsï¼šä¸€ç§é¢å‘å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹çš„è¡¨ç¤ºæ–¹æ³•",
      "authors": [
        "Zhiqiu Xu",
        "Amish Sethi",
        "Mayur Naik",
        "Ser-Nam Lim"
      ],
      "abstract": "The success of powerful open source Large Language Models (LLMs) has enabled the community to create a vast collection of post-trained models adapted to specific tasks and domains. However, navigating and understanding these models remains challenging due to inconsistent metadata and unstructured repositories. We introduce Delta Activations, a method to represent finetuned models as vector embeddings by measuring shifts in their internal activations relative to a base model. This representation allows for effective clustering by domain and task, revealing structure in the model landscape. Delta Activations also demonstrate desirable properties: it is robust across finetuning settings and exhibits an additive property when finetuning datasets are mixed. In addition, we show that Delta Activations can embed tasks via few-shot finetuning, and further explore its use for model selection and merging. We hope Delta Activations can facilitate the practice of reusing publicly available models. Code is available at https://github.com/OscarXZQ/delta_activations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Delta Activationsï¼Œè¿™æ˜¯ä¸€ç§å°†ç»è¿‡å¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹ (LLMs) è¡¨ç¤ºä¸ºå‘é‡åµŒå…¥ (vector embeddings) çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¾®è°ƒæ¨¡å‹åº“ä¸­å…ƒæ•°æ®ä¸ä¸€è‡´å’Œç»“æ„åŒ–ç¨‹åº¦ä½çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡æµ‹é‡å¾®è°ƒæ¨¡å‹ç›¸å¯¹äºåŸºç¡€æ¨¡å‹ (base model) çš„å†…éƒ¨æ¿€æ´» (internal activations) åç§»é‡æ¥æ„å»ºè¡¨ç¤ºï¼Œä»è€Œèƒ½å¤Ÿæ ¹æ®é¢†åŸŸå’Œä»»åŠ¡å¯¹æ¨¡å‹è¿›è¡Œæœ‰æ•ˆèšç±»å¹¶æ­ç¤ºå…¶æ½œåœ¨ç»“æ„ã€‚å®éªŒè¡¨æ˜ Delta Activations åœ¨ä¸åŒçš„å¾®è°ƒè®¾ç½®ä¸‹è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œå¹¶ä¸”åœ¨æ··åˆå¾®è°ƒæ•°æ®é›†æ—¶å…·æœ‰ç‹¬ç‰¹çš„ç›¸åŠ æ€§ (additive property)ã€‚æ­¤å¤–ï¼Œç ”ç©¶å±•ç¤ºäº†è¯¥æ–¹æ³•å¯é€šè¿‡å°‘æ ·æœ¬ (few-shot) å¾®è°ƒæ¥åµŒå…¥ä»»åŠ¡ï¼Œå¹¶åœ¨æ¨¡å‹é€‰æ‹© (model selection) å’Œæ¨¡å‹åˆå¹¶ (model merging) åœºæ™¯ä¸­å±•ç°å‡ºä¼˜å¼‚çš„åº”ç”¨æ½œåŠ›ã€‚è¯¥ç ”ç©¶ä¸ºä¿ƒè¿›å…¬å¼€å¯ç”¨æ¨¡å‹çš„é‡ç”¨å’Œç®¡ç†æä¾›äº†æ–°çš„è§†è§’ä¸å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04442v1",
      "published_date": "2025-09-04 17:59:06 UTC",
      "updated_date": "2025-09-04 17:59:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:50.984809+00:00"
    },
    {
      "arxiv_id": "2509.04441v2",
      "title": "DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation",
      "title_zh": "DEXOPï¼šä¸€ç§ç”¨äºæœºå™¨äººè¿ç§»äººç±»çµå·§æ“ä½œçš„è£…ç½®",
      "authors": [
        "Hao-Shu Fang",
        "Branden Romero",
        "Yichen Xie",
        "Arthur Hu",
        "Bo-Ruei Huang",
        "Juan Alvarez",
        "Matthew Kim",
        "Gabriel Margolis",
        "Kavya Anbarasu",
        "Masayoshi Tomizuka",
        "Edward Adelson",
        "Pulkit Agrawal"
      ],
      "abstract": "We introduce perioperation, a paradigm for robotic data collection that sensorizes and records human manipulation while maximizing the transferability of the data to real robots. We implement this paradigm in DEXOP, a passive hand exoskeleton designed to maximize human ability to collect rich sensory (vision + tactile) data for diverse dexterous manipulation tasks in natural environments. DEXOP mechanically connects human fingers to robot fingers, providing users with direct contact feedback (via proprioception) and mirrors the human hand pose to the passive robot hand to maximize the transfer of demonstrated skills to the robot. The force feedback and pose mirroring make task demonstrations more natural for humans compared to teleoperation, increasing both speed and accuracy. We evaluate DEXOP across a range of dexterous, contact-rich tasks, demonstrating its ability to collect high-quality demonstration data at scale. Policies learned with DEXOP data significantly improve task performance per unit time of data collection compared to teleoperation, making DEXOP a powerful tool for advancing robot dexterity. Our project page is at https://dex-op.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†åä¸ºperioperationçš„æœºå™¨äººæ•°æ®é‡‡é›†èŒƒå¼ï¼Œæ—¨åœ¨é€šè¿‡è®°å½•äººç±»æ“ä½œæ¥æœ€å¤§åŒ–æ•°æ®å‘çœŸå®æœºå™¨äººçš„å¯è¿ç§»æ€§ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†DEXOPï¼Œè¿™æ˜¯ä¸€ç§è¢«åŠ¨å¼æ‰‹éƒ¨å¤–éª¨éª¼(passive hand exoskeleton)ï¼Œä¸“ä¸ºåœ¨è‡ªç„¶ç¯å¢ƒä¸­é‡‡é›†ä¸°å¯Œçš„è§†è§‰ä¸è§¦è§‰(tactile)æ„Ÿå®˜æ•°æ®è€Œè®¾è®¡ã€‚DEXOPé€šè¿‡æœºæ¢°æ‰‹æ®µå°†äººç±»æ‰‹æŒ‡ä¸æœºå™¨äººæ‰‹æŒ‡è¿æ¥ï¼Œä¸ºç”¨æˆ·æä¾›ç›´æ¥çš„æœ¬ä½“æ„Ÿè§‰(proprioception)åé¦ˆå¹¶å®ç°æ‰‹åŠ¿é•œåƒï¼Œä½¿æ¼”ç¤ºè¿‡ç¨‹æ¯”ä¼ ç»Ÿé¥æ“ä½œ(teleoperation)æ›´è‡ªç„¶ã€æ›´é«˜æ•ˆä¸”æ›´å‡†ç¡®ã€‚åœ¨æ¶‰åŠå¤šç§çµå·§ã€æ¥è§¦å¯†é›†å‹ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼Œå®éªŒè¯æ˜åˆ©ç”¨DEXOPé‡‡é›†çš„æ•°æ®æ‰€è®­ç»ƒçš„ç­–ç•¥åœ¨å•ä½æ—¶é—´å†…çš„ä»»åŠ¡è¡¨ç°æ˜¾è‘—ä¼˜äºé¥æ“ä½œï¼Œä¸ºæ¨è¿›æœºå™¨äººçµå·§æ“ä½œ(robot dexterity)æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "project page: https://dex-op.github.io",
      "pdf_url": "https://arxiv.org/pdf/2509.04441v2",
      "published_date": "2025-09-04 17:57:13 UTC",
      "updated_date": "2025-09-08 12:08:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:30:45.392063+00:00"
    },
    {
      "arxiv_id": "2509.04439v3",
      "title": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory",
      "title_zh": "ArcMemoï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹ç»ˆèº«è®°å¿†çš„æŠ½è±¡æ¨ç†ç»„åˆ",
      "authors": [
        "Matthew Ho",
        "Chen Si",
        "Zhaoxiang Feng",
        "Fangxu Yu",
        "Yichi Yang",
        "Zhijian Liu",
        "Zhiting Hu",
        "Lianhui Qin"
      ],
      "abstract": "While inference-time scaling enables LLMs to carry out increasingly long and capable reasoning traces, the patterns and insights uncovered during these traces are immediately discarded once the context window is reset for a new query. External memory is a natural way to persist these discoveries, and recent work has shown clear benefits for reasoning-intensive tasks. We see an opportunity to make such memories more broadly reusable and scalable by moving beyond instance-based memory entries (e.g. exact query/response pairs, or summaries tightly coupled with the original problem context) toward concept-level memory: reusable, modular abstractions distilled from solution traces and stored in natural language. For future queries, relevant concepts are selectively retrieved and integrated into the prompt, enabling test-time continual learning without weight updates. Our design introduces new strategies for abstracting takeaways from rollouts and retrieving entries for new queries, promoting reuse and allowing memory to expand with additional experiences. We evaluate on ARC-AGI, a benchmark that stresses compositional generalization and abstract reasoning, making it a natural fit for concept memory. Our method yields a 7.5% relative gain over a strong no-memory baseline with performance continuing to scale with inference compute. We find abstract concepts to be the most consistent memory design, outscoring the baseline at all tested inference compute scales. Moreover, dynamically updating memory during test-time outperforms fixed settings, supporting the hypothesis that accumulating and abstracting patterns enables further solutions in a form of self-improvement. Code is available at https://github.com/matt-seb-ho/arc_memo.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ArcMemoï¼Œä¸€ç§å…·å¤‡ç»ˆèº«é•¿æ•ˆè®°å¿†çš„æŠ½è±¡æ¨ç†ç»„åˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ¨ç†è¿‡ç¨‹ä¸­äº§ç”Ÿçš„æ´å¯Ÿéšä¸Šä¸‹æ–‡çª—å£é‡ç½®è€Œä¸¢å¤±çš„é—®é¢˜ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºå®ä¾‹æˆ–ç®€å•æ‘˜è¦çš„å¤–éƒ¨å­˜å‚¨ä¸åŒï¼ŒArcMemoå¼•å…¥äº†æ¦‚å¿µçº§å­˜å‚¨(concept-level memory)ï¼Œå°†ä»è§£é¢˜è·¯å¾„ä¸­æç‚¼å‡ºçš„æ¨¡å—åŒ–æŠ½è±¡æ¦‚å¿µä»¥è‡ªç„¶è¯­è¨€å½¢å¼å­˜å‚¨ï¼Œä½¿å…¶æ›´å…·é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚åœ¨å¤„ç†æ–°æŸ¥è¯¢æ—¶ï¼Œç³»ç»Ÿä¼šé€‰æ‹©æ€§åœ°æ£€ç´¢å¹¶æ•´åˆç›¸å…³æ¦‚å¿µåˆ°æç¤ºè¯ä¸­ï¼Œå®ç°æ— éœ€æƒé‡æ›´æ–°çš„æ¨ç†æ—¶æŒç»­å­¦ä¹ (test-time continual learning)ã€‚è¯¥æ–¹æ³•åœ¨å¼ºè°ƒç»„åˆæ³›åŒ–ä¸æŠ½è±¡æ¨ç†çš„ARC-AGIåŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºå…¶ç›¸å¯¹äºå¼ºåŸºçº¿æ¨¡å‹å–å¾—äº†7.5%çš„ç›¸å¯¹å¢ç›Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒæŠ½è±¡æ¦‚å¿µå­˜å‚¨åœ¨ä¸åŒæ¨ç†è®¡ç®—è§„æ¨¡ä¸‹å‡è¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨æµ‹è¯•æ—¶åŠ¨æ€æ›´æ–°å­˜å‚¨æ¯”å›ºå®šè®¾ç½®æ›´æœ‰æ•ˆï¼Œæ”¯æŒäº†é€šè¿‡ç§¯ç´¯å’ŒæŠ½è±¡æ¨¡å¼å®ç°æ¨¡å‹è‡ªæˆ‘æ”¹è¿›çš„å‡è®¾ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04439v3",
      "published_date": "2025-09-04 17:54:19 UTC",
      "updated_date": "2025-10-04 00:01:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:31:00.391610+00:00"
    },
    {
      "arxiv_id": "2509.06998v2",
      "title": "Not All Splits Are Equal: Rethinking Attribute Generalization Across Unrelated Categories",
      "title_zh": "å¹¶éæ‰€æœ‰åˆ’åˆ†å‡ç­‰ï¼šé‡æ–°å®¡è§†è·¨æ— å…³ç±»åˆ«çš„å±æ€§æ³›åŒ–",
      "authors": [
        "Liviu Nicolae FircÄƒ",
        "Antonio BÄƒrbÄƒlau",
        "Dan Oneata",
        "Elena Burceanu"
      ],
      "abstract": "Can models generalize attribute knowledge across semantically and perceptually dissimilar categories? While prior work has addressed attribute prediction within narrow taxonomic or visually similar domains, it remains unclear whether current models can abstract attributes and apply them to conceptually distant categories. This work presents the first explicit evaluation for the robustness of the attribute prediction task under such conditions, testing whether models can correctly infer shared attributes between unrelated object types: e.g., identifying that the attribute \"has four legs\" is common to both \"dogs\" and \"chairs\". To enable this evaluation, we introduce train-test split strategies that progressively reduce correlation between training and test sets, based on: LLM-driven semantic grouping, embedding similarity thresholding, embedding-based clustering, and supercategory-based partitioning using ground-truth labels. Results show a sharp drop in performance as the correlation between training and test categories decreases, indicating strong sensitivity to split design. Among the evaluated methods, clustering yields the most effective trade-off, reducing hidden correlations while preserving learnability. These findings offer new insights into the limitations of current representations and inform future benchmark construction for attribute reasoning.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†æ¨¡å‹æ˜¯å¦èƒ½åœ¨è¯­ä¹‰å’Œæ„ŸçŸ¥ä¸Šå®Œå…¨ä¸åŒçš„ç±»åˆ«ä¹‹é—´å®ç°å±æ€§çŸ¥è¯†çš„æ³›åŒ–ï¼ˆattribute generalizationï¼‰ï¼Œå¹¶æå‡ºäº†é¦–ä¸ªé’ˆå¯¹éç›¸å…³å¯¹è±¡ç±»å‹ä¹‹é—´å…±äº«å±æ€§æ¨ç†çš„é²æ£’æ€§è¯„ä¼°æ–¹æ¡ˆã€‚é€šè¿‡å¼•å…¥åŒ…æ‹¬LLMé©±åŠ¨çš„è¯­ä¹‰åˆ†ç»„ã€åµŒå…¥ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆembedding similarity thresholdingï¼‰ã€åŸºäºåµŒå…¥çš„èšç±»ï¼ˆembedding-based clusteringï¼‰ä»¥åŠè¶…ç±»åˆ’åˆ†ï¼ˆsupercategory-based partitioningï¼‰åœ¨å†…çš„å¤šç§åˆ’åˆ†ç­–ç•¥ï¼Œç ”ç©¶æµ‹è¯•äº†æ¨¡å‹åœ¨å‡å°‘è®­ç»ƒä¸æµ‹è¯•é›†ç›¸å…³æ€§ä¸‹çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œéšç€ç±»åˆ«ç›¸å…³æ€§çš„é™ä½ï¼Œæ¨¡å‹æ€§èƒ½å‡ºç°å‰§çƒˆä¸‹æ»‘ï¼Œè¡¨æ˜å½“å‰ç³»ç»Ÿå¯¹åˆ’åˆ†è®¾è®¡å…·æœ‰æå¼ºçš„æ•æ„Ÿæ€§ã€‚åœ¨è¯„ä¼°çš„æ–¹æ³•ä¸­ï¼Œèšç±»ï¼ˆclusteringï¼‰è¢«è¯æ˜æ˜¯å‡å°‘éšè—ç›¸å…³æ€§å¹¶ä¿æŒå¯å­¦ä¹ æ€§çš„æœ€æœ‰æ•ˆæŠ˜è¡·æ–¹æ¡ˆã€‚è¿™äº›å‘ç°æ­ç¤ºäº†å½“å‰è¡¨ç¤ºå­¦ä¹ åœ¨å±æ€§æŠ½è±¡æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥å±æ€§æ¨ç†ï¼ˆattribute reasoningï¼‰åŸºå‡†çš„æ„å»ºæä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at NeurIPS 2025 Workshop: CauScien - Uncovering Causality in Science and NeurIPS 2025 Workshop: Reliable ML from Unreliable Data",
      "pdf_url": "https://arxiv.org/pdf/2509.06998v2",
      "published_date": "2025-09-04 17:52:22 UTC",
      "updated_date": "2025-11-26 11:47:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:31:17.890561+00:00"
    },
    {
      "arxiv_id": "2509.04419v2",
      "title": "Towards a Unified View of Large Language Model Post-Training",
      "title_zh": "è¿ˆå‘å¤§è¯­è¨€æ¨¡å‹åè®­ç»ƒçš„ç»Ÿä¸€è§†è§’",
      "authors": [
        "Xingtai Lv",
        "Yuxin Zuo",
        "Youbang Sun",
        "Hongyi Liu",
        "Yuntian Wei",
        "Zhekai Chen",
        "Xuekai Zhu",
        "Kaiyan Zhang",
        "Bingning Wang",
        "Ning Ding",
        "Bowen Zhou"
      ],
      "abstract": "Two major sources of training data exist for post-training modern language models: online (model-generated rollouts) data, and offline (human or other-model demonstrations) data. These two types of data are typically used by approaches like Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT), respectively. In this paper, we show that these approaches are not in contradiction, but are instances of a single optimization process. We derive a Unified Policy Gradient Estimator, and present the calculations of a wide spectrum of post-training approaches as the gradient of a common objective under different data distribution assumptions and various bias-variance tradeoffs. The gradient estimator is constructed with four interchangeable parts: stabilization mask, reference policy denominator, advantage estimate, and likelihood gradient. Motivated by our theoretical findings, we propose Hybrid Post-Training (HPT), an algorithm that dynamically selects different training signals. HPT is designed to yield both effective exploitation of demonstration and stable exploration without sacrificing learned reasoning patterns. We provide extensive experiments and ablation studies to verify the effectiveness of our unified theoretical framework and HPT. Across six mathematical reasoning benchmarks and two out-of-distribution suites, HPT consistently surpasses strong baselines across models of varying scales and families.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åè®­ç»ƒ(Post-Training)çš„ç»Ÿä¸€è§†è§’ï¼ŒæŒ‡å‡ºå¼ºåŒ–å­¦ä¹ (RL)å’Œæœ‰ç›‘ç£å¾®è°ƒ(SFT)å®é™…ä¸Šæ˜¯å•ä¸€ä¼˜åŒ–è¿‡ç¨‹çš„å®ä¾‹ã€‚ä½œè€…æ¨å¯¼å‡ºäº†ç»Ÿä¸€ç­–ç•¥æ¢¯åº¦ä¼°è®¡å™¨(Unified Policy Gradient Estimator)ï¼Œå°†å¤šç§åè®­ç»ƒæ–¹æ³•å½’çº³ä¸ºåœ¨ä¸åŒæ•°æ®åˆ†å¸ƒå‡è®¾å’Œåç½®-æ–¹å·®æƒè¡¡ä¸‹çš„å…±åŒç›®æ ‡æ¢¯åº¦ã€‚è¯¥ä¼°è®¡å™¨ç”±ç¨³å®šåŒ–æ©ç (stabilization mask)ã€å‚è€ƒç­–ç•¥åˆ†æ¯(reference policy denominator)ã€ä¼˜åŠ¿ä¼°è®¡(advantage estimate)å’Œä¼¼ç„¶æ¢¯åº¦(likelihood gradient)å››ä¸ªå¯äº¤æ¢éƒ¨åˆ†ç»„æˆã€‚åŸºäºç†è®ºå‘ç°ï¼Œç ”ç©¶æå‡ºäº†æ··åˆåè®­ç»ƒ(Hybrid Post-Training, HPT)ç®—æ³•ï¼Œæ—¨åœ¨åŠ¨æ€é€‰æ‹©è®­ç»ƒä¿¡å·ä»¥å¹³è¡¡å¯¹ç¤ºèŒƒæ•°æ®çš„åˆ©ç”¨ä¸ç¨³å®šçš„æ¢ç´¢ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼ŒHPTåœ¨å…­é¡¹æ•°å­¦æ¨ç†åŸºå‡†å’Œåˆ†å¸ƒå¤–(Out-of-Distribution)æµ‹è¯•ä¸­ä¸€è‡´è¶…è¶Šäº†å¤šç§è§„æ¨¡çš„å¼ºåŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†è¯¥ç»Ÿä¸€æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04419v2",
      "published_date": "2025-09-04 17:40:33 UTC",
      "updated_date": "2026-01-20 05:05:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:31:22.499864+00:00"
    },
    {
      "arxiv_id": "2509.04549v1",
      "title": "Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions",
      "title_zh": "æ“æ§åŸºäº Transformer çš„æ¨¡å‹ï¼šå¯æ§æ€§ã€å¯å¼•å¯¼æ€§ä¸é²æ£’å¹²é¢„",
      "authors": [
        "Faruk Alpay",
        "Taylan Alpay"
      ],
      "abstract": "Transformer-based language models excel in NLP tasks, but fine-grained control remains challenging. This paper explores methods for manipulating transformer models through principled interventions at three levels: prompts, activations, and weights. We formalize controllable text generation as an optimization problem addressable via prompt engineering, parameter-efficient fine-tuning, model editing, and reinforcement learning. We introduce a unified framework encompassing prompt-level steering, activation interventions, and weight-space edits. We analyze robustness and safety implications, including adversarial attacks and alignment mitigations. Theoretically, we show minimal weight updates can achieve targeted behavior changes with limited side-effects. Empirically, we demonstrate >90% success in sentiment control and factual edits while preserving base performance, though generalization-specificity trade-offs exist. We discuss ethical dual-use risks and the need for rigorous evaluation. This work lays groundwork for designing controllable and robust language models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ“æ§åŸºäº Transformer çš„æ¨¡å‹çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç»†ç²’åº¦æ§åˆ¶çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†æ¶µç›–æç¤º (prompts)ã€æ¿€æ´» (activations) å’Œæƒé‡ (weights) ä¸‰ä¸ªå±‚é¢çš„åŸåˆ™æ€§å¹²é¢„æ¡†æ¶ã€‚æ–‡ç« å°†å¯æ§æ–‡æœ¬ç”Ÿæˆ (controllable text generation) å½¢å¼åŒ–ä¸ºä¼˜åŒ–é—®é¢˜ï¼Œç»¼åˆè¿ç”¨äº†æç¤ºå·¥ç¨‹ (prompt engineering)ã€å‚æ•°é«˜æ•ˆå¾®è°ƒ (parameter-efficient fine-tuning)ã€æ¨¡å‹ç¼–è¾‘ (model editing) å’Œå¼ºåŒ–å­¦ä¹  (reinforcement learning) ç­‰æŠ€æœ¯ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œæå°çš„æƒé‡æ›´æ–°å³å¯å®ç°ç›®æ ‡çš„è¡Œä¸ºæ”¹å˜ï¼Œä¸”äº§ç”Ÿçš„å‰¯ä½œç”¨æœ‰é™ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æƒ…æ„Ÿæ§åˆ¶å’Œäº‹å®ç¼–è¾‘æ–¹é¢çš„æˆåŠŸç‡è¶…è¿‡ 90%ï¼ŒåŒæ—¶èƒ½è¾ƒå¥½åœ°ä¿æŒæ¨¡å‹çš„åŸºç¡€æ€§èƒ½ï¼Œå°½ç®¡åœ¨æ³›åŒ–æ€§ä¸ç‰¹å¼‚æ€§ä¹‹é—´å­˜åœ¨æƒè¡¡ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜è®¨è®ºäº†é²æ£’æ€§ã€å®‰å…¨æ€§åŠä¼¦ç†é£é™©ï¼Œä¸ºè®¾è®¡å¯æ§ä¸”ç¨³å¥çš„è¯­è¨€æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.04549v1",
      "published_date": "2025-09-04 17:32:56 UTC",
      "updated_date": "2025-09-04 17:32:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:31:16.483901+00:00"
    },
    {
      "arxiv_id": "2509.04404v2",
      "title": "No Thoughts Just AI: Biased LLM Hiring Recommendations Alter Human Decision Making and Limit Human Autonomy",
      "title_zh": "ä¸å‡æ€ç´¢ï¼Œå”¯ AI æ˜¯ä»ï¼šå¤§è¯­è¨€æ¨¡å‹åå‘æ€§æ‹›è˜å»ºè®®å¯¹äººç±»å†³ç­–çš„æ”¹å˜ä¸è‡ªä¸»æ€§çš„é™åˆ¶",
      "authors": [
        "Kyra Wilson",
        "Mattea Sim",
        "Anna-Maria Gueorguieva",
        "Aylin Caliskan"
      ],
      "abstract": "In this study, we conduct a resume-screening experiment (N=528) where people collaborate with simulated AI models exhibiting race-based preferences (bias) to evaluate candidates for 16 high and low status occupations. Simulated AI bias approximates factual and counterfactual estimates of racial bias in real-world AI systems. We investigate people's preferences for White, Black, Hispanic, and Asian candidates (represented through names and affinity groups on quality-controlled resumes) across 1,526 scenarios and measure their unconscious associations between race and status using implicit association tests (IATs), which predict discriminatory hiring decisions but have not been investigated in human-AI collaboration. When making decisions without AI or with AI that exhibits no race-based preferences, people select all candidates at equal rates. However, when interacting with AI favoring a particular group, people also favor those candidates up to 90% of the time, indicating a significant behavioral shift. The likelihood of selecting candidates whose identities do not align with common race-status stereotypes can increase by 13% if people complete an IAT before conducting resume screening. Finally, even if people think AI recommendations are low quality or not important, their decisions are still vulnerable to AI bias under certain circumstances. This work has implications for people's autonomy in AI-HITL scenarios, AI and work, design and evaluation of AI hiring systems, and strategies for mitigating bias in collaborative decision-making tasks. In particular, organizational and regulatory policy should acknowledge the complex nature of AI-HITL decision making when implementing these systems, educating people who use them, and determining which are subject to oversight.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…·æœ‰ç§æ—åå¥½çš„å¤§è¯­è¨€æ¨¡å‹(LLM)æ‹›è˜å»ºè®®å¦‚ä½•æ”¹å˜äººç±»å†³ç­–å¹¶é™åˆ¶äººç±»è‡ªä¸»æƒã€‚ç ”ç©¶é€šè¿‡ä¸€é¡¹ç®€å†ç­›é€‰å®éªŒ(N=528)ï¼Œè®©å‚ä¸è€…ä¸æ¨¡æ‹Ÿäº†ç§æ—åå¥½çš„AIæ¨¡å‹åä½œè¯„ä¼°é’ˆå¯¹16ç§èŒä¸šçš„Whiteã€Blackã€Hispanicå’ŒAsianå€™é€‰äººï¼Œå¹¶åˆ©ç”¨å†…éšè”æƒ³æµ‹è¯•(IAT)æµ‹é‡ç§æ—ä¸åœ°ä½ä¹‹é—´çš„æ— æ„è¯†å…³è”ã€‚å®éªŒå‘ç°ï¼Œåœ¨æ²¡æœ‰AIæˆ–AIä¸­ç«‹çš„æƒ…å†µä¸‹ï¼Œäººç±»çš„é€‰æ‹©å€¾å‘æ˜¯å‡è¡¡çš„ï¼›ä½†å½“AIåå¥½ç‰¹å®šç¾¤ä½“æ—¶ï¼Œäººç±»è·ŸéšAIå»ºè®®çš„æ¯”ä¾‹é«˜è¾¾90%ï¼Œè¡¨æ˜AIæ˜¾è‘—é‡å¡‘äº†äººç±»çš„è¡Œä¸ºã€‚æ­¤å¤–ï¼Œåœ¨ç­›é€‰å‰å®ŒæˆIATæµ‹è¯•èƒ½å°†é€‰æ‹©éåˆ»æ¿å°è±¡å€™é€‰äººçš„æ¦‚ç‡æé«˜13%ã€‚ç ”ç©¶è¿˜æŒ‡å‡ºï¼Œå³ä½¿å‚ä¸è€…è®¤ä¸ºAIå»ºè®®è´¨é‡è¾ƒä½ï¼Œå…¶å†³ç­–åœ¨ç‰¹å®šæƒ…å½¢ä¸‹ä»æ˜“å—AI biasçš„å½±å“ã€‚è¯¥æˆæœæ­ç¤ºäº†AI-HITLåœºæ™¯ä¸­äººç±»è‡ªä¸»æƒçš„å±€é™æ€§ï¼Œå¹¶ä¸ºAIæ‹›è˜ç³»ç»Ÿçš„è®¾è®¡ã€åå·®ç¼“è§£ä»¥åŠç›‘ç®¡æ”¿ç­–æä¾›äº†é‡è¦çš„å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Published in Proceedings of the 2025 AAAI/ACM Conference on AI, Ethics, and Society; code available at https://github.com/kyrawilson/No-Thoughts-Just-AI",
      "pdf_url": "https://arxiv.org/pdf/2509.04404v2",
      "published_date": "2025-09-04 17:16:26 UTC",
      "updated_date": "2025-09-08 19:40:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:31:42.798648+00:00"
    },
    {
      "arxiv_id": "2509.04398v3",
      "title": "IPA: An Information-Reconstructive Input Projection Framework for Efficient Foundation Model Adaptation",
      "title_zh": "IPAï¼šé¢å‘é«˜æ•ˆåŸºç¡€æ¨¡å‹é€‚é…çš„ä¿¡æ¯é‡æ„è¾“å…¥æŠ•å½±æ¡†æ¶",
      "authors": [
        "Yuan Yin",
        "Shashanka Venkataramanan",
        "Tuan-Hung Vu",
        "Andrei Bursuc",
        "Matthieu Cord"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, reduce adaptation cost by injecting low-rank updates into pretrained weights. However, LoRA's down-projection is randomly initialized and data-agnostic, discarding potentially useful information. Prior analyses show that this projection changes little during training, while the up-projection carries most of the adaptation, making the random input compression a performance bottleneck. We propose IPA, a feature-aware projection framework that explicitly aims to reconstruct the original input within a reduced hidden space. In the linear case, we instantiate IPA with algorithms approximating top principal components, enabling efficient projector pretraining with negligible inference overhead. Across language and vision benchmarks, IPA consistently improves over LoRA and DoRA, achieving on average 1.5 points higher accuracy on commonsense reasoning and 2.3 points on VTAB-1k, while matching full LoRA performance with roughly half the trainable parameters when the projection is frozen. Code available at https://github.com/valeoai/peft-ipa .",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ LoRA ç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT) æ–¹æ³•ä¸­ä¸‹é‡‡æ ·æŠ•å½±éšæœºåˆå§‹åŒ–å¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±é—®é¢˜ï¼Œæå‡ºäº† IPA æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§å…·æœ‰ç‰¹å¾æ„ŸçŸ¥èƒ½åŠ›çš„è¾“å…¥æŠ•å½±æ–¹æ³•ï¼Œæ—¨åœ¨ç¼©å‡çš„éšç©ºé—´å†…æ˜¾å¼é‡å»ºåŸå§‹è¾“å…¥ä¿¡æ¯ã€‚åœ¨çº¿æ€§æƒ…å†µä¸‹ï¼ŒIPA åˆ©ç”¨è¿‘ä¼¼ä¸»æˆåˆ†ç®—æ³•å®ç°æŠ•å½±å™¨çš„é¢„è®­ç»ƒï¼Œåœ¨ä¿è¯æ¨ç†å¼€é”€æä½çš„åŒæ—¶æœ‰æ•ˆè§£å†³äº†ä¼ ç»ŸæŠ•å½±å±‚åœ¨è®­ç»ƒä¸­å˜åŒ–æå°æ‰€å¸¦æ¥çš„æ€§èƒ½ç“¶é¢ˆã€‚å®éªŒè¡¨æ˜ï¼ŒIPA åœ¨è¯­è¨€å¸¸è¯†æ¨ç†å’Œè§†è§‰ VTAB-1k åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°å§‹ç»ˆä¼˜äº LoRA å’Œ DoRAï¼Œå¹³å‡å‡†ç¡®ç‡åˆ†åˆ«æå‡äº† 1.5 å’Œ 2.3 ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼Œåœ¨æŠ•å½±å±‚å†»ç»“çš„æƒ…å†µä¸‹ï¼ŒIPA ä»…éœ€çº¦ä¸€åŠçš„å¯è®­ç»ƒå‚æ•°å³å¯è¾¾åˆ°å…¨é‡ LoRA çš„æ€§èƒ½æ°´å¹³ã€‚è¯¥æ¡†æ¶çš„ä»£ç å·²å¼€æºï¼Œä¸ºåŸºç¡€æ¨¡å‹çš„é«˜æ•ˆé€‚é…æä¾›äº†ä¸€ç§æ›´å…·ä¿¡æ¯ä¿çœŸåº¦çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to TMLR",
      "pdf_url": "https://arxiv.org/pdf/2509.04398v3",
      "published_date": "2025-09-04 17:10:01 UTC",
      "updated_date": "2026-01-06 09:17:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:31:41.697747+00:00"
    },
    {
      "arxiv_id": "2509.04379v1",
      "title": "SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer",
      "title_zh": "SSGaussianï¼šè¯­ä¹‰æ„ŸçŸ¥ä¸ç»“æ„ä¿æŒçš„3Dé£æ ¼è¿ç§»",
      "authors": [
        "Jimin Xu",
        "Bosheng Qin",
        "Tao Jin",
        "Zhou Zhao",
        "Zhenhui Ye",
        "Jun Yu",
        "Fei Wu"
      ],
      "abstract": "Recent advancements in neural representations, such as Neural Radiance Fields and 3D Gaussian Splatting, have increased interest in applying style transfer to 3D scenes. While existing methods can transfer style patterns onto 3D-consistent neural representations, they struggle to effectively extract and transfer high-level style semantics from the reference style image. Additionally, the stylized results often lack structural clarity and separation, making it difficult to distinguish between different instances or objects within the 3D scene. To address these limitations, we propose a novel 3D style transfer pipeline that effectively integrates prior knowledge from pretrained 2D diffusion models. Our pipeline consists of two key stages: First, we leverage diffusion priors to generate stylized renderings of key viewpoints. Then, we transfer the stylized key views onto the 3D representation. This process incorporates two innovative designs. The first is cross-view style alignment, which inserts cross-view attention into the last upsampling block of the UNet, allowing feature interactions across multiple key views. This ensures that the diffusion model generates stylized key views that maintain both style fidelity and instance-level consistency. The second is instance-level style transfer, which effectively leverages instance-level consistency across stylized key views and transfers it onto the 3D representation. This results in a more structured, visually coherent, and artistically enriched stylization. Extensive qualitative and quantitative experiments demonstrate that our 3D style transfer pipeline significantly outperforms state-of-the-art methods across a wide range of scenes, from forward-facing to challenging 360-degree environments. Visit our project page https://jm-xu.github.io/SSGaussian for immersive visualization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SSGaussianï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹3Dåœºæ™¯çš„è¯­ä¹‰æ„ŸçŸ¥ä¸”ä¿æŒç»“æ„çš„é£æ ¼è¿ç§»æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨æå–é«˜çº§é£æ ¼è¯­ä¹‰ä»¥åŠä¿æŒ3Dåœºæ™¯ç»“æ„æ¸…æ™°åº¦æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆé¢„è®­ç»ƒçš„2D Diffusion Modelså…ˆéªŒçŸ¥è¯†ï¼Œåˆ©ç”¨ä¸¤ä¸ªå…³é”®é˜¶æ®µå®ç°é«˜è´¨é‡çš„é£æ ¼è¿ç§»ã€‚é¦–å…ˆï¼Œç ”ç©¶å¼•å…¥äº†Cross-view style alignmentæœºåˆ¶ï¼Œé€šè¿‡åœ¨UNetä¸­åµŒå…¥Cross-view attentionï¼Œç¡®ä¿ç”Ÿæˆçš„å…³é”®è§†å›¾åœ¨é£æ ¼ä¿çœŸåº¦å’ŒInstance-levelä¸€è‡´æ€§ä¸Šè¾¾åˆ°å¹³è¡¡ã€‚éšåï¼Œé€šè¿‡Instance-level style transferæŠ€æœ¯å°†ä¸€è‡´çš„é£æ ¼ä¿¡æ¯æœ‰æ•ˆåœ°æ˜ å°„åˆ°3Dè¡¨ç¤ºä¸­ï¼Œä»è€Œè·å¾—æ›´å…·ç»“æ„æ„Ÿå’Œè§†è§‰è¿è´¯æ€§çš„é£æ ¼åŒ–æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSSGaussianåœ¨ä»å‰å‘åœºæ™¯åˆ°æŒ‘æˆ˜æ€§çš„360åº¦ç¯å¢ƒçš„å¤šç§æµ‹è¯•ä¸­ï¼Œå…¶æ€§èƒ½å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„State-of-the-artæ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ä¸ºå®ç°å…·æœ‰è‰ºæœ¯æ„Ÿä¸”å®ä¾‹åˆ†æ˜çš„3Dåœºæ™¯é‡å»ºæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04379v1",
      "published_date": "2025-09-04 16:40:44 UTC",
      "updated_date": "2025-09-04 16:40:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:31:46.794162+00:00"
    },
    {
      "arxiv_id": "2509.05378v3",
      "title": "Code Like Humans: A Multi-Agent Solution for Medical Coding",
      "title_zh": "Code Like Humansï¼šé¢å‘åŒ»ç–—ç¼–ç çš„å¤šæ™ºèƒ½ä½“è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Andreas Motzfeldt",
        "Joakim Edin",
        "Casper L. Christensen",
        "Christian Hardmeier",
        "Lars MaalÃ¸e",
        "Anna Rogers"
      ],
      "abstract": "In medical coding, experts map unstructured clinical notes to alphanumeric codes for diagnoses and procedures. We introduce Code Like Humans: a new agentic framework for medical coding with large language models. It implements official coding guidelines for human experts, and it is the first solution that can support the full ICD-10 coding system (+70K labels). It achieves the best performance to date on rare diagnosis codes (fine-tuned discriminative classifiers retain an advantage for high-frequency codes, to which they are limited). Towards future work, we also contribute an analysis of system performance and identify its `blind spots' (codes that are systematically undercoded).",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Code Like Humansï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºåŒ»ç–—ç¼–ç è®¾è®¡çš„æ–°å‹å¤šæ™ºèƒ½ä½“æ¡†æ¶(agentic framework)ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å°†éç»“æ„åŒ–ä¸´åºŠè®°å½•å‡†ç¡®æ˜ å°„ä¸ºæ ‡å‡†çš„è¯Šæ–­å’Œæ‰‹æœ¯ä»£ç ã€‚è¯¥æ¡†æ¶é€šè¿‡å®æ–½é’ˆå¯¹äººç±»ä¸“å®¶çš„å®˜æ–¹ç¼–ç å‡†åˆ™ï¼Œæˆä¸ºäº†é¦–ä¸ªèƒ½å¤Ÿæ”¯æŒè¶…è¿‡7ä¸‡ä¸ªæ ‡ç­¾çš„å®Œæ•´ ICD-10 ç¼–ç ç³»ç»Ÿçš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†ç½•è§è¯Šæ–­ä»£ç æ–¹é¢å–å¾—äº†è¿„ä»Šä¸ºæ­¢çš„æœ€ä½³æ€§èƒ½ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†ä¼ ç»Ÿå¾®è°ƒåˆ¤åˆ«åˆ†ç±»å™¨ä»…åœ¨æœ‰é™é«˜é¢‘ä»£ç ä¸Šå…·æœ‰ä¼˜åŠ¿çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æ·±å…¥åˆ†æäº†ç³»ç»Ÿæ€§èƒ½å¹¶è¯†åˆ«äº†å…¶â€œç›²ç‚¹â€ï¼Œå³é‚£äº›è¢«ç³»ç»Ÿæ€§æ¬ ç¼–ç çš„ç‰¹å®šä»£ç ã€‚è¯¥å·¥ä½œä¸ä»…æ˜¾è‘—æå‡äº†è‡ªåŠ¨åŒ–åŒ»ç–—ç¼–ç çš„è¦†ç›–èŒƒå›´ï¼Œä¹Ÿä¸ºæœªæ¥è¿›ä¸€æ­¥ä¼˜åŒ–å¯æ‰©å±•ä¸”ç¬¦åˆå‡†åˆ™çš„æ™ºèƒ½åŒ»ç–—ç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP Findings 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.05378v3",
      "published_date": "2025-09-04 16:31:38 UTC",
      "updated_date": "2025-10-08 05:07:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:31:51.861419+00:00"
    },
    {
      "arxiv_id": "2509.04362v1",
      "title": "Parking Availability Prediction via Fusing Multi-Source Data with A Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer",
      "title_zh": "åŸºäºå¤šæºæ•°æ®èåˆä¸è‡ªç›‘ç£å­¦ä¹ å¢å¼ºæ—¶ç©ºåç½® Transformer çš„åœè½¦ä½å¯ç”¨æ€§é¢„æµ‹",
      "authors": [
        "Yin Huang",
        "Yongqi Dong",
        "Youhua Tang",
        "Li Li"
      ],
      "abstract": "The rapid growth of private car ownership has worsened the urban parking predicament, underscoring the need for accurate and effective parking availability prediction to support urban planning and management. To address key limitations in modeling spatio-temporal dependencies and exploiting multi-source data for parking availability prediction, this study proposes a novel approach with SST-iTransformer. The methodology leverages K-means clustering to establish parking cluster zones (PCZs), extracting and integrating traffic demand characteristics from various transportation modes (i.e., metro, bus, online ride-hailing, and taxi) associated with the targeted parking lots. Upgraded on vanilla iTransformer, SST-iTransformer integrates masking-reconstruction-based pretext tasks for self-supervised spatio-temporal representation learning, and features an innovative dual-branch attention mechanism: Series Attention captures long-term temporal dependencies via patching operations, while Channel Attention models cross-variate interactions through inverted dimensions. Extensive experiments using real-world data from Chengdu, China, demonstrate that SST-iTransformer outperforms baseline deep learning models (including Informer, Autoformer, Crossformer, and iTransformer), achieving state-of-the-art performance with the lowest mean squared error (MSE) and competitive mean absolute error (MAE). Comprehensive ablation studies quantitatively reveal the relative importance of different data sources: incorporating ride-hailing data provides the largest performance gains, followed by taxi, whereas fixed-route transit features (bus/metro) contribute marginally. Spatial correlation analysis further confirms that excluding historical data from correlated parking lots within PCZs leads to substantial performance degradation, underscoring the importance of modeling spatial dependencies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º SST-iTransformer çš„æ¨¡å‹ï¼Œé€šè¿‡èåˆå¤šæºäº¤é€šæ•°æ®æ¥æé«˜åŸå¸‚åœè½¦å¯ç”¨æ€§é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ K-means èšç±»å»ºç«‹åœè½¦ç°‡åŒº (PCZs)ï¼Œå¹¶æ•´åˆäº†åœ°é“ã€å…¬äº¤ã€ç½‘çº¦è½¦å’Œå‡ºç§Ÿè½¦ç­‰å¤šç§è¿è¾“æ¨¡å¼çš„éœ€æ±‚ç‰¹å¾ã€‚SST-iTransformer æ”¹è¿›äº† vanilla iTransformerï¼Œå¼•å…¥äº†åŸºäºæ©ç é‡å»º (masking-reconstruction) çš„è‡ªç›‘ç£æ—¶ç©ºè¡¨ç¤ºå­¦ä¹ ï¼Œå¹¶é‡‡ç”¨ Series Attention å’Œ Channel Attention åŒåˆ†æ”¯æ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰é•¿æœŸæ—¶é—´ä¾èµ–å’Œè·¨å˜é‡äº¤äº’ã€‚åœ¨æˆéƒ½å¸‚çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹çš„æ€§èƒ½ä¼˜äº Informerã€Autoformer å’Œ Crossformer ç­‰åŸºçº¿æ¨¡å‹ï¼Œè¾¾åˆ°äº† SOTA æ°´å¹³ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œç½‘çº¦è½¦æ•°æ®å¯¹æ€§èƒ½æå‡çš„è´¡çŒ®æœ€å¤§ï¼ŒåŒæ—¶å¼ºè°ƒäº†å»ºæ¨¡ PCZs å†…éƒ¨ç©ºé—´ç›¸å…³æ€§å¯¹äºå‡†ç¡®é¢„æµ‹çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 5 figures, under review for journal publication",
      "pdf_url": "https://arxiv.org/pdf/2509.04362v1",
      "published_date": "2025-09-04 16:22:29 UTC",
      "updated_date": "2025-09-04 16:22:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:31:56.465750+00:00"
    },
    {
      "arxiv_id": "2509.04357v1",
      "title": "PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation",
      "title_zh": "PARCOï¼šåŸºäºå¯¹æ¯”å®ä½“æ¶ˆæ­§çš„éŸ³ç´ å¢å¼ºé²æ£’ä¸Šä¸‹æ–‡è¯­éŸ³è¯†åˆ«",
      "authors": [
        "Jiajun He",
        "Naoki Sawada",
        "Koichi Miyazaki",
        "Tomoki Toda"
      ],
      "abstract": "Automatic speech recognition (ASR) systems struggle with domain-specific named entities, especially homophones. Contextual ASR improves recognition but often fails to capture fine-grained phoneme variations due to limited entity diversity. Moreover, prior methods treat entities as independent tokens, leading to incomplete multi-token biasing. To address these issues, we propose Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation (PARCO), which integrates phoneme-aware encoding, contrastive entity disambiguation, entity-level supervision, and hierarchical entity filtering. These components enhance phonetic discrimination, ensure complete entity retrieval, and reduce false positives under uncertainty. Experiments show that PARCO achieves CER of 4.22% on Chinese AISHELL-1 and WER of 11.14% on English DATA2 under 1,000 distractors, significantly outperforming baselines. PARCO also demonstrates robust gains on out-of-domain datasets like THCHS-30 and LibriSpeech.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PARCOï¼Œä¸€ç§é€šè¿‡å¯¹æ¯”å®ä½“æ¶ˆæ­§å¢å¼ºéŸ³ç´ çš„é²æ£’ä¸Šä¸‹æ–‡è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³è¯­éŸ³è¯†åˆ«åœ¨å¤„ç†é¢†åŸŸç‰¹å®šå‘½åå®ä½“ï¼ˆå°¤å…¶æ˜¯åŒéŸ³è¯ï¼‰æ—¶çš„ç²¾åº¦ç“¶é¢ˆï¼Œä»¥åŠå¤šæ ‡è®°å®ä½“åç½®ä¸å®Œæ•´çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿåˆ›æ–°æ€§åœ°é›†æˆäº†éŸ³ç´ æ„ŸçŸ¥ç¼–ç (phoneme-aware encoding)ã€å¯¹æ¯”å®ä½“æ¶ˆæ­§ã€å®ä½“çº§ç›‘ç£å’Œå±‚æ¬¡åŒ–å®ä½“è¿‡æ»¤ç­‰æŠ€æœ¯ï¼Œæ˜¾è‘—å¢å¼ºäº†éŸ³ç´ åŒºåˆ†åº¦å¹¶é™ä½äº†ä¸ç¡®å®šæ€§ä¸‹çš„è¯¯æŠ¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨åŒ…å«1000ä¸ªå¹²æ‰°é¡¹çš„æŒ‘æˆ˜åœºæ™¯ä¸‹ï¼ŒPARCOåœ¨ä¸­æ–‡AISHELL-1ä¸Šçš„å­—ç¬¦é”™è¯¯ç‡(CER)ä»…ä¸º4.22%ï¼Œåœ¨è‹±æ–‡DATA2ä¸Šçš„è¯é”™è¯¯ç‡(WER)ä¸º11.14%ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒPARCOåœ¨THCHS-30å’ŒLibriSpeechç­‰åŸŸå¤–æ•°æ®é›†ä¸Šäº¦å±•ç°å‡ºå¼ºåŠ²çš„é²æ£’æ€§å¢ç›Šï¼Œä¸ºæå‡å¤æ‚è¯­å¢ƒä¸‹çš„å®ä½“æ£€ç´¢ä¸è¯­éŸ³è¯†åˆ«å‡†ç¡®æ€§æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ASRU 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04357v1",
      "published_date": "2025-09-04 16:18:34 UTC",
      "updated_date": "2025-09-04 16:18:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:01.561496+00:00"
    },
    {
      "arxiv_id": "2509.04345v1",
      "title": "AUDETER: A Large-scale Dataset for Deepfake Audio Detection in Open Worlds",
      "title_zh": "AUDETERï¼šé¢å‘å¼€æ”¾ä¸–ç•ŒéŸ³é¢‘ä¼ªé€ æ£€æµ‹çš„å¤§è§„æ¨¡æ•°æ®é›†",
      "authors": [
        "Qizhou Wang",
        "Hanxun Huang",
        "Guansong Pang",
        "Sarah Erfani",
        "Christopher Leckie"
      ],
      "abstract": "Speech generation systems can produce remarkably realistic vocalisations that are often indistinguishable from human speech, posing significant authenticity challenges. Although numerous deepfake detection methods have been developed, their effectiveness in real-world environments remains unrealiable due to the domain shift between training and test samples arising from diverse human speech and fast evolving speech synthesis systems. This is not adequately addressed by current datasets, which lack real-world application challenges with diverse and up-to-date audios in both real and deep-fake categories. To fill this gap, we introduce AUDETER (AUdio DEepfake TEst Range), a large-scale, highly diverse deepfake audio dataset for comprehensive evaluation and robust development of generalised models for deepfake audio detection. It consists of over 4,500 hours of synthetic audio generated by 11 recent TTS models and 10 vocoders with a broad range of TTS/vocoder patterns, totalling 3 million audio clips, making it the largest deepfake audio dataset by scale. Through extensive experiments with AUDETER, we reveal that i) state-of-the-art (SOTA) methods trained on existing datasets struggle to generalise to novel deepfake audio samples and suffer from high false positive rates on unseen human voice, underscoring the need for a comprehensive dataset; and ii) these methods trained on AUDETER achieve highly generalised detection performance and significantly reduce detection error rate by 44.1% to 51.6%, achieving an error rate of only 4.17% on diverse cross-domain samples in the popular In-the-Wild dataset, paving the way for training generalist deepfake audio detectors. AUDETER is available on GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³ç”Ÿæˆç³»ç»Ÿå¼•å‘çš„çœŸå®æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº† AUDETER (AUdio DEepfake TEst Range)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¼€æ”¾ä¸–ç•Œæ·±åº¦ä¼ªé€ éŸ³é¢‘æ£€æµ‹çš„å¤§è§„æ¨¡é«˜å¤šæ ·æ€§æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«è¶…è¿‡ 4,500 å°æ—¶çš„åˆæˆéŸ³é¢‘ï¼Œæ¶µç›–äº† 11 ç§æœ€æ–°çš„ TTS æ¨¡å‹å’Œ 10 ç§ vocodersï¼Œæ€»è®¡ 300 ä¸‡ä¸ªéŸ³é¢‘å‰ªè¾‘ï¼Œæ˜¯ç›®å‰è§„æ¨¡æœ€å¤§çš„æ·±åº¦ä¼ªé€ éŸ³é¢‘æ•°æ®é›†ã€‚é€šè¿‡å¹¿æ³›å®éªŒï¼Œç ”ç©¶æ­ç¤ºäº†ç°æœ‰å…ˆè¿›æ–¹æ³• (SOTA) åœ¨é¢å¯¹æ–°å‹ä¼ªé€ æ ·æœ¬å’Œæœªè§è¿‡çš„çœŸäººè¯­éŸ³æ—¶æ³›åŒ–èƒ½åŠ›ä¸¥é‡ä¸è¶³çš„é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ AUDETER ä¸Šè®­ç»ƒçš„æ¨¡å‹è¡¨ç°å‡ºæé«˜çš„æ³›åŒ–æ€§èƒ½ï¼Œå°†æ£€æµ‹é”™è¯¯ç‡æ˜¾è‘—é™ä½äº† 44.1% è‡³ 51.6%ã€‚ç‰¹åˆ«æ˜¯åœ¨æµè¡Œçš„ In-the-Wild æ•°æ®é›†è·¨åŸŸæ ·æœ¬ä¸Šï¼Œè¯¥æ–¹æ³•å®ç°äº†ä»…ä¸º 4.17% çš„é”™è¯¯ç‡ï¼Œä¸ºå¼€å‘é€šç”¨çš„æ·±åº¦ä¼ªé€ éŸ³é¢‘æ£€æµ‹å™¨å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04345v1",
      "published_date": "2025-09-04 16:03:44 UTC",
      "updated_date": "2025-09-04 16:03:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:03.867646+00:00"
    },
    {
      "arxiv_id": "2509.04343v1",
      "title": "Psychologically Enhanced AI Agents",
      "title_zh": "å¿ƒç†å­¦å¢å¼ºå‹ AI æ™ºèƒ½ä½“",
      "authors": [
        "Maciej Besta",
        "Shriram Chandran",
        "Robert Gerstenberger",
        "Mathis Lindner",
        "Marcin Chrapek",
        "Sebastian Hermann Martschat",
        "Taraneh Ghandi",
        "Patrick Iff",
        "Hubert Niewiadomski",
        "Piotr Nyczyk",
        "JÃ¼rgen MÃ¼ller",
        "Torsten Hoefler"
      ],
      "abstract": "We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of Large Language Model (LLM) agents through psychologically grounded personality conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method primes agents with distinct personality archetypes via prompt engineering, enabling control over behavior along two foundational axes of human psychology, cognition and affect. We show that such personality priming yields consistent, interpretable behavioral biases across diverse tasks: emotionally expressive agents excel in narrative generation, while analytically primed agents adopt more stable strategies in game-theoretic settings. Our framework supports experimenting with structured multi-agent communication protocols and reveals that self-reflection prior to interaction improves cooperation and reasoning quality. To ensure trait persistence, we integrate the official 16Personalities test for automated verification. While our focus is on MBTI, we show that our approach generalizes seamlessly to other psychological frameworks such as Big Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior design, we establish a foundation for psychologically enhanced AI agents without any fine-tuning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MBTI-in-Thoughts æ¡†æ¶ï¼Œé€šè¿‡å¿ƒç†å­¦çš„äººæ ¼è°ƒèŠ‚(personality conditioning)æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“çš„æ•ˆèƒ½ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æç¤ºå·¥ç¨‹(prompt engineering)ä¸ºæ™ºèƒ½ä½“æ³¨å…¥ Myers-Briggs Type Indicator (MBTI) äººæ ¼åŸå‹ï¼Œå®ç°äº†å¯¹æ™ºèƒ½ä½“åœ¨è®¤çŸ¥(cognition)å’Œæƒ…æ„Ÿ(affect)è½´å‘ä¸Šçš„è¡Œä¸ºæ§åˆ¶ã€‚ç ”ç©¶è¡¨æ˜ï¼Œäººæ ¼å¼•å¯¼èƒ½åœ¨ä¸åŒä»»åŠ¡ä¸­äº§ç”Ÿä¸€è‡´ä¸”å¯è§£é‡Šçš„è¡Œä¸ºåå¥½ï¼Œä¾‹å¦‚æƒ…æ„Ÿè¡¨è¾¾å‹æ™ºèƒ½ä½“æ“…é•¿å™äº‹ç”Ÿæˆ(narrative generation)ï¼Œè€Œåˆ†æå‹æ™ºèƒ½ä½“åœ¨åšå¼ˆè®º(game-theoretic)åœºæ™¯ä¸‹è¡¨ç°æ›´ç¨³å¥ã€‚æ­¤å¤–ï¼Œæ¡†æ¶å‘ç°å¤šæ™ºèƒ½ä½“é€šä¿¡ä¸­çš„äº¤äº’å‰è‡ªæˆ‘åæ€(self-reflection)èƒ½æœ‰æ•ˆæå‡åä½œå’Œæ¨ç†è´¨é‡ã€‚ä¸ºç¡®ä¿äººæ ¼ç‰¹è´¨çš„æŒä¹…æ€§ï¼Œç ”ç©¶é›†æˆäº†å®˜æ–¹ 16Personalities æµ‹è¯•è¿›è¡Œè‡ªåŠ¨åŒ–éªŒè¯ï¼Œå¹¶è¯æ˜è¯¥æ–¹æ³•å¯æ— ç¼æ‰©å±•è‡³ Big Five æˆ– Enneagram ç­‰å…¶ä»–å¿ƒç†å­¦æ¡†æ¶ã€‚è¯¥ç ”ç©¶é€šè¿‡å°†å¿ƒç†å­¦ç†è®ºä¸è¡Œä¸ºè®¾è®¡ç›¸ç»“åˆï¼Œä¸ºæ„å»ºæ— éœ€å¾®è°ƒ(fine-tuning)çš„å¿ƒç†å¢å¼ºå‹ AI æ™ºèƒ½ä½“å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04343v1",
      "published_date": "2025-09-04 16:03:03 UTC",
      "updated_date": "2025-09-04 16:03:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:05.561430+00:00"
    },
    {
      "arxiv_id": "2509.04338v1",
      "title": "From Editor to Dense Geometry Estimator",
      "title_zh": "ä»ç¼–è¾‘æ¨¡å‹åˆ°ç¨ å¯†å‡ ä½•ä¼°è®¡å™¨",
      "authors": [
        "JiYuan Wang",
        "Chunyu Lin",
        "Lei Sun",
        "Rongying Liu",
        "Lang Nie",
        "Mingxing Li",
        "Kang Liao",
        "Xiangxiang Chu",
        "Yao Zhao"
      ],
      "abstract": "Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be a more suitable foundation for fine-tuning.\n  Motivated by this, we conduct a systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by ``refining\" their innate features, and ultimately achieve higher performance than their generative counterparts.\n  Based on these findings, we introduce \\textbf{FE2E}, a framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editor's original flow matching loss into the ``consistent velocity\" training objective. And we use logarithmic quantization to resolve the precision conflict between the editor's native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiT's global attention for a cost-free joint estimation of depth and normals in a single forward pass, enabling their supervisory signals to mutually enhance each other.\n  Without scaling up the training data, FE2E achieves impressive performance improvements in zero-shot monocular depth and normal estimation across multiple datasets. Notably, it achieves over 35\\% performance gains on the ETH3D dataset and outperforms the DepthAnything series, which is trained on 100$\\times$ data. The project page can be accessed \\href{https://amap-ml.github.io/FE2E/}{here}.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¨ å¯†å‡ ä½•é¢„æµ‹ä»»åŠ¡ä¸­å›¾åƒç¼–è¾‘æ¨¡å‹ç›¸è¾ƒäºæ–‡æœ¬ç”Ÿæˆå›¾åƒ(T2I)æ¨¡å‹çš„ä¼˜åŠ¿ï¼ŒæŒ‡å‡ºç¨ å¯†é¢„æµ‹æœ¬è´¨ä¸Šæ˜¯å›¾åƒåˆ°å›¾åƒ(image-to-image)ä»»åŠ¡ï¼Œç¼–è¾‘æ¨¡å‹å…·å¤‡æ›´å¼ºçš„å†…åœ¨ç»“æ„å…ˆéªŒã€‚åŸºäºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†FE2Eæ¡†æ¶ï¼Œé¦–æ¬¡å°†åŸºäºæ‰©æ•£Transformer(DiT)æ¶æ„çš„ç¼–è¾‘æ¨¡å‹åº”ç”¨äºç¨ å¯†å‡ ä½•é¢„æµ‹ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†åŸå§‹çš„æµåŒ¹é…æŸå¤±(flow matching loss)é‡æ„ä¸ºä¸€è‡´é€Ÿåº¦(consistent velocity)è®­ç»ƒç›®æ ‡ï¼Œå¹¶é‡‡ç”¨å¯¹æ•°åŒ–é‡åŒ–(logarithmic quantization)æŠ€æœ¯ï¼Œæœ‰æ•ˆè§£å†³äº†æ¨¡å‹æ ¼å¼ä¸é«˜ç²¾åº¦éœ€æ±‚ä¹‹é—´çš„å†²çªã€‚æ­¤å¤–ï¼ŒFE2Eåˆ©ç”¨DiTçš„å…¨å±€æ³¨æ„åŠ›æœºåˆ¶å®ç°äº†æ·±åº¦ä¸æ³•çº¿çš„è”åˆä¼°è®¡ï¼Œä½¿ä¸¤ç§ç›‘ç£ä¿¡å·åœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­äº’ä¸ºå¢å¼ºã€‚å®éªŒè¡¨æ˜ï¼ŒFE2Eåœ¨å¤šä¸ªæ•°æ®é›†çš„é›¶æ ·æœ¬(zero-shot)å•ç›®æ·±åº¦å’Œæ³•çº¿ä¼°è®¡ä¸­è¡¨ç°å“è¶Šï¼Œåœ¨ETH3Dæ•°æ®é›†ä¸Šå–å¾—äº†è¶…è¿‡35%çš„æ€§èƒ½æå‡ã€‚åœ¨æœªæ‰©å¤§è®­ç»ƒæ•°æ®è§„æ¨¡çš„æƒ…å†µä¸‹ï¼Œå…¶è¡¨ç°ç”šè‡³è¶…è¶Šäº†ä½¿ç”¨100å€è®­ç»ƒæ•°æ®çš„DepthAnythingç³»åˆ—æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20pages",
      "pdf_url": "https://arxiv.org/pdf/2509.04338v1",
      "published_date": "2025-09-04 15:58:50 UTC",
      "updated_date": "2025-09-04 15:58:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:06.867113+00:00"
    },
    {
      "arxiv_id": "2509.04337v1",
      "title": "Decoupled Entity Representation Learning for Pinterest Ads Ranking",
      "title_zh": "Pinterest å¹¿å‘Šæ’åºä¸­çš„è§£è€¦å®ä½“è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Jie Liu",
        "Yinrui Li",
        "Jiankai Sun",
        "Kungang Li",
        "Han Sun",
        "Sihan Wang",
        "Huasen Wu",
        "Siyuan Gao",
        "Paulo Soares",
        "Nan Li",
        "Zhifang Liu",
        "Haoyang Li",
        "Siping Ji",
        "Ling Leng",
        "Prathibha Deshikachar"
      ],
      "abstract": "In this paper, we introduce a novel framework following an upstream-downstream paradigm to construct user and item (Pin) embeddings from diverse data sources, which are essential for Pinterest to deliver personalized Pins and ads effectively. Our upstream models are trained on extensive data sources featuring varied signals, utilizing complex architectures to capture intricate relationships between users and Pins on Pinterest. To ensure scalability of the upstream models, entity embeddings are learned, and regularly refreshed, rather than real-time computation, allowing for asynchronous interaction between the upstream and downstream models. These embeddings are then integrated as input features in numerous downstream tasks, including ad retrieval and ranking models for CTR and CVR predictions. We demonstrate that our framework achieves notable performance improvements in both offline and online settings across various downstream tasks. This framework has been deployed in Pinterest's production ad ranking systems, resulting in significant gains in online metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºä¸Šä¸‹æ¸¸èŒƒå¼(upstream-downstream paradigm)çš„æ–°é¢–æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ„å»ºé«˜æ•ˆçš„ç”¨æˆ·å’Œé¡¹ç›®(Pin)åµŒå…¥å‘é‡æ¥ä¼˜åŒ– Pinterest çš„ä¸ªæ€§åŒ–å¹¿å‘Šæ¨èã€‚å…¶ä¸Šæ¸¸æ¨¡å‹(upstream models)åˆ©ç”¨å¤šæºæ•°æ®å’Œå¤æ‚æ¶æ„æ•æ‰ç”¨æˆ·ä¸ Pin ä¹‹é—´çš„æ·±åº¦å…³ç³»ã€‚ä¸ºäº†ä¿éšœç³»ç»Ÿçš„å¯æ‰©å±•æ€§ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†å®ä½“è¡¨ç¤ºå­¦ä¹ çš„è§£è€¦æœºåˆ¶(Decoupled Entity Representation Learning)ï¼Œé€šè¿‡å®šæœŸåˆ·æ–°åµŒå…¥å‘é‡å®ç°ä¸Šä¸‹æ¸¸çš„å¼‚æ­¥äº¤äº’ï¼Œé¿å…äº†å®æ—¶è®¡ç®—çš„å¼€é”€ã€‚è¿™äº›ç”Ÿæˆçš„åµŒå…¥å‘é‡è¢«ä½œä¸ºå…³é”®ç‰¹å¾é›†æˆåˆ°å¹¿å‘Šæ£€ç´¢ã€ç‚¹å‡»ç‡(CTR)é¢„æµ‹åŠè½¬åŒ–ç‡(CVR)é¢„æµ‹ç­‰å¤šä¸ªä¸‹æ¸¸æ’åºä»»åŠ¡ä¸­ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç¦»çº¿è¯„ä¼°å’Œåœ¨çº¿æµ‹è¯•ä¸­å‡è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ç›®å‰è¯¥æ–¹æ¡ˆå·²æˆåŠŸéƒ¨ç½²äº Pinterest çš„ç”Ÿäº§å¹¿å‘Šæ’åºç³»ç»Ÿï¼Œå¹¶ä¸ºåœ¨çº¿ä¸šåŠ¡æŒ‡æ ‡å¸¦æ¥äº†å®è´¨æ€§çš„å¢é•¿ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04337v1",
      "published_date": "2025-09-04 15:56:40 UTC",
      "updated_date": "2025-09-04 15:56:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:08.756051+00:00"
    },
    {
      "arxiv_id": "2509.04317v2",
      "title": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes",
      "title_zh": "æå‡ AlphaZero ç®—æ³•å¯¹æµ‹è¯•é˜¶æ®µç¯å¢ƒå˜åŒ–çš„é²æ£’æ€§",
      "authors": [
        "Isidoro Tamassia",
        "Wendelin BÃ¶hmer"
      ],
      "abstract": "The AlphaZero framework provides a standard way of combining Monte Carlo planning with prior knowledge provided by a previously trained policy-value neural network. AlphaZero usually assumes that the environment on which the neural network was trained will not change at test time, which constrains its applicability. In this paper, we analyze the problem of deploying AlphaZero agents in potentially changed test environments and demonstrate how the combination of simple modifications to the standard framework can significantly boost performance, even in settings with a low planning budget available. The code is publicly available on GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•æé«˜ AlphaZero ç®—æ³•åœ¨æµ‹è¯•æ—¶é¢å¯¹ç¯å¢ƒå˜åŒ–æ—¶çš„ç¨³å¥æ€§ï¼ˆRobustnessï¼‰ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ¡†æ¶å‡è®¾è®­ç»ƒä¸æµ‹è¯•ç¯å¢ƒä¸€è‡´æ‰€å¯¼è‡´çš„é€‚ç”¨æ€§å±€é™ã€‚æ–‡ç« æ·±å…¥åˆ†æäº†å°† AlphaZero ä»£ç†éƒ¨ç½²åˆ°æ½œåœ¨å˜åŒ–çš„æµ‹è¯•ç¯å¢ƒä¸­æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ç³»åˆ—é’ˆå¯¹æ ‡å‡†æ¡†æ¶çš„ç®€å•ä¿®æ”¹ï¼ˆModificationsï¼‰ã€‚è¿™äº›æ”¹è¿›æ˜¾è‘—æå‡äº†ç®—æ³•åœ¨ç¯å¢ƒå˜åŠ¨ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼Œä¸”å³ä½¿åœ¨è§„åˆ’é¢„ç®—ï¼ˆPlanning budgetï¼‰è¾ƒä½çš„æƒ…å†µä¸‹ä¾ç„¶æœ‰æ•ˆã€‚è¯¥ç ”ç©¶ä¸ºå¼ºåŒ–å­¦ä¹ æ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„åº”ç”¨æä¾›äº†å®ç”¨æ–¹æ¡ˆï¼Œç›¸å…³ä»£ç å·²åœ¨ GitHub ä¸Šå…¬å¼€å‘å¸ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the 37th Benelux Conference on Artificial Intelligence and the 34th Belgian Dutch Conference on Machine Learning (BNAIC/BeNeLearn 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.04317v2",
      "published_date": "2025-09-04 15:38:37 UTC",
      "updated_date": "2025-10-29 11:06:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:26.252832+00:00"
    },
    {
      "arxiv_id": "2509.04310v3",
      "title": "EvoEmo: Towards Evolved Emotional Policies for Adversarial LLM Agents in Multi-Turn Price Negotiation",
      "title_zh": "EvoEmoï¼šé¢å‘å¤šè½®ä»·æ ¼è°ˆåˆ¤ä¸­å¯¹æŠ—æ€§å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“çš„æ¼”åŒ–æƒ…æ„Ÿç­–ç•¥",
      "authors": [
        "Yunbo Long",
        "Liming Xu",
        "Lukas Beckenbauer",
        "Yuhan Liu",
        "Alexandra Brintrup"
      ],
      "abstract": "Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs) has demonstrated that agents can engage in \\textit{complex}, \\textit{multi-turn} negotiations, opening new avenues for agentic AI. However, existing LLM agents largely overlook the functional role of emotions in such negotiations, instead generating passive, preference-driven emotional responses that make them vulnerable to manipulation and strategic exploitation by adversarial counterparts. To address this gap, we present EvoEmo, an evolutionary reinforcement learning framework that optimizes dynamic emotional expression in negotiations. EvoEmo models emotional state transitions as a Markov Decision Process and employs population-based genetic optimization to evolve high-reward emotion policies across diverse negotiation scenarios. We further propose an evaluation framework with two baselines -- vanilla strategies and fixed-emotion strategies -- for benchmarking emotion-aware negotiation. Extensive experiments and ablation studies show that EvoEmo consistently outperforms both baselines, achieving higher success rates, higher efficiency, and increased buyer savings. This findings highlight the importance of adaptive emotional expression in enabling more effective LLM agents for multi-turn negotiation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹LLMæ™ºèƒ½ä½“åœ¨å¤šè½®ä»·æ ¼è°ˆåˆ¤ä¸­å› å¿½è§†æƒ…ç»ªåŠŸèƒ½è€Œæ˜“å—æ“çºµçš„é—®é¢˜ï¼Œæå‡ºäº†EvoEmoæ¡†æ¶ã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäºè¿›åŒ–å¼ºåŒ–å­¦ä¹ (Evolutionary Reinforcement Learning)çš„ç³»ç»Ÿï¼Œæ—¨åœ¨ä¼˜åŒ–æ™ºèƒ½ä½“åœ¨è°ˆåˆ¤è¿‡ç¨‹ä¸­çš„åŠ¨æ€æƒ…ç»ªè¡¨è¾¾ã€‚EvoEmoå°†æƒ…ç»ªçŠ¶æ€è½¬ç§»å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Markov Decision Process)ï¼Œå¹¶é‡‡ç”¨åŸºäºç§ç¾¤çš„é—ä¼ ç®—æ³•(Population-based Genetic Optimization)åœ¨å¤šç§åœºæ™¯ä¸‹è¿›åŒ–å‡ºé«˜å¥–åŠ±çš„æƒ…ç»ªç­–ç•¥ã€‚ç ”ç©¶äººå‘˜è¿˜æ„å»ºäº†ä¸€ä¸ªåŒ…å«åŸºå‡†ç­–ç•¥(Vanilla Strategies)å’Œå›ºå®šæƒ…ç»ªç­–ç•¥(Fixed-emotion Strategies)çš„è¯„ä¼°æ¡†æ¶è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEvoEmoåœ¨æˆäº¤æˆåŠŸç‡ã€æ²Ÿé€šæ•ˆç‡åŠä¹°å®¶èŠ‚çœé¢åº¦ç­‰æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†è‡ªé€‚åº”æƒ…ç»ªè¡¨è¾¾åœ¨æå‡LLMæ™ºèƒ½ä½“å¤„ç†å¤æ‚å¤šè½®è°ˆåˆ¤ä»»åŠ¡æ—¶çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04310v3",
      "published_date": "2025-09-04 15:23:58 UTC",
      "updated_date": "2025-10-13 16:04:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:24.860542+00:00"
    },
    {
      "arxiv_id": "2509.04304v1",
      "title": "Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models",
      "title_zh": "äº‹å®æ˜“é€ï¼šè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹å¯¹è¿‡æ—¶åŒ»å­¦çŸ¥è¯†çš„è®°å¿†",
      "authors": [
        "Juraj Vladika",
        "Mahdi Dhaini",
        "Florian Matthes"
      ],
      "abstract": "The growing capabilities of Large Language Models (LLMs) show significant potential to enhance healthcare by assisting medical researchers and physicians. However, their reliance on static training data is a major risk when medical recommendations evolve with new research and developments. When LLMs memorize outdated medical knowledge, they can provide harmful advice or fail at clinical reasoning tasks. To investigate this problem, we introduce two novel question-answering (QA) datasets derived from systematic reviews: MedRevQA (16,501 QA pairs covering general biomedical knowledge) and MedChangeQA (a subset of 512 QA pairs where medical consensus has changed over time). Our evaluation of eight prominent LLMs on the datasets reveals consistent reliance on outdated knowledge across all models. We additionally analyze the influence of obsolete pre-training data and training strategies to explain this phenomenon and propose future directions for mitigation, laying the groundwork for developing more current and reliable medical AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ä¾èµ–é™æ€è®­ç»ƒæ•°æ®å¯¼è‡´åŒ»å­¦çŸ¥è¯†æ»åçš„é£é™©ï¼Œæ¢è®¨äº†æ¨¡å‹è®°å¿†è¿‡æ—¶çŸ¥è¯†å¯¹ä¸´åºŠæ¨ç†å’ŒåŒ»ç–—å»ºè®®å¯èƒ½äº§ç”Ÿçš„å±å®³ã€‚ç ”ç©¶è€…å‘å¸ƒäº†ä¸¤ä¸ªå…¨æ–°çš„é—®ç­”æ•°æ®é›†ï¼šMedRevQA å’Œä¸“é—¨åŒ…å«åŒ»å­¦å…±è¯†æ¼”å˜æ ·æœ¬çš„ MedChangeQAï¼Œç”¨äºé‡åŒ–è¯„ä¼°æ¨¡å‹çš„çŸ¥è¯†æ›´æ–°èƒ½åŠ›ã€‚å®éªŒå¯¹å…«ç§ä¸»æµ LLMs è¿›è¡Œæµ‹è¯•ï¼Œç»“æœæ˜¾ç¤ºè¿™äº›æ¨¡å‹æ™®éè¡¨ç°å‡ºå¯¹é™ˆæ—§åŒ»å­¦çŸ¥è¯†çš„ä¸¥é‡ä¾èµ–ã€‚è®ºæ–‡è¿›ä¸€æ­¥åˆ†æäº†é¢„è®­ç»ƒæ•°æ® (pre-training data) åŠè®­ç»ƒç­–ç•¥å¯¹è¯¥ç°è±¡çš„å½±å“ï¼Œå¹¶æå‡ºäº†æ—¨åœ¨æå‡æ¨¡å‹æ—¶æ•ˆæ€§çš„ç¼“è§£æ–¹æ¡ˆã€‚è¯¥å·¥ä½œä¸ºå¼€å‘æ›´å…·å¯é æ€§å’Œå®æ—¶æ€§çš„åŒ»ç–—äººå·¥æ™ºèƒ½ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ï¼Œå¼ºè°ƒäº†åœ¨åŠ¨æ€åŒ»å­¦é¢†åŸŸæŒç»­æ›´æ–°æ¨¡å‹çŸ¥è¯†çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04304v1",
      "published_date": "2025-09-04 15:17:50 UTC",
      "updated_date": "2025-09-04 15:17:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:31.295021+00:00"
    },
    {
      "arxiv_id": "2509.04303v2",
      "title": "HumAIne-Chatbot: Real-Time Personalized Conversational AI via Reinforcement Learning",
      "title_zh": "HumAIne-Chatbotï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„å®æ—¶ä¸ªæ€§åŒ–å¯¹è¯å¼äººå·¥æ™ºèƒ½",
      "authors": [
        "Georgios Makridis",
        "George Fragiadakis",
        "Jorge Oliveira",
        "Tomaz Saraiva",
        "Philip Mavrepis",
        "Georgios Fatouros",
        "Dimosthenis Kyriazis"
      ],
      "abstract": "Current conversational AI systems often provide generic, one-size-fits-all interactions that overlook individual user characteristics and lack adaptive dialogue management. To address this gap, we introduce \\textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes responses through a novel user profiling framework. The system is pre-trained on a diverse set of GPT-generated virtual personas to establish a broad prior over user types. During live interactions, an online reinforcement learning agent refines per-user models by combining implicit signals (e.g. typing speed, sentiment, engagement duration) with explicit feedback (e.g., likes and dislikes). This profile dynamically informs the chatbot dialogue policy, enabling real-time adaptation of both content and style. To evaluate the system, we performed controlled experiments with 50 synthetic personas in multiple conversation domains. The results showed consistent improvements in user satisfaction, personalization accuracy, and task achievement when personalization features were enabled. Statistical analysis confirmed significant differences between personalized and nonpersonalized conditions, with large effect sizes across key metrics. These findings highlight the effectiveness of AI-driven user profiling and provide a strong foundation for future real-world validation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HumAIne-chatbotï¼Œæ—¨åœ¨é€šè¿‡ä¸€ç§æ–°å‹çš„User profilingæ¡†æ¶è§£å†³å½“å‰å¯¹è¯AIäº¤äº’æ¨¡å¼å•ä¸€ä¸”ç¼ºä¹è‡ªé€‚åº”Dialogue managementçš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿé¦–å…ˆåœ¨ç”±GPTç”Ÿæˆçš„å¤šç§è™šæ‹ŸPersonasä¸Šè¿›è¡Œé¢„è®­ç»ƒä»¥è·å–å¹¿æ³›çš„ç”¨æˆ·å…ˆéªŒçŸ¥è¯†ï¼Œéšååœ¨å®æ—¶äº¤äº’ä¸­åˆ©ç”¨åœ¨çº¿Reinforcement LearningæŠ€æœ¯ï¼Œç»“åˆæ‰“å­—é€Ÿåº¦ã€æƒ…æ„ŸåŠå‚ä¸æ—¶é•¿ç­‰Implicit signalsä¸æ˜¾å¼åé¦ˆæ¥æŒç»­ç²¾ç»†åŒ–ç”¨æˆ·æ¨¡å‹ã€‚è¿™ç§ç”»åƒæœºåˆ¶èƒ½å¤ŸåŠ¨æ€æŒ‡å¯¼Dialogue policyï¼Œä»è€Œå®ç°äº¤äº’å†…å®¹ä¸é£æ ¼çš„å®æ—¶é€‚é…ã€‚é€šè¿‡å¯¹50ä¸ªåˆæˆPersonasè¿›è¡Œçš„å—æ§å®éªŒæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨ç”¨æˆ·æ»¡æ„åº¦ã€ä¸ªæ€§åŒ–å‡†ç¡®æ€§åŠä»»åŠ¡è¾¾æˆåº¦æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚ç»Ÿè®¡åˆ†æè¯å®äº†ä¸ªæ€§åŒ–ç‰¹å¾å¸¦æ¥çš„æ˜¾è‘—ä¼˜è¶Šæ€§ï¼Œä¸ºæœªæ¥åœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²AIé©±åŠ¨çš„ä¸ªæ€§åŒ–å¯¹è¯ä»£ç†å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 4 figures, IEEE conference format",
      "pdf_url": "https://arxiv.org/pdf/2509.04303v2",
      "published_date": "2025-09-04 15:16:38 UTC",
      "updated_date": "2025-09-24 04:51:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:48.684138+00:00"
    },
    {
      "arxiv_id": "2509.10526v1",
      "title": "Resource-Aware Neural Network Pruning Using Graph-based Reinforcement Learning",
      "title_zh": "åŸºäºå›¾å¼ºåŒ–å­¦ä¹ çš„èµ„æºæ„ŸçŸ¥å‹ç¥ç»ç½‘ç»œå‰ªæ",
      "authors": [
        "Dieter Balemans",
        "Thomas Huybrechts",
        "Jan Steckel",
        "Siegfried Mercelis"
      ],
      "abstract": "This paper presents a novel approach to neural network pruning by integrating a graph-based observation space into an AutoML framework to address the limitations of existing methods. Traditional pruning approaches often depend on hand-crafted heuristics and local optimization perspectives, which can lead to suboptimal performance and inefficient pruning strategies. Our framework transforms the pruning process by introducing a graph representation of the target neural network that captures complete topological relationships between layers and channels, replacing the limited layer-wise observation space with a global view of network structure. The core innovations include a Graph Attention Network (GAT) encoder that processes the network's graph representation and generates a rich embedding. Additionally, for the action space we transition from continuous pruning ratios to fine-grained binary action spaces which enables the agent to learn optimal channel importance criteria directly from data, moving away from predefined scoring functions. These contributions are modelled within a Constrained Markov Decision Process (CMDP) framework, allowing the agent to make informed pruning decisions while adhering to resource constraints such as target compression rates. For this, we design a self-competition reward system that encourages the agent to outperform its previous best performance while satisfying the defined constraints. We demonstrate the effectiveness of our approach through extensive experiments on benchmark datasets including CIFAR-10, CIFAR-100, and ImageNet. The experiments show that our method consistently outperforms traditional pruning techniques, showing state-of-the-art results while learning task-specific pruning strategies that identify functionally redundant connections beyond simple weight magnitude considerations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå›¾å¼ºåŒ–å­¦ä¹ (Graph-based Reinforcement Learning)çš„èµ„æºæ„ŸçŸ¥ç¥ç»ç½‘ç»œå‰ªææ–¹æ³•ï¼Œæ—¨åœ¨å…‹æœä¼ ç»Ÿæ–¹æ³•ä¾èµ–äººå·¥å¯å‘å¼è§„åˆ™å’Œå±€éƒ¨ä¼˜åŒ–çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡æ„å»ºç¥ç»ç½‘ç»œçš„å›¾è¡¨ç¤º(Graph representation)å¹¶åˆ©ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œ(GAT)ç¼–ç å™¨ï¼Œå®ç°äº†å¯¹ç½‘ç»œç»“æ„å…¨å±€æ‹“æ‰‘å…³ç³»çš„æ•è·ã€‚é€šè¿‡åœ¨å—é™é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(CMDP)ä¸­å¼•å…¥ç»†ç²’åº¦çš„äºŒè¿›åˆ¶åŠ¨ä½œç©ºé—´å’Œè‡ªæˆ‘ç«äº‰å¥–åŠ±ç³»ç»Ÿï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿç›´æ¥ä»æ•°æ®ä¸­å­¦ä¹ æœ€ä¼˜çš„é€šé“å‰ªæç­–ç•¥ã€‚å®éªŒåœ¨CIFAR-10ã€CIFAR-100å’ŒImageNetç­‰åŸºå‡†æ•°æ®é›†ä¸Šè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç»“æœæ˜¾ç¤ºå…¶åœ¨æ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿå‰ªææŠ€æœ¯ï¼Œè¾¾åˆ°äº†SOTAæ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜èƒ½è¯†åˆ«å‡ºè¶…è¶Šæƒé‡æ•°å€¼ä¹‹å¤–çš„åŠŸèƒ½å†—ä½™è¿æ¥ï¼Œä¸ºé«˜æ•ˆã€è‡ªåŠ¨åŒ–çš„æ¨¡å‹å‹ç¼©æä¾›äº†æ–°çš„è§£å†³æ€è·¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10526v1",
      "published_date": "2025-09-04 15:05:05 UTC",
      "updated_date": "2025-09-04 15:05:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:40.688516+00:00"
    },
    {
      "arxiv_id": "2509.04288v2",
      "title": "Reinforcement Learning for Robust Ageing-Aware Control of Li-ion Battery Systems with Data-Driven Formal Verification",
      "title_zh": "åŸºäºæ•°æ®é©±åŠ¨å½¢å¼åŒ–éªŒè¯çš„é”‚ç¦»å­ç”µæ± ç³»ç»Ÿé²æ£’è€åŒ–æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ æ§åˆ¶",
      "authors": [
        "Rudi Coppola",
        "Hovsep Touloujian",
        "Pierfrancesco Ombrini",
        "Manuel Mazo"
      ],
      "abstract": "Rechargeable lithium-ion (Li-ion) batteries are a ubiquitous element of modern technology. In the last decades, the production and design of such batteries and their adjacent embedded charging and safety protocols, denoted by Battery Management Systems (BMS), has taken central stage. A fundamental challenge to be addressed is the trade-off between the speed of charging and the ageing behavior, resulting in the loss of capacity in the battery cell. We rely on a high-fidelity physics-based battery model and propose an approach to data-driven charging and safety protocol design. Following a Counterexample-Guided Inductive Synthesis scheme, we combine Reinforcement Learning (RL) with recent developments in data-driven formal methods to obtain a hybrid control strategy: RL is used to synthesise the individual controllers, and a data-driven abstraction guides their partitioning into a switched structure, depending on the initial output measurements of the battery. The resulting discrete selection among RL-based controllers, coupled with the continuous battery dynamics, realises a hybrid system. When a design meets the desired criteria, the abstraction provides probabilistic guarantees on the closed-loop performance of the cell.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹é”‚ç¦»å­ç”µæ±  (Li-ion batteries) å……ç”µé€Ÿåº¦ä¸å®¹é‡è¡°å‡çš„è€åŒ– (ageing) æƒè¡¡æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ•°æ®é©±åŠ¨çš„å……ç”µä¸å®‰å…¨åè®®è®¾è®¡æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŸºäºé«˜ä¿çœŸç‰©ç†ç”µæ± æ¨¡å‹ï¼Œé‡‡ç”¨åä¾‹è¯±å¯¼å½’çº³åˆæˆ (Counterexample-Guided Inductive Synthesis) æ–¹æ¡ˆï¼Œå°†å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) ä¸æœ€æ–°çš„æ•°æ®é©±åŠ¨å½¢å¼åŒ–æ–¹æ³• (formal methods) ç›¸ç»“åˆã€‚ç ”ç©¶åˆ©ç”¨ RL åˆæˆå•ä¸ªæ§åˆ¶å™¨ï¼Œå¹¶é€šè¿‡æ•°æ®é©±åŠ¨çš„æŠ½è±¡æŠ€æœ¯å¼•å¯¼å…¶æ ¹æ®åˆå§‹æµ‹é‡å€¼åˆ’åˆ†ä¸ºåˆ‡æ¢ç»“æ„ï¼Œä»è€Œæ„å»ºå‡ºä¸€ç§é€‚ç”¨äº Battery Management Systems (BMS) çš„æ··åˆæ§åˆ¶ç­–ç•¥ (hybrid control strategy)ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§ç»“åˆäº†ç¦»æ•£é€‰æ‹©ä¸è¿ç»­ç”µæ± åŠ¨åŠ›å­¦çš„æ··åˆç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆå®ç°é²æ£’çš„è€åŒ–æ„ŸçŸ¥æ§åˆ¶ã€‚æœ€ç»ˆï¼Œè¯¥æ–¹æ³•é€šè¿‡æ•°æ®é©±åŠ¨çš„æŠ½è±¡ä¸ºç”µæ± çš„é—­ç¯æ€§èƒ½æä¾›äº†æ¦‚ç‡ä¿è¯ (probabilistic guarantees)ï¼Œä¸ºå…¼é¡¾å……ç”µæ•ˆç‡ä¸ç”µæ± å¯¿å‘½çš„æ§åˆ¶æŠ€æœ¯æä¾›äº†ç†è®ºæ”¯æŒã€‚",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04288v2",
      "published_date": "2025-09-04 15:01:03 UTC",
      "updated_date": "2025-09-06 20:36:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:47.190742+00:00"
    },
    {
      "arxiv_id": "2509.04260v1",
      "title": "An Empirical Study of Vulnerabilities in Python Packages and Their Detection",
      "title_zh": "Python è½¯ä»¶åŒ…æ¼æ´åŠå…¶æ£€æµ‹çš„å®è¯ç ”ç©¶",
      "authors": [
        "Haowei Quan",
        "Junjie Wang",
        "Xinzhe Li",
        "Terry Yue Zhuo",
        "Xiao Chen",
        "Xiaoning Du"
      ],
      "abstract": "In the rapidly evolving software development landscape, Python stands out for its simplicity, versatility, and extensive ecosystem. Python packages, as units of organization, reusability, and distribution, have become a pressing concern, highlighted by the considerable number of vulnerability reports. As a scripting language, Python often cooperates with other languages for performance or interoperability. This adds complexity to the vulnerabilities inherent to Python packages, and the effectiveness of current vulnerability detection tools remains underexplored. This paper addresses these gaps by introducing PyVul, the first comprehensive benchmark suite of Python-package vulnerabilities. PyVul includes 1,157 publicly reported, developer-verified vulnerabilities, each linked to its affected packages. To accommodate diverse detection techniques, it provides annotations at both commit and function levels. An LLM-assisted data cleansing method is incorporated to improve label accuracy, achieving 100% commit-level and 94% function-level accuracy, establishing PyVul as the most precise large-scale Python vulnerability benchmark. We further carry out a distribution analysis of PyVul, which demonstrates that vulnerabilities in Python packages involve multiple programming languages and exhibit a wide variety of types. Moreover, our analysis reveals that multi-lingual Python packages are potentially more susceptible to vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark reveals a significant discrepancy between the capabilities of existing tools and the demands of effectively identifying real-world security issues in Python packages. Additionally, we conduct an empirical review of the top-ranked CWEs observed in Python packages, to diagnose the fine-grained limitations of current detection tools and highlight the necessity for future advancements in the field.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Python åŒ…ä¸­æ—¥ç›Šä¸¥é‡çš„æ¼æ´é—®é¢˜åŠæ£€æµ‹æ‰‹æ®µçš„æœ‰æ•ˆæ€§è¿›è¡Œäº†æ·±å…¥å®è¯ç ”ç©¶ï¼Œæ—¨åœ¨å¡«è¡¥è¯¥é¢†åŸŸçš„è®¤çŸ¥ç©ºç™½ã€‚ç ”ç©¶è€…æ¨å‡ºäº†é¦–ä¸ªå…¨é¢çš„ Python åŒ…æ¼æ´åŸºå‡†æµ‹è¯•é›† PyVulï¼Œå…¶ä¸­åŒ…å« 1,157 ä¸ªç»å¼€å‘è€…éªŒè¯çš„æ¼æ´ï¼Œå¹¶æä¾› commit å’Œ function çº§åˆ«çš„ç»†ç²’åº¦æ ‡æ³¨ã€‚é€šè¿‡å¼•å…¥ LLM-assisted æ•°æ®æ¸…æ´—æ–¹æ³•ï¼ŒPyVul åœ¨æ ‡ç­¾å‡†ç¡®æ€§ä¸Šè¾¾åˆ°äº†æé«˜æ°´å¹³ï¼Œæˆä¸ºç›®å‰æœ€ç²¾ç¡®çš„å¤§è§„æ¨¡ Python æ¼æ´åŸºå‡†ã€‚åˆ†å¸ƒåˆ†æè¡¨æ˜ Python åŒ…æ¼æ´æ¶‰åŠå¤šç§ç¼–ç¨‹è¯­è¨€ä¸”ç±»å‹å¹¿æ³›ï¼Œä¸”å¤šè¯­è¨€ Python åŒ… (multi-lingual Python packages) åœ¨å®‰å…¨ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„è„†å¼±æ€§ã€‚é€šè¿‡å¯¹ç°æœ‰æœ€å…ˆè¿›æ£€æµ‹å™¨çš„è¯„ä¼°ï¼Œç ”ç©¶æ­ç¤ºäº†å½“å‰å·¥å…·åœ¨å¤„ç†çœŸå®ä¸–ç•Œå®‰å…¨æŒ‘æˆ˜æ—¶çš„èƒ½åŠ›ä¸è¶³ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯¹æ’åé å‰çš„ CWEs è¿›è¡Œäº†å®è¯å›é¡¾ï¼Œæ˜ç¡®äº†ç°æœ‰æ£€æµ‹æŠ€æœ¯çš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥è¯¥é¢†åŸŸçš„å‘å±•æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04260v1",
      "published_date": "2025-09-04 14:38:28 UTC",
      "updated_date": "2025-09-04 14:38:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:42.986431+00:00"
    },
    {
      "arxiv_id": "2509.09700v1",
      "title": "Cross-Layer Attention Probing for Fine-Grained Hallucination Detection",
      "title_zh": "ç”¨äºç»†ç²’åº¦å¹»è§‰æ£€æµ‹çš„è·¨å±‚æ³¨æ„åŠ›æ¢æµ‹",
      "authors": [
        "Malavika Suresh",
        "Rahaf Aljundi",
        "Ikechukwu Nkisi-Orji",
        "Nirmalie Wiratunga"
      ],
      "abstract": "With the large-scale adoption of Large Language Models (LLMs) in various applications, there is a growing reliability concern due to their tendency to generate inaccurate text, i.e. hallucinations. In this work, we propose Cross-Layer Attention Probing (CLAP), a novel activation probing technique for hallucination detection, which processes the LLM activations across the entire residual stream as a joint sequence. Our empirical evaluations using five LLMs and three tasks show that CLAP improves hallucination detection compared to baselines on both greedy decoded responses as well as responses sampled at higher temperatures, thus enabling fine-grained detection, i.e. the ability to disambiguate hallucinations and non-hallucinations among different sampled responses to a given prompt. This allows us to propose a detect-then-mitigate strategy using CLAP to reduce hallucinations and improve LLM reliability compared to direct mitigation approaches. Finally, we show that CLAP maintains high reliability even when applied out-of-distribution.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨åº”ç”¨ä¸­äº§ç”Ÿçš„å¹»è§‰ (hallucinations) é—®é¢˜ï¼Œæå‡ºäº† Cross-Layer Attention Probing (CLAP)ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¹»è§‰æ£€æµ‹çš„æ–°å‹æ¿€æ´»æ¢æµ‹æŠ€æœ¯ã€‚è¯¥æ–¹æ³•é€šè¿‡å°† LLM æ•´ä¸ªæ®‹å·®æµ (residual stream) çš„æ¿€æ´»ä½œä¸ºè”åˆåºåˆ—è¿›è¡Œå¤„ç†ï¼Œå®ç°äº†å¯¹å†…éƒ¨çŠ¶æ€çš„æ·±åº¦åˆ†æã€‚å®éªŒè¡¨æ˜ï¼ŒCLAP åœ¨äº”ç§ LLMs å’Œä¸‰é¡¹ä»»åŠ¡ä¸­å‡æ˜¾è‘—æå‡äº†å¹»è§‰æ£€æµ‹çš„å‡†ç¡®æ€§ï¼Œæ— è®ºæ˜¯è´ªå©ªè§£ç è¿˜æ˜¯é«˜é‡‡æ ·æ¸©åº¦ä¸‹çš„å“åº”ã€‚è¿™ç§ç»†ç²’åº¦çš„æ£€æµ‹èƒ½åŠ›ä½¿å¾— CLAP èƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†ä¸åŒé‡‡æ ·å“åº”ä¸­çš„é”™è¯¯å†…å®¹ï¼Œè¿›è€Œæ”¯æŒä¸€ç§â€œå…ˆæ£€æµ‹åç¼“è§£â€ (detect-then-mitigate) çš„ç­–ç•¥ä»¥æé«˜æ¨¡å‹å¯é æ€§ã€‚æ­¤å¤–ï¼ŒCLAP åœ¨åˆ†å¸ƒå¤– (out-of-distribution) åœºæ™¯ä¸‹ä¾ç„¶ä¿æŒäº†æé«˜çš„æ¢æµ‹æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ³›åŒ–æ½œåŠ›å’Œç¨³å¥æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published at the TRUST-AI workshop, ECAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.09700v1",
      "published_date": "2025-09-04 14:37:34 UTC",
      "updated_date": "2025-09-04 14:37:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:47.359908+00:00"
    },
    {
      "arxiv_id": "2509.04250v2",
      "title": "How many patients could we save with LLM priors?",
      "title_zh": "åˆ©ç”¨ LLM å…ˆéªŒèƒ½ä¸ºä¸´åºŠè¯•éªŒèŠ‚çœå¤šå°‘æ‚£è€…ï¼Ÿ",
      "authors": [
        "Shota Arai",
        "David Selby",
        "Andrew Vargo",
        "Sebastian Vollmer"
      ],
      "abstract": "Imagine a world where clinical trials need far fewer patients to achieve the same statistical power, thanks to the knowledge encoded in large language models (LLMs). We present a novel framework for hierarchical Bayesian modeling of adverse events in multi-center clinical trials, leveraging LLM-informed prior distributions. Unlike data augmentation approaches that generate synthetic data points, our methodology directly obtains parametric priors from the model. Our approach systematically elicits informative priors for hyperparameters in hierarchical Bayesian models using a pre-trained LLM, enabling the incorporation of external clinical expertise directly into Bayesian safety modeling. Through comprehensive temperature sensitivity analysis and rigorous cross-validation on real-world clinical trial data, we demonstrate that LLM-derived priors consistently improve predictive performance compared to traditional meta-analytical approaches. This methodology paves the way for more efficient and expert-informed clinical trial design, enabling substantial reductions in the number of patients required to achieve robust safety assessment and with the potential to transform drug safety monitoring and regulatory decision making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆçš„å…ˆéªŒçŸ¥è¯†æ¥ä¼˜åŒ–å¤šä¸­å¿ƒä¸´åºŠè¯•éªŒä¸­ä¸è‰¯äº‹ä»¶åˆ†å±‚è´å¶æ–¯å»ºæ¨¡(hierarchical Bayesian modeling)çš„æ–°æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„ç”Ÿæˆåˆæˆæ•°æ®çš„æ•°æ®å¢å¼ºæ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•ç›´æ¥ä»é¢„è®­ç»ƒçš„ LLM ä¸­è·å–å‚æ•°åŒ–å…ˆéªŒ(parametric priors)ï¼Œä»è€Œå°†å¤–éƒ¨ä¸´åºŠä¸“å®¶çŸ¥è¯†ç›´æ¥æ•´åˆåˆ°è´å¶æ–¯å®‰å…¨æ€§å»ºæ¨¡ä¸­ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡è¯¦å°½çš„æ¸©åº¦æ•æ„Ÿæ€§åˆ†æä»¥åŠåœ¨çœŸå®ä¸´åºŠè¯•éªŒæ•°æ®ä¸Šçš„äº¤å‰éªŒè¯ï¼Œè¯æ˜äº†åŸºäº LLM çš„å…ˆéªŒä¸ä¼ ç»Ÿçš„å…ƒåˆ†æ(meta-analytical)æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿä¸€è‡´åœ°æå‡é¢„æµ‹æ€§èƒ½ã€‚è¿™ä¸€æ–¹æ³•è®ºä¸ºå¼€å‘æ›´é«˜æ•ˆã€ç”±ä¸“å®¶çŸ¥è¯†é©±åŠ¨çš„ä¸´åºŠè¯•éªŒè®¾è®¡é“ºå¹³äº†é“è·¯ï¼Œèƒ½å¤Ÿåœ¨ç¡®ä¿å®‰å…¨æ€§è¯„ä¼°ç¨³å¥æ€§çš„åŒæ—¶ï¼Œå¤§å¹…å‡å°‘æ‰€éœ€çš„å—è¯•æ‚£è€…æ•°é‡ã€‚è¯¥é¡¹å·¥ä½œå…·æœ‰å˜é©è¯ç‰©å®‰å…¨æ€§ç›‘æµ‹å’Œç›‘ç®¡å†³ç­–çš„æ½œåŠ›ï¼Œå±•ç°äº†åˆ©ç”¨ AI å…ˆéªŒçŸ¥è¯†åŠ é€Ÿä¸´åºŠåŒ»å­¦ç ”ç©¶çš„å·¨å¤§åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.ET",
        "cs.IR",
        "stat.AP"
      ],
      "primary_category": "stat.ME",
      "comment": "9 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.04250v2",
      "published_date": "2025-09-04 14:23:35 UTC",
      "updated_date": "2025-11-20 08:51:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:32:59.686764+00:00"
    },
    {
      "arxiv_id": "2509.04243v1",
      "title": "Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding",
      "title_zh": "åŸºäºè‡ªæ¼”åŒ–åå¥½ä¼˜åŒ–çš„ GUI å®šä½ä¸»åŠ¨æ„ŸçŸ¥å­¦ä¹ ",
      "authors": [
        "Wanfu Wang",
        "Qipeng Huang",
        "Guangquan Xue",
        "Xiaobo Liang",
        "Juntao Li"
      ],
      "abstract": "Vision Language Models (VLMs) have recently achieved significant progress in bridging visual perception and linguistic reasoning. Recently, OpenAI o3 model introduced a zoom-in search strategy that effectively elicits active perception capabilities in VLMs, improving downstream task performance. However, enabling VLMs to reason effectively over appropriate image regions remains a core challenge in GUI grounding, particularly under high-resolution inputs and complex multi-element visual interactions. In this work, we propose LASER, a self-evolving framework that progressively endows VLMs with multi-step perception capabilities, enabling precise coordinate prediction. Specifically, our approach integrate Monte Carlo quality estimation with Intersection-over-Union (IoU)-based region quality evaluation to jointly encourage both accuracy and diversity in constructing high-quality preference data. This combination explicitly guides the model to focus on instruction-relevant key regions while adaptively allocating reasoning steps based on task complexity. Comprehensive experiments on the ScreenSpot Pro and ScreenSpot-v2 benchmarks demonstrate consistent performance gains, validating the effectiveness of our method. Furthermore, when fine-tuned on GTA1-7B, LASER achieves a score of 55.7 on the ScreenSpot-Pro benchmark, establishing a new state-of-the-art (SoTA) among 7B-scale models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LASERï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨èµ‹äºˆè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)å¤šæ­¥ä¸»åŠ¨æ„ŸçŸ¥èƒ½åŠ›çš„è‡ªæˆ‘æ¼”è¿›æ¡†æ¶ï¼Œä»¥è§£å†³GUI groundingä¸­çš„é«˜åˆ†è¾¨ç‡è¾“å…¥å’Œå¤æ‚äº¤äº’æŒ‘æˆ˜ã€‚LASERé€šè¿‡é›†æˆMonte Carloè´¨é‡ä¼°è®¡ä¸åŸºäºIntersection-over-Union (IoU)çš„åŒºåŸŸè´¨é‡è¯„ä¼°ï¼Œå…±åŒä¿ƒè¿›é«˜è´¨é‡åå¥½æ•°æ®çš„æ„å»ºï¼Œä»è€Œå¢å¼ºäº†åæ ‡é¢„æµ‹çš„ç²¾ç¡®æ€§ã€‚è¯¥æ¡†æ¶å¼•å¯¼æ¨¡å‹èšç„¦äºä¸æŒ‡ä»¤ç›¸å…³çš„å…³é”®åŒºåŸŸï¼Œå¹¶èƒ½æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªé€‚åº”åœ°åˆ†é…æ¨ç†æ­¥éª¤ã€‚åœ¨ScreenSpot Proå’ŒScreenSpot-v2åŸºå‡†ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æŒç»­æ€§èƒ½æå‡ã€‚ç‰¹åˆ«æ˜¯ç»è¿‡å¾®è°ƒçš„LASERåœ¨ScreenSpot-Proä¸Šè¾¾åˆ°äº†55.7åˆ†ï¼Œåˆ·æ–°äº†7Bè§„æ¨¡æ¨¡å‹çš„State-of-the-Art (SoTA)çºªå½•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04243v1",
      "published_date": "2025-09-04 14:17:01 UTC",
      "updated_date": "2025-09-04 14:17:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:33:00.587181+00:00"
    },
    {
      "arxiv_id": "2509.04239v1",
      "title": "Evaluating Quality of Gaming Narratives Co-created with AI",
      "title_zh": "è¯„ä¼° AI ååŒåˆ›ä½œçš„æ¸¸æˆå™äº‹è´¨é‡",
      "authors": [
        "Arturo Valdivia",
        "Paolo Burelli"
      ],
      "abstract": "This paper proposes a structured methodology to evaluate AI-generated game narratives, leveraging the Delphi study structure with a panel of narrative design experts. Our approach synthesizes story quality dimensions from literature and expert insights, mapping them into the Kano model framework to understand their impact on player satisfaction. The results can inform game developers on prioritizing quality aspects when co-creating game narratives with generative AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“æ„åŒ–çš„æ–¹æ³•ï¼Œæ—¨åœ¨è¯„ä¼°ä¸AIå…±åŒåˆ›ä½œçš„æ¸¸æˆå™äº‹è´¨é‡ã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº†Delphi studyï¼ˆå¾·å°”è²ç ”ç©¶ï¼‰ç»“æ„ï¼Œé€šè¿‡å’¨è¯¢ä¸€ç»„å™äº‹è®¾è®¡ä¸“å®¶ï¼ˆnarrative design expertsï¼‰æ¥ç»¼åˆæ–‡çŒ®ä¸ä¸“å®¶è§è§£ä¸­çš„æ•…äº‹è´¨é‡ç»´åº¦ï¼ˆstory quality dimensionsï¼‰ã€‚ç ”ç©¶è¿›ä¸€æ­¥å°†è¿™äº›ç»´åº¦æ˜ å°„åˆ°Kano modelï¼ˆå¡è¯ºæ¨¡å‹ï¼‰æ¡†æ¶ä¸­ï¼Œç”¨ä»¥åˆ†æä¸åŒå™äº‹å±æ€§å¯¹ç©å®¶æ»¡æ„åº¦ï¼ˆplayer satisfactionï¼‰çš„å…·ä½“å½±å“ã€‚å®éªŒç»“æœå¯ä»¥æŒ‡å¯¼æ¸¸æˆå¼€å‘è€…åœ¨åˆ©ç”¨Generative AIï¼ˆç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼‰ååŒåˆ›ä½œæ¸¸æˆå™äº‹æ—¶ï¼Œç§‘å­¦åœ°ç¡®å®šå„é¡¹è´¨é‡æŒ‡æ ‡çš„ä¼˜å…ˆçº§ã€‚è¯¥ç ”ç©¶ä¸ºAIè¾…åŠ©çš„æ¸¸æˆå™äº‹è¯„ä¼°æä¾›äº†ä¸€å¥—ç³»ç»ŸåŒ–çš„ç†è®ºä¾æ®å’Œå®è·µæ¡†æ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04239v1",
      "published_date": "2025-09-04 14:13:42 UTC",
      "updated_date": "2025-09-04 14:13:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:33:31.694002+00:00"
    },
    {
      "arxiv_id": "2509.04192v1",
      "title": "Domain size asymptotics for Markov logic networks",
      "title_zh": "é©¬å°”å¯å¤«é€»è¾‘ç½‘ç»œè®ºåŸŸè§„æ¨¡çš„æ¸è¿‘æ€§è´¨",
      "authors": [
        "Vera Koponen"
      ],
      "abstract": "A Markov logic network (MLN) determines a probability distribution on the set of structures, or ``possible worlds'', with an arbitrary finite domain. We study the properties of such distributions as the domain size tends to infinity. Three types of concrete examples of MLNs will be considered, and the properties of random structures with domain sizes tending to infinity will be studied: (1) Arbitrary quantifier-free MLNs over a language with only one relation symbol which has arity 1. In this case we give a pretty complete characterization of the possible limit behaviours of random structures. (2) An MLN that favours graphs with fewer triangles (or more generally, fewer k-cliques). As a corollary of the analysis a ``$Î´$-approximate 0-1 law'' for first-order logic is obtained. (3) An MLN that favours graphs with fewer vertices with degree higher than a fixed (but arbitrary) number. The analysis shows that depending on which ``soft constraints'' an MLN uses the limit behaviour of random structures can be quite different, and the weights of the soft constraints may, or may not, have influence on the limit behaviour. It will also be demonstrated, using (1), that quantifier-free MLNs and lifted Bayesian networks (in a broad sense) are asymptotically incomparable, roughly meaning that there is a sequence of distributions on possible worlds with increasing domain sizes that can be defined by one of the formalisms but not even approximated by the other. In a rather general context it is also shown that on large domains the distribution determined by an MLN concentrates almost all its probability mass on a totally different part of the space of possible worlds than the uniform distribution does.",
      "tldr_zh": "è¯¥è®ºæ–‡æ·±å…¥ç ”ç©¶äº†é©¬å°”å¯å¤«é€»è¾‘ç½‘ç»œ (Markov logic networks, MLNs) åœ¨å®šä¹‰åŸŸå¤§å°è¶‹äºæ— ç©·å¤§æ—¶çš„æ¸è¿‘æ€§è´¨ã€‚ç ”ç©¶è€…é€šè¿‡åˆ†æä¸‰ç±»å…·ä½“å®ä¾‹ï¼Œé¦–å…ˆç»™å‡ºäº†ä»…å«ä¸€å…ƒå…³ç³»ç¬¦å·çš„æ— é‡è¯ MLN æé™è¡Œä¸ºçš„å®Œæ•´è¡¨å¾ï¼Œéšåæ¢è®¨äº†åå‘äºè¾ƒå°‘ $k$-å›¢ (k-cliques) çš„å›¾ç»“æ„å¹¶æ¨å¯¼å‡ºäº†ä¸€é˜¶é€»è¾‘çš„ $\\delta$-è¿‘ä¼¼ 0-1 å¾‹ ($\\delta$-approximate 0-1 law)ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹é™åˆ¶é¡¶ç‚¹åº¦æ•°çš„ MLN åˆ†æè¡¨æ˜ï¼Œè½¯çº¦æŸ (soft constraints) åŠå…¶æƒé‡å¯¹æé™è¡Œä¸ºå…·æœ‰ä¸åŒç¨‹åº¦çš„å½±å“ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†æ— é‡è¯ MLN ä¸æå‡è´å¶æ–¯ç½‘ç»œ (lifted Bayesian networks) åœ¨æ¸è¿‘æ€§ä¸Šå…·æœ‰ä¸å¯æ¯”æ€§ã€‚æœ€åï¼Œè®ºæ–‡æŒ‡å‡ºåœ¨å¤§å‹å®šä¹‰åŸŸä¸­ï¼ŒMLN çš„æ¦‚ç‡åˆ†å¸ƒä¼šé›†ä¸­åœ¨ä¸å‡åŒ€åˆ†å¸ƒæˆªç„¶ä¸åŒçš„å¯èƒ½ä¸–ç•Œç©ºé—´åŒºåŸŸï¼Œæ­ç¤ºäº†å…¶åœ¨å¤„ç†å¤æ‚çº¦æŸä¸‹çš„æ¦‚ç‡é›†ä¸­ç‰¹æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO",
        "math.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04192v1",
      "published_date": "2025-09-04 13:15:02 UTC",
      "updated_date": "2025-09-04 13:15:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:33:26.090266+00:00"
    },
    {
      "arxiv_id": "2509.05376v1",
      "title": "Privacy Preservation and Identity Tracing Prevention in AI-Driven Eye Tracking for Interactive Learning Environments",
      "title_zh": "äº¤äº’å¼å­¦ä¹ ç¯å¢ƒä¸­AIé©±åŠ¨çœ¼åŠ¨è¿½è¸ªçš„éšç§ä¿æŠ¤ä¸èº«ä»½è¿½è¸ªé¢„é˜²",
      "authors": [
        "Abdul Rehman",
        "Are DÃ¦hlen",
        "Ilona Heldal",
        "Jerry Chun-wei Lin"
      ],
      "abstract": "Eye-tracking technology can aid in understanding neurodevelopmental disorders and tracing a person's identity. However, this technology poses a significant risk to privacy, as it captures sensitive information about individuals and increases the likelihood that data can be traced back to them. This paper proposes a human-centered framework designed to prevent identity backtracking while preserving the pedagogical benefits of AI-powered eye tracking in interactive learning environments. We explore how real-time data anonymization, ethical design principles, and regulatory compliance (such as GDPR) can be integrated to build trust and transparency. We first demonstrate the potential for backtracking student IDs and diagnoses in various scenarios using serious game-based eye-tracking data. We then provide a two-stage privacy-preserving framework that prevents participants from being tracked while still enabling diagnostic classification. The first phase covers four scenarios: I) Predicting disorder diagnoses based on different game levels. II) Predicting student IDs based on different game levels. III) Predicting student IDs based on randomized data. IV) Utilizing K-Means for out-of-sample data. In the second phase, we present a two-stage framework that preserves privacy. We also employ Federated Learning (FL) across multiple clients, incorporating a secure identity management system with dummy IDs and administrator-only access controls. In the first phase, the proposed framework achieved 99.3% accuracy for scenario 1, 63% accuracy for scenario 2, and 99.7% accuracy for scenario 3, successfully identifying and assigning a new student ID in scenario 4. In phase 2, we effectively prevented backtracking and established a secure identity management system with dummy IDs and administrator-only access controls, achieving an overall accuracy of 99.40%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº¤äº’å¼å­¦ä¹ ç¯å¢ƒä¸­çš„AIé©±åŠ¨çœ¼åŠ¨è¿½è¸ª(Eye-tracking)æŠ€æœ¯å¯èƒ½å¯¼è‡´çš„æ•æ„Ÿä¿¡æ¯æ³„éœ²å’Œèº«ä»½è¿½è¸ªé£é™©ï¼Œæå‡ºäº†ä¸€ç§ä»¥äººä¸ºä¸­å¿ƒçš„éšç§ä¿æŠ¤ä¸èº«ä»½å›æº¯é¢„é˜²æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨å¹³è¡¡çœ¼åŠ¨æ•°æ®çš„æ•™å­¦è¯Šæ–­ä»·å€¼ä¸ç”¨æˆ·éšç§ï¼Œé›†æˆäº†å®æ—¶æ•°æ®åŒ¿ååŒ–ã€ä¼¦ç†è®¾è®¡åŸåˆ™åŠè”é‚¦å­¦ä¹ (Federated Learning)æŠ€æœ¯ã€‚ç ”ç©¶é€šè¿‡ä¸¤ä¸ªé˜¶æ®µè¿›è¡ŒéªŒè¯ï¼šç¬¬ä¸€é˜¶æ®µé€šè¿‡ä¸¥è‚ƒæ¸¸æˆæ•°æ®æ­ç¤ºäº†é€šè¿‡çœ¼åŠ¨ç‰¹å¾é¢„æµ‹å­¦ç”ŸIDåŠè¯Šæ–­ç»“æœçš„æ½œåœ¨å›æº¯é£é™©ï¼›ç¬¬äºŒé˜¶æ®µåˆ™å®æ–½äº†åŒ…å«è™šæ‹ŸID(dummy IDs)å’Œä¸¥æ ¼æƒé™æ§åˆ¶çš„å®‰å…¨ç®¡ç†ç³»ç»Ÿã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨ç¬¬ä¸€é˜¶æ®µçš„é£é™©è¯†åˆ«å‡†ç¡®ç‡æœ€é«˜è¾¾99.7%ï¼Œè€Œåœ¨ç¬¬äºŒé˜¶æ®µé€šè¿‡éšç§ä¿æŠ¤æœºåˆ¶æœ‰æ•ˆé˜²æ­¢äº†èº«ä»½å›æº¯ï¼Œå¹¶ä¿æŒäº†99.40%çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚è¿™ä¸€æ–¹æ¡ˆä¸ºåœ¨æ™ºæ…§æ•™è‚²ä¸­æ„å»ºå®‰å…¨ã€é€æ˜ä¸”ç¬¦åˆGDPRè¦æ±‚çš„çœ¼åŠ¨åˆ†æç³»ç»Ÿæä¾›äº†æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05376v1",
      "published_date": "2025-09-04 13:08:06 UTC",
      "updated_date": "2025-09-04 13:08:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:33:26.890318+00:00"
    },
    {
      "arxiv_id": "2509.04183v2",
      "title": "MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions",
      "title_zh": "MAGneTï¼šåŸºäºååŒå¤šæ™ºèƒ½ä½“çš„åˆæˆå¤šè½®å¿ƒç†å¥åº·å’¨è¯¢å¯¹è¯ç”Ÿæˆ",
      "authors": [
        "Aishik Mandal",
        "Tanmoy Chakraborty",
        "Iryna Gurevych"
      ],
      "abstract": "The growing demand for scalable psychological counseling highlights the need for high-quality, privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT, a novel multi-agent framework for synthetic psychological counseling session generation that decomposes counselor response generation into coordinated sub-tasks handled by specialized LLM agents, each modeling a key psychological technique. Unlike prior single-agent approaches, MAGneT better captures the structure and nuance of real counseling. We further propose a unified evaluation framework that consolidates diverse automatic metrics and expands expert assessment from four to nine counseling dimensions, thus addressing inconsistencies in prior evaluation protocols. Empirically, MAGneT substantially outperforms existing methods: experts prefer MAGneT-generated sessions in 77.2% of cases, and sessions generated by MAGneT yield 3.2% higher general counseling skills and 4.3% higher CBT-specific skills on cognitive therapy rating scale (CTRS). A open source Llama3-8B-Instruct model fine-tuned on MAGneT-generated data also outperforms models fine-tuned using baseline synthetic datasets by 6.9% on average on CTRS.We also make our code and data public.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¿ƒç†å¥åº·å’¨è¯¢é¢†åŸŸé«˜è´¨é‡ã€ç¬¦åˆéšç§åˆè§„æ•°æ®çŸ­ç¼ºçš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºMAGneTçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆåˆæˆçš„å¤šè½®å¿ƒç†å’¨è¯¢å¯¹è¯ã€‚è¯¥æ¡†æ¶å°†å’¨è¯¢å¸ˆçš„å›å¤ç”Ÿæˆåˆ†è§£ä¸ºç”±ä¸“é—¨LLM agentså¤„ç†çš„åè°ƒå­ä»»åŠ¡ï¼Œæ¯ä¸ªagentè´Ÿè´£å»ºæ¨¡ä¸€ç§æ ¸å¿ƒå¿ƒç†å­¦æŠ€æœ¯ï¼Œä»è€Œæ¯”å•æ™ºèƒ½ä½“æ–¹æ³•æ›´æœ‰æ•ˆåœ°æ•æ‰çœŸå®å’¨è¯¢çš„ç»“æ„ä¸ç»†å¾®å·®åˆ«ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œå°†ä¸“å®¶è¯„ä¼°ç»´åº¦ä»å››ä¸ªæ‰©å±•è‡³ä¹ä¸ªï¼Œè§£å†³äº†å…ˆå‰è¯„ä¼°åè®®ä¸­çš„ä¸ä¸€è‡´é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸“å®¶åœ¨77.2%çš„æƒ…å†µä¸‹æ›´å€¾å‘äºé€‰æ‹©MAGneTç”Ÿæˆçš„ä¼šè¯ï¼Œå…¶åœ¨è®¤çŸ¥æ²»ç–—é‡è¡¨(CTRS)ä¸Šçš„é€šç”¨å’¨è¯¢æŠ€èƒ½å’ŒCBTç‰¹å®šæŠ€èƒ½å¾—åˆ†åˆ†åˆ«æå‡äº†3.2%å’Œ4.3%ã€‚æ­¤å¤–ï¼Œåœ¨MAGneTç”Ÿæˆæ•°æ®ä¸Šå¾®è°ƒçš„Llama3-8B-Instructæ¨¡å‹åœ¨CTRSä¸Šçš„å¹³å‡è¡¨ç°ä¼˜äºåŸºçº¿æ¨¡å‹6.9%ã€‚è¯¥ç ”ç©¶é€šè¿‡å¼€æºä»£ç å’Œæ•°æ®ï¼Œä¸ºå¼€å‘å¤§è§„æ¨¡ã€é«˜è´¨é‡çš„å¿ƒç†å¥åº·è¾…åŠ©æŠ€æœ¯æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "38 pages, 32 figures, 12 Tables",
      "pdf_url": "https://arxiv.org/pdf/2509.04183v2",
      "published_date": "2025-09-04 12:59:24 UTC",
      "updated_date": "2026-01-09 10:37:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:33:37.396894+00:00"
    },
    {
      "arxiv_id": "2509.04180v1",
      "title": "VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer Vision",
      "title_zh": "VisioFirmï¼šé¢å‘è®¡ç®—æœºè§†è§‰çš„è·¨å¹³å° AI è¾…åŠ©æ ‡æ³¨å·¥å…·",
      "authors": [
        "Safouane El Ghazouali",
        "Umberto Michelucci"
      ],
      "abstract": "AI models rely on annotated data to learn pattern and perform prediction. Annotation is usually a labor-intensive step that require associating labels ranging from a simple classification label to more complex tasks such as object detection, oriented bounding box estimation, and instance segmentation. Traditional tools often require extensive manual input, limiting scalability for large datasets. To address this, we introduce VisioFirm, an open-source web application designed to streamline image labeling through AI-assisted automation. VisioFirm integrates state-of-the-art foundation models into an interface with a filtering pipeline to reduce human-in-the-loop efforts. This hybrid approach employs CLIP combined with pre-trained detectors like Ultralytics models for common classes and zero-shot models such as Grounding DINO for custom labels, generating initial annotations with low-confidence thresholding to maximize recall. Through this framework, when tested on COCO-type of classes, initial prediction have been proven to be mostly correct though the users can refine these via interactive tools supporting bounding boxes, oriented bounding boxes, and polygons. Additionally, VisioFirm has on-the-fly segmentation powered by Segment Anything accelerated through WebGPU for browser-side efficiency. The tool supports multiple export formats (YOLO, COCO, Pascal VOC, CSV) and operates offline after model caching, enhancing accessibility. VisioFirm demonstrates up to 90\\% reduction in manual effort through benchmarks on diverse datasets, while maintaining high annotation accuracy via clustering of connected CLIP-based disambiguate components and IoU-graph for redundant detection suppression. VisioFirm can be accessed from \\href{https://github.com/OschAI/VisioFirm}{https://github.com/OschAI/VisioFirm}.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† VisioFirmï¼Œä¸€ä¸ªå¼€æºçš„ Web åº”ç”¨ç¨‹åºï¼Œæ—¨åœ¨é€šè¿‡ AI è¾…åŠ©è‡ªåŠ¨åŒ–ç®€åŒ–è®¡ç®—æœºè§†è§‰ä¸­çš„å›¾åƒæ ‡æ³¨è¿‡ç¨‹ã€‚è¯¥å·¥å…·é›†æˆäº† CLIPã€Ultralytics é¢„è®­ç»ƒæ£€æµ‹å™¨ä»¥åŠ Grounding DINO ç­‰å…ˆè¿›çš„åŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤Ÿé’ˆå¯¹é€šç”¨ç±»åˆ«å’Œè‡ªå®šä¹‰æ ‡ç­¾ç”Ÿæˆåˆå§‹æ ‡æ³¨ï¼Œä»è€Œæ˜¾è‘—é™ä½äººå·¥å‚ä¸çš„æˆæœ¬ã€‚VisioFirm é‡‡ç”¨åŸºäº WebGPU åŠ é€Ÿçš„ Segment Anything (SAM) æŠ€æœ¯å®ç°æµè§ˆå™¨ç«¯çš„å®æ—¶åˆ†å‰²ï¼Œå¹¶æ”¯æŒå¯¹ Bounding Boxesã€Oriented Bounding Boxes å’Œ Polygons çš„äº¤äº’å¼å¾®è°ƒã€‚æ­¤å¤–ï¼Œç³»ç»Ÿé€šè¿‡ CLIP èšç±»å’Œ IoU-graph æŠ€æœ¯æœ‰æ•ˆæŠ‘åˆ¶å†—ä½™æ£€æµ‹ï¼Œå¹¶æ”¯æŒ YOLOã€COCO ç­‰å¤šç§ä¸»æµæ•°æ®æ ¼å¼å¯¼å‡ºã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒVisioFirm åœ¨ç¡®ä¿é«˜ç²¾åº¦æ ‡æ³¨çš„å‰æä¸‹ï¼Œå¯å°†äººå·¥æ‰‹åŠ¨æ ‡æ³¨çš„å·¥ä½œé‡å‡å°‘é«˜è¾¾ 90%ï¼Œä¸ºå¤§è§„æ¨¡æ•°æ®é›†çš„æ ‡æ³¨æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04180v1",
      "published_date": "2025-09-04 12:54:32 UTC",
      "updated_date": "2025-09-04 12:54:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:33:40.191577+00:00"
    },
    {
      "arxiv_id": "2509.04166v1",
      "title": "Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds",
      "title_zh": "è·¨è¶Šç‰©ç§é¸¿æ²Ÿï¼šä»è¯­éŸ³åˆ°åŠ¨ç‰©å£°éŸ³çš„è¿ç§»å­¦ä¹ ",
      "authors": [
        "Jules Cauzinille",
        "Marius Miron",
        "Olivier Pietquin",
        "Masato Hagiwara",
        "Ricard Marxer",
        "Arnaud Rey",
        "Benoit Favre"
      ],
      "abstract": "Self-supervised speech models have demonstrated impressive performance in speech processing, but their effectiveness on non-speech data remains underexplored. We study the transfer learning capabilities of such models on bioacoustic detection and classification tasks. We show that models such as HuBERT, WavLM, and XEUS can generate rich latent representations of animal sounds across taxa. We analyze the models properties with linear probing on time-averaged representations. We then extend the approach to account for the effect of time-wise information with other downstream architectures. Finally, we study the implication of frequency range and noise on performance. Notably, our results are competitive with fine-tuned bioacoustic pre-trained models and show the impact of noise-robust pre-training setups. These findings highlight the potential of speech-based self-supervised learning as an efficient framework for advancing bioacoustic research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è‡ªç›‘ç£è¯­éŸ³æ¨¡å‹ (Self-supervised speech models) åœ¨éè¯­éŸ³æ•°æ®ï¼ˆå¦‚åŠ¨ç‰©å£°éŸ³ï¼‰ä¸Šçš„è¿ç§»å­¦ä¹  (Transfer learning) èƒ½åŠ›ï¼Œé‡ç‚¹åˆ†æäº† HuBERTã€WavLM å’Œ XEUS ç­‰æ¨¡å‹åœ¨ä¸åŒåˆ†ç±»ç¾¤ç”Ÿç‰©å£°å­¦æ£€æµ‹ä¸åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼Œè¿™äº›è¯­éŸ³é¢„è®­ç»ƒæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆä¸°å¯Œçš„æ½œåœ¨è¡¨å¾ (Latent representations)ï¼Œé€šè¿‡çº¿æ€§æ¢æµ‹ (Linear probing) å’Œèåˆæ—¶é—´ä¿¡æ¯çš„ä¸‹æ¸¸æ¶æ„ï¼Œæ¨¡å‹å±•ç°å‡ºè·¨ç‰©ç§çš„å¼ºå¤§é€‚åº”æ€§ã€‚ç ”ç©¶è¿˜æ·±å…¥è¯„ä¼°äº†é¢‘ç‡èŒƒå›´å’Œå™ªå£°å¯¹æ€§èƒ½çš„å½±å“ï¼Œè¯æ˜æŠ—å™ªé¢„è®­ç»ƒè®¾ç½®åœ¨ç”Ÿç‰©å£°å­¦åœºæ™¯ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹åœ¨å¤„ç†åŠ¨ç‰©å£°éŸ³æ—¶çš„è¡¨ç°å¯ä¸ä¸“é—¨å¾®è°ƒçš„ç”Ÿç‰©å£°å­¦æ¨¡å‹ç›¸åª²ç¾ã€‚è¿™ä¸€å‘ç°çªæ˜¾äº†è¯­éŸ³è‡ªç›‘ç£å­¦ä¹ ä½œä¸ºé«˜æ•ˆæ¡†æ¶åœ¨æ¨åŠ¨ç”Ÿç‰©å£°å­¦ (Bioacoustics) ç ”ç©¶æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºè·¨é¢†åŸŸéŸ³é¢‘åˆ†ææä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 3 figures, uses dcase2025.sty, submitted to DCASE 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04166v1",
      "published_date": "2025-09-04 12:39:05 UTC",
      "updated_date": "2025-09-04 12:39:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:33:45.668094+00:00"
    },
    {
      "arxiv_id": "2509.04159v1",
      "title": "Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs",
      "title_zh": "è¿ˆå‘åŸºäºæ—¶åºå›¾çš„ä»¥åŠ¨ä½œä¸ºä¸­å¿ƒçš„çƒ¹é¥ªç¨‹åºæœ¬ä½“",
      "authors": [
        "Aarush Kumbhakern",
        "Saransh Kumar Gupta",
        "Lipika Dey",
        "Partha Pratim Das"
      ],
      "abstract": "Formalizing cooking procedures remains a challenging task due to their inherent complexity and ambiguity. We introduce an extensible domain-specific language for representing recipes as directed action graphs, capturing processes, transfers, environments, concurrency, and compositional structure. Our approach enables precise, modular modeling of complex culinary workflows. Initial manual evaluation on a full English breakfast recipe demonstrates the DSL's expressiveness and suitability for future automated recipe analysis and execution. This work represents initial steps towards an action-centric ontology for cooking, using temporal graphs to enable structured machine understanding, precise interpretation, and scalable automation of culinary processes - both in home kitchens and professional culinary settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çƒ¹é¥ªè¿‡ç¨‹å½¢å¼åŒ–ä¸­çš„å¤æ‚æ€§å’Œæ­§ä¹‰æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ—¶é—´å›¾(Temporal Graphs)çš„ä»¥åŠ¨ä½œä¸ºä¸­å¿ƒçš„æœ¬ä½“ã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ç§å¯æ‰©å±•çš„é¢†åŸŸç‰¹å®šè¯­è¨€(DSL)ï¼Œå°†é£Ÿè°±è¡¨ç¤ºä¸ºæœ‰å‘åŠ¨ä½œå›¾ï¼Œèƒ½å¤Ÿæ•æ‰è¿‡ç¨‹ã€è½¬ç§»ã€ç¯å¢ƒã€å¹¶å‘å’Œç»„åˆç»“æ„ã€‚è¯¥æ–¹æ³•å®ç°äº†å¯¹å¤æ‚çƒ¹é¥ªå·¥ä½œæµçš„ç²¾ç¡®ä¸”æ¨¡å—åŒ–çš„å»ºæ¨¡ï¼Œæœ‰åŠ©äºå®ç°æ›´ç»“æ„åŒ–çš„æœºå™¨ç†è§£ã€‚é€šè¿‡å¯¹å…¨è‹±å¼æ—©é¤é£Ÿè°±çš„æ‰‹åŠ¨è¯„ä¼°ï¼Œå®éªŒéªŒè¯äº†è¯¥DSLçš„è¡¨è¾¾èƒ½åŠ›åŠå…¶åœ¨æœªæ¥è‡ªåŠ¨åŒ–é£Ÿè°±åˆ†æä¸æ‰§è¡Œä¸­çš„é€‚ç”¨æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºå®ç°åœ¨å®¶åº­å’Œä¸“ä¸šå¨æˆ¿åœºæ™¯ä¸‹çƒ¹é¥ªè¿‡ç¨‹çš„ç²¾ç¡®è§£é‡Šå’Œå¯æ‰©å±•è‡ªåŠ¨åŒ–å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 3 figures, 1 table, 11 references, ACM International Conference on Multimedia 2025 - Multi-modal Food Computing Workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.04159v1",
      "published_date": "2025-09-04 12:34:56 UTC",
      "updated_date": "2025-09-04 12:34:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:33:52.148170+00:00"
    },
    {
      "arxiv_id": "2509.04156v1",
      "title": "YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components",
      "title_zh": "ç”¨äºæ— äººæœºé£æœºéƒ¨ä»¶å¤šå…‰è°±ç¼ºé™·æ£€æµ‹çš„ YOLO é›†æˆæ¨¡å‹",
      "authors": [
        "Serhii Svystun",
        "Pavlo Radiuk",
        "Oleksandr Melnychenko",
        "Oleg Savenko",
        "Anatoliy Sachenko"
      ],
      "abstract": "Unmanned aerial vehicles (UAVs) equipped with advanced sensors have opened up new opportunities for monitoring wind power plants, including blades, towers, and other critical components. However, reliable defect detection requires high-resolution data and efficient methods to process multispectral imagery. In this research, we aim to enhance defect detection accuracy through the development of an ensemble of YOLO-based deep learning models that integrate both visible and thermal channels. We propose an ensemble approach that integrates a general-purpose YOLOv8 model with a specialized thermal model, using a sophisticated bounding box fusion algorithm to combine their predictions. Our experiments show this approach achieves a mean Average Precision (mAP@.5) of 0.93 and an F1-score of 0.90, outperforming a standalone YOLOv8 model, which scored an mAP@.5 of 0.91. These findings demonstrate that combining multiple YOLO architectures with fused multispectral data provides a more reliable solution, improving the detection of both visual and thermal defects.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ— äººæœº(UAV)åœ¨é£åŠ›å‘ç”µæœºç»„ä»¶ç¼ºé™·æ£€æµ‹ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨è§£å†³å¤šå…‰è°±å›¾åƒå¤„ç†ä¸­çš„ç²¾åº¦å’Œæ•ˆç‡æŒ‘æˆ˜ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºYOLOæ¶æ„çš„é›†æˆæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡èåˆå¯è§å…‰å’Œçƒ­æˆåƒé€šé“æ¥æå‡æ£€æµ‹å‡†ç¡®ç‡ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä¸€ç§å¤æ‚çš„è¾¹ç•Œæ¡†èåˆç®—æ³•(bounding box fusion algorithm)ï¼Œå°†é€šç”¨å‹YOLOv8æ¨¡å‹ä¸ä¸“é—¨çš„çƒ­æˆåƒæ¨¡å‹è¿›è¡Œé¢„æµ‹æ•´åˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥é›†æˆæ–¹æ¡ˆå®ç°äº†0.93çš„å¹³å‡ç²¾åº¦(mAP@.5)å’Œ0.90çš„F1-scoreï¼Œæ€§èƒ½æ˜æ˜¾ä¼˜äºå•ä¸€çš„YOLOv8åŸºå‡†æ¨¡å‹ã€‚è¿™ä¸€å‘ç°è¯æ˜ï¼Œç»“åˆå¤šç§YOLOæ¶æ„ä¸å¤šå…‰è°±èåˆæ•°æ®èƒ½å¤Ÿæ›´å¯é åœ°è¯†åˆ«è§†è§‰å’Œçƒ­ç¼ºé™·ï¼Œä¸ºé£åŠ›å‘ç”µå‚çš„è‡ªåŠ¨åŒ–ç›‘æµ‹æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "The 13th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications, 4-6 September, 2025, Gliwice, Poland",
      "pdf_url": "https://arxiv.org/pdf/2509.04156v1",
      "published_date": "2025-09-04 12:32:04 UTC",
      "updated_date": "2025-09-04 12:32:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:33:51.169438+00:00"
    },
    {
      "arxiv_id": "2509.04154v3",
      "title": "Attention as an Adaptive Filter",
      "title_zh": "ä½œä¸ºè‡ªé€‚åº”æ»¤æ³¢å™¨çš„æ³¨æ„åŠ›æœºåˆ¶",
      "authors": [
        "Peter Racioppo"
      ],
      "abstract": "We introduce Adaptive Filter Attention (AFA), a novel attention mechanism that incorporates a learnable dynamics model directly into the computation of attention weights. Rather than comparing queries and keys directly, we model the input sequence as discrete observations of a linear stochastic differential equation (SDE). By assuming a continuous-time linear time-invariant system with simultaneously-diagonalizable state matrices and noise covariances, we can make use of a closed-form solution of the differential Lyapunov equation to efficiently propagate uncertainties through the dynamics from keys to queries. A generalization of attention naturally arises as the maximum likelihood solution for filtering the trajectory of this linear SDE, with attention weights corresponding to robust residual-based reweightings of the propagated query-key precisions. We further constrain the system dynamics and noise in order to obtain a simplified variant with the same computational and memory complexity as standard attention. In the limit of zero decay and process noise, and using a small-angle approximation, we recover a complex-valued generalization of ordinary dot-product attention with rotary positional encodings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†è‡ªé€‚åº”æ»¤æ³¢å™¨æ³¨æ„åŠ›(Adaptive Filter Attention, AFA)ï¼Œè¿™æ˜¯ä¸€ç§å°†å¯å­¦ä¹ çš„åŠ¨åŠ›å­¦æ¨¡å‹ç›´æ¥èå…¥æ³¨æ„åŠ›æƒé‡è®¡ç®—çš„æ–°å‹æœºåˆ¶ã€‚ç ”ç©¶äººå‘˜å°†è¾“å…¥åºåˆ—å»ºæ¨¡ä¸ºçº¿æ€§éšæœºå¾®åˆ†æ–¹ç¨‹(SDE)çš„ç¦»æ•£è§‚æµ‹å€¼ï¼Œå¹¶åˆ©ç”¨å¾®åˆ†Lyapunovæ–¹ç¨‹(differential Lyapunov equation)çš„è§£æè§£ï¼Œé«˜æ•ˆåœ°åœ¨é”®(keys)åˆ°æŸ¥è¯¢(queries)ä¹‹é—´ä¼ æ’­ä¸ç¡®å®šæ€§ã€‚ç ”ç©¶å‘ç°ï¼Œä¸€ç§å¹¿ä¹‰çš„æ³¨æ„åŠ›æœºåˆ¶å¯ä»¥è‡ªç„¶åœ°ä½œä¸ºè¯¥çº¿æ€§SDEè½¨è¿¹æ»¤æ³¢çš„æœ€å¤§ä¼¼ç„¶(MLE)è§£å‡ºç°ï¼Œå…¶æ³¨æ„åŠ›æƒé‡å¯¹åº”äºä¼ æ’­åçš„æŸ¥è¯¢-é”®ç²¾åº¦çš„é²æ£’æ®‹å·®é‡æƒåŒ–ã€‚é€šè¿‡è¿›ä¸€æ­¥çº¦æŸç³»ç»ŸåŠ¨åŠ›å­¦å’Œå™ªå£°ï¼Œè¯¥ç ”ç©¶æ¨å¯¼å‡ºäº†ä¸€ä¸ªç®€åŒ–å˜ä½“ï¼Œä½¿å…¶åœ¨è®¡ç®—å’Œç©ºé—´å¤æ‚åº¦ä¸Šä¸æ ‡å‡†æ³¨æ„åŠ›(Standard Attention)ä¿æŒä¸€è‡´ã€‚åœ¨é›¶è¡°å‡å’Œè¿‡ç¨‹å™ªå£°çš„æé™æƒ…å†µä¸‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡å°è§’è¿‘ä¼¼å¯ä»¥è¿˜åŸä¸ºå¸¦æœ‰æ—‹è½¬ä½ç½®ç¼–ç (RoPE)çš„å¤æ•°å€¼å¹¿ä¹‰ç‚¹ç§¯æ³¨æ„åŠ›ï¼Œåœ¨ç†è®ºä¸Šç»Ÿä¸€äº†ç»å…¸æ³¨æ„åŠ›æœºåˆ¶ä¸æ»¤æ³¢åŠ¨åŠ›å­¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04154v3",
      "published_date": "2025-09-04 12:29:14 UTC",
      "updated_date": "2025-10-14 02:25:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:02.046356+00:00"
    },
    {
      "arxiv_id": "2509.04152v1",
      "title": "TAGAL: Tabular Data Generation using Agentic LLM Methods",
      "title_zh": "TAGALï¼šåŸºäºæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹æ–¹æ³•çš„è¡¨æ ¼æ•°æ®ç”Ÿæˆ",
      "authors": [
        "BenoÃ®t Ronval",
        "Pierre Dupont",
        "Siegfried Nijssen"
      ],
      "abstract": "The generation of data is a common approach to improve the performance of machine learning tasks, among which is the training of models for classification. In this paper, we present TAGAL, a collection of methods able to generate synthetic tabular data using an agentic workflow. The methods leverage Large Language Models (LLMs) for an automatic and iterative process that uses feedback to improve the generated data without any further LLM training. The use of LLMs also allows for the addition of external knowledge in the generation process. We evaluate TAGAL across diverse datasets and different aspects of quality for the generated data. We look at the utility of downstream ML models, both by training classifiers on synthetic data only and by combining real and synthetic data. Moreover, we compare the similarities between the real and the generated data. We show that TAGAL is able to perform on par with state-of-the-art approaches that require LLM training and generally outperforms other training-free approaches. These findings highlight the potential of agentic workflow and open new directions for LLM-based data generation methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TAGALï¼Œè¿™æ˜¯ä¸€å¥—åˆ©ç”¨ Agentic Workflow ç”Ÿæˆåˆæˆè¡¨æ ¼æ•°æ® (Tabular Data) çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ Large Language Models (LLMs) æ„å»ºäº†ä¸€ä¸ªè‡ªåŠ¨åŒ–ä¸”è¿­ä»£çš„è¿‡ç¨‹ï¼Œé€šè¿‡åé¦ˆæœºåˆ¶åœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹æŒç»­ä¼˜åŒ–ç”Ÿæˆæ•°æ®ï¼Œå¹¶æ”¯æŒåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å¼•å…¥å¤–éƒ¨çŸ¥è¯†ã€‚ç ”ç©¶äººå‘˜é€šè¿‡åœ¨å¤šæ ·åŒ–æ•°æ®é›†ä¸Šè®­ç»ƒåˆ†ç±»å™¨ä»¥åŠè¯„ä¼°çœŸå®æ•°æ®ä¸åˆæˆæ•°æ®ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå…¨é¢è¡¡é‡äº†æ•°æ®çš„è´¨é‡ä¸æ•ˆç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTAGAL çš„è¡¨ç°ä¸éœ€è¦é¢å¤–è®­ç»ƒçš„ State-of-the-art (SOTA) æ–¹æ³•ç›¸å½“ï¼Œä¸”æ™®éä¼˜äºå…¶ä»–æ— éœ€è®­ç»ƒçš„æ–¹æ³•ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†æ™ºèƒ½ä½“å·¥ä½œæµåœ¨è¡¨æ ¼æ•°æ®ç”Ÿæˆé¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œä¸ºåŸºäº LLMs çš„æ•°æ®å¢å¼ºæŠ€æœ¯æä¾›äº†æ–°çš„æ€è·¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04152v1",
      "published_date": "2025-09-04 12:25:14 UTC",
      "updated_date": "2025-09-04 12:25:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:02.864358+00:00"
    },
    {
      "arxiv_id": "2509.04139v1",
      "title": "Enhancing Technical Documents Retrieval for RAG",
      "title_zh": "å¢å¼ºé¢å‘ RAG çš„æŠ€æœ¯æ–‡æ¡£æ£€ç´¢",
      "authors": [
        "Songjiang Lai",
        "Tsun-Hin Cheung",
        "Ka-Chun Fung",
        "Kaiwen Xue",
        "Kwan-Ho Lin",
        "Yan-Ming Choi",
        "Vincent Ng",
        "Kin-Man Lam"
      ],
      "abstract": "In this paper, we introduce Technical-Embeddings, a novel framework designed to optimize semantic retrieval in technical documentation, with applications in both hardware and software development. Our approach addresses the challenges of understanding and retrieving complex technical content by leveraging the capabilities of Large Language Models (LLMs). First, we enhance user queries by generating expanded representations that better capture user intent and improve dataset diversity, thereby enriching the fine-tuning process for embedding models. Second, we apply summary extraction techniques to encode essential contextual information, refining the representation of technical documents. To further enhance retrieval performance, we fine-tune a bi-encoder BERT model using soft prompting, incorporating separate learning parameters for queries and document context to capture fine-grained semantic nuances. We evaluate our approach on two public datasets, RAG-EDA and Rust-Docs-QA, demonstrating that Technical-Embeddings significantly outperforms baseline models in both precision and recall. Our findings highlight the effectiveness of integrating query expansion and contextual summarization to enhance information access and comprehension in technical domains. This work advances the state of Retrieval-Augmented Generation (RAG) systems, offering new avenues for efficient and accurate technical document retrieval in engineering and product development workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Technical-Embeddingsï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ä¼˜åŒ–ç¡¬ä»¶å’Œè½¯ä»¶å¼€å‘ç­‰æŠ€æœ¯æ–‡æ¡£è¯­ä¹‰æ£€ç´¢çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤æ‚æŠ€æœ¯å†…å®¹çš„ç†è§£ä¸æ£€ç´¢éš¾é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨Large Language Models (LLMs)çš„èƒ½åŠ›ï¼Œé€šè¿‡ç”Ÿæˆæ‰©å±•çš„æŸ¥è¯¢è¡¨ç¤ºæ¥å¢å¼ºç”¨æˆ·æ„å›¾çš„æ•æ‰ï¼Œå¹¶ä¸°å¯Œäº†åµŒå…¥æ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹ã€‚åŒæ—¶ï¼Œç ”ç©¶é‡‡ç”¨äº†æ‘˜è¦æå–æŠ€æœ¯æ¥ç¼–ç å…³é”®çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œè¿›ä¸€æ­¥ç»†åŒ–æŠ€æœ¯æ–‡æ¡£çš„ç‰¹å¾è¡¨ç¤ºã€‚åœ¨æ¨¡å‹ä¼˜åŒ–æ–¹é¢ï¼Œç ”ç©¶äººå‘˜é€šè¿‡soft promptingå¾®è°ƒäº†åŒç¼–ç å™¨BERTæ¨¡å‹ï¼Œå¹¶ä¸ºæŸ¥è¯¢å’Œæ–‡æ¡£ä¸Šä¸‹æ–‡è®¾ç½®äº†ç‹¬ç«‹çš„å­¦ä¹ å‚æ•°ï¼Œä»¥æ•æ‰ç»†ç²’åº¦çš„è¯­ä¹‰å·®åˆ«ã€‚å®éªŒåœ¨RAG-EDAå’ŒRust-Docs-QAä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æœæ˜¾ç¤ºTechnical-Embeddingsåœ¨å‡†ç¡®ç‡å’Œå¬å›ç‡ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚è¿™ä¸€æˆæœè¯æ˜äº†ç»“åˆæŸ¥è¯¢æ‰©å±•å’Œä¸Šä¸‹æ–‡æ‘˜è¦åœ¨æå‡æŠ€æœ¯é¢†åŸŸä¿¡æ¯è·å–æ•ˆç‡æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºRetrieval-Augmented Generation (RAG)ç³»ç»Ÿåœ¨å·¥ç¨‹å’Œäº§å“å¼€å‘å·¥ä½œæµä¸­çš„åº”ç”¨æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04139v1",
      "published_date": "2025-09-04 12:11:03 UTC",
      "updated_date": "2025-09-04 12:11:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:26.559179+00:00"
    },
    {
      "arxiv_id": "2509.09699v1",
      "title": "Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs",
      "title_zh": "ç»“æ„åŒ–ä¿¡æ¯è‡³å…³é‡è¦ï¼šåŸºäºæ‚£è€…çº§çŸ¥è¯†å›¾è°±çš„å¯è§£é‡Š ICD ç¼–ç ",
      "authors": [
        "Mingyang Li",
        "Viktor Schlegel",
        "Tingting Mu",
        "Warren Del-Pinto",
        "Goran Nenadic"
      ],
      "abstract": "Mapping clinical documents to standardised clinical vocabularies is an important task, as it provides structured data for information retrieval and analysis, which is essential to clinical research, hospital administration and improving patient care. However, manual coding is both difficult and time-consuming, making it impractical at scale. Automated coding can potentially alleviate this burden, improving the availability and accuracy of structured clinical data. The task is difficult to automate, as it requires mapping to high-dimensional and long-tailed target spaces, such as the International Classification of Diseases (ICD). While external knowledge sources have been readily utilised to enhance output code representation, the use of external resources for representing the input documents has been underexplored. In this work, we compute a structured representation of the input documents, making use of document-level knowledge graphs (KGs) that provide a comprehensive structured view of a patient's condition. The resulting knowledge graph efficiently represents the patient-centred input documents with 23\\% of the original text while retaining 90\\% of the information. We assess the effectiveness of this graph for automated ICD-9 coding by integrating it into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments yield improved Macro-F1 scores by up to 3.20\\% on popular benchmarks, while improving training efficiency. We attribute this improvement to different types of entities and relationships in the KG, and demonstrate the improved explainability potential of the approach over the text-only baseline.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨ ICD ç¼–ç ä¸­è¾“å…¥æ–‡æ¡£è¡¨ç¤ºä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ‚£è€…çº§åˆ« Knowledge Graphs (KGs) çš„ç»“æ„åŒ–ä¿¡æ¯å¤„ç†æ–¹æ³•ã€‚é€šè¿‡æ„å»ºæ–‡æ¡£çº§çŸ¥è¯†å›¾è°±ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»¥ä»… 23% çš„åŸå§‹æ–‡æœ¬é‡ä¿ç•™ 90% çš„å…³é”®ä¿¡æ¯ï¼Œä»è€Œé«˜æ•ˆè¡¨å¾æ‚£è€…ç—…å†µã€‚å®éªŒå°†è¯¥ç»“æ„åŒ–è¡¨ç¤ºé›†æˆåˆ°ç°æœ‰çš„ PLM-ICD æ¶æ„ä¸­ï¼Œåœ¨ä¸»æµåŸºå‡†æµ‹è¯•ä¸Šä½¿ Macro-F1 åˆ†æ•°æå‡äº†é«˜è¾¾ 3.20%ï¼Œå¹¶æ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚ç ”ç©¶è¿›ä¸€æ­¥åˆ†æäº†çŸ¥è¯†å›¾è°±ä¸­ä¸åŒå®ä½“å’Œå…³ç³»å¯¹æ€§èƒ½çš„è´¡çŒ®ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¯è§£é‡Šæ€§ (explainability) æ–¹é¢ç›¸è¾ƒäºçº¯æ–‡æœ¬ baseline çš„æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºåŒ»ç–—ä¿¡æ¯çš„è‡ªåŠ¨åŒ–æå–å’Œåˆ†ææä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09699v1",
      "published_date": "2025-09-04 12:01:38 UTC",
      "updated_date": "2025-09-04 12:01:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:18.159097+00:00"
    },
    {
      "arxiv_id": "2509.04130v1",
      "title": "The human biological advantage over AI",
      "title_zh": "äººç±»ç›¸è¾ƒäºäººå·¥æ™ºèƒ½çš„ç”Ÿç‰©å­¦ä¼˜åŠ¿",
      "authors": [
        "William Stewart"
      ],
      "abstract": "Recent advances in AI raise the possibility that AI systems will one day be able to do anything humans can do, only better. If artificial general intelligence (AGI) is achieved, AI systems may be able to understand, reason, problem solve, create, and evolve at a level and speed that humans will increasingly be unable to match, or even understand. These possibilities raise a natural question as to whether AI will eventually become superior to humans, a successor \"digital species\", with a rightful claim to assume leadership of the universe. However, a deeper consideration suggests the overlooked differentiator between human beings and AI is not the brain, but the central nervous system (CNS), providing us with an immersive integration with physical reality. It is our CNS that enables us to experience emotion including pain, joy, suffering, and love, and therefore to fully appreciate the consequences of our actions on the world around us. And that emotional understanding of the consequences of our actions is what is required to be able to develop sustainable ethical systems, and so be fully qualified to be the leaders of the universe. A CNS cannot be manufactured or simulated; it must be grown as a biological construct. And so, even the development of consciousness will not be sufficient to make AI systems superior to humans. AI systems may become more capable than humans on almost every measure and transform our society. However, the best foundation for leadership of our universe will always be DNA, not silicon.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨é€šç”¨äººå·¥æ™ºèƒ½(AGI)å¯èƒ½è¶…è¶Šäººç±»è®¤çŸ¥æ°´å¹³çš„èƒŒæ™¯ä¸‹ï¼Œäººç±»æ˜¯å¦ä¼šå¤±å»å¯¹å®‡å®™é¢†å¯¼åœ°ä½çš„é—®é¢˜ã€‚ä½œè€…æŒ‡å‡ºï¼Œäººç±»ä¸äººå·¥æ™ºèƒ½(AI)ä¹‹é—´è¢«å¿½è§†çš„æ ¸å¿ƒå·®å¼‚ä¸åœ¨äºå¤§è„‘ï¼Œè€Œåœ¨äºèƒ½å¤Ÿæä¾›ç‰©ç†ç°å®æ²‰æµ¸æ„Ÿçš„ä¸­æ¢ç¥ç»ç³»ç»Ÿ(CNS)ã€‚ä¸­æ¢ç¥ç»ç³»ç»Ÿ(CNS)ä½¿äººç±»èƒ½å¤Ÿä½“éªŒç—›è‹¦ä¸çˆ±ç­‰æƒ…æ„Ÿå¹¶ç†è§£è¡Œä¸ºçš„åæœï¼Œè¿™æ˜¯æ„å»ºå¯æŒç»­ä¼¦ç†ä½“ç³»çš„å…³é”®å‰æã€‚è®ºæ–‡å¼ºè°ƒï¼Œä¸­æ¢ç¥ç»ç³»ç»Ÿ(CNS)å¿…é¡»ä½œä¸ºç”Ÿç‰©ç»“æ„ç”Ÿé•¿è€Œæ— æ³•è¢«æ¨¡æ‹Ÿï¼Œå› æ­¤å³ä½¿AIå…·å¤‡äº†æ„è¯†ä¹Ÿæ— æ³•åœ¨æœ¬è´¨ä¸Šä¼˜äºäººç±»ã€‚ç ”ç©¶æœ€ç»ˆè®¤ä¸ºï¼Œå°½ç®¡AIåœ¨å‡ ä¹æ‰€æœ‰è¡¡é‡æŒ‡æ ‡ä¸Šå¯èƒ½å…¨é¢é¢†å…ˆï¼Œä½†åŸºäºDNAçš„ç”Ÿç‰©å®ä½“åœ¨é¢†å¯¼åŠ›åŸºç¡€æ–¹é¢ä¾ç„¶å…·æœ‰ä¸å¯æ›¿ä»£çš„ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.04130v1",
      "published_date": "2025-09-04 11:54:27 UTC",
      "updated_date": "2025-09-04 11:54:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:23.564635+00:00"
    },
    {
      "arxiv_id": "2509.04129v1",
      "title": "Simplicity Lies in the Eye of the Beholder: A Strategic Perspective on Controllers in Reactive Synthesis",
      "title_zh": "ç®€ä¹‹å®šä¹‰ï¼Œè§ä»è§æ™ºï¼šååº”å¼åˆæˆä¸­æ§åˆ¶å™¨çš„ç­–ç•¥è§†è§’",
      "authors": [
        "Mickael Randour"
      ],
      "abstract": "In the game-theoretic approach to controller synthesis, we model the interaction between a system to be controlled and its environment as a game between these entities, and we seek an appropriate (e.g., winning or optimal) strategy for the system. This strategy then serves as a formal blueprint for a real-world controller. A common belief is that simple (e.g., using limited memory) strategies are better: corresponding controllers are easier to conceive and understand, and cheaper to produce and maintain.\n  This invited contribution focuses on the complexity of strategies in a variety of synthesis contexts. We discuss recent results concerning memory and randomness, and take a brief look at what lies beyond our traditional notions of complexity for strategies.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†ååº”å¼åˆæˆ (Reactive Synthesis) ä¸­æ§åˆ¶å™¨åˆæˆçš„åšå¼ˆè®ºæ–¹æ³•ï¼Œå°†ç³»ç»Ÿä¸ç¯å¢ƒçš„äº¤äº’å»ºæ¨¡ä¸ºåšå¼ˆè¿‡ç¨‹ã€‚ç³»ç»Ÿé€šè¿‡å¯»æ±‚è·èƒœæˆ–æœ€ä¼˜ç­–ç•¥ (Strategy) ä¸ºå®é™…æ§åˆ¶å™¨æä¾›æ­£å¼è“å›¾ï¼Œè€Œä¼ ç»Ÿè§‚ç‚¹å€¾å‘äºç®€å•çš„ç­–ç•¥ï¼Œå¦‚ä½¿ç”¨æœ‰é™å­˜å‚¨ (Limited Memory)ï¼Œè®¤ä¸ºå…¶æ›´æ˜“äºç†è§£ä¸”ç»´æŠ¤æˆæœ¬æ›´ä½ã€‚è¯¥ç ”ç©¶é‡ç‚¹åˆ†æäº†å¤šç§åˆæˆèƒŒæ™¯ä¸‹ç­–ç•¥çš„å¤æ‚åº¦ï¼Œå¹¶è®¨è®ºäº†å…³äºå­˜å‚¨ (Memory) ä¸éšæœºæ€§ (Randomness) çš„æœ€æ–°ç ”ç©¶æˆæœã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è¿›ä¸€æ­¥å±•æœ›äº†è¶…è¶Šä¼ ç»Ÿå¤æ‚åº¦å®šä¹‰çš„é¢†åŸŸï¼Œå¯¹ç­–ç•¥ç®€å•æ€§çš„æœ¬è´¨æå‡ºäº†æˆ˜ç•¥æ€§çš„è§†è§’ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.FL",
        "math.PR"
      ],
      "primary_category": "cs.LO",
      "comment": "Invited paper at RP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04129v1",
      "published_date": "2025-09-04 11:54:19 UTC",
      "updated_date": "2025-09-04 11:54:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:26.753203+00:00"
    },
    {
      "arxiv_id": "2509.05375v1",
      "title": "Characterizing Fitness Landscape Structures in Prompt Engineering",
      "title_zh": "æç¤ºå·¥ç¨‹ä¸­é€‚åº”åº¦æ™¯è§‚ç»“æ„çš„è¡¨å¾",
      "authors": [
        "Arend Hintze"
      ],
      "abstract": "While prompt engineering has emerged as a crucial technique for optimizing large language model performance, the underlying optimization landscape remains poorly understood. Current approaches treat prompt optimization as a black-box problem, applying sophisticated search algorithms without characterizing the landscape topology they navigate. We present a systematic analysis of fitness landscape structures in prompt engineering using autocorrelation analysis across semantic embedding spaces. Through experiments on error detection tasks with two distinct prompt generation strategies -- systematic enumeration (1,024 prompts) and novelty-driven diversification (1,000 prompts) -- we reveal fundamentally different landscape topologies. Systematic prompt generation yields smoothly decaying autocorrelation, while diversified generation exhibits non-monotonic patterns with peak correlation at intermediate semantic distances, indicating rugged, hierarchically structured landscapes. Task-specific analysis across 10 error detection categories reveals varying degrees of ruggedness across different error types. Our findings provide an empirical foundation for understanding the complexity of optimization in prompt engineering landscapes.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåˆ†æäº†æç¤ºå·¥ç¨‹ (Prompt Engineering) ä¸­çš„é€‚åº”åº¦åœ°å½¢ (Fitness Landscape) ç»“æ„ï¼Œæ—¨åœ¨æ­ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½ä¼˜åŒ–èƒŒåçš„æ‹“æ‰‘ç‰¹å¾ã€‚ç ”ç©¶äººå‘˜é€šè¿‡åœ¨è¯­ä¹‰åµŒå…¥ç©ºé—´ä¸­è¿›è¡Œè‡ªç›¸å…³åˆ†æ (Autocorrelation Analysis)ï¼Œé‡åŒ–å¹¶å¯¹æ¯”äº†ä¸åŒæç¤ºç”Ÿæˆç­–ç•¥ä¸‹çš„æ™¯è§‚å¤æ‚æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç³»ç»Ÿæšä¸¾ (Systematic Enumeration) ç”Ÿæˆçš„æç¤ºå‘ˆç°å¹³æ»‘è¡°å‡çš„è‡ªç›¸å…³ç‰¹æ€§ï¼Œè€Œæ–°é¢–é©±åŠ¨çš„å¤šæ ·åŒ– (Novelty-driven Diversification) ç­–ç•¥åˆ™è¡¨ç°å‡ºéå•è°ƒæ¨¡å¼ï¼Œæ­ç¤ºäº†å´å²–ä¸”å…·æœ‰å±‚æ¬¡ç»“æ„çš„æ‹“æ‰‘æ™¯è§‚ã€‚é’ˆå¯¹ 10 ç±»é”™è¯¯æ£€æµ‹ä»»åŠ¡çš„åˆ†æè¿›ä¸€æ­¥è¯å®ï¼Œä¸åŒä»»åŠ¡ç±»å‹åœ¨åœ°å½¢å´å²–ç¨‹åº¦ (Ruggedness) ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚è¿™é¡¹å·¥ä½œä¸ºç†è§£æç¤ºå·¥ç¨‹ä¼˜åŒ–é—®é¢˜çš„å¤æ‚æ€§æä¾›äº†å®è¯åŸºç¡€ï¼Œä¸ºæœªæ¥å¼€å‘æ›´é«˜æ•ˆçš„æç¤ºä¼˜åŒ–ç®—æ³•æä¾›äº†ç†è®ºæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05375v1",
      "published_date": "2025-09-04 11:52:19 UTC",
      "updated_date": "2025-09-04 11:52:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:28.064267+00:00"
    },
    {
      "arxiv_id": "2509.04126v2",
      "title": "MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image Generation",
      "title_zh": "MEPGï¼šé¢å‘ä¸°å¯Œç»„åˆå›¾åƒç”Ÿæˆçš„å¤šä¸“å®¶è§„åˆ’ä¸ç”Ÿæˆ",
      "authors": [
        "Yuan Zhao",
        "Lin Liu"
      ],
      "abstract": "Text-to-image diffusion models have achieved remarkable image quality, but they still struggle with complex, multiele ment prompts, and limited stylistic diversity. To address these limitations, we propose a Multi-Expert Planning and Gen eration Framework (MEPG) that synergistically integrates position- and style-aware large language models (LLMs) with spatial-semantic expert modules. The framework comprises two core components: (1) a Position-Style-Aware (PSA) module that utilizes a supervised fine-tuned LLM to decom pose input prompts into precise spatial coordinates and style encoded semantic instructions; and (2) a Multi-Expert Dif fusion (MED) module that implements cross-region genera tion through dynamic expert routing across both local regions and global areas. During the generation process for each lo cal region, specialized models (e.g., realism experts, styliza tion specialists) are selectively activated for each spatial par tition via attention-based gating mechanisms. The architec ture supports lightweight integration and replacement of ex pert models, providing strong extensibility. Additionally, an interactive interface enables real-time spatial layout editing and per-region style selection from a portfolio of experts. Ex periments show that MEPG significantly outperforms base line models with the same backbone in both image quality\n  and style diversity.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MEPGï¼Œä¸€ä¸ªå¤šä¸“å®¶è§„åˆ’ä¸ç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ–‡æœ¬ç”Ÿæˆå›¾åƒ (Text-to-image) æ‰©æ•£æ¨¡å‹åœ¨å¤„ç†å¤æ‚ã€å¤šå…ƒç´ æç¤ºè¯ä»¥åŠé£æ ¼å¤šæ ·æ€§æ–¹é¢çš„å±€é™ã€‚è¯¥æ¡†æ¶ç”±ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼šé¦–å…ˆæ˜¯ Position-Style-Aware (PSA) æ¨¡å—ï¼Œåˆ©ç”¨ç»è¿‡ç›‘ç£å¾®è°ƒçš„ LLM å°†è¾“å…¥æç¤ºåˆ†è§£ä¸ºç²¾ç¡®çš„ç©ºé—´åæ ‡å’Œç¼–ç äº†é£æ ¼çš„è¯­ä¹‰æŒ‡ä»¤ï¼›å…¶æ¬¡æ˜¯ Multi-Expert Diffusion (MED) æ¨¡å—ï¼Œé€šè¿‡åœ¨å±€éƒ¨åŒºåŸŸå’Œå…¨å±€åŒºåŸŸé—´è¿›è¡ŒåŠ¨æ€ä¸“å®¶è·¯ç”± (dynamic expert routing) å®ç°è·¨åŒºåŸŸç”Ÿæˆã€‚åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿåˆ©ç”¨åŸºäºæ³¨æ„åŠ›çš„é—¨æ§æœºåˆ¶ (attention-based gating mechanisms) ä¸ºæ¯ä¸ªç©ºé—´åˆ†åŒºé€‰æ‹©æ€§åœ°æ¿€æ´» realism æˆ– stylization ç­‰ä¸“é—¨ä¸“å®¶æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¶æ„æ”¯æŒä¸“å®¶æ¨¡å‹çš„è½»é‡çº§é›†æˆä¸æ›¿æ¢ï¼Œå¹¶æä¾›å¯å®æ—¶ç¼–è¾‘ç©ºé—´å¸ƒå±€å’Œé£æ ¼çš„äº¤äº’ç•Œé¢ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒMEPG åœ¨å›¾åƒè´¨é‡å’Œé£æ ¼å¤šæ ·æ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç›¸åŒéª¨å¹²ç½‘ç»œçš„åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04126v2",
      "published_date": "2025-09-04 11:44:28 UTC",
      "updated_date": "2025-09-14 00:18:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:30.362764+00:00"
    },
    {
      "arxiv_id": "2509.04544v1",
      "title": "i-Mask: An Intelligent Mask for Breath-Driven Activity Recognition",
      "title_zh": "i-Maskï¼šä¸€ç§ç”¨äºå‘¼å¸é©±åŠ¨æ´»åŠ¨è¯†åˆ«çš„æ™ºèƒ½å£ç½©",
      "authors": [
        "Ashutosh Kumar Sinha",
        "Ayush Patel",
        "Mitul Dudhat",
        "Pritam Anand",
        "Rahul Mishra"
      ],
      "abstract": "The patterns of inhalation and exhalation contain important physiological signals that can be used to anticipate human behavior, health trends, and vital parameters. Human activity recognition (HAR) is fundamentally connected to these vital signs, providing deeper insights into well-being and enabling real-time health monitoring. This work presents i-Mask, a novel HAR approach that leverages exhaled breath patterns captured using a custom-developed mask equipped with integrated sensors. Data collected from volunteers wearing the mask undergoes noise filtering, time-series decomposition, and labeling to train predictive models. Our experimental results validate the effectiveness of the approach, achieving over 95\\% accuracy and highlighting its potential in healthcare and fitness applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º i-Mask çš„æ–°å‹äººç±»æ´»åŠ¨è¯†åˆ« (Human Activity Recognition, HAR) æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡å®šåˆ¶é¢ç½©æ•è·çš„å‘¼å¸æ¨¡å¼ç›‘æµ‹äººç±»è¡Œä¸ºä¸å¥åº·è¶‹åŠ¿ã€‚è¯¥æ¡†æ¶åˆ©ç”¨é›†æˆä¼ æ„Ÿå™¨æ”¶é›†å¸æ°”å’Œå‘¼æ°”æ•°æ®ï¼Œå¹¶ç»è¿‡å™ªå£°è¿‡æ»¤ (noise filtering)ã€æ—¶é—´åºåˆ—åˆ†è§£ (time-series decomposition) åŠæ•°æ®æ ‡æ³¨ç­‰è¿‡ç¨‹æ¥è®­ç»ƒé¢„æµ‹æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œi-Mask åœ¨æ´»åŠ¨è¯†åˆ«ä»»åŠ¡ä¸­è¾¾åˆ°äº†è¶…è¿‡ 95% çš„å‡†ç¡®ç‡ï¼ŒéªŒè¯äº†å…¶æ•è·ç”Ÿç†ä¿¡å·çš„ç²¾ç¡®æ€§ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†å‘¼å¸é©±åŠ¨ç›‘æµ‹æŠ€æœ¯åœ¨åŒ»ç–—ä¿å¥å’Œå¥èº«é¢†åŸŸçš„å¹¿æ³›åº”ç”¨æ½œåŠ›ï¼Œä¸ºå®ç°å®æ—¶ã€æ·±åº¦çš„ä¸ªäººå¥åº·ç›‘æµ‹å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 Pages, 10 Figures",
      "pdf_url": "https://arxiv.org/pdf/2509.04544v1",
      "published_date": "2025-09-04 11:42:43 UTC",
      "updated_date": "2025-09-04 11:42:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:41.784546+00:00"
    },
    {
      "arxiv_id": "2509.04125v1",
      "title": "Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker",
      "title_zh": "Leduc å¾·å·æ‰‘å…‹ä¸­ DQN ä¸ CFR çš„è¯ˆå”¬è¡Œä¸ºåˆ†æ",
      "authors": [
        "Tarik Zaciragic",
        "Aske Plaat",
        "K. Joost Batenburg"
      ],
      "abstract": "In the game of poker, being unpredictable, or bluffing, is an essential skill. When humans play poker, they bluff. However, most works on computer-poker focus on performance metrics such as win rates, while bluffing is overlooked. In this paper we study whether two popular algorithms, DQN (based on reinforcement learning) and CFR (based on game theory), exhibit bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed an experiment where we let the DQN and CFR agent play against each other while we log their actions. We find that both DQN and CFR exhibit bluffing behavior, but they do so in different ways. Although both attempt to perform bluffs at different rates, the percentage of successful bluffs (where the opponent folds) is roughly the same. This suggests that bluffing is an essential aspect of the game, not of the algorithm. Future work should look at different bluffing styles and at the full game of poker. Code at https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ·±åº¦Qç½‘ç»œ(DQN)å’Œåäº‹å®é—æ†¾æœ€å°åŒ–(CFR)ç®—æ³•åœ¨ç®€åŒ–ç‰ˆæ‰‘å…‹æ¸¸æˆLeduc Hold'emä¸­æ˜¯å¦è¡¨ç°å‡ºè™šå¼ å£°åŠ¿(bluffing)è¡Œä¸ºï¼Œå¡«è¡¥äº†è¿‡å¾€ç ”ç©¶ä¸»è¦å…³æ³¨èƒœç‡è€Œå¿½è§†åšå¼ˆç­–ç•¥çš„ç©ºç™½ã€‚ç ”ç©¶äººå‘˜è®¾è®¡äº†ä¸€é¡¹å®éªŒï¼Œè®©åŸºäºå¼ºåŒ–å­¦ä¹ (RL)çš„DQNæ™ºèƒ½ä½“ä¸åŸºäºåšå¼ˆè®ºçš„CFRæ™ºèƒ½ä½“è¿›è¡Œå¯¹æˆ˜å¹¶è®°å½•å…¶å†³ç­–è¡Œä¸ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDQNå’ŒCFRå‡è¡¨ç°å‡ºäº†æ˜æ˜¾çš„è™šå¼ å£°åŠ¿è¡Œä¸ºï¼Œä½†ä¸¤è€…åœ¨å®æ–½æ–¹å¼å’Œé¢‘ç‡ä¸Šå­˜åœ¨å·®å¼‚ã€‚å°½ç®¡å°è¯•é¢‘ç‡ä¸åŒï¼Œä¸¤ç§ç®—æ³•è™šå¼ å£°åŠ¿çš„æˆåŠŸç‡ï¼ˆå³å¯¼è‡´å¯¹æ‰‹å¼ƒç‰Œçš„æ¯”ä¾‹ï¼‰åŸºæœ¬æŒå¹³ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œè™šå¼ å£°åŠ¿æ˜¯æ‰‘å…‹åšå¼ˆæœ¬èº«çš„æœ¬è´¨å±æ€§ï¼Œè€Œéç‰¹å®šç®—æ³•çš„äº§ç‰©ã€‚æœªæ¥å·¥ä½œå°†è¿›ä¸€æ­¥ç ”ç©¶ä¸åŒçš„è™šå¼ å£°åŠ¿é£æ ¼ä»¥åŠåœ¨å®Œæ•´æ‰‘å…‹æ¸¸æˆä¸­çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04125v1",
      "published_date": "2025-09-04 11:40:24 UTC",
      "updated_date": "2025-09-04 11:40:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:41.086703+00:00"
    },
    {
      "arxiv_id": "2509.04118v1",
      "title": "EHVC: Efficient Hierarchical Reference and Quality Structure for Neural Video Coding",
      "title_zh": "EHVCï¼šç¥ç»è§†é¢‘ç¼–ç çš„é«˜æ•ˆå±‚çº§å‚è€ƒä¸è´¨é‡ç»“æ„",
      "authors": [
        "Junqi Liao",
        "Yaojun Wu",
        "Chaoyi Lin",
        "Zhipin Deng",
        "Li Li",
        "Dong Liu",
        "Xiaoyan Sun"
      ],
      "abstract": "Neural video codecs (NVCs), leveraging the power of end-to-end learning, have demonstrated remarkable coding efficiency improvements over traditional video codecs. Recent research has begun to pay attention to the quality structures in NVCs, optimizing them by introducing explicit hierarchical designs. However, less attention has been paid to the reference structure design, which fundamentally should be aligned with the hierarchical quality structure. In addition, there is still significant room for further optimization of the hierarchical quality structure. To address these challenges in NVCs, we propose EHVC, an efficient hierarchical neural video codec featuring three key innovations: (1) a hierarchical multi-reference scheme that draws on traditional video codec design to align reference and quality structures, thereby addressing the reference-quality mismatch; (2) a lookahead strategy to utilize an encoder-side context from future frames to enhance the quality structure; (3) a layer-wise quality scale with random quality training strategy to stabilize quality structures during inference. With these improvements, EHVC achieves significantly superior performance to the state-of-the-art NVCs. Code will be released in: https://github.com/bytedance/NEVC.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EHVCï¼Œä¸€ç§é’ˆå¯¹ç¥ç»è§†é¢‘ç¼–ç (Neural video codecs, NVCs)çš„é«˜æ•ˆå±‚æ¬¡åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹ä¸­å‚è€ƒç»“æ„ä¸åˆ†å±‚è´¨é‡ç»“æ„ä¸åŒ¹é…çš„é—®é¢˜ã€‚EHVCå¼•å…¥äº†å±‚æ¬¡åŒ–å¤šå‚è€ƒæ–¹æ¡ˆ(hierarchical multi-reference scheme)ï¼Œé€šè¿‡å€Ÿé‰´ä¼ ç»Ÿç¼–è§£ç å™¨è®¾è®¡å®ç°äº†å‚è€ƒä¸è´¨é‡ç»“æ„çš„æ·±åº¦å¯¹é½ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†å‰ç»ç­–ç•¥(lookahead strategy)ï¼Œåˆ©ç”¨ç¼–ç å™¨ç«¯çš„æœªæ¥å¸§ä¸Šä¸‹æ–‡å¢å¼ºè´¨é‡ç»“æ„ï¼Œå¹¶ç»“åˆé€å±‚è´¨é‡ç¼©æ”¾(layer-wise quality scale)ä¸éšæœºè´¨é‡è®­ç»ƒç­–ç•¥æ¥æå‡æ¨ç†é˜¶æ®µçš„ç¨³å®šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEHVCåœ¨ç¼–ç æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„ç¥ç»è§†é¢‘ç¼–ç å™¨(SOTA NVCs)ã€‚è¯¥å·¥ä½œé€šè¿‡å¯¹åˆ†å±‚å‚è€ƒä¸è´¨é‡ä½“ç³»çš„ååŒä¼˜åŒ–ï¼Œä¸ºç«¯åˆ°ç«¯è§†é¢‘å‹ç¼©æŠ€æœ¯æä¾›äº†æ›´é«˜æ•ˆçš„å®ç°è·¯å¾„ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "9 pages, 8 figures, Accepted to ACMMM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04118v1",
      "published_date": "2025-09-04 11:31:12 UTC",
      "updated_date": "2025-09-04 11:31:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:44.091719+00:00"
    },
    {
      "arxiv_id": "2509.04100v1",
      "title": "Hybrid Reinforcement Learning and Search for Flight Trajectory Planning",
      "title_zh": "èåˆå¼ºåŒ–å­¦ä¹ ä¸æœç´¢çš„é£è¡Œè½¨è¿¹è§„åˆ’",
      "authors": [
        "Alberto Luise",
        "Michele Lombardi",
        "Florent Teichteil Koenigsbuch"
      ],
      "abstract": "This paper explores the combination of Reinforcement Learning (RL) and search-based path planners to speed up the optimization of flight paths for airliners, where in case of emergency a fast route re-calculation can be crucial. The fundamental idea is to train an RL Agent to pre-compute near-optimal paths based on location and atmospheric data and use those at runtime to constrain the underlying path planning solver and find a solution within a certain distance from the initial guess. The approach effectively reduces the size of the solver's search space, significantly speeding up route optimization. Although global optimality is not guaranteed, empirical results conducted with Airbus aircraft's performance models show that fuel consumption remains nearly identical to that of an unconstrained solver, with deviations typically within 1%. At the same time, computation speed can be improved by up to 50% as compared to using a conventional solver alone.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç´§æ€¥æƒ…å†µä¸‹å®¢æœºé£è¡Œè·¯å¾„å¿«é€Ÿé‡è®¡ç®—çš„éœ€æ±‚ï¼Œæ¢ç´¢äº†å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)ä¸åŸºäºæœç´¢çš„è·¯å¾„è§„åˆ’ç®—æ³•çš„ç»“åˆã€‚å…¶æ ¸å¿ƒæ€è·¯æ˜¯è®­ç»ƒä¸€ä¸ªå¼ºåŒ–å­¦ä¹ (RL)æ™ºèƒ½ä½“ï¼ŒåŸºäºåœ°ç†ä½ç½®å’Œå¤§æ°”æ•°æ®é¢„è®¡ç®—è¿‘ä¹æœ€ä¼˜çš„è·¯å¾„ï¼Œå¹¶åœ¨è¿è¡Œæ—¶åˆ©ç”¨è¯¥ç»“æœçº¦æŸåº•å±‚è·¯å¾„è§„åˆ’æ±‚è§£å™¨çš„æœç´¢ç©ºé—´ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°ç¼©å°äº†æ±‚è§£å™¨çš„æœç´¢èŒƒå›´ï¼Œæ˜¾è‘—åŠ å¿«äº†è·¯å¾„ä¼˜åŒ–é€Ÿåº¦ã€‚è™½ç„¶è¯¥æ–¹æ³•ä¸ä¿è¯å…¨å±€æœ€ä¼˜ï¼Œä½†åŸºäºAirbusé£æœºæ€§èƒ½æ¨¡å‹çš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶ç‡ƒæ²¹æ¶ˆè€—ä¸æ— çº¦æŸæ±‚è§£å™¨ç›¸æ¯”åå·®é€šå¸¸åœ¨1%ä»¥å†…ã€‚åŒæ—¶ï¼Œè¯¥æ··åˆæ–¹æ³•åœ¨è®¡ç®—é€Ÿåº¦ä¸Šæ¯”å•ç‹¬ä½¿ç”¨ä¼ ç»Ÿæ±‚è§£å™¨æå‡äº†é«˜è¾¾50%ï¼Œä¸ºé«˜æ•ˆã€å®æ—¶çš„é£è¡Œè½¨è¿¹è§„åˆ’æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04100v1",
      "published_date": "2025-09-04 11:01:43 UTC",
      "updated_date": "2025-09-04 11:01:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:34:45.892371+00:00"
    },
    {
      "arxiv_id": "2509.04083v1",
      "title": "Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning",
      "title_zh": "ä¸­é—´è¯­è¨€è‡³å…³é‡è¦ï¼šå½¢å¼è¯­è¨€ä¸å¤§è¯­è¨€æ¨¡å‹å¯¹ç¥ç»ç¬¦å·æ¨ç†çš„å½±å“",
      "authors": [
        "Alexander Beiser",
        "David Penz",
        "Nysret Musliu"
      ],
      "abstract": "Large language models (LLMs) achieve astonishing results on a wide range of tasks. However, their formal reasoning ability still lags behind. A promising approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators from natural to formal languages and symbolic solvers for deriving correct results. Still, the contributing factors to the success of Neurosymbolic LLM reasoning remain unclear. This paper demonstrates that one previously overlooked factor is the choice of the formal language. We introduce the intermediate language challenge: selecting a suitable formal language for neurosymbolic reasoning. By comparing four formal languages across three datasets and seven LLMs, we show that the choice of formal language affects both syntactic and semantic reasoning capabilities. We also discuss the varying effects across different LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å½¢å¼åŒ–æ¨ç†æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶èšç„¦äºç¥ç»ç¬¦å·æ¨ç†(Neurosymbolic LLM reasoning)ä¸­ä¸€ä¸ªå¸¸è¢«å¿½è§†çš„å…³é”®å› ç´ ï¼šä¸­é—´è¯­è¨€çš„é€‰æ‹©ã€‚é€šè¿‡å°†LLMsä½œä¸ºè‡ªç„¶è¯­è¨€åˆ°å½¢å¼è¯­è¨€(Formal Languages)çš„ç¿»è¯‘å™¨å¹¶ç»“åˆç¬¦å·æ±‚è§£å™¨ï¼Œç ”ç©¶è€…æå‡ºäº†â€œä¸­é—´è¯­è¨€æŒ‘æˆ˜â€ï¼Œæ—¨åœ¨æ¢è®¨å¦‚ä½•ä¸ºç¥ç»ç¬¦å·æ¨ç†é€‰æ‹©æœ€åˆé€‚çš„å½¢å¼åŒ–è¡¨è¾¾ã€‚å®éªŒé€šè¿‡åœ¨ä¸‰ä¸ªæ•°æ®é›†å’Œä¸ƒä¸ªLLMsä¸Šå¯¹æ¯”å››ç§å½¢å¼è¯­è¨€ï¼Œè¯æ˜äº†ä¸­é—´è¯­è¨€çš„é€‰æ‹©ä¼šæ˜¾è‘—å½±å“æ¨¡å‹çš„è¯­æ³•å’Œè¯­ä¹‰æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ·±å…¥è®¨è®ºäº†ä¸åŒLLMsåœ¨å¤„ç†è¿™äº›å½¢å¼è¯­è¨€æ—¶è¡¨ç°å‡ºçš„å·®å¼‚åŒ–æ•ˆæœï¼Œå¼ºè°ƒäº†ä¸­é—´è¯­è¨€åœ¨æ„å»ºé«˜æ•ˆç¥ç»ç¬¦å·ç³»ç»Ÿä¸­çš„æ ¸å¿ƒåœ°ä½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in the proceedings of The Second Workshop on Knowledge Graphs and Neurosymbolic AI (KG-NeSy) Co-located with SEMANTiCS 2025 Conference, Vienna, Austria - September 3rd, 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04083v1",
      "published_date": "2025-09-04 10:25:50 UTC",
      "updated_date": "2025-09-04 10:25:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:11.591689+00:00"
    },
    {
      "arxiv_id": "2509.04078v2",
      "title": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models",
      "title_zh": "RepoDebugï¼šå¤§è¯­è¨€æ¨¡å‹ä»“åº“çº§å¤šä»»åŠ¡ä¸å¤šè¯­è¨€ä»£ç è°ƒè¯•è¯„ä¼°",
      "authors": [
        "Jingjing Liu",
        "Zeming Liu",
        "Zihao Cheng",
        "Mengliang He",
        "Xiaoming Shi",
        "Yuhang Guo",
        "Xiangrong Zhu",
        "Yuanfang Guo",
        "Yunhong Wang",
        "Haifeng Wang"
      ],
      "abstract": "Large Language Models (LLMs) have exhibited significant proficiency in code debugging, especially in automatic program repair, which may substantially reduce the time consumption of developers and enhance their efficiency. Significant advancements in debugging datasets have been made to promote the development of code debugging. However, these datasets primarily focus on assessing the LLM's function-level code repair capabilities, neglecting the more complex and realistic repository-level scenarios, which leads to an incomplete understanding of the LLM's challenges in repository-level debugging. While several repository-level datasets have been proposed, they often suffer from limitations such as limited diversity of tasks, languages, and error types. To mitigate this challenge, this paper introduces RepoDebug, a multi-task and multi-language repository-level code debugging dataset with 22 subtypes of errors that supports 8 commonly used programming languages and 3 debugging tasks. Furthermore, we conduct evaluation experiments on 10 LLMs, where Claude 3.5 Sonnect, the best-performing model, still cannot perform well in repository-level debugging.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œå°½ç®¡å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å‡½æ•°çº§ä»£ç ä¿®å¤ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç°æœ‰æ•°æ®é›†ç¼ºä¹å¯¹å¤æ‚ä»“åº“çº§(Repository-Level)è°ƒè¯•åœºæ™¯çš„å……åˆ†è¦†ç›–ï¼Œä¸”åœ¨ä»»åŠ¡ã€è¯­è¨€å’Œé”™è¯¯ç±»å‹å¤šæ ·æ€§ä¸Šå­˜åœ¨å±€é™ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æ¨å‡ºäº†RepoDebugï¼Œè¿™æ˜¯ä¸€ä¸ªæ”¯æŒ8ç§å¸¸ç”¨ç¼–ç¨‹è¯­è¨€å’Œ3é¡¹è°ƒè¯•ä»»åŠ¡çš„å¤šä»»åŠ¡ã€å¤šè¯­è¨€ä»“åº“çº§ä»£ç è°ƒè¯•è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº†22ç§ç»†åˆ†çš„é”™è¯¯ç±»å‹ã€‚é€šè¿‡å¯¹10ç§ä¸»æµå¤§è¯­è¨€æ¨¡å‹çš„å®éªŒè¯„ä¼°å‘ç°ï¼Œå³ä¾¿æ˜¯åœ¨è¯¥åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æœ€ä¼˜çš„Claude 3.5 Sonnectï¼Œåœ¨åº”å¯¹ä»“åº“çº§è°ƒè¯•æ—¶ä¾ç„¶éš¾ä»¥è¾¾åˆ°ç†æƒ³æ•ˆæœã€‚è¿™é¡¹å·¥ä½œæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨å¤„ç†å¤§è§„æ¨¡ã€å¤šæ–‡ä»¶åä½œä»£ç ç¯å¢ƒä¸‹çš„å±€é™æ€§ã€‚RepoDebugçš„æå‡ºä¸ºæ·±å…¥ç†è§£å’Œæ”¹è¿›å¤§è¯­è¨€æ¨¡å‹åœ¨çœŸå®è½¯ä»¶ä»“åº“ä¸­çš„è°ƒè¯•æ•ˆèƒ½æä¾›äº†é‡è¦çš„åŸºå‡†å’Œè¯„ä»·ä½“ç³»ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "30 pages, 12 figures, EMNLP 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2509.04078v2",
      "published_date": "2025-09-04 10:13:21 UTC",
      "updated_date": "2025-09-08 08:22:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:04.099704+00:00"
    },
    {
      "arxiv_id": "2509.04076v2",
      "title": "Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot",
      "title_zh": "NICOL æœºå™¨äººä¸ŠåŸºäºå…³é”®ç‚¹çš„è¿åŠ¨è§„åˆ’æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Lennart Clasmeier",
        "Jan-Gerrit Habekost",
        "Connor GÃ¤de",
        "Philipp Allgeuer",
        "Stefan Wermter"
      ],
      "abstract": "We propose a novel diffusion-based action model for robotic motion planning. Commonly, established numerical planning approaches are used to solve general motion planning problems, but have significant runtime requirements. By leveraging the power of deep learning, we are able to achieve good results in a much smaller runtime by learning from a dataset generated by these planners. While our initial model uses point cloud embeddings in the input to predict keypoint-based joint sequences in its output, we observed in our ablation study that it remained challenging to condition the network on the point cloud embeddings. We identified some biases in our dataset and refined it, which improved the model's performance. Our model, even without the use of the point cloud encodings, outperforms numerical models by an order of magnitude regarding the runtime, while reaching a success rate of up to 90% of collision free solutions on the test set.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨äººè¿åŠ¨è§„åˆ’ (Robotic motion planning) æå‡ºäº†ä¸€ç§æ–°å‹çš„åŸºäºæ‰©æ•£ (Diffusion-based) çš„åŠ¨ä½œæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ•°å€¼è§„åˆ’æ–¹æ³•è¿è¡Œæ—¶é—´è¿‡é•¿çš„é—®é¢˜ã€‚é€šè¿‡åœ¨æ•°å€¼è§„åˆ’å™¨ç”Ÿæˆçš„æ•°æ®é›†ä¸Šè¿›è¡Œå­¦ä¹ ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿æ˜¾è‘—ç¼©çŸ­äº†è§„åˆ’æ—¶é—´ã€‚ç ”ç©¶å›¢é˜Ÿæœ€åˆå°è¯•åˆ©ç”¨ç‚¹äº‘åµŒå…¥ (Point cloud embeddings) ä½œä¸ºè¾“å…¥æ¥é¢„æµ‹åŸºäºå…³é”®ç‚¹ (Keypoint-based) çš„å…³èŠ‚åºåˆ—ï¼Œå¹¶é’ˆå¯¹æ•°æ®é›†ä¸­çš„åç½®è¿›è¡Œäº†ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è¿è¡Œé€Ÿåº¦ä¸Šæ¯”æ•°å€¼æ¨¡å‹æé«˜äº†ä¸€ä¸ªæ•°é‡çº§ï¼Œå±•ç°å‡ºæé«˜çš„è®¡ç®—æ•ˆç‡ã€‚åœ¨æµ‹è¯•é›†ä¸Šï¼Œè¯¥æ¨¡å‹å®ç°äº†é«˜è¾¾ 90% çš„æ— ç¢°æ’è·¯å¾„è§„åˆ’æˆåŠŸç‡ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åŸºäºæ‰©æ•£çš„æ¨¡å‹åœ¨æå‡æœºå™¨äººè¿åŠ¨è§„åˆ’å®æ—¶æ€§æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted and published at the 34th International Conference on Artificial Neural Networks (ICANN 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.04076v2",
      "published_date": "2025-09-04 10:11:51 UTC",
      "updated_date": "2025-09-16 08:06:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:14.982261+00:00"
    },
    {
      "arxiv_id": "2509.04051v1",
      "title": "Neural Video Compression with In-Loop Contextual Filtering and Out-of-Loop Reconstruction Enhancement",
      "title_zh": "åŸºäºç¯å†…ä¸Šä¸‹æ–‡æ»¤æ³¢ä¸ç¯å¤–é‡å»ºå¢å¼ºçš„ç¥ç»è§†é¢‘å‹ç¼©",
      "authors": [
        "Yaojun Wu",
        "Chaoyi Lin",
        "Yiming Wang",
        "Semih Esenlik",
        "Zhaobin Zhang",
        "Kai Zhang",
        "Li Zhang"
      ],
      "abstract": "This paper explores the application of enhancement filtering techniques in neural video compression. Specifically, we categorize these techniques into in-loop contextual filtering and out-of-loop reconstruction enhancement based on whether the enhanced representation affects the subsequent coding loop. In-loop contextual filtering refines the temporal context by mitigating error propagation during frame-by-frame encoding. However, its influence on both the current and subsequent frames poses challenges in adaptively applying filtering throughout the sequence. To address this, we introduce an adaptive coding decision strategy that dynamically determines filtering application during encoding. Additionally, out-of-loop reconstruction enhancement is employed to refine the quality of reconstructed frames, providing a simple yet effective improvement in coding efficiency. To the best of our knowledge, this work presents the first systematic study of enhancement filtering in the context of conditional-based neural video compression. Extensive experiments demonstrate a 7.71% reduction in bit rate compared to state-of-the-art neural video codecs, validating the effectiveness of the proposed approach.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¥ç»è§†é¢‘å‹ç¼©ï¼ˆNeural Video Compressionï¼‰ä¸­çš„å¢å¼ºæ»¤æ³¢æŠ€æœ¯ï¼Œå¹¶å°†å…¶åˆ†ä¸ºç¯å†…ä¸Šä¸‹æ–‡æ»¤æ³¢ï¼ˆIn-loop contextual filteringï¼‰å’Œç¯å¤–é‡å»ºå¢å¼ºï¼ˆOut-of-loop reconstruction enhancementï¼‰ä¸¤ç±»ã€‚ç¯å†…ä¸Šä¸‹æ–‡æ»¤æ³¢é€šè¿‡ç¼“è§£é€å¸§ç¼–ç è¿‡ç¨‹ä¸­çš„è¯¯å·®ä¼ æ’­æ¥ç²¾ç‚¼æ—¶é—´ä¸Šä¸‹æ–‡ï¼Œå¹¶é…åˆä¸€ç§è‡ªé€‚åº”ç¼–ç å†³ç­–ç­–ç•¥ï¼ˆAdaptive coding decision strategyï¼‰æ¥åŠ¨æ€ä¼˜åŒ–æ»¤æ³¢åº”ç”¨ã€‚ç¯å¤–é‡å»ºå¢å¼ºåˆ™ç”¨äºè¿›ä¸€æ­¥æå‡é‡å»ºå¸§çš„è´¨é‡ï¼Œä¸ºæé«˜ç¼–ç æ•ˆç‡æä¾›äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ‰‹æ®µã€‚è¯¥å·¥ä½œä»£è¡¨äº†åœ¨åŸºäºæ¡ä»¶çš„ç¥ç»è§†é¢‘å‹ç¼©é¢†åŸŸå¯¹å¢å¼ºæ»¤æ³¢è¿›è¡Œçš„é¦–æ¬¡ç³»ç»Ÿæ€§ç ”ç©¶ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”ç›®å‰æœ€å…ˆè¿›çš„ç¥ç»è§†é¢‘ç¼–è§£ç å™¨èƒ½å¤Ÿå®ç°7.71%çš„ç ç‡é™ä½ï¼Œå……åˆ†éªŒè¯äº†æ‰€ææ¶æ„çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "9 pages, 8 figures, Accepted to ACMMM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04051v1",
      "published_date": "2025-09-04 09:29:30 UTC",
      "updated_date": "2025-09-04 09:29:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:18.295529+00:00"
    },
    {
      "arxiv_id": "2509.04041v1",
      "title": "Oruga: An Avatar of Representational Systems Theory",
      "title_zh": "Orugaï¼šè¡¨å¾ç³»ç»Ÿç†è®ºçš„åŒ–èº«",
      "authors": [
        "Daniel Raggi",
        "Gem Stapleton",
        "Mateja Jamnik",
        "Aaron Stockdill",
        "Grecia Garcia Garcia",
        "Peter C-H. Cheng"
      ],
      "abstract": "Humans use representations flexibly. We draw diagrams, change representations and exploit creative analogies across different domains. We want to harness this kind of power and endow machines with it to make them more compatible with human use. Previously we developed Representational Systems Theory (RST) to study the structure and transformations of representations. In this paper we present Oruga (caterpillar in Spanish; a symbol of transformation), an implementation of various aspects of RST. Oruga consists of a core of data structures corresponding to concepts in RST, a language for communicating with the core, and an engine for producing transformations using a method we call structure transfer. In this paper we present an overview of the core and language of Oruga, with a brief example of the kind of transformation that structure transfer can execute.",
      "tldr_zh": "è¯¥ç ”ç©¶å±•ç¤ºäº†Orugaï¼Œå®ƒæ˜¯é’ˆå¯¹è¡¨å¾ç³»ç»Ÿç†è®º(Representational Systems Theory, RST)ä¸­å„ç§ç»´åº¦çš„å…·ä½“è®¡ç®—å®ç°ï¼Œæ—¨åœ¨èµ‹äºˆæœºå™¨ç±»ä¼¼äººç±»çš„çµæ´»è¡¨å¾å¤„ç†èƒ½åŠ›ã€‚Orugaçš„æ ¸å¿ƒç”±å¯¹åº”RSTæ¦‚å¿µçš„åº•å±‚æ•°æ®ç»“æ„ç»„æˆï¼Œå¹¶é…å¤‡äº†ä¸€å¥—ç”¨äºä¸æ ¸å¿ƒç»„ä»¶äº¤äº’çš„ä¸“é—¨è¯­è¨€ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†ä¸€ä¸ªå˜æ¢å¼•æ“ï¼Œåˆ©ç”¨ä¸€ç§è¢«ç§°ä¸ºç»“æ„è½¬ç§»(structure transfer)çš„æ–¹æ³•æ¥å®ç°è¡¨å¾çš„åŠ¨æ€è½¬æ¢ã€‚è®ºæ–‡è¯¦ç»†æ¦‚è¿°äº†Orugaçš„æ¶æ„è®¾è®¡ä¸è¯­è¨€è§„èŒƒï¼Œå¹¶é€šè¿‡å®ä¾‹è¯æ˜äº†å…¶åœ¨æ‰§è¡Œå¤æ‚è¡¨å¾å˜æ¢æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™ä¸€æˆæœä¸ºæ·±å…¥æ¢ç´¢è¡¨å¾çš„ç»“æ„æ¼”å˜åŠå…¶åœ¨è·¨é¢†åŸŸç±»æ¯”ä¸­çš„åº”ç”¨æä¾›äº†å…³é”®å·¥å…·ï¼Œæå‡äº†äººæœºåä½œçš„å…¼å®¹æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04041v1",
      "published_date": "2025-09-04 09:21:57 UTC",
      "updated_date": "2025-09-04 09:21:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:28.585784+00:00"
    },
    {
      "arxiv_id": "2509.04027v2",
      "title": "CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning",
      "title_zh": "CoT-Spaceï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„å†…éƒ¨æ…¢æ€è€ƒç†è®ºæ¡†æ¶",
      "authors": [
        "Zeyu Gan",
        "Hao Yi",
        "Yong Liu"
      ],
      "abstract": "Reinforcement Learning (RL) has become a pivotal approach for enhancing the reasoning capabilities of Large Language Models (LLMs). However, a significant theoretical gap persists, as traditional token-level RL frameworks fail to align with the reasoning-level nature of complex, multi-step thought processes like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space, a novel theoretical framework that recasts LLM reasoning from a discrete token-prediction task to an optimization process within a continuous, reasoning-level semantic space. This shift in perspective serves as a conceptual bridge, revitalizing foundational principles from classical learning theory to analyze the unique dynamics of LLMs. By analyzing this process from both a noise perspective and a risk perspective, we demonstrate that the convergence to an optimal CoT length is a natural consequence of the fundamental trade-off between underfitting and overfitting. Furthermore, extensive experiments provide strong empirical validation for our theoretical findings. Our framework not only provides a coherent explanation for empirical phenomena such as overthinking but also offers a solid theoretical foundation to guide the future development of more effective and generalizable reasoning agents. We open-source our code at https://github.com/ZyGan1999/CoT-Space.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CoT-Spaceï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é€šè¿‡å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)å¢å¼ºå¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èƒ½åŠ›çš„ç†è®ºæ¡†æ¶ã€‚ä¸ºäº†è§£å†³ä¼ ç»ŸToken-levelå¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸å¤æ‚çš„é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†è¿‡ç¨‹ä¹‹é—´çš„ä¸åŒ¹é…é—®é¢˜ï¼ŒCoT-Spaceå°†æ¨ç†è¿‡ç¨‹ä»ç¦»æ•£çš„Tokené¢„æµ‹ä»»åŠ¡é‡æ–°å®šä¹‰ä¸ºè¿ç»­è¯­ä¹‰ç©ºé—´ä¸­çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚è¯¥æ¡†æ¶ä»å™ªå£°å’Œé£é™©çš„è§’åº¦è¿›è¡Œåˆ†æï¼Œè¯æ˜äº†æ”¶æ•›è‡³æœ€ä¼˜CoTé•¿åº¦æ˜¯æ¬ æ‹Ÿåˆä¸è¿‡æ‹Ÿåˆä¹‹é—´æƒè¡¡çš„è‡ªç„¶ç»“æœã€‚é€šè¿‡å¤§é‡çš„å®éªŒéªŒè¯ï¼ŒCoT-Spaceä¸ä»…ä¸ºè¿‡åº¦æ€è€ƒ(Overthinking)ç­‰ç»éªŒç°è±¡æä¾›äº†è¿è´¯çš„åˆç†è§£é‡Šï¼Œè¿˜ä¸ºæœªæ¥å¼€å‘æ›´é«˜æ•ˆã€æ³›åŒ–èƒ½åŠ›æ›´å¼ºçš„æ¨ç†æ™ºèƒ½ä½“å¥ å®šäº†åšå®çš„ç†è®ºåŸºç¡€ã€‚ç›®å‰ï¼Œè¯¥ç ”ç©¶çš„ç›¸å…³ä»£ç å·²åœ¨GitHubå¼€æºã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint Edition",
      "pdf_url": "https://arxiv.org/pdf/2509.04027v2",
      "published_date": "2025-09-04 09:02:16 UTC",
      "updated_date": "2025-09-25 06:48:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:31.286414+00:00"
    },
    {
      "arxiv_id": "2509.19305v1",
      "title": "Wavelet Fourier Diffuser: Frequency-Aware Diffusion Model for Reinforcement Learning",
      "title_zh": "Wavelet Fourier Diffuserï¼šé¢å‘å¼ºåŒ–å­¦ä¹ çš„é¢‘ç‡æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Yifu Luo",
        "Yongzhe Chang",
        "Xueqian Wang"
      ],
      "abstract": "Diffusion probability models have shown significant promise in offline reinforcement learning by directly modeling trajectory sequences. However, existing approaches primarily focus on time-domain features while overlooking frequency-domain features, leading to frequency shift and degraded performance according to our observation. In this paper, we investigate the RL problem from a new perspective of the frequency domain. We first observe that time-domain-only approaches inadvertently introduce shifts in the low-frequency components of the frequency domain, which results in trajectory instability and degraded performance. To address this issue, we propose Wavelet Fourier Diffuser (WFDiffuser), a novel diffusion-based RL framework that integrates Discrete Wavelet Transform to decompose trajectories into low- and high-frequency components. To further enhance diffusion modeling for each component, WFDiffuser employs Short-Time Fourier Transform and cross attention mechanisms to extract frequency-domain features and facilitate cross-frequency interaction. Extensive experiment results on the D4RL benchmark demonstrate that WFDiffuser effectively mitigates frequency shift, leading to smoother, more stable trajectories and improved decision-making performance over existing methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»çº¿å¼ºåŒ–å­¦ä¹  (Offline Reinforcement Learning) ä¸­æ‰©æ•£æ¨¡å‹ä»…å…³æ³¨æ—¶åŸŸç‰¹å¾è€Œå¿½ç•¥é¢‘åŸŸç‰¹å¾å¯¼è‡´çš„é¢‘ç‡åç§» (Frequency Shift) å’Œæ€§èƒ½ä¸‹é™é—®é¢˜ï¼Œæå‡ºäº† Wavelet Fourier Diffuser (WFDiffuser) æ¡†æ¶ã€‚ä½œè€…é€šè¿‡ç ”ç©¶å‘ç°ï¼Œä»…ä¾èµ–æ—¶åŸŸçš„æ–¹æ³•ä¼šå¯¼è‡´é¢‘åŸŸä½é¢‘æˆåˆ†å‘ç”Ÿåç§»ï¼Œè¿›è€Œé€ æˆè½¨è¿¹ä¸ç¨³å®šã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼ŒWFDiffuser å¼•å…¥äº†ç¦»æ•£å°æ³¢å˜æ¢ (Discrete Wavelet Transform) å°†è½¨è¿¹åˆ†è§£ä¸ºé«˜é¢‘å’Œä½é¢‘æˆåˆ†ã€‚è¯¥æ¡†æ¶è¿›ä¸€æ­¥ç»“åˆçŸ­æ—¶å‚…é‡Œå¶å˜æ¢ (Short-Time Fourier Transform) æå–é¢‘åŸŸç‰¹å¾ï¼Œå¹¶åˆ©ç”¨äº¤å‰æ³¨æ„åŠ› (Cross Attention) æœºåˆ¶ä¿ƒè¿›è·¨é¢‘ç‡é—´çš„äº¤äº’ã€‚åœ¨ D4RL åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒWFDiffuser æœ‰æ•ˆç¼“è§£äº†é¢‘ç‡åç§»ç°è±¡ï¼Œç”Ÿæˆäº†æ›´å¹³æ»‘ã€æ›´ç¨³å®šçš„è½¨è¿¹ï¼Œå¹¶åœ¨å†³ç­–æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19305v1",
      "published_date": "2025-09-04 08:50:31 UTC",
      "updated_date": "2025-09-04 08:50:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:33.990254+00:00"
    },
    {
      "arxiv_id": "2509.04013v1",
      "title": "On Robustness and Reliability of Benchmark-Based Evaluation of LLMs",
      "title_zh": "è®ºå¤§è¯­è¨€æ¨¡å‹åŸºå‡†è¯„ä¼°çš„é²æ£’æ€§ä¸å¯é æ€§",
      "authors": [
        "Riccardo Lunardi",
        "Vincenzo Della Mea",
        "Stefano Mizzaro",
        "Kevin Roitero"
      ],
      "abstract": "Large Language Models (LLMs) effectiveness is usually evaluated by means of benchmarks such as MMLU, ARC-C, or HellaSwag, where questions are presented in their original wording, thus in a fixed, standardized format. However, real-world applications involve linguistic variability, requiring models to maintain their effectiveness across diverse rewordings of the same question or query. In this study, we systematically assess the robustness of LLMs to paraphrased benchmark questions and investigate whether benchmark-based evaluations provide a reliable measure of model capabilities. We systematically generate various paraphrases of all the questions across six different common benchmarks, and measure the resulting variations in effectiveness of 34 state-of-the-art LLMs, of different size and effectiveness. Our findings reveal that while LLM rankings remain relatively stable across paraphrased inputs, absolute effectiveness scores change, and decline significantly. This suggests that LLMs struggle with linguistic variability, raising concerns about their generalization abilities and evaluation methodologies. Furthermore, the observed performance drop challenges the reliability of benchmark-based evaluations, indicating that high benchmark scores may not fully capture a model's robustness to real-world input variations. We discuss the implications of these findings for LLM evaluation methodologies, emphasizing the need for robustness-aware benchmarks that better reflect practical deployment scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨åŸºäºåŸºå‡†æµ‹è¯•(Benchmark-based evaluation)è¯„ä¼°ä¸­çš„ç¨³å¥æ€§(Robustness)ä¸å¯é æ€§(Reliability)é—®é¢˜ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¯¹ MMLU, ARC-C å’Œ HellaSwag ç­‰å…­ä¸ªå¸¸ç”¨åŸºå‡†æµ‹è¯•ä¸­çš„æ‰€æœ‰é—®é¢˜è¿›è¡Œç³»ç»Ÿæ€§çš„æ”¹å†™(Paraphrased)ï¼Œæµ‹é‡äº† 34 ä¸ªä¸åŒè§„æ¨¡çš„æœ€å…ˆè¿› LLMs çš„æ€§èƒ½å˜åŒ–ã€‚ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶æ¨¡å‹åœ¨æ”¹å†™è¾“å…¥åçš„æ’åä¿æŒç›¸å¯¹ç¨³å®šï¼Œä½†å…¶ç»å¯¹æœ‰æ•ˆæ€§å¾—åˆ†(Absolute effectiveness scores)æ˜¾è‘—ä¸‹é™ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ LLMs åœ¨åº”å¯¹è¯­è¨€å˜å¼‚æ€§(Linguistic variability)æ–¹é¢è¡¨ç°æ¬ ä½³ï¼Œå¼•å‘äº†å¯¹å…¶æ³›åŒ–èƒ½åŠ›(Generalization abilities)çš„è´¨ç–‘ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç°æœ‰çš„é«˜åŸºå‡†æµ‹è¯•å¾—åˆ†æœªå¿…èƒ½çœŸå®åæ˜ æ¨¡å‹åœ¨å¤„ç†ç°å®ä¸–ç•Œè¾“å…¥å˜åŒ–æ—¶çš„ç¨³å¥ç¨‹åº¦ã€‚æœ€åï¼Œä½œè€…å¼ºè°ƒéœ€è¦å¼€å‘å…·æœ‰ç¨³å¥æ€§æ„è¯†(Robustness-aware)çš„åŸºå‡†æµ‹è¯•ï¼Œä»¥æ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ECAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04013v1",
      "published_date": "2025-09-04 08:43:27 UTC",
      "updated_date": "2025-09-04 08:43:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:45.391069+00:00"
    },
    {
      "arxiv_id": "2509.04011v1",
      "title": "NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings",
      "title_zh": "NER Retrieverï¼šåŸºäºç±»å‹æ„ŸçŸ¥åµŒå…¥çš„é›¶æ ·æœ¬å‘½åå®ä½“æ£€ç´¢",
      "authors": [
        "Or Shachar",
        "Uri Katz",
        "Yoav Goldberg",
        "Oren Glickman"
      ],
      "abstract": "We present NER Retriever, a zero-shot retrieval framework for ad-hoc Named Entity Retrieval, a variant of Named Entity Recognition (NER), where the types of interest are not provided in advance, and a user-defined type description is used to retrieve documents mentioning entities of that type. Instead of relying on fixed schemas or fine-tuned models, our method builds on internal representations of large language models (LLMs) to embed both entity mentions and user-provided open-ended type descriptions into a shared semantic space. We show that internal representations, specifically the value vectors from mid-layer transformer blocks, encode fine-grained type information more effectively than commonly used top-layer embeddings. To refine these representations, we train a lightweight contrastive projection network that aligns type-compatible entities while separating unrelated types. The resulting entity embeddings are compact, type-aware, and well-suited for nearest-neighbor search. Evaluated on three benchmarks, NER Retriever significantly outperforms both lexical and dense sentence-level retrieval baselines. Our findings provide empirical support for representation selection within LLMs and demonstrate a practical solution for scalable, schema-free entity retrieval. The NER Retriever Codebase is publicly available at https://github.com/ShacharOr100/ner_retriever",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† NER Retrieverï¼Œä¸€ä¸ªç”¨äºå³æ—¶ Named Entity Retrieval çš„é›¶æ ·æœ¬æ£€ç´¢æ¡†æ¶ï¼Œæ—¨åœ¨æ ¹æ®ç”¨æˆ·æä¾›çš„å¼€æ”¾å¼ç±»å‹æè¿°æ£€ç´¢ç›¸å…³å®ä½“ï¼Œæ— éœ€é¢„å®šä¹‰ schema æˆ–å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚è¯¥æ–¹æ³•åˆ©ç”¨ Large Language Models (LLMs) çš„å†…éƒ¨è¡¨ç¤ºï¼Œå°†å®ä½“æåŠ (entity mentions) å’Œç±»å‹æè¿°åµŒå…¥åˆ°ç»Ÿä¸€çš„å…±äº«è¯­ä¹‰ç©ºé—´ä¸­ã€‚ç ”ç©¶å‘ç°ï¼ŒTransformer ä¸­é—´å±‚çš„ value vectors ç›¸æ¯”å¸¸ç”¨çš„é¡¶å±‚ embeddings èƒ½æ›´æœ‰æ•ˆåœ°ç¼–ç ç»†ç²’åº¦çš„ç±»å‹ä¿¡æ¯ã€‚ä¸ºäº†ä¼˜åŒ–è¿™äº›è¡¨ç¤ºï¼Œä½œè€…è®­ç»ƒäº†ä¸€ä¸ªè½»é‡çº§çš„å¯¹æ¯”æŠ•å½±ç½‘ç»œ (contrastive projection network)ï¼Œé€šè¿‡å¯¹é½ç±»å‹å…¼å®¹çš„å®ä½“å¹¶åˆ†ç¦»æ— å…³ç±»å‹ï¼Œç”Ÿæˆç´§å‡‘ä¸”ç±»å‹æ„ŸçŸ¥çš„å®ä½“åµŒå…¥ã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒNER Retriever çš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„è¯æ±‡æ£€ç´¢å’Œç¨ å¯†å¥å­çº§æ£€ç´¢åŸºçº¿ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°å¤§è§„æ¨¡ã€æ— æ¨¡å¼çš„å®ä½“æ£€ç´¢æä¾›äº†æœ‰æ•ˆçš„å®è¯æ”¯æŒå’Œå®ç”¨è§£å†³æ–¹æ¡ˆï¼Œå¹¶å…¬å¼€äº†å…¶ä»£ç åº“ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Findings of EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04011v1",
      "published_date": "2025-09-04 08:42:23 UTC",
      "updated_date": "2025-09-04 08:42:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:45.190885+00:00"
    },
    {
      "arxiv_id": "2509.04009v1",
      "title": "Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding",
      "title_zh": "åŸºäº Token ä¸¢å¼ƒçš„è§†è§‰ Transformer åŒºåŸŸæ€§è™šå‡ç›¸å…³æ£€æµ‹",
      "authors": [
        "Solha Kang",
        "Esla Timothy Anzaku",
        "Wesley De Neve",
        "Arnout Van Messem",
        "Joris Vankerschaver",
        "Francois Rameau",
        "Utku Ozbulak"
      ],
      "abstract": "Due to their powerful feature association capabilities, neural network-based computer vision models have the ability to detect and exploit unintended patterns within the data, potentially leading to correct predictions based on incorrect or unintended but statistically relevant signals. These clues may vary from simple color aberrations to small texts within the image. In situations where these unintended signals align with the predictive task, models can mistakenly link these features with the task and rely on them for making predictions. This phenomenon is referred to as spurious correlations, where patterns appear to be associated with the task but are actually coincidental. As a result, detection and mitigation of spurious correlations have become crucial tasks for building trustworthy, reliable, and generalizable machine learning models. In this work, we present a novel method to detect spurious correlations in vision transformers, a type of neural network architecture that gained significant popularity in recent years. Using both supervised and self-supervised trained models, we present large-scale experiments on the ImageNet dataset demonstrating the ability of the proposed method to identify spurious correlations. We also find that, even if the same architecture is used, the training methodology has a significant impact on the model's reliance on spurious correlations. Furthermore, we show that certain classes in the ImageNet dataset contain spurious signals that are easily detected by the models and discuss the underlying reasons for those spurious signals. In light of our findings, we provide an exhaustive list of the aforementioned images and call for caution in their use in future research efforts. Lastly, we present a case study investigating spurious signals in invasive breast mass classification, grounding our work in real-world scenarios.",
      "tldr_zh": "é’ˆå¯¹ Vision Transformers (ViTs) å®¹æ˜“åˆ©ç”¨æ•°æ®ä¸­éé¢„æœŸæ¨¡å¼ï¼ˆSpurious Correlationsï¼‰å¯¼è‡´é”™è¯¯é¢„æµ‹çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é€šè¿‡ Token Discarding æ£€æµ‹åŒºåŸŸæ€§ä¼ªç›¸å…³çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶è€…åœ¨ ImageNet æ•°æ®é›†ä¸Šå¯¹ç›‘ç£å­¦ä¹ å’Œè‡ªç›‘ç£å­¦ä¹ æ¨¡å‹è¿›è¡Œäº†å¤§è§„æ¨¡å®éªŒï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•è¯†åˆ«ä¼ªä¿¡å·çš„æœ‰æ•ˆæ€§ã€‚å®éªŒå‘ç°ï¼Œå³ä½¿åœ¨ç›¸åŒçš„æ¶æ„ä¸‹ï¼ŒTraining Methodology å¯¹æ¨¡å‹ä¾èµ–ä¼ªç›¸å…³çš„ç¨‹åº¦å…·æœ‰æ˜¾è‘—å½±å“ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº† ImageNet ä¸­æŸäº›ç±»åˆ«å­˜åœ¨æ˜“è¢«æ¨¡å‹æ•æ‰çš„ä¼ªä¿¡å·ï¼Œåˆ†æäº†å…¶èƒŒåçš„åŸå› ï¼Œå¹¶æä¾›äº†ä¸€ä»½å—å½±å“å›¾åƒçš„è¯¦å°½æ¸…å•ä»¥ä¾›åç»­ç ”ç©¶å‚è€ƒã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜é€šè¿‡ä¾µå…¥æ€§ä¹³è…ºåŒ…å—åˆ†ç±» (Invasive Breast Mass Classification) çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„åº”ç”¨ä»·å€¼ã€‚è¿™é¡¹ç ”ç©¶ä¸ºæ„å»ºæ›´å…·é²æ£’æ€§ã€å¯é ä¸”å¯æ³›åŒ–çš„è®¡ç®—æœºè§†è§‰æ¨¡å‹æä¾›äº†é‡è¦çš„æ£€æµ‹å·¥å…·ä¸ç†è®ºä¾æ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04009v1",
      "published_date": "2025-09-04 08:40:40 UTC",
      "updated_date": "2025-09-04 08:40:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:35:49.092088+00:00"
    },
    {
      "arxiv_id": "2509.04007v1",
      "title": "AutoPBO: LLM-powered Optimization for Local Search PBO Solvers",
      "title_zh": "AutoPBOï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å±€éƒ¨æœç´¢ PBO æ±‚è§£å™¨ä¼˜åŒ–",
      "authors": [
        "Jinyuan Li",
        "Yi Chu",
        "Yiwen Sun",
        "Mengchuan Zou",
        "Shaowei Cai"
      ],
      "abstract": "Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling combinatorial problems through pseudo-Boolean (PB) constraints. Local search solvers have shown excellent performance in PBO solving, and their efficiency is highly dependent on their internal heuristics to guide the search. Still, their design often requires significant expert effort and manual tuning in practice. While Large Language Models (LLMs) have demonstrated potential in automating algorithm design, their application to optimizing PBO solvers remains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered framework to automatically enhance PBO local search solvers. We conduct experiments on a broad range of four public benchmarks, including one real-world benchmark, a benchmark from PB competition, an integer linear programming optimization benchmark, and a crafted combinatorial benchmark, to evaluate the performance improvement achieved by AutoPBO and compare it with six state-of-the-art competitors, including two local search PBO solvers NuPBO and OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed integer programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates significant improvements over previous local search approaches, while maintaining competitive performance compared to state-of-the-art competitors. The results suggest that AutoPBO offers a promising approach to automating local search solver design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AutoPBOï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ Large Language Models (LLMs) è‡ªåŠ¨å¢å¼º Pseudo-Boolean Optimization (PBO) é¢†åŸŸ local search æ±‚è§£å™¨æ€§èƒ½çš„æ–°å‹æ¡†æ¶ã€‚é’ˆå¯¹ local search æ±‚è§£å™¨é«˜åº¦ä¾èµ–äººå·¥è®¾è®¡å’Œå¯å‘å¼ç­–ç•¥ (heuristics) è°ƒä¼˜çš„ç°çŠ¶ï¼ŒAutoPBO å®ç°äº†ç®—æ³•è®¾è®¡çš„è‡ªåŠ¨åŒ–ï¼Œæ¢ç´¢äº† LLM åœ¨ä¼˜åŒ– PBO æ±‚è§£å™¨æ–¹é¢çš„æ½œåŠ›ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨åŒ…æ‹¬çœŸå®ä¸–ç•Œä»»åŠ¡å’Œ PB ç«èµ›åœ¨å†…çš„å››ä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå¹¶ä¸ NuPBOã€OraSLS ä»¥åŠ Gurobi å’Œ SCIP ç­‰å…­ç§ state-of-the-art æ±‚è§£å™¨è¿›è¡Œäº†å¯¹æ¯”åˆ†æã€‚ç»“æœè¡¨æ˜ï¼ŒAutoPBO ç›¸æ¯”ä»¥å¾€çš„ local search æ–¹æ³•å®ç°äº†æ˜¾è‘—æ”¹è¿›ï¼Œå¹¶åœ¨ä¸é¡¶å°–æ±‚è§£å™¨çš„ç«äº‰ä¸­ä¿æŒäº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚è¯¥ç ”ç©¶è¯æ˜äº† AutoPBO æ˜¯è‡ªåŠ¨åŒ– local search æ±‚è§£å™¨è®¾è®¡çš„ä¸€ç§æœ‰æ•ˆæ–¹æ³•ï¼Œä¸ºå¤„ç†å¤æ‚çš„ç»„åˆä¼˜åŒ–é—®é¢˜æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04007v1",
      "published_date": "2025-09-04 08:38:42 UTC",
      "updated_date": "2025-09-04 08:38:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:07.391843+00:00"
    },
    {
      "arxiv_id": "2509.03995v1",
      "title": "RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question Answering with Large Language Models",
      "title_zh": "RTQAï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤æ‚æ—¶åºçŸ¥è¯†å›¾è°±é—®ç­”é€’å½’æ€ç»´",
      "authors": [
        "Zhaoyan Gong",
        "Juan Li",
        "Zhiqiang Liu",
        "Lei Liang",
        "Huajun Chen",
        "Wen Zhang"
      ],
      "abstract": "Current temporal knowledge graph question answering (TKGQA) methods primarily focus on implicit temporal constraints, lacking the capability of handling more complex temporal queries, and struggle with limited reasoning abilities and error propagation in decomposition frameworks. We propose RTQA, a novel framework to address these challenges by enhancing reasoning over TKGs without requiring training. Following recursive thinking, RTQA recursively decomposes questions into sub-problems, solves them bottom-up using LLMs and TKG knowledge, and employs multi-path answer aggregation to improve fault tolerance. RTQA consists of three core components: the Temporal Question Decomposer, the Recursive Solver, and the Answer Aggregator. Experiments on MultiTQ and TimelineKGQA benchmarks demonstrate significant Hits@1 improvements in \"Multiple\" and \"Complex\" categories, outperforming state-of-the-art methods. Our code and data are available at https://github.com/zjukg/RTQA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰æ—¶åºçŸ¥è¯†å›¾è°±é—®ç­”(TKGQA)æ–¹æ³•åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢æ—¶çš„å±€é™æ€§ä»¥åŠåˆ†è§£æ¡†æ¶ä¸­çš„æ¨ç†èƒ½åŠ›å—é™å’Œé”™è¯¯ä¼ æ’­é—®é¢˜ï¼Œæå‡ºäº†RTQAæ¡†æ¶ã€‚RTQAéµå¾ªé€’å½’æ€ç»´(Recursive Thinking)æ¨¡å¼ï¼Œæ— éœ€é¢å¤–è®­ç»ƒå³å¯é€šè¿‡å¤§è¯­è¨€æ¨¡å‹(LLMs)å¯¹å¤æ‚é—®é¢˜è¿›è¡Œé€’å½’åˆ†è§£ï¼Œå¹¶ç»“åˆæ—¶åºçŸ¥è¯†å›¾è°±(TKGs)çŸ¥è¯†è¿›è¡Œè‡ªä¸‹è€Œä¸Šçš„æ±‚è§£ã€‚è¯¥æ¡†æ¶ç”±æ—¶åºé—®é¢˜åˆ†è§£å™¨(Temporal Question Decomposer)ã€é€’å½’æ±‚è§£å™¨(Recursive Solver)å’Œç­”æ¡ˆèšåˆå™¨(Answer Aggregator)ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼Œå¹¶å¼•å…¥å¤šè·¯å¾„ç­”æ¡ˆèšåˆæœºåˆ¶ä»¥å¢å¼ºå®¹é”™æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRTQAåœ¨MultiTQå’ŒTimelineKGQAåŸºå‡†æµ‹è¯•çš„â€œMultipleâ€å’Œâ€œComplexâ€ä»»åŠ¡åˆ†ç±»ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„Hits@1æŒ‡æ ‡æå‡ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.03995v1",
      "published_date": "2025-09-04 08:25:01 UTC",
      "updated_date": "2025-09-04 08:25:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:15.681988+00:00"
    },
    {
      "arxiv_id": "2509.03990v2",
      "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent",
      "title_zh": "Meta-Policy Reflexionï¼šé¢å‘èµ„æºé«˜æ•ˆå‹ LLM æ™ºèƒ½ä½“çš„å¯å¤ç”¨åæ€è®°å¿†ä¸è§„åˆ™å‡†å…¥",
      "authors": [
        "Chunlong Wu",
        "Ye Luo",
        "Zhibo Qu",
        "Min Wang"
      ],
      "abstract": "Large language model (LLM) agents achieve impressive single-task performance but commonly exhibit repeated failures, inefficient exploration, and limited cross-task adaptability. Existing reflective strategies (e.g., Reflexion, ReAct) improve per-episode behavior but typically produce ephemeral, task-specific traces that are not reused across tasks. Reinforcement-learning based alternatives can produce transferable policies but require substantial parameter updates and compute. In this work we introduce Meta-Policy Reflexion (MPR): a hybrid framework that consolidates LLM-generated reflections into a structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at inference time through two complementary mechanisms soft memory-guided decoding and hard rule admissibility checks(HAC). MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection. We formalize the MPM representation, present algorithms for update and decoding, and validate the approach in a text-based agent environment following the experimental protocol described in the provided implementation (AlfWorld-based). Empirical results reported in the supplied material indicate consistent gains in execution accuracy and robustness when compared to Reflexion baselines; rule admissibility further improves stability. We analyze mechanisms that explain these gains, discuss scalability and failure modes, and outline future directions for multimodal and multi-agent extensions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Meta-Policy Reflexion (MPR)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(Large Language Model, LLM)æ™ºèƒ½ä½“åœ¨ä»»åŠ¡ä¸­é‡å¤å¤±è´¥ã€æ¢ç´¢æ•ˆç‡ä½ä¸‹ä»¥åŠè·¨ä»»åŠ¡é€‚åº”æ€§æœ‰é™ç­‰é—®é¢˜çš„æ··åˆæ¡†æ¶ã€‚MPRé€šè¿‡å°†æ™ºèƒ½ä½“ç”Ÿæˆçš„åæ€æ•´åˆåˆ°ç»“æ„åŒ–çš„å…ƒç­–ç•¥è®°å¿†(Meta-Policy Memory, MPM)ä¸­ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µåº”ç”¨è½¯è®°å¿†å¼•å¯¼è§£ç (soft memory-guided decoding)å’Œç¡¬æ€§è§„åˆ™å®¹è®¸æ£€æŸ¥(hard rule admissibility checks, HAC)ä¸¤ç§äº’è¡¥æœºåˆ¶ã€‚è¯¥æ–¹æ³•æ— éœ€æ›´æ–°æ¨¡å‹æƒé‡å³å¯å®ç°ä¿®æ­£æ€§çŸ¥è¯†çš„è·¨ä»»åŠ¡é‡ç”¨ï¼Œå¹¶é€šè¿‡å®æ–½é¢†åŸŸçº¦æŸæœ‰æ•ˆå‡å°‘äº†ä¸å®‰å…¨æˆ–æ— æ•ˆçš„æ“ä½œã€‚åœ¨AlfWorldç¯å¢ƒä¸‹çš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ReflexionåŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒMPRåœ¨æ‰§è¡Œå‡†ç¡®æ€§å’Œé²æ£’æ€§æ–¹é¢å‡è¡¨ç°å‡ºæŒç»­çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œè§„åˆ™å®¹è®¸æœºåˆ¶è¿›ä¸€æ­¥å¢å¼ºäº†ç³»ç»Ÿçš„ç¨³å®šæ€§ï¼Œä¸ºæ„å»ºèµ„æºé«˜æ•ˆä¸”å…·å¤‡æŒç»­å­¦ä¹ èƒ½åŠ›çš„è‡ªä¸»æ™ºèƒ½ä½“æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03990v2",
      "published_date": "2025-09-04 08:18:39 UTC",
      "updated_date": "2025-09-08 07:40:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:17.868342+00:00"
    },
    {
      "arxiv_id": "2509.03986v1",
      "title": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?",
      "title_zh": "Promptceptionï¼šå¤§å¤šæ¨¡æ€æ¨¡å‹å¯¹æç¤ºè¯çš„æ•æ„Ÿæ€§ç ”ç©¶",
      "authors": [
        "Mohamed Insaf Ismithdeen",
        "Muhammad Uzair Khattak",
        "Salman Khan"
      ],
      "abstract": "Despite the success of Large Multimodal Models (LMMs) in recent years, prompt design for LMMs in Multiple-Choice Question Answering (MCQA) remains poorly understood. We show that even minor variations in prompt phrasing and structure can lead to accuracy deviations of up to 15% for certain prompts and models. This variability poses a challenge for transparent and fair LMM evaluation, as models often report their best-case performance using carefully selected prompts. To address this, we introduce Promptception, a systematic framework for evaluating prompt sensitivity in LMMs. It consists of 61 prompt types, spanning 15 categories and 6 supercategories, each targeting specific aspects of prompt formulation, and is used to evaluate 10 LMMs ranging from lightweight open-source models to GPT-4o and Gemini 1.5 Pro, across 3 MCQA benchmarks: MMStar, MMMU-Pro, MVBench. Our findings reveal that proprietary models exhibit greater sensitivity to prompt phrasing, reflecting tighter alignment with instruction semantics, while open-source models are steadier but struggle with nuanced and complex phrasing. Based on this analysis, we propose Prompting Principles tailored to proprietary and open-source LMMs, enabling more robust and fair model evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ (LMMs) åœ¨å¤šé¡¹é€‰æ‹©é¢˜è§£ç­” (MCQA) ä»»åŠ¡ä¸­å¯¹æç¤ºè¯ (Prompt) è®¾è®¡çš„æ•æ„Ÿæ€§ï¼ŒæŒ‡å‡ºæç¤ºè¯è¡¨è¿°çš„å¾®å°å˜åŒ–å¯èƒ½å¯¼è‡´å‡†ç¡®ç‡äº§ç”Ÿé«˜è¾¾ 15% çš„æ³¢åŠ¨ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº† Promptception æ¡†æ¶ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼°æ¨¡å‹å¯¹æç¤ºè¯çš„æ•æ„Ÿç¨‹åº¦ã€‚è¯¥æ¡†æ¶åŒ…å« 61 ç§æç¤ºè¯ç±»å‹ï¼Œå¹¶åœ¨ MMStarã€MMMU-Pro å’Œ MVBench ç­‰åŸºå‡†æµ‹è¯•ä¸­å¯¹åŒ…æ‹¬ GPT-4o å’Œ Gemini 1.5 Pro åœ¨å†…çš„ 10 ä¸ªæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼Œé—­æºæ¨¡å‹å¯¹è¯­ä¹‰æŒ‡ä»¤çš„å¯¹é½åº¦æ›´é«˜ï¼Œå› è€Œå¯¹æªè¾æ›´æ•æ„Ÿï¼Œè€Œå¼€æºæ¨¡å‹è™½ç„¶è¡¨ç°æ›´ç¨³å®šï¼Œä½†åœ¨ç†è§£å¤æ‚ç»†å¾®çš„æªè¾æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶æ€»ç»“å‡ºäº†é’ˆå¯¹ä¸åŒç±»å‹æ¨¡å‹çš„æç¤ºè¯åŸåˆ™ (Prompting Principles)ï¼Œä¸ºå»ºç«‹æ›´å…¬å¹³ã€æ›´ç¨³å¥çš„ LMMs è¯„ä¼°ä½“ç³»æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.03986v1",
      "published_date": "2025-09-04 08:13:06 UTC",
      "updated_date": "2025-09-04 08:13:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:11.870408+00:00"
    },
    {
      "arxiv_id": "2509.03985v1",
      "title": "NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models",
      "title_zh": "NeuroBreakï¼šæ­ç¤ºå¤§è¯­è¨€æ¨¡å‹å†…éƒ¨è¶Šç‹±æœºåˆ¶",
      "authors": [
        "Chuhan Zhang",
        "Ye Zhang",
        "Bowen Shi",
        "Yuyou Gan",
        "Tianyu Du",
        "Shouling Ji",
        "Dazhan Deng",
        "Yingcai Wu"
      ],
      "abstract": "In deployment and application, large language models (LLMs) typically undergo safety alignment to prevent illegal and unethical outputs. However, the continuous advancement of jailbreak attack techniques, designed to bypass safety mechanisms with adversarial prompts, has placed increasing pressure on the security defenses of LLMs. Strengthening resistance to jailbreak attacks requires an in-depth understanding of the security mechanisms and vulnerabilities of LLMs. However, the vast number of parameters and complex structure of LLMs make analyzing security weaknesses from an internal perspective a challenging task. This paper presents NeuroBreak, a top-down jailbreak analysis system designed to analyze neuron-level safety mechanisms and mitigate vulnerabilities. We carefully design system requirements through collaboration with three experts in the field of AI security. The system provides a comprehensive analysis of various jailbreak attack methods. By incorporating layer-wise representation probing analysis, NeuroBreak offers a novel perspective on the model's decision-making process throughout its generation steps. Furthermore, the system supports the analysis of critical neurons from both semantic and functional perspectives, facilitating a deeper exploration of security mechanisms. We conduct quantitative evaluations and case studies to verify the effectiveness of our system, offering mechanistic insights for developing next-generation defense strategies against evolving jailbreak attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† NeuroBreakï¼Œä¸€ç§è‡ªä¸Šè€Œä¸‹çš„è¶Šç‹±åˆ†æç³»ç»Ÿï¼Œæ—¨åœ¨ä»ç¥ç»å…ƒçº§åˆ« (neuron-level) æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„å†…éƒ¨å®‰å…¨æœºåˆ¶å¹¶ç¼“è§£æ½œåœ¨æ¼æ´ã€‚é’ˆå¯¹æ¨¡å‹å‚æ•°åºå¤§å¯¼è‡´å®‰å…¨å¼±ç‚¹éš¾ä»¥ä»å†…éƒ¨é€è§†çš„æŒ‘æˆ˜ï¼Œè¯¥ç³»ç»Ÿç»“åˆäº† AI å®‰å…¨ä¸“å®¶çš„éœ€æ±‚ï¼Œæä¾›äº†å¯¹å¤šç§è¶Šç‹±æ”»å‡»æ–¹å¼çš„å…¨é¢åˆ†æã€‚NeuroBreak å¼•å…¥äº†é€å±‚è¡¨å¾æ¢æµ‹åˆ†æ (layer-wise representation probing analysis)ï¼Œä¸ºæ¨¡å‹åœ¨ç”Ÿæˆæ­¥éª¤ä¸­çš„å†³ç­–è¿‡ç¨‹æä¾›äº†ç‹¬ç‰¹è§†è§’ï¼Œå¹¶æ”¯æŒä»è¯­ä¹‰ (semantic) å’ŒåŠŸèƒ½ (functional) ç»´åº¦å¯¹å…³é”®ç¥ç»å…ƒè¿›è¡Œæ·±åº¦æ¢ç´¢ã€‚é€šè¿‡å®šé‡è¯„ä¼°ä¸æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥ç ”ç©¶éªŒè¯äº†ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºå¼€å‘åº”å¯¹æ¼”è¿›å¼è¶Šç‹±æ”»å‡»çš„ä¸‹ä¸€ä»£é˜²å¾¡ç­–ç•¥æä¾›äº†æœºåˆ¶å±‚é¢çš„è§è§£ (mechanistic insights)ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.03985v1",
      "published_date": "2025-09-04 08:12:06 UTC",
      "updated_date": "2025-09-04 08:12:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:17.703747+00:00"
    },
    {
      "arxiv_id": "2509.04537v3",
      "title": "Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem",
      "title_zh": "El Farol é…’å§é—®é¢˜ä¸­ LLM æ™ºèƒ½ä½“çš„æ¶Œç°ç¤¾ä¼šåŠ¨åŠ›å­¦",
      "authors": [
        "Ryosuke Takata",
        "Atsushi Masumori",
        "Takashi Ikegami"
      ],
      "abstract": "We investigate the emergent social dynamics of Large Language Model (LLM) agents in a spatially extended El Farol Bar problem, observing how they autonomously navigate this classic social dilemma. As a result, the LLM agents generated a spontaneous motivation to go to the bar and changed their decision making by becoming a collective. We also observed that the LLM agents did not solve the problem completely, but rather behaved more like humans. These findings reveal a complex interplay between external incentives (prompt-specified constraints such as the 60% threshold) and internal incentives (culturally-encoded social preferences derived from pre-training), demonstrating that LLM agents naturally balance formal game-theoretic rationality with social motivations that characterize human behavior. These findings suggest that a new model of group decision making, which could not be handled in the previous game-theoretic problem setting, can be realized by LLM agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“åœ¨ç©ºé—´æ‰©å±•çš„ El Farol Bar é—®é¢˜ä¸­çš„æ¶Œç°ç¤¾ä¼šåŠ¨æ€ï¼Œè§‚å¯Ÿå®ƒä»¬å¦‚ä½•è‡ªä¸»åº”å¯¹è¿™ä¸€ç»å…¸ç¤¾ä¼šå›°å¢ƒã€‚ç ”ç©¶å‘ç°ï¼ŒLLM æ™ºèƒ½ä½“è‡ªå‘äº§ç”Ÿäº†å»é…’å§çš„åŠ¨åŠ›ï¼Œå¹¶é€šè¿‡å½¢æˆé›†ä½“å†³ç­–æ¨¡å¼æ”¹å˜äº†å…¶è¡Œä¸ºæ–¹å¼ã€‚å®éªŒè§‚å¯Ÿåˆ° LLM æ™ºèƒ½ä½“å¹¶æœªå®Œå…¨ä»¥æœ€ä¼˜æ–¹å¼è§£å†³è¯¥é—®é¢˜ï¼Œè€Œæ˜¯è¡¨ç°å‡ºä¸äººç±»æå…¶ç›¸ä¼¼çš„è¡Œä¸ºç‰¹å¾ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†å¤–éƒ¨æ¿€åŠ±ï¼ˆå¦‚æç¤ºè¯æŒ‡å®šçš„ 60% é˜ˆå€¼çº¦æŸï¼‰ä¸å†…éƒ¨æ¿€åŠ±ï¼ˆæºè‡ªé¢„è®­ç»ƒçš„æ–‡åŒ–ç¼–ç ç¤¾ä¼šåå¥½ï¼‰ä¹‹é—´å¤æ‚çš„ç›¸äº’ä½œç”¨ã€‚ç»“æœè¯æ˜ LLM æ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªç„¶åœ°åœ¨åšå¼ˆè®ºçš„ç†æ€§ä¸è¡¨å¾äººç±»è¡Œä¸ºçš„ç¤¾ä¼šåŠ¨æœºä¹‹é—´å–å¾—å¹³è¡¡ã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡ LLM æ™ºèƒ½ä½“å¯ä»¥å®ç°ä¸€ç§å…¨æ–°çš„ç¾¤ä½“å†³ç­–æ¨¡å‹ï¼Œå¡«è¡¥äº†ä»¥å¾€åšå¼ˆè®ºæ¡†æ¶æ— æ³•å¤„ç†çš„å¤æ‚åœºæ™¯ç©ºç™½ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04537v3",
      "published_date": "2025-09-04 08:09:42 UTC",
      "updated_date": "2025-09-17 13:45:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:21.251107+00:00"
    },
    {
      "arxiv_id": "2509.03973v1",
      "title": "SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification",
      "title_zh": "SAC-MILï¼šé¢å‘ç»„ç»‡ç—…ç†å­¦å…¨è§†é‡åˆ‡ç‰‡å›¾åƒåˆ†ç±»çš„ç©ºé—´æ„ŸçŸ¥å…³è”å¤šç¤ºä¾‹å­¦ä¹ ",
      "authors": [
        "Yu Bai",
        "Zitong Yu",
        "Haowen Tian",
        "Xijing Wang",
        "Shuo Yan",
        "Lin Wang",
        "Honglin Li",
        "Xitong Ling",
        "Bo Zhang",
        "Zheng Zhang",
        "Wufan Wang",
        "Hui Gao",
        "Xiangyang Gong",
        "Wendong Wang"
      ],
      "abstract": "We propose Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL) for performing WSI classification. SAC-MIL consists of a positional encoding module to encode position information and a SAC block to perform full instance correlations. The positional encoding module utilizes the instance coordinates within the slide to encode the spatial relationships instead of the instance index in the input WSI sequence. The positional encoding module can also handle the length extrapolation issue where the training and testing sequences have different lengths. The SAC block is an MLP-based method that performs full instance correlation in linear time complexity with respect to the sequence length. Due to the simple structure of MLP, it is easy to deploy since it does not require custom CUDA kernels, compared to Transformer-based methods for WSI classification. SAC-MIL has achieved state-of-the-art performance on the CAMELYON-16, TCGA-LUNG, and TCGA-BRAC datasets. The code will be released upon acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SAC-MILï¼Œä¸€ç§ç”¨äºç»„ç»‡ç—…ç†å­¦å…¨åˆ‡ç‰‡å›¾åƒ (Whole Slide Image, WSI) åˆ†ç±»çš„ç©ºé—´æ„ŸçŸ¥å…³è”å¤šç¤ºä¾‹å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¨¡å‹é€šè¿‡ä½ç½®ç¼–ç æ¨¡å—åˆ©ç”¨å®ä¾‹åœ¨åˆ‡ç‰‡ä¸­çš„å®é™…åæ ‡è€Œéåºåˆ—ç´¢å¼•æ¥æ•æ‰ç©ºé—´å…³ç³»ï¼Œæœ‰æ•ˆè§£å†³äº†è®­ç»ƒä¸æµ‹è¯•åºåˆ—é•¿åº¦ä¸ä¸€çš„é•¿åº¦å¤–æ¨ (length extrapolation) é—®é¢˜ã€‚å…¶æ ¸å¿ƒSAC blocké‡‡ç”¨åŸºäºå¤šå±‚æ„ŸçŸ¥æœº (MLP) çš„æ–¹æ³•ï¼Œåœ¨å®ç°å…¨å±€å®ä¾‹å…³è”çš„åŒæ—¶å°†æ—¶é—´å¤æ‚åº¦æ§åˆ¶åœ¨ç›¸å¯¹äºåºåˆ—é•¿åº¦çš„çº¿æ€§æ°´å¹³ã€‚å¾—ç›Šäºç®€æ´çš„MLPç»“æ„ï¼ŒSAC-MILæ— éœ€å®šåˆ¶CUDAå†…æ ¸ï¼Œæ¯”Transformerç±»æ–¹æ³•æ›´æ˜“äºéƒ¨ç½²ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨CAMELYON-16ã€TCGA-LUNGå’ŒTCGA-BRACç­‰å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›çš„ (state-of-the-art) æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03973v1",
      "published_date": "2025-09-04 07:58:52 UTC",
      "updated_date": "2025-09-04 07:58:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:36.786193+00:00"
    },
    {
      "arxiv_id": "2509.03972v1",
      "title": "Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study",
      "title_zh": "ä»¥éŸ©è¯­ä¸ºæ¡ˆä¾‹ç ”ç©¶ï¼šæ‰©å±•å¼€æºå¤§è¯­è¨€æ¨¡å‹çš„åŸºç¡€è¯­è¨€èƒ½åŠ›",
      "authors": [
        "Junghwan Lim",
        "Gangwon Jo",
        "Sungmin Lee",
        "Jiyoung Park",
        "Dongseok Kim",
        "Jihwan Kim",
        "Junhyeok Lee",
        "Wai Ting Cheung",
        "Dahye Choi",
        "Kibong Choi",
        "Jaeyeon Huh",
        "Beomgyu Kim",
        "Jangwoong Kim",
        "Taehyun Kim",
        "Haesol Lee",
        "Jeesoo Lee",
        "Dongpin Oh",
        "Changseok Song",
        "Daewon Suh"
      ],
      "abstract": "We introduce Llama-3-Motif, a language model consisting of 102 billion parameters, specifically designed to enhance Korean capabilities while retaining strong performance in English. Developed on the Llama 3 architecture, Llama-3-Motif employs advanced training techniques, including LlamaPro and Masked Structure Growth, to effectively scale the model without altering its core Transformer architecture. Using the MoAI platform for efficient training across hyperscale GPU clusters, we optimized Llama-3-Motif using a carefully curated dataset that maintains a balanced ratio of Korean and English data. Llama-3-Motif shows decent performance on Korean-specific benchmarks, outperforming existing models and achieving results comparable to GPT-4.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Llama-3-Motifï¼Œä¸€ä¸ªæ‹¥æœ‰ 102 billion å‚æ•°çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨å¢å¼ºéŸ©è¯­èƒ½åŠ›çš„åŒæ—¶ä¿ç•™å¼ºåŠ²çš„è‹±è¯­æ€§èƒ½ã€‚è¯¥æ¨¡å‹åŸºäº Llama 3 æ¶æ„ï¼Œé‡‡ç”¨äº† LlamaPro å’Œ Masked Structure Growth ç­‰å…ˆè¿›è®­ç»ƒæŠ€æœ¯ï¼Œåœ¨ä¸æ”¹å˜æ ¸å¿ƒ Transformer æ¶æ„çš„å‰æä¸‹å®ç°äº†æ¨¡å‹çš„æœ‰æ•ˆæ‰©å±•ã€‚é€šè¿‡åœ¨ MoAI å¹³å°ä¸Šåˆ©ç”¨è¶…å¤§è§„æ¨¡ GPU é›†ç¾¤è¿›è¡Œè®­ç»ƒï¼Œç ”ç©¶äººå‘˜ä½¿ç”¨äº†ç²¾å¿ƒç­›é€‰ä¸”å¹³è¡¡äº†éŸ©è¯­ä¸è‹±è¯­æ¯”ä¾‹çš„æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLlama-3-Motif åœ¨éŸ©è¯­ç‰¹å®šåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸ä»…è¶…è¶Šäº†ç°æœ‰å¼€æºæ¨¡å‹ï¼Œè¿˜å–å¾—äº†ä¸ GPT-4 ç›¸å½“çš„è¯„ä¼°ç»“æœã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03972v1",
      "published_date": "2025-09-04 07:56:24 UTC",
      "updated_date": "2025-09-04 07:56:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:29.368098+00:00"
    },
    {
      "arxiv_id": "2509.03961v1",
      "title": "Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection",
      "title_zh": "ç»“åˆæ–‡æœ¬å·®å¼‚å¢å¼ºçš„é¥æ„Ÿå˜åŒ–æ£€æµ‹å¤šæ¨¡æ€ç‰¹å¾èåˆç½‘ç»œ",
      "authors": [
        "Yijun Zhou",
        "Yikui Zhai",
        "Zilu Ying",
        "Tingfeng Xian",
        "Wenlve Zhou",
        "Zhiheng Zhou",
        "Xiaolin Tian",
        "Xudong Jia",
        "Hongsheng Zhang",
        "C. L. Philip Chen"
      ],
      "abstract": "Although deep learning has advanced remote sensing change detection (RSCD), most methods rely solely on image modality, limiting feature representation, change pattern modeling, and generalization especially under illumination and noise disturbances. To address this, we propose MMChange, a multimodal RSCD method that combines image and text modalities to enhance accuracy and robustness. An Image Feature Refinement (IFR) module is introduced to highlight key regions and suppress environmental noise. To overcome the semantic limitations of image features, we employ a vision language model (VLM) to generate semantic descriptions of bitemporal images. A Textual Difference Enhancement (TDE) module then captures fine grained semantic shifts, guiding the model toward meaningful changes. To bridge the heterogeneity between modalities, we design an Image Text Feature Fusion (ITFF) module that enables deep cross modal integration. Extensive experiments on LEVIRCD, WHUCD, and SYSUCD demonstrate that MMChange consistently surpasses state of the art methods across multiple metrics, validating its effectiveness for multimodal RSCD. Code is available at: https://github.com/yikuizhai/MMChange.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MMChangeï¼Œä¸€ç§ç»“åˆå›¾åƒå’Œæ–‡æœ¬æ¨¡æ€çš„å¤šæ¨¡æ€è¿œç¨‹ä¼ æ„Ÿå˜åŒ–æ£€æµ‹ (Remote Sensing Change Detection, RSCD) æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå•æ¨¡æ€æ–¹æ³•åœ¨å…‰ç…§å’Œå™ªå£°å¹²æ‰°ä¸‹ç‰¹å¾è¡¨è¾¾å—é™çš„é—®é¢˜ã€‚è®ºæ–‡å¼•å…¥äº†å›¾åƒç‰¹å¾ç²¾ç‚¼ (Image Feature Refinement, IFR) æ¨¡å—ï¼Œé€šè¿‡çªå‡ºå…³é”®åŒºåŸŸå¹¶æŠ‘åˆ¶ç¯å¢ƒå™ªå£°æ¥ä¼˜åŒ–è§†è§‰ç‰¹å¾ã€‚ä¸ºäº†å…‹æœå›¾åƒç‰¹å¾çš„è¯­ä¹‰å±€é™æ€§ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (Vision Language Model, VLM) ç”ŸæˆåŒæ—¶ç›¸å›¾åƒçš„è¯­ä¹‰æè¿°ï¼Œå¹¶åˆ©ç”¨æ–‡æœ¬å·®å¼‚å¢å¼º (Textual Difference Enhancement, TDE) æ¨¡å—æ•è·ç»†ç²’åº¦çš„è¯­ä¹‰åç§»ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†å›¾åƒæ–‡æœ¬ç‰¹å¾èåˆ (Image Text Feature Fusion, ITFF) æ¨¡å—ä»¥å®ç°æ·±åº¦çš„è·¨æ¨¡æ€é›†æˆï¼Œæœ‰æ•ˆæ¡¥æ¥äº†ä¸åŒæ¨¡æ€é—´çš„å¼‚è´¨æ€§ã€‚åœ¨ LEVIR-CDã€WHU-CD å’Œ SYSU-CD ç­‰å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMMChange åœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚è¯¥å·¥ä½œä¸ä»…æå‡äº†å˜åŒ–æ£€æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œä¹Ÿä¸ºåˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯è¿›è¡Œé¥æ„Ÿåˆ†ææä¾›äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03961v1",
      "published_date": "2025-09-04 07:39:18 UTC",
      "updated_date": "2025-09-04 07:39:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:38.152940+00:00"
    },
    {
      "arxiv_id": "2509.03957v1",
      "title": "CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese Misinformation Fact-Checking",
      "title_zh": "CANDYï¼šä¸­æ–‡è™šå‡ä¿¡æ¯äº‹å®æ ¸æŸ¥ä¸­å¤§è¯­è¨€æ¨¡å‹çš„å±€é™æ€§ä¸è¾…åŠ©æ½œåŠ›åŸºå‡†æµ‹è¯•",
      "authors": [
        "Ruiling Guo",
        "Xinwei Yang",
        "Chen Huang",
        "Tong Zhang",
        "Yong Hu"
      ],
      "abstract": "The effectiveness of large language models (LLMs) to fact-check misinformation remains uncertain, despite their growing use. To this end, we present CANDY, a benchmark designed to systematically evaluate the capabilities and limitations of LLMs in fact-checking Chinese misinformation. Specifically, we curate a carefully annotated dataset of ~20k instances. Our analysis shows that current LLMs exhibit limitations in generating accurate fact-checking conclusions, even when enhanced with chain-of-thought reasoning and few-shot prompting. To understand these limitations, we develop a taxonomy to categorize flawed LLM-generated explanations for their conclusions and identify factual fabrication as the most common failure mode. Although LLMs alone are unreliable for fact-checking, our findings indicate their considerable potential to augment human performance when deployed as assistive tools in scenarios. Our dataset and code can be accessed at https://github.com/SCUNLP/CANDY",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CANDYï¼Œä¸€ä¸ªæ—¨åœ¨ç³»ç»Ÿè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸­æ–‡è™šå‡ä¿¡æ¯äº‹å®æ ¸æŸ¥ä¸­èƒ½åŠ›ä¸å±€é™æ€§çš„åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å«çº¦2ä¸‡ä¸ªå®ä¾‹çš„ç²¾å¿ƒæ ‡æ³¨æ•°æ®é›†ï¼Œå¹¶åˆ†æå‘ç°å½“å‰çš„LLMså³ä½¿åœ¨é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†å’Œå°‘æ ·æœ¬æç¤º(Few-shot prompting)çš„å¢å¼ºä¸‹ï¼Œåœ¨ç”Ÿæˆå‡†ç¡®çš„äº‹å®æ ¸æŸ¥ç»“è®ºæ–¹é¢ä»è¡¨ç°å‡ºå±€é™æ€§ã€‚é€šè¿‡å»ºç«‹åˆ†ç±»ä½“ç³»å¯¹æ¨¡å‹ç”Ÿæˆçš„é”™è¯¯è§£é‡Šè¿›è¡Œåˆ†æï¼Œç ”ç©¶è¯†åˆ«å‡ºäº‹å®æé€ (Factual fabrication)æ˜¯æ¨¡å‹æœ€å¸¸è§çš„å¤±æ•ˆæ¨¡å¼ã€‚å°½ç®¡LLMsç›®å‰åœ¨ç‹¬ç«‹è¿›è¡Œäº‹å®æ ¸æŸ¥æ—¶å¹¶ä¸å¯é ï¼Œä½†å…¶ä½œä¸ºäººç±»è¾…åŠ©å·¥å…·åœ¨æå‡äº‹å®æ ¸æŸ¥è¡¨ç°æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚è¯¥ç ”ç©¶è¿˜å…¬å¼€å‘å¸ƒäº†æ•°æ®é›†å’Œä»£ç ï¼Œä¸ºè¯„ä¼°å’Œæå‡æ¨¡å‹åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹çš„äº‹å®æ ¸æŸ¥èƒ½åŠ›æä¾›äº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.03957v1",
      "published_date": "2025-09-04 07:33:44 UTC",
      "updated_date": "2025-09-04 07:33:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:35.598189+00:00"
    },
    {
      "arxiv_id": "2509.03956v1",
      "title": "World Model Implanting for Test-time Adaptation of Embodied Agents",
      "title_zh": "é¢å‘å…·èº«æ™ºèƒ½ä½“æµ‹è¯•æ—¶è‡ªé€‚åº”çš„ä¸–ç•Œæ¨¡å‹æ¤å…¥",
      "authors": [
        "Minjong Yoo",
        "Jinwoo Jang",
        "Sihyung Yoon",
        "Honguk Woo"
      ],
      "abstract": "In embodied AI, a persistent challenge is enabling agents to robustly adapt to novel domains without requiring extensive data collection or retraining. To address this, we present a world model implanting framework (WorMI) that combines the reasoning capabilities of large language models (LLMs) with independently learned, domain-specific world models through test-time composition. By allowing seamless implantation and removal of the world models, the embodied agent's policy achieves and maintains cross-domain adaptability. In the WorMI framework, we employ a prototype-based world model retrieval approach, utilizing efficient trajectory-based abstract representation matching, to incorporate relevant models into test-time composition. We also develop a world-wise compound attention method that not only integrates the knowledge from the retrieved world models but also aligns their intermediate representations with the reasoning model's representation within the agent's policy. This framework design effectively fuses domain-specific knowledge from multiple world models, ensuring robust adaptation to unseen domains. We evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating superior zero-shot and few-shot performance compared to several LLM-based approaches across a range of unseen domains. These results highlight the frameworks potential for scalable, real-world deployment in embodied agent scenarios where adaptability and data efficiency are essential.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·èº«æ™ºèƒ½(Embodied AI)ä¸­æ™ºèƒ½ä½“éš¾ä»¥åœ¨æ— éœ€å¤§é‡æ•°æ®æˆ–é‡è®­ç»ƒçš„æƒ…å†µä¸‹å¿«é€Ÿé€‚åº”æ–°é¢†åŸŸçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸–ç•Œæ¨¡å‹æ¤å…¥æ¡†æ¶(World Model Implanting, WorMI)ã€‚è¯¥æ¡†æ¶é€šè¿‡æµ‹è¯•æ—¶ç»„åˆ(test-time composition)æŠ€æœ¯ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ¨ç†èƒ½åŠ›ä¸é¢†åŸŸç‰¹å®šçš„ä¸–ç•Œæ¨¡å‹æ— ç¼ç»“åˆï¼Œå®ç°äº†æ˜¾è‘—çš„è·¨é¢†åŸŸé€‚åº”æ€§ã€‚WorMI é‡‡ç”¨åŸºäºåŸå‹çš„ä¸–ç•Œæ¨¡å‹æ£€ç´¢æ–¹æ³•ï¼Œåˆ©ç”¨é«˜æ•ˆçš„åŸºäºè½¨è¿¹çš„æŠ½è±¡è¡¨ç¤ºåŒ¹é…(trajectory-based abstract representation matching)æ¥å¼•å…¥ç›¸å…³æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼€å‘äº†ä¸–ç•Œçº§å¤åˆæ³¨æ„åŠ›(world-wise compound attention)æœºåˆ¶ï¼Œæ—¨åœ¨æ•´åˆå¤šæ¨¡å‹çŸ¥è¯†å¹¶å°†å…¶ä¸­é—´è¡¨ç¤ºä¸ç­–ç•¥ä¸­çš„æ¨ç†æ¨¡å‹è¿›è¡Œå¯¹é½ã€‚åœ¨ VirtualHome å’Œ ALFWorld åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒWorMI åœ¨å¤šä¸ªæœªçŸ¥é¢†åŸŸçš„é›¶æ ·æœ¬(zero-shot)å’Œå°‘æ ·æœ¬(few-shot)æ€§èƒ½å‡ä¼˜äºç°æœ‰çš„ LLM æ–¹æ³•ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºå…·èº«æ™ºèƒ½ä½“åœ¨å¼ºè°ƒé€‚åº”æ€§å’Œæ•°æ®æ•ˆç‡çš„ç°å®åœºæ™¯ä¸­å®ç°å¯æ‰©å±•éƒ¨ç½²æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03956v1",
      "published_date": "2025-09-04 07:32:16 UTC",
      "updated_date": "2025-09-04 07:32:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:36:56.696990+00:00"
    },
    {
      "arxiv_id": "2509.03953v2",
      "title": "Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions",
      "title_zh": "åŸºäºå»¶è¿Ÿéƒ¨åˆ†æ‰©å±•çš„æœ€ä½³ä¼˜å…ˆæœç´¢å¤„ç†è§„åˆ’ä¸­çš„æ— é™åŸŸå‚æ•°",
      "authors": [
        "Ãngel Aso-Mollar",
        "Diego Aineto",
        "Enrico Scala",
        "Eva Onaindia"
      ],
      "abstract": "In automated planning, control parameters extend standard action representations through the introduction of continuous numeric decision variables. Existing state-of-the-art approaches have primarily handled control parameters as embedded constraints alongside other temporal and numeric restrictions, and thus have implicitly treated them as additional constraints rather than as decision points in the search space. In this paper, we propose an efficient alternative that explicitly handles control parameters as true decision points within a systematic search scheme. We develop a best-first, heuristic search algorithm that operates over infinite decision spaces defined by control parameters and prove a notion of completeness in the limit under certain conditions. Our algorithm leverages the concept of delayed partial expansion, where a state is not fully expanded but instead incrementally expands a subset of its successors. Our results demonstrate that this novel search algorithm is a competitive alternative to existing approaches for solving planning problems involving control parameters.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨è§„åˆ’ (automated planning) ä¸­çš„æ§åˆ¶å‚æ•° (control parameters) å¤„ç†é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å°†è¿ç»­æ•°å€¼å†³ç­–å˜é‡è§†ä¸ºæ˜¾å¼å†³ç­–ç‚¹è€ŒéåµŒå…¥å¼çº¦æŸçš„é«˜æ•ˆæ–¹æ¡ˆã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€ç§åœ¨ç”±æ§åˆ¶å‚æ•°å®šä¹‰çš„æ— é™å†³ç­–ç©ºé—´ä¸Šè¿è¡Œçš„æœ€ä½³ä¼˜å…ˆå¯å‘å¼æœç´¢ç®—æ³• (best-first, heuristic search algorithm)ï¼Œå¹¶åœ¨ç†è®ºä¸Šè¯æ˜äº†å…¶åœ¨ç‰¹å®šæ¡ä»¶ä¸‹çš„æé™å®Œå¤‡æ€§ (completeness in the limit)ã€‚è¯¥ç®—æ³•çš„æ ¸å¿ƒåœ¨äºå¼•å…¥äº†å»¶è¿Ÿéƒ¨åˆ†æ‰©å±• (delayed partial expansion) çš„æ¦‚å¿µï¼Œé€šè¿‡å¢é‡å¼æ‰©å±•åç»§çŠ¶æ€çš„å­é›†æ¥åº”å¯¹å¤æ‚çš„æœç´¢éœ€æ±‚ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¿™ç§æ–°å‹æœç´¢ç®—æ³•åœ¨è§£å†³æ¶‰åŠæ§åˆ¶å‚æ•°çš„è§„åˆ’é—®é¢˜æ—¶ï¼Œå·²æˆä¸ºç°æœ‰ä¸»æµæŠ€æœ¯è·¯å¾„ä¹‹å¤–æå…·ç«äº‰åŠ›çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.SC",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03953v2",
      "published_date": "2025-09-04 07:27:27 UTC",
      "updated_date": "2025-09-22 11:45:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:37:01.993913+00:00"
    },
    {
      "arxiv_id": "2509.03950v1",
      "title": "Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer Learning in a U-Net Architecture",
      "title_zh": "åŸºäºU-Netæ¶æ„ä¸EfficientNet-B4è¿ç§»å­¦ä¹ çš„èƒ¸éƒ¨Xå°„çº¿æ°”èƒ¸åˆ†å‰²",
      "authors": [
        "Alvaro Aranibar Roque",
        "Helga Sebastian"
      ],
      "abstract": "Pneumothorax, the abnormal accumulation of air in the pleural space, can be life-threatening if undetected. Chest X-rays are the first-line diagnostic tool, but small cases may be subtle. We propose an automated deep-learning pipeline using a U-Net with an EfficientNet-B4 encoder to segment pneumothorax regions. Trained on the SIIM-ACR dataset with data augmentation and a combined binary cross-entropy plus Dice loss, the model achieved an IoU of 0.7008 and Dice score of 0.8241 on the independent PTX-498 dataset. These results demonstrate that the model can accurately localize pneumothoraces and support radiologists.",
      "tldr_zh": "æ°”èƒ¸(Pneumothorax)æ˜¯ç”±äºç©ºæ°”åœ¨èƒ¸è†œè…”å†…å¼‚å¸¸ç§¯èšå¯¼è‡´çš„ç—…ç—‡ï¼Œè‹¥æœªèƒ½åŠæ—¶å‘ç°å¯èƒ½å±åŠç”Ÿå‘½ã€‚è¯¥ç ”ç©¶é’ˆå¯¹èƒ¸éƒ¨Xå°„çº¿(Chest X-rays)ä¸­å¾®å°ç—…ä¾‹éš¾ä»¥è¯†åˆ«çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨ä»¥EfficientNet-B4ä½œä¸ºç¼–ç å™¨çš„U-Netæ¶æ„çš„è‡ªåŠ¨åŒ–æ·±åº¦å­¦ä¹ æµæ°´çº¿ã€‚æ¨¡å‹é€šè¿‡SIIM-ACRæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå¹¶åº”ç”¨äº†æ•°æ®å¢å¼ºä»¥åŠç»“åˆäºŒå…ƒäº¤å‰ç†µ(binary cross-entropy)ä¸Dice lossçš„æŸå¤±å‡½æ•°ã€‚åœ¨ç‹¬ç«‹çš„PTX-498æ•°æ®é›†æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹å®ç°äº†0.7008çš„IoUå’Œ0.8241çš„Dice scoreã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿå‡†ç¡®å¯¹æ°”èƒ¸åŒºåŸŸè¿›è¡Œåˆ†å‰²ä¸å®šä½ï¼Œä¸ºæ”¾å°„ç§‘åŒ»å¸ˆæä¾›äº†æœ‰æ•ˆçš„è¾…åŠ©è¯Šæ–­å·¥å…·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 page, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.03950v1",
      "published_date": "2025-09-04 07:21:37 UTC",
      "updated_date": "2025-09-04 07:21:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:37:19.882033+00:00"
    },
    {
      "arxiv_id": "2509.12221v1",
      "title": "MEUV: Achieving Fine-Grained Capability Activation in Large Language Models via Mutually Exclusive Unlock Vectors",
      "title_zh": "MEUVï¼šåŸºäºäº’æ–¥è§£é”å‘é‡çš„å¤§è¯­è¨€æ¨¡å‹ç»†ç²’åº¦èƒ½åŠ›æ¿€æ´»",
      "authors": [
        "Xin Tong",
        "Zhi Lin",
        "Jingya Wang",
        "Meng Han",
        "Bo Jin"
      ],
      "abstract": "Large language models (LLMs) enforce safety alignment to reliably refuse malicious requests, yet the same blanket safeguards also block legitimate uses in policing, defense, and other high-stakes settings. Earlier \"refusal-direction\" edits can bypass those layers, but they rely on a single vector that indiscriminately unlocks all hazardous topics, offering no semantic control. We introduce Mutually Exclusive Unlock Vectors (MEUV), a lightweight framework that factorizes the monolithic refusal direction into topic-aligned, nearly orthogonal vectors, each dedicated to one sensitive capability. MEUV is learned in a single epoch with a multi-task objective that blends a differential-ablation margin, cross-topic and orthogonality penalties, and several auxiliary terms. On bilingual malicious-prompt benchmarks, MEUV achieves an attack success rate of no less than 87% on Gemma-2-2B, LLaMA-3-8B, and Qwen-7B, yet cuts cross-topic leakage by up to 90% compared with the best single-direction baseline. Vectors trained in Chinese transfer almost unchanged to English (and vice versa), suggesting a language-agnostic refusal subspace. The results show that fine-grained, topic-level capability activation is achievable with minimal utility loss, paving the way for controlled LLMs deployment in security-sensitive domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Mutually Exclusive Unlock Vectors (MEUV)ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å®‰å…¨å¯¹é½(safety alignment)ä¸­é¢ä¸´çš„æ‹’ç»æœºåˆ¶ç¼ºä¹è¯­ä¹‰æ§åˆ¶çš„é—®é¢˜ã€‚ç°æœ‰çš„æ‹’ç»æ–¹å‘(refusal-direction)ç¼–è¾‘å¾€å¾€ä¼šæ— å·®åˆ«åœ°è§£é”æ‰€æœ‰å—é™è¯é¢˜ï¼Œè€ŒMEUVé€šè¿‡å°†å•ä¸€æ‹’ç»æ–¹å‘åˆ†è§£ä¸ºå¤šä¸ªé’ˆå¯¹ç‰¹å®šæ•æ„Ÿèƒ½åŠ›ä¸”è¿‘ä¹æ­£äº¤(nearly orthogonal)çš„ä¸»é¢˜å¯¹é½å‘é‡ï¼Œå®ç°äº†ç»†ç²’åº¦çš„èƒ½åŠ›æ¿€æ´»ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŒ…å«å·®å¼‚æ¶ˆèä½™é‡(differential-ablation margin)å’Œæ­£äº¤æ€§æƒ©ç½šçš„å¤šä»»åŠ¡ç›®æ ‡ï¼Œä»…éœ€ä¸€ä¸ªè®­ç»ƒè½®æ¬¡(epoch)å³å¯å®Œæˆå­¦ä¹ ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMEUVåœ¨Gemma-2-2Bã€LLaMA-3-8Bå’ŒQwen-7Bç­‰æ¨¡å‹ä¸Šå®ç°äº†è¶…è¿‡87%çš„æ”»å‡»æˆåŠŸç‡ï¼ŒåŒæ—¶æ¯”å•æ–¹å‘åŸºçº¿æ¨¡å‹å‡å°‘äº†é«˜è¾¾90%çš„è·¨ä¸»é¢˜æ³„æ¼(cross-topic leakage)ã€‚æ­¤å¤–ï¼ŒMEUVåœ¨ä¸­æ–‡å’Œè‹±æ–‡ä¹‹é—´å…·æœ‰æå¼ºçš„è¿ç§»æ€§ï¼Œæ­ç¤ºäº†è¯­è¨€æ— å…³çš„æ‹’ç»å­ç©ºé—´(refusal subspace)ï¼Œä¸ºå®‰å…¨æ•æ„Ÿé¢†åŸŸçš„å—æ§LLMséƒ¨ç½²å¼€è¾Ÿäº†é“è·¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2509.12221v1",
      "published_date": "2025-09-04 07:16:06 UTC",
      "updated_date": "2025-09-04 07:16:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:37:09.891548+00:00"
    },
    {
      "arxiv_id": "2509.03940v1",
      "title": "VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents",
      "title_zh": "VoxRoleï¼šè¯„ä¼°è¯­éŸ³è§’è‰²æ‰®æ¼”æ™ºèƒ½ä½“çš„ç»¼åˆåŸºå‡†",
      "authors": [
        "Weihao Wu",
        "Liang Cao",
        "Xinyu Wu",
        "Zhiwei Lin",
        "Rui Niu",
        "Jingbei Li",
        "Zhiyong Wu"
      ],
      "abstract": "Recent significant advancements in Large Language Models (LLMs) have greatly propelled the development of Role-Playing Conversational Agents (RPCAs). These systems aim to create immersive user experiences through consistent persona adoption. However, current RPCA research faces dual limitations. First, existing work predominantly focuses on the textual modality, entirely overlooking critical paralinguistic features including intonation, prosody, and rhythm in speech, which are essential for conveying character emotions and shaping vivid identities. Second, the speech-based role-playing domain suffers from a long-standing lack of standardized evaluation benchmarks. Most current spoken dialogue datasets target only fundamental capability assessments, featuring thinly sketched or ill-defined character profiles. Consequently, they fail to effectively quantify model performance on core competencies like long-term persona consistency. To address this critical gap, we introduce VoxRole, the first comprehensive benchmark specifically designed for the evaluation of speech-based RPCAs. The benchmark comprises 13335 multi-turn dialogues, totaling 65.6 hours of speech from 1228 unique characters across 261 movies. To construct this resource, we propose a novel two-stage automated pipeline that first aligns movie audio with scripts and subsequently employs an LLM to systematically build multi-dimensional profiles for each character. Leveraging VoxRole, we conduct a multi-dimensional evaluation of contemporary spoken dialogue models, revealing crucial insights into their respective strengths and limitations in maintaining persona consistency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§’è‰²æ‰®æ¼”å¯¹è¯æ™ºèƒ½ä½“(RPCAs)åœ¨æ–‡æœ¬æ¨¡æ€å¤–çš„è¯­éŸ³å‰¯è¯­è¨€ç‰¹å¾ç¼ºå¤±ä»¥åŠç¼ºä¹æ ‡å‡†åŒ–åŸºå‡†çš„é—®é¢˜ï¼Œæå‡ºäº†VoxRoleï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨è¯„ä¼°åŸºäºè¯­éŸ³çš„RPCAsçš„ç»¼åˆåŸºå‡†ã€‚è¯¥åŸºå‡†åŒ…å«æ¥è‡ª261éƒ¨ç”µå½±ã€1228ä¸ªç‹¬ç‰¹è§’è‰²çš„13335è½®å¯¹è¯ï¼Œæ€»è®¡65.6å°æ—¶çš„è¯­éŸ³æ•°æ®ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ç§åˆ›æ–°çš„ä¸¤é˜¶æ®µè‡ªåŠ¨åŒ–æµç¨‹ï¼Œé€šè¿‡å¯¹é½ç”µå½±éŸ³é¢‘ä¸å‰§æœ¬å¹¶åˆ©ç”¨LLMæ„å»ºè§’è‰²çš„å¤šç»´åº¦ç”»åƒæ¥å®Œæˆæ•°æ®æ„å»ºã€‚åˆ©ç”¨VoxRoleï¼Œç ”ç©¶å›¢é˜Ÿå¯¹å½“å‰ä¸»æµçš„å£è¯­å¯¹è¯æ¨¡å‹è¿›è¡Œäº†å¤šç»´åº¦è¯„ä¼°ï¼Œæ·±å…¥æ­ç¤ºäº†è¿™äº›æ¨¡å‹åœ¨ç»´æŒäººæ ¼ä¸€è‡´æ€§(Persona Consistency)æ–¹é¢çš„ä¼˜åŠ¿ä¸çŸ­æ¿ã€‚è¯¥å·¥ä½œçš„å¼€å±•ä¸ºè¡¡é‡è¯­éŸ³æ™ºèƒ½ä½“åœ¨å¤æ‚è§’è‰²å¡‘é€ å’Œé•¿æœŸä¸€è‡´æ€§æ–¹é¢çš„èƒ½åŠ›æä¾›äº†æ ‡å‡†åŒ–çš„é‡åŒ–å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03940v1",
      "published_date": "2025-09-04 07:03:46 UTC",
      "updated_date": "2025-09-04 07:03:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:37:10.588177+00:00"
    },
    {
      "arxiv_id": "2509.03937v2",
      "title": "SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self-Play Fine-Tuning",
      "title_zh": "SPFT-SQLï¼šé€šè¿‡è‡ªæˆ‘åšå¼ˆå¾®è°ƒå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„ Text-to-SQL è§£æèƒ½åŠ›",
      "authors": [
        "Yuhao Zhang",
        "Shaoming Duan",
        "Jinhang Su",
        "Chuanyi Liu",
        "Peiyi Han"
      ],
      "abstract": "Despite the significant advancements of self-play fine-tuning (SPIN), which can transform a weak large language model (LLM) into a strong one through competitive interactions between models of varying capabilities, it still faces challenges in the Text-to-SQL task. SPIN does not generate new information, and the large number of correct SQL queries produced by the opponent model during self-play reduces the main model's ability to generate accurate SQL queries. To address this challenge, we propose a new self-play fine-tuning method tailored for the Text-to-SQL task, called SPFT-SQL. Prior to self-play, we introduce a verification-based iterative fine-tuning approach, which synthesizes high-quality fine-tuning data iteratively based on the database schema and validation feedback to enhance model performance, while building a model base with varying capabilities. During the self-play fine-tuning phase, we propose an error-driven loss method that incentivizes incorrect outputs from the opponent model, enabling the main model to distinguish between correct SQL and erroneous SQL generated by the opponent model, thereby improving its ability to generate correct SQL. Extensive experiments and in-depth analyses on six open-source LLMs and five widely used benchmarks demonstrate that our approach outperforms existing state-of-the-art (SOTA) methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Text-to-SQL ä»»åŠ¡ä¸­è‡ªå¯¹å¼ˆå¾®è°ƒ (Self-Play Fine-Tuning, SPIN) å­˜åœ¨çš„æ— æ³•ç”Ÿæˆæ–°ä¿¡æ¯ä»¥åŠå¯¹æ‰‹æ¨¡å‹äº§ç”Ÿçš„æ­£ç¡®æŸ¥è¯¢è¿‡å¤šå¯¼è‡´ä¸»æ¨¡å‹åˆ¤åˆ«åŠ›ä¸‹é™ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº† SPFT-SQL æ¡†æ¶ã€‚åœ¨è‡ªå¯¹å¼ˆé˜¶æ®µä¹‹å‰ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†åŸºäºéªŒè¯çš„è¿­ä»£å¾®è°ƒ (Verification-based iterative fine-tuning) ç­–ç•¥ï¼Œé€šè¿‡æ•°æ®åº“æ¨¡å¼å’ŒéªŒè¯åé¦ˆè¿­ä»£åˆæˆé«˜è´¨é‡å¾®è°ƒæ•°æ®ï¼Œå¹¶æ„å»ºå‡ºå…·æœ‰ä¸åŒèƒ½åŠ›çš„æ¨¡å‹åŸºç¡€ã€‚åœ¨è‡ªå¯¹å¼ˆå¾®è°ƒé˜¶æ®µï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é”™è¯¯é©±åŠ¨çš„æŸå¤±æ–¹æ³• (Error-driven loss method)ï¼Œé€šè¿‡æ¿€åŠ±å¯¹æ‰‹æ¨¡å‹äº§ç”Ÿé”™è¯¯è¾“å‡ºï¼Œä½¿ä¸»æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¾¨åˆ«æ­£ç¡® SQL ä¸å¯¹æ‰‹ç”Ÿæˆçš„é”™è¯¯ SQLã€‚è¿™ç§æœºåˆ¶æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹ç”Ÿæˆç²¾ç¡® SQL æŸ¥è¯¢çš„èƒ½åŠ›ï¼Œè§£å†³äº†ä¼ ç»Ÿè‡ªå¯¹å¼ˆåœ¨ç‰¹å®šä»»åŠ¡ä¸‹çš„ä¿¡æ¯åŒ®ä¹é—®é¢˜ã€‚å®éªŒåœ¨ 6 ä¸ªå¼€æºå¤§è¯­è¨€æ¨¡å‹ (LLMs) å’Œ 5 ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•é›†ä¸Šè¿›è¡Œï¼Œç»“æœè¡¨æ˜ SPFT-SQL çš„æ€§èƒ½ä¼˜äºç°æœ‰çš„å…ˆè¿› (SOTA) æ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2509.03937v2",
      "published_date": "2025-09-04 06:55:46 UTC",
      "updated_date": "2025-10-11 08:01:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:37:18.889814+00:00"
    },
    {
      "arxiv_id": "2509.04535v1",
      "title": "In-Context Policy Adaptation via Cross-Domain Skill Diffusion",
      "title_zh": "åŸºäºè·¨åŸŸæŠ€èƒ½æ‰©æ•£çš„ä¸Šä¸‹æ–‡ç­–ç•¥è‡ªé€‚åº”",
      "authors": [
        "Minjong Yoo",
        "Woo Kyung Kim",
        "Honguk Woo"
      ],
      "abstract": "In this work, we present an in-context policy adaptation (ICPAD) framework designed for long-horizon multi-task environments, exploring diffusion-based skill learning techniques in cross-domain settings. The framework enables rapid adaptation of skill-based reinforcement learning policies to diverse target domains, especially under stringent constraints on no model updates and only limited target domain data. Specifically, the framework employs a cross-domain skill diffusion scheme, where domain-agnostic prototype skills and a domain-grounded skill adapter are learned jointly and effectively from an offline dataset through cross-domain consistent diffusion processes. The prototype skills act as primitives for common behavior representations of long-horizon policies, serving as a lingua franca to bridge different domains. Furthermore, to enhance the in-context adaptation performance, we develop a dynamic domain prompting scheme that guides the diffusion-based skill adapter toward better alignment with the target domain. Through experiments with robotic manipulation in Metaworld and autonomous driving in CARLA, we show that our $\\oursol$ framework achieves superior policy adaptation performance under limited target domain data conditions for various cross-domain configurations including differences in environment dynamics, agent embodiment, and task horizon.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ICPAD æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é•¿ç¨‹å¤šä»»åŠ¡ç¯å¢ƒä¸‹çš„ä¸Šä¸‹æ–‡ç­–ç•¥è‡ªé€‚åº” (In-Context Policy Adaptation) é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†è·¨åŸŸæŠ€èƒ½æ‰©æ•£ (Cross-Domain Skill Diffusion) æ–¹æ¡ˆï¼Œä»ç¦»çº¿æ•°æ®ä¸­å…±åŒå­¦ä¹ é¢†åŸŸæ— å…³çš„åŸå‹æŠ€èƒ½ (Domain-Agnostic Prototype Skills) å’Œé¢†åŸŸæ¥åœ°çš„æŠ€èƒ½é€‚é…å™¨ (Domain-Grounded Skill Adapter)ã€‚å…¶ä¸­åŸå‹æŠ€èƒ½ä½œä¸ºé€šç”¨è¡Œä¸ºè¡¨å¾çš„åŸºå…ƒï¼Œèƒ½å¤Ÿå……å½“è¿æ¥ä¸åŒé¢†åŸŸçš„æ¡¥æ¢ï¼Œè€ŒåŠ¨æ€é¢†åŸŸæç¤º (Dynamic Domain Prompting) æœºåˆ¶åˆ™è¿›ä¸€æ­¥å¢å¼ºäº†é€‚é…å™¨ä¸ç›®æ ‡é¢†åŸŸçš„å¯¹é½æ•ˆæœã€‚åœ¨æ— éœ€æ¨¡å‹æ›´æ–°ä¸”ä»…æœ‰å°‘é‡ç›®æ ‡é¢†åŸŸæ•°æ®çš„ä¸¥è‹›æ¡ä»¶ä¸‹ï¼Œè¯¥æ–¹æ³•å®ç°äº†ç­–ç•¥çš„å¿«é€Ÿè¿ç§»ã€‚é€šè¿‡åœ¨ Metaworld æœºå™¨äººæ“ä½œå’Œ CARLA è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„å®éªŒï¼Œè¯æ˜äº† ICPAD åœ¨ç¯å¢ƒåŠ¨åŠ›å­¦ã€æ™ºèƒ½ä½“å½¢æ€åŠä»»åŠ¡è·¨åº¦å­˜åœ¨å·®å¼‚çš„å¤šç§è·¨åŸŸé…ç½®ä¸‹ï¼Œå‡å…·æœ‰ä¼˜è¶Šçš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.04535v1",
      "published_date": "2025-09-04 06:55:38 UTC",
      "updated_date": "2025-09-04 06:55:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:37:27.898053+00:00"
    },
    {
      "arxiv_id": "2509.03934v1",
      "title": "SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment",
      "title_zh": "SelfAugï¼šé€šè¿‡åˆ†å¸ƒè‡ªå¯¹é½ç¼“è§£æ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„ç¾éš¾æ€§é—å¿˜",
      "authors": [
        "Yuqing Huang",
        "Rongyang Zhang",
        "Qimeng Wang",
        "Chengqiang Lu",
        "Yan Gao",
        "Yi Wu",
        "Yao Hu",
        "Xuyang Zhi",
        "Guiquan Liu",
        "Xin Li",
        "Hao Wang",
        "Enhong Chen"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have revolutionized natural language processing through their remarkable capabilities in understanding and executing diverse tasks. While supervised fine-tuning, particularly in Retrieval-Augmented Generation (RAG) scenarios, effectively enhances task-specific performance, it often leads to catastrophic forgetting, where models lose their previously acquired knowledge and general capabilities. Existing solutions either require access to general instruction data or face limitations in preserving the model's original distribution. To overcome these limitations, we propose SelfAug, a self-distribution alignment method that aligns input sequence logits to preserve the model's semantic distribution, thereby mitigating catastrophic forgetting and improving downstream performance. Extensive experiments demonstrate that SelfAug achieves a superior balance between downstream learning and general capability retention. Our comprehensive empirical analysis reveals a direct correlation between distribution shifts and the severity of catastrophic forgetting in RAG scenarios, highlighting how the absence of RAG capabilities in general instruction tuning leads to significant distribution shifts during fine-tuning. Our findings not only advance the understanding of catastrophic forgetting in RAG contexts but also provide a practical solution applicable across diverse fine-tuning scenarios. Our code is publicly available at https://github.com/USTC-StarTeam/SelfAug.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åœºæ™¯è¿›è¡Œç›‘ç£å¾®è°ƒæ—¶äº§ç”Ÿçš„ç¾éš¾æ€§é—å¿˜(catastrophic forgetting)é—®é¢˜ï¼Œæå‡ºäº†åä¸ºSelfAugçš„è‡ªåˆ†å¸ƒå¯¹é½(self-distribution alignment)æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹é½è¾“å…¥åºåˆ—çš„logitsæ¥ä¿ç•™æ¨¡å‹çš„åŸå§‹è¯­ä¹‰åˆ†å¸ƒï¼Œä»è€Œåœ¨æå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„åŒæ—¶æœ‰æ•ˆç¼“è§£é€šç”¨èƒ½åŠ›çš„ä¸¢å¤±ã€‚å®è¯åˆ†ææ­ç¤ºäº†åˆ†å¸ƒåç§»(distribution shifts)æ˜¯å¯¼è‡´RAGåœºæ™¯ä¸‹ç¾éš¾æ€§é—å¿˜çš„å…³é”®å› ç´ ï¼Œè€ŒSelfAugé€šè¿‡ç»´æŒåˆ†å¸ƒä¸€è‡´æ€§ï¼Œåœ¨ä¸‹æ¸¸å­¦ä¹ ä¸é€šç”¨çŸ¥è¯†ä¿ç•™ä¹‹é—´å–å¾—äº†ä¼˜å¼‚çš„å¹³è¡¡ã€‚å®éªŒç»“æœéªŒè¯äº†SelfAugåœ¨å¤šç§å¾®è°ƒåœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ï¼Œä¸ä»…æ·±åŒ–äº†å¯¹RAGè¯­å¢ƒä¸‹é—å¿˜æœºåˆ¶çš„ç†è§£ï¼Œä¹Ÿä¸ºè§£å†³æ¨¡å‹é€€åŒ–é—®é¢˜æä¾›äº†å®ç”¨çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03934v1",
      "published_date": "2025-09-04 06:50:47 UTC",
      "updated_date": "2025-09-04 06:50:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:37:35.688971+00:00"
    },
    {
      "arxiv_id": "2509.03918v2",
      "title": "Chain or tree? Re-evaluating complex reasoning from the perspective of a matrix of thought",
      "title_zh": "é“¾å¼è¿˜æ˜¯æ ‘çŠ¶ï¼Ÿä»æ€ç»´çŸ©é˜µè§†è§’é‡æ–°å®¡è§†å¤æ‚æ¨ç†",
      "authors": [
        "Fengxiao Tang",
        "Yufeng Li",
        "Zongzong Wu",
        "Ming Zhao"
      ],
      "abstract": "Large Language Models (LLMs) face significant accuracy degradation due to insufficient reasoning ability when dealing with complex and abstract tasks. Thought structures such as Chain of Thought (CoT) and Tree of Thought (ToT) focus on enhancing the reasoning capability of LLMs. However, they suffer from inherent drawbacks such as redundancy within the same layer of the tree structure and the singularity of the paths in the chain structure. Some studies have utilized Retrieval-Augmented Generation (RAG) methods to enhance CoT and ToT in mitigating hallucinations in LLMs, yet the fundamental shortcomings of the thought structures still persist. Furthermore, when dealing with multi-entity and multi-hop information, the retrieved verification knowledge often contains large amounts of fragmented, superficial, or even erroneous data, misleading the reasoning process of LLMs. To address these issues, we propose the Matrix of Thought (MoT), a novel and efficient thought structure for LLMs. MoT explores problems in both horizontal and vertical dimensions through a \"column-cell communication\" mechanism, enabling LLMs to actively engage in multi-strategy and deep thinking while reducing redundancy in the thought nodes within the column cells, thereby enhancing the reasoning capability of LLMs. Additionally, through a fact-correction mechanism, it leverages the knowledge graph triples retrieved by RAG and the original text to construct knowledge units and correct erroneous answers. To validate the effectiveness of this method, we conducted extensive experiments in three tasks: 24-point game, question answering evaluation, and proposition writing.The results demonstrate that our framework outperforms state-of-the-art methods, with reasoning time only 14.4\\% of that of the baseline method, proving its efficiency and accuracy. The code for framework is available at https://github.com/lyfiter/mtqa.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤„ç†å¤æ‚æŠ½è±¡ä»»åŠ¡æ—¶æ¨ç†èƒ½åŠ›ä¸è¶³å¯¼è‡´å‡†ç¡®ç‡ä¸‹é™çš„é—®é¢˜ï¼Œåˆ†æäº† Chain of Thought (CoT) å’Œ Tree of Thought (ToT) åœ¨è·¯å¾„å•ä¸€æ€§åŠç»“æ„å†—ä½™æ–¹é¢çš„å›ºæœ‰ç¼ºé™·ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º Matrix of Thought (MoT) çš„æ–°å‹é«˜æ•ˆæ¨ç†ç»“æ„ï¼Œæ—¨åœ¨å¢å¼ºæ¨¡å‹çš„é€»è¾‘å¤„ç†èƒ½åŠ›ã€‚MoT é€šè¿‡â€œåˆ—å•å…ƒé€šä¿¡ (column-cell communication)â€æœºåˆ¶åœ¨æ°´å¹³å’Œå‚ç›´ä¸¤ä¸ªç»´åº¦æ¢ç´¢é—®é¢˜ï¼Œåœ¨æ”¯æŒå¤šç­–ç•¥æ·±åº¦æ€è€ƒçš„åŒæ—¶å‡å°‘äº†æ¨ç†èŠ‚ç‚¹çš„å†—ä½™ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯ï¼Œåˆ©ç”¨çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„æ„å»ºäº‹å®ä¿®æ­£æœºåˆ¶ï¼Œä»è€Œæœ‰æ•ˆçº æ­£æ¨ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ä¿¡æ¯ã€‚å®éªŒåœ¨ 24ç‚¹æ¸¸æˆã€é—®ç­”è¯„ä¼°å’Œå‘½é¢˜å†™ä½œä¸‰é¡¹ä»»åŠ¡ä¸­éªŒè¯äº† MoT çš„æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¸”æ¨ç†è€—æ—¶ä»…ä¸ºåŸºçº¿æ–¹æ³•çš„ 14.4%ï¼Œæ˜¾è‘—æå‡äº†å¤æ‚æ¨ç†ä»»åŠ¡çš„æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03918v2",
      "published_date": "2025-09-04 06:13:28 UTC",
      "updated_date": "2025-09-26 15:57:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:37:41.784362+00:00"
    },
    {
      "arxiv_id": "2509.05368v3",
      "title": "Long-Horizon Visual Imitation Learning via Plan and Code Reflection",
      "title_zh": "åŸºäºè§„åˆ’ä¸ä»£ç åæ€çš„é•¿ç¨‹è§†è§‰æ¨¡ä»¿å­¦ä¹ ",
      "authors": [
        "Quan Chen",
        "Chenrui Shi",
        "Qi Chen",
        "Yuwei Wu",
        "Zhi Gao",
        "Xintong Zhang",
        "Rui Gao",
        "Kun Wu",
        "Yunde Jia"
      ],
      "abstract": "Learning from long-horizon demonstrations with complex action sequences presents significant challenges for visual imitation learning, particularly in understanding temporal relationships of actions and spatial relationships between objects. In this paper, we propose a new agent framework that incorporates two dedicated reflection modules to enhance both plan and code generation. The plan generation module produces an initial action sequence, which is then verified by the plan reflection module to ensure temporal coherence and spatial alignment with the demonstration video. The code generation module translates the plan into executable code, while the code reflection module verifies and refines the generated code to ensure correctness and consistency with the generated plan. These two reflection modules jointly enable the agent to detect and correct errors in both the plan generation and code generation, improving performance in tasks with intricate temporal and spatial dependencies. To support systematic evaluation, we introduce LongVILBench, a benchmark comprising 300 human demonstrations with action sequences of up to 18 steps. LongVILBench emphasizes temporal and spatial complexity across multiple task types. Experimental results demonstrate that existing methods perform poorly on this benchmark, whereas our new framework establishes a strong baseline for long-horizon visual imitation learning.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹é•¿æ—¶ç¨‹è§†è§‰æ¨¡ä»¿å­¦ä¹ (Long-Horizon Visual Imitation Learning)ä¸­åŠ¨ä½œæ—¶é—´å…³ç³»å’Œç‰©ä½“ç©ºé—´å…³ç³»ç†è§£å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆè§„åˆ’ä¸ä»£ç åæ€çš„æ–°å‹æ™ºèƒ½ä½“æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸“é—¨çš„åæ€æ¨¡å—ï¼Œå…¶ä¸­è§„åˆ’ç”Ÿæˆæ¨¡å—(Plan Generation Module)è´Ÿè´£äº§ç”Ÿåˆå§‹åŠ¨ä½œåºåˆ—ï¼Œå¹¶ç”±è§„åˆ’åæ€æ¨¡å—(Plan Reflection Module)éªŒè¯å…¶æ—¶é—´è¿è´¯æ€§ä»¥åŠä¸æ¼”ç¤ºè§†é¢‘çš„ç©ºé—´å¯¹é½ã€‚ä»£ç ç”Ÿæˆæ¨¡å—(Code Generation Module)éšåå°†è§„åˆ’è½¬åŒ–ä¸ºå¯æ‰§è¡Œä»£ç ï¼Œå¹¶ç”±ä»£ç åæ€æ¨¡å—(Code Reflection Module)è¿›ä¸€æ­¥éªŒè¯ä»£ç çš„æ­£ç¡®æ€§ä¸ä¸€è‡´æ€§ã€‚è¿™ä¸¤ä¸ªåæ€æ¨¡å—ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ£€æµ‹å¹¶çº æ­£ç”Ÿæˆè¿‡ç¨‹ä¸­çš„é”™è¯¯ï¼Œä»è€Œæ˜¾è‘—æå‡å¤„ç†å¤æ‚æ—¶ç©ºä¾èµ–ä»»åŠ¡çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…æ¨å‡ºäº†åŒ…å«300ä¸ªäººç±»æ¼”ç¤ºæ¡ˆä¾‹çš„LongVILBenchåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†å¤šè¾¾18æ­¥çš„é•¿åºåˆ—ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç°æœ‰æ–¹æ³•è¡¨ç°ä¸ä½³çš„æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸­å»ºç«‹äº†å¼ºæœ‰åŠ›çš„åŸºå‡†(Strong Baseline)ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05368v3",
      "published_date": "2025-09-04 06:10:32 UTC",
      "updated_date": "2025-12-18 08:12:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:37:39.600131+00:00"
    },
    {
      "arxiv_id": "2509.03906v1",
      "title": "A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning",
      "title_zh": "é€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ å®ç°å®šä½æ¨ç†çš„èƒ¸éƒ¨ X çº¿ç‰‡è§£è¯»åŸºç¡€æ¨¡å‹",
      "authors": [
        "Qika Lin",
        "Yifan Zhu",
        "Bin Pu",
        "Ling Huang",
        "Haoran Luo",
        "Jingying Ma",
        "Zhen Peng",
        "Tianzhe Zhao",
        "Fangzhi Xu",
        "Jian Zhang",
        "Kai He",
        "Zhonghong Ou",
        "Swapnil Mishra",
        "Mengling Feng"
      ],
      "abstract": "Medical foundation models (FMs) have shown tremendous promise amid the rapid advancements in artificial intelligence (AI) technologies. However, current medical FMs typically generate answers in a black-box manner, lacking transparent reasoning processes and locally grounded interpretability, which hinders their practical clinical deployments. To this end, we introduce DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It leverages a sequential training pipeline: initially fine-tuned on curated CXR instruction data to equip with fundamental CXR interpretation capabilities, then exposed to high-quality synthetic reasoning samples to enable cold-start reasoning, and finally refined via online reinforcement learning to enhance both grounded reasoning quality and generation performance. Thus, the model produces both an answer and reasoning steps tied to the image's local regions for each query. Quantitative evaluation demonstrates substantial improvements in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent) tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking framework using advanced language models to evaluate answer quality, further highlighting the superiority of DeepMedix-R1. Expert review of generated reasoning steps reveals greater interpretability and clinical plausibility compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall preference). Collectively, our work advances medical FM development toward holistic, transparent, and clinically actionable modeling for CXR interpretation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† DeepMedix-R1ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹èƒ¸éƒ¨ X å°„çº¿ (Chest X-ray, CXR) è§£é‡Šçš„å…¨æ–¹ä½åŒ»ç–—åŸºç¡€æ¨¡å‹ (Medical Foundation Model)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹ç¼ºä¹é€æ˜æ¨ç†è¿‡ç¨‹å’Œå±€éƒ¨è½åœ°å¯è§£é‡Šæ€§çš„é»‘ç›’é—®é¢˜ã€‚è¯¥æ¨¡å‹é‡‡ç”¨é¡ºåºè®­ç»ƒæµæ°´çº¿ (sequential training pipeline)ï¼Œé¦–å…ˆåœ¨ CXR æŒ‡ä»¤æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œéšåé€šè¿‡é«˜è´¨é‡åˆæˆæ¨ç†æ ·æœ¬å®ç°å†·å¯åŠ¨æ¨ç† (cold-start reasoning)ï¼Œå¹¶æœ€ç»ˆåˆ©ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹  (Online Reinforcement Learning) ä¼˜åŒ–è½åœ°æ¨ç† (grounded reasoning) è´¨é‡ã€‚è¿™ä½¿å¾— DeepMedix-R1 åœ¨å›ç­”æŸ¥è¯¢æ—¶èƒ½äº§ç”Ÿä¸å›¾åƒå±€éƒ¨åŒºåŸŸç»‘å®šçš„æ¨ç†æ­¥éª¤ï¼Œæ˜¾è‘—å¢å¼ºäº†ä¸´åºŠå¯è§£é‡Šæ€§ã€‚å®šé‡è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨æŠ¥å‘Šç”Ÿæˆå’Œè§†è§‰é—®ç­” (VQA) ä»»åŠ¡ä¸Šçš„è¡¨ç°å¤§å¹…é¢†å…ˆäº LLaVA-Radã€MedGemma å’Œ CheXagent ç­‰åŸºå‡†æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æå‡ºäº† Report Arena è¯„ä¼°æ¡†æ¶ï¼Œä¸“å®¶è¯„å®¡è¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ¨¡å‹åœ¨ä¸´åºŠåˆç†æ€§ä¸å¯è§£é‡Šæ€§ä¸Šä¼˜äº Qwen2.5-VL-7Bã€‚è¯¥å·¥ä½œæœ‰åŠ›æ¨åŠ¨äº†åŒ»ç–—åŸºç¡€æ¨¡å‹å‘æ•´ä½“åŒ–ã€é€æ˜åŒ–åŠå…·å¤‡ä¸´åºŠå¯æ“ä½œæ€§çš„æ–¹å‘å‘å±•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.03906v1",
      "published_date": "2025-09-04 06:00:04 UTC",
      "updated_date": "2025-09-04 06:00:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:00.885654+00:00"
    },
    {
      "arxiv_id": "2509.05367v3",
      "title": "Between a Rock and a Hard Place: The Tension Between Ethical Reasoning and Safety Alignment in LLMs",
      "title_zh": "è¿›é€€ç»´è°·ï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­ä¼¦ç†æ¨ç†ä¸å®‰å…¨å¯¹é½ä¹‹é—´çš„å¼ åŠ›",
      "authors": [
        "Shei Pern Chua",
        "Zhen Leng Thai",
        "Kai Jun Teh",
        "Xiao Li",
        "Qibing Ren",
        "Xiaolin Hu"
      ],
      "abstract": "Large Language Model safety alignment predominantly operates on a binary assumption that requests are either safe or unsafe. This classification proves insufficient when models encounter ethical dilemmas, where the capacity to reason through moral trade-offs creates a distinct attack surface. We formalize this vulnerability through TRIAL, a multi-turn red-teaming methodology that embeds harmful requests within ethical framings. TRIAL achieves high attack success rates across most tested models by systematically exploiting the model's ethical reasoning capabilities to frame harmful actions as morally necessary compromises. Building on these insights, we introduce ERR (Ethical Reasoning Robustness), a defense framework that distinguishes between instrumental responses that enable harmful outcomes and explanatory responses that analyze ethical frameworks without endorsing harmful acts. ERR employs a Layer-Stratified Harm-Gated LoRA architecture, achieving robust defense against reasoning-based attacks while preserving model utility.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å¯¹é½ï¼ˆSafety Alignmentï¼‰ä¸ä¼¦ç†æ¨ç†ï¼ˆEthical Reasoningï¼‰ä¹‹é—´çš„å†…åœ¨å¼ åŠ›ï¼ŒæŒ‡å‡ºç›®å‰çš„äºŒè¿›åˆ¶å®‰å…¨å‡è®¾åœ¨å¤„ç†ä¼¦ç†å›°å¢ƒæ—¶å­˜åœ¨æ˜¾è‘—ç¼ºé™·ã€‚ä½œè€…é€šè¿‡å½¢å¼åŒ–ä¸€ç§åä¸º TRIAL çš„å¤šè½®çº¢é˜Ÿæµ‹è¯•ï¼ˆRed-teamingï¼‰æ–¹æ³•ï¼Œæ­ç¤ºäº†æ”»å‡»è€…å¯ä»¥åˆ©ç”¨ä¼¦ç†æ¡†æ¶å°†æœ‰å®³è¡Œä¸ºä¼ªè£…æˆâ€œé“å¾·ä¸Šå¿…è¦çš„æŠ˜ä¸­â€ï¼Œä»è€Œè¯±å¯¼æ¨¡å‹ç»•è¿‡å®‰å…¨é™åˆ¶ã€‚é’ˆå¯¹è¿™ä¸€æ¼æ´ï¼Œç ”ç©¶æå‡ºäº†ä¼¦ç†æ¨ç†é²æ£’æ€§ï¼ˆEthical Reasoning Robustness, ERRï¼‰é˜²å¾¡æ¡†æ¶ï¼Œæ—¨åœ¨åŒºåˆ†ä¿ƒæˆæœ‰å®³ç»“æœçš„å·¥å…·æ€§å“åº”ä¸ä»…è¿›è¡Œä¼¦ç†åˆ†æçš„è§£é‡Šæ€§å“åº”ã€‚ERR é‡‡ç”¨äº†å±‚åˆ†å±‚å®³é—¨æ§ LoRAï¼ˆLayer-Stratified Harm-Gated LoRAï¼‰æ¶æ„ï¼Œåœ¨ä¸æŸå®³æ¨¡å‹é€šç”¨å®ç”¨æ€§çš„å‰æä¸‹ï¼Œå®ç°äº†å¯¹åŸºäºæ¨ç†æ”»å‡»çš„é²æ£’é˜²å¾¡ã€‚è¯¥ç ”ç©¶ä¸ºç†è§£æ¨¡å‹é“å¾·æ¨ç†ä¸å®‰å…¨è¾¹ç•Œä¹‹é—´çš„å¤æ‚å…³ç³»æä¾›äº†é‡è¦è§è§£ï¼Œå¹¶ä¸ºæ„å»ºæ›´å…·é˜²å¾¡æ€§çš„è¯­è¨€æ¨¡å‹å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05367v3",
      "published_date": "2025-09-04 05:53:20 UTC",
      "updated_date": "2026-01-10 05:42:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:03.592451+00:00"
    },
    {
      "arxiv_id": "2509.03898v2",
      "title": "Diffusion Generative Models Meet Compressed Sensing, with Applications to Imaging and Finance",
      "title_zh": "æ‰©æ•£ç”Ÿæˆæ¨¡å‹ä¸å‹ç¼©æ„ŸçŸ¥çš„ç»“åˆï¼šæˆåƒä¸é‡‘èé¢†åŸŸçš„åº”ç”¨",
      "authors": [
        "Zhengyi Guo",
        "Jiatu Li",
        "Wenpin Tang",
        "David D. Yao"
      ],
      "abstract": "In this study we develop dimension-reduction techniques to accelerate diffusion model inference in the context of synthetic data generation. The idea is to integrate compressed sensing into diffusion models (hence, CSDM): First, compress the dataset into a latent space (from an ambient space), and train a diffusion model in the latent space; next, apply a compressed sensing algorithm to the samples generated in the latent space for decoding back to the original space; and the goal is to facilitate the efficiency of both model training and inference. Under certain sparsity assumptions on data, our proposed approach achieves provably faster convergence, via combining diffusion model inference with sparse recovery. It also sheds light on the best choice of the latent space dimension. To illustrate the effectiveness of this approach, we run numerical experiments on a range of datasets, including handwritten digits, medical and climate images, and financial time series for stress testing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CSDMï¼ˆCompressed Sensing into Diffusion Modelsï¼‰æ¡†æ¶ï¼Œé€šè¿‡å°†å‹ç¼©æ„ŸçŸ¥ï¼ˆCompressed Sensingï¼‰æŠ€æœ¯ä¸æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰ç›¸ç»“åˆï¼Œæ—¨åœ¨åŠ é€Ÿåˆæˆæ•°æ®ç”Ÿæˆä¸­çš„æ¨¡å‹æ¨ç†ä¸è®­ç»ƒè¿‡ç¨‹ã€‚è¯¥æ–¹æ³•é¦–å…ˆå°†æ•°æ®é›†å‹ç¼©åˆ°ä½ç»´æ½œç©ºé—´ï¼ˆLatent Spaceï¼‰ï¼Œåœ¨è¯¥ç©ºé—´å†…è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œéšååˆ©ç”¨å‹ç¼©æ„ŸçŸ¥ç®—æ³•å°†ç”Ÿæˆçš„æ½œç©ºé—´æ ·æœ¬è§£ç å›åŸå§‹ç©ºé—´ã€‚åœ¨æ•°æ®æ»¡è¶³ç‰¹å®šç¨€ç–æ€§å‡è®¾çš„æƒ…å†µä¸‹ï¼Œè¯¥ç ”ç©¶ä»ç†è®ºä¸Šè¯æ˜äº†ç»“åˆæ‰©æ•£æ¨¡å‹æ¨ç†ä¸ç¨€ç–æ¢å¤ï¼ˆSparse Recoveryï¼‰èƒ½å¤Ÿå®ç°æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼Œå¹¶ä¸ºæ½œç©ºé—´ç»´åº¦çš„æœ€ä¼˜é€‰æ‹©æä¾›äº†æŒ‡å¯¼ã€‚é€šè¿‡åœ¨æ‰‹å†™æ•°å­—ã€åŒ»ç–—ä¸æ°”å€™å›¾åƒä»¥åŠç”¨äºå‹åŠ›æµ‹è¯•çš„é‡‘èæ—¶é—´åºåˆ—ï¼ˆFinancial Time Seriesï¼‰ç­‰å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ•°å€¼å®éªŒï¼Œè¯¥ç ”ç©¶éªŒè¯äº†æ­¤æ–¹æ³•åœ¨æå‡è®¡ç®—æ•ˆç‡å’Œç”Ÿæˆè´¨é‡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03898v2",
      "published_date": "2025-09-04 05:45:06 UTC",
      "updated_date": "2025-09-28 19:56:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:08.107711+00:00"
    },
    {
      "arxiv_id": "2509.06996v5",
      "title": "Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems",
      "title_zh": "å¯è§å´ä¸å¯è¯»ï¼šè§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¸åŒä¹¦å†™ç³»ç»Ÿä¸­çš„ç³»ç»Ÿæ€§ç›²åŒº",
      "authors": [
        "Jie Zhang",
        "Ting Xu",
        "Gelei Deng",
        "Runyi Hu",
        "Han Qiu",
        "Tianwei Zhang",
        "Qing Guo",
        "Ivor Tsang"
      ],
      "abstract": "Writing is a universal cultural technology that reuses vision for symbolic communication. Humans display striking resilience: we readily recognize words even when characters are fragmented, fused, or partially occluded. This paper investigates whether advanced vision language models (VLMs) share this resilience. We construct two psychophysics inspired benchmarks across distinct writing systems, Chinese logographs and English alphabetic words, by splicing, recombining, and overlaying glyphs to yield ''visible but unreadable'' stimuli for models while remaining legible to humans. Despite strong performance on clean text, contemporary VLMs show a severe drop under these perturbations, frequently producing unrelated or incoherent outputs. The pattern suggests a structural limitation: models heavily leverage generic visual invariances but under rely on compositional priors needed for robust literacy. We release stimuli generation code, prompts, and evaluation protocols to facilitate transparent replication and follow up work. Our findings motivate architectures and training strategies that encode symbol segmentation, composition, and binding across scripts, and they delineate concrete challenges for deploying multimodal systems in education, accessibility, cultural heritage, and security.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨é¢å¯¹ç¢ç‰‡åŒ–ã€èåˆæˆ–éƒ¨åˆ†é®æŒ¡çš„æ–‡å­—æ—¶ï¼Œæ˜¯å¦å…·å¤‡äººç±»èˆ¬çš„è¯†åˆ«éŸ§æ€§ã€‚ç ”ç©¶è€…é’ˆå¯¹ä¸­æ–‡è¡¨æ„æ–‡å­—å’Œè‹±æ–‡æ‹¼éŸ³æ–‡å­—æ„å»ºäº†ä¸¤ä¸ªå—å¿ƒç†ç‰©ç†å­¦å¯å‘çš„åŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡å‰ªè¾‘ã€é‡ç»„å’Œå åŠ å­—å½¢ï¼Œåˆ¶é€ å‡ºäººç±»å¯è¯»ä½†æ¨¡å‹éš¾ä»¥è¾¨è¯†çš„åˆºæ¿€ã€‚å®éªŒå‘ç°ï¼Œå°½ç®¡å½“ä»£VLMsåœ¨æ¸…æ™°æ–‡æœ¬ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨è¿™äº›æ‰°åŠ¨ä¸‹å‡†ç¡®ç‡ä¸¥é‡ä¸‹é™ï¼Œå¸¸äº§ç”Ÿæ— å…³æˆ–ä¸è¿è´¯çš„è¾“å‡ºã€‚è¿™ä¸€ç°è±¡æ­ç¤ºäº†æ¨¡å‹çš„ç»“æ„æ€§å±€é™ï¼Œå³è¿‡åº¦ä¾èµ–é€šç”¨è§†è§‰ä¸å˜æ€§ï¼Œè€Œç¼ºä¹é²æ£’è¯†å­—æ‰€éœ€çš„ç»„åˆå…ˆéªŒ(compositional priors)ã€‚è¯¥ç ”ç©¶æä¾›äº†å®Œæ•´çš„åˆºæ¿€ç”Ÿæˆä»£ç å’Œè¯„ä¼°åè®®ï¼Œæ—¨åœ¨é€šè¿‡ç¼–ç ç¬¦å·åˆ†å‰²ä¸ç»„åˆæ¥æ”¹è¿›å¤šæ¨¡æ€ç³»ç»Ÿæ¶æ„ï¼Œä¸ºæ•™è‚²ã€æ— éšœç¢å’Œå®‰å…¨ç­‰é¢†åŸŸçš„åº”ç”¨æŒ‡æ˜äº†å…·ä½“æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: This article has been withdrawn by arXiv administrators due to violation of arXiv policy regarding generative AI authorship",
      "pdf_url": "https://arxiv.org/pdf/2509.06996v5",
      "published_date": "2025-09-04 05:35:32 UTC",
      "updated_date": "2025-12-01 20:23:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:11.584217+00:00"
    },
    {
      "arxiv_id": "2509.03890v1",
      "title": "FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace",
      "title_zh": "FaMAï¼šé¢å‘ C2C äº¤æ˜“å¹³å°çš„å¤§æ¨¡å‹èµ‹èƒ½æ™ºèƒ½ä½“åŠ©æ‰‹",
      "authors": [
        "Yineng Yan",
        "Xidong Wang",
        "Jin Seng Cheng",
        "Ran Hu",
        "Wentao Guan",
        "Nahid Farahmand",
        "Hengte Lin",
        "Yue Li"
      ],
      "abstract": "The emergence of agentic AI, powered by Large Language Models (LLMs), marks a paradigm shift from reactive generative systems to proactive, goal-oriented autonomous agents capable of sophisticated planning, memory, and tool use. This evolution presents a novel opportunity to address long-standing challenges in complex digital environments. Core tasks on Consumer-to-Consumer (C2C) e-commerce platforms often require users to navigate complex Graphical User Interfaces (GUIs), making the experience time-consuming for both buyers and sellers. This paper introduces a novel approach to simplify these interactions through an LLM-powered agentic assistant. This agent functions as a new, conversational entry point to the marketplace, shifting the primary interaction model from a complex GUI to an intuitive AI agent. By interpreting natural language commands, the agent automates key high-friction workflows. For sellers, this includes simplified updating and renewal of listings, and the ability to send bulk messages. For buyers, the agent facilitates a more efficient product discovery process through conversational search. We present the architecture for Facebook Marketplace Assistant (FaMA), arguing that this agentic, conversational paradigm provides a lightweight and more accessible alternative to traditional app interfaces, allowing users to manage their marketplace activities with greater efficiency. Experiments show FaMA achieves a 98% task success rate on solving complex tasks on the marketplace and enables up to a 2x speedup on interaction time.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†FaMAï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºC2Cï¼ˆConsumer-to-Consumerï¼‰ç”µå­å•†åŠ¡å¹³å°è®¾è®¡çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ä½“åŠ©æ‰‹ï¼Œæ—¨åœ¨è§£å†³ç”¨æˆ·åœ¨å¤æ‚å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIsï¼‰ä¸­å¯¼èˆªæ—¶é¢ä¸´çš„ä½æ•ˆé—®é¢˜ã€‚FaMAé€šè¿‡å°†äº¤äº’æ¨¡å‹ä»ä¼ ç»Ÿç•Œé¢è½¬å‘ç›´è§‚çš„å¯¹è¯å¼æ™ºèƒ½ä½“ï¼Œåˆ©ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªåŠ¨åŒ–é«˜æ‘©æ“¦çš„å·¥ä½œæµã€‚å¯¹äºå–å®¶ï¼Œè¯¥åŠ©æ‰‹ç®€åŒ–äº†å•†å“åˆ—è¡¨çš„æ›´æ–°ã€ç»­æœŸåŠæ‰¹é‡æ¶ˆæ¯å‘é€ï¼›å¯¹äºä¹°å®¶ï¼Œå®ƒåˆ™é€šè¿‡å¯¹è¯å¼æœç´¢æå‡äº†äº§å“å‘ç°çš„æ•ˆç‡ã€‚è¿™ç§åŸºäºAgentçš„å¯¹è¯èŒƒå¼ä¸ºä¼ ç»Ÿçš„åº”ç”¨äº¤äº’æä¾›äº†ä¸€ç§è½»é‡ä¸”æ›´å…·å¯è®¿é—®æ€§çš„æ›¿ä»£æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFaMAåœ¨å¤„ç†å¤æ‚çš„å¸‚åœºä»»åŠ¡æ—¶è¾¾åˆ°äº†98%çš„ä»»åŠ¡æˆåŠŸç‡ï¼Œå¹¶å°†äº¤äº’æ—¶é—´ç¼©çŸ­äº†å¤šè¾¾2å€ï¼Œæ˜¾è‘—æå‡äº†ç”¨æˆ·ç®¡ç†å¸‚åœºæ´»åŠ¨çš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03890v1",
      "published_date": "2025-09-04 05:22:25 UTC",
      "updated_date": "2025-09-04 05:22:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:16.446246+00:00"
    },
    {
      "arxiv_id": "2509.03889v1",
      "title": "Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance",
      "title_zh": "åŸºäºç½®ä¿¡åº¦æ„ŸçŸ¥ç¨ å¯†å¯¹åº”ä¸è§†è§¦è§‰ç¤ºèƒ½çš„ååº”å¼ç©ºä¸­è¡£ç‰©æ“çºµ",
      "authors": [
        "Neha Sunil",
        "Megha Tippur",
        "Arnau Saumell",
        "Edward Adelson",
        "Alberto Rodriguez"
      ],
      "abstract": "Manipulating clothing is challenging due to complex configurations, variable material dynamics, and frequent self-occlusion. Prior systems often flatten garments or assume visibility of key features. We present a dual-arm visuotactile framework that combines confidence-aware dense visual correspondence and tactile-supervised grasp affordance to operate directly on crumpled and suspended garments. The correspondence model is trained on a custom, high-fidelity simulated dataset using a distributional loss that captures cloth symmetries and generates correspondence confidence estimates. These estimates guide a reactive state machine that adapts folding strategies based on perceptual uncertainty. In parallel, a visuotactile grasp affordance network, self-supervised using high-resolution tactile feedback, determines which regions are physically graspable. The same tactile classifier is used during execution for real-time grasp validation. By deferring action in low-confidence states, the system handles highly occluded table-top and in-air configurations. We demonstrate our task-agnostic grasp selection module in folding and hanging tasks. Moreover, our dense descriptors provide a reusable intermediate representation for other planning modalities, such as extracting grasp targets from human video demonstrations, paving the way for more generalizable and scalable garment manipulation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŒè‡‚è§†è§‰è§¦è§‰(visuotactile)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¡£ç‰©åœ¨æ‚¬ç©ºå’Œè¤¶çš±çŠ¶æ€ä¸‹ç”±äºå¤æ‚çš„æ„å‹ã€ææ–™åŠ¨æ€å’Œè‡ªé®æŒ¡å¯¼è‡´çš„æ“çºµéš¾é¢˜ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ç½®ä¿¡åº¦æ„ŸçŸ¥çš„ç¨ å¯†è§†è§‰å¯¹åº”(confidence-aware dense visual correspondence)æ¨¡å‹ï¼Œåˆ©ç”¨åœ¨é«˜è´¨é‡ä»¿çœŸæ•°æ®é›†ä¸Šè®­ç»ƒçš„åˆ†å¸ƒæŸå¤±(distributional loss)æ¥æ•æ‰ç»‡ç‰©çš„å¯¹ç§°æ€§å¹¶ç”Ÿæˆç½®ä¿¡åº¦ä¼°è®¡ã€‚è¿™äº›ç½®ä¿¡åº¦ä¼°è®¡å¼•å¯¼ä¸€ä¸ªååº”å¼çŠ¶æ€æœº(reactive state machine)ï¼Œèƒ½å¤Ÿæ ¹æ®æ„ŸçŸ¥ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´æŠ˜å ç­–ç•¥ã€‚åŒæ—¶ï¼Œç³»ç»Ÿé‡‡ç”¨äº†ä¸€ä¸ªé€šè¿‡é«˜åˆ†è¾¨ç‡è§¦è§‰åé¦ˆè¿›è¡Œè‡ªç›‘ç£è®­ç»ƒçš„è§†è§‰è§¦è§‰æŠ“å–å¯å‘(visuotactile grasp affordance)ç½‘ç»œï¼Œç”¨äºç¡®å®šç‰©ç†å¯æŠ“å–åŒºåŸŸã€‚åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œè¯¥è§¦è§‰åˆ†ç±»å™¨è¿˜ç”¨äºå®æ—¶æŠ“å–éªŒè¯(real-time grasp validation)ï¼Œé€šè¿‡åœ¨ä½ç½®ä¿¡åº¦çŠ¶æ€ä¸‹å»¶è¿ŸåŠ¨ä½œæ¥å¤„ç†é«˜åº¦é®æŒ¡çš„æ¡Œé¢åŠç©ºä¸­æ„å‹ã€‚å®éªŒåœ¨æŠ˜å å’ŒæŒ‚è¡£ä»»åŠ¡ä¸­éªŒè¯äº†è¯¥ä»»åŠ¡æ— å…³çš„æŠ“å–é€‰æ‹©æ¨¡å—ã€‚æ­¤å¤–ï¼Œå…¶ç¨ å¯†æè¿°ç¬¦(dense descriptors)æä¾›äº†ä¸€ç§å¯å¤ç”¨çš„ä¸­é—´è¡¨ç¤ºï¼Œèƒ½å¤Ÿä»äººç±»è§†é¢‘æ¼”ç¤ºä¸­æå–æŠ“å–ç›®æ ‡ï¼Œä¸ºå®ç°æ›´å…·æ³›åŒ–æ€§å’Œå¯æ‰©å±•æ€§çš„è¡£ç‰©æ“çºµå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at CoRL 2025. Project website: https://mhtippur.github.io/inairclothmanipulation/",
      "pdf_url": "https://arxiv.org/pdf/2509.03889v1",
      "published_date": "2025-09-04 05:16:56 UTC",
      "updated_date": "2025-09-04 05:16:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:22.788000+00:00"
    },
    {
      "arxiv_id": "2509.10524v1",
      "title": "Data-Efficient Psychiatric Disorder Detection via Self-supervised Learning on Frequency-enhanced Brain Networks",
      "title_zh": "åŸºäºé¢‘åŸŸå¢å¼ºè„‘ç½‘ç»œè‡ªç›‘ç£å­¦ä¹ çš„æ•°æ®é«˜æ•ˆå‹ç²¾ç¥éšœç¢æ£€æµ‹",
      "authors": [
        "Mujie Liu",
        "Mengchu Zhu",
        "Qichao Dong",
        "Ting Dang",
        "Jiangang Ma",
        "Jing Ren",
        "Feng Xia"
      ],
      "abstract": "Psychiatric disorders involve complex neural activity changes, with functional magnetic resonance imaging (fMRI) data serving as key diagnostic evidence. However, data scarcity and the diverse nature of fMRI information pose significant challenges. While graph-based self-supervised learning (SSL) methods have shown promise in brain network analysis, they primarily focus on time-domain representations, often overlooking the rich information embedded in the frequency domain. To overcome these limitations, we propose Frequency-Enhanced Network (FENet), a novel SSL framework specially designed for fMRI data that integrates time-domain and frequency-domain information to improve psychiatric disorder detection in small-sample datasets. FENet constructs multi-view brain networks based on the inherent properties of fMRI data, explicitly incorporating frequency information into the learning process of representation. Additionally, it employs domain-specific encoders to capture temporal-spectral characteristics, including an efficient frequency-domain encoder that highlights disease-relevant frequency features. Finally, FENet introduces a domain consistency-guided learning objective, which balances the utilization of diverse information and generates frequency-enhanced brain graph representations. Experiments on two real-world medical datasets demonstrate that FENet outperforms state-of-the-art methods while maintaining strong performance in minimal data conditions. Furthermore, we analyze the correlation between various frequency-domain features and psychiatric disorders, emphasizing the critical role of high-frequency information in disorder detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç²¾ç¥ç–¾ç—…æ£€æµ‹ä¸­åŠŸèƒ½ç£å…±æŒ¯æˆåƒ (fMRI) æ•°æ®ç¨€ç¼ºä»¥åŠç°æœ‰è‡ªç›‘ç£å­¦ä¹  (SSL) æ–¹æ³•å¿½è§†é¢‘åŸŸä¿¡æ¯çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º FENet çš„é¢‘ç‡å¢å¼ºç½‘ç»œæ¡†æ¶ã€‚FENet é€šè¿‡æ•´åˆæ—¶åŸŸå’Œé¢‘åŸŸä¿¡æ¯æ„å»ºå¤šè§†è§’è„‘ç½‘ç»œï¼Œå¹¶åˆ©ç”¨ä¸“é—¨çš„é¢†åŸŸç¼–ç å™¨æ•æ‰æ—¶ç©ºè°±ç‰¹å¾ï¼Œæ—¨åœ¨ä»å°æ ·æœ¬æ•°æ®ä¸­æå–ä¸ç–¾ç—…ç›¸å…³çš„å…³é”®ç‰¹å¾ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†é¢†åŸŸä¸€è‡´æ€§å¼•å¯¼çš„å­¦ä¹ ç›®æ ‡ï¼Œæœ‰æ•ˆå¹³è¡¡äº†å¤šå…ƒä¿¡æ¯çš„åˆ©ç”¨å¹¶ç”Ÿæˆå¢å¼ºçš„è„‘å›¾è¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFENet åœ¨ä¸¤ä¸ªçœŸå®åŒ»ç–—æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¸”åœ¨æå°æ ·æœ¬é‡ä¸‹ä¾ç„¶ä¿æŒå¼ºåŠ²æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼ºè°ƒäº†é«˜é¢‘ä¿¡æ¯åœ¨ç²¾ç¥ç–¾ç—…æ£€æµ‹ä¸­çš„å…³é”®ä½œç”¨ï¼Œä¸ºæ•°æ®é«˜æ•ˆçš„åŒ»å­¦è¯Šæ–­æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10524v1",
      "published_date": "2025-09-04 05:10:13 UTC",
      "updated_date": "2025-09-04 05:10:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:26.584824+00:00"
    },
    {
      "arxiv_id": "2509.03884v1",
      "title": "Peptidomic-Based Prediction Model for Coronary Heart Disease Using a Multilayer Perceptron Neural Network",
      "title_zh": "åŸºäºå¤šå±‚æ„ŸçŸ¥å™¨ç¥ç»ç½‘ç»œçš„è‚½ç»„å­¦å† å¿ƒç—…é¢„æµ‹æ¨¡å‹",
      "authors": [
        "Jesus Celis-Porras"
      ],
      "abstract": "Coronary heart disease (CHD) is a leading cause of death worldwide and contributes significantly to annual healthcare expenditures. To develop a non-invasive diagnostic approach, we designed a model based on a multilayer perceptron (MLP) neural network, trained on 50 key urinary peptide biomarkers selected via genetic algorithms. Treatment and control groups, each comprising 345 individuals, were balanced using the Synthetic Minority Over-sampling Technique (SMOTE). The neural network was trained using a stratified validation strategy. Using a network with three hidden layers of 60 neurons each and an output layer of two neurons, the model achieved a precision, sensitivity, and specificity of 95.67 percent, with an F1-score of 0.9565. The area under the ROC curve (AUC) reached 0.9748 for both classes, while the Matthews correlation coefficient (MCC) and Cohen's kappa coefficient were 0.9134 and 0.9131, respectively, demonstrating its reliability in detecting CHD. These results indicate that the model provides a highly accurate and robust non-invasive diagnostic tool for coronary heart disease.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å† å¿ƒç—…(Coronary Heart Disease, CHD)å¼€å‘äº†ä¸€ç§åŸºäºå¤šå±‚æ„ŸçŸ¥å™¨(Multilayer Perceptron, MLP)ç¥ç»ç½‘ç»œçš„éä¾µå…¥å¼è¯Šæ–­é¢„æµ‹æ¨¡å‹ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨é—ä¼ ç®—æ³•(Genetic Algorithms)ä»å°¿æ¶²è‚½ç»„å­¦æ•°æ®ä¸­ç­›é€‰å‡º50ä¸ªå…³é”®è‚½ç”Ÿç‰©æ ‡å¿—ç‰©ï¼Œå¹¶é‡‡ç”¨åˆæˆå°‘æ•°ç±»è¿‡é‡‡æ ·æŠ€æœ¯(Synthetic Minority Over-sampling Technique, SMOTE)ç¡®ä¿äº†å®éªŒç»„ä¸å¯¹ç…§ç»„çš„æ•°æ®å¹³è¡¡ã€‚è¯¥æ¨¡å‹é‡‡ç”¨äº†åŒ…å«ä¸‰ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œå¹¶é€šè¿‡åˆ†å±‚éªŒè¯ç­–ç•¥è¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ç²¾ç¡®åº¦ã€çµæ•åº¦å’Œç‰¹å¼‚æ€§ä¸Šå‡è¾¾åˆ°äº†95.67%ï¼ŒF1åˆ†æ•°è¾¾åˆ°0.9565ï¼Œä¸”ROCæ›²çº¿ä¸‹é¢ç§¯(AUC)é«˜è¾¾0.9748ã€‚æ­¤å¤–ï¼ŒMatthewsç›¸å…³ç³»æ•°(MCC)å’ŒCohen's kappaç³»æ•°çš„è¡¨ç°è¿›ä¸€æ­¥éªŒè¯äº†ç³»ç»Ÿçš„å¯é æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºå† å¿ƒç—…æä¾›äº†ä¸€ä¸ªé«˜ç²¾åº¦ä¸”ç¨³å¥çš„éä¾µå…¥æ€§è¯Šæ–­å·¥å…·ï¼Œå…·æœ‰æ˜¾è‘—çš„ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 6 figures, Submitted to arXiv for public dissemination",
      "pdf_url": "https://arxiv.org/pdf/2509.03884v1",
      "published_date": "2025-09-04 04:54:02 UTC",
      "updated_date": "2025-09-04 04:54:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:25.792115+00:00"
    },
    {
      "arxiv_id": "2509.03873v1",
      "title": "SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition",
      "title_zh": "SalientFusionï¼šä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ç»„åˆå¼é›¶æ ·æœ¬é£Ÿç‰©è¯†åˆ«",
      "authors": [
        "Jiajun Song",
        "Xiaoou Liu"
      ],
      "abstract": "Food recognition has gained significant attention, but the rapid emergence of new dishes requires methods for recognizing unseen food categories, motivating Zero-Shot Food Learning (ZSFL). We propose the task of Compositional Zero-Shot Food Recognition (CZSFR), where cuisines and ingredients naturally align with attributes and objects in Compositional Zero-Shot learning (CZSL). However, CZSFR faces three challenges: (1) Redundant background information distracts models from learning meaningful food features, (2) Role confusion between staple and side dishes leads to misclassification, and (3) Semantic bias in a single attribute can lead to confusion of understanding. Therefore, we propose SalientFusion, a context-aware CZSFR method with two components: SalientFormer, which removes background redundancy and uses depth features to resolve role confusion; DebiasAT, which reduces the semantic bias by aligning prompts with visual features. Using our proposed benchmarks, CZSFood-90 and CZSFood-164, we show that SalientFusion achieves state-of-the-art results on these benchmarks and the most popular general datasets for the general CZSL. The code is avaliable at https://github.com/Jiajun-RUC/SalientFusion.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ç»„åˆé›¶æ ·æœ¬é£Ÿç‰©è¯†åˆ«(Compositional Zero-Shot Food Recognition, CZSFR)ä»»åŠ¡ï¼Œé€šè¿‡å°†èœç³»å’Œé£Ÿæå¯¹åº”ä¸ºå±æ€§å’Œå¯¹è±¡ï¼Œä»¥è§£å†³æ–°èœå“å±‚å‡ºä¸ç©·å¸¦æ¥çš„è¯†åˆ«éš¾é¢˜ã€‚é’ˆå¯¹èƒŒæ™¯ä¿¡æ¯å†—ä½™ã€ä¸»å‰¯é£Ÿè§’è‰²æ··æ·†ä»¥åŠå•ä¸€å±æ€§äº§ç”Ÿçš„è¯­ä¹‰åå·®(Semantic bias)ç­‰æ ¸å¿ƒæŒ‘æˆ˜ï¼Œä½œè€…å¼€å‘äº†åä¸ºSalientFusionçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯†åˆ«æ–¹æ³•ã€‚è¯¥æ¡†æ¶åŒ…å«SalientFormerç»„ä»¶ï¼Œåˆ©ç”¨æ·±åº¦ç‰¹å¾(depth features)æ¶ˆé™¤èƒŒæ™¯å¹²æ‰°å¹¶æ˜ç¡®èœå“è§’è‰²å…³ç³»ï¼›åŒæ—¶å¼•å…¥DebiasATç»„ä»¶ï¼Œé€šè¿‡å°†æç¤ºè¯(prompts)ä¸è§†è§‰ç‰¹å¾å¯¹é½æ¥é™ä½è¯­ä¹‰åå·®ã€‚åœ¨CZSFood-90å’ŒCZSFood-164åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSalientFusionå–å¾—äº†å½“å‰æœ€å…ˆè¿›(State-of-the-art)çš„æ€§èƒ½è¡¨ç°ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨é€šç”¨çš„ç»„åˆé›¶æ ·æœ¬å­¦ä¹ (CZSL)æ•°æ®é›†ä¸Šä¹ŸåŒæ ·å±•ç°äº†æå¼ºçš„ç«äº‰åŠ›ä¸æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "34th International Conference on Artificial Neural Networks - ICANN 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.03873v1",
      "published_date": "2025-09-04 04:22:36 UTC",
      "updated_date": "2025-09-04 04:22:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:28.756302+00:00"
    },
    {
      "arxiv_id": "2509.04534v1",
      "title": "Quantized Large Language Models in Biomedical Natural Language Processing: Evaluation and Recommendation",
      "title_zh": "é‡åŒ–å¤§è¯­è¨€æ¨¡å‹åœ¨ç”Ÿç‰©åŒ»å­¦è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„è¯„ä¼°ä¸å»ºè®®",
      "authors": [
        "Zaifu Zhan",
        "Shuang Zhou",
        "Min Zeng",
        "Kai Yu",
        "Meijia Song",
        "Xiaoyi Chen",
        "Jun Wang",
        "Yu Hou",
        "Rui Zhang"
      ],
      "abstract": "Large language models have demonstrated remarkable capabilities in biomedical natural language processing, yet their rapid growth in size and computational requirements present a major barrier to adoption in healthcare settings where data privacy precludes cloud deployment and resources are limited. In this study, we systematically evaluated the impact of quantization on 12 state-of-the-art large language models, including both general-purpose and biomedical-specific models, across eight benchmark datasets covering four key tasks: named entity recognition, relation extraction, multi-label classification, and question answering. We show that quantization substantially reduces GPU memory requirements-by up to 75%-while preserving model performance across diverse tasks, enabling the deployment of 70B-parameter models on 40GB consumer-grade GPUs. In addition, domain-specific knowledge and responsiveness to advanced prompting methods are largely maintained. These findings provide significant practical and guiding value, highlighting quantization as a practical and effective strategy for enabling the secure, local deployment of large yet high-capacity language models in biomedical contexts, bridging the gap between technical advances in AI and real-world clinical translation.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿè¯„ä¼°äº†é‡åŒ–(Quantization)æŠ€æœ¯å¯¹12ç§å…ˆè¿›å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç”Ÿç‰©åŒ»å­¦è‡ªç„¶è¯­è¨€å¤„ç†(Biomedical NLP)é¢†åŸŸçš„å½±å“ï¼Œæ¶µç›–äº†å‘½åå®ä½“è¯†åˆ«(Named Entity Recognition)ã€å…³ç³»æŠ½å–(Relation Extraction)ã€å¤šæ ‡ç­¾åˆ†ç±»å’Œé—®ç­”(Question Answering)å››å¤§æ ¸å¿ƒä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡åŒ–æŠ€æœ¯èƒ½å°†GPUå†…å­˜éœ€æ±‚æ˜¾è‘—é™ä½é«˜è¾¾75%ï¼ŒåŒæ—¶åœ¨å„é¡¹ä»»åŠ¡ä¸­åŸºæœ¬ä¿æŒäº†æ¨¡å‹çš„åŸå§‹æ€§èƒ½ï¼ŒæˆåŠŸå®ç°äº†åœ¨40GBæ¶ˆè´¹çº§GPUä¸Šéƒ¨ç½²70Bå‚æ•°è§„æ¨¡çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œé‡åŒ–è¿‡ç¨‹å¾ˆå¥½åœ°ä¿ç•™äº†æ¨¡å‹çš„é¢†åŸŸç‰¹å®šçŸ¥è¯†ä»¥åŠå¯¹é«˜çº§æç¤º(Prompting)æ–¹æ³•çš„å“åº”èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨èµ„æºå—é™ä¸”å¯¹æ•°æ®éšç§æœ‰ä¸¥æ ¼è¦æ±‚çš„åŒ»ç–—ç¯å¢ƒä¸­ï¼Œå®‰å…¨åœ°æœ¬åœ°éƒ¨ç½²é«˜æ€§èƒ½å¤§æ¨¡å‹æä¾›äº†å…·æœ‰å®æˆ˜ä»·å€¼çš„ç­–ç•¥æŒ‡å¯¼ã€‚è¿™äº›å‘ç°å¯¹äºç¼©è¡¥AIæŠ€æœ¯å‰æ²¿ä¸å®é™…ä¸´åºŠåº”ç”¨ä¹‹é—´çš„å·®è·å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.04534v1",
      "published_date": "2025-09-04 04:18:45 UTC",
      "updated_date": "2025-09-04 04:18:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:37.071749+00:00"
    },
    {
      "arxiv_id": "2509.03871v1",
      "title": "A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ¨ç†å¯ä¿¡æ€§å…¨é¢ç»¼è¿°",
      "authors": [
        "Yanbo Wang",
        "Yongcan Yu",
        "Jian Liang",
        "Ran He"
      ],
      "abstract": "The development of Long-CoT reasoning has advanced LLM performance across various tasks, including language understanding, complex problem solving, and code generation. This paradigm enables models to generate intermediate reasoning steps, thereby improving both accuracy and interpretability. However, despite these advancements, a comprehensive understanding of how CoT-based reasoning affects the trustworthiness of language models remains underdeveloped. In this paper, we survey recent work on reasoning models and CoT techniques, focusing on five core dimensions of trustworthy reasoning: truthfulness, safety, robustness, fairness, and privacy. For each aspect, we provide a clear and structured overview of recent studies in chronological order, along with detailed analyses of their methodologies, findings, and limitations. Future research directions are also appended at the end for reference and discussion. Overall, while reasoning techniques hold promise for enhancing model trustworthiness through hallucination mitigation, harmful content detection, and robustness improvement, cutting-edge reasoning models themselves often suffer from comparable or even greater vulnerabilities in safety, robustness, and privacy. By synthesizing these insights, we hope this work serves as a valuable and timely resource for the AI safety community to stay informed on the latest progress in reasoning trustworthiness. A full list of related papers can be found at \\href{https://github.com/ybwang119/Awesome-reasoning-safety}{https://github.com/ybwang119/Awesome-reasoning-safety}.",
      "tldr_zh": "è¯¥ç»¼è¿°é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨Long-CoTæ¨ç†èŒƒå¼ä¸‹çš„å¯ä¿¡æ€§é—®é¢˜è¿›è¡Œäº†ç³»ç»Ÿæ€§æ¢è®¨ã€‚ç ”ç©¶é‡ç‚¹å›´ç»•truthfulnessã€safetyã€robustnessã€fairnesså’Œprivacyäº”ä¸ªæ ¸å¿ƒç»´åº¦ï¼ŒæŒ‰æ—¶é—´é¡ºåºæ¢³ç†äº†ç›¸å…³æŠ€æœ¯çš„å‘å±•è„‰ç»œã€‚æ–‡ç« æ·±å…¥åˆ†æäº†ç°æœ‰ç ”ç©¶çš„æ–¹æ³•è®ºã€ä¸»è¦å‘ç°åŠå…¶å±€é™æ€§ï¼Œå¹¶æä¾›äº†å¯¹æœªæ¥ç ”ç©¶æ–¹å‘çš„å‚è€ƒä¸è®¨è®ºã€‚å°½ç®¡æ¨ç†æŠ€æœ¯åœ¨ç¼“è§£å¹»è§‰å’Œæå‡robustnessæ–¹é¢å…·æœ‰æ½œåŠ›ï¼Œä½†å‰æ²¿æ¨ç†æ¨¡å‹æœ¬èº«åœ¨safetyå’Œprivacyç­‰ç»´åº¦ä»é¢ä¸´ä¸¥å³»ç”šè‡³æ›´å¤§çš„è„†å¼±æ€§æŒ‘æˆ˜ã€‚è¯¥å·¥ä½œé€šè¿‡æ•´åˆç›¸å…³æ´å¯Ÿï¼Œä¸ºAI safetyç¤¾åŒºäº†è§£æ¨ç†å¯ä¿¡æ€§çš„æœ€æ–°è¿›å±•æä¾›äº†åŠæ—¶çš„èµ„æºæ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "38 pages. This survey considers papers published up to June 30, 2025. Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2509.03871v1",
      "published_date": "2025-09-04 04:12:31 UTC",
      "updated_date": "2025-09-04 04:12:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:53.197723+00:00"
    },
    {
      "arxiv_id": "2509.10523v1",
      "title": "From Predictions to Explanations: Explainable AI for Autism Diagnosis and Identification of Critical Brain Regions",
      "title_zh": "ä»é¢„æµ‹åˆ°è§£é‡Šï¼šé¢å‘è‡ªé—­ç—‡è¯Šæ–­ä¸å…³é”®è„‘åŒºè¯†åˆ«çš„å¯è§£é‡Šäººå·¥æ™ºèƒ½",
      "authors": [
        "Kush Gupta",
        "Amir Aly",
        "Emmanuel Ifeachor",
        "Rohit Shankar"
      ],
      "abstract": "Autism spectrum disorder (ASD) is a neurodevelopmental condition characterized by atypical brain maturation. However, the adaptation of transfer learning paradigms in machine learning for ASD research remains notably limited. In this study, we propose a computer-aided diagnostic framework with two modules. This chapter presents a two-module framework combining deep learning and explainable AI for ASD diagnosis. The first module leverages a deep learning model fine-tuned through cross-domain transfer learning for ASD classification. The second module focuses on interpreting the model decisions and identifying critical brain regions. To achieve this, we employed three explainable AI (XAI) techniques: saliency mapping, Gradient-weighted Class Activation Mapping, and SHapley Additive exPlanations (SHAP) analysis. This framework demonstrates that cross-domain transfer learning can effectively address data scarcity in ASD research. In addition, by applying three established explainability techniques, the approach reveals how the model makes diagnostic decisions and identifies brain regions most associated with ASD. These findings were compared against established neurobiological evidence, highlighting strong alignment and reinforcing the clinical relevance of the proposed approach.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»“åˆæ·±åº¦å­¦ä¹ (Deep Learning)ä¸å¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI, XAI)çš„åŒæ¨¡å—æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜è‡ªé—­ç—‡è°±ç³»éšœç¢(Autism spectrum disorder, ASD)çš„è¯Šæ–­å‡†ç¡®æ€§å¹¶è¯†åˆ«å…³é”®è„‘åŒºã€‚ç¬¬ä¸€ä¸ªæ¨¡å—åˆ©ç”¨é€šè¿‡è·¨åŸŸè¿ç§»å­¦ä¹ (Cross-domain transfer learning)è¿›è¡Œå¾®è°ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡ŒASDåˆ†ç±»ï¼Œæœ‰æ•ˆè§£å†³äº†è¯¥é¢†åŸŸç ”ç©¶ä¸­é¢ä¸´çš„æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚ç¬¬äºŒä¸ªæ¨¡å—é‡‡ç”¨äº†æ˜¾è‘—æ€§æ˜ å°„(Saliency mapping)ã€æ¢¯åº¦åŠ æƒç±»æ¿€æ´»æ˜ å°„(Grad-CAM)å’ŒSHAPåˆ†æ(SHapley Additive exPlanations)ä¸‰ç§æŠ€æœ¯ï¼Œå¯¹æ¨¡å‹çš„è¯Šæ–­å†³ç­–è¿›è¡Œæ·±åº¦è§£æã€‚è¯¥æ¡†æ¶ä¸ä»…æ­ç¤ºäº†æ¨¡å‹åšå‡ºé¢„æµ‹çš„å†…åœ¨æœºåˆ¶ï¼Œè¿˜æˆåŠŸè¯†åˆ«äº†ä¸ASDå…³è”æœ€å¼ºçš„ç‰¹å®šè„‘åŒºã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿™äº›å‘ç°ä¸æ—¢æœ‰çš„ç¥ç»ç”Ÿç‰©å­¦è¯æ®é«˜åº¦ä¸€è‡´ï¼Œå……åˆ†éªŒè¯äº†è¯¥æ–¹æ³•åœ¨ä¸´åºŠè¯Šæ–­è¾…åŠ©ä¸­çš„å¯é æ€§ä¸åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10523v1",
      "published_date": "2025-09-04 03:48:10 UTC",
      "updated_date": "2025-09-04 03:48:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:54.558805+00:00"
    },
    {
      "arxiv_id": "2509.03863v1",
      "title": "Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata",
      "title_zh": "è¿œå¾ä¸æ‰©å¼ ï¼šåˆ©ç”¨è¯­ä¹‰è¡¨ç¤ºåœ¨è¿ç»­å…ƒèƒè‡ªåŠ¨æœºä¸­å®ç°ç›®æ ‡å¯¼å‘çš„æ¢ç´¢",
      "authors": [
        "Sina Khajehabdollahi",
        "Gautier Hamon",
        "Marko Cvjetko",
        "Pierre-Yves Oudeyer",
        "ClÃ©ment Moulin-Frier",
        "CÃ©dric Colas"
      ],
      "abstract": "Discovering diverse visual patterns in continuous cellular automata (CA) is challenging due to the vastness and redundancy of high-dimensional behavioral spaces. Traditional exploration methods like Novelty Search (NS) expand locally by mutating known novel solutions but often plateau when local novelty is exhausted, failing to reach distant, unexplored regions. We introduce Expedition and Expansion (E&E), a hybrid strategy where exploration alternates between local novelty-driven expansions and goal-directed expeditions. During expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic goals--descriptions of interesting but hypothetical patterns that drive exploration toward uncharted regions. By operating in semantic spaces that align with human perception, E&E both evaluates novelty and generates goals in conceptually meaningful ways, enhancing the interpretability and relevance of discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich, emergent behaviors, E&E consistently uncovers more diverse solutions than existing exploration methods. A genealogical analysis further reveals that solutions originating from expeditions disproportionately influence long-term exploration, unlocking new behavioral niches that serve as stepping stones for subsequent search. These findings highlight E&E's capacity to break through local novelty boundaries and explore behavioral landscapes in human-aligned, interpretable ways, offering a promising template for open-ended exploration in artificial life and beyond.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Expedition and Expansion (E&E)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¿ç»­ç»†èƒè‡ªåŠ¨æœº(Continuous Cellular Automata)åœ¨å‘ç°å¤šæ ·åŒ–è§†è§‰æ¨¡å¼æ—¶é¢ä¸´çš„è¡Œä¸ºç©ºé—´å†—ä½™å’Œæ¢ç´¢ç“¶é¢ˆé—®é¢˜ã€‚ä¼ ç»Ÿçš„Novelty Search (NS)æ–¹æ³•å®¹æ˜“åœ¨å±€éƒ¨æ–°é¢–æ€§è€—å°½æ—¶é™·å…¥åœæ»ï¼Œè€ŒE&Eé€šè¿‡åœ¨å±€éƒ¨æ‰©å±•ä¸ç›®æ ‡å¯¼å‘çš„è¿œå¾(Expeditions)ä¹‹é—´äº¤æ›¿è¿›è¡Œï¼Œæœ‰æ•ˆçªç ´äº†æœç´¢å±€é™ã€‚è¯¥ç­–ç•¥åˆ›æ–°æ€§åœ°åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Model, VLM)ç”Ÿæˆè¯­ä¹‰å±‚é¢çš„è¯­è¨€ç›®æ ‡ï¼Œæè¿°æ½œåœ¨çš„æœ‰è¶£æ¨¡å¼ï¼Œä»è€Œå¼•å¯¼æœç´¢å‘æœªå¼€å‘çš„è¡Œä¸ºåŒºåŸŸè¿›å‘ã€‚åœ¨Flow Leniaç³»ç»Ÿä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒE&Eæ¯”ç°æœ‰æ–¹æ³•èƒ½å‘ç°æ›´ä¸°å¯Œçš„è§£é›†ï¼Œä¸”è¯­ä¹‰ç©ºé—´çš„æ“ä½œæ˜¾è‘—å¢å¼ºäº†æ¢ç´¢è¿‡ç¨‹çš„å¯è§£é‡Šæ€§ã€‚ç³»è°±åˆ†æè¿›ä¸€æ­¥è¯æ˜ï¼Œæºè‡ªè¿œå¾çš„æ–¹æ¡ˆå¯¹é•¿æœŸæ¢ç´¢å…·æœ‰æ˜¾è‘—å½±å“åŠ›ï¼Œèƒ½å¤Ÿå¼€å¯å…¨æ–°çš„è¡Œä¸ºç”Ÿæ€ä½(Behavioral niches)ã€‚è¯¥å·¥ä½œå±•ç¤ºäº†ç»“åˆè¯­ä¹‰è¡¨å¾å¼•å¯¼äººå·¥æ™ºèƒ½ç”Ÿå‘½ç³»ç»Ÿè¿›è¡Œå¼€æ”¾å¼æ¢ç´¢(Open-ended exploration)çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03863v1",
      "published_date": "2025-09-04 03:44:44 UTC",
      "updated_date": "2025-09-04 03:44:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:38:57.654086+00:00"
    },
    {
      "arxiv_id": "2509.03857v1",
      "title": "Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures",
      "title_zh": "åŸºäºç¡®å®šæ€§çŸ¥è¯†å›¾è°±ç»“æ„çš„å¤§è§„æ¨¡ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æŒç»­ç›‘æµ‹",
      "authors": [
        "Kishor Datta Gupta",
        "Mohd Ariful Haque",
        "Hasmot Ali",
        "Marufa Kamal",
        "Syed Bahauddin Alam",
        "Mohammad Ashiqur Rahman"
      ],
      "abstract": "Generative AI (GEN AI) models have revolutionized diverse application domains but present substantial challenges due to reliability concerns, including hallucinations, semantic drift, and inherent biases. These models typically operate as black-boxes, complicating transparent and objective evaluation. Current evaluation methods primarily depend on subjective human assessment, limiting scalability, transparency, and effectiveness. This research proposes a systematic methodology using deterministic and Large Language Model (LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN AI reliability. We construct two parallel KGs: (i) a deterministic KG built using explicit rule-based methods, predefined ontologies, domain-specific dictionaries, and structured entity-relation extraction rules, and (ii) an LLM-generated KG dynamically derived from real-time textual data streams such as live news articles. Utilizing real-time news streams ensures authenticity, mitigates biases from repetitive training, and prevents adaptive LLMs from bypassing predefined benchmarks through feedback memorization. To quantify structural deviations and semantic discrepancies, we employ several established KG metrics, including Instantiated Class Ratio (ICR), Instantiated Property Ratio (IPR), and Class Instantiation (CI). An automated real-time monitoring framework continuously computes deviations between deterministic and LLM-generated KGs. By establishing dynamic anomaly thresholds based on historical structural metric distributions, our method proactively identifies and flags significant deviations, thus promptly detecting semantic anomalies or hallucinations. This structured, metric-driven comparison between deterministic and dynamically generated KGs delivers a robust and scalable evaluation framework.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ç¡®å®šæ€§çŸ¥è¯†å›¾è°± (Knowledge Graph) ç»“æ„å¯¹å¤§è§„æ¨¡ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) è¿›è¡ŒæŒç»­ç›‘æµ‹çš„ç³»ç»ŸåŒ–æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æ¨¡å‹é¢ä¸´çš„å¹»è§‰ (hallucinations)ã€è¯­ä¹‰åç§» (semantic drift) å’Œå›ºæœ‰åè§ç­‰å¯é æ€§æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡æ„å»ºä¸¤ä¸ªå¹³è¡Œçš„çŸ¥è¯†å›¾è°±ï¼šä¸€ä¸ªæ˜¯åŸºäºæ˜¾å¼è§„åˆ™å’Œé¢„å®šä¹‰æœ¬ä½“ç”Ÿæˆçš„ç¡®å®šæ€§ KGï¼Œå¦ä¸€ä¸ªæ˜¯æ ¹æ®å®æ—¶æ–°é—»æµåŠ¨æ€ç”Ÿæˆçš„ LLM-generated KGã€‚åˆ©ç”¨å®æ—¶æ•°æ®æµç¡®ä¿äº†è¯„ä¼°çš„çœŸå®æ€§ï¼Œå¹¶æœ‰æ•ˆé˜²æ­¢äº†æ¨¡å‹é€šè¿‡è®°å¿†åé¦ˆæ¥ç»•è¿‡é¢„å®šä¹‰åŸºå‡†ã€‚ç ”ç©¶é‡‡ç”¨äº†å®ä¾‹åŒ–ç±»æ¯”ç‡ (Instantiated Class Ratio, ICR)ã€å®ä¾‹åŒ–å±æ€§æ¯”ç‡ (Instantiated Property Ratio, IPR) å’Œç±»å®ä¾‹åŒ– (Class Instantiation, CI) ç­‰æŒ‡æ ‡æ¥é‡åŒ–ç»“æ„åå·®ã€‚é€šè¿‡è‡ªåŠ¨åŒ–æ¡†æ¶è®¡ç®—ä¸¤ç±»å›¾è°±é—´çš„å·®å¼‚å¹¶è®¾å®šåŠ¨æ€å¼‚å¸¸é˜ˆå€¼ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿä¸»åŠ¨è¯†åˆ«å¹¶æ ‡è®°æ˜¾è‘—çš„è¯­ä¹‰å¼‚å¸¸ã€‚è¿™ç§ç»“æ„åŒ–ã€æŒ‡æ ‡é©±åŠ¨çš„è¯„ä¼°æœºåˆ¶ä¸ºå¤§è§„æ¨¡ç”Ÿæˆå¼æ¨¡å‹çš„å¯é æ€§æä¾›äº†ä¸€ä¸ªç¨³å¥ä¸”å¯æ‰©å±•çš„ç›‘æ§æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03857v1",
      "published_date": "2025-09-04 03:34:49 UTC",
      "updated_date": "2025-09-04 03:34:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:00.474588+00:00"
    },
    {
      "arxiv_id": "2509.03852v1",
      "title": "MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting",
      "title_zh": "MillGNNï¼šé¢å‘å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹çš„å¤šå°ºåº¦è¶…å‰æ»åä¾èµ–å­¦ä¹ ",
      "authors": [
        "Binqing Wu",
        "Zongjiang Shang",
        "Jianlong Huang",
        "Ling Chen"
      ],
      "abstract": "Multi-variate time series (MTS) forecasting is crucial for various applications. Existing methods have shown promising results owing to their strong ability to capture intra- and inter-variate dependencies. However, these methods often overlook lead-lag dependencies at multiple grouping scales, failing to capture hierarchical lead-lag effects in complex systems. To this end, we propose MillGNN, a novel \\underline{g}raph \\underline{n}eural \\underline{n}etwork-based method that learns \\underline{m}ult\\underline{i}ple grouping scale \\underline{l}ead-\\underline{l}ag dependencies for MTS forecasting, which can comprehensively capture lead-lag effects considering variate-wise and group-wise dynamics and decays. Specifically, MillGNN introduces two key innovations: (1) a scale-specific lead-lag graph learning module that integrates cross-correlation coefficients and dynamic decaying features derived from real-time inputs and time lags to learn lead-lag dependencies for each scale, which can model evolving lead-lag dependencies with statistical interpretability and data-driven flexibility; (2) a hierarchical lead-lag message passing module that passes lead-lag messages at multiple grouping scales in a structured way to simultaneously propagate intra- and inter-scale lead-lag effects, which can capture multi-scale lead-lag effects with a balance of comprehensiveness and efficiency. Experimental results on 11 datasets demonstrate the superiority of MillGNN for long-term and short-term MTS forecasting, compared with 16 state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MillGNNï¼Œä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œ(Graph Neural Network)çš„åˆ›æ–°æ–¹æ³•ï¼Œæ—¨åœ¨æ•æ‰å¤šå˜é‡æ—¶é—´åºåˆ—(MTS)é¢„æµ‹ä¸­å¸¸è¢«å¿½è§†çš„å¤šå°ºåº¦åˆ†ç»„é¢†å…ˆæ»å(lead-lag)ä¾èµ–å…³ç³»ã€‚ä¸ºäº†æœ‰æ•ˆå¤„ç†å¤æ‚ç³»ç»Ÿä¸­çš„å±‚çº§åŒ–é¢†å…ˆæ»åæ•ˆåº”ï¼ŒMillGNNå¼•å…¥äº†å°ºåº¦ç‰¹å®šçš„é¢†å…ˆæ»åå›¾å­¦ä¹ æ¨¡å—ï¼Œç»“åˆäº’ç›¸å…³ç³»æ•°(cross-correlation coefficients)ä¸åŠ¨æ€è¡°å‡ç‰¹å¾æ¥å»ºæ¨¡æ¼”åŒ–çš„ä¾èµ–å…³ç³»ã€‚åŒæ—¶ï¼Œè¯¥æ¨¡å‹é€šè¿‡å±‚æ¬¡åŒ–é¢†å…ˆæ»åæ¶ˆæ¯ä¼ é€’æ¨¡å—ï¼Œä»¥ç»“æ„åŒ–æ–¹å¼åœ¨å¤šä¸ªåˆ†ç»„å°ºåº¦é—´ä¼ æ’­ä¿¡æ¯ï¼Œä»è€ŒåŒæ—¶æ•æ‰å°ºåº¦å†…ä¸å°ºåº¦é—´çš„åŠ¨æ€å…³è”ã€‚è¿™ç§è®¾è®¡åœ¨ä¿è¯æ•æ‰å˜é‡çº§å’Œç»„çº§åŠ¨æ€å…¨é¢æ€§çš„åŒæ—¶ï¼Œå…¼é¡¾äº†è®¡ç®—æ•ˆç‡ä¸ç»Ÿè®¡è§£é‡Šæ€§ã€‚åœ¨11ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMillGNNåœ¨é•¿çŸ­æœŸé¢„æµ‹ä»»åŠ¡ä¸­å‡æ˜¾è‘—ä¼˜äº16ç§æœ€å…ˆè¿›(state-of-the-art)çš„åŸºå‡†æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºè§£å†³å¤æ‚æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„å¤šå°ºåº¦æ¼”åŒ–é—®é¢˜æä¾›äº†ä¸€ä¸ªçµæ´»ä¸”é«˜æ•ˆçš„æ•°æ®é©±åŠ¨æ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CIKM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.03852v1",
      "published_date": "2025-09-04 03:28:42 UTC",
      "updated_date": "2025-09-04 03:28:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:12.499216+00:00"
    },
    {
      "arxiv_id": "2509.03845v1",
      "title": "Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables",
      "title_zh": "åŸºäºæ¦‚ç‡ä¸Šä¸‹æ–‡å˜é‡çš„å¹³å‡åœºåšå¼ˆå…ƒé€†å‘å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yang Chen",
        "Xiao Lin",
        "Bo Yan",
        "Libo Zhang",
        "Jiamou Liu",
        "Neset Ã–zkan Tan",
        "Michael Witbrock"
      ],
      "abstract": "Designing suitable reward functions for numerous interacting intelligent agents is challenging in real-world applications. Inverse reinforcement learning (IRL) in mean field games (MFGs) offers a practical framework to infer reward functions from expert demonstrations. While promising, the assumption of agent homogeneity limits the capability of existing methods to handle demonstrations with heterogeneous and unknown objectives, which are common in practice. To this end, we propose a deep latent variable MFG model and an associated IRL method. Critically, our method can infer rewards from different yet structurally similar tasks without prior knowledge about underlying contexts or modifying the MFG model itself. Our experiments, conducted on simulated scenarios and a real-world spatial taxi-ride pricing problem, demonstrate the superiority of our approach over state-of-the-art IRL methods in MFGs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°å®åº”ç”¨ä¸­ä¸ºå¤§é‡äº’åŠ¨æ™ºèƒ½ä½“è®¾è®¡å¥–åŠ±å‡½æ•°çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæ¦‚ç‡ä¸Šä¸‹æ–‡å˜é‡(Probabilistic Context Variables)çš„å‡å€¼åœºåšå¼ˆ(Mean Field Games, MFGs)å…ƒé€†å¼ºåŒ–å­¦ä¹ (Meta-Inverse Reinforcement Learning)æ–¹æ³•ã€‚ä¸ºäº†å…‹æœç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¼‚æ„ä¸”æœªçŸ¥ç›®æ ‡æ—¶å­˜åœ¨çš„æ™ºèƒ½ä½“åŒè´¨æ€§å‡è®¾å±€é™ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªæ·±åº¦æ½œå˜é‡MFGæ¨¡å‹åŠç›¸å…³çš„é€†å¼ºåŒ–å­¦ä¹ (IRL)æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºæ— éœ€åº•å±‚ä¸Šä¸‹æ–‡çš„å…ˆéªŒçŸ¥è¯†ï¼Œä¹Ÿæ— éœ€ä¿®æ”¹MFGæ¨¡å‹æœ¬èº«ï¼Œå³å¯ä»ä¸åŒä½†ç»“æ„ç›¸ä¼¼çš„ä»»åŠ¡ä¸­æ¨æ–­å¥–åŠ±å‡½æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿåœºæ™¯ä»¥åŠç°å®ä¸–ç•Œçš„ç©ºé—´å‡ºç§Ÿè½¦å®šä»·é—®é¢˜ä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„MFGé¢†åŸŸIRLç®—æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2024",
      "pdf_url": "https://arxiv.org/pdf/2509.03845v1",
      "published_date": "2025-09-04 03:13:11 UTC",
      "updated_date": "2025-09-04 03:13:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:07.986184+00:00"
    },
    {
      "arxiv_id": "2509.03842v3",
      "title": "INGRID: Intelligent Generative Robotic Design Using Large Language Models",
      "title_zh": "INGRIDï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ç”Ÿæˆå¼æœºå™¨äººè®¾è®¡",
      "authors": [
        "Guanglu Jia",
        "Ceng Zhang",
        "Gregory S. Chirikjian"
      ],
      "abstract": "The integration of large language models (LLMs) into robotic systems has accelerated progress in embodied artificial intelligence, yet current approaches remain constrained by existing robotic architectures, particularly serial mechanisms. This hardware dependency fundamentally limits the scope of robotic intelligence. Here, we present INGRID (Intelligent Generative Robotic Design), a framework that enables the automated design of parallel robotic mechanisms through deep integration with reciprocal screw theory and kinematic synthesis methods. We decompose the design challenge into four progressive tasks: constraint analysis, kinematic joint generation, chain construction, and complete mechanism design. INGRID demonstrates the ability to generate novel parallel mechanisms with both fixed and variable mobility, discovering kinematic configurations not previously documented in the literature. We validate our approach through three case studies demonstrating how INGRID assists users in designing task-specific parallel robots based on desired mobility requirements. By bridging the gap between mechanism theory and machine learning, INGRID enables researchers without specialized robotics training to create custom parallel mechanisms, thereby decoupling advances in robotic intelligence from hardware constraints. This work establishes a foundation for mechanism intelligence, where AI systems actively design robotic hardware, potentially transforming the development of embodied AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† INGRID (Intelligent Generative Robotic Design) æ¡†æ¶ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) å®ç°å¹¶è”æœºå™¨äººæœºæ„çš„è‡ªåŠ¨åŒ–è®¾è®¡ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨äººç¡¬ä»¶æ¶æ„å¯¹å…·èº«æ™ºèƒ½å‘å±•çš„çº¦æŸã€‚é€šè¿‡å°†äº’åèºæ—‹ç†è®º (reciprocal screw theory) ä¸æœºæ„ç»¼åˆæ–¹æ³• (kinematic synthesis methods) æ·±åº¦ç»“åˆï¼Œè¯¥æ¡†æ¶å°†å¤æ‚çš„è®¾è®¡æµç¨‹åˆ†è§£ä¸ºçº¦æŸåˆ†æã€è¿åŠ¨å‰¯ç”Ÿæˆã€æ”¯é“¾æ„å»ºå’Œå®Œæ•´æœºæ„è®¾è®¡å››ä¸ªé˜¶æ®µã€‚å®éªŒè¯æ˜ï¼ŒINGRID èƒ½å¤Ÿç”Ÿæˆå…·æœ‰å›ºå®šæˆ–å˜è‡ªç”±åº¦çš„æ–°å‹å¹¶è”æœºæ„ï¼Œå¹¶å‘ç°äº†ç°æœ‰æ–‡çŒ®ä¸­æœªæ›¾è®°è½½çš„è¿åŠ¨æ„å‹ã€‚é€šè¿‡ä¸‰ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥æ¡†æ¶å±•ç¤ºäº†å…¶æ ¹æ®ç‰¹å®šéœ€æ±‚è¾…åŠ©è®¾è®¡ä»»åŠ¡å¯¼å‘å‹æœºå™¨äººçš„èƒ½åŠ›ã€‚è¿™ä¸€æˆæœæœ‰æ•ˆå¼¥åˆäº†æœºæ„å­¦ç†è®ºä¸æœºå™¨å­¦ä¹ ä¹‹é—´çš„ä»£æ²Ÿï¼Œä½¿å¾—éä¸“ä¸šèƒŒæ™¯çš„ç ”ç©¶äººå‘˜ä¹Ÿèƒ½åˆ›å»ºè‡ªå®šä¹‰å¹¶è”æœºæ„ã€‚è¯¥å·¥ä½œç¡®ç«‹äº†æœºæ„æ™ºèƒ½ (mechanism intelligence) çš„åŸºç¡€ï¼Œå®ç°äº†ç”±äººå·¥æ™ºèƒ½ä¸»åŠ¨è®¾è®¡æœºå™¨äººç¡¬ä»¶ï¼Œå¯¹å…·èº« AI ç³»ç»Ÿçš„æœªæ¥å‘å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "We are revising it",
      "pdf_url": "https://arxiv.org/pdf/2509.03842v3",
      "published_date": "2025-09-04 03:08:01 UTC",
      "updated_date": "2025-10-05 14:20:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:12.791734+00:00"
    },
    {
      "arxiv_id": "2509.03834v1",
      "title": "From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game",
      "title_zh": "ä» Leiden åˆ° Pleasure Islandï¼šä½œä¸ºäº«ä¹åšå¼ˆçš„ç¤¾åŒºå‘ç°å¸¸æ•°æ³¢èŒ¨æ¨¡å‹",
      "authors": [
        "Lucas Lopes Felipe",
        "Konstantin Avrachenkov",
        "Daniel Sadoc Menasche"
      ],
      "abstract": "Community detection is one of the fundamental problems in data science which consists of partitioning nodes into disjoint communities. We present a game-theoretic perspective on the Constant Potts Model (CPM) for partitioning networks into disjoint communities, emphasizing its efficiency, robustness, and accuracy. Efficiency: We reinterpret CPM as a potential hedonic game by decomposing its global Hamiltonian into local utility functions, where the local utility gain of each agent matches the corresponding increase in global utility. Leveraging this equivalence, we prove that local optimization of the CPM objective via better-response dynamics converges in pseudo-polynomial time to an equilibrium partition. Robustness: We introduce and relate two stability criteria: a strict criterion based on a novel notion of robustness, requiring nodes to simultaneously maximize neighbors and minimize non-neighbors within communities, and a relaxed utility function based on a weighted sum of these objectives, controlled by a resolution parameter. Accuracy: In community tracking scenarios, where initial partitions are used to bootstrap the Leiden algorithm with partial ground-truth information, our experiments reveal that robust partitions yield higher accuracy in recovering ground-truth communities.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»åšå¼ˆè®ºè§’åº¦é‡æ–°å®¡è§†äº†ç”¨äºç¤¾åŒºå‘ç°(Community Detection)çš„æ’å®šæ³¢èŒ¨æ¨¡å‹(Constant Potts Model, CPM)ï¼Œå°†å…¶å®šä¹‰ä¸ºä¸€ç§åŠ¿èƒ½äº«ä¹åšå¼ˆ(potential hedonic game)ã€‚é€šè¿‡å°†å…¨å±€ Hamiltonian åˆ†è§£ä¸ºå±€éƒ¨æ•ˆç”¨å‡½æ•°(local utility functions)ï¼Œç ”ç©¶ç¡®ä¿äº†å„æ™ºèƒ½ä½“çš„å±€éƒ¨æ•ˆç”¨å¢ç›Šä¸å…¨å±€æ•ˆç”¨çš„å¢åŠ ç›¸åŒ¹é…ã€‚åŸºäºè¿™ç§ç­‰ä»·æ€§ï¼Œè®ºæ–‡è¯æ˜äº†é€šè¿‡æœ€ä½³å“åº”åŠ¨æ€(better-response dynamics)è¿›è¡Œçš„å±€éƒ¨ä¼˜åŒ–èƒ½åœ¨ä¼ªå¤šé¡¹å¼æ—¶é—´å†…æ”¶æ•›è‡³å¹³è¡¡åˆ’åˆ†(equilibrium partition)ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäº Robustness æ¦‚å¿µçš„ä¸¥æ ¼ç¨³å®šæ€§å‡†åˆ™ï¼Œä»¥åŠå—åˆ†è¾¨ç‡å‚æ•°(resolution parameter)æ§åˆ¶çš„åŠ æƒæ•ˆç”¨å‡½æ•°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨åˆ©ç”¨ Leiden ç®—æ³•è¿›è¡Œç¤¾åŒºè¿½è¸ªçš„åœºæ™¯ä¸­ï¼Œè¿™ç§ç¨³å¥çš„åˆ’åˆ†åœ¨æ¢å¤åœ°é¢çœŸå€¼(ground-truth)æ–¹é¢å…·æœ‰æ›´é«˜çš„å‡†ç¡®ç‡ï¼Œä»è€Œè¯æ˜äº† CPM åœ¨ç½‘ç»œåˆ†åŒºä»»åŠ¡ä¸­çš„æ•ˆç‡ã€ç¨³å¥æ€§å’Œå‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "Manuscript submitted to Physica A: Statistical Mechanics and its Applications",
      "pdf_url": "https://arxiv.org/pdf/2509.03834v1",
      "published_date": "2025-09-04 02:50:54 UTC",
      "updated_date": "2025-09-04 02:50:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:17.287423+00:00"
    },
    {
      "arxiv_id": "2509.05364v1",
      "title": "Prototyping an AI-powered Tool for Energy Efficiency in New Zealand Homes",
      "title_zh": "é’ˆå¯¹ New Zealand ä½å®…èƒ½æºæ•ˆç‡çš„ AI é©±åŠ¨å·¥å…·åŸå‹å¼€å‘",
      "authors": [
        "Abdollah Baghaei Daemei"
      ],
      "abstract": "Residential buildings contribute significantly to energy use, health outcomes, and carbon emissions. In New Zealand, housing quality has historically been poor, with inadequate insulation and inefficient heating contributing to widespread energy hardship. Recent reforms, including the Warmer Kiwi Homes program, Healthy Homes Standards, and H1 Building Code upgrades, have delivered health and comfort improvements, yet challenges persist. Many retrofits remain partial, data on household performance are limited, and decision-making support for homeowners is fragmented. This study presents the design and evaluation of an AI-powered decision-support tool for residential energy efficiency in New Zealand. The prototype, developed using Python and Streamlit, integrates data ingestion, anomaly detection, baseline modeling, and scenario simulation (e.g., LED retrofits, insulation upgrades) into a modular dashboard. Fifteen domain experts, including building scientists, consultants, and policy practitioners, tested the tool through semi-structured interviews. Results show strong usability (M = 4.3), high value of scenario outputs (M = 4.5), and positive perceptions of its potential to complement subsidy programs and regulatory frameworks. The tool demonstrates how AI can translate national policies into personalized, household-level guidance, bridging the gap between funding, standards, and practical decision-making. Its significance lies in offering a replicable framework for reducing energy hardship, improving health outcomes, and supporting climate goals. Future development should focus on carbon metrics, tariff modeling, integration with national datasets, and longitudinal trials to assess real-world adoption.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–°è¥¿å…°ä½å®…å»ºç­‘èƒ½æºæ•ˆç‡ä½ã€ç¢³æ’æ”¾é«˜åŠæˆ¿ä¸»å†³ç­–æ”¯æŒç¢ç‰‡åŒ–ç­‰æŒ‘æˆ˜ï¼Œå¼€å‘å¹¶è¯„ä¼°äº†ä¸€ä¸ªåŸºäº AI-powered çš„å†³ç­–æ”¯æŒå·¥å…·åŸå‹ã€‚è¯¥åŸå‹åˆ©ç”¨ Python å’Œ Streamlit æ„å»ºï¼Œé›†æˆäº†æ•°æ®æ‘„å…¥(data ingestion)ã€å¼‚å¸¸æ£€æµ‹(anomaly detection)ã€åŸºå‡†å»ºæ¨¡(baseline modeling)å’Œåœºæ™¯æ¨¡æ‹Ÿ(scenario simulation)ç­‰æ¨¡å—åŒ–åŠŸèƒ½ï¼Œæ—¨åœ¨æä¾›ä¸ªæ€§åŒ–çš„èƒ½æ•ˆæå‡å»ºè®®ã€‚é€šè¿‡å¯¹åäº”ä½é¢†åŸŸä¸“å®¶çš„åŠç»“æ„åŒ–è®¿è°ˆæµ‹è¯•ï¼Œç»“æœè¡¨æ˜è¯¥å·¥å…·åœ¨å¯ç”¨æ€§ï¼ˆM=4.3ï¼‰å’Œåœºæ™¯è¾“å‡ºä»·å€¼ï¼ˆM=4.5ï¼‰æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¾…åŠ© LED æ”¹é€ æˆ–ç»ç¼˜å‡çº§ç­‰å†³ç­–ã€‚è¯¥å·¥å…·æˆåŠŸåœ°å°†å›½å®¶æ”¿ç­–è½¬åŒ–ä¸ºå®¶åº­å±‚é¢çš„å…·ä½“æŒ‡å¯¼ï¼Œæœ‰æ•ˆå¼¥åˆäº†èµ„åŠ©è®¡åˆ’ã€è¡Œä¸šæ ‡å‡†ä¸å®é™…å†³ç­–ä¹‹é—´çš„å·®è·ã€‚æ­¤é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºæä¾›äº†ä¸€ä¸ªå¯å¤åˆ¶çš„æ¡†æ¶ï¼Œç”¨äºç¼“è§£èƒ½æºå›°é¡¿(energy hardship)ã€æå‡å±…æ°‘å¥åº·æ°´å¹³å¹¶æ”¯æŒæ°”å€™ç›®æ ‡çš„å®ç°ã€‚æœªæ¥ç ”ç©¶å°†è¿›ä¸€æ­¥æ•´åˆç¢³æ’æ”¾æŒ‡æ ‡ã€ç”µä»·å»ºæ¨¡åŠå›½å®¶çº§æ•°æ®é›†ï¼Œå¹¶é€šè¿‡çºµå‘è¯•éªŒè¯„ä¼°å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨æ•ˆæœã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05364v1",
      "published_date": "2025-09-04 02:41:38 UTC",
      "updated_date": "2025-09-04 02:41:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:19.158553+00:00"
    },
    {
      "arxiv_id": "2509.03832v2",
      "title": "Gravity Well Echo Chamber Modeling With An LLM-Based Confirmation Bias Model",
      "title_zh": "åŸºäº LLM ç¡®è®¤åå·®æ¨¡å‹çš„é‡åŠ›äº•å›éŸ³å®¤å»ºæ¨¡",
      "authors": [
        "Joseph Jackson",
        "Georgiy Lapin",
        "Jeremy E. Thompson"
      ],
      "abstract": "Social media echo chambers play a central role in the spread of misinformation, yet existing models often overlook the influence of individual confirmation bias. An existing model of echo chambers is the \"gravity well\" model, which creates an analog between echo chambers and spatial gravity wells. We extend this established model by introducing a dynamic confirmation bias variable that adjusts the strength of pull based on a user's susceptibility to belief-reinforcing content. This variable is calculated for each user through comparisons between their posting history and their responses to posts of a wide range of viewpoints.\n  Incorporating this factor produces a confirmation-bias-integrated gravity well model that more accurately identifies echo chambers and reveals community-level markers of information health. We validated the approach on nineteen Reddit communities, demonstrating improved detection of echo chambers.\n  Our contribution is a framework for systematically capturing the role of confirmation bias in online group dynamics, enabling more effective identification of echo chambers. By flagging these high-risk environments, the model supports efforts to curb the spread of misinformation at its most common points of amplification.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“ echo chambers åœ¨è¯¯å¯¼ä¿¡æ¯ä¼ æ’­ä¸­çš„æ ¸å¿ƒä½œç”¨ï¼Œæå‡ºäº†ä¸€ä¸ªç»“åˆå¤§è¯­è¨€æ¨¡å‹ LLM é©±åŠ¨çš„ confirmation bias æ¨¡å‹ã€‚ç ”ç©¶è€…é€šè¿‡å¼•å…¥åŠ¨æ€çš„ confirmation bias å˜é‡æ‰©å±•äº†ç°æœ‰çš„ gravity well æ¨¡å‹ï¼Œç”¨ä»¥è¡¡é‡ç”¨æˆ·å¯¹å¼ºåŒ–å…¶å›ºæœ‰ä¿¡å¿µå†…å®¹çš„æ˜“æ„Ÿæ€§å¼ºåº¦ã€‚è¯¥å˜é‡é€šè¿‡å¯¹æ¯”ç”¨æˆ·çš„å‘å¸–å†å²åŠå…¶å¯¹å¤šå…ƒè§‚ç‚¹å¸–å­çš„åé¦ˆè¿›è¡Œè®¡ç®—ï¼Œä»è€Œå®ç°å¯¹ä¸ªä½“åå·®çš„é‡åŒ–ã€‚åœ¨ 19 ä¸ª Reddit ç¤¾åŒºçš„å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥é›†æˆæ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯†åˆ« echo chambers å¹¶æ­ç¤ºç¤¾åŒºå±‚é¢çš„ä¿¡æ¯å¥åº·æŒ‡æ ‡ã€‚è¯¥æ¡†æ¶ä¸ºç³»ç»Ÿæ€§æ•æ‰åœ¨çº¿ç¾¤ä½“åŠ¨åŠ›å­¦ä¸­çš„ confirmation bias æä¾›äº†æ–°è·¯å¾„ï¼Œæœ‰åŠ©äºåŠæ—¶æ ‡è®°é«˜é£é™©ç¯å¢ƒå¹¶ä»æºå¤´ä¸Šéåˆ¶è¯¯å¯¼ä¿¡æ¯çš„æ”¾å¤§ä¼ æ’­ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03832v2",
      "published_date": "2025-09-04 02:41:35 UTC",
      "updated_date": "2025-09-07 00:29:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:23.092244+00:00"
    },
    {
      "arxiv_id": "2509.03830v2",
      "title": "A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai",
      "title_zh": "å†å²è¡—åŒºæ¸¸å®¢æ„ŸçŸ¥çš„å¤šç»´åº¦äººå·¥æ™ºèƒ½é©±åŠ¨åˆ†ææ¡†æ¶ï¼šä»¥ Shanghai ä¸ºä¾‹",
      "authors": [
        "Kaizhen Tan",
        "Yufan Wu",
        "Yuxuan Liu",
        "Haoran Zeng"
      ],
      "abstract": "Historic urban quarters play a vital role in preserving cultural heritage while serving as vibrant spaces for tourism and everyday life. Understanding how tourists perceive these environments is essential for sustainable, human-centered urban planning. This study proposes a multidimensional AI-powered framework for analyzing tourist perception in historic urban quarters using multimodal data from social media. Applied to twelve historic quarters in central Shanghai, the framework integrates focal point extraction, color theme analysis, and sentiment mining. Visual focus areas are identified from tourist-shared photos using a fine-tuned semantic segmentation model. To assess aesthetic preferences, dominant colors are extracted using a clustering method, and their spatial distribution across quarters is analyzed. Color themes are further compared between social media photos and real-world street views, revealing notable shifts. This divergence highlights potential gaps between visual expectations and the built environment, reflecting both stylistic preferences and perceptual bias. Tourist reviews are evaluated through a hybrid sentiment analysis approach combining a rule-based method and a multi-task BERT model. Satisfaction is assessed across four dimensions: tourist activities, built environment, service facilities, and business formats. The results reveal spatial variations in aesthetic appeal and emotional response. Rather than focusing on a single technical innovation, this framework offers an integrated, data-driven approach to decoding tourist perception and contributes to informed decision-making in tourism, heritage conservation, and the design of aesthetically engaging public spaces.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå¤šç»´åº¦äººå·¥æ™ºèƒ½é©±åŠ¨çš„æ¡†æ¶(multidimensional AI-powered framework)ï¼Œæ—¨åœ¨é€šè¿‡ç¤¾äº¤åª’ä½“çš„å¤šæ¨¡æ€æ•°æ®(multimodal data)åˆ†ææ¸¸å®¢å¯¹å†å²åŸå¸‚è¡—åŒºçš„æ„ŸçŸ¥ï¼Œå¹¶ä»¥ä¸Šæµ·12ä¸ªå†å²è¡—åŒºä¸ºä¾‹è¿›è¡Œäº†å®è¯ç ”ç©¶ã€‚è¯¥æ¡†æ¶é›†æˆäº†ç„¦ç‚¹æå–ã€è‰²å½©ä¸»é¢˜åˆ†æå’Œæƒ…æ„ŸæŒ–æ˜ï¼Œåˆ©ç”¨å¾®è°ƒçš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹(semantic segmentation model)ä»æ¸¸å®¢ç…§ç‰‡ä¸­è¯†åˆ«è§†è§‰å…³æ³¨ç‚¹ï¼Œå¹¶é€šè¿‡èšç±»ç®—æ³•æå–ä¸»å¯¼è‰²å½©ã€‚ç ”ç©¶é€šè¿‡å¯¹æ¯”ç¤¾äº¤åª’ä½“ç…§ç‰‡ä¸ç°å®è¡—æ™¯çš„è‰²å½©ä¸»é¢˜ï¼Œæ­ç¤ºäº†è§†è§‰é¢„æœŸä¸å»ºæˆç¯å¢ƒä¹‹é—´çš„æ˜¾è‘—å·®å¼‚ï¼Œåæ˜ äº†æ¸¸å®¢çš„å®¡ç¾åå¥½ä¸æ„ŸçŸ¥åå·®(perceptual bias)ã€‚åœ¨æƒ…æ„Ÿåˆ†ææ–¹é¢ï¼Œç ”ç©¶ç»“åˆäº†åŸºäºè§„åˆ™çš„æ–¹æ³•å’Œå¤šä»»åŠ¡BERTæ¨¡å‹(multi-task BERT model)ï¼Œä»æ¸¸å®¢æ´»åŠ¨ã€å»ºæˆç¯å¢ƒã€æœåŠ¡è®¾æ–½å’Œä¸šæ€å››ä¸ªç»´åº¦è¯„ä¼°æ»¡æ„åº¦ã€‚å®éªŒç»“æœæ­ç¤ºäº†ä¸åŒè¡—åŒºåœ¨å®¡ç¾å¸å¼•åŠ›å’Œæƒ…æ„Ÿååº”ä¸Šçš„ç©ºé—´å·®å¼‚ã€‚è¯¥ç ”ç©¶æä¾›äº†ä¸€ç§è§£ç æ¸¸å®¢æ„ŸçŸ¥çš„é›†æˆæ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œä¸ºæ—…æ¸¸ç®¡ç†ã€æ–‡åŒ–é—äº§ä¿æŠ¤åŠå…¬å…±ç©ºé—´è®¾è®¡æä¾›äº†ç§‘å­¦å†³ç­–ä¾æ®ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03830v2",
      "published_date": "2025-09-04 02:35:14 UTC",
      "updated_date": "2026-01-06 16:02:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:15.284154+00:00"
    },
    {
      "arxiv_id": "2509.03828v1",
      "title": "An Agentic Model Context Protocol Framework for Medical Concept Standardization",
      "title_zh": "é¢å‘åŒ»å­¦æ¦‚å¿µæ ‡å‡†åŒ–çš„æ™ºèƒ½ä½“æ¨¡å‹ä¸Šä¸‹æ–‡åè®®æ¡†æ¶",
      "authors": [
        "Jaerong Ahn",
        "Andrew Wen",
        "Nan Wang",
        "Heling Jia",
        "Zhiyi Yue",
        "Sunyang Fu",
        "Hongfang Liu"
      ],
      "abstract": "The Observational Medical Outcomes Partnership (OMOP) common data model (CDM) provides a standardized representation of heterogeneous health data to support large-scale, multi-institutional research. One critical step in data standardization using OMOP CDM is the mapping of source medical terms to OMOP standard concepts, a procedure that is resource-intensive and error-prone. While large language models (LLMs) have the potential to facilitate this process, their tendency toward hallucination makes them unsuitable for clinical deployment without training and expert validation. Here, we developed a zero-training, hallucination-preventive mapping system based on the Model Context Protocol (MCP), a standardized and secure framework allowing LLMs to interact with external resources and tools. The system enables explainable mapping and significantly improves efficiency and accuracy with minimal effort. It provides real-time vocabulary lookups and structured reasoning outputs suitable for immediate use in both exploratory and production environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—æ•°æ®æ ‡å‡†åŒ–è¿‡ç¨‹ä¸­åŸå§‹åŒ»å­¦æœ¯è¯­å‘OMOPé€šç”¨æ•°æ®æ¨¡å‹(Common Data Model, CDM)æ˜ å°„æ—¶å­˜åœ¨çš„èµ„æºå¯†é›†å’Œæ˜“å‡ºé”™é—®é¢˜ï¼Œå¼€å‘äº†ä¸€ç§åŸºäºæ¨¡å‹ä¸Šä¸‹æ–‡åè®®(Model Context Protocol, MCP)çš„æ™ºèƒ½ä½“æ¡†æ¶ã€‚é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸´åºŠéƒ¨ç½²ä¸­å¯èƒ½äº§ç”Ÿçš„å¹»è§‰æŒ‘æˆ˜ï¼Œè¯¥ç³»ç»Ÿé‡‡ç”¨äº†ä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒ(zero-training)ä¸”å…·å¤‡å¹»è§‰é¢„é˜²æœºåˆ¶çš„æ˜ å°„ç­–ç•¥ã€‚é€šè¿‡åˆ©ç”¨MCPè¿™ä¸€æ ‡å‡†åŒ–å®‰å…¨æ¡†æ¶ï¼Œè¯¥ç³»ç»Ÿä½¿LLMsèƒ½å¤Ÿå®æ—¶ä¸å¤–éƒ¨èµ„æºåŠå·¥å…·äº¤äº’ï¼Œä»è€Œå®ç°å…·å¤‡å¯è§£é‡Šæ€§çš„æœ¯è¯­æ˜ å°„å’Œç»“æ„åŒ–æ¨ç†è¾“å‡ºã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä»…éœ€æå°‘äººå·¥åŠªåŠ›çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æå‡äº†åŒ»å­¦æœ¯è¯­æ˜ å°„çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆé€‚ç”¨äºå³æ—¶ç§‘ç ”æ¢ç´¢æˆ–ç”Ÿäº§ç¯å¢ƒçš„æ ‡å‡†åŒ–ç»“æœï¼Œä¸ºå¤§è§„æ¨¡å¤šæœºæ„åŒ»å­¦ç ”ç©¶æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯ä¿éšœã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03828v1",
      "published_date": "2025-09-04 02:32:22 UTC",
      "updated_date": "2025-09-04 02:32:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:48.490931+00:00"
    },
    {
      "arxiv_id": "2509.03827v1",
      "title": "What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¼šå¦‚ä½•å†³ç­–ï¼Ÿè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„æ”¿ç­–åˆ¶å®šèƒ½åŠ›",
      "authors": [
        "Pierre Le Coz",
        "Jia An Liu",
        "Debarun Bhattacharjya",
        "Georgina Curto",
        "Serge Stinckwich"
      ],
      "abstract": "Large language models (LLMs) are increasingly being adopted in high-stakes domains. Their capacity to process vast amounts of unstructured data, explore flexible scenarios, and handle a diversity of contextual factors can make them uniquely suited to provide new insights for the complexity of social policymaking. This article evaluates whether LLMs' are aligned with domain experts (and among themselves) to inform social policymaking on the subject of homelessness alleviation - a challenge affecting over 150 million people worldwide. We develop a novel benchmark comprised of decision scenarios with policy choices across four geographies (South Bend, USA; Barcelona, Spain; Johannesburg, South Africa; Macau SAR, China). The policies in scope are grounded in the conceptual framework of the Capability Approach for human development. We also present an automated pipeline that connects the benchmarked policies to an agent-based model, and we explore the social impact of the recommended policies through simulated social scenarios. The paper results reveal promising potential to leverage LLMs for social policy making. If responsible guardrails and contextual calibrations are introduced in collaboration with local domain experts, LLMs can provide humans with valuable insights, in the form of alternative policies at scale.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç¤¾ä¼šæ”¿ç­–åˆ¶å®šé¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«å…³æ³¨å…¨çƒèŒƒå›´å†…çš„æ— å®¶å¯å½’(homelessness)ç¼“è§£é—®é¢˜ã€‚ä½œè€…å¼€å‘äº†ä¸€ä¸ªå…¨æ–°çš„åŸºå‡†æµ‹è¯•(benchmark)ï¼Œæ¶µç›–äº†ç¾å›½å—æœ¬å¾·ã€è¥¿ç­ç‰™å·´å¡ç½—é‚£ã€å—éçº¦ç¿°å†…æ–¯å ¡å’Œä¸­å›½æ¾³é—¨å››ä¸ªåœ°ç†åŒºåŸŸçš„å†³ç­–åœºæ™¯ã€‚è¿™äº›æ”¿ç­–è¯„ä¼°åŸºäºäººç±»å‘å±•çš„èƒ½åŠ›é€”å¾„(Capability Approach)æ¡†æ¶ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªè‡ªåŠ¨åŒ–æµæ°´çº¿å°†åŸºå‡†æ”¿ç­–ä¸åŸºäºæ™ºèƒ½ä½“çš„æ¨¡å‹(Agent-Based Model)ç›¸è¿ï¼Œä»¥æ¨¡æ‹Ÿæ¨èæ”¿ç­–åœ¨ä¸åŒç¤¾ä¼šåœºæ™¯ä¸‹çš„å½±å“ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåœ¨ä¸å½“åœ°é¢†åŸŸä¸“å®¶åˆä½œå¹¶å¼•å…¥è´Ÿè´£ä»»çš„æŠ¤æ (guardrails)ä¸è¯­å¢ƒæ ¡å‡†çš„å‰æä¸‹ï¼ŒLLMsèƒ½å¤Ÿå¤§è§„æ¨¡åœ°ä¸ºäººç±»æä¾›å…·æœ‰ä»·å€¼çš„æ›¿ä»£æ”¿ç­–è§è§£ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åˆ©ç”¨LLMsè¾…åŠ©å¤æ‚ç¤¾ä¼šæ”¿ç­–åˆ¶å®šçš„å¯è¡Œæ€§ï¼Œä¸ºæå‡å†³ç­–çš„å¤šæ ·æ€§å’Œç§‘å­¦æ€§æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03827v1",
      "published_date": "2025-09-04 02:28:58 UTC",
      "updated_date": "2025-09-04 02:28:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:45.191721+00:00"
    },
    {
      "arxiv_id": "2509.10522v1",
      "title": "Multimodal Deep Learning for ATCO Command Lifecycle Modeling and Workload Prediction",
      "title_zh": "åŸºäºå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ çš„ ATCO æŒ‡ä»¤ç”Ÿå‘½å‘¨æœŸå»ºæ¨¡ä¸å·¥ä½œè´Ÿè·é¢„æµ‹",
      "authors": [
        "Kaizhen Tan"
      ],
      "abstract": "Air traffic controllers (ATCOs) issue high-intensity voice commands in dense airspace, where accurate workload modeling is critical for safety and efficiency. This paper proposes a multimodal deep learning framework that integrates structured data, trajectory sequences, and image features to estimate two key parameters in the ATCO command lifecycle: the time offset between a command and the resulting aircraft maneuver, and the command duration. A high-quality dataset was constructed, with maneuver points detected using sliding window and histogram-based methods. A CNN-Transformer ensemble model was developed for accurate, generalizable, and interpretable predictions. By linking trajectories to voice commands, this work offers the first model of its kind to support intelligent command generation and provides practical value for workload assessment, staffing, and scheduling.",
      "tldr_zh": "åœ¨é«˜å¯†åº¦ç©ºåŸŸä¸­ï¼Œç©ºä¸­äº¤é€šç®¡åˆ¶å‘˜ (ATCO) é¢‘ç¹å‘å‡ºé«˜å¼ºåº¦è¯­éŸ³æŒ‡ä»¤ï¼Œå‡†ç¡®çš„å·¥ä½œè´Ÿè½½å»ºæ¨¡å¯¹ä¿éšœé£è¡Œå®‰å…¨ä¸æ•ˆç‡è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æ·±åº¦å­¦ä¹  (Multimodal Deep Learning) æ¡†æ¶ï¼Œé€šè¿‡æ•´åˆç»“æ„åŒ–æ•°æ®ã€è½¨è¿¹åºåˆ—å’Œå›¾åƒç‰¹å¾ï¼Œæ—¨åœ¨æ¨¡æ‹Ÿ ATCO æŒ‡ä»¤ç”Ÿå‘½å‘¨æœŸå¹¶é¢„æµ‹å·¥ä½œè´Ÿè½½ã€‚è¯¥æ¡†æ¶é‡ç‚¹ä¼°ç®—ä¸¤ä¸ªæ ¸å¿ƒå‚æ•°ï¼šæŒ‡ä»¤å‘å‡ºä¸é£æœºæœºåŠ¨ä¹‹é—´çš„åç§»æ—¶é—´ (Time Offset) ä»¥åŠæŒ‡ä»¤æŒç»­æ—¶é—´ (Command Duration)ã€‚ç ”ç©¶åˆ©ç”¨æ»‘åŠ¨çª—å£å’ŒåŸºäºç›´æ–¹å›¾çš„æ–¹æ³•æ£€æµ‹æœºåŠ¨ç‚¹ï¼Œå¹¶åŸºäºæ­¤å¼€å‘äº† CNN-Transformer é›†æˆæ¨¡å‹ï¼Œä»¥å®ç°å‡†ç¡®ä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„é¢„æµ‹ã€‚é€šè¿‡å°†é£è¡Œè½¨è¿¹ä¸è¯­éŸ³æŒ‡ä»¤ç›¸è¿æ¥ï¼Œè¯¥å·¥ä½œé¦–æ¬¡å®ç°äº†æ­¤ç±»å»ºæ¨¡ï¼Œä¸ä»…æ”¯æŒæ™ºèƒ½æŒ‡ä»¤ç”Ÿæˆï¼Œè¿˜ä¸ºå·¥ä½œè´Ÿè½½è¯„ä¼° (Workload Assessment)ã€äººå‘˜é…å¤‡å’Œæ’ç­è°ƒåº¦æä¾›äº†æ˜¾è‘—çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10522v1",
      "published_date": "2025-09-04 02:28:41 UTC",
      "updated_date": "2025-09-04 02:28:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:39:56.005706+00:00"
    },
    {
      "arxiv_id": "2509.05363v1",
      "title": "SasAgent: Multi-Agent AI System for Small-Angle Scattering Data Analysis",
      "title_zh": "SasAgentï¼šé¢å‘å°è§’æ•£å°„æ•°æ®åˆ†æçš„å¤šæ™ºèƒ½ä½“äººå·¥æ™ºèƒ½ç³»ç»Ÿ",
      "authors": [
        "Lijie Ding",
        "Changwoo Do"
      ],
      "abstract": "We introduce SasAgent, a multi-agent AI system powered by large language models (LLMs) that automates small-angle scattering (SAS) data analysis by leveraging tools from the SasView software and enables user interaction via text input. SasAgent features a coordinator agent that interprets user prompts and delegates tasks to three specialized agents for scattering length density (SLD) calculation, synthetic data generation, and experimental data fitting. These agents utilize LLM-friendly tools to execute tasks efficiently. These tools, including the model data tool, Retrieval-Augmented Generation (RAG) documentation tool, bump fitting tool, and SLD calculator tool, are derived from the SasView Python library. A user-friendly Gradio-based interface enhances user accessibility. Through diverse examples, we demonstrate SasAgent's ability to interpret complex prompts, calculate SLDs, generate accurate scattering data, and fit experimental datasets with high precision. This work showcases the potential of LLM-driven AI systems to streamline scientific workflows and enhance automation in SAS research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SasAgentï¼Œä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šæ™ºèƒ½ä½“AIç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆSasViewè½¯ä»¶å·¥å…·å®ç°å°è§’æ•£å°„(Small-Angle Scattering, SAS)æ•°æ®åˆ†æçš„è‡ªåŠ¨åŒ–ã€‚ç³»ç»Ÿæ ¸å¿ƒç”±ä¸€ä¸ªåè°ƒæ™ºèƒ½ä½“(Coordinator Agent)é©±åŠ¨ï¼Œè´Ÿè´£è§£æç”¨æˆ·æç¤ºå¹¶è°ƒåº¦ä¸‰ä¸ªä¸“é—¨æ™ºèƒ½ä½“è¿›è¡Œæ•£å°„é•¿åº¦å¯†åº¦(SLD)è®¡ç®—ã€åˆæˆæ•°æ®ç”ŸæˆåŠå®éªŒæ•°æ®æ‹Ÿåˆã€‚è¿™äº›æ™ºèƒ½ä½“é›†æˆäº†æ¨¡å‹æ•°æ®å·¥å…·ã€æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æ–‡æ¡£å·¥å…·ã€bumpæ‹Ÿåˆå·¥å…·ä»¥åŠSLDè®¡ç®—å™¨ç­‰åŸºäºSasView Pythonåº“çš„LLMå‹å¥½å‹å·¥å…·ã€‚é€šè¿‡æ˜“ç”¨çš„Gradioç•Œé¢ï¼Œç”¨æˆ·å¯ä»¥è½»æ¾è¿›è¡Œäº¤äº’å¼åˆ†æã€‚å¤šæ ·åŒ–çš„å®ä¾‹è¯æ˜SasAgentåœ¨è§£æå¤æ‚æŒ‡ä»¤ã€ç”Ÿæˆç²¾ç¡®æ•£å°„æ•°æ®ä»¥åŠé«˜ç²¾åº¦æ‹Ÿåˆå®éªŒæ•°æ®é›†æ–¹é¢å…·æœ‰å“è¶Šèƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†LLMé©±åŠ¨çš„ç³»ç»Ÿåœ¨ç®€åŒ–ç§‘å­¦å·¥ä½œæµå’Œæå‡SASç ”ç©¶è‡ªåŠ¨åŒ–æ°´å¹³æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05363v1",
      "published_date": "2025-09-04 02:23:23 UTC",
      "updated_date": "2025-09-04 02:23:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:06.588206+00:00"
    },
    {
      "arxiv_id": "2509.03817v2",
      "title": "Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning",
      "title_zh": "å­¦ä¼šå®¡è®®ï¼šåŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„æ™ºèƒ½ä½“åŒ–å¤§è¯­è¨€æ¨¡å‹å…ƒç­–ç•¥ååŒ",
      "authors": [
        "Wei Yang",
        "Jesse Thomason"
      ],
      "abstract": "Multi-agent systems of large language models (LLMs) show promise for complex reasoning, but their effectiveness is often limited by fixed collaboration protocols. These frameworks typically focus on macro-level orchestration while overlooking agents' internal deliberative capabilities. This critical meta-cognitive blindspot treats agents as passive executors unable to adapt their strategy based on internal cognitive states like uncertainty or confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where agents learn a decentralized policy over a set of high-level meta-cognitive actions: Persist, Refine, and Concede. To overcome the instability of traditional policy gradients in this setting, we develop SoftRankPO, a novel reinforcement learning algorithm. SoftRankPO stabilizes training by shaping advantages based on the rank of rewards mapped through smooth normal quantiles, making the learning process robust to reward variance. Experiments show that MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across five mathematical and general reasoning benchmarks compared to six state-of-the-art heuristic and learning-based multi-agent reasoning algorithms. Our work presents a paradigm for learning adaptive, meta-cognitive policies for multi-agent LLM systems, shifting the focus from designing fixed protocols to learning dynamic, deliberative strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤æ‚æ¨ç†ä¸­å—é™äºå›ºå®šåä½œåè®®çš„é—®é¢˜ï¼Œæå‡ºäº†å…ƒç­–ç•¥å®¡è®®æ¡†æ¶(Meta-Policy Deliberation Framework, MPDF)ã€‚é’ˆå¯¹ä¼ ç»Ÿæ¡†æ¶å¿½è§†æ™ºèƒ½ä½“å†…éƒ¨å…ƒè®¤çŸ¥(meta-cognitive)èƒ½åŠ›çš„ç¼ºé™·ï¼ŒMPDF å…è®¸æ™ºèƒ½ä½“æ ¹æ®å…¶å†…éƒ¨è®¤çŸ¥çŠ¶æ€ï¼Œåœ¨åšæŒ(Persist)ã€ç²¾ç‚¼(Refine)å’Œè®©æ­¥(Concede)ç­‰é«˜å±‚å…ƒè®¤çŸ¥åŠ¨ä½œä¸­å­¦ä¹ å»ä¸­å¿ƒåŒ–çš„åä½œç­–ç•¥ã€‚ä¸ºäº†å…‹æœç­–ç•¥æ¢¯åº¦è®­ç»ƒä¸­çš„ä¸ç¨³å®šæ€§ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº† SoftRankPO å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ç®—æ³•ï¼Œé€šè¿‡åŸºäºå¹³æ»‘æ­£æ€åˆ†ä½æ•°çš„å¥–åŠ±æ’åå¤„ç†æ¥æ˜¾è‘—å¢å¼ºå­¦ä¹ è¿‡ç¨‹çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMPDF ç»“åˆ SoftRankPO åœ¨äº”ä¸ªæ•°å­¦å’Œé€šç”¨æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼Œç›¸è¾ƒäºå…­ç§æœ€å…ˆè¿›çš„å¯å‘å¼æˆ–åŸºäºå­¦ä¹ çš„ç®—æ³•ï¼Œå®ç°äº† 4-5% çš„å¹³å‡å‡†ç¡®ç‡ç»å¯¹æå‡ã€‚è¯¥é¡¹å·¥ä½œä¸ºå¼€å‘å…·æœ‰è‡ªé€‚åº”èƒ½åŠ›çš„å…ƒè®¤çŸ¥å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ï¼Œå®ç°äº†ä»è®¾è®¡å›ºå®šåè®®åˆ°å­¦ä¹ åŠ¨æ€å®¡è®®ç­–ç•¥çš„è·¨è¶Šã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03817v2",
      "published_date": "2025-09-04 02:06:06 UTC",
      "updated_date": "2025-12-08 19:56:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:02.702676+00:00"
    },
    {
      "arxiv_id": "2509.03811v2",
      "title": "Rethinking Supply Chain Planning: A Generative Paradigm",
      "title_zh": "é‡æ–°æ€è€ƒä¾›åº”é“¾è§„åˆ’ï¼šä¸€ç§ç”Ÿæˆå¼èŒƒå¼",
      "authors": [
        "Jiaheng Yin",
        "Yongzhi Qi",
        "Jianshen Zhang",
        "Dongyang Geng",
        "Zhengyu Chen",
        "Hao Hu",
        "Wei Qi",
        "Zuo-Jun Max Shen"
      ],
      "abstract": "Supply chain planning is the critical process of anticipating future demand and coordinating operational activities across the logistics network. However, within the context of contemporary e-commerce, traditional planning paradigms, typically characterized by fragmented processes and static optimization, prove inadequate in addressing dynamic demand, organizational silos, and the complexity of multi-stage coordination. To address these challenges, this study proposes a fundamental rethinking of supply chain planning, redefining it not merely as a computational task, but as an interactive, integrated, and automated cognitive process. This new paradigm emphasizes the organic unification of human strategic intent with adaptive execution, shifting the focus from rigid control to continuous, intelligent orchestration. To operationalize this conceptual shift, we introduce a Generative AI-powered agentic framework. Functioning as an intelligent cognitive interface, this framework bridges the gap between unstructured business contexts and structured analytical workflows, enabling the system to comprehend complex semantics and coordinate decisions across organizational boundaries. We demonstrate the empirical validity of this approach within JD.com's large-scale operations. The deployment confirms the efficacy of this cognitive paradigm, yielding an approximate 22% improvement in planning accuracy and a 2% increase in in-stock rates, thereby validating the transformation of planning into an adaptive, knowledge-driven capability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£ç”µå­å•†åŠ¡ä¸­ä¼ ç»Ÿä¾›åº”é“¾è®¡åˆ’é¢ä¸´çš„æµç¨‹ç¢ç‰‡åŒ–ã€ç»„ç»‡å­¤å²›å’Œå¤šé˜¶æ®µåè°ƒå¤æ‚ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†å°†ä¾›åº”é“¾è®¡åˆ’é‡æ–°å®šä¹‰ä¸ºäº¤äº’å¼ã€é›†æˆåŒ–ä¸”è‡ªåŠ¨åŒ–çš„è®¤çŸ¥è¿‡ç¨‹çš„æ–°èŒƒå¼ã€‚æ ¸å¿ƒè´¡çŒ®åœ¨äºå¼•å…¥äº†ä¸€ç§åŸºäº Generative AI çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼ˆagentic frameworkï¼‰ï¼Œè¯¥æ¡†æ¶ä½œä¸ºæ™ºèƒ½è®¤çŸ¥æ¥å£ï¼Œæœ‰æ•ˆå¼¥åˆäº†éç»“æ„åŒ–ä¸šåŠ¡åœºæ™¯ä¸ç»“æ„åŒ–åˆ†æå·¥ä½œæµä¹‹é—´çš„é¸¿æ²Ÿã€‚é€šè¿‡è¯¥æ¡†æ¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿæ·±åº¦ç†è§£å¤æ‚ä¸šåŠ¡è¯­ä¹‰å¹¶å®ç°è·¨ç»„ç»‡è¾¹ç•Œçš„å†³ç­–åè°ƒï¼Œæ¨åŠ¨è®¡åˆ’æ¨¡å¼ä»åƒµåŒ–æ§åˆ¶å‘æŒç»­æ™ºèƒ½ç¼–æ’è½¬å˜ã€‚åœ¨äº¬ä¸œï¼ˆJD.comï¼‰å¤§è§„æ¨¡è¿è¥ä¸­çš„å®è¯ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆå°†è®¡åˆ’å‡†ç¡®ç‡æå‡äº†çº¦ 22%ï¼Œç°è´§ç‡ï¼ˆin-stock ratesï¼‰æé«˜äº† 2%ã€‚è¿™ä¸€å®è·µæœ‰åŠ›è¯æ˜äº†å°†ä¾›åº”é“¾è®¡åˆ’è½¬åŒ–ä¸ºè‡ªé€‚åº”ã€çŸ¥è¯†é©±åŠ¨èƒ½åŠ›çš„å¿…è¦æ€§ä¸æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03811v2",
      "published_date": "2025-09-04 01:55:58 UTC",
      "updated_date": "2026-01-09 07:47:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:24.456719+00:00"
    },
    {
      "arxiv_id": "2509.03809v1",
      "title": "Align-then-Slide: A complete evaluation framework for Ultra-Long Document-Level Machine Translation",
      "title_zh": "Align-then-Slideï¼šé’ˆå¯¹è¶…é•¿æ–‡æ¡£çº§æœºå™¨ç¿»è¯‘çš„å®Œæ•´è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Jiaxin Guo",
        "Daimeng Wei",
        "Yuanchang Luo",
        "Xiaoyu Chen",
        "Zhanglin Wu",
        "Huan Yang",
        "Hengchao Shang",
        "Zongyao Li",
        "Zhiqiang Rao",
        "Jinlong Yang",
        "Hao Yang"
      ],
      "abstract": "Large language models (LLMs) have ushered in a new era for document-level machine translation (\\textit{doc}-mt), yet their whole-document outputs challenge existing evaluation methods that assume sentence-by-sentence alignment. We introduce \\textit{\\textbf{Align-then-Slide}}, a complete evaluation framework for ultra-long doc-mt. In the Align stage, we automatically infer sentence-level source-target correspondences and rebuild the target to match the source sentence number, resolving omissions and many-to-one/one-to-many mappings. In the n-Chunk Sliding Evaluate stage, we calculate averaged metric scores under 1-, 2-, 3- and 4-chunk for multi-granularity assessment. Experiments on the WMT benchmark show a Pearson correlation of 0.929 between our method with expert MQM rankings. On a newly curated real-world test set, our method again aligns closely with human judgments. Furthermore, preference data produced by Align-then-Slide enables effective CPO training and its direct use as a reward model for GRPO, both yielding translations preferred over a vanilla SFT baseline. The results validate our framework as an accurate, robust, and actionable evaluation tool for doc-mt systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¶…é•¿æ–‡æ¡£çº§æœºå™¨ç¿»è¯‘(doc-mt)ä¸­å› å…¨æ–‡æ¡£è¾“å‡ºå¯¼è‡´ç°æœ‰å¥å¯¹å¥è¯„ä¼°æ–¹æ³•å¤±æ•ˆçš„é—®é¢˜ï¼Œæå‡ºäº†Align-then-Slideè¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„Aligné˜¶æ®µé€šè¿‡è‡ªåŠ¨æ¨æ–­æºå¥ä¸ç›®æ ‡å¥çš„å¯¹åº”å…³ç³»å¹¶é‡å»ºç›®æ ‡æ–‡æ¡£ï¼Œæœ‰æ•ˆè§£å†³äº†ç¿»è¯‘ä¸­çš„é—æ¼åŠå¤šå¯¹ä¸€ã€ä¸€å¯¹å¤šæ˜ å°„ç­‰å¤æ‚å¯¹é½æŒ‘æˆ˜ã€‚åœ¨n-Chunk Sliding Evaluateé˜¶æ®µï¼Œè¯¥æ–¹æ³•é€šè¿‡è®¡ç®—1è‡³4ä¸ªåˆ†å—(chunk)çš„å¹³å‡æŒ‡æ ‡å¾—åˆ†ï¼Œå®ç°äº†å¯¹ç¿»è¯‘è´¨é‡çš„å¤šç²’åº¦è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨WMTåŸºå‡†æµ‹è¯•ä¸­ä¸ä¸“å®¶MQMæ’åè¾¾åˆ°äº†0.929çš„Pearsonç›¸å…³æ€§ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œæµ‹è¯•é›†ä¸­ä¸äººç±»è¯„ä»·é«˜åº¦ä¸€è‡´ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨Align-then-Slideç”Ÿæˆçš„åå¥½æ•°æ®å¯æˆåŠŸç”¨äºCPOè®­ç»ƒæˆ–ä½œä¸ºGRPOçš„å¥–åŠ±æ¨¡å‹(reward model)ï¼Œå…¶ç”Ÿæˆçš„ç¿»è¯‘æ•ˆæœä¼˜äºä¼ ç»Ÿçš„SFTåŸºçº¿ã€‚è¯¥ç ”ç©¶å……åˆ†éªŒè¯äº†è¯¥æ¡†æ¶ä½œä¸ºä¸€ç§å‡†ç¡®ã€é²æ£’ä¸”å…·æœ‰å®è·µæ„ä¹‰çš„æ–‡æ¡£çº§æœºå™¨ç¿»è¯‘è¯„ä¼°å·¥å…·çš„æ˜¾è‘—ä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "under preview",
      "pdf_url": "https://arxiv.org/pdf/2509.03809v1",
      "published_date": "2025-09-04 01:50:20 UTC",
      "updated_date": "2025-09-04 01:50:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:14.694176+00:00"
    },
    {
      "arxiv_id": "2509.03805v1",
      "title": "Measuring How (Not Just Whether) VLMs Build Common Ground",
      "title_zh": "è¡¡é‡ VLM å¦‚ä½•ï¼ˆè€Œä¸ä»…æ˜¯æ˜¯å¦ï¼‰æ„å»ºå…±åŒåŸºç¡€",
      "authors": [
        "Saki Imai",
        "Mert Ä°nan",
        "Anthony Sicilia",
        "Malihe Alikhani"
      ],
      "abstract": "Large vision language models (VLMs) increasingly claim reasoning skills, yet current benchmarks evaluate them in single-turn or question answering settings. However, grounding is an interactive process in which people gradually develop shared understanding through ongoing communication. We introduce a four-metric suite (grounding efficiency, content alignment, lexical adaptation, and human-likeness) to systematically evaluate VLM performance in interactive grounding contexts. We deploy the suite on 150 self-play sessions of interactive referential games between three proprietary VLMs and compare them with human dyads. All three models diverge from human patterns on at least three metrics, while GPT4o-mini is the closest overall. We find that (i) task success scores do not indicate successful grounding and (ii) high image-utterance alignment does not necessarily predict task success. Our metric suite and findings offer a framework for future research on VLM grounding.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨äº¤äº’å¼åœºæ™¯ä¸­æ„å»ºå…±è¯† (Common Ground) çš„èƒ½åŠ›ï¼ŒæŒ‡å‡ºå½“å‰çš„åŸºå‡†æµ‹è¯•å¤šå±€é™äºå•è½®é—®ç­”ï¼Œå¿½è§†äº†æ²Ÿé€šä¸­é€æ¸å»ºç«‹ç†è§£çš„äº’åŠ¨è¿‡ç¨‹ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€å¥—åŒ…å«å››é¡¹æŒ‡æ ‡çš„è¯„ä¼°ä½“ç³» (grounding efficiency, content alignment, lexical adaptation, and human-likeness)ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§è¡¡é‡æ¨¡å‹åœ¨äº¤äº’è¯­å¢ƒä¸‹çš„è¡¨ç°ã€‚ç ”ç©¶è€…å¯¹ä¸‰ç§å•†ä¸š VLMs åœ¨ 150 åœºäº¤äº’å¼æŒ‡ä»£æ¸¸æˆ (referential games) ä¸­çš„è‡ªæˆ‘å¯¹å¼ˆ (self-play) è¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶å°†å…¶ä¸äººç±»è¡¨ç°è¿›è¡Œå¯¹æ¯”ã€‚å®éªŒå‘ç°ï¼Œæ‰€æœ‰æµ‹è¯•æ¨¡å‹åœ¨è‡³å°‘ä¸‰é¡¹æŒ‡æ ‡ä¸Šéƒ½ä¸äººç±»æ¨¡å¼å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå…¶ä¸­ GPT4o-mini åœ¨æ•´ä½“è¡¨ç°ä¸Šæœ€æ¥è¿‘äººç±»ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä»»åŠ¡æˆåŠŸç‡ (task success scores) å¹¶ä¸ç­‰åŒäºæˆåŠŸçš„å…±è¯†æ„å»ºï¼Œä¸”é«˜å›¾åƒ-è¯è¯­å¯¹é½åº¦ (image-utterance alignment) ä¹Ÿä¸ä¸€å®šèƒ½é¢„ç¤ºä»»åŠ¡æˆåŠŸã€‚è¿™ä¸€åº¦é‡ä½“ç³»å’Œå‘ç°ä¸ºæœªæ¥å…³äº VLM äº¤äº’å¼å…±è¯†æ„å»ºçš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªé‡è¦çš„å‚è€ƒæ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03805v1",
      "published_date": "2025-09-04 01:43:49 UTC",
      "updated_date": "2025-09-04 01:43:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:20.269198+00:00"
    },
    {
      "arxiv_id": "2509.03793v1",
      "title": "SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India",
      "title_zh": "SAMVADï¼šæ¨¡æ‹Ÿ India å¸æ³•è¯„è®®åŠ¨æ€çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Prathamesh Devadiga",
        "Omkaar Jayadev Shetty",
        "Pooja Agarwal"
      ],
      "abstract": "Understanding the complexities of judicial deliberation is crucial for assessing the efficacy and fairness of a justice system. However, empirical studies of judicial panels are constrained by significant ethical and practical barriers. This paper introduces SAMVAD, an innovative Multi-Agent System (MAS) designed to simulate the deliberation process within the framework of the Indian justice system.\n  Our system comprises agents representing key judicial roles: a Judge, a Prosecution Counsel, a Defense Counsel, and multiple Adjudicators (simulating a judicial bench), all powered by large language models (LLMs). A primary contribution of this work is the integration of Retrieval-Augmented Generation (RAG), grounded in a domain-specific knowledge base of landmark Indian legal documents, including the Indian Penal Code and the Constitution of India. This RAG functionality enables the Judge and Counsel agents to generate legally sound instructions and arguments, complete with source citations, thereby enhancing both the fidelity and transparency of the simulation.\n  The Adjudicator agents engage in iterative deliberation rounds, processing case facts, legal instructions, and arguments to reach a consensus-based verdict. We detail the system architecture, agent communication protocols, the RAG pipeline, the simulation workflow, and a comprehensive evaluation plan designed to assess performance, deliberation quality, and outcome consistency.\n  This work provides a configurable and explainable MAS platform for exploring legal reasoning and group decision-making dynamics in judicial simulations, specifically tailored to the Indian legal context and augmented with verifiable legal grounding via RAG.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SAMVADï¼Œä¸€ç§æ—¨åœ¨æ¨¡æ‹Ÿå°åº¦å¸æ³•å®¡è®®åŠ¨æ€çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multi-Agent System, MAS)ï¼Œä»¥å…‹æœå¸æ³•ç ”ç©¶ä¸­é¢ä¸´çš„ä¼¦ç†å’Œå®è·µé™åˆ¶ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)æ„å»ºäº†æ³•å®˜ã€æ§æ–¹å¾‹å¸ˆã€è¾©æ–¹å¾‹å¸ˆåŠå¤šåè£å†³å‘˜ç­‰å…³é”®å¸æ³•è§’è‰²ï¼Œå¹¶è¯¦ç»†è®¾è®¡äº†æ™ºèƒ½ä½“é—´çš„é€šä¿¡åè®®ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºæ•´åˆäº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯ï¼Œé€šè¿‡å¯¹æ¥å°åº¦åˆ‘æ³•å…¸(Indian Penal Code)å’Œå°åº¦å®ªæ³•(Constitution of India)ç­‰é¢†åŸŸç‰¹å®šçŸ¥è¯†åº“ï¼Œç¡®ä¿ç”Ÿæˆçš„æ³•å¾‹æŒ‡ä»¤å’Œè®ºç‚¹å…·å¤‡æƒå¨ä¾æ®ã€‚è£å†³å‘˜æ™ºèƒ½ä½“é€šè¿‡å¤šè½®è¿­ä»£å®¡è®®å¤„ç†æ¡ˆä»¶äº‹å®ä¸æ³•å¾‹è¾©è®ºï¼Œæœ€ç»ˆè¾¾æˆåŸºäºå…±è¯†çš„è£å†³ã€‚è¯¥å·¥ä½œä¸ºåœ¨å°åº¦æ³•å¾‹èƒŒæ™¯ä¸‹æ¢ç´¢æ³•å¾‹æ¨ç†å’Œç¾¤ä½“å†³ç­–åŠ¨æ€æä¾›äº†ä¸€ä¸ªå¯é…ç½®ã€å¯è§£é‡Šä¸”å…·æœ‰éªŒè¯æ€§æ³•å¾‹ä¾æ®çš„ä»¿çœŸå¹³å°ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03793v1",
      "published_date": "2025-09-04 01:04:44 UTC",
      "updated_date": "2025-09-04 01:04:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:31.565941+00:00"
    },
    {
      "arxiv_id": "2509.03791v1",
      "title": "SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation",
      "title_zh": "SiLVERScoreï¼šé¢å‘æ‰‹è¯­ç”Ÿæˆè¯„ä¼°çš„è¯­ä¹‰æ„ŸçŸ¥åµŒå…¥",
      "authors": [
        "Saki Imai",
        "Mert Ä°nan",
        "Anthony Sicilia",
        "Malihe Alikhani"
      ],
      "abstract": "Evaluating sign language generation is often done through back-translation, where generated signs are first recognized back to text and then compared to a reference using text-based metrics. However, this two-step evaluation pipeline introduces ambiguity: it not only fails to capture the multimodal nature of sign language-such as facial expressions, spatial grammar, and prosody-but also makes it hard to pinpoint whether evaluation errors come from sign generation model or the translation system used to assess it. In this work, we propose SiLVERScore, a novel semantically-aware embedding-based evaluation metric that assesses sign language generation in a joint embedding space. Our contributions include: (1) identifying limitations of existing metrics, (2) introducing SiLVERScore for semantically-aware evaluation, (3) demonstrating its robustness to semantic and prosodic variations, and (4) exploring generalization challenges across datasets. On PHOENIX-14T and CSL-Daily datasets, SiLVERScore achieves near-perfect discrimination between correct and random pairs (ROC AUC = 0.99, overlap < 7%), substantially outperforming traditional metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰‹è¯­ç”Ÿæˆè¯„ä¼°ä¸­å›è¯‘(back-translation)å­˜åœ¨çš„æ­§ä¹‰æ€§ã€æ— æ³•æ•æ‰å¤šæ¨¡æ€ç‰¹å¾ï¼ˆå¦‚é¢éƒ¨è¡¨æƒ…ã€ç©ºé—´è¯­æ³•ï¼‰ä»¥åŠé”™è¯¯å½’å› å›°éš¾ç­‰é—®é¢˜ï¼Œæå‡ºäº†SiLVERScoreã€‚è¿™æ˜¯ä¸€ç§åŸºäºè¯­ä¹‰æ„ŸçŸ¥åµŒå…¥(semantically-aware embedding-based)çš„æ–°å‹è¯„ä¼°æŒ‡æ ‡ï¼Œé€šè¿‡åœ¨è”åˆåµŒå…¥ç©ºé—´(joint embedding space)ä¸­å¯¹æ‰‹è¯­ç”Ÿæˆè¿›è¡Œç›´æ¥è¯„ä¼°ã€‚è¯¥æŒ‡æ ‡æœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿä¸¤æ­¥èµ°è¯„ä¼°æµç¨‹ä¸­éš¾ä»¥åŒºåˆ†é”™è¯¯æ¥æºçš„å›°å¢ƒï¼Œå¹¶å±•ç°å‡ºå¯¹è¯­ä¹‰å’ŒéŸµå¾‹(prosodic)å˜åŒ–çš„æå¼ºé²æ£’æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSiLVERScoreåœ¨PHOENIX-14Tå’ŒCSL-Dailyæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå…¶åŒºåˆ†æ­£ç¡®ä¸éšæœºé…å¯¹çš„ROC AUCè¾¾åˆ°0.99ï¼Œæ˜¾è‘—è¶…è¶Šäº†ä¼ ç»Ÿæ–‡æœ¬è¯„ä¼°æŒ‡æ ‡ã€‚è¯¥ç ”ç©¶è¿˜æ·±å…¥æ¢è®¨äº†è·¨æ•°æ®é›†çš„æ³›åŒ–æŒ‘æˆ˜ï¼Œä¸ºå®ç°æ›´ç²¾å‡†ã€æ›´å…·è¯­ä¹‰æ„ŸçŸ¥çš„è‡ªåŠ¨åŒ–æ‰‹è¯­è¯„ä¼°æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03791v1",
      "published_date": "2025-09-04 00:58:43 UTC",
      "updated_date": "2025-09-04 00:58:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:57.152797+00:00"
    },
    {
      "arxiv_id": "2509.03790v2",
      "title": "What Fundamental Structure in Reward Functions Enables Efficient Sparse-Reward Learning?",
      "title_zh": "å¥–åŠ±å‡½æ•°ä¸­çš„ä½•ç§åŸºç¡€ç»“æ„èƒ½å®ç°é«˜æ•ˆçš„ç¨€ç–å¥–åŠ±å­¦ä¹ ï¼Ÿ",
      "authors": [
        "Ibne Farabi Shihab",
        "Sanjeda Akter",
        "Anuj Sharma"
      ],
      "abstract": "Sparse-reward reinforcement learning (RL) remains fundamentally hard: without structure, any agent needs $Î©(|\\mathcal{S}||\\mathcal{A}|/p)$ samples to recover rewards. We introduce Policy-Aware Matrix Completion (PAMC) as a first concrete step toward a structural reward learning framework. Our key idea is to exploit approximate low-rank + sparse structure in the reward matrix, under policy-biased (MNAR) sampling. We prove recovery guarantees with inverse-propensity weighting, and establish a visitation-weighted error-to-regret bound linking completion error to control performance. Importantly, when assumptions weaken, PAMC degrades gracefully: confidence intervals widen and the algorithm abstains, ensuring safe fallback to exploration. Empirically, PAMC improves sample efficiency across Atari-26 (10M steps), DM Control, MetaWorld MT50, D4RL offline RL, and preference-based RL benchmarks, outperforming DrQ-v2, DreamerV3, Agent57, T-REX/D-REX, and PrefPPO under compute-normalized comparisons. Our results highlight PAMC as a practical and principled tool when structural rewards exist, and as a concrete first instantiation of a broader structural reward learning perspective.",
      "tldr_zh": "é’ˆå¯¹ç¨€ç–å¥–åŠ±å¼ºåŒ–å­¦ä¹ (Sparse-reward RL)é¢ä¸´çš„é«˜æ ·æœ¬å¤æ‚åº¦éš¾é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†Policy-Aware Matrix Completion (PAMC)æ¡†æ¶ï¼Œæ¢è®¨å¥–åŠ±å‡½æ•°ä¸­çš„åŸºç¡€ç»“æ„å¦‚ä½•æ”¯æŒé«˜æ•ˆå­¦ä¹ ã€‚PAMCåˆ©ç”¨å¥–åŠ±çŸ©é˜µä¸­è¿‘ä¼¼ä½ç§©(Low-rank)ä¸ç¨€ç–(Sparse)çš„ç»“æ„ç‰¹å¾ï¼Œåœ¨ç­–ç•¥åå·®(MNAR)é‡‡æ ·ä¸‹é€šè¿‡é€†å€¾å‘åŠ æƒ(Inverse-propensity weighting)å®ç°å¥–åŠ±æ¢å¤ï¼Œå¹¶è¯æ˜äº†å…¶ç†è®ºæ¢å¤ä¿è¯ã€‚ç ”ç©¶é€šè¿‡ç¡®ç«‹è®¿é—®åŠ æƒçš„è¯¯å·®-é—æ†¾ç•Œé™(Error-to-regret bound)ï¼Œå°†çŸ©é˜µè¡¥å…¨è¯¯å·®ä¸æœ€ç»ˆçš„æ§åˆ¶æ€§èƒ½ç›´æ¥è”ç³»ã€‚å½“ç»“æ„å‡è®¾å‡å¼±æ—¶ï¼Œè¯¥ç®—æ³•èƒ½é€šè¿‡æ‰©å¤§ç½®ä¿¡åŒºé—´å®ç°ä¼˜é›…é™çº§ï¼Œä»è€Œç¡®ä¿å®‰å…¨åœ°å›é€€åˆ°æ¢ç´¢é˜¶æ®µã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPAMCåœ¨Atari-26ã€DM Controlã€MetaWorld MT50åŠD4RLç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ ·æœ¬æ•ˆç‡ï¼Œæ€§èƒ½è¶…è¶Šäº†DrQ-v2ã€DreamerV3å’ŒAgent57ç­‰å…ˆè¿›æ¨¡å‹ã€‚è¯¥å·¥ä½œä¸ºç¨€ç–å¥–åŠ±ç¯å¢ƒä¸‹çš„ç»“æ„åŒ–å¥–åŠ±å­¦ä¹ æä¾›äº†ä¸€ä¸ªå®ç”¨ä¸”å…·å¤‡ç†è®ºæ”¯æ’‘çš„æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03790v2",
      "published_date": "2025-09-04 00:53:02 UTC",
      "updated_date": "2025-09-09 02:53:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:50.584440+00:00"
    },
    {
      "arxiv_id": "2509.03780v1",
      "title": "Natural Latents: Latent Variables Stable Across Ontologies",
      "title_zh": "Natural Latentsï¼šè·¨æœ¬ä½“ç¨³å®šçš„æ½œå˜é‡",
      "authors": [
        "John Wentworth",
        "David Lorell"
      ],
      "abstract": "Suppose two Bayesian agents each learn a generative model of the same environment. We will assume the two have converged on the predictive distribution, i.e. distribution over some observables in the environment, but may have different generative models containing different latent variables. Under what conditions can one agent guarantee that their latents are a function of the other agents latents?\n  We give simple conditions under which such translation is guaranteed to be possible: the natural latent conditions. We also show that, absent further constraints, these are the most general conditions under which translatability is guaranteed. Crucially for practical application, our theorems are robust to approximation error in the natural latent conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å½“ä¸¤ä¸ª Bayesian agents é’ˆå¯¹åŒä¸€ç¯å¢ƒå­¦ä¹ ä¸åŒçš„ç”Ÿæˆæ¨¡å‹æ—¶ï¼Œå…¶æ½œå˜é‡ (latent variables) ä¹‹é—´æ˜¯å¦å­˜åœ¨ç¡®å®šçš„æ˜ å°„å…³ç³»ã€‚ä½œè€…æå‡ºäº†â€œè‡ªç„¶æ½œå˜é‡æ¡ä»¶â€ (natural latent conditions)ï¼Œæ˜ç¡®äº†åœ¨ä½•ç§æ¡ä»¶ä¸‹å¯ä»¥ä¿è¯ä¸€ä¸ªæ™ºèƒ½ä½“çš„æ½œå˜é‡èƒ½å¤Ÿè¢«ç¿»è¯‘ä¸ºå¦ä¸€ä¸ªæ™ºèƒ½ä½“æ½œå˜é‡çš„å‡½æ•°ã€‚ç ”ç©¶è¯æ˜ï¼Œåœ¨æ²¡æœ‰é¢å¤–çº¦æŸçš„æƒ…å†µä¸‹ï¼Œè¿™äº›æ¡ä»¶æ˜¯ä¿è¯æ½œå˜é‡å¯ç¿»è¯‘æ€§ (translatability) çš„æœ€æ™®é€‚æ¡ä»¶ã€‚æ­¤å¤–ï¼Œè¯¥ç†è®ºå¯¹äºè‡ªç„¶æ½œå˜é‡æ¡ä»¶ä¸­çš„è¿‘ä¼¼è¯¯å·®å…·æœ‰é²æ£’æ€§ (robust)ï¼Œä»è€Œç¡®ä¿äº†å…¶åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ä¸å¯é æ€§ã€‚",
      "categories": [
        "math.PR",
        "cs.AI",
        "cs.IT",
        "cs.LG"
      ],
      "primary_category": "math.PR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03780v1",
      "published_date": "2025-09-04 00:24:24 UTC",
      "updated_date": "2025-09-04 00:24:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:50.084852+00:00"
    },
    {
      "arxiv_id": "2509.05362v4",
      "title": "AI-in-the-Loop: Privacy Preserving Real-Time Scam Detection and Conversational Scambaiting by Leveraging LLMs and Federated Learning",
      "title_zh": "AI åœ¨ç¯ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹ä¸è”é‚¦å­¦ä¹ çš„éšç§ä¿æŠ¤å®æ—¶è¯ˆéª—æ£€æµ‹åŠå¯¹è¯å¼åè¯ˆè¯±å¯¼",
      "authors": [
        "Ismail Hossain",
        "Sai Puppala",
        "Md Jahangir Alam",
        "Sajedul Talukder"
      ],
      "abstract": "Scams exploiting real-time social engineering -- such as phishing, impersonation, and phone fraud -- remain a persistent and evolving threat across digital platforms. Existing defenses are largely reactive, offering limited protection during active interactions. We propose a privacy-preserving, AI-in-the-loop framework that proactively detects and disrupts scam conversations in real time. The system combines instruction-tuned artificial intelligence with a safety-aware utility function that balances engagement with harm minimization, and employs federated learning to enable continual model updates without raw data sharing. Experimental evaluations show that the system produces fluent and engaging responses (perplexity as low as 22.3, engagement $\\approx$0.80), while human studies confirm significant gains in realism, safety, and effectiveness over strong baselines. In federated settings, models trained with FedAvg sustain up to 30 rounds while preserving high engagement ($\\approx$0.80), strong relevance ($\\approx$0.74), and low PII leakage ($\\leq$0.0085). Even with differential privacy, novelty and safety remain stable, indicating that robust privacy can be achieved without sacrificing performance. The evaluation of guard models (LlamaGuard, LlamaGuard2/3, MD-Judge) shows a straightforward pattern: stricter moderation settings reduce the chance of exposing personal information, but they also limit how much the model engages in conversation. In contrast, more relaxed settings allow longer and richer interactions, which improve scam detection, but at the cost of higher privacy risk. To our knowledge, this is the first framework to unify real-time scam-baiting, federated privacy preservation, and calibrated safety moderation into a proactive defense paradigm.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåä¸º AI-in-the-loop çš„éšç§ä¿æŠ¤æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) å’Œè”é‚¦å­¦ä¹  (Federated Learning) æŠ€æœ¯ï¼Œå®ç°å¯¹ç¤¾äº¤å·¥ç¨‹è¯ˆéª—çš„å®æ—¶ç›‘æµ‹ä¸ä¸»åŠ¨åè¯ˆè¯±å¯¼ (Conversational Scambaiting)ã€‚è¯¥ç³»ç»Ÿç»“åˆäº†ç»è¿‡æŒ‡ä»¤å¾®è°ƒ (Instruction-tuned) çš„äººå·¥æ™ºèƒ½ä¸å®‰å…¨æ„ŸçŸ¥æ•ˆç”¨å‡½æ•°ï¼Œåœ¨ç»´æŒå¯¹è¯å‚ä¸åº¦çš„åŒæ—¶æœ€å¤§é™åº¦åœ°é™ä½æ½œåœ¨å±å®³ã€‚ä¸ºäº†ä¿æŠ¤éšç§ï¼Œæ¡†æ¶é‡‡ç”¨è”é‚¦å­¦ä¹ æœºåˆ¶å®ç°æ— éœ€å…±äº«åŸå§‹æ•°æ®çš„æ¨¡å‹æŒç»­æ›´æ–°ï¼Œå¹¶è¯æ˜äº†å¼•å…¥å·®å¼‚éšç§ (Differential Privacy) ä»èƒ½ä¿æŒæ€§èƒ½ç¨³å®šã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨çœŸå®æ„Ÿå’Œå®‰å…¨æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå…¶ FedAvg æ¨¡å‹åœ¨å¤šè½®è¿­ä»£ä¸­ä¿æŒäº†æä½çš„äººèº«è¯†åˆ«ä¿¡æ¯ (PII) æ³„éœ²ç‡ã€‚ç ”ç©¶è¿˜é€šè¿‡è¯„ä¼° LlamaGuard ç­‰é˜²æŠ¤æ¨¡å‹ï¼Œæ­ç¤ºäº†å®‰å…¨å®¡æ ¸å¼ºåº¦ä¸å¯¹è¯å‚ä¸åº¦ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚ä½œä¸ºé¦–ä¸ªå°†å®æ—¶åè¯ˆè¯±å¯¼ã€è”é‚¦éšç§ä¿æŠ¤å’Œæ ¡å‡†å®‰å…¨å®¡æ ¸ç»Ÿä¸€çš„ä¸»åŠ¨é˜²å¾¡èŒƒå¼ï¼Œè¯¥ç ”ç©¶ä¸ºåº”å¯¹æ¼”è¿›ä¸­çš„æ•°å­—è¯ˆéª—å¨èƒæä¾›äº†é‡è¦æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper got accepted in 26th Privacy Enhancing Technologies Symposium (PETS 2026). We uploaded it into ArXiv as pre-print",
      "pdf_url": "https://arxiv.org/pdf/2509.05362v4",
      "published_date": "2025-09-04 00:19:48 UTC",
      "updated_date": "2026-01-20 03:48:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:40:56.265137+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 134,
  "processed_papers_count": 134,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T16:41:48.819129+00:00"
}