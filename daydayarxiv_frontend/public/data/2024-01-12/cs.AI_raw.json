[
  {
    "arxiv_id": "2401.10282v2",
    "title": "BioDiffusion: A Versatile Diffusion Model for Biomedical Signal Synthesis",
    "authors": [
      "Xiaomin Li",
      "Mykhailo Sakevych",
      "Gentry Atkinson",
      "Vangelis Metsis"
    ],
    "abstract": "Machine learning tasks involving biomedical signals frequently grapple with\nissues such as limited data availability, imbalanced datasets, labeling\ncomplexities, and the interference of measurement noise. These challenges often\nhinder the optimal training of machine learning algorithms. Addressing these\nconcerns, we introduce BioDiffusion, a diffusion-based probabilistic model\noptimized for the synthesis of multivariate biomedical signals. BioDiffusion\ndemonstrates excellence in producing high-fidelity, non-stationary,\nmultivariate signals for a range of tasks including unconditional,\nlabel-conditional, and signal-conditional generation. Leveraging these\nsynthesized signals offers a notable solution to the aforementioned challenges.\nOur research encompasses both qualitative and quantitative assessments of the\nsynthesized data quality, underscoring its capacity to bolster accuracy in\nmachine learning tasks tied to biomedical signals. Furthermore, when juxtaposed\nwith current leading time-series generative models, empirical evidence suggests\nthat BioDiffusion outperforms them in biomedical signal generation quality.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.10282v2",
    "published_date": "2024-01-12 23:52:44 UTC",
    "updated_date": "2024-01-27 17:44:55 UTC"
  },
  {
    "arxiv_id": "2401.06925v2",
    "title": "Modeling Latent Selection with Structural Causal Models",
    "authors": [
      "Leihao Chen",
      "Onno Zoeter",
      "Joris M. Mooij"
    ],
    "abstract": "Selection bias is ubiquitous in real-world data, and can lead to misleading\nresults if not dealt with properly. We introduce a conditioning operation on\nStructural Causal Models (SCMs) to model latent selection from a causal\nperspective. We show that the conditioning operation transforms an SCM with the\npresence of an explicit latent selection mechanism into an SCM without such\nselection mechanism, which partially encodes the causal semantics of the\nselected subpopulation according to the original SCM. Furthermore, we show that\nthis conditioning operation preserves the simplicity, acyclicity, and linearity\nof SCMs, and commutes with marginalization. Thanks to these properties,\ncombined with marginalization and intervention, the conditioning operation\noffers a valuable tool for conducting causal reasoning tasks within causal\nmodels where latent details have been abstracted away. We demonstrate by\nexample how classical results of causal inference can be generalized to include\nselection bias and how the conditioning operation helps with modeling of\nreal-world problems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06925v2",
    "published_date": "2024-01-12 23:14:34 UTC",
    "updated_date": "2024-08-01 08:51:46 UTC"
  },
  {
    "arxiv_id": "2401.06922v1",
    "title": "Open RAN LSTM Traffic Prediction and Slice Management using Deep Reinforcement Learning",
    "authors": [
      "Fatemeh Lotfi",
      "Fatemeh Afghah"
    ],
    "abstract": "With emerging applications such as autonomous driving, smart cities, and\nsmart factories, network slicing has become an essential component of 5G and\nbeyond networks as a means of catering to a service-aware network. However,\nmanaging different network slices while maintaining quality of services (QoS)\nis a challenge in a dynamic environment. To address this issue, this paper\nleverages the heterogeneous experiences of distributed units (DUs) in ORAN\nsystems and introduces a novel approach to ORAN slicing xApp using distributed\ndeep reinforcement learning (DDRL). Additionally, to enhance the\ndecision-making performance of the RL agent, a prediction rApp based on long\nshort-term memory (LSTM) is incorporated to provide additional information from\nthe dynamic environment to the xApp. Simulation results demonstrate significant\nimprovements in network performance, particularly in reducing QoS violations.\nThis emphasizes the importance of using the prediction rApp and distributed\nactors' information jointly as part of a dynamic xApp.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to publish in the IEEE Asilomar Conference on Signals,\n  Systems, and Computers, 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.06922v1",
    "published_date": "2024-01-12 22:43:07 UTC",
    "updated_date": "2024-01-12 22:43:07 UTC"
  },
  {
    "arxiv_id": "2401.06915v2",
    "title": "DocFinQA: A Long-Context Financial Reasoning Dataset",
    "authors": [
      "Varshini Reddy",
      "Rik Koncel-Kedziorski",
      "Viet Dac Lai",
      "Michael Krumdick",
      "Charles Lovering",
      "Chris Tanner"
    ],
    "abstract": "For large language models (LLMs) to be effective in the financial domain --\nwhere each decision can have a significant impact -- it is necessary to\ninvestigate realistic tasks and data. Financial professionals often interact\nwith documents that are hundreds of pages long, but most financial research\ndatasets only deal with short excerpts from these documents. To address this,\nwe introduce a long-document financial QA task. We augment 7,437 questions from\nthe existing FinQA dataset with the full-document context, extending the\naverage context length from under 700 words in FinQA to 123k words in DocFinQA.\nWe conduct extensive experiments over retrieval-based QA pipelines and\nlong-context language models. DocFinQA proves a significant challenge for even\nstate-of-the-art systems. We also provide a case-study on the longest documents\nin DocFinQA and find that models particularly struggle on these documents.\nAddressing these challenges may have a wide reaching impact across applications\nwhere specificity and long-range contexts are critical, like gene sequences and\nlegal document contract analysis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.06915v2",
    "published_date": "2024-01-12 22:19:22 UTC",
    "updated_date": "2024-02-29 19:55:14 UTC"
  },
  {
    "arxiv_id": "2401.06883v1",
    "title": "Scaling While Privacy Preserving: A Comprehensive Synthetic Tabular Data Generation and Evaluation in Learning Analytics",
    "authors": [
      "Qinyi Liu",
      "Mohammad Khalil",
      "Ronas Shakya",
      "Jelena Jovanovic"
    ],
    "abstract": "Privacy poses a significant obstacle to the progress of learning analytics\n(LA), presenting challenges like inadequate anonymization and data misuse that\ncurrent solutions struggle to address. Synthetic data emerges as a potential\nremedy, offering robust privacy protection. However, prior LA research on\nsynthetic data lacks thorough evaluation, essential for assessing the delicate\nbalance between privacy and data utility. Synthetic data must not only enhance\nprivacy but also remain practical for data analytics. Moreover, diverse LA\nscenarios come with varying privacy and utility needs, making the selection of\nan appropriate synthetic data approach a pressing challenge. To address these\ngaps, we propose a comprehensive evaluation of synthetic data, which\nencompasses three dimensions of synthetic data quality, namely resemblance,\nutility, and privacy. We apply this evaluation to three distinct LA datasets,\nusing three different synthetic data generation methods. Our results show that\nsynthetic data can maintain similar utility (i.e., predictive performance) as\nreal data, while preserving privacy. Furthermore, considering different privacy\nand data utility requirements in different LA scenarios, we make customized\nrecommendations for synthetic data generation. This paper not only presents a\ncomprehensive evaluation of synthetic data but also illustrates its potential\nin mitigating privacy concerns within the field of LA, thus contributing to a\nwider application of synthetic data in LA and promoting a better practice for\nopen science.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06883v1",
    "published_date": "2024-01-12 20:27:55 UTC",
    "updated_date": "2024-01-12 20:27:55 UTC"
  },
  {
    "arxiv_id": "2401.06868v1",
    "title": "Multicriteria decision support employing adaptive prediction in a tensor-based feature representation",
    "authors": [
      "Betania Silva Carneiro Campello",
      "Leonardo Tomazeli Duarte",
      "João Marcos Travassos Romano"
    ],
    "abstract": "Multicriteria decision analysis (MCDA) is a widely used tool to support\ndecisions in which a set of alternatives should be ranked or classified based\non multiple criteria. Recent studies in MCDA have shown the relevance of\nconsidering not only current evaluations of each criterion but also past data.\nPast-data-based approaches carry new challenges, especially in time-varying\nenvironments. This study deals with this challenge via essential tools of\nsignal processing, such as tensorial representations and adaptive prediction.\nMore specifically, we structure the criteria' past data as a tensor and, by\napplying adaptive prediction, we compose signals with these prediction values\nof the criteria. Besides, we transform the prediction in the time domain into a\nmost favorable decision making domain, called the feature domain. We present a\nnovel extension of the MCDA method PROMETHEE II, aimed at addressing the tensor\nin the feature domain to obtain a ranking of alternatives. Numerical\nexperiments were performed using real-world time series, and our approach is\ncompared with other existing strategies. The results highlight the relevance\nand efficiency of our proposal, especially for nonstationary time series.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06868v1",
    "published_date": "2024-01-12 19:46:29 UTC",
    "updated_date": "2024-01-12 19:46:29 UTC"
  },
  {
    "arxiv_id": "2401.06866v2",
    "title": "Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data",
    "authors": [
      "Yubin Kim",
      "Xuhai Xu",
      "Daniel McDuff",
      "Cynthia Breazeal",
      "Hae Won Park"
    ],
    "abstract": "Large language models (LLMs) are capable of many natural language tasks, yet\nthey are far from perfect. In health applications, grounding and interpreting\ndomain-specific and non-linguistic data is crucial. This paper investigates the\ncapacity of LLMs to make inferences about health based on contextual\ninformation (e.g. user demographics, health knowledge) and physiological data\n(e.g. resting heart rate, sleep minutes). We present a comprehensive evaluation\nof 12 state-of-the-art LLMs with prompting and fine-tuning techniques on four\npublic health datasets (PMData, LifeSnaps, GLOBEM and AW_FB). Our experiments\ncover 10 consumer health prediction tasks in mental health, activity,\nmetabolic, and sleep assessment. Our fine-tuned model, HealthAlpaca exhibits\ncomparable performance to much larger models (GPT-3.5, GPT-4 and Gemini-Pro),\nachieving the best performance in 8 out of 10 tasks. Ablation studies highlight\nthe effectiveness of context enhancement strategies. Notably, we observe that\nour context enhancement can yield up to 23.8% improvement in performance. While\nconstructing contextually rich prompts (combining user context, health\nknowledge and temporal information) exhibits synergistic improvement, the\ninclusion of health knowledge context in prompts significantly enhances overall\nperformance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06866v2",
    "published_date": "2024-01-12 19:40:11 UTC",
    "updated_date": "2024-04-27 06:20:26 UTC"
  },
  {
    "arxiv_id": "2401.06757v2",
    "title": "Synthetic Data Generation Framework, Dataset, and Efficient Deep Model for Pedestrian Intention Prediction",
    "authors": [
      "Muhammad Naveed Riaz",
      "Maciej Wielgosz",
      "Abel Garcia Romera",
      "Antonio M. Lopez"
    ],
    "abstract": "Pedestrian intention prediction is crucial for autonomous driving. In\nparticular, knowing if pedestrians are going to cross in front of the\nego-vehicle is core to performing safe and comfortable maneuvers. Creating\naccurate and fast models that predict such intentions from sequential images is\nchallenging. A factor contributing to this is the lack of datasets with diverse\ncrossing and non-crossing (C/NC) scenarios. We address this scarceness by\nintroducing a framework, named ARCANE, which allows programmatically generating\nsynthetic datasets consisting of C/NC video clip samples. As an example, we use\nARCANE to generate a large and diverse dataset named PedSynth. We will show how\nPedSynth complements widely used real-world datasets such as JAAD and PIE, so\nenabling more accurate models for C/NC prediction. Considering the onboard\ndeployment of C/NC prediction models, we also propose a deep model named\nPedGNN, which is fast and has a very low memory footprint. PedGNN is based on a\nGNN-GRU architecture that takes a sequence of pedestrian skeletons as input to\npredict crossing intentions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06757v2",
    "published_date": "2024-01-12 18:44:01 UTC",
    "updated_date": "2024-06-15 13:44:22 UTC"
  },
  {
    "arxiv_id": "2401.06751v2",
    "title": "The Unreasonable Effectiveness of Easy Training Data for Hard Tasks",
    "authors": [
      "Peter Hase",
      "Mohit Bansal",
      "Peter Clark",
      "Sarah Wiegreffe"
    ],
    "abstract": "How can we train models to perform well on hard test data when hard training\ndata is by definition difficult to label correctly? This question has been\ntermed the scalable oversight problem and has drawn increasing attention as\nlanguage models have continually improved. In this paper, we present the\nsurprising conclusion that current pretrained language models often generalize\nrelatively well from easy to hard data, even performing as well as oracle\nmodels finetuned on hard data. We demonstrate this kind of easy-to-hard\ngeneralization using simple finetuning methods like in-context learning, linear\nclassifier heads, and QLoRA for seven different measures of datapoint hardness,\nincluding six empirically diverse human hardness measures (like grade level)\nand one model-based measure (loss-based). Furthermore, we show that even if one\ncares most about model performance on hard data, it can be better to collect\neasy data rather than hard data for finetuning, since hard data is generally\nnoisier and costlier to collect. Our experiments use open models up to 70b in\nsize and four publicly available question-answering datasets with questions\nranging in difficulty from 3rd grade science questions to college level STEM\nquestions and general-knowledge trivia. We conclude that easy-to-hard\ngeneralization in LMs is surprisingly strong for the tasks studied. Our code is\navailable at: https://github.com/allenai/easy-to-hard-generalization",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024. 23 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.06751v2",
    "published_date": "2024-01-12 18:36:29 UTC",
    "updated_date": "2024-06-05 14:10:11 UTC"
  },
  {
    "arxiv_id": "2401.06742v1",
    "title": "Using Natural Language Inference to Improve Persona Extraction from Dialogue in a New Domain",
    "authors": [
      "Alexandra DeLucia",
      "Mengjie Zhao",
      "Yoshinori Maeda",
      "Makoto Yoda",
      "Keiichi Yamada",
      "Hiromi Wakaki"
    ],
    "abstract": "While valuable datasets such as PersonaChat provide a foundation for training\npersona-grounded dialogue agents, they lack diversity in conversational and\nnarrative settings, primarily existing in the \"real\" world. To develop dialogue\nagents with unique personas, models are trained to converse given a specific\npersona, but hand-crafting these persona can be time-consuming, thus methods\nexist to automatically extract persona information from existing\ncharacter-specific dialogue. However, these persona-extraction models are also\ntrained on datasets derived from PersonaChat and struggle to provide\nhigh-quality persona information from conversational settings that do not take\nplace in the real world, such as the fantasy-focused dataset, LIGHT. Creating\nnew data to train models on a specific setting is human-intensive, thus\nprohibitively expensive. To address both these issues, we introduce a natural\nlanguage inference method for post-hoc adapting a trained persona extraction\nmodel to a new setting. We draw inspiration from the literature of dialog\nnatural language inference (NLI), and devise NLI-reranking methods to extract\nstructured persona information from dialogue. Compared to existing persona\nextraction models, our method returns higher-quality extracted persona and\nrequires less human annotation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code and models will be released upon publication",
    "pdf_url": "http://arxiv.org/pdf/2401.06742v1",
    "published_date": "2024-01-12 18:25:03 UTC",
    "updated_date": "2024-01-12 18:25:03 UTC"
  },
  {
    "arxiv_id": "2401.06730v2",
    "title": "Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty",
    "authors": [
      "Kaitlyn Zhou",
      "Jena D. Hwang",
      "Xiang Ren",
      "Maarten Sap"
    ],
    "abstract": "As natural language becomes the default interface for human-AI interaction,\nthere is a need for LMs to appropriately communicate uncertainties in\ndownstream applications. In this work, we investigate how LMs incorporate\nconfidence in responses via natural language and how downstream users behave in\nresponse to LM-articulated uncertainties. We examine publicly deployed models\nand find that LMs are reluctant to express uncertainties when answering\nquestions even when they produce incorrect responses. LMs can be explicitly\nprompted to express confidences, but tend to be overconfident, resulting in\nhigh error rates (an average of 47%) among confident responses. We test the\nrisks of LM overconfidence by conducting human experiments and show that users\nrely heavily on LM generations, whether or not they are marked by certainty.\nLastly, we investigate the preference-annotated datasets used in post training\nalignment and find that humans are biased against texts with uncertainty. Our\nwork highlights new safety harms facing human-LM interactions and proposes\ndesign recommendations and mitigating strategies moving forward.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 (Camera Ready)",
    "pdf_url": "http://arxiv.org/pdf/2401.06730v2",
    "published_date": "2024-01-12 18:03:30 UTC",
    "updated_date": "2024-07-09 23:53:06 UTC"
  },
  {
    "arxiv_id": "2402.10908v1",
    "title": "LLM-Assisted Crisis Management: Building Advanced LLM Platforms for Effective Emergency Response and Public Collaboration",
    "authors": [
      "Hakan T. Otal",
      "M. Abdullah Canbaz"
    ],
    "abstract": "Emergencies and critical incidents often unfold rapidly, necessitating a\nswift and effective response. In this research, we introduce a novel approach\nto identify and classify emergency situations from social media posts and\ndirect emergency messages using an open source Large Language Model, LLAMA2.\nThe goal is to harness the power of natural language processing and machine\nlearning to assist public safety telecommunicators and huge crowds during\ncountrywide emergencies. Our research focuses on developing a language model\nthat can understand users describe their situation in the 911 call, enabling\nLLAMA2 to analyze the content and offer relevant instructions to the\ntelecommunicator, while also creating workflows to notify government agencies\nwith the caller's information when necessary. Another benefit this language\nmodel provides is its ability to assist people during a significant emergency\nincident when the 911 system is overwhelmed, by assisting the users with simple\ninstructions and informing authorities with their location and emergency\ninformation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "68T50 68T50 68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10908v1",
    "published_date": "2024-01-12 17:50:35 UTC",
    "updated_date": "2024-01-12 17:50:35 UTC"
  },
  {
    "arxiv_id": "2401.06837v2",
    "title": "Structsum Generation for Faster Text Comprehension",
    "authors": [
      "Parag Jain",
      "Andreea Marzoca",
      "Francesco Piccinno"
    ],
    "abstract": "We consider the task of generating structured representations of text using\nlarge language models (LLMs). We focus on tables and mind maps as\nrepresentative modalities. Tables are more organized way of representing data,\nwhile mind maps provide a visually dynamic and flexible approach, particularly\nsuitable for sparse content. Despite the effectiveness of LLMs on different\ntasks, we show that current models struggle with generating structured outputs.\nIn response, we present effective prompting strategies for both of these tasks.\nWe introduce a taxonomy of problems around factuality, global and local\nstructure, common to both modalities and propose a set of critiques to tackle\nthese issues resulting in an absolute improvement in accuracy of +37pp (79%)\nfor mind maps and +15pp (78%) for tables. To evaluate semantic coverage of\ngenerated structured representations we propose Auto-QA, and we verify the\nadequacy of Auto-QA using SQuAD dataset. We further evaluate the usefulness of\nstructured representations via a text comprehension user study. The results\nshow a significant reduction in comprehension time compared to text when using\ntable (42.9%) and mind map (31.9%), without loss in accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "camera ready",
    "pdf_url": "http://arxiv.org/pdf/2401.06837v2",
    "published_date": "2024-01-12 17:43:51 UTC",
    "updated_date": "2024-06-19 09:59:51 UTC"
  },
  {
    "arxiv_id": "2401.08683v1",
    "title": "Zero-Shot RTL Code Generation with Attention Sink Augmented Large Language Models",
    "authors": [
      "Selim Sandal",
      "Ismail Akturk"
    ],
    "abstract": "The design and optimization of hardware have traditionally been\nresource-intensive, demanding considerable expertise and dependence on\nestablished design automation tools. This paper discusses the possibility of\nexploiting large language models to streamline the code generation process in\nhardware design. In contrast to earlier studies, this paper aims to use large\nlanguage models that accepts high-level design specifications through a single\nprompt to generate corresponding Register-Transfer Level (RTL) code. The\nability to use large language models on RTL code generation not only expedites\ndesign iteration cycles but also facilitates the exploration of design spaces\nthat have computational challenges for conventional techniques. Through our\nevaluation, we demonstrate the shortcoming of existing attention mechanisms,\nand present the abilities of language models to produce functional, optimized,\nand industry-standard compliant RTL code when a novel attention mechanism is\nused. These findings underscore the expanding role of large language models in\nshaping the future landscape of architectural exploration and automation in\nhardware design.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.08683v1",
    "published_date": "2024-01-12 17:41:38 UTC",
    "updated_date": "2024-01-12 17:41:38 UTC"
  },
  {
    "arxiv_id": "2401.06715v1",
    "title": "Reframing Tax Law Entailment as Analogical Reasoning",
    "authors": [
      "Xinrui Zou",
      "Ming Zhang",
      "Nathaniel Weir",
      "Benjamin Van Durme",
      "Nils Holzenberger"
    ],
    "abstract": "Statutory reasoning refers to the application of legislative provisions to a\nseries of case facts described in natural language. We re-frame statutory\nreasoning as an analogy task, where each instance of the analogy task involves\na combination of two instances of statutory reasoning. This increases the\ndataset size by two orders of magnitude, and introduces an element of\ninterpretability. We show that this task is roughly as difficult to Natural\nLanguage Processing models as the original task. Finally, we come back to\nstatutory reasoning, solving it with a combination of a retrieval mechanism and\nanalogy models, and showing some progress on prior comparable work.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06715v1",
    "published_date": "2024-01-12 17:37:07 UTC",
    "updated_date": "2024-01-12 17:37:07 UTC"
  },
  {
    "arxiv_id": "2401.06709v1",
    "title": "Reliability Analysis of Psychological Concept Extraction and Classification in User-penned Text",
    "authors": [
      "Muskan Garg",
      "MSVPJ Sathvik",
      "Amrit Chadha",
      "Shaina Raza",
      "Sunghwan Sohn"
    ],
    "abstract": "The social NLP research community witness a recent surge in the computational\nadvancements of mental health analysis to build responsible AI models for a\ncomplex interplay between language use and self-perception. Such responsible AI\nmodels aid in quantifying the psychological concepts from user-penned texts on\nsocial media. On thinking beyond the low-level (classification) task, we\nadvance the existing binary classification dataset, towards a higher-level task\nof reliability analysis through the lens of explanations, posing it as one of\nthe safety measures. We annotate the LoST dataset to capture nuanced textual\ncues that suggest the presence of low self-esteem in the posts of Reddit users.\nWe further state that the NLP models developed for determining the presence of\nlow self-esteem, focus more on three types of textual cues: (i) Trigger: words\nthat triggers mental disturbance, (ii) LoST indicators: text indicators\nemphasizing low self-esteem, and (iii) Consequences: words describing the\nconsequences of mental disturbance. We implement existing classifiers to\nexamine the attention mechanism in pre-trained language models (PLMs) for a\ndomain-specific psychology-grounded task. Our findings suggest the need of\nshifting the focus of PLMs from Trigger and Consequences to a more\ncomprehensive explanation, emphasizing LoST indicators while determining low\nself-esteem in Reddit posts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06709v1",
    "published_date": "2024-01-12 17:19:14 UTC",
    "updated_date": "2024-01-12 17:19:14 UTC"
  },
  {
    "arxiv_id": "2401.06699v2",
    "title": "A Closed-form Solution for Weight Optimization in Fully-connected Feed-forward Neural Networks",
    "authors": [
      "Slavisa Tomic",
      "João Pedro Matos-Carvalho",
      "Marko Beko"
    ],
    "abstract": "This work addresses weight optimization problem for fully-connected\nfeed-forward neural networks. Unlike existing approaches that are based on\nback-propagation (BP) and chain rule gradient-based optimization (which implies\niterative execution, potentially burdensome and time-consuming in some cases),\nthe proposed approach offers the solution for weight optimization in\nclosed-form by means of least squares (LS) methodology. In the case where the\ninput-to-output mapping is injective, the new approach optimizes the weights in\na back-propagating fashion in a single iteration by jointly optimizing a set of\nweights in each layer for each neuron. In the case where the input-to-output\nmapping is not injective (e.g., in classification problems), the proposed\nsolution is easily adapted to obtain its final solution in a few iterations. An\nimportant advantage over the existing solutions is that these computations (for\nall neurons in a layer) are independent from each other; thus, they can be\ncarried out in parallel to optimize all weights in a given layer\nsimultaneously. Furthermore, its running time is deterministic in the sense\nthat one can obtain the exact number of computations necessary to optimize the\nweights in all network layers (per iteration, in the case of non-injective\nmapping). Our simulation and empirical results show that the proposed scheme,\nBPLS, works well and is competitive with existing ones in terms of accuracy,\nbut significantly surpasses them in terms of running time. To summarize, the\nnew method is straightforward to implement, is competitive and computationally\nmore efficient than the existing ones, and is well-tailored for parallel\nimplementation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06699v2",
    "published_date": "2024-01-12 17:03:55 UTC",
    "updated_date": "2024-06-17 07:16:27 UTC"
  },
  {
    "arxiv_id": "2401.06692v3",
    "title": "An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models",
    "authors": [
      "Gantavya Bhatt",
      "Yifang Chen",
      "Arnav M. Das",
      "Jifan Zhang",
      "Sang T. Truong",
      "Stephen Mussmann",
      "Yinglun Zhu",
      "Jeffrey Bilmes",
      "Simon S. Du",
      "Kevin Jamieson",
      "Jordan T. Ash",
      "Robert D. Nowak"
    ],
    "abstract": "Supervised finetuning (SFT) on instruction datasets has played a crucial role\nin achieving the remarkable zero-shot generalization capabilities observed in\nmodern large language models (LLMs). However, the annotation efforts required\nto produce high quality responses for instructions are becoming prohibitively\nexpensive, especially as the number of tasks spanned by instruction datasets\ncontinues to increase. Active learning is effective in identifying useful\nsubsets of samples to annotate from an unlabeled pool, but its high\ncomputational cost remains a barrier to its widespread applicability in the\ncontext of LLMs. To mitigate the annotation cost of SFT and circumvent the\ncomputational bottlenecks of active learning, we propose using experimental\ndesign. Experimental design techniques select the most informative samples to\nlabel, and typically maximize some notion of uncertainty and/or diversity. In\nour work, we implement a framework that evaluates several existing and novel\nexperimental design techniques and find that these methods consistently yield\nsignificant gains in label efficiency with little computational overhead. On\ngenerative tasks, our methods achieve the same generalization performance with\nonly $50\\%$ of annotation cost required by random sampling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Findings of the Association for Computational\n  Linguistics: ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.06692v3",
    "published_date": "2024-01-12 16:56:54 UTC",
    "updated_date": "2024-07-08 02:52:05 UTC"
  },
  {
    "arxiv_id": "2401.06683v2",
    "title": "DQNC2S: DQN-based Cross-stream Crisis event Summarizer",
    "authors": [
      "Daniele Rege Cambrin",
      "Luca Cagliero",
      "Paolo Garza"
    ],
    "abstract": "Summarizing multiple disaster-relevant data streams simultaneously is\nparticularly challenging as existing Retrieve&Re-ranking strategies suffer from\nthe inherent redundancy of multi-stream data and limited scalability in a\nmulti-query setting. This work proposes an online approach to crisis timeline\ngeneration based on weak annotation with Deep Q-Networks. It selects on-the-fly\nthe relevant pieces of text without requiring neither human annotations nor\ncontent re-ranking. This makes the inference time independent of the number of\ninput queries. The proposed approach also incorporates a redundancy filter into\nthe reward function to effectively handle cross-stream content overlaps. The\nachieved ROUGE and BERTScore results are superior to those of best-performing\nmodels on the CrisisFACTS 2022 benchmark.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "accepted at ECIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.06683v2",
    "published_date": "2024-01-12 16:43:28 UTC",
    "updated_date": "2024-02-02 09:54:18 UTC"
  },
  {
    "arxiv_id": "2401.06836v3",
    "title": "Enhancing Emotional Generation Capability of Large Language Models via Emotional Chain-of-Thought",
    "authors": [
      "Zaijing Li",
      "Gongwei Chen",
      "Rui Shao",
      "Yuquan Xie",
      "Dongmei Jiang",
      "Liqiang Nie"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable performance in various\nemotion recognition tasks, thereby piquing the research community's curiosity\nfor exploring their potential in emotional intelligence. However, several\nissues in the field of emotional generation tasks remain unresolved, including\nhuman preference alignment and emotional generation assessment. In this paper,\nwe propose the Emotional Chain-of-Thought (ECoT), a plug-and-play prompting\nmethod that enhances the performance of LLMs on various emotional generation\ntasks by aligning with human emotional intelligence guidelines. To assess the\nreliability of ECoT, we propose an automated model-based evaluation method\ncalled Emotional Generation Score (EGS). EGS incorporates Goleman's Emotional\nIntelligence Theory as a consensus of human experts, providing a new\nperspective on the evaluation of emotional generation tasks. Extensive\nexperimental results demonstrate the effectiveness of ECoT and EGS. Further, we\ndiscuss the promise of LLMs in the field of emotional intelligence and present\nkey insights into the LLMs with the ECoT in emotional generation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06836v3",
    "published_date": "2024-01-12 16:42:10 UTC",
    "updated_date": "2024-08-07 08:09:53 UTC"
  },
  {
    "arxiv_id": "2401.06676v1",
    "title": "LLMRS: Unlocking Potentials of LLM-Based Recommender Systems for Software Purchase",
    "authors": [
      "Angela John",
      "Theophilus Aidoo",
      "Hamayoon Behmanush",
      "Irem B. Gunduz",
      "Hewan Shrestha",
      "Maxx Richard Rahman",
      "Wolfgang Maaß"
    ],
    "abstract": "Recommendation systems are ubiquitous, from Spotify playlist suggestions to\nAmazon product suggestions. Nevertheless, depending on the methodology or the\ndataset, these systems typically fail to capture user preferences and generate\ngeneral recommendations. Recent advancements in Large Language Models (LLM)\noffer promising results for analyzing user queries. However, employing these\nmodels to capture user preferences and efficiency remains an open question. In\nthis paper, we propose LLMRS, an LLM-based zero-shot recommender system where\nwe employ pre-trained LLM to encode user reviews into a review score and\ngenerate user-tailored recommendations. We experimented with LLMRS on a\nreal-world dataset, the Amazon product reviews, for software purchase use\ncases. The results show that LLMRS outperforms the ranking-based baseline model\nwhile successfully capturing meaningful information from product reviews,\nthereby providing more reliable recommendations.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06676v1",
    "published_date": "2024-01-12 16:33:17 UTC",
    "updated_date": "2024-01-12 16:33:17 UTC"
  },
  {
    "arxiv_id": "2403.07884v1",
    "title": "Seg-metrics: a Python package to compute segmentation metrics",
    "authors": [
      "Jingnan Jia",
      "Marius Staring",
      "Berend C. Stoel"
    ],
    "abstract": "In response to a concerning trend of selectively emphasizing metrics in\nmedical image segmentation (MIS) studies, we introduce \\texttt{seg-metrics}, an\nopen-source Python package for standardized MIS model evaluation. Unlike\nexisting packages, \\texttt{seg-metrics} offers user-friendly interfaces for\nvarious overlap-based and distance-based metrics, providing a comprehensive\nsolution. \\texttt{seg-metrics} supports multiple file formats and is easily\ninstallable through the Python Package Index (PyPI). With a focus on speed and\nconvenience, \\texttt{seg-metrics} stands as a valuable tool for efficient MIS\nmodel assessment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07884v1",
    "published_date": "2024-01-12 16:30:54 UTC",
    "updated_date": "2024-01-12 16:30:54 UTC"
  },
  {
    "arxiv_id": "2401.06373v2",
    "title": "How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs",
    "authors": [
      "Yi Zeng",
      "Hongpeng Lin",
      "Jingwen Zhang",
      "Diyi Yang",
      "Ruoxi Jia",
      "Weiyan Shi"
    ],
    "abstract": "Most traditional AI safety research has approached AI models as machines and\ncentered on algorithm-focused attacks developed by security experts. As large\nlanguage models (LLMs) become increasingly common and competent, non-expert\nusers can also impose risks during daily interactions. This paper introduces a\nnew perspective to jailbreak LLMs as human-like communicators, to explore this\noverlooked intersection between everyday language interaction and AI safety.\nSpecifically, we study how to persuade LLMs to jailbreak them. First, we\npropose a persuasion taxonomy derived from decades of social science research.\nThen, we apply the taxonomy to automatically generate interpretable persuasive\nadversarial prompts (PAP) to jailbreak LLMs. Results show that persuasion\nsignificantly increases the jailbreak performance across all risk categories:\nPAP consistently achieves an attack success rate of over $92\\%$ on Llama 2-7b\nChat, GPT-3.5, and GPT-4 in $10$ trials, surpassing recent algorithm-focused\nattacks. On the defense side, we explore various mechanisms against PAP and,\nfound a significant gap in existing defenses, and advocate for more fundamental\nmitigation for highly interactive LLMs",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages of the main text, qualitative examples of jailbreaks may be\n  harmful in nature",
    "pdf_url": "http://arxiv.org/pdf/2401.06373v2",
    "published_date": "2024-01-12 16:13:24 UTC",
    "updated_date": "2024-01-23 22:46:12 UTC"
  },
  {
    "arxiv_id": "2401.09354v1",
    "title": "Transcending Controlled Environments Assessing the Transferability of ASRRobust NLU Models to Real-World Applications",
    "authors": [
      "Hania Khan",
      "Aleena Fatima Khalid",
      "Zaryab Hassan"
    ],
    "abstract": "This research investigates the transferability of Automatic Speech\nRecognition (ASR)-robust Natural Language Understanding (NLU) models from\ncontrolled experimental conditions to practical, real-world applications.\nFocused on smart home automation commands in Urdu, the study assesses model\nperformance under diverse noise profiles, linguistic variations, and ASR error\nscenarios. Leveraging the UrduBERT model, the research employs a systematic\nmethodology involving real-world data collection, cross-validation, transfer\nlearning, noise variation studies, and domain adaptation. Evaluation metrics\nencompass task-specific accuracy, latency, user satisfaction, and robustness to\nASR errors. The findings contribute insights into the challenges and\nadaptability of ASR-robust NLU models in transcending controlled environments.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.09354v1",
    "published_date": "2024-01-12 16:10:04 UTC",
    "updated_date": "2024-01-12 16:10:04 UTC"
  },
  {
    "arxiv_id": "2401.06654v1",
    "title": "Decoupling Pixel Flipping and Occlusion Strategy for Consistent XAI Benchmarks",
    "authors": [
      "Stefan Blücher",
      "Johanna Vielhaben",
      "Nils Strodthoff"
    ],
    "abstract": "Feature removal is a central building block for eXplainable AI (XAI), both\nfor occlusion-based explanations (Shapley values) as well as their evaluation\n(pixel flipping, PF). However, occlusion strategies can vary significantly from\nsimple mean replacement up to inpainting with state-of-the-art diffusion\nmodels. This ambiguity limits the usefulness of occlusion-based approaches. For\nexample, PF benchmarks lead to contradicting rankings. This is amplified by\ncompeting PF measures: Features are either removed starting with most\ninfluential first (MIF) or least influential first (LIF). This study proposes\ntwo complementary perspectives to resolve this disagreement problem. Firstly,\nwe address the common criticism of occlusion-based XAI, that artificial samples\nlead to unreliable model evaluations. We propose to measure the reliability by\nthe R(eference)-Out-of-Model-Scope (OMS) score. The R-OMS score enables a\nsystematic comparison of occlusion strategies and resolves the disagreement\nproblem by grouping consistent PF rankings. Secondly, we show that the\ninsightfulness of MIF and LIF is conversely dependent on the R-OMS score. To\nleverage this, we combine the MIF and LIF measures into the symmetric relevance\ngain (SRG) measure. This breaks the inherent connection to the underlying\nocclusion strategy and leads to consistent rankings. This resolves the\ndisagreement problem, which we verify for a set of 40 different occlusion\nstrategies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "28 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.06654v1",
    "published_date": "2024-01-12 16:01:17 UTC",
    "updated_date": "2024-01-12 16:01:17 UTC"
  },
  {
    "arxiv_id": "2401.06640v2",
    "title": "Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently",
    "authors": [
      "Kanishka Misra",
      "Allyson Ettinger",
      "Kyle Mahowald"
    ],
    "abstract": "Recent zero-shot evaluations have highlighted important limitations in the\nabilities of language models (LMs) to perform meaning extraction. However, it\nis now well known that LMs can demonstrate radical improvements in the presence\nof experimental contexts such as in-context examples and instructions. How well\ndoes this translate to previously studied meaning-sensitive tasks? We present a\ncase-study on the extent to which experimental contexts can improve LMs'\nrobustness in performing property inheritance -- predicting semantic properties\nof novel concepts, a task that they have been previously shown to fail on. Upon\ncarefully controlling the nature of the in-context examples and the\ninstructions, our work reveals that they can indeed lead to non-trivial\nproperty inheritance behavior in LMs. However, this ability is inconsistent:\nwith a minimal reformulation of the task, some LMs were found to pick up on\nshallow, non-semantic heuristics from their inputs, suggesting that the\ncomputational principles of semantic property inference are yet to be mastered\nby LMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 (main) camera-ready",
    "pdf_url": "http://arxiv.org/pdf/2401.06640v2",
    "published_date": "2024-01-12 15:40:31 UTC",
    "updated_date": "2024-10-17 00:06:23 UTC"
  },
  {
    "arxiv_id": "2401.06634v1",
    "title": "CCFC: Bridging Federated Clustering and Contrastive Learning",
    "authors": [
      "Jie Yan",
      "Jing Liu",
      "Zhong-Yuan Zhang"
    ],
    "abstract": "Federated clustering, an essential extension of centralized clustering for\nfederated scenarios, enables multiple data-holding clients to collaboratively\ngroup data while keeping their data locally. In centralized scenarios,\nclustering driven by representation learning has made significant advancements\nin handling high-dimensional complex data. However, the combination of\nfederated clustering and representation learning remains underexplored. To\nbridge this, we first tailor a cluster-contrastive model for learning\nclustering-friendly representations. Then, we harness this model as the\nfoundation for proposing a new federated clustering method, named\ncluster-contrastive federated clustering (CCFC). Benefiting from representation\nlearning, the clustering performance of CCFC even double those of the best\nbaseline methods in some cases. Compared to the most related baseline, the\nbenefit results in substantial NMI score improvements of up to 0.4155 on the\nmost conspicuous case. Moreover, CCFC also shows superior performance in\nhandling device failures from a practical viewpoint.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06634v1",
    "published_date": "2024-01-12 15:26:44 UTC",
    "updated_date": "2024-01-12 15:26:44 UTC"
  },
  {
    "arxiv_id": "2401.06633v2",
    "title": "Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential Recommendations",
    "authors": [
      "Lei Li",
      "Jianxun Lian",
      "Xiao Zhou",
      "Xing Xie"
    ],
    "abstract": "Retrieval models aim at selecting a small set of item candidates which match\nthe preference of a given user. They play a vital role in large-scale\nrecommender systems since subsequent models such as rankers highly depend on\nthe quality of item candidates. However, most existing retrieval models employ\na single-round inference paradigm, which may not adequately capture the dynamic\nnature of user preferences and stuck in one area in the item space. In this\npaper, we propose Ada-Retrieval, an adaptive multi-round retrieval paradigm for\nrecommender systems that iteratively refines user representations to better\ncapture potential candidates in the full item space. Ada-Retrieval comprises\ntwo key modules: the item representation adapter and the user representation\nadapter, designed to inject context information into items' and users'\nrepresentations. The framework maintains a model-agnostic design, allowing\nseamless integration with various backbone models such as RNNs or Transformers.\nWe perform experiments on three widely used public datasets, incorporating five\npowerful sequential recommenders as backbone models. Our results demonstrate\nthat Ada-Retrieval significantly enhances the performance of various base\nmodels, with consistent improvements observed across different datasets. Our\ncode and data are publicly available at:\nhttps://github.com/ll0ruc/Ada-Retrieval.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages, Accepted to AAAI2024",
    "pdf_url": "http://arxiv.org/pdf/2401.06633v2",
    "published_date": "2024-01-12 15:26:40 UTC",
    "updated_date": "2024-01-31 11:07:32 UTC"
  },
  {
    "arxiv_id": "2401.06833v1",
    "title": "A hierarchical control framework for autonomous decision-making systems: Integrating HMDP and MPC",
    "authors": [
      "Xue-Fang Wang",
      "Jingjing Jiang",
      "Wen-Hua Chen"
    ],
    "abstract": "This paper proposes a comprehensive hierarchical control framework for\nautonomous decision-making arising in robotics and autonomous systems. In a\ntypical hierarchical control architecture, high-level decision making is often\ncharacterised by discrete state and decision/control sets. However, a rational\ndecision is usually affected by not only the discrete states of the autonomous\nsystem, but also the underlying continuous dynamics even the evolution of its\noperational environment. This paper proposes a holistic and comprehensive\ndesign process and framework for this type of challenging problems, from new\nmodelling and design problem formulation to control design and stability\nanalysis. It addresses the intricate interplay between traditional continuous\nsystems dynamics utilized at the low levels for control design and discrete\nMarkov decision processes (MDP) for facilitating high-level decision making. We\nmodel the decision making system in complex environments as a hybrid system\nconsisting of a controlled MDP and autonomous (i.e. uncontrolled) continuous\ndynamics. Consequently, the new formulation is called as hybrid Markov decision\nprocess (HMDP). The design problem is formulated with a focus on ensuring both\nsafety and optimality while taking into account the influence of both the\ndiscrete and continuous state variables of different levels. With the help of\nthe model predictive control (MPC) concept, a decision maker design scheme is\nproposed for the proposed hybrid decision making model. By carefully designing\nkey ingredients involved in this scheme, it is shown that the recursive\nfeasibility and stability of the proposed autonomous decision making scheme are\nguaranteed. The proposed framework is applied to develop an autonomous lane\nchanging system for intelligent vehicles.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "11 pages, 14 figures, submitted to Automatica",
    "pdf_url": "http://arxiv.org/pdf/2401.06833v1",
    "published_date": "2024-01-12 15:25:51 UTC",
    "updated_date": "2024-01-12 15:25:51 UTC"
  },
  {
    "arxiv_id": "2402.01659v1",
    "title": "Generative Artificial Intelligence in Higher Education: Evidence from an Analysis of Institutional Policies and Guidelines",
    "authors": [
      "Nora McDonald",
      "Aditya Johri",
      "Areej Ali",
      "Aayushi Hingle"
    ],
    "abstract": "The release of ChatGPT in November 2022 prompted a massive uptake of\ngenerative artificial intelligence (GenAI) across higher education institutions\n(HEIs). HEIs scrambled to respond to its use, especially by students, looking\nfirst to regulate it and then arguing for its productive integration within\nteaching and learning. In the year since the release, HEIs have increasingly\nprovided policies and guidelines to direct GenAI. In this paper we examined\ndocuments produced by 116 US universities categorized as high research activity\nor R1 institutions to comprehensively understand GenAI related advice and\nguidance given to institutional stakeholders. Through an extensive analysis, we\nfound the majority of universities (N=73, 63%) encourage the use of GenAI and\nmany provide detailed guidance for its use in the classroom (N=48, 41%). More\nthan half of all institutions provided sample syllabi (N=65, 56%) and half\n(N=58, 50%) provided sample GenAI curriculum and activities that would help\ninstructors integrate and leverage GenAI in their classroom. Notably, most\nguidance for activities focused on writing, whereas code and STEM-related\nactivities were mentioned half the time and vaguely even when they were (N=58,\n50%). Finally, more than one half of institutions talked about the ethics of\nGenAI on a range of topics broadly, including Diversity, Equity and Inclusion\n(DEI) (N=60, 52%). Overall, based on our findings we caution that guidance for\nfaculty can become burdensome as extensive revision of pedagogical approaches\nis often recommended in the policies.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01659v1",
    "published_date": "2024-01-12 14:58:13 UTC",
    "updated_date": "2024-01-12 14:58:13 UTC"
  },
  {
    "arxiv_id": "2401.06595v1",
    "title": "Every Node is Different: Dynamically Fusing Self-Supervised Tasks for Attributed Graph Clustering",
    "authors": [
      "Pengfei Zhu",
      "Qian Wang",
      "Yu Wang",
      "Jialu Li",
      "Qinghua Hu"
    ],
    "abstract": "Attributed graph clustering is an unsupervised task that partitions nodes\ninto different groups. Self-supervised learning (SSL) shows great potential in\nhandling this task, and some recent studies simultaneously learn multiple SSL\ntasks to further boost performance. Currently, different SSL tasks are assigned\nthe same set of weights for all graph nodes. However, we observe that some\ngraph nodes whose neighbors are in different groups require significantly\ndifferent emphases on SSL tasks. In this paper, we propose to dynamically learn\nthe weights of SSL tasks for different nodes and fuse the embeddings learned\nfrom different SSL tasks to boost performance. We design an innovative graph\nclustering approach, namely Dynamically Fusing Self-Supervised Learning\n(DyFSS). Specifically, DyFSS fuses features extracted from diverse SSL tasks\nusing distinct weights derived from a gating network. To effectively learn the\ngating network, we design a dual-level self-supervised strategy that\nincorporates pseudo labels and the graph structure. Extensive experiments on\nfive datasets show that DyFSS outperforms the state-of-the-art multi-task SSL\nmethods by up to 8.66% on the accuracy metric. The code of DyFSS is available\nat: https://github.com/q086/DyFSS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06595v1",
    "published_date": "2024-01-12 14:24:10 UTC",
    "updated_date": "2024-01-12 14:24:10 UTC"
  },
  {
    "arxiv_id": "2401.06588v1",
    "title": "Dynamic Behaviour of Connectionist Speech Recognition with Strong Latency Constraints",
    "authors": [
      "Giampiero Salvi"
    ],
    "abstract": "This paper describes the use of connectionist techniques in phonetic speech\nrecognition with strong latency constraints. The constraints are imposed by the\ntask of deriving the lip movements of a synthetic face in real time from the\nspeech signal, by feeding the phonetic string into an articulatory synthesiser.\nParticular attention has been paid to analysing the interaction between the\ntime evolution model learnt by the multi-layer perceptrons and the transition\nmodel imposed by the Viterbi decoder, in different latency conditions. Two\nexperiments were conducted in which the time dependencies in the language model\n(LM) were controlled by a parameter. The results show a strong interaction\nbetween the three factors involved, namely the neural network topology, the\nlength of time dependencies in the LM and the decoder latency.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SD",
      "I.5.0; I.2.7; E.4"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06588v1",
    "published_date": "2024-01-12 14:10:28 UTC",
    "updated_date": "2024-01-12 14:10:28 UTC"
  },
  {
    "arxiv_id": "2401.06583v1",
    "title": "Mapping Transformer Leveraged Embeddings for Cross-Lingual Document Representation",
    "authors": [
      "Tsegaye Misikir Tashu",
      "Eduard-Raul Kontos",
      "Matthia Sabatelli",
      "Matias Valdenegro-Toro"
    ],
    "abstract": "Recommendation systems, for documents, have become tools to find relevant\ncontent on the Web. However, these systems have limitations when it comes to\nrecommending documents in languages different from the query language, which\nmeans they might overlook resources in non-native languages. This research\nfocuses on representing documents across languages by using Transformer\nLeveraged Document Representations (TLDRs) that are mapped to a cross-lingual\ndomain. Four multilingual pre-trained transformer models (mBERT, mT5 XLM\nRoBERTa, ErnieM) were evaluated using three mapping methods across 20 language\npairs representing combinations of five selected languages of the European\nUnion. Metrics like Mate Retrieval Rate and Reciprocal Rank were used to\nmeasure the effectiveness of mapped TLDRs compared to non-mapped ones. The\nresults highlight the power of cross-lingual representations achieved through\npre-trained transformers and mapping approaches suggesting a promising\ndirection for expanding beyond language connections, between two specific\nlanguages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06583v1",
    "published_date": "2024-01-12 14:01:15 UTC",
    "updated_date": "2024-01-12 14:01:15 UTC"
  },
  {
    "arxiv_id": "2401.10280v1",
    "title": "GANs for EVT Based Model Parameter Estimation in Real-time Ultra-Reliable Communication",
    "authors": [
      "Parmida Valiahdi",
      "Sinem Coleri"
    ],
    "abstract": "The Ultra-Reliable Low-Latency Communications (URLLC) paradigm in\nsixth-generation (6G) systems heavily relies on precise channel modeling,\nespecially when dealing with rare and extreme events within wireless\ncommunication channels. This paper explores a novel methodology integrating\nExtreme Value Theory (EVT) and Generative Adversarial Networks (GANs) to\nachieve the precise channel modeling in real-time. The proposed approach\nharnesses EVT by employing the Generalized Pareto Distribution (GPD) to model\nthe distribution of extreme events. Subsequently, Generative Adversarial\nNetworks (GANs) are employed to estimate the parameters of the GPD. In contrast\nto conventional GAN configurations that focus on estimating the overall\ndistribution, the proposed approach involves the incorporation of an additional\nblock within the GAN structure. This specific augmentation is designed with the\nexplicit purpose of directly estimating the parameters of the Generalized\nPareto Distribution (GPD). Through extensive simulations across different\nsample sizes, the proposed GAN based approach consistently demonstrates\nsuperior adaptability, surpassing Maximum Likelihood Estimation (MLE),\nparticularly in scenarios with limited sample sizes.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.10280v1",
    "published_date": "2024-01-12 13:34:34 UTC",
    "updated_date": "2024-01-12 13:34:34 UTC"
  },
  {
    "arxiv_id": "2401.06568v2",
    "title": "Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation",
    "authors": [
      "Xu Huang",
      "Zhirui Zhang",
      "Xiang Geng",
      "Yichao Du",
      "Jiajun Chen",
      "Shujian Huang"
    ],
    "abstract": "This study investigates how Large Language Models (LLMs) leverage source and\nreference data in machine translation evaluation task, aiming to better\nunderstand the mechanisms behind their remarkable performance in this task. We\ndesign the controlled experiments across various input modes and model types,\nand employ both coarse-grained and fine-grained prompts to discern the utility\nof source versus reference information. We find that reference information\nsignificantly enhances the evaluation accuracy, while surprisingly, source\ninformation sometimes is counterproductive, indicating LLMs' inability to fully\nleverage the cross-lingual capability when evaluating translations. Further\nanalysis of the fine-grained evaluation and fine-tuning experiments show\nsimilar results. These findings also suggest a potential research direction for\nLLMs that fully exploits the cross-lingual capability of LLMs to achieve better\nperformance in machine translation evaluation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2401.06568v2",
    "published_date": "2024-01-12 13:23:21 UTC",
    "updated_date": "2024-06-06 07:51:16 UTC"
  },
  {
    "arxiv_id": "2401.06559v1",
    "title": "A General Benchmark Framework is Dynamic Graph Neural Network Need",
    "authors": [
      "Yusen Zhang"
    ],
    "abstract": "Dynamic graph learning is crucial for modeling real-world systems with\nevolving relationships and temporal dynamics. However, the lack of a unified\nbenchmark framework in current research has led to inaccurate evaluations of\ndynamic graph models. This paper highlights the significance of dynamic graph\nlearning and its applications in various domains. It emphasizes the need for a\nstandardized benchmark framework that captures temporal dynamics, evolving\ngraph structures, and downstream task requirements. Establishing a unified\nbenchmark will help researchers understand the strengths and limitations of\nexisting models, foster innovation, and advance dynamic graph learning. In\nconclusion, this paper identifies the lack of a standardized benchmark\nframework as a current limitation in dynamic graph learning research . Such a\nframework will facilitate accurate model evaluation, drive advancements in\ndynamic graph learning techniques, and enable the development of more effective\nmodels for real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06559v1",
    "published_date": "2024-01-12 13:12:07 UTC",
    "updated_date": "2024-01-12 13:12:07 UTC"
  },
  {
    "arxiv_id": "2401.06557v1",
    "title": "Treatment-Aware Hyperbolic Representation Learning for Causal Effect Estimation with Social Networks",
    "authors": [
      "Ziqiang Cui",
      "Xing Tang",
      "Yang Qiao",
      "Bowei He",
      "Liang Chen",
      "Xiuqiang He",
      "Chen Ma"
    ],
    "abstract": "Estimating the individual treatment effect (ITE) from observational data is a\ncrucial research topic that holds significant value across multiple domains.\nHow to identify hidden confounders poses a key challenge in ITE estimation.\nRecent studies have incorporated the structural information of social networks\nto tackle this challenge, achieving notable advancements. However, these\nmethods utilize graph neural networks to learn the representation of hidden\nconfounders in Euclidean space, disregarding two critical issues: (1) the\nsocial networks often exhibit a scalefree structure, while Euclidean embeddings\nsuffer from high distortion when used to embed such graphs, and (2) each\nego-centric network within a social network manifests a treatment-related\ncharacteristic, implying significant patterns of hidden confounders. To address\nthese issues, we propose a novel method called Treatment-Aware Hyperbolic\nRepresentation Learning (TAHyper). Firstly, TAHyper employs the hyperbolic\nspace to encode the social networks, thereby effectively reducing the\ndistortion of confounder representation caused by Euclidean embeddings.\nSecondly, we design a treatment-aware relationship identification module that\nenhances the representation of hidden confounders by identifying whether an\nindividual and her neighbors receive the same treatment. Extensive experiments\non two benchmark datasets are conducted to demonstrate the superiority of our\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by SIAM SDM'24",
    "pdf_url": "http://arxiv.org/pdf/2401.06557v1",
    "published_date": "2024-01-12 13:02:39 UTC",
    "updated_date": "2024-01-12 13:02:39 UTC"
  },
  {
    "arxiv_id": "2401.06550v3",
    "title": "Multimodal Urban Areas of Interest Generation via Remote Sensing Imagery and Geographical Prior",
    "authors": [
      "Chuanji Shi",
      "Yingying Zhang",
      "Jiaotuan Wang",
      "Xin Guo",
      "Qiqi Zhu"
    ],
    "abstract": "Urban area-of-interest (AOI) refers to an integrated urban functional zone\nwith defined polygonal boundaries. The rapid development of urban commerce has\nled to increasing demands for highly accurate and timely AOI data. However,\nexisting research primarily focuses on coarse-grained functional zones for\nurban planning or regional economic analysis, and often neglects the expiration\nof AOI in the real world. They fail to fulfill the precision demands of Mobile\nInternet Online-to-Offline (O2O) businesses. These businesses require accuracy\ndown to a specific community, school, or hospital. In this paper, we propose a\ncomprehensive end-to-end multimodal deep learning framework designed for\nsimultaneously detecting accurate AOI boundaries and validating the reliability\nof AOI by leveraging remote sensing imagery coupled with geographical prior,\ntitled AOITR. Unlike conventional AOI generation methods, such as the Road-cut\nmethod that segments road networks at various levels, our approach diverges\nfrom semantic segmentation algorithms that depend on pixel-level\nclassification. Instead, our AOITR begins by selecting a point-of-interest\n(POI) of specific category, and uses it to retrieve corresponding remote\nsensing imagery and geographical prior such as entrance POIs and road nodes.\nThis information helps to build a multimodal detection model based on\ntransformer encoder-decoder architecture to regress the AOI polygon.\nAdditionally, we utilize the dynamic features from human mobility, nearby POIs,\nand logistics addresses for AOI reliability evaluation via a cascaded network\nmodule. The experimental results reveal that our algorithm achieves a\nsignificant improvement on Intersection over Union (IoU) metric, surpassing\nprevious methods by a large margin.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T99",
      "I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.06550v3",
    "published_date": "2024-01-12 12:54:30 UTC",
    "updated_date": "2024-02-08 06:23:42 UTC"
  },
  {
    "arxiv_id": "2401.10279v1",
    "title": "A systematic review of geospatial location embedding approaches in large language models: A path to spatial AI systems",
    "authors": [
      "Sean Tucker"
    ],
    "abstract": "Geospatial Location Embedding (GLE) helps a Large Language Model (LLM)\nassimilate and analyze spatial data. GLE emergence in Geospatial Artificial\nIntelligence (GeoAI) is precipitated by the need for deeper geospatial\nawareness in our complex contemporary spaces and the success of LLMs in\nextracting deep meaning in Generative AI. We searched Google Scholar, Science\nDirect, and arXiv for papers on geospatial location embedding and LLM and\nreviewed articles focused on gaining deeper spatial \"knowing\" through LLMs. We\nscreened 304 titles, 30 abstracts, and 18 full-text papers that reveal four GLE\nthemes - Entity Location Embedding (ELE), Document Location Embedding (DLE),\nSequence Location Embedding (SLE), and Token Location Embedding (TLE).\nSynthesis is tabular and narrative, including a dialogic conversation between\n\"Space\" and \"LLM.\" Though GLEs aid spatial understanding by superimposing\nspatial data, they emphasize the need to advance in the intricacies of spatial\nmodalities and generalized reasoning. GLEs signal the need for a Spatial\nFoundation/Language Model (SLM) that embeds spatial knowing within the model\narchitecture. The SLM framework advances Spatial Artificial Intelligence\nSystems (SPAIS), establishing a Spatial Vector Space (SVS) that maps to\nphysical space. The resulting spatially imbued Language Model is unique. It\nsimultaneously represents actual space and an AI-capable space, paving the way\nfor AI native geo storage, analysis, and multi-modality as the basis for\nSpatial Artificial Intelligence Systems (SPAIS).",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "20 pages, 11 figures, 3 appendices",
    "pdf_url": "http://arxiv.org/pdf/2401.10279v1",
    "published_date": "2024-01-12 12:43:33 UTC",
    "updated_date": "2024-01-12 12:43:33 UTC"
  },
  {
    "arxiv_id": "2401.06541v1",
    "title": "Medical Dialogue Generation via Intuitive-then-Analytical Differential Diagnosis",
    "authors": [
      "Kaishuai Xu",
      "Wenjun Hou",
      "Yi Cheng",
      "Jian Wang",
      "Wenjie Li"
    ],
    "abstract": "Medical dialogue systems have attracted growing research attention as they\nhave the potential to provide rapid diagnoses, treatment plans, and health\nconsultations. In medical dialogues, a proper diagnosis is crucial as it\nestablishes the foundation for future consultations. Clinicians typically\nemploy both intuitive and analytic reasoning to formulate a differential\ndiagnosis. This reasoning process hypothesizes and verifies a variety of\npossible diseases and strives to generate a comprehensive and rigorous\ndiagnosis. However, recent studies on medical dialogue generation have\noverlooked the significance of modeling a differential diagnosis, which hinders\nthe practical application of these systems. To address the above issue, we\npropose a medical dialogue generation framework with the\nIntuitive-then-Analytic Differential Diagnosis (IADDx). Our method starts with\na differential diagnosis via retrieval-based intuitive association and\nsubsequently refines it through a graph-enhanced analytic procedure. The\nresulting differential diagnosis is then used to retrieve medical knowledge and\nguide response generation. Experimental results on two datasets validate the\nefficacy of our method. Besides, we demonstrate how our framework assists both\nclinicians and patients in understanding the diagnostic process, for instance,\nby producing intermediate results and graph-based diagnosis paths.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2401.06541v1",
    "published_date": "2024-01-12 12:35:19 UTC",
    "updated_date": "2024-01-12 12:35:19 UTC"
  },
  {
    "arxiv_id": "2401.06538v1",
    "title": "Intelligent Data-Driven Architectural Features Orchestration for Network Slicing",
    "authors": [
      "Rodrigo Moreira",
      "Flavio de Oliveira Silva",
      "Tereza Cristina Melo de Brito Carvalho",
      "Joberto S. B. Martins"
    ],
    "abstract": "Network slicing is a crucial enabler and a trend for the Next Generation\nMobile Network (NGMN) and various other new systems like the Internet of\nVehicles (IoV) and Industrial IoT (IIoT). Orchestration and machine learning\nare key elements with a crucial role in the network-slicing processes since the\nNS process needs to orchestrate resources and functionalities, and machine\nlearning can potentially optimize the orchestration process. However, existing\nnetwork-slicing architectures lack the ability to define intelligent approaches\nto orchestrate features and resources in the slicing process. This paper\ndiscusses machine learning-based orchestration of features and capabilities in\nnetwork slicing architectures. Initially, the slice resource orchestration and\nallocation in the slicing planning, configuration, commissioning, and operation\nphases are analyzed. In sequence, we highlight the need for optimized\narchitectural feature orchestration and recommend using ML-embed agents,\nfederated learning intrinsic mechanisms for knowledge acquisition, and a\ndata-driven approach embedded in the network slicing architecture. We further\ndevelop an architectural features orchestration case embedded in the SFI2\nnetwork slicing architecture. An attack prevention security mechanism is\ndeveloped for the SFI2 architecture using distributed embedded and cooperating\nML agents. The case presented illustrates the architectural feature's\norchestration process and benefits, highlighting its importance for the network\nslicing process.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "I.2.11; C.2.1; I.2.1"
    ],
    "primary_category": "cs.NI",
    "comment": "12 pages, 6 figures, Conference ADVANCE 24 - International Workshop\n  on ADVANCEs in ICT Infrastructures and Services - February 26--29, 2024 -\n  Hanoi, Vietnam",
    "pdf_url": "http://arxiv.org/pdf/2401.06538v1",
    "published_date": "2024-01-12 12:32:36 UTC",
    "updated_date": "2024-01-12 12:32:36 UTC"
  },
  {
    "arxiv_id": "2401.06528v1",
    "title": "PCB-Vision: A Multiscene RGB-Hyperspectral Benchmark Dataset of Printed Circuit Boards",
    "authors": [
      "Elias Arbash",
      "Margret Fuchs",
      "Behnood Rasti",
      "Sandra Lorenz",
      "Pedram Ghamisi",
      "Richard Gloaguen"
    ],
    "abstract": "Addressing the critical theme of recycling electronic waste (E-waste), this\ncontribution is dedicated to developing advanced automated data processing\npipelines as a basis for decision-making and process control. Aligning with the\nbroader goals of the circular economy and the United Nations (UN) Sustainable\nDevelopment Goals (SDG), our work leverages non-invasive analysis methods\nutilizing RGB and hyperspectral imaging data to provide both quantitative and\nqualitative insights into the E-waste stream composition for optimizing\nrecycling efficiency. In this paper, we introduce 'PCB-Vision'; a pioneering\nRGB-hyperspectral printed circuit board (PCB) benchmark dataset, comprising 53\nRGB images of high spatial resolution paired with their corresponding high\nspectral resolution hyperspectral data cubes in the visible and near-infrared\n(VNIR) range. Grounded in open science principles, our dataset provides a\ncomprehensive resource for researchers through high-quality ground truths,\nfocusing on three primary PCB components: integrated circuits (IC), capacitors,\nand connectors. We provide extensive statistical investigations on the proposed\ndataset together with the performance of several state-of-the-art (SOTA)\nmodels, including U-Net, Attention U-Net, Residual U-Net, LinkNet, and\nDeepLabv3+. By openly sharing this multi-scene benchmark dataset along with the\nbaseline codes, we hope to foster transparent, traceable, and comparable\ndevelopments of advanced data processing across various scientific communities,\nincluding, but not limited to, computer vision and remote sensing. Emphasizing\nour commitment to supporting a collaborative and inclusive scientific\ncommunity, all materials, including code, data, ground truth, and masks, will\nbe accessible at https://github.com/hifexplo/PCBVision.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06528v1",
    "published_date": "2024-01-12 12:00:26 UTC",
    "updated_date": "2024-01-12 12:00:26 UTC"
  },
  {
    "arxiv_id": "2401.06513v1",
    "title": "ML-On-Rails: Safeguarding Machine Learning Models in Software Systems A Case Study",
    "authors": [
      "Hala Abdelkader",
      "Mohamed Abdelrazek",
      "Scott Barnett",
      "Jean-Guy Schneider",
      "Priya Rani",
      "Rajesh Vasa"
    ],
    "abstract": "Machine learning (ML), especially with the emergence of large language models\n(LLMs), has significantly transformed various industries. However, the\ntransition from ML model prototyping to production use within software systems\npresents several challenges. These challenges primarily revolve around ensuring\nsafety, security, and transparency, subsequently influencing the overall\nrobustness and trustworthiness of ML models. In this paper, we introduce\nML-On-Rails, a protocol designed to safeguard ML models, establish a\nwell-defined endpoint interface for different ML tasks, and clear communication\nbetween ML providers and ML consumers (software engineers). ML-On-Rails\nenhances the robustness of ML models via incorporating detection capabilities\nto identify unique challenges specific to production ML. We evaluated the\nML-On-Rails protocol through a real-world case study of the MoveReminder\napplication. Through this evaluation, we emphasize the importance of\nsafeguarding ML models in production.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06513v1",
    "published_date": "2024-01-12 11:27:15 UTC",
    "updated_date": "2024-01-12 11:27:15 UTC"
  },
  {
    "arxiv_id": "2401.09473v1",
    "title": "Business and ethical concerns in domestic Conversational Generative AI-empowered multi-robot systems",
    "authors": [
      "Rebekah Rousi",
      "Hooman Samani",
      "Niko Mäkitalo",
      "Ville Vakkuri",
      "Simo Linkola",
      "Kai-Kristian Kemell",
      "Paulius Daubaris",
      "Ilenia Fronza",
      "Tommi Mikkonen",
      "Pekka Abrahamsson"
    ],
    "abstract": "Business and technology are intricately connected through logic and design.\nThey are equally sensitive to societal changes and may be devastated by\nscandal. Cooperative multi-robot systems (MRSs) are on the rise, allowing\nrobots of different types and brands to work together in diverse contexts.\nGenerative artificial intelligence has been a dominant topic in recent\nartificial intelligence (AI) discussions due to its capacity to mimic humans\nthrough the use of natural language and the production of media, including deep\nfakes. In this article, we focus specifically on the conversational aspects of\ngenerative AI, and hence use the term Conversational Generative artificial\nintelligence (CGI). Like MRSs, CGIs have enormous potential for revolutionizing\nprocesses across sectors and transforming the way humans conduct business. From\na business perspective, cooperative MRSs alone, with potential conflicts of\ninterest, privacy practices, and safety concerns, require ethical examination.\nMRSs empowered by CGIs demand multi-dimensional and sophisticated methods to\nuncover imminent ethical pitfalls. This study focuses on ethics in\nCGI-empowered MRSs while reporting the stages of developing the MORUL model.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "15 pages, 4 figures, International Conference on Software Business",
    "pdf_url": "http://arxiv.org/pdf/2401.09473v1",
    "published_date": "2024-01-12 11:05:32 UTC",
    "updated_date": "2024-01-12 11:05:32 UTC"
  },
  {
    "arxiv_id": "2401.06506v3",
    "title": "Frequency Masking for Universal Deepfake Detection",
    "authors": [
      "Chandler Timm Doloriel",
      "Ngai-Man Cheung"
    ],
    "abstract": "We study universal deepfake detection. Our goal is to detect synthetic images\nfrom a range of generative AI approaches, particularly from emerging ones which\nare unseen during training of the deepfake detector. Universal deepfake\ndetection requires outstanding generalization capability. Motivated by recently\nproposed masked image modeling which has demonstrated excellent generalization\nin self-supervised pre-training, we make the first attempt to explore masked\nimage modeling for universal deepfake detection. We study spatial and frequency\ndomain masking in training deepfake detectors. Based on empirical analysis, we\npropose a novel deepfake detector via frequency masking. Our focus on frequency\ndomain is different from the majority, which primarily target spatial domain\ndetection. Our comparative analyses reveal substantial performance gains over\nexisting methods. Code and models are publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IEEE ICASSP-2024",
    "pdf_url": "http://arxiv.org/pdf/2401.06506v3",
    "published_date": "2024-01-12 11:02:12 UTC",
    "updated_date": "2024-01-17 07:44:50 UTC"
  },
  {
    "arxiv_id": "2401.06503v1",
    "title": "Improving the Detection of Small Oriented Objects in Aerial Images",
    "authors": [
      "Chandler Timm C. Doloriel",
      "Rhandley D. Cajote"
    ],
    "abstract": "Small oriented objects that represent tiny pixel-area in large-scale aerial\nimages are difficult to detect due to their size and orientation. Existing\noriented aerial detectors have shown promising results but are mainly focused\non orientation modeling with less regard to the size of the objects. In this\nwork, we proposed a method to accurately detect small oriented objects in\naerial images by enhancing the classification and regression tasks of the\noriented object detection model. We designed the Attention-Points Network\nconsisting of two losses: Guided-Attention Loss (GALoss) and Box-Points Loss\n(BPLoss). GALoss uses an instance segmentation mask as ground-truth to learn\nthe attention features needed to improve the detection of small objects. These\nattention features are then used to predict box points for BPLoss, which\ndetermines the points' position relative to the target oriented bounding box.\nExperimental results show the effectiveness of our Attention-Points Network on\na standard oriented aerial dataset with small object instances (DOTA-v1.5) and\non a maritime-related dataset (HRSC2016). The code is publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "C. T. C. Doloriel and R. D. Cajote, \"Improving the Detection of Small\n  Oriented Objects in Aerial Images,\" 2023 IEEE/CVF Winter Conference on\n  Applications of Computer Vision Workshops (WACVW), Waikoloa, HI, USA, 2023,\n  pp. 176-185, doi: 10.1109/WACVW58289.2023.00023",
    "pdf_url": "http://arxiv.org/pdf/2401.06503v1",
    "published_date": "2024-01-12 11:00:07 UTC",
    "updated_date": "2024-01-12 11:00:07 UTC"
  },
  {
    "arxiv_id": "2401.12803v1",
    "title": "Enhancements for 5G NR PRACH Reception: An AI/ML Approach",
    "authors": [
      "Rohit Singh",
      "Anil Kumar Yerrapragada",
      "Jeeva Keshav S",
      "Radha Krishna Ganti"
    ],
    "abstract": "Random Access is an important step in enabling the initial attachment of a\nUser Equipment (UE) to a Base Station (gNB). The UE identifies itself by\nembedding a Preamble Index (RAPID) in the phase rotation of a known base\nsequence, which it transmits on the Physical Random Access Channel (PRACH). The\nsignal on the PRACH also enables the estimation of propagation delay, often\nknown as Timing Advance (TA), which is induced by virtue of the UE's position.\nTraditional receivers estimate the RAPID and TA using correlation-based\ntechniques. This paper presents an alternative receiver approach that uses\nAI/ML models, wherein two neural networks are proposed, one for the RAPID and\none for the TA. Different from other works, these two models can run in\nparallel as opposed to sequentially. Experiments with both simulated data and\nover-the-air hardware captures highlight the improved performance of the\nproposed AI/ML-based techniques compared to conventional correlation methods.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12803v1",
    "published_date": "2024-01-12 10:44:23 UTC",
    "updated_date": "2024-01-12 10:44:23 UTC"
  },
  {
    "arxiv_id": "2401.06493v2",
    "title": "Expected Shapley-Like Scores of Boolean Functions: Complexity and Applications to Probabilistic Databases",
    "authors": [
      "Pratik Karmakar",
      "Mikaël Monet",
      "Pierre Senellart",
      "Stéphane Bressan"
    ],
    "abstract": "Shapley values, originating in game theory and increasingly prominent in\nexplainable AI, have been proposed to assess the contribution of facts in query\nanswering over databases, along with other similar power indices such as\nBanzhaf values. In this work we adapt these Shapley-like scores to\nprobabilistic settings, the objective being to compute their expected value. We\nshow that the computations of expected Shapley values and of the expected\nvalues of Boolean functions are interreducible in polynomial time, thus\nobtaining the same tractability landscape. We investigate the specific\ntractable case where Boolean functions are represented as deterministic\ndecomposable circuits, designing a polynomial-time algorithm for this setting.\nWe present applications to probabilistic databases through database provenance,\nand an effective implementation of this algorithm within the ProvSQL system,\nwhich experimentally validates its feasibility over a standard benchmark.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.DB",
    "comment": "27 pages, including 20 pages of maintext. This is the authors'\n  version of the corresponding PODS'2024 article",
    "pdf_url": "http://arxiv.org/pdf/2401.06493v2",
    "published_date": "2024-01-12 10:34:31 UTC",
    "updated_date": "2024-04-16 12:16:02 UTC"
  },
  {
    "arxiv_id": "2401.06831v1",
    "title": "A Survey on the Applications of Frontier AI, Foundation Models, and Large Language Models to Intelligent Transportation Systems",
    "authors": [
      "Mohamed R. Shoaib",
      "Heba M. Emara",
      "Jun Zhao"
    ],
    "abstract": "This survey paper explores the transformative influence of frontier AI,\nfoundation models, and Large Language Models (LLMs) in the realm of Intelligent\nTransportation Systems (ITS), emphasizing their integral role in advancing\ntransportation intelligence, optimizing traffic management, and contributing to\nthe realization of smart cities. Frontier AI refers to the forefront of AI\ntechnology, encompassing the latest advancements, innovations, and experimental\ntechniques in the field, especially AI foundation models and LLMs. Foundation\nmodels, like GPT-4, are large, general-purpose AI models that provide a base\nfor a wide range of applications. They are characterized by their versatility\nand scalability. LLMs are obtained from finetuning foundation models with a\nspecific focus on processing and generating natural language. They excel in\ntasks like language understanding, text generation, translation, and\nsummarization. By leveraging vast textual data, including traffic reports and\nsocial media interactions, LLMs extract critical insights, fostering the\nevolution of ITS. The survey navigates the dynamic synergy between LLMs and\nITS, delving into applications in traffic management, integration into\nautonomous vehicles, and their role in shaping smart cities. It provides\ninsights into ongoing research, innovations, and emerging trends, aiming to\ninspire collaboration at the intersection of language, intelligence, and\nmobility for safer, more efficient, and sustainable transportation systems. The\npaper further surveys interactions between LLMs and various aspects of ITS,\nexploring roles in traffic management, facilitating autonomous vehicles, and\ncontributing to smart city development, while addressing challenges brought by\nfrontier AI and foundation models. This paper offers valuable inspiration for\nfuture research and innovation in the transformative domain of intelligent\ntransportation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper appears in International Conference on Computer and\n  Applications (ICCA) 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.06831v1",
    "published_date": "2024-01-12 10:29:48 UTC",
    "updated_date": "2024-01-12 10:29:48 UTC"
  },
  {
    "arxiv_id": "2401.06830v1",
    "title": "RecSys Challenge 2023: From data preparation to prediction, a simple, efficient, robust and scalable solution",
    "authors": [
      "Maxime Manderlier",
      "Fabian Lecron"
    ],
    "abstract": "The RecSys Challenge 2023, presented by ShareChat, consists to predict if an\nuser will install an application on his smartphone after having seen\nadvertising impressions in ShareChat & Moj apps. This paper presents the\nsolution of 'Team UMONS' to this challenge, giving accurate results (our best\nscore is 6.622686) with a relatively small model that can be easily implemented\nin different production configurations. Our solution scales well when\nincreasing the dataset size and can be used with datasets containing missing\nvalues.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06830v1",
    "published_date": "2024-01-12 10:14:10 UTC",
    "updated_date": "2024-01-12 10:14:10 UTC"
  },
  {
    "arxiv_id": "2401.06477v4",
    "title": "Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation",
    "authors": [
      "Tianyu Zheng",
      "Shuyue Guo",
      "Xingwei Qu",
      "Jiawei Guo",
      "Xinrun Du",
      "Qi Jia",
      "Chenghua Lin",
      "Wenhao Huang",
      "Jie Fu",
      "Ge Zhang"
    ],
    "abstract": "In this paper, we introduce Kun, a novel approach for creating high-quality\ninstruction-tuning datasets for large language models (LLMs) without relying on\nmanual annotations. Adapting a self-training algorithm based on instruction\nback-translation and answer polishment, Kun leverages unlabelled data from\ndiverse sources such as Wudao, Wanjuan, and SkyPile to generate a substantial\ndataset of over a million Chinese instructional data points. This approach\nsignificantly deviates from traditional methods by using a self-curation\nprocess to refine and select the most effective instruction-output pairs. Our\nexperiments with the 6B-parameter Yi model across various benchmarks\ndemonstrate Kun's robustness and scalability. Our method's core contributions\nlie in its algorithmic advancement, which enhances data retention and clarity,\nand its innovative data generation approach that substantially reduces the\nreliance on costly and time-consuming manual annotations. This methodology\npresents a scalable and efficient solution for improving the\ninstruction-following capabilities of LLMs, with significant implications for\ntheir application across diverse fields. The code and dataset can be found at\nhttps://github.com/Zheng0428/COIG-Kun",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.06477v4",
    "published_date": "2024-01-12 09:56:57 UTC",
    "updated_date": "2024-11-05 16:02:21 UTC"
  },
  {
    "arxiv_id": "2401.06829v1",
    "title": "Cross-Attention Watermarking of Large Language Models",
    "authors": [
      "Folco Bertini Baldassini",
      "Huy H. Nguyen",
      "Ching-Chung Chang",
      "Isao Echizen"
    ],
    "abstract": "A new approach to linguistic watermarking of language models is presented in\nwhich information is imperceptibly inserted into the output text while\npreserving its readability and original meaning. A cross-attention mechanism is\nused to embed watermarks in the text during inference. Two methods using\ncross-attention are presented that minimize the effect of watermarking on the\nperformance of a pretrained model. Exploration of different training strategies\nfor optimizing the watermarking and of the challenges and implications of\napplying this approach in real-world scenarios clarified the tradeoff between\nwatermark robustness and text quality. Watermark selection substantially\naffects the generated output for high entropy sentences. This proactive\nwatermarking approach has potential application in future model development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 3 figures. Accepted to ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.06829v1",
    "published_date": "2024-01-12 09:39:50 UTC",
    "updated_date": "2024-01-12 09:39:50 UTC"
  },
  {
    "arxiv_id": "2401.06471v1",
    "title": "A Brain-inspired Computational Model for Human-like Concept Learning",
    "authors": [
      "Yuwei Wang",
      "Yi Zeng"
    ],
    "abstract": "Concept learning is a fundamental aspect of human cognition and plays a\ncritical role in mental processes such as categorization, reasoning, memory,\nand decision-making. Researchers across various disciplines have shown\nconsistent interest in the process of concept acquisition in individuals. To\nelucidate the mechanisms involved in human concept learning, this study\nexamines the findings from computational neuroscience and cognitive psychology.\nThese findings indicate that the brain's representation of concepts relies on\ntwo essential components: multisensory representation and text-derived\nrepresentation. These two types of representations are coordinated by a\nsemantic control system, ultimately leading to the acquisition of concepts.\nDrawing inspiration from this mechanism, the study develops a human-like\ncomputational model for concept learning based on spiking neural networks. By\neffectively addressing the challenges posed by diverse sources and imbalanced\ndimensionality of the two forms of concept representations, the study\nsuccessfully attains human-like concept representations. Tests involving\nsimilar concepts demonstrate that our model, which mimics the way humans learn\nconcepts, yields representations that closely align with human cognition.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06471v1",
    "published_date": "2024-01-12 09:32:51 UTC",
    "updated_date": "2024-01-12 09:32:51 UTC"
  },
  {
    "arxiv_id": "2401.06466v1",
    "title": "PersianMind: A Cross-Lingual Persian-English Large Language Model",
    "authors": [
      "Pedram Rostami",
      "Ali Salemi",
      "Mohammad Javad Dousti"
    ],
    "abstract": "Large language models demonstrate remarkable proficiency in various\nlinguistic tasks and have extensive knowledge across various domains. Although\nthey perform best in English, their ability in other languages is notable too.\nIn contrast, open-source models, such as LLaMa, are primarily trained on\nEnglish datasets, resulting in poor performance in non-English languages. In\nthis paper, we introduce PersianMind, an open-source bilingual large language\nmodel which demonstrates comparable performance to closed-source GPT-3.5-turbo\nin the Persian language. By expanding LLaMa2's vocabulary with 10,000 Persian\ntokens and training it on a dataset comprising nearly 2 billion Persian tokens,\nwe show that our approach preserves the model's English knowledge and employs\ntransfer learning to excel at transferring task knowledge from one language to\nanother.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06466v1",
    "published_date": "2024-01-12 09:24:10 UTC",
    "updated_date": "2024-01-12 09:24:10 UTC"
  },
  {
    "arxiv_id": "2401.06465v1",
    "title": "Sanity Checks Revisited: An Exploration to Repair the Model Parameter Randomisation Test",
    "authors": [
      "Anna Hedström",
      "Leander Weber",
      "Sebastian Lapuschkin",
      "Marina MC Höhne"
    ],
    "abstract": "The Model Parameter Randomisation Test (MPRT) is widely acknowledged in the\neXplainable Artificial Intelligence (XAI) community for its well-motivated\nevaluative principle: that the explanation function should be sensitive to\nchanges in the parameters of the model function. However, recent works have\nidentified several methodological caveats for the empirical interpretation of\nMPRT. To address these caveats, we introduce two adaptations to the original\nMPRT -- Smooth MPRT and Efficient MPRT, where the former minimises the impact\nthat noise has on the evaluation results through sampling and the latter\ncircumvents the need for biased similarity measurements by re-interpreting the\ntest through the explanation's rise in complexity, after full parameter\nrandomisation. Our experimental results demonstrate that these proposed\nvariants lead to improved metric reliability, thus enabling a more trustworthy\napplication of XAI methods.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 12 figures, NeurIPS XAIA 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.06465v1",
    "published_date": "2024-01-12 09:21:18 UTC",
    "updated_date": "2024-01-12 09:21:18 UTC"
  },
  {
    "arxiv_id": "2401.06461v5",
    "title": "Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers",
    "authors": [
      "Yuling Shi",
      "Hongyu Zhang",
      "Chengcheng Wan",
      "Xiaodong Gu"
    ],
    "abstract": "Large language models have catalyzed an unprecedented wave in code\ngeneration. While achieving significant advances, they blur the distinctions\nbetween machine- and human-authored source code, causing integrity and\nauthenticity issues of software artifacts. Previous methods such as DetectGPT\nhave proven effective in discerning machine-generated texts, but they do not\nidentify and harness the unique patterns of machine-generated code. Thus, its\napplicability falters when applied to code. In this paper, we carefully study\nthe specific patterns that characterize machine- and human-authored code.\nThrough a rigorous analysis of code attributes such as lexical diversity,\nconciseness, and naturalness, we expose unique patterns inherent to each\nsource. We particularly notice that the syntactic segmentation of code is a\ncritical factor in identifying its provenance. Based on our findings, we\npropose DetectCodeGPT, a novel method for detecting machine-generated code,\nwhich improves DetectGPT by capturing the distinct stylized patterns of code.\nDiverging from conventional techniques that depend on external LLMs for\nperturbations, DetectCodeGPT perturbs the code corpus by strategically\ninserting spaces and newlines, ensuring both efficacy and efficiency.\nExperiment results show that our approach significantly outperforms\nstate-of-the-art techniques in detecting machine-generated code.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by the 47th International Conference on Software Engineering\n  (ICSE 2025). Code available at https://github.com/YerbaPage/DetectCodeGPT",
    "pdf_url": "http://arxiv.org/pdf/2401.06461v5",
    "published_date": "2024-01-12 09:15:20 UTC",
    "updated_date": "2024-07-30 09:26:04 UTC"
  },
  {
    "arxiv_id": "2401.06437v1",
    "title": "3D-PreMise: Can Large Language Models Generate 3D Shapes with Sharp Features and Parametric Control?",
    "authors": [
      "Zeqing Yuan",
      "Haoxuan Lan",
      "Qiang Zou",
      "Junbo Zhao"
    ],
    "abstract": "Recent advancements in implicit 3D representations and generative models have\nmarkedly propelled the field of 3D object generation forward. However, it\nremains a significant challenge to accurately model geometries with defined\nsharp features under parametric controls, which is crucial in fields like\nindustrial design and manufacturing. To bridge this gap, we introduce a\nframework that employs Large Language Models (LLMs) to generate text-driven 3D\nshapes, manipulating 3D software via program synthesis. We present 3D-PreMise,\na dataset specifically tailored for 3D parametric modeling of industrial\nshapes, designed to explore state-of-the-art LLMs within our proposed pipeline.\nOur work reveals effective generation strategies and delves into the\nself-correction capabilities of LLMs using a visual interface. Our work\nhighlights both the potential and limitations of LLMs in 3D parametric modeling\nfor industrial applications.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.GR",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.06437v1",
    "published_date": "2024-01-12 08:07:52 UTC",
    "updated_date": "2024-01-12 08:07:52 UTC"
  },
  {
    "arxiv_id": "2401.06436v1",
    "title": "Improving Graph Convolutional Networks with Transformer Layer in social-based items recommendation",
    "authors": [
      "Thi Linh Hoang",
      "Tuan Dung Pham",
      "Viet Cuong Ta"
    ],
    "abstract": "In this work, we have proposed an approach for improving the GCN for\npredicting ratings in social networks. Our model is expanded from the standard\nmodel with several layers of transformer architecture. The main focus of the\npaper is on the encoder architecture for node embedding in the network. Using\nthe embedding layer from the graph-based convolution layer, the attention\nmechanism could rearrange the feature space to get a more efficient embedding\nfor the downstream task. The experiments showed that our proposed architecture\nachieves better performance than GCN on the traditional link prediction task.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06436v1",
    "published_date": "2024-01-12 08:07:09 UTC",
    "updated_date": "2024-01-12 08:07:09 UTC"
  },
  {
    "arxiv_id": "2401.06431v2",
    "title": "Human-AI Collaborative Essay Scoring: A Dual-Process Framework with LLMs",
    "authors": [
      "Changrong Xiao",
      "Wenxing Ma",
      "Qingping Song",
      "Sean Xin Xu",
      "Kunpeng Zhang",
      "Yufang Wang",
      "Qi Fu"
    ],
    "abstract": "Receiving timely and personalized feedback is essential for second-language\nlearners, especially when human instructors are unavailable. This study\nexplores the effectiveness of Large Language Models (LLMs), including both\nproprietary and open-source models, for Automated Essay Scoring (AES). Through\nextensive experiments with public and private datasets, we find that while LLMs\ndo not surpass conventional state-of-the-art (SOTA) grading models in\nperformance, they exhibit notable consistency, generalizability, and\nexplainability. We propose an open-source LLM-based AES system, inspired by the\ndual-process theory. Our system offers accurate grading and high-quality\nfeedback, at least comparable to that of fine-tuned proprietary LLMs, in\naddition to its ability to alleviate misgrading. Furthermore, we conduct\nhuman-AI co-grading experiments with both novice and expert graders. We find\nthat our system not only automates the grading process but also enhances the\nperformance and efficiency of human graders, particularly for essays where the\nmodel has lower confidence. These results highlight the potential of LLMs to\nfacilitate effective human-AI collaboration in the educational context,\npotentially transforming learning experiences through AI-generated feedback.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06431v2",
    "published_date": "2024-01-12 07:50:10 UTC",
    "updated_date": "2024-06-15 03:44:08 UTC"
  },
  {
    "arxiv_id": "2401.06426v1",
    "title": "UPDP: A Unified Progressive Depth Pruner for CNN and Vision Transformer",
    "authors": [
      "Ji Liu",
      "Dehua Tang",
      "Yuanxian Huang",
      "Li Zhang",
      "Xiaocheng Zeng",
      "Dong Li",
      "Mingjie Lu",
      "Jinzhang Peng",
      "Yu Wang",
      "Fan Jiang",
      "Lu Tian",
      "Ashish Sirasao"
    ],
    "abstract": "Traditional channel-wise pruning methods by reducing network channels\nstruggle to effectively prune efficient CNN models with depth-wise\nconvolutional layers and certain efficient modules, such as popular inverted\nresidual blocks. Prior depth pruning methods by reducing network depths are not\nsuitable for pruning some efficient models due to the existence of some\nnormalization layers. Moreover, finetuning subnet by directly removing\nactivation layers would corrupt the original model weights, hindering the\npruned model from achieving high performance. To address these issues, we\npropose a novel depth pruning method for efficient models. Our approach\nproposes a novel block pruning strategy and progressive training method for the\nsubnet. Additionally, we extend our pruning method to vision transformer\nmodels. Experimental results demonstrate that our method consistently\noutperforms existing depth pruning methods across various pruning\nconfigurations. We obtained three pruned ConvNeXtV1 models with our method\napplying on ConvNeXtV1, which surpass most SOTA efficient models with\ncomparable inference performance. Our method also achieves state-of-the-art\npruning performance on the vision transformer model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06426v1",
    "published_date": "2024-01-12 07:43:48 UTC",
    "updated_date": "2024-01-12 07:43:48 UTC"
  },
  {
    "arxiv_id": "2401.06421v1",
    "title": "Uncertainty quantification for probabilistic machine learning in earth observation using conformal prediction",
    "authors": [
      "Geethen Singh",
      "Glenn Moncrieff",
      "Zander Venter",
      "Kerry Cawse-Nicholson",
      "Jasper Slingsby",
      "Tamara B Robinson"
    ],
    "abstract": "Unreliable predictions can occur when using artificial intelligence (AI)\nsystems with negative consequences for downstream applications, particularly\nwhen employed for decision-making. Conformal prediction provides a\nmodel-agnostic framework for uncertainty quantification that can be applied to\nany dataset, irrespective of its distribution, post hoc. In contrast to other\npixel-level uncertainty quantification methods, conformal prediction operates\nwithout requiring access to the underlying model and training dataset,\nconcurrently offering statistically valid and informative prediction regions,\nall while maintaining computational efficiency. In response to the increased\nneed to report uncertainty alongside point predictions, we bring attention to\nthe promise of conformal prediction within the domain of Earth Observation (EO)\napplications. To accomplish this, we assess the current state of uncertainty\nquantification in the EO domain and found that only 20% of the reviewed Google\nEarth Engine (GEE) datasets incorporated a degree of uncertainty information,\nwith unreliable methods prevalent. Next, we introduce modules that seamlessly\nintegrate into existing GEE predictive modelling workflows and demonstrate the\napplication of these tools for datasets spanning local to global scales,\nincluding the Dynamic World and Global Ecosystem Dynamics Investigation (GEDI)\ndatasets. These case studies encompass regression and classification tasks,\nfeaturing both traditional and deep learning-based workflows. Subsequently, we\ndiscuss the opportunities arising from the use of conformal prediction in EO.\nWe anticipate that the increased availability of easy-to-use implementations of\nconformal predictors, such as those provided here, will drive wider adoption of\nrigorous uncertainty quantification in EO, thereby enhancing the reliability of\nuses such as operational monitoring and decision making.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06421v1",
    "published_date": "2024-01-12 07:31:21 UTC",
    "updated_date": "2024-01-12 07:31:21 UTC"
  },
  {
    "arxiv_id": "2401.06416v2",
    "title": "Mission: Impossible Language Models",
    "authors": [
      "Julie Kallini",
      "Isabel Papadimitriou",
      "Richard Futrell",
      "Kyle Mahowald",
      "Christopher Potts"
    ],
    "abstract": "Chomsky and others have very directly claimed that large language models\n(LLMs) are equally capable of learning languages that are possible and\nimpossible for humans to learn. However, there is very little published\nexperimental evidence to support such a claim. Here, we develop a set of\nsynthetic impossible languages of differing complexity, each designed by\nsystematically altering English data with unnatural word orders and grammar\nrules. These languages lie on an impossibility continuum: at one end are\nlanguages that are inherently impossible, such as random and irreversible\nshuffles of English words, and on the other, languages that may not be\nintuitively impossible but are often considered so in linguistics, particularly\nthose with rules based on counting word positions. We report on a wide range of\nevaluations to assess the capacity of GPT-2 small models to learn these\nuncontroversially impossible languages, and crucially, we perform these\nassessments at various stages throughout training to compare the learning\nprocess for each language. Our core finding is that GPT-2 struggles to learn\nimpossible languages when compared to English as a control, challenging the\ncore claim. More importantly, we hope our approach opens up a productive line\nof inquiry in which different LLM architectures are tested on a variety of\nimpossible languages in an effort to learn more about how LLMs can be used as\ntools for these cognitive and typological investigations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06416v2",
    "published_date": "2024-01-12 07:24:26 UTC",
    "updated_date": "2024-08-02 21:59:03 UTC"
  },
  {
    "arxiv_id": "2401.06406v1",
    "title": "Knowledge-Informed Machine Learning for Cancer Diagnosis and Prognosis: A review",
    "authors": [
      "Lingchao Mao",
      "Hairong Wang",
      "Leland S. Hu",
      "Nhan L Tran",
      "Peter D Canoll",
      "Kristin R Swanson",
      "Jing Li"
    ],
    "abstract": "Cancer remains one of the most challenging diseases to treat in the medical\nfield. Machine learning has enabled in-depth analysis of rich multi-omics\nprofiles and medical imaging for cancer diagnosis and prognosis. Despite these\nadvancements, machine learning models face challenges stemming from limited\nlabeled sample sizes, the intricate interplay of high-dimensionality data\ntypes, the inherent heterogeneity observed among patients and within tumors,\nand concerns about interpretability and consistency with existing biomedical\nknowledge. One approach to surmount these challenges is to integrate biomedical\nknowledge into data-driven models, which has proven potential to improve the\naccuracy, robustness, and interpretability of model results. Here, we review\nthe state-of-the-art machine learning studies that adopted the fusion of\nbiomedical knowledge and data, termed knowledge-informed machine learning, for\ncancer diagnosis and prognosis. Emphasizing the properties inherent in four\nprimary data types including clinical, imaging, molecular, and treatment data,\nwe highlight modeling considerations relevant to these contexts. We provide an\noverview of diverse forms of knowledge representation and current strategies of\nknowledge integration into machine learning pipelines with concrete examples.\nWe conclude the review article by discussing future directions to advance\ncancer research through knowledge-informed machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "92B99"
    ],
    "primary_category": "cs.LG",
    "comment": "41 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.06406v1",
    "published_date": "2024-01-12 07:01:36 UTC",
    "updated_date": "2024-01-12 07:01:36 UTC"
  },
  {
    "arxiv_id": "2401.06401v4",
    "title": "DevEval: Evaluating Code Generation in Practical Software Projects",
    "authors": [
      "Jia Li",
      "Ge Li",
      "Yunfei Zhao",
      "Yongmin Li",
      "Zhi Jin",
      "Hao Zhu",
      "Huanyu Liu",
      "Kaibo Liu",
      "Lecheng Wang",
      "Zheng Fang",
      "Lanshen Wang",
      "Jiazheng Ding",
      "Xuanming Zhang",
      "Yihong Dong",
      "Yuqi Zhu",
      "Bin Gu",
      "Mengfei Yang"
    ],
    "abstract": "How to evaluate Large Language Models (LLMs) in code generation is an open\nquestion. Many benchmarks have been proposed but are inconsistent with\npractical software projects, e.g., unreal program distributions, insufficient\ndependencies, and small-scale project contexts. Thus, the capabilities of LLMs\nin practical projects are still unclear. In this paper, we propose a new\nbenchmark named DevEval, aligned with Developers' experiences in practical\nprojects. DevEval is collected through a rigorous pipeline, containing 2,690\nsamples from 119 practical projects and covering 10 domains. Compared to\nprevious benchmarks, DevEval aligns to practical projects in multiple\ndimensions, e.g., real program distributions, sufficient dependencies, and\nenough-scale project contexts. We assess five popular LLMs on DevEval (e.g.,\ngpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual\nabilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo\nonly is 42 in our experiments. We also discuss the challenges and future\ndirections of code generation in practical projects. We open-source DevEval and\nhope it can facilitate the development of code generation in practical\nprojects.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "We are re-checking this benchmark and repeating related experiments.\n  New versions of DevEval will be released later",
    "pdf_url": "http://arxiv.org/pdf/2401.06401v4",
    "published_date": "2024-01-12 06:51:30 UTC",
    "updated_date": "2024-03-06 02:16:51 UTC"
  },
  {
    "arxiv_id": "2401.06394v1",
    "title": "Adaptive Data Augmentation for Aspect Sentiment Quad Prediction",
    "authors": [
      "Wenyuan Zhang",
      "Xinghua Zhang",
      "Shiyao Cui",
      "Kun Huang",
      "Xuebin Wang",
      "Tingwen Liu"
    ],
    "abstract": "Aspect sentiment quad prediction (ASQP) aims to predict the quad sentiment\nelements for a given sentence, which is a critical task in the field of\naspect-based sentiment analysis. However, the data imbalance issue has not\nreceived sufficient attention in ASQP task. In this paper, we divide the issue\ninto two-folds, quad-pattern imbalance and aspect-category imbalance, and\npropose an Adaptive Data Augmentation (ADA) framework to tackle the imbalance\nissue. Specifically, a data augmentation process with a condition function\nadaptively enhances the tail quad patterns and aspect categories, alleviating\nthe data imbalance in ASQP. Following previous studies, we also further explore\nthe generative framework for extracting complete quads by introducing the\ncategory prior knowledge and syntax-guided decoding target. Experimental\nresults demonstrate that data augmentation for imbalance in ASQP task can\nimprove the performance, and the proposed ADA method is superior to naive data\noversampling.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICASSP 2024, 5 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.06394v1",
    "published_date": "2024-01-12 06:20:56 UTC",
    "updated_date": "2024-01-12 06:20:56 UTC"
  },
  {
    "arxiv_id": "2401.06382v1",
    "title": "What should I say? -- Interacting with AI and Natural Language Interfaces",
    "authors": [
      "Mark Adkins"
    ],
    "abstract": "As Artificial Intelligence (AI) technology becomes more and more prevalent,\nit becomes increasingly important to explore how we as humans interact with AI.\nThe Human-AI Interaction (HAI) sub-field has emerged from the Human-Computer\nInteraction (HCI) field and aims to examine this very notion. Many interaction\npatterns have been implemented without fully understanding the changes in\nrequired cognition as well as the cognitive science implications of using these\nalternative interfaces that aim to be more human-like in nature. Prior research\nsuggests that theory of mind representations are crucial to successful and\neffortless communication, however very little is understood when it comes to\nhow theory of mind representations are established when interacting with AI.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "I.2.m; J.4; B.4.2"
    ],
    "primary_category": "cs.HC",
    "comment": "6 pages, 12 figures, 12 data tables, study data included in appendix",
    "pdf_url": "http://arxiv.org/pdf/2401.06382v1",
    "published_date": "2024-01-12 05:10:23 UTC",
    "updated_date": "2024-01-12 05:10:23 UTC"
  },
  {
    "arxiv_id": "2401.06379v1",
    "title": "Vehicle: Bridging the Embedding Gap in the Verification of Neuro-Symbolic Programs",
    "authors": [
      "Matthew L. Daggitt",
      "Wen Kokke",
      "Robert Atkey",
      "Natalia Slusarz",
      "Luca Arnaboldi",
      "Ekaterina Komendantskaya"
    ],
    "abstract": "Neuro-symbolic programs -- programs containing both machine learning\ncomponents and traditional symbolic code -- are becoming increasingly\nwidespread. However, we believe that there is still a lack of a general\nmethodology for verifying these programs whose correctness depends on the\nbehaviour of the machine learning components. In this paper, we identify the\n``embedding gap'' -- the lack of techniques for linking semantically-meaningful\n``problem-space'' properties to equivalent ``embedding-space'' properties -- as\none of the key issues, and describe Vehicle, a tool designed to facilitate the\nend-to-end verification of neural-symbolic programs in a modular fashion.\nVehicle provides a convenient language for specifying ``problem-space''\nproperties of neural networks and declaring their relationship to the\n``embedding-space\", and a powerful compiler that automates interpretation of\nthese properties in the language of a chosen machine-learning training\nenvironment, neural network verifier, and interactive theorem prover. We\ndemonstrate Vehicle's utility by using it to formally verify the safety of a\nsimple autonomous car equipped with a neural network controller.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06379v1",
    "published_date": "2024-01-12 05:01:47 UTC",
    "updated_date": "2024-01-12 05:01:47 UTC"
  },
  {
    "arxiv_id": "2401.06375v1",
    "title": "Cognitive BPM as an Equalizer: Improving Access and Efficiency for Employees with (and without) Cognitive Disabilities",
    "authors": [
      "Gordon Banks",
      "Gates Bierhuizen",
      "Katherine McCrum",
      "Ellen Wengert"
    ],
    "abstract": "We examine ProcessGPT, an AI model designed to automate, augment, and improve\nbusiness processes, to study the challenges of managing business processes\nwithin the cognitive limitations of the human workforce, particularly\nindividuals with cognitive disabilities. ProcessGPT provides a blueprint for\ndesigning efficient business processes that take into account human cognitive\nlimitations. By viewing this through the lens of cognitive disabilities, we\nshow that ProcessGPT improves process usability for individuals with and\nwithout cognitive disabilities. We also demonstrate that organizations\nimplementing ProcessGPT-like capabilities will realize increased productivity,\nmorale, and inclusion.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.06375v1",
    "published_date": "2024-01-12 04:54:06 UTC",
    "updated_date": "2024-01-12 04:54:06 UTC"
  },
  {
    "arxiv_id": "2401.06827v2",
    "title": "APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning",
    "authors": [
      "Guiming Cao",
      "Kaize Shi",
      "Hong Fu",
      "Huaiwen Zhang",
      "Guandong Xu"
    ],
    "abstract": "Pre-trained Vision-Language (V-L) models set the benchmark for generalization\nto downstream tasks among the noteworthy contenders. Many characteristics of\nthe V-L model have been explored in existing research including the challenge\nof the sensitivity to text input and the tuning process across multi-modal\nprompts. With the advanced utilization of the V-L model like CLIP, recent\napproaches deploy learnable prompts instead of hand-craft prompts to boost the\ngeneralization performance and address the aforementioned challenges. Inspired\nby layer-wise training, which is wildly used in image fusion, we note that\nusing a sequential training process to adapt different modalities branches of\nCLIP efficiently facilitates the improvement of generalization. In the context\nof addressing the multi-modal prompting challenge, we propose Token-wise\nAdaptive for Multi-modal Prompt Learning (APLe) for tuning both modalities\nprompts, vision and language, as tokens in a sequential manner. APLe addresses\nthe challenges in V-L models to promote prompt learning across both modalities,\nwhich indicates a competitive generalization performance in line with the\nstate-of-the-art. Preeminently, APLe shows robustness and favourable\nperformance in prompt-length experiments with an absolute advantage in adopting\nthe V-L models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages,3 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.06827v2",
    "published_date": "2024-01-12 04:54:01 UTC",
    "updated_date": "2024-01-23 08:54:15 UTC"
  },
  {
    "arxiv_id": "2401.06370v1",
    "title": "Graph Relation Distillation for Efficient Biomedical Instance Segmentation",
    "authors": [
      "Xiaoyu Liu",
      "Yueyi Zhang",
      "Zhiwei Xiong",
      "Wei Huang",
      "Bo Hu",
      "Xiaoyan Sun",
      "Feng Wu"
    ],
    "abstract": "Instance-aware embeddings predicted by deep neural networks have\nrevolutionized biomedical instance segmentation, but its resource requirements\nare substantial. Knowledge distillation offers a solution by transferring\ndistilled knowledge from heavy teacher networks to lightweight yet\nhigh-performance student networks. However, existing knowledge distillation\nmethods struggle to extract knowledge for distinguishing instances and overlook\nglobal relation information. To address these challenges, we propose a graph\nrelation distillation approach for efficient biomedical instance segmentation,\nwhich considers three essential types of knowledge: instance-level features,\ninstance relations, and pixel-level boundaries. We introduce two graph\ndistillation schemes deployed at both the intra-image level and the inter-image\nlevel: instance graph distillation (IGD) and affinity graph distillation (AGD).\nIGD constructs a graph representing instance features and relations,\ntransferring these two types of knowledge by enforcing instance graph\nconsistency. AGD constructs an affinity graph representing pixel relations to\ncapture structured knowledge of instance boundaries, transferring\nboundary-related knowledge by ensuring pixel affinity consistency. Experimental\nresults on a number of biomedical datasets validate the effectiveness of our\napproach, enabling student models with less than $ 1\\%$ parameters and less\nthan $10\\%$ inference time while achieving promising performance compared to\nteacher models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06370v1",
    "published_date": "2024-01-12 04:41:23 UTC",
    "updated_date": "2024-01-12 04:41:23 UTC"
  },
  {
    "arxiv_id": "2401.06340v2",
    "title": "A Temporal-Spectral Fusion Transformer with Subject-Specific Adapter for Enhancing RSVP-BCI Decoding",
    "authors": [
      "Xujin Li",
      "Wei Wei",
      "Shuang Qiu",
      "Huiguang He"
    ],
    "abstract": "The Rapid Serial Visual Presentation (RSVP)-based Brain-Computer Interface\n(BCI) is an efficient technology for target retrieval using\nelectroencephalography (EEG) signals. The performance improvement of\ntraditional decoding methods relies on a substantial amount of training data\nfrom new test subjects, which increases preparation time for BCI systems.\nSeveral studies introduce data from existing subjects to reduce the dependence\nof performance improvement on data from new subjects, but their optimization\nstrategy based on adversarial learning with extensive data increases training\ntime during the preparation procedure. Moreover, most previous methods only\nfocus on the single-view information of EEG signals, but ignore the information\nfrom other views which may further improve performance. To enhance decoding\nperformance while reducing preparation time, we propose a Temporal-Spectral\nfusion transformer with Subject-specific Adapter (TSformer-SA). Specifically, a\ncross-view interaction module is proposed to facilitate information transfer\nand extract common representations across two-view features extracted from EEG\ntemporal signals and spectrogram images. Then, an attention-based fusion module\nfuses the features of two views to obtain comprehensive discriminative features\nfor classification. Furthermore, a multi-view consistency loss is proposed to\nmaximize the feature similarity between two views of the same EEG signal.\nFinally, we propose a subject-specific adapter to rapidly transfer the\nknowledge of the model trained on data from existing subjects to decode data\nfrom new subjects. Experimental results show that TSformer-SA significantly\noutperforms comparison methods and achieves outstanding performance with\nlimited training data from new subjects. This facilitates efficient decoding\nand rapid deployment of BCI systems in practical use.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "68T07",
      "I.5.4"
    ],
    "primary_category": "cs.HC",
    "comment": "19 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.06340v2",
    "published_date": "2024-01-12 03:18:51 UTC",
    "updated_date": "2024-07-11 05:07:54 UTC"
  },
  {
    "arxiv_id": "2401.06826v1",
    "title": "Direct Distillation between Different Domains",
    "authors": [
      "Jialiang Tang",
      "Shuo Chen",
      "Gang Niu",
      "Hongyuan Zhu",
      "Joey Tianyi Zhou",
      "Chen Gong",
      "Masashi Sugiyama"
    ],
    "abstract": "Knowledge Distillation (KD) aims to learn a compact student network using\nknowledge from a large pre-trained teacher network, where both networks are\ntrained on data from the same distribution. However, in practical applications,\nthe student network may be required to perform in a new scenario (i.e., the\ntarget domain), which usually exhibits significant differences from the known\nscenario of the teacher network (i.e., the source domain). The traditional\ndomain adaptation techniques can be integrated with KD in a two-stage process\nto bridge the domain gap, but the ultimate reliability of two-stage approaches\ntends to be limited due to the high computational consumption and the\nadditional errors accumulated from both stages. To solve this problem, we\npropose a new one-stage method dubbed ``Direct Distillation between Different\nDomains\" (4Ds). We first design a learnable adapter based on the Fourier\ntransform to separate the domain-invariant knowledge from the domain-specific\nknowledge. Then, we build a fusion-activation mechanism to transfer the\nvaluable domain-invariant knowledge to the student network, while\nsimultaneously encouraging the adapter within the teacher network to learn the\ndomain-specific knowledge of the target data. As a result, the teacher network\ncan effectively transfer categorical knowledge that aligns with the target\ndomain of the student network. Intensive experiments on various benchmark\ndatasets demonstrate that our proposed 4Ds method successfully produces\nreliable student networks and outperforms state-of-the-art approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06826v1",
    "published_date": "2024-01-12 02:48:51 UTC",
    "updated_date": "2024-01-12 02:48:51 UTC"
  },
  {
    "arxiv_id": "2401.06318v1",
    "title": "Striking a Balance in Fairness for Dynamic Systems Through Reinforcement Learning",
    "authors": [
      "Yaowei Hu",
      "Jacob Lear",
      "Lu Zhang"
    ],
    "abstract": "While significant advancements have been made in the field of fair machine\nlearning, the majority of studies focus on scenarios where the decision model\noperates on a static population. In this paper, we study fairness in dynamic\nsystems where sequential decisions are made. Each decision may shift the\nunderlying distribution of features or user behavior. We model the dynamic\nsystem through a Markov Decision Process (MDP). By acknowledging that\ntraditional fairness notions and long-term fairness are distinct requirements\nthat may not necessarily align with one another, we propose an algorithmic\nframework to integrate various fairness considerations with reinforcement\nlearning using both pre-processing and in-processing approaches. Three case\nstudies show that our method can strike a balance between traditional fairness\nnotions, long-term fairness, and utility.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06318v1",
    "published_date": "2024-01-12 01:29:26 UTC",
    "updated_date": "2024-01-12 01:29:26 UTC"
  },
  {
    "arxiv_id": "2401.06824v5",
    "title": "Revisiting Jailbreaking for Large Language Models: A Representation Engineering Perspective",
    "authors": [
      "Tianlong Li",
      "Zhenghua Wang",
      "Wenhao Liu",
      "Muling Wu",
      "Shihan Dou",
      "Changze Lv",
      "Xiaohua Wang",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ],
    "abstract": "The recent surge in jailbreaking attacks has revealed significant\nvulnerabilities in Large Language Models (LLMs) when exposed to malicious\ninputs. While various defense strategies have been proposed to mitigate these\nthreats, there has been limited research into the underlying mechanisms that\nmake LLMs vulnerable to such attacks. In this study, we suggest that the\nself-safeguarding capability of LLMs is linked to specific activity patterns\nwithin their representation space. Although these patterns have little impact\non the semantic content of the generated text, they play a crucial role in\nshaping LLM behavior under jailbreaking attacks. Our findings demonstrate that\nthese patterns can be detected with just a few pairs of contrastive queries.\nExtensive experimentation shows that the robustness of LLMs against\njailbreaking can be manipulated by weakening or strengthening these patterns.\nFurther visual analysis provides additional evidence for our conclusions,\nproviding new insights into the jailbreaking phenomenon. These findings\nhighlight the importance of addressing the potential misuse of open-source LLMs\nwithin the community.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2401.06824v5",
    "published_date": "2024-01-12 00:50:04 UTC",
    "updated_date": "2025-02-21 05:17:52 UTC"
  },
  {
    "arxiv_id": "2401.06308v2",
    "title": "A Semantic-Aware Multiple Access Scheme for Distributed, Dynamic 6G-Based Applications",
    "authors": [
      "Hamidreza Mazandarani",
      "Masoud Shokrnezhad",
      "Tarik Taleb"
    ],
    "abstract": "The emergence of the semantic-aware paradigm presents opportunities for\ninnovative services, especially in the context of 6G-based applications.\nAlthough significant progress has been made in semantic extraction techniques,\nthe incorporation of semantic information into resource allocation\ndecision-making is still in its early stages, lacking consideration of the\nrequirements and characteristics of future systems. In response, this paper\nintroduces a novel formulation for the problem of multiple access to the\nwireless spectrum. It aims to optimize the utilization-fairness trade-off,\nusing the $\\alpha$-fairness metric, while accounting for user data correlation\nby introducing the concepts of self- and assisted throughputs. Initially, the\nproblem is analyzed to identify its optimal solution. Subsequently, a\nSemantic-Aware Multi-Agent Double and Dueling Deep Q-Learning (SAMA-D3QL)\ntechnique is proposed. This method is grounded in Model-free Multi-Agent Deep\nReinforcement Learning (MADRL), enabling the user equipment to autonomously\nmake decisions regarding wireless spectrum access based solely on their local\nindividual observations. The efficiency of the proposed technique is evaluated\nthrough two scenarios: single-channel and multi-channel. The findings\nillustrate that, across a spectrum of $\\alpha$ values, association matrices,\nand channels, SAMA-D3QL consistently outperforms alternative approaches. This\nestablishes it as a promising candidate for facilitating the realization of\nfuture federated, dynamically evolving applications.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.NI",
    "comment": "Accepted at the 2024 IEEE Wireless Communications and Networking\n  Conference (WCNC 2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.06308v2",
    "published_date": "2024-01-12 00:32:38 UTC",
    "updated_date": "2024-07-04 18:48:25 UTC"
  }
]