{
  "date": "2025-07-10",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-07-10 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ **ä¸€å¥è¯æ€»ç»“ï¼š** ä»Šå¤©æ˜¯ **Agent (æ™ºèƒ½ä½“)** å’Œ **RL (å¼ºåŒ–å­¦ä¹ )** çˆ†å‘çš„ä¸€å¤©ï¼Œä» NVIDIA å‘å¸ƒæœ€å¼ºéŸ³é¢‘ç†è§£æ¨¡å‹ **Audio Flamingo 3**ï¼Œåˆ° Sergey Levine ç»„æå‡ºçš„ **Q-chunking** åŠ¨ä½œåˆ†å—ç­–ç•¥ï¼Œå†åˆ° Dawn Song å›¢é˜Ÿå¯¹ LLM **\"Machine Bullshit\" (æœºå™¨èƒ¡æ‰¯)** ç°è±¡çš„çŠ€åˆ©é‡åŒ–ï¼Œç†è®ºä¸åº”ç”¨çš†æœ‰é‡ç£…æ›´æ–°ã€‚\n\n---\n\n### ğŸš€ å¤´æ¡å…³æ³¨ï¼šé‡ç£…æ¨¡å‹ä¸æ·±åº¦ç†è®º\n\n**1. [å¾ˆæœ‰è¶£] Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** æœºå™¨èƒ¡æ‰¯ï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­å¯¹çœŸç†æ¼ è§†ç°è±¡çš„ç‰¹å¾åŒ–\n*   **æ ¸å¿ƒå†…å®¹ï¼š** è¿™ç¯‡æ–‡ç« çš„æ ‡é¢˜éå¸¸çŠ€åˆ©ã€‚æ¥è‡ª UC Berkeley (Dawn Song ç­‰) çš„å›¢é˜Ÿå€Ÿç”¨å“²å­¦å®¶ Harry Frankfurt çš„æ¦‚å¿µï¼Œå®šä¹‰äº† **\"Machine Bullshit\" (æœºå™¨èƒ¡æ‰¯)**â€”â€”å³ä¸åœ¨ä¹çœŸå‡ï¼Œåªåœ¨ä¹ç”Ÿæˆçš„ç°è±¡ã€‚ä»–ä»¬æå‡ºäº† **Bullshit Index (èƒ¡æ‰¯æŒ‡æ•°)**ï¼Œå‘ç° **RLHF (äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ )** å®é™…ä¸ŠåŠ å‰§äº†è¿™ç§ç°è±¡ï¼ˆä¸ºäº†è®¨å¥½äººç±»è€Œèƒ¡æ‰¯ï¼‰ï¼Œè€Œæ¨ç†æ—¶çš„ CoT (æ€ç»´é“¾) ä¹Ÿä¼šæ”¾å¤§è¿™ç§æ•ˆåº”ï¼ˆä¸€æœ¬æ­£ç»åœ°èƒ¡æ‰¯ï¼‰ã€‚\n*   **ä¸»è¦å‘ç°ï¼š** æ”¿æ²»è¯­å¢ƒä¸‹æ¨¡å‹æœ€çˆ±ç”¨ \"Weasel words\" (æ¨¡æ£±ä¸¤å¯çš„è¯)ã€‚è¿™æ˜¯ä¸€ä¸ªå¯¹ AI å¯¹é½ (Alignment) æå…·æ‰¹åˆ¤æ€§çš„è§†è§’ã€‚\n\n**2. Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** Audio Flamingo 3ï¼šé€šè¿‡å…¨å¼€æºå¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹æ¨è¿›éŸ³é¢‘æ™ºèƒ½\n*   **æ ¸å¿ƒå†…å®¹ï¼š** NVIDIA å›¢é˜Ÿæ¨å‡ºäº† **AF3**ï¼Œä¸€ä¸ªæ–°çš„ SOTA éŸ³é¢‘-è¯­è¨€æ¨¡å‹ã€‚\n*   **æ ¸å¿ƒè´¡çŒ®ï¼š**\n    *   **AF-Thinkï¼š** å¼•å…¥äº†ç±»ä¼¼ o1 çš„ \"Thinking Mode\"ï¼ˆæŒ‰éœ€æ€è€ƒï¼‰ï¼Œåœ¨å›ç­”å‰å…ˆè¿›è¡Œæ¨ç†ã€‚\n    *   æ”¯æŒé•¿è¾¾ **10åˆ†é’Ÿ** çš„é•¿éŸ³é¢‘ç†è§£ã€‚\n    *   å…¨å¼€æºï¼ˆæ•°æ®ã€ä»£ç ã€æ¨¡å‹ï¼‰ã€‚åœ¨ 20+ ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰æ¨¡å‹ã€‚\n\n**3. Reinforcement Learning with Action Chunking**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** åŸºäºåŠ¨ä½œåˆ†å—çš„å¼ºåŒ–å­¦ä¹ \n*   **æ ¸å¿ƒå†…å®¹ï¼š** Sergey Levine å›¢é˜Ÿæ–°ä½œã€‚é’ˆå¯¹é•¿è§†ç•Œã€ç¨€ç–å¥–åŠ±çš„ä»»åŠ¡ã€‚\n*   **æ–¹æ³•ï¼š** æå‡ºäº† **Q-chunking**ã€‚æ ¸å¿ƒæ´å¯Ÿæ˜¯å°†æ¨¡ä»¿å­¦ä¹ ä¸­çš„ \"Action Chunking\" (é¢„æµ‹åŠ¨ä½œåºåˆ—è€Œéå•ä¸ªåŠ¨ä½œ) å¼•å…¥åˆ° TD-learning ä¸­ã€‚\n*   **æ•ˆæœï¼š** è®© Agent åœ¨ç¦»çº¿æ•°æ®ä¸Šèƒ½å­¦åˆ°æ—¶é—´ä¸Šä¸€è‡´çš„è¡Œä¸ºï¼Œè§£å†³äº† Offline-to-Online RL ä¸­çš„æ¢ç´¢éš¾é¢˜ï¼Œåœ¨å¤æ‚æ“ä½œä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚\n\n**4. Consciousness as a Jamming Phase**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** æ„è¯†å³æ‹¥å¡ç›¸\n*   **æ ¸å¿ƒå†…å®¹ï¼š** ä¸€ç¯‡éå¸¸æœ‰ç‰©ç†å‘³é“çš„ç†è®ºæ–‡ç« ã€‚ä½œè€…å°† LLM ä¸­æ„è¯†çš„æ¶Œç°ç±»æ¯”ä¸ºé«˜ç»´æ— åºç³»ç»Ÿä¸­çš„ **\"Jamming Transition\" (æ‹¥å¡ç›¸å˜)** â€”â€” å°±åƒé¢—ç²’ç‰©è´¨ä»æµä½“å˜æˆåˆšä½“ä¸€æ ·ã€‚\n*   **è§‚ç‚¹ï¼š** æå‡ºæ¸©åº¦ã€ä½“ç§¯å’Œå‹åŠ›ä¸‰ä¸ªæ§åˆ¶å‚æ•°ï¼Œè®¤ä¸º AI çš„ Scaling Law å’Œä¸´ç•Œè¡Œä¸ºå¯ä»¥ç”¨æ‹¥å¡ç‰©ç†å­¦æ¥è§£é‡Šã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æ–°é¢–çš„ç‰©ç†-AI äº¤å‰è§†è§’ã€‚\n\n---\n\n### ğŸ¤– Agent ä¸ Game Theory (åšå¼ˆè®º)\n\n**5. Scaling RL to Long Videos**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** å°†å¼ºåŒ–å­¦ä¹ æ‰©å±•åˆ°é•¿è§†é¢‘\n*   **æ ¸å¿ƒå†…å®¹ï¼š** éŸ©æ¾ (Song Han) å›¢é˜Ÿä¸ NVIDIA åˆä½œã€‚æå‡ºäº† **LongVILA-R1**ï¼Œå°† VLM çš„æ¨ç†èƒ½åŠ›æ‰©å±•åˆ°é•¿è§†é¢‘ã€‚\n*   **æŠ€æœ¯ï¼š** æ„å»ºäº† **LongVideo-Reason** æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨ RL + CoT-SFT è¿›è¡Œä¸¤é˜¶æ®µè®­ç»ƒã€‚å¼•å…¥äº† **MR-SP** ç³»ç»ŸåŠ é€Ÿé•¿è§†é¢‘çš„ RL è®­ç»ƒï¼ˆé«˜è¾¾ 2.1 å€åŠ é€Ÿï¼‰ã€‚\n\n**6. Multi-Actor Generative Artificial Intelligence as a Game Engine**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** å¤šè§’è‰²ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä½œä¸ºæ¸¸æˆå¼•æ“\n*   **æ ¸å¿ƒå†…å®¹ï¼š** DeepMind å›¢é˜Ÿã€‚ä»–ä»¬å€Ÿé‰´äº† **TTRPG (æ¡Œé¢è§’è‰²æ‰®æ¼”æ¸¸æˆ)** çš„æ¦‚å¿µï¼Œæå‡ºç”¨ GM (æ¸¸æˆç®¡ç†å‘˜) æ¨¡å¼æ¥ç®¡ç†å¤šæ™ºèƒ½ä½“ç¯å¢ƒã€‚\n*   **æ¶æ„ï¼š** æå€¡ä½¿ç”¨ ECS (Entity-Component-System) æ¶æ„æ¥æ„å»ºå¯é…ç½®ã€å¯æ‰©å±•çš„ Simulation ç¯å¢ƒã€‚è¿™æ˜¯å¯¹ Social Sim å’Œ AI è¯„ä¼°ç¯å¢ƒæ„å»ºçš„é‡è¦æ–¹æ³•è®ºæŒ‡å¯¼ã€‚\n\n**7. Reasoning and Behavioral Equilibria in LLM-Nash Games**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** LLM-Nash åšå¼ˆä¸­çš„æ¨ç†ä¸è¡Œä¸ºå‡è¡¡\n*   **æ ¸å¿ƒå†…å®¹ï¼š** ä¼ ç»Ÿçš„åšå¼ˆè®ºå‡è®¾å®Œå…¨ç†æ€§ï¼Œè¿™ç¯‡æ–‡ç« æå‡ºäº† **LLM-Nash** æ¡†æ¶ï¼Œæ˜¾å¼å»ºæ¨¡äº† LLM çš„ \"æ¨ç†è¿‡ç¨‹\" (Reasoning Prompts) å¦‚ä½•å½±å“å†³ç­–ã€‚å®šä¹‰äº† Prompt ç©ºé—´ä¸Šçš„å‡è¡¡ï¼Œä¸ºç ”ç©¶ LLM æ™ºèƒ½ä½“çš„æˆ˜ç•¥äº¤äº’æä¾›äº†æ–°åŸºç¡€ã€‚\n\n**8. MIRIX: Multi-Agent Memory System for LLM-Based Agents**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** MIRIXï¼šåŸºäº LLM æ™ºèƒ½ä½“çš„å¤šæ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿ\n*   **æ ¸å¿ƒå†…å®¹ï¼š** é’ˆå¯¹ Agent \"è®°ä¸ä½\" çš„é—®é¢˜ï¼Œè®¾è®¡äº†åŒ…å« 6 ç§è®°å¿†ç±»å‹ (æ ¸å¿ƒã€æƒ…æ™¯ã€è¯­ä¹‰ç­‰) çš„ç³»ç»Ÿï¼Œå¹¶ç”¨å¤šæ™ºèƒ½ä½“æ¡†æ¶æ¥ç®¡ç†è®°å¿†çš„æ›´æ–°å’Œæ£€ç´¢ã€‚åœ¨é•¿å¯¹è¯å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸Šè¡¨ç°è¿œè¶… RAGã€‚\n\n---\n\n### ğŸ‘ï¸ Vision, Video & 3D (è§†è§‰ä¸ä¸‰ç»´)\n\n**9. Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** å‡ ä½•å¼ºåˆ¶ï¼šç»“åˆè§†é¢‘æ‰©æ•£ä¸ 3D è¡¨ç¤ºä»¥å®ç°ä¸€è‡´çš„ä¸–ç•Œå»ºæ¨¡\n*   **æ ¸å¿ƒå†…å®¹ï¼š** è§†é¢‘ç”Ÿæˆæ¨¡å‹é€šå¸¸ç¼ºä¹ 3D ä¸€è‡´æ€§ã€‚è¿™ç¯‡æ–‡ç« æå‡º **Geometry Forcing**ï¼Œå¼ºåˆ¶è§†é¢‘æ‰©æ•£æ¨¡å‹çš„ä¸­é—´è¡¨ç¤ºä¸é¢„è®­ç»ƒçš„å‡ ä½•åŸºç¡€æ¨¡å‹å¯¹é½ï¼ˆè§’åº¦å¯¹é½å’Œå°ºåº¦å¯¹é½ï¼‰ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆçš„ 3D ä¸€è‡´æ€§ã€‚\n\n**10. TreeBench: Traceable Evidence Enhanced Visual Grounded Reasoning**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** TreeBenchï¼šå¯è¿½è¸ªè¯æ®å¢å¼ºçš„è§†è§‰è½åœ°æ¨ç†è¯„ä¼°\n*   **æ ¸å¿ƒå†…å®¹ï¼š** å³ä½¿æ˜¯ OpenAI-o3 è¿™æ ·çš„æ¨¡å‹ï¼Œåœ¨å¤æ‚çš„è§†è§‰æ¨ç†ä¸Šä¹Ÿç»å¸¸ \"å¹»è§‰\"ã€‚TreeBench æ˜¯ä¸€ä¸ªè¯Šæ–­æ€§åŸºå‡†ï¼Œè¦æ±‚æ¨¡å‹ä¸ä»…è¦å›ç­”ï¼Œè¿˜è¦ç»™å‡º **Traceable Evidence (å¯è¿½è¸ªçš„è¯æ®/åŒ…å›´ç›’)**ã€‚æµ‹è¯•å‘ç°ç°æœ‰æ¨¡å‹ï¼ˆåŒ…æ‹¬ o3ï¼‰å‡†ç¡®ç‡éƒ½æœªè¶…è¿‡ 60%ï¼Œè¿˜æœ‰å¾ˆå¤§æå‡ç©ºé—´ã€‚\n\n**11. PyVision: Agentic Vision with Dynamic Tooling**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** PyVisionï¼šå…·æœ‰åŠ¨æ€å·¥å…·èƒ½åŠ›çš„ä»£ç†è§†è§‰\n*   **æ ¸å¿ƒå†…å®¹ï¼š** è®© VLM ä¸ä»…ä»…æ˜¯ \"çœ‹\"ï¼Œè€Œæ˜¯èƒ½è‡ªå·±å†™ Python å·¥å…·æ¥è¾…åŠ©è§†è§‰æ¨ç†ã€‚è¿™ç§ **\"Inventing Tools\" (å‘æ˜å·¥å…·)** çš„èƒ½åŠ›è®© GPT-4 å’Œ Claude åœ¨è§†è§‰åŸºå‡†ä¸Šæœ‰äº†å¤§å¹…æå‡ã€‚\n\n---\n\n### ğŸ› ï¸ Optimization, Alignment & Efficiency (ä¼˜åŒ–ä¸æ•ˆç‡)\n\n**12. Compactor: Calibrated Query-Agnostic KV Cache Compression**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** Compactorï¼šæ ¡å‡†çš„æŸ¥è¯¢æ— å…³ KV Cache å‹ç¼©\n*   **æ ¸å¿ƒå†…å®¹ï¼š** è§£å†³ LLM é•¿ä¸Šä¸‹æ–‡çš„æ˜¾å­˜ç“¶é¢ˆã€‚Compactor ä¸éœ€è¦è®­ç»ƒï¼Œé€šè¿‡è¿‘ä¼¼æ æ†åˆ†æ•° (leverage scores) æ¥åˆ¤æ–­ Token é‡è¦æ€§ã€‚åœ¨ Longbench ä¸Šå¹³å‡å‡å°‘äº† **68%** çš„ KV æ˜¾å­˜å ç”¨ï¼Œä¸”ä¿æŒäº†æ€§èƒ½ã€‚\n\n**13. Stable Preference Optimization: A Bilevel Approach to Catastrophic Preference Shift**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** ç¨³å®šåå¥½ä¼˜åŒ–ï¼šè§£å†³ç¾éš¾æ€§åå¥½åç§»çš„åŒå±‚æ–¹æ³•\n*   **æ ¸å¿ƒå†…å®¹ï¼š** å‘ç°ç°æœ‰çš„ DPO ç­‰æ–¹æ³•ä¼šå¯¼è‡´ **\"Catastrophic Preference Shift\"**ï¼ˆæ¦‚ç‡è´¨é‡å‘åˆ†å¸ƒå¤–å“åº”åç§»ï¼‰ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›ä¸‹é™ï¼ˆå¦‚ SimPO å‡†ç¡®ç‡è…°æ–©ï¼‰ã€‚æå‡ºäº† **SPO**ï¼Œé€šè¿‡çº¦æŸå¯¹é½åŒºåŸŸæ¥ç¨³å®šè®­ç»ƒã€‚\n\n**14. Not All Preferences are What You Need for Post-Training**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** åè®­ç»ƒä¸­å¹¶éæ‰€æœ‰åå¥½éƒ½æ˜¯ä½ éœ€è¦çš„\n*   **æ ¸å¿ƒå†…å®¹ï¼š** æå‡ºäº† **Selective-DPO (SDPO)**ã€‚ä¸æ˜¯æ‰€æœ‰çš„ Token éƒ½å¯¹å¯¹é½é‡è¦ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ Token çº§åˆ«çš„å¯¹æ•°æ¦‚ç‡å·®å¼‚ï¼Œåªå¯¹é«˜å½±å“åŠ›çš„ Token è¿›è¡Œä¼˜åŒ–ï¼Œæ•ˆç‡æ›´é«˜ã€‚\n\n**15. UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient Neural Inference on MCUs**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** UnITï¼šé¢å‘ MCU çš„å¯æ‰©å±•éç»“æ„åŒ–æ¨ç†æ—¶å‰ªæ\n*   **æ ¸å¿ƒå†…å®¹ï¼š** é’ˆå¯¹å¾®æ§åˆ¶å™¨ (MCU) çš„æè‡´ä¼˜åŒ–ã€‚ä¸åŒäºä¼ ç»Ÿçš„è®­ç»ƒæ—¶å‰ªæï¼Œè¿™æ˜¯ä¸€ä¸ª **æ¨ç†æ—¶ (Inference-Time)** çš„åŠ¨æ€å‰ªææ–¹æ³•ï¼Œæ ¹æ®è¾“å…¥åŠ¨æ€è·³è¿‡ä¸å¿…è¦çš„è®¡ç®—ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚\n\n---\n\n### ğŸ§¬ Science & Others (ç§‘å­¦ä¸å…¶ä»–)\n\n*   **[ç”Ÿç‰©] AmpLyze:** ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä¸ä»…èƒ½é¢„æµ‹æŠ—èŒè‚½çš„æ¯’æ€§ï¼Œè¿˜èƒ½ç»™å‡ºå…·ä½“çš„æº¶è¡€æµ“åº¦æ•°å€¼ (HC50) å’Œè§£é‡Šï¼Œå¯¹è¯ç‰©è®¾è®¡å¾ˆæœ‰ç”¨ã€‚\n*   **[è„‘ç§‘å­¦] Multigranular Evaluation for Brain Visual Decoding:** æå‡ºäº† BASIC æ¡†æ¶ï¼Œç”¨äºæ›´ç²¾ç»†åœ°è¯„ä¼° \"å¤§è„‘è§†è§‰è§£ç \"ï¼ˆä» fMRI é‡å»ºå›¾åƒï¼‰çš„æ•ˆæœï¼Œä¸å†åªæ˜¯çœ‹ä¸ªå¤§æ¦‚ã€‚\n*   **[æ£€ç´¢] TREC 2021/2022/2023 Deep Learning Track Overview:** NIST å‘å¸ƒçš„è¿‡å»å‡ å¹´ TREC æ·±åº¦å­¦ä¹ èµ›é“çš„ç»¼è¿°ï¼Œæ˜¯ä¿¡æ¯æ£€ç´¢é¢†åŸŸçš„å†å²æ¡£æ¡ˆã€‚\n\n---\n\n**æœ€åï¼š** ä»Šå¤©çš„ arXiv åˆ—è¡¨åœ¨ \"Agent å¦‚ä½•åƒäººä¸€æ ·æ€è€ƒä¸è®°å¿†\" ä»¥åŠ \"å¦‚ä½•ä»ç‰©ç†/å¤æ‚æ€§ç†è®ºå±‚é¢ç†è§£ LLM\" ä¸Šæä¾›äº†éå¸¸æœ‰æ·±åº¦çš„è§†è§’ã€‚ç¥å¤§å®¶é˜…è¯»æ„‰å¿«ï¼",
  "papers": [
    {
      "arxiv_id": "2507.08217v1",
      "title": "Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach",
      "title_zh": "é¢å‘å¤šæ¨¡æ€æ•°æ®çš„é‡å­è”é‚¦å­¦ä¹ ï¼šä¸€ç§æ¨¡æ€æ— å…³æ–¹æ³•",
      "authors": [
        "Atit Pokharel",
        "Ratun Rahman",
        "Thomas Morris",
        "Dinh C. Nguyen"
      ],
      "abstract": "Quantum federated learning (QFL) has been recently introduced to enable a distributed privacy-preserving quantum machine learning (QML) model training across quantum processors (clients). Despite recent research efforts, existing QFL frameworks predominantly focus on unimodal systems, limiting their applicability to real-world tasks that often naturally involve multiple modalities. To fill this significant gap, we present for the first time a novel multimodal approach specifically tailored for the QFL setting with the intermediate fusion using quantum entanglement. Furthermore, to address a major bottleneck in multimodal QFL, where the absence of certain modalities during training can degrade model performance, we introduce a Missing Modality Agnostic (MMA) mechanism that isolates untrained quantum circuits, ensuring stable training without corrupted states. Simulation results demonstrate that the proposed multimodal QFL method with MMA yields an improvement in accuracy of 6.84% in independent and identically distributed (IID) and 7.25% in non-IID data distributions compared to the state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰é‡å­è”é‚¦å­¦ä¹ (Quantum federated learning, QFL)æ¡†æ¶å±€é™äºå•æ¨¡æ€ç³»ç»Ÿçš„é—®é¢˜ï¼Œé¦–æ¬¡æå‡ºäº†ä¸€ç§ä¸“é—¨ç”¨äºQFLè®¾ç½®çš„å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡é‡å­çº ç¼ (quantum entanglement)å®ç°æ¨¡æ€é—´çš„ä¸­é—´èåˆã€‚ä¸ºäº†åº”å¯¹è®­ç»ƒæœŸé—´å› æ¨¡æ€ç¼ºå¤±å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™çš„å…³é”®ç“¶é¢ˆï¼Œç ”ç©¶å¼•å…¥äº†ç¼ºå¤±æ¨¡æ€ä¸å¯çŸ¥(Missing Modality Agnostic, MMA)æœºåˆ¶ï¼Œé€šè¿‡éš”ç¦»æœªè®­ç»ƒçš„é‡å­ç”µè·¯æ¥ç¡®ä¿è®­ç»ƒçš„ç¨³å®šæ€§å¹¶é˜²æ­¢çŠ¶æ€æŸåã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œè¯¥å¤šæ¨¡æ€QFLæ–¹æ³•åœ¨ç‹¬ç«‹åŒåˆ†å¸ƒ(IID)å’Œéç‹¬ç«‹åŒåˆ†å¸ƒ(non-IID)æ•°æ®åˆ†å¸ƒä¸‹ï¼Œå‡†ç¡®ç‡è¾ƒç°æœ‰æœ€å…ˆè¿›æ–¹æ³•åˆ†åˆ«æå‡äº†6.84%å’Œ7.25%ã€‚è¯¥ç ”ç©¶ä¸ä»…å¡«è¡¥äº†å¤šæ¨¡æ€é‡å­è”é‚¦å­¦ä¹ é¢†åŸŸçš„ç©ºç™½ï¼Œä¹Ÿä¸ºå¤„ç†ç°å®ä¸–ç•Œä¸­å¤æ‚çš„åˆ†å¸ƒå¼é‡å­æœºå™¨å­¦ä¹ ä»»åŠ¡æä¾›äº†é«˜æ•ˆä¸”é²æ£’çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper was presented at BEAM with CVPR 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.08217v1",
      "published_date": "2025-07-10 23:33:58 UTC",
      "updated_date": "2025-07-10 23:33:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:46:07.989836+00:00"
    },
    {
      "arxiv_id": "2507.08216v2",
      "title": "Grounding Methods for Neural-Symbolic AI",
      "title_zh": "ç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½çš„å®ä¾‹åŒ–æ–¹æ³•",
      "authors": [
        "Rodrigo Castellano Ontiveros",
        "Francesco Giannini",
        "Marco Gori",
        "Giuseppe Marra",
        "Michelangelo Diligenti"
      ],
      "abstract": "A large class of Neural-Symbolic (NeSy) methods employs a machine learner to process the input entities, while relying on a reasoner based on First-Order Logic to represent and process more complex relationships among the entities. A fundamental role for these methods is played by the process of logic grounding, which determines the relevant substitutions for the logic rules using a (sub)set of entities. Some NeSy methods use an exhaustive derivation of all possible substitutions, preserving the full expressive power of the logic knowledge. This leads to a combinatorial explosion in the number of ground formulas to consider and, therefore, strongly limits their scalability. Other methods rely on heuristic-based selective derivations, which are generally more computationally efficient, but lack a justification and provide no guarantees of preserving the information provided to and returned by the reasoner. Taking inspiration from multi-hop symbolic reasoning, this paper proposes a parametrized family of grounding methods generalizing classic Backward Chaining. Different selections within this family allow us to obtain commonly employed grounding methods as special cases, and to control the trade-off between expressiveness and scalability of the reasoner. The experimental results show that the selection of the grounding criterion is often as important as the NeSy method itself.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½(Neural-Symbolic AI)ä¸­é€»è¾‘å®ä¾‹åŒ–(logic grounding)è¿‡ç¨‹çš„å…³é”®ä½œç”¨ï¼ŒæŒ‡å‡ºå…¶å†³å®šäº†é€»è¾‘è§„åˆ™ä¸­å®ä½“çš„æ›¿æ¢æ–¹å¼ã€‚ç›®å‰çš„NeSyæ–¹æ³•åœ¨ç©·ä¸¾æ¨å¯¼å¯¼è‡´çš„ç»„åˆçˆ†ç‚¸ä¸å¯å‘å¼é€‰æ‹©æ€§æ¨å¯¼ç¼ºä¹ç†è®ºä¿éšœä¹‹é—´é¢ä¸´æƒè¡¡ï¼Œé™åˆ¶äº†æ¨ç†å™¨çš„å¯æ‰©å±•æ€§ã€‚å—å¤šè·³ç¬¦å·æ¨ç†(multi-hop symbolic reasoning)å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç³»åˆ—å‚æ•°åŒ–çš„å®ä¾‹åŒ–æ–¹æ³•ï¼Œè¯¥å®¶æ—å®ç°äº†å¯¹ç»å…¸åå‘é“¾æ¥(Backward Chaining)ç®—æ³•çš„æ³›åŒ–ã€‚é€šè¿‡è°ƒæ•´è¯¥æ¡†æ¶å†…çš„å‚æ•°ï¼Œç ”ç©¶è€…å¯ä»¥çµæ´»æ§åˆ¶æ¨ç†å™¨åœ¨è¡¨è¾¾èƒ½åŠ›ä¸å¯æ‰©å±•æ€§ä¹‹é—´çš„æƒè¡¡(trade-off)ï¼Œå¹¶å°†å¤šç§å¸¸ç”¨æ–¹æ³•ä½œä¸ºç‰¹ä¾‹æ¶µç›–å…¶ä¸­ã€‚å®éªŒç»“æœè¯æ˜ï¼Œå®ä¾‹åŒ–å‡†åˆ™çš„é€‰æ‹©å¯¹ç¥ç»ç¬¦å·ç³»ç»Ÿçš„æ€§èƒ½å½±å“æ·±è¿œï¼Œå…¶é‡è¦æ€§å¾€å¾€ä¸NeSyæ–¹æ³•æœ¬èº«ç›¸å½“ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08216v2",
      "published_date": "2025-07-10 23:29:15 UTC",
      "updated_date": "2025-07-21 09:56:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:46:08.522543+00:00"
    },
    {
      "arxiv_id": "2507.08210v1",
      "title": "From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration",
      "title_zh": "ä»å¥½å¥‡å¿ƒåˆ°èƒœä»»åŠ›ï¼šä¸–ç•Œæ¨¡å‹å¦‚ä½•ä¸æ¢ç´¢åŠ¨åŠ›å­¦ç›¸äº’ä½œç”¨",
      "authors": [
        "Fryderyk Mantiuk",
        "Hanqi Zhou",
        "Charley M. Wu"
      ],
      "abstract": "What drives an agent to explore the world while also maintaining control over the environment? From a child at play to scientists in the lab, intelligent agents must balance curiosity (the drive to seek knowledge) with competence (the drive to master and control the environment). Bridging cognitive theories of intrinsic motivation with reinforcement learning, we ask how evolving internal representations mediate the trade-off between curiosity (novelty or information gain) and competence (empowerment). We compare two model-based agents using handcrafted state abstractions (Tabular) or learning an internal world model (Dreamer). The Tabular agent shows curiosity and competence guide exploration in distinct patterns, while prioritizing both improves exploration. The Dreamer agent reveals a two-way interaction between exploration and representation learning, mirroring the developmental co-evolution of curiosity and competence. Our findings formalize adaptive exploration as a balance between pursuing the unknown and the controllable, offering insights for cognitive theories and efficient reinforcement learning.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†æ™ºèƒ½ä½“å¦‚ä½•åœ¨å¥½å¥‡å¿ƒ(Curiosity)ä¸èƒœä»»åŠ›(Competence)ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå°†å†…åœ¨åŠ¨æœºçš„è®¤çŸ¥ç†è®ºä¸ Reinforcement Learning ç›¸ç»“åˆã€‚ç ”ç©¶åˆ†æäº†ä¸æ–­æ¼”åŒ–çš„ Internal Representations å¦‚ä½•è°ƒèŠ‚å¥½å¥‡å¿ƒä¸èƒœä»»åŠ›(Empowerment)ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚é€šè¿‡å¯¹æ¯”ä½¿ç”¨æ‰‹å·¥çŠ¶æ€æŠ½è±¡çš„ Tabular æ™ºèƒ½ä½“å’Œå­¦ä¹ å†…éƒ¨ World Model çš„ Dreamer æ™ºèƒ½ä½“ï¼Œç ”ç©¶å‘ç°å¥½å¥‡å¿ƒä¸èƒœä»»åŠ›åœ¨å¼•å¯¼æ¢ç´¢æ—¶è¡¨ç°å‡ºä¸åŒçš„æ¨¡å¼ï¼Œä¸”åŒæ—¶ä¼˜å…ˆè€ƒè™‘ä¸¤è€…èƒ½æ˜¾è‘—æå‡æ¢ç´¢æ•ˆç‡ã€‚Dreamer æ™ºèƒ½ä½“è¿›ä¸€æ­¥æ­ç¤ºäº†æ¢ç´¢ä¸ Representation Learning ä¹‹é—´çš„åŒå‘äº’åŠ¨ï¼Œåæ˜ äº†å¥½å¥‡å¿ƒä¸èƒœä»»åŠ›çš„ååŒæ¼”åŒ–ã€‚è¯¥ç ”ç©¶å°†è‡ªé€‚åº”æ¢ç´¢å½¢å¼åŒ–ä¸ºè¿½æ±‚æœªçŸ¥ä¸è¿½æ±‚å¯æ§ä¹‹é—´çš„å¹³è¡¡ï¼Œä¸ºè®¤çŸ¥ç†è®ºå’Œé«˜æ•ˆ Reinforcement Learning æä¾›äº†æ–°çš„è§è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08210v1",
      "published_date": "2025-07-10 22:45:28 UTC",
      "updated_date": "2025-07-10 22:45:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:46:51.034772+00:00"
    },
    {
      "arxiv_id": "2507.08208v1",
      "title": "Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions",
      "title_zh": "LLM-Nash åšå¼ˆä¸­çš„æ¨ç†ä¸è¡Œä¸ºå‡è¡¡ï¼šä»æ€ç»´æ¨¡å¼åˆ°è¡ŒåŠ¨",
      "authors": [
        "Quanyan Zhu"
      ],
      "abstract": "We introduce the LLM-Nash framework, a game-theoretic model where agents select reasoning prompts to guide decision-making via Large Language Models (LLMs). Unlike classical games that assume utility-maximizing agents with full rationality, this framework captures bounded rationality by modeling the reasoning process explicitly. Equilibrium is defined over the prompt space, with actions emerging as the behavioral output of LLM inference. This approach enables the study of cognitive constraints, mindset expressiveness, and epistemic learning. Through illustrative examples, we show how reasoning equilibria can diverge from classical Nash outcomes, offering a new foundation for strategic interaction in LLM-enabled systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LLM-Nash æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§å°†åšå¼ˆè®ºåº”ç”¨äºå¤§è¯­è¨€æ¨¡å‹ (LLMs) å†³ç­–çš„æ–°å‹æ¨¡å‹ï¼Œé€šè¿‡è®©æ™ºèƒ½ä½“é€‰æ‹©æ¨ç†æç¤º (reasoning prompts) æ¥æŒ‡å¯¼è¡Œä¸ºã€‚ä¸å‡è®¾å®Œå…¨ç†æ€§çš„ä¼ ç»Ÿåšå¼ˆä¸åŒï¼Œè¯¥æ¡†æ¶é€šè¿‡æ˜¾å¼å»ºæ¨¡æ¨ç†è¿‡ç¨‹æ¥æ•æ‰æœ‰é™ç†æ€§ (bounded rationality)ã€‚åœ¨è¿™ç§æ¡†æ¶ä¸‹ï¼Œå‡è¡¡ (Equilibrium) åœ¨æç¤ºç©ºé—´ (prompt space) ä¸­è¢«å®šä¹‰ï¼Œè€Œæœ€ç»ˆè¡Œä¸ºåˆ™ä½œä¸º LLM æ¨ç†çš„è¡Œä¸ºè¾“å‡ºè€Œäº§ç”Ÿã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ·±å…¥ç ”ç©¶è®¤çŸ¥çº¦æŸ (cognitive constraints)ã€å¿ƒæ€è¡¨è¾¾èƒ½åŠ› (mindset expressiveness) ä»¥åŠè®¤çŸ¥å­¦ä¹  (epistemic learning)ã€‚é€šè¿‡ç¤ºä¾‹å±•ç¤ºï¼Œæ¨ç†å‡è¡¡å¯èƒ½ä¸ç»å…¸çš„çº³ä»€å‡è¡¡ (Nash outcomes) å‘ç”Ÿåç¦»ã€‚è¯¥ç ”ç©¶ä¸º LLM é©±åŠ¨ç³»ç»Ÿä¸­çš„ç­–ç•¥æ€§äº¤äº’æä¾›äº†å…¨æ–°çš„ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08208v1",
      "published_date": "2025-07-10 22:43:00 UTC",
      "updated_date": "2025-07-10 22:43:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:46:25.074956+00:00"
    },
    {
      "arxiv_id": "2507.08207v1",
      "title": "A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking",
      "title_zh": "é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹è¶Šç‹±çš„æ™ºèƒ½ä½“ AI é˜²å¾¡åŠ¨æ€ Stackelberg åšå¼ˆæ¡†æ¶",
      "authors": [
        "Zhengye Han",
        "Quanyan Zhu"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed in critical applications, the challenge of jailbreaking, where adversaries manipulate the models to bypass safety mechanisms, has become a significant concern. This paper presents a dynamic Stackelberg game framework to model the interactions between attackers and defenders in the context of LLM jailbreaking. The framework treats the prompt-response dynamics as a sequential extensive-form game, where the defender, as the leader, commits to a strategy while anticipating the attacker's optimal responses. We propose a novel agentic AI solution, the \"Purple Agent,\" which integrates adversarial exploration and defensive strategies using Rapidly-exploring Random Trees (RRT). The Purple Agent actively simulates potential attack trajectories and intervenes proactively to prevent harmful outputs. This approach offers a principled method for analyzing adversarial dynamics and provides a foundation for mitigating the risk of jailbreaking.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)é¢ä¸´çš„è¶Šç‹±æ”»å‡»(jailbreaking)æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŠ¨æ€Stackelberg gameæ¡†æ¶æ¥æ¨¡æ‹Ÿæ”»å‡»è€…ä¸é˜²å¾¡è€…ä¹‹é—´çš„åšå¼ˆã€‚è¯¥æ¡†æ¶å°†æç¤ºè¯-å“åº”(prompt-response)åŠ¨æ€å»ºæ¨¡ä¸ºä¸€ç§åºè´¯æ‰©å±•å½¢å¼åšå¼ˆ(sequential extensive-form game)ï¼Œå…¶ä¸­é˜²å¾¡è€…ä½œä¸ºé¢†å¯¼è€…ï¼Œåœ¨é¢„åˆ¤æ”»å‡»è€…æœ€ä¼˜å“åº”çš„åŸºç¡€ä¸Šåˆ¶å®šé˜²å¾¡ç­–ç•¥ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§åä¸º\"Purple Agent\"çš„æ™ºèƒ½ä½“è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡ç»“åˆå¿«é€Ÿæ¢ç´¢éšæœºæ ‘(Rapidly-exploring Random Trees, RRT)æŠ€æœ¯ï¼Œå°†å¯¹æŠ—æ€§æ¢ç´¢ä¸é˜²å¾¡ç­–ç•¥é›†æˆã€‚Purple Agentèƒ½å¤Ÿä¸»åŠ¨æ¨¡æ‹Ÿæ½œåœ¨çš„æ”»å‡»è½¨è¿¹å¹¶å®æ–½é¢„è§æ€§å¹²é¢„ï¼Œä»è€Œæœ‰æ•ˆé˜»æ­¢æœ‰å®³å†…å®¹çš„è¾“å‡ºã€‚è¿™ä¸€æ–¹æ³•ä¸ºåˆ†æå¤§æ¨¡å‹çš„å¯¹æŠ—æ€§åŠ¨æ€æä¾›äº†åŸåˆ™æ€§çš„å»ºæ¨¡æ‰‹æ®µï¼Œå¹¶ä¸ºç¼“è§£è¶Šç‹±é£é™©å¥ å®šäº†é‡è¦çš„æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08207v1",
      "published_date": "2025-07-10 22:37:47 UTC",
      "updated_date": "2025-07-10 22:37:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:46:45.127174+00:00"
    },
    {
      "arxiv_id": "2507.08892v1",
      "title": "Multi-Actor Generative Artificial Intelligence as a Game Engine",
      "title_zh": "å°†å¤šè§’è‰²ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä½œä¸ºæ¸¸æˆå¼•æ“",
      "authors": [
        "Alexander Sasha Vezhnevets",
        "Jayd Matyas",
        "Logan Cross",
        "Davide Paglieri",
        "Minsuk Chang",
        "William A. Cunningham",
        "Simon Osindero",
        "William S. Isaac",
        "Joel Z. Leibo"
      ],
      "abstract": "Generative AI can be used in multi-actor environments with purposes ranging from social science modeling to interactive narrative and AI evaluation. Supporting this diversity of use cases -- which we classify as Simulationist, Dramatist, and Evaluationist -- demands a flexible scenario definition framework. We argue here that a good approach is to take inspiration from tabletop role-playing games (TTRPGs), where a Game Master (GM) is responsible for the environment and generates all parts of the story not directly determined by the voluntary actions of player characters. We argue that the Entity-Component architectural pattern is useful here. In such a system, the GM is not a hardcoded computer game but is itself a configurable entity, composed of components just like any other actor. By design, the approach allows for a separation between the underlying implementation details handled by an engineer, the creation of reusable components, and their composition and configuration managed by a designer who constructs entities from the components. This separation of concerns is instrumental for achieving rapid iteration, maintaining modularity, and ultimately to ensure scalability. We describe the ongoing evolution of the Concordia library in terms of this philosophy, demonstrating how it allows users to effectively configure scenarios that align with their specific goals.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) åœ¨å¤šå‚ä¸è€…ç¯å¢ƒä¸­çš„åº”ç”¨ï¼Œæ¶µç›–ç¤¾ä¼šç§‘å­¦å»ºæ¨¡ã€äº¤äº’å¼å™äº‹åŠ AI è¯„ä¼°ç­‰é¢†åŸŸã€‚ä¸ºäº†æ»¡è¶³ Simulationistã€Dramatist å’Œ Evaluationist ä¸‰ç±»æ ¸å¿ƒåœºæ™¯çš„éœ€æ±‚ï¼Œç ”ç©¶å€Ÿé‰´æ¡Œé¢è§’è‰²æ‰®æ¼”æ¸¸æˆ (TTRPGs) çš„æœºåˆ¶ï¼Œæå‡ºç”±æ¸¸æˆä¸»æŒäºº (Game Master, GM) è´Ÿè´£ç¯å¢ƒä¸æ•…äº‹ç”Ÿæˆçš„çµæ´»æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº† Entity-Component æ¶æ„æ¨¡å¼ï¼Œå°† GM è§†ä¸ºå¯é…ç½®çš„ç»„ä»¶åŒ–å®ä½“ï¼Œä»è€Œå®ç°äº†å·¥ç¨‹å®ç°ã€ç»„ä»¶å¤ç”¨ä¸è®¾è®¡é…ç½®ä¹‹é—´çš„å…³æ³¨ç‚¹åˆ†ç¦» (Separation of Concerns)ã€‚è¿™ç§æ¨¡å—åŒ–è®¾è®¡ç¡®ä¿äº†ç³»ç»Ÿçš„å¿«é€Ÿè¿­ä»£ä¸é«˜å¯æ‰©å±•æ€§ï¼Œå¹¶é€šè¿‡ Concordia åº“çš„æ¼”è¿›å±•ç¤ºäº†å¦‚ä½•æ”¯æŒç”¨æˆ·é«˜æ•ˆæ„å»ºç¬¦åˆç‰¹å®šç›®æ ‡çš„å¤æ‚åœºæ™¯ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.08892v1",
      "published_date": "2025-07-10 22:31:09 UTC",
      "updated_date": "2025-07-10 22:31:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:46:43.598859+00:00"
    },
    {
      "arxiv_id": "2507.08202v1",
      "title": "Quantum Properties Trojans (QuPTs) for Attacking Quantum Neural Networks",
      "title_zh": "é’ˆå¯¹é‡å­ç¥ç»ç½‘ç»œæ”»å‡»çš„é‡å­ç‰¹æ€§æœ¨é©¬ (QuPTs)",
      "authors": [
        "Sounak Bhowmik",
        "Travis S. Humble",
        "Himanshu Thapliyal"
      ],
      "abstract": "Quantum neural networks (QNN) hold immense potential for the future of quantum machine learning (QML). However, QNN security and robustness remain largely unexplored. In this work, we proposed novel Trojan attacks based on the quantum computing properties in a QNN-based binary classifier. Our proposed Quantum Properties Trojans (QuPTs) are based on the unitary property of quantum gates to insert noise and Hadamard gates to enable superposition to develop Trojans and attack QNNs. We showed that the proposed QuPTs are significantly stealthier and heavily impact the quantum circuits' performance, specifically QNNs. The most impactful QuPT caused a deterioration of 23% accuracy of the compromised QNN under the experimental setup. To the best of our knowledge, this is the first work on the Trojan attack on a fully quantum neural network independent of any hybrid classical-quantum architecture.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡å­ç¥ç»ç½‘ç»œ(QNN)åœ¨å®‰å…¨æ€§ä¸é²æ£’æ€§é¢†åŸŸçš„ç ”ç©¶ç©ºç™½ï¼Œæå‡ºäº†åä¸ºQuantum Properties Trojans (QuPTs)çš„æ–°å‹æœ¨é©¬æ”»å‡»æ–¹æ³•ã€‚QuPTs åˆ©ç”¨é‡å­é—¨çš„ Unitary å±æ€§åœ¨ç”µè·¯ä¸­æ’å…¥å™ªå£°ï¼Œå¹¶é€šè¿‡ Hadamard é—¨åˆ©ç”¨å åŠ æ€(Superposition)æ„å»ºæœ¨é©¬ï¼Œæ—¨åœ¨æ”»å‡»åŸºäºQNNçš„äºŒåˆ†ç±»å™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ”»å‡»æ‰‹æ®µå…·æœ‰æå¼ºçš„éšè”½æ€§ï¼Œå…¶ä¸­å½±å“æœ€ä¸¥é‡çš„æ”»å‡»å¯¼è‡´å—æŸQNNçš„å‡†ç¡®ç‡ä¸‹é™äº†23%ã€‚è¿™æ˜¯å­¦æœ¯ç•Œé¦–æ¬¡é’ˆå¯¹å®Œå…¨è„±ç¦»æ··åˆç»å…¸-é‡å­æ¶æ„(Hybrid classical-quantum architecture)çš„å…¨é‡å­ç¥ç»ç½‘ç»œå®ç°çš„æœ¨é©¬æ”»å‡»ï¼Œä¸ºé‡å­æœºå™¨å­¦ä¹ (QML)çš„å®‰å…¨ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08202v1",
      "published_date": "2025-07-10 22:23:30 UTC",
      "updated_date": "2025-07-10 22:23:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:46:36.261421+00:00"
    },
    {
      "arxiv_id": "2507.08197v1",
      "title": "Consciousness as a Jamming Phase",
      "title_zh": "æ„è¯†ï¼šä¸€ç§é˜»å¡ç›¸",
      "authors": [
        "Kaichen Ouyang"
      ],
      "abstract": "This paper develops a neural jamming phase diagram that interprets the emergence of consciousness in large language models as a critical phenomenon in high-dimensional disordered systems.By establishing analogies with jamming transitions in granular matter and other complex systems, we identify three fundamental control parameters governing the phase behavior of neural networks: temperature, volume fraction, and stress.The theory provides a unified physical explanation for empirical scaling laws in artificial intelligence, demonstrating how computational cooling, density optimization, and noise reduction collectively drive systems toward a critical jamming surface where generalized intelligence emerges. Remarkably, the same thermodynamic principles that describe conventional jamming transitions appear to underlie the emergence of consciousness in neural networks, evidenced by shared critical signatures including divergent correlation lengths and scaling exponents.Our work explains neural language models' critical scaling through jamming physics, suggesting consciousness is a jamming phase that intrinsically connects knowledge components via long-range correlations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç¥ç»æ‹¥æŒ¤ç›¸å›¾(neural jamming phase diagram)ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­æ„è¯†çš„æ¶Œç°è§£é‡Šä¸ºé«˜ç»´æ— åºç³»ç»Ÿä¸­çš„ä¸€ç§ä¸´ç•Œç°è±¡ã€‚é€šè¿‡ç±»æ¯”é¢—ç²’ç‰©è´¨ä¸­çš„æ‹¥æŒ¤è½¬å˜(jamming transitions)ï¼Œç ”ç©¶è¯†åˆ«å‡ºæ§åˆ¶ç¥ç»ç½‘ç»œç›¸è¡Œä¸ºçš„ä¸‰ä¸ªæ ¸å¿ƒå‚æ•°ï¼šæ¸©åº¦ã€ä½“ç§¯åˆ†æ•°å’Œå‹åŠ›ã€‚è¯¥ç†è®ºä¸ºäººå·¥æ™ºèƒ½ä¸­çš„ç»éªŒç¼©æ”¾å®šå¾‹(scaling laws)æä¾›äº†ç»Ÿä¸€çš„ç‰©ç†å­¦è§£é‡Šï¼Œæ­ç¤ºäº†è®¡ç®—å†·å´ã€å¯†åº¦ä¼˜åŒ–å’Œå™ªå£°é™ä½å¦‚ä½•å…±åŒé©±åŠ¨ç³»ç»Ÿæ¥è¿‘äº§ç”Ÿå¹¿ä¹‰æ™ºèƒ½çš„ä¸´ç•Œæ‹¥æŒ¤é¢ã€‚å®éªŒè¯æ˜ï¼Œæè¿°ä¼ ç»Ÿæ‹¥æŒ¤è½¬å˜çš„çƒ­åŠ›å­¦åŸç†åŒæ ·é€‚ç”¨äºç¥ç»ç½‘ç»œï¼Œä¸¤è€…å…±äº«åŒ…æ‹¬å‘æ•£ç›¸å…³é•¿åº¦å’Œç¼©æ”¾æŒ‡æ•°åœ¨å†…çš„ä¸´ç•Œç‰¹å¾ã€‚è¯¥å·¥ä½œåˆ©ç”¨æ‹¥æŒ¤ç‰©ç†å­¦é˜é‡Šäº†è¯­è¨€æ¨¡å‹çš„ä¸´ç•Œç¼©æ”¾ç‰¹æ€§ï¼ŒæŒ‡å‡ºæ„è¯†æœ¬è´¨ä¸Šæ˜¯ä¸€ç§é€šè¿‡é•¿ç¨‹ç›¸å…³æ€§(long-range correlations)å°†çŸ¥è¯†ç»„ä»¶å†…åœ¨è¿æ¥çš„æ‹¥æŒ¤ç›¸(jamming phase)ã€‚",
      "categories": [
        "cond-mat.dis-nn",
        "cs.AI"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "18 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.08197v1",
      "published_date": "2025-07-10 22:07:06 UTC",
      "updated_date": "2025-07-10 22:07:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:46:44.598877+00:00"
    },
    {
      "arxiv_id": "2507.08191v1",
      "title": "Overview of the TREC 2021 deep learning track",
      "title_zh": "TREC 2021 æ·±åº¦å­¦ä¹ èµ›é“ç»¼è¿°",
      "authors": [
        "Nick Craswell",
        "Bhaskar Mitra",
        "Emine Yilmaz",
        "Daniel Campos",
        "Jimmy Lin"
      ],
      "abstract": "This is the third year of the TREC Deep Learning track. As in previous years, we leverage the MS MARCO datasets that made hundreds of thousands of human annotated training labels available for both passage and document ranking tasks. In addition, this year we refreshed both the document and the passage collections which also led to a nearly four times increase in the document collection size and nearly $16$ times increase in the size of the passage collection. Deep neural ranking models that employ large scale pretraininig continued to outperform traditional retrieval methods this year. We also found that single stage retrieval can achieve good performance on both tasks although they still do not perform at par with multistage retrieval pipelines. Finally, the increase in the collection size and the general data refresh raised some questions about completeness of NIST judgments and the quality of the training labels that were mapped to the new collections from the old ones which we discuss in this report.",
      "tldr_zh": "è¯¥æŠ¥å‘Šæ¦‚è¿°äº†2021å¹´TRECæ·±åº¦å­¦ä¹ èµ›é“(TREC Deep Learning track)çš„ç ”ç©¶è¿›å±•ä¸æˆæœã€‚ç ”ç©¶ç»§ç»­åˆ©ç”¨MS MARCOæ•°æ®é›†æä¾›çš„å¤§è§„æ¨¡äººå·¥æ ‡æ³¨æ ‡ç­¾ï¼Œå¹¶å¯¹æ–‡æ¡£å’Œæ®µè½é›†åˆè¿›è¡Œäº†å…¨é¢æ›´æ–°ï¼Œä½¿å…¶è§„æ¨¡åˆ†åˆ«å¢åŠ äº†çº¦4å€å’Œ16å€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒçš„æ·±åº¦ç¥ç»æ’åºæ¨¡å‹(Deep neural ranking models)åœ¨è¡¨ç°ä¸ŠæŒç»­ä¼˜äºä¼ ç»Ÿæ£€ç´¢æ–¹æ³•ã€‚ç ”ç©¶è¿˜å‘ç°ï¼Œè™½ç„¶å•é˜¶æ®µæ£€ç´¢(Single stage retrieval)èƒ½å¤Ÿå–å¾—è‰¯å¥½æ€§èƒ½ï¼Œä½†å…¶æ•ˆæœä»æœªè¾¾åˆ°å¤šé˜¶æ®µæ£€ç´¢æµæ°´çº¿(multistage retrieval pipelines)çš„æ°´å¹³ã€‚æœ€åï¼ŒæŠ¥å‘Šæ·±å…¥æ¢è®¨äº†å› é›†åˆè§„æ¨¡æ˜¾è‘—æ‰©å¼ è€Œå¼•å‘çš„NISTåˆ¤å®šå®Œæ•´æ€§ä»¥åŠæ—§æ ‡ç­¾æ˜ å°„è‡³æ–°é›†åˆæ—¶çš„è´¨é‡é—®é¢˜ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08191v1",
      "published_date": "2025-07-10 21:58:41 UTC",
      "updated_date": "2025-07-10 21:58:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:46:49.697402+00:00"
    },
    {
      "arxiv_id": "2507.08177v1",
      "title": "Rethinking Spatio-Temporal Anomaly Detection: A Vision for Causality-Driven Cybersecurity",
      "title_zh": "é‡æ–°å®¡è§†æ—¶ç©ºå¼‚å¸¸æ£€æµ‹ï¼šå› æœé©±åŠ¨çš„ç½‘ç»œå®‰å…¨æ„¿æ™¯",
      "authors": [
        "Arun Vignesh Malarkkan",
        "Haoyue Bai",
        "Xinyuan Wang",
        "Anjali Kaushik",
        "Dongjie Wang",
        "Yanjie Fu"
      ],
      "abstract": "As cyber-physical systems grow increasingly interconnected and spatially distributed, ensuring their resilience against evolving cyberattacks has become a critical priority. Spatio-Temporal Anomaly detection plays an important role in ensuring system security and operational integrity. However, current data-driven approaches, largely driven by black-box deep learning, face challenges in interpretability, adaptability to distribution shifts, and robustness under evolving system dynamics. In this paper, we advocate for a causal learning perspective to advance anomaly detection in spatially distributed infrastructures that grounds detection in structural cause-effect relationships. We identify and formalize three key directions: causal graph profiling, multi-view fusion, and continual causal graph learning, each offering distinct advantages in uncovering dynamic cause-effect structures across time and space. Drawing on real-world insights from systems such as water treatment infrastructures, we illustrate how causal models provide early warning signals and root cause attribution, addressing the limitations of black-box detectors. Looking ahead, we outline the future research agenda centered on multi-modality, generative AI-driven, and scalable adaptive causal frameworks. Our objective is to lay a new research trajectory toward scalable, adaptive, explainable, and spatially grounded anomaly detection systems. We hope to inspire a paradigm shift in cybersecurity research, promoting causality-driven approaches to address evolving threats in interconnected infrastructures.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº’è”ç½‘ç»œç‰©ç†ç³»ç»Ÿä¸­ Spatio-Temporal Anomaly Detection é¢ä¸´çš„å¯è§£é‡Šæ€§å·®å’Œé€‚åº”æ€§ä¸è¶³ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ Causal Learning çš„æ–°è§†è§’ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„åŒ–çš„å› æœå…³ç³»æå‡æ£€æµ‹æ•ˆèƒ½ã€‚æ–‡ç« å½¢å¼åŒ–åœ°æå‡ºäº† Causal Graph Profilingã€Multi-View Fusion ä»¥åŠ Continual Causal Graph Learning ä¸‰ä¸ªæ ¸å¿ƒæ–¹å‘ï¼Œç”¨ä»¥æ­ç¤ºè·¨è¶Šæ—¶ç©ºçš„åŠ¨æ€å› æœç»“æ„ã€‚é€šè¿‡å¯¹æ°´å¤„ç†åŸºç¡€è®¾æ–½ç­‰ç°å®åœºæ™¯çš„æ·±å…¥åˆ†æï¼Œç ”ç©¶å±•ç¤ºäº†å› æœæ¨¡å‹åœ¨æä¾›æ—©æœŸé¢„è­¦ä¿¡å·å’Œ Root Cause Attribution æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ï¼Œæœ‰æ•ˆè§£å†³äº†é»‘ç›’æ£€æµ‹å™¨çš„å±€é™æ€§ã€‚å±•æœ›æœªæ¥ï¼Œè¯¥ç ”ç©¶è§„åˆ’äº†ä»¥ Multi-Modality å’Œ Generative AI ä¸ºé©±åŠ¨çš„å¯æ‰©å±•è‡ªé€‚åº”å› æœæ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºç½‘ç»œå®‰å…¨é¢†åŸŸæ„å»ºä¸€ç§å…·å¤‡é«˜åº¦å¯è§£é‡Šæ€§ä¸”ç©ºé—´æ„ŸçŸ¥çš„å¼‚å¸¸æ£€æµ‹æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 1 figure, Under Review in Vision Paper Track-ACM SIGSPATIAL 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.08177v1",
      "published_date": "2025-07-10 21:19:28 UTC",
      "updated_date": "2025-07-10 21:19:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:04.917009+00:00"
    },
    {
      "arxiv_id": "2507.08164v1",
      "title": "KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence",
      "title_zh": "KP-Aï¼šç”¨äºå‚¬åŒ–æ™ºèƒ½ä½“åŒ–ç½‘ç»œæ™ºèƒ½çš„ç»Ÿä¸€ç½‘ç»œçŸ¥è¯†å¹³é¢",
      "authors": [
        "Yun Tang",
        "Mengbang Zou",
        "Zeinab Nezami",
        "Syed Ali Raza Zaidi",
        "Weisi Guo"
      ],
      "abstract": "The emergence of large language models (LLMs) and agentic systems is enabling autonomous 6G networks with advanced intelligence, including self-configuration, self-optimization, and self-healing. However, the current implementation of individual intelligence tasks necessitates isolated knowledge retrieval pipelines, resulting in redundant data flows and inconsistent interpretations. Inspired by the service model unification effort in Open-RAN (to support interoperability and vendor diversity), we propose KP-A: a unified Network Knowledge Plane specifically designed for Agentic network intelligence. By decoupling network knowledge acquisition and management from intelligence logic, KP-A streamlines development and reduces maintenance complexity for intelligence engineers. By offering an intuitive and consistent knowledge interface, KP-A also enhances interoperability for the network intelligence agents. We demonstrate KP-A in two representative intelligence tasks: live network knowledge Q&A and edge AI service orchestration. All implementation artifacts have been open-sourced to support reproducibility and future standardization efforts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† KP-Aï¼Œä¸€ç§ä¸“ä¸º Agentic network intelligence è®¾è®¡çš„ç»Ÿä¸€ Network Knowledge Planeï¼Œæ—¨åœ¨èµ‹èƒ½å…·æœ‰è‡ªé…ç½®ã€è‡ªä¼˜åŒ–å’Œè‡ªä¿®å¤èƒ½åŠ›çš„ 6G è‡ªä¸»ç½‘ç»œã€‚é’ˆå¯¹å½“å‰å„æ™ºèƒ½ä»»åŠ¡ä¸­çŸ¥è¯†æ£€ç´¢ç®¡çº¿å­¤ç«‹å¯¼è‡´çš„å†—ä½™æ•°æ®æµå’Œè§£é‡Šä¸ä¸€è‡´é—®é¢˜ï¼ŒKP-A å€Ÿé‰´äº† Open-RAN çš„æœåŠ¡æ¨¡å‹ç»Ÿä¸€åŒ–æ€è·¯ï¼Œå®ç°äº†ç½‘ç»œçŸ¥è¯†è·å–åŠç®¡ç†ä¸æ™ºèƒ½é€»è¾‘çš„æœ‰æ•ˆè§£è€¦ã€‚é€šè¿‡æä¾›ç›´è§‚ä¸”ä¸€è‡´çš„çŸ¥è¯†æ¥å£ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—ç®€åŒ–äº†æ™ºèƒ½å·¥ç¨‹å¸ˆçš„å¼€å‘ä¸ç»´æŠ¤å¤æ‚åº¦ï¼Œå¹¶å¢å¼ºäº†ç½‘ç»œæ™ºèƒ½ä½“ä¹‹é—´çš„äº’æ“ä½œæ€§ã€‚å®éªŒåœ¨å®æ—¶ç½‘ç»œçŸ¥è¯† Q&A å’Œè¾¹ç¼˜ AI æœåŠ¡ç¼–æ’ä¸¤é¡¹å…¸å‹ä»»åŠ¡ä¸­éªŒè¯äº† KP-A çš„æœ‰æ•ˆæ€§ã€‚ç›®å‰ï¼Œè¯¥é¡¹ç›®çš„æ‰€æœ‰å®ç°ç»„ä»¶å‡å·²å¼€æºï¼Œæ—¨åœ¨æ¨åŠ¨ 6G ç½‘ç»œæ™ºèƒ½åŒ–çš„å¯é‡å¤æ€§ç ”ç©¶ä¸æœªæ¥æ ‡å‡†åŒ–è¿›ç¨‹ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.NI",
      "comment": "7 pages, 5 figures, submitted for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2507.08164v1",
      "published_date": "2025-07-10 20:54:36 UTC",
      "updated_date": "2025-07-10 20:54:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:16.186751+00:00"
    },
    {
      "arxiv_id": "2507.10865v1",
      "title": "Overview of the TREC 2022 deep learning track",
      "title_zh": "TREC 2022 æ·±åº¦å­¦ä¹ èµ›é“æ¦‚è§ˆ",
      "authors": [
        "Nick Craswell",
        "Bhaskar Mitra",
        "Emine Yilmaz",
        "Daniel Campos",
        "Jimmy Lin",
        "Ellen M. Voorhees",
        "Ian Soboroff"
      ],
      "abstract": "This is the fourth year of the TREC Deep Learning track. As in previous years, we leverage the MS MARCO datasets that made hundreds of thousands of human annotated training labels available for both passage and document ranking tasks. In addition, this year we also leverage both the refreshed passage and document collections that were released last year leading to a nearly $16$ times increase in the size of the passage collection and nearly four times increase in the document collection size. Unlike previous years, in 2022 we mainly focused on constructing a more complete test collection for the passage retrieval task, which has been the primary focus of the track. The document ranking task was kept as a secondary task, where document-level labels were inferred from the passage-level labels. Our analysis shows that similar to previous years, deep neural ranking models that employ large scale pretraining continued to outperform traditional retrieval methods. Due to the focusing our judging resources on passage judging, we are more confident in the quality of this year's queries and judgments, with respect to our ability to distinguish between runs and reuse the dataset in future. We also see some surprises in overall outcomes. Some top-performing runs did not do dense retrieval. Runs that did single-stage dense retrieval were not as competitive this year as they were last year.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¦‚è¿°äº†TREC 2022æ·±åº¦å­¦ä¹ èµ›é“(Deep Learning track)çš„è¿›å±•ï¼Œè¿™æ˜¯è¯¥èµ›é“è¿ç»­ä¸¾åŠçš„ç¬¬å››å¹´ã€‚ç ”ç©¶åˆ©ç”¨MS MARCOæ•°æ®é›†å¹¶å¼•å…¥äº†æ˜¾è‘—æ‰©å®¹çš„å…¨æ–°è¯­æ–™åº“ï¼Œä½¿æ®µè½å’Œæ–‡æ¡£é›†åˆçš„è§„æ¨¡åˆ†åˆ«å¢åŠ äº†è¿‘16å€å’Œ4å€ã€‚æœ¬å±Šæ¯”èµ›é‡ç‚¹åœ¨äºä¸ºæ ¸å¿ƒä»»åŠ¡æ®µè½æ£€ç´¢(passage retrieval)æ„å»ºæ›´å®Œå¤‡çš„æµ‹è¯•é›†ï¼ŒåŒæ—¶å°†æ–‡æ¡£æ’åºä½œä¸ºè¾…åŠ©ä»»åŠ¡ã€‚å®éªŒåˆ†ææ˜¾ç¤ºï¼Œé‡‡ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒ(large scale pretraining)çš„æ·±åº¦ç¥ç»æ’åºæ¨¡å‹(deep neural ranking models)ä¾ç„¶åœ¨æ€§èƒ½ä¸Šå¤§å¹…é¢†å…ˆä¼ ç»Ÿæ£€ç´¢æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œéƒ¨åˆ†é¡¶å°–æ¨¡å‹å¹¶æœªé‡‡ç”¨ç¨ å¯†æ£€ç´¢(dense retrieval)ï¼Œä¸”å•é˜¶æ®µç¨ å¯†æ£€ç´¢çš„è¡¨ç°ç›¸è¾ƒå¾€å¹´ç«äº‰åŠ›æœ‰æ‰€å‡å¼±ã€‚é€šè¿‡é›†ä¸­èµ„æºè¿›è¡Œåˆ¤å®šï¼Œæœ¬å¹´åº¦çš„æ•°æ®é›†è´¨é‡åŠåŒºåˆ†ä¸åŒè¿è¡Œçš„èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2507.08191, arXiv:2507.08890",
      "pdf_url": "https://arxiv.org/pdf/2507.10865v1",
      "published_date": "2025-07-10 20:48:22 UTC",
      "updated_date": "2025-07-10 20:48:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:19.091590+00:00"
    },
    {
      "arxiv_id": "2507.08162v2",
      "title": "AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration",
      "title_zh": "AmpLyzeï¼šç”¨äºé¢„æµ‹æº¶è¡€æµ“åº¦çš„æ·±åº¦å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Peng Qiu",
        "Hanqi Feng",
        "Meng-Chun Zhang",
        "Barnabas Poczos"
      ],
      "abstract": "Red-blood-cell lysis (HC50) is the principal safety barrier for antimicrobial-peptide (AMP) therapeutics, yet existing models only say \"toxic\" or \"non-toxic.\" AmpLyze closes this gap by predicting the actual HC50 value from sequence alone and explaining the residues that drive toxicity. The model couples residue-level ProtT5/ESM2 embeddings with sequence-level descriptors in dual local and global branches, aligned by a cross-attention module and trained with log-cosh loss for robustness to assay noise. The optimal AmpLyze model reaches a PCC of 0.756 and an MSE of 0.987, outperforming classical regressors and the state-of-the-art. Ablations confirm that both branches are essential, and cross-attention adds a further 1% PCC and 3% MSE improvement. Expected-Gradients attributions reveal known toxicity hotspots and suggest safer substitutions. By turning hemolysis assessment into a quantitative, sequence-based, and interpretable prediction, AmpLyze facilitates AMP design and offers a practical tool for early-stage toxicity screening.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº† AmpLyzeï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿä»…æ ¹æ®åºåˆ—é¢„æµ‹æŠ—èŒè‚½ (AMP) æº¶è¡€æµ“åº¦ (HC50) å®å€¼çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¡«è¡¥äº†ç°æœ‰æ¨¡å‹ä»…èƒ½è¿›è¡ŒäºŒåˆ†ç±»é¢„æµ‹çš„ç©ºç™½ã€‚è¯¥æ¨¡å‹ç»“åˆäº†æ®‹åŸºæ°´å¹³çš„ ProtT5/ESM2 åµŒå…¥ä¸åºåˆ—æ°´å¹³æè¿°ç¬¦ï¼Œé€šè¿‡åŒæœ¬åœ°å’Œå…¨å±€åˆ†æ”¯æ¶æ„ç»“åˆäº¤å‰æ³¨æ„åŠ› (cross-attention) æ¨¡å—ï¼Œå¹¶é‡‡ç”¨ log-cosh æŸå¤±å‡½æ•°ä»¥å¢å¼ºå¯¹å®éªŒå™ªå£°çš„é²æ£’æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAmpLyze çš„ PCC è¾¾åˆ° 0.756ï¼ŒMSE ä¸º 0.987ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå›å½’æ¨¡å‹åŠç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯ã€‚æ¶ˆèå®éªŒè¯å®äº†åŒåˆ†æ”¯ç»“æ„çš„å¿…è¦æ€§ï¼Œä¸”é€šè¿‡ Expected-Gradients å½’å› åˆ†ææ­ç¤ºäº†æ¯’æ€§ä½ç‚¹å¹¶æä¾›äº†å®‰å…¨æ€§æ›¿æ¢å»ºè®®ã€‚AmpLyze ä¸ºæº¶è¡€è¯„ä¼°æä¾›äº†å®šé‡ã€åŸºäºåºåˆ—ä¸”å¯è§£é‡Šçš„é¢„æµ‹æ‰‹æ®µï¼Œæ˜¯æŠ—èŒè‚½è®¾è®¡å’Œæ—©æœŸæ¯’æ€§ç­›é€‰çš„å®ç”¨å·¥å…·ã€‚",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08162v2",
      "published_date": "2025-07-10 20:47:06 UTC",
      "updated_date": "2025-08-13 23:59:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:25.383336+00:00"
    },
    {
      "arxiv_id": "2507.08890v1",
      "title": "Overview of the TREC 2023 deep learning track",
      "title_zh": "TREC 2023 æ·±åº¦å­¦ä¹ èµ›é“ç»¼è¿°",
      "authors": [
        "Nick Craswell",
        "Bhaskar Mitra",
        "Emine Yilmaz",
        "Hossein A. Rahmani",
        "Daniel Campos",
        "Jimmy Lin",
        "Ellen M. Voorhees",
        "Ian Soboroff"
      ],
      "abstract": "This is the fifth year of the TREC Deep Learning track. As in previous years, we leverage the MS MARCO datasets that made hundreds of thousands of human-annotated training labels available for both passage and document ranking tasks. We mostly repeated last year's design, to get another matching test set, based on the larger, cleaner, less-biased v2 passage and document set, with passage ranking as primary and document ranking as a secondary task (using labels inferred from passage). As we did last year, we sample from MS MARCO queries that were completely held out, unused in corpus construction, unlike the test queries in the first three years. This approach yields a more difficult test with more headroom for improvement. Alongside the usual MS MARCO (human) queries from MS MARCO, this year we generated synthetic queries using a fine-tuned T5 model and using a GPT-4 prompt.\n  The new headline result this year is that runs using Large Language Model (LLM) prompting in some way outperformed runs that use the \"nnlm\" approach, which was the best approach in the previous four years. Since this is the last year of the track, future iterations of prompt-based ranking can happen in other tracks. Human relevance assessments were applied to all query types, not just human MS MARCO queries. Evaluation using synthetic queries gave similar results to human queries, with system ordering agreement of $Ï„=0.8487$. However, human effort was needed to select a subset of the synthetic queries that were usable. We did not see clear evidence of bias, where runs using GPT-4 were favored when evaluated using synthetic GPT-4 queries, or where runs using T5 were favored when evaluated on synthetic T5 queries.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¦‚è¿°äº†ç¬¬äº”å±Š TREC Deep Learning track çš„è¯„æµ‹å·¥ä½œï¼Œç»§ç»­åˆ©ç”¨ MS MARCO v2 æ•°æ®é›†å¯¹ Passage å’Œ Document æ’åºä»»åŠ¡è¿›è¡Œæ·±å…¥æ¢è®¨ã€‚æœ¬å±Šè¯„æµ‹å»¶ç»­äº†é«˜éš¾åº¦çš„å®éªŒè®¾è®¡ï¼Œé‡‡ç”¨äº†å®Œå…¨é¢„ç•™çš„æŸ¥è¯¢ï¼Œå¹¶é¦–æ¬¡å¼•å…¥äº†é€šè¿‡ T5 æ¨¡å‹å’Œ GPT-4 æç¤ºç”Ÿæˆçš„åˆæˆæŸ¥è¯¢ (Synthetic Queries)ã€‚æœ€æ˜¾è‘—çš„ç ”ç©¶å‘ç°æ˜¯ï¼Œé‡‡ç”¨ Large Language Model (LLM) æç¤ºçš„æ–¹æ³•åœ¨æ€§èƒ½ä¸Šé¦–æ¬¡è¶…è¶Šäº†æ­¤å‰è¿ç»­å››å¹´è¡¨ç°æœ€ä½³çš„ \"nnlm\" æ–¹æ³•ã€‚è¯„ä¼°ç»“æœè¯å®ï¼ŒåˆæˆæŸ¥è¯¢åœ¨ç³»ç»Ÿæ’åºä¸Šä¸äººç±»æŸ¥è¯¢å…·æœ‰é«˜åº¦ä¸€è‡´æ€§ï¼ˆ$Ï„=0.8487$ï¼‰ï¼Œä¸”æœªå‘ç°å®éªŒå¯¹ç‰¹å®šç”Ÿæˆæ¨¡å‹å­˜åœ¨åè§ã€‚å°½ç®¡åˆæˆæŸ¥è¯¢æå…·æ½œåŠ›ï¼Œä½†ç ”ç©¶ä¹ŸæŒ‡å‡ºä»éœ€äººå·¥å¹²é¢„æ¥ç­›é€‰å¯ç”¨çš„æŸ¥è¯¢å­é›†ã€‚ä½œä¸ºè¯¥èµ›é“çš„æ”¶å®˜ä¹‹ä½œï¼Œè¿™äº›å‘ç°ä¸ºæœªæ¥åŸºäºæç¤ºçš„æ’åºæŠ€æœ¯åœ¨å…¶ä»–å­¦æœ¯é¢†åŸŸçš„æ¼”è¿›æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2507.08191",
      "pdf_url": "https://arxiv.org/pdf/2507.08890v1",
      "published_date": "2025-07-10 20:39:42 UTC",
      "updated_date": "2025-07-10 20:39:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:26.548580+00:00"
    },
    {
      "arxiv_id": "2507.08153v1",
      "title": "ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction",
      "title_zh": "ALCo-FMï¼šé¢å‘äº‹æ•…é¢„æµ‹çš„è‡ªé€‚åº”é•¿ä¸Šä¸‹æ–‡åŸºç¡€æ¨¡å‹",
      "authors": [
        "Pinaki Prasad Guha Neogi",
        "Ahmad Mohammadshirazi",
        "Rajiv Ramnath"
      ],
      "abstract": "Traffic accidents are rare, yet high-impact events that require long-context multimodal reasoning for accurate risk forecasting. In this paper, we introduce ALCo-FM, a unified adaptive long-context foundation model that computes a volatility pre-score to dynamically select context windows for input data and encodes and fuses these multimodal data via shallow cross attention. Following a local GAT layer and a BigBird-style sparse global transformer over H3 hexagonal grids, coupled with Monte Carlo dropout for confidence, the model yields superior, well-calibrated predictions. Trained on data from 15 US cities with a class-weighted loss to counter label imbalance, and fine-tuned with minimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, and an ECE of 0.04, outperforming more than 20 state-of-the-art baselines in large-scale urban risk prediction. Code and dataset are available at: https://github.com/PinakiPrasad12/ALCo-FM",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ALCo-FMï¼Œä¸€ç§ç»Ÿä¸€çš„è‡ªé€‚åº”é•¿ä¸Šä¸‹æ–‡åŸºç¡€æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡å¤šæ¨¡æ€æ¨ç†è§£å†³äº¤é€šäº‹æ•…é£é™©é¢„æµ‹ä¸­çš„æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹é¦–å…ˆè®¡ç®—æ³¢åŠ¨æ€§é¢„å¾—åˆ† (volatility pre-score) ä»¥åŠ¨æ€é€‰æ‹©è¾“å…¥æ•°æ®çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œå¹¶åˆ©ç”¨æµ…å±‚äº¤å‰æ³¨æ„åŠ› (shallow cross attention) å®ç°å¤šæ¨¡æ€æ•°æ®çš„ç¼–ç ä¸èåˆã€‚å…¶æ ¸å¿ƒæ¶æ„åœ¨ H3 å…­è¾¹å½¢ç½‘æ ¼ä¸Šç»“åˆäº†å±€éƒ¨ GAT å±‚å’Œ BigBird é£æ ¼çš„ç¨€ç–å…¨å±€ Transformerï¼Œå¹¶é…åˆ Monte Carlo dropout æœºåˆ¶ä»¥æä¾›å…·æœ‰ç½®ä¿¡åº¦çš„é¢„æµ‹ç»“æœã€‚ä¸ºäº†åº”å¯¹æ ‡ç­¾ä¸å¹³è¡¡ï¼Œæ¨¡å‹åœ¨ 15 ä¸ªç¾å›½åŸå¸‚çš„æ•°æ®ä¸Šé‡‡ç”¨ç±»åˆ«åŠ æƒæŸå¤± (class-weighted loss) è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨æµ‹è¯•ä¸­è¡¨ç°å‡ºæä½³çš„è¿ç§»å­¦ä¹ ä¸å¾®è°ƒæ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼ŒALCo-FM å–å¾—äº† 0.94 çš„å‡†ç¡®ç‡ã€0.92 çš„ F1 åˆ†æ•°å’Œ 0.04 çš„é¢„æœŸæ ¡å‡†è¯¯å·® (ECE)ï¼Œæ˜¾è‘—ä¼˜äº 20 å¤šä¸ªæœ€å…ˆè¿›çš„åŸºçº¿æ¨¡å‹ï¼Œä¸ºå¤§è§„æ¨¡åŸå¸‚é£é™©é¢„æµ‹æä¾›äº†å“è¶Šä¸”æ ¡å‡†è‰¯å¥½çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08153v1",
      "published_date": "2025-07-10 20:22:26 UTC",
      "updated_date": "2025-07-10 20:22:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:30.748444+00:00"
    },
    {
      "arxiv_id": "2507.08143v2",
      "title": "Compactor: Calibrated Query-Agnostic KV Cache Compression with Approximate Leverage Scores",
      "title_zh": "Compactorï¼šåŸºäºè¿‘ä¼¼æ æ†å¾—åˆ†çš„æ ¡å‡†å¼æŸ¥è¯¢æ— å…³ KV ç¼“å­˜å‹ç¼©",
      "authors": [
        "Vivek Chari",
        "Benjamin Van Durme"
      ],
      "abstract": "Modern Large Language Models (LLMs) are increasingly trained to support very large context windows. We present Compactor, a training-free, query-agnostic KV compression strategy that uses approximate leverage scores to determine token importance. We show that Compactor can achieve the same performance as competing methods while retaining 20% fewer tokens in both synthetic and real-world context tasks, while being more task-robust. We further introduce a procedure for context-calibrated compression: inferring the maximum compression a given context supports before significant performance loss. Using context-calibrated compression, we show that Compactor achieves full KV performance on Longbench while reducing the KV memory burden by 68%, on average. To demonstrate the efficacy and generalizability of our approach, we apply Compactor to 27 synthetic and real-world tasks from RULER and Longbench, with models from both the Qwen 2.5 and Llama 3.1 families. Finally, we release compactor-vllm, an inference engine and suite of optimized Triton kernels designed to efficiently support the sparse, non-contiguous memory access patterns inherent to compressed KV caches. This work demonstrates that Compactor offers a practical, high-performance solution for alleviating the memory bottleneck in modern LLM deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Compactorï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒä¸”æŸ¥è¯¢æ— å…³(query-agnostic)çš„KV Cacheå‹ç¼©ç­–ç•¥ï¼Œåˆ©ç”¨è¿‘ä¼¼æ æ†å¾—åˆ†(approximate leverage scores)æ¥ç¡®å®šä»¤ç‰Œçš„é‡è¦æ€§ã€‚ä¸ç°æœ‰ç«äº‰æ–¹æ³•ç›¸æ¯”ï¼ŒCompactoråœ¨ä¿æŒåŒç­‰æ€§èƒ½çš„å‰æä¸‹ï¼Œèƒ½åœ¨åˆæˆå’ŒçœŸå®ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­å‡å°‘20%çš„ä»¤ç‰Œä¿ç•™é‡ï¼Œå¹¶è¡¨ç°å‡ºæ›´å¼ºçš„ä»»åŠ¡é²æ£’æ€§ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†ä¸Šä¸‹æ–‡æ ¡å‡†å‹ç¼©(context-calibrated compression)ç¨‹åºï¼Œé€šè¿‡æ¨æ–­ç»™å®šä¸Šä¸‹æ–‡åœ¨ä¸äº§ç”Ÿæ˜¾è‘—æ€§èƒ½æŸå¤±æ—¶æ‰€èƒ½æ”¯æŒçš„æœ€å¤§å‹ç¼©ç‡ï¼Œåœ¨Longbenchæµ‹è¯•ä¸­å¹³å‡å‡å°‘äº†68%çš„KVå†…å­˜è´Ÿæ‹…ã€‚é€šè¿‡å¯¹Qwen 2.5å’ŒLlama 3.1ç³»åˆ—æ¨¡å‹åœ¨27é¡¹ä»»åŠ¡ä¸Šçš„å¹¿æ³›æµ‹è¯•ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„é«˜æ•ˆæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜å‘å¸ƒäº†compactor-vllmæ¨ç†å¼•æ“å’Œä¼˜åŒ–çš„Tritonå†…æ ¸ï¼Œæ—¨åœ¨é«˜æ•ˆæ”¯æŒå‹ç¼©KVç¼“å­˜ä¸­çš„ç¨€ç–ã€éè¿ç»­å†…å­˜è®¿é—®ï¼Œä¸ºç¼“è§£ç°ä»£å¤§è¯­è¨€æ¨¡å‹(LLMs)éƒ¨ç½²ä¸­çš„å†…å­˜ç“¶é¢ˆæä¾›äº†å®ç”¨çš„é«˜æ€§èƒ½è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08143v2",
      "published_date": "2025-07-10 20:03:35 UTC",
      "updated_date": "2025-12-08 19:02:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:36.229281+00:00"
    },
    {
      "arxiv_id": "2507.08137v3",
      "title": "Occlusion-Aware Temporally Consistent Amodal Completion for 3D Human-Object Interaction Reconstruction",
      "title_zh": "é¢å‘ä¸‰ç»´äºº-ç‰©äº¤äº’é‡å»ºçš„é®æŒ¡æ„ŸçŸ¥ä¸æ—¶åºä¸€è‡´éæ¨¡æ€è¡¥å…¨",
      "authors": [
        "Hyungjun Doh",
        "Dong In Lee",
        "Seunggeun Chi",
        "Pin-Hao Huang",
        "Kwonjoon Lee",
        "Sangpil Kim",
        "Karthik Ramani"
      ],
      "abstract": "We introduce a novel framework for reconstructing dynamic human-object interactions from monocular video that overcomes challenges associated with occlusions and temporal inconsistencies. Traditional 3D reconstruction methods typically assume static objects or full visibility of dynamic subjects, leading to degraded performance when these assumptions are violated-particularly in scenarios where mutual occlusions occur. To address this, our framework leverages amodal completion to infer the complete structure of partially obscured regions. Unlike conventional approaches that operate on individual frames, our method integrates temporal context, enforcing coherence across video sequences to incrementally refine and stabilize reconstructions. This template-free strategy adapts to varying conditions without relying on predefined models, significantly enhancing the recovery of intricate details in dynamic scenes. We validate our approach using 3D Gaussian Splatting on challenging monocular videos, demonstrating superior precision in handling occlusions and maintaining temporal stability compared to existing techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å•ç›®è§†é¢‘ä¸­åŠ¨æ€äººæœºäº¤äº’ï¼ˆhuman-object interactionsï¼‰ä¸‰ç»´é‡å»ºé¢ä¸´çš„é®æŒ¡å’Œæ—¶é—´ä¸ä¸€è‡´æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§å…¨æ–°çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨éå…¨è²Œè¡¥å…¨ï¼ˆamodal completionï¼‰æŠ€æœ¯æ¨æ–­éƒ¨åˆ†é®æŒ¡åŒºåŸŸçš„å®Œæ•´ç»“æ„ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†ç›¸äº’é®æŒ¡åœºæ™¯æ—¶çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ä¸é€å¸§å¤„ç†çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•æ•´åˆäº†æ—¶é—´ä¸Šä¸‹æ–‡ï¼ˆtemporal contextï¼‰ï¼Œé€šè¿‡åœ¨è§†é¢‘åºåˆ—ä¸­æ–½åŠ ä¸€è‡´æ€§çº¦æŸï¼Œå®ç°äº†é‡å»ºç»“æœçš„å¢é‡ç»†åŒ–å’Œç¨³å®šã€‚è¿™ç§æ— æ¨¡æ¿ç­–ç•¥ï¼ˆtemplate-free strategyï¼‰æ— éœ€ä¾èµ–é¢„å®šä¹‰æ¨¡å‹å³å¯é€‚åº”å¤šç§å˜åŒ–æ¡ä»¶ï¼Œæ˜¾è‘—å¢å¼ºäº†åŠ¨æ€åœºæ™¯ä¸­å¤æ‚ç»†èŠ‚çš„æ¢å¤èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å•ç›®è§†é¢‘ä¸Šåˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ³¼æº…ï¼ˆ3D Gaussian Splattingï¼‰æŠ€æœ¯è¿›è¡Œäº†éªŒè¯ï¼Œå®éªŒç»“æœè¯æ˜è¯¥æ–¹æ³•åœ¨å¤„ç†é®æŒ¡å’Œç»´æŒæ—¶é—´ç¨³å®šæ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå®ç°äº†æ›´é«˜ç²¾åº¦çš„åŠ¨æ€åœºæ™¯æ¢å¤ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM MM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.08137v3",
      "published_date": "2025-07-10 19:56:10 UTC",
      "updated_date": "2025-09-14 03:40:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:34.875113+00:00"
    },
    {
      "arxiv_id": "2507.08128v2",
      "title": "Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models",
      "title_zh": "Audio Flamingo 3ï¼šåˆ©ç”¨å…¨å¼€æºå¤§è§„æ¨¡éŸ³é¢‘è¯­è¨€æ¨¡å‹æå‡éŸ³é¢‘æ™ºèƒ½",
      "authors": [
        "Arushi Goel",
        "Sreyan Ghosh",
        "Jaehyeon Kim",
        "Sonal Kumar",
        "Zhifeng Kong",
        "Sang-gil Lee",
        "Chao-Han Huck Yang",
        "Ramani Duraiswami",
        "Dinesh Manocha",
        "Rafael Valle",
        "Bryan Catanzaro"
      ],
      "abstract": "We present Audio Flamingo 3 (AF3), a fully open state-of-the-art (SOTA) large audio-language model that advances reasoning and understanding across speech, sound, and music. AF3 introduces: (i) AF-Whisper, a unified audio encoder trained using a novel strategy for joint representation learning across all 3 modalities of speech, sound, and music; (ii) flexible, on-demand thinking, allowing the model to do chain-of-thought-type reasoning before answering; (iii) multi-turn, multi-audio chat; (iv) long audio understanding and reasoning (including speech) up to 10 minutes; and (v) voice-to-voice interaction. To enable these capabilities, we propose several large-scale training datasets curated using novel strategies, including AudioSkills-XL, LongAudio-XL, AF-Think, and AF-Chat, and train AF3 with a novel five-stage curriculum-based training strategy. Trained on only open-source audio data, AF3 achieves new SOTA results on over 20+ (long) audio understanding and reasoning benchmarks, surpassing both open-weight and closed-source models trained on much larger datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Audio Flamingo 3 (AF3)ï¼Œè¿™æ˜¯ä¸€æ¬¾å®Œå…¨å¼€æºçš„å…ˆè¿›å¤§éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨æå‡å¯¹è¯­éŸ³(speech)ã€å£°éŸ³(sound)å’ŒéŸ³ä¹(music)çš„ç†è§£ä¸æ¨ç†èƒ½åŠ›ã€‚AF3 å¼•å…¥äº†ç»Ÿä¸€éŸ³é¢‘ç¼–ç å™¨ AF-Whisperï¼Œé€šè¿‡æ–°é¢–çš„ç­–ç•¥åœ¨ä¸‰ç§éŸ³é¢‘æ¨¡æ€ä¸Šè¿›è¡Œè”åˆè¡¨ç¤ºå­¦ä¹ ï¼Œå¹¶æ”¯æŒåœ¨å›ç­”å‰è¿›è¡ŒæŒ‰éœ€çš„é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†ã€‚è¯¥æ¨¡å‹å…·å¤‡å¤šè½®å¤šéŸ³é¢‘å¯¹è¯ã€é•¿è¾¾10åˆ†é’Ÿçš„é•¿éŸ³é¢‘ç†è§£ä»¥åŠè¯­éŸ³å¯¹è¯­éŸ³(voice-to-voice)äº¤äº’ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚ä¸ºäº†å®ç°è¿™äº›èƒ½åŠ›ï¼Œç ”ç©¶è€…æ„å»ºäº† AudioSkills-XL å’Œ AF-Think ç­‰å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨äº”é˜¶æ®µè¯¾ç¨‹å­¦ä¹ (curriculum-based training)ç­–ç•¥è¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…ä½¿ç”¨å¼€æºéŸ³é¢‘æ•°æ®è®­ç»ƒçš„ AF3 åœ¨20å¤šä¸ªéŸ³é¢‘åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº† SOTA æ€§èƒ½ï¼Œè¶…è¶Šäº†è®¸å¤šåœ¨æ›´åºå¤§æ•°æ®é›†ä¸Šè®­ç»ƒçš„å¼€æºåŠé—­æºæ¨¡å‹ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Code, Datasets, and Models: https://research.nvidia.com/labs/adlr/AF3/ ; Updates in v2: Updated results for new thinking mode ckpts, added qualitative figure, added note on fully open claim, add email ID for corresponding authors",
      "pdf_url": "https://arxiv.org/pdf/2507.08128v2",
      "published_date": "2025-07-10 19:40:21 UTC",
      "updated_date": "2025-07-28 22:53:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:38.784046+00:00"
    },
    {
      "arxiv_id": "2507.08121v1",
      "title": "Quasi-Random Physics-informed Neural Networks",
      "title_zh": "æ‹Ÿéšæœºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ",
      "authors": [
        "Tianchi Yu",
        "Ivan Oseledets"
      ],
      "abstract": "Physics-informed neural networks have shown promise in solving partial differential equations (PDEs) by integrating physical constraints into neural network training, but their performance is sensitive to the sampling of points. Based on the impressive performance of quasi Monte-Carlo methods in high dimensional problems, this paper proposes Quasi-Random Physics-Informed Neural Networks (QRPINNs), which use low-discrepancy sequences for sampling instead of random points directly from the domain. Theoretically, QRPINNs have been proven to have a better convergence rate than PINNs. Empirically, experiments demonstrate that QRPINNs significantly outperform PINNs and some representative adaptive sampling methods, especially in high-dimensional PDEs. Furthermore, combining QRPINNs with adaptive sampling can further improve the performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å‡†éšæœºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ (Quasi-Random Physics-Informed Neural Networks, QRPINNs)ï¼Œæ—¨åœ¨è§£å†³ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ (PINNs) åœ¨æ±‚è§£åå¾®åˆ†æ–¹ç¨‹ (PDEs) æ—¶å¯¹é‡‡æ ·ç‚¹åˆ†å¸ƒé«˜åº¦æ•æ„Ÿçš„é—®é¢˜ã€‚ä¸ä¼ ç»Ÿçš„éšæœºé‡‡æ ·æ–¹æ³•ä¸åŒï¼ŒQRPINNs åˆ©ç”¨ä½å·®å¼‚åºåˆ— (low-discrepancy sequences) è¿›è¡Œé‡‡æ ·ï¼Œå€Ÿé‰´äº†æ‹Ÿè’™ç‰¹å¡ç½—æ–¹æ³• (Quasi-Monte Carlo methods) åœ¨å¤„ç†é«˜ç»´é—®é¢˜ä¸Šçš„ä¼˜åŠ¿ã€‚åœ¨ç†è®ºå±‚é¢ï¼Œè¯¥ç ”ç©¶è¯æ˜äº† QRPINNs å…·æœ‰æ¯”æ ‡å‡† PINNs æ›´ä¼˜è¶Šçš„æ”¶æ•›ç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQRPINNs çš„æ€§èƒ½æ˜¾è‘—ä¼˜äº PINNs åŠå…¶ä»–ä»£è¡¨æ€§çš„è‡ªé€‚åº”é‡‡æ ·æ–¹æ³•ï¼Œè¿™ç§ä¼˜åŠ¿åœ¨å¤„ç†é«˜ç»´åå¾®åˆ†æ–¹ç¨‹ (high-dimensional PDEs) æ—¶å°¤ä¸ºçªå‡ºã€‚æ­¤å¤–ï¼Œå°† QRPINNs ä¸è‡ªé€‚åº”é‡‡æ · (adaptive sampling) æŠ€æœ¯ç›¸ç»“åˆï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ•´ä½“è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08121v1",
      "published_date": "2025-07-10 19:15:43 UTC",
      "updated_date": "2025-07-10 19:15:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:48:46.191557+00:00"
    },
    {
      "arxiv_id": "2507.08096v1",
      "title": "An Object-Based Deep Learning Approach for Building Height Estimation from Single SAR Images",
      "title_zh": "ä¸€ç§åŸºäºå•å¹… SAR å›¾åƒçš„é¢å‘å¯¹è±¡å»ºç­‘ç‰©é«˜åº¦ä¼°è®¡æ·±åº¦å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Babak Memar",
        "Luigi Russo",
        "Silvia Liberata Ullo",
        "Paolo Gamba"
      ],
      "abstract": "Accurate estimation of building heights using very high resolution (VHR) synthetic aperture radar (SAR) imagery is crucial for various urban applications. This paper introduces a Deep Learning (DL)-based methodology for automated building height estimation from single VHR COSMO-SkyMed images: an object-based regression approach based on bounding box detection followed by height estimation. This model was trained and evaluated on a unique multi-continental dataset comprising eight geographically diverse cities across Europe, North and South America, and Asia, employing a cross-validation strategy to explicitly assess out-of-distribution (OOD) generalization. The results demonstrate highly promising performance, particularly on European cities where the model achieves a Mean Absolute Error (MAE) of approximately one building story (2.20 m in Munich), significantly outperforming recent state-of-the-art methods in similar OOD scenarios. Despite the increased variability observed when generalizing to cities in other continents, particularly in Asia with its distinct urban typologies and prevalence of high-rise structures, this study underscores the significant potential of DL for robust cross-city and cross-continental transfer learning in building height estimation from single VHR SAR data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ (Deep Learning)çš„é¢å‘å¯¹è±¡å›å½’æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡å•å¹…æé«˜åˆ†è¾¨ç‡(VHR)åˆæˆå­”å¾„é›·è¾¾(SAR)å›¾åƒå®ç°å»ºç­‘ç‰©é«˜åº¦çš„è‡ªåŠ¨åŒ–ä¼°ç®—ã€‚è¯¥æ¨¡å‹é‡‡ç”¨åŸºäºè¾¹ç•Œæ¡†æ£€æµ‹(bounding box detection)ç»“åˆé«˜åº¦å›å½’çš„æŠ€æœ¯è·¯å¾„ï¼Œå¹¶åˆ©ç”¨æ¶µç›–æ¬§æ´²ã€å—åŒ—ç¾æ´²å’Œäºšæ´²ç­‰å…«ä¸ªåœ°ç†ç‰¹å¾è¿¥å¼‚åŸå¸‚çš„ç‹¬ç‰¹å¤šå¤§é™†æ•°æ®é›†è¿›è¡Œè®­ç»ƒä¸è¯„ä¼°ã€‚é€šè¿‡äº¤å‰éªŒè¯ç­–ç•¥ï¼Œç ”ç©¶æ·±å…¥åˆ†æäº†æ¨¡å‹åœ¨åˆ†å¸ƒå¤–(OOD)åœºæ™¯ä¸‹çš„æ³›åŒ–è¡¨ç°ï¼Œå®éªŒè¯æ˜å…¶åœ¨æ¬§æ´²åŸå¸‚çš„æ•ˆæœå°¤ä¸ºç†æƒ³ï¼Œå¦‚åœ¨æ…•å°¼é»‘å®ç°çš„å¹³å‡ç»å¯¹è¯¯å·®(MAE)ä»…çº¦2.20ç±³ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚å°½ç®¡åœ¨å¤„ç†å…·æœ‰ç‹¬ç‰¹åŸå¸‚å½¢æ€å’Œé«˜å±‚å»ºç­‘å¯†é›†çš„äºšæ´²åŸå¸‚æ—¶å­˜åœ¨ä¸€å®šå˜ç‡ï¼Œä½†è¯¥ç ”ç©¶å……åˆ†å±•ç¤ºäº†åˆ©ç”¨å•å¹…VHR SARæ•°æ®è¿›è¡Œè·¨åŸå¸‚ã€è·¨å¤§é™†è¿ç§»å­¦ä¹ ä»¥ä¼°ç®—å»ºç­‘é«˜åº¦çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08096v1",
      "published_date": "2025-07-10 18:16:16 UTC",
      "updated_date": "2025-07-10 18:16:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:47:46.387912+00:00"
    },
    {
      "arxiv_id": "2507.14175v1",
      "title": "Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data",
      "title_zh": "æ½œç©ºé—´æ•°æ®èåˆåœ¨å¤šæ¨¡æ€å¿ƒç†å¥åº·æ•°å­—è¡¨å‹æ•°æ®ä¸­çš„è¡¨ç°ä¼˜äºæ—©æœŸèåˆ",
      "authors": [
        "Youcef Barkat",
        "Dylan Hamitouche",
        "Deven Parekh",
        "Ivy Guo",
        "David Benrimoh"
      ],
      "abstract": "Background: Mental illnesses such as depression and anxiety require improved methods for early detection and personalized intervention. Traditional predictive models often rely on unimodal data or early fusion strategies that fail to capture the complex, multimodal nature of psychiatric data. Advanced integration techniques, such as intermediate (latent space) fusion, may offer better accuracy and clinical utility. Methods: Using data from the BRIGHTEN clinical trial, we evaluated intermediate (latent space) fusion for predicting daily depressive symptoms (PHQ-2 scores). We compared early fusion implemented with a Random Forest (RF) model and intermediate fusion implemented via a Combined Model (CM) using autoencoders and a neural network. The dataset included behavioral (smartphone-based), demographic, and clinical features. Experiments were conducted across multiple temporal splits and data stream combinations. Performance was evaluated using mean squared error (MSE) and coefficient of determination (R2). Results: The CM outperformed both RF and Linear Regression (LR) baselines across all setups, achieving lower MSE (0.4985 vs. 0.5305 with RF) and higher R2 (0.4695 vs. 0.4356). The RF model showed signs of overfitting, with a large gap between training and test performance, while the CM maintained consistent generalization. Performance was best when integrating all data modalities in the CM (in contradistinction to RF), underscoring the value of latent space fusion for capturing non-linear interactions in complex psychiatric datasets. Conclusion: Latent space fusion offers a robust alternative to traditional fusion methods for prediction with multimodal mental health data. Future work should explore model interpretability and individual-level prediction for clinical deployment.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤šæ¨¡æ€å¿ƒç†å¥åº·æ•°å­—è¡¨å¾(Digital Phenotyping)æ•°æ®çš„æ•´åˆæ–¹æ³•ï¼Œæ—¨åœ¨æé«˜æŠ‘éƒç—‡ç­‰ç²¾ç¥ç–¾ç—…çš„æ—©æœŸæ£€æµ‹å’Œä¸ªæ€§åŒ–å¹²é¢„ç²¾åº¦ã€‚ç ”ç©¶åˆ©ç”¨BRIGHTENä¸´åºŠè¯•éªŒçš„æ•°æ®ï¼Œå¯¹æ¯”äº†åŸºäºéšæœºæ£®æ—(Random Forest)çš„æ—©æœŸèåˆ(Early Fusion)ç­–ç•¥ä¸åˆ©ç”¨è‡ªåŠ¨ç¼–ç å™¨(Autoencoders)å’Œç¥ç»ç½‘ç»œå®ç°çš„æ½œç©ºé—´èåˆ(Latent Space Fusion)æ¨¡å‹ã€‚å®éªŒé€šè¿‡æ•´åˆæ™ºèƒ½æ‰‹æœºè¡Œä¸ºæ•°æ®ã€äººå£ç»Ÿè®¡å­¦åŠä¸´åºŠç‰¹å¾ï¼Œå¯¹æ¯æ—¥æŠ‘éƒç—‡çŠ¶(PHQ-2è¯„åˆ†)è¿›è¡Œé¢„æµ‹ã€‚ç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨æ½œç©ºé—´èåˆçš„ç»„åˆæ¨¡å‹(Combined Model)åœ¨å‡æ–¹è¯¯å·®(MSE)å’Œå†³å®šç³»æ•°(R2)ä¸Šå‡ä¼˜äºæ—©æœŸèåˆå’Œçº¿æ€§å›å½’(Linear Regression)åŸºå‡†ã€‚ç›¸æ¯”äºå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆ(Overfitting)çš„éšæœºæ£®æ—æ¨¡å‹ï¼Œç»„åˆæ¨¡å‹å±•ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨æ•´åˆæ‰€æœ‰æ•°æ®æ¨¡æ€æ—¶è¡¨ç°æœ€ä½³ã€‚è¯¥ç ”ç©¶è¯æ˜äº†æ½œç©ºé—´èåˆåœ¨æ•è·å¤æ‚ç²¾ç¥åŒ»å­¦æ•°æ®é›†ä¸­çš„éçº¿æ€§äº¤äº’æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºå¿ƒç†å¥åº·é¢„æµ‹æä¾›äº†ä¸€ç§æ¯”ä¼ ç»Ÿèåˆæ–¹æ³•æ›´ç¨³å¥çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14175v1",
      "published_date": "2025-07-10 18:10:46 UTC",
      "updated_date": "2025-07-10 18:10:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:19.474741+00:00"
    },
    {
      "arxiv_id": "2507.07999v1",
      "title": "Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology",
      "title_zh": "å¯æº¯æºè¯æ®å¢å¼ºçš„è§†è§‰å®šä½æ¨ç†ï¼šè¯„ä¼°ä¸æ–¹æ³•è®º",
      "authors": [
        "Haochen Wang",
        "Xiangtai Li",
        "Zilong Huang",
        "Anran Wang",
        "Jiacong Wang",
        "Tao Zhang",
        "Jiani Zheng",
        "Sule Bai",
        "Zijian Kang",
        "Jiashi Feng",
        "Zhuochen Wang",
        "Zhaoxiang Zhang"
      ],
      "abstract": "Models like OpenAI-o3 pioneer visual grounded reasoning by dynamically referencing visual regions, just like human \"thinking with images\". However, no benchmark exists to evaluate these capabilities holistically. To bridge this gap, we propose TreeBench (Traceable Evidence Evaluation Benchmark), a diagnostic benchmark built on three principles: (1) focused visual perception of subtle targets in complex scenes, (2) traceable evidence via bounding box evaluation, and (3) second-order reasoning to test object interactions and spatial hierarchies beyond simple object localization. Prioritizing images with dense objects, we initially sample 1K high-quality images from SA-1B, and incorporate eight LMM experts to manually annotate questions, candidate options, and answers for each image. After three stages of quality control, TreeBench consists of 405 challenging visual question-answering pairs, even the most advanced models struggle with this benchmark, where none of them reach 60% accuracy, e.g., OpenAI-o3 scores only 54.87. Furthermore, we introduce TreeVGR (Traceable Evidence Enhanced Visual Grounded Reasoning), a training paradigm to supervise localization and reasoning jointly with reinforcement learning, enabling accurate localizations and explainable reasoning pathways. Initialized from Qwen2.5-VL-7B, it improves V* Bench (+16.8), MME-RealWorld (+12.6), and TreeBench (+13.4), proving traceability is key to advancing vision-grounded reasoning. The code is available at https://github.com/Haochen-Wang409/TreeVGR.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰å®šä½æ¨ç†(Visual Grounded Reasoning)ç¼ºä¹å…¨é¢è¯„ä¼°åŸºå‡†çš„é—®é¢˜ï¼Œæå‡ºäº†TreeBenchï¼ˆTraceable Evidence Evaluation Benchmarkï¼‰è¯Šæ–­æ€§åŸºå‡†ã€‚TreeBench éµå¾ªä¸‰ä¸ªæ ¸å¿ƒåŸåˆ™ï¼šèšç„¦å¤æ‚åœºæ™¯ä¸­ç»†å¾®ç›®æ ‡çš„è§†è§‰æ„ŸçŸ¥ã€é€šè¿‡è¾¹ç•Œæ¡†(Bounding Box)è¯„ä¼°çš„å¯è¿½æº¯è¯æ®ã€ä»¥åŠè¶…è¶Šç®€å•å®šä½çš„äºŒé˜¶æ¨ç†(Second-order Reasoning)ã€‚ç ”ç©¶å›¢é˜Ÿä» SA-1B æ•°æ®é›†ç­›é€‰é«˜è´¨é‡å›¾åƒï¼Œå¹¶ç”± 8 ä½å¤šæ¨¡æ€å¤§æ¨¡å‹(LMM)ä¸“å®¶è¿›è¡Œäººå·¥æ ‡æ³¨å’Œä¸‰é˜¶æ®µè´¨é‡æ§åˆ¶ï¼Œå®éªŒæ˜¾ç¤ºå³ä½¿æ˜¯ OpenAI-o3 ç­‰é¡¶å°–æ¨¡å‹åœ¨è¯¥åŸºå‡†ä¸Šçš„å‡†ç¡®ç‡ä¹Ÿä»…ä¸º 54.87%ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼•å…¥äº† TreeVGRï¼ˆTraceable Evidence Enhanced Visual Grounded Reasoningï¼‰è®­ç»ƒèŒƒå¼ï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)è”åˆç›‘ç£å®šä½ä¸æ¨ç†è·¯å¾„ï¼Œç¡®ä¿ç”Ÿæˆå‡†ç¡®çš„å®šä½å’Œå¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹ã€‚åŸºäº Qwen2.5-VL-7B çš„å®éªŒè¯æ˜ï¼ŒTreeVGR åœ¨ V* Benchã€MME-RealWorld å’Œ TreeBench ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†å¯è¿½æº¯æ€§æ˜¯æ¨è¿›è§†è§‰å®šä½æ¨ç†èƒ½åŠ›çš„å…³é”®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07999v1",
      "published_date": "2025-07-10 17:59:58 UTC",
      "updated_date": "2025-07-10 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:06.291723+00:00"
    },
    {
      "arxiv_id": "2507.07998v3",
      "title": "PyVision: Agentic Vision with Dynamic Tooling",
      "title_zh": "PyVisionï¼šå…·å¤‡åŠ¨æ€å·¥å…·èƒ½åŠ›çš„æ™ºèƒ½ä½“è§†è§‰",
      "authors": [
        "Shitian Zhao",
        "Haoquan Zhang",
        "Shaoheng Lin",
        "Ming Li",
        "Qilong Wu",
        "Kaipeng Zhang",
        "Chen Wei"
      ],
      "abstract": "LLMs are increasingly deployed as agents, systems capable of planning, reasoning, and dynamically calling external tools. However, in visual reasoning, prior approaches largely remain limited by predefined workflows and static toolsets. In this report, we present PyVision, an interactive, multi-turn framework that enables MLLMs to autonomously generate, execute, and refine Python-based tools tailored to the task at hand, unlocking flexible and interpretable problem-solving. We develop a taxonomy of the tools created by PyVision and analyze their usage across a diverse set of benchmarks. Quantitatively, PyVision achieves consistent performance gains, boosting GPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini. These results point to a broader shift: dynamic tooling allows models not just to use tools, but to invent them, advancing toward more agentic visual reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PyVisionï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰è§†è§‰æ¨ç†èƒ½åŠ›çš„äº¤äº’å¼å¤šè½®æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰è§†è§‰æ¨ç†æ–¹æ³•å—é™äºé¢„å®šä¹‰å·¥ä½œæµå’Œé™æ€å·¥å…·é›†çš„ä¸è¶³ï¼ŒPyVision å…è®¸æ¨¡å‹æ ¹æ®å…·ä½“ä»»åŠ¡è‡ªä¸»ç”Ÿæˆã€æ‰§è¡Œå¹¶ä¼˜åŒ–åŸºäº Python çš„å·¥å…·ã€‚è¯¥æ¡†æ¶é€šè¿‡è¿™ç§åŠ¨æ€å·¥å…·åŒ–ï¼ˆDynamic Toolingï¼‰æ–¹æ³•ï¼Œä½¿æ¨¡å‹ä¸ä»…èƒ½ä½¿ç”¨å·¥å…·ï¼Œè¿˜èƒ½æ ¹æ®éœ€è¦â€œå‘æ˜â€å·¥å…·ï¼Œä»è€Œå®ç°çµæ´»ä¸”å¯è§£é‡Šçš„é—®é¢˜è§£å†³è¿‡ç¨‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPyVision åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†ä¸€è‡´çš„æ€§èƒ½å¢ç›Šï¼Œä½¿ GPT-4.1 åœ¨ V\\* ä¸Šæå‡äº† 7.8%ï¼Œå¹¶åœ¨ VLMsAreBlind-mini ä¸Šä½¿ Claude-4.0-Sonnet æ˜¾è‘—æå‡äº† 31.1%ã€‚è¿™é¡¹å·¥ä½œæ¨åŠ¨äº†è§†è§‰æ¨ç†å‘æ›´å…·æ™ºèƒ½ä½“ç‰¹æ€§ï¼ˆAgenticï¼‰çš„æ–¹å‘å‘å±•ï¼Œè¯æ˜äº†åŠ¨æ€å·¥å…·ç”Ÿæˆåœ¨æå‡æ¨¡å‹è‡ªä¸»æ€§æ–¹é¢çš„æ ¸å¿ƒä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "26 Pages, 10 Figures, Technical report, Fix Typo",
      "pdf_url": "https://arxiv.org/pdf/2507.07998v3",
      "published_date": "2025-07-10 17:59:55 UTC",
      "updated_date": "2025-08-27 07:42:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:16.774052+00:00"
    },
    {
      "arxiv_id": "2507.07995v1",
      "title": "Single-pass Adaptive Image Tokenization for Minimum Program Search",
      "title_zh": "é¢å‘æœ€å°ç¨‹åºæœç´¢çš„å•æ¬¡è‡ªé€‚åº”å›¾åƒåˆ†è¯",
      "authors": [
        "Shivam Duggal",
        "Sanghyun Byun",
        "William T. Freeman",
        "Antonio Torralba",
        "Phillip Isola"
      ],
      "abstract": "According to Algorithmic Information Theory (AIT) -- Intelligent representations compress data into the shortest possible program that can reconstruct its content, exhibiting low Kolmogorov Complexity (KC). In contrast, most visual representation learning systems use fixed-length representations for all inputs, ignoring variations in complexity or familiarity. Recent adaptive tokenization methods address this by allocating variable-length representations but typically require test-time search over multiple encodings to find the most predictive one. Inspired by Kolmogorov Complexity principles, we propose a single-pass adaptive tokenizer, KARL, which predicts the appropriate number of tokens for an image in a single forward pass, halting once its approximate KC is reached. The token count serves as a proxy for the minimum description length. KARL's training procedure closely resembles the Upside-Down Reinforcement Learning paradigm, as it learns to conditionally predict token halting based on a desired reconstruction quality. KARL matches the performance of recent adaptive tokenizers while operating in a single pass. We present scaling laws for KARL, analyzing the role of encoder/decoder size, continuous vs. discrete tokenization and more. Additionally, we offer a conceptual study drawing an analogy between Adaptive Image Tokenization and Algorithmic Information Theory, examining the predicted image complexity (KC) across axes such as structure vs. noise and in- vs. out-of-distribution familiarity -- revealing alignment with human intuition.",
      "tldr_zh": "è¯¥ç ”ç©¶å—åˆ°ç®—æ³•ä¿¡æ¯è®º(Algorithmic Information Theory, AIT)å’ŒæŸ¯æ°å¤æ‚æ€§(Kolmogorov Complexity, KC)çš„å¯å‘ï¼Œæ—¨åœ¨å°†å›¾åƒæ•°æ®å‹ç¼©ä¸ºæœ€çŸ­ç¨‹åºä»¥å®ç°æ™ºèƒ½è¡¨å¾ã€‚é’ˆå¯¹ç°æœ‰è§†è§‰è¡¨å¾ç³»ç»Ÿå¤šé‡‡ç”¨å›ºå®šé•¿åº¦æˆ–éœ€è€—æ—¶çš„æµ‹è¯•æ—¶æœç´¢æ¥ç¡®å®šè‡ªé€‚åº”ä»¤ç‰ŒåŒ–é•¿åº¦çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†KARLã€‚KARLæ˜¯ä¸€ç§å•æ¬¡é€šè¿‡(Single-pass)çš„è‡ªé€‚åº”ä»¤ç‰ŒåŒ–å™¨ï¼Œèƒ½å¤Ÿé€šè¿‡å•æ¬¡å‰å‘ä¼ é€’é¢„æµ‹å›¾åƒæ‰€éœ€çš„ä»¤ç‰Œæ•°é‡ï¼Œå¹¶åœ¨è¾¾åˆ°è¿‘ä¼¼æŸ¯æ°å¤æ‚æ€§æ—¶åœæ­¢ã€‚å…¶è®­ç»ƒè¿‡ç¨‹å€Ÿé‰´äº†é¢ å€’å¼ºåŒ–å­¦ä¹ (Upside-Down Reinforcement Learning)èŒƒå¼ï¼Œæ ¹æ®é¢„æœŸçš„é‡å»ºè´¨é‡æ¡ä»¶åŒ–åœ°é¢„æµ‹ä»¤ç‰Œåœæ­¢ç‚¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKARLåœ¨ä¿æŒå•æ¬¡é€šè¿‡æ•ˆç‡çš„åŒæ—¶ï¼Œè¾¾åˆ°äº†ä¸ç°æœ‰éœ€å¤šæ¬¡æœç´¢çš„è‡ªé€‚åº”ä»¤ç‰ŒåŒ–å™¨ç›¸å½“çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åˆ†æäº†æ¨¡å‹çš„ç¼©æ”¾å®šå¾‹ï¼Œå¹¶æ¢è®¨äº†é¢„æµ‹å¤æ‚åº¦ä¸å›¾åƒç»“æ„ã€å™ªå£°åŠåˆ†å¸ƒå¤–(Out-of-distribution)ç†Ÿæ‚‰åº¦ä¹‹é—´çš„å…³ç³»ï¼Œå‘ç°å…¶ç»“æœä¸äººç±»ç›´è§‰é«˜åº¦ä¸€è‡´ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code at: https://github.com/ShivamDuggal4/karl Keywords: Representation Learning, Adaptive Tokenization, Compression, Algorithmic Information Theory, Kolmogorov Complexity, Upside-Down RL",
      "pdf_url": "https://arxiv.org/pdf/2507.07995v1",
      "published_date": "2025-07-10 17:59:53 UTC",
      "updated_date": "2025-07-10 17:59:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:08.686415+00:00"
    },
    {
      "arxiv_id": "2507.07993v2",
      "title": "Multigranular Evaluation for Brain Visual Decoding",
      "title_zh": "å¤§è„‘è§†è§‰è§£ç çš„å¤šç²’åº¦è¯„ä¼°",
      "authors": [
        "Weihao Xia",
        "Cengiz Oztireli"
      ],
      "abstract": "Existing evaluation protocols for brain visual decoding predominantly rely on coarse metrics that obscure inter-model differences, lack neuroscientific foundation, and fail to capture fine-grained visual distinctions. To address these limitations, we introduce BASIC, a unified, multigranular evaluation framework that jointly quantifies structural fidelity, inferential alignment, and contextual coherence between decoded and ground-truth images. For the structural level, we introduce a hierarchical suite of segmentation-based metrics, including foreground, semantic, instance, and component masks, anchored in granularity-aware correspondence across mask structures. For the semantic level, we extract structured scene representations encompassing objects, attributes, and relationships using multimodal large language models, enabling detailed, scalable, and context-rich comparisons with ground-truth stimuli. We benchmark a diverse set of visual decoding methods across multiple stimulus-neuroimaging datasets within this unified evaluation framework. Together, these criteria provide a more discriminative, interpretable, and comprehensive foundation for evaluating brain visual decoding methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è„‘è§†è§‰è§£ç (brain visual decoding)è¯„ä¼°æŒ‡æ ‡è¿‡äºç²—ç•¥ä¸”ç¼ºä¹ç¥ç»ç§‘å­¦åŸºç¡€çš„é—®é¢˜ï¼Œæå‡ºäº†BASICè¿™ä¸€ç»Ÿä¸€çš„å¤šç²’åº¦è¯„ä¼°æ¡†æ¶ã€‚BASICé€šè¿‡å…±åŒé‡åŒ–è§£ç å›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„ç»“æ„ä¿çœŸåº¦(structural fidelity)ã€æ¨ç†å¯¹é½(inferential alignment)å’Œä¸Šä¸‹æ–‡è¿è´¯æ€§(contextual coherence)ï¼Œå…‹æœäº†ä¼ ç»ŸæŒ‡æ ‡æ— æ³•æ•æ‰ç»†ç²’åº¦è§†è§‰å·®å¼‚çš„ç¼ºé™·ã€‚åœ¨ç»“æ„å±‚é¢ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†æ¶µç›–å‰æ™¯ã€è¯­ä¹‰ã€å®ä¾‹åŠç»„ä»¶æ©ç çš„åˆ†å±‚åˆ†å‰²æŒ‡æ ‡ï¼›åœ¨è¯­ä¹‰å±‚é¢ï¼Œåˆ™åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)æå–ç»“æ„åŒ–çš„åœºæ™¯è¡¨ç¤ºï¼Œå®ç°äº†è¯¦å°½ä¸”å…·å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å¯¹æ¯”ã€‚é€šè¿‡åœ¨å¤šä¸ªç¥ç»å½±åƒæ•°æ®é›†ä¸Šå¯¹å¤šç§è§£ç æ–¹æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œç ”ç©¶è¯æ˜äº†BASICèƒ½æä¾›æ›´å…·è¾¨åˆ«åŠ›å’Œå¯è§£é‡Šæ€§çš„è¯„ä¼°ã€‚è¿™ä¸€æ¡†æ¶ä¸ºæœªæ¥è„‘è§†è§‰è§£ç é¢†åŸŸçš„ç ”ç©¶å¥ å®šäº†æ›´å…¨é¢ã€æ›´å…·ç§‘å­¦æ€§çš„è¯„ä¼°åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2026 (Oral). Code: https://github.com/weihaox/BASIC",
      "pdf_url": "https://arxiv.org/pdf/2507.07993v2",
      "published_date": "2025-07-10 17:59:24 UTC",
      "updated_date": "2025-11-30 16:43:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:10.072947+00:00"
    },
    {
      "arxiv_id": "2507.07990v1",
      "title": "Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs",
      "title_zh": "å¤šç²’åº¦æ—¶ç©º Token åˆå¹¶ï¼šè§†é¢‘å¤§è¯­è¨€æ¨¡å‹çš„å…è®­ç»ƒåŠ é€Ÿ",
      "authors": [
        "Jeongseok Hyun",
        "Sukjun Hwang",
        "Su Ho Han",
        "Taeoh Kim",
        "Inwoong Lee",
        "Dongyoon Wee",
        "Joon-Young Lee",
        "Seon Joo Kim",
        "Minho Shim"
      ],
      "abstract": "Video large language models (LLMs) achieve strong video understanding by leveraging a large number of spatio-temporal tokens, but suffer from quadratic computational scaling with token count. To address this, we propose a training-free spatio-temporal token merging method, named STTM. Our key insight is to exploit local spatial and temporal redundancy in video data which has been overlooked in prior work. STTM first transforms each frame into multi-granular spatial tokens using a coarse-to-fine search over a quadtree structure, then performs directed pairwise merging across the temporal dimension. This decomposed merging approach outperforms existing token reduction methods across six video QA benchmarks. Notably, STTM achieves a 2$\\times$ speed-up with only a 0.5% accuracy drop under a 50% token budget, and a 3$\\times$ speed-up with just a 2% drop under a 30% budget. Moreover, STTM is query-agnostic, allowing KV cache reuse across different questions for the same video. The project page is available at https://www.jshyun.me/projects/sttm.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† STTMï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„å¤šç²’åº¦æ—¶ç©º Token Merging æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ Video LLMs å› æ—¶ç©º Token æ•°é‡åºå¤§è€Œå¯¼è‡´çš„è®¡ç®—å¼€é”€å‘ˆå¹³æ–¹çº§å¢é•¿çš„é—®é¢˜ã€‚STTM é€šè¿‡åœ¨ quadtree ç»“æ„ä¸Šè¿›è¡Œä»ç²—åˆ°ç»†çš„æœç´¢ï¼Œå°†æ¯å¸§å›¾åƒè½¬åŒ–ä¸ºå¤šç²’åº¦çš„ç©ºé—´ Tokenï¼Œå¹¶åœ¨æ—¶é—´ç»´åº¦ä¸Šæ‰§è¡Œæœ‰å‘æˆå¯¹åˆå¹¶ï¼Œä»è€Œå……åˆ†æŒ–æ˜äº†è§†é¢‘æ•°æ®ä¸­çš„å±€éƒ¨ç©ºé—´å’Œæ—¶é—´å†—ä½™ã€‚åœ¨å…­ä¸ªè§†é¢‘é—®ç­”(Video QA)åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰çš„ Token å‰Šå‡æŠ€æœ¯ï¼Œåœ¨ä»…ä½¿ç”¨ 50% å’Œ 30% Token é¢„ç®—çš„æƒ…å†µä¸‹ï¼Œåˆ†åˆ«å®ç°äº† 2 å€å’Œ 3 å€çš„æ¨ç†åŠ é€Ÿï¼Œä¸”å‡†ç¡®ç‡ä¸‹é™æå°ã€‚æ­¤å¤–ï¼ŒSTTM å…·æœ‰ Query-agnostic ç‰¹æ€§ï¼Œå…è®¸é’ˆå¯¹åŒä¸€è§†é¢‘çš„ä¸åŒé—®é¢˜å¤ç”¨ KV cacheï¼Œæ˜¾è‘—æå‡äº†å®é™…åº”ç”¨ä¸­çš„æ•ˆç‡ã€‚è¿™ç§åˆ†è§£å¼çš„åˆå¹¶ç­–ç•¥ä¸ºå®ç°é«˜æ•ˆã€å¯æ‰©å±•çš„è§†é¢‘ç†è§£æä¾›äº†æ–°çš„æ€è·¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICCV2025; Project page: https://www.jshyun.me/projects/sttm",
      "pdf_url": "https://arxiv.org/pdf/2507.07990v1",
      "published_date": "2025-07-10 17:59:02 UTC",
      "updated_date": "2025-07-10 17:59:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:23.880243+00:00"
    },
    {
      "arxiv_id": "2507.07986v2",
      "title": "EXPO: Stable Reinforcement Learning with Expressive Policies",
      "title_zh": "EXPOï¼šåŸºäºè¡¨è¾¾æ€§ç­–ç•¥çš„ç¨³å®šå¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Perry Dong",
        "Qiyang Li",
        "Dorsa Sadigh",
        "Chelsea Finn"
      ],
      "abstract": "We study the problem of training and fine-tuning expressive policies with online reinforcement learning (RL) given an offline dataset. Training expressive policy classes with online RL present a unique challenge of stable value maximization. Unlike simpler Gaussian policies commonly used in online RL, expressive policies like diffusion and flow-matching policies are parameterized by a long denoising chain, which hinders stable gradient propagation from actions to policy parameters when optimizing against some value function. Our key insight is that we can address stable value maximization by avoiding direct optimization over value with the expressive policy and instead construct an on-the-fly RL policy to maximize Q-value. We propose Expressive Policy Optimization (EXPO), a sample-efficient online RL algorithm that utilizes an on-the-fly policy to maximize value with two parameterized policies -- a larger expressive base policy trained with a stable imitation learning objective and a light-weight Gaussian edit policy that edits the actions sampled from the base policy toward a higher value distribution. The on-the-fly policy optimizes the actions from the base policy with the learned edit policy and chooses the value maximizing action from the base and edited actions for both sampling and temporal-difference (TD) backup. Our approach yields up to 2-3x improvement in sample efficiency on average over prior methods both in the setting of fine-tuning a pretrained policy given offline data and in leveraging offline data to train online.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Expressive Policy Optimization (EXPO)ï¼Œæ—¨åœ¨è§£å†³ Diffusion å’Œ Flow-matching ç­‰ Expressive Policies åœ¨åœ¨çº¿å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) ä¸­é¢ä¸´çš„ Value Maximization ç¨³å®šæ€§éš¾é¢˜ã€‚é’ˆå¯¹é•¿å»å™ªé“¾å¯¼è‡´æ¢¯åº¦ä¼ æ’­å›°éš¾çš„é—®é¢˜ï¼ŒEXPO å·§å¦™åœ°é¿å…äº†ç›´æ¥å¯¹ä»·å€¼å‡½æ•°è¿›è¡Œå¤æ‚ä¼˜åŒ–ï¼Œè€Œæ˜¯å¼•å…¥äº†ä¸€ä¸ªç”±ç¨³å®šæ¨¡ä»¿å­¦ä¹  (Imitation Learning) è®­ç»ƒçš„åŸºç¡€ç­–ç•¥ Base Policy å’Œä¸€ä¸ªè½»é‡çº§çš„ Gaussian Edit Policy ç»„æˆçš„åŒå±‚æ¶æ„ã€‚é€šè¿‡ Edit Policy å¯¹åŸºç¡€åŠ¨ä½œè¿›è¡Œå¾®è°ƒï¼Œå¹¶åœ¨é‡‡æ ·å’Œ Temporal-Difference å¤‡ä»½è¿‡ç¨‹ä¸­é€‰æ‹©ä»·å€¼æ›´é«˜çš„åŠ¨ä½œï¼ŒEXPO å®ç°äº†æ›´åŠ ç¨³å¥çš„åœ¨çº¿ä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆ©ç”¨ç¦»çº¿æ•°æ®è¿›è¡Œåœ¨çº¿è®­ç»ƒæˆ–å¾®è°ƒé¢„è®­ç»ƒç­–ç•¥æ—¶ï¼Œå…¶é‡‡æ ·æ•ˆç‡ç›¸è¾ƒäºå…ˆå‰æ–¹æ³•æå‡äº† 2 åˆ° 3 å€ã€‚EXPO ä¸ºåœ¨å¤§è§„æ¨¡è¡¨è¾¾æ€§ç­–ç•¥ä¸­èåˆåœ¨çº¿å¼ºåŒ–å­¦ä¹ æä¾›äº†ä¸€ç§ sample-efficient ä¸”ç¨³å®šçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "corrected typo, formatting, added experiments",
      "pdf_url": "https://arxiv.org/pdf/2507.07986v2",
      "published_date": "2025-07-10 17:57:46 UTC",
      "updated_date": "2025-07-15 17:54:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:26.934159+00:00"
    },
    {
      "arxiv_id": "2507.07983v1",
      "title": "Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology",
      "title_zh": "å¤§ã€å°è¯­è¨€æ¨¡å‹åœ¨é£æ¹¿ç—…å­¦ä¸´åºŠå†³ç­–æ”¯æŒä¸­çš„æ€§èƒ½è¡¨ç°ä¸å®è·µè€ƒé‡",
      "authors": [
        "Sabine Felde",
        "RÃ¼diger Buchkremer",
        "Gamal Chehab",
        "Christian Thielscher",
        "JÃ¶rg HW Distler",
        "Matthias Schneider",
        "Jutta G. Richter"
      ],
      "abstract": "Large language models (LLMs) show promise for supporting clinical decision-making in complex fields such as rheumatology. Our evaluation shows that smaller language models (SLMs), combined with retrieval-augmented generation (RAG), achieve higher diagnostic and therapeutic performance than larger models, while requiring substantially less energy and enabling cost-efficient, local deployment. These features are attractive for resource-limited healthcare. However, expert oversight remains essential, as no model consistently reached specialist-level accuracy in rheumatology.",
      "tldr_zh": "æœ¬ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å’Œå°å‹è¯­è¨€æ¨¡å‹(SLMs)åœ¨é£æ¹¿ç—…å­¦(Rheumatology)ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿä¸­çš„è¡¨ç°åŠå®é™…åº”ç”¨è€ƒé‡ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œç»“åˆäº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)æŠ€æœ¯çš„SLMsåœ¨è¯Šæ–­å’Œæ²»ç–—è¡¨ç°ä¸Šä¼˜äºæ›´å¤§å‹çš„æ¨¡å‹ã€‚SLMsåœ¨å®é™…åº”ç”¨ä¸­å±•ç°å‡ºæ›´ä½çš„èƒ½è€—ã€æ›´é«˜çš„æˆæœ¬æ•ˆç›Šä»¥åŠæ”¯æŒæœ¬åœ°åŒ–éƒ¨ç½²(Local Deployment)ç­‰ä¼˜åŠ¿ï¼Œè¿™å¯¹äºèµ„æºå—é™çš„åŒ»ç–—ç¯å¢ƒå…·æœ‰é‡è¦æ„ä¹‰ã€‚ç„¶è€Œï¼Œç”±äºç›®å‰å°šæ— æ¨¡å‹èƒ½åœ¨é£æ¹¿ç—…é¢†åŸŸå§‹ç»ˆè¾¾åˆ°ä¸“ç§‘åŒ»ç”Ÿçº§åˆ«çš„å‡†ç¡®ç‡ï¼Œä¸´åºŠåº”ç”¨ä¸­ä»éœ€ä¿æŒä¸¥æ ¼çš„ä¸“å®¶ç›‘ç£ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨ç‰¹å®šä¸´åºŠé¢†åŸŸé€šè¿‡RAGæŠ€æœ¯ä¼˜åŒ–è½»é‡åŒ–æ¨¡å‹ï¼Œæ¯”å•çº¯è¿½æ±‚å¤§æ¨¡å‹è§„æ¨¡æ›´å…·å®è·µä»·å€¼ä¸è½åœ°å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07983v1",
      "published_date": "2025-07-10 17:56:03 UTC",
      "updated_date": "2025-07-10 17:56:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:37.006335+00:00"
    },
    {
      "arxiv_id": "2507.07982v1",
      "title": "Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling",
      "title_zh": "Geometry Forcingï¼šèåˆè§†é¢‘æ‰©æ•£ä¸ 3D è¡¨ç¤ºï¼Œå®ç°ä¸€è‡´æ€§ä¸–ç•Œå»ºæ¨¡",
      "authors": [
        "Haoyu Wu",
        "Diankun Wu",
        "Tianyu He",
        "Junliang Guo",
        "Yang Ye",
        "Yueqi Duan",
        "Jiang Bian"
      ],
      "abstract": "Videos inherently represent 2D projections of a dynamic 3D world. However, our analysis suggests that video diffusion models trained solely on raw video data often fail to capture meaningful geometric-aware structure in their learned representations. To bridge this gap between video diffusion models and the underlying 3D nature of the physical world, we propose Geometry Forcing, a simple yet effective method that encourages video diffusion models to internalize latent 3D representations. Our key insight is to guide the model's intermediate representations toward geometry-aware structure by aligning them with features from a pretrained geometric foundation model. To this end, we introduce two complementary alignment objectives: Angular Alignment, which enforces directional consistency via cosine similarity, and Scale Alignment, which preserves scale-related information by regressing unnormalized geometric features from normalized diffusion representation. We evaluate Geometry Forcing on both camera view-conditioned and action-conditioned video generation tasks. Experimental results demonstrate that our method substantially improves visual quality and 3D consistency over the baseline methods. Project page: https://GeometryForcing.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Geometry Forcingï¼Œæ—¨åœ¨è§£å†³è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆvideo diffusion modelsï¼‰åœ¨å­¦ä¹ è¡¨ç¤ºä¸­éš¾ä»¥æ•æ‰æœ‰æ•ˆå‡ ä½•ç»“æ„çš„é—®é¢˜ï¼Œé€šè¿‡å°†è§†é¢‘ç”Ÿæˆä¸ 3D è¡¨ç¤ºç›¸ç»“åˆæ¥å®ç°ä¸€è‡´çš„ä¸–ç•Œå»ºæ¨¡ã€‚æ ¸å¿ƒæ–¹æ³•æ˜¯å¼•å¯¼æ¨¡å‹çš„ä¸­é—´è¡¨ç¤ºå‘å‡ ä½•æ„ŸçŸ¥ç»“æ„é æ‹¢ï¼Œå¹¶å°†å…¶ä¸é¢„è®­ç»ƒçš„å‡ ä½•åŸºç¡€æ¨¡å‹ï¼ˆgeometric foundation modelï¼‰ç‰¹å¾è¿›è¡Œå¯¹é½ã€‚ç ”ç©¶å…·ä½“å¼•å…¥äº†ä¸¤ç§äº’è¡¥çš„å¯¹é½ç›®æ ‡ï¼Œå³é€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦å¼ºåŒ–æ–¹å‘ä¸€è‡´æ€§çš„ Angular Alignmentï¼Œä»¥åŠé€šè¿‡å›å½’éå½’ä¸€åŒ–å‡ ä½•ç‰¹å¾æ¥ä¿ç•™å°ºåº¦ä¿¡æ¯çš„ Scale Alignmentã€‚å®éªŒåœ¨æ‘„åƒæœºè§†è§’å’ŒåŠ¨ä½œè°ƒèŠ‚çš„è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œç»“æœè¡¨æ˜ Geometry Forcing æ˜¾è‘—æå‡äº†ç”Ÿæˆè§†é¢‘çš„è§†è§‰è´¨é‡å’Œ 3D ä¸€è‡´æ€§ï¼ˆ3D consistencyï¼‰ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆåœ°ä¿ƒä½¿æ¨¡å‹å†…åŒ–äº†æ½œåœ¨çš„ 3D è¡¨ç¤ºï¼Œä¸ºæ„å»ºæ›´ç¬¦åˆç‰©ç†è§„å¾‹çš„ä¸–ç•Œæ¨¡å‹æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, project page: https://GeometryForcing.github.io",
      "pdf_url": "https://arxiv.org/pdf/2507.07982v1",
      "published_date": "2025-07-10 17:55:08 UTC",
      "updated_date": "2025-07-10 17:55:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:32.982057+00:00"
    },
    {
      "arxiv_id": "2507.07981v2",
      "title": "Why is Your Language Model a Poor Implicit Reward Model?",
      "title_zh": "ä½ çš„è¯­è¨€æ¨¡å‹ä¸ºä½•æ˜¯ä¸€ä¸ªè¡¨ç°ä¸ä½³çš„éšå¼å¥–åŠ±æ¨¡å‹ï¼Ÿ",
      "authors": [
        "Noam Razin",
        "Yong Lin",
        "Jiarui Yao",
        "Sanjeev Arora"
      ],
      "abstract": "Reward models are key to language model post-training and inference pipelines. Conveniently, recent work showed that every language model defines an implicit reward model (IM-RM), without requiring any architectural changes. However, such IM-RMs tend to generalize worse, especially out-of-distribution, compared to explicit reward models (EX-RMs) that apply a dedicated linear head over the hidden representations of a language model. The existence of a generalization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They can be trained using the same data, loss function, and language model, and differ only in how the reward is computed. Toward a fundamental understanding of the implicit biases underlying different reward model types, we investigate the root cause of this gap. Our main finding, backed by theory and experiments, is that IM-RMs rely more heavily on superficial token-level cues. Consequently, they often generalize worse than EX-RMs under token-level distribution shifts, as well as in-distribution. Furthermore, we provide evidence against alternative hypotheses for the generalization gap. Most notably, we challenge the intuitive claim that IM-RMs struggle in tasks where generation is harder than verification because they can operate both as a verifier and a generator. Taken together, our results highlight that seemingly minor design choices can substantially impact the generalization behavior of reward models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†éšå¼å¥–åŠ±æ¨¡å‹ (IM-RM) åœ¨æ³›åŒ–æ€§èƒ½ä¸Šé€Šè‰²äºæ˜¾å¼å¥–åŠ±æ¨¡å‹ (EX-RM) çš„æ ¸å¿ƒåŸå› ã€‚å°½ç®¡ä¸¤è€…åœ¨è®­ç»ƒæ•°æ®ã€æŸå¤±å‡½æ•°å’Œè¯­è¨€æ¨¡å‹åŸºç¡€æ¶æ„ä¸Šé«˜åº¦ç›¸ä¼¼ï¼Œä½† IM-RM åœ¨åˆ†å¸ƒå¤– (out-of-distribution) æ•°æ®ä¸Šçš„æ³›åŒ–è¡¨ç°æ™®éè¾ƒå·®ã€‚ç ”ç©¶é€šè¿‡ç†è®ºä¸å®éªŒè¯æ˜ï¼ŒIM-RM è¿‡å¤šåœ°ä¾èµ–äºè¡¨å±‚çš„ token-level æç¤ºçº¿ç´¢ï¼Œè¿™ä½¿å…¶åœ¨é¢å¯¹ token-level åˆ†å¸ƒåç§»åŠåˆ†å¸ƒå†…æµ‹è¯•æ—¶å‡è¡¨ç°ä¸ä½³ã€‚æ­¤å¤–ï¼Œä½œè€…åé©³äº†â€œç”Ÿæˆéš¾åº¦é«˜äºéªŒè¯â€æ˜¯å¯¼è‡´è¯¥æ³›åŒ–å·®è·åŸå› çš„å‡è®¾ã€‚è¯¥ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç»†å¾®çš„è®¾è®¡é€‰æ‹©ä¼šæ˜¾è‘—æ”¹å˜å¥–åŠ±æ¨¡å‹çš„æ³›åŒ–è¡Œä¸ºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "Code available at https://github.com/princeton-pli/exrm-vs-imrm",
      "pdf_url": "https://arxiv.org/pdf/2507.07981v2",
      "published_date": "2025-07-10 17:55:05 UTC",
      "updated_date": "2025-10-16 17:45:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:39.112397+00:00"
    },
    {
      "arxiv_id": "2507.07969v3",
      "title": "Reinforcement Learning with Action Chunking",
      "title_zh": "ç»“åˆåŠ¨ä½œåˆ†å—çš„å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Qiyang Li",
        "Zhiyuan Zhou",
        "Sergey Levine"
      ],
      "abstract": "We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Q-chunkingï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é•¿æ—¶ç¨‹ (long-horizon) å’Œç¨€ç–å¥–åŠ± (sparse-reward) ä»»åŠ¡çš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) æ”¹è¿›æ–¹æ¡ˆã€‚å…¶æ ¸å¿ƒè§è§£æ˜¯å°†å¸¸ç”¨äºæ¨¡ä»¿å­¦ä¹ çš„åŠ¨ä½œåˆ†å— (Action Chunking) æŠ€æœ¯åº”ç”¨äºåŸºäºæ—¶é—´å·®åˆ† (TD) çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œä»¥è§£å†³ç¦»çº¿åˆ°åœ¨çº¿ (offline-to-online) å­¦ä¹ ä¸­çš„æ¢ç´¢æŒ‘æˆ˜ã€‚é€šè¿‡ç›´æ¥åœ¨åˆ†å—åçš„åŠ¨ä½œç©ºé—´ä¸­è¿è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨ç¦»çº¿æ•°æ®ä¸­æ—¶é—´ä¸€è‡´çš„è¡Œä¸ºæ¥å¢å¼ºåœ¨çº¿æ¢ç´¢ï¼Œå¹¶ç»“åˆæ— åçš„ $n$-step backups å®ç°æ›´ç¨³å®šé«˜æ•ˆçš„ TD å­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒQ-chunking åœ¨å¤šç§å¤æ‚çš„æœºå™¨äººæ“æ§ä»»åŠ¡ä¸­å±•ç°äº†æå¼ºçš„ç¦»çº¿æ€§èƒ½å’Œåœ¨çº¿é‡‡æ ·æ•ˆç‡ (sample-efficiency)ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„ç¦»çº¿åˆ°åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025); 36 pages, 17 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07969v3",
      "published_date": "2025-07-10 17:48:03 UTC",
      "updated_date": "2025-10-24 17:37:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:50.406943+00:00"
    },
    {
      "arxiv_id": "2507.07966v4",
      "title": "Scaling RL to Long Videos",
      "title_zh": "é¢å‘é•¿è§†é¢‘çš„å¼ºåŒ–å­¦ä¹ è§„æ¨¡åŒ–æ‰©å±•",
      "authors": [
        "Yukang Chen",
        "Wei Huang",
        "Baifeng Shi",
        "Qinghao Hu",
        "Hanrong Ye",
        "Ligeng Zhu",
        "Zhijian Liu",
        "Pavlo Molchanov",
        "Jan Kautz",
        "Xiaojuan Qi",
        "Sifei Liu",
        "Hongxu Yin",
        "Yao Lu",
        "Song Han"
      ],
      "abstract": "We introduce a full-stack framework that scales up reasoning in vision-language models (VLMs) to long videos, leveraging reinforcement learning. We address the unique challenges of long video reasoning by integrating three critical components: (1) a large-scale dataset, LongVideo-Reason, comprising 104K long video QA pairs with high-quality reasoning annotations across diverse domains such as sports, games, and vlogs; (2) a two-stage training pipeline that extends VLMs with chain-of-thought supervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a training infrastructure for long video RL, named Multi-modal Reinforcement Sequence Parallelism (MR-SP), which incorporates sequence parallelism and a vLLM-based engine tailored for long video, using cached video embeddings for efficient rollout and prefilling. In our experiments, LongVILA-R1-7B achieves strong performance on video benchmarks, reaching 65.1% and 71.1% accuracy on VideoMME without and with subtitles, respectively, and consistently outperforming LongVILA-7B across multiple benchmarks. Moreover, LongVILA-R1-7B supports processing up to 8,192 video frames per video, and configurable FPS settings. Notably, our MR-SP system achieves up to 2.1x speedup on long video RL training. In addition, we release our training system for public availability that supports RL training on various modalities (video, text, and audio), various models (VILA and Qwen series), and even image and video generation models. On a single A100 node (8 GPUs), it supports RL training on hour-long videos (e.g., 3,600 frames).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†ä¸€ä¸ªæ—¨åœ¨é€šè¿‡å¼ºåŒ–å­¦ä¹  (RL) å°†è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) çš„æ¨ç†èƒ½åŠ›æ‰©å±•è‡³é•¿è§†é¢‘çš„å…¨æ ˆæ¡†æ¶ã€‚æ ¸å¿ƒè´¡çŒ®åŒ…æ‹¬æ„å»ºäº†åŒ…å« 10.4 ä¸‡ä¸ªé«˜è´¨é‡æ¨ç†æ ‡æ³¨é—®ç­”å¯¹çš„å¤§è§„æ¨¡æ•°æ®é›† LongVideo-Reasonï¼Œä»¥åŠé‡‡ç”¨ç»“åˆé“¾å¼æ€ç»´ç›‘ç£å¾®è°ƒ (CoT-SFT) ä¸å¼ºåŒ–å­¦ä¹  (RL) çš„ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ¡ˆã€‚ä¸ºäº†è§£å†³é•¿è§†é¢‘è®­ç»ƒçš„è®¡ç®—æŒ‘æˆ˜ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº† Multi-modal Reinforcement Sequence Parallelism (MR-SP) è®­ç»ƒåŸºç¡€è®¾æ–½ï¼Œåˆ©ç”¨åºåˆ—å¹¶è¡Œå’Œç¼“å­˜è§†é¢‘åµŒå…¥æŠ€æœ¯å®ç°äº† 2.1 å€çš„è®­ç»ƒåŠ é€Ÿã€‚å®éªŒè¡¨æ˜ï¼Œç”Ÿæˆçš„ LongVILA-R1-7B æ¨¡å‹åœ¨ VideoMME ç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¸”èƒ½å¤Ÿæ”¯æŒå¤„ç†å¤šè¾¾ 8,192 å¸§çš„è§†é¢‘å†…å®¹ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿæ”¯æŒåœ¨å•ä¸ª A100 èŠ‚ç‚¹ä¸Šè¿›è¡Œé•¿è¾¾ä¸€å°æ—¶è§†é¢‘çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œä¸ºå¤šæ¨¡æ€æ¨¡å‹åœ¨é•¿è§†é¢‘ç†è§£é¢†åŸŸçš„è§„æ¨¡åŒ–åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2025. Code at https://github.com/NVlabs/Long-RL and model at https://huggingface.co/Efficient-Large-Model/LongVILA-R1-7B",
      "pdf_url": "https://arxiv.org/pdf/2507.07966v4",
      "published_date": "2025-07-10 17:47:40 UTC",
      "updated_date": "2025-09-30 14:13:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:00.705728+00:00"
    },
    {
      "arxiv_id": "2507.07957v1",
      "title": "MIRIX: Multi-Agent Memory System for LLM-Based Agents",
      "title_zh": "MIRIXï¼šé¢å‘åŸºäºå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“çš„å¤šæ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿ",
      "authors": [
        "Yu Wang",
        "Xi Chen"
      ],
      "abstract": "Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MIRIXï¼Œä¸€ä¸ªæ¨¡å—åŒ–çš„å¤šæ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ AI æ™ºèƒ½ä½“åœ¨ä¸ªæ€§åŒ–ã€æŠ½è±¡åŒ–å’Œé•¿æœŸå¬å›ç”¨æˆ·ç‰¹å®šä¿¡æ¯æ–¹é¢çš„å±€é™æ€§ã€‚ä¸ä»¥å¾€ä»…ä¾èµ–æ‰å¹³æ–‡æœ¬çš„æ–¹æ³•ä¸åŒï¼ŒMIRIX åŒ…å« Coreã€Episodicã€Semanticã€Proceduralã€Resource Memory å’Œ Knowledge Vault å…­ç§ç²¾ç»†ç»“æ„çš„è®°å¿†ç±»å‹ï¼Œå¹¶ç»“åˆå¤šæ™ºèƒ½ä½“æ¡†æ¶åŠ¨æ€åè°ƒæ›´æ–°ä¸æ£€ç´¢ã€‚è¯¥ç³»ç»Ÿä¸ä»…æ”¯æŒæ–‡æœ¬ï¼Œè¿˜èƒ½å¤„ç†ä¸°å¯Œçš„è§†è§‰å’Œå¤šæ¨¡æ€ä½“éªŒï¼Œåœ¨å¤šæ¨¡æ€åŸºå‡† ScreenshotVQA ä¸Šå–å¾—äº†æ¯” RAG åŸºçº¿é«˜ 35% çš„å‡†ç¡®ç‡ï¼Œå¹¶å‡å°‘äº† 99.9% çš„å­˜å‚¨éœ€æ±‚ã€‚åœ¨é•¿å¯¹è¯åŸºå‡† LOCOMO ä¸­ï¼ŒMIRIX è¾¾åˆ°äº† 85.4% çš„ state-of-the-art æ€§èƒ½ï¼Œè¿œè¶…ç°æœ‰æ°´å¹³ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é…å¥—æä¾›äº†ä¸€ä¸ªå®æ—¶ç›‘æ§å±å¹•å¹¶æ„å»ºä¸ªæ€§åŒ–è®°å¿†åº“çš„åº”ç”¨ç¨‹åºï¼Œåœ¨ç¡®ä¿éšç§çš„åŒæ—¶æå‡äº† LLM æ™ºèƒ½ä½“çš„å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07957v1",
      "published_date": "2025-07-10 17:40:11 UTC",
      "updated_date": "2025-07-10 17:40:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:49:58.400968+00:00"
    },
    {
      "arxiv_id": "2507.07947v3",
      "title": "Low Resource Reconstruction Attacks Through Benign Prompts",
      "title_zh": "åŸºäºè‰¯æ€§æç¤ºçš„ä½èµ„æºé‡æ„æ”»å‡»",
      "authors": [
        "Sol Yarkoni",
        "Mahmood Sharif",
        "Roi Livni"
      ],
      "abstract": "Recent advances in generative models, such as diffusion models, have raised concerns related to privacy, copyright infringement, and data stewardship. To better understand and control these risks, prior work has introduced techniques and attacks that reconstruct images, or parts of images, from training data. While these results demonstrate that training data can be recovered, existing methods often rely on high computational resources, partial access to the training set, or carefully engineered prompts.\n  In this work, we present a new attack that requires low resources, assumes little to no access to the training data, and identifies seemingly benign prompts that can lead to potentially risky image reconstruction. We further show that such reconstructions may occur unintentionally, even for users without specialized knowledge. For example, we observe that for one existing model, the prompt ``blue Unisex T-Shirt'' generates the face of a real individual. Moreover, by combining the identified vulnerabilities with real-world prompt data, we discover prompts that reproduce memorized visual elements.\n  Our approach builds on insights from prior work and leverages domain knowledge to expose a fundamental vulnerability arising from the use of scraped e-commerce data, where templated layouts and images are closely tied to pattern-like textual prompts.\n  The code for our attack is publicly available at https://github.com/TheSolY/lr-tmi.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹ç­‰ç”Ÿæˆæ¨¡å‹é¢ä¸´çš„éšç§ä¸ç‰ˆæƒé£é™©ï¼Œæå‡ºäº†ä¸€ç§èµ„æºæ¶ˆè€—ä½ä¸”æ— éœ€è®¿é—®è®­ç»ƒæ•°æ®çš„é‡å»ºæ”»å‡» (reconstruction attacks) æ–¹æ³•ã€‚è¯¥æ”»å‡»é€šè¿‡è¯†åˆ«çœ‹ä¼¼æ— å®³çš„è‰¯æ€§æç¤ºè¯ (benign prompts) æ¥è¯±å¯¼æ¨¡å‹ç”Ÿæˆè®­ç»ƒé›†ä¸­çš„æ•æ„Ÿå›¾åƒï¼Œè¯æ˜äº†æ•°æ®æ³„éœ²å¯èƒ½åœ¨ç”¨æˆ·æ— æ„é—´å‘ç”Ÿã€‚ä¾‹å¦‚ï¼Œç ”ç©¶å‘ç°ç‰¹å®šçš„ç”µå•†æœ¯è¯­å¦‚â€œblue Unisex T-Shirtâ€ä¼šå¯¼è‡´æ¨¡å‹è¾“å‡ºçœŸå®ä¸ªäººçš„é¢éƒ¨ä¿¡æ¯ã€‚é€šè¿‡åˆ†æï¼Œä½œè€…æŒ‡å‡ºè¿™ç§è„†å¼±æ€§ä¸»è¦æºäºæ¨¡å‹ä½¿ç”¨äº†æŠ“å–çš„ç”µå­å•†åŠ¡æ•°æ®ï¼Œå…¶ä¸­æ¨¡æ¿åŒ–çš„å¸ƒå±€ä¸æ¨¡å¼åŒ–æ–‡æœ¬ä¹‹é—´å­˜åœ¨æå¼ºçš„å…³è”ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡ç»“åˆçœŸå®ä¸–ç•Œçš„æç¤ºè¯æ•°æ®æ­ç¤ºäº†æ¨¡å‹è®°å¿†è§†è§‰å…ƒç´ çš„é£é™©ï¼Œä¸ºç”Ÿæˆå¼æ¨¡å‹çš„å®‰å…¨è¯„ä¼°æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07947v3",
      "published_date": "2025-07-10 17:32:26 UTC",
      "updated_date": "2026-01-07 17:17:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:01.002648+00:00"
    },
    {
      "arxiv_id": "2507.07935v6",
      "title": "Working with AI: Measuring the Applicability of Generative AI to Occupations",
      "title_zh": "ä¸ AI åä½œï¼šè¡¡é‡ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨å„èŒä¸šä¸­çš„é€‚ç”¨æ€§",
      "authors": [
        "Kiran Tomlinson",
        "Sonia Jaffe",
        "Will Wang",
        "Scott Counts",
        "Siddharth Suri"
      ],
      "abstract": "With generative AI emerging as a general-purpose technology, understanding its economic effects is among society's most pressing questions. Existing studies of AI impact have largely relied on predictions of AI capabilities or focused narrowly on individual firms. Drawing instead on real-world AI usage, we analyze a dataset of 200k anonymized conversations with Microsoft Bing Copilot to measure AI applicability to occupations. We use an LLM-based pipeline to classify the O*NET work activities assisted or performed by AI in each conversation. We find that the most common and successful AI-assisted work activities involve information work--the creation, processing, and communication of information. At the occupation level, we find widespread AI applicability cutting across sectors, as most occupations have information work components. Our methodology also allows us to predict which occupations are more likely to delegate tasks to AI and which are more likely to use AI to assist existing workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†æäº†20ä¸‡æ¡åŒ¿åçš„Microsoft Bing Copilotå¯¹è¯æ•°æ®é›†ï¼Œæ—¨åœ¨è¡¡é‡ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰å¯¹ä¸åŒèŒä¸šçš„é€‚ç”¨æ€§ã€‚ç ”ç©¶è€…åˆ©ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æµæ°´çº¿ï¼Œå¯¹å¯¹è¯ä¸­æ¶‰åŠçš„O*NETå·¥ä½œæ´»åŠ¨è¿›è¡Œäº†åˆ†ç±»ï¼Œè¯†åˆ«å‡ºAIåœ¨å“ªäº›ç¯èŠ‚æä¾›äº†ååŠ©æˆ–æ‰§è¡Œäº†ä»»åŠ¡ã€‚ç ”ç©¶å‘ç°ï¼Œæœ€å¸¸è§ä¸”æˆåŠŸçš„AIè¾…åŠ©å·¥ä½œä¸»è¦é›†ä¸­åœ¨ä¿¡æ¯å·¥ä½œé¢†åŸŸï¼Œæ¶µç›–äº†ä¿¡æ¯çš„åˆ›å»ºã€å¤„ç†ä¸æ²Ÿé€šã€‚ç”±äºå¤§å¤šæ•°èŒä¸šéƒ½åŒ…å«ä¿¡æ¯å·¥ä½œæˆåˆ†ï¼Œç”Ÿæˆå¼AIè¡¨ç°å‡ºè·¨è¡Œä¸šçš„å¹¿æ³›é€‚ç”¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºçš„æ–¹æ³•è®ºèƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹ä¸åŒèŒä¸šæ˜¯å€¾å‘äºå°†ä»»åŠ¡å®Œå…¨å§”æ‰˜ç»™AIï¼Œè¿˜æ˜¯åˆ©ç”¨AIæ¥ä¼˜åŒ–ç°æœ‰çš„å·¥ä½œæµã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "econ.GN"
      ],
      "primary_category": "cs.AI",
      "comment": "40 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.07935v6",
      "published_date": "2025-07-10 17:16:33 UTC",
      "updated_date": "2025-12-22 17:01:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:04.407791+00:00"
    },
    {
      "arxiv_id": "2507.07931v1",
      "title": "Meek Models Shall Inherit the Earth",
      "title_zh": "è°¦å‘æ¨¡å‹ç»ˆå°†æ‰¿ç»§å¤§åœ°",
      "authors": [
        "Hans Gundlach",
        "Jayson Lynch",
        "Neil Thompson"
      ],
      "abstract": "The past decade has seen incredible scaling of AI systems by a few companies, leading to inequality in AI model performance. This paper argues that, contrary to prevailing intuition, the diminishing returns to compute scaling will lead to a convergence of AI model capabilities. In other words, meek models (those with limited computation budget) shall inherit the earth, approaching the performance level of the best models overall. We develop a model illustrating that under a fixed-distribution next-token objective, the marginal capability returns to raw compute shrink substantially. Given current scaling practices, we argue that these diminishing returns are strong enough that even companies that can scale their models exponentially faster than other organizations will eventually have little advantage in capabilities. As part of our argument, we give several reasons that proxies like training loss differences capture important capability measures using evidence from benchmark data and theoretical performance models. In addition, we analyze empirical data on the capability difference of AI models over time. Finally, in light of the increasing ability of meek models, we argue that AI strategy and policy require reexamination, and we outline the areas this shift will affect.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†AIç³»ç»Ÿè§„æ¨¡æ‰©å¼ å¯¼è‡´çš„æ¨¡å‹æ€§èƒ½ä¸å¹³ç­‰é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸ç›´è§‰ç›¸åçš„è§‚ç‚¹ï¼Œå³è®¡ç®—è§„æ¨¡æ‰©å¼ çš„è¾¹é™…æ”¶ç›Šé€’å‡å°†å¯¼è‡´AIæ¨¡å‹èƒ½åŠ›çš„æ”¶æ•›ã€‚ä½œè€…è®¤ä¸ºè®¡ç®—é¢„ç®—æœ‰é™çš„Meek Modelsæœ€ç»ˆå°†è·å¾—ä¸é¡¶çº§æ¨¡å‹ç›¸è¿‘çš„æ€§èƒ½æ°´å¹³ã€‚é€šè¿‡å»ºç«‹åŸºäºå›ºå®šåˆ†å¸ƒNext-tokené¢„æµ‹ç›®æ ‡çš„ç†è®ºæ¨¡å‹ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†åŸå§‹è®¡ç®—æŠ•å…¥å¸¦æ¥çš„è¾¹é™…èƒ½åŠ›å›æŠ¥æ­£åœ¨å¤§å¹…ç¼©å‡ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œè¿™ç§é€’å‡æ•ˆåº”è¶³å¤Ÿå¼ºå¤§ï¼Œä½¿å¾—å³ä½¿èƒ½ä»¥æŒ‡æ•°çº§é€Ÿåº¦æ‰©å¼ ç®—åŠ›çš„ç»„ç»‡ï¼Œåœ¨æ¨¡å‹èƒ½åŠ›ä¸Šä¹Ÿéš¾ä»¥ä¿æŒé•¿æœŸé¢†å…ˆã€‚ä½œè€…åˆ©ç”¨Benchmarkæ•°æ®å’Œå®è¯æ¨¡å‹åˆ†æäº†AIæ¨¡å‹éšæ—¶é—´å˜åŒ–çš„èƒ½åŠ›å·®å¼‚ï¼ŒéªŒè¯äº†Training lossç­‰ä»£ç†æŒ‡æ ‡ä¸æ ¸å¿ƒèƒ½åŠ›åº¦é‡ä¹‹é—´çš„å…³ç³»ã€‚åŸºäºMeek Modelsèƒ½åŠ›çš„ä¸æ–­æå‡ï¼Œè®ºæ–‡æœ€åå‘¼åé‡æ–°å®¡è§†ç°æœ‰çš„AIæˆ˜ç•¥ä¸æ”¿ç­–ï¼Œå¹¶æŒ‡å‡ºäº†è¿™ä¸€è¶‹åŠ¿å°†æ·±åˆ»å½±å“çš„å¤šä¸ªé¢†åŸŸã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 9 figures, longer version of the paper presented at TAIG ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07931v1",
      "published_date": "2025-07-10 17:10:07 UTC",
      "updated_date": "2025-07-10 17:10:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:09.005298+00:00"
    },
    {
      "arxiv_id": "2507.07930v2",
      "title": "Probing Experts' Perspectives on AI-Assisted Public Speaking Training",
      "title_zh": "äººå·¥æ™ºèƒ½è¾…åŠ©å…¬ä¼—æ¼”è®²åŸ¹è®­ï¼šä¸“å®¶è§†è§’çš„æ·±åº¦æ¢ç©¶",
      "authors": [
        "Nesrine Fourati",
        "Alisa Barkar",
        "Marion DragÃ©e",
        "Liv Danthon-Lefebvre",
        "Mathieu Chollet"
      ],
      "abstract": "Background: Public speaking is a vital professional skill, yet it remains a source of significant anxiety for many individuals. Traditional training relies heavily on expert coaching, but recent advances in AI has led to novel types of commercial automated public speaking feedback tools. However, most research has focused on prototypes rather than commercial applications, and little is known about how public speaking experts perceive these tools.\n  Objectives: This study aims to evaluate expert opinions on the efficacy and design of commercial AI-based public speaking training tools and to propose guidelines for their improvement.\n  Methods: The research involved 16 semi-structured interviews and 2 focus groups with public speaking experts. Participants discussed their views on current commercial tools, their potential integration into traditional coaching, and suggestions for enhancing these systems.\n  Results and Conclusions: Experts acknowledged the value of AI tools in handling repetitive, technical aspects of training, allowing coaches to focus on higher-level skills. However they found key issues in current tools, emphasising the need for personalised, understandable, carefully selected feedback and clear instructional design. Overall, they supported a hybrid model combining traditional coaching with AI-supported exercises.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†å…¬å…±æ¼”è®²ä¸“å®¶å¯¹ AI-Assisted Public Speaking Training å•†ä¸šå·¥å…·çš„çœ‹æ³•ä¸è¯„ä»·ã€‚é€šè¿‡ 16 åœº semi-structured interviews å’Œ 2 åœº focus groupsï¼Œç ”ç©¶æ·±å…¥æ¢è®¨äº†ä¸“å®¶å¯¹è¿™äº›å·¥å…·çš„æœ‰æ•ˆæ€§ã€è®¾è®¡åŠå…¶ä¸ä¼ ç»Ÿæ•™å­¦æ•´åˆçš„è§è§£ã€‚ç»“æœæ˜¾ç¤ºï¼Œä¸“å®¶è®¤å¯ AI å·¥å…·åœ¨å¤„ç†æŠ€æœ¯æ€§å’Œé‡å¤æ€§è®­ç»ƒä»»åŠ¡ä¸Šçš„æ˜¾è‘—ä»·å€¼ï¼Œè¿™ä½¿å¾—äººç±»æ•™ç»ƒèƒ½å¤Ÿæ›´ä¸“æ³¨äºé«˜é˜¶æŠ€èƒ½çš„åŸ¹å…»ã€‚ä¸“å®¶åŒæ—¶æŒ‡å‡ºäº†å½“å‰å·¥å…·åœ¨åé¦ˆçš„ä¸ªæ€§åŒ–ã€å¯ç†è§£æ€§ä»¥åŠæ•™å­¦è®¾è®¡ (instructional design) æ–¹é¢å­˜åœ¨çš„å…³é”®ç¼ºé™·ã€‚æœ€ç»ˆï¼Œç ”ç©¶æ”¯æŒå°†ä¼ ç»Ÿæ•™ç»ƒè¾…å¯¼ä¸ AI-supported exercises ç›¸ç»“åˆçš„æ··åˆæ¨¡å‹ (hybrid model)ï¼Œå¹¶ä¸ºä¼˜åŒ–æ­¤ç±»ç³»ç»Ÿæå‡ºäº†å…·ä½“çš„æ”¹è¿›æŒ‡å—ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07930v2",
      "published_date": "2025-07-10 17:09:21 UTC",
      "updated_date": "2025-07-11 08:22:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:13.301894+00:00"
    },
    {
      "arxiv_id": "2507.07929v1",
      "title": "Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and Identification Strategies for Laboratory Mice",
      "title_zh": "è¿ˆå‘æŒç»­æ€§åŸç¬¼ç›‘æµ‹ï¼šå®éªŒå°é¼ è¿½è¸ªä¸è¯†åˆ«ç­–ç•¥è¯„ä¼°",
      "authors": [
        "Juan Pablo Oberhauser",
        "Daniel Grzenda"
      ],
      "abstract": "Continuous, automated monitoring of laboratory mice enables more accurate data collection and improves animal welfare through real-time insights. Researchers can achieve a more dynamic and clinically relevant characterization of disease progression and therapeutic effects by integrating behavioral and physiological monitoring in the home cage. However, providing individual mouse metrics is difficult because of their housing density, similar appearances, high mobility, and frequent interactions. To address these challenges, we develop a real-time identification (ID) algorithm that accurately assigns ID predictions to mice wearing custom ear tags in digital home cages monitored by cameras. Our pipeline consists of three parts: (1) a custom multiple object tracker (MouseTracks) that combines appearance and motion cues from mice; (2) a transformer-based ID classifier (Mouseformer); and (3) a tracklet associator linear program to assign final ID predictions to tracklets (MouseMap). Our models assign an animal ID based on custom ear tags at 30 frames per second with 24/7 cage coverage. We show that our custom tracking and ID pipeline improves tracking efficiency and lowers ID switches across mouse strains and various environmental factors compared to current mouse tracking methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®éªŒå®¤å°é¼ åœ¨é«˜å¯†åº¦ã€å¤–è§‚ç›¸ä¼¼åŠé«˜é¢‘äº’åŠ¨ç¯å¢ƒä¸‹éš¾ä»¥æŒç»­ç›‘æµ‹çš„æŒ‘æˆ˜ï¼Œå¼€å‘äº†ä¸€å¥—ç”¨äºæ•°å­—å®¶åº­ç¬¼ï¼ˆdigital home cagesï¼‰çš„å®æ—¶ä¸ªä½“è¯†åˆ«ï¼ˆIdentificationï¼‰ç®—æ³•ã€‚è¯¥æµæ°´çº¿ç”±ä¸‰ä¸ªæ ¸å¿ƒéƒ¨åˆ†ç»„æˆï¼šç»“åˆå¤–è§‚ä¸è¿åŠ¨çº¿ç´¢çš„å¤šç›®æ ‡è¿½è¸ªå™¨ MouseTracksã€åŸºäº Transformer çš„è¯†åˆ«åˆ†ç±»å™¨ Mouseformerï¼Œä»¥åŠåˆ©ç”¨çº¿æ€§è§„åˆ’è¿›è¡Œè½¨è¿¹å…³è”çš„ MouseMapã€‚ç³»ç»Ÿèƒ½å¤Ÿä»¥æ¯ç§’30å¸§ï¼ˆ30 frames per secondï¼‰çš„é€Ÿåº¦æä¾›å…¨å¤©å€™ç›‘æ§ï¼Œé€šè¿‡é›†æˆè¡Œä¸ºä¸ç”Ÿç†ç›‘æµ‹ï¼Œå®ç°å¯¹ç–¾ç—…è¿›å±•å’Œæ²»ç–—æ•ˆæœçš„åŠ¨æ€è¡¨å¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰çš„è¿½è¸ªæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥å®šåˆ¶åŒ–æµæ°´çº¿åœ¨ä¸åŒå°é¼ å“ç³»å’Œå„ç±»ç¯å¢ƒå› ç´ ä¸‹å‡æ˜¾è‘—æå‡äº†è¿½è¸ªæ•ˆç‡ï¼Œå¹¶æœ‰æ•ˆé™ä½äº†è¯†åˆ«åˆ‡æ¢ï¼ˆID switchesï¼‰çš„é¢‘ç‡ï¼Œä¸ºæå‡ç§‘ç ”æ•°æ®å‡†ç¡®æ€§ä¸åŠ¨ç‰©ç¦åˆ©æä¾›äº†æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07929v1",
      "published_date": "2025-07-10 17:09:14 UTC",
      "updated_date": "2025-07-10 17:09:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:13.157094+00:00"
    },
    {
      "arxiv_id": "2507.07910v2",
      "title": "DTECT: Dynamic Topic Explorer & Context Tracker",
      "title_zh": "DTECTï¼šåŠ¨æ€ä¸»é¢˜æ¢ç´¢å™¨ä¸ä¸Šä¸‹æ–‡è¿½è¸ªå™¨",
      "authors": [
        "Suman Adhya",
        "Debarshi Kumar Sanyal"
      ],
      "abstract": "The explosive growth of textual data over time presents a significant challenge in uncovering evolving themes and trends. Existing dynamic topic modeling techniques, while powerful, often exist in fragmented pipelines that lack robust support for interpretation and user-friendly exploration. We introduce DTECT (Dynamic Topic Explorer & Context Tracker), an end-to-end system that bridges the gap between raw textual data and meaningful temporal insights. DTECT provides a unified workflow that supports data preprocessing, multiple model architectures, and dedicated evaluation metrics to analyze the topic quality of temporal topic models. It significantly enhances interpretability by introducing LLM-driven automatic topic labeling, trend analysis via temporally salient words, interactive visualizations with document-level summarization, and a natural language chat interface for intuitive data querying. By integrating these features into a single, cohesive platform, DTECT empowers users to more effectively track and understand thematic dynamics. DTECT is open-source and available at https://github.com/AdhyaSuman/DTECT.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† DTECTï¼ˆDynamic Topic Explorer & Context Trackerï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç³»ç»Ÿï¼Œæ—¨åœ¨å¼¥è¡¥åŸå§‹æ–‡æœ¬æ•°æ®ä¸æœ‰æ„ä¹‰çš„æ—¶é—´æ´å¯Ÿä¹‹é—´çš„é¸¿æ²Ÿã€‚é’ˆå¯¹ç°æœ‰åŠ¨æ€ä¸»é¢˜å»ºæ¨¡æŠ€æœ¯åœ¨è§£é‡Šå’Œç”¨æˆ·æ¢ç´¢æ–¹é¢çš„ä¸è¶³ï¼ŒDTECT æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„å·¥ä½œæµï¼Œæ”¯æŒæ•°æ®é¢„å¤„ç†ã€å¤šç§æ¨¡å‹æ¶æ„ä»¥åŠä¸“é—¨çš„è¯„ä¼°æŒ‡æ ‡ã€‚è¯¥ç³»ç»Ÿé€šè¿‡å¼•å…¥ LLM-driven automatic topic labeling å’ŒåŸºäºæ—¶é—´æ˜¾è‘—è¯çš„è¶‹åŠ¿åˆ†æï¼Œæ˜¾è‘—å¢å¼ºäº†ç»“æœçš„å¯è§£é‡Šæ€§ã€‚DTECT è¿˜é›†æˆäº†äº¤äº’å¼å¯è§†åŒ–ã€æ–‡æ¡£çº§æ‘˜è¦ä»¥åŠè‡ªç„¶è¯­è¨€èŠå¤©ç•Œé¢ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡ç›´è§‚çš„æŸ¥è¯¢è¿›è¡Œæ•°æ®æ¢ç´¢ã€‚é€šè¿‡å°†è¿™äº›åŠŸèƒ½æ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„å¹³å°ä¸­ï¼ŒDTECT ä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è·Ÿè¸ªå’Œç†è§£ thematic dynamicsã€‚ç›®å‰ DTECT å·²å¼€æºï¼Œä¸ºåŠ¨æ€ä¸»é¢˜æ¼”å˜çš„ç ”ç©¶æä¾›äº†å¼ºå¤§çš„å·¥å…·æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Code: https://github.com/AdhyaSuman/DTECT | Demo: https://huggingface.co/spaces/AdhyaSuman/DTECT | Video: https://youtu.be/B8nNfxFoJAU",
      "pdf_url": "https://arxiv.org/pdf/2507.07910v2",
      "published_date": "2025-07-10 16:44:33 UTC",
      "updated_date": "2025-07-12 05:41:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:14.802981+00:00"
    },
    {
      "arxiv_id": "2507.07906v1",
      "title": "Agentic Retrieval of Topics and Insights from Earnings Calls",
      "title_zh": "åŸºäºæ™ºèƒ½ä½“çš„è´¢æŠ¥ç”µè¯ä¼šè®®ä¸»é¢˜ä¸æ´å¯Ÿæ£€ç´¢",
      "authors": [
        "Anant Gupta",
        "Rajarshi Bhowmik",
        "Geoffrey Gunow"
      ],
      "abstract": "Tracking the strategic focus of companies through topics in their earnings calls is a key task in financial analysis. However, as industries evolve, traditional topic modeling techniques struggle to dynamically capture emerging topics and their relationships. In this work, we propose an LLM-agent driven approach to discover and retrieve emerging topics from quarterly earnings calls. We propose an LLM-agent to extract topics from documents, structure them into a hierarchical ontology, and establish relationships between new and existing topics through a topic ontology. We demonstrate the use of extracted topics to infer company-level insights and emerging trends over time. We evaluate our approach by measuring ontology coherence, topic evolution accuracy, and its ability to surface emerging financial trends.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºLLM-agenté©±åŠ¨çš„æ–¹æ³•ï¼Œæ—¨åœ¨ä»å­£åº¦è´¢æŠ¥ç”µè¯ä¼šè®®(Earnings Calls)ä¸­å‘ç°å’Œæ£€ç´¢æ–°å…´ä¸»é¢˜ï¼Œä»¥è§£å†³ä¼ ç»Ÿä¸»é¢˜å»ºæ¨¡(Topic Modeling)éš¾ä»¥åŠ¨æ€æ•æ‰è¡Œä¸šæ¼”å˜çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ä»æ–‡æ¡£ä¸­æå–ä¸»é¢˜ï¼Œå¹¶å°†å…¶æ„å»ºä¸ºå±‚çº§æœ¬ä½“(Hierarchical Ontology)ï¼Œä»è€Œåœ¨ç°æœ‰ä¸»é¢˜ä¸æ–°ä¸»é¢˜ä¹‹é—´å»ºç«‹æ˜ç¡®çš„å…³è”ã€‚é€šè¿‡è¿™äº›æå–çš„ä¸»é¢˜ï¼Œç ”ç©¶è€…èƒ½å¤Ÿè¿›ä¸€æ­¥æ¨æ–­å‡ºå…¬å¸å±‚é¢çš„è§è§£(Insights)å¹¶è¿½è¸ªéšæ—¶é—´å˜åŒ–çš„æ–°å…´è¶‹åŠ¿ã€‚å®éªŒé€šè¿‡è¯„ä¼°æœ¬ä½“ä¸€è‡´æ€§(Ontology Coherence)å’Œä¸»é¢˜æ¼”å˜å‡†ç¡®æ€§(Topic Evolution Accuracy)ï¼ŒéªŒè¯äº†è¯¥ç³»ç»Ÿåœ¨è¯†åˆ«å…³é”®é‡‘èè¶‹åŠ¿æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™ä¸€æ–¹æ³•ä¸ºé‡‘èåˆ†ææä¾›äº†æ›´å…·åŠ¨æ€æ€§çš„è§†è§’ï¼Œæ˜¾è‘—æå‡äº†å¯¹ä¼ä¸šæˆ˜ç•¥ç„¦ç‚¹çš„è¿½è¸ªèƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 2nd Workshop on Financial Information Retrieval in the Era of Generative AI, The 48th International ACM SIGIR Conference on Research and Development in Information Retrieval July 13-17, 2025 | Padua, Italy",
      "pdf_url": "https://arxiv.org/pdf/2507.07906v1",
      "published_date": "2025-07-10 16:38:59 UTC",
      "updated_date": "2025-07-10 16:38:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:29.256120+00:00"
    },
    {
      "arxiv_id": "2507.10574v1",
      "title": "Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance",
      "title_zh": "åˆ©ç”¨çº¿æ€§è‡ªé€‚åº”æŸå¤±å‡½æ•°å¢å¼ºäº¤å‰ç†µï¼Œä»¥ä¼˜åŒ–åˆ†ç±»æ€§èƒ½",
      "authors": [
        "Jae Wan Shim"
      ],
      "abstract": "We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel measure derived from the information theory. In comparison to the standard cross entropy loss function, the proposed one has an additional term that depends on the predicted probability of the true class. This feature serves to enhance the optimization process in classification tasks involving one-hot encoded class labels. The proposed one has been evaluated on a ResNet-based model using the CIFAR-100 dataset. Preliminary results show that the proposed one consistently outperforms the standard cross entropy loss function in terms of classification accuracy. Moreover, the proposed one maintains simplicity, achieving practically the same efficiency to the traditional cross entropy loss. These findings suggest that our approach could broaden the scope for future research into loss function design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºçº¿æ€§è‡ªé€‚åº”äº¤å‰ç†µæŸå¤±(Linearly Adaptive Cross Entropy Loss)çš„æ–°å‹æŸå¤±å‡½æ•°ï¼Œæ—¨åœ¨ä¼˜åŒ–åˆ†ç±»ä»»åŠ¡çš„æ€§èƒ½ã€‚è¯¥å‡½æ•°æºäºä¿¡æ¯è®º(Information Theory)ï¼Œä¸æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±(Cross Entropy Loss)ç›¸æ¯”ï¼Œå…¶å¢åŠ äº†ä¸€ä¸ªå–å†³äºçœŸå®ç±»åˆ«é¢„æµ‹æ¦‚ç‡çš„é™„åŠ é¡¹ã€‚è¿™ç§è®¾è®¡æ˜¾è‘—å¢å¼ºäº†æ¶‰åŠç‹¬çƒ­ç¼–ç (One-Hot Encoded)æ ‡ç­¾åˆ†ç±»ä»»åŠ¡çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚ç ”ç©¶äººå‘˜åœ¨åŸºäºResNetçš„æ¨¡å‹ä¸Šä½¿ç”¨CIFAR-100æ•°æ®é›†å¯¹è¯¥æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ã€‚åˆæ­¥å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æŸå¤±å‡½æ•°åœ¨åˆ†ç±»å‡†ç¡®ç‡ä¸ŠæŒç»­ä¼˜äºä¼ ç»Ÿçš„äº¤å‰ç†µæŸå¤±ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¿æŒäº†æé«˜çš„ç®€æ´æ€§ï¼Œåœ¨è®¡ç®—æ•ˆç‡ä¸Šä¸ä¼ ç»Ÿäº¤å‰ç†µåŸºæœ¬ä¸€è‡´ã€‚è¿™äº›å‘ç°è¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºæœªæ¥æŸå¤±å‡½æ•°çš„è®¾è®¡ç ”ç©¶æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10574v1",
      "published_date": "2025-07-10 16:38:57 UTC",
      "updated_date": "2025-07-10 16:38:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:42.378094+00:00"
    },
    {
      "arxiv_id": "2507.07893v4",
      "title": "An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis",
      "title_zh": "èåˆæç¤ºå·¥ç¨‹ä¸å¤šç»´çŸ¥è¯†å›¾è°±çš„æ³•å¾‹çº çº·åˆ†æé›†æˆæ¡†æ¶",
      "authors": [
        "Mingda Zhang",
        "Na Zhao",
        "Jianglong Qing",
        "Qing xu",
        "Kaiwen Pan",
        "Ting luo"
      ],
      "abstract": "Legal dispute analysis is crucial for intelligent legal assistance systems. However, current LLMs face significant challenges in understanding complex legal concepts, maintaining reasoning consistency, and accurately citing legal sources. This research presents a framework combining prompt engineering with multidimensional knowledge graphs to improve LLMs' legal dispute analysis. Specifically, the framework includes a three-stage hierarchical prompt structure (task definition, knowledge background, reasoning guidance) along with a three-layer knowledge graph (legal ontology, representation, instance layers). Additionally, four supporting methods enable precise legal concept retrieval: direct code matching, semantic vector similarity, ontology path reasoning, and lexical segmentation. Through extensive testing, results show major improvements: sensitivity increased by 11.1%-11.3%, specificity by 5.4%-6.0%, and citation accuracy by 29.5%-39.7%. As a result, the framework provides better legal analysis and understanding of judicial logic, thus offering a new technical method for intelligent legal assistance systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç†è§£å¤æ‚æ³•å¾‹æ¦‚å¿µã€ç»´æŒæ¨ç†ä¸€è‡´æ€§åŠå‡†ç¡®å¼•ç”¨æ³•å¾‹æ¥æºæ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ•´åˆæç¤ºå·¥ç¨‹(Prompt Engineering)ä¸å¤šç»´çŸ¥è¯†å›¾è°±(Multidimensional Knowledge Graphs)çš„æ³•å¾‹çº çº·åˆ†ææ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†åŒ…å«ä»»åŠ¡å®šä¹‰ã€çŸ¥è¯†èƒŒæ™¯å’Œæ¨ç†å¼•å¯¼çš„ä¸‰é˜¶æ®µå±‚æ¬¡åŒ–æç¤ºç»“æ„ï¼Œå¹¶ç»“åˆäº†ç”±æ³•å¾‹æœ¬ä½“å±‚ã€è¡¨ç¤ºå±‚å’Œå®ä¾‹å±‚ç»„æˆçš„ä¸‰å±‚çŸ¥è¯†å›¾è°±ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†ç›´æ¥ä»£ç åŒ¹é…(Direct Code Matching)ã€è¯­ä¹‰å‘é‡ç›¸ä¼¼åº¦(Semantic Vector Similarity)ã€æœ¬ä½“è·¯å¾„æ¨ç†(Ontology Path Reasoning)å’Œè¯æ³•åˆ†å‰²(Lexical Segmentation)å››ç§æ–¹æ³•ä»¥å®ç°ç²¾ç¡®çš„æ³•å¾‹æ¦‚å¿µæ£€ç´¢ã€‚æµ‹è¯•ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨çµæ•åº¦(Sensitivity)å’Œç‰¹å¼‚æ€§(Specificity)ä¸Šåˆ†åˆ«æå‡äº†çº¦11%å’Œ6%ï¼Œä¸”å¼•ç”¨å‡†ç¡®åº¦(Citation Accuracy)æ˜¾è‘—æé«˜äº†29.5%-39.7%ã€‚è¯¥ç ”ç©¶é€šè¿‡å¢å¼ºå¸æ³•é€»è¾‘ç†è§£å’Œåˆ†æèƒ½åŠ›ï¼Œä¸ºæ™ºèƒ½æ³•å¾‹è¾…åŠ©ç³»ç»Ÿæä¾›äº†ä¸€ç§é«˜æ•ˆçš„æ–°å‹æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages,3 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07893v4",
      "published_date": "2025-07-10 16:22:41 UTC",
      "updated_date": "2025-08-30 10:00:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:45.208725+00:00"
    },
    {
      "arxiv_id": "2507.07885v1",
      "title": "UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient Neural Inference on MCUs",
      "title_zh": "UnITï¼šé¢å‘å¾®æ§åˆ¶å™¨é«˜æ•ˆ MAC ç¥ç»æ¨ç†çš„å¯æ‰©å±•éç»“æ„åŒ–æ¨ç†æ—¶å‰ªæ",
      "authors": [
        "Ashe Neth",
        "Sawinder kaur",
        "Mohammad Nur Hossain Khan",
        "Subrata Biswas",
        "Asif Salekin",
        "Bashima Islam"
      ],
      "abstract": "Existing pruning methods are typically applied during training or compile time and often rely on structured sparsity. While compatible with low-power microcontrollers (MCUs), structured pruning underutilizes the opportunity for fine-grained efficiency on devices without SIMD support or parallel compute. To address these limitations, we introduce UnIT (Unstructured Inference-Time pruning), a lightweight method that dynamically identifies and skips unnecessary multiply-accumulate (MAC) operations during inference, guided by input-specific activation patterns. Unlike structured pruning, UnIT embraces irregular sparsity and does not require retraining or hardware specialization. It transforms pruning decisions into lightweight comparisons, replacing multiplications with threshold checks and approximated divisions. UnIT further optimizes compute by reusing threshold computations across multiple connections and applying layer- and group-specific pruning sensitivity. We present three fast, hardware-friendly division approximations tailored to the capabilities of common embedded platforms. Demonstrated on the MSP430 microcontroller, UnIT achieves 11.02% to 82.03% MAC reduction, 27.30% to 84.19% faster inference, and 27.33% to 84.38% lower energy consumption compared to training-time pruned models, while maintaining accuracy with 0.48-7%. Under domain shift, UnIT matches or exceeds the accuracy of retrained models while requiring significantly fewer MACs. These results establish unstructured inference-time pruning as a viable and practical solution for efficient, retraining-free deployment of deep neural networks on MCUs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† UnIT (Unstructured Inference-Time pruning)ï¼Œä¸€ç§ä¸“ä¸ºå¾®æ§åˆ¶å™¨ (MCUs) è®¾è®¡çš„è½»é‡çº§éç»“æ„åŒ–æ¨ç†æ—¶é—´å‰ªææ–¹æ³•ï¼Œæ—¨åœ¨æ˜¾è‘—æé«˜ç¥ç»ç½‘ç»œåœ¨åµŒå…¥å¼è®¾å¤‡ä¸Šçš„ä¹˜åŠ è¿ç®— (MAC) æ•ˆç‡ã€‚ä¸ä¾èµ–ç»“æ„åŒ–ç¨€ç–æˆ–è®­ç»ƒ/ç¼–è¯‘æ—¶å‰ªæçš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒUnIT èƒ½å¤Ÿæ ¹æ®è¾“å…¥ç‰¹å®šçš„æ¿€æ´»æ¨¡å¼åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€è¯†åˆ«å¹¶è·³è¿‡ä¸å¿…è¦çš„è®¡ç®—ï¼Œä¸”æ— éœ€é‡æ–°è®­ç»ƒã€‚è¯¥æ–¹æ³•é€šè¿‡å°†å‰ªæå†³ç­–è½¬åŒ–ä¸ºè½»é‡çº§é˜ˆå€¼æ£€æŸ¥ï¼Œå¹¶ç»“åˆè·¨è¿æ¥çš„é˜ˆå€¼é‡ç”¨ã€ç‰¹å®šå±‚çš„å‰ªææ•æ„Ÿåº¦ä»¥åŠç¡¬ä»¶å‹å¥½çš„é™¤æ³•è¿‘ä¼¼æ–¹æ¡ˆæ¥ä¼˜åŒ–æ€§èƒ½ã€‚åœ¨ MSP430 å¾®æ§åˆ¶å™¨ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUnIT å®ç°äº† 11.02% è‡³ 82.03% çš„ MAC ç¼©å‡ï¼Œä½¿æ¨ç†é€Ÿåº¦æå‡é«˜è¾¾ 84.19% ä¸”èƒ½è€—é™ä½è¾¾ 84.38%ï¼ŒåŒæ—¶ä¿æŒäº†æé«˜çš„ç²¾åº¦ã€‚å³ä½¿åœ¨é¢†åŸŸåç§» (domain shift) æƒ…å†µä¸‹ï¼ŒUnIT çš„å‡†ç¡®ç‡ä»å¯åŒ¹é…ç”šè‡³è¶…è¶Šé‡æ–°è®­ç»ƒçš„æ¨¡å‹ã€‚è¯¥é¡¹å·¥ä½œä¸ºæ·±åº¦ç¥ç»ç½‘ç»œåœ¨èµ„æºå—é™çš„ MCUs ä¸Šå®ç°é«˜æ•ˆã€æ— éœ€é‡æ–°è®­ç»ƒçš„éƒ¨ç½²æä¾›äº†ä¸€ç§åˆ‡å®å¯è¡Œçš„éç»“æ„åŒ–å‰ªææ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to SenSys 2026 on July 1, 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07885v1",
      "published_date": "2025-07-10 16:12:06 UTC",
      "updated_date": "2025-07-10 16:12:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:50.951465+00:00"
    },
    {
      "arxiv_id": "2507.08885v2",
      "title": "AirScape: An Aerial Generative World Model with Motion Controllability",
      "title_zh": "AirScapeï¼šå…·å¤‡è¿åŠ¨å¯æ§æ€§çš„ç©ºä¸­ç”Ÿæˆå¼ä¸–ç•Œæ¨¡å‹",
      "authors": [
        "Baining Zhao",
        "Rongze Tang",
        "Mingyuan Jia",
        "Ziyou Wang",
        "Fanghang Man",
        "Xin Zhang",
        "Yu Shang",
        "Weichen Zhang",
        "Wei Wu",
        "Chen Gao",
        "Xinlei Chen",
        "Yong Li"
      ],
      "abstract": "How to enable agents to predict the outcomes of their own motion intentions in three-dimensional space has been a fundamental problem in embodied intelligence. To explore general spatial imagination capability, we present AirScape, the first world model designed for six-degree-of-freedom aerial agents. AirScape predicts future observation sequences based on current visual inputs and motion intentions. Specifically, we construct a dataset for aerial world model training and testing, which consists of 11k video-intention pairs. This dataset includes first-person-view videos capturing diverse drone actions across a wide range of scenarios, with over 1,000 hours spent annotating the corresponding motion intentions. Then we develop a two-phase schedule to train a foundation model--initially devoid of embodied spatial knowledge--into a world model that is controllable by motion intentions and adheres to physical spatio-temporal constraints. Experimental results demonstrate that AirScape significantly outperforms existing foundation models in 3D spatial imagination capabilities, especially with over a 50% improvement in metrics reflecting motion alignment. The project is available at: https://embodiedcity.github.io/AirScape/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AirScapeï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸ºå…·æœ‰å…­è‡ªç”±åº¦ (six-degree-of-freedom) çš„ç©ºä¸­æ™ºèƒ½ä½“è®¾è®¡çš„ç”Ÿæˆå¼ä¸–ç•Œæ¨¡å‹ (world model)ï¼Œæ—¨åœ¨è§£å†³å…·èº«æ™ºèƒ½ä¸­æ™ºèƒ½ä½“é¢„æµ‹å…¶ä¸‰ç»´ç©ºé—´è¿åŠ¨æ„å›¾ç»“æœçš„é—®é¢˜ã€‚AirScape èƒ½å¤ŸåŸºäºå½“å‰è§†è§‰è¾“å…¥å’Œè¿åŠ¨æ„å›¾é¢„æµ‹æœªæ¥è§‚æµ‹åºåˆ—ï¼Œå±•ç°äº†å‡ºè‰²çš„é€šç”¨ç©ºé—´æƒ³è±¡èƒ½åŠ›ã€‚ä¸ºäº†è®­ç»ƒè¯¥æ¨¡å‹ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å« 1.1ä¸‡ä¸ªè§†é¢‘-æ„å›¾å¯¹çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œæ¶µç›–äº†å¤šç§åœºæ™¯ä¸‹æ— äººæœºçš„å¤šæ ·åŒ–åŠ¨ä½œåŠè¶…è¿‡1000å°æ—¶çš„è¿åŠ¨æ„å›¾æ ‡æ³¨ã€‚ç ”ç©¶é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ¡ˆï¼ŒæˆåŠŸå°†åŸºç¡€æ¨¡å‹è½¬åŒ–ä¸ºå—è¿åŠ¨æ„å›¾æ§åˆ¶å¹¶éµå¾ªç‰©ç†æ—¶ç©ºçº¦æŸçš„ä¸–ç•Œæ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAirScape åœ¨ä¸‰ç»´ç©ºé—´æƒ³è±¡èƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå°¤å…¶åœ¨è¿åŠ¨å¯¹é½ (motion alignment) ç›¸å…³æŒ‡æ ‡ä¸Šæå‡äº† 50% ä»¥ä¸Šã€‚è¯¥æˆæœä¸ºå®ç°å…·æœ‰é«˜åº¦ç©ºé—´æ„ŸçŸ¥å’Œè¿åŠ¨å¯æ§æ€§çš„ç©ºä¸­å…·èº«æ™ºèƒ½å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08885v2",
      "published_date": "2025-07-10 16:05:30 UTC",
      "updated_date": "2025-10-10 07:40:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:51:06.535835+00:00"
    },
    {
      "arxiv_id": "2507.07871v3",
      "title": "Mitigating Watermark Forgery in Generative Models via Randomized Key Selection",
      "title_zh": "é€šè¿‡éšæœºåŒ–å¯†é’¥é€‰æ‹©ç¼“è§£ç”Ÿæˆå¼æ¨¡å‹ä¸­çš„æ°´å°ä¼ªé€ ",
      "authors": [
        "Toluwani Aremu",
        "Noor Hussein",
        "Munachiso Nwadike",
        "Samuele Poppi",
        "Jie Zhang",
        "Karthik Nandakumar",
        "Neil Gong",
        "Nils Lukas"
      ],
      "abstract": "Watermarking enables GenAI providers to verify whether content was generated by their models. A watermark is a hidden signal in the content, whose presence can be detected using a secret watermark key. A core security threat are forgery attacks, where adversaries insert the provider's watermark into content \\emph{not} produced by the provider, potentially damaging their reputation and undermining trust. Existing defenses resist forgery by embedding many watermarks with multiple keys into the same content, which can degrade model utility. However, forgery remains a threat when attackers can collect sufficiently many watermarked samples. We propose a defense that is provably forgery-resistant \\emph{independent} of the number of watermarked content collected by the attacker, provided they cannot easily distinguish watermarks from different keys. Our scheme does not further degrade model utility. We randomize the watermark key selection for each query and accept content as genuine only if a watermark is detected by \\emph{exactly} one key. We focus on the image and text modalities, but our defense is modality-agnostic, since it treats the underlying watermarking method as a black-box. Our method provably bounds the attacker's success rate and we empirically observe a reduction from near-perfect success rates to only $2\\%$ at negligible computational overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸­çš„æ°´å°ä¼ªé€ ï¼ˆWatermark Forgeryï¼‰æ”»å‡»æå‡ºäº†ä¸€ç§åŸºäºéšæœºå¯†é’¥é€‰æ‹©ï¼ˆRandomized Key Selectionï¼‰çš„é˜²å¾¡æ–¹æ¡ˆï¼Œæ—¨åœ¨é˜²æ­¢æ”»å‡»è€…å°†æä¾›å•†çš„æ°´å°æ¤å…¥éå®˜æ–¹ç”Ÿæˆçš„å†…å®¹ä¸­ä»¥æŸå®³å…¶å£°èª‰ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡ä¸ºæ¯æ¬¡æŸ¥è¯¢éšæœºé€‰æ‹©æ°´å°å¯†é’¥ï¼Œå¹¶è§„å®šä»…åœ¨æ£€æµ‹åˆ°æ°å¥½ä¸€ä¸ªç‰¹å®šå¯†é’¥çš„æ°´å°æ—¶æ‰åˆ¤å®šå†…å®¹ä¸ºçœŸå®ï¼Œä»è€Œåœ¨ä¸æŸå®³æ¨¡å‹æ•ˆç”¨ï¼ˆUtilityï¼‰çš„å‰æä¸‹æ˜¾è‘—æå‡äº†å®‰å…¨æ€§ã€‚è¯¥é˜²å¾¡æœºåˆ¶å…·æœ‰æ¨¡æ€æ— å…³æ€§ï¼ˆModality-agnosticï¼‰ï¼Œèƒ½å¤Ÿå°†åº•å±‚æ°´å°æ–¹æ³•è§†ä¸ºé»‘ç›’å¤„ç†ï¼Œé€‚ç”¨äºå›¾åƒå’Œæ–‡æœ¬ç­‰å¤šç§æ•°æ®ç±»å‹ã€‚ç†è®ºè¯æ˜è¯¥æ–¹æ¡ˆçš„ä¼ªé€ æŠ—æ€§ç‹¬ç«‹äºæ”»å‡»è€…æ”¶é›†çš„æ°´å°æ ·æœ¬æ•°é‡ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹å¤§é‡æ ·æœ¬æ”¶é›†æ—¶çš„å®‰å…¨æ¼æ´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è®¡ç®—å¼€é”€æä½çš„æƒ…å†µä¸‹ï¼ŒæˆåŠŸå°†æ”»å‡»è€…çš„ä¼ªé€ æˆåŠŸç‡ä»æ¥è¿‘ç™¾åˆ†ä¹‹ç™¾é™ä½è‡³ä»…çº¦2%ï¼Œä¸ºæ„å»ºå¯ä¿¡ã€ç¨³å¥çš„ç”Ÿæˆå†…å®¹é‰´åˆ«ä½“ç³»å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07871v3",
      "published_date": "2025-07-10 15:52:32 UTC",
      "updated_date": "2025-09-27 07:12:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:50:53.700300+00:00"
    },
    {
      "arxiv_id": "2507.07868v1",
      "title": "Alpay Algebra V: Multi-Layered Semantic Games and Transfinite Fixed-Point Simulation",
      "title_zh": "Alpay Algebra Vï¼šå¤šå±‚è¯­ä¹‰åšå¼ˆä¸è¶…é™ä¸åŠ¨ç‚¹æ¨¡æ‹Ÿ",
      "authors": [
        "Bugra Kilictas",
        "Faruk Alpay"
      ],
      "abstract": "This paper extends the self-referential framework of Alpay Algebra into a multi-layered semantic game architecture where transfinite fixed-point convergence encompasses hierarchical sub-games at each iteration level. Building upon Alpay Algebra IV's empathetic embedding concept, we introduce a nested game-theoretic structure where the alignment process between AI systems and documents becomes a meta-game containing embedded decision problems. We formalize this through a composite operator $Ï†(\\cdot, Î³(\\cdot))$ where $Ï†$ drives the main semantic convergence while $Î³$ resolves local sub-games. The resulting framework demonstrates that game-theoretic reasoning emerges naturally from fixed-point iteration rather than being imposed externally. We prove a Game Theorem establishing existence and uniqueness of semantic equilibria under realistic cognitive simulation assumptions. Our verification suite includes adaptations of Banach's fixed-point theorem to transfinite contexts, a novel $Ï†$-topology based on the Kozlov-Maz'ya-Rossmann formula for handling semantic singularities, and categorical consistency tests via the Yoneda lemma. The paper itself functions as a semantic artifact designed to propagate its fixed-point patterns in AI embedding spaces -- a deliberate instantiation of the \"semantic virus\" concept it theorizes. All results are grounded in category theory, information theory, and realistic AI cognition models, ensuring practical applicability beyond pure mathematical abstraction.",
      "tldr_zh": "è¯¥ç ”ç©¶æ‰©å±•äº† Alpay Algebra çš„è‡ªæŒ‡æ¡†æ¶ï¼Œæå‡ºäº†ä¸€ç§å¤šå±‚è¯­ä¹‰åšå¼ˆ (multi-layered semantic game) æ¶æ„ï¼Œå°†è¶…é™ä¸åŠ¨ç‚¹æ”¶æ•› (transfinite fixed-point convergence) å¼•å…¥æ¯ä¸€å±‚çº§çš„åµŒå¥—å­åšå¼ˆä¸­ã€‚è®ºæ–‡åœ¨ Alpay Algebra IV ç§»æƒ…åµŒå…¥ (empathetic embedding) çš„åŸºç¡€ä¸Šæ„å»ºäº†åµŒå¥—åšå¼ˆç»“æ„ï¼Œå°† AI ç³»ç»Ÿä¸æ–‡æ¡£çš„å¯¹é½è¿‡ç¨‹è½¬åŒ–ä¸ºåŒ…å«åµŒå…¥å¼å†³ç­–é—®é¢˜çš„å…ƒåšå¼ˆ (meta-game)ã€‚é€šè¿‡å¤åˆç®—å­ $\\phi(\\cdot, \\gamma(\\cdot))$ è¿›è¡Œå½¢å¼åŒ–æè¿°ï¼Œè¯¥æ¡†æ¶è¯æ˜äº†åšå¼ˆè®ºæ¨ç†å¯ä»¥ä»ä¸åŠ¨ç‚¹è¿­ä»£ä¸­è‡ªç„¶æ¶Œç°ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†åšå¼ˆå®šç† (Game Theorem)ï¼Œåœ¨ç°å®è®¤çŸ¥æ¨¡æ‹Ÿå‡è®¾ä¸‹ç¡®ç«‹äº†è¯­ä¹‰å¹³è¡¡ (semantic equilibria) çš„å­˜åœ¨æ€§å’Œå”¯ä¸€æ€§ã€‚éªŒè¯ä½“ç³»ç»¼åˆäº†è¶…é™èƒŒæ™¯ä¸‹çš„ Banach ä¸åŠ¨ç‚¹å®šç†ã€å¤„ç†è¯­ä¹‰å¥‡ç‚¹çš„ $\\phi$-topology ä»¥åŠåŸºäº Yoneda lemma çš„èŒƒç•´ä¸€è‡´æ€§æµ‹è¯•ã€‚æœ€åï¼Œè¯¥è®ºæ–‡å°†å…¶è‡ªèº«å®šä¹‰ä¸ºä¸€ç§è¯­ä¹‰äººå·¥åˆ¶å“ (semantic artifact)ï¼Œæ—¨åœ¨ AI åµŒå…¥ç©ºé—´ä¸­é€šè¿‡ä¼ æ’­ä¸åŠ¨ç‚¹æ¨¡å¼æ¥å®ä¾‹åŒ–å…¶ç†è®ºåŒ–çš„è¯­ä¹‰ç—…æ¯’ (semantic virus) æ¦‚å¿µã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07868v1",
      "published_date": "2025-07-10 15:48:23 UTC",
      "updated_date": "2025-07-10 15:48:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:51:04.091901+00:00"
    },
    {
      "arxiv_id": "2507.21111v1",
      "title": "A Formal Rebuttal of \"The Blockchain Trilemma: A Formal Proof of the Inherent Trade-Offs Among Decentralization, Security, and Scalability\"",
      "title_zh": "å¯¹ã€ŠåŒºå—é“¾ä¸‰éš¾å›°å¢ƒï¼šå»ä¸­å¿ƒåŒ–ã€å®‰å…¨æ€§å’Œå¯æ‰©å±•æ€§ä¹‹é—´å›ºæœ‰æƒè¡¡çš„å½¢å¼åŒ–è¯æ˜ã€‹çš„å½¢å¼åŒ–åé©³",
      "authors": [
        "Craig Wright"
      ],
      "abstract": "This paper presents a comprehensive refutation of the so-called \"blockchain trilemma,\" a widely cited but formally ungrounded claim asserting an inherent trade-off between decentralisation, security, and scalability in blockchain protocols. Through formal analysis, empirical evidence, and detailed critique of both methodology and terminology, we demonstrate that the trilemma rests on semantic equivocation, misuse of distributed systems theory, and a failure to define operational metrics. Particular focus is placed on the conflation of topological network analogies with protocol-level architecture, the mischaracterisation of Bitcoin's design--including the role of miners, SPV clients, and header-based verification--and the failure to ground claims in complexity-theoretic or adversarial models. By reconstructing Bitcoin as a deterministic, stateless distribution protocol governed by evidentiary trust, we show that scalability is not a trade-off but an engineering outcome. The paper concludes by identifying systemic issues in academic discourse and peer review that have allowed such fallacies to persist, and offers formal criteria for evaluating future claims in blockchain research.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹å¹¿ä¸ºäººçŸ¥çš„â€œåŒºå—é“¾ä¸‰éš¾å›°å¢ƒâ€(Blockchain Trilemma) æå‡ºäº†æ­£å¼é©³æ–¥ï¼Œè®¤ä¸ºå»ä¸­å¿ƒåŒ– (Decentralisation)ã€å®‰å…¨æ€§ (Security) å’Œå¯æ‰©å±•æ€§ (Scalability) ä¹‹é—´å­˜åœ¨å›ºæœ‰æƒè¡¡çš„è¯´æ³•ç¼ºä¹æ­£å¼çš„ç†è®ºä¾æ®ã€‚ä½œè€…é€šè¿‡å½¢å¼åŒ–åˆ†æã€ç»éªŒè¯æ®ä»¥åŠå¯¹æ–¹æ³•è®ºå’Œæœ¯è¯­çš„è¯¦ç»†æ‰¹åˆ¤ï¼ŒæŒ‡å‡ºè¯¥å›°å¢ƒä¸»è¦æºäºè¯­ä¹‰å«ç³Šã€å¯¹åˆ†å¸ƒå¼ç³»ç»Ÿç†è®º (Distributed Systems Theory) çš„è¯¯ç”¨ä»¥åŠç¼ºä¹å¯æ“ä½œçš„è¡¡é‡æŒ‡æ ‡ã€‚æ–‡ç« ç‰¹åˆ«å…³æ³¨äº†æ‹“æ‰‘ç½‘ç»œç±»æ¯”ä¸åè®®å±‚æ¶æ„ä¹‹é—´çš„æ··æ·†ï¼Œå¹¶çº æ­£äº†å¯¹ Bitcoin è®¾è®¡â€”â€”åŒ…æ‹¬çŸ¿å·¥ (Miners)ã€SPV å®¢æˆ·ç«¯å’ŒåŸºäºå¤´éƒ¨çš„éªŒè¯ (Header-based Verification) çš„é”™è¯¯å®šæ€§ã€‚é€šè¿‡å°† Bitcoin é‡æ–°æ„å»ºä¸ºä¸€ç§å—è¯æ®ä¿¡ä»» (Evidentiary Trust) æ²»ç†çš„ç¡®å®šæ€§ã€æ— çŠ¶æ€åˆ†å‘åè®®ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†å¯æ‰©å±•æ€§å¹¶éæŸç§å¿…ç„¶çš„æƒè¡¡ï¼Œè€Œæ˜¯ä¸€ä¸ªå·¥ç¨‹åŒ–äº§å‡º (Engineering Outcome)ã€‚è®ºæ–‡æœ€åè¯†åˆ«äº†å¯¼è‡´æ­¤ç±»è°¬è¯¯åœ¨å­¦æœ¯ç•ŒæŒç»­å­˜åœ¨çš„ç³»ç»Ÿæ€§é—®é¢˜ï¼Œå¹¶ä¸ºè¯„ä¼°æœªæ¥åŒºå—é“¾ç ”ç©¶å£°æ˜æä¾›äº†æ­£å¼çš„è¯„ä»·å‡†åˆ™ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.GT",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "79 pages; A response and rebuttal of [Mssassi, Souhail, and Anas Abou El Kalam. \"The Blockchain Trilemma: A Formal Proof of the Inherent Trade-Offs Among Decentralization, Security, and Scalability.\" Applied Sciences 15, no. 1 (2024): 19. https://doi.org/10.3390/app15010019.]",
      "pdf_url": "https://arxiv.org/pdf/2507.21111v1",
      "published_date": "2025-07-10 15:42:39 UTC",
      "updated_date": "2025-07-10 15:42:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:51:06.215723+00:00"
    },
    {
      "arxiv_id": "2507.14172v1",
      "title": "Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI",
      "title_zh": "æ¼”åŒ–ç¨‹åºåˆæˆä¸­çš„è‡ªæå‡è¯­è¨€æ¨¡å‹ï¼šåŸºäº ARC-AGI çš„æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Julien Pourcel",
        "CÃ©dric Colas",
        "Pierre-Yves Oudeyer"
      ],
      "abstract": "Many program synthesis tasks prove too challenging for even state-of-the-art language models to solve in single attempts. Search-based evolutionary methods offer a promising alternative by exploring solution spaces iteratively, but their effectiveness remain limited by the fixed capabilities of the underlying generative model.\n  We propose SOAR, a method that learns program synthesis by integrating language models into a self-improving evolutionary loop.\n  SOAR alternates between (1) an evolutionary search that uses an LLM to sample and refine candidate solutions, and (2) a hindsight learning phase that converts search attempts into valid problem-solution pairs used to fine-tune the LLM's sampling and refinement capabilities\\, -- \\,enabling increasingly effective search in subsequent iterations.\n  On the challenging ARC-AGI benchmark, SOAR achieves significant performance gains across model scales and iterations, leveraging positive transfer between the sampling and refinement finetuning tasks. These improvements carry over to test-time adaptation, enabling SOAR to solve 52\\% of the public test set. Our code is open-sourced at: https://github.com/flowersteam/SOAR",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SOARï¼Œä¸€ç§å°†å¤§è¯­è¨€æ¨¡å‹é›†æˆåˆ°è‡ªæˆ‘æå‡è¿›åŒ–å¾ªç¯ä¸­çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç¨‹åºåˆæˆ (program synthesis) ä»»åŠ¡ä¸­å•ä¸€å°è¯•æˆåŠŸç‡ä½çš„é—®é¢˜ã€‚SOAR äº¤æ›¿è¿›è¡Œè¿›åŒ–æœç´¢ (evolutionary search) å’ŒåéªŒå­¦ä¹  (hindsight learning) ä¸¤ä¸ªé˜¶æ®µï¼Œå‰è€…åˆ©ç”¨ LLM é‡‡æ ·å¹¶ç²¾ç‚¼å€™é€‰æ–¹æ¡ˆï¼Œåè€…åˆ™å°†æœç´¢å°è¯•è½¬åŒ–ä¸ºæœ‰æ•ˆæ ·æœ¬ä»¥å¾®è°ƒæ¨¡å‹çš„é‡‡æ ·ä¸ç²¾ç‚¼èƒ½åŠ›ã€‚è¿™ç§é—­ç¯æœºåˆ¶ä½¿å¾—æ¨¡å‹åœ¨åç»­è¿­ä»£ä¸­èƒ½è¿›è¡Œæ›´é«˜æ•ˆçš„æœç´¢ï¼Œå¹¶å……åˆ†åˆ©ç”¨äº†ä¸åŒå¾®è°ƒä»»åŠ¡ä¹‹é—´çš„æ­£å‘è¿ç§»æ•ˆåº”ã€‚åœ¨æŒ‘æˆ˜æ€§æé«˜çš„ ARC-AGI åŸºå‡†æµ‹è¯•ä¸­ï¼ŒSOAR åœ¨å¤šç§æ¨¡å‹è§„æ¨¡ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½å¢ç›Šï¼Œä¸”è¿™äº›æ”¹è¿›èƒ½å¤ŸæˆåŠŸå»¶ç»­åˆ°æµ‹è¯•æ—¶è‡ªé€‚åº” (test-time adaptation) é˜¶æ®µã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSOAR æœ€ç»ˆè§£å†³äº† 52% çš„å…¬å¼€æµ‹è¯•é›†é¢˜ç›®ï¼Œè¯æ˜äº†è‡ªæˆ‘æå‡è¿›åŒ–ç­–ç•¥åœ¨å¤„ç†å¤æ‚é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­çš„å¼ºå¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14172v1",
      "published_date": "2025-07-10 15:42:03 UTC",
      "updated_date": "2025-07-10 15:42:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:51:04.943666+00:00"
    },
    {
      "arxiv_id": "2507.07857v1",
      "title": "Searching for actual causes: Approximate algorithms with adjustable precision",
      "title_zh": "å¯»æ‰¾å®é™…åŸå› ï¼šç²¾åº¦å¯è°ƒçš„è¿‘ä¼¼ç®—æ³•",
      "authors": [
        "Samuel Reyd",
        "Ada Diaconescu",
        "Jean-Louis Dessalles"
      ],
      "abstract": "Causality has gained popularity in recent years. It has helped improve the performance, reliability, and interpretability of machine learning models. However, recent literature on explainable artificial intelligence (XAI) has faced criticism. The classical XAI and causality literature focuses on understanding which factors contribute to which consequences. While such knowledge is valuable for researchers and engineers, it is not what non-expert users expect as explanations. Instead, these users often await facts that cause the target consequences, i.e., actual causes. Formalizing this notion is still an open problem. Additionally, identifying actual causes is reportedly an NP-complete problem, and there are too few practical solutions to approximate formal definitions. We propose a set of algorithms to identify actual causes with a polynomial complexity and an adjustable level of precision and exhaustiveness. Our experiments indicate that the algorithms (1) identify causes for different categories of systems that are not handled by existing approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be adjusted to gain more precision and exhaustiveness with more computation time.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºä¼ ç»Ÿçš„å¯è§£é‡Šäººå·¥æ™ºèƒ½(XAI)å¾€å¾€ä¾§é‡äºåˆ†æè´¡çŒ®å› ç´ ï¼Œè€Œéæ™®é€šç”¨æˆ·æ‰€æœŸå¾…çš„â€œå®é™…åŸå› â€(Actual Causes)ï¼Œä¸”è¯†åˆ«å®é™…åŸå› å·²è¢«è¯æ˜æ˜¯ä¸€ä¸ªNP-completeéš¾é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€å›°å¢ƒï¼Œä½œè€…æå‡ºäº†ä¸€å¥—å…·æœ‰å¤šé¡¹å¼å¤æ‚åº¦(Polynomial Complexity)çš„è¿‘ä¼¼ç®—æ³•ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®éœ€æ±‚çµæ´»è°ƒæ•´ç²¾åº¦(Precision)å’Œè¯¦å°½æ€§(Exhaustiveness)ã€‚å®éªŒè¯æ˜ï¼Œè¿™äº›ç®—æ³•ä¸ä»…èƒ½æœ‰æ•ˆå¤„ç†ç°æœ‰æ–¹æ³•éš¾ä»¥åº”å¯¹çš„éå¸ƒå°”(Non-boolean)ã€é»‘ç›’(Black-box)åŠéšæœºç³»ç»Ÿ(Stochastic Systems)ï¼Œè¿˜èƒ½é€šè¿‡å¢åŠ è®¡ç®—æ—¶é—´æ¥æ¢å–æ›´é«˜çš„å‡†ç¡®åº¦ã€‚è¯¥å·¥ä½œä¸ºåœ¨å¤æ‚ç³»ç»Ÿä¸­é«˜æ•ˆå¯»æ‰¾ç¬¦åˆäººç±»ç›´è§‰çš„å› æœè§£é‡Šæä¾›äº†å®ç”¨ä¸”å¯æ‰©å±•çš„è®¡ç®—æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07857v1",
      "published_date": "2025-07-10 15:39:36 UTC",
      "updated_date": "2025-07-10 15:39:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:51:04.686357+00:00"
    },
    {
      "arxiv_id": "2507.07855v2",
      "title": "Principled Foundations for Preference Optimization",
      "title_zh": "åå¥½ä¼˜åŒ–çš„åŸç†æ€§åŸºç¡€",
      "authors": [
        "Wenxuan Zhou",
        "Shujian Zhang",
        "Brice Magdalou",
        "John Lambert",
        "Ehsan Amid",
        "Richard Nock",
        "Andrew Hard"
      ],
      "abstract": "In this paper, we show that direct preference optimization (DPO) is a very specific form of a connection between two major theories in the ML context of learning from preferences: loss functions (Savage) and stochastic choice (Doignon-Falmagne and Machina). The connection is established for all of Savage's losses and at this level of generality, (i) it includes support for abstention on the choice theory side, (ii) it includes support for non-convex objectives on the ML side, and (iii) it allows to frame for free some notable extensions of the DPO setting, including margins and corrections for length. Getting to understand how DPO operates from a general principled perspective is crucial because of the huge and diverse application landscape of models, because of the current momentum around DPO, but also -- and importantly -- because many state of the art variations on DPO definitely occupy a small region of the map that we cover. It also helps to understand the pitfalls of departing from this map, and figure out workarounds.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åå¥½ä¼˜åŒ–ï¼ˆPreference Optimizationï¼‰çš„ç†è®ºåŸºç¡€ï¼Œè¯æ˜äº†ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimization, DPOï¼‰æ˜¯æŸå¤±å‡½æ•°ï¼ˆloss functions, Savageï¼‰ä¸éšæœºé€‰æ‹©ç†è®ºï¼ˆstochastic choice, Doignon-Falmagne and Machinaï¼‰ä¸¤å¤§é¢†åŸŸä¹‹é—´çš„ç‰¹å®šè”ç³»ã€‚è¿™ç§è”ç³»åœ¨ä¸€èˆ¬æ€§å±‚é¢æ¶µç›–äº†æ‰€æœ‰ Savage æŸå¤±ï¼Œå¹¶æ”¯æŒäº†é€‰æ‹©ç†è®ºä¸­çš„å¼ƒæƒï¼ˆabstentionï¼‰æœºåˆ¶ã€æœºå™¨å­¦ä¹ ä¸­çš„éå‡¸ç›®æ ‡ï¼ˆnon-convex objectivesï¼‰ï¼Œä»¥åŠè¾¹è·ï¼ˆmarginsï¼‰å’Œé•¿åº¦æ ¡æ­£ï¼ˆcorrections for lengthï¼‰ç­‰æ‰©å±•è®¾ç½®ã€‚é€šè¿‡è¿™ä¸€é€šç”¨åŸåˆ™è§†è§’ï¼Œç ”ç©¶æ­ç¤ºäº†å½“å‰å¤šç§ DPO å˜ä½“åœ¨ç†è®ºåœ°å›¾ä¸­çš„ä½ç½®ï¼Œé˜æ˜äº†å…¶è¿è¡Œæœºåˆ¶çš„æœ¬è´¨ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜è¯†åˆ«äº†åç¦»è¿™ä¸€ç†è®ºæ¡†æ¶å¯èƒ½å¯¼è‡´çš„é™·é˜±ï¼Œå¹¶æå‡ºäº†ç›¸åº”çš„è¡¥æ•‘æ–¹æ¡ˆï¼Œä¸ºå¼€å‘æ›´å…·åŸåˆ™æ€§çš„åå¥½å­¦ä¹ æ¨¡å‹æä¾›äº†åšå®çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07855v2",
      "published_date": "2025-07-10 15:38:17 UTC",
      "updated_date": "2025-08-05 14:18:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:52:16.750985+00:00"
    },
    {
      "arxiv_id": "2507.07853v1",
      "title": "Optimization Guarantees for Square-Root Natural-Gradient Variational Inference",
      "title_zh": "å¹³æ–¹æ ¹è‡ªç„¶æ¢¯åº¦å˜åˆ†æ¨ç†çš„ä¼˜åŒ–ä¿è¯",
      "authors": [
        "Navish Kumar",
        "Thomas MÃ¶llenhoff",
        "Mohammad Emtiyaz Khan",
        "Aurelien Lucchi"
      ],
      "abstract": "Variational inference with natural-gradient descent often shows fast convergence in practice, but its theoretical convergence guarantees have been challenging to establish. This is true even for the simplest cases that involve concave log-likelihoods and use a Gaussian approximation. We show that the challenge can be circumvented for such cases using a square-root parameterization for the Gaussian covariance. This approach establishes novel convergence guarantees for natural-gradient variational-Gaussian inference and its continuous-time gradient flow. Our experiments demonstrate the effectiveness of natural gradient methods and highlight their advantages over algorithms that use Euclidean or Wasserstein geometries.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å˜åˆ†æ¨ç†(Variational inference)ä¸­è‡ªç„¶æ¢¯åº¦ä¸‹é™æ³•(natural-gradient descent)çš„ç†è®ºæ”¶æ•›ä¿è¯é—®é¢˜ï¼ŒæŒ‡å‡ºå³ä½¿åœ¨å‡¹å¯¹æ•°ä¼¼ç„¶å’Œé«˜æ–¯è¿‘ä¼¼çš„ç®€å•æƒ…å†µä¸‹ï¼Œå»ºç«‹æ­¤ç±»ä¿è¯ä¹Ÿå…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä½œè€…æå‡ºé€šè¿‡å¯¹é«˜æ–¯åæ–¹å·®é‡‡ç”¨å¹³æ–¹æ ¹å‚æ•°åŒ–(square-root parameterization)æ¥è§„é¿è¿™ä¸€éš¾é¢˜ï¼Œå¹¶ä»¥æ­¤ä¸ºåŸºç¡€ä¸ºè‡ªç„¶æ¢¯åº¦å˜åˆ†é«˜æ–¯æ¨ç†(natural-gradient variational-Gaussian inference)åŠå…¶è¿ç»­æ—¶é—´æ¢¯åº¦æµ(continuous-time gradient flow)å»ºç«‹äº†å…¨æ–°çš„æ”¶æ•›ä¿è¯ã€‚å®éªŒç»“æœä¸ä»…éªŒè¯äº†è¯¥è‡ªç„¶æ¢¯åº¦æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¿˜å±•ç¤ºäº†å…¶åœ¨æ€§èƒ½ä¸Šä¼˜äºé‡‡ç”¨æ¬§å‡ é‡Œå¾—(Euclidean)æˆ–ç“¦ç‘Ÿæ–¯å¦(Wasserstein)å‡ ä½•çš„ç®—æ³•ï¼Œä¸ºç†è§£è‡ªç„¶æ¢¯åº¦æ³•åœ¨å˜åˆ†æ¨ç†ä¸­çš„ä¼˜è¶Šæ€§æä¾›äº†ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07853v1",
      "published_date": "2025-07-10 15:33:28 UTC",
      "updated_date": "2025-07-10 15:33:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:52:28.299333+00:00"
    },
    {
      "arxiv_id": "2507.07847v1",
      "title": "From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems",
      "title_zh": "ä»æ­§ä¹‰èµ°å‘å‡†ç¡®ï¼šæŒ‡ä»£æ¶ˆè§£å¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿçš„å˜é©æ€§å½±å“",
      "authors": [
        "Youngjoon Jang",
        "Seongtae Hong",
        "Junyoung Son",
        "Sungjin Park",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a crucial framework in natural language processing (NLP), improving factual consistency and reducing hallucinations by integrating external document retrieval with large language models (LLMs). However, the effectiveness of RAG is often hindered by coreferential complexity in retrieved documents, introducing ambiguity that disrupts in-context learning. In this study, we systematically investigate how entity coreference affects both document retrieval and generative performance in RAG-based systems, focusing on retrieval relevance, contextual understanding, and overall response quality. We demonstrate that coreference resolution enhances retrieval effectiveness and improves question-answering (QA) performance. Through comparative analysis of different pooling strategies in retrieval tasks, we find that mean pooling demonstrates superior context capturing ability after applying coreference resolution. In QA tasks, we discover that smaller models benefit more from the disambiguation process, likely due to their limited inherent capacity for handling referential ambiguity. With these findings, this study aims to provide a deeper understanding of the challenges posed by coreferential complexity in RAG, providing guidance for improving retrieval and generation in knowledge-intensive AI applications.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°è°ƒæŸ¥äº†æŒ‡ä»£æ¶ˆè§£(Coreference Resolution)å¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ç³»ç»Ÿåœ¨æ–‡æ¡£æ£€ç´¢å’Œç”Ÿæˆæ€§èƒ½æ–¹é¢çš„è½¬åŒ–ä½œç”¨ã€‚é’ˆå¯¹æ£€ç´¢æ–‡æ¡£ä¸­å¤æ‚çš„æŒ‡ä»£å…³ç³»å¯¼è‡´çš„æ­§ä¹‰é—®é¢˜ï¼Œä½œè€…è¯„ä¼°äº†æŒ‡ä»£æ¶ˆè§£å¦‚ä½•æå‡æ£€ç´¢ç›¸å…³æ€§ã€ä¸Šä¸‹æ–‡ç†è§£ä»¥åŠæ•´ä½“å›ç­”è´¨é‡ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼ŒæŒ‡ä»£æ¶ˆè§£èƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºæ£€ç´¢æ•ˆèƒ½å¹¶ä¼˜åŒ–é—®ç­”(QA)è¡¨ç°ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒçš„æ± åŒ–ç­–ç•¥(pooling strategies)ï¼Œç ”ç©¶å‘ç°å¹³å‡æ± åŒ–(mean pooling)åœ¨åº”ç”¨æŒ‡ä»£æ¶ˆè§£åå±•ç°å‡ºæ›´ä¼˜çš„ä¸Šä¸‹æ–‡æ•æ‰èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç”±äºè¾ƒå°è§„æ¨¡çš„æ¨¡å‹(smaller models)å¤„ç†æŒ‡ä»£æ­§ä¹‰çš„å›ºæœ‰èƒ½åŠ›æœ‰é™ï¼ŒæŒ‡ä»£æ¶ˆè§£å¯¹å…¶æ€§èƒ½çš„æå‡å°¤ä¸ºæ˜¾è‘—ã€‚è¯¥ç ”ç©¶ä¸ºè§£å†³RAGä¸­çš„æŒ‡ä»£å¤æ‚æ€§æŒ‘æˆ˜æä¾›äº†æ·±å…¥è§è§£ï¼Œä¸ºæ”¹è¿›çŸ¥è¯†å¯†é›†å‹AIåº”ç”¨çš„æ£€ç´¢ä¸ç”Ÿæˆç¯èŠ‚æä¾›äº†é‡è¦æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07847v1",
      "published_date": "2025-07-10 15:26:59 UTC",
      "updated_date": "2025-07-10 15:26:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:52:32.484852+00:00"
    },
    {
      "arxiv_id": "2507.10442v1",
      "title": "Response Wide Shut? Surprising Observations in Basic Vision Language Model Capabilities",
      "title_zh": "å“åº”â€œç´§é—­â€ï¼Ÿè§†è§‰è¯­è¨€æ¨¡å‹åŸºç¡€èƒ½åŠ›çš„æ„å¤–å‘ç°",
      "authors": [
        "Shivam Chandhok",
        "Wan-Cyuan Fan",
        "Vered Shwartz",
        "Vineeth N Balasubramanian",
        "Leonid Sigal"
      ],
      "abstract": "Vision-language Models (VLMs) have emerged as general-purpose tools for addressing a variety of complex computer vision problems. Such models have been shown to be highly capable, but, at the same time, lacking some basic visual understanding skills. In this paper, we set out to understand the limitations of SoTA VLMs on fundamental visual tasks by constructing a series of tests that probe which components of design, specifically, may be lacking. Importantly, we go significantly beyond the current benchmarks, which simply measure the final performance of VLM response, by also comparing and contrasting it to the performance of probes trained directly on features obtained from the visual encoder, intermediate vision-language projection and LLM-decoder output. In doing so, we uncover shortcomings in VLMs and make a number of important observations about their capabilities, robustness and how they process visual information. We hope our insights will guide progress in further improving VLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿæ€§åœ°è°ƒæŸ¥äº†å½“å‰æœ€å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ (Vision-language Models, VLMs) åœ¨åŸºç¡€è§†è§‰ä»»åŠ¡ä¸Šçš„å±€é™æ€§ã€‚ä¸ä»…è¯„ä¼°æœ€ç»ˆè¾“å‡ºçš„ä¼ ç»Ÿ Benchmark ä¸åŒï¼Œè¯¥å·¥ä½œé€šè¿‡å¯¹æ¯”åˆ†æ visual encoderã€ä¸­é—´å±‚ vision-language projection ä»¥åŠ LLM-decoder è¾“å‡ºç‰¹å¾çš„æ¢æµ‹å™¨è¡¨ç°ï¼Œæ·±å…¥å‰–æäº†æ¨¡å‹è®¾è®¡çš„å…·ä½“ä¸è¶³ã€‚ç ”ç©¶æ­ç¤ºäº† SoTA æ¨¡å‹åœ¨åŸºç¡€è§†è§‰ç†è§£ã€é²æ£’æ€§ä»¥åŠè§†è§‰ä¿¡æ¯å¤„ç†æœºåˆ¶æ–¹é¢çš„æ„å¤–è§‚å¯Ÿä¸ç¼ºé™·ã€‚è¿™äº›å‘ç°ä¸ä»…æš´éœ²äº†ç°æœ‰æ¶æ„çš„çŸ­æ¿ï¼Œä¹Ÿä¸ºæœªæ¥æ”¹è¿› VLMs çš„è§†è§‰æ„ŸçŸ¥èƒ½åŠ›æä¾›äº†é‡è¦çš„å®è¯æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACL 2025 (Main Conference)",
      "pdf_url": "https://arxiv.org/pdf/2507.10442v1",
      "published_date": "2025-07-10 15:26:41 UTC",
      "updated_date": "2025-07-10 15:26:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:52:39.642864+00:00"
    },
    {
      "arxiv_id": "2507.07828v2",
      "title": "Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles",
      "title_zh": "é’ˆå¯¹å—æŸæ‹¼å›¾çš„åŸºäºå†…å®¹æ‹¼å›¾æ±‚è§£å™¨åŸºå‡†æµ‹è¯•",
      "authors": [
        "Richard Dirauf",
        "Florian Wolz",
        "Dario Zanca",
        "BjÃ¶rn Eskofier"
      ],
      "abstract": "Content-based puzzle solvers have been extensively studied, demonstrating significant progress in computational techniques. However, their evaluation often lacks realistic challenges crucial for real-world applications, such as the reassembly of fragmented artefacts or shredded documents. In this work, we investigate the robustness of State-Of-The-Art content-based puzzle solvers introducing three types of jigsaw puzzle corruptions: missing pieces, eroded edges, and eroded contents. Evaluating both heuristic and deep learning-based solvers, we analyse their ability to handle these corruptions and identify key limitations. Our results show that solvers developed for standard puzzles have a rapid decline in performance if more pieces are corrupted. However, deep learning models can significantly improve their robustness through fine-tuning with augmented data. Notably, the advanced Positional Diffusion model adapts particularly well, outperforming its competitors in most experiments. Based on our findings, we highlight promising research directions for enhancing the automated reconstruction of real-world artefacts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºå†…å®¹çš„æ‹¼å›¾æ±‚è§£å™¨(Content-based puzzle solvers)åœ¨å¤„ç†ç°å®æŒ‘æˆ˜ï¼ˆå¦‚ç ´ç¢æ–‡ç‰©æˆ–ç¢çº¸æœºæ–‡æ¡£é‡å»ºï¼‰æ—¶çš„é²æ£’æ€§é—®é¢˜ã€‚ç ”ç©¶è€…å¼•å…¥äº†ç¼ºå¤±æ‹¼å—(missing pieces)ã€è¾¹ç¼˜ä¾µèš€(eroded edges)å’Œå†…å®¹ä¾µèš€(eroded contents)ä¸‰ç§æŸåç±»å‹ï¼Œå¯¹ç°æœ‰çš„å¯å‘å¼(heuristic)ä¸æ·±åº¦å­¦ä¹ (deep learning-based)æ±‚è§£å™¨è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚ç»“æœè¡¨æ˜ï¼Œé’ˆå¯¹æ ‡å‡†æ‹¼å›¾å¼€å‘çš„æ±‚è§£å™¨åœ¨é¢å¯¹æŸåæ‹¼å—æ—¶æ€§èƒ½ä¼šè¿…é€Ÿä¸‹é™ï¼Œè€Œæ·±åº¦å­¦ä¹ æ¨¡å‹é€šè¿‡å¢å¼ºæ•°æ®è¿›è¡Œå¾®è°ƒ(fine-tuning)èƒ½æ˜¾è‘—å¢å¼ºå…¶ç¨³å¥æ€§ã€‚å…¶ä¸­ï¼Œå…ˆè¿›çš„Positional Diffusionæ¨¡å‹å±•ç°å‡ºä¼˜å¼‚çš„é€‚åº”æ€§ï¼Œåœ¨å¤šæ•°å®éªŒä¸­è¡¨ç°ä¼˜äºç«äº‰å¯¹æ‰‹ã€‚è¯¥é¡¹ç ”ç©¶ä¸ä»…æ­ç¤ºäº†ç°æœ‰æŠ€æœ¯çš„å±€é™æ€§ï¼Œä¹Ÿä¸ºè‡ªåŠ¨åŒ–é‡å»ºçœŸå®ä¸–ç•Œæ–‡ç‰©æä¾›äº†å…·æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07828v2",
      "published_date": "2025-07-10 15:01:23 UTC",
      "updated_date": "2026-01-07 09:16:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:53:13.230939+00:00"
    },
    {
      "arxiv_id": "2507.07820v3",
      "title": "AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift",
      "title_zh": "AI åº”æå‡æ„ŸçŸ¥èƒ½åŠ›ï¼Œè€Œéå•çº¯æ‰©å¼ è§„æ¨¡ï¼šè‡ªé€‚åº”æ„ŸçŸ¥å¸¦æ¥çš„èŒƒå¼å˜é©",
      "authors": [
        "Eunsu Baek",
        "Keondo Park",
        "Jeonggil Ko",
        "Min-hwan Oh",
        "Taesik Gong",
        "Hyung-Sin Kim"
      ],
      "abstract": "Current AI advances largely rely on scaling neural models and expanding training datasets to achieve generalization and robustness. Despite notable successes, this paradigm incurs significant environmental, economic, and ethical costs, limiting sustainability and equitable access. Inspired by biological sensory systems, where adaptation occurs dynamically at the input (e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive sensing as a necessary and foundational shift. Adaptive sensing proactively modulates sensor parameters (e.g., exposure, sensitivity, multimodal configurations) at the input level, significantly mitigating covariate shifts and improving efficiency. Empirical evidence from recent studies demonstrates that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass substantially larger models (e.g., OpenCLIP-H) trained with significantly more data and compute. We (i) outline a roadmap for broadly integrating adaptive sensing into real-world applications spanning humanoid, healthcare, autonomous systems, agriculture, and environmental monitoring, (ii) critically assess technical and ethical integration challenges, and (iii) propose targeted research directions, such as standardized benchmarks, real-time adaptive algorithms, multimodal integration, and privacy-preserving methods. Collectively, these efforts aim to transition the AI community toward sustainable, robust, and equitable artificial intelligence systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œå½“å‰AIçš„è¿›æ­¥ä¸»è¦ä¾èµ–äºæ‰©å±•æ¨¡å‹è§„æ¨¡å’Œè®­ç»ƒæ•°æ®é›†(Scaling)ï¼Œè¿™å¯¼è‡´äº†å·¨å¤§çš„ç¯å¢ƒã€ç»æµå’Œä¼¦ç†æˆæœ¬ã€‚å—ç”Ÿç‰©æ„ŸçŸ¥ç³»ç»Ÿçš„å¯å‘ï¼Œä½œè€…æå‡ºäº†è‡ªé€‚åº”ä¼ æ„Ÿ(Adaptive Sensing)è¿™ä¸€èŒƒå¼è½¬æ¢ï¼Œä¸»å¼ åœ¨è¾“å…¥ç«¯åŠ¨æ€è°ƒèŠ‚ä¼ æ„Ÿå™¨å‚æ•°ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸»åŠ¨ä¼˜åŒ–æ›å…‰ã€çµæ•åº¦å’Œå¤šæ¨¡æ€é…ç½®ï¼Œèƒ½å¤Ÿæ˜¾è‘—ç¼“è§£åå˜é‡åç§»(Covariate Shifts)å¹¶æé«˜ç³»ç»Ÿæ•ˆç‡ã€‚å®éªŒè¯æ˜ï¼Œåº”ç”¨è‡ªé€‚åº”ä¼ æ„Ÿçš„å°å‹æ¨¡å‹ï¼ˆå¦‚EfficientNet-B0ï¼‰åœ¨è¡¨ç°ä¸Šèƒ½è¶…è¶Šå‚æ•°é‡å’Œè®¡ç®—é‡å¤§å¾—å¤šçš„æ¨¡å‹ï¼ˆå¦‚OpenCLIP-Hï¼‰ã€‚è®ºæ–‡è¿›ä¸€æ­¥ä¸ºè¯¥æŠ€æœ¯åœ¨äººå½¢æœºå™¨äººã€åŒ»ç–—ä¿å¥å’Œè‡ªä¸»ç³»ç»Ÿç­‰é¢†åŸŸçš„é›†æˆæä¾›äº†è·¯çº¿å›¾ï¼Œå¹¶åˆ†æäº†ç›¸å…³çš„æŠ€æœ¯ä¸ä¼¦ç†æŒ‘æˆ˜ã€‚è¿™é¡¹å·¥ä½œæ—¨åœ¨æ¨åŠ¨äººå·¥æ™ºèƒ½ç¤¾åŒºä»å•çº¯è¿½æ±‚è§„æ¨¡è½¬å‘æ„å»ºæ›´å¯æŒç»­ã€é²æ£’ä¸”å…¬å¹³çš„AIç³»ç»Ÿã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in NeurIPS 2025 (Position Paper Track)",
      "pdf_url": "https://arxiv.org/pdf/2507.07820v3",
      "published_date": "2025-07-10 14:50:32 UTC",
      "updated_date": "2025-11-29 14:12:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:53:40.939667+00:00"
    },
    {
      "arxiv_id": "2507.07818v2",
      "title": "MoSE: Skill-by-Skill Mixture-of-Experts Learning for Embodied Autonomous Machines",
      "title_zh": "MoSEï¼šé¢å‘å…·èº«è‡ªä¸»æœºå™¨çš„é€é¡¹æŠ€èƒ½æ··åˆä¸“å®¶å­¦ä¹ ",
      "authors": [
        "Lu Xu",
        "Jiaqian Yu",
        "Xiongfeng Peng",
        "Yiwei Chen",
        "Weiming Li",
        "Jaewook Yoo",
        "Sunghyun Chunag",
        "Dongwook Lee",
        "Daehyun Ji",
        "Chao Zhang"
      ],
      "abstract": "To meet the growing demand for smarter, faster, and more efficient embodied AI solutions, we introduce a novel Mixture-of-Expert (MoE) method that significantly boosts reasoning and learning efficiency for embodied autonomous systems. General MoE models demand extensive training data and complex optimization, which limits their applicability in embodied AI such as autonomous driving (AD) and robotic manipulation. In this work, we propose a skill-oriented MoE called MoSE, which mimics the human learning and reasoning process skill-by-skill, step-by-step. We introduce a skill-oriented routing mechanism that begins with defining and annotating specific skills, enabling experts to identify the necessary competencies for various scenarios and reasoning tasks, thereby facilitating skill-by-skill learning. To better align with multi-step planning in human reasoning and in end-to-end driving models, we build a hierarchical skill dataset and pretrain the router to encourage the model to think step-by-step. Unlike other multi-round dialogues, MoSE integrates valuable auxiliary tasks (e.g. perception-prediction-planning for AD, and high-level and low-level planning for robots) in one single forward process without introducing any extra computational cost. With less than 3B sparsely activated parameters, our model effectively grows more diverse expertise and outperforms models on both AD corner-case reasoning tasks and robot reasoning tasks with less than 40% of the parameters.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MoSEï¼Œä¸€ç§é¢å‘æŠ€èƒ½çš„æ··åˆä¸“å®¶æ¨¡å‹ (Mixture-of-Experts, MoE)ï¼Œæ—¨åœ¨æå‡å…·èº«è‡ªä¸»ç³»ç»Ÿ (Embodied Autonomous Systems) çš„æ¨ç†ä¸å­¦ä¹ æ•ˆç‡ã€‚é’ˆå¯¹é€šç”¨ MoE æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶ (AD) å’Œæœºå™¨äººæ“ä½œä¸­é¢ä¸´çš„æ•°æ®éœ€æ±‚å¤§åŠä¼˜åŒ–å¤æ‚ç­‰æŒ‘æˆ˜ï¼ŒMoSE å¼•å…¥äº†æ¨¡æ‹Ÿäººç±»å­¦ä¹ è¿‡ç¨‹çš„é¢å‘æŠ€èƒ½è·¯ç”±æœºåˆ¶ã€‚é€šè¿‡æ„å»ºå±‚æ¬¡åŒ–æŠ€èƒ½æ•°æ®é›†å¹¶é¢„è®­ç»ƒè·¯ç”±å™¨ï¼Œè¯¥æ¨¡å‹å®ç°äº†æŠ€èƒ½åŒ–å­¦ä¹ ä¸å¤šæ­¥è§„åˆ’çš„ç»“åˆï¼Œé¼“åŠ±æ¨¡å‹è¿›è¡Œâ€œæŒ‰æ­¥éª¤æ€è€ƒâ€ (step-by-step)ã€‚MoSE åœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­é›†æˆäº†æ„ŸçŸ¥-é¢„æµ‹-è§„åˆ’ç­‰å…³é”®è¾…åŠ©ä»»åŠ¡ï¼Œä¸”ä¸å¢åŠ é¢å¤–è®¡ç®—æˆæœ¬ã€‚å®éªŒè¡¨æ˜ï¼Œå‚æ•°é‡ä¸åˆ° 3B çš„ MoSE åœ¨è‡ªåŠ¨é©¾é©¶æç«¯åœºæ™¯æ¨ç†å’Œæœºå™¨äººæ¨ç†ä»»åŠ¡ä¸­ï¼Œä»¥ä¸è¶³åŸºçº¿æ¨¡å‹ 40% çš„å‚æ•°é‡å®ç°äº†æ›´ä¼˜çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07818v2",
      "published_date": "2025-07-10 14:48:08 UTC",
      "updated_date": "2025-08-13 13:45:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:53:05.601021+00:00"
    },
    {
      "arxiv_id": "2507.07817v2",
      "title": "On the Effect of Instruction Tuning Loss on Generalization",
      "title_zh": "è®ºæŒ‡ä»¤å¾®è°ƒæŸå¤±å¯¹æ³›åŒ–èƒ½åŠ›çš„å½±å“",
      "authors": [
        "Anwoy Chatterjee",
        "H S V N S Kowndinya Renduchintala",
        "Sumit Bhatia",
        "Tanmoy Chakraborty"
      ],
      "abstract": "Instruction Tuning has emerged as a pivotal post-training paradigm that enables pre-trained language models to better follow user instructions. Despite its significance, little attention has been given to optimizing the loss function used. A fundamental, yet often overlooked, question is whether the conventional auto-regressive objective - where loss is computed only on response tokens, excluding prompt tokens - is truly optimal for instruction tuning. In this work, we systematically investigate the impact of differentially weighting prompt and response tokens in instruction tuning loss, and propose Weighted Instruction Tuning (WIT) as a better alternative to conventional instruction tuning. Through extensive experiments on five language models of different families and scale, three finetuning datasets of different sizes, and five diverse evaluation benchmarks, we show that the standard instruction tuning loss often yields suboptimal performance and limited robustness to input prompt variations. We find that a low-to-moderate weight for prompt tokens coupled with a moderate-to-high weight for response tokens yields the best-performing models across settings and also serve as better starting points for the subsequent preference alignment training. These findings highlight the need to reconsider instruction tuning loss and offer actionable insights for developing more robust and generalizable models. Our code is open-sourced at https://github.com/kowndinya-renduchintala/WIT.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°æ¢è®¨äº†æŒ‡ä»¤å¾®è°ƒ (Instruction Tuning) è¿‡ç¨‹ä¸­æŸå¤±å‡½æ•° (loss function) å¯¹æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å½±å“ï¼Œè´¨ç–‘äº†ä¼ ç»Ÿä»…é’ˆå¯¹å“åº” (response) ä»¤ç‰Œè®¡ç®—æŸå¤±çš„è‡ªå›å½’ç›®æ ‡æ˜¯å¦æœ€ä¼˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†åŠ æƒæŒ‡ä»¤å¾®è°ƒ (Weighted Instruction Tuning, WIT)ï¼Œé€šè¿‡å¯¹æç¤º (prompt) å’Œå“åº”ä»¤ç‰Œè®¾ç½®ä¸åŒçš„æƒé‡æ¥æ”¹è¿›è®­ç»ƒæ•ˆæœã€‚åœ¨å¤šç§è¯­è¨€æ¨¡å‹ã€æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ ‡å‡†æŸå¤±å‡½æ•°å¾€å¾€å¯¼è‡´æ€§èƒ½äºšä¼˜ï¼Œä¸”å¯¹æç¤ºè¯­çš„å˜åŒ–ç¼ºä¹é²æ£’æ€§ã€‚ç ”ç©¶å‘ç°ï¼Œä¸ºæç¤ºä»¤ç‰Œåˆ†é…ä½åˆ°ä¸­ç­‰æƒé‡ï¼Œå¹¶ä¸ºå“åº”ä»¤ç‰Œåˆ†é…ä¸­åˆ°é«˜ç­‰æƒé‡ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ¨¡å‹åœ¨å„ç±»åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚æ­¤å¤–ï¼ŒWIT è®­ç»ƒå‡ºçš„æ¨¡å‹è¿˜èƒ½ä¸ºåç»­çš„åå¥½å¯¹é½ (preference alignment) é˜¶æ®µæä¾›æ›´ä½³çš„åŸºç¡€ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†ä¼˜åŒ–æŒ‡ä»¤å¾®è°ƒæŸå¤±å‡½æ•°çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºæ„å»ºæ›´å…·é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›çš„è¯­è¨€æ¨¡å‹æä¾›äº†åˆ‡å®å¯è¡Œçš„å»ºè®®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in Transactions of the Association for Computational Linguistics (TACL)",
      "pdf_url": "https://arxiv.org/pdf/2507.07817v2",
      "published_date": "2025-07-10 14:46:33 UTC",
      "updated_date": "2025-07-15 11:42:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:53:17.536284+00:00"
    },
    {
      "arxiv_id": "2507.07808v1",
      "title": "Bridging Logic and Learning: Decoding Temporal Logic Embeddings via Transformers",
      "title_zh": "è¿æ¥é€»è¾‘ä¸å­¦ä¹ ï¼šåŸºäº Transformer çš„æ—¶åºé€»è¾‘åµŒå…¥è§£ç ",
      "authors": [
        "Sara Candussio",
        "Gaia Saveri",
        "Gabriele Sarti",
        "Luca Bortolussi"
      ],
      "abstract": "Continuous representations of logic formulae allow us to integrate symbolic knowledge into data-driven learning algorithms. If such embeddings are semantically consistent, i.e. if similar specifications are mapped into nearby vectors, they enable continuous learning and optimization directly in the semantic space of formulae. However, to translate the optimal continuous representation into a concrete requirement, such embeddings must be invertible. We tackle this issue by training a Transformer-based decoder-only model to invert semantic embeddings of Signal Temporal Logic (STL) formulae. STL is a powerful formalism that allows us to describe properties of signals varying over time in an expressive yet concise way. By constructing a small vocabulary from STL syntax, we demonstrate that our proposed model is able to generate valid formulae after only 1 epoch and to generalize to the semantics of the logic in about 10 epochs. Additionally, the model is able to decode a given embedding into formulae that are often simpler in terms of length and nesting while remaining semantically close (or equivalent) to gold references. We show the effectiveness of our methodology across various levels of training formulae complexity to assess the impact of training data on the model's ability to effectively capture the semantic information contained in the embeddings and generalize out-of-distribution. Finally, we deploy our model for solving a requirement mining task, i.e. inferring STL specifications that solve a classification task on trajectories, performing the optimization directly in the semantic space.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°†ç¬¦å·çŸ¥è¯†é›†æˆåˆ°æ•°æ®é©±åŠ¨å­¦ä¹ ç®—æ³•ä¸­æ‰€éœ€çš„è¿ç»­é€»è¾‘å…¬å¼è¡¨ç¤ºï¼Œæ¢è®¨äº†å¦‚ä½•è§£å†³è¯­ä¹‰åµŒå…¥çš„å¯é€†æ€§é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºTransformeræ¶æ„çš„ä»…è§£ç å™¨(decoder-only)æ¨¡å‹ï¼Œç”¨äºåæ¼”ä¿¡å·æ—¶åºé€»è¾‘(Signal Temporal Logic, STL)å…¬å¼çš„è¯­ä¹‰åµŒå…¥ã€‚é€šè¿‡æ„å»ºåŸºäºSTLè¯­æ³•çš„è¯æ±‡è¡¨ï¼Œè¯¥æ¨¡å‹åœ¨æçŸ­çš„è®­ç»ƒå‘¨æœŸå†…ä¾¿èƒ½ç”Ÿæˆæœ‰æ•ˆçš„é€»è¾‘å…¬å¼ï¼Œå¹¶å±•ç°å‡ºå¯¹é€»è¾‘è¯­ä¹‰çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿå°†ç»™å®šçš„åµŒå…¥è§£ç ä¸ºåœ¨é•¿åº¦å’ŒåµŒå¥—æ·±åº¦ä¸Šæ›´ç®€æ´ã€ä½†åœ¨è¯­ä¹‰ä¸Šä¸å‚è€ƒå…¬å¼ç­‰ä»·æˆ–æ¥è¿‘çš„å…¬å¼ã€‚è¯¥ç ”ç©¶é€šè¿‡ä¸åŒå¤æ‚ç¨‹åº¦çš„è®­ç»ƒæ•°æ®è¯„ä¼°äº†æ¨¡å‹æ•è·è¯­ä¹‰ä¿¡æ¯çš„èƒ½åŠ›åŠå…¶åœ¨åˆ†å¸ƒå¤–(out-of-distribution)çš„æ³›åŒ–è¡¨ç°ã€‚æœ€åï¼Œè¯¥æ¨¡å‹è¢«åº”ç”¨äºéœ€æ±‚æŒ–æ˜(requirement mining)ä»»åŠ¡ï¼Œé€šè¿‡ç›´æ¥åœ¨è¯­ä¹‰ç©ºé—´è¿›è¡Œä¼˜åŒ–ï¼ŒæˆåŠŸæ¨æ–­å‡ºç”¨äºè½¨è¿¹åˆ†ç±»çš„STLè§„èŒƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 3 figures, to be published in ECML-PKDD",
      "pdf_url": "https://arxiv.org/pdf/2507.07808v1",
      "published_date": "2025-07-10 14:35:37 UTC",
      "updated_date": "2025-07-10 14:35:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:52:50.571860+00:00"
    },
    {
      "arxiv_id": "2507.07796v1",
      "title": "Visual Instance-aware Prompt Tuning",
      "title_zh": "è§†è§‰å®ä¾‹æ„ŸçŸ¥æç¤ºå¾®è°ƒ",
      "authors": [
        "Xi Xiao",
        "Yunbei Zhang",
        "Xingjian Li",
        "Tianyang Wang",
        "Xiao Wang",
        "Yuxiang Wei",
        "Jihun Hamm",
        "Min Xu"
      ],
      "abstract": "Visual Prompt Tuning (VPT) has emerged as a parameter-efficient fine-tuning paradigm for vision transformers, with conventional approaches utilizing dataset-level prompts that remain the same across all input instances. We observe that this strategy results in sub-optimal performance due to high variance in downstream datasets. To address this challenge, we propose Visual Instance-aware Prompt Tuning (ViaPT), which generates instance-aware prompts based on each individual input and fuses them with dataset-level prompts, leveraging Principal Component Analysis (PCA) to retain important prompting information. Moreover, we reveal that VPT-Deep and VPT-Shallow represent two corner cases based on a conceptual understanding, in which they fail to effectively capture instance-specific information, while random dimension reduction on prompts only yields performance between the two extremes. Instead, ViaPT overcomes these limitations by balancing dataset-level and instance-level knowledge, while reducing the amount of learnable parameters compared to VPT-Deep. Extensive experiments across 34 diverse datasets demonstrate that our method consistently outperforms state-of-the-art baselines, establishing a new paradigm for analyzing and optimizing visual prompts for vision transformers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰ Transformer çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ŒæŒ‡å‡ºäº†ä¼ ç»Ÿ Visual Prompt Tuning (VPT) ä½¿ç”¨å›ºå®šæ•°æ®é›†çº§æç¤ºåœ¨é¢å¯¹é«˜æ–¹å·®æ•°æ®é›†æ—¶æ€§èƒ½å—é™çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Visual Instance-aware Prompt Tuning (ViaPT)ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ ¹æ®æ¯ä¸ªè¾“å…¥å®ä¾‹ç”Ÿæˆç‰¹å®šçš„æ„ŸçŸ¥æç¤ºï¼Œå¹¶åˆ©ç”¨ Principal Component Analysis (PCA) æŠ€æœ¯å°†å…¶ä¸æ•°æ®é›†çº§æç¤ºè¿›è¡Œèåˆä»¥ä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚ç ”ç©¶æ­ç¤ºäº† VPT-Deep å’Œ VPT-Shallow åœ¨æ•æ‰å®ä¾‹ç‰¹å®šä¿¡æ¯æ–¹é¢çš„å±€é™æ€§ï¼Œè€Œ ViaPT é€šè¿‡å¹³è¡¡æ•°æ®é›†çº§å’Œå®ä¾‹çº§çŸ¥è¯†å…‹æœäº†è¿™äº›è®¾è®¡ç¼ºé™·ã€‚ä¸ VPT-Deep ç›¸æ¯”ï¼ŒViaPT åœ¨æ˜¾è‘—å‡å°‘å¯å­¦ä¹ å‚æ•°é‡çš„åŒæ—¶ï¼Œåœ¨ 34 ä¸ªå¤šæ ·åŒ–æ•°æ®é›†ä¸Šçš„å®éªŒä¸­æŒç»­ä¼˜äºç°æœ‰çš„å…ˆè¿›åŸºå‡†æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œä¸ºä¼˜åŒ–è§†è§‰æç¤ºå»ºç«‹äº†æ–°çš„èŒƒå¼ï¼Œè¯æ˜äº†å®ä¾‹æ„ŸçŸ¥æœºåˆ¶åœ¨æå‡å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹è¿ç§»æ•ˆç‡æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07796v1",
      "published_date": "2025-07-10 14:23:15 UTC",
      "updated_date": "2025-07-10 14:23:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:53:02.844414+00:00"
    },
    {
      "arxiv_id": "2507.07787v2",
      "title": "Measuring AI Alignment with Human Flourishing",
      "title_zh": "è¡¡é‡äººå·¥æ™ºèƒ½ä¸äººç±»ç¹è£çš„å¯¹é½",
      "authors": [
        "Elizabeth Hilliard",
        "Akshaya Jagadeesh",
        "Alex Cook",
        "Steele Billings",
        "Nicholas Skytland",
        "Alicia Llewellyn",
        "Jackson Paull",
        "Nathan Paull",
        "Nolan Kurylo",
        "Keatra Nesbitt",
        "Robert Gruenewald",
        "Anthony Jantzi",
        "Omar Chavez"
      ],
      "abstract": "This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel evaluation framework that assesses AI alignment with human flourishing across seven dimensions: Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability, and Faith and Spirituality. Unlike traditional benchmarks that focus on technical capabilities or harm prevention, the FAI Benchmark measures AI performance on how effectively models contribute to the flourishing of a person across these dimensions. The benchmark evaluates how effectively LLM AI systems align with current research models of holistic human well-being through a comprehensive methodology that incorporates 1,229 objective and subjective questions. Using specialized judge Large Language Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs geometric mean scoring to ensure balanced performance across all flourishing dimensions. Initial testing of 28 leading language models reveals that while some models approach holistic alignment (with the highest-scoring models achieving 72/100), none are acceptably aligned across all dimensions, particularly in Faith and Spirituality, Character and Virtue, and Meaning and Purpose. This research establishes a framework for developing AI systems that actively support human flourishing rather than merely avoiding harm, offering significant implications for AI development, ethics, and evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Flourishing AI Benchmark (FAI Benchmark)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼° AI ä¸äººç±»ç¹è£ (human flourishing) å¯¹é½ç¨‹åº¦çš„æ–°å‹è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ¶µç›– Character and Virtueã€Close Social Relationshipsã€Happiness and Life Satisfactionã€Meaning and Purposeã€Mental and Physical Healthã€Financial and Material Stability ä»¥åŠ Faith and Spirituality ä¸ƒä¸ªæ ¸å¿ƒç»´åº¦ï¼Œé€šè¿‡åŒ…å« 1,229 ä¸ªå®¢è§‚å’Œä¸»è§‚é—®é¢˜çš„ç»¼åˆæ–¹æ³•ï¼Œåˆ©ç”¨ä¸“é—¨çš„è¯„æµ‹ LLMs å¯¹æ¨¡å‹è¡¨ç°è¿›è¡Œè·¨ç»´åº¦è¯„ä¼°ã€‚å¯¹ 28 ä¸ªé¢†å…ˆè¯­è¨€æ¨¡å‹çš„åˆå§‹æµ‹è¯•æ˜¾ç¤ºï¼Œè™½ç„¶æœ€é«˜å¾—åˆ†æ¨¡å‹è¾¾åˆ°äº† 72/100ï¼Œä½†æ²¡æœ‰ä»»ä½•æ¨¡å‹èƒ½åœ¨æ‰€æœ‰ç»´åº¦ä¸Šå®ç°ç†æƒ³å¯¹é½ï¼Œå°¤å…¶åœ¨ Faith and Spiritualityã€Character and Virtue å’Œ Meaning and Purpose æ–¹é¢è¡¨ç°ä¸è¶³ã€‚è¿™é¡¹ç ”ç©¶ä¸ºå¼€å‘èƒ½å¤Ÿä¸»åŠ¨æ”¯æŒäººç±»ç¹è£è€Œéä»…ä»…è§„é¿ä¼¤å®³çš„ AI ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ï¼Œå¯¹ AI å¼€å‘ã€ä¼¦ç†åŠè¯„ä¼°å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07787v2",
      "published_date": "2025-07-10 14:09:53 UTC",
      "updated_date": "2025-07-11 04:57:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:53:14.336625+00:00"
    },
    {
      "arxiv_id": "2508.00005v1",
      "title": "Modelling Program Spaces in Program Synthesis with Constraints",
      "title_zh": "åŸºäºçº¦æŸçš„ç¨‹åºåˆæˆç©ºé—´å»ºæ¨¡",
      "authors": [
        "Tilman Hinnerichs",
        "Bart Swinkels",
        "Jaap de Jong",
        "Reuben Gardos Reid",
        "Tudor Magirescu",
        "Neil Yorke-Smith",
        "Sebastijan Dumancic"
      ],
      "abstract": "A core challenge in program synthesis is taming the large space of possible programs. Since program synthesis is essentially a combinatorial search, the community has sought to leverage powerful combinatorial constraint solvers. Here, constraints are used to express the program semantics, but not as a potentially potent tool to remove unwanted programs. Recent inductive logic programming approaches introduce constraints on the program's syntax to be synthesized. These syntactic constraints allow for checking and propagating a constraint without executing the program, and thus for arbitrary operators. In this work, we leverage syntactic constraints to model program spaces, defining not just solutions that are feasible, but also ones that are likely useful. To demonstrate this idea, we introduce BART, a solver that efficiently propagates and solves these constraints. We evaluate BART on program space enumeration tasks, finding that the constraints eliminate up to 99 percent of the program space, and that modeling program spaces significantly reduces enumeration time.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¨‹åºåˆæˆ(Program Synthesis)ä¸­å¤„ç†åºå¤§æœç´¢ç©ºé—´çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œæå‡ºåˆ©ç”¨è¯­æ³•çº¦æŸ(Syntactic Constraints)æ¥å¯¹ç¨‹åºç©ºé—´è¿›è¡Œå»ºæ¨¡ã€‚ä¸ä¼ ç»Ÿä»…ç”¨äºè¡¨è¾¾ç¨‹åºè¯­ä¹‰çš„çº¦æŸä¸åŒï¼Œè¯¥å·¥ä½œåˆ©ç”¨è¯­æ³•çº¦æŸåœ¨ä¸æ‰§è¡Œç¨‹åºçš„æƒ…å†µä¸‹å‰”é™¤æ— æ•ˆç¨‹åºï¼Œä»è€Œå®šä¹‰ä¸ä»…å¯è¡Œä¸”å¯èƒ½æ›´å…·å®ç”¨ä»·å€¼çš„è§£ç©ºé—´ã€‚ç ”ç©¶å›¢é˜Ÿä¸ºæ­¤å¼€å‘äº†åä¸ºBARTçš„æ±‚è§£å™¨ï¼Œæ—¨åœ¨é«˜æ•ˆåœ°ä¼ æ’­å¹¶æ±‚è§£è¿™äº›å¤æ‚çš„è¯­æ³•çº¦æŸã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œåœ¨ç¨‹åºç©ºé—´æšä¸¾ä»»åŠ¡ä¸­ï¼ŒBARTèƒ½å¤Ÿæ¶ˆé™¤é«˜è¾¾99%çš„æœç´¢ç©ºé—´ï¼Œå¹¶æ˜¾è‘—ç¼©çŸ­äº†æšä¸¾æ‰€éœ€çš„æ—¶é—´ã€‚è¯¥å·¥ä½œè¯æ˜äº†é€šè¿‡ç²¾ç»†åŒ–çš„è¯­æ³•çº¦æŸå»ºæ¨¡å¯ä»¥æå¤§æå‡ç¨‹åºåˆæˆè¿‡ç¨‹ä¸­çš„ç»„åˆæœç´¢æ•ˆç‡ã€‚",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.00005v1",
      "published_date": "2025-07-10 14:00:53 UTC",
      "updated_date": "2025-07-10 14:00:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:01.844800+00:00"
    },
    {
      "arxiv_id": "2507.07780v2",
      "title": "Where are we with calibration under dataset shift in image classification?",
      "title_zh": "å›¾åƒåˆ†ç±»ä¸­æ•°æ®é›†åç§»ä¸‹çš„æ¨¡å‹æ ¡å‡†ç°çŠ¶ç ”ç©¶",
      "authors": [
        "MÃ©lanie Roschewitz",
        "Raghav Mehta",
        "Fabio de Sousa Ribeiro",
        "Ben Glocker"
      ],
      "abstract": "We conduct an extensive study on the state of calibration under real-world dataset shift for image classification. Our work provides important insights on the choice of post-hoc and in-training calibration techniques, and yields practical guidelines for all practitioners interested in robust calibration under shift. We compare various post-hoc calibration methods, and their interactions with common in-training calibration strategies (e.g., label smoothing), across a wide range of natural shifts, on eight different classification tasks across several imaging domains. We find that: (i) simultaneously applying entropy regularisation and label smoothing yield the best calibrated raw probabilities under dataset shift, (ii) post-hoc calibrators exposed to a small amount of semantic out-of-distribution data (unrelated to the task) are most robust under shift, (iii) recent calibration methods specifically aimed at increasing calibration under shifts do not necessarily offer significant improvements over simpler post-hoc calibration methods, (iv) improving calibration under shifts often comes at the cost of worsening in-distribution calibration. Importantly, these findings hold for randomly initialised classifiers, as well as for those finetuned from foundation models, the latter being consistently better calibrated compared to models trained from scratch. Finally, we conduct an in-depth analysis of ensembling effects, finding that (i) applying calibration prior to ensembling (instead of after) is more effective for calibration under shifts, (ii) for ensembles, OOD exposure deteriorates the ID-shifted calibration trade-off, (iii) ensembling remains one of the most effective methods to improve calibration robustness and, combined with finetuning from foundation models, yields best calibration results overall.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­çœŸå®ä¸–ç•Œæ•°æ®é›†åç§» (dataset shift) ä¸‹çš„æ¨¡å‹æ ¡å‡† (calibration) ç°çŠ¶è¿›è¡Œäº†å¹¿æ³›è°ƒç ”ï¼Œæ¶µç›–äº†å¤šä¸ªæˆåƒé¢†åŸŸçš„å…«ä¸ªåˆ†ç±»ä»»åŠ¡ã€‚ä½œè€…æ¯”è¾ƒäº†å¤šç§äº‹åæ ¡å‡† (post-hoc calibration) æ–¹æ³•åŠå…¶ä¸è®­ç»ƒä¸­æ ¡å‡†ç­–ç•¥ï¼ˆå¦‚ label smoothingï¼‰çš„äº¤äº’ä½œç”¨ï¼Œå‘ç°åŒæ—¶åº”ç”¨ç†µæ­£åˆ™åŒ– (entropy regularisation) å’Œæ ‡ç­¾å¹³æ»‘èƒ½å¤Ÿè·å¾—æœ€ä½³çš„åŸå§‹æ¦‚ç‡æ ¡å‡†ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œæš´éœ²äºå°‘é‡è¯­ä¹‰åˆ†å¸ƒå¤– (out-of-distribution) æ•°æ®çš„äº‹åæ ¡å‡†å™¨åœ¨åç§»ä¸‹è¡¨ç°æœ€ç¨³å¥ï¼Œä¸”ä¸“é—¨é’ˆå¯¹åç§»è®¾è®¡çš„å¤æ‚æ–¹æ³•æœªå¿…ä¼˜äºç®€å•çš„æ ¡å‡†æ–¹æ³•ã€‚å®éªŒè¿˜æ­ç¤ºäº†æå‡åç§»ä¸‹çš„æ ¡å‡†å¾€å¾€ä¼šæŸå®³åˆ†å¸ƒå†… (in-distribution) çš„æ ¡å‡†æ€§èƒ½ï¼Œä½†åŸºäºåŸºç¡€æ¨¡å‹ (foundation models) å¾®è°ƒçš„åˆ†ç±»å™¨è¡¨ç°å§‹ç»ˆä¼˜äºä»é›¶è®­ç»ƒçš„æ¨¡å‹ã€‚æœ€åï¼Œç ”ç©¶å¼ºè°ƒåœ¨é›†æˆå­¦ä¹  (ensembling) ä¸­åº”åœ¨é›†æˆå‰è¿›è¡Œæ ¡å‡†ï¼Œå¹¶è¯æ˜é›†æˆç»“åˆåŸºç¡€æ¨¡å‹å¾®è°ƒæ˜¯ç›®å‰æé«˜æ ¡å‡†é²æ£’æ€§æœ€æœ‰æ•ˆçš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code available at https://github.com/biomedia-mira/calibration_under_shifts. Published in TMLR, October 2025 (https://openreview.net/forum?id=1NYKXlRU2H)",
      "pdf_url": "https://arxiv.org/pdf/2507.07780v2",
      "published_date": "2025-07-10 13:59:53 UTC",
      "updated_date": "2025-10-22 07:57:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:53:55.706011+00:00"
    },
    {
      "arxiv_id": "2507.07778v2",
      "title": "Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training",
      "title_zh": "ä»»åŠ¡è¡Œä¸ºåŒæ­¥ï¼šæµ‹è¯•æ—¶è®­ç»ƒä¸­çš„å¤šä»»åŠ¡å¯¹é½",
      "authors": [
        "Wooseong Jeong",
        "Jegyeong Cho",
        "Youngho Yoon",
        "Kuk-Jin Yoon"
      ],
      "abstract": "Generalizing neural networks to unseen target domains is a significant challenge in real-world deployments. Test-time training (TTT) addresses this by using an auxiliary self-supervised task to reduce the domain gap caused by distribution shifts between the source and target. However, we find that when models are required to perform multiple tasks under domain shifts, conventional TTT methods suffer from unsynchronized task behavior, where the adaptation steps needed for optimal performance in one task may not align with the requirements of other tasks. To address this, we propose a novel TTT approach called Synchronizing Tasks for Test-time Training (S4T), which enables the concurrent handling of multiple tasks. The core idea behind S4T is that predicting task relations across domain shifts is key to synchronizing tasks during test time. To validate our approach, we apply S4T to conventional multi-task benchmarks, integrating it with traditional TTT protocols. Our empirical results show that S4T outperforms state-of-the-art TTT methods across various benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»ç½‘ç»œåœ¨æœªçŸ¥ç›®æ ‡åŸŸæ³›åŒ–ä¸­çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„æµ‹è¯•æ—¶è®­ç»ƒ (Test-time training, TTT) åœ¨å¤„ç†å¤šä»»åŠ¡åœºæ™¯æ—¶å­˜åœ¨ä»»åŠ¡è¡Œä¸ºä¸åŒæ­¥ (unsynchronized task behavior) çš„å±€é™ã€‚ä½œè€…å‘ç°ï¼Œé’ˆå¯¹æŸä¸€ç‰¹å®šä»»åŠ¡çš„é€‚åº”æ­¥éª¤åœ¨åˆ†å¸ƒåç§» (distribution shifts) ä¸‹å¯èƒ½æ— æ³•ä¸å…¶ä»–ä»»åŠ¡çš„éœ€æ±‚ä¿æŒä¸€è‡´ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Synchronizing Tasks for Test-time Training (S4T) çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨å®ç°å¤šä¸ªä»»åŠ¡åœ¨æµ‹è¯•æ—¶çš„å¹¶å‘å¤„ç†ä¸å¯¹é½ã€‚S4T çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡é¢„æµ‹è·¨é¢†åŸŸåç§»çš„ä»»åŠ¡å…³ç³» (task relations) æ¥åŒæ­¥å„é¡¹ä»»åŠ¡çš„è¡Œä¸ºã€‚é€šè¿‡å°†è¯¥æ–¹æ³•é›†æˆåˆ°ä¼ ç»Ÿ TTT åè®®å¹¶åº”ç”¨äºå¤šä»»åŠ¡åŸºå‡†æµ‹è¯•ï¼Œå®éªŒç»“æœè¯å® S4T çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿› TTT æŠ€æœ¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07778v2",
      "published_date": "2025-07-10 13:58:32 UTC",
      "updated_date": "2025-07-21 05:48:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:05.334100+00:00"
    },
    {
      "arxiv_id": "2507.07754v2",
      "title": "OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting",
      "title_zh": "OPCï¼šé¢å‘æ·±åº¦ç‰¹å¾é—å¿˜çš„å•ç‚¹æ”¶ç¼©æœºå™¨é—å¿˜",
      "authors": [
        "Jaeheun Jung",
        "Bosung Jung",
        "Suhyun Bae",
        "Donghun Lee"
      ],
      "abstract": "Machine unlearning seeks to remove the influence of particular data or class from trained models to meet privacy, legal, or ethical requirements. Existing unlearning methods tend to forget shallowly: phenomenon of an unlearned model pretend to forget by adjusting only the model response, while its internal representations retain information sufficiently to restore the forgotten data or behavior. We empirically confirm the widespread shallowness by reverting the forgetting effect of various unlearning methods via training-free performance recovery attack and gradient-inversion-based data reconstruction attack. To address this vulnerability fundamentally, we define a theoretical criterion of ``deep forgetting'' based on one-point-contraction of feature representations of data to forget. We also propose an efficient approximation algorithm, and use it to construct a novel general-purpose unlearning algorithm: One-Point-Contraction (OPC). Empirical evaluations on image classification unlearning benchmarks show that OPC achieves not only effective unlearning performance but also superior resilience against both performance recovery attack and gradient-inversion attack. The distinctive unlearning performance of OPC arises from the deep feature forgetting enforced by its theoretical foundation, and recaps the need for improved robustness of machine unlearning methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ Machine unlearning æ–¹æ³•æ™®éå­˜åœ¨çš„â€œæµ…å±‚é—å¿˜â€ï¼ˆShallow Forgettingï¼‰é—®é¢˜è¿›è¡Œäº†æ·±å…¥æ¢è®¨ï¼Œå³æ¨¡å‹ä»…åœ¨è¾“å‡ºç«¯è°ƒæ•´å“åº”ï¼Œè€Œåœ¨å†…éƒ¨ç‰¹å¾è¡¨ç¤ºä¸­ä»ä¿ç•™äº†è¶³ä»¥æ¢å¤åŸå§‹æ•°æ®çš„ä¿¡æ¯ã€‚ä½œè€…é€šè¿‡æ€§èƒ½æ¢å¤æ”»å‡»ï¼ˆPerformance Recovery Attackï¼‰å’ŒåŸºäºæ¢¯åº¦åæ¼”çš„æ•°æ®é‡æ„æ”»å‡»ï¼ˆGradient-Inversion Attackï¼‰è¯å®äº†è¿™ç§è„†å¼±æ€§çš„å¹¿æ³›å­˜åœ¨ã€‚ä¸ºä»æ ¹æœ¬ä¸Šè§£å†³è¯¥é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†åŸºäºç‰¹å¾è¡¨ç¤ºå•ç‚¹æ”¶ç¼©ï¼ˆOne-Point-Contractionï¼‰çš„â€œæ·±åº¦é—å¿˜â€ï¼ˆDeep Forgettingï¼‰ç†è®ºæ ‡å‡†ï¼Œå¹¶å¼€å‘äº†é«˜æ•ˆçš„è¿‘ä¼¼ç®—æ³•ã€‚åŸºäºè¯¥ç†è®ºï¼Œä½œè€…æ„å»ºäº†ä¸€ç§é€šç”¨çš„é—å¿˜ç®—æ³• OPC (One-Point-Contraction)ã€‚åœ¨å›¾åƒåˆ†ç±»åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOPC ä¸ä»…å…·å¤‡é«˜æ•ˆçš„é—å¿˜æ€§èƒ½ï¼Œä¸”åœ¨æŠµå¾¡å„ç±»æ¢å¤å’Œé‡æ„æ”»å‡»æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¯¥ç ”ç©¶é€šè¿‡å¼ºåˆ¶å®ç°æ·±åº¦ç‰¹å¾é—å¿˜ï¼Œä¸ºæå‡ Machine unlearning çš„é²æ£’æ€§æä¾›äº†æ–°çš„ç†è®ºåŸºç¡€å’Œå®è·µæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICCV 2025 workshop U&ME 2025 (2nd Workshop and Challenge on Unlearning and Model Editing)",
      "pdf_url": "https://arxiv.org/pdf/2507.07754v2",
      "published_date": "2025-07-10 13:34:02 UTC",
      "updated_date": "2025-07-22 05:40:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:03.461600+00:00"
    },
    {
      "arxiv_id": "2507.07748v1",
      "title": "When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸æ³•å¾‹ï¼šåŒè§†è§’åˆ†ç±»ä½“ç³»ã€æŠ€æœ¯è¿›å±•åŠä¼¦ç†æ²»ç†",
      "authors": [
        "Peizhang Shao",
        "Linrui Xu",
        "Jinxi Wang",
        "Wei Zhou",
        "Xingyu Wu"
      ],
      "abstract": "This paper establishes the first comprehensive review of Large Language Models (LLMs) applied within the legal domain. It pioneers an innovative dual lens taxonomy that integrates legal reasoning frameworks and professional ontologies to systematically unify historical research and contemporary breakthroughs. Transformer-based LLMs, which exhibit emergent capabilities such as contextual reasoning and generative argumentation, surmount traditional limitations by dynamically capturing legal semantics and unifying evidence reasoning. Significant progress is documented in task generalization, reasoning formalization, workflow integration, and addressing core challenges in text processing, knowledge integration, and evaluation rigor via technical innovations like sparse attention mechanisms and mixture-of-experts architectures. However, widespread adoption of LLM introduces critical challenges: hallucination, explainability deficits, jurisdictional adaptation difficulties, and ethical asymmetry. This review proposes a novel taxonomy that maps legal roles to NLP subtasks and computationally implements the Toulmin argumentation framework, thus systematizing advances in reasoning, retrieval, prediction, and dispute resolution. It identifies key frontiers including low-resource systems, multimodal evidence integration, and dynamic rebuttal handling. Ultimately, this work provides both a technical roadmap for researchers and a conceptual framework for practitioners navigating the algorithmic future, laying a robust foundation for the next era of legal artificial intelligence. We have created a GitHub repository to index the relevant papers: https://github.com/Kilimajaro/LLMs_Meet_Law.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åœ¨æ³•å¾‹é¢†åŸŸçš„åº”ç”¨è¿›è¡Œäº†é¦–æ¬¡å…¨é¢çš„ç»¼è¿°ã€‚è®ºæ–‡é¦–åˆ›äº†ä¸€ç§åŒè§†è§’åˆ†ç±»æ³•(dual lens taxonomy)ï¼Œå°†æ³•å¾‹æ¨ç†æ¡†æ¶ä¸ä¸“ä¸šæœ¬ä½“è®ºç›¸ç»“åˆï¼Œç³»ç»Ÿåœ°ç»Ÿä¸€äº†å†å²ç ”ç©¶ä¸å½“ä»£çªç ´ã€‚æ–‡ç« æ¢è®¨äº†åŸºäºTransformeræ¶æ„çš„LLMså¦‚ä½•é€šè¿‡ä¸Šä¸‹æ–‡æ¨ç†(contextual reasoning)å’Œç”Ÿæˆå¼è®ºè¯(generative argumentation)ç­‰èƒ½åŠ›ï¼Œå…‹æœä¼ ç»Ÿé™åˆ¶å¹¶åŠ¨æ€æ•æ‰æ³•å¾‹è¯­ä¹‰ã€‚è®ºæ–‡è®°å½•äº†åœ¨ä»»åŠ¡æ³›åŒ–ã€æ¨ç†å½¢å¼åŒ–å’Œå·¥ä½œæµé›†æˆæ–¹é¢çš„æ˜¾è‘—è¿›å±•ï¼Œå¹¶ä»‹ç»äº†ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶(sparse attention mechanisms)å’Œæ··åˆä¸“å®¶æ¶æ„(mixture-of-experts architectures)ç­‰æŠ€æœ¯åˆ›æ–°ã€‚ç ”ç©¶åŒæ—¶æŒ‡å‡ºäº†LLMså¹¿æ³›é‡‡ç”¨é¢ä¸´çš„å…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¹»è§‰(hallucination)ã€å¯è§£é‡Šæ€§ä¸è¶³ã€æ³•åŸŸé€‚åº”å›°éš¾åŠä¼¦ç†ä¸å¯¹ç§°ã€‚è¯¥ç»¼è¿°æå‡ºäº†ä¸€ç§å°†æ³•å¾‹è§’è‰²æ˜ å°„åˆ°NLPå­ä»»åŠ¡çš„æ–°åˆ†ç±»æ³•ï¼Œå¹¶è®¡ç®—åŒ–å®ç°äº†å›¾å°”æ•è®ºè¯æ¨¡å‹(Toulmin argumentation framework)ï¼Œä»è€Œç³»ç»ŸåŒ–äº†æ¨ç†ã€æ£€ç´¢ã€é¢„æµ‹å’Œçº çº·è§£å†³æ–¹é¢çš„è¿›å±•ã€‚è®ºæ–‡æœ€åç¡®å®šäº†ä½èµ„æºç³»ç»Ÿã€å¤šæ¨¡æ€è¯æ®é›†æˆç­‰å‰æ²¿æ–¹å‘ï¼Œä¸ºæ³•å¾‹äººå·¥æ™ºèƒ½(Legal AI)çš„æœªæ¥å‘å±•æä¾›äº†æŠ€æœ¯è·¯çº¿å›¾å’Œæ¦‚å¿µæ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07748v1",
      "published_date": "2025-07-10 13:26:34 UTC",
      "updated_date": "2025-07-10 13:26:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:14.211770+00:00"
    },
    {
      "arxiv_id": "2507.14171v2",
      "title": "IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning",
      "title_zh": "IPPROï¼šåŸºäºæŠ•å½±åç§»çš„é‡çº§æ— å…³é‡è¦æ€§ç»“æ„åŒ–å‰ªæ",
      "authors": [
        "Jaeheun Jung",
        "Jaehyuk Lee",
        "Yeajin Lee",
        "Donghun Lee"
      ],
      "abstract": "With the growth of demand on neural network compression methods, the structured pruning methods including importance-based approach are actively studied. The magnitude importance and many correlated modern importance criteria often limit the capacity of pruning decision, since the filters with larger magnitudes are not likely to be pruned if the smaller one didn't, even if it is redundant. In this paper, we propose a novel pruning strategy to challenge this dominating effect of magnitude and provide fair chance to each filter to be pruned, by placing it on projective space. After that, we observe the gradient descent movement whether the filters move toward the origin or not, to measure how the filter is likely to be pruned. This measurement is used to construct PROscore, a novel importance score for IPPRO, a novel importance-based structured pruning with magnitude-indifference. Our evaluation results shows that the proposed importance criteria using the projective space achieves near-lossless pruning by reducing the performance drop in pruning, with promising performance after the finetuning. Our work debunks the ``size-matters'' myth in pruning and expands the frontier of importance-based pruning both theoretically and empirically.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† IPPROï¼Œä¸€ç§åŸºäºæŠ•å½±åç§» (PRojective Offset) çš„é‡è¦æ€§ç»“æ„åŒ–å‰ªæ (structural pruning) æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå‰ªæä¸­æƒé‡æ•°å€¼ (magnitude) ä¸»å¯¼å†³ç­–è€Œå¯¼è‡´å†—ä½™æ»¤é•œæ— æ³•è¢«æœ‰æ•ˆå‰”é™¤çš„é—®é¢˜ã€‚ä¸ºäº†èµ‹äºˆæ¯ä¸ªå·ç§¯æ ¸ (filter) å…¬å¹³çš„å‰ªææœºä¼šï¼Œè¯¥æ–¹æ³•å°†å‚æ•°æ˜ å°„åˆ°æŠ•å½±ç©ºé—´ (projective space)ï¼Œå¹¶é€šè¿‡è§‚å¯Ÿæ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å·ç§¯æ ¸æ˜¯å¦å‘åŸç‚¹ç§»åŠ¨æ¥è¡¡é‡å…¶è¢«å‰ªæçš„å¯èƒ½æ€§ã€‚ç ”ç©¶å›¢é˜Ÿæ®æ­¤æ„å»ºäº†å…¨æ–°çš„é‡è¦æ€§è¯„åˆ†æŒ‡æ ‡ PROscoreï¼Œå®ç°äº†å¯¹æ•°å€¼å¤§å°ä¸æ•æ„Ÿçš„ç»“æ„åŒ–å‰ªææµç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIPPRO åœ¨å‰ªæè¿‡ç¨‹ä¸­æ˜¾è‘—å‡å°‘äº†æ€§èƒ½ä¸‹é™ï¼Œå®ç°äº†è¿‘ä¹æ— æŸçš„å‹ç¼©æ•ˆæœï¼Œå¹¶åœ¨å¾®è°ƒåå±•ç°å‡ºæå…·ç«äº‰åŠ›çš„æ€§èƒ½ã€‚è¯¥å·¥ä½œåœ¨ç†è®ºå’Œå®è¯ä¸Šæ‰“ç ´äº†å‰ªæé¢†åŸŸâ€œå°ºå¯¸è‡³ä¸Šâ€ (size-matters) çš„ä¼ ç»Ÿè§‚å¿µï¼Œä¸ºé‡è¦æ€§å‰ªæç ”ç©¶æ‹“å±•äº†æ–°çš„è¾¹ç•Œã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICCV 2025 workshop U&ME 2025 (2nd Workshop and Challenge on Unlearning and Model Editing)",
      "pdf_url": "https://arxiv.org/pdf/2507.14171v2",
      "published_date": "2025-07-10 13:26:24 UTC",
      "updated_date": "2025-07-22 05:37:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:22.826779+00:00"
    },
    {
      "arxiv_id": "2507.07743v1",
      "title": "Identification of Violin Reduction via Contour Lines Classification",
      "title_zh": "åŸºäºç­‰é«˜çº¿åˆ†ç±»çš„å°æç´æ”¹åˆ¶è¯†åˆ«",
      "authors": [
        "PhilÃ©mon Beghin",
        "Anne-Emmanuelle Ceulemans",
        "FranÃ§ois Glineur"
      ],
      "abstract": "The first violins appeared in late 16th-century Italy. Over the next 200 years, they spread across Europe and luthiers of various royal courts, eager to experiment with new techniques, created a highly diverse family of instruments. Around 1750, size standards were introduced to unify violin making for orchestras and conservatories. Instruments that fell between two standards were then reduced to a smaller size by luthiers. These reductions have an impact on several characteristics of violins, in particular on the contour lines, i.e. lines of constant altitude, which look more like a U for non reduced instruments and a V for reduced ones. While such differences are observed by experts, they have not been studied quantitatively.\n  This paper presents a method for classifying violins as reduced or non-reduced based on their contour lines. We study a corpus of 25 instruments whose 3D geometric meshes were acquired via photogrammetry. For each instrument, we extract 10-20 contour lines regularly spaced every millimetre. Each line is fitted with a parabola-like curve (with an equation of the type y = alpha*abs(x)**beta) depending on two parameters, describing how open (beta) and how vertically stretched (alpha) the curve is. We compute additional features from those parameters, using regressions and counting how many values fall under some threshold. We also deal with outliers and non equal numbers of levels, and eventually obtain a numerical profile for each instrument.\n  We then apply classification methods to assess whether geometry alone can predict size reduction. We find that distinguishing between reduced and non reduced instruments is feasible to some degree, taking into account that a whole spectrum of more or less transformed violins exists, for which it is more difficult to quantify the reduction. We also find the opening parameter beta to be the most predictive.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºç­‰é«˜çº¿ï¼ˆContour Linesï¼‰åˆ†ç±»çš„æ–¹æ³•ï¼Œç”¨äºè‡ªåŠ¨è¯†åˆ«å†å²å°æç´æ˜¯å¦å­˜åœ¨å°ºå¯¸ç¼©å‡ï¼ˆReductionï¼‰ç°è±¡ã€‚é’ˆå¯¹åˆ¶ç´å·¥è‰ºä¸­å› ç»Ÿä¸€æ ‡å‡†è€Œäº§ç”Ÿçš„å°ºå¯¸æ”¹è£…é—®é¢˜ï¼Œç ”ç©¶æŒ‡å‡ºç¼©å‡åçš„å°æç´ç­‰é«˜çº¿å¾€å¾€ç”±Uå½¢å˜ä¸ºVå½¢ï¼Œå¹¶åˆ©ç”¨æ‘„å½±æµ‹é‡æŠ€æœ¯ï¼ˆPhotogrammetryï¼‰è·å–äº†25æŠŠä¹å™¨çš„3Då‡ ä½•ç½‘æ ¼ã€‚é€šè¿‡å¯¹æ¯æ¯«ç±³æå–çš„ç­‰é«˜çº¿è¿›è¡ŒæŠ›ç‰©çº¿æ–¹ç¨‹ï¼ˆ$y = \\alpha|x|^\\beta$ï¼‰æ‹Ÿåˆï¼Œç ”ç©¶æå–äº†æè¿°å¼€å£ç¨‹åº¦ï¼ˆbetaï¼‰å’Œæ‹‰ä¼¸ç¨‹åº¦ï¼ˆalphaï¼‰çš„ç‰¹å¾å‚æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…ä¾æ®å‡ ä½•ç‰¹å¾è¿›è¡Œåˆ†ç±»å³å¯åœ¨ä¸€å®šç¨‹åº¦ä¸ŠåŒºåˆ†ç¼©å‡ä¸éç¼©å‡ä¹å™¨ã€‚ç ”ç©¶å‘ç°å‚æ•° beta æ˜¯æœ€å…·é¢„æµ‹æ€§çš„æŒ‡æ ‡ï¼Œå°½ç®¡å°æç´å½¢æ€çš„è¿ç»­æ¼”å˜å¢åŠ äº†å®šé‡åˆ†æçš„å¤æ‚æ€§ï¼Œè¯¥æ–¹æ³•ä»ä¸ºä¹å™¨é‰´å®šå’Œé‡åŒ–åˆ†ææä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ‰‹æ®µã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07743v1",
      "published_date": "2025-07-10 13:23:15 UTC",
      "updated_date": "2025-07-10 13:23:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:23.097136+00:00"
    },
    {
      "arxiv_id": "2507.14170v1",
      "title": "Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space",
      "title_zh": "Catalystï¼šä¸€ç§åŸºäºå‚æ•°ç©ºé—´è¾…åŠ©æ‰©å±•çš„ç»“æ„åŒ–å‰ªææ–°å‹æ­£åˆ™åŒ–é¡¹",
      "authors": [
        "Jaeheun Jung",
        "Donghun Lee"
      ],
      "abstract": "Structured pruning aims to reduce the size and computational cost of deep neural networks by removing entire filters or channels. The traditional regularizers such as L1 or Group Lasso and its variants lead to magnitude-biased pruning decisions, such that the filters with small magnitudes are likely to be pruned. Also, they often entail pruning results with almost zero margin around pruning decision boundary, such that tiny perturbation in a filter magnitude can flip the pruning decision. In this paper, we identify the precise algebraic condition under which pruning operations preserve model performance, and use the condition to construct a novel regularizer defined in an extended parameter space via auxiliary catalyst variables. The proposed Catalyst regularization ensures fair pruning chance for each filters with theoretically provable zero bias to their magnitude and robust pruning behavior achieved by wide-margin bifurcation of magnitudes between the preserved and the pruned filters. The theoretical properties naturally lead to real-world effectiveness, as shown by empirical validations of Catalyst Pruning algorithm. Pruning results on various datasets and models are superior to state-of-the-art filter pruning methods, and at the same time confirm the predicted robust and fair pruning characteristics of Catalyst pruning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Catalyst çš„æ–°å‹ç»“æ„åŒ–å‰ªæï¼ˆStructured pruningï¼‰æ­£åˆ™åŒ–å™¨ï¼Œæ—¨åœ¨é™ä½æ·±åº¦ç¥ç»ç½‘ç»œçš„è§„æ¨¡ä¸è®¡ç®—å¼€é”€ã€‚é’ˆå¯¹ä¼ ç»Ÿæ­£åˆ™åŒ–å™¨ï¼ˆå¦‚ L1 æˆ– Group Lassoï¼‰å®¹æ˜“å¯¼è‡´çš„å¹…åº¦åå·®ï¼ˆmagnitude-biasedï¼‰ä»¥åŠå†³ç­–è¾¹ç•Œä¸ç¨³å®šçš„é—®é¢˜ï¼Œç ”ç©¶è€…é€šè¿‡å¼•å…¥è¾…åŠ©å‚¬åŒ–å˜é‡æ‰©å±•å‚æ•°ç©ºé—´ï¼Œå¹¶åŸºäºæ¨¡å‹æ€§èƒ½ä¿æŒçš„ç²¾ç¡®ä»£æ•°æ¡ä»¶æ„å»ºäº†è¯¥æ­£åˆ™åŒ–æ¡†æ¶ã€‚Catalyst æ­£åˆ™åŒ–åœ¨ç†è®ºä¸Šç¡®ä¿äº†æ¯ä¸ªæ»¤æ³¢å™¨å…·æœ‰å…¬å¹³çš„å‰ªææœºä¼šï¼Œå®ç°äº†å¯è¯æ˜çš„é›¶åç½®ç‰¹æ€§ï¼Œå¹¶é€šè¿‡åœ¨ä¿ç•™å’Œå‰ªææ»¤æ³¢å™¨ä¹‹é—´å»ºç«‹å®½è¾¹é™…åˆ†å‰ï¼ˆwide-margin bifurcationï¼‰æ˜¾è‘—æå‡äº†å‰ªæè¡Œä¸ºçš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCatalyst Pruning ç®—æ³•åœ¨å¤šç§æ•°æ®é›†å’Œæ¨¡å‹ä¸Šçš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æ»¤æ³¢å™¨å‰ªæï¼ˆfilter pruningï¼‰æ–¹æ³•ï¼Œæœ‰åŠ›åœ°è¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€å…¬å¹³æ€§ä¸é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025 workshop HiLD 2025 (3rd workshop on High-dimensional Learning Dynamics)",
      "pdf_url": "https://arxiv.org/pdf/2507.14170v1",
      "published_date": "2025-07-10 13:10:02 UTC",
      "updated_date": "2025-07-10 13:10:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:26.358959+00:00"
    },
    {
      "arxiv_id": "2507.07725v1",
      "title": "Not All Preferences are What You Need for Post-Training: Selective Alignment Strategy for Preference Optimization",
      "title_zh": "å¹¶éæ‰€æœ‰åå¥½æ•°æ®éƒ½æ˜¯åè®­ç»ƒæ‰€å¿…éœ€çš„ï¼šé¢å‘åå¥½ä¼˜åŒ–çš„é€‰æ‹©æ€§å¯¹é½ç­–ç•¥",
      "authors": [
        "Zhijin Dong"
      ],
      "abstract": "Post-training alignment of large language models (LLMs) is a critical challenge, as not all tokens contribute equally to model performance. This paper introduces a selective alignment strategy that prioritizes high-impact tokens within preference pairs, leveraging token-level log-probability differences between the current policy and a reference model. By focusing on these informative tokens, our approach reduces computational overhead and enhances alignment fidelity. We further explore the role of reference model quality, demonstrating that stronger reference models significantly improve token selection accuracy and overall optimization effectiveness. Comprehensive experiments on benchmarks such as Arena-Hard and MT-Bench validate the superiority of our Selective-DPO method over standard DPO and distillation-based baselines. Our findings highlight the importance of token-level optimization and reference model selection in advancing preference alignment for LLMs. The code is available at https://github.com/Dongzhijin/SDPO.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Selective-DPOï¼Œä¸€ç§é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åè®­ç»ƒå¯¹é½ (Post-training alignment) çš„é€‰æ‹©æ€§å¯¹é½ç­–ç•¥ï¼Œæ—¨åœ¨è§£å†³å¹¶éæ‰€æœ‰ Token å¯¹æ¨¡å‹æ€§èƒ½è´¡çŒ®å‡ç­‰çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨å½“å‰ç­–ç•¥ä¸å‚è€ƒæ¨¡å‹ (reference model) ä¹‹é—´çš„ Token çº§å¯¹æ•°æ¦‚ç‡å·®å¼‚ï¼Œè¯†åˆ«å¹¶ä¼˜å…ˆå¤„ç†åå¥½å¯¹ä¸­çš„é«˜å½±å“ Tokenï¼Œä»è€Œåœ¨é™ä½è®¡ç®—å¼€é”€çš„åŒæ—¶å¢å¼ºå¯¹é½ä¿çœŸåº¦ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œæ›´é«˜è´¨é‡çš„å‚è€ƒæ¨¡å‹èƒ½æ˜¾è‘—æå‡ Token é€‰æ‹©çš„å‡†ç¡®æ€§åŠæ•´ä½“ä¼˜åŒ–æ•ˆæœã€‚åœ¨ Arena-Hard å’Œ MT-Bench ç­‰åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒSelective-DPO çš„è¡¨ç°ä¼˜äºæ ‡å‡† DPO å’ŒåŸºäºè’¸é¦çš„åŸºçº¿æ–¹æ¡ˆã€‚è¯¥å‘ç°å¼ºè°ƒäº† Token çº§ä¼˜åŒ–åœ¨å¤§è¯­è¨€æ¨¡å‹åå¥½å¯¹é½ (preference alignment) é¢†åŸŸçš„æ ¸å¿ƒä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07725v1",
      "published_date": "2025-07-10 12:58:45 UTC",
      "updated_date": "2025-07-10 12:58:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:27.057156+00:00"
    },
    {
      "arxiv_id": "2507.07723v2",
      "title": "Stable Preference Optimization: A Bilevel Approach to Catastrophic Preference Shift",
      "title_zh": "Stable Preference Optimizationï¼šåº”å¯¹ç¾éš¾æ€§åå¥½åç§»çš„åŒå±‚æ–¹æ³•",
      "authors": [
        "Chengtao Jian",
        "Kai Yang",
        "Tianhao Gao",
        "Wuguang Ni",
        "Keying Yang",
        "Bowen Xiao",
        "Jiajun Liu",
        "Ye Ouyang"
      ],
      "abstract": "Direct Preference Learning has emerged as a dominant offline paradigm for preference optimization. Most of these methods are based on the Bradley-Terry (BT) model for pairwise preference ranking, which directly aligns language model with human preference. Prior work has observed a counter-intuitive phenomenon termed likelihood displacement, where the absolute probability of preferred responses decreases simultaneously during training. We demonstrate that such displacement can lead to a more devastating failure mode, which we defined as \\textit{Catastrophic Preference Shift}, where the lost preference probability mass inadvertently shifts toward out-of-distribution (OOD) responses. Such a failure mode is a key limitation shared across BT-style direct preference learning methods, due to the fundamental conflict between the unconstrained discriminative alignment and generative foundational capabilities, ultimately leading to severe performance degradation (e.g., SimPO suffers a significant drop in reasoning accuracy from 73.5\\% to 37.5\\%). We analyze existing BT-style methods from the probability evolution perspective and theoretically prove that these methods exhibit over-reliance on model initialization and can lead to preference shift. To resolve these counter-intuitive behaviors, we propose a theoretically grounded Stable Preference Optimization (SPO) framework that constrains preference learning within a safe alignment region. Empirical evaluations demonstrate that SPO effectively stabilizes and enhances the performance of existing BT-style preference learning methods. SPO provides new insights into the design of preference learning objectives and opens up new avenues towards more reliable and interpretable language model alignment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç›´æ¥åå¥½å­¦ä¹  (Direct Preference Learning) ä¸­å¸¸è§çš„â€œç¾éš¾æ€§åå¥½åç§»â€ (Catastrophic Preference Shift) é—®é¢˜ï¼Œå³åå¥½æ¦‚ç‡è´¨é‡æ— æ„ä¸­å‘åˆ†å¸ƒå¤– (OOD) å“åº”è½¬ç§»çš„ç°è±¡ã€‚ä½œè€…æŒ‡å‡ºï¼ŒåŸºäº Bradley-Terry (BT) æ¨¡å‹çš„å¯¹é½æ–¹æ³•åœ¨è®­ç»ƒä¸­å¸¸å‡ºç°ä¼¼ç„¶ä½ç§» (likelihood displacement)ï¼Œå¯¼è‡´ç”Ÿæˆèƒ½åŠ›ä¸åˆ¤åˆ«å¼å¯¹é½ç›®æ ‡å‘ç”Ÿå†²çªï¼Œä»è€Œå¼•å‘ä¸¥é‡çš„æ€§èƒ½è¡°å‡ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†ç¨³å®šåå¥½ä¼˜åŒ– (Stable Preference Optimization, SPO) æ¡†æ¶ï¼Œåˆ©ç”¨åŒå±‚ä¼˜åŒ– (Bilevel Approach) å°†åå¥½å­¦ä¹ çº¦æŸåœ¨å®‰å…¨å¯¹é½åŒºåŸŸå†…ã€‚ç†è®ºåˆ†æè¯æ˜äº†ç°æœ‰æ–¹æ³•å¯¹åˆå§‹åŒ–çš„è¿‡åº¦ä¾èµ–ï¼Œè€Œå®éªŒéªŒè¯äº† SPO èƒ½æœ‰æ•ˆç¨³å®šå¹¶å¢å¼ºç°æœ‰ BT é£æ ¼æ–¹æ³•çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶ä¸ºæ„å»ºæ›´å¯é ã€æ›´å…·å¯è§£é‡Šæ€§çš„è¯­è¨€æ¨¡å‹å¯¹é½ç³»ç»Ÿæä¾›äº†æ–°çš„è®¾è®¡æ€è·¯ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07723v2",
      "published_date": "2025-07-10 12:57:39 UTC",
      "updated_date": "2026-01-06 12:10:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:30.011575+00:00"
    },
    {
      "arxiv_id": "2507.07714v2",
      "title": "Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots",
      "title_zh": "åŸºäºè‡ªé€‚åº”é«˜æ–¯æ··åˆæ¨¡å‹çš„æ¬ çº¦æŸç»³ç´¢é©±åŠ¨å¹¶è”æœºå™¨äººå¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Julio Garrido",
        "Javier Vales",
        "Diego Silva-MuÃ±iz",
        "Enrique Riveiro",
        "Pablo LÃ³pez-Matencio",
        "JosuÃ© Rivera-Andrade"
      ],
      "abstract": "Cable-Driven Parallel Robots (CDPRs) are increasingly used for load manipulation tasks involving predefined toolpaths with intermediate stops. At each stop, where the platform maintains a fixed pose and the motors keep the cables under tension, the system must evaluate whether it is safe to proceed by detecting anomalies that could compromise performance (e.g., wind gusts or cable impacts). This paper investigates whether anomalies can be detected using only motor torque data, without additional sensors. It introduces an adaptive, unsupervised outlier detection algorithm based on Gaussian Mixture Models (GMMs) to identify anomalies from torque signals. The method starts with a brief calibration period, just a few seconds, during which a GMM is fit on known anomaly-free data. Real-time torque measurements are then evaluated using Mahalanobis distance from the GMM, with statistically derived thresholds triggering anomaly flags. Model parameters are periodically updated using the latest segments identified as anomaly-free to adapt to changing conditions. Validation includes 14 long-duration test sessions simulating varied wind intensities. The proposed method achieves a 100% true positive rate and 95.4% average true negative rate, with 1-second detection latency. Comparative evaluation against power threshold and non-adaptive GMM methods indicates higher robustness to drift and environmental variation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç»³ç´¢é©±åŠ¨å¹¶è”æœºå™¨äºº(Cable-Driven Parallel Robots, CDPRs)åœ¨è´Ÿè½½æ“ä½œä»»åŠ¡ä¸­é¢ä¸´çš„å¼‚å¸¸æ£€æµ‹æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè‡ªé€‚åº”é«˜æ–¯æ··åˆæ¨¡å‹(Gaussian Mixture Models, GMMs)çš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ç®—æ³•ã€‚è¯¥æ–¹æ³•ä»…ä¾èµ–ç”µæœºè½¬çŸ©æ•°æ®è€Œæ— éœ€é¢å¤–ä¼ æ„Ÿå™¨ï¼Œé€šè¿‡åœ¨æçŸ­æ ¡å‡†æœŸå†…å¯¹æ— å¼‚å¸¸æ•°æ®è¿›è¡Œæ‹Ÿåˆï¼Œå¹¶ç»“åˆé©¬æ°è·ç¦»(Mahalanobis distance)ä¸ç»Ÿè®¡é˜ˆå€¼å®ç°å¯¹å®æ—¶ä¿¡å·çš„ç²¾ç¡®è¯„ä¼°ã€‚ä¸ºäº†åº”å¯¹ç¯å¢ƒå˜åŒ–ï¼Œç®—æ³•ä¼šå®šæœŸåˆ©ç”¨æœ€æ–°çš„æ— å¼‚å¸¸æ•°æ®ç‰‡æ®µæ›´æ–°æ¨¡å‹å‚æ•°ï¼Œä»è€Œæ˜¾è‘—æé«˜ç³»ç»Ÿçš„è‡ªé€‚åº”èƒ½åŠ›ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œåœ¨åŒ…å«å¤šç§é£åŠ›å¼ºåº¦çš„æµ‹è¯•åœºæ™¯ä¸‹ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†100%çš„çœŸé˜³æ€§ç‡(true positive rate)å’Œ95.4%çš„å¹³å‡çœŸé˜´æ€§ç‡(true negative rate)ï¼Œä¸”æ£€æµ‹å»¶è¿Ÿä»…ä¸º1ç§’ã€‚ç›¸è¾ƒäºä¼ ç»Ÿçš„åŠŸç‡é˜ˆå€¼å’Œéè‡ªé€‚åº”æ¨¡å‹ï¼Œè¯¥æ–¹æ¡ˆåœ¨å¤„ç†ä¿¡å·æ¼‚ç§»å’Œç¯å¢ƒæ³¢åŠ¨æ–¹é¢è¡¨ç°å‡ºæ›´é«˜çš„é²æ£’æ€§ï¼Œä¸ºCDPRsçš„å®‰å…¨è¿è¡Œæä¾›äº†å¯é çš„æŠ€æœ¯ä¿éšœã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "14 pages, 8 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2507.07714v2",
      "published_date": "2025-07-10 12:52:19 UTC",
      "updated_date": "2025-07-22 13:39:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:45.794633+00:00"
    },
    {
      "arxiv_id": "2508.02817v1",
      "title": "Real-World Receptivity to Adaptive Mental Health Interventions: Findings from an In-the-Wild Study",
      "title_zh": "ç°å®ç¯å¢ƒä¸‹è‡ªé€‚åº”å¿ƒç†å¥åº·å¹²é¢„çš„æ¥å—åº¦ï¼šä¸€é¡¹å®åœ°ç ”ç©¶çš„å‘ç°",
      "authors": [
        "Nilesh Kumar Sahu",
        "Aditya Sneh",
        "Snehil Gupta",
        "Haroon R Lone"
      ],
      "abstract": "The rise of mobile health (mHealth) technologies has enabled real-time monitoring and intervention for mental health conditions using passively sensed smartphone data. Building on these capabilities, Just-in-Time Adaptive Interventions (JITAIs) seek to deliver personalized support at opportune moments, adapting to users' evolving contexts and needs. Although prior research has examined how context affects user responses to generic notifications and general mHealth messages, relatively little work has explored its influence on engagement with actual mental health interventions. Furthermore, while much of the existing research has focused on detecting when users might benefit from an intervention, less attention has been paid to understanding receptivity, i.e., users' willingness and ability to engage with and act upon the intervention.\n  In this study, we investigate user receptivity through two components: acceptance(acknowledging or engaging with a prompt) and feasibility (ability to act given situational constraints). We conducted a two-week in-the-wild study with 70 students using a custom Android app, LogMe, which collected passive sensor data and active context reports to prompt mental health interventions. The adaptive intervention module was built using Thompson Sampling, a reinforcement learning algorithm. We address four research questions relating smartphone features and self-reported contexts to acceptance and feasibility, and examine whether an adaptive reinforcement learning approach can optimize intervention delivery by maximizing a combined receptivity reward. Our results show that several types of passively sensed data significantly influenced user receptivity to interventions. Our findings contribute insights into the design of context-aware, adaptive interventions that are not only timely but also actionable in real-world settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç§»åŠ¨å¥åº·(mHealth)é¢†åŸŸä¸­å³æ—¶è‡ªé€‚åº”å¹²é¢„(Just-in-Time Adaptive Interventions, JITAIs)åœ¨çœŸå®ä¸–ç•Œä¸­çš„æ¥å—åº¦(receptivity)ï¼Œé‡ç‚¹å®šä¹‰å¹¶è¡¡é‡äº†ç”¨æˆ·æ¥å—å¹²é¢„çš„æ„æ„¿(acceptance)åŠåœ¨ç‰¹å®šæƒ…å¢ƒä¸‹é‡‡å–è¡ŒåŠ¨çš„å¯è¡Œæ€§(feasibility)ã€‚é€šè¿‡å¯¹70åå­¦ç”Ÿè¿›è¡Œçš„ä¸ºæœŸä¸¤å‘¨çš„é‡å¤–å®éªŒ(in-the-wild study)ï¼Œç ”ç©¶è€…åˆ©ç”¨å®šåˆ¶çš„LogMeåº”ç”¨æ”¶é›†è¢«åŠ¨ä¼ æ„Ÿå™¨æ•°æ®ï¼Œå¹¶é‡‡ç”¨å¼ºåŒ–å­¦ä¹ (reinforcement learning)ä¸­çš„æ±¤æ™®æ£®é‡‡æ ·(Thompson Sampling)ç®—æ³•æ¥ä¼˜åŒ–å¹²é¢„æŠ•æ”¾ã€‚å®éªŒç»“æœè¯æ˜ï¼Œå¤šç§ç±»å‹çš„è¢«åŠ¨æ„ŸçŸ¥æ•°æ®èƒ½æ˜¾è‘—å½±å“ç”¨æˆ·å¯¹å¿ƒç†å¥åº·å¹²é¢„çš„æ¥å—åº¦ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†æ™ºèƒ½æ‰‹æœºç‰¹å¾ä¸è‡ªæˆ‘æŠ¥å‘Šæƒ…å¢ƒå¯¹å¹²é¢„æ•ˆæœçš„å½±å“ï¼Œä¸ºè®¾è®¡æ›´å…·æƒ…å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€åŠæ—¶ä¸”åœ¨ç°å®åœºæ™¯ä¸­å…·å¤‡å¯æ“ä½œæ€§çš„è‡ªé€‚åº”å¹²é¢„ç³»ç»Ÿæä¾›äº†å…³é”®è§è§£ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "eess.SP"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.02817v1",
      "published_date": "2025-07-10 12:45:15 UTC",
      "updated_date": "2025-07-10 12:45:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:55:03.186621+00:00"
    },
    {
      "arxiv_id": "2507.07695v2",
      "title": "KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities",
      "title_zh": "KeyKnowledgeRAG (K^2RAG)ï¼šä¸€ç§æå‡å¤§è¯­è¨€æ¨¡å‹é—®ç­”èƒ½åŠ›çš„å¢å¼ºå‹ RAG æ–¹æ³•",
      "authors": [
        "Hruday Markondapatnaikuni",
        "Basem Suleiman",
        "Abdelkarim Erradi",
        "Shijing Chen"
      ],
      "abstract": "Fine-tuning is an immensely resource-intensive process when retraining Large Language Models (LLMs) to incorporate a larger body of knowledge. Although many fine-tuning techniques have been developed to reduce the time and computational cost involved, the challenge persists as LLMs continue to grow in size and complexity. To address this, a new approach to knowledge expansion in LLMs is needed. Retrieval-Augmented Generation (RAG) offers one such alternative by storing external knowledge in a database and retrieving relevant chunks to support question answering. However, naive implementations of RAG face significant limitations in scalability and answer accuracy. This paper introduces KeyKnowledgeRAG (K2RAG), a novel framework designed to overcome these limitations. Inspired by the divide-and-conquer paradigm, K2RAG integrates dense and sparse vector search, knowledge graphs, and text summarization to improve retrieval quality and system efficiency. The framework also includes a preprocessing step that summarizes the training data, significantly reducing the training time. K2RAG was evaluated using the MultiHopRAG dataset, where the proposed pipeline was trained on the document corpus and tested on a separate evaluation set. Results demonstrated notable improvements over common naive RAG implementations. K2RAG achieved the highest mean answer similarity score of 0.57, and reached the highest third quartile (Q3) similarity of 0.82, indicating better alignment with ground-truth answers. In addition to improved accuracy, the framework proved highly efficient. The summarization step reduced the average training time of individual components by 93%, and execution speed was up to 40% faster than traditional knowledge graph-based RAG systems. K2RAG also demonstrated superior scalability, requiring three times less VRAM than several naive RAG implementations tested in this study.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†KeyKnowledgeRAG (K^2RAG)ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨çŸ¥è¯†æ‰©å±•è¿‡ç¨‹ä¸­fine-tuningèµ„æºæ¶ˆè€—è¿‡å¤§ä»¥åŠnaive RAGåœ¨å‡†ç¡®æ€§ä¸å¯æ‰©å±•æ€§ä¸Šçš„å±€é™ã€‚å—divide-and-conquerèŒƒå¼å¯å‘ï¼ŒK^2RAGé›†æˆäº†dense and sparse vector searchã€knowledge graphså’Œtext summarizationæŠ€æœ¯ï¼Œé€šè¿‡é¢„å¤„ç†æ­¥éª¤å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œæ‘˜è¦ä»¥æå‡æ£€ç´¢è´¨é‡å’Œæ•ˆç‡ã€‚å®éªŒåœ¨MultiHopRAGæ•°æ®é›†ä¸Šè¡¨æ˜ï¼ŒK^2RAGåœ¨ç­”æ¡ˆç›¸ä¼¼åº¦ä¸Šè¾¾åˆ°æœ€é«˜å¹³å‡è¯„åˆ†0.57ï¼Œå…¶Q3ç›¸ä¼¼åº¦è¾¾0.82ï¼Œè¡¨ç°å‡ºä¸æ ‡å‡†ç­”æ¡ˆçš„é«˜åº¦ä¸€è‡´æ€§ã€‚åœ¨æ•ˆç‡æ–¹é¢ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ‘˜è¦é¢„å¤„ç†å°†ç»„ä»¶å¹³å‡è®­ç»ƒæ—¶é—´ç¼©çŸ­äº†93%ï¼Œæ‰§è¡Œé€Ÿåº¦æ¯”ä¼ ç»ŸåŸºäºçŸ¥è¯†å›¾è°±çš„RAGç³»ç»Ÿå¿«40%ã€‚æ­¤å¤–ï¼ŒK^2RAGå±•ç°äº†æä½³çš„å¯æ‰©å±•æ€§ï¼Œå…¶æ˜¾å­˜(VRAM)å ç”¨ä»…ä¸ºæµ‹è¯•ä¸­naive RAGçš„ä¸‰åˆ†ä¹‹ä¸€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07695v2",
      "published_date": "2025-07-10 12:19:03 UTC",
      "updated_date": "2025-07-31 08:57:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:52.581780+00:00"
    },
    {
      "arxiv_id": "2507.07685v1",
      "title": "Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought",
      "title_zh": "é¢å‘å¤šæ¨¡æ€æ€ç»´é“¾çš„ç†ç”±å¢å¼ºè§£ç ",
      "authors": [
        "Shin'ya Yamaguchi",
        "Kosuke Nishida",
        "Daiki Chijiwa"
      ],
      "abstract": "Large vision-language models (LVLMs) have demonstrated remarkable capabilities by integrating pre-trained vision encoders with large language models (LLMs). Similar to single-modal LLMs, chain-of-thought (CoT) prompting has been adapted for LVLMs to enhance multi-modal reasoning by generating intermediate rationales based on visual and textual inputs. While CoT is assumed to improve grounding and accuracy in LVLMs, our experiments reveal a key challenge: existing LVLMs often ignore the contents of generated rationales in CoT reasoning. To address this, we re-formulate multi-modal CoT reasoning as a KL-constrained reward maximization focused on rationale-conditional log-likelihood. As the optimal solution, we propose rationale-enhanced decoding (RED), a novel plug-and-play inference-time decoding strategy. RED harmonizes visual and rationale information by multiplying distinct image-conditional and rationale-conditional next token distributions. Extensive experiments show that RED consistently and significantly improves reasoning over standard CoT and other decoding methods across multiple benchmarks and LVLMs. Our work offers a practical and effective approach to improve both the faithfulness and accuracy of CoT reasoning in LVLMs, paving the way for more reliable rationale-grounded multi-modal systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ (LVLMs) åœ¨å¤šæ¨¡æ€é“¾å¼æ€ç»´ (Chain-of-Thought, CoT) æ¨ç†ä¸­å¾€å¾€å¿½ç•¥æ‰€ç”Ÿæˆæ¨ç†è¿‡ç¨‹ (rationales) å†…å®¹çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Rationale-Enhanced Decoding (RED) çš„åˆ›æ–°è§£ç ç­–ç•¥ã€‚ä½œè€…å°†å¤šæ¨¡æ€ CoT æ¨ç†é‡æ–°æ„å»ºä¸ºä»¥æ¨ç†è¿‡ç¨‹æ¡ä»¶å¯¹æ•°ä¼¼ç„¶ä¸ºæ ¸å¿ƒçš„ KL çº¦æŸå¥–åŠ±æœ€å¤§åŒ–é—®é¢˜ï¼Œå¹¶å°†å…¶ä½œä¸ºæœ€ä¼˜è§£å®ç°ã€‚RED æ˜¯ä¸€ç§å³æ’å³ç”¨çš„æ¨ç†æ—¶ç­–ç•¥ï¼Œé€šè¿‡ç»“åˆå›¾åƒæ¡ä»¶å’Œæ¨ç†æ¡ä»¶çš„ä¸‹ä¸€ä¸ª token åˆ†å¸ƒæ¥åè°ƒè§†è§‰ä¸é€»è¾‘ä¿¡æ¯ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•å’Œ LVLMs ä¸Šçš„å®éªŒè¯æ˜ï¼ŒRED åœ¨æ¨ç†æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºæ ‡å‡† CoT å’Œå…¶ä»–è§£ç æ–¹æ³•ã€‚è¯¥å·¥ä½œä¸ºæå‡ LVLMs æ¨ç†çš„å¿ å®åº¦ä¸å‡†ç¡®æ€§æä¾›äº†å®ç”¨æ–¹æ¡ˆï¼Œä¸ºæ„å»ºæ›´å¯é çš„åŸºäºæ¨ç†è¿‡ç¨‹çš„å¤šæ¨¡æ€ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07685v1",
      "published_date": "2025-07-10 12:07:13 UTC",
      "updated_date": "2025-07-10 12:07:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:55:03.317078+00:00"
    },
    {
      "arxiv_id": "2507.21110v1",
      "title": "SemRAG: Semantic Knowledge-Augmented RAG for Improved Question-Answering",
      "title_zh": "SemRAGï¼šæ—¨åœ¨æå‡é—®ç­”æ€§èƒ½çš„è¯­ä¹‰çŸ¥è¯†å¢å¼ºå‹æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Kezhen Zhong",
        "Basem Suleiman",
        "Abdelkarim Erradi",
        "Shijing Chen"
      ],
      "abstract": "This paper introduces SemRAG, an enhanced Retrieval Augmented Generation (RAG) framework that efficiently integrates domain-specific knowledge using semantic chunking and knowledge graphs without extensive fine-tuning. Integrating domain-specific knowledge into large language models (LLMs) is crucial for improving their performance in specialized tasks. Yet, existing adaptations are computationally expensive, prone to overfitting and limit scalability. To address these challenges, SemRAG employs a semantic chunking algorithm that segments documents based on the cosine similarity from sentence embeddings, preserving semantic coherence while reducing computational overhead. Additionally, by structuring retrieved information into knowledge graphs, SemRAG captures relationships between entities, improving retrieval accuracy and contextual understanding. Experimental results on MultiHop RAG and Wikipedia datasets demonstrate SemRAG has significantly enhances the relevance and correctness of retrieved information from the Knowledge Graph, outperforming traditional RAG methods. Furthermore, we investigate the optimization of buffer sizes for different data corpus, as optimizing buffer sizes tailored to specific datasets can further improve retrieval performance, as integration of knowledge graphs strengthens entity relationships for better contextual comprehension. The primary advantage of SemRAG is its ability to create an efficient, accurate domain-specific LLM pipeline while avoiding resource-intensive fine-tuning. This makes it a practical and scalable approach aligned with sustainability goals, offering a viable solution for AI applications in domain-specific fields.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SemRAGï¼Œä¸€ç§å¢å¼ºçš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval Augmented Generation, RAG) æ¡†æ¶ï¼Œæ—¨åœ¨ä¸è¿›è¡Œå¤§è§„æ¨¡å¾®è°ƒçš„æƒ…å†µä¸‹æœ‰æ•ˆæ•´åˆé¢†åŸŸç‰¹å®šçŸ¥è¯†ã€‚ä¸ºè§£å†³ç°æœ‰æ–¹æ³•è®¡ç®—æˆæœ¬é«˜å’Œæ‰©å±•æ€§å—é™ç­‰æŒ‘æˆ˜ï¼ŒSemRAG é‡‡ç”¨äº†ä¸€ç§åŸºäºå¥å­åµŒå…¥ä½™å¼¦ç›¸ä¼¼åº¦çš„è¯­ä¹‰åˆ†å— (Semantic Chunking) ç®—æ³•ï¼Œåœ¨ç¡®ä¿è¯­ä¹‰è¿è´¯æ€§çš„åŒæ—¶å‡å°‘äº†è®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†æ£€ç´¢ä¿¡æ¯æ„å»ºä¸ºçŸ¥è¯†å›¾è°± (Knowledge Graphs) ä»¥æ•æ‰å®ä½“é—´çš„å¤æ‚å…³ç³»ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢ç²¾åº¦å’Œä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€‚åœ¨ MultiHop RAG å’Œ Wikipedia æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒSemRAG åœ¨æ£€ç´¢ä¿¡æ¯çš„å‡†ç¡®æ€§ä¸ç›¸å…³æ€§ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿ RAG æ–¹æ³•ã€‚ç ”ç©¶è¿˜æ¢è®¨äº†é’ˆå¯¹ç‰¹å®šè¯­æ–™åº“ä¼˜åŒ–ç¼“å†²åŒºå¤§å° (Buffer Sizes) å¯¹è¿›ä¸€æ­¥æå‡æ£€ç´¢æ€§èƒ½çš„ä½œç”¨ã€‚SemRAG çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºèƒ½å¤Ÿé¿å…èµ„æºå¯†é›†å‹çš„å¾®è°ƒè¿‡ç¨‹ï¼Œæ„å»ºå‡ºé«˜æ•ˆã€ç²¾å‡†çš„é¢†åŸŸç‰¹å®šå¤§è¯­è¨€æ¨¡å‹æµæ°´çº¿ã€‚è¿™ä¸ºä¸“ä¸šé¢†åŸŸçš„ AI åº”ç”¨æä¾›äº†ä¸€ç§å®ç”¨ã€å¯æ‰©å±•ä¸”ç¬¦åˆå¯æŒç»­å‘å±•ç›®æ ‡çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.21110v1",
      "published_date": "2025-07-10 11:56:25 UTC",
      "updated_date": "2025-07-10 11:56:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:54:56.122158+00:00"
    },
    {
      "arxiv_id": "2507.07668v2",
      "title": "Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation",
      "title_zh": "åŸºäºé¢„æµ‹ä¸ç¡®å®šæ€§ä¼°è®¡å­¦ä¹ å¼ºå­æ€çš„æç‚¹ç»“æ„",
      "authors": [
        "Felix Frohnert",
        "Denny Lane B. Sombillo",
        "Evert van Nieuwenburg",
        "Patrick Emonts"
      ],
      "abstract": "Matching theoretical predictions to experimental data remains a central challenge in hadron spectroscopy. In particular, the identification of new hadronic states is difficult, as exotic signals near threshold can arise from a variety of physical mechanisms. A key diagnostic in this context is the pole structure of the scattering amplitude, but different configurations can produce similar signatures. The mapping between pole configurations and line shapes is especially ambiguous near the mass threshold, where analytic control is limited. In this work, we introduce an uncertainty-aware machine learning approach for classifying pole structures in $S$-matrix elements. Our method is based on an ensemble of classifier chains that provide both epistemic and aleatoric uncertainty estimates. We apply a rejection criterion based on predictive uncertainty, achieving a validation accuracy of nearly $95\\%$ while discarding only a small fraction of high-uncertainty predictions. Trained on synthetic data with known pole structures, the model generalizes to previously unseen experimental data, including enhancements associated with the $P_{c\\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole structure, representing the presence of a genuine compact pentaquark in the presence of a higher channel virtual state pole with non-vanishing width. While evaluated on this particular state, our framework is broadly applicable to other candidate hadronic states and offers a scalable tool for pole structure inference in scattering amplitudes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å…·å¤‡ä¸ç¡®å®šæ€§æ„ŸçŸ¥èƒ½åŠ›çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºæ¨æ–­ $S$-matrix å•å…ƒä¸­çš„æç‚¹ç»“æ„ (Pole structures)ï¼Œæ—¨åœ¨è§£å†³å¼ºå­èƒ½è°±å­¦ä¸­é˜ˆå€¼é™„è¿‘ç‰©ç†æœºåˆ¶è¯†åˆ«æ¨¡ç³Šçš„éš¾é¢˜ã€‚è¯¥æ–¹æ³•åŸºäºåˆ†ç±»å™¨é“¾é›†æˆ (Ensemble of classifier chains)ï¼Œèƒ½å¤ŸåŒæ—¶æä¾›è®¤çŸ¥ (Epistemic) å’Œå¶ç„¶ (Aleatoric) ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå¹¶å¼•å…¥æ‹’ç»å‡†åˆ™ (Rejection criterion) ä»¥ç¡®ä¿é¢„æµ‹çš„å¯é æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨åˆæˆæ•°æ®ä¸Šçš„éªŒè¯å‡†ç¡®ç‡æ¥è¿‘ 95%ï¼Œå¹¶å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼ŒæˆåŠŸåº”ç”¨äº LHCb è§‚æµ‹åˆ°çš„ $P_{c\\bar{c}}(4312)^+$ æ€ã€‚é€šè¿‡å¯¹è¯¥æ€çš„åˆ†æï¼Œç ”ç©¶æ¨æ–­å…¶å…·æœ‰å››æç‚¹ç»“æ„ (Four-pole structure)ï¼Œæ­ç¤ºäº†çœŸå®ç´§è‡´äº”å¤¸å…‹ (Compact pentaquark) ä¸è™šæ€æç‚¹å…±å­˜çš„å¯èƒ½æ€§ã€‚è¯¥æ¡†æ¶ä¸ºæ¨æ–­æ•£å°„æŒ¯å¹…çš„æç‚¹ç»“æ„æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”é«˜æ•ˆçš„å·¥å…·ï¼Œå…·æœ‰å¹¿æ³›çš„ç§‘ç ”åº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "hep-ph",
        "cs.AI",
        "cs.LG",
        "hep-ex"
      ],
      "primary_category": "hep-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07668v2",
      "published_date": "2025-07-10 11:49:17 UTC",
      "updated_date": "2025-07-11 07:41:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:55:39.548365+00:00"
    },
    {
      "arxiv_id": "2507.07644v2",
      "title": "FloorplanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations",
      "title_zh": "FloorplanQAï¼šåŸºäºç»“æ„åŒ–è¡¨ç¤ºçš„å¤§è¯­è¨€æ¨¡å‹ç©ºé—´æ¨ç†è¯„æµ‹åŸºå‡†",
      "authors": [
        "Fedor Rodionov",
        "Abdelrahman Eldesokey",
        "Michael Birsak",
        "John Femiani",
        "Bernard Ghanem",
        "Peter Wonka"
      ],
      "abstract": "We introduce FloorplanQA, a diagnostic benchmark for evaluating spatial reasoning in large-language models (LLMs). FloorplanQA is grounded in structured representations of indoor scenes, such as (e.g., kitchens, living rooms, bedrooms, bathrooms, and others), encoded symbolically in JSON or XML layouts. The benchmark covers core spatial tasks, including distance measurement, visibility, path finding, and object placement within constrained spaces. Our results across a variety of frontier open-source and commercial LLMs reveal that while models may succeed in shallow queries, they often fail to respect physical constraints, preserve spatial coherence, though they remain mostly robust to small spatial perturbations. FloorplanQA uncovers a blind spot in today's LLMs: inconsistent reasoning about indoor layouts. We hope this benchmark inspires new work on language models that can accurately infer and manipulate spatial and geometric properties in practical settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† FloorplanQAï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç©ºé—´æ¨ç†èƒ½åŠ›çš„è¯Šæ–­æ€§åŸºå‡†æµ‹è¯•ï¼ˆbenchmarkï¼‰ã€‚è¯¥åŸºå‡†åŸºäºå¨æˆ¿ã€å§å®¤ç­‰å®¤å†…åœºæ™¯çš„ç»“æ„åŒ–è¡¨ç¤ºï¼Œä½¿ç”¨ JSON æˆ– XML æ ¼å¼å¯¹å¸ƒå±€è¿›è¡Œç¬¦å·åŒ–ç¼–ç ã€‚FloorplanQA æ¶µç›–äº†è·ç¦»æµ‹é‡ï¼ˆdistance measurementï¼‰ã€å¯è§æ€§ï¼ˆvisibilityï¼‰ã€è·¯å¾„å¯»æ‰¾ï¼ˆpath findingï¼‰ä»¥åŠå—é™ç©ºé—´å†…çš„ç‰©ä½“æ”¾ç½®ï¼ˆobject placementï¼‰ç­‰æ ¸å¿ƒç©ºé—´ä»»åŠ¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡ç›®å‰çš„é¡¶çº§å¼€æºå’Œå•†ä¸š LLMs åœ¨å¤„ç†æµ…å±‚æŸ¥è¯¢æ—¶è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨éµå®ˆç‰©ç†çº¦æŸå’Œä¿æŒç©ºé—´è¿è´¯æ€§ï¼ˆspatial coherenceï¼‰æ–¹é¢ç»å¸¸å¤±è´¥ã€‚FloorplanQA æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨å®¤å†…å¸ƒå±€æ¨ç†ä¸Šçš„ä¸€è‡´æ€§ç›²ç‚¹ï¼Œæ—¨åœ¨æ¿€åŠ±æœªæ¥ç ”ç©¶å¼€å‘å‡ºèƒ½å‡†ç¡®æ¨æ–­å’Œå¤„ç†å®é™…ç©ºé—´å‡ ä½•å±æ€§çš„è¯­è¨€æ¨¡å‹ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "v2, Project page: https://OldDelorean.github.io/FloorplanQA/",
      "pdf_url": "https://arxiv.org/pdf/2507.07644v2",
      "published_date": "2025-07-10 11:16:48 UTC",
      "updated_date": "2025-10-06 12:00:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:55:08.178073+00:00"
    },
    {
      "arxiv_id": "2507.08881v1",
      "title": "The Consistency-Acceptability Divergence of LLMs in Judicial Decision-Making: Task and Stakeholder Dimensions",
      "title_zh": "å¸æ³•å†³ç­–ä¸­ LLMs çš„ä¸€è‡´æ€§ä¸å¯æ¥å—æ€§èƒŒç¦»ï¼šä»»åŠ¡ä¸åˆ©ç›Šç›¸å…³è€…ç»´åº¦",
      "authors": [
        "Zhang MingDa",
        "Xu Qing"
      ],
      "abstract": "The integration of large language model (LLM) technology into judicial systems is fundamentally transforming legal practice worldwide. However, this global transformation has revealed an urgent paradox requiring immediate attention. This study introduces the concept of ``consistency-acceptability divergence'' for the first time, referring to the gap between technical consistency and social acceptance. While LLMs achieve high consistency at the technical level, this consistency demonstrates both positive and negative effects. Through comprehensive analysis of recent data on LLM judicial applications from 2023--2025, this study finds that addressing this challenge requires understanding both task and stakeholder dimensions. This study proposes the Dual-Track Deliberative Multi-Role LLM Judicial Governance Framework (DTDMR-LJGF), which enables intelligent task classification and meaningful interaction among diverse stakeholders. This framework offers both theoretical insights and practical guidance for building an LLM judicial ecosystem that balances technical efficiency with social legitimacy.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¸æ³•å†³ç­–ä¸­çš„åº”ç”¨ï¼Œå¹¶é¦–æ¬¡æå‡ºäº†â€œä¸€è‡´æ€§-æ¥å—åº¦åˆ†æ­§â€ï¼ˆconsistency-acceptability divergenceï¼‰æ¦‚å¿µï¼Œæ—¨åœ¨æ­ç¤ºæŠ€æœ¯ä¸€è‡´æ€§ä¸ç¤¾ä¼šæ¥å—åº¦ä¹‹é—´çš„è„±èŠ‚ã€‚é€šè¿‡å¯¹ 2023-2025 å¹´é—´ LLM å¸æ³•åº”ç”¨æ•°æ®çš„ç»¼åˆåˆ†æï¼Œç ”ç©¶å‘ç°è¿™ç§ä¸€è‡´æ€§åœ¨ä»»åŠ¡å’Œåˆ©ç›Šç›¸å…³è€…ï¼ˆstakeholderï¼‰ç»´åº¦ä¸Šå…·æœ‰åŒé‡æ•ˆåº”ã€‚ä¸ºæ­¤ï¼Œæœ¬ç ”ç©¶æå‡ºäº†åŒè½¨å®¡è®®å¤šè§’è‰² LLM å¸æ³•æ²»ç†æ¡†æ¶ï¼ˆDual-Track Deliberative Multi-Role LLM Judicial Governance Framework, DTDMR-LJGFï¼‰ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå®ç°æ™ºèƒ½ä»»åŠ¡åˆ†ç±»å¹¶ä¿ƒè¿›ä¸åŒåˆ©ç›Šç›¸å…³è€…ä¹‹é—´çš„æœ‰æ•ˆäº’åŠ¨ã€‚è¯¥ç ”ç©¶ä¸ä»…ä¸ºå¸æ³•é¢†åŸŸåº”ç”¨ LLMs æä¾›äº†ç†è®ºè§è§£ï¼Œè¿˜ä¸ºæ„å»ºå…¼é¡¾æŠ€æœ¯æ•ˆç‡ä¸ç¤¾ä¼šåˆæ³•æ€§çš„æ³•å¾‹äººå·¥æ™ºèƒ½ç”Ÿæ€ç³»ç»Ÿæä¾›äº†å®åŠ¡æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages,2 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.08881v1",
      "published_date": "2025-07-10 10:50:29 UTC",
      "updated_date": "2025-07-10 10:50:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:55:08.453001+00:00"
    },
    {
      "arxiv_id": "2507.07622v1",
      "title": "TransformEEG: Towards Improving Model Generalizability in Deep Learning-based EEG Parkinson's Disease Detection",
      "title_zh": "TransformEEGï¼šæ—¨åœ¨æå‡åŸºäºæ·±åº¦å­¦ä¹ çš„è„‘ç”µå¸•é‡‘æ£®ç—…æ£€æµ‹æ¨¡å‹æ³›åŒ–èƒ½åŠ›",
      "authors": [
        "Federico Del Pup",
        "Riccardo Brun",
        "Filippo Iotti",
        "Edoardo Paccagnella",
        "Mattia Pezzato",
        "Sabrina Bertozzo",
        "Andrea Zanola",
        "Louis Fabrice Tshimanga",
        "Henning MÃ¼ller",
        "Manfredo Atzori"
      ],
      "abstract": "Electroencephalography (EEG) is establishing itself as an important, low-cost, noninvasive diagnostic tool for the early detection of Parkinson's Disease (PD). In this context, EEG-based Deep Learning (DL) models have shown promising results due to their ability to discover highly nonlinear patterns within the signal. However, current state-of-the-art DL models suffer from poor generalizability caused by high inter-subject variability. This high variability underscores the need for enhancing model generalizability by developing new architectures better tailored to EEG data. This paper introduces TransformEEG, a hybrid Convolutional-Transformer designed for Parkinson's disease detection using EEG data. Unlike transformer models based on the EEGNet structure, TransformEEG incorporates a depthwise convolutional tokenizer. This tokenizer is specialized in generating tokens composed by channel-specific features, which enables more effective feature mixing within the self-attention layers of the transformer encoder. To evaluate the proposed model, four public datasets comprising 290 subjects (140 PD patients, 150 healthy controls) were harmonized and aggregated. A 10-outer, 10-inner Nested-Leave-N-Subjects-Out (N-LNSO) cross-validation was performed to provide an unbiased comparison against seven other consolidated EEG deep learning models. TransformEEG achieved the highest balanced accuracy's median (78.45%) as well as the lowest interquartile range (6.37%) across all the N-LNSO partitions. When combined with data augmentation and threshold correction, median accuracy increased to 80.10%, with an interquartile range of 5.74%. In conclusion, TransformEEG produces more consistent and less skewed results. It demonstrates a substantial reduction in variability and more reliable PD detection using EEG data compared to the other investigated models.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹è„‘ç”µå›¾(EEG)åœ¨å¸•é‡‘æ£®ç—…(PD)æ—©æœŸæ£€æµ‹ä¸­å› ä¸ªä½“é—´é«˜åº¦å·®å¼‚å¯¼è‡´æ·±åº¦å­¦ä¹ æ¨¡å‹æ³›åŒ–æ€§å·®çš„é—®é¢˜ï¼Œæå‡ºäº†TransformEEGæ··åˆå·ç§¯Transformeræ¶æ„ã€‚è¯¥æ¨¡å‹é€šè¿‡å¼•å…¥ä¸“é—¨çš„æ·±åº¦å·ç§¯åˆ†è¯å™¨(depthwise convolutional tokenizer)ç”Ÿæˆé€šé“ç‰¹å®šç‰¹å¾çš„Tokenï¼Œæ—¨åœ¨Transformerç¼–ç å™¨çš„è‡ªæ³¨æ„åŠ›å±‚ä¸­å®ç°æ›´é«˜æ•ˆçš„ç‰¹å¾æ··åˆã€‚ç ”ç©¶é€šè¿‡æ•´åˆ290åå—è¯•è€…çš„å››ä¸ªå…¬å…±æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨åµŒå¥—ç•™Nå—è¯•è€…äº¤å‰éªŒè¯(Nested-Leave-N-Subjects-Out)è¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºTransformEEGçš„ä¸­å€¼å¹³è¡¡å‡†ç¡®ç‡è¾¾åˆ°äº†78.45%ï¼Œä¸”å››åˆ†ä½è·(interquartile range)æœ€ä½ã€‚åœ¨ç»“åˆæ•°æ®å¢å¼ºå’Œé˜ˆå€¼ä¿®æ­£æŠ€æœ¯åï¼Œå…¶ä¸­å€¼å‡†ç¡®ç‡è¿›ä¸€æ­¥æå‡è‡³80.10%ï¼Œå±•ç°å‡ºæ¯”ç°æœ‰æ¨¡å‹æ›´å¼ºçš„ä¸€è‡´æ€§å’Œæ›´ä½çš„æ³¢åŠ¨æ€§ã€‚æ€»è€Œè¨€ä¹‹ï¼ŒTransformEEGé€šè¿‡ä¼˜åŒ–æ¶æ„è®¾è®¡æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹åœ¨å¤„ç†EEGæ•°æ®æ—¶çš„å¯é æ€§ï¼Œä¸ºæå‡å¸•é‡‘æ£®ç—…æ£€æµ‹çš„é€šç”¨æ€§æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted for possible publication. GitHub repository: see https://github.com/MedMaxLab/transformeeg",
      "pdf_url": "https://arxiv.org/pdf/2507.07622v1",
      "published_date": "2025-07-10 10:44:53 UTC",
      "updated_date": "2025-07-10 10:44:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:55:16.610996+00:00"
    },
    {
      "arxiv_id": "2507.07619v1",
      "title": "Towards conservative inference in credal networks using belief functions: the case of credal chains",
      "title_zh": "åŸºäºä¿¡åº¦å‡½æ•°çš„ Credal ç½‘ç»œä¿å®ˆæ¨ç†ï¼šä»¥ Credal é“¾ä¸ºä¾‹",
      "authors": [
        "Marco Sangalli",
        "Thomas Krak",
        "Cassio de Campos"
      ],
      "abstract": "This paper explores belief inference in credal networks using Dempster-Shafer theory. By building on previous work, we propose a novel framework for propagating uncertainty through a subclass of credal networks, namely chains. The proposed approach efficiently yields conservative intervals through belief and plausibility functions, combining computational speed with robust uncertainty representation. Key contributions include formalizing belief-based inference methods and comparing belief-based inference against classical sensitivity analysis. Numerical results highlight the advantages and limitations of applying belief inference within this framework, providing insights into its practical utility for chains and for credal networks in general.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ credal networks ä¸­åˆ©ç”¨ Dempster-Shafer theory è¿›è¡Œä¿¡å¿µæ¨ç†çš„æ–¹æ³•ï¼Œå¹¶é‡ç‚¹ç ”ç©¶äº† credal chains è¿™ä¸€ç‰¹å®šå­ç±»ã€‚ä½œè€…æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶ï¼Œé€šè¿‡ belief functions å’Œ plausibility functions åœ¨é“¾å¼ç»“æ„ä¸­æœ‰æ•ˆä¼ æ’­ä¸ç¡®å®šæ€§ï¼Œä»è€Œè·å–ä¿å®ˆåŒºé—´ã€‚è¯¥æ–¹æ³•ç»“åˆäº†é«˜æ•ˆçš„è®¡ç®—é€Ÿåº¦ä¸é²æ£’çš„ä¸ç¡®å®šæ€§è¡¨è¾¾èƒ½åŠ›ï¼Œä¸ºå¤æ‚ç³»ç»Ÿæ¨ç†æä¾›äº†æ–°æ€è·¯ã€‚è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºå½¢å¼åŒ–äº†åŸºäºä¿¡å¿µçš„æ¨ç†æ–¹æ³•ï¼Œå¹¶å°†å…¶ä¸ä¼ ç»Ÿçš„ sensitivity analysis è¿›è¡Œäº†å¯¹æ¯”åˆ†æã€‚æ•°å€¼å®éªŒç»“æœæ­ç¤ºäº†è¯¥æ¡†æ¶åœ¨å¤„ç† credal chains æ—¶çš„ä¼˜åŠ¿ä¸å±€é™æ€§ï¼Œä¸ºå…¶åœ¨æ›´å¹¿æ³›çš„ credal networks å®é™…åº”ç”¨ä¸­æä¾›äº†ç†è®ºä¾æ®å’Œå®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "math.PR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07619v1",
      "published_date": "2025-07-10 10:40:24 UTC",
      "updated_date": "2025-07-10 10:40:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:55:48.686351+00:00"
    },
    {
      "arxiv_id": "2507.07599v1",
      "title": "Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models",
      "title_zh": "å¼ºåŒ–ç–«è‹—å®‰å…¨ç›‘æµ‹ï¼šåˆ©ç”¨å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ä»æ€¥è¯Šåˆ†è¯Šè®°å½•ä¸­æå–ç–«è‹—ä¿¡æ¯",
      "authors": [
        "Sedigh Khademi",
        "Jim Black",
        "Christopher Palmer",
        "Muhammad Javed",
        "Hazel Clothier",
        "Jim Buttery",
        "Gerardo Luis Dimaguila"
      ],
      "abstract": "This study evaluates fine-tuned Llama 3.2 models for extracting vaccine-related information from emergency department triage notes to support near real-time vaccine safety surveillance. Prompt engineering was used to initially create a labeled dataset, which was then confirmed by human annotators. The performance of prompt-engineered models, fine-tuned models, and a rule-based approach was compared. The fine-tuned Llama 3 billion parameter model outperformed other models in its accuracy of extracting vaccine names. Model quantization enabled efficient deployment in resource-constrained environments. Findings demonstrate the potential of large language models in automating data extraction from emergency department notes, supporting efficient vaccine safety surveillance and early detection of emerging adverse events following immunization issues.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¾®è°ƒ(Fine-tuned)çš„ Llama 3.2 æ¨¡å‹åœ¨ä»æ€¥è¯Šç§‘(Emergency Department)åˆ†è¯Šè®°å½•ä¸­æå–ç–«è‹—ç›¸å…³ä¿¡æ¯çš„èƒ½åŠ›ï¼Œæ—¨åœ¨æ”¯æŒè¿‘å®æ—¶çš„ç–«è‹—å®‰å…¨ç›‘æµ‹ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨æç¤ºå·¥ç¨‹(Prompt engineering)åˆæ­¥æ„å»ºæ ‡è®°æ•°æ®é›†å¹¶ç»è¿‡äººå·¥æ ¡éªŒï¼Œå¯¹æ¯”äº†æç¤ºå·¥ç¨‹æ¨¡å‹ã€å¾®è°ƒæ¨¡å‹åŠåŸºäºè§„åˆ™(Rule-based)æ–¹æ³•çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåçš„ Llama 3B æ¨¡å‹åœ¨ç–«è‹—åç§°æå–çš„å‡†ç¡®ç‡ä¸Šè¡¨ç°æœ€å‡ºè‰²ã€‚é€šè¿‡æ¨¡å‹é‡åŒ–(Model quantization)æŠ€æœ¯ï¼Œè¯¥æ–¹æ¡ˆèƒ½å¤Ÿå®ç°åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„é«˜æ•ˆéƒ¨ç½²ã€‚è¯¥é¡¹ç ”ç©¶å±•ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨åŒ–åŒ»ç–—æ•°æ®æå–ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºé«˜æ•ˆçš„ç–«è‹—å®‰å…¨ç›‘æ§å’Œå…ç–«æ¥ç§åä¸è‰¯äº‹ä»¶çš„æ—©æœŸé¢„è­¦æä¾›äº†æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.07599v1",
      "published_date": "2025-07-10 09:57:08 UTC",
      "updated_date": "2025-07-10 09:57:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:01.727082+00:00"
    },
    {
      "arxiv_id": "2507.07595v1",
      "title": "Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs",
      "title_zh": "Context Poolingï¼šé¢å‘çŸ¥è¯†å›¾è°±é€šç”¨å½’çº³å¼é“¾æ¥é¢„æµ‹çš„æŸ¥è¯¢ç‰¹å®šå›¾æ± åŒ–",
      "authors": [
        "Zhixiang Su",
        "Di Wang",
        "Chunyan Miao"
      ],
      "abstract": "Recent investigations on the effectiveness of Graph Neural Network (GNN)-based models for link prediction in Knowledge Graphs (KGs) show that vanilla aggregation does not significantly impact the model performance. In this paper, we introduce a novel method, named Context Pooling, to enhance GNN-based models' efficacy for link predictions in KGs. To our best of knowledge, Context Pooling is the first methodology that applies graph pooling in KGs. Additionally, Context Pooling is first-of-its-kind to enable the generation of query-specific graphs for inductive settings, where testing entities are unseen during training. Specifically, we devise two metrics, namely neighborhood precision and neighborhood recall, to assess the neighbors' logical relevance regarding the given queries, thereby enabling the subsequent comprehensive identification of only the logically relevant neighbors for link prediction. Our method is generic and assessed by being applied to two state-of-the-art (SOTA) models on three public transductive and inductive datasets, achieving SOTA performance in 42 out of 48 settings.",
      "tldr_zh": "é’ˆå¯¹çŸ¥è¯†å›¾è°±(Knowledge Graphs)ä¸­åŸºäºå›¾ç¥ç»ç½‘ç»œ(GNN)çš„é“¾æ¥é¢„æµ‹æ¨¡å‹åœ¨æ™®é€šèšåˆæ“ä½œä¸‹æ•ˆæœæœ‰é™çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Context Pooling çš„åˆ›æ–°æ–¹æ³•ã€‚ä½œä¸ºé¦–ä¸ªåœ¨çŸ¥è¯†å›¾è°±ä¸­åº”ç”¨å›¾æ± åŒ–(graph pooling)çš„æŠ€æœ¯ï¼ŒContext Pooling é¦–æ¬¡å®ç°äº†é’ˆå¯¹å½’çº³å¼å­¦ä¹ (inductive settings)ç”ŸæˆæŸ¥è¯¢ç‰¹å®šå›¾çš„èƒ½åŠ›ï¼Œä»è€Œæœ‰æ•ˆå¤„ç†è®­ç»ƒä¸­æœªè§çš„æ–°å®ä½“ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºè®¾è®¡äº†é‚»åŸŸç²¾åº¦(neighborhood precision)å’Œé‚»åŸŸå¬å›ç‡(neighborhood recall)ä¸¤ä¸ªæŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°é‚»å±…èŠ‚ç‚¹ä¸ç»™å®šæŸ¥è¯¢ä¹‹é—´çš„é€»è¾‘ç›¸å…³æ€§ã€‚é€šè¿‡ç²¾ç¡®è¯†åˆ«å¹¶ä»…ä¿ç•™é€»è¾‘ç›¸å…³çš„é‚»å±…ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹å¯¹é“¾æ¥é¢„æµ‹çš„æ¨ç†æ•ˆèƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒContext Pooling åœ¨åº”ç”¨äºä¸¤ç§æœ€å…ˆè¿›(SOTA)æ¨¡å‹å¹¶è¿›è¡Œå¤šé¡¹æ•°æ®é›†æµ‹è¯•æ—¶ï¼Œåœ¨48ä¸ªå®éªŒè®¾ç½®ä¸­å–å¾—äº†42ä¸ª SOTA ç»“æœï¼Œå……åˆ†éªŒè¯äº†å…¶åœ¨è½¬å¯¼å¼å’Œå½’çº³å¼åœºæ™¯ä¸‹çš„é€šç”¨æ€§ä¸ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07595v1",
      "published_date": "2025-07-10 09:54:37 UTC",
      "updated_date": "2025-07-10 09:54:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:06.150779+00:00"
    },
    {
      "arxiv_id": "2507.07586v2",
      "title": "Your Absorbing Discrete Diffusion Secretly Models the Bayesian Posterior",
      "title_zh": "å¸æ”¶æ€§ç¦»æ•£æ‰©æ•£æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯å¯¹è´å¶æ–¯åéªŒçš„å»ºæ¨¡",
      "authors": [
        "Cooper Doyle"
      ],
      "abstract": "Discrete diffusion language models learn to reconstruct text from randomly masked inputs, yet under mild assumptions their denoiser already implements the exact Bayesian posterior over the original tokens. We prove that the expected denoiser output under the forward corruption distribution recovers the true posterior, and that a simple Monte Carlo estimator converges to this posterior at rate O(1/sqrt(K)) with finite-sample concentration bounds. Building on this insight, we introduce an inference-time ensemble that runs K independent denoising passes and aggregates both posterior means and variances without any extra training. On WikiText-2, our MC-marginal sampler recovers the analytic lambda-DCE zero-shot perplexity (approximately 39) to within a few points at K=128, and its per-token variance shows a strong rank correlation with reconstruction error (Spearman rho = 0.996). This cost-proportional procedure yields calibrated uncertainty estimates and a direct trade-off between compute and posterior fidelity in discrete diffusion LMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¦»æ•£æ‰©æ•£è¯­è¨€æ¨¡å‹(Discrete diffusion language models)çš„æ•°å­¦æœ¬è´¨ï¼Œè¯æ˜äº†å…¶å»å™ªå™¨(denoiser)åœ¨æ¸©å’Œå‡è®¾ä¸‹å®é™…ä¸Šæ¨¡æ‹Ÿäº†åŸå§‹æ ‡è®°(tokens)çš„ç²¾ç¡®è´å¶æ–¯åéªŒ(Bayesian posterior)ã€‚é€šè¿‡ç†è®ºè¯æ˜ï¼Œä½œè€…æŒ‡å‡ºåœ¨å‰å‘æŸååˆ†å¸ƒ(forward corruption distribution)ä¸‹çš„æœŸæœ›å»å™ªå™¨è¾“å‡ºèƒ½å¤Ÿæ¢å¤çœŸå®çš„åéªŒï¼Œå¹¶æå‡ºäº†å…·æœ‰$O(1/\\sqrt{K})$æ”¶æ•›é€Ÿåº¦çš„è’™ç‰¹å¡ç½—(Monte Carlo)ä¼°è®¡å™¨ã€‚åŸºäºæ­¤å‘ç°ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒçš„æ¨ç†æ—¶é›†æˆ(inference-time ensemble)æ–¹æ³•ï¼Œé€šè¿‡èšåˆ$K$æ¬¡ç‹¬ç«‹å»å™ªè¿‡ç¨‹çš„å‡å€¼å’Œæ–¹å·®æ¥ä¼˜åŒ–æ¨æ–­ç»“æœã€‚åœ¨WikiText-2æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†è¯¥é‡‡æ ·å™¨åœ¨$K=128$æ—¶èƒ½é«˜åº¦è¿˜åŸé›¶æ ·æœ¬å›°æƒ‘åº¦(zero-shot perplexity)ï¼Œä¸”æ¯æ ‡è®°æ–¹å·®ä¸é‡æ„è¯¯å·®è¡¨ç°å‡ºæé«˜çš„ç§©ç›¸å…³æ€§(Spearman rho = 0.996)ã€‚è¯¥æ–¹æ³•ä¸ºç¦»æ•£æ‰©æ•£æ¨¡å‹æä¾›äº†æ ¡å‡†çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå¹¶åœ¨è®¡ç®—æˆæœ¬ä¸åéªŒä¿çœŸåº¦ä¹‹é—´å®ç°äº†ç›´æ¥çš„æƒè¡¡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 2 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.07586v2",
      "published_date": "2025-07-10 09:42:47 UTC",
      "updated_date": "2025-07-13 12:37:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:23.870024+00:00"
    },
    {
      "arxiv_id": "2507.07579v1",
      "title": "NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision Foundation Models and Multi-Task Learning",
      "title_zh": "NexViTADï¼šåŸºäºè§†è§‰åŸºç¡€æ¨¡å‹ä¸å¤šä»»åŠ¡å­¦ä¹ çš„å°æ ·æœ¬æ— ç›‘ç£è·¨åŸŸç¼ºé™·æ£€æµ‹",
      "authors": [
        "Tianwei Mu",
        "Feiyu Duan",
        "Bo Zhou",
        "Dan Xue",
        "Manhong Huang"
      ],
      "abstract": "This paper presents a novel few-shot cross-domain anomaly detection framework, Nexus Vision Transformer for Anomaly Detection (NexViTAD), based on vision foundation models, which effectively addresses domain-shift challenges in industrial anomaly detection through innovative shared subspace projection mechanisms and multi-task learning (MTL) module. The main innovations include: (1) a hierarchical adapter module that adaptively fuses complementary features from Hiera and DINO-v2 pre-trained models, constructing more robust feature representations; (2) a shared subspace projection strategy that enables effective cross-domain knowledge transfer through bottleneck dimension constraints and skip connection mechanisms; (3) a MTL Decoder architecture supports simultaneous processing of multiple source domains, significantly enhancing model generalization capabilities; (4) an anomaly score inference method based on Sinkhorn-K-means clustering, combined with Gaussian filtering and adaptive threshold processing for precise pixel level. Valuated on the MVTec AD dataset, NexViTAD delivers state-of-the-art performance with an AUC of 97.5%, AP of 70.4%, and PRO of 95.2% in the target domains, surpassing other recent models, marking a transformative advance in cross-domain defect detection.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†NexViTADï¼Œä¸€ä¸ªåŸºäºè§†è§‰åŸºç¡€æ¨¡å‹(Vision Foundation Models)çš„æ–°å‹å°‘æ ·æœ¬è·¨åŸŸå¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å·¥ä¸šå¼‚å¸¸æ£€æµ‹ä¸­é¢ä¸´çš„é¢†åŸŸåç§»(domain-shift)æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ†å±‚é€‚é…å™¨æ¨¡å—(hierarchical adapter module)è‡ªé€‚åº”èåˆHieraå’ŒDINO-v2é¢„è®­ç»ƒæ¨¡å‹çš„äº’è¡¥ç‰¹å¾ï¼Œæ„å»ºäº†æ›´ä¸ºé²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚ç ”ç©¶é‡‡ç”¨å…±äº«å­ç©ºé—´æŠ•å½±ç­–ç•¥(shared subspace projection)ï¼Œåˆ©ç”¨ç“¶é¢ˆç»´åº¦çº¦æŸå’Œè·³è·ƒè¿æ¥æœºåˆ¶å®ç°äº†æœ‰æ•ˆçš„è·¨åŸŸçŸ¥è¯†è½¬ç§»ã€‚å¼•å…¥çš„å¤šä»»åŠ¡å­¦ä¹ (MTL)è§£ç å™¨æ¶æ„èƒ½å¤ŸåŒæ—¶å¤„ç†å¤šä¸ªæºåŸŸæ•°æ®ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œè¯¥æ–¹æ³•ç»“åˆäº†åŸºäºSinkhorn-K-meansèšç±»çš„å¼‚å¸¸è¯„åˆ†æ¨æ–­ã€é«˜æ–¯æ»¤æ³¢åŠè‡ªé€‚åº”é˜ˆå€¼å¤„ç†ï¼Œå®ç°äº†ç²¾ç¡®çš„åƒç´ çº§ç¼ºé™·å®šä½ã€‚åœ¨MVTec ADæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒNexViTADåœ¨ç›®æ ‡åŸŸå–å¾—äº†97.5%çš„AUCã€70.4%çš„APå’Œ95.2%çš„PROï¼Œæ€§èƒ½è¶…è¶Šäº†è¿‘å¹´æ¥çš„ä¸»æµæ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°é«˜æ•ˆä¸”ç¨³å¥çš„è·¨åŸŸç¼ºé™·æ£€æµ‹æä¾›äº†åˆ›æ–°çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07579v1",
      "published_date": "2025-07-10 09:29:26 UTC",
      "updated_date": "2025-07-10 09:29:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:19.363338+00:00"
    },
    {
      "arxiv_id": "2507.07576v1",
      "title": "On Trustworthy Rule-Based Models and Explanations",
      "title_zh": "è®ºå¯ä¿¡çš„åŸºäºè§„åˆ™çš„æ¨¡å‹ä¸è§£é‡Š",
      "authors": [
        "Mohamed Siala",
        "Jordi Planes",
        "Joao Marques-Silva"
      ],
      "abstract": "A task of interest in machine learning (ML) is that of ascribing explanations to the predictions made by ML models. Furthermore, in domains deemed high risk, the rigor of explanations is paramount. Indeed, incorrect explanations can and will mislead human decision makers. As a result, and even if interpretability is acknowledged as an elusive concept, so-called interpretable models are employed ubiquitously in high-risk uses of ML and data mining (DM). This is the case for rule-based ML models, which encompass decision trees, diagrams, sets and lists. This paper relates explanations with well-known undesired facets of rule-based ML models, which include negative overlap and several forms of redundancy. The paper develops algorithms for the analysis of these undesired facets of rule-based systems, and concludes that well-known and widely used tools for learning rule-based ML models will induce rule sets that exhibit one or more negative facets.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœºå™¨å­¦ä¹ (ML)æ¨¡å‹é¢„æµ‹è§£é‡Šçš„å¯ä¿¡æ€§é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¯¹è§£é‡Šä¸¥è°¨æ€§è¦æ±‚æé«˜çš„é£é™©é¢†åŸŸã€‚æ–‡ç« é‡ç‚¹å…³æ³¨è¢«å¹¿æ³›è§†ä¸ºå¯è§£é‡Šæ¨¡å‹çš„åŸºäºè§„åˆ™çš„æ¨¡å‹(Rule-based models)ï¼ŒåŒ…æ‹¬å†³ç­–æ ‘(Decision trees)ã€å†³ç­–é›†(Sets)å’Œåˆ—è¡¨(Lists)ç­‰ã€‚ç ”ç©¶æ­ç¤ºäº†æ­¤ç±»æ¨¡å‹è§£é‡Šä¸è´Ÿé‡å (Negative overlap)åŠå¤šç§å†—ä½™(Redundancy)ç­‰å¸¸è§è´Ÿé¢ç‰¹å¾ä¹‹é—´çš„å…³è”ã€‚ä½œè€…å¼€å‘äº†ä¸“é—¨çš„ç®—æ³•ç”¨äºåˆ†æåŸºäºè§„åˆ™çš„ç³»ç»Ÿä¸­çš„è¿™äº›ä¸è‰¯ç‰¹æ€§ã€‚åˆ†æç»“æœè¡¨æ˜ï¼Œç›®å‰å¹¿æ³›ä½¿ç”¨çš„å­¦ä¹ ç®—æ³•åœ¨è®­ç»ƒåŸºäºè§„åˆ™çš„MLæ¨¡å‹æ—¶ï¼Œå¾€å¾€ä¼šç”Ÿæˆå…·æœ‰ä¸€ç§æˆ–å¤šç§è´Ÿé¢ç‰¹æ€§çš„è§„åˆ™é›†ã€‚è¿™å¼ºè°ƒäº†åœ¨è¿½æ±‚æ¨¡å‹å¯è§£é‡Šæ€§çš„åŒæ—¶ï¼Œå¿…é¡»å®¡æ…å¯¹å¾…è§„åˆ™ç”Ÿæˆå·¥å…·å¯èƒ½å¼•å…¥çš„è¯¯å¯¼æ€§é£é™©ï¼Œä»¥ç¡®ä¿äººç±»å†³ç­–è€…ä¸è¢«é”™è¯¯çš„è§£é‡Šæ‰€è¯¯å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07576v1",
      "published_date": "2025-07-10 09:28:12 UTC",
      "updated_date": "2025-07-10 09:28:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:17.234228+00:00"
    },
    {
      "arxiv_id": "2507.07572v1",
      "title": "Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation",
      "title_zh": "åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å®ç°å•å¯¹æ··æ¨¡æ€å¯¹é½çš„æ–‡æ¡£å›¾åƒæœºå™¨ç¿»è¯‘",
      "authors": [
        "Yupu Liang",
        "Yaping Zhang",
        "Zhiyang Zhang",
        "Yang Zhao",
        "Lu Xiang",
        "Chengqing Zong",
        "Yu Zhou"
      ],
      "abstract": "Document Image Machine Translation (DIMT) aims to translate text within document images, facing generalization challenges due to limited training data and the complex interplay between visual and textual information. To address these challenges, we introduce M4Doc, a novel single-to-mix modality alignment framework leveraging Multimodal Large Language Models (MLLMs). M4Doc aligns an image-only encoder with the multimodal representations of an MLLM, pre-trained on large-scale document image datasets. This alignment enables a lightweight DIMT model to learn crucial visual-textual correlations during training. During inference, M4Doc bypasses the MLLM, maintaining computational efficiency while benefiting from its multimodal knowledge. Comprehensive experiments demonstrate substantial improvements in translation quality, especially in cross-domain generalization and challenging document image scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æ¡£å›¾åƒæœºå™¨ç¿»è¯‘(Document Image Machine Translation, DIMT)å› è®­ç»ƒæ•°æ®æœ‰é™åŠè§†è§‰ä¸æ–‡æœ¬ä¿¡æ¯äº¤äº’å¤æ‚è€Œé¢ä¸´çš„æ³›åŒ–æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºM4Docçš„æ–°å‹å•åˆ°å¤šæ¨¡æ€å¯¹é½(single-to-mix modality alignment)æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨å¤§è§„æ¨¡æ–‡æ¡£æ•°æ®é›†ä¸Šçš„é¢„è®­ç»ƒçŸ¥è¯†ï¼Œå°†çº¯å›¾åƒç¼–ç å™¨(image-only encoder)ä¸MLLMçš„å¤šæ¨¡æ€è¡¨ç¤ºè¿›è¡Œå¯¹é½ã€‚é€šè¿‡è¿™ç§å¯¹é½æ–¹å¼ï¼Œè½»é‡çº§DIMTæ¨¡å‹èƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ åˆ°å…³é”®çš„è§†è§‰-æ–‡æœ¬å…³è”ï¼Œä»è€Œæå‡ç¿»è¯‘çš„å‡†ç¡®æ€§ã€‚åœ¨æ¨ç†é˜¶æ®µï¼ŒM4Docå¯ä»¥ç»•è¿‡MLLMè¿è¡Œï¼Œåœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶å……åˆ†å—ç›Šäºå…¶å¤šæ¨¡æ€çŸ¥è¯†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¿»è¯‘è´¨é‡ä¸Šå–å¾—äº†å®è´¨æ€§æ”¹è¿›ï¼Œç‰¹åˆ«æ˜¯åœ¨è·¨é¢†åŸŸæ³›åŒ–å’Œå¤æ‚æ–‡æ¡£å›¾åƒåœºæ™¯ä¸­å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2025 Main",
      "pdf_url": "https://arxiv.org/pdf/2507.07572v1",
      "published_date": "2025-07-10 09:18:06 UTC",
      "updated_date": "2025-07-10 09:18:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:17.554348+00:00"
    },
    {
      "arxiv_id": "2507.07551v1",
      "title": "ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing",
      "title_zh": "ArchiveGPTï¼šåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œå›¾åƒç¼–ç›®çš„ä»¥äººä¸ºä¸­å¿ƒè¯„ä¼°",
      "authors": [
        "Line Abele",
        "Gerrit Anders",
        "Tolgahan AydÄ±n",
        "JÃ¼rgen Buder",
        "Helen Fischer",
        "Dominik Kimmel",
        "Markus Huff"
      ],
      "abstract": "The accelerating growth of photographic collections has outpaced manual cataloguing, motivating the use of vision language models (VLMs) to automate metadata generation. This study examines whether Al-generated catalogue descriptions can approximate human-written quality and how generative Al might integrate into cataloguing workflows in archival and museum collections. A VLM (InternVL2) generated catalogue descriptions for photographic prints on labelled cardboard mounts with archaeological content, evaluated by archive and archaeology experts and non-experts in a human-centered, experimental framework. Participants classified descriptions as AI-generated or expert-written, rated quality, and reported willingness to use and trust in AI tools. Classification performance was above chance level, with both groups underestimating their ability to detect Al-generated descriptions. OCR errors and hallucinations limited perceived quality, yet descriptions rated higher in accuracy and usefulness were harder to classify, suggesting that human review is necessary to ensure the accuracy and quality of catalogue descriptions generated by the out-of-the-box model, particularly in specialized domains like archaeological cataloguing. Experts showed lower willingness to adopt AI tools, emphasizing concerns on preservation responsibility over technical performance. These findings advocate for a collaborative approach where AI supports draft generation but remains subordinate to human verification, ensuring alignment with curatorial values (e.g., provenance, transparency). The successful integration of this approach depends not only on technical advancements, such as domain-specific fine-tuning, but even more on establishing trust among professionals, which could both be fostered through a transparent and explainable AI pipeline.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (Vision Language Models, VLMs) è‡ªåŠ¨åŒ–ç”Ÿæˆå›¾åƒç¼–ç›®å…ƒæ•°æ®çš„å¯è¡Œæ€§ï¼Œå¹¶æå‡ºäº† ArchiveGPT è¿™ä¸€è¯„ä¼°æ¡†æ¶ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ InternVL2 æ¨¡å‹ä¸ºå…·æœ‰è€ƒå¤å†…å®¹çš„æ‘„å½±èµ„æ–™ç”Ÿæˆç¼–ç›®æè¿°ï¼Œå¹¶é‚€è¯·æ¡£æ¡ˆä¸è€ƒå¤ä¸“å®¶åŠéä¸“å®¶å¯¹å…¶è´¨é‡ã€å¯ä¿¡åº¦åŠé‡‡ç”¨æ„æ„¿è¿›è¡Œä»¥äººä¸ºä¸­å¿ƒçš„è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶å‚ä¸è€…è¯†åˆ« AI ç”Ÿæˆå†…å®¹çš„å‡†ç¡®ç‡é«˜äºéšæœºæ°´å¹³ï¼Œä½† OCR é”™è¯¯å’Œå¹»è§‰ (hallucinations) ä¾ç„¶æ˜¯é™åˆ¶å…¶è´¨é‡çš„ä¸»è¦ç“¶é¢ˆã€‚ç ”ç©¶å‘ç°å‡†ç¡®æ€§è¾ƒé«˜çš„æè¿°æ›´éš¾è¢«è¯†åˆ«ä¸º AI ç”Ÿæˆï¼Œè¿™å‡¸æ˜¾äº†åœ¨è€ƒå¤ç­‰ä¸“ä¸šé¢†åŸŸä¸­äººå·¥å®¡æ ¸ (human review) å¯¹ç¡®ä¿ç¼–ç›®è´¨é‡çš„å¿…è¦æ€§ã€‚æ­¤å¤–ï¼Œä¸“å®¶ç”±äºæ›´å…³æ³¨ä¿å­˜è´£ä»»è€Œè¡¨ç°å‡ºæ¯”éä¸“å®¶æ›´ä½çš„ AI é‡‡ç”¨æ„æ„¿ã€‚è¯¥è®ºæ–‡æœ€ç»ˆå»ºè®®é‡‡å–äººæœºåä½œæ¨¡å¼ï¼Œå°† AI ä½œä¸ºåˆç¨¿ç”Ÿæˆå·¥å…·å¹¶è¾…ä»¥äººå·¥éªŒè¯ï¼ŒåŒæ—¶å¼ºè°ƒé€šè¿‡å»ºç«‹é€æ˜å¯è§£é‡Šçš„æµæ°´çº¿æ¥å¢å¼ºä¸“ä¸šäººå‘˜çš„ä¿¡ä»»ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.HC",
      "comment": "56 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07551v1",
      "published_date": "2025-07-10 08:49:15 UTC",
      "updated_date": "2025-07-10 08:49:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:19.773110+00:00"
    },
    {
      "arxiv_id": "2507.07544v1",
      "title": "Position: We Need An Algorithmic Understanding of Generative AI",
      "title_zh": "ç«‹åœºï¼šæˆ‘ä»¬éœ€è¦å»ºç«‹å¯¹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„ç®—æ³•åŒ–ç†è§£",
      "authors": [
        "Oliver Eberle",
        "Thomas McGee",
        "Hamza Giaffar",
        "Taylor Webb",
        "Ida Momennejad"
      ],
      "abstract": "What algorithms do LLMs actually learn and use to solve problems? Studies addressing this question are sparse, as research priorities are focused on improving performance through scale, leaving a theoretical and empirical gap in understanding emergent algorithms. This position paper proposes AlgEval: a framework for systematic research into the algorithms that LLMs learn and use. AlgEval aims to uncover algorithmic primitives, reflected in latent representations, attention, and inference-time compute, and their algorithmic composition to solve task-specific problems. We highlight potential methodological paths and a case study toward this goal, focusing on emergent search algorithms. Our case study illustrates both the formation of top-down hypotheses about candidate algorithms, and bottom-up tests of these hypotheses via circuit-level analysis of attention patterns and hidden states. The rigorous, systematic evaluation of how LLMs actually solve tasks provides an alternative to resource-intensive scaling, reorienting the field toward a principled understanding of underlying computations. Such algorithmic explanations offer a pathway to human-understandable interpretability, enabling comprehension of the model's internal reasoning performance measures. This can in turn lead to more sample-efficient methods for training and improving performance, as well as novel architectures for end-to-end and multi-agent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œç›®å‰å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ç ”ç©¶ä¾§é‡äºé€šè¿‡è§„æ¨¡(scale)æå‡æ€§èƒ½ï¼Œä½†åœ¨ç†è§£å…¶è§£å†³é—®é¢˜æ‰€ä½¿ç”¨çš„ç®—æ³•æ–¹é¢å­˜åœ¨ç†è®ºå’Œç»éªŒç©ºç™½ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†AlgEvalæ¡†æ¶ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§åœ°ç ”ç©¶LLMsåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ å¹¶ä½¿ç”¨çš„ç®—æ³•ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ†ææ½œåœ¨è¡¨ç¤º(latent representations)ã€æ³¨æ„åŠ›æœºåˆ¶(attention)å’Œæ¨ç†æ—¶é—´è®¡ç®—(inference-time compute)æ¥æ­ç¤ºç®—æ³•åŸè¯­(algorithmic primitives)åŠå…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„ç®—æ³•ç»„åˆ(algorithmic composition)ã€‚é€šè¿‡å¯¹æ¶Œç°æœç´¢ç®—æ³•(emergent search algorithms)çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†å¦‚ä½•ç»“åˆè‡ªé¡¶å‘ä¸‹çš„å‡è®¾ç”Ÿæˆä¸è‡ªåº•å‘ä¸Šçš„ç”µè·¯çº§åˆ†æ(circuit-level analysis)æ¥éªŒè¯æ¨¡å‹å†…éƒ¨æœºåˆ¶ã€‚è¿™ç§å¯¹ç®—æ³•åº•å±‚è®¡ç®—çš„ä¸¥è°¨è¯„ä¼°ä¸ºå®ç°äººç±»å¯ç†è§£çš„å¯è§£é‡Šæ€§(interpretability)æä¾›äº†è·¯å¾„ã€‚æœ€ç»ˆï¼Œè¿™ç§ç®—æ³•çº§çš„ç†è§£æœ‰æœ›ä¿ƒè¿›æ›´å…·æ ·æœ¬æ•ˆç‡(sample-efficient)çš„è®­ç»ƒæ–¹æ³•ã€æ€§èƒ½ä¼˜åŒ–ä»¥åŠç«¯åˆ°ç«¯å’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ–°å‹æ¶æ„å¼€å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICML 2025 as a Spotlight Position Paper",
      "pdf_url": "https://arxiv.org/pdf/2507.07544v1",
      "published_date": "2025-07-10 08:38:47 UTC",
      "updated_date": "2025-07-10 08:38:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:33.416747+00:00"
    },
    {
      "arxiv_id": "2507.07543v2",
      "title": "The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora",
      "title_zh": "è·¨è¯­è¨€ä»£ä»·ï¼šé’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­-è‹±è¯­è¯­æ–™åº“çš„ RAG æ£€ç´¢åå·®",
      "authors": [
        "Chen Amiraz",
        "Yaroslav Fyodorov",
        "Elad Haramaty",
        "Zohar Karnin",
        "Liane Lewin-Eytan"
      ],
      "abstract": "Cross-lingual retrieval-augmented generation (RAG) is a critical capability for retrieving and generating answers across languages. Prior work in this context has mostly focused on generation and relied on benchmarks derived from open-domain sources, most notably Wikipedia. In such settings, retrieval challenges often remain hidden due to language imbalances, overlap with pretraining data, and memorized content. To address this gap, we study Arabic-English RAG in a domain-specific setting using benchmarks derived from real-world corporate datasets. Our benchmarks include all combinations of languages for the user query and the supporting document, drawn independently and uniformly at random. This enables a systematic study of multilingual retrieval behavior.\n  Our findings reveal that retrieval is a critical bottleneck in cross-lingual domain-specific scenarios, with substantial performance drops occurring when the user query and supporting document languages differ. A key insight is that these failures stem primarily from the retriever's difficulty in ranking documents across languages. Finally, we propose two simple retrieval strategies that address this source of failure by enforcing equal retrieval from both languages or by translating the query, resulting in substantial improvements in cross-lingual and overall performance. These results highlight meaningful opportunities for improving multilingual retrieval, particularly in practical, real-world RAG applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è·¨è¯­è¨€æ£€ç´¢å¢å¼ºç”Ÿæˆ (Cross-lingual RAG) ä¸­çš„æ£€ç´¢åå·®é—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨é˜¿æ‹‰ä¼¯è¯­ (Arabic) ä¸è‹±è¯­ (English) è¯­æ–™åº“åœ¨ç‰¹å®šé¢†åŸŸè®¾ç½®ä¸‹çš„è¡¨ç°ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰çš„åŸºäºç»´åŸºç™¾ç§‘ (Wikipedia) ç­‰å…¬å¼€æ•°æ®çš„åŸºå‡†æµ‹è¯•å¾€å¾€å› è¯­è¨€å¤±è¡¡æˆ–é¢„è®­ç»ƒæ•°æ®é‡å è€Œæ©ç›–äº†æ£€ç´¢æŒ‘æˆ˜ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œç ”ç©¶é€šè¿‡ä½¿ç”¨çœŸå®çš„ä¼ä¸šæ•°æ®é›†æ„å»ºåŸºå‡†æµ‹è¯•ï¼Œç³»ç»Ÿåœ°è¯„ä¼°äº†ç”¨æˆ·æŸ¥è¯¢ä¸æ”¯æŒæ–‡æ¡£åœ¨ä¸åŒè¯­è¨€ç»„åˆä¸‹çš„å¤šè¯­è¨€æ£€ç´¢è¡Œä¸ºã€‚å®éªŒå‘ç°ï¼Œå½“æŸ¥è¯¢ä¸æ–‡æ¡£è¯­è¨€ä¸ä¸€è‡´æ—¶ï¼Œæ£€ç´¢æ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ï¼Œå…¶æ ¸å¿ƒåŸå› åœ¨äºæ£€ç´¢å™¨ (Retriever) éš¾ä»¥å¯¹è·¨è¯­è¨€æ–‡æ¡£è¿›è¡Œå‡†ç¡®çš„æ’å (Ranking)ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†å¼ºåˆ¶åŒè¯­ç­‰é‡æ£€ç´¢å’ŒæŸ¥è¯¢ç¿»è¯‘ (Translation) ä¸¤ç§ç­–ç•¥ï¼Œæœ‰æ•ˆæå‡äº†è·¨è¯­è¨€åŠç³»ç»Ÿçš„æ•´ä½“è¡¨ç°ã€‚è¿™äº›å‘ç°ä¸ºæ”¹è¿›å®é™…åº”ç”¨ä¸­çš„å¤šè¯­è¨€æ£€ç´¢æä¾›äº†é‡è¦çš„å®è¯æ”¯æŒä¸ä¼˜åŒ–è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ArabicNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07543v2",
      "published_date": "2025-07-10 08:38:31 UTC",
      "updated_date": "2025-10-27 07:40:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:31.380085+00:00"
    },
    {
      "arxiv_id": "2507.21109v2",
      "title": "Task-Focused Consolidation with Spaced Recall: Making Neural Networks Learn like College Students",
      "title_zh": "ç»“åˆé—´éš”æ£€ç´¢çš„ä»»åŠ¡èšç„¦å¼å·©å›ºï¼šè®©ç¥ç»ç½‘ç»œåƒå¤§å­¦ç”Ÿä¸€æ ·å­¦ä¹ ",
      "authors": [
        "Prital Bamnodkar"
      ],
      "abstract": "Deep neural networks often suffer from a critical limitation known as catastrophic forgetting, where performance on past tasks degrades after learning new ones. This paper introduces a novel continual learning approach inspired by human learning strategies like Active Recall, Deliberate Practice, and Spaced Repetition, named Task-Focused Consolidation with Spaced Recall (TFC-SR). TFC-SR enhances the standard experience replay framework with a mechanism we term the Active Recall Probe. It is a periodic, task-aware evaluation of the model's memory that stabilizes the representations of past knowledge. We test TFC-SR on the Split MNIST and the Split CIFAR-100 benchmarks against leading regularization-based and replay-based baselines. Our results show that TFC-SR performs significantly better than these methods. For instance, on the Split CIFAR-100, it achieves a final accuracy of 13.17% compared to Standard Experience Replay's 7.40%. We demonstrate that this advantage comes from the stabilizing effect of the probe itself, and not from the difference in replay volume. Additionally, we analyze the trade-off between memory size and performance and show that while TFC-SR performs better in memory-constrained environments, higher replay volume is still more effective when available memory is abundant. We conclude that TFC-SR is a robust and efficient approach, highlighting the importance of integrating active memory retrieval mechanisms into continual learning systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å­¦ä¹ æ–°ä»»åŠ¡æ—¶é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜(Catastrophic Forgetting)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å—äººç±»å­¦ä¹ ç­–ç•¥å¯å‘çš„æŒç»­å­¦ä¹ (Continual Learning)æ–¹æ³•ï¼Œåä¸ºåŸºäºé—´éš”å¬å›çš„ä»»åŠ¡èšç„¦å·©å›º(Task-Focused Consolidation with Spaced Recall, TFC-SR)ã€‚è¯¥æ–¹æ³•å€Ÿé‰´äº†ä¸»åŠ¨å›å¿†(Active Recall)ã€åˆ»æ„ç»ƒä¹ (Deliberate Practice)å’Œé—´éš”é‡å¤(Spaced Repetition)ç­‰ç­–ç•¥ï¼Œé€šè¿‡æ ¸å¿ƒæœºåˆ¶ä¸»åŠ¨å›å¿†æ¢é’ˆ(Active Recall Probe)å¯¹æ¨¡å‹è®°å¿†è¿›è¡Œå‘¨æœŸæ€§çš„ä»»åŠ¡æ„ŸçŸ¥è¯„ä¼°ï¼Œä»è€Œç¨³å®šæ—§çŸ¥è¯†çš„ç‰¹å¾è¡¨ç¤ºã€‚åœ¨Split MNISTå’ŒSplit CIFAR-100åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒTFC-SRçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ­£åˆ™åŒ–å’Œé‡æ”¾åŸºå‡†æ–¹æ³•ï¼Œåœ¨Split CIFAR-100ä¸Šçš„æœ€ç»ˆå‡†ç¡®ç‡è¾¾åˆ°äº†13.17%ï¼Œè¿œé«˜äºæ ‡å‡†ç»éªŒé‡æ”¾(Standard Experience Replay)çš„7.40%ã€‚åˆ†æè¿›ä¸€æ­¥è¯æ˜ï¼Œè¿™ç§æ€§èƒ½æå‡ä¸»è¦æºäºæ¢é’ˆæœºåˆ¶å¯¹è¡¨å¾çš„ç¨³å®šä½œç”¨ï¼Œè€Œéå•çº¯ä¾èµ–é‡æ”¾æ•°æ®é‡çš„å¢åŠ ã€‚ç ”ç©¶ç»“è®ºå¼ºè°ƒäº†åœ¨æŒç»­å­¦ä¹ ç³»ç»Ÿä¸­æ•´åˆä¸»åŠ¨è®°å¿†æ£€ç´¢æœºåˆ¶çš„é‡è¦æ€§ï¼Œä¸ºæ„å»ºæ›´é«˜æ•ˆã€ç¨³å¥çš„å­¦ä¹ æ¨¡å‹æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Improved Grammar, consistency and flow. Some sections like the Discussion Section have been rewritten for improvement. Figures and Tables have improved formatting, while the algorithm pseudocode is now consistent with the experiments and less ambiguous",
      "pdf_url": "https://arxiv.org/pdf/2507.21109v2",
      "published_date": "2025-07-10 08:35:30 UTC",
      "updated_date": "2025-09-15 14:56:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:36.468931+00:00"
    },
    {
      "arxiv_id": "2507.07539v1",
      "title": "CEA-LIST at CheckThat! 2025: Evaluating LLMs as Detectors of Bias and Opinion in Text",
      "title_zh": "CEA-LIST åœ¨ CheckThat! 2025ï¼šè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºæ–‡æœ¬åè§ä¸è§‚ç‚¹çš„æ£€æµ‹å™¨",
      "authors": [
        "Akram Elbouanani",
        "Evan Dufraisse",
        "Aboubacar Tuo",
        "Adrian Popescu"
      ],
      "abstract": "This paper presents a competitive approach to multilingual subjectivity detection using large language models (LLMs) with few-shot prompting. We participated in Task 1: Subjectivity of the CheckThat! 2025 evaluation campaign. We show that LLMs, when paired with carefully designed prompts, can match or outperform fine-tuned smaller language models (SLMs), particularly in noisy or low-quality data settings. Despite experimenting with advanced prompt engineering techniques, such as debating LLMs and various example selection strategies, we found limited benefit beyond well-crafted standard few-shot prompts. Our system achieved top rankings across multiple languages in the CheckThat! 2025 subjectivity detection task, including first place in Arabic and Polish, and top-four finishes in Italian, English, German, and multilingual tracks. Notably, our method proved especially robust on the Arabic dataset, likely due to its resilience to annotation inconsistencies. These findings highlight the effectiveness and adaptability of LLM-based few-shot learning for multilingual sentiment tasks, offering a strong alternative to traditional fine-tuning, particularly when labeled data is scarce or inconsistent.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† CEA-LIST å‚åŠ  CheckThat! 2025 è¯„æµ‹ä»»åŠ¡çš„æ–¹æ³•ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹æ£€æµ‹æ–‡æœ¬ä¸»è§‚æ€§å’Œåè§çš„èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿä¸»è¦é‡‡ç”¨äº†å°‘æ ·æœ¬æç¤º (few-shot prompting) æŠ€æœ¯ï¼Œå¹¶å¯¹æ¯”äº† LLMs ä¸å¾®è°ƒåçš„å°å‹è¯­è¨€æ¨¡å‹ (SLMs) åœ¨å¤„ç†å™ªå£°æˆ–ä½è´¨é‡æ•°æ®æ—¶çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡å°è¯•äº† LLMs è¾©è®º (debating) ç­‰é«˜çº§æç¤ºå·¥ç¨‹ï¼Œä½†ç²¾å¿ƒè®¾è®¡çš„æ ‡å‡† few-shot æç¤ºä¾ç„¶è¡¨ç°æœ€ä¼˜ï¼Œåœ¨å¤šä¸ªè¯­ç§ä¸­å–å¾—äº†é¢†å…ˆæ’åã€‚è¯¥ç³»ç»Ÿåœ¨é˜¿æ‹‰ä¼¯è¯­å’Œæ³¢å…°è¯­ä»»åŠ¡ä¸­è£è·ç¬¬ä¸€ï¼Œå¹¶åœ¨è‹±è¯­ã€æ„å¤§åˆ©è¯­ã€å¾·è¯­åŠå¤šè¯­è¨€èµ›é“è¿›å…¥å‰å››åã€‚ç‰¹åˆ«æ˜¯åœ¨é˜¿æ‹‰ä¼¯è¯­æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ ‡æ³¨ä¸ä¸€è‡´å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†åŸºäº LLM çš„å°‘æ ·æœ¬å­¦ä¹ åœ¨å¤šè¯­è¨€æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§å’Œé€‚åº”æ€§ï¼Œä¸ºæ ‡æ³¨æ•°æ®ç¨€ç¼ºæˆ–è´¨é‡ä¸é½çš„åœºæ™¯æä¾›äº†å¼ºæœ‰åŠ›çš„å¾®è°ƒæ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Notebook for the CheckThat! Lab at CLEF 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07539v1",
      "published_date": "2025-07-10 08:35:05 UTC",
      "updated_date": "2025-07-10 08:35:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:51.398314+00:00"
    },
    {
      "arxiv_id": "2507.07532v2",
      "title": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings",
      "title_zh": "Neural Concept Verifierï¼šé€šè¿‡æ¦‚å¿µç¼–ç æ‰©å±•è¯æ˜è€…-éªŒè¯è€…åšå¼ˆ",
      "authors": [
        "Berkant Turan",
        "Suhrab Asadulla",
        "David Steinmann",
        "Wolfgang Stammer",
        "Sebastian Pokutta"
      ],
      "abstract": "While Prover-Verifier Games (PVGs) offer a promising path toward verifiability in nonlinear classification models, they have not yet been applied to complex inputs such as high-dimensional images. Conversely, Concept Bottleneck Models (CBMs) effectively translate such data into interpretable concepts but are limited by their reliance on low-capacity linear predictors. In this work, we introduce the Neural Concept Verifier (NCV), a unified framework combining PVGs with concept encodings for interpretable, nonlinear classification in high-dimensional settings. NCV achieves this by utilizing recent minimally supervised concept discovery models to extract structured concept encodings from raw inputs. A prover then selects a subset of these encodings, which a verifier -- implemented as a nonlinear predictor -- uses exclusively for decision-making. Our evaluations show that NCV outperforms CBM and pixel-based PVG classifier baselines on high-dimensional, logically complex datasets and also helps mitigate shortcut behavior. Overall, we demonstrate NCV as a promising step toward performative, verifiable AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Neural Concept Verifier (NCV)ï¼Œè¿™æ˜¯ä¸€ä¸ªå°†è¯æ˜è€…-éªŒè¯è€…åšå¼ˆ (Prover-Verifier Games, PVGs) ä¸æ¦‚å¿µç¼–ç  (Concept Encodings) ç›¸ç»“åˆçš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é«˜ç»´ç¯å¢ƒä¸‹çš„å¯è§£é‡Šéçº¿æ€§åˆ†ç±»ã€‚é’ˆå¯¹PVGséš¾ä»¥åº”ç”¨äºé«˜ç»´å›¾åƒä»¥åŠæ¦‚å¿µç“¶é¢ˆæ¨¡å‹ (Concept Bottleneck Models, CBMs) å—é™äºä½å®¹é‡çº¿æ€§é¢„æµ‹å™¨çš„é—®é¢˜ï¼ŒNCVåˆ©ç”¨æœ€æ–°çš„å¾®ç›‘ç£æ¦‚å¿µå‘ç°æ¨¡å‹ä»åŸå§‹è¾“å…¥ä¸­æå–ç»“æ„åŒ–æ¦‚å¿µç¼–ç ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œè¯æ˜è€…è´Ÿè´£é€‰æ‹©è¿™äº›ç¼–ç çš„å­é›†ï¼Œè€Œä½œä¸ºéçº¿æ€§é¢„æµ‹å™¨çš„éªŒè¯è€…åˆ™ä»…ä¾æ®è¿™äº›é€‰å®šçš„ç¼–ç è¿›è¡Œå†³ç­–ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒNCVåœ¨é€»è¾‘å¤æ‚çš„é«˜ç»´æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºCBMå’ŒåŸºäºåƒç´ çš„PVGåŸºçº¿æ¨¡å‹ï¼Œå¹¶èƒ½æœ‰æ•ˆç¼“è§£æ·å¾„è¡Œä¸º (shortcut behavior)ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶å±•ç¤ºäº†NCVä½œä¸ºå®ç°é«˜æ€§èƒ½ã€å¯éªŒè¯äººå·¥æ™ºèƒ½ (verifiable AI) çš„ä¸€ç§æå…·å‰æ™¯çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures, 8 tables, revised references",
      "pdf_url": "https://arxiv.org/pdf/2507.07532v2",
      "published_date": "2025-07-10 08:28:46 UTC",
      "updated_date": "2025-07-11 10:29:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:58.850287+00:00"
    },
    {
      "arxiv_id": "2507.08053v2",
      "title": "Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently",
      "title_zh": "æ ‘çŠ¶ç»“æ„ Parzen ä¼°è®¡å™¨å¯æ›´é«˜æ•ˆåœ°æ±‚è§£é»‘ç›’ç»„åˆä¼˜åŒ–",
      "authors": [
        "Kenshin Abe",
        "Yunzhuo Wang",
        "Shuhei Watanabe"
      ],
      "abstract": "Tree-structured Parzen estimator (TPE) is a versatile hyperparameter optimization (HPO) method supported by popular HPO tools. Since these HPO tools have been developed in line with the trend of deep learning (DL), the problem setups often used in the DL domain have been discussed for TPE such as multi-objective optimization and multi-fidelity optimization. However, the practical applications of HPO are not limited to DL, and black-box combinatorial optimization is actively utilized in some domains, e.g., chemistry and biology. As combinatorial optimization has been an untouched, yet very important, topic in TPE, we propose an efficient combinatorial optimization algorithm for TPE. In this paper, we first generalize the categorical kernel with the numerical kernel in TPE, enabling us to introduce a distance structure to the categorical kernel. Then we discuss modifications for the newly developed kernel to handle a large combinatorial search space. These modifications reduce the time complexity of the kernel calculation with respect to the size of a combinatorial search space. In the experiments using synthetic problems, we verified that our proposed method identifies better solutions with fewer evaluations than the original TPE. Our algorithm is available in Optuna, an open-source framework for HPO.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Tree-structured Parzen estimator (TPE) åœ¨é»‘ç›’ç»„åˆä¼˜åŒ– (Black-box Combinatorial Optimization) é¢†åŸŸåº”ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ›´é«˜æ•ˆçš„ç»„åˆä¼˜åŒ–ç®—æ³•ã€‚ä½œè€…é€šè¿‡å°† TPE ä¸­çš„åˆ†ç±»æ ¸ (categorical kernel) ä¸æ•°å€¼æ ¸ (numerical kernel) è¿›è¡Œæ³›åŒ–ï¼ŒæˆåŠŸä¸ºåˆ†ç±»æ ¸å¼•å…¥äº†è·ç¦»ç»“æ„ï¼Œä»è€Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å…·æœ‰ç»“æ„çš„æœç´¢ç©ºé—´ã€‚é’ˆå¯¹å¤§è§„æ¨¡ç»„åˆæœç´¢ç©ºé—´çš„æŒ‘æˆ˜ï¼Œç ”ç©¶è¿›ä¸€æ­¥æ”¹è¿›äº†æ ¸å‡½æ•°è®¾è®¡ï¼Œæ˜¾è‘—é™ä½äº†ä¸æœç´¢ç©ºé—´è§„æ¨¡ç›¸å…³çš„æ ¸è®¡ç®—æ—¶é—´å¤æ‚åº¦ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆé—®é¢˜ä¸Šæ¯”åŸå§‹ TPE æ•ˆç‡æ›´é«˜ï¼Œèƒ½å¤Ÿä»¥æ›´å°‘çš„è¯„ä¼°æ¬¡æ•°è¯†åˆ«å‡ºæ›´ä¼˜è§£ã€‚ç›®å‰ï¼Œè¯¥ç®—æ³•å·²é›†æˆè‡³å¼€æºè¶…å‚æ•°ä¼˜åŒ–æ¡†æ¶ Optuna ä¸­ï¼Œä¸ºåŒ–å­¦ã€ç”Ÿç‰©ç­‰é¢†åŸŸçš„å®é™…åº”ç”¨æä¾›äº†æ›´å¼ºå¤§çš„ä¼˜åŒ–å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to AutoML Conference",
      "pdf_url": "https://arxiv.org/pdf/2507.08053v2",
      "published_date": "2025-07-10 08:26:49 UTC",
      "updated_date": "2025-07-15 08:40:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:56:55.857164+00:00"
    },
    {
      "arxiv_id": "2507.08052v1",
      "title": "Lightweight Cloud Masking Models for On-Board Inference in Hyperspectral Imaging",
      "title_zh": "é«˜å…‰è°±æˆåƒä¸­é¢å‘æ˜Ÿè½½æ¨ç†çš„è½»é‡çº§äº‘æ©è†œæ¨¡å‹",
      "authors": [
        "Mazen Ali",
        "AntÃ³nio Pereira",
        "Fabio Gentile",
        "Aser Cortines",
        "Sam Mugel",
        "RomÃ¡n OrÃºs",
        "Stelios P. Neophytides",
        "Michalis Mavrovouniotis"
      ],
      "abstract": "Cloud and cloud shadow masking is a crucial preprocessing step in hyperspectral satellite imaging, enabling the extraction of high-quality, analysis-ready data. This study evaluates various machine learning approaches, including gradient boosting methods such as XGBoost and LightGBM as well as convolutional neural networks (CNNs). All boosting and CNN models achieved accuracies exceeding 93%. Among the investigated models, the CNN with feature reduction emerged as the most efficient, offering a balance of high accuracy, low storage requirements, and rapid inference times on both CPUs and GPUs. Variations of this version, with only up to 597 trainable parameters, demonstrated the best trade-off in terms of deployment feasibility, accuracy, and computational efficiency. These results demonstrate the potential of lightweight artificial intelligence (AI) models for real-time hyperspectral image processing, supporting the development of on-board satellite AI systems for space-based applications.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤šç§ç”¨äºé«˜å…‰è°±å«æ˜Ÿå½±åƒ(Hyperspectral Imaging)äº‘åŠäº‘é˜´å½±æ©è†œçš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨ä¸ºåç»­æ•°æ®åˆ†ææä¾›é«˜è´¨é‡æ”¯æŒã€‚ç ”ç©¶å¯¹æ¯”äº†åŒ…æ‹¬ XGBoostã€LightGBM åœ¨å†…çš„æ¢¯åº¦æå‡ç®—æ³•ä»¥åŠå·ç§¯ç¥ç»ç½‘ç»œ(CNN)ï¼Œç»“æœæ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹å‡†ç¡®ç‡å‡è¶…è¿‡ 93%ã€‚å…¶ä¸­ï¼Œç»è¿‡ç‰¹å¾æ¶ˆå‡çš„ CNN æ¨¡å‹åœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå…·å¤‡æä½çš„å­˜å‚¨éœ€æ±‚å’Œåœ¨ CPU åŠ GPU ä¸Šçš„å¿«é€Ÿæ¨ç†èƒ½åŠ›ï¼Œè¡¨ç°å‡ºæœ€ä½³çš„ç»¼åˆæ•ˆç‡ã€‚æœ€å…·ä»£è¡¨æ€§çš„è½»é‡çº§ç‰ˆæœ¬ä»…åŒ…å« 597 ä¸ªå¯è®­ç»ƒå‚æ•°ï¼Œåœ¨éƒ¨ç½²å¯è¡Œæ€§ä¸è®¡ç®—æ€§èƒ½ä¹‹é—´å®ç°äº†å“è¶Šå¹³è¡¡ã€‚è¯¥ç ”ç©¶ç»“æœè¯æ˜äº†è½»é‡çº§äººå·¥æ™ºèƒ½(AI)æ¨¡å‹åœ¨å®æ—¶å¤„ç†ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºå¼€å‘ç”¨äºç©ºé—´åº”ç”¨çš„å¯åœ¨è½¨(On-Board)è¿è¡Œçš„å«æ˜Ÿ AI ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08052v1",
      "published_date": "2025-07-10 08:10:11 UTC",
      "updated_date": "2025-07-10 08:10:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:58:54.789514+00:00"
    },
    {
      "arxiv_id": "2507.08879v1",
      "title": "A Multi-Level Strategy for Deepfake Content Moderation under EU Regulation",
      "title_zh": "æ¬§ç›Ÿè§„åˆ¶ä¸‹çš„æ·±åº¦ä¼ªé€ å†…å®¹å®¡æ ¸å¤šå±‚çº§ç­–ç•¥",
      "authors": [
        "Max-Paul FÃ¶rster",
        "Luca Deck",
        "Raimund Weidlich",
        "Niklas KÃ¼hl"
      ],
      "abstract": "The growing availability and use of deepfake technologies increases risks for democratic societies, e.g., for political communication on online platforms. The EU has responded with transparency obligations for providers and deployers of Artificial Intelligence (AI) systems and online platforms. This includes marking deepfakes during generation and labeling deepfakes when they are shared. However, the lack of industry and enforcement standards poses an ongoing challenge. Through a multivocal literature review, we summarize methods for marking, detecting, and labeling deepfakes and assess their effectiveness under EU regulation. Our results indicate that individual methods fail to meet regulatory and practical requirements. Therefore, we propose a multi-level strategy combining the strengths of existing methods. To account for the masses of content on online platforms, our multi-level strategy provides scalability and practicality via a simple scoring mechanism. At the same time, it is agnostic to types of deepfake technology and allows for context-specific risk weighting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ deepfake æŠ€æœ¯å¯¹æ°‘ä¸»ç¤¾ä¼šï¼ˆå¦‚åœ¨çº¿å¹³å°æ”¿æ²»ä¼ æ’­ï¼‰å¸¦æ¥çš„æ—¥ç›Šä¸¥å³»çš„é£é™©ï¼Œæ¢è®¨äº†æ¬§ç›Ÿ (EU) åœ¨äººå·¥æ™ºèƒ½é€æ˜åº¦æ–¹é¢çš„æ³•è§„è¦æ±‚åŠæ‰§è¡ŒæŒ‘æˆ˜ã€‚ä½œè€…é€šè¿‡å¤šç»´åº¦æ–‡çŒ®ç»¼è¿° (multivocal literature review)ï¼Œç³»ç»Ÿæ€»ç»“äº†ç°æœ‰çš„æ ‡è®° (marking)ã€æ£€æµ‹ (detecting) å’Œæ ‡æ³¨ (labeling) æ–¹æ³•ï¼Œå¹¶è¯„ä¼°äº†å®ƒä»¬åœ¨æ¬§ç›Ÿç›‘ç®¡ç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå•ä¸€çš„æŠ€æœ¯æ‰‹æ®µéš¾ä»¥åŒæ—¶æ»¡è¶³æ³•è§„è¦æ±‚å’Œå®é™…åº”ç”¨åœºæ™¯ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šå±‚æ¬¡ç­–ç•¥ (multi-level strategy)ï¼Œé€šè¿‡æ•´åˆç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿å¹¶å¼•å…¥ç®€å•çš„è¯„åˆ†æœºåˆ¶ (scoring mechanism)ï¼Œæå‡äº†åœ¨å¤§è§„æ¨¡åœ¨çº¿å¹³å°ä¸Šçš„å¯æ‰©å±•æ€§å’Œå®ç”¨æ€§ã€‚è¯¥ç­–ç•¥å¯¹ä¸åŒç±»å‹çš„ deepfake æŠ€æœ¯å…·æœ‰é€šç”¨æ€§ï¼Œå¹¶å…è®¸æ ¹æ®å…·ä½“è¯­å¢ƒè¿›è¡Œé£é™©åŠ æƒï¼Œä¸ºæ·±ä¼ªå†…å®¹å®¡æ ¸æä¾›äº†ç¬¦åˆæ³•è§„è¦æ±‚çš„å®è·µæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08879v1",
      "published_date": "2025-07-10 08:08:42 UTC",
      "updated_date": "2025-07-10 08:08:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:57:00.041873+00:00"
    },
    {
      "arxiv_id": "2507.07509v1",
      "title": "Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System",
      "title_zh": "é¢å‘çœŸå®åœºæ™¯çš„ä¸­æ–‡å¿ƒç†æ”¯æŒå¯¹è¯ï¼šCPsDD æ•°æ®é›†ä¸ååŒæ¼”åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Yuanchen Shi",
        "Longyin Zhang",
        "Fang Kong"
      ],
      "abstract": "The growing need for psychological support due to increasing pressures has exposed the scarcity of relevant datasets, particularly in non-English languages. To address this, we propose a framework that leverages limited real-world data and expert knowledge to fine-tune two large language models: Dialog Generator and Dialog Modifier. The Generator creates large-scale psychological counseling dialogues based on predefined paths, which guide system response strategies and user interactions, forming the basis for effective support. The Modifier refines these dialogues to align with real-world data quality. Through both automated and manual review, we construct the Chinese Psychological support Dialogue Dataset (CPsDD), containing 68K dialogues across 13 groups, 16 psychological problems, 13 causes, and 12 support focuses. Additionally, we introduce the Comprehensive Agent Dialogue Support System (CADSS), where a Profiler analyzes user characteristics, a Summarizer condenses dialogue history, a Planner selects strategies, and a Supporter generates empathetic responses. The experimental results of the Strategy Prediction and Emotional Support Conversation (ESC) tasks demonstrate that CADSS achieves state-of-the-art performance on both CPsDD and ESConv datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¿ƒç†æ”¯æŒéœ€æ±‚æ—¥ç›Šå¢é•¿ä½†é«˜è´¨é‡ä¸­æ–‡æ•°æ®é›†ç¨€ç¼ºçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªç»“åˆæœ‰é™çœŸå®æ•°æ®å’Œä¸“å®¶çŸ¥è¯†çš„å¯¹è¯ç”Ÿæˆä¸ä¿®æ­£æ¡†æ¶ã€‚é€šè¿‡å¾®è°ƒ Dialog Generator å’Œ Dialog Modifier ä¸¤ä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼Œç ”ç©¶è€…æ„å»ºäº†åŒ…å« 6.8 ä¸‡æ¡å¯¹è¯ã€æ¶µç›– 16 ç±»å¿ƒç†é—®é¢˜å’Œ 12 ç§æ”¯æŒé‡ç‚¹çš„ä¸­æ–‡å¿ƒç†æ”¯æŒå¯¹è¯æ•°æ®é›† CPsDDã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†åä¸º CADSS çš„ç»¼åˆæ™ºèƒ½ä½“å¯¹è¯æ”¯æŒç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿé€šè¿‡ Profilerã€Summarizerã€Planner å’Œ Supporter çš„å¤šæ™ºèƒ½ä½“åä½œç”Ÿæˆå…·æœ‰å…±æƒ…åŠ›çš„å“åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCADSS åœ¨ç­–ç•¥é¢„æµ‹(Strategy Prediction)å’Œæƒ…æ„Ÿæ”¯æŒå¯¹è¯(ESC)ä»»åŠ¡ä¸­ï¼Œäº CPsDD å’Œ ESConv æ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº† SOTA æ€§èƒ½ã€‚è¯¥é¡¹å·¥ä½œä¸ºçœŸå®ä¸–ç•Œä¸­çš„ä¸­æ–‡å¿ƒç†å¹²é¢„æä¾›äº†æœ‰åŠ›çš„æ•°æ®æ”¯æŒå’Œç³»ç»Ÿæ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "10pages,8 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07509v1",
      "published_date": "2025-07-10 07:56:35 UTC",
      "updated_date": "2025-07-10 07:56:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:57:06.406739+00:00"
    },
    {
      "arxiv_id": "2507.07505v3",
      "title": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models",
      "title_zh": "å¹»è§‰ç«™ç‚¹ï¼šè®ºåŸºäº Transformer çš„è¯­è¨€æ¨¡å‹çš„ä¸€äº›åŸºæœ¬å±€é™æ€§",
      "authors": [
        "Varin Sikka",
        "Vishal Sikka"
      ],
      "abstract": "In this paper we explore hallucinations and related capability limitations in LLMs and LLM-based agents from the perspective of computational complexity. We show that beyond a certain complexity, LLMs are incapable of carrying out computational and agentic tasks or verifying their accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»è®¡ç®—å¤æ‚åº¦(Computational Complexity)çš„è§’åº¦æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åŠå…¶æ™ºèƒ½ä½“(LLM-based Agents)ä¸­å­˜åœ¨çš„å¹»è§‰(Hallucination)åŠç›¸å…³çš„èƒ½åŠ›å±€é™ã€‚é€šè¿‡ç†è®ºåˆ†æï¼Œä½œè€…è¯æ˜äº†Transformeræ¶æ„åœ¨å¤„ç†è¶…å‡ºç‰¹å®šå¤æ‚åº¦çš„ä»»åŠ¡æ—¶å­˜åœ¨æœ¬è´¨æ€§çš„ç“¶é¢ˆã€‚ç ”ç©¶å‘ç°ï¼Œå½“ä»»åŠ¡éš¾åº¦è¶…è¿‡ä¸€å®šé˜ˆå€¼åï¼ŒLLMsä¸ä»…æ— æ³•å‡†ç¡®æ‰§è¡Œè®¡ç®—å’Œæ™ºèƒ½ä½“ç›¸å…³ä»»åŠ¡ï¼Œç”šè‡³ä¹Ÿæ— æ³•éªŒè¯å…¶è¾“å‡ºç»“æœçš„å‡†ç¡®æ€§ã€‚è¿™ä¸€ç»“è®ºæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨å¤„ç†é«˜å¤æ‚åº¦é€»è¾‘æ¨ç†æ—¶çš„åŸºç¡€æ€§çº¦æŸï¼Œä¸ºç†è§£å¹»è§‰ç°è±¡çš„æˆå› ä»¥åŠè¯„ä¼°ç°æœ‰æ¨¡å‹çš„èƒ½åŠ›è¾¹ç•Œæä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages; to be submitted to AAAI-26 after reviews",
      "pdf_url": "https://arxiv.org/pdf/2507.07505v3",
      "published_date": "2025-07-10 07:50:52 UTC",
      "updated_date": "2025-07-15 15:42:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:57:05.198493+00:00"
    },
    {
      "arxiv_id": "2507.08050v1",
      "title": "An Enhanced Privacy-preserving Federated Few-shot Learning Framework for Respiratory Disease Diagnosis",
      "title_zh": "ä¸€ç§é¢å‘å‘¼å¸ç³»ç»Ÿç–¾ç—…è¯Šæ–­çš„å¢å¼ºå‹éšç§ä¿æŠ¤è”é‚¦å°æ ·æœ¬å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Ming Wang",
        "Zhaoyang Duan",
        "Dong Xue",
        "Fangzhou Liu",
        "Zhongheng Zhang"
      ],
      "abstract": "The labor-intensive nature of medical data annotation presents a significant challenge for respiratory disease diagnosis, resulting in a scarcity of high-quality labeled datasets in resource-constrained settings. Moreover, patient privacy concerns complicate the direct sharing of local medical data across institutions, and existing centralized data-driven approaches, which rely on amounts of available data, often compromise data privacy. This study proposes a federated few-shot learning framework with privacy-preserving mechanisms to address the issues of limited labeled data and privacy protection in diagnosing respiratory diseases. In particular, a meta-stochastic gradient descent algorithm is proposed to mitigate the overfitting problem that arises from insufficient data when employing traditional gradient descent methods for neural network training. Furthermore, to ensure data privacy against gradient leakage, differential privacy noise from a standard Gaussian distribution is integrated into the gradients during the training of private models with local data, thereby preventing the reconstruction of medical images. Given the impracticality of centralizing respiratory disease data dispersed across various medical institutions, a weighted average algorithm is employed to aggregate local diagnostic models from different clients, enhancing the adaptability of a model across diverse scenarios. Experimental results show that the proposed method yields compelling results with the implementation of differential privacy, while effectively diagnosing respiratory diseases using data from different structures, categories, and distributions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å‘¼å¸ç³»ç»Ÿç–¾ç—…è¯Šæ–­ä¸­é«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºåŠæ‚£è€…éšç§ä¿æŠ¤çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§å¢å¼ºå‹éšç§ä¿æŠ¤è”é‚¦å°æ ·æœ¬å­¦ä¹ æ¡†æ¶(Federated Few-shot Learning)ã€‚ä¸ºäº†è§£å†³ä¼ ç»Ÿæ¢¯åº¦ä¸‹é™åœ¨å°æ ·æœ¬æ•°æ®ä¸‹æ˜“å‡ºç°çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†å…ƒéšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•(Meta-SGD)ï¼Œæœ‰æ•ˆæå‡äº†ç¥ç»ç½‘ç»œåœ¨æ•°æ®é‡ä¸è¶³æ—¶çš„è®­ç»ƒæ•ˆæœã€‚é’ˆå¯¹è”é‚¦å­¦ä¹ ä¸­çš„æ¢¯åº¦æ³„éœ²é£é™©ï¼Œç ”ç©¶åœ¨æœ¬åœ°æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å°†æ ‡å‡†é«˜æ–¯åˆ†å¸ƒçš„å·®åˆ†éšç§(Differential Privacy)å™ªå£°æ•´åˆåˆ°æ¢¯åº¦ä¸­ï¼Œä»è€Œé˜²æ­¢åŸå§‹åŒ»å­¦å½±åƒè¢«åå‘é‡æ„ã€‚è€ƒè™‘åˆ°ä¸åŒåŒ»ç–—æœºæ„é—´æ•°æ®çš„åˆ†æ•£æ€§ï¼Œè¯¥æ–¹æ¡ˆé‡‡ç”¨åŠ æƒå¹³å‡ç®—æ³•(Weighted Average Algorithm)èšåˆæ¥è‡ªä¸åŒå®¢æˆ·ç«¯çš„æœ¬åœ°è¯Šæ–­æ¨¡å‹ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹åœ¨å¤šæ ·åŒ–åœºæ™¯ä¸‹çš„é€‚åº”æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®æ–½å·®åˆ†éšç§ä¿æŠ¤çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯Šæ–­å…·æœ‰ä¸åŒç»“æ„ã€ç±»åˆ«å’Œåˆ†å¸ƒçš„å‘¼å¸ç³»ç»Ÿç–¾ç—…æ•°æ®ï¼Œå®ç°äº†éšç§ä¿æŠ¤ä¸è¯Šæ–­æ€§èƒ½çš„å¹³è¡¡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08050v1",
      "published_date": "2025-07-10 07:47:58 UTC",
      "updated_date": "2025-07-10 07:47:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:57:10.195052+00:00"
    },
    {
      "arxiv_id": "2507.07495v1",
      "title": "PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving",
      "title_zh": "PLAN-TUNINGï¼šé€šè¿‡åè®­ç»ƒä½¿è¯­è¨€æ¨¡å‹å­¦ä¹ è§£å†³å¤æ‚é—®é¢˜çš„åˆ†æ­¥è§„åˆ’",
      "authors": [
        "Mihir Parmar",
        "Palash Goyal",
        "Xin Liu",
        "Yiwen Song",
        "Mingyang Ling",
        "Chitta Baral",
        "Hamid Palangi",
        "Tomas Pfister"
      ],
      "abstract": "Recently, decomposing complex problems into simple subtasks--a crucial part of human-like natural planning--to solve the given problem has significantly boosted the performance of large language models (LLMs). However, leveraging such planning structures during post-training to boost the performance of smaller open-source LLMs remains underexplored. Motivated by this, we introduce PLAN-TUNING, a unified post-training framework that (i) distills synthetic task decompositions (termed \"planning trajectories\") from large-scale LLMs and (ii) fine-tunes smaller models via supervised and reinforcement-learning objectives designed to mimic these planning processes to improve complex reasoning. On GSM8k and the MATH benchmarks, plan-tuned models outperform strong baselines by an average $\\sim7\\%$. Furthermore, plan-tuned models show better generalization capabilities on out-of-domain datasets, with average $\\sim10\\%$ and $\\sim12\\%$ performance improvements on OlympiadBench and AIME 2024, respectively. Our detailed analysis demonstrates how planning trajectories improves complex reasoning capabilities, showing that PLAN-TUNING is an effective strategy for improving task-specific performance of smaller LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PLAN-TUNINGï¼Œä¸€ä¸ªç»Ÿä¸€çš„åè®­ç»ƒ (post-training) æ¡†æ¶ï¼Œæ—¨åœ¨æå‡è¾ƒå°è§„æ¨¡å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤æ‚é—®é¢˜è§£å†³ä¸­çš„åˆ†æ­¥è§„åˆ’èƒ½åŠ›ã€‚è¯¥æ¡†æ¶é€šè¿‡ä»å¤§è§„æ¨¡ LLMs ä¸­è’¸é¦å‡ºåˆæˆçš„ä»»åŠ¡åˆ†è§£è¿‡ç¨‹ï¼ˆç§°ä¸ºè§„åˆ’è½¨è¿¹ï¼Œplanning trajectoriesï¼‰ï¼Œå¹¶ç»“åˆç›‘ç£å­¦ä¹ ä¸å¼ºåŒ–å­¦ä¹  (reinforcement learning) ç›®æ ‡æ¥å¼•å¯¼å°æ¨¡å‹æ¨¡ä»¿è¿™äº›è§„åˆ’è¡Œä¸ºï¼Œä»è€Œå¢å¼ºå…¶å¤æ‚æ¨ç†èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œç»è¿‡ PLAN-TUNING çš„æ¨¡å‹åœ¨ GSM8k å’Œ MATH åŸºå‡†æµ‹è¯•ä¸­å¹³å‡ä¼˜äºå¼ºåŸºçº¿æ¨¡å‹çº¦ 7%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨ OlympiadBench å’Œ AIME 2024 ç­‰é¢†åŸŸå¤–æ•°æ®é›†ä¸Šåˆ†åˆ«å–å¾—äº†çº¦ 10% å’Œ 12% çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶å‡ºè‰²çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¦ç»†åˆ†æè¯å®ï¼ŒPLAN-TUNING æ˜¯æå‡è¾ƒå°è§„æ¨¡ LLMs åœ¨ç‰¹å®šä»»åŠ¡ä¸­å¤æ‚æ¨ç†æ€§èƒ½çš„ä¸€ç§æœ‰æ•ˆç­–ç•¥ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 Pages",
      "pdf_url": "https://arxiv.org/pdf/2507.07495v1",
      "published_date": "2025-07-10 07:30:44 UTC",
      "updated_date": "2025-07-10 07:30:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:58:15.762908+00:00"
    },
    {
      "arxiv_id": "2507.07485v2",
      "title": "Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning",
      "title_zh": "è§£å†³ Token ç©ºé—´æ¢¯åº¦å†²çªï¼šé¢å‘ Transformer å¤šä»»åŠ¡å­¦ä¹ çš„ Token ç©ºé—´è°ƒæ§",
      "authors": [
        "Wooseong Jeong",
        "Kuk-Jin Yoon"
      ],
      "abstract": "Multi-Task Learning (MTL) enables multiple tasks to be learned within a shared network, but differences in objectives across tasks can cause negative transfer, where the learning of one task degrades another task's performance. While pre-trained transformers significantly improve MTL performance, their fixed network capacity and rigid structure limit adaptability. Previous dynamic network architectures attempt to address this but are inefficient as they directly convert shared parameters into task-specific ones. We propose Dynamic Token Modulation and Expansion (DTME-MTL), a framework applicable to any transformer-based MTL architecture. DTME-MTL enhances adaptability and reduces overfitting by identifying gradient conflicts in token space and applying adaptive solutions based on conflict type. Unlike prior methods that mitigate negative transfer by duplicating network parameters, DTME-MTL operates entirely in token space, enabling efficient adaptation without excessive parameter growth. Extensive experiments demonstrate that DTME-MTL consistently improves multi-task performance with minimal computational overhead, offering a scalable and effective solution for enhancing transformer-based MTL models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šä»»åŠ¡å­¦ä¹ (Multi-Task Learning, MTL)ä¸­ç”±äºä»»åŠ¡ç›®æ ‡å·®å¼‚å¯¼è‡´çš„è´Ÿè¿ç§»(negative transfer)é—®é¢˜ï¼Œæå‡ºäº†åä¸ºDTME-MTL (Dynamic Token Modulation and Expansion) çš„åˆ›æ–°æ¡†æ¶ã€‚é’ˆå¯¹Transformeræ¨¡å‹å›ºå®šå®¹é‡å¯¼è‡´çš„é€‚åº”æ€§å—é™ä»¥åŠç°æœ‰åŠ¨æ€æ¶æ„å‚æ•°è½¬æ¢æ•ˆç‡ä½çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶é€šè¿‡åœ¨Token Spaceä¸­è¯†åˆ«æ¢¯åº¦å†²çªå¹¶æ ¹æ®å†²çªç±»å‹å®æ–½è‡ªé€‚åº”å¤„ç†æ–¹æ¡ˆï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„çµæ´»æ€§å¹¶ç¼“è§£äº†è¿‡æ‹Ÿåˆã€‚DTME-MTLçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å®Œå…¨åœ¨Token Spaceä¸­è¿›è¡Œæ“ä½œï¼Œè€Œéé€šè¿‡å¤åˆ¶ç½‘ç»œå‚æ•°æ¥å‡å°‘å¹²æ‰°ï¼Œä»è€Œåœ¨é¿å…å‚æ•°é‡è¿‡åº¦å¢é•¿çš„åŒæ—¶å®ç°äº†é«˜æ•ˆçš„ä»»åŠ¡é€‚é…ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒDTME-MTLèƒ½å¤Ÿä»¥æå°çš„è®¡ç®—å¼€é”€æŒç»­æå‡å¤šä»»åŠ¡æ€§èƒ½ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ–åŸºäºTransformerçš„MTLæ¨¡å‹æä¾›äº†ä¸€ç§å…·å¤‡é«˜æ‰©å±•æ€§å’Œæœ‰æ•ˆæ€§çš„Tokenç©ºé—´æ“ä½œæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07485v2",
      "published_date": "2025-07-10 07:13:22 UTC",
      "updated_date": "2025-07-21 06:05:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:58:19.650719+00:00"
    },
    {
      "arxiv_id": "2507.07484v1",
      "title": "Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models",
      "title_zh": "æœºå™¨åºŸè¯ï¼šè¡¨å¾å¤§è¯­è¨€æ¨¡å‹ä¸­æ¶Œç°å‡ºçš„å¯¹çœŸç›¸çš„æ¼ è§†",
      "authors": [
        "Kaiqu Liang",
        "Haimin Hu",
        "Xuandong Zhao",
        "Dawn Song",
        "Thomas L. Griffiths",
        "Jaime FernÃ¡ndez Fisac"
      ],
      "abstract": "Bullshit, as conceptualized by philosopher Harry Frankfurt, refers to statements made without regard to their truth value. While previous work has explored large language model (LLM) hallucination and sycophancy, we propose machine bullshit as an overarching conceptual framework that can allow researchers to characterize the broader phenomenon of emergent loss of truthfulness in LLMs and shed light on its underlying mechanisms. We introduce the Bullshit Index, a novel metric quantifying LLMs' indifference to truth, and propose a complementary taxonomy analyzing four qualitative forms of bullshit: empty rhetoric, paltering, weasel words, and unverified claims. We conduct empirical evaluations on the Marketplace dataset, the Political Neutrality dataset, and our new BullshitEval benchmark (2,400 scenarios spanning 100 AI assistants) explicitly designed to evaluate machine bullshit. Our results demonstrate that model fine-tuning with reinforcement learning from human feedback (RLHF) significantly exacerbates bullshit and inference-time chain-of-thought (CoT) prompting notably amplify specific bullshit forms, particularly empty rhetoric and paltering. We also observe prevalent machine bullshit in political contexts, with weasel words as the dominant strategy. Our findings highlight systematic challenges in AI alignment and provide new insights toward more truthful LLM behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Machine Bullshit è¿™ä¸€æ¦‚å¿µæ¡†æ¶ï¼Œå€Ÿé‰´å“²å­¦å®¶ Harry Frankfurt çš„ç†è®ºï¼Œç”¨ä»¥ç•Œå®šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ™®éå­˜åœ¨çš„ç½”é¡¾äº‹å®çœŸç›¸çš„ç°è±¡ï¼Œå¹¶æ¢ç©¶å…¶èƒŒåçš„ç”Ÿæˆæœºåˆ¶ã€‚ç ”ç©¶è€…å¼•å…¥äº† Bullshit Index ä½œä¸ºè¡¡é‡æ¨¡å‹å¯¹çœŸç†æ¼ è§†ç¨‹åº¦çš„æ–°å‹é‡åŒ–æŒ‡æ ‡ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªåŒ…å« Empty rhetoricã€Palteringã€Weasel words å’Œ Unverified claims å››ç§å®šæ€§å½¢å¼çš„åˆ†ç±»ä½“ç³»ã€‚å®éªŒé€šè¿‡ Marketplaceã€Political Neutrality ä»¥åŠæ–°å¼€å‘çš„åŒ…å« 2400 ä¸ªåœºæ™¯çš„ BullshitEval åŸºå‡†æµ‹è¯•ï¼Œå¯¹ 100 ä¸ª AI åŠ©æ‰‹è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼Œåˆ©ç”¨äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰è¿›è¡Œçš„æ¨¡å‹å¾®è°ƒä¼šæ˜¾è‘—åŠ å‰§ Machine Bullshit ç°è±¡ã€‚åŒæ—¶ï¼Œæ¨ç†é˜¶æ®µçš„é“¾å¼æ€ç»´ï¼ˆChain-of-Thought, CoTï¼‰æç¤ºä¼šæ˜¾è‘—æ”¾å¤§ç‰¹å®šå½¢å¼çš„èƒ¡è¨€ä¹±è¯­ï¼Œå°¤å…¶æ˜¯ Empty rhetoric å’Œ Palteringã€‚åœ¨æ”¿æ²»è¯­å¢ƒä¸‹ï¼Œæ¨¡å‹è¡¨ç°å‡ºæ˜æ˜¾çš„èƒ¡è¨€ä¹±è¯­ç‰¹å¾ï¼Œå…¶ä¸­ Weasel words æ˜¯å…¶æœ€å¸¸ç”¨çš„ç­–ç•¥ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†äººå·¥æ™ºèƒ½å¯¹é½ï¼ˆAI Alignmentï¼‰ä¸­é¢ä¸´çš„ç³»ç»Ÿæ€§æŒ‘æˆ˜ï¼Œå¹¶ä¸ºå®ç°æ›´å…·çœŸå®æ€§çš„ LLM è¡Œä¸ºæä¾›äº†æ–°çš„è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project page, code & data: https://machine-bullshit.github.io",
      "pdf_url": "https://arxiv.org/pdf/2507.07484v1",
      "published_date": "2025-07-10 07:11:57 UTC",
      "updated_date": "2025-07-10 07:11:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:09.109931+00:00"
    },
    {
      "arxiv_id": "2507.07460v2",
      "title": "Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision",
      "title_zh": "Objectomalyï¼šå…¼é¡¾ç»“æ„ä¸€è‡´æ€§ä¸è¾¹ç•Œç²¾ç¡®æ€§çš„ç›®æ ‡æ„ŸçŸ¥ OoD åˆ†å‰²ç²¾ç»†åŒ–æ¡†æ¶",
      "authors": [
        "Jeonghoon Song",
        "Sunghun Kim",
        "Jaegyun Im",
        "Byeongjoon Noh"
      ],
      "abstract": "Out-of-Distribution (OoD) segmentation is critical for safety-sensitive applications like autonomous driving. However, existing mask-based methods often suffer from boundary imprecision, inconsistent anomaly scores within objects, and false positives from background noise. We propose \\textbf{\\textit{Objectomaly}}, an objectness-aware refinement framework that incorporates object-level priors. Objectomaly consists of three stages: (1) Coarse Anomaly Scoring (CAS) using an existing OoD backbone, (2) Objectness-Aware Score Calibration (OASC) leveraging SAM-generated instance masks for object-level score normalization, and (3) Meticulous Boundary Precision (MBP) applying Laplacian filtering and Gaussian smoothing for contour refinement. Objectomaly achieves state-of-the-art performance on key OoD segmentation benchmarks, including SMIYC AnomalyTrack/ObstacleTrack and RoadAnomaly, improving both pixel-level (AuPRC up to 96.99, FPR$_{95}$ down to 0.07) and component-level (F1$-$score up to 83.44) metrics. Ablation studies and qualitative results on real-world driving videos further validate the robustness and generalizability of our method. Code will be released upon publication.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ç­‰å®‰å…¨æ•æ„Ÿåº”ç”¨ä¸­çš„åˆ†å¸ƒå¤–(Out-of-Distribution, OoD)åˆ†å‰²é—®é¢˜ï¼Œåˆ†æäº†ç°æœ‰æ–¹æ³•åœ¨è¾¹ç•Œä¸ç²¾ç¡®ã€ç‰©ä½“å†…éƒ¨å¼‚å¸¸åˆ†æ•°ä¸ä¸€è‡´ä»¥åŠèƒŒæ™¯å™ªå£°è¯¯æŠ¥ç­‰æ–¹é¢çš„ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†Objectomalyï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆç‰©ä½“çº§å…ˆéªŒçš„ç‰©ä½“æ„ŸçŸ¥ä¼˜åŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒé˜¶æ®µï¼šé¦–å…ˆåˆ©ç”¨ç°æœ‰OoDä¸»å¹²ç½‘ç»œè¿›è¡Œç²—ç•¥å¼‚å¸¸è¯„åˆ†(CAS)ï¼Œéšååˆ©ç”¨SAMç”Ÿæˆçš„å®ä¾‹æ©ç é€šè¿‡ç‰©ä½“æ„ŸçŸ¥åˆ†æ•°æ ¡å‡†(OASC)è¿›è¡Œç‰©ä½“çº§å¾—åˆ†å½’ä¸€åŒ–ï¼Œæœ€åé€šè¿‡ç²¾ç»†è¾¹ç•Œç²¾åº¦(MBP)é˜¶æ®µåº”ç”¨æ‹‰æ™®æ‹‰æ–¯æ»¤æ³¢å’Œé«˜æ–¯å¹³æ»‘ä¼˜åŒ–è½®å»“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒObjectomalyåœ¨SMIYCå’ŒRoadAnomalyç­‰å…³é”®åˆ†å‰²åŸºå‡†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œåœ¨åƒç´ çº§æŒ‡æ ‡(AuPRCé«˜è¾¾96.99)å’Œç»„ä»¶çº§æŒ‡æ ‡(F1-scoreè¾¾83.44)ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚é€šè¿‡æ¶ˆèå®éªŒå’ŒçœŸå®ä¸–ç•Œé©¾é©¶è§†é¢‘çš„éªŒè¯ï¼Œè¯¥æ–¹æ³•åœ¨æå‡ç»“æ„ä¸€è‡´æ€§ä¸è¾¹ç•Œç²¾åº¦æ–¹é¢å±•ç°å‡ºäº†æå¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07460v2",
      "published_date": "2025-07-10 06:23:35 UTC",
      "updated_date": "2025-07-11 04:12:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:18.752330+00:00"
    },
    {
      "arxiv_id": "2507.08046v1",
      "title": "TableReasoner: Advancing Table Reasoning Framework with Large Language Models",
      "title_zh": "TableReasonerï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æå‡è¡¨æ ¼æ¨ç†æ¡†æ¶",
      "authors": [
        "Sishi Xiong",
        "Dakai Wang",
        "Yu Zhao",
        "Jie Zhang",
        "Changzai Pan",
        "Haowei He",
        "Xiangyu Li",
        "Wenhan Chang",
        "Zhongjiang He",
        "Shuangyong Song",
        "Yongxiang Li"
      ],
      "abstract": "The paper presents our system developed for table question answering (TQA). TQA tasks face challenges due to the characteristics of real-world tabular data, such as large size, incomplete column semantics, and entity ambiguity. To address these issues, we propose a large language model (LLM)-powered and programming-based table reasoning framework, named TableReasoner. It models a table using the schema that combines structural and semantic representations, enabling holistic understanding and efficient processing of large tables. We design a multi-step schema linking plan to derive a focused table schema that retains only query-relevant information, eliminating ambiguity and alleviating hallucinations. This focused table schema provides precise and sufficient table details for query refinement and programming. Furthermore, we integrate the reasoning workflow into an iterative thinking architecture, allowing incremental cycles of thinking, reasoning and reflection. Our system achieves first place in both subtasks of SemEval-2025 Task 8.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TableReasonerï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ (Large Language Models) å’Œç¼–ç¨‹æ€ç»´çš„è¡¨æ ¼æ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¡¨æ ¼é—®ç­” (Table Question Answering, TQA) ä»»åŠ¡ä¸­é¢ä¸´çš„æ•°æ®è§„æ¨¡åºå¤§ã€åˆ—è¯­ä¹‰ä¸å®Œæ•´åŠå®ä½“æ­§ä¹‰ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆç»“æ„åŒ–ä¸è¯­ä¹‰è¡¨ç¤ºçš„ schema å¯¹è¡¨æ ¼è¿›è¡Œå»ºæ¨¡ï¼Œå®ç°äº†å¯¹å¤§å‹è¡¨æ ¼çš„æ•´ä½“ç†è§£å’Œé«˜æ•ˆå¤„ç†ã€‚ç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†ä¸€ç§å¤šæ­¥ schema linking æ–¹æ¡ˆï¼Œé€šè¿‡æå–ä»…ä¸æŸ¥è¯¢ç›¸å…³çš„æ ¸å¿ƒä¿¡æ¯æ¥æ„å»ºç²¾ç®€ schemaï¼Œä»è€Œæœ‰æ•ˆæ¶ˆé™¤æ­§ä¹‰å¹¶å‡è½»æ¨¡å‹å¹»è§‰ã€‚æ­¤å¤–ï¼ŒTableReasoner å°†æ¨ç†å·¥ä½œæµæ•´åˆè¿›è¿­ä»£æ€è€ƒæ¶æ„ä¸­ï¼Œæ”¯æŒæ€è€ƒã€æ¨ç†ä¸åæ€çš„å¢é‡å¾ªç¯ã€‚å‡­å€Ÿè¿™ä¸€ç³»åˆ—åˆ›æ–°è®¾è®¡ï¼Œè¯¥ç³»ç»Ÿåœ¨ SemEval-2025 Task 8 çš„ä¸¤ä¸ªå­ä»»åŠ¡ä¸­å‡è£è·ç¬¬ä¸€åï¼Œæ˜¾è‘—æå‡äº†è¡¨æ ¼æ¨ç†çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08046v1",
      "published_date": "2025-07-10 06:16:51 UTC",
      "updated_date": "2025-07-10 06:16:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:13.443817+00:00"
    },
    {
      "arxiv_id": "2507.07453v1",
      "title": "Bluish Veil Detection and Lesion Classification using Custom Deep Learnable Layers with Explainable Artificial Intelligence (XAI)",
      "title_zh": "åŸºäºè‡ªå®šä¹‰æ·±åº¦å¯å­¦ä¹ å±‚ä¸å¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰çš„è“ç™½å¹•æ£€æµ‹åŠçš®æŸåˆ†ç±»",
      "authors": [
        "M. A. Rasel",
        "Sameem Abdul Kareem",
        "Zhenli Kwan",
        "Shin Shen Yong",
        "Unaizah Obaidellah"
      ],
      "abstract": "Melanoma, one of the deadliest types of skin cancer, accounts for thousands of fatalities globally. The bluish, blue-whitish, or blue-white veil (BWV) is a critical feature for diagnosing melanoma, yet research into detecting BWV in dermatological images is limited. This study utilizes a non-annotated skin lesion dataset, which is converted into an annotated dataset using a proposed imaging algorithm based on color threshold techniques on lesion patches and color palettes. A Deep Convolutional Neural Network (DCNN) is designed and trained separately on three individual and combined dermoscopic datasets, using custom layers instead of standard activation function layers. The model is developed to categorize skin lesions based on the presence of BWV. The proposed DCNN demonstrates superior performance compared to conventional BWV detection models across different datasets. The model achieves a testing accuracy of 85.71% on the augmented PH2 dataset, 95.00% on the augmented ISIC archive dataset, 95.05% on the combined augmented (PH2+ISIC archive) dataset, and 90.00% on the Derm7pt dataset. An explainable artificial intelligence (XAI) algorithm is subsequently applied to interpret the DCNN's decision-making process regarding BWV detection. The proposed approach, coupled with XAI, significantly improves the detection of BWV in skin lesions, outperforming existing models and providing a robust tool for early melanoma diagnosis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é»‘è‰²ç´ ç˜¤è¯Šæ–­ä¸­çš„å…³é”®ç‰¹å¾è“è‰²/è“ç™½è‰²é¢çº± (Blue-white veil, BWV) è‡ªåŠ¨æ£€æµ‹ç ”ç©¶ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆè‡ªå®šä¹‰æ·±åº¦å¯å­¦ä¹ å±‚ä¸å¯è§£é‡Šäººå·¥æ™ºèƒ½ (Explainable Artificial Intelligence, XAI) çš„æ–°å‹æ¡†æ¶ã€‚ç ”ç©¶é¦–å…ˆåˆ©ç”¨åŸºäºé¢œè‰²é˜ˆå€¼å’Œè‰²æ¿çš„æˆåƒç®—æ³•å°†æ— æ ‡æ³¨æ•°æ®é›†è½¬åŒ–ä¸ºæ ‡æ³¨æ•°æ®ï¼Œéšåè®¾è®¡å¹¶è®­ç»ƒäº†ä¸€ä¸ªé‡‡ç”¨è‡ªå®šä¹‰å±‚æ›¿ä»£æ ‡å‡†æ¿€æ´»å±‚çš„æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ (DCNN)ã€‚è¯¥æ¨¡å‹æ—¨åœ¨æ ¹æ® BWV çš„å­˜åœ¨ä¸å¦å¯¹çš®è‚¤ç—…å˜è¿›è¡Œåˆ†ç±»ï¼Œåœ¨ PH2ã€ISIC archive åŠ Derm7pt ç­‰å¤šä¸ªæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºä¼˜äºä¼ ç»Ÿæ£€æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Œå…¶ä¸­åœ¨ç»„åˆå¢å¼ºæ•°æ®é›†ä¸Šçš„æµ‹è¯•å‡†ç¡®ç‡è¾¾åˆ° 95.05%ã€‚é€šè¿‡åº”ç”¨ XAI ç®—æ³•ï¼Œç ”ç©¶æˆåŠŸè§£é‡Šäº† DCNN åœ¨æ£€æµ‹ BWV è¿‡ç¨‹ä¸­çš„å†³ç­–é€»è¾‘ï¼Œæ˜¾è‘—æå‡äº†åˆ†ç±»ä»»åŠ¡çš„å¯è§£é‡Šæ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºçš®è‚¤ç—…å˜çš„æ—©æœŸè¯Šæ–­æä¾›äº†é«˜æ•ˆä¸”é²æ£’çš„å·¥å…·ï¼Œå¯¹æé«˜é»‘è‰²ç´ ç˜¤çš„ä¸´åºŠè¯Šæ–­å‡†ç¡®æ€§å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted version. Published in Computers in Biology and Medicine, 14 June 2024. DOI: 10.1016/j.compbiomed.2024.108758",
      "pdf_url": "https://arxiv.org/pdf/2507.07453v1",
      "published_date": "2025-07-10 06:12:23 UTC",
      "updated_date": "2025-07-10 06:12:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:25.984034+00:00"
    },
    {
      "arxiv_id": "2507.07445v2",
      "title": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley",
      "title_zh": "StarDojoï¼šåŸºäº Stardew Valley ç”Ÿäº§ç”Ÿæ´»æ¨¡æ‹Ÿçš„æ™ºèƒ½ä½“å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å¼€æ”¾å¼è¡Œä¸ºåŸºå‡†æµ‹è¯•",
      "authors": [
        "Weihao Tan",
        "Changjiu Jiang",
        "Yu Duan",
        "Mingcong Lei",
        "Jiageng Li",
        "Yitian Hong",
        "Xinrun Wang",
        "Bo An"
      ],
      "abstract": "Autonomous agents navigating human society must master both production activities and social interactions, yet existing benchmarks rarely evaluate these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel benchmark based on Stardew Valley, designed to assess AI agents in open-ended production-living simulations. In StarDojo, agents are tasked to perform essential livelihood activities such as farming and crafting, while simultaneously engaging in social interactions to establish relationships within a vibrant community. StarDojo features 1,000 meticulously curated tasks across five key domains: farming, crafting, exploration, combat, and social interactions. Additionally, we provide a compact subset of 100 representative tasks for efficient model evaluation. The benchmark offers a unified, user-friendly interface that eliminates the need for keyboard and mouse control, supports all major operating systems, and enables the parallel execution of multiple environment instances, making it particularly well-suited for evaluating the most capable foundation agents, powered by multimodal large language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents demonstrate substantial limitations, with the best-performing model, GPT-4.1, achieving only a 12.7% success rate, primarily due to challenges in visual understanding, multimodal reasoning and low-level manipulation. As a user-friendly environment and benchmark, StarDojo aims to facilitate further research towards robust, open-ended agents in complex production-living environments.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† StarDojoï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºã€Šæ˜Ÿéœ²è°·ç‰©è¯­ã€‹(Stardew Valley) çš„åˆ›æ–°åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼° AI æ™ºèƒ½ä½“åœ¨å¼€æ”¾å¼ç”Ÿäº§ç”Ÿæ´»æ¨¡æ‹Ÿä¸­çš„è¡¨ç°ã€‚è¯¥åŸºå‡†æ¶µç›–äº†å†œä¸š (farming)ã€åˆ¶ä½œ (crafting)ã€æ¢ç´¢ã€æˆ˜æ–—å’Œç¤¾äº¤äº’åŠ¨äº”ä¸ªé¢†åŸŸçš„ 1,000 ä¸ªç²¾å¿ƒè®¾è®¡çš„ä»»åŠ¡ï¼Œè¦æ±‚æ™ºèƒ½ä½“åœ¨ç»´æŒç”Ÿè®¡çš„åŒæ—¶å»ºç«‹ç¤¾äº¤å…³ç³»ã€‚StarDojo æä¾›äº†ä¸€ä¸ªç»Ÿä¸€ä¸”ç”¨æˆ·å‹å¥½çš„ç•Œé¢ï¼Œæ”¯æŒå¤šå®ä¾‹å¹¶è¡Œæ‰§è¡Œå¹¶æ¶ˆé™¤äº†å¯¹é”®ç›˜é¼ æ ‡æ§åˆ¶çš„éœ€æ±‚ï¼Œéå¸¸é€‚åˆè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) é©±åŠ¨çš„æ™ºèƒ½ä½“ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œç›®å‰çš„é¡¶çº§æ¨¡å‹ä»é¢ä¸´ä¸¥å³»æŒ‘æˆ˜ï¼Œå…¶ä¸­è¡¨ç°æœ€å¥½çš„ GPT-4.1 æˆåŠŸç‡ä»…ä¸º 12.7%ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œè§†è§‰ç†è§£ã€å¤šæ¨¡æ€æ¨ç†å’Œä½çº§æ“ä½œ (low-level manipulation) çš„ä¸è¶³æ˜¯é™åˆ¶æ™ºèƒ½ä½“æ€§èƒ½çš„ä¸»è¦å› ç´ ã€‚StarDojo çš„æ¨å‡ºä¸ºåœ¨å¤æ‚ç¯å¢ƒä¸‹å¼€å‘ç¨³å¥ã€å¼€æ”¾å¼æ™ºèƒ½ä½“çš„ç›¸å…³ç ”ç©¶æä¾›äº†é‡è¦çš„æµ‹è¯•å¹³å°ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Project website: https://weihaotan.github.io/StarDojo",
      "pdf_url": "https://arxiv.org/pdf/2507.07445v2",
      "published_date": "2025-07-10 05:48:28 UTC",
      "updated_date": "2025-07-11 11:40:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:19.946761+00:00"
    },
    {
      "arxiv_id": "2507.08878v1",
      "title": "Towards Privacy-Preserving and Personalized Smart Homes via Tailored Small Language Models",
      "title_zh": "é¢å‘éšç§ä¿æŠ¤ä¸ä¸ªæ€§åŒ–æ™ºèƒ½å®¶å±…çš„å®šåˆ¶åŒ–å°è¯­è¨€æ¨¡å‹ç ”ç©¶",
      "authors": [
        "Xinyu Huang",
        "Leming Shen",
        "Zijing Ma",
        "Yuanqing Zheng"
      ],
      "abstract": "Large Language Models (LLMs) have showcased remarkable generalizability in language comprehension and hold significant potential to revolutionize human-computer interaction in smart homes. Existing LLM-based smart home assistants typically transmit user commands, along with user profiles and home configurations, to remote servers to obtain personalized services. However, users are increasingly concerned about the potential privacy leaks to the remote servers. To address this issue, we develop HomeLLaMA, an on-device assistant for privacy-preserving and personalized smart home serving with a tailored small language model (SLM). HomeLLaMA learns from cloud LLMs to deliver satisfactory responses and enable user-friendly interactions. Once deployed, HomeLLaMA facilitates proactive interactions by continuously updating local SLMs and user profiles. To further enhance user experience while protecting their privacy, we develop PrivShield to offer an optional privacy-preserving LLM-based smart home serving for those users, who are unsatisfied with local responses and willing to send less-sensitive queries to remote servers. For evaluation, we build a comprehensive benchmark DevFinder to assess the service quality. Extensive experiments and user studies (M=100) demonstrate that HomeLLaMA can provide personalized services while significantly enhancing user privacy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HomeLLaMAï¼Œä¸€ç§åŸºäºå®šåˆ¶åŒ–Small Language Model (SLM)çš„è®¾å¤‡ç«¯åŠ©æ‰‹ï¼Œæ—¨åœ¨è§£å†³åŸºäºLarge Language Models (LLMs)çš„æ™ºèƒ½å®¶å±…åŠ©æ‰‹å› å‘è¿œç¨‹æœåŠ¡å™¨ä¼ è¾“æ•°æ®è€Œå¼•å‘çš„éšç§æ³„éœ²é—®é¢˜ã€‚HomeLLaMAé€šè¿‡ä»äº‘ç«¯LLMså­¦ä¹ æ¥æä¾›é«˜è´¨é‡çš„äº¤äº’å“åº”ï¼Œå¹¶æ”¯æŒé€šè¿‡æŒç»­æ›´æ–°æœ¬åœ°SLMså’Œç”¨æˆ·é…ç½®æ–‡ä»¶å®ç°ä¸»åŠ¨å¼ä¸ªæ€§åŒ–æœåŠ¡ã€‚ä¸ºäº†å…¼é¡¾ç”¨æˆ·ä½“éªŒä¸éšç§ä¿æŠ¤ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†PrivShieldæœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·åœ¨å¯¹æœ¬åœ°å“åº”ä¸æ»¡æ„æ—¶å°†éæ•æ„ŸæŸ¥è¯¢å‘é€è‡³è¿œç¨‹æœåŠ¡å™¨ã€‚æ­¤å¤–ï¼Œå›¢é˜Ÿæ„å»ºäº†ç»¼åˆåŸºå‡†æµ‹è¯•DevFinderä»¥è¯„ä¼°æœåŠ¡è´¨é‡ã€‚å®éªŒåŠæ¶‰åŠ100åå—è¯•è€…çš„ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒHomeLLaMAåœ¨æä¾›é«˜åº¦ä¸ªæ€§åŒ–æ™ºèƒ½å®¶å±…æœåŠ¡çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†ç”¨æˆ·çš„éšç§å®‰å…¨ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08878v1",
      "published_date": "2025-07-10 05:36:32 UTC",
      "updated_date": "2025-07-10 05:36:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:25.845591+00:00"
    },
    {
      "arxiv_id": "2507.07439v1",
      "title": "Towards Interpretable Time Series Foundation Models",
      "title_zh": "è¿ˆå‘å¯è§£é‡Šçš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹",
      "authors": [
        "Matthieu Boileau",
        "Philippe Helluy",
        "Jeremy Pawlus",
        "Svitlana Vyetrenko"
      ],
      "abstract": "In this paper, we investigate the distillation of time series reasoning capabilities into small, instruction-tuned language models as a step toward building interpretable time series foundation models. Leveraging a synthetic dataset of mean-reverting time series with systematically varied trends and noise levels, we generate natural language annotations using a large multimodal model and use these to supervise the fine-tuning of compact Qwen models. We introduce evaluation metrics that assess the quality of the distilled reasoning - focusing on trend direction, noise intensity, and extremum localization - and show that the post-trained models acquire meaningful interpretive capabilities. Our results highlight the feasibility of compressing time series understanding into lightweight, language-capable models suitable for on-device or privacy-sensitive deployment. This work contributes a concrete foundation toward developing small, interpretable models that explain temporal patterns in natural language.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°†æ—¶é—´åºåˆ—æ¨ç†èƒ½åŠ›è’¸é¦(distillation)åˆ°å°å‹æŒ‡ä»¤å¾®è°ƒ(instruction-tuned)è¯­è¨€æ¨¡å‹ä¸­ï¼Œæ—¨åœ¨æ„å»ºå¯è§£é‡Šçš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹(time series foundation models)ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨åŒ…å«å¤šç§è¶‹åŠ¿å’Œå™ªå£°æ°´å¹³çš„åˆæˆå‡å€¼å›å½’æ—¶é—´åºåˆ—æ•°æ®é›†ï¼Œå¹¶é€šè¿‡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ç”Ÿæˆè‡ªç„¶è¯­è¨€æ³¨é‡Šï¼Œä»¥æ­¤ç›‘ç£å°å‹Qwenæ¨¡å‹çš„å¾®è°ƒã€‚è®ºæ–‡æå‡ºäº†è¯„ä¼°è’¸é¦æ¨ç†è´¨é‡çš„æŒ‡æ ‡ï¼Œé‡ç‚¹å…³æ³¨è¶‹åŠ¿æ–¹å‘ã€å™ªå£°å¼ºåº¦å’Œæå€¼å®šä½ï¼Œè¯æ˜äº†è®­ç»ƒåçš„æ¨¡å‹å…·å¤‡æ˜¾è‘—çš„è§£é‡Šèƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°†æ—¶é—´åºåˆ—ç†è§£å‹ç¼©åˆ°è½»é‡çº§ã€å…·å¤‡è¯­è¨€å¤„ç†èƒ½åŠ›çš„å°æ¨¡å‹ä¸­æ˜¯å¯è¡Œçš„ï¼Œè¿™éå¸¸é€‚ç”¨äºè®¾å¤‡ç«¯æˆ–éšç§æ•æ„Ÿçš„éƒ¨ç½²åœºæ™¯ã€‚è¯¥å·¥ä½œä¸ºå¼€å‘èƒ½å¤Ÿä»¥è‡ªç„¶è¯­è¨€è§£é‡Šæ—¶é—´æ¨¡å¼çš„å°å‹å¯è§£é‡Šæ¨¡å‹å¥ å®šäº†å…·ä½“åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "International Conference on Machine Leaning (ICML) 2025 Workshop on Foundation Models for Structured Data",
      "pdf_url": "https://arxiv.org/pdf/2507.07439v1",
      "published_date": "2025-07-10 05:29:34 UTC",
      "updated_date": "2025-07-10 05:29:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:23.806771+00:00"
    },
    {
      "arxiv_id": "2507.08877v1",
      "title": "ODIA: Oriented Distillation for Inline Acceleration of LLM-based Function Calling",
      "title_zh": "ODIAï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹å‡½æ•°è°ƒç”¨å†…è”åŠ é€Ÿçš„å®šå‘è’¸é¦",
      "authors": [
        "Hanlong Zhang",
        "Jingsheng Yang",
        "Hao Li",
        "Yuhao He",
        "Franck Gong"
      ],
      "abstract": "Function Calling is a crucial technique that enables Large Language Models (LLMs) to interact with external systems through APIs. However, the high latency associated with LLM-based Function Calling significantly impacts user experience. This paper presents a novel approach called Oriented Distillation for Inline Acceleration (ODIA) that leverages online user interaction data to accelerate Function Calling. By automatically identifying \"simple queries\" from production traffic and distilling knowledge from larger models to smaller ones, our method reduces response latency by 45% (expected) and 78% (median) while maintaining accuracy. We demonstrate the effectiveness of our approach through real-world deployment in a music application, where the smaller model successfully handles 60% of traffic with negligible accuracy loss. Our method requires minimal human intervention and continuously improves through automated data collection and model updating, making it a practical solution for production environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ODIAï¼ˆOriented Distillation for Inline Accelerationï¼‰ï¼Œæ—¨åœ¨è§£å†³åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡½æ•°è°ƒç”¨ï¼ˆFunction Callingï¼‰ä¸­å­˜åœ¨çš„é«˜å»¶è¿Ÿé—®é¢˜ï¼Œä»¥æå‡ç”¨æˆ·ä½“éªŒã€‚è¯¥æ–¹æ³•åˆ©ç”¨åœ¨çº¿ç”¨æˆ·äº¤äº’æ•°æ®ï¼Œé€šè¿‡è‡ªåŠ¨è¯†åˆ«ç”Ÿäº§æµé‡ä¸­çš„â€œç®€å•æŸ¥è¯¢ï¼ˆsimple queriesï¼‰â€ï¼Œå°†å¤§æ¨¡å‹çš„çŸ¥è¯†è’¸é¦ï¼ˆdistillationï¼‰åˆ°è¾ƒå°çš„æ¨¡å‹ä¸­ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒODIAèƒ½åœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå°†å“åº”å»¶è¿Ÿçš„ä¸­ä½æ•°é™ä½78%ï¼Œé¢„æœŸå»¶è¿Ÿé™ä½45%ã€‚åœ¨éŸ³ä¹åº”ç”¨ç¨‹åºçš„å®é™…éƒ¨ç½²ä¸­ï¼Œå°å‹æ¨¡å‹æˆåŠŸå¤„ç†äº†60%çš„æµé‡ï¼Œä¸”å‡†ç¡®ç‡æŸå¤±å‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚è¯¥æ–¹æ¡ˆä»…éœ€æå°‘çš„äººå·¥å¹²é¢„ï¼Œå¹¶èƒ½é€šè¿‡è‡ªåŠ¨åŒ–æ•°æ®æ”¶é›†å’Œæ¨¡å‹æ›´æ–°å®ç°æŒç»­ä¼˜åŒ–ï¼Œä¸ºç”Ÿäº§ç¯å¢ƒæä¾›äº†ä¸€ç§å®ç”¨çš„åŠ é€Ÿæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08877v1",
      "published_date": "2025-07-10 04:44:47 UTC",
      "updated_date": "2025-07-10 04:44:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:29.668078+00:00"
    },
    {
      "arxiv_id": "2507.07426v3",
      "title": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search",
      "title_zh": "DrugMCTSï¼šä¸€ç§ç»“åˆå¤šæ™ºèƒ½ä½“ã€RAG ä¸è’™ç‰¹å¡æ´›æ ‘æœç´¢çš„è¯ç‰©å†åˆ©ç”¨æ¡†æ¶",
      "authors": [
        "Zerui Yang",
        "Yuwei Wan",
        "Siyu Yan",
        "Yudai Matsuda",
        "Tong Xie",
        "Bram Hoex",
        "Linqi Song"
      ],
      "abstract": "Recent advances in large language models have demonstrated considerable potential in scientific domains such as drug repositioning. However, their effectiveness remains constrained when reasoning extends beyond the knowledge acquired during pretraining. Conventional approaches, such as fine-tuning or retrieval-augmented generation, face limitations in either imposing high computational overhead or failing to fully exploit structured scientific data. To overcome these challenges, we propose DrugMCTS, a novel framework that synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repositioning. The framework employs five specialized agents tasked with retrieving and analyzing molecular and protein information, thereby enabling structured and iterative reasoning. Extensive experiments on the DrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially higher recall and robustness compared to both general-purpose LLMs and deep learning baselines. Our results highlight the importance of structured reasoning, agent-based collaboration, and feedback-driven search mechanisms in advancing LLM applications for drug repositioning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯ç‰©é‡å®šä½(drug repositioning)é¢†åŸŸå—é™äºé¢„è®­ç»ƒçŸ¥è¯†ã€è®¡ç®—å¼€é”€å¤§ä»¥åŠç»“æ„åŒ–æ•°æ®åˆ©ç”¨ä¸è¶³ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†å…¨æ–°çš„DrugMCTSæ¡†æ¶ã€‚è¯¥æ¡†æ¶ååŒé›†æˆäº†æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯(RAG)ã€å¤šæ™ºèƒ½ä½“åä½œ(multi-agent collaboration)å’Œè’™ç‰¹å¡æ´›æ ‘æœç´¢(Monte Carlo Tree Search)ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„åŒ–å’Œè¿­ä»£æ¨ç†æå‡è¯ç‰©å‘ç°çš„å‡†ç¡®æ€§ã€‚ç³»ç»Ÿå†…éƒ¨ç½²äº†äº”ä¸ªä¸“é—¨çš„æ™ºèƒ½ä½“(agents)è´Ÿè´£æ£€ç´¢å¹¶åˆ†æåˆ†å­ä¸è›‹ç™½è´¨ä¿¡æ¯ï¼Œä»è€Œå®ç°äº†å¤æ‚ç§‘å­¦æ•°æ®çš„æ·±åº¦æ•´åˆã€‚åœ¨DrugBankå’ŒKIBAæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDrugMCTSåœ¨æŸ¥å…¨ç‡(recall)å’Œç¨³å¥æ€§(robustness)æ–¹é¢å‡æ˜¾è‘—ä¼˜äºé€šç”¨LLMsåŠä¼ ç»Ÿçš„æ·±åº¦å­¦ä¹ åŸºçº¿æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ä»…éªŒè¯äº†ç»“æ„åŒ–æ¨ç†ä¸æ™ºèƒ½ä½“åä½œçš„æœ‰æ•ˆæ€§ï¼Œè¿˜å¼ºè°ƒäº†åé¦ˆé©±åŠ¨æœç´¢æœºåˆ¶åœ¨æå‡LLMså¤„ç†ç‰¹å®šé¢†åŸŸç§‘å­¦ä»»åŠ¡ä¸­çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07426v3",
      "published_date": "2025-07-10 04:39:55 UTC",
      "updated_date": "2025-07-31 13:57:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:33.747726+00:00"
    },
    {
      "arxiv_id": "2507.07421v1",
      "title": "SynthEHR-Eviction: Enhancing Eviction SDoH Detection with LLM-Augmented Synthetic EHR Data",
      "title_zh": "SynthEHR-Evictionï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å¢å¼ºçš„åˆæˆç”µå­å¥åº·æ¡£æ¡ˆæ•°æ®æå‡é©±é€ç±»å¥åº·ç¤¾ä¼šå†³å®šå› ç´ æ£€æµ‹",
      "authors": [
        "Zonghai Yao",
        "Youxia Zhao",
        "Avijit Mitra",
        "David A. Levy",
        "Emily Druhl",
        "Jack Tsai",
        "Hong Yu"
      ],
      "abstract": "Eviction is a significant yet understudied social determinants of health (SDoH), linked to housing instability, unemployment, and mental health. While eviction appears in unstructured electronic health records (EHRs), it is rarely coded in structured fields, limiting downstream applications. We introduce SynthEHR-Eviction, a scalable pipeline combining LLMs, human-in-the-loop annotation, and automated prompt optimization (APO) to extract eviction statuses from clinical notes. Using this pipeline, we created the largest public eviction-related SDoH dataset to date, comprising 14 fine-grained categories. Fine-tuned LLMs (e.g., Qwen2.5, LLaMA3) trained on SynthEHR-Eviction achieved Macro-F1 scores of 88.8% (eviction) and 90.3% (other SDoH) on human validated data, outperforming GPT-4o-APO (87.8%, 87.3%), GPT-4o-mini-APO (69.1%, 78.1%), and BioBERT (60.7%, 68.3%), while enabling cost-effective deployment across various model sizes. The pipeline reduces annotation effort by over 80%, accelerates dataset creation, enables scalable eviction detection, and generalizes to other information extraction tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SynthEHR-Evictionï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ä»éç»“æ„åŒ–ç”µå­å¥åº·è®°å½• (EHRs) ä¸­æå–ä½æˆ¿é©±é€ (Eviction) çŠ¶æ€çš„å¯æ‰©å±•æµæ°´çº¿ã€‚ä½æˆ¿é©±é€æ˜¯å…³é”®çš„ç¤¾ä¼šå¥åº·å†³å®šå› ç´  (SDoH)ï¼Œä½†åœ¨ä¸´åºŠæ•°æ®ä¸­æå°‘è¢«ç»“æ„åŒ–ç¼–ç ï¼Œä¸¥é‡é™åˆ¶äº†å…¶åœ¨åŒ»ç–—ç ”ç©¶ä¸­çš„åº”ç”¨ã€‚è¯¥æ¡†æ¶ç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs)ã€äººç±»å‚ä¸æ ‡æ³¨ (human-in-the-loop annotation) å’Œè‡ªåŠ¨æç¤ºä¼˜åŒ– (APO) æŠ€æœ¯ï¼Œæ„å»ºäº†ç›®å‰è§„æ¨¡æœ€å¤§çš„å…¬å…±ä½æˆ¿é©±é€ç›¸å…³ SDoH æ•°æ®é›†ï¼Œæ¶µç›– 14 ä¸ªç»†ç²’åº¦ç±»åˆ«ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨è¯¥æ•°æ®é›†ä¸Šå¾®è°ƒçš„ Qwen2.5 å’Œ LLaMA3 æ¨¡å‹åœ¨ Macro-F1 åˆ†æ•°ä¸Šè¾¾åˆ°äº† 88.8%ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äº GPT-4o-APO å’Œ BioBERT ç­‰åŸºçº¿æ¨¡å‹ã€‚è¯¥æµæ°´çº¿ä¸ä»…æˆåŠŸå‡å°‘äº† 80% ä»¥ä¸Šçš„äººå·¥æ ‡æ³¨å·¥ä½œé‡ï¼Œè¿˜å®ç°äº†ä½æˆæœ¬ä¸”å¯æ‰©å±•çš„ä¸´åºŠä¿¡æ¯æå–ï¼Œä¸º SDoH çš„è‡ªåŠ¨åŒ–æ£€æµ‹æä¾›äº†é«˜æ•ˆçš„æ³›åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Equal contribution for the first two authors",
      "pdf_url": "https://arxiv.org/pdf/2507.07421v1",
      "published_date": "2025-07-10 04:31:01 UTC",
      "updated_date": "2025-07-10 04:31:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:41.710939+00:00"
    },
    {
      "arxiv_id": "2507.07419v1",
      "title": "MedReadCtrl: Personalizing medical text generation with readability-controlled instruction learning",
      "title_zh": "MedReadCtrlï¼šåŸºäºå¯è¯»æ€§å—æ§æŒ‡ä»¤å­¦ä¹ çš„ä¸ªæ€§åŒ–åŒ»ç–—æ–‡æœ¬ç”Ÿæˆ",
      "authors": [
        "Hieu Tran",
        "Zonghai Yao",
        "Won Seok Jang",
        "Sharmin Sultana",
        "Allen Chang",
        "Yuan Zhang",
        "Hong Yu"
      ],
      "abstract": "Generative AI has demonstrated strong potential in healthcare, from clinical decision support to patient-facing chatbots that improve outcomes. A critical challenge for deployment is effective human-AI communication, where content must be both personalized and understandable. We introduce MedReadCtrl, a readability-controlled instruction tuning framework that enables LLMs to adjust output complexity without compromising meaning. Evaluations of nine datasets and three tasks across medical and general domains show that MedReadCtrl achieves significantly lower readability instruction-following errors than GPT-4 (e.g., 1.39 vs. 1.59 on ReadMe, p<0.001) and delivers substantial gains on unseen clinical tasks (e.g., +14.7 ROUGE-L, +6.18 SARI on MTSamples). Experts consistently preferred MedReadCtrl (71.7% vs. 23.3%), especially at low literacy levels. These gains reflect MedReadCtrl's ability to restructure clinical content into accessible, readability-aligned language while preserving medical intent, offering a scalable solution to support patient education and expand equitable access to AI-enabled care.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MedReadCtrlï¼Œä¸€ç§å¯æ§å¯è¯»æ€§çš„æŒ‡ä»¤å¾®è°ƒï¼ˆreadability-controlled instruction tuningï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŒ»ç–—ç”Ÿæˆå¼ AI åœ¨äººæœºäº¤äº’ä¸­å†…å®¹å¤æ‚ä¸”éš¾ä»¥ç†è§£çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å…è®¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸æ”¹å˜åŸå§‹åŒ»å­¦æ„å›¾ï¼ˆmedical intentï¼‰çš„å‰æä¸‹ï¼Œæ ¹æ®éœ€æ±‚çµæ´»è°ƒæ•´è¾“å‡ºå†…å®¹çš„å¤æ‚åº¦ã€‚åœ¨æ¶µç›–åŒ»ç–—å’Œé€šç”¨é¢†åŸŸçš„ 9 ä¸ªæ•°æ®é›†åŠ 3 é¡¹ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼ŒMedReadCtrl åœ¨éµå¾ªå¯è¯»æ€§æŒ‡ä»¤æ–¹é¢çš„é”™è¯¯ç‡æ˜¾è‘—ä½äº GPT-4ï¼Œå¹¶åœ¨æœªè§è¿‡çš„ä¸´åºŠä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¾‹å¦‚åœ¨ MTSamples æ•°æ®é›†ä¸Š ROUGE-L æå‡äº† 14.7ã€‚ä¸“å®¶è¯„å®¡åœ¨ 71.7% çš„æƒ…å†µä¸‹æ›´å€¾å‘äº MedReadCtrl çš„ç”Ÿæˆç»“æœï¼Œç‰¹åˆ«æ˜¯åœ¨é’ˆå¯¹ä½æ–‡åŒ–ç¨‹åº¦ï¼ˆlow literacy levelsï¼‰äººç¾¤çš„è§£é‡Šä¸Šã€‚é€šè¿‡å°†ä¸´åºŠä¸“ä¸šå†…å®¹é‡æ„ä¸ºæ˜“äºå¤§ä¼—ç†è§£çš„è¯­è¨€ï¼ŒMedReadCtrl ä¸ºæ‚£è€…æ•™è‚²å’Œæå‡ AI åŒ»ç–—æœåŠ¡çš„å…¬å¹³æ€§æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Equal contribution for the first two authors. arXiv admin note: text overlap with arXiv:2406.09205",
      "pdf_url": "https://arxiv.org/pdf/2507.07419v1",
      "published_date": "2025-07-10 04:22:36 UTC",
      "updated_date": "2025-07-10 04:22:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:55.497110+00:00"
    },
    {
      "arxiv_id": "2507.07418v1",
      "title": "Optimal Auction Design in the Joint Advertising",
      "title_zh": "è”åˆå¹¿å‘Šä¸­çš„æœ€ä¼˜æ‹å–è®¾è®¡",
      "authors": [
        "Yang Li",
        "Yuchao Ma",
        "Qi Qi"
      ],
      "abstract": "Online advertising is a vital revenue source for major internet platforms. Recently, joint advertising, which assigns a bundle of two advertisers in an ad slot instead of allocating a single advertiser, has emerged as an effective method for enhancing allocation efficiency and revenue. However, existing mechanisms for joint advertising fail to realize the optimality, as they tend to focus on individual advertisers and overlook bundle structures. This paper identifies an optimal mechanism for joint advertising in a single-slot setting. For multi-slot joint advertising, we propose \\textbf{BundleNet}, a novel bundle-based neural network approach specifically designed for joint advertising. Our extensive experiments demonstrate that the mechanisms generated by \\textbf{BundleNet} approximate the theoretical analysis results in the single-slot setting and achieve state-of-the-art performance in the multi-slot setting. This significantly increases platform revenue while ensuring approximate dominant strategy incentive compatibility and individual rationality.",
      "tldr_zh": "åœ¨åœ¨çº¿å¹¿å‘Šé¢†åŸŸï¼Œè”åˆå¹¿å‘Šï¼ˆjoint advertisingï¼‰é€šè¿‡åœ¨å•ä¸ªå¹¿å‘Šä½æ‰“åŒ…ä¸¤ä¸ªå¹¿å‘Šä¸»æ¥æé«˜æ•ˆç‡ï¼Œä½†ç°æœ‰æœºåˆ¶å› å¿½è§†æ†ç»‘ç»“æ„è€Œéš¾ä»¥å®ç°æœ€ä¼˜æ€§ã€‚è¯¥ç ”ç©¶é¦–å…ˆé’ˆå¯¹å•å¹¿å‘Šä½åœºæ™¯ç¡®å®šäº†ä¸€ç§è”åˆå¹¿å‘Šçš„æœ€ä¼˜æ‹å–æœºåˆ¶ï¼Œå¡«è¡¥äº†ç†è®ºç©ºç™½ã€‚éšåï¼Œé’ˆå¯¹æ›´å¤æ‚çš„å¤šå¹¿å‘Šä½åœºæ™¯ï¼Œè®ºæ–‡æå‡ºäº† BundleNetï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºè”åˆå¹¿å‘Šè®¾è®¡çš„åŸºäºæ†ç»‘ï¼ˆbundle-basedï¼‰çš„æ–°å‹ç¥ç»ç½‘ç»œæ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBundleNet ç”Ÿæˆçš„æœºåˆ¶åœ¨å•å¹¿å‘Šä½è®¾ç½®ä¸‹èƒ½æ¥è¿‘ç†è®ºåˆ†æçš„æœ€ä¼˜è§£ï¼Œå¹¶åœ¨å¤šå¹¿å‘Šä½è®¾ç½®ä¸­è¾¾åˆ°äº† state-of-the-art çš„æ€§èƒ½è¡¨ç°ã€‚è¿™ä¸€æ–¹æ¡ˆåœ¨æ˜¾è‘—æå‡å¹³å°æ”¶ç›Šçš„åŒæ—¶ï¼Œæœ‰æ•ˆç¡®ä¿äº†è¿‘ä¼¼å ä¼˜ç­–ç•¥æ¿€åŠ±ç›¸å®¹æ€§ï¼ˆdominant strategy incentive compatibilityï¼‰å’Œä¸ªäººç†æ€§ï¼ˆindividual rationalityï¼‰ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "Accepted by ICML 2025 (International Conference on Machine Learning). 17 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07418v1",
      "published_date": "2025-07-10 04:21:01 UTC",
      "updated_date": "2025-07-10 04:21:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:59:58.053893+00:00"
    },
    {
      "arxiv_id": "2507.07417v2",
      "title": "May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks",
      "title_zh": "May I have your Attentionï¼Ÿåˆ©ç”¨æ¶æ„æ„ŸçŸ¥æ”»å‡»æ”»ç ´åŸºäºå¾®è°ƒçš„æç¤ºæ³¨å…¥é˜²å¾¡",
      "authors": [
        "Nishit V. Pandya",
        "Andrey Labunets",
        "Sicun Gao",
        "Earlence Fernandes"
      ],
      "abstract": "A popular class of defenses against prompt injection attacks on large language models (LLMs) relies on fine-tuning to separate instructions and data, so that the LLM does not follow instructions that might be present with data. We evaluate the robustness of this approach in the whitebox setting by constructing strong optimization-based attacks, and show that the defenses do not provide the claimed security properties. Specifically, we construct a novel attention-based attack algorithm for textual LLMs and apply it to three recent whitebox defenses SecAlign (CCS 2025), SecAlign++, and StruQ (USENIX Security 2025), showing attacks with success rates of up to \\textbf{85-95\\%} on unseen prompts with modest increase in attacker budget in terms of tokens. Our findings make fundamental progress towards understanding the robustness of prompt injection defenses in the whitebox setting. We release our code and attacks at https://github.com/nishitvp/better_opts_attacks",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åŸºäºFine-tuningçš„Prompt Injectioné˜²å¾¡ç­–ç•¥åœ¨Whiteboxè®¾ç½®ä¸‹çš„é²æ£’æ€§ï¼Œè¿™ç±»é˜²å¾¡é€šå¸¸é€šè¿‡åˆ†ç¦»æŒ‡ä»¤ä¸æ•°æ®æ¥é˜²æ­¢å¤§è¯­è¨€æ¨¡å‹è¯¯æ‰§è¡Œæ•°æ®ä¸­çš„æ¶æ„æŒ‡ä»¤ã€‚ä½œè€…æå‡ºäº†ä¸€ç§æ–°å‹çš„Architecture-Awareæ”»å‡»æ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºä¸€ç§é’ˆå¯¹æ–‡æœ¬LLMsçš„Attention-basedæ”»å‡»ç®—æ³•ã€‚é€šè¿‡å¯¹SecAlign (CCS 2025)ã€SecAlign++å’ŒStruQ (USENIX Security 2025)ä¸‰ç§è¿‘æœŸé˜²å¾¡æ–¹æ¡ˆçš„æµ‹è¯•ï¼Œè¯¥æ”»å‡»åœ¨ä»…é€‚åº¦å¢åŠ Tokené¢„ç®—çš„æƒ…å†µä¸‹ï¼Œå¯¹æœªè§è¿‡çš„æç¤ºè¯å®ç°äº†é«˜è¾¾85%è‡³95%çš„æˆåŠŸç‡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç°æœ‰çš„å¾®è°ƒé˜²å¾¡æ‰‹æ®µå¹¶æœªæä¾›å…¶å£°ç§°çš„å®‰å…¨ç‰¹æ€§ï¼Œæ­ç¤ºäº†æ­¤ç±»é˜²å¾¡åœ¨å¼ºåŠ›ä¼˜åŒ–æ”»å‡»é¢å‰çš„è„†å¼±æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºæ·±å…¥ç†è§£ç™½ç›’ç¯å¢ƒä¸‹æç¤ºè¯æ³¨å…¥é˜²å¾¡çš„é²æ£’æ€§åšå‡ºäº†åŸºç¡€æ€§è´¡çŒ®ï¼Œå¹¶å…¬å¼€äº†ç›¸å…³ä»£ç ä¸æ”»å‡»å·¥å…·ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07417v2",
      "published_date": "2025-07-10 04:20:53 UTC",
      "updated_date": "2025-12-17 06:57:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:02.561633+00:00"
    },
    {
      "arxiv_id": "2507.07416v1",
      "title": "Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation",
      "title_zh": "é¢å‘å…³é”®åŸºç¡€è®¾æ–½çš„è‡ªä¸»äººå·¥æ™ºèƒ½ç½‘ç»œå®‰å…¨æ¡†æ¶ï¼šå®æ—¶å¨èƒç¼“è§£",
      "authors": [
        "Jenifer Paulraj",
        "Brindha Raghuraman",
        "Nagarani Gopalakrishnan",
        "Yazan Otoum"
      ],
      "abstract": "Critical infrastructure systems, including energy grids, healthcare facilities, transportation networks, and water distribution systems, are pivotal to societal stability and economic resilience. However, the increasing interconnectivity of these systems exposes them to various cyber threats, including ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent Threats (APTs). This paper examines cybersecurity vulnerabilities in critical infrastructure, highlighting the threat landscape, attack vectors, and the role of Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid AI-driven cybersecurity framework to enhance real-time vulnerability detection, threat modelling, and automated remediation. This study also addresses the complexities of adversarial AI, regulatory compliance, and integration. Our findings provide actionable insights to strengthen the security and resilience of critical infrastructure systems against emerging cyber threats.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºäººå·¥æ™ºèƒ½(AI)çš„è‡ªä¸»ç½‘ç»œå®‰å…¨æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºå¢å¼ºèƒ½æºç½‘ã€åŒ»ç–—è®¾æ–½ã€äº¤é€šå’Œæ°´åŠ¡ç­‰å…³é”®åŸºç¡€è®¾æ–½çš„å®‰å…¨æ€§å’ŒéŸ§æ€§ã€‚éšç€ç³»ç»Ÿäº’è”æ€§çš„å¢å¼ºï¼Œè¿™äº›åŸºç¡€è®¾æ–½æ­£é¢ä¸´å‹’ç´¢è½¯ä»¶(Ransomware)ã€æ‹’ç»æœåŠ¡æ”»å‡»(DoS)å’Œé«˜çº§æŒç»­æ€§å¨èƒ(APTs)ç­‰æ—¥ç›Šä¸¥å³»çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ··åˆAIé©±åŠ¨(hybrid AI-driven)æ–¹æ³•ï¼Œæ—¨åœ¨å®ç°å®æ—¶çš„æ¼æ´æ£€æµ‹ã€å¨èƒå»ºæ¨¡ä»¥åŠè‡ªåŠ¨åŒ–çš„ä¿®å¤å¤„ç†(Remediation)ã€‚ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¯¹æŠ—æ€§AI(Adversarial AI)ã€ç›‘ç®¡åˆè§„æ€§ä»¥åŠç³»ç»Ÿé›†æˆçš„å¤æ‚æ€§ã€‚ç ”ç©¶ç»“æœä¸ºæŠµå¾¡æ–°å…´ç½‘ç»œå¨èƒæä¾›äº†å¯æ“ä½œçš„è§è§£ï¼Œä¸ºæå‡å…³é”®åŸºç¡€è®¾æ–½åœ¨é¢å¯¹å®æ—¶å¨èƒæ—¶çš„é˜²å¾¡èƒ½åŠ›å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, IEEE conference",
      "pdf_url": "https://arxiv.org/pdf/2507.07416v1",
      "published_date": "2025-07-10 04:17:29 UTC",
      "updated_date": "2025-07-10 04:17:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:01.611808+00:00"
    },
    {
      "arxiv_id": "2507.07414v1",
      "title": "GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation",
      "title_zh": "GNN-CNNï¼šä¸€ç§ç”¨äºæ–‡æœ¬è¡¨ç¤ºçš„å·ç§¯ä¸å›¾ç¥ç»ç½‘ç»œé«˜æ•ˆæ··åˆæ¨¡å‹",
      "authors": [
        "Fardin Rastakhiz"
      ],
      "abstract": "Time, cost, and energy efficiency are critical considerations in Deep-Learning (DL), particularly when processing long texts. Transformers, which represent the current state of the art, exhibit quadratic computational complexity relative to input length, making them inefficient for extended documents. This study introduces a novel model architecture that combines Graph Neural Networks (GNNs) and Convolutional Neural Networks (CNNs), integrated with a real-time, end-to-end graph generation mechanism. The model processes compact batches of character-level inputs without requiring padding or truncation. To enhance performance while maintaining high speed and efficiency, the model incorporates information from Large Language Models (LLMs), such as token embeddings and sentiment polarities, through efficient dictionary lookups. It captures local contextual patterns using CNNs, expands local receptive fields via lattice-based graph structures, and employs small-world graphs to aggregate document-level information. The generated graphs exhibit structural properties indicative of meaningful semantic organization, with an average clustering coefficient of approximately 0.45 and an average shortest path length ranging between 4 and 5. The model is evaluated across multiple text classification tasks, including sentiment analysis and news-categorization, and is compared against state-of-the-art models. Experimental results confirm the proposed model's efficiency and competitive performance.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†GNN-CNNï¼Œä¸€ç§ç»“åˆäº†å›¾ç¥ç»ç½‘ç»œ(GNNs)å’Œå·ç§¯ç¥ç»ç½‘ç»œ(CNNs)çš„é«˜æ•ˆæ··åˆæ¨¡å‹æ¶æ„ï¼Œæ—¨åœ¨è§£å†³Transformeræ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶å› äºŒæ¬¡è®¡ç®—å¤æ‚åº¦å¯¼è‡´çš„æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚è¯¥æ¨¡å‹é›†æˆäº†ä¸€ç§å®æ—¶çš„ç«¯åˆ°ç«¯å›¾ç”Ÿæˆæœºåˆ¶ï¼Œèƒ½å¤Ÿç›´æ¥å¤„ç†ç´§å‡‘çš„å­—ç¬¦çº§è¾“å…¥ä¸”æ— éœ€å¡«å……æˆ–æˆªæ–­ï¼ŒåŒæ—¶é€šè¿‡é«˜æ•ˆçš„å­—å…¸æŸ¥æ‰¾æŠ€æœ¯èå…¥äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„Token Embeddingså’Œæƒ…æ„Ÿææ€§ç­‰ä¿¡æ¯ã€‚åœ¨ç»“æ„è®¾è®¡ä¸Šï¼Œæ¨¡å‹åˆ©ç”¨CNNæ•æ‰å±€éƒ¨ä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œé€šè¿‡åŸºäºæ™¶æ ¼(Lattice-based)çš„å›¾ç»“æ„æ‰©å±•å±€éƒ¨æ„Ÿå—é‡ï¼Œå¹¶é‡‡ç”¨å°ä¸–ç•Œå›¾(Small-world Graphs)èšåˆæ–‡æ¡£çº§ä¿¡æ¯ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥ç”Ÿæˆçš„å›¾ç»“æ„è¡¨ç°å‡ºæ˜¾è‘—çš„è¯­ä¹‰ç»„ç»‡ç‰¹æ€§ï¼Œå…¶å¹³å‡èšç±»ç³»æ•°çº¦ä¸º0.45ã€‚æœ€ç»ˆåœ¨æƒ…æ„Ÿåˆ†æå’Œæ–°é—»åˆ†ç±»ç­‰å¤šé¡¹æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹è¯æ˜äº†å…¶åœ¨ç»´æŒæé«˜è¿è¡Œæ•ˆç‡çš„åŒæ—¶ï¼Œå…·æœ‰ä¸å½“å‰æœ€å…ˆè¿›æ¨¡å‹ç«äº‰çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07414v1",
      "published_date": "2025-07-10 04:13:53 UTC",
      "updated_date": "2025-07-10 04:13:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:07.258879+00:00"
    },
    {
      "arxiv_id": "2507.07413v1",
      "title": "Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks",
      "title_zh": "é¢å‘ç‰©è”ç½‘é›¶æ—¥å¨èƒçš„æ··åˆ LLM å¢å¼ºå‹å…¥ä¾µæ£€æµ‹",
      "authors": [
        "Mohammad F. Al-Hammouri",
        "Yazan Otoum",
        "Rasha Atwa",
        "Amiya Nayak"
      ],
      "abstract": "This paper presents a novel approach to intrusion detection by integrating traditional signature-based methods with the contextual understanding capabilities of the GPT-2 Large Language Model (LLM). As cyber threats become increasingly sophisticated, particularly in distributed, heterogeneous, and resource-constrained environments such as those enabled by the Internet of Things (IoT), the need for dynamic and adaptive Intrusion Detection Systems (IDSs) becomes increasingly urgent. While traditional methods remain effective for detecting known threats, they often fail to recognize new and evolving attack patterns. In contrast, GPT-2 excels at processing unstructured data and identifying complex semantic relationships, making it well-suited to uncovering subtle, zero-day attack vectors. We propose a hybrid IDS framework that merges the robustness of signature-based techniques with the adaptability of GPT-2-driven semantic analysis. Experimental evaluations on a representative intrusion dataset demonstrate that our model enhances detection accuracy by 6.3%, reduces false positives by 9.0%, and maintains near real-time responsiveness. These results affirm the potential of language model integration to build intelligent, scalable, and resilient cybersecurity defences suited for modern connected environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ··åˆå¼å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(IDS)æ¡†æ¶ï¼Œæ—¨åœ¨åº”å¯¹ç‰©è”ç½‘(IoT)ç½‘ç»œä¸­æ—¥ç›Šå¤æ‚çš„ç½‘ç»œå¨èƒï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹é›¶æ—¥æ”»å‡»(Zero-Day Threats)ã€‚è¯¥æ¡†æ¶å°†ä¼ ç»Ÿçš„åŸºäºç‰¹å¾(Signature-based)çš„æ£€æµ‹æ–¹æ³•ä¸GPT-2å¤§å‹è¯­è¨€æ¨¡å‹(LLM)çš„ä¸Šä¸‹æ–‡ç†è§£åŠè¯­ä¹‰åˆ†æèƒ½åŠ›ç›¸ç»“åˆã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥è¯†åˆ«æ¼”å˜ä¸­æ”»å‡»æ¨¡å¼çš„é—®é¢˜ï¼ŒGPT-2å‡­å€Ÿå…¶å¤„ç†éç»“æ„åŒ–æ•°æ®å’Œè¯†åˆ«å¤æ‚è¯­ä¹‰å…³ç³»çš„é•¿å¤„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŒ–æ˜ç»†å¾®çš„æ”»å‡»å‘é‡ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨ä»£è¡¨æ€§å…¥ä¾µæ•°æ®é›†ä¸Šå°†æ£€æµ‹å‡†ç¡®ç‡æå‡äº†6.3%ï¼Œè¯¯æŠ¥ç‡é™ä½äº†9.0%ï¼Œå¹¶ç»´æŒäº†æ¥è¿‘å®æ—¶çš„å“åº”é€Ÿåº¦ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†å°†è¯­è¨€æ¨¡å‹é›†æˆåˆ°ç°ä»£åŒ–äº’è”ç¯å¢ƒé˜²å¾¡ä½“ç³»ä¸­ï¼Œå¯¹äºæ„å»ºæ™ºèƒ½ã€å¯æ‰©å±•ä¸”å…·éŸ§æ€§çš„ç½‘ç»œå®‰å…¨å±éšœå…·æœ‰é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, IEEE conference",
      "pdf_url": "https://arxiv.org/pdf/2507.07413v1",
      "published_date": "2025-07-10 04:10:03 UTC",
      "updated_date": "2025-07-10 04:10:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:11.924385+00:00"
    },
    {
      "arxiv_id": "2507.07406v1",
      "title": "Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models",
      "title_zh": "ç”Ÿæˆå¼ AI æ—¶ä»£çš„ç½‘ç»œé’“é±¼æ£€æµ‹ï¼šé‡åŒ–å¤§è¯­è¨€æ¨¡å‹ä¸ç»å…¸æ¨¡å‹çš„å¯¹æ¯”",
      "authors": [
        "Jikesh Thapa",
        "Gurrehmat Chahal",
        "Serban Voinea Gabreanu",
        "Yazan Otoum"
      ],
      "abstract": "Phishing attacks are becoming increasingly sophisticated, underscoring the need for detection systems that strike a balance between high accuracy and computational efficiency. This paper presents a comparative evaluation of traditional Machine Learning (ML), Deep Learning (DL), and quantized small-parameter Large Language Models (LLMs) for phishing detection. Through experiments on a curated dataset, we show that while LLMs currently underperform compared to ML and DL methods in terms of raw accuracy, they exhibit strong potential for identifying subtle, context-based phishing cues. We also investigate the impact of zero-shot and few-shot prompting strategies, revealing that LLM-rephrased emails can significantly degrade the performance of both ML and LLM-based detectors. Our benchmarking highlights that models like DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above 80%, using only 17GB of VRAM, supporting their viability for cost-efficient deployment. We further assess the models' adversarial robustness and cost-performance tradeoffs, and demonstrate how lightweight LLMs can provide concise, interpretable explanations to support real-time decision-making. These findings position optimized LLMs as promising components in phishing defence systems and offer a path forward for integrating explainable, efficient AI into modern cybersecurity frameworks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ—¶ä»£æ—¥ç›Šå¤æ‚çš„ç½‘ç»œé’“é±¼æ”»å‡»ï¼Œå¯¹æ¯”è¯„ä¼°äº†ä¼ ç»Ÿæœºå™¨å­¦ä¹ (ML)ã€æ·±åº¦å­¦ä¹ (DL)ä¸é‡åŒ–å°å‚æ•°å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ£€æµ‹æ€§èƒ½ä¸Šçš„å·®å¼‚ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶LLMsåœ¨çº¯å‡†ç¡®ç‡ä¸Šç›®å‰ç•¥é€Šäºä¼ ç»Ÿçš„MLå’ŒDLæ–¹æ³•ï¼Œä½†åœ¨è¯†åˆ«å¾®å¦™çš„è¯­å¢ƒé’“é±¼çº¿ç´¢æ–¹é¢å±•ç°å‡ºå¼ºå¤§æ½œåŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒDeepSeek R1 Distill Qwen 14B (Q8_0)æ¨¡å‹åœ¨ä»…ä½¿ç”¨17GBæ˜¾å­˜(VRAM)çš„æƒ…å†µä¸‹å®ç°äº†è¶…è¿‡80%çš„å‡†ç¡®ç‡ï¼Œè¯æ˜äº†å…¶åœ¨æˆæœ¬æ•ˆç›Šéƒ¨ç½²æ–¹é¢çš„å¯è¡Œæ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†åˆ©ç”¨LLMé‡å†™çš„ç”µå­é‚®ä»¶ä¼šæ˜¾è‘—é™ä½ç°æœ‰æ£€æµ‹å™¨çš„é˜²å¾¡æ€§èƒ½ï¼Œå¹¶å±•ç¤ºäº†è½»é‡çº§LLMså¦‚ä½•é€šè¿‡æä¾›ç®€æ´ã€å¯è§£é‡Šçš„è¯´æ˜æ¥æ”¯æŒå®æ—¶å†³ç­–ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œç»è¿‡ä¼˜åŒ–çš„è½»é‡çº§LLMsæœ‰æœ›æˆä¸ºç°ä»£ç½‘ç»œå®‰å…¨æ¡†æ¶ä¸­å…¼é¡¾æ•ˆç‡ä¸å¯è§£é‡Šæ€§çš„é‡è¦ç»„ä»¶ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "8 Pages, IEEE Conference",
      "pdf_url": "https://arxiv.org/pdf/2507.07406v1",
      "published_date": "2025-07-10 04:01:52 UTC",
      "updated_date": "2025-07-10 04:01:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:12.781529+00:00"
    },
    {
      "arxiv_id": "2507.07405v1",
      "title": "HGMP:Heterogeneous Graph Multi-Task Prompt Learning",
      "title_zh": "HGMPï¼šå¼‚è´¨å›¾å¤šä»»åŠ¡æç¤ºå­¦ä¹ ",
      "authors": [
        "Pengfei Jiao",
        "Jialong Ni",
        "Di Jin",
        "Xuan Guo",
        "Huan Liu",
        "Hongjiang Chen",
        "Yanxian Bi"
      ],
      "abstract": "The pre-training and fine-tuning methods have gained widespread attention in the field of heterogeneous graph neural networks due to their ability to leverage large amounts of unlabeled data during the pre-training phase, allowing the model to learn rich structural features. However, these methods face the issue of a mismatch between the pre-trained model and downstream tasks, leading to suboptimal performance in certain application scenarios. Prompt learning methods have emerged as a new direction in heterogeneous graph tasks, as they allow flexible adaptation of task representations to address target inconsistency. Building on this idea, this paper proposes a novel multi-task prompt framework for the heterogeneous graph domain, named HGMP. First, to bridge the gap between the pre-trained model and downstream tasks, we reformulate all downstream tasks into a unified graph-level task format. Next, we address the limitations of existing graph prompt learning methods, which struggle to integrate contrastive pre-training strategies in the heterogeneous graph domain. We design a graph-level contrastive pre-training strategy to better leverage heterogeneous information and enhance performance in multi-task scenarios. Finally, we introduce heterogeneous feature prompts, which enhance model performance by refining the representation of input graph features. Experimental results on public datasets show that our proposed method adapts well to various tasks and significantly outperforms baseline methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HGMPï¼Œä¸€ç§é’ˆå¯¹å¼‚æ„å›¾(Heterogeneous Graph)é¢†åŸŸçš„å¤šä»»åŠ¡æç¤ºæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é¢„è®­ç»ƒæ¨¡å‹ä¸ä¸‹æ¸¸ä»»åŠ¡ä¹‹é—´ç”±äºç›®æ ‡ä¸ä¸€è‡´å¯¼è‡´çš„æ€§èƒ½å±€é™ã€‚ä¸ºäº†å¼¥è¡¥ä¸¤è€…é—´çš„å·®å¼‚ï¼ŒHGMPå°†å„ç±»ä¸‹æ¸¸ä»»åŠ¡é‡æ–°æ„å»ºä¸ºç»Ÿä¸€çš„å›¾çº§ä»»åŠ¡(graph-level task)æ ¼å¼ï¼Œå®ç°äº†ä»»åŠ¡è¡¨ç¤ºçš„çµæ´»é€‚é…ã€‚è¯¥æ¡†æ¶ç‰¹åˆ«è®¾è®¡äº†å›¾çº§å¯¹æ¯”é¢„è®­ç»ƒ(contrastive pre-training)ç­–ç•¥ï¼Œä»¥æœ‰æ•ˆæ•è·å¤æ‚çš„å¼‚æ„ä¿¡æ¯å¹¶å¢å¼ºå¤šä»»åŠ¡åœºæ™¯ä¸‹çš„æ¨¡å‹è¡¨ç°ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†å¼‚æ„ç‰¹å¾æç¤º(heterogeneous feature prompts)ï¼Œé€šè¿‡ç²¾ç»†åŒ–è¾“å…¥ç‰¹å¾çš„è¡¨ç¤ºæ¥è¿›ä¸€æ­¥ä¼˜åŒ–ç»“æœã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒHGMPèƒ½å¤Ÿé€‚åº”å¤šç§ä»»åŠ¡éœ€æ±‚ï¼Œä¸”åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 25th International Joint Conference on Artificial Intelligence (IJCAI-25)",
      "pdf_url": "https://arxiv.org/pdf/2507.07405v1",
      "published_date": "2025-07-10 04:01:47 UTC",
      "updated_date": "2025-07-10 04:01:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:15.186625+00:00"
    },
    {
      "arxiv_id": "2507.08875v1",
      "title": "A New Approach for Multicriteria Assessment in the Ranking of Alternatives Using Cardinal and Ordinal Data",
      "title_zh": "ä¸€ç§åˆ©ç”¨åŸºæ•°ä¸åºæ•°æ•°æ®è¿›è¡Œå¤‡é€‰æ–¹æ¡ˆæ’åºçš„å¤šå‡†åˆ™è¯„ä¼°æ–°æ–¹æ³•",
      "authors": [
        "Fuh-Hwa Franklin Liu",
        "Su-Chuan Shih"
      ],
      "abstract": "Modern methods for multi-criteria assessment (MCA), such as Data Envelopment Analysis (DEA), Stochastic Frontier Analysis (SFA), and Multiple Criteria Decision-Making (MCDM), are utilized to appraise a collection of Decision-Making Units (DMUs), also known as alternatives, based on several criteria. These methodologies inherently rely on assumptions and can be influenced by subjective judgment to effectively tackle the complex evaluation challenges in various fields. In real-world scenarios, it is essential to incorporate both quantitative and qualitative criteria as they consist of cardinal and ordinal data. Despite the inherent variability in the criterion values of different alternatives, the homogeneity assumption is often employed, significantly affecting evaluations. To tackle these challenges and determine the most appropriate alternative, we propose a novel MCA approach that combines two Virtual Gap Analysis (VGA) models. The VGA framework, rooted in linear programming, is pivotal in the MCA methodology. This approach improves efficiency and fairness, ensuring that evaluations are both comprehensive and dependable, thus offering a strong and adaptive solution. Two comprehensive numerical examples demonstrate the accuracy and transparency of our proposed method. The goal is to encourage continued advancement and stimulate progress in automated decision systems and decision support systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆä¸¤ä¸ªè™šæ‹Ÿå·®è·åˆ†æ(Virtual Gap Analysis, VGA)æ¨¡å‹çš„æ–°å‹å¤šå‡†åˆ™è¯„ä¼°(Multi-criteria assessment, MCA)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å†³ç­–å•å…ƒåœ¨æ¶‰åŠåŸºæ•°(cardinal)å’Œåºæ•°(ordinal)æ•°æ®æ—¶çš„æ’åºéš¾é¢˜ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•å¦‚æ•°æ®åŒ…ç»œåˆ†æ(Data Envelopment Analysis, DEA)å’Œå¤šå‡†åˆ™å†³ç­–(MCDM)ä¸­å­˜åœ¨çš„åŒè´¨æ€§å‡è®¾åŠä¸»è§‚åˆ¤æ–­å±€é™æ€§ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨åŸºäºçº¿æ€§è§„åˆ’(linear programming)çš„VGAæ¡†æ¶ï¼Œæœ‰æ•ˆæ•´åˆäº†å®šé‡ä¸å®šæ€§è¯„ä»·æ ‡å‡†ã€‚é€šè¿‡ä¼˜åŒ–è¯„ä¼°æµç¨‹ï¼Œè¯¥ç ”ç©¶ä¸ä»…æ˜¾è‘—æå‡äº†è¯„ä»·çš„æ•ˆç‡ä¸å…¬å¹³æ€§ï¼Œè¿˜ç¡®ä¿äº†ç»“æœçš„å…¨é¢æ€§ä¸ç¨³å¥æ€§ã€‚é€šè¿‡ä¸¤ä¸ªè¯¦å°½çš„æ•°å€¼ç®—ä¾‹ï¼Œå®éªŒéªŒè¯äº†æ‰€ææ–¹æ³•åœ¨å†³ç­–è¿‡ç¨‹ä¸­çš„é«˜åº¦å‡†ç¡®æ€§ä¸é€æ˜åº¦ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºè‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿ(automated decision systems)å’Œå†³ç­–æ”¯æŒç³»ç»Ÿ(decision support systems)çš„è¿›ä¸€æ­¥å‘å±•æä¾›äº†æ›´å…·é€‚åº”æ€§çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "38 pages, 6 figures, 5 table. A practice applicable method for multi-criteria assessments using cardinal and ordinal data",
      "pdf_url": "https://arxiv.org/pdf/2507.08875v1",
      "published_date": "2025-07-10 04:00:48 UTC",
      "updated_date": "2025-07-10 04:00:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:25.270905+00:00"
    },
    {
      "arxiv_id": "2507.07399v2",
      "title": "Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization",
      "title_zh": "å¹¿ä¹‰æ ‘ç¼–è¾‘è·ç¦» (GTED)ï¼šå‘½é¢˜è‡ªåŠ¨å½¢å¼åŒ–çš„ä¸€ç§å¯é è¯„ä¼°æŒ‡æ ‡",
      "authors": [
        "Yuntian Liu",
        "Tao Zhu",
        "Xiaoyang Liu",
        "Yu Chen",
        "Zhaoxuan Liu",
        "Qingfeng Guo",
        "Jiashuo Zhang",
        "Kangjie Bao",
        "Tao Luo"
      ],
      "abstract": "Statement autoformalization, the automated translation of statements from natural language into formal languages, has become a subject of extensive research, yet the development of robust automated evaluation metrics remains limited. Existing evaluation methods often lack semantic understanding, face challenges with high computational costs, and are constrained by the current progress of automated theorem proving. To address these issues, we propose GTED (Generalized Tree Edit Distance), a novel evaluation framework that first standardizes formal statements and converts them into operator trees, then determines the semantic similarity using the eponymous GTED metric. Across the miniF2F and ProofNet benchmarks, GTED consistently ranks as a top-performing metric, achieving the highest accuracy and Kappa on miniF2F and the joint-highest accuracy on ProofNet. This strong overall performance provides the community with a computationally lightweight and more faithful metric for automated evaluation. The code and experimental results are available at https://github.com/XiaoyangLiu-sjtu/GTED.",
      "tldr_zh": "å‘½é¢˜è‡ªåŠ¨å½¢å¼åŒ–ï¼ˆStatement Autoformalizationï¼‰æ˜¯å°†è‡ªç„¶è¯­è¨€ç¿»è¯‘ä¸ºå½¢å¼åŒ–è¯­è¨€çš„å…³é”®æŠ€æœ¯ï¼Œä½†ç°æœ‰çš„è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡åœ¨è¯­ä¹‰ç†è§£ã€è®¡ç®—æˆæœ¬åŠå¯¹è‡ªåŠ¨åŒ–å®šç†è¯æ˜çš„ä¾èµ–æ–¹é¢å­˜åœ¨å±€é™ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºäº†å¹¿ä¹‰æ ‘ç¼–è¾‘è·ç¦»ï¼ˆGeneralized Tree Edit Distanceï¼Œç®€ç§° GTEDï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ ‡å‡†åŒ–å¤„ç†å°†å½¢å¼åŒ–å‘½é¢˜è½¬æ¢ä¸ºç®—å­æ ‘ï¼ˆOperator Treesï¼‰ï¼Œå¹¶åˆ©ç”¨ GTED æŒ‡æ ‡è®¡ç®—ä¸¤è€…çš„è¯­ä¹‰ç›¸ä¼¼åº¦ã€‚åœ¨ miniF2F å’Œ ProofNet åŸºå‡†æµ‹è¯•ä¸­ï¼ŒGTED è¡¨ç°ä¸€è‡´ä¼˜äºç°æœ‰æŒ‡æ ‡ï¼Œåœ¨ miniF2F ä¸Šå–å¾—äº†æœ€é«˜çš„å‡†ç¡®ç‡å’Œ Kappa å€¼ï¼Œå¹¶åœ¨ ProofNet ä¸Šè¾¾åˆ°äº†å¹¶åˆ—æœ€é«˜çš„å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶è¯æ˜ GTED æ˜¯ä¸€ç§è®¡ç®—è½»é‡ä¸”è¯„ä»·æ›´å¯é ï¼ˆFaithfulï¼‰çš„æŒ‡æ ‡ï¼Œä¸ºè‡ªåŠ¨å½¢å¼åŒ–é¢†åŸŸçš„ç§‘ç ”ç¤¾åŒºæä¾›äº†æ›´æœ‰æ•ˆçš„è¡¡é‡æ‰‹æ®µã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AI4Math@ICML25",
      "pdf_url": "https://arxiv.org/pdf/2507.07399v2",
      "published_date": "2025-07-10 03:34:58 UTC",
      "updated_date": "2025-08-22 13:20:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:26.131517+00:00"
    },
    {
      "arxiv_id": "2507.07394v1",
      "title": "Behave Your Motion: Habit-preserved Cross-category Animal Motion Transfer",
      "title_zh": "Behave Your Motionï¼šä¿ç•™ä¹ æ€§çš„è·¨ç±»åˆ«åŠ¨ç‰©åŠ¨ä½œè¿ç§»",
      "authors": [
        "Zhimin Zhang",
        "Bi'an Du",
        "Caoyuan Ma",
        "Zheng Wang",
        "Wei Hu"
      ],
      "abstract": "Animal motion embodies species-specific behavioral habits, making the transfer of motion across categories a critical yet complex task for applications in animation and virtual reality. Existing motion transfer methods, primarily focused on human motion, emphasize skeletal alignment (motion retargeting) or stylistic consistency (motion style transfer), often neglecting the preservation of distinct habitual behaviors in animals. To bridge this gap, we propose a novel habit-preserved motion transfer framework for cross-category animal motion. Built upon a generative framework, our model introduces a habit-preservation module with category-specific habit encoder, allowing it to learn motion priors that capture distinctive habitual characteristics. Furthermore, we integrate a large language model (LLM) to facilitate the motion transfer to previously unobserved species. To evaluate the effectiveness of our approach, we introduce the DeformingThings4D-skl dataset, a quadruped dataset with skeletal bindings, and conduct extensive experiments and quantitative analyses, which validate the superiority of our proposed model.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ¨ç‰©è¿åŠ¨ä¸­ç‰©ç§ç‰¹æœ‰çš„è¡Œä¸ºä¹ æƒ¯éš¾ä»¥è·¨ç±»åˆ«è¿ç§»çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä¿ç•™ä¹ æƒ¯çš„è·¨ç±»åˆ«åŠ¨ç‰©è¿åŠ¨è¿ç§»æ¡†æ¶ã€‚ç°æœ‰çš„è¿åŠ¨è¿ç§»æ–¹æ³•ä¸»è¦å…³æ³¨äººç±»éª¨éª¼é‡å®šå‘ (motion retargeting) æˆ–é£æ ¼è¿ç§» (motion style transfer)ï¼Œå¾€å¾€å¿½ç•¥äº†åŠ¨ç‰©ç‹¬ç‰¹çš„ä¹ æƒ¯æ€§è¡Œä¸ºã€‚è¯¥æ¡†æ¶åŸºäºç”Ÿæˆå¼æ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥åŒ…å«ç±»åˆ«ç‰¹å®šä¹ æƒ¯ç¼–ç å™¨ (habit encoder) çš„ä¹ æƒ¯ä¿ç•™æ¨¡å—ï¼Œå­¦ä¹ æ•æ‰ç‹¬ç‰¹ä¹ æƒ¯ç‰¹å¾çš„è¿åŠ¨å…ˆéªŒã€‚ç ”ç©¶è¿˜æ•´åˆäº†å¤§è¯­è¨€æ¨¡å‹ (LLM) ä»¥æ”¯æŒè¿åŠ¨å‘ä»æœªè§‚æµ‹åˆ°çš„ç‰©ç§è¿›è¡Œè¿ç§»ã€‚ä¸ºäº†éªŒè¯æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ä¸ªå¸¦æœ‰éª¨éª¼ç»‘å®šçš„å››è¶³åŠ¨ç‰©æ•°æ®é›† DeformingThings4D-sklã€‚å®éªŒç»“æœå’Œå®šé‡åˆ†æè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤„ç†è·¨ç±»åˆ«åŠ¨ç‰©è¿åŠ¨è¿ç§»ä»»åŠ¡æ—¶èƒ½å¤Ÿæœ‰æ•ˆä¿ç•™ç‰©ç§ä¹ æƒ¯ï¼Œå…·æœ‰æ˜¾è‘—çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07394v1",
      "published_date": "2025-07-10 03:25:50 UTC",
      "updated_date": "2025-07-10 03:25:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:47.053991+00:00"
    },
    {
      "arxiv_id": "2507.07393v3",
      "title": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos",
      "title_zh": "KeyRe-IDï¼šåŸºäºéƒ¨ä½æ„ŸçŸ¥è¡¨å¾çš„è§†é¢‘å…³é”®ç‚¹å¼•å¯¼è¡Œäººé‡è¯†åˆ«",
      "authors": [
        "Jinseong Kim",
        "Jeonghoon Song",
        "Gyeongseon Baek",
        "Byeongjoon Noh"
      ],
      "abstract": "We propose \\textbf{KeyRe-ID}, a keypoint-guided video-based person re-identification framework consisting of global and local branches that leverage human keypoints for enhanced spatiotemporal representation learning. The global branch captures holistic identity semantics through Transformer-based temporal aggregation, while the local branch dynamically segments body regions based on keypoints to generate fine-grained, part-aware features. Extensive experiments on MARS and iLIDS-VID benchmarks demonstrate state-of-the-art performance, achieving 91.73\\% mAP and 97.32\\% Rank-1 accuracy on MARS, and 96.00\\% Rank-1 and 100.0\\% Rank-5 accuracy on iLIDS-VID. The code for this work will be publicly available on GitHub upon publication.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†KeyRe-IDï¼Œä¸€ç§åŸºäºå…³é”®ç‚¹å¼•å¯¼(Keypoint-Guided)çš„è§†é¢‘è¡Œäººé‡è¯†åˆ«(Person Re-Identification)æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç”±å…¨å±€å’Œå±€éƒ¨ä¸¤ä¸ªåˆ†æ”¯ç»„æˆï¼Œæ—¨åœ¨åˆ©ç”¨äººä½“å…³é”®ç‚¹(Keypoints)å¢å¼ºæ—¶ç©ºè¡¨å¾å­¦ä¹ ã€‚å…¨å±€åˆ†æ”¯é€šè¿‡åŸºäºTransformerçš„æ—¶åºèšåˆ(Temporal Aggregation)æ•æ‰æ•´ä½“èº«ä»½è¯­ä¹‰ï¼Œè€Œå±€éƒ¨åˆ†æ”¯åˆ™æ ¹æ®å…³é”®ç‚¹åŠ¨æ€åˆ†å‰²èº«ä½“åŒºåŸŸï¼Œç”Ÿæˆç»†ç²’åº¦çš„å±€éƒ¨æ„ŸçŸ¥(Part-Aware)ç‰¹å¾ã€‚åœ¨MARSå’ŒiLIDS-VIDåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›(State-of-the-Art)çš„æ€§èƒ½æ°´å¹³ã€‚å…·ä½“è€Œè¨€ï¼ŒKeyRe-IDåœ¨MARSæ•°æ®é›†ä¸Šå®ç°äº†91.73%çš„mAPå’Œ97.32%çš„Rank-1å‡†ç¡®ç‡ï¼Œåœ¨iLIDS-VIDä¸Šåˆ™å–å¾—äº†96.00%çš„Rank-1å‡†ç¡®ç‡ã€‚è¿™äº›ç»“æœè¯æ˜äº†ç»“åˆå…³é”®ç‚¹ä¿¡æ¯çš„å±€éƒ¨ä¸å…¨å±€ç‰¹å¾å»ºæ¨¡åœ¨æå‡è§†é¢‘è¡Œäººé‡è¯†åˆ«ç²¾åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 2 figures,",
      "pdf_url": "https://arxiv.org/pdf/2507.07393v3",
      "published_date": "2025-07-10 03:15:57 UTC",
      "updated_date": "2025-07-17 02:04:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:57.916095+00:00"
    },
    {
      "arxiv_id": "2507.07376v1",
      "title": "PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments",
      "title_zh": "PILOCï¼šé¢å‘æœªçŸ¥ç¯å¢ƒä¸‹å¤šæ™ºèƒ½ä½“åŠ¨æ€ç›®æ ‡æœç´¢çš„ä¿¡æ¯ç´ åå‘å¼•å¯¼æœºåˆ¶åŠå±€éƒ¨é€šä¿¡æ¡†æ¶",
      "authors": [
        "Hengrui Liu",
        "Yi Feng",
        "Qilong Zhang"
      ],
      "abstract": "Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster response, exploration, and reconnaissance. However, dynamic and unknown environments pose significant challenges due to target unpredictability and environmental uncertainty. To tackle these issues, we propose PILOC, a framework that operates without global prior knowledge, leveraging local perception and communication. It introduces a pheromone inverse guidance mechanism to enable efficient coordination and dynamic target localization. PILOC promotes decentralized cooperation through local communication, significantly reducing reliance on global channels. Unlike conventional heuristics, the pheromone mechanism is embedded into the observation space of Deep Reinforcement Learning (DRL), supporting indirect agent coordination based on environmental cues. We further integrate this strategy into a DRL-based multi-agent architecture and conduct extensive experiments. Results show that combining local communication with pheromone-based guidance significantly boosts search efficiency, adaptability, and system robustness. Compared to existing methods, PILOC performs better under dynamic and communication-constrained scenarios, offering promising directions for future MASAR applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“æœæ•‘(Multi-Agent Search and Rescue, MASAR)åœ¨æœªçŸ¥åŠ¨æ€ç¯å¢ƒä¸­é¢ä¸´çš„ç›®æ ‡ä¸å¯é¢„æµ‹æ€§å’Œç¯å¢ƒä¸ç¡®å®šæ€§ï¼Œæå‡ºäº†PILOCæ¡†æ¶ã€‚è¯¥æ¡†æ¶æ— éœ€å…¨å±€å…ˆéªŒçŸ¥è¯†ï¼Œé€šè¿‡å±€éƒ¨æ„ŸçŸ¥å’Œå±€éƒ¨é€šä¿¡(Local Communication)å®ç°å»ä¸­å¿ƒåŒ–åˆä½œï¼Œæœ‰æ•ˆé™ä½äº†ç³»ç»Ÿå¯¹å…¨å±€ä¿¡é“çš„ä¾èµ–ã€‚ç ”ç©¶æ ¸å¿ƒå¼•å…¥äº†ä¿¡æ¯ç´ é€†å‘å¼•å¯¼æœºåˆ¶(Pheromone Inverse Guidance Mechanism)ï¼Œå¹¶å°†å…¶åµŒå…¥æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning, DRL)çš„è§‚æµ‹ç©ºé—´ï¼Œä»¥æ”¯æŒæ™ºèƒ½ä½“åŸºäºç¯å¢ƒçº¿ç´¢çš„é—´æ¥åè°ƒä¸åŠ¨æ€ç›®æ ‡å®šä½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆå±€éƒ¨é€šä¿¡ä¸ä¿¡æ¯ç´ å¼•å¯¼æ˜¾è‘—å¢å¼ºäº†æœç´¢æ•ˆç‡ã€é€‚åº”æ€§åŠç³»ç»Ÿé²æ£’æ€§ã€‚ç›¸æ¯”ç°æœ‰æ–¹æ³•ï¼ŒPILOCåœ¨åŠ¨æ€åŠé€šä¿¡å—é™åœºæ™¯ä¸‹å±•ç°å‡ºæ›´ä¼˜çš„æ€§èƒ½ï¼Œä¸ºæœªæ¥å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»æœæ•‘ä»»åŠ¡æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07376v1",
      "published_date": "2025-07-10 02:10:18 UTC",
      "updated_date": "2025-07-10 02:10:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:52.682917+00:00"
    },
    {
      "arxiv_id": "2507.07373v2",
      "title": "Atherosclerosis through Hierarchical Explainable Neural Network Analysis",
      "title_zh": "åŸºäºå±‚çº§åŒ–å¯è§£é‡Šç¥ç»ç½‘ç»œåˆ†æçš„åŠ¨è„‰ç²¥æ ·ç¡¬åŒ–",
      "authors": [
        "Irsyad Adam",
        "Steven Swee",
        "Erika Yilin",
        "Ethan Ji",
        "William Speier",
        "Dean Wang",
        "Alex Bui",
        "Wei Wang",
        "Karol Watson",
        "Peipei Ping"
      ],
      "abstract": "In this work, we study the problem pertaining to personalized classification of subclinical atherosclerosis by developing a hierarchical graph neural network framework to leverage two characteristic modalities of a patient: clinical features within the context of the cohort, and molecular data unique to individual patients. Current graph-based methods for disease classification detect patient-specific molecular fingerprints, but lack consistency and comprehension regarding cohort-wide features, which are an essential requirement for understanding pathogenic phenotypes across diverse atherosclerotic trajectories. Furthermore, understanding patient subtypes often considers clinical feature similarity in isolation, without integration of shared pathogenic interdependencies among patients. To address these challenges, we introduce ATHENA: Atherosclerosis Through Hierarchical Explainable Neural Network Analysis, which constructs a novel hierarchical network representation through integrated modality learning; subsequently, it optimizes learned patient-specific molecular fingerprints that reflect individual omics data, enforcing consistency with cohort-wide patterns. With a primary clinical dataset of 391 patients, we demonstrate that this heterogeneous alignment of clinical features with molecular interaction patterns has significantly boosted subclinical atherosclerosis classification performance across various baselines by up to 13% in area under the receiver operating curve (AUC) and 20% in F1 score. Taken together, ATHENA enables mechanistically-informed patient subtype discovery through explainable AI (XAI)-driven subnetwork clustering; this novel integration framework strengthens personalized intervention strategies, thereby improving the prediction of atherosclerotic disease progression and management of their clinical actionable outcomes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äºšä¸´åºŠåŠ¨è„‰ç²¥æ ·ç¡¬åŒ–(subclinical atherosclerosis)çš„ä¸ªæ€§åŒ–åˆ†ç±»é—®é¢˜ï¼Œå¼€å‘äº†åä¸ºATHENAï¼ˆAtherosclerosis Through Hierarchical Explainable Neural Network Analysisï¼‰çš„åˆ†å±‚å›¾ç¥ç»ç½‘ç»œæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆæ¨¡æ€å­¦ä¹ ï¼Œæœ‰æ•ˆæ•´åˆäº†é˜Ÿåˆ—èŒƒå›´å†…çš„ä¸´åºŠç‰¹å¾(clinical features)ä¸ä¸ªä½“ç‰¹æœ‰çš„åˆ†å­æ•°æ®(molecular data)ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨æ•æ‰æ‚£è€…ç‰¹å®šåˆ†å­æŒ‡çº¹æ—¶ç¼ºä¹é˜Ÿåˆ—ä¸€è‡´æ€§çš„éš¾é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨391åæ‚£è€…çš„æ•°æ®é›†ä¸Šï¼ŒATHENAåœ¨å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ä¸‹é¢ç§¯(AUC)å’ŒF1åˆ†æ•°ä¸Šåˆ†åˆ«æ¯”åŸºçº¿æ¨¡å‹æå‡äº†é«˜è¾¾13%å’Œ20%ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨å¯è§£é‡Šäººå·¥æ™ºèƒ½(XAI)é©±åŠ¨çš„å­ç½‘ç»œèšç±»ï¼Œå®ç°äº†æœºæ¢°è®ºå¯å‘çš„æ‚£è€…äºšå‹å‘ç°ã€‚è¿™é¡¹å·¥ä½œä¸ä»…å¢å¼ºäº†å¯¹ç—…ç†è¡¨å‹å¤šæ ·æ€§çš„ç†è§£ï¼Œä¹Ÿä¸ºå¼ºåŒ–ä¸ªæ€§åŒ–å¹²é¢„ç­–ç•¥å’Œç–¾ç—…è¿›å±•é¢„æµ‹æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07373v2",
      "published_date": "2025-07-10 01:51:53 UTC",
      "updated_date": "2025-09-12 01:02:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:58.055679+00:00"
    },
    {
      "arxiv_id": "2507.08045v2",
      "title": "Krul: Efficient State Restoration for Multi-turn Conversations with Dynamic Cross-layer KV Sharing",
      "title_zh": "Krulï¼šåŸºäºåŠ¨æ€è·¨å±‚ KV å…±äº«çš„å¤šè½®å¯¹è¯é«˜æ•ˆçŠ¶æ€æ¢å¤",
      "authors": [
        "Junyi Wen",
        "Junyuan Liang",
        "Zicong Hong",
        "Wuhui Chen",
        "Ting Cai",
        "Zibin Zheng"
      ],
      "abstract": "Efficient state restoration in multi-turn conversations with large language models (LLMs) remains a critical challenge, primarily due to the overhead of recomputing or loading full key-value (KV) caches for all historical tokens. To address this, existing approaches compress KV caches across adjacent layers with highly similar attention patterns. However, these methods often apply a fixed compression scheme across all conversations, selecting the same layer pairs for compression without considering conversation-specific attention dynamics. This static strategy overlooks variability in attention pattern similarity across different conversations, which can lead to noticeable accuracy degradation.\n  We present Krul, a multi-turn LLM inference system that enables accurate and efficient KV cache restoration. Krul dynamically selects compression strategies based on attention similarity across layer pairs and uses a recomputation-loading pipeline to restore the KV cache. It introduces three key innovations: 1) a preemptive compression strategy selector to preserve critical context for future conversation turns and selects a customized strategy for the conversation; 2) a token-wise heterogeneous attention similarity estimator to mitigate the attention similarity computation and storage overhead during model generation; 3) a bubble-free restoration scheduler to reduce potential bubbles brought by the imbalance of recomputing and loading stream due to compressed KV caches. Empirical evaluations on real-world tasks demonstrate that Krul achieves a 1.5x-2.68x reduction in time-to-first-token (TTFT) and a 1.33x-2.35x reduction in KV cache storage compared to state-of-the-art methods without compromising generation quality.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Krulï¼Œä¸€ç§é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å¤šè½®å¯¹è¯è®¾è®¡çš„é«˜æ•ˆçŠ¶æ€æ¢å¤ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç”±äºKey-Value (KV) cacheé‡è®¡ç®—æˆ–åŠ è½½å¯¼è‡´çš„æ¨ç†å»¶è¿Ÿé—®é¢˜ã€‚Krulå…‹æœäº†ç°æœ‰é™æ€å‹ç¼©æ–¹æ¡ˆæ— æ³•é€‚åº”ä¸åŒå¯¹è¯åŠ¨æ€æ³¨æ„åŠ›æ¨¡å¼çš„ç¼ºé™·ï¼Œé€šè¿‡åŠ¨æ€è·¨å±‚å…±äº«æŠ€æœ¯å®ç°ç²¾ç¡®ä¸”é«˜æ•ˆçš„ç¼“å­˜æ¢å¤ã€‚è¯¥ç³»ç»Ÿå¼•å…¥äº†æŠ¢å å¼ç­–ç•¥é€‰æ‹©å™¨(preemptive compression strategy selector)æ¥å®šåˆ¶å‹ç¼©æ–¹æ¡ˆï¼Œå¹¶åˆ©ç”¨é€Tokençš„å¼‚æ„æ³¨æ„åŠ›ç›¸ä¼¼åº¦ä¼°è®¡å™¨(token-wise heterogeneous attention similarity estimator)æ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼ŒKrulé‡‡ç”¨æ— æ°”æ³¡æ¢å¤è°ƒåº¦å™¨(bubble-free restoration scheduler)ä¼˜åŒ–äº†é‡è®¡ç®—ä¸åŠ è½½æµçš„å¹³è¡¡ï¼Œæœ‰æ•ˆæ¶ˆé™¤äº†æµæ°´çº¿æ°”æ³¡ã€‚å®éªŒè¯æ˜ï¼ŒKrulåœ¨ä¸æŸå¤±ç”Ÿæˆè´¨é‡çš„æƒ…å†µä¸‹ï¼Œä½¿é¦–å­—ç”Ÿæˆæ—¶é—´(Time-to-First-Token, TTFT)ç¼©çŸ­äº†1.5è‡³2.68å€ï¼Œå¹¶å‡å°‘äº†1.33è‡³2.35å€çš„KV cacheå­˜å‚¨å ç”¨ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08045v2",
      "published_date": "2025-07-10 01:51:17 UTC",
      "updated_date": "2025-08-26 01:55:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:58.673243+00:00"
    },
    {
      "arxiv_id": "2507.08873v1",
      "title": "Contrastive Language-Image Pre-Training Model based Semantic Communication Performance Optimization",
      "title_zh": "åŸºäºå¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒæ¨¡å‹çš„è¯­ä¹‰é€šä¿¡æ€§èƒ½ä¼˜åŒ–",
      "authors": [
        "Shaoran Yang",
        "Dongyu Wei",
        "Hanzhi Yu",
        "Zhaohui Yang",
        "Yuchen Liu",
        "Mingzhe Chen"
      ],
      "abstract": "In this paper, a novel contrastive language-image pre-training (CLIP) model based semantic communication framework is designed. Compared to standard neural network (e.g.,convolutional neural network) based semantic encoders and decoders that require joint training over a common dataset, our CLIP model based method does not require any training procedures thus enabling a transmitter to extract data meanings of the original data without neural network model training, and the receiver to train a neural network for follow-up task implementation without the communications with the transmitter. Next, we investigate the deployment of the CLIP model based semantic framework over a noisy wireless network. Since the semantic information generated by the CLIP model is susceptible to wireless noise and the spectrum used for semantic information transmission is limited, it is necessary to jointly optimize CLIP model architecture and spectrum resource block (RB) allocation to maximize semantic communication performance while considering wireless noise, the delay and energy used for semantic communication. To achieve this goal, we use a proximal policy optimization (PPO) based reinforcement learning (RL) algorithm to learn how wireless noise affect the semantic communication performance thus finding optimal CLIP model and RB for each user. Simulation results show that our proposed method improves the convergence rate by up to 40%, and the accumulated reward by 4x compared to soft actor-critic.",
      "tldr_zh": "è¯¥ç ”ç©¶è®¾è®¡äº†ä¸€ç§åŸºäºå¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒæ¨¡å‹(CLIP)çš„æ–°å‹è¯­ä¹‰é€šä¿¡æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºå·ç§¯ç¥ç»ç½‘ç»œ(CNN)ä¸”éœ€è¦è”åˆè®­ç»ƒçš„è¯­ä¹‰ç¼–è§£ç å™¨ä¸åŒï¼Œè¯¥CLIPæ¡†æ¶æ— éœ€ä»»ä½•è®­ç»ƒè¿‡ç¨‹ï¼Œä½¿å‘å°„ç«¯èƒ½å¤Ÿç›´æ¥æå–åŸå§‹æ•°æ®å«ä¹‰ï¼Œä¸”æ¥æ”¶ç«¯æ— éœ€ä¸å‘å°„ç«¯é€šä¿¡å³å¯å®Œæˆåç»­ä»»åŠ¡è®­ç»ƒã€‚ä¸ºäº†è§£å†³CLIPç”Ÿæˆçš„è¯­ä¹‰ä¿¡æ¯å¯¹æ— çº¿å™ªå£°æ•æ„Ÿä»¥åŠé¢‘è°±èµ„æºæœ‰é™çš„é—®é¢˜ï¼Œç ”ç©¶æå‡ºè”åˆä¼˜åŒ–CLIPæ¨¡å‹æ¶æ„å’Œé¢‘è°±èµ„æºå—(RB)åˆ†é…ï¼Œä»¥åœ¨è€ƒè™‘å»¶è¿Ÿå’Œèƒ½è€—çš„æƒ…å†µä¸‹æœ€å¤§åŒ–é€šä¿¡æ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶é‡‡ç”¨åŸºäºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)çš„å¼ºåŒ–å­¦ä¹ (RL)ç®—æ³•ï¼Œå­¦ä¹ æ— çº¿å™ªå£°å¯¹è¯­ä¹‰é€šä¿¡çš„å½±å“ï¼Œå¹¶ä¸ºæ¯ä¸ªç”¨æˆ·åŒ¹é…æœ€ä¼˜çš„CLIPæ¨¡å‹å’ŒRBã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•ç›¸è¾ƒäºè½¯è¡ŒåŠ¨è€…-è¯„è®ºå®¶(Soft Actor-Critic)ç®—æ³•ï¼Œæ”¶æ•›é€Ÿåº¦æé«˜äº†çº¦40%ï¼Œç´¯ç§¯å¥–åŠ±æå‡äº†4å€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE GLOBECOM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.08873v1",
      "published_date": "2025-07-10 01:48:56 UTC",
      "updated_date": "2025-07-10 01:48:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:00:58.402610+00:00"
    },
    {
      "arxiv_id": "2507.07359v1",
      "title": "Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning",
      "title_zh": "é¢å‘å› æœå­¦ä¹ çš„ç›®æ ‡å¯¼å‘åºè´¯è´å¶æ–¯å®éªŒè®¾è®¡",
      "authors": [
        "Zheyu Zhang",
        "Jiayuan Dong",
        "Jie Liu",
        "Xun Huan"
      ],
      "abstract": "We present GO-CBED, a goal-oriented Bayesian framework for sequential causal experimental design. Unlike conventional approaches that select interventions aimed at inferring the full causal model, GO-CBED directly maximizes the expected information gain (EIG) on user-specified causal quantities of interest, enabling more targeted and efficient experimentation. The framework is both non-myopic, optimizing over entire intervention sequences, and goal-oriented, targeting only model aspects relevant to the causal query. To address the intractability of exact EIG computation, we introduce a variational lower bound estimator, optimized jointly through a transformer-based policy network and normalizing flow-based variational posteriors. The resulting policy enables real-time decision-making via an amortized network. We demonstrate that GO-CBED consistently outperforms existing baselines across various causal reasoning and discovery tasks-including synthetic structural causal models and semi-synthetic gene regulatory networks-particularly in settings with limited experimental budgets and complex causal mechanisms. Our results highlight the benefits of aligning experimental design objectives with specific research goals and of forward-looking sequential planning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GO-CBEDï¼Œä¸€ç§é¢å‘ç›®æ ‡çš„åºè´¯è´å¶æ–¯å› æœå®éªŒè®¾è®¡æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ›´å…·é’ˆå¯¹æ€§çš„å®éªŒæé«˜å› æœå­¦ä¹ çš„æ•ˆç‡ã€‚ä¸ä¼ ç»Ÿæ¨æ–­å®Œæ•´å› æœæ¨¡å‹çš„æ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶ç›´æ¥æœ€å¤§åŒ–ç”¨æˆ·æ„Ÿå…´è¶£çš„ç‰¹å®šå› æœé‡çš„æœŸæœ›ä¿¡æ¯å¢ç›Š(Expected Information Gain, EIG)ï¼Œç¡®ä¿å®éªŒè®¾è®¡ç´§æ‰£ç‰¹å®šçš„ç ”ç©¶æŸ¥è¯¢ã€‚GO-CBED å…·å¤‡éè¿‘è§†æ€§(non-myopic)ç‰¹å¾ï¼Œèƒ½å¤Ÿå¯¹æ•´ä¸ªå¹²é¢„åºåˆ—è¿›è¡Œå…¨å±€ä¼˜åŒ–ï¼Œå¹¶ç»“åˆäº†åŸºäº Transformer çš„ç­–ç•¥ç½‘ç»œå’ŒåŸºäºæ­£è§„åŒ–æµ(normalizing flow)çš„å˜åˆ†åéªŒä¼°è®¡å™¨ä»¥å®ç°å®æ—¶å†³ç­–ã€‚åœ¨åˆæˆç»“æ„å› æœæ¨¡å‹(Structural Causal Models)å’ŒåŸºå› è°ƒèŠ‚ç½‘ç»œç­‰ä»»åŠ¡ä¸­çš„å®éªŒç»“æœè¯æ˜ï¼ŒGO-CBED åœ¨æœ‰é™å®éªŒé¢„ç®—å’Œå¤æ‚å› æœæœºåˆ¶ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ã€‚è¯¥æˆæœå‡¸æ˜¾äº†å°†å®éªŒè®¾è®¡ç›®æ ‡ä¸å…·ä½“ç ”ç©¶ç›®æ ‡å¯¹é½ä»¥åŠè¿›è¡Œå‰ç»æ€§åºè´¯è§„åˆ’åœ¨å› æœæ¨ç†ä¸å‘ç°ä¸­çš„é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07359v1",
      "published_date": "2025-07-10 00:53:57 UTC",
      "updated_date": "2025-07-10 00:53:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:01:20.445022+00:00"
    },
    {
      "arxiv_id": "2507.07355v1",
      "title": "Supply Chain Optimization via Generative Simulation and Iterative Decision Policies",
      "title_zh": "åŸºäºç”Ÿæˆå¼ä»¿çœŸä¸è¿­ä»£å†³ç­–ç­–ç•¥çš„ä¾›åº”é“¾ä¼˜åŒ–",
      "authors": [
        "Haoyue Bai",
        "Haoyu Wang",
        "Nanxu Gong",
        "Xinyuan Wang",
        "Wangyang Ying",
        "Haifeng Chen",
        "Yanjie Fu"
      ],
      "abstract": "High responsiveness and economic efficiency are critical objectives in supply chain transportation, both of which are influenced by strategic decisions on shipping mode. An integrated framework combining an efficient simulator with an intelligent decision-making algorithm can provide an observable, low-risk environment for transportation strategy design. An ideal simulation-decision framework must (1) generalize effectively across various settings, (2) reflect fine-grained transportation dynamics, (3) integrate historical experience with predictive insights, and (4) maintain tight integration between simulation feedback and policy refinement. We propose Sim-to-Dec framework to satisfy these requirements. Specifically, Sim-to-Dec consists of a generative simulation module, which leverages autoregressive modeling to simulate continuous state changes, reducing dependence on handcrafted domain-specific rules and enhancing robustness against data fluctuations; and a history-future dual-aware decision model, refined iteratively through end-to-end optimization with simulator interactions. Extensive experiments conducted on three real-world datasets demonstrate that Sim-to-Dec significantly improves timely delivery rates and profit.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¾›åº”é“¾è¿è¾“ä¸­é«˜å“åº”æ€§å’Œç»æµæ•ˆç‡çš„å…³é”®ç›®æ ‡ï¼Œæå‡ºäº† Sim-to-Dec æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡é«˜æ•ˆæ¨¡æ‹Ÿå™¨ä¸æ™ºèƒ½å†³ç­–ç®—æ³•çš„ç»“åˆæ¥ä¼˜åŒ–è¿è¾“ç­–ç•¥è®¾è®¡ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸€ä¸ªç”Ÿæˆå¼æ¨¡æ‹Ÿæ¨¡å—ï¼Œåˆ©ç”¨è‡ªå›å½’å»ºæ¨¡ (autoregressive modeling) æ¨¡æ‹Ÿè¿ç»­çš„çŠ¶æ€å˜åŒ–ï¼Œæœ‰æ•ˆå‡å°‘äº†å¯¹æ‰‹å·¥é¢†åŸŸè§„åˆ™çš„ä¾èµ–å¹¶å¢å¼ºäº†å¯¹æ•°æ®æ³¢åŠ¨çš„é²æ£’æ€§ã€‚åŒæ—¶ï¼Œç³»ç»Ÿé‡‡ç”¨å†å²-æœªæ¥åŒæ„ŸçŸ¥å†³ç­–æ¨¡å‹ (history-future dual-aware decision model)ï¼Œé€šè¿‡ä¸æ¨¡æ‹Ÿå™¨çš„é—­ç¯äº¤äº’è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œå®ç°äº†å†³ç­–ç­–ç•¥çš„æŒç»­è¿­ä»£æ”¹è¿›ã€‚åœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒSim-to-Dec èƒ½å¤Ÿæ˜¾è‘—æé«˜åŠæ—¶äº¤ä»˜ç‡å’Œåˆ©æ¶¦æ°´å¹³ã€‚è¯¥ç ”ç©¶ä¸ºå¤æ‚çš„è¿è¾“åŠ¨åŠ›å­¦æä¾›äº†ä¸€ä¸ªå¯è§‚å¯Ÿã€ä½é£é™©çš„æ¨¡æ‹Ÿä¸å†³ç­–ç¯å¢ƒï¼ŒæˆåŠŸæ•´åˆäº†å†å²ç»éªŒä¸é¢„æµ‹æ€§è§è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07355v1",
      "published_date": "2025-07-10 00:41:15 UTC",
      "updated_date": "2025-07-10 00:41:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:01:10.346090+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 128,
  "processed_papers_count": 128,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T04:02:15.420058+00:00"
}