{
  "date": "2024-05-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-14 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 64 篇论文，主要聚焦于 AI 模型能力评估、LLM（Large Language Models）应用、医疗图像分析和高效深度学习训练等领域。其中，令人印象深刻的包括姚富（Yao Fu）关于长上下文 Transformer 部署挑战的分析，以及 LLM 在哲学和实际应用（如粒子加速器调优）的创新探索；知名学者如 Jason Mars 等参与的论文也值得关注。\n\n下面，我将挑选并讨论最具影响力和话题度的论文，先从核心主题入手，将相关论文归并讨论。对于次要或技术细节较少的论文（如一些纯算法优化或小数据集实验），我将快速掠过，只列出标题和简要要点，以保持篇幅简洁。\n\n### LLM 和 AI 模型能力\n- **What is it for a Machine Learning Model to Have a Capability?（机器学习模型能力的定义）**  \n  作者：Jacqueline Harding, Nathaniel Sharadin。这篇论文从哲学角度分析 ML 模型的能力定义，提出条件分析框架（CAMA），以大型语言模型为例，探讨模型在特定任务中的可靠性和证据支持。主要贡献：为模型评估提供新框架，帮助理解模型“能力”的含义，并应用于公平模型比较。\n\n- **Meaning-Typed Programming: Language-level Abstractions and Runtime for GenAI Applications（基于含义类型的编程：用于生成式 AI 应用的语言级抽象和运行时）**  \n  作者：Jason Mars 等。该论文引入含义类型编程（MTP），简化 LLM 与传统代码的集成，通过语言级抽象和中间表示（MT-IR）提升开发效率。主要发现：在真实数据集上，MTP 超越了手动提示工程，显著提高了生成式 AI 应用的准确性和可用性。这篇论文因作者知名度和实际应用潜力而突出。\n\n- **Large Language Models for Human-Machine Collaborative Particle Accelerator Tuning through Natural Language（通过自然语言的大型语言模型用于人机协作粒子加速器调优）**  \n  作者：Jan Kaiser, Anne Lauscher 等。论文探索 LLM 在粒子加速器调优中的应用，仅需自然语言提示即可实现自治优化。主要贡献：LLM 比传统优化算法（如 Bayesian Optimization）更高效，并展示了 LLM 在非线性优化任务中的潜力，扩展了 AI 在物理科学的应用。\n\n- **Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Non-Literal Intent Resolution in LLMs（教皇是天主教徒吗？是的。LLM 非字面意图解析的生成式评估）**  \n  作者：Akhila Yerukola 等。该论文评估 LLM 处理非字面语言（如隐喻）的能力，发现 LLM 在意图理解上准确率仅 50-55%，但提供意图后可提升。主要发现：强调 LLM 生成的实用性问题，并建议通过链式思考改进。\n\n这些 LLM 相关论文整体揭示了 LLM 在哲学评估、编程和科学应用中的潜力，但也暴露了泛化挑战，值得 AI 研究者关注。其他如 LLM 在航空法规的论文（Towards Enhanced RAC Accessibility...）则快速掠过：它构建了 RAC 数据库并微调 LLM 提升法规可访问性，贡献在于数据集和模型，但影响力较小。\n\n### 医疗 AI 和图像分析\n- **Self-supervised vision-language alignment of deep learning representations for bone X-rays analysis（骨骼 X 光的自监督视觉-语言对齐）**  \n  作者：Alexandre Englebert 等。论文使用自监督方法对齐骨骼 X 光图像和法语报告，应用于骨折检测等任务。主要贡献：在少量标注下实现高性能，首次整合法语报告提升嵌入空间，展示了医疗 AI 的泛化潜力。\n\n- **Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling（利用 Transformer 的纵向医疗图像序列建模预测眼部疾病）**  \n  作者：Gregory Holste 等。论文提出 Longitudinal Transformer for Survival Analysis (LTSA)，用于眼部疾病（如 AMD）预测。主要发现：在 AREDS 和 OHTS 数据集上，LTSA 比单图像基线提升 25%，强调历史图像的价值。\n\n- **Achieving Fairness Through Channel Pruning for Dermatological Disease Diagnosis（通过通道剪枝实现皮肤病诊断的公平性）**  \n  作者：Qingpeng Kong 等。论文使用 Soft Nearest Neighbor Loss 进行通道剪枝，减少模型偏差。主要贡献：在皮肤病数据集上实现公平性提升，同时保持准确性，证明剪枝在医疗 AI 中的新应用。\n\n医疗 AI 论文主题集中，突出了自监督学习和公平性的创新，但其他如眼部图像跟踪（EchoTracker...）和图像增强（Progressive enhancement...）等，仅快速提到：它们改善了图像质量和跟踪精度，但实验性较强。\n\n### 高效训练和模型优化\n- **Challenges in Deploying Long-Context Transformers: A Theoretical Peak Performance Analysis（长上下文 Transformer 部署挑战：理论峰值性能分析）**  \n  作者：Yao Fu。这篇论文分析长上下文模型（如 50K 标记）的部署问题，焦点在于 KV cache 的内存开销。主要贡献：提出框架解释四类挑战（如延迟和并发），并建议优化策略，将 1M 上下文成本降至 4K 水平。该论文因其实用性和作者知名度而备受关注。\n\n- **EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training（EfficientTrain++：用于高效视觉主干训练的广义课程学习）**  \n  作者：Yulin Wang 等。论文扩展课程学习，通过傅里叶谱裁剪和数据增强优化训练。主要发现：在 ImageNet 上，训练时间减少 1.5-3.0 倍，同时保持准确性，适用于自监督学习。\n\n这些优化论文强调了 AI 部署的实际挑战，相关论文如 Kolmogorov-Arnold Networks for Time Series Analysis（KANs 用于时间序列分析）快速掠过：它使用样条函数提升预测精度，但影响较局限。\n\n### 其他快速掠过\n剩余论文多为特定领域小改进，如网络安全（Distributed Threat Intelligence...）、文本生成（QCRD...）和机器人（I-CTRL...），我仅列出标题并简要总结：\n- **Distributed Threat Intelligence at the Edge Devices: A Novel LLM-Driven Approach（边缘设备分布式威胁情报：基于 LLM 的新方法）** 贡献：使用 LLM 提升边缘设备的安全性。\n- **Targeted Augmentation for Low-Resource Event Extraction（针对低资源事件抽取的增强方法）** 发现：改善数据增强策略，提升抽取性能。\n- **Automated Repair of AI Code with Large Language Models and Formal Verification（使用 LLM 和形式验证的 AI 代码自动修复）** 贡献：结合 LLM 和验证修复代码漏洞。\n\n总体而言，今天的 arXiv 论文展示了 AI 在多领域的潜力，但 LLM 能力和医疗应用的讨论最值得追踪。感兴趣的读者可关注这些主题的后续发展！",
  "papers": [
    {
      "arxiv_id": "2405.08989v1",
      "title": "What is it for a Machine Learning Model to Have a Capability?",
      "title_zh": "对于机器学习模型，拥有能力意味着什么？",
      "authors": [
        "Jacqueline Harding",
        "Nathaniel Sharadin"
      ],
      "abstract": "What can contemporary machine learning (ML) models do? Given the\nproliferation of ML models in society, answering this question matters to a\nvariety of stakeholders, both public and private. The evaluation of models'\ncapabilities is rapidly emerging as a key subfield of modern ML, buoyed by\nregulatory attention and government grants. Despite this, the notion of an ML\nmodel possessing a capability has not been interrogated: what are we saying\nwhen we say that a model is able to do something? And what sorts of evidence\nbear upon this question? In this paper, we aim to answer these questions, using\nthe capabilities of large language models (LLMs) as a running example. Drawing\non the large philosophical literature on abilities, we develop an account of ML\nmodels' capabilities which can be usefully applied to the nascent science of\nmodel evaluation. Our core proposal is a conditional analysis of model\nabilities (CAMA): crudely, a machine learning model has a capability to X just\nwhen it would reliably succeed at doing X if it 'tried'. The main contribution\nof the paper is making this proposal precise in the context of ML, resulting in\nan operationalisation of CAMA applicable to LLMs. We then put CAMA to work,\nshowing that it can help make sense of various features of ML model evaluation\npractice, as well as suggest procedures for performing fair inter-model\ncomparisons.",
      "tldr_zh": "这篇论文探讨了机器学习 (ML) 模型“能力”的定义问题，强调在模型广泛应用的社会背景下，评估模型能力的重要性，并以大型语言模型 (LLMs) 为例进行分析。作者借鉴哲学文献，提出条件分析框架 (CAMA)，即一个 ML 模型具备能力 X，当它在“尝试”时能够可靠地完成 X，从而为模型评估提供一个精确的操作化方法。该框架有助于解释当前的 ML 模型评估实践，并指导进行公平的模型间比较，以推进模型评估这一新兴领域。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "forthcoming in the British Journal for the Philosophy of Science\n  (BJPS)",
      "pdf_url": "http://arxiv.org/pdf/2405.08989v1",
      "published_date": "2024-05-14 23:03:52 UTC",
      "updated_date": "2024-05-14 23:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:20:04.213206"
    },
    {
      "arxiv_id": "2405.08965v3",
      "title": "Meaning-Typed Programming: Language-level Abstractions and Runtime for GenAI Applications",
      "title_zh": "意义类型化编程",
      "authors": [
        "Jason Mars",
        "Yiping Kang",
        "Jayanaka L. Dantanarayana",
        "Kugesan Sivasothynathan",
        "Christopher Clarke",
        "Baichuan Li",
        "Krisztian Flautner",
        "Lingjia Tang"
      ],
      "abstract": "Software is rapidly evolving from being programmed with traditional logical\ncode, to neuro-integrated applications that leverage generative AI and large\nlanguage models (LLMs) for application functionality. This shift increases the\ncomplexity of building applications, as developers now must reasoning about,\nprogram, and prompt LLMs. Despite efforts to create tools to assist with prompt\nengineering, these solutions often introduce additional layers of complexity to\nthe development of neuro-integrated applications. This paper proposes\nmeaning-typed programming (MTP), a novel approach to simplify the creation of\nneuro-integrated applications by introducing new language-level abstractions\nthat hide the complexities of LLM integration. Our key insight is that typical\nconventional code already possesses a high level of semantic richness that can\nbe automatically reasoned about, as it is designed to be readable and\nmaintainable by humans. Leveraging this insight, we conceptualize LLMs as\nmeaning-typed code constructs and introduce a by abstraction at the language\nlevel, MT-IR, a new meaning-based intermediate representation at the compiler\nlevel, and MT Runtime, an automated run-time engine for LLM integration and\noperations. We implement MTP in a production-grade Python super-set language\ncalled Jac and perform an extensive evaluation. Our results demonstrate that\nMTP not only simplifies the development process but also meets or exceeds the\nefficacy of state-of-the-art manual and tool-assisted prompt engineering\ntechniques in terms of accuracy and usability.",
      "tldr_zh": "本论文探讨了软件开发从传统代码向整合生成AI和大型语言模型(LLMs)的神经整合应用转型所带来的复杂性问题。作者提出Meaning-Typed Programming (MTP)，一种新方法，通过语言级抽象（如将LLMs视为meaning-typed代码结构）来隐藏LLM整合的复杂性，并引入MT-IR（meaning-based intermediate representation）和MT Runtime作为编译器级和运行时引擎。MTP在Python超集语言Jac中实现，实验结果显示它不仅简化了开发过程，还在准确性和可用性上优于现有的手动和工具辅助提示工程技术。",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08965v3",
      "published_date": "2024-05-14 21:12:01 UTC",
      "updated_date": "2025-01-16 18:56:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:20:17.419933"
    },
    {
      "arxiv_id": "2405.08961v1",
      "title": "Bird's-Eye View to Street-View: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Khawlah Bajbaa",
        "Muhammad Usman",
        "Saeed Anwar",
        "Ibrahim Radwan",
        "Abdul Bais"
      ],
      "abstract": "In recent years, street view imagery has grown to become one of the most\nimportant sources of geospatial data collection and urban analytics, which\nfacilitates generating meaningful insights and assisting in decision-making.\nSynthesizing a street-view image from its corresponding satellite image is a\nchallenging task due to the significant differences in appearance and viewpoint\nbetween the two domains. In this study, we screened 20 recent research papers\nto provide a thorough review of the state-of-the-art of how street-view images\nare synthesized from their corresponding satellite counterparts. The main\nfindings are: (i) novel deep learning techniques are required for synthesizing\nmore realistic and accurate street-view images; (ii) more datasets need to be\ncollected for public usage; and (iii) more specific evaluation metrics need to\nbe investigated for evaluating the generated images appropriately. We conclude\nthat, due to applying outdated deep learning techniques, the recent literature\nfailed to generate detailed and diverse street-view images.",
      "tldr_zh": "这篇论文对从鸟瞰视图（卫星图像）合成街景图像的技术进行了全面调查，分析了20篇最近的研究文献。论文强调了由于外观和视角差异，这一合成任务的挑战，并指出需要新型deep learning技术来生成更真实和准确的街景图像。同时，它呼吁收集更多公开数据集并开发特定评估指标，以提升图像生成质量。最终，结论认为，现有的研究因采用过时的deep learning方法，导致生成的街景图像细节和多样性不足。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08961v1",
      "published_date": "2024-05-14 21:01:12 UTC",
      "updated_date": "2024-05-14 21:01:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:20:29.273954"
    },
    {
      "arxiv_id": "2405.08944v1",
      "title": "Challenges in Deploying Long-Context Transformers: A Theoretical Peak Performance Analysis",
      "title_zh": "部署长上下文Transformer的挑战：理论峰值性能分析",
      "authors": [
        "Yao Fu"
      ],
      "abstract": "Transformer-based long context generative models power emerging AI\napplications like hour-long video understanding and project-level coding agent.\nDeploying long context transformers (e.g., 100K to 10M tokens) is prohibitively\nexpensive compared to short context (e.g., 4K tokens) model variants. Reducing\nthe cost of long-context transformers is becoming a pressing research and\nengineering challenge starting from the year of 2024. This work describes a\nconcurrent programming framework for quantitatively analyzing the efficiency\nchallenges in serving multiple long-context requests under limited size of GPU\nhigh-bandwidth memory (HBM) regime. We give a detailed analysis of how all\nadditional computational costs, compared to 4K context, trace back to\n\\textit{one single source: the large size of the KV cache}. We use a 34B\nGPT-3.5 level model of 50K context on A100 NVLink as a running example, and\ndescribe how its large KV cache causes four types of deployment challenges: (1)\nprefilling long inputs takes much longer compute time and GPU memory than short\ninputs; (2) after prefilling, the large KV cache residing on the GPU HBM\nsubstantially restricts the number of concurrent users being served; (3) during\ndecoding, repeatedly reading the KV cache from HBM to SM largely increases\nlatency; (4) when KV cache memory overflows, swapping it from HBM to DDR causes\nsignificant context switching latency. We use this framework to analyze\nexisting works and identify possibilities of combining them to build end-to-end\nsystems. Overall, this work offers a foundational framework for analyzing long\ncontext transformer deployment and identifies directions towards reducing the\ninference cost of 1M context to be as cheap as 4K.",
      "tldr_zh": "本论文分析了部署长上下文 Transformer（如100K到10M tokens）模型的挑战，这些模型用于AI应用如视频理解和代码代理，但相比短上下文（如4K tokens）模型，计算成本过高。作者提出一个并发编程框架，定量评估在有限GPU HBM内存下服务多个长上下文请求的效率问题，并详细分解KV cache的大尺寸如何导致四个关键挑战：预填充时间延长、并发用户限制、解码阶段延迟增加，以及内存溢出时的上下文切换延迟。实验以34B GPT-3.5级别模型为例，展示了这些问题，并识别了结合现有方法构建端到端系统的潜力，最终目标是将1M上下文的推理成本降低到与4K上下文相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08944v1",
      "published_date": "2024-05-14 20:17:22 UTC",
      "updated_date": "2024-05-14 20:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:20:42.013266"
    },
    {
      "arxiv_id": "2405.08932v1",
      "title": "Self-supervised vision-langage alignment of deep learning representations for bone X-rays analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Englebert",
        "Anne-Sophie Collin",
        "Olivier Cornu",
        "Christophe De Vleeschouwer"
      ],
      "abstract": "This paper proposes leveraging vision-language pretraining on bone X-rays\npaired with French reports to address downstream tasks of interest on bone\nradiography. A practical processing pipeline is introduced to anonymize and\nprocess French medical reports. Pretraining then consists in the\nself-supervised alignment of visual and textual embedding spaces derived from\ndeep model encoders. The resulting image encoder is then used to handle various\ndownstream tasks, including quantification of osteoarthritis, estimation of\nbone age on pediatric wrists, bone fracture and anomaly detection. Our approach\ndemonstrates competitive performance on downstream tasks, compared to\nalternatives requiring a significantly larger amount of human expert\nannotations. Our work stands as the first study to integrate French reports to\nshape the embedding space devoted to bone X-Rays representations, capitalizing\non the large quantity of paired images and reports data available in an\nhospital. By relying on generic vision-laguage deep models in a\nlanguage-specific scenario, it contributes to the deployement of vision models\nfor wider healthcare applications.",
      "tldr_zh": "本论文提出了一种self-supervised vision-language alignment方法，利用骨X-rays图像及其配对的法语报告进行预训练，以处理骨骼放射学下游任务。研究引入了一个处理管道来匿名化和处理法语医疗报告，通过深度模型编码器对齐视觉和文本嵌入空间，从而生成高效的图像编码器。该编码器应用于多种任务，包括骨关节炎量化、骨龄估计、骨折检测和异常识别，与需要大量专家标注的替代方法相比，表现出竞争性性能。论文首次整合法语报告来塑造骨X-rays嵌入空间，利用医院的大量配对数据，促进视觉模型在更广泛医疗应用中的部署。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08932v1",
      "published_date": "2024-05-14 19:53:20 UTC",
      "updated_date": "2024-05-14 19:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:20:55.388170"
    },
    {
      "arxiv_id": "2405.09580v1",
      "title": "Error-margin Analysis for Hidden Neuron Activation Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Abhilekha Dalal",
        "Rushrukh Rayan",
        "Pascal Hitzler"
      ],
      "abstract": "Understanding how high-level concepts are represented within artificial\nneural networks is a fundamental challenge in the field of artificial\nintelligence. While existing literature in explainable AI emphasizes the\nimportance of labeling neurons with concepts to understand their functioning,\nthey mostly focus on identifying what stimulus activates a neuron in most\ncases, this corresponds to the notion of recall in information retrieval. We\nargue that this is only the first-part of a two-part job, it is imperative to\nalso investigate neuron responses to other stimuli, i.e., their precision. We\ncall this the neuron labels error margin.",
      "tldr_zh": "该论文探讨了在可解释 AI 中理解神经网络隐藏神经元激活标签的重要性，强调现有研究主要关注神经元的召回（即什么刺激最常激活它们），这仅是完整工作的第一部分。论文主张需要进一步分析神经元对其他刺激的响应，以评估其精确度，并引入了“neuron labels error margin”的概念来量化这种错误边界。通过这一方法，论文旨在提供更全面的神经元功能解读，推动人工智能模型的可解释性研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09580v1",
      "published_date": "2024-05-14 19:13:50 UTC",
      "updated_date": "2024-05-14 19:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:21:05.808685"
    },
    {
      "arxiv_id": "2405.08888v1",
      "title": "Large Language Models for Human-Machine Collaborative Particle Accelerator Tuning through Natural Language",
      "title_zh": "大语言模型通过自然语言用于人机协作粒子加速器调优",
      "authors": [
        "Jan Kaiser",
        "Annika Eichler",
        "Anne Lauscher"
      ],
      "abstract": "Autonomous tuning of particle accelerators is an active and challenging field\nof research with the goal of enabling novel accelerator technologies\ncutting-edge high-impact applications, such as physics discovery, cancer\nresearch and material sciences. A key challenge with autonomous accelerator\ntuning remains that the most capable algorithms require an expert in\noptimisation, machine learning or a similar field to implement the algorithm\nfor every new tuning task. In this work, we propose the use of large language\nmodels (LLMs) to tune particle accelerators. We demonstrate on a\nproof-of-principle example the ability of LLMs to successfully and autonomously\ntune a particle accelerator subsystem based on nothing more than a natural\nlanguage prompt from the operator, and compare the performance of our LLM-based\nsolution to state-of-the-art optimisation algorithms, such as Bayesian\noptimisation (BO) and reinforcement learning-trained optimisation (RLO). In\ndoing so, we also show how LLMs can perform numerical optimisation of a highly\nnon-linear real-world objective function. Ultimately, this work represents yet\nanother complex task that LLMs are capable of solving and promises to help\naccelerate the deployment of autonomous tuning algorithms to the day-to-day\noperations of particle accelerators.",
      "tldr_zh": "本研究提出使用 Large Language Models (LLMs) 通过自然语言提示，实现人类-机器协作调谐粒子加速器，解决传统算法需专家定制的挑战。LLMs 基于操作员的自然语言指令，成功自主优化粒子加速器子系统，并在证明性示例中表现出色，与 Bayesian Optimisation (BO) 和 Reinforcement Learning-Optimised (RLO) 等算法相比，展示了处理高度非线性目标函数的能力。该方法有望加速自主调谐算法在粒子加速器日常操作中的部署，促进物理发现、癌症研究和材料科学等领域的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "physics.acc-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.08888v1",
      "published_date": "2024-05-14 18:05:44 UTC",
      "updated_date": "2024-05-14 18:05:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:21:18.647140"
    },
    {
      "arxiv_id": "2405.08792v1",
      "title": "Towards Enhanced RAC Accessibility: Leveraging Datasets and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Edison Jair Bejarano Sepulveda",
        "Nicolai Potes Hector",
        "Santiago Pineda Montoya",
        "Felipe Ivan Rodriguez",
        "Jaime Enrique Orduy",
        "Alec Rosales Cabezas",
        "Danny Traslaviña Navarrete",
        "Sergio Madrid Farfan"
      ],
      "abstract": "This paper explores the potential of large language models (LLMs) to make the\nAeronautical Regulations of Colombia (RAC) more accessible. Given the\ncomplexity and extensive technicality of the RAC, this study introduces a novel\napproach to simplifying these regulations for broader understanding. By\ndeveloping the first-ever RAC database, which contains 24,478 expertly labeled\nquestion-and-answer pairs, and fine-tuning LLMs specifically for RAC\napplications, the paper outlines the methodology for dataset assembly,\nexpert-led annotation, and model training. Utilizing the Gemma1.1 2b model\nalong with advanced techniques like Unsloth for efficient VRAM usage and flash\nattention mechanisms, the research aims to expedite training processes. This\ninitiative establishes a foundation to enhance the comprehensibility and\naccessibility of RAC, potentially benefiting novices and reducing dependence on\nexpert consultations for navigating the aviation industry's regulatory\nlandscape.\n  You can visit the dataset\n(https://huggingface.co/somosnlp/gemma-1.1-2b-it_ColombiaRAC_FullyCurated_format_chatML_V1)\nand the model\n(https://huggingface.co/datasets/somosnlp/ColombiaRAC_FullyCurated) here.",
      "tldr_zh": "本论文探讨如何利用大型语言模型（LLMs）提升哥伦比亚航空条例（RAC）的可访问性，以解决其复杂性和技术性问题。研究者开发了首个 RAC 数据库，包含 24,478 个专家标注的问题-答案对，并通过微调 Gemma1.1 2b 模型以及采用 Unsloth 和 flash attention 等技术优化训练过程。实验结果表明，这一方法显著提高了法规的可理解性，有助于新手用户减少对专家咨询的依赖，并提供了公开数据集和模型以支持进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08792v1",
      "published_date": "2024-05-14 17:41:07 UTC",
      "updated_date": "2024-05-14 17:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:21:29.967882"
    },
    {
      "arxiv_id": "2405.08790v2",
      "title": "Kolmogorov-Arnold Networks (KANs) for Time Series Analysis",
      "title_zh": "Kolmogorov-Arnold Networks (KANs) 用于时间序列分析",
      "authors": [
        "Cristian J. Vaca-Rubio",
        "Luis Blanco",
        "Roberto Pereira",
        "Màrius Caus"
      ],
      "abstract": "This paper introduces a novel application of Kolmogorov-Arnold Networks\n(KANs) to time series forecasting, leveraging their adaptive activation\nfunctions for enhanced predictive modeling. Inspired by the Kolmogorov-Arnold\nrepresentation theorem, KANs replace traditional linear weights with\nspline-parametrized univariate functions, allowing them to learn activation\npatterns dynamically. We demonstrate that KANs outperforms conventional\nMulti-Layer Perceptrons (MLPs) in a real-world satellite traffic forecasting\ntask, providing more accurate results with considerably fewer number of\nlearnable parameters. We also provide an ablation study of KAN-specific\nparameters impact on performance. The proposed approach opens new avenues for\nadaptive forecasting models, emphasizing the potential of KANs as a powerful\ntool in predictive analytics.",
      "tldr_zh": "本文引入 Kolmogorov-Arnold Networks (KANs) 用于时间序列分析，通过自适应激活函数（如 spline-parametrized univariate functions）动态学习激活模式，以提升预测建模。KANs 受 Kolmogorov-Arnold 表示定理启发，在卫星交通预测任务中比传统的 Multi-Layer Perceptrons (MLPs) 提供更准确的结果，且使用更少的参数。研究还进行了 KANs 特定参数的消融研究，验证其性能影响。该方法为自适应预测模型开辟新途径，强调 KANs 在预测分析中的强大潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08790v2",
      "published_date": "2024-05-14 17:38:17 UTC",
      "updated_date": "2024-09-25 12:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:21:42.727864"
    },
    {
      "arxiv_id": "2405.08780v2",
      "title": "Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Holste",
        "Mingquan Lin",
        "Ruiwen Zhou",
        "Fei Wang",
        "Lei Liu",
        "Qi Yan",
        "Sarah H. Van Tassel",
        "Kyle Kovacs",
        "Emily Y. Chew",
        "Zhiyong Lu",
        "Zhangyang Wang",
        "Yifan Peng"
      ],
      "abstract": "Deep learning has enabled breakthroughs in automated diagnosis from medical\nimaging, with many successful applications in ophthalmology. However, standard\nmedical image classification approaches only assess disease presence at the\ntime of acquisition, neglecting the common clinical setting of longitudinal\nimaging. For slow, progressive eye diseases like age-related macular\ndegeneration (AMD) and primary open-angle glaucoma (POAG), patients undergo\nrepeated imaging over time to track disease progression and forecasting the\nfuture risk of developing disease is critical to properly plan treatment. Our\nproposed Longitudinal Transformer for Survival Analysis (LTSA) enables dynamic\ndisease prognosis from longitudinal medical imaging, modeling the time to\ndisease from sequences of fundus photography images captured over long,\nirregular time periods. Using longitudinal imaging data from the Age-Related\nEye Disease Study (AREDS) and Ocular Hypertension Treatment Study (OHTS), LTSA\nsignificantly outperformed a single-image baseline in 19/20 head-to-head\ncomparisons on late AMD prognosis and 18/20 comparisons on POAG prognosis. A\ntemporal attention analysis also suggested that, while the most recent image is\ntypically the most influential, prior imaging still provides additional\nprognostic value.",
      "tldr_zh": "本研究提出了一种Longitudinal Transformer for Survival Analysis (LTSA)模型，利用Transformer-based sequence modeling处理纵向医疗影像序列，以预测眼部疾病的进展风险。针对年龄相关性黄斑变性(AMD)和原发性开角型青光眼(POAG)等缓慢进展性眼病，LTSA从长期不规则的眼底摄影图像中建模疾病发生时间，显著优于单图像基线，在AREDS和OHTS数据集上分别在19/20和18/20的比较中表现出色。通过时间注意力分析，发现最近图像通常最有影响力，但先前图像仍提供额外预后价值。该方法为基于纵向影像的动态疾病预后提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to npj Digital Medicine",
      "pdf_url": "http://arxiv.org/pdf/2405.08780v2",
      "published_date": "2024-05-14 17:15:28 UTC",
      "updated_date": "2024-07-30 03:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:21:53.869057"
    },
    {
      "arxiv_id": "2405.08768v1",
      "title": "EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training",
      "title_zh": "EfficientTrain++：泛化课程学习用于高效视觉主干训练",
      "authors": [
        "Yulin Wang",
        "Yang Yue",
        "Rui Lu",
        "Yizeng Han",
        "Shiji Song",
        "Gao Huang"
      ],
      "abstract": "The superior performance of modern visual backbones usually comes with a\ncostly training procedure. We contribute to this issue by generalizing the idea\nof curriculum learning beyond its original formulation, i.e., training models\nusing easier-to-harder data. Specifically, we reformulate the training\ncurriculum as a soft-selection function, which uncovers progressively more\ndifficult patterns within each example during training, instead of performing\neasier-to-harder sample selection. Our work is inspired by an intriguing\nobservation on the learning dynamics of visual backbones: during the earlier\nstages of training, the model predominantly learns to recognize some\n'easier-to-learn' discriminative patterns in the data. These patterns, when\nobserved through frequency and spatial domains, incorporate lower-frequency\ncomponents, and the natural image contents without distortion or data\naugmentation. Motivated by these findings, we propose a curriculum where the\nmodel always leverages all the training data at every learning stage, yet the\nexposure to the 'easier-to-learn' patterns of each example is initiated first,\nwith harder patterns gradually introduced as training progresses. To implement\nthis idea in a computationally efficient way, we introduce a cropping operation\nin the Fourier spectrum of the inputs, enabling the model to learn from only\nthe lower-frequency components. Then we show that exposing the contents of\nnatural images can be readily achieved by modulating the intensity of data\naugmentation. Finally, we integrate these aspects and design curriculum\nschedules with tailored search algorithms. The resulting method,\nEfficientTrain++, is simple, general, yet surprisingly effective. It reduces\nthe training time of a wide variety of popular models by 1.5-3.0x on\nImageNet-1K/22K without sacrificing accuracy. It also demonstrates efficacy in\nself-supervised learning (e.g., MAE).",
      "tldr_zh": "该论文提出 EfficientTrain++，一种泛化 curriculum learning 方法，用于高效训练视觉 backbones，避免传统易到难样本选择的局限性。研究观察到模型在早期训练中优先学习“易学”模式，如图像的低频组件和自然内容，因此设计了软选择函数，通过傅立叶谱裁剪和渐进式数据增强强度调节，让模型先从每个样本的易学模式开始逐步引入更难模式。实验结果显示，该方法在 ImageNet-1K/22K 上将多种流行模型的训练时间减少 1.5-3.0 倍，同时保持准确率不变，并在 self-supervised learning（如 MAE）中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI). Journal version of arXiv:2211.09703 (ICCV 2023). Code\n  is available at: https://github.com/LeapLabTHU/EfficientTrain",
      "pdf_url": "http://arxiv.org/pdf/2405.08768v1",
      "published_date": "2024-05-14 17:00:43 UTC",
      "updated_date": "2024-05-14 17:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:22:06.340860"
    },
    {
      "arxiv_id": "2405.08760v2",
      "title": "Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Non-Literal Intent Resolution in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Akhila Yerukola",
        "Saujas Vaduguru",
        "Daniel Fried",
        "Maarten Sap"
      ],
      "abstract": "Humans often express their communicative intents indirectly or non-literally,\nwhich requires their interlocutors -- human or AI -- to understand beyond the\nliteral meaning of words. While most existing work has focused on\ndiscriminative evaluations, we present a new approach to generatively evaluate\nlarge language models' (LLMs') intention understanding by examining their\nresponses to non-literal utterances. Ideally, an LLM should respond in line\nwith the true intention of a non-literal utterance, not its literal\ninterpretation. Our findings show that LLMs struggle to generate pragmatically\nrelevant responses to non-literal language, achieving only 50-55% accuracy on\naverage. While explicitly providing oracle intentions significantly improves\nperformance (e.g., 75% for Mistral-Instruct), this still indicates challenges\nin leveraging given intentions to produce appropriate responses. Using\nchain-of-thought to make models spell out intentions yields much smaller gains\n(60% for Mistral-Instruct). These findings suggest that LLMs are not yet\neffective pragmatic interlocutors, highlighting the need for better approaches\nfor modeling intentions and utilizing them for pragmatic generation.",
      "tldr_zh": "本研究提出了一种生成式评估方法，考察大型语言模型(LLMs)对非字面表达意图的理解能力，旨在超越传统判别式评估。研究通过分析LLMs对非字面语句的响应，发现其平均准确率仅为50-55%，表明模型难以生成符合真实意图的回应。提供预知意图（oracle intentions）可显著提升性能（如Mistral-Instruct达75%），而使用chain-of-thought推理仅带来有限改进（60%）。这些发现突显了LLMs在意图建模和实用生成方面的挑战，需要开发更有效的策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08760v2",
      "published_date": "2024-05-14 16:48:56 UTC",
      "updated_date": "2024-06-19 19:07:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:22:19.354811"
    },
    {
      "arxiv_id": "2405.08755v2",
      "title": "Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Syed Mhamudul Hasan",
        "Alaa M. Alotaibi",
        "Sajedul Talukder",
        "Abdur R. Shahid"
      ],
      "abstract": "With the proliferation of edge devices, there is a significant increase in\nattack surface on these devices. The decentralized deployment of threat\nintelligence on edge devices, coupled with adaptive machine learning techniques\nsuch as the in-context learning feature of Large Language Models (LLMs),\nrepresents a promising paradigm for enhancing cybersecurity on\nresource-constrained edge devices. This approach involves the deployment of\nlightweight machine learning models directly onto edge devices to analyze local\ndata streams, such as network traffic and system logs, in real-time.\nAdditionally, distributing computational tasks to an edge server reduces\nlatency and improves responsiveness while also enhancing privacy by processing\nsensitive data locally. LLM servers can enable these edge servers to\nautonomously adapt to evolving threats and attack patterns, continuously\nupdating their models to improve detection accuracy and reduce false positives.\nFurthermore, collaborative learning mechanisms facilitate peer-to-peer secure\nand trustworthy knowledge sharing among edge devices, enhancing the collective\nintelligence of the network and enabling dynamic threat mitigation measures\nsuch as device quarantine in response to detected anomalies. The scalability\nand flexibility of this approach make it well-suited for diverse and evolving\nnetwork environments, as edge devices only send suspicious information such as\nnetwork traffic and system log changes, offering a resilient and efficient\nsolution to combat emerging cyber threats at the network edge. Thus, our\nproposed framework can improve edge computing security by providing better\nsecurity in cyber threat detection and mitigation by isolating the edge devices\nfrom the network.",
      "tldr_zh": "该研究提出了一种基于 Large Language Models (LLMs) 的分布式威胁情报框架，旨在应对边缘设备攻击面的急剧扩大问题。该框架通过在边缘设备上部署轻量级机器学习模型，利用 LLMs 的 in-context learning 特性，对本地数据流（如网络流量和系统日志）进行实时分析，同时将计算任务分发到边缘服务器以降低延迟、提升隐私和响应性。LLMs 服务器支持边缘服务器自主适应演变中的威胁模式，持续更新模型以提高检测准确率并减少假阳性。此外，协作学习机制促进边缘设备之间安全知识共享，提升网络集体智能，实现动态威胁缓解，如隔离异常设备。该方法具有良好的可扩展性和灵活性，仅传输可疑信息，从而为边缘计算提供高效的安全解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08755v2",
      "published_date": "2024-05-14 16:40:37 UTC",
      "updated_date": "2024-05-26 06:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:22:29.941445"
    },
    {
      "arxiv_id": "2405.08729v1",
      "title": "Targeted Augmentation for Low-Resource Event Extraction",
      "title_zh": "针对低资源事件抽取的增强方法",
      "authors": [
        "Sijia Wang",
        "Lifu Huang"
      ],
      "abstract": "Addressing the challenge of low-resource information extraction remains an\nongoing issue due to the inherent information scarcity within limited training\nexamples. Existing data augmentation methods, considered potential solutions,\nstruggle to strike a balance between weak augmentation (e.g., synonym\naugmentation) and drastic augmentation (e.g., conditional generation without\nproper guidance). This paper introduces a novel paradigm that employs targeted\naugmentation and back validation to produce augmented examples with enhanced\ndiversity, polarity, accuracy, and coherence. Extensive experimental results\ndemonstrate the effectiveness of the proposed paradigm. Furthermore, identified\nlimitations are discussed, shedding light on areas for future improvement.",
      "tldr_zh": "这篇论文针对低资源事件提取（low-resource event extraction）的挑战，提出了一种新型范式，使用 targeted augmentation 和 back validation 来生成增强样本，从而提升样本的多样性、极性、准确性和连贯性。相比现有数据增强方法（如同义词增强或无指导条件生成），该方法更好地平衡了增强强度。实验结果证明了该范式的有效性，并讨论了其限制，为未来改进提供了方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08729v1",
      "published_date": "2024-05-14 16:15:31 UTC",
      "updated_date": "2024-05-14 16:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:22:41.236118"
    },
    {
      "arxiv_id": "2405.08726v2",
      "title": "I-CTRL: Imitation to Control Humanoid Robots Through Constrained Reinforcement Learning",
      "title_zh": "I-CTRL：通过约束强化学习实现对人形机器人的模仿控制",
      "authors": [
        "Yashuai Yan",
        "Esteve Valls Mascaro",
        "Tobias Egle",
        "Dongheui Lee"
      ],
      "abstract": "Humanoid robots have the potential to mimic human motions with high visual\nfidelity, yet translating these motions into practical, physical execution\nremains a significant challenge. Existing techniques in the graphics community\noften prioritize visual fidelity over physics-based feasibility, posing a\nsignificant challenge for deploying bipedal systems in practical applications.\nThis paper addresses these issues through bounded residual reinforcement\nlearning to produce physics-based high-quality motion imitation onto legged\nhumanoid robots that enhance motion resemblance while successfully following\nthe reference human trajectory. Our framework, Imitation to Control Humanoid\nRobots Through Bounded Residual Reinforcement Learning (I-CTRL), reformulates\nmotion imitation as a constrained refinement over non-physics-based retargeted\nmotions. I-CTRL excels in motion imitation with simple and unique rewards that\ngeneralize across five robots. Moreover, our framework introduces an automatic\npriority scheduler to manage large-scale motion datasets when efficiently\ntraining a unified RL policy across diverse motions. The proposed approach\nsignifies a crucial step forward in advancing the control of bipedal robots,\nemphasizing the importance of aligning visual and physical realism for\nsuccessful motion imitation.",
      "tldr_zh": "本论文针对人形机器人（humanoid robots）在模仿人类动作时视觉逼真性与物理可行性之间的挑战，提出I-CTRL框架，通过bounded residual reinforcement learning（约束残差强化学习）方法，将运动模仿转化为对非物理基础重定向运动的约束精炼。该框架采用简单且通用的奖励函数，并在五种机器人上实现泛化，同时引入自动优先级调度器（automatic priority scheduler）来高效处理大规模运动数据集。实验结果显示，I-CTRL显著提升了动作模仿的质量，确保机器人成功跟随参考人类轨迹，并为双足机器人（bipedal robots）的控制推进了关键一步，强调了视觉和物理现实的协调重要性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08726v2",
      "published_date": "2024-05-14 16:12:27 UTC",
      "updated_date": "2025-02-17 14:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:22:53.696023"
    },
    {
      "arxiv_id": "2405.08852v1",
      "title": "A Click-Through Rate Prediction Method Based on Cross-Importance of Multi-Order Features",
      "title_zh": "基于多阶特征交叉重要性的点击通过率预测方法",
      "authors": [
        "Hao Wang",
        "Nao Li"
      ],
      "abstract": "Most current click-through rate prediction(CTR)models create explicit or\nimplicit high-order feature crosses through Hadamard product or inner product,\nwith little attention to the importance of feature crossing; only few models\nare either limited to the second-order explicit feature crossing, implicitly to\nhigh-order feature crossing, or can learn the importance of high-order explicit\nfeature crossing but fail to provide good interpretability for the model. This\npaper proposes a new model, FiiNet (Multiple Order Feature Interaction\nImportance Neural Networks). The model first uses the selective kernel network\n(SKNet) to explicitly construct multi-order feature crosses. It dynamically\nlearns the importance of feature interaction combinations in a fine grained\nmanner, increasing the attention weight of important feature cross combinations\nand reducing the weight of featureless crosses. To verify that the FiiNet model\ncan dynamically learn the importance of feature interaction combinations in a\nfine-grained manner and improve the model's recommendation performance and\ninterpretability, this paper compares it with many click-through rate\nprediction models on two real datasets, proving that the FiiNet model\nincorporating the selective kernel network can effectively improve the\nrecommendation effect and provide better interpretability. FiiNet model\nimplementations are available in PyTorch.",
      "tldr_zh": "本论文针对点击率预测(CTR)模型中特征交叉重要性被忽略的问题，提出了一种新模型FiiNet（Multiple Order Feature Interaction Importance Neural Networks）。FiiNet使用selective kernel network(SKNet)显式构建多阶特征交叉，并动态学习特征交互组合的重要性，以细粒度方式增加重要交叉的权重，同时减少无用交叉的权重，从而提升模型的推荐性能和可解释性。在两个真实数据集上的实验对比显示，FiiNet比现有CTR模型表现出色，有效提高了预测准确性和模型解释性，且提供了PyTorch实现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08852v1",
      "published_date": "2024-05-14 16:05:57 UTC",
      "updated_date": "2024-05-14 16:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:23:07.660642"
    },
    {
      "arxiv_id": "2405.08681v1",
      "title": "Achieving Fairness Through Channel Pruning for Dermatological Disease Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Qingpeng Kong",
        "Ching-Hao Chiu",
        "Dewen Zeng",
        "Yu-Jen Chen",
        "Tsung-Yi Ho",
        "Jingtong hu",
        "Yiyu Shi"
      ],
      "abstract": "Numerous studies have revealed that deep learning-based medical image\nclassification models may exhibit bias towards specific demographic attributes,\nsuch as race, gender, and age. Existing bias mitigation methods often achieve\nhigh level of fairness at the cost of significant accuracy degradation. In\nresponse to this challenge, we propose an innovative and adaptable Soft Nearest\nNeighbor Loss-based channel pruning framework, which achieves fairness through\nchannel pruning. Traditionally, channel pruning is utilized to accelerate\nneural network inference. However, our work demonstrates that pruning can also\nbe a potent tool for achieving fairness. Our key insight is that different\nchannels in a layer contribute differently to the accuracy of different groups.\nBy selectively pruning critical channels that lead to the accuracy difference\nbetween the privileged and unprivileged groups, we can effectively improve\nfairness without sacrificing accuracy significantly. Experiments conducted on\ntwo skin lesion diagnosis datasets across multiple sensitive attributes\nvalidate the effectiveness of our method in achieving state-of-the-art\ntrade-off between accuracy and fairness. Our code is available at\nhttps://github.com/Kqp1227/Sensitive-Channel-Pruning.",
      "tldr_zh": "该研究针对深度学习模型在皮肤病诊断中的偏见问题（如种族、性别和年龄），提出了一种基于Soft Nearest Neighbor Loss的channel pruning框架，以实现公平性。传统channel pruning用于加速神经网络，但本方法通过选择性地修剪导致特权群和非特权群准确率差异的关键通道，有效改善公平性，同时最小化准确率损失。在两个皮肤病诊断数据集上的实验验证了该框架在多个敏感属性上达到了最先进的准确性和公平性权衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 3 figures, early accepted by International Conference on\n  Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08681v1",
      "published_date": "2024-05-14 15:04:46 UTC",
      "updated_date": "2024-05-14 15:04:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:23:18.322703"
    },
    {
      "arxiv_id": "2406.18841v4",
      "title": "Navigating LLM Ethics: Advancements, Challenges, and Future Directions",
      "title_zh": "导航大型语言模型伦理：进展、挑战和未来方向",
      "authors": [
        "Junfeng Jiao",
        "Saleh Afroogh",
        "Yiming Xu",
        "Connor Phillips"
      ],
      "abstract": "This study addresses ethical issues surrounding Large Language Models (LLMs)\nwithin the field of artificial intelligence. It explores the common ethical\nchallenges posed by both LLMs and other AI systems, such as privacy and\nfairness, as well as ethical challenges uniquely arising from LLMs. It\nhighlights challenges such as hallucination, verifiable accountability, and\ndecoding censorship complexity, which are unique to LLMs and distinct from\nthose encountered in traditional AI systems. The study underscores the need to\ntackle these complexities to ensure accountability, reduce biases, and enhance\ntransparency in the influential role that LLMs play in shaping information\ndissemination. It proposes mitigation strategies and future directions for LLM\nethics, advocating for interdisciplinary collaboration. It recommends ethical\nframeworks tailored to specific domains and dynamic auditing systems adapted to\ndiverse contexts. This roadmap aims to guide responsible development and\nintegration of LLMs, envisioning a future where ethical considerations govern\nAI advancements in society.",
      "tldr_zh": "这项研究探讨了大型语言模型(LLMs)在人工智能领域的伦理挑战，包括隐私、公平性等常见问题，以及LLMs特有的hallucination、verifiable accountability和decoding censorship complexity。\n它强调了解决这些复杂性以提升问责制、减少偏差并提高透明度的必要性，从而确保LLMs在信息传播中的负责任作用。\n研究提出了缓解策略和未来方向，倡导interdisciplinary collaboration、针对特定领域的ethical frameworks以及动态auditing systems，以指导LLMs的伦理发展和社会应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18841v4",
      "published_date": "2024-05-14 15:03:05 UTC",
      "updated_date": "2025-03-18 16:57:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:23:30.188272"
    },
    {
      "arxiv_id": "2405.08679v1",
      "title": "Investigating Design Choices in Joint-Embedding Predictive Architectures for General Audio Representation Learning",
      "title_zh": "探究联合嵌入预测架构中设计选择，用于通用音频表示学习",
      "authors": [
        "Alain Riou",
        "Stefan Lattner",
        "Gaëtan Hadjeres",
        "Geoffroy Peeters"
      ],
      "abstract": "This paper addresses the problem of self-supervised general-purpose audio\nrepresentation learning. We explore the use of Joint-Embedding Predictive\nArchitectures (JEPA) for this task, which consists of splitting an input\nmel-spectrogram into two parts (context and target), computing neural\nrepresentations for each, and training the neural network to predict the target\nrepresentations from the context representations. We investigate several design\nchoices within this framework and study their influence through extensive\nexperiments by evaluating our models on various audio classification\nbenchmarks, including environmental sounds, speech and music downstream tasks.\nWe focus notably on which part of the input data is used as context or target\nand show experimentally that it significantly impacts the model's quality. In\nparticular, we notice that some effective design choices in the image domain\nlead to poor performance on audio, thus highlighting major differences between\nthese two modalities.",
      "tldr_zh": "这篇论文探讨了自监督通用音频表示学习中 Joint-Embedding Predictive Architectures (JEPA) 的设计选择，方法是将输入的 mel-spectrogram 分成 context 和 target 两部分，并训练模型从 context 表示预测 target 表示。研究者通过在环境声音、语音和音乐等音频分类基准上的广泛实验，评估了这些设计选择的影響，特别是 context 和 target 分配的影响。结果显示，某些在图像领域有效的设计在音频领域表现不佳，突出了音频和图像模态之间的显著差异。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Self-supervision in Audio, Speech and Beyond workshop, IEEE\n  International Conference on Acoustics, Speech, and Signal Processing, 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08679v1",
      "published_date": "2024-05-14 15:00:09 UTC",
      "updated_date": "2024-05-14 15:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:23:43.095926"
    },
    {
      "arxiv_id": "2405.08674v1",
      "title": "Expensive Multi-Objective Bayesian Optimization Based on Diffusion Models",
      "title_zh": "基于扩散模型的昂贵多目标贝叶斯优化",
      "authors": [
        "Bingdong Li",
        "Zixiang Di",
        "Yongfan Lu",
        "Hong Qian",
        "Feng Wang",
        "Peng Yang",
        "Ke Tang",
        "Aimin Zhou"
      ],
      "abstract": "Multi-objective Bayesian optimization (MOBO) has shown promising performance\non various expensive multi-objective optimization problems (EMOPs). However,\neffectively modeling complex distributions of the Pareto optimal solutions is\ndifficult with limited function evaluations. Existing Pareto set learning\nalgorithms may exhibit considerable instability in such expensive scenarios,\nleading to significant deviations between the obtained solution set and the\nPareto set (PS). In this paper, we propose a novel Composite Diffusion Model\nbased Pareto Set Learning algorithm, namely CDM-PSL, for expensive MOBO.\nCDM-PSL includes both unconditional and conditional diffusion model for\ngenerating high-quality samples. Besides, we introduce an information entropy\nbased weighting method to balance different objectives of EMOPs. This method is\nintegrated with the guiding strategy, ensuring that all the objectives are\nappropriately balanced and given due consideration during the optimization\nprocess; Extensive experimental results on both synthetic benchmarks and\nreal-world problems demonstrates that our proposed algorithm attains superior\nperformance compared with various state-of-the-art MOBO algorithms.",
      "tldr_zh": "该论文针对昂贵多目标优化问题 (EMOPs) 中，多目标贝叶斯优化 (MOBO) 在建模 Pareto 最佳解分布时的不稳定性问题，提出了一种新型算法 CDM-PSL。CDM-PSL 利用复合扩散模型，包括无条件和条件扩散模型，来生成高质量样本，并引入基于信息熵的加权方法与引导策略相结合，以平衡不同目标的优化过程。实验结果显示，该算法在合成基准和真实世界问题上，显著优于现有 MOBO 算法，证明了其在处理 EMOPs 时的有效性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08674v1",
      "published_date": "2024-05-14 14:55:57 UTC",
      "updated_date": "2024-05-14 14:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:23:53.869849"
    },
    {
      "arxiv_id": "2405.08668v1",
      "title": "Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research",
      "title_zh": "翻译失败",
      "authors": [
        "Qinglong Cao",
        "Yuntian Chen",
        "Lu Lu",
        "Hao Sun",
        "Zhenzhong Zeng",
        "Xiaokang Yang",
        "Dongxiao Zhang"
      ],
      "abstract": "Large-scale Vision-Language Models (VLMs) have demonstrated exceptional\nperformance in natural vision tasks, motivating researchers across domains to\nexplore domain-specific VLMs. However, the construction of powerful\ndomain-specific VLMs demands vast amounts of annotated data, substantial\nelectrical energy, and computing resources, primarily accessible to industry,\nyet hindering VLM research in academia. To address this challenge and foster\nsustainable and equitable VLM research, we present the Generalized Domain\nPrompt Learning (GDPL) framework. GDPL facilitates the transfer of VLMs' robust\nrecognition capabilities from natural vision to specialized domains, without\nthe need for extensive data or resources. By leveraging small-scale\ndomain-specific foundation models and minimal prompt samples, GDPL empowers the\nlanguage branch with domain knowledge through quaternion networks, uncovering\ncross-modal relationships between domain-specific vision features and natural\nvision-based contextual embeddings. Simultaneously, GDPL guides the vision\nbranch into specific domains through hierarchical propagation of generated\nvision prompt features, grounded in well-matched vision-language relations.\nFurthermore, to fully harness the domain adaptation potential of VLMs, we\nintroduce a novel low-rank adaptation approach. Extensive experiments across\ndiverse domains like remote sensing, medical imaging, geology, Synthetic\nAperture Radar, and fluid dynamics, validate the efficacy of GDPL,\ndemonstrating its ability to achieve state-of-the-art domain recognition\nperformance in a prompt learning paradigm. Our framework paves the way for\nsustainable and inclusive VLM research, transcending the barriers between\nacademia and industry.",
      "tldr_zh": "该研究针对大型视觉语言模型 (VLMs) 在领域特定应用中面临的资源障碍，提出 Generalized Domain Prompt Learning (GDPL) 框架，以促进 AI 在科学领域的公平性。GDPL 通过利用小规模领域特定基础模型和最小提示样本，利用 quaternion networks 增强语言分支的领域知识，并通过层次传播引导视觉分支，探索跨模态关系，同时引入低秩适应方法，实现高效的模型转移。实验在遥感、医学成像、地质学、Synthetic Aperture Radar 和流体动力学等多样领域验证了 GDPL 的效能，实现了最先进的领域识别性能，为可持续和包容性的 VLM 研究铺平道路，缩小了学术界与行业的差距。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08668v1",
      "published_date": "2024-05-14 14:51:12 UTC",
      "updated_date": "2024-05-14 14:51:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:24:07.139590"
    },
    {
      "arxiv_id": "2405.08658v2",
      "title": "Beyond the Black Box: Do More Complex Deep Learning Models Provide Superior XAI Explanations?",
      "title_zh": "翻译失败",
      "authors": [
        "Mateusz Cedro",
        "Marcin Chlebus"
      ],
      "abstract": "The increasing complexity of Artificial Intelligence models poses challenges\nto interpretability, particularly in the healthcare sector. This study\ninvestigates the impact of deep learning model complexity and Explainable AI\n(XAI) efficacy, utilizing four ResNet architectures (ResNet-18, 34, 50, 101).\nThrough methodical experimentation on 4,369 lung X-ray images of\nCOVID-19-infected and healthy patients, the research evaluates models'\nclassification performance and the relevance of corresponding XAI explanations\nwith respect to the ground-truth disease masks. Results indicate that the\nincrease in model complexity is associated with a decrease in classification\naccuracy and AUC-ROC scores (ResNet-18: 98.4%, 0.997; ResNet-101: 95.9%,\n0.988). Notably, in eleven out of twelve statistical tests performed, no\nstatistically significant differences occurred between XAI quantitative metrics\n- Relevance Rank Accuracy and the proposed Positive Attribution Ratio - across\ntrained models. These results suggest that increased model complexity does not\nconsistently lead to higher performance or relevance of explanations for\nmodels' decision-making processes.",
      "tldr_zh": "本研究探讨了深度学习模型的复杂性是否能提升可解释性（XAI）解释的有效性，特别是针对医疗图像分类任务。研究者使用四种 ResNet 架构（ResNet-18、34、50、101）在 4,369 张肺 X 光图像上进行实验，评估模型的分类性能和 XAI 解释的相关性，包括 Relevance Rank Accuracy 和 Positive Attribution Ratio。结果显示，随着模型复杂度增加，分类准确率和 AUC-ROC 分数下降（ResNet-18：98.4%、0.997；ResNet-101：95.9%、0.988）。在 12 次统计测试中，有 11 次 XAI 指标无显著差异，这表明更复杂的模型并不一致地提供更好的性能或解释相关性。总的来说，该研究质疑了增加模型复杂度的必要性，在医疗 AI 应用中强调了平衡准确性和可解释性的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 9 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.08658v2",
      "published_date": "2024-05-14 14:35:35 UTC",
      "updated_date": "2024-10-05 16:36:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:24:19.506537"
    },
    {
      "arxiv_id": "2405.08655v2",
      "title": "A Distributed Approach to Autonomous Intersection Management via Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Cederle",
        "Marco Fabris",
        "Gian Antonio Susto"
      ],
      "abstract": "Autonomous intersection management (AIM) poses significant challenges due to\nthe intricate nature of real-world traffic scenarios and the need for a highly\nexpensive centralised server in charge of simultaneously controlling all the\nvehicles. This study addresses such issues by proposing a novel distributed\napproach to AIM utilizing multi-agent reinforcement learning (MARL). We show\nthat by leveraging the 3D surround view technology for advanced assistance\nsystems, autonomous vehicles can accurately navigate intersection scenarios\nwithout needing any centralised controller. The contributions of this paper\nthus include a MARL-based algorithm for the autonomous management of a 4-way\nintersection and also the introduction of a new strategy called prioritised\nscenario replay for improved training efficacy. We validate our approach as an\ninnovative alternative to conventional centralised AIM techniques, ensuring the\nfull reproducibility of our results. Specifically, experiments conducted in\nvirtual environments using the SMARTS platform highlight its superiority over\nbenchmarks across various metrics.",
      "tldr_zh": "这篇论文提出了一种分布式方法，用于Autonomous Intersection Management (AIM)，通过Multi-Agent Reinforcement Learning (MARL)解决复杂交通场景中对昂贵集中式服务器的依赖。方法利用3D 围观视图技术，让自动驾驶车辆无需中央控制器即可精确导航4向交叉路口，并引入Prioritised Scenario Replay策略以提升训练效率。主要贡献包括MARL-based算法的设计和该新策略的创新应用。实验在SMARTS平台虚拟环境中验证，该方法在多种指标上比基准模型表现优越，并确保结果完全可重现。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 2 figures, submitted to Agents in Traffic and\n  Transportation (ATT2024). Status: accepted",
      "pdf_url": "http://arxiv.org/pdf/2405.08655v2",
      "published_date": "2024-05-14 14:34:24 UTC",
      "updated_date": "2024-09-24 12:04:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:24:30.364588"
    },
    {
      "arxiv_id": "2405.08654v2",
      "title": "Can we Defend Against the Unknown? An Empirical Study About Threshold Selection for Neural Network Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Khoi Tran Dang",
        "Kevin Delmas",
        "Jérémie Guiochet",
        "Joris Guérin"
      ],
      "abstract": "With the increasing use of neural networks in critical systems, runtime\nmonitoring becomes essential to reject unsafe predictions during inference.\nVarious techniques have emerged to establish rejection scores that maximize the\nseparability between the distributions of safe and unsafe predictions. The\nefficacy of these approaches is mostly evaluated using threshold-agnostic\nmetrics, such as the area under the receiver operating characteristic curve.\nHowever, in real-world applications, an effective monitor also requires\nidentifying a good threshold to transform these scores into meaningful binary\ndecisions. Despite the pivotal importance of threshold optimization, this\nproblem has received little attention. A few studies touch upon this question,\nbut they typically assume that the runtime data distribution mirrors the\ntraining distribution, which is a strong assumption as monitors are supposed to\nsafeguard a system against potentially unforeseen threats. In this work, we\npresent rigorous experiments on various image datasets to investigate: 1. The\neffectiveness of monitors in handling unforeseen threats, which are not\navailable during threshold adjustments. 2. Whether integrating generic threats\ninto the threshold optimization scheme can enhance the robustness of monitors.",
      "tldr_zh": "本研究通过实证实验探讨了神经网络监控中阈值选择的挑战，旨在评估监控系统对未知威胁的防御能力。论文指出，现有的监控方法通常依赖阈值无关指标如receiver operating characteristic curve (ROC)面积，但实际应用需优化阈值以处理运行时数据分布与训练分布不同的情况。实验在各种图像数据集上测试了监控在面对不可预见威胁时的有效性，并考察了将通用威胁整合到阈值优化方案中是否能提升监控的鲁棒性。结果为改进神经网络的安全性提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 5 figures, 6 tables. To appear in the proceedings of the\n  40th Conference on Uncertainty in Artificial Intelligence (UAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.08654v2",
      "published_date": "2024-05-14 14:32:58 UTC",
      "updated_date": "2024-05-21 07:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:24:42.458033"
    },
    {
      "arxiv_id": "2405.08644v1",
      "title": "Thinking Tokens for Language Modeling",
      "title_zh": "用于语言建模的思考令牌",
      "authors": [
        "David Herel",
        "Tomas Mikolov"
      ],
      "abstract": "How much is 56 times 37? Language models often make mistakes in these types\nof difficult calculations. This is usually explained by their inability to\nperform complex reasoning. Since language models rely on large training sets\nand great memorization capability, naturally they are not equipped to run\ncomplex calculations. However, one can argue that humans also cannot perform\nthis calculation immediately and require a considerable amount of time to\nconstruct the solution. In order to enhance the generalization capability of\nlanguage models, and as a parallel to human behavior, we propose to use special\n'thinking tokens' which allow the model to perform much more calculations\nwhenever a complex problem is encountered.",
      "tldr_zh": "语言模型在复杂计算（如56乘以37）中常出错，主要归因于其依赖训练数据和记忆能力，而非实时推理。论文提出引入特殊的 'thinking tokens'，允许模型在遇到复杂问题时进行更多计算，模仿人类需要时间构建解决方案的过程。该方法旨在提升语言模型的泛化能力，使其更好地处理未见过的计算任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AITP 2023 (May 10, 2023)",
      "pdf_url": "http://arxiv.org/pdf/2405.08644v1",
      "published_date": "2024-05-14 14:21:43 UTC",
      "updated_date": "2024-05-14 14:21:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:24:54.052874"
    },
    {
      "arxiv_id": "2405.08604v3",
      "title": "Context-aware Diversity Enhancement for Neural Multi-Objective Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yongfan Lu",
        "Zixiang Di",
        "Bingdong Li",
        "Shengcai Liu",
        "Hong Qian",
        "Peng Yang",
        "Ke Tang",
        "Aimin Zhou"
      ],
      "abstract": "Multi-objective combinatorial optimization (MOCO) problems are prevalent in\nvarious real-world applications. Most existing neural MOCO methods rely on\nproblem decomposition to transform an MOCO problem into a series of\nsinge-objective combinatorial optimization (SOCO) problems and train attention\nmodels based on a single-step and deterministic greedy rollout. However,\ninappropriate decomposition and undesirable short-sighted behaviors of previous\nmethods tend to induce a decline in diversity. To address the above limitation,\nwe design a Context-aware Diversity Enhancement algorithm named CDE, which\ncasts the neural MOCO problems as conditional sequence modeling via\nautoregression (node-level context awareness) and establishes a direct\nrelationship between the mapping of preferences and diversity indicator of\nreward based on hypervolume expectation maximization (solution-level context\nawareness). Based on the solution-level context awareness, we further propose a\nhypervolume residual update strategy to enable the Pareto attention model to\ncapture both local and non-local information of the Pareto set/front. The\nproposed CDE can effectively and efficiently grasp the context information,\nresulting in diversity enhancement. Experimental results on three classic MOCO\nproblems demonstrate that our CDE outperforms several state-of-the-art\nbaselines.",
      "tldr_zh": "该研究针对多目标组合优化 (MOCO) 问题，指出现有神经方法依赖问题分解和确定性贪婪 rollout，导致解决方案多样性下降。论文提出 Context-aware Diversity Enhancement (CDE) 算法，将 MOCO 问题建模为自回归的条件序列模型（node-level context awareness），并通过 hypervolume 期望最大化建立偏好映射与多样性指标的直接关系（solution-level context awareness）。此外，CDE 引入 hypervolume residual update 策略，使 Pareto attention model 捕获局部和非局部信息，从而有效提升多样性。实验结果显示，在三个经典 MOCO 问题上，CDE 优于多种最先进基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08604v3",
      "published_date": "2024-05-14 13:42:19 UTC",
      "updated_date": "2025-01-26 01:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:25:07.286586"
    },
    {
      "arxiv_id": "2405.13015v1",
      "title": "Assisted Debate Builder with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Elliot Faugier",
        "Frédéric Armetta",
        "Angela Bonifati",
        "Bruno Yun"
      ],
      "abstract": "We introduce ADBL2, an assisted debate builder tool. It is based on the\ncapability of large language models to generalise and perform relation-based\nargument mining in a wide-variety of domains. It is the first open-source tool\nthat leverages relation-based mining for (1) the verification of\npre-established relations in a debate and (2) the assisted creation of new\narguments by means of large language models. ADBL2 is highly modular and can\nwork with any open-source large language models that are used as plugins. As a\nby-product, we also provide the first fine-tuned Mistral-7B large language\nmodel for relation-based argument mining, usable by ADBL2, which outperforms\nexisting approaches for this task with an overall F1-score of 90.59% across all\ndomains.",
      "tldr_zh": "我们引入了 ADBL2，一种基于 Large Language Models 的辅助辩论构建工具，利用关系-based argument mining 来验证预先建立的辩论关系并辅助创建新论点，这是首个开源工具实现这一功能。ADBL2 设计高度模块化，可与任何开源 Large Language Models 插件集成。实验结果显示，我们微调的 Mistral-7B 模型在关系-based argument mining 任务上取得了 90.59% 的 F1-score，超越了现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13015v1",
      "published_date": "2024-05-14 13:42:12 UTC",
      "updated_date": "2024-05-14 13:42:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:25:18.816071"
    },
    {
      "arxiv_id": "2405.08587v1",
      "title": "EchoTracker: Advancing Myocardial Point Tracking in Echocardiography",
      "title_zh": "翻译失败",
      "authors": [
        "Md Abulkalam Azad",
        "Artem Chernyshov",
        "John Nyberg",
        "Ingrid Tveten",
        "Lasse Lovstakken",
        "Håvard Dalen",
        "Bjørnar Grenne",
        "Andreas Østvik"
      ],
      "abstract": "Tissue tracking in echocardiography is challenging due to the complex cardiac\nmotion and the inherent nature of ultrasound acquisitions. Although optical\nflow methods are considered state-of-the-art (SOTA), they struggle with\nlong-range tracking, noise occlusions, and drift throughout the cardiac cycle.\nRecently, novel learning-based point tracking techniques have been introduced\nto tackle some of these issues. In this paper, we build upon these techniques\nand introduce EchoTracker, a two-fold coarse-to-fine model that facilitates the\ntracking of queried points on a tissue surface across ultrasound image\nsequences. The architecture contains a preliminary coarse initialization of the\ntrajectories, followed by reinforcement iterations based on fine-grained\nappearance changes. It is efficient, light, and can run on mid-range GPUs.\nExperiments demonstrate that the model outperforms SOTA methods, with an\naverage position accuracy of 67% and a median trajectory error of 2.86 pixels.\nFurthermore, we show a relative improvement of 25% when using our model to\ncalculate the global longitudinal strain (GLS) in a clinical test-retest\ndataset compared to other methods. This implies that learning-based point\ntracking can potentially improve performance and yield a higher diagnostic and\nprognostic value for clinical measurements than current techniques. Our source\ncode is available at: https://github.com/riponazad/echotracker/.",
      "tldr_zh": "这篇论文针对超声心动图中组织跟踪的挑战，如复杂的心脏运动和图像噪声，引入了 EchoTracker，一种两阶段粗到细的点跟踪模型。模型首先进行粗略轨迹初始化，然后通过基于细粒度外观变化的强化迭代来优化跟踪精度，该架构高效轻量，可在中等性能的 GPUs 上运行。实验结果显示，EchoTracker 优于现有最先进（SOTA）方法，平均位置准确率达到 67%，中位轨迹误差为 2.86 像素，并在临床测试-再测试数据集上计算全局纵向应变（GLS）时实现 25% 的相对改善。这表明基于学习的点跟踪技术可提升临床测量的诊断和预后价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted version that got provisionally (early) accepted (top 11%)\n  to MICCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08587v1",
      "published_date": "2024-05-14 13:24:51 UTC",
      "updated_date": "2024-05-14 13:24:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:25:32.763876"
    },
    {
      "arxiv_id": "2405.08576v1",
      "title": "Hearing Touch: Audio-Visual Pretraining for Contact-Rich Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Jared Mejia",
        "Victoria Dean",
        "Tess Hellebrekers",
        "Abhinav Gupta"
      ],
      "abstract": "Although pre-training on a large amount of data is beneficial for robot\nlearning, current paradigms only perform large-scale pretraining for visual\nrepresentations, whereas representations for other modalities are trained from\nscratch. In contrast to the abundance of visual data, it is unclear what\nrelevant internet-scale data may be used for pretraining other modalities such\nas tactile sensing. Such pretraining becomes increasingly crucial in the\nlow-data regimes common in robotics applications. In this paper, we address\nthis gap by using contact microphones as an alternative tactile sensor. Our key\ninsight is that contact microphones capture inherently audio-based information,\nallowing us to leverage large-scale audio-visual pretraining to obtain\nrepresentations that boost the performance of robotic manipulation. To the best\nof our knowledge, our method is the first approach leveraging large-scale\nmultisensory pre-training for robotic manipulation. For supplementary\ninformation including videos of real robot experiments, please see\nhttps://sites.google.com/view/hearing-touch.",
      "tldr_zh": "该论文指出，现有的机器人学习仅对视觉表示进行大规模预训练，而触觉等其他模态则从零开始训练，导致在低数据环境中表现欠佳。为解决这一问题，研究者使用接触麦克风作为触觉传感器，利用音频-视觉 pretraining 来获取增强的表示，从而提升接触丰富 manipulation 的性能。到目前为止，这是首个基于大规模多感官 pretraining 的方法，为机器人应用提供了新途径。实验结果显示，该方法显著改善了机器人操作的表现。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08576v1",
      "published_date": "2024-05-14 13:16:46 UTC",
      "updated_date": "2024-05-14 13:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:25:41.878619"
    },
    {
      "arxiv_id": "2405.13014v2",
      "title": "QCRD: Quality-guided Contrastive Rationale Distillation for Large Language Models",
      "title_zh": "QCRD：质量引导的对比推理蒸馏，用于大型语言模型",
      "authors": [
        "Wei Wang",
        "Zhaowei Li",
        "Qi Xu",
        "Yiqing Cai",
        "Hang Song",
        "Qi Qi",
        "Ran Zhou",
        "Zhida Huang",
        "Tao Wang",
        "Li Xiao"
      ],
      "abstract": "The deployment of large language models (LLMs) faces considerable challenges\nconcerning resource constraints and inference efficiency. Recent research has\nincreasingly focused on smaller, task-specific models enhanced by distilling\nknowledge from LLMs. However, prior studies have often overlooked the diversity\nand quality of knowledge, especially the untapped potential of negative\nknowledge. Constructing effective negative knowledge remains severely\nunderstudied. In this paper, we introduce a novel framework called\nquality-guided contrastive rationale distillation aimed at enhancing reasoning\ncapabilities through contrastive knowledge learning. For positive knowledge, we\nenrich its diversity through temperature sampling and employ self-consistency\nfor further denoising and refinement. For negative knowledge, we propose an\ninnovative self-adversarial approach that generates low-quality rationales by\nsampling previous iterations of smaller language models, embracing the idea\nthat one can learn from one's own weaknesses. A contrastive loss is developed\nto distill both positive and negative knowledge into smaller language models,\nwhere an online-updating discriminator is integrated to assess qualities of\nrationales and assign them appropriate weights, optimizing the training\nprocess. Through extensive experiments across multiple reasoning tasks, we\ndemonstrate that our method consistently outperforms existing distillation\ntechniques, yielding higher-quality rationales.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 的部署挑战，提出了一种名为 QCRD 的质量引导对比推理提炼框架，以提升较小语言模型的推理能力。该框架通过温度采样和自一致性增强正面知识的多样性与质量，同时采用自对抗方法从模型先前迭代生成负面知识，允许模型从自身弱点中学习。QCRD 整合对比损失函数和在线更新鉴别器来评估并加权推理质量，优化训练过程；实验结果显示，该方法在多个推理任务上显著优于现有提炼技术，提供更高质量的推理输出。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13014v2",
      "published_date": "2024-05-14 13:07:10 UTC",
      "updated_date": "2024-09-19 07:23:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:25:56.319962"
    },
    {
      "arxiv_id": "2405.08540v1",
      "title": "Generalizing Knowledge Graph Embedding with Universal Orthogonal Parameterization",
      "title_zh": "通用正交参数化的知识图谱嵌入泛化",
      "authors": [
        "Rui Li",
        "Chaozhuo Li",
        "Yanming Shen",
        "Zeyu Zhang",
        "Xu Chen"
      ],
      "abstract": "Recent advances in knowledge graph embedding (KGE) rely on\nEuclidean/hyperbolic orthogonal relation transformations to model intrinsic\nlogical patterns and topological structures. However, existing approaches are\nconfined to rigid relational orthogonalization with restricted dimension and\nhomogeneous geometry, leading to deficient modeling capability. In this work,\nwe move beyond these approaches in terms of both dimension and geometry by\nintroducing a powerful framework named GoldE, which features a universal\northogonal parameterization based on a generalized form of Householder\nreflection. Such parameterization can naturally achieve dimensional extension\nand geometric unification with theoretical guarantees, enabling our framework\nto simultaneously capture crucial logical patterns and inherent topological\nheterogeneity of knowledge graphs. Empirically, GoldE achieves state-of-the-art\nperformance on three standard benchmarks. Codes are available at\nhttps://github.com/xxrep/GoldE.",
      "tldr_zh": "该论文提出了一种名为 GoldE 的框架，用于泛化知识图嵌入 (KGE)，通过引入基于广义 Householder reflection 的通用正交参数化，超越了现有方法的维度限制和同质几何问题。GoldE 框架能够实现维度的扩展和几何的统一，具有理论保证，从而同时捕捉知识图的关键逻辑模式和固有的拓扑异质性。相比传统依赖欧式/双曲正交关系变换的 KGE 模型，该方法显著提升了建模能力。在三个标准基准测试中，GoldE 取得了最先进性能，代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08540v1",
      "published_date": "2024-05-14 12:26:19 UTC",
      "updated_date": "2024-05-14 12:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:26:08.724137"
    },
    {
      "arxiv_id": "2406.00006v1",
      "title": "A Prompt-driven Task Planning Method for Multi-drones based on Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yaohua Liu"
      ],
      "abstract": "With the rapid development of drone technology, the application of\nmulti-drones is becoming increasingly widespread in various fields. However,\nthe task planning technology for multi-drones still faces challenges such as\nthe complexity of remote operation and the convenience of human-machine\ninteraction. To address these issues, this paper proposes a prompt-driven task\nplanning method for multi-drones based on large language models. By introducing\nthe Prompt technique, appropriate prompt information is provided for the\nmulti-drone system.",
      "tldr_zh": "这篇论文针对多无人机的任务规划问题，解决了远程操作复杂性和人机交互不便等挑战，提出了一种基于 Large Language Model 的提示驱动方法。方法通过引入 Prompt 技术，为多无人机系统提供适当的提示信息，以简化任务规划过程。该方法有望提升多无人机应用的便利性和效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00006v1",
      "published_date": "2024-05-14 12:24:39 UTC",
      "updated_date": "2024-05-14 12:24:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:26:20.913728"
    },
    {
      "arxiv_id": "2405.08528v2",
      "title": "From Internet of Things Data to Business Processes: Challenges and a Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Juergen Mangler",
        "Ronny Seiger",
        "Janik-Vasily Benzin",
        "Joscha Grüger",
        "Yusuf Kirikkayis",
        "Florian Gallik",
        "Lukas Malburg",
        "Matthias Ehrendorfer",
        "Yannis Bertrand",
        "Marco Franceschetti",
        "Barbara Weber",
        "Stefanie Rinderle-Ma",
        "Ralph Bergmann",
        "Estefanía Serral Asensio",
        "Manfred Reichert"
      ],
      "abstract": "The IoT and Business Process Management (BPM) communities co-exist in many\nshared application domains, such as manufacturing and healthcare. The IoT\ncommunity has a strong focus on hardware, connectivity and data; the BPM\ncommunity focuses mainly on finding, controlling, and enhancing the structured\ninteractions among the IoT devices in processes. While the field of Process\nMining deals with the extraction of process models and process analytics from\nprocess event logs, the data produced by IoT sensors often is at a lower\ngranularity than these process-level events. The fundamental questions about\nextracting and abstracting process-related data from streams of IoT sensor\nvalues are: (1) Which sensor values can be clustered together as part of\nprocess events?, (2) Which sensor values signify the start and end of such\nevents?, (3) Which sensor values are related but not essential? This work\nproposes a framework to semi-automatically perform a set of structured steps to\nconvert low-level IoT sensor data into higher-level process events that are\nsuitable for process mining. The framework is meant to provide a generic\nsequence of abstract steps to guide the event extraction, abstraction, and\ncorrelation, with variation points for plugging in specific analysis techniques\nand algorithms for each step. To assess the completeness of the framework, we\npresent a set of challenges, how they can be tackled through the framework, and\nan example on how to instantiate the framework in a real-world demonstration\nfrom the field of smart manufacturing. Based on this framework, future research\ncan be conducted in a structured manner through refining and improving\nindividual steps.",
      "tldr_zh": "这篇论文探讨了从物联网（IoT）数据中提取业务流程（BPM）的挑战，包括如何聚类传感器值作为过程事件、识别事件的开始和结束，以及区分相关但非必需的值。论文提出一个框架，通过半自动化的结构化步骤（如事件提取、抽象和相关性分析）将低级IoT传感器数据转换为适合Process Mining的高级过程事件，该框架允许插入特定算法以实现灵活性。为了评估框架的完整性，论文分析了相关挑战、框架的应用示例（如智能制造领域），并为未来研究提供结构化的改进路径。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "H.3.3; I.2.1"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08528v2",
      "published_date": "2024-05-14 12:07:07 UTC",
      "updated_date": "2024-05-22 13:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:26:33.616419"
    },
    {
      "arxiv_id": "2405.08848v1",
      "title": "Automated Repair of AI Code with Large Language Models and Formal Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Yiannis Charalambous",
        "Edoardo Manino",
        "Lucas C. Cordeiro"
      ],
      "abstract": "The next generation of AI systems requires strong safety guarantees. This\nreport looks at the software implementation of neural networks and related\nmemory safety properties, including NULL pointer deference, out-of-bound\naccess, double-free, and memory leaks. Our goal is to detect these\nvulnerabilities, and automatically repair them with the help of large language\nmodels. To this end, we first expand the size of NeuroCodeBench, an existing\ndataset of neural network code, to about 81k programs via an automated process\nof program mutation. Then, we verify the memory safety of the mutated neural\nnetwork implementations with ESBMC, a state-of-the-art software verifier.\nWhenever ESBMC spots a vulnerability, we invoke a large language model to\nrepair the source code. For the latest task, we compare the performance of\nvarious state-of-the-art prompt engineering techniques, and an iterative\napproach that repeatedly calls the large language model.",
      "tldr_zh": "本论文提出了一种自动修复 AI 代码中内存安全问题的框架，使用 Large Language Models (LLMs) 和 Formal Verification 技术，针对漏洞如 NULL 指针引用、越界访问、双重释放和内存泄漏。研究者首先扩展了 NeuroCodeBench 数据集至约 81k 程序，通过程序变异过程，并采用 ESBMC 验证器检测这些漏洞。接下来，调用 LLMs 进行代码修复，并比较了各种提示工程技巧和迭代方法的性能。该方法为提升 AI 系统安全性提供了有效途径，展示了自动修复的可行性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08848v1",
      "published_date": "2024-05-14 11:52:56 UTC",
      "updated_date": "2024-05-14 11:52:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:26:45.403753"
    },
    {
      "arxiv_id": "2405.08510v1",
      "title": "Growing Artificial Neural Networks for Control: the Role of Neuronal Diversity",
      "title_zh": "翻译失败",
      "authors": [
        "Eleni Nisioti",
        "Erwan Plantec",
        "Milton Montero",
        "Joachim Winther Pedersen",
        "Sebastian Risi"
      ],
      "abstract": "In biological evolution complex neural structures grow from a handful of\ncellular ingredients. As genomes in nature are bounded in size, this complexity\nis achieved by a growth process where cells communicate locally to decide\nwhether to differentiate, proliferate and connect with other cells. This\nself-organisation is hypothesized to play an important part in the\ngeneralisation, and robustness of biological neural networks. Artificial neural\nnetworks (ANNs), on the other hand, are traditionally optimized in the space of\nweights. Thus, the benefits and challenges of growing artificial neural\nnetworks remain understudied. Building on the previously introduced Neural\nDevelopmental Programs (NDP), in this work we present an algorithm for growing\nANNs that solve reinforcement learning tasks. We identify a key challenge:\nensuring phenotypic complexity requires maintaining neuronal diversity, but\nthis diversity comes at the cost of optimization stability. To address this, we\nintroduce two mechanisms: (a) equipping neurons with an intrinsic state\ninherited upon neurogenesis; (b) lateral inhibition, a mechanism inspired by\nbiological growth, which controlls the pace of growth, helping diversity\npersist. We show that both mechanisms contribute to neuronal diversity and\nthat, equipped with them, NDPs achieve comparable results to existing direct\nand developmental encodings in complex locomotion tasks",
      "tldr_zh": "本文研究了生长人工神经网络(ANNs)用于控制任务的过程，强调神经元多样性在提升网络泛化和鲁棒性方面的关键作用。基于Neural Developmental Programs (NDP)，作者提出了一种算法，通过为神经元配备遗传的内在状态和引入横向抑制(lateral inhibition)机制来维持多样性，从而解决优化稳定性与复杂性之间的挑战。实验结果表明，该方法在强化学习任务中与现有直接和发育编码方法取得了可比的性能表现。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08510v1",
      "published_date": "2024-05-14 11:21:52 UTC",
      "updated_date": "2024-05-14 11:21:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:26:57.067690"
    },
    {
      "arxiv_id": "2405.17441v2",
      "title": "When Large Language Models Meet Optical Networks: Paving the Way for Automation",
      "title_zh": "当大型语言模型遇见光网络：为自动化铺平道路",
      "authors": [
        "Danshi Wang",
        "Yidi Wang",
        "Xiaotian Jiang",
        "Yao Zhang",
        "Yue Pang",
        "Min Zhang"
      ],
      "abstract": "Since the advent of GPT, large language models (LLMs) have brought about\nrevolutionary advancements in all walks of life. As a superior natural language\nprocessing (NLP) technology, LLMs have consistently achieved state-of-the-art\nperformance on numerous areas. However, LLMs are considered to be\ngeneral-purpose models for NLP tasks, which may encounter challenges when\napplied to complex tasks in specialized fields such as optical networks. In\nthis study, we propose a framework of LLM-empowered optical networks,\nfacilitating intelligent control of the physical layer and efficient\ninteraction with the application layer through an LLM-driven agent (AI-Agent)\ndeployed in the control layer. The AI-Agent can leverage external tools and\nextract domain knowledge from a comprehensive resource library specifically\nestablished for optical networks. This is achieved through user input and\nwell-crafted prompts, enabling the generation of control instructions and\nresult representations for autonomous operation and maintenance in optical\nnetworks. To improve LLM's capability in professional fields and stimulate its\npotential on complex tasks, the details of performing prompt engineering,\nestablishing domain knowledge library, and implementing complex tasks are\nillustrated in this study. Moreover, the proposed framework is verified on two\ntypical tasks: network alarm analysis and network performance optimization. The\ngood response accuracies and sematic similarities of 2,400 test situations\nexhibit the great potential of LLM in optical networks.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 在光学网络领域的应用，以实现自动化。论文提出一个LLM赋能的光学网络框架，通过部署在控制层的AI-Agent，利用外部工具和专门的光学网络知识库，以及精心设计的提示工程(prompt engineering)，来生成控制指令并处理复杂任务。该框架实现了物理层智能控制和应用层高效交互，并在网络警报分析和网络性能优化两个典型任务上进行了验证。实验结果显示，在2400个测试场景中，响应准确性和语义相似度表现出色，证明了LLMs在光学网络中推动自动化的巨大潜力。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CL",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17441v2",
      "published_date": "2024-05-14 10:46:33 UTC",
      "updated_date": "2024-06-25 03:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:27:08.638782"
    },
    {
      "arxiv_id": "2405.13013v2",
      "title": "Amplifying Aspect-Sentence Awareness: A Novel Approach for Aspect-Based Sentiment Analysis",
      "title_zh": "增强方面-句子意识：一种基于方面的情感分析的新颖方法",
      "authors": [
        "Adamu Lawan",
        "Juhua Pu",
        "Haruna Yunusa",
        "Jawad Muhammad",
        "Aliyu Umar"
      ],
      "abstract": "Aspect-Based Sentiment Analysis (ABSA) is increasingly crucial in Natural\nLanguage Processing (NLP) for applications such as customer feedback analysis\nand product recommendation systems. ABSA goes beyond traditional sentiment\nanalysis by extracting sentiments related to specific aspects mentioned in the\ntext; existing attention-based models often need help to effectively connect\naspects with context due to language complexity and multiple sentiment\npolarities in a single sentence. Recent research underscores the value of\nintegrating syntactic information, such as dependency trees, to understand\nlong-range syntactic relationships better and link aspects with context.\nDespite these advantages, challenges persist, including sensitivity to parsing\nerrors and increased computational complexity when combining syntactic and\nsemantic information. To address these issues, we propose Amplifying\nAspect-Sentence Awareness (A3SN), a novel technique designed to enhance ABSA\nthrough amplifying aspect-sentence awareness attention. Following the\ntransformer's standard process, our innovative approach incorporates multi-head\nattention mechanisms to augment the model with sentence and aspect semantic\ninformation. We added another multi-head attention module: amplify\naspect-sentence awareness attention. By doubling its focus between the sentence\nand aspect, we effectively highlighted aspect importance within the sentence\ncontext. This enables accurate capture of subtle relationships and\ndependencies. Additionally, gated fusion integrates feature representations\nfrom multi-head and amplified aspect-sentence awareness attention mechanisms,\nwhich is essential for ABSA. Experimental results across three benchmark\ndatasets demonstrate A3SN's effectiveness and outperform state-of-the-art\n(SOTA) baseline models.",
      "tldr_zh": "本论文针对Aspect-Based Sentiment Analysis (ABSA) 的挑战，提出了一种新方法Amplifying Aspect-Sentence Awareness (A3SN)，旨在通过增强方面-句子意识注意力来更好地连接文本中的特定方面与上下文，解决语言复杂性和多情感极性问题。A3SN 在Transformer的标准过程中添加了一个多头注意力模块（amplify aspect-sentence awareness attention），并使用gated fusion整合特征表示，以突出方面的关键性和捕捉细微关系。实验结果显示，该方法在三个基准数据集上超过了state-of-the-art (SOTA) 基线模型，证明了其在情感分析中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 4 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.13013v2",
      "published_date": "2024-05-14 10:29:59 UTC",
      "updated_date": "2024-10-26 21:09:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:27:20.995334"
    },
    {
      "arxiv_id": "2405.08483v1",
      "title": "RDPN6D: Residual-based Dense Point-wise Network for 6Dof Object Pose Estimation Based on RGB-D Images",
      "title_zh": "翻译失败",
      "authors": [
        "Zong-Wei Hong",
        "Yen-Yang Hung",
        "Chu-Song Chen"
      ],
      "abstract": "In this work, we introduce a novel method for calculating the 6DoF pose of an\nobject using a single RGB-D image. Unlike existing methods that either directly\npredict objects' poses or rely on sparse keypoints for pose recovery, our\napproach addresses this challenging task using dense correspondence, i.e., we\nregress the object coordinates for each visible pixel. Our method leverages\nexisting object detection methods. We incorporate a re-projection mechanism to\nadjust the camera's intrinsic matrix to accommodate cropping in RGB-D images.\nMoreover, we transform the 3D object coordinates into a residual\nrepresentation, which can effectively reduce the output space and yield\nsuperior performance. We conducted extensive experiments to validate the\nefficacy of our approach for 6D pose estimation. Our approach outperforms most\nprevious methods, especially in occlusion scenarios, and demonstrates notable\nimprovements over the state-of-the-art methods. Our code is available on\nhttps://github.com/AI-Application-and-Integration-Lab/RDPN6D.",
      "tldr_zh": "本文提出了一种名为 RDPN6D 的新方法，用于基于单张 RGB-D 图像进行 6DoF 物体姿态估计。该方法通过密集对应（dense correspondence）回归每个可见像素的物体坐标，并采用 residual representation 将 3D 坐标转换为残差形式，以减少输出空间并提升性能，同时整合再投影机制（re-projection mechanism）调整相机内参矩阵。实验结果表明，RDPN6D 在遮挡场景中显著优于现有方法，并在整体性能上超越了 state-of-the-art 技术，该方法的代码已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR Workshop DLGC, 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08483v1",
      "published_date": "2024-05-14 10:10:45 UTC",
      "updated_date": "2024-05-14 10:10:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:27:33.392800"
    },
    {
      "arxiv_id": "2405.08469v1",
      "title": "GPT-3.5 for Grammatical Error Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Anisia Katinskaia",
        "Roman Yangarber"
      ],
      "abstract": "This paper investigates the application of GPT-3.5 for Grammatical Error\nCorrection (GEC) in multiple languages in several settings: zero-shot GEC,\nfine-tuning for GEC, and using GPT-3.5 to re-rank correction hypotheses\ngenerated by other GEC models. In the zero-shot setting, we conduct automatic\nevaluations of the corrections proposed by GPT-3.5 using several methods:\nestimating grammaticality with language models (LMs), the Scribendi test, and\ncomparing the semantic embeddings of sentences. GPT-3.5 has a known tendency to\nover-correct erroneous sentences and propose alternative corrections. For\nseveral languages, such as Czech, German, Russian, Spanish, and Ukrainian,\nGPT-3.5 substantially alters the source sentences, including their semantics,\nwhich presents significant challenges for evaluation with reference-based\nmetrics. For English, GPT-3.5 demonstrates high recall, generates fluent\ncorrections, and generally preserves sentence semantics. However, human\nevaluation for both English and Russian reveals that, despite its strong\nerror-detection capabilities, GPT-3.5 struggles with several error types,\nincluding punctuation mistakes, tense errors, syntactic dependencies between\nwords, and lexical compatibility at the sentence level.",
      "tldr_zh": "本论文探讨了 GPT-3.5 在多语言语法错误修正 (GEC) 中的应用，包括零样本 GEC、微调 GEC 以及使用 GPT-3.5 重新排序其他模型的修正假设。研究通过语言模型估计、Scribendi 测试和句子语义嵌入等自动评估方法发现，GPT-3.5 在英语中表现出高召回率和流畅修正，但倾向于过度修正并可能改变某些语言（如捷克语、德语、俄语、西班牙语和乌克兰语）的句子语义。人类评估进一步揭示，GPT-3.5 虽在错误检测方面强大，但处理标点错误、时态错误、句法依赖和词汇兼容性时存在挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08469v1",
      "published_date": "2024-05-14 09:51:09 UTC",
      "updated_date": "2024-05-14 09:51:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:27:46.934959"
    },
    {
      "arxiv_id": "2405.08468v1",
      "title": "Challenges and Opportunities in Text Generation Explainability",
      "title_zh": "文本生成可解释性的挑战与机遇",
      "authors": [
        "Kenza Amara",
        "Rita Sevastjanova",
        "Mennatallah El-Assady"
      ],
      "abstract": "The necessity for interpretability in natural language processing (NLP) has\nrisen alongside the growing prominence of large language models. Among the\nmyriad tasks within NLP, text generation stands out as a primary objective of\nautoregressive models. The NLP community has begun to take a keen interest in\ngaining a deeper understanding of text generation, leading to the development\nof model-agnostic explainable artificial intelligence (xAI) methods tailored to\nthis task. The design and evaluation of explainability methods are non-trivial\nsince they depend on many factors involved in the text generation process,\ne.g., the autoregressive model and its stochastic nature. This paper outlines\n17 challenges categorized into three groups that arise during the development\nand assessment of attribution-based explainability methods. These challenges\nencompass issues concerning tokenization, defining explanation similarity,\ndetermining token importance and prediction change metrics, the level of human\nintervention required, and the creation of suitable test datasets. The paper\nillustrates how these challenges can be intertwined, showcasing new\nopportunities for the community. These include developing probabilistic\nword-level explainability methods and engaging humans in the explainability\npipeline, from the data design to the final evaluation, to draw robust\nconclusions on xAI methods.",
      "tldr_zh": "这篇论文探讨了自然语言处理(NLP)中文本生成任务的解释性(xAI)挑战与机遇，随着大型语言模型的兴起，解释性需求日益增加。论文概述了17个归因基于(attribution-based)解释性方法的挑战，分为三类，包括分词(tokenization)、解释相似性、标记重要性(token importance)和预测变化指标、所需的人为干预水平，以及合适测试数据集的创建，这些问题因自回归模型的随机性而复杂。作者强调这些挑战相互关联，提供了新机会，如开发概率词级(probabilistic word-level)解释性方法，并在从数据设计到最终评估的解释性流程中增加人为参与，以得出更可靠的xAI结论。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 5 figures, xAI-2024 Conference, Main track",
      "pdf_url": "http://arxiv.org/pdf/2405.08468v1",
      "published_date": "2024-05-14 09:44:52 UTC",
      "updated_date": "2024-05-14 09:44:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:27:56.009597"
    },
    {
      "arxiv_id": "2405.08467v1",
      "title": "Equilibrium Propagation: the Quantum and the Thermal Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Serge Massar",
        "Bortolo Matteo Mognetti"
      ],
      "abstract": "Equilibrium propagation is a recently introduced method to use and train\nartificial neural networks in which the network is at the minimum (more\ngenerally extremum) of an energy functional. Equilibrium propagation has shown\ngood performance on a number of benchmark tasks. Here we extend equilibrium\npropagation in two directions. First we show that there is a natural quantum\ngeneralization of equilibrium propagation in which a quantum neural network is\ntaken to be in the ground state (more generally any eigenstate) of the network\nHamiltonian, with a similar training mechanism that exploits the fact that the\nmean energy is extremal on eigenstates. Second we extend the analysis of\nequilibrium propagation at finite temperature, showing that thermal\nfluctuations allow one to naturally train the network without having to clamp\nthe output layer during training. We also study the low temperature limit of\nequilibrium propagation.",
      "tldr_zh": "这篇论文扩展了 Equilibrium Propagation 方法，用于训练神经网络，使其处于能量函数的极值状态。作者首先提出量子泛化，将量子神经网络置于 Hamiltonian 的基态（或本征态），并通过利用平均能量在本征态上的极值特性实现类似训练机制。其次，在热力学方面，论文展示了有限温度下热涨落的益处，能够自然训练网络而无需固定输出层，并分析了低温度极限。这些扩展为 Equilibrium Propagation 在量子和热力学场景下的应用提供了新框架。",
      "categories": [
        "quant-ph",
        "cond-mat.stat-mech",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08467v1",
      "published_date": "2024-05-14 09:43:32 UTC",
      "updated_date": "2024-05-14 09:43:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:28:10.063596"
    },
    {
      "arxiv_id": "2405.08465v1",
      "title": "How to Surprisingly Consider Recommendations? A Knowledge-Graph-based Approach Relying on Complex Network Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Baumann",
        "Durgesh Nandini",
        "Anderson Rossanez",
        "Mirco Schoenfeld",
        "Julio Cesar dos Reis"
      ],
      "abstract": "Traditional recommendation proposals, including content-based and\ncollaborative filtering, usually focus on similarity between items or users.\nExisting approaches lack ways of introducing unexpectedness into\nrecommendations, prioritizing globally popular items over exposing users to\nunforeseen items. This investigation aims to design and evaluate a novel layer\non top of recommender systems suited to incorporate relational information and\nsuggest items with a user-defined degree of surprise. We propose a Knowledge\nGraph (KG) based recommender system by encoding user interactions on item\ncatalogs. Our study explores whether network-level metrics on KGs can influence\nthe degree of surprise in recommendations. We hypothesize that surprisingness\ncorrelates with certain network metrics, treating user profiles as subgraphs\nwithin a larger catalog KG. The achieved solution reranks recommendations based\non their impact on structural graph metrics. Our research contributes to\noptimizing recommendations to reflect the metrics. We experimentally evaluate\nour approach on two datasets of LastFM listening histories and synthetic\nNetflix viewing profiles. We find that reranking items based on complex network\nmetrics leads to a more unexpected and surprising composition of recommendation\nlists.",
      "tldr_zh": "本研究针对传统推荐系统（如基于内容的和协同过滤的）缺乏意外性的问题，提出了一种基于 Knowledge Graph (KG) 的方法，通过编码用户交互并利用复杂网络指标（如结构图指标）来重新排序推荐列表，以实现用户定义的惊喜程度。  \n该方法假设意外性与 KG 中的网络级指标相关，将用户配置文件视为子图，并通过实验验证了这种相关性。  \n在 LastFM 听歌历史和合成 Netflix 查看配置文件的数据集上评估结果显示，基于复杂网络指标的重新排序显著提高了推荐列表的意外性和惊喜性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.SI",
        "H.5.0; H.5.1; H.3.4; H.4.0; I.2.4"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08465v1",
      "published_date": "2024-05-14 09:38:44 UTC",
      "updated_date": "2024-05-14 09:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:28:21.790226"
    },
    {
      "arxiv_id": "2405.08460v3",
      "title": "Is Your LLM Outdated? A Deep Look at Temporal Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghao Zhu",
        "Nuo Chen",
        "Yufei Gao",
        "Yunyi Zhang",
        "Prayag Tiwari",
        "Benyou Wang"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has led to the\ndevelopment of benchmarks that consider temporal dynamics, however, there\nremains a gap in understanding how well these models can generalize across\ntemporal contexts due to the inherent dynamic nature of language and\ninformation. This paper introduces the concept of temporal generalization in\nLLMs, including bias in past and future generalizations. Then we introduce\nFreshBench, a new evaluation framework that employs fresh text and event\nprediction for assessing LLMs' temporal adaptability, ensuring the evaluation\nprocess free from data leakage and subjective bias. The experiment shows\nsignificant temporal biases and a decline in performance over time. Our\nfindings reveal that powerful models, while initially superior, tend to decline\nmore rapidly in future generalization. Additionally, powerful open-source\nmodels demonstrate better long-term adaptability compared to their\nclosed-source counterparts. Our code is available at\nhttps://github.com/FreedomIntelligence/FreshBench.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLM)的 temporal generalization 问题，分析了模型在时间动态下的泛化偏差，包括过去和未来的表现衰退。作者引入了 FreshBench 框架，该框架利用新鲜文本和事件预测进行评估，确保过程免受数据泄漏和主观偏差的影响。实验结果显示，LLM 存在显著的时间偏差，性能随时间推移而下降，且强大模型的未来泛化能力下降更快，而开源模型在长期适应性上优于闭源模型。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Oral",
      "pdf_url": "http://arxiv.org/pdf/2405.08460v3",
      "published_date": "2024-05-14 09:31:31 UTC",
      "updated_date": "2025-04-02 07:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:28:33.257054"
    },
    {
      "arxiv_id": "2405.08448v1",
      "title": "Understanding the performance gap between online and offline alignment algorithms",
      "title_zh": "理解在线和离线对齐算法之间的性能差距",
      "authors": [
        "Yunhao Tang",
        "Daniel Zhaohan Guo",
        "Zeyu Zheng",
        "Daniele Calandriello",
        "Yuan Cao",
        "Eugene Tarassov",
        "Rémi Munos",
        "Bernardo Ávila Pires",
        "Michal Valko",
        "Yong Cheng",
        "Will Dabney"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) is the canonical framework\nfor large language model alignment. However, rising popularity in offline\nalignment algorithms challenge the need for on-policy sampling in RLHF. Within\nthe context of reward over-optimization, we start with an opening set of\nexperiments that demonstrate the clear advantage of online methods over offline\nmethods. This prompts us to investigate the causes to the performance\ndiscrepancy through a series of carefully designed experimental ablations. We\nshow empirically that hypotheses such as offline data coverage and data quality\nby itself cannot convincingly explain the performance difference. We also find\nthat while offline algorithms train policy to become good at pairwise\nclassification, it is worse at generations; in the meantime the policies\ntrained by online algorithms are good at generations while worse at pairwise\nclassification. This hints at a unique interplay between discriminative and\ngenerative capabilities, which is greatly impacted by the sampling process.\nLastly, we observe that the performance discrepancy persists for both\ncontrastive and non-contrastive loss functions, and appears not to be addressed\nby simply scaling up policy networks. Taken together, our study sheds light on\nthe pivotal role of on-policy sampling in AI alignment, and hints at certain\nfundamental challenges of offline alignment algorithms.",
      "tldr_zh": "该研究比较了在线和离线对齐算法在强化学习从人类反馈 (RLHF) 中的性能差异，实验显示在线方法在奖励过优化方面明显优于离线方法。通过一系列实验消融，研究者发现数据覆盖和质量等因素无法充分解释这一差距，而是与采样过程相关的判别和生成能力的互动有关。结果表明，离线算法在配对分类上表现较好但在生成任务上较弱，而在线算法则相反；这种差异在对比和非对比损失函数下均存在，且通过扩大策略网络无法解决。该研究强调了在线采样的关键作用，并揭示了离线对齐算法的根本挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08448v1",
      "published_date": "2024-05-14 09:12:30 UTC",
      "updated_date": "2024-05-14 09:12:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:28:45.502904"
    },
    {
      "arxiv_id": "2405.08427v1",
      "title": "Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent Recognition: A New Task, Dataset and Baseline",
      "title_zh": "贴纸对多模态聊天情感分析和意图识别的影响：一个新任务、数据集和基线",
      "authors": [
        "Yuanchen Shi",
        "Biao Ma",
        "Fang Kong"
      ],
      "abstract": "Stickers are increasingly used in social media to express sentiment and\nintent. When finding typing troublesome, people often use a sticker instead.\nDespite the significant impact of stickers on sentiment analysis and intent\nrecognition, little research has been conducted. To address this gap, we\npropose a new task: Multimodal chat Sentiment Analysis and Intent Recognition\ninvolving Stickers (MSAIRS). Additionally, we introduce a novel multimodal\ndataset containing Chinese chat records and stickers excerpted from several\nmainstream social media platforms. Our dataset includes paired data with the\nsame text but different stickers, and various stickers consisting of the same\nimages with different texts, allowing us to better understand the impact of\nstickers on chat sentiment and intent. We also propose an effective multimodal\njoint model, MMSAIR, for our task, which is validated on our datasets and\nindicates that visual information of stickers counts. Our dataset and code will\nbe publicly available.",
      "tldr_zh": "该研究探讨了社交媒体中贴纸对多模态聊天情感分析和意图识别的影响，提出一个新任务 MSAIRS，以填补相关研究的空白。  \n他们构建了一个新数据集，包含中文聊天记录和贴纸，包括相同文本但不同贴纸的配对数据，以及相同图像但不同文本的贴纸样本，用于分析贴纸的视觉和文本作用。  \n此外，研究团队开发了多模态联合模型 MMSAIR，并在数据集上进行验证，结果显示贴纸的视觉信息对情感和意图识别有显著影响。  \n数据集和代码将公开可用，为未来研究提供基线。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.08427v1",
      "published_date": "2024-05-14 08:42:49 UTC",
      "updated_date": "2024-05-14 08:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:28:57.605291"
    },
    {
      "arxiv_id": "2405.08843v1",
      "title": "FLEXIBLE: Forecasting Cellular Traffic by Leveraging Explicit Inductive Graph-Based Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Duc Thinh Ngo",
        "Kandaraj Piamrat",
        "Ons Aouedi",
        "Thomas Hassan",
        "Philippe Raipin-Parvédy"
      ],
      "abstract": "From a telecommunication standpoint, the surge in users and services\nchallenges next-generation networks with escalating traffic demands and limited\nresources. Accurate traffic prediction can offer network operators valuable\ninsights into network conditions and suggest optimal allocation policies.\nRecently, spatio-temporal forecasting, employing Graph Neural Networks (GNNs),\nhas emerged as a promising method for cellular traffic prediction. However,\nexisting studies, inspired by road traffic forecasting formulations, overlook\nthe dynamic deployment and removal of base stations, requiring the GNN-based\nforecaster to handle an evolving graph. This work introduces a novel inductive\nlearning scheme and a generalizable GNN-based forecasting model that can\nprocess diverse graphs of cellular traffic with one-time training. We also\ndemonstrate that this model can be easily leveraged by transfer learning with\nminimal effort, making it applicable to different areas. Experimental results\nshow up to 9.8% performance improvement compared to the state-of-the-art,\nespecially in rare-data settings with training data reduced to below 20%.",
      "tldr_zh": "本论文提出FLEXIBLE框架，通过显式归纳学习方案和基于Graph Neural Networks (GNNs)的模型，来预测蜂窝流量，解决了现有方法忽略基站动态部署的问题。该模型只需一次训练即可处理多样化的时空图，并支持轻松的transfer learning以应用于不同区域。实验结果显示，与最先进方法相比，性能提升高达9.8%，特别是在训练数据少于20%的稀缺数据场景中表现突出。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08843v1",
      "published_date": "2024-05-14 07:53:23 UTC",
      "updated_date": "2024-05-14 07:53:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:29:09.292980"
    },
    {
      "arxiv_id": "2405.08842v1",
      "title": "Automated Deep Learning for Load Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Julie Keisler",
        "Sandra Claudel",
        "Gilles Cabriel",
        "Margaux Brégère"
      ],
      "abstract": "Accurate forecasting of electricity consumption is essential to ensure the\nperformance and stability of the grid, especially as the use of renewable\nenergy increases. Forecasting electricity is challenging because it depends on\nmany external factors, such as weather and calendar variables. While\nregression-based models are currently effective, the emergence of new\nexplanatory variables and the need to refine the temporality of the signals to\nbe forecasted is encouraging the exploration of novel methodologies, in\nparticular deep learning models. However, Deep Neural Networks (DNNs) struggle\nwith this task due to the lack of data points and the different types of\nexplanatory variables (e.g. integer, float, or categorical). In this paper, we\nexplain why and how we used Automated Deep Learning (AutoDL) to find performing\nDNNs for load forecasting. We ended up creating an AutoDL framework called\nEnergyDragon by extending the DRAGON package and applying it to load\nforecasting. EnergyDragon automatically selects the features embedded in the\nDNN training in an innovative way and optimizes the architecture and the\nhyperparameters of the networks. We demonstrate on the French load signal that\nEnergyDragon can find original DNNs that outperform state-of-the-art load\nforecasting methods as well as other AutoDL approaches.",
      "tldr_zh": "准确的电力负荷预测对电网稳定至关重要，尤其在可再生能源使用增加时，因为它受天气和日历变量等外部因素影响。论文提出使用 Automated Deep Learning (AutoDL) 来解决 Deep Neural Networks (DNNs) 面临的 数据点不足和变量类型多样（例如整数、浮点或分类）的问题，通过扩展 DRAGON 包创建了 EnergyDragon 框架，该框架创新性地自动选择特征并优化网络架构和超参数。在法国负荷信号上的实验显示，EnergyDragon 发现的 DNNs 超过了现有负荷预测方法和其他 AutoDL 方法，证明了其优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08842v1",
      "published_date": "2024-05-14 07:51:55 UTC",
      "updated_date": "2024-05-14 07:51:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:29:21.448026"
    },
    {
      "arxiv_id": "2405.08380v1",
      "title": "CIER: A Novel Experience Replay Approach with Causal Inference in Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwen Wang",
        "Dehui Du",
        "Yida Li",
        "Yiyang Li",
        "Yikang Chen"
      ],
      "abstract": "In the training process of Deep Reinforcement Learning (DRL), agents require\nrepetitive interactions with the environment. With an increase in training\nvolume and model complexity, it is still a challenging problem to enhance data\nutilization and explainability of DRL training. This paper addresses these\nchallenges by focusing on the temporal correlations within the time dimension\nof time series. We propose a novel approach to segment multivariate time series\ninto meaningful subsequences and represent the time series based on these\nsubsequences. Furthermore, the subsequences are employed for causal inference\nto identify fundamental causal factors that significantly impact training\noutcomes. We design a module to provide feedback on the causality during DRL\ntraining. Several experiments demonstrate the feasibility of our approach in\ncommon environments, confirming its ability to enhance the effectiveness of DRL\ntraining and impart a certain level of explainability to the training process.\nAdditionally, we extended our approach with priority experience replay\nalgorithm, and experimental results demonstrate the continued effectiveness of\nour approach.",
      "tldr_zh": "本研究提出了一种名为 CIER 的新颖经验回放方法，旨在解决深度强化学习 (DRL) 训练中数据利用和可解释性挑战，通过将多变量时间序列分割成有意义的子序列，并利用这些子序列进行因果推理来识别影响训练结果的关键因果因素。CIER 还设计了一个模块在 DRL 训练过程中提供因果反馈，并与优先经验回放 (priority experience replay) 算法相结合，以提升整体训练效率。在常见环境中进行的实验证明，该方法显著提高了 DRL 训练的有效性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08380v1",
      "published_date": "2024-05-14 07:23:10 UTC",
      "updated_date": "2024-05-14 07:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:29:32.232151"
    },
    {
      "arxiv_id": "2407.12131v1",
      "title": "Improving Health Information Access in the World's Largest Maternal Mobile Health Program via Bandit Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Arshika Lalan",
        "Shresth Verma",
        "Paula Rodriguez Diaz",
        "Panayiotis Danassis",
        "Amrita Mahale",
        "Kumar Madhu Sudan",
        "Aparna Hegde",
        "Milind Tambe",
        "Aparna Taneja"
      ],
      "abstract": "Harnessing the wide-spread availability of cell phones, many nonprofits have\nlaunched mobile health (mHealth) programs to deliver information via voice or\ntext to beneficiaries in underserved communities, with maternal and infant\nhealth being a key area of such mHealth programs. Unfortunately, dwindling\nlistenership is a major challenge, requiring targeted interventions using\nlimited resources. This paper focuses on Kilkari, the world's largest mHealth\nprogram for maternal and child care - with over 3 million active subscribers at\na time - launched by India's Ministry of Health and Family Welfare (MoHFW) and\nrun by the non-profit ARRMAN. We present a system called CHAHAK that aims to\nreduce automated dropouts as well as boost engagement with the program through\nthe strategic allocation of interventions to beneficiaries. Past work in a\nsimilar domain has focused on a much smaller scale mHealth program and used\nmarkovian restless multiarmed bandits to optimize a single limited intervention\nresource. However this paper demonstrates the challenges in adopting a\nmarkovian approach in Kilkari; therefore CHAHAK instead relies on non-markovian\ntime-series restless bandits, and optimizes multiple interventions to improve\nlistenership. We use real Kilkari data from the Odisha state in India to show\nCHAHAK's effectiveness in harnessing multiple interventions to boost\nlistenership, benefiting marginalized communities. When deployed CHAHAK will\nassist the largest maternal mHealth program to date.",
      "tldr_zh": "这篇论文针对全球最大的孕产妇移动健康(mHealth)程序Kilkari，提出了一种名为CHAHAK的系统，利用Bandit Algorithms优化多个干预措施，以减少自动退订并提升听众参与度。不同于以往针对小规模程序的Markovian restless multiarmed bandits方法，CHAHAK采用non-markovian time-series restless bandits来处理大规模场景下的复杂动态。实验基于印度Odisha州的真实数据，证明了CHAHAK能有效提高听众参与率，从而改善边缘化社区的健康信息访问。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CY",
      "comment": "Published at Innovative Applications of Artificial Intelligence (IAAI\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.12131v1",
      "published_date": "2024-05-14 07:21:49 UTC",
      "updated_date": "2024-05-14 07:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:29:45.432852"
    },
    {
      "arxiv_id": "2405.08839v1",
      "title": "PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation using Ensemble LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Satya K Gundabathula",
        "Sriram R Kolar"
      ],
      "abstract": "This paper presents our approach to the EHRSQL-2024 shared task, which aims\nto develop a reliable Text-to-SQL system for electronic health records. We\npropose two approaches that leverage large language models (LLMs) for prompting\nand fine-tuning to generate EHRSQL queries. In both techniques, we concentrate\non bridging the gap between the real-world knowledge on which LLMs are trained\nand the domain specific knowledge required for the task. The paper provides the\nresults of each approach individually, demonstrating that they achieve high\nexecution accuracy. Additionally, we show that an ensemble approach further\nenhances generation reliability by reducing errors. This approach secured us\n2nd place in the shared task competition. The methodologies outlined in this\npaper are designed to be transferable to domain-specific Text-to-SQL problems\nthat emphasize both accuracy and reliability.",
      "tldr_zh": "这篇论文介绍了PromptMind团队在EHRSQL-2024共享任务中的方法，旨在开发一个可靠的Text-to-SQL系统，用于电子健康记录。团队提出两种基于LLMs的提示和微调技术，重点桥接LLMs的通用训练知识与任务所需的领域特定知识，从而生成高质量的EHRSQL查询。结果显示，每种方法均实现了高执行准确率，而采用Ensemble LLMs的集成方法进一步减少了错误，提升了整体可靠性，最终在竞赛中获得第2名。该方法的设计具有可转移性，可应用于其他强调准确性和可靠性的领域特定Text-to-SQL问题。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "Accepted as a poster for Clinical NLP workshop at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08839v1",
      "published_date": "2024-05-14 07:16:56 UTC",
      "updated_date": "2024-05-14 07:16:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:29:57.597887"
    },
    {
      "arxiv_id": "2405.08373v1",
      "title": "PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction with Error Categorization and LLM Ensembles",
      "title_zh": "翻译失败",
      "authors": [
        "Satya Kesav Gundabathula",
        "Sriram R Kolar"
      ],
      "abstract": "This paper describes our approach to the MEDIQA-CORR shared task, which\ninvolves error detection and correction in clinical notes curated by medical\nprofessionals. This task involves handling three subtasks: detecting the\npresence of errors, identifying the specific sentence containing the error, and\ncorrecting it. Through our work, we aim to assess the capabilities of Large\nLanguage Models (LLMs) trained on a vast corpora of internet data that contain\nboth factual and unreliable information. We propose to comprehensively address\nall subtasks together, and suggest employing a unique prompt-based in-context\nlearning strategy. We will evaluate its efficacy in this specialized task\ndemanding a combination of general reasoning and medical knowledge. In medical\nsystems where prediction errors can have grave consequences, we propose\nleveraging self-consistency and ensemble methods to enhance error correction\nand error detection performance.",
      "tldr_zh": "这篇论文介绍了 PromptMind 团队在 MEDIQA-CORR 2024 共享任务中的方法，该任务涉及临床笔记的错误检测、识别和修正三个子任务。研究者提出使用基于提示的 in-context learning 策略，并结合 error categorization 和 LLM ensembles 来全面处理这些子任务，同时通过 self-consistency 和 ensemble 方法提升错误检测与修正的准确性。实验评估了 Large Language Models (LLMs) 在整合一般推理与医疗知识方面的效能，为高风险医疗应用中的可靠文本修正提供了改进途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper accepted for oral presentation at Clinical NLP workshop, NAACL\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08373v1",
      "published_date": "2024-05-14 07:16:36 UTC",
      "updated_date": "2024-05-14 07:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:30:11.523723"
    },
    {
      "arxiv_id": "2405.08838v1",
      "title": "PolyGlotFake: A Novel Multilingual and Multimodal DeepFake Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Hou",
        "Haitao Fu",
        "Chuankai Chen",
        "Zida Li",
        "Haoyu Zhang",
        "Jianjun Zhao"
      ],
      "abstract": "With the rapid advancement of generative AI, multimodal deepfakes, which\nmanipulate both audio and visual modalities, have drawn increasing public\nconcern. Currently, deepfake detection has emerged as a crucial strategy in\ncountering these growing threats. However, as a key factor in training and\nvalidating deepfake detectors, most existing deepfake datasets primarily focus\non the visual modal, and the few that are multimodal employ outdated\ntechniques, and their audio content is limited to a single language, thereby\nfailing to represent the cutting-edge advancements and globalization trends in\ncurrent deepfake technologies. To address this gap, we propose a novel,\nmultilingual, and multimodal deepfake dataset: PolyGlotFake. It includes\ncontent in seven languages, created using a variety of cutting-edge and popular\nText-to-Speech, voice cloning, and lip-sync technologies. We conduct\ncomprehensive experiments using state-of-the-art detection methods on\nPolyGlotFake dataset. These experiments demonstrate the dataset's significant\nchallenges and its practical value in advancing research into multimodal\ndeepfake detection.",
      "tldr_zh": "本论文提出PolyGlotFake，一种新型多语言和多模态deepfake数据集，以填补现有数据集在音频-视觉处理、语言多样性和技术先进性上的空白。该数据集涵盖七种语言，并使用先进的Text-to-Speech、语音克隆和唇同步技术生成内容。实验结果显示，在PolyGlotFake上应用最先进的检测方法揭示了显著挑战，并证明了其在推进多模态deepfake检测研究方面的实际价值。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "68T45",
        "I.4.9"
      ],
      "primary_category": "cs.SD",
      "comment": "13 page, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.08838v1",
      "published_date": "2024-05-14 06:40:05 UTC",
      "updated_date": "2024-05-14 06:40:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:30:22.187736"
    },
    {
      "arxiv_id": "2405.08337v2",
      "title": "Perivascular space Identification Nnunet for Generalised Usage (PINGU)",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Sinclair",
        "Lucy Vivash",
        "Jasmine Moses",
        "Miranda Lynch",
        "William Pham",
        "Karina Dorfman",
        "Cassandra Marotta",
        "Shaun Koh",
        "Jacob Bunyamin",
        "Ella Rowsthorn",
        "Alex Jarema",
        "Himashi Peiris",
        "Zhaolin Chen",
        "Sandy R Shultz",
        "David K Wright",
        "Dexiao Kong",
        "Sharon L. Naismith",
        "Terence J. OBrien",
        "Meng Law"
      ],
      "abstract": "Perivascular spaces(PVSs) form a central component of the brain\\'s waste\nclearance system, the glymphatic system. These structures are visible on MRI\nimages, and their morphology is associated with aging and neurological disease.\nManual quantification of PVS is time consuming and subjective. Numerous deep\nlearning methods for PVS segmentation have been developed, however the majority\nhave been developed and evaluated on homogenous datasets and high resolution\nscans, perhaps limiting their applicability for the wide range of image\nqualities acquired in clinic and research. In this work we train a nnUNet, a\ntop-performing biomedical image segmentation algorithm, on a heterogenous\ntraining sample of manually segmented MRI images of a range of different\nqualities and resolutions from 6 different datasets. These are compared to\npublicly available deep learning methods for 3D segmentation of PVS. The\nresulting model, PINGU (Perivascular space Identification Nnunet for\nGeneralised Usage), achieved voxel and cluster level dice scores of\n0.50(SD=0.15), 0.63(0.17) in the white matter(WM), and 0.54(0.11), 0.66(0.17)\nin the basal ganglia(BG). Performance on data from unseen sites was\nsubstantially lower for both PINGU(0.20-0.38(WM, voxel), 0.29-0.58(WM,\ncluster), 0.22-0.36(BG, voxel), 0.46-0.60(BG, cluster)) and the publicly\navailable algorithms(0.18-0.30(WM, voxel), 0.29-0.38(WM cluster), 0.10-0.20(BG,\nvoxel), 0.15-0.37(BG, cluster)), but PINGU strongly outperformed the publicly\navailable algorithms, particularly in the BG. Finally, training PINGU on manual\nsegmentations from a single site with homogenous scan properties gave\nmarginally lower performances on internal cross-validation, but in some cases\ngave higher performance on external validation. PINGU stands out as broad-use\nPVS segmentation tool, with particular strength in the BG, an area of PVS\nrelated to vascular disease and pathology.",
      "tldr_zh": "本文提出PINGU（Perivascular space Identification Nnunet for Generalised Usage），一种基于nnUNet的深度学习模型，用于MRI图像中Perivascular spaces (PVSs) 的分割，以解决现有方法在异质数据集上的适用性问题。模型在从6个不同数据集的异质MRI图像（各种质量和分辨率）上训练，并与公开算法进行比较。结果显示，PINGU在白质(WM)和基底神经节(BG)上取得了较高的Dice分数（WM voxel级0.50、cluster级0.63等），并在外部验证中显著优于其他算法，尤其在BG区域。总体而言，PINGU作为一种广泛适用的PVS分割工具，有助于研究与衰老及神经疾病相关的脑部废物清除系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08337v2",
      "published_date": "2024-05-14 06:16:13 UTC",
      "updated_date": "2024-05-17 06:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:30:37.618244"
    },
    {
      "arxiv_id": "2405.08334v2",
      "title": "Could Chemical LLMs benefit from Message Passing",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqing Xie",
        "Ziheng Chi"
      ],
      "abstract": "Pretrained language models (LMs) showcase significant capabilities in\nprocessing molecular text, while concurrently, message passing neural networks\n(MPNNs) demonstrate resilience and versatility in the domain of molecular\nscience. Despite these advancements, we find there are limited studies\ninvestigating the bidirectional interactions between molecular structures and\ntheir corresponding textual representations. Therefore, in this paper, we\npropose two strategies to evaluate whether an information integration can\nenhance the performance: contrast learning, which involves utilizing an MPNN to\nsupervise the training of the LM, and fusion, which exploits information from\nboth models. Our empirical analysis reveals that the integration approaches\nexhibit superior performance compared to baselines when applied to smaller\nmolecular graphs, while these integration approaches do not yield performance\nenhancements on large scale graphs.",
      "tldr_zh": "本研究探讨了预训练语言模型（LMs）在处理分子文本时的性能是否能通过消息传递神经网络（MPNNs）得到提升，针对分子结构和文本表示之间的双向互动问题进行分析。论文提出两种策略：对比学习（利用MPNN监督LM训练）和融合（整合两者信息），以评估信息整合的效果。实验结果表明，这些整合方法在较小的分子图上比基线模型表现出色，但在大规模分子图上并未带来性能提升。总的来说，该工作为化学LLMs的优化提供了新见解，但也突显了应用规模的限制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACL @ Languages and Molecules 2024. In Proceedings of ACL\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08334v2",
      "published_date": "2024-05-14 06:09:08 UTC",
      "updated_date": "2024-08-26 08:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:30:47.871513"
    },
    {
      "arxiv_id": "2405.08329v1",
      "title": "Cross-Dataset Generalization For Retinal Lesions Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Clément Playout",
        "Farida Cheriet"
      ],
      "abstract": "Identifying lesions in fundus images is an important milestone toward an\nautomated and interpretable diagnosis of retinal diseases. To support research\nin this direction, multiple datasets have been released, proposing groundtruth\nmaps for different lesions. However, important discrepancies exist between the\nannotations and raise the question of generalization across datasets. This\nstudy characterizes several known datasets and compares different techniques\nthat have been proposed to enhance the generalisation performance of a model,\nsuch as stochastic weight averaging, model soups and ensembles. Our results\nprovide insights into how to combine coarsely labelled data with a\nfinely-grained dataset in order to improve the lesions segmentation.",
      "tldr_zh": "该研究探讨了眼底图像中视网膜病变分割（Retinal Lesions Segmentation）的跨数据集泛化问题，针对不同数据集标注差异的影响。作者表征了多个已知数据集，并比较了随机权重平均（stochastic weight averaging）、模型 soups 和 ensembles 等技术，以提升模型的泛化性能。结果显示，通过结合粗粒度标注数据与细粒度数据集，这些方法能显著改进病变分割的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.08329v1",
      "published_date": "2024-05-14 05:52:01 UTC",
      "updated_date": "2024-05-14 05:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:30:57.470085"
    },
    {
      "arxiv_id": "2405.08311v1",
      "title": "A Decoupling and Aggregating Framework for Joint Extraction of Entities and Relations",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Wang",
        "Xin Liu",
        "Weikun Kong",
        "Hai-Tao Yu",
        "Teeradaj Racharak",
        "Kyoung-Sook Kim",
        "Minh Le Nguyen"
      ],
      "abstract": "Named Entity Recognition and Relation Extraction are two crucial and\nchallenging subtasks in the field of Information Extraction. Despite the\nsuccesses achieved by the traditional approaches, fundamental research\nquestions remain open. First, most recent studies use parameter sharing for a\nsingle subtask or shared features for both two subtasks, ignoring their\nsemantic differences. Second, information interaction mainly focuses on the two\nsubtasks, leaving the fine-grained informtion interaction among the\nsubtask-specific features of encoding subjects, relations, and objects\nunexplored. Motivated by the aforementioned limitations, we propose a novel\nmodel to jointly extract entities and relations. The main novelties are as\nfollows: (1) We propose to decouple the feature encoding process into three\nparts, namely encoding subjects, encoding objects, and encoding relations.\nThanks to this, we are able to use fine-grained subtask-specific features. (2)\nWe propose novel inter-aggregation and intra-aggregation strategies to enhance\nthe information interaction and construct individual fine-grained\nsubtask-specific features, respectively. The experimental results demonstrate\nthat our model outperforms several previous state-of-the-art models. Extensive\nadditional experiments further confirm the effectiveness of our model.",
      "tldr_zh": "该论文针对信息提取领域的命名实体识别（Named Entity Recognition）和关系提取（Relation Extraction）提出了一种新的联合提取框架，以解决现有方法忽略子任务语义差异和细粒度信息交互的问题。框架的核心创新是将特征编码过程解耦为编码主语（subjects）、编码宾语（objects）和编码关系（relations）三个部分，从而利用细粒度的子任务特定特征；同时，引入 inter-aggregation 和 intra-aggregation 策略来增强信息交互。实验结果显示，该模型优于多项现有最先进模型（state-of-the-art models），并通过额外实验验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08311v1",
      "published_date": "2024-05-14 04:27:16 UTC",
      "updated_date": "2024-05-14 04:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:31:11.016882"
    },
    {
      "arxiv_id": "2405.08304v2",
      "title": "Computational Thought Experiments for a More Rigorous Philosophy and Science of the Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Iris Oved",
        "Nikhil Krishnaswamy",
        "James Pustejovsky",
        "Joshua Hartshorne"
      ],
      "abstract": "We offer philosophical motivations for a method we call Virtual World\nCognitive Science (VW CogSci), in which researchers use virtual embodied agents\nthat are embedded in virtual worlds to explore questions in the field of\nCognitive Science. We focus on questions about mental and linguistic\nrepresentation and the ways that such computational modeling can add rigor to\nphilosophical thought experiments, as well as the terminology used in the\nscientific study of such representations. We find that this method forces\nresearchers to take a god's-eye view when describing dynamical relationships\nbetween entities in minds and entities in an environment in a way that\neliminates the need for problematic talk of belief and concept types, such as\nthe belief that cats are silly, and the concept CAT, while preserving belief\nand concept tokens in individual cognizers' minds. We conclude with some\nfurther key advantages of VW CogSci for the scientific study of mental and\nlinguistic representation and for Cognitive Science more broadly.",
      "tldr_zh": "本研究提出了一种名为 Virtual World Cognitive Science (VW CogSci) 的方法，使用虚拟嵌入式代理在虚拟世界中探索认知科学领域的关键问题，特别是心理和语言表示。VW CogSci 通过计算建模为哲学思想 experiments 注入严谨性，迫使研究者采用上帝视角描述心智与环境间的动态关系，从而避免使用模糊的信念和概念类型（如“the belief that cats are silly”或“the concept CAT”），同时保留个体认知者中的信念和概念 tokens。总体而言，这种方法为认知科学，尤其是心理和语言表示的研究，提供更精确的术语和更广泛的优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 4 figures, to appear at CogSci 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08304v2",
      "published_date": "2024-05-14 03:58:19 UTC",
      "updated_date": "2024-05-15 02:32:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:31:21.290913"
    },
    {
      "arxiv_id": "2405.08297v2",
      "title": "Distance-Restricted Explanations: Theoretical Underpinnings & Efficient Implementation",
      "title_zh": "距离受限解释：理论基础与高效实现",
      "authors": [
        "Yacine Izza",
        "Xuanxiang Huang",
        "Antonio Morgado",
        "Jordi Planes",
        "Alexey Ignatiev",
        "Joao Marques-Silva"
      ],
      "abstract": "The uses of machine learning (ML) have snowballed in recent years. In many\ncases, ML models are highly complex, and their operation is beyond the\nunderstanding of human decision-makers. Nevertheless, some uses of ML models\ninvolve high-stakes and safety-critical applications. Explainable artificial\nintelligence (XAI) aims to help human decision-makers in understanding the\noperation of such complex ML models, thus eliciting trust in their operation.\nUnfortunately, the majority of past XAI work is based on informal approaches,\nthat offer no guarantees of rigor. Unsurprisingly, there exists comprehensive\nexperimental and theoretical evidence confirming that informal methods of XAI\ncan provide human-decision makers with erroneous information. Logic-based XAI\nrepresents a rigorous approach to explainability; it is model-based and offers\nthe strongest guarantees of rigor of computed explanations. However, a\nwell-known drawback of logic-based XAI is the complexity of logic reasoning,\nespecially for highly complex ML models. Recent work proposed\ndistance-restricted explanations, i.e. explanations that are rigorous provided\nthe distance to a given input is small enough. Distance-restricted\nexplainability is tightly related with adversarial robustness, and it has been\nshown to scale for moderately complex ML models, but the number of inputs still\nrepresents a key limiting factor. This paper investigates novel algorithms for\nscaling up the performance of logic-based explainers when computing and\nenumerating ML model explanations with a large number of inputs.",
      "tldr_zh": "机器学习（ML）模型在高风险应用中常因复杂性而难以理解，非正式的可解释人工智能（XAI）方法可能提供错误信息，而逻辑-based XAI 虽提供严格解释，但面临计算复杂性挑战。本文深入探讨 distance-restricted explanations，这种方法在给定输入的小距离范围内确保解释的严谨性，并与 adversarial robustness 紧密相关，已证明适用于中等复杂模型。研究提出新算法来提升逻辑-based explainers 的性能，特别是在处理大量输入时的计算效率和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08297v2",
      "published_date": "2024-05-14 03:42:33 UTC",
      "updated_date": "2024-12-24 08:12:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:31:34.588911"
    },
    {
      "arxiv_id": "2405.08834v1",
      "title": "Adversarial Machine Learning Threats to Spacecraft",
      "title_zh": "对抗性机器学习对航天器的威胁",
      "authors": [
        "Rajiv Thummala",
        "Shristi Sharma",
        "Matteo Calabrese",
        "Gregory Falco"
      ],
      "abstract": "Spacecraft are among the earliest autonomous systems. Their ability to\nfunction without a human in the loop have afforded some of humanity's grandest\nachievements. As reliance on autonomy grows, space vehicles will become\nincreasingly vulnerable to attacks designed to disrupt autonomous\nprocesses-especially probabilistic ones based on machine learning. This paper\naims to elucidate and demonstrate the threats that adversarial machine learning\n(AML) capabilities pose to spacecraft. First, an AML threat taxonomy for\nspacecraft is introduced. Next, we demonstrate the execution of AML attacks\nagainst spacecraft through experimental simulations using NASA's Core Flight\nSystem (cFS) and NASA's On-board Artificial Intelligence Research (OnAIR)\nPlatform. Our findings highlight the imperative for incorporating AML-focused\nsecurity measures in spacecraft that engage autonomy.",
      "tldr_zh": "本文探讨了Adversarial Machine Learning (AML)对航天器的威胁，随着自治依赖增加，这些威胁可能破坏航天器的自主进程。作者引入了针对航天器的AML威胁分类，并通过实验模拟，使用NASA的Core Flight System (cFS)和On-board Artificial Intelligence Research (OnAIR) Platform，演示了潜在攻击。研究结果突出了在航天器中整合AML-focused安全措施的紧迫性，以提升其可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2405.08834v1",
      "published_date": "2024-05-14 02:42:40 UTC",
      "updated_date": "2024-05-14 02:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:31:46.544835"
    },
    {
      "arxiv_id": "2405.08252v1",
      "title": "Smart Sampling: Self-Attention and Bootstrapping for Improved Ensembled Q-Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Junaid Khan",
        "Syed Hammad Ahmed",
        "Gita Sukthankar"
      ],
      "abstract": "We present a novel method aimed at enhancing the sample efficiency of\nensemble Q learning. Our proposed approach integrates multi-head self-attention\ninto the ensembled Q networks while bootstrapping the state-action pairs\ningested by the ensemble. This not only results in performance improvements\nover the original REDQ (Chen et al. 2021) and its variant DroQ (Hi-raoka et al.\n2022), thereby enhancing Q predictions, but also effectively reduces both the\naverage normalized bias and standard deviation of normalized bias within\nQ-function ensembles. Importantly, our method also performs well even in\nscenarios with a low update-to-data (UTD) ratio. Notably, the implementation of\nour proposed method is straightforward, requiring minimal modifications to the\nbase model.",
      "tldr_zh": "本论文提出了一种名为 Smart Sampling 的方法，用于提升 ensembled Q learning 的样本效率，通过将 multi-head self-attention 集成到集成 Q 网络中，并使用 bootstrapping 处理状态-动作对，从而改善 Q 预测性能。相比 REDQ 和 DroQ，该方法显著降低了 Q 函数集成的平均归一化偏差和标准差。实验结果显示，即使在低 UTD ratio 场景下，该方法也能表现出色，且实现简单，仅需对基础模型进行最小修改。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "FLAIRS-37 (2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.08252v1",
      "published_date": "2024-05-14 00:57:02 UTC",
      "updated_date": "2024-05-14 00:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:31:58.467881"
    },
    {
      "arxiv_id": "2405.08247v1",
      "title": "Automated classification of multi-parametric body MRI series",
      "title_zh": "多参数体部 MRI 系列的自动分类",
      "authors": [
        "Boah Kim",
        "Tejas Sudharshan Mathai",
        "Kimberly Helm",
        "Ronald M. Summers"
      ],
      "abstract": "Multi-parametric MRI (mpMRI) studies are widely available in clinical\npractice for the diagnosis of various diseases. As the volume of mpMRI exams\nincreases yearly, there are concomitant inaccuracies that exist within the\nDICOM header fields of these exams. This precludes the use of the header\ninformation for the arrangement of the different series as part of the\nradiologist's hanging protocol, and clinician oversight is needed for\ncorrection. In this pilot work, we propose an automated framework to classify\nthe type of 8 different series in mpMRI studies. We used 1,363 studies acquired\nby three Siemens scanners to train a DenseNet-121 model with 5-fold\ncross-validation. Then, we evaluated the performance of the DenseNet-121\nensemble on a held-out test set of 313 mpMRI studies. Our method achieved an\naverage precision of 96.6%, sensitivity of 96.6%, specificity of 99.6%, and F1\nscore of 96.6% for the MRI series classification task. To the best of our\nknowledge, we are the first to develop a method to classify the series type in\nmpMRI studies acquired at the level of the chest, abdomen, and pelvis. Our\nmethod has the capability for robust automation of hanging protocols in modern\nradiology practice.",
      "tldr_zh": "本研究针对多参数MRI (mpMRI) 研究中DICOM头字段不准确的问题，提出了一种自动框架，用于分类8种不同系列，以辅助放射科医生的挂钩协议。该框架基于DenseNet-121模型，使用1,363个来自Siemens扫描仪的样本进行训练和5折交叉验证，在313个测试样本上达到了平均精度96.6%、敏感性96.6%、特异性99.6%和F1分数96.6%。这是首次开发针对胸部、腹部和骨盆水平mpMRI系列分类的方法，有望实现放射学实践中的挂钩协议自动化。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08247v1",
      "published_date": "2024-05-14 00:39:21 UTC",
      "updated_date": "2024-05-14 00:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:32:15.364819"
    },
    {
      "arxiv_id": "2405.08246v1",
      "title": "Compositional Text-to-Image Generation with Dense Blob Representations",
      "title_zh": "基于密集斑点表示的组合文本到",
      "authors": [
        "Weili Nie",
        "Sifei Liu",
        "Morteza Mardani",
        "Chao Liu",
        "Benjamin Eckart",
        "Arash Vahdat"
      ],
      "abstract": "Existing text-to-image models struggle to follow complex text prompts,\nraising the need for extra grounding inputs for better controllability. In this\nwork, we propose to decompose a scene into visual primitives - denoted as dense\nblob representations - that contain fine-grained details of the scene while\nbeing modular, human-interpretable, and easy-to-construct. Based on blob\nrepresentations, we develop a blob-grounded text-to-image diffusion model,\ntermed BlobGEN, for compositional generation. Particularly, we introduce a new\nmasked cross-attention module to disentangle the fusion between blob\nrepresentations and visual features. To leverage the compositionality of large\nlanguage models (LLMs), we introduce a new in-context learning approach to\ngenerate blob representations from text prompts. Our extensive experiments show\nthat BlobGEN achieves superior zero-shot generation quality and better\nlayout-guided controllability on MS-COCO. When augmented by LLMs, our method\nexhibits superior numerical and spatial correctness on compositional image\ngeneration benchmarks. Project page: https://blobgen-2d.github.io.",
      "tldr_zh": "本研究针对现有文本到图像模型在处理复杂提示时的局限性，提出了一种基于 dense blob representations 的组合生成方法，将场景分解为模块化、可解释的视觉基元，以提升生成的可控性和细粒度细节。作者开发了 BlobGEN 扩散模型，引入 masked cross-attention 模块来分离 blob 表示与视觉特征的融合，并利用 LLMs 的 in-context learning 从文本提示自动生成 blob 表示。实验结果显示，BlobGEN 在 MS-COCO 数据集上实现了优越的零样本生成质量和布局引导可控性，并在组合图像生成基准上表现出更好的数值和空间正确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.08246v1",
      "published_date": "2024-05-14 00:22:06 UTC",
      "updated_date": "2024-05-14 00:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:32:23.920890"
    },
    {
      "arxiv_id": "2405.08245v2",
      "title": "Progressive enhancement and restoration for mural images under low-light and defected conditions based on multi-receptive field strategy",
      "title_zh": "基于多感受野策略的低光照和缺陷条件下壁画图像的渐进式增强与修复",
      "authors": [
        "Xiameng Wei",
        "Binbin Fan",
        "Ying Wang",
        "Yanxiang Feng",
        "Laiyi Fu"
      ],
      "abstract": "Ancient murals are valuable cultural heritage with great archaeological\nvalue. They provide insights into ancient religions, ceremonies, folklore,\namong other things through their content. However, due to long-term oxidation\nand inadequate protection, ancient murals have suffered continuous damage,\nincluding peeling and mold etc. Additionally, since ancient murals were\ntypically painted indoors, the light intensity in images captured by digital\ndevices is often low. The poor visibility hampers the further restoration of\ndamaged areas. To address the escalating damage to ancient murals and\nfacilitate batch restoration at archaeological sites, we propose a two-stage\nrestoration model with automatic defect area detection strategy which called\nMER(Mural Enhancement and Restoration net) for ancient murals that are damaged\nand have been captured in low light. Our two-stage model not only enhances the\nvisual quality of restored images but also achieves commendable results in\nrelevant metric evaluations compared with other competitors. Furthermore, we\nhave launched a website dedicated to the restoration of ancient mural\npaintings, utilizing the proposed model. Code is available at\nhttps://gitee.com/bbfan2024/MER.git.",
      "tldr_zh": "本研究针对古壁画在低光和损坏条件下（如剥落和霉变）的图像问题，提出了一种基于 multi-receptive field strategy 的两阶段修复模型MER（Mural Enhancement and Restoration net）。该模型包括自动缺陷区域检测策略，先增强图像视觉质量，再进行修复，从而改善了图像可见性和修复效果。实验结果显示，MER在相关指标评估中优于其他竞争者，并通过发布专用网站和代码（https://gitee.com/bbfan2024/MER.git）支持批量修复应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08245v2",
      "published_date": "2024-05-14 00:20:32 UTC",
      "updated_date": "2024-07-17 03:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:32:35.172136"
    },
    {
      "arxiv_id": "2407.04711v1",
      "title": "MetaFruit Meets Foundation Models: Leveraging a Comprehensive Multi-Fruit Dataset for Advancing Agricultural Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajia Li",
        "Kyle Lammers",
        "Xunyuan Yin",
        "Xiang Yin",
        "Long He",
        "Renfu Lu",
        "Zhaojian Li"
      ],
      "abstract": "Fruit harvesting poses a significant labor and financial burden for the\nindustry, highlighting the critical need for advancements in robotic harvesting\nsolutions. Machine vision-based fruit detection has been recognized as a\ncrucial component for robust identification of fruits to guide robotic\nmanipulation. Despite considerable progress in leveraging deep learning and\nmachine learning techniques for fruit detection, a common shortfall is the\ninability to swiftly extend the developed models across different orchards\nand/or various fruit species. Additionally, the limited availability of\npertinent data further compounds these challenges. In this work, we introduce\nMetaFruit, the largest publicly available multi-class fruit dataset, comprising\n4,248 images and 248,015 manually labeled instances across diverse U.S.\norchards. Furthermore, this study proposes an innovative open-set fruit\ndetection system leveraging advanced Vision Foundation Models (VFMs) for fruit\ndetection that can adeptly identify a wide array of fruit types under varying\norchard conditions. This system not only demonstrates remarkable adaptability\nin learning from minimal data through few-shot learning but also shows the\nability to interpret human instructions for subtle detection tasks. The\nperformance of the developed foundation model is comprehensively evaluated\nusing several metrics, which outperforms the existing state-of-the-art\nalgorithms in both our MetaFruit dataset and other open-sourced fruit datasets,\nthereby setting a new benchmark in the field of agricultural technology and\nrobotic harvesting. The MetaFruit dataset and detection framework are\nopen-sourced to foster future research in vision-based fruit harvesting,\nmarking a significant stride toward addressing the urgent needs of the\nagricultural sector.",
      "tldr_zh": "本研究引入了MetaFruit，这是目前最大的公开多类水果数据集，包含4,248张图像和248,015个手动标注实例，旨在解决机器视觉水果检测在不同果园和水果种类间的扩展难题。论文提出了一种创新的开放集水果检测系统，利用先进的Vision Foundation Models (VFMs)，通过few-shot learning从少量数据学习，并能解释人类指令以适应复杂果园条件。该系统在MetaFruit数据集和其他开源数据集上的性能评估显示，其准确性超越现有最先进算法，为农业机器人采摘技术设立新基准，并已开源以推动未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 5 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.04711v1",
      "published_date": "2024-05-14 00:13:47 UTC",
      "updated_date": "2024-05-14 00:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:32:49.098071"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 64,
  "processed_papers_count": 64,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T08:33:14.579886"
}