[
  {
    "arxiv_id": "2407.21244v1",
    "title": "VITAL: Visual Teleoperation to Enhance Robot Learning through Human-in-the-Loop Corrections",
    "authors": [
      "Hamidreza Kasaei",
      "Mohammadreza Kasaei"
    ],
    "abstract": "Imitation Learning (IL) has emerged as a powerful approach in robotics,\nallowing robots to acquire new skills by mimicking human actions. Despite its\npotential, the data collection process for IL remains a significant challenge\ndue to the logistical difficulties and high costs associated with obtaining\nhigh-quality demonstrations. To address these issues, we propose a low-cost\nvisual teleoperation system for bimanual manipulation tasks, called VITAL. Our\napproach leverages affordable hardware and visual processing techniques to\ncollect demonstrations, which are then augmented to create extensive training\ndatasets for imitation learning. We enhance the generalizability and robustness\nof the learned policies by utilizing both real and simulated environments and\nhuman-in-the-loop corrections. We evaluated our method through several rounds\nof experiments in simulated and real-robot settings, focusing on tasks of\nvarying complexity, including bottle collecting, stacking objects, and\nhammering. Our experimental results validate the effectiveness of our approach\nin learning robust robot policies from simulated data, significantly improved\nby human-in-the-loop corrections and real-world data integration. Additionally,\nwe demonstrate the framework's capability to generalize to new tasks, such as\nsetting a drink tray, showcasing its adaptability and potential for handling a\nwide range of real-world bimanual manipulation tasks. A video of the\nexperiments can be found at: https://youtu.be/YeVAMRqRe64?si=R179xDlEGc7nPu8i",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21244v1",
    "published_date": "2024-07-30 23:29:47 UTC",
    "updated_date": "2024-07-30 23:29:47 UTC"
  },
  {
    "arxiv_id": "2407.21243v2",
    "title": "Informed Correctors for Discrete Diffusion Models",
    "authors": [
      "Yixiu Zhao",
      "Jiaxin Shi",
      "Feng Chen",
      "Shaul Druckmann",
      "Lester Mackey",
      "Scott Linderman"
    ],
    "abstract": "Discrete diffusion has emerged as a powerful framework for generative\nmodeling in discrete domains, yet efficiently sampling from these models\nremains challenging. Existing sampling strategies often struggle to balance\ncomputation and sample quality when the number of sampling steps is reduced,\neven when the model has learned the data distribution well. To address these\nlimitations, we propose a predictor-corrector sampling scheme where the\ncorrector is informed by the diffusion model to more reliably counter the\naccumulating approximation errors. To further enhance the effectiveness of our\ninformed corrector, we introduce complementary architectural modifications\nbased on hollow transformers and a simple tailored training objective that\nleverages more training signal. We use a synthetic example to illustrate the\nfailure modes of existing samplers and show how informed correctors alleviate\nthese problems. On tokenized ImageNet 256x256, this approach consistently\nproduces superior samples with fewer steps, achieving improved FID scores for\ndiscrete diffusion models. These results underscore the potential of informed\ncorrectors for fast and high-fidelity generation using discrete diffusion.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21243v2",
    "published_date": "2024-07-30 23:29:29 UTC",
    "updated_date": "2025-03-13 20:39:53 UTC"
  },
  {
    "arxiv_id": "2407.21241v1",
    "title": "Bug Analysis Towards Bug Resolution Time Prediction",
    "authors": [
      "Hasan Yagiz Ozkan",
      "Poul Einer Heegaard",
      "Wolfgang Kellerer",
      "Carmen Mas-Machuca"
    ],
    "abstract": "Bugs are inevitable in software development, and their reporting in open\nrepositories can enhance software transparency and reliability assessment. This\nstudy aims to extract information from the issue tracking system Jira and\nproposes a methodology to estimate resolution time for new bugs. The\nmethodology is applied to network project ONAP, addressing concerns of network\noperators and manufacturers. This research provides insights into bug\nresolution times and related aspects in network softwarization projects.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21241v1",
    "published_date": "2024-07-30 23:18:14 UTC",
    "updated_date": "2024-07-30 23:18:14 UTC"
  },
  {
    "arxiv_id": "2407.21233v1",
    "title": "TMA-Grid: An open-source, zero-footprint web application for FAIR Tissue MicroArray De-arraying",
    "authors": [
      "Aaron Ge",
      "Monjoy Saha",
      "Maire A. Duggan",
      "Petra Lenz",
      "Mustapha Abubakar",
      "Montserrat Garc√≠a-Closas",
      "Jeya Balasubramanian",
      "Jonas S. Almeida",
      "Praphulla MS Bhawsar"
    ],
    "abstract": "Background:\n  Tissue Microarrays (TMAs) significantly increase analytical efficiency in\nhistopathology and large-scale epidemiologic studies by allowing multiple\ntissue cores to be scanned on a single slide. The individual cores can be\ndigitally extracted and then linked to metadata for analysis in a process known\nas de-arraying. However, TMAs often contain core misalignments and artifacts\ndue to assembly errors, which can adversely affect the reliability of the\nextracted cores during the de-arraying process. Moreover, conventional\napproaches for TMA de-arraying rely on desktop solutions.Therefore, a robust\nyet flexible de-arraying method is crucial to account for these inaccuracies\nand ensure effective downstream analyses.\n  Results:\n  We developed TMA-Grid, an in-browser, zero-footprint, interactive web\napplication for TMA de-arraying. This web application integrates a\nconvolutional neural network for precise tissue segmentation and a grid\nestimation algorithm to match each identified core to its expected location.\nThe application emphasizes interactivity, allowing users to easily adjust\nsegmentation and gridding results. Operating entirely in the web-browser,\nTMA-Grid eliminates the need for downloads or installations and ensures data\nprivacy. Adhering to FAIR principles (Findable, Accessible, Interoperable, and\nReusable), the application and its components are designed for seamless\nintegration into TMA research workflows.\n  Conclusions:\n  TMA-Grid provides a robust, user-friendly solution for TMA dearraying on the\nweb. As an open, freely accessible platform, it lays the foundation for\ncollaborative analyses of TMAs and similar histopathology imaging data.\nAvailability: Web application: https://episphere.github.io/tma-grid Code:\nhttps://github.com/episphere/tma-grid Tutorial: https://youtu.be/miajqyw4BVk",
    "categories": [
      "q-bio.TO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.TO",
    "comment": "NA",
    "pdf_url": "http://arxiv.org/pdf/2407.21233v1",
    "published_date": "2024-07-30 22:40:32 UTC",
    "updated_date": "2024-07-30 22:40:32 UTC"
  },
  {
    "arxiv_id": "2407.21227v2",
    "title": "TaskEval: Assessing Difficulty of Code Generation Tasks for Large Language Models",
    "authors": [
      "Florian Tambon",
      "Amin Nikanjam",
      "Cyrine Zid",
      "Foutse Khomh",
      "Giuliano Antoniol"
    ],
    "abstract": "Large Language Models (LLMs) excel in code-related tasks like code\ngeneration, but benchmark evaluations often overlook task characteristics, such\nas difficulty. Moreover, benchmarks are usually built using tasks described\nwith one single prompt, despite the formulation of prompts having a profound\nimpact on the outcome. This paper introduces a generalist approach, TaskEval, a\nframework using diverse prompts and Item Response Theory (IRT) to efficiently\nassess LLMs' capabilities and benchmark task characteristics, improving the\nunderstanding of their performance.\n  Using two code generation benchmarks, HumanEval+ and ClassEval, as well as 5\ncode generation LLMs, we show that TaskEval is capable of characterizing the\nproperties of tasks. Using topic analysis, we identify and analyze the tasks of\nrespectively 17 and 21 topics within the benchmarks. We also cross-analyze\ntasks' characteristics with programming constructs (e.g., variable assignment,\nconditions, etc.) used by LLMs, emphasizing some patterns with tasks'\ndifficulty. Finally, we conduct a comparison between the difficulty assessment\nof tasks by human-annotators and LLMs. Orthogonal to current benchmarking\nevaluation efforts, TaskEval can assist researchers and practitioners in\nfostering better assessments of LLMs. The tasks' characteristics can be used to\nidentify shortcomings within existing benchmarks. This could be used to\ngenerate additional related tasks for the evaluation or improvement of LLM.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21227v2",
    "published_date": "2024-07-30 22:31:19 UTC",
    "updated_date": "2025-03-10 17:41:17 UTC"
  },
  {
    "arxiv_id": "2407.21225v1",
    "title": "AI methods for approximate compiling of unitaries",
    "authors": [
      "David Kremer",
      "Victor Villar",
      "Sanjay Vishwakarma",
      "Ismael Faro",
      "Juan Cruz-Benito"
    ],
    "abstract": "This paper explores artificial intelligence (AI) methods for the approximate\ncompiling of unitaries, focusing on the use of fixed two-qubit gates and\narbitrary single-qubit rotations typical in superconducting hardware. Our\napproach involves three main stages: identifying an initial template that\napproximates the target unitary, predicting initial parameters for this\ntemplate, and refining these parameters to maximize the fidelity of the\ncircuit. We propose AI-driven approaches for the first two stages, with a deep\nlearning model that suggests initial templates and an autoencoder-like model\nthat suggests parameter values, which are refined through gradient descent to\nachieve the desired fidelity. We demonstrate the method on 2 and 3-qubit\nunitaries, showcasing promising improvements over exhaustive search and random\nparameter initialization. The results highlight the potential of AI to enhance\nthe transpiling process, supporting more efficient quantum computations on\ncurrent and future quantum hardware.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21225v1",
    "published_date": "2024-07-30 22:30:15 UTC",
    "updated_date": "2024-07-30 22:30:15 UTC"
  },
  {
    "arxiv_id": "2407.21204v1",
    "title": "LoRaWAN Based Dynamic Noise Mapping with Machine Learning for Urban Noise Enforcement",
    "authors": [
      "H. Emre Erdem",
      "Henry Leung"
    ],
    "abstract": "Static noise maps depicting long-term noise levels over wide areas are\nvaluable urban planning assets for municipalities in decreasing noise exposure\nof residents. However, non-traffic noise sources with transient behavior, which\npeople complain frequently, are usually ignored by static maps. We propose here\na dynamic noise mapping approach using the data collected via low-power\nwide-area network (LPWAN, specifically LoRaWAN) based internet of things (IoT)\ninfrastructure, which is one of the most common communication backbones for\nsmart cities. Noise mapping based on LPWAN is challenging due to the low data\nrates of these protocols. The proposed dynamic noise mapping approach\ndiminishes the negative implications of data rate limitations using machine\nlearning (ML) for event and location prediction of non-traffic sources based on\nthe scarce data. The strength of these models lies in their consideration of\nthe spatial variance in acoustic behavior caused by the buildings in urban\nsettings. The effectiveness of the proposed method and the accuracy of the\nresulting dynamic maps are evaluated in field tests. The results show that the\nproposed system can decrease the map error caused by non-traffic sources up to\n51% and can stay effective under significant packet losses.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21204v1",
    "published_date": "2024-07-30 21:40:12 UTC",
    "updated_date": "2024-07-30 21:40:12 UTC"
  },
  {
    "arxiv_id": "2407.21202v1",
    "title": "Rolling in the deep of cognitive and AI biases",
    "authors": [
      "Athena Vakali",
      "Nicoleta Tantalaki"
    ],
    "abstract": "Nowadays, we delegate many of our decisions to Artificial Intelligence (AI)\nthat acts either in solo or as a human companion in decisions made to support\nseveral sensitive domains, like healthcare, financial services and law\nenforcement. AI systems, even carefully designed to be fair, are heavily\ncriticized for delivering misjudged and discriminated outcomes against\nindividuals and groups. Numerous work on AI algorithmic fairness is devoted on\nMachine Learning pipelines which address biases and quantify fairness under a\npure computational view. However, the continuous unfair and unjust AI outcomes,\nindicate that there is urgent need to understand AI as a sociotechnical system,\ninseparable from the conditions in which it is designed, developed and\ndeployed. Although, the synergy of humans and machines seems imperative to make\nAI work, the significant impact of human and societal factors on AI bias is\ncurrently overlooked. We address this critical issue by following a radical new\nmethodology under which human cognitive biases become core entities in our AI\nfairness overview. Inspired by the cognitive science definition and taxonomy of\nhuman heuristics, we identify how harmful human actions influence the overall\nAI lifecycle, and reveal human to AI biases hidden pathways. We introduce a new\nmapping, which justifies the human heuristics to AI biases reflections and we\ndetect relevant fairness intensities and inter-dependencies. We envision that\nthis approach will contribute in revisiting AI fairness under deeper\nhuman-centric case studies, revealing hidden biases cause and effects.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2407.21202v1",
    "published_date": "2024-07-30 21:34:04 UTC",
    "updated_date": "2024-07-30 21:34:04 UTC"
  },
  {
    "arxiv_id": "2407.21191v2",
    "title": "GenRec: Generative Sequential Recommendation with Large Language Models",
    "authors": [
      "Panfeng Cao",
      "Pietro Lio"
    ],
    "abstract": "Sequential recommendation is a task to capture hidden user preferences from\nhistorical user item interaction data and recommend next items for the user.\nSignificant progress has been made in this domain by leveraging classification\nbased learning methods. Inspired by the recent paradigm of 'pretrain, prompt\nand predict' in NLP, we consider sequential recommendation as a sequence to\nsequence generation task and propose a novel model named Generative\nRecommendation (GenRec). Unlike classification based models that learn explicit\nuser and item representations, GenRec utilizes the sequence modeling capability\nof Transformer and adopts the masked item prediction objective to effectively\nlearn the hidden bidirectional sequential patterns. Different from existing\ngenerative sequential recommendation models, GenRec does not rely on manually\ndesigned hard prompts. The input to GenRec is textual user item sequence and\nthe output is top ranked next items. Moreover, GenRec is lightweight and\nrequires only a few hours to train effectively in low-resource settings, making\nit highly applicable to real-world scenarios and helping to democratize large\nlanguage models in the sequential recommendation domain. Our extensive\nexperiments have demonstrated that GenRec generalizes on various public\nreal-world datasets and achieves state-of-the-art results. Our experiments also\nvalidate the effectiveness of the the proposed masked item prediction objective\nthat improves the model performance by a large margin.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21191v2",
    "published_date": "2024-07-30 20:58:36 UTC",
    "updated_date": "2024-08-29 02:27:19 UTC"
  },
  {
    "arxiv_id": "2407.21189v2",
    "title": "Multi-task Photonic Reservoir Computing: Wavelength Division Multiplexing for Parallel Computing with a Silicon Microring Resonator",
    "authors": [
      "Bernard J. Giron Castro",
      "Christophe Peucheret",
      "Darko Zibar",
      "Francesco Da Ros"
    ],
    "abstract": "Nowadays, as the ever-increasing demand for more powerful computing resources\ncontinues, alternative advanced computing paradigms are under extensive\ninvestigation. Significant effort has been made to deviate from conventional\nVon Neumann architectures. In-memory computing has emerged in the field of\nelectronics as a possible solution to the infamous bottleneck between memory\nand computing processors, which reduces the effective throughput of data. In\nphotonics, novel schemes attempt to collocate the computing processor and\nmemory in a single device. Photonics offers the flexibility of multiplexing\nstreams of data not only spatially and in time, but also in frequency or,\nequivalently, in wavelength, which makes it highly suitable for parallel\ncomputing. Here, we numerically show the use of time and wavelength division\nmultiplexing (WDM) to solve four independent tasks at the same time in a single\nphotonic chip, serving as a proof of concept for our proposal. The system is a\ntime-delay reservoir computing (TDRC) based on a microring resonator (MRR). The\naddressed tasks cover different applications: Time-series prediction, waveform\nsignal classification, wireless channel equalization, and radar signal\nprediction. The system is also tested for simultaneous computing of up to 10\ninstances of the same task, exhibiting excellent performance. The footprint of\nthe system is reduced by using time-division multiplexing of the nodes that act\nas the neurons of the studied neural network scheme. WDM is used for the\nparallelization of wavelength channels, each addressing a single task. By\nadjusting the input power and frequency of each optical channel, we can achieve\nlevels of performance for each of the tasks that are comparable to those quoted\nin state-of-the-art reports focusing on single-task operation...",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "physics.optics"
    ],
    "primary_category": "cs.NE",
    "comment": "Main text: 11 figures, 3 tables. Supplementary material: 2 figures, 4\n  tables. The manuscript presented in this pre-print has been accepted for\n  publication in Frontiers: Advanced Optical Technologies. The abstract is\n  shorter than in the PDF file to comply with arXiv requirements",
    "pdf_url": "http://arxiv.org/pdf/2407.21189v2",
    "published_date": "2024-07-30 20:54:07 UTC",
    "updated_date": "2024-10-08 12:08:49 UTC"
  },
  {
    "arxiv_id": "2407.21178v1",
    "title": "Deduction Game Framework and Information Set Entropy Search",
    "authors": [
      "Fandi Meng",
      "Simon Lucas"
    ],
    "abstract": "We present a game framework tailored for deduction games, enabling structured\nanalysis from the perspective of Shannon entropy variations. Additionally, we\nintroduce a new forward search algorithm, Information Set Entropy Search\n(ISES), which effectively solves many single-player deduction games. The ISES\nalgorithm, augmented with sampling techniques, allows agents to make decisions\nwithin controlled computational resources and time constraints. Experimental\nresults on eight games within our framework demonstrate the significant\nsuperiority of our method over the Single Observer Information Set Monte Carlo\nTree Search(SO-ISMCTS) algorithm under limited decision time constraints. The\nentropy variation of game states in our framework enables explainable\ndecision-making, which can also be used to analyze the appeal of deduction\ngames and provide insights for game designers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "IEEE Conference on Games (IEEE CoG)",
    "pdf_url": "http://arxiv.org/pdf/2407.21178v1",
    "published_date": "2024-07-30 20:33:15 UTC",
    "updated_date": "2024-07-30 20:33:15 UTC"
  },
  {
    "arxiv_id": "2407.21174v1",
    "title": "AI Safety in Practice: Enhancing Adversarial Robustness in Multimodal Image Captioning",
    "authors": [
      "Maisha Binte Rashid",
      "Pablo Rivas"
    ],
    "abstract": "Multimodal machine learning models that combine visual and textual data are\nincreasingly being deployed in critical applications, raising significant\nsafety and security concerns due to their vulnerability to adversarial attacks.\nThis paper presents an effective strategy to enhance the robustness of\nmultimodal image captioning models against such attacks. By leveraging the Fast\nGradient Sign Method (FGSM) to generate adversarial examples and incorporating\nadversarial training techniques, we demonstrate improved model robustness on\ntwo benchmark datasets: Flickr8k and COCO. Our findings indicate that\nselectively training only the text decoder of the multimodal architecture shows\nperformance comparable to full adversarial training while offering increased\ncomputational efficiency. This targeted approach suggests a balance between\nrobustness and training costs, facilitating the ethical deployment of\nmultimodal AI systems across various domains.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.AS",
      "I.2.7"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted into KDD 2024 workshop on Ethical AI",
    "pdf_url": "http://arxiv.org/pdf/2407.21174v1",
    "published_date": "2024-07-30 20:28:31 UTC",
    "updated_date": "2024-07-30 20:28:31 UTC"
  },
  {
    "arxiv_id": "2407.21164v3",
    "title": "Extending choice assessments to choice functions: An algorithm for computing the natural extension",
    "authors": [
      "Arne Decadt",
      "Alexander Erreygers",
      "Jasper De Bock"
    ],
    "abstract": "We study how to infer new choices from prior choices using the framework of\nchoice functions, a unifying mathematical framework for decision-making based\non sets of preference orders. In particular, we define the natural (most\nconservative) extension of a given choice assessment to a coherent choice\nfunction -- whenever possible -- and use this natural extension to make new\nchoices. We provide a practical algorithm for computing this natural extension\nand various ways to improve scalability. Finally, we test these algorithms for\ndifferent types of choice assessments.",
    "categories": [
      "cs.AI",
      "math.PR",
      "68T37, 60A99"
    ],
    "primary_category": "cs.AI",
    "comment": "40 pages, 8 figures, pre-print for International Journal of\n  Approximate Reasoning",
    "pdf_url": "http://arxiv.org/pdf/2407.21164v3",
    "published_date": "2024-07-30 20:10:59 UTC",
    "updated_date": "2024-11-28 17:53:51 UTC"
  },
  {
    "arxiv_id": "2407.21163v1",
    "title": "Understanding Public Safety Trends in Calgary through data mining",
    "authors": [
      "Zack Dewis",
      "Apratim Sen",
      "Jeffrey Wong",
      "Yujia Zhang"
    ],
    "abstract": "This paper utilizes statistical data from various open datasets in Calgary to\nto uncover patterns and insights for community crimes, disorders, and traffic\nincidents. Community attributes like demographics, housing, and pet\nregistration were collected and analyzed through geospatial visualization and\ncorrelation analysis. Strongly correlated features were identified using the\nchi-square test, and predictive models were built using association rule mining\nand machine learning algorithms. The findings suggest that crime rates are\nclosely linked to factors such as population density, while pet registration\nhas a smaller impact. This study offers valuable insights for city managers to\nenhance community safety strategies.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.21163v1",
    "published_date": "2024-07-30 20:04:51 UTC",
    "updated_date": "2024-07-30 20:04:51 UTC"
  },
  {
    "arxiv_id": "2407.21151v2",
    "title": "Private Collaborative Edge Inference via Over-the-Air Computation",
    "authors": [
      "Selim F. Yilmaz",
      "Burak Hasircioglu",
      "Li Qiao",
      "Deniz Gunduz"
    ],
    "abstract": "We consider collaborative inference at the wireless edge, where each client's\nmodel is trained independently on its local dataset. Clients are queried in\nparallel to make an accurate decision collaboratively. In addition to\nmaximizing the inference accuracy, we also want to ensure the privacy of local\nmodels. To this end, we leverage the superposition property of the multiple\naccess channel to implement bandwidth-efficient multi-user inference methods.\nWe propose different methods for ensemble and multi-view classification that\nexploit over-the-air computation (OAC). We show that these schemes perform\nbetter than their orthogonal counterparts with statistically significant\ndifferences while using fewer resources and providing privacy guarantees. We\nalso provide experimental results verifying the benefits of the proposed OAC\napproach to multi-user inference, and perform an ablation study to demonstrate\nthe effectiveness of our design choices. We share the source code of the\nframework publicly on Github to facilitate further research and\nreproducibility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 8 figures. This work extends from our preliminary study\n  presented at the 2022 IEEE International Symposium on Information Theory [1].\n  arXiv admin note: text overlap with arXiv:2202.03129",
    "pdf_url": "http://arxiv.org/pdf/2407.21151v2",
    "published_date": "2024-07-30 19:28:28 UTC",
    "updated_date": "2025-01-14 09:58:24 UTC"
  },
  {
    "arxiv_id": "2407.21149v1",
    "title": "Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population",
    "authors": [
      "Mayanka Chandrashekar",
      "Ian Goethert",
      "Md Inzamam Ul Haque",
      "Benjamin McMahon",
      "Sayera Dhaubhadel",
      "Kathryn Knight",
      "Joseph Erdos",
      "Donna Reagan",
      "Caroline Taylor",
      "Peter Kuzmak",
      "John Michael Gaziano",
      "Eileen McAllister",
      "Lauren Costa",
      "Yuk-Lam Ho",
      "Kelly Cho",
      "Suzanne Tamang",
      "Samah Fodeh-Jarad",
      "Olga S. Ovchinnikova",
      "Amy C. Justice",
      "Jacob Hinkle",
      "Ioana Danciu"
    ],
    "abstract": "Objectives: This study aims to assess the impact of domain shift on chest\nX-ray classification accuracy and to analyze the influence of ground truth\nlabel quality and demographic factors such as age group, sex, and study year.\nMaterials and Methods: We used a DenseNet121 model pretrained MIMIC-CXR dataset\nfor deep learning-based multilabel classification using ground truth labels\nfrom radiology reports extracted using the CheXpert and CheXbert Labeler. We\ncompared the performance of the 14 chest X-ray labels on the MIMIC-CXR and\nVeterans Healthcare Administration chest X-ray dataset (VA-CXR). The VA-CXR\ndataset comprises over 259k chest X-ray images spanning between the years 2010\nand 2022. Results: The validation of ground truth and the assessment of\nmulti-label classification performance across various NLP extraction tools\nrevealed that the VA-CXR dataset exhibited lower disagreement rates than the\nMIMIC-CXR datasets. Additionally, there were notable differences in AUC scores\nbetween models utilizing CheXpert and CheXbert. When evaluating multi-label\nclassification performance across different datasets, minimal domain shift was\nobserved in unseen datasets, except for the label \"Enlarged Cardiomediastinum.\"\nThe study year's subgroup analyses exhibited the most significant variations in\nmulti-label classification model performance. These findings underscore the\nimportance of considering domain shifts in chest X-ray classification tasks,\nparticularly concerning study years. Conclusion: Our study reveals the\nsignificant impact of domain shift and demographic factors on chest X-ray\nclassification, emphasizing the need for improved transfer learning and\nequitable model development. Addressing these challenges is crucial for\nadvancing medical imaging and enhancing patient care.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21149v1",
    "published_date": "2024-07-30 19:23:29 UTC",
    "updated_date": "2024-07-30 19:23:29 UTC"
  },
  {
    "arxiv_id": "2408.00019v1",
    "title": "WebApp1K: A Practical Code-Generation Benchmark for Web App Development",
    "authors": [
      "Yi Cui"
    ],
    "abstract": "We introduce WebApp1K, a practical code-generation benchmark to measure LLM\nability to develop web apps. This benchmark aims to calibrate LLM output and\naid the models to progressively improve code correctness and functionality. The\nbenchmark is lightweight and easy to run. We present the initial version of\nWebApp1K, and share our findings of running the benchmark against the latest\nfrontier LLMs. First, open source LLMs deliver impressive performance, closely\ntrailing behind GPT-4o and Claude 3.5. Second, model size has strong\ncorrelation with code correctness. Third, no prompting techniques have been\nfound to lift performance either universally to all models, or significantly to\na single model.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00019v1",
    "published_date": "2024-07-30 18:49:26 UTC",
    "updated_date": "2024-07-30 18:49:26 UTC"
  },
  {
    "arxiv_id": "2407.21124v1",
    "title": "Zero Shot Health Trajectory Prediction Using Transformer",
    "authors": [
      "Pawel Renc",
      "Yugang Jia",
      "Anthony E. Samir",
      "Jaroslaw Was",
      "Quanzheng Li",
      "David W. Bates",
      "Arkadiusz Sitek"
    ],
    "abstract": "Integrating modern machine learning and clinical decision-making has great\npromise for mitigating healthcare's increasing cost and complexity. We\nintroduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a\nnovel application of the transformer deep-learning architecture for analyzing\nhigh-dimensional, heterogeneous, and episodic health data. ETHOS is trained\nusing Patient Health Timelines (PHTs)-detailed, tokenized records of health\nevents-to predict future health trajectories, leveraging a zero-shot learning\napproach. ETHOS represents a significant advancement in foundation model\ndevelopment for healthcare analytics, eliminating the need for labeled data and\nmodel fine-tuning. Its ability to simulate various treatment pathways and\nconsider patient-specific factors positions ETHOS as a tool for care\noptimization and addressing biases in healthcare delivery. Future developments\nwill expand ETHOS' capabilities to incorporate a wider range of data types and\ndata sources. Our work demonstrates a pathway toward accelerated AI development\nand deployment in healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21124v1",
    "published_date": "2024-07-30 18:33:05 UTC",
    "updated_date": "2024-07-30 18:33:05 UTC"
  },
  {
    "arxiv_id": "2407.21118v2",
    "title": "Palu: Compressing KV-Cache with Low-Rank Projection",
    "authors": [
      "Chi-Chih Chang",
      "Wei-Cheng Lin",
      "Chien-Yu Lin",
      "Chong-Yan Chen",
      "Yu-Fang Hu",
      "Pei-Shuo Wang",
      "Ning-Chi Huang",
      "Luis Ceze",
      "Mohamed S. Abdelfattah",
      "Kai-Chiang Wu"
    ],
    "abstract": "Post-training KV-Cache compression methods typically either sample a subset\nof effectual tokens or quantize the data into lower numerical bit width.\nHowever, these methods cannot exploit redundancy in the hidden dimension of the\nKV tensors. This paper presents a hidden dimension compression approach called\nPalu, a KV-Cache compression framework that utilizes low-rank projection to\nreduce inference-time LLM memory usage. Palu decomposes the linear layers into\nlow-rank matrices, caches compressed intermediate states, and reconstructs the\nfull keys and values on the fly. To improve accuracy, compression rate, and\nefficiency, Palu further encompasses (1) a medium-grained low-rank\ndecomposition scheme, (2) an efficient rank search algorithm, (3)\nlow-rank-aware quantization compatibility enhancements, and (4) optimized GPU\nkernels with operators fusion. Extensive experiments with popular LLMs show\nthat Palu compresses KV-Cache by 50% while maintaining strong accuracy and\ndelivering up to 1.89x on the RoPE-based attention module. When combined with\nquantization, Palu's inherent quantization-friendly design yields small to\nnegligible extra accuracy degradation while saving additional memory than\nquantization-only methods and achieving up to 2.91x speedup for the RoPE-based\nattention. Moreover, it maintains comparable or even better accuracy (up to\n1.19 lower perplexity) compared to quantization-only methods. These results\ndemonstrate Palu's superior capability to effectively address the efficiency\nand memory challenges of LLM inference posed by KV-Cache. Our code is publicly\navailable at: https://github.com/shadowpa0327/Palu",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21118v2",
    "published_date": "2024-07-30 18:19:38 UTC",
    "updated_date": "2024-11-04 02:08:55 UTC"
  },
  {
    "arxiv_id": "2407.21018v3",
    "title": "ThinK: Thinner Key Cache by Query-Driven Pruning",
    "authors": [
      "Yuhui Xu",
      "Zhanming Jie",
      "Hanze Dong",
      "Lei Wang",
      "Xudong Lu",
      "Aojun Zhou",
      "Amrita Saha",
      "Caiming Xiong",
      "Doyen Sahoo"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing, achieving unprecedented performance across a variety of\napplications. However, their increased computational and memory demands present\nsignificant challenges, especially when handling long sequences. This paper\nfocuses on the long-context scenario, addressing the inefficiencies in KV cache\nmemory consumption during inference. Unlike existing approaches that optimize\nthe memory based on the sequence length, we identify substantial redundancy in\nthe channel dimension of the KV cache, as indicated by an uneven magnitude\ndistribution and a low-rank structure in the attention weights. In response, we\npropose ThinK, a novel query-dependent KV cache pruning method designed to\nminimize attention weight loss while selectively pruning the least significant\nchannels. Our approach not only maintains or enhances model accuracy but also\nachieves a reduction in KV cache memory costs by over 20% compared with vanilla\nKV cache eviction and quantization methods. For instance, ThinK integrated with\nKIVI can achieve a 2.8x reduction in peak memory usage while maintaining nearly\nthe same quality, enabling up to a 5x increase in batch size when using a\nsingle GPU. Extensive evaluations on the LLaMA and Mistral models across\nvarious long-sequence datasets verified the efficiency of ThinK, establishing a\nnew baseline algorithm for efficient LLM deployment without compromising\nperformance. Our code has been made available at\nhttps://github.com/SalesforceAIResearch/ThinK.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2407.21018v3",
    "published_date": "2024-07-30 17:59:08 UTC",
    "updated_date": "2025-02-27 12:30:43 UTC"
  },
  {
    "arxiv_id": "2407.21011v1",
    "title": "CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning",
    "authors": [
      "Yuexi Du",
      "Brian Chang",
      "Nicha C. Dvornek"
    ],
    "abstract": "Recent advancements in Contrastive Language-Image Pre-training (CLIP) have\ndemonstrated notable success in self-supervised representation learning across\nvarious tasks. However, the existing CLIP-like approaches often demand\nextensive GPU resources and prolonged training times due to the considerable\nsize of the model and dataset, making them poor for medical applications, in\nwhich large datasets are not always common. Meanwhile, the language model\nprompts are mainly manually derived from labels tied to images, potentially\noverlooking the richness of information within training samples. We introduce a\nnovel language-image Contrastive Learning method with an Efficient large\nlanguage model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of\nthe extensive pre-trained language and visual models. Furthermore, we present\nan efficient strategy for learning context-based prompts that mitigates the gap\nbetween informative clinical diagnostic data and simple class labels. Our\nmethod demonstrates state-of-the-art performance on multiple chest X-ray and\nmammography datasets compared with various baselines. The proposed parameter\nefficient framework can reduce the total trainable model size by 39% and reduce\nthe trainable language model to only 4% compared with the current BERT encoder.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.21011v1",
    "published_date": "2024-07-30 17:57:32 UTC",
    "updated_date": "2024-07-30 17:57:32 UTC"
  },
  {
    "arxiv_id": "2407.21009v4",
    "title": "AI-Assisted Generation of Difficult Math Questions",
    "authors": [
      "Vedant Shah",
      "Dingli Yu",
      "Kaifeng Lyu",
      "Simon Park",
      "Jiatong Yu",
      "Yinghui He",
      "Nan Rosemary Ke",
      "Michael Mozer",
      "Yoshua Bengio",
      "Sanjeev Arora",
      "Anirudh Goyal"
    ],
    "abstract": "Current LLM training positions mathematical reasoning as a core capability.\nWith publicly available sources fully tapped, there is unmet demand for diverse\nand challenging math questions. Relying solely on human experts is both\ntime-consuming and costly, while LLM-generated questions often lack the\nrequisite diversity and difficulty. We present a design framework that combines\nthe strengths of LLMs with a human-in-the-loop approach to generate a diverse\narray of challenging math questions. We leverage LLM metacognition skills\n[Didolkar et al., 2024] of a strong LLM to extract core \"skills\" from existing\nmath datasets. These skills serve as the basis for generating novel and\ndifficult questions by prompting the LLM with random pairs of core skills. The\nuse of two different skills within each question makes finding such questions\nan \"out of distribution\" task for both LLMs and humans. Our pipeline employs\nLLMs to iteratively generate and refine questions and solutions through\nmultiturn prompting. Human annotators then verify and further refine the\nquestions, with their efficiency enhanced via further LLM interactions.\nApplying this pipeline on skills extracted from the MATH dataset [Hendrycks et\nal., 2021] resulted in MATH$^2$ - a dataset of higher-quality math questions,\nas evidenced by: (a) Lower performance of all models on MATH$^2$ than on MATH\n(b) Higher performance on MATH when using MATH$^2$ questions as in-context\nexamples. Although focused on mathematics, our methodology seems applicable to\nother domains requiring structured reasoning, and potentially as a component of\nscalable oversight. Also of interest is a striking relationship observed\nbetween models' performance on the new dataset: the success rate on MATH$^2$ is\nthe square on MATH, suggesting that successfully solving the question in\nMATH$^2$ requires a nontrivial combination of two distinct math skills.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21009v4",
    "published_date": "2024-07-30 17:55:36 UTC",
    "updated_date": "2025-02-03 12:53:41 UTC"
  },
  {
    "arxiv_id": "2407.21002v1",
    "title": "XHand: Real-time Expressive Hand Avatar",
    "authors": [
      "Qijun Gan",
      "Zijie Zhou",
      "Jianke Zhu"
    ],
    "abstract": "Hand avatars play a pivotal role in a wide array of digital interfaces,\nenhancing user immersion and facilitating natural interaction within virtual\nenvironments. While previous studies have focused on photo-realistic hand\nrendering, little attention has been paid to reconstruct the hand geometry with\nfine details, which is essential to rendering quality. In the realms of\nextended reality and gaming, on-the-fly rendering becomes imperative. To this\nend, we introduce an expressive hand avatar, named XHand, that is designed to\ncomprehensively generate hand shape, appearance, and deformations in real-time.\nTo obtain fine-grained hand meshes, we make use of three feature embedding\nmodules to predict hand deformation displacements, albedo, and linear blending\nskinning weights, respectively. To achieve photo-realistic hand rendering on\nfine-grained meshes, our method employs a mesh-based neural renderer by\nleveraging mesh topological consistency and latent codes from embedding\nmodules. During training, a part-aware Laplace smoothing strategy is proposed\nby incorporating the distinct levels of regularization to effectively maintain\nthe necessary details and eliminate the undesired artifacts. The experimental\nevaluations on InterHand2.6M and DeepHandMesh datasets demonstrate the efficacy\nof XHand, which is able to recover high-fidelity geometry and texture for hand\nanimations across diverse poses in real-time. To reproduce our results, we will\nmake the full implementation publicly available at\nhttps://github.com/agnJason/XHand.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21002v1",
    "published_date": "2024-07-30 17:49:21 UTC",
    "updated_date": "2024-07-30 17:49:21 UTC"
  },
  {
    "arxiv_id": "2407.21001v3",
    "title": "GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models",
    "authors": [
      "Ali Abdollahi",
      "Mahdi Ghaznavi",
      "Mohammad Reza Karimi Nejad",
      "Arash Mari Oriyad",
      "Reza Abbasi",
      "Ali Salesi",
      "Melika Behjati",
      "Mohammad Hossein Rohban",
      "Mahdieh Soleymani Baghshah"
    ],
    "abstract": "Vision-language models (VLMs) are intensively used in many downstream tasks,\nincluding those requiring assessments of individuals appearing in the images.\nWhile VLMs perform well in simple single-person scenarios, in real-world\napplications, we often face complex situations in which there are persons of\ndifferent genders doing different activities. We show that in such cases, VLMs\nare biased towards identifying the individual with the expected gender\n(according to ingrained gender stereotypes in the model or other forms of\nsample selection bias) as the performer of the activity. We refer to this bias\nin associating an activity with the gender of its actual performer in an image\nor text as the Gender-Activity Binding (GAB) bias and analyze how this bias is\ninternalized in VLMs. To assess this bias, we have introduced the GAB dataset\nwith approximately 5500 AI-generated images that represent a variety of\nactivities, addressing the scarcity of real-world images for some scenarios. To\nhave extensive quality control, the generated images are evaluated for their\ndiversity, quality, and realism. We have tested 12 renowned pre-trained VLMs on\nthis dataset in the context of text-to-image and image-to-text retrieval to\nmeasure the effect of this bias on their predictions. Additionally, we have\ncarried out supplementary experiments to quantify the bias in VLMs' text\nencoders and to evaluate VLMs' capability to recognize activities. Our\nexperiments indicate that VLMs experience an average performance decline of\nabout 13.2% when confronted with gender-activity binding bias.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21001v3",
    "published_date": "2024-07-30 17:46:06 UTC",
    "updated_date": "2024-10-25 11:30:26 UTC"
  },
  {
    "arxiv_id": "2407.20999v3",
    "title": "MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning",
    "authors": [
      "Yupeng Chen",
      "Senmiao Wang",
      "Yushun Zhang",
      "Zhihang Lin",
      "Haozhe Zhang",
      "Weijian Sun",
      "Tian Ding",
      "Ruoyu Sun"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\na wide range of tasks. Typically, LLMs are first pre-trained on large corpora\nand subsequently fine-tuned on task-specific datasets. However, during\nfine-tuning, LLMs may forget some knowledge acquired in the pre-training stage,\nleading to a decline in general capabilities. Existing approaches to mitigate\nforgetting often rely on access to pre-training data, which may be unavailable\nin many real-world scenarios--such as fine-tuning checkpoint-only open-source\nLLMs. To address this challenge, we propose a new fine-tuning algorithm termed\nMomentum-Filtered Optimizer (MoFO). MoFO is an extension of greedy block\ncoordinate descent (BCD) methods: in each iteration, MoFO only updates the\nmodel parameters with the largest momentum magnitudes, while keeping all other\nparameters fixed. MoFO achieves similar fine-tuning performance to the default\nfine-tuning algorithm while effectively mitigating knowledge forgetting. We\nvalidate MoFO through rigorous convergence analysis and extensive experiments,\ndemonstrating its effectiveness in mitigating forgetting without pre-training\ndata.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20999v3",
    "published_date": "2024-07-30 17:38:24 UTC",
    "updated_date": "2025-04-18 09:04:15 UTC"
  },
  {
    "arxiv_id": "2407.20990v1",
    "title": "From Feature Importance to Natural Language Explanations Using LLMs with RAG",
    "authors": [
      "Sule Tekkesinoglu",
      "Lars Kunze"
    ],
    "abstract": "As machine learning becomes increasingly integral to autonomous\ndecision-making processes involving human interaction, the necessity of\ncomprehending the model's outputs through conversational means increases. Most\nrecently, foundation models are being explored for their potential as post hoc\nexplainers, providing a pathway to elucidate the decision-making mechanisms of\npredictive models. In this work, we introduce traceable question-answering,\nleveraging an external knowledge repository to inform the responses of Large\nLanguage Models (LLMs) to user queries within a scene understanding task. This\nknowledge repository comprises contextual details regarding the model's output,\ncontaining high-level features, feature importance, and alternative\nprobabilities. We employ subtractive counterfactual reasoning to compute\nfeature importance, a method that entails analysing output variations resulting\nfrom decomposing semantic features. Furthermore, to maintain a seamless\nconversational flow, we integrate four key characteristics - social, causal,\nselective, and contrastive - drawn from social science research on human\nexplanations into a single-shot prompt, guiding the response generation\nprocess. Our evaluation demonstrates that explanations generated by the LLMs\nencompassed these elements, indicating its potential to bridge the gap between\ncomplex model outputs and natural language expressions.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20990v1",
    "published_date": "2024-07-30 17:27:20 UTC",
    "updated_date": "2024-07-30 17:27:20 UTC"
  },
  {
    "arxiv_id": "2407.20970v1",
    "title": "Large Language Models (LLMs) for Semantic Communication in Edge-based IoT Networks",
    "authors": [
      "Alakesh Kalita"
    ],
    "abstract": "With the advent of Fifth Generation (5G) and Sixth Generation (6G)\ncommunication technologies, as well as the Internet of Things (IoT), semantic\ncommunication is gaining attention among researchers as current communication\ntechnologies are approaching Shannon's limit. On the other hand, Large Language\nModels (LLMs) can understand and generate human-like text, based on extensive\ntraining on diverse datasets with billions of parameters. Considering the\nrecent near-source computational technologies like Edge, in this article, we\ngive an overview of a framework along with its modules, where LLMs can be used\nunder the umbrella of semantic communication at the network edge for efficient\ncommunication in IoT networks. Finally, we discuss a few applications and\nanalyze the challenges and opportunities to develop such systems.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "6pages, 3 figures, Magazine",
    "pdf_url": "http://arxiv.org/pdf/2407.20970v1",
    "published_date": "2024-07-30 16:57:41 UTC",
    "updated_date": "2024-07-30 16:57:41 UTC"
  },
  {
    "arxiv_id": "2407.20956v1",
    "title": "An Effective Dynamic Gradient Calibration Method for Continual Learning",
    "authors": [
      "Weichen Lin",
      "Jiaxiang Chen",
      "Ruomin Huang",
      "Hu Ding"
    ],
    "abstract": "Continual learning (CL) is a fundamental topic in machine learning, where the\ngoal is to train a model with continuously incoming data and tasks. Due to the\nmemory limit, we cannot store all the historical data, and therefore confront\nthe ``catastrophic forgetting'' problem, i.e., the performance on the previous\ntasks can substantially decrease because of the missing information in the\nlatter period. Though a number of elegant methods have been proposed, the\ncatastrophic forgetting phenomenon still cannot be well avoided in practice. In\nthis paper, we study the problem from the gradient perspective, where our aim\nis to develop an effective algorithm to calibrate the gradient in each updating\nstep of the model; namely, our goal is to guide the model to be updated in the\nright direction under the situation that a large amount of historical data are\nunavailable. Our idea is partly inspired by the seminal stochastic variance\nreduction methods (e.g., SVRG and SAGA) for reducing the variance of gradient\nestimation in stochastic gradient descent algorithms. Another benefit is that\nour approach can be used as a general tool, which is able to be incorporated\nwith several existing popular CL methods to achieve better performance. We also\nconduct a set of experiments on several benchmark datasets to evaluate the\nperformance in practice.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20956v1",
    "published_date": "2024-07-30 16:30:09 UTC",
    "updated_date": "2024-07-30 16:30:09 UTC"
  },
  {
    "arxiv_id": "2407.20955v1",
    "title": "Emotion-driven Piano Music Generation via Two-stage Disentanglement and Functional Representation",
    "authors": [
      "Jingyue Huang",
      "Ke Chen",
      "Yi-Hsuan Yang"
    ],
    "abstract": "Managing the emotional aspect remains a challenge in automatic music\ngeneration. Prior works aim to learn various emotions at once, leading to\ninadequate modeling. This paper explores the disentanglement of emotions in\npiano performance generation through a two-stage framework. The first stage\nfocuses on valence modeling of lead sheet, and the second stage addresses\narousal modeling by introducing performance-level attributes. To further\ncapture features that shape valence, an aspect less explored by previous\napproaches, we introduce a novel functional representation of symbolic music.\nThis representation aims to capture the emotional impact of major-minor\ntonality, as well as the interactions among notes, chords, and key signatures.\nObjective and subjective experiments validate the effectiveness of our\nframework in both emotional valence and arousal modeling. We further leverage\nour framework in a novel application of emotional controls, showing a broad\npotential in emotion-driven music generation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Proceedings of the 25th International Society for Music Information\n  Retrieval Conference, ISMIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.20955v1",
    "published_date": "2024-07-30 16:29:28 UTC",
    "updated_date": "2024-07-30 16:29:28 UTC"
  },
  {
    "arxiv_id": "2407.20951v1",
    "title": "An evidence-based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems",
    "authors": [
      "Alessandro Mantelero",
      "Maria Samantha Esposito"
    ],
    "abstract": "Different approaches have been adopted in addressing the challenges of\nArtificial Intelligence (AI), some centred on personal data and others on\nethics, respectively narrowing and broadening the scope of AI regulation. This\ncontribution aims to demonstrate that a third way is possible, starting from\nthe acknowledgement of the role that human rights can play in regulating the\nimpact of data-intensive systems. The focus on human rights is neither a\nparadigm shift nor a mere theoretical exercise. Through the analysis of more\nthan 700 decisions and documents of the data protection authorities of six\ncountries, we show that human rights already underpin the decisions in the\nfield of data use. Based on empirical analysis of this evidence, this work\npresents a methodology and a model for a Human Rights Impact Assessment (HRIA).\nThe methodology and related assessment model are focused on AI applications,\nwhose nature and scale require a proper contextualisation of HRIA methodology.\nMoreover, the proposed models provide a more measurable approach to risk\nassessment which is consistent with the regulatory proposals centred on risk\nthresholds. The proposed methodology is tested in concrete case-studies to\nprove its feasibility and effectiveness. The overall goal is to respond to the\ngrowing interest in HRIA, moving from a mere theoretical debate to a concrete\nand context-specific implementation in the field of data-intensive applications\nbased on AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20951v1",
    "published_date": "2024-07-30 16:27:52 UTC",
    "updated_date": "2024-07-30 16:27:52 UTC"
  },
  {
    "arxiv_id": "2407.20932v1",
    "title": "Complete Approximations of Incomplete Queries",
    "authors": [
      "Julien Corman",
      "Werner Nutt",
      "Ognjen Savkoviƒá"
    ],
    "abstract": "This paper studies the completeness of conjunctive queries over a partially\ncomplete database and the approximation of incomplete queries. Given a query\nand a set of completeness rules (a special kind of tuple generating\ndependencies) that specify which parts of the database are complete, we\ninvestigate whether the query can be fully answered, as if all data were\navailable. If not, we explore reformulating the query into either Maximal\nComplete Specializations (MCSs) or the (unique up to equivalence) Minimal\nComplete Generalization (MCG) that can be fully answered, that is, the best\ncomplete approximations of the query from below or above in the sense of query\ncontainment. We show that the MSG can be characterized as the least fixed-point\nof a monotonic operator in a preorder. Then, we show that an MCS can be\ncomputed by recursive backward application of completeness rules. We study the\ncomplexity of both problems and discuss implementation techniques that rely on\nan ASP and Prolog engines, respectively.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "accepted at RuleML+RR 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.20932v1",
    "published_date": "2024-07-30 16:13:42 UTC",
    "updated_date": "2024-07-30 16:13:42 UTC"
  },
  {
    "arxiv_id": "2407.20918v1",
    "title": "The Realizability of Revision and Contraction Operators in Epistemic Spaces",
    "authors": [
      "Kai Sauerwald",
      "Matthias Thimm"
    ],
    "abstract": "This paper studies the realizability of belief revision and belief\ncontraction operators in epistemic spaces. We observe that AGM revision and AGM\ncontraction operators for epistemic spaces are only realizable in precisely\ndetermined epistemic spaces. We define the class of linear change operators, a\nspecial kind of maxichoice operator. When AGM revision, respectively, AGM\ncontraction, is realizable, linear change operators are a canonical\nrealization.",
    "categories": [
      "cs.AI",
      "03B42",
      "I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20918v1",
    "published_date": "2024-07-30 15:55:01 UTC",
    "updated_date": "2024-07-30 15:55:01 UTC"
  },
  {
    "arxiv_id": "2407.20917v1",
    "title": "How to Choose a Reinforcement-Learning Algorithm",
    "authors": [
      "Fabian Bongratz",
      "Vladimir Golkov",
      "Lukas Mautner",
      "Luca Della Libera",
      "Frederik Heetmeyer",
      "Felix Czaja",
      "Julian Rodemann",
      "Daniel Cremers"
    ],
    "abstract": "The field of reinforcement learning offers a large variety of concepts and\nmethods to tackle sequential decision-making problems. This variety has become\nso large that choosing an algorithm for a task at hand can be challenging. In\nthis work, we streamline the process of choosing reinforcement-learning\nalgorithms and action-distribution families. We provide a structured overview\nof existing methods and their properties, as well as guidelines for when to\nchoose which methods. An interactive version of these guidelines is available\nonline at https://rl-picker.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML",
      "62M45",
      "I.2.8; I.2.6; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "40 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.20917v1",
    "published_date": "2024-07-30 15:54:18 UTC",
    "updated_date": "2024-07-30 15:54:18 UTC"
  },
  {
    "arxiv_id": "2407.20906v5",
    "title": "Automated Review Generation Method Based on Large Language Models",
    "authors": [
      "Shican Wu",
      "Xiao Ma",
      "Dehui Luo",
      "Lulu Li",
      "Xiangcheng Shi",
      "Xin Chang",
      "Xiaoyun Lin",
      "Ran Luo",
      "Chunlei Pei",
      "Changying Du",
      "Zhi-Jian Zhao",
      "Jinlong Gong"
    ],
    "abstract": "Literature research, vital for scientific work, faces the challenge of\nsurging information volumes exceeding researchers' processing capabilities. We\npresent an automated review generation method based on large language models\n(LLMs) to overcome efficiency bottlenecks and reduce cognitive load. Our\nstatistically validated evaluation framework demonstrates that the generated\nreviews match or exceed manual quality, offering broad applicability across\nresearch fields without requiring users' domain knowledge. Applied to propane\ndehydrogenation (PDH) catalysts, our method swiftly analyzed 343 articles,\naveraging seconds per article per LLM account, producing comprehensive reviews\nspanning 35 topics, with extended analysis of 1041 articles providing insights\ninto catalysts' properties. Through multi-layered quality control, we\neffectively mitigated LLMs' hallucinations, with expert verification confirming\naccuracy and citation integrity while demonstrating hallucination risks reduced\nto below 0.5\\% with 95\\% confidence. Released Windows application enables\none-click review generation, enhancing research productivity and literature\nrecommendation efficiency while setting the stage for broader scientific\nexplorations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "physics.data-an"
    ],
    "primary_category": "cs.CL",
    "comment": "Code: https://github.com/TJU-ECAT-AI/AutomaticReviewGeneration Data:\n  https://github.com/TJU-ECAT-AI/AutomaticReviewGenerationData This research\n  has been invited for a Short Oral presentation at the 18th ICC -\n  International Congress on Catalysis, taking place in Lyon, France from July\n  14-19, 2024 Published at https://doi.org/10.1093/nsr/nwaf169 for newer\n  edition",
    "pdf_url": "http://arxiv.org/pdf/2407.20906v5",
    "published_date": "2024-07-30 15:26:36 UTC",
    "updated_date": "2025-05-01 16:24:05 UTC"
  },
  {
    "arxiv_id": "2407.20899v3",
    "title": "Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach",
    "authors": [
      "Adam Wojciechowski",
      "Mateusz Lango",
      "Ondrej Dusek"
    ],
    "abstract": "Existing explanation methods for image classification struggle to provide\nfaithful and plausible explanations. This paper addresses this issue by\nproposing a post-hoc natural language explanation method that can be applied to\nany CNN-based classifier without altering its training process or affecting\npredictive performance. By analysing influential neurons and the corresponding\nactivation maps, the method generates a faithful description of the\nclassifier's decision process in the form of a structured meaning\nrepresentation, which is then converted into text by a language model. Through\nthis pipeline approach, the generated explanations are grounded in the neural\nnetwork architecture, providing accurate insight into the classification\nprocess while remaining accessible to non-experts. Experimental results show\nthat the NLEs constructed by our method are significantly more plausible and\nfaithful. In particular, user interventions in the neural network structure\n(masking of neurons) are three times more effective than the baselines.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Findings of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.20899v3",
    "published_date": "2024-07-30 15:17:15 UTC",
    "updated_date": "2025-03-18 14:13:40 UTC"
  },
  {
    "arxiv_id": "2407.20893v1",
    "title": "MambaCapsule: Towards Transparent Cardiac Disease Diagnosis with Electrocardiography Using Mamba Capsule Network",
    "authors": [
      "Yinlong Xu",
      "Xiaoqiang Liu",
      "Zitai Kong",
      "Yixuan Wu",
      "Yue Wang",
      "Yingzhou Lu",
      "Honghao Gao",
      "Jian Wu",
      "Hongxia Xu"
    ],
    "abstract": "Cardiac arrhythmia, a condition characterized by irregular heartbeats, often\nserves as an early indication of various heart ailments. With the advent of\ndeep learning, numerous innovative models have been introduced for diagnosing\narrhythmias using Electrocardiogram (ECG) signals. However, recent studies\nsolely focus on the performance of models, neglecting the interpretation of\ntheir results. This leads to a considerable lack of transparency, posing a\nsignificant risk in the actual diagnostic process. To solve this problem, this\npaper introduces MambaCapsule, a deep neural networks for ECG arrhythmias\nclassification, which increases the explainability of the model while enhancing\nthe accuracy.Our model utilizes Mamba for feature extraction and Capsule\nnetworks for prediction, providing not only a confidence score but also signal\nfeatures. Akin to the processing mechanism of human brain, the model learns\nsignal features and their relationship between them by reconstructing ECG\nsignals in the predicted selection. The model evaluation was conducted on\nMIT-BIH and PTB dataset, following the AAMI standard. MambaCapsule has achieved\na total accuracy of 99.54% and 99.59% on the test sets respectively. These\nresults demonstrate the promising performance of under the standard test\nprotocol.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20893v1",
    "published_date": "2024-07-30 15:12:29 UTC",
    "updated_date": "2024-07-30 15:12:29 UTC"
  },
  {
    "arxiv_id": "2407.20891v5",
    "title": "Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks",
    "authors": [
      "Bao Gia Doan",
      "Afshar Shamsi",
      "Xiao-Yu Guo",
      "Arash Mohammadi",
      "Hamid Alinejad-Rokny",
      "Dino Sejdinovic",
      "Damien Teney",
      "Damith C. Ranasinghe",
      "Ehsan Abbasnejad"
    ],
    "abstract": "Computational complexity of Bayesian learning is impeding its adoption in\npractical, large-scale tasks. Despite demonstrations of significant merits such\nas improved robustness and resilience to unseen or out-of-distribution inputs\nover their non- Bayesian counterparts, their practical use has faded to near\ninsignificance. In this study, we introduce an innovative framework to mitigate\nthe computational burden of Bayesian neural networks (BNNs). Our approach\nfollows the principle of Bayesian techniques based on deep ensembles, but\nsignificantly reduces their cost via multiple low-rank perturbations of\nparameters arising from a pre-trained neural network. Both vanilla version of\nensembles as well as more sophisticated schemes such as Bayesian learning with\nStein Variational Gradient Descent (SVGD), previously deemed impractical for\nlarge models, can be seamlessly implemented within the proposed framework,\ncalled Bayesian Low-Rank LeArning (Bella). In a nutshell, i) Bella achieves a\ndramatic reduction in the number of trainable parameters required to\napproximate a Bayesian posterior; and ii) it not only maintains, but in some\ninstances, surpasses the performance of conventional Bayesian learning methods\nand non-Bayesian baselines. Our results with large-scale tasks such as\nImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA demonstrate the\neffectiveness and versatility of Bella in building highly scalable and\npractical Bayesian deep models for real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper is accepted in AAAI'25\", and the code is available at\n  https://bnn-bella.github.io/BNN-Bella/",
    "pdf_url": "http://arxiv.org/pdf/2407.20891v5",
    "published_date": "2024-07-30 15:07:13 UTC",
    "updated_date": "2025-02-18 12:44:35 UTC"
  },
  {
    "arxiv_id": "2407.20884v1",
    "title": "Effective Black Box Testing of Sentiment Analysis Classification Networks",
    "authors": [
      "Parsa Karbasizadeh",
      "Fathiyeh Faghih",
      "Pouria Golshanrad"
    ],
    "abstract": "Transformer-based neural networks have demonstrated remarkable performance in\nnatural language processing tasks such as sentiment analysis. Nevertheless, the\nissue of ensuring the dependability of these complicated architectures through\ncomprehensive testing is still open. This paper presents a collection of\ncoverage criteria specifically designed to assess test suites created for\ntransformer-based sentiment analysis networks. Our approach utilizes input\nspace partitioning, a black-box method, by considering emotionally relevant\nlinguistic features such as verbs, adjectives, adverbs, and nouns. In order to\neffectively produce test cases that encompass a wide range of emotional\nelements, we utilize the k-projection coverage metric. This metric minimizes\nthe complexity of the problem by examining subsets of k features at the same\ntime, hence reducing dimensionality. Large language models are employed to\ngenerate sentences that display specific combinations of emotional features.\nThe findings from experiments obtained from a sentiment analysis dataset\nillustrate that our criteria and generated tests have led to an average\nincrease of 16\\% in test coverage. In addition, there is a corresponding\naverage decrease of 6.5\\% in model accuracy, showing the ability to identify\nvulnerabilities. Our work provides a foundation for improving the dependability\nof transformer-based sentiment analysis systems through comprehensive test\nevaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper uses LaTeX with the IEEEtran.cls document class",
    "pdf_url": "http://arxiv.org/pdf/2407.20884v1",
    "published_date": "2024-07-30 14:58:11 UTC",
    "updated_date": "2024-07-30 14:58:11 UTC"
  },
  {
    "arxiv_id": "2407.20879v1",
    "title": "A Scalable Tool For Analyzing Genomic Variants Of Humans Using Knowledge Graphs and Machine Learning",
    "authors": [
      "Shivika Prasanna",
      "Ajay Kumar",
      "Deepthi Rao",
      "Eduardo Simoes",
      "Praveen Rao"
    ],
    "abstract": "The integration of knowledge graphs and graph machine learning (GML) in\ngenomic data analysis offers several opportunities for understanding complex\ngenetic relationships, especially at the RNA level. We present a comprehensive\napproach for leveraging these technologies to analyze genomic variants,\nspecifically in the context of RNA sequencing (RNA-seq) data from COVID-19\npatient samples. The proposed method involves extracting variant-level genetic\ninformation, annotating the data with additional metadata using SnpEff, and\nconverting the enriched Variant Call Format (VCF) files into Resource\nDescription Framework (RDF) triples. The resulting knowledge graph is further\nenhanced with patient metadata and stored in a graph database, facilitating\nefficient querying and indexing. We utilize the Deep Graph Library (DGL) to\nperform graph machine learning tasks, including node classification with\nGraphSAGE and Graph Convolutional Networks (GCNs). Our approach demonstrates\nsignificant utility using our proposed tool, VariantKG, in three key scenarios:\nenriching graphs with new VCF data, creating subgraphs based on user-defined\nfeatures, and conducting graph machine learning for node classification.",
    "categories": [
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2312.04423",
    "pdf_url": "http://arxiv.org/pdf/2407.20879v1",
    "published_date": "2024-07-30 14:56:10 UTC",
    "updated_date": "2024-07-30 14:56:10 UTC"
  },
  {
    "arxiv_id": "2407.20856v1",
    "title": "Learn by Selling: Equipping Large Language Models with Product Knowledge for Context-Driven Recommendations",
    "authors": [
      "Sarthak Anand",
      "Yutong Jiang",
      "Giorgi Kokaia"
    ],
    "abstract": "The rapid evolution of large language models (LLMs) has opened up new\npossibilities for applications such as context-driven product recommendations.\nHowever, the effectiveness of these models in this context is heavily reliant\non their comprehensive understanding of the product inventory. This paper\npresents a novel approach to equipping LLMs with product knowledge by training\nthem to respond contextually to synthetic search queries that include product\nIDs. We delve into an extensive analysis of this method, evaluating its\neffectiveness, outlining its benefits, and highlighting its constraints. The\npaper also discusses the potential improvements and future directions for this\napproach, providing a comprehensive understanding of the role of LLMs in\nproduct recommendations.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20856v1",
    "published_date": "2024-07-30 14:31:53 UTC",
    "updated_date": "2024-07-30 14:31:53 UTC"
  },
  {
    "arxiv_id": "2407.20830v1",
    "title": "Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing",
    "authors": [
      "Eugenio Lomurno",
      "Matteo Matteucci"
    ],
    "abstract": "Federated learning has emerged as a paradigm for collaborative learning,\nenabling the development of robust models without the need to centralise\nsensitive data. However, conventional federated learning techniques have\nprivacy and security vulnerabilities due to the exposure of models, parameters\nor updates, which can be exploited as an attack surface. This paper presents\nFederated Knowledge Recycling (FedKR), a cross-silo federated learning approach\nthat uses locally generated synthetic data to facilitate collaboration between\ninstitutions. FedKR combines advanced data generation techniques with a dynamic\naggregation process to provide greater security against privacy attacks than\nexisting methods, significantly reducing the attack surface. Experimental\nresults on generic and medical datasets show that FedKR achieves competitive\nperformance, with an average improvement in accuracy of 4.24% compared to\ntraining models from local data, demonstrating particular effectiveness in data\nscarcity scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20830v1",
    "published_date": "2024-07-30 13:56:26 UTC",
    "updated_date": "2024-07-30 13:56:26 UTC"
  },
  {
    "arxiv_id": "2407.20828v1",
    "title": "How to Measure the Intelligence of Large Language Models?",
    "authors": [
      "Nils K√∂rber",
      "Silvan Wehrli",
      "Christopher Irrgang"
    ],
    "abstract": "With the release of ChatGPT and other large language models (LLMs) the\ndiscussion about the intelligence, possibilities, and risks, of current and\nfuture models have seen large attention. This discussion included much debated\nscenarios about the imminent rise of so-called \"super-human\" AI, i.e., AI\nsystems that are orders of magnitude smarter than humans. In the spirit of Alan\nTuring, there is no doubt that current state-of-the-art language models already\npass his famous test. Moreover, current models outperform humans in several\nbenchmark tests, so that publicly available LLMs have already become versatile\ncompanions that connect everyday life, industry and science. Despite their\nimpressive capabilities, LLMs sometimes fail completely at tasks that are\nthought to be trivial for humans. In other cases, the trustworthiness of LLMs\nbecomes much more elusive and difficult to evaluate. Taking the example of\nacademia, language models are capable of writing convincing research articles\non a given topic with only little input. Yet, the lack of trustworthiness in\nterms of factual consistency or the existence of persistent hallucinations in\nAI-generated text bodies has led to a range of restrictions for AI-based\ncontent in many scientific journals. In view of these observations, the\nquestion arises as to whether the same metrics that apply to human intelligence\ncan also be applied to computational methods and has been discussed\nextensively. In fact, the choice of metrics has already been shown to\ndramatically influence assessments on potential intelligence emergence. Here,\nwe argue that the intelligence of LLMs should not only be assessed by\ntask-specific statistical metrics, but separately in terms of qualitative and\nquantitative measures.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "3 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2407.20828v1",
    "published_date": "2024-07-30 13:53:48 UTC",
    "updated_date": "2024-07-30 13:53:48 UTC"
  },
  {
    "arxiv_id": "2407.20822v1",
    "title": "Adding Circumscription to Decidable Fragments of First-Order Logic: A Complexity Rollercoaster",
    "authors": [
      "Carsten Lutz",
      "Quentin Mani√®re"
    ],
    "abstract": "We study extensions of expressive decidable fragments of first-order logic\nwith circumscription, in particular the two-variable fragment FO$^2$, its\nextension C$^2$ with counting quantifiers, and the guarded fragment GF. We\nprove that if only unary predicates are minimized (or fixed) during\ncircumscription, then decidability of logical consequence is preserved. For\nFO$^2$ the complexity increases from $\\textrm{coNexp}$ to\n$\\textrm{coNExp}^\\textrm{NP}$-complete, for GF it (remarkably!) increases from\n$\\textrm{2Exp}$ to $\\textrm{Tower}$-complete, and for C$^2$ the complexity\nremains open. We also consider querying circumscribed knowledge bases whose\nontology is a GF sentence, showing that the problem is decidable for unions of\nconjunctive queries, $\\textrm{Tower}$-complete in combined complexity, and\nelementary in data complexity. Already for atomic queries and ontologies that\nare sets of guarded existential rules, however, for every $k \\geq 0$ there is\nan ontology and query that are $k$-$\\textrm{Exp}$-hard in data complexity.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages - Extended version of a paper accepted at KR 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.20822v1",
    "published_date": "2024-07-30 13:39:38 UTC",
    "updated_date": "2024-07-30 13:39:38 UTC"
  },
  {
    "arxiv_id": "2407.20806v1",
    "title": "ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning",
    "authors": [
      "Hosung Lee",
      "Sejin Kim",
      "Seungpil Lee",
      "Sanha Hwang",
      "Jihwan Lee",
      "Byung-Jun Lee",
      "Sundong Kim"
    ],
    "abstract": "This paper introduces ARCLE, an environment designed to facilitate\nreinforcement learning research on the Abstraction and Reasoning Corpus (ARC).\nAddressing this inductive reasoning benchmark with reinforcement learning\npresents these challenges: a vast action space, a hard-to-reach goal, and a\nvariety of tasks. We demonstrate that an agent with proximal policy\noptimization can learn individual tasks through ARCLE. The adoption of\nnon-factorial policies and auxiliary losses led to performance enhancements,\neffectively mitigating issues associated with action spaces and goal\nattainment. Based on these insights, we propose several research directions and\nmotivations for using ARCLE, including MAML, GFlowNets, and World Models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by CoLLAs 2024, Project page:\n  https://github.com/confeitoHS/arcle",
    "pdf_url": "http://arxiv.org/pdf/2407.20806v1",
    "published_date": "2024-07-30 13:11:45 UTC",
    "updated_date": "2024-07-30 13:11:45 UTC"
  },
  {
    "arxiv_id": "2407.20798v1",
    "title": "Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning",
    "authors": [
      "Norman Di Palo",
      "Leonard Hasenclever",
      "Jan Humplik",
      "Arunkumar Byravan"
    ],
    "abstract": "We introduce Diffusion Augmented Agents (DAAG), a novel framework that\nleverages large language models, vision language models, and diffusion models\nto improve sample efficiency and transfer learning in reinforcement learning\nfor embodied agents. DAAG hindsight relabels the agent's past experience by\nusing diffusion models to transform videos in a temporally and geometrically\nconsistent way to align with target instructions with a technique we call\nHindsight Experience Augmentation. A large language model orchestrates this\nautonomous process without requiring human supervision, making it well-suited\nfor lifelong learning scenarios. The framework reduces the amount of\nreward-labeled data needed to 1) finetune a vision language model that acts as\na reward detector, and 2) train RL agents on new tasks. We demonstrate the\nsample efficiency gains of DAAG in simulated robotics environments involving\nmanipulation and navigation. Our results show that DAAG improves learning of\nreward detectors, transferring past experience, and acquiring new tasks - key\nabilities for developing efficient lifelong learning agents. Supplementary\nmaterial and visualizations are available on our website\nhttps://sites.google.com/view/diffusion-augmented-agents/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at 3rd Conference on Lifelong Learning Agents (CoLLAs),\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2407.20798v1",
    "published_date": "2024-07-30 13:01:31 UTC",
    "updated_date": "2024-07-30 13:01:31 UTC"
  },
  {
    "arxiv_id": "2407.20792v1",
    "title": "How Novice Programmers Use and Experience ChatGPT when Solving Programming Exercises in an Introductory Course",
    "authors": [
      "Andreas Scholl",
      "Natalie Kiesler"
    ],
    "abstract": "This research paper contributes to the computing education research\ncommunity's understanding of Generative AI (GenAI) in the context of\nintroductory programming, and specifically, how students utilize related tools,\nsuch as ChatGPT. An increased understanding of students' use is mandatory for\neducators and higher education institutions, as GenAI is here to stay, and its\nperformance is likely to improve rapidly in the near future. Learning about\nstudents' use patterns is not only crucial to support their learning, but to\ndevelop adequate forms of instruction and assessment. With the rapid\nadvancement of AI, its broad availability, and ubiquitous presence in\neducational environments, elaborating how AI can enhance learning experiences,\nespecially in courses such as introductory programming is important. To date,\nmost studies have focused on the educator's perspective on GenAI, its\nperformance, characteristics, and limitations. However, the student\nperspective, and how they actually use GenAI tools in course contexts, has not\nbeen subject to a great number of studies. Therefore, this study is guided by\nthe following research questions: (1) What do students report on their use\npattern of ChatGPT in the context of introductory programming exercises? and\n(2) How do students perceive ChatGPT in the context of introductory programming\nexercises? To address these questions, computing students at a large German\nuniversity were asked to solve programming tasks with the assistance of ChatGPT\nas part of their introductory programming course. Students (n=298) provided\ninformation regarding the use of ChatGPT, and their evaluation of the tool via\nan online survey. This research provides a comprehensive evaluation of\nChatGPT-3.5's application by novice programmers in a higher education\ncontext...",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at 2024 IEEE ASEE Frontiers in Education Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.20792v1",
    "published_date": "2024-07-30 12:55:42 UTC",
    "updated_date": "2024-07-30 12:55:42 UTC"
  },
  {
    "arxiv_id": "2407.20786v2",
    "title": "Be aware of overfitting by hyperparameter optimization!",
    "authors": [
      "Igor V. Tetko",
      "Ruud van Deursen",
      "Guillaume Godin"
    ],
    "abstract": "Hyperparameter optimization is very frequently employed in machine learning.\nHowever, an optimization of a large space of parameters could result in\noverfitting of models. In recent studies on solubility prediction the authors\ncollected seven thermodynamic and kinetic solubility datasets from different\ndata sources. They used state-of-the-art graph-based methods and compared\nmodels developed for each dataset using different data cleaning protocols and\nhyperparameter optimization. In our study we showed that hyperparameter\noptimization did not always result in better models, possibly due to\noverfitting when using the same statistical measures. Similar results could be\ncalculated using pre-set hyperparameters, reducing the computational effort by\naround 10,000 times. We also extended the previous analysis by adding a\nrepresentation learning method based on Natural Language Processing of smiles\ncalled Transformer CNN. We show that across all analyzed sets using exactly the\nsame protocol, Transformer CNN provided better results than graph-based methods\nfor 26 out of 28 pairwise comparisons by using only a tiny fraction of time as\ncompared to other methods. Last but not least we stressed the importance of\ncomparing calculation results using exactly the same statistical measures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 5 Tables",
    "pdf_url": "http://arxiv.org/pdf/2407.20786v2",
    "published_date": "2024-07-30 12:45:05 UTC",
    "updated_date": "2024-11-24 07:15:24 UTC"
  },
  {
    "arxiv_id": "2407.20777v1",
    "title": "Metaheuristic Enhanced with Feature-Based Guidance and Diversity Management for Solving the Capacitated Vehicle Routing Problem",
    "authors": [
      "Bachtiar Herdianto",
      "Romain Billot",
      "Flavien Lucas",
      "Marc Sevaux"
    ],
    "abstract": "We propose a metaheuristic algorithm enhanced with feature-based guidance\nthat is designed to solve the Capacitated Vehicle Routing Problem (CVRP). To\nformulate the proposed guidance, we developed and explained a supervised\nMachine Learning (ML) model, that is used to formulate the guidance and control\nthe diversity of the solution during the optimization process. We propose a\nmetaheuristic algorithm combining neighborhood search and a novel mechanism of\nhybrid split and path relinking to implement the proposed guidance. The\nproposed guidance has proven to give a statistically significant improvement to\nthe proposed metaheuristic algorithm when solving CVRP. Moreover, the proposed\nguided metaheuristic is also capable of producing competitive solutions among\nstate-of-the-art metaheuristic algorithms.",
    "categories": [
      "cs.AI",
      "cs.DM"
    ],
    "primary_category": "cs.AI",
    "comment": "https://hal.science/hal-04663574",
    "pdf_url": "http://arxiv.org/pdf/2407.20777v1",
    "published_date": "2024-07-30 12:26:07 UTC",
    "updated_date": "2024-07-30 12:26:07 UTC"
  },
  {
    "arxiv_id": "2407.20775v2",
    "title": "Interpretable Pre-Trained Transformers for Heart Time-Series Data",
    "authors": [
      "Harry J. Davies",
      "James Monsen",
      "Danilo P. Mandic"
    ],
    "abstract": "Decoder-only transformers are the backbone of the popular generative\npre-trained transformer (GPT) series of large language models. In this work, we\nemploy this framework to the analysis of clinical heart time-series data, to\ncreate two pre-trained general purpose cardiac models, termed PPG-PT and\nECG-PT. We place a special emphasis on making both such pre-trained models\nfully interpretable. This is achieved firstly through aggregate attention maps\nwhich show that, in order to make predictions, the model focuses on similar\npoints in previous cardiac cycles and gradually broadens its attention in\ndeeper layers. Next, we show that tokens with the same value, which occur at\ndifferent distinct points in the electrocardiography (ECG) and\nphotoplethysmography (PPG) cycle, form separate clusters in high dimensional\nspace. The clusters form according to phase, as the tokens propagate through\nthe transformer blocks. Finally, we highlight that individual attention heads\nrespond to specific physiologically relevent features, such as the dicrotic\nnotch in PPG and the P-wave in ECG. It is also demonstrated that these\npre-trained models are straightforward to fine-tune for tasks such as\nclassification of atrial fibrillation (AF), and beat detection in\nphotoplethysmography. For the example of AF, the fine-tuning took 11 minutes of\ncomputer time, and achieved the respective leave-one-subject-out AUCs of 0.99\nand 0.93 for ECG and PPG within the MIMIC Perform AF dataset. In addition, the\nfine-tuned beat detector achieved a state-of-the-art F1 score of 98%, as well\nas uniquely providing a beat confidence level which acts as a signal quality\nestimator. Importantly, the fine-tuned models for AF screening are also fully\nexplainable, with attention shifting to regions in the context that are\nstrongly indicative of atrial fibrillation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.20775v2",
    "published_date": "2024-07-30 12:22:03 UTC",
    "updated_date": "2024-08-13 10:18:45 UTC"
  },
  {
    "arxiv_id": "2407.20761v3",
    "title": "OmniBal: Towards Fast Instruct-tuning for Vision-Language Models via Omniverse Computation Balance",
    "authors": [
      "Yongqiang Yao",
      "Jingru Tan",
      "Jiahao Hu",
      "Feizhao Zhang",
      "Yazhe Niu",
      "Xin Jin",
      "Bo Li",
      "Ruihao Gong",
      "Pengfei Liu",
      "Dahua Lin",
      "Ningyi Xu"
    ],
    "abstract": "Recently, vision-language instruct-tuning models have made significant\nprogress due to their more comprehensive understanding of the world. In this\nwork, we discovered that large-scale 3D parallel training on those models leads\nto an imbalanced computation load across different devices. The vision and\nlanguage parts are inherently heterogeneous: their data distribution and model\narchitecture differ significantly, which affects distributed training\nefficiency. We rebalanced the computational loads from data, model, and memory\nperspectives to address this issue, achieving more balanced computation across\ndevices. These three components are not independent but are closely connected,\nforming an omniverse balanced training framework. Specifically, for the data,\nwe grouped instances into new balanced mini-batches within and across devices.\nFor the model, we employed a search-based method to achieve a more balanced\npartitioning. For memory optimization, we adaptively adjusted the\nre-computation strategy for each partition to utilize the available memory\nfully. We conducted extensive experiments to validate the effectiveness of our\nmethod. Compared with the open-source training code of InternVL-Chat, we\nsignificantly reduced GPU days, achieving about 1.8x speed-up. Our method's\nefficacy and generalizability were further demonstrated across various models\nand datasets. Codes will be released at https://github.com/ModelTC/OmniBal.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20761v3",
    "published_date": "2024-07-30 12:02:58 UTC",
    "updated_date": "2025-02-11 03:53:46 UTC"
  },
  {
    "arxiv_id": "2407.20754v2",
    "title": "Cost-Based Semantics for Querying Inconsistent Weighted Knowledge Bases",
    "authors": [
      "Meghyn Bienvenu",
      "Camille Bourgaux",
      "Robin Jean"
    ],
    "abstract": "In this paper, we explore a quantitative approach to querying inconsistent\ndescription logic knowledge bases. We consider weighted knowledge bases in\nwhich both axioms and assertions have (possibly infinite) weights, which are\nused to assign a cost to each interpretation based upon the axioms and\nassertions it violates. Two notions of certain and possible answer are defined\nby either considering interpretations whose cost does not exceed a given bound\nor restricting attention to optimal-cost interpretations. Our main contribution\nis a comprehensive analysis of the combined and data complexity of bounded cost\nsatisfiability and certain and possible answer recognition, for description\nlogics between ELbot and ALCO.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LO",
    "comment": "This is an extended version of a paper appearing at the 21st\n  International Conference on Principles of Knowledge Representation and\n  Reasoning (KR 2024). 20 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.20754v2",
    "published_date": "2024-07-30 11:56:02 UTC",
    "updated_date": "2024-07-31 08:26:28 UTC"
  },
  {
    "arxiv_id": "2407.20753v1",
    "title": "Efficient Quantum One-Class Support Vector Machines for Anomaly Detection Using Randomized Measurements and Variable Subsampling",
    "authors": [
      "Michael K√∂lle",
      "Afrae Ahouzi",
      "Pascal Debus",
      "Elif √áetiner",
      "Robert M√ºller",
      "Dani√´lle Schuman",
      "Claudia Linnhoff-Popien"
    ],
    "abstract": "Quantum one-class support vector machines leverage the advantage of quantum\nkernel methods for semi-supervised anomaly detection. However, their quadratic\ntime complexity with respect to data size poses challenges when dealing with\nlarge datasets. In recent work, quantum randomized measurements kernels and\nvariable subsampling were proposed, as two independent methods to address this\nproblem. The former achieves higher average precision, but suffers from\nvariance, while the latter achieves linear complexity to data size and has\nlower variance. The current work focuses instead on combining these two\nmethods, along with rotated feature bagging, to achieve linear time complexity\nboth to data size and to number of features. Despite their instability, the\nresulting models exhibit considerably higher performance and faster training\nand testing times.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to Springer Nature CS",
    "pdf_url": "http://arxiv.org/pdf/2407.20753v1",
    "published_date": "2024-07-30 11:55:52 UTC",
    "updated_date": "2024-07-30 11:55:52 UTC"
  },
  {
    "arxiv_id": "2407.20750v1",
    "title": "JaColBERTv2.5: Optimising Multi-Vector Retrievers to Create State-of-the-Art Japanese Retrievers with Constrained Resources",
    "authors": [
      "Benjamin Clavi√©"
    ],
    "abstract": "Neural Information Retrieval has advanced rapidly in high-resource languages,\nbut progress in lower-resource ones such as Japanese has been hindered by data\nscarcity, among other challenges. Consequently, multilingual models have\ndominated Japanese retrieval, despite their computational inefficiencies and\ninability to capture linguistic nuances. While recent multi-vector monolingual\nmodels like JaColBERT have narrowed this gap, they still lag behind\nmultilingual methods in large-scale evaluations. This work addresses the\nsuboptimal training methods of multi-vector retrievers in lower-resource\nsettings, focusing on Japanese. We systematically evaluate and improve key\naspects of the inference and training settings of JaColBERT, and more broadly,\nmulti-vector models. We further enhance performance through a novel checkpoint\nmerging step, showcasing it to be an effective way of combining the benefits of\nfine-tuning with the generalization capabilities of the original checkpoint.\nBuilding on our analysis, we introduce a novel training recipe, resulting in\nthe JaColBERTv2.5 model. JaColBERTv2.5, with only 110 million parameters and\ntrained in under 15 hours on 4 A100 GPUs, significantly outperforms all\nexisting methods across all common benchmarks, reaching an average score of\n0.754, significantly above the previous best of 0.720. To support future\nresearch, we make our final models, intermediate checkpoints and all data used\npublicly available.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20750v1",
    "published_date": "2024-07-30 11:42:19 UTC",
    "updated_date": "2024-07-30 11:42:19 UTC"
  },
  {
    "arxiv_id": "2407.20739v1",
    "title": "Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization",
    "authors": [
      "Michael K√∂lle",
      "Karola Schneider",
      "Sabrina Egger",
      "Felix Topp",
      "Thomy Phan",
      "Philipp Altmann",
      "Jonas N√º√ülein",
      "Claudia Linnhoff-Popien"
    ],
    "abstract": "In recent years, Multi-Agent Reinforcement Learning (MARL) has found\napplication in numerous areas of science and industry, such as autonomous\ndriving, telecommunications, and global health. Nevertheless, MARL suffers\nfrom, for instance, an exponential growth of dimensions. Inherent properties of\nquantum mechanics help to overcome these limitations, e.g., by significantly\nreducing the number of trainable parameters. Previous studies have developed an\napproach that uses gradient-free quantum Reinforcement Learning and\nevolutionary optimization for variational quantum circuits (VQCs) to reduce the\ntrainable parameters and avoid barren plateaus as well as vanishing gradients.\nThis leads to a significantly better performance of VQCs compared to classical\nneural networks with a similar number of trainable parameters and a reduction\nin the number of parameters by more than 97 \\% compared to similarly good\nneural networks. We extend an approach of K\\\"olle et al. by proposing a\nGate-Based, a Layer-Based, and a Prototype-Based concept to mutate and\nrecombine VQCs. Our results show the best performance for mutation-only\nstrategies and the Gate-Based approach. In particular, we observe a\nsignificantly better score, higher total and own collected coins, as well as a\nsuperior own coin rate for the best agent when evaluated in the Coin Game\nenvironment.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20739v1",
    "published_date": "2024-07-30 11:16:25 UTC",
    "updated_date": "2024-07-30 11:16:25 UTC"
  },
  {
    "arxiv_id": "2408.02676v2",
    "title": "On Biases in a UK Biobank-based Retinal Image Classification Model",
    "authors": [
      "Anissa Alloula",
      "Rima Mustafa",
      "Daniel R McGowan",
      "Bart≈Çomiej W. Papie≈º"
    ],
    "abstract": "Recent work has uncovered alarming disparities in the performance of machine\nlearning models in healthcare. In this study, we explore whether such\ndisparities are present in the UK Biobank fundus retinal images by training and\nevaluating a disease classification model on these images. We assess possible\ndisparities across various population groups and find substantial differences\ndespite strong overall performance of the model. In particular, we discover\nunfair performance for certain assessment centres, which is surprising given\nthe rigorous data standardisation protocol. We compare how these differences\nemerge and apply a range of existing bias mitigation methods to each one. A key\ninsight is that each disparity has unique properties and responds differently\nto the mitigation methods. We also find that these methods are largely unable\nto enhance fairness, highlighting the need for better bias mitigation methods\ntailored to the specific type of bias.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear at MICCAI FAIMI Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.02676v2",
    "published_date": "2024-07-30 10:50:07 UTC",
    "updated_date": "2024-10-25 16:51:19 UTC"
  },
  {
    "arxiv_id": "2407.20724v2",
    "title": "Exploring Loss Landscapes through the Lens of Spin Glass Theory",
    "authors": [
      "Hao Liao",
      "Wei Zhang",
      "Zhanyi Huang",
      "Zexiao Long",
      "Mingyang Zhou",
      "Xiaoqun Wu",
      "Rui Mao",
      "Chi Ho Yeung"
    ],
    "abstract": "In the past decade, significant strides in deep learning have led to numerous\ngroundbreaking applications. Despite these advancements, the understanding of\nthe high generalizability of deep learning, especially in such an\nover-parametrized space, remains limited. For instance, in deep neural networks\n(DNNs), their internal representations, decision-making mechanism, absence of\noverfitting in an over-parametrized space, superior generalizability, etc.,\nremain less understood. Successful applications are often considered as\nempirical rather than scientific achievement. This paper delves into the loss\nlandscape of DNNs through the lens of spin glass in statistical physics, a\nsystem characterized by a complex energy landscape with numerous metastable\nstates, as a novel perspective in understanding how DNNs work. We investigated\nthe loss landscape of single hidden layer neural networks activated by\nRectified Linear Unit (ReLU) function, and introduced several protocols to\nexamine the analogy between DNNs and spin glass. Specifically, we used (1)\nrandom walk in the parameter space of DNNs to unravel the structures in their\nloss landscape; (2) a permutation-interpolation protocol to study the\nconnection between copies of identical regions in the loss landscape due to the\npermutation symmetry in the hidden layers; (3) hierarchical clustering to\nreveal the hierarchy among trained solutions of DNNs, reminiscent of the\nso-called Replica Symmetry Breaking (RSB) phenomenon (i.e. the Parisi solution)\nin spin glass; (4) finally, we examine the relationship between the ruggedness\nof DNN's loss landscape and its generalizability, showing an improvement of\nflattened minima.",
    "categories": [
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "primary_category": "cond-mat.dis-nn",
    "comment": "24 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.20724v2",
    "published_date": "2024-07-30 10:37:15 UTC",
    "updated_date": "2024-09-16 12:39:33 UTC"
  },
  {
    "arxiv_id": "2407.20712v1",
    "title": "Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming",
    "authors": [
      "Yate Ge",
      "Yi Dai",
      "Run Shan",
      "Kechun Li",
      "Yuanda Hu",
      "Xiaohua Sun"
    ],
    "abstract": "End-user development allows everyday users to tailor service robots or\napplications to their needs. One user-friendly approach is natural language\nprogramming. However, it encounters challenges such as an expansive user\nexpression space and limited support for debugging and editing, which restrict\nits application in end-user programming. The emergence of large language models\n(LLMs) offers promising avenues for the translation and interpretation between\nhuman language instructions and the code executed by robots, but their\napplication in end-user programming systems requires further study. We\nintroduce Cocobo, a natural language programming system with interactive\ndiagrams powered by LLMs. Cocobo employs LLMs to understand users' authoring\nintentions, generate and explain robot programs, and facilitate the conversion\nbetween executable code and flowchart representations. Our user study shows\nthat Cocobo has a low learning curve, enabling even users with zero coding\nexperience to customize robot programs successfully.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "This is the preprint version of a paper accepted for presentation at\n  the IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC),\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2407.20712v1",
    "published_date": "2024-07-30 10:13:00 UTC",
    "updated_date": "2024-07-30 10:13:00 UTC"
  },
  {
    "arxiv_id": "2407.20708v4",
    "title": "Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection",
    "authors": [
      "Xinhao Luo",
      "Man Yao",
      "Yuhong Chou",
      "Bo Xu",
      "Guoqi Li"
    ],
    "abstract": "Brain-inspired Spiking Neural Networks (SNNs) have bio-plausibility and\nlow-power advantages over Artificial Neural Networks (ANNs). Applications of\nSNNs are currently limited to simple classification tasks because of their poor\nperformance. In this work, we focus on bridging the performance gap between\nANNs and SNNs on object detection. Our design revolves around network\narchitecture and spiking neuron. First, the overly complex module design causes\nspike degradation when the YOLO series is converted to the corresponding\nspiking version. We design a SpikeYOLO architecture to solve this problem by\nsimplifying the vanilla YOLO and incorporating meta SNN blocks. Second, object\ndetection is more sensitive to quantization errors in the conversion of\nmembrane potentials into binary spikes by spiking neurons. To address this\nchallenge, we design a new spiking neuron that activates Integer values during\ntraining while maintaining spike-driven by extending virtual timesteps during\ninference. The proposed method is validated on both static and neuromorphic\nobject detection datasets. On the static COCO dataset, we obtain 66.2% mAP@50\nand 48.9% mAP@50:95, which is +15.0% and +18.7% higher than the prior\nstate-of-the-art SNN, respectively. On the neuromorphic Gen1 dataset, we\nachieve 67.2% mAP@50, which is +2.5% greater than the ANN with equivalent\narchitecture, and the energy efficiency is improved by 5.7*. Code:\nhttps://github.com/BICLab/SpikeYOLO",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ECCV2024; 19 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.20708v4",
    "published_date": "2024-07-30 10:04:16 UTC",
    "updated_date": "2025-04-15 11:34:30 UTC"
  },
  {
    "arxiv_id": "2407.20705v1",
    "title": "PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning",
    "authors": [
      "Muhammad Anwar Ma'sum",
      "Mahardhika Pratama",
      "Savitha Ramasamy",
      "Lin Liu",
      "Habibullah Habibullah",
      "Ryszard Kowalczyk"
    ],
    "abstract": "Federated Class Incremental Learning (FCIL) is a new direction in continual\nlearning (CL) for addressing catastrophic forgetting and non-IID data\ndistribution simultaneously. Existing FCIL methods call for high communication\ncosts and exemplars from previous classes. We propose a novel rehearsal-free\nmethod for FCIL named prototypes-injected prompt (PIP) that involves 3 main\nideas: a) prototype injection on prompt learning, b) prototype augmentation,\nand c) weighted Gaussian aggregation on the server side. Our experiment result\nshows that the proposed method outperforms the current state of the arts\n(SOTAs) with a significant improvement (up to 33%) in CIFAR100, MiniImageNet\nand TinyImageNet datasets. Our extensive analysis demonstrates the robustness\nof PIP in different task sizes, and the advantage of requiring smaller\nparticipating local clients, and smaller global rounds. For further study,\nsource codes of PIP, baseline, and experimental logs are shared publicly in\nhttps://github.com/anwarmaxsum/PIP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Conference on Information and Knowledge Management (CIKM) 2024\n  (Accepted)",
    "pdf_url": "http://arxiv.org/pdf/2407.20705v1",
    "published_date": "2024-07-30 10:00:16 UTC",
    "updated_date": "2024-07-30 10:00:16 UTC"
  },
  {
    "arxiv_id": "2407.20700v1",
    "title": "Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concept",
    "authors": [
      "Alexandre Trilla",
      "Ossee Yiboe",
      "Nenad Mijatovic",
      "Jordi Vitri√†"
    ],
    "abstract": "This paper describes the development of a causal diagnosis approach for\ntroubleshooting an industrial environment on the basis of the technical\nlanguage expressed in Return on Experience records. The proposed method\nleverages the vectorized linguistic knowledge contained in the distributed\nrepresentation of a Large Language Model, and the causal associations entailed\nby the embedded failure modes and mechanisms of the industrial assets. The\npaper presents the elementary but essential concepts of the solution, which is\nconceived as a causality-aware retrieval augmented generation system, and\nillustrates them experimentally on a real-world Predictive Maintenance setting.\nFinally, it discusses avenues of improvement for the maturity of the utilized\ncausal technology to meet the robustness challenges of increasingly complex\nscenarios in the industry.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "2nd Workshop on Causal Inference and Machine Learning in Practice at\n  the KDD 2024 Conference. arXiv admin note: text overlap with arXiv:2407.11056",
    "pdf_url": "http://arxiv.org/pdf/2407.20700v1",
    "published_date": "2024-07-30 09:53:55 UTC",
    "updated_date": "2024-07-30 09:53:55 UTC"
  },
  {
    "arxiv_id": "2407.20693v1",
    "title": "Boosting Audio Visual Question Answering via Key Semantic-Aware Cues",
    "authors": [
      "Guangyao Li",
      "Henghui Du",
      "Di Hu"
    ],
    "abstract": "The Audio Visual Question Answering (AVQA) task aims to answer questions\nrelated to various visual objects, sounds, and their interactions in videos.\nSuch naturally multimodal videos contain rich and complex dynamic audio-visual\ncomponents, with only a portion of them closely related to the given questions.\nHence, effectively perceiving audio-visual cues relevant to the given questions\nis crucial for correctly answering them. In this paper, we propose a\nTemporal-Spatial Perception Model (TSPM), which aims to empower the model to\nperceive key visual and auditory cues related to the questions. Specifically,\nconsidering the challenge of aligning non-declarative questions and visual\nrepresentations into the same semantic space using visual-language pretrained\nmodels, we construct declarative sentence prompts derived from the question\ntemplate, to assist the temporal perception module in better identifying\ncritical segments relevant to the questions. Subsequently, a spatial perception\nmodule is designed to merge visual tokens from selected segments to highlight\nkey latent targets, followed by cross-modal interaction with audio to perceive\npotential sound-aware areas. Finally, the significant temporal-spatial cues\nfrom these modules are integrated to answer the question. Extensive experiments\non multiple AVQA benchmarks demonstrate that our framework excels not only in\nunderstanding audio-visual scenes but also in answering complex questions\neffectively. Code is available at https://github.com/GeWu-Lab/TSPM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.20693v1",
    "published_date": "2024-07-30 09:41:37 UTC",
    "updated_date": "2024-07-30 09:41:37 UTC"
  },
  {
    "arxiv_id": "2407.20684v1",
    "title": "RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer Recommendation",
    "authors": [
      "Weibin Liao",
      "Yifan Zhu",
      "Yanyan Li",
      "Qi Zhang",
      "Zhonghong Ou",
      "Xuesong Li"
    ],
    "abstract": "Acquiring reviewers for academic submissions is a challenging recommendation\nscenario. Recent graph learning-driven models have made remarkable progress in\nthe field of recommendation, but their performance in the academic reviewer\nrecommendation task may suffer from a significant false negative issue. This\narises from the assumption that unobserved edges represent negative samples. In\nfact, the mechanism of anonymous review results in inadequate exposure of\ninteractions between reviewers and submissions, leading to a higher number of\nunobserved interactions compared to those caused by reviewers declining to\nparticipate. Therefore, investigating how to better comprehend the negative\nlabeling of unobserved interactions in academic reviewer recommendations is a\nsignificant challenge. This study aims to tackle the ambiguous nature of\nunobserved interactions in academic reviewer recommendations. Specifically, we\npropose an unsupervised Pseudo Neg-Label strategy to enhance graph contrastive\nlearning (GCL) for recommending reviewers for academic submissions, which we\ncall RevGNN. RevGNN utilizes a two-stage encoder structure that encodes both\nscientific knowledge and behavior using Pseudo Neg-Label to approximate review\npreference. Extensive experiments on three real-world datasets demonstrate that\nRevGNN outperforms all baselines across four metrics. Additionally, detailed\nfurther analyses confirm the effectiveness of each component in RevGNN.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by ACM Transactions on Information Systems (TOIS)",
    "pdf_url": "http://arxiv.org/pdf/2407.20684v1",
    "published_date": "2024-07-30 09:25:40 UTC",
    "updated_date": "2024-07-30 09:25:40 UTC"
  },
  {
    "arxiv_id": "2407.20673v1",
    "title": "Label-Guided Prompt for Multi-label Few-shot Aspect Category Detection",
    "authors": [
      "ChaoFeng Guan",
      "YaoHui Zhu",
      "Yu Bai",
      "LingYun Wang"
    ],
    "abstract": "Multi-label few-shot aspect category detection aims at identifying multiple\naspect categories from sentences with a limited number of training instances.\nThe representation of sentences and categories is a key issue in this task.\nMost of current methods extract keywords for the sentence representations and\nthe category representations. Sentences often contain many category-independent\nwords, which leads to suboptimal performance of keyword-based methods. Instead\nof directly extracting keywords, we propose a label-guided prompt method to\nrepresent sentences and categories. To be specific, we design label-specific\nprompts to represent sentences by combining crucial contextual and semantic\ninformation. Further, the label is introduced into a prompt to obtain category\ndescriptions by utilizing a large language model. This kind of category\ndescriptions contain the characteristics of the aspect categories, guiding the\nconstruction of discriminative category prototypes. Experimental results on two\npublic datasets show that our method outperforms current state-of-the-art\nmethods with a 3.86% - 4.75% improvement in the Macro-F1 score.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20673v1",
    "published_date": "2024-07-30 09:11:17 UTC",
    "updated_date": "2024-07-30 09:11:17 UTC"
  },
  {
    "arxiv_id": "2408.07295v3",
    "title": "Learning Multi-Modal Whole-Body Control for Real-World Humanoid Robots",
    "authors": [
      "Pranay Dugar",
      "Aayam Shrestha",
      "Fangzhou Yu",
      "Bart van Marum",
      "Alan Fern"
    ],
    "abstract": "The foundational capabilities of humanoid robots should include robustly\nstanding, walking, and mimicry of whole and partial-body motions. This work\nintroduces the Masked Humanoid Controller (MHC), which supports all of these\ncapabilities by tracking target trajectories over selected subsets of humanoid\nstate variables while ensuring balance and robustness against disturbances. The\nMHC is trained in simulation using a carefully designed curriculum that\nimitates partially masked motions from a library of behaviors spanning\nstanding, walking, optimized reference trajectories, re-targeted video clips,\nand human motion capture data. It also allows for combining joystick-based\ncontrol with partial-body motion mimicry. We showcase simulation experiments\nvalidating the MHC's ability to execute a wide variety of behaviors from\npartially-specified target motions. Moreover, we demonstrate sim-to-real\ntransfer on the real-world Digit V3 humanoid robot. To our knowledge, this is\nthe first instance of a learned controller that can realize whole-body control\nof a real-world humanoid for such diverse multi-modal targets.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Website: https://masked-humanoid.github.io/mhc/",
    "pdf_url": "http://arxiv.org/pdf/2408.07295v3",
    "published_date": "2024-07-30 09:10:24 UTC",
    "updated_date": "2025-02-28 18:05:33 UTC"
  },
  {
    "arxiv_id": "2407.20669v2",
    "title": "A Tutorial on the Use of Physics-Informed Neural Networks to Compute the Spectrum of Quantum Systems",
    "authors": [
      "Lorenzo Brevi",
      "Antonio Mandarino",
      "Enrico Prati"
    ],
    "abstract": "Quantum many-body systems are of great interest for many research areas,\nincluding physics, biology and chemistry. However, their simulation is\nextremely challenging, due to the exponential growth of the Hilbert space with\nthe system size, making it exceedingly difficult to parameterize the wave\nfunctions of large systems by using exact methods. Neural networks and machine\nlearning in general are a way to face this challenge. For instance, methods\nlike Tensor networks and Neural Quantum States are being investigated as\npromising tools to obtain the wave function of a quantum mechanical system. In\nthis tutorial, we focus on a particularly promising class of deep learning\nalgorithms. We explain how to construct a Physics-Informed Neural Network\n(PINN) able to solve the Schr\\\"odinger equation for a given potential, by\nfinding its eigenvalues and eigenfunctions. This technique is unsupervised, and\nutilizes a novel computational method in a manner that is barely explored.\nPINNs are a deep learning method that exploits Automatic Differentiation to\nsolve Integro-Differential Equations in a mesh-free way. We show how to find\nboth the ground and the excited states. The method discovers the states\nprogressively by starting from the ground state. We explain how to introduce\ninductive biases in the loss to exploit further knowledge of the physical\nsystem. Such additional constraints allow for a faster and more accurate\nconvergence. This technique can then be enhanced by a smart choice of\ncollocation points in order to take advantage of the mesh-free nature of the\nPINN. The methods are made explicit by applying them to the infinite potential\nwell and the particle in a ring, a challenging problem to be learned by an\nArtificial Intelligence agent due to the presence of complex-valued\neigenfunctions and degenerate states.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "18 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.20669v2",
    "published_date": "2024-07-30 09:07:03 UTC",
    "updated_date": "2024-09-11 11:08:12 UTC"
  },
  {
    "arxiv_id": "2407.20668v1",
    "title": "Mimicking the Mavens: Agent-based Opinion Synthesis and Emotion Prediction for Social Media Influencers",
    "authors": [
      "Qinglan Wei",
      "Ruiqi Xue",
      "Yutian Wang",
      "Hongjiang Xiao",
      "Yuhao Wang",
      "Xiaoyan Duan"
    ],
    "abstract": "Predicting influencers' views and public sentiment on social media is crucial\nfor anticipating societal trends and guiding strategic responses. This study\nintroduces a novel computational framework to predict opinion leaders'\nperspectives and the emotive reactions of the populace, addressing the inherent\nchallenges posed by the unstructured, context-sensitive, and heterogeneous\nnature of online communication. Our research introduces an innovative module\nthat starts with the automatic 5W1H (Where, Who, When, What, Why, and How)\nquestions formulation engine, tailored to emerging news stories and trending\ntopics. We then build a total of 60 anonymous opinion leader agents in six\ndomains and realize the views generation based on an enhanced large language\nmodel (LLM) coupled with retrieval-augmented generation (RAG). Subsequently, we\nsynthesize the potential views of opinion leaders and predicted the emotional\nresponses to different events. The efficacy of our automated 5W1H module is\ncorroborated by an average GPT-4 score of 8.83/10, indicative of high fidelity.\nThe influencer agents exhibit a consistent performance, achieving an average\nGPT-4 rating of 6.85/10 across evaluative metrics. Utilizing the\n'Russia-Ukraine War' as a case study, our methodology accurately foresees key\ninfluencers' perspectives and aligns emotional predictions with real-world\nsentiment trends in various domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Upon acceptance of the article by IEEE, the preprint article must be\n  replaced with the accepted version, as described in the section 'Accepted\n  article.'",
    "pdf_url": "http://arxiv.org/pdf/2407.20668v1",
    "published_date": "2024-07-30 09:04:45 UTC",
    "updated_date": "2024-07-30 09:04:45 UTC"
  },
  {
    "arxiv_id": "2407.20667v1",
    "title": "Rethinking the Function of Neurons in KANs",
    "authors": [
      "Mohammed Ghaith Altarabichi"
    ],
    "abstract": "The neurons of Kolmogorov-Arnold Networks (KANs) perform a simple summation\nmotivated by the Kolmogorov-Arnold representation theorem, which asserts that\nsum is the only fundamental multivariate function. In this work, we investigate\nthe potential for identifying an alternative multivariate function for KAN\nneurons that may offer increased practical utility. Our empirical research\ninvolves testing various multivariate functions in KAN neurons across a range\nof benchmark Machine Learning tasks.\n  Our findings indicate that substituting the sum with the average function in\nKAN neurons results in significant performance enhancements compared to\ntraditional KANs. Our study demonstrates that this minor modification\ncontributes to the stability of training by confining the input to the spline\nwithin the effective range of the activation function. Our implementation and\nexperiments are available at: \\url{https://github.com/Ghaith81/dropkan}",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20667v1",
    "published_date": "2024-07-30 09:04:23 UTC",
    "updated_date": "2024-07-30 09:04:23 UTC"
  },
  {
    "arxiv_id": "2407.20657v2",
    "title": "Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks",
    "authors": [
      "Hunmin Yang",
      "Jongoh Jeong",
      "Kuk-Jin Yoon"
    ],
    "abstract": "Recent vision-language foundation models, such as CLIP, have demonstrated\nsuperior capabilities in learning representations that can be transferable\nacross diverse range of downstream tasks and domains. With the emergence of\nsuch powerful models, it has become crucial to effectively leverage their\ncapabilities in tackling challenging vision tasks. On the other hand, only a\nfew works have focused on devising adversarial examples that transfer well to\nboth unknown domains and model architectures. In this paper, we propose a novel\ntransfer attack method called PDCL-Attack, which leverages the CLIP model to\nenhance the transferability of adversarial perturbations generated by a\ngenerative model-based attack framework. Specifically, we formulate an\neffective prompt-driven feature guidance by harnessing the semantic\nrepresentation power of text, particularly from the ground-truth class labels\nof input images. To the best of our knowledge, we are the first to introduce\nprompt learning to enhance the transferable generative attacks. Extensive\nexperiments conducted across various cross-domain and cross-model settings\nempirically validate our approach, demonstrating its superiority over\nstate-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV 2024 (Oral), Project Page:\n  https://PDCL-Attack.github.io",
    "pdf_url": "http://arxiv.org/pdf/2407.20657v2",
    "published_date": "2024-07-30 08:52:16 UTC",
    "updated_date": "2025-03-13 06:16:16 UTC"
  },
  {
    "arxiv_id": "2407.20654v1",
    "title": "Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian",
    "authors": [
      "Serena Auriemma",
      "Martina Miliani",
      "Mauro Madeddu",
      "Alessandro Bondielli",
      "Lucia Passaro",
      "Alessandro Lenci"
    ],
    "abstract": "Addressing the challenge of limited annotated data in specialized fields and\nlow-resource languages is crucial for the effective use of Language Models\n(LMs). While most Large Language Models (LLMs) are trained on general-purpose\nEnglish corpora, there is a notable gap in models specifically tailored for\nItalian, particularly for technical and bureaucratic jargon. This paper\nexplores the feasibility of employing smaller, domain-specific encoder LMs\nalongside prompting techniques to enhance performance in these specialized\ncontexts. Our study concentrates on the Italian bureaucratic and legal\nlanguage, experimenting with both general-purpose and further pre-trained\nencoder-only models. We evaluated the models on downstream tasks such as\ndocument classification and entity typing and conducted intrinsic evaluations\nusing Pseudo-Log-Likelihood. The results indicate that while further\npre-trained models may show diminished robustness in general knowledge, they\nexhibit superior adaptability for domain-specific tasks, even in a zero-shot\nsetting. Furthermore, the application of calibration techniques and in-domain\nverbalizers significantly enhances the efficacy of encoder models. These\ndomain-specialized models prove to be particularly advantageous in scenarios\nwhere in-domain resources or expertise are scarce. In conclusion, our findings\noffer new insights into the use of Italian models in specialized contexts,\nwhich may have a significant impact on both research and industrial\napplications in the digital transformation era.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50, 68T07",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to 'Language Resource and Evaluation'",
    "pdf_url": "http://arxiv.org/pdf/2407.20654v1",
    "published_date": "2024-07-30 08:50:16 UTC",
    "updated_date": "2024-07-30 08:50:16 UTC"
  },
  {
    "arxiv_id": "2407.20653v1",
    "title": "FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks",
    "authors": [
      "Hunmin Yang",
      "Jongoh Jeong",
      "Kuk-Jin Yoon"
    ],
    "abstract": "Deep neural networks are known to be vulnerable to security risks due to the\ninherent transferable nature of adversarial examples. Despite the success of\nrecent generative model-based attacks demonstrating strong transferability, it\nstill remains a challenge to design an efficient attack strategy in a\nreal-world strict black-box setting, where both the target domain and model\narchitectures are unknown. In this paper, we seek to explore a feature\ncontrastive approach in the frequency domain to generate adversarial examples\nthat are robust in both cross-domain and cross-model settings. With that goal\nin mind, we propose two modules that are only employed during the training\nphase: a Frequency-Aware Domain Randomization (FADR) module to randomize\ndomain-variant low- and high-range frequency components and a\nFrequency-Augmented Contrastive Learning (FACL) module to effectively separate\ndomain-invariant mid-frequency features of clean and perturbed image. We\ndemonstrate strong transferability of our generated adversarial perturbations\nthrough extensive cross-domain and cross-model experiments, while keeping the\ninference time complexity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI 2024, Project Page: https://FACL-Attack.github.io",
    "pdf_url": "http://arxiv.org/pdf/2407.20653v1",
    "published_date": "2024-07-30 08:50:06 UTC",
    "updated_date": "2024-07-30 08:50:06 UTC"
  },
  {
    "arxiv_id": "2407.20650v1",
    "title": "No learning rates needed: Introducing SALSA -- Stable Armijo Line Search Adaptation",
    "authors": [
      "Philip Kenneweg",
      "Tristan Kenneweg",
      "Fabian Fumagalli",
      "Barbara Hammer"
    ],
    "abstract": "In recent studies, line search methods have been demonstrated to\nsignificantly enhance the performance of conventional stochastic gradient\ndescent techniques across various datasets and architectures, while making an\notherwise critical choice of learning rate schedule superfluous. In this paper,\nwe identify problems of current state-of-the-art of line search methods,\npropose enhancements, and rigorously assess their effectiveness. Furthermore,\nwe evaluate these methods on orders of magnitude larger datasets and more\ncomplex data domains than previously done. More specifically, we enhance the\nArmijo line search method by speeding up its computation and incorporating a\nmomentum term into the Armijo criterion, making it better suited for stochastic\nmini-batching. Our optimization approach outperforms both the previous Armijo\nimplementation and a tuned learning rate schedule for the Adam and SGD\noptimizers. Our evaluation covers a diverse range of architectures, such as\nTransformers, CNNs, and MLPs, as well as data domains, including NLP and image\ndata.\n  Our work is publicly available as a Python package, which provides a simple\nPytorch optimizer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "published in IJCNN 2024. arXiv admin note: text overlap with\n  arXiv:2403.18519",
    "pdf_url": "http://arxiv.org/pdf/2407.20650v1",
    "published_date": "2024-07-30 08:47:02 UTC",
    "updated_date": "2024-07-30 08:47:02 UTC"
  },
  {
    "arxiv_id": "2407.20648v2",
    "title": "Leveraging Multi-facet Paths for Heterogeneous Graph Representation Learning",
    "authors": [
      "JongWoo Kim",
      "SeongYeub Chu",
      "HyeongMin Park",
      "Bryan Wong",
      "MunYong Yi"
    ],
    "abstract": "Recent advancements in graph neural networks (GNNs) and heterogeneous GNNs\n(HGNNs) have advanced node embeddings and relationship learning for various\ntasks. However, existing methods often rely on domain-specific predefined\nmeta-paths, which are coarse-grained and focus solely on aspects like node\ntype, limiting their ability to capture complex interactions. We introduce\nMF2Vec, a model that uses multi-faceted (fine-grained) paths instead of\npredefined meta-paths. MF2Vec extracts paths via random walks and generates\nmulti-faceted vectors, ignoring predefined schemas. This method learns diverse\naspects of nodes and their relationships, constructs a homogeneous network, and\ncreates node embeddings for classification, link prediction, and clustering.\nExtensive experiments show that MF2Vec outperforms existing methods, offering a\nmore flexible and comprehensive framework for analyzing complex networks. The\ncode is available at https://anonymous.4open.science/r/MF2Vec-6ABC.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20648v2",
    "published_date": "2024-07-30 08:45:32 UTC",
    "updated_date": "2025-02-03 14:26:04 UTC"
  },
  {
    "arxiv_id": "2407.20635v2",
    "title": "Autonomous Improvement of Instruction Following Skills via Foundation Models",
    "authors": [
      "Zhiyuan Zhou",
      "Pranav Atreya",
      "Abraham Lee",
      "Homer Walke",
      "Oier Mees",
      "Sergey Levine"
    ],
    "abstract": "Intelligent instruction-following robots capable of improving from\nautonomously collected experience have the potential to transform robot\nlearning: instead of collecting costly teleoperated demonstration data,\nlarge-scale deployment of fleets of robots can quickly collect larger\nquantities of autonomous data that can collectively improve their performance.\nHowever, autonomous improvement requires solving two key problems: (i) fully\nautomating a scalable data collection procedure that can collect diverse and\nsemantically meaningful robot data and (ii) learning from non-optimal,\nautonomous data with no human annotations. To this end, we propose a novel\napproach that addresses these challenges, allowing instruction-following\npolicies to improve from autonomously collected data without human supervision.\nOur framework leverages vision-language models to collect and evaluate\nsemantically meaningful experiences in new environments, and then utilizes a\ndecomposition of instruction following tasks into (semantic)\nlanguage-conditioned image generation and (non-semantic) goal reaching, which\nmakes it significantly more practical to improve from this autonomously\ncollected data without any human annotations. We carry out extensive\nexperiments in the real world to demonstrate the effectiveness of our approach,\nand find that in a suite of unseen environments, the robot policy can be\nimproved 2x with autonomously collected data. We open-source the code for our\nsemantic autonomous improvement pipeline, as well as our autonomous dataset of\n30.5K trajectories collected across five tabletop environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "2024 Conference on Robot Learning (CoRL)",
    "pdf_url": "http://arxiv.org/pdf/2407.20635v2",
    "published_date": "2024-07-30 08:26:44 UTC",
    "updated_date": "2024-10-15 17:54:17 UTC"
  },
  {
    "arxiv_id": "2407.20584v3",
    "title": "Pruning Large Language Models with Semi-Structural Adaptive Sparse Training",
    "authors": [
      "Weiyu Huang",
      "Yuezhou Hu",
      "Guohao Jian",
      "Jun Zhu",
      "Jianfei Chen"
    ],
    "abstract": "The remarkable success of Large Language Models (LLMs) relies heavily on\ntheir substantial scale, which poses significant challenges during model\ndeployment in terms of latency and memory consumption. Recently, numerous\nstudies have attempted to compress LLMs using one-shot pruning methods.\nHowever, these methods often suffer from considerable performance degradation\non complex language understanding tasks, raising concerns about the feasibility\nof pruning in LLMs. To address this issue, we propose Adaptive Sparse Trainer\n(AST), a novel and efficient retraining framework tailored for semi-structured\nsparse models. AST enables models to learn optimal masks during the weight\nupdate process without incurring additional computational overhead.\nFurthermore, we demonstrate that incorporating knowledge distillation\nsignificantly improves retraining efficiency and enhances model performance\nunder fixed computational constraints. Additionally, a supplementary set of\nwell-initialized parameters is integrated to further augment the model's\nefficacy. AST achieves state-of-the-art performance with minimal training cost.\nWhen applied to the LLaMA2-7B model, AST reduces the perplexity and zero-shot\naccuracy gap between dense and 2:4 semi-structured sparse models to 0.6 and\n1.16%, respectively, utilizing less than 0.4% of the pretraining tokens and GPU\nhours. Our work demonstrates the feasibility of deploying semi-structured\nsparse LLMs and offers a promising alternative for achieving highly compressed\nmodels when combined with existing quantization techniques.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2407.20584v3",
    "published_date": "2024-07-30 06:33:44 UTC",
    "updated_date": "2024-12-18 07:14:33 UTC"
  },
  {
    "arxiv_id": "2407.20582v1",
    "title": "Image-based Detection of Segment Misalignment in Multi-mirror Satellites using Transfer Learning",
    "authors": [
      "C. Tanner Fredieu",
      "Jonathan Tesch",
      "Andrew Kee",
      "David Redding"
    ],
    "abstract": "In this paper, we introduce a system based on transfer learning for detecting\nsegment misalignment in multimirror satellites, such as future CubeSat designs\nand the James Webb Space Telescope (JWST), using image-based methods. When a\nmirror segment becomes misaligned due to various environmental factors, such as\nspace debris, the images can become distorted with a shifted copy of itself\ncalled a \"ghost image\". To detect whether segments are misaligned, we use\npre-trained, large-scale image models trained on the Fast Fourier Transform\n(FFT) of patches of satellite images in grayscale. Multi-mirror designs can use\nany arbitrary number of mirrors. For our purposes, the tests were performed on\nsimulated CubeSats with 4, 6, and 8 segments. For system design, we took this\ninto account when we want to know when a satellite has a misaligned segment and\nhow many segments are misaligned. The intensity of the ghost image is directly\nproportional to the number of segments misaligned. Models trained for intensity\nclassification attempted to classify N-1 segments. Across eight classes, binary\nmodels were able to achieve a classification accuracy of 98.75%, and models for\nintensity classification were able to achieve an accuracy of 98.05%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20582v1",
    "published_date": "2024-07-30 06:29:40 UTC",
    "updated_date": "2024-07-30 06:29:40 UTC"
  },
  {
    "arxiv_id": "2407.20578v2",
    "title": "Comparison of Large Language Models for Generating Contextually Relevant Questions",
    "authors": [
      "Ivo Lodovico Molina",
      "Valdemar ≈†v√°bensk√Ω",
      "Tsubasa Minematsu",
      "Li Chen",
      "Fumiya Okubo",
      "Atsushi Shimada"
    ],
    "abstract": "This study explores the effectiveness of Large Language Models (LLMs) for\nAutomatic Question Generation in educational settings. Three LLMs are compared\nin their ability to create questions from university slide text without\nfine-tuning. Questions were obtained in a two-step pipeline: first, answer\nphrases were extracted from slides using Llama 2-Chat 13B; then, the three\nmodels generated questions for each answer. To analyze whether the questions\nwould be suitable in educational applications for students, a survey was\nconducted with 46 students who evaluated a total of 246 questions across five\nmetrics: clarity, relevance, difficulty, slide relation, and question-answer\nalignment. Results indicate that GPT-3.5 and Llama 2-Chat 13B outperform Flan\nT5 XXL by a small margin, particularly in terms of clarity and question-answer\nalignment. GPT-3.5 especially excels at tailoring questions to match the input\nanswers. The contribution of this research is the analysis of the capacity of\nLLMs for Automatic Question Generation in education.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "K.3"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in Springer ECTEL 2024 conference proceedings, see\n  https://doi.org/10.1007/978-3-031-72312-4_18",
    "pdf_url": "http://arxiv.org/pdf/2407.20578v2",
    "published_date": "2024-07-30 06:23:59 UTC",
    "updated_date": "2024-09-15 07:23:10 UTC"
  },
  {
    "arxiv_id": "2407.20563v1",
    "title": "Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering",
    "authors": [
      "Ruoyue Shen",
      "Nakamasa Inoue",
      "Koichi Shinoda"
    ],
    "abstract": "Visual question answering (VQA) is the task of providing accurate answers to\nnatural language questions based on visual input. Programmatic VQA (PVQA)\nmodels have been gaining attention recently. These use large language models\n(LLMs) to formulate executable programs that address questions requiring\ncomplex visual reasoning. However, there are challenges in enabling LLMs to\ncomprehend the usage of image processing modules and generate relevant code. To\novercome these challenges, this paper introduces PyramidCoder, a novel\nprompting framework for PVQA models. PyramidCoder consists of three\nhierarchical levels, each serving a distinct purpose: query rephrasing, code\ngeneration, and answer aggregation. Notably, PyramidCoder utilizes a single\nfrozen LLM and pre-defined prompts at each level, eliminating the need for\nadditional training and ensuring flexibility across various LLM architectures.\nCompared to the state-of-the-art PVQA model, our approach improves accuracy by\nat least 0.5% on the GQA dataset, 1.4% on the VQAv2 dataset, and 2.9% on the\nNLVR2 dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the IEEE International Conference on Image Processing\n  (IEEE ICIP) 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.20563v1",
    "published_date": "2024-07-30 05:36:43 UTC",
    "updated_date": "2024-07-30 05:36:43 UTC"
  },
  {
    "arxiv_id": "2407.20519v1",
    "title": "DuA: Dual Attentive Transformer in Long-Term Continuous EEG Emotion Analysis",
    "authors": [
      "Yue Pan",
      "Qile Liu",
      "Qing Liu",
      "Li Zhang",
      "Gan Huang",
      "Xin Chen",
      "Fali Li",
      "Peng Xu",
      "Zhen Liang"
    ],
    "abstract": "Affective brain-computer interfaces (aBCIs) are increasingly recognized for\ntheir potential in monitoring and interpreting emotional states through\nelectroencephalography (EEG) signals. Current EEG-based emotion recognition\nmethods perform well with short segments of EEG data. However, these methods\nencounter significant challenges in real-life scenarios where emotional states\nevolve over extended periods. To address this issue, we propose a Dual\nAttentive (DuA) transformer framework for long-term continuous EEG emotion\nanalysis. Unlike segment-based approaches, the DuA transformer processes an\nentire EEG trial as a whole, identifying emotions at the trial level, referred\nto as trial-based emotion analysis. This framework is designed to adapt to\nvarying signal lengths, providing a substantial advantage over traditional\nmethods. The DuA transformer incorporates three key modules: the\nspatial-spectral network module, the temporal network module, and the transfer\nlearning module. The spatial-spectral network module simultaneously captures\nspatial and spectral information from EEG signals, while the temporal network\nmodule detects temporal dependencies within long-term EEG data. The transfer\nlearning module enhances the model's adaptability across different subjects and\nconditions. We extensively evaluate the DuA transformer using a\nself-constructed long-term EEG emotion database, along with two benchmark EEG\nemotion databases. On the basis of the trial-based leave-one-subject-out\ncross-subject cross-validation protocol, our experimental results demonstrate\nthat the proposed DuA transformer significantly outperforms existing methods in\nlong-term continuous EEG emotion analysis, with an average enhancement of\n5.28%.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.20519v1",
    "published_date": "2024-07-30 03:31:03 UTC",
    "updated_date": "2024-07-30 03:31:03 UTC"
  },
  {
    "arxiv_id": "2407.20518v1",
    "title": "High-Resolution Spatial Transcriptomics from Histology Images using HisToSGE",
    "authors": [
      "Zhiceng Shi",
      "Shuailin Xue",
      "Fangfang Zhu",
      "Wenwen Min"
    ],
    "abstract": "Spatial transcriptomics (ST) is a groundbreaking genomic technology that\nenables spatial localization analysis of gene expression within tissue\nsections. However, it is significantly limited by high costs and sparse spatial\nresolution. An alternative, more cost-effective strategy is to use deep\nlearning methods to predict high-density gene expression profiles from\nhistological images. However, existing methods struggle to capture rich image\nfeatures effectively or rely on low-dimensional positional coordinates, making\nit difficult to accurately predict high-resolution gene expression profiles. To\naddress these limitations, we developed HisToSGE, a method that employs a\nPathology Image Large Model (PILM) to extract rich image features from\nhistological images and utilizes a feature learning module to robustly generate\nhigh-resolution gene expression profiles. We evaluated HisToSGE on four ST\ndatasets, comparing its performance with five state-of-the-art baseline\nmethods. The results demonstrate that HisToSGE excels in generating\nhigh-resolution gene expression profiles and performing downstream tasks such\nas spatial domain identification. All code and public datasets used in this\npaper are available at https://github.com/wenwenmin/HisToSGE and\nhttps://zenodo.org/records/12792163.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20518v1",
    "published_date": "2024-07-30 03:29:57 UTC",
    "updated_date": "2024-07-30 03:29:57 UTC"
  },
  {
    "arxiv_id": "2407.20516v1",
    "title": "Machine Unlearning in Generative AI: A Survey",
    "authors": [
      "Zheyuan Liu",
      "Guangyao Dou",
      "Zhaoxuan Tan",
      "Yijun Tian",
      "Meng Jiang"
    ],
    "abstract": "Generative AI technologies have been deployed in many places, such as\n(multimodal) large language models and vision generative models. Their\nremarkable performance should be attributed to massive training data and\nemergent reasoning abilities. However, the models would memorize and generate\nsensitive, biased, or dangerous information originated from the training data\nespecially those from web crawl. New machine unlearning (MU) techniques are\nbeing developed to reduce or eliminate undesirable knowledge and its effects\nfrom the models, because those that were designed for traditional\nclassification tasks could not be applied for Generative AI. We offer a\ncomprehensive survey on many things about MU in Generative AI, such as a new\nproblem formulation, evaluation methods, and a structured discussion on the\nadvantages and limitations of different kinds of MU techniques. It also\npresents several critical challenges and promising directions in MU research. A\ncurated list of readings can be found:\nhttps://github.com/franciscoliu/GenAI-MU-Reading.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20516v1",
    "published_date": "2024-07-30 03:26:09 UTC",
    "updated_date": "2024-07-30 03:26:09 UTC"
  },
  {
    "arxiv_id": "2407.20515v1",
    "title": "Markers Identification for Relative Pose Estimation of an Uncooperative Target",
    "authors": [
      "Batu Candan",
      "Simone Servadio"
    ],
    "abstract": "This paper introduces a novel method using chaser spacecraft image processing\nand Convolutional Neural Networks (CNNs) to detect structural markers on the\nEuropean Space Agency's (ESA) Environmental Satellite (ENVISAT) for safe\nde-orbiting. Advanced image pre-processing techniques, including noise addition\nand blurring, are employed to improve marker detection accuracy and robustness.\nInitial results show promising potential for autonomous space debris removal,\nsupporting proactive strategies for space sustainability. The effectiveness of\nour approach suggests that our estimation method could significantly enhance\nthe safety and efficiency of debris removal operations by implementing more\nrobust and autonomous systems in actual space missions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "2024 AAS/AIAA Astrodynamics Specialist Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.20515v1",
    "published_date": "2024-07-30 03:20:54 UTC",
    "updated_date": "2024-07-30 03:20:54 UTC"
  },
  {
    "arxiv_id": "2407.20513v1",
    "title": "Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language",
    "authors": [
      "Hossein Rajaby Faghihi",
      "Aliakbar Nafar",
      "Andrzej Uszok",
      "Hamid Karimian",
      "Parisa Kordjamshidi"
    ],
    "abstract": "This paper presents a conversational pipeline for crafting domain knowledge\nfor complex neuro-symbolic models through natural language prompts. It\nleverages large language models to generate declarative programs in the\nDomiKnowS framework. The programs in this framework express concepts and their\nrelationships as a graph in addition to logical constraints between them. The\ngraph, later, can be connected to trainable neural models according to those\nspecifications. Our proposed pipeline utilizes techniques like dynamic\nin-context demonstration retrieval, model refinement based on feedback from a\nsymbolic parser, visualization, and user interaction to generate the tasks'\nstructure and formal knowledge representation. This approach empowers domain\nexperts, even those not well-versed in ML/AI, to formally declare their\nknowledge to be incorporated in customized neural models in the DomiKnowS\nframework.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in NeSy 2024 Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.20513v1",
    "published_date": "2024-07-30 03:10:30 UTC",
    "updated_date": "2024-07-30 03:10:30 UTC"
  },
  {
    "arxiv_id": "2407.20508v1",
    "title": "Unveiling the Potential of Spiking Dynamics in Graph Representation Learning through Spatial-Temporal Normalization and Coding Strategies",
    "authors": [
      "Mingkun Xu",
      "Huifeng Yin",
      "Yujie Wu",
      "Guoqi Li",
      "Faqiang Liu",
      "Jing Pei",
      "Shuai Zhong",
      "Lei Deng"
    ],
    "abstract": "In recent years, spiking neural networks (SNNs) have attracted substantial\ninterest due to their potential to replicate the energy-efficient and\nevent-driven processing of biological neurons. Despite this, the application of\nSNNs in graph representation learning, particularly for non-Euclidean data,\nremains underexplored, and the influence of spiking dynamics on graph learning\nis not yet fully understood. This work seeks to address these gaps by examining\nthe unique properties and benefits of spiking dynamics in enhancing graph\nrepresentation learning. We propose a spike-based graph neural network model\nthat incorporates spiking dynamics, enhanced by a novel spatial-temporal\nfeature normalization (STFN) technique, to improve training efficiency and\nmodel stability. Our detailed analysis explores the impact of rate coding and\ntemporal coding on SNN performance, offering new insights into their advantages\nfor deep graph networks and addressing challenges such as the oversmoothing\nproblem. Experimental results demonstrate that our SNN models can achieve\ncompetitive performance with state-of-the-art graph neural networks (GNNs)\nwhile considerably reducing computational costs, highlighting the potential of\nSNNs for efficient neuromorphic computing applications in complex graph-based\nscenarios.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20508v1",
    "published_date": "2024-07-30 02:53:26 UTC",
    "updated_date": "2024-07-30 02:53:26 UTC"
  },
  {
    "arxiv_id": "2407.20506v1",
    "title": "Boosting Efficiency in Task-Agnostic Exploration through Causal Knowledge",
    "authors": [
      "Yupei Yang",
      "Biwei Huang",
      "Shikui Tu",
      "Lei Xu"
    ],
    "abstract": "The effectiveness of model training heavily relies on the quality of\navailable training resources. However, budget constraints often impose\nlimitations on data collection efforts. To tackle this challenge, we introduce\ncausal exploration in this paper, a strategy that leverages the underlying\ncausal knowledge for both data collection and model training. We, in\nparticular, focus on enhancing the sample efficiency and reliability of the\nworld model learning within the domain of task-agnostic reinforcement learning.\nDuring the exploration phase, the agent actively selects actions expected to\nyield causal insights most beneficial for world model training. Concurrently,\nthe causal knowledge is acquired and incrementally refined with the ongoing\ncollection of data. We demonstrate that causal exploration aids in learning\naccurate world models using fewer data and provide theoretical guarantees for\nits convergence. Empirical experiments, on both synthetic data and real-world\napplications, further validate the benefits of causal exploration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper was accepted by IJCAI'24",
    "pdf_url": "http://arxiv.org/pdf/2407.20506v1",
    "published_date": "2024-07-30 02:51:21 UTC",
    "updated_date": "2024-07-30 02:51:21 UTC"
  },
  {
    "arxiv_id": "2407.20503v1",
    "title": "A federated large language model for long-term time series forecasting",
    "authors": [
      "Raed Abdel-Sater",
      "A. Ben Hamza"
    ],
    "abstract": "Long-term time series forecasting in centralized environments poses unique\nchallenges regarding data privacy, communication overhead, and scalability. To\naddress these challenges, we propose FedTime, a federated large language model\n(LLM) tailored for long-range time series prediction. Specifically, we\nintroduce a federated pre-trained LLM with fine-tuning and alignment\nstrategies. Prior to the learning process, we employ K-means clustering to\npartition edge devices or clients into distinct clusters, thereby facilitating\nmore focused model training. We also incorporate channel independence and\npatching to better preserve local semantic information, ensuring that important\ncontextual details are retained while minimizing the risk of information loss.\nWe demonstrate the effectiveness of our FedTime model through extensive\nexperiments on various real-world forecasting benchmarks, showcasing\nsubstantial improvements over recent approaches. In addition, we demonstrate\nthe efficiency of FedTime in streamlining resource usage, resulting in reduced\ncommunication overhead.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20503v1",
    "published_date": "2024-07-30 02:38:27 UTC",
    "updated_date": "2024-07-30 02:38:27 UTC"
  },
  {
    "arxiv_id": "2407.20496v1",
    "title": "Toward Efficient Permutation for Hierarchical N:M Sparsity on GPUs",
    "authors": [
      "Seungmin Yu",
      "Xiaodie Yi",
      "Hayun Lee",
      "Dongkun Shin"
    ],
    "abstract": "N:M sparsity pruning is a powerful technique for compressing deep neural\nnetworks, utilizing NVIDIA's Sparse Tensor Core technology. This method\nbenefits from hardware support for sparse indexing, enabling the adoption of\nfine-grained sparsity to maintain model accuracy while minimizing the overhead\ntypically associated with irregular data access. Although restricted to a fixed\nlevel of sparsity due to its reliance on hardware, N:M sparsity can be combined\nwith coarser sparsity techniques to achieve diverse compression ratios.\nInitially, column-wise vector sparsity is applied to a dense model, followed by\nrow-wise N:M sparsity on the preserved column vectors. We call this multi-level\napproach as hierarchical N:M (HiNM) sparsity. Similar to earlier single-level\nsparsity techniques, HiNM sparsity necessitates an effective channel\npermutation strategy to maximize the accuracy of the compressed networks.\nHowever, it introduces further complexities by requiring the rearrangement of\nboth input and output channels, addressing challenges such as permutation\nsequence, HiNM-sparsity-aware permutation, and maintaining consistency in\nchannel ordering across layers. In this paper, we introduce a channel\npermutation method designed specifically for HiNM sparsity, named\ngyro-permutation. This method is crafted to exploit the unique characteristics\nof HiNM pruning, incorporating a strategic policy in each permutation phase,\nincluding channel sampling, clustering, and assignment, to circumvent local\nminima. Additionally, we have developed a GPU kernel that facilitates\nindependent layer permutation during the execution of HiNM sparse networks. Our\nextensive experimental evaluations on various DNN models demonstrate that our\ngyro-permutation significantly enhances the accuracy of HiNM sparse networks,\nallowing them to reach performance levels comparable to those of unstructured\nsparse networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.20496v1",
    "published_date": "2024-07-30 01:40:50 UTC",
    "updated_date": "2024-07-30 01:40:50 UTC"
  }
]