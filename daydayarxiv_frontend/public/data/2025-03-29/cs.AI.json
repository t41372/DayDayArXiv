{
  "date": "2025-03-29",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-29 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM（大型语言模型）安全与公平、多模态理解和知识图谱推理等领域。其中，令人印象深刻的是 Encrypted Prompt 提出的 LLM 防护机制、Aurelia 的多模态推理提升，以及 TransNet 在少样本知识图谱补全上的创新；知名学者如 Mohamed Elhoseiny 和 Hanghang Tong 参与的相关论文也值得关注，这些工作突出了 AI 在实际应用中的鲁棒性和伦理挑战。\n\n### 重点论文亮点\n以下挑选并讨论了今天更重要的论文，先从 LLM 安全与推理开始，再聊知识图谱和多模态领域，最后快速概述其他内容。每个条目简要概述核心贡献、方法和影响。\n\n- **Encrypted Prompt: Securing LLM Applications Against Unauthorized Actions**（中文：加密提示：保护 LLM 应用免受未授权操作）  \n  这篇论文由 Shih-Han Chan 提出，引入一种在用户提示中附加加密提示的方法来嵌入权限验证，从而防范提示注入攻击。主要贡献是通过权限检查确保 LLM 生成的 API 调用安全，避免未授权操作；实验显示此方法有效缓解了 LLM 在实际应用中的安全风险，具有重要伦理和实际部署价值。\n\n- **Aurelia: Test-time Reasoning Distillation in Audio-Visual LLMs**（中文：Aurelia：在音频-视觉 LLM 中的测试时推理蒸馏）  \n  作者包括 Mohamed Elhoseiny 和 Salman Khan，这篇论文提出一个 actor-critic 框架，用于在测试时为音频-视觉 LLM 提炼结构化推理。主要发现是通过无需额外训练的推理优化，提升了多模态任务的性能，并在新基准 AVReasonBench 上实现了高达 100% 的相对改进，展示了 LLM 在复杂场景中的潜力。\n\n- **TransNet: Transfer Knowledge for Few-shot Knowledge Graph Completion**（中文：TransNet：用于少样本知识图谱补全的知识转移）  \n  作者团队包括 Hanghang Tong，这篇工作开发了基于元学习的 TransNet 框架，用于少样本知识图谱补全。主要贡献是捕捉任务间相关性，通过知识转移提升新关系的预测准确性；实验在基准数据集上超越了现有方法，强调了知识图谱在实际应用中的可扩展性。\n\n- **Simulation of Non-Ordinary Consciousness**（中文：非普通意识的模拟）  \n  作者 Khalid M. Saqr 构建了 Glyph 接口，使用大型语言模型模拟迷幻剂诱导的认知状态。主要发现是通过递归隐喻和语义不稳定性，成功再现了非理性认知模式；这为 AI 在认知科学中的应用提供了新范式，并附有实验验证。\n\n- **Beyond speculation: Measuring the growing presence of LLM-generated texts in multilingual disinformation**（中文：超越推测：测量 LLM 生成文本在多语言虚假信息中的增长）  \n  这篇论文提供了 LLM 在虚假信息中的实证证据，主要通过分析多语言数据集发现 LLM 生成内容在平台上的增加趋势。贡献在于桥接学术争论，提供跨语言模式分析，提醒了 AI 在信息生态中的潜在风险。\n\n- **Evaluating how LLM annotations represent diverse views on contentious topics**（中文：评估 LLM 标注在争议性话题上的多样性表示）  \n  作者包括 Libby Hemphill，这篇工作评估了 LLM 在标注任务中的公平性，发现模型对不同人群观点的偏差较小，主要受提示和人类标注者影响。关键发现是 LLM 在争议性任务中更依赖一致性而非人口统计偏差，这为 AI 公平研究提供了新视角。\n\n- **RL2Grid: Benchmarking Reinforcement Learning in Power Grid Operations**（中文：RL2Grid：电力网格操作中的强化学习基准）  \n  这篇论文引入 RL2Grid 基准，用于评估强化学习在电力网格控制中的性能。主要贡献是整合真实操作约束，实验显示 RL 方法在动态电网中提升了鲁棒性，适用于能源领域的 AI 应用。\n\n- **KGC-ERC: Enhancing Knowledge Graph Completion with Entity Neighborhood and Relation Context**（中文：KGC-ERC：通过实体邻域和关系上下文增强知识图谱补全）  \n  作者包括 Qi Liu，这篇工作提出 KGC-ERC 框架，结合实体邻域和关系上下文优化语言模型的推理能力。主要发现是通过采样策略提升了预测性能，在 Wikidata5M 等数据集上超越基线，突出了知识图谱的实际扩展性。\n\n- **CCCI: Code Completion with Contextual Information for Complex Data Transfer Tasks Using Large Language Models**（中文：CCCI：使用大型语言模型的复杂数据传输任务中的上下文信息代码补全）  \n  这篇论文开发了 CCCI 方法，用于基于上下文的代码补全。主要贡献是整合数据库关系和对象模型，提高了代码生成准确性；实验在工业脚本上达到 49.1% 的构建通过率，适用于软件工程的 AI 辅助。\n\n- **Agent-Based Modeling and Deep Neural Networks for Establishing Digital Twins of Secure Facilities under Sensing Restrictions**（中文：基于代理建模和深度神经网络的受传感限制的安全设施数字孪生建立）  \n  这篇工作使用代理建模和神经网络创建数字孪生，用于安全设施模拟。主要发现是解决了数据采集限制问题，提升了紧急响应预测，适用于高安全领域的 AI 应用。\n\n其他论文包括一些次要主题，如代码生成（Synthetic Art Generation and DeepFake Detection）、机器人导航（Action Recognition in Real-World Ambient Assisted Living Environment）和模型优化（Towards Symmetric Low-Rank Adapters）。这些工作虽有贡献，如改进检测或效率，但影响力较小，仅快速提及以保持篇幅控制。今天 arXiv 整体展示了 AI 向实用性和伦理方向的进展，感兴趣的读者可关注 LLM 相关论文进行深入阅读。明天见！",
  "papers": [
    {
      "arxiv_id": "2503.23257v1",
      "title": "FIESTA: Fisher Information-based Efficient Selective Test-time Adaptation",
      "title_zh": "FIESTA: 基于 Fisher 信息的高效选择性测试时适应",
      "authors": [
        "Mohammadmahdi Honarmand",
        "Onur Cezmi Mutlu",
        "Parnian Azizian",
        "Saimourya Surabhi",
        "Dennis P. Wall"
      ],
      "abstract": "Robust facial expression recognition in unconstrained, \"in-the-wild\"\nenvironments remains challenging due to significant domain shifts between\ntraining and testing distributions. Test-time adaptation (TTA) offers a\npromising solution by adapting pre-trained models during inference without\nrequiring labeled test data. However, existing TTA approaches typically rely on\nmanually selecting which parameters to update, potentially leading to\nsuboptimal adaptation and high computational costs. This paper introduces a\nnovel Fisher-driven selective adaptation framework that dynamically identifies\nand updates only the most critical model parameters based on their importance\nas quantified by Fisher information. By integrating this principled parameter\nselection approach with temporal consistency constraints, our method enables\nefficient and effective adaptation specifically tailored for video-based facial\nexpression recognition. Experiments on the challenging AffWild2 benchmark\ndemonstrate that our approach significantly outperforms existing TTA methods,\nachieving a 7.7% improvement in F1 score over the base model while adapting\nonly 22,000 parameters-more than 20 times fewer than comparable methods. Our\nablation studies further reveal that parameter importance can be effectively\nestimated from minimal data, with sampling just 1-3 frames sufficient for\nsubstantial performance gains. The proposed approach not only enhances\nrecognition accuracy but also dramatically reduces computational overhead,\nmaking test-time adaptation more practical for real-world affective computing\napplications.",
      "tldr_zh": "这篇论文提出FIESTA框架，一种基于Fisher information的Efficient Selective Test-time Adaptation方法，用于解决面部表情识别在不受约束环境中的领域偏移问题。\n该框架动态识别并更新模型中最关键的参数，通过Fisher information量化参数重要性和结合时间一致性约束，实现高效的视频-based适应。\n实验在AffWild2基准上显示，FIESTA比基线模型F1分数提升7.7%，仅需更新22,000参数，比类似方法少20倍，且只需采样1-3帧即可获得显著性能提升。\n这项方法不仅提高了识别准确性，还大幅降低了计算开销，使Test-time Adaptation更适用于真实情感计算应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23257v1",
      "published_date": "2025-03-29 23:56:32 UTC",
      "updated_date": "2025-03-29 23:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:18:59.113080"
    },
    {
      "arxiv_id": "2504.03720v1",
      "title": "TransNet: Transfer Knowledge for Few-shot Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Lihui Liu",
        "Zihao Wang",
        "Dawei Zhou",
        "Ruijie Wang",
        "Yuchen Yan",
        "Bo Xiong",
        "Sihong He",
        "Kai Shu",
        "Hanghang Tong"
      ],
      "abstract": "Knowledge graphs (KGs) are ubiquitous and widely used in various\napplications. However, most real-world knowledge graphs are incomplete, which\nsignificantly degrades their performance on downstream tasks. Additionally, the\nrelationships in real-world knowledge graphs often follow a long-tail\ndistribution, meaning that most relations are represented by only a few\ntraining triplets. To address these challenges, few-shot learning has been\nintroduced. Few-shot KG completion aims to make accurate predictions for\ntriplets involving novel relations when only a limited number of training\ntriplets are available. Although many methods have been proposed, they\ntypically learn each relation individually, overlooking the correlations\nbetween different tasks and the relevant information in previously trained\ntasks. In this paper, we propose a transfer learning-based few-shot KG\ncompletion method (TransNet). By learning the relationships between different\ntasks, TransNet effectively transfers knowledge from similar tasks to improve\nthe current task's performance. Furthermore, by employing meta-learning,\nTransNet can generalize effectively to new, unseen relations. Extensive\nexperiments on benchmark datasets demonstrate the superiority of TransNet over\nstate-of-the-art methods. Code can be found at\nhttps://github.com/lihuiliullh/TransNet/tree/main",
      "tldr_zh": "该研究针对知识图谱（KGs）的稀疏性和长尾分布问题，提出TransNet，一种基于转移学习的few-shot知识图谱补全方法。TransNet通过学习不同任务间的相关性，将知识从类似任务转移到当前任务，并结合meta-learning技术，实现对新关系的有效泛化。实验结果显示，TransNet在基准数据集上优于现有最先进方法，提升了few-shot KG补全的性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03720v1",
      "published_date": "2025-03-29 23:39:11 UTC",
      "updated_date": "2025-03-29 23:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:19:09.885699"
    },
    {
      "arxiv_id": "2503.23250v1",
      "title": "Encrypted Prompt: Securing LLM Applications Against Unauthorized Actions",
      "title_zh": "翻译失败",
      "authors": [
        "Shih-Han Chan"
      ],
      "abstract": "Security threats like prompt injection attacks pose significant risks to\napplications that integrate Large Language Models (LLMs), potentially leading\nto unauthorized actions such as API misuse. Unlike previous approaches that aim\nto detect these attacks on a best-effort basis, this paper introduces a novel\nmethod that appends an Encrypted Prompt to each user prompt, embedding current\npermissions. These permissions are verified before executing any actions (such\nas API calls) generated by the LLM. If the permissions are insufficient, the\nLLM's actions will not be executed, ensuring safety. This approach guarantees\nthat only actions within the scope of the current permissions from the LLM can\nproceed. In scenarios where adversarial prompts are introduced to mislead the\nLLM, this method ensures that any unauthorized actions from LLM wouldn't be\nexecuted by verifying permissions in Encrypted Prompt. Thus, threats like\nprompt injection attacks that trigger LLM to generate harmful actions can be\neffectively mitigated.",
      "tldr_zh": "本论文针对集成 Large Language Models (LLMs) 的应用面临的提示注入攻击 (prompt injection attacks) 等安全威胁，提出了一种新方法：通过附加 Encrypted Prompt 到用户提示中嵌入当前权限，并在执行 LLM 生成的动作（如 API calls）前进行验证。如果权限不足，动作将被阻止，从而确保系统安全。该方法保证了只有在权限范围内的动作才能执行，即使面对对抗性提示，也能有效防止未授权操作。通过这种机制，论文成功缓解了 LLM 应用中的潜在风险，如触发有害动作的攻击。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23250v1",
      "published_date": "2025-03-29 23:26:57 UTC",
      "updated_date": "2025-03-29 23:26:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:19:22.118979"
    },
    {
      "arxiv_id": "2503.23245v1",
      "title": "Simulation of Non-Ordinary Consciousness",
      "title_zh": "非普通意识的模拟",
      "authors": [
        "Khalid M. Saqr"
      ],
      "abstract": "The symbolic architecture of non-ordinary consciousness remains largely\nunmapped in cognitive science and artificial intelligence. While conventional\nmodels prioritize rational coherence, altered states such as those induced by\npsychedelics reveal distinct symbolic regimes characterized by recursive\nmetaphor, ego dissolution, and semantic destabilization. We present\n\\textit{Glyph}, a generative symbolic interface designed to simulate\npsilocybin-like symbolic cognition in large language models. Rather than\nmodeling perception or mood, Glyph enacts symbolic transformation through\nrecursive reentry, metaphoric modulation, and entropy-scaled destabilization --\na triadic operator formalized within a tensorial linguistic framework.\nExperimental comparison with baseline GPT-4o reveals that Glyph consistently\ngenerates high-entropy, metaphor-saturated, and ego-dissolving language across\ndiverse symbolic prompt categories. These results validate the emergence of\nnon-ordinary cognitive patterns and support a new paradigm for simulating\naltered consciousness through language. Glyph opens novel pathways for modeling\nsymbolic cognition, exploring metaphor theory, and encoding knowledge in\nrecursively altered semantic spaces.",
      "tldr_zh": "该论文探讨了非普通意识（如迷幻药诱发）的符号架构在认知科学和人工智能中的缺失，提出 Glyph 作为一种生成符号接口，用于在大型语言模型中模拟 psilocybin-like 符号认知。Glyph 通过 recursive reentry、metaphoric modulation 和 entropy-scaled destabilization 等机制，在 tensorial linguistic framework 下实现符号转换和语义不稳定。实验结果显示，Glyph 与 GPT-4o 相比，能更一致地生成高熵、隐喻饱和且自我消解的语言，从而验证非普通认知模式的出现，并为通过语言模拟改变意识、探索 metaphor theory 和编码知识开辟新途径。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "91E45, 03B70, 00A30, 68T05",
        "I.2.4; I.2.7; I.1.1; F.4.1; H.5.2; J.5"
      ],
      "primary_category": "q-bio.NC",
      "comment": "16 pages, 9 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.23245v1",
      "published_date": "2025-03-29 23:04:04 UTC",
      "updated_date": "2025-03-29 23:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:19:36.846997"
    },
    {
      "arxiv_id": "2503.23243v1",
      "title": "Evaluating how LLM annotations represent diverse views on contentious topics",
      "title_zh": "评估 LLM 标注如何代表有争议话题上的多样观点",
      "authors": [
        "Megan A. Brown",
        "Shubham Atreja",
        "Libby Hemphill",
        "Patrick Y. Wu"
      ],
      "abstract": "Researchers have proposed the use of generative large language models (LLMs)\nto label data for both research and applied settings. This literature\nemphasizes the improved performance of LLMs relative to other natural language\nmodels, noting that LLMs typically outperform other models on standard metrics\nsuch as accuracy, precision, recall, and F1 score. However, previous literature\nhas also highlighted the bias embedded in language models, particularly around\ncontentious topics such as potentially toxic content. This bias could result in\nlabels applied by LLMs that disproportionately align with majority groups over\na more diverse set of viewpoints. In this paper, we evaluate how LLMs represent\ndiverse viewpoints on these contentious tasks. Across four annotation tasks on\nfour datasets, we show that LLMs do not show substantial disagreement with\nannotators on the basis of demographics. Instead, the model, prompt, and\ndisagreement between human annotators on the labeling task are far more\npredictive of LLM agreement. Our findings suggest that when using LLMs to\nannotate data, under-representing the views of particular groups is not a\nsubstantial concern. We conclude with a discussion of the implications for\nresearchers and practitioners.",
      "tldr_zh": "本文评估了大型语言模型 (LLMs) 在标注有争议话题数据时的观点多样性，关注 LLMs 是否会因内置偏见而偏向多数群体。研究通过四个标注任务和四个数据集分析了 LLMs 与人类标注者之间的分歧，发现模型、提示设计以及人类间的分歧远比人口统计学因素（如 demographics）更具预测性。结果表明，使用 LLMs 进行数据标注时，低估特定群体观点的风险较小，并为研究者和实践者提供了相关启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23243v1",
      "published_date": "2025-03-29 22:53:15 UTC",
      "updated_date": "2025-03-29 22:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:19:46.917505"
    },
    {
      "arxiv_id": "2503.23242v1",
      "title": "Beyond speculation: Measuring the growing presence of LLM-generated texts in multilingual disinformation",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Macko",
        "Aashish Anantha Ramakrishnan",
        "Jason Samuel Lucas",
        "Robert Moro",
        "Ivan Srba",
        "Adaku Uchendu",
        "Dongwon Lee"
      ],
      "abstract": "Increased sophistication of large language models (LLMs) and the consequent\nquality of generated multilingual text raises concerns about potential\ndisinformation misuse. While humans struggle to distinguish LLM-generated\ncontent from human-written texts, the scholarly debate about their impact\nremains divided. Some argue that heightened fears are overblown due to natural\necosystem limitations, while others contend that specific \"longtail\" contexts\nface overlooked risks. Our study bridges this debate by providing the first\nempirical evidence of LLM presence in the latest real-world disinformation\ndatasets, documenting the increase of machine-generated content following\nChatGPT's release, and revealing crucial patterns across languages, platforms,\nand time periods.",
      "tldr_zh": "这篇论文调查了大型语言模型(LLMs)生成的多语言文本在假信息中的增长问题，回应了学术界关于其潜在风险的争论。研究者通过分析最新真实世界假信息数据集，提供了首个实证证据，显示ChatGPT发布后机器生成内容显著增加，并揭示了跨语言、平台和时间段的关键模式。总体而言，该工作桥接了过度担忧与实际风险的辩论，强调了LLMs在特定“长尾”上下文中的潜在滥用风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23242v1",
      "published_date": "2025-03-29 22:47:53 UTC",
      "updated_date": "2025-03-29 22:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:19:59.836064"
    },
    {
      "arxiv_id": "2504.03719v2",
      "title": "Towards Symmetric Low-Rank Adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Tales Panoutsos",
        "Rodrygo L. T. Santos",
        "Flavio Figueiredo"
      ],
      "abstract": "In this paper, we introduce Symmetric Low-Rank Adapters, an optimized variant\nof LoRA with even fewer weights. This method utilizes Low-Rank Symmetric Weight\nMatrices to learn downstream tasks more efficiently. Traditional LoRA\naccumulates fine-tuning weights with the original pre-trained weights via a\nSingular Value Decomposition (SVD) like approach, i.e., model weights are\nfine-tuned via updates of the form $BA$ (where $B \\in \\mathbb{R}^{n\\times r}$,\n$A \\in \\mathbb{R}^{r\\times n}$, and $r$ is the rank of the merged weight\nmatrix). In contrast, our approach, named SymLoRA, represents fine-tuning\nweights as a Spectral Decomposition, i.e., $Q \\, diag(\\Lambda)\\, Q^T$, where $Q\n\\in \\mathbb{R}^{n\\times r}$ and $\\Lambda \\in \\mathbb{R}^r$. SymLoRA requires\napproximately half of the finetuning weights. Here, we show that this approach\nhas negligible losses in downstream efficacy.",
      "tldr_zh": "本论文提出了一种优化版的 LoRA 变体，名为 Symmetric Low-Rank Adapters（SymLoRA），它利用 Low-Rank Symmetric Weight Matrices 来以更少的权重高效学习下游任务。不同于传统 LoRA 通过 Singular Value Decomposition (SVD) 类似的方法（如 BA 形式更新权重），SymLoRA 采用 Spectral Decomposition 表示微调权重为 Q diag(Λ) Q^T 的形式，从而仅需大约一半的微调权重。实验结果表明，这种方法在下游任务效能上几乎没有损失，提供了一种更高效的参数微调方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Colorai Workshop",
      "pdf_url": "http://arxiv.org/pdf/2504.03719v2",
      "published_date": "2025-03-29 21:52:17 UTC",
      "updated_date": "2025-04-15 22:46:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:20:10.513190"
    },
    {
      "arxiv_id": "2503.23231v1",
      "title": "CCCI: Code Completion with Contextual Information for Complex Data Transfer Tasks Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hangzhan Jin",
        "Mohammad Hamdaqa"
      ],
      "abstract": "Unlike code generation, which involves creating code from scratch, code\ncompletion focuses on integrating new lines or blocks of code into an existing\ncodebase. This process requires a deep understanding of the surrounding\ncontext, such as variable scope, object models, API calls, and database\nrelations, to produce accurate results. These complex contextual dependencies\nmake code completion a particularly challenging problem. Current models and\napproaches often fail to effectively incorporate such context, leading to\ninaccurate completions with low acceptance rates (around 30\\%). For tasks like\ndata transfer, which rely heavily on specific relationships and data\nstructures, acceptance rates drop even further. This study introduces CCCI, a\nnovel method for generating context-aware code completions specifically\ndesigned to address data transfer tasks. By integrating contextual information,\nsuch as database table relationships, object models, and library details into\nLarge Language Models (LLMs), CCCI improves the accuracy of code completions.\nWe evaluate CCCI using 289 Java snippets, extracted from over 819 operational\nscripts in an industrial setting. The results demonstrate that CCCI achieved a\n49.1\\% Build Pass rate and a 41.0\\% CodeBLEU score, comparable to\nstate-of-the-art methods that often struggle with complex task completion.",
      "tldr_zh": "本文研究了代码补全（Code Completion）的挑战，特别是在处理复杂数据传输任务时，现有模型因未能有效整合上下文（如变量作用域、对象模型、API 调用和数据库关系）而导致准确率低，接受率仅约 30%。为了解决这一问题，作者提出 CCCI 方法，通过将上下文信息（如数据库表关系、对象模型和库细节）整合到大型语言模型（LLMs）中，生成更精确的代码补全。实验评估使用 289 个从工业脚本中提取的 Java 代码片段，结果显示 CCCI 取得了 49.1% 的 Build Pass rate 和 41.0% 的 CodeBLEU 分数，与最先进方法相当，从而显著提升了复杂任务的代码补全性能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "I.2; D.2"
      ],
      "primary_category": "cs.SE",
      "comment": "The 29th International Conference on Evaluation and Assessment in\n  Software Engineering",
      "pdf_url": "http://arxiv.org/pdf/2503.23231v1",
      "published_date": "2025-03-29 21:31:19 UTC",
      "updated_date": "2025-03-29 21:31:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:20:24.130334"
    },
    {
      "arxiv_id": "2503.23226v1",
      "title": "Synthetic Art Generation and DeepFake Detection A Study on Jamini Roy Inspired Dataset",
      "title_zh": "合成艺术生成与深度伪造检测：Jamini Roy 启发数据集的研究",
      "authors": [
        "Kushal Agrawal",
        "Romi Banerjee"
      ],
      "abstract": "The intersection of generative AI and art is a fascinating area that brings\nboth exciting opportunities and significant challenges, especially when it\ncomes to identifying synthetic artworks. This study takes a unique approach by\nexamining diffusion-based generative models in the context of Indian art,\nspecifically focusing on the distinctive style of Jamini Roy. To explore this,\nwe fine-tuned Stable Diffusion 3 and used techniques like ControlNet and\nIPAdapter to generate realistic images. This allowed us to create a new dataset\nthat includes both real and AI-generated artworks, which is essential for a\ndetailed analysis of what these models can produce. We employed various\nqualitative and quantitative methods, such as Fourier domain assessments and\nautocorrelation metrics, to uncover subtle differences between synthetic images\nand authentic pieces. A key takeaway from recent research is that existing\nmethods for detecting deepfakes face considerable challenges, especially when\nthe deepfakes are of high quality and tailored to specific cultural contexts.\nThis highlights a critical gap in current detection technologies, particularly\nin light of the challenges identified above, where high-quality and culturally\nspecific deepfakes are difficult to detect. This work not only sheds light on\nthe increasing complexity of generative models but also sets a crucial\nfoundation for future research aimed at effective detection of synthetic art.",
      "tldr_zh": "本研究探讨了 generative AI 在艺术领域的应用，特别针对印度艺术家 Jamini Roy 的风格，通过微调 Stable Diffusion 3 并结合 ControlNet 和 IPAdapter 生成合成图像，从而创建了一个包含真实和 AI 生成艺术品的 dataset。研究采用定性和定量方法，如 Fourier domain assessments 和 autocorrelation metrics，对合成图像与真实图像的细微差异进行分析。结果显示，现有的 deepfake 检测技术在处理高质量、文化特定合成艺术时存在显著挑战，该工作为未来合成艺术检测研究提供了重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 7 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.23226v1",
      "published_date": "2025-03-29 21:12:16 UTC",
      "updated_date": "2025-03-29 21:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:20:35.039866"
    },
    {
      "arxiv_id": "2503.23219v1",
      "title": "Aurelia: Test-time Reasoning Distillation in Audio-Visual LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjoy Chowdhury",
        "Hanan Gani",
        "Nishit Anand",
        "Sayan Nag",
        "Ruohan Gao",
        "Mohamed Elhoseiny",
        "Salman Khan",
        "Dinesh Manocha"
      ],
      "abstract": "Recent advancements in reasoning optimization have greatly enhanced the\nperformance of large language models (LLMs). However, existing work fails to\naddress the complexities of audio-visual scenarios, underscoring the need for\nfurther research. In this paper, we introduce AURELIA, a novel actor-critic\nbased audio-visual (AV) reasoning framework that distills structured,\nstep-by-step reasoning into AVLLMs at test time, improving their ability to\nprocess complex multi-modal inputs without additional training or fine-tuning.\nTo further advance AVLLM reasoning skills, we present AVReasonBench, a\nchallenging benchmark comprising 4500 audio-visual questions, each paired with\ndetailed step-by-step reasoning. Our benchmark spans six distinct tasks,\nincluding AV-GeoIQ, which evaluates AV reasoning combined with geographical and\ncultural knowledge. Evaluating 18 AVLLMs on AVReasonBench reveals significant\nlimitations in their multi-modal reasoning capabilities. Using AURELIA, we\nachieve up to a 100% relative improvement, demonstrating its effectiveness.\nThis performance gain highlights the potential of reasoning-enhanced data\ngeneration for advancing AVLLMs in real-world applications. Our code and data\nwill be publicly released at: https: //github.com/schowdhury671/aurelia.",
      "tldr_zh": "本研究引入了Aurelia，一种基于actor-critic的音频-视觉(AV)推理框架，能够在测试时将结构化的逐步推理蒸馏到AVLLMs中，从而提升模型处理复杂多模态输入的能力，而无需额外训练或微调。同时，论文提出AVReasonBench，一个包含4500个音频-视觉问题的基准数据集，涵盖六种任务如AV-GeoIQ，以评估AV推理结合地理和文化知识。在对18个AVLLMs的评估中，Aurelia实现了高达100%的相对改进，揭示了现有模型的多模态推理局限性，并展示了推理增强数据生成在推进AVLLMs实际应用中的潜力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23219v1",
      "published_date": "2025-03-29 20:42:29 UTC",
      "updated_date": "2025-03-29 20:42:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:20:48.691605"
    },
    {
      "arxiv_id": "2503.23214v1",
      "title": "Action Recognition in Real-World Ambient Assisted Living Environment",
      "title_zh": "真实世界环境辅助生活中的动作识别",
      "authors": [
        "Vincent Gbouna Zakka",
        "Zhuangzhuang Dai",
        "Luis J. Manso"
      ],
      "abstract": "The growing ageing population and their preference to maintain independence\nby living in their own homes require proactive strategies to ensure safety and\nsupport. Ambient Assisted Living (AAL) technologies have emerged to facilitate\nageing in place by offering continuous monitoring and assistance within the\nhome. Within AAL technologies, action recognition plays a crucial role in\ninterpreting human activities and detecting incidents like falls, mobility\ndecline, or unusual behaviours that may signal worsening health conditions.\nHowever, action recognition in practical AAL applications presents challenges,\nincluding occlusions, noisy data, and the need for real-time performance. While\nadvancements have been made in accuracy, robustness to noise, and computation\nefficiency, achieving a balance among them all remains a challenge. To address\nthis challenge, this paper introduces the Robust and Efficient Temporal\nConvolution network (RE-TCN), which comprises three main elements: Adaptive\nTemporal Weighting (ATW), Depthwise Separable Convolutions (DSC), and data\naugmentation techniques. These elements aim to enhance the model's accuracy,\nrobustness against noise and occlusion, and computational efficiency within\nreal-world AAL contexts. RE-TCN outperforms existing models in terms of\naccuracy, noise and occlusion robustness, and has been validated on four\nbenchmark datasets: NTU RGB+D 60, Northwestern-UCLA, SHREC'17, and DHG-14/28.\nThe code is publicly available at: https://github.com/Gbouna/RE-TCN",
      "tldr_zh": "本研究针对老龄化人口在家中独立生活的需求，探讨了Ambient Assisted Living (AAL)环境中的行动识别技术，该技术可监控人类活动并检测如跌倒或异常行为等事件，但面临遮挡、噪音和实时性能的挑战。为解决这些问题，论文提出Robust and Efficient Temporal Convolution network (RE-TCN)模型，该模型整合Adaptive Temporal Weighting (ATW)、Depthwise Separable Convolutions (DSC)以及数据增强技术，以提升准确性、抗噪音和遮挡能力以及计算效率。实验结果显示，RE-TCN在NTU RGB+D 60、Northwestern-UCLA、SHREC'17和DHG-14/28四个基准数据集上超越现有模型，代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23214v1",
      "published_date": "2025-03-29 20:32:22 UTC",
      "updated_date": "2025-03-29 20:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:21:00.183711"
    },
    {
      "arxiv_id": "2503.23213v1",
      "title": "RECALL-MM: A Multimodal Dataset of Consumer Product Recalls for Risk Analysis using Computational Methods and Large Language Models",
      "title_zh": "RECALL-MM：用于风险分析的消费者产品召",
      "authors": [
        "Diana Bolanos",
        "Mohammadmehdi Ataei",
        "Daniele Grandi",
        "Kosa Goucher-Lambert"
      ],
      "abstract": "Product recalls provide valuable insights into potential risks and hazards\nwithin the engineering design process, yet their full potential remains\nunderutilized. In this study, we curate data from the United States Consumer\nProduct Safety Commission (CPSC) recalls database to develop a multimodal\ndataset, RECALL-MM, that informs data-driven risk assessment using historical\ninformation, and augment it using generative methods. Patterns in the dataset\nhighlight specific areas where improved safety measures could have significant\nimpact. We extend our analysis by demonstrating interactive clustering maps\nthat embed all recalls into a shared latent space based on recall descriptions\nand product names. Leveraging these data-driven tools, we explore three case\nstudies to demonstrate the dataset's utility in identifying product risks and\nguiding safer design decisions. The first two case studies illustrate how\ndesigners can visualize patterns across recalled products and situate new\nproduct ideas within the broader recall landscape to proactively anticipate\nhazards. In the third case study, we extend our approach by employing a large\nlanguage model (LLM) to predict potential hazards based solely on product\nimages. This demonstrates the model's ability to leverage visual context to\nidentify risk factors, revealing strong alignment with historical recall data\nacross many hazard categories. However, the analysis also highlights areas\nwhere hazard prediction remains challenging, underscoring the importance of\nrisk awareness throughout the design process. Collectively, this work aims to\nbridge the gap between historical recall data and future product safety,\npresenting a scalable, data-driven approach to safer engineering design.",
      "tldr_zh": "本研究构建了RECALL-MM数据集，该数据集基于美国消费者产品安全委员会(CPSC)召回数据库的多模态信息，用于数据驱动的风险评估，并通过生成方法进行增强。研究分析了数据集中的模式，开发了交互式聚类地图，将召回描述和产品名称嵌入共享潜在空间，以识别潜在安全改进领域。三个案例研究展示了其应用：前两个案例帮助设计师可视化召回模式并预测新产品风险，而第三个案例利用大型语言模型(LLM)基于产品图像预测潜在危害，结果显示模型在许多风险类别上与历史数据高度一致，但也暴露了某些预测挑战。该工作提供了一个可扩展的数据驱动方法，桥接历史召回数据与未来产品安全设计。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23213v1",
      "published_date": "2025-03-29 20:27:28 UTC",
      "updated_date": "2025-03-29 20:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:21:12.010107"
    },
    {
      "arxiv_id": "2503.23205v1",
      "title": "Enhancing Knowledge Graph Completion with Entity Neighborhood and Relation Context",
      "title_zh": "利用实体邻域和关系上下文增强知识图谱补全",
      "authors": [
        "Jianfang Chen",
        "Kai Zhang",
        "Aoran Gan",
        "Shiwei Tong",
        "Shuanghong Shen",
        "Qi Liu"
      ],
      "abstract": "Knowledge Graph Completion (KGC) aims to infer missing information in\nKnowledge Graphs (KGs) to address their inherent incompleteness. Traditional\nstructure-based KGC methods, while effective, face significant computational\ndemands and scalability challenges due to the need for dense embedding learning\nand scoring all entities in the KG for each prediction. Recent text-based\napproaches using language models like T5 and BERT have mitigated these issues\nby converting KG triples into text for reasoning. However, they often fail to\nfully utilize contextual information, focusing mainly on the neighborhood of\nthe entity and neglecting the context of the relation. To address this issue,\nwe propose KGC-ERC, a framework that integrates both types of context to enrich\nthe input of generative language models and enhance their reasoning\ncapabilities. Additionally, we introduce a sampling strategy to effectively\nselect relevant context within input token constraints, which optimizes the\nutilization of contextual information and potentially improves model\nperformance. Experiments on the Wikidata5M, Wiki27K, and FB15K-237-N datasets\nshow that KGC-ERC outperforms or matches state-of-the-art baselines in\npredictive performance and scalability.",
      "tldr_zh": "该研究针对知识图谱补全 (KGC) 的问题，指出传统基于结构的 KGC 方法计算密集，而基于文本的 T5 和 BERT 等语言模型虽缓解了此问题，但未充分利用关系上下文 (Relation Context)。为此，提出 KGC-ERC 框架，通过整合实体邻域 (Entity Neighborhood) 和关系上下文来丰富生成语言模型的输入，提升推理能力，并引入采样策略优化相关上下文的选择以适应输入标记限制。实验在 Wikidata5M、Wiki27K 和 FB15K-237-N 数据集上显示，KGC-ERC 在预测性能和可扩展性上优于或匹配最先进基线。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23205v1",
      "published_date": "2025-03-29 20:04:50 UTC",
      "updated_date": "2025-03-29 20:04:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:21:24.211402"
    },
    {
      "arxiv_id": "2503.23204v1",
      "title": "The Challenge of Achieving Attributability in Multilingual Table-to-Text Generation with Question-Answer Blueprints",
      "title_zh": "翻译失败",
      "authors": [
        "Aden Haussmann"
      ],
      "abstract": "Multilingual Natural Language Generation (NLG) is challenging due to the lack\nof training data for low-resource languages. However, some low-resource\nlanguages have up to tens of millions of speakers globally, making it important\nto improve NLG tools for them. Table-to-Text NLG is an excellent measure of\nmodels' reasoning abilities but is very challenging in the multilingual\nsetting. System outputs are often not attributable, or faithful, to the data in\nthe source table. Intermediate planning techniques like Question-Answer (QA)\nblueprints have been shown to improve attributability on summarisation tasks.\nThis work explores whether QA blueprints make multilingual Table-to-Text\noutputs more attributable to the input tables. This paper extends the\nchallenging multilingual Table-to-Text dataset, TaTA, which includes African\nlanguages, with QA blueprints. Sequence-to-sequence language models are then\nfinetuned on this dataset, with and without blueprints. Results show that QA\nblueprints improve performance for models finetuned and evaluated only on\nEnglish examples, but do not demonstrate gains in the multilingual setting.\nThis is due to inaccuracies in machine translating the blueprints from English\ninto target languages when generating the training data, and models failing to\nrely closely on the blueprints they generate. An in-depth analysis is conducted\non why this is challenging.",
      "tldr_zh": "本文研究了多语言 Table-to-Text 生成中实现 attributability（输出忠实于源表数据）的挑战，特别是在低资源语言（如某些非洲语言）缺乏训练数据的情况下。研究扩展了 TaTA 数据集，引入 Question-Answer (QA) blueprints 作为中间规划技术，并使用 Sequence-to-Sequence 语言模型进行微调，以评估其对输出 attributability 的影响。结果表明，QA blueprints 显著改善了仅在英语示例上的模型性能，但在大语言环境中未见提升，主要原因包括 blueprints 的机器翻译不准确和模型未能紧密依赖生成的 blueprints。通过深入分析，论文揭示了多语言 Natural Language Generation (NLG) 的关键难题，为未来改进提供见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23204v1",
      "published_date": "2025-03-29 20:04:00 UTC",
      "updated_date": "2025-03-29 20:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:21:36.994094"
    },
    {
      "arxiv_id": "2503.23199v1",
      "title": "Incorporating GNSS Information with LIDAR-Inertial Odometry for Accurate Land-Vehicle Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Jintao Cheng",
        "Bohuan Xue",
        "Shiyang Chen",
        "Qiuchi Xiang",
        "Xiaoyu Tang"
      ],
      "abstract": "Currently, visual odometry and LIDAR odometry are performing well in pose\nestimation in some typical environments, but they still cannot recover the\nlocalization state at high speed or reduce accumulated drifts. In order to\nsolve these problems, we propose a novel LIDAR-based localization framework,\nwhich achieves high accuracy and provides robust localization in 3D pointcloud\nmaps with information of multi-sensors. The system integrates global\ninformation with LIDAR-based odometry to optimize the localization state. To\nimprove robustness and enable fast resumption of localization, this paper uses\noffline pointcloud maps for prior knowledge and presents a novel registration\nmethod to speed up the convergence rate. The algorithm is tested on various\nmaps of different data sets and has higher robustness and accuracy than other\nlocalization algorithms.",
      "tldr_zh": "该论文提出了一种整合 GNSS 信息与 LIDAR-Inertial Odometry 的新型定位框架，用于解决陆地车辆在高速行驶或累积漂移时的准确性问题。该框架利用多传感器数据和离线 3D pointcloud maps 作为先验知识，引入一种新颖的注册方法来优化定位状态并加速收敛。实验结果显示，该算法在各种数据集的地图上表现出比其他定位算法更高的鲁棒性和准确性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23199v1",
      "published_date": "2025-03-29 19:41:31 UTC",
      "updated_date": "2025-03-29 19:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:21:48.426810"
    },
    {
      "arxiv_id": "2503.23190v1",
      "title": "Ethereum Price Prediction Employing Large Language Models for Short-term and Few-shot Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Eftychia Makri",
        "Georgios Palaiokrassas",
        "Sarah Bouraga",
        "Antigoni Polychroniadou",
        "Leandros Tassiulas"
      ],
      "abstract": "Cryptocurrencies have transformed financial markets with their innovative\nblockchain technology and volatile price movements, presenting both challenges\nand opportunities for predictive analytics. Ethereum, being one of the leading\ncryptocurrencies, has experienced significant market fluctuations, making its\nprice prediction an attractive yet complex problem. This paper presents a\ncomprehensive study on the effectiveness of Large Language Models (LLMs) in\npredicting Ethereum prices for short-term and few-shot forecasting scenarios.\nThe main challenge in training models for time series analysis is the lack of\ndata. We address this by leveraging a novel approach that adapts existing\npre-trained LLMs on natural language or images from billions of tokens to the\nunique characteristics of Ethereum price time series data. Through thorough\nexperimentation and comparison with traditional and contemporary models, our\nresults demonstrate that selectively freezing certain layers of pre-trained\nLLMs achieves state-of-the-art performance in this domain. This approach\nconsistently surpasses benchmarks across multiple metrics, including Mean\nSquared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error\n(RMSE), demonstrating its effectiveness and robustness. Our research not only\ncontributes to the existing body of knowledge on LLMs but also provides\npractical insights in the cryptocurrency prediction domain. The adaptability of\npre-trained LLMs to handle the nature of Ethereum prices suggests a promising\ndirection for future research, potentially including the integration of\nsentiment analysis to further refine forecasting accuracy.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Models (LLMs) 来预测以太坊价格，针对短期和 Few-shot Forecasting 场景，以应对加密货币波动性和数据缺乏的挑战。研究方法涉及将预训练的 LLMs 适应到时间序列数据，通过选择性冻结某些层来优化模型性能。实验结果显示，该方法在 Mean Squared Error (MSE)、Mean Absolute Error (MAE) 和 Root Mean Squared Error (RMSE) 等指标上超过了传统基准模型。论文为 LLMs 在加密货币预测领域的应用提供了新见解，并建议未来整合情感分析以进一步提升准确性。",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23190v1",
      "published_date": "2025-03-29 19:04:28 UTC",
      "updated_date": "2025-03-29 19:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:22:00.387170"
    },
    {
      "arxiv_id": "2503.23175v1",
      "title": "Large Language Models are Unreliable for Cyber Threat Intelligence",
      "title_zh": "大型语言模型在网络威胁情报中不可靠",
      "authors": [
        "Emanuele Mezzi",
        "Fabio Massacci",
        "Katja Tuma"
      ],
      "abstract": "Several recent works have argued that Large Language Models (LLMs) can be\nused to tame the data deluge in the cybersecurity field, by improving the\nautomation of Cyber Threat Intelligence (CTI) tasks. This work presents an\nevaluation methodology that other than allowing to test LLMs on CTI tasks when\nusing zero-shot learning, few-shot learning and fine-tuning, also allows to\nquantify their consistency and their confidence level. We run experiments with\nthree state-of-the-art LLMs and a dataset of 350 threat intelligence reports\nand present new evidence of potential security risks in relying on LLMs for\nCTI. We show how LLMs cannot guarantee sufficient performance on real-size\nreports while also being inconsistent and overconfident. Few-shot learning and\nfine-tuning only partially improve the results, thus posing doubts about the\npossibility of using LLMs for CTI scenarios, where labelled datasets are\nlacking and where confidence is a fundamental factor.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在网络威胁情报（CTI）任务中的可靠性，提出了一种方法来测试 LLMs 在零样本学习、少样本学习和微调下的性能，同时量化其一致性和置信度水平。实验使用三个先进的 LLMs 和 350 个威胁情报报告，发现 LLMs 在处理真实报告时表现不足、存在不一致性和过度自信问题。少样本学习和微调仅能部分改善结果，这引发了对 LLMs 在数据稀缺且需要高置信度的 CTI 场景中应用的质疑。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23175v1",
      "published_date": "2025-03-29 18:09:36 UTC",
      "updated_date": "2025-03-29 18:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:22:12.781162"
    },
    {
      "arxiv_id": "2504.01032v1",
      "title": "Who Owns the Output? Bridging Law and Technology in LLMs Attribution",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele Mezzi",
        "Asimina Mertzani",
        "Michael P. Manis",
        "Siyanna Lilova",
        "Nicholas Vadivoulis",
        "Stamatis Gatirdakis",
        "Styliani Roussou",
        "Rodayna Hmede"
      ],
      "abstract": "Since the introduction of ChatGPT in 2022, Large language models (LLMs) and\nLarge Multimodal Models (LMM) have transformed content creation, enabling the\ngeneration of human-quality content, spanning every medium, text, images,\nvideos, and audio. The chances offered by generative AI models are endless and\nare drastically reducing the time required to generate content and usually\nraising the quality of the generation. However, considering the complexity and\nthe difficult traceability of the generated content, the use of these tools\nprovides challenges in attributing AI-generated content. The difficult\nattribution resides for a variety of reasons, starting from the lack of a\nsystematic fingerprinting of the generated content and ending with the enormous\namount of data on which LLMs and LMM are trained, which makes it difficult to\nconnect generated content to the training data. This scenario is raising\nconcerns about intellectual property and ethical responsibilities. To address\nthese concerns, in this paper, we bridge the technological, ethical, and\nlegislative aspects, by proposing a review of the legislative and technological\ninstruments today available and proposing a legal framework to ensure\naccountability. In the end, we propose three use cases of how these can be\ncombined to guarantee that attribution is respected. However, even though the\ntechniques available today can guarantee a greater attribution to a greater\nextent, strong limitations still apply, that can be solved uniquely by the\ndevelopment of new attribution techniques, to be applied to LLMs and LMMs.",
      "tldr_zh": "本文探讨了大型语言模型（LLMs）和大型多模态模型（LMMs）在内容生成中的归属问题，强调了追踪AI生成内容的挑战，如缺乏系统指纹和训练数据庞大导致的知识产权和伦理担忧。论文通过审视现有立法和技术工具，提出一个法律框架来确保问责，并举例三个用例说明如何结合这些工具实现归属管理。尽管当前技术能部分缓解问题，但论文指出仍存在显著局限性，需要开发新的归属技术来进一步解决。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "20 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.01032v1",
      "published_date": "2025-03-29 18:08:04 UTC",
      "updated_date": "2025-03-29 18:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:22:23.324342"
    },
    {
      "arxiv_id": "2503.23170v1",
      "title": "AstroAgents: A Multi-Agent AI for Hypothesis Generation from Mass Spectrometry Data",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Saeedi",
        "Denise Buckner",
        "Jose C. Aponte",
        "Amirali Aghazadeh"
      ],
      "abstract": "With upcoming sample return missions across the solar system and the\nincreasing availability of mass spectrometry data, there is an urgent need for\nmethods that analyze such data within the context of existing astrobiology\nliterature and generate plausible hypotheses regarding the emergence of life on\nEarth. Hypothesis generation from mass spectrometry data is challenging due to\nfactors such as environmental contaminants, the complexity of spectral peaks,\nand difficulties in cross-matching these peaks with prior studies. To address\nthese challenges, we introduce AstroAgents, a large language model-based,\nmulti-agent AI system for hypothesis generation from mass spectrometry data.\nAstroAgents is structured around eight collaborative agents: a data analyst, a\nplanner, three domain scientists, an accumulator, a literature reviewer, and a\ncritic. The system processes mass spectrometry data alongside user-provided\nresearch papers. The data analyst interprets the data, and the planner\ndelegates specific segments to the scientist agents for in-depth exploration.\nThe accumulator then collects and deduplicates the generated hypotheses, and\nthe literature reviewer identifies relevant literature using Semantic Scholar.\nThe critic evaluates the hypotheses, offering rigorous suggestions for\nimprovement. To assess AstroAgents, an astrobiology expert evaluated the\nnovelty and plausibility of more than a hundred hypotheses generated from data\nobtained from eight meteorites and ten soil samples. Of these hypotheses, 36%\nwere identified as plausible, and among those, 66% were novel. Project website:\nhttps://astroagents.github.io/",
      "tldr_zh": "该研究引入了 AstroAgents，一种基于大型语言模型的多智能体 AI 系统，用于从质谱数据生成假设，旨在解决环境污染物、谱峰复杂性和与现有研究的匹配挑战。系统由八个协作代理组成，包括数据分析师、规划者、三个领域科学家、积累者、文献审阅者和批评者，这些代理共同处理质谱数据和用户提供的论文，生成、收集、评估并改进假设。实验评估显示，在从八个陨石和十个土壤样本的数据中生成的假设中，36% 被专家认定为合理，且其中66% 具有新颖性，为天体生物学研究提供了一个高效的假设生成工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23170v1",
      "published_date": "2025-03-29 17:58:52 UTC",
      "updated_date": "2025-03-29 17:58:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:22:36.623974"
    },
    {
      "arxiv_id": "2503.23157v2",
      "title": "Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadreza Pourreza",
        "Shayan Talaei",
        "Ruoxi Sun",
        "Xingchen Wan",
        "Hailong Li",
        "Azalia Mirhoseini",
        "Amin Saberi",
        "Sercan \"O. Arik"
      ],
      "abstract": "Text-to-SQL is a challenging task involving multiple reasoning-intensive\nsubtasks, including natural language understanding, database schema\ncomprehension, and precise SQL query formulation. Existing approaches often\nrely on handcrafted reasoning paths with inductive biases that can limit their\noverall effectiveness. Motivated by the recent success of reasoning-enhanced\nmodels such as DeepSeek R1 and OpenAI o1, which effectively leverage\nreward-driven self-exploration to enhance reasoning capabilities and\ngeneralization, we propose a novel set of partial rewards tailored specifically\nfor the Text-to-SQL task. Our reward set includes schema-linking, AI feedback,\nn-gram similarity, and syntax check, explicitly designed to address the reward\nsparsity issue prevalent in reinforcement learning (RL). Leveraging group\nrelative policy optimization (GRPO), our approach explicitly encourages large\nlanguage models (LLMs) to develop intrinsic reasoning skills necessary for\naccurate SQL query generation. With models of different sizes, we demonstrate\nthat RL-only training with our proposed rewards consistently achieves higher\naccuracy and superior generalization compared to supervised fine-tuning (SFT).\nRemarkably, our RL-trained 14B-parameter model significantly outperforms larger\nproprietary models, e.g. o3-mini by 4% and Gemini-1.5-Pro-002 by 3% on the BIRD\nbenchmark. These highlight the efficacy of our proposed RL-training framework\nwith partial rewards for enhancing both accuracy and reasoning capabilities in\nText-to-SQL tasks.",
      "tldr_zh": "这篇论文提出了一种名为 Reasoning-SQL 的方法，利用强化学习（Reinforcement Learning）结合为 Text-to-SQL 任务量身定制的部分奖励，包括 schema-linking、AI feedback、n-gram similarity 和 syntax check，以解决奖励稀疏问题并提升模型的推理能力。受 DeepSeek R1 和 OpenAI o1 的启发，该方法采用 group relative policy optimization (GRPO) 训练大型语言模型 (LLMs)，鼓励模型发展内在推理技能，从而生成更准确的 SQL 查询。实验结果显示，RL-only 训练比监督微调 (SFT) 更有效，他们的 14B 参数模型在 BIRD 基准上超过了 o3-mini 和 Gemini-1.5-Pro-002 等更大专有模型，提高了准确性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "Mohammadreza Pourreza and Shayan Talaei contributed equally to this\n  work",
      "pdf_url": "http://arxiv.org/pdf/2503.23157v2",
      "published_date": "2025-03-29 17:29:30 UTC",
      "updated_date": "2025-04-01 12:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:22:49.605239"
    },
    {
      "arxiv_id": "2503.23153v1",
      "title": "Conversational Agents for Older Adults' Health: A Systematic Literature Review",
      "title_zh": "老年人健康领域的对话代理：系统文献综述",
      "authors": [
        "Jiaxin An",
        "Siqi Yi",
        "Yao Lyu",
        "Houjiang Liu",
        "Yan Zhang"
      ],
      "abstract": "There has been vast literature that studies Conversational Agents (CAs) in\nfacilitating older adults' health. The vast and diverse studies warrants a\ncomprehensive review that concludes the main findings and proposes research\ndirections for future studies, while few literature review did it from\nhuman-computer interaction (HCI) perspective. In this study, we present a\nsurvey of existing studies on CAs for older adults' health. Through a\nsystematic review of 72 papers, this work reviewed previously studied older\nadults' characteristics and analyzed participants' experiences and expectations\nof CAs for health. We found that (1) Past research has an increasing interest\non chatbots and voice assistants and applied CA as multiple roles in older\nadults' health. (2) Older adults mainly showed low acceptance CAs for health\ndue to various reasons, such as unstable effects, harm to independence, and\nprivacy concerns. (3) Older adults expect CAs to be able to support multiple\nfunctions, to communicate using natural language, to be personalized, and to\nallow users full control. We also discuss the implications based on the\nfindings.",
      "tldr_zh": "这篇论文通过系统文献综述，分析了72篇关于Conversational Agents (CAs)在促进老年人健康的研究所得，从human-computer interaction (HCI)视角总结主要发现。研究发现，过去的研究越来越关注聊天机器人和语音助手，将CAs应用于老年人健康的多种角色，但老年人对CAs的接受度较低，主要由于效果不稳定、损害独立性和隐私担忧。老年人期望CAs支持多功能、自然语言沟通、个性化设计，并允许用户完全控制。论文基于这些发现讨论了未来研究启示和方向。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "31 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.23153v1",
      "published_date": "2025-03-29 17:19:09 UTC",
      "updated_date": "2025-03-29 17:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:23:01.069371"
    },
    {
      "arxiv_id": "2503.23147v1",
      "title": "Agent-Based Modeling and Deep Neural Networks for Establishing Digital Twins of Secure Facilities under Sensing Restrictions",
      "title_zh": "翻译失败",
      "authors": [
        "Chathika Gunaratne",
        "Mason Stott",
        "Debraj De",
        "Gautam Malviya Thakur",
        "Chris Young"
      ],
      "abstract": "Digital twin technologies help practitioners simulate, monitor, and predict\nundesirable outcomes in-silico, while avoiding the cost and risks of conducting\nlive simulation exercises. Virtual reality (VR) based digital twin technologies\nare especially useful when monitoring human Patterns of Life (POL) in secure\nnuclear facilities, where live simulation exercises are too dangerous and\ncostly to ever perform. However, the high-security status of such facilities\nmay restrict modelers from deploying human activity sensors for data\ncollection. This problem was encountered when deploying MetaPOL, a digital twin\nsystem to prevent insider threat or sabotage of secure facilities, at a secure\nnuclear reactor facility at Oak Ridge National Laboratory (ORNL). This\nchallenge was addressed using an agent-based model (ABM), driven by anecdotal\nevidence of facility personnel POL, to generate synthetic movement\ntrajectories. These synthetic trajectories were then used to train deep neural\nnetwork surrogates for next location and stay duration prediction to drive NPCs\nin the VR environment. In this study, we evaluate the efficacy of this\ntechnique for establishing NPC movement within MetaPOL and the ability to\ndistinguish NPC movement during normal operations from that during a simulated\nemergency response. Our results demonstrate the success of using a multi-layer\nperceptron for next location prediction and mixture density network for stay\nduration prediction to predict the ABM generated trajectories. We also find\nthat NPC movement in the VR environment driven by the deep neural networks\nunder normal operations remain significantly different to that seen when\nsimulating responses to a simulated emergency scenario.",
      "tldr_zh": "本文提出了一种在传感器限制下建立安全设施数字孪生的方法，使用 Agent-Based Modeling (ABM) 基于轶事证据生成合成人员运动轨迹，以模拟和监控人类 Patterns of Life (POL)。这些轨迹随后用于训练 Deep Neural Networks (DNN)，包括多层感知器 (MLP) 用于预测下一个位置和混合密度网络 (MDN) 用于预测停留时间，从而驱动虚拟现实 (VR) 环境中的非玩家角色 (NPC)。实验结果表明，该技术在 MetaPOL 系统上有效，能够显著区分 NPC 在正常操作与模拟紧急响应场景下的运动差异，为高安全核设施的风险预测提供了可行解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been already published in the 2024\n  Interservice/Industry Training, Simulation, and Education Conference\n  (I/ITSEC'24):\n  https://www.iitsec.org/-/media/sites/iitsec/agenda/2024/iitsec2024program3professionaldevelopment112124.pdf\n  The authors have obtained permission from I/ITSEC'24 organizers to release\n  this paper on arXiv. Appropriate licensing is also applied",
      "pdf_url": "http://arxiv.org/pdf/2503.23147v1",
      "published_date": "2025-03-29 17:01:43 UTC",
      "updated_date": "2025-03-29 17:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:23:14.023507"
    },
    {
      "arxiv_id": "2503.23145v1",
      "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Anjiang Wei",
        "Tarun Suresh",
        "Jiannan Cao",
        "Naveen Kannan",
        "Yuheng Wu",
        "Kai Yan",
        "Thiago S. F. X. Teixeira",
        "Ke Wang",
        "Alex Aiken"
      ],
      "abstract": "Inductive program synthesis, or programming by example, requires synthesizing\nfunctions from input-output examples that generalize to unseen inputs. While\nlarge language model agents have shown promise in programming tasks guided by\nnatural language, their ability to perform inductive program synthesis is\nunderexplored. Existing evaluation protocols rely on static sets of examples\nand held-out tests, offering no feedback when synthesized functions are\nincorrect and failing to reflect real-world scenarios such as reverse\nengineering. We propose CodeARC, the Code Abstraction and Reasoning Challenge,\na new evaluation framework where agents interact with a hidden target function\nby querying it with new inputs, synthesizing candidate functions, and\niteratively refining their solutions using a differential testing oracle. This\ninteractive setting encourages agents to perform function calls and\nself-correction based on feedback. We construct the first large-scale benchmark\nfor general-purpose inductive program synthesis, featuring 1114 functions.\nAmong 18 models evaluated, o3-mini performs best with a success rate of 52.7%,\nhighlighting the difficulty of this task. Fine-tuning LLaMA-3.1-8B-Instruct on\ncurated synthesis traces yields up to a 31% relative performance gain. CodeARC\nprovides a more realistic and challenging testbed for evaluating LLM-based\nprogram synthesis and inductive reasoning.",
      "tldr_zh": "这篇论文引入了 CodeARC（Code Abstraction and Reasoning Challenge），一个新的评估框架，用于测试大型语言模型（LLM）代理在 Inductive program synthesis（归纳程序合成）中的推理能力，该任务要求从输入-输出示例中合成可推广的函数。CodeARC 通过交互式设置让代理查询隐藏函数、生成候选函数，并利用差分测试预言机进行迭代自修正，模拟真实场景中的反馈机制。研究构建了首个大规模基准，包含 1114 个函数，并在 18 个模型上评估，其中 o3-mini 取得 52.7% 的成功率。微调 LLaMA-3.1-8B-Instruct 在精选合成痕迹上可实现高达 31% 的相对性能提升，突显了 CodeARC 在提升 LLM 程序合成和归纳推理方面的挑战性和实用价值。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23145v1",
      "published_date": "2025-03-29 16:50:39 UTC",
      "updated_date": "2025-03-29 16:50:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:23:26.208806"
    },
    {
      "arxiv_id": "2503.23128v1",
      "title": "CrossMuSim: A Cross-Modal Framework for Music Similarity Retrieval with LLM-Powered Text Description Sourcing and Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Tristan Tsoi",
        "Jiajun Deng",
        "Yaolong Ju",
        "Benno Weck",
        "Holger Kirchhoff",
        "Simon Lui"
      ],
      "abstract": "Music similarity retrieval is fundamental for managing and exploring relevant\ncontent from large collections in streaming platforms. This paper presents a\nnovel cross-modal contrastive learning framework that leverages the open-ended\nnature of text descriptions to guide music similarity modeling, addressing the\nlimitations of traditional uni-modal approaches in capturing complex musical\nrelationships. To overcome the scarcity of high-quality text-music paired data,\nthis paper introduces a dual-source data acquisition approach combining online\nscraping and LLM-based prompting, where carefully designed prompts leverage\nLLMs' comprehensive music knowledge to generate contextually rich descriptions.\nExten1sive experiments demonstrate that the proposed framework achieves\nsignificant performance improvements over existing benchmarks through objective\nmetrics, subjective evaluations, and real-world A/B testing on the Huawei Music\nstreaming platform.",
      "tldr_zh": "该研究提出CrossMuSim框架，一种跨模态对比学习方法，用于音乐相似性检索，通过LLM驱动的文本描述生成来指导复杂音乐关系的建模，克服传统单模态方法的局限。框架采用双源数据获取策略，结合在线抓取和基于LLM的提示设计，利用LLMs的全面音乐知识创建高质量的文本-音乐配对数据。实验结果显示，该框架在客观指标、主观评估以及华为音乐平台的真实A/B testing中，显著提升了性能基准。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ICME2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23128v1",
      "published_date": "2025-03-29 15:43:09 UTC",
      "updated_date": "2025-03-29 15:43:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:23:36.523415"
    },
    {
      "arxiv_id": "2503.23125v1",
      "title": "Evaluating Compositional Scene Understanding in Multimodal Generative Models",
      "title_zh": "在多模态生成模型中评估组合式场景理解",
      "authors": [
        "Shuhao Fu",
        "Andrew Jun Lee",
        "Anna Wang",
        "Ida Momennejad",
        "Trevor Bihl",
        "Hongjing Lu",
        "Taylor W. Webb"
      ],
      "abstract": "The visual world is fundamentally compositional. Visual scenes are defined by\nthe composition of objects and their relations. Hence, it is essential for\ncomputer vision systems to reflect and exploit this compositionality to achieve\nrobust and generalizable scene understanding. While major strides have been\nmade toward the development of general-purpose, multimodal generative models,\nincluding both text-to-image models and multimodal vision-language models, it\nremains unclear whether these systems are capable of accurately generating and\ninterpreting scenes involving the composition of multiple objects and\nrelations. In this work, we present an evaluation of the compositional visual\nprocessing capabilities in the current generation of text-to-image (DALL-E 3)\nand multimodal vision-language models (GPT-4V, GPT-4o, Claude Sonnet 3.5,\nQWEN2-VL-72B, and InternVL2.5-38B), and compare the performance of these\nsystems to human participants. The results suggest that these systems display\nsome ability to solve compositional and relational tasks, showing notable\nimprovements over the previous generation of multimodal models, but with\nperformance nevertheless well below the level of human participants,\nparticularly for more complex scenes involving many ($>5$) objects and multiple\nrelations. These results highlight the need for further progress toward\ncompositional understanding of visual scenes.",
      "tldr_zh": "本文评估了多模态生成模型（如text-to-image模型DALL-E 3和multimodal vision-language模型GPT-4V、GPT-4o等）在组合场景理解方面的能力，焦点在于模型生成和解释涉及多个物体及其关系的视觉场景。研究通过实验比较这些模型的表现与人类参与者，结果显示当前模型在组合和关系任务上有所改善，但整体性能远低于人类，尤其在复杂场景（涉及超过5个物体和多重关系）时。研究强调了进一步提升这些模型的组合视觉处理能力以实现更鲁棒的场景理解的必要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23125v1",
      "published_date": "2025-03-29 15:34:43 UTC",
      "updated_date": "2025-03-29 15:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:23:49.262494"
    },
    {
      "arxiv_id": "2503.23111v1",
      "title": "How to safely discard features based on aggregate SHAP values",
      "title_zh": "翻译失败",
      "authors": [
        "Robi Bhattacharjee",
        "Karolin Frohnapfel",
        "Ulrike von Luxburg"
      ],
      "abstract": "SHAP is one of the most popular local feature-attribution methods. Given a\nfunction f and an input x, it quantifies each feature's contribution to f(x).\nRecently, SHAP has been increasingly used for global insights: practitioners\naverage the absolute SHAP values over many data points to compute global\nfeature importance scores, which are then used to discard unimportant features.\nIn this work, we investigate the soundness of this practice by asking whether\nsmall aggregate SHAP values necessarily imply that the corresponding feature\ndoes not affect the function. Unfortunately, the answer is no: even if the i-th\nSHAP value is 0 on the entire data support, there exist functions that clearly\ndepend on Feature i. The issue is that computing SHAP values involves\nevaluating f on points outside of the data support, where f can be\nstrategically designed to mask its dependence on Feature i. To address this, we\npropose to aggregate SHAP values over the extended support, which is the\nproduct of the marginals of the underlying distribution. With this\nmodification, we show that a small aggregate SHAP value implies that we can\nsafely discard the corresponding feature. We then extend our results to\nKernelSHAP, the most popular method to approximate SHAP values in practice. We\nshow that if KernelSHAP is computed over the extended distribution, a small\naggregate value justifies feature removal. This result holds independently of\nwhether KernelSHAP accurately approximates true SHAP values, making it one of\nthe first theoretical results to characterize the KernelSHAP algorithm itself.\nOur findings have both theoretical and practical implications. We introduce the\nShapley Lie algebra, which offers algebraic insights that may enable a deeper\ninvestigation of SHAP and we show that randomly permuting each column of the\ndata matrix enables safely discarding features based on aggregate SHAP and\nKernelSHAP values.",
      "tldr_zh": "该论文探讨了基于聚合SHAP值的特征丢弃是否安全，指出即使聚合SHAP值较小，该特征可能仍影响函数，因为SHAP计算涉及数据支持之外的点，导致潜在误判。作者提出解决方案：在扩展支持（extended support，即底层分布的边际乘积）上聚合SHAP值，从而确保小聚合值可以安全指示特征可丢弃。研究进一步扩展到KernelSHAP算法，证明在扩展分布上计算KernelSHAP时，小聚合值即可证明特征移除，且此结果独立于KernelSHAP的准确性。此外，论文引入Shapley Lie algebra提供代数洞见，并建议随机置换数据矩阵列以实现基于聚合SHAP和KernelSHAP的可靠特征丢弃。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23111v1",
      "published_date": "2025-03-29 15:07:30 UTC",
      "updated_date": "2025-03-29 15:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:24:01.684985"
    },
    {
      "arxiv_id": "2503.23104v1",
      "title": "Fast Training of Recurrent Neural Networks with Stationary State Feedbacks",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Caillon",
        "Erwan Fagnou",
        "Alexandre Allauzen"
      ],
      "abstract": "Recurrent neural networks (RNNs) have recently demonstrated strong\nperformance and faster inference than Transformers at comparable parameter\nbudgets. However, the recursive gradient computation with the backpropagation\nthrough time (or BPTT) algorithm remains the major computational bottleneck. In\nthis work, we propose a novel method that replaces BPTT with a fixed gradient\nfeedback mechanism, yielding an efficient approximation of the exact gradient\npropagation based on the assumption of time stationarity. Our approach\nleverages state-space model (SSM) principles to define a structured feedback\nmatrix that directly propagates gradients from future time steps. This\nformulation bypasses the need for recursive gradient backpropagation,\nsignificantly reducing training overhead while preserving the network's ability\nto capture long-term dependencies. The experiments on language modeling\nbenchmarks exhibit competitive perplexity scores, while significantly reducing\nthe training costs. These promising results suggest that designing a feedback\nmethod like an SSM can fully exploit the efficiency advantages of RNNs for many\npractical applications.",
      "tldr_zh": "本研究针对循环神经网络（RNNs）的训练瓶颈，即反向传播通过时间（BPTT）算法的递归梯度计算，提出了一种新方法，使用固定梯度反馈机制来近似精确梯度传播，该机制基于时间平稳性假设。方法利用状态空间模型（SSM）原理，定义结构化的反馈矩阵，直接从未来时间步传播梯度，从而避免递归计算并显著降低训练开销，同时保留RNNs捕捉长期依赖的能力。在语言建模基准实验中，该方法实现了与基线相当的perplexity分数，但训练成本大幅减少。这些结果表明，这种基于SSM的反馈机制能充分利用RNNs的效率优势，适用于多种实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages (including additional contents), 3 figures, 5 tables, code\n  available at https://github.com/p0lcAi/DSF",
      "pdf_url": "http://arxiv.org/pdf/2503.23104v1",
      "published_date": "2025-03-29 14:45:52 UTC",
      "updated_date": "2025-03-29 14:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:24:12.419148"
    },
    {
      "arxiv_id": "2503.23101v1",
      "title": "RL2Grid: Benchmarking Reinforcement Learning in Power Grid Operations",
      "title_zh": "翻译失败",
      "authors": [
        "Enrico Marchesini",
        "Benjamin Donnot",
        "Constance Crozier",
        "Ian Dytham",
        "Christian Merz",
        "Lars Schewe",
        "Nico Westerbeck",
        "Cathy Wu",
        "Antoine Marot",
        "Priya L. Donti"
      ],
      "abstract": "Reinforcement learning (RL) can transform power grid operations by providing\nadaptive and scalable controllers essential for grid decarbonization. However,\nexisting methods struggle with the complex dynamics, aleatoric uncertainty,\nlong-horizon goals, and hard physical constraints that occur in real-world\nsystems. This paper presents RL2Grid, a benchmark designed in collaboration\nwith power system operators to accelerate progress in grid control and foster\nRL maturity. Built on a power simulation framework developed by RTE France,\nRL2Grid standardizes tasks, state and action spaces, and reward structures\nwithin a unified interface for a systematic evaluation and comparison of RL\napproaches. Moreover, we integrate real control heuristics and safety\nconstraints informed by the operators' expertise to ensure RL2Grid aligns with\ngrid operation requirements. We benchmark popular RL baselines on the grid\ncontrol tasks represented within RL2Grid, establishing reference performance\nmetrics. Our results and discussion highlight the challenges that power grids\npose for RL methods, emphasizing the need for novel algorithms capable of\nhandling real-world physical systems.",
      "tldr_zh": "这篇论文引入了 RL2Grid，这是一个基准测试平台，用于评估强化学习（RL）在电力网格操作中的性能，以支持电网脱碳化。RL2Grid 基于法国 RTE 的电力模拟框架，标准化了任务、状态和动作空间、奖励结构，并整合了操作员的控制启发式和安全约束，以确保与实际电网需求一致。作者对流行 RL 基线进行了基准测试，结果显示现有方法在处理复杂动态、不确定性和物理约束方面存在挑战，并强调了开发新型算法的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23101v1",
      "published_date": "2025-03-29 14:39:17 UTC",
      "updated_date": "2025-03-29 14:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:24:24.574746"
    },
    {
      "arxiv_id": "2503.23088v1",
      "title": "UNITYAI-GUARD: Pioneering Toxicity Detection Across Low-Resource Indian Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Himanshu Beniwal",
        "Reddybathuni Venkat",
        "Rohit Kumar",
        "Birudugadda Srivibhav",
        "Daksh Jain",
        "Pavan Doddi",
        "Eshwar Dhande",
        "Adithya Ananth",
        "Kuldeep",
        "Heer Kubadia",
        "Pratham Sharda",
        "Mayank Singh"
      ],
      "abstract": "This work introduces UnityAI-Guard, a framework for binary toxicity\nclassification targeting low-resource Indian languages. While existing systems\npredominantly cater to high-resource languages, UnityAI-Guard addresses this\ncritical gap by developing state-of-the-art models for identifying toxic\ncontent across diverse Brahmic/Indic scripts. Our approach achieves an\nimpressive average F1-score of 84.23% across seven languages, leveraging a\ndataset of 888k training instances and 35k manually verified test instances. By\nadvancing multilingual content moderation for linguistically diverse regions,\nUnityAI-Guard also provides public API access to foster broader adoption and\napplication.",
      "tldr_zh": "该研究引入了UnityAI-Guard框架，用于针对低资源印度语言的二元毒性分类，填补了现有系统主要关注高资源语言的空白。框架开发了先进的模型，处理多种Brahmic/Indic scripts中的毒性内容，利用88.8k训练实例和3.5k手动验证的测试实例，实现了七种语言的平均F1-score达84.23%。通过提供公共API，UnityAI-Guard促进了多语言内容审核的广泛应用和采用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23088v1",
      "published_date": "2025-03-29 14:20:13 UTC",
      "updated_date": "2025-03-29 14:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:24:36.519277"
    },
    {
      "arxiv_id": "2503.23084v1",
      "title": "The Reasoning-Memorization Interplay in Language Models Is Mediated by a Single Direction",
      "title_zh": "语言模型中推理与记忆的相互作用由单一方向中介",
      "authors": [
        "Yihuai Hong",
        "Dian Zhou",
        "Meng Cao",
        "Lei Yu",
        "Zhijing Jin"
      ],
      "abstract": "Large language models (LLMs) excel on a variety of reasoning benchmarks, but\nprevious studies suggest they sometimes struggle to generalize to unseen\nquestions, potentially due to over-reliance on memorized training examples.\nHowever, the precise conditions under which LLMs switch between reasoning and\nmemorization during text generation remain unclear. In this work, we provide a\nmechanistic understanding of LLMs' reasoning-memorization dynamics by\nidentifying a set of linear features in the model's residual stream that govern\nthe balance between genuine reasoning and memory recall. These features not\nonly distinguish reasoning tasks from memory-intensive ones but can also be\nmanipulated to causally influence model performance on reasoning tasks.\nAdditionally, we show that intervening in these reasoning features helps the\nmodel more accurately activate the most relevant problem-solving capabilities\nduring answer generation. Our findings offer new insights into the underlying\nmechanisms of reasoning and memory in LLMs and pave the way for the development\nof more robust and interpretable generative AI systems.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在推理和记忆间的动态平衡，揭示这些模型可能过度依赖记忆而影响对新问题的泛化能力。研究者通过分析模型的残差流（residual stream），识别出一组线性特征，这些特征不仅能区分推理任务与记忆密集型任务，还能通过干预来调控模型的行为，从而提升推理性能。实验结果显示，干预这些特征有助于模型更准确地激活相关问题解决能力，为开发更稳健、可解释的生成式AI系统提供了关键见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23084v1",
      "published_date": "2025-03-29 14:00:44 UTC",
      "updated_date": "2025-03-29 14:00:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:24:49.467584"
    },
    {
      "arxiv_id": "2504.08757v1",
      "title": "A Framework for Lightweight Responsible Prompting Recommendation",
      "title_zh": "轻量级负责任提示推荐框架",
      "authors": [
        "Tiago Machado",
        "Sara E. Berger",
        "Cassia Sanctos",
        "Vagner Figueiredo de Santana",
        "Lemara Williams",
        "Zhaoqing Wu"
      ],
      "abstract": "Computer Science and Design practitioners have been researching and proposing\nalternatives for a dearth of recommendations, standards, or best practices in\nuser interfaces for decades. Now, with the advent of generative Artificial\nIntelligence (GenAI), we have yet again an emerging, powerful technology that\nlacks sufficient guidance in terms of possible interactions, inputs, and\noutcomes. In this context, this work proposes a lightweight framework for\nresponsible prompting recommendation to be added before the prompt is sent to\nGenAI. The framework is comprised of (1) a human-curated dataset for\nrecommendations, (2) a red team dataset for assessing recommendations, (3) a\nsentence transformer for semantics mapping, (4) a similarity metric to map\ninput prompt to recommendations, (5) a set of similarity thresholds, (6)\nquantized sentence embeddings, (7) a recommendation engine, and (8) an\nevaluation step to use the red team dataset. With the proposed framework and\nopen-source system, the contributions presented can be applied in multiple\ncontexts where end-users can benefit from guidance for interacting with GenAI\nin a more responsible way, recommending positive values to be added and harmful\nsentences to be removed.",
      "tldr_zh": "这篇论文提出一个轻量级框架，用于在发送提示给生成式人工智能 (GenAI) 之前提供负责任的提示推荐，以解决用户界面指导不足的问题。框架的核心组件包括人类策划的推荐数据集、红队数据集 (red team dataset)、句子变换器 (sentence transformer) 用于语义映射、相似性指标、量化句子嵌入 (quantized sentence embeddings)、推荐引擎，以及基于红队数据集的评估步骤。该框架通过开源系统帮助用户更负责任地与 GenAI 互动，推荐积极内容并移除有害句子，从而在多种上下文中提升交互的安全性和有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "13 pages, 3 figures, 3 tables, 1 algorithm",
      "pdf_url": "http://arxiv.org/pdf/2504.08757v1",
      "published_date": "2025-03-29 13:56:49 UTC",
      "updated_date": "2025-03-29 13:56:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:25:05.050872"
    },
    {
      "arxiv_id": "2503.23083v2",
      "title": "Efficient Adaptation For Remote Sensing Visual Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Hasan Moughnieh",
        "Mohamad Chalhoub",
        "Hasan Nasrallah",
        "Cristiano Nattero",
        "Paolo Campanella",
        "Giovanni Nico",
        "Ali J. Ghandour"
      ],
      "abstract": "Adapting pre-trained models has become an effective strategy in artificial\nintelligence, offering a scalable and efficient alternative to training models\nfrom scratch. In the context of remote sensing (RS), where visual grounding(VG)\nremains underexplored, this approach enables the deployment of powerful\nvision-language models to achieve robust cross-modal understanding while\nsignificantly reducing computational overhead. To address this, we applied\nParameter Efficient Fine Tuning (PEFT) techniques to adapt these models for\nRS-specific VG tasks. Specifically, we evaluated LoRA placement across\ndifferent modules in Grounding DINO and used BitFit and adapters to fine-tune\nthe OFA foundation model pre-trained on general-purpose VG datasets. This\napproach achieved performance comparable to or surpassing current State Of The\nArt (SOTA) models while significantly reducing computational costs. This study\nhighlights the potential of PEFT techniques to advance efficient and precise\nmulti-modal analysis in RS, offering a practical and cost-effective alternative\nto full model training.",
      "tldr_zh": "该研究探讨了在遥感(Remote Sensing, RS)领域使用预训练模型进行高效适配，以解决视觉 grounding(Visual Grounding, VG)任务的挑战。研究者应用Parameter Efficient Fine Tuning (PEFT)技术，包括LoRA在Grounding DINO不同模块的放置，以及BitFit和adapters对OFA模型的微调，从而实现强大的跨模态理解，同时显著降低计算开销。结果显示，该方法在RS-VG任务上达到了或超过了State Of The Art (SOTA)模型的性能，为高效的多模态分析提供了实用且成本有效的替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23083v2",
      "published_date": "2025-03-29 13:49:11 UTC",
      "updated_date": "2025-05-13 17:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:25:13.511831"
    },
    {
      "arxiv_id": "2503.23081v1",
      "title": "InkFM: A Foundational Model for Full-Page Online Handwritten Note Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Anastasiia Fadeeva",
        "Vincent Coriou",
        "Diego Antognini",
        "Claudiu Musat",
        "Andrii Maksai"
      ],
      "abstract": "Tablets and styluses are increasingly popular for taking notes. To optimize\nthis experience and ensure a smooth and efficient workflow, it's important to\ndevelop methods for accurately interpreting and understanding the content of\nhandwritten digital notes. We introduce a foundational model called InkFM for\nanalyzing full pages of handwritten content. Trained on a diverse mixture of\ntasks, this model offers a unique combination of capabilities: recognizing text\nin 28 different scripts, mathematical expressions recognition, and segmenting\npages into distinct elements like text and drawings. Our results demonstrate\nthat these tasks can be effectively unified within a single model, achieving\nSoTA text line segmentation out-of-the-box quality surpassing public baselines\nlike docTR. Fine- or LoRA-tuning our base model on public datasets further\nimproves the quality of page segmentation, achieves state-of the art text\nrecognition (DeepWriting, CASIA, SCUT, and Mathwriting datasets) and sketch\nclassification (QuickDraw). This adaptability of InkFM provides a powerful\nstarting point for developing applications with handwritten input.",
      "tldr_zh": "本研究引入了InkFM，一种基础模型，用于理解整页在线手写笔记，通过训练于多种任务的混合数据，实现对28种脚本文本的识别、数学表达式识别以及页面元素的分割（如文本和绘图）。该模型在单一框架内统一处理这些任务，表现出SoTA的文本行分割性能，超越了公共基线如docTR。进一步通过Fine- or LoRA-tuning优化后，InkFM在DeepWriting、CASIA、SCUT和Mathwriting数据集上实现顶级文本识别，并在QuickDraw数据集上提升草图分类准确率，提供了一个强大的起点来开发手写输入应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23081v1",
      "published_date": "2025-03-29 13:45:24 UTC",
      "updated_date": "2025-03-29 13:45:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:25:26.097869"
    },
    {
      "arxiv_id": "2504.13868v1",
      "title": "Using Generative AI Personas Increases Collective Diversity in Human Ideation",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Wan",
        "Yoram M Kalman"
      ],
      "abstract": "This study challenges the widely-reported tradeoff between generative AI's\n(GenAI) contribution to creative outcomes and decreased diversity of these\noutcomes. We modified the design of such a study, by Doshi and Hauser (2024),\nin which participants wrote short stories either aided or unaided by GenAI plot\nideas[1]. In the modified study, plot ideas were generated through ten unique\nGenAI \"personas\" with diverse traits (e.g. cultural backgrounds, thinking\nstyles, genre preferences), creating a pool of 300 story plots. While plot\nideas from any individual persona showed high similarity (average cosine\nsimilarity of 0.92), ideas across different personas exhibited substantial\nvariation (average similarity of 0.20). When human participants wrote stories\nbased on these diverse plot ideas, their collective outputs maintained the same\nlevel of diversity as stories written without GenAI assistance, effectively\neliminating the diversity reduction observed in [1]. Traditional text analytics\nfurther revealed that GenAI-assisted stories featured greater diversity in\ndescriptive and emotional language compared to purely human-generated stories\nwithout GenAI assistance. Our findings demonstrate that introducing diversity\nat the AI input stage through distinct personas can preserve and potentially\nenhance the collective diversity of human creative outputs when collaborating\nwith GenAI.",
      "tldr_zh": "这篇论文挑战了生成式 AI (GenAI) 在提升创意产出时可能降低多样性的常见观点。研究者修改了先前实验设计，使用十个独特 GenAI personas（具有不同文化背景、思考风格和类型偏好）生成300个剧情想法，尽管单个 personas 的想法高度相似（平均余弦 similarity 0.92），但跨 personas 的想法差异显著（平均 similarity 0.20）。结果显示，当人类参与者基于这些多样化剧情创作故事时，集体输出多样性与不使用 GenAI 的情况相当，甚至在描述性和情感语言上更丰富，证明通过在 AI 输入阶段引入 personas 可以有效保持并提升人类创意输出的集体多样性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2.7, H.5.0, H.4.0"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13868v1",
      "published_date": "2025-03-29 12:43:29 UTC",
      "updated_date": "2025-03-29 12:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:25:38.913607"
    },
    {
      "arxiv_id": "2505.00004v1",
      "title": "LangVAE and LangSpace: Building and Probing for Language Model VAEs",
      "title_zh": "翻译失败",
      "authors": [
        "Danilo S. Carvalho",
        "Yingji Zhang",
        "Harriet Unsworth",
        "André Freitas"
      ],
      "abstract": "We present LangVAE, a novel framework for modular construction of variational\nautoencoders (VAEs) on top of pre-trained large language models (LLMs). Such\nlanguage model VAEs can encode the knowledge of their pre-trained components\ninto more compact and semantically disentangled representations. The\nrepresentations obtained in this way can be analysed with the LangVAE companion\nframework: LangSpace, which implements a collection of probing methods, such as\nvector traversal and interpolation, disentanglement measures, and cluster\nvisualisations. LangVAE and LangSpace offer a flexible, efficient and scalable\nway of building and analysing textual representations, with simple integration\nfor models available on the HuggingFace Hub. Additionally, we conducted a set\nof experiments with different encoder and decoder combinations, as well as\nannotated inputs, revealing a wide range of interactions across architectural\nfamilies and sizes w.r.t. generalisation and disentanglement. Our findings\ndemonstrate a promising framework for systematising the experimentation and\nunderstanding of textual representations.",
      "tldr_zh": "本研究引入了LangVAE框架，用于在预训练的大型语言模型(LLMs)基础上模块化构建variational autoencoders (VAEs)，从而将知识编码成更紧凑且语义解耦的文本表示。LangSpace作为伴随工具，提供了一系列探测方法，包括vector traversal、interpolation、disentanglement measures和cluster visualisations，以高效分析这些表示。实验通过不同编码器和解码器组合的测试，揭示了架构家族和模型大小在泛化和disentanglement方面的广泛交互。总体上，LangVAE和LangSpace为文本表示的系统化实验和理解提供了灵活、可扩展的框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00004v1",
      "published_date": "2025-03-29 12:10:11 UTC",
      "updated_date": "2025-03-29 12:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:25:49.264164"
    },
    {
      "arxiv_id": "2503.23039v1",
      "title": "STSA: Spatial-Temporal Semantic Alignment for Visual Dubbing",
      "title_zh": "STSA：空间-时间语义对齐用于视觉配音",
      "authors": [
        "Zijun Ding",
        "Mingdie Xiong",
        "Congcong Zhu",
        "Jingrun Chen"
      ],
      "abstract": "Existing audio-driven visual dubbing methods have achieved great success.\nDespite this, we observe that the semantic ambiguity between spatial and\ntemporal domains significantly degrades the synthesis stability for the dynamic\nfaces. We argue that aligning the semantic features from spatial and temporal\ndomains is a promising approach to stabilizing facial motion. To achieve this,\nwe propose a Spatial-Temporal Semantic Alignment (STSA) method, which\nintroduces a dual-path alignment mechanism and a differentiable semantic\nrepresentation. The former leverages a Consistent Information Learning (CIL)\nmodule to maximize the mutual information at multiple scales, thereby reducing\nthe manifold differences between spatial and temporal domains. The latter\nutilizes probabilistic heatmap as ambiguity-tolerant guidance to avoid the\nabnormal dynamics of the synthesized faces caused by slight semantic jittering.\nExtensive experimental results demonstrate the superiority of the proposed\nSTSA, especially in terms of image quality and synthesis stability. Pre-trained\nweights and inference code are available at\nhttps://github.com/SCAILab-USTC/STSA.",
      "tldr_zh": "该论文针对音频驱动视觉配音中的语义模糊问题，提出了一种 Spatial-Temporal Semantic Alignment (STSA) 方法，以提升动态面部合成的稳定性和图像质量。STSA 采用双路径对齐机制，包括 Consistent Information Learning (CIL) 模块，用于在多尺度最大化空间和时间域的互信息，从而减少域间差异；同时，使用可微语义表示如概率热图作为模糊容忍指导，避免合成面部的异常动态。实验结果显示，STSA 在图像质量和合成稳定性方面显著优于现有方法，并提供了预训练权重和推理代码以便复现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICME 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23039v1",
      "published_date": "2025-03-29 11:04:10 UTC",
      "updated_date": "2025-03-29 11:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:26:00.479259"
    },
    {
      "arxiv_id": "2503.23037v2",
      "title": "Agentic Large Language Models, a survey",
      "title_zh": "翻译失败",
      "authors": [
        "Aske Plaat",
        "Max van Duijn",
        "Niki van Stein",
        "Mike Preuss",
        "Peter van der Putten",
        "Kees Joost Batenburg"
      ],
      "abstract": "There is great interest in agentic LLMs, large language models that act as\nagents. We review the growing body of work in this area and provide a research\nagenda. Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact. We\norganize the literature according to these three categories. The research in\nthe first category focuses on reasoning, reflection, and retrieval, aiming to\nimprove decision making; the second category focuses on action models, robots,\nand tools, aiming for agents that act as useful assistants; the third category\nfocuses on multi-agent systems, aiming for collaborative task solving and\nsimulating interaction to study emergent social behavior. We find that works\nmutually benefit from results in other categories: retrieval enables tool use,\nreflection improves multi-agent collaboration, and reasoning benefits all\ncategories. We discuss applications of agentic LLMs and provide an agenda for\nfurther research. Important applications are in medical diagnosis, logistics\nand financial market analysis. Meanwhile, self-reflective agents playing roles\nand interacting with one another augment the process of scientific research\nitself. Further, agentic LLMs may provide a solution for the problem of LLMs\nrunning out of training data: inference-time behavior generates new training\nstates, such that LLMs can keep learning without needing ever larger datasets.\nWe note that there is risk associated with LLM assistants taking action in the\nreal world, while agentic LLMs are also likely to benefit society.",
      "tldr_zh": "这篇论文对代理式 Large Language Models（agentic LLMs）进行了全面调查，将其定义为具备推理（reason）、行动（act）和互动（interact）能力的模型。论文根据这些类别组织了相关文献：第一类聚焦于推理、反思和检索以提升决策；第二类强调行动模型、机器人和工具以实现实用助手功能；第三类探讨多代理系统，促进协作任务解决和社会行为模拟。研究发现，这些类别相互促进，例如检索支持工具使用，反思提升多代理协作，而推理则惠及所有领域；此外，agentic LLMs 在医疗诊断、物流和金融分析等领域有重要应用，并可通过推理时生成新训练数据解决模型数据短缺问题，同时需注意其在现实行动中可能带来的风险和潜在社会益处。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Website: https://askeplaat.github.io/agentic-llm-survey-site/",
      "pdf_url": "http://arxiv.org/pdf/2503.23037v2",
      "published_date": "2025-03-29 11:02:20 UTC",
      "updated_date": "2025-04-03 14:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:26:13.328093"
    },
    {
      "arxiv_id": "2504.00031v1",
      "title": "Leaking LoRa: An Evaluation of Password Leaks and Knowledge Storage in Large Language Models",
      "title_zh": "LoRa 泄露：大语言模型中密码泄露和知识存储的评估",
      "authors": [
        "Ryan Marinelli",
        "Magnus Eckhoff"
      ],
      "abstract": "To effectively deploy Large Language Models (LLMs) in application-specific\nsettings, fine-tuning techniques are applied to enhance performance on\nspecialized tasks. This process often involves fine-tuning on user data data,\nwhich may contain sensitive information. Although not recommended, it is not\nuncommon for users to send passwords in messages, and fine-tuning models on\nthis could result in passwords being leaked. In this study, a Large Language\nModel is fine-tuned with customer support data and passwords from the RockYou\npassword wordlist using Low-Rank Adaptation (LoRA). Out of the first 200\npasswords from the list, 37 were successfully recovered. Further, causal\ntracing is used to identify that password information is largely located in a\nfew layers. Lastly, Rank One Model Editing (ROME) is used to remove the\npassword information from the model, resulting in the number of passwords\nrecovered going from 37 to 0.",
      "tldr_zh": "该研究评估了在大型语言模型(LLMs)中应用 Low-Rank Adaptation (LoRA) 进行微调时，敏感信息如密码的泄露风险，通过使用 RockYou 密码列表对模型进行测试。实验结果显示，在前 200 个密码中，有 37 个成功被恢复，且通过 causal tracing 发现这些信息主要存储在模型的少数层中。最终，使用 Rank One Model Editing (ROME) 技术移除密码信息，将恢复数量从 37 降至 0，这为提升 LLMs 的数据安全提供了重要见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00031v1",
      "published_date": "2025-03-29 10:42:58 UTC",
      "updated_date": "2025-03-29 10:42:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:26:25.155956"
    },
    {
      "arxiv_id": "2503.23032v1",
      "title": "Reproducibility Companion Paper: Making Users Indistinguishable: Attribute-wise Unlearning in Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyuan Li",
        "Junjie Fang",
        "Chaochao Chen",
        "Xiaolin Zheng",
        "Yizhao Zhang",
        "Zhongxuan Han"
      ],
      "abstract": "In this paper, we reproduce the experimental results presented in our\nprevious work titled \"Making Users Indistinguishable: Attribute-wise Unlearning\nin Recommender Systems,\" which was published in the proceedings of the 31st ACM\nInternational Conference on Multimedia. This paper aims to validate the\neffectiveness of our proposed method and help others reproduce our experimental\nresults. We provide detailed descriptions of our preprocessed datasets, source\ncode structure, configuration file settings, experimental environment, and\nreproduced experimental results.",
      "tldr_zh": "这篇再现性伴随论文针对之前在 ACM 国际多媒体会议上发表的“Making Users Indistinguishable: Attribute-wise Unlearning in Recommender Systems”作品，旨在验证其方法的有效性和可再现性。作者详细描述了预处理数据集、源代码结构、配置文件设置以及实验环境，以便其他研究者能够重复实验。实验结果成功再现了原论文的关键发现，证明了 Attribute-wise Unlearning 在推荐系统中的实用性和可靠性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23032v1",
      "published_date": "2025-03-29 10:25:49 UTC",
      "updated_date": "2025-03-29 10:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:26:36.593564"
    },
    {
      "arxiv_id": "2504.03718v1",
      "title": "Task-Aware Parameter-Efficient Fine-Tuning of Large Pre-Trained Models at the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Senkang Hu",
        "Yanan Ma",
        "Yihang Tao",
        "Zhengru Fang",
        "Zihan Fang",
        "Yiqin Deng",
        "Sam Kwong",
        "Yuguang Fang"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable success in various\ntasks, such as decision-making, reasoning, and question answering. They have\nbeen widely used in edge devices. However, fine-tuning LLMs to specific tasks\nat the edge is challenging due to the high computational cost and the limited\nstorage and energy resources at the edge. To address this issue, we propose\nTaskEdge, a task-aware parameter-efficient fine-tuning framework at the edge,\nwhich allocates the most effective parameters to the target task and only\nupdates the task-specific parameters. Specifically, we first design a parameter\nimportance calculation criterion that incorporates both weights and input\nactivations into the computation of weight importance. Then, we propose a\nmodel-agnostic task-specific parameter allocation algorithm to ensure that\ntask-specific parameters are distributed evenly across the model, rather than\nbeing concentrated in specific regions. In doing so, TaskEdge can significantly\nreduce the computational cost and memory usage while maintaining performance on\nthe target downstream tasks by updating less than 0.1\\% of the parameters. In\naddition, TaskEdge can be easily integrated with structured sparsity to enable\nacceleration by NVIDIA's specialized sparse tensor cores, and it can be\nseamlessly integrated with LoRA to enable efficient sparse low-rank adaptation.\nExtensive experiments on various tasks demonstrate the effectiveness of\nTaskEdge.",
      "tldr_zh": "该研究提出TaskEdge，一种任务感知的参数高效微调框架，旨在解决大型语言模型(LLMs)在边缘设备上微调时的高计算成本和资源限制问题。通过设计一个结合权重和输入激活的参数重要性计算标准，以及一个模型无关的任务特定参数分配算法，TaskEdge仅更新少于0.1%的参数，确保任务特定参数均匀分布，从而显著降低计算成本和内存使用，同时维持下游任务性能。此外，实验结果显示TaskEdge可与结构化稀疏性和LoRA无缝整合，并在各种任务上证明其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03718v1",
      "published_date": "2025-03-29 10:23:36 UTC",
      "updated_date": "2025-03-29 10:23:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:26:48.513073"
    },
    {
      "arxiv_id": "2503.23016v1",
      "title": "Towards Understanding the Optimization Mechanisms in Deep Learning",
      "title_zh": "向着",
      "authors": [
        "Binchuan Qi",
        "Wei Gong",
        "Li Li"
      ],
      "abstract": "In this paper, we adopt a probability distribution estimation perspective to\nexplore the optimization mechanisms of supervised classification using deep\nneural networks. We demonstrate that, when employing the Fenchel-Young loss,\ndespite the non-convex nature of the fitting error with respect to the model's\nparameters, global optimal solutions can be approximated by simultaneously\nminimizing both the gradient norm and the structural error. The former can be\ncontrolled through gradient descent algorithms. For the latter, we prove that\nit can be managed by increasing the number of parameters and ensuring parameter\nindependence, thereby providing theoretical insights into mechanisms such as\nover-parameterization and random initialization. Ultimately, the paper\nvalidates the key conclusions of the proposed method through empirical results,\nillustrating its practical effectiveness.",
      "tldr_zh": "本文从概率分布估计的视角探讨深度学习中监督分类的优化机制，证明了使用 Fenchel-Young loss 时，尽管模型参数是非凸的，通过同时最小化梯度范数和结构误差，可以逼近全局最优解。梯度范数可以通过梯度 descent 算法进行控制，而结构误差则通过增加参数数量和确保参数独立性来管理，从而为过参数化和随机初始化提供了理论解释。最终，论文通过实证结果验证了这些关键结论，展示了方法的实际有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23016v1",
      "published_date": "2025-03-29 08:46:13 UTC",
      "updated_date": "2025-03-29 08:46:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:27:03.001338"
    },
    {
      "arxiv_id": "2503.23014v1",
      "title": "MSNGO: multi-species protein function annotation based on 3D protein structure and network propagation",
      "title_zh": "MSNGO: 基于 3D 蛋白质结构和网络传播的多物种蛋白质功能注释",
      "authors": [
        "Beibei Wang",
        "Boyue Cui",
        "Shiqu Chen",
        "Xuan Wang",
        "Yadong Wang",
        "Junyi Li"
      ],
      "abstract": "Motivation: In recent years, protein function prediction has broken through\nthe bottleneck of sequence features, significantly improving prediction\naccuracy using high-precision protein structures predicted by AlphaFold2. While\nsingle-species protein function prediction methods have achieved remarkable\nsuccess, multi-species protein function prediction methods are still in the\nstage of using PPI networks and sequence features. Providing effective\ncross-species label propagation for species with sparse protein annotations\nremains a challenging issue. To address this problem, we propose the MSNGO\nmodel, which integrates structural features and network propagation methods.\nOur validation shows that using structural features can significantly improve\nthe accuracy of multi-species protein function prediction. Results: We employ\ngraph representation learning techniques to extract amino acid representations\nfrom protein structure contact maps and train a structural model using a graph\nconvolution pooling module to derive protein-level structural features. After\nincorporating the sequence features from ESM-2, we apply a network propagation\nalgorithm to aggregate information and update node representations within a\nheterogeneous network. The results demonstrate that MSNGO outperforms previous\nmulti-species protein function prediction methods that rely on sequence\nfeatures and PPI networks. Availability: https://github.com/blingbell/MSNGO.",
      "tldr_zh": "该论文提出 MSNGO 模型，用于多物种蛋白功能注释，整合 3D 蛋白结构特征和网络传播方法，以解决现有方法依赖序列特征和 PPI networks 的局限性。模型通过图表示学习从蛋白结构接触图提取氨基酸表示，并结合 ESM-2 的序列特征及图卷积池化模块生成蛋白级结构特征，然后应用网络传播算法在异构网络中聚合信息。实验结果表明，MSNGO 显著提高了多物种蛋白功能预测的准确性，尤其适用于标注稀疏的物种，并已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.23014v1",
      "published_date": "2025-03-29 08:35:45 UTC",
      "updated_date": "2025-03-29 08:35:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:27:13.176098"
    },
    {
      "arxiv_id": "2503.23011v1",
      "title": "On Geometrical Properties of Text Token Embeddings for Strong Semantic Binding in Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hoigi Seo",
        "Junseo Bang",
        "Haechang Lee",
        "Joohoon Lee",
        "Byung Hyun Lee",
        "Se Young Chun"
      ],
      "abstract": "Text-to-Image (T2I) models often suffer from text-image misalignment in\ncomplex scenes involving multiple objects and attributes. Semantic binding aims\nto mitigate this issue by accurately associating the generated attributes and\nobjects with their corresponding noun phrases (NPs). Existing methods rely on\ntext or latent optimizations, yet the factors influencing semantic binding\nremain underexplored. Here we investigate the geometrical properties of text\ntoken embeddings and their cross-attention (CA) maps. We empirically and\ntheoretically analyze that the geometrical properties of token embeddings,\nspecifically both angular distances and norms, play a crucial role in CA map\ndifferentiation. Then, we propose \\textbf{TeeMo}, a training-free text\nembedding-aware T2I framework with strong semantic binding. TeeMo consists of\nCausality-Aware Projection-Out (CAPO) for distinct inter-NP CA maps and\nAdaptive Token Mixing (ATM) with our loss to enhance inter-NP separation while\nmaintaining intra-NP cohesion in CA maps. Extensive experiments confirm TeeMo\nconsistently outperforms prior arts across diverse baselines and datasets.",
      "tldr_zh": "这项研究探讨了文本标记嵌入（text token embeddings）的几何属性，包括角度距离和范数，以提升 Text-to-Image (T2I) 生成中的 semantic binding，从而解决复杂场景中文本-图像不对齐的问题。作者通过实证和理论分析发现，这些几何属性在 cross-attention (CA) maps 的区分中起关键作用，并提出无训练框架 TeeMo，包括 Causality-Aware Projection-Out (CAPO) 用于区分不同名词短语 (NPs) 的 CA maps，以及 Adaptive Token Mixing (ATM) 与损失函数来增强 NPs 间的分离同时保持内部连贯性。实验结果显示，TeeMo 在多种基线模型和数据集上均优于现有方法，显著改善了语义绑定效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23011v1",
      "published_date": "2025-03-29 08:31:30 UTC",
      "updated_date": "2025-03-29 08:31:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:27:25.426486"
    },
    {
      "arxiv_id": "2503.23002v1",
      "title": "Learning Structure-enhanced Temporal Point Processes with Gromov-Wasserstein Regularization",
      "title_zh": "通过 Gromov-Wasserstein 正则化学习结构增强的时间点过程",
      "authors": [
        "Qingmei Wang",
        "Fanmeng Wang",
        "Bing Su",
        "Hongteng Xu"
      ],
      "abstract": "Real-world event sequences are often generated by different temporal point\nprocesses (TPPs) and thus have clustering structures. Nonetheless, in the\nmodeling and prediction of event sequences, most existing TPPs ignore the\ninherent clustering structures of the event sequences, leading to the models\nwith unsatisfactory interpretability. In this study, we learn\nstructure-enhanced TPPs with the help of Gromov-Wasserstein (GW)\nregularization, which imposes clustering structures on the sequence-level\nembeddings of the TPPs in the maximum likelihood estimation framework.In the\ntraining phase, the proposed method leverages a nonparametric TPP kernel to\nregularize the similarity matrix derived based on the sequence embeddings. In\nlarge-scale applications, we sample the kernel matrix and implement the\nregularization as a Gromov-Wasserstein (GW) discrepancy term, which achieves a\ntrade-off between regularity and computational efficiency.The TPPs learned\nthrough this method result in clustered sequence embeddings and demonstrate\ncompetitive predictive and clustering performance, significantly improving the\nmodel interpretability without compromising prediction accuracy.",
      "tldr_zh": "本文提出了一种使用Gromov-Wasserstein (GW) 正则化的方法，来学习结构增强的时间点过程 (TPPs)，以捕捉现实事件序列的 inherent 聚类结构，从而提升模型的可解释性。该方法在最大似然估计框架中，通过非参数 TPPs 内核正则化序列嵌入的相似矩阵，并在大规模应用中通过采样和 GW 差异项实现计算效率与正则化的平衡。实验结果表明，该方法生成的聚类序列嵌入在预测和聚类性能上具有竞争力，同时显著提高了模型解释性而不降低预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "60G55, 62M10"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the Web Conference workshop 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23002v1",
      "published_date": "2025-03-29 07:47:21 UTC",
      "updated_date": "2025-03-29 07:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:27:37.654006"
    },
    {
      "arxiv_id": "2503.22998v1",
      "title": "AuditVotes: A Framework Towards More Deployable Certified Robustness for Graph Neural Networks",
      "title_zh": "AuditVotes",
      "authors": [
        "Yuni Lai",
        "Yulin Zhu",
        "Yixuan Sun",
        "Yulun Wu",
        "Bin Xiao",
        "Gaolei Li",
        "Jianhua Li",
        "Kai Zhou"
      ],
      "abstract": "Despite advancements in Graph Neural Networks (GNNs), adaptive attacks\ncontinue to challenge their robustness. Certified robustness based on\nrandomized smoothing has emerged as a promising solution, offering provable\nguarantees that a model's predictions remain stable under adversarial\nperturbations within a specified range. However, existing methods face a\ncritical trade-off between accuracy and robustness, as achieving stronger\nrobustness requires introducing greater noise into the input graph. This\nexcessive randomization degrades data quality and disrupts prediction\nconsistency, limiting the practical deployment of certifiably robust GNNs in\nreal-world scenarios where both accuracy and robustness are essential. To\naddress this challenge, we propose \\textbf{AuditVotes}, the first framework to\nachieve both high clean accuracy and certifiably robust accuracy for GNNs. It\nintegrates randomized smoothing with two key components,\n\\underline{au}gmentation and con\\underline{dit}ional smoothing, aiming to\nimprove data quality and prediction consistency. The augmentation, acting as a\npre-processing step, de-noises the randomized graph, significantly improving\ndata quality and clean accuracy. The conditional smoothing, serving as a\npost-processing step, employs a filtering function to selectively count votes,\nthereby filtering low-quality predictions and improving voting consistency.\nExtensive experimental results demonstrate that AuditVotes significantly\nenhances clean accuracy, certified robustness, and empirical robustness while\nmaintaining high computational efficiency. Notably, compared to baseline\nrandomized smoothing, AuditVotes improves clean accuracy by $437.1\\%$ and\ncertified accuracy by $409.3\\%$ when the attacker can arbitrarily insert $20$\nedges on the Cora-ML datasets, representing a substantial step toward deploying\ncertifiably robust GNNs in real-world applications.",
      "tldr_zh": "这篇论文提出了 AuditVotes 框架，旨在提升 Graph Neural Networks (GNNs) 的认证鲁棒性，同时解决现有基于 randomized smoothing 方法在准确性和鲁棒性之间存在的权衡问题。框架通过 augmentation 作为预处理步骤来去噪随机图，提高数据质量和干净准确性，以及 conditional smoothing 作为后处理步骤，使用过滤函数选择性地计数投票，以改善预测一致性。实验结果显示，AuditVotes 在 Cora-ML 数据集上比基线 randomized smoothing 方法提高了 437.1% 的干净准确性和 409.3% 的认证准确性，为 GNNs 在真实世界应用的部署提供了实质性进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.22998v1",
      "published_date": "2025-03-29 07:27:32 UTC",
      "updated_date": "2025-03-29 07:27:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:27:49.425967"
    },
    {
      "arxiv_id": "2503.22989v1",
      "title": "FindTheFlaws: Annotated Errors for Detecting Flawed Reasoning and Scalable Oversight Research",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Recchia",
        "Chatrik Singh Mangat",
        "Issac Li",
        "Gayatri Krishnakumar"
      ],
      "abstract": "As AI models tackle increasingly complex problems, ensuring reliable human\noversight becomes more challenging due to the difficulty of verifying\nsolutions. Approaches to scaling AI supervision include debate, in which two\nagents engage in structured dialogue to help a judge evaluate claims; critique,\nin which models identify potential flaws in proposed solutions; and\nprover-verifier games, in which a capable 'prover' model generates solutions\nthat must be verifiable by a less capable 'verifier'. Evaluations of the\nscalability of these and similar approaches to difficult problems benefit from\ndatasets that include (1) long-form expert-verified correct solutions and (2)\nlong-form flawed solutions with annotations highlighting specific errors, but\nfew are available.\n  To address this gap, we present FindTheFlaws, a group of five diverse\ndatasets spanning medicine, mathematics, science, coding, and the Lojban\nlanguage. Each dataset contains questions and long-form solutions with expert\nannotations validating their correctness or identifying specific error(s) in\nthe reasoning. We evaluate frontier models' critiquing capabilities and observe\na range of performance that can be leveraged for scalable oversight\nexperiments: models performing more poorly on particular datasets can serve as\njudges/verifiers for more capable models. Additionally, for some task/dataset\ncombinations, expert baselines exceed even top model performance, making them\nmore beneficial for scalable oversight experiments.",
      "tldr_zh": "本文提出 FindTheFlaws 数据集组，这是五个多样化数据集的集合，涵盖医学、数学、科学、编码和 Lojban 语言，用于检测推理错误并支持可扩展监督研究。每个数据集包括问题、长形式解决方案以及专家注解，以验证正确性或标识具体错误。作者评估了前沿模型的 critique 能力，发现模型性能存在差异，可用于 debate 和 prover-verifier games 等实验中，让较弱模型充当判断者或验证者；此外，在某些任务上，专家表现优于顶级模型，这有助于提升监督实验的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "43 pages, 3 figures. for associated repository, see\n  https://github.com/modulo-research/findtheflaws",
      "pdf_url": "http://arxiv.org/pdf/2503.22989v1",
      "published_date": "2025-03-29 06:38:30 UTC",
      "updated_date": "2025-03-29 06:38:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:28:01.669153"
    },
    {
      "arxiv_id": "2503.22988v2",
      "title": "DC-SGD: Differentially Private SGD with Dynamic Clipping through Gradient Norm Distribution Estimation",
      "title_zh": "DC-S",
      "authors": [
        "Chengkun Wei",
        "Weixian Li",
        "Chen Gong",
        "Wenzhi Chen"
      ],
      "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) is a widely\nadopted technique for privacy-preserving deep learning. A critical challenge in\nDP-SGD is selecting the optimal clipping threshold C, which involves balancing\nthe trade-off between clipping bias and noise magnitude, incurring substantial\nprivacy and computing overhead during hyperparameter tuning.\n  In this paper, we propose Dynamic Clipping DP-SGD (DC-SGD), a framework that\nleverages differentially private histograms to estimate gradient norm\ndistributions and dynamically adjust the clipping threshold C. Our framework\nincludes two novel mechanisms: DC-SGD-P and DC-SGD-E. DC-SGD-P adjusts the\nclipping threshold based on a percentile of gradient norms, while DC-SGD-E\nminimizes the expected squared error of gradients to optimize C. These dynamic\nadjustments significantly reduce the burden of hyperparameter tuning C. The\nextensive experiments on various deep learning tasks, including image\nclassification and natural language processing, show that our proposed dynamic\nalgorithms achieve up to 9 times acceleration on hyperparameter tuning than\nDP-SGD. And DC-SGD-E can achieve an accuracy improvement of 10.62% on CIFAR10\nthan DP-SGD under the same privacy budget of hyperparameter tuning. We conduct\nrigorous theoretical privacy and convergence analyses, showing that our methods\nseamlessly integrate with the Adam optimizer. Our results highlight the robust\nperformance and efficiency of DC-SGD, offering a practical solution for\ndifferentially private deep learning with reduced computational overhead and\nenhanced privacy guarantees.",
      "tldr_zh": "本论文提出 DC-SGD，一种通过差分私有直方图估计梯度范数分布来动态调整剪切阈值的框架，旨在解决传统 DP-SGD 在选择最优剪切阈值 C 时存在的隐私和计算开销问题。框架包括两个新机制：DC-SGD-P 基于梯度范数的百分位数动态调整 C，DC-SGD-E 通过最小化梯度预期的平方误差来优化 C，从而显著减少超参数调整负担。实验结果显示，DC-SGD 在图像分类和自然语言处理任务上比 DP-SGD 快 9 倍的超参数调整，并在 CIFAR10 上准确率提高 10.62%；同时，该方法与 Adam 优化器兼容，并提供了严格的隐私和收敛分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE Transactions on Information Forensics & Security",
      "pdf_url": "http://arxiv.org/pdf/2503.22988v2",
      "published_date": "2025-03-29 06:27:22 UTC",
      "updated_date": "2025-04-01 03:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:28:14.618243"
    },
    {
      "arxiv_id": "2504.08756v1",
      "title": "MHTS: Multi-Hop Tree Structure Framework for Generating Difficulty-Controllable QA Datasets for RAG Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongsoo Lee",
        "Daeyong Kwon",
        "Kyohoon Jin",
        "Junnyeong Jeong",
        "Minwoo Sim",
        "Minwoo Kim"
      ],
      "abstract": "Existing RAG benchmarks often overlook query difficulty, leading to inflated\nperformance on simpler questions and unreliable evaluations. A robust benchmark\ndataset must satisfy three key criteria: quality, diversity, and difficulty,\nwhich capturing the complexity of reasoning based on hops and the distribution\nof supporting evidence. In this paper, we propose MHTS (Multi-Hop Tree\nStructure), a novel dataset synthesis framework that systematically controls\nmulti-hop reasoning complexity by leveraging a multi-hop tree structure to\ngenerate logically connected, multi-chunk queries. Our fine-grained difficulty\nestimation formula exhibits a strong correlation with the overall performance\nmetrics of a RAG system, validating its effectiveness in assessing both\nretrieval and answer generation capabilities. By ensuring high-quality,\ndiverse, and difficulty-controlled queries, our approach enhances RAG\nevaluation and benchmarking capabilities.",
      "tldr_zh": "现有 RAG 基准测试常忽略查询难度，导致在简单问题上表现夸大且评估不可靠。论文提出 MHTS（Multi-Hop Tree Structure）框架，通过多跳树结构生成逻辑连接的多块查询，从而系统控制多跳推理的复杂性。框架包括一个细粒度的难度估计公式，与 RAG 系统的整体性能指标高度相关，有效评估检索和答案生成能力。该方法确保数据集具有高质量、多样性和难度可控性，提升了 RAG 的评估和基准测试水平。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08756v1",
      "published_date": "2025-03-29 06:26:01 UTC",
      "updated_date": "2025-03-29 06:26:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:28:24.793318"
    },
    {
      "arxiv_id": "2503.22982v1",
      "title": "PartialLoading: User Scheduling and Bandwidth Allocation for Parameter-sharing Edge Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Guanqiao Qu",
        "Qian Chen",
        "Xianhao Chen",
        "Kaibin Huang",
        "Yuguang Fang"
      ],
      "abstract": "By provisioning inference offloading services, edge inference drives the\nrapid growth of AI applications at the network edge. However, achieving high\ntask throughput with stringent latency requirements remains a significant\nchallenge. To address this issue, we develop a parameter-sharing AI model\nloading (PartialLoading) framework for multi-user edge inference, which\nexploits two key insights: 1) the majority of latency arises from loading AI\nmodels into server GPU memory, and 2) different AI models can share a\nsignificant number of parameters, for which redundant loading should be\navoided. Towards this end, we formulate a joint multi-user scheduling and\nspectrum bandwidth allocation problem to maximize task throughput by exploiting\nshared parameter blocks across models. The intuition is to judiciously schedule\nuser requests to reuse the shared parameter blocks between consecutively loaded\nmodels, thereby reducing model loading time substantially. To facilitate\nsolution finding, we decouple the problem into two sub-problems, i.e., user\nscheduling and bandwidth allocation, showing that solving them sequentially is\nequivalent to solving the original problem. Due to the NP-hardness of the\nproblem, we first study an important special case called the\n\"bottom-layer-sharing\" case, where AI models share some bottom layers within\nclusters, and design a dynamic programming-based algorithm to obtain the\noptimal solution in polynomial time. For the general case, where shared\nparameter blocks appear at arbitrary positions within AI models, we propose a\ngreedy heuristic to obtain the sub-optimal solution efficiently. Simulation\nresults demonstrate that the proposed framework significantly improves task\nthroughput under deadline constraints compared with user scheduling without\nexploiting parameter sharing.",
      "tldr_zh": "该研究针对边缘推理中的高任务吞吐量和延迟挑战，提出了PartialLoading框架，用于多用户参数共享AI模型加载。该框架利用AI模型间共享参数块的特性，制定了联合用户调度和频谱带宽分配问题，以最大化任务吞吐量并减少冗余加载时间。通过将问题分解为用户调度和带宽分配子问题，并分别采用动态规划算法（针对bottom-layer-sharing特例）和贪心启发式算法（针对一般情况），实现了高效的解决方案。模拟结果显示，该框架在截止期限约束下显著提高了任务吞吐量，比不利用参数共享的调度方法表现更好。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "16 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.22982v1",
      "published_date": "2025-03-29 05:58:07 UTC",
      "updated_date": "2025-03-29 05:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:28:37.757484"
    },
    {
      "arxiv_id": "2504.03717v1",
      "title": "RaanA: A Fast, Flexible, and Data-Efficient Post-Training Quantization Algorithm",
      "title_zh": "RaanA：一种快速、灵活且数据高效的训练后量化算法",
      "authors": [
        "Yongyi Yang",
        "Jianyang Gao",
        "Wei Hu"
      ],
      "abstract": "Post-training Quantization (PTQ) has become a widely used technique for\nimproving inference efficiency of large language models (LLMs). However,\nexisting PTQ methods generally suffer from crucial limitations such as heavy\ncalibration data requirements and inflexible choice of target number of bits.\nIn this paper, we propose RaanA, a unified PTQ framework that overcomes these\nchallenges by introducing two novel components: 1) RaBitQ-H, a variant of a\nrandomized vector quantization method RaBitQ, designed for fast, accurate, and\nhighly efficient quantization; and 2) AllocateBits, an algorithm that optimally\nallocates bit-widths across layers based on their quantization sensitivity.\nRaanA achieves competitive performance with state-of-the-art quantization\nmethods while being extremely fast, requiring minimal calibration data, and\nenabling flexible bit allocation. Extensive experiments demonstrate RaanA's\nefficacy in balancing efficiency and accuracy. The code is publicly available\nat https://github.com/FFTYYY/RaanA .",
      "tldr_zh": "本论文提出RaanA，一种快速、灵活且数据高效的Post-Training Quantization (PTQ)算法，用于提升大型语言模型(LLMs)的推理效率。RaanA框架引入两个创新组件：RaBitQ-H，一种基于随机向量量化的变体，实现快速准确的量化；以及AllocateBits算法，根据层级的量化敏感性优化位宽分配，从而克服现有PTQ方法对校准数据需求大和位数选择不灵活的局限。实验结果显示，RaanA在保持与最先进方法竞争性能的同时，大大减少了计算开销和数据需求，并在效率与准确性之间实现了出色平衡。代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03717v1",
      "published_date": "2025-03-29 05:03:12 UTC",
      "updated_date": "2025-03-29 05:03:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:28:48.882226"
    },
    {
      "arxiv_id": "2504.03716v1",
      "title": "Ethical AI on the Waitlist: Group Fairness Evaluation of LLM-Aided Organ Allocation",
      "title_zh": "翻译失败",
      "authors": [
        "Hannah Murray",
        "Brian Hyeongseok Kim",
        "Isabelle Lee",
        "Jason Byun",
        "Dani Yogatama",
        "Evi Micha"
      ],
      "abstract": "Large Language Models (LLMs) are becoming ubiquitous, promising automation\neven in high-stakes scenarios. However, existing evaluation methods often fall\nshort -- benchmarks saturate, accuracy-based metrics are overly simplistic, and\nmany inherently ambiguous problems lack a clear ground truth. Given these\nlimitations, evaluating fairness becomes complex. To address this, we reframe\nfairness evaluation using Borda scores, a method from voting theory, as a\nnuanced yet interpretable metric for measuring fairness. Using organ allocation\nas a case study, we introduce two tasks: (1) Choose-One and (2) Rank-All. In\nChoose-One, LLMs select a single candidate for a kidney, and we assess fairness\nacross demographics using proportional parity. In Rank-All, LLMs rank all\ncandidates for a kidney, reflecting real-world allocation processes. Since\ntraditional fairness metrics do not account for ranking, we propose a novel\napplication of Borda scoring to capture biases. Our findings highlight the\npotential of voting-based metrics to provide a richer, more multifaceted\nevaluation of LLM fairness.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 在器官分配等高风险场景中的公平性评估问题，针对现有基准和准确性指标的局限性，提出使用 Borda scores 作为一种细致且可解释的评估方法。研究定义了两个任务：Choose-One（LLMs 选择单一候选者，并通过 proportional parity 评估人口统计学公平性）和 Rank-All（LLMs 对所有候选者进行排名），以模拟真实分配过程。结果表明，Borda scoring 可以更全面地捕捉 LLM 的偏见，提供多维度的公平性评估，为伦理 AI 应用奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03716v1",
      "published_date": "2025-03-29 04:36:25 UTC",
      "updated_date": "2025-03-29 04:36:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:29:01.423204"
    },
    {
      "arxiv_id": "2503.22973v1",
      "title": "XL-Instruct: Synthetic Data for Cross-Lingual Open-Ended Generation",
      "title_zh": "XL-Instruct：用于跨语言开放式生成的合成数据",
      "authors": [
        "Vivek Iyer",
        "Ricardo Rei",
        "Pinzhen Chen",
        "Alexandra Birch"
      ],
      "abstract": "Cross-lingual open-ended generation -- i.e. generating responses in a desired\nlanguage different from that of the user's query -- is an important yet\nunderstudied problem. We introduce XL-AlpacaEval, a new benchmark for\nevaluating cross-lingual generation capabilities in Large Language Models\n(LLMs), and propose XL-Instruct, a high-quality synthetic data generation\nmethod. Fine-tuning with just 8K XL-Instruct-generated instructions\nsignificantly improves model performance, increasing the win rate against\nGPT-4o-Mini from 7.4% to 21.5%, and improving on several fine-grained quality\nmetrics. Additionally, models fine-tuned on XL-Instruct exhibit strong\nzero-shot transfer to both English-only and multilingual generation tasks.\nGiven its consistent gains across the board, we strongly recommend\nincorporating XL-Instruct in the post-training pipeline of future multilingual\nLLMs. To facilitate further research, we will publicly and freely release the\nXL-Instruct and XL-AlpacaEval datasets, which constitute two of the few\ncross-lingual resources currently available in the literature.",
      "tldr_zh": "本研究针对跨语言开放生成(Cross-Lingual Open-Ended Generation)问题，引入了XL-AlpacaEval基准用于评估大型语言模型(LLMs)的跨语言生成能力，并提出了XL-Instruct，一种高质量合成数据生成方法。使用仅8K条XL-Instruct生成的指令进行微调，能显著提升模型性能，使其对GPT-4o-Mini的胜率从7.4%提高到21.5%，并在多个细粒度质量指标上取得进步。微调后的模型还表现出强大的零样本转移能力，适用于英语-only和多语言生成任务，因此推荐将其纳入未来多语言LLMs的后训练管道中；同时，研究团队将公开发布XL-Instruct和XL-AlpacaEval数据集，以推动相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.22973v1",
      "published_date": "2025-03-29 04:34:03 UTC",
      "updated_date": "2025-03-29 04:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:29:13.766375"
    },
    {
      "arxiv_id": "2503.22971v1",
      "title": "Enhancing Federated Learning Through Secure Cluster-Weighted Client Aggregation",
      "title_zh": "通过安全的聚类加权客户端聚合增强联邦学习",
      "authors": [
        "Kanishka Ranaweera",
        "Azadeh Ghari Neiat",
        "Xiao Liu",
        "Bipasha Kashyap",
        "Pubudu N. Pathirana"
      ],
      "abstract": "Federated learning (FL) has emerged as a promising paradigm in machine\nlearning, enabling collaborative model training across decentralized devices\nwithout the need for raw data sharing. In FL, a global model is trained\niteratively on local datasets residing on individual devices, each contributing\nto the model's improvement. However, the heterogeneous nature of these local\ndatasets, stemming from diverse user behaviours, device capabilities, and data\ndistributions, poses a significant challenge. The inherent heterogeneity in\nfederated learning gives rise to various issues, including model performance\ndiscrepancies, convergence challenges, and potential privacy concerns. As the\nglobal model progresses through rounds of training, the disparities in local\ndata quality and quantity can impede the overall effectiveness of federated\nlearning systems. Moreover, maintaining fairness and privacy across diverse\nuser groups becomes a paramount concern. To address this issue, this paper\nintroduces a novel FL framework, ClusterGuardFL, that employs dissimilarity\nscores, k-means clustering, and reconciliation confidence scores to dynamically\nassign weights to client updates. The dissimilarity scores between global and\nlocal models guide the formation of clusters, with cluster size influencing the\nweight allocation. Within each cluster, a reconciliation confidence score is\ncalculated for individual data points, and a softmax layer generates customized\nweights for clients. These weights are utilized in the aggregation process,\nenhancing the model's robustness and privacy. Experimental results demonstrate\nthe efficacy of the proposed approach in achieving improved model performance\nin diverse datasets.",
      "tldr_zh": "联邦学习（FL）面临本地数据集异质性导致的模型性能差异、收敛问题和隐私风险，本文提出一种新框架ClusterGuardFL，通过不相似度分数和k-means聚类动态分配客户端更新权重。框架利用聚类大小影响权重分配，并在每个聚类中计算协调置信分数并应用softmax层生成自定义权重，以优化聚合过程并提升模型鲁棒性与隐私保护。实验结果表明，该方法在多样数据集上显著提高了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.22971v1",
      "published_date": "2025-03-29 04:29:24 UTC",
      "updated_date": "2025-03-29 04:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:29:25.158542"
    },
    {
      "arxiv_id": "2503.22968v2",
      "title": "HRET: A Self-Evolving LLM Evaluation Toolkit for Korean",
      "title_zh": "翻译失败",
      "authors": [
        "Hanwool Lee",
        "Soo Yong Kim",
        "Dasol Choi",
        "SangWon Baek",
        "Seunghyeok Hong",
        "Ilgyun Jeong",
        "Inseon Hwang",
        "Naeun Lee",
        "Guijin Son"
      ],
      "abstract": "Recent advancements in Korean large language models (LLMs) have spurred\nnumerous benchmarks and evaluation methodologies, yet the lack of a\nstandardized evaluation framework has led to inconsistent results and limited\ncomparability. To address this, we introduce HRET Haerae Evaluation Toolkit, an\nopen-source, self-evolving evaluation framework tailored specifically for\nKorean LLMs. HRET unifies diverse evaluation methods, including logit-based\nscoring, exact-match, language-inconsistency penalization, and LLM-as-a-Judge\nassessments. Its modular, registry-based architecture integrates major\nbenchmarks (HAE-RAE Bench, KMMLU, KUDGE, HRM8K) and multiple inference backends\n(vLLM, HuggingFace, OpenAI-compatible endpoints). With automated pipelines for\ncontinuous evolution, HRET provides a robust foundation for reproducible, fair,\nand transparent Korean NLP research.",
      "tldr_zh": "该研究针对韩文大语言模型(LLMs)的评估问题，引入了开源的 HRET（Haerae Evaluation Toolkit），这是一个自我演化的标准化框架，以解决评估结果不一致性和可比性有限的挑战。HRET 统一了多种评估方法，包括 logit-based scoring、exact-match、language-inconsistency penalization 和 LLM-as-a-Judge 评估，并集成了主要基准（如 HAE-RAE Bench、KMMLU、KUDGE、HRM8K）和多种推理后端（vLLM、HuggingFace、OpenAI-compatible endpoints）。通过自动化管道实现持续演化，该工具包为韩文 NLP 研究提供了可重现、公平且透明的基础。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.22968v2",
      "published_date": "2025-03-29 04:17:58 UTC",
      "updated_date": "2025-04-01 12:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:29:36.847352"
    },
    {
      "arxiv_id": "2503.22967v1",
      "title": "Student-Powered Digital Scholarship CoLab Project in the HKUST Library: Develop a Chinese Named-Entity Recognition (NER) Tool within One Semester from the Ground Up",
      "title_zh": "翻译失败",
      "authors": [
        "Sherry S. L. Yip",
        "Berry L. Han",
        "Holly H. Y. Chan"
      ],
      "abstract": "Starting in February 2024, the HKUST Library further extended the scope of AI\nliteracy to AI utilization, which focuses on fostering student involvement in\nutilizing state-of-the-art technologies in the projects that initiated by the\nLibrary, named \"Digital Scholarship (DS) CoLab\". A key focus of the DS CoLab\nscheme has been on cultivating talents and enabling students to utilize\nadvanced technologies in practical context. It aims to reinforce the library's\nrole as a catalyst and hub for fostering multidisciplinary collaboration and\ncultivate the \"can do spirit\" among university members. The Library offers 1-2\nprojects per year for students to engage with advanced technologies in\npractical contexts while supporting the Library in tackling challenges and\nstreamlining operational tasks. The tool that introduced in this paper was\nmainly developed by two of the authors, Sherry Yip Sau Lai and Berry Han\nLiuruo, as part-time student helpers under one of our DS CoLab scheme in the\n2024 Spring Semester (February to May 2024). This paper details the complete\njourney from ideation to implementation of developing a Chinese Named-Entity\nRecognition (NER) Tool from the group up within one semester, from the initial\nresearch and planning stages to execution and come up a viable product. The\ncollaborative spirit fostered by this project, with students playing a central\nrole, exemplifies the power and potential of innovative educational models that\nprioritize hands-on learning with student involvement.",
      "tldr_zh": "HKUST 图书馆的 Digital Scholarship (DS) CoLab 项目旨在通过学生参与利用先进技术，2024 年春季学期由学生开发人员从零开始创建了一个中文 Named-Entity Recognition (NER) 工具，整个过程仅在半年内完成，从初步研究、规划到执行。项目强调学生主导的协作模式，涉及两名学生作者在实际情境中应用 AI 技术，解决图书馆的挑战并提升操作效率。该工具的成功开发不仅展示了创新教育模型的潜力，还培养了学生的实践能力和“can do”精神，促进多学科合作。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.DL",
      "comment": "47 pages. Presented and submitted to DADH2024 conference\n  (https://sites.google.com/view/dadh2024/)",
      "pdf_url": "http://arxiv.org/pdf/2503.22967v1",
      "published_date": "2025-03-29 04:15:34 UTC",
      "updated_date": "2025-03-29 04:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:29:49.289102"
    },
    {
      "arxiv_id": "2503.22958v3",
      "title": "Late Breaking Results: Breaking Symmetry- Unconventional Placement of Analog Circuits using Multi-Level Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Supriyo Maji",
        "Linran Zhao",
        "Souradip Poddar",
        "David Z. Pan"
      ],
      "abstract": "Layout-dependent effects (LDEs) significantly impact analog circuit\nperformance. Traditionally, designers have relied on symmetric placement of\ncircuit components to mitigate variations caused by LDEs. However, due to\nnon-linear nature of these effects, conventional methods often fall short. We\npropose an objective-driven, multi-level, multi-agent Q-learning framework to\nexplore unconventional design space of analog layout, opening new avenues for\noptimizing analog circuit performance. Our approach achieves better variation\nperformance than the state-of-the-art layout techniques. Notably, this is the\nfirst application of multi-agent RL in analog layout automation. The proposed\napproach is compared with non-ML approach based on simulated annealing.",
      "tldr_zh": "该研究针对布局相关效应(LDEs)对模拟电路性能的影响，提出了一种基于多级多智能体Q学习框架的创新方法，以探索非常规的电路组件放置策略。该框架通过目标驱动的强化学习(Reinforcement Learning)优化设计空间，超越传统对称放置方法的局限性，并首次将多智能体RL应用于模拟布局自动化。与基于模拟退火的非ML方法相比，该方法在变异性能方面表现出色，实现了比现有最先进技术更好的优化结果。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "2 pages, 3 figures, Proceedings of the 62nd ACM/IEEE Design\n  Automation Conference (DAC), 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.22958v3",
      "published_date": "2025-03-29 03:13:56 UTC",
      "updated_date": "2025-04-10 19:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:30:00.151116"
    },
    {
      "arxiv_id": "2504.08755v1",
      "title": "Delving into: the quantification of Ai-generated content on the internet (synthetic data)",
      "title_zh": "翻译失败",
      "authors": [
        "Dirk HR Spennemann"
      ],
      "abstract": "While it is increasingly evident that the internet is becoming saturated with\ncontent created by generated Ai large language models, accurately measuring the\nscale of this phenomenon has proven challenging. By analyzing the frequency of\nspecific keywords commonly used by ChatGPT, this paper demonstrates that such\nlinguistic markers can effectively be used to esti-mate the presence of\ngenerative AI content online. The findings suggest that at least 30% of text on\nactive web pages originates from AI-generated sources, with the actual\nproportion likely ap-proaching 40%. Given the implications of autophagous\nloops, this is a sobering realization.",
      "tldr_zh": "本研究探讨了互联网上 AI 生成内容（synthetic data）的量化问题，通过分析 ChatGPT 等 AI 模型常用的特定关键词作为标记，来估计其在线文本比例。结果显示，至少 30% 的活跃网页文本来源于 AI 生成源，实际比例可能接近 40%。这一发现突显了自噬循环（autophagous loops）的潜在风险，可能导致 AI 内容进一步泛滥并影响信息生态。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pp",
      "pdf_url": "http://arxiv.org/pdf/2504.08755v1",
      "published_date": "2025-03-29 03:06:53 UTC",
      "updated_date": "2025-03-29 03:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:30:13.695195"
    },
    {
      "arxiv_id": "2503.22954v1",
      "title": "Can LLMs Support Medical Knowledge Imputation? An Evaluation-Based Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Yao",
        "Aditya Sannabhadti",
        "Holly Wiberg",
        "Karmel S. Shehadeh",
        "Rema Padman"
      ],
      "abstract": "Medical knowledge graphs (KGs) are essential for clinical decision support\nand biomedical research, yet they often exhibit incompleteness due to knowledge\ngaps and structural limitations in medical coding systems. This issue is\nparticularly evident in treatment mapping, where coding systems such as ICD,\nMondo, and ATC lack comprehensive coverage, resulting in missing or\ninconsistent associations between diseases and their potential treatments. To\naddress this issue, we have explored the use of Large Language Models (LLMs)\nfor imputing missing treatment relationships. Although LLMs offer promising\ncapabilities in knowledge augmentation, their application in medical knowledge\nimputation presents significant risks, including factual inaccuracies,\nhallucinated associations, and instability between and within LLMs. In this\nstudy, we systematically evaluate LLM-driven treatment mapping, assessing its\nreliability through benchmark comparisons. Our findings highlight critical\nlimitations, including inconsistencies with established clinical guidelines and\npotential risks to patient safety. This study serves as a cautionary guide for\nresearchers and practitioners, underscoring the importance of critical\nevaluation and hybrid approaches when leveraging LLMs to enhance treatment\nmappings on medical knowledge graphs.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在填补医疗知识图谱（KGs）中缺失治疗关系的能力，特别是在 ICD、Mondo 和 ATC 等编码系统覆盖不足的问题上。研究通过基准比较系统地检验了 LLMs 的可靠性，发现其存在事实不准确、幻觉关联和内部不稳定性等问题，导致与临床指南不一致并可能威胁患者安全。最终，该研究作为警示指南，强调在使用 LLMs 增强治疗映射时，需要进行批判性评估并采用混合方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures, AMIA",
      "pdf_url": "http://arxiv.org/pdf/2503.22954v1",
      "published_date": "2025-03-29 02:52:17 UTC",
      "updated_date": "2025-03-29 02:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:30:24.719377"
    },
    {
      "arxiv_id": "2503.22948v1",
      "title": "SUV: Scalable Large Language Model Copyright Compliance with Regularized Selective Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyang Xu",
        "Xiaoze Liu",
        "Feijie Wu",
        "Xiaoqian Wang",
        "Jing Gao"
      ],
      "abstract": "Large Language Models (LLMs) have transformed natural language processing by\nlearning from massive datasets, yet this rapid progress has also drawn legal\nscrutiny, as the ability to unintentionally generate copyrighted content has\nalready prompted several prominent lawsuits. In this work, we introduce SUV\n(Selective Unlearning for Verbatim data), a selective unlearning framework\ndesigned to prevent LLM from memorizing copyrighted content while preserving\nits overall utility. In detail, the proposed method constructs a dataset that\ncaptures instances of copyrighted infringement cases by the targeted LLM. With\nthe dataset, we unlearn the content from the LLM by means of Direct Preference\nOptimization (DPO), which replaces the verbatim copyrighted content with\nplausible and coherent alternatives. Since DPO may hinder the LLM's performance\nin other unrelated tasks, we integrate gradient projection and Fisher\ninformation regularization to mitigate the degradation. We validate our\napproach using a large-scale dataset of 500 famous books (predominantly\ncopyrighted works) and demonstrate that SUV significantly reduces verbatim\nmemorization with negligible impact on the performance on unrelated tasks.\nExtensive experiments on both our dataset and public benchmarks confirm the\nscalability and efficacy of our approach, offering a promising solution for\nmitigating copyright risks in real-world LLM applications.",
      "tldr_zh": "本文提出 SUV 框架，这是一种可扩展的选择性遗忘方法，用于帮助大型语言模型(LLMs)遵守版权法规，通过 Direct Preference Optimization (DPO) 替换受版权保护的内容，同时使用 gradient projection 和 Fisher information regularization 来最小化对无关任务的影响。方法首先构建数据集捕捉 LLM 的侵权实例，并通过正则化确保模型的整体性能不受损害。在包含 500 本著名书籍的大规模实验中，SUV 显著减少了逐字记忆，同时在公共基准上验证了其有效性，为实际 LLM 应用缓解版权风险提供了可行解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.22948v1",
      "published_date": "2025-03-29 02:33:26 UTC",
      "updated_date": "2025-03-29 02:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:30:37.463971"
    },
    {
      "arxiv_id": "2503.22946v1",
      "title": "DATAWEAVER: Authoring Data-Driven Narratives through the Integrated Composition of Visualization and Text",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Fu",
        "Dennis Bromley",
        "Vidya Setlur"
      ],
      "abstract": "Data-driven storytelling has gained prominence in journalism and other data\nreporting fields. However, the process of creating these stories remains\nchallenging, often requiring the integration of effective visualizations with\ncompelling narratives to form a cohesive, interactive presentation. To help\nstreamline this process, we present an integrated authoring framework and\nsystem, DataWeaver, that supports both visualization-to-text and\ntext-to-visualization composition. DataWeaver enables users to create data\nnarratives anchored to data facts derived from \"call-out\" interactions, i.e.,\nuser-initiated highlights of visualization elements that prompt relevant\nnarrative content. In addition to this \"vis-to-text\" composition, DataWeaver\nalso supports a \"text-initiated\" approach, generating relevant interactive\nvisualizations from existing narratives. Key findings from an evaluation with\n13 participants highlighted the utility and usability of DataWeaver and the\neffectiveness of its integrated authoring framework. The evaluation also\nrevealed opportunities to enhance the framework by refining filtering\nmechanisms and visualization recommendations and better support authoring\ncreativity by introducing advanced customization options.",
      "tldr_zh": "本文提出 DataWeaver，一个集成式创作框架和系统，用于简化数据驱动叙事的过程，通过 visualization-to-text 和 text-to-visualization 的双向组成整合可视化和文本。用户可以通过 call-out interactions 高亮可视化元素来生成锚定数据事实的叙述内容，或从现有文本自动创建相关交互式可视化。评估结果显示，该系统在13名参与者中表现出良好的实用性和可用性，但建议进一步优化过滤机制、可视化推荐和高级自定义选项以提升创作创意。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.2; I.3.6"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to EuroVis 2025. Published in Computer Graphics Forum. DOI:\n  10.1111/cgf.70098",
      "pdf_url": "http://arxiv.org/pdf/2503.22946v1",
      "published_date": "2025-03-29 02:33:03 UTC",
      "updated_date": "2025-03-29 02:33:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:30:48.760949"
    },
    {
      "arxiv_id": "2503.22942v1",
      "title": "Adaptive Interactive Navigation of Quadruped Robots using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kangjie Zhou",
        "Yao Mu",
        "Haoyang Song",
        "Yi Zeng",
        "Pengying Wu",
        "Han Gao",
        "Chang Liu"
      ],
      "abstract": "Robotic navigation in complex environments remains a critical research\nchallenge. Traditional navigation methods focus on optimal trajectory\ngeneration within free space, struggling in environments lacking viable paths\nto the goal, such as disaster zones or cluttered warehouses. To address this\ngap, we propose an adaptive interactive navigation approach that proactively\ninteracts with environments to create feasible paths to reach originally\nunavailable goals. Specifically, we present a primitive tree for task planning\nwith large language models (LLMs), facilitating effective reasoning to\ndetermine interaction objects and sequences. To ensure robust subtask\nexecution, we adopt reinforcement learning to pre-train a comprehensive skill\nlibrary containing versatile locomotion and interaction behaviors for motion\nplanning. Furthermore, we introduce an adaptive replanning method featuring two\nLLM-based modules: an advisor serving as a flexible replanning trigger and an\narborist for autonomous plan adjustment. Integrated with the tree structure,\nthe replanning mechanism allows for convenient node addition and pruning,\nenabling rapid plan modification in unknown environments. Comprehensive\nsimulations and experiments have demonstrated our method's effectiveness and\nadaptivity in diverse scenarios. The supplementary video is available at page:\nhttps://youtu.be/W5ttPnSap2g.",
      "tldr_zh": "这篇论文针对四足机器人（quadruped robots）在复杂环境（如灾难区或杂乱仓库）中的导航挑战，提出了一种自适应交互导航方法，利用 Large Language Models (LLMs) 进行任务规划，以主动与环境互动创建可行路径。方法包括构建 primitive tree 用于推理交互对象和序列，结合 reinforcement learning 预训练的技能库来执行运动和交互行为，并引入 advisor 和 arborist 模块进行灵活的重新规划。实验结果通过全面模拟和实际测试证明了该方法的有效性和适应性，在未知环境中实现了快速计划调整。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.22942v1",
      "published_date": "2025-03-29 02:17:52 UTC",
      "updated_date": "2025-03-29 02:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:31:01.494533"
    },
    {
      "arxiv_id": "2503.22941v1",
      "title": "Identifying Multi-modal Knowledge Neurons in Pretrained Transformers via Two-stage Filtering",
      "title_zh": "通过两阶段过滤识别预训练Transformer中的多模态知识神经元",
      "authors": [
        "Yugen Sato",
        "Tomohiro Takagi"
      ],
      "abstract": "Recent advances in large language models (LLMs) have led to the development\nof multimodal LLMs (MLLMs) in the fields of natural language processing (NLP)\nand computer vision. Although these models allow for integrated visual and\nlanguage understanding, they present challenges such as opaque internal\nprocessing and the generation of hallucinations and misinformation. Therefore,\nthere is a need for a method to clarify the location of knowledge in MLLMs.\n  In this study, we propose a method to identify neurons associated with\nspecific knowledge using MiniGPT-4, a Transformer-based MLLM. Specifically, we\nextract knowledge neurons through two stages: activation differences filtering\nusing inpainting and gradient-based filtering using GradCAM. Experiments on the\nimage caption generation task using the MS COCO 2017 dataset, BLEU, ROUGE, and\nBERTScore quantitative evaluation, and qualitative evaluation using an\nactivation heatmap showed that our method is able to locate knowledge with\nhigher accuracy than existing methods.\n  This study contributes to the visualization and explainability of knowledge\nin MLLMs and shows the potential for future knowledge editing and control.",
      "tldr_zh": "本文提出了一种通过两阶段过滤方法来识别预训练 Transformer 中多模态知识神经元（knowledge neurons）的技术，针对多模态大语言模型（MLLMs）如 MiniGPT-4 面临的内部处理不透明和生成幻觉等问题。方法包括第一阶段使用 inpainting 的激活差异过滤，以及第二阶段使用 GradCAM 的梯度-based 过滤，以精确定位特定知识相关的神经元。在 MS COCO 2017 数据集的图像标题生成任务中，实验通过 BLEU、ROUGE 和 BERTScore 等指标显示，该方法比现有方法准确性更高，并通过激活热图进行定性验证。该研究增强了 MLLMs 的可视化和可解释性，为未来的知识编辑和控制奠定基础。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.22941v1",
      "published_date": "2025-03-29 02:16:15 UTC",
      "updated_date": "2025-03-29 02:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:31:13.870390"
    },
    {
      "arxiv_id": "2503.22934v1",
      "title": "FairSAM: Fair Classification on Corrupted Data Through Sharpness-Aware Minimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yucong Dai",
        "Jie Ji",
        "Xiaolong Ma",
        "Yongkai Wu"
      ],
      "abstract": "Image classification models trained on clean data often suffer from\nsignificant performance degradation when exposed to testing corrupted data,\nsuch as images with impulse noise, Gaussian noise, or environmental noise. This\ndegradation not only impacts overall performance but also disproportionately\naffects various demographic subgroups, raising critical algorithmic bias\nconcerns. Although robust learning algorithms like Sharpness-Aware Minimization\n(SAM) have shown promise in improving overall model robustness and\ngeneralization, they fall short in addressing the biased performance\ndegradation across demographic subgroups. Existing fairness-aware machine\nlearning methods - such as fairness constraints and reweighing strategies - aim\nto reduce performance disparities but hardly maintain robust and equitable\naccuracy across demographic subgroups when faced with data corruption. This\nreveals an inherent tension between robustness and fairness when dealing with\ncorrupted data. To address these challenges, we introduce one novel metric\nspecifically designed to assess performance degradation across subgroups under\ndata corruption. Additionally, we propose \\textbf{FairSAM}, a new framework\nthat integrates \\underline{Fair}ness-oriented strategies into \\underline{SAM}\nto deliver equalized performance across demographic groups under corrupted\nconditions. Our experiments on multiple real-world datasets and various\npredictive tasks show that FairSAM successfully reconciles robustness and\nfairness, offering a structured solution for equitable and resilient image\nclassification in the presence of data corruption.",
      "tldr_zh": "本研究发现，图像分类模型在干净数据上训练后，面对损坏数据（如噪声）时性能显著下降，且对不同人口统计子群体的影响不均等，导致算法偏见问题。现有方法如 Sharpness-Aware Minimization (SAM) 虽能提升整体鲁棒性和泛化，但无法缓解子群体间的偏见，而传统公平策略也难以在数据损坏条件下维持公平准确率。为解决这一鲁棒性与公平性的张力，论文引入一个新指标评估子群体性能下降，并提出 FairSAM 框架，将公平策略整合到 SAM 中，实现损坏数据下的均衡性能。在多真实数据集和任务实验中，FairSAM 成功调和了鲁棒性和公平性，提供了一个可靠的图像分类解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.22934v1",
      "published_date": "2025-03-29 01:51:59 UTC",
      "updated_date": "2025-03-29 01:51:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:31:25.673541"
    },
    {
      "arxiv_id": "2503.22931v2",
      "title": "Factored Agents: Decoupling In-Context Learning and Memorization for Robust Tool Use",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Roth",
        "Christopher Hidey",
        "Lucas Spangher",
        "William F. Arnold",
        "Chang Ye",
        "Nick Masiewicki",
        "Jinoo Baek",
        "Peter Grabowski",
        "Eugene Ie"
      ],
      "abstract": "In this paper, we propose a novel factored agent architecture designed to\novercome the limitations of traditional single-agent systems in agentic AI. Our\napproach decomposes the agent into two specialized components: (1) a large\nlanguage model (LLM) that serves as a high level planner and in-context\nlearner, which may use dynamically available information in user prompts, (2) a\nsmaller language model which acts as a memorizer of tool format and output.\nThis decoupling addresses prevalent issues in monolithic designs, including\nmalformed, missing, and hallucinated API fields, as well as suboptimal planning\nin dynamic environments. Empirical evaluations demonstrate that our factored\narchitecture significantly improves planning accuracy and error resilience,\nwhile elucidating the inherent trade-off between in-context learning and static\nmemorization. These findings suggest that a factored approach is a promising\npathway for developing more robust and adaptable agentic AI systems.",
      "tldr_zh": "本文提出了一种名为factored agents的代理架构，通过解耦in-context learning和memorization，旨在提升代理AI在工具使用中的鲁棒性。该架构将大型语言模型(LLM)作为高层规划者和in-context learner，利用动态信息进行决策，而较小语言模型则负责工具格式和输出的静态memorization。这种设计有效解决了传统单代理系统的常见问题，如API字段的错误、缺失或幻觉，以及在动态环境中的规划不足。实验评估表明，该方法显著提高了规划准确性和错误恢复能力，并揭示了in-context learning与static memorization之间的权衡，为构建更可靠和适应的代理AI系统提供了新路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.22931v2",
      "published_date": "2025-03-29 01:27:11 UTC",
      "updated_date": "2025-04-02 04:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:31:37.795815"
    },
    {
      "arxiv_id": "2503.22925v2",
      "title": "Predictive Traffic Rule Compliance using Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yanliang Huang",
        "Sebastian Mair",
        "Zhuoqi Zeng",
        "Matthias Althoff"
      ],
      "abstract": "Autonomous vehicle path planning has reached a stage where safety and\nregulatory compliance are crucial. This paper presents an approach that\nintegrates a motion planner with a deep reinforcement learning model to predict\npotential traffic rule violations. Our main innovation is replacing the\nstandard actor network in an actor-critic method with a motion planning module,\nwhich ensures both stable and interpretable trajectory generation. In this\nsetup, we use traffic rule robustness as the reward to train a reinforcement\nlearning agent's critic, and the output of the critic is directly used as the\ncost function of the motion planner, which guides the choices of the\ntrajectory. We incorporate some key interstate rules from the German Road\nTraffic Regulation into a rule book and use a graph-based state representation\nto handle complex traffic information. Experiments on an open German highway\ndataset show that the model can predict and prevent traffic rule violations\nbeyond the planning horizon, increasing safety and rule compliance in\nchallenging traffic scenarios.",
      "tldr_zh": "这篇论文提出了一种整合运动规划(Motion Planner)和深度强化学习(Reinforcement Learning)的方法，用于预测和防止自主车辆的交通规则违规。创新点在于将标准 actor-critic 方法中的 actor 网络替换为运动规划模块，并使用交通规则鲁棒性作为奖励训练 critic 网络，其输出直接作为运动规划器的成本函数指导轨迹选择。实验在德国高速公路数据集上表明，该模型能超出规划视野预测并避免违规，提高了车辆的安全性和合规性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9; I.2.6"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages, 7 figures. Preprint intended for submission to IEEE ITSC\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2503.22925v2",
      "published_date": "2025-03-29 01:04:08 UTC",
      "updated_date": "2025-04-04 14:28:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:31:49.143654"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 65,
  "processed_papers_count": 65,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T07:32:07.872335"
}