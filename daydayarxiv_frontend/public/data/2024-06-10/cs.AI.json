{
  "date": "2024-06-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-10 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 112 篇论文，主要聚焦 AI 模型的安全性、多模态处理、强化学习和医疗应用等领域。其中，令人印象深刻的包括 Merlin 和 Towards a Personal Health Large Language Model 等医疗 AI 论文，它们展示了大型语言模型 (LLMs) 在实际应用中的潜力；同时，有名学者如 Peter Clark 和 Arman Cohan 参与的 SciRIFF 数据集论文，也突出了科学文献理解的创新。以下我将挑选并简要讨论部分关键论文，先聊重要或话题度高的，其余快速掠过。\n\n### 关键论文讨论\n\n**1. 大语言模型的后门攻击与防御调查 (A Survey of Recent Backdoor Attacks and Defenses in Large Language Models)**  \n这篇由 Jie Fu 和其他作者的综述论文系统地分类了针对 LLMs 的后门攻击，聚焦于 fine-tuning 方法，包括全参数、参数高效和无 fine-tuning 类别。主要贡献是揭示攻击趋势，并提出未来研究方向，如开发无需 fine-tuning 的隐蔽攻击算法。该论文强调了 LLMs 安全性的潜在风险，对 AI 部署有重要启示。\n\n**5. LLM辅助的易触发后门攻击：针对代码补全模型注入伪装漏洞 (An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models)**  \nShenao Yan 等作者的论文提出 CodeBreaker 框架，利用 LLMs（如 GPT-4）在代码补全模型中注入后门攻击。主要发现是，该方法能绕过强检测机制，生成功能正常但易被触发的漏洞代码。该工作揭示了代码生成 AI 的安全隐患，并为更鲁棒的防御提供新思路，具有实际应用话题度。\n\n**6. SciRIFF：用于提升语言模型科学文献指令遵循的资源 (SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature)**  \n由 Peter Clark、Arman Cohan 等知名学者领导的论文，引入一个包含 13.7 万演示的 SciRIFF 数据集，覆盖信息提取、总结、问答等任务。主要贡献是开发 SciTulu 模型，通过混合微调提升科学任务性能，平均在 9 个任务上比基线提高 28.1%。这为 LLMs 在科学领域的应用提供了高效基准，令人印象深刻。\n\n**24. Merlin：用于 3D 计算机断层扫描的视觉语言基础模型 (Merlin: A Vision Language Foundation Model for 3D Computed Tomography)**  \nAkshay S. Chaudhari 等作者的论文提出 Merlin 模型，用于 3D CT 图像分析，训练于海量配对数据。主要发现是，Merlin 在多任务（如疾病预测和报告生成）上超越基线，提升了医疗图像理解。该工作展示了多模态 AI 在临床中的潜力，应用价值高。\n\n**30. 迈向个人健康大型语言模型 (Towards a Personal Health Large Language Model)**  \n由 Shwetak Patel 和 Cory Y. McLean 等人合作，提出 PH-LLM 模型，针对可穿戴设备数据进行健康洞见生成。主要贡献是通过微调提升模型在睡眠和健身任务上的性能，实验显示在多个基准上优于传统方法。该论文强调 AI 在个性化健康监测中的作用，结合实际数据，具有显著的社会影响。\n\n**32. Husky：用于多步推理的统一开源语言代理 (Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning)**  \nHannaneh Hajishirzi 等作者的论文引入 Husky 代理，支持多模态任务如图像和文本推理。主要发现是，它在 14 个数据集上超越基线，提升了零样本泛化。该工作为开源 LLMs 提供了实用框架，易于扩展。\n\n其他论文中，如强化学习领域的 **4. Locally Interdependent Multi-Agent MDP (Locally Interdependent Multi-Agent MDP)** 和 **8. PlanDQ (PlanDQ)**，它们提出新的多代理决策框架和层次规划方法，提升了任务鲁棒性，但相对专业，我这里快速掠过。图像处理论文如 **22. IllumiNeRF (IllumiNeRF)** 和 **34. An Elliptic Kernel Unsupervised Autoencoder-Graph Convolutional Network (An Elliptic Kernel Unsupervised Autoencoder-Graph Convolutional Network)**，分别在 3D 重照明和光谱解混上取得进展，但不为核心焦点，仅提及其方法创新。\n\n总之，今天的论文突出了 AI 在安全和实际应用中的挑战与机遇，建议关注 LLMs 的医疗和科学扩展。更多细节可查阅 arXiv。明天见！",
  "papers": [
    {
      "arxiv_id": "2406.06852v5",
      "title": "A Survey of Recent Backdoor Attacks and Defenses in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Zhao",
        "Meihuizi Jia",
        "Zhongliang Guo",
        "Leilei Gan",
        "Xiaoyu Xu",
        "Xiaobao Wu",
        "Jie Fu",
        "Yichao Feng",
        "Fengjun Pan",
        "Luu Anh Tuan"
      ],
      "abstract": "Large Language Models (LLMs), which bridge the gap between human language\nunderstanding and complex problem-solving, achieve state-of-the-art performance\non several NLP tasks, particularly in few-shot and zero-shot settings. Despite\nthe demonstrable efficacy of LLMs, due to constraints on computational\nresources, users have to engage with open-source language models or outsource\nthe entire training process to third-party platforms. However, research has\ndemonstrated that language models are susceptible to potential security\nvulnerabilities, particularly in backdoor attacks. Backdoor attacks are\ndesigned to introduce targeted vulnerabilities into language models by\npoisoning training samples or model weights, allowing attackers to manipulate\nmodel responses through malicious triggers. While existing surveys on backdoor\nattacks provide a comprehensive overview, they lack an in-depth examination of\nbackdoor attacks specifically targeting LLMs. To bridge this gap and grasp the\nlatest trends in the field, this paper presents a novel perspective on backdoor\nattacks for LLMs by focusing on fine-tuning methods. Specifically, we\nsystematically classify backdoor attacks into three categories: full-parameter\nfine-tuning, parameter-efficient fine-tuning, and no fine-tuning Based on\ninsights from a substantial review, we also discuss crucial issues for future\nresearch on backdoor attacks, such as further exploring attack algorithms that\ndo not require fine-tuning, or developing more covert attack algorithms.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）中的后门攻击和防御进行了最新调查，强调了LLMs在处理NLP任务时面临的潜在安全风险，如通过污染训练样本或模型权重引入的恶意触发。论文从微调方法的角度系统分类后门攻击为三类：full-parameter fine-tuning、parameter-efficient fine-tuning 和 no fine-tuning，并分析了现有研究的不足。最终，它提出了未来研究方向，包括探索无需微调的攻击算法和开发更隐蔽的攻击策略，以提升LLMs的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted in TMLR",
      "pdf_url": "http://arxiv.org/pdf/2406.06852v5",
      "published_date": "2024-06-10 23:54:21 UTC",
      "updated_date": "2025-01-04 13:39:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:08:43.839876"
    },
    {
      "arxiv_id": "2406.06848v1",
      "title": "Taxes Are All You Need: Integration of Taxonomical Hierarchy Relationships into the Contrastive Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Kiran Kokilepersaud",
        "Yavuz Yarici",
        "Mohit Prabhushankar",
        "Ghassan AlRegib"
      ],
      "abstract": "In this work, we propose a novel supervised contrastive loss that enables the\nintegration of taxonomic hierarchy information during the representation\nlearning process. A supervised contrastive loss operates by enforcing that\nimages with the same class label (positive samples) project closer to each\nother than images with differing class labels (negative samples). The advantage\nof this approach is that it directly penalizes the structure of the\nrepresentation space itself. This enables greater flexibility with respect to\nencoding semantic concepts. However, the standard supervised contrastive loss\nonly enforces semantic structure based on the downstream task (i.e. the class\nlabel). In reality, the class label is only one level of a \\emph{hierarchy of\ndifferent semantic relationships known as a taxonomy}. For example, the class\nlabel is oftentimes the species of an animal, but between different classes\nthere are higher order relationships such as all animals with wings being\n``birds\". We show that by explicitly accounting for these relationships with a\nweighting penalty in the contrastive loss we can out-perform the supervised\ncontrastive loss. Additionally, we demonstrate the adaptability of the notion\nof a taxonomy by integrating our loss into medical and noise-based settings\nthat show performance improvements by as much as 7%.",
      "tldr_zh": "我们提出了一种新型的 supervised contrastive loss，通过在损失函数中整合 taxonomic hierarchy 关系（即类标签之间的层次结构），来提升表示学习（representation learning）的性能。该方法通过添加权重惩罚（weighting penalty），确保正样本和负样本的投影更准确地反映语义层次关系，例如动物分类中的物种和更高阶关系。实验结果表明，该方法在标准 supervised contrastive loss 的基础上表现出色，并在医疗和噪声环境等应用中性能提升多达 7%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at IEEE International Conference on Image Processing",
      "pdf_url": "http://arxiv.org/pdf/2406.06848v1",
      "published_date": "2024-06-10 23:36:58 UTC",
      "updated_date": "2024-06-10 23:36:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:08:55.661800"
    },
    {
      "arxiv_id": "2406.06838v1",
      "title": "Stable Minima Cannot Overfit in Univariate ReLU Networks: Generalization by Large Step Sizes",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Qiao",
        "Kaiqi Zhang",
        "Esha Singh",
        "Daniel Soudry",
        "Yu-Xiang Wang"
      ],
      "abstract": "We study the generalization of two-layer ReLU neural networks in a univariate\nnonparametric regression problem with noisy labels. This is a problem where\nkernels (\\emph{e.g.} NTK) are provably sub-optimal and benign overfitting does\nnot happen, thus disqualifying existing theory for interpolating (0-loss,\nglobal optimal) solutions. We present a new theory of generalization for local\nminima that gradient descent with a constant learning rate can \\emph{stably}\nconverge to. We show that gradient descent with a fixed learning rate $\\eta$\ncan only find local minima that represent smooth functions with a certain\nweighted \\emph{first order total variation} bounded by $1/\\eta - 1/2 +\n\\widetilde{O}(\\sigma + \\sqrt{\\mathrm{MSE}})$ where $\\sigma$ is the label noise\nlevel, $\\mathrm{MSE}$ is short for mean squared error against the ground truth,\nand $\\widetilde{O}(\\cdot)$ hides a logarithmic factor. Under mild assumptions,\nwe also prove a nearly-optimal MSE bound of $\\widetilde{O}(n^{-4/5})$ within\nthe strict interior of the support of the $n$ data points. Our theoretical\nresults are validated by extensive simulation that demonstrates large learning\nrate training induces sparse linear spline fits. To the best of our knowledge,\nwe are the first to obtain generalization bound via minima stability in the\nnon-interpolation case and the first to show ReLU NNs without regularization\ncan achieve near-optimal rates in nonparametric regression.",
      "tldr_zh": "这篇论文研究了单变量非参数回归问题中，双层 ReLU 神经网络的泛化性能，特别是在存在噪声标签的情况下，证明了梯度下降算法通过大步长（固定学习率 η）能稳定收敛到不会过拟合的局部最小值。论文提出，这些局部最小值代表平滑函数，其加权一阶总变差被限制在 1/η - 1/2 + Õ(σ + √MSE) 的范围内，并在温和假设下获得近似最优的 MSE 界，为 Õ(n^{-4/5})。实验验证显示，大学习率训练诱导稀疏线性样条拟合，这是首次通过最小值稳定性在非插值场景下实现无正则化 ReLU NN 的近优泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "51 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.06838v1",
      "published_date": "2024-06-10 22:57:27 UTC",
      "updated_date": "2024-06-10 22:57:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:09:12.208090"
    },
    {
      "arxiv_id": "2406.06823v1",
      "title": "Locally Interdependent Multi-Agent MDP: Theoretical Framework for Decentralized Agents with Dynamic Dependencies",
      "title_zh": "翻译失败",
      "authors": [
        "Alex DeWeese",
        "Guannan Qu"
      ],
      "abstract": "Many multi-agent systems in practice are decentralized and have dynamically\nvarying dependencies. There has been a lack of attempts in the literature to\nanalyze these systems theoretically. In this paper, we propose and\ntheoretically analyze a decentralized model with dynamically varying\ndependencies called the Locally Interdependent Multi-Agent MDP. This model can\nrepresent problems in many disparate domains such as cooperative navigation,\nobstacle avoidance, and formation control. Despite the intractability that\ngeneral partially observable multi-agent systems suffer from, we propose three\nclosed-form policies that are theoretically near-optimal in this setting and\ncan be scalable to compute and store. Consequentially, we reveal a fundamental\nproperty of Locally Interdependent Multi-Agent MDP's that the partially\nobservable decentralized solution is exponentially close to the fully\nobservable solution with respect to the visibility radius. We then discuss\nextensions of our closed-form policies to further improve tractability. We\nconclude by providing simulations to investigate some long horizon behaviors of\nour closed-form policies.",
      "tldr_zh": "本论文提出Locally Interdependent Multi-Agent MDP框架，用于理论分析分散多智能体系统中的动态依赖关系，该模型适用于领域如合作导航、障碍避免和编队控制。论文针对部分可观察系统的计算挑战，设计了三种可扩展的封闭形式策略，这些策略在理论上近似最优，并揭示了部分可观察解决方案在可见半径方面指数级接近完全可观察解决方案。最终，通过模拟实验探讨了这些策略的长期行为，为实际多智能体系统提供了可扩展的理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to International Conference on Machine Learning 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06823v1",
      "published_date": "2024-06-10 22:11:00 UTC",
      "updated_date": "2024-06-10 22:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:09:20.105976"
    },
    {
      "arxiv_id": "2406.06822v1",
      "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Shenao Yan",
        "Shen Wang",
        "Yue Duan",
        "Hanbin Hong",
        "Kiho Lee",
        "Doowon Kim",
        "Yuan Hong"
      ],
      "abstract": "Large Language Models (LLMs) have transformed code completion tasks,\nproviding context-based suggestions to boost developer productivity in software\nengineering. As users often fine-tune these models for specific applications,\npoisoning and backdoor attacks can covertly alter the model outputs. To address\nthis critical security challenge, we introduce CodeBreaker, a pioneering\nLLM-assisted backdoor attack framework on code completion models. Unlike recent\nattacks that embed malicious payloads in detectable or irrelevant sections of\nthe code (e.g., comments), CodeBreaker leverages LLMs (e.g., GPT-4) for\nsophisticated payload transformation (without affecting functionalities),\nensuring that both the poisoned data for fine-tuning and generated code can\nevade strong vulnerability detection. CodeBreaker stands out with its\ncomprehensive coverage of vulnerabilities, making it the first to provide such\nan extensive set for evaluation. Our extensive experimental evaluations and\nuser studies underline the strong attack performance of CodeBreaker across\nvarious settings, validating its superiority over existing approaches. By\nintegrating malicious payloads directly into the source code with minimal\ntransformation, CodeBreaker challenges current security measures, underscoring\nthe critical need for more robust defenses for code completion.",
      "tldr_zh": "本文提出 CodeBreaker，一种基于 LLM（如 GPT-4）的后门攻击框架，针对代码补全模型注入伪装漏洞，能够规避强检测机制，同时不影响代码功能。不同于传统攻击将恶意负载置于易检测位置，CodeBreaker 通过 LLM 辅助的负载转换，实现对多种漏洞的全面覆盖。实验评估和用户研究显示，该框架在各种场景下优于现有方法，突显了代码补全模型安全风险的紧迫性，并呼吁开发更robust的防御措施。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in USENIX Security '24",
      "pdf_url": "http://arxiv.org/pdf/2406.06822v1",
      "published_date": "2024-06-10 22:10:05 UTC",
      "updated_date": "2024-06-10 22:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:09:31.052734"
    },
    {
      "arxiv_id": "2406.07835v3",
      "title": "SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature",
      "title_zh": "SciRIFF：一种用于增强语言模型在科学文献中指令遵循能力的资源",
      "authors": [
        "David Wadden",
        "Kejian Shi",
        "Jacob Morrison",
        "Aakanksha Naik",
        "Shruti Singh",
        "Nitzan Barzilay",
        "Kyle Lo",
        "Tom Hope",
        "Luca Soldaini",
        "Shannon Zejiang Shen",
        "Doug Downey",
        "Hannaneh Hajishirzi",
        "Arman Cohan"
      ],
      "abstract": "We present SciRIFF (Scientific Resource for Instruction-Following and\nFinetuning), a dataset of 137K instruction-following demonstrations for 54\ntasks covering five essential scientific literature understanding capabilities:\ninformation extraction, summarization, question answering, claim verification,\nand classification. SciRIFF demonstrations are notable for their long input\ncontexts, detailed task specifications, and complex structured outputs. While\ninstruction-following resources are available in specific domains such as\nclinical medicine and chemistry, SciRIFF is the first dataset focused on\nextracting and synthesizing information from research literature across a wide\nrange of scientific fields. To demonstrate the utility of SciRIFF, we develop a\nsample-efficient strategy to adapt a general instruction-following model for\nscience by performing additional finetuning on a mix of general-domain and\nSciRIFF demonstrations. In evaluations on nine held-out scientific tasks, our\nmodel -- called SciTulu -- improves over a strong LLM baseline by 28.1% and\n6.5% at the 7B and 70B scales respectively, while maintaining general\ninstruction-following performance within 2% of the baseline. We are optimistic\nthat SciRIFF will facilitate the development and evaluation of LLMs to help\nresearchers navigate the ever-growing body of scientific literature. We release\nour dataset, model checkpoints, and data processing and evaluation code to\nenable further research.",
      "tldr_zh": "该论文介绍了 SciRIFF 数据集，这是一个包含 137K 指令-following 演示的资源，针对 54 个任务，涵盖信息 extraction、summarization、question answering、claim verification 和 classification 等五种科学文献理解能力。SciRIFF 的创新在于其长输入上下文、详细任务规范和复杂结构化输出，是首个专注于跨科学领域文献提取和合成的数据集。研究者通过样本高效的 finetuning 策略，将一般 instruction-following 模型适应科学领域，开发出 SciTulu 模型，在九个留出任务上分别比基线 LLM 提升 28.1%（7B 规模）和 6.5%（70B 规模），同时保持一般性能仅下降 2%。该工作发布了数据集、模型检查点和代码，以促进 LLM 在科学文献导航中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to NeurIPS Datasets and Benchmarks 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.07835v3",
      "published_date": "2024-06-10 21:22:08 UTC",
      "updated_date": "2024-08-20 01:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:09:45.277235"
    },
    {
      "arxiv_id": "2406.06796v1",
      "title": "FlexLoc: Conditional Neural Networks for Zero-Shot Sensor Perspective Invariance in Object Localization with Distributed Multimodal Sensors",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Wu",
        "Ziqi Wang",
        "Xiaomin Ouyang",
        "Ho Lyun Jeong",
        "Colin Samplawski",
        "Lance Kaplan",
        "Benjamin Marlin",
        "Mani Srivastava"
      ],
      "abstract": "Localization is a critical technology for various applications ranging from\nnavigation and surveillance to assisted living. Localization systems typically\nfuse information from sensors viewing the scene from different perspectives to\nestimate the target location while also employing multiple modalities for\nenhanced robustness and accuracy. Recently, such systems have employed\nend-to-end deep neural models trained on large datasets due to their superior\nperformance and ability to handle data from diverse sensor modalities. However,\nsuch neural models are often trained on data collected from a particular set of\nsensor poses (i.e., locations and orientations). During real-world deployments,\nslight deviations from these sensor poses can result in extreme inaccuracies.\nTo address this challenge, we introduce FlexLoc, which employs conditional\nneural networks to inject node perspective information to adapt the\nlocalization pipeline. Specifically, a small subset of model weights are\nderived from node poses at run time, enabling accurate generalization to unseen\nperspectives with minimal additional overhead. Our evaluations on a multimodal,\nmultiview indoor tracking dataset showcase that FlexLoc improves the\nlocalization accuracy by almost 50% in the zero-shot case (no calibration data\navailable) compared to the baselines. The source code of FlexLoc is available\nat https://github.com/nesl/FlexLoc.",
      "tldr_zh": "该论文提出FlexLoc，一种基于条件神经网络(Conditional Neural Networks)的框架，旨在解决分布式多模态传感器在物体定位任务中对传感器视角变化的敏感性问题。FlexLoc通过在运行时从节点姿势派生一小部分模型权重，实现零样本(Zero-Shot)泛化，从而使定位系统适应未见视角，而无需额外校准。在多模态多视图室内跟踪数据集上的评估显示，FlexLoc在零样本场景下比基线模型提高了近50%的定位准确性，为鲁棒性更强的定位应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06796v1",
      "published_date": "2024-06-10 21:02:53 UTC",
      "updated_date": "2024-06-10 21:02:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:09:54.350057"
    },
    {
      "arxiv_id": "2406.06793v1",
      "title": "PlanDQ: Hierarchical Plan Orchestration via D-Conductor and Q-Performer",
      "title_zh": "PlanDQ：通过 D-Conductor 和 Q-Performer 的层次化计划编排",
      "authors": [
        "Chang Chen",
        "Junyeob Baek",
        "Fei Deng",
        "Kenji Kawaguchi",
        "Caglar Gulcehre",
        "Sungjin Ahn"
      ],
      "abstract": "Despite the recent advancements in offline RL, no unified algorithm could\nachieve superior performance across a broad range of tasks. Offline\n\\textit{value function learning}, in particular, struggles with sparse-reward,\nlong-horizon tasks due to the difficulty of solving credit assignment and\nextrapolation errors that accumulates as the horizon of the task grows.~On the\nother hand, models that can perform well in long-horizon tasks are designed\nspecifically for goal-conditioned tasks, which commonly perform worse than\nvalue function learning methods on short-horizon, dense-reward scenarios. To\nbridge this gap, we propose a hierarchical planner designed for offline RL\ncalled PlanDQ. PlanDQ incorporates a diffusion-based planner at the high level,\nnamed D-Conductor, which guides the low-level policy through sub-goals. At the\nlow level, we used a Q-learning based approach called the Q-Performer to\naccomplish these sub-goals. Our experimental results suggest that PlanDQ can\nachieve superior or competitive performance on D4RL continuous control\nbenchmark tasks as well as AntMaze, Kitchen, and Calvin as long-horizon tasks.",
      "tldr_zh": "本论文提出PlanDQ，一种针对offline RL的层次化规划器，旨在桥接value function learning在稀疏奖励和长时序任务中的挑战，以及其他模型在短时序任务上的局限性。PlanDQ的高层采用D-Conductor（基于扩散的规划器）来生成子目标指导，低层则使用Q-Performer（基于Q-learning的方法）来执行这些子目标。实验结果表明，PlanDQ在D4RL连续控制基准任务以及AntMaze、Kitchen和Calvin等长时序任务上实现了优越或竞争性的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06793v1",
      "published_date": "2024-06-10 20:59:53 UTC",
      "updated_date": "2024-06-10 20:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:10:09.178877"
    },
    {
      "arxiv_id": "2406.06792v2",
      "title": "Reinforced Compressive Neural Architecture Search for Versatile Adversarial Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Dingrong Wang",
        "Hitesh Sapkota",
        "Zhiqiang Tao",
        "Qi Yu"
      ],
      "abstract": "Prior neural architecture search (NAS) for adversarial robustness works have\ndiscovered that a lightweight and adversarially robust neural network\narchitecture could exist in a non-robust large teacher network, generally\ndisclosed by heuristic rules through statistical analysis and neural\narchitecture search, generally disclosed by heuristic rules from neural\narchitecture search. However, heuristic methods cannot uniformly handle\ndifferent adversarial attacks and \"teacher\" network capacity. To solve this\nchallenge, we propose a Reinforced Compressive Neural Architecture Search\n(RC-NAS) for Versatile Adversarial Robustness. Specifically, we define task\nsettings that compose datasets, adversarial attacks, and teacher network\ninformation. Given diverse tasks, we conduct a novel dual-level training\nparadigm that consists of a meta-training and a fine-tuning phase to\neffectively expose the RL agent to diverse attack scenarios (in meta-training),\nand making it adapt quickly to locate a sub-network (in fine-tuning) for any\npreviously unseen scenarios. Experiments show that our framework could achieve\nadaptive compression towards different initial teacher networks, datasets, and\nadversarial attacks, resulting in more lightweight and adversarially robust\narchitectures.",
      "tldr_zh": "本研究针对现有神经架构搜索(NAS)方法在对抗鲁棒性方面的局限性（如依赖启发式规则，无法统一处理不同对抗攻击和教师网络容量），提出了一种Reinforced Compressive Neural Architecture Search (RC-NAS)框架，以实现多任务适应。RC-NAS定义了包括数据集、对抗攻击和教师网络信息的任务设置，并采用双层训练范式：meta-training阶段让强化学习(RL)代理暴露于多样攻击场景中，fine-tuning阶段则快速定位子网络以适应新场景。实验结果表明，该框架能对不同初始教师网络、数据集和对抗攻击进行自适应压缩，生成更轻量级且鲁棒性更强的神经架构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.06792v2",
      "published_date": "2024-06-10 20:59:52 UTC",
      "updated_date": "2024-06-14 03:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:10:20.803046"
    },
    {
      "arxiv_id": "2406.06786v2",
      "title": "BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification",
      "title_zh": "翻译失败",
      "authors": [
        "June-Woo Kim",
        "Miika Toikkanen",
        "Yera Choi",
        "Seoung-Eun Moon",
        "Ho-Young Jung"
      ],
      "abstract": "Respiratory sound classification (RSC) is challenging due to varied acoustic\nsignatures, primarily influenced by patient demographics and recording\nenvironments. To address this issue, we introduce a text-audio multimodal model\nthat utilizes metadata of respiratory sounds, which provides useful\ncomplementary information for RSC. Specifically, we fine-tune a pretrained\ntext-audio multimodal model using free-text descriptions derived from the sound\nsamples' metadata which includes the gender and age of patients, type of\nrecording devices, and recording location on the patient's body. Our method\nachieves state-of-the-art performance on the ICBHI dataset, surpassing the\nprevious best result by a notable margin of 1.17%. This result validates the\neffectiveness of leveraging metadata and respiratory sound samples in enhancing\nRSC performance. Additionally, we investigate the model performance in the case\nwhere metadata is partially unavailable, which may occur in real-world clinical\nsetting.",
      "tldr_zh": "该研究针对呼吸音分类（Respiratory Sound Classification, RSC）的挑战（如声学特征的变异性），提出了一种文本-音频多模态模型（BTS），利用呼吸音元数据（如患者性别、年龄、录制设备和位置）作为补充信息，通过微调预训练模型并使用元数据派生的自由文本描述来提升分类性能。在ICBHI数据集上，该方法实现了state-of-the-art性能，比之前最佳结果提高了1.17%，验证了元数据在RSC中的有效性。此外，研究还探讨了元数据部分不可用时的模型表现，以适应真实临床场景。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06786v2",
      "published_date": "2024-06-10 20:49:54 UTC",
      "updated_date": "2024-06-14 12:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:10:31.308764"
    },
    {
      "arxiv_id": "2406.06777v5",
      "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
      "title_zh": "翻译失败",
      "authors": [
        "Khiem Le",
        "Zhichun Guo",
        "Kaiwen Dong",
        "Xiaobao Huang",
        "Bozhao Nan",
        "Roshni Iyer",
        "Xiangliang Zhang",
        "Olaf Wiest",
        "Wei Wang",
        "Nitesh V. Chawla"
      ],
      "abstract": "Large Language Models (LLMs) with their strong task-handling capabilities\nhave shown remarkable advancements across a spectrum of fields, moving beyond\nnatural language understanding. However, their proficiency within the chemistry\ndomain remains restricted, especially in solving professional molecule-related\ntasks. This challenge is attributed to their inherent limitations in\ncomprehending molecules using only common textual representations, i.e., SMILES\nstrings. In this study, we seek to enhance the ability of LLMs to comprehend\nmolecules by equipping them with a multi-modal external module, namely MolX. In\nparticular, instead of directly using a SMILES string to represent a molecule,\nwe utilize specific encoders to extract fine-grained features from both SMILES\nstring and 2D molecular graph representations for feeding into an LLM.\nMoreover, a handcrafted molecular fingerprint is incorporated to leverage its\nembedded domain knowledge. Then, to establish an alignment between MolX and the\nLLM's textual input space, the whole model in which the LLM is frozen, is\npre-trained with a versatile strategy including a diverse set of tasks.\nExperimental evaluations show that our proposed method outperforms baselines\nacross 4 downstream molecule-related tasks ranging from molecule-to-text\ntranslation to retrosynthesis, with and without fine-tuning the LLM, while only\nintroducing a small number of trainable parameters 0.53% and 0.82%,\nrespectively.",
      "tldr_zh": "本文提出 MolX，一种多模态扩展模块，用于增强 Large Language Models (LLMs) 在分子学习中的能力，解决它们仅依赖 SMILES 字符串导致的化学领域局限性。MolX 通过特定编码器从 SMILES 字符串和 2D 分子图提取细粒度特征，并整合 molecular fingerprint，然后采用多任务预训练策略，使其与 LLMs 的文本输入空间对齐，同时冻结 LLMs 参数。实验结果显示，MolX 在 4 个下游任务（如分子到文本翻译和逆合成）上优于基线模型，仅引入 0.53% 和 0.82% 的可训练参数，无论是否微调 LLMs 均表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06777v5",
      "published_date": "2024-06-10 20:25:18 UTC",
      "updated_date": "2025-04-02 22:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:10:47.469972"
    },
    {
      "arxiv_id": "2406.06773v2",
      "title": "Evaluating Zero-Shot Long-Context LLM Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyu Wang",
        "Yihan Wang",
        "Kai Li"
      ],
      "abstract": "This study evaluates the effectiveness of zero-shot compression techniques on\nlarge language models (LLMs) under long-context. We identify the tendency for\ncomputational errors to increase under long-context when employing certain\ncompression methods. We propose a hypothesis to explain the varied behavior of\ndifferent LLM compression techniques and explore remedies to mitigate the\nperformance decline observed in some techniques under long-context. This is a\ncourse report for COS 598D Machine Learning and Systems by Prof. Kai Li at\nPrinceton University. Due to limited computational resources, our experiments\nwere conducted only on LLaMA-2-7B-32K.",
      "tldr_zh": "本研究评估了 zero-shot 压缩技术在大型语言模型 (LLMs) 的 long-context 场景下的有效性，发现某些压缩方法在长上下文条件下会导致计算错误显著增加。论文提出一个假设来解释不同 LLM 压缩技术的行为差异，并探索了缓解性能下降的潜在解决方案，如优化技术以提升稳定性。由于计算资源限制，实验仅在 LLaMA-2-7B-32K 模型上进行，作为普林斯顿大学 COS 598D 课程报告的一部分。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06773v2",
      "published_date": "2024-06-10 20:19:55 UTC",
      "updated_date": "2025-02-13 17:50:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:10:56.429369"
    },
    {
      "arxiv_id": "2406.06769v2",
      "title": "DISCOVERYWORLD: A Virtual Environment for Developing and Evaluating Automated Scientific Discovery Agents",
      "title_zh": "DISCOVERYWORLD：用于开发和评估自动化科学发现代理的虚拟环境",
      "authors": [
        "Peter Jansen",
        "Marc-Alexandre Côté",
        "Tushar Khot",
        "Erin Bransom",
        "Bhavana Dalvi Mishra",
        "Bodhisattwa Prasad Majumder",
        "Oyvind Tafjord",
        "Peter Clark"
      ],
      "abstract": "Automated scientific discovery promises to accelerate progress across\nscientific domains. However, developing and evaluating an AI agent's capacity\nfor end-to-end scientific reasoning is challenging as running real-world\nexperiments is often prohibitively expensive or infeasible. In this work we\nintroduce DISCOVERYWORLD, the first virtual environment for developing and\nbenchmarking an agent's ability to perform complete cycles of novel scientific\ndiscovery. DISCOVERYWORLD contains a variety of different challenges, covering\ntopics as diverse as radioisotope dating, rocket science, and proteomics, to\nencourage development of general discovery skills rather than task-specific\nsolutions. DISCOVERYWORLD itself is an inexpensive, simulated, text-based\nenvironment (with optional 2D visual overlay). It includes 120 different\nchallenge tasks, spanning eight topics each with three levels of difficulty and\nseveral parametric variations. Each task requires an agent to form hypotheses,\ndesign and run experiments, analyze results, and act on conclusions.\nDISCOVERYWORLD further provides three automatic metrics for evaluating\nperformance, based on (a) task completion, (b) task-relevant actions taken, and\n(c) the discovered explanatory knowledge. We find that strong baseline agents,\nthat perform well in prior published environments, struggle on most\nDISCOVERYWORLD tasks, suggesting that DISCOVERYWORLD captures some of the novel\nchallenges of discovery, and thus that DISCOVERYWORLD may help accelerate\nnear-term development and assessment of scientific discovery competency in\nagents. Code available at: www.github.com/allenai/discoveryworld",
      "tldr_zh": "本文介绍了 DISCOVERYWORLD，一种虚拟环境，用于开发和评估 AI agents 的端到端科学发现能力，以解决真实实验成本高昂的问题。该环境包括 120 个任务，覆盖八个主题（如放射性同位素测年和火箭科学），每个主题有三个难度级别和参数变化，要求 agents 形成假设、设计运行实验、分析结果并据此行动。同时，提供基于任务完成、任务相关行动和发现解释性知识的三个自动评估指标；实验结果显示，现有强基线 agents 在 DISCOVERYWORLD 上表现不佳，突显其在促进通用发现技能方面的价值。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NeurIPS 2024 (Benchmark Track, Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2406.06769v2",
      "published_date": "2024-06-10 20:08:44 UTC",
      "updated_date": "2024-10-07 20:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:11:11.176929"
    },
    {
      "arxiv_id": "2406.06751v1",
      "title": "Complexity-Aware Deep Symbolic Regression with Robust Risk-Seeking Policy Gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Zachary Bastiani",
        "Robert M. Kirby",
        "Jacob Hochhalter",
        "Shandian Zhe"
      ],
      "abstract": "This paper proposes a novel deep symbolic regression approach to enhance the\nrobustness and interpretability of data-driven mathematical expression\ndiscovery. Despite the success of the state-of-the-art method, DSR, it is built\non recurrent neural networks, purely guided by data fitness, and potentially\nmeet tail barriers, which can zero out the policy gradient and cause\ninefficient model updates. To overcome these limitations, we use transformers\nin conjunction with breadth-first-search to improve the learning performance.\nWe use Bayesian information criterion (BIC) as the reward function to\nexplicitly account for the expression complexity and optimize the trade-off\nbetween interpretability and data fitness. We propose a modified risk-seeking\npolicy that not only ensures the unbiasness of the gradient, but also removes\nthe tail barriers, thus ensuring effective updates from top performers. Through\na series of benchmarks and systematic experiments, we demonstrate the\nadvantages of our approach.",
      "tldr_zh": "本论文提出了一种考虑复杂度的深度符号回归方法，旨在提升数据驱动数学表达式发现的鲁棒性和可解释性，通过使用 Transformer 结合 breadth-first-search 来改善学习性能，并解决现有 DSR 方法的尾部障碍问题。方法采用 Bayesian Information Criterion (BIC) 作为奖励函数，优化表达式复杂度和数据拟合的权衡，同时引入改进后的风险寻求策略（robust risk-seeking policy gradients），确保梯度无偏并实现有效模型更新。通过一系列基准测试和系统实验，该方法展示了显著的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06751v1",
      "published_date": "2024-06-10 19:29:10 UTC",
      "updated_date": "2024-06-10 19:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:11:21.277462"
    },
    {
      "arxiv_id": "2406.06742v1",
      "title": "An Elliptic Kernel Unsupervised Autoencoder-Graph Convolutional Network Ensemble Model for Hyperspectral Unmixing",
      "title_zh": "翻译失败",
      "authors": [
        "Estefania Alfaro-Mejia",
        "Carlos J Delgado",
        "Vidya Manian"
      ],
      "abstract": "Spectral Unmixing is an important technique in remote sensing used to analyze\nhyperspectral images to identify endmembers and estimate abundance maps. Over\nthe past few decades, performance of techniques for endmember extraction and\nfractional abundance map estimation have significantly improved. This article\npresents an ensemble model workflow called Autoencoder Graph Ensemble Model\n(AEGEM) designed to extract endmembers and fractional abundance maps. An\nelliptical kernel is applied to measure spectral distances, generating the\nadjacency matrix within the elliptical neighborhood. This information is used\nto construct an elliptical graph, with centroids as senders and remaining\npixels within the geometry as receivers. The next step involves stacking\nabundance maps, senders, and receivers as inputs to a Graph Convolutional\nNetwork, which processes this input to refine abundance maps. Finally, an\nensemble decision-making process determines the best abundance maps based on\nroot mean square error metric. The proposed AEGEM is assessed with benchmark\ndatasets such as Samson, Jasper, and Urban, outperforming results obtained by\nbaseline algorithms. For the Samson dataset, AEGEM excels in three abundance\nmaps: water, tree and soil yielding values of 0.081, 0.158, and 0.182,\nrespectively. For the Jasper dataset, results are improved for the tree and\nwater endmembers with values of 0.035 and 0.060 in that order, as well as for\nthe mean average of the spectral angle distance metric 0.109. For the Urban\ndataset, AEGEM outperforms previous results for the abundance maps of roof and\nasphalt, achieving values of 0.135 and 0.240, respectively. Additionally, for\nthe endmembers of grass and roof, AEGEM achieves values of 0.063 and 0.094.",
      "tldr_zh": "本文提出了一种名为 Autoencoder Graph Ensemble Model (AEGEM) 的集成模型，用于 hyperspectral unmixing，通过 elliptical kernel 测量 spectral distances 并构建 elliptical graph，以提取 endmembers 和估计 abundance maps。模型将 abundance maps、senders 和 receivers 输入 Graph Convolutional Network (GCN) 处理，并采用基于 root mean square error (RMSE) 的集成决策来优化结果。在 Samson、Jasper 和 Urban 等基准数据集上，AEGEM 优于基线算法，例如在 Samson 数据集中，water、tree 和 soil 的 abundance maps 分别为 0.081、0.158 和 0.182，而在 Jasper 和 Urban 数据集中，也取得了显著改进，如 tree 和 water 的值分别为 0.035 和 0.060。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 13 figures, Transaction in Geoscience",
      "pdf_url": "http://arxiv.org/pdf/2406.06742v1",
      "published_date": "2024-06-10 19:04:39 UTC",
      "updated_date": "2024-06-10 19:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:11:36.112279"
    },
    {
      "arxiv_id": "2406.06736v2",
      "title": "Long-Term Fairness Inquiries and Pursuits in Machine Learning: A Survey of Notions, Methods, and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Usman Gohar",
        "Zeyu Tang",
        "Jialu Wang",
        "Kun Zhang",
        "Peter L. Spirtes",
        "Yang Liu",
        "Lu Cheng"
      ],
      "abstract": "The widespread integration of Machine Learning systems in daily life,\nparticularly in high-stakes domains, has raised concerns about the fairness\nimplications. While prior works have investigated static fairness measures,\nrecent studies reveal that automated decision-making has long-term implications\nand that off-the-shelf fairness approaches may not serve the purpose of\nachieving long-term fairness. Additionally, the existence of feedback loops and\nthe interaction between models and the environment introduces additional\ncomplexities that may deviate from the initial fairness goals. In this survey,\nwe review existing literature on long-term fairness from different perspectives\nand present a taxonomy for long-term fairness studies. We highlight key\nchallenges and consider future research directions, analyzing both current\nissues and potential further explorations.",
      "tldr_zh": "这篇调查论文探讨了Machine Learning系统中长期公平性的问题，强调了现有静态fairness measures在处理决策长期影响方面的不足，以及feedback loops和模型与环境互动带来的复杂性。作者回顾了相关文献，并提出一个长期公平性taxonomy，以分类和分析现有研究。论文突出了关键挑战，如实现长期公平的难度，并指出了未来研究方向，包括更深入的探索和改进策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06736v2",
      "published_date": "2024-06-10 18:57:06 UTC",
      "updated_date": "2025-02-12 23:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:11:44.196782"
    },
    {
      "arxiv_id": "2406.06730v1",
      "title": "TRINS: Towards Multimodal Language Models that Can Read",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiyi Zhang",
        "Yanzhe Zhang",
        "Jian Chen",
        "Yufan Zhou",
        "Jiuxiang Gu",
        "Changyou Chen",
        "Tong Sun"
      ],
      "abstract": "Large multimodal language models have shown remarkable proficiency in\nunderstanding and editing images. However, a majority of these visually-tuned\nmodels struggle to comprehend the textual content embedded in images, primarily\ndue to the limitation of training data. In this work, we introduce TRINS: a\nText-Rich image INStruction dataset, with the objective of enhancing the\nreading ability of the multimodal large language model. TRINS is built upon\nLAION using hybrid data annotation strategies that include machine-assisted and\nhuman-assisted annotation processes. It contains 39,153 text-rich images,\ncaptions, and 102,437 questions. Specifically, we show that the number of words\nper annotation in TRINS is significantly longer than that of related datasets,\nproviding new challenges. Furthermore, we introduce a simple and effective\narchitecture, called a Language-vision Reading Assistant (LaRA), which is good\nat understanding textual content within images. LaRA outperforms existing\nstate-of-the-art multimodal large language models on the TRINS dataset, as well\nas other classical benchmarks. Lastly, we conducted a comprehensive evaluation\nwith TRINS on various text-rich image understanding and generation tasks,\ndemonstrating its effectiveness.",
      "tldr_zh": "本文研究发现，现有的多模态语言模型在理解和编辑图像方面表现出色，但难以处理图像中的文本内容，主要受限于训练数据。论文引入了 TRINS（Text-Rich image INStruction）数据集，该数据集基于 LAION，通过混合数据标注策略（包括机器辅助和人类辅助）构建，包含39,153张文本丰富的图像、标题和102,437个问题，且注释词数显著长于相关数据集，提供新挑战。同时，提出了一种简单有效的架构LaRA（Language-vision Reading Assistant），专长于图像文本理解，并在TRINS及其他基准上超越现有最先进模型，证明了其在文本丰富图像理解和生成任务中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06730v1",
      "published_date": "2024-06-10 18:52:37 UTC",
      "updated_date": "2024-06-10 18:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:11:58.318873"
    },
    {
      "arxiv_id": "2406.06729v1",
      "title": "Synthetic Query Generation using Large Language Models for Virtual Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Sonal Sannigrahi",
        "Thiago Fraga-Silva",
        "Youssef Oualil",
        "Christophe Van Gysel"
      ],
      "abstract": "Virtual Assistants (VAs) are important Information Retrieval platforms that\nhelp users accomplish various tasks through spoken commands. The speech\nrecognition system (speech-to-text) uses query priors, trained solely on text,\nto distinguish between phonetically confusing alternatives. Hence, the\ngeneration of synthetic queries that are similar to existing VA usage can\ngreatly improve upon the VA's abilities -- especially for use-cases that do not\n(yet) occur in paired audio/text data.\n  In this paper, we provide a preliminary exploration of the use of Large\nLanguage Models (LLMs) to generate synthetic queries that are complementary to\ntemplate-based methods. We investigate whether the methods (a) generate queries\nthat are similar to randomly sampled, representative, and anonymized user\nqueries from a popular VA, and (b) whether the generated queries are specific.\n  We find that LLMs generate more verbose queries, compared to template-based\nmethods, and reference aspects specific to the entity. The generated queries\nare similar to VA user queries, and are specific enough to retrieve the\nrelevant entity. We conclude that queries generated by LLMs and templates are\ncomplementary.",
      "tldr_zh": "本研究探索使用 Large Language Models (LLMs) 生成合成查询，以提升 Virtual Assistants (VAs) 的信息检索能力，特别是针对语音识别中语音相似的备选方案。研究比较了 LLMs 方法与基于模板的方法，评估生成的查询是否类似于真实 VA 用户查询，并检查其具体性。结果显示，LLMs 生成的查询更冗长且更精确地引用实体方面，与用户查询相似，且足够具体以检索相关实体。最终，论文得出结论，LLMs 和模板方法生成的查询是互补的，可共同改善 VA 的性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "SIGIR '24. The 47th International ACM SIGIR Conference on Research &\n  Development in Information Retrieval",
      "pdf_url": "http://arxiv.org/pdf/2406.06729v1",
      "published_date": "2024-06-10 18:50:57 UTC",
      "updated_date": "2024-06-10 18:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:12:10.182441"
    },
    {
      "arxiv_id": "2406.06728v2",
      "title": "AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "K M Tawsik Jawad",
        "Anusha Verma",
        "Fathi Amsaad",
        "Lamia Ashraf"
      ],
      "abstract": "Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with\nno known ultimo cure and high morbidity. Research demonstrates that progressive\nChronic Kidney Disease (CKD) is a heterogeneous disorder that significantly\nimpacts kidney structure and functions, eventually leading to kidney failure.\nWith the progression of time, chronic kidney disease has moved from a\nlife-threatening disease affecting few people to a common disorder of varying\nseverity. The goal of this research is to visualize dominating features,\nfeature scores, and values exhibited for early prognosis and detection of CKD\nusing ensemble learning and explainable AI. For that, an AI-driven predictive\nanalytics approach is proposed to aid clinical practitioners in prescribing\nlifestyle modifications for individual patients to reduce the rate of\nprogression of this disease. Our dataset is collected on body vitals from\nindividuals with CKD and healthy subjects to develop our proposed AI-driven\nsolution accurately. In this regard, blood and urine test results are provided,\nand ensemble tree-based machine-learning models are applied to predict unseen\ncases of CKD. Our research findings are validated after lengthy consultations\nwith nephrologists. Our experiments and interpretation results are compared\nwith existing explainable AI applications in various healthcare domains,\nincluding CKD. The comparison shows that our developed AI models, particularly\nthe Random Forest model, have identified more features as significant\ncontributors than XgBoost. Interpretability (I), which measures the ratio of\nimportant to masked features, indicates that our XgBoost model achieved a\nhigher score, specifically a Fidelity of 98\\%, in this metric and naturally in\nthe FII index compared to competing models.",
      "tldr_zh": "本文提出了一种基于 AI 的预测分析方法，使用 Ensemble Learning 和 Explainable AI 来实现慢性肾病 (CKD) 的早期预后和检测。该方法通过应用树-based 机器学习模型，如 Random Forest 和 XgBoost，对患者血液和尿液测试数据进行分析，识别关键特征并可视化其分数，以帮助临床医生制定个性化生活方式修改建议。实验结果显示，Random Forest 模型识别了更多重要特征，而 XgBoost 在可解释性指标上达到了 98% 的 Fidelity 得分，比现有模型表现更优。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06728v2",
      "published_date": "2024-06-10 18:46:14 UTC",
      "updated_date": "2025-01-24 20:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:12:23.772030"
    },
    {
      "arxiv_id": "2406.06714v2",
      "title": "Coprocessor Actor Critic: A Model-Based Reinforcement Learning Approach For Adaptive Brain Stimulation",
      "title_zh": "Coprocessor Actor Critic：一种基于模型的强化学习方法，用于自适应脑刺激",
      "authors": [
        "Michelle Pan",
        "Mariah Schrum",
        "Vivek Myers",
        "Erdem Bıyık",
        "Anca Dragan"
      ],
      "abstract": "Adaptive brain stimulation can treat neurological conditions such as\nParkinson's disease and post-stroke motor deficits by influencing abnormal\nneural activity. Because of patient heterogeneity, each patient requires a\nunique stimulation policy to achieve optimal neural responses. Model-free\nreinforcement learning (MFRL) holds promise in learning effective policies for\na variety of similar control tasks, but is limited in domains like brain\nstimulation by a need for numerous costly environment interactions. In this\nwork we introduce Coprocessor Actor Critic, a novel, model-based reinforcement\nlearning (MBRL) approach for learning neural coprocessor policies for brain\nstimulation. Our key insight is that coprocessor policy learning is a\ncombination of learning how to act optimally in the world and learning how to\ninduce optimal actions in the world through stimulation of an injured brain. We\nshow that our approach overcomes the limitations of traditional MFRL methods in\nterms of sample efficiency and task success and outperforms baseline MBRL\napproaches in a neurologically realistic model of an injured brain.",
      "tldr_zh": "这篇论文提出了Coprocessor Actor Critic，一种基于模型的强化学习 (MBRL) 方法，用于自适应脑刺激治疗神经疾病，如帕金森病和中风后运动缺陷。针对患者异质性导致的个性化策略需求，该方法结合了在世界中行动学习和通过刺激受损大脑诱导最优行动的关键洞见，从而克服了模型无关强化学习 (MFRL) 的样本效率不足问题。在神经学真实模型中，Coprocessor Actor Critic 在任务成功率和样本效率上超过了基线 MBRL 方法，为高效的脑刺激策略提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 41st International Conference on Machine Learning\n  (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.06714v2",
      "published_date": "2024-06-10 18:23:03 UTC",
      "updated_date": "2024-10-07 21:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:12:35.816903"
    },
    {
      "arxiv_id": "2406.06700v1",
      "title": "Forget Sharpness: Perturbed Forgetting of Model Biases Within SAM Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Ankit Vani",
        "Frederick Tung",
        "Gabriel L. Oliveira",
        "Hossein Sharifi-Noghabi"
      ],
      "abstract": "Despite attaining high empirical generalization, the sharpness of models\ntrained with sharpness-aware minimization (SAM) do not always correlate with\ngeneralization error. Instead of viewing SAM as minimizing sharpness to improve\ngeneralization, our paper considers a new perspective based on SAM's training\ndynamics. We propose that perturbations in SAM perform perturbed forgetting,\nwhere they discard undesirable model biases to exhibit learning signals that\ngeneralize better. We relate our notion of forgetting to the information\nbottleneck principle, use it to explain observations like the better\ngeneralization of smaller perturbation batches, and show that perturbed\nforgetting can exhibit a stronger correlation with generalization than\nflatness. While standard SAM targets model biases exposed by the steepest\nascent directions, we propose a new perturbation that targets biases exposed\nthrough the model's outputs. Our output bias forgetting perturbations\noutperform standard SAM, GSAM, and ASAM on ImageNet, robustness benchmarks, and\ntransfer to CIFAR-{10,100}, while sometimes converging to sharper regions. Our\nresults suggest that the benefits of SAM can be explained by alternative\nmechanistic principles that do not require flatness of the loss surface.",
      "tldr_zh": "本论文质疑了基于 sharpness-aware minimization (SAM) 的模型训练中，sharpness 与泛化性能的相关性，转而提出 SAM 通过 perturbed forgetting 机制丢弃模型偏差，从而提升泛化学习信号。作者将这种 forgetting 与 information bottleneck principle 联系起来，解释了如更小扰动批次导致更好泛化的现象，并证明 perturbed forgetting 与泛化的相关性强于损失表面的 flatness。论文引入一种新扰动方法，针对模型输出偏差而非标准 SAM 的最陡上升方向，在 ImageNet、鲁棒性基准和转移到 CIFAR-10/100 上优于 SAM、GSAM 和 ASAM，即使有时收敛到更 sharp 的区域。这些发现表明，SAM 的益处可由其他机制解释，而非依赖于损失表面的平坦性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICML 2024. 9 pages main, 15 pages\n  total including references and appendix",
      "pdf_url": "http://arxiv.org/pdf/2406.06700v1",
      "published_date": "2024-06-10 18:02:48 UTC",
      "updated_date": "2024-06-10 18:02:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:12:50.871854"
    },
    {
      "arxiv_id": "2406.06527v2",
      "title": "IllumiNeRF: 3D Relighting Without Inverse Rendering",
      "title_zh": "IllumiNeRF：无需反向渲染的3D重照明",
      "authors": [
        "Xiaoming Zhao",
        "Pratul P. Srinivasan",
        "Dor Verbin",
        "Keunhong Park",
        "Ricardo Martin Brualla",
        "Philipp Henzler"
      ],
      "abstract": "Existing methods for relightable view synthesis -- using a set of images of\nan object under unknown lighting to recover a 3D representation that can be\nrendered from novel viewpoints under a target illumination -- are based on\ninverse rendering, and attempt to disentangle the object geometry, materials,\nand lighting that explain the input images. Furthermore, this typically\ninvolves optimization through differentiable Monte Carlo rendering, which is\nbrittle and computationally-expensive. In this work, we propose a simpler\napproach: we first relight each input image using an image diffusion model\nconditioned on target environment lighting and estimated object geometry. We\nthen reconstruct a Neural Radiance Field (NeRF) with these relit images, from\nwhich we render novel views under the target lighting. We demonstrate that this\nstrategy is surprisingly competitive and achieves state-of-the-art results on\nmultiple relighting benchmarks. Please see our project page at\nhttps://illuminerf.github.io/.",
      "tldr_zh": "本文提出IllumiNeRF方法，实现3D重光照而不依赖Inverse Rendering，从而简化了传统基于物体几何、材质和光照分离的过程。该方法首先使用image diffusion model对输入图像进行重光照，结合目标环境光照和估计的物体几何；随后，通过这些重光照图像重建Neural Radiance Field (NeRF)，以渲染目标光照下的新视图。实验结果显示，该策略在多个重光照基准上取得了state-of-the-art性能，出人意料地高效且计算友好。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024; v2 (for camera-ready) added single-GPU results and\n  discussions on Stanford-ORB illuminations; Project page:\n  https://illuminerf.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.06527v2",
      "published_date": "2024-06-10 17:59:59 UTC",
      "updated_date": "2024-11-01 20:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:13:02.549780"
    },
    {
      "arxiv_id": "2406.06520v1",
      "title": "Decentralized Personalized Federated Learning",
      "title_zh": "去中心化的个性化联邦学习",
      "authors": [
        "Salma Kharrat",
        "Marco Canini",
        "Samuel Horvath"
      ],
      "abstract": "This work tackles the challenges of data heterogeneity and communication\nlimitations in decentralized federated learning. We focus on creating a\ncollaboration graph that guides each client in selecting suitable collaborators\nfor training personalized models that leverage their local data effectively.\nOur approach addresses these issues through a novel, communication-efficient\nstrategy that enhances resource efficiency. Unlike traditional methods, our\nformulation identifies collaborators at a granular level by considering\ncombinatorial relations of clients, enhancing personalization while minimizing\ncommunication overhead. We achieve this through a bi-level optimization\nframework that employs a constrained greedy algorithm, resulting in a\nresource-efficient collaboration graph for personalized learning. Extensive\nevaluation against various baselines across diverse datasets demonstrates the\nsuperiority of our method, named DPFL. DPFL consistently outperforms other\napproaches, showcasing its effectiveness in handling real-world data\nheterogeneity, minimizing communication overhead, enhancing resource\nefficiency, and building personalized models in decentralized federated\nlearning scenarios.",
      "tldr_zh": "该研究解决了去中心化联邦学习（Federated Learning）中的数据异质性和通信限制问题，通过构建一个协作图来指导每个客户端选择合适的合作者，从而训练出利用本地数据的高效个性化模型。他们的方法采用一种新型通信高效策略，通过考虑客户端的组合关系来识别合作者，并使用双层优化框架（bi-level optimization）和受限贪婪算法生成资源高效的协作图。实验结果显示，名为 DPFL 的方法在多种数据集上优于现有基线，在处理数据异质性、减少通信开销、提升资源效率和构建个性化模型方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.MA",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06520v1",
      "published_date": "2024-06-10 17:58:48 UTC",
      "updated_date": "2024-06-10 17:58:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:13:14.624726"
    },
    {
      "arxiv_id": "2406.06512v1",
      "title": "Merlin: A Vision Language Foundation Model for 3D Computed Tomography",
      "title_zh": "Merlin：用于 3D 计算断层扫描的视觉语言基础模型",
      "authors": [
        "Louis Blankemeier",
        "Joseph Paul Cohen",
        "Ashwin Kumar",
        "Dave Van Veen",
        "Syed Jamal Safdar Gardezi",
        "Magdalini Paschali",
        "Zhihong Chen",
        "Jean-Benoit Delbrouck",
        "Eduardo Reis",
        "Cesar Truyts",
        "Christian Bluethgen",
        "Malte Engmann Kjeldskov Jensen",
        "Sophie Ostmeier",
        "Maya Varma",
        "Jeya Maria Jose Valanarasu",
        "Zhongnan Fang",
        "Zepeng Huo",
        "Zaid Nabulsi",
        "Diego Ardila",
        "Wei-Hung Weng",
        "Edson Amaro Junior",
        "Neera Ahuja",
        "Jason Fries",
        "Nigam H. Shah",
        "Andrew Johnston",
        "Robert D. Boutin",
        "Andrew Wentland",
        "Curtis P. Langlotz",
        "Jason Hom",
        "Sergios Gatidis",
        "Akshay S. Chaudhari"
      ],
      "abstract": "Over 85 million computed tomography (CT) scans are performed annually in the\nUS, of which approximately one quarter focus on the abdomen. Given the current\nradiologist shortage, there is a large impetus to use artificial intelligence\nto alleviate the burden of interpreting these complex imaging studies. Prior\nstate-of-the-art approaches for automated medical image interpretation leverage\nvision language models (VLMs). However, current medical VLMs are generally\nlimited to 2D images and short reports, and do not leverage electronic health\nrecord (EHR) data for supervision. We introduce Merlin - a 3D VLM that we train\nusing paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes\n(1.8+ million codes), and radiology reports (6+ million tokens). We evaluate\nMerlin on 6 task types and 752 individual tasks. The non-adapted\n(off-the-shelf) tasks include zero-shot findings classification (31 findings),\nphenotype classification (692 phenotypes), and zero-shot cross-modal retrieval\n(image to findings and image to impressions), while model adapted tasks include\n5-year disease prediction (6 diseases), radiology report generation, and 3D\nsemantic segmentation (20 organs). We perform internal validation on a test set\nof 5,137 CTs, and external validation on 7,000 clinical CTs and on two public\nCT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevant\nevaluations, we assess the efficacy of various network architectures and\ntraining strategies to depict that Merlin has favorable performance to existing\ntask-specific baselines. We derive data scaling laws to empirically assess\ntraining data needs for requisite downstream task performance. Furthermore,\nunlike conventional VLMs that require hundreds of GPUs for training, we perform\nall training on a single GPU.",
      "tldr_zh": "该研究引入了Merlin，一种针对3D Computed Tomography (CT) 图像的Vision Language Foundation Model (VLM)，旨在缓解放射科医生短缺问题，通过整合CT扫描、EHR诊断代码和放射学报告进行训练。Merlin利用6+百万图像、1.8+百万诊断代码和6+百万tokens的数据，在752个任务中表现出色，包括零样本发现分类、表型分类、跨模态检索、5年疾病预测、报告生成和3D语义分割。实验结果显示，Merlin在内部（5137个CT）和外部验证（7000个临床CT及公共数据集）中优于现有任务特定基线，且所有训练仅需单GPU，同时导出了数据缩放定律以指导未来模型开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06512v1",
      "published_date": "2024-06-10 17:53:01 UTC",
      "updated_date": "2024-06-10 17:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:13:28.958277"
    },
    {
      "arxiv_id": "2406.06508v1",
      "title": "Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Sigal Raab",
        "Inbar Gat",
        "Nathan Sala",
        "Guy Tevet",
        "Rotem Shalev-Arkushin",
        "Ohad Fried",
        "Amit H. Bermano",
        "Daniel Cohen-Or"
      ],
      "abstract": "Given the remarkable results of motion synthesis with diffusion models, a\nnatural question arises: how can we effectively leverage these models for\nmotion editing? Existing diffusion-based motion editing methods overlook the\nprofound potential of the prior embedded within the weights of pre-trained\nmodels, which enables manipulating the latent feature space; hence, they\nprimarily center on handling the motion space. In this work, we explore the\nattention mechanism of pre-trained motion diffusion models. We uncover the\nroles and interactions of attention elements in capturing and representing\nintricate human motion patterns, and carefully integrate these elements to\ntransfer a leader motion to a follower one while maintaining the nuanced\ncharacteristics of the follower, resulting in zero-shot motion transfer.\nEditing features associated with selected motions allows us to confront a\nchallenge observed in prior motion diffusion approaches, which use general\ndirectives (e.g., text, music) for editing, ultimately failing to convey subtle\nnuances effectively. Our work is inspired by how a monkey closely imitates what\nit sees while maintaining its unique motion patterns; hence we call it Monkey\nSee, Monkey Do, and dub it MoMo. Employing our technique enables accomplishing\ntasks such as synthesizing out-of-distribution motions, style transfer, and\nspatial editing. Furthermore, diffusion inversion is seldom employed for\nmotions; as a result, editing efforts focus on generated motions, limiting the\neditability of real ones. MoMo harnesses motion inversion, extending its\napplication to both real and generated motions. Experimental results show the\nadvantage of our approach over the current art. In particular, unlike methods\ntailored for specific applications through training, our approach is applied at\ninference time, requiring no training. Our webpage is at\nhttps://monkeyseedocg.github.io.",
      "tldr_zh": "该论文提出 MoMo（Monkey See, Monkey Do）方法，利用预训练运动扩散模型的自注意力机制（self-attention），实现零样本（zero-shot）运动转移，即将领导者运动转移到跟随者上，同时保留跟随者的细微特征。不同于现有方法，该框架直接操作模型的潜在特征空间，而非仅处理运动空间，且无需额外训练，仅在推理时应用。实验结果显示，MoMo 在合成分布外运动、风格转移和空间编辑等任务上优于基线模型，并扩展到真实运动编辑，提供更精确和灵活的运动编辑能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Video: https://www.youtube.com/watch?v=s5oo3sKV0YU, Project page:\n  https://monkeyseedocg.github.io, Code:\n  https://github.com/MonkeySeeDoCG/MoMo-code",
      "pdf_url": "http://arxiv.org/pdf/2406.06508v1",
      "published_date": "2024-06-10 17:47:14 UTC",
      "updated_date": "2024-06-10 17:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:13:39.215060"
    },
    {
      "arxiv_id": "2406.06500v1",
      "title": "Adaptive Opponent Policy Detection in Multi-Agent MDPs: Real-Time Strategy Switch Identification Using Running Error Estimation",
      "title_zh": "多智能体 MDPs 中的自适应对手策略检测：使用运行错误估计的实时策略切换识别",
      "authors": [
        "Mohidul Haque Mridul",
        "Mohammad Foysal Khan",
        "Redwan Ahmed Rizvee",
        "Md Mosaddek Khan"
      ],
      "abstract": "In Multi-agent Reinforcement Learning (MARL), accurately perceiving\nopponents' strategies is essential for both cooperative and adversarial\ncontexts, particularly within dynamic environments. While Proximal Policy\nOptimization (PPO) and related algorithms such as Actor-Critic with Experience\nReplay (ACER), Trust Region Policy Optimization (TRPO), and Deep Deterministic\nPolicy Gradient (DDPG) perform well in single-agent, stationary environments,\nthey suffer from high variance in MARL due to non-stationary and hidden\npolicies of opponents, leading to diminished reward performance. Additionally,\nexisting methods in MARL face significant challenges, including the need for\ninter-agent communication, reliance on explicit reward information, high\ncomputational demands, and sampling inefficiencies. These issues render them\nless effective in continuous environments where opponents may abruptly change\ntheir policies without prior notice. Against this background, we present\nOPS-DeMo (Online Policy Switch-Detection Model), an online algorithm that\nemploys dynamic error decay to detect changes in opponents' policies. OPS-DeMo\ncontinuously updates its beliefs using an Assumed Opponent Policy (AOP) Bank\nand selects corresponding responses from a pre-trained Response Policy Bank.\nEach response policy is trained against consistently strategizing opponents,\nreducing training uncertainty and enabling the effective use of algorithms like\nPPO in multi-agent environments. Comparative assessments show that our approach\noutperforms PPO-trained models in dynamic scenarios like the Predator-Prey\nsetting, providing greater robustness to sudden policy shifts and enabling more\ninformed decision-making through precise opponent policy insights.",
      "tldr_zh": "在多智能体强化学习(MARL)环境中，现有的算法如PPO、ACER、TRPO和DDPG因对手策略的非平稳性和突变而面临高方差和性能下降的问题。论文提出OPS-DeMo算法，该方法利用动态错误衰减实时检测对手策略切换，通过Assumed Opponent Policy (AOP) Bank和Response Policy Bank预训练响应策略，以减少训练不确定性和提升决策效率。实验结果显示，OPS-DeMo在Predator-Prey动态场景中显著优于PPO基准模型，提供更强的鲁棒性和精确的对手策略洞察。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06500v1",
      "published_date": "2024-06-10 17:34:44 UTC",
      "updated_date": "2024-06-10 17:34:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:13:50.670834"
    },
    {
      "arxiv_id": "2406.06494v2",
      "title": "Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits",
      "title_zh": "扩展连续潜在变量模型作为概率积分电路",
      "authors": [
        "Gennaro Gala",
        "Cassio de Campos",
        "Antonio Vergari",
        "Erik Quaeghebeur"
      ],
      "abstract": "Probabilistic integral circuits (PICs) have been recently introduced as\nprobabilistic models enjoying the key ingredient behind expressive generative\nmodels: continuous latent variables (LVs). PICs are symbolic computational\ngraphs defining continuous LV models as hierarchies of functions that are\nsummed and multiplied together, or integrated over some LVs. They are tractable\nif LVs can be analytically integrated out, otherwise they can be approximated\nby tractable probabilistic circuits (PC) encoding a hierarchical numerical\nquadrature process, called QPCs.\n  So far, only tree-shaped PICs have been explored, and training them via\nnumerical quadrature requires memory-intensive processing at scale. In this\npaper, we address these issues, and present: (i) a pipeline for building\nDAG-shaped PICs out of arbitrary variable decompositions, (ii) a procedure for\ntraining PICs using tensorized circuit architectures, and (iii) neural\nfunctional sharing techniques to allow scalable training. In extensive\nexperiments, we showcase the effectiveness of functional sharing and the\nsuperiority of QPCs over traditional PCs.",
      "tldr_zh": "该研究将连续潜在变量（LVs）模型扩展为Probabilistic Integral Circuits (PICs)，这些是符号计算图，通过函数的求和、乘法和积分构建层次化概率模型，以提升生成模型的表达性。论文提出了一种管道来构建DAG-shaped PICs、基于tensorized电路架构的训练过程，以及神经功能共享技术，以解决现有树状PICs的内存密集型训练问题。实验结果证明了功能共享的有效性，并显示Tractable Probabilistic Circuits (PCs)编码的QPCs在性能上优于传统PCs。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06494v2",
      "published_date": "2024-06-10 17:30:17 UTC",
      "updated_date": "2025-02-05 13:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:14:02.095038"
    },
    {
      "arxiv_id": "2406.06485v1",
      "title": "Can Language Models Serve as Text-Based World Simulators?",
      "title_zh": "语言模型能否充当基于文本的世界",
      "authors": [
        "Ruoyao Wang",
        "Graham Todd",
        "Ziang Xiao",
        "Xingdi Yuan",
        "Marc-Alexandre Côté",
        "Peter Clark",
        "Peter Jansen"
      ],
      "abstract": "Virtual environments play a key role in benchmarking advances in complex\nplanning and decision-making tasks but are expensive and complicated to build\nby hand. Can current language models themselves serve as world simulators,\ncorrectly predicting how actions change different world states, thus bypassing\nthe need for extensive manual coding? Our goal is to answer this question in\nthe context of text-based simulators. Our approach is to build and use a new\nbenchmark, called ByteSized32-State-Prediction, containing a dataset of text\ngame state transitions and accompanying game tasks. We use this to directly\nquantify, for the first time, how well LLMs can serve as text-based world\nsimulators. We test GPT-4 on this dataset and find that, despite its impressive\nperformance, it is still an unreliable world simulator without further\ninnovations. This work thus contributes both new insights into current LLM's\ncapabilities and weaknesses, as well as a novel benchmark to track future\nprogress as new models appear.",
      "tldr_zh": "该研究探讨了语言模型是否能作为文本-based世界模拟器，来准确预测动作如何改变世界状态，从而取代手动构建虚拟环境。论文引入了一个新基准 ByteSized32-State-Prediction，包含文本游戏状态转换数据集和任务，用于量化语言模型的模拟能力。实验结果显示，GPT-4 尽管表现出色，但作为世界模拟器仍不可靠，需要进一步创新。该工作为理解当前 LLMs 的优势和局限性提供了新洞见，并提供了一个基准来跟踪未来模型的进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06485v1",
      "published_date": "2024-06-10 17:24:44 UTC",
      "updated_date": "2024-06-10 17:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:14:15.772824"
    },
    {
      "arxiv_id": "2406.06475v1",
      "title": "Survey for Landing Generative AI in Social and E-commerce Recsys -- the Industry Perspectives",
      "title_zh": "翻译失败",
      "authors": [
        "Da Xu",
        "Danqing Zhang",
        "Guangyu Yang",
        "Bo Yang",
        "Shuyuan Xu",
        "Lingling Zheng",
        "Cindy Liang"
      ],
      "abstract": "Recently, generative AI (GAI), with their emerging capabilities, have\npresented unique opportunities for augmenting and revolutionizing industrial\nrecommender systems (Recsys). Despite growing research efforts at the\nintersection of these fields, the integration of GAI into industrial Recsys\nremains in its infancy, largely due to the intricate nature of modern\nindustrial Recsys infrastructure, operations, and product sophistication.\nDrawing upon our experiences in successfully integrating GAI into several major\nsocial and e-commerce platforms, this survey aims to comprehensively examine\nthe underlying system and AI foundations, solution frameworks, connections to\nkey research advancements, as well as summarize the practical insights and\nchallenges encountered in the endeavor to integrate GAI into industrial Recsys.\nAs pioneering work in this domain, we hope outline the representative\ndevelopments of relevant fields, shed lights on practical GAI adoptions in the\nindustry, and motivate future research.",
      "tldr_zh": "这篇调查基于行业经验，探讨了生成式 AI (GAI) 在社交和电商推荐系统 (Recsys) 中的整合现状和挑战。作者通过分析系统基础、解决方案框架以及与关键研究进展的联系，总结了实际部署过程中的实用洞见和障碍。最终，该工作旨在概述相关领域的发展，提供行业指导，并激励未来 GAI 在工业 Recsys 中的应用研究。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06475v1",
      "published_date": "2024-06-10 17:16:59 UTC",
      "updated_date": "2024-06-10 17:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:14:25.560075"
    },
    {
      "arxiv_id": "2406.06474v1",
      "title": "Towards a Personal Health Large Language Model",
      "title_zh": "迈向个人健康大语言模型",
      "authors": [
        "Justin Cosentino",
        "Anastasiya Belyaeva",
        "Xin Liu",
        "Nicholas A. Furlotte",
        "Zhun Yang",
        "Chace Lee",
        "Erik Schenck",
        "Yojan Patel",
        "Jian Cui",
        "Logan Douglas Schneider",
        "Robby Bryant",
        "Ryan G. Gomes",
        "Allen Jiang",
        "Roy Lee",
        "Yun Liu",
        "Javier Perez",
        "Jameson K. Rogers",
        "Cathy Speed",
        "Shyam Tailor",
        "Megan Walker",
        "Jeffrey Yu",
        "Tim Althoff",
        "Conor Heneghan",
        "John Hernandez",
        "Mark Malhotra",
        "Leor Stern",
        "Yossi Matias",
        "Greg S. Corrado",
        "Shwetak Patel",
        "Shravya Shetty",
        "Jiening Zhan",
        "Shruthi Prabhakara",
        "Daniel McDuff",
        "Cory Y. McLean"
      ],
      "abstract": "In health, most large language model (LLM) research has focused on clinical\ntasks. However, mobile and wearable devices, which are rarely integrated into\nsuch tasks, provide rich, longitudinal data for personal health monitoring.\nHere we present Personal Health Large Language Model (PH-LLM), fine-tuned from\nGemini for understanding and reasoning over numerical time-series personal\nhealth data. We created and curated three datasets that test 1) production of\npersonalized insights and recommendations from sleep patterns, physical\nactivity, and physiological responses, 2) expert domain knowledge, and 3)\nprediction of self-reported sleep outcomes. For the first task we designed 857\ncase studies in collaboration with domain experts to assess real-world\nscenarios in sleep and fitness. Through comprehensive evaluation of\ndomain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not\nstatistically different from expert performance in fitness and, while experts\nremain superior for sleep, fine-tuning PH-LLM provided significant improvements\nin using relevant domain knowledge and personalizing information for sleep\ninsights. We evaluated PH-LLM domain knowledge using multiple choice sleep\nmedicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% on\nfitness, exceeding average scores from a sample of human experts. Finally, we\ntrained PH-LLM to predict self-reported sleep quality outcomes from textual and\nmultimodal encoding representations of wearable data, and demonstrate that\nmultimodal encoding is required to match performance of specialized\ndiscriminative models. Although further development and evaluation are\nnecessary in the safety-critical personal health domain, these results\ndemonstrate both the broad knowledge and capabilities of Gemini models and the\nbenefit of contextualizing physiological data for personal health applications\nas done with PH-LLM.",
      "tldr_zh": "本文提出 Personal Health Large Language Model (PH-LLM)，一种从 Gemini 模型微调而来的 LLM，用于理解和推理个人健康数据的数字时间序列数据，如睡眠模式、身体活动和生理反应。研究创建了三个数据集，包括857个真实场景案例研究，以评估PH-LLM在提供个性化洞见、专家领域知识和预测自我报告睡眠结果方面的性能。结果显示，PH-LLM在健身洞见上与专家表现相当，在睡眠知识测试中得分分别为79%（睡眠）和88%（健身），超过人类专家平均分，且多模态编码是实现预测准确性的关键。这为LLM在个人健康监测中的应用提供了重要基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "72 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.06474v1",
      "published_date": "2024-06-10 17:16:49 UTC",
      "updated_date": "2024-06-10 17:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:14:41.653001"
    },
    {
      "arxiv_id": "2406.06470v1",
      "title": "GKAN: Graph Kolmogorov-Arnold Networks",
      "title_zh": "GKAN: 图 Kolmogorov-Arnold 网络",
      "authors": [
        "Mehrdad Kiamari",
        "Mohammad Kiamari",
        "Bhaskar Krishnamachari"
      ],
      "abstract": "We introduce Graph Kolmogorov-Arnold Networks (GKAN), an innovative neural\nnetwork architecture that extends the principles of the recently proposed\nKolmogorov-Arnold Networks (KAN) to graph-structured data. By adopting the\nunique characteristics of KANs, notably the use of learnable univariate\nfunctions instead of fixed linear weights, we develop a powerful model for\ngraph-based learning tasks. Unlike traditional Graph Convolutional Networks\n(GCNs) that rely on a fixed convolutional architecture, GKANs implement\nlearnable spline-based functions between layers, transforming the way\ninformation is processed across the graph structure. We present two different\nways to incorporate KAN layers into GKAN: architecture 1 -- where the learnable\nfunctions are applied to input features after aggregation and architecture 2 --\nwhere the learnable functions are applied to input features before aggregation.\nWe evaluate GKAN empirically using a semi-supervised graph learning task on a\nreal-world dataset (Cora). We find that architecture generally performs better.\nWe find that GKANs achieve higher accuracy in semi-supervised learning tasks on\ngraphs compared to the traditional GCN model. For example, when considering 100\nfeatures, GCN provides an accuracy of 53.5 while a GKAN with a comparable\nnumber of parameters gives an accuracy of 61.76; with 200 features, GCN\nprovides an accuracy of 61.24 while a GKAN with a comparable number of\nparameters gives an accuracy of 67.66. We also present results on the impact of\nvarious parameters such as the number of hidden nodes, grid-size, and the\npolynomial-degree of the spline on the performance of GKAN.",
      "tldr_zh": "论文提出 Graph Kolmogorov-Arnold Networks (GKAN)，一种将 Kolmogorov-Arnold Networks (KAN) 扩展到图结构数据的创新神经网络架构，使用可学习的单变量函数和 spline-based 函数来处理图数据，从而取代传统 Graph Convolutional Networks (GCNs) 的固定卷积结构。GKAN 包括两种整合方式：一种在特征聚合后应用可学习函数，另一种在聚合前应用，并在 Cora 数据集的半监督学习任务中进行评估。实验结果显示，GKAN 显著提升了准确率，例如在 100 个特征时达到 61.76%（相比 GCN 的 53.5%），在 200 个特征时达到 67.66%（相比 GCN 的 61.24%），并探讨了隐藏节点数、网格大小和样条多项式度对性能的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06470v1",
      "published_date": "2024-06-10 17:09:38 UTC",
      "updated_date": "2024-06-10 17:09:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:14:58.786684"
    },
    {
      "arxiv_id": "2406.06469v1",
      "title": "Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Joongwon Kim",
        "Bhargavi Paranjape",
        "Tushar Khot",
        "Hannaneh Hajishirzi"
      ],
      "abstract": "Language agents perform complex tasks by using tools to execute each step\nprecisely. However, most existing agents are based on proprietary models or\ndesigned to target specific tasks, such as mathematics or multi-hop question\nanswering. We introduce Husky, a holistic, open-source language agent that\nlearns to reason over a unified action space to address a diverse set of\ncomplex tasks involving numerical, tabular, and knowledge-based reasoning.\nHusky iterates between two stages: 1) generating the next action to take\ntowards solving a given task and 2) executing the action using expert models\nand updating the current solution state. We identify a thorough ontology of\nactions for addressing complex tasks and curate high-quality data to train\nexpert models for executing these actions. Our experiments show that Husky\noutperforms prior language agents across 14 evaluation datasets. Moreover, we\nintroduce HuskyQA, a new evaluation set which stress tests language agents for\nmixed-tool reasoning, with a focus on retrieving missing knowledge and\nperforming numerical reasoning. Despite using 7B models, Husky matches or even\nexceeds frontier LMs such as GPT-4 on these tasks, showcasing the efficacy of\nour holistic approach in addressing complex reasoning problems. Our code and\nmodels are available at https://github.com/agent-husky/Husky-v1.",
      "tldr_zh": "本研究引入Husky，一个统一的开源Language Agent，用于处理多步推理任务，包括数值、表格和基于知识的推理。Husky通过在生成行动和执行行动两个阶段迭代，使用统一的行动空间和训练的专家模型来解决问题，从而克服现有代理依赖专有模型或针对特定任务的局限性。实验结果显示，Husky在14个评估数据集上优于先前的Language Agent，并在新引入的HuskyQA评估集中，即使使用7B模型，也能匹配或超过GPT-4的表现。代码和模型已在GitHub上开源，提供了一个全面的复杂推理解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "50 pages, 42 figures. Project webpage available\n  [here](https://agent-husky.github.io/)",
      "pdf_url": "http://arxiv.org/pdf/2406.06469v1",
      "published_date": "2024-06-10 17:07:25 UTC",
      "updated_date": "2024-06-10 17:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:15:09.081180"
    },
    {
      "arxiv_id": "2406.06467v3",
      "title": "How Far Can Transformers Reason? The Globality Barrier and Inductive Scratchpad",
      "title_zh": "Transformer 能推理到何种程度？全局性障碍与归纳暂存区",
      "authors": [
        "Emmanuel Abbe",
        "Samy Bengio",
        "Aryo Lotfi",
        "Colin Sandon",
        "Omid Saremi"
      ],
      "abstract": "Can Transformers predict new syllogisms by composing established ones? More\ngenerally, what type of targets can be learned by such models from scratch?\nRecent works show that Transformers can be Turing-complete in terms of\nexpressivity, but this does not address the learnability objective. This paper\nputs forward the notion of 'globality degree' of a target distribution to\ncapture when weak learning is efficiently achievable by regular Transformers.\nThis measure shows a contrast with the expressivity results of Transformers\ncaptured by $TC^0/TC^1$ classes (further studied here), since the globality\nrelates to correlations with the more limited $NC^0$ class. We show here\nexperimentally and theoretically under additional assumptions that\ndistributions with high globality cannot be learned efficiently. In particular,\nsyllogisms cannot be composed on long chains. Further, we develop scratchpad\ntechniques and show that: (i) agnostic scratchpads cannot break the globality\nbarrier, (ii) educated scratchpads can break the globality with intermediate\nsteps, although not all such scratchpads can generalize out-of-distribution\n(OOD), (iii) a notion of 'inductive scratchpad', that composes the prior\ninformation more efficiently, can both break the globality barrier and improve\nthe OOD generalization. In particular, some of our inductive scratchpads can\nachieve length generalizations of up to $6\\times$ for some arithmetic tasks\ndepending on the input formatting.",
      "tldr_zh": "本文探讨了Transformer模型的推理极限，引入“globality degree”概念来衡量目标分布是否能被模型高效学习，并与表达性相关的TC^0/NC^0类进行对比。研究发现，高globality的分布（如长链三段论）无法高效学习，实验和理论证明了这一限制。作者开发了scratchpad技术，其中“inductive scratchpad”能打破globality障碍、提升OOD泛化，并在某些算术任务上实现高达6倍的长度泛化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06467v3",
      "published_date": "2024-06-10 17:05:12 UTC",
      "updated_date": "2024-11-01 17:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:15:20.626803"
    },
    {
      "arxiv_id": "2406.06465v1",
      "title": "AID: Adapting Image2Video Diffusion Models for Instruction-guided Video Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Xing",
        "Qi Dai",
        "Zejia Weng",
        "Zuxuan Wu",
        "Yu-Gang Jiang"
      ],
      "abstract": "Text-guided video prediction (TVP) involves predicting the motion of future\nframes from the initial frame according to an instruction, which has wide\napplications in virtual reality, robotics, and content creation. Previous TVP\nmethods make significant breakthroughs by adapting Stable Diffusion for this\ntask. However, they struggle with frame consistency and temporal stability\nprimarily due to the limited scale of video datasets. We observe that\npretrained Image2Video diffusion models possess good priors for video dynamics\nbut they lack textual control. Hence, transferring Image2Video models to\nleverage their video dynamic priors while injecting instruction control to\ngenerate controllable videos is both a meaningful and challenging task. To\nachieve this, we introduce the Multi-Modal Large Language Model (MLLM) to\npredict future video states based on initial frames and text instructions. More\nspecifically, we design a dual query transformer (DQFormer) architecture, which\nintegrates the instructions and frames into the conditional embeddings for\nfuture frame prediction. Additionally, we develop Long-Short Term Temporal\nAdapters and Spatial Adapters that can quickly transfer general video diffusion\nmodels to specific scenarios with minimal training costs. Experimental results\nshow that our method significantly outperforms state-of-the-art techniques on\nfour datasets: Something Something V2, Epic Kitchen-100, Bridge Data, and\nUCF-101. Notably, AID achieves 91.2% and 55.5% FVD improvements on Bridge and\nSSv2 respectively, demonstrating its effectiveness in various domains. More\nexamples can be found at our website https://chenhsing.github.io/AID.",
      "tldr_zh": "该论文提出 AID 方法，将预训练的 Image2Video 扩散模型适应于文本引导的视频预测 (Text-guided video prediction)，以解决帧一致性和时间稳定性问题。\n他们引入 Multi-Modal Large Language Model (MLLM) 结合 Dual Query Transformer (DQFormer) 架构，将文本指令和初始帧整合到条件嵌入中进行未来帧预测，并开发 Long-Short Term Temporal Adapters 和 Spatial Adapters，以最小训练成本转移模型到特定场景。\n实验结果显示，AID 在 Something Something V2、Epic Kitchen-100、Bridge Data 和 UCF-101 数据集上显著优于现有技术，分别在 Bridge 和 SSv2 上实现了 91.2% 和 55.5% 的 FVD 改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06465v1",
      "published_date": "2024-06-10 17:02:08 UTC",
      "updated_date": "2024-06-10 17:02:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:15:34.853234"
    },
    {
      "arxiv_id": "2406.06464v2",
      "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Mike A. Merrill",
        "Akshay Paruchuri",
        "Naghmeh Rezaei",
        "Geza Kovacs",
        "Javier Perez",
        "Yun Liu",
        "Erik Schenck",
        "Nova Hammerquist",
        "Jake Sunshine",
        "Shyam Tailor",
        "Kumar Ayush",
        "Hao-Wei Su",
        "Qian He",
        "Cory Y. McLean",
        "Mark Malhotra",
        "Shwetak Patel",
        "Jiening Zhan",
        "Tim Althoff",
        "Daniel McDuff",
        "Xin Liu"
      ],
      "abstract": "Despite the proliferation of wearable health trackers and the importance of\nsleep and exercise to health, deriving actionable personalized insights from\nwearable data remains a challenge because doing so requires non-trivial\nopen-ended analysis of these data. The recent rise of large language model\n(LLM) agents, which can use tools to reason about and interact with the world,\npresents a promising opportunity to enable such personalized analysis at scale.\nYet, the application of LLM agents in analyzing personal health is still\nlargely untapped. In this paper, we introduce the Personal Health Insights\nAgent (PHIA), an agent system that leverages state-of-the-art code generation\nand information retrieval tools to analyze and interpret behavioral health data\nfrom wearables. We curate two benchmark question-answering datasets of over\n4000 health insights questions. Based on 650 hours of human and expert\nevaluation we find that PHIA can accurately address over 84% of factual\nnumerical questions and more than 83% of crowd-sourced open-ended questions.\nThis work has implications for advancing behavioral health across the\npopulation, potentially enabling individuals to interpret their own wearable\ndata, and paving the way for a new era of accessible, personalized wellness\nregimens that are informed by data-driven insights.",
      "tldr_zh": "该研究探讨了如何利用大型语言模型（LLM）代理从可穿戴设备数据中提取可操作的个性化健康洞见，以解决数据分析的复杂性问题。论文引入了Personal Health Insights Agent (PHIA)系统，该系统结合先进的代码生成和信息检索工具，对睡眠和运动等行为健康数据进行分析和解读。研究构建了两个基准数据集，包含超过4000个健康问题，通过650小时的人类和专家评估，发现PHIA能准确回答84%的事实性数字问题和83%的开放式问题。该工作有望推动大众行为健康发展，实现数据驱动的个性化健康方案，让用户更容易解读自身可穿戴数据。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "38 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.06464v2",
      "published_date": "2024-06-10 17:00:54 UTC",
      "updated_date": "2024-06-11 15:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:15:43.673020"
    },
    {
      "arxiv_id": "2406.06460v1",
      "title": "Towards Real-World Efficiency: Domain Randomization in Reinforcement Learning for Pre-Capture of Free-Floating Moving Targets by Autonomous Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Bahador Beigomi",
        "Zheng H. Zhu"
      ],
      "abstract": "In this research, we introduce a deep reinforcement learning-based control\napproach to address the intricate challenge of the robotic pre-grasping phase\nunder microgravity conditions. Leveraging reinforcement learning eliminates the\nnecessity for manual feature design, therefore simplifying the problem and\nempowering the robot to learn pre-grasping policies through trial and error.\nOur methodology incorporates an off-policy reinforcement learning framework,\nemploying the soft actor-critic technique to enable the gripper to proficiently\napproach a free-floating moving object, ensuring optimal pre-grasp success. For\neffective learning of the pre-grasping approach task, we developed a reward\nfunction that offers the agent clear and insightful feedback. Our case study\nexamines a pre-grasping task where a Robotiq 3F gripper is required to navigate\ntowards a free-floating moving target, pursue it, and subsequently position\nitself at the desired pre-grasp location. We assessed our approach through a\nseries of experiments in both simulated and real-world environments. The source\ncode, along with recordings of real-world robot grasping, is available at\nFanuc_Robotiq_Grasp.",
      "tldr_zh": "本研究提出了一种基于深度强化学习的控制方法，针对自主机器人捕获自由浮动移动目标的预抓取阶段，采用 domain randomization 技术以提升真实世界效率，避免了手动特征设计的复杂性。\n该方法使用 off-policy 强化学习框架和 soft actor-critic 技术，结合一个提供清晰反馈的奖励函数，让机器人通过试错学习有效接近并定位目标。\n实验在模拟和真实环境中评估，证明了该方法在微重力条件下实现预抓取任务的可靠性，并公开了源代码和机器人抓取录像。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This is a preprint for the work submitted to the ICRA 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2406.06460v1",
      "published_date": "2024-06-10 16:54:51 UTC",
      "updated_date": "2024-06-10 16:54:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:15:57.803954"
    },
    {
      "arxiv_id": "2406.06455v2",
      "title": "A Large Language Model Pipeline for Breast Cancer Oncology",
      "title_zh": "翻译失败",
      "authors": [
        "Tristen Pool",
        "Dennis Trujillo"
      ],
      "abstract": "Large language models (LLMs) have demonstrated potential in the innovation of\nmany disciplines. However, how they can best be developed for oncology remains\nunderdeveloped. State-of-the-art OpenAI models were fine-tuned on a clinical\ndataset and clinical guidelines text corpus for two important cancer treatment\nfactors, adjuvant radiation therapy and chemotherapy, using a novel Langchain\nprompt engineering pipeline. A high accuracy (0.85+) was achieved in the\nclassification of adjuvant radiation therapy and chemotherapy for breast cancer\npatients. Furthermore, a confidence interval was formed from observational data\non the quality of treatment from human oncologists to estimate the proportion\nof scenarios in which the model must outperform the original oncologist in its\ntreatment prediction to be a better solution overall as 8.2% to 13.3%. Due to\nindeterminacy in the outcomes of cancer treatment decisions, future\ninvestigation, potentially a clinical trial, would be required to determine if\nthis threshold was met by the models. Nevertheless, with 85% of U.S. cancer\npatients receiving treatment at local community facilities, these kinds of\nmodels could play an important part in expanding access to quality care with\noutcomes that lie, at minimum, close to a human oncologist.",
      "tldr_zh": "本研究开发了一种大型语言模型(LLMs)管道，针对乳腺癌肿瘤学中的辅助放射治疗和化疗决策进行优化，通过微调OpenAI模型和Langchain提示工程，利用临床数据集和指南文本来提升预测准确性。实验结果显示，该模型在分类任务中达到了0.85+的高准确率，并通过观察数据估算模型需在8.2%至13.3%的场景中超越人类肿瘤专家，以整体表现优于后者。未来可能需进行临床试验验证，但此方法有望扩展高质量护理，尤其在美国社区设施中，为更多患者提供接近人类专家水平的治疗支持。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06455v2",
      "published_date": "2024-06-10 16:44:48 UTC",
      "updated_date": "2024-06-13 18:48:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:16:08.386961"
    },
    {
      "arxiv_id": "2406.06451v1",
      "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
      "title_zh": "翻译失败",
      "authors": [
        "Aadarsh Padiyath",
        "Xinying Hou",
        "Amy Pang",
        "Diego Viramontes Vargas",
        "Xingjian Gu",
        "Tamara Nelson-Fromm",
        "Zihan Wu",
        "Mark Guzdial",
        "Barbara Ericson"
      ],
      "abstract": "The capability of large language models (LLMs) to generate, debug, and\nexplain code has sparked the interest of researchers and educators in\nundergraduate programming, with many anticipating their transformative\npotential in programming education. However, decisions about why and how to use\nLLMs in programming education may involve more than just the assessment of an\nLLM's technical capabilities. Using the social shaping of technology theory as\na guiding framework, our study explores how students' social perceptions\ninfluence their own LLM usage. We then examine the correlation of self-reported\nLLM usage with students' self-efficacy and midterm performances in an\nundergraduate programming course. Triangulating data from an anonymous\nend-of-course student survey (n = 158), a mid-course self-efficacy survey\n(n=158), student interviews (n = 10), self-reported LLM usage on homework, and\nmidterm performances, we discovered that students' use of LLMs was associated\nwith their expectations for their future careers and their perceptions of peer\nusage. Additionally, early self-reported LLM usage in our context correlated\nwith lower self-efficacy and lower midterm scores, while students' perceived\nover-reliance on LLMs, rather than their usage itself, correlated with\ndecreased self-efficacy later in the course.",
      "tldr_zh": "这篇论文运用 social shaping of technology theory 探讨了大型语言模型 (LLMs) 在本科编程课程中的采用，焦点在于学生的社会认知（如对未来职业的期望和同伴使用感知）如何影响他们的 LLM 使用习惯。研究通过匿名调查（n=158）、自我效能调查（n=158）、学生访谈（n=10）、自我报告使用和期中成绩进行数据三角验证，发现学生的 LLM 使用与职业期望和同伴行为密切相关。结果显示，早期 LLM 使用与较低的 self-efficacy 和期中成绩相关，而学生感知到的过度依赖 LLM 而非实际使用，会导致课程后期自我效能感的下降。该研究为编程教育中 LLM 的整合提供了重要社会洞见。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to the ACM Conference on International Computing Education\n  Research V.1 (ICER '24 Vol. 1)",
      "pdf_url": "http://arxiv.org/pdf/2406.06451v1",
      "published_date": "2024-06-10 16:40:14 UTC",
      "updated_date": "2024-06-10 16:40:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:16:22.194044"
    },
    {
      "arxiv_id": "2406.06441v1",
      "title": "Interpretability of Language Models via Task Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Weber",
        "Jaap Jumelet",
        "Elia Bruni",
        "Dieuwke Hupkes"
      ],
      "abstract": "The usual way to interpret language models (LMs) is to test their performance\non different benchmarks and subsequently infer their internal processes. In\nthis paper, we present an alternative approach, concentrating on the quality of\nLM processing, with a focus on their language abilities. To this end, we\nconstruct 'linguistic task spaces' -- representations of an LM's language\nconceptualisation -- that shed light on the connections LMs draw between\nlanguage phenomena. Task spaces are based on the interactions of the learning\nsignals from different linguistic phenomena, which we assess via a method we\ncall 'similarity probing'. To disentangle the learning signals of linguistic\nphenomena, we further introduce a method called 'fine-tuning via gradient\ndifferentials' (FTGD). We apply our methods to language models of three\ndifferent scales and find that larger models generalise better to overarching\ngeneral concepts for linguistic tasks, making better use of their shared\nstructure. Further, the distributedness of linguistic processing increases with\npre-training through increased parameter sharing between related linguistic\ntasks. The overall generalisation patterns are mostly stable throughout\ntraining and not marked by incisive stages, potentially explaining the lack of\nsuccessful curriculum strategies for LMs.",
      "tldr_zh": "本文提出一种新方法，通过构建“linguistic task spaces”来解释语言模型(LMs)的语言处理质量，重点揭示LMs在不同语言现象之间的连接。研究引入“similarity probing”评估学习信号的互动，以及“fine-tuning via gradient differentials”(FTGD)方法来分离这些信号。在三种规模的LMs上应用后，发现较大模型在语言任务的总体概念上泛化更好，利用共享结构更高效，且语言处理的分布式性随预训练增加，但泛化模式整体稳定，没有明显阶段性转变。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published at ACL 2024 (main)",
      "pdf_url": "http://arxiv.org/pdf/2406.06441v1",
      "published_date": "2024-06-10 16:34:30 UTC",
      "updated_date": "2024-06-10 16:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:16:33.400083"
    },
    {
      "arxiv_id": "2406.06435v1",
      "title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain",
      "title_zh": "语言模型是可对齐决策者：数据集与医疗分诊领域的应用",
      "authors": [
        "Brian Hu",
        "Bill Ray",
        "Alice Leung",
        "Amy Summerville",
        "David Joy",
        "Christopher Funk",
        "Arslan Basharat"
      ],
      "abstract": "In difficult decision-making scenarios, it is common to have conflicting\nopinions among expert human decision-makers as there may not be a single right\nanswer. Such decisions may be guided by different attributes that can be used\nto characterize an individual's decision. We introduce a novel dataset for\nmedical triage decision-making, labeled with a set of decision-maker attributes\n(DMAs). This dataset consists of 62 scenarios, covering six different DMAs,\nincluding ethical principles such as fairness and moral desert. We present a\nnovel software framework for human-aligned decision-making by utilizing these\nDMAs, paving the way for trustworthy AI with better guardrails. Specifically,\nwe demonstrate how large language models (LLMs) can serve as ethical\ndecision-makers, and how their decisions can be aligned to different DMAs using\nzero-shot prompting. Our experiments focus on different open-source models with\nvarying sizes and training techniques, such as Falcon, Mistral, and Llama 2.\nFinally, we also introduce a new form of weighted self-consistency that\nimproves the overall quantified performance. Our results provide new research\ndirections in the use of LLMs as alignable decision-makers. The dataset and\nopen-source software are publicly available at:\nhttps://github.com/ITM-Kitware/llm-alignable-dm.",
      "tldr_zh": "该研究提出了一种新数据集，包含62个医疗分诊场景和六种决策者属性(DMAs)，如公平性和道德原则，用于处理专家意见分歧的决策场景。论文开发了一个软件框架，通过zero-shot prompting对大型语言模型(LLMs)进行对齐，使其作为可信赖的伦理决策者，并引入加权自一致性方法来提升性能。实验在Falcon、Mistral和Llama 2等开源模型上验证，展示了LLMs在医疗分诊领域的潜力，并为可对齐AI决策提供了新研究方向；数据集和软件已开源在GitHub上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages total (including appendix), NAACL 2024 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2406.06435v1",
      "published_date": "2024-06-10 16:25:23 UTC",
      "updated_date": "2024-06-10 16:25:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:16:45.083809"
    },
    {
      "arxiv_id": "2406.06433v3",
      "title": "DISCO: An End-to-End Bandit Framework for Personalised Discount Allocation",
      "title_zh": "DISCO：端到端的多臂老虎机框架，用于个性化的折扣",
      "authors": [
        "Jason Shuo Zhang",
        "Benjamin Howson",
        "Panayiota Savva",
        "Eleanor Loh"
      ],
      "abstract": "Personalised discount codes provide a powerful mechanism for managing\ncustomer relationships and operational spend in e-commerce. Bandits are well\nsuited for this product area, given the partial information nature of the\nproblem, as well as the need for adaptation to the changing business\nenvironment. Here, we introduce DISCO, an end-to-end contextual bandit\nframework for personalised discount code allocation at ASOS. DISCO adapts the\ntraditional Thompson Sampling algorithm by integrating it within an integer\nprogram, thereby allowing for operational cost control. Because bandit learning\nis often worse with high dimensional actions, we focused on building low\ndimensional action and context representations that were nonetheless capable of\ngood accuracy. Additionally, we sought to build a model that preserved the\nrelationship between price and sales, in which customers increasing their\npurchasing in response to lower prices (\"negative price elasticity\"). These\naims were achieved by using radial basis functions to represent the continuous\n(i.e. infinite armed) action space, in combination with context embeddings\nextracted from a neural network. These feature representations were used within\na Thompson Sampling framework to facilitate exploration, and further integrated\nwith an integer program to allocate discount codes across ASOS's customer base.\nThese modelling decisions result in a reward model that (a) enables pooled\nlearning across similar actions, (b) is highly accurate, including in\nextrapolation, and (c) preserves the expected negative price elasticity.\nThrough offline analysis, we show that DISCO is able to effectively enact\nexploration and improves its performance over time, despite the global\nconstraint. Finally, we subjected DISCO to a rigorous online A/B test, and find\nthat it achieves a significant improvement of >1% in average basket value,\nrelative to the legacy systems.",
      "tldr_zh": "本文提出 DISCO，一个端到端的上下文 bandit 框架，用于电商平台（如 ASOS）的个性化折扣分配，旨在通过适应性算法管理客户关系和操作成本。DISCO 改进了 Thompson Sampling 算法，将其整合到整数程序中，并使用 radial basis functions 表示连续动作空间以及神经网络提取的上下文嵌入，以实现低维表示、支持类似动作的池化学习，并保持负价格弹性。实验结果显示，该框架在离线分析中有效进行探索并提升性能，在在线 A/B 测试中，平均篮子价值提高了超过 1%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ECML/PKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06433v3",
      "published_date": "2024-06-10 16:24:35 UTC",
      "updated_date": "2024-06-12 21:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:17:00.396108"
    },
    {
      "arxiv_id": "2406.06417v2",
      "title": "Explainable Graph Neural Networks Under Fire",
      "title_zh": "翻译失败",
      "authors": [
        "Zhong Li",
        "Simon Geisler",
        "Yuhang Wang",
        "Stephan Günnemann",
        "Matthijs van Leeuwen"
      ],
      "abstract": "Predictions made by graph neural networks (GNNs) usually lack\ninterpretability due to their complex computational behavior and the abstract\nnature of graphs. In an attempt to tackle this, many GNN explanation methods\nhave emerged. Their goal is to explain a model's predictions and thereby obtain\ntrust when GNN models are deployed in decision critical applications. Most GNN\nexplanation methods work in a post-hoc manner and provide explanations in the\nform of a small subset of important edges and/or nodes. In this paper we\ndemonstrate that these explanations can unfortunately not be trusted, as common\nGNN explanation methods turn out to be highly susceptible to adversarial\nperturbations. That is, even small perturbations of the original graph\nstructure that preserve the model's predictions may yield drastically different\nexplanations. This calls into question the trustworthiness and practical\nutility of post-hoc explanation methods for GNNs. To be able to attack GNN\nexplanation models, we devise a novel attack method dubbed \\textit{GXAttack},\nthe first \\textit{optimization-based} adversarial white-box attack method for\npost-hoc GNN explanations under such settings. Due to the devastating\neffectiveness of our attack, we call for an adversarial evaluation of future\nGNN explainers to demonstrate their robustness. For reproducibility, our code\nis available via GitHub.",
      "tldr_zh": "该研究揭示了图神经网络（GNNs）的后验（post-hoc）解释方法存在严重缺陷，这些方法通过重要边和/或节点的子集来解释模型预测，但容易受到对抗性扰动（adversarial perturbations）的攻击，导致即使模型预测不变，解释结果也大相径庭，从而质疑其可信性和实用性。论文提出了一种新型优化-based攻击方法GXAttack，这是首个针对后验GNN解释的白盒攻击工具，实验证明其破坏力极强。作者呼吁未来GNN解释器进行对抗性评估以提升鲁棒性，并提供了GitHub代码以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06417v2",
      "published_date": "2024-06-10 16:09:16 UTC",
      "updated_date": "2024-10-18 05:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:17:14.648001"
    },
    {
      "arxiv_id": "2406.06400v2",
      "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Alva Markelius"
      ],
      "abstract": "The integration of Large Language Models (LLMs) in social robotics presents a\nunique set of ethical challenges and social impacts. This research is set out\nto identify ethical considerations that arise in the design and development of\nthese two technologies in combination. Using LLMs for social robotics may\nprovide benefits, such as enabling natural language open-domain dialogues.\nHowever, the intersection of these two technologies also gives rise to ethical\nconcerns related to misinformation, non-verbal cues, emotional disruption, and\nbiases. The robot's physical social embodiment adds complexity, as ethical\nhazards associated with LLM-based Social AI, such as hallucinations and\nmisinformation, can be exacerbated due to the effects of physical embodiment on\nsocial perception and communication. To address these challenges, this study\nemploys an empirical design justice-based methodology, focusing on identifying\nsocio-technical ethical considerations through a qualitative co-design and\ninteraction study. The purpose of the study is to identify ethical\nconsiderations relevant to the process of co-design of, and interaction with a\nhumanoid social robot as the interface of a LLM, and to evaluate how a design\njustice methodology can be used in the context of designing LLMs-based social\nrobotics. The findings reveal a mapping of ethical considerations arising in\nfour conceptual dimensions: interaction, co-design, terms of service and\nrelationship and evaluates how a design justice approach can be used\nempirically in the intersection of LLMs and social robotics.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）与社交机器人结合时所引发的伦理挑战和社会影响，包括错误信息、非语言线索、情感干扰以及偏见等问题。研究采用基于设计正义的实证方法，通过定性共同设计和互动研究，识别与 humanoid 社交机器人接口相关的社会技术伦理考虑。结果揭示了伦理问题在四个概念维度（interaction、co-design、terms of service and relationship）中的映射，并评估了设计正义方法在 LLMs 和社交机器人交叉领域的实证应用，为更负责任的技术开发提供了指导。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2; K.4; H.5"
      ],
      "primary_category": "cs.RO",
      "comment": "This is a preprint",
      "pdf_url": "http://arxiv.org/pdf/2406.06400v2",
      "published_date": "2024-06-10 15:53:50 UTC",
      "updated_date": "2024-06-12 09:25:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:17:22.803815"
    },
    {
      "arxiv_id": "2406.06399v3",
      "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
      "title_zh": "翻译失败",
      "authors": [
        "Simone Alghisi",
        "Massimo Rizzoli",
        "Gabriel Roccabruna",
        "Seyed Mahed Mousavi",
        "Giuseppe Riccardi"
      ],
      "abstract": "We study the limitations of Large Language Models (LLMs) for the task of\nresponse generation in human-machine dialogue. Several techniques have been\nproposed in the literature for different dialogue types (e.g., Open-Domain).\nHowever, the evaluations of these techniques have been limited in terms of base\nLLMs, dialogue types and evaluation metrics. In this work, we extensively\nanalyze different LLM adaptation techniques when applied to different dialogue\ntypes. We have selected two base LLMs, Llama-2 and Mistral, and four dialogue\ntypes Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering.\nWe evaluate the performance of in-context learning and fine-tuning techniques\nacross datasets selected for each dialogue type. We assess the impact of\nincorporating external knowledge to ground the generation in both scenarios of\nRetrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistent\nevaluation and explainability criteria for automatic metrics and human\nevaluation protocols. Our analysis shows that there is no universal\nbest-technique for adapting large language models as the efficacy of each\ntechnique depends on both the base LLM and the specific type of dialogue. Last\nbut not least, the assessment of the best adaptation technique should include\nhuman evaluation to avoid false expectations and outcomes derived from\nautomatic metrics.",
      "tldr_zh": "本研究评估了在人类-机器对话中适应 Large Language Models (LLMs) 的不同技术，包括 In-Context Learning 和 Fine-Tuning，针对 Open-Domain、Knowledge-Grounded、Task-Oriented 和 Question Answering 等对话类型。使用 Llama-2 和 Mistral 作为基模型，实验比较了这些技术的性能，并探讨了 Retrieval-Augmented Generation (RAG) 和外部知识整合的影响。结果显示，没有通用最佳技术，其效果取决于具体 LLM 和对话类型，且人类评估比自动指标更可靠，以避免误导性结论。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at INLG 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06399v3",
      "published_date": "2024-06-10 15:52:49 UTC",
      "updated_date": "2024-08-03 15:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:17:35.423152"
    },
    {
      "arxiv_id": "2406.06397v2",
      "title": "Contrastive learning of T cell receptor representations",
      "title_zh": "T 细胞受体表征的对比学习",
      "authors": [
        "Yuta Nagano",
        "Andrew Pyo",
        "Martina Milighetti",
        "James Henderson",
        "John Shawe-Taylor",
        "Benny Chain",
        "Andreas Tiffeau-Mayer"
      ],
      "abstract": "Computational prediction of the interaction of T cell receptors (TCRs) and\ntheir ligands is a grand challenge in immunology. Despite advances in\nhigh-throughput assays, specificity-labelled TCR data remains sparse. In other\ndomains, the pre-training of language models on unlabelled data has been\nsuccessfully used to address data bottlenecks. However, it is unclear how to\nbest pre-train protein language models for TCR specificity prediction. Here we\nintroduce a TCR language model called SCEPTR (Simple Contrastive Embedding of\nthe Primary sequence of T cell Receptors), capable of data-efficient transfer\nlearning. Through our model, we introduce a novel pre-training strategy\ncombining autocontrastive learning and masked-language modelling, which enables\nSCEPTR to achieve its state-of-the-art performance. In contrast, existing\nprotein language models and a variant of SCEPTR pre-trained without\nautocontrastive learning are outperformed by sequence alignment-based methods.\nWe anticipate that contrastive learning will be a useful paradigm to decode the\nrules of TCR specificity.",
      "tldr_zh": "该研究针对 T cell receptors (TCRs) 与配体相互作用的计算预测问题，提出了一种数据高效的语言模型 SCEPTR（Simple Contrastive Embedding of the Primary sequence of T cell Receptors）。SCEPTR 采用创新的预训练策略，将 autocontrastive learning 与 masked-language modelling 相结合，实现对无标签数据的有效利用。实验结果显示，SCEPTR 在 TCR 特异性预测中超越了现有蛋白质语言模型和基于序列比对的方法，展示了其在转移学习中的优越性能。该方法有望成为解码 TCR 特异性规则的重要范式。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "J.3; I.2.7"
      ],
      "primary_category": "q-bio.BM",
      "comment": "25 pages, 23 figures; additional analyses and improvements to\n  existing figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06397v2",
      "published_date": "2024-06-10 15:50:45 UTC",
      "updated_date": "2024-10-10 10:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:17:49.362773"
    },
    {
      "arxiv_id": "2406.06385v3",
      "title": "Low-Rank Quantization-Aware Training for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yelysei Bondarenko",
        "Riccardo Del Chiaro",
        "Markus Nagel"
      ],
      "abstract": "Large language models (LLMs) are omnipresent, however their practical\ndeployment is challenging due to their ever increasing computational and memory\ndemands. Quantization is one of the most effective ways to make them more\ncompute and memory efficient. Quantization-aware training (QAT) methods,\ngenerally produce the best quantized performance, however it comes at the cost\nof potentially long training time and excessive memory usage, making it\nimpractical when applying for LLMs. Inspired by parameter-efficient fine-tuning\n(PEFT) and low-rank adaptation (LoRA) literature, we propose LR-QAT -- a\nlightweight and memory-efficient QAT algorithm for LLMs. LR-QAT employs several\ncomponents to save memory without sacrificing predictive performance: (a)\nlow-rank auxiliary weights that are aware of the quantization grid; (b) a\ndowncasting operator using fixed-point or double-packed integers and (c)\ncheckpointing. Unlike most related work, our method (i) is inference-efficient,\nleading to no additional overhead compared to traditional PTQ; (ii) can be seen\nas a general extended pretraining framework, meaning that the resulting model\ncan still be utilized for any downstream task afterwards; (iii) can be applied\nacross a wide range of quantization settings, such as different choices\nquantization granularity, activation quantization, and seamlessly combined with\nmany PTQ techniques. We apply LR-QAT to LLaMA-1/2/3 and Mistral model families\nand validate its effectiveness on several downstream tasks. Our method\noutperforms common post-training quantization (PTQ) approaches and reaches the\nsame model performance as full-model QAT at the fraction of its memory usage.\nSpecifically, we can train a 7B LLM on a single consumer grade GPU with 24GB of\nmemory. Our source code is available at\nhttps://github.com/qualcomm-ai-research/LR-QAT",
      "tldr_zh": "本文提出了一种轻量级量化感知训练方法LR-QAT，用于解决大型语言模型(LLMs)的计算和内存效率问题。该方法受参数高效微调(PEFT)和低秩适应(LoRA)启发，通过引入低秩辅助权重、downcasting operator（如fixed-point或double-packed integers）和checkpointing组件，实现高效训练，同时保持量化网格感知。实验结果显示，LR-QAT在LLaMA-1/2/3和Mistral模型上优于传统后训练量化(PTQ)方法，达到全模型QAT的性能水平，但内存使用大幅减少，能在单张24GB消费级GPU上训练7B LLM模型。总之，LR-QAT作为一种通用扩展预训练框架，支持多种量化设置，并适用于下游任务。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06385v3",
      "published_date": "2024-06-10 15:44:22 UTC",
      "updated_date": "2024-09-03 16:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:18:02.123991"
    },
    {
      "arxiv_id": "2406.06375v1",
      "title": "MOSA: Music Motion with Semantic Annotation Dataset for Cross-Modal Music Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Fen Huang",
        "Nikki Moran",
        "Simon Coleman",
        "Jon Kelly",
        "Shun-Hwa Wei",
        "Po-Yin Chen",
        "Yun-Hsin Huang",
        "Tsung-Ping Chen",
        "Yu-Chia Kuo",
        "Yu-Chi Wei",
        "Chih-Hsuan Li",
        "Da-Yu Huang",
        "Hsuan-Kai Kao",
        "Ting-Wei Lin",
        "Li Su"
      ],
      "abstract": "In cross-modal music processing, translation between visual, auditory, and\nsemantic content opens up new possibilities as well as challenges. The\nconstruction of such a transformative scheme depends upon a benchmark corpus\nwith a comprehensive data infrastructure. In particular, the assembly of a\nlarge-scale cross-modal dataset presents major challenges. In this paper, we\npresent the MOSA (Music mOtion with Semantic Annotation) dataset, which\ncontains high quality 3-D motion capture data, aligned audio recordings, and\nnote-by-note semantic annotations of pitch, beat, phrase, dynamic,\narticulation, and harmony for 742 professional music performances by 23\nprofessional musicians, comprising more than 30 hours and 570 K notes of data.\nTo our knowledge, this is the largest cross-modal music dataset with note-level\nannotations to date. To demonstrate the usage of the MOSA dataset, we present\nseveral innovative cross-modal music information retrieval (MIR) and musical\ncontent generation tasks, including the detection of beats, downbeats, phrase,\nand expressive contents from audio, video and motion data, and the generation\nof musicians' body motion from given music audio. The dataset and codes are\navailable alongside this publication\n(https://github.com/yufenhuang/MOSA-Music-mOtion-and-Semantic-Annotation-dataset).",
      "tldr_zh": "本文提出 MOSA 数据集，用于跨模态音乐处理（cross-modal music processing），旨在促进视觉、听觉和语义内容的转换。数据集包括 742 次专业音乐表演的 3-D 动作捕捉数据、对齐音频记录以及音符级别的语义注释（如音高、节拍、短语、动态、连奏和和声），总计超过 30 小时和 570K 音符，是目前最大的此类数据集。论文展示了数据集的应用，包括音乐信息检索 (MIR) 任务（如从音频、视频和动作数据检测节拍、下拍、短语和表现内容）以及音乐内容生成任务（如从给定音频生成音乐家的身体动作）。数据集和代码已开源（https://github.com/yufenhuang/MOSA-Music-mOtion-and-Semantic-Annotation-dataset）。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "IEEE/ACM Transactions on Audio, Speech, and Language Processing,\n  2024. 14 pages, 7 figures. Dataset is available on:\n  https://github.com/yufenhuang/MOSA-Music-mOtion-and-Semantic-Annotation-dataset/tree/main\n  and https://zenodo.org/records/11393449",
      "pdf_url": "http://arxiv.org/pdf/2406.06375v1",
      "published_date": "2024-06-10 15:37:46 UTC",
      "updated_date": "2024-06-10 15:37:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:18:13.715811"
    },
    {
      "arxiv_id": "2406.06372v1",
      "title": "Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Marek Wodzinski",
        "Kamil Kwarciak",
        "Mateusz Daniol",
        "Daria Hemmerling"
      ],
      "abstract": "Modeling and manufacturing of personalized cranial implants are important\nresearch areas that may decrease the waiting time for patients suffering from\ncranial damage. The modeling of personalized implants may be partially\nautomated by the use of deep learning-based methods. However, this task suffers\nfrom difficulties with generalizability into data from previously unseen\ndistributions that make it difficult to use the research outcomes in real\nclinical settings. Due to difficulties with acquiring ground-truth annotations,\ndifferent techniques to improve the heterogeneity of datasets used for training\nthe deep networks have to be considered and introduced. In this work, we\npresent a large-scale study of several augmentation techniques, varying from\nclassical geometric transformations, image registration, variational\nautoencoders, and generative adversarial networks, to the most recent advances\nin latent diffusion models. We show that the use of heavy data augmentation\nsignificantly increases both the quantitative and qualitative outcomes,\nresulting in an average Dice Score above 0.94 for the SkullBreak and above 0.96\nfor the SkullFix datasets. Moreover, we show that the synthetically augmented\nnetwork successfully reconstructs real clinical defects. The work is a\nconsiderable contribution to the field of artificial intelligence in the\nautomatic modeling of personalized cranial implants.",
      "tldr_zh": "该研究旨在通过大量数据增强技术改善基于深度学习的颅骨缺陷自动重建方法，以提升模型对新数据分布的泛化能力。研究评估了多种增强策略，包括几何变换、图像注册、变分自编码器(Variational Autoencoders)、生成对抗网络(Generative Adversarial Networks)以及潜在扩散模型(Latent Diffusion Models)。结果显示，这些增强技术显著提高了模型性能，在SkullBreak数据集上Dice Score超过0.94，在SkullFix数据集上超过0.96，并成功应用于真实临床缺陷重建。该工作为人工智能在个性化颅骨植入物自动建模领域提供了重要贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06372v1",
      "published_date": "2024-06-10 15:34:23 UTC",
      "updated_date": "2024-06-10 15:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:18:23.671911"
    },
    {
      "arxiv_id": "2406.06363v1",
      "title": "Automating Food Drop: The Power of Two Choices for Dynamic and Fair Food Allocation",
      "title_zh": "翻译失败",
      "authors": [
        "Marios Mertzanidis",
        "Alexandros Psomas",
        "Paritosh Verma"
      ],
      "abstract": "Food waste and food insecurity are two closely related pressing global\nissues. Food rescue organizations worldwide run programs aimed at addressing\nthe two problems. In this paper, we partner with a non-profit organization in\nthe state of Indiana that leads \\emph{Food Drop}, a program that is designed to\nredirect rejected truckloads of food away from landfills and into food banks.\nThe truckload to food bank matching decisions are currently made by an employee\nof our partner organization. In addition to this being a very time-consuming\ntask, as perhaps expected from human-based matching decisions, the allocations\nare often skewed: a small percentage of the possible recipients receives the\nmajority of donations. Our goal in this partnership is to completely automate\nFood Drop. In doing so, we need a matching algorithm for making real-time\ndecisions that strikes a balance between ensuring fairness for the food banks\nthat receive the food and optimizing efficiency for the truck drivers. In this\npaper, we describe the theoretical guarantees and experiments that dictated our\nchoice of algorithm in the platform we built and deployed for our partner\norganization. Our work also makes contributions to the literature on load\nbalancing and balls-into-bins games, that might be of independent interest.\nSpecifically, we study the allocation of $m$ weighted balls into $n$ weighted\nbins, where each ball has two non-uniformly sampled random bin choices, and\nprove upper bounds, that hold with high probability, on the maximum load of any\nbin.",
      "tldr_zh": "这篇论文针对食物浪费和食物不安全问题，合作开发了自动化 Food Drop 平台，以优化卡车货物从垃圾填埋场转向食物银行的分配过程。研究提出使用 The Power of Two Choices 算法进行实时匹配决策，该算法平衡了食物银行的公平性（如避免分配倾斜）和卡车司机的效率，并在理论上证明了 m 个加权球分配到 n 个加权 bin 的最大负载上界。实验验证和部署结果表明，该方法显著改善了分配公平性，并为负载 balancing 和 balls-into-bins games 文献提供了新贡献。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06363v1",
      "published_date": "2024-06-10 15:22:41 UTC",
      "updated_date": "2024-06-10 15:22:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:18:35.846886"
    },
    {
      "arxiv_id": "2406.10256v1",
      "title": "Explicit Word Density Estimation for Language Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Jovan Andonov",
        "Octavian Ganea",
        "Paulina Grnarova",
        "Gary Bécigneul",
        "Thomas Hofmann"
      ],
      "abstract": "Language Modelling has been a central part of Natural Language Processing for\na very long time and in the past few years LSTM-based language models have been\nthe go-to method for commercial language modeling. Recently, it has been shown\nthat when looking at language modelling from a matrix factorization point of\nview, the final Softmax layer limits the expressiveness of the model, by\nputting an upper bound on the rank of the resulting matrix. Additionally, a new\nfamily of neural networks based called NeuralODEs, has been introduced as a\ncontinuous alternative to Residual Networks. Moreover, it has been shown that\nthere is a connection between these models and Normalizing Flows. In this work\nwe propose a new family of language models based on NeuralODEs and the\ncontinuous analogue of Normalizing Flows and manage to improve on some of the\nbaselines.",
      "tldr_zh": "该论文探讨了 Language Modelling 中的问题，指出传统 LSTM 模型受 Softmax 层限制，导致矩阵秩的上限影响模型表达性，同时引入 NeuralODEs 作为 Residual Networks 的连续替代，并强调其与 Normalizing Flows 的联系。作者提出了一种新语言模型家族，基于 NeuralODEs 和 Normalizing Flows 的连续版本，以提升模型性能。实验结果显示，该方法在某些基线上取得了改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Master's thesis",
      "pdf_url": "http://arxiv.org/pdf/2406.10256v1",
      "published_date": "2024-06-10 15:21:33 UTC",
      "updated_date": "2024-06-10 15:21:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:18:46.875567"
    },
    {
      "arxiv_id": "2406.06357v1",
      "title": "MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows",
      "title_zh": "翻译失败",
      "authors": [
        "Xingjian Zhang",
        "Yutong Xie",
        "Jin Huang",
        "Jinge Ma",
        "Zhaoying Pan",
        "Qijia Liu",
        "Ziyang Xiong",
        "Tolga Ergen",
        "Dongsub Shim",
        "Honglak Lee",
        "Qiaozhu Mei"
      ],
      "abstract": "Scientific innovation relies on detailed workflows, which include critical\nsteps such as analyzing literature, generating ideas, validating these ideas,\ninterpreting results, and inspiring follow-up research. However, scientific\npublications that document these workflows are extensive and unstructured. This\nmakes it difficult for both human researchers and AI systems to effectively\nnavigate and explore the space of scientific innovation. To address this issue,\nwe introduce MASSW, a comprehensive text dataset on Multi-Aspect Summarization\nof Scientific Workflows. MASSW includes more than 152,000 peer-reviewed\npublications from 17 leading computer science conferences spanning the past 50\nyears. Using Large Language Models (LLMs), we automatically extract five core\naspects from these publications -- context, key idea, method, outcome, and\nprojected impact -- which correspond to five key steps in the research\nworkflow. These structured summaries facilitate a variety of downstream tasks\nand analyses. The quality of the LLM-extracted summaries is validated by\ncomparing them with human annotations. We demonstrate the utility of MASSW\nthrough multiple novel machine-learning tasks that can be benchmarked using\nthis new dataset, which make various types of predictions and recommendations\nalong the scientific workflow. MASSW holds significant potential for\nresearchers to create and benchmark new AI methods for optimizing scientific\nworkflows and fostering scientific innovation in the field. Our dataset is\nopenly available at \\url{https://github.com/xingjian-zhang/massw}.",
      "tldr_zh": "本文引入了 MASSW，这是一个新的文本数据集，包含超过 15.2 万篇计算机科学会议论文，旨在辅助 AI 优化科学工作流的多方面总结。数据集使用 Large Language Models (LLMs) 自动提取论文的五个核心方面：context, key idea, method, outcome, and projected impact，这些对应于研究工作流的關鍵步骤。提取质量通过与人类注解比较得到验证，并支持多种下游机器学习任务，如预测和推荐。MASSW 的公开可用性为开发新 AI 方法以促进科学创新提供了重要基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: text overlap with arXiv:1706.03762 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2406.06357v1",
      "published_date": "2024-06-10 15:19:09 UTC",
      "updated_date": "2024-06-10 15:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:19:01.272789"
    },
    {
      "arxiv_id": "2406.06356v1",
      "title": "Re.Dis.Cover Place with Generative AI: Exploring the Experience and Design of City Wandering with Image-to-Image AI",
      "title_zh": "翻译失败",
      "authors": [
        "Peng-Kai Hung",
        "Janet Yi-Ching Huang",
        "Stephan Wensveen",
        "Rung-Huei Liang"
      ],
      "abstract": "The HCI field has demonstrated a growing interest in leveraging emerging\ntechnologies to enrich urban experiences. However, insufficient studies\ninvestigate the experience and design space of AI image technology (AIGT)\napplications for playful urban interaction, despite its widespread adoption. To\nexplore this gap, we conducted an exploratory study involving four participants\nwho wandered and photographed within Eindhoven Centre and interacted with an\nimage-to-image AI. Preliminary findings present their observations, the effect\nof their familiarity with places, and how AIGT becomes an explorer's tool or\nco-speculator. We then highlight AIGT's capability of supporting playfulness,\nreimaginations, and rediscoveries of places through defamiliarizing and\nfamiliarizing cityscapes. Additionally, we propose the metaphor AIGT as a\n'tourist' to discuss its opportunities for engaging explorations and risks of\nstereotyping places. Collectively, our research provides initial empirical\ninsights and design considerations, inspiring future HCI endeavors for creating\nurban play with generative AI.",
      "tldr_zh": "本研究探讨了HCI领域中利用image-to-image AI（AIGT）增强城市漫游体验的设计空间，以填补相关经验研究的空白。通过一项探索性研究，四名参与者在Eindhoven Centre漫游、拍照并与AIGT互动，初步发现显示AIGT能作为探索工具或共同推测者，影响参与者对地方的熟悉程度，并通过陌生化和熟悉化城市景观支持玩乐性、再想象和重新发现。论文提出AIGT作为“tourist”的隐喻，讨论其促进深度探索的机会以及固化地方刻板印象的风险。总体上，该研究提供初步经验洞见和设计考虑，激发未来HCI领域使用生成AI创建城市互动的设计创新。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06356v1",
      "published_date": "2024-06-10 15:18:14 UTC",
      "updated_date": "2024-06-10 15:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:19:16.121728"
    },
    {
      "arxiv_id": "2406.06341v1",
      "title": "Predicting Heart Activity from Speech using Data-driven and Knowledge-based features",
      "title_zh": "翻译失败",
      "authors": [
        "Gasser Elbanna",
        "Zohreh Mostaani",
        "Mathew Magimai. -Doss"
      ],
      "abstract": "Accurately predicting heart activity and other biological signals is crucial\nfor diagnosis and monitoring. Given that speech is an outcome of multiple\nphysiological systems, a significant body of work studied the acoustic\ncorrelates of heart activity. Recently, self-supervised models have excelled in\nspeech-related tasks compared to traditional acoustic methods. However, the\nrobustness of data-driven representations in predicting heart activity remained\nunexplored. In this study, we demonstrate that self-supervised speech models\noutperform acoustic features in predicting heart activity parameters. We also\nemphasize the impact of individual variability on model generalizability. These\nfindings underscore the value of data-driven representations in such tasks and\nthe need for more speech-based physiological data to mitigate speaker-related\nchallenges.",
      "tldr_zh": "这篇论文探讨了使用数据驱动和知识-based 特征从语音预测心脏活动的重要性，以支持诊断和监测。研究比较了自-supervised speech models 与传统 acoustic features，结果显示自-supervised models 在预测心脏活动参数时表现出色。论文还强调了个体变异性对模型泛化能力的影响，并呼吁收集更多语音-based 生理数据来解决与说话者相关的挑战。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06341v1",
      "published_date": "2024-06-10 15:01:46 UTC",
      "updated_date": "2024-06-10 15:01:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:19:35.180632"
    },
    {
      "arxiv_id": "2406.06340v1",
      "title": "Optimisation of federated learning settings under statistical heterogeneity variations",
      "title_zh": "翻译失败",
      "authors": [
        "Basem Suleiman",
        "Muhammad Johan Alibasa",
        "Rizka Widyarini Purwanto",
        "Lewis Jeffries",
        "Ali Anaissi",
        "Jacky Song"
      ],
      "abstract": "Federated Learning (FL) enables local devices to collaboratively learn a\nshared predictive model by only periodically sharing model parameters with a\ncentral aggregator. However, FL can be disadvantaged by statistical\nheterogeneity produced by the diversity in each local devices data\ndistribution, which creates different levels of Independent and Identically\nDistributed (IID) data. Furthermore, this can be more complex when optimising\ndifferent combinations of FL parameters and choosing optimal aggregation. In\nthis paper, we present an empirical analysis of different FL training\nparameters and aggregators over various levels of statistical heterogeneity on\nthree datasets. We propose a systematic data partition strategy to simulate\ndifferent levels of statistical heterogeneity and a metric to measure the level\nof IID. Additionally, we empirically identify the best FL model and key\nparameters for datasets of different characteristics. On the basis of these, we\npresent recommended guidelines for FL parameters and aggregators to optimise\nmodel performance under different levels of IID and with different datasets",
      "tldr_zh": "该论文探讨了在统计异质性（statistical heterogeneity）变化下对Federated Learning (FL)设置的优化问题，FL允许设备协作训练共享模型，但数据分布多样性导致不同水平的Independent and Identically Distributed (IID)数据。研究者提出了一种系统的数据分区策略和IID度量指标，并在三个数据集上对各种FL参数和聚合器进行经验分析。最终，他们识别出适合不同数据集特征的最佳FL模型和关键参数，并提供优化指南，以提升模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06340v1",
      "published_date": "2024-06-10 15:01:03 UTC",
      "updated_date": "2024-06-10 15:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:19:37.946773"
    },
    {
      "arxiv_id": "2406.06331v2",
      "title": "MedExQA: Medical Question Answering Benchmark with Multiple Explanations",
      "title_zh": "MedExQA：带有多个解释的医疗问答基准",
      "authors": [
        "Yunsoo Kim",
        "Jinge Wu",
        "Yusuf Abdulle",
        "Honghan Wu"
      ],
      "abstract": "This paper introduces MedExQA, a novel benchmark in medical\nquestion-answering, to evaluate large language models' (LLMs) understanding of\nmedical knowledge through explanations. By constructing datasets across five\ndistinct medical specialties that are underrepresented in current datasets and\nfurther incorporating multiple explanations for each question-answer pair, we\naddress a major gap in current medical QA benchmarks which is the absence of\ncomprehensive assessments of LLMs' ability to generate nuanced medical\nexplanations. Our work highlights the importance of explainability in medical\nLLMs, proposes an effective methodology for evaluating models beyond\nclassification accuracy, and sheds light on one specific domain, speech\nlanguage pathology, where current LLMs including GPT4 lack good understanding.\nOur results show generation evaluation with multiple explanations aligns better\nwith human assessment, highlighting an opportunity for a more robust automated\ncomprehension assessment for LLMs. To diversify open-source medical LLMs\n(currently mostly based on Llama2), this work also proposes a new medical\nmodel, MedPhi-2, based on Phi-2 (2.7B). The model outperformed medical LLMs\nbased on Llama2-70B in generating explanations, showing its effectiveness in\nthe resource-constrained medical domain. We will share our benchmark datasets\nand the trained model.",
      "tldr_zh": "本研究引入了MedExQA，一种新型医疗问答基准，用于评估大型语言模型(LLMs)的医疗知识理解能力，特别是通过生成多个解释来填补现有基准的不足。该基准构建了覆盖五个 underrepresented 医疗专业的数据集，每个问题-答案对包含多重解释，并强调了解释性在医疗LLMs中的重要性，同时揭示了当前LLMs（如GPT4）在语音语言病理学领域的理解缺陷。结果显示，使用多个解释的生成评估更符合人类评估，且新提出的MedPhi-2模型（基于Phi-2，2.7B参数）在解释生成方面优于基于Llama2-70B的医疗LLMs，研究者将共享数据集和模型以促进进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL2024 BioNLP Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.06331v2",
      "published_date": "2024-06-10 14:47:04 UTC",
      "updated_date": "2024-07-03 10:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:19:50.322542"
    },
    {
      "arxiv_id": "2406.06316v1",
      "title": "Tx-LLM: A Large Language Model for Therapeutics",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Manuel Zambrano Chaves",
        "Eric Wang",
        "Tao Tu",
        "Eeshit Dhaval Vaishnav",
        "Byron Lee",
        "S. Sara Mahdavi",
        "Christopher Semturs",
        "David Fleet",
        "Vivek Natarajan",
        "Shekoofeh Azizi"
      ],
      "abstract": "Developing therapeutics is a lengthy and expensive process that requires the\nsatisfaction of many different criteria, and AI models capable of expediting\nthe process would be invaluable. However, the majority of current AI approaches\naddress only a narrowly defined set of tasks, often circumscribed within a\nparticular domain. To bridge this gap, we introduce Tx-LLM, a generalist large\nlanguage model (LLM) fine-tuned from PaLM-2 which encodes knowledge about\ndiverse therapeutic modalities. Tx-LLM is trained using a collection of 709\ndatasets that target 66 tasks spanning various stages of the drug discovery\npipeline. Using a single set of weights, Tx-LLM simultaneously processes a wide\nvariety of chemical or biological entities(small molecules, proteins, nucleic\nacids, cell lines, diseases) interleaved with free-text, allowing it to predict\na broad range of associated properties, achieving competitive with\nstate-of-the-art (SOTA) performance on 43 out of 66 tasks and exceeding SOTA on\n22. Among these, Tx-LLM is particularly powerful and exceeds best-in-class\nperformance on average for tasks combining molecular SMILES representations\nwith text such as cell line names or disease names, likely due to context\nlearned during pretraining. We observe evidence of positive transfer between\ntasks with diverse drug types (e.g.,tasks involving small molecules and tasks\ninvolving proteins), and we study the impact of model size, domain finetuning,\nand prompting strategies on performance. We believe Tx-LLM represents an\nimportant step towards LLMs encoding biochemical knowledge and could have a\nfuture role as an end-to-end tool across the drug discovery development\npipeline.",
      "tldr_zh": "本研究引入 Tx-LLM，这是一个从 PaLM-2 微调而来的通用 Large Language Model (LLM)，旨在加速治疗开发过程，通过编码多样化的生化知识处理药物发现管道中的各种任务。Tx-LLM 使用 709 个数据集训练，覆盖 66 个任务，包括处理小分子、蛋白质、核酸、细胞系和疾病等实体与自由文本的组合，并在 43 个任务上达到与 State-of-the-Art (SOTA) 相当的性能，在 22 个任务上超过 SOTA。模型特别在结合分子 SMILES 表示与文本的任务中表现出色，并展示了任务之间的正向转移（如小分子和蛋白质任务）。总之，Tx-LLM 代表了 LLM 在生化知识编码方面的关键进展，有望成为药物发现管道的端到端工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06316v1",
      "published_date": "2024-06-10 14:33:02 UTC",
      "updated_date": "2024-06-10 14:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:20:02.535028"
    },
    {
      "arxiv_id": "2406.06309v2",
      "title": "Is Value Functions Estimation with Classification Plug-and-play for Offline Reinforcement Learning?",
      "title_zh": "使用分类的价值函数估计在离线强化学习中",
      "authors": [
        "Denis Tarasov",
        "Kirill Brilliantov",
        "Dmitrii Kharlapenko"
      ],
      "abstract": "In deep Reinforcement Learning (RL), value functions are typically\napproximated using deep neural networks and trained via mean squared error\nregression objectives to fit the true value functions. Recent research has\nproposed an alternative approach, utilizing the cross-entropy classification\nobjective, which has demonstrated improved performance and scalability of RL\nalgorithms. However, existing study have not extensively benchmarked the\neffects of this replacement across various domains, as the primary objective\nwas to demonstrate the efficacy of the concept across a broad spectrum of\ntasks, without delving into in-depth analysis. Our work seeks to empirically\ninvestigate the impact of such a replacement in an offline RL setup and analyze\nthe effects of different aspects on performance. Through large-scale\nexperiments conducted across a diverse range of tasks using different\nalgorithms, we aim to gain deeper insights into the implications of this\napproach. Our results reveal that incorporating this change can lead to\nsuperior performance over state-of-the-art solutions for some algorithms in\ncertain tasks, while maintaining comparable performance levels in other tasks,\nhowever for other algorithms this modification might lead to the dramatic\nperformance drop. This findings are crucial for further application of\nclassification approach in research and practical tasks.",
      "tldr_zh": "本文研究了在离线Reinforcement Learning中，使用交叉熵分类目标来估计价值函数是否能实现即插即用的效果，以替代传统的均方误差回归方法。通过大规模实验，评估了这种替换在不同算法和任务中的影响，结果显示它在某些任务中使性能优于最先进方案，在其他任务中保持相当水平，但对某些算法可能导致显著性能下降。这些发现为交叉熵分类方法在Reinforcement Learning研究和实际应用中的进一步推广提供了关键洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/DT6A/ClORL",
      "pdf_url": "http://arxiv.org/pdf/2406.06309v2",
      "published_date": "2024-06-10 14:25:11 UTC",
      "updated_date": "2024-11-16 14:03:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:20:13.264627"
    },
    {
      "arxiv_id": "2406.06305v1",
      "title": "NeuroMoCo: A Neuromorphic Momentum Contrast Learning Method for Spiking Neural Networks",
      "title_zh": "NeuroMoCo：一种针对脉冲神经网络的神经形态动量",
      "authors": [
        "Yuqi Ma",
        "Huamin Wang",
        "Hangchi Shen",
        "Xuemei Chen",
        "Shukai Duan",
        "Shiping Wen"
      ],
      "abstract": "Recently, brain-inspired spiking neural networks (SNNs) have attracted great\nresearch attention owing to their inherent bio-interpretability,\nevent-triggered properties and powerful perception of spatiotemporal\ninformation, which is beneficial to handling event-based neuromorphic datasets.\nIn contrast to conventional static image datasets, event-based neuromorphic\ndatasets present heightened complexity in feature extraction due to their\ndistinctive time series and sparsity characteristics, which influences their\nclassification accuracy. To overcome this challenge, a novel approach termed\nNeuromorphic Momentum Contrast Learning (NeuroMoCo) for SNNs is introduced in\nthis paper by extending the benefits of self-supervised pre-training to SNNs to\neffectively stimulate their potential. This is the first time that\nself-supervised learning (SSL) based on momentum contrastive learning is\nrealized in SNNs. In addition, we devise a novel loss function named MixInfoNCE\ntailored to their temporal characteristics to further increase the\nclassification accuracy of neuromorphic datasets, which is verified through\nrigorous ablation experiments. Finally, experiments on DVS-CIFAR10,\nDVS128Gesture and N-Caltech101 have shown that NeuroMoCo of this paper\nestablishes new state-of-the-art (SOTA) benchmarks: 83.6% (Spikformer-2-256),\n98.62% (Spikformer-2-256), and 84.4% (SEW-ResNet-18), respectively.",
      "tldr_zh": "本文提出了一种名为 NeuroMoCo 的 neuromorphic momentum contrast learning 方法，针对 spiking neural networks (SNNs) 处理事件-based neuromorphic 数据集的特征提取挑战，通过引入 self-supervised learning (SSL) 基于 momentum contrastive learning 来提升模型性能。创新点包括设计了新的 MixInfoNCE 损失函数，以适应数据集的时序和稀疏特性，并通过消融实验验证其有效性。在 DVS-CIFAR10、DVS128Gesture 和 N-Caltech101 数据集上，NeuroMoCo 达到了新的 state-of-the-art (SOTA) 结果，准确率分别为 83.6% (Spikformer-2-256)、98.62% (Spikformer-2-256) 和 84.4% (SEW-ResNet-18)。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages,4 figures,4 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.06305v1",
      "published_date": "2024-06-10 14:20:48 UTC",
      "updated_date": "2024-06-10 14:20:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:20:27.631092"
    },
    {
      "arxiv_id": "2406.10254v1",
      "title": "Towards Signal Processing In Large Language Models",
      "title_zh": "迈向大型语言模型中的信号处理",
      "authors": [
        "Prateek Verma",
        "Mert Pilanci"
      ],
      "abstract": "This paper introduces the idea of applying signal processing inside a Large\nLanguage Model (LLM). With the recent explosion of generative AI, our work can\nhelp bridge two fields together, namely the field of signal processing and\nlarge language models. We draw parallels between classical Fourier-Transforms\nand Fourier Transform-like learnable time-frequency representations for every\nintermediate activation signal of an LLM. Once we decompose every activation\nsignal across tokens into a time-frequency representation, we learn how to\nfilter and reconstruct them, with all components learned from scratch, to\npredict the next token given the previous context. We show that for GPT-like\narchitectures, our work achieves faster convergence and significantly increases\nperformance by adding a minuscule number of extra parameters when trained for\nthe same epochs. We hope this work paves the way for algorithms exploring\nsignal processing inside the signals found in neural architectures like LLMs\nand beyond.",
      "tldr_zh": "本论文探讨在大型语言模型（LLM）内部应用信号处理的理念，以桥接信号处理领域与LLM领域。研究者将经典的Fourier-Transforms与LLM激活信号的可学习时频表示类比，通过分解、过滤和重建这些信号来预测下一个token，所有组件从零开始训练。在GPT-like架构中，该方法仅添加少量额外参数，便实现了更快收敛和显著性能提升。该工作有望为探索LLM等神经架构中信号处理的算法铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.10254v1",
      "published_date": "2024-06-10 13:51:52 UTC",
      "updated_date": "2024-06-10 13:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:20:36.998866"
    },
    {
      "arxiv_id": "2406.06262v1",
      "title": "Modular Growth of Hierarchical Networks: Efficient, General, and Robust Curriculum Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mani Hamidi",
        "Sina Khajehabdollahi",
        "Emmanouil Giannakakis",
        "Tim Schäfer",
        "Anna Levina",
        "Charley M. Wu"
      ],
      "abstract": "Structural modularity is a pervasive feature of biological neural networks,\nwhich have been linked to several functional and computational advantages. Yet,\nthe use of modular architectures in artificial neural networks has been\nrelatively limited despite early successes. Here, we explore the performance\nand functional dynamics of a modular network trained on a memory task via an\niterative growth curriculum. We find that for a given classical, non-modular\nrecurrent neural network (RNN), an equivalent modular network will perform\nbetter across multiple metrics, including training time, generalizability, and\nrobustness to some perturbations. We further examine how different aspects of a\nmodular network's connectivity contribute to its computational capability. We\nthen demonstrate that the inductive bias introduced by the modular topology is\nstrong enough for the network to perform well even when the connectivity within\nmodules is fixed and only the connections between modules are trained. Our\nfindings suggest that gradual modular growth of RNNs could provide advantages\nfor learning increasingly complex tasks on evolutionary timescales, and help\nbuild more scalable and compressible artificial networks.",
      "tldr_zh": "本研究探讨了模块化网络（modular networks）在神经网络中的应用，强调其结构模块性如何提升训练效率、泛化性和鲁棒性。研究者通过迭代增长课程（curriculum learning）训练模块化网络在记忆任务上的性能，发现与经典的非模块化RNN相比，模块化网络在训练时间、泛化能力和对某些扰动的鲁棒性方面表现出显著优势。进一步分析显示，模块化拓扑的归纳偏差（inductive bias）强大，即使模块内部连接固定，只训练模块间连接，网络也能有效执行任务。这些发现表明，渐进的模块化增长有助于在进化时间尺度上学习更复杂的任务，并构建更可扩展和可压缩的人工网络。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06262v1",
      "published_date": "2024-06-10 13:44:07 UTC",
      "updated_date": "2024-06-10 13:44:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:21:00.861098"
    },
    {
      "arxiv_id": "2406.10252v2",
      "title": "AutoSurvey: Large Language Models Can Automatically Write Surveys",
      "title_zh": "翻译失败",
      "authors": [
        "Yidong Wang",
        "Qi Guo",
        "Wenjin Yao",
        "Hongbo Zhang",
        "Xin Zhang",
        "Zhen Wu",
        "Meishan Zhang",
        "Xinyu Dai",
        "Min Zhang",
        "Qingsong Wen",
        "Wei Ye",
        "Shikun Zhang",
        "Yue Zhang"
      ],
      "abstract": "This paper introduces AutoSurvey, a speedy and well-organized methodology for\nautomating the creation of comprehensive literature surveys in rapidly evolving\nfields like artificial intelligence. Traditional survey paper creation faces\nchallenges due to the vast volume and complexity of information, prompting the\nneed for efficient survey methods. While large language models (LLMs) offer\npromise in automating this process, challenges such as context window\nlimitations, parametric knowledge constraints, and the lack of evaluation\nbenchmarks remain. AutoSurvey addresses these challenges through a systematic\napproach that involves initial retrieval and outline generation, subsection\ndrafting by specialized LLMs, integration and refinement, and rigorous\nevaluation and iteration. Our contributions include a comprehensive solution to\nthe survey problem, a reliable evaluation method, and experimental validation\ndemonstrating AutoSurvey's effectiveness.We open our resources at\n\\url{https://github.com/AutoSurveys/AutoSurvey}.",
      "tldr_zh": "这篇论文介绍了 AutoSurvey，一种基于 Large Language Models (LLMs) 的方法，用于自动化生成全面的文献综述，尤其适用于人工智能等快速发展的领域。AutoSurvey 通过系统流程解决传统综述面临的挑战，包括初始检索和提纲生成、子部分草稿由专业 LLMs 起草、整合完善以及严格评估和迭代。该方法不仅克服了 LLMs 的上下文窗口限制和参数知识约束，还提供了一个可靠的评估基准，并通过实验验证了其有效性。作者开源了相关资源，以促进进一步研究。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10252v2",
      "published_date": "2024-06-10 12:56:06 UTC",
      "updated_date": "2024-06-18 02:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:21:15.520980"
    },
    {
      "arxiv_id": "2406.06662v1",
      "title": "Proximity Matters: Analyzing the Role of Geographical Proximity in Shaping AI Research Collaborations",
      "title_zh": "邻近性事关紧要：分析地理邻近性在塑造AI研究合作中的作用",
      "authors": [
        "Mohammadmahdi Toobaee",
        "Andrea Schiffauerova",
        "Ashkan Ebadi"
      ],
      "abstract": "The role of geographical proximity in facilitating inter-regional or\ninter-organizational collaborations has been studied thoroughly in recent\nyears. However, the effect of geographical proximity on forming scientific\ncollaborations at the individual level still needs to be addressed. Using\npublication data in the field of artificial intelligence from 2001 to 2019, in\nthis work, the effect of geographical proximity on the likelihood of forming\nfuture scientific collaborations among researchers is studied. In addition, the\ninteraction between geographical and network proximities is examined to see\nwhether network proximity can substitute geographical proximity in encouraging\nlong-distance scientific collaborations. Employing conventional and machine\nlearning techniques, our results suggest that geographical distance impedes\nscientific collaboration at the individual level despite the tremendous\nimprovements in transportation and communication technologies during recent\ndecades. Moreover, our findings show that the effect of network proximity on\nthe likelihood of scientific collaboration increases with geographical\ndistance, implying that network proximity can act as a substitute for\ngeographical proximity.",
      "tldr_zh": "本研究分析了地理接近度(Geographical Proximity)在塑造AI研究合作中的作用，使用2001-2019年人工智能领域的出版数据，考察其对个体层面科学合作的影响。研究采用传统和机器学习技术，结果显示，尽管交通和通信技术进步，地理距离仍阻碍未来合作的可能性。此外，网络接近度(Network Proximity)的作用随地理距离增加而增强，表明它能部分替代地理接近度，促进长距离合作。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.DL",
        "cs.LG",
        "physics.soc-ph"
      ],
      "primary_category": "cs.SI",
      "comment": "17 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06662v1",
      "published_date": "2024-06-10 12:37:47 UTC",
      "updated_date": "2024-06-10 12:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:21:25.431722"
    },
    {
      "arxiv_id": "2406.06220v2",
      "title": "Label-Looping: Highly Efficient Decoding for Transducers",
      "title_zh": "翻译失败",
      "authors": [
        "Vladimir Bataev",
        "Hainan Xu",
        "Daniel Galvez",
        "Vitaly Lavrukhin",
        "Boris Ginsburg"
      ],
      "abstract": "This paper introduces a highly efficient greedy decoding algorithm for\nTransducer-based speech recognition models. We redesign the standard\nnested-loop design for RNN-T decoding, swapping loops over frames and labels:\nthe outer loop iterates over labels, while the inner loop iterates over frames\nsearching for the next non-blank symbol. Additionally, we represent partial\nhypotheses in a special structure using CUDA tensors, supporting parallelized\nhypotheses manipulations. Experiments show that the label-looping algorithm is\nup to 2.0X faster than conventional batched decoding when using batch size 32.\nIt can be further combined with other compiler or GPU call-related techniques\nto achieve even more speedup. Our algorithm is general-purpose and can work\nwith both conventional Transducers and Token-and-Duration Transducers. We\nopen-source our implementation to benefit the research community.",
      "tldr_zh": "这篇论文提出了一种高效的贪婪解码算法Label-Looping，用于Transducer-based语音识别模型，通过重新设计RNN-T的嵌套循环（外循环迭代标签，内循环迭代帧）并使用CUDA张量表示部分假设，支持并行化操作。实验显示，该算法在批量大小为32时比传统批量解码快2.0倍，并可与其他GPU优化技术结合进一步加速。该方法通用，适用于传统Transducer和Token-and-Duration Transducers，并开源实现以促进研究社区发展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at IEEE SLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06220v2",
      "published_date": "2024-06-10 12:34:38 UTC",
      "updated_date": "2024-09-16 19:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:21:38.990802"
    },
    {
      "arxiv_id": "2406.06218v2",
      "title": "Data Augmentation in Earth Observation: A Diffusion Model Approach",
      "title_zh": "地球观测中的数据增强：一种扩散模型方法",
      "authors": [
        "Tiago Sousa",
        "Benoît Ries",
        "Nicolas Guelfi"
      ],
      "abstract": "High-quality Earth Observation (EO) imagery is essential for accurate\nanalysis and informed decision making across sectors. However, data scarcity\ncaused by atmospheric conditions, seasonal variations, and limited geographical\ncoverage hinders the effective application of Artificial Intelligence (AI) in\nEO. Traditional data augmentation techniques, which rely on basic parameterized\nimage transformations, often fail to introduce sufficient diversity across key\nsemantic axes. These axes include natural changes such as snow and floods,\nhuman impacts like urbanization and roads, and disasters such as wildfires and\nstorms, which limits the accuracy of AI models in EO applications. To address\nthis, we propose a four-stage data augmentation approach that integrates\ndiffusion models to enhance semantic diversity. Our method employs meta-prompts\nfor instruction generation, vision-language models for rich captioning,\nEO-specific diffusion model fine-tuning, and iterative data augmentation.\nExtensive experiments using four augmentation techniques demonstrate that our\napproach consistently outperforms established methods, generating semantically\ndiverse EO images and improving AI model performance.",
      "tldr_zh": "地球观测 (EO) 图像数据稀缺问题，如大气条件和季节变化，导致 AI 应用准确性不足，而传统数据增强技术无法有效引入语义多样性，包括自然变化（如雪、洪水）、人类影响（如城市化）和灾害（如野火）。本文提出一个四阶段数据增强方法，整合 diffusion models，通过 meta-prompts 生成指令、视觉语言模型进行丰富标题、EO 特定扩散模型微调以及迭代增强，来提升图像的语义多样性。实验结果显示，该方法在四种增强技术上均优于现有方法，能生成更多样化的 EO 图像，并显著改善 AI 模型的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SE",
        "I.4.9; I.4.9; I.2.m"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06218v2",
      "published_date": "2024-06-10 12:33:47 UTC",
      "updated_date": "2025-03-26 16:23:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:21:52.219812"
    },
    {
      "arxiv_id": "2406.06213v1",
      "title": "A Statistical Theory of Regularization-Based Continual Learning",
      "title_zh": "基于正则化的持续学习的统计理论",
      "authors": [
        "Xuyang Zhao",
        "Huiyuan Wang",
        "Weiran Huang",
        "Wei Lin"
      ],
      "abstract": "We provide a statistical analysis of regularization-based continual learning\non a sequence of linear regression tasks, with emphasis on how different\nregularization terms affect the model performance. We first derive the\nconvergence rate for the oracle estimator obtained as if all data were\navailable simultaneously. Next, we consider a family of generalized\n$\\ell_2$-regularization algorithms indexed by matrix-valued hyperparameters,\nwhich includes the minimum norm estimator and continual ridge regression as\nspecial cases. As more tasks are introduced, we derive an iterative update\nformula for the estimation error of generalized $\\ell_2$-regularized\nestimators, from which we determine the hyperparameters resulting in the\noptimal algorithm. Interestingly, the choice of hyperparameters can effectively\nbalance the trade-off between forward and backward knowledge transfer and\nadjust for data heterogeneity. Moreover, the estimation error of the optimal\nalgorithm is derived explicitly, which is of the same order as that of the\noracle estimator. In contrast, our lower bounds for the minimum norm estimator\nand continual ridge regression show their suboptimality. A byproduct of our\ntheoretical analysis is the equivalence between early stopping and generalized\n$\\ell_2$-regularization in continual learning, which may be of independent\ninterest. Finally, we conduct experiments to complement our theory.",
      "tldr_zh": "本研究对基于正则化的持续学习进行了统计分析，焦点是线性回归任务序列中不同正则化项对模型性能的影响。论文首先推导了oracle估计器的收敛率，然后分析了由矩阵值超参数索引的广义$\\ell_2$-regularization算法，包括最小范数估计器和持续岭回归作为特例，并确定了最优超参数以平衡前向和后向知识转移及数据异质性。最优算法的估计误差与oracle估计器同阶，而其他算法则次优；此外，论文证明了早期停止与广义$\\ell_2$-regularization在持续学习中的等价性，并通过实验验证了理论结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06213v1",
      "published_date": "2024-06-10 12:25:13 UTC",
      "updated_date": "2024-06-10 12:25:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:22:04.728791"
    },
    {
      "arxiv_id": "2406.06210v1",
      "title": "Quantum Architecture Search: A Survey",
      "title_zh": "量子架构搜索：综述",
      "authors": [
        "Darya Martyniuk",
        "Johannes Jung",
        "Adrian Paschke"
      ],
      "abstract": "Quantum computing has made significant progress in recent years, attracting\nimmense interest not only in research laboratories but also in various\nindustries. However, the application of quantum computing to solve real-world\nproblems is still hampered by a number of challenges, including hardware\nlimitations and a relatively under-explored landscape of quantum algorithms,\nespecially when compared to the extensive development of classical computing.\nThe design of quantum circuits, in particular parameterized quantum circuits\n(PQCs), which contain learnable parameters optimized by classical methods, is a\nnon-trivial and time-consuming task requiring expert knowledge. As a result,\nresearch on the automated generation of PQCs, known as quantum architecture\nsearch (QAS), has gained considerable interest. QAS focuses on the use of\nmachine learning and optimization-driven techniques to generate PQCs tailored\nto specific problems and characteristics of quantum hardware. In this paper, we\nprovide an overview of QAS methods by examining relevant research studies in\nthe field. We discuss main challenges in designing and performing an automated\nsearch for an optimal PQC, and survey ways to address them to ease future\nresearch.",
      "tldr_zh": "这篇论文对 Quantum Architecture Search (QAS) 进行了全面调查，旨在通过机器学习和优化驱动技术自动生成参数化量子电路 (PQCs)，以解决量子计算面临的硬件限制和算法开发不足等问题。论文回顾了相关研究，探讨了设计和执行 QAS 的主要挑战，如需要专家知识和时间消耗。最终，它提出了应对这些挑战的策略，为未来量子算法优化和应用提供宝贵指导。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "I.2.2; J.6"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06210v1",
      "published_date": "2024-06-10 12:17:46 UTC",
      "updated_date": "2024-06-10 12:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:22:14.707558"
    },
    {
      "arxiv_id": "2406.07584v1",
      "title": "BrainChat: Decoding Semantic Information from fMRI using Vision-language Pretrained Models",
      "title_zh": "BrainChat：使用视觉-语言预训练模型从",
      "authors": [
        "Wanaiu Huang"
      ],
      "abstract": "Semantic information is vital for human interaction, and decoding it from\nbrain activity enables non-invasive clinical augmentative and alternative\ncommunication. While there has been significant progress in reconstructing\nvisual images, few studies have focused on the language aspect. To address this\ngap, leveraging the powerful capabilities of the decoder-based vision-language\npretrained model CoCa, this paper proposes BrainChat, a simple yet effective\ngenerative framework aimed at rapidly accomplishing semantic information\ndecoding tasks from brain activity, including fMRI question answering and fMRI\ncaptioning. BrainChat employs the self-supervised approach of Masked Brain\nModeling to encode sparse fMRI data, obtaining a more compact embedding\nrepresentation in the latent space. Subsequently, BrainChat bridges the gap\nbetween modalities by applying contrastive loss, resulting in aligned\nrepresentations of fMRI, image, and text embeddings. Furthermore, the fMRI\nembeddings are mapped to the generative Brain Decoder via cross-attention\nlayers, where they guide the generation of textual content about fMRI in a\nregressive manner by minimizing caption loss. Empirically, BrainChat exceeds\nthe performance of existing state-of-the-art methods in the fMRI captioning\ntask and, for the first time, implements fMRI question answering. Additionally,\nBrainChat is highly flexible and can achieve high performance without image\ndata, making it better suited for real-world scenarios with limited data.",
      "tldr_zh": "该论文提出BrainChat框架，利用视觉语言预训练模型CoCa，从fMRI脑活动数据中解码语义信息，支持fMRI问答和fMRI描述生成任务。框架采用自监督的Masked Brain Modeling方法编码稀疏fMRI数据，并通过contrastive loss对齐fMRI、图像和文本嵌入，然后利用cross-attention layers将fMRI嵌入映射到生成器，实现文本内容的回归式生成。实验结果显示，BrainChat在fMRI描述任务中超越现有最先进方法，并首次实现了fMRI问答，且无需图像数据，具有高灵活性和适用于数据有限的真实场景。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07584v1",
      "published_date": "2024-06-10 12:06:15 UTC",
      "updated_date": "2024-06-10 12:06:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:22:26.319683"
    },
    {
      "arxiv_id": "2406.06201v1",
      "title": "2DP-2MRC: 2-Dimensional Pointer-based Machine Reading Comprehension Method for Multimodal Moment Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun He",
        "Tomoki Toda"
      ],
      "abstract": "Moment retrieval aims to locate the most relevant moment in an untrimmed\nvideo based on a given natural language query. Existing solutions can be\nroughly categorized into moment-based and clip-based methods. The former often\ninvolves heavy computations, while the latter, due to overlooking\ncoarse-grained information, typically underperforms compared to moment-based\nmodels. Hence, this paper proposes a novel 2-Dimensional Pointer-based Machine\nReading Comprehension for Moment Retrieval Choice (2DP-2MRC) model to address\nthe issue of imprecise localization in clip-based methods while maintaining\nlower computational complexity than moment-based methods. Specifically, we\nintroduce an AV-Encoder to capture coarse-grained information at moment and\nvideo levels. Additionally, a 2D pointer encoder module is introduced to\nfurther enhance boundary detection for target moment. Extensive experiments on\nthe HiREST dataset demonstrate that 2DP-2MRC significantly outperforms existing\nbaseline models.",
      "tldr_zh": "本研究针对多模态时刻检索（Moment Retrieval）问题，提出了一种新型的2-Dimensional Pointer-based Machine Reading Comprehension方法（2DP-2MRC），旨在解决基于剪辑（clip-based）方法的定位不精确问题，同时保持比基于时刻（moment-based）方法更低的计算复杂度。具体而言，该模型引入AV-Encoder来捕获时刻和视频级别的粗粒度信息，并利用2D pointer encoder模块增强目标时刻的边界检测。在HiREST数据集上的广泛实验显示，2DP-2MRC显著优于现有基线模型，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06201v1",
      "published_date": "2024-06-10 11:53:29 UTC",
      "updated_date": "2024-06-10 11:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:22:40.057645"
    },
    {
      "arxiv_id": "2406.06199v1",
      "title": "Implications for Governance in Public Perceptions of Societal-scale AI Risks",
      "title_zh": "翻译失败",
      "authors": [
        "Ross Gruetzemacher",
        "Toby D. Pilditch",
        "Huigang Liang",
        "Christy Manning",
        "Vael Gates",
        "David Moss",
        "James W. B. Elsey",
        "Willem W. A. Sleegers",
        "Kyle Kilian"
      ],
      "abstract": "Amid growing concerns over AI's societal risks--ranging from civilizational\ncollapse to misinformation and systemic bias--this study explores the\nperceptions of AI experts and the general US registered voters on the\nlikelihood and impact of 18 specific AI risks, alongside their policy\npreferences for managing these risks. While both groups favor international\noversight over national or corporate governance, our survey reveals a\ndiscrepancy: voters perceive AI risks as both more likely and more impactful\nthan experts, and also advocate for slower AI development. Specifically, our\nfindings indicate that policy interventions may best assuage collective\nconcerns if they attempt to more carefully balance mitigation efforts across\nall classes of societal-scale risks, effectively nullifying the\nnear-vs-long-term debate over AI risks. More broadly, our results will serve\nnot only to enable more substantive policy discussions for preventing and\nmitigating AI risks, but also to underscore the challenge of consensus building\nfor effective policy implementation.",
      "tldr_zh": "本研究调查了 AI 专家和美国选民对 18 种 societal-scale AI risks 的感知，包括风险的可能性、影响以及治理偏好。结果显示，两组受访者均支持 international oversight 而非国家或企业治理，但选民认为这些风险更可能发生且影响更大，并主张放缓 AI 发展。论文强调，政策干预应平衡所有 AI risks 的缓解努力，以消除近期与长远风险的争论，并促进更有效的共识构建和风险管理。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages, 18 page supplementary materials",
      "pdf_url": "http://arxiv.org/pdf/2406.06199v1",
      "published_date": "2024-06-10 11:52:25 UTC",
      "updated_date": "2024-06-10 11:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:22:53.674861"
    },
    {
      "arxiv_id": "2406.06660v1",
      "title": "Space-Time Continuous PDE Forecasting using Equivariant Neural Fields",
      "title_zh": "翻译失败",
      "authors": [
        "David M. Knigge",
        "David R. Wessels",
        "Riccardo Valperga",
        "Samuele Papa",
        "Jan-Jakob Sonke",
        "Efstratios Gavves",
        "Erik J. Bekkers"
      ],
      "abstract": "Recently, Conditional Neural Fields (NeFs) have emerged as a powerful\nmodelling paradigm for PDEs, by learning solutions as flows in the latent space\nof the Conditional NeF. Although benefiting from favourable properties of NeFs\nsuch as grid-agnosticity and space-time-continuous dynamics modelling, this\napproach limits the ability to impose known constraints of the PDE on the\nsolutions -- e.g. symmetries or boundary conditions -- in favour of modelling\nflexibility. Instead, we propose a space-time continuous NeF-based solving\nframework that - by preserving geometric information in the latent space -\nrespects known symmetries of the PDE. We show that modelling solutions as flows\nof pointclouds over the group of interest $G$ improves generalization and\ndata-efficiency. We validated that our framework readily generalizes to unseen\nspatial and temporal locations, as well as geometric transformations of the\ninitial conditions - where other NeF-based PDE forecasting methods fail - and\nimprove over baselines in a number of challenging geometries.",
      "tldr_zh": "该研究提出了一种基于 Equivariant Neural Fields 的时空连续框架，用于改进偏微分方程 (PDE) 预测。该框架通过在潜在空间中保留几何信息，将解决方案建模为点云在兴趣群组 $G$ 上的流动，从而更好地遵守 PDE 的已知对称性，如对称性和边界条件。相比传统 Conditional Neural Fields (NeFs)，该方法显著提升了泛化和数据效率，并在实验中成功泛化到未见的空间、时间位置以及初始条件的几何变换，并在多种挑战性几何中优于基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06660v1",
      "published_date": "2024-06-10 11:49:11 UTC",
      "updated_date": "2024-06-10 11:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:23:03.658759"
    },
    {
      "arxiv_id": "2406.06192v1",
      "title": "AI Cat Narrator: Designing an AI Tool for Exploring the Shared World and Social Connection with a Cat",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenchi Lai",
        "Janet Yi-Ching Huang",
        "Rung-Huei Liang"
      ],
      "abstract": "As technology continues to advance, the interaction between humans and cats\nis becoming more diverse. Our research introduces a new tool called the AI Cat\nNarrator, which offers a unique perspective on the shared lives of humans and\ncats. We combined the method of ethnography with fictional storytelling, using\na defamiliarization strategy to merge real-world data seen through the eyes of\ncats with excerpts from cat literature. This combination serves as the\nfoundation for a database to instruct the AI Cat Narrator in crafting\nalternative narrative. Our findings indicate that using defamiliarized data for\ntraining purposes significantly contributes to the development of characters\nthat are both more empathetic and individualized. The contributions of our\nstudy are twofold: 1) proposing an innovative approach to prompting a\nreevaluation of living alongside cats; 2) establishing a collaborative,\nexploratory tool developed by humans, cats, and AI together.",
      "tldr_zh": "本研究引入了 AI Cat Narrator 工具，用于探索人类与猫的共享世界和社会连接。该工具结合 ethnography 和 fictional storytelling 方法，通过 defamiliarization 策略，将真实世界数据（从猫视角）与猫文学摘录整合，形成数据库以指导 AI 生成替代叙述。研究发现，使用 defamiliarized 数据训练 AI，能创建更具同理心和个性化的角色。总体贡献包括：提出创新方法促使人们重新审视与猫共同生活，以及开发一个由人类、猫和 AI 共同协作的探索工具。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.06192v1",
      "published_date": "2024-06-10 11:44:15 UTC",
      "updated_date": "2024-06-10 11:44:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:25:12.645074"
    },
    {
      "arxiv_id": "2407.13685v1",
      "title": "Beyond Trend Following: Deep Learning for Market Trend Prediction",
      "title_zh": "超越趋势跟踪：深度学习用于市场趋势预测",
      "authors": [
        "Fernando Berzal",
        "Alberto Garcia"
      ],
      "abstract": "Trend following and momentum investing are common strategies employed by\nasset managers. Even though they can be helpful in the proper situations, they\nare limited in the sense that they work just by looking at past, as if we were\ndriving with our focus on the rearview mirror. In this paper, we advocate for\nthe use of Artificial Intelligence and Machine Learning techniques to predict\nfuture market trends. These predictions, when done properly, can improve the\nperformance of asset managers by increasing returns and reducing drawdowns.",
      "tldr_zh": "本文批评传统趋势跟随和动量投资策略的局限性，因为它们仅依赖过去数据，无法有效预测未来市场变化。论文提出使用人工智能（Artificial Intelligence）和机器学习（Machine Learning），尤其是深度学习（Deep Learning），来实现更准确的市场趋势预测。预计这种方法能显著提升资产管理者的表现，包括增加回报并减少回撤风险。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.LG",
        "q-fin.CP"
      ],
      "primary_category": "q-fin.TR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13685v1",
      "published_date": "2024-06-10 11:42:30 UTC",
      "updated_date": "2024-06-10 11:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:23:32.823721"
    },
    {
      "arxiv_id": "2406.06184v2",
      "title": "Deep Multi-Objective Reinforcement Learning for Utility-Based Infrastructural Maintenance Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse van Remmerden",
        "Maurice Kenter",
        "Diederik M. Roijers",
        "Charalampos Andriotis",
        "Yingqian Zhang",
        "Zaharah Bukhsh"
      ],
      "abstract": "In this paper, we introduce Multi-Objective Deep Centralized Multi-Agent\nActor-Critic (MO- DCMAC), a multi-objective reinforcement learning (MORL)\nmethod for infrastructural maintenance optimization, an area traditionally\ndominated by single-objective reinforcement learning (RL) approaches. Previous\nsingle-objective RL methods combine multiple objectives, such as probability of\ncollapse and cost, into a singular reward signal through reward-shaping. In\ncontrast, MO-DCMAC can optimize a policy for multiple objectives directly, even\nwhen the utility function is non-linear. We evaluated MO-DCMAC using two\nutility functions, which use probability of collapse and cost as input. The\nfirst utility function is the Threshold utility, in which MO-DCMAC should\nminimize cost so that the probability of collapse is never above the threshold.\nThe second is based on the Failure Mode, Effects, and Criticality Analysis\n(FMECA) methodology used by asset managers to asses maintenance plans. We\nevaluated MO-DCMAC, with both utility functions, in multiple maintenance\nenvironments, including ones based on a case study of the historical quay walls\nof Amsterdam. The performance of MO-DCMAC was compared against multiple\nrule-based policies based on heuristics currently used for constructing\nmaintenance plans. Our results demonstrate that MO-DCMAC outperforms\ntraditional rule-based policies across various environments and utility\nfunctions.",
      "tldr_zh": "这篇论文提出了 MO-DCMAC（Multi-Objective Deep Centralized Multi-Agent Actor-Critic），一种多目标强化学习(MORL)方法，用于基于效用的基础设施维护优化，与传统的单目标 RL 方法不同，它能直接优化多个目标（如崩溃概率和成本），即使效用函数是非线性的。论文评估了 MO-DCMAC 在两种效用函数下，包括 Threshold utility（确保崩溃概率不超过阈值）和基于 FMECA（Failure Mode, Effects, and Criticality Analysis）方法的效用，在多个环境中进行测试。结果显示，MO-DCMAC 在包括阿姆斯特丹历史码头案例在内的场景中，优于传统的基于规则的政策，证明了其在维护优化中的卓越性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in the Neural Computing and Applications: Topical Collection\n  on Multi-Objective Decision Making 2023 (MODeM 2023)",
      "pdf_url": "http://arxiv.org/pdf/2406.06184v2",
      "published_date": "2024-06-10 11:28:25 UTC",
      "updated_date": "2025-01-08 15:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:23:43.610840"
    },
    {
      "arxiv_id": "2406.06658v1",
      "title": "Link Prediction in Bipartite Networks",
      "title_zh": "二分网络中的链路预测",
      "authors": [
        "Şükrü Demir İnan Özer",
        "Günce Keziban Orman",
        "Vincent Labatut"
      ],
      "abstract": "Bipartite networks serve as highly suitable models to represent systems\ninvolving interactions between two distinct types of entities, such as online\ndating platforms, job search services, or ecommerce websites. These models can\nbe leveraged to tackle a number of tasks, including link prediction among the\nmost useful ones, especially to design recommendation systems. However, if this\ntask has garnered much interest when conducted on unipartite (i.e. standard)\nnetworks, it is far from being the case for bipartite ones. In this study, we\naddress this gap by performing an experimental comparison of 19 link prediction\nmethods able to handle bipartite graphs. Some come directly from the\nliterature, and some are adapted by us from techniques originally designed for\nunipartite networks. We also propose to repurpose recommendation systems based\non graph convolutional networks (GCN) as a novel link prediction solution for\nbipartite networks. To conduct our experiments, we constitute a benchmark of 3\nreal-world bipartite network datasets with various topologies. Our results\nindicate that GCN-based personalized recommendation systems, which have\nreceived significant attention in recent years, can produce successful results\nfor link prediction in bipartite networks. Furthermore, purely heuristic\nmetrics that do not rely on any learning process, like the Structural\nPerturbation Method (SPM), can also achieve success.",
      "tldr_zh": "该研究探讨了二分网络（bipartite networks）中的链接预测（link prediction），强调其在推荐系统（如在线约会、求职和电商平台）中的应用，并填补了这一领域的现有研究空白。作者比较了19种链接预测方法，包括直接从文献中获取的和从单分网络（unipartite networks）技术中适配的，并首次提出将基于图卷积网络（GCN）的推荐系统重新应用于二分网络。实验基于3个真实世界数据集进行，结果表明GCN-based方法和纯启发式指标如Structural Perturbation Method (SPM) 在链接预测任务中表现出色，提供了一种高效的解决方案。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SI",
      "comment": "28th International Conference on Knowledge-Based and Intelligent\n  Information & Engineering Systems (KES), Sep 2024, Sevilla, Spain",
      "pdf_url": "http://arxiv.org/pdf/2406.06658v1",
      "published_date": "2024-06-10 11:23:30 UTC",
      "updated_date": "2024-06-10 11:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:24:05.351781"
    },
    {
      "arxiv_id": "2406.06657v1",
      "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
      "title_zh": "利用 AI 进行复杂政策文档的高效分析：以 Executive Order 14110 为案例研究",
      "authors": [
        "Mark A. Kramer",
        "Allen Leavens",
        "Alexander Scarlat"
      ],
      "abstract": "Policy documents, such as legislation, regulations, and executive orders, are\ncrucial in shaping society. However, their length and complexity make\ninterpretation and application challenging and time-consuming. Artificial\nintelligence (AI), particularly large language models (LLMs), has the potential\nto automate the process of analyzing these documents, improving accuracy and\nefficiency. This study aims to evaluate the potential of AI in streamlining\npolicy analysis and to identify the strengths and limitations of current AI\napproaches. The research focuses on question answering and tasks involving\ncontent extraction from policy documents. A case study was conducted using\nExecutive Order 14110 on \"Safe, Secure, and Trustworthy Development and Use of\nArtificial Intelligence\" as a test case. Four commercial AI systems were used\nto analyze the document and answer a set of representative policy questions.\nThe performance of the AI systems was compared to manual analysis conducted by\nhuman experts. The study found that two AI systems, Gemini 1.5 Pro and Claude 3\nOpus, demonstrated significant potential for supporting policy analysis,\nproviding accurate and reliable information extraction from complex documents.\nThey performed comparably to human analysts but with significantly higher\nefficiency. However, achieving reproducibility remains a challenge,\nnecessitating further research and development.",
      "tldr_zh": "这篇论文探讨了利用 AI，特别是大型语言模型(LLMs)，来高效分析复杂政策文档的潜力，并以“Executive Order 14110”作为案例研究。研究通过比较四个商业 AI 系统（如 Gemini 1.5 Pro 和 Claude 3 Opus）在问答和内容提取任务中的表现，与人类专家手动分析进行对比。结果显示，Gemini 1.5 Pro 和 Claude 3 Opus 提供了准确可靠的信息，效率远超人类，但再现性(reproducibility)问题仍需进一步研究和发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2406.06657v1",
      "published_date": "2024-06-10 11:19:28 UTC",
      "updated_date": "2024-06-10 11:19:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:24:06.852976"
    },
    {
      "arxiv_id": "2406.06165v1",
      "title": "Generalized Nested Latent Variable Models for Lossy Coding applied to Wind Turbine Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Raül Pérez-Gonzalo",
        "Andreas Espersen",
        "Antonio Agudo"
      ],
      "abstract": "Rate-distortion optimization through neural networks has accomplished\ncompetitive results in compression efficiency and image quality. This\nlearning-based approach seeks to minimize the compromise between compression\nrate and reconstructed image quality by automatically extracting and retaining\ncrucial information, while discarding less critical details. A successful\ntechnique consists in introducing a deep hyperprior that operates within a\n2-level nested latent variable model, enhancing compression by capturing\ncomplex data dependencies. This paper extends this concept by designing a\ngeneralized L-level nested generative model with a Markov chain structure. We\ndemonstrate as L increases that a trainable prior is detrimental and explore a\ncommon dimensionality along the distinct latent variables to boost compression\nperformance. As this structured framework can represent autoregressive coders,\nwe outperform the hyperprior model and achieve state-of-the-art performance\nwhile reducing substantially the computational cost. Our experimental\nevaluation is performed on wind turbine scenarios to study its application on\nvisual inspections",
      "tldr_zh": "本研究扩展了神经网络驱动的率失真优化（Rate-distortion optimization），设计了一个通用 L 级嵌套潜在变量模型（nested latent variable model），采用 Markov 链结构来提升图像压缩效率。该模型通过分析 L 增加时可训练先验（trainable prior）的负面影响，并引入共同维度（common dimensionality），成功表示自回归编码器（autoregressive coders），从而显著降低计算成本并超越超先验模型（hyperprior model）。实验结果显示，该框架在风力涡轮机场景（wind turbine scenarios）的视觉检查应用中实现了 state-of-the-art 性能，压缩性能和图像质量均有显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICIP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06165v1",
      "published_date": "2024-06-10 11:00:26 UTC",
      "updated_date": "2024-06-10 11:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:24:17.977692"
    },
    {
      "arxiv_id": "2406.06158v2",
      "title": "Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Kunin",
        "Allan Raventós",
        "Clémentine Dominé",
        "Feng Chen",
        "David Klindt",
        "Andrew Saxe",
        "Surya Ganguli"
      ],
      "abstract": "While the impressive performance of modern neural networks is often\nattributed to their capacity to efficiently extract task-relevant features from\ndata, the mechanisms underlying this rich feature learning regime remain\nelusive, with much of our theoretical understanding stemming from the opposing\nlazy regime. In this work, we derive exact solutions to a minimal model that\ntransitions between lazy and rich learning, precisely elucidating how\nunbalanced layer-specific initialization variances and learning rates determine\nthe degree of feature learning. Our analysis reveals that they conspire to\ninfluence the learning regime through a set of conserved quantities that\nconstrain and modify the geometry of learning trajectories in parameter and\nfunction space. We extend our analysis to more complex linear models with\nmultiple neurons, outputs, and layers and to shallow nonlinear networks with\npiecewise linear activation functions. In linear networks, rapid feature\nlearning only occurs from balanced initializations, where all layers learn at\nsimilar speeds. While in nonlinear networks, unbalanced initializations that\npromote faster learning in earlier layers can accelerate rich learning. Through\na series of experiments, we provide evidence that this unbalanced rich regime\ndrives feature learning in deep finite-width networks, promotes\ninterpretability of early layers in CNNs, reduces the sample complexity of\nlearning hierarchical data, and decreases the time to grokking in modular\narithmetic. Our theory motivates further exploration of unbalanced\ninitializations to enhance efficient feature learning.",
      "tldr_zh": "本研究探讨了神经网络如何通过不平衡初始化(unbalanced initializations)促进快速特征学习(rich feature learning)，对比传统的lazy regime。作者推导了最小模型的精确解，揭示了层特定初始化方差和学习率如何通过守恒量(conserved quantities)影响学习轨迹的几何形状，从而决定特征学习程度；在线性网络中，快速学习需平衡初始化，而在非线性网络中，不平衡初始化可加速早期层学习。实验结果显示，这种unbalanced rich regime在深度网络中提升了特征学习效率、早期层可解释性(interpretability)、样本复杂度(sample complexity)降低，以及grokking速度的加快，最终为优化神经网络初始化提供理论指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "40 pages, 12 figures, NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06158v2",
      "published_date": "2024-06-10 10:42:37 UTC",
      "updated_date": "2024-10-12 21:38:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:24:31.690761"
    },
    {
      "arxiv_id": "2406.06144v3",
      "title": "Language Models Resist Alignment: Evidence From Data Compression",
      "title_zh": "语言模型抵抗对齐：来自数据压缩的证据",
      "authors": [
        "Jiaming Ji",
        "Kaile Wang",
        "Tianyi Qiu",
        "Boyuan Chen",
        "Jiayi Zhou",
        "Changye Li",
        "Hantao Lou",
        "Josef Dai",
        "Yunhuai Liu",
        "Yaodong Yang"
      ],
      "abstract": "Large language models (LLMs) may exhibit unintended or undesirable behaviors.\nRecent works have concentrated on aligning LLMs to mitigate harmful outputs.\nDespite these efforts, some anomalies indicate that even a well-conducted\nalignment process can be easily circumvented, whether intentionally or\naccidentally. Does alignment fine-tuning yield have robust effects on models,\nor are its impacts merely superficial? In this work, we make the first\nexploration of this phenomenon from both theoretical and empirical\nperspectives. Empirically, we demonstrate the elasticity of post-alignment\nmodels, i.e., the tendency to revert to the behavior distribution formed during\nthe pre-training phase upon further fine-tuning. Leveraging compression theory,\nwe formally deduce that fine-tuning disproportionately undermines alignment\nrelative to pre-training, potentially by orders of magnitude. We validate the\npresence of elasticity through experiments on models of varying types and\nscales. Specifically, we find that model performance declines rapidly before\nreverting to the pre-training distribution, after which the rate of decline\ndrops significantly. Furthermore, we further reveal that elasticity positively\ncorrelates with the increased model size and the expansion of pre-training\ndata. Our findings underscore the need to address the inherent elasticity of\nLLMs to mitigate their resistance to alignment.",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)对对齐(alignment)的抵抗性，通过理论和实证角度揭示了对齐微调(fine-tuning)的影响可能较浅显。作者利用压缩理论(compression theory)推导出，微调对对齐的破坏远大于对预训练(pre-training)的破坏，可能相差数个数量级。实验验证了模型的弹性(elasticity)，即在进一步微调后，性能快速下降并回归预训练行为分布，且这种弹性随模型规模和预训练数据规模的增加而增强。这些发现强调了需要解决LLMs的内在抵抗性，以提升对齐的有效性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The five-page version has been accepted by NeurIPS 2024 Workshop\n  SoLaR. In the current version, we have conducted an in-depth expansion of\n  both the theoretical and experimental aspects",
      "pdf_url": "http://arxiv.org/pdf/2406.06144v3",
      "published_date": "2024-06-10 10:03:16 UTC",
      "updated_date": "2024-12-20 16:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:24:44.783564"
    },
    {
      "arxiv_id": "2406.06655v1",
      "title": "Fed-Sophia: A Communication-Efficient Second-Order Federated Learning Algorithm",
      "title_zh": "Fed-Sophia：一种通信高效的二阶联邦学习算法",
      "authors": [
        "Ahmed Elbakary",
        "Chaouki Ben Issaid",
        "Mohammad Shehab",
        "Karim Seddik",
        "Tamer ElBatt",
        "Mehdi Bennis"
      ],
      "abstract": "Federated learning is a machine learning approach where multiple devices\ncollaboratively learn with the help of a parameter server by sharing only their\nlocal updates. While gradient-based optimization techniques are widely adopted\nin this domain, the curvature information that second-order methods exhibit is\ncrucial to guide and speed up the convergence. This paper introduces a scalable\nsecond-order method, allowing the adoption of curvature information in\nfederated large models. Our method, coined Fed-Sophia, combines a weighted\nmoving average of the gradient with a clipping operation to find the descent\ndirection. In addition to that, a lightweight estimation of the Hessian's\ndiagonal is used to incorporate the curvature information. Numerical evaluation\nshows the superiority, robustness, and scalability of the proposed Fed-Sophia\nscheme compared to first and second-order baselines.",
      "tldr_zh": "该论文提出 Fed-Sophia，一种通信高效的二阶联邦学习算法，旨在通过利用曲率信息来加速多设备协作学习的收敛过程。算法结合梯度的加权移动平均、剪裁操作，以及对 Hessian 矩阵对角线的轻量级估计，以优化下降方向。实验结果显示，Fed-Sophia 相较于一阶和二阶基线方法，在优越性、鲁棒性和可扩展性方面表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "ICC 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06655v1",
      "published_date": "2024-06-10 09:57:30 UTC",
      "updated_date": "2024-06-10 09:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:24:53.940681"
    },
    {
      "arxiv_id": "2406.06139v1",
      "title": "Thunder : Unified Regression-Diffusion Speech Enhancement with a Single Reverse Step using Brownian Bridge",
      "title_zh": "翻译失败",
      "authors": [
        "Thanapat Trachu",
        "Chawan Piansaddhayanon",
        "Ekapol Chuangsuwanich"
      ],
      "abstract": "Diffusion-based speech enhancement has shown promising results, but can\nsuffer from a slower inference time. Initializing the diffusion process with\nthe enhanced audio generated by a regression-based model can be used to reduce\nthe computational steps required. However, these approaches often necessitate a\nregression model, further increasing the system's complexity. We propose\nThunder, a unified regression-diffusion model that utilizes the Brownian bridge\nprocess which can allow the model to act in both modes. The regression mode can\nbe accessed by setting the diffusion time step closed to 1. However, the\nstandard score-based diffusion modeling does not perform well in this setup due\nto gradient instability. To mitigate this problem, we modify the diffusion\nmodel to predict the clean speech instead of the score function, achieving\ncompetitive performance with a more compact model size and fewer reverse steps.",
      "tldr_zh": "该论文提出Thunder，一种统一的回归-扩散语音增强模型，使用Brownian Bridge过程来整合两种模式，从而减少推断步骤。传统score-based diffusion建模在回归模式下易受梯度不稳定影响，因此作者修改模型使其预测干净语音而非分数函数。实验结果显示，Thunder在更紧凑的模型大小和单一反向步骤下，实现了与现有方法竞争性的性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 3 figures, 4 tables, This paper will be submitted in the\n  interspeech conference",
      "pdf_url": "http://arxiv.org/pdf/2406.06139v1",
      "published_date": "2024-06-10 09:52:25 UTC",
      "updated_date": "2024-06-10 09:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:25:06.386084"
    },
    {
      "arxiv_id": "2406.06134v1",
      "title": "DiffInject: Revisiting Debias via Synthetic Data Generation using Diffusion-based Style Injection",
      "title_zh": "翻译失败",
      "authors": [
        "Donggeun Ko",
        "Sangwoo Jo",
        "Dongjun Lee",
        "Namjun Park",
        "Jaekwang Kim"
      ],
      "abstract": "Dataset bias is a significant challenge in machine learning, where specific\nattributes, such as texture or color of the images are unintentionally learned\nresulting in detrimental performance. To address this, previous efforts have\nfocused on debiasing models either by developing novel debiasing algorithms or\nby generating synthetic data to mitigate the prevalent dataset biases. However,\ngenerative approaches to date have largely relied on using bias-specific\nsamples from the dataset, which are typically too scarce. In this work, we\npropose, DiffInject, a straightforward yet powerful method to augment synthetic\nbias-conflict samples using a pretrained diffusion model. This approach\nsignificantly advances the use of diffusion models for debiasing purposes by\nmanipulating the latent space. Our framework does not require any explicit\nknowledge of the bias types or labelling, making it a fully unsupervised\nsetting for debiasing. Our methodology demonstrates substantial result in\neffectively reducing dataset bias.",
      "tldr_zh": "该论文探讨了机器学习中数据集偏差（dataset bias）的问题，例如图像的纹理或颜色导致模型性能下降，现有的生成合成数据方法依赖于稀缺的偏置特定样本。作者提出DiffInject，一种使用预训练扩散模型（diffusion model）通过风格注入（Style Injection）生成合成偏置冲突样本的方法，该框架通过操纵潜在空间（latent space）实现完全无监督（fully unsupervised）的去偏过程，而无需偏置类型或标签信息。实验结果显示，DiffInject显著有效地减少了数据集偏差，提升了模型的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages (including supplementary), 3 figures, SynData4CV@CVPR 24\n  (Workshop)",
      "pdf_url": "http://arxiv.org/pdf/2406.06134v1",
      "published_date": "2024-06-10 09:45:38 UTC",
      "updated_date": "2024-06-10 09:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:25:26.941862"
    },
    {
      "arxiv_id": "2406.06127v1",
      "title": "Comparing Data Augmentation Methods for End-to-End Task-Oriented Dialog Systems",
      "title_zh": "比较端到端任务导向对话系统的数据增强方法",
      "authors": [
        "Christos Vlachos",
        "Themos Stafylakis",
        "Ion Androutsopoulos"
      ],
      "abstract": "Creating effective and reliable task-oriented dialog systems (ToDSs) is\nchallenging, not only because of the complex structure of these systems, but\nalso due to the scarcity of training data, especially when several modules need\nto be trained separately, each one with its own input/output training examples.\nData augmentation (DA), whereby synthetic training examples are added to the\ntraining data, has been successful in other NLP systems, but has not been\nexplored as extensively in ToDSs. We empirically evaluate the effectiveness of\nDA methods in an end-to-end ToDS setting, where a single system is trained to\nhandle all processing stages, from user inputs to system outputs. We experiment\nwith two ToDSs (UBAR, GALAXY) on two datasets (MultiWOZ, KVRET). We consider\nthree types of DA methods (word-level, sentence-level, dialog-level), comparing\neight DA methods that have shown promising results in ToDSs and other NLP\nsystems. We show that all DA methods considered are beneficial, and we\nhighlight the best ones, also providing advice to practitioners. We also\nintroduce a more challenging few-shot cross-domain ToDS setting, reaching\nsimilar conclusions.",
      "tldr_zh": "这篇论文比较了各种数据增强(DA)方法在端到端任务导向对话系统(ToDSs)中的有效性，以解决训练数据稀缺的问题。研究者实验了三种DA类型（词级别、句子级别和对话级别），并在两个ToDS系统(UBAR和GALAXY)上，使用两个数据集(MultiWOZ和KVRET)评估了八种DA方法。结果表明，所有DA方法都能改善系统性能，其中某些方法表现出色；此外，论文还引入了更具挑战性的少样本跨域设置，并为从业者提供了实用建议。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "There are 25 pages in total, 23 tables, 18 figures. Accepted in ACL\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06127v1",
      "published_date": "2024-06-10 09:36:05 UTC",
      "updated_date": "2024-06-10 09:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:25:41.724770"
    },
    {
      "arxiv_id": "2406.07583v1",
      "title": "Situated Ground Truths: Enhancing Bias-Aware AI by Situating Data Labels with SituAnnotate",
      "title_zh": "翻译失败",
      "authors": [
        "Delfina Sol Martinez Pandiani",
        "Valentina Presutti"
      ],
      "abstract": "In the contemporary world of AI and data-driven applications, supervised\nmachines often derive their understanding, which they mimic and reproduce,\nthrough annotations--typically conveyed in the form of words or labels.\nHowever, such annotations are often divorced from or lack contextual\ninformation, and as such hold the potential to inadvertently introduce biases\nwhen subsequently used for training. This paper introduces SituAnnotate, a\nnovel ontology explicitly crafted for 'situated grounding,' aiming to anchor\nthe ground truth data employed in training AI systems within the contextual and\nculturally-bound situations from which those ground truths emerge. SituAnnotate\noffers an ontology-based approach to structured and context-aware data\nannotation, addressing potential bias issues associated with isolated\nannotations. Its representational power encompasses situational context,\nincluding annotator details, timing, location, remuneration schemes, annotation\nroles, and more, ensuring semantic richness. Aligned with the foundational\nDolce Ultralight ontology, it provides a robust and consistent framework for\nknowledge representation. As a method to create, query, and compare label-based\ndatasets, SituAnnotate empowers downstream AI systems to undergo training with\nexplicit consideration of context and cultural bias, laying the groundwork for\nenhanced system interpretability and adaptability, and enabling AI models to\nalign with a multitude of cultural contexts and viewpoints.",
      "tldr_zh": "本论文探讨了传统数据注解缺乏上下文可能引入偏差的问题，提出了一种名为 SituAnnotate 的新本体（ontology），用于实现“situated grounding”，即将 AI 训练中的 ground truth 数据锚定于其文化和情境背景。SituAnnotate 通过结构化注解方法，涵盖注解者细节、时间、地点、报酬方案等元素，并基于 Dolce Ultralight ontology 构建稳健的知识表示框架。最终，该方法能增强 AI 系统的偏差意识，提高其可解释性和适应性，使 AI 模型更好地适应多种文化视角和情境。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Author preprint",
      "pdf_url": "http://arxiv.org/pdf/2406.07583v1",
      "published_date": "2024-06-10 09:33:13 UTC",
      "updated_date": "2024-06-10 09:33:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:25:50.066444"
    },
    {
      "arxiv_id": "2406.06124v1",
      "title": "Enhancing Long-Term Memory using Hierarchical Aggregate Tree for Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Aadharsh Aadhithya A",
        "Sachin Kumar S",
        "Soman K. P"
      ],
      "abstract": "Large language models have limited context capacity, hindering reasoning over\nlong conversations. We propose the Hierarchical Aggregate Tree memory structure\nto recursively aggregate relevant dialogue context through conditional tree\ntraversals. HAT encapsulates information from children nodes, enabling broad\ncoverage with depth control. We formulate finding best context as optimal tree\ntraversal. Experiments show HAT improves dialog coherence and summary quality\nover baseline contexts, demonstrating the techniques effectiveness for multi\nturn reasoning without exponential parameter growth. This memory augmentation\nenables more consistent, grounded longform conversations from LLMs",
      "tldr_zh": "该论文针对大型语言模型(LLMs)上下文容量有限的问题，提出Hierarchical Aggregate Tree (HAT)内存结构，用于Retrieval Augmented Generation，以递归聚合相关对话上下文并通过条件树遍历实现信息的封装和深度控制。\nHAT将寻找最佳上下文表述为最优树遍历，从而在多轮推理中提供广泛覆盖而不需指数级参数增长。\n实验结果表明，HAT比基线方法显著提高了对话连贯性和摘要质量，促进LLMs进行更一致、基于事实的长对话。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06124v1",
      "published_date": "2024-06-10 09:29:08 UTC",
      "updated_date": "2024-06-10 09:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:26:04.435786"
    },
    {
      "arxiv_id": "2406.06652v3",
      "title": "Improving Generalization of Neural Vehicle Routing Problem Solvers Through the Lens of Model Architecture",
      "title_zh": "通过模型架构的视角改善神经车辆路由问题求解器的泛化能力",
      "authors": [
        "Yubin Xiao",
        "Di Wang",
        "Xuan Wu",
        "Yuesong Wu",
        "Boyang Li",
        "Wei Du",
        "Liupu Wang",
        "You Zhou"
      ],
      "abstract": "Neural models produce promising results when solving Vehicle Routing Problems\n(VRPs), but often fall short in generalization. Recent attempts to enhance\nmodel generalization often incur unnecessarily large training cost or cannot be\ndirectly applied to other models solving different VRP variants. To address\nthese issues, we take a novel perspective on model architecture in this study.\nSpecifically, we propose a plug-and-play Entropy-based Scaling Factor (ESF) and\na Distribution-Specific (DS) decoder to enhance the size and distribution\ngeneralization, respectively. ESF adjusts the attention weight pattern of the\nmodel towards familiar ones discovered during training when solving VRPs of\nvarying sizes. The DS decoder explicitly models VRPs of multiple training\ndistribution patterns through multiple auxiliary light decoders, expanding the\nmodel representation space to encompass a broader range of distributional\nscenarios. We conduct extensive experiments on both synthetic and widely\nrecognized real-world benchmarking datasets and compare the performance with\nseven baseline models. The results demonstrate the effectiveness of using ESF\nand DS decoder to obtain a more generalizable model and showcase their\napplicability to solve different VRP variants, i.e., travelling salesman\nproblem and capacitated VRP. Notably, our proposed generic components require\nminimal computational resources, and can be effortlessly integrated into\nconventional generalization strategies to further elevate model generalization.",
      "tldr_zh": "本研究针对神经模型在解决Vehicle Routing Problems (VRPs)时的泛化能力不足问题，从模型架构角度提出改进策略。具体地，引入Entropy-based Scaling Factor (ESF)来调整注意力权重模式，以提升模型对不同规模VRPs的适应性；同时，提出Distribution-Specific (DS) decoder，通过多个辅助轻量解码器显式建模多种训练分布模式，从而扩展模型表示空间。在合成和真实世界基准数据集上的实验显示，与七个基线模型相比，该方法显著提高了泛化性能，并在travelling salesman problem和capacitated VRP等变体上表现出色，且这些组件计算资源需求低，便于与其他策略整合。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted by Neural Networks",
      "pdf_url": "http://arxiv.org/pdf/2406.06652v3",
      "published_date": "2024-06-10 09:03:17 UTC",
      "updated_date": "2025-03-18 08:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:26:16.076930"
    },
    {
      "arxiv_id": "2406.06111v1",
      "title": "JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunjae Cho",
        "Junhyeok Lee",
        "Wonbin Jung"
      ],
      "abstract": "Non-autoregressive GAN-based neural vocoders are widely used due to their\nfast inference speed and high perceptual quality. However, they often suffer\nfrom audible artifacts such as tonal artifacts in their generated results.\nTherefore, we propose JenGAN, a new training strategy that involves stacking\nshifted low-pass filters to ensure the shift-equivariant property. This method\nhelps prevent aliasing and reduce artifacts while preserving the model\nstructure used during inference. In our experimental evaluation, JenGAN\nconsistently enhances the performance of vocoder models, yielding significantly\nsuperior scores across the majority of evaluation metrics.",
      "tldr_zh": "这篇论文提出JenGAN，一种新的训练策略，用于基于GAN的语音合成模型，通过堆叠移位低通滤波器确保shift-equivariant property，从而防止aliasing并减少生成音频中的可听伪像，如色调伪像。JenGAN保留了推理时的模型结构，同时在实验评估中显著提升了声码器性能，在大多数评估指标上获得更好分数。总的来说，该方法为非自回归GAN vocoder提供了更高质量的音频输出。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06111v1",
      "published_date": "2024-06-10 08:51:04 UTC",
      "updated_date": "2024-06-10 08:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:26:27.496676"
    },
    {
      "arxiv_id": "2406.06110v1",
      "title": "Recurrent Context Compression: Efficiently Expanding the Context Window of LLM",
      "title_zh": "循环上下文压缩：高效扩展LLM的上下文窗口",
      "authors": [
        "Chensen Huang",
        "Guibo Zhu",
        "Xuepeng Wang",
        "Yifei Luo",
        "Guojing Ge",
        "Haoran Chen",
        "Dong Yi",
        "Jinqiao Wang"
      ],
      "abstract": "To extend the context length of Transformer-based large language models\n(LLMs) and improve comprehension capabilities, we often face limitations due to\ncomputational resources and bounded memory storage capacity. This work\nintroduces a method called Recurrent Context Compression (RCC), designed to\nefficiently expand the context window length of LLMs within constrained storage\nspace. We also investigate the issue of poor model responses when both\ninstructions and context are compressed in downstream tasks, and propose an\ninstruction reconstruction method to mitigate this problem. We validated the\neffectiveness of our approach on multiple tasks, achieving a compression rate\nof up to 32x on text reconstruction tasks with a BLEU4 score close to 0.95, and\nnearly 100\\% accuracy on a passkey retrieval task with a sequence length of 1M.\nFinally, our method demonstrated competitive performance in long-text\nquestion-answering tasks compared to non-compressed methods, while\nsignificantly saving storage resources in long-text inference tasks. Our code,\nmodels, and demo are available at https://github.com/WUHU-G/RCC_Transformer",
      "tldr_zh": "这篇论文提出了Recurrent Context Compression (RCC)方法，用于高效扩展Transformer-based LLMs的上下文窗口长度，同时在受限计算资源和存储容量下实现改进的理解能力。作者还引入了instruction reconstruction技术，以缓解下游任务中压缩指令和上下文导致的模型响应问题。实验验证显示，RCC在文本重建任务中实现了高达32x的压缩率，BLEU4分数接近0.95；在1M序列长度的passkey检索任务中准确率近100%；此外，在长文本问答任务中，该方法与非压缩方法竞争性能，同时显著节省存储资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06110v1",
      "published_date": "2024-06-10 08:50:59 UTC",
      "updated_date": "2024-06-10 08:50:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:26:40.652621"
    },
    {
      "arxiv_id": "2406.06107v1",
      "title": "EXPIL: Explanatory Predicate Invention for Learning in Games",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyuan Sha",
        "Hikaru Shindo",
        "Quentin Delfosse",
        "Kristian Kersting",
        "Devendra Singh Dhami"
      ],
      "abstract": "Reinforcement learning (RL) has proven to be a powerful tool for training\nagents that excel in various games. However, the black-box nature of neural\nnetwork models often hinders our ability to understand the reasoning behind the\nagent's actions. Recent research has attempted to address this issue by using\nthe guidance of pretrained neural agents to encode logic-based policies,\nallowing for interpretable decisions. A drawback of such approaches is the\nrequirement of large amounts of predefined background knowledge in the form of\npredicates, limiting its applicability and scalability. In this work, we\npropose a novel approach, Explanatory Predicate Invention for Learning in Games\n(EXPIL), that identifies and extracts predicates from a pretrained neural\nagent, later used in the logic-based agents, reducing the dependency on\npredefined background knowledge. Our experimental evaluation on various games\ndemonstrate the effectiveness of EXPIL in achieving explainable behavior in\nlogic agents while requiring less background knowledge.",
      "tldr_zh": "该研究针对强化学习（RL）在游戏中训练代理的黑箱问题，提出了一种名为 EXPIL 的新方法，即 Explanatory Predicate Invention for Learning in Games，以提升代理行为的解释性。EXPIL 通过从预训练神经代理中自动识别和提取 predicates，用于构建逻辑-based 代理，从而减少了对预定义背景知识的依赖。实验结果显示，在多种游戏场景下，EXPIL 实现了高效的可解释行为，同时显著提高了方法的适用性和可扩展性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 2 pages references, 8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.06107v1",
      "published_date": "2024-06-10 08:46:49 UTC",
      "updated_date": "2024-06-10 08:46:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:26:50.709080"
    },
    {
      "arxiv_id": "2406.06103v1",
      "title": "Adaptive Control in Assistive Application -- A Study Evaluating Shared Control by Users with Limited Upper Limb Mobility",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Ferdinand Goldau",
        "Max Pascher",
        "Annalies Baumeister",
        "Patrizia Tolle",
        "Jens Gerken",
        "Udo Frese"
      ],
      "abstract": "Shared control in assistive robotics blends human autonomy with computer\nassistance, thus simplifying complex tasks for individuals with physical\nimpairments. This study assesses an adaptive Degrees of Freedom control method\nspecifically tailored for individuals with upper limb impairments. It employs a\nbetween-subjects analysis with 24 participants, conducting 81 trials across\nthree distinct input devices in a realistic everyday-task setting. Given the\ndiverse capabilities of the vulnerable target demographic and the known\nchallenges in statistical comparisons due to individual differences, the study\nfocuses primarily on subjective qualitative data. The results reveal\nconsistently high success rates in trial completions, irrespective of the input\ndevice used. Participants appreciated their involvement in the research\nprocess, displayed a positive outlook, and quick adaptability to the control\nsystem. Notably, each participant effectively managed the given task within a\nshort time frame.",
      "tldr_zh": "这篇论文评估了自适应 Degrees of Freedom 控制方法在辅助机器人中的应用，针对上肢障碍者的 Shared Control 系统，通过 24 名参与者和 81 次试验，使用三种输入设备在现实日常任务环境中进行研究。研究重点关注主观定性数据，结果显示无论输入设备如何，试验完成率均保持高水平。参与者对研究过程表现出积极态度，快速适应控制系统，并在短时间内有效完成任务，为提升辅助机器人对脆弱人群的可用性提供了宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "RO-MAN'24: 33rd IEEE International Conference on Robot and Human\n  Interactive Communication, Pasadena, California, US",
      "pdf_url": "http://arxiv.org/pdf/2406.06103v1",
      "published_date": "2024-06-10 08:36:55 UTC",
      "updated_date": "2024-06-10 08:36:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:27:02.635976"
    },
    {
      "arxiv_id": "2406.06097v1",
      "title": "StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Papi",
        "Marco Gaido",
        "Matteo Negri",
        "Luisa Bentivogli"
      ],
      "abstract": "Streaming speech-to-text translation (StreamST) is the task of automatically\ntranslating speech while incrementally receiving an audio stream. Unlike\nsimultaneous ST (SimulST), which deals with pre-segmented speech, StreamST\nfaces the challenges of handling continuous and unbounded audio streams. This\nrequires additional decisions about what to retain of the previous history,\nwhich is impractical to keep entirely due to latency and computational\nconstraints. Despite the real-world demand for real-time ST, research on\nstreaming translation remains limited, with existing works solely focusing on\nSimulST. To fill this gap, we introduce StreamAtt, the first StreamST policy,\nand propose StreamLAAL, the first StreamST latency metric designed to be\ncomparable with existing metrics for SimulST. Extensive experiments across all\n8 languages of MuST-C v1.0 show the effectiveness of StreamAtt compared to a\nnaive streaming baseline and the related state-of-the-art SimulST policy,\nproviding a first step in StreamST research.",
      "tldr_zh": "本研究针对 Streaming speech-to-text translation (StreamST) 的挑战，提出了一种直接流式翻译方法，即 StreamAtt，通过 attention-based audio history selection 机制智能选择和保留音频历史，以应对连续音频流的延迟和计算限制问题。与传统的 Simultaneous ST (SimulST) 不同，StreamST 需要处理无界音频，并引入了新的延迟指标 StreamLAAL，以实现与现有指标的可比性。在 MuST-C v1.0 的 8 种语言实验中，StreamAtt 比朴素基线和最先进 SimulST 政策表现出色，准确率和效率显著提升，为实时翻译研究奠定了基础。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at ACL 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2406.06097v1",
      "published_date": "2024-06-10 08:27:58 UTC",
      "updated_date": "2024-06-10 08:27:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:27:14.978853"
    },
    {
      "arxiv_id": "2406.10251v3",
      "title": "The Impact of Quantization on Retrieval-Augmented Generation: An Analysis of Small LLMs",
      "title_zh": "量化对检索增强生成的影响：小规模大语言模型的分析",
      "authors": [
        "Mert Yazan",
        "Suzan Verberne",
        "Frederik Situmeang"
      ],
      "abstract": "Post-training quantization reduces the computational demand of Large Language\nModels (LLMs) but can weaken some of their capabilities. Since LLM abilities\nemerge with scale, smaller LLMs are more sensitive to quantization. In this\npaper, we explore how quantization affects smaller LLMs' ability to perform\nretrieval-augmented generation (RAG), specifically in longer contexts. We chose\npersonalization for evaluation because it is a challenging domain to perform\nusing RAG as it requires long-context reasoning over multiple documents. We\ncompare the original FP16 and the quantized INT4 performance of multiple 7B and\n8B LLMs on two tasks while progressively increasing the number of retrieved\ndocuments to test how quantized models fare against longer contexts. To better\nunderstand the effect of retrieval, we evaluate three retrieval models in our\nexperiments. Our findings reveal that if a 7B LLM performs the task well,\nquantization does not impair its performance and long-context reasoning\ncapabilities. We conclude that it is possible to utilize RAG with quantized\nsmaller LLMs.",
      "tldr_zh": "这篇论文分析了量化（Quantization）对小型大型语言模型（LLMs）在检索增强生成（RAG）中的影响，重点关注长上下文场景。研究者通过比较 FP16 和 INT4 版本的 7B 和 8B LLMs 在个性化任务上的性能，随着检索文档数量增加，评估了三款检索模型的表现。结果显示，如果 7B LLMs 在任务中表现良好，量化不会损害其性能和长上下文推理能力，从而结论是可以利用量化后的小型 LLMs 进行 RAG。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the IR-RAG Workshop at SIGIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10251v3",
      "published_date": "2024-06-10 08:23:52 UTC",
      "updated_date": "2024-08-01 16:27:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:27:30.929750"
    },
    {
      "arxiv_id": "2406.06062v2",
      "title": "ProcessPainter: Learn Painting Process from Sequence Data",
      "title_zh": "ProcessPainter: 从序列数据学习绘画过程",
      "authors": [
        "Yiren Song",
        "Shijie Huang",
        "Chen Yao",
        "Xiaojun Ye",
        "Hai Ci",
        "Jiaming Liu",
        "Yuxuan Zhang",
        "Mike Zheng Shou"
      ],
      "abstract": "The painting process of artists is inherently stepwise and varies\nsignificantly among different painters and styles. Generating detailed,\nstep-by-step painting processes is essential for art education and research,\nyet remains largely underexplored. Traditional stroke-based rendering methods\nbreak down images into sequences of brushstrokes, yet they fall short of\nreplicating the authentic processes of artists, with limitations confined to\nbasic brushstroke modifications. Text-to-image models utilizing diffusion\nprocesses generate images through iterative denoising, also diverge\nsubstantially from artists' painting process. To address these challenges, we\nintroduce ProcessPainter, a text-to-video model that is initially pre-trained\non synthetic data and subsequently fine-tuned with a select set of artists'\npainting sequences using the LoRA model. This approach successfully generates\npainting processes from text prompts for the first time. Furthermore, we\nintroduce an Artwork Replication Network capable of accepting arbitrary-frame\ninput, which facilitates the controlled generation of painting processes,\ndecomposing images into painting sequences, and completing semi-finished\nartworks. This paper offers new perspectives and tools for advancing art\neducation and image generation technology.",
      "tldr_zh": "该论文提出ProcessPainter，一种文本到视频模型，用于从序列数据学习艺术家的逐步绘画过程，以解决传统方法无法真实复制绘画流程的问题。模型首先在合成数据上预训练，然后使用LoRA微调艺术家绘画序列，从而实现从文本提示生成详细绘画过程的创新。论文还引入Artwork Replication Network，支持任意帧输入，用于控制生成流程、分解图像成序列以及完成半成品艺术品。这种方法为艺术教育和图像生成技术提供了新的视角和工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06062v2",
      "published_date": "2024-06-10 07:18:41 UTC",
      "updated_date": "2024-07-20 07:23:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:27:42.602646"
    },
    {
      "arxiv_id": "2406.06061v1",
      "title": "Greedy SLIM: A SLIM-Based Approach For Preference Elicitation",
      "title_zh": "翻译失败",
      "authors": [
        "Claudius Proissl",
        "Amel Vatic",
        "Helmut Waldschmidt"
      ],
      "abstract": "Preference elicitation is an active learning approach to tackle the\ncold-start problem of recommender systems. Roughly speaking, new users are\nasked to rate some carefully selected items in order to compute appropriate\nrecommendations for them. To the best of our knowledge, we are the first to\npropose a method for preference elicitation that is based on SLIM , a\nstate-of-the-art technique for top-N recommendation. Our approach mainly\nconsists of a new training technique for SLIM, which we call Greedy SLIM. This\ntechnique iteratively selects items for the training in order to minimize the\nSLIM loss greedily. We conduct offline experiments as well as a user study to\nassess the performance of this new method. The results are remarkable,\nespecially with respect to the user study. We conclude that Greedy SLIM seems\nto be more suitable for preference elicitation than widely used methods based\non latent factor models.",
      "tldr_zh": "该论文提出 Greedy SLIM，一种基于 SLIM 的新方法，用于解决推荐系统的冷启动问题，通过 Preference Elicitation 主动学习让新用户评估选定的物品。Greedy SLIM 通过迭代贪婪选择训练物品来最小化 SLIM 损失，从而优化 Top-N 推荐。实验结果，包括离线实验和用户研究，显示该方法性能显著优于基于 latent factor models 的传统方法，尤其在用户满意度方面。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06061v1",
      "published_date": "2024-06-10 07:18:24 UTC",
      "updated_date": "2024-06-10 07:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:27:53.804881"
    },
    {
      "arxiv_id": "2406.12902v2",
      "title": "JavaBench: A Benchmark of Object-Oriented Code Generation for Evaluating Large Language Models",
      "title_zh": "JavaBench：面向对象代码生成基准，用于评估大型语言模型",
      "authors": [
        "Jialun Cao",
        "Zhiyong Chen",
        "Jiarong Wu",
        "Shing-chi Cheung",
        "Chang Xu"
      ],
      "abstract": "Code generation benchmarks such as HumanEval are widely adopted to evaluate\nLLMs' capabilities. However, after consolidating the latest 24 benchmarks, we\nnoticed three significant imbalances. First, imbalanced programming language.\n95.8% of benchmarks involve Python, while only 5 benchmarks involve Java.\nSecond, imbalanced code granularity. Function-/statement-level benchmarks\naccount for over 83.3% of benchmarks. Only a mere handful extends to\nclass-/project-levels, and all are limited to Python. Third, lacking advanced\nfeatures. Existing benchmarks primarily assess basic coding skills, while\noverlooking advanced Object-Oriented Programming (OOP) features (i.e.,\nencapsulation, inheritance, and polymorphism).\n  To fill these gaps, we propose JavaBench, a project-level Java benchmark that\nexercises OOP features. It comprises four Java projects with 389 methods in 106\nJava classes. The test coverage is up to 92%, and JavaBench is attested by 282\nundergraduate students, reaching a 90.93/100 average score (i.e., pass rate\nagainst the test suite), ensuring the quality of documentation, code skeleton,\nand tests. To better evaluate LLM's capability against JavaBench, we introduce\na systematic evaluation design covering three context settings and five\nsynthesis strategies at two granularities using three hierarchical metrics. Our\nextensive experiment yields several interesting findings. First, we noticed\nthat regarding project-level Java programming, LLMs are far behind\nundergraduate students (no project can be correctly completed by any studied\nLLMs, and at most 41.17% Pass@5 in a more relaxed evaluation). Second, using\nmethod signature as prompt context may strike an ideal balance for\nproject-level code generation. JavaBench is publicly available at\nhttps://github.com/java-bench/JavaBench.",
      "tldr_zh": "本论文指出了现有代码生成基准（如 HumanEval）存在编程语言不平衡（主要为 Python）、代码粒度不平衡（多为函数/语句级别）以及忽略高级 Object-Oriented Programming (OOP) 特性的问题。针对这些不足，研究者提出 JavaBench，这是一个项目级别的 Java 基准测试，包含 4 个 Java 项目、389 个方法和 106 个类，测试覆盖率达 92%，并通过 282 名本科生的验证确保高质量。实验采用系统化评估设计（涵盖三种上下文设置、五种合成策略和三种层次指标），结果显示 Large Language Models (LLMs) 在项目级 Java 编程中远落后于本科生（最高 Pass@5 为 41.17%），而使用方法签名作为提示上下文可能在代码生成中取得更好平衡。JavaBench 已公开在 GitHub 上，供进一步研究使用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ASE 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12902v2",
      "published_date": "2024-06-10 06:43:25 UTC",
      "updated_date": "2024-10-11 10:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:28:08.616140"
    },
    {
      "arxiv_id": "2406.06051v2",
      "title": "On the Utility of Accounting for Human Beliefs about AI Intention in Human-AI Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Guanghui Yu",
        "Robert Kasumba",
        "Chien-Ju Ho",
        "William Yeoh"
      ],
      "abstract": "To enable effective human-AI collaboration, merely optimizing AI performance\nwithout considering human factors is insufficient. Recent research has shown\nthat designing AI agents that take human behavior into account leads to\nimproved performance in human-AI collaboration. However, a limitation of most\nexisting approaches is their assumption that human behavior remains static,\nregardless of the AI agent's actions. In reality, humans may adjust their\nactions based on their beliefs about the AI's intentions, specifically, the\nsubtasks they perceive the AI to be attempting to complete based on its\nbehavior. In this paper, we address this limitation by enabling a collaborative\nAI agent to consider its human partner's beliefs about its intentions, i.e.,\nwhat the human partner thinks the AI agent is trying to accomplish, and to\ndesign its action plan accordingly to facilitate more effective human-AI\ncollaboration. Specifically, we developed a model of human beliefs that\ncaptures how humans interpret and reason about their AI partner's intentions.\nUsing this belief model, we created an AI agent that incorporates both human\nbehavior and human beliefs when devising its strategy for interacting with\nhumans. Through extensive real-world human-subject experiments, we demonstrate\nthat our belief model more accurately captures human perceptions of AI\nintentions. Furthermore, we show that our AI agent, designed to account for\nhuman beliefs over its intentions, significantly enhances performance in\nhuman-AI collaboration.",
      "tldr_zh": "该论文探讨了在人类-AI 协作中，单纯优化 AI 性能的局限性，强调需要考虑人类对 AI 意图的信念，因为人类行为会根据这些信念动态调整。研究开发了一个人类信念模型，用于捕捉人类如何解读和推理 AI 代理的意图，并据此设计 AI 代理的行动策略，使其同时考虑人类行为和信念。实验结果显示，该信念模型更准确地反映人类对 AI 意图的感知，且这种改进的 AI 代理显著提升了人类-AI 协作的整体性能。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06051v2",
      "published_date": "2024-06-10 06:39:37 UTC",
      "updated_date": "2024-11-08 21:57:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:28:18.159173"
    },
    {
      "arxiv_id": "2406.06048v2",
      "title": "Robust Latent Representation Tuning for Image-text Classification",
      "title_zh": "用于图像-文本分类的鲁棒潜在表示调整",
      "authors": [
        "Hao Sun",
        "Yu Song"
      ],
      "abstract": "Large models have demonstrated exceptional generalization capabilities in\ncomputer vision and natural language processing. Recent efforts have focused on\nenhancing these models with multimodal processing abilities. However,\naddressing the challenges posed by scenarios where one modality is absent\nremains a significant hurdle. In response to this issue, we propose a robust\nlatent representation tuning method for large models. Specifically, our\napproach introduces a modality latent translation module to maximize the\ncorrelation between modalities, resulting in a robust representation. Following\nthis, a newly designed fusion module is employed to facilitate information\ninteraction between the modalities. Within this framework, common semantics are\nrefined during training, and robust performance is achieved even in the absence\nof one modality. Importantly, our method maintains the frozen state of the\nimage and text foundation models to preserve their capabilities acquired\nthrough large-scale pretraining. We conduct experiments on several public\ndatasets, and the results underscore the effectiveness of our proposed method.",
      "tldr_zh": "本文提出了一种鲁棒的潜在表示调整（Robust Latent Representation Tuning）方法，用于图像-文本分类任务，以解决模态缺失的挑战。该方法引入模态潜在翻译模块（modality latent translation module）来最大化模态间相关性，并使用一个新的融合模块（fusion module）促进信息交互，同时保持图像和文本基础模型冻结状态以保留其预训练能力。在多个公共数据集上的实验结果表明，该方法在模态缺失场景下实现了鲁棒性能，并验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06048v2",
      "published_date": "2024-06-10 06:29:00 UTC",
      "updated_date": "2024-06-14 12:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:28:30.345940"
    },
    {
      "arxiv_id": "2406.06045v1",
      "title": "Synthesizing Efficient Data with Diffusion Models for Person Re-Identification Pre-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Niu",
        "Haiyang Yu",
        "Xuelin Qian",
        "Teng Fu",
        "Bin Li",
        "Xiangyang Xue"
      ],
      "abstract": "Existing person re-identification (Re-ID) methods principally deploy the\nImageNet-1K dataset for model initialization, which inevitably results in\nsub-optimal situations due to the large domain gap. One of the key challenges\nis that building large-scale person Re-ID datasets is time-consuming. Some\nprevious efforts address this problem by collecting person images from the\ninternet e.g., LUPerson, but it struggles to learn from unlabeled,\nuncontrollable, and noisy data. In this paper, we present a novel paradigm\nDiffusion-ReID to efficiently augment and generate diverse images based on\nknown identities without requiring any cost of data collection and annotation.\nTechnically, this paradigm unfolds in two stages: generation and filtering.\nDuring the generation stage, we propose Language Prompts Enhancement (LPE) to\nensure the ID consistency between the input image sequence and the generated\nimages. In the diffusion process, we propose a Diversity Injection (DI) module\nto increase attribute diversity. In order to make the generated data have\nhigher quality, we apply a Re-ID confidence threshold filter to further remove\nthe low-quality images. Benefiting from our proposed paradigm, we first create\na new large-scale person Re-ID dataset Diff-Person, which consists of over 777K\nimages from 5,183 identities. Next, we build a stronger person Re-ID backbone\npre-trained on our Diff-Person. Extensive experiments are conducted on four\nperson Re-ID benchmarks in six widely used settings. Compared with other\npre-training and self-supervised competitors, our approach shows significant\nsuperiority.",
      "tldr_zh": "本文提出了一种新范式Diffusion-ReID，利用扩散模型高效生成多样化图像，用于Person Re-Identification (Re-ID)预训练，以解决现有方法依赖ImageNet-1K导致的领域差距问题，并避免数据收集和标注的成本。方法包括生成阶段的Language Prompts Enhancement (LPE)确保身份一致性，以及Diversity Injection (DI)模块增加属性多样性；随后通过Re-ID置信度阈值过滤移除低质量图像。基于此，作者创建了大规模数据集Diff-Person，包含超过777K图像和5,183个身份，并在四个Re-ID基准的六种设置中实验，显示出比其他预训练和自监督方法显著的性能优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06045v1",
      "published_date": "2024-06-10 06:26:03 UTC",
      "updated_date": "2024-06-10 06:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:28:43.824654"
    },
    {
      "arxiv_id": "2406.06037v1",
      "title": "Investigating Pre-Training Objectives for Generalization in Vision-Based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Donghu Kim",
        "Hojoon Lee",
        "Kyungmin Lee",
        "Dongyoon Hwang",
        "Jaegul Choo"
      ],
      "abstract": "Recently, various pre-training methods have been introduced in vision-based\nReinforcement Learning (RL). However, their generalization ability remains\nunclear due to evaluations being limited to in-distribution environments and\nnon-unified experimental setups. To address this, we introduce the Atari\nPre-training Benchmark (Atari-PB), which pre-trains a ResNet-50 model on 10\nmillion transitions from 50 Atari games and evaluates it across diverse\nenvironment distributions. Our experiments show that pre-training objectives\nfocused on learning task-agnostic features (e.g., identifying objects and\nunderstanding temporal dynamics) enhance generalization across different\nenvironments. In contrast, objectives focused on learning task-specific\nknowledge (e.g., identifying agents and fitting reward functions) improve\nperformance in environments similar to the pre-training dataset but not in\nvaried ones. We publicize our codes, datasets, and model checkpoints at\nhttps://github.com/dojeon-ai/Atari-PB.",
      "tldr_zh": "这篇论文调查了视觉-based Reinforcement Learning (RL) 中预训练目标对模型泛化能力的影响，引入了 Atari Pre-training Benchmark (Atari-PB) 作为统一评估框架，在50个Atari游戏的10百万transitions上预训练ResNet-50模型。实验发现，专注于任务无关特征（如识别对象和理解时间动态）的预训练目标，能显著提升模型在不同环境下的泛化性能；相反，专注于任务相关知识（如识别代理和拟合奖励函数）的目标，仅在与预训练数据集相似的环境中表现更好。论文通过这些发现强调了设计鲁棒预训练策略的重要性，并公开了代码、数据集和模型检查点以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06037v1",
      "published_date": "2024-06-10 06:06:38 UTC",
      "updated_date": "2024-06-10 06:06:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:28:53.957202"
    },
    {
      "arxiv_id": "2406.06649v1",
      "title": "2DQuant: Low-bit Post-Training Quantization for Image Super-Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Liu",
        "Haotong Qin",
        "Yong Guo",
        "Xin Yuan",
        "Linghe Kong",
        "Guihai Chen",
        "Yulun Zhang"
      ],
      "abstract": "Low-bit quantization has become widespread for compressing image\nsuper-resolution (SR) models for edge deployment, which allows advanced SR\nmodels to enjoy compact low-bit parameters and efficient integer/bitwise\nconstructions for storage compression and inference acceleration, respectively.\nHowever, it is notorious that low-bit quantization degrades the accuracy of SR\nmodels compared to their full-precision (FP) counterparts. Despite several\nefforts to alleviate the degradation, the transformer-based SR model still\nsuffers severe degradation due to its distinctive activation distribution. In\nthis work, we present a dual-stage low-bit post-training quantization (PTQ)\nmethod for image super-resolution, namely 2DQuant, which achieves efficient and\naccurate SR under low-bit quantization. The proposed method first investigates\nthe weight and activation and finds that the distribution is characterized by\ncoexisting symmetry and asymmetry, long tails. Specifically, we propose\nDistribution-Oriented Bound Initialization (DOBI), using different searching\nstrategies to search a coarse bound for quantizers. To obtain refined quantizer\nparameters, we further propose Distillation Quantization Calibration (DQC),\nwhich employs a distillation approach to make the quantized model learn from\nits FP counterpart. Through extensive experiments on different bits and scaling\nfactors, the performance of DOBI can reach the state-of-the-art (SOTA) while\nafter stage two, our method surpasses existing PTQ in both metrics and visual\neffects. 2DQuant gains an increase in PSNR as high as 4.52dB on Set5 (x2)\ncompared with SOTA when quantized to 2-bit and enjoys a 3.60x compression ratio\nand 5.08x speedup ratio. The code and models will be available at\nhttps://github.com/Kai-Liu001/2DQuant.",
      "tldr_zh": "本文提出 2DQuant，一种双阶段低位后训练量化 (low-bit PTQ) 方法，用于图像超分辨率 (SR)，旨在解决量化导致的模型准确性下降问题，尤其针对 transformer-based SR 模型的激活分布特性。方法包括 Distribution-Oriented Bound Initialization (DOBI)，通过分析权重和激活的分布采用不同搜索策略初始化量化器参数，以及 Distillation Quantization Calibration (DQC)，利用知识蒸馏让量化模型从全精度 (FP) 模型中学习。实验结果显示，2DQuant 在不同位宽和缩放因子下超越现有 PTQ 方法，在 Set5 (x2) 上量化到 2-bit 时，PSNR 提高高达 4.52dB，并实现 3.60x 压缩比和 5.08x 加速比。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "9 pages, 6 figures. The code and models will be available at\n  https://github.com/Kai-Liu001/2DQuant",
      "pdf_url": "http://arxiv.org/pdf/2406.06649v1",
      "published_date": "2024-06-10 06:06:11 UTC",
      "updated_date": "2024-06-10 06:06:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:29:09.449261"
    },
    {
      "arxiv_id": "2406.06648v1",
      "title": "SignBLEU: Automatic Evaluation of Multi-channel Sign Language Translation",
      "title_zh": "SignBLEU：多通道手语翻译的自动评估",
      "authors": [
        "Jung-Ho Kim",
        "Mathew Huerta-Enochian",
        "Changyong Ko",
        "Du Hui Lee"
      ],
      "abstract": "Sign languages are multi-channel languages that communicate information\nthrough not just the hands (manual signals) but also facial expressions and\nupper body movements (non-manual signals). However, since automatic sign\nlanguage translation is usually performed by generating a single sequence of\nglosses, researchers eschew non-manual and co-occurring manual signals in favor\nof a simplified list of manual glosses. This can lead to significant\ninformation loss and ambiguity. In this paper, we introduce a new task named\nmulti-channel sign language translation (MCSLT) and present a novel metric,\nSignBLEU, designed to capture multiple signal channels. We validated SignBLEU\non a system-level task using three sign language corpora with varied linguistic\nstructures and transcription methodologies and examined its correlation with\nhuman judgment through two segment-level tasks. We found that SignBLEU\nconsistently correlates better with human judgment than competing metrics. To\nfacilitate further MCSLT research, we report benchmark scores for the three\nsign language corpora and release the source code for SignBLEU at\nhttps://github.com/eq4all-projects/SignBLEU.",
      "tldr_zh": "本论文引入了多通道手语翻译 (MCSLT) 任务，以解决现有手语翻译方法忽略非手动信号（如面部表情和上身动作）导致的信息丢失和歧义问题。作者提出了一种新指标 SignBLEU，用于捕捉多信号通道的翻译质量，并通过三个手语语料库的系统级和段级实验验证其与人类判断的相关性优于现有指标。实验结果显示 SignBLEU 显著提升了评估准确性，并提供了基准分数及源代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in LREC-Coling 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06648v1",
      "published_date": "2024-06-10 05:01:26 UTC",
      "updated_date": "2024-06-10 05:01:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:29:17.584880"
    },
    {
      "arxiv_id": "2406.06017v1",
      "title": "Neuro-TransUNet: Segmentation of stroke lesion in MRI using transformers",
      "title_zh": "Neuro-TransUNet：使用 Transformer 在 MRI 中对中风病变进行分割",
      "authors": [
        "Muhammad Nouman",
        "Mohamed Mabrok",
        "Essam A. Rashed"
      ],
      "abstract": "Accurate segmentation of the stroke lesions using magnetic resonance imaging\n(MRI) is associated with difficulties due to the complicated anatomy of the\nbrain and the different properties of the lesions. This study introduces the\nNeuro-TransUNet framework, which synergizes the U-Net's spatial feature\nextraction with SwinUNETR's global contextual processing ability, further\nenhanced by advanced feature fusion and segmentation synthesis techniques. The\ncomprehensive data pre-processing pipeline improves the framework's efficiency,\nwhich involves resampling, bias correction, and data standardization, enhancing\ndata quality and consistency. Ablation studies confirm the significant impact\nof the advanced integration of U-Net with SwinUNETR and data pre-processing\npipelines on performance and demonstrate the model's effectiveness. The\nproposed Neuro-TransUNet model, trained with the ATLAS v2.0 \\emph{training}\ndataset, outperforms existing deep learning algorithms and establishes a new\nbenchmark in stroke lesion segmentation.",
      "tldr_zh": "这篇论文引入了 Neuro-TransUNet 框架，用于精确分割 MRI 中的中风病变，通过结合 U-Net 的空间特征提取和 SwinUNETR 的全局上下文处理，并融入高级特征融合以及分割合成技术来提升模型性能。框架还包括全面的数据预处理管道，如重采样、偏差校正和数据标准化，以提高数据质量和一致性。实验结果显示，Neuro-TransUNet 在 ATLAS v2.0 训练数据集上超越了现有深度学习算法，建立了新的基准，且消融研究证实了组件整合的关键作用。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06017v1",
      "published_date": "2024-06-10 04:36:21 UTC",
      "updated_date": "2024-06-10 04:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:29:32.375825"
    },
    {
      "arxiv_id": "2406.06647v4",
      "title": "How Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Ruizhong Qiu",
        "Weiliang Will Zeng",
        "James Ezick",
        "Christopher Lott",
        "Hanghang Tong"
      ],
      "abstract": "The emergence of large language models (LLMs) has significantly pushed the\nfrontiers of program synthesis. Advancement of LLM-based program synthesis\ncalls for a thorough evaluation of LLM-generated code. Most evaluation\nframeworks focus on the (functional) correctness of generated code; efficiency,\nas an important measure of code quality, has been overlooked in existing\nevaluations. In this work, we develop ENAMEL (EfficeNcy AutoMatic EvaLuator), a\nrigorous and high-standard benchmark for evaluating the capability of LLMs in\ngenerating efficient code. Firstly, we propose a new efficiency metric called\neff@k, which generalizes the pass@k metric from correctness to efficiency and\nappropriately handles right-censored execution time. Furthermore, we derive an\nunbiased and variance-reduced estimator of eff@k via Rao--Blackwellization; we\nalso provide a numerically stable implementation for the new estimator.\nSecondly, to set a high-standard for efficiency evaluation, we employ a human\nexpert to design best algorithms and implementations as our reference solutions\nof efficiency, many of which are much more efficient than existing canonical\nsolutions in HumanEval and HumanEval+. Moreover, to ensure a rigorous\nevaluation, we employ a human expert to curate strong test case generators to\nfilter out wrong code and differentiate suboptimal algorithms. An extensive\nstudy across 30 popular LLMs using our benchmark ENAMEL shows that LLMs still\nfall short of generating expert-level efficient code. Using two subsets of our\nproblem set, we demonstrate that such deficiency is because current LLMs\nstruggle in designing advanced algorithms and are barely aware of\nimplementation optimization. Our benchmark is publicly available at\nhttps://github.com/q-rz/enamel .",
      "tldr_zh": "本文开发了 ENAMEL 基准，用于评估大型语言模型 (LLMs) 生成代码的效率问题，弥补了现有评估框架忽略效率的不足。研究提出 eff@k 指标作为 pass@k 的扩展，用于量化代码效率，并通过 Rao--Blackwellization 技术提供无偏且方差减少的估计器，同时雇佣人类专家设计高效参考解决方案和强测试用例生成器。实验结果显示，30 个流行 LLMs 在 ENAMEL 基准上表现不佳，无法生成专家级高效代码，主要由于 LLMs 在设计高级算法和实现优化方面存在挑战。该基准已公开可用，有助于提升 LLM 程序合成的质量。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.06647v4",
      "published_date": "2024-06-10 04:19:20 UTC",
      "updated_date": "2025-02-19 04:16:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:29:45.330683"
    },
    {
      "arxiv_id": "2406.06009v1",
      "title": "The Impact of AI on Academic Research and Publishing",
      "title_zh": "翻译失败",
      "authors": [
        "Brady Lund",
        "Manika Lamba",
        "Sang Hoo Oh"
      ],
      "abstract": "Generative artificial intelligence (AI) technologies like ChatGPT, have\nsignificantly impacted academic writing and publishing through their ability to\ngenerate content at levels comparable to or surpassing human writers. Through a\nreview of recent interdisciplinary literature, this paper examines ethical\nconsiderations surrounding the integration of AI into academia, focusing on the\npotential for this technology to be used for scholarly misconduct and necessary\noversight when using it for writing, editing, and reviewing of scholarly\npapers. The findings highlight the need for collaborative approaches to AI\nusage among publishers, editors, reviewers, and authors to ensure that this\ntechnology is used ethically and productively.",
      "tldr_zh": "这篇论文探讨了生成式 AI（如 ChatGPT）对学术写作和出版的影响，通过审查最近的跨学科文献，分析了将 AI 整合到学术领域的伦理考虑。重点关注 AI 可能导致的学术不当行为风险，以及在写作、编辑和审阅学术论文时所需的监督机制。研究发现，出版商、编辑、审阅者和作者需要采用合作方法，确保 AI 被伦理和高效地使用，以促进学术诚信。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06009v1",
      "published_date": "2024-06-10 04:10:18 UTC",
      "updated_date": "2024-06-10 04:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:29:56.780753"
    },
    {
      "arxiv_id": "2406.06004v1",
      "title": "FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yebin Lee",
        "Imseong Park",
        "Myungjoo Kang"
      ],
      "abstract": "Most existing image captioning evaluation metrics focus on assigning a single\nnumerical score to a caption by comparing it with reference captions. However,\nthese methods do not provide an explanation for the assigned score. Moreover,\nreference captions are expensive to acquire. In this paper, we propose FLEUR,\nan explainable reference-free metric to introduce explainability into image\ncaptioning evaluation metrics. By leveraging a large multimodal model, FLEUR\ncan evaluate the caption against the image without the need for reference\ncaptions, and provide the explanation for the assigned score. We introduce\nscore smoothing to align as closely as possible with human judgment and to be\nrobust to user-defined grading criteria. FLEUR achieves high correlations with\nhuman judgment across various image captioning evaluation benchmarks and\nreaches state-of-the-art results on Flickr8k-CF, COMPOSITE, and Pascal-50S\nwithin the domain of reference-free evaluation metrics. Our source code and\nresults are publicly available at: https://github.com/Yebin46/FLEUR.",
      "tldr_zh": "该论文提出 FLEUR，一种可解释的、无参考图像描述评估指标，使用 Large Multimodal Model 直接评估描述与图像的匹配度，并提供分数解释，以解决现有指标缺乏解释和依赖参考描述的难题。FLEUR 引入分数平滑机制，以更好地与人类判断一致，并提升对用户定义标准的鲁棒性。在 Flickr8k-CF、COMPOSITE 和 Pascal-50S 等基准上，FLEUR 实现了与人类判断的高度相关性，并在无参考评估领域达到最先进水平，代码已公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ACL (Main) 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06004v1",
      "published_date": "2024-06-10 03:57:39 UTC",
      "updated_date": "2024-06-10 03:57:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:30:11.147276"
    },
    {
      "arxiv_id": "2406.05999v1",
      "title": "fSEAD: a Composable FPGA-based Streaming Ensemble Anomaly Detection Library",
      "title_zh": "翻译失败",
      "authors": [
        "Binglei Lou",
        "David Boland",
        "Philip H. W. Leong"
      ],
      "abstract": "Machine learning ensembles combine multiple base models to produce a more\naccurate output. They can be applied to a range of machine learning problems,\nincluding anomaly detection. In this paper, we investigate how to maximize the\ncomposability and scalability of an FPGA-based streaming ensemble anomaly\ndetector (fSEAD). To achieve this, we propose a flexible computing architecture\nconsisting of multiple partially reconfigurable regions, pblocks, which each\nimplement anomaly detectors. Our proof-of-concept design supports three\nstate-of-the-art anomaly detection algorithms: Loda, RS-Hash and xStream. Each\nalgorithm is scalable, meaning multiple instances can be placed within a pblock\nto improve performance. Moreover, fSEAD is implemented using High-level\nsynthesis (HLS), meaning further custom anomaly detectors can be supported.\nPblocks are interconnected via an AXI-switch, enabling them to be composed in\nan arbitrary fashion before combining and merging results at run-time to create\nan ensemble that maximizes the use of FPGA resources and accuracy. Through\nutilizing reconfigurable Dynamic Function eXchange (DFX), the detector can be\nmodified at run-time to adapt to changing environmental conditions. We compare\nfSEAD to an equivalent central processing unit (CPU) implementation using four\nstandard datasets, with speed-ups ranging from $3\\times$ to $8\\times$.",
      "tldr_zh": "本研究提出 fSEAD，一种基于 FPGA 的流式集成异常检测库，旨在最大化异常检测器的可组合性和可扩展性。fSEAD 采用灵活的计算架构，包括多个部分可重配置区域 (pblocks)，每个区域实现如 Loda、RS-Hash 和 xStream 等先进算法，并通过 AXI-switch 互连以任意方式组合结果，同时利用 High-level synthesis (HLS) 支持自定义检测器。借助可重配置的 Dynamic Function eXchange (DFX)，系统能在运行时动态适应环境变化；实验结果显示，与 CPU 实现相比，在四个标准数据集上，fSEAD 的速度提升了 3 倍至 8 倍。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "The source code for this paper is available at:\n  https://github.com/bingleilou/fSEAD",
      "pdf_url": "http://arxiv.org/pdf/2406.05999v1",
      "published_date": "2024-06-10 03:38:35 UTC",
      "updated_date": "2024-06-10 03:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:30:23.234923"
    },
    {
      "arxiv_id": "2406.05995v1",
      "title": "A Dual-View Approach to Classifying Radiology Reports by Co-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Han",
        "Yan Yuan",
        "Lili Mou"
      ],
      "abstract": "Radiology report analysis provides valuable information that can aid with\npublic health initiatives, and has been attracting increasing attention from\nthe research community. In this work, we present a novel insight that the\nstructure of a radiology report (namely, the Findings and Impression sections)\noffers different views of a radiology scan. Based on this intuition, we further\npropose a co-training approach, where two machine learning models are built\nupon the Findings and Impression sections, respectively, and use each other's\ninformation to boost performance with massive unlabeled data in a\nsemi-supervised manner. We conducted experiments in a public health\nsurveillance study, and results show that our co-training approach is able to\nimprove performance using the dual views and surpass competing supervised and\nsemi-supervised methods.",
      "tldr_zh": "本研究提出了一种双视角（dual-view）方法，用于分类放射学报告（radiology reports），基于报告结构中Findings和Impression部分的不同视角。研究采用co-training方法，构建两个机器学习模型分别基于这些部分，并通过互换信息在半监督（semi-supervised）方式下利用大量未标注数据提升性能。在公共卫生监测研究中的实验结果显示，该方法超过了现有的监督和半监督方法，显著提高了分类准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05995v1",
      "published_date": "2024-06-10 03:29:23 UTC",
      "updated_date": "2024-06-10 03:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:30:41.235715"
    },
    {
      "arxiv_id": "2406.05984v1",
      "title": "Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook",
      "title_zh": "通过社交媒体的解释性 AI 用于精神障碍检测：调查与展望",
      "authors": [
        "Yusif Ibrahimov",
        "Tarique Anwar",
        "Tommy Yuan"
      ],
      "abstract": "Mental health constitutes a complex and pervasive global challenge, affecting\nmillions of lives and often leading to severe consequences. In this paper, we\nconduct a thorough survey to explore the intersection of data science,\nartificial intelligence, and mental healthcare, focusing on the recent\ndevelopments of mental disorder detection through online social media (OSM). A\nsignificant portion of the population actively engages in OSM platforms,\ncreating a vast repository of personal data that holds immense potential for\nmental health analytics. The paper navigates through traditional diagnostic\nmethods, state-of-the-art data- and AI-driven research studies, and the\nemergence of explainable AI (XAI) models for mental healthcare. We review\nstate-of-the-art machine learning methods, particularly those based on modern\ndeep learning, while emphasising the need for explainability in healthcare AI\nmodels. The experimental design section provides insights into prevalent\npractices, including available datasets and evaluation approaches. We also\nidentify key issues and challenges in the field and propose promising future\nresearch directions. As mental health decisions demand transparency,\ninterpretability, and ethical considerations, this paper contributes to the\nongoing discourse on advancing XAI in mental healthcare through social media.\nThe comprehensive overview presented here aims to guide researchers,\npractitioners, and policymakers in developing the area of mental disorder\ndetection.",
      "tldr_zh": "这篇论文对通过在线社交媒体(OSM)检测精神障碍的Explainable AI (XAI)进行了全面调查，探讨了数据科学、AI与心理健康领域的交叉点。论文回顾了传统诊断方法、先进的机器学习和深度学习技术，并强调了XAI模型在确保AI决策透明性、解释性和伦理考虑方面的必要性。作者分析了实验设计、可用数据集和评估方法，同时识别了关键挑战，如数据隐私和模型可靠性，并提出了未来研究方向。总体上，这为研究者、从业者和决策者提供了指导，推动XAI在精神健康检测领域的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05984v1",
      "published_date": "2024-06-10 02:51:16 UTC",
      "updated_date": "2024-06-10 02:51:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:30:44.821726"
    },
    {
      "arxiv_id": "2406.05981v4",
      "title": "ShiftAddLLM: Accelerating Pretrained LLMs via Post-Training Multiplication-Less Reparameterization",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran You",
        "Yipin Guo",
        "Yichao Fu",
        "Wei Zhou",
        "Huihong Shi",
        "Xiaofan Zhang",
        "Souvik Kundu",
        "Amir Yazdanbakhsh",
        "Yingyan Celine Lin"
      ],
      "abstract": "Large language models (LLMs) have shown impressive performance on language\ntasks but face challenges when deployed on resource-constrained devices due to\ntheir extensive parameters and reliance on dense multiplications, resulting in\nhigh memory demands and latency bottlenecks. Shift-and-add reparameterization\noffers a promising solution by replacing costly multiplications with\nhardware-friendly primitives in both the attention and multi-layer perceptron\n(MLP) layers of an LLM. However, current reparameterization techniques require\ntraining from scratch or full parameter fine-tuning to restore accuracy, which\nis resource-intensive for LLMs. To address this, we propose accelerating\npretrained LLMs through post-training shift-and-add reparameterization,\ncreating efficient multiplication-free models, dubbed ShiftAddLLM.\nSpecifically, we quantize each weight matrix into binary matrices paired with\ngroup-wise scaling factors. The associated multiplications are reparameterized\ninto (1) shifts between activations and scaling factors and (2) queries and\nadds according to the binary matrices. To reduce accuracy loss, we present a\nmulti-objective optimization method to minimize both weight and output\nactivation reparameterization errors. Additionally, based on varying\nsensitivity across layers to reparameterization, we develop an automated bit\nallocation strategy to further reduce memory usage and latency. Experiments on\nfive LLM families and eight tasks consistently validate the effectiveness of\nShiftAddLLM, achieving average perplexity improvements of 5.6 and 22.7 points\nat comparable or lower latency compared to the most competitive quantized LLMs\nat 3 and 2 bits, respectively, and more than 80% memory and energy reductions\nover the original LLMs. Codes and models are available at\nhttps://github.com/GATECH-EIC/ShiftAddLLM.",
      "tldr_zh": "本研究提出ShiftAddLLM，一种后训练重参数化方法，用于加速预训练的大型语言模型(LLMs)，通过替换密集乘法为移位和加法操作，解决LLMs在资源受限设备上的高内存需求和延迟问题。具体而言，该方法将权重矩阵量化成二进制矩阵和组级缩放因子，并使用多目标优化最小化重参数化误差，同时引入自动化位分配策略以进一步降低内存和延迟。实验在五个LLM系列和八个任务上验证了其有效性，与最先进的量化LLMs相比，ShiftAddLLM在3位和2位量化下分别提高了平均困惑度5.6和22.7点，同时实现了80%以上的内存和能量减少。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05981v4",
      "published_date": "2024-06-10 02:47:55 UTC",
      "updated_date": "2024-11-18 20:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:30:59.384937"
    },
    {
      "arxiv_id": "2406.05972v2",
      "title": "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context",
      "title_zh": "针对不确定语境的LL",
      "authors": [
        "Jingru Jia",
        "Zehua Yuan",
        "Junhao Pan",
        "Paul E. McNamara",
        "Deming Chen"
      ],
      "abstract": "When making decisions under uncertainty, individuals often deviate from\nrational behavior, which can be evaluated across three dimensions: risk\npreference, probability weighting, and loss aversion. Given the widespread use\nof large language models (LLMs) in decision-making processes, it is crucial to\nassess whether their behavior aligns with human norms and ethical expectations\nor exhibits potential biases. Several empirical studies have investigated the\nrationality and social behavior performance of LLMs, yet their internal\ndecision-making tendencies and capabilities remain inadequately understood.\nThis paper proposes a framework, grounded in behavioral economics, to evaluate\nthe decision-making behaviors of LLMs. Through a multiple-choice-list\nexperiment, we estimate the degree of risk preference, probability weighting,\nand loss aversion in a context-free setting for three commercial LLMs:\nChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro. Our results reveal that\nLLMs generally exhibit patterns similar to humans, such as risk aversion and\nloss aversion, with a tendency to overweight small probabilities. However,\nthere are significant variations in the degree to which these behaviors are\nexpressed across different LLMs. We also explore their behavior when embedded\nwith socio-demographic features, uncovering significant disparities. For\ninstance, when modeled with attributes of sexual minority groups or physical\ndisabilities, Claude-3-Opus displays increased risk aversion, leading to more\nconservative choices. These findings underscore the need for careful\nconsideration of the ethical implications and potential biases in deploying\nLLMs in decision-making scenarios. Therefore, this study advocates for\ndeveloping standards and guidelines to ensure that LLMs operate within ethical\nboundaries while enhancing their utility in complex decision-making\nenvironments.",
      "tldr_zh": "本研究基于行为经济学，提出一个框架来评估大型语言模型(LLMs)在不确定情境下的决策行为，涵盖风险偏好、概率权重和损失厌恶三个维度。研究通过多选实验测试了ChatGPT-4.0-Turbo、Claude-3-Opus和Gemini-1.0-pro，发现这些LLMs表现出类似于人类的模式，如风险厌恶和损失厌恶，并倾向于过度重视小概率事件，但不同模型间的表现有显著差异。进一步探索显示，当LLMs嵌入社会人口学特征（如性少数群体或身体残疾属性）时，Claude-3-Opus会表现出更高的风险厌恶，导致更保守的选择，这揭示了潜在偏见。论文强调了LLMs在决策应用中的伦理风险，并呼吁制定标准以确保其合乎道德规范。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG",
        "econ.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "Jingru Jia and Zehua Yuan have equal contribution",
      "pdf_url": "http://arxiv.org/pdf/2406.05972v2",
      "published_date": "2024-06-10 02:14:19 UTC",
      "updated_date": "2024-11-01 00:50:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:31:12.339940"
    },
    {
      "arxiv_id": "2406.05967v2",
      "title": "CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark",
      "title_zh": "CVQA: 文化多样的多语言视觉问答基准",
      "authors": [
        "David Romero",
        "Chenyang Lyu",
        "Haryo Akbarianto Wibowo",
        "Teresa Lynn",
        "Injy Hamed",
        "Aditya Nanda Kishore",
        "Aishik Mandal",
        "Alina Dragonetti",
        "Artem Abzaliev",
        "Atnafu Lambebo Tonja",
        "Bontu Fufa Balcha",
        "Chenxi Whitehouse",
        "Christian Salamea",
        "Dan John Velasco",
        "David Ifeoluwa Adelani",
        "David Le Meur",
        "Emilio Villa-Cueva",
        "Fajri Koto",
        "Fauzan Farooqui",
        "Frederico Belcavello",
        "Ganzorig Batnasan",
        "Gisela Vallejo",
        "Grainne Caulfield",
        "Guido Ivetta",
        "Haiyue Song",
        "Henok Biadglign Ademtew",
        "Hernán Maina",
        "Holy Lovenia",
        "Israel Abebe Azime",
        "Jan Christian Blaise Cruz",
        "Jay Gala",
        "Jiahui Geng",
        "Jesus-German Ortiz-Barajas",
        "Jinheon Baek",
        "Jocelyn Dunstan",
        "Laura Alonso Alemany",
        "Kumaranage Ravindu Yasas Nagasinghe",
        "Luciana Benotti",
        "Luis Fernando D'Haro",
        "Marcelo Viridiano",
        "Marcos Estecha-Garitagoitia",
        "Maria Camila Buitrago Cabrera",
        "Mario Rodríguez-Cantelar",
        "Mélanie Jouitteau",
        "Mihail Mihaylov",
        "Mohamed Fazli Mohamed Imam",
        "Muhammad Farid Adilazuarda",
        "Munkhjargal Gochoo",
        "Munkh-Erdene Otgonbold",
        "Naome Etori",
        "Olivier Niyomugisha",
        "Paula Mónica Silva",
        "Pranjal Chitale",
        "Raj Dabre",
        "Rendi Chevi",
        "Ruochen Zhang",
        "Ryandito Diandaru",
        "Samuel Cahyawijaya",
        "Santiago Góngora",
        "Soyeong Jeong",
        "Sukannya Purkayastha",
        "Tatsuki Kuribayashi",
        "Teresa Clifford",
        "Thanmay Jayakumar",
        "Tiago Timponi Torrent",
        "Toqeer Ehsan",
        "Vladimir Araujo",
        "Yova Kementchedjhieva",
        "Zara Burzo",
        "Zheng Wei Lim",
        "Zheng Xin Yong",
        "Oana Ignat",
        "Joan Nwatu",
        "Rada Mihalcea",
        "Thamar Solorio",
        "Alham Fikri Aji"
      ],
      "abstract": "Visual Question Answering (VQA) is an important task in multimodal AI, and it\nis often used to test the ability of vision-language models to understand and\nreason on knowledge present in both visual and textual data. However, most of\nthe current VQA models use datasets that are primarily focused on English and a\nfew major world languages, with images that are typically Western-centric.\nWhile recent efforts have tried to increase the number of languages covered on\nVQA datasets, they still lack diversity in low-resource languages. More\nimportantly, although these datasets often extend their linguistic range via\ntranslation or some other approaches, they usually keep images the same,\nresulting in narrow cultural representation. To address these limitations, we\nconstruct CVQA, a new Culturally-diverse multilingual Visual Question Answering\nbenchmark, designed to cover a rich set of languages and cultures, where we\nengage native speakers and cultural experts in the data collection process. As\na result, CVQA includes culturally-driven images and questions from across 30\ncountries on four continents, covering 31 languages with 13 scripts, providing\na total of 10k questions. We then benchmark several Multimodal Large Language\nModels (MLLMs) on CVQA, and show that the dataset is challenging for the\ncurrent state-of-the-art models. This benchmark can serve as a probing\nevaluation suite for assessing the cultural capability and bias of multimodal\nmodels and hopefully encourage more research efforts toward increasing cultural\nawareness and linguistic diversity in this field.",
      "tldr_zh": "这篇论文提出了 CVQA，一个文化多样多语言的 Visual Question Answering (VQA) 基准数据集，以解决现有数据集在语言和文化代表性上的不足问题。CVQA 包括来自 30 个国家（覆盖四大洲）的文化驱动图像和问题，总共 10,000 个问题，涉及 31 种语言和 13 种脚本，并由母语者和文化专家参与数据收集。通过基准测试几种 Multimodal Large Language Models (MLLMs)，结果显示当前最先进模型在 CVQA 上面临挑战，突显了模型的文化偏见。该基准可作为评估工具，促进更多研究以提升多模态模型的文化意识和语言多样性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) Track on Datasets and Benchmarks",
      "pdf_url": "http://arxiv.org/pdf/2406.05967v2",
      "published_date": "2024-06-10 01:59:00 UTC",
      "updated_date": "2024-11-04 07:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:31:23.241861"
    },
    {
      "arxiv_id": "2406.05965v1",
      "title": "MakeSinger: A Semi-Supervised Training Method for Data-Efficient Singing Voice Synthesis via Classifier-free Diffusion Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Semin Kim",
        "Myeonghun Jeong",
        "Hyeonseung Lee",
        "Minchan Kim",
        "Byoung Jin Choi",
        "Nam Soo Kim"
      ],
      "abstract": "In this paper, we propose MakeSinger, a semi-supervised training method for\nsinging voice synthesis (SVS) via classifier-free diffusion guidance. The\nchallenge in SVS lies in the costly process of gathering aligned sets of text,\npitch, and audio data. MakeSinger enables the training of the diffusion-based\nSVS model from any speech and singing voice data regardless of its labeling,\nthereby enhancing the quality of generated voices with large amount of\nunlabeled data. At inference, our novel dual guiding mechanism gives text and\npitch guidance on the reverse diffusion step by estimating the score of masked\ninput. Experimental results show that the model trained in a semi-supervised\nmanner outperforms other baselines trained only on the labeled data in terms of\npronunciation, pitch accuracy and overall quality. Furthermore, we demonstrate\nthat by adding Text-to-Speech (TTS) data in training, the model can synthesize\nthe singing voices of TTS speakers even without their singing voices.",
      "tldr_zh": "本研究提出 MakeSinger，一种半监督训练方法，用于数据高效的歌声合成 (Singing Voice Synthesis, SVS)，通过 classifier-free diffusion guidance 利用未标注的语音和歌声数据进行训练，从而降低数据收集成本并提升生成声音质量。MakeSinger 在推理阶段引入新型双引导机制，对反向扩散步骤提供文本和音高引导，基于掩码输入的得分估计实现精确控制。实验结果显示，该方法在发音、音高准确性和整体质量上优于仅使用标注数据的基线模型。此外，通过添加 Text-to-Speech (TTS) 数据，模型能合成 TTS 说话者的歌声，即使没有他们的歌声数据。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05965v1",
      "published_date": "2024-06-10 01:47:52 UTC",
      "updated_date": "2024-06-10 01:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:31:38.329865"
    },
    {
      "arxiv_id": "2406.05963v1",
      "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Jinwoo Ahn",
        "Junhyeok Park",
        "Min-Jun Kim",
        "Kang-Hyeon Kim",
        "So-Yeong Sohn",
        "Yun-Ji Lee",
        "Du-Seong Chang",
        "Yu-Jung Heo",
        "Eun-Sol Kim"
      ],
      "abstract": "In this paper, the solution of HYU MLLAB KT Team to the Multimodal\nAlgorithmic Reasoning Task: SMART-101 CVPR 2024 Challenge is presented. Beyond\nconventional visual question-answering problems, the SMART-101 challenge aims\nto achieve human-level multimodal understanding by tackling complex\nvisio-linguistic puzzles designed for children in the 6-8 age group. To solve\nthis problem, we suggest two main ideas. First, to utilize the reasoning\nability of a large-scale language model (LLM), the given visual cues (images)\nare grounded in the text modality. For this purpose, we generate highly\ndetailed text captions that describe the context of the image and use these\ncaptions as input for the LLM. Second, due to the nature of puzzle images,\nwhich often contain various geometric visual patterns, we utilize an object\ndetection algorithm to ensure these patterns are not overlooked in the\ncaptioning process. We employed the SAM algorithm, which can detect\nvarious-size objects, to capture the visual features of these geometric\npatterns and used this information as input for the LLM. Under the puzzle split\nconfiguration, we achieved an option selection accuracy Oacc of 29.5 on the\ntest set and a weighted option selection accuracy (WOSA) of 27.1 on the\nchallenge set.",
      "tldr_zh": "这篇论文介绍了 HYU MLLAB KT 团队针对 CVPR 2024 SMART-101 挑战的解决方案，该挑战旨在通过处理针对 6-8 岁儿童设计的复杂视觉语言谜题，实现人类水平的多模态理解。团队的主要方法包括：首先，将图像视觉线索转化为详细文本标题，作为 LLM 的输入，以利用其推理能力；其次，使用对象检测算法（如 SAM）捕捉谜题中的几何视觉模式，确保这些特征不被忽略，并将其信息整合进 LLM 输入。实验结果显示，在谜题分割配置下，测试集的选项选择准确率 (Oacc) 为 29.5%，挑战集的加权选项选择准确率 (WOSA) 为 27.1%，证明了该方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05963v1",
      "published_date": "2024-06-10 01:45:55 UTC",
      "updated_date": "2024-06-10 01:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:32:02.120055"
    },
    {
      "arxiv_id": "2406.05954v3",
      "title": "Aligning Large Language Models with Representation Editing: A Control Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Lingkai Kong",
        "Haorui Wang",
        "Wenhao Mu",
        "Yuanqi Du",
        "Yuchen Zhuang",
        "Yifei Zhou",
        "Yue Song",
        "Rongzhi Zhang",
        "Kai Wang",
        "Chao Zhang"
      ],
      "abstract": "Aligning large language models (LLMs) with human objectives is crucial for\nreal-world applications. However, fine-tuning LLMs for alignment often suffers\nfrom unstable training and requires substantial computing resources. Test-time\nalignment techniques, such as prompting and guided decoding, do not modify the\nunderlying model, and their performance remains dependent on the original\nmodel's capabilities. To address these challenges, we propose aligning LLMs\nthrough representation editing. The core of our method is to view a pre-trained\nautoregressive LLM as a discrete-time stochastic dynamical system. To achieve\nalignment for specific objectives, we introduce external control signals into\nthe state space of this language dynamical system. We train a value function\ndirectly on the hidden states according to the Bellman equation, enabling\ngradient-based optimization to obtain the optimal control signals at test time.\nOur experiments demonstrate that our method outperforms existing test-time\nalignment techniques while requiring significantly fewer resources compared to\nfine-tuning methods. Our code is available at\nhttps://github.com/Lingkai-Kong/RE-Control.",
      "tldr_zh": "这篇论文提出了一种通过表示编辑(representation editing)从控制视角对齐大型语言模型(LLMs)的新方法，以解决传统微调的不稳定性和高资源消耗问题，同时克服测试时对齐技术的依赖性。核心方法是将预训练的自回归LLMs视为离散时间随机动态系统，引入外部控制信号到状态空间，并通过在隐藏状态上训练价值函数(Bellman equation)来实现梯度优化获取最优控制信号。实验结果表明，该方法在性能上优于现有测试时对齐技术，且所需资源显著少于微调方法，为高效LLMs对齐提供了可行方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05954v3",
      "published_date": "2024-06-10 01:21:31 UTC",
      "updated_date": "2024-11-01 17:46:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:32:04.413732"
    },
    {
      "arxiv_id": "2406.05948v2",
      "title": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models",
      "title_zh": "Chain-of-Scrutiny：检测大型语言模型的后门攻击",
      "authors": [
        "Xi Li",
        "Yusen Zhang",
        "Renze Lou",
        "Chen Wu",
        "Jiaqi Wang"
      ],
      "abstract": "Large Language Models (LLMs), especially those accessed via APIs, have\ndemonstrated impressive capabilities across various domains. However, users\nwithout technical expertise often turn to (untrustworthy) third-party services,\nsuch as prompt engineering, to enhance their LLM experience, creating\nvulnerabilities to adversarial threats like backdoor attacks.\nBackdoor-compromised LLMs generate malicious outputs to users when inputs\ncontain specific \"triggers\" set by attackers. Traditional defense strategies,\noriginally designed for small-scale models, are impractical for API-accessible\nLLMs due to limited model access, high computational costs, and data\nrequirements. To address these limitations, we propose Chain-of-Scrutiny (CoS)\nwhich leverages LLMs' unique reasoning abilities to mitigate backdoor attacks.\nIt guides the LLM to generate reasoning steps for a given input and scrutinizes\nfor consistency with the final output -- any inconsistencies indicating a\npotential attack. It is well-suited for the popular API-only LLM deployments,\nenabling detection at minimal cost and with little data. User-friendly and\ndriven by natural language, it allows non-experts to perform the defense\nindependently while maintaining transparency. We validate the effectiveness of\nCoS through extensive experiments on various tasks and LLMs, with results\nshowing greater benefits for more powerful LLMs.",
      "tldr_zh": "这篇论文提出了 Chain-of-Scrutiny (CoS) 方法，用于检测 Large Language Models (LLMs) 的后门攻击，针对 API 访问场景中用户依赖第三方服务带来的风险。CoS 利用 LLM 的推理能力，引导模型为输入生成推理步骤，并检查这些步骤与最终输出的一致性——任何不一致都可能表明攻击存在。该方法低成本、少数据需求，且用户友好，便于非专家独立操作。实验验证显示，CoS 在多种任务和 LLM 上有效，尤其对更强大的模型收益更大。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05948v2",
      "published_date": "2024-06-10 00:53:25 UTC",
      "updated_date": "2024-12-21 00:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:32:14.697781"
    },
    {
      "arxiv_id": "2406.05946v1",
      "title": "Safety Alignment Should Be Made More Than Just a Few Tokens Deep",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Qi",
        "Ashwinee Panda",
        "Kaifeng Lyu",
        "Xiao Ma",
        "Subhrajit Roy",
        "Ahmad Beirami",
        "Prateek Mittal",
        "Peter Henderson"
      ],
      "abstract": "The safety alignment of current Large Language Models (LLMs) is vulnerable.\nRelatively simple attacks, or even benign fine-tuning, can jailbreak aligned\nmodels. We argue that many of these vulnerabilities are related to a shared\nunderlying issue: safety alignment can take shortcuts, wherein the alignment\nadapts a model's generative distribution primarily over only its very first few\noutput tokens. We refer to this issue as shallow safety alignment. In this\npaper, we present case studies to explain why shallow safety alignment can\nexist and provide evidence that current aligned LLMs are subject to this issue.\nWe also show how these findings help explain multiple recently discovered\nvulnerabilities in LLMs, including the susceptibility to adversarial suffix\nattacks, prefilling attacks, decoding parameter attacks, and fine-tuning\nattacks. Importantly, we discuss how this consolidated notion of shallow safety\nalignment sheds light on promising research directions for mitigating these\nvulnerabilities. For instance, we show that deepening the safety alignment\nbeyond just the first few tokens can often meaningfully improve robustness\nagainst some common exploits. Finally, we design a regularized finetuning\nobjective that makes the safety alignment more persistent against fine-tuning\nattacks by constraining updates on initial tokens. Overall, we advocate that\nfuture safety alignment should be made more than just a few tokens deep.",
      "tldr_zh": "该研究指出，大型语言模型 (LLMs) 的安全对齐（safety alignment）存在浅层问题，即仅在模型的最初几个输出 tokens 上生效，导致其易受简单攻击或良性微调（如对抗后缀攻击、预填充攻击、解码参数攻击和微调攻击）破坏。作者通过案例研究和证据分析，解释了浅层安全对齐（shallow safety alignment）的原因，并证明了当前 LLMs 普遍存在这一漏洞。论文进一步探讨了加深安全对齐的潜在解决方案，如通过正则化微调目标约束初始 tokens 的更新，以提升模型的鲁棒性。实验结果显示，这种方法能显著改善对常见攻击的抵抗力。总之，该工作主张未来安全对齐应扩展到更多 tokens，以构建更可靠的 LLM 系统。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05946v1",
      "published_date": "2024-06-10 00:35:23 UTC",
      "updated_date": "2024-06-10 00:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T18:32:28.971871"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 115,
  "processed_papers_count": 115,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T18:32:58.248031"
}