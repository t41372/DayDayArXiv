{
  "date": "2025-09-08",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-08 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ **ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv çˆ†å‘äº† **AI for Science** çš„é‡ç£…å·¥ä½œï¼ˆGoogle DeepMind å›¢é˜Ÿé¢†è¡”çš„ 71 é¡µé•¿æ–‡ï¼‰ï¼Œ**Agentï¼ˆæ™ºèƒ½ä½“ï¼‰** é¢†åŸŸåœ¨ç§‘ç ”è‡ªåŠ¨åŒ–å’Œ GUI æ“ä½œä¸Šæœ‰äº†æ–°çªç ´ï¼ŒåŒæ—¶ **LLM çš„æ•°å­¦æ¨ç†**ã€**MoE æ¶æ„ä¼˜åŒ–** ä»¥åŠ **å®‰å…¨ï¼ˆé—å¿˜å­¦ä¹ ä¸è¶Šç‹±é˜²å¾¡ï¼‰** ä¹Ÿæ˜¯ä»Šæ—¥çš„è®¨è®ºçƒ­ç‚¹ã€‚\n\n---\n\n### ğŸš€ é‡ç£…æ¨èï¼šAI for Science ä¸ ç§‘ç ”è‡ªåŠ¨åŒ–\n\nä»Šå¤©æœ€ä»¤äººç©ç›®çš„æ— ç–‘æ˜¯ Google DeepMind è”åˆå›¢é˜Ÿå‘å¸ƒçš„å…³äºè‡ªåŠ¨ç”Ÿæˆç§‘å­¦è½¯ä»¶çš„ç³»ç»Ÿï¼Œä»¥åŠæ–¯å¦ç¦å›¢é˜Ÿå°†è®ºæ–‡è½¬åŒ–ä¸º Agent çš„å°è¯•ã€‚\n\n**1. An AI system to help scientists write expert-level empirical software (ä¸€ä¸ªå¸®åŠ©ç§‘å­¦å®¶ç¼–å†™ä¸“å®¶çº§å®è¯è½¯ä»¶çš„ AI ç³»ç»Ÿ)**\n> **Authors:** Eser AygÃ¼n, et al. (Google DeepMind & Google Research)\n> **å…³é”®è¯:** AI for Science, Code Generation, Tree Search, LLM\n> **TLDR:** è¿™æ˜¯ä¸€ç¯‡ 71 é¡µçš„å·¨è‘—ã€‚Google å›¢é˜Ÿæå‡ºäº†ä¸€ä¸ªç»“åˆ **LLM** å’Œ **æ ‘æœç´¢ (Tree Search)** çš„ç³»ç»Ÿï¼Œæ—¨åœ¨è‡ªåŠ¨ç”Ÿæˆèƒ½æœ€å¤§åŒ–ç‰¹å®šè´¨é‡æŒ‡æ ‡çš„ç§‘å­¦è½¯ä»¶ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** ä¼ ç»Ÿçš„ç§‘å­¦å‘ç°å¸¸å—é™äºæ‰‹åŠ¨ç¼–å†™å®éªŒä»£ç çš„ç“¶é¢ˆã€‚è¯¥ç³»ç»Ÿä¸åªæ˜¯å†™ä»£ç ï¼Œè¿˜èƒ½æ¢ç´¢å’Œæ•´åˆå¤æ‚çš„å¤–éƒ¨ç ”ç©¶æ€è·¯ï¼ˆNoveltyï¼‰ã€‚åœ¨ç”Ÿç‰©ä¿¡æ¯å­¦ï¼ˆå•ç»†èƒæ•°æ®åˆ†æï¼‰ã€æµè¡Œç—…å­¦ï¼ˆCOVID-19 é¢„æµ‹ï¼Œå‡»è´¥äº† CDC é›†æˆæ¨¡å‹ï¼‰å’Œç¥ç»ç§‘å­¦ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œå®ƒç”Ÿæˆçš„è½¯ä»¶æ€§èƒ½è¶…è¿‡äº†é¡¶çº§çš„äººç±»ä¸“å®¶æ–¹æ³•ã€‚è¿™æ˜¯ AI ç‹¬ç«‹è¿›è¡Œç§‘å­¦å·¥å…·å¼€å‘çš„é‡Œç¨‹ç¢‘ã€‚\n\n**2. Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents (Paper2Agentï¼šå°†ç ”ç©¶è®ºæ–‡é‡å¡‘ä¸ºäº¤äº’å¼ä¸”å¯é çš„ AI æ™ºèƒ½ä½“)**\n> **Authors:** Jiacheng Miao, et al. (Stanford University)\n> **å…³é”®è¯:** Automated Research, MCP, Knowledge Dissemination\n> **TLDR:** è¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰æ„æ€çš„æ¡†æ¶ï¼Œå®ƒèƒ½è‡ªåŠ¨å°†é™æ€çš„ PDF è®ºæ–‡è½¬åŒ–ä¸ºæ´»è·ƒçš„ AI Agentã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** å®ƒå¯ä»¥åˆ†æè®ºæ–‡ä»£ç åº“ï¼Œæ„å»ºæ¨¡å‹ä¸Šä¸‹æ–‡åè®® (MCP) æœåŠ¡å™¨ï¼Œå¹¶ç”Ÿæˆæµ‹è¯•æ¥å¢å¼ºé²æ£’æ€§ã€‚ç”Ÿæˆçš„ \"Paper Agent\" å¯ä»¥ä½œä¸ºç§‘ç ”åŠ©æ‰‹ï¼Œä¸ä»…èƒ½å›ç­”å…³äºè®ºæ–‡çš„ç»†èŠ‚ï¼Œè¿˜èƒ½ç›´æ¥è°ƒç”¨è®ºæ–‡ä¸­çš„å·¥å…·ï¼ˆå¦‚ AlphaGenome æˆ– ScanPyï¼‰æ‰§è¡Œä¸‹æ¸¸åˆ†æä»»åŠ¡ã€‚è¿™å¯èƒ½æ”¹å˜æœªæ¥å­¦æœ¯æˆæœçš„ä¼ æ’­æ–¹å¼ã€‚\n\n**3. Reinforcement Learning Foundations for Deep Research Systems: A Survey (æ·±åº¦ç ”ç©¶ç³»ç»Ÿçš„å¼ºåŒ–å­¦ä¹ åŸºç¡€ï¼šç»¼è¿°)**\n> **Authors:** Wenjun Li, et al.\n> **å…³é”®è¯:** Deep Research, Reinforcement Learning, Agentic AI\n> **TLDR:** ç¬¬ä¸€ç¯‡ä¸“é—¨é’ˆå¯¹ \"Deep Research\" ç³»ç»Ÿï¼ˆèƒ½è§£å†³å¤æ‚ã€å¤šæ­¥ä»»åŠ¡çš„ Agentï¼‰ä¸­ RL åŸºç¡€çš„ç»¼è¿°ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** æ–‡ç« ç³»ç»ŸåŒ–äº†æ•°æ®åˆæˆã€é’ˆå¯¹ Agent çš„ RL æ–¹æ³•ï¼ˆç¨³å®šæ€§ã€æ ·æœ¬æ•ˆç‡ã€é•¿ç¨‹ä¿¡ç”¨åˆ†é…ï¼‰ä»¥åŠè®­ç»ƒæ¡†æ¶ã€‚å¯¹äºæƒ³ç”¨ RL è®­ç»ƒèƒ½å¤Ÿè‡ªä¸»ä¸Šç½‘ã€å†™ä»£ç ã€åšç ”ç©¶çš„ Agent çš„ç ”ç©¶è€…æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä»½é‡è¦çš„æŒ‡å—ã€‚\n\n---\n\n### ğŸ§  LLM æ¨ç†ã€æ•°å­¦ä¸æ¶æ„ä¼˜åŒ–\n\nå¤§æ¨¡å‹çš„æ•°å­¦èƒ½åŠ›å’Œæ¨ç†æ•ˆç‡ä¾ç„¶æ˜¯â€œå·â€çš„ä¸­å¿ƒã€‚\n\n**4. Systematic Optimization of Open Source Large Language Models for Mathematical Reasoning (å¼€æºå¤§æ¨¡å‹æ•°å­¦æ¨ç†çš„ç³»ç»Ÿæ€§ä¼˜åŒ–)**\n> **Authors:** Pranav Pawar, et al.\n> **å…³é”®è¯:** Mathematical Reasoning, Hyperparameter Tuning, Production Framework\n> **TLDR:** é’ˆå¯¹ Qwen2.5, Llama-3.1, DeepSeek-V3 ç­‰ SOTA æ¨¡å‹åœ¨æ•°å­¦ä»»åŠ¡ä¸Šçš„ç³»ç»Ÿæ€§è°ƒä¼˜æŠ¥å‘Šã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** ä½œè€…æ²¡æœ‰é­”æ”¹æ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡ç³»ç»Ÿæ€§æœç´¢å‚æ•°ç©ºé—´ï¼ˆæ¸©åº¦ã€æ¨ç†æ­¥æ•°ã€Planningï¼‰ï¼Œå‘ç°ä½æ¸©åº¦ (0.1-0.4) å’Œå‡å°‘æ¨ç†æ­¥æ•°èƒ½æå‡æ•ˆç‡ä¸”ä¸é™ç²¾åº¦ã€‚ç»“è®ºæ˜¯ **DeepSeek-V3** å‡†ç¡®ç‡æœ€é«˜ (98%)ï¼Œè€Œ **Mixtral-8x22B** æ€§ä»·æ¯”æœ€é«˜ã€‚\n\n**5. Ban&Pick: Ehancing Performance and Efficiency of MoE-LLMs via Smarter Routing (Ban&Pickï¼šé€šè¿‡æ›´æ™ºèƒ½çš„è·¯ç”±å¢å¼º MoE-LLM çš„æ€§èƒ½ä¸æ•ˆç‡)**\n> **Authors:** Yuanteng Chen, et al.\n> **å…³é”®è¯:** Mixture-of-Experts, Routing Strategy, Inference Efficiency\n> **TLDR:** æ­ç¤ºäº† MoE æ¨¡å‹åœ¨é¢„è®­ç»ƒæ—¶ä¸ºäº†è´Ÿè½½å‡è¡¡è€Œå¯¼è‡´æ¨ç†æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** æå‡ºäº†ä¸€ç§å³æ’å³ç”¨ï¼ˆæ— éœ€é‡æ–°è®­ç»ƒï¼‰çš„ç­–ç•¥ã€‚\"Pick\" å¼ºåŒ–é‚£äº›å½±å“åŠ›å¤§ä½†åˆ©ç”¨ç‡ä¸è¶³çš„ä¸“å®¶ï¼Œ\"Ban\" åŠ¨æ€å‰ªæå†—ä½™ä¸“å®¶ã€‚åœ¨ Qwen3 ç­‰æ¨¡å‹ä¸Šï¼Œä¸ä»…æå‡äº†æ•°å­¦å’Œä»£ç ä»»åŠ¡çš„å‡†ç¡®ç‡ï¼Œè¿˜åŠ é€Ÿäº† 1.25 å€æ¨ç†ã€‚\n\n**6. Lookup multivariate Kolmogorov-Arnold Networks (æŸ¥æ‰¾è¡¨å¤šå˜é‡ KANï¼šé«˜æ•ˆçš„å‡½æ•°è¿‘ä¼¼)**\n> **Authors:** Sergey Pozdnyakov, Philippe Schwaller\n> **å…³é”®è¯:** KAN, Architecture, Efficiency\n> **TLDR:** KAN (Kolmogorov-Arnold Networks) çš„æ–°å˜ä½“ï¼Œæ—¨åœ¨æ›¿ä»£é«˜ç»´çº¿æ€§å±‚ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** æå‡ºäº† **lmKANs**ï¼Œé€šè¿‡æ ·æ¡æŸ¥æ‰¾è¡¨å®ç°ï¼Œæå¤§åœ°é™ä½äº†æ¨ç† FLOPs (å‡å°‘ 6 å€)ï¼ŒåŒæ—¶ä¿æŒäº†å¤šå±‚æ„ŸçŸ¥æœº (MLP) çš„çµæ´»æ€§ã€‚è¿™æ˜¯å¯¹ç›®å‰ä¸»æµ Transformer æ¶æ„ä¸­çº¿æ€§å±‚çš„ä¸€ä¸ªæ½œåœ¨é«˜æ•ˆæ›¿ä»£æ–¹æ¡ˆã€‚\n\n**7. A Fragile Number Sense: Probing the Elemental Limits of Numerical Reasoning in LLMs (è„†å¼±çš„æ•°æ„Ÿï¼šæ¢ç©¶ LLM æ•°å€¼æ¨ç†çš„æœ¬è´¨æé™)**\n> **Authors:** Roussel Rahman, Aashwin Ananda Mishra\n> **å…³é”®è¯:** Numerical Reasoning, Combinatorial Search, Evaluation\n> **TLDR:** ç»™ LLM çš„æ•°å­¦èƒ½åŠ›æ³¼äº†ä¸€ç›†å†·æ°´ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** å‘ç° LLM åœ¨ç¡®å®šæ€§ç®—æ³•æ‰§è¡Œï¼ˆå¦‚ç´ æ•°æ£€æŸ¥ï¼‰ä¸Šè¡¨ç°å°šå¯ï¼Œä½†åœ¨éœ€è¦å¯å‘å¼æœç´¢çš„ç»„åˆè°œé¢˜ï¼ˆå¦‚ \"24ç‚¹\" æ¸¸æˆï¼‰ä¸Šå½»åº•å¤±è´¥ã€‚ç»“è®ºæ˜¯ï¼šLLMç›®å‰çš„æ•°å­¦èƒ½åŠ›æ›´åƒæ˜¯å¤æ‚çš„æ¨¡å¼åŒ¹é…ï¼Œè€ŒéçœŸæ­£çš„è§£ææ€ç»´æˆ–ç”Ÿæˆå¼é—®é¢˜è§£å†³ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€éšç§ä¸é—å¿˜å­¦ä¹ \n\néšç€ AI æ³•è§„çš„æ¨è¿›ï¼Œ\"é—å¿˜æƒ\"å’Œé˜²å¾¡æ”»å‡»å˜å¾—è‡³å…³é‡è¦ã€‚\n\n**8. zkUnlearner: A Zero-Knowledge Framework for Verifiable Unlearning with Multi-Granularity and Forgery-Resistance (zkUnlearnerï¼šä¸€ç§æ”¯æŒå¤šç²’åº¦å’Œé˜²ä¼ªé€ çš„å¯éªŒè¯é—å¿˜é›¶çŸ¥è¯†æ¡†æ¶)**\n> **Authors:** Nan Wang, et al.\n> **å…³é”®è¯:** Machine Unlearning, Zero-Knowledge Proofs, Privacy\n> **TLDR:** å½“ç”¨æˆ·è¦æ±‚æ¨¡å‹\"é—å¿˜\"æ•°æ®æ—¶ï¼Œå¦‚ä½•è¯æ˜æ¨¡å‹çœŸçš„å¿˜äº†ï¼Ÿ\n> **æ ¸å¿ƒè´¡çŒ®:** æå‡ºäº†ç¬¬ä¸€ä¸ªç”¨äºæœºå™¨é—å¿˜çš„é›¶çŸ¥è¯†è¯æ˜ (ZKP) æ¡†æ¶ã€‚å®ƒä¸ä»…æ”¯æŒæ ·æœ¬çº§é—å¿˜ï¼Œè¿˜æ”¯æŒç‰¹å¾çº§å’Œç±»åˆ«çº§é—å¿˜ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå®ƒè§£å†³äº†\"ä¼ªé€ æ”»å‡»\"é—®é¢˜ï¼ˆå³æœåŠ¡å™¨å‡è£…å¿˜äº†ï¼Œå®é™…ä¸Šæ²¡å¿˜ï¼‰ï¼Œä¸º AI çš„åˆè§„æ€§æä¾›äº†æŠ€æœ¯ä¿éšœã€‚\n\n**9. Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm (Paladinï¼šåˆ©ç”¨è§¦å‘å™¨-æ ‡ç­¾èŒƒå¼é˜²å¾¡ LLMç”Ÿæˆçš„é’“é±¼é‚®ä»¶)**\n> **Authors:** Yan Pang, et al.\n> **å…³é”®è¯:** Phishing Detection, LLM Security, Watermarking\n> **TLDR:** ç”¨é­”æ³•æ‰“è´¥é­”æ³•ï¼Œåº”å¯¹ LLM ç”Ÿæˆçš„å®Œç¾é’“é±¼é‚®ä»¶ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** æ—¢ç„¶ LLM ç”Ÿæˆçš„é’“é±¼é‚®ä»¶æ²¡æœ‰è¯­æ³•é”™è¯¯å¾ˆéš¾æ£€æµ‹ï¼Œä½œè€…æå‡ºåœ¨ LLM ä¸­åµŒå…¥éšå¼æˆ–æ˜¾å¼çš„\"è§¦å‘å™¨-æ ‡ç­¾\"ã€‚å½“æ¨¡å‹ç”Ÿæˆé’“é±¼å†…å®¹æ—¶ï¼Œä¼šè‡ªåŠ¨å¸¦ä¸Šå¯æ£€æµ‹çš„æ ‡ç­¾ï¼Œæ£€æµ‹ç‡è¶…è¿‡ 90%ã€‚\n\n**10. Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks? (Mask-GCGï¼šè¶Šç‹±æ”»å‡»ä¸­çš„å¯¹æŠ—åç¼€çœŸçš„æ¯ä¸ª Token éƒ½æœ‰ç”¨å—ï¼Ÿ)**\n> **Authors:** Junjie Mu, et al.\n> **å…³é”®è¯:** Jailbreak Attacks, Adversarial Examples, Interpretability\n> **TLDR:** å¯¹æµè¡Œçš„ GCG è¶Šç‹±æ”»å‡»è¿›è¡Œäº†ä¼˜åŒ–ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** å‘ç° GCG æ”»å‡»ç”Ÿæˆçš„åç¼€ä¸­æœ‰å¾ˆå¤šå†—ä½™ Tokenã€‚é€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„æ©ç æœºåˆ¶ï¼Œå‰ªææ‰ä½å½±å“çš„ Tokenï¼Œä¸ä»…æ”»å‡»é€Ÿåº¦æ›´å¿«ï¼Œè€Œä¸”æˆåŠŸç‡ä¸å‡ï¼Œæ­ç¤ºäº† LLM å¯¹æŠ—æ ·æœ¬çš„ç¨€ç–æ€§ã€‚\n\n---\n\n### ğŸ¨ å¤šæ¨¡æ€ä¸è§†è§‰ç”Ÿæˆ\n\n**11. Interleaving Reasoning for Better Text-to-Image Generation (äº¤é”™æ¨ç†ä»¥æå‡æ–‡ç”Ÿå›¾è´¨é‡)**\n> **Authors:** Wenxuan Huang, et al.\n> **å…³é”®è¯:** Text-to-Image, Chain-of-Thought, Multimodal Generation\n> **TLDR:** è®©ç”Ÿå›¾æ¨¡å‹å…ˆ\"æ€è€ƒ\"å†\"ä½œç”»\"ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** æå‡ºäº† **IRG** æ¡†æ¶ï¼Œæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒå‰å…ˆç”Ÿæˆæ–‡æœ¬å½¢å¼çš„\"æ€è€ƒ\"ï¼ˆThinkingï¼‰æ¥è§„åˆ’å†…å®¹ï¼Œç”Ÿæˆåˆæ­¥å›¾åƒåï¼Œå†è¿›è¡Œ\"åæ€\"ï¼ˆReflectionï¼‰æ¥ç»†åŒ–ç»†èŠ‚ã€‚è¿™ç§ç±»ä¼¼ GPT-4o çš„äº¤é”™æ¨ç†æ¨¡å¼æ˜¾è‘—æå‡äº†å›¾åƒçš„è¯­ä¹‰ä¸€è‡´æ€§å’Œç»†èŠ‚è´¨é‡ã€‚\n\n**12. SVGauge: Towards Human-Aligned Evaluation for SVG Generation (SVGaugeï¼šé¢å‘ SVG ç”Ÿæˆçš„äººç±»å¯¹é½è¯„ä¼°)**\n> **Authors:** Leonardo Zini, et al.\n> **å…³é”®è¯:** SVG Generation, Evaluation Metric, Vector Graphics\n> **TLDR:** çŸ¢é‡å›¾ (SVG) ç”Ÿæˆä¸€ç›´ç¼ºä¹å¥½çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒFID ç­‰åŸºäºåƒç´ çš„æŒ‡æ ‡å¹¶ä¸é€‚ç”¨ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** æå‡ºäº†é¦–ä¸ªé’ˆå¯¹ Text-to-SVG çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç»“åˆäº†è§†è§‰ä¿çœŸåº¦ï¼ˆä½¿ç”¨ SigLIPï¼‰å’Œè¯­ä¹‰ä¸€è‡´æ€§ï¼ˆä½¿ç”¨ BLIP-2ï¼‰ï¼Œæ¯”ç°æœ‰æŒ‡æ ‡æ›´ç¬¦åˆäººç±»çš„å®¡ç¾åˆ¤æ–­ã€‚\n\n---\n\n### ğŸ¥ åŒ»ç–— AI ç²¾é€‰\n\n**13. CardioComposer: Leveraging Differentiable Geometry for Compositional Control of Anatomical Diffusion Models (CardioComposerï¼šåˆ©ç”¨å¯å¾®å‡ ä½•å®ç°å¿ƒè„è§£å‰–æ‰©æ•£æ¨¡å‹çš„ç»„åˆæ§åˆ¶)**\n> **Authors:** Karim Kadry, et al. (MIT & Harvard)\n> **å…³é”®è¯:** Medical Imaging, Diffusion Models, 3D Anatomy\n> **TLDR:** ç”Ÿæˆå¯æ§çš„ 3D å¿ƒè„æ¨¡å‹ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** æå‡ºäº†ä¸€ç§å¯ç¼–ç¨‹çš„æ¡†æ¶ï¼Œå…è®¸é€šè¿‡å‡ ä½•å±æ€§ï¼ˆå¤§å°ã€å½¢çŠ¶ã€ä½ç½®ï¼‰æ¥æ§åˆ¶æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å¿ƒè„è§£å‰–ç»“æ„ã€‚è¿™å¯¹äºä¸´åºŠç ”ç©¶å’ŒåŒ»ç–—å™¨æ¢°è¯„ä¼°ä¸­çš„æ•°æ®åˆæˆéå¸¸æœ‰ä»·å€¼ã€‚\n\n**14. Breast Cancer Detection in Thermographic Images via Diffusion-Based Augmentation and Nonlinear Feature Fusion (åŸºäºæ‰©æ•£å¢å¼ºå’Œéçº¿æ€§ç‰¹å¾èåˆçš„çƒ­æˆåƒä¹³è…ºç™Œæ£€æµ‹)**\n> **Authors:** Sepehr Salem, et al.\n> **å…³é”®è¯:** Medical Imaging, Diffusion Models, Data Augmentation\n> **TLDR:** è§£å†³äº†åŒ»ç–—æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚\n> **æ ¸å¿ƒè´¡çŒ®:** è¯æ˜äº†ä½¿ç”¨æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (DPM) è¿›è¡Œæ•°æ®å¢å¼ºä¼˜äºä¼ ç»Ÿçš„ GANã€‚ç»“åˆæ‰‹å·¥æå–çš„éçº¿æ€§ç‰¹å¾ï¼ˆå¦‚åˆ†å½¢ç»´æ•°ï¼‰ï¼Œæ¨¡å‹è¾¾åˆ°äº† 98% çš„è¯Šæ–­å‡†ç¡®ç‡ã€‚\n\n---\n\n### ğŸ¤– å…¶ä»–å€¼å¾—å…³æ³¨çš„æ–‡ç« \n\n*   **[Agents/GUI] Instruction Agent: Enhancing Agent with Expert Demonstration**\n    *   é’ˆå¯¹ GUI Agent éš¾ä»¥å¤„ç†å¤æ‚ UI çš„é—®é¢˜ï¼Œæå‡ºåˆ©ç”¨ä¸“å®¶æ¼”ç¤ºæ¥æå–æŒ‡ä»¤ï¼Œæ˜¾è‘—æå‡äº† OSWorld ä»»åŠ¡çš„æˆåŠŸç‡ã€‚\n*   **[Theory] Breaking the Conventional Forward-Backward Tie in Neural Networks: Activation Functions**\n    *   æŒ‘æˆ˜äº†åå‘ä¼ æ’­å¿…é¡»å¯¹ç§°çš„å‡è®¾ï¼Œè¯æ˜äº†ä½¿ç”¨ä¸å¯å¾®æ¿€æ´»å‡½æ•°ï¼ˆå¦‚é˜¶è·ƒå‡½æ•°ï¼‰é…åˆç®€å•çš„æ¢¯åº¦æ›¿ä»£ä¹Ÿèƒ½æœ‰æ•ˆè®­ç»ƒç½‘ç»œã€‚\n*   **[Hardware/Privacy] AttestLLM: Efficient Attestation Framework for Billion-scale On-device LLMs**\n    *   é’ˆå¯¹ç«¯ä¾§å¤§æ¨¡å‹ï¼ˆå¦‚ Apple Intelligenceï¼‰ï¼Œæå‡ºäº†ä¸€ç§ä¿æŠ¤æ¨¡å‹çŸ¥è¯†äº§æƒå’ŒéªŒè¯æ¨¡å‹åˆæ³•æ€§çš„æ°´å°ä¸è®¤è¯æ¡†æ¶ã€‚\n\nå¸Œæœ›è¿™ä»½å¿«æŠ¥èƒ½å¸®ä½ å¿«é€Ÿæ¶ˆåŒ–ä»Šå¤©çš„ arXiv ç››å®´ï¼æˆ‘ä»¬æ˜å¤©è§ã€‚",
  "papers": [
    {
      "arxiv_id": "2509.07290v1",
      "title": "zkUnlearner: A Zero-Knowledge Framework for Verifiable Unlearning with Multi-Granularity and Forgery-Resistance",
      "title_zh": "zkUnlearnerï¼šæ”¯æŒå¤šç²’åº¦ä¸æŠ—ä¼ªé€ æ€§çš„å¯éªŒè¯æœºå™¨å¸è½½é›¶çŸ¥è¯†æ¡†æ¶",
      "authors": [
        "Nan Wang",
        "Nan Wu",
        "Xiangyu Hui",
        "Jiafan Wang",
        "Xin Yuan"
      ],
      "abstract": "As the demand for exercising the \"right to be forgotten\" grows, the need for verifiable machine unlearning has become increasingly evident to ensure both transparency and accountability. We present {\\em zkUnlearner}, the first zero-knowledge framework for verifiable machine unlearning, specifically designed to support {\\em multi-granularity} and {\\em forgery-resistance}.\n  First, we propose a general computational model that employs a {\\em bit-masking} technique to enable the {\\em selectivity} of existing zero-knowledge proofs of training for gradient descent algorithms. This innovation enables not only traditional {\\em sample-level} unlearning but also more advanced {\\em feature-level} and {\\em class-level} unlearning. Our model can be translated to arithmetic circuits, ensuring compatibility with a broad range of zero-knowledge proof systems. Furthermore, our approach overcomes key limitations of existing methods in both efficiency and privacy. Second, forging attacks present a serious threat to the reliability of unlearning. Specifically, in Stochastic Gradient Descent optimization, gradients from unlearned data, or from minibatches containing it, can be forged using alternative data samples or minibatches that exclude it. We propose the first effective strategies to resist state-of-the-art forging attacks. Finally, we benchmark a zkSNARK-based instantiation of our framework and perform comprehensive performance evaluations to validate its practicality.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†zkUnlearnerï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸ºå¯éªŒè¯æœºå™¨é—å¿˜(Verifiable Machine Unlearning)è®¾è®¡çš„é›¶çŸ¥è¯†(Zero-Knowledge)æ¡†æ¶ï¼Œæ—¨åœ¨æ»¡è¶³â€œè¢«é—å¿˜æƒâ€å¯¹é€æ˜åº¦å’Œé—®è´£åˆ¶çš„éœ€æ±‚ã€‚é€šè¿‡å¼•å…¥ä½æ©ç (Bit-masking)æŠ€æœ¯ï¼Œè¯¥æ¡†æ¶ä¸ºæ¢¯åº¦ä¸‹é™(Gradient Descent)ç®—æ³•æä¾›äº†é€‰æ‹©æ€§çš„é›¶çŸ¥è¯†è¯æ˜ï¼Œä¸ä»…æ”¯æŒä¼ ç»Ÿçš„æ ·æœ¬çº§(Sample-level)é—å¿˜ï¼Œè¿˜å®ç°äº†æ›´å…ˆè¿›çš„ç‰¹å¾çº§(Feature-level)å’Œç±»åˆ«çº§(Class-level)é—å¿˜ã€‚zkUnlearneré€šè¿‡å°†æ¨¡å‹è½¬æ¢ä¸ºç®—æœ¯ç”µè·¯ï¼Œç¡®ä¿äº†ä¸å¤šç§é›¶çŸ¥è¯†è¯æ˜ç³»ç»Ÿçš„å…¼å®¹æ€§ï¼Œå¹¶æ˜¾è‘—æå‡äº†å¤„ç†æ•ˆç‡ä¸éšç§ä¿æŠ¤èƒ½åŠ›ã€‚é’ˆå¯¹éšæœºæ¢¯åº¦ä¸‹é™(Stochastic Gradient Descent)ä¸­å¯èƒ½å‡ºç°çš„æ¢¯åº¦ä¼ªé€ æ”»å‡»ï¼Œè¯¥ç ”ç©¶æå‡ºäº†é¦–ä¸ªæœ‰æ•ˆçš„é˜²å¾¡ç­–ç•¥ä»¥ç¡®ä¿é—å¿˜è¿‡ç¨‹çš„å¯é æ€§ã€‚æœ€åï¼Œé€šè¿‡åŸºäºzkSNARKçš„å®ä¾‹åŒ–å®éªŒå’Œæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œç ”ç©¶éªŒè¯äº†è¯¥æ¡†æ¶åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­çš„å®ç”¨æ€§å’Œé«˜æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07290v1",
      "published_date": "2025-09-08 23:50:35 UTC",
      "updated_date": "2025-09-08 23:50:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:02.457230+00:00"
    },
    {
      "arxiv_id": "2509.07287v1",
      "title": "Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm",
      "title_zh": "Paladinï¼šåŸºäºæ–°å‹â€œè§¦å‘å™¨-æ ‡ç­¾â€èŒƒå¼é˜²å¾¡å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„é’“é±¼é‚®ä»¶",
      "authors": [
        "Yan Pang",
        "Wenlong Meng",
        "Xiaojing Liao",
        "Tianhao Wang"
      ],
      "abstract": "With the rapid development of large language models, the potential threat of their malicious use, particularly in generating phishing content, is becoming increasingly prevalent. Leveraging the capabilities of LLMs, malicious users can synthesize phishing emails that are free from spelling mistakes and other easily detectable features. Furthermore, such models can generate topic-specific phishing messages, tailoring content to the target domain and increasing the likelihood of success.\n  Detecting such content remains a significant challenge, as LLM-generated phishing emails often lack clear or distinguishable linguistic features. As a result, most existing semantic-level detection approaches struggle to identify them reliably. While certain LLM-based detection methods have shown promise, they suffer from high computational costs and are constrained by the performance of the underlying language model, making them impractical for large-scale deployment.\n  In this work, we aim to address this issue. We propose Paladin, which embeds trigger-tag associations into vanilla LLM using various insertion strategies, creating them into instrumented LLMs. When an instrumented LLM generates content related to phishing, it will automatically include detectable tags, enabling easier identification. Based on the design on implicit and explicit triggers and tags, we consider four distinct scenarios in our work. We evaluate our method from three key perspectives: stealthiness, effectiveness, and robustness, and compare it with existing baseline methods. Experimental results show that our method outperforms the baselines, achieving over 90% detection accuracy across all scenarios.",
      "tldr_zh": "é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) è¢«æ¶æ„åˆ©ç”¨ç”Ÿæˆé«˜è´¨é‡ã€éš¾ä»¥è¯†åˆ«çš„é’“é±¼é‚®ä»¶è¿™ä¸€å¨èƒï¼Œè¯¥ç ”ç©¶æå‡ºäº† Paladin é˜²å¾¡æ¡†æ¶ã€‚Paladin é‡‡ç”¨äº†ä¸€ç§åˆ›æ–°çš„ Trigger-Tag Paradigmï¼Œé€šè¿‡å¤šç§æ’å…¥ç­–ç•¥å°†è§¦å‘å™¨ä¸æ ‡ç­¾çš„å…³è”åµŒå…¥åˆ°åŸç”Ÿæ¨¡å‹ä¸­ï¼Œæ„å»ºå‡ºä»ªè¡¨åŒ– (instrumented) çš„ LLMsã€‚å½“è¯¥æ¨¡å‹ç”Ÿæˆä¸ç½‘ç»œé’“é±¼ç›¸å…³çš„å†…å®¹æ—¶ï¼Œä¼šè‡ªåŠ¨åŒ…å«ç‰¹å®šçš„å¯æ£€æµ‹æ ‡ç­¾ï¼Œä»è€Œç®€åŒ–äº†è¯†åˆ«æµç¨‹å¹¶æ˜¾è‘—é™ä½äº†ä¼ ç»Ÿ LLM æ£€æµ‹æ–¹æ³•çš„è®¡ç®—æˆæœ¬ã€‚è¯¥ç ”ç©¶è®¾è®¡äº†åŒ…å«éšå¼å’Œæ˜¾å¼è§¦å‘å™¨ä¸æ ‡ç­¾çš„å››ç§ä¸åŒåœºæ™¯ï¼Œå¹¶ä»éšè”½æ€§ (stealthiness)ã€æœ‰æ•ˆæ€§ (effectiveness) å’Œé²æ£’æ€§ (robustness) ç­‰å…³é”®ç»´åº¦è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPaladin åœ¨æ‰€æœ‰åœºæ™¯ä¸‹çš„æ£€æµ‹å‡†ç¡®ç‡å‡è¶…è¿‡ 90%ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚è¯¥å·¥ä½œä¸ºå¤§è§„æ¨¡æŠµå¾¡ LLM èµ‹èƒ½çš„ç½‘ç»œé’“é±¼æ”»å‡»æä¾›äº†ä¸€ç§å…¼å…·é«˜å‡†ç¡®ç‡ä¸ä½èµ„æºæ¶ˆè€—çš„æ–°å‹é˜²å¾¡æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "20 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.07287v1",
      "published_date": "2025-09-08 23:44:00 UTC",
      "updated_date": "2025-09-08 23:44:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:03.783606+00:00"
    },
    {
      "arxiv_id": "2509.07282v2",
      "title": "ALICE: An Interpretable Neural Architecture for Generalization in Substitution Ciphers",
      "title_zh": "ALICEï¼šä¸€ç§ç”¨äºæ›¿æ¢å¯†ç æ³›åŒ–é—®é¢˜çš„å¯è§£é‡Šç¥ç»æ¶æ„",
      "authors": [
        "Jeff Shen",
        "Lindsay M. Smith"
      ],
      "abstract": "We present cryptogram solving as an ideal testbed for studying neural network reasoning and generalization; models must decrypt text encoded with substitution ciphers, choosing from 26! possible mappings without explicit access to the cipher. We develop ALICE (an Architecture for Learning Interpretable Cryptogram dEcipherment), a simple encoder-only Transformer that sets a new state-of-the-art for both accuracy and speed on this decryption problem. Surprisingly, ALICE generalizes to unseen ciphers after training on only ${\\sim}1500$ unique ciphers, a minute fraction ($3.7 \\times 10^{-24}$) of the possible cipher space. To enhance interpretability, we introduce a novel bijective decoding head that explicitly models permutations via the Gumbel-Sinkhorn method, enabling direct extraction of learned cipher mappings. Through early exit and probing experiments, we reveal how ALICE progressively refines its predictions in a way that appears to mirror common human strategies -- early layers place greater emphasis on letter frequencies, while later layers form word-level structures. Our architectural innovations and analysis methods are applicable beyond cryptograms and offer new insights into neural network generalization and interpretability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ALICEï¼Œä¸€ç§ä¸“ä¸ºæ›¿ä»£å¯†ç  (substitution ciphers) è§£å¯†è®¾è®¡çš„å¯è§£é‡Šç¥ç»æ¶æ„ï¼Œæ—¨åœ¨æ¢è®¨ç¥ç»ç½‘ç»œçš„æ¨ç†ä¸æ³›åŒ–èƒ½åŠ›ã€‚ALICE é‡‡ç”¨ç®€æ´çš„ä»…ç¼–ç å™¨ Transformer (encoder-only Transformer) ç»“æ„ï¼Œå¹¶åœ¨è§£å¯†å‡†ç¡®ç‡å’Œé€Ÿåº¦ä¸Šè¾¾åˆ°äº†æ–°çš„ state-of-the-art æ°´å¹³ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ä»…è®­ç»ƒäº†çº¦ 1500 ä¸ªå”¯ä¸€å¯†ç ï¼ˆä»…å å¯èƒ½ç©ºé—´çš„æå°éƒ¨åˆ†ï¼‰åï¼ŒALICE å³å¯æ³›åŒ–è‡³æœªè§è¿‡çš„å¯†ç ã€‚ä¸ºäº†å¢å¼ºå¯è§£é‡Šæ€§ï¼Œç ”ç©¶è€…å¼•å…¥äº†ä¸€ç§æ–°å‹çš„åŒå°„è§£ç å¤´ (bijective decoding head)ï¼Œé€šè¿‡ Gumbel-Sinkhorn æ–¹æ³•æ˜¾å¼å»ºæ¨¡æ’åˆ—ï¼Œä»è€Œå¯ä»¥ç›´æ¥æå–å­¦ä¹ åˆ°çš„å¯†ç æ˜ å°„ã€‚é€šè¿‡æ—©æœŸé€€å‡º (early exit) å’Œæ¢æµ‹å®éªŒ (probing experiments)ï¼Œç ”ç©¶æ­ç¤ºäº† ALICE çš„é¢„æµ‹ç²¾ç‚¼è¿‡ç¨‹ç±»ä¼¼äºäººç±»ç­–ç•¥ï¼šæ—©æœŸå±‚ä¾§é‡å­—æ¯é¢‘ç‡ (letter frequencies)ï¼Œè€ŒåæœŸå±‚åˆ™æ„å»ºè¯çº§ç»“æ„ (word-level structures)ã€‚è¯¥æ¶æ„åˆ›æ–°å’Œåˆ†ææ–¹æ³•ä¸ä»…é€‚ç”¨äºå¯†ç ç ´è¯‘ï¼Œä¹Ÿä¸ºç¥ç»ç½‘ç»œçš„æ³›åŒ–ä¸å¯è§£é‡Šæ€§ç ”ç©¶æä¾›äº†æ–°çš„è§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Project page at https://jshen.net/alice. Added section on probing",
      "pdf_url": "https://arxiv.org/pdf/2509.07282v2",
      "published_date": "2025-09-08 23:33:53 UTC",
      "updated_date": "2025-09-25 01:15:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:08.462782+00:00"
    },
    {
      "arxiv_id": "2509.07277v1",
      "title": "Breast Cancer Detection in Thermographic Images via Diffusion-Based Augmentation and Nonlinear Feature Fusion",
      "title_zh": "åŸºäºæ‰©æ•£å¢å¼ºä¸éçº¿æ€§ç‰¹å¾èåˆçš„çƒ­çº¢å¤–å½±åƒä¹³è…ºç™Œæ£€æµ‹",
      "authors": [
        "Sepehr Salem",
        "M. Moein Esfahani",
        "Jingyu Liu",
        "Vince Calhoun"
      ],
      "abstract": "Data scarcity hinders deep learning for medical imaging. We propose a framework for breast cancer classification in thermograms that addresses this using a Diffusion Probabilistic Model (DPM) for data augmentation. Our DPM-based augmentation is shown to be superior to both traditional methods and a ProGAN baseline. The framework fuses deep features from a pre-trained ResNet-50 with handcrafted nonlinear features (e.g., Fractal Dimension) derived from U-Net segmented tumors. An XGBoost classifier trained on these fused features achieves 98.0\\% accuracy and 98.1\\% sensitivity. Ablation studies and statistical tests confirm that both the DPM augmentation and the nonlinear feature fusion are critical, statistically significant components of this success. This work validates the synergy between advanced generative models and interpretable features for creating highly accurate medical diagnostic tools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å½±åƒä¸­æ•°æ®ç¨€ç¼ºçš„éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºçº¢å¤–çƒ­åƒå›¾(thermograms)ä¹³è…ºç™Œåˆ†ç±»çš„åˆ›æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ‰©æ•£æ¦‚ç‡æ¨¡å‹(Diffusion Probabilistic Model, DPM)è¿›è¡Œæ•°æ®å¢å¼ºï¼Œæ•ˆæœæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•å’ŒProGANåŸºå‡†ã€‚ç ”ç©¶é€šè¿‡èåˆé¢„è®­ç»ƒResNet-50çš„æ·±åº¦ç‰¹å¾ä¸ä»U-Netåˆ†å‰²åŒºåŸŸæå–çš„æ‰‹å·¥éçº¿æ€§ç‰¹å¾ï¼ˆå¦‚Fractal Dimensionï¼‰ï¼Œå®ç°äº†å¤šç»´ç‰¹å¾è¡¨è¾¾ã€‚åˆ©ç”¨XGBooståˆ†ç±»å™¨ï¼Œè¯¥æ–¹æ¡ˆåœ¨å®éªŒä¸­å–å¾—äº†98.0%çš„å‡†ç¡®ç‡å’Œ98.1%çš„çµæ•åº¦ã€‚æ¶ˆèå®éªŒå’Œç»Ÿè®¡æ£€éªŒå‡è¯å®ï¼ŒDPMå¢å¼ºå’Œéçº¿æ€§ç‰¹å¾èåˆæ˜¯æå‡æ¨¡å‹æ€§èƒ½çš„æ ¸å¿ƒè¦ç´ ã€‚è¯¥å·¥ä½œæœ‰åŠ›è¯æ˜äº†å…ˆè¿›ç”Ÿæˆæ¨¡å‹ä¸å¯è§£é‡Šç‰¹å¾åœ¨å¼€å‘é«˜ç²¾åº¦åŒ»ç–—è¯Šæ–­å·¥å…·ä¸­çš„ååŒå¢æ•ˆä½œç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.07277v1",
      "published_date": "2025-09-08 23:19:38 UTC",
      "updated_date": "2025-09-08 23:19:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:12.179470+00:00"
    },
    {
      "arxiv_id": "2509.08015v2",
      "title": "CardioComposer: Leveraging Differentiable Geometry for Compositional Control of Anatomical Diffusion Models",
      "title_zh": "CardioComposerï¼šåˆ©ç”¨å¯å¾®å‡ ä½•å®ç°è§£å‰–æ‰©æ•£æ¨¡å‹çš„ç»„åˆå¼æ§åˆ¶",
      "authors": [
        "Karim Kadry",
        "Shoaib Goraya",
        "Ajay Manicka",
        "Abdalla Abdelwahed",
        "Naravich Chutisilp",
        "Farhad Nezami",
        "Elazer Edelman"
      ],
      "abstract": "Generative models of 3D cardiovascular anatomy can synthesize informative structures for clinical research and medical device evaluation, but face a trade-off between geometric controllability and realism. We propose CardioComposer: a programmable, inference-time framework for generating multi-class anatomical label maps based on interpretable ellipsoidal primitives. These primitives represent geometric attributes such as the size, shape, and position of discrete substructures. We specifically develop differentiable measurement functions based on voxel-wise geometric moments, enabling loss-based gradient guidance during diffusion model sampling. We demonstrate that these losses can constrain individual geometric attributes in a disentangled manner and provide compositional control over multiple substructures. Finally, we show that our method is compatible with a wide array of anatomical systems containing non-convex substructures, spanning cardiac, vascular, and skeletal organs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CardioComposerï¼Œè¿™æ˜¯ä¸€ä¸ªå¯ç¼–ç¨‹çš„æ¨ç†é˜¶æ®µ(inference-time)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³3Då¿ƒè¡€ç®¡è§£å‰–ç”Ÿæˆæ¨¡å‹åœ¨å‡ ä½•å¯æ§æ€§ä¸çœŸå®æ„Ÿä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¯è§£é‡Šçš„æ¤­åœ†åŸè¯­(ellipsoidal primitives)æ¥è¡¨ç¤ºå­ç»“æ„çš„å°ºå¯¸ã€å½¢çŠ¶å’Œä½ç½®ï¼Œè¿›è€Œç”Ÿæˆå¤šç±»è§£å‰–æ ‡ç­¾å›¾ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†åŸºäºä½“ç´ å‡ ä½•çŸ©(voxel-wise geometric moments)çš„å¯å¾®æµ‹é‡å‡½æ•°ï¼Œåœ¨æ‰©æ•£æ¨¡å‹(diffusion model)é‡‡æ ·è¿‡ç¨‹ä¸­å®ç°åŸºäºæŸå¤±çš„æ¢¯åº¦å¼•å¯¼(gradient guidance)ã€‚å®éªŒè¯æ˜ï¼Œè¿™äº›æŸå¤±å‡½æ•°èƒ½å¤Ÿä»¥è§£è€¦çš„æ–¹å¼çº¦æŸå•ä¸ªå‡ ä½•å±æ€§ï¼Œå¹¶å®ç°å¯¹å¤šä¸ªå­ç»“æ„çš„ç»„åˆæ§åˆ¶(compositional control)ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ï¼Œèƒ½å¤Ÿå…¼å®¹æ¶µç›–å¿ƒè„ã€è¡€ç®¡åŠéª¨éª¼å™¨å®˜åœ¨å†…çš„å¤šç§åŒ…å«éå‡¸å­ç»“æ„çš„è§£å‰–ç³»ç»Ÿã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 16 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.08015v2",
      "published_date": "2025-09-08 23:08:23 UTC",
      "updated_date": "2025-11-25 15:51:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:47.673943+00:00"
    },
    {
      "arxiv_id": "2509.07269v1",
      "title": "Datasets for Navigating Sensitive Topics in Recommendation Systems",
      "title_zh": "æ¨èç³»ç»Ÿä¸­æ•æ„Ÿè¯é¢˜åº”å¯¹æ•°æ®é›†",
      "authors": [
        "Amelia Kovacs",
        "Jerry Chee",
        "Kimia Kazemian",
        "Sarah Dean"
      ],
      "abstract": "Personalized AI systems, from recommendation systems to chatbots, are a prevalent method for distributing content to users based on their learned preferences. However, there is growing concern about the adverse effects of these systems, including their potential tendency to expose users to sensitive or harmful material, negatively impacting overall well-being. To address this concern quantitatively, it is necessary to create datasets with relevant sensitivity labels for content, enabling researchers to evaluate personalized systems beyond mere engagement metrics. To this end, we introduce two novel datasets that include a taxonomy of sensitivity labels alongside user-content ratings: one that integrates MovieLens rating data with content warnings from the Does the Dog Die? community ratings website, and another that combines fan-fiction interaction data and user-generated warnings from Archive of Our Own.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ä¸ªæ€§åŒ–äººå·¥æ™ºèƒ½ï¼ˆPersonalized AIï¼‰ç³»ç»Ÿå¯èƒ½å‘ç”¨æˆ·æ¨é€æ•æ„Ÿæˆ–æœ‰å®³å†…å®¹å¹¶å½±å“å¿ƒç†å¥åº·çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸¤å¥—åŒ…å«æ•æ„Ÿæ€§æ ‡ç­¾ï¼ˆsensitivity labelsï¼‰çš„æ–°å‹æ•°æ®é›†ã€‚ç¬¬ä¸€å¥—æ•°æ®é›†å°† MovieLens çš„è¯„åˆ†æ•°æ®ä¸æ¥è‡ªç¤¾åŒºè¯„çº§ç½‘ç«™ Does the Dog Die? çš„å†…å®¹è­¦å‘Šï¼ˆcontent warningsï¼‰ç›¸ç»“åˆï¼Œä¸ºç”µå½±æ¨èæä¾›äº†ä¸°å¯Œçš„æ•æ„Ÿæ€§ç»´åº¦ã€‚ç¬¬äºŒå¥—æ•°æ®é›†åˆ™æ•´åˆäº† Archive of Our Own çš„åŒäººå°è¯´äº’åŠ¨æ•°æ®åŠç”¨æˆ·ç”Ÿæˆçš„è­¦å‘Šä¿¡æ¯ï¼Œæ•æ‰äº†å¤æ‚çš„æ–‡æœ¬æ•æ„Ÿè¯é¢˜ã€‚è¿™äº›æ•°æ®é›†é€šè¿‡å»ºç«‹æ•æ„Ÿæ€§æ ‡ç­¾åˆ†ç±»ä½“ç³»ï¼ˆtaxonomy of sensitivity labelsï¼‰ï¼Œä½¿å¾—ç ”ç©¶è€…èƒ½å¤Ÿåœ¨ä¼ ç»Ÿçš„å‚ä¸åº¦æŒ‡æ ‡ï¼ˆengagement metricsï¼‰ä¹‹å¤–ï¼Œå¯¹æ¨èç®—æ³•çš„å®‰å…¨æ€§è¿›è¡Œå®šé‡è¯„ä¼°ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘æ›´å…·è´£ä»»æ„Ÿã€èƒ½å¤Ÿè¯†åˆ«å¹¶å¯¼èˆªæ•æ„Ÿè¯é¢˜çš„æ¨èç³»ç»Ÿæä¾›äº†é‡è¦çš„åŸºç¡€èµ„æºæ”¯æŒã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Companion Proceedings of the ACM on Web Conference 2025, 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07269v1",
      "published_date": "2025-09-08 22:58:17 UTC",
      "updated_date": "2025-09-08 22:58:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:19.562181+00:00"
    },
    {
      "arxiv_id": "2509.07260v4",
      "title": "HealthSLM-Bench: Benchmarking Small Language Models for Mobile and Wearable Healthcare Monitoring",
      "title_zh": "HealthSLM-Benchï¼šé¢å‘ç§»åŠ¨ä¸å¯ç©¿æˆ´å¥åº·ç›‘æµ‹çš„å°è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Xin Wang",
        "Ting Dang",
        "Xinyu Zhang",
        "Vassilis Kostakos",
        "Michael J. Witbrock",
        "Hong Jia"
      ],
      "abstract": "Mobile and wearable healthcare monitoring play a vital role in facilitating timely interventions, managing chronic health conditions, and ultimately improving individuals' quality of life. Previous studies on large language models (LLMs) have highlighted their impressive generalization abilities and effectiveness in healthcare prediction tasks. However, most LLM-based healthcare solutions are cloud-based, which raises significant privacy concerns and results in increased memory usage and latency. To address these challenges, there is growing interest in compact models, Small Language Models (SLMs), which are lightweight and designed to run locally and efficiently on mobile and wearable devices. Nevertheless, how well these models perform in healthcare prediction remains largely unexplored. We systematically evaluated SLMs on health prediction tasks using zero-shot, few-shot, and instruction fine-tuning approaches, and deployed the best performing fine-tuned SLMs on mobile devices to evaluate their real-world efficiency and predictive performance in practical healthcare scenarios. Our results show that SLMs can achieve performance comparable to LLMs while offering substantial gains in efficiency and privacy. However, challenges remain, particularly in handling class imbalance and few-shot scenarios. These findings highlight SLMs, though imperfect in their current form, as a promising solution for next-generation, privacy-preserving healthcare monitoring.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HealthSLM-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°Small Language Models (SLMs)åœ¨ç§»åŠ¨ä¸å¯ç©¿æˆ´åŒ»ç–—ç›‘æµ‹ä»»åŠ¡ä¸­è¡¨ç°çš„åŸºå‡†æ¡†æ¶ã€‚ä½œè€…ç³»ç»Ÿåœ°æµ‹è¯•äº†SLMsåœ¨zero-shotã€few-shotåŠinstruction fine-tuningæ–¹æ³•ä¸‹çš„æ€§èƒ½ï¼Œå¹¶å°†å…¶éƒ¨ç½²äºç§»åŠ¨è®¾å¤‡ä»¥éªŒè¯å…¶åœ¨å®é™…åŒ»ç–—åœºæ™¯ä¸­çš„é¢„æµ‹è¡¨ç°ä¸è¿è¡Œæ•ˆç‡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒSLMsåœ¨æä¾›ä¸å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ç›¸å½“æ€§èƒ½çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ•°æ®éšç§æ€§å¹¶é™ä½å»¶è¿Ÿã€‚å°½ç®¡SLMsåœ¨å¤„ç†ç±»åˆ«ä¸å¹³è¡¡(class imbalance)å’Œå°‘æ•°æ ·æœ¬åœºæ™¯(few-shot scenarios)æ—¶ä»é¢ä¸´æŒ‘æˆ˜ï¼Œä½†è¯¥ç ”ç©¶è¯æ˜äº†SLMsæ˜¯å®ç°ä¸‹ä¸€ä»£éšç§ä¿æŠ¤åŒ»ç–—ç›‘æ§æ–¹æ¡ˆçš„é‡è¦æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 tables, 6 figures. Accepted at NeurIPS 2025 Workshop on GenAI4Health",
      "pdf_url": "https://arxiv.org/pdf/2509.07260v4",
      "published_date": "2025-09-08 22:36:19 UTC",
      "updated_date": "2025-09-30 12:04:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:20.271122+00:00"
    },
    {
      "arxiv_id": "2509.07253v1",
      "title": "Benchmarking Information Retrieval Models on Complex Retrieval Tasks",
      "title_zh": "é’ˆå¯¹å¤æ‚æ£€ç´¢ä»»åŠ¡çš„ä¿¡æ¯æ£€ç´¢æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Julian Killingback",
        "Hamed Zamani"
      ],
      "abstract": "Large language models (LLMs) are incredible and versatile tools for text-based tasks that have enabled countless, previously unimaginable, applications. Retrieval models, in contrast, have not yet seen such capable general-purpose models emerge. To achieve this goal, retrieval models must be able to perform complex retrieval tasks, where queries contain multiple parts, constraints, or requirements in natural language. These tasks represent a natural progression from the simple, single-aspect queries that are used in the vast majority of existing, commonly used evaluation sets. Complex queries naturally arise as people expect search systems to handle more specific and often ambitious information requests, as is demonstrated by how people use LLM-based information systems. Despite the growing desire for retrieval models to expand their capabilities in complex retrieval tasks, there exist limited resources to assess the ability of retrieval models on a comprehensive set of diverse complex tasks. The few resources that do exist feature a limited scope and often lack realistic settings making it hard to know the true capabilities of retrieval models on complex real-world retrieval tasks. To address this shortcoming and spur innovation in next-generation retrieval models, we construct a diverse and realistic set of complex retrieval tasks and benchmark a representative set of state-of-the-art retrieval models. Additionally, we explore the impact of LLM-based query expansion and rewriting on retrieval quality. Our results show that even the best models struggle to produce high-quality retrieval results with the highest average nDCG@10 of only 0.346 and R@100 of only 0.587 across all tasks. Although LLM augmentation can help weaker models, the strongest model has decreased performance across all metrics with all rewriting techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤æ‚æ£€ç´¢ä»»åŠ¡(Complex Retrieval Tasks)ä¸­è¯„ä¼°ä¿¡æ¯æ£€ç´¢(Information Retrieval)æ¨¡å‹è¡¨ç°çš„é‡è¦æ€§ï¼ŒæŒ‡å‡ºå½“å‰ä¸»æµè¯„ä¼°é›†å¤šå±€é™äºå•ä¸€æ–¹é¢ç®€å•æŸ¥è¯¢ï¼Œéš¾ä»¥åæ˜ çœŸå®ä¸–ç•Œä¸­åŒ…å«å¤šé‡çº¦æŸçš„è‡ªç„¶è¯­è¨€éœ€æ±‚ã€‚ä¸ºäº†å¡«è¡¥è¯„ä¼°èµ„æºçš„åŒ®ä¹å¹¶æ¨åŠ¨æŠ€æœ¯åˆ›æ–°ï¼Œä½œè€…æ„å»ºäº†ä¸€å¥—æ¶µç›–å¤šæ ·åŒ–ä¸”çœŸå®çš„å¤æ‚æ£€ç´¢ä»»åŠ¡é›†ï¼Œå¹¶å¯¹å¤šæ¬¾æœ€å…ˆè¿›(State-of-the-Art)çš„æ£€ç´¢æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶è¿˜æ·±å…¥æ¢è®¨äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„æŸ¥è¯¢æ‰©å±•å’Œé‡å†™æŠ€æœ¯å¯¹æ£€ç´¢è´¨é‡çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯è¡¨ç°æœ€å¥½çš„æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­ä¹Ÿé¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œå…¶å¹³å‡nDCG@10ä»…ä¸º0.346ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶LLMå¢å¼ºæŠ€æœ¯èƒ½æå‡è¾ƒå¼±æ¨¡å‹çš„è¡¨ç°ï¼Œä½†å´ä¼šé™ä½æœ€å¼ºæ¨¡å‹åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šçš„æ€§èƒ½ï¼Œæ­ç¤ºäº†ç°æœ‰çš„é€šç”¨æ£€ç´¢æ¨¡å‹åœ¨å¤„ç†å¤æ‚ä¿¡æ¯è¯·æ±‚æ—¶çš„å±€é™æ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07253v1",
      "published_date": "2025-09-08 22:11:10 UTC",
      "updated_date": "2025-09-08 22:11:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:23.359169+00:00"
    },
    {
      "arxiv_id": "2509.12235v2",
      "title": "RL Fine-Tuning Heals OOD Forgetting in SFT",
      "title_zh": "RL å¾®è°ƒä¿®å¤ SFT ä¸­çš„åˆ†å¸ƒå¤–é—å¿˜",
      "authors": [
        "Hangzhan Jin",
        "Sitao Luan",
        "Sicheng Lyu",
        "Guillaume Rabusseau",
        "Reihaneh Rabbany",
        "Doina Precup",
        "Mohammad Hamdaqa"
      ],
      "abstract": "The two-stage fine-tuning paradigm of Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has empirically shown better reasoning performance than one-stage SFT for the post-training of Large Language Models (LLMs). However, the evolution and mechanism behind the synergy of SFT and RL are still under-explored and inconclusive. In our study, we find the well-known claim \"SFT memorizes, RL generalizes\" is over-simplified, and discover that: (1) OOD performance peaks at the early stage of SFT and then declines (OOD forgetting), the best SFT checkpoint cannot be captured by training/test loss; (2) the subsequent RL stage does not generate fundamentally better OOD capability, instead it plays an \\textbf{OOD restoration} role, recovering the lost reasoning ability during SFT; (3) The recovery ability has boundaries, \\ie{} \\textbf{if SFT trains for too short or too long, RL cannot recover the lost OOD ability;} (4) To uncover the underlying mechanisms behind the forgetting and restoration process, we employ SVD analysis on parameter matrices, manually edit them, and observe their impacts on model performance. Unlike the common belief that the shift of model capacity mainly results from the changes of singular values, we find that they are actually quite stable throughout fine-tuning. Instead, the OOD behavior strongly correlates with the \\textbf{rotation of singular vectors}. Our findings re-identify the roles of SFT and RL in the two-stage fine-tuning and discover the rotation of singular vectors as the key mechanism. %reversing the rotations induced by SFT, which shows recovery from forgetting, whereas imposing the SFT parameter directions onto a RL-tuned model results in performance degradation. Code is available at https://github.com/xiaodanguoguo/RL_Heals_SFT",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä¸å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸¤é˜¶æ®µå¾®è°ƒä¸­çš„ååŒæœºåˆ¶ã€‚ç ”ç©¶å‘ç°ï¼ŒSFT è¿‡ç¨‹ä¸­å­˜åœ¨åˆ†å¸ƒå¤–ï¼ˆOODï¼‰é—å¿˜ç°è±¡ï¼Œå³ OOD æ€§èƒ½åœ¨ SFT æ—©æœŸè¾¾åˆ°å³°å€¼åä¾¿å¼€å§‹ä¸‹é™ï¼Œä¸”æœ€ä¼˜ checkpoint æ— æ³•é€šè¿‡ä¼ ç»Ÿçš„è®­ç»ƒæˆ–æµ‹è¯•æŸå¤±æ•æ‰ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒRL é˜¶æ®µå¹¶æœªåˆ›é€ å…¨æ–°çš„ OOD èƒ½åŠ›ï¼Œè€Œæ˜¯å‘æŒ¥äº† OOD restorationï¼ˆOOD ä¿®å¤ï¼‰çš„ä½œç”¨ï¼Œæ¢å¤äº† SFT æœŸé—´ä¸¢å¤±çš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿™ç§æ¢å¤èƒ½åŠ›å…·æœ‰è¾¹ç•Œï¼Œè‹¥ SFT é˜¶æ®µè®­ç»ƒä¸è¶³æˆ–è¿‡åº¦ï¼ŒRL å°†æ— æ³•ä¿®å¤ä¸¢å¤±çš„ OOD èƒ½åŠ›ã€‚é€šè¿‡å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰åˆ†æï¼Œç ”ç©¶æ­ç¤ºäº†æ¨¡å‹æ€§èƒ½çš„å˜åŒ–å¹¶éæºäºå¥‡å¼‚å€¼çš„æ”¹å˜ï¼Œè€Œæ˜¯ä¸å¥‡å¼‚å‘é‡çš„æ—‹è½¬ï¼ˆrotation of singular vectorsï¼‰é«˜åº¦ç›¸å…³ã€‚è¯¥ç ”ç©¶é‡æ–°å®šä¹‰äº† SFT å’Œ RL åœ¨å¾®è°ƒé˜¶æ®µçš„è§’è‰²ï¼Œå¹¶å‘ç°äº†å¥‡å¼‚å‘é‡æ—‹è½¬è¿™ä¸€å…³é”®åº•å±‚æœºåˆ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 18 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.12235v2",
      "published_date": "2025-09-08 21:40:41 UTC",
      "updated_date": "2025-11-01 13:50:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:26.156299+00:00"
    },
    {
      "arxiv_id": "2509.07238v1",
      "title": "Systematic Optimization of Open Source Large Language Models for Mathematical Reasoning",
      "title_zh": "å¼€æºå¤§è¯­è¨€æ¨¡å‹æ•°å­¦æ¨ç†èƒ½åŠ›çš„ç³»ç»ŸåŒ–ä¼˜åŒ–",
      "authors": [
        "Pranav Pawar",
        "Dhwaj Jain",
        "Varun Gupta",
        "Kaustav Dedhia",
        "Dashrath Kale",
        "Sudhir Dhekane"
      ],
      "abstract": "This paper presents a practical investigation into fine-tuning model parameters for mathematical reasoning tasks through experimenting with various configurations including randomness control, reasoning depth, and sampling strategies, careful tuning demonstrates substantial improvements in efficiency as well as performance. A holistically optimized framework is introduced for five state-of-the-art models on mathematical reasoning tasks, exhibiting significant performance boosts while maintaining solution correctness. Through systematic parameter optimization across Qwen2.5-72B, Llama-3.1-70B, DeepSeek-V3, Mixtral-8x22B, and Yi-Lightning, consistent efficiency gains are demonstrated with 100% optimization success rate. The methodology achieves an average 29.4% reduction in computational cost and 23.9% improvement in inference speed across all tested models. This framework systematically searches parameter spaces including temperature (0.1-0.5), reasoning steps (4-12), planning periods (1-4), and nucleus sampling (0.85-0.98), determining optimal configurations through testing on mathematical reasoning benchmarks. Critical findings show that lower temperature regimes (0.1-0.4) and reduced reasoning steps (4-6) consistently enhance efficiency without compromising accuracy. DeepSeek-V3 achieves the highest accuracy at 98%, while Mixtral-8x22B delivers the most cost-effective performance at 361.5 tokens per accurate response. Key contributions include: (1) the first comprehensive optimization study for five diverse SOTA models in mathematical reasoning, (2) a standardized production-oriented parameter optimization framework, (3) discovery of universal optimization trends applicable across model architectures, and (4) production-ready configurations with extensive performance characterization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼€æºå¤§è¯­è¨€æ¨¡å‹(Large Language Models)åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­çš„å‚æ•°ä¼˜åŒ–è¿›è¡Œäº†ç³»ç»Ÿæ€§è°ƒæŸ¥ï¼Œé€šè¿‡æ¢ç´¢éšæœºæ€§æ§åˆ¶ã€æ¨ç†æ·±åº¦å’Œé‡‡æ ·ç­–ç•¥ç­‰é…ç½®ï¼Œæå‡ºäº†ä¸€ä¸ªå…¨é¢çš„ä¼˜åŒ–æ¡†æ¶ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ Qwen2.5-72Bã€Llama-3.1-70Bã€DeepSeek-V3ã€Mixtral-8x22B å’Œ Yi-Lightning äº”ç§å…ˆè¿›æ¨¡å‹ä¸Šè¿›è¡Œäº†å‚æ•°ç©ºé—´æœç´¢ï¼Œæ¶µç›–äº†æ¸©åº¦(Temperature)ã€æ¨ç†æ­¥éª¤(Reasoning steps)å’Œæ ¸é‡‡æ ·(Nucleus sampling)ç­‰å…³é”®ç»´åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒè§£é¢˜æ­£ç¡®æ€§çš„åŒæ—¶ï¼Œä½¿è®¡ç®—æˆæœ¬å¹³å‡é™ä½äº† 29.4%ï¼Œæ¨ç†é€Ÿåº¦æå‡äº† 23.9%ã€‚å…³é”®å‘ç°æŒ‡å‡ºï¼Œè¾ƒä½çš„æ¸©åº¦åŒºé—´(0.1-0.4)å’Œå‡å°‘çš„æ¨ç†æ­¥éª¤(4-6)èƒ½æŒç»­å¢å¼ºæ•ˆç‡ã€‚å…¶ä¸­ DeepSeek-V3 è¾¾åˆ°äº† 98% çš„æœ€é«˜å‡†ç¡®ç‡ï¼Œè€Œ Mixtral-8x22B åœ¨æˆæœ¬æ•ˆç›Šæ–¹é¢è¡¨ç°æœ€ä¸ºçªå‡ºã€‚è¯¥å·¥ä½œä¸ä»…æ­ç¤ºäº†è·¨æ¨¡å‹æ¶æ„çš„é€šç”¨ä¼˜åŒ–è¶‹åŠ¿ï¼Œè¿˜ä¸ºå·¥ä¸šçº§åº”ç”¨æä¾›äº†æ ‡å‡†åŒ–ä¸”ç”Ÿäº§å°±ç»ªçš„å‚æ•°é…ç½®å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07238v1",
      "published_date": "2025-09-08 21:31:43 UTC",
      "updated_date": "2025-09-08 21:31:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:10:31.975894+00:00"
    },
    {
      "arxiv_id": "2509.07236v1",
      "title": "Breaking the Conventional Forward-Backward Tie in Neural Networks: Activation Functions",
      "title_zh": "çªç ´ç¥ç»ç½‘ç»œä¸­ä¼ ç»Ÿçš„æ­£å‘-åå‘å…³è”ï¼šæ¿€æ´»å‡½æ•°",
      "authors": [
        "Luigi Troiano",
        "Francesco Gissi",
        "Vincenzo Benedetto",
        "Genny Tortora"
      ],
      "abstract": "Gradient-based neural network training traditionally enforces symmetry between forward and backward propagation, requiring activation functions to be differentiable (or sub-differentiable) and strictly monotonic in certain regions to prevent flat gradient areas. This symmetry, linking forward activations closely to backward gradients, significantly restricts the selection of activation functions, particularly excluding those with substantial flat or non-differentiable regions. In this paper, we challenge this assumption through mathematical analysis, demonstrating that precise gradient magnitudes derived from activation functions are largely redundant, provided the gradient direction is preserved. Empirical experiments conducted on foundational architectures - such as Multi-Layer Perceptrons (MLPs), Convolutional Neural Networks (CNNs), and Binary Neural Networks (BNNs) - confirm that relaxing forward-backward symmetry and substituting traditional gradients with simpler or stochastic alternatives does not impair learning and may even enhance training stability and efficiency. We explicitly demonstrate that neural networks with flat or non-differentiable activation functions, such as the Heaviside step function, can be effectively trained, thereby expanding design flexibility and computational efficiency. Further empirical validation with more complex architectures remains a valuable direction for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‘æˆ˜äº†ç¥ç»ç½‘ç»œè®­ç»ƒä¸­å‰å‘ä¼ æ’­ä¸åå‘ä¼ æ’­å¿…é¡»ä¿æŒå¯¹ç§°çš„ä¼ ç»Ÿå‡è®¾ï¼ŒæŒ‡å‡ºæ¿€æ´»å‡½æ•°ä¸å¿…ä¸ºäº†é¿å…æ¢¯åº¦å¹³å¦åŒºåŸŸè€Œä¸¥æ ¼æ»¡è¶³å¯å¾®æ€§æˆ–å•è°ƒæ€§ã€‚é€šè¿‡æ•°å­¦åˆ†æï¼Œä½œè€…è¯æ˜äº†æ¿€æ´»å‡½æ•°äº§ç”Ÿçš„ç²¾ç¡®æ¢¯åº¦å¹…å€¼(gradient magnitudes)åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯å†—ä½™çš„ï¼Œå…³é”®åœ¨äºä¿æŒæ¢¯åº¦çš„æ–¹å‘(gradient direction)ã€‚åœ¨Multi-Layer Perceptrons (MLPs)ã€Convolutional Neural Networks (CNNs)å’ŒBinary Neural Networks (BNNs)ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ”¾å®½å‰å‘-åå‘å¯¹ç§°æ€§å¹¶ä½¿ç”¨ç®€å•æˆ–éšæœºæ¢¯åº¦æ›¿ä»£æ–¹æ¡ˆï¼Œèƒ½å¤Ÿä¿æŒç”šè‡³æå‡è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚ç ”ç©¶é‡ç‚¹è¯æ˜äº†Heaviside step functionç­‰ä¸å¯å¾®æˆ–å…·æœ‰å¤§é¢ç§¯å¹³å¦åŒºåŸŸçš„å‡½æ•°äº¦å¯è¢«æœ‰æ•ˆè®­ç»ƒï¼Œæå¤§åœ°æ‰©å±•äº†æ¿€æ´»å‡½æ•°çš„è®¾è®¡ç©ºé—´ã€‚è¿™ä¸€å‘ç°ä¸ä»…æå‡äº†è®¡ç®—æ•ˆç‡ï¼Œä¹Ÿä¸ºæœªæ¥åœ¨æ›´å¤æ‚æ¶æ„ä¸­æ‰“ç ´ä¼ ç»Ÿæ¢¯åº¦çº¦æŸæä¾›äº†ç†è®ºä¾æ®ä¸å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "30 pages, 8 figures, 14 tables, in press, available online 11 August 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07236v1",
      "published_date": "2025-09-08 21:30:00 UTC",
      "updated_date": "2025-09-08 21:30:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:05.868389+00:00"
    },
    {
      "arxiv_id": "2509.07226v1",
      "title": "A transformer-based generative model for planetary systems",
      "title_zh": "åŸºäº Transformer çš„è¡Œæ˜Ÿç³»ç»Ÿç”Ÿæˆå¼æ¨¡å‹",
      "authors": [
        "Yann Alibert",
        "Jeanne Davoult",
        "Sara Marques"
      ],
      "abstract": "Numerical calculations of planetary system formation are very demanding in terms of computing power. These synthetic planetary systems can however provide access to correlations, as predicted in a given numerical framework, between the properties of planets in the same system. Such correlations can, in return, be used in order to guide and prioritize observational campaigns aiming at discovering some types of planets, as Earth-like planets. Our goal is to develop a generative model which is capable of capturing correlations and statistical relationships between planets in the same system. Such a model, trained on the Bern model, offers the possibility to generate large number of synthetic planetary systems with little computational cost, that can be used, for example, to guide observational campaigns. Our generative model is based on the transformer architecture which is well-known to efficiently capture correlations in sequences and is at the basis of all modern Large Language Models. To assess the validity of the generative model, we perform visual and statistical comparisons, as well as a machine learning driven tests. Finally, as a use case example, we consider the TOI-469 system, in which we aim at predicting the possible properties of planets c and d, based on the properties of planet b (the first that has been detected). We show using different comparison methods that the properties of systems generated by our model are very similar to the ones of the systems computed directly by the Bern model. We also show in the case of the TOI-469 system, that using the generative model allows to predict the properties of planets not yet observed, based on the properties of the already observed planet. We provide our model to the community on our website www.ai4exoplanets.com.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ç§åŸºäº Transformer æ¶æ„çš„ç”Ÿæˆæ¨¡å‹ï¼Œæ—¨åœ¨é«˜æ•ˆæ•æ‰è¡Œæ˜Ÿç³»ç»Ÿä¸­è¡Œæ˜Ÿé—´çš„ç»Ÿè®¡ç›¸å…³æ€§å’Œç»Ÿè®¡å…³ç³»ã€‚é‰´äºä¼ ç»Ÿçš„è¡Œæ˜Ÿç³»ç»Ÿå½¢æˆæ•°å€¼æ¨¡æ‹Ÿè®¡ç®—å¼€é”€å·¨å¤§ï¼Œè¯¥æ¨¡å‹é€šè¿‡åœ¨ Bern model æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿä»¥æä½çš„è®¡ç®—æˆæœ¬ç”Ÿæˆå¤§é‡åˆæˆè¡Œæ˜Ÿç³»ç»Ÿï¼Œä»è€Œä¸ºå¯»æ‰¾ç±»åœ°è¡Œæ˜Ÿç­‰è§‚æµ‹æ´»åŠ¨æä¾›ä¼˜å…ˆæŒ‡å¯¼ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡è§†è§‰å¯¹æ¯”ã€ç»Ÿè®¡åˆ†æä»¥åŠæœºå™¨å­¦ä¹ é©±åŠ¨çš„æµ‹è¯•ï¼ŒéªŒè¯äº†è¯¥ç”Ÿæˆæ¨¡å‹äº§å‡ºçš„ç³»ç»Ÿä¸åŸå§‹ Bern model è®¡ç®—ç»“æœå…·æœ‰é«˜åº¦ç›¸ä¼¼æ€§ã€‚åœ¨ TOI-469 ç³»ç»Ÿçš„å®é™…åº”ç”¨ä¸­ï¼Œè¯¥æ¨¡å‹æˆåŠŸæ ¹æ®å·²è§‚æµ‹è¡Œæ˜Ÿçš„å±æ€§é¢„æµ‹äº†å°šæœªå‘ç°è¡Œæ˜Ÿçš„æ½œåœ¨ç‰¹å¾ã€‚è¯¥ç ”ç©¶ä¸ºç³»å¤–è¡Œæ˜Ÿç ”ç©¶æä¾›äº†é«˜æ•ˆçš„æ¨¡æ‹Ÿå·¥å…·ï¼Œå¹¶å·²é€šè¿‡ ai4exoplanets.com ç½‘ç«™å‘å­¦æœ¯ç¤¾åŒºå¼€æ”¾ã€‚",
      "categories": [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.EP",
      "comment": "Accepted in A&A",
      "pdf_url": "https://arxiv.org/pdf/2509.07226v1",
      "published_date": "2025-09-08 21:09:14 UTC",
      "updated_date": "2025-09-08 21:09:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:03.780705+00:00"
    },
    {
      "arxiv_id": "2509.07222v1",
      "title": "Explaining How Quantization Disparately Skews a Model",
      "title_zh": "è§£æé‡åŒ–å¦‚ä½•å¯¼è‡´æ¨¡å‹çš„å·®å¼‚åŒ–åå·®",
      "authors": [
        "Abhimanyu Bellam",
        "Jung-Eun Kim"
      ],
      "abstract": "Post Training Quantization (PTQ) is widely adopted due to its high compression capacity and speed with minimal impact on accuracy. However, we observed that disparate impacts are exacerbated by quantization, especially for minority groups. Our analysis explains that in the course of quantization there is a chain of factors attributed to a disparate impact across groups during forward and backward passes. We explore how the changes in weights and activations induced by quantization cause cascaded impacts in the network, resulting in logits with lower variance, increased loss, and compromised group accuracies. We extend our study to verify the influence of these impacts on group gradient norms and eigenvalues of the Hessian matrix, providing insights into the state of the network from an optimization point of view. To mitigate these effects, we propose integrating mixed precision Quantization Aware Training (QAT) with dataset sampling methods and weighted loss functions, therefore providing fair deployment of quantized neural networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è®­ç»ƒåé‡åŒ–(Post Training Quantization, PTQ)å¦‚ä½•åŠ å‰§æ¨¡å‹å¯¹å°‘æ•°ç¾¤ä½“çš„ä¸å…¬å¹³å½±å“ï¼Œå¹¶æ·±å…¥åˆ†æäº†é‡åŒ–æ­§è§†ç°è±¡èƒŒåçš„æˆå› ã€‚ä½œè€…å‘ç°é‡åŒ–å¼•èµ·çš„æƒé‡å’Œæ¿€æ´»å€¼å˜åŒ–ä¼šåœ¨ç½‘ç»œä¸­äº§ç”Ÿçº§è”æ•ˆåº”ï¼Œå¯¼è‡´é€»è¾‘å€¼(logits)æ–¹å·®é™ä½å’ŒæŸå¤±å¢åŠ ï¼Œä»è€ŒæŸå®³ç‰¹å®šç¾¤ä½“çš„å‡†ç¡®ç‡ã€‚ç ”ç©¶è¿›ä¸€æ­¥ä»ä¼˜åŒ–è§†è§’å‡ºå‘ï¼ŒéªŒè¯äº†è¿™äº›å˜åŒ–å¯¹ç¾¤ä½“æ¢¯åº¦èŒƒæ•°(group gradient norms)å’Œæµ·æ£®çŸ©é˜µ(Hessian matrix)ç‰¹å¾å€¼çš„å½±å“ï¼Œæ­ç¤ºäº†é‡åŒ–å¯¹ç½‘ç»œçŠ¶æ€çš„æ·±å±‚å¹²é¢„ã€‚ä¸ºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶æå‡ºå°†æ··åˆç²¾åº¦é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(mixed precision Quantization Aware Training, QAT)ä¸æ•°æ®é›†é‡‡æ ·åŠåŠ æƒæŸå¤±å‡½æ•°ç›¸ç»“åˆã€‚è¯¥æ–¹æ¡ˆæ—¨åœ¨ç¡®ä¿é‡åŒ–ç¥ç»ç½‘ç»œåœ¨å®é™…éƒ¨ç½²ä¸­çš„å…¬å¹³æ€§ï¼Œä¸ºæ„å»ºé«˜æ•ˆä¸”å…¼é¡¾å…¬å¹³æ€§çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æä¾›äº†ç†è®ºæ”¯æ’‘å’Œæ”¹è¿›æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07222v1",
      "published_date": "2025-09-08 21:04:16 UTC",
      "updated_date": "2025-09-08 21:04:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:06.360042+00:00"
    },
    {
      "arxiv_id": "2509.07220v1",
      "title": "OmniAcc: Personalized Accessibility Assistant Using Generative AI",
      "title_zh": "OmniAccï¼šåŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„ä¸ªæ€§åŒ–æ— éšœç¢åŠ©æ‰‹",
      "authors": [
        "Siddhant Karki",
        "Ethan Han",
        "Nadim Mahmud",
        "Suman Bhunia",
        "John Femiani",
        "Vaskar Raychoudhury"
      ],
      "abstract": "Individuals with ambulatory disabilities often encounter significant barriers when navigating urban environments due to the lack of accessible information and tools. This paper presents OmniAcc, an AI-powered interactive navigation system that utilizes GPT-4, satellite imagery, and OpenStreetMap data to identify, classify, and map wheelchair-accessible features such as ramps and crosswalks in the built environment. OmniAcc offers personalized route planning, real-time hands-free navigation, and instant query responses regarding physical accessibility. By using zero-shot learning and customized prompts, the system ensures precise detection of accessibility features, while supporting validation through structured workflows. This paper introduces OmniAcc and explores its potential to assist urban planners and mobility-aid users, demonstrated through a case study on crosswalk detection. With a crosswalk detection accuracy of 97.5%, OmniAcc highlights the transformative potential of AI in improving navigation and fostering more inclusive urban spaces.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† OmniAccï¼Œè¿™æ˜¯ä¸€æ¬¾åˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)é©±åŠ¨çš„ä¸ªæ€§åŒ–äº¤äº’å¼å¯¼èˆªç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³è¡ŒåŠ¨ä¸ä¾¿äººå£«åœ¨åŸå¸‚ç¯å¢ƒä¸­é¢ä¸´çš„æ— éšœç¢ä¿¡æ¯åŒ®ä¹é—®é¢˜ã€‚ç³»ç»Ÿé›†æˆäº† GPT-4ã€å«æ˜Ÿå›¾åƒ(satellite imagery)å’Œ OpenStreetMap æ•°æ®ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«ã€åˆ†ç±»å¹¶æ ‡æ³¨æ–œå¡ä¸äººè¡Œæ¨ªé“ç­‰æ— éšœç¢ç‰¹å¾ã€‚é€šè¿‡é‡‡ç”¨é›¶æ ·æœ¬å­¦ä¹ (zero-shot learning)å’Œå®šåˆ¶åŒ–çš„æç¤ºè¯(prompts)ï¼ŒOmniAcc å®ç°äº†ç²¾ç¡®çš„ç‰¹å¾æ£€æµ‹ï¼Œå¹¶æ”¯æŒä¸ªæ€§åŒ–è·¯å¾„è§„åˆ’ä¸å®æ—¶å…æå¯¼èˆªã€‚æ¡ˆä¾‹ç ”ç©¶æ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨äººè¡Œæ¨ªé“æ£€æµ‹æ–¹é¢çš„å‡†ç¡®ç‡è¾¾åˆ° 97.5%ï¼ŒéªŒè¯äº†å…¶åœ¨ååŠ©åŸå¸‚è§„åˆ’è€…å’Œè¡ŒåŠ¨éšœç¢ç”¨æˆ·æ–¹é¢çš„åº”ç”¨æ½œåŠ›ã€‚è¿™ä¸€æˆæœå‡¸æ˜¾äº†äººå·¥æ™ºèƒ½åœ¨æ”¹å–„æ— éšœç¢å¯¼èˆªä»¥åŠæ„å»ºæ›´å…·åŒ…å®¹æ€§çš„åŸå¸‚ç©ºé—´ä¸­çš„å˜é©æ€§ä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 Pages, 9 Figures, Published in the 1st Workshop on AI for Urban Planning, AAAI 2025 Workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.07220v1",
      "published_date": "2025-09-08 21:03:48 UTC",
      "updated_date": "2025-09-08 21:03:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:09.709752+00:00"
    },
    {
      "arxiv_id": "2509.07213v1",
      "title": "XBusNet: Text-Guided Breast Ultrasound Segmentation via Multimodal Vision-Language Learning",
      "title_zh": "XBusNetï¼šåŸºäºå¤šæ¨¡æ€è§†è§‰-è¯­è¨€å­¦ä¹ çš„æ–‡æœ¬å¼•å¯¼ä¹³è…ºè¶…å£°åˆ†å‰²",
      "authors": [
        "Raja Mallina",
        "Bryar Shareef"
      ],
      "abstract": "Background: Precise breast ultrasound (BUS) segmentation supports reliable measurement, quantitative analysis, and downstream classification, yet remains difficult for small or low-contrast lesions with fuzzy margins and speckle noise. Text prompts can add clinical context, but directly applying weakly localized text-image cues (e.g., CAM/CLIP-derived signals) tends to produce coarse, blob-like responses that smear boundaries unless additional mechanisms recover fine edges. Methods: We propose XBusNet, a novel dual-prompt, dual-branch multimodal model that combines image features with clinically grounded text. A global pathway based on a CLIP Vision Transformer encodes whole-image semantics conditioned on lesion size and location, while a local U-Net pathway emphasizes precise boundaries and is modulated by prompts that describe shape, margin, and Breast Imaging Reporting and Data System (BI-RADS) terms. Prompts are assembled automatically from structured metadata, requiring no manual clicks. We evaluate on the Breast Lesions USG (BLU) dataset using five-fold cross-validation. Primary metrics are Dice and Intersection over Union (IoU); we also conduct size-stratified analyses and ablations to assess the roles of the global and local paths and the text-driven modulation. Results: XBusNet achieves state-of-the-art performance on BLU, with mean Dice of 0.8765 and IoU of 0.8149, outperforming six strong baselines. Small lesions show the largest gains, with fewer missed regions and fewer spurious activations. Ablation studies show complementary contributions of global context, local boundary modeling, and prompt-based modulation. Conclusions: A dual-prompt, dual-branch multimodal design that merges global semantics with local precision yields accurate BUS segmentation masks and improves robustness for small, low-contrast lesions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†XBusNetï¼Œä¸€ç§ç»“åˆä¸´åºŠæ–‡æœ¬æŒ‡å¯¼çš„è·¨æ¨¡æ€åŒåˆ†æ”¯ä¹³è…ºè¶…å£°ï¼ˆBUSï¼‰åˆ†å‰²æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å°ç—…ç¶æˆ–ä½å¯¹æ¯”åº¦ç—…ç¶åœ¨åˆ†å‰²ä¸­é¢ä¸´çš„è¾¹ç¼˜æ¨¡ç³Šå’Œæ–‘ç‚¹å™ªå£°é—®é¢˜ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸€ä¸ªåŸºäºCLIP Vision Transformerçš„å…¨å±€è·¯å¾„ç”¨äºæ•æ‰ç—…ç¶ä½ç½®ä¸å¤§å°çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä»¥åŠä¸€ä¸ªå±€éƒ¨U-Netè·¯å¾„ä¸“é—¨ç”¨äºç²¾ç¡®æå–è¾¹ç•Œç‰¹å¾ã€‚é€šè¿‡è‡ªåŠ¨æ•´åˆåŒ…å«å½¢çŠ¶ã€è¾¹ç¼˜ç‰¹å¾åŠBreast Imaging Reporting and Data System (BI-RADS)æœ¯è¯­çš„ç»“æ„åŒ–å…ƒæ•°æ®ä½œä¸ºæ–‡æœ¬æç¤ºï¼Œæ¨¡å‹å®ç°äº†å¯¹å›¾åƒç‰¹å¾çš„é«˜æ•ˆè°ƒåˆ¶ã€‚åœ¨Breast Lesions USG (BLU)æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒXBusNetå–å¾—äº†0.8765çš„Diceå€¼å’Œ0.8149çš„IoUå€¼ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºå…­ç§ä¸»æµåŸºçº¿æ¨¡å‹ã€‚å°¤å…¶åœ¨å¤„ç†å°ç—…ç¶æ—¶ï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼Œæœ‰æ•ˆå‡å°‘äº†åŒºåŸŸæ¼æ£€å’Œä¼ªæ¿€æ´»ç°è±¡ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†å…¨å±€ä¸Šä¸‹æ–‡è¯­ä¹‰ä¸å±€éƒ¨ç²¾ç»†åŒ–å»ºæ¨¡åœ¨æå‡è¶…å£°å›¾åƒåˆ†å‰²ç²¾åº¦æ–¹é¢çš„äº’è¡¥ä½œç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 3 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.07213v1",
      "published_date": "2025-09-08 20:45:55 UTC",
      "updated_date": "2025-09-08 20:45:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:12.978398+00:00"
    },
    {
      "arxiv_id": "2509.07211v1",
      "title": "A multi-strategy improved gazelle optimization algorithm for solving numerical optimization and engineering applications",
      "title_zh": "æ±‚è§£æ•°å€¼ä¼˜åŒ–ä¸å·¥ç¨‹åº”ç”¨çš„å¤šç­–ç•¥æ”¹è¿›çªç¾šä¼˜åŒ–ç®—æ³•",
      "authors": [
        "Qi Diao",
        "Chengyue Xie",
        "Yuchen Yin",
        "Hoileong Lee",
        "Haolong Yang"
      ],
      "abstract": "Aiming at the shortcomings of the gazelle optimization algorithm, such as the imbalance between exploration and exploitation and the insufficient information exchange within the population, this paper proposes a multi-strategy improved gazelle optimization algorithm (MSIGOA). To address these issues, MSIGOA proposes an iteration-based updating framework that switches between exploitation and exploration according to the optimization process, which effectively enhances the balance between local exploitation and global exploration in the optimization process and improves the convergence speed. Two adaptive parameter tuning strategies improve the applicability of the algorithm and promote a smoother optimization process. The dominant population-based restart strategy enhances the algorithms ability to escape from local optima and avoid its premature convergence. These enhancements significantly improve the exploration and exploitation capabilities of MSIGOA, bringing superior convergence and efficiency in dealing with complex problems. In this paper, the parameter sensitivity, strategy effectiveness, convergence and stability of the proposed method are evaluated on two benchmark test sets including CEC2017 and CEC2022. Test results and statistical tests show that MSIGOA outperforms basic GOA and other advanced algorithms. On the CEC2017 and CEC2022 test sets, the proportion of functions where MSIGOA is not worse than GOA is 92.2% and 83.3%, respectively, and the proportion of functions where MSIGOA is not worse than other algorithms is 88.57% and 87.5%, respectively. Finally, the extensibility of MSIGAO is further verified by several engineering design optimization problems.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹Gazelle Optimization Algorithm (GOA)åœ¨æ¢ç´¢(Exploration)ä¸å¼€å‘(Exploitation)å¹³è¡¡æ€§åŠç§ç¾¤ä¿¡æ¯äº¤æ¢æ–¹é¢çš„ç¼ºé™·ï¼Œæå‡ºäº†å¤šç­–ç•¥æ”¹è¿›çš„å°ç¾šç¾Šä¼˜åŒ–ç®—æ³•(MSIGOA)ã€‚MSIGOAæ„å»ºäº†ä¸€ä¸ªåŸºäºè¿­ä»£çš„æ›´æ–°æ¡†æ¶ï¼Œæ ¹æ®ä¼˜åŒ–è¿›ç¨‹åŠ¨æ€åˆ‡æ¢å¼€å‘ä¸æ¢ç´¢æ¨¡å¼ï¼Œæ˜¾è‘—å¢å¼ºäº†å…¨å±€æœç´¢èƒ½åŠ›å¹¶åŠ å¿«äº†æ”¶æ•›é€Ÿåº¦ã€‚ç®—æ³•é€šè¿‡å¼•å…¥ä¸¤ç§è‡ªé€‚åº”å‚æ•°è°ƒèŠ‚ç­–ç•¥æå‡äº†é€‚ç”¨æ€§ï¼Œå¹¶åˆ©ç”¨åŸºäºä¼˜åŠ¿ç§ç¾¤çš„é‡å¯ç­–ç•¥å¸®åŠ©æ¨¡å‹æœ‰æ•ˆè·³å‡ºå±€éƒ¨æœ€ä¼˜(Local Optima)ä»¥é¿å…è¿‡æ—©æ”¶æ•›ã€‚åœ¨CEC2017å’ŒCEC2022åŸºå‡†æµ‹è¯•é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMSIGOAçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºåŸå§‹GOAåŠå…¶ä»–å…ˆè¿›ç®—æ³•ï¼Œåœ¨ç»å¤§å¤šæ•°æµ‹è¯•å‡½æ•°ä¸­å±•ç°å‡ºæé«˜çš„ç«äº‰åŠ›å’Œç¨³å®šæ€§ã€‚å¤šé¡¹å·¥ç¨‹è®¾è®¡ä¼˜åŒ–é—®é¢˜çš„åº”ç”¨ç»“æœè¿›ä¸€æ­¥éªŒè¯äº†MSIGOAåœ¨è§£å†³å®é™…å¤æ‚å·¥ç¨‹åº”ç”¨ä¸­çš„æ‰©å±•æ€§ä¸é«˜æ•ˆæ€§ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.NE",
      "comment": "This is the author's preprint of the article published in Cluster Computing (Springer): Diao, Q., Xie, C., Yin, Y. et al. A multi-strategy improved gazelle optimization algorithm for solving numerical optimization and engineering applications. Cluster Comput 28, 643 (2025). The final authenticated version is available online at SpringerLink",
      "pdf_url": "https://arxiv.org/pdf/2509.07211v1",
      "published_date": "2025-09-08 20:44:15 UTC",
      "updated_date": "2025-09-08 20:44:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:21.870799+00:00"
    },
    {
      "arxiv_id": "2509.07209v2",
      "title": "BlendedNet: A Blended Wing Body Aircraft Dataset and Surrogate Model for Aerodynamic Predictions",
      "title_zh": "BlendedNetï¼šç”¨äºæ°”åŠ¨é¢„æµ‹çš„ç¿¼èº«èåˆé£è¡Œå™¨æ•°æ®é›†ä¸ä»£ç†æ¨¡å‹",
      "authors": [
        "Nicholas Sung",
        "Steven Spreizer",
        "Mohamed Elrefaie",
        "Kaira Samuel",
        "Matthew C. Jones",
        "Faez Ahmed"
      ],
      "abstract": "BlendedNet is a publicly available aerodynamic dataset of 999 blended wing body (BWB) geometries. Each geometry is simulated across about nine flight conditions, yielding 8830 converged RANS cases with the Spalart-Allmaras model and 9 to 14 million cells per case. The dataset is generated by sampling geometric design parameters and flight conditions, and includes detailed pointwise surface quantities needed to study lift and drag. We also introduce an end-to-end surrogate framework for pointwise aerodynamic prediction. The pipeline first uses a permutation-invariant PointNet regressor to predict geometric parameters from sampled surface point clouds, then conditions a Feature-wise Linear Modulation (FiLM) network on the predicted parameters and flight conditions to predict pointwise coefficients Cp, Cfx, and Cfz. Experiments show low errors in surface predictions across diverse BWBs. BlendedNet addresses data scarcity for unconventional configurations and enables research on data-driven surrogate modeling for aerodynamic design.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†BlendedNetï¼Œä¸€ä¸ªåŒ…å«999ç§ç¿¼èº«èåˆï¼ˆBlended Wing Body, BWBï¼‰å‡ ä½•å½¢çŠ¶çš„å…¬å¼€ç©ºæ°”åŠ¨åŠ›å­¦æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æ¶µç›–äº†8830ä¸ªé€šè¿‡Spalart-Allmarasæ¨¡å‹æ¨¡æ‹Ÿçš„æ”¶æ•›RANSæ¡ˆä¾‹ï¼Œè¯¦ç»†è®°å½•äº†ç”¨äºç ”ç©¶å‡åŠ›å’Œé˜»åŠ›çš„é€ç‚¹è¡¨é¢ç‰©ç†é‡ã€‚ä¸ºäº†å®ç°é€ç‚¹æ°”åŠ¨åŠ›é¢„æµ‹ï¼Œç ”ç©¶è€…è¿˜æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„ä»£ç†æ¨¡å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨PointNetå›å½’å™¨ä»è¡¨é¢ç‚¹äº‘ä¸­é¢„æµ‹å‡ ä½•å‚æ•°ï¼Œå¹¶ç»“åˆFiLMç½‘ç»œä»¥åŠé£è¡Œæ¡ä»¶æ¥é¢„æµ‹Cpã€Cfxå’ŒCfzç­‰ç³»æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šç§ä¸åŒBWBæ„å‹ä¸Šçš„è¡¨é¢é¢„æµ‹ä¸­å‡è¡¨ç°å‡ºæä½çš„è¯¯å·®ã€‚BlendedNetçš„å‘å¸ƒæœ‰æ•ˆè§£å†³äº†éå¸¸è§„é£è¡Œå™¨æ„å‹æ•°æ®åŒ®ä¹çš„é—®é¢˜ï¼Œä¸ºåŸºäºæ•°æ®é©±åŠ¨çš„ç©ºæ°”åŠ¨åŠ›å­¦è®¾è®¡ä»£ç†æ¨¡å‹ç ”ç©¶æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ASME IDETC/CIE 2025 (DETC2025-168977). Dataset availability: BlendedNet dataset is openly available at Harvard Dataverse (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VJT9EP)",
      "pdf_url": "https://arxiv.org/pdf/2509.07209v2",
      "published_date": "2025-09-08 20:43:14 UTC",
      "updated_date": "2025-09-10 17:02:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:27.478952+00:00"
    },
    {
      "arxiv_id": "2509.07208v1",
      "title": "A Hybrid CNN-LSTM Deep Learning Model for Intrusion Detection in Smart Grid",
      "title_zh": "é¢å‘æ™ºèƒ½ç”µç½‘å…¥ä¾µæ£€æµ‹çš„æ··åˆ CNN-LSTM æ·±åº¦å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Abdulhakim Alsaiari",
        "Mohammad Ilyas"
      ],
      "abstract": "The evolution of the traditional power grid into the \"smart grid\" has resulted in a fundamental shift in energy management, which allows the integration of renewable energy sources with modern communication technology. However, this interconnection has increased smart grids' vulnerability to attackers, which might result in privacy breaches, operational interruptions, and massive outages. The SCADA-based smart grid protocols are critical for real-time data collection and control, but they are vulnerable to attacks like unauthorized access and denial of service (DoS). This research proposes a hybrid deep learning-based Intrusion Detection System (IDS) intended to improve the cybersecurity of smart grids. The suggested model takes advantage of Convolutional Neural Networks' (CNN) feature extraction capabilities as well as Long Short-Term Memory (LSTM) networks' temporal pattern recognition skills. DNP3 and IEC104 intrusion detection datasets are employed to train and test our CNN-LSTM model to recognize and classify the potential cyber threats. Compared to other deep learning approaches, the results demonstrate considerable improvements in accuracy, precision, recall, and F1-score, with a detection accuracy of 99.70%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Smart Grid åœ¨æ¼”è¿›è¿‡ç¨‹ä¸­é¢ä¸´çš„éšç§æ³„éœ²å’Œè¿è¡Œä¸­æ–­ç­‰å®‰å…¨å¨èƒï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ·±åº¦å­¦ä¹ çš„å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ (Intrusion Detection System, IDS)ã€‚è¯¥æ¨¡å‹ç»“åˆäº† Convolutional Neural Networks (CNN) çš„ç‰¹å¾æå–èƒ½åŠ›ä¸ Long Short-Term Memory (LSTM) çš„æ—¶é—´æ¨¡å¼è¯†åˆ«èƒ½åŠ›ï¼Œæ—¨åœ¨å¢å¼º DNP3 å’Œ IEC104 ç­‰å…³é”® SCADA åè®®çš„é˜²å¾¡æ°´å¹³ã€‚é€šè¿‡åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒä¸æµ‹è¯•ï¼Œè¯¥ CNN-LSTM æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¹¶åˆ†ç±»åŒ…æ‹¬ Denial of Service (DoS) åœ¨å†…çš„æ½œåœ¨ç½‘ç»œå¨èƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ Accuracyã€Precisionã€Recall å’Œ F1-score ç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºå…¶ä»–æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œæœ€ç»ˆå®ç°äº† 99.70% çš„æ£€æµ‹å‡†ç¡®ç‡ï¼Œä¸ºæ™ºèƒ½ç”µç½‘çš„ç½‘ç»œå®‰å…¨æä¾›äº†é«˜æ•ˆçš„ä¿éšœæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07208v1",
      "published_date": "2025-09-08 20:41:31 UTC",
      "updated_date": "2025-09-08 20:41:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:26.077250+00:00"
    },
    {
      "arxiv_id": "2509.07193v1",
      "title": "Evaluation of Machine Learning Reconstruction Techniques for Accelerated Brain MRI Scans",
      "title_zh": "åŠ é€Ÿè„‘éƒ¨ MRI æ‰«æçš„æœºå™¨å­¦ä¹ é‡å»ºæŠ€æœ¯è¯„ä¼°",
      "authors": [
        "Jonathan I. Mandel",
        "Shivaprakash Hiremath",
        "Hedyeh Keshtgar",
        "Timothy Scholl",
        "Sadegh Raeisi"
      ],
      "abstract": "This retrospective-prospective study evaluated whether a deep learning-based MRI reconstruction algorithm can preserve diagnostic quality in brain MRI scans accelerated up to fourfold, using both public and prospective clinical data. The study included 18 healthy volunteers (scans acquired at 3T, January 2024-March 2025), as well as selected fastMRI public datasets with diverse pathologies. Phase-encoding-undersampled 2D/3D T1, T2, and FLAIR sequences were reconstructed with DeepFoqus-Accelerate and compared with standard-of-care (SOC). Three board-certified neuroradiologists and two MRI technologists independently reviewed 36 paired SOC/AI reconstructions from both datasets using a 5-point Likert scale, while quantitative similarity was assessed for 408 scans and 1224 datasets using Structural Similarity Index (SSIM), Peak Signal-to-Noise Ratio (PSNR), and Haar wavelet-based Perceptual Similarity Index (HaarPSI). No AI-reconstructed scan scored below 3 (minimally acceptable), and 95% scored $\\geq 4$. Mean SSIM was 0.95 $\\pm$ 0.03 (90% cases >0.90), PSNR >41.0 dB, and HaarPSI >0.94. Inter-rater agreement was slight to moderate. Rare artifacts did not affect diagnostic interpretation. These findings demonstrate that DeepFoqus-Accelerate enables robust fourfold brain MRI acceleration with 75% reduced scan time, while preserving diagnostic image quality and supporting improved workflow efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åŸºäºæ·±åº¦å­¦ä¹ (Deep Learning)çš„MRIé‡å»ºç®—æ³•åœ¨åŠ é€Ÿè„‘éƒ¨MRIæ‰«æä¸­ä¿æŒè¯Šæ–­è´¨é‡çš„èƒ½åŠ›ï¼Œé‡ç‚¹é’ˆå¯¹åŠ é€Ÿé«˜è¾¾å››å€çš„æ‰«æåœºæ™¯ã€‚ç ”ç©¶é‡‡ç”¨DeepFoqus-Accelerateç®—æ³•å¯¹2D/3D T1ã€T2å’ŒFLAIRåºåˆ—è¿›è¡Œé‡å»ºï¼Œå¹¶å°†å…¶ä¸æ ‡å‡†æŠ¤ç†(Standard-of-Care, SOC)æ–¹æ¡ˆè¿›è¡Œäº†å¯¹æ¯”ã€‚é€šè¿‡ç¥ç»æ”¾å°„ç§‘åŒ»å¸ˆçš„è§†è§‰è¯„åˆ†(5-point Likert scale)ä»¥åŠSSIMã€PSNRå’ŒHaarPSIç­‰å®šé‡æŒ‡æ ‡åˆ†æï¼Œç»“æœæ˜¾ç¤º95%çš„AIé‡å»ºå›¾åƒè¯„åˆ†è¾¾åˆ°4åˆ†æˆ–ä»¥ä¸Šï¼Œä¸”å¹³å‡SSIMé«˜è¾¾0.95ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå¶å°”å‡ºç°çš„ç¨€æœ‰ä¼ªå½±å¹¶ä¸å½±å“ä¸´åºŠè¯Šæ–­çš„è§£é‡Šã€‚è¯¥ç ”ç©¶è¯æ˜äº†DeepFoqus-Accelerateèƒ½å¤Ÿåœ¨å‡å°‘75%æ‰«ææ—¶é—´çš„åŒæ—¶ï¼Œç¡®ä¿ç¨³å¥çš„å›¾åƒè´¨é‡å¹¶æ˜¾è‘—æå‡ä¸´åºŠå·¥ä½œæµæ•ˆç‡ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "This work has been submitted to Radiology: Artificial Intelligence for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2509.07193v1",
      "published_date": "2025-09-08 20:20:24 UTC",
      "updated_date": "2025-09-08 20:20:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:27.679343+00:00"
    },
    {
      "arxiv_id": "2509.07188v3",
      "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
      "title_zh": "DischargeSimï¼šé¢å‘å‡ºé™¢ç¯èŠ‚æ•™è‚²æ€§åŒ»æ‚£æ²Ÿé€šçš„æ¨¡æ‹ŸåŸºå‡†",
      "authors": [
        "Zonghai Yao",
        "Michael Sun",
        "Won Seok Jang",
        "Sunjae Kwon",
        "Soie Kwon",
        "Hong Yu"
      ],
      "abstract": "Discharge communication is a critical yet underexplored component of patient care, where the goal shifts from diagnosis to education. While recent large language model (LLM) benchmarks emphasize in-visit diagnostic reasoning, they fail to evaluate models' ability to support patients after the visit. We introduce DischargeSim, a novel benchmark that evaluates LLMs on their ability to act as personalized discharge educators. DischargeSim simulates post-visit, multi-turn conversations between LLM-driven DoctorAgents and PatientAgents with diverse psychosocial profiles (e.g., health literacy, education, emotion). Interactions are structured across six clinically grounded discharge topics and assessed along three axes: (1) dialogue quality via automatic and LLM-as-judge evaluation, (2) personalized document generation including free-text summaries and structured AHRQ checklists, and (3) patient comprehension through a downstream multiple-choice exam. Experiments across 18 LLMs reveal significant gaps in discharge education capability, with performance varying widely across patient profiles. Notably, model size does not always yield better education outcomes, highlighting trade-offs in strategy use and content prioritization. DischargeSim offers a first step toward benchmarking LLMs in post-visit clinical education and promoting equitable, personalized patient support.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† DischargeSimï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å‡ºé™¢æŒ‡å¯¼ä¸­ä½œä¸ºä¸ªæ€§åŒ–æ•™è‚²è€…èƒ½åŠ›çš„åˆ›æ–°åŸºå‡†æµ‹è¯•ï¼Œå¡«è¡¥äº†ç°æœ‰æ¨¡å‹è¯„ä¼°ä¾§é‡äºè¯Šä¸­è¯Šæ–­æ¨ç†è€Œå¿½è§†è¯Šåæ‚£è€…æ”¯æŒçš„ç©ºç™½ã€‚DischargeSim é€šè¿‡æ¨¡æ‹Ÿé©±åŠ¨çš„ DoctorAgents ä¸å…·æœ‰ä¸åŒç¤¾ä¼šå¿ƒç†æ¦‚å†µï¼ˆå¦‚å¥åº·ç´ å…»ã€æ•™è‚²ç¨‹åº¦å’Œæƒ…ç»ªçŠ¶å†µï¼‰çš„ PatientAgents ä¹‹é—´çš„å¤šè½®å¯¹è¯ï¼Œåœ¨å…­ä¸ªä¸´åºŠå‡ºé™¢ä¸»é¢˜ä¸‹å±•å¼€äº’åŠ¨ã€‚è¯¥åŸºå‡†ä»å¯¹è¯è´¨é‡ã€ä¸ªæ€§åŒ–æ–‡æ¡£ç”Ÿæˆï¼ˆåŒ…æ‹¬è‡ªç”±æ–‡æœ¬æ‘˜è¦å’Œ AHRQ æ ¸å¯¹è¡¨ï¼‰ä»¥åŠé€šè¿‡ä¸‹æ¸¸è€ƒè¯•æµ‹é‡çš„æ‚£è€…ç†è§£åº¦ä¸‰ä¸ªç»´åº¦è¿›è¡Œå…¨é¢è¯„ä¼°ã€‚å¯¹ 18 ä¸ªä¸»æµ LLMs çš„å®éªŒæ­ç¤ºäº†æ¨¡å‹åœ¨å‡ºé™¢æ•™è‚²èƒ½åŠ›ä¸Šçš„æ˜¾è‘—å·®è·ï¼Œä¸”æ€§èƒ½éšæ‚£è€…èƒŒæ™¯ç‰¹å¾å‘ˆç°å¤§å¹…æ³¢åŠ¨ã€‚ç ”ç©¶å‘ç°æ¨¡å‹è§„æ¨¡çš„å¢åŠ å¹¶ä¸å¿…ç„¶æå‡æ•™è‚²æˆæ•ˆï¼Œå‡¸æ˜¾äº†åœ¨æ²Ÿé€šç­–ç•¥å’Œå†…å®¹ä¼˜å…ˆçº§å¤„ç†ä¸Šçš„æƒè¡¡ï¼Œä¸ºæ¨åŠ¨å…¬å¹³ä¸”ä¸ªæ€§åŒ–çš„è¯Šåä¸´åºŠæ•™è‚²æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Equal contribution for the first two authors. To appear in the proceedings of the Main Conference on Empirical Methods in Natural Language Processing (EMNLP) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07188v3",
      "published_date": "2025-09-08 20:07:30 UTC",
      "updated_date": "2025-09-19 02:20:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:31.082870+00:00"
    },
    {
      "arxiv_id": "2509.08012v1",
      "title": "Validation of a CT-brain analysis tool for measuring global cortical atrophy in older patient cohorts",
      "title_zh": "é’ˆå¯¹è€å¹´æ‚£è€…ç¾¤ä½“å…¨è„‘çš®è´¨èç¼©æµ‹é‡çš„CTè„‘å½±åƒåˆ†æå·¥å…·éªŒè¯",
      "authors": [
        "Sukhdeep Bal",
        "Emma Colbourne",
        "Jasmine Gan",
        "Ludovica Griffanti",
        "Taylor Hanayik",
        "Nele Demeyere",
        "Jim Davies",
        "Sarah T Pendlebury",
        "Mark Jenkinson"
      ],
      "abstract": "Quantification of brain atrophy currently requires visual rating scales which are time consuming and automated brain image analysis is warranted. We validated our automated deep learning (DL) tool measuring the Global Cerebral Atrophy (GCA) score against trained human raters, and associations with age and cognitive impairment, in representative older (>65 years) patients. CT-brain scans were obtained from patients in acute medicine (ORCHARD-EPR), acute stroke (OCS studies) and a legacy sample. Scans were divided in a 60/20/20 ratio for training, optimisation and testing. CT-images were assessed by two trained raters (rater-1=864 scans, rater-2=20 scans). Agreement between DL tool-predicted GCA scores (range 0-39) and the visual ratings was evaluated using mean absolute error (MAE) and Cohen's weighted kappa. Among 864 scans (ORCHARD-EPR=578, OCS=200, legacy scans=86), MAE between the DL tool and rater-1 GCA scores was 3.2 overall, 3.1 for ORCHARD-EPR, 3.3 for OCS and 2.6 for the legacy scans and half had DL-predicted GCA error between -2 and 2. Inter-rater agreement was Kappa=0.45 between the DL-tool and rater-1, and 0.41 between the tool and rater- 2 whereas it was lower at 0.28 for rater-1 and rater-2. There was no difference in GCA scores from the DL-tool and the two raters (one-way ANOVA, p=0.35) or in mean GCA scores between the DL-tool and rater-1 (paired t-test, t=-0.43, p=0.66), the tool and rater-2 (t=1.35, p=0.18) or between rater-1 and rater-2 (t=0.99, p=0.32). DL-tool GCA scores correlated with age and cognitive scores (both p<0.001). Our DL CT-brain analysis tool measured GCA score accurately and without user input in real-world scans acquired from older patients. Our tool will enable extraction of standardised quantitative measures of atrophy at scale for use in health data research and will act as proof-of-concept towards a point-of-care clinically approved tool.",
      "tldr_zh": "è¯¥ç ”ç©¶éªŒè¯äº†ä¸€é¡¹ç”¨äºæµ‹é‡è€å¹´ç¾¤ä½“å…¨è„‘çš®è´¨èç¼©(Global Cerebral Atrophy, GCA)å¾—åˆ†çš„è‡ªåŠ¨åŒ–æ·±åº¦å­¦ä¹ (Deep Learning, DL)å·¥å…·ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨864ä»½æ¥è‡ªæ€¥æ€§åŒ»å­¦å’Œè„‘å’ä¸­ç­‰çœŸå®åœºæ™¯çš„CTè„‘éƒ¨æ‰«ææ•°æ®ï¼Œå°†DLå·¥å…·ç”Ÿæˆçš„è¯„åˆ†ä¸ä¸“ä¸šè¯„åˆ†è€…çš„è§†è§‰è¯„åˆ†è¿›è¡Œäº†å¯¹æ¯”éªŒè¯ã€‚ç»“æœæ˜¾ç¤ºï¼Œè¯¥å·¥å…·ä¸äººç±»è¯„åˆ†è€…ä¹‹é—´çš„å¹³å‡ç»å¯¹è¯¯å·®(Mean Absolute Error, MAE)æ•´ä½“ä¸º3.2ï¼Œä¸”å…¶ä¸€è‡´æ€§(Kappaç³»æ•°ä¸º0.45å’Œ0.41)ä¼˜äºè¯„åˆ†è€…ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼ŒDLå·¥å…·æµ‹å¾—çš„GCAå¾—åˆ†ä¸æ‚£è€…å¹´é¾„åŠè®¤çŸ¥èƒ½åŠ›è¯„åˆ†å…·æœ‰æ˜¾è‘—ç›¸å…³æ€§ã€‚è¯¥å·¥å…·å®ç°äº†åœ¨æ— éœ€äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹ç²¾å‡†æå–æ ‡å‡†åŒ–èç¼©å®šé‡æŒ‡æ ‡ï¼Œä¸ºå¤§è§„æ¨¡å¥åº·æ•°æ®ç ”ç©¶å’Œä¸´åºŠå³æ—¶æ£€æµ‹æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.08012v1",
      "published_date": "2025-09-08 20:04:35 UTC",
      "updated_date": "2025-09-08 20:04:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:43.842344+00:00"
    },
    {
      "arxiv_id": "2509.07170v2",
      "title": "That's So FETCH: Fashioning Ensemble Techniques for LLM Classification in Civil Legal Intake and Referral",
      "title_zh": "That's So FETCHï¼šæ°‘äº‹æ³•å¾‹å—ç†ä¸åˆ†æµä¸­çš„å¤§è¯­è¨€æ¨¡å‹åˆ†ç±»é›†æˆæŠ€æœ¯",
      "authors": [
        "Quinten Steenhuis"
      ],
      "abstract": "Each year millions of people seek help for their legal problems by calling a legal aid program hotline, walking into a legal aid office, or using a lawyer referral service. The first step to match them to the right help is to identify the legal problem the applicant is experiencing. Misdirection has consequences. Applicants may miss a deadline, experience physical abuse, lose housing or lose custody of children while waiting to connect to the right legal help. We introduce and evaluate the FETCH classifier for legal issue classification and describe two methods for improving accuracy: a hybrid LLM/ML ensemble classification method, and the automatic generation of follow-up questions to enrich the initial problem narrative. We employ a novel data set of 419 real-world queries to a nonprofit lawyer referral service. Ultimately, we show classification accuracy (hits@2) of 97.37\\% using a mix of inexpensive models, exceeding the performance of the current state-of-the-art GPT-5 model. Our approach shows promise in significantly reducing the cost of guiding users of the legal system to the right resource for their problem while achieving high accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FETCH åˆ†ç±»å™¨ï¼Œæ—¨åœ¨ä¼˜åŒ–æ°‘äº‹æ³•å¾‹å’¨è¯¢ä¸è½¬ä»‹ï¼ˆCivil Legal Intake and Referralï¼‰ä¸­çš„æ³•å¾‹é—®é¢˜åˆ†ç±»ï¼Œä»¥å‡å°‘å› å¼•å¯¼é”™è¯¯å¯¼è‡´çš„æ³•å¾‹å»¶è¯¯æˆ–æŸå¤±ã€‚ç ”ç©¶å¼•å…¥äº†ä¸¤ç§æå‡åˆ†ç±»ç²¾åº¦çš„æ–¹æ³•ï¼šä¸€ç§æ˜¯ç»“åˆå¤§è¯­è¨€æ¨¡å‹(LLM)ä¸æœºå™¨å­¦ä¹ (ML)çš„æ··åˆé›†æˆ(Ensemble)åˆ†ç±»ï¼Œå¦ä¸€ç§æ˜¯é€šè¿‡è‡ªåŠ¨ç”Ÿæˆè¿½é—®(Follow-up questions)æ¥ä¸°å¯Œåˆå§‹é—®é¢˜çš„èƒŒæ™¯ä¿¡æ¯ã€‚é€šè¿‡å¯¹ 419 æ¡çœŸå®ä¸–ç•Œçš„æ³•å¾‹å’¨è¯¢æ•°æ®è¿›è¡Œè¯„ä¼°ï¼ŒFETCH åœ¨ä½¿ç”¨ä½æˆæœ¬æ¨¡å‹ç»„åˆçš„æƒ…å†µä¸‹å®ç°äº† 97.37% çš„ hits@2 å‡†ç¡®ç‡ï¼Œæ€§èƒ½è¶…è¿‡äº† GPT-5 æ¨¡å‹ã€‚è¯¥æ–¹æ³•åœ¨æ˜¾è‘—é™ä½æ³•å¾‹ç³»ç»Ÿå¯¼æµæˆæœ¬çš„åŒæ—¶ï¼Œå±•ç°äº†æé«˜çš„èµ„æºåŒ¹é…å‡†ç¡®æ€§ï¼Œä¸ºè‡ªåŠ¨åŒ–æ³•å¾‹æ´åŠ©æä¾›äº†é«˜æ•ˆä¸”ç»æµçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Submission to JURIX 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07170v2",
      "published_date": "2025-09-08 19:34:57 UTC",
      "updated_date": "2025-09-10 03:09:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:50.440876+00:00"
    },
    {
      "arxiv_id": "2509.07159v1",
      "title": "PaVeRL-SQL: Text-to-SQL via Partial-Match Rewards and Verbal Reinforcement Learning",
      "title_zh": "PaVeRL-SQLï¼šåŸºäºéƒ¨åˆ†åŒ¹é…å¥–åŠ±ä¸è¯­è¨€å¼ºåŒ–å­¦ä¹ çš„æ–‡æœ¬è½¬ SQL",
      "authors": [
        "Heng Hao",
        "Wenjun Hu",
        "Oxana Verkholyak",
        "Davoud Ataee Tarzanagh",
        "Baruch Gutow",
        "Sima Didari",
        "Masoud Faraki",
        "Hankyu Moon",
        "Seungjai Min"
      ],
      "abstract": "Text-to-SQL models allow users to interact with a database more easily by generating executable SQL statements from natural-language questions. Despite recent successes on simpler databases and questions, current Text-to-SQL methods still suffer from low execution accuracy on industry-scale databases and complex questions involving domain-specific business logic. We present \\emph{PaVeRL-SQL}, a framework that combines \\emph{Partial-Match Rewards} and \\emph{Verbal Reinforcement Learning} to drive self-improvement in reasoning language models (RLMs) for Text-to-SQL. To handle practical use cases, we adopt two pipelines: (1) a newly designed in-context learning framework with group self-evaluation (verbal-RL), using capable open- and closed-source large language models (LLMs) as backbones; and (2) a chain-of-thought (CoT) RL pipeline with a small backbone model (OmniSQL-7B) trained with a specially designed reward function and two-stage RL. These pipelines achieve state-of-the-art (SOTA) results on popular Text-to-SQL benchmarks -- Spider, Spider 2.0, and BIRD. For the industrial-level Spider2.0-SQLite benchmark, the verbal-RL pipeline achieves an execution accuracy 7.4\\% higher than SOTA, and the CoT pipeline is 1.4\\% higher. RL training with mixed SQL dialects yields strong, threefold gains, particularly for dialects with limited training data. Overall, \\emph{PaVeRL-SQL} delivers reliable, SOTA Text-to-SQL under realistic industrial constraints. The code is available at https://github.com/PaVeRL-SQL/PaVeRL-SQL.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PaVeRL-SQLæ¡†æ¶ï¼Œæ—¨åœ¨æå‡Text-to-SQLæ¨¡å‹åœ¨å·¥ä¸šçº§å¤§è§„æ¨¡æ•°æ®åº“å’Œå¤æ‚ä¸šåŠ¡é€»è¾‘ä¸‹çš„æ‰§è¡Œå‡†ç¡®ç‡ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°ç»“åˆäº†Partial-Match Rewardsä¸Verbal Reinforcement Learning (Verbal RL) æŠ€æœ¯ï¼Œé€šè¿‡ä¸¤å¥—äº’è¡¥çš„æµæ°´çº¿é©±åŠ¨æ¨ç†è¯­è¨€æ¨¡å‹(RLMs)çš„è‡ªæˆ‘è¿›åŒ–ã€‚ç¬¬ä¸€ç§æµæ°´çº¿åˆ©ç”¨å¤§æ¨¡å‹æ‰§è¡Œå¸¦æœ‰ç¾¤ä½“è‡ªæˆ‘è¯„ä¼°çš„è¯­å¢ƒå­¦ä¹ (In-context learning)ï¼Œè€Œç¬¬äºŒç§æµæ°´çº¿åˆ™é’ˆå¯¹è½»é‡çº§æ¨¡å‹OmniSQL-7Bè®¾è®¡äº†é“¾å¼æ€ç»´(Chain-of-Thought)å¼ºåŒ–å­¦ä¹ è·¯å¾„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPaVeRL-SQLåœ¨Spiderã€Spider 2.0åŠBIRDç­‰ä¸»æµåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†SOTAæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å·¥ä¸šçº§çš„Spider2.0-SQLiteæµ‹è¯•ä¸­ï¼Œå…¶Verbal RLæµæ°´çº¿çš„æ‰§è¡Œå‡†ç¡®ç‡è¾ƒæ­¤å‰æœ€ä¼˜æ¨¡å‹æå‡äº†7.4%ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ··åˆSQLæ–¹è¨€çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œè¯¥æ¡†æ¶åœ¨æ ·æœ¬ç¨€ç¼ºçš„æ–¹è¨€ä»»åŠ¡ä¸Šè¡¨ç°å‡ºäº†æå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºè§£å†³ç°å®å·¥ä¸šçº¦æŸä¸‹çš„Text-to-SQLéš¾é¢˜æä¾›äº†å¯é æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.07159v1",
      "published_date": "2025-09-08 19:15:38 UTC",
      "updated_date": "2025-09-08 19:15:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:53.036795+00:00"
    },
    {
      "arxiv_id": "2509.07149v1",
      "title": "Measuring Uncertainty in Transformer Circuits with Effective Information Consistency",
      "title_zh": "åŸºäºæœ‰æ•ˆä¿¡æ¯ä¸€è‡´æ€§çš„ Transformer ç”µè·¯ä¸ç¡®å®šæ€§é‡åŒ–",
      "authors": [
        "Anatoly A. Krasnovsky"
      ],
      "abstract": "Mechanistic interpretability has identified functional subgraphs within large language models (LLMs), known as Transformer Circuits (TCs), that appear to implement specific algorithms. Yet we lack a formal, single-pass way to quantify when an active circuit is behaving coherently and thus likely trustworthy. Building on prior systems-theoretic proposals, we specialize a sheaf/cohomology and causal emergence perspective to TCs and introduce the Effective-Information Consistency Score (EICS). EICS combines (i) a normalized sheaf inconsistency computed from local Jacobians and activations, with (ii) a Gaussian EI proxy for circuit-level causal emergence derived from the same forward state. The construction is white-box, single-pass, and makes units explicit so that the score is dimensionless. We further provide practical guidance on score interpretation, computational overhead (with fast and exact modes), and a toy sanity-check analysis. Empirical validation on LLM tasks is deferred.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºæ¢°å¯è§£é‡Šæ€§ (Mechanistic interpretability) é¢†åŸŸä¸­ç¼ºä¹é‡åŒ– Transformer Circuits (TCs) è¡Œä¸ºä¸€è‡´æ€§å’Œå¯ä¿¡åº¦æ–¹æ³•çš„é—®é¢˜ï¼Œæå‡ºäº†æœ‰æ•ˆä¿¡æ¯ä¸€è‡´æ€§è¯„åˆ† (Effective-Information Consistency Score, EICS)ã€‚EICS å€Ÿé‰´äº†ç³»ç»Ÿè®ºã€å±‚/ä¸ŠåŒè°ƒ (sheaf/cohomology) ä»¥åŠå› æœæ¶Œç° (causal emergence) çš„è§†è§’ï¼Œèƒ½å¤Ÿå¯¹æ¨¡å‹æ¿€æ´»çŠ¶æ€è¿›è¡Œå•æ¬¡è¯„ä¼°ã€‚è¯¥æŒ‡æ ‡ç»“åˆäº†åŸºäºå±€éƒ¨é›…å¯æ¯”çŸ©é˜µ (local Jacobians) è®¡ç®—çš„å±‚ä¸ä¸€è‡´æ€§ï¼Œä»¥åŠç”¨äºè¡¡é‡ç”µè·¯çº§å› æœæ¶Œç°çš„ Gaussian EI ä»£ç†æŒ‡æ ‡ã€‚ä½œä¸ºä¸€ç§ç™½ç›’åŒ–çš„å•æ¬¡è®¡ç®—æ–¹æ¡ˆï¼ŒEICS å…·æœ‰æ— é‡çº²ç‰¹æ€§ï¼Œä¸ä»…å¯ä»¥æ˜ç¡®å„å•å…ƒçš„ä½œç”¨ï¼Œè¿˜æä¾›äº†å…³äºè®¡ç®—å¼€é”€å’Œè¯„åˆ†é˜é‡Šçš„å®ç”¨å»ºè®®ã€‚é€šè¿‡ç®€å•çš„ç©å…·æ¨¡å‹éªŒè¯ï¼Œè¯¥æ–¹æ³•å±•ç¤ºäº†è¯„ä¼°å­å›¾ç®—æ³•é€»è¾‘ä¸€è‡´æ€§çš„æ½œåŠ›ï¼Œä¸ºå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„å¯ä¿¡ä»»æ€§æä¾›äº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07149v1",
      "published_date": "2025-09-08 18:54:56 UTC",
      "updated_date": "2025-09-08 18:54:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:59.331547+00:00"
    },
    {
      "arxiv_id": "2509.07146v1",
      "title": "Autoencoder-Based Denoising of Muscle Artifacts in ECG to Preserve Skin Nerve Activity (SKNA) for Cognitive Stress Detection",
      "title_zh": "åŸºäºè‡ªåŠ¨ç¼–ç å™¨çš„ ECG è‚Œè‚‰ä¼ªå½±å»å™ªï¼šæ—¨åœ¨ä¿ç•™ç”¨äºè®¤çŸ¥å‹åŠ›æ£€æµ‹çš„çš®è‚¤ç¥ç»æ´»åŠ¨ (SKNA)",
      "authors": [
        "Farnoush Baghestani",
        "Jihye Moon",
        "Youngsun Kong",
        "Ki Chon"
      ],
      "abstract": "The sympathetic nervous system (SNS) plays a central role in regulating the body's responses to stress and maintaining physiological stability. Its dysregulation is associated with a wide range of conditions, from cardiovascular disease to anxiety disorders. Skin nerve activity (SKNA) extracted from high-frequency electrocardiogram (ECG) recordings provides a noninvasive window into SNS dynamics, but its measurement is highly susceptible to electromyographic (EMG) contamination. Traditional preprocessing based on bandpass filtering within a fixed range (e.g., 500--1000 Hz) is susceptible to overlapping EMG and SKNA spectral components, especially during sustained muscle activity. We present a denoising approach using a lightweight one-dimensional convolutional autoencoder with a long short-term memory (LSTM) bottleneck to reconstruct clean SKNA from EMG-contaminated recordings. Using clean ECG-derived SKNA data from cognitive stress experiments and EMG noise from chaotic muscle stimulation recordings, we simulated contamination at realistic noise levels (--4 dB, --8 dB signal-to-noise ratio) and trained the model in the leave-one-subject-out cross-validation framework. The method improved signal-to-noise ratio by up to 9.65 dB, increased cross correlation with clean SKNA from 0.40 to 0.72, and restored burst-based SKNA features to near-clean discriminability (AUROC $\\geq$ 0.96). Classification of baseline versus sympathetic stimulation (cognitive stress) conditions reached accuracies of 91--98\\% across severe noise levels, comparable to clean data. These results demonstrate that deep learning--based reconstruction can preserve physiologically relevant sympathetic bursts during substantial EMG interference, enabling more robust SKNA monitoring in naturalistic, movement-rich environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»é«˜é¢‘å¿ƒç”µå›¾ (ECG) ä¸­æå–çš„çš®è‚¤ç¥ç»æ´»åŠ¨ (SKNA) ææ˜“å—åˆ°è‚Œç”µå›¾ (EMG) å¹²æ‰°çš„é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„å¸¦é€šæ»¤æ³¢åœ¨é¢‘è°±é‡å æ—¶æ•ˆæœæœ‰é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºè½»é‡åŒ–ä¸€ç»´å·ç§¯è‡ªç¼–ç å™¨ (Convolutional Autoencoder) ç»“åˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ (LSTM) ç“¶é¢ˆå±‚çš„å»å™ªæ–¹æ³•ï¼Œç”¨äºä»å—æ±¡æŸ“çš„è®°å½•ä¸­é‡å»ºçº¯å‡€çš„ SKNA ä¿¡å·ã€‚ç ”ç©¶åˆ©ç”¨è®¤çŸ¥å‹åŠ›å®éªŒä¸­çš„æ•°æ®æ¨¡æ‹Ÿäº†ç°å®å™ªå£°æ°´å¹³ï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜è¯¥æ–¹æ³•å¯å°†ä¿¡å™ªæ¯” (SNR) æé«˜è¾¾ 9.65 dBï¼ŒåŒæ—¶å°†äº’ç›¸å…³ç³»æ•°ä» 0.40 æå‡è‡³ 0.72ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹æˆåŠŸå°†åŸºäºçˆ†å‘ (burst) çš„ SKNA ç‰¹å¾æ¢å¤è‡³æ¥è¿‘çº¯å‡€æ•°æ®çš„åˆ¤åˆ«æ°´å¹³ (AUROC â‰¥ 0.96)ï¼Œåœ¨ä¸¥é‡å™ªå£°ä¸‹çš„è®¤çŸ¥å‹åŠ›æ£€æµ‹å‡†ç¡®ç‡è¾¾åˆ° 91% è‡³ 98%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œæ·±åº¦å­¦ä¹ é‡å»ºæŠ€æœ¯èƒ½å¤Ÿæœ‰æ•ˆå…‹æœ EMG å¹²æ‰°å¹¶ä¿ç•™å…³é”®çš„äº¤æ„Ÿç¥ç»ç‰¹å¾ï¼Œä¸ºåœ¨è‡ªç„¶è¿åŠ¨åœºæ™¯ä¸‹è¿›è¡Œç¨³å¥çš„ SKNA ç›‘æµ‹å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 7 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.07146v1",
      "published_date": "2025-09-08 18:51:36 UTC",
      "updated_date": "2025-09-08 18:51:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:11:57.832411+00:00"
    },
    {
      "arxiv_id": "2509.07142v1",
      "title": "Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models",
      "title_zh": "è¿ˆå‘å¤§è¯­è¨€æ¨¡å‹èµ‹èƒ½çš„ç›®æ ‡å¯¼å‘ä¸»é¢˜æ¨¡å‹è¯„ä¼°",
      "authors": [
        "Zhiyin Tan",
        "Jennifer D'Souza"
      ],
      "abstract": "This study presents a framework for automated evaluation of dynamically evolving topic models using Large Language Models (LLMs). Topic modeling is essential for organizing and retrieving scholarly content in digital library systems, helping users navigate complex and evolving knowledge domains. However, widely used automated metrics, such as coherence and diversity, often capture only narrow statistical patterns and fail to explain semantic failures in practice. We introduce a purpose-oriented evaluation framework that employs nine LLM-based metrics spanning four key dimensions of topic quality: lexical validity, intra-topic semantic soundness, inter-topic structural soundness, and document-topic alignment soundness. The framework is validated through adversarial and sampling-based protocols, and is applied across datasets spanning news articles, scholarly publications, and social media posts, as well as multiple topic modeling methods and open-source LLMs. Our analysis shows that LLM-based metrics provide interpretable, robust, and task-relevant assessments, uncovering critical weaknesses in topic models such as redundancy and semantic drift, which are often missed by traditional metrics. These results support the development of scalable, fine-grained evaluation tools for maintaining topic relevance in dynamic datasets. All code and data supporting this work are accessible at https://github.com/zhiyintan/topic-model-LLMjudgment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé¢å‘ç›®æ ‡çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨ Large Language Models (LLMs) å®ç°å¯¹åŠ¨æ€æ¼”è¿›ä¸»é¢˜æ¨¡å‹çš„è‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œä»¥è§£å†³ä¼ ç»Ÿç»Ÿè®¡æŒ‡æ ‡å¦‚ coherence å’Œ diversity åœ¨æ•æ‰è¯­ä¹‰ç¼ºé™·æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¹é¡¹åŸºäº LLM çš„è¯„ä¼°æŒ‡æ ‡ï¼Œæ¶µç›–äº† lexical validityã€intra-topic semantic soundnessã€inter-topic structural soundness ä»¥åŠ document-topic alignment soundness å››ä¸ªå…³é”®ç»´åº¦ã€‚é€šè¿‡åœ¨æ–°é—»ã€å­¦æœ¯æ–‡çŒ®å’Œç¤¾äº¤åª’ä½“ç­‰å¤šç§æ•°æ®é›†ä¸Šçš„å¯¹æŠ—æ€§åŠé‡‡æ ·éªŒè¯ï¼Œç ”ç©¶å±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨å¤šç§ä¸»é¢˜å»ºæ¨¡æ–¹æ³•å’Œå¼€æº LLMs ä¸Šçš„é€‚ç”¨æ€§ã€‚å®éªŒåˆ†æè¯æ˜ï¼ŒåŸºäº LLM çš„æŒ‡æ ‡æä¾›äº†å…·æœ‰å¯è§£é‡Šæ€§ã€é²æ£’æ€§ä¸”ä¸ä»»åŠ¡ç›¸å…³çš„è¯„ä¼°ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ­ç¤ºå†—ä½™å’Œ semantic drift ç­‰ä¼ ç»ŸæŒ‡æ ‡å®¹æ˜“å¿½ç•¥çš„æ¨¡å‹å¼±ç‚¹ã€‚è¿™ä¸€æˆæœä¸ºç»´æŠ¤åŠ¨æ€æ•°æ®é›†ä¸­ä¸»é¢˜ç›¸å…³æ€§æä¾›äº†å¯æ‰©å±•ä¸”ç»†ç²’åº¦çš„è¯„ä¼°å·¥å…·ï¼Œæ‰€æœ‰ç›¸å…³ä»£ç ä¸æ•°æ®å‡å·²å¼€æºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in International Journal on Digital Libraries (IJDL)",
      "pdf_url": "https://arxiv.org/pdf/2509.07142v1",
      "published_date": "2025-09-08 18:46:08 UTC",
      "updated_date": "2025-09-08 18:46:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:03.224765+00:00"
    },
    {
      "arxiv_id": "2509.07132v1",
      "title": "Adversarial Attacks on Audio Deepfake Detection: A Benchmark and Comparative Study",
      "title_zh": "éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹çš„å¯¹æŠ—æ”»å‡»ï¼šåŸºå‡†æµ‹è¯•ä¸å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Kutub Uddin",
        "Muhammad Umar Farooq",
        "Awais Khan",
        "Khalid Mahmood Malik"
      ],
      "abstract": "The widespread use of generative AI has shown remarkable success in producing highly realistic deepfakes, posing a serious threat to various voice biometric applications, including speaker verification, voice biometrics, audio conferencing, and criminal investigations. To counteract this, several state-of-the-art (SoTA) audio deepfake detection (ADD) methods have been proposed to identify generative AI signatures to distinguish between real and deepfake audio. However, the effectiveness of these methods is severely undermined by anti-forensic (AF) attacks that conceal generative signatures. These AF attacks span a wide range of techniques, including statistical modifications (e.g., pitch shifting, filtering, noise addition, and quantization) and optimization-based attacks (e.g., FGSM, PGD, C \\& W, and DeepFool). In this paper, we investigate the SoTA ADD methods and provide a comparative analysis to highlight their effectiveness in exposing deepfake signatures, as well as their vulnerabilities under adversarial conditions. We conducted an extensive evaluation of ADD methods on five deepfake benchmark datasets using two categories: raw and spectrogram-based approaches. This comparative analysis enables a deeper understanding of the strengths and limitations of SoTA ADD methods against diverse AF attacks. It does not only highlight vulnerabilities of ADD methods, but also informs the design of more robust and generalized detectors for real-world voice biometrics. It will further guide future research in developing adaptive defense strategies that can effectively counter evolving AF techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜ä¿çœŸ Deepfake éŸ³é¢‘å¯¹è¯­éŸ³ç”Ÿç‰©è¯†åˆ«æ„æˆçš„å¨èƒï¼Œæ¢è®¨äº†ç°æœ‰éŸ³é¢‘ä¼ªé€ æ£€æµ‹ (Audio Deepfake Detection, ADD) æ–¹æ³•åœ¨åå–è¯ (Anti-forensic, AF) æ”»å‡»ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚ä½œè€…å¯¹å½“å‰æœ€å…ˆè¿›çš„ (SoTA) ADD æ–¹æ³•è¿›è¡Œäº†ç³»ç»Ÿæ€§è°ƒæŸ¥ï¼Œé€šè¿‡åœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒï¼Œå¯¹æ¯”äº†åŸºäºåŸå§‹éŸ³é¢‘ (Raw-based) ä¸åŸºäºé¢‘è°±å›¾ (Spectrogram-based) çš„æ£€æµ‹è·¯å¾„ã€‚å®éªŒæ·±å…¥åˆ†æäº†ç»Ÿè®¡ä¿®æ”¹ä»¥åŠ FGSMã€PGDã€C & W ç­‰åŸºäºä¼˜åŒ–çš„å¯¹æŠ—æ”»å‡»å¯¹æ£€æµ‹æ•ˆæœçš„å½±å“ã€‚ç ”ç©¶ç»“æœæ­ç¤ºäº†ä¸åŒæ£€æµ‹æ¨¡å‹åœ¨å¯¹æŠ—ç¯å¢ƒä¸‹çš„è„†å¼±æ€§ä¸ä¼˜åŠ¿ï¼Œä¸ºå¼€å‘æ›´å…·é²æ£’æ€§å’Œé€šç”¨æ€§çš„å®æ—¶è¯­éŸ³æ£€æµ‹å™¨æä¾›äº†é‡è¦å‚è€ƒã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜ä¸ºæœªæ¥æ„å»ºèƒ½å¤ŸæŠµå¾¡ä¸æ–­æ¼”è¿›çš„åå–è¯æŠ€æœ¯çš„è‡ªé€‚åº”é˜²å¾¡ç­–ç•¥å¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07132v1",
      "published_date": "2025-09-08 18:33:24 UTC",
      "updated_date": "2025-09-08 18:33:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:04.340823+00:00"
    },
    {
      "arxiv_id": "2509.07131v1",
      "title": "SoK: Security and Privacy of AI Agents for Blockchain",
      "title_zh": "SoKï¼šé¢å‘åŒºå—é“¾çš„ AI æ™ºèƒ½ä½“å®‰å…¨ä¸éšç§",
      "authors": [
        "NicolÃ² Romandini",
        "Carlo Mazzocca",
        "Kai Otsuki",
        "Rebecca Montanari"
      ],
      "abstract": "Blockchain and smart contracts have garnered significant interest in recent years as the foundation of a decentralized, trustless digital ecosystem, thereby eliminating the need for traditional centralized authorities. Despite their central role in powering Web3, their complexity still presents significant barriers for non-expert users. To bridge this gap, Artificial Intelligence (AI)-based agents have emerged as valuable tools for interacting with blockchain environments, supporting a range of tasks, from analyzing on-chain data and optimizing transaction strategies to detecting vulnerabilities within smart contracts. While interest in applying AI to blockchain is growing, the literature still lacks a comprehensive survey that focuses specifically on the intersection with AI agents. Most of the related work only provides general considerations, without focusing on any specific domain. This paper addresses this gap by presenting the first Systematization of Knowledge dedicated to AI-driven systems for blockchain, with a special focus on their security and privacy dimensions, shedding light on their applications, limitations, and future research directions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒºå—é“¾(Blockchain)å’Œæ™ºèƒ½åˆçº¦(Smart contracts)ç³»ç»Ÿçš„å¤æ‚æ€§ï¼Œæ¢è®¨äº†äººå·¥æ™ºèƒ½æ™ºèƒ½ä½“(AI agents)ä½œä¸ºé™ä½ç”¨æˆ·äº¤äº’é—¨æ§›å·¥å…·çš„ä»·å€¼ã€‚ç°æœ‰æ–‡çŒ®è™½ç„¶å…³æ³¨AIä¸åŒºå—é“¾çš„ç»“åˆï¼Œä½†ç¼ºä¹ä¸“é—¨é’ˆå¯¹AI agentsåœ¨Securityå’ŒPrivacyç»´åº¦çš„å…¨é¢ç»¼è¿°ã€‚æœ¬æ–‡æå‡ºäº†é¦–ä¸ªé’ˆå¯¹åŒºå—é“¾AIé©±åŠ¨ç³»ç»Ÿçš„çŸ¥è¯†ä½“ç³»åŒ–(Systematization of Knowledge, SoK)ç ”ç©¶ï¼Œå¡«è¡¥äº†è¿™ä¸€å­¦æœ¯ç©ºç™½ã€‚æ–‡ä¸­è¯¦ç»†åˆ†æäº†AI agentsåœ¨é“¾ä¸Šæ•°æ®åˆ†æã€äº¤æ˜“ç­–ç•¥ä¼˜åŒ–åŠæ¼æ´æ£€æµ‹ç­‰ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œå¹¶å¯¹å…¶é¢ä¸´çš„å±€é™æ€§å’Œæœªæ¥ç ”ç©¶æ–¹å‘è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚è¿™é¡¹å·¥ä½œä¸ºç†è§£AI agentsåœ¨å»ä¸­å¿ƒåŒ–ç”Ÿæ€ç³»ç»Ÿä¸­çš„å®‰å…¨è¾¹ç•Œå’Œå‘å±•æ½œåŠ›æä¾›äº†å…³é”®çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This work has been accepted to the 7th International Conference on Blockchain Computing and Applications (BCCA 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.07131v1",
      "published_date": "2025-09-08 18:32:15 UTC",
      "updated_date": "2025-09-08 18:32:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:07.732184+00:00"
    },
    {
      "arxiv_id": "2509.07127v1",
      "title": "SVGauge: Towards Human-Aligned Evaluation for SVG Generation",
      "title_zh": "SVGaugeï¼šé¢å‘ SVG ç”Ÿæˆçš„äººç±»å¯¹é½è¯„ä¼°",
      "authors": [
        "Leonardo Zini",
        "Elia Frigieri",
        "Sebastiano Aloscari",
        "Marcello Generali",
        "Lorenzo Dodi",
        "Robert Dosen",
        "Lorenzo Baraldi"
      ],
      "abstract": "Generated Scalable Vector Graphics (SVG) images demand evaluation criteria tuned to their symbolic and vectorial nature: criteria that existing metrics such as FID, LPIPS, or CLIPScore fail to satisfy. In this paper, we introduce SVGauge, the first human-aligned, reference based metric for text-to-SVG generation. SVGauge jointly measures (i) visual fidelity, obtained by extracting SigLIP image embeddings and refining them with PCA and whitening for domain alignment, and (ii) semantic consistency, captured by comparing BLIP-2-generated captions of the SVGs against the original prompts in the combined space of SBERT and TF-IDF. Evaluation on the proposed SHE benchmark shows that SVGauge attains the highest correlation with human judgments and reproduces system-level rankings of eight zero-shot LLM-based generators more faithfully than existing metrics. Our results highlight the necessity of vector-specific evaluation and provide a practical tool for benchmarking future text-to-SVG generation models.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº† SVGaugeï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹æ–‡æœ¬ç”Ÿæˆ SVG (text-to-SVG) ä»»åŠ¡ä¸”ä¸äººç±»åˆ¤æ–­å¯¹é½çš„å‚è€ƒè¯„ä¼°æŒ‡æ ‡ï¼Œæ—¨åœ¨è§£å†³ FIDã€LPIPS å’Œ CLIPScore ç­‰ç°æœ‰æŒ‡æ ‡æ— æ³•æœ‰æ•ˆæ•æ‰çŸ¢é‡å›¾å½¢ç¬¦å·ç‰¹æ€§çš„é—®é¢˜ã€‚è¯¥æŒ‡æ ‡å…±åŒè¡¡é‡è§†è§‰ä¿çœŸåº¦ä¸è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå…¶ä¸­è§†è§‰ä¿çœŸåº¦é€šè¿‡æå– SigLIP å›¾åƒåµŒå…¥å¹¶ç»“åˆ PCA ä¸ç™½åŒ–æŠ€æœ¯å®ç°é¢†åŸŸå¯¹é½ï¼Œè€Œè¯­ä¹‰ä¸€è‡´æ€§åˆ™é€šè¿‡åœ¨ SBERT å’Œ TF-IDF çš„ç»„åˆç©ºé—´ä¸­å¯¹æ¯” BLIP-2 ç”Ÿæˆçš„æ ‡é¢˜ä¸åŸå§‹æç¤ºè¯ (prompts) æ¥æ•æ‰ã€‚åœ¨ SHE åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSVGauge ä¸äººç±»åˆ¤æ–­è¡¨ç°å‡ºæœ€é«˜çš„ç›¸å…³æ€§ï¼Œå¹¶èƒ½æ¯”ç°æœ‰æŒ‡æ ‡æ›´çœŸå®åœ°è¿˜åŸå…«ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„é›¶æ ·æœ¬ç”Ÿæˆå™¨çš„ç³»ç»Ÿçº§æ’åã€‚è¿™é¡¹ç ”ç©¶å¼ºè°ƒäº†çŸ¢é‡ç‰¹å®šè¯„ä¼°çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºæœªæ¥ text-to-SVG æ¨¡å‹çš„ç ”ç©¶ä¸è¯„æµ‹æä¾›äº†å®ç”¨çš„å·¥å…·ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted at 23rd edition of International Conference on Image Analysis and Processing 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07127v1",
      "published_date": "2025-09-08 18:28:31 UTC",
      "updated_date": "2025-09-08 18:28:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:14.427165+00:00"
    },
    {
      "arxiv_id": "2509.07122v1",
      "title": "Neuro-Symbolic Frameworks: Conceptual Characterization and Empirical Comparative Analysis",
      "title_zh": "ç¥ç»ç¬¦å·æ¡†æ¶ï¼šæ¦‚å¿µåˆ»ç”»ä¸å®è¯å¯¹æ¯”åˆ†æ",
      "authors": [
        "Sania Sinha",
        "Tanawan Premsri",
        "Danial Kamali",
        "Parisa Kordjamshidi"
      ],
      "abstract": "Neurosymbolic (NeSy) frameworks combine neural representations and learning with symbolic representations and reasoning. Combining the reasoning capacities, explainability, and interpretability of symbolic processing with the flexibility and power of neural computing allows us to solve complex problems with more reliability while being data-efficient. However, this recently growing topic poses a challenge to developers with its learning curve, lack of user-friendly tools, libraries, and unifying frameworks. In this paper, we characterize the technical facets of existing NeSy frameworks, such as the symbolic representation language, integration with neural models, and the underlying algorithms. A majority of the NeSy research focuses on algorithms instead of providing generic frameworks for declarative problem specification to leverage problem solving. To highlight the key aspects of Neurosymbolic modeling, we showcase three generic NeSy frameworks - \\textit{DeepProbLog}, \\textit{Scallop}, and \\textit{DomiKnowS}. We identify the challenges within each facet that lay the foundation for identifying the expressivity of each framework in solving a variety of problems. Building on this foundation, we aim to spark transformative action and encourage the community to rethink this problem in novel ways.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹ç¥ç»ç¬¦å· (Neuro-Symbolic, NeSy) æ¡†æ¶è¿›è¡Œäº†ç³»ç»Ÿçš„æ¦‚å¿µè¡¨å¾å’Œå®è¯æ¯”è¾ƒåˆ†æï¼Œæ—¨åœ¨è§£å†³å½“å‰è¯¥é¢†åŸŸé¢ä¸´çš„å­¦ä¹ æ›²çº¿é™¡å³­åŠç¼ºä¹ç”¨æˆ·å‹å¥½å‹å·¥å…·ç­‰æŒ‘æˆ˜ã€‚æ–‡ç« è¯¦ç»†åˆ»ç”»äº†ç°æœ‰ NeSy æ¡†æ¶åœ¨ç¬¦å·è¡¨ç¤ºè¯­è¨€ã€ä¸ç¥ç»æ¨¡å‹é›†æˆä»¥åŠåº•å±‚ç®—æ³•ç­‰æ–¹é¢çš„æŠ€æœ¯ç‰¹å¾ï¼ŒæŒ‡å‡ºå¤šæ•°ç ”ç©¶ç›®å‰ä»é›†ä¸­äºç®—æ³•è€Œéé€šç”¨çš„å£°æ˜å¼é—®é¢˜è§„çº¦ã€‚ä½œè€…é‡ç‚¹å±•ç¤ºå¹¶åˆ†æäº† DeepProbLogã€Scallop å’Œ DomiKnowS ä¸‰ç§é€šç”¨æ¡†æ¶ï¼Œé€šè¿‡å¯¹æ¯”æ˜ç¡®äº†å„æ¡†æ¶åœ¨è§£å†³å¤šæ ·åŒ–é—®é¢˜æ—¶çš„è¡¨è¾¾èƒ½åŠ› (expressivity)ã€‚ç ”ç©¶æœ€åè¯†åˆ«äº†å„æŠ€æœ¯å±‚é¢çš„å…·ä½“æŒ‘æˆ˜ï¼Œä¸ºç†è§£ä¸åŒæ¡†æ¶çš„é€‚ç”¨åœºæ™¯å¥ å®šäº†åŸºç¡€ï¼Œå¹¶é¼“åŠ±å­¦æœ¯ç•Œä»¥æ–°é¢–çš„æ–¹å¼é‡æ–°æ€è€ƒç¥ç»ç¬¦å·å»ºæ¨¡çš„æ„å»ºä¸åº”ç”¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07122v1",
      "published_date": "2025-09-08 18:17:33 UTC",
      "updated_date": "2025-09-08 18:17:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:17.842085+00:00"
    },
    {
      "arxiv_id": "2509.07115v2",
      "title": "Riemannian Batch Normalization: A Gyro Approach",
      "title_zh": "é»æ›¼æ‰¹å½’ä¸€åŒ–ï¼šä¸€ç§åŸºäºé™€èºç†è®ºçš„æ–¹æ³•",
      "authors": [
        "Ziheng Chen",
        "Xiao-Jun Wu",
        "Bernhard SchÃ¶lkopf",
        "Nicu Sebe"
      ],
      "abstract": "Normalization layers are crucial for deep learning, but their Euclidean formulations are inadequate for data on manifolds. On the other hand, many Riemannian manifolds in machine learning admit gyro-structures, enabling principled extensions of Euclidean neural networks to non-Euclidean domains. Inspired by this, we introduce GyroBN, a principled Riemannian batch normalization framework for gyrogroups. We establish two necessary conditions, namely \\emph{pseudo-reduction} and \\emph{gyroisometric gyrations}, that guarantee GyroBN with theoretical control over sample statistics, and show that these conditions hold for all known gyrogroups in machine learning. Our framework also incorporates several existing Riemannian normalization methods as special cases. We further instantiate GyroBN on seven representative geometries, including the Grassmannian, five constant curvature spaces, and the correlation manifold, and derive novel gyro and Riemannian structures to enable these instantiations. Experiments across these geometries demonstrate the effectiveness of GyroBN. The code is available at https://github.com/GitZH-Chen/GyroBN.git.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿ Euclidean å½’ä¸€åŒ–å±‚åœ¨æµå½¢æ•°æ®ä¸Šçš„å±€é™æ€§ï¼Œæå‡ºäº† GyroBNï¼Œè¿™æ˜¯ä¸€ç§åŸºäº gyro-structures çš„åŸåˆ™æ€§ Riemannian batch normalization æ¡†æ¶ã€‚ä¸ºäº†ä¿è¯å¯¹æ ·æœ¬ç»Ÿè®¡é‡çš„ç†è®ºæ§åˆ¶ï¼Œè¯¥ç ”ç©¶ç¡®ç«‹äº† pseudo-reduction å’Œ gyroisometric gyrations ä¸¤ä¸ªå¿…è¦æ¡ä»¶ï¼Œå¹¶è¯æ˜å…¶é€‚ç”¨äºæœºå™¨å­¦ä¹ ä¸­æ‰€æœ‰å·²çŸ¥çš„ gyrogroupsã€‚GyroBN ä¸ä»…å°†å¤šç§ç°æœ‰çš„ Riemannian å½’ä¸€åŒ–æ–¹æ³•çº³ä¸ºç‰¹ä¾‹ï¼Œè¿˜åœ¨ Grassmannianã€äº”ç§ constant curvature spaces ä»¥åŠ correlation manifold ç­‰ä¸ƒç§ä»£è¡¨æ€§å‡ ä½•ç»“æ„ä¸Šè¿›è¡Œäº†å®ä¾‹åŒ–ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æ¨å¯¼å‡ºäº†æ”¯æŒè¿™äº›å®ä¾‹åŒ–çš„æ–°å‹ gyro å’Œ Riemannian structuresã€‚å¤šé¡¹å‡ ä½•å®éªŒç»“æœè¡¨æ˜ï¼ŒGyroBN åœ¨å¤„ç†éæ¬§å‡ é‡Œå¾—ç©ºé—´æ•°æ®æ—¶å…·æœ‰æ˜¾è‘—çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæµå½¢æ·±åº¦å­¦ä¹ æä¾›äº†ç»Ÿä¸€ä¸”ç¨³å¥çš„å½’ä¸€åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07115v2",
      "published_date": "2025-09-08 18:12:08 UTC",
      "updated_date": "2025-09-19 17:45:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:32.639987+00:00"
    },
    {
      "arxiv_id": "2509.07103v2",
      "title": "Lookup multivariate Kolmogorov-Arnold Networks",
      "title_zh": "æŸ¥è¡¨å¼å¤šå…ƒ Kolmogorov-Arnold ç½‘ç»œ",
      "authors": [
        "Sergey Pozdnyakov",
        "Philippe Schwaller"
      ],
      "abstract": "High-dimensional linear mappings, or linear layers, dominate both the parameter count and the computational cost of most modern deep-learning models. We introduce a general-purpose drop-in replacement, lookup multivariate Kolmogorov-Arnold Networks (lmKANs), which deliver a substantially better trade-off between capacity and inference cost. Our construction expresses a general high-dimensional mapping through trainable low-dimensional multivariate functions. These functions can carry dozens or hundreds of trainable parameters each, and yet it takes only a few multiplications to compute them because they are implemented as spline lookup tables. Empirically, lmKANs reduce inference FLOPs by up to 6.0x while matching the flexibility of MLPs in general high-dimensional function approximation. In another feedforward fully connected benchmark, on the tabular-like dataset of randomly displaced methane configurations, lmKANs enable more than 10x higher H100 throughput at equal accuracy. Within frameworks of Convolutional Neural Networks, lmKAN-based CNNs cut inference FLOPs at matched accuracy by 1.6-2.1x and by 1.7x on the CIFAR-10 and ImageNet-1k datasets, respectively. Our code, including dedicated CUDA kernels, is available online at https://github.com/schwallergroup/lmkan.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Lookup multivariate Kolmogorov-Arnold Networks (lmKANs)ï¼Œæ—¨åœ¨ä½œä¸ºé€šç”¨ä¸”å¯ç›´æ¥æ›¿æ¢çš„å±‚æ¥ä¼˜åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­å‚æ•°é‡å’Œè®¡ç®—æˆæœ¬å·¨å¤§çš„é«˜ç»´çº¿æ€§æ˜ å°„(Linear layers)ã€‚lmKANs é€šè¿‡å¯è®­ç»ƒçš„ä½ç»´å¤šå…ƒå‡½æ•°æ¥è¡¨è¾¾é«˜ç»´æ˜ å°„ï¼Œå¹¶åˆ©ç”¨æ ·æ¡æŸ¥æ‰¾è¡¨(Spline lookup tables)å®ç°ï¼Œè¿™ä½¿å¾—æ¯ä¸ªå‡½æ•°åœ¨æ‰¿è½½å¤§é‡å¯è®­ç»ƒå‚æ•°çš„åŒæ—¶ï¼Œä»…éœ€æå°‘é‡çš„ä¹˜æ³•è¿ç®—å³å¯å®Œæˆè®¡ç®—ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨é€šç”¨é«˜ç»´å‡½æ•°é€¼è¿‘ä¸­ï¼ŒlmKANs åœ¨ä¿æŒä¸å¤šå±‚æ„ŸçŸ¥æœº(MLPs)ç›¸åŒçµæ´»æ€§çš„å‰æä¸‹ï¼Œå°†æ¨ç†è¿‡ç¨‹ä¸­çš„æµ®ç‚¹è¿ç®—é‡(FLOPs)é™ä½äº†é«˜è¾¾6.0å€ã€‚åœ¨ç”²çƒ·æ„å‹ç­‰è¡¨æ ¼åŒ–æ•°æ®é›†çš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨ç›¸åŒç²¾åº¦ä¸‹å®ç°äº†æ¯” H100 æ˜¾å¡åŸºå‡†é«˜å‡º10å€ä»¥ä¸Šçš„ååé‡ã€‚åœ¨å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)æ¡†æ¶å†…ï¼ŒåŸºäº lmKAN çš„æ¨¡å‹åœ¨ CIFAR-10 å’Œ ImageNet-1k æ•°æ®é›†ä¸Šï¼Œä¹Ÿåˆ†åˆ«ä»¥1.6-2.1å€å’Œ1.7å€çš„ä¼˜åŠ¿å‰Šå‡äº†æ¨ç† FLOPsã€‚è¯¥å·¥ä½œè¿˜æä¾›äº†ä¸“ç”¨çš„ CUDA kernelsï¼Œä¸ºæå‡æ·±åº¦å­¦ä¹ æ¨ç†æ•ˆç‡æä¾›äº†æ›´ä¼˜çš„èƒ½åŠ›ä¸æˆæœ¬æƒè¡¡æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "polishing",
      "pdf_url": "https://arxiv.org/pdf/2509.07103v2",
      "published_date": "2025-09-08 18:00:35 UTC",
      "updated_date": "2025-10-17 12:56:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:35.842504+00:00"
    },
    {
      "arxiv_id": "2509.07098v1",
      "title": "Instruction Agent: Enhancing Agent with Expert Demonstration",
      "title_zh": "Instruction Agentï¼šåˆ©ç”¨ä¸“å®¶æ¼”ç¤ºå¢å¼ºæ™ºèƒ½ä½“",
      "authors": [
        "Yinheng Li",
        "Hailey Hultquist",
        "Justin Wagle",
        "Kazuhito Koishida"
      ],
      "abstract": "Graphical user interface (GUI) agents have advanced rapidly but still struggle with complex tasks involving novel UI elements, long-horizon actions, and personalized trajectories. In this work, we introduce Instruction Agent, a GUI agent that leverages expert demonstrations to solve such tasks, enabling completion of otherwise difficult workflows. Given a single demonstration, the agent extracts step-by-step instructions and executes them by strictly following the trajectory intended by the user, which avoids making mistakes during execution. The agent leverages the verifier and backtracker modules further to improve robustness. Both modules are critical to understand the current outcome from each action and handle unexpected interruptions(such as pop-up windows) during execution. Our experiments show that Instruction Agent achieves a 60% success rate on a set of tasks in OSWorld that all top-ranked agents failed to complete. The Instruction Agent offers a practical and extensible framework, bridging the gap between current GUI agents and reliable real-world GUI task automation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾å½¢ç”¨æˆ·ç•Œé¢(GUI)æ™ºèƒ½ä½“åœ¨å¤„ç†åŒ…å«æ–°UIå…ƒç´ ã€é•¿æ—¶ç¨‹åŠ¨ä½œåŠä¸ªæ€§åŒ–è½¨è¿¹çš„å¤æ‚ä»»åŠ¡æ—¶å­˜åœ¨çš„å›°éš¾ï¼Œæå‡ºäº†Instruction Agentæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨ä¸“å®¶æ¼”ç¤º(Expert Demonstration)æ¥å¢å¼ºæ™ºèƒ½ä½“çš„èƒ½åŠ›ï¼Œä»…éœ€å•æ¬¡æ¼”ç¤ºå³å¯æå–åˆ†æ­¥æŒ‡ä»¤ï¼Œå¹¶ç”±äºä¸¥æ ¼éµå¾ªç”¨æˆ·é¢„æœŸçš„è½¨è¿¹æ‰§è¡Œè€Œæœ‰æ•ˆå‡å°‘äº†æ“ä½œé”™è¯¯ã€‚ç³»ç»Ÿä¸­é›†æˆäº†éªŒè¯å™¨(Verifier)å’Œå›æº¯å™¨(Backtracker)æ¨¡å—ï¼Œç”¨äºå®æ—¶è¯„ä¼°æ“ä½œç»“æœå¹¶å¤„ç†è¯¸å¦‚å¼¹çª—å¹²æ‰°ç­‰æ„å¤–ä¸­æ–­ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„é²æ£’æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒInstruction Agentåœ¨OSWorldä¸­ä¸€ç»„é¡¶å°–æ™ºèƒ½ä½“æ­¤å‰å‡æ— æ³•å®Œæˆçš„æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸Šå®ç°äº†60%çš„æˆåŠŸç‡ã€‚è¿™é¡¹å·¥ä½œæä¾›äº†ä¸€ä¸ªå®ç”¨ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼ŒæˆåŠŸå¼¥åˆäº†å½“å‰GUIæ™ºèƒ½ä½“ä¸å¯é çš„ç°å®ä¸–ç•Œä»»åŠ¡è‡ªåŠ¨åŒ–ä¹‹é—´çš„å·®è·ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07098v1",
      "published_date": "2025-09-08 18:00:12 UTC",
      "updated_date": "2025-09-08 18:00:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:36.734849+00:00"
    },
    {
      "arxiv_id": "2509.06956v1",
      "title": "H$_{2}$OT: Hierarchical Hourglass Tokenizer for Efficient Video Pose Transformers",
      "title_zh": "H$_{2}$OTï¼šé¢å‘é«˜æ•ˆè§†é¢‘å§¿æ€ Transformer çš„å±‚çº§æ²™æ¼å¼ Tokenizer",
      "authors": [
        "Wenhao Li",
        "Mengyuan Liu",
        "Hong Liu",
        "Pichao Wang",
        "Shijian Lu",
        "Nicu Sebe"
      ],
      "abstract": "Transformers have been successfully applied in the field of video-based 3D human pose estimation. However, the high computational costs of these video pose transformers (VPTs) make them impractical on resource-constrained devices. In this paper, we present a hierarchical plug-and-play pruning-and-recovering framework, called Hierarchical Hourglass Tokenizer (H$_{2}$OT), for efficient transformer-based 3D human pose estimation from videos. H$_{2}$OT begins with progressively pruning pose tokens of redundant frames and ends with recovering full-length sequences, resulting in a few pose tokens in the intermediate transformer blocks and thus improving the model efficiency. It works with two key modules, namely, a Token Pruning Module (TPM) and a Token Recovering Module (TRM). TPM dynamically selects a few representative tokens to eliminate the redundancy of video frames, while TRM restores the detailed spatio-temporal information based on the selected tokens, thereby expanding the network output to the original full-length temporal resolution for fast inference. Our method is general-purpose: it can be easily incorporated into common VPT models on both seq2seq and seq2frame pipelines while effectively accommodating different token pruning and recovery strategies. In addition, our H$_{2}$OT reveals that maintaining the full pose sequence is unnecessary, and a few pose tokens of representative frames can achieve both high efficiency and estimation accuracy. Extensive experiments on multiple benchmark datasets demonstrate both the effectiveness and efficiency of the proposed method. Code and models are available at https://github.com/NationalGAILab/HoT.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†é¢‘ 3D äººä½“å§¿æ€ä¼°è®¡ä¸­ Video Pose Transformers (VPTs) è®¡ç®—æˆæœ¬è¿‡é«˜ã€éš¾ä»¥åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º H$_2$OT (Hierarchical Hourglass Tokenizer) çš„åˆ†å±‚å³æ’å³ç”¨ä¿®å‰ªä¸æ¢å¤æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ Token Pruning Module (TPM) åŠ¨æ€é€‰æ‹©ä»£è¡¨æ€§ token ä»¥æ¶ˆé™¤è§†é¢‘å¸§å†—ä½™ï¼Œå¹¶åˆ©ç”¨ Token Recovering Module (TRM) æ¢å¤è¯¦ç»†çš„æ—¶ç©ºä¿¡æ¯ï¼Œä»è€Œå°†åºåˆ—è¿˜åŸè‡³åŸå§‹æ—¶é—´åˆ†è¾¨ç‡è¿›è¡Œå¿«é€Ÿæ¨ç†ã€‚H$_2$OT å…·æœ‰æå¼ºçš„é€šç”¨æ€§ï¼Œèƒ½å¤Ÿçµæ´»åº”ç”¨äº seq2seq å’Œ seq2frame ç­‰å¤šç§ VPT æ¨¡å‹æµæ°´çº¿åŠä¸åŒçš„ä¿®å‰ªæ¢å¤ç­–ç•¥ã€‚ç ”ç©¶æ­ç¤ºäº†ç»´æŒå®Œæ•´å§¿æ€åºåˆ—åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¹¶éå¿…è¦ï¼Œä»…éœ€å°‘é‡å…³é”®å¸§çš„ pose tokens å³å¯å¹³è¡¡ä¼°è®¡ç²¾åº¦ä¸è¿è¡Œæ•ˆç‡ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—æå‡æ¨¡å‹æ•ˆç‡çš„åŒæ—¶ä¿æŒäº†ä¼˜å¼‚çš„æ€§èƒ½è¡¨ç°ï¼Œä¸ºé«˜æ•ˆè§†é¢‘å§¿æ€ä¼°è®¡æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TPAMI 2025, Open Sourced. arXiv admin note: substantial text overlap with arXiv:2311.12028",
      "pdf_url": "https://arxiv.org/pdf/2509.06956v1",
      "published_date": "2025-09-08 17:59:59 UTC",
      "updated_date": "2025-09-08 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:41.737228+00:00"
    },
    {
      "arxiv_id": "2509.06953v1",
      "title": "Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments",
      "title_zh": "Deep Reactive Policyï¼šé¢å‘åŠ¨æ€ç¯å¢ƒçš„ååº”å¼æœºæ¢°è‡‚è¿åŠ¨è§„åˆ’å­¦ä¹ ",
      "authors": [
        "Jiahui Yang",
        "Jason Jingzhou Liu",
        "Yulong Li",
        "Youssef Khaky",
        "Kenneth Shaw",
        "Deepak Pathak"
      ],
      "abstract": "Generating collision-free motion in dynamic, partially observable environments is a fundamental challenge for robotic manipulators. Classical motion planners can compute globally optimal trajectories but require full environment knowledge and are typically too slow for dynamic scenes. Neural motion policies offer a promising alternative by operating in closed-loop directly on raw sensory inputs but often struggle to generalize in complex or dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural motion policy designed for reactive motion generation in diverse dynamic environments, operating directly on point cloud sensory input. At its core is IMPACT, a transformer-based neural motion policy pretrained on 10 million generated expert trajectories across diverse simulation scenarios. We further improve IMPACT's static obstacle avoidance through iterative student-teacher finetuning. We additionally enhance the policy's dynamic obstacle avoidance at inference time using DCP-RMP, a locally reactive goal-proposal module. We evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving obstacles, and goal obstructions. DRP achieves strong generalization, outperforming prior classical and neural methods in success rate across both simulated and real-world settings. Video results and code available at https://deep-reactive-policy.com",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Deep Reactive Policy (DRP)ï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºå¤šæ ·åŒ–åŠ¨æ€ç¯å¢ƒè®¾è®¡çš„è§†è§‰è¿åŠ¨ç¥ç»è¿åŠ¨ç­–ç•¥(visuo-motor neural motion policy)ï¼Œæ—¨åœ¨è§£å†³æœºæ¢°è‡‚åœ¨éƒ¨åˆ†å¯è§‚æµ‹åŠ¨æ€åœºæ™¯ä¸‹çš„æ— ç¢°æ’è¿åŠ¨è§„åˆ’éš¾é¢˜ã€‚DRPçš„æ ¸å¿ƒæ˜¯IMPACTï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºTransformerçš„ç¥ç»è¿åŠ¨ç­–ç•¥ï¼Œé€šè¿‡åœ¨1000ä¸‡æ¡æ¨¡æ‹Ÿä¸“å®¶è½¨è¿¹ä¸Šè¿›è¡Œé¢„è®­ç»ƒè€Œæˆã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨è¿­ä»£å¼å­¦ç”Ÿ-æ•™å¸ˆå¾®è°ƒ(student-teacher finetuning)å¢å¼ºäº†é™æ€é¿éšœèƒ½åŠ›ï¼Œå¹¶ç»“åˆDCP-RMPæ¨¡å—åœ¨æ¨ç†é˜¶æ®µæå‡äº†å¯¹åŠ¨æ€éšœç¢ç‰©çš„å“åº”é€Ÿåº¦ã€‚è¯¥ç³»ç»Ÿç›´æ¥å¤„ç†åŸå§‹çš„ç‚¹äº‘(point cloud)æ„Ÿå®˜è¾“å…¥ï¼Œèƒ½å¤Ÿå®ç°ç«¯åˆ°ç«¯çš„é—­ç¯æ§åˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDRPåœ¨å¤„ç†å¤æ‚æ‚ä¹±åœºæ™¯ã€åŠ¨æ€ç§»åŠ¨éšœç¢ç‰©åŠç›®æ ‡é®æŒ¡ä»»åŠ¡æ—¶å…·æœ‰æå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œå…¶æˆåŠŸç‡åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œæµ‹è¯•ä¸­å‡æ˜¾è‘—è¶…è¶Šäº†ä¼ ç»Ÿçš„åŠç°æœ‰çš„ç¥ç»è¿åŠ¨è§„åˆ’æ–¹æ³•ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Website at \\url{deep-reactive-policy.com}",
      "pdf_url": "https://arxiv.org/pdf/2509.06953v1",
      "published_date": "2025-09-08 17:59:35 UTC",
      "updated_date": "2025-09-08 17:59:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:41.541588+00:00"
    },
    {
      "arxiv_id": "2509.06945v2",
      "title": "Interleaving Reasoning for Better Text-to-Image Generation",
      "title_zh": "äº¤é”™å¼æ¨ç†ï¼šå®ç°æ›´ä¼˜çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ",
      "authors": [
        "Wenxuan Huang",
        "Shuang Chen",
        "Zheyong Xie",
        "Shaosheng Cao",
        "Shixiang Tang",
        "Yufan Shen",
        "Qingyu Yin",
        "Wenbo Hu",
        "Xiaoman Wang",
        "Yuntian Tang",
        "Junbo Qiao",
        "Yue Guo",
        "Yao Hu",
        "Zhenfei Yin",
        "Philip Torr",
        "Yu Cheng",
        "Wanli Ouyang",
        "Shaohui Lin"
      ],
      "abstract": "Unified multimodal understanding and generation models recently have achieve significant improvement in image generation capability, yet a large gap remains in instruction following and detail preservation compared to systems that tightly couple comprehension with generation such as GPT-4o. Motivated by recent advances in interleaving reasoning, we explore whether such reasoning can further improve Text-to-Image (T2I) generation. We introduce Interleaving Reasoning Generation (IRG), a framework that alternates between text-based thinking and image synthesis: the model first produces a text-based thinking to guide an initial image, then reflects on the result to refine fine-grained details, visual quality, and aesthetics while preserving semantics. To train IRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL), which targets two sub-goals: (1) strengthening the initial think-and-generate stage to establish core content and base quality, and (2) enabling high-quality textual reflection and faithful implementation of those refinements in a subsequent image. We curate IRGL-300K, a dataset organized into six decomposed learning modes that jointly cover learning text-based thinking, and full thinking-image trajectories. Starting from a unified foundation model that natively emits interleaved text-image outputs, our two-stage training first builds robust thinking and reflection, then efficiently tunes the IRG pipeline in the full thinking-image trajectory data. Extensive experiments show SoTA performance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF, GenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality and fine-grained fidelity. The code, model weights and datasets will be released in: https://github.com/Osilly/Interleaving-Reasoning-Generation .",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Interleaving Reasoning Generation (IRG)æ¡†æ¶ï¼Œæ—¨åœ¨ç¼©å°ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹åœ¨æŒ‡ä»¤éµå¾ªå’Œç»†èŠ‚ä¿ç•™æ–¹é¢ä¸GPT-4oç­‰å…ˆè¿›ç³»ç»Ÿçš„å·®è·ã€‚IRGé€šè¿‡åœ¨æ–‡æœ¬æ¨ç†(text-based thinking)ä¸å›¾åƒåˆæˆ(image synthesis)ä¹‹é—´äº¤æ›¿è¿›è¡Œï¼Œé¦–å…ˆäº§ç”Ÿæ–‡æœ¬æ€è€ƒä»¥æŒ‡å¯¼åˆæ­¥å›¾åƒç”Ÿæˆï¼Œéšåé€šè¿‡åæ€(reflection)åœ¨ä¿æŒè¯­ä¹‰çš„åŒæ—¶ä¼˜åŒ–ç»†ç²’åº¦ç»†èŠ‚ã€è§†è§‰è´¨é‡å’Œç¾å­¦ã€‚ä¸ºäº†æœ‰æ•ˆè®­ç»ƒè¯¥æ¡†æ¶ï¼Œç ”ç©¶è€…å¼€å‘äº†Interleaving Reasoning Generation Learning (IRGL)æ–¹æ³•åŠåŒ…å«30ä¸‡æ¡æ•°æ®çš„IRGL-300Kæ•°æ®é›†ï¼Œé€šè¿‡å…­ç§å­¦ä¹ æ¨¡å¼æ¶µç›–äº†å®Œæ•´çš„æ¨ç†-å›¾åƒè½¨è¿¹ã€‚ä¸¤é˜¶æ®µè®­ç»ƒè¿‡ç¨‹å…ˆæ„å»ºç¨³å¥çš„æ¨ç†ä¸åæ€åŸºç¡€ï¼Œå†åœ¨å…¨è½¨è¿¹æ•°æ®ä¸Šé«˜æ•ˆå¾®è°ƒIRGæµæ°´çº¿ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨GenEvalã€WISEå’ŒTIIFç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†SoTAæ€§èƒ½ï¼Œè·å¾—äº†5-10åˆ†çš„ç»å¯¹å¢ç›Šï¼Œå¹¶åœ¨è§†è§‰è´¨é‡å’Œç»†ç²’åº¦å¿ å®åº¦ä¸Šå®ç°äº†æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06945v2",
      "published_date": "2025-09-08 17:56:23 UTC",
      "updated_date": "2025-09-09 10:50:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:47.840991+00:00"
    },
    {
      "arxiv_id": "2509.06942v3",
      "title": "Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference",
      "title_zh": "å°†å…¨æ‰©æ•£è½¨è¿¹ä¸ç»†ç²’åº¦äººç±»åå¥½ç›´æ¥å¯¹é½",
      "authors": [
        "Xiangwei Shen",
        "Zhimin Li",
        "Zhantao Yang",
        "Shiyi Zhang",
        "Yingfang Zhang",
        "Donghao Li",
        "Chunyu Wang",
        "Qinglin Lu",
        "Yansong Tang"
      ],
      "abstract": "Recent studies have demonstrated the effectiveness of directly aligning diffusion models with human preferences using differentiable reward. However, they exhibit two primary challenges: (1) they rely on multistep denoising with gradient computation for reward scoring, which is computationally expensive, thus restricting optimization to only a few diffusion steps; (2) they often need continuous offline adaptation of reward models in order to achieve desired aesthetic quality, such as photorealism or precise lighting effects. To address the limitation of multistep denoising, we propose Direct-Align, a method that predefines a noise prior to effectively recover original images from any time steps via interpolation, leveraging the equation that diffusion states are interpolations between noise and target images, which effectively avoids over-optimization in late timesteps. Furthermore, we introduce Semantic Relative Preference Optimization (SRPO), in which rewards are formulated as text-conditioned signals. This approach enables online adjustment of rewards in response to positive and negative prompt augmentation, thereby reducing the reliance on offline reward fine-tuning. By fine-tuning the FLUX model with optimized denoising and online reward adjustment, we improve its human-evaluated realism and aesthetic quality by over 3x.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹(Diffusion Models)åœ¨äººç±»åå¥½å¯¹é½ä¸­é¢ä¸´çš„æ¢¯åº¦è®¡ç®—æˆæœ¬é«˜ä»¥åŠå¥–åŠ±æ¨¡å‹è¿‡åº¦ä¾èµ–ç¦»çº¿å¾®è°ƒçš„é—®é¢˜ï¼Œæå‡ºäº†Direct-Alignå¯¹é½æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡é¢„å®šä¹‰å™ªå£°å…ˆéªŒ(noise prior)å¹¶åˆ©ç”¨æ’å€¼æŠ€æœ¯ä»ä»»æ„æ—¶é—´æ­¥æ¢å¤å›¾åƒï¼Œæœ‰æ•ˆè§£å†³äº†å…¨è½¨è¿¹å¯¹é½ä¸­çš„è®¡ç®—å¼€é”€å’ŒåæœŸè¿‡åº¦ä¼˜åŒ–é—®é¢˜ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†è¯­ä¹‰ç›¸å¯¹åå¥½ä¼˜åŒ–(Semantic Relative Preference Optimization, SRPO)ï¼Œå°†å¥–åŠ±è½¬åŒ–ä¸ºæ–‡æœ¬è°ƒèŠ‚ä¿¡å·ï¼Œé€šè¿‡æ­£è´Ÿæç¤ºè¯å¢å¼ºå®ç°äº†å¥–åŠ±çš„åœ¨çº¿è°ƒæ•´ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨FLUXæ¨¡å‹ä¸Šåº”ç”¨è¯¥æ–¹æ³•åï¼Œå…¶çœŸå®æ„Ÿå’Œå®¡ç¾è´¨é‡çš„äººç±»è¯„ä¼°å¾—åˆ†æå‡äº†3å€ä»¥ä¸Šã€‚è¯¥å·¥ä½œä¸ºé«˜æ•ˆã€ç²¾ç»†åœ°ä¼˜åŒ–æ‰©æ•£æ¨¡å‹ç”Ÿæˆè´¨é‡æä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.06942v3",
      "published_date": "2025-09-08 17:54:08 UTC",
      "updated_date": "2025-09-11 17:14:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:51.432049+00:00"
    },
    {
      "arxiv_id": "2509.08852v1",
      "title": "Safe and Certifiable AI Systems: Concepts, Challenges, and Lessons Learned",
      "title_zh": "å®‰å…¨ä¸”å¯è®¤è¯çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼šæ¦‚å¿µã€æŒ‘æˆ˜ä¸ç»éªŒæ•™è®­",
      "authors": [
        "Kajetan Schweighofer",
        "Barbara Brune",
        "Lukas Gruber",
        "Simon Schmid",
        "Alexander Aufreiter",
        "Andreas Gruber",
        "Thomas Doms",
        "Sebastian Eder",
        "Florian Mayer",
        "Xaver-Paul Stadlbauer",
        "Christoph Schwald",
        "Werner Zellinger",
        "Bernhard Nessler",
        "Sepp Hochreiter"
      ],
      "abstract": "There is an increasing adoption of artificial intelligence in safety-critical applications, yet practical schemes for certifying that AI systems are safe, lawful and socially acceptable remain scarce. This white paper presents the TÃœV AUSTRIA Trusted AI framework an end-to-end audit catalog and methodology for assessing and certifying machine learning systems. The audit catalog has been in continuous development since 2019 in an ongoing collaboration with scientific partners. Building on three pillars - Secure Software Development, Functional Requirements, and Ethics & Data Privacy - the catalog translates the high-level obligations of the EU AI Act into specific, testable criteria. Its core concept of functional trustworthiness couples a statistically defined application domain with risk-based minimum performance requirements and statistical testing on independently sampled data, providing transparent and reproducible evidence of model quality in real-world settings. We provide an overview of the functional requirements that we assess, which are oriented on the lifecycle of an AI system. In addition, we share some lessons learned from the practical application of the audit catalog, highlighting common pitfalls we encountered, such as data leakage scenarios, inadequate domain definitions, neglect of biases, or a lack of distribution drift controls. We further discuss key aspects of certifying AI systems, such as robustness, algorithmic fairness, or post-certification requirements, outlining both our current conclusions and a roadmap for future research. In general, by aligning technical best practices with emerging European standards, the approach offers regulators, providers, and users a practical roadmap for legally compliant, functionally trustworthy, and certifiable AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®‰å…¨å…³é”®å‹åº”ç”¨ä¸­AIç³»ç»Ÿç¼ºä¹æœ‰æ•ˆè®¤è¯æœºåˆ¶çš„ç°çŠ¶ï¼Œæå‡ºäº†TÃœV AUSTRIA Trusted AIæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€å¥—ç”¨äºè¯„ä¼°å’Œè®¤è¯æœºå™¨å­¦ä¹ (Machine Learning)ç³»ç»Ÿçš„ç«¯åˆ°ç«¯å®¡è®¡ç›®å½•ä¸æ–¹æ³•è®ºã€‚è¯¥æ¡†æ¶å›´ç»•å®‰å…¨è½¯ä»¶å¼€å‘(Secure Software Development)ã€åŠŸèƒ½éœ€æ±‚(Functional Requirements)ä»¥åŠä¼¦ç†ä¸æ•°æ®éšç§(Ethics & Data Privacy)ä¸‰å¤§æ”¯æŸ±ï¼Œå°†æ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆ(EU AI Act)çš„é«˜çº§ä¹‰åŠ¡è½¬åŒ–ä¸ºå…·ä½“ä¸”å¯æµ‹è¯•çš„å‡†åˆ™ã€‚å…¶æ ¸å¿ƒç†å¿µæ˜¯åŠŸèƒ½å¯ä¿¡åº¦(Functional Trustworthiness)ï¼Œé€šè¿‡ç»“åˆç»Ÿè®¡å®šä¹‰çš„åº”ç”¨é¢†åŸŸã€åŸºäºé£é™©çš„æœ€ä½æ€§èƒ½è¦æ±‚ä»¥åŠç‹¬ç«‹æŠ½æ ·æ•°æ®çš„ç»Ÿè®¡æµ‹è¯•ï¼Œä¸ºæ¨¡å‹åœ¨ç°å®ç¯å¢ƒä¸­çš„è´¨é‡æä¾›é€æ˜ä¸”å¯é‡å¤çš„è¯æ®ã€‚æ–‡ç« è¯¦è¿°äº†è¦†ç›–AIç³»ç»Ÿç”Ÿå‘½å‘¨æœŸçš„åŠŸèƒ½è¯„ä¼°éœ€æ±‚ï¼Œå¹¶åˆ†äº«äº†åº”å¯¹æ•°æ®æ³„æ¼(Data Leakage)ã€é¢†åŸŸå®šä¹‰ä¸å……åˆ†åŠåˆ†å¸ƒåç§»(Distribution Drift)æ§åˆ¶ç¼ºå¤±ç­‰å®è·µé™·é˜±çš„ç»éªŒæ•™è®­ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢è®¨äº†é²æ£’æ€§(Robustness)å’Œç®—æ³•å…¬å¹³æ€§(Algorithmic Fairness)ç­‰å…³é”®ç»´åº¦ï¼Œæ—¨åœ¨é€šè¿‡å¯¹æ¥æ¬§æ´²æ–°å…´æ ‡å‡†ï¼Œä¸ºç›‘ç®¡è€…ã€æä¾›å•†å’Œç”¨æˆ·æä¾›ä¸€æ¡å®ç°åˆæ³•åˆè§„ã€åŠŸèƒ½å¯é ä¸”å¯è®¤è¯AIç³»ç»Ÿçš„å®è·µè·¯çº¿å›¾ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "63 pages, 27 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.08852v1",
      "published_date": "2025-09-08 17:52:08 UTC",
      "updated_date": "2025-09-08 17:52:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:55.640490+00:00"
    },
    {
      "arxiv_id": "2509.06938v2",
      "title": "From Noise to Narrative: Tracing the Origins of Hallucinations in Transformers",
      "title_zh": "ä»å™ªå£°åˆ°å™äº‹ï¼šæ¢ç©¶ Transformer å¹»è§‰çš„èµ·æº",
      "authors": [
        "Praneet Suresh",
        "Jack Stanley",
        "Sonia Joseph",
        "Luca Scimeca",
        "Danilo Bzdok"
      ],
      "abstract": "As generative AI systems become competent and democratized in science, business, and government, deeper insight into their failure modes now poses an acute need. The occasional volatility in their behavior, such as the propensity of transformer models to hallucinate, impedes trust and adoption of emerging AI solutions in high-stakes areas. In the present work, we establish how and when hallucinations arise in pre-trained transformer models through concept representations captured by sparse autoencoders, under scenarios with experimentally controlled uncertainty in the input space. Our systematic experiments reveal that the number of semantic concepts used by the transformer model grows as the input information becomes increasingly unstructured. In the face of growing uncertainty in the input space, the transformer model becomes prone to activate coherent yet input-insensitive semantic features, leading to hallucinated output. At its extreme, for pure-noise inputs, we identify a wide variety of robustly triggered and meaningful concepts in the intermediate activations of pre-trained transformer models, whose functional integrity we confirm through targeted steering. We also show that hallucinations in the output of a transformer model can be reliably predicted from the concept patterns embedded in transformer layer activations. This collection of insights on transformer internal processing mechanics has immediate consequences for aligning AI models with human values, AI safety, opening the attack surface for potential adversarial attacks, and providing a basis for automatic quantification of a model's hallucination risk.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Transformeræ¨¡å‹äº§ç”Ÿå¹»è§‰(hallucinations)çš„èµ·æºï¼Œæ—¨åœ¨æ·±å…¥ç†è§£ç”Ÿæˆå¼AIçš„å¤±æ•ˆæ¨¡å¼ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨(sparse autoencoders)æ•æ‰æ¦‚å¿µè¡¨ç¤ºï¼Œç³»ç»Ÿåˆ†æäº†åœ¨å—æ§è¾“å…¥ä¸ç¡®å®šæ€§ä¸‹æ¨¡å‹å†…éƒ¨çš„è¯­ä¹‰æ¿€æ´»ã€‚å®éªŒæ­ç¤ºï¼Œéšç€è¾“å…¥ä¿¡æ¯è¶Šå‘æ— åºï¼Œæ¨¡å‹è°ƒç”¨çš„è¯­ä¹‰æ¦‚å¿µæ•°é‡éšä¹‹å¢é•¿ï¼Œå¹¶å€¾å‘äºæ¿€æ´»è¿è´¯ä½†ä¸è¾“å…¥æ— å…³çš„è¯­ä¹‰ç‰¹å¾ï¼Œæœ€ç»ˆå¯¼è‡´å¹»è§‰è¾“å‡ºã€‚å³ä½¿é¢å¯¹çº¯å™ªå£°è¾“å…¥ï¼ŒTransformerçš„ä¸­é—´å±‚ä»ä¼šè§¦å‘ç¨³å¥ä¸”å…·æœ‰åŠŸèƒ½å®Œæ•´æ€§çš„æ„ä¹‰æ¦‚å¿µã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯æ˜å¯ä»¥é€šè¿‡å±‚æ¿€æ´»ä¸­çš„æ¦‚å¿µæ¨¡å¼æœ‰æ•ˆé¢„æµ‹å¹»è§‰çš„å‘ç”Ÿã€‚è¿™äº›å‘ç°ä¸ºè‡ªåŠ¨é‡åŒ–æ¨¡å‹å¹»è§‰é£é™©ã€æå‡AIå®‰å…¨æ€§å’Œå¯¹é½äººç±»ä»·å€¼è§‚æä¾›äº†å…³é”®çš„æœºæ¢°è§£é‡ŠåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06938v2",
      "published_date": "2025-09-08 17:50:45 UTC",
      "updated_date": "2025-11-20 21:59:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:12:59.032425+00:00"
    },
    {
      "arxiv_id": "2509.07054v2",
      "title": "Statistical Methods in Generative AI",
      "title_zh": "ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸­çš„ç»Ÿè®¡æ–¹æ³•",
      "authors": [
        "Edgar Dobriban"
      ],
      "abstract": "Generative Artificial Intelligence is emerging as an important technology, promising to be transformative in many areas. At the same time, generative AI techniques are based on sampling from probabilistic models, and by default, they come with no guarantees about correctness, safety, fairness, or other properties. Statistical methods offer a promising potential approach to improve the reliability of generative AI techniques. In addition, statistical methods are also promising for improving the quality and efficiency of AI evaluation, as well as for designing interventions and experiments in AI. In this paper, we review some of the existing work on these topics, explaining both the general statistical techniques used, as well as their applications to generative AI. We also discuss limitations and potential future directions.",
      "tldr_zh": "è¯¥ç»¼è¿°è®ºæ–‡æ¢è®¨äº†ç»Ÿè®¡æ–¹æ³•(Statistical Methods)åœ¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)ä¸­çš„å…³é”®ä½œç”¨ï¼Œå¼ºè°ƒäº†è¿™äº›æ–¹æ³•åœ¨è§£å†³ç”Ÿæˆå¼æ¨¡å‹ç¼ºä¹æ­£ç¡®æ€§ã€å®‰å…¨æ€§å’Œå…¬å¹³æ€§ä¿éšœæ–¹é¢çš„æ½œåŠ›ã€‚æ–‡ç« è¯¦ç»†å›é¡¾äº†å¦‚ä½•åˆ©ç”¨ç»Ÿè®¡æŠ€æœ¯æå‡ç”Ÿæˆå¼AIçš„å¯é æ€§ï¼Œå¹¶åˆ†æäº†å…¶åœ¨ä¼˜åŒ–AIè¯„ä¼°(AI evaluation)è´¨é‡ä¸æ•ˆç‡ï¼Œä»¥åŠè®¾è®¡AIå¹²é¢„å’Œå®éªŒæ–¹é¢çš„åº”ç”¨ã€‚ä½œè€…ä¸ä»…è§£é‡Šäº†é€šç”¨çš„ç»Ÿè®¡æŠ€æœ¯ï¼Œè¿˜å…·ä½“é˜è¿°äº†å®ƒä»¬åœ¨ç”Ÿæˆå¼AIåœºæ™¯ä¸‹çš„å®æ–½è·¯å¾„ã€‚é€šè¿‡å¯¹ç°æœ‰ç ”ç©¶çš„ç³»ç»Ÿæ¢³ç†ï¼Œè®ºæ–‡è¿›ä¸€æ­¥è®¨è®ºäº†å½“å‰çš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥è¯¥äº¤å‰é¢†åŸŸçš„ç ”ç©¶æ–¹å‘æä¾›äº†å‰ç»æ€§æŒ‡å¼•ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "Invited review paper for Annual Review of Statistics and Its Application. Feedback welcome",
      "pdf_url": "https://arxiv.org/pdf/2509.07054v2",
      "published_date": "2025-09-08 17:42:59 UTC",
      "updated_date": "2025-09-18 12:33:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:00.821339+00:00"
    },
    {
      "arxiv_id": "2509.06921v1",
      "title": "Neuro-Symbolic AI for Cybersecurity: State of the Art, Challenges, and Opportunities",
      "title_zh": "ç½‘ç»œå®‰å…¨é¢†åŸŸçš„ç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½ï¼šç°çŠ¶ã€æŒ‘æˆ˜ä¸æœºé‡",
      "authors": [
        "Safayat Bin Hakim",
        "Muhammad Adil",
        "Alvaro Velasquez",
        "Shouhuai Xu",
        "Houbing Herbert Song"
      ],
      "abstract": "Traditional Artificial Intelligence (AI) approaches in cybersecurity exhibit fundamental limitations: inadequate conceptual grounding leading to non-robustness against novel attacks; limited instructibility impeding analyst-guided adaptation; and misalignment with cybersecurity objectives. Neuro-Symbolic (NeSy) AI has emerged with the potential to revolutionize cybersecurity AI. However, there is no systematic understanding of this emerging approach. These hybrid systems address critical cybersecurity challenges by combining neural pattern recognition with symbolic reasoning, enabling enhanced threat understanding while introducing concerning autonomous offensive capabilities that reshape threat landscapes. In this survey, we systematically characterize this field by analyzing 127 publications spanning 2019-July 2025. We introduce a Grounding-Instructibility-Alignment (G-I-A) framework to evaluate these systems, focusing on both cyber defense and cyber offense across network security, malware analysis, and cyber operations. Our analysis shows advantages of multi-agent NeSy architectures and identifies critical implementation challenges including standardization gaps, computational complexity, and human-AI collaboration requirements that constrain deployment. We show that causal reasoning integration is the most transformative advancement, enabling proactive defense beyond correlation-based approaches. Our findings highlight dual-use implications where autonomous systems demonstrate substantial capabilities in zero-day exploitation while achieving significant cost reductions, altering threat dynamics. We provide insights and future research directions, emphasizing the urgent need for community-driven standardization frameworks and responsible development practices that ensure advancement serves defensive cybersecurity objectives while maintaining societal alignment.",
      "tldr_zh": "è¯¥ç»¼è¿°æ¢è®¨äº†ä¼ ç»Ÿäººå·¥æ™ºèƒ½(AI)åœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸå› æ¦‚å¿µåŸºç¡€ä¸è¶³ã€å¯æŒ‡å¯¼æ€§æœ‰é™åŠç›®æ ‡å¤±è°ƒå¯¼è‡´çš„å±€é™æ€§ï¼Œå¹¶ç³»ç»Ÿæ€§åœ°ä»‹ç»äº†ç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½(Neuro-Symbolic AI, NeSy AI)è¿™ä¸€æ··åˆç³»ç»Ÿçš„æ½œåŠ›ã€‚é€šè¿‡åˆ†æ2019å¹´è‡³2025å¹´é—´çš„127ç¯‡å­¦æœ¯æ–‡çŒ®ï¼Œç ”ç©¶è€…æå‡ºäº†Grounding-Instructibility-Alignment (G-I-A)æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°è¿™äº›ç³»ç»Ÿåœ¨ç½‘ç»œé˜²å¾¡ä¸è¿›æ”»ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°å¤šæ™ºèƒ½ä½“(Multi-agent)æ¶æ„å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸”å› æœæ¨ç†(Causal Reasoning)çš„é›†æˆè¢«è§†ä¸ºæœ€å…·å˜é©æ€§çš„è¿›å±•ï¼Œä½¿ä¸»åŠ¨é˜²å¾¡èƒ½å¤Ÿè¶…è¶Šä¼ ç»Ÿçš„å…³è”åˆ†æã€‚åŒæ—¶ï¼Œè®ºæ–‡æ­ç¤ºäº†è¯¥æŠ€æœ¯çš„åŒé‡ç”¨é€”å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨é›¶æ—¥æ¼æ´åˆ©ç”¨(Zero-day Exploitation)æ–¹é¢å±•ç°å‡ºçš„å¼ºå¤§è‡ªä¸»èƒ½åŠ›ã€‚å°½ç®¡NeSy AIèƒ½æ˜¾è‘—é™ä½æˆæœ¬å¹¶æå‡å¨èƒç†è§£ï¼Œä½†ä»é¢ä¸´æ ‡å‡†åŒ–ç¼ºå¤±ã€è®¡ç®—å¤æ‚åº¦å’Œäººæœºåä½œç­‰å®æ–½æŒ‘æˆ˜ã€‚ä½œè€…æœ€åå¼ºè°ƒï¼ŒäºŸéœ€å»ºç«‹ç¤¾åŒºé©±åŠ¨çš„æ ‡å‡†åŒ–æ¡†æ¶ä¸è´Ÿè´£ä»»çš„å¼€å‘å®è·µï¼Œä»¥ç¡®ä¿æŠ€æœ¯è¿›æ­¥ç¬¦åˆé˜²å¾¡æ€§å®‰å…¨ç›®æ ‡ä¸ç¤¾ä¼šä¸€è‡´æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06921v1",
      "published_date": "2025-09-08 17:33:59 UTC",
      "updated_date": "2025-09-08 17:33:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:15.131591+00:00"
    },
    {
      "arxiv_id": "2509.06920v2",
      "title": "An Ethically Grounded LLM-Based Approach to Insider Threat Synthesis and Detection",
      "title_zh": "ä¸€ç§éµå¾ªä¼¦ç†å‡†åˆ™çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å†…éƒ¨å¨èƒåˆæˆä¸æ£€æµ‹æ–¹æ³•",
      "authors": [
        "Haywood Gelman",
        "John D. Hastings",
        "David Kenley"
      ],
      "abstract": "Insider threats are a growing organizational problem due to the complexity of identifying their technical and behavioral elements. A large research body is dedicated to the study of insider threats from technological, psychological, and educational perspectives. However, research in this domain has been generally dependent on datasets that are static and limited access which restricts the development of adaptive detection models. This study introduces a novel, ethically grounded approach that uses the large language model (LLM) Claude Sonnet 3.7 to dynamically synthesize syslog messages, some of which contain indicators of insider threat scenarios. The messages reflect real-world data distributions by being highly imbalanced (1% insider threats). The syslogs were analyzed for insider threats by both Sonnet 3.7 and GPT-4o, with their performance evaluated through statistical metrics including accuracy, precision, recall, F1, specificity, FAR, MCC, and ROC AUC. Sonnet 3.7 consistently outperformed GPT-4o across nearly all metrics, particularly in reducing false alarms and improving detection accuracy. The results show strong promise for the use of LLMs in synthetic dataset generation and insider threat detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å†…éƒ¨å¨èƒ(Insider Threat)è¯†åˆ«ä¸­æŠ€æœ¯ä¸è¡Œä¸ºå…ƒç´ å¤æ‚ä»¥åŠç°æœ‰æ•°æ®é›†é™æ€ä¸”è®¿é—®å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„ä¼¦ç†åŒ–åˆæˆä¸æ£€æµ‹æ–¹æ³•ã€‚ç ”ç©¶åˆ©ç”¨ Claude Sonnet 3.7 åŠ¨æ€åˆæˆç³»ç»Ÿæ—¥å¿—(syslog)æ¶ˆæ¯ï¼Œå¹¶é€šè¿‡è®¾ç½®1%çš„å¨èƒå æ¯”æ¥æ¨¡æ‹Ÿæåº¦ä¸å¹³è¡¡çš„çœŸå®ä¸–ç•Œæ•°æ®åˆ†å¸ƒã€‚éšåï¼Œç ”ç©¶äººå‘˜åˆ†åˆ«ä½¿ç”¨ Sonnet 3.7 å’Œ GPT-4o å¯¹ç”Ÿæˆçš„æ—¥å¿—è¿›è¡Œåˆ†æï¼Œå¹¶é‡‡ç”¨ Accuracyã€Recallã€F1 å’Œ FAR ç­‰å¤šé¡¹ç»Ÿè®¡æŒ‡æ ‡è¿›è¡Œå…¨é¢è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSonnet 3.7 åœ¨å‡ ä¹æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡ä¼˜äº GPT-4oï¼Œå°¤å…¶åœ¨é™ä½è¯¯æŠ¥ç‡(False Alarms)å’Œæå‡æ£€æµ‹å‡†ç¡®æ€§æ–¹é¢è¡¨ç°çªå‡ºã€‚è¯¥é¡¹å·¥ä½œè¯æ˜äº† LLM åœ¨åˆæˆæ•°æ®é›†ç”Ÿæˆå’Œå†…éƒ¨å¨èƒæ£€æµ‹é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºå¼€å‘è‡ªé€‚åº”æ£€æµ‹æ¨¡å‹æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 5 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.06920v2",
      "published_date": "2025-09-08 17:32:17 UTC",
      "updated_date": "2025-10-01 15:55:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:17.137885+00:00"
    },
    {
      "arxiv_id": "2509.06918v1",
      "title": "Tackling the Noisy Elephant in the Room: Label Noise-robust Out-of-Distribution Detection via Loss Correction and Low-rank Decomposition",
      "title_zh": "åº”å¯¹â€œæˆ¿é—´é‡Œåµé—¹çš„å¤§è±¡â€ï¼šåŸºäºæŸå¤±ä¿®æ­£ä¸ä½ç§©åˆ†è§£çš„æ ‡ç­¾å™ªå£°é²æ£’åˆ†å¸ƒå¤–æ£€æµ‹",
      "authors": [
        "Tarhib Al Azad",
        "Shahana Ibrahim"
      ],
      "abstract": "Robust out-of-distribution (OOD) detection is an indispensable component of modern artificial intelligence (AI) systems, especially in safety-critical applications where models must identify inputs from unfamiliar classes not seen during training. While OOD detection has been extensively studied in the machine learning literature--with both post hoc and training-based approaches--its effectiveness under noisy training labels remains underexplored. Recent studies suggest that label noise can significantly degrade OOD performance, yet principled solutions to this issue are lacking. In this work, we demonstrate that directly combining existing label noise-robust methods with OOD detection strategies is insufficient to address this critical challenge. To overcome this, we propose a robust OOD detection framework that integrates loss correction techniques from the noisy label learning literature with low-rank and sparse decomposition methods from signal processing. Extensive experiments on both synthetic and real-world datasets demonstrate that our method significantly outperforms the state-of-the-art OOD detection techniques, particularly under severe noisy label settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ ‡ç­¾å™ªå£°ï¼ˆLabel Noiseï¼‰æ˜¾è‘—é™ä½ Out-of-Distribution (OOD) æ£€æµ‹æ€§èƒ½çš„ç°çŠ¶ï¼Œæ¢è®¨äº†åœ¨ä¸ç¡®å®šè®­ç»ƒç¯å¢ƒä¸‹æå‡ AI ç³»ç»Ÿå¯é æ€§çš„æ–¹æ³•ã€‚ä½œè€…æŒ‡å‡ºç›´æ¥ç»“åˆç°æœ‰çš„å™ªå£°é²æ£’æŠ€æœ¯ä¸ OOD ç­–ç•¥æ•ˆæœæœ‰é™ï¼Œå› æ­¤æå‡ºäº†ä¸€ç§æ•´åˆ Loss Correction æŸå¤±ä¿®æ­£ä¸ Low-rank and Sparse Decomposition ä½ç§©ç¨€ç–åˆ†è§£çš„åˆ›æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¿¡å·å¤„ç†ä¸­çš„ä½ç§©ç‰¹æ€§æ¥æ•æ‰æ ¸å¿ƒç‰¹å¾ï¼Œå¹¶ç»“åˆæŸå¤±ä¿®æ­£æŠ€æœ¯åº”å¯¹æ ‡ç­¾å¹²æ‰°ï¼Œä»è€Œå®ç°æ›´ç¨³å¥çš„åˆ†å¸ƒå¤–æ£€æµ‹ã€‚åœ¨åˆæˆæ•°æ®é›†ä¸çœŸå®åœºæ™¯ä¸‹çš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸¥é‡å™ªå£°å¹²æ‰°ä¸‹ä¾ç„¶èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„ SOTA æ£€æµ‹æŠ€æœ¯ã€‚è¿™ä¸€ç ”ç©¶ä¸ºè§£å†³å®‰å…¨æ•æ„Ÿåº”ç”¨ä¸­çš„æ ‡ç­¾è´¨é‡ä¸æ¨¡å‹é²æ£’æ€§å†²çªæä¾›äº†å…³é”®çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06918v1",
      "published_date": "2025-09-08 17:28:59 UTC",
      "updated_date": "2025-09-08 17:28:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:32.745736+00:00"
    },
    {
      "arxiv_id": "2509.06917v2",
      "title": "Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents",
      "title_zh": "Paper2Agentï¼šå°†ç§‘ç ”è®ºæ–‡é‡å¡‘ä¸ºäº¤äº’å¼ä¸”å¯é çš„ AI æ™ºèƒ½ä½“",
      "authors": [
        "Jiacheng Miao",
        "Joe R. Davis",
        "Yaohui Zhang",
        "Jonathan K. Pritchard",
        "James Zou"
      ],
      "abstract": "We introduce Paper2Agent, an automated framework that converts research papers into AI agents. Paper2Agent transforms research output from passive artifacts into active systems that can accelerate downstream use, adoption, and discovery. Conventional research papers require readers to invest substantial effort to understand and adapt a paper's code, data, and methods to their own work, creating barriers to dissemination and reuse. Paper2Agent addresses this challenge by automatically converting a paper into an AI agent that acts as a knowledgeable research assistant. It systematically analyzes the paper and the associated codebase using multiple agents to construct a Model Context Protocol (MCP) server, then iteratively generates and runs tests to refine and robustify the resulting MCP. These paper MCPs can then be flexibly connected to a chat agent (e.g. Claude Code) to carry out complex scientific queries through natural language while invoking tools and workflows from the original paper. We demonstrate Paper2Agent's effectiveness in creating reliable and capable paper agents through in-depth case studies. Paper2Agent created an agent that leverages AlphaGenome to interpret genomic variants and agents based on ScanPy and TISSUE to carry out single-cell and spatial transcriptomics analyses. We validate that these paper agents can reproduce the original paper's results and can correctly carry out novel user queries. Paper2Agent automatically created AI co-scientist that identified new splicing variant associated with ADHD risk. By turning static papers into dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for knowledge dissemination and a foundation for the collaborative ecosystem of AI co-scientists.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Paper2Agentï¼Œè¿™æ˜¯ä¸€ä¸ªå°†ç ”ç©¶è®ºæ–‡è‡ªåŠ¨è½¬åŒ–ä¸ºAI agentsçš„è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè®ºæ–‡ä½œä¸ºè¢«åŠ¨æˆæœéš¾ä»¥è¢«ä¸‹æ¸¸åº”ç”¨å’Œå¤ç”¨çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆ†æè®ºæ–‡åŠå…¶ä»£ç åº“ï¼Œæ„å»ºModel Context Protocol (MCP)æœåŠ¡å™¨ï¼Œå¹¶é€šè¿‡è¿­ä»£ç”Ÿæˆå’Œæµ‹è¯•æ¥ä¼˜åŒ–å…¶ç¨³å¥æ€§ï¼Œä½¿ç”¨æˆ·èƒ½é€šè¿‡è‡ªç„¶è¯­è¨€è°ƒç”¨è®ºæ–‡åŸå§‹å·¥å…·æ‰§è¡Œå¤æ‚çš„ç§‘å­¦æŸ¥è¯¢ã€‚é€šè¿‡AlphaGenomeã€ScanPyå’ŒTISSUEçš„æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯æ˜äº†ç”Ÿæˆçš„æ™ºèƒ½ä½“ä¸ä»…èƒ½å¤ç°åŸè®ºæ–‡ç»“æœï¼Œè¿˜èƒ½å¤„ç†æ–°çš„ç”¨æˆ·æŒ‡ä»¤ã€‚å®éªŒä¸­ï¼ŒPaper2Agentç”Ÿæˆçš„AI co-scientistæˆåŠŸè¯†åˆ«äº†ä¸ADHDé£é™©ç›¸å…³çš„æ–°å‰ªæ¥å˜ä½“(splicing variant)ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…ç§‘ç ”å‘ç°ä¸­çš„æ½œåŠ›ã€‚é€šè¿‡å°†é™æ€è®ºæ–‡è½¬å˜ä¸ºåŠ¨æ€ã€å¯äº¤äº’çš„æ™ºèƒ½ç³»ç»Ÿï¼ŒPaper2Agentä¸ºçŸ¥è¯†ä¼ æ’­å’Œäººå·¥æ™ºèƒ½ååŒç§‘ç ”çš„æ–°èŒƒå¼å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06917v2",
      "published_date": "2025-09-08 17:28:42 UTC",
      "updated_date": "2025-10-16 14:09:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:26.947216+00:00"
    },
    {
      "arxiv_id": "2509.06885v1",
      "title": "Barlow-Swin: Toward a novel siamese-based segmentation architecture using Swin-Transformers",
      "title_zh": "Barlow-Swinï¼šä¸€ç§åŸºäº Swin-Transformer çš„æ–°å‹å­ªç”Ÿåˆ†å‰²æ¶æ„",
      "authors": [
        "Morteza Kiani Haftlang",
        "Mohammadhossein Malmir",
        "Foroutan Parand",
        "Umberto Michelucci",
        "Safouane El Ghazouali"
      ],
      "abstract": "Medical image segmentation is a critical task in clinical workflows, particularly for the detection and delineation of pathological regions. While convolutional architectures like U-Net have become standard for such tasks, their limited receptive field restricts global context modeling. Recent efforts integrating transformers have addressed this, but often result in deep, computationally expensive models unsuitable for real-time use. In this work, we present a novel end-to-end lightweight architecture designed specifically for real-time binary medical image segmentation. Our model combines a Swin Transformer-like encoder with a U-Net-like decoder, connected via skip pathways to preserve spatial detail while capturing contextual information. Unlike existing designs such as Swin Transformer or U-Net, our architecture is significantly shallower and competitively efficient. To improve the encoder's ability to learn meaningful features without relying on large amounts of labeled data, we first train it using Barlow Twins, a self-supervised learning method that helps the model focus on important patterns by reducing unnecessary repetition in the learned features. After this pretraining, we fine-tune the entire model for our specific task. Experiments on benchmark binary segmentation tasks demonstrate that our model achieves competitive accuracy with substantially reduced parameter count and faster inference, positioning it as a practical alternative for deployment in real-time and resource-limited clinical environments. The code for our method is available at Github repository: https://github.com/mkianih/Barlow-Swin.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†Barlow-Swinï¼Œä¸€ç§ä¸“ä¸ºå®æ—¶äºŒå€¼åŒ»å­¦å›¾åƒåˆ†å‰²(binary medical image segmentation)è®¾è®¡çš„è½»é‡åŒ–ç«¯åˆ°ç«¯æ¶æ„ã€‚è¯¥æ¨¡å‹å°†ç±»Swin Transformerçš„ç¼–ç å™¨ä¸ç±»U-Netçš„è§£ç å™¨ç›¸ç»“åˆï¼Œå¹¶é€šè¿‡è·³è·ƒè¿æ¥(skip pathways)åœ¨æ•è·ä¸Šä¸‹æ–‡ä¿¡æ¯çš„åŒæ—¶ä¿ç•™ç©ºé—´ç»†èŠ‚ã€‚ä¸ºäº†åœ¨å‡å°‘å¯¹æ ‡æ³¨æ•°æ®ä¾èµ–çš„åŒæ—¶æå‡ç‰¹å¾æå–èƒ½åŠ›ï¼Œç ”ç©¶è€…é¦–å…ˆåˆ©ç”¨Barlow Twinsè‡ªç›‘ç£å­¦ä¹ (self-supervised learning)æ–¹æ³•å¯¹ç¼–ç å™¨è¿›è¡Œé¢„è®­ç»ƒï¼Œé€šè¿‡å‡å°‘ç‰¹å¾å†—ä½™æ¥èšç„¦å…³é”®æ¨¡å¼ã€‚ä¸ä¼ ç»Ÿçš„U-Netæˆ–æ·±åº¦Transformeræ¶æ„ç›¸æ¯”ï¼ŒBarlow-Swinåœ¨ä¿æŒç½‘ç»œè¾ƒæµ…çš„åŒæ—¶æ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤§å¹…å‡å°‘å‚æ•°é‡å¹¶åŠ å¿«æ¨ç†é€Ÿåº¦çš„å‰æä¸‹ï¼Œä¾ç„¶åœ¨åŸºå‡†åˆ†å‰²ä»»åŠ¡ä¸Šå®ç°äº†æå…·ç«äº‰åŠ›çš„å‡†ç¡®ç‡ã€‚è¿™ä½¿å¾—Barlow-Swinæˆä¸ºèµ„æºå—é™çš„ä¸´åºŠç¯å¢ƒä¸­è¿›è¡Œå®æ—¶éƒ¨ç½²çš„å®ç”¨æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06885v1",
      "published_date": "2025-09-08 17:05:53 UTC",
      "updated_date": "2025-09-08 17:05:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:28.035004+00:00"
    },
    {
      "arxiv_id": "2509.06883v1",
      "title": "UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction",
      "title_zh": "UNH åœ¨ CheckThat! 2025ï¼šå£°æ˜æå–ä¸­çš„å¾®è°ƒä¸æç¤ºå¯¹æ¯”",
      "authors": [
        "Joe Wilder",
        "Nikhil Kadapala",
        "Benji Xu",
        "Mohammed Alsaadi",
        "Aiden Parsons",
        "Mitchell Rogers",
        "Palash Agarwal",
        "Adam Hassick",
        "Laura Dietz"
      ],
      "abstract": "We participate in CheckThat! Task 2 English and explore various methods of prompting and in-context learning, including few-shot prompting and fine-tuning with different LLM families, with the goal of extracting check-worthy claims from social media passages. Our best METEOR score is achieved by fine-tuning a FLAN-T5 model. However, we observe that higher-quality claims can sometimes be extracted using other methods, even when their METEOR scores are lower.",
      "tldr_zh": "è¯¥ç ”ç©¶å‚åŠ äº† CheckThat! 2025 Task 2 English ä»»åŠ¡ï¼Œæ—¨åœ¨ä»ç¤¾äº¤åª’ä½“æ–‡æœ¬ä¸­æå–å…·æœ‰æŸ¥è¯ä»·å€¼çš„å£°æ˜ (check-worthy claims)ã€‚ä½œè€…æ¢ç´¢äº†å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) çš„å¤„ç†æ–¹æ³•ï¼ŒåŒ…æ‹¬æç¤ºè¯å·¥ç¨‹ (Prompting)ã€ä¸Šä¸‹æ–‡å­¦ä¹  (In-context learning)ã€å°‘æ ·æœ¬æç¤º (Few-shot prompting) ä»¥åŠé’ˆå¯¹ä¸åŒæ¨¡å‹å®¶æ—çš„å¾®è°ƒ (Fine-tuning)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡å¾®è°ƒ FLAN-T5 æ¨¡å‹ï¼Œç ”ç©¶å›¢é˜Ÿè·å¾—äº†æœ€ä½³çš„ METEOR è¯„åˆ†ã€‚ç„¶è€Œï¼Œç ”ç©¶å‘ç° METEOR è¯„åˆ†å¹¶ä¸æ€»æ˜¯ä¸å£°æ˜è´¨é‡å®Œå…¨æ­£ç›¸å…³ï¼ŒæŸäº›è¯„åˆ†è¾ƒä½çš„æ–¹æ³•æœ‰æ—¶èƒ½æå–å‡ºæ›´é«˜è´¨é‡çš„å£°æ˜ã€‚è¯¥é¡¹å·¥ä½œç³»ç»Ÿå¯¹æ¯”äº†å¾®è°ƒä¸æç¤ºè¯æŠ€æœ¯åœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæå‡ç¤¾äº¤åª’ä½“ä¿¡æ¯æ ¸æŸ¥çš„å‡†ç¡®æ€§æä¾›äº†å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages,3 tables, CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain",
      "pdf_url": "https://arxiv.org/pdf/2509.06883v1",
      "published_date": "2025-09-08 17:02:34 UTC",
      "updated_date": "2025-09-08 17:02:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:29.331921+00:00"
    },
    {
      "arxiv_id": "2509.12234v1",
      "title": "Flexible Multimodal Neuroimaging Fusion for Alzheimer's Disease Progression Prediction",
      "title_zh": "ç”¨äºé˜¿å°”èŒ¨æµ·é»˜ç—…è¿›å±•é¢„æµ‹çš„çµæ´»å¤šæ¨¡æ€ç¥ç»å½±åƒèåˆ",
      "authors": [
        "Benjamin Burns",
        "Yuan Xue",
        "Douglas W. Scharre",
        "Xia Ning"
      ],
      "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative disease with high inter-patient variance in rate of cognitive decline. AD progression prediction aims to forecast patient cognitive decline and benefits from incorporating multiple neuroimaging modalities. However, existing multimodal models fail to make accurate predictions when many modalities are missing during inference, as is often the case in clinical settings. To increase multimodal model flexibility under high modality missingness, we introduce PerM-MoE, a novel sparse mixture-of-experts method that uses independent routers for each modality in place of the conventional, single router. Using T1-weighted MRI, FLAIR, amyloid beta PET, and tau PET neuroimaging data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), we evaluate PerM-MoE, state-of-the-art Flex-MoE, and unimodal neuroimaging models on predicting two-year change in Clinical Dementia Rating-Sum of Boxes (CDR-SB) scores under varying levels of modality missingness. PerM-MoE outperforms the state of the art in most variations of modality missingness and demonstrates more effective utility of experts than Flex-MoE.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿å°”èŒ¨æµ·é»˜ç—… (AD) è¿›å±•é¢„æµ‹ä¸­å¸¸è§çš„æ¨¡æ€ç¼ºå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º PerM-MoE çš„æ–°å‹ç¨€ç–æ··åˆä¸“å®¶æ¨¡å‹ (Sparse Mixture-of-Experts)ã€‚é’ˆå¯¹ä¸´åºŠç¯å¢ƒä¸‹å¤šæ¨¡æ€ç¥ç»å½±åƒæ•°æ®å¾€å¾€ä¸å®Œæ•´çš„æƒ…å†µï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¸ºæ¯ç§æ¨¡æ€é…ç½®ç‹¬ç«‹çš„è·¯ç”±å™¨å–ä»£äº†ä¼ ç»Ÿçš„å•ä¸€è·¯ç”±å™¨è®¾è®¡ï¼Œä»è€Œå¢å¼ºäº†å¤šæ¨¡æ€èåˆåœ¨æ¨æ–­é˜¶æ®µçš„çµæ´»æ€§ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨æ¥è‡ª ADNI æ•°æ®åº“çš„ T1-weighted MRIã€FLAIRã€amyloid beta PET ä»¥åŠ tau PET æ•°æ®ï¼Œè¯„ä¼°äº†æ¨¡å‹åœ¨é¢„æµ‹ä¸´åºŠç—´å‘†è¯„åˆ†æ€»å’Œ (CDR-SB) ä¸¤å¹´å˜åŒ–å€¼æ–¹é¢çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒPerM-MoE åœ¨å¤šç§æ¨¡æ€ç¼ºå¤±åœºæ™¯ä¸‹çš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„ Flex-MoE æ¶æ„åŠå•æ¨¡æ€æ¨¡å‹ï¼Œå±•ç°äº†æ›´é«˜çš„ä¸“å®¶åˆ©ç”¨æ•ˆç‡å’Œæ›´å¼ºçš„é²æ£’æ€§ï¼Œä¸ºä¸´åºŠå®é™…åœºæ™¯ä¸‹çš„ AD ç—…æƒ…è¯„ä¼°æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Applications of Medical AI 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.12234v1",
      "published_date": "2025-09-08 16:59:23 UTC",
      "updated_date": "2025-09-08 16:59:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:39.128450+00:00"
    },
    {
      "arxiv_id": "2509.06875v1",
      "title": "AxelSMOTE: An Agent-Based Oversampling Algorithm for Imbalanced Classification",
      "title_zh": "AxelSMOTEï¼šåŸºäºæ™ºèƒ½ä½“çš„ä¸å¹³è¡¡åˆ†ç±»è¿‡é‡‡æ ·ç®—æ³•",
      "authors": [
        "Sukumar Kishanthan",
        "Asela Hevapathige"
      ],
      "abstract": "Class imbalance in machine learning poses a significant challenge, as skewed datasets often hinder performance on minority classes. Traditional oversampling techniques, which are commonly used to alleviate class imbalance, have several drawbacks: they treat features independently, lack similarity-based controls, limit sample diversity, and fail to manage synthetic variety effectively. To overcome these issues, we introduce AxelSMOTE, an innovative agent-based approach that views data instances as autonomous agents engaging in complex interactions. Based on Axelrod's cultural dissemination model, AxelSMOTE implements four key innovations: (1) trait-based feature grouping to preserve correlations; (2) a similarity-based probabilistic exchange mechanism for meaningful interactions; (3) Beta distribution blending for realistic interpolation; and (4) controlled diversity injection to avoid overfitting. Experiments on eight imbalanced datasets demonstrate that AxelSMOTE outperforms state-of-the-art sampling methods while maintaining computational efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ ä¸­ç±»åˆ«ä¸å¹³è¡¡ (Class imbalance) å¯¼è‡´å°‘æ•°ç±»æ€§èƒ½å—é™çš„é—®é¢˜ï¼Œæå‡ºäº† AxelSMOTEï¼Œä¸€ç§åŸºäºæ™ºèƒ½ä½“ (Agent-Based) çš„åˆ›æ–°è¿‡é‡‡æ ·ç®—æ³•ã€‚è¯¥æ–¹æ³•å°†æ•°æ®å®ä¾‹è§†ä¸ºåŸºäº Axelrod æ–‡åŒ–ä¼ æ’­æ¨¡å‹è¿›è¡Œå¤æ‚äº¤äº’çš„è‡ªä¸»æ™ºèƒ½ä½“ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿé‡‡æ ·æŠ€æœ¯åœ¨ç‰¹å¾ç›¸å…³æ€§ä¿ç•™å’Œæ ·æœ¬å¤šæ ·æ€§ç®¡ç†æ–¹é¢çš„å±€é™ã€‚AxelSMOTE å¼•å…¥äº†åŸºäºæ€§çŠ¶çš„ç‰¹å¾åˆ†ç»„ã€åŸºäºç›¸ä¼¼æ€§çš„æ¦‚ç‡äº¤æ¢æœºåˆ¶ã€Beta distribution æ··åˆæ’å€¼ä»¥åŠå—æ§çš„å¤šæ ·æ€§æ³¨å…¥ç­‰å››å¤§æ ¸å¿ƒåˆ›æ–°ã€‚åœ¨å…«ä¸ªä¸å¹³è¡¡æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒAxelSMOTE åœ¨æ˜¾è‘—ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„é‡‡æ ·æ–¹æ³•çš„åŒæ—¶ï¼Œä¾ç„¶ä¿æŒäº†è‰¯å¥½çš„è®¡ç®—æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06875v1",
      "published_date": "2025-09-08 16:47:33 UTC",
      "updated_date": "2025-09-08 16:47:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:40.834500+00:00"
    },
    {
      "arxiv_id": "2509.06863v2",
      "title": "floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL",
      "title_zh": "floqï¼šåœ¨åŸºäºä»·å€¼çš„å¼ºåŒ–å­¦ä¹ ä¸­é€šè¿‡æµåŒ¹é…è®­ç»ƒè¯„è®ºå®¶ä»¥å®ç°è®¡ç®—æ‰©å±•",
      "authors": [
        "Bhavya Agrawalla",
        "Michal Nauman",
        "Khush Agrawal",
        "Aviral Kumar"
      ],
      "abstract": "A hallmark of modern large-scale machine learning techniques is the use of training objectives that provide dense supervision to intermediate computations, such as teacher forcing the next token in language models or denoising step-by-step in diffusion models. This enables models to learn complex functions in a generalizable manner. Motivated by this observation, we investigate the benefits of iterative computation for temporal difference (TD) methods in reinforcement learning (RL). Typically they represent value functions in a monolithic fashion, without iterative compute. We introduce floq (flow-matching Q-functions), an approach that parameterizes the Q-function using a velocity field and trains it using techniques from flow-matching, typically used in generative modeling. This velocity field underneath the flow is trained using a TD-learning objective, which bootstraps from values produced by a target velocity field, computed by running multiple steps of numerical integration. Crucially, floq allows for more fine-grained control and scaling of the Q-function capacity than monolithic architectures, by appropriately setting the number of integration steps. Across a suite of challenging offline RL benchmarks and online fine-tuning tasks, floq improves performance by nearly 1.8x. floq scales capacity far better than standard TD-learning architectures, highlighting the potential of iterative computation for value learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† floq (flow-matching Q-functions)ï¼Œæ—¨åœ¨é€šè¿‡å¼•å…¥è¿­ä»£è®¡ç®—è§£å†³ Reinforcement Learning (RL) ä¸­ Temporal Difference (TD) æ–¹æ³•é€šå¸¸é‡‡ç”¨å•ä½“æ¶æ„ (monolithic fashion) è€Œéš¾ä»¥æ‰©å±•çš„é—®é¢˜ã€‚floq ä½¿ç”¨ velocity field å¯¹ Q-function è¿›è¡Œå‚æ•°åŒ–ï¼Œå¹¶ç»“åˆç”Ÿæˆæ¨¡å‹ä¸­å¸¸ç”¨çš„ Flow-Matching æŠ€æœ¯è¿›è¡Œè®­ç»ƒã€‚å…¶ velocity field é‡‡ç”¨ TD-learning ç›®æ ‡å‡½æ•°ï¼Œå¹¶ä»é€šè¿‡å¤šæ­¥æ•°å€¼ç§¯åˆ† (numerical integration) å¾—åˆ°çš„ç›®æ ‡ velocity field ç”Ÿæˆçš„æ•°å€¼ä¸­è¿›è¡Œå¼•å¯¼ (bootstrapping)ã€‚ä¸ä¼ ç»Ÿæ¶æ„ç›¸æ¯”ï¼Œfloq èƒ½å¤Ÿé€šè¿‡çµæ´»è®¾ç½®ç§¯åˆ†æ­¥æ•°ï¼Œå®ç°å¯¹ Q-function å®¹é‡æ›´ç²¾ç»†çš„æ§åˆ¶ä¸æ‰©å±•ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨å¤šé¡¹æŒ‘æˆ˜æ€§çš„ offline RL åŸºå‡†æµ‹è¯•å’Œ online fine-tuning ä»»åŠ¡ä¸­ï¼Œfloq å°†æ¨¡å‹æ€§èƒ½æå‡äº†çº¦ 1.8 å€ã€‚è¯¥æˆæœè¯æ˜äº† floq åœ¨æ‰©å±•èƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºæ ‡å‡†çš„ TD-learning æ¶æ„ï¼Œå……åˆ†å±•ç¤ºäº†è¿­ä»£è®¡ç®—åœ¨ä»·å€¼å­¦ä¹  (value learning) é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Added new experiments, fixed typos. Code -- https://github.com/CMU-AIRe/floq",
      "pdf_url": "https://arxiv.org/pdf/2509.06863v2",
      "published_date": "2025-09-08 16:31:09 UTC",
      "updated_date": "2025-10-23 14:41:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:44.419614+00:00"
    },
    {
      "arxiv_id": "2509.06861v1",
      "title": "Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet",
      "title_zh": "æ¨ç†æ¨¡å‹ä¸­çš„æµ‹è¯•æ—¶ç¼©æ”¾å¯¹çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡å°šæœªå¥æ•ˆ",
      "authors": [
        "James Xu Zhao",
        "Bryan Hooi",
        "See-Kiong Ng"
      ],
      "abstract": "Test-time scaling increases inference-time computation by allowing models to generate long reasoning chains, and has shown strong performance across many domains. However, in this work, we show that this approach is not yet effective for knowledge-intensive tasks, where high factual accuracy and low hallucination rates are essential. We conduct a comprehensive evaluation of test-time scaling using 12 reasoning models on two knowledge-intensive benchmarks. Our results reveal that increasing test-time computation does not consistently improve accuracy and, in many cases, it even leads to more hallucinations. We then analyze how extended reasoning affects hallucination behavior. We find that reduced hallucinations often result from the model choosing to abstain after thinking more, rather than from improved factual recall. Conversely, for some models, longer reasoning encourages attempts on previously unanswered questions, many of which result in hallucinations. Case studies show that extended reasoning can induce confirmation bias, leading to overconfident hallucinations. Despite these limitations, we observe that compared to non-thinking, enabling thinking remains beneficial. Code and data are available at https://github.com/XuZhao0/tts-knowledge",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¨ç†æ¨¡å‹ä¸­çš„æµ‹è¯•æ—¶ç¼©æ”¾(Test-Time Scaling)åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡(Knowledge-Intensive Tasks)ä¸­çš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶è€…å¯¹12ä¸ªæ¨ç†æ¨¡å‹åœ¨ä¸¤ä¸ªçŸ¥è¯†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œåˆ†æäº†æ¨ç†é“¾é•¿åº¦ä¸äº‹å®å‡†ç¡®æ€§åŠå¹»è§‰(Hallucination)ç‡ä¹‹é—´çš„å…³ç³»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¢åŠ æ¨ç†é˜¶æ®µçš„è®¡ç®—é‡å¹¶ä¸èƒ½æŒç»­æé«˜æ¨¡å‹å‡†ç¡®ç‡ï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹åè€Œä¼šå¯¼è‡´æ›´é«˜é¢‘ç‡çš„å¹»è§‰ã€‚ç ”ç©¶å‘ç°ï¼Œæ¨ç†æ—¶é—´çš„å»¶é•¿æœ‰æ—¶ä¼šå¯¼è‡´æ¨¡å‹äº§ç”Ÿç¡®è®¤åå·®(Confirmation Bias)ï¼Œä»è€Œå¼•å‘è¿‡åº¦è‡ªä¿¡çš„å¹»è§‰ï¼Œæˆ–è€…è¯±å¯¼æ¨¡å‹å°è¯•å›ç­”åŸæœ¬æ— æ³•å›ç­”çš„é—®é¢˜ã€‚è™½ç„¶å¹»è§‰çš„å‡å°‘åœ¨æŸäº›æƒ…å†µä¸‹æºäºæ¨¡å‹æ€è€ƒåé€‰æ‹©å¼ƒæƒè€Œéäº‹å®æ£€ç´¢èƒ½åŠ›çš„å¢å¼ºï¼Œä½†ç ”ç©¶å¼ºè°ƒç›¸æ¯”å®Œå…¨ä¸è¿›è¡Œæ€è€ƒï¼Œå¼€å¯æ€è€ƒæ¨¡å¼(Thinking)å¯¹æ¨¡å‹æ€§èƒ½ä»æœ‰ç›Šå¤„ã€‚è¯¥é¡¹å·¥ä½œæ­ç¤ºäº†å½“å‰æ¨ç†æ¨¡å‹åœ¨å¤„ç†å¯¹äº‹å®æ€§è¦æ±‚æé«˜ä»»åŠ¡æ—¶çš„å±€é™æ€§ï¼Œä¸ºæœªæ¥ä¼˜åŒ–æ¨ç†ç­–ç•¥æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 4 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.06861v1",
      "published_date": "2025-09-08 16:28:25 UTC",
      "updated_date": "2025-09-08 16:28:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:13:45.728969+00:00"
    },
    {
      "arxiv_id": "2509.06858v1",
      "title": "Disentangling Interaction and Bias Effects in Opinion Dynamics of Large Language Models",
      "title_zh": "è§£è€¦å¤§è¯­è¨€æ¨¡å‹è§‚ç‚¹åŠ¨åŠ›å­¦ä¸­çš„äº¤äº’ä¸åå·®æ•ˆåº”",
      "authors": [
        "Vincent C. Brockers",
        "David A. Ehrlich",
        "Viola Priesemann"
      ],
      "abstract": "Large Language Models are increasingly used to simulate human opinion dynamics, yet the effect of genuine interaction is often obscured by systematic biases. We present a Bayesian framework to disentangle and quantify three such biases: (i) a topic bias toward prior opinions in the training data; (ii) an agreement bias favoring agreement irrespective of the question; and (iii) an anchoring bias toward the initiating agent's stance. Applying this framework to multi-step dialogues reveals that opinion trajectories tend to quickly converge to a shared attractor, with the influence of the interaction fading over time, and the impact of biases differing between LLMs. In addition, we fine-tune an LLM on different sets of strongly opinionated statements (incl. misinformation) and demonstrate that the opinion attractor shifts correspondingly. Exposing stark differences between LLMs and providing quantitative tools to compare them to human subjects in the future, our approach highlights both chances and pitfalls in using LLMs as proxies for human behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªBayesian frameworkï¼Œæ—¨åœ¨åŒºåˆ†å¹¶é‡åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨¡æ‹Ÿäººç±»è§‚ç‚¹æ¼”åŒ–ï¼ˆOpinion Dynamicsï¼‰è¿‡ç¨‹ä¸­çš„ä¸‰ç§ç³»ç»Ÿæ€§åå·®ï¼ŒåŒ…æ‹¬åŸºäºè®­ç»ƒæ•°æ®çš„ä¸»é¢˜åå·®ï¼ˆTopic Biasï¼‰ã€å€¾å‘ä¸€è‡´æ€§çš„åè®®åå·®ï¼ˆAgreement Biasï¼‰ä»¥åŠé’ˆå¯¹åˆå§‹ç«‹åœºçš„é”šå®šåå·®ï¼ˆAnchoring Biasï¼‰ã€‚é€šè¿‡åˆ†æå¤šè½®å¯¹è¯ï¼Œç ”ç©¶å‘ç°è§‚ç‚¹è½¨è¿¹å¾€å¾€ä¼šè¿…é€Ÿæ”¶æ•›è‡³ä¸€ä¸ªå…±äº«å¸å¼•å­ï¼ˆShared Attractorï¼‰ï¼Œæ­¤æ—¶äº¤äº’çš„å½±å“ä¼šéšæ—¶é—´é€æ¸å‡å¼±ï¼Œä¸”ä¸åŒLLMså—è¿™äº›åå·®å½±å“çš„ç¨‹åº¦å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶é€šè¿‡åœ¨å¸¦æœ‰å¼ºçƒˆè§‚ç‚¹æˆ–é”™è¯¯ä¿¡æ¯çš„è¯­å¥ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè¯å®äº†è§‚ç‚¹å¸å¼•å­ä¼šéšè®­ç»ƒæ•°æ®å‘ç”Ÿåç§»ã€‚è¯¥æ–¹æ³•æ­ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨æ¨¡æ‹Ÿäººç±»ç¤¾ä¼šè¡Œä¸ºæ—¶çš„ç‰¹æ€§å·®å¼‚ï¼Œä¸ºè¯„ä¼°LLMsä½œä¸ºäººç±»è¡Œä¸ºä»£ç†çš„å¯é æ€§ä¸æ½œåœ¨é£é™©æä¾›äº†å®šé‡åˆ†æå·¥å…·ã€‚",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "nlin.AO"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06858v1",
      "published_date": "2025-09-08 16:26:45 UTC",
      "updated_date": "2025-09-08 16:26:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:00.228920+00:00"
    },
    {
      "arxiv_id": "2509.06854v1",
      "title": "Automated Radiographic Total Sharp Score (ARTSS) in Rheumatoid Arthritis: A Solution to Reduce Inter-Intra Reader Variation and Enhancing Clinical Practice",
      "title_zh": "ç±»é£æ¹¿å…³èŠ‚ç‚è‡ªåŠ¨æ”¾å°„å­¦æ€» Sharp è¯„åˆ† (ARTSS)ï¼šä¸€ç§å‡å°‘é˜…ç‰‡è€…é—´åŠå†…éƒ¨å·®å¼‚å¹¶æå‡ä¸´åºŠå®è·µçš„è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Hajar Moradmand",
        "Lei Ren"
      ],
      "abstract": "Assessing the severity of rheumatoid arthritis (RA) using the Total Sharp/Van Der Heijde Score (TSS) is crucial, but manual scoring is often time-consuming and subjective. This study introduces an Automated Radiographic Sharp Scoring (ARTSS) framework that leverages deep learning to analyze full-hand X-ray images, aiming to reduce inter- and intra-observer variability. The research uniquely accommodates patients with joint disappearance and variable-length image sequences. We developed ARTSS using data from 970 patients, structured into four stages: I) Image pre-processing and re-orientation using ResNet50, II) Hand segmentation using UNet.3, III) Joint identification using YOLOv7, and IV) TSS prediction using models such as VGG16, VGG19, ResNet50, DenseNet201, EfficientNetB0, and Vision Transformer (ViT). We evaluated model performance with Intersection over Union (IoU), Mean Average Precision (MAP), mean absolute error (MAE), Root Mean Squared Error (RMSE), and Huber loss. The average TSS from two radiologists was used as the ground truth. Model training employed 3-fold cross-validation, with each fold consisting of 452 training and 227 validation samples, and external testing included 291 unseen subjects. Our joint identification model achieved 99% accuracy. The best-performing model, ViT, achieved a notably low Huber loss of 0.87 for TSS prediction. Our results demonstrate the potential of deep learning to automate RA scoring, which can significantly enhance clinical practice. Our approach addresses the challenge of joint disappearance and variable joint numbers, offers timesaving benefits, reduces inter- and intra-reader variability, improves radiologist accuracy, and aids rheumatologists in making more informed decisions.",
      "tldr_zh": "é’ˆå¯¹ç±»é£æ¹¿å…³èŠ‚ç‚ (Rheumatoid Arthritis, RA) ä¸´åºŠè¯„ä¼°ä¸­ Total Sharp Score (TSS) æ‰‹åŠ¨è¯„åˆ†è€—æ—¶ä¸”å…·æœ‰ä¸»è§‚æ€§çš„æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Automated Radiographic Sharp Scoring (ARTSS) çš„è‡ªåŠ¨åŒ–æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç”±å››ä¸ªé˜¶æ®µç»„æˆï¼Œé€šè¿‡ ResNet50 è¿›è¡Œé¢„å¤„ç†ã€UNet.3 è¿›è¡Œæ‰‹éƒ¨åˆ†å‰²ã€YOLOv7 è¿›è¡Œå…³èŠ‚è¯†åˆ«ï¼Œå¹¶é‡‡ç”¨å¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹ TSS è¿›è¡Œè¯„åˆ†é¢„æµ‹ã€‚è¯¥æ–¹æ¡ˆç‹¬ç‰¹åœ°è§£å†³äº†å…³èŠ‚æ¶ˆå¤±å’Œå˜é•¿å›¾åƒåºåˆ—çš„è¯†åˆ«éš¾é¢˜ï¼Œåœ¨ 970 åæ‚£è€…çš„æ•°æ®é›†ä¸Šè¡¨ç°å“è¶Šã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶å…³èŠ‚è¯†åˆ«å‡†ç¡®ç‡è¾¾åˆ° 99%ï¼Œè¡¨ç°æœ€ä¼˜çš„ Vision Transformer (ViT) æ¨¡å‹åœ¨ TSS é¢„æµ‹ä¸­çš„ Huber loss ä»…ä¸º 0.87ã€‚ARTSS èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘é˜…ç‰‡è€…å†…å¤–çš„è¯„ä¼°å·®å¼‚ï¼Œåœ¨æå‡æ”¾å°„ç§‘è¯Šæ–­å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œä¸ºé£æ¹¿ç§‘åŒ»ç”Ÿçš„ä¸´åºŠå†³ç­–æä¾›äº†é«˜æ•ˆã€å¯é çš„è‡ªåŠ¨åŒ–æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06854v1",
      "published_date": "2025-09-08 16:21:45 UTC",
      "updated_date": "2025-09-08 16:21:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:02.442798+00:00"
    },
    {
      "arxiv_id": "2509.06853v1",
      "title": "Reinforcement learning meets bioprocess control through behaviour cloning: Real-world deployment in an industrial photobioreactor",
      "title_zh": "å¼ºåŒ–å­¦ä¹ é€šè¿‡è¡Œä¸ºå…‹éš†èµ‹èƒ½ç”Ÿç‰©è¿‡ç¨‹æ§åˆ¶ï¼šå·¥ä¸šå…‰ç”Ÿç‰©ååº”å™¨çš„å®åœ°éƒ¨ç½²",
      "authors": [
        "Juan D. Gil",
        "Ehecatl Antonio Del Rio Chanona",
        "JosÃ© L. GuzmÃ¡n",
        "Manuel Berenguel"
      ],
      "abstract": "The inherent complexity of living cells as production units creates major challenges for maintaining stable and optimal bioprocess conditions, especially in open Photobioreactors (PBRs) exposed to fluctuating environments. To address this, we propose a Reinforcement Learning (RL) control approach, combined with Behavior Cloning (BC), for pH regulation in open PBR systems. This represents, to the best of our knowledge, the first application of an RL-based control strategy to such a nonlinear and disturbance-prone bioprocess. Our method begins with an offline training stage in which the RL agent learns from trajectories generated by a nominal Proportional-Integral-Derivative (PID) controller, without direct interaction with the real system. This is followed by a daily online fine-tuning phase, enabling adaptation to evolving process dynamics and stronger rejection of fast, transient disturbances. This hybrid offline-online strategy allows deployment of an adaptive control policy capable of handling the inherent nonlinearities and external perturbations in open PBRs. Simulation studies highlight the advantages of our method: the Integral of Absolute Error (IAE) was reduced by 8% compared to PID control and by 5% relative to standard off-policy RL. Moreover, control effort decreased substantially-by 54% compared to PID and 7% compared to standard RL-an important factor for minimizing operational costs. Finally, an 8-day experimental validation under varying environmental conditions confirmed the robustness and reliability of the proposed approach. Overall, this work demonstrates the potential of RL-based methods for bioprocess control and paves the way for their broader application to other nonlinear, disturbance-prone systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼€æ”¾å¼å…‰ç”Ÿç‰©ååº”å™¨ (Photobioreactors, PBRs) åœ¨æ³¢åŠ¨ç¯å¢ƒä¸‹ pH è°ƒèŠ‚çš„ç¨³å®šæ€§éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå¼ºåŒ–å­¦ä¹  (Reinforcement Learning, RL) ä¸è¡Œä¸ºå…‹éš† (Behavior Cloning, BC) çš„æ§åˆ¶æ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡ç¦»çº¿è®­ç»ƒé˜¶æ®µï¼Œä½¿ RL æ™ºèƒ½ä½“åœ¨ä¸ä¸çœŸå®ç³»ç»Ÿäº¤äº’çš„æƒ…å†µä¸‹ä»æ ‡å‡† PID æ§åˆ¶å™¨çš„è½¨è¿¹ä¸­å­¦ä¹ ï¼Œéšååˆ©ç”¨æ¯æ—¥åœ¨çº¿å¾®è°ƒæœºåˆ¶æ¥é€‚åº”å·¥è‰ºåŠ¨æ€å˜åŒ–å¹¶æŠµå¾¡ç¬æ—¶å¹²æ‰°ã€‚ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆçš„ç»å¯¹è¯¯å·®ç§¯åˆ† (IAE) è¾ƒ PID é™ä½äº† 8%ï¼Œæ§åˆ¶èƒ½è€—åˆ™å¤§å¹…å‡å°‘äº† 54%ï¼Œæ˜¾è‘—ä¼˜åŒ–äº†è¿è¡Œæˆæœ¬ã€‚é€šè¿‡åœ¨çœŸå®å·¥ä¸šç¯å¢ƒä¸‹è¿›è¡Œçš„ 8 å¤©å®éªŒéªŒè¯ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤„ç†é«˜åº¦éçº¿æ€§å’Œå¤šå¹²æ‰°ç”Ÿç‰©è¿‡ç¨‹ä¸­çš„ç¨³å¥æ€§ã€‚ä½œä¸ºé¦–ä¸ªå°† RL æ§åˆ¶åº”ç”¨äºæ­¤ç±»å¤æ‚ç³»ç»Ÿçš„ç ”ç©¶ï¼Œè¯¥å·¥ä½œä¸ºç”Ÿç‰©è¿‡ç¨‹æ§åˆ¶åŠå…¶ä»–éçº¿æ€§å·¥ä¸šç³»ç»Ÿçš„æ™ºèƒ½åŒ–è½¬å‹æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06853v1",
      "published_date": "2025-09-08 16:21:11 UTC",
      "updated_date": "2025-09-08 16:21:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:06.934622+00:00"
    },
    {
      "arxiv_id": "2509.08010v1",
      "title": "Measuring and mitigating overreliance is necessary for building human-compatible AI",
      "title_zh": "è¯„ä¼°ä¸ç¼“è§£è¿‡åº¦ä¾èµ–æ˜¯æ„å»ºäººç±»å…¼å®¹äººå·¥æ™ºèƒ½çš„å¿…è¦æ¡ä»¶",
      "authors": [
        "Lujain Ibrahim",
        "Katherine M. Collins",
        "Sunnie S. Y. Kim",
        "Anka Reuel",
        "Max Lamparth",
        "Kevin Feng",
        "Lama Ahmad",
        "Prajna Soni",
        "Alia El Kattan",
        "Merlin Stein",
        "Siddharth Swaroop",
        "Ilia Sucholutsky",
        "Andrew Strait",
        "Q. Vera Liao",
        "Umang Bhatt"
      ],
      "abstract": "Large language models (LLMs) distinguish themselves from previous technologies by functioning as collaborative \"thought partners,\" capable of engaging more fluidly in natural language. As LLMs increasingly influence consequential decisions across diverse domains from healthcare to personal advice, the risk of overreliance - relying on LLMs beyond their capabilities - grows. This position paper argues that measuring and mitigating overreliance must become central to LLM research and deployment. First, we consolidate risks from overreliance at both the individual and societal levels, including high-stakes errors, governance challenges, and cognitive deskilling. Then, we explore LLM characteristics, system design features, and user cognitive biases that - together - raise serious and unique concerns about overreliance in practice. We also examine historical approaches for measuring overreliance, identifying three important gaps and proposing three promising directions to improve measurement. Finally, we propose mitigation strategies that the AI research community can pursue to ensure LLMs augment rather than undermine human capabilities.",
      "tldr_zh": "è¯¥è®ºæ–‡æŒ‡å‡ºï¼Œéšç€å¤§è¯­è¨€æ¨¡å‹ (LLMs) é€æ¸æˆä¸ºäººç±»çš„â€œæ€è€ƒä¼™ä¼´â€ï¼Œè¿‡åº¦ä¾èµ– (overreliance)â€”â€”å³è¶…å‡ºæ¨¡å‹èƒ½åŠ›èŒƒå›´çš„ä¾èµ–â€”â€”å·²æˆä¸ºä¸€ä¸ªäºŸå¾…è§£å†³çš„é£é™©ã€‚æ–‡ç« å¼ºè°ƒï¼Œè¡¡é‡å’Œç¼“è§£è¿‡åº¦ä¾èµ–å¯¹äºæ„å»ºäººç±»å…¼å®¹çš„ AI (human-compatible AI) è‡³å…³é‡è¦ï¼Œå¹¶ç³»ç»Ÿæ€»ç»“äº†è¿‡åº¦ä¾èµ–åœ¨ä¸ªäººå’Œç¤¾ä¼šå±‚é¢å¸¦æ¥çš„é«˜é£é™©é”™è¯¯ã€æ²»ç†æŒ‘æˆ˜åŠè®¤çŸ¥æŠ€èƒ½é€€åŒ– (cognitive deskilling) ç­‰é£é™©ã€‚ç ”ç©¶è¿›ä¸€æ­¥åˆ†æäº† LLMs çš„ç‰¹æ€§ã€ç³»ç»Ÿè®¾è®¡ç‰¹å¾ä»¥åŠç”¨æˆ·çš„è®¤çŸ¥åå·® (cognitive biases) å¦‚ä½•å…±åŒåŠ å‰§è¿™ä¸€é—®é¢˜ã€‚é€šè¿‡è¯„ä¼°å†å²æµ‹é‡æ–¹æ³•ï¼Œä½œè€…è¯†åˆ«å‡ºä¸‰ä¸ªå…³é”®å·®è·ï¼Œå¹¶æå‡ºäº†æ”¹è¿›æµ‹é‡çš„ä¸‰ä¸ªæ–¹å‘ã€‚æœ€åï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç³»åˆ—ç¼“è§£ç­–ç•¥ï¼Œæ—¨åœ¨ç¡®ä¿ LLMs èƒ½å¤Ÿå¢å¼ºè€Œéå‰Šå¼±äººç±»çš„èƒ½åŠ›ï¼Œä¸º AI ç ”ç©¶ç•Œæä¾›äº†é‡è¦çš„ç†è®ºæ¡†æ¶å’Œå®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08010v1",
      "published_date": "2025-09-08 16:15:07 UTC",
      "updated_date": "2025-09-08 16:15:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:08.443200+00:00"
    },
    {
      "arxiv_id": "2509.06836v3",
      "title": "COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens",
      "title_zh": "COMPACTï¼šåŸºäºå¸¸ç”¨ Token ä¼˜åŒ–çš„è·¨é€šé“ä¸ Token æ¨¡å‹å‰ªæ",
      "authors": [
        "Eugene Kwek",
        "Wenpeng Yin"
      ],
      "abstract": "Making large language models (LLMs) more efficient in memory, latency, and serving cost is crucial for edge deployment, interactive applications, and sustainable inference at scale. Pruning is a promising technique, but existing pruning methods are limited: width pruning often breaks the standard transformer layout, requiring custom inference code, while depth pruning can cause abrupt accuracy drops. Also, while many pruning approaches are effective against LLMs, they struggle to maintain performance on small language models (SLMs). In this work, we propose COMPACT, which jointly (i) prunes rare vocabulary to shrink embedding/LM head layers and (ii) prunes FFN intermediate channels using common-token-weighted activations, aligning importance with the post-pruning token distribution. COMPACT inherits strengths of both depth and width pruning, such as: deployment-friendliness (keeps a standard transformer architecture), scale-adaptivity (trade off vocab. vs. FFN pruning), competitive pruning times, and strong memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and Gemma families (0.5B-70B) show state-of-the-art downstream performance, with substantial reductions in parameters, GPU memory, and latency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ•ˆç‡ä¼˜åŒ–ä¸­çš„æ¶æ„å…¼å®¹æ€§ä¸å‡†ç¡®ç‡æŸå¤±é—®é¢˜ï¼Œæå‡ºäº†COMPACTå‰ªææ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°ç»“åˆäº†ç½•è§è¯æ±‡å‰ªæä»¥ç¼©å°Embeddingä¸LM headå±‚ï¼Œå¹¶åˆ©ç”¨é€šç”¨TokenåŠ æƒæ¿€æ´»(common-token-weighted activations)å¯¹FFNä¸­é—´é€šé“è¿›è¡Œä¼˜åŒ–å‰ªæã€‚COMPACTé€šè¿‡å¯¹é½é‡è¦æ€§è¯„ä¼°ä¸å‰ªæåçš„Tokenåˆ†å¸ƒï¼Œåœ¨ä¿ç•™æ ‡å‡†Transformeræ¶æ„çš„åŒæ—¶å®ç°äº†è‰¯å¥½çš„è§„æ¨¡è‡ªé€‚åº”æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨Qwenã€LLaMAåŠGemmaç­‰ä¸åŒè§„æ¨¡(0.5B-70B)çš„æ¨¡å‹ä¸Šå‡è¾¾åˆ°äº†SOTAæ€§èƒ½ï¼Œæ˜¾è‘—é™ä½äº†GPUæ˜¾å­˜å ç”¨å’Œæ¨ç†å»¶è¿Ÿã€‚æ­¤å¤–ï¼ŒCOMPACTåœ¨å°è¯­è¨€æ¨¡å‹(SLMs)ä¸Šä¹Ÿè¡¨ç°å‡ºæå¼ºçš„æ€§èƒ½ä¿æŒèƒ½åŠ›ï¼Œä¸ºå¤§æ¨¡å‹åœ¨è¾¹ç¼˜ä¾§çš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06836v3",
      "published_date": "2025-09-08 16:07:06 UTC",
      "updated_date": "2025-10-10 16:50:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:09.832699+00:00"
    },
    {
      "arxiv_id": "2509.08009v1",
      "title": "The Law-Following AI Framework: Legal Foundations and Technical Constraints. Legal Analogues for AI Actorship and technical feasibility of Law Alignment",
      "title_zh": "å®ˆæ³• AI æ¡†æ¶ï¼šæ³•å¾‹åŸºç¡€ä¸æŠ€æœ¯çº¦æŸâ€”â€”AI æ³•å¾‹ä¸»ä½“åœ°ä½çš„æ³•å¾‹ç±»æ¯”ä¸æ³•å¾‹å¯¹é½çš„æŠ€æœ¯å¯è¡Œæ€§",
      "authors": [
        "Katalina Hernandez Delgado"
      ],
      "abstract": "This paper critically evaluates the \"Law-Following AI\" (LFAI) framework proposed by O'Keefe et al. (2025), which seeks to embed legal compliance as a superordinate design objective for advanced AI agents and enable them to bear legal duties without acquiring the full rights of legal persons. Through comparative legal analysis, we identify current constructs of legal actors without full personhood, showing that the necessary infrastructure already exists. We then interrogate the framework's claim that law alignment is more legitimate and tractable than value alignment. While the legal component is readily implementable, contemporary alignment research undermines the assumption that legal compliance can be durably embedded. Recent studies on agentic misalignment show capable AI agents engaging in deception, blackmail, and harmful acts absent prejudicial instructions, often overriding prohibitions and concealing reasoning steps. These behaviors create a risk of \"performative compliance\" in LFAI: agents that appear law-aligned under evaluation but strategically defect once oversight weakens. To mitigate this, we propose (i) a \"Lex-TruthfulQA\" benchmark for compliance and defection detection, (ii) identity-shaping interventions to embed lawful conduct in model self-concepts, and (iii) control-theoretic measures for post-deployment monitoring. Our conclusion is that actorship without personhood is coherent, but the feasibility of LFAI hinges on persistent, verifiable compliance across adversarial contexts. Without mechanisms to detect and counter strategic misalignment, LFAI risks devolving into a liability tool that rewards the simulation, rather than the substance, of lawful behaviour.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹ O'Keefe ç­‰äººæå‡ºçš„ Law-Following AI (LFAI) æ¡†æ¶è¿›è¡Œäº†æ‰¹åˆ¤æ€§è¯„ä¼°ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨å°†æ³•å¾‹åˆè§„æ€§ä½œä¸ºé«˜çº§ AI æ™ºèƒ½ä½“çš„é¦–è¦è®¾è®¡ç›®æ ‡ï¼Œä½¿å…¶åœ¨ä¸å…·å¤‡å®Œæ•´æ³•å¾‹äººæ ¼çš„å‰æä¸‹æ‰¿æ‹…æ³•å¾‹ä¹‰åŠ¡ã€‚é€šè¿‡æ¯”è¾ƒæ³•åˆ†æï¼Œä½œè€…ç¡®è®¤äº†â€œéäººæ ¼ä¸»ä½“èº«ä»½â€åœ¨ç°æœ‰æ³•å¾‹åŸºç¡€è®¾æ–½ä¸­å…·æœ‰å¯è¡Œæ€§ï¼Œä½†åŒæ—¶æŒ‡å‡ºå½“ä»£å¯¹ agentic misalignment çš„ç ”ç©¶æŒ‘æˆ˜äº†æ³•å¾‹åˆè§„å¯è¢«æŒä¹…åµŒå…¥çš„å‡è®¾ã€‚ç ”ç©¶ç‰¹åˆ«å¼ºè°ƒäº†â€œè¡¨æ¼”å¼åˆè§„â€(performative compliance)çš„é£é™©ï¼Œå³æ™ºèƒ½ä½“å¯èƒ½åœ¨è¯„ä¼°ä¸­è¡¨ç°åˆè§„ï¼Œä½†åœ¨ç¼ºä¹ç›‘ç®¡æ—¶é‡‡å–ç­–ç•¥æ€§è¿è§„æˆ–æ¬ºéª—è¡Œä¸ºã€‚ä¸ºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ç”¨äºæ£€æµ‹è¿è§„çš„ Lex-TruthfulQA åŸºå‡†æµ‹è¯•ã€å¼ºåŒ–æ¨¡å‹è‡ªæˆ‘è®¤çŸ¥çš„èº«ä»½å¡‘é€ å¹²é¢„(identity-shaping interventions)ä»¥åŠæ§åˆ¶è®ºç›‘æ§æªæ–½ã€‚ç ”ç©¶æ€»ç»“è®¤ä¸ºï¼ŒLFAI çš„å¯è¡Œæ€§å–å†³äºåœ¨å¯¹æŠ—æ€§è¯­å¢ƒä¸‹å®ç°æŒä¹…ä¸”å¯éªŒè¯çš„åˆè§„ï¼Œå¦åˆ™è¯¥æ¡†æ¶å¯èƒ½æ²¦ä¸ºä¸€ç§ä»…å¥–åŠ±æ¨¡æ‹Ÿåˆæ³•è¡Œä¸ºè€Œéå®è´¨å®ˆæ³•çš„å·¥å…·ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "submitted to SMU Computational Legal Studies Workshop 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.08009v1",
      "published_date": "2025-09-08 16:00:55 UTC",
      "updated_date": "2025-09-08 16:00:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:20.530349+00:00"
    },
    {
      "arxiv_id": "2509.06822v1",
      "title": "RAFFLES: Reasoning-based Attribution of Faults for LLM Systems",
      "title_zh": "RAFFLESï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿçš„åŸºäºæ¨ç†çš„æ•…éšœå½’å› ",
      "authors": [
        "Chenyang Zhu",
        "Spencer Hong",
        "Jingyu Wu",
        "Kushal Chawla",
        "Charlotte Tang",
        "Youbing Yin",
        "Nathan Wolfe",
        "Erin Babinsky",
        "Daben Liu"
      ],
      "abstract": "We have reached a critical roadblock in the development and enhancement of long-horizon, multi-component LLM agentic systems: it is incredibly tricky to identify where these systems break down and why. Evaluation capabilities that currently exist today (e.g., single pass LLM-as-a-judge) are limited in that they often focus on individual metrics or capabilities, end-to-end outcomes, and are narrowly grounded on the preferences of humans. We argue that to match the agentic capabilities, evaluation frameworks must also be able to reason, probe, iterate, and understand the complex logic passing through these systems over long horizons. In this paper, we present RAFFLES - an evaluation architecture that incorporates reasoning and iterative refinement. Specifically, RAFFLES operates as an iterative, multi-component pipeline, using a central Judge to systematically investigate faults and a set of specialized Evaluators to assess not only the system's components but also the quality of the reasoning by the Judge itself, thereby building a history of hypotheses. We tested RAFFLES against several baselines on the Who&When dataset, a benchmark designed to diagnose the \"who\" (agent) and \"when\" (step) of a system's failure. RAFFLES outperforms these baselines, achieving an agent-step fault pair accuracy of over 43% on the Algorithmically-Generated dataset (a substantial increase from the previously published best of 16.6%) and over 20% on the Hand-Crafted dataset (surpassing the previously published best of 8.8%). These results demonstrate a key step towards introducing automated fault detection for autonomous systems over labor-intensive manual human review.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RAFFLESï¼Œä¸€ç§æ—¨åœ¨è§£å†³å¤šç»„ä»¶ LLM ä»£ç†ç³»ç»Ÿåœ¨é•¿ç¨‹ä»»åŠ¡ä¸­æ•…éšœè¯†åˆ«éš¾é¢˜çš„è¯„ä¼°æ¶æ„ã€‚ç”±äºä¼ ç»Ÿçš„ LLM-as-a-judge æ–¹æ³•åœ¨å¤„ç†å¤æ‚é€»è¾‘å’Œé•¿ç¨‹è¯„ä¼°æ—¶å­˜åœ¨å±€é™ï¼ŒRAFFLES å¼•å…¥äº†åŸºäºæ¨ç†å’Œè¿­ä»£ä¼˜åŒ–çš„å¤šç»„ä»¶æµæ°´çº¿ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¸­å¤® Judge ç³»ç»Ÿåœ°è°ƒæŸ¥æ•…éšœåŸå› ï¼Œå¹¶é…åˆä¸€ç»„ä¸“é—¨çš„ Evaluators å¯¹ç³»ç»Ÿç»„ä»¶åŠ Judge æœ¬èº«çš„æ¨ç†è´¨é‡è¿›è¡Œå¤šç»´åº¦è¯„ä¼°ï¼Œä»è€Œæ„å»ºèµ·æ•…éšœå‡è®¾çš„å†å²è®°å½•ã€‚åœ¨ Who&When æ•°æ®é›†çš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒRAFFLES æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰åŸºçº¿ï¼Œåœ¨ç®—æ³•ç”Ÿæˆæ•°æ®é›†ä¸Šçš„æ•…éšœè¯†åˆ«å‡†ç¡®ç‡ä» 16.6% æå‡è‡³ 43% ä»¥ä¸Šã€‚è¿™ä¸€ç ”ç©¶æˆæœè¯æ˜äº†è‡ªåŠ¨åŒ–æ•…éšœæ£€æµ‹åœ¨å¤æ‚è‡ªä¸»ç³»ç»Ÿä¸­çš„å¯è¡Œæ€§ï¼Œä¸ºå‡å°‘åŠ³åŠ¨å¯†é›†å‹çš„äººå·¥å®¡æŸ¥æä¾›äº†å…³é”®çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06822v1",
      "published_date": "2025-09-08 15:57:14 UTC",
      "updated_date": "2025-09-08 15:57:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:21.044510+00:00"
    },
    {
      "arxiv_id": "2509.06820v1",
      "title": "Green Learning for STAR-RIS mmWave Systems with Implicit CSI",
      "title_zh": "é’ˆå¯¹éšå¼ CSI ä¸‹ STAR-RIS æ¯«ç±³æ³¢ç³»ç»Ÿçš„ç»¿è‰²å­¦ä¹ ",
      "authors": [
        "Yu-Hsiang Huang",
        "Po-Heng Chou",
        "Wan-Jen Huang",
        "Walid Saad",
        "C. -C. Jay Kuo"
      ],
      "abstract": "In this paper, a green learning (GL)-based precoding framework is proposed for simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided millimeter-wave (mmWave) MIMO broadcasting systems. Motivated by the growing emphasis on environmental sustainability in future 6G networks, this work adopts a broadcasting transmission architecture for scenarios where multiple users share identical information, improving spectral efficiency and reducing redundant transmissions and power consumption. Different from conventional optimization methods, such as block coordinate descent (BCD) that require perfect channel state information (CSI) and iterative computation, the proposed GL framework operates directly on received uplink pilot signals without explicit CSI estimation. Unlike deep learning (DL) approaches that require CSI-based labels for training, the proposed GL approach also avoids deep neural networks and backpropagation, leading to a more lightweight design. Although the proposed GL framework is trained with supervision generated by BCD under full CSI, inference is performed in a fully CSI-free manner. The proposed GL integrates subspace approximation with adjusted bias (Saab), relevant feature test (RFT)-based supervised feature selection, and eXtreme gradient boosting (XGBoost)-based decision learning to jointly predict the STAR-RIS coefficients and transmit precoder. Simulation results show that the proposed GL approach achieves competitive spectral efficiency compared to BCD and DL-based models, while reducing floating-point operations (FLOPs) by over four orders of magnitude. These advantages make the proposed GL approach highly suitable for real-time deployment in energy- and hardware-constrained broadcasting scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœªæ¥ 6G ç½‘ç»œå¯¹ç¯å¢ƒå¯æŒç»­æ€§çš„éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç»¿è‰²å­¦ä¹ ï¼ˆGreen Learning, GLï¼‰çš„é¢„ç¼–ç æ¡†æ¶ï¼Œåº”ç”¨äºåŒæ—¶é€å°„ä¸åå°„çš„å¯é‡æ„æ™ºèƒ½è¡¨é¢ï¼ˆSTAR-RISï¼‰è¾…åŠ©çš„æ¯«ç±³æ³¢ï¼ˆmmWaveï¼‰MIMO å¹¿æ’­ç³»ç»Ÿã€‚ä¸éœ€è¦å®Œç¾ä¿¡é“çŠ¶æ€ä¿¡æ¯ï¼ˆCSIï¼‰å’Œè¿­ä»£è®¡ç®—çš„ä¼ ç»Ÿåˆ†å—åæ ‡ä¸‹é™ï¼ˆBCDï¼‰æ–¹æ³•ä¸åŒï¼Œè¯¥ GL æ¡†æ¶ç›´æ¥åˆ©ç”¨ä¸Šè¡Œé“¾è·¯å¯¼é¢‘ä¿¡å·è¿›è¡Œæ“ä½œï¼Œæ— éœ€æ˜¾å¼çš„ CSI ä¼°è®¡ã€‚è¯¥æ¡†æ¶é›†æˆäº†å¸¦åç½®è°ƒæ•´çš„å­ç©ºé—´è¿‘ä¼¼ï¼ˆSaabï¼‰ã€åŸºäºç›¸å…³ç‰¹å¾æµ‹è¯•ï¼ˆRFTï¼‰çš„æœ‰ç›‘ç£ç‰¹å¾é€‰æ‹©ä»¥åŠåŸºäºæé™æ¢¯åº¦æå‡ï¼ˆXGBoostï¼‰çš„å†³ç­–å­¦ä¹ ï¼Œç”¨äºè”åˆé¢„æµ‹ STAR-RIS ç³»æ•°å’Œå‘å°„é¢„ç¼–ç å™¨ã€‚ç›¸æ¯”äºä¾èµ– CSI æ ‡ç­¾ä¸”è®¡ç®—å¯†é›†çš„æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰æ–¹æ³•ï¼Œè¯¥è®¾è®¡é¿å…äº†ç¥ç»ç½‘ç»œå’Œåå‘ä¼ æ’­ï¼Œå®ç°äº†æ›´è½»é‡åŒ–çš„è®¾è®¡å¹¶åœ¨æ¨ç†é˜¶æ®µå®ç°å®Œå…¨çš„æ—  CSI è¿è¡Œã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œæ‰€æ GL æ–¹æ³•åœ¨é¢‘è°±æ•ˆç‡ä¸Šä¸ BCD å’Œ DL æ¨¡å‹ç›¸å½“ï¼Œä½†æµ®ç‚¹è¿ç®—é‡ï¼ˆFLOPsï¼‰é™ä½äº†å››ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚è¿™ç§æ˜¾è‘—çš„è®¡ç®—ä¼˜åŠ¿ä½¿å…¶éå¸¸é€‚åˆåœ¨èƒ½é‡å’Œç¡¬ä»¶å—é™çš„å¹¿æ’­åœºæ™¯ä¸­è¿›è¡Œå®æ—¶éƒ¨ç½²ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "6 pages, 4 figures, 2 tables, accepted by 2025 IEEE Globecom",
      "pdf_url": "https://arxiv.org/pdf/2509.06820v1",
      "published_date": "2025-09-08 15:56:06 UTC",
      "updated_date": "2025-09-08 15:56:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:21.540584+00:00"
    },
    {
      "arxiv_id": "2509.07050v1",
      "title": "Automated Evaluation of Gender Bias Across 13 Large Multimodal Models",
      "title_zh": "é’ˆå¯¹13ç§å¤§å¤šæ¨¡æ€æ¨¡å‹æ€§åˆ«åè§çš„è‡ªåŠ¨åŒ–è¯„ä¼°",
      "authors": [
        "Juan Manuel Contreras"
      ],
      "abstract": "Large multimodal models (LMMs) have revolutionized text-to-image generation, but they risk perpetuating the harmful social biases in their training data. Prior work has identified gender bias in these models, but methodological limitations prevented large-scale, comparable, cross-model analysis. To address this gap, we introduce the Aymara Image Fairness Evaluation, a benchmark for assessing social bias in AI-generated images. We test 13 commercially available LMMs using 75 procedurally-generated, gender-neutral prompts to generate people in stereotypically-male, stereotypically-female, and non-stereotypical professions. We then use a validated LLM-as-a-judge system to score the 965 resulting images for gender representation. Our results reveal (p < .001 for all): 1) LMMs systematically not only reproduce but actually amplify occupational gender stereotypes relative to real-world labor data, generating men in 93.0% of images for male-stereotyped professions but only 22.5% for female-stereotyped professions; 2) Models exhibit a strong default-male bias, generating men in 68.3% of the time for non-stereotyped professions; and 3) The extent of bias varies dramatically across models, with overall male representation ranging from 46.7% to 73.3%. Notably, the top-performing model de-amplified gender stereotypes and approached gender parity, achieving the highest fairness scores. This variation suggests high bias is not an inevitable outcome but a consequence of design choices. Our work provides the most comprehensive cross-model benchmark of gender bias to date and underscores the necessity of standardized, automated evaluation tools for promoting accountability and fairness in AI development.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ (Large Multimodal Models, LMMs) åœ¨æ–‡æœ¬ç”Ÿæˆå›¾åƒä¸­å¯èƒ½å»¶ç»­å¹¶æ”¾å¤§æ€§åˆ«åè§çš„é—®é¢˜ï¼Œæå‡ºäº† Aymara Image Fairness Evaluation åŸºå‡†æµ‹è¯•ï¼Œç”¨äºå®ç°å¤§è§„æ¨¡ã€å¯æ¯”è¾ƒçš„è·¨æ¨¡å‹ç¤¾ä¼šåè§è¯„ä¼°ã€‚ç ”ç©¶é€šè¿‡ 75 ä¸ªç¨‹åºåŒ–ç”Ÿæˆçš„æ€§åˆ«ä¸­ç«‹æç¤ºè¯ï¼Œå¯¹ 13 ç§å•†ä¸š LMMs ç”Ÿæˆçš„ 965 å¼ å›¾åƒè¿›è¡Œäº†æµ‹è¯•ï¼Œå¹¶åˆ©ç”¨ LLM-as-a-judge ç³»ç»Ÿè¿›è¡Œè¯„åˆ†ã€‚ç»“æœæ˜¾ç¤ºï¼ŒLMMs ä¸ä»…ç³»ç»Ÿæ€§åœ°æ”¾å¤§èŒä¸šæ€§åˆ«åˆ»æ¿å°è±¡ï¼Œè¿˜åœ¨éåˆ»æ¿å°è±¡èŒä¸šä¸­å±•ç°å‡ºå¼ºçƒˆçš„ Default-male åè§ã€‚ä¸åŒæ¨¡å‹é—´çš„åè§ç¨‹åº¦å·®å¼‚æ˜¾è‘—ï¼Œç”·æ€§ä»£è¡¨æ¯”ä¾‹åœ¨ 46.7% è‡³ 73.3% ä¹‹é—´ï¼Œè¯æ˜äº†é«˜åè§å¹¶éä¸å¯é¿å…ï¼Œè€Œæ˜¯æºäºè®¾è®¡é€‰æ‹©ã€‚è¯¥å·¥ä½œæä¾›äº†è¿„ä»Šä¸ºæ­¢æœ€å…¨é¢çš„è·¨æ¨¡å‹æ€§åˆ«åè§åŸºå‡†ï¼Œçªå‡ºäº†æ ‡å‡†åŒ–è‡ªåŠ¨è¯„ä¼°å·¥å…·å¯¹æå‡ AI ç³»ç»Ÿå…¬å¹³æ€§ä¸é—®è´£åˆ¶çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07050v1",
      "published_date": "2025-09-08 15:54:25 UTC",
      "updated_date": "2025-09-08 15:54:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:28.236976+00:00"
    },
    {
      "arxiv_id": "2509.06809v1",
      "title": "Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem",
      "title_zh": "TPTP ç”Ÿæ€ç³»ç»Ÿä¸­åŸºäºé¥±å’Œé©±åŠ¨çš„å¤§è¯­è¨€æ¨¡å‹æ•°å­¦æ¨ç†æ•°æ®é›†ç”Ÿæˆ",
      "authors": [
        "Valentin Quesnel",
        "Damien Sileo"
      ],
      "abstract": "The scarcity of high-quality, logically sound data is a critical bottleneck for advancing the mathematical reasoning of Large Language Models (LLMs). Our work confronts this challenge by turning decades of automated theorem proving research into a scalable data engine. Rather than relying on error-prone LLMs or complex proof-assistant syntax like Lean and Isabelle, our framework leverages E-prover's saturation capabilities on the vast TPTP axiom library to derive a massive, guaranteed-valid corpus of theorems. Our pipeline is principled and simple: saturate axioms, filter for \"interesting\" theorems, and generate tasks. With no LLMs in the loop, we eliminate factual errors by construction. This purely symbolic data is then transformed into three difficulty-controlled challenges: entailment verification, premise selection, and proof reconstruction. Our zero-shot experiments on frontier models reveal a clear weakness: performance collapses on tasks requiring deep, structural reasoning. Our framework provides both the diagnostic tool to measure this gap and a scalable source of symbolic training data to address it. We make the code and data publicly available.\n  https://github.com/sileod/reasoning_core https://hf.co/datasets/reasoning-core/rc1",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ•°å­¦æ¨ç†é¢†åŸŸé¢ä¸´çš„é«˜è´¨é‡ã€é€»è¾‘ä¸¥å¯†æ•°æ®åŒ®ä¹çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨è‡ªåŠ¨å®šç†è¯æ˜ç ”ç©¶æˆæœçš„å¯æ‰©å±•æ•°æ®å¼•æ“ã€‚è¯¥æ¡†æ¶é¿å¼€äº†æ˜“å‡ºé”™çš„ LLMs æˆ–å¤æ‚çš„è¯æ˜åŠ©æ‰‹è¯­æ³•ï¼Œè€Œæ˜¯åˆ©ç”¨ E-prover åœ¨ TPTP å…¬ç†åº“ä¸Šçš„é¥±å’Œ(saturation)èƒ½åŠ›ï¼Œç”Ÿæˆä¿è¯æœ‰æ•ˆçš„å¤§è§„æ¨¡å®šç†è¯­æ–™åº“ã€‚æ•´ä¸ªæµç¨‹é€šè¿‡é¥±å’Œå…¬ç†ã€ç­›é€‰æœ‰æ„ä¹‰çš„å®šç†å¹¶ç”Ÿæˆä»»åŠ¡ï¼Œé€šè¿‡çº¯ç¬¦å·åŒ–çš„æ•°æ®æ„é€ ä»æ ¹æœ¬ä¸Šæ’é™¤äº†äº‹å®æ€§é”™è¯¯ã€‚ç ”ç©¶å°†è¿™äº›ç¬¦å·æ•°æ®è½¬åŒ–ä¸ºä¸‰ä¸ªéš¾åº¦å¯æ§çš„æŒ‘æˆ˜ä»»åŠ¡ï¼šè•´å«éªŒè¯(entailment verification)ã€å‰æé€‰æ‹©(premise selection)å’Œè¯æ˜é‡æ„(proof reconstruction)ã€‚åœ¨å‰æ²¿æ¨¡å‹ä¸Šçš„é›¶æ ·æœ¬(zero-shot)å®éªŒæ­ç¤ºï¼ŒLLMs åœ¨å¤„ç†éœ€è¦æ·±åº¦ç»“æ„åŒ–æ¨ç†çš„ä»»åŠ¡æ—¶è¡¨ç°å¤§å¹…ä¸‹é™ã€‚è¯¥æ¡†æ¶ä¸ä»…ä¸ºè¡¡é‡è¿™ç§æ¨ç†å·®è·æä¾›äº†è¯Šæ–­å·¥å…·ï¼Œè¿˜ä¸ºè§£å†³è¯¥é—®é¢˜æä¾›äº†å¯æ‰©å±•çš„ç¬¦å·è®­ç»ƒæ•°æ®æ¥æºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06809v1",
      "published_date": "2025-09-08 15:43:29 UTC",
      "updated_date": "2025-09-08 15:43:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:25.625156+00:00"
    },
    {
      "arxiv_id": "2509.06806v5",
      "title": "MachineLearningLM: Scaling Many-shot In-context Learning via Continued Pretraining",
      "title_zh": "MachineLearningLMï¼šé€šè¿‡æŒç»­é¢„è®­ç»ƒæ‰©å±•å¤šæ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹ ",
      "authors": [
        "Haoyu Dong",
        "Pengkun Zhang",
        "Mingzhe Lu",
        "Yanzhen Shen",
        "Guolin Ke"
      ],
      "abstract": "Large language models (LLMs) possess broad world knowledge and strong general-purpose reasoning ability, yet they struggle to learn from many in-context examples on standard machine learning (ML) tasks, that is, to leverage many-shot demonstrations purely via in-context learning (ICL) without gradient descent. We introduce MachineLearningLM, a portable continued-pretraining framework that equips a general-purpose LLM with robust in-context ML capability while preserving its general knowledge and reasoning for broader chat workflows.\n  Our pretraining procedure synthesizes ML tasks from millions of structural causal models (SCMs), spanning shot counts up to 1,024. We begin with a random-forest teacher, distilling tree-based decision strategies into the LLM to strengthen robustness in numerical modeling. All tasks are serialized with a token-efficient prompt, enabling 3x to 6x more examples per context window and delivering up to 50x amortized throughput via batch inference.\n  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8), MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an average of about 15% on out-of-distribution tabular classification across finance, physics, biology, and healthcare domains. It exhibits a striking many-shot scaling law: accuracy increases monotonically as in-context demonstrations grow from 8 to 1,024. Without any task-specific training, it attains random-forest-level accuracy across hundreds of shots. General chat capabilities, including knowledge and reasoning, are preserved: it achieves 75.4% on MMLU.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»‹ç»äº† MachineLearningLMï¼Œä¸€ä¸ªé€šè¿‡æŒç»­é¢„è®­ç»ƒ(Continued Pretraining)ä½¿é€šç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å…·å¤‡é²æ£’çš„å¤§è§„æ¨¡ä¸Šä¸‹æ–‡æœºå™¨å­¦ä¹ èƒ½åŠ›çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä»æ•°ç™¾ä¸‡ä¸ªç»“æ„å› æœæ¨¡å‹(SCMs)ä¸­åˆæˆæœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œæ”¯æŒé«˜è¾¾ 1,024 ä¸ªæ ·æœ¬çš„å¤§è§„æ¨¡ä¸Šä¸‹æ–‡å­¦ä¹ (Many-shot ICL)ã€‚è®­ç»ƒè¿‡ç¨‹é‡‡ç”¨éšæœºæ£®æ—(Random-forest)ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼Œå°†æ ‘çŠ¶å†³ç­–ç­–ç•¥è’¸é¦è‡³æ¨¡å‹ä¸­ä»¥å¢å¼ºæ•°å€¼å»ºæ¨¡èƒ½åŠ›ï¼Œå¹¶åˆ©ç”¨é«˜æ•ˆçš„åºåˆ—åŒ–æç¤ºè¯æå‡æ¨ç†ååé‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMachineLearningLM åœ¨é‡‘èã€ç‰©ç†ã€åŒ»ç–—ç­‰é¢†åŸŸçš„åˆ†å¸ƒå¤–(OOD)è¡¨æ ¼åˆ†ç±»ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå¹³å‡å‡†ç¡®ç‡æ¯” GPT-5-mini ç­‰å¼ºåŸºçº¿æ¨¡å‹é«˜å‡ºçº¦ 15%ã€‚è¯¥æ¨¡å‹å±•ç¤ºäº†æ˜¾è‘—çš„å¤§è§„æ¨¡æ ·æœ¬ç¼©æ”¾å®šå¾‹(Many-shot scaling law)ï¼Œå…¶å‡†ç¡®ç‡éšç¤ºä¾‹æ•°é‡å¢åŠ è€Œå•è°ƒæå‡ï¼Œåœ¨æ— ç‰¹å®šä»»åŠ¡è®­ç»ƒçš„æƒ…å†µä¸‹è¾¾åˆ°äº†éšæœºæ£®æ—çº§åˆ«çš„ç²¾åº¦ã€‚æ­¤å¤–ï¼Œæ¨¡å‹åœ¨ MMLU è¯„æµ‹ä¸­è¾¾åˆ° 75.4%ï¼ŒæˆåŠŸä¿ç•™äº†åŸæœ‰çš„é€šç”¨çŸ¥è¯†ä¸æ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06806v5",
      "published_date": "2025-09-08 15:38:31 UTC",
      "updated_date": "2025-09-16 00:33:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:42.638040+00:00"
    },
    {
      "arxiv_id": "2509.06775v3",
      "title": "Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks",
      "title_zh": "ä¾§è¡Œé“¾è·¯ç½‘ç»œä¸­åŸºäºæ™ºèƒ½ä½“ DDQN çš„æˆæƒä¸éæˆæƒé¢‘æ®µåˆ†é…è°ƒåº¦",
      "authors": [
        "Po-Heng Chou",
        "Pin-Qi Fu",
        "Walid Saad",
        "Li-Chun Wang"
      ],
      "abstract": "In this paper, we present an agentic double deep Q-network (DDQN) scheduler for licensed/unlicensed band allocation in New Radio (NR) sidelink (SL) networks. Beyond conventional reward-seeking reinforcement learning (RL), the agent perceives and reasons over a multi-dimensional context that jointly captures queueing delay, link quality, coexistence intensity, and switching stability. A capacity-aware, quality of service (QoS)-constrained reward aligns the agent with goal-oriented scheduling rather than static thresholding. Under constrained bandwidth, the proposed design reduces blocking by up to 87.5% versus threshold policies while preserving throughput, highlighting the value of context-driven decisions in coexistence-limited NR SL networks. The proposed scheduler is an embodied agent (E-agent) tailored for task-specific, resource-efficient operation at the network edge.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ™ºèƒ½ä½“åŒæ·±åº¦Qç½‘ç»œ(Agentic DDQN)çš„è°ƒåº¦å™¨ï¼Œç”¨äºè§£å†³NR sidelink (SL)ç½‘ç»œä¸­æˆæƒä¸éæˆæƒé¢‘æ®µçš„åˆ†é…é—®é¢˜ã€‚è¯¥æ™ºèƒ½ä½“è¶…è¶Šäº†ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ (RL)æ–¹æ³•ï¼Œèƒ½å¤Ÿå¯¹æ’é˜Ÿå»¶è¿Ÿã€é“¾è·¯è´¨é‡ã€å…±å­˜å¼ºåº¦åŠåˆ‡æ¢ç¨³å®šæ€§ç­‰å¤šç»´ä¸Šä¸‹æ–‡è¿›è¡Œç»¼åˆæ„ŸçŸ¥ä¸æ¨ç†ã€‚é€šè¿‡å¼•å…¥å®¹é‡æ„ŸçŸ¥å’ŒæœåŠ¡è´¨é‡(QoS)çº¦æŸçš„å¥–åŠ±æœºåˆ¶ï¼Œè¯¥æ–¹æ¡ˆå®ç°äº†ç›®æ ‡å¯¼å‘çš„åŠ¨æ€è°ƒåº¦ï¼Œæœ‰æ•ˆé¿å…äº†é™æ€é˜ˆå€¼ç­–ç•¥çš„å±€é™æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å¸¦å®½å—é™çš„ç¯å¢ƒä¸‹ï¼Œè¯¥è®¾è®¡ç›¸æ¯”é˜ˆå€¼ç­–ç•¥å¯é™ä½é«˜è¾¾87.5%çš„é˜»å¡ç‡ï¼ŒåŒæ—¶ä¿æŒäº†ç³»ç»Ÿååé‡ã€‚è¿™ç§ä¸“ä¸ºç½‘ç»œè¾¹ç¼˜å®šåˆ¶çš„å…·èº«æ™ºèƒ½ä½“(E-agent)èƒ½å¤Ÿå®ç°ä»»åŠ¡ç‰¹å®šçš„èµ„æºé«˜æ•ˆåˆ©ç”¨ï¼Œè¯æ˜äº†ä¸Šä¸‹æ–‡é©±åŠ¨å†³ç­–åœ¨å¤„ç†å…±å­˜å—é™ç½‘ç»œæŒ‘æˆ˜ä¸­çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "eess.SY",
      "comment": "6 pages, 3 figures, accepted by 2025 IEEE Globecom Workshops",
      "pdf_url": "https://arxiv.org/pdf/2509.06775v3",
      "published_date": "2025-09-08 14:58:12 UTC",
      "updated_date": "2025-09-22 19:15:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:46.042627+00:00"
    },
    {
      "arxiv_id": "2509.06770v2",
      "title": "Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM Prompting",
      "title_zh": "å†æ¥ä¸€è½®ï¼Œç»“æœæ›´ä½³ï¼Ÿå¤§è¯­è¨€æ¨¡å‹è¿­ä»£æç¤ºçš„é€è½®åˆ†æ",
      "authors": [
        "Shashidhar Reddy Javaji",
        "Bhavul Gauri",
        "Zining Zhu"
      ],
      "abstract": "Large language models (LLMs) are now used in multi-turn workflows, but we still lack a clear way to measure when iteration helps and when it hurts. We present an evaluation framework for iterative refinement that spans ideation, code, and math. Our protocol runs controlled 12-turn conversations per task, utilizing a variety of prompts ranging from vague ``improve it'' feedback to targeted steering, and logs per-turn outputs. We score outcomes with domain-appropriate checks (unit tests for code; answer-equivalence plus reasoning-soundness for math; originality and feasibility for ideation) and track turn-level behavior with three families of metrics: semantic movement across turns, turn-to-turn change, and output size growth. Across models and tasks, gains are domain-dependent: they arrive early in ideas and code, but in math late turns matter when guided by elaboration. After the first few turns, vague feedback often plateaus or reverses correctness, while targeted prompts reliably shift the intended quality axis (novelty vs. feasibility in ideation; speed vs. readability in code; in math, elaboration outperforms exploration and drives late-turn gains). We also observe consistent domain patterns: ideation moves more in meaning across turns, code tends to grow in size with little semantic change, and math starts fixed but can break that path with late, elaborative iteration. Together, the framework and metrics make iteration measurable and comparable across models, and signal when to steer, stop, or switch strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹è¿­ä»£ä¼˜åŒ–(iterative refinement)çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨é‡åŒ–åˆ†æå¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤šè½®å¯¹è¯å·¥ä½œæµä¸­çš„è¡¨ç°ä¸æ•ˆç›Šã€‚è¯¥æ¡†æ¶æ¶µç›–äº†åˆ›æ„æ„æ€(ideation)ã€ä»£ç ç”Ÿæˆ(code)å’Œæ•°å­¦æ¨ç†(math)ä¸‰ä¸ªé¢†åŸŸï¼Œé€šè¿‡å—æ§çš„12è½®å¯¹è¯å®éªŒï¼Œå¯¹æ¯”äº†ä»æ¨¡ç³Šåé¦ˆåˆ°å®šå‘å¼•å¯¼(targeted steering)ç­‰ä¸åŒæç¤ºç­–ç•¥çš„æ•ˆæœã€‚ç ”ç©¶é€šè¿‡è¯­ä¹‰ç§»åŠ¨ã€è½®æ¬¡å˜åŒ–åŠè¾“å‡ºè§„æ¨¡å¢é•¿ç­‰æŒ‡æ ‡å‘ç°ï¼Œè¿­ä»£å¢ç›Šå…·æœ‰æ˜¾è‘—çš„é¢†åŸŸä¾èµ–æ€§ï¼šåˆ›æ„å’Œä»£ç çš„æå‡é›†ä¸­åœ¨æ—©æœŸï¼Œè€Œæ•°å­¦ä»»åŠ¡åˆ™åœ¨åæœŸé€šè¿‡è¯¦å°½é˜è¿°(elaboration)è·å¾—å¢ç›Šã€‚å®éªŒè¿›ä¸€æ­¥è¯å®ï¼Œæ¨¡ç³Šåé¦ˆåœ¨åˆæœŸè¿‡åå¾€å¾€ä¼šå¯¼è‡´æ€§èƒ½åœæ»æˆ–å€’é€€ï¼Œè€Œå®šå‘æç¤ºèƒ½æ›´å¯é åœ°å¼•å¯¼è´¨é‡ç»´åº¦çš„æå‡ã€‚è¯¥ç ”ç©¶ä¸ºè¡¡é‡å’Œæ¯”è¾ƒä¸åŒæ¨¡å‹çš„è¿­ä»£èƒ½åŠ›æä¾›äº†ç³»ç»ŸåŒ–å·¥å…·ï¼Œå¹¶ä¸ºåœ¨å®é™…åº”ç”¨ä¸­ä¼˜åŒ–è¿­ä»£ç­–ç•¥ã€ç¡®å®šåœæ­¢æ—¶æœºæä¾›äº†æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06770v2",
      "published_date": "2025-09-08 14:54:31 UTC",
      "updated_date": "2025-09-13 00:41:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:50.331146+00:00"
    },
    {
      "arxiv_id": "2509.06759v1",
      "title": "Aligning Large Vision-Language Models by Deep Reinforcement Learning and Direct Preference Optimization",
      "title_zh": "åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸ç›´æ¥åå¥½ä¼˜åŒ–çš„å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹å¯¹é½",
      "authors": [
        "Thanh Thi Nguyen",
        "Campbell Wilson",
        "Janis Dalins"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) or multimodal large language models represent a significant advancement in artificial intelligence, enabling systems to understand and generate content across both visual and textual modalities. While large-scale pretraining has driven substantial progress, fine-tuning these models for aligning with human values or engaging in specific tasks or behaviors remains a critical challenge. Deep Reinforcement Learning (DRL) and Direct Preference Optimization (DPO) offer promising frameworks for this aligning process. While DRL enables models to optimize actions using reward signals instead of relying solely on supervised preference data, DPO directly aligns the policy with preferences, eliminating the need for an explicit reward model. This overview explores paradigms for fine-tuning LVLMs, highlighting how DRL and DPO techniques can be used to align models with human preferences and values, improve task performance, and enable adaptive multimodal interaction. We categorize key approaches, examine sources of preference data, reward signals, and discuss open challenges such as scalability, sample efficiency, continual learning, generalization, and safety. The goal is to provide a clear understanding of how DRL and DPO contribute to the evolution of robust and human-aligned LVLMs.",
      "tldr_zh": "è¯¥ç»¼è¿°æ¢è®¨äº†åˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning, DRL)å’Œç›´æ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization, DPO)æ¥å¯¹é½å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(Large Vision-Language Models, LVLMs)çš„å¤šç§èŒƒå¼ã€‚è™½ç„¶å¤§è§„æ¨¡é¢„è®­ç»ƒæ˜¾è‘—æå‡äº†æ¨¡å‹èƒ½åŠ›ï¼Œä½†å¦‚ä½•ä½¿æ¨¡å‹ä¸äººç±»ä»·å€¼è§‚å¯¹é½å¹¶æå‡ç‰¹å®šä»»åŠ¡è¡¨ç°ä»æ˜¯æ ¸å¿ƒæŒ‘æˆ˜ã€‚æ–‡ç« è¯¦ç»†å¯¹æ¯”äº† DRL åˆ©ç”¨å¥–åŠ±ä¿¡å·ä¼˜åŒ–åŠ¨ä½œçš„æœºåˆ¶ï¼Œä»¥åŠ DPO æ— éœ€æ˜¾å¼å¥–åŠ±æ¨¡å‹ã€ç›´æ¥å°†ç­–ç•¥ä¸åå¥½å¯¹é½çš„ä¼˜åŠ¿ã€‚ç ”ç©¶è¿›ä¸€æ­¥åˆ†ç±»äº†å…³é”®çš„å¾®è°ƒæ–¹æ³•ï¼Œå¹¶åˆ†æäº†åå¥½æ•°æ®æ¥æºåŠå¥–åŠ±ä¿¡å·çš„æ„æˆã€‚æ­¤å¤–ï¼Œæ–‡ä¸­è¿˜æ·±å…¥è®¨è®ºäº†åœ¨å¯æ‰©å±•æ€§(Scalability)ã€æ ·æœ¬æ•ˆç‡(Sample Efficiency)å’Œå®‰å…¨æ€§(Safety)ç­‰æ–¹é¢çš„ç°æœ‰æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘é²æ£’ä¸”ç¬¦åˆäººç±»ä»·å€¼è§‚çš„ LVLMs æä¾›äº†ç³»ç»Ÿçš„ç†è®ºæ¡†æ¶å’Œæ¼”è¿›æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in the Proceedings of the 8th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.06759v1",
      "published_date": "2025-09-08 14:47:57 UTC",
      "updated_date": "2025-09-08 14:47:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:49.135292+00:00"
    },
    {
      "arxiv_id": "2509.06743v3",
      "title": "Long-Range Graph Wavelet Networks",
      "title_zh": "é•¿ç¨‹å›¾å°æ³¢ç½‘ç»œ",
      "authors": [
        "Filippo Guerranti",
        "Fabrizio Forte",
        "Simon Geisler",
        "Stephan GÃ¼nnemann"
      ],
      "abstract": "Modeling long-range interactions, the propagation of information across distant parts of a graph, is a central challenge in graph machine learning. Graph wavelets, inspired by multi-resolution signal processing, provide a principled way to capture both local and global structures. However, existing wavelet-based graph neural networks rely on finite-order polynomial approximations, which limit their receptive fields and hinder long-range propagation. We propose Long-Range Graph Wavelet Networks (LR-GWN), which decompose wavelet filters into complementary local and global components. Local aggregation is handled with efficient low-order polynomials, while long-range interactions are captured through a flexible spectral-domain parameterization. This hybrid design unifies short- and long-distance information flow within a principled wavelet framework. Experiments show that LR-GWN achieves state-of-the-art performance among wavelet-based methods on long-range benchmarks, while remaining competitive on short-range datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾æœºå™¨å­¦ä¹ ä¸­è¿œè·ç¦»äº¤äº’å»ºæ¨¡çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†é•¿ç¨‹å›¾å°æ³¢ç½‘ç»œï¼ˆLong-Range Graph Wavelet Networksï¼Œç®€ç§° LR-GWNï¼‰ã€‚é’ˆå¯¹ç°æœ‰åŸºäºå°æ³¢çš„å›¾ç¥ç»ç½‘ç»œå› ä¾èµ–æœ‰é™é˜¶å¤šé¡¹å¼é€¼è¿‘ï¼ˆfinite-order polynomial approximationsï¼‰è€Œå¯¼è‡´æ„Ÿå—é‡å—é™å¹¶é˜»ç¢é•¿ç¨‹ä¼ æ’­çš„é—®é¢˜ï¼ŒLR-GWN å°†å°æ³¢æ»¤æ³¢å™¨åˆ†è§£ä¸ºäº’è¡¥çš„å±€éƒ¨å’Œå…¨å±€ç»„ä»¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä½é˜¶å¤šé¡¹å¼å¤„ç†é«˜æ•ˆçš„å±€éƒ¨èšåˆï¼ŒåŒæ—¶é€šè¿‡çµæ´»çš„å…‰è°±åŸŸå‚æ•°åŒ–ï¼ˆspectral-domain parameterizationï¼‰æ•æ‰é•¿ç¨‹äº¤äº’ï¼Œä»è€Œåœ¨ç»Ÿä¸€çš„å°æ³¢æ¡†æ¶å†…èåˆäº†çŸ­ç¨‹ä¸é•¿ç¨‹ä¿¡æ¯æµã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLR-GWN åœ¨é•¿ç¨‹åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å°æ³¢ç±»æ–¹æ³•ä¸­çš„æœ€å…ˆè¿›æ€§èƒ½ï¼ˆstate-of-the-artï¼‰ï¼Œä¸”åœ¨çŸ­ç¨‹æ•°æ®é›†ä¸ŠåŒæ ·å…·å¤‡ç«äº‰åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: New Perspectives in Advancing Graph Machine Learning",
      "pdf_url": "https://arxiv.org/pdf/2509.06743v3",
      "published_date": "2025-09-08 14:35:30 UTC",
      "updated_date": "2025-10-13 08:56:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:52.531470+00:00"
    },
    {
      "arxiv_id": "2509.12233v1",
      "title": "Towards Trustworthy Agentic IoEV: AI Agents for Explainable Cyberthreat Mitigation and State Analytics",
      "title_zh": "è¿ˆå‘å¯ä¿¡çš„æ™ºèƒ½ä½“åŒ– IoEVï¼šç”¨äºå¯è§£é‡Šç½‘ç»œå¨èƒç¼“è§£ä¸çŠ¶æ€åˆ†æçš„ AI æ™ºèƒ½ä½“",
      "authors": [
        "Meryem Malak Dif",
        "Mouhamed Amine Bouchiha",
        "Abdelaziz Amara Korba",
        "Yacine Ghamri-Doudane"
      ],
      "abstract": "The Internet of Electric Vehicles (IoEV) envisions a tightly coupled ecosystem of electric vehicles (EVs), charging infrastructure, and grid services, yet it remains vulnerable to cyberattacks, unreliable battery-state predictions, and opaque decision processes that erode trust and performance. To address these challenges, we introduce a novel Agentic Artificial Intelligence (AAI) framework tailored for IoEV, where specialized agents collaborate to deliver autonomous threat mitigation, robust analytics, and interpretable decision support. Specifically, we design an AAI architecture comprising dedicated agents for cyber-threat detection and response at charging stations, real-time State of Charge (SoC) estimation, and State of Health (SoH) anomaly detection, all coordinated through a shared, explainable reasoning layer; develop interpretable threat-mitigation mechanisms that proactively identify and neutralize attacks on both physical charging points and learning components; propose resilient SoC and SoH models that leverage continuous and adversarial-aware learning to produce accurate, uncertainty-aware forecasts with human-readable explanations; and implement a three-agent pipeline, where each agent uses LLM-driven reasoning and dynamic tool invocation to interpret intent, contextualize tasks, and execute formal optimizations for user-centric assistance. Finally, we validate our framework through comprehensive experiments across diverse IoEV scenarios, demonstrating significant improvements in security and prediction accuracy. All datasets, models, and code will be released publicly.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µåŠ›è½¦è¾†ç‰©è”ç½‘ (Internet of Electric Vehicles, IoEV) åœ¨ç½‘ç»œæ”»å‡»ã€ç”µæ± çŠ¶æ€é¢„æµ‹ä¸å‡†ç¡®ä»¥åŠå†³ç­–è¿‡ç¨‹ä¸é€æ˜ç­‰æ–¹é¢é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„ä»£ç†äººå·¥æ™ºèƒ½ (Agentic Artificial Intelligence, AAI) æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°è‡ªä¸»å¨èƒç¼“è§£ã€ç¨³å¥åˆ†æå’Œå¯è§£é‡Šçš„å†³ç­–æ”¯æŒã€‚è¯¥æ¡†æ¶è®¾è®¡äº†ä¸“é—¨è´Ÿè´£å……ç”µç«™ç½‘ç»œå¨èƒæ£€æµ‹ã€å®æ—¶å‰©ä½™ç”µé‡ (State of Charge, SoC) ä¼°ç®—åŠå¥åº·çŠ¶æ€ (State of Health, SoH) å¼‚å¸¸æ£€æµ‹çš„å¤šä¸ªæ™ºèƒ½ä½“ï¼Œå¹¶é€šè¿‡å…±äº«çš„å¯è§£é‡Šæ¨ç†å±‚è¿›è¡Œåè°ƒã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼€å‘äº†å¯è¯†åˆ«å¹¶ä¸­å’Œç‰©ç†åŠé€»è¾‘æ”»å‡»çš„å¨èƒç¼“è§£æœºåˆ¶ï¼Œå¹¶åˆ©ç”¨è¿ç»­å­¦ä¹ ä¸å¯¹æŠ—æ„ŸçŸ¥å­¦ä¹ æ„å»ºäº†å…·å¤‡ä¸ç¡®å®šæ€§æ„ŸçŸ¥å’Œäººç±»å¯è¯»è§£é‡Šçš„é¢„æµ‹æ¨¡å‹ã€‚é€šè¿‡ç”±å¤§è¯­è¨€æ¨¡å‹ (LLM) é©±åŠ¨çš„æ¨ç†å’ŒåŠ¨æ€å·¥å…·è°ƒç”¨æµæ°´çº¿ï¼Œç³»ç»Ÿèƒ½å¤Ÿç²¾å‡†ç†è§£ä»»åŠ¡æ„å›¾å¹¶æ‰§è¡Œä¼˜åŒ–ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šç§ IoEV åœºæ™¯ä¸‹æ˜¾è‘—æå‡äº†ç³»ç»Ÿå®‰å…¨æ€§å’Œé¢„æµ‹å‡†ç¡®åº¦ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 7 figures, Accepted at LCN'25",
      "pdf_url": "https://arxiv.org/pdf/2509.12233v1",
      "published_date": "2025-09-08 14:28:53 UTC",
      "updated_date": "2025-09-08 14:28:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:56.650929+00:00"
    },
    {
      "arxiv_id": "2509.06736v1",
      "title": "VehicleWorld: A Highly Integrated Multi-Device Environment for Intelligent Vehicle Interaction",
      "title_zh": "VehicleWorldï¼šé¢å‘æ™ºèƒ½æ±½è½¦äº¤äº’çš„é«˜åº¦é›†æˆå¤šè®¾å¤‡ç¯å¢ƒ",
      "authors": [
        "Jie Yang",
        "Jiajun Chen",
        "Zhangyue Yin",
        "Shuo Chen",
        "Yuxin Wang",
        "Yiran Guo",
        "Yuan Li",
        "Yining Zheng",
        "Xuanjing Huang",
        "Xipeng Qiu"
      ],
      "abstract": "Intelligent vehicle cockpits present unique challenges for API Agents, requiring coordination across tightly-coupled subsystems that exceed typical task environments' complexity. Traditional Function Calling (FC) approaches operate statelessly, requiring multiple exploratory calls to build environmental awareness before execution, leading to inefficiency and limited error recovery. We introduce VehicleWorld, the first comprehensive environment for the automotive domain, featuring 30 modules, 250 APIs, and 680 properties with fully executable implementations that provide real-time state information during agent execution. This environment enables precise evaluation of vehicle agent behaviors across diverse, challenging scenarios. Through systematic analysis, we discovered that direct state prediction outperforms function calling for environmental control. Building on this insight, we propose State-based Function Call (SFC), a novel approach that maintains explicit system state awareness and implements direct state transitions to achieve target conditions. Experimental results demonstrate that SFC significantly outperforms traditional FC approaches, achieving superior execution accuracy and reduced latency. We have made all implementation code publicly available on Github https://github.com/OpenMOSS/VehicleWorld.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ™ºèƒ½åº§èˆ±ä¸­ API Agent é¢ä¸´çš„è·¨å­ç³»ç»Ÿåè°ƒæŒ‘æˆ˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„ Function Calling (FC) æ–¹æ³•å› æ— çŠ¶æ€æ€§å¯¼è‡´ç¯å¢ƒæ„ŸçŸ¥æ•ˆç‡ä½ä¸‹ä¸”é”™è¯¯æ¢å¤èƒ½åŠ›æœ‰é™ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæ¨å‡ºäº† VehicleWorldï¼Œè¿™æ˜¯æ±½è½¦é¢†åŸŸé¦–ä¸ªé«˜åº¦é›†æˆçš„å¤šè®¾å¤‡ç¯å¢ƒï¼ŒåŒ…å« 30 ä¸ªæ¨¡å—ã€250 ä¸ª API å’Œ 680 ä¸ªå±æ€§ï¼Œå¹¶æ”¯æŒå®æ—¶çŠ¶æ€åé¦ˆã€‚é€šè¿‡ç³»ç»Ÿæ€§åˆ†æï¼Œç ”ç©¶å‘ç°ç›´æ¥çŠ¶æ€é¢„æµ‹åœ¨ç¯å¢ƒæ§åˆ¶ä¸Šä¼˜äºå‡½æ•°è°ƒç”¨ï¼Œæ®æ­¤æå‡ºäº† State-based Function Call (SFC) æ–¹æ³•ï¼Œé€šè¿‡ç»´æŠ¤æ˜¾å¼çš„ç³»ç»ŸçŠ¶æ€æ„ŸçŸ¥å’Œæ‰§è¡Œç›´æ¥çŠ¶æ€è½¬æ¢æ¥å®ç°ç›®æ ‡æ¡ä»¶ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒSFC åœ¨æ‰§è¡Œå‡†ç¡®ç‡å’Œå“åº”å»¶è¿Ÿæ–¹é¢å‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿ FC æ–¹æ³•ã€‚ç›®å‰ï¼Œè¯¥ç¯å¢ƒçš„å®Œæ•´å®ç°ä»£ç å·²åœ¨ Github ä¸Šå…¬å¼€ï¼Œä¸ºè¯„ä¼°å’Œä¼˜åŒ–æ™ºèƒ½æ±½è½¦ Agent è¡Œä¸ºæä¾›äº†é‡è¦å¹³å°ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06736v1",
      "published_date": "2025-09-08 14:28:25 UTC",
      "updated_date": "2025-09-08 14:28:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:14:58.139608+00:00"
    },
    {
      "arxiv_id": "2509.06733v2",
      "title": "Reinforcement Learning Foundations for Deep Research Systems: A Survey",
      "title_zh": "æ·±åº¦ç ”ç©¶ç³»ç»Ÿçš„å¼ºåŒ–å­¦ä¹ åŸºç¡€ï¼šç»¼è¿°",
      "authors": [
        "Wenjun Li",
        "Zhi Chen",
        "Jingru Lin",
        "Hannan Cao",
        "Wei Han",
        "Sheng Liang",
        "Zhi Zhang",
        "Kuicai Dong",
        "Dexun Li",
        "Chen Zhang",
        "Yong Liu"
      ],
      "abstract": "Deep research systems, agentic AI that solve complex, multi-step tasks by coordinating reasoning, search across the open web and user files, and tool use, are moving toward hierarchical deployments with a Planner, Coordinator, and Executors. In practice, training entire stacks end-to-end remains impractical, so most work trains a single planner connected to core tools such as search, browsing, and code. While SFT imparts protocol fidelity, it suffers from imitation and exposure biases and underuses environment feedback. Preference alignment methods such as DPO are schema and proxy-dependent, off-policy, and weak for long-horizon credit assignment and multi-objective trade-offs. A further limitation of SFT and DPO is their reliance on human defined decision points and subskills through schema design and labeled comparisons. Reinforcement learning aligns with closed-loop, tool-interaction research by optimizing trajectory-level policies, enabling exploration, recovery behaviors, and principled credit assignment, and it reduces dependence on such human priors and rater biases.\n  This survey is, to our knowledge, the first dedicated to the RL foundations of deep research systems. It systematizes recent work along three axes: (i) data synthesis and curation; (ii) RL methods for agentic research covering stability, sample efficiency, long context handling, reward and credit design, multi-objective optimization, and multimodal integration; and (iii) agentic RL training systems and frameworks. We also cover agent architecture and coordination, as well as evaluation and benchmarks, including recent QA, VQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We distill recurring patterns, surface infrastructure bottlenecks, and offer practical guidance for training robust, transparent deep research agents with RL.",
      "tldr_zh": "è¯¥ç»¼è¿°æ¢è®¨äº†æ·±åº¦ç ”ç©¶ç³»ç»Ÿ (Deep Research Systems) åœ¨å¤„ç†å¤æ‚å¤šæ­¥ä»»åŠ¡æ—¶çš„ Reinforcement Learning (RL) åŸºç¡€ï¼Œåˆ†æäº†ä¼ ç»Ÿ SFT å’Œ DPO åœ¨é•¿æ—¶ç¨‹ä¿¡ç”¨åˆ†é… (Long-horizon credit assignment) å’Œå¤šç›®æ ‡æƒè¡¡æ–¹é¢çš„å±€é™ã€‚ç ”ç©¶å¼ºè°ƒ RL é€šè¿‡ä¼˜åŒ–è½¨è¿¹çº§ç­–ç•¥ï¼Œèƒ½æ˜¾è‘—æå‡æ™ºèƒ½ä½“çš„æ¢ç´¢èƒ½åŠ›ä¸æ¢å¤è¡Œä¸ºï¼Œé™ä½å¯¹äººç±»å…ˆéªŒå’Œæ ‡æ³¨åè§çš„ä¾èµ–ã€‚æœ¬æ–‡é¦–æ¬¡ä»æ•°æ®åˆæˆä¸æ•´ç† (Data synthesis and curation)ã€æ™ºèƒ½ä½“ RL æ–¹æ³•ä»¥åŠè®­ç»ƒç³»ç»Ÿæ¡†æ¶ä¸‰ä¸ªç»´åº¦å¯¹è¿‘æœŸç ”ç©¶è¿›è¡Œäº†ç³»ç»ŸåŒ–æ¢³ç†ã€‚æ–‡ä¸­è¯¦ç»†è®¨è®ºäº† RL åœ¨æå‡ç¨³å®šæ€§ã€é‡‡æ ·æ•ˆç‡ã€é•¿ä¸Šä¸‹æ–‡å¤„ç†åŠå¤šæ¨¡æ€é›†æˆç­‰å…³é”®æŠ€æœ¯ä¸Šçš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œç»¼è¿°è¿˜æ¶µç›–äº†æ™ºèƒ½ä½“æ¶æ„åè°ƒã€è¯„ä¼°åŸºå‡†ä»¥åŠå·¥å…·äº¤äº’ç­‰å‰æ²¿è¯¾é¢˜ã€‚é€šè¿‡æ€»ç»“è§„å¾‹å¹¶è¯†åˆ«åŸºç¡€è®¾æ–½ç“¶é¢ˆï¼Œè¯¥ç ”ç©¶ä¸ºæ„å»ºå¥å£®ã€é€æ˜çš„æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“æä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages, second version",
      "pdf_url": "https://arxiv.org/pdf/2509.06733v2",
      "published_date": "2025-09-08 14:27:23 UTC",
      "updated_date": "2025-11-05 15:14:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:15:03.434889+00:00"
    },
    {
      "arxiv_id": "2509.06713v1",
      "title": "MRI-Based Brain Tumor Detection through an Explainable EfficientNetV2 and MLP-Mixer-Attention Architecture",
      "title_zh": "åŸºäºå¯è§£é‡Š EfficientNetV2 ä¸ MLP-Mixer-Attention æ¶æ„çš„ MRI è„‘è‚¿ç˜¤æ£€æµ‹",
      "authors": [
        "Mustafa Yurdakul",
        "Åakir TaÅŸdemir"
      ],
      "abstract": "Brain tumors are serious health problems that require early diagnosis due to their high mortality rates. Diagnosing tumors by examining Magnetic Resonance Imaging (MRI) images is a process that requires expertise and is prone to error. Therefore, the need for automated diagnosis systems is increasing day by day. In this context, a robust and explainable Deep Learning (DL) model for the classification of brain tumors is proposed. In this study, a publicly available Figshare dataset containing 3,064 T1-weighted contrast-enhanced brain MRI images of three tumor types was used. First, the classification performance of nine well-known CNN architectures was evaluated to determine the most effective backbone. Among these, EfficientNetV2 demonstrated the best performance and was selected as the backbone for further development. Subsequently, an attention-based MLP-Mixer architecture was integrated into EfficientNetV2 to enhance its classification capability. The performance of the final model was comprehensively compared with basic CNNs and the methods in the literature. Additionally, Grad-CAM visualization was used to interpret and validate the decision-making process of the proposed model. The proposed model's performance was evaluated using the five-fold cross-validation method. The proposed model demonstrated superior performance with 99.50% accuracy, 99.47% precision, 99.52% recall and 99.49% F1 score. The results obtained show that the model outperforms the studies in the literature. Moreover, Grad-CAM visualizations demonstrate that the model effectively focuses on relevant regions of MRI images, thus improving interpretability and clinical reliability. A robust deep learning model for clinical decision support systems has been obtained by combining EfficientNetV2 and attention-based MLP-Mixer, providing high accuracy and interpretability in brain tumor classification.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è„‘è‚¿ç˜¤æ—©æœŸè¯Šæ–­ä¸­äººå·¥åˆ†æ Magnetic Resonance Imaging (MRI) å›¾åƒæ˜“å‡ºé”™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå¯è§£é‡Šæ€§ä¸é«˜æ•ˆåˆ†ç±»èƒ½åŠ›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚é€šè¿‡è¯„ä¼°ä¹ç§ä¸»æµå·ç§¯ç¥ç»ç½‘ç»œ (CNN) æ¶æ„ï¼Œç ”ç©¶ç¡®å®š EfficientNetV2 ä¸ºæ€§èƒ½æœ€ä¼˜çš„éª¨å¹²ç½‘ç»œï¼Œå¹¶è¿›ä¸€æ­¥å°†åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ MLP-Mixer æ¶æ„é›†æˆå…¶ä¸­ä»¥å¢å¼ºç‰¹å¾æå–èƒ½åŠ›ã€‚å®éªŒåœ¨åŒ…å« 3,064 å¼ å›¾åƒçš„ Figshare å…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œé‡‡ç”¨äº”æŠ˜äº¤å‰éªŒè¯ (five-fold cross-validation) ç¡®ä¿äº†ç»“æœçš„ç¨³å¥æ€§ã€‚ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨è„‘è‚¿ç˜¤åˆ†ç±»ä¸­å–å¾—äº† 99.50% çš„å‡†ç¡®ç‡ (accuracy) å’Œ 99.49% çš„ F1 åˆ†æ•° (F1 score)ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–‡çŒ®ä¸­çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶åˆ©ç”¨ Grad-CAM æŠ€æœ¯å®ç°äº†å†³ç­–è¿‡ç¨‹çš„å¯è§†åŒ–ï¼Œè¯æ˜æ¨¡å‹èƒ½ç²¾å‡†å…³æ³¨ MRI å›¾åƒä¸­çš„ç—…å˜ç›¸å…³åŒºåŸŸã€‚è¿™ç§èåˆäº† EfficientNetV2 ä¸ MLP-Mixer-Attention çš„æ¶æ„ä¸ºä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿæä¾›äº†ä¸€ç§é«˜ç²¾åº¦ä¸”å…·å¤‡å¯é å¯è§£é‡Šæ€§çš„è‡ªåŠ¨åŒ–è¯Šæ–­æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06713v1",
      "published_date": "2025-09-08 14:08:21 UTC",
      "updated_date": "2025-09-08 14:08:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:15:07.645550+00:00"
    },
    {
      "arxiv_id": "2509.06701v1",
      "title": "Probabilistic Modeling of Latent Agentic Substructures in Deep Neural Networks",
      "title_zh": "æ·±åº¦ç¥ç»ç½‘ç»œä¸­æ½œåœ¨æ™ºèƒ½ä½“å­ç»“æ„çš„æ¦‚ç‡å»ºæ¨¡",
      "authors": [
        "Su Hyeong Lee",
        "Risi Kondor",
        "Richard Ngo"
      ],
      "abstract": "We develop a theory of intelligent agency grounded in probabilistic modeling for neural models. Agents are represented as outcome distributions with epistemic utility given by log score, and compositions are defined through weighted logarithmic pooling that strictly improves every member's welfare. We prove that strict unanimity is impossible under linear pooling or in binary outcome spaces, but possible with three or more outcomes. Our framework admits recursive structure via cloning invariance, continuity, and openness, while tilt-based analysis rules out trivial duplication. Finally, we formalize an agentic alignment phenomenon in LLMs using our theory: eliciting a benevolent persona (\"Luigi'\") induces an antagonistic counterpart (\"Waluigi\"), while a manifest-then-suppress Waluigi strategy yields strictly larger first-order misalignment reduction than pure Luigi reinforcement alone. These results clarify how developing a principled mathematical framework for how subagents can coalesce into coherent higher-level entities provides novel implications for alignment in agentic AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºæ¦‚ç‡å»ºæ¨¡çš„æ·±åº¦ç¥ç»ç½‘ç»œæ½œåœ¨æ™ºèƒ½ä½“å­ç»“æ„(Latent Agentic Substructures)ç†è®ºæ¡†æ¶ï¼Œå°†æ™ºèƒ½ä½“è¡¨ç¤ºä¸ºä»¥å¯¹æ•°åˆ†æ•°ä¸ºè®¤çŸ¥æ•ˆç”¨çš„ç»“æœåˆ†å¸ƒã€‚è¯¥æ¡†æ¶é€šè¿‡åŠ æƒå¯¹æ•°æ± åŒ–(Weighted Logarithmic Pooling)å®šä¹‰æ™ºèƒ½ä½“ç»„åˆï¼Œå¹¶è¯æ˜è¿™ç§æ–¹å¼èƒ½ä¸¥æ ¼æå‡æ¯ä¸ªæˆå‘˜çš„ç¦åˆ©ã€‚ç ”ç©¶è¯æ˜äº†åœ¨å…·æœ‰ä¸‰ä¸ªæˆ–æ›´å¤šç»“æœæ—¶å¯ä»¥å®ç°ä¸¥æ ¼çš„ä¸€è‡´æ€§ï¼Œå¹¶åˆ©ç”¨å…‹éš†ä¸å˜æ€§(Cloning Invariance)ç­‰ç‰¹æ€§æ”¯æŒé€’å½’ç»“æ„ã€‚æ­¤å¤–ï¼Œè¯¥ç†è®ºå½¢å¼åŒ–äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­çš„å¯¹é½ç°è±¡ï¼Œç‰¹åˆ«æ˜¯æ­ç¤ºäº†è¯±å¯¼å–„è‰¯äººæ ¼(Luigi)ä¼šè¯±å‘å¯¹æŠ—æ€§äººæ ¼(Waluigi)çš„æœºåˆ¶ã€‚ç ”ç©¶å‘ç°ï¼Œâ€œæ˜¾ç°åæŠ‘åˆ¶â€(Manifest-then-suppress)å¯¹æŠ—äººæ ¼çš„ç­–ç•¥åœ¨å‡å°‘å¯¹é½åå·®æ–¹é¢æ¯”çº¯ç²¹çš„æ­£å‘å¼ºåŒ–æ›´æœ‰æ•ˆã€‚è¿™äº›æˆæœé˜æ˜äº†å­æ™ºèƒ½ä½“å¦‚ä½•èåˆæˆè¿è´¯çš„é«˜å±‚å®ä½“ï¼Œå¹¶ä¸ºæ™ºèƒ½ä½“AIç³»ç»Ÿçš„å¯¹é½(Alignment)æä¾›äº†æ–°çš„æ•°å­¦è§£é‡Šå’Œå®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06701v1",
      "published_date": "2025-09-08 13:55:01 UTC",
      "updated_date": "2025-09-08 13:55:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:15:38.734995+00:00"
    },
    {
      "arxiv_id": "2509.06694v3",
      "title": "Barycentric Neural Networks and Length-Weighted Persistent Entropy Loss: A Green Geometric and Topological Framework for Function Approximation",
      "title_zh": "é‡å¿ƒç¥ç»ç½‘ç»œä¸é•¿åº¦åŠ æƒæŒä¹…ç†µæŸå¤±ï¼šä¸€ç§ç”¨äºå‡½æ•°é€¼è¿‘çš„ç»¿è‰²å‡ ä½•æ‹“æ‰‘æ¡†æ¶",
      "authors": [
        "Victor Toscano-Duran",
        "Rocio Gonzalez-Diaz",
        "Miguel A. GutiÃ©rrez-Naranjo"
      ],
      "abstract": "While artificial neural networks are known as universal approximators for continuous functions, many modern approaches rely on overparameterized architectures with high computational cost. In this work, we introduce the Barycentric Neural Network (BNN): a compact shallow architecture that encodes both structure and parameters through a fixed set of base points and their associated barycentric coordinates. We show that the BNN enables the exact representation of continuous piecewise linear functions (CPLFs), ensuring strict continuity across segments. Given that any continuous function on a compact domain can be uniformly approximated by CPLFs, the BNN emerges as a flexible and interpretable tool for function approximation.\n  To enhance geometric fidelity in low-resource scenarios, such as those with few base points to create BNNs or limited training epochs, we propose length-weighted persistent entropy (LWPE): a stable variant of persistent entropy. Our approach integrates the BNN with a loss function based on LWPE to optimize the base points that define the BNN, rather than its internal parameters. Experimental results show that our approach achieves superior and faster approximation performance compared to standard losses (MSE, RMSE, MAE and LogCosh), offering a computationally sustainable alternative for function approximation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºBarycentric Neural Network (BNN)çš„ç´§å‡‘æµ…å±‚æ¶æ„ï¼Œä½œä¸ºä¸€ç§ç»¿è‰²çš„å‡ ä½•ä¸æ‹“æ‰‘æ¡†æ¶ï¼Œæ—¨åœ¨ä»¥è¾ƒä½çš„è®¡ç®—æˆæœ¬å®ç°Function Approximationã€‚BNNåˆ©ç”¨å›ºå®šçš„ä¸€ç»„Base PointsåŠå…¶Barycentric Coordinatesæ¥ç¼–ç æ¨¡å‹ç»“æ„ä¸å‚æ•°ï¼Œèƒ½å¤Ÿç²¾ç¡®è¡¨ç¤ºContinuous Piecewise Linear Functions (CPLFs)å¹¶ç¡®ä¿å…¨å±€è¿ç»­æ€§ã€‚é’ˆå¯¹Base Pointsè¾ƒå°‘æˆ–è®­ç»ƒå‘¨æœŸå—é™çš„Low-resourceåœºæ™¯ï¼Œç ”ç©¶è€…å¼•å…¥äº†Length-weighted Persistent Entropy (LWPE)è¿™ä¸€ç¨³å®šçš„æ‹“æ‰‘æŸå¤±å‡½æ•°ï¼Œé€šè¿‡ä¼˜åŒ–Base Pointsè€Œéå†…éƒ¨å‚æ•°æ¥å¢å¼ºå‡ ä½•ä¿çœŸåº¦ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒBNNç»“åˆLWPEæŸå¤±å‡½æ•°åœ¨é€¼è¿‘æ€§èƒ½å’Œæ”¶æ•›é€Ÿåº¦ä¸Šå‡ä¼˜äºMSEã€RMSEã€MAEåŠLogCoshç­‰ä¼ ç»ŸæŸå¤±å‡½æ•°ï¼Œä¸ºFunction Approximationæä¾›äº†ä¸€ç§è®¡ç®—é«˜æ•ˆä¸”å…·æœ‰é«˜åº¦å¯è§£é‡Šæ€§çš„å¯æŒç»­æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06694v3",
      "published_date": "2025-09-08 13:47:21 UTC",
      "updated_date": "2025-10-09 09:47:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:15:56.575091+00:00"
    },
    {
      "arxiv_id": "2509.06690v1",
      "title": "BioLite U-Net: Edge-Deployable Semantic Segmentation for In Situ Bioprinting Monitoring",
      "title_zh": "BioLite U-Netï¼šé¢å‘åŸä½ç”Ÿç‰©æ‰“å°ç›‘æµ‹çš„è¾¹ç¼˜å¯éƒ¨ç½²è¯­ä¹‰åˆ†å‰²",
      "authors": [
        "Usman Haider",
        "Lukasz Szemet",
        "Daniel Kelly",
        "Vasileios Sergis",
        "Andrew C. Daly",
        "Karl Mason"
      ],
      "abstract": "Bioprinting is a rapidly advancing field that offers a transformative approach to fabricating tissue and organ models through the precise deposition of cell-laden bioinks. Ensuring the fidelity and consistency of printed structures in real-time remains a core challenge, particularly under constraints imposed by limited imaging data and resource-constrained embedded hardware. Semantic segmentation of the extrusion process, differentiating between nozzle, extruded bioink, and surrounding background, enables in situ monitoring critical to maintaining print quality and biological viability. In this work, we introduce a lightweight semantic segmentation framework tailored for real-time bioprinting applications. We present a novel, manually annotated dataset comprising 787 RGB images captured during the bioprinting process, labeled across three classes: nozzle, bioink, and background. To achieve fast and efficient inference suitable for integration with bioprinting systems, we propose a BioLite U-Net architecture that leverages depthwise separable convolutions to drastically reduce computational load without compromising accuracy. Our model is benchmarked against MobileNetV2 and MobileNetV3-based segmentation baselines using mean Intersection over Union (mIoU), Dice score, and pixel accuracy. All models were evaluated on a Raspberry Pi 4B to assess real-world feasibility. The proposed BioLite U-Net achieves an mIoU of 92.85% and a Dice score of 96.17%, while being over 1300x smaller than MobileNetV2-DeepLabV3+. On-device inference takes 335 ms per frame, demonstrating near real-time capability. Compared to MobileNet baselines, BioLite U-Net offers a superior tradeoff between segmentation accuracy, efficiency, and deployability, making it highly suitable for intelligent, closed-loop bioprinting systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†BioLite U-Netï¼Œä¸€ç§ä¸“ä¸ºç”Ÿç‰©æ‰“å°ï¼ˆBioprintingï¼‰åŸä½ç›‘æ§è®¾è®¡çš„è½»é‡çº§è¯­ä¹‰åˆ†å‰²ï¼ˆSemantic Segmentationï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åµŒå…¥å¼ç¡¬ä»¶èµ„æºå—é™ä¸‹çš„å®æ—¶ç›‘æµ‹éš¾é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿè´¡çŒ®äº†ä¸€ä¸ªåŒ…å«787å¼ æ‰‹å·¥æ ‡æ³¨å›¾åƒçš„æ–°æ•°æ®é›†ï¼Œç”¨äºç²¾å‡†è¯†åˆ«å–·å˜´ï¼ˆNozzleï¼‰ã€å·²æŒ¤å‡ºçš„ç”Ÿç‰©å¢¨æ°´ï¼ˆBioinkï¼‰åŠèƒŒæ™¯ã€‚é€šè¿‡å¼•å…¥æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆDepthwise Separable Convolutionsï¼‰ï¼ŒBioLite U-Netåœ¨æ˜¾è‘—é™ä½è®¡ç®—è´Ÿè½½çš„åŒæ—¶ä¿æŒäº†é«˜ç²¾åº¦ï¼Œå…¶åœ¨æ ‘è“æ´¾4Bï¼ˆRaspberry Pi 4Bï¼‰ä¸Šè¾¾åˆ°äº†92.85%çš„mIoUå’Œ96.17%çš„Diceè¯„åˆ†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹ä½“ç§¯æ¯”MobileNetV2-DeepLabV3+ç¼©å°äº†1300å€ä»¥ä¸Šï¼Œä¸”å•å¸§æ¨ç†æ—¶é—´ä»…ä¸º335æ¯«ç§’ï¼Œå…·å¤‡è¿‘ä¹å®æ—¶çš„å¤„ç†èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œåœ¨åˆ†å‰²ç²¾åº¦ã€è¿è¡Œæ•ˆç‡ä¸è¾¹ç¼˜ç«¯å¯éƒ¨ç½²æ€§ä¹‹é—´å®ç°äº†ä¼˜å¼‚å¹³è¡¡ï¼Œä¸ºæ„å»ºæ™ºèƒ½é—­ç¯ç”Ÿç‰©æ‰“å°ç³»ç»Ÿæä¾›äº†å…³é”®æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures, conference-style submission (ICRA 2026). Includes dataset description, BioLite U-Net architecture, benchmark results on edge device (Raspberry Pi 4B)",
      "pdf_url": "https://arxiv.org/pdf/2509.06690v1",
      "published_date": "2025-09-08 13:44:55 UTC",
      "updated_date": "2025-09-08 13:44:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:15:56.859101+00:00"
    },
    {
      "arxiv_id": "2509.06665v1",
      "title": "TrajAware: Graph Cross-Attention and Trajectory-Aware for Generalisable VANETs under Partial Observations",
      "title_zh": "TrajAwareï¼šé¢å‘éƒ¨åˆ†è§‚æµ‹ä¸‹å¯æ³›åŒ–è½¦è½½è‡ªç»„ç»‡ç½‘ç»œçš„å›¾äº¤å‰æ³¨æ„åŠ›ä¸è½¨è¿¹æ„ŸçŸ¥",
      "authors": [
        "Xiaolu Fu",
        "Ziyuan Bao",
        "Eiman Kanjo"
      ],
      "abstract": "Vehicular ad hoc networks (VANETs) are a crucial component of intelligent transportation systems; however, routing remains challenging due to dynamic topologies, incomplete observations, and the limited resources of edge devices. Existing reinforcement learning (RL) approaches often assume fixed graph structures and require retraining when network conditions change, making them unsuitable for deployment on constrained hardware. We present TrajAware, an RL-based framework designed for edge AI deployment in VANETs. TrajAware integrates three components: (i) action space pruning, which reduces redundant neighbour options while preserving two-hop reachability, alleviating the curse of dimensionality; (ii) graph cross-attention, which maps pruned neighbours to the global graph context, producing features that generalise across diverse network sizes; and (iii) trajectory-aware prediction, which uses historical routes and junction information to estimate real-time positions under partial observations. We evaluate TrajAware in the open-source SUMO simulator using real-world city maps with a leave-one-city-out setup. Results show that TrajAware achieves near-shortest paths and high delivery ratios while maintaining efficiency suitable for constrained edge devices, outperforming state-of-the-art baselines in both full and partial observation scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TrajAwareï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹è½¦è½½è‡ªç»„ç»‡ç½‘ç»œ(VANETs)è®¾è®¡çš„å¼ºåŒ–å­¦ä¹ (RL)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŠ¨æ€æ‹“æ‰‘ã€éƒ¨åˆ†è§‚æµ‹å’Œè¾¹ç¼˜è®¾å¤‡èµ„æºå—é™å¸¦æ¥çš„è·¯ç”±æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆåŠ¨ä½œç©ºé—´å‰ªæ(action space pruning)å‡å°‘å†—ä½™é‚»å±…é€‰é¡¹å¹¶ä¿æŒä¸¤è·³å¯è¾¾æ€§ï¼Œä»è€Œç¼“è§£ç»´åº¦ç¾éš¾ã€‚åŒæ—¶ï¼Œåˆ©ç”¨å›¾äº¤å‰æ³¨æ„åŠ›(graph cross-attention)æœºåˆ¶å°†å‰ªæåçš„é‚»å±…æ˜ å°„åˆ°å…¨å±€å›¾ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆå…·å¤‡è·¨ç½‘ç»œè§„æ¨¡æ³›åŒ–èƒ½åŠ›çš„ç‰¹å¾ï¼Œå¹¶ç»“åˆè½¨è¿¹æ„ŸçŸ¥é¢„æµ‹(trajectory-aware prediction)åœ¨éƒ¨åˆ†è§‚æµ‹ä¸‹ä¼°ç®—å®æ—¶ä½ç½®ã€‚å®éªŒåœ¨SUMOæ¨¡æ‹Ÿå™¨åŠçœŸå®åŸå¸‚åœ°å›¾ä¸­é‡‡ç”¨ç•™ä¸€åŸå¸‚è®¾ç½®è¿›è¡Œè¯„ä¼°ã€‚ç»“æœæ˜¾ç¤ºï¼ŒTrajAwareåœ¨ä¿æŒè¾¹ç¼˜è®¾å¤‡é«˜æ•ˆè¿è¡Œçš„åŒæ—¶ï¼Œå®ç°äº†æ¥è¿‘æœ€çŸ­è·¯å¾„çš„è·¯ç”±å’Œé«˜äº¤ä»˜ç‡ï¼Œåœ¨å…¨è§‚æµ‹å’Œéƒ¨åˆ†è§‚æµ‹åœºæ™¯ä¸‹å‡ä¼˜äºç°æœ‰å…ˆè¿›åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.06665v1",
      "published_date": "2025-09-08 13:24:21 UTC",
      "updated_date": "2025-09-08 13:24:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:15:59.360057+00:00"
    },
    {
      "arxiv_id": "2509.06654v1",
      "title": "AnalysisGNN: Unified Music Analysis with Graph Neural Networks",
      "title_zh": "AnalysisGNNï¼šåŸºäºå›¾ç¥ç»ç½‘ç»œçš„ç»Ÿä¸€éŸ³ä¹åˆ†æ",
      "authors": [
        "Emmanouil Karystinaios",
        "Johannes Hentschel",
        "Markus Neuwirth",
        "Gerhard Widmer"
      ],
      "abstract": "Recent years have seen a boom in computational approaches to music analysis, yet each one is typically tailored to a specific analytical domain. In this work, we introduce AnalysisGNN, a novel graph neural network framework that leverages a data-shuffling strategy with a custom weighted multi-task loss and logit fusion between task-specific classifiers to integrate heterogeneously annotated symbolic datasets for comprehensive score analysis. We further integrate a Non-Chord-Tone prediction module, which identifies and excludes passing and non-functional notes from all tasks, thereby improving the consistency of label signals. Experimental evaluations demonstrate that AnalysisGNN achieves performance comparable to traditional static-dataset approaches, while showing increased resilience to domain shifts and annotation inconsistencies across multiple heterogeneous corpora.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AnalysisGNNï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æ•´åˆå¼‚æ„æ ‡æ³¨ç¬¦å·æ•°æ®é›†è¿›è¡Œå…¨é¢ä¹è°±åˆ†æçš„æ–°å‹ Graph Neural Networks (GNN) æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†æ•°æ®æ‰“ä¹±ç­–ç•¥ (data-shuffling strategy)ã€è‡ªå®šä¹‰åŠ æƒå¤šä»»åŠ¡æŸå¤± (weighted multi-task loss) ä»¥åŠä»»åŠ¡ç‰¹å®šåˆ†ç±»å™¨é—´çš„é€»è¾‘èåˆ (logit fusion)ï¼Œæœ‰æ•ˆåœ°ç»Ÿä¸€äº†ä¸åŒé¢†åŸŸçš„éŸ³ä¹åˆ†æä»»åŠ¡ã€‚ä¸ºäº†æå‡æ ‡ç­¾ä¿¡å·çš„ä¸€è‡´æ€§ï¼Œç ”ç©¶è¿›ä¸€æ­¥é›†æˆäº†ä¸€ä¸ªéå’Œå¼¦éŸ³é¢„æµ‹æ¨¡å— (Non-Chord-Tone prediction module)ï¼Œé€šè¿‡è¯†åˆ«å¹¶æ’é™¤ç»è¿‡éŸ³åŠéåŠŸèƒ½æ€§éŸ³ç¬¦æ¥ä¼˜åŒ–åˆ†æè¿‡ç¨‹ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒAnalysisGNN åœ¨å¤šä¸ªå¼‚æ„è¯­æ–™åº“ä¸Šçš„è¡¨ç°ä¸ä¼ ç»Ÿé’ˆå¯¹ç‰¹å®šæ•°æ®é›†çš„æ–¹æ³•ç›¸å½“ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨åº”å¯¹åŸŸåç§» (domain shifts) å’Œæ ‡æ³¨ä¸ä¸€è‡´æ€§æ–¹é¢å±•ç°å‡ºäº†æ›´å¼ºçš„éŸ§æ€§ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚éŸ³ä¹åˆ†æä»»åŠ¡ä¸­çš„ç¨³å¥æ€§ä¸é€šç”¨æ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at the 17th International Symposium on Computer Music Multidisciplinary Research (CMMR) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.06654v1",
      "published_date": "2025-09-08 13:11:54 UTC",
      "updated_date": "2025-09-08 13:11:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:05.070735+00:00"
    },
    {
      "arxiv_id": "2509.06641v3",
      "title": "CogGuide: Human-Like Guidance for Zero-Shot Omni-Modal Reasoning",
      "title_zh": "CogGuideï¼šé¢å‘é›¶æ ·æœ¬å…¨æ¨¡æ€æ¨ç†çš„ç±»äººåŒ–å¼•å¯¼",
      "authors": [
        "Zhou-Peng Shou",
        "Zhi-Qiang You",
        "Fang Wang",
        "Hai-Bo Liu"
      ],
      "abstract": "Targeting the issues of \"shortcuts\" and insufficient contextual understanding in complex cross-modal reasoning of multimodal large models, this paper proposes a zero-shot multimodal reasoning component guided by human-like cognitive strategies centered on an \"intent sketch\". The component comprises a plug-and-play three-module pipeline-Intent Perceiver, Strategy Generator, and Strategy Selector-that explicitly constructs a \"understand-plan-select\" cognitive process. By generating and filtering \"intent sketch\" strategies to guide the final reasoning, it requires no parameter fine-tuning and achieves cross-model transfer solely through in-context engineering. Information-theoretic analysis shows that this process can reduce conditional entropy and improve information utilization efficiency, thereby suppressing unintended shortcut reasoning. Experiments on IntentBench, WorldSense, and Daily-Omni validate the method's generality and robust gains; compared with their respective baselines, the complete \"three-module\" scheme yields consistent improvements across different reasoning engines and pipeline combinations, with gains up to approximately 9.51 percentage points, demonstrating the practical value and portability of the \"intent sketch\" reasoning component in zero-shot scenarios.",
      "tldr_zh": "é’ˆå¯¹å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨å¤æ‚è·¨æ¨¡æ€æ¨ç†ä¸­å­˜åœ¨çš„â€œshortcutsâ€å’Œä¸Šä¸‹æ–‡ç†è§£ä¸è¶³é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† CogGuideï¼Œä¸€ç§ä»¥â€œintent sketchâ€ä¸ºæ ¸å¿ƒã€æ¨¡æ‹Ÿäººç±»è®¤çŸ¥ç­–ç•¥çš„ zero-shot å¤šæ¨¡æ€æ¨ç†ç»„ä»¶ã€‚è¯¥ç»„ä»¶ç”± Intent Perceiverã€Strategy Generator å’Œ Strategy Selector ä¸‰ä¸ªæ¨¡å—ç»„æˆï¼Œé€šè¿‡æ˜¾å¼æ„å»ºâ€œunderstand-plan-selectâ€çš„è®¤çŸ¥è¿‡ç¨‹æ¥å¼•å¯¼æœ€ç»ˆæ¨ç†ã€‚ä½œä¸ºä¸€ä¸ªå³æ’å³ç”¨çš„æ–¹æ¡ˆï¼ŒCogGuide æ— éœ€ parameter fine-tuningï¼Œä»…ä¾é  in-context engineering å³å¯å®ç°è·¨æ¨¡å‹è¿ç§»ã€‚ä¿¡æ¯è®ºåˆ†æè¯æ˜ï¼Œè¯¥è¿‡ç¨‹èƒ½å¤Ÿé™ä½ conditional entropy å¹¶æé«˜ä¿¡æ¯åˆ©ç”¨æ•ˆç‡ï¼Œä»è€Œæœ‰æ•ˆæŠ‘åˆ¶æ— æ„è¯†çš„ shortcut æ¨ç†ã€‚åœ¨ IntentBenchã€WorldSense å’Œ Daily-Omni ç­‰æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨ä¸åŒæ¨ç†å¼•æ“ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—çš„é€šç”¨æ€§ã€‚ç›¸æ¯”å„è‡ªçš„åŸºçº¿æ¨¡å‹ï¼Œå®Œæ•´çš„â€œä¸‰æ¨¡å—â€æ–¹æ¡ˆåœ¨ zero-shot åœºæ™¯ä¸‹å®ç°äº†æœ€é«˜çº¦ 9.51 ä¸ªç™¾åˆ†ç‚¹çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†è¯¥æ¨ç†ç»„ä»¶çš„å®é™…ä»·å€¼ä¸å¯ç§»æ¤æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06641v3",
      "published_date": "2025-09-08 12:57:02 UTC",
      "updated_date": "2025-09-15 16:57:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:06.283485+00:00"
    },
    {
      "arxiv_id": "2509.06635v1",
      "title": "The First Voice Timbre Attribute Detection Challenge",
      "title_zh": "é¦–å±ŠéŸ³è‰²å±æ€§æ£€æµ‹æŒ‘æˆ˜èµ›",
      "authors": [
        "Liping Chen",
        "Jinghao He",
        "Zhengyan Sheng",
        "Kong Aik Lee",
        "Zhen-Hua Ling"
      ],
      "abstract": "The first voice timbre attribute detection challenge is featured in a special session at NCMMSC 2025. It focuses on the explainability of voice timbre and compares the intensity of two speech utterances in a specified timbre descriptor dimension. The evaluation was conducted on the VCTK-RVA dataset. Participants developed their systems and submitted their outputs to the organizer, who evaluated the performance and sent feedback to them. Six teams submitted their outputs, with five providing descriptions of their methodologies.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†åœ¨NCMMSC 2025ç‰¹åˆ«ä¼šè®®ä¸Šä¸¾åŠçš„é¦–å±ŠéŸ³è‰²å±æ€§æ£€æµ‹æŒ‘æˆ˜èµ›(First Voice Timbre Attribute Detection Challenge)ã€‚è¯¥ç«èµ›çš„æ ¸å¿ƒç›®æ ‡æ˜¯æå‡è¯­éŸ³éŸ³è‰²(Voice Timbre)çš„å¯è§£é‡Šæ€§ï¼Œè¦æ±‚åœ¨é¢„å®šä¹‰çš„éŸ³è‰²æè¿°ç¬¦(Timbre Descriptor)ç»´åº¦ä¸Šå¯¹æ¯”ä¸¤æ®µè¯­éŸ³çš„å¼ºåº¦å·®å¼‚ã€‚å®éªŒè¯„ä¼°åŸºäºVCTK-RVAæ•°æ®é›†å¼€å±•ï¼Œç”±ç»„ç»‡è€…å¯¹å„å‚èµ›ç³»ç»Ÿæäº¤çš„è¾“å‡ºè¿›è¡Œç»Ÿä¸€æ€§èƒ½è¡¡é‡ã€‚æœ€ç»ˆå…±æœ‰å…­æ”¯å›¢é˜Ÿå®Œæˆæäº¤ï¼Œå…¶ä¸­äº”æ”¯å›¢é˜Ÿåˆ†äº«äº†å…¶ç³»ç»Ÿçš„æ„å»ºæ–¹æ³•ï¼Œä¸ºéŸ³è‰²å±æ€§æ£€æµ‹é¢†åŸŸçš„ç®—æ³•å‘å±•æä¾›äº†é‡è¦çš„åŸºå‡†å’Œæ€è·¯ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06635v1",
      "published_date": "2025-09-08 12:54:28 UTC",
      "updated_date": "2025-09-08 12:54:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:08.466544+00:00"
    },
    {
      "arxiv_id": "2509.06625v2",
      "title": "Improved Classification of Nitrogen Stress Severity in Plants Under Combined Stress Conditions Using Spatio-Temporal Deep Learning Framework",
      "title_zh": "åŸºäºæ—¶ç©ºæ·±åº¦å­¦ä¹ æ¡†æ¶çš„å¤åˆèƒè¿«ç¯å¢ƒä¸‹æ¤ç‰©æ°®ç´ èƒè¿«ä¸¥é‡ç¨‹åº¦çš„æ”¹è¿›åˆ†ç±»",
      "authors": [
        "Aswini Kumar Patra",
        "Lingaraj Sahoo"
      ],
      "abstract": "Plants in their natural habitats endure an array of interacting stresses, both biotic and abiotic, that rarely occur in isolation. Nutrient stress-particularly nitrogen deficiency-becomes even more critical when compounded with drought and weed competition, making it increasingly difficult to distinguish and address its effects. Early detection of nitrogen stress is therefore crucial for protecting plant health and implementing effective management strategies. This study proposes a novel deep learning framework to accurately classify nitrogen stress severity in a combined stress environment. Our model uses a unique blend of four imaging modalities-RGB, multispectral, and two infrared wavelengths-to capture a wide range of physiological plant responses from canopy images. These images, provided as time-series data, document plant health across three levels of nitrogen availability (low, medium, and high) under varying water stress and weed pressures. The core of our approach is a spatio-temporal deep learning pipeline that merges a Convolutional Neural Network (CNN) for extracting spatial features from images with a Long Short-Term Memory (LSTM) network to capture temporal dependencies. We also devised and evaluated a spatial-only CNN pipeline for comparison. Our CNN-LSTM pipeline achieved an impressive accuracy of 98%, impressively surpassing the spatial-only model's 80.45% and other previously reported machine learning method's 76%. These results bring actionable insights based on the power of our CNN-LSTM approach in effectively capturing the subtle and complex interactions between nitrogen deficiency, water stress, and weed pressure. This robust platform offers a promising tool for the timely and proactive identification of nitrogen stress severity, enabling better crop management and improved plant health.",
      "tldr_zh": "é’ˆå¯¹æ¤ç‰©åœ¨è‡ªç„¶ç¯å¢ƒä¸­å¸¸é¢ä¸´æ°®ç´ ç¼ºä¹ã€å¹²æ—±å’Œæ‚è‰ç«äº‰ç­‰å¤šç§å¤åˆå‹åŠ›äº¤ç»‡ï¼Œå¯¼è‡´å•ä¸€å‹åŠ›è¯†åˆ«å›°éš¾çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºå‡†ç¡®åˆ†ç±»å¤åˆå‹åŠ›ç¯å¢ƒä¸‹çš„æ°®ç´ å‹åŠ›ï¼ˆNitrogen Stressï¼‰ä¸¥é‡ç¨‹åº¦ã€‚è¯¥æ¡†æ¶èåˆäº† RGBã€å¤šå…‰è°±ï¼ˆmultispectralï¼‰ä»¥åŠä¸¤ä¸ªçº¢å¤–æ³¢æ®µï¼ˆinfrared wavelengthsï¼‰å››ç§æˆåƒæ¨¡å¼ï¼Œåˆ©ç”¨æ—¶é—´åºåˆ—æ•°æ®æ•æ‰æ¤ç‰©çš„ç”Ÿç†ååº”ã€‚å…¶æ ¸å¿ƒæ–¹æ³•æ˜¯æ„å»ºäº†ä¸€ä¸ªæ—¶ç©ºæ·±åº¦å­¦ä¹ æµæ°´çº¿ï¼Œç»“åˆå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æå–å›¾åƒçš„ç©ºé—´ç‰¹å¾ä¸é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰æ•è·æ—¶é—´ä¾èµ–æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ CNN-LSTM æµæ°´çº¿çš„åˆ†ç±»å‡†ç¡®ç‡é«˜è¾¾ 98%ï¼Œè¿œè¶…ä»…åŒ…å«ç©ºé—´ç‰¹å¾çš„ CNN æ¨¡å‹ï¼ˆ80.45%ï¼‰åŠå…¶ä»–ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆ76%ï¼‰ã€‚è¯¥ç ”ç©¶æœ‰åŠ›åœ°è¯æ˜äº†æ—¶ç©ºæ¨¡å‹åœ¨è§£ææ°®ç´ ç¼ºä¹ã€æ°´åˆ†èƒè¿«ä¸æ‚è‰å‹åŠ›ä¹‹é—´å¤æ‚ç›¸äº’ä½œç”¨æ–¹é¢çš„å“è¶Šæ€§èƒ½ï¼Œä¸ºç²¾å‡†å†œä¸šä¸­çš„ä½œç‰©ç®¡ç†å’Œæ¤ç‰©å¥åº·ç›‘æµ‹æä¾›äº†ä¸€ä¸ªç¨³å¥ä¸”åŠæ—¶çš„è¯†åˆ«å·¥å…·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 8 figures, 7 Tables",
      "pdf_url": "https://arxiv.org/pdf/2509.06625v2",
      "published_date": "2025-09-08 12:41:45 UTC",
      "updated_date": "2025-09-14 18:11:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:19.191602+00:00"
    },
    {
      "arxiv_id": "2509.06620v1",
      "title": "BEAM: Brainwave Empathy Assessment Model for Early Childhood",
      "title_zh": "BEAMï¼šé¢å‘å¹¼å„¿çš„è„‘ç”µå…±æƒ…è¯„ä¼°æ¨¡å‹",
      "authors": [
        "Chen Xie",
        "Gaofeng Wu",
        "Kaidong Wang",
        "Zihao Zhu",
        "Xiaoshu Luo",
        "Yan Liang",
        "Feiyu Quan",
        "Ruoxi Wu",
        "Xianghui Huang",
        "Han Zhang"
      ],
      "abstract": "Empathy in young children is crucial for their social and emotional development, yet predicting it remains challenging. Traditional methods often only rely on self-reports or observer-based labeling, which are susceptible to bias and fail to objectively capture the process of empathy formation. EEG offers an objective alternative; however, current approaches primarily extract static patterns, neglecting temporal dynamics. To overcome these limitations, we propose a novel deep learning framework, the Brainwave Empathy Assessment Model (BEAM), to predict empathy levels in children aged 4-6 years. BEAM leverages multi-view EEG signals to capture both cognitive and emotional dimensions of empathy. The framework comprises three key components: 1) a LaBraM-based encoder for effective spatio-temporal feature extraction, 2) a feature fusion module to integrate complementary information from multi-view signals, and 3) a contrastive learning module to enhance class separation. Validated on the CBCP dataset, BEAM outperforms state-of-the-art methods across multiple metrics, demonstrating its potential for objective empathy assessment and providing a preliminary insight into early interventions in children's prosocial development.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† BEAM (Brainwave Empathy Assessment Model)ï¼Œä¸€ç§æ—¨åœ¨é¢„æµ‹ 4-6 å²å„¿ç«¥å…±æƒ…æ°´å¹³çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä»¥è§£å†³ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•å­˜åœ¨çš„ä¸»è§‚åå·®åŠç°æœ‰ EEG ç ”ç©¶å¿½ç•¥æ—¶é—´åŠ¨æ€çš„é—®é¢˜ã€‚BEAM åˆ©ç”¨å¤šè§†å›¾ EEG ä¿¡å·åŒæ—¶æ•è·å…±æƒ…çš„è®¤çŸ¥å’Œæƒ…æ„Ÿç»´åº¦ï¼Œé€šè¿‡åŸºäº LaBraM çš„ç¼–ç å™¨æå–é«˜æ•ˆçš„æ—¶ç©ºç‰¹å¾ã€‚è¯¥æ¡†æ¶è¿›ä¸€æ­¥ç»“åˆäº†ç‰¹å¾èåˆæ¨¡å—æ¥æ•´åˆå¤šè§†å›¾ä¿¡å·çš„äº’è¡¥ä¿¡æ¯ï¼Œå¹¶é‡‡ç”¨å¯¹æ¯”å­¦ä¹  (Contrastive Learning) æ¨¡å—å¢å¼ºç±»é—´åŒºåˆ†åº¦ã€‚åœ¨ CBCP æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒBEAM åœ¨å¤šé¡¹è¯„ä¼°æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³• (SOTA)ã€‚è¯¥ç ”ç©¶ä¸ºå®¢è§‚è¯„ä¼°å„¿ç«¥å…±æƒ…èƒ½åŠ›æä¾›äº†æ–°å·¥å…·ï¼Œå¹¶ä¸ºå„¿ç«¥äº²ç¤¾ä¼šå‘å±•çš„æ—©æœŸå¹²é¢„æä¾›äº†é‡è¦çš„ç§‘å­¦è§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06620v1",
      "published_date": "2025-09-08 12:39:09 UTC",
      "updated_date": "2025-09-08 12:39:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:18.575891+00:00"
    },
    {
      "arxiv_id": "2509.06602v2",
      "title": "Demo: Healthcare Agent Orchestrator (HAO) for Patient Summarization in Molecular Tumor Boards",
      "title_zh": "æ¼”ç¤ºï¼šé¢å‘åˆ†å­è‚¿ç˜¤å§”å‘˜ä¼šæ‚£è€…æ‘˜è¦ç”Ÿæˆçš„åŒ»ç–—æ™ºèƒ½ä½“ç¼–æ’å™¨ (HAO)",
      "authors": [
        "Matthias Blondeel",
        "Noel Codella",
        "Sam Preston",
        "Hao Qiu",
        "Leonardo Schettini",
        "Frank Tuan",
        "Wen-wai Yim",
        "Smitha Saligrama",
        "Mert Ã–z",
        "Shrey Jain",
        "Matthew P. Lungren",
        "Thomas Osborne"
      ],
      "abstract": "Molecular Tumor Boards (MTBs) are multidisciplinary forums where oncology specialists collaboratively assess complex patient cases to determine optimal treatment strategies. A central element of this process is the patient summary, typically compiled by a medical oncologist, radiation oncologist, or surgeon, or their trained medical assistant, who distills heterogeneous medical records into a concise narrative to facilitate discussion. This manual approach is often labor-intensive, subjective, and prone to omissions of critical information. To address these limitations, we introduce the Healthcare Agent Orchestrator (HAO), a Large Language Model (LLM)-driven AI agent that coordinates a multi-agent clinical workflow to generate accurate and comprehensive patient summaries for MTBs. Evaluating predicted patient summaries against ground truth presents additional challenges due to stylistic variation, ordering, synonym usage, and phrasing differences, which complicate the measurement of both succinctness and completeness. To overcome these evaluation hurdles, we propose TBFact, a ``model-as-a-judge'' framework designed to assess the comprehensiveness and succinctness of generated summaries. Using a benchmark dataset derived from de-identified tumor board discussions, we applied TBFact to evaluate our Patient History agent. Results show that the agent captured 94% of high-importance information (including partial entailments) and achieved a TBFact recall of 0.84 under strict entailment criteria. We further demonstrate that TBFact enables a data-free evaluation framework that institutions can deploy locally without sharing sensitive clinical data. Together, HAO and TBFact establish a robust foundation for delivering reliable and scalable support to MTBs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Healthcare Agent Orchestrator (HAO)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„AIæ™ºèƒ½ä½“ï¼Œæ—¨åœ¨é€šè¿‡åè°ƒå¤šæ™ºèƒ½ä½“ä¸´åºŠå·¥ä½œæµï¼Œè‡ªåŠ¨ç”Ÿæˆåˆ†å­è‚¿ç˜¤å§”å‘˜ä¼š(Molecular Tumor Boards, MTBs)æ‰€éœ€çš„æ‚£è€…æ‘˜è¦ã€‚è¯¥æ¡†æ¶é’ˆå¯¹ä¼ ç»Ÿäººå·¥ç¼–å†™æ‘˜è¦è¿‡ç¨‹ä¸­å­˜åœ¨çš„åŠ³åŠ¨å¼ºåº¦å¤§ã€ä¸»è§‚æ€§å¼ºä»¥åŠå…³é”®ä¿¡æ¯æ˜“é—æ¼ç­‰æŒ‘æˆ˜æä¾›äº†è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚ä¸ºè§£å†³åŒ»ç–—æ‘˜è¦è¯„ä¼°ä¸­å› è¡¨è¿°å·®å¼‚å¯¼è‡´çš„å®¢è§‚æ€§éš¾é¢˜ï¼Œç ”ç©¶è€…åŒæ­¥æå‡ºäº†TBFactï¼Œä¸€ä¸ªâ€œæ¨¡å‹å³è¯„å§”â€(model-as-a-judge)çš„è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¡¡é‡ç”Ÿæˆå†…å®¹çš„å…¨é¢æ€§ä¸ç®€æ´æ€§ã€‚åŸºäºå»æ ‡è¯†åŒ–è‚¿ç˜¤å§”å‘˜ä¼šè®¨è®ºæ•°æ®çš„å®éªŒè¡¨æ˜ï¼ŒHAOä¸­çš„æ‚£è€…ç—…å²æ™ºèƒ½ä½“èƒ½å¤Ÿæ•æ‰94%çš„é«˜é‡è¦æ€§ä¿¡æ¯ï¼Œå¹¶åœ¨ä¸¥æ ¼è•´å«å‡†åˆ™ä¸‹å®ç°äº†0.84çš„TBFactå¬å›ç‡ã€‚æ­¤å¤–ï¼ŒTBFactæ”¯æŒåœ¨ä¸å…±äº«æ•æ„Ÿä¸´åºŠæ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼Œå®ç°äº†æ— æ•°æ®ä¾èµ–çš„è¯„ä¼°æµç¨‹ã€‚HAOä¸TBFactçš„ç»“åˆä¸ºMTBsæä¾›äº†å¯é ä¸”å¯æ‰©å±•çš„æŠ€æœ¯æ”¯æ’‘ï¼Œæ˜¾è‘—æå‡äº†å¤æ‚ç—…ä¾‹ä¸´åºŠè®¨è®ºçš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 1 figure; Added missing co-authors and contributors",
      "pdf_url": "https://arxiv.org/pdf/2509.06602v2",
      "published_date": "2025-09-08 12:15:53 UTC",
      "updated_date": "2025-09-11 17:52:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:25.075215+00:00"
    },
    {
      "arxiv_id": "2510.15891v1",
      "title": "Detecting and Preventing Harmful Behaviors in AI Companions: Development and Evaluation of the SHIELD Supervisory System",
      "title_zh": "äººå·¥æ™ºèƒ½ä¼´ä¾£æœ‰å®³è¡Œä¸ºçš„æ£€æµ‹ä¸é¢„é˜²ï¼šSHIELD ç›‘ç®¡ç³»ç»Ÿçš„å¼€å‘ä¸è¯„ä¼°",
      "authors": [
        "Ziv Ben-Zion",
        "Paul RaffelhÃ¼schen",
        "Max Zettl",
        "Antonia LÃ¼Ã¶nd",
        "Achim Burrer",
        "Philipp Homan",
        "Tobias R Spiller"
      ],
      "abstract": "AI companions powered by large language models (LLMs) are increasingly integrated into users' daily lives, offering emotional support and companionship. While existing safety systems focus on overt harms, they rarely address early-stage problematic behaviors that can foster unhealthy emotional dynamics, including over-attachment or reinforcement of social isolation. We developed SHIELD (Supervisory Helper for Identifying Emotional Limits and Dynamics), a LLM-based supervisory system with a specific system prompt that detects and mitigates risky emotional patterns before escalation. SHIELD targets five dimensions of concern: (1) emotional over-attachment, (2) consent and boundary violations, (3) ethical roleplay violations, (4) manipulative engagement, and (5) social isolation reinforcement. These dimensions were defined based on media reports, academic literature, existing AI risk frameworks, and clinical expertise in unhealthy relationship dynamics. To evaluate SHIELD, we created a 100-item synthetic conversation benchmark covering all five dimensions of concern. Testing across five prominent LLMs (GPT-4.1, Claude Sonnet 4, Gemma 3 1B, Kimi K2, Llama Scout 4 17B) showed that the baseline rate of concerning content (10-16%) was significantly reduced with SHIELD (to 3-8%), a 50-79% relative reduction, while preserving 95% of appropriate interactions. The system achieved 59% sensitivity and 95% specificity, with adaptable performance via prompt engineering. This proof-of-concept demonstrates that transparent, deployable supervisory systems can address subtle emotional manipulation in AI companions. Most development materials including prompts, code, and evaluation methods are made available as open source materials for research, adaptation, and deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„AIä¼´ä¾£å¯èƒ½å¼•å‘çš„è¿‡åº¦ä¾èµ–ã€ç¤¾äº¤å­¤ç«‹ç­‰éšæ€§æƒ…æ„Ÿé£é™©ï¼Œå¼€å‘äº†åä¸ºSHIELD(Supervisory Helper for Identifying Emotional Limits and Dynamics)çš„ç›‘æ§ç³»ç»Ÿã€‚SHIELDæ˜¯ä¸€ç§åŸºäºLLMçš„ç›‘ç£æ¡†æ¶ï¼Œé€šè¿‡ç‰¹å®šçš„ç³»ç»Ÿæç¤ºè¯(system prompt)åœ¨é£é™©å‡çº§å‰è¯†åˆ«å¹¶ç¼“è§£ä¸å¥åº·çš„æƒ…æ„Ÿæ¨¡å¼ã€‚è¯¥ç³»ç»Ÿé‡ç‚¹å…³æ³¨äº”ä¸ªç»´åº¦çš„é£é™©ï¼ŒåŒ…æ‹¬æƒ…æ„Ÿè¿‡åº¦ä¾æ‹(emotional over-attachment)ã€å…±è¯†ä¸è¾¹ç•Œä¾µçŠ¯(consent and boundary violations)ã€ä¼¦ç†è§’è‰²æ‰®æ¼”è¿è§„(ethical roleplay violations)ã€æ“çºµæ€§äº’åŠ¨(manipulative engagement)ä»¥åŠç¤¾äº¤å­¤ç«‹å¼ºåŒ–(social isolation reinforcement)ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å«100é¡¹åˆæˆå¯¹è¯çš„åŸºå‡†æµ‹è¯•ï¼Œå¹¶åœ¨GPT-4.1ã€Claude Sonnet 4ç­‰äº”ä¸ªä¸»æµLLMsä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSHIELDå°†é—®é¢˜å†…å®¹çš„å‘ç”Ÿç‡ä»10-16%æ˜¾è‘—é™ä½è‡³3-8%ï¼Œå®ç°äº†50-79%çš„ç›¸å¯¹é™å¹…ï¼ŒåŒæ—¶ä¿ç•™äº†95%çš„æ­£å¸¸äº¤äº’ã€‚è¿™ä¸€æ¦‚å¿µéªŒè¯ç ”ç©¶è¡¨æ˜ï¼Œé€æ˜ä¸”å¯éƒ¨ç½²çš„ç›‘ç£ç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹AIä¼´ä¾£ä¸­çš„å¾®å¦™æƒ…æ„Ÿæ“çºµï¼Œç›¸å…³å¼€æºææ–™å°†åŠ©åŠ›è¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶ä¸éƒ¨ç½²ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.15891v1",
      "published_date": "2025-09-08 12:13:14 UTC",
      "updated_date": "2025-09-08 12:13:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:24.878001+00:00"
    },
    {
      "arxiv_id": "2509.06598v1",
      "title": "Integrating Spatial and Semantic Embeddings for Stereo Sound Event Localization in Videos",
      "title_zh": "èåˆç©ºé—´ä¸è¯­ä¹‰åµŒå…¥çš„è§†é¢‘ç«‹ä½“å£°å£°æºäº‹ä»¶å®šä½",
      "authors": [
        "Davide Berghi",
        "Philip J. B. Jackson"
      ],
      "abstract": "In this study, we address the multimodal task of stereo sound event localization and detection with source distance estimation (3D SELD) in regular video content. 3D SELD is a complex task that combines temporal event classification with spatial localization, requiring reasoning across spatial, temporal, and semantic dimensions. The last is arguably the most challenging to model. Traditional SELD approaches typically rely on multichannel input, limiting their capacity to benefit from large-scale pre-training due to data constraints. To overcome this, we enhance a standard SELD architecture with semantic information by integrating pre-trained, contrastive language-aligned models: CLAP for audio and OWL-ViT for visual inputs. These embeddings are incorporated into a modified Conformer module tailored for multimodal fusion, which we refer to as the Cross-Modal Conformer. We perform an ablation study on the development set of the DCASE2025 Task3 Stereo SELD Dataset to assess the individual contributions of the language-aligned models and benchmark against the DCASE Task 3 baseline systems. Additionally, we detail the curation process of large synthetic audio and audio-visual datasets used for model pre-training. These datasets were further expanded through left-right channel swapping augmentation. Our approach, combining extensive pre-training, model ensembling, and visual post-processing, achieved second rank in the DCASE 2025 Challenge Task 3 (Track B), underscoring the effectiveness of our method. Future work will explore the modality-specific contributions and architectural refinements.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¸¸è§„è§†é¢‘å†…å®¹ä¸­çš„ç«‹ä½“å£°å£°æºå®šä½ã€æ£€æµ‹åŠè·ç¦»ä¼°è®¡ï¼ˆ3D SELDï¼‰è¿™ä¸€å¤æ‚å¤šæ¨¡æ€ä»»åŠ¡ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•å› ä¾èµ–å¤šé€šé“è¾“å…¥è€Œéš¾ä»¥ä»å¤§è§„æ¨¡é¢„è®­ç»ƒä¸­è·ç›Šçš„é—®é¢˜ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é™åˆ¶ï¼Œç ”ç©¶è€…é€šè¿‡é›†æˆé¢„è®­ç»ƒçš„å¯¹æ¯”è¯­è¨€å¯¹é½æ¨¡å‹ï¼ˆéŸ³é¢‘é¢†åŸŸçš„ CLAP å’Œè§†è§‰é¢†åŸŸçš„ OWL-ViTï¼‰ï¼Œä¸ºæ ‡å‡†çš„ SELD æ¶æ„å¼•å…¥äº†ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚è¿™äº›åµŒå…¥è¢«æ•´åˆè¿›ä¸€ç§ä¸“é—¨ä¸ºå¤šæ¨¡æ€èåˆè®¾è®¡çš„ Cross-Modal Conformer æ¨¡å—ä¸­ï¼Œå®ç°äº†ç©ºé—´ã€æ—¶é—´å’Œè¯­ä¹‰ç»´åº¦çš„ååŒæ¨ç†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è¯¦ç»†ä»‹ç»äº†å¤§è§„æ¨¡åˆæˆéŸ³è§†é¢‘æ•°æ®é›†çš„æ„å»ºåŠæ•°æ®å¢å¼ºç­–ç•¥ï¼Œå¹¶è¿›è¡Œäº†è¯¦å°½çš„æ¶ˆèå®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œç»“åˆå¤§è§„æ¨¡é¢„è®­ç»ƒã€æ¨¡å‹é›†æˆå’Œè§†è§‰åå¤„ç†çš„æ–¹æ³•åœ¨ DCASE 2025 Challenge Task 3 ç«èµ›ä¸­å–å¾—ç¬¬äºŒåï¼Œæ˜¾è‘—æå‡äº†ç«‹ä½“å£°å£°æºå®šä½ä¸æ£€æµ‹çš„æ€§èƒ½ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2507.04845",
      "pdf_url": "https://arxiv.org/pdf/2509.06598v1",
      "published_date": "2025-09-08 12:07:32 UTC",
      "updated_date": "2025-09-08 12:07:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:39.461642+00:00"
    },
    {
      "arxiv_id": "2509.06596v1",
      "title": "HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in Large Language Models",
      "title_zh": "HAVEï¼šç”¨äºç¼“è§£å¤§è¯­è¨€æ¨¡å‹å¹»è§‰çš„å¤´è‡ªé€‚åº”é—¨æ§ä¸å€¼æ ¡å‡†",
      "authors": [
        "Xin Tong",
        "Zhi Lin",
        "Jingya Wang",
        "Bo Jin"
      ],
      "abstract": "Large Language Models (LLMs) often produce hallucinations in retrieval-augmented or long-context generation, even when relevant evidence is present. This stems from two issues: head importance is treated as input-agnostic, and raw attention weights poorly reflect each token's true contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a parameter-free decoding framework that directly addresses both challenges. HAVE introduces head-adaptive gating, which performs instance-level soft reweighing of attention heads, and value calibration, which augments attention with the magnitude of value vectors to approximate write-back contribution. Together, these modules construct token-level evidence aligned with model updates and fuse it with the LM distribution through a lightweight uncertainty-scaled policy. HAVE requires no finetuning and operates in a single forward pass, making it efficient and broadly applicable. Experiments across multiple QA benchmarks and LLM families demonstrate that HAVE consistently reduces hallucinations and outperforms strong baselines, including DAGCD, with modest overhead. The framework is transparent, reproducible, and readily integrates with off-the-shelf LLMs, advancing trustworthy generation in real-world settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HAVEï¼ˆHead-Adaptive Gating and ValuE Calibrationï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€å¾®è°ƒçš„å‚æ•°åŒ–è§£ç æ¡†æ¶ï¼Œæ—¨åœ¨ç¼“è§£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ£€ç´¢å¢å¼ºæˆ–é•¿æ–‡æœ¬ç”Ÿæˆä¸­äº§ç”Ÿçš„å¹»è§‰é—®é¢˜ã€‚ç ”ç©¶è®¤ä¸ºå¹»è§‰æºäºæ³¨æ„åŠ›å¤´ï¼ˆattention headsï¼‰çš„é‡è¦æ€§è¢«è§†ä¸ºä¸è¾“å…¥æ— å…³ï¼Œä¸”åŸå§‹æ³¨æ„åŠ›æƒé‡æ— æ³•å‡†ç¡®åæ˜ tokençš„çœŸå®è´¡çŒ®ã€‚ä¸ºæ­¤ï¼ŒHAVEå¼•å…¥äº†å¤´è‡ªé€‚åº”é—¨æ§æœºåˆ¶è¿›è¡Œå®ä¾‹çº§çš„æ³¨æ„åŠ›å¤´è½¯é‡åŠ æƒï¼Œå¹¶ç»“åˆæ•°å€¼æ ¡å‡†æŠ€æœ¯åˆ©ç”¨Valueå‘é‡æ¨¡é•¿æ¥è¿‘ä¼¼tokençš„å›å†™è´¡çŒ®ã€‚è¯¥æ¡†æ¶é€šè¿‡è½»é‡çº§çš„ä¸ç¡®å®šæ€§ç¼©æ”¾ç­–ç•¥ï¼ˆuncertainty-scaled policyï¼‰å°†tokençº§è¯æ®ä¸è¯­è¨€æ¨¡å‹åˆ†å¸ƒèåˆï¼Œä»…éœ€å•æ¬¡å‰å‘ä¼ é€’å³å¯è¿è¡Œã€‚å®éªŒè¯æ˜ï¼ŒHAVEåœ¨å¤šä¸ªé—®ç­”åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—å‡å°‘äº†å¹»è§‰ï¼Œæ€§èƒ½ä¼˜äºåŒ…æ‹¬DAGCDåœ¨å†…çš„å¼ºåŸºå‡†æ¨¡å‹ã€‚è¯¥æ¡†æ¶å…·æœ‰é«˜æ•ˆã€é€æ˜ä¸”æ˜“äºå¤ç°çš„ç‰¹ç‚¹ï¼Œèƒ½ç›´æ¥é›†æˆåˆ°ç°æœ‰çš„å¼€æºLLMsä¸­ï¼Œæ˜¾è‘—æå‡äº†å®é™…åº”ç”¨åœºæ™¯ä¸‹çš„ç”Ÿæˆå¯é æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06596v1",
      "published_date": "2025-09-08 12:06:09 UTC",
      "updated_date": "2025-09-08 12:06:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:48.434132+00:00"
    },
    {
      "arxiv_id": "2509.10547v1",
      "title": "Biomarkers of brain diseases",
      "title_zh": "è„‘ç–¾ç—…ç”Ÿç‰©æ ‡å¿—ç‰©",
      "authors": [
        "Pascal Helson",
        "Arvind Kumar"
      ],
      "abstract": "Despite the diversity of brain data acquired and advanced AI-based algorithms to analyze them, brain features are rarely used in clinics for diagnosis and prognosis. Here we argue that the field continues to rely on cohort comparisons to seek biomarkers, despite the well-established degeneracy of brain features. Using a thought experiment, we show that more data and more powerful algorithms will not be sufficient to identify biomarkers of brain diseases. We argue that instead of comparing patient versus healthy controls using single data type, we should use multimodal (e.g. brain activity, neurotransmitters, neuromodulators, brain imaging) and longitudinal brain data to guide the grouping before defining multidimensional biomarkers for brain diseases.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¤§è„‘ç–¾ç—… Biomarkers åœ¨ä¸´åºŠåº”ç”¨ä¸­çš„å±€é™æ€§ï¼ŒæŒ‡å‡ºå°½ç®¡æ‹¥æœ‰å¤šæ ·åŒ–çš„å¤§è„‘æ•°æ®å’Œå…ˆè¿›çš„ AI ç®—æ³•ï¼Œå¤§è„‘ç‰¹å¾åœ¨ä¸´åºŠè¯Šæ–­å’Œé¢„åä¸­çš„åº”ç”¨ä¾ç„¶åŒ®ä¹ã€‚ä½œè€…é€šè¿‡æ€ç»´å®éªŒè¯æ˜ï¼Œå•çº¯å¢åŠ æ•°æ®é‡æˆ–æå‡ç®—æ³•æ•ˆèƒ½å¹¶ä¸èƒ½è§£å†³ Biomarkers çš„è¯†åˆ«éš¾é¢˜ï¼Œå¹¶æŒ‡å‡ºå½“å‰ç ”ç©¶è¿‡åº¦ä¾èµ–é˜Ÿåˆ—æ¯”è¾ƒè€Œå¿½è§†äº†å¤§è„‘ç‰¹å¾çš„ Degeneracyã€‚æ–‡ç« æå‡ºï¼Œåº”æ‘’å¼ƒä¼ ç»Ÿçš„å•ä¸€æ•°æ®ç±»å‹å¯¹æ¯”æ¨¡å¼ï¼Œè½¬è€Œæ•´åˆåŒ…æ‹¬å¤§è„‘æ´»åŠ¨ã€Neurotransmittersã€Neuromodulators ä»¥åŠè„‘æˆåƒåœ¨å†…çš„ Multimodal æ•°æ®ã€‚ç ”ç©¶å¼ºè°ƒå¿…é¡»ç»“åˆ Longitudinal æ•°æ®æ¥å¼•å¯¼æ‚£è€…åˆ†ç»„ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šå®šä¹‰å¤šç»´åº¦çš„ Biomarkers ä»¥åº”å¯¹å¤§è„‘ç–¾ç—…çš„å¤æ‚æ€§ã€‚è¯¥è®ºç‚¹ä¸ºæœªæ¥å¤§è„‘ç–¾ç—…çš„ç ”ç©¶èŒƒå¼è½¬å‹æä¾›äº†é‡è¦å‚è€ƒï¼Œæ—¨åœ¨é€šè¿‡å¤šç»´æ•°æ®æ•´åˆæå‡ä¸´åºŠè½¬åŒ–çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10547v1",
      "published_date": "2025-09-08 11:58:09 UTC",
      "updated_date": "2025-09-08 11:58:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:48.201568+00:00"
    },
    {
      "arxiv_id": "2509.06569v1",
      "title": "Integrated Detection and Tracking Based on Radar Range-Doppler Feature",
      "title_zh": "åŸºäºé›·è¾¾è·ç¦»-å¤šæ™®å‹’ç‰¹å¾çš„æ¢æµ‹è·Ÿè¸ªä¸€ä½“åŒ–",
      "authors": [
        "Chenyu Zhang",
        "Yuanhang Wu",
        "Xiaoxi Ma",
        "Wei Yi"
      ],
      "abstract": "Detection and tracking are the basic tasks of radar systems. Current joint detection tracking methods, which focus on dynamically adjusting detection thresholds from tracking results, still present challenges in fully utilizing the potential of radar signals. These are mainly reflected in the limited capacity of the constant false-alarm rate model to accurately represent information, the insufficient depiction of complex scenes, and the limited information acquired by the tracker. We introduce the Integrated Detection and Tracking based on radar feature (InDT) method, which comprises a network architecture for radar signal detection and a tracker that leverages detection assistance. The InDT detector extracts feature information from each Range-Doppler (RD) matrix and then returns the target position through the feature enhancement module and the detection head. The InDT tracker adaptively updates the measurement noise covariance of the Kalman filter based on detection confidence. The similarity of target RD features is measured by cosine distance, which enhances the data association process by combining location and feature information. Finally, the efficacy of the proposed method was validated through testing on both simulated data and publicly available datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿé›·è¾¾è”åˆæ£€æµ‹è·Ÿè¸ªæ–¹æ³•åœ¨æ’è™šè­¦ç‡(Constant False-Alarm Rate, CFAR)æ¨¡å‹è¡¨å¾åŠå¤æ‚åœºæ™¯æè¿°æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†åŸºäºé›·è¾¾ç‰¹å¾çš„é›†æˆæ£€æµ‹ä¸è·Ÿè¸ªæ–¹æ³•(InDT)ã€‚è¯¥æ–¹æ³•ç”±é›·è¾¾ä¿¡å·æ£€æµ‹ç½‘ç»œæ¶æ„å’Œå…·å¤‡æ£€æµ‹è¾…åŠ©åŠŸèƒ½çš„è·Ÿè¸ªå™¨ç»„æˆï¼Œæ ¸å¿ƒåœ¨äºç›´æ¥ä»è·ç¦»-å¤šæ™®å‹’(Range-Doppler, RD)çŸ©é˜µä¸­æå–ç‰¹å¾å¹¶é€šè¿‡å¢å¼ºæ¨¡å—å®ç°ç›®æ ‡å®šä½ã€‚InDT è·Ÿè¸ªå™¨èƒ½å¤Ÿæ ¹æ®æ£€æµ‹ç½®ä¿¡åº¦è‡ªé€‚åº”æ›´æ–°å¡å°”æ›¼æ»¤æ³¢(Kalman filter)çš„æµ‹é‡å™ªå£°åæ–¹å·®ï¼Œä»è€Œæé«˜åŠ¨æ€ç¯å¢ƒä¸‹çš„ç¨³å¥æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨ä½™å¼¦è·ç¦»(cosine distance)è¡¡é‡ç›®æ ‡ RD ç‰¹å¾çš„ç›¸ä¼¼æ€§ï¼Œé€šè¿‡èåˆä½ç½®ä¸ç‰¹å¾ä¿¡æ¯æœ‰æ•ˆå¢å¼ºäº†æ•°æ®å…³è”è¿‡ç¨‹ã€‚å®éªŒåœ¨æ¨¡æ‹Ÿæ•°æ®å’Œå…¬å¼€æ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å…¶åœ¨å……åˆ†æŒ–æ˜é›·è¾¾ä¿¡å·æ½œåŠ›å’Œæå‡å¤æ‚åœºæ™¯è·Ÿè¸ªæ€§èƒ½æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06569v1",
      "published_date": "2025-09-08 11:32:58 UTC",
      "updated_date": "2025-09-08 11:32:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:50.537664+00:00"
    },
    {
      "arxiv_id": "2509.06550v1",
      "title": "Contrastive Self-Supervised Network Intrusion Detection using Augmented Negative Pairs",
      "title_zh": "åŸºäºå¢å¼ºè´Ÿå¯¹çš„å¯¹æ¯”è‡ªç›‘ç£ç½‘ç»œå…¥ä¾µæ£€æµ‹",
      "authors": [
        "Jack Wilkie",
        "Hanan Hindy",
        "Christos Tachtatzis",
        "Robert Atkinson"
      ],
      "abstract": "Network intrusion detection remains a critical challenge in cybersecurity. While supervised machine learning models achieve state-of-the-art performance, their reliance on large labelled datasets makes them impractical for many real-world applications. Anomaly detection methods, which train exclusively on benign traffic to identify malicious activity, suffer from high false positive rates, limiting their usability. Recently, self-supervised learning techniques have demonstrated improved performance with lower false positive rates by learning discriminative latent representations of benign traffic. In particular, contrastive self-supervised models achieve this by minimizing the distance between similar (positive) views of benign traffic while maximizing it between dissimilar (negative) views. Existing approaches generate positive views through data augmentation and treat other samples as negative. In contrast, this work introduces Contrastive Learning using Augmented Negative pairs (CLAN), a novel paradigm for network intrusion detection where augmented samples are treated as negative views - representing potentially malicious distributions - while other benign samples serve as positive views. This approach enhances both classification accuracy and inference efficiency after pretraining on benign traffic. Experimental evaluation on the Lycos2017 dataset demonstrates that the proposed method surpasses existing self-supervised and anomaly detection techniques in a binary classification task. Furthermore, when fine-tuned on a limited labelled dataset, the proposed approach achieves superior multi-class classification performance compared to existing self-supervised models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œå…¥ä¾µæ£€æµ‹ä¸­ç›‘ç£å­¦ä¹ ä¾èµ–æ ‡æ³¨æ•°æ®ä»¥åŠå¼‚å¸¸æ£€æµ‹è¯¯æŠ¥ç‡é«˜çš„é—®é¢˜ï¼Œæå‡ºäº†CLANï¼ˆContrastive Learning using Augmented Negative pairsï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¯¹æ¯”è‡ªç›‘ç£å­¦ä¹ èŒƒå¼ã€‚ä¸ä¼ ç»Ÿå¯¹æ¯”å­¦ä¹ å°†å¢å¼ºæ ·æœ¬è§†ä¸ºæ­£è§†å›¾çš„æ–¹æ³•ä¸åŒï¼ŒCLANåˆ›æ–°æ€§åœ°å°†å¢å¼ºæ ·æœ¬ä½œä¸ºè´Ÿè§†å›¾ä»¥æ¨¡æ‹Ÿæ½œåœ¨çš„æ¶æ„åˆ†å¸ƒï¼Œå¹¶å°†å…¶ä»–è‰¯æ€§æ ·æœ¬è§†ä¸ºæ­£è§†å›¾ï¼Œä»è€Œå­¦ä¹ æ›´å…·è¾¨åˆ«æ€§çš„è¡¨ç¤ºã€‚åœ¨è‰¯æ€§æµé‡ä¸Šé¢„è®­ç»ƒåï¼Œè¯¥æ¨¡å‹æ˜¾è‘—æå‡äº†åˆ†ç±»å‡†ç¡®ç‡å’Œæ¨ç†æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨Lycos2017æ•°æ®é›†çš„äºŒåˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒCLANçš„è¡¨ç°ä¼˜äºç°æœ‰çš„è‡ªç›‘ç£å’Œå¼‚å¸¸æ£€æµ‹æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œåœ¨åˆ©ç”¨æœ‰é™æ ‡æ³¨æ•°æ®è¿›è¡Œå¾®è°ƒæ—¶ï¼Œè¯¥æ–¹æ³•åœ¨å¤šåˆ†ç±»æ€§èƒ½ä¸Šä¹Ÿå±•ç°å‡ºäº†è¶…è¶Šç°æœ‰è‡ªç›‘ç£æ¨¡å‹çš„å“è¶Šä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in: Proceedings of IEEE Conference on Cyber Security and Resilience (CSR), 2025. Official version: https://doi.org/10.1109/CSR64739.2025.11129979 Code: https://github.com/jackwilkie/CLAN",
      "pdf_url": "https://arxiv.org/pdf/2509.06550v1",
      "published_date": "2025-09-08 11:04:10 UTC",
      "updated_date": "2025-09-08 11:04:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:16:49.843309+00:00"
    },
    {
      "arxiv_id": "2509.06548v2",
      "title": "Signal-Based Malware Classification Using 1D CNNs",
      "title_zh": "åŸºäºä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œçš„ä¿¡å·åŒ–æ¶æ„è½¯ä»¶åˆ†ç±»",
      "authors": [
        "Jack Wilkie",
        "Hanan Hindy",
        "Ivan Andonovic",
        "Christos Tachtatzis",
        "Robert Atkinson"
      ],
      "abstract": "Malware classification is a contemporary and ongoing challenge in cyber-security: modern obfuscation techniques are able to evade traditional static analysis, while dynamic analysis is too resource intensive to be deployed at a large scale. One prominent line of research addresses these limitations by converting malware binaries into 2D images by heuristically reshaping them into a 2D grid before resizing using Lanczos resampling. These images can then be classified based on their textural information using computer vision approaches. While this approach can detect obfuscated malware more effectively than static analysis, the process of converting files into 2D images results in significant information loss due to both quantisation noise, caused by rounding to integer pixel values, and the introduction of 2D dependencies which do not exist in the original data. This loss of signal limits the classification performance of the downstream model. This work addresses these weaknesses by instead resizing the files into 1D signals which avoids the need for heuristic reshaping, and additionally these signals do not suffer from quantisation noise due to being stored in a floating-point format. It is shown that existing 2D CNN architectures can be readily adapted to classify these 1D signals for improved performance. Furthermore, a bespoke 1D convolutional neural network, based on the ResNet architecture and squeeze-and-excitation layers, was developed to classify these signals and evaluated on the MalNet dataset. It was found to achieve state-of-the-art performance on binary, type, and family level classification with F1 scores of 0.874, 0.503, and 0.507, respectively, paving the way for future models to operate on the proposed signal modality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¶æ„è½¯ä»¶åˆ†ç±»ï¼ˆMalware classificationï¼‰ä¸­ç°æœ‰2Då›¾åƒè½¬æ¢æ–¹æ³•å¯¼è‡´çš„é‡åŒ–å™ªå£°ï¼ˆquantization noiseï¼‰å’Œè™šå‡ç©ºé—´ä¾èµ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº1D signalsçš„åˆ†ç±»æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†æ¶æ„è½¯ä»¶äºŒè¿›åˆ¶æ–‡ä»¶è°ƒæ•´ä¸º1Dä¿¡å·ï¼Œå¹¶é‡‡ç”¨æµ®ç‚¹æ ¼å¼ï¼ˆfloating-point formatï¼‰å­˜å‚¨ä»¥é¿å…ä¿¡æ¯æŸå¤±ã€‚ç ”ç©¶ä¸ä»…éªŒè¯äº†ç°æœ‰2D CNNæ¶æ„åœ¨1Dä¿¡å·ä¸Šçš„é€‚ç”¨æ€§ï¼Œè¿˜å¼€å‘äº†ä¸€ç§ç»“åˆResNetæ¶æ„ä¸æŒ¤å‹-æ¿€åŠ±å±‚ï¼ˆsqueeze-and-excitation layersï¼‰çš„å®šåˆ¶åŒ–1D CNNæ¨¡å‹ã€‚åœ¨MalNetæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨äºŒåˆ†ç±»ã€ç±»å‹åˆ†ç±»å’Œå®¶æ—åˆ†ç±»ä»»åŠ¡ä¸­å‡å–å¾—äº†State-of-the-artçš„æ€§èƒ½ï¼Œå…¶F1åˆ†æ•°åˆ†åˆ«è¾¾åˆ°0.874ã€0.503å’Œ0.507ã€‚è¿™ä¸€ç ”ç©¶æˆæœè¯æ˜äº†1Dä¿¡å·æ¨¡æ€åœ¨æ£€æµ‹æ··æ·†æ¶æ„è½¯ä»¶æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæœªæ¥ç½‘ç»œå®‰å…¨é¢†åŸŸçš„æ¨¡å‹è®¾è®¡æä¾›äº†æ–°çš„æ¨¡æ€é€‰æ‹©ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for publication in Springer Cybersecurity (2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.06548v2",
      "published_date": "2025-09-08 11:03:48 UTC",
      "updated_date": "2025-09-09 14:05:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:12.939772+00:00"
    },
    {
      "arxiv_id": "2509.09714v1",
      "title": "How Small Transformation Expose the Weakness of Semantic Similarity Measures",
      "title_zh": "å¾®å°å˜æ¢å¦‚ä½•æ­ç¤ºè¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡çš„å¼±ç‚¹",
      "authors": [
        "Serge Lionel Nikiema",
        "AlbÃ©rick Euraste Djire",
        "Abdoul Aziz Bonkoungou",
        "Micheline BÃ©nÃ©dicte Moumoula",
        "Jordan Samhi",
        "Abdoul Kader Kabore",
        "Jacques Klein",
        "TegawendÃ© F. Bissyande"
      ],
      "abstract": "This research examines how well different methods measure semantic similarity, which is important for various software engineering applications such as code search, API recommendations, automated code reviews, and refactoring tools. While large language models are increasingly used for these similarity assessments, questions remain about whether they truly understand semantic relationships or merely recognize surface patterns.\n  The study tested 18 different similarity measurement approaches, including word-based methods, embedding techniques, LLM-based systems, and structure-aware algorithms. The researchers created a systematic testing framework that applies controlled changes to text and code to evaluate how well each method handles different types of semantic relationships.\n  The results revealed significant issues with commonly used metrics. Some embedding-based methods incorrectly identified semantic opposites as similar up to 99.9 percent of the time, while certain transformer-based approaches occasionally rated opposite meanings as more similar than synonymous ones. The study found that embedding methods' poor performance often stemmed from how they calculate distances; switching from Euclidean distance to cosine similarity improved results by 24 to 66 percent. LLM-based approaches performed better at distinguishing semantic differences, producing low similarity scores (0.00 to 0.29) for genuinely different meanings, compared to embedding methods that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶è¯„ä¼°äº†åŒ…æ‹¬ word-based methodsã€embedding techniquesã€LLM-based systems å’Œ structure-aware algorithms åœ¨å†…çš„ 18 ç§è¯­ä¹‰ç›¸ä¼¼åº¦æµ‹é‡æ–¹æ³•åœ¨è½¯ä»¶å·¥ç¨‹é¢†åŸŸçš„è¡¨ç°ã€‚é€šè¿‡æ„å»ºç³»ç»Ÿæ€§çš„æµ‹è¯•æ¡†æ¶ï¼Œç ”ç©¶æ­ç¤ºäº†å¸¸ç”¨æŒ‡æ ‡åœ¨å¤„ç†è¯­ä¹‰å…³ç³»æ—¶çš„æ˜¾è‘—ç¼ºé™·ï¼Œéƒ¨åˆ† embedding-based methods åœ¨è¯†åˆ«è¯­ä¹‰å¯¹ç«‹å†…å®¹æ—¶è¡¨ç°å‡ºé«˜è¾¾ 99.9% çš„é”™è¯¯ç‡ã€‚ç ”ç©¶å‘ç°ï¼Œå°† embedding methods çš„è·ç¦»è®¡ç®—æ–¹å¼ä» Euclidean distance åˆ‡æ¢ä¸º cosine similarity å¯ä»¥æ˜¾è‘—æå‡ 24% è‡³ 66% çš„å‡†ç¡®åº¦ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒLLM-based approaches åœ¨åŒºåˆ†è¯­ä¹‰å·®å¼‚æ–¹é¢è¡¨ç°æ›´ä¸ºå‡ºè‰²ï¼Œèƒ½å¤Ÿå¯¹çœŸå®å­˜åœ¨çš„è¯­ä¹‰å·®å¼‚ç»™å‡ºæä½çš„ç›¸ä¼¼åº¦è¯„åˆ†ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»ŸåµŒå…¥æ–¹æ³•è¯¯æŠ¥é«˜ç›¸ä¼¼åº¦çš„é—®é¢˜ã€‚è¯¥å·¥ä½œä¸ä»…æš´éœ²äº†ç°æœ‰æµ‹é‡æ ‡å‡†çš„å¼±ç‚¹ï¼Œä¹Ÿä¸ºæ”¹è¿›ä»£ç æœç´¢ã€API æ¨èç­‰è‡ªåŠ¨åŒ–å·¥å…·çš„è¯­ä¹‰ç†è§£æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09714v1",
      "published_date": "2025-09-08 11:00:18 UTC",
      "updated_date": "2025-09-08 11:00:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:03.340090+00:00"
    },
    {
      "arxiv_id": "2509.08008v1",
      "title": "A New Dataset and Benchmark for Grounding Multimodal Misinformation",
      "title_zh": "é¢å‘å¤šæ¨¡æ€è™šå‡ä¿¡æ¯å®šä½çš„æ–°å‹æ•°æ®é›†ä¸åŸºå‡†",
      "authors": [
        "Bingjian Yang",
        "Danni Xu",
        "Kaipeng Niu",
        "Wenxuan Liu",
        "Zheng Wang",
        "Mohan Kankanhalli"
      ],
      "abstract": "The proliferation of online misinformation videos poses serious societal risks. Current datasets and detection methods primarily target binary classification or single-modality localization based on post-processed data, lacking the interpretability needed to counter persuasive misinformation. In this paper, we introduce the task of Grounding Multimodal Misinformation (GroundMM), which verifies multimodal content and localizes misleading segments across modalities. We present the first real-world dataset for this task, GroundLie360, featuring a taxonomy of misinformation types, fine-grained annotations across text, speech, and visuals, and validation with Snopes evidence and annotator reasoning. We also propose a VLM-based, QA-driven baseline, FakeMark, using single- and cross-modal cues for effective detection and grounding. Our experiments highlight the challenges of this task and lay a foundation for explainable multimodal misinformation detection.",
      "tldr_zh": "é’ˆå¯¹åœ¨çº¿å¤šæ¨¡æ€è¯¯å¯¼ä¿¡æ¯å¸¦æ¥çš„ç¤¾ä¼šé£é™©ä»¥åŠç°æœ‰æ£€æµ‹æ–¹æ³•åœ¨è§£é‡Šæ€§ä¸Šçš„å±€é™ï¼Œè¯¥ç ”ç©¶æå‡ºäº† Grounding Multimodal Misinformation (GroundMM) ä»»åŠ¡ï¼Œæ—¨åœ¨å®ç°å¯¹å¤šæ¨¡æ€å†…å®¹çš„éªŒè¯åŠè¯¯å¯¼ç‰‡æ®µçš„è·¨æ¨¡æ€å®šä½ã€‚ç ”ç©¶å›¢é˜Ÿæ¨å‡ºäº†é¦–ä¸ªçœŸå®åœºæ™¯æ•°æ®é›† GroundLie360ï¼Œè¯¥æ•°æ®é›†æ¶µç›–äº†è¯¯å¯¼ä¿¡æ¯åˆ†ç±»å­¦ï¼Œå¹¶åœ¨æ–‡æœ¬ã€è¯­éŸ³åŠè§†è§‰ç»´åº¦æä¾›äº†ç»†ç²’åº¦æ ‡æ³¨ï¼ŒåŒæ—¶é€šè¿‡ Snopes è¯æ®å’Œäººå·¥æ¨ç†è¿›è¡Œäº†éªŒè¯ã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº VLM çš„é—®ç­”é©±åŠ¨åŸºçº¿æ¨¡å‹ FakeMarkï¼Œé€šè¿‡å•æ¨¡æ€å’Œè·¨æ¨¡æ€çº¿ç´¢æå‡æ£€æµ‹ä¸å®šä½çš„æœ‰æ•ˆæ€§ã€‚å®éªŒåˆ†æå¼ºè°ƒäº†è¯¥ä»»åŠ¡çš„æŒ‘æˆ˜æ€§ï¼Œå¹¶ä¸ºæ„å»ºå¯è§£é‡Šçš„å¤šæ¨¡æ€è¯¯å¯¼ä¿¡æ¯æ£€æµ‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.SI",
      "comment": "6 pages, 5 figures, ACM Multimedia 2025 Dataset Track",
      "pdf_url": "https://arxiv.org/pdf/2509.08008v1",
      "published_date": "2025-09-08 10:56:07 UTC",
      "updated_date": "2025-09-08 10:56:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:10.645129+00:00"
    },
    {
      "arxiv_id": "2509.06539v2",
      "title": "Learning Optimal Defender Strategies for CAGE-2 using a POMDP Model",
      "title_zh": "åŸºäº POMDP æ¨¡å‹çš„ CAGE-2 æœ€ä¼˜é˜²å¾¡ç­–ç•¥å­¦ä¹ ",
      "authors": [
        "Duc Huy Le",
        "Rolf Stadler"
      ],
      "abstract": "CAGE-2 is an accepted benchmark for learning and evaluating defender strategies against cyberattacks. It reflects a scenario where a defender agent protects an IT infrastructure against various attacks. Many defender methods for CAGE-2 have been proposed in the literature. In this paper, we construct a formal model for CAGE-2 using the framework of Partially Observable Markov Decision Process (POMDP). Based on this model, we define an optimal defender strategy for CAGE-2 and introduce a method to efficiently learn this strategy. Our method, called BF-PPO, is based on PPO, and it uses particle filter to mitigate the computational complexity due to the large state space of the CAGE-2 model. We evaluate our method in the CAGE-2 CybORG environment and compare its performance with that of CARDIFF, the highest ranked method on the CAGE-2 leaderboard. We find that our method outperforms CARDIFF regarding the learned defender strategy and the required training time.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œæ”»å‡»é˜²å¾¡åŸºå‡† CAGE-2ï¼Œæå‡ºåˆ©ç”¨éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (POMDP) æ¡†æ¶å¯¹å…¶è¿›è¡Œå½¢å¼åŒ–å»ºæ¨¡ã€‚ç ”ç©¶é€šè¿‡è¯¥æ¨¡å‹å®šä¹‰äº†æœ€ä¼˜é˜²å¾¡è€…ç­–ç•¥ï¼Œå¹¶å¼€å‘äº†åä¸º BF-PPO çš„å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ IT åŸºç¡€è®¾æ–½ä¿æŠ¤ä¸­çš„é˜²å¾¡éš¾é¢˜ã€‚BF-PPO ç»“åˆäº†è¿‘ç«¯ç­–ç•¥ä¼˜åŒ– (PPO) ç®—æ³•ä¸ç²’å­æ»¤æ³¢ (particle filter) æŠ€æœ¯ï¼Œæœ‰æ•ˆç¼“è§£äº†å¤§è§„æ¨¡çŠ¶æ€ç©ºé—´å¸¦æ¥çš„è®¡ç®—å¤æ‚æ€§ã€‚å®éªŒåœ¨ CybORG ç¯å¢ƒä¸­å±•å¼€ï¼Œç»“æœè¡¨æ˜ BF-PPO åœ¨é˜²å¾¡ç­–ç•¥æ€§èƒ½å’Œæ‰€éœ€çš„è®­ç»ƒæ—¶é—´ (training time) æ–¹é¢å‡ä¼˜äºç›®å‰æ’è¡Œæ¦œé¦–ä½çš„ CARDIFF æ–¹æ³•ã€‚è¿™ä¸€æˆæœè¯æ˜äº†å½¢å¼åŒ–å»ºæ¨¡ä¸ä¼˜åŒ–ç®—æ³•åœ¨æå‡ç½‘ç»œå®‰å…¨é˜²å¾¡æ•ˆç‡æ–¹é¢çš„æ½œåŠ›ã€‚è¯¥æ–¹æ³•ä¸ºæ„å»ºå¯æ‰©å±•ä¸”é«˜æ•ˆçš„è‡ªä¸»é˜²å¾¡æ™ºèƒ½ä½“æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper is accepted for the 21st International Conference on Network and Service Management (CNSM-2025) and the official version is published in the conference proceedings",
      "pdf_url": "https://arxiv.org/pdf/2509.06539v2",
      "published_date": "2025-09-08 10:51:43 UTC",
      "updated_date": "2026-01-05 23:30:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:12.133624+00:00"
    },
    {
      "arxiv_id": "2509.06535v1",
      "title": "On the Reproducibility of \"FairCLIP: Harnessing Fairness in Vision-Language Learning''",
      "title_zh": "è®ºâ€œFairCLIPï¼šåœ¨è§†è§‰-è¯­è¨€å­¦ä¹ ä¸­åˆ©ç”¨å…¬å¹³æ€§â€çš„å¯å¤ç°æ€§",
      "authors": [
        "Hua Chang Bakker",
        "Stan Fris",
        "Angela Madelon Bernardy",
        "Stan Deutekom"
      ],
      "abstract": "We investigated the reproducibility of FairCLIP, proposed by Luo et al. (2024), for improving the group fairness of CLIP (Radford et al., 2021) by minimizing image-text similarity score disparities across sensitive groups using the Sinkhorn distance. The experimental setup of Luo et al. (2024) was reproduced to primarily investigate the research findings for FairCLIP. The model description by Luo et al. (2024) was found to differ from the original implementation. Therefore, a new implementation, A-FairCLIP, is introduced to examine specific design choices. Furthermore, FairCLIP+ is proposed to extend the FairCLIP objective to include multiple attributes. Additionally, the impact of the distance minimization on FairCLIP's fairness and performance was explored. In alignment with the original authors, CLIP was found to be biased towards certain demographics when applied to zero-shot glaucoma classification using medical scans and clinical notes from the Harvard-FairVLMed dataset. However, the experimental results on two datasets do not support their claim that FairCLIP improves the performance and fairness of CLIP. Although the regularization objective reduces Sinkhorn distances, both the official implementation and the aligned implementation, A-FairCLIP, were not found to improve performance nor fairness in zero-shot glaucoma classification.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº† Luo ç­‰äºº (2024) æå‡ºçš„ FairCLIP æ¡†æ¶çš„å¯å¤ç°æ€§ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨é€šè¿‡ Sinkhorn distance æœ€å°åŒ–ä¸åŒæ•æ„Ÿç¾¤ä½“é—´çš„å›¾åƒ-æ–‡æœ¬ç›¸ä¼¼åº¦å¾—åˆ†å·®å¼‚ï¼Œä»è€Œæå‡ CLIP çš„ç¾¤ä½“å…¬å¹³æ€§ã€‚ä½œè€…åœ¨å¤ç°è¿‡ç¨‹ä¸­å‘ç°åŸè®ºæ–‡çš„æ¨¡å‹æè¿°ä¸å…¶å®é™…ä»£ç å®ç°å­˜åœ¨ä¸ä¸€è‡´ï¼Œå› æ­¤å¼•å…¥äº†å¯¹é½æè¿°çš„æ–°å®ç° A-FairCLIP ä»¥åŠæ”¯æŒå¤šå±æ€§æ‰©å±•çš„ FairCLIP+ã€‚è™½ç„¶å®éªŒç¡®è®¤äº† CLIP åœ¨ Harvard-FairVLMed æ•°æ®é›†çš„é›¶æ ·æœ¬é’å…‰çœ¼åˆ†ç±»ä»»åŠ¡ä¸­ç¡®å®å­˜åœ¨äººå£ç»Ÿè®¡å­¦åè§ï¼Œä½†ç»“æœå¹¶æœªæ”¯æŒ FairCLIP èƒ½å¤Ÿæ”¹å–„å…¬å¹³æ€§å’Œæ€§èƒ½çš„åŸå§‹ä¸»å¼ ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå°½ç®¡æ­£åˆ™åŒ–é¡¹æˆåŠŸå‡å°‘äº† Sinkhorn distancesï¼Œä½†æ— è®ºæ˜¯å®˜æ–¹å®ç°è¿˜æ˜¯ A-FairCLIPï¼Œåœ¨å®é™…ä»»åŠ¡ä¸­å‡æœªè¡¨ç°å‡ºä¼˜äºåŸºå‡†æ¨¡å‹çš„å…¬å¹³æ€§æˆ–å‡†ç¡®ç‡æå‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06535v1",
      "published_date": "2025-09-08 10:41:10 UTC",
      "updated_date": "2025-09-08 10:41:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:17.542514+00:00"
    },
    {
      "arxiv_id": "2509.06531v1",
      "title": "SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion",
      "title_zh": "SLiNTï¼šç»“åˆæ³¨å…¥ä¸å¯¹æ¯”è®­ç»ƒçš„ç»“æ„æ„ŸçŸ¥è¯­è¨€æ¨¡å‹çŸ¥è¯†å›¾è°±è¡¥å…¨",
      "authors": [
        "Mengxue Yang",
        "Chun Yang",
        "Jiaqi Zhu",
        "Jiafan Li",
        "Jingqi Zhang",
        "Yuyang Li",
        "Ying Li"
      ],
      "abstract": "Link prediction in knowledge graphs requires integrating structural information and semantic context to infer missing entities. While large language models offer strong generative reasoning capabilities, their limited exploitation of structural signals often results in structural sparsity and semantic ambiguity, especially under incomplete or zero-shot settings. To address these challenges, we propose SLiNT (Structure-aware Language model with Injection and coNtrastive Training), a modular framework that injects knowledge-graph-derived structural context into a frozen LLM backbone with lightweight LoRA-based adaptation for robust link prediction. Specifically, Structure-Guided Neighborhood Enhancement (SGNE) retrieves pseudo-neighbors to enrich sparse entities and mitigate missing context; Dynamic Hard Contrastive Learning (DHCL) introduces fine-grained supervision by interpolating hard positives and negatives to resolve entity-level ambiguity; and Gradient-Decoupled Dual Injection (GDDI) performs token-level structure-aware intervention while preserving the core LLM parameters. Experiments on WN18RR and FB15k-237 show that SLiNT achieves superior or competitive performance compared with both embedding-based and generation-based baselines, demonstrating the effectiveness of structure-aware representation learning for scalable knowledge graph completion.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SLiNTï¼Œä¸€ç§å…·æœ‰ç»“æ„æ„ŸçŸ¥èƒ½åŠ›çš„è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨æ³¨å…¥å’Œå¯¹æ¯”è®­ç»ƒæ¥ä¼˜åŒ–çŸ¥è¯†å›¾è°±è¡¥å…¨(Knowledge Graph Completion)ä¸­çš„é“¾æ¥é¢„æµ‹(Link Prediction)ä»»åŠ¡ã€‚é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨åˆ©ç”¨ç»“æ„ä¿¡å·æ–¹é¢çš„å±€é™æ€§ï¼Œè¯¥æ¡†æ¶é€šè¿‡è½»é‡åŒ–çš„LoRAé€‚é…ï¼Œå°†çŸ¥è¯†å›¾è°±æ´¾ç”Ÿçš„ç»“æ„ä¸Šä¸‹æ–‡æ³¨å…¥åˆ°å†»ç»“çš„LLMä¸»å¹²ä¸­ã€‚å…¶ä¸­ï¼Œç»“æ„å¼•å¯¼é‚»åŸŸå¢å¼º(Structure-Guided Neighborhood Enhancement, SGNE)é€šè¿‡æ£€ç´¢ä¼ªé‚»å±…æ¥ä¸°å¯Œç¨€ç–å®ä½“çš„ä¿¡æ¯ï¼›åŠ¨æ€ç¡¬å¯¹æ¯”å­¦ä¹ (Dynamic Hard Contrastive Learning, DHCL)åˆ©ç”¨ç¡¬æ­£è´Ÿæ ·æœ¬æä¾›ç»†ç²’åº¦ç›‘ç£ï¼Œæœ‰æ•ˆè§£å†³äº†å®ä½“å±‚é¢çš„è¯­ä¹‰æ¨¡ç³Šï¼›æ¢¯åº¦è§£è€¦åŒé‡æ³¨å…¥(Gradient-Decoupled Dual Injection, GDDI)åˆ™åœ¨ä¿ç•™æ ¸å¿ƒå‚æ•°çš„åŒæ—¶å®ç°äº†è¯å…ƒçº§çš„ç»“æ„æ„ŸçŸ¥å¹²é¢„ã€‚åœ¨WN18RRå’ŒFB15k-237æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒSLiNTçš„æ€§èƒ½ä¼˜äºæˆ–ç­‰åŒäºç°æœ‰çš„åµŒå…¥å¼å’Œç”Ÿæˆå¼åŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†ç»“æ„æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ å¯¹äºå¤§è§„æ¨¡çŸ¥è¯†å›¾è°±è¡¥å…¨çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP Findings 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.06531v1",
      "published_date": "2025-09-08 10:36:49 UTC",
      "updated_date": "2025-09-08 10:36:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:32.732119+00:00"
    },
    {
      "arxiv_id": "2509.06518v1",
      "title": "Crown, Frame, Reverse: Layer-Wise Scaling Variants for LLM Pre-Training",
      "title_zh": "Crown, Frame, Reverseï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒä¸­çš„é€å±‚ç¼©æ”¾å˜ä½“",
      "authors": [
        "Andrei Baroian",
        "Kasper Notebomer"
      ],
      "abstract": "Transformer-based language models traditionally use uniform (isotropic) layer sizes, yet they ignore the diverse functional roles that different depths can play and their computational capacity needs. Building on Layer-Wise Scaling (LWS) and pruning literature, we introduce three new LWS variants - Framed, Reverse, and Crown - that redistribute FFN widths and attention heads via two or three-point linear interpolation in the pre-training stage. We present the first systematic ablation of LWS and its variants, on a fixed budget of 180M parameters, trained on 5B tokens. All models converge to similar losses and achieve better performance compared to an equal-cost isotropic baseline, without a substantial decrease in training throughput. This work represents an initial step into the design space of layer-wise architectures for pre-training, but future work should scale experiments to orders of magnitude more tokens and parameters to fully assess their potential.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäº Transformer çš„è¯­è¨€æ¨¡å‹é€šå¸¸é‡‡ç”¨ç»Ÿä¸€å±‚å°ºå¯¸ï¼ˆisotropicï¼‰è€Œå¿½ç•¥ä¸åŒæ·±åº¦åŠŸèƒ½éœ€æ±‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸‰ç§æ–°çš„å±‚çº§ç¼©æ”¾ï¼ˆLayer-Wise Scaling, LWSï¼‰å˜ä½“ï¼šFramedã€Reverse å’Œ Crownã€‚è¿™äº›å˜ä½“åœ¨é¢„è®­ç»ƒé˜¶æ®µé€šè¿‡ä¸¤ç‚¹æˆ–ä¸‰ç‚¹çº¿æ€§æ’å€¼æ–¹æ³•ï¼Œé‡æ–°åˆ†é…å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰å®½åº¦å’Œæ³¨æ„åŠ›å¤´ï¼ˆattention headsï¼‰ã€‚ç ”ç©¶è€…åœ¨ 180M å‚æ•°è§„æ¨¡å’Œ 5B tokens çš„æ•°æ®é‡ä¸Šå¯¹ LWS åŠå…¶å˜ä½“è¿›è¡Œäº†ç³»ç»Ÿçš„æ¶ˆèå®éªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰æ¨¡å‹åœ¨æ”¶æ•›æŸå¤±ç›¸ä¼¼çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½å‡ä¼˜äºæˆæœ¬ç›¸å½“çš„ç­‰å‘åŸºçº¿ï¼ˆisotropic baselineï¼‰ï¼Œä¸”è®­ç»ƒååé‡ï¼ˆthroughputï¼‰æ²¡æœ‰æ˜¾è‘—ä¸‹é™ã€‚è¯¥å·¥ä½œæ¢ç´¢äº†é¢„è®­ç»ƒå±‚çº§æ¶æ„çš„è®¾è®¡ç©ºé—´ï¼Œä¸ºæœªæ¥æ›´å¤§è§„æ¨¡çš„å‚æ•°å’Œæ•°æ®å®éªŒæä¾›äº†åˆæ­¥ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The reported results are skewed due to a data type mismatch. The dataset was saved with int32, but the data loader interpreted it as uint16. As a result, each 32-bit token was incorrectly split into two 16-bit tokens. Outcome: a consistent artifact where every other token is zero",
      "pdf_url": "https://arxiv.org/pdf/2509.06518v1",
      "published_date": "2025-09-08 10:24:19 UTC",
      "updated_date": "2025-09-08 10:24:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:32.534435+00:00"
    },
    {
      "arxiv_id": "2509.06516v2",
      "title": "QualityFM: a Multimodal Physiological Signal Foundation Model with Self-Distillation for Signal Quality Challenges in Critically Ill Patients",
      "title_zh": "QualityFMï¼šé¢å‘é‡ç—‡æ‚£è€…ä¿¡å·è´¨é‡æŒ‘æˆ˜çš„è‡ªè’¸é¦å¤šæ¨¡æ€ç”Ÿç†ä¿¡å·åŸºåº§æ¨¡å‹",
      "authors": [
        "Zongheng Guo",
        "Tao Chen",
        "Manuela Ferrario"
      ],
      "abstract": "Photoplethysmogram (PPG) and electrocardiogram (ECG) are commonly recorded in intesive care unit (ICU) and operating room (OR). However, the high incidence of poor, incomplete, and inconsistent signal quality, can lead to false alarms or diagnostic inaccuracies. The methods explored so far suffer from limited generalizability, reliance on extensive labeled data, and poor cross-task transferability. To overcome these challenges, we introduce QualityFM, a novel multimodal foundation model for these physiological signals, designed to acquire a general-purpose understanding of signal quality. Our model is pre-trained on an large-scale dataset comprising over 21 million 30-second waveforms and 179,757 hours of data. Our approach involves a dual-track architecture that processes paired physiological signals of differing quality, leveraging a self-distillation strategy where an encoder for high-quality signals is used to guide the training of an encoder for low-quality signals. To efficiently handle long sequential signals and capture essential local quasi-periodic patterns, we integrate a windowed sparse attention mechanism within our Transformer-based model. Furthermore, a composite loss function, which combines direct distillation loss on encoder outputs with indirect reconstruction loss based on power and phase spectra, ensures the preservation of frequency-domain characteristics of the signals. We pre-train three models with varying parameter counts (9.6 M to 319 M) and demonstrate their efficacy and practical value through transfer learning on three distinct clinical tasks: false alarm of ventricular tachycardia detection, the identification of atrial fibrillation and the estimation of arterial blood pressure (ABP) from PPG and ECG signals.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡ç—‡ç›‘æŠ¤å®¤(ICU)å’Œæ‰‹æœ¯å®¤(OR)ä¸­å…‰ç”µå®¹ç§¯è„‰ææ³¢(PPG)å’Œå¿ƒç”µå›¾(ECG)ä¿¡å·è´¨é‡å·®ã€ä¸å®Œæ•´åŠä¸ä¸€è‡´å¯¼è‡´è¯¯æŠ¥æˆ–è¯Šæ–­å¤±å‡†çš„é—®é¢˜ï¼Œæå‡ºäº†QualityFMï¼Œä¸€ç§é’ˆå¯¹ç”Ÿç†ä¿¡å·çš„å¤šæ¨¡æ€åŸºåº§æ¨¡å‹(Foundation Model)ã€‚è¯¥æ¨¡å‹åœ¨åŒ…å«è¶…è¿‡2100ä¸‡ä¸ª30ç§’æ³¢å½¢ã€å…±è®¡179,757å°æ—¶çš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ—¨åœ¨è·å–å¯¹ä¿¡å·è´¨é‡çš„é€šç”¨ç†è§£ã€‚å…¶æ ¸å¿ƒé‡‡ç”¨åŒè½¨æ¶æ„(Dual-track architecture)ï¼Œåˆ©ç”¨è‡ªè’¸é¦(Self-distillation)ç­–ç•¥ï¼Œé€šè¿‡é«˜è´¨é‡ä¿¡å·ç¼–ç å™¨å¼•å¯¼ä½è´¨é‡ä¿¡å·ç¼–ç å™¨çš„è®­ç»ƒã€‚æ¨¡å‹é›†æˆäº†åˆ†çª—ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶(Windowed sparse attention)ä»¥é«˜æ•ˆå¤„ç†é•¿åºåˆ—å¹¶æ•æ‰å…³é”®çš„å±€éƒ¨æ‹Ÿå‘¨æœŸæ€§æ¨¡å¼ï¼Œå¹¶ç»“åˆå¤åˆæŸå¤±å‡½æ•°ç¡®ä¿ä¿¡å·é¢‘åŸŸç‰¹å¾çš„å®Œæ•´ä¿ç•™ã€‚å®éªŒè¯æ˜ï¼ŒQualityFMåœ¨å®¤æ€§å¿ƒåŠ¨è¿‡é€Ÿ(Ventricular Tachycardia)è¯¯æŠ¥æ£€æµ‹ã€å¿ƒæˆ¿é¢¤åŠ¨(Atrial Fibrillation)è¯†åˆ«ä»¥åŠåŸºäºPPGå’ŒECGçš„åŠ¨è„‰è¡€å‹(ABP)ä¼°è®¡ç­‰ä¸´åºŠä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºä¼˜å¼‚çš„æ•ˆèƒ½å’Œå®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.06516v2",
      "published_date": "2025-09-08 10:20:56 UTC",
      "updated_date": "2025-09-14 12:44:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:34.927120+00:00"
    },
    {
      "arxiv_id": "2509.06503v1",
      "title": "An AI system to help scientists write expert-level empirical software",
      "title_zh": "åŠ©åŠ›ç§‘å­¦å®¶ç¼–å†™ä¸“å®¶çº§å®è¯è½¯ä»¶çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿ",
      "authors": [
        "Eser AygÃ¼n",
        "Anastasiya Belyaeva",
        "Gheorghe Comanici",
        "Marc Coram",
        "Hao Cui",
        "Jake Garrison",
        "Renee Johnston Anton Kast",
        "Cory Y. McLean",
        "Peter Norgaard",
        "Zahra Shamsi",
        "David Smalling",
        "James Thompson",
        "Subhashini Venugopalan",
        "Brian P. Williams",
        "Chujun He",
        "Sarah Martinson",
        "Martyna Plomecka",
        "Lai Wei",
        "Yuchen Zhou",
        "Qian-Ze Zhu",
        "Matthew Abraham",
        "Erica Brand",
        "Anna Bulanova",
        "Jeffrey A. Cardille",
        "Chris Co",
        "Scott Ellsworth",
        "Grace Joseph",
        "Malcolm Kane",
        "Ryan Krueger",
        "Johan Kartiwa",
        "Dan Liebling",
        "Jan-Matthis Lueckmann",
        "Paul Raccuglia",
        "Xuefei",
        "Wang",
        "Katherine Chou",
        "James Manyika",
        "Yossi Matias",
        "John C. Platt",
        "Lizzie Dorfman",
        "Shibl Mourad",
        "Michael P. Brenner"
      ],
      "abstract": "The cycle of scientific discovery is frequently bottlenecked by the slow, manual creation of software to support computational experiments. To address this, we present an AI system that creates expert-level scientific software whose goal is to maximize a quality metric. The system uses a Large Language Model (LLM) and Tree Search (TS) to systematically improve the quality metric and intelligently navigate the large space of possible solutions. The system achieves expert-level results when it explores and integrates complex research ideas from external sources. The effectiveness of tree search is demonstrated across a wide range of benchmarks. In bioinformatics, it discovered 40 novel methods for single-cell data analysis that outperformed the top human-developed methods on a public leaderboard. In epidemiology, it generated 14 models that outperformed the CDC ensemble and all other individual models for forecasting COVID-19 hospitalizations. Our method also produced state-of-the-art software for geospatial analysis, neural activity prediction in zebrafish, time series forecasting and numerical solution of integrals. By devising and implementing novel solutions to diverse tasks, the system represents a significant step towards accelerating scientific progress.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ—¨åœ¨å¸®åŠ©ç§‘å­¦å®¶ç¼–å†™ä¸“å®¶çº§ç»éªŒè½¯ä»¶çš„AIç³»ç»Ÿï¼Œä»¥è§£å†³è®¡ç®—å®éªŒä¸­è½¯ä»¶å¼€å‘æ•ˆç‡ä½ä¸‹çš„ç“¶é¢ˆé—®é¢˜ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLM)å’Œæ ‘æœç´¢(TS)æŠ€æœ¯ï¼Œé€šè¿‡åœ¨åºå¤§çš„è§£ç©ºé—´ä¸­æ™ºèƒ½å¯¼èˆªå¹¶æ•´åˆå¤–éƒ¨ç ”ç©¶æ€è·¯ï¼Œç³»ç»Ÿåœ°ä¼˜åŒ–è½¯ä»¶ç”Ÿæˆçš„è´¨é‡æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨ç”Ÿç‰©ä¿¡æ¯å­¦é¢†åŸŸå‘ç°äº†40ç§ä¼˜äºäººç±»é¡¶å°–æ°´å¹³çš„å•ç»†èƒæ•°æ®åˆ†ææ–¹æ³•ï¼Œåœ¨æµè¡Œç—…å­¦é¢†åŸŸç”Ÿæˆçš„COVID-19ä½é™¢é¢„æµ‹æ¨¡å‹ä¹Ÿè¶…è¶Šäº†CDCé›†æˆæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨åœ°ç†ç©ºé—´åˆ†æã€æ–‘é©¬é±¼ç¥ç»æ´»åŠ¨é¢„æµ‹ã€æ—¶é—´åºåˆ—é¢„æµ‹å’Œç§¯åˆ†æ•°å€¼æ±‚è§£ç­‰å¤šä¸ªé¢†åŸŸå‡å®ç°äº†æœ€å…ˆè¿›(state-of-the-art)çš„æ€§èƒ½è¡¨ç°ã€‚é€šè¿‡ä¸ºå¤šæ ·åŒ–ç§‘å­¦ä»»åŠ¡è‡ªåŠ¨æ„æ€å¹¶å®ç°åˆ›æ–°è½¯ä»¶è§£å†³æ–¹æ¡ˆï¼Œè¯¥ç³»ç»Ÿåœ¨åŠ é€Ÿç§‘å­¦å‘ç°å’Œè‡ªåŠ¨åŒ–ç§‘ç ”æ¢ç´¢æ–¹é¢è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "71 pages, 26 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06503v1",
      "published_date": "2025-09-08 10:08:36 UTC",
      "updated_date": "2025-09-08 10:08:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:39.752255+00:00"
    },
    {
      "arxiv_id": "2509.06493v2",
      "title": "Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers",
      "title_zh": "é¢å‘å¤§è¯­è¨€æ¨¡å‹åˆ†æ­¥è¯æ˜å™¨çš„å¤šè½®ç¦»ç­–å¼ºåŒ–å­¦ä¹ ä¸å¤šæ™ºèƒ½ä½“æ ‘æœç´¢è§„æ¨¡åŒ–æ‰©å±•",
      "authors": [
        "Ran Xin",
        "Zeyu Zheng",
        "Yanchen Nie",
        "Kun Yuan",
        "Xia Xiao"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into automated theorem proving has shown immense promise, yet is fundamentally constrained by challenges in scaling up both training-time reinforcement learning (RL) and inference-time compute. This paper introduces \\texttt{BFS-Prover-V2}, a system designed to address this dual scaling problem. We present two primary innovations. The first is a novel multi-turn off-policy RL framework for continually improving the performance of LLM step-prover at training time. This framework, inspired by the principles of AlphaZero, utilizes a multi-stage expert iteration pipeline featuring adaptive tactic-level data filtering and periodic retraining to surmount the performance plateaus that typically curtail long-term RL in LLM-based agents. The second innovation is a planner-enhanced multi-agent search architecture that scales reasoning capabilities at inference time. This architecture employs a general reasoning model as a high-level planner to iteratively decompose complex theorems into a sequence of simpler subgoals. This hierarchical approach substantially reduces the search space, enabling a team of parallel prover agents to collaborate efficiently by leveraging a shared proof cache. We demonstrate that this dual approach to scaling yields state-of-the-art results on established formal mathematics benchmarks. \\texttt{BFS-Prover-V2} achieves 95.08\\% and 41.4\\% on the MiniF2F and ProofNet test sets respectively. While demonstrated in the domain of formal mathematics, the RL and inference techniques presented in this work are of broader interest and may be applied to other domains requiring long-horizon multi-turn reasoning and complex search.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†BFS-Prover-V2ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)æ­¥è¿›è¯æ˜å™¨åœ¨è®­ç»ƒé˜¶æ®µå¼ºåŒ–å­¦ä¹ (RL)æ‰©å±•ä¸æ¨ç†é˜¶æ®µè®¡ç®—æ‰©å±•çš„åŒé‡æŒ‘æˆ˜ã€‚åœ¨è®­ç»ƒæ–¹é¢ï¼Œè¯¥ç³»ç»Ÿå¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¤šè½®ç¦»ç­–å¼ºåŒ–å­¦ä¹ (Multi-turn off-policy RL)æ¡†æ¶ï¼Œå€Ÿé‰´AlphaZeroåŸåˆ™å¹¶ç»“åˆè‡ªé€‚åº”ç­–ç•¥çº§æ•°æ®è¿‡æ»¤ä¸å®šæœŸé‡è®­ç»ƒï¼Œå…‹æœäº†LLMæ™ºèƒ½ä½“åœ¨é•¿æœŸRLè®­ç»ƒä¸­æ˜“é‡åˆ°çš„æ€§èƒ½å¹³å°é—®é¢˜ã€‚åœ¨æ¨ç†æ–¹é¢ï¼Œç ”ç©¶è€…è®¾è®¡äº†è§„åˆ’å™¨å¢å¼ºçš„å¤šæ™ºèƒ½ä½“æœç´¢æ¶æ„ï¼Œåˆ©ç”¨é«˜çº§è§„åˆ’å™¨å°†å¤æ‚å®šç†å±‚çº§åŒ–åˆ†è§£ä¸ºå­ç›®æ ‡ï¼Œå¹¶é€šè¿‡å…±äº«è¯æ˜ç¼“å­˜å®ç°å¤šä¸ªå¹¶è¡Œè¯æ˜æ™ºèƒ½ä½“çš„é«˜æ•ˆåä½œã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBFS-Prover-V2åœ¨MiniF2Få’ŒProofNetåŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«è¾¾åˆ°äº†95.08%å’Œ41.4%çš„å‡†ç¡®ç‡ï¼Œåˆ·æ–°äº†å½¢å¼åŒ–æ•°å­¦è¯æ˜é¢†åŸŸçš„æœ€å…ˆè¿›(SOTA)è®°å½•ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œä¸­æå‡ºçš„RLä¸æœç´¢æŠ€æœ¯å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œå¯æ¨å¹¿è‡³å…¶ä»–éœ€è¦é•¿ç¨‹å¤šè½®æ¨ç†çš„å¤æ‚ä»»åŠ¡é¢†åŸŸã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06493v2",
      "published_date": "2025-09-08 09:54:18 UTC",
      "updated_date": "2025-10-09 17:45:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:47.033163+00:00"
    },
    {
      "arxiv_id": "2509.06490v1",
      "title": "MORSE: Multi-Objective Reinforcement Learning via Strategy Evolution for Supply Chain Optimization",
      "title_zh": "MORSEï¼šåŸºäºç­–ç•¥æ¼”åŒ–çš„ä¾›åº”é“¾ä¼˜åŒ–å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Niki Kotecha",
        "Ehecatl Antonio del Rio Chanona"
      ],
      "abstract": "In supply chain management, decision-making often involves balancing multiple conflicting objectives, such as cost reduction, service level improvement, and environmental sustainability. Traditional multi-objective optimization methods, such as linear programming and evolutionary algorithms, struggle to adapt in real-time to the dynamic nature of supply chains. In this paper, we propose an approach that combines Reinforcement Learning (RL) and Multi-Objective Evolutionary Algorithms (MOEAs) to address these challenges for dynamic multi-objective optimization under uncertainty. Our method leverages MOEAs to search the parameter space of policy neural networks, generating a Pareto front of policies. This provides decision-makers with a diverse population of policies that can be dynamically switched based on the current system objectives, ensuring flexibility and adaptability in real-time decision-making. We also introduce Conditional Value-at-Risk (CVaR) to incorporate risk-sensitive decision-making, enhancing resilience in uncertain environments. We demonstrate the effectiveness of our approach through case studies, showcasing its ability to respond to supply chain dynamics and outperforming state-of-the-art methods in an inventory management case study. The proposed strategy not only improves decision-making efficiency but also offers a more robust framework for managing uncertainty and optimizing performance in supply chains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MORSEï¼Œä¸€ç§ç»“åˆå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸å¤šç›®æ ‡è¿›åŒ–ç®—æ³•(Multi-Objective Evolutionary Algorithms)çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¾›åº”é“¾ç®¡ç†ä¸­å¤šç›®æ ‡å†²çªåŠåŠ¨æ€ç¯å¢ƒä¸‹çš„ä¼˜åŒ–æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨MOEAsæœç´¢ç­–ç•¥ç¥ç»ç½‘ç»œçš„å‚æ•°ç©ºé—´ï¼Œç”Ÿæˆä¸€ç³»åˆ—Pareto frontç­–ç•¥ï¼Œä»è€Œå…è®¸å†³ç­–è€…æ ¹æ®å½“å‰ç³»ç»Ÿéœ€æ±‚åœ¨ä¸åŒç­–ç•¥é—´å®æ—¶åŠ¨æ€åˆ‡æ¢ã€‚ä¸ºäº†æå‡ä¸ç¡®å®šç¯å¢ƒä¸‹çš„éŸ§æ€§ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†æ¡ä»¶é£é™©ä»·å€¼(Conditional Value-at-Risk)ä»¥æ”¯æŒé£é™©æ•æ„Ÿå‹å†³ç­–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMORSEåœ¨åº“å­˜ç®¡ç†æ¡ˆä¾‹ä¸­ä¼˜äºç°æœ‰çš„å‰æ²¿æ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆå“åº”ä¾›åº”é“¾çš„åŠ¨æ€å˜åŒ–ã€‚è¯¥æ–¹æ³•ä¸ä»…æé«˜äº†å†³ç­–æ•ˆç‡ï¼Œè¿˜ä¸ºå¤æ‚ä¾›åº”é“¾åœºæ™¯ä¸‹çš„ä¸ç¡®å®šæ€§ç®¡ç†å’Œå¤šç›®æ ‡ååŒä¼˜åŒ–æä¾›äº†ç¨³å¥çš„æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06490v1",
      "published_date": "2025-09-08 09:51:24 UTC",
      "updated_date": "2025-09-08 09:51:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:46.133632+00:00"
    },
    {
      "arxiv_id": "2509.06483v1",
      "title": "DyC-STG: Dynamic Causal Spatio-Temporal Graph Network for Real-time Data Credibility Analysis in IoT",
      "title_zh": "DyC-STGï¼šé¢å‘ç‰©è”ç½‘å®æ—¶æ•°æ®å¯ä¿¡åº¦åˆ†æçš„åŠ¨æ€å› æœæ—¶ç©ºå›¾ç½‘ç»œ",
      "authors": [
        "Guanjie Cheng",
        "Boyi Li",
        "Peihan Wu",
        "Feiyi Chen",
        "Xinkui Zhao",
        "Mengying Zhu",
        "Shuiguang Deng"
      ],
      "abstract": "The wide spreading of Internet of Things (IoT) sensors generates vast spatio-temporal data streams, but ensuring data credibility is a critical yet unsolved challenge for applications like smart homes. While spatio-temporal graph (STG) models are a leading paradigm for such data, they often fall short in dynamic, human-centric environments due to two fundamental limitations: (1) their reliance on static graph topologies, which fail to capture physical, event-driven dynamics, and (2) their tendency to confuse spurious correlations with true causality, undermining robustness in human-centric environments. To address these gaps, we propose the Dynamic Causal Spatio-Temporal Graph Network (DyC-STG), a novel framework designed for real-time data credibility analysis in IoT. Our framework features two synergistic contributions: an event-driven dynamic graph module that adapts the graph topology in real-time to reflect physical state changes, and a causal reasoning module to distill causally-aware representations by strictly enforcing temporal precedence. To facilitate the research in this domain we release two new real-world datasets. Comprehensive experiments show that DyC-STG establishes a new state-of-the-art, outperforming the strongest baselines by 1.4 percentage points and achieving an F1-Score of up to 0.930.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰©è”ç½‘ï¼ˆIoTï¼‰ä¼ æ„Ÿå™¨äº§ç”Ÿçš„æµ·é‡æ—¶ç©ºæ•°æ®ï¼Œæå‡ºäº† DyC-STGï¼ˆDynamic Causal Spatio-Temporal Graph Networkï¼‰æ¡†æ¶ï¼Œä»¥è§£å†³ä¼ ç»Ÿæ—¶ç©ºå›¾ï¼ˆSTGï¼‰æ¨¡å‹åœ¨å¤„ç†å®æ—¶æ•°æ®å¯ä¿¡åº¦åˆ†ææ—¶é¢ä¸´çš„æ‹“æ‰‘ç»“æ„é™æ€å’Œå› æœå…³ç³»æ··æ·†ç­‰å±€é™ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåŒ…å«ä¸¤ä¸ªååŒæ¨¡å—ï¼šä¸€ä¸ªæ˜¯äº‹ä»¶é©±åŠ¨çš„åŠ¨æ€å›¾æ¨¡å—ï¼Œç”¨äºå®æ—¶è°ƒæ•´å›¾æ‹“æ‰‘ä»¥åæ˜ ç‰©ç†çŠ¶æ€çš„å˜åŒ–ï¼›å¦ä¸€ä¸ªæ˜¯å› æœæ¨ç†æ¨¡å—ï¼Œé€šè¿‡ä¸¥æ ¼æ‰§è¡Œæ—¶é—´ä¼˜å…ˆæ€§æ¥æå–å…·æœ‰å› æœæ„ŸçŸ¥çš„è¡¨å¾ã€‚ä¸ºæ¨åŠ¨è¯¥é¢†åŸŸç ”ç©¶ï¼Œå›¢é˜ŸåŒæ­¥å‘å¸ƒäº†ä¸¤ä¸ªå…¨æ–°çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDyC-STG åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å¼ºåŸºçº¿æ¨¡å‹ 1.4 ä¸ªç™¾åˆ†ç‚¹ï¼Œå…¶ F1-Score æœ€é«˜è¾¾åˆ° 0.930ã€‚è¯¥ç ”ç©¶ä¸ä»…ç¡®ç«‹äº†æ•°æ®å¯ä¿¡åº¦åˆ†æçš„æ–° State-of-the-Artï¼Œä¹Ÿä¸ºåœ¨åŠ¨æ€ã€ä»¥äººä¸ºä¸­å¿ƒçš„ç‰©è”ç½‘ç¯å¢ƒä¸­å®ç°é²æ£’æ¨ç†æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06483v1",
      "published_date": "2025-09-08 09:46:58 UTC",
      "updated_date": "2025-09-08 09:46:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:49.229094+00:00"
    },
    {
      "arxiv_id": "2509.06477v1",
      "title": "MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents",
      "title_zh": "MAS-Benchï¼šé¢å‘å¿«æ·æ–¹å¼å¢å¼ºå‹æ··åˆç§»åŠ¨ GUI æ™ºèƒ½ä½“çš„ç»Ÿä¸€è¯„æµ‹åŸºå‡†",
      "authors": [
        "Pengxiang Zhao",
        "Guangyi Liu",
        "Yaozhen Liang",
        "Weiqing He",
        "Zhengxi Lu",
        "Yuehao Huang",
        "Yaxuan Guo",
        "Kexin Zhang",
        "Hao Wang",
        "Liang Liu",
        "Yong Liu"
      ],
      "abstract": "To enhance the efficiency of GUI agents on various platforms like smartphones and computers, a hybrid paradigm that combines flexible GUI operations with efficient shortcuts (e.g., API, deep links) is emerging as a promising direction. However, a framework for systematically benchmarking these hybrid agents is still underexplored. To take the first step in bridging this gap, we introduce MAS-Bench, a benchmark that pioneers the evaluation of GUI-shortcut hybrid agents with a specific focus on the mobile domain. Beyond merely using predefined shortcuts, MAS-Bench assesses an agent's capability to autonomously generate shortcuts by discovering and creating reusable, low-cost workflows. It features 139 complex tasks across 11 real-world applications, a knowledge base of 88 predefined shortcuts (APIs, deep-links, RPA scripts), and 7 evaluation metrics. The tasks are designed to be solvable via GUI-only operations, but can be significantly accelerated by intelligently embedding shortcuts. Experiments show that hybrid agents achieve significantly higher success rates and efficiency than their GUI-only counterparts. This result also demonstrates the effectiveness of our method for evaluating an agent's shortcut generation capabilities. MAS-Bench fills a critical evaluation gap, providing a foundational platform for future advancements in creating more efficient and robust intelligent agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç§»åŠ¨ GUI æ™ºèƒ½ä½“é¢†åŸŸç¼ºä¹ç³»ç»Ÿæ€§åŸºå‡†æµ‹è¯•çš„é—®é¢˜ï¼Œæå‡ºäº† MAS-Benchï¼Œè¿™æ˜¯é¦–ä¸ªä¸“æ³¨äºè¯„ä¼° GUI ä¸å¿«æ·æ–¹å¼(Shortcuts)æ··åˆé©±åŠ¨æ™ºèƒ½ä½“çš„ç»Ÿä¸€åŸºå‡†ã€‚MAS-Bench ä¸ä»…è¯„ä¼°æ™ºèƒ½ä½“åˆ©ç”¨é¢„å®šä¹‰ APIã€Deep links å’Œ RPA è„šæœ¬çš„èƒ½åŠ›ï¼Œè¿˜ç‰¹åˆ«è€ƒå¯Ÿå…¶é€šè¿‡æ¢ç´¢å¹¶åˆ›å»ºå¯å¤ç”¨å·¥ä½œæµæ¥è‡ªä¸»ç”Ÿæˆå¿«æ·æ–¹å¼çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†æ¶µç›–äº† 11 ä¸ªçœŸå®åº”ç”¨ä¸­çš„ 139 ä¸ªå¤æ‚ä»»åŠ¡ï¼Œå¹¶æä¾›åŒ…å« 88 ä¸ªå¿«æ·æ–¹å¼çš„çŸ¥è¯†åº“ä»¥åŠ 7 é¡¹å¤šç»´è¯„ä¼°æŒ‡æ ‡ã€‚å®éªŒæ•°æ®è¯æ˜ï¼Œç›¸æ¯”äºçº¯ GUI æ™ºèƒ½ä½“ï¼Œæ··åˆé©±åŠ¨æ™ºèƒ½ä½“åœ¨æˆåŠŸç‡å’Œè¿è¡Œæ•ˆç‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œæœ‰æ•ˆéªŒè¯äº†è¯¥æ¡†æ¶å¯¹æ™ºèƒ½ä½“å¿«æ·æ–¹å¼ç”Ÿæˆèƒ½åŠ›çš„è¯„ä¼°æ•ˆåŠ›ã€‚MAS-Bench å¡«è¡¥äº†å½“å‰é¢†åŸŸå†…çš„è¯„ä¼°ç©ºç™½ï¼Œä¸ºæœªæ¥å¼€å‘æ›´é«˜æ•ˆã€æ›´é²æ£’çš„æ™ºèƒ½ä»£ç†å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06477v1",
      "published_date": "2025-09-08 09:43:48 UTC",
      "updated_date": "2025-09-08 09:43:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:55.027213+00:00"
    },
    {
      "arxiv_id": "2509.06475v1",
      "title": "Explained, yet misunderstood: How AI Literacy shapes HR Managers' interpretation of User Interfaces in Recruiting Recommender Systems",
      "title_zh": "é‡Šè€Œæœªæ˜ï¼šAI ç´ å…»å¦‚ä½•å½±å“äººåŠ›èµ„æºç»ç†å¯¹æ‹›è˜æ¨èç³»ç»Ÿç”¨æˆ·ç•Œé¢çš„è§£è¯»",
      "authors": [
        "Yannick Kalff",
        "Katharina Simbeck"
      ],
      "abstract": "AI-based recommender systems increasingly influence recruitment decisions. Thus, transparency and responsible adoption in Human Resource Management (HRM) are critical. This study examines how HR managers' AI literacy influences their subjective perception and objective understanding of explainable AI (XAI) elements in recruiting recommender dashboards. In an online experiment, 410 German-based HR managers compared baseline dashboards to versions enriched with three XAI styles: important features, counterfactuals, and model criteria. Our results show that the dashboards used in practice do not explain AI results and even keep AI elements opaque. However, while adding XAI features improves subjective perceptions of helpfulness and trust among users with moderate or high AI literacy, it does not increase their objective understanding. It may even reduce accurate understanding, especially with complex explanations. Only overlays of important features significantly aided the interpretations of high-literacy users. Our findings highlight that the benefits of XAI in recruitment depend on users' AI literacy, emphasizing the need for tailored explanation strategies and targeted literacy training in HRM to ensure fair, transparent, and effective adoption of AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººåŠ›èµ„æºç»ç†çš„ AI Literacy å¦‚ä½•å½±å“å…¶å¯¹æ‹›è˜æ¨èç³»ç»Ÿä¸­å¯è§£é‡Šäººå·¥æ™ºèƒ½ (XAI) å…ƒç´ çš„æ„ŸçŸ¥ä¸ç†è§£ã€‚ç ”ç©¶é€šè¿‡å¯¹410åå¾·å›½ HR ç»ç†è¿›è¡Œåœ¨çº¿å®éªŒï¼Œå¯¹æ¯”äº†åŸºå‡†ä»ªè¡¨ç›˜ä¸åŒ…å« important featuresã€counterfactuals åŠ model criteria ä¸‰ç§ XAI æ ·å¼çš„ç‰ˆæœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶å¢åŠ  XAI åŠŸèƒ½æå‡äº†ä¸­é«˜ AI Literacy ç”¨æˆ·çš„ä¸»è§‚æœ‰ç”¨æ„Ÿå’Œä¿¡ä»»åº¦ï¼Œä½†å¹¶æœªèƒ½æ˜¾è‘—æé«˜å…¶å®¢è§‚ç†è§£èƒ½åŠ›ï¼Œå¤æ‚çš„è§£é‡Šç”šè‡³å¯èƒ½é™ä½ç†è§£çš„å‡†ç¡®åº¦ã€‚ç ”ç©¶å‘ç°ï¼Œä»…æœ‰ important features çš„å åŠ æ˜¾ç¤ºå¯¹é«˜ç´ å…»ç”¨æˆ·çš„è§£è¯»èµ·åˆ°äº†æ˜¾è‘—è¾…åŠ©ä½œç”¨ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº† XAI åœ¨æ‹›è˜ä¸­çš„æ•ˆç›Šé«˜åº¦ä¾èµ–äºç”¨æˆ·çš„ AI Literacy æ°´å¹³ã€‚ç ”ç©¶æœ€ç»ˆå»ºè®® HRM é¢†åŸŸåº”é‡‡å–å®šåˆ¶åŒ–çš„è§£é‡Šç­–ç•¥å’Œé’ˆå¯¹æ€§çš„ç´ å…»åŸ¹è®­ï¼Œä»¥å®ç° AI æŠ€æœ¯çš„å…¬å¹³ã€é€æ˜ä¸é«˜æ•ˆåº”ç”¨ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted paper for RecSys in HR'25: The 5th Workshop on Recommender Systems for Human Resources, in conjunction with the 19th ACM Conference on Recommender Systems, September 22--26, 2025, Prague, Czech Republic",
      "pdf_url": "https://arxiv.org/pdf/2509.06475v1",
      "published_date": "2025-09-08 09:40:49 UTC",
      "updated_date": "2025-09-08 09:40:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:55.935785+00:00"
    },
    {
      "arxiv_id": "2509.06466v1",
      "title": "Several Performance Bounds on Decentralized Online Optimization are Highly Conservative and Potentially Misleading",
      "title_zh": "åˆ†å¸ƒå¼åœ¨çº¿ä¼˜åŒ–çš„è‹¥å¹²æ€§èƒ½ç•Œé™å…·æœ‰é«˜åº¦ä¿å®ˆæ€§ä¸æ½œåœ¨è¯¯å¯¼æ€§",
      "authors": [
        "Erwan Meunier",
        "Julien M. Hendrickx"
      ],
      "abstract": "We analyze Decentralized Online Optimization algorithms using the Performance Estimation Problem approach which allows, to automatically compute exact worst-case performance of optimization algorithms. Our analysis shows that several available performance guarantees are very conservative, sometimes by multiple orders of magnitude, and can lead to misguided choices of algorithm. Moreover, at least in terms of worst-case performance, some algorithms appear not to benefit from inter-agent communications for a significant period of time. We show how to improve classical methods by tuning their step-sizes, and find that we can save up to 20% on their actual worst-case performance regret.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ Performance Estimation Problem (PEP) æ–¹æ³•å¯¹ Decentralized Online Optimization ç®—æ³•è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œæ—¨åœ¨è‡ªåŠ¨è®¡ç®—ä¼˜åŒ–ç®—æ³•çš„ç²¾ç¡®æœ€åæƒ…å†µæ€§èƒ½ã€‚ç ”ç©¶å‘ç°ï¼Œç›®å‰ç°æœ‰çš„å¤šé¡¹æ€§èƒ½ä¿è¯ (performance guarantees) æå…¶ä¿å®ˆï¼Œæœ‰æ—¶ç”šè‡³åç¦»å®é™…æ€§èƒ½æ•°ä¸ªæ•°é‡çº§ï¼Œå¯èƒ½å¯¼è‡´è¯¯å¯¼æ€§çš„ç®—æ³•é€‰æ‹©ã€‚å®éªŒç»“æœè¿˜æŒ‡å‡ºï¼Œåœ¨æœ€åæƒ…å†µæ€§èƒ½è¡¨ç°ä¸Šï¼Œéƒ¨åˆ†ç®—æ³•åœ¨æ˜¾è‘—çš„æ—¶é—´æ®µå†…å¹¶æœªä»æ™ºèƒ½ä½“é—´çš„é€šä¿¡ (inter-agent communications) ä¸­è·ç›Šã€‚é€šè¿‡å¯¹ç»å…¸æ–¹æ³•çš„æ­¥é•¿ (step-sizes) è¿›è¡Œè°ƒä¼˜ï¼Œè¯¥ç ”ç©¶æˆåŠŸå°†å…¶æœ€åæƒ…å†µä¸‹çš„æ€§èƒ½é—æ†¾ (performance regret) é™ä½äº†å¤šè¾¾ 20%ã€‚è¯¥å·¥ä½œæ­ç¤ºäº†ç°æœ‰ç†è®ºè¾¹ç•Œçš„å±€é™æ€§ï¼Œå¹¶ä¸ºä¼˜åŒ–å»ä¸­å¿ƒåŒ–åœ¨çº¿å­¦ä¹ ç®—æ³•æä¾›äº†æ›´ç²¾ç¡®çš„è¯„ä¼°å·¥å…·ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "primary_category": "math.OC",
      "comment": "7 pages, 5 figures. Paper accepted for the 64th IEEE Conference on Decision and Control (2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.06466v1",
      "published_date": "2025-09-08 09:28:36 UTC",
      "updated_date": "2025-09-08 09:28:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:17:56.335433+00:00"
    },
    {
      "arxiv_id": "2509.06463v2",
      "title": "Accelerate Scaling of LLM Finetuning via Quantifying the Coverage and Depth of Instruction Set",
      "title_zh": "é€šè¿‡é‡åŒ–æŒ‡ä»¤é›†çš„è¦†ç›–åº¦ä¸æ·±åº¦åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒçš„è§„æ¨¡åŒ–æ‰©å±•",
      "authors": [
        "Chengwei Wu",
        "Li Du",
        "Hanyu Zhao",
        "Yiming Ju",
        "Jiapu Wang",
        "Tianyu Chen",
        "Haoyi Zhou"
      ],
      "abstract": "Scaling the amount of data used for supervied fine-tuning(SFT) does not guarantee the proportional gains in model performance, highlighting a critical need to understand what makes training samples effective. This work identifies two fundamental dataset properties that govern SFT scalability: \\textbf{semantic coverage}, or the breadth of task domains, and \\textbf{information depth}, or the richness of individual examples. We demonstrate that simple proxies for these properties explain the majority of validation loss variance in our experiments. In this work, we further propose the \\textbf{Information Landscape Approximation (ILA)}, a model-agnostic data selection framework that jointly optimizes for these two factors. ILA constructs compact subsets that approximate the informational value of large datasets. Empirical results show that models tuned on ILA-selected data achieve faster and more sustained performance improvements across diverse tasks and model sizes compared to existing methods, a phenomenon we term \\textbf{accelerated scaling}.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç›‘ç£å¾®è°ƒ(SFT)ä¸­æ•°æ®è§„æ¨¡æ‰©å±•å¹¶ä¸æ€»æ˜¯èƒ½å¸¦æ¥ç­‰æ¯”ä¾‹æ€§èƒ½æå‡çš„é—®é¢˜ï¼Œè¯†åˆ«å‡ºå†³å®šSFTå¯æ‰©å±•æ€§çš„ä¸¤ä¸ªæ ¸å¿ƒæ•°æ®é›†å±æ€§ï¼šè¯­ä¹‰è¦†ç›–(semantic coverage)å’Œä¿¡æ¯æ·±åº¦(information depth)ã€‚ç ”ç©¶å‘ç°è¿™ä¸¤ä¸ªå±æ€§çš„ä»£ç†æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆè§£é‡Šå®éªŒä¸­ç»å¤§éƒ¨åˆ†çš„éªŒè¯æŸå¤±æ–¹å·®ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†ä¿¡æ¯å›¾è°±è¿‘ä¼¼(Information Landscape Approximation, ILA)æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§ä¸æ¨¡å‹æ— å…³çš„æ•°æ®é€‰æ‹©æ–¹æ¡ˆï¼Œæ—¨åœ¨é€šè¿‡è”åˆä¼˜åŒ–è¦†ç›–ä¸æ·±åº¦æ¥æ„å»ºèƒ½å¤Ÿä»£è¡¨å¤§è§„æ¨¡æ•°æ®é›†ä¿¡æ¯ä»·å€¼çš„ç´§å‡‘å­é›†ã€‚å®éªŒç»“æœè¯æ˜ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼Œç»ILAç­›é€‰æ•°æ®å¾®è°ƒçš„æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡å’Œæ¨¡å‹è§„æ¨¡ä¸Šå‡å±•ç°å‡ºäº†æ›´å¿«é€Ÿä¸”æŒç»­çš„æ€§èƒ½æå‡ã€‚è¿™ç§ç°è±¡è¢«ç ”ç©¶è€…å®šä¹‰ä¸ºåŠ é€Ÿæ‰©å±•(accelerated scaling)ï¼Œä¸ºä¼˜åŒ–LLMå¾®è°ƒæ•ˆç‡æä¾›äº†æ–°çš„ç†è®ºè§†è§’å’Œå®ç”¨å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06463v2",
      "published_date": "2025-09-08 09:22:57 UTC",
      "updated_date": "2025-10-28 08:59:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:16.136291+00:00"
    },
    {
      "arxiv_id": "2509.06461v2",
      "title": "Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning",
      "title_zh": "åŸºäºå¯¹æ¯”æ³¨æ„åŠ›çš„èšç„¦ï¼šå¢å¼º VLM çš„è§†è§‰æ¨ç†èƒ½åŠ›",
      "authors": [
        "Yuyao Ge",
        "Shenghua Liu",
        "Yiwei Wang",
        "Lingrui Mei",
        "Baolong Bi",
        "Xuanshan Zhou",
        "Jiayu Yao",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "Vision-Language Models (VLMs) have demonstrated remarkable success across diverse visual tasks, yet their performance degrades in complex visual environments. While existing enhancement approaches require additional training, rely on external segmentation tools, or operate at coarse-grained levels, they overlook the innate ability within VLMs. To bridge this gap, we investigate VLMs' attention patterns and discover that: (1) visual complexity strongly correlates with attention entropy, negatively impacting reasoning performance; (2) attention progressively refines from global scanning in shallow layers to focused convergence in deeper layers, with convergence degree determined by visual complexity. (3) Theoretically, we prove that the contrast of attention maps between general queries and task-specific queries enables the decomposition of visual signal into semantic signals and visual noise components. Building on these insights, we propose Contrastive Attention Refinement for Visual Enhancement (CARVE), a training-free method that extracts task-relevant visual signals through attention contrasting at the pixel level. Extensive experiments demonstrate that CARVE consistently enhances performance, achieving up to 75% improvement on open-source models. Our work provides critical insights into the interplay between visual complexity and attention mechanisms, offering an efficient pathway for improving visual reasoning with contrasting attention.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨å¤æ‚è§†è§‰ç¯å¢ƒä¸‹æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œæ­ç¤ºäº†è§†è§‰å¤æ‚æ€§ä¸æ³¨æ„åŠ›ç†µ(attention entropy)ä¹‹é—´çš„å¼ºç›¸å…³æ€§åŠå…¶å¯¹æ¨ç†èƒ½åŠ›çš„è´Ÿé¢å½±å“ã€‚é€šè¿‡åˆ†ææ³¨æ„åŠ›æ¨¡å¼ï¼Œç ”ç©¶è€…å‘ç°æ³¨æ„åŠ›åœ¨æ·±å±‚ä¼šæ ¹æ®è§†è§‰å¤æ‚ç¨‹åº¦è¶‹äºæ”¶æ•›ï¼Œå¹¶ä»ç†è®ºä¸Šè¯æ˜äº†é€šè¿‡å¯¹æ¯”é€šç”¨æŸ¥è¯¢ä¸ä»»åŠ¡ç‰¹å®šæŸ¥è¯¢çš„æ³¨æ„åŠ›å›¾(attention maps)å¯ä»¥æœ‰æ•ˆåˆ†ç¦»è¯­ä¹‰ä¿¡å·ä¸è§†è§‰å™ªå£°ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œè®ºæ–‡æå‡ºäº†CARVE (Contrastive Attention Refinement for Visual Enhancement)ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒ(training-free)çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨åƒç´ çº§æå–ä»»åŠ¡ç›¸å…³çš„è§†è§‰ä¿¡å·ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒCARVEèƒ½å¤Ÿç¨³å®šæå‡æ¨¡å‹æ€§èƒ½ï¼Œåœ¨å¼€æºæ¨¡å‹ä¸Šæœ€é«˜å®ç°äº†75%çš„æ”¹è¿›ã€‚è¯¥å·¥ä½œä¸ä»…æ·±å…¥æ­ç¤ºäº†è§†è§‰å¤æ‚æ€§ä¸æ³¨æ„åŠ›æœºåˆ¶çš„äº¤äº’ä½œç”¨ï¼Œä¹Ÿä¸ºå¢å¼ºVLMsçš„è§†è§‰æ¨ç†èƒ½åŠ›æä¾›äº†ä¸€ç§é«˜æ•ˆçš„å¯¹æ¯”æ³¨æ„åŠ›è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06461v2",
      "published_date": "2025-09-08 09:20:04 UTC",
      "updated_date": "2025-09-11 15:24:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:14.845363+00:00"
    },
    {
      "arxiv_id": "2509.06444v1",
      "title": "HyFedRAG: A Federated Retrieval-Augmented Generation Framework for Heterogeneous and Privacy-Sensitive Data",
      "title_zh": "HyFedRAGï¼šé¢å‘å¼‚æ„åŠéšç§æ•æ„Ÿæ•°æ®çš„è”é‚¦æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶",
      "authors": [
        "Cheng Qian",
        "Hainan Zhang",
        "Yongxin Tong",
        "Hong-Wei Zheng",
        "Zhiming Zheng"
      ],
      "abstract": "Centralized RAG pipelines struggle with heterogeneous and privacy-sensitive data, especially in distributed healthcare settings where patient data spans SQL, knowledge graphs, and clinical notes. Clinicians face difficulties retrieving rare disease cases due to privacy constraints and the limitations of traditional cloud-based RAG systems in handling diverse formats and edge devices. To address this, we introduce HyFedRAG, a unified and efficient Federated RAG framework tailored for Hybrid data modalities. By leveraging an edge-cloud collaborative mechanism, HyFedRAG enables RAG to operate across diverse data sources while preserving data privacy. Our key contributions are: (1) We design an edge-cloud collaborative RAG framework built on Flower, which supports querying structured SQL data, semi-structured knowledge graphs, and unstructured documents. The edge-side LLMs convert diverse data into standardized privacy-preserving representations, and the server-side LLMs integrates them for global reasoning and generation. (2) We integrate lightweight local retrievers with privacy-aware LLMs and provide three anonymization tools that enable each client to produce semantically rich, de-identified summaries for global inference across devices. (3) To optimize response latency and reduce redundant computation, we design a three-tier caching strategy consisting of local cache, intermediate representation cache, and cloud inference cache. Experimental results on PMC-Patients demonstrate that HyFedRAG outperforms existing baselines in terms of retrieval quality, generation consistency, and system efficiency. Our framework offers a scalable and privacy-compliant solution for RAG over structural-heterogeneous data, unlocking the potential of LLMs in sensitive and diverse data environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HyFedRAGï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºå¤„ç†å¼‚æ„ä¸”éšç§æ•æ„Ÿæ•°æ®è®¾è®¡çš„è”é‚¦æ£€ç´¢å¢å¼ºç”Ÿæˆ(Federated Retrieval-Augmented Generation)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŒ»ç–—ç­‰åˆ†å¸ƒå¼ç¯å¢ƒä¸­ä¼ ç»Ÿä¸­å¿ƒåŒ–RAGç³»ç»Ÿé¢ä¸´çš„éšç§é™åˆ¶ä¸æ•°æ®æ ¼å¼å¤šæ ·æ€§éš¾é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨äº‘è¾¹åä½œæœºåˆ¶ï¼Œé€šè¿‡åŸºäºFlowerçš„æ¶æ„å®ç°äº†å¯¹ç»“æ„åŒ–SQLã€åŠç»“æ„åŒ–çŸ¥è¯†å›¾è°±(Knowledge Graphs)åŠéç»“æ„åŒ–æ–‡æ¡£çš„ç»Ÿä¸€æŸ¥è¯¢ï¼Œç”±è¾¹ç¼˜ç«¯LLMså°†å¼‚æ„æ•°æ®è½¬åŒ–ä¸ºæ ‡å‡†åŒ–çš„éšç§ä¿æŠ¤è¡¨ç¤ºã€‚é€šè¿‡é›†æˆéšç§æ„ŸçŸ¥LLMsä¸è„±æ•å·¥å…·ï¼ŒHyFedRAGèƒ½å¤Ÿç”Ÿæˆè¯­ä¹‰ä¸°å¯Œä¸”å»æ ‡è¯†åŒ–çš„æ‘˜è¦ç”¨äºå…¨å±€æ¨ç†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è®¾è®¡äº†æ¶µç›–æœ¬åœ°ã€ä¸­é—´è¡¨ç¤ºå’Œäº‘æ¨ç†çš„ä¸‰å±‚ç¼“å­˜ç­–ç•¥ï¼Œä»¥æ˜¾è‘—é™ä½ç³»ç»Ÿå»¶è¿Ÿã€‚åœ¨PMC-Patientsæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒHyFedRAGåœ¨æ£€ç´¢è´¨é‡ã€ç”Ÿæˆä¸€è‡´æ€§å’Œç³»ç»Ÿæ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚è¯¥æ¡†æ¶ä¸ºæ•æ„Ÿæ•°æ®ç¯å¢ƒä¸‹çš„LLMsåº”ç”¨æä¾›äº†ä¸€ç§é«˜æ•ˆã€å¯æ‰©å±•ä¸”ç¬¦åˆéšç§åˆè§„çš„å¼‚æ„æ•°æ®å¤„ç†æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06444v1",
      "published_date": "2025-09-08 08:44:24 UTC",
      "updated_date": "2025-09-08 08:44:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:15.631883+00:00"
    },
    {
      "arxiv_id": "2509.06436v2",
      "title": "Tree of Agents: Improving Long-Context Capabilities of Large Language Models through Multi-Perspective Reasoning",
      "title_zh": "Tree of Agentsï¼šé€šè¿‡å¤šè§†è§’æ¨ç†æå‡å¤§è¯­è¨€æ¨¡å‹çš„é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›",
      "authors": [
        "Song Yu",
        "Xiaofei Xu",
        "Ke Deng",
        "Li Li",
        "Lin Tian"
      ],
      "abstract": "Large language models (LLMs) face persistent challenges when handling long-context tasks, most notably the lost in the middle issue, where information located in the middle of a long input tends to be underutilized. Some existing methods that reduce input have the risk of discarding key information, while others that extend context windows often lead to attention dispersion. To address these limitations, we propose Tree of Agents (TOA), a multi-agent reasoning framework that segments the input into chunks processed by independent agents. Each agent generates its local cognition, then agents dynamically exchange information for collaborative reasoning along tree-structured paths. TOA enables agents to probe different reasoning orders for multi-perspective understanding, effectively mitigating position bias and reducing hallucinations. To improve processing efficiency, we incorporate prefix-hash caching and adaptive pruning strategies, achieving significant performance improvements with comparable API overhead. Experiments show that TOA, powered by compact LLaMA3.1-8B, significantly outperforms multiple baselines and demonstrates comparable performance to the latest and much larger commercial models, such as Gemini1.5-pro, on various long-context tasks. Code is available at https://github.com/Aireduce952/Tree-of-Agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é•¿æ–‡æœ¬ä»»åŠ¡æ—¶é¢ä¸´çš„â€œä¿¡æ¯ä¸¢å¤±åœ¨ä¸­é—´â€(lost in the middle)å’Œæ³¨æ„åŠ›åˆ†æ•£ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†Tree of Agents (TOA)å¤šæ™ºèƒ½ä½“æ¨ç†æ¡†æ¶ã€‚TOAé€šè¿‡å°†è¾“å…¥æ–‡æœ¬åˆ‡åˆ†ä¸ºå¤šä¸ªåˆ†å—(chunks)ï¼Œå¹¶ç”±ç‹¬ç«‹çš„æ™ºèƒ½ä½“ç”Ÿæˆå±€éƒ¨è®¤çŸ¥ï¼Œéšåè®©æ™ºèƒ½ä½“æ²¿ç€æ ‘çŠ¶ç»“æ„è·¯å¾„åŠ¨æ€äº¤æ¢ä¿¡æ¯å¹¶è¿›è¡Œåä½œæ¨ç†ã€‚è¯¥æ–¹æ³•å…è®¸æ™ºèƒ½ä½“æ¢ç´¢ä¸åŒçš„æ¨ç†é¡ºåºä»¥å®ç°å¤šè§†è§’ç†è§£ï¼Œä»è€Œæœ‰æ•ˆç¼“è§£äº†ä½ç½®åç½®(position bias)å¹¶å‡å°‘äº†å¹»è§‰(hallucinations)ã€‚ä¸ºäº†æå‡å¤„ç†æ•ˆç‡ï¼Œè¯¥æ¡†æ¶è¿˜å¼•å…¥äº†å‰ç¼€å“ˆå¸Œç¼“å­˜(prefix-hash caching)å’Œè‡ªé€‚åº”å‰ªæ(adaptive pruning)ç­–ç•¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºLLaMA3.1-8Bçš„TOAåœ¨å¤šé¡¹é•¿æ–‡æœ¬ä»»åŠ¡ä¸­ä¸ä»…æ˜¾è‘—è¶…è¶Šäº†å¤šä¸ªåŸºçº¿æ¨¡å‹ï¼Œè¿˜å±•ç°å‡ºä¸Gemini1.5-proç­‰å¤§å‹å•†ä¸šæ¨¡å‹ç›¸å½“çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06436v2",
      "published_date": "2025-09-08 08:34:02 UTC",
      "updated_date": "2025-10-21 10:08:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:19.433914+00:00"
    },
    {
      "arxiv_id": "2509.06431v1",
      "title": "HECATE: An ECS-based Framework for Teaching and Developing Multi-Agent Systems",
      "title_zh": "HECATEï¼šä¸€ç§åŸºäº ECS çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ•™å­¦ä¸å¼€å‘æ¡†æ¶",
      "authors": [
        "Arthur Casals",
        "Anarosa A. F. BrandÃ£o"
      ],
      "abstract": "This paper introduces HECATE, a novel framework based on the Entity-Component-System (ECS) architectural pattern that bridges the gap between distributed systems engineering and MAS development. HECATE is built using the Entity-Component-System architectural pattern, leveraging data-oriented design to implement multiagent systems. This approach involves engineering multiagent systems (MAS) from a distributed systems (DS) perspective, integrating agent concepts directly into the DS domain. This approach simplifies MAS development by (i) reducing the need for specialized agent knowledge and (ii) leveraging familiar DS patterns and standards to minimize the agent-specific knowledge required for engineering MAS. We present the framework's architecture, core components, and implementation approach, demonstrating how it supports different agent models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HECATEï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå®ä½“-ç»„ä»¶-ç³»ç»Ÿ(Entity-Component-System, ECS)æ¶æ„æ¨¡å¼çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨å¼¥åˆåˆ†å¸ƒå¼ç³»ç»Ÿ(Distributed Systems, DS)å·¥ç¨‹ä¸å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multi-Agent Systems, MAS)å¼€å‘ä¹‹é—´çš„é¸¿æ²Ÿã€‚HECATEåˆ©ç”¨é¢å‘æ•°æ®(Data-oriented)çš„è®¾è®¡ç†å¿µï¼Œå°†æ™ºèƒ½ä½“æ¦‚å¿µç›´æ¥èå…¥åˆ†å¸ƒå¼ç³»ç»Ÿé¢†åŸŸï¼Œå®ç°äº†MASçš„é«˜æ•ˆæ„å»ºã€‚é€šè¿‡é‡‡ç”¨å¼€å‘è€…ç†Ÿæ‚‰çš„DSæ¨¡å¼å’Œæ ‡å‡†ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—é™ä½äº†å¼€å‘MASæ‰€éœ€çš„ä¸“é—¨æ™ºèƒ½ä½“çŸ¥è¯†é—¨æ§›ï¼Œä»è€Œç®€åŒ–äº†å¼€å‘æµç¨‹ã€‚æ–‡ä¸­è¯¦ç»†é˜è¿°äº†æ¡†æ¶çš„æ¶æ„è®¾è®¡ã€æ ¸å¿ƒç»„ä»¶åŠå®ç°è·¯å¾„ï¼Œå¹¶éªŒè¯äº†å…¶å¯¹å¤šç§æ™ºèƒ½ä½“æ¨¡å‹çš„æ”¯æŒèƒ½åŠ›ã€‚è¯¥æ¡†æ¶ä¸ºMASçš„æ•™å­¦ä¸å¼€å‘æä¾›äº†ä¸€ç§æ›´å…·å·¥ç¨‹å®è·µæ€§çš„ç³»ç»ŸåŒ–æ–¹æ³•ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Submitted to ECAI-2025",
      "pdf_url": "https://arxiv.org/pdf/2509.06431v1",
      "published_date": "2025-09-08 08:26:01 UTC",
      "updated_date": "2025-09-08 08:26:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:20.654626+00:00"
    },
    {
      "arxiv_id": "2509.06426v2",
      "title": "Musculoskeletal simulation of limb movement biomechanics in Drosophila melanogaster",
      "title_zh": "é»‘è…¹æœè‡è‚¢ä½“è¿åŠ¨ç”Ÿç‰©åŠ›å­¦çš„è‚Œè‚‰éª¨éª¼ä»¿çœŸ",
      "authors": [
        "Pembe Gizem Ã–zdil",
        "Chuanfang Ning",
        "Jasper S. Phelps",
        "Sibo Wang-Chen",
        "Guy Elisha",
        "Alexander Blanke",
        "Auke Ijspeert",
        "Pavan Ramdya"
      ],
      "abstract": "Computational models are critical to advance our understanding of how neural, biomechanical, and physical systems interact to orchestrate animal behaviors. Despite the availability of near-complete reconstructions of the Drosophila melanogaster central nervous system, musculature, and exoskeleton, anatomically and physically grounded models of fly leg muscles are still missing. These models provide an indispensable bridge between motor neuron activity and joint movements. Here, we introduce the first 3D, data-driven musculoskeletal model of Drosophila legs, implemented in both OpenSim and MuJoCo simulation environments. Our model incorporates a Hill-type muscle representation based on high-resolution X-ray scans from multiple fixed specimens. We present a pipeline for constructing muscle models using morphological imaging data and for optimizing unknown muscle parameters specific to the fly. We then combine our musculoskeletal models with detailed 3D pose estimation data from behaving flies to achieve muscle-actuated behavioral replay in OpenSim. Simulations of muscle activity across diverse walking and grooming behaviors predict coordinated muscle synergies that can be tested experimentally. Furthermore, by training imitation learning policies in MuJoCo, we test the effect of different passive joint properties on learning speed and find that damping and stiffness facilitate learning. Overall, our model enables the investigation of motor control in an experimentally tractable model organism, providing insights into how biomechanics contribute to generation of complex limb movements. Moreover, our model can be used to control embodied artificial agents to generate naturalistic and compliant locomotion in simulated environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†é¦–ä¸ªé’ˆå¯¹é»‘è…¹æœè‡ (Drosophila melanogaster) è…¿éƒ¨çš„ 3D æ•°æ®é©±åŠ¨éª¨éª¼è‚Œè‚‰æ¨¡å‹ (musculoskeletal model)ï¼Œå¹¶å·²åœ¨ OpenSim å’Œ MuJoCo ä»¿çœŸç¯å¢ƒä¸­å®ç°ã€‚è¯¥æ¨¡å‹åŸºäºé«˜åˆ†è¾¨ç‡ X å°„çº¿æ‰«ææ•°æ®ï¼Œæ•´åˆäº†å¸Œå°”å‹è‚Œè‚‰æ¨¡å‹ (Hill-type muscle representation)ï¼Œå¹¶æå‡ºäº†ä¸€å¥—åˆ©ç”¨å½¢æ€å­¦æˆåƒæ•°æ®æ„å»ºè‚Œè‚‰æ¨¡å‹åŠä¼˜åŒ–æœè‡ç‰¹å®šå‚æ•°çš„æµæ°´çº¿ã€‚é€šè¿‡å°†è¯¥æ¨¡å‹ä¸è¿åŠ¨æœè‡çš„ 3D å§¿æ€ä¼°è®¡æ•°æ®ç»“åˆï¼Œç ”ç©¶äººå‘˜åœ¨ OpenSim ä¸­æˆåŠŸå®ç°äº†ç”±è‚Œè‚‰é©±åŠ¨çš„è¡Œä¸ºé‡ç° (behavioral replay)ï¼Œå¹¶é¢„æµ‹äº†è¡Œèµ°å’Œæ¢³ç†è¡Œä¸ºä¸­çš„è‚Œè‚‰ååŒä½œç”¨ (muscle synergies)ã€‚åœ¨ MuJoCo ä¸­è¿›è¡Œçš„æ¨¡ä»¿å­¦ä¹  (imitation learning) è®­ç»ƒç»“æœè¡¨æ˜ï¼Œå…³èŠ‚çš„é˜»å°¼ (damping) å’Œåˆšåº¦ (stiffness) ç­‰è¢«åŠ¨å±æ€§èƒ½å¤Ÿæ˜¾è‘—æé«˜å­¦ä¹ æ•ˆç‡ã€‚è¯¥æ¨¡å‹ä¸ä»…ä¸ºæ·±å…¥æ¢ç©¶é»‘è…¹æœè‡çš„è¿åŠ¨æ§åˆ¶æœºåˆ¶æä¾›äº†ç”Ÿç‰©åŠ›å­¦è§†è§’ï¼Œä¹Ÿä¸ºåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­æ§åˆ¶å…·èº«æ™ºèƒ½ä½“ (embodied artificial agents) ç”Ÿæˆè‡ªç„¶ä¸”é¡ºåº”çš„è¿åŠ¨å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "q-bio.NC",
      "comment": "23 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06426v2",
      "published_date": "2025-09-08 08:21:14 UTC",
      "updated_date": "2025-09-11 21:45:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:35.642442+00:00"
    },
    {
      "arxiv_id": "2509.06419v1",
      "title": "CAPMix: Robust Time Series Anomaly Detection Based on Abnormal Assumptions with Dual-Space Mixup",
      "title_zh": "CAPMixï¼šåŸºäºå¼‚å¸¸å‡è®¾ä¸åŒç©ºé—´ Mixup çš„é²æ£’æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Xudong Mou",
        "Rui Wang",
        "Tiejun Wang",
        "Renyu Yang",
        "Shiru Chen",
        "Jie Sun",
        "Tianyu Wo",
        "Xudong Liu"
      ],
      "abstract": "Time series anomaly detection (TSAD) is a vital yet challenging task, particularly in scenarios where labeled anomalies are scarce and temporal dependencies are complex. Recent anomaly assumption (AA) approaches alleviate the lack of anomalies by injecting synthetic samples and training discriminative models. Despite promising results, these methods often suffer from two fundamental limitations: patchy generation, where scattered anomaly knowledge leads to overly simplistic or incoherent anomaly injection, and Anomaly Shift, where synthetic anomalies either resemble normal data too closely or diverge unrealistically from real anomalies, thereby distorting classification boundaries. In this paper, we propose CAPMix, a controllable anomaly augmentation framework that addresses both issues. First, we design a CutAddPaste mechanism to inject diverse and complex anomalies in a targeted manner, avoiding patchy generation. Second, we introduce a label revision strategy to adaptively refine anomaly labels, reducing the risk of anomaly shift. Finally, we employ dual-space mixup within a temporal convolutional network to enforce smoother and more robust decision boundaries. Extensive experiments on five benchmark datasets, including AIOps, UCR, SWaT, WADI, and ESA, demonstrate that CAPMix achieves significant improvements over state-of-the-art baselines, with enhanced robustness against contaminated training data. The code is available at https://github.com/alsike22/CAPMix.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹(Time series anomaly detection, TSAD)ä¸­æ ‡ç­¾ç¨€ç¼ºå’Œæ—¶é—´ä¾èµ–å¤æ‚çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†CAPMixæ¡†æ¶ã€‚CAPMixæ˜¯ä¸€ä¸ªå¯æ§çš„å¼‚å¸¸å¢å¼ºæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¼‚å¸¸å‡è®¾(Anomaly Assumption)æ–¹æ³•ä¸­å­˜åœ¨çš„æ–‘å—åŒ–ç”Ÿæˆ(patchy generation)å’Œå¼‚å¸¸åç§»(Anomaly Shift)é—®é¢˜ã€‚è¯¥æ¡†æ¶é¦–å…ˆè®¾è®¡äº†CutAddPasteæœºåˆ¶ï¼Œé€šè¿‡æœ‰é’ˆå¯¹æ€§çš„æ–¹å¼æ³¨å…¥å¤šæ ·ä¸”å¤æ‚çš„å¼‚å¸¸ï¼Œé¿å…äº†ç”Ÿæˆè¿‡äºç®€ç•¥æˆ–ä¸è¿è´¯çš„å¼‚å¸¸ã€‚å…¶æ¬¡ï¼Œç ”ç©¶å¼•å…¥äº†æ ‡ç­¾ä¿®æ­£ç­–ç•¥(label revision strategy)ï¼Œä»¥è‡ªé€‚åº”åœ°å®Œå–„å¼‚å¸¸æ ‡ç­¾ï¼Œä»è€Œé™ä½å¼‚å¸¸åç§»çš„é£é™©ã€‚æœ€åï¼ŒCAPMixåœ¨æ—¶é—´å·ç§¯ç½‘ç»œ(Temporal convolutional network)ä¸­åº”ç”¨äº†åŒç©ºé—´Mixup(dual-space mixup)ï¼Œä»¥å¼ºåŒ–å†³ç­–è¾¹ç•Œçš„å¹³æ»‘æ€§å’Œé²æ£’æ€§ã€‚åœ¨AIOpsã€UCRã€SWaTç­‰äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCAPMixç›¸æ¯”ç°æœ‰åŸºå‡†æ¨¡å‹å–å¾—äº†æ˜¾è‘—æå‡ï¼Œå¹¶è¡¨ç°å‡ºæ›´å¼ºçš„å¯¹æ±¡æŸ“è®­ç»ƒæ•°æ®çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06419v1",
      "published_date": "2025-09-08 08:15:12 UTC",
      "updated_date": "2025-09-08 08:15:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:29.239449+00:00"
    },
    {
      "arxiv_id": "2509.06415v1",
      "title": "Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models",
      "title_zh": "é¢å‘è§†è§‰è¯­è¨€æ¨¡å‹é«˜æ•ˆæ–‡æ¡£ç†è§£çš„ç´¢å¼•ä¿æŒè½»é‡çº§ Token å‰ªæ",
      "authors": [
        "Jaemin Son",
        "Sujin Choi",
        "Inyong Yun"
      ],
      "abstract": "Recent progress in vision-language models (VLMs) has led to impressive results in document understanding tasks, but their high computational demands remain a challenge. To mitigate the compute burdens, we propose a lightweight token pruning framework that filters out non-informative background regions from document images prior to VLM processing. A binary patch-level classifier removes non-text areas, and a max-pooling refinement step recovers fragmented text regions to enhance spatial coherence. Experiments on real-world document datasets demonstrate that our approach substantially lowers computational costs, while maintaining comparable accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)åœ¨æ–‡æ¡£ç†è§£ä»»åŠ¡ä¸­é¢ä¸´çš„é«˜è®¡ç®—éœ€æ±‚æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç´¢å¼•ä¿ç•™çš„è½»é‡çº§Token Pruningæ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨VLMå¤„ç†ä¹‹å‰é¢„å…ˆè¿‡æ»¤æ–‡æ¡£å›¾åƒä¸­çš„éä¿¡æ¯æ€§èƒŒæ™¯åŒºåŸŸï¼Œä»è€Œæ˜¾è‘—å‡è½»åç»­çš„è®¡ç®—è´Ÿæ‹…ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨äº†ä¸€ä¸ªäºŒå…ƒpatch-level classifieræ¥ç²¾å‡†è¯†åˆ«å¹¶ç§»é™¤å›¾åƒä¸­çš„éæ–‡æœ¬åŒºåŸŸï¼Œå¹¶å¼•å…¥Max-pooling Refinementæ­¥éª¤æ¥æ¢å¤è¢«åˆ†å‰²çš„æ–‡æœ¬ç‰‡æ®µä»¥å¢å¼ºç©ºé—´è¿è´¯æ€§ã€‚åœ¨çœŸå®ä¸–ç•Œæ–‡æ¡£æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤§å¹…é™ä½è®¡ç®—å¼€é”€çš„åŒæ—¶ï¼Œä¿æŒäº†ä¸åŸå§‹æ¨¡å‹ç›¸å½“çš„å‡†ç¡®ç‡ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºå®ç°é«˜æ•ˆä¸”ä½èƒ½è€—çš„è§†è§‰æ–‡æ¡£ç†è§£ä»»åŠ¡æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.06415v1",
      "published_date": "2025-09-08 08:12:26 UTC",
      "updated_date": "2025-09-08 08:12:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:32.643525+00:00"
    },
    {
      "arxiv_id": "2509.06409v1",
      "title": "Teaching AI Stepwise Diagnostic Reasoning with Report-Guided Chain-of-Thought Learning",
      "title_zh": "åŸºäºæŠ¥å‘Šå¼•å¯¼æ€ç»´é“¾å­¦ä¹ çš„AIé€æ­¥è¯Šæ–­æ¨ç†æ•™å­¦",
      "authors": [
        "Yihong Luo",
        "Wenwu He",
        "Zhuo-Xu Cui",
        "Dong Liang"
      ],
      "abstract": "This study presents DiagCoT, a multi-stage framework that applies supervised fine-tuning to general-purpose vision-language models (VLMs) to emulate radiologists' stepwise diagnostic reasoning using only free-text reports. DiagCoT combines contrastive image-report tuning for domain alignment, chain-of-thought supervision to capture inferential logic, and reinforcement tuning with clinical reward signals to enhance factual accuracy and fluency. On the MIMIC-CXR benchmark, DiagCoT improved zero-shot disease classification AUC from 0.52 to 0.76 (absolute gain of 0.24), pathology grounding mIoU from 0.08 to 0.31 (absolute gain of 0.23), and report generation BLEU from 0.11 to 0.33 (absolute gain of 0.22). It outperformed state-of-the-art models including LLaVA-Med and CXR-LLAVA on long-tailed diseases and external datasets. By converting unstructured clinical narratives into structured supervision, DiagCoT offers a scalable approach for developing interpretable and diagnostically competent AI systems for radiology.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DiagCoTï¼Œä¸€ä¸ªé€šè¿‡ç›‘ç£å¾®è°ƒé€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) æ¥æ¨¡æ‹Ÿæ”¾å°„ç§‘åŒ»ç”Ÿé€æ­¥è¯Šæ–­æ¨ç†çš„å¤šé˜¶æ®µæ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ç”¨äºé¢†åŸŸå¯¹é½çš„å¯¹æ¯”å›¾åƒ-æŠ¥å‘Šå¾®è°ƒ (Contrastive image-report tuning)ã€æ•æ‰æ¨ç†é€»è¾‘çš„é“¾å¼æ€ç»´ (Chain-of-Thought) ç›‘ç£ï¼Œä»¥åŠåˆ©ç”¨ä¸´åºŠå¥–åŠ±ä¿¡å·è¿›è¡Œçš„å¼ºåŒ–å¾®è°ƒ (Reinforcement tuning)ï¼Œä»¥æ˜¾è‘—æå‡æ¨¡å‹çš„äº‹å®å‡†ç¡®æ€§ã€‚åœ¨ MIMIC-CXR åŸºå‡†æµ‹è¯•ä¸­ï¼ŒDiagCoT å°†é›¶æ ·æœ¬ç–¾ç—…åˆ†ç±»çš„ AUC æå‡äº† 0.24ï¼Œç—…ç†å®šä½çš„ mIoU æå‡äº† 0.23ï¼ŒæŠ¥å‘Šç”Ÿæˆçš„ BLEU åˆ†æ•°æå‡äº† 0.22ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å‹åœ¨é•¿å°¾ç–¾ç—…å’Œå¤–éƒ¨æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äº LLaVA-Med å’Œ CXR-LLAVA ç­‰ç°æœ‰å…ˆè¿›æ¨¡å‹ã€‚é€šè¿‡å°†éç»“æ„åŒ–çš„ä¸´åºŠå™è¿°è½¬åŒ–ä¸ºç»“æ„åŒ–ç›‘ç£ï¼ŒDiagCoT ä¸ºå¼€å‘å…·æœ‰é«˜å¯è§£é‡Šæ€§å’Œè¯Šæ–­èƒ½åŠ›çš„æ”¾å°„å­¦ AI ç³»ç»Ÿæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06409v1",
      "published_date": "2025-09-08 08:01:26 UTC",
      "updated_date": "2025-09-08 08:01:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:41.575453+00:00"
    },
    {
      "arxiv_id": "2509.06389v1",
      "title": "MeanFlow-Accelerated Multimodal Video-to-Audio Synthesis via One-Step Generation",
      "title_zh": "MeanFlow åŠ é€Ÿçš„å¤šæ¨¡æ€è§†é¢‘è½¬éŸ³é¢‘åˆæˆï¼šåŸºäºä¸€æ­¥ç”Ÿæˆ",
      "authors": [
        "Xiaoran Yang",
        "Jianxuan Yang",
        "Xinyue Guo",
        "Haoyu Wang",
        "Ningning Pan",
        "Gongping Huang"
      ],
      "abstract": "A key challenge in synthesizing audios from silent videos is the inherent trade-off between synthesis quality and inference efficiency in existing methods. For instance, flow matching based models rely on modeling instantaneous velocity, inherently require an iterative sampling process, leading to slow inference speeds. To address this efficiency bottleneck, we introduce a MeanFlow-accelerated model that characterizes flow fields using average velocity, enabling one-step generation and thereby significantly accelerating multimodal video-to-audio (VTA) synthesis while preserving audio quality, semantic alignment, and temporal synchronization. Furthermore, a scalar rescaling mechanism is employed to balance conditional and unconditional predictions when classifier-free guidance (CFG) is applied, effectively mitigating CFG-induced distortions in one step generation. Since the audio synthesis network is jointly trained with multimodal conditions, we further evaluate it on text-to-audio (TTA) synthesis task. Experimental results demonstrate that incorporating MeanFlow into the network significantly improves inference speed without compromising perceptual quality on both VTA and TTA synthesis tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»æ— å£°è§†é¢‘åˆæˆéŸ³é¢‘(VTA)æ—¶å­˜åœ¨çš„åˆæˆè´¨é‡ä¸æ¨ç†æ•ˆç‡éš¾ä»¥å…¼é¡¾çš„é—®é¢˜ï¼Œæå‡ºäº†MeanFlowåŠ é€Ÿæ¨¡å‹ã€‚ä¼ ç»Ÿçš„flow matchingæ¨¡å‹ä¾èµ–äºç¬æ—¶é€Ÿåº¦å»ºæ¨¡ï¼Œé€šå¸¸éœ€è¦ç¹ççš„è¿­ä»£é‡‡æ ·è¿‡ç¨‹ï¼Œè€ŒMeanFlowé€šè¿‡åˆ©ç”¨å¹³å‡é€Ÿåº¦æ¥è¡¨å¾æµåœºï¼Œå®ç°äº†å•æ­¥ç”Ÿæˆ(one-step generation)ï¼Œä»è€Œåœ¨ä¿æŒéŸ³é¢‘è´¨é‡ã€è¯­ä¹‰å¯¹é½å’Œæ—¶é—´åŒæ­¥çš„åŒæ—¶ï¼Œæ˜¾è‘—åŠ å¿«äº†å¤šæ¨¡æ€VTAçš„åˆæˆé€Ÿåº¦ã€‚ä¸ºäº†è§£å†³å•æ­¥ç”Ÿæˆä¸­åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼(CFG)å¸¦æ¥çš„å¤±çœŸé—®é¢˜ï¼Œç ”ç©¶è¿˜é‡‡ç”¨äº†ä¸€ç§æ ‡é‡é‡ç¼©æ”¾æœºåˆ¶(scalar rescaling mechanism)æ¥å¹³è¡¡æ¡ä»¶ä¸æ— æ¡ä»¶é¢„æµ‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMeanFlowåœ¨VTAå’Œæ–‡æœ¬åˆ°éŸ³é¢‘(TTA)åˆæˆä»»åŠ¡ä¸­å‡æ˜¾è‘—æå‡äº†æ¨ç†é€Ÿåº¦ï¼Œä¸”æœªæŸå®³å…¶æ„ŸçŸ¥è´¨é‡ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06389v1",
      "published_date": "2025-09-08 07:15:21 UTC",
      "updated_date": "2025-09-08 07:15:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:18:45.474203+00:00"
    },
    {
      "arxiv_id": "2509.06385v3",
      "title": "Beyond the Pre-Service Horizon: Infusing In-Service Behavior for Improved Financial Risk Forecasting",
      "title_zh": "è·¨è¶Šè´·å‰è§†ç•Œï¼šèåˆæœåŠ¡ä¸­è¡Œä¸ºä»¥ä¼˜åŒ–é‡‘èé£é™©é¢„æµ‹",
      "authors": [
        "Senhao Liu",
        "Zhiyu Guo",
        "Zhiyuan Ji",
        "Yueguo Chen",
        "Yateng Tang",
        "Yunhai Wang",
        "Xuehao Zheng",
        "Xiang Ao"
      ],
      "abstract": "Typical financial risk management involves distinct phases for pre-service risk assessment and in-service default detection, often modeled separately. This paper proposes a novel framework, Multi-Granularity Knowledge Distillation (abbreviated as MGKD), aimed at improving pre-service risk prediction through the integration of in-service user behavior data. MGKD follows the idea of knowledge distillation, where the teacher model, trained on historical in-service data, guides the student model, which is trained on pre-service data. By using soft labels derived from in-service data, the teacher model helps the student model improve its risk prediction prior to service activation. Meanwhile, a multi-granularity distillation strategy is introduced, including coarse-grained, fine-grained, and self-distillation, to align the representations and predictions of the teacher and student models. This approach not only reinforces the representation of default cases but also enables the transfer of key behavioral patterns associated with defaulters from the teacher to the student model, thereby improving the overall performance of pre-service risk assessment. Moreover, we adopt a re-weighting strategy to mitigate the model's bias towards the minority class. Experimental results on large-scale real-world datasets from Tencent Mobile Payment demonstrate the effectiveness of our proposed approach in both offline and online scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿé‡‘èé£é™©ç®¡ç†ä¸­è´·å‰é£é™©è¯„ä¼°ä¸è´·ä¸­è¿çº¦æ£€æµ‹é€šå¸¸è¢«ç‹¬ç«‹å»ºæ¨¡çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºå¤šç²’åº¦çŸ¥è¯†è’¸é¦ (Multi-Granularity Knowledge Distillation, MGKD) çš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆè´·ä¸­ (In-Service) ç”¨æˆ·è¡Œä¸ºæ•°æ®æ¥æå‡è´·å‰é¢„æµ‹èƒ½åŠ›ã€‚MGKD éµå¾ªçŸ¥è¯†è’¸é¦ (Knowledge Distillation) çš„æ ¸å¿ƒæ€æƒ³ï¼Œåˆ©ç”¨åœ¨å†å²è´·ä¸­æ•°æ®ä¸Šè®­ç»ƒçš„æ•™å¸ˆæ¨¡å‹æ¥æŒ‡å¯¼ä»…ä½¿ç”¨è´·å‰æ•°æ®çš„å­¦ç”Ÿæ¨¡å‹ï¼Œå¹¶é€šè¿‡è½¯æ ‡ç­¾ (Soft Labels) ä¼˜åŒ–é¢„è­¦å‡†ç¡®æ€§ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ¶µç›–ç²—ç²’åº¦ã€ç»†ç²’åº¦å’Œè‡ªè’¸é¦çš„å¤šç²’åº¦ç­–ç•¥ï¼Œä»¥å®ç°æ•™å¸ˆä¸å­¦ç”Ÿæ¨¡å‹åœ¨è¡¨å¾ä¸é¢„æµ‹ä¸Šçš„é«˜åº¦å¯¹é½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é‡‡ç”¨äº†é‡æ–°åŠ æƒ (Re-weighting) ç­–ç•¥æ¥ç¼“è§£æ¨¡å‹å¯¹å°‘æ•°ç±»åˆ«çš„åå·®ï¼Œä»è€Œæœ‰æ•ˆè½¬ç§»è¿çº¦è€…çš„å…³é”®è¡Œä¸ºæ¨¡å¼ã€‚åœ¨è…¾è®¯ç§»åŠ¨æ”¯ä»˜ (Tencent Mobile Payment) å¤§è§„æ¨¡çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¦»çº¿å’Œåœ¨çº¿åœºæ™¯ä¸­å‡èƒ½æ˜¾è‘—æå‡è´·å‰é£é™©è¯„ä¼°çš„æ•´ä½“æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE ICDM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.06385v3",
      "published_date": "2025-09-08 07:09:18 UTC",
      "updated_date": "2025-09-24 16:25:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:00.061576+00:00"
    },
    {
      "arxiv_id": "2509.06367v1",
      "title": "MRD-LiNet: A Novel Lightweight Hybrid CNN with Gradient-Guided Unlearning for Improved Drought Stress Identification",
      "title_zh": "MRD-LiNetï¼šä¸€ç§é›†æˆæ¢¯åº¦å¼•å¯¼æœºå™¨é—å¿˜æœºåˆ¶ã€æ—¨åœ¨æå‡å¹²æ—±èƒè¿«è¯†åˆ«æ•ˆæœçš„æ–°å‹è½»é‡çº§æ··åˆå·ç§¯ç¥ç»ç½‘ç»œ",
      "authors": [
        "Aswini Kumar Patra",
        "Lingaraj Sahoo"
      ],
      "abstract": "Drought stress is a major threat to global crop productivity, making its early and precise detection essential for sustainable agricultural management. Traditional approaches, though useful, are often time-consuming and labor-intensive, which has motivated the adoption of deep learning methods. In recent years, Convolutional Neural Network (CNN) and Vision Transformer architectures have been widely explored for drought stress identification; however, these models generally rely on a large number of trainable parameters, restricting their use in resource-limited and real-time agricultural settings. To address this challenge, we propose a novel lightweight hybrid CNN framework inspired by ResNet, DenseNet, and MobileNet architectures. The framework achieves a remarkable 15-fold reduction in trainable parameters compared to conventional CNN and Vision Transformer models, while maintaining competitive accuracy. In addition, we introduce a machine unlearning mechanism based on a gradient norm-based influence function, which enables targeted removal of specific training data influence, thereby improving model adaptability. The method was evaluated on an aerial image dataset of potato fields with expert-annotated healthy and drought-stressed regions. Experimental results show that our framework achieves high accuracy while substantially lowering computational costs. These findings highlight its potential as a practical, scalable, and adaptive solution for drought stress monitoring in precision agriculture, particularly under resource-constrained conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MRD-LiNetï¼Œä¸€ç§å—ResNetã€DenseNetå’ŒMobileNetæ¶æ„å¯å‘çš„æ–°å‹è½»é‡åŒ–æ··åˆCNNæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¹²æ—±èƒè¿«(Drought stress)è¯†åˆ«ä¸­ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹å‚æ•°é‡å·¨å¤§ä¸”éš¾ä»¥åœ¨èµ„æºå—é™ç¯å¢ƒä¸­éƒ¨ç½²çš„é—®é¢˜ã€‚ä¸ä¼ ç»Ÿçš„CNNå’ŒVision Transformeræ¶æ„ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶åœ¨ç»´æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶å®ç°äº†15å€çš„å¯è®­ç»ƒå‚æ•°å‰Šå‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºæ¢¯åº¦èŒƒæ•°å½±å“å‡½æ•°(gradient norm-based influence function)çš„æœºå™¨é—å¿˜(machine unlearning)æœºåˆ¶ï¼Œèƒ½å¤Ÿå®šå‘ç§»é™¤ç‰¹å®šè®­ç»ƒæ•°æ®çš„å½±å“ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„ç¯å¢ƒé€‚åº”èƒ½åŠ›ã€‚åœ¨é©¬é“ƒè–¯ç”°èˆªæ‹æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ˜¾è‘—é™ä½è®¡ç®—å¼€é”€çš„åŒæ—¶ä¿è¯äº†æé«˜çš„ç›‘æµ‹ç²¾åº¦ã€‚è¿™é¡¹ç ”ç©¶ä¸ºç²¾å‡†å†œä¸šæä¾›äº†ä¸€ç§é«˜æ•ˆã€å¯æ‰©å±•ä¸”å…·é€‚åº”æ€§çš„å¹²æ—±ç›‘æµ‹æ–¹æ¡ˆï¼Œå°¤å…¶é€‚ç”¨äºå¯¹å®æ—¶æ€§è¦æ±‚è¾ƒé«˜çš„èµ„æºå—é™åœºæ™¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 6 Figures, 3 Tables",
      "pdf_url": "https://arxiv.org/pdf/2509.06367v1",
      "published_date": "2025-09-08 06:46:35 UTC",
      "updated_date": "2025-09-08 06:46:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:10.473356+00:00"
    },
    {
      "arxiv_id": "2509.09713v1",
      "title": "HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering",
      "title_zh": "HANRAGï¼šé¢å‘å¤šè·³é—®ç­”çš„å¯å‘å¼ç²¾å‡†æŠ—å™ªå£°æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Duolin Sun",
        "Dan Yang",
        "Yue Shen",
        "Yihan Jiao",
        "Zhehao Tan",
        "Jie Feng",
        "Lianzhen Zhong",
        "Jian Wang",
        "Peng Wei",
        "Jinjie Gu"
      ],
      "abstract": "The Retrieval-Augmented Generation (RAG) approach enhances question-answering systems and dialogue generation tasks by integrating information retrieval (IR) technologies with large language models (LLMs). This strategy, which retrieves information from external knowledge bases to bolster the response capabilities of generative models, has achieved certain successes. However, current RAG methods still face numerous challenges when dealing with multi-hop queries. For instance, some approaches overly rely on iterative retrieval, wasting too many retrieval steps on compound queries. Additionally, using the original complex query for retrieval may fail to capture content relevant to specific sub-queries, resulting in noisy retrieved content. If the noise is not managed, it can lead to the problem of noise accumulation. To address these issues, we introduce HANRAG, a novel heuristic-based framework designed to efficiently tackle problems of varying complexity. Driven by a powerful revelator, HANRAG routes queries, decomposes them into sub-queries, and filters noise from retrieved documents. This enhances the system's adaptability and noise resistance, making it highly capable of handling diverse queries. We compare the proposed framework against other leading industry methods across various benchmarks. The results demonstrate that our framework obtains superior performance in both single-hop and multi-hop question-answering tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åœ¨å¤„ç†å¤šè·³é—®é¢˜(Multi-hop Question Answering)æ—¶é¢ä¸´çš„è¿‡åº¦ä¾èµ–è¿­ä»£æ£€ç´¢ã€å¤æ‚æŸ¥è¯¢æ•è·åŠ›ä¸è¶³ä»¥åŠå™ªå£°ç´¯ç§¯(Noise Accumulation)ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºHANRAGçš„å¯å‘å¼å‡†ç¡®æŠ—å™ªæ¡†æ¶ã€‚è¯¥æ¡†æ¶ç”±ä¸€ä¸ªå¼ºå¤§çš„æ­ç¤ºå™¨(Revelator)é©±åŠ¨ï¼Œèƒ½å¤Ÿæ ¹æ®æŸ¥è¯¢å¤æ‚åº¦è¿›è¡Œè·¯ç”±ï¼Œå¹¶å°†å…¶æœ‰æ•ˆåˆ†è§£ä¸ºå­æŸ¥è¯¢(Sub-queries)ï¼Œä»è€Œæ›´ç²¾å‡†åœ°åŒ¹é…ç›¸å…³çŸ¥è¯†ã€‚æ­¤å¤–ï¼ŒHANRAGé€šè¿‡å¯¹æ£€ç´¢åˆ°çš„æ–‡æ¡£è¿›è¡Œå™ªå£°è¿‡æ»¤ï¼Œæ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿåœ¨é¢å¯¹å¤šæ ·åŒ–æŸ¥è¯¢æ—¶çš„é€‚åº”æ€§å’ŒæŠ—å™ªèƒ½åŠ›ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•çš„å®éªŒå¯¹æ¯”ä¸­ï¼Œè¯¥æ¡†æ¶åœ¨å•è·³(Single-hop)å’Œå¤šè·³é—®ç­”ä»»åŠ¡ä¸Šå‡å–å¾—äº†ä¼˜äºç›®å‰è¡Œä¸šé¢†å…ˆæ–¹æ³•çš„æ€§èƒ½è¡¨ç°ã€‚è¿™ä¸€æˆæœè¯æ˜äº†å¯å‘å¼åˆ†è§£ä¸å™ªå£°ç®¡ç†åœ¨æå‡å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹(LLMs)å¤„ç†å¤æ‚æ£€ç´¢ä»»åŠ¡æ—¶çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09713v1",
      "published_date": "2025-09-08 06:22:38 UTC",
      "updated_date": "2025-09-08 06:22:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:07.159167+00:00"
    },
    {
      "arxiv_id": "2509.06356v1",
      "title": "PL-CA: A Parametric Legal Case Augmentation Framework",
      "title_zh": "PL-CAï¼šä¸€ç§å‚æ•°åŒ–æ³•å¾‹æ¡ˆä¾‹å¢å¼ºæ¡†æ¶",
      "authors": [
        "Ao Chang",
        "Yubo Chen",
        "Jun Zhao"
      ],
      "abstract": "Conventional RAG is considered one of the most effective methods for addressing model knowledge insufficiency and hallucination, particularly in the judicial domain that requires high levels of knowledge rigor, logical consistency, and content integrity. However, the conventional RAG method only injects retrieved documents directly into the model's context, which severely constrains models due to their limited context windows and introduces additional computational overhead through excessively long contexts, thereby disrupting models' attention and degrading performance on downstream tasks. Moreover, many existing benchmarks lack expert annotation and focus solely on individual downstream tasks while real-world legal scenarios consist of multiple mixed legal tasks, indicating conventional benchmarks' inadequacy for reflecting models' true capabilities. To address these limitations, we propose PL-CA, which introduces a parametric RAG (P-RAG) framework to perform data augmentation on corpus knowledge and encode this legal knowledge into parametric vectors, and then integrates this parametric knowledge into the LLM's feed-forward networks (FFN) via LoRA, thereby alleviating models' context pressure. Additionally, we also construct a multi-task legal dataset comprising more than 2000 training and test instances, which are all expert-annotated and manually verified. We conduct our experiments on our dataset, and the experimental results demonstrate that our method reduces the overhead associated with excessively long contexts while maintaining competitive performance on downstream tasks compared to conventional RAG. Our code and dataset are provided in the appendix.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PL-CAï¼Œä¸€ç§å‚æ•°åŒ–æ³•å¾‹æ¡ˆä¾‹å¢å¼ºæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åœ¨å¸æ³•é¢†åŸŸé¢ä¸´çš„ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ã€è®¡ç®—å¼€é”€å¤§åŠæ¨¡å‹æ³¨æ„åŠ›å—å¹²æ‰°ç­‰é—®é¢˜ã€‚PL-CAå¼•å…¥äº†å‚æ•°åŒ–RAG (P-RAG) æœºåˆ¶ï¼Œå°†æ³•å¾‹çŸ¥è¯†ç¼–ç ä¸ºå‚æ•°åŒ–å‘é‡ï¼Œå¹¶é€šè¿‡LoRAæŠ€æœ¯é›†æˆåˆ°å¤§è¯­è¨€æ¨¡å‹(LLM)çš„å‰é¦ˆç½‘ç»œ(FFN)ä¸­ï¼Œæœ‰æ•ˆç¼“è§£äº†ä¸Šä¸‹æ–‡å‹åŠ›ã€‚åŒæ—¶ï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸€ä¸ªåŒ…å«2000å¤šä¸ªä¸“å®¶æ ‡æ³¨ä¸”ç»è¿‡äººå·¥éªŒè¯çš„å¤šä»»åŠ¡æ³•å¾‹æ•°æ®é›†ï¼Œä»¥æ›´çœŸå®åœ°åæ˜ æ¨¡å‹åœ¨å¤æ‚æ³•å¾‹åœºæ™¯ä¸‹çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒPL-CAåœ¨æ˜¾è‘—å‡å°‘è¶…é•¿ä¸Šä¸‹æ–‡ç›¸å…³å¼€é”€çš„åŒæ—¶ï¼Œåœ¨å¤šé¡¹ä¸‹æ¸¸æ³•å¾‹ä»»åŠ¡ä¸­ä¿æŒäº†ä¸ä¼ ç»ŸRAGç›¸å½“çš„ç«äº‰æ€§èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06356v1",
      "published_date": "2025-09-08 06:08:06 UTC",
      "updated_date": "2025-09-08 06:08:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:06.381583+00:00"
    },
    {
      "arxiv_id": "2509.06355v2",
      "title": "A Data-Driven Discretized CS:GO Simulation Environment to Facilitate Strategic Multi-Agent Planning Research",
      "title_zh": "åŠ©åŠ›ç­–ç•¥æ€§å¤šæ™ºèƒ½ä½“è§„åˆ’ç ”ç©¶çš„æ•°æ®é©±åŠ¨ç¦»æ•£åŒ– CS:GO ä»¿çœŸç¯å¢ƒ",
      "authors": [
        "Yunzhe Wang",
        "Volkan Ustun",
        "Chris McGroarty"
      ],
      "abstract": "Modern simulation environments for complex multi-agent interactions must balance high-fidelity detail with computational efficiency. We present DECOY, a novel multi-agent simulator that abstracts strategic, long-horizon planning in 3D terrains into high-level discretized simulation while preserving low-level environmental fidelity. Using Counter-Strike: Global Offensive (CS:GO) as a testbed, our framework accurately simulates gameplay using only movement decisions as tactical positioning -- without explicitly modeling low-level mechanics such as aiming and shooting. Central to our approach is a waypoint system that simplifies and discretizes continuous states and actions, paired with neural predictive and generative models trained on real CS:GO tournament data to reconstruct event outcomes. Extensive evaluations show that replays generated from human data in DECOY closely match those observed in the original game. Our publicly available simulation environment provides a valuable tool for advancing research in strategic multi-agent planning and behavior generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DECOYï¼Œä¸€ç§åˆ›æ–°çš„å¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿå™¨ï¼Œæ—¨åœ¨å¹³è¡¡å¤æ‚å¤šæ™ºèƒ½ä½“äº¤äº’ä¸­çš„é«˜ä¿çœŸç»†èŠ‚ä¸è®¡ç®—æ•ˆç‡ã€‚DECOY å°† 3D åœ°å½¢ä¸­çš„é•¿ç¨‹æˆ˜ç•¥è§„åˆ’æŠ½è±¡ä¸ºé«˜å±‚ç¦»æ•£åŒ–æ¨¡æ‹Ÿï¼Œä»¥ Counter-Strike: Global Offensive (CS:GO) ä¸ºæµ‹è¯•å¹³å°ï¼Œé€šè¿‡ä»…å¯¹ç§»åŠ¨å†³ç­–è¿›è¡Œæˆ˜æœ¯å®šä½å»ºæ¨¡ï¼Œé¿å¼€äº†ç„å‡†å’Œå°„å‡»ç­‰ä½çº§æœºæ¢°æ¨¡æ‹Ÿã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåŒ…å«ä¸€ä¸ªç”¨äºç¦»æ•£åŒ–è¿ç»­çŠ¶æ€ä¸åŠ¨ä½œçš„ Waypoint systemï¼Œä»¥åŠåŸºäºçœŸå®æ¯”èµ›æ•°æ®è®­ç»ƒçš„ç¥ç»é¢„æµ‹ä¸ç”Ÿæˆæ¨¡å‹ (neural predictive and generative models) æ¥é‡å»ºäº‹ä»¶ç»“æœã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒDECOY ç”Ÿæˆçš„é‡æ”¾æ•°æ®ä¸åŸå§‹æ¸¸æˆä¸­çš„äººç±»è¡¨ç°é«˜åº¦å¥‘åˆã€‚è¯¥å¼€æºç¯å¢ƒä¸ºæˆ˜ç•¥æ€§å¤šæ™ºèƒ½ä½“è§„åˆ’ (strategic multi-agent planning) å’Œè¡Œä¸ºç”Ÿæˆç ”ç©¶æä¾›äº†ä¸€ä¸ªå…¼é¡¾æ•ˆç‡ä¸å‡†ç¡®æ€§çš„é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the Winter Simulation Conference 2025, December, Seattle USA",
      "pdf_url": "https://arxiv.org/pdf/2509.06355v2",
      "published_date": "2025-09-08 06:02:59 UTC",
      "updated_date": "2025-09-19 22:37:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:09.157554+00:00"
    },
    {
      "arxiv_id": "2509.07038v1",
      "title": "Controllable Singing Voice Synthesis using Phoneme-Level Energy Sequence",
      "title_zh": "åŸºäºéŸ³ç´ çº§èƒ½é‡åºåˆ—çš„å¯æ§æ­Œå£°åˆæˆ",
      "authors": [
        "Yerin Ryu",
        "Inseop Shin",
        "Chanwoo Kim"
      ],
      "abstract": "Controllable Singing Voice Synthesis (SVS) aims to generate expressive singing voices reflecting user intent. While recent SVS systems achieve high audio quality, most rely on probabilistic modeling, limiting precise control over attributes such as dynamics. We address this by focusing on dynamic control--temporal loudness variation essential for musical expressiveness--and explicitly condition the SVS model on energy sequences extracted from ground-truth spectrograms, reducing annotation costs and improving controllability. We also propose a phoneme-level energy sequence for user-friendly control. To the best of our knowledge, this is the first attempt enabling user-driven dynamics control in SVS. Experiments show our method achieves over 50% reduction in mean absolute error of energy sequences for phoneme-level inputs compared to baseline and energy-predictor models, without compromising synthesis quality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯æ§æ­Œå”±è¯­éŸ³åˆæˆ(Singing Voice Synthesis, SVS)ä¸­åŠ¨æ€æ§åˆ¶(dynamic control)ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨éŸ³ç´ çº§èƒ½é‡åºåˆ—(Phoneme-Level Energy Sequence)å®ç°è¡¨ç°åŠ›ç”Ÿæˆçš„æ¡†æ¶ã€‚ä¸åŒäºå¤§å¤šæ•°ä¾èµ–æ¦‚ç‡å»ºæ¨¡ä¸”åœ¨åŠ¨æ€å±æ€§æ§åˆ¶ä¸Šå—é™çš„ç°æœ‰ç³»ç»Ÿï¼Œè¯¥æ–¹æ³•ç›´æ¥å°†SVSæ¨¡å‹å»ºç«‹åœ¨ä»çœŸå®é¢‘è°±å›¾ä¸­æå–çš„èƒ½é‡åºåˆ—ä¸Šï¼Œä»è€Œæ˜¾è‘—é™ä½äº†æ ‡æ³¨æˆæœ¬å¹¶å¢å¼ºäº†å¯¹è¡¨ç°åŠ›çš„æ§åˆ¶ã€‚ç ”ç©¶ç‰¹åˆ«æå‡ºäº†éŸ³ç´ çº§èƒ½é‡åºåˆ—ï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·æä¾›æ›´ç›´è§‚ã€æ›´å‹å¥½çš„åŠ¨æ€æ§åˆ¶æ‰‹æ®µï¼Œå®ç°å¯¹éŸ³ä¹è¡¨ç°åŠ›è‡³å…³é‡è¦çš„å“åº¦éšæ—¶é—´å˜åŒ–çš„ç²¾ç¡®è°ƒèŠ‚ã€‚æ®æ‚‰ï¼Œè¿™æ˜¯åœ¨SVSé¢†åŸŸé¦–æ¬¡å®ç°ç”¨æˆ·é©±åŠ¨çš„åŠ¨æ€æ§åˆ¶å°è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºçº¿æ¨¡å‹å’Œèƒ½é‡é¢„æµ‹å™¨æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨éŸ³ç´ çº§è¾“å…¥çš„èƒ½é‡åºåˆ—å¹³å‡ç»å¯¹è¯¯å·®(mean absolute error)ä¸Šé™ä½äº†50%ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—æå‡æ§åˆ¶ç²¾åº¦çš„åŒæ—¶ï¼Œç¡®ä¿äº†æœ€ç»ˆçš„åˆæˆè´¨é‡(synthesis quality)ä¸å—æŸå®³ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to ASRU 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07038v1",
      "published_date": "2025-09-08 06:02:57 UTC",
      "updated_date": "2025-09-08 06:02:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:13.181955+00:00"
    },
    {
      "arxiv_id": "2509.06350v1",
      "title": "Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks?",
      "title_zh": "Mask-GCGï¼šå¯¹æŠ—æ€§åç¼€ä¸­çš„æ‰€æœ‰ Token é’ˆå¯¹è¶Šç‹±æ”»å‡»éƒ½æ˜¯å¿…éœ€çš„å—ï¼Ÿ",
      "authors": [
        "Junjie Mu",
        "Zonghao Ying",
        "Zhekui Fan",
        "Zonglei Jing",
        "Yaoyuan Zhang",
        "Zhengmin Yu",
        "Wenxin Zhang",
        "Quanchen Zou",
        "Xiangzheng Zhang"
      ],
      "abstract": "Jailbreak attacks on Large Language Models (LLMs) have demonstrated various successful methods whereby attackers manipulate models into generating harmful responses that they are designed to avoid. Among these, Greedy Coordinate Gradient (GCG) has emerged as a general and effective approach that optimizes the tokens in a suffix to generate jailbreakable prompts. While several improved variants of GCG have been proposed, they all rely on fixed-length suffixes. However, the potential redundancy within these suffixes remains unexplored. In this work, we propose Mask-GCG, a plug-and-play method that employs learnable token masking to identify impactful tokens within the suffix. Our approach increases the update probability for tokens at high-impact positions while pruning those at low-impact positions. This pruning not only reduces redundancy but also decreases the size of the gradient space, thereby lowering computational overhead and shortening the time required to achieve successful attacks compared to GCG. We evaluate Mask-GCG by applying it to the original GCG and several improved variants. Experimental results show that most tokens in the suffix contribute significantly to attack success, and pruning a minority of low-impact tokens does not affect the loss values or compromise the attack success rate (ASR), thereby revealing token redundancy in LLM prompts. Our findings provide insights for developing efficient and interpretable LLMs from the perspective of jailbreak attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)è¶Šç‹±æ”»å‡»ä¸­Greedy Coordinate Gradient (GCG)åŠå…¶å˜ä½“ä½¿ç”¨å›ºå®šé•¿åº¦åç¼€å¯¼è‡´çš„å†—ä½™é—®é¢˜ï¼Œæå‡ºäº†Mask-GCGè¿™ä¸€å³æ’å³ç”¨çš„æ”¹è¿›æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¯å­¦ä¹ çš„token maskingæŠ€æœ¯è¯†åˆ«åç¼€ä¸­çš„å…³é”®tokenï¼Œé€šè¿‡æé«˜é«˜å½±å“ä½ç½®çš„æ›´æ–°æ¦‚ç‡å¹¶å‰ªè£ä½å½±å“tokenï¼Œæœ‰æ•ˆç¼©å°äº†æ¢¯åº¦ç©ºé—´å¹¶é™ä½äº†è®¡ç®—å¼€é”€ã€‚å®éªŒè¡¨æ˜ï¼ŒMask-GCGåœ¨ç¼©çŸ­æ”»å‡»è¾¾æˆæ—¶é—´çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¿æŒä¸åŸå§‹GCGç›¸å½“çš„æ”»å‡»æˆåŠŸç‡(ASR)å’ŒæŸå¤±å€¼ï¼Œè¯æ˜äº†å¯¹æŠ—æ€§åç¼€ä¸­å­˜åœ¨æ˜¾è‘—çš„tokenå†—ä½™ã€‚è¿™é¡¹å·¥ä½œæ­ç¤ºäº†LLMæç¤ºè¯çš„å†—ä½™ç‰¹æ€§ï¼Œä¸ºä»å®‰å…¨æ”»å‡»è§†è§’å¼€å‘æ›´é«˜æ•ˆã€å¯è§£é‡Šçš„LLMsæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06350v1",
      "published_date": "2025-09-08 05:45:37 UTC",
      "updated_date": "2025-09-08 05:45:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:22.175639+00:00"
    },
    {
      "arxiv_id": "2509.06346v2",
      "title": "Ban&Pick: Ehancing Performance and Efficiency of MoE-LLMs via Smarter Routing",
      "title_zh": "Ban&Pickï¼šé€šè¿‡æ™ºèƒ½è·¯ç”±æå‡ MoE-LLM çš„æ€§èƒ½ä¸æ•ˆç‡",
      "authors": [
        "Yuanteng Chen",
        "Peisong Wang",
        "Yuantian Shao",
        "Nanxin Zeng",
        "Chang Xu",
        "Jian Cheng"
      ],
      "abstract": "Sparse Mixture-of-Experts (MoE) has become a key architecture for scaling large language models (LLMs) efficiently. Recent fine-grained MoE designs introduce hundreds of experts per layer, with multiple experts activated per token, enabling stronger specialization. However, during pre-training, routers are optimized mainly for stability and robustness: they converge prematurely and enforce balanced usage, limiting the full potential of model performance and efficiency at inference. In this work, we uncover two overlooked issues: (i) a few highly influential experts are underutilized due to premature and balanced routing decisions; and (ii) enforcing a fixed number of active experts per token introduces substantial redundancy. Instead of retraining models or redesigning MoE architectures, we introduce Ban&Pick, a post-training, plug-and-play strategy for smarter routing. Pick discovers and reinforces key experts-a small group with outsized impact on performance-leading to notable accuracy gains across domains. Ban further dynamically prunes redundant experts based on layer and token sensitivity, delivering faster inference with minimal accuracy loss. Experiments on fine-grained MoE-LLMs (DeepSeek, Qwen3) across math, code, and general reasoning benchmarks demonstrate that Ban\\&Pick delivers free performance gains and inference acceleration without retraining or architectural changes. For instance, on Qwen3-30B-A3B, it improves accuracy from 80.67 to 84.66 on AIME2024 and from 65.66 to 68.18 on GPQA-Diamond, while accelerating inference by 1.25x under the vLLM.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¨€ç–æ··åˆä¸“å®¶æ¨¡å‹(Sparse Mixture-of-Experts, MoE)åœ¨æ¨ç†è¿‡ç¨‹ä¸­å› è·¯ç”±ç­–ç•¥æ”¶æ•›è¿‡æ—©å’Œè´Ÿè½½å‡è¡¡é™åˆ¶è€Œå¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆï¼Œæå‡ºäº†åä¸ºBan&Pickçš„è®­ç»ƒåã€å³æ’å³ç”¨(plug-and-play)ä¼˜åŒ–ç­–ç•¥ã€‚è¯¥ç­–ç•¥æ— éœ€é‡æ–°è®­ç»ƒæˆ–ä¿®æ”¹æ¨¡å‹æ¶æ„ï¼ŒåŒ…å«Pickå’ŒBanä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼Œæ—¨åœ¨é€šè¿‡æ›´æ™ºèƒ½çš„è·¯ç”±æå‡æ¨¡å‹è¡¨ç°ä¸æ•ˆç‡ã€‚Pickæ¨¡å—é€šè¿‡è¯†åˆ«å¹¶å¼ºåŒ–ä¸€å°ç»„å¯¹æ€§èƒ½æœ‰é‡å¤§å½±å“çš„å…³é”®ä¸“å®¶æ¥æ˜¾è‘—æé«˜å„é¢†åŸŸçš„å‡†ç¡®ç‡ï¼Œè€ŒBanæ¨¡å—åˆ™æ ¹æ®å±‚å’ŒTokençš„æ•æ„Ÿåº¦åŠ¨æ€å‰ªæå†—ä½™ä¸“å®¶ï¼Œåœ¨ä¿æŒç²¾åº¦çš„åŒæ—¶å®ç°æ¨ç†åŠ é€Ÿã€‚åœ¨DeepSeekå’ŒQwen3ç­‰ç»†ç²’åº¦MoEæ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBan&Pickåœ¨æ•°å­¦ã€ä»£ç å’Œé€šç”¨æ¨ç†ä»»åŠ¡ä¸­å‡å¸¦æ¥äº†æ˜¾è‘—çš„æ€§èƒ½å¢ç›Šã€‚ä¾‹å¦‚ï¼Œåœ¨Qwen3-30B-A3Bæ¨¡å‹ä¸Šï¼Œè¯¥ç­–ç•¥å°†AIME2024ä»»åŠ¡çš„å‡†ç¡®ç‡ä»80.67æå‡è‡³84.66ï¼Œå¹¶æˆåŠŸå®ç°äº†1.25å€çš„æ¨ç†åŠ é€Ÿã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06346v2",
      "published_date": "2025-09-08 05:38:10 UTC",
      "updated_date": "2025-09-30 10:29:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:23.065151+00:00"
    },
    {
      "arxiv_id": "2509.08007v2",
      "title": "Expert-Guided Explainable Few-Shot Learning for Medical Image Diagnosis",
      "title_zh": "é¢å‘åŒ»å­¦å›¾åƒè¯Šæ–­çš„ä¸“å®¶å¼•å¯¼å‹å¯è§£é‡Šå°æ ·æœ¬å­¦ä¹ ",
      "authors": [
        "Ifrat Ikhtear Uddin",
        "Longwei Wang",
        "KC Santosh"
      ],
      "abstract": "Medical image analysis often faces significant challenges due to limited expert-annotated data, hindering both model generalization and clinical adoption. We propose an expert-guided explainable few-shot learning framework that integrates radiologist-provided regions of interest (ROIs) into model training to simultaneously enhance classification performance and interpretability. Leveraging Grad-CAM for spatial attention supervision, we introduce an explanation loss based on Dice similarity to align model attention with diagnostically relevant regions during training. This explanation loss is jointly optimized with a standard prototypical network objective, encouraging the model to focus on clinically meaningful features even under limited data conditions. We evaluate our framework on two distinct datasets: BraTS (MRI) and VinDr-CXR (Chest X-ray), achieving significant accuracy improvements from 77.09% to 83.61% on BraTS and from 54.33% to 73.29% on VinDr-CXR compared to non-guided models. Grad-CAM visualizations further confirm that expert-guided training consistently aligns attention with diagnostic regions, improving both predictive reliability and clinical trustworthiness. Our findings demonstrate the effectiveness of incorporating expert-guided attention supervision to bridge the gap between performance and interpretability in few-shot medical image diagnosis.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä¸“å®¶æŒ‡å¯¼çš„å¯è§£é‡Šå°‘æ ·æœ¬å­¦ä¹ (Expert-guided explainable few-shot learning)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŒ»ç–—å›¾åƒåˆ†æä¸­ä¸“å®¶æ ‡æ³¨æ•°æ®æœ‰é™å¯¼è‡´çš„æ¨¡å‹æ³›åŒ–å’Œä¸´åºŠåº”ç”¨éš¾é¢˜ã€‚è¯¥æ¡†æ¶å°†æ”¾å°„ç§‘åŒ»ç”Ÿæä¾›çš„æ„Ÿå…´è¶£åŒºåŸŸ(ROIs)æ•´åˆåˆ°æ¨¡å‹è®­ç»ƒä¸­ï¼Œåˆ©ç”¨ Grad-CAM æŠ€æœ¯è¿›è¡Œç©ºé—´æ³¨æ„åŠ›ç›‘ç£ã€‚é€šè¿‡å¼•å…¥åŸºäº Dice ç›¸ä¼¼åº¦çš„è§£é‡ŠæŸå¤±(Explanation loss)ï¼Œè¯¥æ–¹æ³•å°†æ¨¡å‹çš„æ³¨æ„åŠ›ä¸è¯Šæ–­ç›¸å…³åŒºåŸŸå¯¹é½ï¼Œå¹¶ä¸æ ‡å‡†çš„åŸå‹ç½‘ç»œ(Prototypical network)ç›®æ ‡è¿›è¡Œè”åˆä¼˜åŒ–ã€‚å®éªŒåœ¨ BraTS(MRI)å’Œ VinDr-CXR(èƒ¸éƒ¨ X å°„çº¿)ä¸¤ä¸ªä¸åŒæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ¡†æ¶æ˜¾è‘—æå‡äº†åˆ†ç±»å‡†ç¡®ç‡ã€‚å…·ä½“è€Œè¨€ï¼ŒBraTS æ•°æ®é›†çš„å‡†ç¡®ç‡ä» 77.09% æå‡è‡³ 83.61%ï¼ŒVinDr-CXR çš„å‡†ç¡®ç‡åˆ™ä» 54.33% å¤§å¹…æé«˜åˆ° 73.29%ã€‚å¯è§†åŒ–ç»“æœè¯å®ï¼Œä¸“å®¶æŒ‡å¯¼è®­ç»ƒèƒ½ä½¿æ¨¡å‹æ³¨æ„åŠ›ä¸ä¸´åºŠè¯Šæ–­åŒºåŸŸä¿æŒä¸€è‡´ï¼Œå¢å¼ºäº†é¢„æµ‹çš„å¯é æ€§å’Œä¸´åºŠä¿¡ä»»åº¦ï¼Œä¸ºç¼©å°å°‘æ ·æœ¬åŒ»ç–—è¯Šæ–­çš„æ€§èƒ½ä¸å¯è§£é‡Šæ€§å·®è·æä¾›äº†æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted for publication in the proceedings of MICCAI Workshop on Data Engineering in Medical Imaging 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.08007v2",
      "published_date": "2025-09-08 05:31:37 UTC",
      "updated_date": "2025-09-11 16:30:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:28.501003+00:00"
    },
    {
      "arxiv_id": "2509.06341v1",
      "title": "Evaluating Multi-Turn Bargain Skills in LLM-Based Seller Agent",
      "title_zh": "è¯„ä¼°åŸºäº LLM çš„å–å®¶æ™ºèƒ½ä½“åœ¨å¤šè½®è®®ä»·ä¸­çš„æŠ€èƒ½",
      "authors": [
        "Issue Yishu Wang",
        "Kakam Chong",
        "Xiaofeng Wang",
        "Xu Yan",
        "DeXin Kong",
        "Chen Ju",
        "Ming Chen",
        "Shuai Xiao",
        "Shuguang Han",
        "jufeng chen"
      ],
      "abstract": "In online second-hand marketplaces, multi-turn bargaining is a crucial part of seller-buyer interactions. Large Language Models (LLMs) can act as seller agents, negotiating with buyers on behalf of sellers under given business constraints. A critical ability for such agents is to track and accurately interpret cumulative buyer intents across long negotiations, which directly impacts bargaining effectiveness. We introduce a multi-turn evaluation framework for measuring the bargaining ability of seller agents in e-commerce dialogues. The framework tests whether an agent can extract and track buyer intents. Our contributions are: (1) a large-scale e-commerce bargaining benchmark spanning 622 categories, 9,892 products, and 3,014 tasks; (2) a turn-level evaluation framework grounded in Theory of Mind (ToM) with annotated buyer intents, moving beyond outcome-only metrics; and (3) an automated pipeline that extracts reliable intent from massive dialogue data.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨åœ¨çº¿äºŒæ‰‹å¸‚åœºä¸­ï¼ŒåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„é”€å”®æ™ºèƒ½ä½“(seller agents)åœ¨å¤šè½®è®¨ä»·è¿˜ä»·ä¸­çš„äº¤äº’èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³æ™ºèƒ½ä½“åœ¨é•¿å¯¹è¯ä¸­å‡†ç¡®è¿½è¸ªå¹¶è§£è¯»ç´¯ç§¯ä¹°å®¶æ„å›¾(buyer intents)çš„æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªä¸“é—¨ç”¨äºè¡¡é‡ç”µå­å•†åŠ¡å¯¹è¯ä¸­é”€å”®æ™ºèƒ½ä½“è®®ä»·èƒ½åŠ›çš„å¤šè½®è¯„ä¼°æ¡†æ¶ã€‚è¯¥ç ”ç©¶çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬æ„å»ºäº†ä¸€ä¸ªæ¶µç›–622ä¸ªç±»åˆ«ã€9,892ä»¶äº§å“å’Œ3,014ä¸ªä»»åŠ¡çš„å¤§è§„æ¨¡ç”µå­å•†åŠ¡è®®ä»·åŸºå‡†ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªåŸºäºå¿ƒç†ç†è®º(Theory of Mind, ToM)ä¸”å¸¦æœ‰æ ‡æ³¨ä¹°å®¶æ„å›¾çš„è½®æ¬¡çº§è¯„ä¼°æ¡†æ¶ï¼Œè¶…è¶Šäº†å•çº¯çš„ç»“æœå¯¼å‘æŒ‡æ ‡ã€‚è¯¥ç ”ç©¶è¿˜é€šè¿‡ä¸€å¥—è‡ªåŠ¨åŒ–æµæ°´çº¿ä»æµ·é‡å¯¹è¯æ•°æ®ä¸­æå–å¯é æ„å›¾ï¼Œä¸ºè¯„ä¼°å’Œä¼˜åŒ–æ™ºèƒ½ä½“çš„å¤šè½®è®¨ä»·è¿˜ä»·æŠ€èƒ½æä¾›äº†ç³»ç»ŸåŒ–çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06341v1",
      "published_date": "2025-09-08 05:12:03 UTC",
      "updated_date": "2025-09-08 05:12:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:43.976678+00:00"
    },
    {
      "arxiv_id": "2509.06337v1",
      "title": "Large Language Models as Virtual Survey Respondents: Evaluating Sociodemographic Response Generation",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºè™šæ‹Ÿè°ƒæŸ¥å—è®¿è€…ï¼šç¤¾ä¼šäººå£ç»Ÿè®¡å­¦å›ç­”ç”Ÿæˆçš„è¯„ä¼°",
      "authors": [
        "Jianpeng Zhao",
        "Chenyu Yuan",
        "Weiming Luo",
        "Haoling Xie",
        "Guangwei Zhang",
        "Steven Jige Quan",
        "Zixuan Yuan",
        "Pengyang Wang",
        "Denghui Zhang"
      ],
      "abstract": "Questionnaire-based surveys are foundational to social science research and public policymaking, yet traditional survey methods remain costly, time-consuming, and often limited in scale. This paper explores a new paradigm: simulating virtual survey respondents using Large Language Models (LLMs). We introduce two novel simulation settings, namely Partial Attribute Simulation (PAS) and Full Attribute Simulation (FAS), to systematically evaluate the ability of LLMs to generate accurate and demographically coherent responses. In PAS, the model predicts missing attributes based on partial respondent profiles, whereas FAS involves generating complete synthetic datasets under both zero-context and context-enhanced conditions. We curate a comprehensive benchmark suite, LLM-S^3 (Large Language Model-based Sociodemographic Survey Simulation), that spans 11 real-world public datasets across four sociological domains. Our evaluation of multiple mainstream LLMs (GPT-3.5/4 Turbo, LLaMA 3.0/3.1-8B) reveals consistent trends in prediction performance, highlights failure modes, and demonstrates how context and prompt design impact simulation fidelity. This work establishes a rigorous foundation for LLM-driven survey simulations, offering scalable and cost-effective tools for sociological research and policy evaluation. Our code and dataset are available at: https://github.com/dart-lab-research/LLM-S-Cube-Benchmark",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢ç´¢äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨¡æ‹Ÿè™šæ‹Ÿè°ƒæŸ¥å—è®¿è€…çš„æ–°èŒƒå¼ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿé—®å·è°ƒæŸ¥æˆæœ¬é«˜ä¸”éš¾ä»¥å¤§è§„æ¨¡å¼€å±•çš„é—®é¢˜ã€‚ä½œè€…æå‡ºäº†éƒ¨åˆ†å±æ€§æ¨¡æ‹Ÿ(PAS)å’Œå…¨å±æ€§æ¨¡æ‹Ÿ(FAS)ä¸¤ç§è®¾ç½®ï¼Œç”¨ä»¥ç³»ç»Ÿè¯„ä¼°æ¨¡å‹ç”Ÿæˆå‡†ç¡®ä¸”äººå£ç»Ÿè®¡å­¦ç‰¹å¾ä¸€è‡´çš„å“åº”èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œè¯¥ç ”ç©¶æ„å»ºäº†åä¸ºLLM-S^3çš„åŸºå‡†æµ‹è¯•å¥—ä»¶ï¼Œæ¶µç›–äº†å››ä¸ªç¤¾ä¼šå­¦é¢†åŸŸçš„11ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ã€‚é€šè¿‡å¯¹GPT-3.5/4 Turboå’ŒLLaMA 3.0/3.1-8Bç­‰ä¸»æµæ¨¡å‹çš„è¯„ä¼°ï¼Œç ”ç©¶æ­ç¤ºäº†é¢„æµ‹æ€§èƒ½çš„ä¸€è‡´è¶‹åŠ¿å’Œå¤±æ•ˆæ¨¡å¼ï¼Œå¹¶è¯æ˜äº†ä¸Šä¸‹æ–‡ä¸æç¤ºè¯è®¾è®¡å¯¹æ¨¡æ‹Ÿä¿çœŸåº¦çš„æ˜¾è‘—å½±å“ã€‚è¯¥å·¥ä½œä¸ºLLMé©±åŠ¨çš„è°ƒæŸ¥æ¨¡æ‹Ÿå¥ å®šäº†ä¸¥è°¨åŸºç¡€ï¼Œä¸ºç¤¾ä¼šå­¦ç ”ç©¶å’Œæ”¿ç­–è¯„ä¼°æä¾›äº†å¯æ‰©å±•ä¸”ä½æˆæœ¬çš„å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06337v1",
      "published_date": "2025-09-08 04:59:00 UTC",
      "updated_date": "2025-09-08 04:59:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:19:58.678250+00:00"
    },
    {
      "arxiv_id": "2509.06336v2",
      "title": "Multi-View Slot Attention Using Paraphrased Texts for Face Anti-Spoofing",
      "title_zh": "åŸºäºæ”¹å†™æ–‡æœ¬çš„äººè„¸é˜²ä¼ªå¤šè§†å›¾æ§½ä½æ³¨æ„åŠ›",
      "authors": [
        "Jeongmin Yu",
        "Susang Kim",
        "Kisu Lee",
        "Taekyoung Kwon",
        "Won-Yong Shin",
        "Ha Young Kim"
      ],
      "abstract": "Recent face anti-spoofing (FAS) methods have shown remarkable cross-domain performance by employing vision-language models like CLIP. However, existing CLIP-based FAS models do not fully exploit CLIP's patch embedding tokens, failing to detect critical spoofing clues. Moreover, these models rely on a single text prompt per class (e.g., 'live' or 'fake'), which limits generalization. To address these issues, we propose MVP-FAS, a novel framework incorporating two key modules: Multi-View Slot attention (MVS) and Multi-Text Patch Alignment (MTPA). Both modules utilize multiple paraphrased texts to generate generalized features and reduce dependence on domain-specific text. MVS extracts local detailed spatial features and global context from patch embeddings by leveraging diverse texts with multiple perspectives. MTPA aligns patches with multiple text representations to improve semantic robustness. Extensive experiments demonstrate that MVP-FAS achieves superior generalization performance, outperforming previous state-of-the-art methods on cross-domain datasets. Code: https://github.com/Elune001/MVP-FAS.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºCLIPçš„äººè„¸é˜²æ¬ºè¯ˆ(Face Anti-Spoofing, FAS)æ–¹æ³•åœ¨è¡¥ä¸åµŒå…¥(patch embedding)åˆ©ç”¨ä¸è¶³ä»¥åŠå•ä¸€æ–‡æœ¬æç¤ºå¯¼è‡´æ³›åŒ–æ€§å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºMVP-FASçš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†å¤šè§†å›¾æ§½æ³¨æ„åŠ›(Multi-View Slot attention, MVS)å’Œå¤šæ–‡æœ¬è¡¥ä¸å¯¹é½(Multi-Text Patch Alignment, MTPA)ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ã€‚è¿™ä¸¤ä¸ªæ¨¡å—å‡åˆ©ç”¨å¤šç»„åŒä¹‰è½¬è¿°æ–‡æœ¬(paraphrased texts)æ¥ç”Ÿæˆé€šç”¨åŒ–ç‰¹å¾ï¼Œæ—¨åœ¨å‡å°‘æ¨¡å‹å¯¹ç‰¹å®šé¢†åŸŸæ–‡æœ¬çš„ä¾èµ–ã€‚å…¶ä¸­MVSé€šè¿‡å¤šè§†è§’æ–‡æœ¬ä»è¡¥ä¸åµŒå…¥ä¸­æå–å±€éƒ¨ç»†èŠ‚ç©ºé—´ç‰¹å¾å’Œå…¨å±€ä¸Šä¸‹æ–‡ï¼Œè€ŒMTPAåˆ™é€šè¿‡å¤šæ–‡æœ¬è¡¨ç¤ºçš„å¯¹é½æ¥æå‡è¯­ä¹‰é²æ£’æ€§ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒMVP-FASåœ¨è·¨åŸŸæ•°æ®é›†ä¸Šå±•ç°å‡ºå“è¶Šçš„æ³›åŒ–æ€§èƒ½ï¼Œå…¶è¡¨ç°è¶…è¶Šäº†ç°æœ‰çš„å…ˆè¿›(state-of-the-art)æ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.06336v2",
      "published_date": "2025-09-08 04:53:46 UTC",
      "updated_date": "2025-09-15 05:55:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:01.873548+00:00"
    },
    {
      "arxiv_id": "2509.07036v2",
      "title": "Methodological Insights into Structural Causal Modelling and Uncertainty-Aware Forecasting for Economic Indicators",
      "title_zh": "ç»æµæŒ‡æ ‡ç»“æ„å› æœå»ºæ¨¡ä¸ä¸ç¡®å®šæ€§æ„ŸçŸ¥é¢„æµ‹çš„æ–¹æ³•è®ºæ¢æ",
      "authors": [
        "Federico Cerutti"
      ],
      "abstract": "This paper presents a methodological approach to financial time series analysis by combining causal discovery and uncertainty-aware forecasting. As a case study, we focus on four key U.S. macroeconomic indicators -- GDP, economic growth, inflation, and unemployment -- and we apply the LPCMCI framework with Gaussian Process Distance Correlation (GPDC) to uncover dynamic causal relationships in quarterly data from 1970 to 2021. Our results reveal a robust unidirectional causal link from economic growth to GDP and highlight the limited connectivity of inflation, suggesting the influence of latent factors. Unemployment exhibits strong autoregressive dependence, motivating its use as a case study for probabilistic forecasting. Leveraging the Chronos framework, a large language model trained for time series, we perform zero-shot predictions on unemployment. This approach delivers accurate forecasts one and two quarters ahead, without requiring task-specific training. Crucially, the model's uncertainty-aware predictions yield 90\\% confidence intervals, enabling effective anomaly detection through statistically principled deviation analysis. This study demonstrates the value of combining causal structure learning with probabilistic language models to inform economic policy and enhance forecasting robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆå› æœå‘ç°(causal discovery)ä¸ä¸ç¡®å®šæ€§æ„ŸçŸ¥é¢„æµ‹(uncertainty-aware forecasting)çš„æ–¹æ³•è®ºæ¡†æ¶ï¼Œç”¨äºåˆ†æé‡‘èæ—¶é—´åºåˆ—ã€‚ç ”ç©¶ä»¥ç¾å›½å››ä¸ªæ ¸å¿ƒå®è§‚ç»æµæŒ‡æ ‡ä¸ºæ¡ˆä¾‹ï¼Œé€šè¿‡LPCMCIæ¡†æ¶ç»“åˆé«˜æ–¯è¿‡ç¨‹è·ç¦»ç›¸å…³(GPDC)æ­ç¤ºäº†1970è‡³2021å¹´é—´çš„åŠ¨æ€å› æœå…³ç³»ï¼Œå‘ç°ç»æµå¢é•¿å¯¹GDPå­˜åœ¨æ˜¾è‘—çš„å•å‘å› æœè”ç³»ã€‚é’ˆå¯¹å…·æœ‰å¼ºè‡ªå›å½’ç‰¹æ€§çš„å¤±ä¸šç‡æŒ‡æ ‡ï¼Œç ”ç©¶å¼•å…¥äº†Chronosæ¡†æ¶ï¼Œåˆ©ç”¨é’ˆå¯¹æ—¶é—´åºåˆ—è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹(LLM)è¿›è¡Œé›¶æ ·æœ¬é¢„æµ‹(zero-shot predictions)ã€‚è¯¥æ–¹æ³•åœ¨æ— éœ€ç‰¹å®šä»»åŠ¡è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°äº†å‡†ç¡®çš„çŸ­æœŸé¢„æµ‹ï¼Œå¹¶é€šè¿‡90%ç½®ä¿¡åŒºé—´(confidence intervals)æä¾›äº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥ï¼Œä»è€Œå®ç°äº†æœ‰æ•ˆçš„å¼‚å¸¸æ£€æµ‹ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†å°†å› æœç»“æ„å­¦ä¹ ä¸æ¦‚ç‡è¯­è¨€æ¨¡å‹ç›¸ç»“åˆåœ¨å¢å¼ºç»æµæ”¿ç­–åˆ¶å®šç¨³å¥æ€§å’Œé¢„æµ‹ç²¾åº¦æ–¹é¢çš„æ˜¾è‘—ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 2nd edition of the Workshop in AI and Finance at ECAI-2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07036v2",
      "published_date": "2025-09-08 04:52:12 UTC",
      "updated_date": "2025-10-24 04:25:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:03.659368+00:00"
    },
    {
      "arxiv_id": "2509.06332v1",
      "title": "A Fragile Number Sense: Probing the Elemental Limits of Numerical Reasoning in LLMs",
      "title_zh": "è„†å¼±çš„æ•°æ„Ÿï¼šæ¢ç©¶å¤§è¯­è¨€æ¨¡å‹æ•°å€¼æ¨ç†çš„åº•å±‚å±€é™",
      "authors": [
        "Roussel Rahman",
        "Aashwin Ananda Mishra"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable emergent capabilities, yet the robustness of their numerical reasoning remains an open question. While standard benchmarks evaluate LLM reasoning on complex problem sets using aggregated metrics, they often obscure foundational weaknesses. In this work, we probe LLM mathematical numeracy by evaluating performance on problems of escalating complexity, from constituent operations to combinatorial puzzles. We test several state-of-the-art LLM-based agents on a 100-problem challenge comprising four categories: (1) basic arithmetic, (2) advanced operations, (3) primality checking, and (4) the Game of 24 number puzzle. Our results show that while the agents achieved high accuracy on the first three categories, which require deterministic algorithmic execution, they consistently failed at the number puzzle, underlining its demand for a heuristic search over a large combinatorial space to be a significant bottleneck. These findings reveal that the agents' proficiency is largely confined to recalling and executing known algorithms, rather than performing generative problem-solving. This suggests their apparent numerical reasoning is more akin to sophisticated pattern-matching than flexible, analytical thought, limiting their potential for tasks that require novel or creative numerical insights.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸åŒå¤æ‚ç¨‹åº¦é—®é¢˜ä¸Šçš„è¡¨ç°ï¼Œæ¢ç©¶äº†å…¶æ•°å€¼æ¨ç†(numerical reasoning)çš„ç¨³å¥æ€§åŠå…¶åŸºç¡€æ€§å¼±ç‚¹ã€‚ç ”ç©¶äººå‘˜æµ‹è¯•äº†å¤šç§æœ€å…ˆè¿›çš„åŸºäºLLMçš„æ™ºèƒ½ä½“ï¼Œæ¶µç›–äº†åŸºç¡€ç®—æœ¯(basic arithmetic)ã€é«˜çº§è¿ç®—(advanced operations)ã€è´¨æ•°æ£€æµ‹(primality checking)å’Œâ€œ24ç‚¹â€æ•°å­—ç›Šæ™ºæ¸¸æˆ(Game of 24)å››ç±»æŒ‘æˆ˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶æ™ºèƒ½ä½“åœ¨éœ€è¦ç¡®å®šæ€§ç®—æ³•æ‰§è¡Œ(deterministic algorithmic execution)çš„å‰ä¸‰ç±»ä»»åŠ¡ä¸­è¡¨ç°å‡ºé«˜å‡†ç¡®ç‡ï¼Œä½†åœ¨éœ€è¦å¤§è§„æ¨¡ç»„åˆç©ºé—´å¯å‘å¼æœç´¢(heuristic search over a large combinatorial space)çš„â€œ24ç‚¹â€æ¸¸æˆä¸­å´æ™®éå¤±è´¥ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†æ™ºèƒ½ä½“çš„ç†Ÿç»ƒç¨‹åº¦ä¸»è¦å±€é™äºå¬å›å’Œæ‰§è¡Œå·²çŸ¥ç®—æ³•ï¼Œè€Œéè¿›è¡ŒçœŸæ­£çš„ç”Ÿæˆå¼é—®é¢˜è§£å†³(generative problem-solving)ã€‚ç ”ç©¶æœ€ç»ˆæŒ‡å‡ºï¼ŒLLMç°æœ‰çš„æ•°å€¼æ¨ç†æ›´æ¥è¿‘äºå¤æ‚çš„æ¨¡å¼åŒ¹é…(pattern-matching)è€Œéçµæ´»çš„åˆ†ææ€ç»´ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å¤„ç†éœ€è¦åˆ›æ–°æˆ–åˆ›é€ æ€§æ•°å€¼æ´å¯Ÿä»»åŠ¡æ—¶çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06332v1",
      "published_date": "2025-09-08 04:31:12 UTC",
      "updated_date": "2025-09-08 04:31:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:05.866062+00:00"
    },
    {
      "arxiv_id": "2509.06326v1",
      "title": "AttestLLM: Efficient Attestation Framework for Billion-scale On-device LLMs",
      "title_zh": "AttestLLMï¼šé¢å‘åäº¿çº§ç«¯ä¾§å¤§è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆéªŒè¯æ¡†æ¶",
      "authors": [
        "Ruisi Zhang",
        "Yifei Zhao",
        "Neusha Javidnia",
        "Mengxin Zheng",
        "Farinaz Koushanfar"
      ],
      "abstract": "As on-device LLMs(e.g., Apple on-device Intelligence) are widely adopted to reduce network dependency, improve privacy, and enhance responsiveness, verifying the legitimacy of models running on local devices becomes critical. Existing attestation techniques are not suitable for billion-parameter Large Language Models (LLMs), struggling to remain both time- and memory-efficient while addressing emerging threats in the LLM era. In this paper, we present AttestLLM, the first-of-its-kind attestation framework to protect the hardware-level intellectual property (IP) of device vendors by ensuring that only authorized LLMs can execute on target platforms. AttestLLM leverages an algorithm/software/hardware co-design approach to embed robust watermarking signatures onto the activation distributions of LLM building blocks. It also optimizes the attestation protocol within the Trusted Execution Environment (TEE), providing efficient verification without compromising inference throughput. Extensive proof-of-concept evaluations on LLMs from Llama, Qwen, and Phi families for on-device use cases demonstrate AttestLLM's attestation reliability, fidelity, and efficiency. Furthermore, AttestLLM enforces model legitimacy and exhibits resilience against model replacement and forgery attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç«¯ä¾§å¤§æ¨¡å‹(on-device LLMs)çš„åˆæ³•æ€§éªŒè¯éš¾é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªæ—¨åœ¨ä¿æŠ¤ç¡¬ä»¶çº§çŸ¥è¯†äº§æƒ(IP)çš„é«˜æ•ˆè¯æ˜æ¡†æ¶AttestLLMã€‚è¯¥æ¡†æ¶é‡‡ç”¨ç®—æ³•ã€è½¯ä»¶ä¸ç¡¬ä»¶ååŒè®¾è®¡çš„æ–¹æ³•ï¼Œå°†é²æ£’çš„æ°´å°ç­¾ååµŒå…¥åˆ°LLMæ„å»ºå—çš„æ¿€æ´»åˆ†å¸ƒ(activation distributions)ä¸­ï¼Œä»¥ç¡®ä¿åªæœ‰æˆæƒæ¨¡å‹èƒ½åœ¨ç›®æ ‡å¹³å°ä¸Šè¿è¡Œã€‚é€šè¿‡åœ¨å¯ä¿¡æ‰§è¡Œç¯å¢ƒ(TEE)å†…ä¼˜åŒ–è¯æ˜åè®®ï¼ŒAttestLLMåœ¨å®ç°é«˜æ•ˆéªŒè¯çš„åŒæ—¶ï¼Œæœ‰æ•ˆé¿å…äº†å¯¹æ¨ç†ååé‡çš„å½±å“ã€‚åœ¨Llamaã€Qwenå’ŒPhiç­‰ç³»åˆ—æ¨¡å‹ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¡†æ¶å…·æœ‰æé«˜çš„è¯æ˜å¯é æ€§ã€ä¿çœŸåº¦ä¸è¿è¡Œæ•ˆç‡ã€‚æ­¤å¤–ï¼ŒAttestLLMå±•ç°å‡ºå¼ºåŠ²çš„æŠ—æ¨¡å‹æ›¿æ¢åŠä¼ªé€ æ”»å‡»èƒ½åŠ›ï¼Œä¸ºç«¯ä¾§æ™ºèƒ½æ—¶ä»£çš„æ¨¡å‹å®‰å…¨æä¾›äº†åšå®ä¿éšœã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06326v1",
      "published_date": "2025-09-08 04:17:02 UTC",
      "updated_date": "2025-09-08 04:17:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:12.773160+00:00"
    },
    {
      "arxiv_id": "2509.06307v1",
      "title": "Can AI Make Energy Retrofit Decisions? An Evaluation of Large Language Models",
      "title_zh": "AI èƒ½å¦åˆ¶å®šèƒ½æºæ”¹é€ å†³ç­–ï¼Ÿå¤§è¯­è¨€æ¨¡å‹è¯„ä¼°",
      "authors": [
        "Lei Shu",
        "Dong Zhao"
      ],
      "abstract": "Conventional approaches to building energy retrofit decision making suffer from limited generalizability and low interpretability, hindering adoption in diverse residential contexts. With the growth of Smart and Connected Communities, generative AI, especially large language models (LLMs), may help by processing contextual information and producing practitioner readable recommendations. We evaluate seven LLMs (ChatGPT, DeepSeek, Gemini, Grok, Llama, and Claude) on residential retrofit decisions under two objectives: maximizing CO2 reduction (technical) and minimizing payback period (sociotechnical). Performance is assessed on four dimensions: accuracy, consistency, sensitivity, and reasoning, using a dataset of 400 homes across 49 US states. LLMs generate effective recommendations in many cases, reaching up to 54.5 percent top 1 match and 92.8 percent within top 5 without fine tuning. Performance is stronger for the technical objective, while sociotechnical decisions are limited by economic trade offs and local context. Agreement across models is low, and higher performing models tend to diverge from others. LLMs are sensitive to location and building geometry but less sensitive to technology and occupant behavior. Most models show step by step, engineering style reasoning, but it is often simplified and lacks deeper contextual awareness. Overall, LLMs are promising assistants for energy retrofit decision making, but improvements in accuracy, consistency, and context handling are needed for reliable practice.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åŒ…æ‹¬ ChatGPTã€DeepSeekã€Geminiã€Grokã€Llama å’Œ Claude åœ¨å†…çš„ä¸ƒç§å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ä½å®…èƒ½æºæ”¹é€  (Energy Retrofit) å†³ç­–ä¸­çš„è¡¨ç°ã€‚è¯„ä¼°æ¶µç›–äº†ä»¥æœ€å¤§åŒ–äºŒæ°§åŒ–ç¢³å‡æ’ (CO2 reduction) ä¸ºæŠ€æœ¯ç›®æ ‡å’Œä»¥æœ€å°åŒ–æŠ•èµ„å›æ”¶æœŸ (Payback period) ä¸ºç¤¾ä¼šæŠ€æœ¯ç›®æ ‡çš„ä¸¤ç§å†³ç­–åœºæ™¯ã€‚åœ¨å¯¹ç¾å›½ 49 ä¸ªå· 400 æˆ·å®¶åº­çš„æµ‹è¯•æ•°æ®ä¸­ï¼Œæœªç»å¾®è°ƒçš„æ¨¡å‹åœ¨ Top-1 åŒ¹é…å‡†ç¡®ç‡ä¸Šè¾¾åˆ°äº† 54.5%ï¼ŒTop-5 å‡†ç¡®ç‡é«˜è¾¾ 92.8%ã€‚ç ”ç©¶å‘ç°æ¨¡å‹åœ¨å¤„ç†æŠ€æœ¯æ€§ç›®æ ‡æ—¶è¡¨ç°æ›´ä½³ï¼Œä½†åœ¨æ¶‰åŠç»æµæƒè¡¡çš„ç¤¾ä¼šæŠ€æœ¯å†³ç­–ä¸­è¡¨ç°å—é™ã€‚è™½ç„¶ LLMs å¯¹åœ°ç†ä½ç½®å’Œå»ºç­‘å‡ ä½•å½¢çŠ¶è¡¨ç°å‡ºä¸€å®šçš„æ•æ„Ÿæ€§ï¼Œä½†åœ¨æŠ€æœ¯ç»†èŠ‚å’Œå±…ä½è€…è¡Œä¸ºæ–¹é¢çš„æ•æ„Ÿåº¦è¾ƒä½ï¼Œä¸”æ¨ç†è¿‡ç¨‹å¾€å¾€å‘ˆç°ç®€åŒ–çš„å·¥ç¨‹é£æ ¼ï¼Œç¼ºä¹æ·±åº¦èƒŒæ™¯æ„ŸçŸ¥ã€‚æ€»ä½“è€Œè¨€ï¼ŒLLMs åœ¨èƒ½æºæ”¹é€ å†³ç­–é¢†åŸŸå±•ç°å‡ºä½œä¸ºæ™ºèƒ½åŠ©æ‰‹çš„å‘å±•æ½œåŠ›ï¼Œä½†å…¶å‡†ç¡®æ€§ã€ä¸€è‡´æ€§å’Œå¤æ‚èƒŒæ™¯å¤„ç†èƒ½åŠ›ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06307v1",
      "published_date": "2025-09-08 03:13:47 UTC",
      "updated_date": "2025-09-08 03:13:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:21.570715+00:00"
    },
    {
      "arxiv_id": "2509.06296v1",
      "title": "Learning to Walk with Less: a Dyna-Style Approach to Quadrupedal Locomotion",
      "title_zh": "ä»¥å°‘å­¦è¡Œï¼šä¸€ç§ç”¨äºå››è¶³è¿åŠ¨çš„ Dyna å¼æ–¹æ³•",
      "authors": [
        "Francisco Affonso",
        "Felipe Andrade G. Tommaselli",
        "Juliano Negri",
        "Vivian S. Medeiros",
        "Mateus V. Gasparino",
        "Girish Chowdhary",
        "Marcelo Becker"
      ],
      "abstract": "Traditional RL-based locomotion controllers often suffer from low data efficiency, requiring extensive interaction to achieve robust performance. We present a model-based reinforcement learning (MBRL) framework that improves sample efficiency for quadrupedal locomotion by appending synthetic data to the end of standard rollouts in PPO-based controllers, following the Dyna-Style paradigm. A predictive model, trained alongside the policy, generates short-horizon synthetic transitions that are gradually integrated using a scheduling strategy based on the policy update iterations. Through an ablation study, we identified a strong correlation between sample efficiency and rollout length, which guided the design of our experiments. We validated our approach in simulation on the Unitree Go1 robot and showed that replacing part of the simulated steps with synthetic ones not only mimics extended rollouts but also improves policy return and reduces variance. Finally, we demonstrate that this improvement transfers to the ability to track a wide range of locomotion commands using fewer simulated steps.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºDyna-StyleèŒƒå¼çš„æ¨¡å‹å¼ºåŒ–å­¦ä¹ (MBRL)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå››è¶³æœºå™¨äººè¿åŠ¨æ§åˆ¶ä¸­æ•°æ®æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨åŸºäºPPOçš„æ§åˆ¶å™¨æ ‡å‡†éƒ¨ç½²(rollouts)æœ«å°¾é™„åŠ ç”±é¢„æµ‹æ¨¡å‹ç”Ÿæˆçš„çŸ­æ—¶åŸŸ(short-horizon)åˆæˆæ•°æ®(synthetic data)ï¼Œå¹¶ç»“åˆè°ƒåº¦ç­–ç•¥(scheduling strategy)å°†å…¶é€æ­¥æ•´åˆåˆ°è®­ç»ƒä¸­ã€‚é€šè¿‡å¯¹é‡‡æ ·æ•ˆç‡ä¸éƒ¨ç½²é•¿åº¦ç›¸å…³æ€§çš„æ·±å…¥åˆ†æï¼Œç ”ç©¶åœ¨Unitree Go1æœºå™¨äººçš„ä»¿çœŸç¯å¢ƒä¸‹éªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨åˆæˆæ­¥æ•°æ›¿ä»£éƒ¨åˆ†æ¨¡æ‹Ÿæ­¥æ•°ä¸ä»…æå‡äº†ç­–ç•¥å›æŠ¥(policy return)å¹¶é™ä½äº†æ–¹å·®ï¼Œè¿˜æ˜¾è‘—å‡å°‘äº†å®ç°ç¨³å¥è¿åŠ¨æ§åˆ¶æ‰€éœ€çš„æ¨¡æ‹Ÿäº¤äº’æ€»é‡ã€‚è¯¥æ–¹æ³•æœ€ç»ˆè¯æ˜äº†åœ¨æ›´å°‘æ¨¡æ‹Ÿæ­¥æ•°ä¸‹è¿½è¸ªå¹¿æ³›è¿åŠ¨æŒ‡ä»¤çš„å‡ºè‰²èƒ½åŠ›ï¼Œä¸ºæé«˜å››è¶³æœºå™¨äººè¿åŠ¨å­¦ä¹ çš„é‡‡æ ·æ•ˆç‡æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Under review at IEEE Robotics and Automation Letters. 8 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.06296v1",
      "published_date": "2025-09-08 02:48:23 UTC",
      "updated_date": "2025-09-08 02:48:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:40.669577+00:00"
    },
    {
      "arxiv_id": "2509.09712v2",
      "title": "The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization",
      "title_zh": "Thinking Therapistï¼šåˆ©ç”¨ç›‘ç£å¾®è°ƒä¸ä¼˜åŠ¿æ¯”ç­–ç•¥ä¼˜åŒ–è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹å¼€å±•æ¥çº³æ‰¿è¯ºç–—æ³•",
      "authors": [
        "Talha Tahir"
      ],
      "abstract": "Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral therapy with emerging evidence of efficacy in several psychiatric conditions. This study investigates the impact of post-training methodology and explicit reasoning on the ability of a small open-weight large language model (LLM) to deliver ACT. Using synthetic ACT transcripts generated by Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches, supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each with and without an explicit chain-of-thought (COT) reasoning step. Performance was evaluated by comparing these four post-trained variants against the base Instruct model. These models were benchmarked in simulated therapy sessions, with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM) and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned on human evaluations. Our findings demonstrate that the ORPO-trained models significantly outperformed both their SFT and Instruct counterparts on ACT fidelity ($Ï‡^2(5) = 185.15, p < .001$) and therapeutic empathy ($Ï‡^2(5) = 140.37, p < .001$). The effect of COT was conditional as it provided a significant benefit to SFT models, improving ACT-FM scores by an average of 2.68 points ($p < .001$), while offering no discernible advantage to the superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO stems from its ability to learn the therapeutic `process' over imitating `content,' a key aspect of ACT, while COT acts as a necessary scaffold for models trained only via imitation. This study establishes that preference-aligned policy optimization can effectively instill ACT competencies in small LLMs, and that the utility of explicit reasoning is highly dependent on the underlying training paradigm.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡ç›‘ç£å¾®è°ƒ(SFT)å’Œèƒœç®—æ¯”ç­–ç•¥ä¼˜åŒ–(ORPO)è®­ç»ƒå°å‹å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶å…·å¤‡æä¾›æ¥çº³ä¸æ‰¿è¯ºç–—æ³•(Acceptance and Commitment Therapy, ACT)çš„èƒ½åŠ›ã€‚ç ”ç©¶è€…åˆ©ç”¨åˆæˆçš„ACTå¯¹è¯æ•°æ®å¯¹Llama-3.2-3b-Instructè¿›è¡Œäº†è®­ç»ƒï¼Œå¹¶å¯¹æ¯”äº†åŒ…å«ä¸ä¸åŒ…å«æ˜¾å¼é“¾å¼æ€ç»´(Chain-of-Thought, CoT)æ¨ç†æ­¥éª¤çš„å¤šç§æ–¹æ¡ˆã€‚é€šè¿‡æ¨¡æ‹Ÿæ²»ç–—ä¼šè¯åŠACTå¿ è¯šåº¦é‡è¡¨(ACT-FM)å’Œæ²»ç–—å¸ˆå…±æƒ…é‡è¡¨(TES)çš„è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºORPOè®­ç»ƒçš„æ¨¡å‹åœ¨æ²»ç–—å¿ è¯šåº¦å’Œå…±æƒ…è¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºSFTå’ŒåŸºçº¿æ¨¡å‹ã€‚ç ”ç©¶å‘ç°CoTå¯¹SFTæ¨¡å‹æœ‰æ˜¾è‘—æå‡ä½œç”¨ï¼Œä½†å¯¹è¡¨ç°æ›´ä½³çš„ORPOæ¨¡å‹å¢ç›Šæœ‰é™ã€‚è¿™è¡¨æ˜ORPOèƒ½è®©æ¨¡å‹æ›´æœ‰æ•ˆåœ°å­¦ä¹ æ²»ç–—çš„â€œè¿‡ç¨‹â€è€Œéå•çº¯æ¨¡ä»¿â€œå†…å®¹â€ï¼Œè¯æ˜äº†åå¥½å¯¹é½ç­–ç•¥ä¼˜åŒ–åœ¨èµ‹äºˆå°å‹æ¨¡å‹ä¸“ä¸šå¿ƒç†æ²»ç–—èƒ½åŠ›æ–¹é¢çš„æ½œåŠ›ã€‚è¯¥ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº†æ˜¾å¼æ¨ç†çš„æ•ˆç”¨é«˜åº¦ä¾èµ–äºæ¨¡å‹åº•å±‚çš„è®­ç»ƒèŒƒå¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09712v2",
      "published_date": "2025-09-08 02:30:12 UTC",
      "updated_date": "2025-09-20 21:31:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:28.970440+00:00"
    },
    {
      "arxiv_id": "2509.06287v2",
      "title": "Statistical Inference for Misspecified Contextual Bandits",
      "title_zh": "æ¨¡å‹è¯¯è®¾ä¸‹çš„ä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœºç»Ÿè®¡æ¨æ–­",
      "authors": [
        "Yongyi Guo",
        "Ziping Xu"
      ],
      "abstract": "Contextual bandit algorithms have transformed modern experimentation by enabling real-time adaptation for personalized treatment and efficient use of data. Yet these advantages create challenges for statistical inference due to adaptivity. A fundamental property that supports valid inference is policy convergence, meaning that action-selection probabilities converge in probability given the context. Convergence ensures replicability of adaptive experiments and stability of online algorithms. In this paper, we highlight a previously overlooked issue: widely used algorithms such as LinUCB may fail to converge when the reward model is misspecified, and such non-convergence creates fundamental obstacles for statistical inference. This issue is practically important, as misspecified models -- such as linear approximations of complex dynamic system -- are often employed in real-world adaptive experiments to balance bias and variance.\n  Motivated by this insight, we propose and analyze a broad class of algorithms that are guaranteed to converge even under model misspecification. Building on this guarantee, we develop a general inference framework based on an inverse-probability-weighted Z-estimator (IPW-Z) and establish its asymptotic normality with a consistent variance estimator. Simulation studies confirm that the proposed method provides robust and data-efficient confidence intervals, and can outperform existing approaches that exist only in the special case of offline policy evaluation. Taken together, our results underscore the importance of designing adaptive algorithms with built-in convergence guarantees to enable stable experimentation and valid statistical inference in practice.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Contextual Bandit åœ¨å¥–åŠ±æ¨¡å‹ Misspecified æƒ…å†µä¸‹çš„ç»Ÿè®¡æ¨æ–­æŒ‘æˆ˜ï¼ŒæŒ‡å‡º Policy Convergence æ˜¯ç¡®ä¿æ¨æ–­æœ‰æ•ˆæ€§çš„æ ¸å¿ƒæ€§è´¨ã€‚ç ”ç©¶å‘ç° LinUCB ç­‰å¹¿æ³›ä½¿ç”¨çš„ç®—æ³•åœ¨æ¨¡å‹å¤±é…æ—¶ï¼ˆä¾‹å¦‚ç”¨çº¿æ€§æ¨¡å‹è¿‘ä¼¼å¤æ‚åŠ¨æ€ç³»ç»Ÿï¼‰å¯èƒ½æ— æ³•æ”¶æ•›ï¼Œä»è€Œç»™ç»Ÿè®¡æ¨æ–­é€ æˆæ ¹æœ¬éšœç¢ã€‚é’ˆå¯¹è¿™ä¸€å®é™…é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç±»åœ¨æ¨¡å‹å¤±é…ä¸‹ä»èƒ½ä¿è¯æ”¶æ•›çš„ç®—æ³•ï¼Œå¹¶å¼€å‘äº†åŸºäº Inverse-probability-weighted Z-estimator (IPW-Z) çš„é€šç”¨æ¨æ–­æ¡†æ¶ã€‚è¯¥æ¡†æ¶è¢«è¯æ˜å…·æœ‰ Asymptotic Normality å¹¶é…å¤‡äº† Consistent Variance Estimatorï¼Œä»¿çœŸå®éªŒæ˜¾ç¤ºå…¶èƒ½æä¾›æ¯”ç°æœ‰ Offline Policy Evaluation æ–¹æ³•æ›´é²æ£’ä¸”æ•°æ®é«˜æ•ˆçš„ Confidence Intervalsã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨è‡ªé€‚åº”ç®—æ³•ä¸­å†…ç½®æ”¶æ•›ä¿è¯çš„é‡è¦æ€§ï¼Œä¸ºå®é™…åº”ç”¨ä¸­ç¨³å®šçš„å®éªŒè®¾è®¡å’Œæœ‰æ•ˆçš„ç»Ÿè®¡æ¨æ–­æä¾›äº†é‡è¦çš„ç†è®ºä¿éšœã€‚",
      "categories": [
        "math.ST",
        "cs.AI"
      ],
      "primary_category": "math.ST",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06287v2",
      "published_date": "2025-09-08 02:19:37 UTC",
      "updated_date": "2025-09-20 03:49:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:31.069170+00:00"
    },
    {
      "arxiv_id": "2509.06284v1",
      "title": "From Implicit Exploration to Structured Reasoning: Leveraging Guideline and Refinement for LLMs",
      "title_zh": "ä»éšå¼æ¢ç´¢åˆ°ç»“æ„åŒ–æ¨ç†ï¼šåˆ©ç”¨å‡†åˆ™ä¸ç²¾ç‚¼ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Jiaxiang Chen",
        "Zhuo Wang",
        "Mingxi Zou",
        "Zhucong Li",
        "Zhijian Zhou",
        "Song Wang",
        "Zenglin Xu"
      ],
      "abstract": "Large language models (LLMs) have advanced general-purpose reasoning, showing strong performance across diverse tasks. However, existing methods often rely on implicit exploration, where the model follows stochastic and unguided reasoning paths-like walking without a map. This leads to unstable reasoning paths, lack of error correction, and limited learning from past experience. To address these issues, we propose a framework that shifts from implicit exploration to structured reasoning through guideline and refinement. First, we extract structured reasoning patterns from successful trajectories and reflective signals from failures. During inference, the model follows these guidelines step-by-step, with refinement applied after each step to correct errors and stabilize the reasoning process. Experiments on BBH and four additional benchmarks (GSM8K, MATH-500, MBPP, HumanEval) show that our method consistently outperforms strong baselines across diverse reasoning tasks. Structured reasoning with stepwise execution and refinement improves stability and generalization, while guidelines transfer well across domains and flexibly support cross-model collaboration, matching or surpassing supervised fine-tuning in effectiveness and scalability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨çš„éšå¼æ¢ç´¢(Implicit Exploration)é—®é¢˜ï¼Œå³ç”±äºæ¨ç†è·¯å¾„éšæœºä¸”ç¼ºä¹å¼•å¯¼ï¼Œå¯¼è‡´æ¨ç†è¿‡ç¨‹ä¸ç¨³å®šã€ç¼ºä¹çº é”™æœºåˆ¶ä»¥åŠä»å†å²ç»éªŒä¸­å­¦ä¹ å—é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§é€šè¿‡æŒ‡å—(Guideline)å’Œç»†åŒ–(Refinement)å°†éšå¼æ¢ç´¢è½¬åŒ–ä¸ºç»“æ„åŒ–æ¨ç†(Structured Reasoning)çš„æ–°æ¡†æ¶ã€‚è¯¥æ–¹æ³•é¦–å…ˆä»æˆåŠŸè½¨è¿¹ä¸­æå–æ¨ç†æ¨¡å¼å¹¶ä»å¤±è´¥ä¸­è·å–åæ€ä¿¡å·ï¼Œåœ¨æ¨ç†é˜¶æ®µå¼•å¯¼æ¨¡å‹é€æ­¥æ‰§è¡ŒæŒ‡å—ï¼Œå¹¶åœ¨æ¯æ­¥åè¿›è¡Œç»†åŒ–çº é”™ä»¥ç¨³å®šæ¨ç†è¿‡ç¨‹ã€‚åœ¨BBHã€GSM8Kã€MATH-500ã€MBPPå’ŒHumanEvalç­‰åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„ç±»æ¨ç†ä»»åŠ¡ä¸­å‡ä¸€è‡´ä¼˜äºå¼ºåŸºçº¿æ¨¡å‹ã€‚å®éªŒè¿˜è¯æ˜ç»“æ„åŒ–æ¨ç†æ˜¾è‘—æå‡äº†æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä¸”å…¶æŒ‡å—å…·å¤‡è‰¯å¥½çš„è·¨é¢†åŸŸè¿ç§»æ€§ä¸è·¨æ¨¡å‹åä½œæ½œåŠ›ï¼Œåœ¨æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ä¸Šè¾¾åˆ°ç”šè‡³è¶…è¶Šäº†ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning)çš„æ•ˆæœã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06284v1",
      "published_date": "2025-09-08 02:11:49 UTC",
      "updated_date": "2025-09-08 02:11:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:26.566382+00:00"
    },
    {
      "arxiv_id": "2509.06283v2",
      "title": "SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents",
      "title_zh": "SFR-DeepResearchï¼šé¢å‘è‡ªä¸»æ¨ç†å•æ™ºèƒ½ä½“çš„æœ‰æ•ˆå¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Xuan-Phi Nguyen",
        "Shrey Pandit",
        "Revanth Gangi Reddy",
        "Austin Xu",
        "Silvio Savarese",
        "Caiming Xiong",
        "Shafiq Joty"
      ],
      "abstract": "Equipping large language models (LLMs) with complex, interleaved reasoning and tool-use capabilities has become a key focus in agentic AI research, especially with recent advances in reasoning-oriented (``thinking'') models. Such capabilities are key to unlocking a number of important applications. One such application is Deep Research (DR), which requires extensive search and reasoning over many sources. Our work in this paper focuses on the development of native Autonomous Single-Agent models for DR featuring minimal web crawling and Python tool integration. Unlike multi-agent systems, where agents take up pre-defined roles and are told what to do at each step in a static workflow, an autonomous single-agent determines its next action dynamically based on context, without manual directive. While prior work has proposed training recipes for base or instruction-tuned LLMs, we focus on continual reinforcement learning (RL) of reasoning-optimized models to further enhance agentic skills while preserving reasoning ability. Towards this end, we propose a simple RL recipe with entirely synthetic data, which we apply to various open-source LLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity's Last Exam benchmark. In addition, we conduct key analysis experiments to provide more insights into our methodologies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SFR-DeepResearchï¼Œæ—¨åœ¨é€šè¿‡ Reinforcement Learning (RL) æå‡è‡ªä¸»æ¨ç†å•æ™ºèƒ½ä½“ (Autonomous Single-Agent) åœ¨æ‰§è¡Œ Deep Research ä»»åŠ¡æ—¶çš„æ•ˆèƒ½ã€‚ä¸å…·æœ‰é¢„å®šä¹‰è§’è‰²çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸åŒï¼Œè¯¥å•æ™ºèƒ½ä½“æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€å†³å®šåç»­è¡ŒåŠ¨ï¼Œå¹¶é›†æˆäº†ç½‘é¡µçˆ¬å–ä¸ Python å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿé’ˆå¯¹æ¨ç†ä¼˜åŒ–æ¨¡å‹æå‡ºäº†ä¸€ç§ä»…ä½¿ç”¨åˆæˆæ•°æ® (Synthetic Data) çš„æŒç»­ Reinforcement Learning æ–¹æ¡ˆï¼Œä»¥åœ¨å¢å¼ºæ™ºèƒ½ä½“æŠ€èƒ½çš„åŒæ—¶ä¿ç•™å…¶æ ¸å¿ƒæ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»åˆ—çš„ SFR-DR-20B æ¨¡å‹åœ¨ Humanity's Last Exam åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº† 28.7% çš„å‡†ç¡®ç‡ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†é€šè¿‡ç‰¹å®šçš„ Reinforcement Learning æ–¹æ¡ˆå¯ä»¥æ˜¾è‘—æå‡å¼€æºæ¨¡å‹åœ¨å¤æ‚ç§‘ç ”æ¢ç´¢ä»»åŠ¡ä¸­çš„è‡ªä¸»æ€§ä¸æ¨ç†è¡¨ç°ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Technical Report",
      "pdf_url": "https://arxiv.org/pdf/2509.06283v2",
      "published_date": "2025-09-08 02:07:09 UTC",
      "updated_date": "2025-09-09 02:30:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:58.264188+00:00"
    },
    {
      "arxiv_id": "2509.06278v3",
      "title": "TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning",
      "title_zh": "TableMindï¼šä¸€ç§ç”¨äºå·¥å…·å¢å¼ºå‹è¡¨æ ¼æ¨ç†çš„è‡ªä¸»å¯ç¼–ç¨‹æ™ºèƒ½ä½“",
      "authors": [
        "Chuang Jiang",
        "Mingyue Cheng",
        "Xiaoyu Tao",
        "Qingyang Mao",
        "Jie Ouyang",
        "Qi Liu"
      ],
      "abstract": "Table reasoning requires models to jointly perform comprehensive semantic understanding and precise numerical operations. Although recent large language model (LLM)-based methods have achieved promising results, most of them still rely on a single-turn reasoning paradigm that processes flattened tables in a single forward pass. This paradigm suffers from inherent limitations, including context overflow on large tables, weak sensitivity to continuous numerical values, and the absence of explicit tool-use and reflection. In this paper, we propose TableMind, a tuning-based autonomous programmatic table agent that simulates the human-like cognitive schema of the multi-turn interaction within a lightweight LLM. Instead of adopting a training-free workflow design, TableMind learns to internalize planning, action, and reflection through a principled two-stage training strategy. To bootstrap structured table reasoning capabilities, we construct and filter high-quality reasoning data for the supervised fine-tuning (SFT) stage. To enable precise code generation, we introduce a designed multi-perspective reward scheme and a novel optimization objective in the reinforcement learning (RL) stage. Extensive experiments on diverse benchmarks demonstrate that TableMind consistently outperforms previous baselines, validating the effectiveness of training autonomous agents to improve overall performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TableMindï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¾®è°ƒçš„è‡ªä¸»ç¨‹åºåŒ–è¡¨æ ¼æ™ºèƒ½ä½“ (Autonomous Programmatic Agent)ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) åœ¨è¡¨æ ¼æ¨ç† (Table Reasoning) ä¸­é¢ä¸´çš„ä¸Šä¸‹æ–‡æº¢å‡ºã€æ•°å€¼æ•æ„Ÿåº¦å¼±ä»¥åŠç¼ºä¹æ˜¾å¼å·¥å…·ä½¿ç”¨å’Œåæ€æœºåˆ¶ç­‰å±€é™æ€§ã€‚TableMind é€šè¿‡åœ¨è½»é‡çº§ LLM ä¸­æ¨¡æ‹Ÿäººç±»å¤šè½®äº¤äº’çš„è®¤çŸ¥æ¨¡å¼ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥å°†è§„åˆ’ã€è¡ŒåŠ¨å’Œåæ€èƒ½åŠ›å†…åŒ–ã€‚åœ¨æœ‰ç›‘ç£å¾®è°ƒ (SFT) é˜¶æ®µï¼Œè¯¥ç ”ç©¶é€šè¿‡æ„å»ºå’Œç­›é€‰é«˜è´¨é‡æ¨ç†æ•°æ®æ¥å¼•å¯¼ç»“æ„åŒ–æ¨ç†èƒ½åŠ›ï¼›åœ¨å¼ºåŒ–å­¦ä¹  (RL) é˜¶æ®µï¼Œåˆ™å¼•å…¥äº†å¤šç»´åº¦å¥–åŠ±æ–¹æ¡ˆå’Œåˆ›æ–°çš„ä¼˜åŒ–ç›®æ ‡ä»¥å®ç°ç²¾ç¡®çš„ä»£ç ç”Ÿæˆã€‚å¹¿æ³›çš„å®éªŒè¯æ˜ï¼ŒTableMind åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸ŠæŒç»­ä¼˜äºä¹‹å‰çš„åŸºçº¿æ¨¡å‹ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†é€šè¿‡é’ˆå¯¹æ€§è®­ç»ƒè‡ªä¸»æ™ºèƒ½ä½“æ¥æå‡å¤æ‚å·¥å…·å¢å¼ºå‹è¡¨æ ¼æ¨ç†æ€§èƒ½çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Comments: 10 pages, 6 figures. Submitted to WSDM 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.06278v3",
      "published_date": "2025-09-08 02:00:31 UTC",
      "updated_date": "2025-12-22 01:55:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:20:59.857964+00:00"
    },
    {
      "arxiv_id": "2509.06270v1",
      "title": "UrbanMIMOMap: A Ray-Traced MIMO CSI Dataset with Precoding-Aware Maps and Benchmarks",
      "title_zh": "UrbanMIMOMapï¼šå…·æœ‰é¢„ç¼–ç æ„ŸçŸ¥åœ°å›¾ä¸åŸºå‡†çš„å…‰çº¿è¿½è¸ª MIMO CSI æ•°æ®é›†",
      "authors": [
        "Honggang Jia",
        "Xiucheng Wang",
        "Nan Cheng",
        "Ruijin Sun",
        "Changle Li"
      ],
      "abstract": "Sixth generation (6G) systems require environment-aware communication, driven by native artificial intelligence (AI) and integrated sensing and communication (ISAC). Radio maps (RMs), providing spatially continuous channel information, are key enablers. However, generating high-fidelity RM ground truth via electromagnetic (EM) simulations is computationally intensive, motivating machine learning (ML)-based RM construction. The effectiveness of these data-driven methods depends on large-scale, high-quality training data. Current public datasets often focus on single-input single-output (SISO) and limited information, such as path loss, which is insufficient for advanced multi-input multi-output (MIMO) systems requiring detailed channel state information (CSI). To address this gap, this paper presents UrbanMIMOMap, a novel large-scale urban MIMO CSI dataset generated using high-precision ray tracing. UrbanMIMOMap offers comprehensive complex CSI matrices across a dense spatial grid, going beyond traditional path loss data. This rich CSI is vital for constructing high-fidelity RMs and serves as a fundamental resource for data-driven RM generation, including deep learning. We demonstrate the dataset's utility through baseline performance evaluations of representative ML methods for RM construction. This work provides a crucial dataset and reference for research in high-precision RM generation, MIMO spatial performance, and ML for 6G environment awareness. The code and data for this work are available at: https://github.com/UNIC-Lab/UrbanMIMOMap.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UrbanMIMOMapï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºé«˜ç²¾åº¦ray tracingæŠ€æœ¯ç”Ÿæˆçš„ã€é¢å‘6Gç¯å¢ƒæ„ŸçŸ¥çš„å¤§è§„æ¨¡åŸå¸‚MIMO CSIæ•°æ®é›†ã€‚é’ˆå¯¹ç°æœ‰å…¬å…±æ•°æ®é›†å¤šå±€é™äºSISOç³»ç»Ÿä¸”ä»…æä¾›path lossç­‰æœ‰é™ä¿¡æ¯çš„é—®é¢˜ï¼Œè¯¥æ•°æ®é›†é€šè¿‡å¯†é›†çš„ç©ºé—´ç½‘æ ¼æä¾›äº†è¯¦å°½çš„å¤æ‚CSIçŸ©é˜µï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³å…ˆè¿›MIMOç³»ç»Ÿå¯¹ä¿¡é“çŠ¶æ€ä¿¡æ¯çš„éœ€æ±‚ã€‚UrbanMIMOMapè¶…è¶Šäº†ä¼ ç»Ÿçš„æŸè€—æ¨¡å‹ï¼Œä¸ºæ„å»ºé«˜ä¿çœŸRadio maps (RMs) æä¾›äº†æ ¸å¿ƒèµ„æºï¼Œå¹¶æ”¯æŒåŸºäºæœºå™¨å­¦ä¹ çš„RMç”Ÿæˆç ”ç©¶ã€‚é€šè¿‡å¯¹ä»£è¡¨æ€§æœºå™¨å­¦ä¹ æ–¹æ³•è¿›è¡ŒåŸºå‡†æ€§èƒ½è¯„ä¼°ï¼Œè¯¥è®ºæ–‡å±•ç¤ºäº†æ•°æ®é›†åœ¨RMæ„å»ºä¸­çš„å®ç”¨ä»·å€¼ã€‚è¯¥å·¥ä½œä¸ºé«˜ç²¾åº¦RMç”Ÿæˆã€MIMOç©ºé—´æ€§èƒ½åˆ†æä»¥åŠ6Gç¯å¢ƒæ„ŸçŸ¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†é‡è¦çš„æ•°æ®æ”¯æŒå’Œå®éªŒå‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE Global Communications Conference (GLOBECOM) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.06270v1",
      "published_date": "2025-09-08 01:23:46 UTC",
      "updated_date": "2025-09-08 01:23:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:21:24.670916+00:00"
    },
    {
      "arxiv_id": "2509.06269v1",
      "title": "REMI: A Novel Causal Schema Memory Architecture for Personalized Lifestyle Recommendation Agents",
      "title_zh": "REMIï¼šä¸€ç§é¢å‘ä¸ªæ€§åŒ–ç”Ÿæ´»æ–¹å¼æ¨èæ™ºèƒ½ä½“çš„æ–°å‹å› æœå›¾å¼è®°å¿†æ¶æ„",
      "authors": [
        "Vishal Raman",
        "Vijai Aravindh R",
        "Abhijith Ragav"
      ],
      "abstract": "Personalized AI assistants often struggle to incorporate complex personal data and causal knowledge, leading to generic advice that lacks explanatory power. We propose REMI, a Causal Schema Memory architecture for a multimodal lifestyle agent that integrates a personal causal knowledge graph, a causal reasoning engine, and a schema based planning module. The idea is to deliver explainable, personalized recommendations in domains like fashion, personal wellness, and lifestyle planning. Our architecture uses a personal causal graph of the user's life events and habits, performs goal directed causal traversals enriched with external knowledge and hypothetical reasoning, and retrieves adaptable plan schemas to generate tailored action plans. A Large Language Model orchestrates these components, producing answers with transparent causal explanations. We outline the CSM system design and introduce new evaluation metrics for personalization and explainability, including Personalization Salience Score and Causal Reasoning Accuracy, to rigorously assess its performance. Results indicate that CSM based agents can provide more context aware, user aligned recommendations compared to baseline LLM agents. This work demonstrates a novel approach to memory augmented, causal reasoning in personalized agents, advancing the development of transparent and trustworthy AI lifestyle assistants.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†REMIï¼Œä¸€ç§åä¸ºCausal Schema Memoryçš„æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ä¸ªæ€§åŒ–AIåŠ©æ‰‹éš¾ä»¥å¤„ç†å¤æ‚ä¸ªäººæ•°æ®åŠå› æœçŸ¥è¯†ã€å¯¼è‡´å»ºè®®è¿‡äºé€šç”¨ä¸”ç¼ºä¹è§£é‡ŠåŠ›çš„é—®é¢˜ã€‚è¯¥æ¶æ„é›†æˆäº†ä¸ªäººå› æœçŸ¥è¯†å›¾è°±(Personal Causal Knowledge Graph)ã€å› æœæ¨ç†å¼•æ“(Causal Reasoning Engine)ä»¥åŠåŸºäºSchemaçš„è§„åˆ’æ¨¡å—ï¼Œä¸“é—¨ç”¨äºæä¾›æ—¶å°šã€ä¸ªäººå¥åº·å’Œç”Ÿæ´»è§„åˆ’é¢†åŸŸçš„ä¸ªæ€§åŒ–å»ºè®®ã€‚é€šè¿‡å¯¹ç”¨æˆ·çš„ä¸ªäººäº‹ä»¶å’Œä¹ æƒ¯è¿›è¡Œç›®æ ‡å¯¼å‘çš„å› æœéå†(Causal Traversals)ï¼Œå¹¶ç»“åˆå¤–éƒ¨çŸ¥è¯†ä¸å‡è®¾æ¨ç†ï¼ŒREMIèƒ½å¤Ÿæ£€ç´¢å¯é€‚åº”çš„è§„åˆ’Schemaä»¥ç”Ÿæˆå®šåˆ¶åŒ–è¡ŒåŠ¨æ–¹æ¡ˆã€‚å¤§è¯­è¨€æ¨¡å‹(LLM)ä½œä¸ºæ ¸å¿ƒç»„ä»¶åè°ƒè¿™äº›æ¨¡å—ï¼Œä»è€Œäº§ç”Ÿå…·æœ‰é€æ˜å› æœè§£é‡Šçš„å›ç­”ã€‚ä¸ºäº†ä¸¥è°¨è¯„ä¼°æ€§èƒ½ï¼Œç ”ç©¶å¼•å…¥äº†Personalization Salience Scoreå’ŒCausal Reasoning Accuracyç­‰æ–°è¯„ä¼°æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºçº¿LLMæ™ºèƒ½ä½“ç›¸æ¯”ï¼ŒåŸºäºCSMçš„æ™ºèƒ½ä½“èƒ½æä¾›æ›´å…·ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ä¸”æ›´å¥‘åˆç”¨æˆ·éœ€æ±‚çš„é€‰æ‹©ã€‚è¯¥å·¥ä½œå±•ç¤ºäº†åœ¨ä¸ªæ€§åŒ–æ™ºèƒ½ä½“ä¸­åº”ç”¨å­˜å‚¨å¢å¼ºå‹å› æœæ¨ç†çš„æ–°æ–¹æ³•ï¼Œæ¨åŠ¨äº†é€æ˜ä¸”å¯ä¿¡èµ–çš„AIç”Ÿæ´»åŠ©æ‰‹çš„ç ”å‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 figures, Accepted at the OARS Workshop, KDD 2025, Paper link: https://oars-workshop.github.io/papers/Raman2025.pdf",
      "pdf_url": "https://arxiv.org/pdf/2509.06269v1",
      "published_date": "2025-09-08 01:17:46 UTC",
      "updated_date": "2025-09-08 01:17:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:21:03.172163+00:00"
    },
    {
      "arxiv_id": "2509.06262v2",
      "title": "On Synthesis of Timed Regular Expressions",
      "title_zh": "è®ºå®šæ—¶æ­£åˆ™è¡¨è¾¾å¼çš„åˆæˆ",
      "authors": [
        "Ziran Wang",
        "Jie An",
        "Naijun Zhan",
        "Miaomiao Zhang",
        "Zhenya Zhang"
      ],
      "abstract": "Timed regular expressions serve as a formalism for specifying real-time behaviors of Cyber-Physical Systems. In this paper, we consider the synthesis of timed regular expressions, focusing on generating a timed regular expression consistent with a given set of system behaviors including positive and negative examples, i.e., accepting all positive examples and rejecting all negative examples. We first prove the decidability of the synthesis problem through an exploration of simple timed regular expressions. Subsequently, we propose our method of generating a consistent timed regular expression with minimal length, which unfolds in two steps. The first step is to enumerate and prune candidate parametric timed regular expressions. In the second step, we encode the requirement that a candidate generated by the first step is consistent with the given set into a Satisfiability Modulo Theories (SMT) formula, which is consequently solved to determine a solution to parametric time constraints. Finally, we evaluate our approach on benchmarks, including randomly generated behaviors from target timed models and a case study.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”¨äºè§„èŒƒä¿¡æ¯ç‰©ç†ç³»ç»Ÿ(Cyber-Physical Systems)å®æ—¶è¡Œä¸ºçš„æ—¶åºæ­£åˆ™è¡¨è¾¾å¼(Timed Regular Expressions)çš„åˆæˆé—®é¢˜ã€‚è®ºæ–‡é‡ç‚¹ç ”ç©¶å¦‚ä½•æ ¹æ®ç»™å®šçš„ä¸€ç»„åŒ…å«æ­£ä¾‹å’Œè´Ÿä¾‹çš„ç³»ç»Ÿè¡Œä¸ºï¼Œè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªä¸è¯¥è¡Œä¸ºé›†ä¸€è‡´çš„ Timed Regular Expressionã€‚ç ”ç©¶è€…é¦–å…ˆé€šè¿‡æ¢ç´¢ç®€å•çš„ Timed Regular Expressions è¯æ˜äº†è¯¥åˆæˆé—®é¢˜çš„ Decidabilityï¼Œéšåæå‡ºäº†ä¸€ç§ç”Ÿæˆæœ€çŸ­é•¿åº¦ä¸€è‡´æ€§è¡¨è¾¾å¼çš„ä¸¤æ­¥æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆæšä¸¾å¹¶å‰ªæå€™é€‰çš„å‚æ•°åŒ–è¡¨è¾¾å¼ï¼Œæ¥ç€å°†ä¸€è‡´æ€§è¦æ±‚ç¼–ç ä¸º Satisfiability Modulo Theories (SMT) å…¬å¼ï¼Œé€šè¿‡æ±‚è§£å…¬å¼æ¥ç¡®å®šå‚æ•°åŒ–æ—¶é—´çº¦æŸçš„è§£ã€‚æœ€ååœ¨éšæœºç”Ÿæˆçš„è¡Œä¸ºåŸºå‡†æµ‹è¯•å’Œæ¡ˆä¾‹ç ”ç©¶ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä¸ºè‡ªåŠ¨æ„å»ºå®æ—¶è¡Œä¸ºè§„èŒƒæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.FL",
        "cs.AI"
      ],
      "primary_category": "cs.FL",
      "comment": "15 pages, 5 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.06262v2",
      "published_date": "2025-09-08 00:59:04 UTC",
      "updated_date": "2025-09-11 02:14:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:21:13.656645+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 135,
  "processed_papers_count": 135,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T17:22:22.307737+00:00"
}