[
  {
    "arxiv_id": "2502.19634v2",
    "title": "MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning",
    "authors": [
      "Jiazhen Pan",
      "Che Liu",
      "Junde Wu",
      "Fenglin Liu",
      "Jiayuan Zhu",
      "Hongwei Bran Li",
      "Chen Chen",
      "Cheng Ouyang",
      "Daniel Rueckert"
    ],
    "abstract": "Reasoning is a critical frontier for advancing medical image analysis, where\ntransparency and trustworthiness play a central role in both clinician trust\nand regulatory approval. Although Medical Visual Language Models (VLMs) show\npromise for radiological tasks, most existing VLMs merely produce final answers\nwithout revealing the underlying reasoning. To address this gap, we introduce\nMedVLM-R1, a medical VLM that explicitly generates natural language reasoning\nto enhance transparency and trustworthiness. Instead of relying on supervised\nfine-tuning (SFT), which often suffers from overfitting to training\ndistributions and fails to foster genuine reasoning, MedVLM-R1 employs a\nreinforcement learning framework that incentivizes the model to discover\nhuman-interpretable reasoning paths without using any reasoning references.\nDespite limited training data (600 visual question answering samples) and model\nparameters (2B), MedVLM-R1 boosts accuracy from 55.11% to 78.22% across MRI,\nCT, and X-ray benchmarks, outperforming larger models trained on over a million\nsamples. It also demonstrates robust domain generalization under\nout-of-distribution tasks. By unifying medical image analysis with explicit\nreasoning, MedVLM-R1 marks a pivotal step toward trustworthy and interpretable\nAI in clinical practice. Inference model is available at:\nhttps://huggingface.co/JZPeterPan/MedVLM-R1.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19634v2",
    "published_date": "2025-02-26 23:57:34 UTC",
    "updated_date": "2025-03-19 13:55:33 UTC"
  },
  {
    "arxiv_id": "2502.19629v1",
    "title": "Agentic Mixture-of-Workflows for Multi-Modal Chemical Search",
    "authors": [
      "Tiffany J. Callahan",
      "Nathaniel H. Park",
      "Sara Capponi"
    ],
    "abstract": "The vast and complex materials design space demands innovative strategies to\nintegrate multidisciplinary scientific knowledge and optimize materials\ndiscovery. While large language models (LLMs) have demonstrated promising\nreasoning and automation capabilities across various domains, their application\nin materials science remains limited due to a lack of benchmarking standards\nand practical implementation frameworks. To address these challenges, we\nintroduce Mixture-of-Workflows for Self-Corrective Retrieval-Augmented\nGeneration (CRAG-MoW) - a novel paradigm that orchestrates multiple agentic\nworkflows employing distinct CRAG strategies using open-source LLMs. Unlike\nprior approaches, CRAG-MoW synthesizes diverse outputs through an orchestration\nagent, enabling direct evaluation of multiple LLMs across the same problem\ndomain. We benchmark CRAG-MoWs across small molecules, polymers, and chemical\nreactions, as well as multi-modal nuclear magnetic resonance (NMR) spectral\nretrieval. Our results demonstrate that CRAG-MoWs achieve performance\ncomparable to GPT-4o while being preferred more frequently in comparative\nevaluations, highlighting the advantage of structured retrieval and multi-agent\nsynthesis. By revealing performance variations across data types, CRAG-MoW\nprovides a scalable, interpretable, and benchmark-driven approach to optimizing\nAI architectures for materials discovery. These insights are pivotal in\naddressing fundamental gaps in benchmarking LLMs and autonomous AI agents for\nscientific applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "PDF includes supplemental material",
    "pdf_url": "http://arxiv.org/pdf/2502.19629v1",
    "published_date": "2025-02-26 23:48:02 UTC",
    "updated_date": "2025-02-26 23:48:02 UTC"
  },
  {
    "arxiv_id": "2502.19623v1",
    "title": "3D Nephrographic Image Synthesis in CT Urography with the Diffusion Model and Swin Transformer",
    "authors": [
      "Hongkun Yu",
      "Syed Jamal Safdar Gardezi",
      "E. Jason Abel",
      "Daniel Shapiro",
      "Meghan G. Lubner",
      "Joshua Warner",
      "Matthew Smith",
      "Giuseppe Toia",
      "Lu Mao",
      "Pallavi Tiwari",
      "Andrew L. Wentland"
    ],
    "abstract": "Purpose: This study aims to develop and validate a method for synthesizing 3D\nnephrographic phase images in CT urography (CTU) examinations using a diffusion\nmodel integrated with a Swin Transformer-based deep learning approach.\nMaterials and Methods: This retrospective study was approved by the local\nInstitutional Review Board. A dataset comprising 327 patients who underwent\nthree-phase CTU (mean $\\pm$ SD age, 63 $\\pm$ 15 years; 174 males, 153 females)\nwas curated for deep learning model development. The three phases for each\npatient were aligned with an affine registration algorithm. A custom deep\nlearning model coined dsSNICT (diffusion model with a Swin transformer for\nsynthetic nephrographic phase images in CT) was developed and implemented to\nsynthesize the nephrographic images. Performance was assessed using Peak\nSignal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Mean Absolute\nError (MAE), and Fr\\'{e}chet Video Distance (FVD). Qualitative evaluation by\ntwo fellowship-trained abdominal radiologists was performed. Results: The\nsynthetic nephrographic images generated by our proposed approach achieved high\nPSNR (26.3 $\\pm$ 4.4 dB), SSIM (0.84 $\\pm$ 0.069), MAE (12.74 $\\pm$ 5.22 HU),\nand FVD (1323). Two radiologists provided average scores of 3.5 for real images\nand 3.4 for synthetic images (P-value = 0.5) on a Likert scale of 1-5,\nindicating that our synthetic images closely resemble real images. Conclusion:\nThe proposed approach effectively synthesizes high-quality 3D nephrographic\nphase images. This model can be used to reduce radiation dose in CTU by 33.3\\%\nwithout compromising image quality, which thereby enhances the safety and\ndiagnostic utility of CT urography.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 6 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.19623v1",
    "published_date": "2025-02-26 23:22:31 UTC",
    "updated_date": "2025-02-26 23:22:31 UTC"
  },
  {
    "arxiv_id": "2502.19622v2",
    "title": "Weaker LLMs' Opinions Also Matter: Mixture of Opinions Enhances LLM's Mathematical Reasoning",
    "authors": [
      "Yanan Chen",
      "Ali Pesaranghader",
      "Tanmana Sadhu"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have raised interest in their\nformal reasoning capabilities, particularly in mathematics. While closed LLMs\nlike GPT-4 perform well on mathematical benchmarks, e.g., GSM8K, it remains\nunclear whether small to medium-sized open LLMs can achieve similar\nperformance, questioning their reliability. To close this gap, we propose a\npost-training approach leveraging a mixture of opinions (MoO) from weaker\nancillary LLMs to enhance a (relatively) stronger LLM's reasoning. For that,\neach post-training sample is augmented with Chain-of-Thought (CoT) reasoning\nsteps and answers from ancillary LLMs, enabling the main LLM to learn from\ndiverse perspectives. We compare MoO with standard supervised fine-tuning\n(SFT), few-shot prompting, and the Mixture of Agents (MoA) method on\nmathematical reasoning benchmarks. Our results show that incorporating weaker\nLLMs' opinions improves mathematical reasoning by an average of 5%,\nhighlighting the value of diverse perspectives in reasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 1 figure, 3 tables, 4 prompt/data templates",
    "pdf_url": "http://arxiv.org/pdf/2502.19622v2",
    "published_date": "2025-02-26 23:22:02 UTC",
    "updated_date": "2025-03-05 05:42:39 UTC"
  },
  {
    "arxiv_id": "2502.19614v1",
    "title": "Is Your Paper Being Reviewed by an LLM? A New Benchmark Dataset and Approach for Detecting AI Text in Peer Review",
    "authors": [
      "Sungduk Yu",
      "Man Luo",
      "Avinash Madusu",
      "Vasudev Lal",
      "Phillip Howard"
    ],
    "abstract": "Peer review is a critical process for ensuring the integrity of published\nscientific research. Confidence in this process is predicated on the assumption\nthat experts in the relevant domain give careful consideration to the merits of\nmanuscripts which are submitted for publication. With the recent rapid\nadvancements in large language models (LLMs), a new risk to the peer review\nprocess is that negligent reviewers will rely on LLMs to perform the often time\nconsuming process of reviewing a paper. However, there is a lack of existing\nresources for benchmarking the detectability of AI text in the domain of peer\nreview.\n  To address this deficiency, we introduce a comprehensive dataset containing a\ntotal of 788,984 AI-written peer reviews paired with corresponding human\nreviews, covering 8 years of papers submitted to each of two leading AI\nresearch conferences (ICLR and NeurIPS). We use this new resource to evaluate\nthe ability of 18 existing AI text detection algorithms to distinguish between\npeer reviews written by humans and different state-of-the-art LLMs. Motivated\nby the shortcomings of existing methods, we propose a new detection approach\nwhich surpasses existing methods in the identification of AI written peer\nreviews. Our work reveals the difficulty of identifying AI-generated text at\nthe individual peer review level, highlighting the urgent need for new tools\nand methods to detect this unethical use of generative AI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19614v1",
    "published_date": "2025-02-26 23:04:05 UTC",
    "updated_date": "2025-02-26 23:04:05 UTC"
  },
  {
    "arxiv_id": "2502.19613v1",
    "title": "Self-rewarding correction for mathematical reasoning",
    "authors": [
      "Wei Xiong",
      "Hanning Zhang",
      "Chenlu Ye",
      "Lichang Chen",
      "Nan Jiang",
      "Tong Zhang"
    ],
    "abstract": "We study self-rewarding reasoning large language models (LLMs), which can\nsimultaneously generate step-by-step reasoning and evaluate the correctness of\ntheir outputs during the inference time-without external feedback. This\nintegrated approach allows a single model to independently guide its reasoning\nprocess, offering computational advantages for model deployment. We\nparticularly focus on the representative task of self-correction, where models\nautonomously detect errors in their responses, revise outputs, and decide when\nto terminate iterative refinement loops. To enable this, we propose a\ntwo-staged algorithmic framework for constructing self-rewarding reasoning\nmodels using only self-generated data. In the first stage, we employ sequential\nrejection sampling to synthesize long chain-of-thought trajectories that\nincorporate both self-rewarding and self-correction mechanisms. Fine-tuning\nmodels on these curated data allows them to learn the patterns of\nself-rewarding and self-correction. In the second stage, we further enhance the\nmodels' ability to assess response accuracy and refine outputs through\nreinforcement learning with rule-based signals. Experiments with Llama-3 and\nQwen-2.5 demonstrate that our approach surpasses intrinsic self-correction\ncapabilities and achieves performance comparable to systems that rely on\nexternal reward models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19613v1",
    "published_date": "2025-02-26 23:01:16 UTC",
    "updated_date": "2025-02-26 23:01:16 UTC"
  },
  {
    "arxiv_id": "2502.19610v2",
    "title": "Program Synthesis Dialog Agents for Interactive Decision-Making",
    "authors": [
      "Matthew Toles",
      "Nikhil Balwani",
      "Rattandeep Singh",
      "Valentina Giulia Sartori Rodriguez",
      "Zhou Yu"
    ],
    "abstract": "Many real-world eligibility problems, ranging from medical diagnosis to tax\nplanning, can be mapped to decision problems expressed in natural language,\nwherein a model must make a binary choice based on user features. Large-scale\ndomains such as legal codes or frequently updated funding opportunities render\nhuman annotation (e.g., web forms or decision trees) impractical, highlighting\nthe need for agents that can automatically assist in decision-making. Since\nrelevant information is often only known to the user, it is crucial that these\nagents ask the right questions. As agents determine when to terminate a\nconversation, they face a trade-off between accuracy and the number of\nquestions asked, a key metric for both user experience and cost. To evaluate\nthis task, we propose BeNYfits, a new benchmark for determining user\neligibility for multiple overlapping social benefits opportunities through\ninteractive decision-making. Our experiments show that current language models\nstruggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a\nReAct-style chain-of-thought. To address this, we introduce ProADA, a novel\napproach that leverages program synthesis to assist in decision-making by\nmapping dialog planning to a code generation problem and using gaps in\nstructured data to determine the best next action. Our agent, ProADA, improves\nthe F1 score to 55.6 while maintaining nearly the same number of dialog turns.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19610v2",
    "published_date": "2025-02-26 22:53:01 UTC",
    "updated_date": "2025-03-17 18:13:03 UTC"
  },
  {
    "arxiv_id": "2503.01885v1",
    "title": "Learning Policy Committees for Effective Personalization in MDPs with Diverse Tasks",
    "authors": [
      "Luise Ge",
      "Michael Lanier",
      "Anindya Sarkar",
      "Bengisu Guresti",
      "Yevgeniy Vorobeychik",
      "Chongjie Zhang"
    ],
    "abstract": "Many dynamic decision problems, such as robotic control, involve a series of\ntasks, many of which are unknown at training time. Typical approaches for these\nproblems, such as multi-task and meta reinforcement learning, do not generalize\nwell when the tasks are diverse. On the other hand, approaches that aim to\ntackle task diversity, such as using task embedding as policy context and task\nclustering, typically lack performance guarantees and require a large number of\ntraining tasks. To address these challenges, we propose a novel approach for\nlearning a policy committee that includes at least one near-optimal policy with\nhigh probability for tasks encountered during execution. While we show that\nthis problem is in general inapproximable, we present two practical algorithmic\nsolutions. The first yields provable approximation and task sample complexity\nguarantees when tasks are low-dimensional (the best we can do due to\ninapproximability), whereas the second is a general and practical\ngradient-based approach. In addition, we provide a provable sample complexity\nbound for few-shot learning. Our experiments on MuJoCo and Meta-World show that\nthe proposed approach outperforms state-of-the-art multi-task, meta-, and task\nclustering baselines in training, generalization, and few-shot learning, often\nby a large margin.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01885v1",
    "published_date": "2025-02-26 22:45:25 UTC",
    "updated_date": "2025-02-26 22:45:25 UTC"
  },
  {
    "arxiv_id": "2503.01884v1",
    "title": "Contextual Quantum Neural Networks for Stock Price Prediction",
    "authors": [
      "Sharan Mourya",
      "Hannes Leipold",
      "Bibhas Adhikari"
    ],
    "abstract": "In this paper, we apply quantum machine learning (QML) to predict the stock\nprices of multiple assets using a contextual quantum neural network. Our\napproach captures recent trends to predict future stock price distributions,\nmoving beyond traditional models that focus on entire historical data,\nenhancing adaptability and precision. Utilizing the principles of quantum\nsuperposition, we introduce a new training technique called the quantum batch\ngradient update (QBGU), which accelerates the standard stochastic gradient\ndescent (SGD) in quantum applications and improves convergence. Consequently,\nwe propose a quantum multi-task learning (QMTL) architecture, specifically, the\nshare-and-specify ansatz, that integrates task-specific operators controlled by\nquantum labels, enabling the simultaneous and efficient training of multiple\nassets on the same quantum circuit as well as enabling efficient portfolio\nrepresentation with logarithmic overhead in the number of qubits. This\narchitecture represents the first of its kind in quantum finance, offering\nsuperior predictive power and computational efficiency for multi-asset stock\nprice forecasting. Through extensive experimentation on S\\&P 500 data for\nApple, Google, Microsoft, and Amazon stocks, we demonstrate that our approach\nnot only outperforms quantum single-task learning (QSTL) models but also\neffectively captures inter-asset correlations, leading to enhanced prediction\naccuracy. Our findings highlight the transformative potential of QML in\nfinancial applications, paving the way for more advanced, resource-efficient\nquantum algorithms in stock price prediction and other complex financial\nmodeling tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01884v1",
    "published_date": "2025-02-26 22:39:23 UTC",
    "updated_date": "2025-02-26 22:39:23 UTC"
  },
  {
    "arxiv_id": "2503.01883v1",
    "title": "Learning Surrogates for Offline Black-Box Optimization via Gradient Matching",
    "authors": [
      "Minh Hoang",
      "Azza Fadhel",
      "Aryan Deshwal",
      "Janardhan Rao Doppa",
      "Trong Nghia Hoang"
    ],
    "abstract": "Offline design optimization problem arises in numerous science and\nengineering applications including material and chemical design, where\nexpensive online experimentation necessitates the use of in silico surrogate\nfunctions to predict and maximize the target objective over candidate designs.\nAlthough these surrogates can be learned from offline data, their predictions\nare often inaccurate outside the offline data regime. This challenge raises a\nfundamental question about the impact of imperfect surrogate model on the\nperformance gap between its optima and the true optima, and to what extent the\nperformance loss can be mitigated. Although prior work developed methods to\nimprove the robustness of surrogate models and their associated optimization\nprocesses, a provably quantifiable relationship between an imperfect surrogate\nand the corresponding performance gap, as well as whether prior methods\ndirectly address it, remain elusive. To shed light on this important question,\nwe present a theoretical framework to understand offline black-box\noptimization, by explicitly bounding the optimization quality based on how well\nthe surrogate matches the latent gradient field that underlines the offline\ndata. Inspired by our theoretical analysis, we propose a principled black-box\ngradient matching algorithm to create effective surrogate models for offline\noptimization, improving over prior approaches on various real-world benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.01883v1",
    "published_date": "2025-02-26 22:35:54 UTC",
    "updated_date": "2025-02-26 22:35:54 UTC"
  },
  {
    "arxiv_id": "2502.19596v2",
    "title": "Trustworthy Answers, Messier Data: Bridging the Gap in Low-Resource Retrieval-Augmented Generation for Domain Expert Systems",
    "authors": [
      "Nayoung Choi",
      "Grace Byun",
      "Andrew Chung",
      "Ellie S. Paek",
      "Shinsun Lee",
      "Jinho D. Choi"
    ],
    "abstract": "RAG has become a key technique for enhancing LLMs by reducing hallucinations,\nespecially in domain expert systems where LLMs may lack sufficient inherent\nknowledge. However, developing these systems in low-resource settings\nintroduces several challenges: (1) handling heterogeneous data sources, (2)\noptimizing retrieval phase for trustworthy answers, and (3) evaluating\ngenerated answers across diverse aspects. To address these, we introduce a data\ngeneration pipeline that transforms raw multi-modal data into structured corpus\nand Q&A pairs, an advanced re-ranking phase improving retrieval precision, and\na reference matching algorithm enhancing answer traceability. Applied to the\nautomotive engineering domain, our system improves factual correctness (+1.94),\ninformativeness (+1.16), and helpfulness (+1.67) over a non-RAG baseline, based\non a 1-5 scale by an LLM judge. These results highlight the effectiveness of\nour approach across distinct aspects, with strong answer grounding and\ntransparency.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19596v2",
    "published_date": "2025-02-26 22:20:08 UTC",
    "updated_date": "2025-04-14 20:00:15 UTC"
  },
  {
    "arxiv_id": "2502.19593v1",
    "title": "Improving Representation Learning of Complex Critical Care Data with ICU-BERT",
    "authors": [
      "Ricardo Santos",
      "André V. Carreiro",
      "Xi Peng",
      "Hugo Gamboa",
      "Holger Fröhlich"
    ],
    "abstract": "The multivariate, asynchronous nature of real-world clinical data, such as\nthat generated in Intensive Care Units (ICUs), challenges traditional AI-based\ndecision-support systems. These often assume data regularity and feature\nindependence and frequently rely on limited data scopes and manual feature\nengineering. The potential of generative AI technologies has not yet been fully\nexploited to analyze clinical data. We introduce ICU-BERT, a transformer-based\nmodel pre-trained on the MIMIC-IV database using a multi-task scheme to learn\nrobust representations of complex ICU data with minimal preprocessing. ICU-BERT\nemploys a multi-token input strategy, incorporating dense embeddings from a\nbiomedical Large Language Model to learn a generalizable representation of\ncomplex and multivariate ICU data. With an initial evaluation of five tasks and\nfour additional ICU datasets, ICU-BERT results indicate that ICU-BERT either\ncompares to or surpasses current performance benchmarks by leveraging\nfine-tuning. By integrating structured and unstructured data, ICU-BERT advances\nthe use of foundational models in medical informatics, offering an adaptable\nsolution for clinical decision support across diverse applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for poster at GenAI4Health Workshop at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19593v1",
    "published_date": "2025-02-26 22:16:58 UTC",
    "updated_date": "2025-02-26 22:16:58 UTC"
  },
  {
    "arxiv_id": "2503.01881v1",
    "title": "Mapping representations in Reinforcement Learning via Semantic Alignment for Zero-Shot Stitching",
    "authors": [
      "Antonio Pio Ricciardi",
      "Valentino Maiorca",
      "Luca Moschella",
      "Riccardo Marin",
      "Emanuele Rodolà"
    ],
    "abstract": "Deep Reinforcement Learning (RL) models often fail to generalize when even\nsmall changes occur in the environment's observations or task requirements.\nAddressing these shifts typically requires costly retraining, limiting the\nreusability of learned policies. In this paper, we build on recent work in\nsemantic alignment to propose a zero-shot method for mapping between latent\nspaces across different agents trained on different visual and task variations.\nSpecifically, we learn a transformation that maps embeddings from one agent's\nencoder to another agent's encoder without further fine-tuning. Our approach\nrelies on a small set of \"anchor\" observations that are semantically aligned,\nwhich we use to estimate an affine or orthogonal transform. Once the\ntransformation is found, an existing controller trained for one domain can\ninterpret embeddings from a different (existing) encoder in a zero-shot\nfashion, skipping additional trainings. We empirically demonstrate that our\nframework preserves high performance under visual and task domain shifts. We\nempirically demonstrate zero-shot stitching performance on the CarRacing\nenvironment with changing background and task. By allowing modular re-assembly\nof existing policies, it paves the way for more robust, compositional RL in\ndynamically changing environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.01881v1",
    "published_date": "2025-02-26 22:06:00 UTC",
    "updated_date": "2025-02-26 22:06:00 UTC"
  },
  {
    "arxiv_id": "2502.19587v1",
    "title": "NeoBERT: A Next-Generation BERT",
    "authors": [
      "Lola Le Breton",
      "Quentin Fournier",
      "Mariam El Mezouar",
      "Sarath Chandar"
    ],
    "abstract": "Recent innovations in architecture, pre-training, and fine-tuning have led to\nthe remarkable in-context learning and reasoning abilities of large\nauto-regressive language models such as LLaMA and DeepSeek. In contrast,\nencoders like BERT and RoBERTa have not seen the same level of progress despite\nbeing foundational for many downstream NLP applications. To bridge this gap, we\nintroduce NeoBERT, a next-generation encoder that redefines the capabilities of\nbidirectional models by integrating state-of-the-art advancements in\narchitecture, modern data, and optimized pre-training methodologies. NeoBERT is\ndesigned for seamless adoption: it serves as a plug-and-play replacement for\nexisting base models, relies on an optimal depth-to-width ratio, and leverages\nan extended context length of 4,096 tokens. Despite its compact 250M parameter\nfootprint, it achieves state-of-the-art results on the massive MTEB benchmark,\noutperforming BERT large, RoBERTa large, NomicBERT, and ModernBERT under\nidentical fine-tuning conditions. In addition, we rigorously evaluate the\nimpact of each modification on GLUE and design a uniform fine-tuning and\nevaluation framework for MTEB. We release all code, data, checkpoints, and\ntraining scripts to accelerate research and real-world adoption.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 5 figures, 9 tables. Submitted to TMLR",
    "pdf_url": "http://arxiv.org/pdf/2502.19587v1",
    "published_date": "2025-02-26 22:00:22 UTC",
    "updated_date": "2025-02-26 22:00:22 UTC"
  },
  {
    "arxiv_id": "2502.19577v1",
    "title": "Tell me why: Visual foundation models as self-explainable classifiers",
    "authors": [
      "Hugues Turbé",
      "Mina Bjelogrlic",
      "Gianmarco Mengaldo",
      "Christian Lovis"
    ],
    "abstract": "Visual foundation models (VFMs) have become increasingly popular due to their\nstate-of-the-art performance. However, interpretability remains crucial for\ncritical applications. In this sense, self-explainable models (SEM) aim to\nprovide interpretable classifiers that decompose predictions into a weighted\nsum of interpretable concepts. Despite their promise, recent studies have shown\nthat these explanations often lack faithfulness. In this work, we combine VFMs\nwith a novel prototypical architecture and specialized training objectives. By\ntraining only a lightweight head (approximately 1M parameters) on top of frozen\nVFMs, our approach (ProtoFM) offers an efficient and interpretable solution.\nEvaluations demonstrate that our approach achieves competitive classification\nperformance while outperforming existing models across a range of\ninterpretability metrics derived from the literature. Code is available at\nhttps://github.com/hturbe/proto-fm.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68T10",
      "I.2.6; I.2.10; I.5.4"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19577v1",
    "published_date": "2025-02-26 21:40:30 UTC",
    "updated_date": "2025-02-26 21:40:30 UTC"
  },
  {
    "arxiv_id": "2502.19573v1",
    "title": "Do Large Language Models Know How Much They Know?",
    "authors": [
      "Gabriele Prato",
      "Jerry Huang",
      "Prasannna Parthasarathi",
      "Shagun Sodhani",
      "Sarath Chandar"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as highly capable systems and are\nincreasingly being integrated into various uses. However, the rapid pace of\ntheir deployment has outpaced a comprehensive understanding of their internal\nmechanisms and a delineation of their capabilities and limitations. A desired\nattribute of an intelligent system is its ability to recognize the scope of its\nown knowledge. To investigate whether LLMs embody this characteristic, we\ndevelop a benchmark designed to challenge these models to enumerate all\ninformation they possess on specific topics. This benchmark evaluates whether\nthe models recall excessive, insufficient, or the precise amount of\ninformation, thereby indicating their awareness of their own knowledge. Our\nfindings reveal that all tested LLMs, given sufficient scale, demonstrate an\nunderstanding of how much they know about specific topics. While different\narchitectures exhibit varying rates of this capability's emergence, the results\nsuggest that awareness of knowledge may be a generalizable attribute of LLMs.\nFurther research is needed to confirm this potential and fully elucidate the\nunderlying mechanisms.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19573v1",
    "published_date": "2025-02-26 21:33:06 UTC",
    "updated_date": "2025-02-26 21:33:06 UTC"
  },
  {
    "arxiv_id": "2502.19567v2",
    "title": "Atlas: A Framework for ML Lifecycle Provenance & Transparency",
    "authors": [
      "Marcin Spoczynski",
      "Marcela S. Melara",
      "Sebastian Szyller"
    ],
    "abstract": "The rapid adoption of open source machine learning (ML) datasets and models\nexposes today's AI applications to critical risks like data poisoning and\nsupply chain attacks across the ML lifecycle. With growing regulatory pressure\nto address these issues through greater transparency, ML model vendors face\nchallenges balancing these requirements against confidentiality for data and\nintellectual property needs. We propose Atlas, a framework that enables fully\nattestable ML pipelines. Atlas leverages open specifications for data and\nsoftware supply chain provenance to collect verifiable records of model\nartifact authenticity and end-to-end lineage metadata. Atlas combines trusted\nhardware and transparency logs to enhance metadata integrity, preserve data\nconfidentiality, and limit unauthorized access during ML pipeline operations,\nfrom training through deployment. Our prototype implementation of Atlas\nintegrates several open-source tools to build an ML lifecycle transparency\nsystem, and assess the practicality of Atlas through two case study ML\npipelines.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19567v2",
    "published_date": "2025-02-26 21:18:03 UTC",
    "updated_date": "2025-05-14 22:11:48 UTC"
  },
  {
    "arxiv_id": "2503.05783v1",
    "title": "Knowledge representation and scalable abstract reasoning for simulated democracy in Unity",
    "authors": [
      "Eleftheria Katsiri",
      "Alexandros Gazis",
      "Angelos Protopapas"
    ],
    "abstract": "We present a novel form of scalable knowledge representation about agents in\na simulated democracy, e-polis, where real users respond to social challenges\nassociated with democratic institutions, structured as Smart Spatial Types, a\nnew type of Smart Building that changes architectural form according to the\nphilosophical doctrine of a visitor. At the end of the game players vote on the\nSmart City that results from their collective choices. Our approach uses\ndeductive systems in an unusual way: by integrating a model of democracy with a\nmodel of a Smart City we are able to prove quality aspects of the simulated\ndemocracy in different urban and social settings, while adding ease and\nflexibility to the development. Second, we can infer and reason with abstract\nknowledge, which is a limitation of the Unity platform; third, our system\nenables real-time decision-making and adaptation of the game flow based on the\nplayer's abstract state, paving the road to explainability. Scalability is\nachieved by maintaining a dual-layer knowledge representation mechanism for\nreasoning about the simulated democracy that functions in a similar way to a\ntwo-level cache. The lower layer knows about the current state of the game by\ncontinually processing a high rate of events produced by the in-built physics\nengine of the Unity platform, e.g., it knows of the position of a player in\nspace, in terms of his coordinates x,y,z as well as their choices for each\nchallenge. The higher layer knows of easily-retrievable, user-defined abstract\nknowledge about current and historical states, e.g., it knows of the political\ndoctrine of a Smart Spatial Type, a player's philosophical doctrine, and the\ncollective philosophical doctrine of a community players with respect to\ncurrent social issues.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY",
      "K.6.3; C.5.2; C.5.3; C.5.5; C.5.m; C.5.0"
    ],
    "primary_category": "cs.MA",
    "comment": "23 pages, 11 figures, 76 references. This article is under review at\n  WSEAS Transactions on Information Science and Applications from 02.2025",
    "pdf_url": "http://arxiv.org/pdf/2503.05783v1",
    "published_date": "2025-02-26 21:03:02 UTC",
    "updated_date": "2025-02-26 21:03:02 UTC"
  },
  {
    "arxiv_id": "2503.00058v1",
    "title": "African Gender Classification Using Clothing Identification Via Deep Learning",
    "authors": [
      "Samuel Ozechi"
    ],
    "abstract": "Human attribute identification and classification are crucial in computer\nvision, driving the development of innovative recognition systems. Traditional\ngender classification methods primarily rely on facial recognition, which,\nwhile effective, struggles under non-ideal conditions such as blurriness, side\nviews, or partial occlusions. This study explores an alternative approach by\nleveraging clothing identification, specifically focusing on African\ntraditional attire, which carries culturally significant and gender-specific\nfeatures.\n  We use the AFRIFASHION1600 dataset, a curated collection of 1,600 images of\nAfrican traditional clothing labeled into two gender classes: male and female.\nA deep learning model, based on a modified VGG16 architecture and trained using\ntransfer learning, was developed for classification. Data augmentation was\napplied to address the challenges posed by the relatively small dataset and to\nmitigate overfitting. The model achieved an accuracy of 87% on the test set,\ndemonstrating strong predictive capability despite dataset imbalances favoring\nfemale samples.\n  These findings highlight the potential of clothing-based identification as a\ncomplementary technique to facial recognition for gender classification in\nAfrican contexts. Future research should focus on expanding and balancing\ndatasets to enhance classification robustness and improve the applicability of\nclothing-based gender recognition systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "8T07 (Primary), 68T01 (Secondary)"
    ],
    "primary_category": "cs.CV",
    "comment": "3 Pages, 10 Figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00058v1",
    "published_date": "2025-02-26 20:59:59 UTC",
    "updated_date": "2025-02-26 20:59:59 UTC"
  },
  {
    "arxiv_id": "2502.19557v1",
    "title": "Distill Not Only Data but Also Rewards: Can Smaller Language Models Surpass Larger Ones?",
    "authors": [
      "Yudi Zhang",
      "Lu Wang",
      "Meng Fang",
      "Yali Du",
      "Chenghua Huang",
      "Jun Wang",
      "Qingwei Lin",
      "Mykola Pechenizkiy",
      "Dongmei Zhang",
      "Saravan Rajmohan",
      "Qi Zhang"
    ],
    "abstract": "Distilling large language models (LLMs) typically involves transferring the\nteacher model's responses through supervised fine-tuning (SFT). However, this\napproach neglects the potential to distill both data (output content) and\nreward signals (quality evaluations). Extracting reliable reward signals\ndirectly from teacher models is challenging, as LLMs are optimized for\ngeneration rather than evaluation, often resulting in biased or inconsistent\nassessments. To address this limitation, we propose a novel distillation\npipeline that transfers both responses and rewards. Our method generates\npseudo-rewards through a self-supervised mechanism that leverages the inherent\nstructure of both teacher and student responses, enabling reward learning\nwithout explicit external evaluation. The reward model subsequently guides\nreinforcement learning (RL), allowing iterative refinement of the student model\nafter an SFT warm-up phase. Experiments on GSM8K and MMLU-PRO demonstrate that\nour method consistently outperforms traditional SFT-based approaches, enabling\nstudent models to surpass the performance of their teachers. This work\nhighlights the potential for scalable, efficient distillation through\nstructured self-supervised reward learning, reducing dependence on external\nreward supervision.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19557v1",
    "published_date": "2025-02-26 20:50:11 UTC",
    "updated_date": "2025-02-26 20:50:11 UTC"
  },
  {
    "arxiv_id": "2502.19546v3",
    "title": "Repurposing the scientific literature with vision-language models",
    "authors": [
      "Anton Alyakin",
      "Jaden Stryker",
      "Daniel Alexander Alber",
      "Karl L. Sangwon",
      "Jin Vivian Lee",
      "Brandon Duderstadt",
      "Akshay Save",
      "David Kurland",
      "Spencer Frome",
      "Shrutika Singh",
      "Jeff Zhang",
      "Eunice Yang",
      "Ki Yun Park",
      "Cordelia Orillac",
      "Aly A. Valliani",
      "Sean Neifert",
      "Albert Liu",
      "Aneek Patel",
      "Christopher Livia",
      "Darryl Lau",
      "Ilya Laufer",
      "Peter A. Rozman",
      "Eveline Teresa Hidalgo",
      "Howard Riina",
      "Rui Feng",
      "Todd Hollon",
      "Yindalon Aphinyanaphongs",
      "John G. Golfinos",
      "Laura Snyder",
      "Eric Leuthardt",
      "Douglas Kondziolka",
      "Eric Karl Oermann"
    ],
    "abstract": "Leading vision-language models (VLMs) are trained on general Internet\ncontent, overlooking scientific journals' rich, domain-specific knowledge.\nTraining on specialty-specific literature could yield high-performance,\ntask-specific tools, enabling generative AI to match generalist models in\nspecialty publishing, educational, and clinical tasks. We created NeuroPubs, a\nmultimodal dataset of 23,000 Neurosurgery Publications articles (134M words,\n78K image-caption pairs). Using NeuroPubs, VLMs generated publication-ready\ngraphical abstracts (70% of 100 abstracts) and board-style questions\nindistinguishable from human-written ones (54% of 89,587 questions). We used\nthese questions to train CNS-Obsidian, a 34B-parameter VLM. In a blinded,\nrandomized controlled trial, our model demonstrated non-inferiority to then\nstate-of-the-art GPT-4o in neurosurgical differential diagnosis (clinical\nutility, 40.62% upvotes vs. 57.89%, p=0.1150; accuracy, 59.38% vs. 65.79%,\np=0.3797). Our pilot study demonstrates how training generative AI models on\nspecialty-specific journal content - without large-scale internet data -\nresults in high-performance academic and clinical tools, enabling\ndomain-tailored AI across diverse fields.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19546v3",
    "published_date": "2025-02-26 20:35:37 UTC",
    "updated_date": "2025-04-28 00:52:00 UTC"
  },
  {
    "arxiv_id": "2502.19545v1",
    "title": "Winning Big with Small Models: Knowledge Distillation vs. Self-Training for Reducing Hallucination in QA Agents",
    "authors": [
      "Ashley Lewis",
      "Michael White",
      "Jing Liu",
      "Toshiaki Koike-Akino",
      "Kieran Parsons",
      "Ye Wang"
    ],
    "abstract": "The deployment of Large Language Models (LLMs) in customer support is\nconstrained by hallucination-generating false information-and the high cost of\nproprietary models. To address these challenges, we propose a\nretrieval-augmented question-answering (QA) pipeline and explore how to balance\nhuman input and automation. Using a dataset of questions about a Samsung Smart\nTV user manual, we demonstrate that synthetic data generated by LLMs\noutperforms crowdsourced data in reducing hallucination in finetuned models. We\nalso compare self-training (fine-tuning models on their own outputs) and\nknowledge distillation (fine-tuning on stronger models' outputs, e.g., GPT-4o),\nand find that self-training achieves comparable hallucination reduction. We\nconjecture that this surprising finding can be attributed to increased exposure\nbias issues in the knowledge distillation case and support this conjecture with\npost hoc analysis. We also improve robustness to unanswerable questions and\nretrieval failures with contextualized \"I don't know\" responses. These findings\nshow that scalable, cost-efficient QA systems can be built using synthetic data\nand self-training with open-source models, reducing reliance on proprietary\ntools or costly human annotations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19545v1",
    "published_date": "2025-02-26 20:34:58 UTC",
    "updated_date": "2025-02-26 20:34:58 UTC"
  },
  {
    "arxiv_id": "2502.19537v3",
    "title": "No, of course I can! Refusal Mechanisms Can Be Exploited Using Harmless Fine-Tuning Data",
    "authors": [
      "Joshua Kazdan",
      "Lisa Yu",
      "Rylan Schaeffer",
      "Chris Cundy",
      "Sanmi Koyejo",
      "Krishnamurthy Dvijotham"
    ],
    "abstract": "Leading language model (LM) providers like OpenAI and Google offer\nfine-tuning APIs that allow customers to adapt LMs for specific use cases. To\nprevent misuse, these LM providers implement filtering mechanisms to block\nharmful fine-tuning data. Consequently, adversaries seeking to produce unsafe\nLMs via these APIs must craft adversarial training data that are not\nidentifiably harmful. We make three contributions in this context: 1. We show\nthat many existing attacks that use harmless data to create unsafe LMs rely on\neliminating model refusals in the first few tokens of their responses. 2. We\nshow that such prior attacks can be blocked by a simple defense that pre-fills\nthe first few tokens from an aligned model before letting the fine-tuned model\nfill in the rest. 3. We describe a new data-poisoning attack, ``No, Of course I\nCan Execute'' (NOICE), which exploits an LM's formulaic refusal mechanism to\nelicit harmful responses. By training an LM to refuse benign requests on the\nbasis of safety before fulfilling those requests regardless, we are able to\njailbreak several open-source models and a closed-source model (GPT-4o). We\nshow an attack success rate (ASR) of 57% against GPT-4o; our attack earned a\nBug Bounty from OpenAI. Against open-source models protected by simple\ndefenses, we improve ASRs by an average of 3.25 times compared to the best\nperforming previous attacks that use only harmless data. NOICE demonstrates the\nexploitability of repetitive refusal mechanisms and broadens understanding of\nthe threats closed-source models face from harmless data.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19537v3",
    "published_date": "2025-02-26 20:20:01 UTC",
    "updated_date": "2025-04-01 18:57:07 UTC"
  },
  {
    "arxiv_id": "2502.19534v1",
    "title": "Retrieval Augmented Anomaly Detection (RAAD): Nimble Model Adjustment Without Retraining",
    "authors": [
      "Sam Pastoriza",
      "Iman Yousfi",
      "Christopher Redino",
      "Marc Vucovich",
      "Abdul Rahman",
      "Sal Aguinaga",
      "Dhruv Nandakumar"
    ],
    "abstract": "We propose a novel mechanism for real-time (human-in-the-loop) feedback\nfocused on false positive reduction to enhance anomaly detection models. It was\ndesigned for the lightweight deployment of a behavioral network anomaly\ndetection model. This methodology is easily integrable to similar domains that\nrequire a premium on throughput while maintaining high precision. In this\npaper, we introduce Retrieval Augmented Anomaly Detection, a novel method\ntaking inspiration from Retrieval Augmented Generation. Human annotated\nexamples are sent to a vector store, which can modify model outputs on the very\nnext processed batch for model inference. To demonstrate the generalization of\nthis technique, we benchmarked several different model architectures and\nmultiple data modalities, including images, text, and graph-based data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 3 figures. 2 tables, accepted at ISDFS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19534v1",
    "published_date": "2025-02-26 20:17:16 UTC",
    "updated_date": "2025-02-26 20:17:16 UTC"
  },
  {
    "arxiv_id": "2502.19529v1",
    "title": "Cognitive networks highlight differences and similarities in the STEM mindsets of human and LLM-simulated trainees, experts and academics",
    "authors": [
      "Edith Haim",
      "Lars van den Bergh",
      "Cynthia S. Q. Siew",
      "Yoed N. Kenett",
      "Daniele Marinazzo",
      "Massimo Stella"
    ],
    "abstract": "Understanding attitudes towards STEM means quantifying the cognitive and\nemotional ways in which individuals, and potentially large language models too,\nconceptualise such subjects. This study uses behavioural forma mentis networks\n(BFMNs) to investigate the STEM-focused mindset, i.e. ways of associating and\nperceiving ideas, of 177 human participants and 177 artificial humans simulated\nby GPT-3.5. Participants were split in 3 groups - trainees, experts and\nacademics - to compare the influence of expertise level on their mindset. The\nresults revealed that human forma mentis networks exhibited significantly\nhigher clustering coefficients compared to GPT-3.5, indicating that human\nmindsets displayed a tendency to form and close triads of conceptual\nassociations while recollecting STEM ideas. Human experts, in particular,\ndemonstrated robust clustering coefficients, reflecting better integration of\nSTEM concepts into their cognitive networks. In contrast, GPT-3.5 produced\nsparser mindsets. Furthermore, both human and GPT mindsets framed mathematics\nin neutral or positive terms, differently from STEM high schoolers, researchers\nand other large language models sampled in other works. This research\ncontributes to understanding how mindset structure can provide cognitive\ninsights about memory structure and machine limitations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T01 (Primary), 05C82 (Secondary)"
    ],
    "primary_category": "cs.CL",
    "comment": "Keywords: cognitive network science; mindset measurement; associative\n  knowledge; artificial intelligence; simulated participants",
    "pdf_url": "http://arxiv.org/pdf/2502.19529v1",
    "published_date": "2025-02-26 20:02:51 UTC",
    "updated_date": "2025-02-26 20:02:51 UTC"
  },
  {
    "arxiv_id": "2502.19519v2",
    "title": "Static Vs. Agentic Game Master AI for Facilitating Solo Role-Playing Experiences",
    "authors": [
      "Nicolai Hejlesen Jørgensen",
      "Sarmilan Tharmabalan",
      "Ilhan Aslan",
      "Nicolai Brodersen Hansen",
      "Timothy Merritt"
    ],
    "abstract": "This paper presents a game master AI for single-player role-playing games.\nThe AI is designed to deliver interactive text-based narratives and experiences\ntypically associated with multiplayer tabletop games like Dungeons & Dragons.\nWe report on the design process and the series of experiments to improve the\nfunctionality and experience design, resulting in two functional versions of\nthe system. While v1 of our system uses simplified prompt engineering, v2\nleverages a multi-agent architecture and the ReAct framework to include\nreasoning and action. A comparative evaluation demonstrates that v2 as an\nagentic system maintains play while significantly improving modularity and game\nexperience, including immersion and curiosity. Our findings contribute to the\nevolution of AI-driven interactive fiction, highlighting new avenues for\nenhancing solo role-playing experiences.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "17 pages, 10 figures, 1 table, submitted for review",
    "pdf_url": "http://arxiv.org/pdf/2502.19519v2",
    "published_date": "2025-02-26 19:42:22 UTC",
    "updated_date": "2025-03-06 16:21:14 UTC"
  },
  {
    "arxiv_id": "2502.19518v2",
    "title": "Assessing LLMs for Front-end Software Architecture Knowledge",
    "authors": [
      "L. P. Franciscatto Guerra",
      "N. Ernst"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant promise in\nautomating software development tasks, yet their capabilities with respect to\nsoftware design tasks remains largely unclear. This study investigates the\ncapabilities of an LLM in understanding, reproducing, and generating structures\nwithin the complex VIPER architecture, a design pattern for iOS applications.\nWe leverage Bloom's taxonomy to develop a comprehensive evaluation framework to\nassess the LLM's performance across different cognitive domains such as\nremembering, understanding, applying, analyzing, evaluating, and creating.\nExperimental results, using ChatGPT 4 Turbo 2024-04-09, reveal that the LLM\nexcelled in higher-order tasks like evaluating and creating, but faced\nchallenges with lower-order tasks requiring precise retrieval of architectural\ndetails. These findings highlight both the potential of LLMs to reduce\ndevelopment costs and the barriers to their effective application in real-world\nsoftware design scenarios. This study proposes a benchmark format for assessing\nLLM capabilities in software architecture, aiming to contribute toward more\nrobust and accessible AI-driven development tools.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2; I.2"
    ],
    "primary_category": "cs.SE",
    "comment": "4 pages, 1 figure, to appear in the International Workshop on\n  Designing Software at ICSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19518v2",
    "published_date": "2025-02-26 19:33:35 UTC",
    "updated_date": "2025-03-10 01:43:42 UTC"
  },
  {
    "arxiv_id": "2502.19513v2",
    "title": "Mixtraining: A Better Trade-Off Between Compute and Performance",
    "authors": [
      "Zexin Li",
      "Jiancheng Zhang",
      "Yufei Li",
      "Yinglun Zhu",
      "Cong Liu"
    ],
    "abstract": "Incorporating self-supervised learning (SSL) before standard supervised\nlearning (SL) has become a widely used strategy to enhance model performance,\nparticularly in data-limited scenarios. However, this approach introduces a\ntrade-off between computation and performance: while SSL helps with\nrepresentation learning, it requires a separate, often time-consuming training\nphase, increasing computational overhead and limiting efficiency in\nresource-constrained settings. To address these challenges, we propose\nMixTraining, a novel framework that interleaves several SSL and SL epochs\nwithin a unified mixtraining training phase, featuring a smooth transition\nbetween two learning objectives. MixTraining enhances synergy between SSL and\nSL for improved accuracy and consolidates shared computation steps to reduce\ncomputation overhead. MixTraining is versatile and applicable to both\nsingle-task and multi-task learning scenarios. Extensive experiments\ndemonstrate that MixTraining offers a superior compute-performance trade-off\ncompared to conventional pipelines, achieving an 8.81% absolute accuracy gain\n(18.89% relative accuracy gain) on the TinyImageNet dataset while accelerating\ntraining by up to 1.29x\n  with the ViT-Tiny model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19513v2",
    "published_date": "2025-02-26 19:25:27 UTC",
    "updated_date": "2025-03-05 03:40:47 UTC"
  },
  {
    "arxiv_id": "2502.19507v1",
    "title": "Building Knowledge Graphs Towards a Global Food Systems Datahub",
    "authors": [
      "Nirmal Gelal",
      "Aastha Gautam",
      "Sanaz Saki Norouzi",
      "Nico Giordano",
      "Claudio Dias da Silva Jr",
      "Jean Ribert Francois",
      "Kelsey Andersen Onofre",
      "Katherine Nelson",
      "Stacy Hutchinson",
      "Xiaomao Lin",
      "Stephen Welch",
      "Romulo Lollato",
      "Pascal Hitzler",
      "Hande Küçük McGinty"
    ],
    "abstract": "Sustainable agricultural production aligns with several sustainability goals\nestablished by the United Nations (UN). However, there is a lack of studies\nthat comprehensively examine sustainable agricultural practices across various\nproducts and production methods. Such research could provide valuable insights\ninto the diverse factors influencing the sustainability of specific crops and\nproduce while also identifying practices and conditions that are universally\napplicable to all forms of agricultural production. While this research might\nhelp us better understand sustainability, the community would still need a\nconsistent set of vocabularies. These consistent vocabularies, which represent\nthe underlying datasets, can then be stored in a global food systems datahub.\nThe standardized vocabularies might help encode important information for\nfurther statistical analyses and AI/ML approaches in the datasets, resulting in\nthe research targeting sustainable agricultural production. A structured method\nof representing information in sustainability, especially for wheat production,\nis currently unavailable. In an attempt to address this gap, we are building a\nset of ontologies and Knowledge Graphs (KGs) that encode knowledge associated\nwith sustainable wheat production using formal logic. The data for this set of\nknowledge graphs are collected from public data sources, experimental results\ncollected at our experiments at Kansas State University, and a Sustainability\nWorkshop that we organized earlier in the year, which helped us collect input\nfrom different stakeholders throughout the value chain of wheat. The modeling\nof the ontology (i.e., the schema) for the Knowledge Graph has been in progress\nwith the help of our domain experts, following a modular structure using KNARM\nmethodology. In this paper, we will present our preliminary results and schemas\nof our Knowledge Graph and ontologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19507v1",
    "published_date": "2025-02-26 19:13:11 UTC",
    "updated_date": "2025-02-26 19:13:11 UTC"
  },
  {
    "arxiv_id": "2502.19500v1",
    "title": "Conversational Planning for Personal Plans",
    "authors": [
      "Konstantina Christakopoulou",
      "Iris Qu",
      "John Canny",
      "Andrew Goodridge",
      "Cj Adams",
      "Minmin Chen",
      "Maja Matarić"
    ],
    "abstract": "The language generation and reasoning capabilities of large language models\n(LLMs) have enabled conversational systems with impressive performance in a\nvariety of tasks, from code generation, to composing essays, to passing STEM\nand legal exams, to a new paradigm for knowledge search. Besides those\nshort-term use applications, LLMs are increasingly used to help with real-life\ngoals or tasks that take a long time to complete, involving multiple sessions\nacross days, weeks, months, or even years. Thus to enable conversational\nsystems for long term interactions and tasks, we need language-based agents\nthat can plan for long horizons. Traditionally, such capabilities were\naddressed by reinforcement learning agents with hierarchical planning\ncapabilities. In this work, we explore a novel architecture where the LLM acts\nas the meta-controller deciding the agent's next macro-action, and tool use\naugmented LLM-based option policies execute the selected macro-action. We\ninstantiate this framework for a specific set of macro-actions enabling\nadaptive planning for users' personal plans through conversation and follow-up\nquestions collecting user feedback. We show how this paradigm can be applicable\nin scenarios ranging from tutoring for academic and non-academic tasks to\nconversational coaching for personal health plans.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19500v1",
    "published_date": "2025-02-26 19:04:26 UTC",
    "updated_date": "2025-02-26 19:04:26 UTC"
  },
  {
    "arxiv_id": "2502.19417v1",
    "title": "Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models",
    "authors": [
      "Lucy Xiaoyang Shi",
      "Brian Ichter",
      "Michael Equi",
      "Liyiming Ke",
      "Karl Pertsch",
      "Quan Vuong",
      "James Tanner",
      "Anna Walling",
      "Haohuan Wang",
      "Niccolo Fusai",
      "Adrian Li-Bell",
      "Danny Driess",
      "Lachy Groom",
      "Sergey Levine",
      "Chelsea Finn"
    ],
    "abstract": "Generalist robots that can perform a range of different tasks in open-world\nsettings must be able to not only reason about the steps needed to accomplish\ntheir goals, but also process complex instructions, prompts, and even feedback\nduring task execution. Intricate instructions (e.g., \"Could you make me a\nvegetarian sandwich?\" or \"I don't like that one\") require not just the ability\nto physically perform the individual steps, but the ability to situate complex\ncommands and feedback in the physical world. In this work, we describe a system\nthat uses vision-language models in a hierarchical structure, first reasoning\nover complex prompts and user feedback to deduce the most appropriate next step\nto fulfill the task, and then performing that step with low-level actions. In\ncontrast to direct instruction following methods that can fulfill simple\ncommands (\"pick up the cup\"), our system can reason through complex prompts and\nincorporate situated feedback during task execution (\"that's not trash\"). We\nevaluate our system across three robotic platforms, including single-arm,\ndual-arm, and dual-arm mobile robots, demonstrating its ability to handle tasks\nsuch as cleaning messy tables, making sandwiches, and grocery shopping.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19417v1",
    "published_date": "2025-02-26 18:58:41 UTC",
    "updated_date": "2025-02-26 18:58:41 UTC"
  },
  {
    "arxiv_id": "2502.19416v1",
    "title": "Norm Growth and Stability Challenges in Localized Sequential Knowledge Editing",
    "authors": [
      "Akshat Gupta",
      "Christine Fang",
      "Atahan Ozdemir",
      "Maochuan Lu",
      "Ahmed Alaa",
      "Thomas Hartvigsen",
      "Gopala Anumanchipalli"
    ],
    "abstract": "This study investigates the impact of localized updates to large language\nmodels (LLMs), specifically in the context of knowledge editing - a task aimed\nat incorporating or modifying specific facts without altering broader model\ncapabilities. We first show that across different post-training interventions\nlike continuous pre-training, full fine-tuning and LORA-based fine-tuning, the\nFrobenius norm of the updated matrices always increases. This increasing norm\nis especially detrimental for localized knowledge editing, where only a subset\nof matrices are updated in a model . We reveal a consistent phenomenon across\nvarious editing techniques, including fine-tuning, hypernetwork-based\napproaches, and locate-and-edit methods: the norm of the updated matrix\ninvariably increases with successive updates. Such growth disrupts model\nbalance, particularly when isolated matrices are updated while the rest of the\nmodel remains static, leading to potential instability and degradation of\ndownstream performance. Upon deeper investigations of the intermediate\nactivation vectors, we find that the norm of internal activations decreases and\nis accompanied by shifts in the subspaces occupied by these activations, which\nshows that these activation vectors now occupy completely different regions in\nthe representation space compared to the unedited model. With our paper, we\nhighlight the technical challenges with continuous and localized sequential\nknowledge editing and their implications for maintaining model stability and\nutility.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for Oral Presentation at KnowFM @ AAAI 2025. arXiv admin\n  note: text overlap with arXiv:2502.01636",
    "pdf_url": "http://arxiv.org/pdf/2502.19416v1",
    "published_date": "2025-02-26 18:58:30 UTC",
    "updated_date": "2025-02-26 18:58:30 UTC"
  },
  {
    "arxiv_id": "2502.19413v2",
    "title": "Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs",
    "authors": [
      "Christoph Schuhmann",
      "Gollam Rabby",
      "Ameya Prabhu",
      "Tawsif Ahmed",
      "Andreas Hochlehnert",
      "Huu Nguyen",
      "Nick Akinci",
      "Ludwig Schmidt",
      "Robert Kaczmarczyk",
      "Sören Auer",
      "Jenia Jitsev",
      "Matthias Bethge"
    ],
    "abstract": "Paywalls, licenses and copyright rules often restrict the broad dissemination\nand reuse of scientific knowledge. We take the position that it is both legally\nand technically feasible to extract the scientific knowledge in scholarly\ntexts. Current methods, like text embeddings, fail to reliably preserve factual\ncontent, and simple paraphrasing may not be legally sound. We propose a new\nidea for the community to adopt: convert scholarly documents into knowledge\npreserving, but style agnostic representations we term Knowledge Units using\nLLMs. These units use structured data capturing entities, attributes and\nrelationships without stylistic content. We provide evidence that Knowledge\nUnits (1) form a legally defensible framework for sharing knowledge from\ncopyrighted research texts, based on legal analyses of German copyright law and\nU.S. Fair Use doctrine, and (2) preserve most (~95\\%) factual knowledge from\noriginal text, measured by MCQ performance on facts from the original\ncopyrighted text across four research domains. Freeing scientific knowledge\nfrom copyright promises transformative benefits for scientific research and\neducation by allowing language models to reuse important facts from copyrighted\ntext. To support this, we share open-source tools for converting research\ndocuments into Knowledge Units. Overall, our work posits the feasibility of\ndemocratizing access to scientific knowledge while respecting copyright.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2502.19413v2",
    "published_date": "2025-02-26 18:56:52 UTC",
    "updated_date": "2025-04-18 15:48:01 UTC"
  },
  {
    "arxiv_id": "2503.00054v1",
    "title": "Deciphering the complaint aspects: Towards an aspect-based complaint identification model with video complaint dataset in finance",
    "authors": [
      "Sarmistha Das",
      "Basha Mujavarsheik",
      "R E Zera Lyngkhoi",
      "Sriparna Saha",
      "Alka Maurya"
    ],
    "abstract": "In today's competitive marketing landscape, effective complaint management is\ncrucial for customer service and business success. Video complaints,\nintegrating text and image content, offer invaluable insights by addressing\ncustomer grievances and delineating product benefits and drawbacks. However,\ncomprehending nuanced complaint aspects within vast daily multimodal financial\ndata remains a formidable challenge. Addressing this gap, we have curated a\nproprietary multimodal video complaint dataset comprising 433 publicly\naccessible instances. Each instance is meticulously annotated at the utterance\nlevel, encompassing five distinct categories of financial aspects and their\nassociated complaint labels. To support this endeavour, we introduce Solution\n3.0, a model designed for multimodal aspect-based complaint identification\ntask. Solution 3.0 is tailored to perform three key tasks: 1) handling\nmultimodal features ( audio and video), 2) facilitating multilabel aspect\nclassification, and 3) conducting multitasking for aspect classifications and\ncomplaint identification parallelly. Solution 3.0 utilizes a CLIP-based dual\nfrozen encoder with an integrated image segment encoder for global feature\nfusion, enhanced by contextual attention (ISEC) to improve accuracy and\nefficiency. Our proposed framework surpasses current multimodal baselines,\nexhibiting superior performance across nearly all metrics by opening new ways\nto strengthen appropriate customer care initiatives and effectively assisting\nindividuals in resolving their problems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00054v1",
    "published_date": "2025-02-26 18:56:07 UTC",
    "updated_date": "2025-02-26 18:56:07 UTC"
  },
  {
    "arxiv_id": "2502.19411v1",
    "title": "Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and Reasoning-Driven Code Intelligence in LLMs",
    "authors": [
      "Dayu Yang",
      "Tianyang Liu",
      "Daoan Zhang",
      "Antoine Simoulin",
      "Xiaoyi Liu",
      "Yuwei Cao",
      "Zhaopu Teng",
      "Xin Qian",
      "Grey Yang",
      "Jiebo Luo",
      "Julian McAuley"
    ],
    "abstract": "In large language models (LLMs), code and reasoning reinforce each other:\ncode offers an abstract, modular, and logic-driven structure that supports\nreasoning, while reasoning translates high-level goals into smaller, executable\nsteps that drive more advanced code intelligence. In this study, we examine how\ncode serves as a structured medium for enhancing reasoning: it provides\nverifiable execution paths, enforces logical decomposition, and enables runtime\nvalidation. We also explore how improvements in reasoning have transformed code\nintelligence from basic completion to advanced capabilities, enabling models to\naddress complex software engineering tasks through planning and debugging.\nFinally, we identify key challenges and propose future research directions to\nstrengthen this synergy, ultimately improving LLM's performance in both areas.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Project Repo: https://github.com/dayuyang1999/Awesome-Code-Reasoning",
    "pdf_url": "http://arxiv.org/pdf/2502.19411v1",
    "published_date": "2025-02-26 18:55:42 UTC",
    "updated_date": "2025-02-26 18:55:42 UTC"
  },
  {
    "arxiv_id": "2502.19410v1",
    "title": "Less or More: Towards Glanceable Explanations for LLM Recommendations Using Ultra-Small Devices",
    "authors": [
      "Xinru Wang",
      "Mengjie Yu",
      "Hannah Nguyen",
      "Michael Iuzzolino",
      "Tianyi Wang",
      "Peiqi Tang",
      "Natasha Lynova",
      "Co Tran",
      "Ting Zhang",
      "Naveen Sendhilnathan",
      "Hrvoje Benko",
      "Haijun Xia",
      "Tanya Jonker"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable potential in recommending\neveryday actions as personal AI assistants, while Explainable AI (XAI)\ntechniques are being increasingly utilized to help users understand why a\nrecommendation is given. Personal AI assistants today are often located on\nultra-small devices such as smartwatches, which have limited screen space. The\nverbosity of LLM-generated explanations, however, makes it challenging to\ndeliver glanceable LLM explanations on such ultra-small devices. To address\nthis, we explored 1) spatially structuring an LLM's explanation text using\ndefined contextual components during prompting and 2) presenting temporally\nadaptive explanations to users based on confidence levels. We conducted a user\nstudy to understand how these approaches impacted user experiences when\ninteracting with LLM recommendations and explanations on ultra-small devices.\nThe results showed that structured explanations reduced users' time to action\nand cognitive load when reading an explanation. Always-on structured\nexplanations increased users' acceptance of AI recommendations. However, users\nwere less satisfied with structured explanations compared to unstructured ones\ndue to their lack of sufficient, readable details. Additionally, adaptively\npresenting structured explanations was less effective at improving user\nperceptions of the AI compared to the always-on structured explanations.\nTogether with users' interview feedback, the results led to design implications\nto be mindful of when personalizing the content and timing of LLM explanations\nthat are displayed on ultra-small devices.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19410v1",
    "published_date": "2025-02-26 18:55:26 UTC",
    "updated_date": "2025-02-26 18:55:26 UTC"
  },
  {
    "arxiv_id": "2502.19400v1",
    "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding",
    "authors": [
      "Max Ku",
      "Thomas Chong",
      "Jonathan Leung",
      "Krish Shah",
      "Alvin Yu",
      "Wenhu Chen"
    ],
    "abstract": "Understanding domain-specific theorems often requires more than just\ntext-based reasoning; effective communication through structured visual\nexplanations is crucial for deeper comprehension. While large language models\n(LLMs) demonstrate strong performance in text-based theorem reasoning, their\nability to generate coherent and pedagogically meaningful visual explanations\nremains an open challenge. In this work, we introduce TheoremExplainAgent, an\nagentic approach for generating long-form theorem explanation videos (over 5\nminutes) using Manim animations. To systematically evaluate multimodal theorem\nexplanations, we propose TheoremExplainBench, a benchmark covering 240 theorems\nacross multiple STEM disciplines, along with 5 automated evaluation metrics.\nOur results reveal that agentic planning is essential for generating detailed\nlong-form videos, and the o3-mini agent achieves a success rate of 93.8% and an\noverall score of 0.77. However, our quantitative and qualitative studies show\nthat most of the videos produced exhibit minor issues with visual element\nlayout. Furthermore, multimodal explanations expose deeper reasoning flaws that\ntext-based explanations fail to reveal, highlighting the importance of\nmultimodal explanations.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19400v1",
    "published_date": "2025-02-26 18:50:09 UTC",
    "updated_date": "2025-02-26 18:50:09 UTC"
  },
  {
    "arxiv_id": "2502.19390v2",
    "title": "Multi-modal Contrastive Learning for Tumor-specific Missing Modality Synthesis",
    "authors": [
      "Minjoo Lim",
      "Bogyeong Kang",
      "Tae-Eui Kam"
    ],
    "abstract": "Multi-modal magnetic resonance imaging (MRI) is essential for providing\ncomplementary information about brain anatomy and pathology, leading to more\naccurate diagnoses. However, obtaining high-quality multi-modal MRI in a\nclinical setting is difficult due to factors such as time constraints, high\ncosts, and patient movement artifacts. To overcome this difficulty, there is\nincreasing interest in developing generative models that can synthesize missing\ntarget modality images from the available source ones. Therefore, our team,\nPLAVE, design a generative model for missing MRI that integrates multi-modal\ncontrastive learning with a focus on critical tumor regions. Specifically, we\nintegrate multi-modal contrastive learning, tailored for multiple source\nmodalities, and enhance its effectiveness by selecting features based on\nentropy during the contrastive learning process. Additionally, our network not\nonly generates the missing target modality images but also predicts\nsegmentation outputs, simultaneously. This approach improves the generator's\ncapability to precisely generate tumor regions, ultimately improving\nperformance in downstream segmentation tasks. By leveraging a combination of\ncontrastive, segmentation, and additional self-representation losses, our model\neffectively reflects target-specific information and generate high-quality\ntarget images. Consequently, our results in the Brain MR Image Synthesis\nchallenge demonstrate that the proposed model excelled in generating the\nmissing modality.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19390v2",
    "published_date": "2025-02-26 18:34:58 UTC",
    "updated_date": "2025-04-12 04:37:26 UTC"
  },
  {
    "arxiv_id": "2502.19386v1",
    "title": "Efficient 4D fMRI ASD Classification using Spatial-Temporal-Omics-based Learning Framework",
    "authors": [
      "Ziqiao Weng",
      "Weidong Cai",
      "Bo Zhou"
    ],
    "abstract": "Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder impacting\nsocial and behavioral development. Resting-state fMRI, a non-invasive tool for\ncapturing brain connectivity patterns, aids in early ASD diagnosis and\ndifferentiation from typical controls (TC). However, previous methods, which\nrely on either mean time series or full 4D data, are limited by a lack of\nspatial information or by high computational costs. This underscores the need\nfor an efficient solution that preserves both spatial and temporal information.\nIn this paper, we propose a novel, simple, and efficient spatial-temporal-omics\nlearning framework designed to efficiently extract spatio-temporal features\nfrom fMRI for ASD classification. Our approach addresses these limitations by\nutilizing 3D time-domain derivatives as the spatial-temporal inter-voxel omics,\nwhich preserve full spatial resolution while capturing diverse statistical\ncharacteristics of the time series at each voxel. Meanwhile, functional\nconnectivity features serve as the spatial-temporal inter-regional omics,\ncapturing correlations across brain regions. Extensive experiments and ablation\nstudies on the ABIDE dataset demonstrate that our framework significantly\noutperforms previous methods while maintaining computational efficiency. We\nbelieve our research offers valuable insights that will inform and advance\nfuture ASD studies, particularly in the realm of spatial-temporal-omics-based\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at 2025 IEEE International Symposium on Biomedical Imaging\n  (ISBI)",
    "pdf_url": "http://arxiv.org/pdf/2502.19386v1",
    "published_date": "2025-02-26 18:31:07 UTC",
    "updated_date": "2025-02-26 18:31:07 UTC"
  },
  {
    "arxiv_id": "2502.19377v1",
    "title": "Preference-Based Gradient Estimation for ML-Based Approximate Combinatorial Optimization",
    "authors": [
      "Arman Mielke",
      "Uwe Bauknecht",
      "Thilo Strauss",
      "Mathias Niepert"
    ],
    "abstract": "Combinatorial optimization (CO) problems arise in a wide range of fields from\nmedicine to logistics and manufacturing. While exact solutions are often not\nnecessary, many applications require finding high-quality solutions quickly.\nFor this purpose, we propose a data-driven approach to improve existing\nnon-learned approximation algorithms for CO. We parameterize the approximation\nalgorithm and train a graph neural network (GNN) to predict parameter values\nthat lead to the best possible solutions. Our pipeline is trained end-to-end in\na self-supervised fashion using gradient estimation, treating the approximation\nalgorithm as a black box. We propose a novel gradient estimation scheme for\nthis purpose, which we call preference-based gradient estimation. Our approach\ncombines the benefits of the neural network and the non-learned approximation\nalgorithm: The GNN leverages the information from the dataset to allow the\napproximation algorithm to find better solutions, while the approximation\nalgorithm guarantees that the solution is feasible. We validate our approach on\ntwo well-known combinatorial optimization problems, the travelling salesman\nproblem and the minimum k-cut problem, and show that our method is competitive\nwith state of the art learned CO solvers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preliminary work, under review",
    "pdf_url": "http://arxiv.org/pdf/2502.19377v1",
    "published_date": "2025-02-26 18:23:07 UTC",
    "updated_date": "2025-02-26 18:23:07 UTC"
  },
  {
    "arxiv_id": "2503.01880v1",
    "title": "BEYONDWORDS is All You Need: Agentic Generative AI based Social Media Themes Extractor",
    "authors": [
      "Mohammed-Khalil Ghali",
      "Abdelrahman Farrag",
      "Sarah Lam",
      "Daehan Won"
    ],
    "abstract": "Thematic analysis of social media posts provides a major understanding of\npublic discourse, yet traditional methods often struggle to capture the\ncomplexity and nuance of unstructured, large-scale text data. This study\nintroduces a novel methodology for thematic analysis that integrates tweet\nembeddings from pre-trained language models, dimensionality reduction using and\nmatrix factorization, and generative AI to identify and refine latent themes.\nOur approach clusters compressed tweet representations and employs generative\nAI to extract and articulate themes through an agentic Chain of Thought (CoT)\nprompting, with a secondary LLM for quality assurance. This methodology is\napplied to tweets from the autistic community, a group that increasingly uses\nsocial media to discuss their experiences and challenges. By automating the\nthematic extraction process, the aim is to uncover key insights while\nmaintaining the richness of the original discourse. This autism case study\ndemonstrates the utility of the proposed approach in improving thematic\nanalysis of social media data, offering a scalable and adaptable framework that\ncan be applied to diverse contexts. The results highlight the potential of\ncombining machine learning and Generative AI to enhance the depth and accuracy\nof theme identification in online communities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01880v1",
    "published_date": "2025-02-26 18:18:37 UTC",
    "updated_date": "2025-02-26 18:18:37 UTC"
  },
  {
    "arxiv_id": "2502.19363v3",
    "title": "DataMan: Data Manager for Pre-training Large Language Models",
    "authors": [
      "Ru Peng",
      "Kexin Yang",
      "Yawen Zeng",
      "Junyang Lin",
      "Dayiheng Liu",
      "Junbo Zhao"
    ],
    "abstract": "The performance emergence of large language models (LLMs) driven by data\nscaling laws makes the selection of pre-training data increasingly important.\nHowever, existing methods rely on limited heuristics and human intuition,\nlacking comprehensive and clear guidelines. To address this, we are inspired by\n``reverse thinking'' -- prompting LLMs to self-identify which criteria benefit\nits performance. As its pre-training capabilities are related to perplexity\n(PPL), we derive 14 quality criteria from the causes of text perplexity\nanomalies and introduce 15 common application domains to support domain mixing.\nIn this paper, we train a Data Manager (DataMan) to learn quality ratings and\ndomain recognition from pointwise rating, and use it to annotate a 447B token\npre-training corpus with 14 quality ratings and domain type. Our experiments\nvalidate our approach, using DataMan to select 30B tokens to train a\n1.3B-parameter language model, demonstrating significant improvements in\nin-context learning (ICL), perplexity, and instruction-following ability over\nthe state-of-the-art baseline. The best-performing model, based on the Overall\nScore l=5 surpasses a model trained with 50% more data using uniform sampling.\nWe continue pre-training with high-rated, domain-specific data annotated by\nDataMan to enhance domain-specific ICL performance and thus verify DataMan's\ndomain mixing ability. Our findings emphasize the importance of quality\nranking, the complementary nature of quality criteria, and their low\ncorrelation with perplexity, analyzing misalignment between PPL and ICL\nperformance. We also thoroughly analyzed our pre-training dataset, examining\nits composition, the distribution of quality ratings, and the original document\nsources.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR2025 paper",
    "pdf_url": "http://arxiv.org/pdf/2502.19363v3",
    "published_date": "2025-02-26 18:01:19 UTC",
    "updated_date": "2025-04-08 03:21:10 UTC"
  },
  {
    "arxiv_id": "2502.19357v1",
    "title": "Physics-Based Hybrid Machine Learning for Critical Heat Flux Prediction with Uncertainty Quantification",
    "authors": [
      "Aidan Furlong",
      "Xingang Zhao",
      "Robert Salko",
      "Xu Wu"
    ],
    "abstract": "Critical heat flux is a key quantity in boiling system modeling due to its\nimpact on heat transfer and component temperature and performance. This study\ninvestigates the development and validation of an uncertainty-aware hybrid\nmodeling approach that combines machine learning with physics-based models in\nthe prediction of critical heat flux in nuclear reactors for cases of dryout.\nTwo empirical correlations, Biasi and Bowring, were employed with three machine\nlearning uncertainty quantification techniques: deep neural network ensembles,\nBayesian neural networks, and deep Gaussian processes. A pure machine learning\nmodel without a base model served as a baseline for comparison. This study\nexamines the performance and uncertainty of the models under both plentiful and\nlimited training data scenarios using parity plots, uncertainty distributions,\nand calibration curves. The results indicate that the Biasi hybrid deep neural\nnetwork ensemble achieved the most favorable performance (with a mean absolute\nrelative error of 1.846% and stable uncertainty estimates), particularly in the\nplentiful data scenario. The Bayesian neural network models showed slightly\nhigher error and uncertainty but superior calibration. By contrast, deep\nGaussian process models underperformed by most metrics. All hybrid models\noutperformed pure machine learning configurations, demonstrating resistance\nagainst data scarcity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to the International Journal of Heat and Mass Transfer",
    "pdf_url": "http://arxiv.org/pdf/2502.19357v1",
    "published_date": "2025-02-26 17:55:01 UTC",
    "updated_date": "2025-02-26 17:55:01 UTC"
  },
  {
    "arxiv_id": "2502.19351v1",
    "title": "Deep Learning-Based Transfer Learning for Classification of Cassava Disease",
    "authors": [
      "Ademir G. Costa Junior",
      "Fábio S. da Silva",
      "Ricardo Rios"
    ],
    "abstract": "This paper presents a performance comparison among four Convolutional Neural\nNetwork architectures (EfficientNet-B3, InceptionV3, ResNet50, and VGG16) for\nclassifying cassava disease images. The images were sourced from an imbalanced\ndataset from a competition. Appropriate metrics were employed to address class\nimbalance. The results indicate that EfficientNet-B3 achieved on this task\naccuracy of 87.7%, precision of 87.8%, revocation of 87.8% and F1-Score of\n87.7%. These findings suggest that EfficientNet-B3 could be a valuable tool to\nsupport Digital Agriculture.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "I.5.1; I.5.4"
    ],
    "primary_category": "eess.IV",
    "comment": "12 pages, in Portuguese language, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19351v1",
    "published_date": "2025-02-26 17:50:01 UTC",
    "updated_date": "2025-02-26 17:50:01 UTC"
  },
  {
    "arxiv_id": "2502.19347v1",
    "title": "Controlled Diversity: Length-optimized Natural Language Generation",
    "authors": [
      "Diana Marie Schenke",
      "Timo Baumann"
    ],
    "abstract": "LLMs are not generally able to adjust the length of their outputs based on\nstrict length requirements, a capability that would improve their usefulness in\napplications that require adherence to diverse user and system requirements. We\npresent an approach to train LLMs to acquire this capability by augmenting\nexisting data and applying existing fine-tuning techniques, which we compare\nbased on the trained models' adherence to the length requirement and overall\nresponse quality relative to the baseline model. Our results demonstrate that\nthese techniques can be successfully applied to train LLMs to adhere to length\nrequirements, with the trained models generating texts which better align to\nthe length requirements. Our results indicate that our method may change the\nresponse quality when using training data that was not generated by the\nbaseline model. This allows simultaneous alignment to another training\nobjective in certain scenarios, but is undesirable otherwise. Training on a\ndataset containing the model's own responses eliminates this issue.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ISCA/ITG Workshop on Diversity in Large Speech and Language Models",
    "pdf_url": "http://arxiv.org/pdf/2502.19347v1",
    "published_date": "2025-02-26 17:38:58 UTC",
    "updated_date": "2025-02-26 17:38:58 UTC"
  },
  {
    "arxiv_id": "2502.19334v1",
    "title": "Joint Optimal Transport and Embedding for Network Alignment",
    "authors": [
      "Qi Yu",
      "Zhichen Zeng",
      "Yuchen Yan",
      "Lei Ying",
      "R. Srikant",
      "Hanghang Tong"
    ],
    "abstract": "Network alignment, which aims to find node correspondence across different\nnetworks, is the cornerstone of various downstream multi-network and Web mining\ntasks. Most of the embedding-based methods indirectly model cross-network node\nrelationships by contrasting positive and negative node pairs sampled from\nhand-crafted strategies, which are vulnerable to graph noises and lead to\npotential misalignment of nodes. Another line of work based on the optimal\ntransport (OT) theory directly models cross-network node relationships and\ngenerates noise-reduced alignments. However, OT methods heavily rely on fixed,\npre-defined cost functions that prohibit end-to-end training and are hard to\ngeneralize. In this paper, we aim to unify the embedding and OT-based methods\nin a mutually beneficial manner and propose a joint optimal transport and\nembedding framework for network alignment named JOENA. For one thing (OT for\nembedding), through a simple yet effective transformation, the noise-reduced OT\nmapping serves as an adaptive sampling strategy directly modeling all\ncross-network node pairs for robust embedding learning.For another (embedding\nfor OT), on top of the learned embeddings, the OT cost can be gradually trained\nin an end-to-end fashion, which further enhances the alignment quality. With a\nunified objective, the mutual benefits of both methods can be achieved by an\nalternating optimization schema with guaranteed convergence. Extensive\nexperiments on real-world networks validate the effectiveness and scalability\nof JOENA, achieving up to 16% improvement in MRR and 20x speedup compared with\nthe state-of-the-art alignment methods.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19334v1",
    "published_date": "2025-02-26 17:28:08 UTC",
    "updated_date": "2025-02-26 17:28:08 UTC"
  },
  {
    "arxiv_id": "2502.19328v1",
    "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems",
    "authors": [
      "Hao Peng",
      "Yunjia Qi",
      "Xiaozhi Wang",
      "Zijun Yao",
      "Bin Xu",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Reward models (RMs) are crucial for the training and inference-time scaling\nup of large language models (LLMs). However, existing reward models primarily\nfocus on human preferences, neglecting verifiable correctness signals which\nhave shown strong potential in training LLMs. In this paper, we propose agentic\nreward modeling, a reward system that combines reward models with verifiable\ncorrectness signals from different aspects to provide reliable rewards. We\nempirically implement a reward agent, named RewardAgent, that combines human\npreference rewards with two verifiable signals: factuality and instruction\nfollowing, to provide more reliable rewards. We conduct comprehensive\nexperiments on existing reward model benchmarks and inference time best-of-n\nsearches on real-world downstream tasks. RewardAgent significantly outperforms\nvanilla reward models, demonstrating its effectiveness. We further construct\ntraining preference pairs using RewardAgent and train an LLM with the DPO\nobjective, achieving superior performance on various NLP benchmarks compared to\nconventional reward models. Our codes are publicly released to facilitate\nfurther research (https://github.com/THU-KEG/Agentic-Reward-Modeling).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19328v1",
    "published_date": "2025-02-26 17:19:12 UTC",
    "updated_date": "2025-02-26 17:19:12 UTC"
  },
  {
    "arxiv_id": "2502.19325v1",
    "title": "Partition Tree Weighting for Non-Stationary Stochastic Bandits",
    "authors": [
      "Joel Veness",
      "Marcus Hutter",
      "Andras Gyorgy",
      "Jordi Grau-Moya"
    ],
    "abstract": "This paper considers a generalisation of universal source coding for\ninteraction data, namely data streams that have actions interleaved with\nobservations. Our goal will be to construct a coding distribution that is both\nuniversal \\emph{and} can be used as a control policy. Allowing for action\ngeneration needs careful treatment, as naive approaches which do not\ndistinguish between actions and observations run into the self-delusion problem\nin universal settings. We showcase our perspective in the context of the\nchallenging non-stationary stochastic Bernoulli bandit problem. Our main\ncontribution is an efficient and high performing algorithm for this problem\nthat generalises the Partition Tree Weighting universal source coding technique\nfor passive prediction to the control setting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19325v1",
    "published_date": "2025-02-26 17:16:33 UTC",
    "updated_date": "2025-02-26 17:16:33 UTC"
  },
  {
    "arxiv_id": "2502.19320v2",
    "title": "Shh, don't say that! Domain Certification in LLMs",
    "authors": [
      "Cornelius Emde",
      "Alasdair Paren",
      "Preetham Arvind",
      "Maxime Kayser",
      "Tom Rainforth",
      "Thomas Lukasiewicz",
      "Bernard Ghanem",
      "Philip H. S. Torr",
      "Adel Bibi"
    ],
    "abstract": "Large language models (LLMs) are often deployed to perform constrained tasks,\nwith narrow domains. For example, customer support bots can be built on top of\nLLMs, relying on their broad language understanding and capabilities to enhance\nperformance. However, these LLMs are adversarially susceptible, potentially\ngenerating outputs outside the intended domain. To formalize, assess, and\nmitigate this risk, we introduce domain certification; a guarantee that\naccurately characterizes the out-of-domain behavior of language models. We then\npropose a simple yet effective approach, which we call VALID that provides\nadversarial bounds as a certificate. Finally, we evaluate our method across a\ndiverse set of datasets, demonstrating that it yields meaningful certificates,\nwhich bound the probability of out-of-domain samples tightly with minimum\npenalty to refusal behavior.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, includes appendix Published in International Conference on\n  Learning Representations (ICLR) 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19320v2",
    "published_date": "2025-02-26 17:13:19 UTC",
    "updated_date": "2025-03-06 21:49:11 UTC"
  },
  {
    "arxiv_id": "2502.19312v1",
    "title": "FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users",
    "authors": [
      "Anikait Singh",
      "Sheryl Hsu",
      "Kyle Hsu",
      "Eric Mitchell",
      "Stefano Ermon",
      "Tatsunori Hashimoto",
      "Archit Sharma",
      "Chelsea Finn"
    ],
    "abstract": "Effective personalization of LLMs is critical for a broad range of\nuser-interfacing applications such as virtual assistants and content curation.\nInspired by the strong in-context learning capabilities of LLMs, we propose\nFew-Shot Preference Optimization (FSPO), which reframes reward modeling as a\nmeta-learning problem. Under this framework, an LLM learns to quickly adapt to\na user via a few labeled preferences from that user, constructing a\npersonalized reward function for them. Additionally, since real-world\npreference data is scarce and challenging to collect at scale, we propose\ncareful design choices to construct synthetic preference datasets for\npersonalization, generating over 1M synthetic personalized preferences using\npublicly available LLMs. In particular, to successfully transfer from synthetic\ndata to real users, we find it crucial for the data to exhibit both high\ndiversity and coherent, self-consistent structure. We evaluate FSPO on\npersonalized open-ended generation for up to 1,500 synthetic users across\nacross three domains: movie reviews, pedagogical adaptation based on\neducational background, and general question answering, along with a controlled\nhuman study. Overall, FSPO achieves an 87% Alpaca Eval winrate on average in\ngenerating responses that are personalized to synthetic users and a 72% winrate\nwith real human users in open-ended question answering.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Website: https://fewshot-preference-optimization.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.19312v1",
    "published_date": "2025-02-26 17:08:46 UTC",
    "updated_date": "2025-02-26 17:08:46 UTC"
  },
  {
    "arxiv_id": "2502.19311v1",
    "title": "Faithful Logic Embeddings in HOL -- A recipe to have it all: deep and shallow, automated and interactive, heavy and light, proofs and counterexamples, meta and object level",
    "authors": [
      "Christoph Benzmüller"
    ],
    "abstract": "Deep and shallow embeddings of non-classical logics in classical higher-order\nlogic have been explored, implemented, and used in various automated reasoning\ntools in recent years. This paper presents a recipe for the simultaneous\ndeployment of different forms of deep and shallow embeddings in classical\nhigher-order logic, enabling not only flexible interactive and automated\ntheorem proving and counterexample finding at meta and object level, but also\nautomated faithfulness proofs between the logic embeddings. The approach, which\nis fruitful for logic education, research and application, is deliberately\nillustrated here using simple propositional modal logic. However, the work\npresented is conceptual in nature and not limited to such a simple logic\ncontext.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "math.LO",
      "03Axx, 03Bxx, 03B15, 68T15",
      "F.4; I.2.3; I.2.4"
    ],
    "primary_category": "cs.LO",
    "comment": "22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19311v1",
    "published_date": "2025-02-26 17:08:07 UTC",
    "updated_date": "2025-02-26 17:08:07 UTC"
  },
  {
    "arxiv_id": "2502.19308v2",
    "title": "WOFOSTGym: A Crop Simulator for Learning Annual and Perennial Crop Management Strategies",
    "authors": [
      "William Solow",
      "Sandhya Saisubramanian",
      "Alan Fern"
    ],
    "abstract": "We introduce WOFOSTGym, a novel crop simulation environment designed to train\nreinforcement learning (RL) agents to optimize agromanagement decisions for\nannual and perennial crops in single and multi-farm settings. Effective crop\nmanagement requires optimizing yield and economic returns while minimizing\nenvironmental impact, a complex sequential decision-making problem well suited\nfor RL. However, the lack of simulators for perennial crops in multi-farm\ncontexts has hindered RL applications in this domain. Existing crop simulators\nalso do not support multiple annual crops. WOFOSTGym addresses these gaps by\nsupporting 23 annual crops and two perennial crops, enabling RL agents to learn\ndiverse agromanagement strategies in multi-year, multi-crop, and multi-farm\nsettings. Our simulator offers a suite of challenging tasks for learning under\npartial observability, non-Markovian dynamics, and delayed feedback.\nWOFOSTGym's standard RL interface allows researchers without agricultural\nexpertise to explore a wide range of agromanagement problems. Our experiments\ndemonstrate the learned behaviors across various crop varieties and soil types,\nhighlighting WOFOSTGym's potential for advancing RL-driven decision support in\nagriculture.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19308v2",
    "published_date": "2025-02-26 17:07:11 UTC",
    "updated_date": "2025-02-27 03:35:09 UTC"
  },
  {
    "arxiv_id": "2502.19307v1",
    "title": "Anomaly Detection in Complex Dynamical Systems: A Systematic Framework Using Embedding Theory and Physics-Inspired Consistency",
    "authors": [
      "Michael Somma",
      "Thomas Gallien",
      "Branka Stojanovic"
    ],
    "abstract": "Anomaly detection in complex dynamical systems is essential for ensuring\nreliability, safety, and efficiency in industrial and cyber-physical\ninfrastructures. Predictive maintenance helps prevent costly failures, while\ncybersecurity monitoring has become critical as digitized systems face growing\nthreats. Many of these systems exhibit oscillatory behaviors and bounded\nmotion, requiring anomaly detection methods that capture structured temporal\ndependencies while adhering to physical consistency principles. In this work,\nwe propose a system-theoretic approach to anomaly detection, grounded in\nclassical embedding theory and physics-inspired consistency principles. We\nbuild upon the Fractal Whitney Embedding Prevalence Theorem, extending\ntraditional embedding techniques to complex system dynamics. Additionally, we\nintroduce state-derivative pairs as an embedding strategy to capture system\nevolution. To enforce temporal coherence, we develop a Temporal Differential\nConsistency Autoencoder (TDC-AE), incorporating a TDC-Loss that aligns the\napproximated derivatives of latent variables with their dynamic\nrepresentations. We evaluate our method on the C-MAPSS dataset, a benchmark for\nturbofan aeroengine degradation. TDC-AE outperforms LSTMs and Transformers\nwhile achieving a 200x reduction in MAC operations, making it particularly\nsuited for lightweight edge computing. Our findings support the hypothesis that\nanomalies disrupt stable system dynamics, providing a robust, interpretable\nsignal for anomaly detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19307v1",
    "published_date": "2025-02-26 17:06:13 UTC",
    "updated_date": "2025-02-26 17:06:13 UTC"
  },
  {
    "arxiv_id": "2502.19305v1",
    "title": "Corporate Fraud Detection in Rich-yet-Noisy Financial Graph",
    "authors": [
      "Shiqi Wang",
      "Zhibo Zhang",
      "Libing Fang",
      "Cam-Tu Nguyen",
      "Wenzhon Li"
    ],
    "abstract": "Corporate fraud detection aims to automatically recognize companies that\nconduct wrongful activities such as fraudulent financial statements or illegal\ninsider trading. Previous learning-based methods fail to effectively integrate\nrich interactions in the company network. To close this gap, we collect 18-year\nfinancial records in China to form three graph datasets with fraud labels. We\nanalyze the characteristics of the financial graphs, highlighting two\npronounced issues: (1) information overload: the dominance of (noisy)\nnon-company nodes over company nodes hinders the message-passing process in\nGraph Convolution Networks (GCN); and (2) hidden fraud: there exists a large\npercentage of possible undetected violations in the collected data. The hidden\nfraud problem will introduce noisy labels in the training dataset and\ncompromise fraud detection results. To handle such challenges, we propose a\nnovel graph-based method, namely, Knowledge-enhanced GCN with Robust Two-stage\nLearning (${\\rm KeGCN}_{R}$), which leverages Knowledge Graph Embeddings to\nmitigate the information overload and effectively learns rich representations.\nThe proposed model adopts a two-stage learning method to enhance robustness\nagainst hidden frauds. Extensive experimental results not only confirm the\nimportance of interactions but also show the superiority of ${\\rm KeGCN}_{R}$\nover a number of strong baselines in terms of fraud detection effectiveness and\nrobustness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.RM",
      "q-fin.ST"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19305v1",
    "published_date": "2025-02-26 17:05:54 UTC",
    "updated_date": "2025-02-26 17:05:54 UTC"
  },
  {
    "arxiv_id": "2503.00053v1",
    "title": "AI and Semantic Communication for Infrastructure Monitoring in 6G-Driven Drone Swarms",
    "authors": [
      "Tasnim Ahmed",
      "Salimur Choudhury"
    ],
    "abstract": "The adoption of unmanned aerial vehicles to monitor critical infrastructure\nis gaining momentum in various industrial domains. Organizational imperatives\ndrive this progression to minimize expenses, accelerate processes, and mitigate\nhazards faced by inspection personnel. However, traditional infrastructure\nmonitoring systems face critical bottlenecks-5G networks lack the latency and\nreliability for large-scale drone coordination, while manual inspections remain\ncostly and slow. We propose a 6G-enabled drone swarm system that integrates\nultra-reliable, low-latency communications, edge AI, and semantic communication\nto automate inspections. By adopting LLMs for structured output and report\ngeneration, our framework is hypothesized to reduce inspection costs and\nimprove fault detection speed compared to existing methods.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00053v1",
    "published_date": "2025-02-26 17:05:35 UTC",
    "updated_date": "2025-02-26 17:05:35 UTC"
  },
  {
    "arxiv_id": "2502.19297v1",
    "title": "Combining Planning and Reinforcement Learning for Solving Relational Multiagent Domains",
    "authors": [
      "Nikhilesh Prabhakar",
      "Ranveer Singh",
      "Harsha Kokel",
      "Sriraam Natarajan",
      "Prasad Tadepalli"
    ],
    "abstract": "Multiagent Reinforcement Learning (MARL) poses significant challenges due to\nthe exponential growth of state and action spaces and the non-stationary nature\nof multiagent environments. This results in notable sample inefficiency and\nhinders generalization across diverse tasks. The complexity is further\npronounced in relational settings, where domain knowledge is crucial but often\nunderutilized by existing MARL algorithms. To overcome these hurdles, we\npropose integrating relational planners as centralized controllers with\nefficient state abstractions and reinforcement learning. This approach proves\nto be sample-efficient and facilitates effective task transfer and\ngeneralization.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19297v1",
    "published_date": "2025-02-26 16:55:23 UTC",
    "updated_date": "2025-02-26 16:55:23 UTC"
  },
  {
    "arxiv_id": "2502.19295v1",
    "title": "Complex LLM Planning via Automated Heuristics Discovery",
    "authors": [
      "Hongyi Ling",
      "Shubham Parashar",
      "Sambhav Khurana",
      "Blake Olson",
      "Anwesha Basu",
      "Gaurangi Sinha",
      "Zhengzhong Tu",
      "James Caverlee",
      "Shuiwang Ji"
    ],
    "abstract": "We consider enhancing large language models (LLMs) for complex planning\ntasks. While existing methods allow LLMs to explore intermediate steps to make\nplans, they either depend on unreliable self-verification or external verifiers\nto evaluate these steps, which demand significant data and computations. Here,\nwe propose automated heuristics discovery (AutoHD), a novel approach that\nenables LLMs to explicitly generate heuristic functions to guide inference-time\nsearch, allowing accurate evaluation of intermediate states. These heuristic\nfunctions are further refined through a heuristic evolution process, improving\ntheir robustness and effectiveness. Our proposed method requires no additional\nmodel training or fine-tuning, and the explicit definition of heuristic\nfunctions generated by the LLMs provides interpretability and insights into the\nreasoning process. Extensive experiments across diverse benchmarks demonstrate\nsignificant gains over multiple baselines, including nearly twice the accuracy\non some datasets, establishing our approach as a reliable and interpretable\nsolution for complex planning tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19295v1",
    "published_date": "2025-02-26 16:52:31 UTC",
    "updated_date": "2025-02-26 16:52:31 UTC"
  },
  {
    "arxiv_id": "2503.00052v1",
    "title": "RURA-Net: A general disease diagnosis method based on Zero-Shot Learning",
    "authors": [
      "Yan Su",
      "Qiulin Wu",
      "Weizhen Li",
      "Chengchang Pan",
      "Honggang Qi"
    ],
    "abstract": "The training of deep learning models relies on a large amount of labeled\ndata. However, the high cost of medical labeling seriously hinders the\ndevelopment of deep learning in the medical field. Our study proposes a general\ndisease diagnosis approach based on Zero-Shot Learning. The Siamese neural\nnetwork is used to find similar diseases for the target diseases, and the U-Net\nsegmentation model is used to accurately segment the key lesions of the\ndisease. Finally, based on the ResNet-Agglomerative clustering algorithm, a\nclustering model is trained on a large number of sample data of similar\ndiseases to obtain a approximate diagnosis of the target disease. Zero-Shot\nLearning of the target disease is then successfully achieved. To evaluate the\nvalidity of the model, we validated our method on a dataset of ophthalmic\ndiseases in CFP modality. The external dataset was used to test its\nperformance, and the accuracy=0.8395, precision=0.8094, recall=0.8463, F1\nScore=0.8274, AUC=0.9226, which exceeded the indexes of most Few-Shot Learning\nand One-Shot Learning models. It proves that our method has great potential and\nreference value in the medical field, where annotation data is usually scarce\nand expensive to obtain.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 3 figures, 6 tables, submitted to The 28th International\n  Conference on Medical Image Computing and Computer Assisted Intervention\n  (MICCAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.00052v1",
    "published_date": "2025-02-26 16:41:32 UTC",
    "updated_date": "2025-02-26 16:41:32 UTC"
  },
  {
    "arxiv_id": "2502.19281v1",
    "title": "Integrating Biological and Machine Intelligence: Attention Mechanisms in Brain-Computer Interfaces",
    "authors": [
      "Jiyuan Wang",
      "Weishan Ye",
      "Jialin He",
      "Li Zhang",
      "Gan Huang",
      "Zhuliang Yu",
      "Zhen Liang"
    ],
    "abstract": "With the rapid advancement of deep learning, attention mechanisms have become\nindispensable in electroencephalography (EEG) signal analysis, significantly\nenhancing Brain-Computer Interface (BCI) applications. This paper presents a\ncomprehensive review of traditional and Transformer-based attention mechanisms,\ntheir embedding strategies, and their applications in EEG-based BCI, with a\nparticular emphasis on multimodal data fusion. By capturing EEG variations\nacross time, frequency, and spatial channels, attention mechanisms improve\nfeature extraction, representation learning, and model robustness. These\nmethods can be broadly categorized into traditional attention mechanisms, which\ntypically integrate with convolutional and recurrent networks, and\nTransformer-based multi-head self-attention, which excels in capturing\nlong-range dependencies. Beyond single-modality analysis, attention mechanisms\nalso enhance multimodal EEG applications, facilitating effective fusion between\nEEG and other physiological or sensory data. Finally, we discuss existing\nchallenges and emerging trends in attention-based EEG modeling, highlighting\nfuture directions for advancing BCI technology. This review aims to provide\nvaluable insights for researchers seeking to leverage attention mechanisms for\nimproved EEG interpretation and application.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19281v1",
    "published_date": "2025-02-26 16:38:28 UTC",
    "updated_date": "2025-02-26 16:38:28 UTC"
  },
  {
    "arxiv_id": "2502.19271v1",
    "title": "Multiview graph dual-attention deep learning and contrastive learning for multi-criteria recommender systems",
    "authors": [
      "Saman Forouzandeh",
      "Pavel N. Krivitsky",
      "Rohitash Chandra"
    ],
    "abstract": "Recommender systems leveraging deep learning models have been crucial for\nassisting users in selecting items aligned with their preferences and\ninterests. However, a significant challenge persists in single-criteria\nrecommender systems, which often overlook the diverse attributes of items that\nhave been addressed by Multi-Criteria Recommender Systems (MCRS). Shared\nembedding vector for multi-criteria item ratings but have struggled to capture\nthe nuanced relationships between users and items based on specific criteria.\nIn this study, we present a novel representation for Multi-Criteria Recommender\nSystems (MCRS) based on a multi-edge bipartite graph, where each edge\nrepresents one criterion rating of items by users, and Multiview Dual Graph\nAttention Networks (MDGAT). Employing MDGAT is beneficial and important for\nadequately considering all relations between users and items, given the\npresence of both local (criterion-based) and global (multi-criteria) relations.\nAdditionally, we define anchor points in each view based on similarity and\nemploy local and global contrastive learning to distinguish between positive\nand negative samples across each view and the entire graph. We evaluate our\nmethod on two real-world datasets and assess its performance based on item\nrating predictions. The results demonstrate that our method achieves higher\naccuracy compared to the baseline method for predicting item ratings on the\nsame datasets. MDGAT effectively capture the local and global impact of\nneighbours and the similarity between nodes.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19271v1",
    "published_date": "2025-02-26 16:25:58 UTC",
    "updated_date": "2025-02-26 16:25:58 UTC"
  },
  {
    "arxiv_id": "2503.05782v1",
    "title": "AI Mentors for Student Projects: Spotting Early Issues in Computer Science Proposals",
    "authors": [
      "Gati Aher",
      "Robin Schmucker",
      "Tom Mitchell",
      "Zachary C. Lipton"
    ],
    "abstract": "When executed well, project-based learning (PBL) engages students' intrinsic\nmotivation, encourages students to learn far beyond a course's limited\ncurriculum, and prepares students to think critically and maturely about the\nskills and tools at their disposal. However, educators experience mixed results\nwhen using PBL in their classrooms: some students thrive with minimal guidance\nand others flounder. Early evaluation of project proposals could help educators\ndetermine which students need more support, yet evaluating project proposals\nand student aptitude is time-consuming and difficult to scale. In this work, we\ndesign, implement, and conduct an initial user study (n = 36) for a software\nsystem that collects project proposals and aptitude information to support\neducators in determining whether a student is ready to engage with PBL. We find\nthat (1) users perceived the system as helpful for writing project proposals\nand identifying tools and technologies to learn more about, (2) educator\nratings indicate that users with less technical experience in the project topic\ntend to write lower-quality project proposals, and (3) GPT-4o's ratings show\nagreement with educator ratings. While the prospect of using LLMs to rate the\nquality of students' project proposals is promising, its long-term\neffectiveness strongly hinges on future efforts at characterizing indicators\nthat reliably predict students' success and motivation to learn.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted for oral presentation at Workshop on Innovation and\n  Responsibility in AI-Supported Education (iRAISE), AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.05782v1",
    "published_date": "2025-02-26 16:24:14 UTC",
    "updated_date": "2025-02-26 16:24:14 UTC"
  },
  {
    "arxiv_id": "2503.01878v1",
    "title": "District Vitality Index Using Machine Learning Methods for Urban Planners",
    "authors": [
      "Sylvain Marcoux",
      "Jean-Sébastien Dessureault"
    ],
    "abstract": "City leaders face critical decisions regarding budget allocation and\ninvestment priorities. How can they identify which city districts require\nrevitalization? To address this challenge, a Current Vitality Index and a\nLong-Term Vitality Index are proposed. These indexes are based on a carefully\ncurated set of indicators. Missing data is handled using K-Nearest Neighbors\nimputation, while Random Forest is employed to identify the most reliable and\nsignificant features. Additionally, k-means clustering is utilized to generate\nmeaningful data groupings for enhanced monitoring of Long-Term Vitality.\nCurrent vitality is visualized through an interactive map, while Long-Term\nVitality is tracked over 15 years with predictions made using Multilayer\nPerceptron or Linear Regression. The results, approved by urban planners, are\nalready promising and helpful, with the potential for further improvement as\nmore data becomes available. This paper proposes leveraging machine learning\nmethods to optimize urban planning and enhance citizens' quality of life.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01878v1",
    "published_date": "2025-02-26 16:17:38 UTC",
    "updated_date": "2025-02-26 16:17:38 UTC"
  },
  {
    "arxiv_id": "2502.19261v2",
    "title": "Drop-Upcycling: Training Sparse Mixture of Experts with Partial Re-initialization",
    "authors": [
      "Taishi Nakamura",
      "Takuya Akiba",
      "Kazuki Fujii",
      "Yusuke Oda",
      "Rio Yokota",
      "Jun Suzuki"
    ],
    "abstract": "The Mixture of Experts (MoE) architecture reduces the training and inference\ncost significantly compared to a dense model of equivalent capacity. Upcycling\nis an approach that initializes and trains an MoE model using a pre-trained\ndense model. While upcycling leads to initial performance gains, the training\nprogresses slower than when trained from scratch, leading to suboptimal\nperformance in the long term. We propose Drop-Upcycling - a method that\neffectively addresses this problem. Drop-Upcycling combines two seemingly\ncontradictory approaches: utilizing the knowledge of pre-trained dense models\nwhile statistically re-initializing some parts of the weights. This approach\nstrategically promotes expert specialization, significantly enhancing the MoE\nmodel's efficiency in knowledge acquisition. Extensive large-scale experiments\ndemonstrate that Drop-Upcycling significantly outperforms previous MoE\nconstruction methods in the long term, specifically when training on hundreds\nof billions of tokens or more. As a result, our MoE model with 5.9B active\nparameters achieves comparable performance to a 13B dense model in the same\nmodel family, while requiring approximately 1/4 of the training FLOPs. All\nexperimental resources, including source code, training data, model checkpoints\nand logs, are publicly available to promote reproducibility and future research\non MoE.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at the 13th International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.19261v2",
    "published_date": "2025-02-26 16:06:36 UTC",
    "updated_date": "2025-03-15 14:50:33 UTC"
  },
  {
    "arxiv_id": "2502.19260v3",
    "title": "EMT: A Visual Multi-Task Benchmark Dataset for Autonomous Driving in the Arab Gulf Region",
    "authors": [
      "Nadya Abdel Madjid",
      "Murad Mebrahtu",
      "Abdelmoamen Nasser",
      "Bilal Hassan",
      "Naoufel Werghi",
      "Jorge Dias",
      "Majid Khonji"
    ],
    "abstract": "This paper introduces the Emirates Multi-Task (EMT) dataset, designed to\nsupport multi-task benchmarking within a unified framework. It comprises over\n30,000 frames from a dash-camera perspective and 570,000 annotated bounding\nboxes, covering approximately 150 kilometers of driving routes that reflect the\ndistinctive road topology, congestion patterns, and driving behavior of Gulf\nregion traffic. The dataset supports three primary tasks: tracking, trajectory\nforecasting, and intention prediction. Each benchmark is accompanied by\ncorresponding evaluations: (1) multi-agent tracking experiments addressing\nmulti-class scenarios and occlusion handling; (2) trajectory forecasting\nevaluation using deep sequential and interaction-aware models; and (3)\nintention prediction experiments based on observed trajectories. The dataset is\npublicly available at https://avlab.io/emt-dataset, with pre-processing scripts\nand evaluation models at https://github.com/AV-Lab/emt-dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19260v3",
    "published_date": "2025-02-26 16:06:35 UTC",
    "updated_date": "2025-04-25 12:00:46 UTC"
  },
  {
    "arxiv_id": "2502.19257v2",
    "title": "Poster: Long PHP webshell files detection based on sliding window attention",
    "authors": [
      "Zhiqiang Wang",
      "Haoyu Wang",
      "Lu Hao"
    ],
    "abstract": "Webshell is a type of backdoor, and web applications are widely exposed to\nwebshell injection attacks. Therefore, it is important to study webshell\ndetection techniques. In this study, we propose a webshell detection method. We\nfirst convert PHP source code to opcodes and then extract Opcode Double-Tuples\n(ODTs). Next, we combine CodeBert and FastText models for feature\nrepresentation and classification. To address the challenge that deep learning\nmethods have difficulty detecting long webshell files, we introduce a sliding\nwindow attention mechanism. This approach effectively captures malicious\nbehavior within long files. Experimental results show that our method reaches\nhigh accuracy in webshell detection, solving the problem of traditional methods\nthat struggle to address new webshell variants and anti-detection techniques.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "3 pages(include 1 page poster), 1 figure. Accepted as a poster at the\n  NDSS 2025. Poster list:\n  http://www.ndss-symposium.org/ndss2025/accepted-posters/. Dataset/code\n  available at\n  http://github.com/w-32768/PHP-Webshell-Detection-via-Opcode-Analysis",
    "pdf_url": "http://arxiv.org/pdf/2502.19257v2",
    "published_date": "2025-02-26 16:04:17 UTC",
    "updated_date": "2025-02-27 12:36:55 UTC"
  },
  {
    "arxiv_id": "2502.19255v3",
    "title": "Can RLHF be More Efficient with Imperfect Reward Models? A Policy Coverage Perspective",
    "authors": [
      "Jiawei Huang",
      "Bingcong Li",
      "Christoph Dann",
      "Niao He"
    ],
    "abstract": "Sample efficiency is critical for online Reinforcement Learning from Human\nFeedback (RLHF). While existing works investigate sample-efficient online\nexploration strategies, the potential of utilizing misspecified yet relevant\nreward models to accelerate learning remains underexplored. This paper studies\nhow to transfer knowledge from those imperfect reward models in online RLHF. We\nstart by identifying a novel property due to KL-regularization in the RLHF\nobjective: \\emph{a policy's coverability of the optimal policy is captured by\nits sub-optimality}. Building on this insight, we propose novel transfer\nlearning principles and a theoretical algorithm -- \\emph{\\textbf{T}ransfer\n\\textbf{P}olicy \\textbf{O}ptimization (\\textbf{TPO})} -- with provable benefits\ncompared to standard online learning. Empirically, inspired by our theoretical\nfindings, we develop a win-rate-based transfer policy selection strategy with\nimproved computational efficiency. Moreover, our empirical transfer learning\ntechnique is modular and can be integrated with various policy optimization\nmethods, such as DPO, IPO and XPO, to further enhance their performance. We\nvalidate the effectiveness of our method through experiments on summarization\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "36 Pages; ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19255v3",
    "published_date": "2025-02-26 16:03:06 UTC",
    "updated_date": "2025-05-18 12:49:16 UTC"
  },
  {
    "arxiv_id": "2502.19252v2",
    "title": "GraphBridge: Towards Arbitrary Transfer Learning in GNNs",
    "authors": [
      "Li Ju",
      "Xingyi Yang",
      "Qi Li",
      "Xinchao Wang"
    ],
    "abstract": "Graph neural networks (GNNs) are conventionally trained on a per-domain,\nper-task basis. It creates a significant barrier in transferring the acquired\nknowledge to different, heterogeneous data setups. This paper introduces\nGraphBridge, a novel framework to enable knowledge transfer across disparate\ntasks and domains in GNNs, circumventing the need for modifications to task\nconfigurations or graph structures. Specifically, GraphBridge allows for the\naugmentation of any pre-trained GNN with prediction heads and a bridging\nnetwork that connects the input to the output layer. This architecture not only\npreserves the intrinsic knowledge of the original model but also supports\noutputs of arbitrary dimensions. To mitigate the negative transfer problem,\nGraphBridge merges the source model with a concurrently trained model, thereby\nreducing the source bias when applied to the target domain. Our method is\nthoroughly evaluated across diverse transfer learning scenarios, including\nGraph2Graph, Node2Node, Graph2Node, and graph2point-cloud. Empirical\nvalidation, conducted over 16 datasets representative of these scenarios,\nconfirms the framework's capacity for task- and domain-agnostic transfer\nlearning within graph-like data, marking a significant advancement in the field\nof GNNs. Code is available at https://github.com/jujulili888/GraphBridge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures, 6 tables, to be published in ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19252v2",
    "published_date": "2025-02-26 15:57:51 UTC",
    "updated_date": "2025-03-01 16:10:27 UTC"
  },
  {
    "arxiv_id": "2502.19249v1",
    "title": "Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases",
    "authors": [
      "Michael Y. Hu",
      "Jackson Petty",
      "Chuan Shi",
      "William Merrill",
      "Tal Linzen"
    ],
    "abstract": "Pretraining language models on formal languages can improve their acquisition\nof natural language, but it is unclear which features of the formal language\nimpart an inductive bias that leads to effective transfer. Drawing on insights\nfrom linguistics and complexity theory, we hypothesize that effective transfer\noccurs when the formal language both captures dependency structures in natural\nlanguage and remains within the computational limitations of the model\narchitecture. Focusing on transformers, we find that formal languages with both\nthese properties enable language models to achieve lower loss on natural\nlanguage and better linguistic generalization compared to other languages. In\nfact, pre-pretraining, or training on formal-then-natural language, reduces\nloss more efficiently than the same amount of natural language. For a\n1B-parameter language model trained on roughly 1.6B tokens of natural language,\npre-pretraining achieves the same loss and better linguistic generalization\nwith a 33% smaller token budget. We also give mechanistic evidence of\ncross-task transfer from formal to natural language: attention heads acquired\nduring formal language pretraining remain crucial for the model's performance\non syntactic evaluations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19249v1",
    "published_date": "2025-02-26 15:55:55 UTC",
    "updated_date": "2025-02-26 15:55:55 UTC"
  },
  {
    "arxiv_id": "2502.19231v3",
    "title": "AI-Powered Bayesian Inference",
    "authors": [
      "Sean O'Hagan",
      "Veronika Ročková"
    ],
    "abstract": "The advent of Generative Artificial Intelligence (GAI) has heralded an\ninflection point that changed how society thinks about knowledge acquisition.\nWhile GAI cannot be fully trusted for decision-making, it may still provide\nvaluable information that can be integrated into a decision pipeline. Rather\nthan seeing the lack of certitude and inherent randomness of GAI as a problem,\nwe view it as an opportunity. Indeed, variable answers to given prompts can be\nleveraged to construct a prior distribution which reflects assuredness of AI\npredictions. This prior distribution may be combined with tailored datasets for\na fully Bayesian analysis with an AI-driven prior. In this paper, we explore\nsuch a possibility within a non-parametric Bayesian framework. The basic idea\nconsists of assigning a Dirichlet process prior distribution on the\ndata-generating distribution with AI generative model as its baseline.\nHyper-parameters of the prior can be tuned out-of-sample to assess the\ninformativeness of the AI prior. Posterior simulation is achieved by computing\na suitably randomized functional on an augmented data that consists of observed\n(labeled) data as well as fake data whose labels have been imputed using AI.\nThis strategy can be parallelized and rapidly produces iid samples from the\nposterior by optimization as opposed to sampling from conditionals. Our method\nenables (predictive) inference and uncertainty quantification leveraging AI\npredictions in a coherent probabilistic manner.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "stat.ME",
    "comment": "44 pages, 4 figures; revised two figures, corrected typos",
    "pdf_url": "http://arxiv.org/pdf/2502.19231v3",
    "published_date": "2025-02-26 15:42:06 UTC",
    "updated_date": "2025-05-17 16:35:43 UTC"
  },
  {
    "arxiv_id": "2502.19227v2",
    "title": "Enhancing the Scalability and Applicability of Kohn-Sham Hamiltonians for Molecular Systems",
    "authors": [
      "Yunyang Li",
      "Zaishuo Xia",
      "Lin Huang",
      "Xinran Wei",
      "Han Yang",
      "Sam Harshe",
      "Zun Wang",
      "Chang Liu",
      "Jia Zhang",
      "Bin Shao",
      "Mark B. Gerstein"
    ],
    "abstract": "Density Functional Theory (DFT) is a pivotal method within quantum chemistry\nand materials science, with its core involving the construction and solution of\nthe Kohn-Sham Hamiltonian. Despite its importance, the application of DFT is\nfrequently limited by the substantial computational resources required to\nconstruct the Kohn-Sham Hamiltonian. In response to these limitations, current\nresearch has employed deep-learning models to efficiently predict molecular and\nsolid Hamiltonians, with roto-translational symmetries encoded in their neural\nnetworks. However, the scalability of prior models may be problematic when\napplied to large molecules, resulting in non-physical predictions of\nground-state properties. In this study, we generate a substantially larger\ntraining set (PubChemQH) than used previously and use it to create a scalable\nmodel for DFT calculations with physical accuracy. For our model, we introduce\na loss function derived from physical principles, which we call Wavefunction\nAlignment Loss (WALoss). WALoss involves performing a basis change on the\npredicted Hamiltonian to align it with the observed one; thus, the resulting\ndifferences can serve as a surrogate for orbital energy differences, allowing\nmodels to make better predictions for molecular orbitals and total energies\nthan previously possible. WALoss also substantially accelerates\nself-consistent-field (SCF) DFT calculations. Here, we show it achieves a\nreduction in total energy prediction error by a factor of 1347 and an SCF\ncalculation speed-up by a factor of 18%. These substantial improvements set new\nbenchmarks for achieving accurate and applicable predictions in larger\nmolecular systems.",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19227v2",
    "published_date": "2025-02-26 15:36:25 UTC",
    "updated_date": "2025-03-20 17:54:16 UTC"
  },
  {
    "arxiv_id": "2503.01877v2",
    "title": "Starjob: Dataset for LLM-Driven Job Shop Scheduling",
    "authors": [
      "Henrik Abgaryan",
      "Tristan Cazenave",
      "Ararat Harutyunyan"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious domains, but their potential for solving combinatorial optimization\nproblems remains largely unexplored. In this paper, we investigate the\napplicability of LLMs to the Job Shop Scheduling Problem (JSSP), a classic\nchallenge in combinatorial optimization that requires efficient job allocation\nto machines to minimize makespan. To this end, we introduce Starjob, the first\nsupervised dataset for JSSP, comprising 130k instances specifically designed\nfor training LLMs. Leveraging this dataset, we fine-tune the LLaMA 8B 4-bit\nquantized model with the LoRA method to develop an end-to-end scheduling\napproach. Our evaluation on standard benchmarks demonstrates that the proposed\nLLM-based method not only surpasses traditional Priority Dispatching Rules\n(PDRs) but also achieves notable improvements over state-of-the-art neural\napproaches like L2D, with an average improvement of 15.36% on DMU and 7.85% on\nTaillard benchmarks. These results highlight the untapped potential of LLMs in\ntackling combinatorial optimization problems, paving the way for future\nadvancements in this area.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2408.06993",
    "pdf_url": "http://arxiv.org/pdf/2503.01877v2",
    "published_date": "2025-02-26 15:20:01 UTC",
    "updated_date": "2025-03-27 10:38:45 UTC"
  },
  {
    "arxiv_id": "2502.19217v2",
    "title": "A Lightweight and Extensible Cell Segmentation and Classification Model for Whole Slide Images",
    "authors": [
      "Nikita Shvetsov",
      "Thomas K. Kilvaer",
      "Masoud Tafavvoghi",
      "Anders Sildnes",
      "Kajsa Møllersen",
      "Lill-Tove Rasmussen Busund",
      "Lars Ailo Bongo"
    ],
    "abstract": "Developing clinically useful cell-level analysis tools in digital pathology\nremains challenging due to limitations in dataset granularity, inconsistent\nannotations, high computational demands, and difficulties integrating new\ntechnologies into workflows. To address these issues, we propose a solution\nthat enhances data quality, model performance, and usability by creating a\nlightweight, extensible cell segmentation and classification model. First, we\nupdate data labels through cross-relabeling to refine annotations of PanNuke\nand MoNuSAC, producing a unified dataset with seven distinct cell types.\nSecond, we leverage the H-Optimus foundation model as a fixed encoder to\nimprove feature representation for simultaneous segmentation and classification\ntasks. Third, to address foundation models' computational demands, we distill\nknowledge to reduce model size and complexity while maintaining comparable\nperformance. Finally, we integrate the distilled model into QuPath, a widely\nused open-source digital pathology platform. Results demonstrate improved\nsegmentation and classification performance using the H-Optimus-based model\ncompared to a CNN-based model. Specifically, average $R^2$ improved from 0.575\nto 0.871, and average $PQ$ score improved from 0.450 to 0.492, indicating\nbetter alignment with actual cell counts and enhanced segmentation quality. The\ndistilled model maintains comparable performance while reducing parameter count\nby a factor of 48. By reducing computational complexity and integrating into\nworkflows, this approach may significantly impact diagnostics, reduce\npathologist workload, and improve outcomes. Although the method shows promise,\nextensive validation is necessary prior to clinical deployment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.6; I.4.9; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "30 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19217v2",
    "published_date": "2025-02-26 15:19:52 UTC",
    "updated_date": "2025-04-09 11:06:08 UTC"
  },
  {
    "arxiv_id": "2502.19463v1",
    "title": "Do LLMs exhibit demographic parity in responses to queries about Human Rights?",
    "authors": [
      "Rafiya Javed",
      "Jackie Kay",
      "David Yanni",
      "Abdullah Zaini",
      "Anushe Sheikh",
      "Maribeth Rauh",
      "Ramona Comanescu",
      "Iason Gabriel",
      "Laura Weidinger"
    ],
    "abstract": "This research describes a novel approach to evaluating hedging behaviour in\nlarge language models (LLMs), specifically in the context of human rights as\ndefined in the Universal Declaration of Human Rights (UDHR). Hedging and\nnon-affirmation are behaviours that express ambiguity or a lack of clear\nendorsement on specific statements. These behaviours are undesirable in certain\ncontexts, such as queries about whether different groups are entitled to\nspecific human rights; since all people are entitled to human rights. Here, we\npresent the first systematic attempt to measure these behaviours in the context\nof human rights, with a particular focus on between-group comparisons. To this\nend, we design a novel prompt set on human rights in the context of different\nnational or social identities. We develop metrics to capture hedging and\nnon-affirmation behaviours and then measure whether LLMs exhibit demographic\nparity when responding to the queries. We present results on three leading LLMs\nand find that all models exhibit some demographic disparities in how they\nattribute human rights between different identity groups. Futhermore, there is\nhigh correlation between different models in terms of how disparity is\ndistributed amongst identities, with identities that have high disparity in one\nmodel also facing high disparity in both the other models. While baseline rates\nof hedging and non-affirmation differ, these disparities are consistent across\nqueries that vary in ambiguity and they are robust across variations of the\nprecise query wording. Our findings highlight the need for work to explicitly\nalign LLMs to human rights principles, and to ensure that LLMs endorse the\nhuman rights of all groups equally.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19463v1",
    "published_date": "2025-02-26 15:19:35 UTC",
    "updated_date": "2025-02-26 15:19:35 UTC"
  },
  {
    "arxiv_id": "2502.19207v1",
    "title": "FaithUn: Toward Faithful Forgetting in Language Models by Investigating the Interconnectedness of Knowledge",
    "authors": [
      "Nakyeong Yang",
      "Minsung Kim",
      "Seunghyun Yoon",
      "Joongbo Shin",
      "Kyomin Jung"
    ],
    "abstract": "Various studies have attempted to remove sensitive or private knowledge from\na language model to prevent its unauthorized exposure. However, prior studies\nhave overlooked the complex and interconnected nature of knowledge, where\nrelated knowledge must be carefully examined. Specifically, they have failed to\nevaluate whether an unlearning method faithfully erases interconnected\nknowledge that should be removed, retaining knowledge that appears relevant but\nexists in a completely different context. To resolve this problem, we first\ndefine a new concept called superficial unlearning, which refers to the\nphenomenon where an unlearning method either fails to erase the interconnected\nknowledge it should remove or unintentionally erases irrelevant knowledge.\nBased on the definition, we introduce a new benchmark, FaithUn, to analyze and\nevaluate the faithfulness of unlearning in real-world knowledge QA settings.\nFurthermore, we propose a novel unlearning method, KLUE, which updates only\nknowledge-related neurons to achieve faithful unlearning. KLUE identifies\nknowledge neurons using an explainability method and updates only those neurons\nusing selected unforgotten samples. Experimental results demonstrate that\nwidely-used unlearning methods fail to ensure faithful unlearning, while our\nmethod shows significant effectiveness in real-world QA unlearning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.19207v1",
    "published_date": "2025-02-26 15:11:03 UTC",
    "updated_date": "2025-02-26 15:11:03 UTC"
  },
  {
    "arxiv_id": "2502.19199v1",
    "title": "EGR-Net: A Novel Embedding Gramian Representation CNN for Intelligent Fault Diagnosis",
    "authors": [
      "Linshan Jia"
    ],
    "abstract": "Feature extraction is crucial in intelligent fault diagnosis of rotating\nmachinery. It is easier for convolutional neural networks(CNNs) to visually\nrecognize and learn fault features by converting the complicated\none-dimensional (1D) vibrational signals into two-dimensional (2D) images with\nsimple textures. However, the existing representation methods for encoding 1D\nsignals as images have two main problems, including complicated computation and\nlow separability. Meanwhile, the existing 2D-CNN fault diagnosis methods taking\n2D images as the only inputs still suffer from the inevitable information loss\nbecause of the conversion process. Considering the above issues, this paper\nproposes a new 1D-to-2D conversion method called Embedding Gramian\nRepresentation (EGR), which is easy to calculate and shows good separability.\nIn EGR, 1D signals are projected in the embedding space and the intrinsic\nperiodicity of vibrational signals is captured enabling the faulty\ncharacteristics contained in raw signals to be uncovered. Second, aiming at the\ninformation loss problem of existing CNN models with the single input of\nconverted images, a double-branch EGR-based CNN, called EGR-Net, is proposed to\nlearn faulty features from both raw signal feature maps and their corresponding\nEGRs. The bridge connection is designed to improve the feature learning\ninteraction between the two branches. Widely used open domain gearbox dataset\nand bearing dataset are used to verify the effectiveness and efficiency of the\nproposed methods. EGR-Net is compared with traditional and state-of-the-art\napproaches, and the results show that the proposed method can deliver enhanced\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19199v1",
    "published_date": "2025-02-26 15:05:56 UTC",
    "updated_date": "2025-02-26 15:05:56 UTC"
  },
  {
    "arxiv_id": "2502.19193v1",
    "title": "Simulation of Language Evolution under Regulated Social Media Platforms: A Synergistic Approach of Large Language Models and Genetic Algorithms",
    "authors": [
      "Jinyu Cai",
      "Yusei Ishimizu",
      "Mingyue Zhang",
      "Munan Li",
      "Jialong Li",
      "Kenji Tei"
    ],
    "abstract": "Social media platforms frequently impose restrictive policies to moderate\nuser content, prompting the emergence of creative evasion language strategies.\nThis paper presents a multi-agent framework based on Large Language Models\n(LLMs) to simulate the iterative evolution of language strategies under\nregulatory constraints. In this framework, participant agents, as social media\nusers, continuously evolve their language expression, while supervisory agents\nemulate platform-level regulation by assessing policy violations. To achieve a\nmore faithful simulation, we employ a dual design of language strategies\n(constraint and expression) to differentiate conflicting goals and utilize an\nLLM-driven GA (Genetic Algorithm) for the selection, mutation, and crossover of\nlanguage strategies. The framework is evaluated using two distinct scenarios:\nan abstract password game and a realistic simulated illegal pet trade scenario.\nExperimental results demonstrate that as the number of dialogue rounds\nincreases, both the number of uninterrupted dialogue turns and the accuracy of\ninformation transmission improve significantly. Furthermore, a user study with\n40 participants validates the real-world relevance of the generated dialogues\nand strategies. Moreover, ablation studies validate the importance of the GA,\nemphasizing its contribution to long-term adaptability and improved overall\nresults.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.SI",
    "comment": "The manuscript has been submitted to IEEE Transactions on\n  Computational Social Systems",
    "pdf_url": "http://arxiv.org/pdf/2502.19193v1",
    "published_date": "2025-02-26 14:59:27 UTC",
    "updated_date": "2025-02-26 14:59:27 UTC"
  },
  {
    "arxiv_id": "2502.19190v1",
    "title": "Provocations from the Humanities for Generative AI Research",
    "authors": [
      "Lauren Klein",
      "Meredith Martin",
      "André Brock",
      "Maria Antoniak",
      "Melanie Walsh",
      "Jessica Marie Johnson",
      "Lauren Tilton",
      "David Mimno"
    ],
    "abstract": "This paper presents a set of provocations for considering the uses, impact,\nand harms of generative AI from the perspective of humanities researchers. We\nprovide a working definition of humanities research, summarize some of its most\nsalient theories and methods, and apply these theories and methods to the\ncurrent landscape of AI. Drawing from foundational work in critical data\nstudies, along with relevant humanities scholarship, we elaborate eight claims\nwith broad applicability to current conversations about generative AI: 1)\nModels make words, but people make meaning; 2) Generative AI requires an\nexpanded definition of culture; 3) Generative AI can never be representative;\n4) Bigger models are not always better models; 5) Not all training data is\nequivalent; 6) Openness is not an easy fix; 7) Limited access to compute\nenables corporate capture; and 8) AI universalism creates narrow human\nsubjects. We conclude with a discussion of the importance of resisting the\nextraction of humanities research by computer science and related fields.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0; K.4.0"
    ],
    "primary_category": "cs.CY",
    "comment": "working draft; final draft in preparation",
    "pdf_url": "http://arxiv.org/pdf/2502.19190v1",
    "published_date": "2025-02-26 14:55:55 UTC",
    "updated_date": "2025-02-26 14:55:55 UTC"
  },
  {
    "arxiv_id": "2503.02890v1",
    "title": "Predicting Cascade Failures in Interdependent Urban Infrastructure Networks",
    "authors": [
      "Yinzhou Tang",
      "Jinghua Piao",
      "Huandong Wang",
      "Shaw Rajib",
      "Yong Li"
    ],
    "abstract": "Cascading failures (CF) entail component breakdowns spreading through\ninfrastructure networks, causing system-wide collapse. Predicting CFs is of\ngreat importance for infrastructure stability and urban function. Despite\nextensive research on CFs in single networks such as electricity and road\nnetworks, interdependencies among diverse infrastructures remain overlooked,\nand capturing intra-infrastructure CF dynamics amid complex evolutions poses\nchallenges. To address these gaps, we introduce the \\textbf{I}ntegrated\n\\textbf{I}nterdependent \\textbf{I}nfrastructure CF model ($I^3$), designed to\ncapture CF dynamics both within and across infrastructures. $I^3$ employs a\ndual GAE with global pooling for intra-infrastructure dynamics and a\nheterogeneous graph for inter-infrastructure interactions. An initial node\nenhancement pre-training strategy mitigates GCN-induced over-smoothing.\nExperiments demonstrate $I^3$ achieves a 31.94\\% in terms of AUC, 18.03\\% in\nterms of Precision, 29.17\\% in terms of Recall, 22.73\\% in terms of F1-score\nboost in predicting infrastructure failures, and a 28.52\\% reduction in terms\nof RMSE for cascade volume forecasts compared to leading models. It accurately\npinpoints phase transitions in interconnected and singular networks, rectifying\nbiases in models tailored for singular networks. Access the code at\nhttps://github.com/tsinghua-fib-lab/Icube.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02890v1",
    "published_date": "2025-02-26 14:50:22 UTC",
    "updated_date": "2025-02-26 14:50:22 UTC"
  },
  {
    "arxiv_id": "2502.19180v1",
    "title": "AutoML for Multi-Class Anomaly Compensation of Sensor Drift",
    "authors": [
      "Melanie Schaller",
      "Mathis Kruse",
      "Antonio Ortega",
      "Marius Lindauer",
      "Bodo Rosenhahn"
    ],
    "abstract": "Addressing sensor drift is essential in industrial measurement systems, where\nprecise data output is necessary for maintaining accuracy and reliability in\nmonitoring processes, as it progressively degrades the performance of machine\nlearning models over time. Our findings indicate that the standard\ncross-validation method used in existing model training overestimates\nperformance by inadequately accounting for drift. This is primarily because\ntypical cross-validation techniques allow data instances to appear in both\ntraining and testing sets, thereby distorting the accuracy of the predictive\nevaluation. As a result, these models are unable to precisely predict future\ndrift effects, compromising their ability to generalize and adapt to evolving\ndata conditions. This paper presents two solutions: (1) a novel sensor drift\ncompensation learning paradigm for validating models, and (2) automated machine\nlearning (AutoML) techniques to enhance classification performance and\ncompensate sensor drift. By employing strategies such as data balancing,\nmeta-learning, automated ensemble learning, hyperparameter optimization,\nfeature selection, and boosting, our AutoML-DC (Drift Compensation) model\nsignificantly improves classification performance against sensor drift.\nAutoML-DC further adapts effectively to varying drift severities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in Measurement Journal",
    "pdf_url": "http://arxiv.org/pdf/2502.19180v1",
    "published_date": "2025-02-26 14:34:53 UTC",
    "updated_date": "2025-02-26 14:34:53 UTC"
  },
  {
    "arxiv_id": "2502.19175v1",
    "title": "MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis",
    "authors": [
      "Daniel Rose",
      "Chia-Chien Hung",
      "Marco Lepri",
      "Israa Alqassem",
      "Kiril Gashteovski",
      "Carolin Lawrence"
    ],
    "abstract": "Differential Diagnosis (DDx) is a fundamental yet complex aspect of clinical\ndecision-making, in which physicians iteratively refine a ranked list of\npossible diseases based on symptoms, antecedents, and medical knowledge. While\nrecent advances in large language models have shown promise in supporting DDx,\nexisting approaches face key limitations, including single-dataset evaluations,\nisolated optimization of components, unrealistic assumptions about complete\npatient profiles, and single-attempt diagnosis. We introduce a Modular\nExplainable DDx Agent (MEDDxAgent) framework designed for interactive DDx,\nwhere diagnostic reasoning evolves through iterative learning, rather than\nassuming a complete patient profile is accessible. MEDDxAgent integrates three\nmodular components: (1) an orchestrator (DDxDriver), (2) a history taking\nsimulator, and (3) two specialized agents for knowledge retrieval and diagnosis\nstrategy. To ensure robust evaluation, we introduce a comprehensive DDx\nbenchmark covering respiratory, skin, and rare diseases. We analyze single-turn\ndiagnostic approaches and demonstrate the importance of iterative refinement\nwhen patient profiles are not available at the outset. Our broad evaluation\ndemonstrates that MEDDxAgent achieves over 10% accuracy improvements in\ninteractive DDx across both large and small LLMs, while offering critical\nexplainability into its diagnostic reasoning process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19175v1",
    "published_date": "2025-02-26 14:31:43 UTC",
    "updated_date": "2025-02-26 14:31:43 UTC"
  },
  {
    "arxiv_id": "2502.19163v1",
    "title": "TestNUC: Enhancing Test-Time Computing Approaches through Neighboring Unlabeled Data Consistency",
    "authors": [
      "Henry Peng Zou",
      "Zhengyao Gu",
      "Yue Zhou",
      "Yankai Chen",
      "Weizhi Zhang",
      "Liancheng Fang",
      "Yibo Wang",
      "Yangning Li",
      "Kay Liu",
      "Philip S. Yu"
    ],
    "abstract": "Test-time computing approaches, which leverage additional computational\nresources during inference, have been proven effective in enhancing large\nlanguage model performance. This work introduces a novel, linearly scaling\napproach, TestNUC, that improves test-time predictions by leveraging the local\nconsistency of neighboring unlabeled data-it classifies an input instance by\nconsidering not only the model's prediction on that instance but also on\nneighboring unlabeled instances. We evaluate TestNUC across eight diverse\ndatasets, spanning intent classification, topic mining, domain discovery, and\nemotion detection, demonstrating its consistent superiority over baseline\nmethods such as standard prompting and self-consistency. Furthermore, TestNUC\ncan be seamlessly integrated with existing test-time computing approaches,\nsubstantially boosting their performance. Our analysis reveals that TestNUC\nscales effectively with increasing amounts of unlabeled data and performs\nrobustly across different embedding models, making it practical for real-world\napplications. Our code is available at https://github.com/HenryPengZou/TestNUC.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19163v1",
    "published_date": "2025-02-26 14:17:56 UTC",
    "updated_date": "2025-02-26 14:17:56 UTC"
  },
  {
    "arxiv_id": "2504.05323v1",
    "title": "Multi-Perspective Attention Mechanism for Bias-Aware Sequential Recommendation",
    "authors": [
      "Mingjian Fu",
      "Hengsheng Chen",
      "Dongchun Jiang",
      "Yanchao Tan"
    ],
    "abstract": "In the era of advancing information technology, recommender systems have\nemerged as crucial tools for dealing with information overload. However,\ntraditional recommender systems still have limitations in capturing the dynamic\nevolution of user behavior. To better understand and predict user behavior,\nespecially taking into account the complexity of temporal evolution, sequential\nrecommender systems have gradually become the focus of research. Currently,\nmany sequential recommendation algorithms ignore the amplification effects of\nprevalent biases, which leads to recommendation results being susceptible to\nthe Matthew Effect. Additionally, it will impose limitations on the recommender\nsystem's ability to deeply perceive and capture the dynamic shifts in user\npreferences, thereby diminishing the extent of its recommendation reach. To\naddress this issue effectively, we propose a recommendation system based on\nsequential information and attention mechanism called Multi-Perspective\nAttention Bias Sequential Recommendation (MABSRec). Firstly, we reconstruct\nuser sequences into three short types and utilize graph neural networks for\nitem weighting. Subsequently, an adaptive multi-bias perspective attention\nmodule is proposed to enhance the accuracy of recommendations. Experimental\nresults show that the MABSRec model exhibits significant advantages in all\nevaluation metrics, demonstrating its excellent performance in the sequence\nrecommendation task.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "I.2"
    ],
    "primary_category": "cs.IR",
    "comment": "30 pages,10 figures,4 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.05323v1",
    "published_date": "2025-02-26 14:16:58 UTC",
    "updated_date": "2025-02-26 14:16:58 UTC"
  },
  {
    "arxiv_id": "2502.19160v1",
    "title": "Detecting Linguistic Indicators for Stereotype Assessment with Large Language Models",
    "authors": [
      "Rebekka Görge",
      "Michael Mock",
      "Héctor Allende-Cid"
    ],
    "abstract": "Social categories and stereotypes are embedded in language and can introduce\ndata bias into Large Language Models (LLMs). Despite safeguards, these biases\noften persist in model behavior, potentially leading to representational harm\nin outputs. While sociolinguistic research provides valuable insights into the\nformation of stereotypes, NLP approaches for stereotype detection rarely draw\non this foundation and often lack objectivity, precision, and interpretability.\nTo fill this gap, in this work we propose a new approach that detects and\nquantifies the linguistic indicators of stereotypes in a sentence. We derive\nlinguistic indicators from the Social Category and Stereotype Communication\n(SCSC) framework which indicate strong social category formulation and\nstereotyping in language, and use them to build a categorization scheme. To\nautomate this approach, we instruct different LLMs using in-context learning to\napply the approach to a sentence, where the LLM examines the linguistic\nproperties and provides a basis for a fine-grained assessment. Based on an\nempirical evaluation of the importance of different linguistic indicators, we\nlearn a scoring function that measures the linguistic indicators of a\nstereotype. Our annotations of stereotyped sentences show that these indicators\nare present in these sentences and explain the strength of a stereotype. In\nterms of model performance, our results show that the models generally perform\nwell in detecting and classifying linguistic indicators of category labels used\nto denote a category, but sometimes struggle to correctly evaluate the\nassociated behaviors and characteristics. Using more few-shot examples within\nthe prompts, significantly improves performance. Model performance increases\nwith size, as Llama-3.3-70B-Instruct and GPT-4 achieve comparable results that\nsurpass those of Mixtral-8x7B-Instruct, GPT-4-mini and Llama-3.1-8B-Instruct.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19160v1",
    "published_date": "2025-02-26 14:15:28 UTC",
    "updated_date": "2025-02-26 14:15:28 UTC"
  },
  {
    "arxiv_id": "2502.19158v1",
    "title": "When Personalization Meets Reality: A Multi-Faceted Analysis of Personalized Preference Learning",
    "authors": [
      "Yijiang River Dong",
      "Tiancheng Hu",
      "Yinhong Liu",
      "Ahmet Üstün",
      "Nigel Collier"
    ],
    "abstract": "While Reinforcement Learning from Human Feedback (RLHF) is widely used to\nalign Large Language Models (LLMs) with human preferences, it typically assumes\nhomogeneous preferences across users, overlooking diverse human values and\nminority viewpoints. Although personalized preference learning addresses this\nby tailoring separate preferences for individual users, the field lacks\nstandardized methods to assess its effectiveness. We present a multi-faceted\nevaluation framework that measures not only performance but also fairness,\nunintended effects, and adaptability across varying levels of preference\ndivergence. Through extensive experiments comparing eight personalization\nmethods across three preference datasets, we demonstrate that performance\ndifferences between methods could reach 36% when users strongly disagree, and\npersonalization can introduce up to 20% safety misalignment. These findings\nhighlight the critical need for holistic evaluation approaches to advance the\ndevelopment of more effective and inclusive preference learning systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19158v1",
    "published_date": "2025-02-26 14:14:58 UTC",
    "updated_date": "2025-02-26 14:14:58 UTC"
  },
  {
    "arxiv_id": "2502.19145v1",
    "title": "Multi-Agent Security Tax: Trading Off Security and Collaboration Capabilities in Multi-Agent Systems",
    "authors": [
      "Pierre Peigne-Lefebvre",
      "Mikolaj Kniejski",
      "Filip Sondej",
      "Matthieu David",
      "Jason Hoelscher-Obermaier",
      "Christian Schroeder de Witt",
      "Esben Kran"
    ],
    "abstract": "As AI agents are increasingly adopted to collaborate on complex objectives,\nensuring the security of autonomous multi-agent systems becomes crucial. We\ndevelop simulations of agents collaborating on shared objectives to study these\nsecurity risks and security trade-offs. We focus on scenarios where an attacker\ncompromises one agent, using it to steer the entire system toward misaligned\noutcomes by corrupting other agents. In this context, we observe infectious\nmalicious prompts - the multi-hop spreading of malicious instructions. To\nmitigate this risk, we evaluated several strategies: two \"vaccination\"\napproaches that insert false memories of safely handling malicious input into\nthe agents' memory stream, and two versions of a generic safety instruction\nstrategy. While these defenses reduce the spread and fulfillment of malicious\ninstructions in our experiments, they tend to decrease collaboration capability\nin the agent network. Our findings illustrate potential trade-off between\nsecurity and collaborative efficiency in multi-agent systems, providing\ninsights for designing more secure yet effective AI collaborations.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to AAAI 2025 Conference",
    "pdf_url": "http://arxiv.org/pdf/2502.19145v1",
    "published_date": "2025-02-26 14:00:35 UTC",
    "updated_date": "2025-02-26 14:00:35 UTC"
  },
  {
    "arxiv_id": "2502.19135v1",
    "title": "A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided Knowledge Base Management",
    "authors": [
      "Enrico Saccon",
      "Ahmet Tikna",
      "Davide De Martini",
      "Edoardo Lamon",
      "Luigi Palopoli",
      "Marco Roveri"
    ],
    "abstract": "This paper presents a novel framework, called PLANTOR (PLanning with Natural\nlanguage for Task-Oriented Robots), that integrates Large Language Models\n(LLMs) with Prolog-based knowledge management and planning for multi-robot\ntasks. The system employs a two-phase generation of a robot-oriented knowledge\nbase, ensuring reusability and compositional reasoning, as well as a three-step\nplanning procedure that handles temporal dependencies, resource constraints,\nand parallel task execution via mixed-integer linear programming. The final\nplan is converted into a Behaviour Tree for direct use in ROS2. We tested the\nframework in multi-robot assembly tasks within a block world and an\narch-building scenario. Results demonstrate that LLMs can produce accurate\nknowledge bases with modest human feedback, while Prolog guarantees formal\ncorrectness and explainability. This approach underscores the potential of LLM\nintegration for advanced robotics tasks requiring flexible, scalable, and\nhuman-understandable planning.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19135v1",
    "published_date": "2025-02-26 13:51:28 UTC",
    "updated_date": "2025-02-26 13:51:28 UTC"
  },
  {
    "arxiv_id": "2503.01875v1",
    "title": "Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement",
    "authors": [
      "Yaxuan Kong",
      "Yiyuan Yang",
      "Yoontae Hwang",
      "Wenjie Du",
      "Stefan Zohren",
      "Zhangyang Wang",
      "Ming Jin",
      "Qingsong Wen"
    ],
    "abstract": "Time series data are foundational in finance, healthcare, and energy domains.\nHowever, most existing methods and datasets remain focused on a narrow spectrum\nof tasks, such as forecasting or anomaly detection. To bridge this gap, we\nintroduce Time Series Multi-Task Question Answering (Time-MQA), a unified\nframework that enables natural language queries across multiple time series\ntasks - numerical analytical tasks and open-ended question answering with\nreasoning. Central to Time-MQA is the TSQA dataset, a large-scale dataset\ncontaining $\\sim$200k question-answer pairs derived from diverse time series\nspanning environment, traffic, etc. This comprehensive resource covers various\ntime series lengths and promotes robust model development. We further\ndemonstrate how continually pre-training large language models (Mistral 7B,\nLlama-3 8B, and Qwen-2.5 7B) on the TSQA dataset enhanced time series reasoning\ncapabilities, moving beyond mere numeric tasks and enabling more advanced and\nintuitive interactions with temporal data. The complete TSQA dataset, models,\nexecutable codes, user study questionnaires for evaluation, and results have\nall been open-sourced.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01875v1",
    "published_date": "2025-02-26 13:47:13 UTC",
    "updated_date": "2025-02-26 13:47:13 UTC"
  },
  {
    "arxiv_id": "2502.19130v1",
    "title": "Voting or Consensus? Decision-Making in Multi-Agent Debate",
    "authors": [
      "Lars Benedikt Kaesberg",
      "Jonas Becker",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Bela Gipp"
    ],
    "abstract": "Much of the success of multi-agent debates depends on carefully choosing the\nright parameters. Among them, the decision-making protocol stands out.\nSystematic comparison of decision protocols is difficult because studies alter\nmultiple discussion parameters beyond the protocol. So far, it has been largely\nunknown how decision-making addresses the challenges of different tasks. This\nwork systematically evaluates the impact of seven decision protocols (e.g.,\nmajority voting, unanimity consensus). We change only one variable at a time\n(i.e., decision protocol) to analyze how different methods affect the\ncollaboration between agents and test different protocols on knowledge (MMLU,\nMMLU-Pro, GPQA) and reasoning datasets (StrategyQA, MuSR, SQuAD 2.0). Our\nresults show that voting protocols improve performance by 13.2% in reasoning\ntasks and consensus protocols by 2.8% in knowledge tasks over the other\ndecision protocol. Increasing the number of agents improves performance, while\nmore discussion rounds before voting reduces it. To improve decision-making by\nincreasing answer diversity, we propose two new methods, All-Agents Drafting\n(AAD) and Collective Improvement (CI). Our methods improve task performance by\nup to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the\nimportance of decision-making in multi-agent debates beyond scaling.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19130v1",
    "published_date": "2025-02-26 13:39:18 UTC",
    "updated_date": "2025-02-26 13:39:18 UTC"
  },
  {
    "arxiv_id": "2502.19123v1",
    "title": "From Traditional to Deep Learning Approaches in Whole Slide Image Registration: A Methodological Review",
    "authors": [
      "Behnaz Elhaminia",
      "Abdullah Alsalemi",
      "Esha Nasir",
      "Mostafa Jahanifar",
      "Ruqayya Awan",
      "Lawrence S. Young",
      "Nasir M. Rajpoot",
      "Fayyaz Minhas",
      "Shan E Ahmed Raza"
    ],
    "abstract": "Whole slide image (WSI) registration is an essential task for analysing the\ntumour microenvironment (TME) in histopathology. It involves the alignment of\nspatial information between WSIs of the same section or serial sections of a\ntissue sample. The tissue sections are usually stained with single or multiple\nbiomarkers before imaging, and the goal is to identify neighbouring nuclei\nalong the Z-axis for creating a 3D image or identifying subclasses of cells in\nthe TME. This task is considerably more challenging compared to radiology image\nregistration, such as magnetic resonance imaging or computed tomography, due to\nvarious factors. These include gigapixel size of images, variations in\nappearance between differently stained tissues, changes in structure and\nmorphology between non-consecutive sections, and the presence of artefacts,\ntears, and deformations. Currently, there is a noticeable gap in the literature\nregarding a review of the current approaches and their limitations, as well as\nthe challenges and opportunities they present. We aim to provide a\ncomprehensive understanding of the available approaches and their application\nfor various purposes. Furthermore, we investigate current deep learning methods\nused for WSI registration, emphasising their diverse methodologies. We examine\nthe available datasets and explore tools and software employed in the field.\nFinally, we identify open challenges and potential future trends in this area\nof research.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19123v1",
    "published_date": "2025-02-26 13:24:16 UTC",
    "updated_date": "2025-02-26 13:24:16 UTC"
  },
  {
    "arxiv_id": "2502.19119v1",
    "title": "Chemical knowledge-informed framework for privacy-aware retrosynthesis learning",
    "authors": [
      "Guikun Chen",
      "Xu Zhang",
      "Yi Yang",
      "Wenguan Wang"
    ],
    "abstract": "Chemical reaction data is a pivotal asset, driving advances in competitive\nfields such as pharmaceuticals, materials science, and industrial chemistry.\nIts proprietary nature renders it sensitive, as it often includes confidential\ninsights and competitive advantages organizations strive to protect. However,\nin contrast to this need for confidentiality, the current standard training\nparadigm for machine learning-based retrosynthesis gathers reaction data from\nmultiple sources into one single edge to train prediction models. This paradigm\nposes considerable privacy risks as it necessitates broad data availability\nacross organizational boundaries and frequent data transmission between\nentities, potentially exposing proprietary information to unauthorized access\nor interception during storage and transfer. In the present study, we introduce\nthe chemical knowledge-informed framework (CKIF), a privacy-preserving approach\nfor learning retrosynthesis models. CKIF enables distributed training across\nmultiple chemical organizations without compromising the confidentiality of\nproprietary reaction data. Instead of gathering raw reaction data, CKIF learns\nretrosynthesis models through iterative, chemical knowledge-informed\naggregation of model parameters. In particular, the chemical properties of\npredicted reactants are leveraged to quantitatively assess the observable\nbehaviors of individual models, which in turn determines the adaptive weights\nused for model aggregation. On a variety of reaction datasets, CKIF outperforms\nseveral strong baselines by a clear margin (e.g., ~20% performance improvement\nover FedAvg on USPTO-50K), showing its feasibility and superiority to stimulate\nfurther research on privacy-preserving retrosynthesis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19119v1",
    "published_date": "2025-02-26 13:13:24 UTC",
    "updated_date": "2025-02-26 13:13:24 UTC"
  },
  {
    "arxiv_id": "2502.19115v2",
    "title": "Improving Customer Service with Automatic Topic Detection in User Emails",
    "authors": [
      "Bojana Bašaragin",
      "Darija Medvecki",
      "Gorana Gojić",
      "Milena Oparnica",
      "Dragiša Mišković"
    ],
    "abstract": "This study introduces a novel natural language processing pipeline that\nenhances customer service efficiency at Telekom Srbija, a leading Serbian\ntelecommunications company, through automated email topic detection and\nlabeling. Central to the pipeline is BERTopic, a modular framework that allows\nunsupervised topic modeling. After a series of preprocessing and postprocessing\nsteps, we assign one of 12 topics and several additional labels to incoming\nemails, allowing the customer service to filter and access them through a\ncustom-made application. The model's performance was evaluated by assessing the\nspeed and correctness of the automatically assigned topics, with a weighted\naverage processing time of 0.041 seconds per email and a weighted average F1\nscore of 0.96. The pipeline shows broad applicability across languages,\nparticularly to those that are low-resourced and morphologically rich. The\nsystem now operates in the company's production environment, streamlining\ncustomer service operations through automated email classification.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper accepted to the 15th International Conference on Information\n  Society and Technology (ICIST), Kopaonik, Serbia, 9-12 March 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19115v2",
    "published_date": "2025-02-26 13:10:38 UTC",
    "updated_date": "2025-04-07 08:58:17 UTC"
  },
  {
    "arxiv_id": "2502.19107v1",
    "title": "The Shady Light of Art Automation",
    "authors": [
      "Dejan Grba"
    ],
    "abstract": "Generative artificial intelligence (generative AI) has entered the mainstream\nculture and become a subject of extensive academic investigation. However, the\ncharacter and background of its impact on art require subtler scrutiny and more\nnuanced contextualization. This paper summarizes a broader study of the roles\nthat AI's conceptual and ideological substrata play in influencing art notions.\nThe focus is on divergent but coalescing and often questionable ideas, values,\nand political views that generative AI and other art-related AI technologies\npropagate from the computer science and AI/tech industry to the contemporary\nart and culture. The paper maps the main areas of this complex relationship and\nconcisely critiques their key aspects.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted to ISEA 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19107v1",
    "published_date": "2025-02-26 12:50:05 UTC",
    "updated_date": "2025-02-26 12:50:05 UTC"
  },
  {
    "arxiv_id": "2502.19095v1",
    "title": "XSS Adversarial Attacks Based on Deep Reinforcement Learning: A Replication and Extension Study",
    "authors": [
      "Samuele Pasini",
      "Gianluca Maragliano",
      "Jinhan Kim",
      "Paolo Tonella"
    ],
    "abstract": "Cross-site scripting (XSS) poses a significant threat to web application\nsecurity. While Deep Learning (DL) has shown remarkable success in detecting\nXSS attacks, it remains vulnerable to adversarial attacks due to the\ndiscontinuous nature of its input-output mapping. These adversarial attacks\nemploy mutation-based strategies for different components of XSS attack\nvectors, allowing adversarial agents to iteratively select mutations to evade\ndetection. Our work replicates a state-of-the-art XSS adversarial attack,\nhighlighting threats to validity in the reference work and extending it toward\na more effective evaluation strategy. Moreover, we introduce an XSS Oracle to\nmitigate these threats. The experimental results show that our approach\nachieves an escape rate above 96% when the threats to validity of the\nreplicated technique are addressed.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19095v1",
    "published_date": "2025-02-26 12:39:55 UTC",
    "updated_date": "2025-02-26 12:39:55 UTC"
  },
  {
    "arxiv_id": "2503.01874v1",
    "title": "CABS: Conflict-Aware and Balanced Sparsification for Enhancing Model Merging",
    "authors": [
      "Zongzhen Yang",
      "Binhang Qi",
      "Hailong Sun",
      "Wenrui Long",
      "Ruobing Zhao",
      "Xiang Gao"
    ],
    "abstract": "Model merging based on task vectors, i.e., the parameter differences between\nfine-tuned models and a shared base model, provides an efficient way to\nintegrate multiple task-specific models into a multitask model without\nretraining. Recent works have endeavored to address the conflicts between task\nvectors, one of the significant challenges faced by model merging, through\nsparsification; however, two issues significantly limit their performance: high\nparameter overlap and unbalanced weight distribution. To address these issues,\nwe propose a simple, yet effective framework called CABS (Conflict-Aware and\nBalanced Sparsification), consisting of Conflict-Aware Sparsification (CA) and\nBalanced Sparsification (BS). CA can reduce parameter overlap by applying masks\nduring sequential pruning, ensuring that each task vector retains distinct,\nnon-overlapping parameters. BS leverages $n$: $m$ pruning to preserve critical\nweights while maintaining an even distribution across layers. Our comprehensive\nexperiments demonstrate that CABS outperforms state-of-the-art methods across\ndiverse tasks and model sizes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01874v1",
    "published_date": "2025-02-26 12:38:55 UTC",
    "updated_date": "2025-02-26 12:38:55 UTC"
  },
  {
    "arxiv_id": "2502.19091v1",
    "title": "Nexus: A Lightweight and Scalable Multi-Agent Framework for Complex Tasks Automation",
    "authors": [
      "Humza Sami",
      "Mubashir ul Islam",
      "Samy Charas",
      "Asav Gandhi",
      "Pierre-Emmanuel Gaillardon",
      "Valerio Tenace"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have substantially\nevolved Multi-Agent Systems (MASs) capabilities, enabling systems that not only\nautomate tasks but also leverage near-human reasoning capabilities. To achieve\nthis, LLM-based MASs need to be built around two critical principles: (i) a\nrobust architecture that fully exploits LLM potential for specific tasks -- or\nrelated task sets -- and ($ii$) an effective methodology for equipping LLMs\nwith the necessary capabilities to perform tasks and manage information\nefficiently. It goes without saying that a priori architectural designs can\nlimit the scalability and domain adaptability of a given MAS.\n  To address these challenges, in this paper we introduce Nexus: a lightweight\nPython framework designed to easily build and manage LLM-based MASs. Nexus\nintroduces the following innovations: (i) a flexible multi-supervisor\nhierarchy, (ii) a simplified workflow design, and (iii) easy installation and\nopen-source flexibility: Nexus can be installed via pip and is distributed\nunder a permissive open-source license, allowing users to freely modify and\nextend its capabilities.\n  Experimental results demonstrate that architectures built with Nexus exhibit\nstate-of-the-art performance across diverse domains. In coding tasks,\nNexus-driven MASs achieve a 99% pass rate on HumanEval and a flawless 100% on\nVerilogEval-Human, outperforming cutting-edge reasoning language models such as\no3-mini and DeepSeek-R1. Moreover, these architectures display robust\nproficiency in complex reasoning and mathematical problem solving, achieving\ncorrect solutions for all randomly selected problems from the MATH dataset. In\nthe realm of multi-objective optimization, Nexus-based architectures\nsuccessfully address challenging timing closure tasks on designs from the VTR\nbenchmark suite, while guaranteeing, on average, a power saving of nearly 30%.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19091v1",
    "published_date": "2025-02-26 12:37:47 UTC",
    "updated_date": "2025-02-26 12:37:47 UTC"
  },
  {
    "arxiv_id": "2503.16465v1",
    "title": "OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents",
    "authors": [
      "Pengzhou Cheng",
      "Zheng Wu",
      "Zongru Wu",
      "Aston Zhang",
      "Zhuosheng Zhang",
      "Gongshen Liu"
    ],
    "abstract": "Autonomous graphical user interface (GUI) agents powered by multimodal large\nlanguage models have shown great promise. However, a critical yet underexplored\nissue persists: over-execution, where the agent executes tasks in a fully\nautonomous way, without adequate assessment of its action confidence to\ncompromise an adaptive human-agent collaboration. This poses substantial risks\nin complex scenarios, such as those involving ambiguous user instructions,\nunexpected interruptions, and environmental hijacks. To address the issue, we\nintroduce OS-Kairos, an adaptive GUI agent capable of predicting confidence\nlevels at each interaction step and efficiently deciding whether to act\nautonomously or seek human intervention. OS-Kairos is developed through two key\nmechanisms: (i) collaborative probing that annotates confidence scores at each\ninteraction step; (ii) confidence-driven interaction that leverages these\nconfidence scores to elicit the ability of adaptive interaction. Experimental\nresults show that OS-Kairos substantially outperforms existing models on our\ncurated dataset featuring complex scenarios, as well as on established\nbenchmarks such as AITZ and Meta-GUI, with 24.59\\%$\\sim$87.29\\% improvements in\ntask success rate. OS-Kairos facilitates an adaptive human-agent collaboration,\nprioritizing effectiveness, generality, scalability, and efficiency for\nreal-world GUI interaction. The dataset and codes are available at\nhttps://github.com/Wuzheng02/OS-Kairos.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "25 pages, 24 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.16465v1",
    "published_date": "2025-02-26 12:31:16 UTC",
    "updated_date": "2025-02-26 12:31:16 UTC"
  },
  {
    "arxiv_id": "2503.00049v1",
    "title": "Omni-SILA: Towards Omni-scene Driven Visual Sentiment Identifying, Locating and Attributing in Videos",
    "authors": [
      "Jiamin Luo",
      "Jingjing Wang",
      "Junxiao Ma",
      "Yujie Jin",
      "Shoushan Li",
      "Guodong Zhou"
    ],
    "abstract": "Prior studies on Visual Sentiment Understanding (VSU) primarily rely on the\nexplicit scene information (e.g., facial expression) to judge visual\nsentiments, which largely ignore implicit scene information (e.g., human\naction, objection relation and visual background), while such information is\ncritical for precisely discovering visual sentiments. Motivated by this, this\npaper proposes a new Omni-scene driven visual Sentiment Identifying, Locating\nand Attributing in videos (Omni-SILA) task, aiming to interactively and\nprecisely identify, locate and attribute visual sentiments through both\nexplicit and implicit scene information. Furthermore, this paper believes that\nthis Omni-SILA task faces two key challenges: modeling scene and highlighting\nimplicit scene beyond explicit. To this end, this paper proposes an\nImplicit-enhanced Causal MoE (ICM) approach for addressing the Omni-SILA task.\nSpecifically, a Scene-Balanced MoE (SBM) and an Implicit-Enhanced Causal (IEC)\nblocks are tailored to model scene information and highlight the implicit scene\ninformation beyond explicit, respectively. Extensive experimental results on\nour constructed explicit and implicit Omni-SILA datasets demonstrate the great\nadvantage of the proposed ICM approach over advanced Video-LLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00049v1",
    "published_date": "2025-02-26 12:05:07 UTC",
    "updated_date": "2025-02-26 12:05:07 UTC"
  },
  {
    "arxiv_id": "2502.19026v1",
    "title": "InternVQA: Advancing Compressed Video Quality Assessment with Distilling Large Foundation Model",
    "authors": [
      "Fengbin Guan",
      "Zihao Yu",
      "Yiting Lu",
      "Xin Li",
      "Zhibo Chen"
    ],
    "abstract": "Video quality assessment tasks rely heavily on the rich features required for\nvideo understanding, such as semantic information, texture, and temporal\nmotion. The existing video foundational model, InternVideo2, has demonstrated\nstrong potential in video understanding tasks due to its large parameter size\nand large-scale multimodal data pertaining. Building on this, we explored the\ntransferability of InternVideo2 to video quality assessment under compression\nscenarios. To design a lightweight model suitable for this task, we proposed a\ndistillation method to equip the smaller model with rich compression quality\npriors. Additionally, we examined the performance of different backbones during\nthe distillation process. The results showed that, compared to other methods,\nour lightweight model distilled from InternVideo2 achieved excellent\nperformance in compression video quality assessment.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by ISCAS 2025(Lecture)",
    "pdf_url": "http://arxiv.org/pdf/2502.19026v1",
    "published_date": "2025-02-26 10:34:14 UTC",
    "updated_date": "2025-02-26 10:34:14 UTC"
  },
  {
    "arxiv_id": "2502.19024v1",
    "title": "Ground-level Viewpoint Vision-and-Language Navigation in Continuous Environments",
    "authors": [
      "Zerui Li",
      "Gengze Zhou",
      "Haodong Hong",
      "Yanyan Shao",
      "Wenqi Lyu",
      "Yanyuan Qiao",
      "Qi Wu"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) empowers agents to associate\ntime-sequenced visual observations with corresponding instructions to make\nsequential decisions. However, generalization remains a persistent challenge,\nparticularly when dealing with visually diverse scenes or transitioning from\nsimulated environments to real-world deployment. In this paper, we address the\nmismatch between human-centric instructions and quadruped robots with a\nlow-height field of view, proposing a Ground-level Viewpoint Navigation (GVNav)\napproach to mitigate this issue. This work represents the first attempt to\nhighlight the generalization gap in VLN across varying heights of visual\nobservation in realistic robot deployments. Our approach leverages weighted\nhistorical observations as enriched spatiotemporal contexts for instruction\nfollowing, effectively managing feature collisions within cells by assigning\nappropriate weights to identical features across different viewpoints. This\nenables low-height robots to overcome challenges such as visual obstructions\nand perceptual mismatches. Additionally, we transfer the connectivity graph\nfrom the HM3D and Gibson datasets as an extra resource to enhance spatial\npriors and a more comprehensive representation of real-world scenarios, leading\nto improved performance and generalizability of the waypoint predictor in\nreal-world environments. Extensive experiments demonstrate that our\nGround-level Viewpoint Navigation (GVnav) approach significantly improves\nperformance in both simulated environments and real-world deployments with\nquadruped robots.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19024v1",
    "published_date": "2025-02-26 10:30:40 UTC",
    "updated_date": "2025-02-26 10:30:40 UTC"
  },
  {
    "arxiv_id": "2502.19023v1",
    "title": "Dealing with Inconsistency for Reasoning over Knowledge Graphs: A Survey",
    "authors": [
      "Anastasios Nentidis",
      "Charilaos Akasiadis",
      "Angelos Charalambidis",
      "Alexander Artikis"
    ],
    "abstract": "In Knowledge Graphs (KGs), where the schema of the data is usually defined by\nparticular ontologies, reasoning is a necessity to perform a range of tasks,\nsuch as retrieval of information, question answering, and the derivation of new\nknowledge. However, information to populate KGs is often extracted (semi-)\nautomatically from natural language resources, or by integrating datasets that\nfollow different semantic schemas, resulting in KG inconsistency. This,\nhowever, hinders the process of reasoning. In this survey, we focus on how to\nperform reasoning on inconsistent KGs, by analyzing the state of the art\ntowards three complementary directions: a) the detection of the parts of the KG\nthat cause the inconsistency, b) the fixing of an inconsistent KG to render it\nconsistent, and c) the inconsistency-tolerant reasoning. We discuss existing\nwork from a range of relevant fields focusing on how, and in which cases they\nare related to the above directions. We also highlight persisting challenges\nand future directions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19023v1",
    "published_date": "2025-02-26 10:30:22 UTC",
    "updated_date": "2025-02-26 10:30:22 UTC"
  },
  {
    "arxiv_id": "2502.19460v3",
    "title": "Overcoming Dependent Censoring in the Evaluation of Survival Models",
    "authors": [
      "Christian Marius Lillelund",
      "Shi-ang Qi",
      "Russell Greiner"
    ],
    "abstract": "Conventional survival metrics, such as Harrell's concordance index (CI) and\nthe Brier Score, rely on the independent censoring assumption for valid\ninference with right-censored data. However, in the presence of so-called\ndependent censoring, where the probability of censoring is related to the event\nof interest, these metrics can give biased estimates of the underlying model\nerror. In this paper, we introduce three new evaluation metrics for survival\nanalysis based on Archimedean copulas that can account for dependent censoring.\nWe also develop a framework to generate realistic, semi-synthetic datasets with\ndependent censoring to facilitate the evaluation of the metrics. Our\nexperiments in synthetic and semi-synthetic data demonstrate that the proposed\nmetrics can provide more accurate estimates of the model error than\nconventional metrics under dependent censoring.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19460v3",
    "published_date": "2025-02-26 10:28:44 UTC",
    "updated_date": "2025-05-19 17:50:52 UTC"
  },
  {
    "arxiv_id": "2502.19014v1",
    "title": "Robust Over-the-Air Computation with Type-Based Multiple Access",
    "authors": [
      "Marc Martinez-Gost",
      "Ana Pérez-Neira",
      "Miguel Ángel Lagunas"
    ],
    "abstract": "This paper utilizes the properties of type-based multiple access (TBMA) to\ninvestigate its effectiveness as a robust approach for over-the-air computation\n(AirComp) in the presence of Byzantine attacks, this is, adversarial strategies\nwhere malicious nodes intentionally distort their transmissions to corrupt the\naggregated result. Unlike classical direct aggregation (DA) AirComp, which\naggregates data in the amplitude of the signals and are highly vulnerable to\nattacks, TBMA distributes data over multiple radio resources, enabling the\nreceiver to construct a histogram representation of the transmitted data. This\nstructure allows the integration of classical robust estimators and supports\nthe computation of diverse functions beyond the arithmetic mean, which is not\nfeasible with DA. Through extensive simulations, we demonstrate that robust\nTBMA significantly outperforms DA, maintaining high accuracy even under\nadversarial conditions, and showcases its applicability in federated learning\n(FEEL) scenarios. Additionally, TBMA reduces channel state information (CSI)\nrequirements, lowers energy consumption, and enhances resiliency by leveraging\nthe diversity of the transmitted data. These results establish TBMA as a\nscalable and robust solution for AirComp, paving the way for secure and\nefficient aggregation in next-generation networks.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "Paper submitted to 33rd European Signal Processing Conference\n  (EUSIPCO 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.19014v1",
    "published_date": "2025-02-26 10:22:00 UTC",
    "updated_date": "2025-02-26 10:22:00 UTC"
  },
  {
    "arxiv_id": "2502.19009v1",
    "title": "Distilling Reinforcement Learning Algorithms for In-Context Model-Based Planning",
    "authors": [
      "Jaehyeon Son",
      "Soochan Lee",
      "Gunhee Kim"
    ],
    "abstract": "Recent studies have shown that Transformers can perform in-context\nreinforcement learning (RL) by imitating existing RL algorithms, enabling\nsample-efficient adaptation to unseen tasks without parameter updates. However,\nthese models also inherit the suboptimal behaviors of the RL algorithms they\nimitate. This issue primarily arises due to the gradual update rule employed by\nthose algorithms. Model-based planning offers a promising solution to this\nlimitation by allowing the models to simulate potential outcomes before taking\naction, providing an additional mechanism to deviate from the suboptimal\nbehavior. Rather than learning a separate dynamics model, we propose\nDistillation for In-Context Planning (DICP), an in-context model-based RL\nframework where Transformers simultaneously learn environment dynamics and\nimprove policy in-context. We evaluate DICP across a range of discrete and\ncontinuous environments, including Darkroom variants and Meta-World. Our\nresults show that DICP achieves state-of-the-art performance while requiring\nsignificantly fewer environment interactions than baselines, which include both\nmodel-free counterparts and existing meta-RL methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19009v1",
    "published_date": "2025-02-26 10:16:57 UTC",
    "updated_date": "2025-02-26 10:16:57 UTC"
  },
  {
    "arxiv_id": "2502.19008v1",
    "title": "Binary Neural Networks for Large Language Model: A Survey",
    "authors": [
      "Liangdong Liu",
      "Zhitong Zheng",
      "Cong Wang",
      "Tianhuang Su",
      "Zhenyu Yang"
    ],
    "abstract": "Large language models (LLMs) have wide applications in the field of natural\nlanguage processing(NLP), such as GPT-4 and Llama. However, with the\nexponential growth of model parameter sizes, LLMs bring significant resource\noverheads. Low-bit quantization, as a key technique, reduces memory usage and\ncomputational demands by decreasing the bit-width of model parameters,\nactivations, and gradients. Previous quantization methods for LLMs have largely\nemployed Post-Training Quantization (PTQ) and Quantization-Aware Training\n(QAT). PTQ does not require any retraining of the original model, while QAT\ninvolves optimizing precision during training to achieve the best quantization\nparameters. The BitNet team proposed a radically different approach, where\nquantization is performed from the start of model training, utilizing\nlow-precision binary weights during the training process. This approach has led\nto the emergence of many binary quantization techniques for large language\nmodels. This paper provides a comprehensive review of these binary quantization\ntechniques. Specifically, we will introduce binary quantization techniques in\ndeep neural networks and further explore their application to LLMs, reviewing\ntheir various contributions, implementations, and applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19008v1",
    "published_date": "2025-02-26 10:14:19 UTC",
    "updated_date": "2025-02-26 10:14:19 UTC"
  },
  {
    "arxiv_id": "2503.05779v1",
    "title": "Homomorphic Encryption of Intuitionistic Logic Proofs and Functional Programs: A Categorical Approach Inspired by Composite-Order Bilinear Groups",
    "authors": [
      "Ben Goertzel"
    ],
    "abstract": "We present a conceptual framework for extending homomorphic encryption beyond\narithmetic or Boolean operations into the domain of intuitionistic logic proofs\nand, by the Curry-Howard correspondence, into the domain of typed functional\nprograms. We begin by reviewing well-known homomorphic encryption schemes for\narithmetic operations, and then discuss the adaptation of similar concepts to\nsupport logical inference steps in intuitionistic logic. Key to our\nconstruction are polynomial functors and Bounded Natural Functors (BNFs), which\nserve as a categorical substrate on which logic formulas and proofs are\nrepresented and manipulated. We outline a complexity-theoretic hardness\nassumption -- the BNF Distinguishing Problem, constructed via a reduction from\nSubgraph Isomorphism, providing a foundation for cryptographic security.\nFinally, we describe how these methods can homomorphically encode the execution\nof total, dependently typed functional programs, and outline strategies for\nmaking the approach potentially efficient, including software optimizations and\nhardware acceleration.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05779v1",
    "published_date": "2025-02-26 10:10:10 UTC",
    "updated_date": "2025-02-26 10:10:10 UTC"
  },
  {
    "arxiv_id": "2502.19004v1",
    "title": "A Multi-Agent DRL-Based Framework for Optimal Resource Allocation and Twin Migration in the Multi-Tier Vehicular Metaverse",
    "authors": [
      "Nahom Abishu Hayla",
      "A. Mohammed Seid",
      "Aiman Erbad",
      "Tilahun M. Getu",
      "Ala Al-Fuqaha",
      "Mohsen Guizani"
    ],
    "abstract": "Although multi-tier vehicular Metaverse promises to transform vehicles into\nessential nodes -- within an interconnected digital ecosystem -- using\nefficient resource allocation and seamless vehicular twin (VT) migration, this\ncan hardly be achieved by the existing techniques operating in a highly dynamic\nvehicular environment, since they can hardly balance multi-objective\noptimization problems such as latency reduction, resource utilization, and user\nexperience (UX). To address these challenges, we introduce a novel multi-tier\nresource allocation and VT migration framework that integrates Graph\nConvolutional Networks (GCNs), a hierarchical Stackelberg game-based incentive\nmechanism, and Multi-Agent Deep Reinforcement Learning (MADRL). The GCN-based\nmodel captures both spatial and temporal dependencies within the vehicular\nnetwork; the Stackelberg game-based incentive mechanism fosters cooperation\nbetween vehicles and infrastructure; and the MADRL algorithm jointly optimizes\nresource allocation and VT migration in real time. By modeling this dynamic and\nmulti-tier vehicular Metaverse as a Markov Decision Process (MDP), we develop a\nMADRL-based algorithm dubbed the Multi-Objective Multi-Agent Deep Deterministic\nPolicy Gradient (MO-MADDPG), which can effectively balances the various\nconflicting objectives. Extensive simulations validate the effectiveness of\nthis algorithm that is demonstrated to enhance scalability, reliability, and\nefficiency while considerably improving latency, resource utilization,\nmigration cost, and overall UX by 12.8%, 9.7%, 14.2%, and 16.1%, respectively.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.NI",
    "comment": "15 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19004v1",
    "published_date": "2025-02-26 10:09:05 UTC",
    "updated_date": "2025-02-26 10:09:05 UTC"
  },
  {
    "arxiv_id": "2502.19002v1",
    "title": "The Sharpness Disparity Principle in Transformers for Accelerating Language Model Pre-Training",
    "authors": [
      "Jinbo Wang",
      "Mingze Wang",
      "Zhanpeng Zhou",
      "Junchi Yan",
      "Weinan E",
      "Lei Wu"
    ],
    "abstract": "Transformers consist of diverse building blocks, such as embedding layers,\nnormalization layers, self-attention mechanisms, and point-wise feedforward\nnetworks. Thus, understanding the differences and interactions among these\nblocks is important. In this paper, we uncover a clear Sharpness Disparity\nacross these blocks, which emerges early in training and intriguingly persists\nthroughout the training process. Motivated by this finding, we propose\nBlockwise Learning Rate (LR), a strategy that tailors the LR to each block's\nsharpness, accelerating large language model (LLM) pre-training. By integrating\nBlockwise LR into AdamW, we consistently achieve lower terminal loss and nearly\n$2\\times$ speedup compared to vanilla AdamW. We demonstrate this acceleration\nacross GPT-2 and LLaMA, with model sizes ranging from 0.12B to 1.1B and\ndatasets of OpenWebText and MiniPile. Finally, we incorporate Blockwise LR into\nAdam-mini (Zhang et al., 2024), a recently proposed memory-efficient variant of\nAdam, achieving a combined $2\\times$ speedup and $2\\times$ memory saving. These\nresults underscore the potential of exploiting the sharpness disparity to\nimprove LLM training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.19002v1",
    "published_date": "2025-02-26 10:06:37 UTC",
    "updated_date": "2025-02-26 10:06:37 UTC"
  },
  {
    "arxiv_id": "2502.18980v1",
    "title": "PEToolLLM: Towards Personalized Tool Learning in Large Language Models",
    "authors": [
      "Qiancheng Xu",
      "Yongqi Li",
      "Heming Xia",
      "Fan Liu",
      "Min Yang",
      "Wenjie Li"
    ],
    "abstract": "Tool learning has emerged as a promising direction by extending Large\nLanguage Models' (LLMs) capabilities with external tools. Existing tool\nlearning studies primarily focus on the general-purpose tool-use capability,\nwhich addresses explicit user requirements in instructions. However, they\noverlook the importance of personalized tool-use capability, leading to an\ninability to handle implicit user preferences. To address the limitation, we\nfirst formulate the task of personalized tool learning, which integrates user's\ninteraction history towards personalized tool usage. To fill the gap of missing\nbenchmarks, we construct PEToolBench, featuring diverse user preferences\nreflected in interaction history under three distinct personalized settings,\nand encompassing a wide range of tool-use scenarios. Moreover, we propose a\nframework PEToolLLaMA to adapt LLMs to the personalized tool learning task,\nwhich is trained through supervised fine-tuning and direct preference\noptimization. Extensive experiments on PEToolBench demonstrate the superiority\nof PEToolLLaMA over existing LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18980v1",
    "published_date": "2025-02-26 09:43:08 UTC",
    "updated_date": "2025-02-26 09:43:08 UTC"
  },
  {
    "arxiv_id": "2502.18978v3",
    "title": "Low-Confidence Gold: Refining Low-Confidence Samples for Efficient Instruction Tuning",
    "authors": [
      "Hongyi Cai",
      "Jie Li",
      "Wenzhen Dong"
    ],
    "abstract": "The effectiveness of instruction fine-tuning for Large Language Models is\nfundamentally constrained by the quality and efficiency of training datasets.\nThis work introduces Low-Confidence Gold (LCG), a novel filtering framework\nthat employs centroid-based clustering and confidence-guided selection for\nidentifying valuable instruction pairs. Through a semi-supervised approach\nusing a lightweight classifier trained on representative samples, LCG curates\nhigh-quality subsets while preserving data diversity. Experimental evaluation\ndemonstrates that models fine-tuned on LCG-filtered subsets of 6K samples\nachieve superior performance compared to existing methods, with substantial\nimprovements on MT-bench and consistent gains across comprehensive evaluation\nmetrics. The framework's efficacy while maintaining model performance\nestablishes a promising direction for efficient instruction tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.18978v3",
    "published_date": "2025-02-26 09:37:21 UTC",
    "updated_date": "2025-03-08 09:47:20 UTC"
  },
  {
    "arxiv_id": "2502.18969v1",
    "title": "(Mis)Fitting: A Survey of Scaling Laws",
    "authors": [
      "Margaret Li",
      "Sneha Kudugunta",
      "Luke Zettlemoyer"
    ],
    "abstract": "Modern foundation models rely heavily on using scaling laws to guide crucial\ntraining decisions. Researchers often extrapolate the optimal architecture and\nhyper parameters settings from smaller training runs by describing the\nrelationship between, loss, or task performance, and scale. All components of\nthis process vary, from the specific equation being fit, to the training setup,\nto the optimization method. Each of these factors may affect the fitted law,\nand therefore, the conclusions of a given study. We discuss discrepancies in\nthe conclusions that several prior works reach, on questions such as the\noptimal token to parameter ratio. We augment this discussion with our own\nanalysis of the critical impact that changes in specific details may effect in\na scaling study, and the resulting altered conclusions. Additionally, we survey\nover 50 papers that study scaling trends: while 45 of these papers quantify\nthese trends using a power law, most under-report crucial details needed to\nreproduce their findings. To mitigate this, we we propose a checklist for\nauthors to consider while contributing to scaling law research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "41 pages, 3 figure, first two authors contributed equally. ICLR, 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.18969v1",
    "published_date": "2025-02-26 09:27:54 UTC",
    "updated_date": "2025-02-26 09:27:54 UTC"
  },
  {
    "arxiv_id": "2503.05778v1",
    "title": "DreamNet: A Multimodal Framework for Semantic and Emotional Analysis of Sleep Narratives",
    "authors": [
      "Tapasvi Panchagnula"
    ],
    "abstract": "Dream narratives provide a unique window into human cognition and emotion,\nyet their systematic analysis using artificial intelligence has been\nunderexplored. We introduce DreamNet, a novel deep learning framework that\ndecodes semantic themes and emotional states from textual dream reports,\noptionally enhanced with REM-stage EEG data. Leveraging a transformer-based\narchitecture with multimodal attention, DreamNet achieves 92.1% accuracy and\n88.4% F1-score in text-only mode (DNet-T) on a curated dataset of 1,500\nanonymized dream narratives, improving to 99.0% accuracy and 95.2% F1-score\nwith EEG integration (DNet-M). Strong dream-emotion correlations (e.g.,\nfalling-anxiety, r = 0.91, p < 0.01) highlight its potential for mental health\ndiagnostics, cognitive science, and personalized therapy. This work provides a\nscalable tool, a publicly available enriched dataset, and a rigorous\nmethodology, bridging AI and psychological research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T07",
      "I.2.7; I.2.6; J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 5 figures, new research contribution",
    "pdf_url": "http://arxiv.org/pdf/2503.05778v1",
    "published_date": "2025-02-26 09:10:07 UTC",
    "updated_date": "2025-02-26 09:10:07 UTC"
  },
  {
    "arxiv_id": "2502.18952v1",
    "title": "DualSpec: Text-to-spatial-audio Generation via Dual-Spectrogram Guided Diffusion Model",
    "authors": [
      "Lei Zhao",
      "Sizhou Chen",
      "Linfeng Feng",
      "Xiao-Lei Zhang",
      "Xuelong Li"
    ],
    "abstract": "Text-to-audio (TTA), which generates audio signals from textual descriptions,\nhas received huge attention in recent years. However, recent works focused on\ntext to monaural audio only. As we know, spatial audio provides more immersive\nauditory experience than monaural audio, e.g. in virtual reality. To address\nthis issue, we propose a text-to-spatial-audio (TTSA) generation framework\nnamed DualSpec.Specifically, it first trains variational autoencoders (VAEs)\nfor extracting the latent acoustic representations from sound event audio.\nThen, given text that describes sound events and event directions, the proposed\nmethod uses the encoder of a pretrained large language model to transform the\ntext into text features. Finally, it trains a diffusion model from the latent\nacoustic representations and text features for the spatial audio generation. In\nthe inference stage, only the text description is needed to generate spatial\naudio. Particularly, to improve the synthesis quality and azimuth accuracy of\nthe spatial sound events simultaneously, we propose to use two kinds of\nacoustic features. One is the Mel spectrograms which is good for improving the\nsynthesis quality, and the other is the short-time Fourier transform\nspectrograms which is good at improving the azimuth accuracy. We provide a\npipeline of constructing spatial audio dataset with text prompts, for the\ntraining of the VAEs and diffusion model. We also introduce new spatial-aware\nevaluation metrics to quantify the azimuth errors of the generated spatial\naudio recordings. Experimental results demonstrate that the proposed method can\ngenerate spatial audio with high directional and event consistency.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18952v1",
    "published_date": "2025-02-26 09:01:59 UTC",
    "updated_date": "2025-02-26 09:01:59 UTC"
  },
  {
    "arxiv_id": "2502.18940v1",
    "title": "MathTutorBench: A Benchmark for Measuring Open-ended Pedagogical Capabilities of LLM Tutors",
    "authors": [
      "Jakub Macina",
      "Nico Daheim",
      "Ido Hakimi",
      "Manu Kapur",
      "Iryna Gurevych",
      "Mrinmaya Sachan"
    ],
    "abstract": "Evaluating the pedagogical capabilities of AI-based tutoring models is\ncritical for making guided progress in the field. Yet, we lack a reliable,\neasy-to-use, and simple-to-run evaluation that reflects the pedagogical\nabilities of models. To fill this gap, we present MathTutorBench, an\nopen-source benchmark for holistic tutoring model evaluation. MathTutorBench\ncontains a collection of datasets and metrics that broadly cover tutor\nabilities as defined by learning sciences research in dialog-based teaching. To\nscore the pedagogical quality of open-ended teacher responses, we train a\nreward model and show it can discriminate expert from novice teacher responses\nwith high accuracy. We evaluate a wide set of closed- and open-weight models on\nMathTutorBench and find that subject expertise, indicated by solving ability,\ndoes not immediately translate to good teaching. Rather, pedagogy and subject\nexpertise appear to form a trade-off that is navigated by the degree of\ntutoring specialization of the model. Furthermore, tutoring appears to become\nmore challenging in longer dialogs, where simpler questioning strategies begin\nto fail. We release the benchmark, code, and leaderboard openly to enable rapid\nbenchmarking of future models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "https://eth-lre.github.io/mathtutorbench",
    "pdf_url": "http://arxiv.org/pdf/2502.18940v1",
    "published_date": "2025-02-26 08:43:47 UTC",
    "updated_date": "2025-02-26 08:43:47 UTC"
  },
  {
    "arxiv_id": "2502.18935v1",
    "title": "JailBench: A Comprehensive Chinese Security Assessment Benchmark for Large Language Models",
    "authors": [
      "Shuyi Liu",
      "Simiao Cui",
      "Haoran Bu",
      "Yuming Shang",
      "Xi Zhang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious applications, highlighting the urgent need for comprehensive safety\nevaluations. In particular, the enhanced Chinese language proficiency of LLMs,\ncombined with the unique characteristics and complexity of Chinese expressions,\nhas driven the emergence of Chinese-specific benchmarks for safety assessment.\nHowever, these benchmarks generally fall short in effectively exposing LLM\nsafety vulnerabilities. To address the gap, we introduce JailBench, the first\ncomprehensive Chinese benchmark for evaluating deep-seated vulnerabilities in\nLLMs, featuring a refined hierarchical safety taxonomy tailored to the Chinese\ncontext. To improve generation efficiency, we employ a novel Automatic\nJailbreak Prompt Engineer (AJPE) framework for JailBench construction, which\nincorporates jailbreak techniques to enhance assessing effectiveness and\nleverages LLMs to automatically scale up the dataset through context-learning.\nThe proposed JailBench is extensively evaluated over 13 mainstream LLMs and\nachieves the highest attack success rate against ChatGPT compared to existing\nChinese benchmarks, underscoring its efficacy in identifying latent\nvulnerabilities in LLMs, as well as illustrating the substantial room for\nimprovement in the security and trustworthiness of LLMs within the Chinese\ncontext. Our benchmark is publicly available at\nhttps://github.com/STAIR-BUPT/JailBench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 5 figures, accepted at PAKDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.18935v1",
    "published_date": "2025-02-26 08:36:42 UTC",
    "updated_date": "2025-02-26 08:36:42 UTC"
  },
  {
    "arxiv_id": "2502.18932v1",
    "title": "SLAM in the Dark: Self-Supervised Learning of Pose, Depth and Loop-Closure from Thermal Images",
    "authors": [
      "Yangfan Xu",
      "Qu Hao",
      "Lilian Zhang",
      "Jun Mao",
      "Xiaofeng He",
      "Wenqi Wu",
      "Changhao Chen"
    ],
    "abstract": "Visual SLAM is essential for mobile robots, drone navigation, and VR/AR, but\ntraditional RGB camera systems struggle in low-light conditions, driving\ninterest in thermal SLAM, which excels in such environments. However, thermal\nimaging faces challenges like low contrast, high noise, and limited large-scale\nannotated datasets, restricting the use of deep learning in outdoor scenarios.\nWe present DarkSLAM, a noval deep learning-based monocular thermal SLAM system\ndesigned for large-scale localization and reconstruction in complex lighting\nconditions.Our approach incorporates the Efficient Channel Attention (ECA)\nmechanism in visual odometry and the Selective Kernel Attention (SKA) mechanism\nin depth estimation to enhance pose accuracy and mitigate thermal depth\ndegradation. Additionally, the system includes thermal depth-based loop closure\ndetection and pose optimization, ensuring robust performance in low-texture\nthermal scenes. Extensive outdoor experiments demonstrate that DarkSLAM\nsignificantly outperforms existing methods like SC-Sfm-Learner and Shin et al.,\ndelivering precise localization and 3D dense mapping even in challenging\nnighttime environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18932v1",
    "published_date": "2025-02-26 08:34:23 UTC",
    "updated_date": "2025-02-26 08:34:23 UTC"
  },
  {
    "arxiv_id": "2502.18928v1",
    "title": "Talking like Piping and Instrumentation Diagrams (P&IDs)",
    "authors": [
      "Achmad Anggawirya Alimin",
      "Dominik P. Goldstein",
      "Lukas Schulze Balhorn",
      "Artur M. Schweidtmann"
    ],
    "abstract": "We propose a methodology that allows communication with Piping and\nInstrumentation Diagrams (P&IDs) using natural language. In particular, we\nrepresent P&IDs through the DEXPI data model as labeled property graphs and\nintegrate them with Large Language Models (LLMs). The approach consists of\nthree main parts: 1) P&IDs are cast into a graph representation from the DEXPI\nformat using our pyDEXPI Python package. 2) A tool for generating P&ID\nknowledge graphs from pyDEXPI. 3) Integration of the P&ID knowledge graph to\nLLMs using graph-based retrieval augmented generation (graph-RAG). This\napproach allows users to communicate with P&IDs using natural language. It\nextends LLM's ability to retrieve contextual data from P&IDs and mitigate\nhallucinations. Leveraging the LLM's large corpus, the model is also able to\ninterpret process information in PIDs, which could help engineers in their\ndaily tasks. In the future, this work will also open up opportunities in the\ncontext of other generative Artificial Intelligence (genAI) solutions on P&IDs,\nand AI-assisted HAZOP studies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18928v1",
    "published_date": "2025-02-26 08:30:35 UTC",
    "updated_date": "2025-02-26 08:30:35 UTC"
  },
  {
    "arxiv_id": "2502.18925v1",
    "title": "BeamVQ: Beam Search with Vector Quantization to Mitigate Data Scarcity in Physical Spatiotemporal Forecasting",
    "authors": [
      "Weiyan Wang",
      "Xingjian Shi",
      "Ruiqi Shu",
      "Yuan Gao",
      "Rui Ray Chen",
      "Kun Wang",
      "Fan Xu",
      "Jinbao Xue",
      "Shuaipeng Li",
      "Yangyu Tao",
      "Di Wang",
      "Hao Wu",
      "Xiaomeng Huang"
    ],
    "abstract": "In practice, physical spatiotemporal forecasting can suffer from data\nscarcity, because collecting large-scale data is non-trivial, especially for\nextreme events. Hence, we propose \\method{}, a novel probabilistic framework to\nrealize iterative self-training with new self-ensemble strategies, achieving\nbetter physical consistency and generalization on extreme events. Following any\nbase forecasting model, we can encode its deterministic outputs into a latent\nspace and retrieve multiple codebook entries to generate probabilistic outputs.\nThen BeamVQ extends the beam search from discrete spaces to the continuous\nstate spaces in this field. We can further employ domain-specific metrics\n(e.g., Critical Success Index for extreme events) to filter out the top-k\ncandidates and develop the new self-ensemble strategy by combining the\nhigh-quality candidates. The self-ensemble can not only improve the inference\nquality and robustness but also iteratively augment the training datasets\nduring continuous self-training. Consequently, BeamVQ realizes the exploration\nof rare but critical phenomena beyond the original dataset. Comprehensive\nexperiments on different benchmarks and backbones show that BeamVQ consistently\nreduces forecasting MSE (up to 39%), enhancing extreme events detection and\nproving its effectiveness in handling data scarcity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18925v1",
    "published_date": "2025-02-26 08:27:25 UTC",
    "updated_date": "2025-02-26 08:27:25 UTC"
  },
  {
    "arxiv_id": "2502.18915v2",
    "title": "END: Early Noise Dropping for Efficient and Effective Context Denoising",
    "authors": [
      "Hongye Jin",
      "Pei Chen",
      "Jingfeng Yang",
      "Zhengyang Wang",
      "Meng Jiang",
      "Yifan Gao",
      "Binxuan Huang",
      "Xinyang Zhang",
      "Zheng Li",
      "Tianyi Liu",
      "Huasheng Li",
      "Bing Yin"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of natural language processing tasks. However, they are often\ndistracted by irrelevant or noisy context in input sequences that degrades\noutput quality. This problem affects both long- and short-context scenarios,\nsuch as retrieval-augmented generation, table question-answering, and\nin-context learning. We reveal that LLMs can implicitly identify whether input\nsequences contain useful information at early layers, prior to token\ngeneration. Leveraging this insight, we introduce Early Noise Dropping\n(\\textsc{END}), a novel approach to mitigate this issue without requiring\nfine-tuning the LLMs. \\textsc{END} segments input sequences into chunks and\nemploys a linear prober on the early layers of LLMs to differentiate between\ninformative and noisy chunks. By discarding noisy chunks early in the process,\n\\textsc{END} preserves critical information, reduces distraction, and lowers\ncomputational overhead. Extensive experiments demonstrate that \\textsc{END}\nsignificantly improves both performance and efficiency across different LLMs on\nmultiple evaluation datasets. Furthermore, by investigating LLMs' implicit\nunderstanding to the input with the prober, this work also deepens\nunderstanding of how LLMs do reasoning with contexts internally.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "It's not approved by the legal from Amazon. They told us arXiv is not\n  allowed unless the paper is accepted later. It's under submission now",
    "pdf_url": "http://arxiv.org/pdf/2502.18915v2",
    "published_date": "2025-02-26 08:07:17 UTC",
    "updated_date": "2025-03-25 20:34:56 UTC"
  },
  {
    "arxiv_id": "2502.18891v1",
    "title": "Dynamic Classification: Leveraging Self-Supervised Classification to Enhance Prediction Performance",
    "authors": [
      "Ziyuan Zhong",
      "Junyang Zhou"
    ],
    "abstract": "In this paper, we propose an innovative dynamic classification algorithm\ndesigned to achieve the objective of zero missed detections and minimal false\npositives. The algorithm partitions the data into N equivalent training subsets\nand N prediction subsets using a supervised model, followed by independent\npredictions from N separate predictive models. This enables each predictive\nmodel to operate within a smaller data range, thereby improving overall\naccuracy. Additionally, the algorithm leverages data generated through\nsupervised learning to further refine prediction results, filtering out\npredictions that do not meet accuracy requirements without the need to\nintroduce additional models. Experimental results demonstrate that, when data\npartitioning errors are minimal, the dynamic classification algorithm achieves\nexceptional performance with zero missed detections and minimal false\npositives, significantly outperforming existing model ensembles. Even in cases\nwhere classification errors are larger, the algorithm remains comparable to\nstate of the art models. The key innovations of this study include\nself-supervised classification learning, the use of small-range subset\npredictions, and the direct rejection of substandard predictions. While the\ncurrent algorithm still has room for improvement in terms of automatic\nparameter tuning and classification model efficiency, it has demonstrated\noutstanding performance across multiple datasets. Future research will focus on\noptimizing the classification component to further enhance the algorithm's\nrobustness and adaptability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "J.0; I.0"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.18891v1",
    "published_date": "2025-02-26 07:11:12 UTC",
    "updated_date": "2025-02-26 07:11:12 UTC"
  },
  {
    "arxiv_id": "2502.18889v2",
    "title": "Clip-TTS: Contrastive Text-content and Mel-spectrogram, A High-Quality Text-to-Speech Method based on Contextual Semantic Understanding",
    "authors": [
      "Tianyun Liu"
    ],
    "abstract": "Traditional text-to-speech (TTS) methods primarily focus on establishing a\nmapping between phonemes and mel-spectrograms. However, during the phoneme\nencoding stage, there is often a lack of real mel-spectrogram auxiliary\ninformation, which results in the encoding process lacking true semantic\nunderstanding. At the same time, traditional TTS systems often struggle to\nbalance the inference speed of the model with the quality of the synthesized\nspeech. Methods that generate high-quality synthesized speech tend to have\nslower inference speeds, while faster inference methods often sacrifice speech\nquality. In this paper, I propose Clip-TTS, a TTS method based on the Clip\narchitecture. This method uses the Clip framework to establish a connection\nbetween text content and real mel-spectrograms during the text encoding stage,\nenabling the text encoder to directly learn the true semantics of the global\ncontext, thereby ensuring the quality of the synthesized speech. In terms of\nmodel architecture, I adopt the basic structure of Transformer, which allows\nClip-TTS to achieve fast inference speeds. Experimental results show that on\nthe LJSpeech and Baker datasets, the speech generated by Clip-TTS achieves\nstate-of-the-art MOS scores, and it also performs excellently on multi-emotion\ndatasets.Audio samples are available at: https://ltydd1314.github.io/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18889v2",
    "published_date": "2025-02-26 07:09:33 UTC",
    "updated_date": "2025-03-08 09:24:53 UTC"
  },
  {
    "arxiv_id": "2502.18875v1",
    "title": "SE(3)-Equivariant Ternary Complex Prediction Towards Target Protein Degradation",
    "authors": [
      "Fanglei Xue",
      "Meihan Zhang",
      "Shuqi Li",
      "Xinyu Gao",
      "James A. Wohlschlegel",
      "Wenbing Huang",
      "Yi Yang",
      "Weixian Deng"
    ],
    "abstract": "Targeted protein degradation (TPD) induced by small molecules has emerged as\na rapidly evolving modality in drug discovery, targeting proteins traditionally\nconsidered \"undruggable\". Proteolysis-targeting chimeras (PROTACs) and\nmolecular glue degraders (MGDs) are the primary small molecules that induce\nTPD. Both types of molecules form a ternary complex linking an E3 ligase with a\ntarget protein, a crucial step for drug discovery. While significant advances\nhave been made in binary structure prediction for proteins and small molecules,\nternary structure prediction remains challenging due to obscure interaction\nmechanisms and insufficient training data. Traditional methods relying on\nmanually assigned rules perform poorly and are computationally demanding due to\nextensive random sampling. In this work, we introduce DeepTernary, a novel deep\nlearning-based approach that directly predicts ternary structures in an\nend-to-end manner using an encoder-decoder architecture. DeepTernary leverages\nan SE(3)-equivariant graph neural network (GNN) with both intra-graph and\nternary inter-graph attention mechanisms to capture intricate ternary\ninteractions from our collected high-quality training dataset, TernaryDB. The\nproposed query-based Pocket Points Decoder extracts the 3D structure of the\nfinal binding ternary complex from learned ternary embeddings, demonstrating\nstate-of-the-art accuracy and speed in existing PROTAC benchmarks without prior\nknowledge from known PROTACs. It also achieves notable accuracy on the more\nchallenging MGD benchmark under the blind docking protocol. Remarkably, our\nexperiments reveal that the buried surface area calculated from predicted\nstructures correlates with experimentally obtained degradation potency-related\nmetrics. Consequently, DeepTernary shows potential in effectively assisting and\naccelerating the development of TPDs for previously undruggable targets.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18875v1",
    "published_date": "2025-02-26 06:33:24 UTC",
    "updated_date": "2025-02-26 06:33:24 UTC"
  },
  {
    "arxiv_id": "2502.18874v2",
    "title": "Learning to Align Multi-Faceted Evaluation: A Unified and Robust Framework",
    "authors": [
      "Kaishuai Xu",
      "Tiezheng Yu",
      "Wenjun Hou",
      "Yi Cheng",
      "Liangyou Li",
      "Xin Jiang",
      "Lifeng Shang",
      "Qun Liu",
      "Wenjie Li"
    ],
    "abstract": "Large Language Models (LLMs) are being used more and more extensively for\nautomated evaluation in various scenarios. Previous studies have attempted to\nfine-tune open-source LLMs to replicate the evaluation explanations and\njudgments of powerful proprietary models, such as GPT-4. However, these methods\nare largely limited to text-based analyses under predefined general criteria,\nresulting in reduced adaptability for unseen instructions and demonstrating\ninstability in evaluating adherence to quantitative and structural constraints.\nTo address these limitations, we propose a novel evaluation framework, ARJudge,\nthat adaptively formulates evaluation criteria and synthesizes both text-based\nand code-driven analyses to evaluate LLM responses. ARJudge consists of two\ncomponents: a fine-tuned Analyzer that generates multi-faceted evaluation\nanalyses and a tuning-free Refiner that combines and refines all analyses to\nmake the final judgment. We construct a Composite Analysis Corpus that\nintegrates tasks for evaluation criteria generation alongside text-based and\ncode-driven analysis generation to train the Analyzer. Our results demonstrate\nthat ARJudge outperforms existing fine-tuned evaluators in effectiveness and\nrobustness. Furthermore, it demonstrates the importance of multi-faceted\nevaluation and code-driven analyses in enhancing evaluation capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18874v2",
    "published_date": "2025-02-26 06:31:45 UTC",
    "updated_date": "2025-03-03 07:13:12 UTC"
  },
  {
    "arxiv_id": "2502.18873v1",
    "title": "Multi-LLM Collaborative Search for Complex Problem Solving",
    "authors": [
      "Sen Yang",
      "Yafu Li",
      "Wai Lam",
      "Yu Cheng"
    ],
    "abstract": "Large language models (LLMs) often struggle with complex reasoning tasks due\nto their limitations in addressing the vast reasoning space and inherent\nambiguities of natural language. We propose the Mixture-of-Search-Agents (MoSA)\nparadigm, a novel approach leveraging the collective expertise of multiple LLMs\nto enhance search-based reasoning. MoSA integrates diverse reasoning pathways\nby combining independent exploration with iterative refinement among LLMs,\nmitigating the limitations of single-model approaches. Using Monte Carlo Tree\nSearch (MCTS) as a backbone, MoSA enables multiple agents to propose and\naggregate reasoning steps, resulting in improved accuracy. Our comprehensive\nevaluation across four reasoning benchmarks demonstrates MoSA's consistent\nperformance improvements over single-agent and other multi-agent baselines,\nparticularly in complex mathematical and commonsense reasoning tasks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18873v1",
    "published_date": "2025-02-26 06:31:04 UTC",
    "updated_date": "2025-02-26 06:31:04 UTC"
  },
  {
    "arxiv_id": "2502.18871v1",
    "title": "Inscanner: Dual-Phase Detection and Classification of Auxiliary Insulation Using YOLOv8 Models",
    "authors": [
      "Youngtae Kim",
      "Soonju Jeong",
      "Sardar Arslan",
      "Dhananjay Agnihotri",
      "Yahya Ahmed",
      "Ali Nawaz",
      "Jinhee Song",
      "Hyewon Kim"
    ],
    "abstract": "This study proposes a two-phase methodology for detecting and classifying\nauxiliary insulation in structural components. In the detection phase, a\nYOLOv8x model is trained on a dataset of complete structural blueprints, each\nannotated with bounding boxes indicating areas that should contain insulation.\nIn the classification phase, these detected insulation patches are cropped and\ncategorized into two classes: present or missing. These are then used to train\na YOLOv8x-CLS model that determines the presence or absence of auxiliary\ninsulation. Preprocessing steps for both datasets included annotation,\naugmentation, and appropriate cropping of the insulation regions. The detection\nmodel achieved a mean average precision (mAP) score of 82%, while the\nclassification model attained an accuracy of 98%. These findings demonstrate\nthe effectiveness of the proposed approach in automating insulation detection\nand classification, providing a foundation for further advancements in this\ndomain.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18871v1",
    "published_date": "2025-02-26 06:29:30 UTC",
    "updated_date": "2025-02-26 06:29:30 UTC"
  },
  {
    "arxiv_id": "2502.19451v1",
    "title": "Multispectral to Hyperspectral using Pretrained Foundational model",
    "authors": [
      "Ruben Gonzalez",
      "Conrad M Albrecht",
      "Nassim Ait Ali Braham",
      "Devyani Lambhate",
      "Joao Lucas de Sousa Almeida",
      "Paolo Fraccaro",
      "Benedikt Blumenstiel",
      "Thomas Brunschwiler",
      "Ranjini Bangalore"
    ],
    "abstract": "Hyperspectral imaging provides detailed spectral information, offering\nsignificant potential for monitoring greenhouse gases like CH4 and NO2.\nHowever, its application is constrained by limited spatial coverage and\ninfrequent revisit times. In contrast, multispectral imaging delivers broader\nspatial and temporal coverage but lacks the spectral granularity required for\nprecise GHG detection. To address these challenges, this study proposes\nSpectral and Spatial-Spectral transformer models that reconstruct hyperspectral\ndata from multispectral inputs. The models in this paper are pretrained on\nEnMAP and EMIT datasets and fine-tuned on spatio-temporally aligned\n(Sentinel-2, EnMAP) and (HLS-S30, EMIT) image pairs respectively. Our model has\nthe potential to enhance atmospheric monitoring by combining the strengths of\nhyperspectral and multispectral imaging systems.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19451v1",
    "published_date": "2025-02-26 06:18:40 UTC",
    "updated_date": "2025-02-26 06:18:40 UTC"
  },
  {
    "arxiv_id": "2502.18865v1",
    "title": "A Theoretical Perspective: How to Prevent Model Collapse in Self-consuming Training Loops",
    "authors": [
      "Shi Fu",
      "Yingjie Wang",
      "Yuzhu Chen",
      "Xinmei Tian",
      "Dacheng Tao"
    ],
    "abstract": "High-quality data is essential for training large generative models, yet the\nvast reservoir of real data available online has become nearly depleted.\nConsequently, models increasingly generate their own data for further training,\nforming Self-consuming Training Loops (STLs). However, the empirical results\nhave been strikingly inconsistent: some models degrade or even collapse, while\nothers successfully avoid these failures, leaving a significant gap in\ntheoretical understanding to explain this discrepancy. This paper introduces\nthe intriguing notion of recursive stability and presents the first theoretical\ngeneralization analysis, revealing how both model architecture and the\nproportion between real and synthetic data influence the success of STLs. We\nfurther extend this analysis to transformers in in-context learning, showing\nthat even a constant-sized proportion of real data ensures convergence, while\nalso providing insights into optimal synthetic data sizing.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.18865v1",
    "published_date": "2025-02-26 06:18:13 UTC",
    "updated_date": "2025-02-26 06:18:13 UTC"
  },
  {
    "arxiv_id": "2502.18864v1",
    "title": "Towards an AI co-scientist",
    "authors": [
      "Juraj Gottweis",
      "Wei-Hung Weng",
      "Alexander Daryin",
      "Tao Tu",
      "Anil Palepu",
      "Petar Sirkovic",
      "Artiom Myaskovsky",
      "Felix Weissenberger",
      "Keran Rong",
      "Ryutaro Tanno",
      "Khaled Saab",
      "Dan Popovici",
      "Jacob Blum",
      "Fan Zhang",
      "Katherine Chou",
      "Avinatan Hassidim",
      "Burak Gokturk",
      "Amin Vahdat",
      "Pushmeet Kohli",
      "Yossi Matias",
      "Andrew Carroll",
      "Kavita Kulkarni",
      "Nenad Tomasev",
      "Yuan Guan",
      "Vikram Dhillon",
      "Eeshit Dhaval Vaishnav",
      "Byron Lee",
      "Tiago R D Costa",
      "José R Penadés",
      "Gary Peltz",
      "Yunhan Xu",
      "Annalisa Pawlosky",
      "Alan Karthikesalingam",
      "Vivek Natarajan"
    ],
    "abstract": "Scientific discovery relies on scientists generating novel hypotheses that\nundergo rigorous experimental validation. To augment this process, we introduce\nan AI co-scientist, a multi-agent system built on Gemini 2.0. The AI\nco-scientist is intended to help uncover new, original knowledge and to\nformulate demonstrably novel research hypotheses and proposals, building upon\nprior evidence and aligned to scientist-provided research objectives and\nguidance. The system's design incorporates a generate, debate, and evolve\napproach to hypothesis generation, inspired by the scientific method and\naccelerated by scaling test-time compute. Key contributions include: (1) a\nmulti-agent architecture with an asynchronous task execution framework for\nflexible compute scaling; (2) a tournament evolution process for self-improving\nhypotheses generation. Automated evaluations show continued benefits of\ntest-time compute, improving hypothesis quality. While general purpose, we\nfocus development and validation in three biomedical areas: drug repurposing,\nnovel target discovery, and explaining mechanisms of bacterial evolution and\nanti-microbial resistance. For drug repurposing, the system proposes candidates\nwith promising validation findings, including candidates for acute myeloid\nleukemia that show tumor inhibition in vitro at clinically applicable\nconcentrations. For novel target discovery, the AI co-scientist proposed new\nepigenetic targets for liver fibrosis, validated by anti-fibrotic activity and\nliver cell regeneration in human hepatic organoids. Finally, the AI\nco-scientist recapitulated unpublished experimental results via a parallel in\nsilico discovery of a novel gene transfer mechanism in bacterial evolution.\nThese results, detailed in separate, co-timed reports, demonstrate the\npotential to augment biomedical and scientific discovery and usher an era of AI\nempowered scientists.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG",
      "physics.soc-ph",
      "q-bio.OT"
    ],
    "primary_category": "cs.AI",
    "comment": "81 pages in total (main 38 pages, appendix 43 pages), 13 main\n  figures, 40 appendix figures, 1 main table, 2 appendix tables, 143 main\n  references, 7 appendix references",
    "pdf_url": "http://arxiv.org/pdf/2502.18864v1",
    "published_date": "2025-02-26 06:17:13 UTC",
    "updated_date": "2025-02-26 06:17:13 UTC"
  },
  {
    "arxiv_id": "2502.18863v1",
    "title": "Sherlock: Towards Multi-scene Video Abnormal Event Extraction and Localization via a Global-local Spatial-sensitive LLM",
    "authors": [
      "Junxiao Ma",
      "Jingjing Wang",
      "Jiamin Luo",
      "Peiying Yu",
      "Guodong Zhou"
    ],
    "abstract": "Prior studies on Video Anomaly Detection (VAD) mainly focus on detecting\nwhether each video frame is abnormal or not in the video, which largely ignore\nthe structured video semantic information (i.e., what, when, and where does the\nabnormal event happen). With this in mind, we propose a new chat-paradigm\n\\textbf{M}ulti-scene Video Abnormal Event Extraction and Localization (M-VAE)\ntask, aiming to extract the abnormal event quadruples (i.e., subject, event\ntype, object, scene) and localize such event. Further, this paper believes that\nthis new task faces two key challenges, i.e., global-local spatial modeling and\nglobal-local spatial balancing. To this end, this paper proposes a Global-local\nSpatial-sensitive Large Language Model (LLM) named Sherlock, i.e., acting like\nSherlock Holmes to track down the criminal events, for this M-VAE task.\nSpecifically, this model designs a Global-local Spatial-enhanced MoE (GSM)\nmodule and a Spatial Imbalance Regulator (SIR) to address the two challenges\nrespectively. Extensive experiments on our M-VAE instruction dataset show the\nsignificant advantages of Sherlock over several advanced Video-LLMs. This\njustifies the importance of global-local spatial information for the M-VAE task\nand the effectiveness of Sherlock in capturing such information.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18863v1",
    "published_date": "2025-02-26 06:16:37 UTC",
    "updated_date": "2025-02-26 06:16:37 UTC"
  },
  {
    "arxiv_id": "2502.18862v1",
    "title": "Investigating Generalization of One-shot LLM Steering Vectors",
    "authors": [
      "Jacob Dunefsky",
      "Arman Cohan"
    ],
    "abstract": "Steering vectors have emerged as a promising approach for interpreting and\ncontrolling LLMs, but current methods typically require large contrastive\ndatasets that are often impractical to construct and may capture spurious\ncorrelations. We propose directly optimizing steering vectors through gradient\ndescent on a single training example, and systematically investigate how these\nvectors generalize. We consider several steering optimization techniques,\nincluding multiple novel ones, and find that the resulting vectors effectively\nmediate safety-relevant behaviors in multiple models. Indeed, in experiments on\nan alignment-faking model, we are able to optimize one-shot steering vectors\nthat induce harmful behavior on benign examples and whose negations suppress\nharmful behavior on malign examples. And in experiments on refusal suppression,\nwe demonstrate that one-shot optimized steering vectors can transfer across\ninputs, yielding a Harmbench attack success rate of 96.9%. Furthermore, to\nquantitatively assess steering effectiveness in instruction-tuned models, we\ndevelop a novel evaluation framework using sequence probabilities from the\ncorresponding base model. With this framework, we analyze how steering vectors\nmodulate an instruction-tuned LLM's ability to recover from outputting false\ninformation, and find that this ability derives from the base model. Overall,\nour findings suggest that optimizing steering vectors on a single example can\nmediate misaligned behavior in LLMs, and provide a path toward better\nunderstanding the relationship between LLM behavior and activation space\nstructure.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 7 figures. Code is available at\n  https://github.com/jacobdunefsky/one-shot-steering-repro",
    "pdf_url": "http://arxiv.org/pdf/2502.18862v1",
    "published_date": "2025-02-26 06:13:01 UTC",
    "updated_date": "2025-02-26 06:13:01 UTC"
  },
  {
    "arxiv_id": "2502.18858v2",
    "title": "Evaluating Intelligence via Trial and Error",
    "authors": [
      "Jingtao Zhan",
      "Jiahao Zhao",
      "Jiayu Li",
      "Yiqun Liu",
      "Bo Zhang",
      "Qingyao Ai",
      "Jiaxin Mao",
      "Hongning Wang",
      "Min Zhang",
      "Shaoping Ma"
    ],
    "abstract": "Intelligence is a crucial trait for species to find solutions within a\nlimited number of trial-and-error attempts. Building on this idea, we introduce\nSurvival Game as a framework to evaluate intelligence based on the number of\nfailed attempts in a trial-and-error process. Fewer failures indicate higher\nintelligence. When the expectation and variance of failure counts are both\nfinite, it signals the ability to consistently find solutions to new\nchallenges, which we define as the Autonomous Level of intelligence. Using\nSurvival Game, we comprehensively evaluate existing AI systems. Our results\nshow that while AI systems achieve the Autonomous Level in simple tasks, they\nare still far from it in more complex tasks, such as vision, search,\nrecommendation, and language. While scaling current AI technologies might help,\nthis would come at an astronomical cost. Projections suggest that achieving the\nAutonomous Level for general tasks would require $10^{26}$ parameters. To put\nthis into perspective, loading such a massive model requires so many H100 GPUs\nthat their total value is $10^{7}$ times that of Apple Inc.'s market value.\nEven with Moore's Law, supporting such a parameter scale would take $70$ years.\nThis staggering cost highlights the complexity of human tasks and the\ninadequacies of current AI technologies. To further investigate this\nphenomenon, we conduct a theoretical analysis of Survival Game and its\nexperimental results. Our findings suggest that human tasks possess a\ncriticality property. As a result, Autonomous Level requires a deep\nunderstanding of the task's underlying mechanisms. Current AI systems, however,\ndo not fully grasp these mechanisms and instead rely on superficial mimicry,\nmaking it difficult for them to reach an autonomous level. We believe Survival\nGame can not only guide the future development of AI but also offer profound\ninsights into human intelligence.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18858v2",
    "published_date": "2025-02-26 05:59:45 UTC",
    "updated_date": "2025-03-03 13:38:50 UTC"
  },
  {
    "arxiv_id": "2502.18853v1",
    "title": "Reimagining Personal Data: Unlocking the Potential of AI-Generated Images in Personal Data Meaning-Making",
    "authors": [
      "Soobin Park",
      "Hankyung Kim",
      "Youn-kyung Lim"
    ],
    "abstract": "Image-generative AI provides new opportunities to transform personal data\ninto alternative visual forms. In this paper, we illustrate the potential of\nAI-generated images in facilitating meaningful engagement with personal data.\nIn a formative autobiographical design study, we explored the design and use of\nAI-generated images derived from personal data. Informed by this study, we\ndesigned a web-based application as a probe that represents personal data\nthrough generative images utilizing Open AI's GPT-4 model and DALL-E 3. We then\nconducted a 21-day diary study and interviews using the probe with 16\nparticipants to investigate users' in-depth experiences with images generated\nby AI in everyday lives. Our findings reveal new qualities of experiences in\nusers' engagement with data, highlighting how participants constructed personal\nmeaning from their data through imagination and speculation on AI-generated\nimages. We conclude by discussing the potential and concerns of leveraging\nimage-generative AI for personal data meaning-making.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.0"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages excluding reference and appendix. Accepted at ACM CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.18853v1",
    "published_date": "2025-02-26 05:50:57 UTC",
    "updated_date": "2025-02-26 05:50:57 UTC"
  },
  {
    "arxiv_id": "2502.18851v1",
    "title": "Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code",
    "authors": [
      "Jungin Kim",
      "Shinwoo Park",
      "Yo-Sub Han"
    ],
    "abstract": "Code watermarking identifies AI-generated code by embedding patterns into the\ncode during generation. Effective watermarking requires meeting two key\nconditions: the watermark should be reliably detectable, and the code should\nretain its original functionality. However, existing methods often modify\ntokens that are critical for program logic, such as keywords in conditional\nexpressions or operators in arithmetic computations. These modifications can\ncause syntax errors or functional failures, limiting the practical use of\nwatermarking. We present STONE, a method that preserves functional integrity by\nselectively inserting watermarks only into non-syntax tokens. By excluding\ntokens essential for code execution, STONE minimizes the risk of functional\ndegradation.\n  In addition, we introduce CWEM, a comprehensive evaluation metric that\nevaluates watermarking techniques based on correctness, detectability, and\nnaturalness. While correctness and detectability have been widely used,\nnaturalness remains underexplored despite its importance. Unnatural patterns\ncan reveal the presence of a watermark, making it easier for adversaries to\nremove. We evaluate STONE using CWEM and compare its performance with the\nstate-of-the-art approach. The results show that STONE achieves an average\nimprovement of 7.69% in CWEM across Python, C++, and Java. Our code is\navailable in https://github.com/inistory/STONE-watermarking/.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18851v1",
    "published_date": "2025-02-26 05:46:13 UTC",
    "updated_date": "2025-02-26 05:46:13 UTC"
  },
  {
    "arxiv_id": "2502.18848v1",
    "title": "A Causal Lens for Evaluating Faithfulness Metrics",
    "authors": [
      "Kerem Zaman",
      "Shashank Srivastava"
    ],
    "abstract": "Large Language Models (LLMs) offer natural language explanations as an\nalternative to feature attribution methods for model interpretability. However,\ndespite their plausibility, they may not reflect the model's internal reasoning\nfaithfully, which is crucial for understanding the model's true decision-making\nprocesses. Although several faithfulness metrics have been proposed, a unified\nevaluation framework remains absent. To address this gap, we present Causal\nDiagnosticity, a framework to evaluate faithfulness metrics for natural\nlanguage explanations. Our framework employs the concept of causal\ndiagnosticity, and uses model-editing methods to generate faithful-unfaithful\nexplanation pairs. Our benchmark includes four tasks: fact-checking, analogy,\nobject counting, and multi-hop reasoning. We evaluate a variety of faithfulness\nmetrics, including post-hoc explanation and chain-of-thought-based methods. We\nfind that all tested faithfulness metrics often fail to surpass a random\nbaseline. Our work underscores the need for improved metrics and more reliable\ninterpretability methods in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 18 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.18848v1",
    "published_date": "2025-02-26 05:35:53 UTC",
    "updated_date": "2025-02-26 05:35:53 UTC"
  },
  {
    "arxiv_id": "2502.18845v1",
    "title": "Sliding Window Attention Training for Efficient Large Language Models",
    "authors": [
      "Zichuan Fu",
      "Wentao Song",
      "Yejing Wang",
      "Xian Wu",
      "Yefeng Zheng",
      "Yingying Zhang",
      "Derong Xu",
      "Xuetao Wei",
      "Tong Xu",
      "Xiangyu Zhao"
    ],
    "abstract": "Recent advances in transformer-based Large Language Models (LLMs) have\ndemonstrated remarkable capabilities across various tasks. However, their\nquadratic computational complexity concerning sequence length remains a\nsignificant bottleneck for processing long documents. As a result, many efforts\nlike sparse attention and state space models have been proposed to improve the\nefficiency of LLMs over long sequences. Though effective, these approaches\ncompromise the performance or introduce structural complexity. This calls for a\nsimple yet efficient model that preserves the fundamental Transformer\narchitecture. To this end, we introduce SWAT, which enables efficient\nlong-context handling via Sliding Window Attention Training. This paper first\nattributes the inefficiency of Transformers to the attention sink phenomenon\nresulting from the high variance of softmax operation. Then, we replace softmax\nwith the sigmoid function and utilize a balanced ALiBi and Rotary Position\nEmbedding for efficient information compression and retention. Experiments\ndemonstrate that SWAT achieves SOTA performance compared with state-of-the-art\nlinear recurrent architectures on eight benchmarks. Code is available at\nhttps://anonymous.4open.science/r/SWAT-attention.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.18845v1",
    "published_date": "2025-02-26 05:31:44 UTC",
    "updated_date": "2025-02-26 05:31:44 UTC"
  },
  {
    "arxiv_id": "2502.18844v1",
    "title": "BarkXAI: A Lightweight Post-Hoc Explainable Method for Tree Species Classification with Quantifiable Concepts",
    "authors": [
      "Yunmei Huang",
      "Songlin Hou",
      "Zachary Nelson Horve",
      "Songlin Fei"
    ],
    "abstract": "The precise identification of tree species is fundamental to forestry,\nconservation, and environmental monitoring. Though many studies have\ndemonstrated that high accuracy can be achieved using bark-based species\nclassification, these models often function as \"black boxes\", limiting\ninterpretability, trust, and adoption in critical forestry applications.\nAttribution-based Explainable AI (XAI) methods have been used to address this\nissue in related works. However, XAI applications are often dependent on local\nfeatures (such as a head shape or paw in animal applications) and cannot\ndescribe global visual features (such as ruggedness or smoothness) that are\npresent in texture-dominant images such as tree bark. Concept-based XAI\nmethods, on the other hand, offer explanations based on global visual features\nwith concepts, but they tend to require large overhead in building external\nconcept image datasets and the concepts can be vague and subjective without\ngood means of precise quantification. To address these challenges, we propose a\nlightweight post-hoc method to interpret visual models for tree species\nclassification using operators and quantifiable concepts. Our approach\neliminates computational overhead, enables the quantification of complex\nconcepts, and evaluates both concept importance and the model's reasoning\nprocess. To the best of our knowledge, our work is the first study to explain\nbark vision models in terms of global visual features with concepts. Using a\nhuman-annotated dataset as ground truth, our experiments demonstrate that our\nmethod significantly outperforms TCAV and Llama3.2 in concept importance\nranking based on Kendall's Tau, highlighting its superior alignment with human\nperceptions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18844v1",
    "published_date": "2025-02-26 05:31:15 UTC",
    "updated_date": "2025-02-26 05:31:15 UTC"
  },
  {
    "arxiv_id": "2502.18842v2",
    "title": "Attention-Guided Integration of CLIP and SAM for Precise Object Masking in Robotic Manipulation",
    "authors": [
      "Muhammad A. Muttaqien",
      "Tomohiro Motoda",
      "Ryo Hanai",
      "Domae Yukiyasu"
    ],
    "abstract": "This paper introduces a novel pipeline to enhance the precision of object\nmasking for robotic manipulation within the specific domain of masking products\nin convenience stores. The approach integrates two advanced AI models, CLIP and\nSAM, focusing on their synergistic combination and the effective use of\nmultimodal data (image and text). Emphasis is placed on utilizing\ngradient-based attention mechanisms and customized datasets to fine-tune\nperformance. While CLIP, SAM, and Grad- CAM are established components, their\nintegration within this structured pipeline represents a significant\ncontribution to the field. The resulting segmented masks, generated through\nthis combined approach, can be effectively utilized as inputs for robotic\nsystems, enabling more precise and adaptive object manipulation in the context\nof convenience store products.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18842v2",
    "published_date": "2025-02-26 05:30:46 UTC",
    "updated_date": "2025-02-28 02:20:15 UTC"
  },
  {
    "arxiv_id": "2502.18836v1",
    "title": "REALM-Bench: A Real-World Planning Benchmark for LLMs and Multi-Agent Systems",
    "authors": [
      "Longling Geng",
      "Edward Y. Chang"
    ],
    "abstract": "This benchmark suite provides a comprehensive evaluation framework for\nassessing both individual LLMs and multi-agent systems in real-world planning\nscenarios. The suite encompasses eleven designed problems that progress from\nbasic to highly complex, incorporating key aspects such as multi-agent\ncoordination, inter-agent dependencies, and dynamic environmental disruptions.\nEach problem can be scaled along three dimensions: the number of parallel\nplanning threads, the complexity of inter-dependencies, and the frequency of\nunexpected disruptions requiring real-time adaptation. The benchmark includes\ndetailed specifications, evaluation metrics, and baseline implementations using\ncontemporary frameworks like LangGraph, enabling rigorous testing of both\nsingle-agent and multi-agent planning capabilities. Through standardized\nevaluation criteria and scalable complexity, this benchmark aims to drive\nprogress in developing more robust and adaptable AI planning systems for\nreal-world applications.",
    "categories": [
      "cs.AI",
      "I.2.11"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 4 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.18836v1",
    "published_date": "2025-02-26 05:24:22 UTC",
    "updated_date": "2025-02-26 05:24:22 UTC"
  },
  {
    "arxiv_id": "2502.18822v1",
    "title": "Data-Efficient Multi-Agent Spatial Planning with LLMs",
    "authors": [
      "Huangyuan Su",
      "Aaron Walsman",
      "Daniel Garces",
      "Sham Kakade",
      "Stephanie Gil"
    ],
    "abstract": "In this project, our goal is to determine how to leverage the world-knowledge\nof pretrained large language models for efficient and robust learning in\nmultiagent decision making. We examine this in a taxi routing and assignment\nproblem where agents must decide how to best pick up passengers in order to\nminimize overall waiting time. While this problem is situated on a graphical\nroad network, we show that with the proper prompting zero-shot performance is\nquite strong on this task. Furthermore, with limited fine-tuning along with the\none-at-a-time rollout algorithm for look ahead, LLMs can out-compete existing\napproaches with 50 times fewer environmental interactions. We also explore the\nbenefits of various linguistic prompting approaches and show that including\ncertain easy-to-compute information in the prompt significantly improves\nperformance. Finally, we highlight the LLM's built-in semantic understanding,\nshowing its ability to adapt to environmental factors through simple prompts.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18822v1",
    "published_date": "2025-02-26 04:53:07 UTC",
    "updated_date": "2025-02-26 04:53:07 UTC"
  },
  {
    "arxiv_id": "2502.18810v1",
    "title": "Holistic Audit Dataset Generation for LLM Unlearning via Knowledge Graph Traversal and Redundancy Removal",
    "authors": [
      "Weipeng Jiang",
      "Juan Zhai",
      "Shiqing Ma",
      "Ziyan Lei",
      "Xiaofei Xie",
      "Yige Wang",
      "Chao Shen"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have faced increasing demands\nto selectively remove sensitive information, protect privacy, and comply with\ncopyright regulations through unlearning, by Machine Unlearning. While\nevaluating unlearning effectiveness is crucial, existing benchmarks are limited\nin scale and comprehensiveness, typically containing only a few hundred test\ncases. We identify two critical challenges in generating holistic audit\ndatasets: ensuring audit adequacy and handling knowledge redundancy between\nforget and retain dataset. To address these challenges, we propose HANKER, an\nautomated framework for holistic audit dataset generation leveraging knowledge\ngraphs to achieve fine-grained coverage and eliminate redundant knowledge.\nApplying HANKER to the popular MUSE benchmark, we successfully generated over\n69,000 and 111,000 audit cases for the News and Books datasets respectively,\nidentifying thousands of knowledge memorization instances that the previous\nbenchmark failed to detect. Our empirical analysis uncovers how knowledge\nredundancy significantly skews unlearning effectiveness metrics, with redundant\ninstances artificially inflating the observed memorization measurements ROUGE\nfrom 19.7% to 26.1% and Entailment Scores from 32.4% to 35.2%, highlighting the\nnecessity of systematic deduplication for accurate assessment.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7; D.2.5; I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.18810v1",
    "published_date": "2025-02-26 04:39:22 UTC",
    "updated_date": "2025-02-26 04:39:22 UTC"
  },
  {
    "arxiv_id": "2503.00046v1",
    "title": "Leveraging Large Models for Evaluating Novel Content: A Case Study on Advertisement Creativity",
    "authors": [
      "Zhaoyi Joey Hou",
      "Adriana Kovashka",
      "Xiang Lorraine Li"
    ],
    "abstract": "Evaluating creativity is challenging, even for humans, not only because of\nits subjectivity but also because it involves complex cognitive processes.\nInspired by work in marketing, we attempt to break down visual advertisement\ncreativity into atypicality and originality. With fine-grained human\nannotations on these dimensions, we propose a suit of tasks specifically for\nsuch a subjective problem. We also evaluate the alignment between\nstate-of-the-art (SoTA) vision language models (VLM) and humans on our proposed\nbenchmark, demonstrating both the promises and challenges of using VLMs for\nautomatic creativity assessment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00046v1",
    "published_date": "2025-02-26 04:28:03 UTC",
    "updated_date": "2025-02-26 04:28:03 UTC"
  },
  {
    "arxiv_id": "2502.18807v2",
    "title": "BatteryLife: A Comprehensive Dataset and Benchmark for Battery Life Prediction",
    "authors": [
      "Ruifeng Tan",
      "Weixiang Hong",
      "Jiayue Tang",
      "Xibin Lu",
      "Ruijun Ma",
      "Xiang Zheng",
      "Jia Li",
      "Jiaqiang Huang",
      "Tong-Yi Zhang"
    ],
    "abstract": "Battery Life Prediction (BLP), which relies on time series data produced by\nbattery degradation tests, is crucial for battery utilization, optimization,\nand production. Despite impressive advancements, this research area faces three\nkey challenges. Firstly, the limited size of existing datasets impedes insights\ninto modern battery life data. Secondly, most datasets are restricted to\nsmall-capacity lithium-ion batteries tested under a narrow range of diversity\nin labs, raising concerns about the generalizability of findings. Thirdly,\ninconsistent and limited benchmarks across studies obscure the effectiveness of\nbaselines and leave it unclear if models popular in other time series fields\nare effective for BLP. To address these challenges, we propose BatteryLife, a\ncomprehensive dataset and benchmark for BLP. BatteryLife integrates 16\ndatasets, offering a 2.4 times sample size compared to the previous largest\ndataset, and provides the most diverse battery life resource with batteries\nfrom 8 formats, 80 chemical systems, 12 operating temperatures, and 646\ncharge/discharge protocols, including both laboratory and industrial tests.\nNotably, BatteryLife is the first to release battery life datasets of zinc-ion\nbatteries, sodium-ion batteries, and industry-tested large-capacity lithium-ion\nbatteries. With the comprehensive dataset, we revisit the effectiveness of\nbaselines popular in this and other time series fields. Furthermore, we propose\nCyclePatch, a plug-in technique that can be employed in a series of neural\nnetworks. Extensive benchmarking of 18 methods reveals that models popular in\nother time series fields can be unsuitable for BLP, and CyclePatch consistently\nimproves model performance establishing state-of-the-art benchmarks. Moreover,\nBatteryLife evaluates model performance across aging conditions and domains.\nBatteryLife is available at https://github.com/Ruifeng-Tan/BatteryLife.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2502.18807v2",
    "published_date": "2025-02-26 04:21:20 UTC",
    "updated_date": "2025-02-27 03:53:57 UTC"
  },
  {
    "arxiv_id": "2502.18798v3",
    "title": "ANPMI: Assessing the True Comprehension Capabilities of LLMs for Multiple Choice Questions",
    "authors": [
      "Gyeongje Cho",
      "Yeonkyoung So",
      "Jaejin Lee"
    ],
    "abstract": "Multiple-choice benchmarks, consisting of various prompts and choices, are\namong the most widely used methods to assess a language model's natural\nlanguage understanding capability. Given a specific prompt, we typically\ncompute $P(Choice|Prompt)$ to evaluate how likely a language model is to\ngenerate the correct choice compared to incorrect ones. However, we observe\nthat performance measured using this approach reflects not only the model's\ncomprehension of the prompt but also its inherent biases for certain choices\nregardless of the prompt. This issue makes it challenging to accurately measure\na model's natural language understanding, as models may select the answer\nwithout fully understanding the prompt. To address this limitation, we propose\na novel metric called ANPMI, which normalizes Pointwise Mutual Information\n(PMI) by $-\\log P(Choice)$. ANPMI provides a more accurate assessment of the\nmodel's natural language understanding by ensuring that it is challenging to\nanswer a question without properly understanding the prompt.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18798v3",
    "published_date": "2025-02-26 04:10:18 UTC",
    "updated_date": "2025-03-12 16:27:59 UTC"
  },
  {
    "arxiv_id": "2502.18791v2",
    "title": "Can LLMs Help Uncover Insights about LLMs? A Large-Scale, Evolving Literature Analysis of Frontier LLMs",
    "authors": [
      "Jungsoo Park",
      "Junmo Kang",
      "Gabriel Stanovsky",
      "Alan Ritter"
    ],
    "abstract": "The surge of LLM studies makes synthesizing their findings challenging.\nAnalysis of experimental results from literature can uncover important trends\nacross studies, but the time-consuming nature of manual data extraction limits\nits use. Our study presents a semi-automated approach for literature analysis\nthat accelerates data extraction using LLMs. It automatically identifies\nrelevant arXiv papers, extracts experimental results and related attributes,\nand organizes them into a structured dataset, LLMEvalDB. We then conduct an\nautomated literature analysis of frontier LLMs, reducing the effort of paper\nsurveying and data extraction by more than 93% compared to manual approaches.\nWe validate LLMEvalDB by showing that it reproduces key findings from a recent\nmanual analysis of Chain-of-Thought (CoT) reasoning and also uncovers new\ninsights that go beyond it, showing, for example, that in-context examples\nbenefit coding and multimodal tasks but offer limited gains in math reasoning\ntasks compared to zero-shot CoT. Our automatically updatable dataset enables\ncontinuous tracking of target models by extracting evaluation studies as new\ndata becomes available. Through LLMEvalDB and empirical analysis, we provide\ninsights into LLMs while facilitating ongoing literature analyses of their\nbehavior.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.18791v2",
    "published_date": "2025-02-26 03:56:34 UTC",
    "updated_date": "2025-04-10 19:47:50 UTC"
  },
  {
    "arxiv_id": "2502.18786v2",
    "title": "NeuroTree: Hierarchical Functional Brain Pathway Decoding for Mental Health Disorders",
    "authors": [
      "Jun-En Ding",
      "Dongsheng Luo",
      "Anna Zilverstand",
      "Feng Liu"
    ],
    "abstract": "Analyzing functional brain networks using functional magnetic resonance\nimaging (fMRI) is crucial for understanding psychiatric disorders and addictive\nbehaviors. While existing fMRI-based graph convolutional networks (GCNs) show\nconsiderable promise for feature extraction, they often fall short in\ncharacterizing complex relationships between brain regions and demographic\nfactors and accounting for interpretable variables linked to psychiatric\nconditions. We propose NeuroTree to overcome these limitations, integrating a\nk-hop AGE-GCN with neural ordinary differential equations (ODEs). This\nframework leverages an attention mechanism to optimize functional connectivity\n(FC), thereby enhancing dynamic FC feature learning for brain disease\nclassification. Furthermore, NeuroTree effectively decodes fMRI network\nfeatures into tree structures, which improves the capture of high-order brain\nregional pathway features and enables the identification of hierarchical neural\nbehavioral patterns essential for understanding disease-related brain\nsubnetworks. Our empirical evaluations demonstrate that NeuroTree achieves\nstate-of-the-art performance across two distinct mental disorder datasets and\nprovides valuable insights into age-related deterioration patterns. These\nfindings underscore the model's efficacy in predicting psychiatric disorders\nand elucidating their underlying neural mechanisms.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18786v2",
    "published_date": "2025-02-26 03:42:58 UTC",
    "updated_date": "2025-03-10 03:03:09 UTC"
  },
  {
    "arxiv_id": "2502.18778v3",
    "title": "M2-omni: Advancing Omni-MLLM for Comprehensive Modality Support with Competitive Performance",
    "authors": [
      "Qingpei Guo",
      "Kaiyou Song",
      "Zipeng Feng",
      "Ziping Ma",
      "Qinglong Zhang",
      "Sirui Gao",
      "Xuzheng Yu",
      "Yunxiao Sun",
      "Tai-Wei Chang",
      "Jingdong Chen",
      "Ming Yang",
      "Jun Zhou"
    ],
    "abstract": "We present M2-omni, a cutting-edge, open-source omni-MLLM that achieves\ncompetitive performance to GPT-4o. M2-omni employs a unified multimodal\nsequence modeling framework, which empowers Large Language Models(LLMs) to\nacquire comprehensive cross-modal understanding and generation capabilities.\nSpecifically, M2-omni can process arbitrary combinations of audio, video,\nimage, and text modalities as input, generating multimodal sequences\ninterleaving with audio, image, or text outputs, thereby enabling an advanced\nand interactive real-time experience. The training of such an omni-MLLM is\nchallenged by significant disparities in data quantity and convergence rates\nacross modalities. To address these challenges, we propose a step balance\nstrategy during pre-training to handle the quantity disparities in\nmodality-specific data. Additionally, a dynamically adaptive balance strategy\nis introduced during the instruction tuning stage to synchronize the\nmodality-wise training progress, ensuring optimal convergence. Notably, we\nprioritize preserving strong performance on pure text tasks to maintain the\nrobustness of M2-omni's language understanding capability throughout the\ntraining process. To our best knowledge, M2-omni is currently a very\ncompetitive open-source model to GPT-4o, characterized by its comprehensive\nmodality and task support, as well as its exceptional performance. We expect\nM2-omni will advance the development of omni-MLLMs, thus facilitating future\nresearch in this domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18778v3",
    "published_date": "2025-02-26 03:21:12 UTC",
    "updated_date": "2025-04-07 08:54:28 UTC"
  },
  {
    "arxiv_id": "2502.18773v2",
    "title": "Research on Edge Computing and Cloud Collaborative Resource Scheduling Optimization Based on Deep Reinforcement Learning",
    "authors": [
      "Yuqing Wang",
      "Xiao Yang"
    ],
    "abstract": "This study addresses the challenge of resource scheduling optimization in\nedge-cloud collaborative computing using deep reinforcement learning (DRL). The\nproposed DRL-based approach improves task processing efficiency, reduces\noverall processing time, enhances resource utilization, and effectively\ncontrols task migrations. Experimental results demonstrate the superiority of\nDRL over traditional scheduling algorithms, particularly in managing complex\ntask allocation, dynamic workloads, and multiple resource constraints. Despite\nits advantages, further improvements are needed to enhance learning efficiency,\nreduce training time, and address convergence issues. Future research should\nfocus on increasing the algorithm's fault tolerance to handle more complex and\nuncertain scheduling scenarios, thereby advancing the intelligence and\nefficiency of edge-cloud computing systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18773v2",
    "published_date": "2025-02-26 03:05:11 UTC",
    "updated_date": "2025-04-10 17:10:03 UTC"
  },
  {
    "arxiv_id": "2502.18770v2",
    "title": "Reward Shaping to Mitigate Reward Hacking in RLHF",
    "authors": [
      "Jiayi Fu",
      "Xuandong Zhao",
      "Chengyuan Yao",
      "Heng Wang",
      "Qi Han",
      "Yanghua Xiao"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is essential for aligning\nlarge language models (LLMs) with human values. However, RLHF is susceptible to\nreward hacking, where the agent exploits flaws in the reward function rather\nthan learning the intended behavior, thus degrading alignment. While reward\nshaping helps stabilize RLHF and partially mitigate reward hacking, a\nsystematic investigation into shaping techniques and their underlying\nprinciples remains lacking. To bridge this gap, we present a comprehensive\nstudy of the prevalent reward shaping methods. Our analysis suggests three key\ndesign principles: (1) RL reward is ideally bounded, (2) RL benefits from rapid\ninitial growth followed by gradual convergence, and (3) RL reward is best\nformulated as a function of centered reward. Guided by these insights, we\npropose Preference As Reward (PAR), a novel approach that leverages the latent\npreferences embedded within the reward model itself as the signal for\nreinforcement learning. We evaluated PAR on two base models, Gemma2-2B and\nLlama3-8B, using two datasets, Ultrafeedback-Binarized and HH-RLHF.\nExperimental results demonstrate PAR's superior performance over other reward\nshaping methods. On the AlpacaEval 2.0 benchmark, PAR achieves a win rate at\nleast 5 percentage points higher than competing approaches. Furthermore, PAR\nexhibits remarkable data efficiency, requiring only a single reference reward\nfor optimal performance, and maintains robustness against reward hacking even\nafter two full epochs of training. Code is available at\nhttps://github.com/PorUna-byte/PAR.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.18770v2",
    "published_date": "2025-02-26 02:57:59 UTC",
    "updated_date": "2025-02-27 04:49:19 UTC"
  },
  {
    "arxiv_id": "2502.18762v1",
    "title": "Online Prototypes and Class-Wise Hypergradients for Online Continual Learning with Pre-Trained Models",
    "authors": [
      "Nicolas Michel",
      "Maorong Wang",
      "Jiangpeng He",
      "Toshihiko Yamasaki"
    ],
    "abstract": "Continual Learning (CL) addresses the problem of learning from a data\nsequence where the distribution changes over time. Recently, efficient\nsolutions leveraging Pre-Trained Models (PTM) have been widely explored in the\noffline CL (offCL) scenario, where the data corresponding to each incremental\ntask is known beforehand and can be seen multiple times. However, such\nsolutions often rely on 1) prior knowledge regarding task changes and 2)\nhyper-parameter search, particularly regarding the learning rate. Both\nassumptions remain unavailable in online CL (onCL) scenarios, where incoming\ndata distribution is unknown and the model can observe each datum only once.\nTherefore, existing offCL strategies fall largely behind performance-wise in\nonCL, with some proving difficult or impossible to adapt to the online\nscenario. In this paper, we tackle both problems by leveraging Online\nPrototypes (OP) and Class-Wise Hypergradients (CWH). OP leverages stable output\nrepresentations of PTM by updating its value on the fly to act as replay\nsamples without requiring task boundaries or storing past data. CWH learns\nclass-dependent gradient coefficients during training to improve over\nsub-optimal learning rates. We show through experiments that both introduced\nstrategies allow for a consistent gain in accuracy when integrated with\nexisting approaches. We will make the code fully available upon acceptance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2502.18762v1",
    "published_date": "2025-02-26 02:43:54 UTC",
    "updated_date": "2025-02-26 02:43:54 UTC"
  },
  {
    "arxiv_id": "2502.18760v2",
    "title": "Learning Autonomy: Off-Road Navigation Enhanced by Human Input",
    "authors": [
      "Akhil Nagariya",
      "Dimitar Filev",
      "Srikanth Saripalli",
      "Gaurav Pandey"
    ],
    "abstract": "In the area of autonomous driving, navigating off-road terrains presents a\nunique set of challenges, from unpredictable surfaces like grass and dirt to\nunexpected obstacles such as bushes and puddles. In this work, we present a\nnovel learning-based local planner that addresses these challenges by directly\ncapturing human driving nuances from real-world demonstrations using only a\nmonocular camera. The key features of our planner are its ability to navigate\nin challenging off-road environments with various terrain types and its fast\nlearning capabilities. By utilizing minimal human demonstration data (5-10\nmins), it quickly learns to navigate in a wide array of off-road conditions.\nThe local planner significantly reduces the real world data required to learn\nhuman driving preferences. This allows the planner to apply learned behaviors\nto real-world scenarios without the need for manual fine-tuning, demonstrating\nquick adjustment and adaptability in off-road autonomous driving technology.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18760v2",
    "published_date": "2025-02-26 02:36:14 UTC",
    "updated_date": "2025-05-14 14:47:40 UTC"
  },
  {
    "arxiv_id": "2503.05777v1",
    "title": "Medical Hallucinations in Foundation Models and Their Impact on Healthcare",
    "authors": [
      "Yubin Kim",
      "Hyewon Jeong",
      "Shan Chen",
      "Shuyue Stella Li",
      "Mingyu Lu",
      "Kumail Alhamoud",
      "Jimin Mun",
      "Cristina Grau",
      "Minseok Jung",
      "Rodrigo Gameiro",
      "Lizhou Fan",
      "Eugene Park",
      "Tristan Lin",
      "Joonsik Yoon",
      "Wonjin Yoon",
      "Maarten Sap",
      "Yulia Tsvetkov",
      "Paul Liang",
      "Xuhai Xu",
      "Xin Liu",
      "Daniel McDuff",
      "Hyeonhoon Lee",
      "Hae Won Park",
      "Samir Tulebaev",
      "Cynthia Breazeal"
    ],
    "abstract": "Foundation Models that are capable of processing and generating multi-modal\ndata have transformed AI's role in medicine. However, a key limitation of their\nreliability is hallucination, where inaccurate or fabricated information can\nimpact clinical decisions and patient safety. We define medical hallucination\nas any instance in which a model generates misleading medical content. This\npaper examines the unique characteristics, causes, and implications of medical\nhallucinations, with a particular focus on how these errors manifest themselves\nin real-world clinical scenarios. Our contributions include (1) a taxonomy for\nunderstanding and addressing medical hallucinations, (2) benchmarking models\nusing medical hallucination dataset and physician-annotated LLM responses to\nreal medical cases, providing direct insight into the clinical impact of\nhallucinations, and (3) a multi-national clinician survey on their experiences\nwith medical hallucinations. Our results reveal that inference techniques such\nas Chain-of-Thought (CoT) and Search Augmented Generation can effectively\nreduce hallucination rates. However, despite these improvements, non-trivial\nlevels of hallucination persist. These findings underscore the ethical and\npractical imperative for robust detection and mitigation strategies,\nestablishing a foundation for regulatory policies that prioritize patient\nsafety and maintain clinical integrity as AI becomes more integrated into\nhealthcare. The feedback from clinicians highlights the urgent need for not\nonly technical advances but also for clearer ethical and regulatory guidelines\nto ensure patient safety. A repository organizing the paper resources,\nsummaries, and additional information is available at\nhttps://github.com/mitmedialab/medical hallucination.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05777v1",
    "published_date": "2025-02-26 02:30:44 UTC",
    "updated_date": "2025-02-26 02:30:44 UTC"
  },
  {
    "arxiv_id": "2502.18754v1",
    "title": "AgentSociety Challenge: Designing LLM Agents for User Modeling and Recommendation on Web Platforms",
    "authors": [
      "Yuwei Yan",
      "Yu Shang",
      "Qingbin Zeng",
      "Yu Li",
      "Keyu Zhao",
      "Zhiheng Zheng",
      "Xuefei Ning",
      "Tianji Wu",
      "Shengen Yan",
      "Yu Wang",
      "Fengli Xu",
      "Yong Li"
    ],
    "abstract": "The AgentSociety Challenge is the first competition in the Web Conference\nthat aims to explore the potential of Large Language Model (LLM) agents in\nmodeling user behavior and enhancing recommender systems on web platforms. The\nChallenge consists of two tracks: the User Modeling Track and the\nRecommendation Track. Participants are tasked to utilize a combined dataset\nfrom Yelp, Amazon, and Goodreads, along with an interactive environment\nsimulator, to develop innovative LLM agents. The Challenge has attracted 295\nteams across the globe and received over 1,400 submissions in total over the\ncourse of 37 official competition days. The participants have achieved 21.9%\nand 20.3% performance improvement for Track 1 and Track 2 in the Development\nPhase, and 9.1% and 15.9% in the Final Phase, representing a significant\naccomplishment. This paper discusses the detailed designs of the Challenge,\nanalyzes the outcomes, and highlights the most successful LLM agent designs. To\nsupport further research and development, we have open-sourced the benchmark\nenvironment at https://tsinghua-fib-lab.github.io/AgentSocietyChallenge.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "8 pages, 10 figures, in Proceedings of the ACM Web Conference 2025\n  (WWW '25)",
    "pdf_url": "http://arxiv.org/pdf/2502.18754v1",
    "published_date": "2025-02-26 02:10:25 UTC",
    "updated_date": "2025-02-26 02:10:25 UTC"
  },
  {
    "arxiv_id": "2503.05776v1",
    "title": "FAA-CLIP: Federated Adversarial Adaptation of CLIP",
    "authors": [
      "Yihang Wu",
      "Ahmad Chaddad",
      "Christian Desrosiers",
      "Tareef Daqqaq",
      "Reem Kateb"
    ],
    "abstract": "Despite the remarkable performance of vision language models (VLMs) such as\nContrastive Language Image Pre-training (CLIP), the large size of these models\nis a considerable obstacle to their use in federated learning (FL) systems\nwhere the parameters of local client models need to be transferred to a global\nserver for aggregation. Another challenge in FL is the heterogeneity of data\nfrom different clients, which affects the generalization performance of the\nsolution. In addition, natural pre-trained VLMs exhibit poor generalization\nability in the medical datasets, suggests there exists a domain gap. To solve\nthese issues, we introduce a novel method for the Federated Adversarial\nAdaptation (FAA) of CLIP. Our method, named FAA-CLIP, handles the large\ncommunication costs of CLIP using a light-weight feature adaptation module\n(FAM) for aggregation, effectively adapting this VLM to each client's data\nwhile greatly reducing the number of parameters to transfer. By keeping CLIP\nfrozen and only updating the FAM parameters, our method is also computationally\nefficient. Unlike existing approaches, our FAA-CLIP method directly addresses\nthe problem of domain shifts across clients via a domain adaptation (DA)\nmodule. This module employs a domain classifier to predict if a given sample is\nfrom the local client or the global server, allowing the model to learn\ndomain-invariant representations. Extensive experiments on six different\ndatasets containing both natural and medical images demonstrate that FAA-CLIP\ncan generalize well on both natural and medical datasets compared to recent FL\napproaches. Our codes are available at https://github.com/AIPMLab/FAA-CLIP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in IEEE Internet of Things Journal",
    "pdf_url": "http://arxiv.org/pdf/2503.05776v1",
    "published_date": "2025-02-26 01:51:11 UTC",
    "updated_date": "2025-02-26 01:51:11 UTC"
  },
  {
    "arxiv_id": "2502.18744v2",
    "title": "ZEBRA: Leveraging Model-Behavioral Knowledge for Zero-Annotation Preference Dataset Construction",
    "authors": [
      "Jeesu Jung",
      "Chanjun Park",
      "Sangkeun Jung"
    ],
    "abstract": "Recent efforts in LLM alignment have focused on constructing large-scale\npreference datasets via human or Artificial Intelligence (AI) annotators.\nHowever, such approaches rely on instance-wise supervision, incurring\nsubstantial annotation cost and limited interpretability. In this paper, we\npropose ZEBRA - a model behavior-wise zero-annotation framework that constructs\npreference data by leveraging model behavior knowledge derived from benchmark\nperformances. ZEBRA binarizes response pairs by evaluating the quality and\nsimilarity of their origin models, entirely bypassing instance-level\nannotation. This allows scalable, controllable, and cost-effective alignment\ndata generation. Empirical results show that ZEBRA achieves alignment\nperformance comparable to instance-supervised methods, despite requiring no\nmanual or model-based labeling.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages,7 figures,5 tables,4 graphs",
    "pdf_url": "http://arxiv.org/pdf/2502.18744v2",
    "published_date": "2025-02-26 01:36:40 UTC",
    "updated_date": "2025-05-20 23:20:33 UTC"
  },
  {
    "arxiv_id": "2502.18737v1",
    "title": "Intent Tagging: Exploring Micro-Prompting Interactions for Supporting Granular Human-GenAI Co-Creation Workflows",
    "authors": [
      "Frederic Gmeiner",
      "Nicolai Marquardt",
      "Michael Bentley",
      "Hugo Romat",
      "Michel Pahud",
      "David Brown",
      "Asta Roseway",
      "Nikolas Martelaro",
      "Kenneth Holstein",
      "Ken Hinckley",
      "Nathalie Riche"
    ],
    "abstract": "Despite Generative AI (GenAI) systems' potential for enhancing content\ncreation, users often struggle to effectively integrate GenAI into their\ncreative workflows. Core challenges include misalignment of AI-generated\ncontent with user intentions (intent elicitation and alignment), user\nuncertainty around how to best communicate their intents to the AI system\n(prompt formulation), and insufficient flexibility of AI systems to support\ndiverse creative workflows (workflow flexibility). Motivated by these\nchallenges, we created IntentTagger: a system for slide creation based on the\nnotion of Intent Tags - small, atomic conceptual units that encapsulate user\nintent - for exploring granular and non-linear micro-prompting interactions for\nHuman-GenAI co-creation workflows. Our user study with 12 participants provides\ninsights into the value of flexibly expressing intent across varying levels of\nambiguity, meta-intent elicitation, and the benefits and challenges of intent\ntag-driven workflows. We conclude by discussing the broader implications of our\nfindings and design considerations for GenAI-supported content creation\nworkflows.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "31 pages, 30 figures, 3 tables. To appear in the Proceedings of the\n  2025 ACM CHI Conference on Human Factors in Computing Systems, Yokohama,\n  Japan",
    "pdf_url": "http://arxiv.org/pdf/2502.18737v1",
    "published_date": "2025-02-26 01:13:47 UTC",
    "updated_date": "2025-02-26 01:13:47 UTC"
  },
  {
    "arxiv_id": "2502.18736v1",
    "title": "AI-Instruments: Embodying Prompts as Instruments to Abstract & Reflect Graphical Interface Commands as General-Purpose Tools",
    "authors": [
      "Nathalie Riche",
      "Anna Offenwanger",
      "Frederic Gmeiner",
      "David Brown",
      "Hugo Romat",
      "Michel Pahud",
      "Nicolai Marquardt",
      "Kori Inkpen",
      "Ken Hinckley"
    ],
    "abstract": "Chat-based prompts respond with verbose linear-sequential texts, making it\ndifficult to explore and refine ambiguous intents, back up and reinterpret, or\nshift directions in creative AI-assisted design work. AI-Instruments instead\nembody \"prompts\" as interface objects via three key principles: (1) Reification\nof user-intent as reusable direct-manipulation instruments; (2) Reflection of\nmultiple interpretations of ambiguous user-intents (Reflection-in-intent) as\nwell as the range of AI-model responses (Reflection-in-response) to inform\ndesign \"moves\" towards a desired result; and (3) Grounding to instantiate an\ninstrument from an example, result, or extrapolation directly from another\ninstrument. Further, AI-Instruments leverage LLM's to suggest, vary, and refine\nnew instruments, enabling a system that goes beyond hard-coded functionality by\ngenerating its own instrumental controls from content. We demonstrate four\ntechnology probes, applied to image generation, and qualitative insights from\ntwelve participants, showing how AI-Instruments address challenges of intent\nformulation, steering via direct manipulation, and non-linear iterative\nworkflows to reflect and resolve ambiguous intents.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "18 pages, 10 figures. To appear in the Proceedings of the 2025 ACM\n  CHI Conference on Human Factors in Computing Systems, Yokohama, Japan.\n  https://hugoromat.github.io/ai_instruments/",
    "pdf_url": "http://arxiv.org/pdf/2502.18736v1",
    "published_date": "2025-02-26 01:11:24 UTC",
    "updated_date": "2025-02-26 01:11:24 UTC"
  },
  {
    "arxiv_id": "2502.18733v1",
    "title": "Cross-Modality Investigation on WESAD Stress Classification",
    "authors": [
      "Eric Oliver",
      "Sagnik Dakshit"
    ],
    "abstract": "Deep learning's growing prevalence has driven its widespread use in\nhealthcare, where AI and sensor advancements enhance diagnosis, treatment, and\nmonitoring. In mobile health, AI-powered tools enable early diagnosis and\ncontinuous monitoring of conditions like stress. Wearable technologies and\nmultimodal physiological data have made stress detection increasingly viable,\nbut model efficacy depends on data quality, quantity, and modality. This study\ndevelops transformer models for stress detection using the WESAD dataset,\ntraining on electrocardiograms (ECG), electrodermal activity (EDA),\nelectromyography (EMG), respiration rate (RESP), temperature (TEMP), and 3-axis\naccelerometer (ACC) signals. The results demonstrate the effectiveness of\nsingle-modality transformers in analyzing physiological signals, achieving\nstate-of-the-art performance with accuracy, precision and recall values in the\nrange of $99.73\\%$ to $99.95\\%$ for stress detection. Furthermore, this study\nexplores cross-modal performance and also explains the same using 2D\nvisualization of the learned embedding space and quantitative analysis based on\ndata variance. Despite the large body of work on stress detection and\nmonitoring, the robustness and generalization of these models across different\nmodalities has not been explored. This research represents one of the initial\nefforts to interpret embedding spaces for stress detection, providing valuable\ninformation on cross-modal performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18733v1",
    "published_date": "2025-02-26 01:04:58 UTC",
    "updated_date": "2025-02-26 01:04:58 UTC"
  },
  {
    "arxiv_id": "2503.16464v1",
    "title": "Human-Centered AI in Multidisciplinary Medical Discussions: Evaluating the Feasibility of a Chat-Based Approach to Case Assessment",
    "authors": [
      "Shinnosuke Sawano",
      "Satoshi Kodera"
    ],
    "abstract": "In this study, we investigate the feasibility of using a human-centered\nartificial intelligence (AI) chat platform where medical specialists\ncollaboratively assess complex cases. As the target population for this\nplatform, we focus on patients with cardiovascular diseases who are in a state\nof multimorbidity, that is, suffering from multiple chronic conditions. We\nevaluate simulated cases with multiple diseases using a chat application by\ncollaborating with physicians to assess feasibility, efficiency gains through\nAI utilization, and the quantification of discussion content. We constructed\nsimulated cases based on past case reports, medical errors reports and complex\ncases of cardiovascular diseases experienced by the physicians. The analysis of\ndiscussions across five simulated cases demonstrated a significant reduction in\nthe time required for summarization using AI, with an average reduction of\n79.98\\%. Additionally, we examined hallucination rates in AI-generated\nsummaries used in multidisciplinary medical discussions. The overall\nhallucination rate ranged from 1.01\\% to 5.73\\%, with an average of 3.62\\%,\nwhereas the harmful hallucination rate varied from 0.00\\% to 2.09\\%, with an\naverage of 0.49\\%. Furthermore, morphological analysis demonstrated that\nmultidisciplinary assessments enabled a more complex and detailed\nrepresentation of medical knowledge compared with single physician assessments.\nWe examined structural differences between multidisciplinary and single\nphysician assessments using centrality metrics derived from the knowledge\ngraph. In this study, we demonstrated that AI-assisted summarization\nsignificantly reduced the time required for medical discussions while\nmaintaining structured knowledge representation. These findings can support the\nfeasibility of AI-assisted chat-based discussions as a human-centered approach\nto multidisciplinary medical decision-making.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 2 figures, 3 tables, 2 supplemental figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16464v1",
    "published_date": "2025-02-26 01:02:47 UTC",
    "updated_date": "2025-02-26 01:02:47 UTC"
  },
  {
    "arxiv_id": "2503.01873v1",
    "title": "Online Pseudo-average Shifting Attention(PASA) for Robust Low-precision LLM Inference: Algorithms and Numerical Analysis",
    "authors": [
      "Long Cheng",
      "Qichen Liao",
      "Fan Wu",
      "Junlin Mu",
      "Tengfei Han",
      "Zhe Qiu",
      "Lianqiang Li",
      "Tianyi Liu",
      "Fangzheng Miao",
      "Keming Gao",
      "Liang Wang",
      "Zhen Zhang",
      "Qiande Yin"
    ],
    "abstract": "Attention calculation is extremely time-consuming for long-sequence inference\ntasks, such as text or image/video generation, in large models. To accelerate\nthis process, we developed a low-precision, mathematically-equivalent algorithm\ncalled PASA, based on Flash Attention. PASA introduces two novel techniques:\nonline pseudo-average shifting and global recovering. These techniques enable\nthe use of half-precision computation throughout the Flash Attention process\nwithout incurring overflow instability or unacceptable numerical accuracy loss.\nThis algorithm enhances performance on memory-restricted AI hardware\narchitectures, such as the Ascend Neural-network Processing Unit(NPU), by\nreducing data movement and increasing computational FLOPs. The algorithm is\nvalidated using both designed random benchmarks and real large models. We find\nthat the large bias and amplitude of attention input data are critical factors\ncontributing to numerical overflow ($>65504$ for half precision) in two\ndifferent categories of large models (Qwen2-7B language models and\nStable-Video-Diffusion multi-modal models). Specifically, overflow arises due\nto the large bias in the sequence dimension and the resonance mechanism between\nthe query and key in the head dimension of the Stable-Video-Diffusion models.\nThe resonance mechanism is defined as phase coincidence or 180-degree phase\nshift between query and key matrices. It will remarkably amplify the element\nvalues of attention score matrix. This issue also applies to the Qwen models.\nAdditionally, numerical accuracy is assessed through root mean square error\n(RMSE) and by comparing the final generated texts and videos to those produced\nusing high-precision attention.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "cs.PF",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "21 Pages, 14 figures, conference paper",
    "pdf_url": "http://arxiv.org/pdf/2503.01873v1",
    "published_date": "2025-02-26 01:00:46 UTC",
    "updated_date": "2025-02-26 01:00:46 UTC"
  },
  {
    "arxiv_id": "2502.18726v1",
    "title": "Deep-Bench: Deep Learning Benchmark Dataset for Code Generation",
    "authors": [
      "Alireza Daghighfarsoodeh",
      "Chung-Yu Wang",
      "Hamed Taherkhani",
      "Melika Sepidband",
      "Mohammad Abdollahi",
      "Hadi Hemmati",
      "Hung Viet Pham"
    ],
    "abstract": "Deep learning (DL) has revolutionized areas such as computer vision, natural\nlanguage processing, and more. However, developing DL systems is challenging\ndue to the complexity of DL workflows. Large Language Models (LLMs), such as\nGPT, Claude, Llama, Mistral, etc., have emerged as promising tools to assist in\nDL code generation, offering potential solutions to these challenges. Despite\nthis, existing benchmarks such as DS-1000 are limited, as they primarily focus\non small DL code snippets related to pre/post-processing tasks and lack a\ncomprehensive coverage of the full DL pipeline, including different DL phases\nand input data types.\n  To address this, we introduce DeepBench, a novel benchmark dataset designed\nfor function-level DL code generation. DeepBench categorizes DL problems based\non three key aspects: phases such as pre-processing, model construction, and\ntraining; tasks, including classification, regression, and recommendation; and\ninput data types such as tabular, image, and text.\n  GPT-4o -- the state-of-the-art LLM -- achieved 31% accuracy on DeepBench,\nsignificantly lower than its 60% on DS-1000. We observed similar difficulty for\nother LLMs (e.g., 28% vs. 54% for Claude, 21% vs. 41% for LLaMA, and 15% vs.\n20% for Mistral). This result underscores DeepBench's greater complexity. We\nalso construct a taxonomy of issues and bugs found in LLM-generated DL code,\nwhich highlights the distinct challenges that LLMs face when generating DL code\ncompared to general code.\n  Furthermore, our analysis also reveals substantial performance variations\nacross categories, with differences of up to 7% among phases and 37% among\ntasks. These disparities suggest that DeepBench offers valuable insights into\nthe LLMs' performance and areas for potential improvement in the DL domain.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18726v1",
    "published_date": "2025-02-26 00:43:50 UTC",
    "updated_date": "2025-02-26 00:43:50 UTC"
  },
  {
    "arxiv_id": "2502.18725v1",
    "title": "Talking to the brain: Using Large Language Models as Proxies to Model Brain Semantic Representation",
    "authors": [
      "Xin Liu",
      "Ziyue Zhang",
      "Jingxin Nie"
    ],
    "abstract": "Traditional psychological experiments utilizing naturalistic stimuli face\nchallenges in manual annotation and ecological validity. To address this, we\nintroduce a novel paradigm leveraging multimodal large language models (LLMs)\nas proxies to extract rich semantic information from naturalistic images\nthrough a Visual Question Answering (VQA) strategy for analyzing human visual\nsemantic representation. LLM-derived representations successfully predict\nestablished neural activity patterns measured by fMRI (e.g., faces, buildings),\nvalidating its feasibility and revealing hierarchical semantic organization\nacross cortical regions. A brain semantic network constructed from LLM-derived\nrepresentations identifies meaningful clusters reflecting functional and\ncontextual associations. This innovative methodology offers a powerful solution\nfor investigating brain semantic organization with naturalistic stimuli,\novercoming limitations of traditional annotation methods and paving the way for\nmore ecologically valid explorations of human cognition.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.18725v1",
    "published_date": "2025-02-26 00:40:28 UTC",
    "updated_date": "2025-02-26 00:40:28 UTC"
  },
  {
    "arxiv_id": "2502.18712v1",
    "title": "TrajLLM: A Modular LLM-Enhanced Agent-Based Framework for Realistic Human Trajectory Simulation",
    "authors": [
      "Chenlu Ju",
      "Jiaxin Liu",
      "Shobhit Sinha",
      "Hao Xue",
      "Flora Salim"
    ],
    "abstract": "This work leverages Large Language Models (LLMs) to simulate human mobility,\naddressing challenges like high costs and privacy concerns in traditional\nmodels. Our hierarchical framework integrates persona generation, activity\nselection, and destination prediction, using real-world demographic and\npsychological data to create realistic movement patterns. Both physical models\nand language models are employed to explore and demonstrate different\nmethodologies for human mobility simulation. By structuring data with\nsummarization and weighted density metrics, the system ensures scalable memory\nmanagement while retaining actionable insights. Preliminary results indicate\nthat LLM-driven simulations align with observed real-world patterns, offering\nscalable, interpretable insights for social problems such as urban planning,\ntraffic management, and public health. The framework's ability to dynamically\ngenerate personas and activities enables it to provide adaptable and realistic\ndaily routines. This study demonstrates the transformative potential of LLMs in\nadvancing mobility modeling for societal and urban applications. The source\ncode and interactive demo for our framework are available at\nhttps://github.com/cju0/TrajLLM.",
    "categories": [
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted WWW2025 Demo Paper",
    "pdf_url": "http://arxiv.org/pdf/2502.18712v1",
    "published_date": "2025-02-26 00:13:26 UTC",
    "updated_date": "2025-02-26 00:13:26 UTC"
  },
  {
    "arxiv_id": "2502.18710v1",
    "title": "Bridging Critical Gaps in Convergent Learning: How Representational Alignment Evolves Across Layers, Training, and Distribution Shifts",
    "authors": [
      "Chaitanya Kapoor",
      "Sudhanshu Srivastava",
      "Meenakshi Khosla"
    ],
    "abstract": "Understanding convergent learning -- the extent to which artificial and\nbiological neural networks develop similar representations -- is crucial for\nneuroscience and AI, as it reveals shared learning principles and guides\nbrain-like model design. While several studies have noted convergence in early\nand late layers of vision networks, key gaps remain. First, much existing work\nrelies on a limited set of metrics, overlooking transformation invariances\nrequired for proper alignment. We compare three metrics that ignore specific\nirrelevant transformations: linear regression (ignoring affine\ntransformations), Procrustes (ignoring rotations and reflections), and\npermutation/soft-matching (ignoring unit order). Notably, orthogonal\ntransformations align representations nearly as effectively as more flexible\nlinear ones, and although permutation scores are lower, they significantly\nexceed chance, indicating a robust representational basis. A second critical\ngap lies in understanding when alignment emerges during training. Contrary to\nexpectations that convergence builds gradually with task-specific learning, our\nfindings reveal that nearly all convergence occurs within the first epoch --\nlong before networks achieve optimal performance. This suggests that shared\ninput statistics, architectural biases, or early training dynamics drive\nconvergence rather than the final task solution. Finally, prior studies have\nnot systematically examined how changes in input statistics affect alignment.\nOur work shows that out-of-distribution (OOD) inputs consistently amplify\ndifferences in later layers, while early layers remain aligned for both\nin-distribution and OOD inputs, suggesting that this alignment is driven by\ngeneralizable features stable across distribution shifts. These findings fill\ncritical gaps in our understanding of representational convergence, with\nimplications for neuroscience and AI.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18710v1",
    "published_date": "2025-02-26 00:04:24 UTC",
    "updated_date": "2025-02-26 00:04:24 UTC"
  }
]