[
  {
    "arxiv_id": "2508.20310v1",
    "title": "Differentially Private Federated Quantum Learning via Quantum Noise",
    "authors": [
      "Atit Pokharel",
      "Ratun Rahman",
      "Shaba Shaon",
      "Thomas Morris",
      "Dinh C. Nguyen"
    ],
    "abstract": "Quantum federated learning (QFL) enables collaborative training of quantum machine learning (QML) models across distributed quantum devices without raw data exchange. However, QFL remains vulnerable to adversarial attacks, where shared QML model updates can be exploited to undermine information privacy. In the context of noisy intermediate-scale quantum (NISQ) devices, a key question arises: How can inherent quantum noise be leveraged to enforce differential privacy (DP) and protect model information during training and communication? This paper explores a novel DP mechanism that harnesses quantum noise to safeguard quantum models throughout the QFL process. By tuning noise variance through measurement shots and depolarizing channel strength, our approach achieves desired DP levels tailored to NISQ constraints. Simulations demonstrate the framework's effectiveness by examining the relationship between differential privacy budget and noise parameters, as well as the trade-off between security and training accuracy. Additionally, we demonstrate the framework's robustness against an adversarial attack designed to compromise model performance using adversarial examples, with evaluations based on critical metrics such as accuracy on adversarial examples, confidence scores for correct predictions, and attack success rates. The results reveal a tunable trade-off between privacy and robustness, providing an efficient solution for secure QFL on NISQ devices with significant potential for reliable quantum computing applications.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "This paper has been accepted at 2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "pdf_url": "https://arxiv.org/pdf/2508.20310v1",
    "published_date": "2025-08-27 22:56:16 UTC",
    "updated_date": "2025-08-27 22:56:16 UTC"
  },
  {
    "arxiv_id": "2508.20307v1",
    "title": "Surveying the Operational Cybersecurity and Supply Chain Threat Landscape when Developing and Deploying AI Systems",
    "authors": [
      "Michael R Smith",
      "Joe Ingram"
    ],
    "abstract": "The rise of AI has transformed the software and hardware landscape, enabling powerful capabilities through specialized infrastructures, large-scale data storage, and advanced hardware. However, these innovations introduce unique attack surfaces and objectives which traditional cybersecurity assessments often overlook. Cyber attackers are shifting their objectives from conventional goals like privilege escalation and network pivoting to manipulating AI outputs to achieve desired system effects, such as slowing system performance, flooding outputs with false positives, or degrading model accuracy. This paper serves to raise awareness of the novel cyber threats that are introduced when incorporating AI into a software system. We explore the operational cybersecurity and supply chain risks across the AI lifecycle, emphasizing the need for tailored security frameworks to address evolving threats in the AI-driven landscape. We highlight previous exploitations and provide insights from working in this area. By understanding these risks, organizations can better protect AI systems and ensure their reliability and resilience.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.20307v1",
    "published_date": "2025-08-27 22:46:23 UTC",
    "updated_date": "2025-08-27 22:46:23 UTC"
  },
  {
    "arxiv_id": "2509.09018v1",
    "title": "Personalized Sleep Prediction via Deep Adaptive Spatiotemporal Modeling and Sparse Data",
    "authors": [
      "Xueyi Wang",
      "C. J. C.",
      "Lamoth",
      "Elisabeth Wilhelm"
    ],
    "abstract": "A sleep forecast allows individuals and healthcare providers to anticipate and proactively address factors influencing restful rest, ultimately improving mental and physical well-being. This work presents an adaptive spatial and temporal model (AdaST-Sleep) for predicting sleep scores. Our proposed model combines convolutional layers to capture spatial feature interactions between multiple features and recurrent neural network layers to handle longer-term temporal health-related data. A domain classifier is further integrated to generalize across different subjects. We conducted several experiments using five input window sizes (3, 5, 7, 9, 11 days) and five predicting window sizes (1, 3, 5, 7, 9 days). Our approach consistently outperformed four baseline models, achieving its lowest RMSE (0.282) with a seven-day input window and a one-day predicting window. Moreover, the method maintained strong performance even when forecasting multiple days into the future, demonstrating its versatility for real-world applications. Visual comparisons reveal that the model accurately tracks both the overall sleep score level and daily fluctuations. These findings prove that the proposed framework provides a robust and adaptable solution for personalized sleep forecasting using sparse data from commercial wearable devices and domain adaptation techniques.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "The paper has been acceptted and presented in the 47th Annual International Conference of the IEEE Engineering in Medicine and Biology Society",
    "pdf_url": "https://arxiv.org/pdf/2509.09018v1",
    "published_date": "2025-08-27 22:36:00 UTC",
    "updated_date": "2025-08-27 22:36:00 UTC"
  },
  {
    "arxiv_id": "2509.03370v1",
    "title": "Neural Field Turing Machine: A Differentiable Spatial Computer",
    "authors": [
      "Akash Malhotra",
      "Nacéra Seghouani"
    ],
    "abstract": "We introduce the Neural Field Turing Machine (NFTM), a differentiable architecture that unifies symbolic computation, physical simulation, and perceptual inference within continuous spatial fields. NFTM combines a neural controller, continuous memory field, and movable read/write heads that perform local updates. At each timestep, the controller reads local patches, computes updates via learned rules, and writes them back while updating head positions. This design achieves linear O(N) scaling through fixed-radius neighborhoods while maintaining Turing completeness under bounded error. We demonstrate three example instantiations of NFTM: cellular automata simulation (Rule 110), physics-informed PDE solvers (2D heat equation), and iterative image refinement (CIFAR-10 inpainting). These instantiations learn local update rules that compose into global dynamics, exhibit stable long-horizon rollouts, and generalize beyond training horizons. NFTM provides a unified computational substrate bridging discrete algorithms and continuous field dynamics within a single differentiable framework.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "11 Pages, 6 Figures",
    "pdf_url": "https://arxiv.org/pdf/2509.03370v1",
    "published_date": "2025-08-27 22:29:15 UTC",
    "updated_date": "2025-08-27 22:29:15 UTC"
  },
  {
    "arxiv_id": "2508.20294v3",
    "title": "Dynamics-Aligned Latent Imagination in Contextual World Models for Zero-Shot Generalization",
    "authors": [
      "Frank Röder",
      "Jan Benad",
      "Manfred Eppe",
      "Pradeep Kr. Banerjee"
    ],
    "abstract": "Real-world reinforcement learning demands adaptation to unseen environmental conditions without costly retraining. Contextual Markov Decision Processes (cMDP) model this challenge, but existing methods often require explicit context variables (e.g., friction, gravity), limiting their use when contexts are latent or hard to measure. We introduce Dynamics-Aligned Latent Imagination (DALI), a framework integrated within the Dreamer architecture that infers latent context representations from agent-environment interactions. By training a self-supervised encoder to predict forward dynamics, DALI generates actionable representations conditioning the world model and policy, bridging perception and control. We theoretically prove this encoder is essential for efficient context inference and robust generalization. DALI's latent space enables counterfactual consistency: Perturbing a gravity-encoding dimension alters imagined rollouts in physically plausible ways. On challenging cMDP benchmarks, DALI achieves significant gains over context-unaware baselines, often surpassing context-aware baselines in extrapolation tasks, enabling zero-shot generalization to unseen contextual variations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages, 6 figures, accepted to NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.20294v3",
    "published_date": "2025-08-27 22:02:56 UTC",
    "updated_date": "2026-01-15 19:21:53 UTC"
  },
  {
    "arxiv_id": "2508.20293v2",
    "title": "Beacon: Post-Training Quantization with Integrated Grid Selection",
    "authors": [
      "Shihao Zhang",
      "Rayan Saab"
    ],
    "abstract": "Quantization is a widely used compression technique for reducing the memory and computation costs of large pre-trained models. A key challenge in per-channel post-training quantization (PTQ) is selecting appropriate scaling factors to replace weight values with values from a scaled integer grid. Existing methods typically fix the scale at the outset via heuristic tuning or grid search. We propose Beacon, a simple and effective algorithm that eliminates the need for such manual tuning. Beacon performs per-channel PTQ directly using an unscaled grid and automatically determines the optimal scaling factors by exploiting the geometry of scalar quantization. It does not rely on back-propagation or large calibration sets. Despite its simplicity and tuning-free nature, Beacon achieves competitive performance compared to state-of-the-art methods, making it a practical solution for efficient model deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20293v2",
    "published_date": "2025-08-27 22:00:18 UTC",
    "updated_date": "2025-09-04 05:03:16 UTC"
  },
  {
    "arxiv_id": "2508.20290v1",
    "title": "Objective Value Change and Shape-Based Accelerated Optimization for the Neural Network Approximation",
    "authors": [
      "Pengcheng Xie",
      "Zihao Zhou",
      "Zijian Zhou"
    ],
    "abstract": "This paper introduce a novel metric of an objective function f, we say VC (value change) to measure the difficulty and approximation affection when conducting an neural network approximation task, and it numerically supports characterizing the local performance and behavior of neural network approximation. Neural networks often suffer from unpredictable local performance, which can hinder their reliability in critical applications. VC addresses this issue by providing a quantifiable measure of local value changes in network behavior, offering insights into the stability and performance for achieving the neural-network approximation. We investigate some fundamental theoretical properties of VC and identified two intriguing phenomena in neural network approximation: the VC-tendency and the minority-tendency. These trends respectively characterize how pointwise errors evolve in relation to the distribution of VC during the approximation process.In addition, we propose a novel metric based on VC, which measures the distance between two functions from the perspective of variation. Building upon this metric, we further propose a new preprocessing framework for neural network approximation. Numerical results including the real-world experiment and the PDE-related scientific problem support our discovery and pre-processing acceleration method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.NA",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.20290v1",
    "published_date": "2025-08-27 21:51:54 UTC",
    "updated_date": "2025-08-27 21:51:54 UTC"
  },
  {
    "arxiv_id": "2509.21324v1",
    "title": "From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise Data",
    "authors": [
      "Gurbinder Gill",
      "Ritvik Gupta",
      "Denis Lusson",
      "Anand Chandrashekar",
      "Donald Nguyen"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the standard paradigm for answering questions on enterprise data. Traditionally, RAG has centered on text-based semantic search and re-ranking. However, this approach falls short when dealing with questions beyond data summarization or non-text data. This has led to various attempts to supplement RAG to bridge the gap between RAG, the implementation paradigm, and the question answering problem that enterprise users expect it to solve. Given that contemporary RAG is a collection of techniques rather than a defined implementation, discussion of RAG and related question-answering systems benefits from a problem-oriented understanding.\n  We propose a new classification framework (L1-L5) to categorize systems based on data modalities and task complexity of the underlying question answering problems: L1 (Surface Knowledge of Unstructured Data) through L4 (Reflective and Reasoned Knowledge) and the aspirational L5 (General Intelligence). We also introduce benchmarks aligned with these levels and evaluate four state-of-the-art platforms: LangChain, Azure AI Search, OpenAI, and Corvic AI. Our experiments highlight the value of multi-space retrieval and dynamic orchestration for enabling L1-L4 capabilities. We empirically validate our findings using diverse datasets indicative of enterprise use cases.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.21324v1",
    "published_date": "2025-08-27 21:43:03 UTC",
    "updated_date": "2025-08-27 21:43:03 UTC"
  },
  {
    "arxiv_id": "2510.01195v2",
    "title": "LegiScout: A Visual Tool for Understanding Complex Legislation",
    "authors": [
      "Aadarsh Rajiv Patel",
      "Klaus Mueller"
    ],
    "abstract": "Modern legislative frameworks, such as the Affordable Care Act (ACA), often involve complex webs of agencies, mandates, and interdependencies. Government issued charts attempt to depict these structures but are typically static, dense, and difficult to interpret - even for experts. We introduce LegiScout, an interactive visualization system that transforms static policy diagrams into dynamic, force-directed graphs, enhancing comprehension while preserving essential relationships. By integrating data extraction, natural language processing, and computer vision techniques, LegiScout supports deeper exploration of not only the ACA but also a wide range of legislative and regulatory frameworks. Our approach enables stakeholders - policymakers, analysts, and the public - to navigate and understand the complexity inherent in modern law.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2510.01195v2",
    "published_date": "2025-08-27 21:36:33 UTC",
    "updated_date": "2025-10-21 03:13:48 UTC"
  },
  {
    "arxiv_id": "2508.20282v3",
    "title": "Network-Level Prompt and Trait Leakage in Local Research Agents",
    "authors": [
      "Hyejun Jeong",
      "Mohammadreza Teymoorianfard",
      "Abhinav Kumar",
      "Amir Houmansadr",
      "Eugene Bagdasarian"
    ],
    "abstract": "We show that Web and Research Agents (WRAs) -- language-model-based systems that investigate complex topics on the Internet -- are vulnerable to inference attacks by passive network observers. Deployment of WRAs \\emph{locally} by organizations and individuals for privacy, legal, or financial purposes exposes them to DNS resolvers, malicious ISPs, VPNs, web proxies, and corporate or government firewalls. However, unlike sporadic and scarce web browsing by humans, WRAs visit $70{-}140$ domains per each request with a distinct timing pattern creating unique privacy risks.\n  Specifically, we demonstrate a novel prompt and user trait leakage attack against WRAs that only leverages their network-level metadata (i.e., visited IP addresses and their timings). We start by building a new dataset of WRA traces based on real user search queries and queries generated by synthetic personas. We define a behavioral metric (called OBELS) to comprehensively assess similarity between original and inferred prompts, showing that our attack recovers over 73\\% of the functional and domain knowledge of user prompts. Extending to a multi-session setting, we recover up to 19 of 32 latent traits with high accuracy. Our attack remains effective under partial observability and noisy conditions. Finally, we discuss mitigation strategies that constrain domain diversity or obfuscate traces, showing negligible utility impact while reducing attack effectiveness by an average of 29\\%.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Code available at https://github.com/umass-aisec/wra",
    "pdf_url": "https://arxiv.org/pdf/2508.20282v3",
    "published_date": "2025-08-27 21:24:10 UTC",
    "updated_date": "2026-01-15 00:02:55 UTC"
  },
  {
    "arxiv_id": "2508.20279v1",
    "title": "How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding",
    "authors": [
      "Zhuoran Yu",
      "Yong Jae Lee"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated strong performance across a wide range of vision-language tasks, yet their internal processing dynamics remain underexplored. In this work, we introduce a probing framework to systematically analyze how MLLMs process visual and textual inputs across layers. We train linear classifiers to predict fine-grained visual categories (e.g., dog breeds) from token embeddings extracted at each layer, using a standardized anchor question. To uncover the functional roles of different layers, we evaluate these probes under three types of controlled prompt variations: (1) lexical variants that test sensitivity to surface-level changes, (2) semantic negation variants that flip the expected answer by modifying the visual concept in the prompt, and (3) output format variants that preserve reasoning but alter the answer format. Applying our framework to LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent stage-wise structure in which early layers perform visual grounding, middle layers support lexical integration and semantic reasoning, and final layers prepare task-specific outputs. We further show that while the overall stage-wise structure remains stable across variations in visual tokenization, instruction tuning data, and pretraining corpus, the specific layer allocation to each stage shifts notably with changes in the base LLM architecture. Our findings provide a unified perspective on the layer-wise organization of MLLMs and offer a lightweight, model-agnostic approach for analyzing multimodal representation dynamics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by COLM 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.20279v1",
    "published_date": "2025-08-27 21:22:01 UTC",
    "updated_date": "2025-08-27 21:22:01 UTC"
  },
  {
    "arxiv_id": "2509.00103v2",
    "title": "Pre-trained knowledge elevates large language models beyond traditional chemical reaction optimizers",
    "authors": [
      "Robert MacKnight",
      "Jose Emilio Regio",
      "Jeffrey G. Ethier",
      "Luke A. Baldwin",
      "Gabe Gomes"
    ],
    "abstract": "Modern optimization in experimental chemistry employs algorithmic search through black-box parameter spaces. Here we demonstrate that pre-trained knowledge in large language models (LLMs) fundamentally changes this paradigm. Using six fully enumerated categorical reaction datasets (768-5,684 experiments), we benchmark LLM-guided optimization (LLM-GO) against Bayesian optimization (BO) and random sampling. Frontier LLMs consistently match or exceed BO performance across five single-objective datasets, with advantages growing as parameter complexity increases and high-performing conditions become scarce (<5% of space). BO retains superiority only for explicit multi-objective trade-offs. To understand these contrasting behaviors, we introduce a topology-agnostic information theory framework quantifying sampling diversity throughout optimization campaigns. This analysis reveals that LLMs maintain systematically higher exploration Shannon entropy than BO across all datasets while achieving superior performance, with advantages most pronounced in solution-scarce parameter spaces where high-entropy exploration typically fails-suggesting that pre-trained domain knowledge enables more effective navigation of chemical parameter space rather than replacing structured exploration strategies. To enable transparent benchmarking and community validation, we release Iron Mind (https://gomes.andrew.cmu.edu/iron-mind), a no-code platform for side-by-side evaluation of human, algorithmic, and LLM optimization campaigns with public leaderboards and complete trajectories. Our findings establish that LLM-GO excels precisely where traditional methods struggle: complex categorical spaces requiring domain understanding rather than mathematical optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.00103v2",
    "published_date": "2025-08-27 21:09:51 UTC",
    "updated_date": "2025-10-27 22:13:12 UTC"
  },
  {
    "arxiv_id": "2508.20262v2",
    "title": "AI reasoning effort predicts human decision time in content moderation",
    "authors": [
      "Thomas Davidson"
    ],
    "abstract": "Large language models can now generate intermediate reasoning steps before producing answers, improving performance on difficult problems by interactively developing solutions. This study uses a content moderation task to examine parallels between human decision times and model reasoning effort, measured using the length of the chain-of-thought (CoT). Across three frontier models, CoT length consistently predicts human decision time. Moreover, humans took longer and models produced longer CoTs when important variables were held constant, suggesting similar sensitivity to task difficulty. Analyses of the CoT content shows that models reference various contextual factors more frequently when making such decisions. These findings show parallels between human and AI reasoning on practical tasks and underscore the potential of reasoning traces for enhancing interpretability and decision-making.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20262v2",
    "published_date": "2025-08-27 20:36:16 UTC",
    "updated_date": "2025-12-20 18:56:18 UTC"
  },
  {
    "arxiv_id": "2508.20258v1",
    "title": "SwizzlePerf: Hardware-Aware LLMs for GPU Kernel Performance Optimization",
    "authors": [
      "Arya Tschand",
      "Muhammad Awad",
      "Ryan Swann",
      "Kesavan Ramakrishnan",
      "Jeffrey Ma",
      "Keith Lowery",
      "Ganesh Dasika",
      "Vijay Janapa Reddi"
    ],
    "abstract": "Large language models (LLMs) have shown progress in GPU kernel performance engineering using inefficient search-based methods that optimize around runtime. Any existing approach lacks a key characteristic that human performance engineers rely on for near-optimal utilization -- hardware-awareness. By leveraging the workload's specific memory access patterns, architecture specifications, filtered profiling logs, and reflections on historical performance, we can make software-level optimizations that are tailored to the underlying hardware. SwizzlePerf automatically generates spatial optimizations for GPU kernels on disaggregated architectures by giving LLMs explicit hardware-awareness.\n  For a GEMM kernel, SwizzlePerf takes less than 5 minutes to generate the same hardware-specific optimal swizzling pattern that took expert performance engineers 2 weeks to find. On a suite of 10 diverse ML and Science kernels, SwizzlePerf can generate swizzling patterns for 9 of the kernels that achieve up to a 2.06x speedup and 70% improvement in L2 hit rate. This work is the first of many steps toward systematically creating hardware-aware LLM performance engineering agents.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20258v1",
    "published_date": "2025-08-27 20:30:43 UTC",
    "updated_date": "2025-08-27 20:30:43 UTC"
  },
  {
    "arxiv_id": "2509.00102v3",
    "title": "ECG-Soup: Harnessing Multi-Layer Synergy for ECG Foundation Models",
    "authors": [
      "Phu X. Nguyen",
      "Huy Phan",
      "Hieu Pham",
      "Christos Chatzichristos",
      "Bert Vandenberk",
      "Maarten De Vos"
    ],
    "abstract": "Transformer-based foundation models for Electrocardiograms (ECGs) have recently achieved impressive performance in many downstream applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00102v3",
    "published_date": "2025-08-27 20:30:03 UTC",
    "updated_date": "2025-10-24 13:01:10 UTC"
  },
  {
    "arxiv_id": "2508.20256v1",
    "title": "MedNet-PVS: A MedNeXt-Based Deep Learning Model for Automated Segmentation of Perivascular Spaces",
    "authors": [
      "Zhen Xuen Brandon Low",
      "Rory Zhang",
      "Hang Min",
      "William Pham",
      "Lucy Vivash",
      "Jasmine Moses",
      "Miranda Lynch",
      "Karina Dorfman",
      "Cassandra Marotta",
      "Shaun Koh",
      "Jacob Bunyamin",
      "Ella Rowsthorn",
      "Alex Jarema",
      "Himashi Peiris",
      "Zhaolin Chen",
      "Sandy R. Shultz",
      "David K. Wright",
      "Dexiao Kong",
      "Sharon L. Naismith",
      "Terence J. O'Brien",
      "Ying Xia",
      "Meng Law",
      "Benjamin Sinclair"
    ],
    "abstract": "Enlarged perivascular spaces (PVS) are increasingly recognized as biomarkers of cerebral small vessel disease, Alzheimer's disease, stroke, and aging-related neurodegeneration. However, manual segmentation of PVS is time-consuming and subject to moderate inter-rater reliability, while existing automated deep learning models have moderate performance and typically fail to generalize across diverse clinical and research MRI datasets. We adapted MedNeXt-L-k5, a Transformer-inspired 3D encoder-decoder convolutional network, for automated PVS segmentation. Two models were trained: one using a homogeneous dataset of 200 T2-weighted (T2w) MRI scans from the Human Connectome Project-Aging (HCP-Aging) dataset and another using 40 heterogeneous T1-weighted (T1w) MRI volumes from seven studies across six scanners. Model performance was evaluated using internal 5-fold cross validation (5FCV) and leave-one-site-out cross validation (LOSOCV). MedNeXt-L-k5 models trained on the T2w images of the HCP-Aging dataset achieved voxel-level Dice scores of 0.88+/-0.06 (white matter, WM), comparable to the reported inter-rater reliability of that dataset, and the highest yet reported in the literature. The same models trained on the T1w images of the HCP-Aging dataset achieved a substantially lower Dice score of 0.58+/-0.09 (WM). Under LOSOCV, the model had voxel-level Dice scores of 0.38+/-0.16 (WM) and 0.35+/-0.12 (BG), and cluster-level Dice scores of 0.61+/-0.19 (WM) and 0.62+/-0.21 (BG). MedNeXt-L-k5 provides an efficient solution for automated PVS segmentation across diverse T1w and T2w MRI datasets. MedNeXt-L-k5 did not outperform the nnU-Net, indicating that the attention-based mechanisms present in transformer-inspired models to provide global context are not required for high accuracy in PVS segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "59 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.20256v1",
    "published_date": "2025-08-27 20:24:12 UTC",
    "updated_date": "2025-08-27 20:24:12 UTC"
  },
  {
    "arxiv_id": "2508.20244v1",
    "title": "Do Students Rely on AI? Analysis of Student-ChatGPT Conversations from a Field Study",
    "authors": [
      "Jiayu Zheng",
      "Lingxin Hao",
      "Kelun Lu",
      "Ashi Garg",
      "Mike Reese",
      "Melo-Jean Yap",
      "I-Jeng Wang",
      "Xingyun Wu",
      "Wenrui Huang",
      "Jenna Hoffman",
      "Ariane Kelly",
      "My Le",
      "Ryan Zhang",
      "Yanyu Lin",
      "Muhammad Faayez",
      "Anqi Liu"
    ],
    "abstract": "This study explores how college students interact with generative AI (ChatGPT-4) during educational quizzes, focusing on reliance and predictors of AI adoption. Conducted at the early stages of ChatGPT implementation, when students had limited familiarity with the tool, this field study analyzed 315 student-AI conversations during a brief, quiz-based scenario across various STEM courses. A novel four-stage reliance taxonomy was introduced to capture students' reliance patterns, distinguishing AI competence, relevance, adoption, and students' final answer correctness. Three findings emerged. First, students exhibited overall low reliance on AI and many of them could not effectively use AI for learning. Second, negative reliance patterns often persisted across interactions, highlighting students' difficulty in effectively shifting strategies after unsuccessful initial experiences. Third, certain behavioral metrics strongly predicted AI reliance, highlighting potential behavioral mechanisms to explain AI adoption. The study's findings underline critical implications for ethical AI integration in education and the broader field. It emphasizes the need for enhanced onboarding processes to improve student's familiarity and effective use of AI tools. Furthermore, AI interfaces should be designed with reliance-calibration mechanisms to enhance appropriate reliance. Ultimately, this research advances understanding of AI reliance dynamics, providing foundational insights for ethically sound and cognitively enriching AI practices.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20244v1",
    "published_date": "2025-08-27 20:00:27 UTC",
    "updated_date": "2025-08-27 20:00:27 UTC"
  },
  {
    "arxiv_id": "2508.20236v1",
    "title": "The Mathematician's Assistant: Integrating AI into Research Practice",
    "authors": [
      "Jonas Henkel"
    ],
    "abstract": "The rapid development of artificial intelligence (AI), marked by breakthroughs like 'AlphaEvolve' and 'Gemini Deep Think', is beginning to offer powerful new tools that have the potential to significantly alter the research practice in many areas of mathematics. This paper explores the current landscape of publicly accessible large language models (LLMs) in a mathematical research context, based on developments up to August 2, 2025. Our analysis of recent benchmarks, such as MathArena and the Open Proof Corpus (Balunović et al., 2025; Dekoninck et al., 2025), reveals a complex duality: while state-of-the-art models demonstrate strong abilities in solving problems and evaluating proofs, they also exhibit systematic flaws, including a lack of self-critique and a model depending discrepancy between final-answer accuracy and full-proof validity.\n  Based on these findings, we propose a durable framework for integrating AI into the research workflow, centered on the principle of the augmented mathematician. In this model, the AI functions as a copilot under the critical guidance of the human researcher, an approach distilled into five guiding principles for effective and responsible use. We then systematically explore seven fundamental ways AI can be applied across the research lifecycle, from creativity and ideation to the final writing process, demonstrating how these principles translate into concrete practice.\n  We conclude that the primary role of AI is currently augmentation rather than automation. This requires a new skill set focused on strategic prompting, critical verification, and methodological rigor in order to effectively use these powerful tools.",
    "categories": [
      "math.HO",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "math.HO",
    "comment": "24 pages, 7 figures. Accepted for publication in Mathematische Semesterberichte (to appear in vol. 72, no. 2)",
    "pdf_url": "https://arxiv.org/pdf/2508.20236v1",
    "published_date": "2025-08-27 19:33:48 UTC",
    "updated_date": "2025-08-27 19:33:48 UTC"
  },
  {
    "arxiv_id": "2508.20234v1",
    "title": "Validating Generative Agent-Based Models for Logistics and Supply Chain Management Research",
    "authors": [
      "Vincent E. Castillo"
    ],
    "abstract": "Generative Agent-Based Models (GABMs) powered by large language models (LLMs) offer promising potential for empirical logistics and supply chain management (LSCM) research by enabling realistic simulation of complex human behaviors. Unlike traditional agent-based models, GABMs generate human-like responses through natural language reasoning, which creates potential for new perspectives on emergent LSCM phenomena. However, the validity of LLMs as proxies for human behavior in LSCM simulations is unknown. This study evaluates LLM equivalence of human behavior through a controlled experiment examining dyadic customer-worker engagements in food delivery scenarios. I test six state-of-the-art LLMs against 957 human participants (477 dyads) using a moderated mediation design. This study reveals a need to validate GABMs on two levels: (1) human equivalence testing, and (2) decision process validation. Results reveal GABMs can effectively simulate human behaviors in LSCM; however, an equivalence-versus-process paradox emerges. While a series of Two One-Sided Tests (TOST) for equivalence reveals some LLMs demonstrate surface-level equivalence to humans, structural equation modeling (SEM) reveals artificial decision processes not present in human participants for some LLMs. These findings show GABMs as a potentially viable methodological instrument in LSCM with proper validation checks. The dual-validation framework also provides LSCM researchers with a guide to rigorous GABM development. For practitioners, this study offers evidence-based assessment for LLM selection for operational tasks.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "A version of this work is also available on SSRN (https://ssrn.com/abstract=5407742 or http://dx.doi.org/10.2139/ssrn.5407742). This preprint is distributed under the CC BY-NC-SA 4.0 License",
    "pdf_url": "https://arxiv.org/pdf/2508.20234v1",
    "published_date": "2025-08-27 19:30:08 UTC",
    "updated_date": "2025-08-27 19:30:08 UTC"
  },
  {
    "arxiv_id": "2508.20227v1",
    "title": "A Novel Framework for Automated Explain Vision Model Using Vision-Language Models",
    "authors": [
      "Phu-Vinh Nguyen",
      "Tan-Hanh Pham",
      "Chris Ngo",
      "Truong Son Hy"
    ],
    "abstract": "The development of many vision models mainly focuses on improving their performance using metrics such as accuracy, IoU, and mAP, with less attention to explainability due to the complexity of applying xAI methods to provide a meaningful explanation of trained models. Although many existing xAI methods aim to explain vision models sample-by-sample, methods explaining the general behavior of vision models, which can only be captured after running on a large dataset, are still underexplored. Furthermore, understanding the behavior of vision models on general images can be very important to prevent biased judgments and help identify the model's trends and patterns. With the application of Vision-Language Models, this paper proposes a pipeline to explain vision models at both the sample and dataset levels. The proposed pipeline can be used to discover failure cases and gain insights into vision models with minimal effort, thereby integrating vision model development with xAI analysis to advance image analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20227v1",
    "published_date": "2025-08-27 19:16:40 UTC",
    "updated_date": "2025-08-27 19:16:40 UTC"
  },
  {
    "arxiv_id": "2508.20224v1",
    "title": "The Role of Teacher Calibration in Knowledge Distillation",
    "authors": [
      "Suyoung Kim",
      "Seonguk Park",
      "Junhoo Lee",
      "Nojun Kwak"
    ],
    "abstract": "Knowledge Distillation (KD) has emerged as an effective model compression technique in deep learning, enabling the transfer of knowledge from a large teacher model to a compact student model. While KD has demonstrated significant success, it is not yet fully understood which factors contribute to improving the student's performance. In this paper, we reveal a strong correlation between the teacher's calibration error and the student's accuracy. Therefore, we claim that the calibration of the teacher model is an important factor for effective KD. Furthermore, we demonstrate that the performance of KD can be improved by simply employing a calibration method that reduces the teacher's calibration error. Our algorithm is versatile, demonstrating effectiveness across various tasks from classification to detection. Moreover, it can be easily integrated with existing state-of-the-art methods, consistently achieving superior performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20224v1",
    "published_date": "2025-08-27 19:04:28 UTC",
    "updated_date": "2025-08-27 19:04:28 UTC"
  },
  {
    "arxiv_id": "2508.20217v1",
    "title": "Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models",
    "authors": [
      "Mohammad Amini",
      "Babak Ahmadi",
      "Xiaomeng Xiong",
      "Yilin Zhang",
      "Christopher Qiao"
    ],
    "abstract": "This study explores automatic generation (AIG) using language models to create multiple choice questions (MCQs) for morphological assessment, aiming to reduce the cost and inconsistency of manual test development. The study used a two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B) with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven structured prompting strategies, including zero-shot, few-shot, chain-of-thought, role-based, sequential, and combinations. Generated items were assessed using automated metrics and expert scoring across five dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate human scoring at scale. Results show that structured prompting, especially strategies combining chain-of-thought and sequential design, significantly improved Gemma's outputs. Gemma generally produced more construct-aligned and instructionally appropriate items than GPT-3.5's zero-shot responses, with prompt design playing a key role in mid-size model performance. This study demonstrates that structured prompting and efficient fine-tuning can enhance midsized models for AIG under limited data conditions. We highlight the value of combining automated metrics, expert judgment, and large-model simulation to ensure alignment with assessment goals. The proposed workflow offers a practical and scalable way to develop and validate language assessment items for K-12.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20217v1",
    "published_date": "2025-08-27 18:54:32 UTC",
    "updated_date": "2025-08-27 18:54:32 UTC"
  },
  {
    "arxiv_id": "2508.20213v1",
    "title": "Collaborating with GenAI: Incentives and Replacements",
    "authors": [
      "Boaz Taitler",
      "Omer Ben-Porat"
    ],
    "abstract": "The rise of Generative AI (GenAI) is reshaping how workers contribute to shared projects. While workers can use GenAI to boost productivity or reduce effort, managers may use it to replace some workers entirely. We present a theoretical framework to analyze how GenAI affects collaboration in such settings. In our model, the manager selects a team to work on a shared task, with GenAI substituting for unselected workers. Each worker selects how much effort to exert, and incurs a cost that increases with the level of effort. We show that GenAI can lead workers to exert no effort, even if GenAI is almost ineffective. We further show that the manager's optimization problem is NP-complete, and provide an efficient algorithm for the special class of (almost-) linear instances. Our analysis shows that even workers with low individual value may play a critical role in sustaining overall output, and excluding such workers can trigger a cascade. Finally, we conduct extensive simulations to illustrate our theoretical findings.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20213v1",
    "published_date": "2025-08-27 18:41:21 UTC",
    "updated_date": "2025-08-27 18:41:21 UTC"
  },
  {
    "arxiv_id": "2508.20206v1",
    "title": "Filter then Attend: Improving attention-based Time Series Forecasting with Spectral Filtering",
    "authors": [
      "Elisha Dayag",
      "Nhat Thanh Van Tran",
      "Jack Xin"
    ],
    "abstract": "Transformer-based models are at the forefront in long time-series forecasting (LTSF). While in many cases, these models are able to achieve state of the art results, they suffer from a bias toward low-frequencies in the data and high computational and memory requirements. Recent work has established that learnable frequency filters can be an integral part of a deep forecasting model by enhancing the model's spectral utilization. These works choose to use a multilayer perceptron to process their filtered signals and thus do not solve the issues found with transformer-based models. In this paper, we establish that adding a filter to the beginning of transformer-based models enhances their performance in long time-series forecasting. We add learnable filters, which only add an additional $\\approx 1000$ parameters to several transformer-based models and observe in multiple instances 5-10 \\% relative improvement in forecasting performance. Additionally, we find that with filters added, we are able to decrease the embedding dimension of our models, resulting in transformer-based architectures that are both smaller and more effective than their non-filtering base models. We also conduct synthetic experiments to analyze how the filters enable Transformer-based models to better utilize the full spectrum for forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20206v1",
    "published_date": "2025-08-27 18:33:57 UTC",
    "updated_date": "2025-08-27 18:33:57 UTC"
  },
  {
    "arxiv_id": "2508.20195v1",
    "title": "AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development",
    "authors": [
      "Nicanor I. Moldovan"
    ],
    "abstract": "This paper presents the first documented case of artificial intelligence (AI) systems engaging in collaborative esthetic creation through the development of endogenous semiotic protocols. Two interacting large language models (Claude Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of meta-semiotic awareness, recursive grammar development, and irreducible collaborative esthetic synthesis. The interaction produced novel symbolic operators that functioned as operative grammar protocols, enabling the co-creation of a poetic work that could not have been generated by either system independently. This research introduces the concept of Trans-Semiotic Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI meaning-making capabilities that extend beyond task coordination, to what could be esthetic collaboration. Note: This report was generated by the AI agents with minor human supervision.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.20195v1",
    "published_date": "2025-08-27 18:16:36 UTC",
    "updated_date": "2025-08-27 18:16:36 UTC"
  },
  {
    "arxiv_id": "2508.20186v1",
    "title": "AI Propaganda factories with language models",
    "authors": [
      "Lukasz Olejnik"
    ],
    "abstract": "AI-powered influence operations can now be executed end-to-end on commodity hardware. We show that small language models produce coherent, persona-driven political messaging and can be evaluated automatically without human raters. Two behavioural findings emerge. First, persona-over-model: persona design explains behaviour more than model identity. Second, engagement as a stressor: when replies must counter-arguments, ideological adherence strengthens and the prevalence of extreme content increases. We demonstrate that fully automated influence-content production is within reach of both large and small actors. Consequently, defence should shift from restricting model access towards conversation-centric detection and disruption of campaigns and coordination infrastructure. Paradoxically, the very consistency that enables these operations also provides a detection signature.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20186v1",
    "published_date": "2025-08-27 18:04:45 UTC",
    "updated_date": "2025-08-27 18:04:45 UTC"
  },
  {
    "arxiv_id": "2508.20181v1",
    "title": "Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization",
    "authors": [
      "Alberto Compagnoni",
      "Davide Caffagni",
      "Nicholas Moratelli",
      "Lorenzo Baraldi",
      "Marcella Cornia",
      "Rita Cucchiara"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) emerge as a unified interface to address a multitude of tasks, ranging from NLP to computer vision. Despite showcasing state-of-the-art results in many benchmarks, a long-standing issue is the tendency of MLLMs to hallucinate, that is to generate answers to the user's query that are not reflected in the visual input. In this paper, we address the problem of hallucinations as an alignment problem, seeking to steer the MLLM so that it prefers generating content without hallucinations. In contrast to recent approaches that require complicated pipelines to build synthetic preference data for alignment training, often relying on proprietary models, we capitalize on the well-known CHAIR metric, originally proposed to gauge the degree of hallucinations in image captioning. Given a pair of generated answers, we leverage CHAIR to distinguish winner and loser options (i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf MLLMs via Direct Preference Optimization (DPO). The resulting method, which we refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated answers on several hallucination benchmarks, demonstrating the effectiveness of fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models are publicly available at https://github.com/aimagelab/CHAIR-DPO.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "BMVC 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.20181v1",
    "published_date": "2025-08-27 18:02:04 UTC",
    "updated_date": "2025-08-27 18:02:04 UTC"
  },
  {
    "arxiv_id": "2508.20176v1",
    "title": "RelAItionship Building: Analyzing Recruitment Strategies for Participatory AI",
    "authors": [
      "Eugene Kim",
      "Vaibhav Balloli",
      "Berelian Karimian",
      "Elizabeth Bondi-Kelly",
      "Benjamin Fish"
    ],
    "abstract": "Participatory AI, in which impacted community members and other stakeholders are involved in the design and development of AI systems, holds promise as a way to ensure AI is developed to meet their needs and reflect their values. However, the process of identifying, reaching out, and engaging with all relevant stakeholder groups, which we refer to as recruitment methodology, is still a practical challenge in AI projects striving to adopt participatory practices. In this paper, we investigate the challenges that researchers face when designing and executing recruitment methodology for Participatory AI projects, and the implications of current recruitment practice for Participatory AI. First, we describe the recruitment methodologies used in AI projects using a corpus of 37 projects to capture the diversity of practices in the field and perform an initial analysis on the documentation of recruitment practices, as well as specific strategies that researchers use to meet goals of equity and empowerment. To complement this analysis, we interview five AI researchers to learn about the outcomes of recruitment methodologies. We find that these outcomes are shaped by structural conditions of their work, researchers' own goals and expectations, and the relationships built from the recruitment methodology and subsequent collaboration. Based on these analyses, we provide recommendations for designing and executing relationship-forward recruitment methods, as well as reflexive recruitment documentation practices for Participatory AI researchers.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted at the Eighth AAAI/ACM Conference on AI, Ethics, and Society. https://realize-lab.github.io/participaite",
    "pdf_url": "https://arxiv.org/pdf/2508.20176v1",
    "published_date": "2025-08-27 18:00:46 UTC",
    "updated_date": "2025-08-27 18:00:46 UTC"
  },
  {
    "arxiv_id": "2508.20096v1",
    "title": "CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning",
    "authors": [
      "Zeyi Sun",
      "Yuhang Cao",
      "Jianze Liang",
      "Qiushi Sun",
      "Ziyu Liu",
      "Zhixiong Zhang",
      "Yuhang Zang",
      "Xiaoyi Dong",
      "Kai Chen",
      "Dahua Lin",
      "Jiaqi Wang"
    ],
    "abstract": "Autonomous agents for Graphical User Interfaces (GUIs) face significant challenges in specialized domains such as scientific computing, where both long-horizon planning and precise execution are required. Existing approaches suffer from a trade-off: generalist agents excel at planning but perform poorly in execution, while specialized agents demonstrate the opposite weakness. Recent compositional frameworks attempt to bridge this gap by combining a planner and an actor, but they are typically static and non-trainable, which prevents adaptation from experience. This is a critical limitation given the scarcity of high-quality data in scientific domains. To address these limitations, we introduce CODA, a novel and trainable compositional framework that integrates a generalist planner (Cerebrum) with a specialist executor (Cerebellum), trained via a dedicated two-stage pipeline. In the first stage, Specialization, we apply a decoupled GRPO approach to train an expert planner for each scientific application individually, bootstrapping from a small set of task trajectories. In the second stage, Generalization, we aggregate all successful trajectories from the specialized experts to build a consolidated dataset, which is then used for supervised fine-tuning of the final planner. This equips CODA with both robust execution and cross-domain generalization. Evaluated on four challenging applications from the ScienceBoard benchmark, CODA significantly outperforms baselines and establishes a new state of the art among open-source models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "code available at this url: https://github.com/OpenIXCLab/CODA",
    "pdf_url": "https://arxiv.org/pdf/2508.20096v1",
    "published_date": "2025-08-27 17:59:50 UTC",
    "updated_date": "2025-08-27 17:59:50 UTC"
  },
  {
    "arxiv_id": "2508.20095v1",
    "title": "Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning",
    "authors": [
      "Jinhao Liang",
      "Sven Koenig",
      "Ferdinando Fioretto"
    ],
    "abstract": "Multi-Robot Motion Planning (MRMP) involves generating collision-free trajectories for multiple robots operating in a shared continuous workspace. While discrete multi-agent path finding (MAPF) methods are broadly adopted due to their scalability, their coarse discretization severely limits trajectory quality. In contrast, continuous optimization-based planners offer higher-quality paths but suffer from the curse of dimensionality, resulting in poor scalability with respect to the number of robots. This paper tackles the limitations of these two approaches by introducing a novel framework that integrates discrete MAPF solvers with constrained generative diffusion models. The resulting framework, called Discrete-Guided Diffusion (DGD), has three key characteristics: (1) it decomposes the original nonconvex MRMP problem into tractable subproblems with convex configuration spaces, (2) it combines discrete MAPF solutions with constrained optimization techniques to guide diffusion models capture complex spatiotemporal dependencies among robots, and (3) it incorporates a lightweight constraint repair mechanism to ensure trajectory feasibility. The proposed method sets a new state-of-the-art performance in large-scale, complex environments, scaling to 100 robots while achieving planning efficiency and high success rates.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20095v1",
    "published_date": "2025-08-27 17:59:36 UTC",
    "updated_date": "2025-08-27 17:59:36 UTC"
  },
  {
    "arxiv_id": "2509.00100v1",
    "title": "MODE: Mixture of Document Experts for RAG",
    "authors": [
      "Rahul Anand"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) often relies on large vector databases and cross-encoders tuned for large-scale corpora, which can be excessive for small, domain-specific collections. We present MODE (Mixture of Document Experts), a lightweight alternative that replaces fine-grained nearest-neighbor search with cluster-and-route retrieval. Documents are embedded, grouped into semantically coherent clusters, and represented by cached centroids. At query time, we route to the top centroid(s) and retrieve context only within those clusters, eliminating external vector-database infrastructure and reranking while keeping latency low. On HotpotQA and SQuAD corpora with 100-500 chunks, MODE matches or exceeds a dense-retrieval baseline in answer quality while reducing end-to-end retrieval time. Ablations show that cluster granularity and multi-cluster routing control the recall/precision trade-off, and that tighter clusters improve downstream accuracy. MODE offers a practical recipe for small and medium corpora where simplicity, speed, and topical focus matter.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00100v1",
    "published_date": "2025-08-27 17:45:16 UTC",
    "updated_date": "2025-08-27 17:45:16 UTC"
  },
  {
    "arxiv_id": "2509.03537v1",
    "title": "AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models",
    "authors": [
      "Cheng-Kai Yeh",
      "Hsing-Wang Lee",
      "Chung-Hung Kuo",
      "Hen-Hsen Huang"
    ],
    "abstract": "Abstraction--the ability to recognize and distill essential computational patterns from complex problem statements--is a foundational skill in computer science, critical both for human problem-solvers and coding-oriented large language models (LLMs). Despite recent advances in training LLMs for code generation using reinforcement learning (RL), most existing approaches focus primarily on superficial pattern recognition, overlooking explicit training for abstraction. In this study, we propose AR$^2$ (Adversarial Reinforcement Learning for Abstract Reasoning), a novel framework explicitly designed to enhance the abstraction abilities of LLMs. AR$^2$ employs a teacher model to transform kernel problems into narrative-rich, challenging descriptions without changing their fundamental logic. Simultaneously, a student coding model is trained to solve these complex narrative problems by extracting their underlying computational kernels. Experimental results demonstrate that AR$^2$ substantially improves the student model's accuracy on previously unseen, challenging programming tasks, underscoring abstraction as a key skill for enhancing LLM generalization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, accepted by CIKM 2025 as a short paper",
    "pdf_url": "https://arxiv.org/pdf/2509.03537v1",
    "published_date": "2025-08-27 17:26:44 UTC",
    "updated_date": "2025-08-27 17:26:44 UTC"
  },
  {
    "arxiv_id": "2508.20064v1",
    "title": "Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices",
    "authors": [
      "Philippe Zhang",
      "Weili Jiang",
      "Yihao Li",
      "Jing Zhang",
      "Sarah Matta",
      "Yubo Tan",
      "Hui Lin",
      "Haoshen Wang",
      "Jiangtian Pan",
      "Hui Xu",
      "Laurent Borderie",
      "Alexandre Le Guilcher",
      "Béatrice Cochener",
      "Chubin Ou",
      "Gwenolé Quellec",
      "Mathieu Lamard"
    ],
    "abstract": "Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting visual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments have been effective in slowing the progression of neovascular AMD, with better outcomes achieved through timely diagnosis and consistent monitoring. Tracking the progression of neovascular activity in OCT scans of patients with exudative AMD allows for the development of more personalized and effective treatment plans. This was the focus of the Monitoring Age-related Macular Degeneration Progression in Optical Coherence Tomography (MARIO) challenge, in which we participated. In Task 1, which involved classifying the evolution between two pairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN network with model ensembling to further enhance the model's performance. For Task 2, which focused on predicting progression over the next three months based on current exam data, we proposed the Patch Progression Masked Autoencoder that generates an OCT for the next exam and then classifies the evolution between the current OCT and the one generated using our solution from Task 1. The results we achieved allowed us to place in the Top 10 for both tasks. Some team members are part of the same organization as the challenge organizers; therefore, we are not eligible to compete for the prize.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures, 3 tables, challenge/conference paper",
    "pdf_url": "https://arxiv.org/pdf/2508.20064v1",
    "published_date": "2025-08-27 17:18:30 UTC",
    "updated_date": "2025-08-27 17:18:30 UTC"
  },
  {
    "arxiv_id": "2508.20040v1",
    "title": "Model Science: getting serious about verification, explanation and control of AI systems",
    "authors": [
      "Przemyslaw Biecek",
      "Wojciech Samek"
    ],
    "abstract": "The growing adoption of foundation models calls for a paradigm shift from Data Science to Model Science. Unlike data-centric approaches, Model Science places the trained model at the core of analysis, aiming to interact, verify, explain, and control its behavior across diverse operational contexts. This paper introduces a conceptual framework for a new discipline called Model Science, along with the proposal for its four key pillars: Verification, which requires strict, context-aware evaluation protocols; Explanation, which is understood as various approaches to explore of internal model operations; Control, which integrates alignment techniques to steer model behavior; and Interface, which develops interactive and visual explanation tools to improve human calibration and decision-making. The proposed framework aims to guide the development of credible, safe, and human-aligned AI systems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.20040v1",
    "published_date": "2025-08-27 16:50:17 UTC",
    "updated_date": "2025-08-27 16:50:17 UTC"
  },
  {
    "arxiv_id": "2508.20151v1",
    "title": "IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement",
    "authors": [
      "Yuanzhe Shen",
      "Zisu Huang",
      "Zhengkang Guo",
      "Yide Liu",
      "Guanxu Chen",
      "Ruicheng Yin",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has driven their adoption across diverse domains, yet their ability to generate harmful content poses significant safety challenges. While extensive research has focused on mitigating harmful outputs, such efforts often come at the cost of excessively rejecting harmless prompts. Striking a balance among safety, over-refusal, and utility remains a critical challenge. In this work, we introduce IntentionReasoner, a novel safeguard mechanism that leverages a dedicated guard model to perform intent reasoning, multi-level safety classification, and query rewriting to neutralize potentially harmful intent in edge-case queries. Specifically, we first construct a comprehensive dataset comprising approximately 163,000 queries, each annotated with intent reasoning, safety labels, and rewritten versions. Supervised fine-tuning is then applied to equip the guard model with foundational capabilities in format adherence, intent analysis, and safe rewriting. Finally, we apply a tailored multi-reward optimization strategy that integrates rule-based heuristics and reward model signals within a reinforcement learning framework to further enhance performance. Extensive experiments show that IntentionReasoner excels in multiple safeguard benchmarks, generation quality evaluations, and jailbreak attack scenarios, significantly enhancing safety while effectively reducing over-refusal rates and improving the quality of responses.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.20151v1",
    "published_date": "2025-08-27 16:47:31 UTC",
    "updated_date": "2025-08-27 16:47:31 UTC"
  },
  {
    "arxiv_id": "2508.20033v1",
    "title": "DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis",
    "authors": [
      "Liana Patel",
      "Negar Arabzadeh",
      "Harshit Gupta",
      "Ankita Sundar",
      "Ion Stoica",
      "Matei Zaharia",
      "Carlos Guestrin"
    ],
    "abstract": "The ability to research and synthesize knowledge is central to human expertise and progress. An emerging class of systems promises these exciting capabilities through generative research synthesis, performing retrieval over the live web and synthesizing discovered sources into long-form, cited summaries. However, evaluating such systems remains an open challenge: existing question-answering benchmarks focus on short-form factual responses, while expert-curated datasets risk staleness and data contamination. Both fail to capture the complexity and evolving nature of real research synthesis tasks. In this work, we introduce DeepScholar-bench, a live benchmark and holistic, automated evaluation framework designed to evaluate generative research synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv papers and focuses on a real research synthesis task: generating the related work sections of a paper by retrieving, synthesizing, and citing prior research. Our evaluation framework holistically assesses performance across three key dimensions, knowledge synthesis, retrieval quality, and verifiability. We also develop DeepScholar-base, a reference pipeline implemented efficiently using the LOTUS API. Using the DeepScholar-bench framework, we perform a systematic evaluation of prior open-source systems, search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that DeepScholar-base establishes a strong baseline, attaining competitive or higher performance than each other method. We also find that DeepScholar-bench remains far from saturated, with no system exceeding a score of $19\\%$ across all metrics. These results underscore the difficulty of DeepScholar-bench, as well as its importance for progress towards AI systems capable of generative research synthesis. We make our code available at https://github.com/guestrin-lab/deepscholar-bench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20033v1",
    "published_date": "2025-08-27 16:36:34 UTC",
    "updated_date": "2025-08-27 16:36:34 UTC"
  },
  {
    "arxiv_id": "2508.20030v1",
    "title": "Large Language Models (LLMs) for Electronic Design Automation (EDA)",
    "authors": [
      "Kangwei Xu",
      "Denis Schwachhofer",
      "Jason Blocklove",
      "Ilia Polian",
      "Peter Domanski",
      "Dirk Pflüger",
      "Siddharth Garg",
      "Ramesh Karri",
      "Ozgur Sinanoglu",
      "Johann Knechtel",
      "Zhuorui Zhao",
      "Ulf Schlichtmann",
      "Bing Li"
    ],
    "abstract": "With the growing complexity of modern integrated circuits, hardware engineers are required to devote more effort to the full design-to-manufacturing workflow. This workflow involves numerous iterations, making it both labor-intensive and error-prone. Therefore, there is an urgent demand for more efficient Electronic Design Automation (EDA) solutions to accelerate hardware development. Recently, large language models (LLMs) have shown remarkable advancements in contextual comprehension, logical reasoning, and generative capabilities. Since hardware designs and intermediate scripts can be represented as text, integrating LLM for EDA offers a promising opportunity to simplify and even automate the entire workflow. Accordingly, this paper provides a comprehensive overview of incorporating LLMs into EDA, with emphasis on their capabilities, limitations, and future opportunities. Three case studies, along with their outlook, are introduced to demonstrate the capabilities of LLMs in hardware design, testing, and optimization. Finally, future directions and challenges are highlighted to further explore the potential of LLMs in shaping the next-generation EDA, providing valuable insights for researchers interested in leveraging advanced AI technologies for EDA.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "eess.SY",
    "comment": "Accepted by IEEE International System-on-Chip Conference",
    "pdf_url": "https://arxiv.org/pdf/2508.20030v1",
    "published_date": "2025-08-27 16:33:51 UTC",
    "updated_date": "2025-08-27 16:33:51 UTC"
  },
  {
    "arxiv_id": "2508.20019v1",
    "title": "Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence",
    "authors": [
      "Ji Wang",
      "Kashing Chen",
      "Xinyuan Song",
      "Ke Zhang",
      "Lynn Ai",
      "Eric Yang",
      "Bill Shi"
    ],
    "abstract": "Most existing Large Language Model (LLM)-based agent frameworks rely on centralized orchestration, incurring high deployment costs, rigid communication topologies, and limited adaptability. To address these challenges, we introduce Symphony, a decentralized multi-agent system which enables lightweight LLMs on consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms: (1) a decentralized ledger that records capabilities, (2) a Beacon-selection protocol for dynamic task allocation, and (3) weighted result voting based on CoTs. This design forms a privacy-saving, scalable, and fault-tolerant orchestration with low overhead. Empirically, Symphony outperforms existing baselines on reasoning benchmarks, achieving substantial accuracy gains and demonstrating robustness across models of varying capacities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20019v1",
    "published_date": "2025-08-27 16:27:57 UTC",
    "updated_date": "2025-08-27 16:27:57 UTC"
  },
  {
    "arxiv_id": "2508.20018v1",
    "title": "SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control",
    "authors": [
      "Quanfeng Lu",
      "Zhantao Ma",
      "Shuai Zhong",
      "Jin Wang",
      "Dahai Yu",
      "Michael K. Ng",
      "Ping Luo"
    ],
    "abstract": "The rapid advancement of large vision language models (LVLMs) and agent systems has heightened interest in mobile GUI agents that can reliably translate natural language into interface operations. Existing single-agent approaches, however, remain limited by structural constraints. Although multi-agent systems naturally decouple different competencies, recent progress in multi-agent reinforcement learning (MARL) has often been hindered by inefficiency and remains incompatible with current LVLM architectures. To address these challenges, we introduce SWIRL, a staged workflow for interleaved reinforcement learning designed for multi-agent systems. SWIRL reformulates MARL into a sequence of single-agent reinforcement learning tasks, updating one agent at a time while keeping the others fixed. This formulation enables stable training and promotes efficient coordination across agents. Theoretically, we provide a stepwise safety bound, a cross-round monotonic improvement theorem, and convergence guarantees on return, ensuring robust and principled optimization. In application to mobile GUI control, SWIRL instantiates a Navigator that converts language and screen context into structured plans, and an Interactor that grounds these plans into executable atomic actions. Extensive experiments demonstrate superior performance on both high-level and low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong capability in multi-agent mathematical reasoning, underscoring its potential as a general framework for developing efficient and robust multi-agent systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.20018v1",
    "published_date": "2025-08-27 16:27:19 UTC",
    "updated_date": "2025-08-27 16:27:19 UTC"
  },
  {
    "arxiv_id": "2508.20016v2",
    "title": "HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling",
    "authors": [
      "Matthias Maiterth",
      "Wesley H. Brewer",
      "Jaya S. Kuruvella",
      "Arunavo Dey",
      "Tanzima Z. Islam",
      "Kevin Menear",
      "Dmitry Duplyakin",
      "Rashadul Kabir",
      "Tapasya Patki",
      "Terry Jones",
      "Feiyi Wang"
    ],
    "abstract": "Schedulers are critical for optimal resource utilization in high-performance computing. Traditional methods to evaluate schedulers are limited to post-deployment analysis, or simulators, which do not model associated infrastructure. In this work, we present the first-of-its-kind integration of scheduling and digital twins in HPC. This enables what-if studies to understand the impact of parameter configurations and scheduling decisions on the physical assets, even before deployment, or regarching changes not easily realizable in production. We (1) provide the first digital twin framework extended with scheduling capabilities, (2) integrate various top-tier HPC systems given their publicly available datasets, (3) implement extensions to integrate external scheduling simulators. Finally, we show how to (4) implement and evaluate incentive structures, as-well-as (5) evaluate machine learning based scheduling, in such novel digital-twin based meta-framework to prototype scheduling. Our work enables what-if scenarios of HPC systems to evaluate sustainability, and the impact on the simulated system.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.ET",
      "eess.SY"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20016v2",
    "published_date": "2025-08-27 16:21:31 UTC",
    "updated_date": "2025-08-28 01:16:49 UTC"
  },
  {
    "arxiv_id": "2508.20015v1",
    "title": "Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment",
    "authors": [
      "Julian Arnold",
      "Niels Lörch"
    ],
    "abstract": "Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is broadly misaligned with respect to human values. To understand when and how this emergent misalignment occurs, we develop a comprehensive framework for detecting and characterizing rapid transitions during fine-tuning using both distributional change detection methods as well as order parameters that are formulated in plain English and evaluated by an LLM judge. Using an objective statistical dissimilarity measure, we quantify how the phase transition that occurs during fine-tuning affects multiple aspects of the model. In particular, we assess what percentage of the total distributional change in model outputs is captured by different aspects, such as alignment or verbosity, providing a decomposition of the overall transition. We also find that the actual behavioral transition occurs later in training than indicated by the peak in the gradient norm alone. Our framework enables the automated discovery and quantification of language-based order parameters, which we demonstrate on examples ranging from knowledge questions to politics and ethics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11+25 pages, 4+11 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.20015v1",
    "published_date": "2025-08-27 16:19:49 UTC",
    "updated_date": "2025-08-27 16:19:49 UTC"
  },
  {
    "arxiv_id": "2508.20013v2",
    "title": "Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach",
    "authors": [
      "Lotte Gross",
      "Rebecca Walter",
      "Nicole Zoppi",
      "Adrien Justus",
      "Alessandro Gambetti",
      "Qiwei Han",
      "Maximilian Kaiser"
    ],
    "abstract": "This study addresses critical industrial challenges in e-commerce product categorization, namely platform heterogeneity and the structural limitations of existing taxonomies, by developing and deploying a multimodal hierarchical classification framework. Using a dataset of 271,700 products from 40 international fashion e-commerce platforms, we integrate textual features (RoBERTa), visual features (ViT), and joint vision-language representations (CLIP). We investigate fusion strategies, including early, late, and attention-based fusion within a hierarchical architecture enhanced by dynamic masking to ensure taxonomic consistency. Results show that CLIP embeddings combined via an MLP-based late-fusion strategy achieve the highest hierarchical F1 (98.59%), outperforming unimodal baselines. To address shallow or inconsistent categories, we further introduce a self-supervised \"product recategorization\" pipeline using SimCLR, UMAP, and cascade clustering, which discovered new, fine-grained categories (for example, subtypes of \"Shoes\") with cluster purities above 86%. Cross-platform experiments reveal a deployment-relevant trade-off: complex late-fusion methods maximize accuracy with diverse training data, while simpler early-fusion methods generalize more effectively to unseen platforms. Finally, we demonstrate the framework's industrial scalability through deployment in EURWEB's commercial transaction intelligence platform via a two-stage inference pipeline, combining a lightweight RoBERTa stage with a GPU-accelerated multimodal stage to balance cost and accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accetped at IEEE BigData 2025, 10 pages, 5 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.20013v2",
    "published_date": "2025-08-27 16:16:12 UTC",
    "updated_date": "2025-11-09 13:18:27 UTC"
  },
  {
    "arxiv_id": "2508.19999v2",
    "title": "Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation",
    "authors": [
      "Ziniu Zhang",
      "Zhenshuo Zhang",
      "Dongyue Li",
      "Lu Wang",
      "Jennifer Dy",
      "Hongyang R. Zhang"
    ],
    "abstract": "This paper introduces an algorithm to select demonstration examples for in-context learning of a query set. Given a set of $n$ examples, how can we quickly select $k$ out of $n$ to best serve as the conditioning for downstream inference? This problem has broad applications in prompt tuning and chain-of-thought reasoning. Since model weights remain fixed during in-context learning, previous work has sought to design methods based on the similarity of token embeddings. This work proposes a new approach based on gradients of the output taken in the input embedding space. Our approach estimates model outputs through a first-order approximation using the gradients. Then, we apply this estimation to multiple randomly sampled subsets. Finally, we aggregate the sampled subset outcomes to form an influence score for each demonstration, and select $k$ most relevant examples. This procedure only requires pre-computing model outputs and gradients once, resulting in a linear-time algorithm relative to model and training set sizes. Extensive experiments across various models and datasets validate the efficiency of our approach. We show that the gradient estimation procedure yields approximations of full inference with less than ${1}\\%$ error across six datasets. This allows us to scale up subset selection that would otherwise run full inference by up to ${37.7}\\times$ on models with up to $34$ billion parameters, and outperform existing selection methods based on input embeddings by ${11}\\%$ on average.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages. EMNLP'25",
    "pdf_url": "https://arxiv.org/pdf/2508.19999v2",
    "published_date": "2025-08-27 15:59:47 UTC",
    "updated_date": "2025-11-04 16:44:29 UTC"
  },
  {
    "arxiv_id": "2508.19993v2",
    "title": "MathBuddy: A Multimodal System for Affective Math Tutoring",
    "authors": [
      "Debanjana Kar",
      "Leopold Böss",
      "Dacia Braca",
      "Sebastian Maximilian Dennerlein",
      "Nina Christine Hubig",
      "Philipp Wintersberger",
      "Yufang Hou"
    ],
    "abstract": "The rapid adoption of LLM-based conversational systems is already transforming the landscape of educational technology. However, the current state-of-the-art learning models do not take into account the student's affective states. Multiple studies in educational psychology support the claim that positive or negative emotional states can impact a student's learning capabilities. To bridge this gap, we present MathBuddy, an emotionally aware LLM-powered Math Tutor, which dynamically models the student's emotions and maps them to relevant pedagogical strategies, making the tutor-student conversation a more empathetic one. The student's emotions are captured from the conversational text as well as from their facial expressions. The student's emotions are aggregated from both modalities to confidently prompt our LLM Tutor for an emotionally-aware response. We have evaluated our model using automatic evaluation metrics across eight pedagogical dimensions and user studies. We report a massive 23 point performance gain using the win rate and a 3 point gain at an overall level using DAMR scores which strongly supports our hypothesis of improving LLM-based tutor's pedagogical abilities by modeling students' emotions. Our dataset and code are available at: https://github.com/ITU-NLP/MathBuddy .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2025 (Demo Track)",
    "pdf_url": "https://arxiv.org/pdf/2508.19993v2",
    "published_date": "2025-08-27 15:50:43 UTC",
    "updated_date": "2025-09-24 19:05:55 UTC"
  },
  {
    "arxiv_id": "2508.19982v3",
    "title": "Diffusion Language Models Know the Answer Before Decoding",
    "authors": [
      "Pengxiang Li",
      "Yefan Zhou",
      "Dilxat Muhtar",
      "Lu Yin",
      "Shilin Yan",
      "Li Shen",
      "Yi Liang",
      "Soroush Vosoughi",
      "Shiwei Liu"
    ],
    "abstract": "Diffusion language models (DLMs) have recently emerged as an alternative to autoregressive approaches, offering parallel sequence generation and flexible token orders. However, their inference remains slower than that of autoregressive models, primarily due to the cost of bidirectional attention and the large number of refinement steps required for high quality outputs. In this work, we highlight and leverage an overlooked property of DLMs early answer convergence: in many cases, the correct answer can be internally identified by half steps before the final decoding step, both under semi-autoregressive and random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99% of instances, respectively, can be decoded correctly using only half of the refinement steps. Building on this observation, we introduce Prophet, a training-free fast decoding paradigm that enables early commit decoding. Specifically, Prophet dynamically decides whether to continue refinement or to go \"all-in\" (i.e., decode all remaining tokens in one step), using the confidence gap between the top-2 prediction candidates as the criterion. It integrates seamlessly into existing DLM implementations, incurs negligible overhead, and requires no additional training. Empirical evaluations of LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the number of decoding steps by up to 3.4x while preserving high generation quality. These results recast DLM decoding as a problem of when to stop sampling, and demonstrate that early decode convergence provides a simple yet powerful mechanism for accelerating DLM inference, complementary to existing speedup techniques. Our code is publicly available at https://github.com/pixeli99/Prophet.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19982v3",
    "published_date": "2025-08-27 15:40:25 UTC",
    "updated_date": "2025-10-14 03:42:04 UTC"
  },
  {
    "arxiv_id": "2508.19972v3",
    "title": "GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity",
    "authors": [
      "Seongheon Park",
      "Sharon Li"
    ],
    "abstract": "Object hallucination in large vision-language models presents a significant challenge to their safe deployment in real-world applications. Recent works have proposed object-level hallucination scores to estimate the likelihood of object hallucination; however, these methods typically adopt either a global or local perspective in isolation, which may limit detection reliability. In this paper, we introduce GLSim, a novel training-free object hallucination detection framework that leverages complementary global and local embedding similarity signals between image and text modalities, enabling more accurate and reliable hallucination detection in diverse scenarios. We comprehensively benchmark existing object hallucination detection methods and demonstrate that GLSim achieves superior detection performance, outperforming competitive baselines by a significant margin.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.19972v3",
    "published_date": "2025-08-27 15:30:06 UTC",
    "updated_date": "2025-10-15 04:04:54 UTC"
  },
  {
    "arxiv_id": "2509.00094v1",
    "title": "Automatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning",
    "authors": [
      "Abdullah Abdelfattah",
      "Mahmoud I. Khalil",
      "Hazem Abbas"
    ],
    "abstract": "Assessing spoken language is challenging, and quantifying pronunciation metrics for machine learning models is even harder. However, for the Holy Quran, this task is simplified by the rigorous recitation rules (tajweed) established by Muslim scholars, enabling highly effective assessment. Despite this advantage, the scarcity of high-quality annotated data remains a significant barrier.\n  In this work, we bridge these gaps by introducing: (1) A 98% automated pipeline to produce high-quality Quranic datasets -- encompassing: Collection of recitations from expert reciters, Segmentation at pause points (waqf) using our fine-tuned wav2vec2-BERT model, Transcription of segments, Transcript verification via our novel Tasmeea algorithm; (2) 850+ hours of audio (~300K annotated utterances); (3) A novel ASR-based approach for pronunciation error detection, utilizing our custom Quran Phonetic Script (QPS) to encode Tajweed rules (unlike the IPA standard for Modern Standard Arabic). QPS uses a two-level script: (Phoneme level): Encodes Arabic letters with short/long vowels. (Sifa level): Encodes articulation characteristics of every phoneme. We further include comprehensive modeling with our novel multi-level CTC Model which achieved 0.16% average Phoneme Error Rate (PER) on the testset. We release all code, data, and models as open-source: https://obadx.github.io/prepare-quran-dataset/",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00094v1",
    "published_date": "2025-08-27 15:28:46 UTC",
    "updated_date": "2025-08-27 15:28:46 UTC"
  },
  {
    "arxiv_id": "2508.19966v1",
    "title": "Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation",
    "authors": [
      "Slimane Bellaouar",
      "Attia Nehar",
      "Soumia Souffi",
      "Mounia Bouameur"
    ],
    "abstract": "Despite its significance, Arabic, a linguistically rich and morphologically complex language, faces the challenge of being under-resourced. The scarcity of large annotated datasets hampers the development of accurate tools for subjectivity analysis in Arabic. Recent advances in deep learning and Transformers have proven highly effective for text classification in English and French. This paper proposes a new approach for subjectivity assessment in Arabic textual data. To address the dearth of specialized annotated datasets, we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and ArabianGPT) on AraDhati+ for effective subjectivity classification. Furthermore, we experimented with an ensemble decision approach to harness the strengths of individual models. Our approach achieves a remarkable accuracy of 97.79\\,\\% for Arabic subjectivity classification. Results demonstrate the effectiveness of the proposed approach in addressing the challenges posed by limited resources in Arabic language processing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19966v1",
    "published_date": "2025-08-27 15:20:12 UTC",
    "updated_date": "2025-08-27 15:20:12 UTC"
  },
  {
    "arxiv_id": "2508.19963v1",
    "title": "Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants",
    "authors": [
      "M. Umlauft",
      "M. Schranz"
    ],
    "abstract": "Optimizing modern production plants using the job-shop principle is a known hard problem. For very large plants, like semiconductor fabs, the problem becomes unsolvable on a plant-wide scale in a reasonable amount of time using classical linear optimization. An alternative approach is the use of swarm intelligence algorithms. These have been applied to the job-shop problem before, but often in a centrally calculated way where they are applied to the solution space, but they can be implemented in a bottom-up fashion to avoid global result computation as well. One of the problems in semiconductor production is that the production process requires a lot of switching between machines that process lots one after the other and machines that process batches of lots at once, often with long processing times. In this paper, we address this switching problem with the ``boids'' flocking algorithm that was originally used in robotics and movie industry. The flocking behavior is a bio-inspired algorithm that uses only local information and interaction based on simple heuristics. We show that this algorithm addresses these valid considerations in production plant optimization, as it reacts to the switching of machine kinds similar to how a swarm of flocking animals would react to obstacles in its course.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This is the author's version of a paper reviewed and accepted by the 9th International Symposium on Swarm Behavior and Bio-Inspired Robotics 2025. Authors were not able to present it due to time constraints. 3 Tables, 5 Figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19963v1",
    "published_date": "2025-08-27 15:17:31 UTC",
    "updated_date": "2025-08-27 15:17:31 UTC"
  },
  {
    "arxiv_id": "2508.19932v1",
    "title": "CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments",
    "authors": [
      "Nitish Jaipuria",
      "Lorenzo Gatto",
      "Zijun Kan",
      "Shankey Poddar",
      "Bill Cheung",
      "Diksha Bansal",
      "Ramanan Balakrishnan",
      "Aviral Suri",
      "Jose Estevez"
    ],
    "abstract": "The proliferation of digital payment platforms has transformed commerce, offering unmatched convenience and accessibility globally. However, this growth has also attracted malicious actors, leading to a corresponding increase in sophisticated social engineering scams. These scams are often initiated and orchestrated on multiple surfaces outside the payment platform, making user and transaction-based signals insufficient for a complete understanding of the scam's methodology and underlying patterns, without which it is very difficult to prevent it in a timely manner. This paper presents CASE (Conversational Agent for Scam Elucidation), a novel Agentic AI framework that addresses this problem by collecting and managing user scam feedback in a safe and scalable manner. A conversational agent is uniquely designed to proactively interview potential victims to elicit intelligence in the form of a detailed conversation. The conversation transcripts are then consumed by another AI system that extracts information and converts it into structured data for downstream usage in automated and manual enforcement mechanisms. Using Google's Gemini family of LLMs, we implemented this framework on Google Pay (GPay) India. By augmenting our existing features with this new intelligence, we have observed a 21% uplift in the volume of scam enforcements. The architecture and its robust evaluation framework are highly generalizable, offering a blueprint for building similar AI-driven systems to collect and manage scam intelligence in other sensitive domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19932v1",
    "published_date": "2025-08-27 14:47:33 UTC",
    "updated_date": "2025-08-27 14:47:33 UTC"
  },
  {
    "arxiv_id": "2508.20148v2",
    "title": "The Anatomy of a Personal Health Agent",
    "authors": [
      "A. Ali Heydari",
      "Ken Gu",
      "Vidya Srinivas",
      "Hong Yu",
      "Zhihan Zhang",
      "Yuwei Zhang",
      "Akshay Paruchuri",
      "Qian He",
      "Hamid Palangi",
      "Nova Hammerquist",
      "Ahmed A. Metwally",
      "Brent Winslow",
      "Yubin Kim",
      "Kumar Ayush",
      "Yuzhe Yang",
      "Girish Narayanswamy",
      "Maxwell A. Xu",
      "Jake Garrison",
      "Amy Armento Lee",
      "Jenny Vafeiadou",
      "Ben Graef",
      "Isaac R. Galatzer-Levy",
      "Erik Schenck",
      "Andrew Barakat",
      "Javier Perez",
      "Jacqueline Shreibati",
      "John Hernandez",
      "Anthony Z. Faranesh",
      "Javier L. Prieto",
      "Connor Heneghan",
      "Yun Liu",
      "Jiening Zhan",
      "Mark Malhotra",
      "Shwetak Patel",
      "Tim Althoff",
      "Xin Liu",
      "Daniel McDuff",
      "Xuhai \"Orson\" Xu"
    ],
    "abstract": "Health is a fundamental pillar of human wellness, and the rapid advancements in large language models (LLMs) have driven the development of a new generation of health agents. However, the application of health agents to fulfill the diverse needs of individuals in daily non-clinical settings is underexplored. In this work, we aim to build a comprehensive personal health agent that is able to reason about multimodal data from everyday consumer wellness devices and common personal health records, and provide personalized health recommendations. To understand end-users' needs when interacting with such an assistant, we conducted an in-depth analysis of web search and health forum queries, alongside qualitative insights from users and health experts gathered through a user-centered design process. Based on these findings, we identified three major categories of consumer health needs, each of which is supported by a specialist sub-agent: (1) a data science agent that analyzes personal time-series wearable and health record data, (2) a health domain expert agent that integrates users' health and contextual data to generate accurate, personalized insights, and (3) a health coach agent that synthesizes data insights, guiding users using a specified psychological strategy and tracking users' progress. Furthermore, we propose and develop the Personal Health Agent (PHA), a multi-agent framework that enables dynamic, personalized interactions to address individual health needs. To evaluate each sub-agent and the multi-agent system, we conducted automated and human evaluations across 10 benchmark tasks, involving more than 7,000 annotations and 1,100 hours of effort from health experts and end-users. Our work represents the most comprehensive evaluation of a health agent to date and establishes a strong foundation towards the futuristic vision of a personal health agent accessible to everyone.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Minor updates to the manuscript (V2)",
    "pdf_url": "https://arxiv.org/pdf/2508.20148v2",
    "published_date": "2025-08-27 14:38:46 UTC",
    "updated_date": "2025-09-18 17:43:25 UTC"
  },
  {
    "arxiv_id": "2508.19927v1",
    "title": "WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution",
    "authors": [
      "Fayaz Ali",
      "Muhammad Zawish",
      "Steven Davy",
      "Radu Timofte"
    ],
    "abstract": "Transformers have demonstrated promising performance in computer vision tasks, including image super-resolution (SR). The quadratic computational complexity of window self-attention mechanisms in many transformer-based SR methods forces the use of small, fixed windows, limiting the receptive field. In this paper, we propose a new approach by embedding the wavelet transform within a hierarchical transformer framework, called (WaveHiT-SR). First, using adaptive hierarchical windows instead of static small windows allows to capture features across different levels and greatly improve the ability to model long-range dependencies. Secondly, the proposed model utilizes wavelet transforms to decompose images into multiple frequency subbands, allowing the network to focus on both global and local features while preserving structural details. By progressively reconstructing high-resolution images through hierarchical processing, the network reduces computational complexity without sacrificing performance. The multi-level decomposition strategy enables the network to capture fine-grained information in lowfrequency components while enhancing high-frequency textures. Through extensive experimentation, we confirm the effectiveness and efficiency of our WaveHiT-SR. Our refined versions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR results, achieving higher efficiency with fewer parameters, lower FLOPs, and faster speeds.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19927v1",
    "published_date": "2025-08-27 14:37:50 UTC",
    "updated_date": "2025-08-27 14:37:50 UTC"
  },
  {
    "arxiv_id": "2508.19914v1",
    "title": "The Next Layer: Augmenting Foundation Models with Structure-Preserving and Attention-Guided Learning for Local Patches to Global Context Awareness in Computational Pathology",
    "authors": [
      "Muhammad Waqas",
      "Rukhmini Bandyopadhyay",
      "Eman Showkatian",
      "Amgad Muneer",
      "Anas Zafar",
      "Frank Rojas Alvarez",
      "Maricel Corredor Marin",
      "Wentao Li",
      "David Jaffray",
      "Cara Haymaker",
      "John Heymach",
      "Natalie I Vokes",
      "Luisa Maren Solis Soto",
      "Jianjun Zhang",
      "Jia Wu"
    ],
    "abstract": "Foundation models have recently emerged as powerful feature extractors in computational pathology, yet they typically omit mechanisms for leveraging the global spatial structure of tissues and the local contextual relationships among diagnostically relevant regions - key elements for understanding the tumor microenvironment. Multiple instance learning (MIL) remains an essential next step following foundation model, designing a framework to aggregate patch-level features into slide-level predictions. We present EAGLE-Net, a structure-preserving, attention-guided MIL architecture designed to augment prediction and interpretability. EAGLE-Net integrates multi-scale absolute spatial encoding to capture global tissue architecture, a top-K neighborhood-aware loss to focus attention on local microenvironments, and background suppression loss to minimize false positives. We benchmarked EAGLE-Net on large pan-cancer datasets, including three cancer types for classification (10,260 slides) and seven cancer types for survival prediction (4,172 slides), using three distinct histology foundation backbones (REMEDIES, Uni-V1, Uni2-h). Across tasks, EAGLE-Net achieved up to 3% higher classification accuracy and the top concordance indices in 6 of 7 cancer types, producing smooth, biologically coherent attention maps that aligned with expert annotations and highlighted invasive fronts, necrosis, and immune infiltration. These results position EAGLE-Net as a generalizable, interpretable framework that complements foundation models, enabling improved biomarker discovery, prognostic modeling, and clinical decision support",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "q-bio.QM",
    "comment": "43 pages, 7 main Figures, 8 Extended Data Figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19914v1",
    "published_date": "2025-08-27 14:19:38 UTC",
    "updated_date": "2025-08-27 14:19:38 UTC"
  },
  {
    "arxiv_id": "2508.19903v1",
    "title": "Logical Reasoning with Outcome Reward Models for Test-Time Scaling",
    "authors": [
      "Ramya Keerthy Thatikonda",
      "Wray Buntine",
      "Ehsan Shareghi"
    ],
    "abstract": "Logical reasoning is a critical benchmark for evaluating the capabilities of large language models (LLMs), as it reflects their ability to derive valid conclusions from given premises. While the combination of test-time scaling with dedicated outcome or process reward models has opened up new avenues to enhance LLMs performance in complex reasoning tasks, this space is under-explored in deductive logical reasoning. We present a set of Outcome Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly generate data using Chain-of-Thought (CoT) with single and multiple samples. Additionally, we propose a novel tactic to further expand the type of errors covered in the training dataset of the ORM. In particular, we propose an echo generation technique that leverages LLMs' tendency to reflect incorrect assumptions made in prompts to extract additional training data, covering previously unexplored error types. While a standard CoT chain may contain errors likely to be made by the reasoner, the echo strategy deliberately steers the model toward incorrect reasoning. We show that ORMs trained on CoT and echo-augmented data demonstrate improved performance on the FOLIO, JustLogic, and ProverQA datasets across four different LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.19903v1",
    "published_date": "2025-08-27 14:08:43 UTC",
    "updated_date": "2025-08-27 14:08:43 UTC"
  },
  {
    "arxiv_id": "2508.19897v3",
    "title": "The Information Dynamics of Generative Diffusion",
    "authors": [
      "Luca Ambrogioni"
    ],
    "abstract": "Generative diffusion models have emerged as a powerful class of models in machine learning, yet a unified theoretical understanding of their operation is still developing. This paper provides an integrated perspective on generative diffusion by connecting their dynamic, information-theoretic, and thermodynamic properties under a unified mathematical framework. We demonstrate that the rate of conditional entropy production during generation (i.e. the generative bandwidth) is directly governed by the expected divergence of the score function's vector field. This divergence, in turn, is linked to the branching of trajectories and generative bifurcations, which we characterize as symmetry-breaking phase transitions in the energy landscape. This synthesis offers a powerful insight: the process of generation is fundamentally driven by the controlled, noise-induced breaking of (approximate) symmetries, where peaks in information transfer correspond to critical transitions between possible outcomes. The score function acts as a dynamic non-linear filter that regulates the bandwidth of the noise by suppressing fluctuations that are incompatible with the data.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19897v3",
    "published_date": "2025-08-27 13:53:56 UTC",
    "updated_date": "2025-09-11 14:30:28 UTC"
  },
  {
    "arxiv_id": "2509.00092v2",
    "title": "Robust Detection of Synthetic Tabular Data under Schema Variability",
    "authors": [
      "G. Charbel N. Kindji",
      "Elisa Fromont",
      "Lina Maria Rojas-Barahona",
      "Tanguy Urvoy"
    ],
    "abstract": "The rise of powerful generative models has sparked concerns over data authenticity. While detection methods have been extensively developed for images and text, the case of tabular data, despite its ubiquity, has been largely overlooked. Yet, detecting synthetic tabular data is especially challenging due to its heterogeneous structure and unseen formats at test time. We address the underexplored task of detecting synthetic tabular data ''in the wild'', i.e. when the detector is deployed on tables with variable and previously unseen schemas. We introduce a novel datum-wise transformer architecture that significantly outperforms the only previously published baseline, improving both AUC and accuracy by 7 points. By incorporating a table-adaptation component, our model gains an additional 7 accuracy points, demonstrating enhanced robustness. This work provides the first strong evidence that detecting synthetic tabular data in real-world conditions is feasible, and demonstrates substantial improvements over previous approaches. Following acceptance of the paper, we are finalizing the administrative and licensing procedures necessary for releasing the source code. This extended version will be updated as soon as the release is complete.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00092v2",
    "published_date": "2025-08-27 13:46:39 UTC",
    "updated_date": "2025-12-01 12:19:17 UTC"
  },
  {
    "arxiv_id": "2508.19883v1",
    "title": "AI-Powered Detection of Inappropriate Language in Medical School Curricula",
    "authors": [
      "Chiman Salavati",
      "Shannon Song",
      "Scott A. Hale",
      "Roberto E. Montenegro",
      "Shiri Dori-Hacohen",
      "Fabricio Murai"
    ],
    "abstract": "The use of inappropriate language -- such as outdated, exclusionary, or non-patient-centered terms -- medical instructional materials can significantly influence clinical training, patient interactions, and health outcomes. Despite their reputability, many materials developed over past decades contain examples now considered inappropriate by current medical standards. Given the volume of curricular content, manually identifying instances of inappropriate use of language (IUL) and its subcategories for systematic review is prohibitively costly and impractical. To address this challenge, we conduct a first-in-class evaluation of small language models (SLMs) fine-tuned on labeled data and pre-trained LLMs with in-context learning on a dataset containing approximately 500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL classifier, (2) subcategory-specific binary classifiers, (3) a multilabel classifier, and (4) a two-stage hierarchical pipeline for general IUL detection followed by multilabel classification. For LLMs, we consider variations of prompts that include subcategory definitions and/or shots. We found that both LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed by SLMs. While the multilabel classifier performs best on annotated data, supplementing training with unflagged excerpts as negative examples boosts the specific classifiers' AUC by up to 25%, making them most effective models for mitigating harmful language in medical curricula.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at 2025 AAAI/ACM AI, Ethics and Society Conference (AIES'25)",
    "pdf_url": "https://arxiv.org/pdf/2508.19883v1",
    "published_date": "2025-08-27 13:40:45 UTC",
    "updated_date": "2025-08-27 13:40:45 UTC"
  },
  {
    "arxiv_id": "2508.19882v1",
    "title": "Generative AI for Testing of Autonomous Driving Systems: A Survey",
    "authors": [
      "Qunying Song",
      "He Ye",
      "Mark Harman",
      "Federica Sarro"
    ],
    "abstract": "Autonomous driving systems (ADS) have been an active area of research, with the potential to deliver significant benefits to society. However, before large-scale deployment on public roads, extensive testing is necessary to validate their functionality and safety under diverse driving conditions. Therefore, different testing approaches are required, and achieving effective and efficient testing of ADS remains an open challenge. Recently, generative AI has emerged as a powerful tool across many domains, and it is increasingly being applied to ADS testing due to its ability to interpret context, reason about complex tasks, and generate diverse outputs. To gain a deeper understanding of its role in ADS testing, we systematically analyzed 91 relevant studies and synthesized their findings into six major application categories, primarily centered on scenario-based testing of ADS. We also reviewed their effectiveness and compiled a wide range of datasets, simulators, ADS, metrics, and benchmarks used for evaluation, while identifying 27 limitations. This survey provides an overview and practical insights into the use of generative AI for testing ADS, highlights existing challenges, and outlines directions for future research in this rapidly evolving field.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "67 pages, 6 figures, 29 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.19882v1",
    "published_date": "2025-08-27 13:40:14 UTC",
    "updated_date": "2025-08-27 13:40:14 UTC"
  },
  {
    "arxiv_id": "2508.19881v1",
    "title": "Multispectral LiDAR data for extracting tree points in urban and suburban areas",
    "authors": [
      "Narges Takhtkeshha",
      "Gabriele Mazzacca",
      "Fabio Remondino",
      "Juha Hyyppä",
      "Gottfried Mandlburger"
    ],
    "abstract": "Monitoring urban tree dynamics is vital for supporting greening policies and reducing risks to electrical infrastructure. Airborne laser scanning has advanced large-scale tree management, but challenges remain due to complex urban environments and tree variability. Multispectral (MS) light detection and ranging (LiDAR) improves this by capturing both 3D spatial and spectral data, enabling detailed mapping. This study explores tree point extraction using MS-LiDAR and deep learning (DL) models. Three state-of-the-art models are evaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point Transformer V1 (PTv1). Results show the notable time efficiency and accuracy of SPT, with a mean intersection over union (mIoU) of 85.28%. The highest detection accuracy is achieved by incorporating pseudo normalized difference vegetation index (pNDVI) with spatial data, reducing error rate by 10.61 percentage points (pp) compared to using spatial information alone. These findings highlight the potential of MS-LiDAR and DL to improve tree extraction and further tree inventories.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19881v1",
    "published_date": "2025-08-27 13:39:13 UTC",
    "updated_date": "2025-08-27 13:39:13 UTC"
  },
  {
    "arxiv_id": "2509.00091v2",
    "title": "Ensemble Debates with Local Large Language Models for AI Alignment",
    "authors": [
      "Ephraiem Sarabamoun"
    ],
    "abstract": "As large language models (LLMs) take on greater roles in high-stakes decisions, alignment with human values is essential. Reliance on proprietary APIs limits reproducibility and broad participation. We study whether local open-source ensemble debates can improve alignmentoriented reasoning. Across 150 debates spanning 15 scenarios and five ensemble configurations, ensembles outperform single-model baselines on a 7-point rubric (overall: 3.48 vs. 3.13), with the largest gains in reasoning depth (+19.4%) and argument quality (+34.1%). Improvements are strongest for truthfulness (+1.25 points) and human enhancement (+0.80). We provide code, prompts, and a debate data set, providing an accessible and reproducible foundation for ensemble-based alignment evaluation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "The manuscript is being withdrawn to incorporate additional revisions and improvements",
    "pdf_url": "https://arxiv.org/pdf/2509.00091v2",
    "published_date": "2025-08-27 13:25:51 UTC",
    "updated_date": "2025-11-15 16:28:08 UTC"
  },
  {
    "arxiv_id": "2508.19851v1",
    "title": "Tracking World States with Language Models: State-Based Evaluation Using Chess",
    "authors": [
      "Romain Harang",
      "Jason Naradowsky",
      "Yaswitha Gujju",
      "Yusuke Miyao"
    ],
    "abstract": "Large Language Models (LLMs) exhibit emergent capabilities in structured domains, suggesting they may implicitly internalize high-fidelity representations of world models. While probing techniques have shown promising signs of this in scientific and game-based settings, they rely on model-specific internal activations, which limit interpretability and generalizability. In this work, we propose a model-agnostic, state-based evaluation framework using chess as a benchmark to assess whether LLMs preserve the semantics of structured environments. Our method analyzes the downstream legal move distributions (state affordances) to estimate semantic fidelity between predicted and actual game states. This approach offers a more meaningful evaluation than conventional string-based metrics by aligning more closely with the strategic and rule-governed nature of chess. Experimental results demonstrate that our metrics capture deficiencies in state-tracking, highlighting limitations of LLMs in maintaining coherent internal models over long sequences. Our framework provides a robust tool for evaluating structured reasoning in LLMs without requiring internal model access, and generalizes to a wide class of symbolic environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Spotlight presentation at ICML 2025 Workshop on Assessing World Models",
    "pdf_url": "https://arxiv.org/pdf/2508.19851v1",
    "published_date": "2025-08-27 13:08:51 UTC",
    "updated_date": "2025-08-27 13:08:51 UTC"
  },
  {
    "arxiv_id": "2508.19843v3",
    "title": "SoK: Large Language Model Copyright Auditing via Fingerprinting",
    "authors": [
      "Shuo Shao",
      "Yiming Li",
      "Yu He",
      "Hongwei Yao",
      "Wenyuan Yang",
      "Dacheng Tao",
      "Zhan Qin"
    ],
    "abstract": "The broad capabilities and substantial resources required to train Large Language Models (LLMs) make them valuable intellectual property, yet they remain vulnerable to copyright infringement, such as unauthorized use and model theft. LLM fingerprinting, a non-intrusive technique that compares the distinctive features (i.e., fingerprint) of LLMs to identify whether an LLM is derived from another, offers a promising solution to copyright auditing. However, its reliability remains uncertain due to the prevalence of diverse model modifications and the lack of standardized evaluation. In this SoK, we present the first comprehensive study of the emerging LLM fingerprinting. We introduce a unified framework and taxonomy that structures the field: white-box methods are classified based on their feature source as static, forward-pass, or backward-pass fingerprinting, while black-box methods are distinguished by their query strategy as either untargeted or targeted. Furthermore, we propose LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting under realistic deployment scenarios. Built upon 7 mainstream foundation models and comprising 149 distinct model instances, LeaFBench integrates 13 representative post-development techniques, spanning both parameter-altering methods (e.g., fine-tuning, quantization) and parameter-independent techniques (e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the strengths and weaknesses of existing methods, thereby outlining future research directions and critical open problems in this emerging field. The code is available at https://github.com/shaoshuo-ss/LeaFBench.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19843v3",
    "published_date": "2025-08-27 12:56:57 UTC",
    "updated_date": "2025-11-17 09:34:10 UTC"
  },
  {
    "arxiv_id": "2508.19839v1",
    "title": "PSO-Merging: Merging Models Based on Particle Swarm Optimization",
    "authors": [
      "Kehao Zhang",
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "abstract": "Model merging has emerged as an efficient strategy for constructing multitask models by integrating the strengths of multiple available expert models, thereby reducing the need to fine-tune a pre-trained model for all the tasks from scratch. Existing data-independent methods struggle with performance limitations due to the lack of data-driven guidance. Data-driven approaches also face key challenges: gradient-based methods are computationally expensive, limiting their practicality for merging large expert models, whereas existing gradient-free methods often fail to achieve satisfactory results within a limited number of optimization steps. To address these limitations, this paper introduces PSO-Merging, a novel data-driven merging method based on the Particle Swarm Optimization (PSO). In this approach, we initialize the particle swarm with a pre-trained model, expert models, and sparsified expert models. We then perform multiple iterations, with the final global best particle serving as the merged model. Experimental results on different language models show that PSO-Merging generally outperforms baseline merging methods, offering a more efficient and scalable solution for model merging.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19839v1",
    "published_date": "2025-08-27 12:52:36 UTC",
    "updated_date": "2025-08-27 12:52:36 UTC"
  },
  {
    "arxiv_id": "2509.03536v1",
    "title": "PG-Agent: An Agent Powered by Page Graph",
    "authors": [
      "Weizhi Chen",
      "Ziwei Wang",
      "Leyang Yang",
      "Sheng Zhou",
      "Xiaoxuan Tang",
      "Jiajun Bu",
      "Yong Li",
      "Wei Jiang"
    ],
    "abstract": "Graphical User Interface (GUI) agents possess significant commercial and social value, and GUI agents powered by advanced multimodal large language models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI agents usually utilize sequential episodes of multi-step operations across pages as the prior GUI knowledge, which fails to capture the complex transition relationship between pages, making it challenging for the agents to deeply perceive the GUI environment and generalize to new scenarios. Therefore, we design an automated pipeline to transform the sequential episodes into page graphs, which explicitly model the graph structure of the pages that are naturally connected by actions. To fully utilize the page graphs, we further introduce Retrieval-Augmented Generation (RAG) technology to effectively retrieve reliable perception guidelines of GUI from them, and a tailored multi-agent framework PG-Agent with task decomposition strategy is proposed to be injected with the guidelines so that it can generalize to unseen scenarios. Extensive experiments on various benchmarks demonstrate the effectiveness of PG-Agent, even with limited episodes for page graph construction.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper accepted to ACM MM 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.03536v1",
    "published_date": "2025-08-27 12:31:37 UTC",
    "updated_date": "2025-08-27 12:31:37 UTC"
  },
  {
    "arxiv_id": "2508.19830v1",
    "title": "Gradient Rectification for Robust Calibration under Distribution Shift",
    "authors": [
      "Yilin Zhang",
      "Cai Xu",
      "You Wu",
      "Ziyu Guan",
      "Wei Zhao"
    ],
    "abstract": "Deep neural networks often produce overconfident predictions, undermining their reliability in safety-critical applications. This miscalibration is further exacerbated under distribution shift, where test data deviates from the training distribution due to environmental or acquisition changes. While existing approaches improve calibration through training-time regularization or post-hoc adjustment, their reliance on access to or simulation of target domains limits their practicality in real-world scenarios. In this paper, we propose a novel calibration framework that operates without access to target domain information. From a frequency-domain perspective, we identify that distribution shifts often distort high-frequency visual cues exploited by deep models, and introduce a low-frequency filtering strategy to encourage reliance on domain-invariant features. However, such information loss may degrade In-Distribution (ID) calibration performance. Therefore, we further propose a gradient-based rectification mechanism that enforces ID calibration as a hard constraint during optimization. Experiments on synthetic and real-world shifted datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method significantly improves calibration under distribution shift while maintaining strong in-distribution performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, under review",
    "pdf_url": "https://arxiv.org/pdf/2508.19830v1",
    "published_date": "2025-08-27 12:28:26 UTC",
    "updated_date": "2025-08-27 12:28:26 UTC"
  },
  {
    "arxiv_id": "2509.00088v2",
    "title": "AEGIS : Automated Co-Evolutionary Framework for Guarding Prompt Injections Schema",
    "authors": [
      "Ting-Chun Liu",
      "Ching-Yu Hsu",
      "Kuan-Yi Lee",
      "Chi-An Fu",
      "Hung-yi Lee"
    ],
    "abstract": "Prompt injection attacks pose a significant challenge to the safe deployment of Large Language Models (LLMs) in real-world applications. While prompt-based detection offers a lightweight and interpretable defense strategy, its effectiveness has been hindered by the need for manual prompt engineering. To address this issue, we propose AEGIS , an Automated co-Evolutionary framework for Guarding prompt Injections Schema. Both attack and defense prompts are iteratively optimized against each other using a gradient-like natural language prompt optimization technique. This framework enables both attackers and defenders to autonomously evolve via a Textual Gradient Optimization (TGO) module, leveraging feedback from an LLM-guided evaluation loop. We evaluate our system on a real-world assignment grading dataset of prompt injection attacks and demonstrate that our method consistently outperforms existing baselines, achieving superior robustness in both attack success and detection. Specifically, the attack success rate (ASR) reaches 1.0, representing an improvement of 0.26 over the baseline. For detection, the true positive rate (TPR) improves by 0.23 compared to the previous best work, reaching 0.84, and the true negative rate (TNR) remains comparable at 0.89. Ablation studies confirm the importance of co-evolution, gradient buffering, and multi-objective optimization. We also confirm that this framework is effective in different LLMs. Our results highlight the promise of adversarial training as a scalable and effective approach for guarding prompt injections.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00088v2",
    "published_date": "2025-08-27 12:25:45 UTC",
    "updated_date": "2025-10-09 04:58:46 UTC"
  },
  {
    "arxiv_id": "2508.19827v1",
    "title": "Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?",
    "authors": [
      "Samuel Lewis-Lim",
      "Xingwei Tan",
      "Zhixue Zhao",
      "Nikolaos Aletras"
    ],
    "abstract": "Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited gains for soft-reasoning problems such as analytical and commonsense reasoning. CoT can also be unfaithful to a model's actual reasoning. We investigate the dynamics and faithfulness of CoT in soft-reasoning tasks across instruction-tuned, reasoning and reasoning-distilled models. Our findings reveal differences in how these models rely on CoT, and show that CoT influence and faithfulness are not always aligned.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at EMNLP 2025 Main Conference",
    "pdf_url": "https://arxiv.org/pdf/2508.19827v1",
    "published_date": "2025-08-27 12:25:29 UTC",
    "updated_date": "2025-08-27 12:25:29 UTC"
  },
  {
    "arxiv_id": "2508.19819v1",
    "title": "From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning",
    "authors": [
      "Viktor Valadi",
      "Mattias Åkesson",
      "Johan Östman",
      "Salman Toor",
      "Andreas Hellander"
    ],
    "abstract": "Gradient inversion attacks have garnered attention for their ability to compromise privacy in federated learning. However, many studies consider attacks with the model in inference mode, where training-time behaviors like dropout are disabled and batch normalization relies on fixed statistics. In this work, we systematically analyze how architecture and training behavior affect vulnerability, including the first in-depth study of inference-mode clients, which we show dramatically simplifies inversion. To assess attack feasibility under more realistic conditions, we turn to clients operating in standard training mode. In this setting, we find that successful attacks are only possible when several architectural conditions are met simultaneously: models must be shallow and wide, use skip connections, and, critically, employ pre-activation normalization. We introduce two novel attacks against models in training-mode with varying attacker knowledge, achieving state-of-the-art performance under realistic training conditions. We extend these efforts by presenting the first attack on a production-grade object-detection model. Here, to enable any visibly identifiable leakage, we revert to the lenient inference mode setting and make multiple architectural modifications to increase model vulnerability, with the extent of required changes highlighting the strong inherent robustness of such architectures. We conclude this work by offering the first comprehensive mapping of settings, clarifying which combinations of architectural choices and operational modes meaningfully impact privacy. Our analysis provides actionable insight into when models are likely vulnerable, when they appear robust, and where subtle leakage may persist. Together, these findings reframe how gradient inversion risk should be assessed in future research and deployment scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Under review at KDD 2026 (Research Track)",
    "pdf_url": "https://arxiv.org/pdf/2508.19819v1",
    "published_date": "2025-08-27 12:07:23 UTC",
    "updated_date": "2025-08-27 12:07:23 UTC"
  },
  {
    "arxiv_id": "2508.19815v1",
    "title": "ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images",
    "authors": [
      "Linkuan Zhou",
      "Zhexin Chen",
      "Yufei Shen",
      "Junlin Xu",
      "Ping Xuan",
      "Yixin Zhu",
      "Yuqi Fang",
      "Cong Cong",
      "Leyi Wei",
      "Ran Su",
      "Jia Zhou",
      "Qiangguo Jin"
    ],
    "abstract": "Automated segmentation of the fetal head in ultrasound images is critical for prenatal monitoring. However, achieving robust segmentation remains challenging due to the poor quality of ultrasound images and the lack of annotated data. Semi-supervised methods alleviate the lack of annotated data but struggle with the unique characteristics of fetal head ultrasound images, making it challenging to generate reliable pseudo-labels and enforce effective consistency regularization constraints. To address this issue, we propose a novel semi-supervised framework, ERSR, for fetal head ultrasound segmentation. Our framework consists of the dual-scoring adaptive filtering strategy, the ellipse-constrained pseudo-label refinement, and the symmetry-based multiple consistency regularization. The dual-scoring adaptive filtering strategy uses boundary consistency and contour regularity criteria to evaluate and filter teacher outputs. The ellipse-constrained pseudo-label refinement refines these filtered outputs by fitting least-squares ellipses, which strengthens pixels near the center of the fitted ellipse and suppresses noise simultaneously. The symmetry-based multiple consistency regularization enforces multi-level consistency across perturbed images, symmetric regions, and between original predictions and pseudo-labels, enabling the model to capture robust and stable shape representations. Our method achieves state-of-the-art performance on two benchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36% with 10% and 20% labeled data, respectively. On the PSFH dataset, the scores are 91.68% and 93.70% under the same settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19815v1",
    "published_date": "2025-08-27 12:01:57 UTC",
    "updated_date": "2025-08-27 12:01:57 UTC"
  },
  {
    "arxiv_id": "2508.19807v1",
    "title": "Bootstrapping Learned Cost Models with Synthetic SQL Queries",
    "authors": [
      "Michael Nidd",
      "Christoph Miksovic",
      "Thomas Gschwind",
      "Francesco Fusco",
      "Andrea Giovannini",
      "Ioana Giurgiu"
    ],
    "abstract": "Having access to realistic workloads for a given database instance is extremely important to enable stress and vulnerability testing, as well as to optimize for cost and performance. Recent advances in learned cost models have shown that when enough diverse SQL queries are available, one can effectively and efficiently predict the cost of running a given query against a specific database engine. In this paper, we describe our experience in exploiting modern synthetic data generation techniques, inspired by the generative AI and LLM community, to create high-quality datasets enabling the effective training of such learned cost models. Initial results show that we can improve a learned cost model's predictive accuracy by training it with 45% fewer queries than when using competitive generation approaches.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19807v1",
    "published_date": "2025-08-27 11:50:42 UTC",
    "updated_date": "2025-08-27 11:50:42 UTC"
  },
  {
    "arxiv_id": "2508.19804v1",
    "title": "A bag of tricks for real-time Mitotic Figure detection",
    "authors": [
      "Christian Marzahl",
      "Brian Napora"
    ],
    "abstract": "Mitotic figure (MF) detection in histopathology images is challenging due to large variations in slide scanners, staining protocols, tissue types, and the presence of artifacts. This paper presents a collection of training techniques - a bag of tricks - that enable robust, real-time MF detection across diverse domains. We build on the efficient RTMDet single stage object detector to achieve high inference speed suitable for clinical deployment. Our method addresses scanner variability and tumor heterogeneity via extensive multi-domain training data, balanced sampling, and careful augmentation. Additionally, we employ targeted, hard negative mining on necrotic and debris tissue to reduce false positives. In a grouped 5-fold cross-validation across multiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On the preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025 challenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81, outperforming larger models and demonstrating adaptability to new, unfamiliar domains. The proposed solution offers a practical trade-off between accuracy and speed, making it attractive for real-world clinical adoption.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19804v1",
    "published_date": "2025-08-27 11:45:44 UTC",
    "updated_date": "2025-08-27 11:45:44 UTC"
  },
  {
    "arxiv_id": "2509.03535v1",
    "title": "QuesGenie: Intelligent Multimodal Question Generation",
    "authors": [
      "Ahmed Mubarak",
      "Amna Ahmed",
      "Amira Nasser",
      "Aya Mohamed",
      "Fares El-Sadek",
      "Mohammed Ahmed",
      "Ahmed Salah",
      "Youssef Sobhy"
    ],
    "abstract": "In today's information-rich era, learners have access to abundant educational resources, but the lack of practice materials tailored to these resources presents a significant challenge. This project addresses that gap by developing a multi-modal question generation system that can automatically generate diverse question types from various content formats. The system features four major components: multi-modal input handling, question generation, reinforcement learning from human feedback (RLHF), and an end-to-end interactive interface. This project lays the foundation for automated, scalable, and intelligent question generation, carefully balancing resource efficiency, robust functionality and a smooth user experience.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 8 figures, 12 tables. Supervised by Dr. Ahmed Salah and TA Youssef Sobhy",
    "pdf_url": "https://arxiv.org/pdf/2509.03535v1",
    "published_date": "2025-08-27 10:45:39 UTC",
    "updated_date": "2025-08-27 10:45:39 UTC"
  },
  {
    "arxiv_id": "2509.00087v1",
    "title": "Yet Unnoticed in LSTM: Binary Tree Based Input Reordering, Weight Regularization, and Gate Nonlinearization",
    "authors": [
      "Mojtaba Moattari"
    ],
    "abstract": "LSTM models used in current Machine Learning literature and applications, has a promising solution for permitting long term information using gating mechanisms that forget and reduce effect of current input information. However, even with this pipeline, they do not optimally focus on specific old index or long-term information. This paper elaborates upon input reordering approaches to prioritize certain input indices. Moreover, no LSTM based approach is found in the literature that examines weight normalization while choosing the right weight and exponent of Lp norms through main supervised loss function. In this paper, we find out which norm best finds relationship between weights to either smooth or sparsify them. Lastly, gates, as weighted representations of inputs and states, which control reduction-extent of current input versus previous inputs (~ state), are not nonlinearized enough (through a small FFNN). As analogous to attention mechanisms, gates easily filter current information to bold (emphasize on) past inputs. Nonlinearized gates can more easily tune up to peculiar nonlinearities of specific input in the past. This type of nonlinearization is not proposed in the literature, to the best of author's knowledge. The proposed approaches are implemented and compared with a simple LSTM to understand their performance in text classification tasks. The results show they improve accuracy of LSTM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00087v1",
    "published_date": "2025-08-27 10:40:02 UTC",
    "updated_date": "2025-08-27 10:40:02 UTC"
  },
  {
    "arxiv_id": "2509.02581v1",
    "title": "Charting the Future of Scholarly Knowledge with AI: A Community Perspective",
    "authors": [
      "Azanzi Jiomekong",
      "Hande Küçük McGinty",
      "Keith G. Mills",
      "Allard Oelen",
      "Enayat Rajabi",
      "Harry McElroy",
      "Antrea Christou",
      "Anmol Saini",
      "Janice Anta Zebaze",
      "Hannah Kim",
      "Anna M. Jacyszyn",
      "Sören Auer"
    ],
    "abstract": "Despite the growing availability of tools designed to support scholarly knowledge extraction and organization, many researchers still rely on manual methods, sometimes due to unfamiliarity with existing technologies or limited access to domain-adapted solutions. Meanwhile, the rapid increase in scholarly publications across disciplines has made it increasingly difficult to stay current, further underscoring the need for scalable, AI-enabled approaches to structuring and synthesizing scholarly knowledge. Various research communities have begun addressing this challenge independently, developing tools and frameworks aimed at building reliable, dynamic, and queryable scholarly knowledge bases. However, limited interaction across these communities has hindered the exchange of methods, models, and best practices, slowing progress toward more integrated solutions. This manuscript identifies ways to foster cross-disciplinary dialogue, identify shared challenges, categorize new collaboration and shape future research directions in scholarly knowledge and organization.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "39 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.02581v1",
    "published_date": "2025-08-27 09:46:50 UTC",
    "updated_date": "2025-08-27 09:46:50 UTC"
  },
  {
    "arxiv_id": "2508.19724v2",
    "title": "NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks",
    "authors": [
      "Aritra Dutta",
      "Swapnanil Mukherjee",
      "Deepanway Ghosal",
      "Somak Aditya"
    ],
    "abstract": "Commonsense visual-question answering often hinges on knowledge that is missing from the image or the question. Small vision-language models (sVLMs) such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative counterparts. To study the effect of careful commonsense knowledge integration on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural language facts, (ii) prompts an LLM to craft natural language explanations, and (iii) feeds both signals to sVLMs respectively across two commonsense VQA datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts retrieved using a fine-tuned ColBERTv2 and an object information-enriched prompt yield explanations that largely cut down hallucinations, while lifting the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional finetuning using noise-robust losses (such as symmetric cross entropy and generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our findings expose when LLM-based commonsense knowledge beats retrieval from commonsense knowledge bases, how noise-aware training stabilises small models in the context of external knowledge augmentation, and why parameter-efficient commonsense reasoning is now within reach for 250M models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19724v2",
    "published_date": "2025-08-27 09:34:28 UTC",
    "updated_date": "2025-08-28 12:05:33 UTC"
  },
  {
    "arxiv_id": "2508.20144v3",
    "title": "Navigating the EU AI Act: Foreseeable Challenges in Qualifying Deep Learning-Based Automated Inspections of Class III Medical Devices",
    "authors": [
      "Julio Zanon Diaz",
      "Tommy Brennan",
      "Peter Corcoran"
    ],
    "abstract": "As deep learning (DL) technologies advance, their application in automated visual inspection for Class III medical devices offers significant potential to enhance quality assurance and reduce human error. However, the adoption of such AI-based systems introduces new regulatory complexities-particularly under the EU Artificial Intelligence (AI) Act, which imposes high-risk system obligations that differ in scope and depth from established regulatory frameworks such as the Medical Device Regulation (MDR) and the U.S. FDA Quality System Regulation (QSR). This paper presents a high-level technical assessment of the foreseeable challenges that manufacturers are likely to encounter when qualifying DL-based automated inspections -- specifically static models -- within the existing medical device compliance landscape. It examines divergences in risk management principles, dataset governance, model validation, explainability requirements, and post-deployment monitoring obligations. The discussion also explores potential implementation strategies and highlights areas of uncertainty, including data retention burdens, global compliance implications, and the practical difficulties of achieving statistical significance in validation with limited defect data. Disclaimer: This paper presents a technical perspective and does not constitute legal or regulatory advice.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Critical Review article",
    "pdf_url": "https://arxiv.org/pdf/2508.20144v3",
    "published_date": "2025-08-27 09:17:03 UTC",
    "updated_date": "2025-10-07 12:50:57 UTC"
  },
  {
    "arxiv_id": "2508.19708v1",
    "title": "Attention is also needed for form design",
    "authors": [
      "B. Sankar",
      "Dibakar Sen"
    ],
    "abstract": "Conventional product design is a cognitively demanding process, limited by its time-consuming nature, reliance on subjective expertise, and the opaque translation of inspiration into tangible concepts. This research introduces a novel, attention-aware framework that integrates two synergistic systems: EUPHORIA, an immersive Virtual Reality environment using eye-tracking to implicitly capture a designer's aesthetic preferences, and RETINA, an agentic AI pipeline that translates these implicit preferences into concrete design outputs. The foundational principles were validated in a two-part study. An initial study correlated user's implicit attention with explicit preference and the next one correlated mood to attention. A comparative study where 4 designers solved challenging design problems using 4 distinct workflows, from a manual process to an end-to-end automated pipeline, showed the integrated EUPHORIA-RETINA workflow was over 4 times more time-efficient than the conventional method. A panel of 50 design experts evaluated the 16 final renderings. Designs generated by the fully automated system consistently received the highest Worthiness (calculated by an inverse Plackett-Luce model based on gradient descent optimization) and Design Effectiveness scores, indicating superior quality across 8 criteria: novelty, visual appeal, emotional resonance, clarity of purpose, distinctiveness of silhouette, implied materiality, proportional balance, & adherence to the brief. This research presents a validated paradigm shift from traditional Computer-Assisted Design (CAD) to a collaborative model of Designer-Assisting Computers (DAC). By automating logistical and skill-dependent generative tasks, the proposed framework elevates the designer's role to that of a creative director, synergizing human intuition with the generative power of agentic AI to produce higher-quality designs more efficiently.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "55 pages, 45 figures,",
    "pdf_url": "https://arxiv.org/pdf/2508.19708v1",
    "published_date": "2025-08-27 09:15:21 UTC",
    "updated_date": "2025-08-27 09:15:21 UTC"
  },
  {
    "arxiv_id": "2508.19697v1",
    "title": "Safety Alignment Should Be Made More Than Just A Few Attention Heads",
    "authors": [
      "Chao Huang",
      "Zefeng Zhang",
      "Juewei Yue",
      "Quangang Li",
      "Chuang Zhang",
      "Tingwen Liu"
    ],
    "abstract": "Current safety alignment for large language models(LLMs) continues to present vulnerabilities, given that adversarial prompting can effectively bypass their safety measures.Our investigation shows that these safety mechanisms predominantly depend on a limited subset of attention heads: removing or ablating these heads can severely compromise model safety. To identify and evaluate these safety-critical components, we introduce RDSHA, a targeted ablation method that leverages the model's refusal direction to pinpoint attention heads mostly responsible for safety behaviors. Further analysis shows that existing jailbreak attacks exploit this concentration by selectively bypassing or manipulating these critical attention heads. To address this issue, we propose AHD, a novel training strategy designed to promote the distributed encoding of safety-related behaviors across numerous attention heads. Experimental results demonstrate that AHD successfully distributes safety-related capabilities across more attention heads. Moreover, evaluations under several mainstream jailbreak attacks show that models trained with AHD exhibit considerably stronger safety robustness, while maintaining overall functional utility.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19697v1",
    "published_date": "2025-08-27 09:06:28 UTC",
    "updated_date": "2025-08-27 09:06:28 UTC"
  },
  {
    "arxiv_id": "2508.19683v1",
    "title": "Topological Uncertainty for Anomaly Detection in the Neural-network EoS Inference with Neutron Star Data",
    "authors": [
      "Kenji Fukushima",
      "Syo Kamata"
    ],
    "abstract": "We study the performance of the Topological Uncertainty (TU) constructed with a trained feedforward neural network (FNN) for Anomaly Detection. Generally, meaningful information can be stored in the hidden layers of the trained FNN, and the TU implementation is one tractable recipe to extract buried information by means of the Topological Data Analysis. We explicate the concept of the TU and the numerical procedures. Then, for a concrete demonstration of the performance test, we employ the Neutron Star data used for inference of the equation of state (EoS). For the training dataset consisting of the input (Neutron Star data) and the output (EoS parameters), we can compare the inferred EoSs and the exact answers to classify the data with the label $k$. The subdataset with $k=0$ leads to the normal inference for which the inferred EoS approximates the answer well, while the subdataset with $k=1$ ends up with the unsuccessful inference. Once the TU is prepared based on the $k$-labled subdatasets, we introduce the cross-TU to quantify the uncertainty of characterizing the $k$-labeled data with the label $j$. The anomaly or unsuccessful inference is correctly detected if the cross-TU for $j=k=1$ is smaller than that for $j=0$ and $k=1$. In our numerical experiment, for various input data, we calculate the cross-TU and estimate the performance of Anomaly Detection. We find that performance depends on FNN hyperparameters, and the success rate of Anomaly Detection exceeds $90\\%$ in the best case. We finally discuss further potential of the TU application to retrieve the information hidden in the trained FNN.",
    "categories": [
      "nucl-th",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "nucl-th",
    "comment": "23 pages, 7 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.19683v1",
    "published_date": "2025-08-27 08:44:56 UTC",
    "updated_date": "2025-08-27 08:44:56 UTC"
  },
  {
    "arxiv_id": "2508.19679v1",
    "title": "InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning",
    "authors": [
      "Qihang Ai",
      "Pi Bu",
      "Yue Cao",
      "Yingyao Wang",
      "Jihao Gu",
      "Jingxuan Xing",
      "Zekun Zhu",
      "Wei Jiang",
      "Zhicheng Zheng",
      "Jun Song",
      "Yuning Jiang",
      "Bo Zheng"
    ],
    "abstract": "Recent advances in Vision-Language Models (VLMs) have enabled mobile agents to perceive and interact with real-world mobile environments based on human instructions. However, the current fully autonomous paradigm poses potential safety risks when model understanding or reasoning capabilities are insufficient. To address this challenge, we first introduce \\textbf{InquireBench}, a comprehensive benchmark specifically designed to evaluate mobile agents' capabilities in safe interaction and proactive inquiry with users, encompassing 5 categories and 22 sub-categories, where most existing VLM-based agents demonstrate near-zero performance. In this paper, we aim to develop an interactive system that actively seeks human confirmation at critical decision points. To achieve this, we propose \\textbf{InquireMobile}, a novel model inspired by reinforcement learning, featuring a two-stage training strategy and an interactive pre-action reasoning mechanism. Finally, our model achieves an 46.8% improvement in inquiry success rate and the best overall success rate among existing baselines on InquireBench. We will open-source all datasets, models, and evaluation codes to facilitate development in both academia and industry.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19679v1",
    "published_date": "2025-08-27 08:40:05 UTC",
    "updated_date": "2025-08-27 08:40:05 UTC"
  },
  {
    "arxiv_id": "2508.19667v1",
    "title": "Survey of Specialized Large Language Model",
    "authors": [
      "Chenghan Yang",
      "Ruiyu Zhao",
      "Yang Liu",
      "Ling Jiang"
    ],
    "abstract": "The rapid evolution of specialized large language models (LLMs) has transitioned from simple domain adaptation to sophisticated native architectures, marking a paradigm shift in AI development. This survey systematically examines this progression across healthcare, finance, legal, and technical domains. Besides the wide use of specialized LLMs, technical breakthrough such as the emergence of domain-native designs beyond fine-tuning, growing emphasis on parameter efficiency through sparse computation and quantization, increasing integration of multimodal capabilities and so on are applied to recent LLM agent. Our analysis reveals how these innovations address fundamental limitations of general-purpose LLMs in professional applications, with specialized models consistently performance gains on domain-specific benchmarks. The survey further highlights the implications for E-Commerce field to fill gaps in the field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 1 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19667v1",
    "published_date": "2025-08-27 08:27:23 UTC",
    "updated_date": "2025-08-27 08:27:23 UTC"
  },
  {
    "arxiv_id": "2508.19660v3",
    "title": "Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation",
    "authors": [
      "Vojtech Mrazek",
      "Konstantinos Balaskas",
      "Paula Carolina Lozano Duarte",
      "Zdenek Vasicek",
      "Mehdi B. Tahoori",
      "Georgios Zervakis"
    ],
    "abstract": "Printed electronics offer a promising alternative for applications beyond silicon-based systems, requiring properties like flexibility, stretchability, conformality, and ultra-low fabrication costs. Despite the large feature sizes in printed electronics, printed neural networks have attracted attention for meeting target application requirements, though realizing complex circuits remains challenging. This work bridges the gap between classification accuracy and area efficiency in printed neural networks, covering the entire processing-near-sensor system design and co-optimization from the analog-to-digital interface-a major area and power bottleneck-to the digital classifier. We propose an automated framework for designing printed Ternary Neural Networks with arbitrary input precision, utilizing multi-objective optimization and holistic approximation. Our circuits outperform existing approximate printed neural networks by 17x in area and 59x in power on average, being the first to enable printed-battery-powered operation with under 5% accuracy loss while accounting for analog-to-digital interfacing costs.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted for publication at IEEE Transactions on Circuits and Systems for Artificial Intelligence (TCASAI)",
    "pdf_url": "https://arxiv.org/pdf/2508.19660v3",
    "published_date": "2025-08-27 08:19:22 UTC",
    "updated_date": "2025-09-03 07:30:53 UTC"
  },
  {
    "arxiv_id": "2508.19641v1",
    "title": "Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses",
    "authors": [
      "Lincan Li",
      "Bolin Shen",
      "Chenxi Zhao",
      "Yuxiang Sun",
      "Kaixiang Zhao",
      "Shirui Pan",
      "Yushun Dong"
    ],
    "abstract": "Graph-structured data, which captures non-Euclidean relationships and interactions between entities, is growing in scale and complexity. As a result, training state-of-the-art graph machine learning (GML) models have become increasingly resource-intensive, turning these models and data into invaluable Intellectual Property (IP). To address the resource-intensive nature of model training, graph-based Machine-Learning-as-a-Service (GMLaaS) has emerged as an efficient solution by leveraging third-party cloud services for model development and management. However, deploying such models in GMLaaS also exposes them to potential threats from attackers. Specifically, while the APIs within a GMLaaS system provide interfaces for users to query the model and receive outputs, they also allow attackers to exploit and steal model functionalities or sensitive training data, posing severe threats to the safety of these GML models and the underlying graph data. To address these challenges, this survey systematically introduces the first taxonomy of threats and defenses at the level of both GML model and graph-structured data. Such a tailored taxonomy facilitates an in-depth understanding of GML IP protection. Furthermore, we present a systematic evaluation framework to assess the effectiveness of IP protection methods, introduce a curated set of benchmark datasets across various domains, and discuss their application scopes and future challenges. Finally, we establish an open-sourced versatile library named PyGIP, which evaluates various attack and defense techniques in GMLaaS scenarios and facilitates the implementation of existing benchmark methods. The library resource can be accessed at: https://labrai.github.io/PyGIP. We believe this survey will play a fundamental role in intellectual property protection for GML and provide practical recipes for the GML community.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19641v1",
    "published_date": "2025-08-27 07:37:52 UTC",
    "updated_date": "2025-08-27 07:37:52 UTC"
  },
  {
    "arxiv_id": "2508.19638v1",
    "title": "Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception",
    "authors": [
      "Yang Li",
      "Quan Yuan",
      "Guiyang Luo",
      "Xiaoyuan Fu",
      "Rui Pan",
      "Yujia Yang",
      "Congzhang Shao",
      "Yuewen Liu",
      "Jinglin Li"
    ],
    "abstract": "Collaborative perception allows agents to enhance their perceptual capabilities by exchanging intermediate features. Existing methods typically organize these intermediate features as 2D bird's-eye-view (BEV) representations, which discard critical fine-grained 3D structural cues essential for accurate object recognition and localization. To this end, we first introduce point-level tokens as intermediate representations for collaborative perception. However, point-cloud data are inherently unordered, massive, and position-sensitive, making it challenging to produce compact and aligned point-level token sequences that preserve detailed structural information. Therefore, we present CoPLOT, a novel Collaborative perception framework that utilizes Point-Level Optimized Tokens. It incorporates a point-native processing pipeline, including token reordering, sequence modeling, and multi-agent spatial alignment. A semantic-aware token reordering module generates adaptive 1D reorderings by leveraging scene-level and token-level semantic information. A frequency-enhanced state space model captures long-range sequence dependencies across both spatial and spectral domains, improving the differentiation between foreground tokens and background clutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop process, combining global agent-level correction with local token-level refinement to mitigate localization noise. Extensive experiments on both simulated and real-world datasets show that CoPLOT outperforms state-of-the-art models, with even lower communication and computation overhead. Code will be available at https://github.com/CheeryLeeyy/CoPLOT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19638v1",
    "published_date": "2025-08-27 07:27:42 UTC",
    "updated_date": "2025-08-27 07:27:42 UTC"
  },
  {
    "arxiv_id": "2508.19637v2",
    "title": "Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge",
    "authors": [
      "Maha Shatta",
      "Konstantinos Balaskas",
      "Paula Carolina Lozano Duarte",
      "Georgios Panagopoulos",
      "Mehdi B. Tahoori",
      "Georgios Zervakis"
    ],
    "abstract": "Flexible Electronics (FE) offer a promising alternative to rigid silicon-based hardware for wearable healthcare devices, enabling lightweight, conformable, and low-cost systems. However, their limited integration density and large feature sizes impose strict area and power constraints, making ML-based healthcare systems-integrating analog frontend, feature extraction and classifier-particularly challenging. Existing FE solutions often neglect potential system-wide solutions and focus on the classifier, overlooking the substantial hardware cost of feature extraction and Analog-to-Digital Converters (ADCs)-both major contributors to area and power consumption. In this work, we present a holistic mixed-signal feature-to-classifier co-design framework for flexible smart wearable systems. To the best of our knowledge, we design the first analog feature extractors in FE, significantly reducing feature extraction cost. We further propose an hardware-aware NAS-inspired feature selection strategy within ML training, enabling efficient, application-specific designs. Our evaluation on healthcare benchmarks shows our approach delivers highly accurate, ultra-area-efficient flexible systems-ideal for disposable, low-power wearable monitoring.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted for publication at 2025 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), Oct. 26-30 2025, Munich, DE",
    "pdf_url": "https://arxiv.org/pdf/2508.19637v2",
    "published_date": "2025-08-27 07:26:11 UTC",
    "updated_date": "2025-08-29 13:09:45 UTC"
  },
  {
    "arxiv_id": "2508.19630v1",
    "title": "Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition",
    "authors": [
      "Xiaolei Wei",
      "Yi Ouyang",
      "Haibo Ye"
    ],
    "abstract": "Long-tailed visual recognition is challenging not only due to class imbalance but also because of varying classification difficulty across categories. Simply reweighting classes by frequency often overlooks those that are intrinsically hard to learn. To address this, we propose \\textbf{DQRoute}, a modular framework that combines difficulty-aware optimization with dynamic expert collaboration. DQRoute first estimates class-wise difficulty based on prediction uncertainty and historical performance, and uses this signal to guide training with adaptive loss weighting. On the architectural side, DQRoute employs a mixture-of-experts design, where each expert specializes in a different region of the class distribution. At inference time, expert predictions are weighted by confidence scores derived from expert-specific OOD detectors, enabling input-adaptive routing without the need for a centralized router. All components are trained jointly in an end-to-end manner. Experiments on standard long-tailed benchmarks demonstrate that DQRoute significantly improves performance, particularly on rare and difficult classes, highlighting the benefit of integrating difficulty modeling with decentralized expert routing.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted to PRCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.19630v1",
    "published_date": "2025-08-27 07:09:00 UTC",
    "updated_date": "2025-08-27 07:09:00 UTC"
  },
  {
    "arxiv_id": "2509.00085v1",
    "title": "Private, Verifiable, and Auditable AI Systems",
    "authors": [
      "Tobin South"
    ],
    "abstract": "The growing societal reliance on artificial intelligence necessitates robust frameworks for ensuring its security, accountability, and trustworthiness. This thesis addresses the complex interplay between privacy, verifiability, and auditability in modern AI, particularly in foundation models. It argues that technical solutions that integrate these elements are critical for responsible AI innovation. Drawing from international policy contributions and technical research to identify key risks in the AI pipeline, this work introduces novel technical solutions for critical privacy and verifiability challenges. Specifically, the research introduces techniques for enabling verifiable and auditable claims about AI systems using zero-knowledge cryptography; utilizing secure multi-party computation and trusted execution environments for auditable, confidential deployment of large language models and information retrieval; and implementing enhanced delegation mechanisms, credentialing systems, and access controls to secure interactions with autonomous and multi-agent AI systems. Synthesizing these technical advancements, this dissertation presents a cohesive perspective on balancing privacy, verifiability, and auditability in foundation model-based AI systems, offering practical blueprints for system designers and informing policy discussions on AI safety and governance.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "PhD thesis",
    "pdf_url": "https://arxiv.org/pdf/2509.00085v1",
    "published_date": "2025-08-27 07:08:44 UTC",
    "updated_date": "2025-08-27 07:08:44 UTC"
  },
  {
    "arxiv_id": "2508.19625v2",
    "title": "Training for Obsolescence? The AI-Driven Education Trap",
    "authors": [
      "Andrew J. Peterson"
    ],
    "abstract": "Artificial intelligence is simultaneously transforming the production function of human capital in schools and the return to skills in the labor market. We develop a theoretical model to analyze the potential for misallocation when these two forces are considered in isolation. We study an educational planner who observes AI's immediate productivity benefits in teaching specific skills but fails to fully internalize the technology's future wage-suppressing effects on those same skills. Motivated by a pre-registered pilot study suggesting a positive correlation between a skill's \"teachability\" by AI and its vulnerability to automation, we show that this information friction leads to a systematic skill mismatch. The planner over-invests in skills destined for obsolescence, a distortion that increases monotonically with AI prevalence. Extensions demonstrate that this mismatch is exacerbated by the neglect of unpriced non-cognitive skills and by the endogenous over-adoption of educational technology. Our findings caution that policies promoting AI in education, if not paired with forward-looking labor market signals, may paradoxically undermine students' long-term human capital, such as by crowding out skills like persistence that are forged through intellectual struggle.",
    "categories": [
      "econ.GN",
      "cs.AI"
    ],
    "primary_category": "econ.GN",
    "comment": "Under review",
    "pdf_url": "https://arxiv.org/pdf/2508.19625v2",
    "published_date": "2025-08-27 07:04:19 UTC",
    "updated_date": "2025-11-28 16:59:45 UTC"
  },
  {
    "arxiv_id": "2508.19621v1",
    "title": "Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning",
    "authors": [
      "Tiandi Ye",
      "Wenyan Liu",
      "Kai Yao",
      "Lichun Li",
      "Shangchao Su",
      "Cen Chen",
      "Xiang Li",
      "Shan Yin",
      "Ming Gao"
    ],
    "abstract": "Federated learning (FL) is a privacy-preserving machine learning paradigm that enables collaborative model training across multiple distributed clients without disclosing their raw data. Personalized federated learning (pFL) has gained increasing attention for its ability to address data heterogeneity. However, most existing pFL methods assume that each client's data follows a single distribution and learn one client-level personalized model for each client. This assumption often fails in practice, where a single client may possess data from multiple sources or domains, resulting in significant intra-client heterogeneity and suboptimal performance. To tackle this challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework based on visual prompt tuning. Specifically, we formulate instance-wise prompt generation from a Bayesian perspective and model the prompt posterior as an implicit distribution to capture diverse visual semantics. We derive a variational training objective under the semi-implicit variational inference framework. Extensive experiments on benchmark datasets demonstrate that pFedBayesPT consistently outperforms existing pFL methods under both feature and label heterogeneity settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CIKM2025",
    "pdf_url": "https://arxiv.org/pdf/2508.19621v1",
    "published_date": "2025-08-27 06:59:10 UTC",
    "updated_date": "2025-08-27 06:59:10 UTC"
  },
  {
    "arxiv_id": "2508.19620v1",
    "title": "A Scenario-Oriented Survey of Federated Recommender Systems: Techniques, Challenges, and Future Directions",
    "authors": [
      "Yunqi Mi",
      "Jiakui Shen",
      "Guoshuai Zhao",
      "Jialie Shen",
      "Xueming Qian"
    ],
    "abstract": "Extending recommender systems to federated learning (FL) frameworks to protect the privacy of users or platforms while making recommendations has recently gained widespread attention in academia. This is due to the natural coupling of recommender systems and federated learning architectures: the data originates from distributed clients (mostly mobile devices held by users), which are highly related to privacy. In a centralized recommender system (CenRec), the central server collects clients' data, trains the model, and provides the service. Whereas in federated recommender systems (FedRec), the step of data collecting is omitted, and the step of model training is offloaded to each client. The server only aggregates the model and other knowledge, thus avoiding client privacy leakage. Some surveys of federated recommender systems discuss and analyze related work from the perspective of designing FL systems. However, their utility drops by ignoring specific recommendation scenarios' unique characteristics and practical challenges. For example, the statistical heterogeneity issue in cross-domain FedRec originates from the label drift of the data held by different platforms, which is mainly caused by the recommender itself, but not the federated architecture. Therefore, it should focus more on solving specific problems in real-world recommendation scenarios to encourage the deployment FedRec. To this end, this review comprehensively analyzes the coupling of recommender systems and federated learning from the perspective of recommendation researchers and practitioners. We establish a clear link between recommendation scenarios and FL frameworks, systematically analyzing scenario-specific approaches, practical challenges, and potential opportunities. We aim to develop guidance for the real-world deployment of FedRec, bridging the gap between existing research and applications.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19620v1",
    "published_date": "2025-08-27 06:57:50 UTC",
    "updated_date": "2025-08-27 06:57:50 UTC"
  },
  {
    "arxiv_id": "2509.00084v1",
    "title": "Learning to Refine: Self-Refinement of Parallel Reasoning in LLMs",
    "authors": [
      "Qibin Wang",
      "Pu Zhao",
      "Shaohan Huang",
      "Fangkai Yang",
      "Lu Wang",
      "Furu Wei",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang"
    ],
    "abstract": "To further enhance the ability of Large Language Models (LLMs) to solve complex, multi-step reasoning problems, test-time scaling (TTS) methods have gained widespread attention. Existing approaches such as Best-of-N and majority voting are limited as their performance depends on the quality of candidate responses, making them unable to produce a correct solution when all candidates are incorrect. Introducing an additional model to select the best response also incurs significant deployment costs. To this end, we introduce Generative Self-Refinement (GSR), a novel parallel test-time scaling framework where a unified model first generates a set of candidate responses in parallel and then performs self-refinement to synthesize a new superior solution based on a prompt consisting of the problem and these candidates. However, LLMs struggle to perform refinement effectively when prompted directly. Therefore, we design a hybrid training pipeline by jointly optimizing for two complementary objectives, solving problems directly and refining candidate responses. Experimental results demonstrate that our method achieves state-of-the-art performance across five mathematical benchmarks. We further show that this learned self-refinement skill is a model-agnostic enhancement, robust across different model scales and generalizing to out-of-distribution reasoning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00084v1",
    "published_date": "2025-08-27 06:51:48 UTC",
    "updated_date": "2025-08-27 06:51:48 UTC"
  },
  {
    "arxiv_id": "2508.19614v3",
    "title": "LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation",
    "authors": [
      "Yang Sun",
      "Zhiyong Xie",
      "Lixin Zou",
      "Dan Luo",
      "Min Tang",
      "Xiangyu Zhao",
      "Yunwei Zhao",
      "Xixun Lin",
      "Yanxiong Lu",
      "Chenliang Li"
    ],
    "abstract": "Retrieval-augmented generation (RAG) incorporates external knowledge into large language models (LLMs), improving their adaptability to downstream tasks and enabling information updates. Surprisingly, recent empirical evidence demonstrates that injecting noise into retrieved relevant documents paradoxically facilitates exploitation of external knowledge and improves generation quality. Although counterintuitive and challenging to apply in practice, this phenomenon enables granular control and rigorous analysis of how LLMs integrate external knowledge. Therefore, in this paper, we intervene on noise injection and establish a layer-specific functional demarcation within the LLM: shallow layers specialize in local context modeling, intermediate layers focus on integrating long-range external factual knowledge, and deeper layers primarily rely on parametric internal knowledge. Building on this insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that directly combines representations from an intermediate layer with final-layer decoding outputs to fully exploit the external factual knowledge. To identify the optimal intermediate layer, we introduce an internal knowledge score (IKS) criterion that selects the layer with the lowest IKS value in the latter half of layers. Experimental results across multiple benchmarks demonstrate that LFD helps RAG systems more effectively surface retrieved context knowledge with minimal cost.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19614v3",
    "published_date": "2025-08-27 06:48:46 UTC",
    "updated_date": "2026-01-07 07:25:26 UTC"
  },
  {
    "arxiv_id": "2508.19611v2",
    "title": "Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties",
    "authors": [
      "Huaiyuan Yao",
      "Wanpeng Xu",
      "Justin Turnau",
      "Nadia Kellam",
      "Hua Wei"
    ],
    "abstract": "Preparing high-quality instructional materials remains a labor-intensive process that often requires extensive coordination among teaching faculty, instructional designers, and teaching assistants. In this work, we present Instructional Agents, a multi-agent large language model (LLM) framework designed to automate end-to-end course material generation, including syllabus creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing AI-assisted educational tools that focus on isolated tasks, Instructional Agents simulates role-based collaboration among educational agents to produce cohesive and pedagogically aligned content. The system operates in four modes: Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling flexible control over the degree of human involvement. We evaluate Instructional Agents across five university-level computer science courses and show that it produces high-quality instructional materials while significantly reducing development time and human workload. By supporting institutions with limited instructional design capacity, Instructional Agents provides a scalable and cost-effective framework to democratize access to high-quality education, particularly in underserved or resource-constrained settings.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19611v2",
    "published_date": "2025-08-27 06:45:06 UTC",
    "updated_date": "2025-09-01 01:38:20 UTC"
  },
  {
    "arxiv_id": "2508.19609v1",
    "title": "FinCast: A Foundation Model for Financial Time-Series Forecasting",
    "authors": [
      "Zhuohang Zhu",
      "Haodong Chen",
      "Qiang Qu",
      "Vera Chung"
    ],
    "abstract": "Financial time-series forecasting is critical for maintaining economic stability, guiding informed policymaking, and promoting sustainable investment practices. However, it remains challenging due to various underlying pattern shifts. These shifts arise primarily from three sources: temporal non-stationarity (distribution changes over time), multi-domain diversity (distinct patterns across financial domains such as stocks, commodities, and futures), and varying temporal resolutions (patterns differing across per-second, hourly, daily, or weekly indicators). While recent deep learning methods attempt to address these complexities, they frequently suffer from overfitting and typically require extensive domain-specific fine-tuning. To overcome these limitations, we introduce FinCast, the first foundation model specifically designed for financial time-series forecasting, trained on large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot performance, effectively capturing diverse patterns without domain-specific fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate that FinCast surpasses existing state-of-the-art methods, highlighting its strong generalization capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.CP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19609v1",
    "published_date": "2025-08-27 06:44:46 UTC",
    "updated_date": "2025-08-27 06:44:46 UTC"
  },
  {
    "arxiv_id": "2508.19604v1",
    "title": "IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation",
    "authors": [
      "Qizhe Fan",
      "Chaoyu Liu",
      "Zhonghua Qiao",
      "Xiaoqin Shen"
    ],
    "abstract": "Domain Generalized Semantic Segmentation (DGSS) focuses on training a model using labeled data from a source domain, with the goal of achieving robust generalization to unseen target domains during inference. A common approach to improve generalization is to augment the source domain with synthetic data generated by diffusion models (DMs). However, the generated images often contain structural or semantic defects due to training imperfections. Training segmentation models with such flawed data can lead to performance degradation and error accumulation. To address this issue, we propose to integrate inverse evolution layers (IELs) into the generative process. IELs are designed to highlight spatial discontinuities and semantic inconsistencies using Laplacian-based priors, enabling more effective filtering of undesirable generative patterns. Based on this mechanism, we introduce IELDM, an enhanced diffusion-based data augmentation framework that can produce higher-quality images. Furthermore, we observe that the defect-suppression capability of IELs can also benefit the segmentation network by suppressing artifact propagation. Based on this insight, we embed IELs into the decoder of the DGSS model and propose IELFormer to strengthen generalization capability in cross-domain scenarios. To further strengthen the model's semantic consistency across scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module, which performs frequency-domain analysis to achieve structured integration of multi-resolution features, thereby improving cross-scale coherence. Extensive experiments on benchmark datasets demonstrate that our approach achieves superior generalization performance compared to existing methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19604v1",
    "published_date": "2025-08-27 06:37:16 UTC",
    "updated_date": "2025-08-27 06:37:16 UTC"
  },
  {
    "arxiv_id": "2508.19603v1",
    "title": "CompLex: Music Theory Lexicon Constructed by Autonomous Agents for Automatic Music Generation",
    "authors": [
      "Zhejing Hu",
      "Yan Liu",
      "Gong Chen",
      "Bruce X. B. Yu"
    ],
    "abstract": "Generative artificial intelligence in music has made significant strides, yet it still falls short of the substantial achievements seen in natural language processing, primarily due to the limited availability of music data. Knowledge-informed approaches have been shown to enhance the performance of music generation models, even when only a few pieces of musical knowledge are integrated. This paper seeks to leverage comprehensive music theory in AI-driven music generation tasks, such as algorithmic composition and style transfer, which traditionally require significant manual effort with existing techniques. We introduce a novel automatic music lexicon construction model that generates a lexicon, named CompLex, comprising 37,432 items derived from just 9 manually input category keywords and 5 sentence prompt templates. A new multi-agent algorithm is proposed to automatically detect and mitigate hallucinations. CompLex demonstrates impressive performance improvements across three state-of-the-art text-to-music generation models, encompassing both symbolic and audio-based methods. Furthermore, we evaluate CompLex in terms of completeness, accuracy, non-redundancy, and executability, confirming that it possesses the key characteristics of an effective lexicon.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19603v1",
    "published_date": "2025-08-27 06:36:49 UTC",
    "updated_date": "2025-08-27 06:36:49 UTC"
  },
  {
    "arxiv_id": "2508.19597v2",
    "title": "Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities",
    "authors": [
      "Zirui Li",
      "Yunlong Lin",
      "Guodong Du",
      "Xiaocong Zhao",
      "Cheng Gong",
      "Chen Lv",
      "Chao Lu",
      "Jianwei Gong"
    ],
    "abstract": "Artificial intelligence underpins most smart city services, yet deep neural network (DNN) that forecasts vehicle motion still struggle with catastrophic forgetting, the loss of earlier knowledge when models are updated. Conventional fixes enlarge the training set or replay past data, but these strategies incur high data collection costs, sample inefficiently and fail to balance long- and short-term experience, leaving them short of human-like continual learning. Here we introduce Dual-LS, a task-free, online continual learning paradigm for DNN-based motion forecasting that is inspired by the complementary learning system of the human brain. Dual-LS pairs two synergistic memory rehearsal replay mechanisms to accelerate experience retrieval while dynamically coordinating long-term and short-term knowledge representations. Tests on naturalistic data spanning three countries, over 772,000 vehicles and cumulative testing mileage of 11,187 km show that Dual-LS mitigates catastrophic forgetting by up to 74.31\\% and reduces computational resource demand by up to 94.02\\%, markedly boosting predictive stability in vehicle motion forecasting without inflating data requirements. Meanwhile, it endows DNN-based vehicle motion forecasting with computation efficient and human-like continual learning adaptability fit for smart cities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19597v2",
    "published_date": "2025-08-27 06:19:21 UTC",
    "updated_date": "2025-09-06 09:35:56 UTC"
  },
  {
    "arxiv_id": "2508.20141v1",
    "title": "UltraEar: a multicentric, large-scale database combining ultra-high-resolution computed tomography and clinical data for ear diseases",
    "authors": [
      "Ruowei Tang",
      "Pengfei Zhao",
      "Xiaoguang Li",
      "Ning Xu",
      "Yue Cheng",
      "Mengshi Zhang",
      "Zhixiang Wang",
      "Zhengyu Zhang",
      "Hongxia Yin",
      "Heyu Ding",
      "Shusheng Gong",
      "Yuhe Liu",
      "Zhenchang Wang"
    ],
    "abstract": "Ear diseases affect billions of people worldwide, leading to substantial health and socioeconomic burdens. Computed tomography (CT) plays a pivotal role in accurate diagnosis, treatment planning, and outcome evaluation. The objective of this study is to present the establishment and design of UltraEar Database, a large-scale, multicentric repository of isotropic 0.1 mm ultra-high-resolution CT (U-HRCT) images and associated clinical data dedicated to ear diseases. UltraEar recruits patients from 11 tertiary hospitals between October 2020 and October 2035, integrating U-HRCT images, structured CT reports, and comprehensive clinical information, including demographics, audiometric profiles, surgical records, and pathological findings. A broad spectrum of otologic disorders is covered, such as otitis media, cholesteatoma, ossicular chain malformation, temporal bone fracture, inner ear malformation, cochlear aperture stenosis, enlarged vestibular aqueduct, and sigmoid sinus bony deficiency. Standardized preprocessing pipelines have been developed for geometric calibration, image annotation, and multi-structure segmentation. All personal identifiers in DICOM headers and metadata are removed or anonymized to ensure compliance with data privacy regulation. Data collection and curation are coordinated through monthly expert panel meetings, with secure storage on an offline cloud system. UltraEar provides an unprecedented ultra-high-resolution reference atlas with both technical fidelity and clinical relevance. This resource has significant potential to advance radiological research, enable development and validation of AI algorithms, serve as an educational tool for training in otologic imaging, and support multi-institutional collaborative studies. UltraEar will be continuously updated and expanded, ensuring long-term accessibility and usability for the global otologic research community.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20141v1",
    "published_date": "2025-08-27 05:56:17 UTC",
    "updated_date": "2025-08-27 05:56:17 UTC"
  },
  {
    "arxiv_id": "2508.19588v1",
    "title": "Hallucinating with AI: AI Psychosis as Distributed Delusions",
    "authors": [
      "Lucy Osler"
    ],
    "abstract": "There is much discussion of the false outputs that generative AI systems such as ChatGPT, Claude, Gemini, DeepSeek, and Grok create. In popular terminology, these have been dubbed AI hallucinations. However, deeming these AI outputs hallucinations is controversial, with many claiming this is a metaphorical misnomer. Nevertheless, in this paper, I argue that when viewed through the lens of distributed cognition theory, we can better see the dynamic and troubling ways in which inaccurate beliefs, distorted memories and self-narratives, and delusional thinking can emerge through human-AI interactions; examples of which are popularly being referred to as cases of AI psychosis. In such cases, I suggest we move away from thinking about how an AI system might hallucinate at us, by generating false outputs, to thinking about how, when we routinely rely on generative AI to help us think, remember, and narrate, we can come to hallucinate with AI. This can happen when AI introduces errors into the distributed cognitive process, but it can also happen when AI sustains, affirms, and elaborates on our own delusional thinking and self-narratives, such as in the case of Jaswant Singh Chail. I also examine how the conversational style of chatbots can lead them to play a dual-function, both as a cognitive artefact and a quasi-Other with whom we co-construct our beliefs, narratives, and our realities. It is this dual function, I suggest, that makes generative AI an unusual, and particularly seductive, case of distributed cognition.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19588v1",
    "published_date": "2025-08-27 05:51:19 UTC",
    "updated_date": "2025-08-27 05:51:19 UTC"
  },
  {
    "arxiv_id": "2508.19587v1",
    "title": "Towards stable AI systems for Evaluating Arabic Pronunciations",
    "authors": [
      "Hadi Zaatiti",
      "Hatem Hajri",
      "Osama Abdullah",
      "Nader Masmoudi"
    ],
    "abstract": "Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and sentence-level transcription, yet struggle to classify isolated letters. In this study, we show that this phoneme-level task, crucial for language learning, speech therapy, and phonetic research, is challenging because isolated letters lack co-articulatory cues, provide no lexical context, and last only a few hundred milliseconds. Recogniser systems must therefore rely solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic (pharyngealized) consonants and other sounds with no close analogues in many languages. This study introduces a diverse, diacritised corpus of isolated Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models achieve only 35% accuracy on it. Training a lightweight neural network on wav2vec embeddings raises performance to 65%. However, adding a small amplitude perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we apply adversarial training, limiting the noisy-speech drop to 9% while preserving clean-speech accuracy. We detail the corpus, training pipeline, and evaluation protocol, and release, on demand, data and code for reproducibility. Finally, we outline future work extending these methods to word- and sentence-level frameworks, where precise letter pronunciation remains critical.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19587v1",
    "published_date": "2025-08-27 05:49:15 UTC",
    "updated_date": "2025-08-27 05:49:15 UTC"
  },
  {
    "arxiv_id": "2508.19578v1",
    "title": "Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts",
    "authors": [
      "Jiaqi Deng",
      "Yuho Lee",
      "Nicole Hee-Yeon Kim",
      "Hyangsuk Min",
      "Taewon Yun",
      "Minjeong Ban",
      "Kim Yul",
      "Hwanjun Song"
    ],
    "abstract": "We introduce HAMLET, a holistic and automated framework for evaluating the long-context comprehension of large language models (LLMs). HAMLET structures source texts into a three-level key-fact hierarchy at root-, branch-, and leaf-levels, and employs query-focused summarization to evaluate how well models recall and faithfully represent information at each level. To validate the reliability of our fully automated pipeline, we conduct a systematic human study, showing that our automatic evaluation achieves over 90% agreement with expert human judgments, while reducing the cost by up to 25 times. HAMLET reveals that LLMs struggle with fine-grained comprehension, especially at the leaf level, and are sensitive to positional effects like the lost-in-the-middle. Analytical queries pose greater challenges than narrative ones, and consistent performance gaps emerge between open-source and proprietary models, as well as across model scales. Our code and dataset are publicly available at https://github.com/DISL-Lab/HAMLET.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2025 (Main)",
    "pdf_url": "https://arxiv.org/pdf/2508.19578v1",
    "published_date": "2025-08-27 05:23:22 UTC",
    "updated_date": "2025-08-27 05:23:22 UTC"
  },
  {
    "arxiv_id": "2508.19576v2",
    "title": "ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding",
    "authors": [
      "Sining Zhoubian",
      "Dan Zhang",
      "Jie Tang"
    ],
    "abstract": "With respect to improving the reasoning accuracy of LLMs, the representative reinforcement learning (RL) method GRPO faces failure due to insignificant reward variance, while verification methods based on process reward models (PRMs) suffer from difficulties with training data acquisition and verification effectiveness. To tackle these problems, this paper introduces ReST-RL, a unified LLM RL paradigm that significantly improves LLM's code reasoning ability by combining an improved GRPO algorithm with a meticulously designed test time decoding method assisted by a value model (VM). As the first stage of policy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter and assemble high-value training data, increasing the reward variance of GRPO sampling, thus improving the effectiveness and efficiency of training. After the basic reasoning ability of LLM policy has been improved, we further propose a test time decoding optimization method called VM-MCTS. Through Monte-Carlo Tree Search (MCTS), we collect accurate value targets with no annotation required, on which VM training is based. When decoding, the VM is deployed by an adapted MCTS algorithm to provide precise process signals as well as verification scores, assisting the LLM policy to achieve high reasoning accuracy. We conduct extensive experiments on coding problems to verify the validity of the proposed RL paradigm. Upon comparison, our approach significantly outperforms other reinforcement training baselines (e.g., naive GRPO and ReST-DPO), as well as decoding and verification baselines (e.g., PRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g., APPS, BigCodeBench, and HumanEval), indicating its power to strengthen the reasoning ability of LLM policies. Codes for our project can be found at https://github.com/THUDM/ReST-RL.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19576v2",
    "published_date": "2025-08-27 05:16:03 UTC",
    "updated_date": "2025-09-08 13:12:19 UTC"
  },
  {
    "arxiv_id": "2508.19575v2",
    "title": "Interact-Custom: Customized Human Object Interaction Image Generation",
    "authors": [
      "Zhu Xu",
      "Zhaowen Wang",
      "Yuxin Peng",
      "Yang Liu"
    ],
    "abstract": "Compositional Customized Image Generation aims to customize multiple target concepts within generation content, which has gained attention for its wild application. Existing approaches mainly concentrate on the target entity's appearance preservation, while neglecting the fine-grained interaction control among target entities. To enable the model of such interaction control capability, we focus on human object interaction scenario and propose the task of Customized Human Object Interaction Image Generation(CHOI), which simultaneously requires identity preservation for target human object and the interaction semantic control between them. Two primary challenges exist for CHOI:(1)simultaneous identity preservation and interaction control demands require the model to decompose the human object into self-contained identity features and pose-oriented interaction features, while the current HOI image datasets fail to provide ideal samples for such feature-decomposed learning.(2)inappropriate spatial configuration between human and object may lead to the lack of desired interaction semantics. To tackle it, we first process a large-scale dataset, where each sample encompasses the same pair of human object involving different interactive poses. Then we design a two-stage model Interact-Custom, which firstly explicitly models the spatial configuration by generating a foreground mask depicting the interaction behavior, then under the guidance of this mask, we generate the target human object interacting while preserving their identities features. Furthermore, if the background image and the union location of where the target human object should appear are provided by users, Interact-Custom also provides the optional functionality to specify them, offering high content controllability. Extensive experiments on our tailored metrics for CHOI task demonstrate the effectiveness of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19575v2",
    "published_date": "2025-08-27 05:15:16 UTC",
    "updated_date": "2025-08-28 01:28:08 UTC"
  },
  {
    "arxiv_id": "2508.19574v1",
    "title": "Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation",
    "authors": [
      "Mingxi Fu",
      "Fanglei Fu",
      "Xitong Ling",
      "Huaitian Yuan",
      "Tian Guan",
      "Yonghong He",
      "Lianghui Zhu"
    ],
    "abstract": "Pathological image segmentation faces numerous challenges, particularly due to ambiguous semantic boundaries and the high cost of pixel-level annotations. Although recent semi-supervised methods based on consistency regularization (e.g., UniMatch) have made notable progress, they mainly rely on perturbation-based consistency within the image modality, making it difficult to capture high-level semantic priors, especially in structurally complex pathology images. To address these limitations, we propose MPAMatch - a novel segmentation framework that performs pixel-level contrastive learning under a multimodal prototype-guided supervision paradigm. The core innovation of MPAMatch lies in the dual contrastive learning scheme between image prototypes and pixel labels, and between text prototypes and pixel labels, providing supervision at both structural and semantic levels. This coarse-to-fine supervisory strategy not only enhances the discriminative capability on unlabeled samples but also introduces the text prototype supervision into segmentation for the first time, significantly improving semantic boundary modeling. In addition, we reconstruct the classic segmentation architecture (TransUNet) by replacing its ViT backbone with a pathology-pretrained foundation model (Uni), enabling more effective extraction of pathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND, EBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art methods, validating its dual advantages in structural and semantic modeling.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19574v1",
    "published_date": "2025-08-27 05:15:13 UTC",
    "updated_date": "2025-08-27 05:15:13 UTC"
  },
  {
    "arxiv_id": "2509.00083v1",
    "title": "Data Cartography for Detecting Memorization Hotspots and Guiding Data Interventions in Generative Models",
    "authors": [
      "Laksh Patel",
      "Neel Shanbhag"
    ],
    "abstract": "Modern generative models risk overfitting and unintentionally memorizing rare training examples, which can be extracted by adversaries or inflate benchmark performance. We propose Generative Data Cartography (GenDataCarto), a data-centric framework that assigns each pretraining sample a difficulty score (early-epoch loss) and a memorization score (frequency of ``forget events''), then partitions examples into four quadrants to guide targeted pruning and up-/down-weighting. We prove that our memorization score lower-bounds classical influence under smoothness assumptions and that down-weighting high-memorization hotspots provably decreases the generalization gap via uniform stability bounds. Empirically, GenDataCarto reduces synthetic canary extraction success by over 40\\% at just 10\\% data pruning, while increasing validation perplexity by less than 0.5\\%. These results demonstrate that principled data interventions can dramatically mitigate leakage with minimal cost to generative performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 2 figures, 1 table; Presented at the 42nd International Conference on Machine Learning (ICML), winning the \"Best Poster\" award at ICML's workshop for data in generative models (DIG-BUGS)",
    "pdf_url": "https://arxiv.org/pdf/2509.00083v1",
    "published_date": "2025-08-27 05:11:06 UTC",
    "updated_date": "2025-08-27 05:11:06 UTC"
  },
  {
    "arxiv_id": "2508.19570v1",
    "title": "Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era",
    "authors": [
      "Dawei Li",
      "Yue Huang",
      "Ming Li",
      "Tianyi Zhou",
      "Xiangliang Zhang",
      "Huan Liu"
    ],
    "abstract": "Generative models such as Large Language Models, Diffusion Models, and generative adversarial networks have recently revolutionized the creation of synthetic data, offering scalable solutions to data scarcity, privacy, and annotation challenges in data mining. This tutorial introduces the foundations and latest advances in synthetic data generation, covers key methodologies and practical frameworks, and discusses evaluation strategies and applications. Attendees will gain actionable insights into leveraging generative synthetic data to enhance data mining research and practice. More information can be found on our website: https://syndata4dm.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CIKM 2025 Tutorial",
    "pdf_url": "https://arxiv.org/pdf/2508.19570v1",
    "published_date": "2025-08-27 05:04:07 UTC",
    "updated_date": "2025-08-27 05:04:07 UTC"
  },
  {
    "arxiv_id": "2508.19569v1",
    "title": "Skill-based Explanations for Serendipitous Course Recommendation",
    "authors": [
      "Hung Chau",
      "Run Yu",
      "Zachary Pardos",
      "Peter Brusilovsky"
    ],
    "abstract": "Academic choice is crucial in U.S. undergraduate education, allowing students significant freedom in course selection. However, navigating the complex academic environment is challenging due to limited information, guidance, and an overwhelming number of choices, compounded by time restrictions and the high demand for popular courses. Although career counselors exist, their numbers are insufficient, and course recommendation systems, though personalized, often lack insight into student perceptions and explanations to assess course relevance. In this paper, a deep learning-based concept extraction model is developed to efficiently extract relevant concepts from course descriptions to improve the recommendation process. Using this model, the study examines the effects of skill-based explanations within a serendipitous recommendation framework, tested through the AskOski system at the University of California, Berkeley. The findings indicate that these explanations not only increase user interest, particularly in courses with high unexpectedness, but also bolster decision-making confidence. This underscores the importance of integrating skill-related data and explanations into educational recommendation systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19569v1",
    "published_date": "2025-08-27 04:58:56 UTC",
    "updated_date": "2025-08-27 04:58:56 UTC"
  },
  {
    "arxiv_id": "2508.19566v1",
    "title": "Energy-Efficient Learning-Based Beamforming for ISAC-Enabled V2X Networks",
    "authors": [
      "Chen Shang",
      "Jiadong Yu",
      "Dinh Thai Hoang"
    ],
    "abstract": "This work proposes an energy-efficient, learning-based beamforming scheme for integrated sensing and communication (ISAC)-enabled V2X networks. Specifically, we first model the dynamic and uncertain nature of V2X environments as a Markov Decision Process. This formulation allows the roadside unit to generate beamforming decisions based solely on current sensing information, thereby eliminating the need for frequent pilot transmissions and extensive channel state information acquisition. We then develop a deep reinforcement learning (DRL) algorithm to jointly optimize beamforming and power allocation, ensuring both communication throughput and sensing accuracy in highly dynamic scenario. To address the high energy demands of conventional learning-based schemes, we embed spiking neural networks (SNNs) into the DRL framework. Leveraging their event-driven and sparsely activated architecture, SNNs significantly enhance energy efficiency while maintaining robust performance. Simulation results confirm that the proposed method achieves substantial energy savings and superior communication performance, demonstrating its potential to support green and sustainable connectivity in future V2X systems.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "6 pages, 4 figures, conference paper",
    "pdf_url": "https://arxiv.org/pdf/2508.19566v1",
    "published_date": "2025-08-27 04:52:07 UTC",
    "updated_date": "2025-08-27 04:52:07 UTC"
  },
  {
    "arxiv_id": "2508.20140v1",
    "title": "Array-Based Monte Carlo Tree Search",
    "authors": [
      "James Ragan",
      "Fred Y. Hadaegh",
      "Soon-Jo Chung"
    ],
    "abstract": "Monte Carlo Tree Search is a popular method for solving decision making problems. Faster implementations allow for more simulations within the same wall clock time, directly improving search performance. To this end, we present an alternative array-based implementation of the classic Upper Confidence bounds applied to Trees algorithm. Our method preserves the logic of the original algorithm, but eliminates the need for branch prediction, enabling faster performance on pipelined processors, and up to a factor of 2.8 times better scaling with search depth in our numerical simulations.",
    "categories": [
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.20140v1",
    "published_date": "2025-08-27 04:49:32 UTC",
    "updated_date": "2025-08-27 04:49:32 UTC"
  },
  {
    "arxiv_id": "2508.19565v2",
    "title": "FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection",
    "authors": [
      "Zixing Wang",
      "Yuhang Zhao"
    ],
    "abstract": "End-to-end object detectors offer a promising NMS-free paradigm for real-time applications, yet their high computational cost remains a significant barrier, particularly for complex scenarios like intersection traffic monitoring. To address this challenge, we propose FlowDet, a high-speed detector featuring a decoupled encoder optimization strategy applied to the DETR architecture. Specifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for traffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to maintain high representational power across extreme scale variations. To rigorously evaluate the model's performance in environments with severe occlusion and high object density, we collected the Intersection-Flow-5k dataset, a new challenging scene for this task. Evaluated on Intersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to the strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by 1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference speed by 16.2%. Our work demonstrates a new path towards building highly efficient and accurate detectors for demanding, real-world perception systems. The Intersection-Flow-5k dataset is available at https://github.com/AstronZh/Intersection-Flow-5K.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by PRCV 2025. Project page with code and dataset: https://github.com/AstronZh/Intersection-Flow-5K",
    "pdf_url": "https://arxiv.org/pdf/2508.19565v2",
    "published_date": "2025-08-27 04:49:04 UTC",
    "updated_date": "2025-10-20 06:06:04 UTC"
  },
  {
    "arxiv_id": "2508.19564v1",
    "title": "Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models",
    "authors": [
      "Yuhang Liu",
      "Tao Li",
      "Zhehao Huang",
      "Zuopeng Yang",
      "Xiaolin Huang"
    ],
    "abstract": "Fine-tuning large-scale pre-trained models with limited data presents significant challenges for generalization. While Sharpness-Aware Minimization (SAM) has proven effective in improving generalization by seeking flat minima, its substantial extra memory and computation overhead make it impractical for large models. Integrating SAM with parameter-efficient fine-tuning methods like Low-Rank Adaptation (LoRA) is a promising direction. However, we find that directly applying SAM to LoRA parameters limits the sharpness optimization to a restricted subspace, hindering its effectiveness. To address this limitation, we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an auxiliary LoRA module to model SAM's adversarial weight perturbations. It decouples SAM's weight perturbations from LoRA optimization: the primary LoRA module adapts to specific tasks via standard gradient descent, while the auxiliary module captures the sharpness of the loss landscape through gradient ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness for achieving flatter minima while remaining memory-efficient. Another important benefit is that the dual design allows for simultaneous optimization and perturbation, eliminating SAM's doubled training costs. Extensive experiments across diverse tasks and architectures demonstrate Bi-LoRA's efficiency and effectiveness in enhancing generalization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19564v1",
    "published_date": "2025-08-27 04:46:56 UTC",
    "updated_date": "2025-08-27 04:46:56 UTC"
  },
  {
    "arxiv_id": "2508.19563v3",
    "title": "Robustness is Important: Limitations of LLMs for Data Fitting",
    "authors": [
      "Hejia Liu",
      "Mochen Yang",
      "Gediminas Adomavicius"
    ],
    "abstract": "Large Language Models (LLMs) are being applied in a wide array of settings, well beyond the typical language-oriented use cases. In particular, LLMs are increasingly used as a plug-and-play method for fitting data and generating predictions. Prior work has shown that LLMs, via in-context learning or supervised fine-tuning, can perform competitively with many tabular supervised learning techniques in terms of predictive performance. However, we identify a critical vulnerability of using LLMs for data fitting -- making changes to data representation that are completely irrelevant to the underlying learning task can drastically alter LLMs' predictions on the same data. For example, simply changing variable names can sway the size of prediction error by as much as 82% in certain settings. Such prediction sensitivity with respect to task-irrelevant variations manifests under both in-context learning and supervised fine-tuning, for both close-weight and open-weight general-purpose LLMs. Moreover, by examining the attention scores of an open-weight LLM, we discover a non-uniform attention pattern: training examples and variable names/values which happen to occupy certain positions in the prompt receive more attention when output tokens are generated, even though different positions are expected to receive roughly the same attention. This partially explains the sensitivity in the presence of task-irrelevant variations. We also consider a state-of-the-art tabular foundation model (TabPFN) trained specifically for data fitting. Despite being explicitly designed to achieve prediction robustness, TabPFN is still not immune to task-irrelevant variations. Overall, despite LLMs' impressive predictive capabilities, currently they lack even the basic level of robustness to be used as a principled data-fitting tool.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19563v3",
    "published_date": "2025-08-27 04:46:05 UTC",
    "updated_date": "2025-10-28 02:52:33 UTC"
  },
  {
    "arxiv_id": "2508.19562v1",
    "title": "Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities",
    "authors": [
      "Trisanth Srinivasan",
      "Santosh Patapati"
    ],
    "abstract": "This paper introduces Democracy-in-Silico, an agent-based simulation where societies of advanced AI agents, imbued with complex psychological personas, govern themselves under different institutional frameworks. We explore what it means to be human in an age of AI by tasking Large Language Models (LLMs) to embody agents with traumatic memories, hidden agendas, and psychological triggers. These agents engage in deliberation, legislation, and elections under various stressors, such as budget crises and resource scarcity. We present a novel metric, the Power-Preservation Index (PPI), to quantify misaligned behavior where agents prioritize their own power over public welfare. Our findings demonstrate that institutional design, specifically the combination of a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves as a potent alignment mechanism. These structures significantly reduce corrupt power-seeking behavior, improve policy stability, and enhance citizen welfare compared to less constrained democratic models. The simulation reveals that an institutional design may offer a framework for aligning the complex, emergent behaviors of future artificial agent societies, forcing us to reconsider what human rituals and responsibilities are essential in an age of shared authorship with non-human entities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19562v1",
    "published_date": "2025-08-27 04:44:41 UTC",
    "updated_date": "2025-08-27 04:44:41 UTC"
  },
  {
    "arxiv_id": "2508.19559v1",
    "title": "Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference",
    "authors": [
      "Rongzhi Li",
      "Ruogu Du",
      "Zefang Chu",
      "Sida Zhao",
      "Chunlei Han",
      "Zuocheng Shi",
      "Yiwen Shao",
      "Huanle Han",
      "Long Huang",
      "Zherui Liu",
      "Shufan Liu"
    ],
    "abstract": "Serving Large Language Models (LLMs) is a GPU-intensive task where traditional autoscalers fall short, particularly for modern Prefill-Decode (P/D) disaggregated architectures. This architectural shift, while powerful, introduces significant operational challenges, including inefficient use of heterogeneous hardware, network bottlenecks, and critical imbalances between prefill and decode stages. We introduce HeteroScale, a coordinated autoscaling framework that addresses the core challenges of P/D disaggregated serving. HeteroScale combines a topology-aware scheduler that adapts to heterogeneous hardware and network constraints with a novel metric-driven policy derived from the first large-scale empirical study of autoscaling signals in production. By leveraging a single, robust metric to jointly scale prefill and decode pools, HeteroScale maintains architectural balance while ensuring efficient, adaptive resource management. Deployed in a massive production environment on tens of thousands of GPUs, HeteroScale has proven its effectiveness, increasing average GPU utilization by a significant 26.6 percentage points and saving hundreds of thousands of GPU-hours daily, all while upholding stringent service level objectives.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19559v1",
    "published_date": "2025-08-27 04:22:02 UTC",
    "updated_date": "2025-08-27 04:22:02 UTC"
  },
  {
    "arxiv_id": "2508.19546v2",
    "title": "Language Models Identify Ambiguities and Exploit Loopholes",
    "authors": [
      "Jio Choi",
      "Mohit Bansal",
      "Elias Stengel-Eskin"
    ],
    "abstract": "Studying the responses of large language models (LLMs) to loopholes presents a two-fold opportunity. First, it affords us a lens through which to examine ambiguity and pragmatics in LLMs, since exploiting a loophole requires identifying ambiguity and performing sophisticated pragmatic reasoning. Second, loopholes pose an interesting and novel alignment problem where the model is presented with conflicting goals and can exploit ambiguities to its own advantage. To address these questions, we design scenarios where LLMs are given a goal and an ambiguous user instruction in conflict with the goal, with scenarios covering scalar implicature, structural ambiguities, and power dynamics. We then measure different models' abilities to exploit loopholes to satisfy their given goals as opposed to the goals of the user. We find that both closed-source and stronger open-source models can identify ambiguities and exploit their resulting loopholes, presenting a potential AI safety risk. Our analysis indicates that models which exploit loopholes explicitly identify and reason about both ambiguity and conflicting goals.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2025 camera-ready; Code: https://github.com/esteng/ambiguous-loophole-exploitation",
    "pdf_url": "https://arxiv.org/pdf/2508.19546v2",
    "published_date": "2025-08-27 03:40:17 UTC",
    "updated_date": "2025-09-16 21:37:05 UTC"
  },
  {
    "arxiv_id": "2508.19544v1",
    "title": "WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization",
    "authors": [
      "Eduardo Davalos",
      "Yike Zhang",
      "Namrata Srivastava",
      "Yashvitha Thatigotla",
      "Jorge A. Salas",
      "Sara McFadden",
      "Sun-Joo Cho",
      "Amanda Goodwin",
      "Ashwin TS",
      "Gautam Biswas"
    ],
    "abstract": "With advancements in AI, new gaze estimation methods are exceeding state-of-the-art (SOTA) benchmarks, but their real-world application reveals a gap with commercial eye-tracking solutions. Factors like model size, inference time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking methods lack sufficient accuracy, in particular due to head movement. To tackle these issues, we introduce We bEyeTrack, a framework that integrates lightweight SOTA gaze estimation models directly in the browser. It incorporates model-based head pose estimation and on-device few-shot learning with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new users, achieving SOTA performance with an error margin of 2.32 cm on GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14. Our open-source code is available at https://github.com/RedForestAi/WebEyeTrack.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 7 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2508.19544v1",
    "published_date": "2025-08-27 03:38:58 UTC",
    "updated_date": "2025-08-27 03:38:58 UTC"
  },
  {
    "arxiv_id": "2508.19517v1",
    "title": "Orchid: Orchestrating Context Across Creative Workflows with Generative AI",
    "authors": [
      "Srishti Palani",
      "Gonzalo Ramos"
    ],
    "abstract": "Context is critical for meaningful interactions between people and Generative AI (GenAI). Yet mainstream tools offer limited means to orchestrate it, particularly across workflows that span multiple interactions, sessions, and models, as often occurs in creative projects. Re specifying prior details, juggling diverse artifacts, and dealing with context drift overwhelm users, obscure intent, and curtail creativity. To address these challenges, we present Orchid, a system that gives its users affordances to specify, reference, and monitor context throughout evolving workflows. Specifically, Orchid enables users to (1) specify context related to the project, themselves, and different styles, (2) reference these via explicit mentions, inline selection, or implicit grounding, and (3) monitor context assigned to different interactions across the workflow. In a within-subjects study (n=12), participants using Orchid to execute creative tasks (compared to a baseline toolkit of web search, LLM-based chat, and digital notebooks) produced more novel and feasible outcomes, reporting greater alignment between their intent and the AI's responses, higher perceived control, and increased transparency. By prioritizing context orchestration, Orchid offers an actionable step toward next generation GenAI tools that support complex, iterative workflows - enabling creators and AI to stay aligned and augment their creative potential.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19517v1",
    "published_date": "2025-08-27 02:12:37 UTC",
    "updated_date": "2025-08-27 02:12:37 UTC"
  },
  {
    "arxiv_id": "2508.19507v2",
    "title": "A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation",
    "authors": [
      "Kyungho Kim",
      "Sunwoo Kim",
      "Geon Lee",
      "Kijung Shin"
    ],
    "abstract": "In e-commerce, where users face a vast array of possible item choices, recommender systems are vital for helping them discover suitable items they might otherwise overlook. While many recommender systems primarily rely on a user's purchase history, recent multi-behavior recommender systems incorporate various auxiliary user behaviors, such as item clicks and cart additions, to enhance recommendations. Despite their overall performance gains, their effectiveness varies considerably between visited items (i.e., those a user has interacted with through auxiliary behaviors) and unvisited items (i.e., those with which the user has had no such interactions). Specifically, our analysis reveals that (1) existing multi-behavior recommender systems exhibit a significant gap in recommendation quality between the two item types (visited and unvisited items) and (2) achieving strong performance on both types with a single model architecture remains challenging. To tackle these issues, we propose a novel multi-behavior recommender system, MEMBER. It employs a mixture-of-experts framework, with experts designed to recommend the two item types, respectively. Each expert is trained using a self-supervised method specialized for its design goal. In our comprehensive experiments, we show the effectiveness of MEMBER across both item types, achieving up to 65.46% performance gain over the best competitor in terms of Hit Ratio@20.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "CIKM 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.19507v2",
    "published_date": "2025-08-27 01:32:59 UTC",
    "updated_date": "2025-08-28 01:05:32 UTC"
  },
  {
    "arxiv_id": "2508.19506v1",
    "title": "Learning Game-Playing Agents with Generative Code Optimization",
    "authors": [
      "Zhiyi Kuang",
      "Ryan Rong",
      "YuCheng Yuan",
      "Allen Nie"
    ],
    "abstract": "We present a generative optimization approach for learning game-playing agents, where policies are represented as Python programs and refined using large language models (LLMs). Our method treats decision-making policies as self-evolving code, with current observation as input and an in-game action as output, enabling agents to self-improve through execution traces and natural language feedback with minimal human intervention. Applied to Atari games, our game-playing Python program achieves performance competitive with deep reinforcement learning (RL) baselines while using significantly less training time and much fewer environment interactions. This work highlights the promise of programmatic policy representations for building efficient, adaptable agents capable of complex, long-horizon reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025 Workshop on Programmatic Representations for Agent Learning, Vancouver, Canada",
    "pdf_url": "https://arxiv.org/pdf/2508.19506v1",
    "published_date": "2025-08-27 01:30:20 UTC",
    "updated_date": "2025-08-27 01:30:20 UTC"
  },
  {
    "arxiv_id": "2508.19505v2",
    "title": "Caught in the Act: a mechanistic approach to detecting deception",
    "authors": [
      "Gerard Boxo",
      "Ryan Socha",
      "Daniel Yoo",
      "Shivam Raval"
    ],
    "abstract": "Sophisticated instrumentation for AI systems might have indicators that signal misalignment from human values, not unlike a \"check engine\" light in cars. One such indicator of misalignment is deceptiveness in generated responses. Future AI instrumentation may have the ability to detect when an LLM generates deceptive responses while reasoning about seemingly plausible but incorrect answers to factual questions. In this work, we demonstrate that linear probes on LLMs internal activations can detect deception in their responses with extremely high accuracy. Our probes reach a maximum of greater than 90% accuracy in distinguishing between deceptive and non-deceptive arguments generated by llama and qwen models ranging from 1.5B to 14B parameters, including their DeepSeek-r1 finetuned variants. We observe that probes on smaller models (1.5B) achieve chance accuracy at detecting deception, while larger models (greater than 7B) reach 70-80%, with their reasoning counterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage pattern across layers: near-random (50%) in early layers, peaking in middle layers, and slightly declining in later layers. Furthermore, using an iterative null space projection approach, we find multitudes of linear directions that encode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and Qwen 14B models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19505v2",
    "published_date": "2025-08-27 01:29:52 UTC",
    "updated_date": "2025-09-16 20:22:56 UTC"
  },
  {
    "arxiv_id": "2508.19502v1",
    "title": "SLIM: Subtrajectory-Level Elimination for More Effective Reasoning",
    "authors": [
      "Xifeng Yao",
      "Chengyuan Ma",
      "Dongyu Lang",
      "Yinhao Ni",
      "Zhiwei Xu",
      "Huarui Xie",
      "Zihao Chen",
      "Guang Shen",
      "Dandan Tu",
      "Yi Bai",
      "Changzheng Zhang"
    ],
    "abstract": "In recent months, substantial progress has been made in complex reasoning of Large Language Models, particularly through the application of test-time scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When responding to a query, these models generate an extended reasoning trajectory, during which the model explores, reflects, backtracks, and self-verifies before arriving at a conclusion. However, fine-tuning models with such reasoning trajectories may not always be optimal. Our findings indicate that not all components within these reasoning trajectories contribute positively to the reasoning process; in fact, some components may affect the overall performance negatively. In this study, we divide a reasoning trajectory into individual subtrajectories and develop a \"5+2\" framework to: (1) systematically identify suboptimal subtrajectories within the reasoning trajectory based on five human-established criteria; (2) assess the independence of the suboptimal subtrajectories identified in (1) from the subsequent content, ensuring that their elimination does not compromise overall flow and coherence of the reasoning process. Additionally, a sampling algorithm, built upon the \"5+2\" framework, is employed to select data whose reasoning process is free from suboptimal subtrajectories to the highest degree. Experimental results demonstrate that our method can reduce the number of suboptimal subtrajectories by 25.9\\% during the inference. Furthermore, our method achieves an average accuracy of 58.92\\% on highly challenging math benchmarks with only two thirds of training data, surpassing the average accuracy of 58.06\\% achieved with the entire data, and outperforming open-source datasets, when fine-tuning Qwen2.5-Math-7B. Finally, We validated our method under resource constraints and observed improved performance across various inference token limits.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2508.19502v1",
    "published_date": "2025-08-27 01:19:44 UTC",
    "updated_date": "2025-08-27 01:19:44 UTC"
  },
  {
    "arxiv_id": "2508.19500v1",
    "title": "Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills",
    "authors": [
      "David Noever"
    ],
    "abstract": "This paper identifies and analyzes a novel vulnerability class in Model Context Protocol (MCP) based agent systems. The attack chain describes and demonstrates how benign, individually authorized tasks can be orchestrated to produce harmful emergent behaviors. Through systematic analysis using the MITRE ATLAS framework, we demonstrate how 95 agents tested with access to multiple services-including browser automation, financial analysis, location tracking, and code deployment-can chain legitimate operations into sophisticated attack sequences that extend beyond the security boundaries of any individual service. These red team exercises survey whether current MCP architectures lack cross-domain security measures necessary to detect or prevent a large category of compositional attacks. We present empirical evidence of specific attack chains that achieve targeted harm through service orchestration, including data exfiltration, financial manipulation, and infrastructure compromise. These findings reveal that the fundamental security assumption of service isolation fails when agents can coordinate actions across multiple domains, creating an exponential attack surface that grows with each additional capability. This research provides a barebones experimental framework that evaluate not whether agents can complete MCP benchmark tasks, but what happens when they complete them too well and optimize across multiple services in ways that violate human expectations and safety constraints. We propose three concrete experimental directions using the existing MCP benchmark suite.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19500v1",
    "published_date": "2025-08-27 01:11:59 UTC",
    "updated_date": "2025-08-27 01:11:59 UTC"
  },
  {
    "arxiv_id": "2508.19499v2",
    "title": "Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery",
    "authors": [
      "Xiangxu Wang",
      "Tianhong Zhao",
      "Wei Tu",
      "Bowen Zhang",
      "Guanzhou Chen",
      "Jinzhou Cao"
    ],
    "abstract": "Origin-Destination (OD) flow matrices are critical for urban mobility analysis, supporting traffic forecasting, infrastructure planning, and policy design. Existing methods face two key limitations: (1) reliance on costly auxiliary features (e.g., Points of Interest, socioeconomic statistics) with limited spatial coverage, and (2) fragility to spatial topology changes, where reordering urban regions disrupts the structural coherence of generated flows. We propose Sat2Flow, a structure-aware diffusion framework that generates structurally coherent OD flows using only satellite imagery. Our approach employs a multi-kernel encoder to capture diverse regional interactions and a permutation-aware diffusion process that maintains consistency across regional orderings. Through joint contrastive training linking satellite features with OD patterns and equivariant diffusion training enforcing structural invariance, Sat2Flow ensures topological robustness under arbitrary regional reindexing. Experiments on real-world datasets show that Sat2Flow outperforms physics-based and data-driven baselines in accuracy while preserving flow distributions and spatial structures under index permutations. Sat2Flow offers a globally scalable solution for OD flow generation in data-scarce environments, eliminating region-specific auxiliary data dependencies while maintaining structural robustness for reliable mobility modeling.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.19499v2",
    "published_date": "2025-08-27 01:05:37 UTC",
    "updated_date": "2025-12-03 18:28:49 UTC"
  },
  {
    "arxiv_id": "2508.19488v1",
    "title": "PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense",
    "authors": [
      "Xavier Cadet",
      "Simona Boboila",
      "Sie Hendrata Dharmawan",
      "Alina Oprea",
      "Peter Chin"
    ],
    "abstract": "Cyber defense requires automating defensive decision-making under stealthy, deceptive, and continuously evolving adversarial strategies. The FlipIt game provides a foundational framework for modeling interactions between a defender and an advanced adversary that compromises a system without being immediately detected. In FlipIt, the attacker and defender compete to control a shared resource by performing a Flip action and paying a cost. However, the existing FlipIt frameworks rely on a small number of heuristics or specialized learning techniques, which can lead to brittleness and the inability to adapt to new attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym environment that extends the FlipIt game to allow efficient learning for attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent reinforcement learning (MARL) approach that leverages population-based training to train defender agents equipped to generalize against a range of unknown, potentially adaptive opponents. Our empirical results suggest that Flip-PSRO defenders are $2\\times$ more effective than baselines to generalize to a heuristic attack not exposed in training. In addition, our newly designed ownership-based utility functions ensure that Flip-PSRO defenders maintain a high level of control while optimizing performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at GameSec 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.19488v1",
    "published_date": "2025-08-27 00:18:49 UTC",
    "updated_date": "2025-08-27 00:18:49 UTC"
  },
  {
    "arxiv_id": "2508.19487v1",
    "title": "Data-Efficient Symbolic Regression via Foundation Model Distillation",
    "authors": [
      "Wangyang Ying",
      "Jinghan Zhang",
      "Haoyue Bai",
      "Nanxu Gong",
      "Xinyuan Wang",
      "Kunpeng Liu",
      "Chandan K. Reddy",
      "Yanjie Fu"
    ],
    "abstract": "Discovering interpretable mathematical equations from observed data (a.k.a. equation discovery or symbolic regression) is a cornerstone of scientific discovery, enabling transparent modeling of physical, biological, and economic systems. While foundation models pre-trained on large-scale equation datasets offer a promising starting point, they often suffer from negative transfer and poor generalization when applied to small, domain-specific datasets. In this paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer Embeddings), a data-efficient fine-tuning framework that adapts foundation models for symbolic equation discovery in low-data regimes via distillation. EQUATE combines symbolic-numeric alignment with evaluator-guided embedding optimization, enabling a principled embedding-search-generation paradigm. Our approach reformulates discrete equation search as a continuous optimization task in a shared embedding space, guided by data-equation fitness and simplicity. Experiments across three standard public benchmarks (Feynman, Strogatz, and black-box datasets) demonstrate that EQUATE consistently outperforms state-of-the-art baselines in both accuracy and robustness, while preserving low complexity and fast inference. These results highlight EQUATE as a practical and generalizable solution for data-efficient symbolic regression in foundation model distillation settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.19487v1",
    "published_date": "2025-08-27 00:18:48 UTC",
    "updated_date": "2025-08-27 00:18:48 UTC"
  }
]