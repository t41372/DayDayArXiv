[
  {
    "arxiv_id": "2405.18663v1",
    "title": "Lifelong Learning and Selective Forgetting via Contrastive Strategy",
    "authors": [
      "Lianlei Shan",
      "Wenzhang Zhou",
      "Wei Li",
      "Xingyu Ding"
    ],
    "abstract": "Lifelong learning aims to train a model with good performance for new tasks\nwhile retaining the capacity of previous tasks. However, some practical\nscenarios require the system to forget undesirable knowledge due to privacy\nissues, which is called selective forgetting. The joint task of the two is\ndubbed Learning with Selective Forgetting (LSF). In this paper, we propose a\nnew framework based on contrastive strategy for LSF. Specifically, for the\npreserved classes (tasks), we make features extracted from different samples\nwithin a same class compacted. And for the deleted classes, we make the\nfeatures from different samples of a same class dispersed and irregular, i.e.,\nthe network does not have any regular response to samples from a specific\ndeleted class as if the network has no training at all. Through maintaining or\ndisturbing the feature distribution, the forgetting and memory of different\nclasses can be or independent of each other. Experiments are conducted on four\nbenchmark datasets, and our method acieves new state-of-the-art.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figure",
    "pdf_url": "http://arxiv.org/pdf/2405.18663v1",
    "published_date": "2024-05-28 23:57:48 UTC",
    "updated_date": "2024-05-28 23:57:48 UTC"
  },
  {
    "arxiv_id": "2405.18658v1",
    "title": "D-CoRP: Differentiable Connectivity Refinement for Functional Brain Networks",
    "authors": [
      "Haoyu Hu",
      "Hongrun Zhang",
      "Chao Li"
    ],
    "abstract": "Brain network is an important tool for understanding the brain, offering\ninsights for scientific research and clinical diagnosis. Existing models for\nbrain networks typically primarily focus on brain regions or overlook the\ncomplexity of brain connectivities. MRI-derived brain network data is commonly\nsusceptible to connectivity noise, underscoring the necessity of incorporating\nconnectivities into the modeling of brain networks. To address this gap, we\nintroduce a differentiable module for refining brain connectivity. We develop\nthe multivariate optimization based on information bottleneck theory to address\nthe complexity of the brain network and filter noisy or redundant connections.\nAlso, our method functions as a flexible plugin that is adaptable to most graph\nneural networks. Our extensive experimental results show that the proposed\nmethod can significantly improve the performance of various baseline models and\noutperform other state-of-the-art methods, indicating the effectiveness and\ngeneralizability of the proposed method in refining brain network connectivity.\nThe code will be released for public availability.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18658v1",
    "published_date": "2024-05-28 23:49:52 UTC",
    "updated_date": "2024-05-28 23:49:52 UTC"
  },
  {
    "arxiv_id": "2405.18655v1",
    "title": "CAVACHON: a hierarchical variational autoencoder to integrate multi-modal single-cell data",
    "authors": [
      "Ping-Han Hsieh",
      "Ru-Xiu Hsiao",
      "Katalin Ferenc",
      "Anthony Mathelier",
      "Rebekka Burkholz",
      "Chien-Yu Chen",
      "Geir Kjetil Sandve",
      "Tatiana Belova",
      "Marieke Lydia Kuijjer"
    ],
    "abstract": "Paired single-cell sequencing technologies enable the simultaneous\nmeasurement of complementary modalities of molecular data at single-cell\nresolution. Along with the advances in these technologies, many methods based\non variational autoencoders have been developed to integrate these data.\nHowever, these methods do not explicitly incorporate prior biological\nrelationships between the data modalities, which could significantly enhance\nmodeling and interpretation. We propose a novel probabilistic learning\nframework that explicitly incorporates conditional independence relationships\nbetween multi-modal data as a directed acyclic graph using a generalized\nhierarchical variational autoencoder. We demonstrate the versatility of our\nframework across various applications pertinent to single-cell multi-omics data\nintegration. These include the isolation of common and distinct information\nfrom different modalities, modality-specific differential analysis, and\nintegrated cell clustering. We anticipate that the proposed framework can\nfacilitate the construction of highly flexible graphical models that can\ncapture the complexities of biological hypotheses and unravel the connections\nbetween different biological data types, such as different modalities of paired\nsingle-cell multi-omics data. The implementation of the proposed framework can\nbe found in the repository https://github.com/kuijjerlab/CAVACHON.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18655v1",
    "published_date": "2024-05-28 23:44:09 UTC",
    "updated_date": "2024-05-28 23:44:09 UTC"
  },
  {
    "arxiv_id": "2405.18650v1",
    "title": "Approximating Human Models During Argumentation-based Dialogues",
    "authors": [
      "Yinxu Tang",
      "Stylianos Loukas Vasileiou",
      "William Yeoh"
    ],
    "abstract": "Explainable AI Planning (XAIP) aims to develop AI agents that can effectively\nexplain their decisions and actions to human users, fostering trust and\nfacilitating human-AI collaboration. A key challenge in XAIP is model\nreconciliation, which seeks to align the mental models of AI agents and humans.\nWhile existing approaches often assume a known and deterministic human model,\nthis simplification may not capture the complexities and uncertainties of\nreal-world interactions. In this paper, we propose a novel framework that\nenables AI agents to learn and update a probabilistic human model through\nargumentation-based dialogues. Our approach incorporates trust-based and\ncertainty-based update mechanisms, allowing the agent to refine its\nunderstanding of the human's mental state based on the human's expressed trust\nin the agent's arguments and certainty in their own arguments. We employ a\nprobability weighting function inspired by prospect theory to capture the\nrelationship between trust and perceived probability, and use a Bayesian\napproach to update the agent's probability distribution over possible human\nmodels. We conduct a human-subject study to empirically evaluate the\neffectiveness of our approach in an argumentation scenario, demonstrating its\nability to capture the dynamics of human belief formation and adaptation.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18650v1",
    "published_date": "2024-05-28 23:22:18 UTC",
    "updated_date": "2024-05-28 23:22:18 UTC"
  },
  {
    "arxiv_id": "2405.18649v2",
    "title": "LeDex: Training LLMs to Better Self-Debug and Explain Code",
    "authors": [
      "Nan Jiang",
      "Xiaopeng Li",
      "Shiqi Wang",
      "Qiang Zhou",
      "Soneya Binta Hossain",
      "Baishakhi Ray",
      "Varun Kumar",
      "Xiaofei Ma",
      "Anoop Deoras"
    ],
    "abstract": "In the domain of code generation, self-debugging is crucial. It allows LLMs\nto refine their generated code based on execution feedback. This is\nparticularly important because generating correct solutions in one attempt\nproves challenging for complex tasks. Prior works on self-debugging mostly\nfocus on prompting methods by providing LLMs with few-shot examples, which work\npoorly on small open-sourced LLMs. In this work, we propose LeDex, a training\nframework that significantly improves the self-debugging capability of LLMs.\nIntuitively, we observe that a chain of explanations on the wrong code followed\nby code refinement helps LLMs better analyze the wrong code and do refinement.\nWe thus propose an automated pipeline to collect a high-quality dataset for\ncode explanation and refinement by generating a number of explanations and\nrefinement trajectories from the LLM itself or a larger teacher model and\nfiltering via execution verification. We perform supervised fine-tuning (SFT)\nand further reinforcement learning (RL) on both success and failure\ntrajectories with a novel reward design considering code explanation and\nrefinement quality. SFT improves the pass@1 by up to 15.92% and pass@10 by\n9.30% over four benchmarks. RL training brings additional up to 3.54%\nimprovement on pass@1 and 2.55% improvement on pass@10. The trained LLMs show\niterative refinement ability and can keep refining code continuously. Lastly,\nour human evaluation shows that the LLMs trained with our framework generate\nmore useful code explanations and help developers better understand bugs in\nsource code.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper is accepted by The Thirty-eighth Annual Conference on\n  Neural Information Processing Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.18649v2",
    "published_date": "2024-05-28 23:20:24 UTC",
    "updated_date": "2025-02-13 23:32:38 UTC"
  },
  {
    "arxiv_id": "2405.18642v1",
    "title": "JADS: A Framework for Self-supervised Joint Aspect Discovery and Summarization",
    "authors": [
      "Xiaobo Guo",
      "Jay Desai",
      "Srinivasan H. Sengamedu"
    ],
    "abstract": "To generate summaries that include multiple aspects or topics for text\ndocuments, most approaches use clustering or topic modeling to group relevant\nsentences and then generate a summary for each group. These approaches struggle\nto optimize the summarization and clustering algorithms jointly. On the other\nhand, aspect-based summarization requires known aspects. Our solution\nintegrates topic discovery and summarization into a single step. Given text\ndata, our Joint Aspect Discovery and Summarization algorithm (JADS) discovers\naspects from the input and generates a summary of the topics, in one step. We\npropose a self-supervised framework that creates a labeled dataset by first\nmixing sentences from multiple documents (e.g., CNN/DailyMail articles) as the\ninput and then uses the article summaries from the mixture as the labels. The\nJADS model outperforms the two-step baselines. With pretraining, the model\nachieves better performance and stability. Furthermore, embeddings derived from\nJADS exhibit superior clustering capabilities. Our proposed method achieves\nhigher semantic alignment with ground truth and is factual.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2405.18642v1",
    "published_date": "2024-05-28 23:01:57 UTC",
    "updated_date": "2024-05-28 23:01:57 UTC"
  },
  {
    "arxiv_id": "2405.18638v2",
    "title": "ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation for Generative Large Language Models",
    "authors": [
      "Aparna Elangovan",
      "Ling Liu",
      "Lei Xu",
      "Sravan Bodapati",
      "Dan Roth"
    ],
    "abstract": "In this position paper, we argue that human evaluation of generative large\nlanguage models (LLMs) should be a multidisciplinary undertaking that draws\nupon insights from disciplines such as user experience research and human\nbehavioral psychology to ensure that the experimental design and results are\nreliable. The conclusions from these evaluations, thus, must consider factors\nsuch as usability, aesthetics, and cognitive biases. We highlight how cognitive\nbiases can conflate fluent information and truthfulness, and how cognitive\nuncertainty affects the reliability of rating scores such as Likert.\nFurthermore, the evaluation should differentiate the capabilities and\nweaknesses of increasingly powerful large language models -- which requires\neffective test sets. The scalability of human evaluation is also crucial to\nwider adoption. Hence, to design an effective human evaluation system in the\nage of generative NLP, we propose the ConSiDERS-The-Human evaluation framework\nconsisting of 6 pillars -- Consistency, Scoring Criteria, Differentiating, User\nExperience, Responsible, and Scalability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18638v2",
    "published_date": "2024-05-28 22:45:28 UTC",
    "updated_date": "2024-08-31 05:17:17 UTC"
  },
  {
    "arxiv_id": "2405.18636v1",
    "title": "ChatGPT as the Marketplace of Ideas: Should Truth-Seeking Be the Goal of AI Content Governance?",
    "authors": [
      "Jiawei Zhang"
    ],
    "abstract": "As one of the most enduring metaphors within legal discourse, the marketplace\nof ideas has wielded considerable influence over the jurisprudential landscape\nfor decades. A century after the inception of this theory, ChatGPT emerged as a\nrevolutionary technological advancement in the twenty-first century. This\nresearch finds that ChatGPT effectively manifests the marketplace metaphor. It\nnot only instantiates the promises envisaged by generations of legal scholars\nbut also lays bare the perils discerned through sustained academic critique.\nSpecifically, the workings of ChatGPT and the marketplace of ideas theory\nexhibit at least four common features: arena, means, objectives, and flaws.\nThese shared attributes are sufficient to render ChatGPT historically the most\nqualified engine for actualizing the marketplace of ideas theory.\n  The comparison of the marketplace theory and ChatGPT merely marks a starting\npoint. A more meaningful undertaking entails reevaluating and reframing both\ninternal and external AI policies by referring to the accumulated experience,\ninsights, and suggestions researchers have raised to fix the marketplace\ntheory. Here, a pivotal issue is: should truth-seeking be set as the goal of AI\ncontent governance? Given the unattainability of the absolute truth-seeking\ngoal, I argue against adopting zero-risk policies. Instead, a more judicious\napproach would be to embrace a knowledge-based alternative wherein large\nlanguage models (LLMs) are trained to generate competing and divergent\nviewpoints based on sufficient justifications. This research also argues that\nso-called AI content risks are not created by AI companies but are inherent in\nthe entire information ecosystem. Thus, the burden of managing these risks\nshould be distributed among different social actors, rather than being solely\nshouldered by chatbot companies.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "cs.IT",
      "math.IT",
      "I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.18636v1",
    "published_date": "2024-05-28 22:38:24 UTC",
    "updated_date": "2024-05-28 22:38:24 UTC"
  },
  {
    "arxiv_id": "2405.19376v2",
    "title": "PureEBM: Universal Poison Purification via Mid-Run Dynamics of Energy-Based Models",
    "authors": [
      "Omead Pooladzandi",
      "Jeffrey Jiang",
      "Sunay Bhat",
      "Gregory Pottie"
    ],
    "abstract": "Data poisoning attacks pose a significant threat to the integrity of machine\nlearning models by leading to misclassification of target distribution data by\ninjecting adversarial examples during training. Existing state-of-the-art\n(SoTA) defense methods suffer from limitations, such as significantly reduced\ngeneralization performance and significant overhead during training, making\nthem impractical or limited for real-world applications. In response to this\nchallenge, we introduce a universal data purification method that defends\nnaturally trained classifiers from malicious white-, gray-, and black-box image\npoisons by applying a universal stochastic preprocessing step $\\Psi_{T}(x)$,\nrealized by iterative Langevin sampling of a convergent Energy Based Model\n(EBM) initialized with an image $x.$ Mid-run dynamics of $\\Psi_{T}(x)$ purify\npoison information with minimal impact on features important to the\ngeneralization of a classifier network. We show that EBMs remain universal\npurifiers, even in the presence of poisoned EBM training data, and achieve SoTA\ndefense on leading triggered and triggerless poisons. This work is a subset of\na larger framework introduced in \\pgen with a more detailed focus on EBM\npurification and poison defense.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2405.18627",
    "pdf_url": "http://arxiv.org/pdf/2405.19376v2",
    "published_date": "2024-05-28 22:31:56 UTC",
    "updated_date": "2024-06-02 20:21:45 UTC"
  },
  {
    "arxiv_id": "2405.18632v1",
    "title": "Large Language Models as Partners in Student Essay Evaluation",
    "authors": [
      "Toru Ishida",
      "Tongxi Liu",
      "Hailong Wang",
      "William K. Cheung"
    ],
    "abstract": "As the importance of comprehensive evaluation in workshop courses increases,\nthere is a growing demand for efficient and fair assessment methods that reduce\nthe workload for faculty members. This paper presents an evaluation conducted\nwith Large Language Models (LLMs) using actual student essays in three\nscenarios: 1) without providing guidance such as rubrics, 2) with pre-specified\nrubrics, and 3) through pairwise comparison of essays. Quantitative analysis of\nthe results revealed a strong correlation between LLM and faculty member\nassessments in the pairwise comparison scenario with pre-specified rubrics,\nalthough concerns about the quality and stability of evaluations remained.\nTherefore, we conducted a qualitative analysis of LLM assessment comments,\nshowing that: 1) LLMs can match the assessment capabilities of faculty members,\n2) variations in LLM assessments should be interpreted as diversity rather than\nconfusion, and 3) assessments by humans and LLMs can differ and complement each\nother. In conclusion, this paper suggests that LLMs should not be seen merely\nas assistants to faculty members but as partners in evaluation committees and\noutlines directions for further research.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18632v1",
    "published_date": "2024-05-28 22:28:50 UTC",
    "updated_date": "2024-05-28 22:28:50 UTC"
  },
  {
    "arxiv_id": "2405.18627v2",
    "title": "PureGen: Universal Data Purification for Train-Time Poison Defense via Generative Model Dynamics",
    "authors": [
      "Sunay Bhat",
      "Jeffrey Jiang",
      "Omead Pooladzandi",
      "Alexander Branch",
      "Gregory Pottie"
    ],
    "abstract": "Train-time data poisoning attacks threaten machine learning models by\nintroducing adversarial examples during training, leading to misclassification.\nCurrent defense methods often reduce generalization performance, are\nattack-specific, and impose significant training overhead. To address this, we\nintroduce a set of universal data purification methods using a stochastic\ntransform, $\\Psi(x)$, realized via iterative Langevin dynamics of Energy-Based\nModels (EBMs), Denoising Diffusion Probabilistic Models (DDPMs), or both. These\napproaches purify poisoned data with minimal impact on classifier\ngeneralization. Our specially trained EBMs and DDPMs provide state-of-the-art\ndefense against various attacks (including Narcissus, Bullseye Polytope,\nGradient Matching) on CIFAR-10, Tiny-ImageNet, and CINIC-10, without needing\nattack or classifier-specific information. We discuss performance trade-offs\nand show that our methods remain highly effective even with poisoned or\ndistributionally shifted generative model training data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18627v2",
    "published_date": "2024-05-28 22:19:26 UTC",
    "updated_date": "2024-06-02 20:11:50 UTC"
  },
  {
    "arxiv_id": "2405.18626v2",
    "title": "Causal Contextual Bandits with Adaptive Context",
    "authors": [
      "Rahul Madhavan",
      "Aurghya Maiti",
      "Gaurav Sinha",
      "Siddharth Barman"
    ],
    "abstract": "We study a variant of causal contextual bandits where the context is chosen\nbased on an initial intervention chosen by the learner. At the beginning of\neach round, the learner selects an initial action, depending on which a\nstochastic context is revealed by the environment. Following this, the learner\nthen selects a final action and receives a reward. Given $T$ rounds of\ninteractions with the environment, the objective of the learner is to learn a\npolicy (of selecting the initial and the final action) with maximum expected\nreward. In this paper we study the specific situation where every action\ncorresponds to intervening on a node in some known causal graph. We extend\nprior work from the deterministic context setting to obtain simple regret\nminimization guarantees. This is achieved through an instance-dependent causal\nparameter, $\\lambda$, which characterizes our upper bound. Furthermore, we\nprove that our simple regret is essentially tight for a large class of\ninstances. A key feature of our work is that we use convex optimization to\naddress the bandit exploration problem. We also conduct experiments to validate\nour theoretical results, and release our code at our project GitHub repository:\nhttps://github.com/adaptiveContextualCausalBandits/aCCB.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Reinforcement Learning Conference (RLC) 2024, 10 pages (31 pages\n  including appendix), 8 plots. arXiv admin note: text overlap with\n  arXiv:2111.00886",
    "pdf_url": "http://arxiv.org/pdf/2405.18626v2",
    "published_date": "2024-05-28 22:17:57 UTC",
    "updated_date": "2024-06-02 13:54:06 UTC"
  },
  {
    "arxiv_id": "2405.18624v1",
    "title": "Enhancing IoT Security with CNN and LSTM-Based Intrusion Detection Systems",
    "authors": [
      "Afrah Gueriani",
      "Hamza Kheddar",
      "Ahmed Cherif Mazari"
    ],
    "abstract": "Protecting Internet of things (IoT) devices against cyber attacks is\nimperative owing to inherent security vulnerabilities. These vulnerabilities\ncan include a spectrum of sophisticated attacks that pose significant damage to\nboth individuals and organizations. Employing robust security measures like\nintrusion detection systems (IDSs) is essential to solve these problems and\nprotect IoT systems from such attacks. In this context, our proposed IDS model\nconsists on a combination of convolutional neural network (CNN) and long\nshort-term memory (LSTM) deep learning (DL) models. This fusion facilitates the\ndetection and classification of IoT traffic into binary categories, benign and\nmalicious activities by leveraging the spatial feature extraction capabilities\nof CNN for pattern recognition and the sequential memory retention of LSTM for\ndiscerning complex temporal dependencies in achieving enhanced accuracy and\nefficiency. In assessing the performance of our proposed model, the authors\nemployed the new CICIoT2023 dataset for both training and final testing, while\nfurther validating the model's performance through a conclusive testing phase\nutilizing the CICIDS2017 dataset. Our proposed model achieves an accuracy rate\nof 98.42%, accompanied by a minimal loss of 0.0275. False positive rate(FPR) is\nequally important, reaching 9.17% with an F1-score of 98.57%. These results\ndemonstrate the effectiveness of our proposed CNN-LSTM IDS model in fortifying\nIoT environments against potential cyber threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18624v1",
    "published_date": "2024-05-28 22:12:15 UTC",
    "updated_date": "2024-05-28 22:12:15 UTC"
  },
  {
    "arxiv_id": "2405.18620v2",
    "title": "RealitySummary: Exploring On-Demand Mixed Reality Text Summarization and Question Answering using Large Language Models",
    "authors": [
      "Aditya Gunturu",
      "Shivesh Jadon",
      "Nandi Zhang",
      "Morteza Faraji",
      "Jarin Thundathil",
      "Tafreed Ahmad",
      "Wesley Willett",
      "Ryo Suzuki"
    ],
    "abstract": "Large Language Models (LLMs) are gaining popularity as tools for reading and\nsummarization aids. However, little is known about their potential benefits\nwhen integrated with mixed reality (MR) interfaces to support everyday reading\nassistants. We developed RealitySummary, an MR reading assistant that\nseamlessly integrates LLMs with always-on camera access, OCR-based text\nextraction, and augmented spatial and visual responses in MR interfaces.\nDeveloped iteratively, RealitySummary evolved across three versions, each\nshaped by user feedback and reflective analysis: 1) a preliminary user study to\nunderstand user perceptions (N=12), 2) an in-the-wild deployment to explore\nreal-world usage (N=11), and 3) a diary study to capture insights from\nreal-world work contexts (N=5). Our findings highlight the unique advantages of\ncombining AI and MR, including an always-on implicit assistant, minimal context\nswitching, and spatial affordances, demonstrating significant potential for\nfuture LLM-MR interfaces beyond traditional screen-based interactions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18620v2",
    "published_date": "2024-05-28 21:59:56 UTC",
    "updated_date": "2024-09-20 18:57:13 UTC"
  },
  {
    "arxiv_id": "2407.13070v2",
    "title": "The Cost of Arbitrariness for Individuals: Examining the Legal and Technical Challenges of Model Multiplicity",
    "authors": [
      "Prakhar Ganesh",
      "Ihsan Ibrahim Daldaban",
      "Ignacio Cofone",
      "Golnoosh Farnadi"
    ],
    "abstract": "Model multiplicity, the phenomenon where multiple models achieve similar\nperformance despite different underlying learned functions, introduces\narbitrariness in model selection. While this arbitrariness may seem\ninconsequential in expectation, its impact on individuals can be severe. This\npaper explores various individual concerns stemming from multiplicity,\nincluding the effects of arbitrariness beyond final predictions, disparate\narbitrariness for individuals belonging to protected groups, and the challenges\nassociated with the arbitrariness of a single algorithmic system creating a\nmonopoly across various contexts. It provides both an empirical examination of\nthese concerns and a comprehensive analysis from the legal standpoint,\naddressing how these issues are perceived in the anti-discrimination law in\nCanada. We conclude the discussion with technical challenges in the current\nlandscape of model multiplicity to meet legal requirements and the legal gap\nbetween current law and the implications of arbitrariness in model selection,\nhighlighting relevant future research directions for both disciplines.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Current version of the paper contains errors in the attribution of\n  previous work. We are working on creating a new version, which can take a\n  while and thus are withdrawing this version in the meantime",
    "pdf_url": "http://arxiv.org/pdf/2407.13070v2",
    "published_date": "2024-05-28 21:54:03 UTC",
    "updated_date": "2024-09-13 09:33:20 UTC"
  },
  {
    "arxiv_id": "2405.18610v1",
    "title": "DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime",
    "authors": [
      "Zhiyao Luo",
      "Mingcheng Zhu",
      "Fenglin Liu",
      "Jiali Li",
      "Yangchen Pan",
      "Jiandong Zhou",
      "Tingting Zhu"
    ],
    "abstract": "Reinforcement learning (RL) has garnered increasing recognition for its\npotential to optimise dynamic treatment regimes (DTRs) in personalised\nmedicine, particularly for drug dosage prescriptions and medication\nrecommendations. However, a significant challenge persists: the absence of a\nunified framework for simulating diverse healthcare scenarios and a\ncomprehensive analysis to benchmark the effectiveness of RL algorithms within\nthese contexts. To address this gap, we introduce \\textit{DTR-Bench}, a\nbenchmarking platform comprising four distinct simulation environments tailored\nto common DTR applications, including cancer chemotherapy, radiotherapy,\nglucose management in diabetes, and sepsis treatment. We evaluate various\nstate-of-the-art RL algorithms across these settings, particularly highlighting\ntheir performance amidst real-world challenges such as\npharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data.\nOur experiments reveal varying degrees of performance degradation among RL\nalgorithms in the presence of noise and patient variability, with some\nalgorithms failing to converge. Additionally, we observe that using temporal\nobservation representations does not consistently lead to improved performance\nin DTR settings. Our findings underscore the necessity of developing robust,\nadaptive RL algorithms capable of effectively managing these complexities to\nenhance patient-specific healthcare. We have open-sourced our benchmark and\ncode at https://github.com/GilesLuo/DTR-Bench.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages for main content",
    "pdf_url": "http://arxiv.org/pdf/2405.18610v1",
    "published_date": "2024-05-28 21:40:00 UTC",
    "updated_date": "2024-05-28 21:40:00 UTC"
  },
  {
    "arxiv_id": "2405.18602v2",
    "title": "SST-GCN: The Sequential based Spatio-Temporal Graph Convolutional networks for Minute-level and Road-level Traffic Accident Risk Prediction",
    "authors": [
      "Tae-wook Kim",
      "Han-jin Lee",
      "Hyeon-Jin Jung",
      "Ji-Woong Yang",
      "Ellen J. Hong"
    ],
    "abstract": "Traffic accidents are recognized as a major social issue worldwide, causing\nnumerous injuries and significant costs annually. Consequently, methods for\npredicting and preventing traffic accidents have been researched for many\nyears. With advancements in the field of artificial intelligence, various\nstudies have applied Machine Learning and Deep Learning techniques to traffic\naccident prediction. Modern traffic conditions change rapidly by the minute,\nand these changes vary significantly across different roads. In other words,\nthe risk of traffic accidents changes minute by minute in various patterns for\neach road. Therefore, it is desirable to predict traffic accident risk at the\nMinute-Level and Road-Level. However, because roads have close and complex\nrelationships with adjacent roads, research on predicting traffic accidents at\nthe Minute-Level and Road-Level is challenging. Thus, it is essential to build\na model that can reflect the spatial and temporal characteristics of roads for\ntraffic accident prediction. Consequently, recent attempts have been made to\nuse Graph Convolutional Networks to capture the spatial characteristics of\nroads and Recurrent Neural Networks to capture their temporal characteristics\nfor predicting traffic accident risk. This paper proposes the Sequential based\nSpatio-Temporal Graph Convolutional Networks (SST-GCN), which combines GCN and\nLSTM, to predict traffic accidents at the Minute-Level and Road-Level using a\nroad dataset constructed in Seoul, the capital of South Korea. Experiments have\ndemonstrated that SST-GCN outperforms other state-of-the-art models in\nMinute-Level predictions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18602v2",
    "published_date": "2024-05-28 21:33:18 UTC",
    "updated_date": "2024-06-03 08:44:05 UTC"
  },
  {
    "arxiv_id": "2405.18581v1",
    "title": "Unleashing the Potential of Text-attributed Graphs: Automatic Relation Decomposition via Large Language Models",
    "authors": [
      "Hyunjin Seo",
      "Taewon Kim",
      "June Yong Yang",
      "Eunho Yang"
    ],
    "abstract": "Recent advancements in text-attributed graphs (TAGs) have significantly\nimproved the quality of node features by using the textual modeling\ncapabilities of language models. Despite this success, utilizing text\nattributes to enhance the predefined graph structure remains largely\nunexplored. Our extensive analysis reveals that conventional edges on TAGs,\ntreated as a single relation (e.g., hyperlinks) in previous literature,\nactually encompass mixed semantics (e.g., \"advised by\" and \"participates in\").\nThis simplification hinders the representation learning process of Graph Neural\nNetworks (GNNs) on downstream tasks, even when integrated with advanced node\nfeatures. In contrast, we discover that decomposing these edges into distinct\nsemantic relations significantly enhances the performance of GNNs. Despite\nthis, manually identifying and labeling of edges to corresponding semantic\nrelations is labor-intensive, often requiring domain expertise. To this end, we\nintroduce RoSE (Relation-oriented Semantic Edge-decomposition), a novel\nframework that leverages the capability of Large Language Models (LLMs) to\ndecompose the graph structure by analyzing raw text attributes - in a fully\nautomated manner. RoSE operates in two stages: (1) identifying meaningful\nrelations using an LLM-based generator and discriminator, and (2) categorizing\neach edge into corresponding relations by analyzing textual contents associated\nwith connected nodes via an LLM-based decomposer. Extensive experiments\ndemonstrate that our model-agnostic framework significantly enhances node\nclassification performance across various datasets, with improvements of up to\n16% on the Wisconsin dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18581v1",
    "published_date": "2024-05-28 20:54:47 UTC",
    "updated_date": "2024-05-28 20:54:47 UTC"
  },
  {
    "arxiv_id": "2405.18580v3",
    "title": "Artificial Intelligence in Industry 4.0: A Review of Integration Challenges for Industrial Systems",
    "authors": [
      "Alexander Windmann",
      "Philipp Wittenberg",
      "Marvin Schieseck",
      "Oliver Niggemann"
    ],
    "abstract": "In Industry 4.0, Cyber-Physical Systems (CPS) generate vast data sets that\ncan be leveraged by Artificial Intelligence (AI) for applications including\npredictive maintenance and production planning. However, despite the\ndemonstrated potential of AI, its widespread adoption in sectors like\nmanufacturing remains limited. Our comprehensive review of recent literature,\nincluding standards and reports, pinpoints key challenges: system integration,\ndata-related issues, managing workforce-related concerns and ensuring\ntrustworthy AI. A quantitative analysis highlights particular challenges and\ntopics that are important for practitioners but still need to be sufficiently\ninvestigated by academics. The paper briefly discusses existing solutions to\nthese challenges and proposes avenues for future research. We hope that this\nsurvey serves as a resource for practitioners evaluating the cost-benefit\nimplications of AI in CPS and for researchers aiming to address these urgent\nchallenges.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 4 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2405.18580v3",
    "published_date": "2024-05-28 20:54:41 UTC",
    "updated_date": "2024-12-17 07:35:35 UTC"
  },
  {
    "arxiv_id": "2405.18572v1",
    "title": "Low-rank finetuning for LLMs: A fairness perspective",
    "authors": [
      "Saswat Das",
      "Marco Romanelli",
      "Cuong Tran",
      "Zarreen Reza",
      "Bhavya Kailkhura",
      "Ferdinando Fioretto"
    ],
    "abstract": "Low-rank approximation techniques have become the de facto standard for\nfine-tuning Large Language Models (LLMs) due to their reduced computational and\nmemory requirements. This paper investigates the effectiveness of these methods\nin capturing the shift of fine-tuning datasets from the initial pre-trained\ndata distribution. Our findings reveal that there are cases in which low-rank\nfine-tuning falls short in learning such shifts. This, in turn, produces\nnon-negligible side effects, especially when fine-tuning is adopted for\ntoxicity mitigation in pre-trained models, or in scenarios where it is\nimportant to provide fair models. Through comprehensive empirical evidence on\nseveral models, datasets, and tasks, we show that low-rank fine-tuning\ninadvertently preserves undesirable biases and toxic behaviors. We also show\nthat this extends to sequential decision-making tasks, emphasizing the need for\ncareful evaluation to promote responsible LLMs development.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18572v1",
    "published_date": "2024-05-28 20:43:53 UTC",
    "updated_date": "2024-05-28 20:43:53 UTC"
  },
  {
    "arxiv_id": "2405.18560v4",
    "title": "Potential Field Based Deep Metric Learning",
    "authors": [
      "Shubhang Bhatnagar",
      "Narendra Ahuja"
    ],
    "abstract": "Deep metric learning (DML) involves training a network to learn a\nsemantically meaningful representation space. Many current approaches mine\nn-tuples of examples and model interactions within each tuplets. We present a\nnovel, compositional DML model that instead of in tuples, represents the\ninfluence of each example (embedding) by a continuous potential field, and\nsuperposes the fields to obtain their combined global potential field. We use\nattractive/repulsive potential fields to represent interactions among\nembeddings from images of the same/different classes. Contrary to typical\nlearning methods, where mutual influence of samples is proportional to their\ndistance, we enforce reduction in such influence with distance, leading to a\ndecaying field. We show that such decay helps improve performance on real world\ndatasets with large intra-class variations and label noise. Like other\nproxy-based methods, we also use proxies to succinctly represent\nsub-populations of examples. We evaluate our method on three standard DML\nbenchmarks- Cars-196, CUB-200-2011, and SOP datasets where it outperforms\nstate-of-the-art baselines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.18560v4",
    "published_date": "2024-05-28 20:10:06 UTC",
    "updated_date": "2025-04-19 09:27:53 UTC"
  },
  {
    "arxiv_id": "2405.18556v2",
    "title": "Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination",
    "authors": [
      "Zhiyao Luo",
      "Yangchen Pan",
      "Peter Watkinson",
      "Tingting Zhu"
    ],
    "abstract": "In the rapidly changing healthcare landscape, the implementation of offline\nreinforcement learning (RL) in dynamic treatment regimes (DTRs) presents a mix\nof unprecedented opportunities and challenges. This position paper offers a\ncritical examination of the current status of offline RL in the context of\nDTRs. We argue for a reassessment of applying RL in DTRs, citing concerns such\nas inconsistent and potentially inconclusive evaluation metrics, the absence of\nnaive and supervised learning baselines, and the diverse choice of RL\nformulation in existing research. Through a case study with more than 17,000\nevaluation experiments using a publicly available Sepsis dataset, we\ndemonstrate that the performance of RL algorithms can significantly vary with\nchanges in evaluation metrics and Markov Decision Process (MDP) formulations.\nSurprisingly, it is observed that in some instances, RL algorithms can be\nsurpassed by random baselines subjected to policy evaluation methods and reward\ndesign. This calls for more careful policy evaluation and algorithm development\nin future DTR works. Additionally, we discussed potential enhancements toward\nmore reliable development of RL-based dynamic treatment regimes and invited\nfurther discussion within the community. Code is available at\nhttps://github.com/GilesLuo/ReassessDTR.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024. 9 pages for main content, 34 pages in total",
    "pdf_url": "http://arxiv.org/pdf/2405.18556v2",
    "published_date": "2024-05-28 20:03:18 UTC",
    "updated_date": "2024-06-03 20:16:11 UTC"
  },
  {
    "arxiv_id": "2405.18553v4",
    "title": "FAIIR: Building Toward A Conversational AI Agent Assistant for Youth Mental Health Service Provision",
    "authors": [
      "Stephen Obadinma",
      "Alia Lachana",
      "Maia Norman",
      "Jocelyn Rankin",
      "Joanna Yu",
      "Xiaodan Zhu",
      "Darren Mastropaolo",
      "Deval Pandya",
      "Roxana Sultan",
      "Elham Dolatabadi"
    ],
    "abstract": "The world's healthcare systems and mental health agencies face both a growing\ndemand for youth mental health services, alongside a simultaneous challenge of\nlimited resources. Here, we focus on frontline crisis support, where Crisis\nResponders (CRs) engage in conversations for youth mental health support and\nassign an issue tag to each conversation. In this study, we develop FAIIR\n(Frontline Assistant: Issue Identification and Recommendation), an advanced\ntool leveraging an ensemble of domain-adapted and fine-tuned transformer models\ntrained on a large conversational dataset comprising 780,000 conversations. The\nprimary aim is to reduce the cognitive burden on CRs, enhance the accuracy of\nissue identification, and streamline post-conversation administrative tasks. We\nevaluate FAIIR on both retrospective and prospective conversations, emphasizing\nhuman-in-the-loop design with active CR engagement for model refinement,\nconsensus-building, and overall assessment. Our results indicate that FAIIR\nachieves an average AUCROC of 94%, a sample average F1-score of 64%, and a\nsample average recall score of 81% on the retrospective test set. We also\ndemonstrate the robustness and generalizability of the FAIIR tool during the\nsilent testing phase, with less than a 2% drop in all performance metrics.\nNotably, CRs' responses exhibited an overall agreement of 90.9% with FAIIR's\npredictions. Furthermore, expert agreement with FAIIR surpassed their agreement\nwith the original labels. To conclude, our findings indicate that assisting\nwith the identification of issues of relevance helps reduce the burden on CRs,\nensuring that appropriate resources can be provided and that active rescues and\nmandatory reporting can take place in critical situations requiring immediate\nde-escalation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18553v4",
    "published_date": "2024-05-28 19:54:46 UTC",
    "updated_date": "2025-02-12 00:23:30 UTC"
  },
  {
    "arxiv_id": "2405.18548v3",
    "title": "Transformer Encoder Satisfiability: Complexity and Impact on Formal Reasoning",
    "authors": [
      "Marco Sälzer",
      "Eric Alsmann",
      "Martin Lange"
    ],
    "abstract": "We analyse the complexity of the satisfiability problem, or similarly\nfeasibility problem, (trSAT) for transformer encoders (TE), which naturally\noccurs in formal verification or interpretation, collectively referred to as\nformal reasoning. We find that trSAT is undecidable when considering TE as they\nare commonly studied in the expressiveness community. Furthermore, we identify\npractical scenarios where trSAT is decidable and establish corresponding\ncomplexity bounds. Beyond trivial cases, we find that quantized TE, those\nrestricted by fixed-width arithmetic, lead to the decidability of trSAT due to\ntheir limited attention capabilities. However, the problem remains difficult,\nas we establish scenarios where trSAT is NEXPTIME-hard and others where it is\nsolvable in NEXPTIME for quantized TE. To complement our complexity results, we\nplace our findings and their implications in the broader context of formal\nreasoning.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.CC",
      "cs.LG"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18548v3",
    "published_date": "2024-05-28 19:30:43 UTC",
    "updated_date": "2025-02-25 06:37:14 UTC"
  },
  {
    "arxiv_id": "2405.18542v1",
    "title": "Automatic detection of cognitive impairment in elderly people using an entertainment chatbot with Natural Language Processing capabilities",
    "authors": [
      "Francisco de Arriba-Pérez",
      "Silvia García-Méndez",
      "Francisco J. González-Castaño",
      "Enrique Costa-Montenegro"
    ],
    "abstract": "Previous researchers have proposed intelligent systems for therapeutic\nmonitoring of cognitive impairments. However, most existing practical\napproaches for this purpose are based on manual tests. This raises issues such\nas excessive caretaking effort and the white-coat effect. To avoid these\nissues, we present an intelligent conversational system for entertaining\nelderly people with news of their interest that monitors cognitive impairment\ntransparently. Automatic chatbot dialogue stages allow assessing content\ndescription skills and detecting cognitive impairment with Machine Learning\nalgorithms. We create these dialogue flows automatically from updated news\nitems using Natural Language Generation techniques. The system also infers the\ngold standard of the answers to the questions, so it can assess cognitive\ncapabilities automatically by comparing these answers with the user responses.\nIt employs a similarity metric with values in [0, 1], in increasing level of\nsimilarity. To evaluate the performance and usability of our approach, we have\nconducted field tests with a test group of 30 elderly people in the earliest\nstages of dementia, under the supervision of gerontologists. In the\nexperiments, we have analysed the effect of stress and concentration in these\nusers. Those without cognitive impairment performed up to five times better. In\nparticular, the similarity metric varied between 0.03, for stressed and\nunfocused participants, and 0.36, for relaxed and focused users. Finally, we\ndeveloped a Machine Learning algorithm based on textual analysis features for\nautomatic cognitive impairment detection, which attained accuracy, F-measure\nand recall levels above 80%. We have thus validated the automatic approach to\ndetect cognitive impairment in elderly people based on entertainment content.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18542v1",
    "published_date": "2024-05-28 19:17:48 UTC",
    "updated_date": "2024-05-28 19:17:48 UTC"
  },
  {
    "arxiv_id": "2405.18523v2",
    "title": "MM-Mixing: Multi-Modal Mixing Alignment for 3D Understanding",
    "authors": [
      "Jiaze Wang",
      "Yi Wang",
      "Ziyu Guo",
      "Renrui Zhang",
      "Donghao Zhou",
      "Guangyong Chen",
      "Anfeng Liu",
      "Pheng-Ann Heng"
    ],
    "abstract": "We introduce MM-Mixing, a multi-modal mixing alignment framework for 3D\nunderstanding. MM-Mixing applies mixing-based methods to multi-modal data,\npreserving and optimizing cross-modal connections while enhancing diversity and\nimproving alignment across modalities. Our proposed two-stage training pipeline\ncombines feature-level and input-level mixing to optimize the 3D encoder. The\nfirst stage employs feature-level mixing with contrastive learning to align 3D\nfeatures with their corresponding modalities. The second stage incorporates\nboth feature-level and input-level mixing, introducing mixed point cloud inputs\nto further refine 3D feature representations. MM-Mixing enhances intermodality\nrelationships, promotes generalization, and ensures feature consistency while\nproviding diverse and realistic training samples. We demonstrate that MM-Mixing\nsignificantly improves baseline performance across various learning scenarios,\nincluding zero-shot 3D classification, linear probing 3D classification, and\ncross-modal 3D shape retrieval. Notably, we improved the zero-shot\nclassification accuracy on ScanObjectNN from 51.3% to 61.9%, and on\nObjaverse-LVIS from 46.8% to 51.4%. Our findings highlight the potential of\nmulti-modal mixing-based alignment to significantly advance 3D object\nrecognition and understanding while remaining straightforward to implement and\nintegrate into existing frameworks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18523v2",
    "published_date": "2024-05-28 18:44:15 UTC",
    "updated_date": "2024-08-19 08:26:25 UTC"
  },
  {
    "arxiv_id": "2405.18520v1",
    "title": "Offline-Boosted Actor-Critic: Adaptively Blending Optimal Historical Behaviors in Deep Off-Policy RL",
    "authors": [
      "Yu Luo",
      "Tianying Ji",
      "Fuchun Sun",
      "Jianwei Zhang",
      "Huazhe Xu",
      "Xianyuan Zhan"
    ],
    "abstract": "Off-policy reinforcement learning (RL) has achieved notable success in\ntackling many complex real-world tasks, by leveraging previously collected data\nfor policy learning. However, most existing off-policy RL algorithms fail to\nmaximally exploit the information in the replay buffer, limiting sample\nefficiency and policy performance. In this work, we discover that concurrently\ntraining an offline RL policy based on the shared online replay buffer can\nsometimes outperform the original online learning policy, though the occurrence\nof such performance gains remains uncertain. This motivates a new possibility\nof harnessing the emergent outperforming offline optimal policy to improve\nonline policy learning. Based on this insight, we present Offline-Boosted\nActor-Critic (OBAC), a model-free online RL framework that elegantly identifies\nthe outperforming offline policy through value comparison, and uses it as an\nadaptive constraint to guarantee stronger policy learning performance. Our\nexperiments demonstrate that OBAC outperforms other popular model-free RL\nbaselines and rivals advanced model-based RL methods in terms of sample\nefficiency and asymptotic performance across 53 tasks spanning 6 task suites.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18520v1",
    "published_date": "2024-05-28 18:38:46 UTC",
    "updated_date": "2024-05-28 18:38:46 UTC"
  },
  {
    "arxiv_id": "2406.00050v2",
    "title": "An Empirical Analysis on Large Language Models in Debate Evaluation",
    "authors": [
      "Xinyi Liu",
      "Pinxin Liu",
      "Hangfeng He"
    ],
    "abstract": "In this study, we investigate the capabilities and inherent biases of\nadvanced large language models (LLMs) such as GPT-3.5 and GPT-4 in the context\nof debate evaluation. We discover that LLM's performance exceeds humans and\nsurpasses the performance of state-of-the-art methods fine-tuned on extensive\ndatasets in debate evaluation. We additionally explore and analyze biases\npresent in LLMs, including positional bias, lexical bias, order bias, which may\naffect their evaluative judgments. Our findings reveal a consistent bias in\nboth GPT-3.5 and GPT-4 towards the second candidate response presented,\nattributed to prompt design. We also uncover lexical biases in both GPT-3.5 and\nGPT-4, especially when label sets carry connotations such as numerical or\nsequential, highlighting the critical need for careful label verbalizer\nselection in prompt design. Additionally, our analysis indicates a tendency of\nboth models to favor the debate's concluding side as the winner, suggesting an\nend-of-discussion bias.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 main",
    "pdf_url": "http://arxiv.org/pdf/2406.00050v2",
    "published_date": "2024-05-28 18:34:53 UTC",
    "updated_date": "2024-06-04 14:51:25 UTC"
  },
  {
    "arxiv_id": "2405.18512v1",
    "title": "Understanding Transformer Reasoning Capabilities via Graph Algorithms",
    "authors": [
      "Clayton Sanford",
      "Bahare Fatemi",
      "Ethan Hall",
      "Anton Tsitsulin",
      "Mehran Kazemi",
      "Jonathan Halcrow",
      "Bryan Perozzi",
      "Vahab Mirrokni"
    ],
    "abstract": "Which transformer scaling regimes are able to perfectly solve different\nclasses of algorithmic problems? While tremendous empirical advances have been\nattained by transformer-based neural networks, a theoretical understanding of\ntheir algorithmic reasoning capabilities in realistic parameter regimes is\nlacking. We investigate this question in terms of the network's depth, width,\nand number of extra tokens for algorithm execution. Our novel representational\nhierarchy separates 9 algorithmic reasoning problems into classes solvable by\ntransformers in different realistic parameter scaling regimes. We prove that\nlogarithmic depth is necessary and sufficient for tasks like graph\nconnectivity, while single-layer transformers with small embedding dimensions\ncan solve contextual retrieval tasks. We also support our theoretical analysis\nwith ample empirical evidence using the GraphQA benchmark. These results show\nthat transformers excel at many graph reasoning tasks, even outperforming\nspecialized graph neural networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "43 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.18512v1",
    "published_date": "2024-05-28 18:31:14 UTC",
    "updated_date": "2024-05-28 18:31:14 UTC"
  },
  {
    "arxiv_id": "2405.18510v1",
    "title": "Improved Emotional Alignment of AI and Humans: Human Ratings of Emotions Expressed by Stable Diffusion v1, DALL-E 2, and DALL-E 3",
    "authors": [
      "James Derek Lomas",
      "Willem van der Maden",
      "Sohhom Bandyopadhyay",
      "Giovanni Lion",
      "Nirmal Patel",
      "Gyanesh Jain",
      "Yanna Litowsky",
      "Haian Xue",
      "Pieter Desmet"
    ],
    "abstract": "Generative AI systems are increasingly capable of expressing emotions via\ntext and imagery. Effective emotional expression will likely play a major role\nin the efficacy of AI systems -- particularly those designed to support human\nmental health and wellbeing. This motivates our present research to better\nunderstand the alignment of AI expressed emotions with the human perception of\nemotions. When AI tries to express a particular emotion, how might we assess\nwhether they are successful? To answer this question, we designed a survey to\nmeasure the alignment between emotions expressed by generative AI and human\nperceptions. Three generative image models (DALL-E 2, DALL-E 3 and Stable\nDiffusion v1) were used to generate 240 examples of images, each of which was\nbased on a prompt designed to express five positive and five negative emotions\nacross both humans and robots. 24 participants recruited from the Prolific\nwebsite rated the alignment of AI-generated emotional expressions with a text\nprompt used to generate the emotion (i.e., \"A robot expressing the emotion\namusement\"). The results of our evaluation suggest that generative AI models\nare indeed capable of producing emotional expressions that are well-aligned\nwith a range of human emotions; however, we show that the alignment\nsignificantly depends upon the AI model used and the emotion itself. We analyze\nvariations in the performance of these systems to identify gaps for future\nimprovement. We conclude with a discussion of the implications for future AI\nsystems designed to support mental health and wellbeing.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18510v1",
    "published_date": "2024-05-28 18:26:57 UTC",
    "updated_date": "2024-05-28 18:26:57 UTC"
  },
  {
    "arxiv_id": "2405.18507v4",
    "title": "Injecting Hierarchical Biological Priors into Graph Neural Networks for Flow Cytometry Prediction",
    "authors": [
      "Fatemeh Nassajian Mojarrad",
      "Lorenzo Bini",
      "Thomas Matthes",
      "Stéphane Marchand-Maillet"
    ],
    "abstract": "In the complex landscape of hematologic samples such as peripheral blood or\nbone marrow derived from flow cytometry (FC) data, cell-level prediction\npresents profound challenges. This work explores injecting hierarchical prior\nknowledge into graph neural networks (GNNs) for single-cell multi-class\nclassification of tabular cellular data. By representing the data as graphs and\nencoding hierarchical relationships between classes, we propose our\nhierarchical plug-in method to be applied to several GNN models, namely,\nFCHC-GNN, and effectively designed to capture neighborhood information crucial\nfor single-cell FC domain. Extensive experiments on our cohort of 19 distinct\npatients, demonstrate that incorporating hierarchical biological constraints\nboosts performance significantly across multiple metrics compared to baseline\nGNNs without such priors. The proposed approach highlights the importance of\nstructured inductive biases for gaining improved generalization in complex\nbiological prediction tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, ICML Conference Workshop 2024. arXiv admin note: text\n  overlap with arXiv:2402.18610",
    "pdf_url": "http://arxiv.org/pdf/2405.18507v4",
    "published_date": "2024-05-28 18:24:16 UTC",
    "updated_date": "2024-07-27 22:11:35 UTC"
  },
  {
    "arxiv_id": "2405.18492v3",
    "title": "LLMs and Memorization: On Quality and Specificity of Copyright Compliance",
    "authors": [
      "Felix B Mueller",
      "Rebekka Görge",
      "Anna K Bernzen",
      "Janna C Pirk",
      "Maximilian Poretschkin"
    ],
    "abstract": "Memorization in large language models (LLMs) is a growing concern. LLMs have\nbeen shown to easily reproduce parts of their training data, including\ncopyrighted work. This is an important problem to solve, as it may violate\nexisting copyright laws as well as the European AI Act. In this work, we\npropose a systematic analysis to quantify the extent of potential copyright\ninfringements in LLMs using European law as an example. Unlike previous work,\nwe evaluate instruction-finetuned models in a realistic end-user scenario. Our\nanalysis builds on a proposed threshold of 160 characters, which we borrow from\nthe German Copyright Service Provider Act and a fuzzy text matching algorithm\nto identify potentially copyright-infringing textual reproductions. The\nspecificity of countermeasures against copyright infringement is analyzed by\ncomparing model behavior on copyrighted and public domain data. We investigate\nwhat behaviors models show instead of producing protected text (such as refusal\nor hallucination) and provide a first legal assessment of these behaviors. We\nfind that there are huge differences in copyright compliance, specificity, and\nappropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminous\nperform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producing\na particularly low absolute number of potential copyright violations. Code can\nbe found at https://github.com/felixbmuller/llms-memorization-copyright.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures, AIES 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2405.18492v3",
    "published_date": "2024-05-28 18:01:52 UTC",
    "updated_date": "2024-11-18 09:44:26 UTC"
  },
  {
    "arxiv_id": "2405.18471v2",
    "title": "Symbolic Regression for Beyond the Standard Model Physics",
    "authors": [
      "Shehu AbdusSalam",
      "Steve Abel",
      "Miguel Crispim Romao"
    ],
    "abstract": "We propose symbolic regression as a powerful tool for studying Beyond the\nStandard Model physics. As a benchmark model, we consider the so-called\nConstrained Minimal Supersymmetric Standard Model, which has a four-dimensional\nparameter space defined at the GUT scale. We provide a set of analytical\nexpressions that reproduce three low-energy observables of interest in terms of\nthe parameters of the theory: the Higgs mass, the contribution to the anomalous\nmagnetic moment of the muon, and the cold dark matter relic density. To\ndemonstrate the power of the approach, we employ the symbolic expressions in a\nglobal fits analysis to derive the posterior probability densities of the\nparameters, which are obtained extremely rapidly in comparison with\nconventional methods.",
    "categories": [
      "hep-ph",
      "cs.AI",
      "cs.LG",
      "hep-th",
      "physics.comp-ph"
    ],
    "primary_category": "hep-ph",
    "comment": "Version accepted for publication in PRD. 8 pages, 10 figures. For\n  associated code and symbolic expressions see\n  https://gitlab.com/miguel.romao/symbolic-regression-bsm",
    "pdf_url": "http://arxiv.org/pdf/2405.18471v2",
    "published_date": "2024-05-28 18:00:01 UTC",
    "updated_date": "2025-04-22 14:35:40 UTC"
  },
  {
    "arxiv_id": "2405.18428v2",
    "title": "DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention",
    "authors": [
      "Lianghui Zhu",
      "Zilong Huang",
      "Bencheng Liao",
      "Jun Hao Liew",
      "Hanshu Yan",
      "Jiashi Feng",
      "Xinggang Wang"
    ],
    "abstract": "Diffusion models with large-scale pre-training have achieved significant\nsuccess in the field of visual content generation, particularly exemplified by\nDiffusion Transformers (DiT). However, DiT models have faced challenges with\nquadratic complexity efficiency, especially when handling long sequences. In\nthis paper, we aim to incorporate the sub-quadratic modeling capability of\nGated Linear Attention (GLA) into the 2D diffusion backbone. Specifically, we\nintroduce Diffusion Gated Linear Attention Transformers (DiG), a simple,\nadoptable solution with minimal parameter overhead. We offer two variants, i,e,\na plain and U-shape architecture, showing superior efficiency and competitive\neffectiveness. In addition to superior performance to DiT and other\nsub-quadratic-time diffusion models at $256 \\times 256$ resolution, DiG\ndemonstrates greater efficiency than these methods starting from a $512$\nresolution. Specifically, DiG-S/2 is $2.5\\times$ faster and saves $75.7\\%$ GPU\nmemory compared to DiT-S/2 at a $1792$ resolution. Additionally, DiG-XL/2 is\n$4.2\\times$ faster than the Mamba-based model at a $1024$ resolution and\n$1.8\\times$ faster than DiT with FlashAttention-2 at a $2048$ resolution. We\nwill release the code soon. Code is released at https://github.com/hustvl/DiG.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is released at https://github.com/hustvl/DiG",
    "pdf_url": "http://arxiv.org/pdf/2405.18428v2",
    "published_date": "2024-05-28 17:59:33 UTC",
    "updated_date": "2024-11-26 16:42:34 UTC"
  },
  {
    "arxiv_id": "2405.18427v1",
    "title": "Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets",
    "authors": [
      "Khen Cohen",
      "Noam Levi",
      "Yaron Oz"
    ],
    "abstract": "We derive closed-form expressions for the Bayes optimal decision boundaries\nin binary classification of high dimensional overlapping Gaussian mixture model\n(GMM) data, and show how they depend on the eigenstructure of the class\ncovariances, for particularly interesting structured data. We empirically\ndemonstrate, through experiments on synthetic GMMs inspired by real-world data,\nthat deep neural networks trained for classification, learn predictors which\napproximate the derived optimal classifiers. We further extend our study to\nnetworks trained on authentic data, observing that decision thresholds\ncorrelate with the covariance eigenvectors rather than the eigenvalues,\nmirroring our GMM analysis. This provides theoretical insights regarding neural\nnetworks' ability to perform probabilistic inference and distill statistical\npatterns from intricate distributions.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "19 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.18427v1",
    "published_date": "2024-05-28 17:59:31 UTC",
    "updated_date": "2024-05-28 17:59:31 UTC"
  },
  {
    "arxiv_id": "2405.18426v2",
    "title": "GFlow: Recovering 4D World from Monocular Video",
    "authors": [
      "Shizun Wang",
      "Xingyi Yang",
      "Qiuhong Shen",
      "Zhenxiang Jiang",
      "Xinchao Wang"
    ],
    "abstract": "Recovering 4D world from monocular video is a crucial yet challenging task.\nConventional methods usually rely on the assumptions of multi-view videos,\nknown camera parameters, or static scenes. In this paper, we relax all these\nconstraints and tackle a highly ambitious but practical task: With only one\nmonocular video without camera parameters, we aim to recover the dynamic 3D\nworld alongside the camera poses. To solve this, we introduce GFlow, a new\nframework that utilizes only 2D priors (depth and optical flow) to lift a video\nto a 4D scene, as a flow of 3D Gaussians through space and time. GFlow starts\nby segmenting the video into still and moving parts, then alternates between\noptimizing camera poses and the dynamics of the 3D Gaussian points. This method\nensures consistency among adjacent points and smooth transitions between\nframes. Since dynamic scenes always continually introduce new visual content,\nwe present prior-driven initialization and pixel-wise densification strategy\nfor Gaussian points to integrate new content. By combining all those\ntechniques, GFlow transcends the boundaries of 4D recovery from causal videos;\nit naturally enables tracking of points and segmentation of moving objects\nacross frames. Additionally, GFlow estimates the camera poses for each frame,\nenabling novel view synthesis by changing camera pose. This capability\nfacilitates extensive scene-level or object-level editing, highlighting GFlow's\nversatility and effectiveness. Visit our project page at:\nhttps://littlepure2333.github.io/GFlow",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2025. Project page: https://littlepure2333.github.io/GFlow",
    "pdf_url": "http://arxiv.org/pdf/2405.18426v2",
    "published_date": "2024-05-28 17:59:22 UTC",
    "updated_date": "2024-12-31 07:05:28 UTC"
  },
  {
    "arxiv_id": "2405.18425v2",
    "title": "ViG: Linear-complexity Visual Sequence Learning with Gated Linear Attention",
    "authors": [
      "Bencheng Liao",
      "Xinggang Wang",
      "Lianghui Zhu",
      "Qian Zhang",
      "Chang Huang"
    ],
    "abstract": "Recently, linear complexity sequence modeling networks have achieved modeling\ncapabilities similar to Vision Transformers on a variety of computer vision\ntasks, while using fewer FLOPs and less memory. However, their advantage in\nterms of actual runtime speed is not significant. To address this issue, we\nintroduce Gated Linear Attention (GLA) for vision, leveraging its superior\nhardware-awareness and efficiency. We propose direction-wise gating to capture\n1D global context through bidirectional modeling and a 2D gating locality\ninjection to adaptively inject 2D local details into 1D global context. Our\nhardware-aware implementation further merges forward and backward scanning into\na single kernel, enhancing parallelism and reducing memory cost and latency.\nThe proposed model, ViG, offers a favorable trade-off in accuracy, parameters,\nand FLOPs on ImageNet and downstream tasks, outperforming popular Transformer\nand CNN-based models. Notably, ViG-S matches DeiT-B's accuracy while using only\n27% of the parameters and 20% of the FLOPs, running 2$\\times$ faster on\n$224\\times224$ images. At $1024\\times1024$ resolution, ViG-T uses 5.2$\\times$\nfewer FLOPs, saves 90% GPU memory, runs 4.8$\\times$ faster, and achieves 20.7%\nhigher top-1 accuracy than DeiT-T. These results position ViG as an efficient\nand scalable solution for visual representation learning. Code is available at\n\\url{https://github.com/hustvl/ViG}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Work in progress. Code is available at\n  \\url{https://github.com/hustvl/ViG}",
    "pdf_url": "http://arxiv.org/pdf/2405.18425v2",
    "published_date": "2024-05-28 17:59:21 UTC",
    "updated_date": "2024-05-29 02:06:30 UTC"
  },
  {
    "arxiv_id": "2405.18415v2",
    "title": "Why are Visually-Grounded Language Models Bad at Image Classification?",
    "authors": [
      "Yuhui Zhang",
      "Alyssa Unell",
      "Xiaohan Wang",
      "Dhruba Ghosh",
      "Yuchang Su",
      "Ludwig Schmidt",
      "Serena Yeung-Levy"
    ],
    "abstract": "Image classification is one of the most fundamental capabilities of machine\nvision intelligence. In this work, we revisit the image classification task\nusing visually-grounded language models (VLMs) such as GPT-4V and LLaVA. We\nfind that existing proprietary and public VLMs, despite often using CLIP as a\nvision encoder and having many more parameters, significantly underperform CLIP\non standard image classification benchmarks like ImageNet. To understand the\nreason, we explore several hypotheses concerning the inference algorithms,\ntraining objectives, and data processing in VLMs. Our analysis reveals that the\nprimary cause is data-related: critical information for image classification is\nencoded in the VLM's latent space but can only be effectively decoded with\nenough training data. Specifically, there is a strong correlation between the\nfrequency of class exposure during VLM training and instruction-tuning and the\nVLM's performance in those classes; when trained with sufficient data, VLMs can\nmatch the accuracy of state-of-the-art classification models. Based on these\nfindings, we enhance a VLM by integrating classification-focused datasets into\nits training, and demonstrate that the enhanced classification performance of\nthe VLM transfers to its general capabilities, resulting in an improvement of\n11.8% on the newly collected ImageWikiQA dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18415v2",
    "published_date": "2024-05-28 17:57:06 UTC",
    "updated_date": "2024-11-03 18:23:45 UTC"
  },
  {
    "arxiv_id": "2405.18414v1",
    "title": "Don't Forget to Connect! Improving RAG with Graph-based Reranking",
    "authors": [
      "Jialin Dong",
      "Bahare Fatemi",
      "Bryan Perozzi",
      "Lin F. Yang",
      "Anton Tsitsulin"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has greatly improved the performance of\nLarge Language Model (LLM) responses by grounding generation with context from\nexisting documents. These systems work well when documents are clearly relevant\nto a question context. But what about when a document has partial information,\nor less obvious connections to the context? And how should we reason about\nconnections between documents? In this work, we seek to answer these two core\nquestions about RAG generation. We introduce G-RAG, a reranker based on graph\nneural networks (GNNs) between the retriever and reader in RAG. Our method\ncombines both connections between documents and semantic information (via\nAbstract Meaning Representation graphs) to provide a context-informed ranker\nfor RAG. G-RAG outperforms state-of-the-art approaches while having smaller\ncomputational footprint. Additionally, we assess the performance of PaLM 2 as a\nreranker and find it to significantly underperform G-RAG. This result\nemphasizes the importance of reranking for RAG even when using Large Language\nModels.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18414v1",
    "published_date": "2024-05-28 17:56:46 UTC",
    "updated_date": "2024-05-28 17:56:46 UTC"
  },
  {
    "arxiv_id": "2405.18406v3",
    "title": "RACCooN: A Versatile Instructional Video Editing Framework with Auto-Generated Narratives",
    "authors": [
      "Jaehong Yoon",
      "Shoubin Yu",
      "Mohit Bansal"
    ],
    "abstract": "Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. (3) RACCooN also plans to imagine new objects in a\ngiven video, so users simply prompt the model to receive a detailed video\nediting plan for complex video editing. The proposed framework demonstrates\nimpressive versatile capabilities in video-to-paragraph generation, video\ncontent editing, and can be incorporated into other SoTA video generative\nmodels for further enhancement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "The first two authors contribute equally. Project Page:\n  https://raccoon-mllm-gen.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2405.18406v3",
    "published_date": "2024-05-28 17:46:36 UTC",
    "updated_date": "2024-10-31 23:27:09 UTC"
  },
  {
    "arxiv_id": "2405.18405v1",
    "title": "WIDIn: Wording Image for Domain-Invariant Representation in Single-Source Domain Generalization",
    "authors": [
      "Jiawei Ma",
      "Yulei Niu",
      "Shiyuan Huang",
      "Guangxing Han",
      "Shih-Fu Chang"
    ],
    "abstract": "Language has been useful in extending the vision encoder to data from diverse\ndistributions without empirical discovery in training domains. However, as the\nimage description is mostly at coarse-grained level and ignores visual details,\nthe resulted embeddings are still ineffective in overcoming complexity of\ndomains at inference time. We present a self-supervision framework WIDIn,\nWording Images for Domain-Invariant representation, to disentangle\ndiscriminative visual representation, by only leveraging data in a single\ndomain and without any test prior. Specifically, for each image, we first\nestimate the language embedding with fine-grained alignment, which can be\nconsequently used to adaptively identify and then remove domain-specific\ncounterpart from the raw visual embedding. WIDIn can be applied to both\npretrained vision-language models like CLIP, and separately trained uni-modal\nmodels like MoCo and BERT. Experimental studies on three domain generalization\ndatasets demonstrate the effectiveness of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18405v1",
    "published_date": "2024-05-28 17:46:27 UTC",
    "updated_date": "2024-05-28 17:46:27 UTC"
  },
  {
    "arxiv_id": "2405.18459v2",
    "title": "Probing the Information Theoretical Roots of Spatial Dependence Measures",
    "authors": [
      "Zhangyu Wang",
      "Krzysztof Janowicz",
      "Gengchen Mai",
      "Ivan Majic"
    ],
    "abstract": "Intuitively, there is a relation between measures of spatial dependence and\ninformation theoretical measures of entropy. For instance, we can provide an\nintuition of why spatial data is special by stating that, on average, spatial\ndata samples contain less than expected information. Similarly, spatial data,\ne.g., remotely sensed imagery, that is easy to compress is also likely to show\nsignificant spatial autocorrelation. Formulating our (highly specific) core\nconcepts of spatial information theory in the widely used language of\ninformation theory opens new perspectives on their differences and similarities\nand also fosters cross-disciplinary collaboration, e.g., with the broader AI/ML\ncommunities. Interestingly, however, this intuitive relation is challenging to\nformalize and generalize, leading prior work to rely mostly on experimental\nresults, e.g., for describing landscape patterns. In this work, we will explore\nthe information theoretical roots of spatial autocorrelation, more specifically\nMoran's I, through the lens of self-information (also known as surprisal) and\nprovide both formal proofs and experiments.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT",
      "stat.ME"
    ],
    "primary_category": "cs.IT",
    "comment": "COSIT-2024 Conference Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2405.18459v2",
    "published_date": "2024-05-28 17:44:35 UTC",
    "updated_date": "2024-07-23 16:50:18 UTC"
  },
  {
    "arxiv_id": "2405.18395v2",
    "title": "MC-GTA: Metric-Constrained Model-Based Clustering using Goodness-of-fit Tests with Autocorrelations",
    "authors": [
      "Zhangyu Wang",
      "Gengchen Mai",
      "Krzysztof Janowicz",
      "Ni Lao"
    ],
    "abstract": "A wide range of (multivariate) temporal (1D) and spatial (2D) data analysis\ntasks, such as grouping vehicle sensor trajectories, can be formulated as\nclustering with given metric constraints. Existing metric-constrained\nclustering algorithms overlook the rich correlation between feature similarity\nand metric distance, i.e., metric autocorrelation. The model-based variations\nof these clustering algorithms (e.g. TICC and STICC) achieve SOTA performance,\nyet suffer from computational instability and complexity by using a\nmetric-constrained Expectation-Maximization procedure. In order to address\nthese two problems, we propose a novel clustering algorithm, MC-GTA\n(Model-based Clustering via Goodness-of-fit Tests with Autocorrelations). Its\nobjective is only composed of pairwise weighted sums of feature similarity\nterms (square Wasserstein-2 distance) and metric autocorrelation terms (a novel\nmultivariate generalization of classic semivariogram). We show that MC-GTA is\neffectively minimizing the total hinge loss for intra-cluster observation pairs\nnot passing goodness-of-fit tests, i.e., statistically not originating from the\nsame distribution. Experiments on 1D/2D synthetic and real-world datasets\ndemonstrate that MC-GTA successfully incorporates metric autocorrelation. It\noutperforms strong baselines by large margins (up to 14.3% in ARI and 32.1% in\nNMI) with faster and stabler optimization (>10x speedup).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML-2024 Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2405.18395v2",
    "published_date": "2024-05-28 17:35:05 UTC",
    "updated_date": "2024-06-03 03:53:16 UTC"
  },
  {
    "arxiv_id": "2405.18387v1",
    "title": "A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic",
    "authors": [
      "Ioanna Gogou",
      "Dimitrios Koutsomitropoulos"
    ],
    "abstract": "Convolutional Neural Networks (CNN) are commonly used for the problem of\nobject detection thanks to their increased accuracy. Nevertheless, the\nperformance of CNN-based detection models is ambiguous when detection speed is\nconsidered. To the best of our knowledge, there has not been sufficient\nevaluation of the available methods in terms of the speed/accuracy trade-off in\nrelated literature. This work assesses the most fundamental object detection\nmodels on the Common Objects in Context (COCO) dataset with respect to this\ntrade-off, their memory consumption, and computational and storage cost. Next,\nwe select a highly efficient model called YOLOv5 to train on the topical and\nunexplored dataset of human faces with medical masks, the Properly-Wearing\nMasked Faces Dataset (PWMFD), and analyze the benefits of specific optimization\ntechniques for real-time medical mask detection: transfer learning, data\naugmentations, and a Squeeze-and-Excitation attention mechanism. Using our\nfindings in the context of the COVID-19 pandemic, we propose an optimized model\nbased on YOLOv5s using transfer learning for the detection of correctly and\nincorrectly worn medical masks that surpassed more than two times in speed (69\nframes per second) the state-of-the-art model SE-YOLOv3 on the PWMFD dataset\nwhile maintaining the same level of mean Average Precision (67%).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18387v1",
    "published_date": "2024-05-28 17:27:24 UTC",
    "updated_date": "2024-05-28 17:27:24 UTC"
  },
  {
    "arxiv_id": "2405.18386v2",
    "title": "Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language Models via Instruction Tuning",
    "authors": [
      "Yixiao Zhang",
      "Yukara Ikemiya",
      "Woosung Choi",
      "Naoki Murata",
      "Marco A. Martínez-Ramírez",
      "Liwei Lin",
      "Gus Xia",
      "Wei-Hsiang Liao",
      "Yuki Mitsufuji",
      "Simon Dixon"
    ],
    "abstract": "Recent advances in text-to-music editing, which employ text queries to modify\nmusic (e.g.\\ by changing its style or adjusting instrumental components),\npresent unique challenges and opportunities for AI-assisted music creation.\nPrevious approaches in this domain have been constrained by the necessity to\ntrain specific editing models from scratch, which is both resource-intensive\nand inefficient; other research uses large language models to predict edited\nmusic, resulting in imprecise audio reconstruction. To Combine the strengths\nand address these limitations, we introduce Instruct-MusicGen, a novel approach\nthat finetunes a pretrained MusicGen model to efficiently follow editing\ninstructions such as adding, removing, or separating stems. Our approach\ninvolves a modification of the original MusicGen architecture by incorporating\na text fusion module and an audio fusion module, which allow the model to\nprocess instruction texts and audio inputs concurrently and yield the desired\nedited music. Remarkably, Instruct-MusicGen only introduces 8% new parameters\nto the original MusicGen model and only trains for 5K steps, yet it achieves\nsuperior performance across all tasks compared to existing baselines, and\ndemonstrates performance comparable to the models trained for specific tasks.\nThis advancement not only enhances the efficiency of text-to-music editing but\nalso broadens the applicability of music language models in dynamic music\nproduction environments.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Code and demo are available at:\n  https://github.com/ldzhangyx/instruct-musicgen",
    "pdf_url": "http://arxiv.org/pdf/2405.18386v2",
    "published_date": "2024-05-28 17:27:20 UTC",
    "updated_date": "2024-05-29 17:05:32 UTC"
  },
  {
    "arxiv_id": "2405.18383v2",
    "title": "Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation",
    "authors": [
      "Dominic LaBella",
      "Katherine Schumacher",
      "Michael Mix",
      "Kevin Leu",
      "Shan McBurney-Lin",
      "Pierre Nedelec",
      "Javier Villanueva-Meyer",
      "Jonathan Shapey",
      "Tom Vercauteren",
      "Kazumi Chia",
      "Omar Al-Salihi",
      "Justin Leu",
      "Lia Halasz",
      "Yury Velichko",
      "Chunhao Wang",
      "John Kirkpatrick",
      "Scott Floyd",
      "Zachary J. Reitman",
      "Trey Mullikin",
      "Ulas Bagci",
      "Sean Sachdev",
      "Jona A. Hattangadi-Gluth",
      "Tyler Seibert",
      "Nikdokht Farid",
      "Connor Puett",
      "Matthew W. Pease",
      "Kevin Shiue",
      "Syed Muhammad Anwar",
      "Shahriar Faghani",
      "Muhammad Ammar Haider",
      "Pranav Warman",
      "Jake Albrecht",
      "András Jakab",
      "Mana Moassefi",
      "Verena Chung",
      "Alejandro Aristizabal",
      "Alexandros Karargyris",
      "Hasan Kassem",
      "Sarthak Pati",
      "Micah Sheller",
      "Christina Huang",
      "Aaron Coley",
      "Siddharth Ghanta",
      "Alex Schneider",
      "Conrad Sharp",
      "Rachit Saluja",
      "Florian Kofler",
      "Philipp Lohmann",
      "Phillipp Vollmuth",
      "Louis Gagnon",
      "Maruf Adewole",
      "Hongwei Bran Li",
      "Anahita Fathi Kazerooni",
      "Nourel Hoda Tahon",
      "Udunna Anazodo",
      "Ahmed W. Moawad",
      "Bjoern Menze",
      "Marius George Linguraru",
      "Mariam Aboian",
      "Benedikt Wiestler",
      "Ujjwal Baid",
      "Gian-Marco Conte",
      "Andreas M. Rauschecker",
      "Ayman Nada",
      "Aly H. Abayazeed",
      "Raymond Huang",
      "Maria Correia de Verdier",
      "Jeffrey D. Rudie",
      "Spyridon Bakas",
      "Evan Calabrese"
    ],
    "abstract": "The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT)\nchallenge aims to advance automated segmentation algorithms using the largest\nknown multi-institutional dataset of radiotherapy planning brain MRIs with\nexpert-annotated target labels for patients with intact or postoperative\nmeningioma that underwent either conventional external beam radiotherapy or\nstereotactic radiosurgery. Each case includes a defaced 3D post-contrast\nT1-weighted radiotherapy planning MRI in its native acquisition space,\naccompanied by a single-label \"target volume\" representing the gross tumor\nvolume (GTV) and any at-risk postoperative site. Target volume annotations\nadhere to established radiotherapy planning protocols, ensuring consistency\nacross cases and institutions. For preoperative meningiomas, the target volume\nencompasses the entire GTV and associated nodular dural tail, while for\npostoperative cases, it includes at-risk resection cavity margins as determined\nby the treating institution. Case annotations were reviewed and approved by\nexpert neuroradiologists and radiation oncologists. Participating teams will\ndevelop, containerize, and evaluate automated segmentation models using this\ncomprehensive dataset. Model performance will be assessed using an adapted\nlesion-wise Dice Similarity Coefficient and the 95% Hausdorff distance. The\ntop-performing teams will be recognized at the Medical Image Computing and\nComputer Assisted Intervention Conference in October 2024. BraTS-MEN-RT is\nexpected to significantly advance automated radiotherapy planning by enabling\nprecise tumor segmentation and facilitating tailored treatment, ultimately\nimproving patient outcomes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 9 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2405.18383v2",
    "published_date": "2024-05-28 17:25:43 UTC",
    "updated_date": "2024-08-15 19:04:26 UTC"
  },
  {
    "arxiv_id": "2405.18380v2",
    "title": "OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning",
    "authors": [
      "Pengxiang Li",
      "Lu Yin",
      "Xiaowei Gao",
      "Shiwei Liu"
    ],
    "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\nvarious natural language processing tasks. However, the substantial size of\nLLMs presents significant challenges in training or fine-tuning. While\nparameter-efficient approaches such as low-rank adaptation (LoRA) have gained\npopularity, they often compromise performance compared to full-rank\nfine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled\nLow-Rank Projection (OwLore), a new memory-efficient fine-tuning approach,\ninspired by the layerwise outlier distribution of LLMs. Unlike LoRA, which adds\nextra adapters to all layers, OwLore strategically assigns higher sampling\nprobabilities to layers with more outliers, selectively sampling only a few\nlayers and fine-tuning their pre-trained weights. To further increase the\nnumber of fine-tuned layers without a proportional rise in memory costs, we\nincorporate gradient low-rank projection, further boosting the approach's\nperformance. Our extensive experiments across various architectures, including\nLLaMa2, LLaMa3, and Mistral, demonstrate that OwLore consistently outperforms\nbaseline approaches, including full fine-tuning. Specifically, it achieves up\nto a 1.1% average accuracy gain on the Commonsense Reasoning benchmark, a 3.0%\nimprovement on MMLU, and a notable 10% boost on MT-Bench, while being more\nmemory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of\nmemory. Code is available at https://github.com/pixeli99/OwLore.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18380v2",
    "published_date": "2024-05-28 17:22:22 UTC",
    "updated_date": "2024-10-12 04:35:10 UTC"
  },
  {
    "arxiv_id": "2405.18377v1",
    "title": "LLaMA-NAS: Efficient Neural Architecture Search for Large Language Models",
    "authors": [
      "Anthony Sarah",
      "Sharath Nittur Sridhar",
      "Maciej Szankin",
      "Sairam Sundaresan"
    ],
    "abstract": "The abilities of modern large language models (LLMs) in solving natural\nlanguage processing, complex reasoning, sentiment analysis and other tasks have\nbeen extraordinary which has prompted their extensive adoption. Unfortunately,\nthese abilities come with very high memory and computational costs which\nprecludes the use of LLMs on most hardware platforms. To mitigate this, we\npropose an effective method of finding Pareto-optimal network architectures\nbased on LLaMA2-7B using one-shot NAS. In particular, we fine-tune LLaMA2-7B\nonly once and then apply genetic algorithm-based search to find smaller, less\ncomputationally complex network architectures. We show that, for certain\nstandard benchmark tasks, the pre-trained LLaMA2-7B network is unnecessarily\nlarge and complex. More specifically, we demonstrate a 1.5x reduction in model\nsize and 1.3x speedup in throughput for certain tasks with negligible drop in\naccuracy. In addition to finding smaller, higher-performing network\narchitectures, our method does so more effectively and efficiently than certain\npruning or sparsification techniques. Finally, we demonstrate how quantization\nis complementary to our method and that the size and complexity of the networks\nwe find can be further decreased using quantization. We believe that our work\nprovides a way to automatically create LLMs which can be used on less expensive\nand more readily available hardware platforms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18377v1",
    "published_date": "2024-05-28 17:20:44 UTC",
    "updated_date": "2024-05-28 17:20:44 UTC"
  },
  {
    "arxiv_id": "2405.18369v2",
    "title": "PromptWizard: Task-Aware Prompt Optimization Framework",
    "authors": [
      "Eshaan Agarwal",
      "Joykirat Singh",
      "Vivek Dani",
      "Raghav Magazine",
      "Tanuja Ganu",
      "Akshay Nambi"
    ],
    "abstract": "Large language models (LLMs) have transformed AI across diverse domains, with\nprompting being central to their success in guiding model outputs. However,\nmanual prompt engineering is both labor-intensive and domain-specific,\nnecessitating the need for automated solutions. We introduce PromptWizard, a\nnovel, fully automated framework for discrete prompt optimization, utilizing a\nself-evolving, self-adapting mechanism. Through a feedback-driven critique and\nsynthesis process, PromptWizard achieves an effective balance between\nexploration and exploitation, iteratively refining both prompt instructions and\nin-context examples to generate human-readable, task-specific prompts. This\nguided approach systematically improves prompt quality, resulting in superior\nperformance across 45 tasks. PromptWizard excels even with limited training\ndata, smaller LLMs, and various LLM architectures. Additionally, our cost\nanalysis reveals a substantial reduction in API calls, token usage, and overall\ncost, demonstrating PromptWizard's efficiency, scalability, and advantages over\nexisting prompt optimization strategies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18369v2",
    "published_date": "2024-05-28 17:08:31 UTC",
    "updated_date": "2024-10-03 09:45:47 UTC"
  },
  {
    "arxiv_id": "2405.18359v1",
    "title": "Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual Performance in LLMs",
    "authors": [
      "Somnath Kumar",
      "Vaibhav Balloli",
      "Mercy Ranjit",
      "Kabir Ahuja",
      "Tanuja Ganu",
      "Sunayana Sitaram",
      "Kalika Bali",
      "Akshay Nambi"
    ],
    "abstract": "Large language models (LLMs) are at the forefront of transforming numerous\ndomains globally. However, their inclusivity and effectiveness remain limited\nfor non-Latin scripts and low-resource languages. This paper tackles the\nimperative challenge of enhancing the multilingual performance of LLMs without\nextensive training or fine-tuning. Through systematic investigation and\nevaluation of diverse languages using popular question-answering (QA) datasets,\nwe present novel techniques that unlock the true potential of LLMs in a\npolyglot landscape. Our approach encompasses three key strategies that yield\nsignificant improvements in multilingual proficiency. First, by meticulously\noptimizing prompts tailored for polyglot LLMs, we unlock their latent\ncapabilities, resulting in substantial performance boosts across languages.\nSecond, we introduce a new hybrid approach that synergizes LLM Retrieval\nAugmented Generation (RAG) with multilingual embeddings and achieves improved\nmultilingual task performance. Finally, we introduce a novel learning approach\nthat dynamically selects the optimal prompt strategy, LLM model, and embedding\nmodel per query at run-time. This dynamic adaptation maximizes the efficacy of\nLLMs across languages, outperforming best static and random strategies.\nAdditionally, our approach adapts configurations in both offline and online\nsettings, and can seamlessly adapt to new languages and datasets, leading to\nsubstantial advancements in multilingual understanding and generation across\ndiverse languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2305.17740",
    "pdf_url": "http://arxiv.org/pdf/2405.18359v1",
    "published_date": "2024-05-28 16:56:42 UTC",
    "updated_date": "2024-05-28 16:56:42 UTC"
  },
  {
    "arxiv_id": "2405.18358v1",
    "title": "MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex Visual Reasoning",
    "authors": [
      "Somnath Kumar",
      "Yash Gadhia",
      "Tanuja Ganu",
      "Akshay Nambi"
    ],
    "abstract": "Recent advancements in Multi-modal Large Language Models (MLLMs) have\nsignificantly improved their performance in tasks combining vision and\nlanguage. However, challenges persist in detailed multi-modal understanding,\ncomprehension of complex tasks, and reasoning over multi-modal information.\nThis paper introduces MMCTAgent, a novel multi-modal critical thinking agent\nframework designed to address the inherent limitations of current MLLMs in\ncomplex visual reasoning tasks. Inspired by human cognitive processes and\ncritical thinking, MMCTAgent iteratively analyzes multi-modal information,\ndecomposes queries, plans strategies, and dynamically evolves its reasoning.\nAdditionally, MMCTAgent incorporates critical thinking elements such as\nverification of final answers and self-reflection through a novel approach that\ndefines a vision-based critic and identifies task-specific evaluation criteria,\nthereby enhancing its decision-making abilities. Through rigorous evaluations\nacross various image and video understanding benchmarks, we demonstrate that\nMMCTAgent (with and without the critic) outperforms both foundational MLLMs and\nother tool-augmented pipelines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18358v1",
    "published_date": "2024-05-28 16:55:41 UTC",
    "updated_date": "2024-05-28 16:55:41 UTC"
  },
  {
    "arxiv_id": "2405.18350v1",
    "title": "A System for Automatic English Text Expansion",
    "authors": [
      "Silvia García Méndez",
      "Milagros Fernández Gavilanes",
      "Enrique Costa Montenegro",
      "Jonathan Juncal Martínez",
      "Francisco Javier González Castaño",
      "Ehud Reiter"
    ],
    "abstract": "We present an automatic text expansion system to generate English sentences,\nwhich performs automatic Natural Language Generation (NLG) by combining\nlinguistic rules with statistical approaches. Here, \"automatic\" means that the\nsystem can generate coherent and correct sentences from a minimum set of words.\nFrom its inception, the design is modular and adaptable to other languages.\nThis adaptability is one of its greatest advantages. For English, we have\ncreated the highly precise aLexiE lexicon with wide coverage, which represents\na contribution on its own. We have evaluated the resulting NLG library in an\nAugmentative and Alternative Communication (AAC) proof of concept, both\ndirectly (by regenerating corpus sentences) and manually (from annotations)\nusing a popular corpus in the NLG field. We performed a second analysis by\ncomparing the quality of text expansion in English to Spanish, using an ad-hoc\nSpanish-English parallel corpus. The system might also be applied to other\ndomains such as report and news generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18350v1",
    "published_date": "2024-05-28 16:48:05 UTC",
    "updated_date": "2024-05-28 16:48:05 UTC"
  },
  {
    "arxiv_id": "2405.18346v1",
    "title": "Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation",
    "authors": [
      "Anjanava Biswas",
      "Wrick Talukdar"
    ],
    "abstract": "Comprehensive clinical documentation is crucial for effective healthcare\ndelivery, yet it poses a significant burden on healthcare professionals,\nleading to burnout, increased medical errors, and compromised patient safety.\nThis paper explores the potential of generative AI (Artificial Intelligence) to\nstreamline the clinical documentation process, specifically focusing on\ngenerating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior,\nIntervention, Response, Plan) notes. We present a case study demonstrating the\napplication of natural language processing (NLP) and automatic speech\nrecognition (ASR) technologies to transcribe patient-clinician interactions,\ncoupled with advanced prompting techniques to generate draft clinical notes\nusing large language models (LLMs). The study highlights the benefits of this\napproach, including time savings, improved documentation quality, and enhanced\npatient-centered care. Additionally, we discuss ethical considerations, such as\nmaintaining patient confidentiality and addressing model biases, underscoring\nthe need for responsible deployment of generative AI in healthcare settings.\nThe findings suggest that generative AI has the potential to revolutionize\nclinical documentation practices, alleviating administrative burdens and\nenabling healthcare professionals to focus more on direct patient care.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.18346v1",
    "published_date": "2024-05-28 16:43:41 UTC",
    "updated_date": "2024-05-28 16:43:41 UTC"
  },
  {
    "arxiv_id": "2405.18344v1",
    "title": "The Battle of LLMs: A Comparative Study in Conversational QA Tasks",
    "authors": [
      "Aryan Rangapur",
      "Aman Rangapur"
    ],
    "abstract": "Large language models have gained considerable interest for their impressive\nperformance on various tasks. Within this domain, ChatGPT and GPT-4, developed\nby OpenAI, and the Gemini, developed by Google, have emerged as particularly\npopular among early adopters. Additionally, Mixtral by Mistral AI and Claude by\nAnthropic are newly released, further expanding the landscape of advanced\nlanguage models. These models are viewed as disruptive technologies with\napplications spanning customer service, education, healthcare, and finance.\nMore recently, Mistral has entered the scene, captivating users with its unique\nability to generate creative content. Understanding the perspectives of these\nusers is crucial, as they can offer valuable insights into the potential\nstrengths, weaknesses, and overall success or failure of these technologies in\nvarious domains. This research delves into the responses generated by ChatGPT,\nGPT-4, Gemini, Mixtral and Claude across different Conversational QA corpora.\nEvaluation scores were meticulously computed and subsequently compared to\nascertain the overall performance of these models. Our study pinpointed\ninstances where these models provided inaccurate answers to questions, offering\ninsights into potential areas where they might be susceptible to errors. In\nessence, this research provides a comprehensive comparison and evaluation of\nthese state of-the-art language models, shedding light on their capabilities\nwhile also highlighting potential areas for improvement",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.7, I.m"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.18344v1",
    "published_date": "2024-05-28 16:42:43 UTC",
    "updated_date": "2024-05-28 16:42:43 UTC"
  },
  {
    "arxiv_id": "2406.01618v1",
    "title": "FinEmbedDiff: A Cost-Effective Approach of Classifying Financial Documents with Vector Sampling using Multi-modal Embedding Models",
    "authors": [
      "Anjanava Biswas",
      "Wrick Talukdar"
    ],
    "abstract": "Accurate classification of multi-modal financial documents, containing text,\ntables, charts, and images, is crucial but challenging. Traditional text-based\napproaches often fail to capture the complex multi-modal nature of these\ndocuments. We propose FinEmbedDiff, a cost-effective vector sampling method\nthat leverages pre-trained multi-modal embedding models to classify financial\ndocuments. Our approach generates multi-modal embedding vectors for documents,\nand compares new documents with pre-computed class embeddings using vector\nsimilarity measures. Evaluated on a large dataset, FinEmbedDiff achieves\ncompetitive classification accuracy compared to state-of-the-art baselines\nwhile significantly reducing computational costs. The method exhibits strong\ngeneralization capabilities, making it a practical and scalable solution for\nreal-world financial applications.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01618v1",
    "published_date": "2024-05-28 16:34:24 UTC",
    "updated_date": "2024-05-28 16:34:24 UTC"
  },
  {
    "arxiv_id": "2405.18335v1",
    "title": "Interpretable classification of wiki-review streams",
    "authors": [
      "Silvia García Méndez",
      "Fátima Leal",
      "Benedita Malheiro",
      "Juan Carlos Burguillo Rial"
    ],
    "abstract": "Wiki articles are created and maintained by a crowd of editors, producing a\ncontinuous stream of reviews. Reviews can take the form of additions, reverts,\nor both. This crowdsourcing model is exposed to manipulation since neither\nreviews nor editors are automatically screened and purged. To protect articles\nagainst vandalism or damage, the stream of reviews can be mined to classify\nreviews and profile editors in real-time. The goal of this work is to\nanticipate and explain which reviews to revert. This way, editors are informed\nwhy their edits will be reverted. The proposed method employs stream-based\nprocessing, updating the profiling and classification models on each incoming\nevent. The profiling uses side and content-based features employing Natural\nLanguage Processing, and editor profiles are incrementally updated based on\ntheir reviews. Since the proposed method relies on self-explainable\nclassification algorithms, it is possible to understand why a review has been\nclassified as a revert or a non-revert. In addition, this work contributes an\nalgorithm for generating synthetic data for class balancing, making the final\nclassification fairer. The proposed online method was tested with a real data\nset from Wikivoyage, which was balanced through the aforementioned synthetic\ndata generation. The results attained near-90 % values for all evaluation\nmetrics (accuracy, precision, recall, and F-measure).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18335v1",
    "published_date": "2024-05-28 16:28:58 UTC",
    "updated_date": "2024-05-28 16:28:58 UTC"
  },
  {
    "arxiv_id": "2405.18330v2",
    "title": "Frustratingly Easy Test-Time Adaptation of Vision-Language Models",
    "authors": [
      "Matteo Farina",
      "Gianni Franchi",
      "Giovanni Iacca",
      "Massimiliano Mancini",
      "Elisa Ricci"
    ],
    "abstract": "Vision-Language Models seamlessly discriminate among arbitrary semantic\ncategories, yet they still suffer from poor generalization when presented with\nchallenging examples. For this reason, Episodic Test-Time Adaptation (TTA)\nstrategies have recently emerged as powerful techniques to adapt VLMs in the\npresence of a single unlabeled image. The recent literature on TTA is dominated\nby the paradigm of prompt tuning by Marginal Entropy Minimization, which,\nrelying on online backpropagation, inevitably slows down inference while\nincreasing memory. In this work, we theoretically investigate the properties of\nthis approach and unveil that a surprisingly strong TTA method lies dormant and\nhidden within it. We term this approach ZERO (TTA with \"zero\" temperature),\nwhose design is both incredibly effective and frustratingly simple: augment N\ntimes, predict, retain the most confident predictions, and marginalize after\nsetting the Softmax temperature to zero. Remarkably, ZERO requires a single\nbatched forward pass through the vision encoder only and no backward passes. We\nthoroughly evaluate our approach following the experimental protocol\nestablished in the literature and show that ZERO largely surpasses or compares\nfavorably w.r.t. the state-of-the-art while being almost 10x faster and 13x\nmore memory-friendly than standard Test-Time Prompt Tuning. Thanks to its\nsimplicity and comparatively negligible computation, ZERO can serve as a strong\nbaseline for future work in this field. The code is available at\nhttps://github.com/FarinaMatteo/zero.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Camera-ready version for NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18330v2",
    "published_date": "2024-05-28 16:24:47 UTC",
    "updated_date": "2024-11-02 15:29:07 UTC"
  },
  {
    "arxiv_id": "2405.18327v1",
    "title": "Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial",
    "authors": [
      "Jay Jasti",
      "Hua Zhong",
      "Vandana Panwar",
      "Vipul Jarmale",
      "Jeffrey Miyata",
      "Deyssy Carrillo",
      "Alana Christie",
      "Dinesh Rakheja",
      "Zora Modrusan",
      "Edward Ernest Kadel III",
      "Niha Beig",
      "Mahrukh Huseni",
      "James Brugarolas",
      "Payal Kapur",
      "Satwik Rajaram"
    ],
    "abstract": "Predictive biomarkers of treatment response are lacking for metastatic clear\ncell renal cell carcinoma (ccRCC), a tumor type that is treated with\nangiogenesis inhibitors, immune checkpoint inhibitors, mTOR inhibitors and a\nHIF2 inhibitor. The Angioscore, an RNA-based quantification of angiogenesis, is\narguably the best candidate to predict anti-angiogenic (AA) response. However,\nthe clinical adoption of transcriptomic assays faces several challenges\nincluding standardization, time delay, and high cost. Further, ccRCC tumors are\nhighly heterogenous, and sampling multiple areas for sequencing is impractical.\nHere we present a novel deep learning (DL) approach to predict the Angioscore\nfrom ubiquitous histopathology slides. To overcome the lack of\ninterpretability, one of the biggest limitations of typical DL models, our\nmodel produces a visual vascular network which is the basis of the model's\nprediction. To test its reliability, we applied this model to multiple cohorts\nincluding a clinical trial dataset. Our model accurately predicts the RNA-based\nAngioscore on multiple independent cohorts (spearman correlations of 0.77 and\n0.73). Further, the predictions help unravel meaningful biology such as\nassociation of angiogenesis with grade, stage, and driver mutation status.\nFinally, we find our model can predict response to AA therapy, in both a\nreal-world cohort and the IMmotion150 clinical trial. The predictive power of\nour model vastly exceeds that of CD31, a marker of vasculature, and nearly\nrivals the performance (c-index 0.66 vs 0.67) of the ground truth RNA-based\nAngioscore at a fraction of the cost. By providing a robust yet interpretable\nprediction of the Angioscore from histopathology slides alone, our approach\noffers insights into angiogenesis biology and AA treatment response.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "19 pages, 4 Figures",
    "pdf_url": "http://arxiv.org/pdf/2405.18327v1",
    "published_date": "2024-05-28 16:21:20 UTC",
    "updated_date": "2024-05-28 16:21:20 UTC"
  },
  {
    "arxiv_id": "2405.18322v1",
    "title": "SCE-MAE: Selective Correspondence Enhancement with Masked Autoencoder for Self-Supervised Landmark Estimation",
    "authors": [
      "Kejia Yin",
      "Varshanth R. Rao",
      "Ruowei Jiang",
      "Xudong Liu",
      "Parham Aarabi",
      "David B. Lindell"
    ],
    "abstract": "Self-supervised landmark estimation is a challenging task that demands the\nformation of locally distinct feature representations to identify sparse facial\nlandmarks in the absence of annotated data. To tackle this task, existing\nstate-of-the-art (SOTA) methods (1) extract coarse features from backbones that\nare trained with instance-level self-supervised learning (SSL) paradigms, which\nneglect the dense prediction nature of the task, (2) aggregate them into\nmemory-intensive hypercolumn formations, and (3) supervise lightweight\nprojector networks to naively establish full local correspondences among all\npairs of spatial features. In this paper, we introduce SCE-MAE, a framework\nthat (1) leverages the MAE, a region-level SSL method that naturally better\nsuits the landmark prediction task, (2) operates on the vanilla feature map\ninstead of on expensive hypercolumns, and (3) employs a Correspondence\nApproximation and Refinement Block (CARB) that utilizes a simple density peak\nclustering algorithm and our proposed Locality-Constrained Repellence Loss to\ndirectly hone only select local correspondences. We demonstrate through\nextensive experiments that SCE-MAE is highly effective and robust,\noutperforming existing SOTA methods by large margins of approximately 20%-44%\non the landmark matching and approximately 9%-15% on the landmark detection\ntasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18322v1",
    "published_date": "2024-05-28 16:14:10 UTC",
    "updated_date": "2024-05-28 16:14:10 UTC"
  },
  {
    "arxiv_id": "2405.18320v2",
    "title": "Self-Supervised Learning Based Handwriting Verification",
    "authors": [
      "Mihir Chauhan",
      "Mohammad Abuzar Hashemi",
      "Abhishek Satbhai",
      "Mir Basheer Ali",
      "Bina Ramamurthy",
      "Mingchen Gao",
      "Siwei Lyu",
      "Sargur Srihari"
    ],
    "abstract": "We present SSL-HV: Self-Supervised Learning approaches applied to the task of\nHandwriting Verification. This task involves determining whether a given pair\nof handwritten images originate from the same or different writer distribution.\nWe have compared the performance of multiple generative, contrastive SSL\napproaches against handcrafted feature extractors and supervised learning on\nCEDAR AND dataset. We show that ResNet based Variational Auto-Encoder (VAE)\noutperforms other generative approaches achieving 76.3% accuracy, while\nResNet-18 fine-tuned using Variance-Invariance-Covariance Regularization\n(VICReg) outperforms other contrastive approaches achieving 78% accuracy. Using\na pre-trained VAE and VICReg for the downstream task of writer verification we\nobserved a relative improvement in accuracy of 6.7% and 9% over ResNet-18\nsupervised baseline with 10% writer labels.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 2 figures, 2 tables, Accepted at Irish Machine Vision and\n  Image Processing Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18320v2",
    "published_date": "2024-05-28 16:11:11 UTC",
    "updated_date": "2024-08-01 17:43:19 UTC"
  },
  {
    "arxiv_id": "2405.18315v1",
    "title": "DSDL: Data Set Description Language for Bridging Modalities and Tasks in AI Data",
    "authors": [
      "Bin Wang",
      "Linke Ouyang",
      "Fan Wu",
      "Wenchang Ning",
      "Xiao Han",
      "Zhiyuan Zhao",
      "Jiahui Peng",
      "Yiying Jiang",
      "Dahua Lin",
      "Conghui He"
    ],
    "abstract": "In the era of artificial intelligence, the diversity of data modalities and\nannotation formats often renders data unusable directly, requiring\nunderstanding and format conversion before it can be used by researchers or\ndevelopers with different needs. To tackle this problem, this article\nintroduces a framework called Dataset Description Language (DSDL) that aims to\nsimplify dataset processing by providing a unified standard for AI datasets.\nDSDL adheres to the three basic practical principles of generic, portable, and\nextensible, using a unified standard to express data of different modalities\nand structures, facilitating the dissemination of AI data, and easily extending\nto new modalities and tasks. The standardized specifications of DSDL reduce the\nworkload for users in data dissemination, processing, and usage. To further\nimprove user convenience, we provide predefined DSDL templates for various\ntasks, convert mainstream datasets to comply with DSDL specifications, and\nprovide comprehensive documentation and DSDL tools. These efforts aim to\nsimplify the use of AI data, thereby improving the efficiency of AI\ndevelopment.",
    "categories": [
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18315v1",
    "published_date": "2024-05-28 16:07:45 UTC",
    "updated_date": "2024-05-28 16:07:45 UTC"
  },
  {
    "arxiv_id": "2405.18300v1",
    "title": "CompetEvo: Towards Morphological Evolution from Competition",
    "authors": [
      "Kangyao Huang",
      "Di Guo",
      "Xinyu Zhang",
      "Xiangyang Ji",
      "Huaping Liu"
    ],
    "abstract": "Training an agent to adapt to specific tasks through co-optimization of\nmorphology and control has widely attracted attention. However, whether there\nexists an optimal configuration and tactics for agents in a multiagent\ncompetition scenario is still an issue that is challenging to definitively\nconclude. In this context, we propose competitive evolution (CompetEvo), which\nco-evolves agents' designs and tactics in confrontation. We build arenas\nconsisting of three animals and their evolved derivatives, placing agents with\ndifferent morphologies in direct competition with each other. The results\nreveal that our method enables agents to evolve a more suitable design and\nstrategy for fighting compared to fixed-morph agents, allowing them to obtain\nadvantages in combat scenarios. Moreover, we demonstrate the amazing and\nimpressive behaviors that emerge when confrontations are conducted under\nasymmetrical morphs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18300v1",
    "published_date": "2024-05-28 15:53:02 UTC",
    "updated_date": "2024-05-28 15:53:02 UTC"
  },
  {
    "arxiv_id": "2405.18299v4",
    "title": "Deep Learning Innovations for Underwater Waste Detection: An In-Depth Analysis",
    "authors": [
      "Jaskaran Singh Walia",
      "Pavithra L K"
    ],
    "abstract": "Addressing the issue of submerged underwater trash is crucial for\nsafeguarding aquatic ecosystems and preserving marine life. While identifying\ndebris present on the surface of water bodies is straightforward, assessing the\nunderwater submerged waste is a challenge due to the image distortions caused\nby factors such as light refraction, absorption, suspended particles, color\nshifts, and occlusion. This paper conducts a comprehensive review of\nstate-of-the-art architectures and on the existing datasets to establish a\nbaseline for submerged waste and trash detection. The primary goal remains to\nestablish the benchmark of the object localization techniques to be leveraged\nby advanced underwater sensors and autonomous underwater vehicles. The ultimate\nobjective is to explore the underwater environment, to identify, and remove\nunderwater debris. The absence of benchmarks (dataset or algorithm) in many\nresearches emphasizes the need for a more robust algorithmic solution. Through\nthis research, we aim to give performance comparative analysis of various\nunderwater trash detection algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18299v4",
    "published_date": "2024-05-28 15:51:18 UTC",
    "updated_date": "2024-11-20 23:23:40 UTC"
  },
  {
    "arxiv_id": "2405.18291v1",
    "title": "FedSAC: Dynamic Submodel Allocation for Collaborative Fairness in Federated Learning",
    "authors": [
      "Zihui Wang",
      "Zheng Wang",
      "Lingjuan Lyu",
      "Zhaopeng Peng",
      "Zhicheng Yang",
      "Chenglu Wen",
      "Rongshan Yu",
      "Cheng Wang",
      "Xiaoliang Fan"
    ],
    "abstract": "Collaborative fairness stands as an essential element in federated learning\nto encourage client participation by equitably distributing rewards based on\nindividual contributions. Existing methods primarily focus on adjusting\ngradient allocations among clients to achieve collaborative fairness. However,\nthey frequently overlook crucial factors such as maintaining consistency across\nlocal models and catering to the diverse requirements of high-contributing\nclients. This oversight inevitably decreases both fairness and model accuracy\nin practice. To address these issues, we propose FedSAC, a novel Federated\nlearning framework with dynamic Submodel Allocation for Collaborative fairness,\nbacked by a theoretical convergence guarantee. First, we present the concept of\n\"bounded collaborative fairness (BCF)\", which ensures fairness by tailoring\nrewards to individual clients based on their contributions. Second, to\nimplement the BCF, we design a submodel allocation module with a theoretical\nguarantee of fairness. This module incentivizes high-contributing clients with\nhigh-performance submodels containing a diverse range of crucial neurons,\nthereby preserving consistency across local models. Third, we further develop a\ndynamic aggregation module to adaptively aggregate submodels, ensuring the\nequitable treatment of low-frequency neurons and consequently enhancing overall\nmodel accuracy. Extensive experiments conducted on three public benchmarks\ndemonstrate that FedSAC outperforms all baseline methods in both fairness and\nmodel accuracy. We see this work as a significant step towards incentivizing\nbroader client participation in federated learning. The source code is\navailable at https://github.com/wangzihuixmu/FedSAC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD'24",
    "pdf_url": "http://arxiv.org/pdf/2405.18291v1",
    "published_date": "2024-05-28 15:43:29 UTC",
    "updated_date": "2024-05-28 15:43:29 UTC"
  },
  {
    "arxiv_id": "2405.18289v1",
    "title": "Highway Reinforcement Learning",
    "authors": [
      "Yuhui Wang",
      "Miroslav Strupl",
      "Francesco Faccio",
      "Qingyuan Wu",
      "Haozhe Liu",
      "Michał Grudzień",
      "Xiaoyang Tan",
      "Jürgen Schmidhuber"
    ],
    "abstract": "Learning from multi-step off-policy data collected by a set of policies is a\ncore problem of reinforcement learning (RL). Approaches based on importance\nsampling (IS) often suffer from large variances due to products of IS ratios.\nTypical IS-free methods, such as $n$-step Q-learning, look ahead for $n$ time\nsteps along the trajectory of actions (where $n$ is called the lookahead depth)\nand utilize off-policy data directly without any additional adjustment. They\nwork well for proper choices of $n$. We show, however, that such IS-free\nmethods underestimate the optimal value function (VF), especially for large\n$n$, restricting their capacity to efficiently utilize information from distant\nfuture time steps. To overcome this problem, we introduce a novel, IS-free,\nmulti-step off-policy method that avoids the underestimation issue and\nconverges to the optimal VF. At its core lies a simple but non-trivial\n\\emph{highway gate}, which controls the information flow from the distant\nfuture by comparing it to a threshold. The highway gate guarantees convergence\nto the optimal VF for arbitrary $n$ and arbitrary behavioral policies. It gives\nrise to a novel family of off-policy RL algorithms that safely learn even when\n$n$ is very large, facilitating rapid credit assignment from the far future to\nthe past. On tasks with greatly delayed rewards, including video games where\nthe reward is given only at the end of the game, our new methods outperform\nmany existing multi-step off-policy algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18289v1",
    "published_date": "2024-05-28 15:42:45 UTC",
    "updated_date": "2024-05-28 15:42:45 UTC"
  },
  {
    "arxiv_id": "2405.18281v2",
    "title": "MODL: Multilearner Online Deep Learning",
    "authors": [
      "Antonios Valkanas",
      "Boris N. Oreshkin",
      "Mark Coates"
    ],
    "abstract": "Online deep learning tackles the challenge of learning from data streams by\nbalancing two competing goals: fast learning and deep learning. However,\nexisting research primarily emphasizes deep learning solutions, which are more\nadept at handling the ``deep'' aspect than the ``fast'' aspect of online\nlearning. In this work, we introduce an alternative paradigm through a hybrid\nmultilearner approach. We begin by developing a fast online logistic regression\nlearner, which operates without relying on backpropagation. It leverages\nclosed-form recursive updates of model parameters, efficiently addressing the\nfast learning component of the online learning challenge. This approach is\nfurther integrated with a cascaded multilearner design, where shallow and deep\nlearners are co-trained in a cooperative, synergistic manner to solve the\nonline learning problem. We demonstrate that this approach achieves\nstate-of-the-art performance on standard online learning datasets. We make our\ncode available: https://github.com/AntonValk/MODL",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18281v2",
    "published_date": "2024-05-28 15:34:33 UTC",
    "updated_date": "2025-03-21 03:21:40 UTC"
  },
  {
    "arxiv_id": "2405.18272v2",
    "title": "Metaheuristics and Large Language Models Join Forces: Toward an Integrated Optimization Approach",
    "authors": [
      "Camilo Chacón Sartori",
      "Christian Blum",
      "Filippo Bistaffa",
      "Guillem Rodríguez Corominas"
    ],
    "abstract": "Since the rise of Large Language Models (LLMs) a couple of years ago,\nresearchers in metaheuristics (MHs) have wondered how to use their power in a\nbeneficial way within their algorithms. This paper introduces a novel approach\nthat leverages LLMs as pattern recognition tools to improve MHs. The resulting\nhybrid method, tested in the context of a social network-based combinatorial\noptimization problem, outperforms existing state-of-the-art approaches that\ncombine machine learning with MHs regarding the obtained solution quality. By\ncarefully designing prompts, we demonstrate that the output obtained from LLMs\ncan be used as problem knowledge, leading to improved results. Lastly, we\nacknowledge LLMs' potential drawbacks and limitations and consider it essential\nto examine them to advance this type of research further. Our method can be\nreproduced using a tool available at: https://github.com/camilochs/optipattern.",
    "categories": [
      "cs.AI",
      "68T20"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18272v2",
    "published_date": "2024-05-28 15:23:46 UTC",
    "updated_date": "2025-02-12 10:22:58 UTC"
  },
  {
    "arxiv_id": "2405.18258v1",
    "title": "Text-only Synthesis for Image Captioning",
    "authors": [
      "Qing Zhou",
      "Junlin Huang",
      "Qiang Li",
      "Junyu Gao",
      "Qi Wang"
    ],
    "abstract": "From paired image-text training to text-only training for image captioning,\nthe pursuit of relaxing the requirements for high-cost and large-scale\nannotation of good quality data remains consistent. In this paper, we propose\nText-only Synthesis for Image Captioning (ToCa), which further advances this\nrelaxation with fewer human labor and less computing time. Specifically, we\ndeconstruct caption text into structures and lexical words, which serve as the\nfundamental components of the caption. By combining different structures and\nlexical words as inputs to the large language model, massive captions that\ncontain various patterns of lexical words are generated. This method not only\napproaches the target domain but also surpasses it by generating new captions,\nthereby enhancing the zero-shot generalization ability of the model.\nConsidering the different levels of data access in the real world, we define\nthree synthesis scenarios: cross-domain synthesis, in-domain synthesis, and\ndata-efficient synthesis. Experiments in these scenarios demonstrate the\ngeneralizability, transferability and practicability of ToCa with a nearly 5\nCIDEr improvement for zero-shot cross-domain captioning and a maximum increase\nof over 20 CIDEr for data-efficient captioning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18258v1",
    "published_date": "2024-05-28 15:11:17 UTC",
    "updated_date": "2024-05-28 15:11:17 UTC"
  },
  {
    "arxiv_id": "2405.18248v1",
    "title": "Extreme Value Monte Carlo Tree Search",
    "authors": [
      "Masataro Asai",
      "Stephen Wissow"
    ],
    "abstract": "Despite being successful in board games and reinforcement learning (RL), UCT,\na Monte-Carlo Tree Search (MCTS) combined with UCB1 Multi-Armed Bandit (MAB),\nhas had limited success in domain-independent planning until recently. Previous\nwork showed that UCB1, designed for $[0,1]$-bounded rewards, is not appropriate\nfor estimating the distance-to-go which are potentially unbounded in\n$\\mathbb{R}$, such as heuristic functions used in classical planning, then\nproposed combining MCTS with MABs designed for Gaussian reward distributions\nand successfully improved the performance. In this paper, we further sharpen\nour understanding of ideal bandits for planning tasks. Existing work has two\nissues: First, while Gaussian MABs no longer over-specify the distances as\n$h\\in [0,1]$, they under-specify them as $h\\in [-\\infty,\\infty]$ while they are\nnon-negative and can be further bounded in some cases. Second, there is no\ntheoretical justifications for Full-Bellman backup (Schulte & Keller, 2014)\nthat backpropagates minimum/maximum of samples. We identified \\emph{extreme\nvalue} statistics as a theoretical framework that resolves both issues at once\nand propose two bandits, UCB1-Uniform/Power, and apply them to MCTS for\nclassical planning. We formally prove their regret bounds and empirically\ndemonstrate their performance in classical planning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2305.09840",
    "pdf_url": "http://arxiv.org/pdf/2405.18248v1",
    "published_date": "2024-05-28 14:58:43 UTC",
    "updated_date": "2024-05-28 14:58:43 UTC"
  },
  {
    "arxiv_id": "2405.18246v3",
    "title": "Utilitarian Algorithm Configuration for Infinite Parameter Spaces",
    "authors": [
      "Devon Graham",
      "Kevin Leyton-Brown"
    ],
    "abstract": "Utilitarian algorithm configuration is a general-purpose technique for\nautomatically searching the parameter space of a given algorithm to optimize\nits performance, as measured by a given utility function, on a given set of\ninputs. Recently introduced utilitarian configuration procedures offer\noptimality guarantees about the returned parameterization while provably\nadapting to the hardness of the underlying problem. However, the applicability\nof these approaches is severely limited by the fact that they only search a\nfinite, relatively small set of parameters. They cannot effectively search the\nconfiguration space of algorithms with continuous or uncountable parameters. In\nthis paper we introduce a new procedure, which we dub COUP (Continuous,\nOptimistic Utilitarian Procrastination). COUP is designed to search infinite\nparameter spaces efficiently to find good configurations quickly. Furthermore,\nCOUP maintains the theoretical benefits of previous utilitarian configuration\nprocedures when applied to finite parameter spaces but is significantly faster,\nboth provably and experimentally.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18246v3",
    "published_date": "2024-05-28 14:58:07 UTC",
    "updated_date": "2025-02-16 15:15:31 UTC"
  },
  {
    "arxiv_id": "2405.18241v1",
    "title": "Active Use of Latent Constituency Representation in both Humans and Large Language Models",
    "authors": [
      "Wei Liu",
      "Ming Xiang",
      "Nai Ding"
    ],
    "abstract": "Understanding how sentences are internally represented in the human brain, as\nwell as in large language models (LLMs) such as ChatGPT, is a major challenge\nfor cognitive science. Classic linguistic theories propose that the brain\nrepresents a sentence by parsing it into hierarchically organized constituents.\nIn contrast, LLMs do not explicitly parse linguistic constituents and their\nlatent representations remains poorly explained. Here, we demonstrate that\nhumans and LLMs construct similar latent representations of hierarchical\nlinguistic constituents by analyzing their behaviors during a novel one-shot\nlearning task, in which they infer which words should be deleted from a\nsentence. Both humans and LLMs tend to delete a constituent, instead of a\nnonconstituent word string. In contrast, a naive sequence processing model that\nhas access to word properties and ordinal positions does not show this\nproperty. Based on the word deletion behaviors, we can reconstruct the latent\nconstituency tree representation of a sentence for both humans and LLMs. These\nresults demonstrate that a latent tree-structured constituency representation\ncan emerge in both the human brain and LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "62 pages, 5 figures. Under review",
    "pdf_url": "http://arxiv.org/pdf/2405.18241v1",
    "published_date": "2024-05-28 14:50:22 UTC",
    "updated_date": "2024-05-28 14:50:22 UTC"
  },
  {
    "arxiv_id": "2405.18208v1",
    "title": "A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models",
    "authors": [
      "Chengxing Xie",
      "Difan Zou"
    ],
    "abstract": "Recent studies have highlighted their proficiency in some simple tasks like\nwriting and coding through various reasoning strategies. However, LLM agents\nstill struggle with tasks that require comprehensive planning, a process that\nchallenges current models and remains a critical research issue. In this study,\nwe concentrate on travel planning, a Multi-Phases planning problem, that\ninvolves multiple interconnected stages, such as outlining, information\ngathering, and planning, often characterized by the need to manage various\nconstraints and uncertainties. Existing reasoning approaches have struggled to\neffectively address this complex task. Our research aims to address this\nchallenge by developing a human-like planning framework for LLM agents, i.e.,\nguiding the LLM agent to simulate various steps that humans take when solving\nMulti-Phases problems. Specifically, we implement several strategies to enable\nLLM agents to generate a coherent outline for each travel query, mirroring\nhuman planning patterns. Additionally, we integrate Strategy Block and\nKnowledge Block into our framework: Strategy Block facilitates information\ncollection, while Knowledge Block provides essential information for detailed\nplanning. Through our extensive experiments, we demonstrate that our framework\nsignificantly improves the planning capabilities of LLM agents, enabling them\nto tackle the travel planning task with improved efficiency and effectiveness.\nOur experimental results showcase the exceptional performance of the proposed\nframework; when combined with GPT-4-Turbo, it attains $10\\times$ the\nperformance gains in comparison to the baseline framework deployed on\nGPT-4-Turbo.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18208v1",
    "published_date": "2024-05-28 14:13:32 UTC",
    "updated_date": "2024-05-28 14:13:32 UTC"
  },
  {
    "arxiv_id": "2405.18196v1",
    "title": "Render and Diffuse: Aligning Image and Action Spaces for Diffusion-based Behaviour Cloning",
    "authors": [
      "Vitalis Vosylius",
      "Younggyo Seo",
      "Jafar Uruç",
      "Stephen James"
    ],
    "abstract": "In the field of Robot Learning, the complex mapping between high-dimensional\nobservations such as RGB images and low-level robotic actions, two inherently\nvery different spaces, constitutes a complex learning problem, especially with\nlimited amounts of data. In this work, we introduce Render and Diffuse (R&D) a\nmethod that unifies low-level robot actions and RGB observations within the\nimage space using virtual renders of the 3D model of the robot. Using this\njoint observation-action representation it computes low-level robot actions\nusing a learnt diffusion process that iteratively updates the virtual renders\nof the robot. This space unification simplifies the learning problem and\nintroduces inductive biases that are crucial for sample efficiency and spatial\ngeneralisation. We thoroughly evaluate several variants of R&D in simulation\nand showcase their applicability on six everyday tasks in the real world. Our\nresults show that R&D exhibits strong spatial generalisation capabilities and\nis more sample efficient than more common image-to-action methods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Robotics: Science and Systems (RSS) 2024. Videos are available on our\n  project webpage at https://vv19.github.io/render-and-diffuse/",
    "pdf_url": "http://arxiv.org/pdf/2405.18196v1",
    "published_date": "2024-05-28 14:06:10 UTC",
    "updated_date": "2024-05-28 14:06:10 UTC"
  },
  {
    "arxiv_id": "2405.18180v2",
    "title": "Safe Reinforcement Learning in Black-Box Environments via Adaptive Shielding",
    "authors": [
      "Daniel Bethell",
      "Simos Gerasimou",
      "Radu Calinescu",
      "Calum Imrie"
    ],
    "abstract": "Empowering safe exploration of reinforcement learning (RL) agents during\ntraining is a critical challenge towards their deployment in many real-world\nscenarios. When prior knowledge of the domain or task is unavailable, training\nRL agents in unknown, \\textit{black-box} environments presents an even greater\nsafety risk. We introduce \\mbox{ADVICE} (Adaptive Shielding with a Contrastive\nAutoencoder), a novel post-shielding technique that distinguishes safe and\nunsafe features of state-action pairs during training, and uses this knowledge\nto protect the RL agent from executing actions that yield likely hazardous\noutcomes. Our comprehensive experimental evaluation against state-of-the-art\nsafe RL exploration techniques shows that ADVICE significantly reduces safety\nviolations ($\\approx\\!\\!50\\%$) during training, with a competitive outcome\nreward compared to other techniques.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18180v2",
    "published_date": "2024-05-28 13:47:21 UTC",
    "updated_date": "2025-01-31 10:45:55 UTC"
  },
  {
    "arxiv_id": "2405.18172v1",
    "title": "AnyFit: Controllable Virtual Try-on for Any Combination of Attire Across Any Scenario",
    "authors": [
      "Yuhan Li",
      "Hao Zhou",
      "Wenxiang Shang",
      "Ran Lin",
      "Xuanhong Chen",
      "Bingbing Ni"
    ],
    "abstract": "While image-based virtual try-on has made significant strides, emerging\napproaches still fall short of delivering high-fidelity and robust fitting\nimages across various scenarios, as their models suffer from issues of\nill-fitted garment styles and quality degrading during the training process,\nnot to mention the lack of support for various combinations of attire.\nTherefore, we first propose a lightweight, scalable, operator known as Hydra\nBlock for attire combinations. This is achieved through a parallel attention\nmechanism that facilitates the feature injection of multiple garments from\nconditionally encoded branches into the main network. Secondly, to\nsignificantly enhance the model's robustness and expressiveness in real-world\nscenarios, we evolve its potential across diverse settings by synthesizing the\nresiduals of multiple models, as well as implementing a mask region boost\nstrategy to overcome the instability caused by information leakage in existing\nmodels. Equipped with the above design, AnyFit surpasses all baselines on\nhigh-resolution benchmarks and real-world data by a large gap, excelling in\nproducing well-fitting garments replete with photorealistic and rich details.\nFurthermore, AnyFit's impressive performance on high-fidelity virtual try-ons\nin any scenario from any image, paves a new path for future research within the\nfashion community.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website: https://colorful-liyu.github.io/anyfit-page/",
    "pdf_url": "http://arxiv.org/pdf/2405.18172v1",
    "published_date": "2024-05-28 13:33:08 UTC",
    "updated_date": "2024-05-28 13:33:08 UTC"
  },
  {
    "arxiv_id": "2405.18166v2",
    "title": "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing",
    "authors": [
      "Wei Zhao",
      "Zhe Li",
      "Yige Li",
      "Ye Zhang",
      "Jun Sun"
    ],
    "abstract": "Large language models (LLMs) are increasingly being adopted in a wide range\nof real-world applications. Despite their impressive performance, recent\nstudies have shown that LLMs are vulnerable to deliberately crafted adversarial\nprompts even when aligned via Reinforcement Learning from Human Feedback or\nsupervised fine-tuning. While existing defense methods focus on either\ndetecting harmful prompts or reducing the likelihood of harmful responses\nthrough various means, defending LLMs against jailbreak attacks based on the\ninner mechanisms of LLMs remains largely unexplored. In this work, we\ninvestigate how LLMs response to harmful prompts and propose a novel defense\nmethod termed \\textbf{L}ayer-specific \\textbf{Ed}iting (LED) to enhance the\nresilience of LLMs against jailbreak attacks. Through LED, we reveal that\nseveral critical \\textit{safety layers} exist among the early layers of LLMs.\nWe then show that realigning these safety layers (and some selected additional\nlayers) with the decoded safe response from selected target layers can\nsignificantly improve the alignment of LLMs against jailbreak attacks.\nExtensive experiments across various LLMs (e.g., Llama2, Mistral) show the\neffectiveness of LED, which effectively defends against jailbreak attacks while\nmaintaining performance on benign prompts. Our code is available at\n\\url{https://github.com/ledllm/ledllm}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18166v2",
    "published_date": "2024-05-28 13:26:12 UTC",
    "updated_date": "2024-06-14 07:27:26 UTC"
  },
  {
    "arxiv_id": "2405.18165v1",
    "title": "Time Series Representation Models",
    "authors": [
      "Robert Leppich",
      "Vanessa Borst",
      "Veronika Lesch",
      "Samuel Kounev"
    ],
    "abstract": "Time series analysis remains a major challenge due to its sparse\ncharacteristics, high dimensionality, and inconsistent data quality. Recent\nadvancements in transformer-based techniques have enhanced capabilities in\nforecasting and imputation; however, these methods are still resource-heavy,\nlack adaptability, and face difficulties in integrating both local and global\nattributes of time series. To tackle these challenges, we propose a new\narchitectural concept for time series analysis based on introspection. Central\nto this concept is the self-supervised pretraining of Time Series\nRepresentation Models (TSRMs), which once learned can be easily tailored and\nfine-tuned for specific tasks, such as forecasting and imputation, in an\nautomated and resource-efficient manner. Our architecture is equipped with a\nflexible and hierarchical representation learning process, which is robust\nagainst missing data and outliers. It can capture and learn both local and\nglobal features of the structure, semantics, and crucial patterns of a given\ntime series category, such as heart rate data. Our learned time series\nrepresentation models can be efficiently adapted to a specific task, such as\nforecasting or imputation, without manual intervention. Furthermore, our\narchitecture's design supports explainability by highlighting the significance\nof each input value for the task at hand. Our empirical study using four\nbenchmark datasets shows that, compared to investigated state-of-the-art\nbaseline methods, our architecture improves imputation and forecasting errors\nby up to 90.34% and 71.54%, respectively, while reducing the required trainable\nparameters by up to 92.43%. The source code is available at\nhttps://github.com/RobertLeppich/TSRM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18165v1",
    "published_date": "2024-05-28 13:25:31 UTC",
    "updated_date": "2024-05-28 13:25:31 UTC"
  },
  {
    "arxiv_id": "2405.18161v1",
    "title": "Back to the Drawing Board for Fair Representation Learning",
    "authors": [
      "Angéline Pouget",
      "Nikola Jovanović",
      "Mark Vero",
      "Robin Staab",
      "Martin Vechev"
    ],
    "abstract": "The goal of Fair Representation Learning (FRL) is to mitigate biases in\nmachine learning models by learning data representations that enable high\naccuracy on downstream tasks while minimizing discrimination based on sensitive\nattributes. The evaluation of FRL methods in many recent works primarily\nfocuses on the tradeoff between downstream fairness and accuracy with respect\nto a single task that was used to approximate the utility of representations\nduring training (proxy task). This incentivizes retaining only features\nrelevant to the proxy task while discarding all other information. In extreme\ncases, this can cause the learned representations to collapse to a trivial,\nbinary value, rendering them unusable in transfer settings. In this work, we\nargue that this approach is fundamentally mismatched with the original\nmotivation of FRL, which arises from settings with many downstream tasks\nunknown at training time (transfer tasks). To remedy this, we propose to\nrefocus the evaluation protocol of FRL methods primarily around the performance\non transfer tasks. A key challenge when conducting such an evaluation is the\nlack of adequate benchmarks. We address this by formulating four criteria that\na suitable evaluation procedure should fulfill. Based on these, we propose\nTransFair, a benchmark that satisfies these criteria, consisting of novel\nvariations of popular FRL datasets with carefully calibrated transfer tasks. In\nthis setting, we reevaluate state-of-the-art FRL methods, observing that they\noften overfit to the proxy task, which causes them to underperform on certain\ntransfer tasks. We further highlight the importance of task-agnostic learning\nsignals for FRL methods, as they can lead to more transferrable\nrepresentations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18161v1",
    "published_date": "2024-05-28 13:23:04 UTC",
    "updated_date": "2024-05-28 13:23:04 UTC"
  },
  {
    "arxiv_id": "2405.18148v1",
    "title": "Learning to Detour: Shortcut Mitigating Augmentation for Weakly Supervised Semantic Segmentation",
    "authors": [
      "JuneHyoung Kwon",
      "Eunju Lee",
      "Yunsung Cho",
      "YoungBin Kim"
    ],
    "abstract": "Weakly supervised semantic segmentation (WSSS) employing weak forms of labels\nhas been actively studied to alleviate the annotation cost of acquiring\npixel-level labels. However, classifiers trained on biased datasets tend to\nexploit shortcut features and make predictions based on spurious correlations\nbetween certain backgrounds and objects, leading to a poor generalization\nperformance. In this paper, we propose shortcut mitigating augmentation (SMA)\nfor WSSS, which generates synthetic representations of object-background\ncombinations not seen in the training data to reduce the use of shortcut\nfeatures. Our approach disentangles the object-relevant and background\nfeatures. We then shuffle and combine the disentangled representations to\ncreate synthetic features of diverse object-background combinations.\nSMA-trained classifier depends less on contexts and focuses more on the target\nobject when making predictions. In addition, we analyzed the behavior of the\nclassifier on shortcut usage after applying our augmentation using an\nattribution method-based metric. The proposed method achieved the improved\nperformance of semantic segmentation result on PASCAL VOC 2012 and MS COCO 2014\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to WACV 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18148v1",
    "published_date": "2024-05-28 13:07:35 UTC",
    "updated_date": "2024-05-28 13:07:35 UTC"
  },
  {
    "arxiv_id": "2405.18144v3",
    "title": "4-bit Shampoo for Memory-Efficient Network Training",
    "authors": [
      "Sike Wang",
      "Pan Zhou",
      "Jia Li",
      "Hua Huang"
    ],
    "abstract": "Second-order optimizers, maintaining a matrix termed a preconditioner, are\nsuperior to first-order optimizers in both theory and practice. The states\nforming the preconditioner and its inverse root restrict the maximum size of\nmodels trained by second-order optimizers. To address this, compressing 32-bit\noptimizer states to lower bitwidths has shown promise in reducing memory usage.\nHowever, current approaches only pertain to first-order optimizers. In this\npaper, we propose the first 4-bit second-order optimizers, exemplified by 4-bit\nShampoo, maintaining performance similar to that of 32-bit ones. We show that\nquantizing the eigenvector matrix of the preconditioner in 4-bit Shampoo is\nremarkably better than quantizing the preconditioner itself both theoretically\nand experimentally. By rectifying the orthogonality of the quantized\neigenvector matrix, we enhance the approximation of the preconditioner's\neigenvector matrix, which also benefits the computation of its inverse 4-th\nroot. Besides, we find that linear square quantization slightly outperforms\ndynamic tree quantization when quantizing second-order optimizer states.\nEvaluation on various networks for image classification and natural language\nmodeling demonstrates that our 4-bit Shampoo achieves comparable performance to\nits 32-bit counterpart while being more memory-efficient.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 final camera-ready revisions, rectify the legend in\n  figure 9",
    "pdf_url": "http://arxiv.org/pdf/2405.18144v3",
    "published_date": "2024-05-28 13:02:56 UTC",
    "updated_date": "2025-01-10 07:22:12 UTC"
  },
  {
    "arxiv_id": "2405.18139v1",
    "title": "Unlocking Futures: A Natural Language Driven Career Prediction System for Computer Science and Software Engineering Students",
    "authors": [
      "Sakir Hossain Faruque",
      "Sharun Akter Khushbu",
      "Sharmin Akter"
    ],
    "abstract": "A career is a crucial aspect for any person to fulfill their desires through\nhard work. During their studies, students cannot find the best career\nsuggestions unless they receive meaningful guidance tailored to their skills.\nTherefore, we developed an AI-assisted model for early prediction to provide\nbetter career suggestions. Although the task is difficult, proper guidance can\nmake it easier. Effective career guidance requires understanding a student's\nacademic skills, interests, and skill-related activities. In this research, we\ncollected essential information from Computer Science (CS) and Software\nEngineering (SWE) students to train a machine learning (ML) model that predicts\ncareer paths based on students' career-related information. To adequately train\nthe models, we applied Natural Language Processing (NLP) techniques and\ncompleted dataset pre-processing. For comparative analysis, we utilized\nmultiple classification ML algorithms and deep learning (DL) algorithms. This\nstudy contributes valuable insights to educational advising by providing\nspecific career suggestions based on the unique features of CS and SWE\nstudents. Additionally, the research helps individual CS and SWE students find\nsuitable jobs that match their skills, interests, and skill-related activities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18139v1",
    "published_date": "2024-05-28 12:56:57 UTC",
    "updated_date": "2024-05-28 12:56:57 UTC"
  },
  {
    "arxiv_id": "2405.18137v2",
    "title": "Exploiting LLM Quantization",
    "authors": [
      "Kazuki Egashira",
      "Mark Vero",
      "Robin Staab",
      "Jingxuan He",
      "Martin Vechev"
    ],
    "abstract": "Quantization leverages lower-precision weights to reduce the memory usage of\nlarge language models (LLMs) and is a key technique for enabling their\ndeployment on commodity hardware. While LLM quantization's impact on utility\nhas been extensively explored, this work for the first time studies its adverse\neffects from a security perspective. We reveal that widely used quantization\nmethods can be exploited to produce a harmful quantized LLM, even though the\nfull-precision counterpart appears benign, potentially tricking users into\ndeploying the malicious quantized model. We demonstrate this threat using a\nthree-staged attack framework: (i) first, we obtain a malicious LLM through\nfine-tuning on an adversarial task; (ii) next, we quantize the malicious model\nand calculate constraints that characterize all full-precision models that map\nto the same quantized model; (iii) finally, using projected gradient descent,\nwe tune out the poisoned behavior from the full-precision model while ensuring\nthat its weights satisfy the constraints computed in step (ii). This procedure\nresults in an LLM that exhibits benign behavior in full precision but when\nquantized, it follows the adversarial behavior injected in step (i). We\nexperimentally demonstrate the feasibility and severity of such an attack\nacross three diverse scenarios: vulnerable code generation, content injection,\nand over-refusal attack. In practice, the adversary could host the resulting\nfull-precision model on an LLM community hub such as Hugging Face, exposing\nmillions of users to the threat of deploying its malicious quantized version on\ntheir devices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18137v2",
    "published_date": "2024-05-28 12:51:01 UTC",
    "updated_date": "2024-11-04 11:16:38 UTC"
  },
  {
    "arxiv_id": "2405.18123v1",
    "title": "PyTAG: Tabletop Games for Multi-Agent Reinforcement Learning",
    "authors": [
      "Martin Balla",
      "George E. M. Long",
      "James Goodman",
      "Raluca D. Gaina",
      "Diego Perez-Liebana"
    ],
    "abstract": "Modern Tabletop Games present various interesting challenges for Multi-agent\nReinforcement Learning. In this paper, we introduce PyTAG, a new framework that\nsupports interacting with a large collection of games implemented in the\nTabletop Games framework. In this work we highlight the challenges tabletop\ngames provide, from a game-playing agent perspective, along with the\nopportunities they provide for future research. Additionally, we highlight the\ntechnical challenges that involve training Reinforcement Learning agents on\nthese games. To explore the Multi-agent setting provided by PyTAG we train the\npopular Proximal Policy Optimisation Reinforcement Learning algorithm using\nself-play on a subset of games and evaluate the trained policies against some\nsimple agents and Monte-Carlo Tree Search implemented in the Tabletop Games\nframework.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18123v1",
    "published_date": "2024-05-28 12:30:28 UTC",
    "updated_date": "2024-05-28 12:30:28 UTC"
  },
  {
    "arxiv_id": "2405.18119v2",
    "title": "Low-Resource Crop Classification from Multi-Spectral Time Series Using Lossless Compressors",
    "authors": [
      "Wei Cheng",
      "Hongrui Ye",
      "Xiao Wen",
      "Jiachen Zhang",
      "Jiping Xu",
      "Feifan Zhang"
    ],
    "abstract": "Deep learning has significantly improved the accuracy of crop classification\nusing multispectral temporal data. However, these models have complex\nstructures with numerous parameters, requiring large amounts of data and costly\ntraining. In low-resource situations with fewer labeled samples, deep learning\nmodels perform poorly due to insufficient data. Conversely, compressors are\ndata-type agnostic, and non-parametric methods do not bring underlying\nassumptions. Inspired by this insight, we propose a non-training alternative to\ndeep learning models, aiming to address these situations. Specifically, the\nSymbolic Representation Module is proposed to convert the reflectivity into\nsymbolic representations. The symbolic representations are then\ncross-transformed in both the channel and time dimensions to generate symbolic\nembeddings. Next, the Multi-scale Normalised Compression Distance (MNCD) is\ndesigned to measure the correlation between any two symbolic embeddings.\nFinally, based on the MNCDs, high quality crop classification can be achieved\nusing only a k-nearest-neighbor classifier kNN. The entire framework is\nready-to-use and lightweight. Without any training, it outperformed, on\naverage, 7 advanced deep learning models trained at scale on three benchmark\ndatasets. It also outperforms more than half of these models in the few-shot\nsetting with sparse crop labels. Therefore, the high performance and robustness\nof our non-training framework makes it truly applicable to real-world crop\nmapping. Codes are available at:\nhttps://github.com/qinfengsama/Compressor-Based-Crop-Mapping.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.18119v2",
    "published_date": "2024-05-28 12:28:12 UTC",
    "updated_date": "2024-07-05 15:23:58 UTC"
  },
  {
    "arxiv_id": "2405.18118v3",
    "title": "An agent design with goal reaching guarantees for enhancement of learning",
    "authors": [
      "Pavel Osinenko",
      "Grigory Yaremenko",
      "Georgiy Malaniya",
      "Anton Bolychev",
      "Alexander Gepperth"
    ],
    "abstract": "Reinforcement learning is commonly concerned with problems of maximizing\naccumulated rewards in Markov decision processes. Oftentimes, a certain goal\nstate or a subset of the state space attain maximal reward. In such a case, the\nenvironment may be considered solved when the goal is reached. Whereas numerous\ntechniques, learning or non-learning based, exist for solving environments,\ndoing so optimally is the biggest challenge. Say, one may choose a reward rate\nwhich penalizes the action effort. Reinforcement learning is currently among\nthe most actively developed frameworks for solving environments optimally by\nvirtue of maximizing accumulated reward, in other words, returns. Yet, tuning\nagents is a notoriously hard task as reported in a series of works. Our aim\nhere is to help the agent learn a near-optimal policy efficiently while\nensuring a goal reaching property of some basis policy that merely solves the\nenvironment. We suggest an algorithm, which is fairly flexible, and can be used\nto augment practically any agent as long as it comprises of a critic. A formal\nproof of a goal reaching property is provided. Comparative experiments on\nseveral problems under popular baseline agents provided an empirical evidence\nthat the learning can indeed be boosted while ensuring goal reaching property.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.DS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18118v3",
    "published_date": "2024-05-28 12:27:36 UTC",
    "updated_date": "2024-08-21 20:43:36 UTC"
  },
  {
    "arxiv_id": "2405.18113v1",
    "title": "Facilitating Multi-Role and Multi-Behavior Collaboration of Large Language Models for Online Job Seeking and Recruiting",
    "authors": [
      "Hongda Sun",
      "Hongzhan Lin",
      "Haiyu Yan",
      "Chen Zhu",
      "Yang Song",
      "Xin Gao",
      "Shuo Shang",
      "Rui Yan"
    ],
    "abstract": "The emergence of online recruitment services has revolutionized the\ntraditional landscape of job seeking and recruitment, necessitating the\ndevelopment of high-quality industrial applications to improve person-job\nfitting. Existing methods generally rely on modeling the latent semantics of\nresumes and job descriptions and learning a matching function between them.\nInspired by the powerful role-playing capabilities of Large Language Models\n(LLMs), we propose to introduce a mock interview process between LLM-played\ninterviewers and candidates. The mock interview conversations can provide\nadditional evidence for candidate evaluation, thereby augmenting traditional\nperson-job fitting based solely on resumes and job descriptions. However,\ncharacterizing these two roles in online recruitment still presents several\nchallenges, such as developing the skills to raise interview questions,\nformulating appropriate answers, and evaluating two-sided fitness. To this end,\nwe propose MockLLM, a novel applicable framework that divides the person-job\nmatching process into two modules: mock interview generation and two-sided\nevaluation in handshake protocol, jointly enhancing their performance through\ncollaborative behaviors between interviewers and candidates. We design a\nrole-playing framework as a multi-role and multi-behavior paradigm to enable a\nsingle LLM agent to effectively behave with multiple functions for both\nparties. Moreover, we propose reflection memory generation and dynamic prompt\nmodification techniques to refine the behaviors of both sides, enabling\ncontinuous optimization of the augmented additional evidence. Extensive\nexperimental results show that MockLLM can achieve the best performance on\nperson-job matching accompanied by high mock interview quality, envisioning its\nemerging application in real online recruitment in the future.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18113v1",
    "published_date": "2024-05-28 12:23:16 UTC",
    "updated_date": "2024-05-28 12:23:16 UTC"
  },
  {
    "arxiv_id": "2405.18110v1",
    "title": "Individual Contributions as Intrinsic Exploration Scaffolds for Multi-agent Reinforcement Learning",
    "authors": [
      "Xinran Li",
      "Zifan Liu",
      "Shibo Chen",
      "Jun Zhang"
    ],
    "abstract": "In multi-agent reinforcement learning (MARL), effective exploration is\ncritical, especially in sparse reward environments. Although introducing global\nintrinsic rewards can foster exploration in such settings, it often complicates\ncredit assignment among agents. To address this difficulty, we propose\nIndividual Contributions as intrinsic Exploration Scaffolds (ICES), a novel\napproach to motivate exploration by assessing each agent's contribution from a\nglobal view. In particular, ICES constructs exploration scaffolds with Bayesian\nsurprise, leveraging global transition information during centralized training.\nThese scaffolds, used only in training, help to guide individual agents towards\nactions that significantly impact the global latent state transitions.\nAdditionally, ICES separates exploration policies from exploitation policies,\nenabling the former to utilize privileged global information during training.\nExtensive experiments on cooperative benchmark tasks with sparse rewards,\nincluding Google Research Football (GRF) and StarCraft Multi-agent Challenge\n(SMAC), demonstrate that ICES exhibits superior exploration capabilities\ncompared with baselines. The code is publicly available at\nhttps://github.com/LXXXXR/ICES.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "I.2.6; I.2.11"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the Forty-first International Conference on Machine\n  Learning",
    "pdf_url": "http://arxiv.org/pdf/2405.18110v1",
    "published_date": "2024-05-28 12:18:19 UTC",
    "updated_date": "2024-05-28 12:18:19 UTC"
  },
  {
    "arxiv_id": "2405.18106v1",
    "title": "A Unified Temporal Knowledge Graph Reasoning Model Towards Interpolation and Extrapolation",
    "authors": [
      "Kai Chen",
      "Ye Wang",
      "Yitong Li",
      "Aiping Li",
      "Han Yu",
      "Xin Song"
    ],
    "abstract": "Temporal knowledge graph (TKG) reasoning has two settings: interpolation\nreasoning and extrapolation reasoning. Both of them draw plenty of research\ninterest and have great significance. Methods of the former de-emphasize the\ntemporal correlations among facts sequences, while methods of the latter\nrequire strict chronological order of knowledge and ignore inferring clues\nprovided by missing facts of the past. These limit the practicability of TKG\napplications as almost all of the existing TKG reasoning methods are designed\nspecifically to address either one setting. To this end, this paper proposes an\noriginal Temporal PAth-based Reasoning (TPAR) model for both the interpolation\nand extrapolation reasoning. TPAR performs a neural-driven symbolic reasoning\nfashion that is robust to ambiguous and noisy temporal data and with fine\ninterpretability as well. Comprehensive experiments show that TPAR outperforms\nSOTA methods on the link prediction task for both the interpolation and the\nextrapolation settings. A novel pipeline experimental setting is designed to\nevaluate the performances of SOTA combinations and the proposed TPAR towards\ninterpolation and extrapolation reasoning. More diverse experiments are\nconducted to show the robustness and interpretability of TPAR.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in ACL 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2405.18106v1",
    "published_date": "2024-05-28 12:13:07 UTC",
    "updated_date": "2024-05-28 12:13:07 UTC"
  },
  {
    "arxiv_id": "2405.18092v2",
    "title": "LLM experiments with simulation: Large Language Model Multi-Agent System for Simulation Model Parametrization in Digital Twins",
    "authors": [
      "Yuchen Xia",
      "Daniel Dittler",
      "Nasser Jazdi",
      "Haonan Chen",
      "Michael Weyrich"
    ],
    "abstract": "This paper presents a novel design of a multi-agent system framework that\napplies large language models (LLMs) to automate the parametrization of\nsimulation models in digital twins. This framework features specialized LLM\nagents tasked with observing, reasoning, decision-making, and summarizing,\nenabling them to dynamically interact with digital twin simulations to explore\nparametrization possibilities and determine feasible parameter settings to\nachieve an objective. The proposed approach enhances the usability of\nsimulation model by infusing it with knowledge heuristics from LLM and enables\nautonomous search for feasible parametrization to solve a user task.\nFurthermore, the system has the potential to increase user-friendliness and\nreduce the cognitive load on human users by assisting in complex\ndecision-making processes. The effectiveness and functionality of the system\nare demonstrated through a case study, and the visualized demos and codes are\navailable at a GitHub Repository:\nhttps://github.com/YuchenXia/LLMDrivenSimulation",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.MA",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to IEEE-ETFA2024, under peer-review",
    "pdf_url": "http://arxiv.org/pdf/2405.18092v2",
    "published_date": "2024-05-28 11:59:40 UTC",
    "updated_date": "2024-07-22 14:03:48 UTC"
  },
  {
    "arxiv_id": "2405.18077v1",
    "title": "Design Principles for Falsifiable, Replicable and Reproducible Empirical ML Research",
    "authors": [
      "Daniel Vranješ",
      "Oliver Niggemann"
    ],
    "abstract": "Empirical research plays a fundamental role in the machine learning domain.\nAt the heart of impactful empirical research lies the development of clear\nresearch hypotheses, which then shape the design of experiments. The execution\nof experiments must be carried out with precision to ensure reliable results,\nfollowed by statistical analysis to interpret these outcomes. This process is\nkey to either supporting or refuting initial hypotheses. Despite its\nimportance, there is a high variability in research practices across the\nmachine learning community and no uniform understanding of quality criteria for\nempirical research. To address this gap, we propose a model for the empirical\nresearch process, accompanied by guidelines to uphold the validity of empirical\nresearch. By embracing these recommendations, greater consistency, enhanced\nreliability and increased impact can be achieved.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18077v1",
    "published_date": "2024-05-28 11:37:59 UTC",
    "updated_date": "2024-05-28 11:37:59 UTC"
  },
  {
    "arxiv_id": "2405.18073v1",
    "title": "Towards Dialogues for Joint Human-AI Reasoning and Value Alignment",
    "authors": [
      "Elfia Bezou-Vrakatseli",
      "Oana Cocarascu",
      "Sanjay Modgil"
    ],
    "abstract": "We argue that enabling human-AI dialogue, purposed to support joint reasoning\n(i.e., 'inquiry'), is important for ensuring that AI decision making is aligned\nwith human values and preferences. In particular, we point to logic-based\nmodels of argumentation and dialogue, and suggest that the traditional focus on\npersuasion dialogues be replaced by a focus on inquiry dialogues, and the\ndistinct challenges that joint inquiry raises. Given recent dramatic advances\nin the performance of large language models (LLMs), and the anticipated\nincrease in their use for decision making, we provide a roadmap for research\ninto inquiry dialogues for supporting joint human-LLM reasoning tasks that are\nethically salient, and that thereby require that decisions are value aligned.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18073v1",
    "published_date": "2024-05-28 11:29:57 UTC",
    "updated_date": "2024-05-28 11:29:57 UTC"
  },
  {
    "arxiv_id": "2405.18068v1",
    "title": "A Survey of Latent Factor Models in Recommender Systems",
    "authors": [
      "Hind I. Alshbanat",
      "Hafida Benhidour",
      "Said Kerrache"
    ],
    "abstract": "Recommender systems are essential tools in the digital era, providing\npersonalized content to users in areas like e-commerce, entertainment, and\nsocial media. Among the many approaches developed to create these systems,\nlatent factor models have proven particularly effective. This survey\nsystematically reviews latent factor models in recommender systems, focusing on\ntheir core principles, methodologies, and recent advancements. The literature\nis examined through a structured framework covering learning data, model\narchitecture, learning strategies, and optimization techniques. The analysis\nincludes a taxonomy of contributions and detailed discussions on the types of\nlearning data used, such as implicit feedback, trust, and content data, various\nmodels such as probabilistic, nonlinear, and neural models, and an exploration\nof diverse learning strategies like online learning, transfer learning, and\nactive learning. Furthermore, the survey addresses the optimization strategies\nused to train latent factor models, improving their performance and\nscalability. By identifying trends, gaps, and potential research directions,\nthis survey aims to provide valuable insights for researchers and practitioners\nlooking to advance the field of recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18068v1",
    "published_date": "2024-05-28 11:28:59 UTC",
    "updated_date": "2024-05-28 11:28:59 UTC"
  },
  {
    "arxiv_id": "2405.18065v2",
    "title": "EffoVPR: Effective Foundation Model Utilization for Visual Place Recognition",
    "authors": [
      "Issar Tzachor",
      "Boaz Lerner",
      "Matan Levy",
      "Michael Green",
      "Tal Berkovitz Shalev",
      "Gavriel Habib",
      "Dvir Samuel",
      "Noam Korngut Zailer",
      "Or Shimshi",
      "Nir Darshan",
      "Rami Ben-Ari"
    ],
    "abstract": "The task of Visual Place Recognition (VPR) is to predict the location of a\nquery image from a database of geo-tagged images. Recent studies in VPR have\nhighlighted the significant advantage of employing pre-trained foundation\nmodels like DINOv2 for the VPR task. However, these models are often deemed\ninadequate for VPR without further fine-tuning on VPR-specific data. In this\npaper, we present an effective approach to harness the potential of a\nfoundation model for VPR. We show that features extracted from self-attention\nlayers can act as a powerful re-ranker for VPR, even in a zero-shot setting.\nOur method not only outperforms previous zero-shot approaches but also\nintroduces results competitive with several supervised methods. We then show\nthat a single-stage approach utilizing internal ViT layers for pooling can\nproduce global features that achieve state-of-the-art performance, with\nimpressive feature compactness down to 128D. Moreover, integrating our local\nfoundation features for re-ranking further widens this performance gap. Our\nmethod also demonstrates exceptional robustness and generalization, setting new\nstate-of-the-art performance, while handling challenging conditions such as\nocclusion, day-night transitions, and seasonal variations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.18065v2",
    "published_date": "2024-05-28 11:24:41 UTC",
    "updated_date": "2025-02-02 22:46:41 UTC"
  },
  {
    "arxiv_id": "2405.18064v2",
    "title": "Automated Real-World Sustainability Data Generation from Images of Buildings",
    "authors": [
      "Peter J Bentley",
      "Soo Ling Lim",
      "Rajat Mathur",
      "Sid Narang"
    ],
    "abstract": "When data on building features is unavailable, the task of determining how to\nimprove that building in terms of carbon emissions becomes infeasible. We show\nthat from only a set of images, a Large Language Model with appropriate prompt\nengineering and domain knowledge can successfully estimate a range of building\nfeatures relevant for sustainability calculations. We compare our novel\nimage-to-data method with a ground truth comprising real building data for 47\napartments and achieve accuracy better than a human performing the same task.\nWe also demonstrate that the method can generate tailored recommendations to\nthe owner on how best to improve their properties and discuss methods to scale\nthe approach.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "68T07, 94A08"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.18064v2",
    "published_date": "2024-05-28 11:24:20 UTC",
    "updated_date": "2024-08-28 13:41:34 UTC"
  },
  {
    "arxiv_id": "2406.17789v1",
    "title": "Spanish and LLM Benchmarks: is MMLU Lost in Translation?",
    "authors": [
      "Irene Plaza",
      "Nina Melero",
      "Cristina del Pozo",
      "Javier Conde",
      "Pedro Reviriego",
      "Marina Mayor-Rocher",
      "María Grandury"
    ],
    "abstract": "The evaluation of Large Language Models (LLMs) is a key element in their\ncontinuous improvement process and many benchmarks have been developed to\nassess the performance of LLMs in different tasks and topics. As LLMs become\nadopted worldwide, evaluating them in languages other than English is\nincreasingly important. However, most LLM benchmarks are simply translated\nusing an automated tool and then run in the target language. This means that\nthe results depend not only on the LLM performance in that language but also on\nthe quality of the translation. In this paper, we consider the case of the\nwell-known Massive Multitask Language Understanding (MMLU) benchmark. Selected\ncategories of the benchmark are translated into Spanish using Azure Translator\nand ChatGPT4 and run on ChatGPT4. Next, the results are processed to identify\nthe test items that produce different answers in Spanish and English. Those are\nthen analyzed manually to understand if the automatic translation caused the\nchange. The results show that a significant fraction of the failing items can\nbe attributed to mistakes in the translation of the benchmark. These results\nmake a strong case for improving benchmarks in languages other than English by\nat least revising the translations of the items and preferably by adapting the\ntests to the target language by experts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17789v1",
    "published_date": "2024-05-28 11:13:40 UTC",
    "updated_date": "2024-05-28 11:13:40 UTC"
  },
  {
    "arxiv_id": "2405.18050v2",
    "title": "Learning-Based Link Anomaly Detection in Continuous-Time Dynamic Graphs",
    "authors": [
      "Tim Poštuvan",
      "Claas Grohnfeldt",
      "Michele Russo",
      "Giulio Lovisotto"
    ],
    "abstract": "Anomaly detection in continuous-time dynamic graphs is an emerging field yet\nunder-explored in the context of learning algorithms. In this paper, we pioneer\nstructured analyses of link-level anomalies and graph representation learning\nfor identifying categorically anomalous graph links. First, we introduce a\nfine-grained taxonomy for edge-level anomalies leveraging structural, temporal,\nand contextual graph properties. Based on these properties, we introduce a\nmethod for generating and injecting typed anomalies into graphs. Next, we\nintroduce a novel method to generate continuous-time dynamic graphs featuring\nconsistencies across either or combinations of time, structure, and context. To\nenable temporal graph learning methods to detect specific types of anomalous\nlinks rather than the bare existence of a link, we extend the generic link\nprediction setting by: (1) conditioning link existence on contextual edge\nattributes; and (2) refining the training regime to accommodate diverse\nperturbations in the negative edge sampler. Comprehensive benchmarks on\nsynthetic and real-world datasets -- featuring synthetic and labeled organic\nanomalies and employing six state-of-the-art link prediction methods --\nvalidate our taxonomy and generation processes for anomalies and benign graphs,\nas well as our approach to adapting methods for anomaly detection. Our results\nreveal that different learning methods excel in capturing different aspects of\ngraph normality and detecting different types of anomalies. We conclude with a\ncomprehensive list of findings highlighting opportunities for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Transactions on Machine Learning Research (TMLR), 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18050v2",
    "published_date": "2024-05-28 11:05:41 UTC",
    "updated_date": "2024-09-28 12:33:56 UTC"
  },
  {
    "arxiv_id": "2405.18047v1",
    "title": "2BP: 2-Stage Backpropagation",
    "authors": [
      "Christopher Rae",
      "Joseph K. L. Lee",
      "James Richings"
    ],
    "abstract": "As Deep Neural Networks (DNNs) grow in size and complexity, they often exceed\nthe memory capacity of a single accelerator, necessitating the sharding of\nmodel parameters across multiple accelerators. Pipeline parallelism is a\ncommonly used sharding strategy for training large DNNs. However, current\nimplementations of pipeline parallelism are being unintentionally bottlenecked\nby the automatic differentiation tools provided by ML frameworks. This paper\nintroduces 2-stage backpropagation (2BP). By splitting the backward propagation\nstep into two separate stages, we can reduce idle compute time. We tested 2BP\non various model architectures and pipelining schedules, achieving increases in\nthroughput in all cases. Using 2BP, we were able to achieve a 1.70x increase in\nthroughput compared to traditional methods when training a LLaMa-like\ntransformer with 7 billion parameters across 4 GPUs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18047v1",
    "published_date": "2024-05-28 11:02:01 UTC",
    "updated_date": "2024-05-28 11:02:01 UTC"
  },
  {
    "arxiv_id": "2405.18044v2",
    "title": "Cognitive Insights and Stable Coalition Matching for Fostering Multi-Agent Cooperation",
    "authors": [
      "Jiaqi Shao",
      "Tianjun Yuan",
      "Tao Lin",
      "Bing Luo"
    ],
    "abstract": "Cognitive abilities, such as Theory of Mind (ToM), play a vital role in\nfacilitating cooperation in human social interactions. However, our study\nreveals that agents with higher ToM abilities may not necessarily exhibit\nbetter cooperative behavior compared to those with lower ToM abilities. To\naddress this challenge, we propose a novel matching coalition mechanism that\nleverages the strengths of agents with different ToM levels by explicitly\nconsidering belief alignment and specialized abilities when forming coalitions.\nOur proposed matching algorithm seeks to find stable coalitions that maximize\nthe potential for cooperative behavior and ensure long-term viability. By\nincorporating cognitive insights into the design of multi-agent systems, our\nwork demonstrates the potential of leveraging ToM to create more sophisticated\nand human-like coordination strategies that foster cooperation and improve\noverall system performance.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18044v2",
    "published_date": "2024-05-28 10:59:33 UTC",
    "updated_date": "2025-05-14 15:08:35 UTC"
  },
  {
    "arxiv_id": "2405.18040v1",
    "title": "Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew Resilience",
    "authors": [
      "Thanh Trung Huynh",
      "Trong Bang Nguyen",
      "Phi Le Nguyen",
      "Thanh Tam Nguyen",
      "Matthias Weidlich",
      "Quoc Viet Hung Nguyen",
      "Karl Aberer"
    ],
    "abstract": "Federated learning (FL) has recently emerged as a compelling machine learning\nparadigm, prioritizing the protection of privacy for training data. The\nincreasing demand to address issues such as ``the right to be forgotten'' and\ncombat data poisoning attacks highlights the importance of techniques, known as\n\\textit{unlearning}, which facilitate the removal of specific training data\nfrom trained FL models. Despite numerous unlearning methods proposed for\ncentralized learning, they often prove inapplicable to FL due to fundamental\ndifferences in the operation of the two learning paradigms. Consequently,\nunlearning in FL remains in its early stages, presenting several challenges.\nMany existing unlearning solutions in FL require a costly retraining process,\nwhich can be burdensome for clients. Moreover, these methods are primarily\nvalidated through experiments, lacking theoretical assurances. In this study,\nwe introduce Fast-FedUL, a tailored unlearning method for FL, which eliminates\nthe need for retraining entirely. Through meticulous analysis of the target\nclient's influence on the global model in each round, we develop an algorithm\nto systematically remove the impact of the target client from the trained\nmodel. In addition to presenting empirical findings, we offer a theoretical\nanalysis delineating the upper bound of our unlearned model and the exact\nretrained model (the one obtained through retraining using untargeted clients).\nExperimental results with backdoor attack scenarios indicate that Fast-FedUL\neffectively removes almost all traces of the target client, while retaining the\nknowledge of untargeted clients (obtaining a high accuracy of up to 98\\% on the\nmain task). Significantly, Fast-FedUL attains the lowest time complexity,\nproviding a speed that is 1000 times faster than retraining. Our source code is\npublicly available at \\url{https://github.com/thanhtrunghuynh93/fastFedUL}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in ECML PKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18040v1",
    "published_date": "2024-05-28 10:51:38 UTC",
    "updated_date": "2024-05-28 10:51:38 UTC"
  },
  {
    "arxiv_id": "2405.18028v1",
    "title": "Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints",
    "authors": [
      "Aryo Pradipta Gema",
      "Chaeeun Lee",
      "Pasquale Minervini",
      "Luke Daines",
      "T. Ian Simpson",
      "Beatrice Alex"
    ],
    "abstract": "The MEDIQA-CORR 2024 shared task aims to assess the ability of Large Language\nModels (LLMs) to identify and correct medical errors in clinical notes. In this\nstudy, we evaluate the capability of general LLMs, specifically GPT-3.5 and\nGPT-4, to identify and correct medical errors with multiple prompting\nstrategies. Recognising the limitation of LLMs in generating accurate\ncorrections only via prompting strategies, we propose incorporating error-span\npredictions from a smaller, fine-tuned model in two ways: 1) by presenting it\nas a hint in the prompt and 2) by framing it as multiple-choice questions from\nwhich the LLM can choose the best correction. We found that our proposed\nprompting strategies significantly improve the LLM's ability to generate\ncorrections. Our best-performing solution with 8-shot + CoT + hints ranked\nsixth in the shared task leaderboard. Additionally, our comprehensive analyses\nshow the impact of the location of the error sentence, the prompted role, and\nthe position of the multiple-choice option on the accuracy of the LLM. This\nprompts further questions about the readiness of LLM to be implemented in\nreal-world clinical settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18028v1",
    "published_date": "2024-05-28 10:20:29 UTC",
    "updated_date": "2024-05-28 10:20:29 UTC"
  },
  {
    "arxiv_id": "2405.18025v2",
    "title": "Where's Waldo: Diffusion Features for Personalized Segmentation and Retrieval",
    "authors": [
      "Dvir Samuel",
      "Rami Ben-Ari",
      "Matan Levy",
      "Nir Darshan",
      "Gal Chechik"
    ],
    "abstract": "Personalized retrieval and segmentation aim to locate specific instances\nwithin a dataset based on an input image and a short description of the\nreference instance. While supervised methods are effective, they require\nextensive labeled data for training. Recently, self-supervised foundation\nmodels have been introduced to these tasks showing comparable results to\nsupervised methods. However, a significant flaw in these models is evident:\nthey struggle to locate a desired instance when other instances within the same\nclass are presented. In this paper, we explore text-to-image diffusion models\nfor these tasks. Specifically, we propose a novel approach called PDM for\nPersonalized Features Diffusion Matching, that leverages intermediate features\nof pre-trained text-to-image models for personalization tasks without any\nadditional training. PDM demonstrates superior performance on popular retrieval\nand segmentation benchmarks, outperforming even supervised methods. We also\nhighlight notable shortcomings in current instance and segmentation datasets\nand propose new benchmarks for these tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18025v2",
    "published_date": "2024-05-28 10:13:18 UTC",
    "updated_date": "2024-09-30 12:50:13 UTC"
  },
  {
    "arxiv_id": "2405.18016v4",
    "title": "On Creativity and Open-Endedness",
    "authors": [
      "L. B. Soros",
      "Alyssa Adams",
      "Stefano Kalonaris",
      "Olaf Witkowski",
      "Christian Guckelsberger"
    ],
    "abstract": "Artificial Life (ALife) as an interdisciplinary field draws inspiration and\ninfluence from a variety of perspectives. Scientific progress crucially\ndepends, then, on concerted efforts to invite cross-disciplinary dialogue. The\ngoal of this paper is to revitalize discussions of potential connections\nbetween the fields of Computational Creativity (CC) and ALife, focusing\nspecifically on the concept of Open-Endedness (OE); the primary goal of CC is\nto endow artificial systems with creativity, and ALife has dedicated much\nresearch effort into studying and synthesizing OE and artificial innovation.\nHowever, despite the close proximity of these concepts, their use so far\nremains confined to their respective communities, and their relationship is\nlargely unclear. We provide historical context for research in both domains,\nand review the limited work connecting research on creativity and OE\nexplicitly. We then highlight specific questions to be considered, with the\neventual goals of (i) decreasing conceptual ambiguity by highlighting\nsimilarities and differences between the concepts of OE and creativity, (ii)\nidentifying synergy effects of a research agenda that encompasses both\nconcepts, and (iii) establishing a dialogue between ALife and CC research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, accepted for publication in the proceedings of the 2024\n  International Conference for Artificial Life, Copenhagen, Denmark",
    "pdf_url": "http://arxiv.org/pdf/2405.18016v4",
    "published_date": "2024-05-28 09:57:37 UTC",
    "updated_date": "2024-06-23 18:10:31 UTC"
  },
  {
    "arxiv_id": "2405.18014v2",
    "title": "Coupled Mamba: Enhanced Multi-modal Fusion with Coupled State Space Model",
    "authors": [
      "Wenbing Li",
      "Hang Zhou",
      "Junqing Yu",
      "Zikai Song",
      "Wei Yang"
    ],
    "abstract": "The essence of multi-modal fusion lies in exploiting the complementary\ninformation inherent in diverse modalities. However, prevalent fusion methods\nrely on traditional neural architectures and are inadequately equipped to\ncapture the dynamics of interactions across modalities, particularly in\npresence of complex intra- and inter-modality correlations. Recent advancements\nin State Space Models (SSMs), notably exemplified by the Mamba model, have\nemerged as promising contenders. Particularly, its state evolving process\nimplies stronger modality fusion paradigm, making multi-modal fusion on SSMs an\nappealing direction. However, fusing multiple modalities is challenging for\nSSMs due to its hardware-aware parallelism designs. To this end, this paper\nproposes the Coupled SSM model, for coupling state chains of multiple\nmodalities while maintaining independence of intra-modality state processes.\nSpecifically, in our coupled scheme, we devise an inter-modal hidden states\ntransition scheme, in which the current state is dependent on the states of its\nown chain and that of the neighbouring chains at the previous time-step. To\nfully comply with the hardware-aware parallelism, we devise an expedite coupled\nstate transition scheme and derive its corresponding global convolution kernel\nfor parallelism. Extensive experiments on CMU-MOSEI, CH-SIMS, CH-SIMSV2 through\nmulti-domain input verify the effectiveness of our model compared to current\nstate-of-the-art methods, improved F1-Score by 0.4\\%, 0.9\\%, and 2.3\\% on the\nthree datasets respectively, 49\\% faster inference and 83.7\\% GPU memory save.\nThe results demonstrate that Coupled Mamba model is capable of enhanced\nmulti-modal fusion.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18014v2",
    "published_date": "2024-05-28 09:57:03 UTC",
    "updated_date": "2024-05-29 05:19:15 UTC"
  },
  {
    "arxiv_id": "2405.18003v1",
    "title": "MAVIN: Multi-Action Video Generation with Diffusion Models via Transition Video Infilling",
    "authors": [
      "Bowen Zhang",
      "Xiaofei Xie",
      "Haotian Lu",
      "Na Ma",
      "Tianlin Li",
      "Qing Guo"
    ],
    "abstract": "Diffusion-based video generation has achieved significant progress, yet\ngenerating multiple actions that occur sequentially remains a formidable task.\nDirectly generating a video with sequential actions can be extremely\nchallenging due to the scarcity of fine-grained action annotations and the\ndifficulty in establishing temporal semantic correspondences and maintaining\nlong-term consistency. To tackle this, we propose an intuitive and\nstraightforward solution: splicing multiple single-action video segments\nsequentially. The core challenge lies in generating smooth and natural\ntransitions between these segments given the inherent complexity and\nvariability of action transitions. We introduce MAVIN (Multi-Action Video\nINfilling model), designed to generate transition videos that seamlessly\nconnect two given videos, forming a cohesive integrated sequence. MAVIN\nincorporates several innovative techniques to address challenges in the\ntransition video infilling task. Firstly, a consecutive noising strategy\ncoupled with variable-length sampling is employed to handle large infilling\ngaps and varied generation lengths. Secondly, boundary frame guidance (BFG) is\nproposed to address the lack of semantic guidance during transition generation.\nLastly, a Gaussian filter mixer (GFM) dynamically manages noise initialization\nduring inference, mitigating train-test discrepancy while preserving generation\nflexibility. Additionally, we introduce a new metric, CLIP-RS (CLIP Relative\nSmoothness), to evaluate temporal coherence and smoothness, complementing\ntraditional quality-based metrics. Experimental results on horse and tiger\nscenarios demonstrate MAVIN's superior performance in generating smooth and\ncoherent video transitions compared to existing methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18003v1",
    "published_date": "2024-05-28 09:46:09 UTC",
    "updated_date": "2024-05-28 09:46:09 UTC"
  },
  {
    "arxiv_id": "2405.17998v1",
    "title": "Source Echo Chamber: Exploring the Escalation of Source Bias in User, Data, and Recommender System Feedback Loop",
    "authors": [
      "Yuqi Zhou",
      "Sunhao Dai",
      "Liang Pang",
      "Gang Wang",
      "Zhenhua Dong",
      "Jun Xu",
      "Ji-Rong Wen"
    ],
    "abstract": "Recently, researchers have uncovered that neural retrieval models prefer\nAI-generated content (AIGC), called source bias. Compared to active search\nbehavior, recommendation represents another important means of information\nacquisition, where users are more prone to source bias. Furthermore, delving\ninto the recommendation scenario, as AIGC becomes integrated within the\nfeedback loop involving users, data, and the recommender system, it\nprogressively contaminates the candidate items, the user interaction history,\nand ultimately, the data used to train the recommendation models. How and to\nwhat extent the source bias affects the neural recommendation models within\nfeedback loop remains unknown. In this study, we extend the investigation of\nsource bias into the realm of recommender systems, specifically examining its\nimpact across different phases of the feedback loop. We conceptualize the\nprogression of AIGC integration into the recommendation content ecosystem in\nthree distinct phases-HGC dominate, HGC-AIGC coexist, and AIGC dominance-each\nrepresenting past, present, and future states, respectively. Through extensive\nexperiments across three datasets from diverse domains, we demonstrate the\nprevalence of source bias and reveal a potential digital echo chamber with\nsource bias amplification throughout the feedback loop. This trend risks\ncreating a recommender ecosystem with limited information source, such as AIGC,\nbeing disproportionately recommended. To counteract this bias and prevent its\nescalation in the feedback loop, we introduce a black-box debiasing method that\nmaintains model impartiality towards both HGC and AIGC. Our experimental\nresults validate the effectiveness of the proposed debiasing method, confirming\nits potential to disrupt the feedback loop.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17998v1",
    "published_date": "2024-05-28 09:34:50 UTC",
    "updated_date": "2024-05-28 09:34:50 UTC"
  },
  {
    "arxiv_id": "2405.17995v1",
    "title": "DMT-JEPA: Discriminative Masked Targets for Joint-Embedding Predictive Architecture",
    "authors": [
      "Shentong Mo",
      "Sukmin Yun"
    ],
    "abstract": "The joint-embedding predictive architecture (JEPA) recently has shown\nimpressive results in extracting visual representations from unlabeled imagery\nunder a masking strategy. However, we reveal its disadvantages, notably its\ninsufficient understanding of local semantics. This deficiency originates from\nmasked modeling in the embedding space, resulting in a reduction of\ndiscriminative power and can even lead to the neglect of critical local\nsemantics. To bridge this gap, we introduce DMT-JEPA, a novel masked modeling\nobjective rooted in JEPA, specifically designed to generate discriminative\nlatent targets from neighboring information. Our key idea is simple: we\nconsider a set of semantically similar neighboring patches as a target of a\nmasked patch. To be specific, the proposed DMT-JEPA (a) computes feature\nsimilarities between each masked patch and its corresponding neighboring\npatches to select patches having semantically meaningful relations, and (b)\nemploys lightweight cross-attention heads to aggregate features of neighboring\npatches as the masked targets. Consequently, DMT-JEPA demonstrates strong\ndiscriminative power, offering benefits across a diverse spectrum of downstream\ntasks. Through extensive experiments, we demonstrate our effectiveness across\nvarious visual benchmarks, including ImageNet-1K image classification, ADE20K\nsemantic segmentation, and COCO object detection tasks. Code is available at:\n\\url{https://github.com/DMTJEPA/DMTJEPA}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17995v1",
    "published_date": "2024-05-28 09:28:52 UTC",
    "updated_date": "2024-05-28 09:28:52 UTC"
  },
  {
    "arxiv_id": "2405.17992v2",
    "title": "fMRI predictors based on language models of increasing complexity recover brain left lateralization",
    "authors": [
      "Laurent Bonnasse-Gahot",
      "Christophe Pallier"
    ],
    "abstract": "Over the past decade, studies of naturalistic language processing where\nparticipants are scanned while listening to continuous text have flourished.\nUsing word embeddings at first, then large language models, researchers have\ncreated encoding models to analyze the brain signals. Presenting these models\nwith the same text as the participants allows to identify brain areas where\nthere is a significant correlation between the functional magnetic resonance\nimaging (fMRI) time series and the ones predicted by the models' artificial\nneurons. One intriguing finding from these studies is that they have revealed\nhighly symmetric bilateral activation patterns, somewhat at odds with the\nwell-known left lateralization of language processing. Here, we report analyses\nof an fMRI dataset where we manipulate the complexity of large language models,\ntesting 28 pretrained models from 8 different families, ranging from 124M to\n14.2B parameters. First, we observe that the performance of models in\npredicting brain responses follows a scaling law, where the fit with brain\nactivity increases linearly with the logarithm of the number of parameters of\nthe model (and its performance on natural language processing tasks). Second,\nalthough this effect is present in both hemispheres, it is stronger in the left\nthan in the right hemisphere. Specifically, the left-right difference in brain\ncorrelation follows a scaling law with the number of parameters. This finding\nreconciles computational analyses of brain activity using large language models\nwith the classic observation from aphasic patients showing left hemisphere\ndominance for language.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.17992v2",
    "published_date": "2024-05-28 09:24:52 UTC",
    "updated_date": "2024-11-04 14:01:50 UTC"
  },
  {
    "arxiv_id": "2405.17991v2",
    "title": "VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections",
    "authors": [
      "Roy Miles",
      "Pradyumna Reddy",
      "Ismail Elezi",
      "Jiankang Deng"
    ],
    "abstract": "Large language models (LLMs) have recently emerged as powerful tools for\ntackling many language-processing tasks. Despite their success, training and\nfine-tuning these models is still far too computationally and memory intensive.\nIn this paper, we identify and characterise the important components needed for\neffective model convergence using gradient descent. In doing so we find that\nthe intermediate activations used to implement backpropagation can be\nexcessively compressed without incurring any degradation in performance. This\nresult leads us to a cheap and memory-efficient algorithm for both fine-tuning\nand pre-training LLMs. The proposed algorithm simply divides the tokens up into\nsmaller sub-tokens before projecting them onto a fixed 1-dimensional subspace\nduring the forward pass. These features are then coarsely reconstructed during\nthe backward pass to implement the update rules. We confirm the effectiveness\nof our algorithm as being complimentary to many state-of-the-art PEFT methods\non the VTAB-1k fine-tuning benchmark. Furthermore, we outperform QLoRA for\nfine-tuning LLaMA and show competitive performance against other\nmemory-efficient pre-training methods on the large-scale C4 dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024. Code available at https://github.com/roymiles/VeLoRA",
    "pdf_url": "http://arxiv.org/pdf/2405.17991v2",
    "published_date": "2024-05-28 09:23:14 UTC",
    "updated_date": "2024-10-21 12:53:21 UTC"
  },
  {
    "arxiv_id": "2405.17978v2",
    "title": "FASTopic: Pretrained Transformer is a Fast, Adaptive, Stable, and Transferable Topic Model",
    "authors": [
      "Xiaobao Wu",
      "Thong Nguyen",
      "Delvin Ce Zhang",
      "William Yang Wang",
      "Anh Tuan Luu"
    ],
    "abstract": "Topic models have been evolving rapidly over the years, from conventional to\nrecent neural models. However, existing topic models generally struggle with\neither effectiveness, efficiency, or stability, highly impeding their practical\napplications. In this paper, we propose FASTopic, a fast, adaptive, stable, and\ntransferable topic model. FASTopic follows a new paradigm: Dual\nSemantic-relation Reconstruction (DSR). Instead of previous conventional,\nVAE-based, or clustering-based methods, DSR directly models the semantic\nrelations among document embeddings from a pretrained Transformer and learnable\ntopic and word embeddings. By reconstructing through these semantic relations,\nDSR discovers latent topics. This brings about a neat and efficient topic\nmodeling framework. We further propose a novel Embedding Transport Plan (ETP)\nmethod. Rather than early straightforward approaches, ETP explicitly\nregularizes the semantic relations as optimal transport plans. This addresses\nthe relation bias issue and thus leads to effective topic modeling. Extensive\nexperiments on benchmark datasets demonstrate that our FASTopic shows superior\neffectiveness, efficiency, adaptivity, stability, and transferability, compared\nto state-of-the-art baselines across various scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NeurIPS 2024. Code is available at\n  https://github.com/BobXWu/Fastopic",
    "pdf_url": "http://arxiv.org/pdf/2405.17978v2",
    "published_date": "2024-05-28 09:06:38 UTC",
    "updated_date": "2024-10-26 12:36:11 UTC"
  },
  {
    "arxiv_id": "2405.17976v2",
    "title": "Yuan 2.0-M32: Mixture of Experts with Attention Router",
    "authors": [
      "Shaohua Wu",
      "Jiangang Luo",
      "Xi Chen",
      "Lingjun Li",
      "Xudong Zhao",
      "Tong Yu",
      "Chao Wang",
      "Yue Wang",
      "Fei Wang",
      "Weixu Qiao",
      "Houbo He",
      "Zeru Zhang",
      "Zeyu Sun",
      "Junxiong Mao",
      "Chong Shen"
    ],
    "abstract": "Yuan 2.0-M32, with a similar base architecture as Yuan-2.0 2B, uses a\nmixture-of-experts architecture with 32 experts of which 2 experts are active.\nA new router network, Attention Router, is proposed and adopted for a more\nefficient selection of experts, which improves the accuracy compared to the\nmodel with classical router network. Yuan 2.0-M32 is trained with 2000B tokens\nfrom scratch, and the training computation consumption is only 9.25% of a dense\nmodel at the same parameter scale. Yuan 2.0-M32 demonstrates competitive\ncapability on coding, math, and various domains of expertise, with only 3.7B\nactive parameters of 40B in total, and 7.4 GFlops forward computation per\ntoken, both of which are only 1/19 of Llama3-70B. Yuan 2.0-M32 surpass\nLlama3-70B on MATH and ARC-Challenge benchmark, with accuracy of 55.89 and 95.8\nrespectively. The models and source codes of Yuan 2.0-M32 are released at\nGithub1.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages,3 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.17976v2",
    "published_date": "2024-05-28 09:05:08 UTC",
    "updated_date": "2024-05-29 07:19:58 UTC"
  },
  {
    "arxiv_id": "2405.17974v1",
    "title": "Recent Trends in Personalized Dialogue Generation: A Review of Datasets, Methodologies, and Evaluations",
    "authors": [
      "Yi-Pei Chen",
      "Noriki Nishida",
      "Hideki Nakayama",
      "Yuji Matsumoto"
    ],
    "abstract": "Enhancing user engagement through personalization in conversational agents\nhas gained significance, especially with the advent of large language models\nthat generate fluent responses. Personalized dialogue generation, however, is\nmultifaceted and varies in its definition -- ranging from instilling a persona\nin the agent to capturing users' explicit and implicit cues. This paper seeks\nto systemically survey the recent landscape of personalized dialogue\ngeneration, including the datasets employed, methodologies developed, and\nevaluation metrics applied. Covering 22 datasets, we highlight benchmark\ndatasets and newer ones enriched with additional features. We further analyze\n17 seminal works from top conferences between 2021-2023 and identify five\ndistinct types of problems. We also shed light on recent progress by LLMs in\npersonalized dialogue generation. Our evaluation section offers a comprehensive\nsummary of assessment facets and metrics utilized in these works. In\nconclusion, we discuss prevailing challenges and envision prospect directions\nfor future research in personalized dialogue generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented in LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.17974v1",
    "published_date": "2024-05-28 09:04:13 UTC",
    "updated_date": "2024-05-28 09:04:13 UTC"
  },
  {
    "arxiv_id": "2405.17969v4",
    "title": "Knowledge Circuits in Pretrained Transformers",
    "authors": [
      "Yunzhi Yao",
      "Ningyu Zhang",
      "Zekun Xi",
      "Mengru Wang",
      "Ziwen Xu",
      "Shumin Deng",
      "Huajun Chen"
    ],
    "abstract": "The remarkable capabilities of modern large language models are rooted in\ntheir vast repositories of knowledge encoded within their parameters, enabling\nthem to perceive the world and engage in reasoning. The inner workings of how\nthese models store knowledge have long been a subject of intense interest and\ninvestigation among researchers. To date, most studies have concentrated on\nisolated components within these models, such as the Multilayer Perceptrons and\nattention head. In this paper, we delve into the computation graph of the\nlanguage model to uncover the knowledge circuits that are instrumental in\narticulating specific knowledge. The experiments, conducted with GPT2 and\nTinyLLAMA, have allowed us to observe how certain information heads, relation\nheads, and Multilayer Perceptrons collaboratively encode knowledge within the\nmodel. Moreover, we evaluate the impact of current knowledge editing techniques\non these knowledge circuits, providing deeper insights into the functioning and\nconstraints of these editing methodologies. Finally, we utilize knowledge\ncircuits to analyze and interpret language model behaviors such as\nhallucinations and in-context learning. We believe the knowledge circuits hold\npotential for advancing our understanding of Transformers and guiding the\nimproved design of knowledge editing. Code and data are available in\nhttps://github.com/zjunlp/KnowledgeCircuits.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024, 26 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.17969v4",
    "published_date": "2024-05-28 08:56:33 UTC",
    "updated_date": "2025-01-03 16:41:37 UTC"
  },
  {
    "arxiv_id": "2405.17959v1",
    "title": "Attention-based sequential recommendation system using multimodal data",
    "authors": [
      "Hyungtaik Oh",
      "Wonkeun Jo",
      "Dongil Kim"
    ],
    "abstract": "Sequential recommendation systems that model dynamic preferences based on a\nuse's past behavior are crucial to e-commerce. Recent studies on these systems\nhave considered various types of information such as images and texts. However,\nmultimodal data have not yet been utilized directly to recommend products to\nusers. In this study, we propose an attention-based sequential recommendation\nmethod that employs multimodal data of items such as images, texts, and\ncategories. First, we extract image and text features from pre-trained VGG and\nBERT and convert categories into multi-labeled forms. Subsequently, attention\noperations are performed independent of the item sequence and multimodal\nrepresentations. Finally, the individual attention information is integrated\nthrough an attention fusion function. In addition, we apply multitask learning\nloss for each modality to improve the generalization performance. The\nexperimental results obtained from the Amazon datasets show that the proposed\nmethod outperforms those of conventional sequential recommendation systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "I.2.1; I.2.4; I.2.7"
    ],
    "primary_category": "cs.IR",
    "comment": "18 pages, 4 figures, preprinted",
    "pdf_url": "http://arxiv.org/pdf/2405.17959v1",
    "published_date": "2024-05-28 08:41:05 UTC",
    "updated_date": "2024-05-28 08:41:05 UTC"
  },
  {
    "arxiv_id": "2405.17957v1",
    "title": "Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking Contrastive Learning and Unassociated Word Exclusion",
    "authors": [
      "Xiaobao Wu",
      "Xinshuai Dong",
      "Liangming Pan",
      "Thong Nguyen",
      "Anh Tuan Luu"
    ],
    "abstract": "Dynamic topic models track the evolution of topics in sequential documents,\nwhich have derived various applications like trend analysis and opinion mining.\nHowever, existing models suffer from repetitive topic and unassociated topic\nissues, failing to reveal the evolution and hindering further applications. To\naddress these issues, we break the tradition of simply chaining topics in\nexisting work and propose a novel neural \\modelfullname. We introduce a new\nevolution-tracking contrastive learning method that builds the similarity\nrelations among dynamic topics. This not only tracks topic evolution but also\nmaintains topic diversity, mitigating the repetitive topic issue. To avoid\nunassociated topics, we further present an unassociated word exclusion method\nthat consistently excludes unassociated words from discovered topics. Extensive\nexperiments demonstrate our model significantly outperforms state-of-the-art\nbaselines, tracking topic evolution with high-quality topics, showing better\nperformance on downstream tasks, and remaining robust to the hyperparameter for\nevolution intensities. Our code is available at https://github.com/bobxwu/CFDTM .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2405.17957v1",
    "published_date": "2024-05-28 08:39:49 UTC",
    "updated_date": "2024-05-28 08:39:49 UTC"
  },
  {
    "arxiv_id": "2405.17956v3",
    "title": "Unified Preference Optimization: Language Model Alignment Beyond the Preference Frontier",
    "authors": [
      "Anirudhan Badrinath",
      "Prabhat Agarwal",
      "Jiajing Xu"
    ],
    "abstract": "For aligning large language models (LLMs), prior work has leveraged\nreinforcement learning via human feedback (RLHF) or variations of direct\npreference optimization (DPO). While DPO offers a simpler framework based on\nmaximum likelihood estimation, it compromises on the ability to easily tune\nlanguage models to maximize auxiliary, non-preferential objectives according to\nthe LLM designer's preferences (e.g., tuning lexical style or minimizing\nspecific kinds of harmful content). Critically, these designer objectives may\nnot be amply human-labeled or represented in available data, align with user\npreferences, or even be able to be captured tractably by binary preference\npairs. To leverage the simplicity and performance of DPO with the generality of\nRL, we propose a unified approach. Based on a simple decomposition of\npreference and auxiliary objectives, we allow for tuning LLMs to optimize user\nand designer preferences without any additional specialized or preference data,\ncomputational cost, stability ``tweaks'', or training instability. The proposed\nmethod, Unified Preference Optimization, shows the ability to effectively\ngeneralize to user preferences and auxiliary objectives, while preserving or\nsurpassing alignment performance on challenging benchmarks across a range of\nmodel sizes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17956v3",
    "published_date": "2024-05-28 08:35:48 UTC",
    "updated_date": "2025-03-31 17:58:31 UTC"
  },
  {
    "arxiv_id": "2405.17950v1",
    "title": "Self-Guiding Exploration for Combinatorial Problems",
    "authors": [
      "Zangir Iklassov",
      "Yali Du",
      "Farkhad Akimov",
      "Martin Takac"
    ],
    "abstract": "Large Language Models (LLMs) have become pivotal in addressing reasoning\ntasks across diverse domains, including arithmetic, commonsense, and symbolic\nreasoning. They utilize prompting techniques such as Exploration-of-Thought,\nDecomposition, and Refinement to effectively navigate and solve intricate\ntasks. Despite these advancements, the application of LLMs to Combinatorial\nProblems (CPs), known for their NP-hardness and critical roles in logistics and\nresource management remains underexplored. To address this gap, we introduce a\nnovel prompting strategy: Self-Guiding Exploration (SGE), designed to enhance\nthe performance of solving CPs. SGE operates autonomously, generating multiple\nthought trajectories for each CP task. It then breaks these trajectories down\ninto actionable subtasks, executes them sequentially, and refines the results\nto ensure optimal outcomes. We present our research as the first to apply LLMs\nto a broad range of CPs and demonstrate that SGE outperforms existing prompting\nstrategies by over 27.84% in CP optimization performance. Additionally, SGE\nachieves a 2.46% higher accuracy over the best existing results in other\nreasoning tasks (arithmetic, commonsense, and symbolic).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.17950v1",
    "published_date": "2024-05-28 08:26:54 UTC",
    "updated_date": "2024-05-28 08:26:54 UTC"
  },
  {
    "arxiv_id": "2405.17942v2",
    "title": "Learning Shared RGB-D Fields: Unified Self-supervised Pre-training for Label-efficient LiDAR-Camera 3D Perception",
    "authors": [
      "Xiaohao Xu",
      "Ye Li",
      "Tianyi Zhang",
      "Jinrong Yang",
      "Matthew Johnson-Roberson",
      "Xiaonan Huang"
    ],
    "abstract": "Constructing large-scale labeled datasets for multi-modal perception model\ntraining in autonomous driving presents significant challenges. This has\nmotivated the development of self-supervised pretraining strategies. However,\nexisting pretraining methods mainly employ distinct approaches for each\nmodality. In contrast, we focus on LiDAR-Camera 3D perception models and\nintroduce a unified pretraining strategy, NeRF-Supervised Masked Auto Encoder\n(NS-MAE), which optimizes all modalities through a shared formulation. NS-MAE\nleverages NeRF's ability to encode both appearance and geometry, enabling\nefficient masked reconstruction of multi-modal data. Specifically, embeddings\nare extracted from corrupted LiDAR point clouds and images, conditioned on view\ndirections and locations. Then, these embeddings are rendered into multi-modal\nfeature maps from two crucial viewpoints for 3D driving perception: perspective\nand bird's-eye views. The original uncorrupted data serve as reconstruction\ntargets for self-supervised learning. Extensive experiments demonstrate the\nsuperior transferability of NS-MAE across various 3D perception tasks under\ndifferent fine-tuning settings. Notably, NS-MAE outperforms prior SOTA\npre-training methods that employ separate strategies for each modality in BEV\nmap segmentation under the label-efficient fine-tuning setting. Our code is\npublicly available at https://github.com/Xiaohao-Xu/Unified-Pretrain-AD/ .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.17942v2",
    "published_date": "2024-05-28 08:13:49 UTC",
    "updated_date": "2024-10-11 22:01:56 UTC"
  },
  {
    "arxiv_id": "2405.17940v1",
    "title": "World Models for General Surgical Grasping",
    "authors": [
      "Hongbin Lin",
      "Bin Li",
      "Chun Wai Wong",
      "Juan Rojas",
      "Xiangyu Chu",
      "Kwok Wai Samuel Au"
    ],
    "abstract": "Intelligent vision control systems for surgical robots should adapt to\nunknown and diverse objects while being robust to system disturbances. Previous\nmethods did not meet these requirements due to mainly relying on pose\nestimation and feature tracking. We propose a world-model-based deep\nreinforcement learning framework \"Grasp Anything for Surgery\" (GAS), that\nlearns a pixel-level visuomotor policy for surgical grasping, enhancing both\ngenerality and robustness. In particular, a novel method is proposed to\nestimate the values and uncertainties of depth pixels for a rigid-link object's\ninaccurate region based on the empirical prior of the object's size; both depth\nand mask images of task objects are encoded to a single compact 3-channel image\n(size: 64x64x3) by dynamically zooming in the mask regions, minimizing the\ninformation loss. The learned controller's effectiveness is extensively\nevaluated in simulation and in a real robot. Our learned visuomotor policy\nhandles: i) unseen objects, including 5 types of target grasping objects and a\nrobot gripper, in unstructured real-world surgery environments, and ii)\ndisturbances in perception and control. Note that we are the first work to\nachieve a unified surgical control system that grasps diverse surgical objects\nusing different robot grippers on real robots in complex surgery scenes\n(average success rate: 69%). Our system also demonstrates significant\nrobustness across 6 conditions including background variation, target\ndisturbance, camera pose variation, kinematic control error, image noise, and\nre-grasping after the gripped target object drops from the gripper. Videos and\ncodes can be found on our project page: https://linhongbin.github.io/gas/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17940v1",
    "published_date": "2024-05-28 08:11:12 UTC",
    "updated_date": "2024-05-28 08:11:12 UTC"
  },
  {
    "arxiv_id": "2405.17935v3",
    "title": "Tool Learning with Large Language Models: A Survey",
    "authors": [
      "Changle Qu",
      "Sunhao Dai",
      "Xiaochi Wei",
      "Hengyi Cai",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Jun Xu",
      "Ji-Rong Wen"
    ],
    "abstract": "Recently, tool learning with large language models (LLMs) has emerged as a\npromising paradigm for augmenting the capabilities of LLMs to tackle highly\ncomplex problems. Despite growing attention and rapid advancements in this\nfield, the existing literature remains fragmented and lacks systematic\norganization, posing barriers to entry for newcomers. This gap motivates us to\nconduct a comprehensive survey of existing works on tool learning with LLMs. In\nthis survey, we focus on reviewing existing literature from the two primary\naspects (1) why tool learning is beneficial and (2) how tool learning is\nimplemented, enabling a comprehensive understanding of tool learning with LLMs.\nWe first explore the \"why\" by reviewing both the benefits of tool integration\nand the inherent benefits of the tool learning paradigm from six specific\naspects. In terms of \"how\", we systematically review the literature according\nto a taxonomy of four key stages in the tool learning workflow: task planning,\ntool selection, tool calling, and response generation. Additionally, we provide\na detailed summary of existing benchmarks and evaluation methods, categorizing\nthem according to their relevance to different stages. Finally, we discuss\ncurrent challenges and outline potential future directions, aiming to inspire\nboth researchers and industrial developers to further explore this emerging and\npromising area. We also maintain a GitHub repository to continually keep track\nof the relevant papers and resources in this rising area at\nhttps://github.com/quchangle1/LLM-Tool-Survey.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The article has been accepted by Frontiers of Computer Science (FCS),\n  with the DOI: {10.1007/s11704-024-40678-2}",
    "pdf_url": "http://arxiv.org/pdf/2405.17935v3",
    "published_date": "2024-05-28 08:01:26 UTC",
    "updated_date": "2024-11-04 15:07:18 UTC"
  },
  {
    "arxiv_id": "2405.17934v2",
    "title": "Proof of Quality: A Costless Paradigm for Trustless Generative AI Model Inference on Blockchains",
    "authors": [
      "Zhenjie Zhang",
      "Yuyang Rao",
      "Hao Xiao",
      "Xiaokui Xiao",
      "Yin Yang"
    ],
    "abstract": "Generative AI models, such as GPT-4 and Stable Diffusion, have demonstrated\npowerful and disruptive capabilities in natural language and image tasks.\nHowever, deploying these models in decentralized environments remains\nchallenging. Unlike traditional centralized deployment, systematically\nguaranteeing the integrity of AI model services in fully decentralized\nenvironments, particularly on trustless blockchains, is both crucial and\ndifficult. In this paper, we present a new inference paradigm called\n\\emph{proof of quality} (PoQ) to enable the deployment of arbitrarily large\ngenerative models on blockchain architecture. Unlike traditional approaches\nbased on validating inference procedures, such as ZKML or OPML, our PoQ\nparadigm focuses on the outcome quality of model inference. Using lightweight\nBERT-based cross-encoders as our underlying quality evaluation model, we design\nand implement PQML, the first practical protocol for real-world NLP generative\nmodel inference on blockchains, tailored for popular open-source models such as\nLlama 3 and Mixtral. Our analysis demonstrates that our protocol is robust\nagainst adversarial but rational participants in ecosystems, where lazy or\ndishonest behavior results in fewer benefits compared to well-behaving\nparticipants. The computational overhead of validating the quality evaluation\nis minimal, allowing quality validators to complete the quality check within a\nsecond, even using only a CPU. Preliminary simulation results show that PoQ\nconsensus is generated in milliseconds, 1,000 times faster than any existing\nscheme.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.17934v2",
    "published_date": "2024-05-28 08:00:54 UTC",
    "updated_date": "2024-05-30 13:26:35 UTC"
  },
  {
    "arxiv_id": "2405.17927v1",
    "title": "The Evolution of Multimodal Model Architectures",
    "authors": [
      "Shakti N. Wadekar",
      "Abhishek Chaurasia",
      "Aman Chadha",
      "Eugenio Culurciello"
    ],
    "abstract": "This work uniquely identifies and characterizes four prevalent multimodal\nmodel architectural patterns in the contemporary multimodal landscape.\nSystematically categorizing models by architecture type facilitates monitoring\nof developments in the multimodal domain. Distinct from recent survey papers\nthat present general information on multimodal architectures, this research\nconducts a comprehensive exploration of architectural details and identifies\nfour specific architectural types. The types are distinguished by their\nrespective methodologies for integrating multimodal inputs into the deep neural\nnetwork model. The first two types (Type A and B) deeply fuses multimodal\ninputs within the internal layers of the model, whereas the following two types\n(Type C and D) facilitate early fusion at the input stage. Type-A employs\nstandard cross-attention, whereas Type-B utilizes custom-designed layers for\nmodality fusion within the internal layers. On the other hand, Type-C utilizes\nmodality-specific encoders, while Type-D leverages tokenizers to process the\nmodalities at the model's input stage. The identified architecture types aid\nthe monitoring of any-to-any multimodal model development. Notably, Type-C and\nType-D are currently favored in the construction of any-to-any multimodal\nmodels. Type-C, distinguished by its non-tokenizing multimodal model\narchitecture, is emerging as a viable alternative to Type-D, which utilizes\ninput-tokenizing techniques. To assist in model selection, this work highlights\nthe advantages and disadvantages of each architecture type based on data and\ncompute requirements, architecture complexity, scalability, simplification of\nadding modalities, training objectives, and any-to-any multimodal generation\ncapability.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 6 tables, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.17927v1",
    "published_date": "2024-05-28 07:48:15 UTC",
    "updated_date": "2024-05-28 07:48:15 UTC"
  },
  {
    "arxiv_id": "2405.17924v1",
    "title": "Generative AI Enhances Team Performance and Reduces Need for Traditional Teams",
    "authors": [
      "Ning Li",
      "Huaikang Zhou",
      "Kris Mikel-Hong"
    ],
    "abstract": "Recent advancements in generative artificial intelligence (AI) have\ntransformed collaborative work processes, yet the impact on team performance\nremains underexplored. Here we examine the role of generative AI in enhancing\nor replacing traditional team dynamics using a randomized controlled experiment\nwith 435 participants across 122 teams. We show that teams augmented with\ngenerative AI significantly outperformed those relying solely on human\ncollaboration across various performance measures. Interestingly, teams with\nmultiple AIs did not exhibit further gains, indicating diminishing returns with\nincreased AI integration. Our analysis suggests that centralized AI usage by a\nfew team members is more effective than distributed engagement. Additionally,\nindividual-AI pairs matched the performance of conventional teams, suggesting a\nreduced need for traditional team structures in some contexts. However, despite\nthis capability, individual-AI pairs still fell short of the performance levels\nachieved by AI-assisted teams. These findings underscore that while generative\nAI can replace some traditional team functions, more comprehensively\nintegrating AI within team structures provides superior benefits, enhancing\noverall effectiveness beyond individual efforts.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.HC",
    "comment": "55 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.17924v1",
    "published_date": "2024-05-28 07:47:03 UTC",
    "updated_date": "2024-05-28 07:47:03 UTC"
  },
  {
    "arxiv_id": "2405.17921v1",
    "title": "Towards Clinical AI Fairness: Filling Gaps in the Puzzle",
    "authors": [
      "Mingxuan Liu",
      "Yilin Ning",
      "Salinelat Teixayavong",
      "Xiaoxuan Liu",
      "Mayli Mertens",
      "Yuqing Shang",
      "Xin Li",
      "Di Miao",
      "Jie Xu",
      "Daniel Shu Wei Ting",
      "Lionel Tim-Ee Cheng",
      "Jasmine Chiat Ling Ong",
      "Zhen Ling Teo",
      "Ting Fang Tan",
      "Narrendar RaviChandran",
      "Fei Wang",
      "Leo Anthony Celi",
      "Marcus Eng Hock Ong",
      "Nan Liu"
    ],
    "abstract": "The ethical integration of Artificial Intelligence (AI) in healthcare\nnecessitates addressing fairness-a concept that is highly context-specific\nacross medical fields. Extensive studies have been conducted to expand the\ntechnical components of AI fairness, while tremendous calls for AI fairness\nhave been raised from healthcare. Despite this, a significant disconnect\npersists between technical advancements and their practical clinical\napplications, resulting in a lack of contextualized discussion of AI fairness\nin clinical settings. Through a detailed evidence gap analysis, our review\nsystematically pinpoints several deficiencies concerning both healthcare data\nand the provided AI fairness solutions. We highlight the scarcity of research\non AI fairness in many medical domains where AI technology is increasingly\nutilized. Additionally, our analysis highlights a substantial reliance on group\nfairness, aiming to ensure equality among demographic groups from a macro\nhealthcare system perspective; in contrast, individual fairness, focusing on\nequity at a more granular level, is frequently overlooked. To bridge these\ngaps, our review advances actionable strategies for both the healthcare and AI\nresearch communities. Beyond applying existing AI fairness methods in\nhealthcare, we further emphasize the importance of involving healthcare\nprofessionals to refine AI fairness concepts and methods to ensure contextually\nrelevant and ethically sound AI applications in healthcare.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17921v1",
    "published_date": "2024-05-28 07:42:55 UTC",
    "updated_date": "2024-05-28 07:42:55 UTC"
  },
  {
    "arxiv_id": "2405.17918v1",
    "title": "Cost-Sensitive Multi-Fidelity Bayesian Optimization with Transfer of Learning Curve Extrapolation",
    "authors": [
      "Dong Bok Lee",
      "Aoxuan Silvia Zhang",
      "Byungjoo Kim",
      "Junhyeon Park",
      "Juho Lee",
      "Sung Ju Hwang",
      "Hae Beom Lee"
    ],
    "abstract": "In this paper, we address the problem of cost-sensitive multi-fidelity\nBayesian Optimization (BO) for efficient hyperparameter optimization (HPO).\nSpecifically, we assume a scenario where users want to early-stop the BO when\nthe performance improvement is not satisfactory with respect to the required\ncomputational cost. Motivated by this scenario, we introduce utility, which is\na function predefined by each user and describes the trade-off between cost and\nperformance of BO. This utility function, combined with our novel acquisition\nfunction and stopping criterion, allows us to dynamically choose for each BO\nstep the best configuration that we expect to maximally improve the utility in\nfuture, and also automatically stop the BO around the maximum utility. Further,\nwe improve the sample efficiency of existing learning curve (LC) extrapolation\nmethods with transfer learning, while successfully capturing the correlations\nbetween different configurations to develop a sensible surrogate function for\nmulti-fidelity BO. We validate our algorithm on various LC datasets and found\nit outperform all the previous multi-fidelity BO and transfer-BO baselines we\nconsider, achieving significantly better trade-off between cost and performance\nof BO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17918v1",
    "published_date": "2024-05-28 07:38:39 UTC",
    "updated_date": "2024-05-28 07:38:39 UTC"
  },
  {
    "arxiv_id": "2405.17913v2",
    "title": "OV-DQUO: Open-Vocabulary DETR with Denoising Text Query Training and Open-World Unknown Objects Supervision",
    "authors": [
      "Junjie Wang",
      "Bin Chen",
      "Bin Kang",
      "Yulin Li",
      "YiChi Chen",
      "Weizhi Xian",
      "Huifeng Chang",
      "Yong Xu"
    ],
    "abstract": "Open-vocabulary detection aims to detect objects from novel categories beyond\nthe base categories on which the detector is trained. However, existing\nopen-vocabulary detectors trained on base category data tend to assign higher\nconfidence to trained categories and confuse novel categories with the\nbackground. To resolve this, we propose OV-DQUO, an\n\\textbf{O}pen-\\textbf{V}ocabulary DETR with \\textbf{D}enoising text\n\\textbf{Q}uery training and open-world \\textbf{U}nknown \\textbf{O}bjects\nsupervision. Specifically, we introduce a wildcard matching method. This method\nenables the detector to learn from pairs of unknown objects recognized by the\nopen-world detector and text embeddings with general semantics, mitigating the\nconfidence bias between base and novel categories. Additionally, we propose a\ndenoising text query training strategy. It synthesizes foreground and\nbackground query-box pairs from open-world unknown objects to train the\ndetector through contrastive learning, enhancing its ability to distinguish\nnovel objects from the background. We conducted extensive experiments on the\nchallenging OV-COCO and OV-LVIS benchmarks, achieving new state-of-the-art\nresults of 45.6 AP50 and 39.3 mAP on novel categories respectively, without the\nneed for additional training data. Models and code are released at\n\\url{https://github.com/xiaomoguhz/OV-DQUO}",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17913v2",
    "published_date": "2024-05-28 07:33:27 UTC",
    "updated_date": "2024-08-21 02:40:34 UTC"
  },
  {
    "arxiv_id": "2405.17910v1",
    "title": "Human-Cobot collaboration's impact on success, time completion, errors, workload, gestures and acceptability during an assembly task",
    "authors": [
      "Étienne Fournier",
      "Christine Jeoffrion",
      "Belal Hmedan",
      "Damien Pellier",
      "Humbert Fiorino",
      "Aurélie Landry"
    ],
    "abstract": "The 5.0 industry promotes collaborative robots (cobots). This research\nstudies the impacts of cobot collaboration using an experimental setup. 120\nparticipants realized a simple and a complex assembly task. 50% collaborated\nwith another human (H/H) and 50% with a cobot (H/C). The workload and the\nacceptability of the cobotic collaboration were measured. Working with a cobot\ndecreases the effect of the task complexity on the human workload and on the\noutput quality. However, it increases the time completion and the number of\ngestures (while decreasing their frequency). The H/C couples have a higher\nchance of success but they take more time and more gestures to realize the\ntask. The results of this research could help developers and stakeholders to\nunderstand the impacts of implementing a cobot in production chains.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17910v1",
    "published_date": "2024-05-28 07:30:28 UTC",
    "updated_date": "2024-05-28 07:30:28 UTC"
  },
  {
    "arxiv_id": "2405.17905v1",
    "title": "Cycle-YOLO: A Efficient and Robust Framework for Pavement Damage Detection",
    "authors": [
      "Zhengji Li",
      "Xi Xiao",
      "Jiacheng Xie",
      "Yuxiao Fan",
      "Wentao Wang",
      "Gang Chen",
      "Liqiang Zhang",
      "Tianyang Wang"
    ],
    "abstract": "With the development of modern society, traffic volume continues to increase\nin most countries worldwide, leading to an increase in the rate of pavement\ndamage Therefore, the real-time and highly accurate pavement damage detection\nand maintenance have become the current need. In this paper, an enhanced\npavement damage detection method with CycleGAN and improved YOLOv5 algorithm is\npresented. We selected 7644 self-collected images of pavement damage samples as\nthe initial dataset and augmented it by CycleGAN. Due to a substantial\ndifference between the images generated by CycleGAN and real road images, we\nproposed a data enhancement method based on an improved Scharr filter,\nCycleGAN, and Laplacian pyramid. To improve the target recognition effect on a\ncomplex background and solve the problem that the spatial pyramid pooling-fast\nmodule in the YOLOv5 network cannot handle multiscale targets, we introduced\nthe convolutional block attention module attention mechanism and proposed the\natrous spatial pyramid pooling with squeeze-and-excitation structure. In\naddition, we optimized the loss function of YOLOv5 by replacing the CIoU with\nEIoU. The experimental results showed that our algorithm achieved a precision\nof 0.872, recall of 0.854, and mean average precision@0.5 of 0.882 in detecting\nthree main types of pavement damage: cracks, potholes, and patching. On the\nGPU, its frames per second reached 68, meeting the requirements for real-time\ndetection. Its overall performance even exceeded the current more advanced\nYOLOv7 and achieved good results in practical applications, providing a basis\nfor decision-making in pavement damage detection and prevention.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17905v1",
    "published_date": "2024-05-28 07:27:42 UTC",
    "updated_date": "2024-05-28 07:27:42 UTC"
  },
  {
    "arxiv_id": "2405.17902v2",
    "title": "Boosting Protein Language Models with Negative Sample Mining",
    "authors": [
      "Yaoyao Xu",
      "Xinjian Zhao",
      "Xiaozhuang Song",
      "Benyou Wang",
      "Tianshu Yu"
    ],
    "abstract": "We introduce a pioneering methodology for boosting large language models in\nthe domain of protein representation learning. Our primary contribution lies in\nthe refinement process for correlating the over-reliance on co-evolution\nknowledge, in a way that networks are trained to distill invaluable insights\nfrom negative samples, constituted by protein pairs sourced from disparate\ncategories. By capitalizing on this novel approach, our technique steers the\ntraining of transformer-based models within the attention score space. This\nadvanced strategy not only amplifies performance but also reflects the nuanced\nbiological behaviors exhibited by proteins, offering aligned evidence with\ntraditional biological mechanisms such as protein-protein interaction. We\nexperimentally observed improved performance on various tasks over datasets, on\ntop of several well-established large protein models. This innovative paradigm\nopens up promising horizons for further progress in the realms of protein\nresearch and computational biology.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 4 figures. Accepted by ECML-PKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.17902v2",
    "published_date": "2024-05-28 07:24:20 UTC",
    "updated_date": "2024-06-29 07:07:49 UTC"
  },
  {
    "arxiv_id": "2405.17901v1",
    "title": "Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote Sensing",
    "authors": [
      "Irem Ulku",
      "O. Ozgur Tanriover",
      "Erdem Akagündüz"
    ],
    "abstract": "Plant health can be monitored dynamically using multispectral sensors that\nmeasure Near-Infrared reflectance (NIR). Despite this potential, obtaining and\nannotating high-resolution NIR images poses a significant challenge for\ntraining deep neural networks. Typically, large networks pre-trained on the RGB\ndomain are utilized to fine-tune infrared images. This practice introduces a\ndomain shift issue because of the differing visual traits between RGB and NIR\nimages.As an alternative to fine-tuning, a method called low-rank adaptation\n(LoRA) enables more efficient training by optimizing rank-decomposition\nmatrices while keeping the original network weights frozen. However, existing\nparameter-efficient adaptation strategies for remote sensing images focus on\nRGB images and overlook domain shift issues in the NIR domain. Therefore, this\nstudy investigates the potential benefits of using vision transformer (ViT)\nbackbones pre-trained in the RGB domain, with low-rank adaptation for\ndownstream tasks in the NIR domain. Extensive experiments demonstrate that\nemploying LoRA with pre-trained ViT backbones yields the best performance for\ndownstream tasks applied to NIR images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.17901v1",
    "published_date": "2024-05-28 07:24:07 UTC",
    "updated_date": "2024-05-28 07:24:07 UTC"
  },
  {
    "arxiv_id": "2405.17898v1",
    "title": "FlashST: A Simple and Universal Prompt-Tuning Framework for Traffic Prediction",
    "authors": [
      "Zhonghang Li",
      "Lianghao Xia",
      "Yong Xu",
      "Chao Huang"
    ],
    "abstract": "The objective of traffic prediction is to accurately forecast and analyze the\ndynamics of transportation patterns, considering both space and time. However,\nthe presence of distribution shift poses a significant challenge in this field,\nas existing models struggle to generalize well when faced with test data that\nsignificantly differs from the training distribution. To tackle this issue,\nthis paper introduces a simple and universal spatio-temporal prompt-tuning\nframework-FlashST, which adapts pre-trained models to the specific\ncharacteristics of diverse downstream datasets, improving generalization in\ndiverse traffic prediction scenarios. Specifically, the FlashST framework\nemploys a lightweight spatio-temporal prompt network for in-context learning,\ncapturing spatio-temporal invariant knowledge and facilitating effective\nadaptation to diverse scenarios. Additionally, we incorporate a distribution\nmapping mechanism to align the data distributions of pre-training and\ndownstream data, facilitating effective knowledge transfer in spatio-temporal\nforecasting. Empirical evaluations demonstrate the effectiveness of our FlashST\nacross different spatio-temporal prediction tasks using diverse urban datasets.\nCode is available at https://github.com/HKUDS/FlashST.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by ICML 2024 (poster)",
    "pdf_url": "http://arxiv.org/pdf/2405.17898v1",
    "published_date": "2024-05-28 07:18:52 UTC",
    "updated_date": "2024-05-28 07:18:52 UTC"
  },
  {
    "arxiv_id": "2405.17894v2",
    "title": "White-box Multimodal Jailbreaks Against Large Vision-Language Models",
    "authors": [
      "Ruofan Wang",
      "Xingjun Ma",
      "Hanxu Zhou",
      "Chuanjun Ji",
      "Guangnan Ye",
      "Yu-Gang Jiang"
    ],
    "abstract": "Recent advancements in Large Vision-Language Models (VLMs) have underscored\ntheir superiority in various multimodal tasks. However, the adversarial\nrobustness of VLMs has not been fully explored. Existing methods mainly assess\nrobustness through unimodal adversarial attacks that perturb images, while\nassuming inherent resilience against text-based attacks. Different from\nexisting attacks, in this work we propose a more comprehensive strategy that\njointly attacks both text and image modalities to exploit a broader spectrum of\nvulnerability within VLMs. Specifically, we propose a dual optimization\nobjective aimed at guiding the model to generate affirmative responses with\nhigh toxicity. Our attack method begins by optimizing an adversarial image\nprefix from random noise to generate diverse harmful responses in the absence\nof text input, thus imbuing the image with toxic semantics. Subsequently, an\nadversarial text suffix is integrated and co-optimized with the adversarial\nimage prefix to maximize the probability of eliciting affirmative responses to\nvarious harmful instructions. The discovered adversarial image prefix and text\nsuffix are collectively denoted as a Universal Master Key (UMK). When\nintegrated into various malicious queries, UMK can circumvent the alignment\ndefenses of VLMs and lead to the generation of objectionable content, known as\njailbreaks. The experimental results demonstrate that our universal attack\nstrategy can effectively jailbreak MiniGPT-4 with a 96% success rate,\nhighlighting the vulnerability of VLMs and the urgent need for new alignment\nstrategies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17894v2",
    "published_date": "2024-05-28 07:13:30 UTC",
    "updated_date": "2024-10-14 03:15:23 UTC"
  },
  {
    "arxiv_id": "2405.17893v1",
    "title": "Arithmetic Reasoning with LLM: Prolog Generation & Permutation",
    "authors": [
      "Xiaocheng Yang",
      "Bingsen Chen",
      "Yik-Cheung Tam"
    ],
    "abstract": "Instructing large language models (LLMs) to solve elementary school math\nproblems has shown great success using Chain of Thought (CoT). However, the CoT\napproach relies on an LLM to generate a sequence of arithmetic calculations\nwhich can be prone to cascaded calculation errors. We hypothesize that an LLM\nshould focus on extracting predicates and generating symbolic formulas from the\nmath problem description so that the underlying calculation can be done via an\nexternal code interpreter. We investigate using LLM to generate Prolog programs\nto solve mathematical questions. Experimental results show that our\nProlog-based arithmetic problem-solving outperforms CoT generation in the GSM8K\nbenchmark across three distinct LLMs. In addition, given the insensitive\nordering of predicates and symbolic formulas in Prolog, we propose to permute\nthe ground truth predicates for more robust LLM training via data augmentation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 4 figures, accepted by NAACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2405.17893v1",
    "published_date": "2024-05-28 07:13:25 UTC",
    "updated_date": "2024-05-28 07:13:25 UTC"
  },
  {
    "arxiv_id": "2405.17888v3",
    "title": "Getting More Juice Out of the SFT Data: Reward Learning from Human Demonstration Improves SFT for LLM Alignment",
    "authors": [
      "Jiaxiang Li",
      "Siliang Zeng",
      "Hoi-To Wai",
      "Chenliang Li",
      "Alfredo Garcia",
      "Mingyi Hong"
    ],
    "abstract": "Aligning human preference and value is an important requirement for\ncontemporary foundation models. State-of-the-art techniques such as\nReinforcement Learning from Human Feedback (RLHF) often consist of two stages:\n1) supervised fine-tuning (SFT), where the model is fine-tuned by learning from\nhuman demonstration data; 2) Preference learning, where preference data is used\nto learn a reward model, which is in turn used by a reinforcement learning (RL)\nstep to fine-tune the model. Such reward model serves as a proxy to human\npreference, and it is critical to guide the RL step towards improving the model\nquality. In this work, we argue that the SFT stage significantly benefits from\nlearning a reward model as well. Instead of using the human demonstration data\ndirectly via supervised learning, we propose to leverage an Inverse\nReinforcement Learning (IRL) technique to simultaneously build an reward model\nand a policy model. This approach leads to new SFT algorithms that are not only\nefficient to implement, but are robust to the presence of low-quality\nsupervised learning data. Moreover, we discover a connection between the\nproposed IRL based approach, and a recent line of works called Self-Play\nFine-tune (SPIN). Theoretically, we show that the proposed algorithms converge\nto the stationary solutions of the IRL problem. Empirically, we align 1B and 7B\nmodels using proposed methods and evaluate them on a reward benchmark model and\nthe HuggingFace Open LLM Leaderboard. The proposed methods show significant\nperformance improvement over existing SFT approaches. Our results indicate that\nit is beneficial to leverage reward learning throughout the entire alignment\nprocess.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17888v3",
    "published_date": "2024-05-28 07:11:05 UTC",
    "updated_date": "2024-10-27 20:09:59 UTC"
  },
  {
    "arxiv_id": "2405.20351v3",
    "title": "Imitating from auxiliary imperfect demonstrations via Adversarial Density Weighted Regression",
    "authors": [
      "Ziqi Zhang",
      "Zifeng Zhuang",
      "Jingzehua Xu",
      "Yiyuan Yang",
      "Yubo Huang",
      "Donglin Wang",
      "Shuai Zhang"
    ],
    "abstract": "We propose a novel one-step supervised imitation learning (IL) framework\ncalled Adversarial Density Regression (ADR). This IL framework aims to correct\nthe policy learned on unknown-quality to match the expert distribution by\nutilizing demonstrations, without relying on the Bellman operator.\nSpecifically, ADR addresses several limitations in previous IL algorithms:\nFirst, most IL algorithms are based on the Bellman operator, which inevitably\nsuffer from cumulative offsets from sub-optimal rewards during multi-step\nupdate processes. Additionally, off-policy training frameworks suffer from\nOut-of-Distribution (OOD) state-actions. Second, while conservative terms help\nsolve the OOD issue, balancing the conservative term is difficult. To address\nthese limitations, we fully integrate a one-step density-weighted Behavioral\nCloning (BC) objective for IL with auxiliary imperfect demonstration.\nTheoretically, we demonstrate that this adaptation can effectively correct the\ndistribution of policies trained on unknown-quality datasets to align with the\nexpert policy's distribution. Moreover, the difference between the empirical\nand the optimal value function is proportional to the upper bound of ADR's\nobjective, indicating that minimizing ADR's objective is akin to approaching\nthe optimal value. Experimentally, we validated the performance of ADR by\nconducting extensive evaluations. Specifically, ADR outperforms all of the\nselected IL algorithms on tasks from the Gym-Mujoco domain. Meanwhile, it\nachieves an 89.5% improvement over IQL when utilizing ground truth rewards on\ntasks from the Adroit and Kitchen domains. Our codebase will be released at:\nhttps://github.com/stevezhangzA/Adverserial_Density_Regression.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.20351v3",
    "published_date": "2024-05-28 06:59:16 UTC",
    "updated_date": "2025-01-13 12:27:56 UTC"
  },
  {
    "arxiv_id": "2405.17879v2",
    "title": "Resisting Stochastic Risks in Diffusion Planners with the Trajectory Aggregation Tree",
    "authors": [
      "Lang Feng",
      "Pengjie Gu",
      "Bo An",
      "Gang Pan"
    ],
    "abstract": "Diffusion planners have shown promise in handling long-horizon and\nsparse-reward tasks due to the non-autoregressive plan generation. However,\ntheir inherent stochastic risk of generating infeasible trajectories presents\nsignificant challenges to their reliability and stability. We introduce a novel\napproach, the Trajectory Aggregation Tree (TAT), to address this issue in\ndiffusion planners. Compared to prior methods that rely solely on raw\ntrajectory predictions, TAT aggregates information from both historical and\ncurrent trajectories, forming a dynamic tree-like structure. Each trajectory is\nconceptualized as a branch and individual states as nodes. As the structure\nevolves with the integration of new trajectories, unreliable states are\nmarginalized, and the most impactful nodes are prioritized for decision-making.\nTAT can be deployed without modifying the original training and sampling\npipelines of diffusion planners, making it a training-free, ready-to-deploy\nsolution. We provide both theoretical analysis and empirical evidence to\nsupport TAT's effectiveness. Our results highlight its remarkable ability to\nresist the risk from unreliable trajectories, guarantee the performance\nboosting of diffusion planners in $100\\%$ of tasks, and exhibit an appreciable\ntolerance margin for sample quality, thereby enabling planning with a more than\n$3\\times$ acceleration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2405.17879v2",
    "published_date": "2024-05-28 06:57:22 UTC",
    "updated_date": "2024-06-07 12:27:03 UTC"
  },
  {
    "arxiv_id": "2405.17878v2",
    "title": "An Information Theoretic Evaluation Metric For Strong Unlearning",
    "authors": [
      "Dongjae Jeon",
      "Wonje Jeung",
      "Taeheon Kim",
      "Albert No",
      "Jonghyun Choi"
    ],
    "abstract": "Machine unlearning (MU) aims to remove the influence of specific data from\ntrained models, addressing privacy concerns and ensuring compliance with\nregulations such as the \"right to be forgotten.\" Evaluating strong unlearning,\nwhere the unlearned model is indistinguishable from one retrained without the\nforgetting data, remains a significant challenge in deep neural networks\n(DNNs). Common black-box metrics, such as variants of membership inference\nattacks and accuracy comparisons, primarily assess model outputs but often fail\nto capture residual information in intermediate layers. To bridge this gap, we\nintroduce the Information Difference Index (IDI), a novel white-box metric\ninspired by information theory. IDI quantifies retained information in\nintermediate features by measuring mutual information between those features\nand the labels to be forgotten, offering a more comprehensive assessment of\nunlearning efficacy. Our experiments demonstrate that IDI effectively measures\nthe degree of unlearning across various datasets and architectures, providing a\nreliable tool for evaluating strong unlearning in DNNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17878v2",
    "published_date": "2024-05-28 06:57:01 UTC",
    "updated_date": "2024-10-19 06:00:20 UTC"
  },
  {
    "arxiv_id": "2405.17874v1",
    "title": "NUTS, NARS, and Speech",
    "authors": [
      "D. van der Sluis"
    ],
    "abstract": "To investigate whether \"Intelligence is the capacity of an\ninformation-processing system to adapt to its environment while operating with\ninsufficient knowledge and resources\", we look at utilising the non axiomatic\nreasoning system (NARS) for speech recognition. This article presents NUTS:\nraNdom dimensionality redUction non axiomaTic reasoning few Shot learner for\nperception. NUTS consists of naive dimensionality reduction, some\npre-processing, and then non axiomatic reasoning (NARS). With only 2 training\nexamples NUTS performs similarly to the Whisper Tiny model for discrete word\nidentification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.17874v1",
    "published_date": "2024-05-28 06:51:42 UTC",
    "updated_date": "2024-05-28 06:51:42 UTC"
  },
  {
    "arxiv_id": "2405.17873v2",
    "title": "MixDQ: Memory-Efficient Few-Step Text-to-Image Diffusion Models with Metric-Decoupled Mixed Precision Quantization",
    "authors": [
      "Tianchen Zhao",
      "Xuefei Ning",
      "Tongcheng Fang",
      "Enshu Liu",
      "Guyue Huang",
      "Zinan Lin",
      "Shengen Yan",
      "Guohao Dai",
      "Yu Wang"
    ],
    "abstract": "Diffusion models have achieved significant visual generation quality.\nHowever, their significant computational and memory costs pose challenge for\ntheir application on resource-constrained mobile devices or even desktop GPUs.\nRecent few-step diffusion models reduces the inference time by reducing the\ndenoising steps. However, their memory consumptions are still excessive. The\nPost Training Quantization (PTQ) replaces high bit-width FP representation with\nlow-bit integer values (INT4/8) , which is an effective and efficient technique\nto reduce the memory cost. However, when applying to few-step diffusion models,\nexisting quantization methods face challenges in preserving both the image\nquality and text alignment. To address this issue, we propose an\nmixed-precision quantization framework - MixDQ. Firstly, We design specialized\nBOS-aware quantization method for highly sensitive text embedding quantization.\nThen, we conduct metric-decoupled sensitivity analysis to measure the\nsensitivity of each layer. Finally, we develop an integer-programming-based\nmethod to conduct bit-width allocation. While existing quantization methods\nfall short at W8A8, MixDQ could achieve W8A8 without performance loss, and W4A8\nwith negligible visual degradation. Compared with FP16, we achieve 3-4x\nreduction in model size and memory cost, and 1.45x latency speedup.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://a-suozhang.xyz/mixdq.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2405.17873v2",
    "published_date": "2024-05-28 06:50:58 UTC",
    "updated_date": "2024-05-30 01:51:10 UTC"
  },
  {
    "arxiv_id": "2405.17871v2",
    "title": "Seeing the Image: Prioritizing Visual Correlation by Contrastive Alignment",
    "authors": [
      "Xin Xiao",
      "Bohong Wu",
      "Jiacong Wang",
      "Chunyuan Li",
      "Xun Zhou",
      "Haoyuan Guo"
    ],
    "abstract": "Existing image-text modality alignment in Vision Language Models (VLMs)\ntreats each text token equally in an autoregressive manner. Despite being\nsimple and effective, this method results in sub-optimal cross-modal alignment\nby over-emphasizing the text tokens that are less correlated with or even\ncontradictory with the input images. In this paper, we advocate for assigning\ndistinct contributions for each text token based on its visual correlation.\nSpecifically, we present by contrasting image inputs, the difference in\nprediction logits on each text token provides strong guidance of visual\ncorrelation. We therefore introduce Contrastive ALignment (CAL), a simple yet\neffective re-weighting strategy that prioritizes training visually correlated\ntokens. Our experimental results demonstrate that CAL consistently improves\ndifferent types of VLMs across different resolutions and model sizes on various\nbenchmark datasets. Importantly, our method incurs minimal additional\ncomputational overhead, rendering it highly efficient compared to alternative\ndata scaling strategies. Codes are available at\nhttps://github.com/foundation-multimodal-models/CAL.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurlPS 2024, Camera ready",
    "pdf_url": "http://arxiv.org/pdf/2405.17871v2",
    "published_date": "2024-05-28 06:44:13 UTC",
    "updated_date": "2024-11-05 02:26:51 UTC"
  },
  {
    "arxiv_id": "2405.17849v2",
    "title": "I-LLM: Efficient Integer-Only Inference for Fully-Quantized Low-Bit Large Language Models",
    "authors": [
      "Xing Hu",
      "Yuan Cheng",
      "Dawei Yang",
      "Zhihang Yuan",
      "Jiangyong Yu",
      "Chen Xu",
      "Sifan Zhou"
    ],
    "abstract": "Post-training quantization (PTQ) serves as a potent technique to accelerate\nthe inference of large language models (LLMs). Nonetheless, existing works\nstill necessitate a considerable number of floating-point (FP) operations\nduring inference, including additional quantization and de-quantization, as\nwell as non-linear operators such as RMSNorm and Softmax. This limitation\nhinders the deployment of LLMs on the edge and cloud devices. In this paper, we\nidentify the primary obstacle to integer-only quantization for LLMs lies in the\nlarge fluctuation of activations across channels and tokens in both linear and\nnon-linear operations. To address this issue, we propose I-LLM, a novel\ninteger-only fully-quantized PTQ framework tailored for LLMs. Specifically, (1)\nwe develop Fully-Smooth Block-Reconstruction (FSBR) to aggressively smooth\ninter-channel variations of all activations and weights. (2) to alleviate\ndegradation caused by inter-token variations, we introduce a novel approach\ncalled Dynamic Integer-only MatMul (DI-MatMul). This method enables dynamic\nquantization in full-integer matrix multiplication by dynamically quantizing\nthe input and outputs with integer-only operations. (3) we design\nDI-ClippedSoftmax, DI-Exp, and DI-Normalization, which utilize bit shift to\nexecute non-linear operators efficiently while maintaining accuracy. The\nexperiment shows that our I-LLM achieves comparable accuracy to the FP baseline\nand outperforms non-integer quantization methods. For example, I-LLM can\noperate at W4A4 with negligible loss of accuracy. To our knowledge, we are the\nfirst to bridge the gap between integer-only quantization and LLMs. We've\npublished our code on anonymous.4open.science, aiming to contribute to the\nadvancement of this field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17849v2",
    "published_date": "2024-05-28 05:56:11 UTC",
    "updated_date": "2024-06-05 15:26:58 UTC"
  },
  {
    "arxiv_id": "2405.17846v1",
    "title": "Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs",
    "authors": [
      "Yong Qi",
      "Gabriel Kyebambo",
      "Siyuan Xie",
      "Wei Shen",
      "Shenghui Wang",
      "Bitao Xie",
      "Bin He",
      "Zhipeng Wang",
      "Shuo Jiang"
    ],
    "abstract": "Safety limitations in service robotics across various industries have raised\nsignificant concerns about the need for robust mechanisms ensuring that robots\nadhere to safe practices, thereby preventing actions that might harm humans or\ncause property damage. Despite advances, including the integration of Knowledge\nGraphs (KGs) with Large Language Models (LLMs), challenges in ensuring\nconsistent safety in autonomous robot actions persist. In this paper, we\npropose a novel integration of Large Language Models with Embodied Robotic\nControl Prompts (ERCPs) and Embodied Knowledge Graphs (EKGs) to enhance the\nsafety framework for service robots. ERCPs are designed as predefined\ninstructions that ensure LLMs generate safe and precise responses. These\nresponses are subsequently validated by EKGs, which provide a comprehensive\nknowledge base ensuring that the actions of the robot are continuously aligned\nwith safety protocols, thereby promoting safer operational practices in varied\ncontexts. Our experimental setup involved diverse real-world tasks, where\nrobots equipped with our framework demonstrated significantly higher compliance\nwith safety standards compared to traditional methods. This integration fosters\nsecure human-robot interactions and positions our methodology at the forefront\nof AI-driven safety innovations in service robotics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17846v1",
    "published_date": "2024-05-28 05:50:25 UTC",
    "updated_date": "2024-05-28 05:50:25 UTC"
  },
  {
    "arxiv_id": "2405.17839v1",
    "title": "PeerFL: A Simulator for Peer-to-Peer Federated Learning at Scale",
    "authors": [
      "Alka Luqman",
      "Shivanshu Shekhar",
      "Anupam Chattopadhyay"
    ],
    "abstract": "This work integrates peer-to-peer federated learning tools with NS3, a widely\nused network simulator, to create a novel simulator designed to allow\nheterogeneous device experiments in federated learning. This cross-platform\nadaptability addresses a critical gap in existing simulation tools, enhancing\nthe overall utility and user experience. NS3 is leveraged to simulate WiFi\ndynamics to facilitate federated learning experiments with participants that\nmove around physically during training, leading to dynamic network\ncharacteristics. Our experiments showcase the simulator's efficiency in\ncomputational resource utilization at scale, with a maximum of 450\nheterogeneous devices modelled as participants in federated learning. This\npositions it as a valuable tool for simulation-based investigations in\npeer-to-peer federated learning. The framework is open source and available for\nuse and extension to the community.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17839v1",
    "published_date": "2024-05-28 05:30:18 UTC",
    "updated_date": "2024-05-28 05:30:18 UTC"
  },
  {
    "arxiv_id": "2405.17838v1",
    "title": "Trust and Terror: Hazards in Text Reveal Negatively Biased Credulity and Partisan Negativity Bias",
    "authors": [
      "Keith Burghardt",
      "Daniel M. T. Fessler",
      "Chyna Tang",
      "Anne Pisor",
      "Kristina Lerman"
    ],
    "abstract": "Socio-linguistic indicators of text, such as emotion or sentiment, are often\nextracted using neural networks in order to better understand features of\nsocial media. One indicator that is often overlooked, however, is the presence\nof hazards within text. Recent psychological research suggests that statements\nabout hazards are more believable than statements about benefits (a property\nknown as negatively biased credulity), and that political liberals and\nconservatives differ in how often they share hazards. Here, we develop a new\nmodel to detect information concerning hazards, trained on a new collection of\nannotated X posts, as well as urban legends annotated in previous work. We show\nthat not only does this model perform well (outperforming, e.g., zero-shot\nhuman annotator proxies, such as GPT-4) but that the hazard information it\nextracts is not strongly correlated with other indicators, namely moral\noutrage, sentiment, emotions, and threat words. (That said, consonant with\nexpectations, hazard information does correlate positively with such emotions\nas fear, and negatively with emotions like joy.) We then apply this model to\nthree datasets: X posts about COVID-19, X posts about the 2023 Hamas-Israel\nwar, and a new expanded collection of urban legends. From these data, we\nuncover words associated with hazards unique to each dataset as well as\ndifferences in this language between groups of users, such as conservatives and\nliberals, which informs what these groups perceive as hazards. We further show\nthat information about hazards peaks in frequency after major hazard events,\nand therefore acts as an automated indicator of such events. Finally, we find\nthat information about hazards is especially prevalent in urban legends, which\nis consistent with previous work that finds that reports of hazards are more\nlikely to be both believed and transmitted.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.17838v1",
    "published_date": "2024-05-28 05:28:49 UTC",
    "updated_date": "2024-05-28 05:28:49 UTC"
  },
  {
    "arxiv_id": "2406.05142v1",
    "title": "Machine Learning-Driven Optimization of TPMS Architected Materials Using Simulated Annealing",
    "authors": [
      "Akshansh Mishra"
    ],
    "abstract": "The research paper presents a novel approach to optimizing the tensile stress\nof Triply Periodic Minimal Surface (TPMS) structures through machine learning\nand Simulated Annealing (SA). The study evaluates the performance of Random\nForest, Decision Tree, and XGBoost models in predicting tensile stress, using a\ndataset generated from finite element analysis of TPMS models. The objective\nfunction minimized the negative R-squared value on the validation set to\nenhance model accuracy. The SA-XGBoost model outperformed the others, achieving\nan R-squared value of 0.96. In contrast, the SA-Random Forest model achieved an\nR squared value of 0.89 while the SA-Decision Tree model exhibited greater\nfluctuations in validation scores. This demonstrates that the SA-XGBoost model\nis most effective in capturing the complex relationships within the data. The\nintegration of SA helps in optimizing the hyperparameters of these machine\nlearning models, thereby enhancing their predictive capabilities.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "25 Pages, 7 figures and 8 Tables",
    "pdf_url": "http://arxiv.org/pdf/2406.05142v1",
    "published_date": "2024-05-28 05:06:37 UTC",
    "updated_date": "2024-05-28 05:06:37 UTC"
  },
  {
    "arxiv_id": "2405.17832v1",
    "title": "Mollification Effects of Policy Gradient Methods",
    "authors": [
      "Tao Wang",
      "Sylvia Herbert",
      "Sicun Gao"
    ],
    "abstract": "Policy gradient methods have enabled deep reinforcement learning (RL) to\napproach challenging continuous control problems, even when the underlying\nsystems involve highly nonlinear dynamics that generate complex non-smooth\noptimization landscapes. We develop a rigorous framework for understanding how\npolicy gradient methods mollify non-smooth optimization landscapes to enable\neffective policy search, as well as the downside of it: while making the\nobjective function smoother and easier to optimize, the stochastic objective\ndeviates further from the original problem. We demonstrate the equivalence\nbetween policy gradient methods and solving backward heat equations. Following\nthe ill-posedness of backward heat equations from PDE theory, we present a\nfundamental challenge to the use of policy gradient under stochasticity.\nMoreover, we make the connection between this limitation and the uncertainty\nprinciple in harmonic analysis to understand the effects of exploration with\nstochastic policies in RL. We also provide experimental results to illustrate\nboth the positive and negative aspects of mollification effects in practice.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 41 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.17832v1",
    "published_date": "2024-05-28 05:05:33 UTC",
    "updated_date": "2024-05-28 05:05:33 UTC"
  },
  {
    "arxiv_id": "2405.17829v2",
    "title": "LDMol: Text-to-Molecule Diffusion Model with Structurally Informative Latent Space",
    "authors": [
      "Jinho Chang",
      "Jong Chul Ye"
    ],
    "abstract": "With the emergence of diffusion models as the frontline of generative models,\nmany researchers have proposed molecule generation techniques with conditional\ndiffusion models. However, the unavoidable discreteness of a molecule makes it\ndifficult for a diffusion model to connect raw data with highly complex\nconditions like natural language. To address this, we present a novel latent\ndiffusion model dubbed LDMol for text-conditioned molecule generation. LDMol\ncomprises a molecule autoencoder that produces a learnable and structurally\ninformative feature space, and a natural language-conditioned latent diffusion\nmodel. In particular, recognizing that multiple SMILES notations can represent\nthe same molecule, we employ a contrastive learning strategy to extract feature\nspace that is aware of the unique characteristics of the molecule structure.\nLDMol outperforms the existing baselines on the text-to-molecule generation\nbenchmark, suggesting a potential for diffusion models can outperform\nautoregressive models in text data generation with a better choice of the\nlatent domain. Furthermore, we show that LDMol can be applied to downstream\ntasks such as molecule-to-text retrieval and text-guided molecule editing,\ndemonstrating its versatility as a diffusion model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17829v2",
    "published_date": "2024-05-28 04:59:13 UTC",
    "updated_date": "2024-10-03 15:14:29 UTC"
  },
  {
    "arxiv_id": "2405.17825v3",
    "title": "Diffusion Model Patching via Mixture-of-Prompts",
    "authors": [
      "Seokil Ham",
      "Sangmin Woo",
      "Jin-Young Kim",
      "Hyojun Go",
      "Byeongjun Park",
      "Changick Kim"
    ],
    "abstract": "We present Diffusion Model Patching (DMP), a simple method to boost the\nperformance of pre-trained diffusion models that have already reached\nconvergence, with a negligible increase in parameters. DMP inserts a small,\nlearnable set of prompts into the model's input space while keeping the\noriginal model frozen. The effectiveness of DMP is not merely due to the\naddition of parameters but stems from its dynamic gating mechanism, which\nselects and combines a subset of learnable prompts at every timestep (i.e.,\nreverse denoising steps). This strategy, which we term \"mixture-of-prompts\",\nenables the model to draw on the distinct expertise of each prompt, essentially\n\"patching\" the model's functionality at every timestep with minimal yet\nspecialized parameters. Uniquely, DMP enhances the model by further training on\nthe original dataset already used for pre-training, even in a scenario where\nsignificant improvements are typically not expected due to model convergence.\nNotably, DMP significantly enhances the FID of converged DiT-L/2 by 10.38% on\nFFHQ, achieved with only a 1.43% parameter increase and 50K additional training\niterations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2025; Project: https://sangminwoo.github.io/DMP/",
    "pdf_url": "http://arxiv.org/pdf/2405.17825v3",
    "published_date": "2024-05-28 04:47:54 UTC",
    "updated_date": "2024-12-11 13:58:19 UTC"
  },
  {
    "arxiv_id": "2405.17822v1",
    "title": "Conv-CoA: Improving Open-domain Question Answering in Large Language Models via Conversational Chain-of-Action",
    "authors": [
      "Zhenyu Pan",
      "Haozheng Luo",
      "Manling Li",
      "Han Liu"
    ],
    "abstract": "We present a Conversational Chain-of-Action (Conv-CoA) framework for\nOpen-domain Conversational Question Answering (OCQA). Compared with literature,\nConv-CoA addresses three major challenges: (i) unfaithful hallucination that is\ninconsistent with real-time or domain facts, (ii) weak reasoning performance in\nconversational scenarios, and (iii) unsatisfying performance in conversational\ninformation retrieval. Our key contribution is a dynamic reasoning-retrieval\nmechanism that extracts the intent of the question and decomposes it into a\nreasoning chain to be solved via systematic prompting, pre-designed actions,\nupdating the Contextual Knowledge Set (CKS), and a novel Hopfield-based\nretriever. Methodologically, we propose a resource-efficiency Hopfield\nretriever to enhance the efficiency and accuracy of conversational information\nretrieval within our actions. Additionally, we propose a\nconversational-multi-reference faith score (Conv-MRFS) to verify and resolve\nconflicts between retrieved knowledge and answers in conversations.\nEmpirically, we conduct comparisons between our framework and 23\nstate-of-the-art methods across five different research directions and two\npublic benchmarks. These comparisons demonstrate that our Conv-CoA outperforms\nother methods in both the accuracy and efficiency dimensions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17822v1",
    "published_date": "2024-05-28 04:46:52 UTC",
    "updated_date": "2024-05-28 04:46:52 UTC"
  },
  {
    "arxiv_id": "2405.17821v2",
    "title": "RITUAL: Random Image Transformations as a Universal Anti-hallucination Lever in Large Vision Language Models",
    "authors": [
      "Sangmin Woo",
      "Jaehyuk Jang",
      "Donguk Kim",
      "Yubin Choi",
      "Changick Kim"
    ],
    "abstract": "Recent advancements in Large Vision Language Models (LVLMs) have\nrevolutionized how machines understand and generate textual responses based on\nvisual inputs, yet they often produce \"hallucinatory\" outputs that misinterpret\nvisual information, posing challenges in reliability and trustworthiness. We\npropose RITUAL, a simple decoding method that reduces hallucinations by\nleveraging randomly transformed images as complementary inputs during decoding,\nadjusting the output probability distribution without additional training or\nexternal models. Our key insight is that random transformations expose the\nmodel to diverse visual perspectives, enabling it to correct misinterpretations\nthat lead to hallucinations. Specifically, when a model hallucinates based on\nthe original image, the transformed images -- altered in aspects such as\norientation, scale, or color -- provide alternative viewpoints that help\nrecalibrate the model's predictions. By integrating the probability\ndistributions from both the original and transformed images, RITUAL effectively\nreduces hallucinations. To further improve reliability and address potential\ninstability from arbitrary transformations, we introduce RITUAL+, an extension\nthat selects image transformations based on self-feedback from the LVLM.\nInstead of applying transformations randomly, RITUAL+ uses the LVLM to evaluate\nand choose transformations that are most beneficial for reducing hallucinations\nin a given context. This self-adaptive approach mitigates the potential\nnegative impact of certain transformations on specific tasks, ensuring more\nconsistent performance across different scenarios. Experiments demonstrate that\nRITUAL and RITUAL+ significantly reduce hallucinations across several object\nhallucination benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project: https://sangminwoo.github.io/RITUAL/",
    "pdf_url": "http://arxiv.org/pdf/2405.17821v2",
    "published_date": "2024-05-28 04:41:02 UTC",
    "updated_date": "2024-12-16 10:27:35 UTC"
  },
  {
    "arxiv_id": "2405.17820v1",
    "title": "Don't Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models",
    "authors": [
      "Sangmin Woo",
      "Donguk Kim",
      "Jaehyuk Jang",
      "Yubin Choi",
      "Changick Kim"
    ],
    "abstract": "This study addresses the issue observed in Large Vision Language Models\n(LVLMs), where excessive attention on a few image tokens, referred to as blind\ntokens, leads to hallucinatory responses in tasks requiring fine-grained\nunderstanding of visual objects. We found that tokens receiving lower attention\nweights often hold essential information for identifying nuanced object details\n-- ranging from merely recognizing object existence to identifying their\nattributes (color, position, etc.) and understanding their relationships. To\ncounteract the over-emphasis on blind tokens and to accurately respond to user\nqueries, we introduce a technique called Attentional Vision Calibration (AVC).\nDuring the decoding phase, AVC identifies blind tokens by analyzing the\nimage-related attention distribution. It then dynamically adjusts the logits\nfor the next token prediction by contrasting the logits conditioned on the\noriginal visual tokens with those conditioned on the blind tokens. This\neffectively lowers the dependency on blind tokens and promotes a more balanced\nconsideration of all tokens. We validate AVC on benchmarks such as POPE, MME,\nand AMBER, where it consistently outperforms existing decoding techniques in\nmitigating object hallucinations in LVLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://sangminwoo.github.io/AvisC/",
    "pdf_url": "http://arxiv.org/pdf/2405.17820v1",
    "published_date": "2024-05-28 04:40:57 UTC",
    "updated_date": "2024-05-28 04:40:57 UTC"
  },
  {
    "arxiv_id": "2405.17814v6",
    "title": "FAIntbench: A Holistic and Precise Benchmark for Bias Evaluation in Text-to-Image Models",
    "authors": [
      "Hanjun Luo",
      "Ziye Deng",
      "Ruizhe Chen",
      "Zuozhu Liu"
    ],
    "abstract": "The rapid development and reduced barriers to entry for Text-to-Image (T2I)\nmodels have raised concerns about the biases in their outputs, but existing\nresearch lacks a holistic definition and evaluation framework of biases,\nlimiting the enhancement of debiasing techniques. To address this issue, we\nintroduce FAIntbench, a holistic and precise benchmark for biases in T2I\nmodels. In contrast to existing benchmarks that evaluate bias in limited\naspects, FAIntbench evaluate biases from four dimensions: manifestation of\nbias, visibility of bias, acquired attributes, and protected attributes. We\napplied FAIntbench to evaluate seven recent large-scale T2I models and\nconducted human evaluation, whose results demonstrated the effectiveness of\nFAIntbench in identifying various biases. Our study also revealed new research\nquestions about biases, including the side-effect of distillation. The findings\npresented here are preliminary, highlighting the potential of FAIntbench to\nadvance future research aimed at mitigating the biases in T2I models. Our\nbenchmark is publicly available to ensure the reproducibility.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICML DMLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.17814v6",
    "published_date": "2024-05-28 04:18:00 UTC",
    "updated_date": "2025-02-24 08:49:32 UTC"
  },
  {
    "arxiv_id": "2405.17809v3",
    "title": "TransVIP: Speech to Speech Translation System with Voice and Isochrony Preservation",
    "authors": [
      "Chenyang Le",
      "Yao Qian",
      "Dongmei Wang",
      "Long Zhou",
      "Shujie Liu",
      "Xiaofei Wang",
      "Midia Yousefi",
      "Yanmin Qian",
      "Jinyu Li",
      "Sheng Zhao",
      "Michael Zeng"
    ],
    "abstract": "There is a rising interest and trend in research towards directly translating\nspeech from one language to another, known as end-to-end speech-to-speech\ntranslation. However, most end-to-end models struggle to outperform cascade\nmodels, i.e., a pipeline framework by concatenating speech recognition, machine\ntranslation and text-to-speech models. The primary challenges stem from the\ninherent complexities involved in direct translation tasks and the scarcity of\ndata. In this study, we introduce a novel model framework TransVIP that\nleverages diverse datasets in a cascade fashion yet facilitates end-to-end\ninference through joint probability. Furthermore, we propose two separated\nencoders to preserve the speaker's voice characteristics and isochrony from the\nsource speech during the translation process, making it highly suitable for\nscenarios such as video dubbing. Our experiments on the French-English language\npair demonstrate that our model outperforms the current state-of-the-art\nspeech-to-speech translation model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Neural Information Processing Systems, poster",
    "pdf_url": "http://arxiv.org/pdf/2405.17809v3",
    "published_date": "2024-05-28 04:11:37 UTC",
    "updated_date": "2024-10-31 03:11:16 UTC"
  },
  {
    "arxiv_id": "2405.17802v1",
    "title": "Multi-level Interaction Modeling for Protein Mutational Effect Prediction",
    "authors": [
      "Yuanle Mo",
      "Xin Hong",
      "Bowen Gao",
      "Yinjun Jia",
      "Yanyan Lan"
    ],
    "abstract": "Protein-protein interactions are central mediators in many biological\nprocesses. Accurately predicting the effects of mutations on interactions is\ncrucial for guiding the modulation of these interactions, thereby playing a\nsignificant role in therapeutic development and drug discovery. Mutations\ngenerally affect interactions hierarchically across three levels: mutated\nresidues exhibit different sidechain conformations, which lead to changes in\nthe backbone conformation, eventually affecting the binding affinity between\nproteins. However, existing methods typically focus only on sidechain-level\ninteraction modeling, resulting in suboptimal predictions. In this work, we\npropose a self-supervised multi-level pre-training framework, ProMIM, to fully\ncapture all three levels of interactions with well-designed pretraining\nobjectives. Experiments show ProMIM outperforms all the baselines on the\nstandard benchmark, especially on mutations where significant changes in\nbackbone conformations may occur. In addition, leading results from zero-shot\nevaluations for SARS-CoV-2 mutational effect prediction and antibody\noptimization underscore the potential of ProMIM as a powerful next-generation\ntool for developing novel therapeutic approaches and new drugs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17802v1",
    "published_date": "2024-05-28 03:53:26 UTC",
    "updated_date": "2024-05-28 03:53:26 UTC"
  },
  {
    "arxiv_id": "2405.17784v2",
    "title": "Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich Differentiable Simulation",
    "authors": [
      "Ignat Georgiev",
      "Krishnan Srinivasan",
      "Jie Xu",
      "Eric Heiden",
      "Animesh Garg"
    ],
    "abstract": "Model-Free Reinforcement Learning (MFRL), leveraging the policy gradient\ntheorem, has demonstrated considerable success in continuous control tasks.\nHowever, these approaches are plagued by high gradient variance due to\nzeroth-order gradient estimation, resulting in suboptimal policies. Conversely,\nFirst-Order Model-Based Reinforcement Learning (FO-MBRL) methods employing\ndifferentiable simulation provide gradients with reduced variance but are\nsusceptible to sampling error in scenarios involving stiff dynamics, such as\nphysical contact. This paper investigates the source of this error and\nintroduces Adaptive Horizon Actor-Critic (AHAC), an FO-MBRL algorithm that\nreduces gradient error by adapting the model-based horizon to avoid stiff\ndynamics. Empirical findings reveal that AHAC outperforms MFRL baselines,\nattaining 40% more reward across a set of locomotion tasks and efficiently\nscaling to high-dimensional control environments with improved wall-clock-time\nefficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Website https://adaptive-horizon-actor-critic.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2405.17784v2",
    "published_date": "2024-05-28 03:28:00 UTC",
    "updated_date": "2024-06-03 20:23:49 UTC"
  },
  {
    "arxiv_id": "2405.17766v1",
    "title": "SleepFM: Multi-modal Representation Learning for Sleep Across Brain Activity, ECG and Respiratory Signals",
    "authors": [
      "Rahul Thapa",
      "Bryan He",
      "Magnus Ruud Kjaer",
      "Hyatt Moore",
      "Gauri Ganjoo",
      "Emmanuel Mignot",
      "James Zou"
    ],
    "abstract": "Sleep is a complex physiological process evaluated through various modalities\nrecording electrical brain, cardiac, and respiratory activities. We curate a\nlarge polysomnography dataset from over 14,000 participants comprising over\n100,000 hours of multi-modal sleep recordings. Leveraging this extensive\ndataset, we developed SleepFM, the first multi-modal foundation model for sleep\nanalysis. We show that a novel leave-one-out approach for contrastive learning\nsignificantly improves downstream task performance compared to representations\nfrom standard pairwise contrastive learning. A logistic regression model\ntrained on SleepFM's learned embeddings outperforms an end-to-end trained\nconvolutional neural network (CNN) on sleep stage classification (macro AUROC\n0.88 vs 0.72 and macro AUPRC 0.72 vs 0.48) and sleep disordered breathing\ndetection (AUROC 0.85 vs 0.69 and AUPRC 0.77 vs 0.61). Notably, the learned\nembeddings achieve 48% top-1 average accuracy in retrieving the corresponding\nrecording clips of other modalities from 90,000 candidates. This work\ndemonstrates the value of holistic multi-modal sleep modeling to fully capture\nthe richness of sleep recordings. SleepFM is open source and available at\nhttps://github.com/rthapa84/sleepfm-codebase.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17766v1",
    "published_date": "2024-05-28 02:43:53 UTC",
    "updated_date": "2024-05-28 02:43:53 UTC"
  },
  {
    "arxiv_id": "2405.17764v3",
    "title": "On the Sequence Evaluation based on Stochastic Processes",
    "authors": [
      "Tianhao Zhang",
      "Zhexiao Lin",
      "Zhecheng Sheng",
      "Chen Jiang",
      "Dongyeop Kang"
    ],
    "abstract": "Generative models have gained significant prominence in Natural Language\nProcessing (NLP), especially in tackling the complex task of modeling and\nevaluating long text sequences. This task is crucial for advancing various\ndownstream applications, such as text generation and machine translation.\nRecent methods that utilize stochastic processes to capture the intrinsic\ndynamics of sequences have shown superior performance in generative modeling.\nHowever, the accurate encoding of both temporal and structural dependencies\nfrom text datasets, as well as leveraging this encoded information for sequence\nevaluation, remains an open area of research. In this paper, we propose a novel\napproach to learn the stochastic dynamics of long text sequences, utilizing a\nnegative log-likelihood-based encoder that outperforms contrastive learning\nmethods. We also introduce a likelihood-based evaluation metric for long-text\nassessment, which measures sequence coherence and can be applied to downstream\ntasks such as Human-AI discrimination. Our encoder preserves sequence coherence\neffectively and performs robustly on out-of-domain datasets. Additionally, the\nproposed evaluation metric captures both temporal and structural information\ncomprehensively. Theoretical analysis demonstrates the superiority of our\nmetric in sequence evaluation, and experimental results highlight its\nflexibility and exceptional performance across a variety of tasks, showcasing\nits utility in diverse NLP applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17764v3",
    "published_date": "2024-05-28 02:33:38 UTC",
    "updated_date": "2024-10-03 03:03:24 UTC"
  },
  {
    "arxiv_id": "2405.17755v1",
    "title": "XL3M: A Training-free Framework for LLM Length Extension Based on Segment-wise Inference",
    "authors": [
      "Shengnan Wang",
      "Youhui Bai",
      "Lin Zhang",
      "Pingyi Zhou",
      "Shixiong Zhao",
      "Gong Zhang",
      "Sen Wang",
      "Renhai Chen",
      "Hua Xu",
      "Hongwei Sun"
    ],
    "abstract": "Length generalization failure problem, namely the large language model (LLM)\nfails to generalize to texts longer than its maximum training length, greatly\nrestricts the application of LLM in the scenarios with streaming long inputs.\nTo address this problem, the existing methods either require substantial costs\nor introduce precision loss. In this paper, we empirically find that the\naccuracy of the LLM's prediction is highly correlated to its certainty. Based\non this, we propose an efficient training free framework, named XL3M (it means\nextra-long large language model), which enables the LLMs trained on short\nsequences to reason extremely long sequence without any further training or\nfine-tuning. Under the XL3M framework, the input context will be firstly\ndecomposed into multiple short sub-contexts, where each sub-context contains an\nindependent segment and a common ``question'' which is a few tokens from the\nend of the original context. Then XL3M gives a method to measure the relevance\nbetween each segment and the ``question'', and constructs a concise key context\nby splicing all the relevant segments in chronological order. The key context\nis further used instead of the original context to complete the inference task.\nEvaluations on comprehensive benchmarks show the superiority of XL3M. Using our\nframework, a Llama2-7B model is able to reason 20M long sequences on an 8-card\nHuawei Ascend 910B NPU machine with 64GB memory per card.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.17755v1",
    "published_date": "2024-05-28 02:12:35 UTC",
    "updated_date": "2024-05-28 02:12:35 UTC"
  },
  {
    "arxiv_id": "2405.17750v1",
    "title": "Magnitude-based Neuron Pruning for Backdoor Defens",
    "authors": [
      "Nan Li",
      "Haoyu Jiang",
      "Ping Yi"
    ],
    "abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks,\nposing concerning threats to their reliable deployment. Recent research reveals\nthat backdoors can be erased from infected DNNs by pruning a specific group of\nneurons, while how to effectively identify and remove these backdoor-associated\nneurons remains an open challenge. In this paper, we investigate the\ncorrelation between backdoor behavior and neuron magnitude, and find that\nbackdoor neurons deviate from the magnitude-saliency correlation of the model.\nThe deviation inspires us to propose a Magnitude-based Neuron Pruning (MNP)\nmethod to detect and prune backdoor neurons. Specifically, MNP uses three\nmagnitude-guided objective functions to manipulate the magnitude-saliency\ncorrelation of backdoor neurons, thus achieving the purpose of exposing\nbackdoor behavior, eliminating backdoor neurons and preserving clean neurons,\nrespectively. Experiments show our pruning strategy achieves state-of-the-art\nbackdoor defense performance against a variety of backdoor attacks with a\nlimited amount of clean data, demonstrating the crucial role of magnitude for\nguiding backdoor defenses.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17750v1",
    "published_date": "2024-05-28 02:05:39 UTC",
    "updated_date": "2024-05-28 02:05:39 UTC"
  },
  {
    "arxiv_id": "2405.17746v1",
    "title": "Rethinking Pruning for Backdoor Mitigation: An Optimization Perspective",
    "authors": [
      "Nan Li",
      "Haiyang Yu",
      "Ping Yi"
    ],
    "abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks,\nposing concerning threats to their reliable deployment. Recent research reveals\nthat backdoors can be erased from infected DNNs by pruning a specific group of\nneurons, while how to effectively identify and remove these backdoor-associated\nneurons remains an open challenge. Most of the existing defense methods rely on\ndefined rules and focus on neuron's local properties, ignoring the exploration\nand optimization of pruning policies. To address this gap, we propose an\nOptimized Neuron Pruning (ONP) method combined with Graph Neural Network (GNN)\nand Reinforcement Learning (RL) to repair backdoor models. Specifically, ONP\nfirst models the target DNN as graphs based on neuron connectivity, and then\nuses GNN-based RL agents to learn graph embeddings and find a suitable pruning\npolicy. To the best of our knowledge, this is the first attempt to employ GNN\nand RL for optimizing pruning policies in the field of backdoor defense.\nExperiments show, with a small amount of clean data, ONP can effectively prune\nthe backdoor neurons implanted by a set of backdoor attacks at the cost of\nnegligible performance degradation, achieving a new state-of-the-art\nperformance for backdoor mitigation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17746v1",
    "published_date": "2024-05-28 01:59:06 UTC",
    "updated_date": "2024-05-28 01:59:06 UTC"
  },
  {
    "arxiv_id": "2405.17743v5",
    "title": "ORLM: A Customizable Framework in Training Large Models for Automated Optimization Modeling",
    "authors": [
      "Chenyu Huang",
      "Zhengyang Tang",
      "Shixi Hu",
      "Ruoqing Jiang",
      "Xin Zheng",
      "Dongdong Ge",
      "Benyou Wang",
      "Zizhuo Wang"
    ],
    "abstract": "Optimization modeling plays a critical role in the application of Operations\nResearch (OR) tools to address real-world problems, yet they pose challenges\nand require extensive expertise from OR experts. With the advent of large\nlanguage models (LLMs), new opportunities have emerged to streamline and\nautomate such task. However, current research predominantly relies on\nclosed-source LLMs such as GPT-4, along with extensive prompt engineering\ntechniques. This reliance stems from the scarcity of high-quality training\ndatasets for optimization modeling, resulting in elevated costs, prolonged\nprocessing times, and privacy concerns. To address these challenges, our work\nis the first to propose a viable path for training open-source LLMs that are\ncapable of optimization modeling and developing solver codes, eventually\nleading to a superior ability for automating optimization modeling and solving.\nParticularly, we design the {\\sc OR-Instruct}, a semi-automated data synthesis\nframework for optimization modeling that enables customizable enhancements for\nspecific scenarios or model types. This work also introduces IndustryOR, the\nfirst industrial benchmark for evaluating LLMs in solving practical OR\nproblems. We train several 7B-scale open-source LLMs using synthesized data\n(dubbed ORLMs{https://github.com/Cardinal-Operations/ORLM}), which exhibit\nsignificantly enhanced optimization modeling capabilities, achieving\ncompetitive performance across the NL4OPT, MAMO, and IndustryOR benchmarks.\nAdditionally, our experiments highlight the potential of scaling law and\nreinforcement learning to further enhance the performance of ORLMs. The\nworkflows and human-machine interaction paradigms of ORLMs in practical\nindustrial applications are also discussed in the paper.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted by Operations Research",
    "pdf_url": "http://arxiv.org/pdf/2405.17743v5",
    "published_date": "2024-05-28 01:55:35 UTC",
    "updated_date": "2025-04-04 13:31:38 UTC"
  },
  {
    "arxiv_id": "2405.17741v1",
    "title": "LoRA-Switch: Boosting the Efficiency of Dynamic LLM Adapters via System-Algorithm Co-design",
    "authors": [
      "Rui Kong",
      "Qiyang Li",
      "Xinyu Fang",
      "Qingtian Feng",
      "Qingfeng He",
      "Yazhu Dong",
      "Weijun Wang",
      "Yuanchun Li",
      "Linghe Kong",
      "Yunxin Liu"
    ],
    "abstract": "Recent literature has found that an effective method to customize or further\nimprove large language models (LLMs) is to add dynamic adapters, such as\nlow-rank adapters (LoRA) with Mixture-of-Experts (MoE) structures. Though such\ndynamic adapters incur modest computational complexity, they surprisingly lead\nto huge inference latency overhead, slowing down the decoding speed by 2.5+\ntimes. In this paper, we analyze the fine-grained costs of the dynamic adapters\nand find that the fragmented CUDA kernel calls are the root cause. Therefore,\nwe propose LoRA-Switch, a system-algorithm co-designed architecture for\nefficient dynamic adapters. Unlike most existing dynamic structures that adopt\nlayer-wise or block-wise dynamic routing, LoRA-Switch introduces a token-wise\nrouting mechanism. It switches the LoRA adapters and weights for each token and\nmerges them into the backbone for inference. For efficiency, this switching is\nimplemented with an optimized CUDA kernel, which fuses the merging operations\nfor all LoRA adapters at once. Based on experiments with popular open-source\nLLMs on common benchmarks, our approach has demonstrated similar accuracy\nimprovement as existing dynamic adapters, while reducing the decoding latency\nby more than 2.4 times.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17741v1",
    "published_date": "2024-05-28 01:53:26 UTC",
    "updated_date": "2024-05-28 01:53:26 UTC"
  },
  {
    "arxiv_id": "2405.17739v1",
    "title": "The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers",
    "authors": [
      "James Prather",
      "Brent Reeves",
      "Juho Leinonen",
      "Stephen MacNeil",
      "Arisoa S. Randrianasolo",
      "Brett Becker",
      "Bailey Kimmel",
      "Jared Wright",
      "Ben Briggs"
    ],
    "abstract": "Novice programmers often struggle through programming problem solving due to\na lack of metacognitive awareness and strategies. Previous research has shown\nthat novices can encounter multiple metacognitive difficulties while\nprogramming. Novices are typically unaware of how these difficulties are\nhindering their progress. Meanwhile, many novices are now programming with\ngenerative AI (GenAI), which can provide complete solutions to most\nintroductory programming problems, code suggestions, hints for next steps when\nstuck, and explain cryptic error messages. Its impact on novice metacognition\nhas only started to be explored. Here we replicate a previous study that\nexamined novice programming problem solving behavior and extend it by\nincorporating GenAI tools. Through 21 lab sessions consisting of participant\nobservation, interview, and eye tracking, we explore how novices are coding\nwith GenAI tools. Although 20 of 21 students completed the assigned programming\nproblem, our findings show an unfortunate divide in the use of GenAI tools\nbetween students who accelerated and students who struggled. Students who\naccelerated were able to use GenAI to create code they already intended to make\nand were able to ignore unhelpful or incorrect inline code suggestions. But for\nstudents who struggled, our findings indicate that previously known\nmetacognitive difficulties persist, and that GenAI unfortunately can compound\nthem and even introduce new metacognitive difficulties. Furthermore, struggling\nstudents often expressed cognitive dissonance about their problem solving\nability, thought they performed better than they did, and finished with an\nillusion of competence. Based on our observations from both groups, we propose\nways to scaffold the novice GenAI experience and make suggestions for future\nwork.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICER 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.17739v1",
    "published_date": "2024-05-28 01:48:28 UTC",
    "updated_date": "2024-05-28 01:48:28 UTC"
  },
  {
    "arxiv_id": "2405.17730v1",
    "title": "MMPareto: Boosting Multimodal Learning with Innocent Unimodal Assistance",
    "authors": [
      "Yake Wei",
      "Di Hu"
    ],
    "abstract": "Multimodal learning methods with targeted unimodal learning objectives have\nexhibited their superior efficacy in alleviating the imbalanced multimodal\nlearning problem. However, in this paper, we identify the previously ignored\ngradient conflict between multimodal and unimodal learning objectives,\npotentially misleading the unimodal encoder optimization. To well diminish\nthese conflicts, we observe the discrepancy between multimodal loss and\nunimodal loss, where both gradient magnitude and covariance of the\neasier-to-learn multimodal loss are smaller than the unimodal one. With this\nproperty, we analyze Pareto integration under our multimodal scenario and\npropose MMPareto algorithm, which could ensure a final gradient with direction\nthat is common to all learning objectives and enhanced magnitude to improve\ngeneralization, providing innocent unimodal assistance. Finally, experiments\nacross multiple types of modalities and frameworks with dense cross-modal\ninteraction indicate our superior and extendable method performance. Our method\nis also expected to facilitate multi-task cases with a clear discrepancy in\ntask difficulty, demonstrating its ideal scalability. The source code and\ndataset are available at https://github.com/GeWu-Lab/MMPareto_ICML2024.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2405.17730v1",
    "published_date": "2024-05-28 01:19:13 UTC",
    "updated_date": "2024-05-28 01:19:13 UTC"
  },
  {
    "arxiv_id": "2405.17728v2",
    "title": "Facilitating Holistic Evaluations with LLMs: Insights from Scenario-Based Experiments",
    "authors": [
      "Toru Ishida",
      "Tongxi Liu",
      "Hailong Wang",
      "William K. Cheunga"
    ],
    "abstract": "Workshop courses designed to foster creativity are gaining popularity.\nHowever, even experienced faculty teams find it challenging to realize a\nholistic evaluation that accommodates diverse perspectives. Adequate\ndeliberation is essential to integrate varied assessments, but faculty often\nlack the time for such exchanges. Deriving an average score without discussion\nundermines the purpose of a holistic evaluation. Therefore, this paper explores\nthe use of a Large Language Model (LLM) as a facilitator to integrate diverse\nfaculty assessments. Scenario-based experiments were conducted to determine if\nthe LLM could integrate diverse evaluations and explain the underlying\npedagogical theories to faculty. The results were noteworthy, showing that the\nLLM can effectively facilitate faculty discussions. Additionally, the LLM\ndemonstrated the capability to create evaluation criteria by generalizing a\nsingle scenario-based experiment, leveraging its already acquired pedagogical\ndomain knowledge.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "The final version appears in the proceedings of the 32nd\n  International Conference on Computers in Education (ICCE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.17728v2",
    "published_date": "2024-05-28 01:07:06 UTC",
    "updated_date": "2024-08-12 00:54:28 UTC"
  },
  {
    "arxiv_id": "2405.17724v2",
    "title": "ClavaDDPM: Multi-relational Data Synthesis with Cluster-guided Diffusion Models",
    "authors": [
      "Wei Pang",
      "Masoumeh Shafieinejad",
      "Lucy Liu",
      "Stephanie Hazlewood",
      "Xi He"
    ],
    "abstract": "Recent research in tabular data synthesis has focused on single tables,\nwhereas real-world applications often involve complex data with tens or\nhundreds of interconnected tables. Previous approaches to synthesizing\nmulti-relational (multi-table) data fall short in two key aspects: scalability\nfor larger datasets and capturing long-range dependencies, such as correlations\nbetween attributes spread across different tables. Inspired by the success of\ndiffusion models in tabular data modeling, we introduce\n  $\\textbf{C}luster$ $\\textbf{La}tent$ $\\textbf{Va}riable$ $guided$\n$\\textbf{D}enoising$ $\\textbf{D}iffusion$ $\\textbf{P}robabilistic$\n$\\textbf{M}odels$ (ClavaDDPM). This novel approach leverages clustering labels\nas intermediaries to model relationships between tables, specifically focusing\non foreign key constraints. ClavaDDPM leverages the robust generation\ncapabilities of diffusion models while incorporating efficient algorithms to\npropagate the learned latent variables across tables. This enables ClavaDDPM to\ncapture long-range dependencies effectively.\n  Extensive evaluations on multi-table datasets of varying sizes show that\nClavaDDPM significantly outperforms existing methods for these long-range\ndependencies while remaining competitive on utility metrics for single-table\ndata.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17724v2",
    "published_date": "2024-05-28 00:42:18 UTC",
    "updated_date": "2024-11-14 11:06:36 UTC"
  },
  {
    "arxiv_id": "2405.17720v2",
    "title": "MindFormer: Semantic Alignment of Multi-Subject fMRI for Brain Decoding",
    "authors": [
      "Inhwa Han",
      "Jaayeon Lee",
      "Jong Chul Ye"
    ],
    "abstract": "Research efforts for visual decoding from fMRI signals have attracted\nconsiderable attention in research community. Still multi-subject fMRI decoding\nwith one model has been considered intractable due to the drastic variations in\nfMRI signals between subjects and even within the same subject across different\ntrials. To address current limitations in multi-subject brain decoding, here we\nintroduce a novel semantic alignment method of multi-subject fMRI signals using\nso-called MindFormer. This model is specifically designed to generate\nfMRI-conditioned feature vectors that can be used for conditioning Stable\nDiffusion model for fMRI- to-image generation or large language model (LLM) for\nfMRI-to-text generation. More specifically, MindFormer incorporates two key\ninnovations: 1) a subject specific token that effectively capture individual\ndifferences in fMRI signals while synergistically combines multi subject fMRI\ndata for training, and 2) a novel feature embedding and training scheme based\non the IP-Adapter to extract semantically meaningful features from fMRI\nsignals. Our experimental results demonstrate that MindFormer generates\nsemantically consistent images and text across different subjects. Since our\nMindFormer maintains semantic fidelity by fully utilizing the training data\nacross different subjects by significantly surpassing existing models in\nmulti-subject brain decoding, this may help deepening our understanding of\nneural processing variations among individuals.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17720v2",
    "published_date": "2024-05-28 00:36:25 UTC",
    "updated_date": "2024-10-06 13:27:37 UTC"
  },
  {
    "arxiv_id": "2405.17713v1",
    "title": "AI Alignment with Changing and Influenceable Reward Functions",
    "authors": [
      "Micah Carroll",
      "Davis Foote",
      "Anand Siththaranjan",
      "Stuart Russell",
      "Anca Dragan"
    ],
    "abstract": "Existing AI alignment approaches assume that preferences are static, which is\nunrealistic: our preferences change, and may even be influenced by our\ninteractions with AI systems themselves. To clarify the consequences of\nincorrectly assuming static preferences, we introduce Dynamic Reward Markov\nDecision Processes (DR-MDPs), which explicitly model preference changes and the\nAI's influence on them. We show that despite its convenience, the\nstatic-preference assumption may undermine the soundness of existing alignment\ntechniques, leading them to implicitly reward AI systems for influencing user\npreferences in ways users may not truly want. We then explore potential\nsolutions. First, we offer a unifying perspective on how an agent's\noptimization horizon may partially help reduce undesirable AI influence. Then,\nwe formalize different notions of AI alignment that account for preference\nchange from the outset. Comparing the strengths and limitations of 8 such\nnotions of alignment, we find that they all either err towards causing\nundesirable AI influence, or are overly risk-averse, suggesting that a\nstraightforward solution to the problems of changing preferences may not exist.\nAs there is no avoiding grappling with changing preferences in real-world\nsettings, this makes it all the more important to handle these issues with\ncare, balancing risks and capabilities. We hope our work can provide conceptual\nclarity and constitute a first step towards AI alignment practices which\nexplicitly account for (and contend with) the changing and influenceable nature\nof human preferences.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.17713v1",
    "published_date": "2024-05-28 00:08:46 UTC",
    "updated_date": "2024-05-28 00:08:46 UTC"
  }
]