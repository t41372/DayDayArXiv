{
  "date": "2025-10-29",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-10-29 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv å‘ˆç°å‡º **Agentic AIï¼ˆä»£ç†æ™ºèƒ½ï¼‰** çš„çˆ†å‘å¼å¢é•¿ï¼Œç ”ç©¶é‡å¿ƒä»å•ä¸€çš„ä»»åŠ¡å®Œæˆè½¬å‘äº†å¤æ‚çš„åä½œä¸æ¨ç†è¿‡ç¨‹ä¼˜åŒ–ï¼›åŒæ—¶ï¼Œ**å°æ¨¡å‹é€†è¢­**ï¼ˆ3.8B æ¨¡å‹æ¯”è‚© GPT-4oï¼‰å’Œ **å¤šæ¨¡æ€ç”Ÿæˆçš„æ–°é«˜åº¦**ï¼ˆ4D è‰å›¾ç”Ÿæˆï¼‰ä¹Ÿä»¤äººçœ¼å‰ä¸€äº®ã€‚\n\n---\n\n### ğŸš€ Agentic AI & å¤æ‚æ¨ç†ï¼šä»â€œå®Œæˆâ€åˆ°â€œåä½œâ€\n*è¿™ä¸€æ¿å—æ˜¯ä»Šå¤©çš„é‡å¤´æˆï¼Œç ”ç©¶è€…ä»¬æ­£åœ¨é‡æ–°å®šä¹‰ Agent çš„æ„å»ºå’Œè¯„ä¼°æ–¹å¼ã€‚*\n\n#### **Completion $\\neq$ Collaboration: Scaling Collaborative Effort with Agents**\n**å®Œæˆ $\\neq$ åä½œï¼šç”¨ Agent æ‰©å±•åä½œåŠªåŠ›**\nè¿™æ˜¯ä¸€ç¯‡å¯¹æ­¤å‰ Agent è¯„ä¼°ä½“ç³»æå‡ºåæ€çš„æ–‡ç« ã€‚ä½œè€…è®¤ä¸ºç›®å‰çš„è¯„ä¼°è¿‡äºå…³æ³¨â€œä¸€æ¬¡æ€§ä»»åŠ¡å®Œæˆï¼ˆone-shot task completionï¼‰â€ï¼Œè€Œå¿½ç•¥äº†ç°å®ä¸–ç•Œä¸­ç›®æ ‡å¾€å¾€æ¨¡ç³Šä¸”åŠ¨æ€å˜åŒ–çš„æœ¬è´¨ã€‚\n- **æ ¸å¿ƒè§‚ç‚¹ï¼š** æå‡ºäº†â€œCollaborative Effort Scalingâ€æ¡†æ¶ï¼Œå¼ºè°ƒ Agent ä¸åº”åªæ˜¯æ‰§è¡Œè€…ï¼Œè€Œåº”æ˜¯èƒ½å¤Ÿéšç”¨æˆ·å‚ä¸åº¦æå‡æ•ˆç”¨çš„åä½œè€…ã€‚\n- **å‘ç°ï¼š** è®¸å¤š SOTA Agent åœ¨å¤šè½®ã€çœŸå®çš„åä½œåœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œç¼ºä¹ç»´æŒäº¤äº’å’Œå¼•å¯¼ç”¨æˆ·ç†è§£çš„èƒ½åŠ›ã€‚\n\n#### **Model-Document Protocol for AI Search**\n**AI æœç´¢çš„æ¨¡å‹-æ–‡æ¡£åè®®**\nä¼ ç»Ÿçš„ RAG æŠŠæ–‡æ¡£å½“æˆçº¯æ–‡æœ¬åˆ‡ç‰‡ï¼Œä½†è¿™ç¯‡è®ºæ–‡è®¤ä¸ºè¿™ä¸å¤Ÿã€‚\n- **æ ¸å¿ƒè´¡çŒ®ï¼š** æå‡ºäº† **MDP (Model-Document Protocol)**ï¼Œä¸€ç§æ–°çš„æ£€ç´¢èŒƒå¼ã€‚å®ƒä¸åªæ˜¯æŠ“å–æ®µè½ï¼Œè€Œæ˜¯é€šè¿‡ Agentic è¿‡ç¨‹å°†éç»“æ„åŒ–æ–‡æ¡£è½¬åŒ–ä¸º LLM å¯ç›´æ¥æ¶ˆè´¹çš„çŸ¥è¯†è¡¨ç¤ºï¼ˆå¦‚ gist memoriesã€å›¾ç»“æ„ï¼‰ã€‚\n- **åº”ç”¨ï¼š** å®ç°äº† MDP-Agentï¼Œé€šè¿‡ map-reduce é£æ ¼çš„åˆæˆï¼Œç”Ÿæˆç´§å‡‘ä¸”å……è¶³çš„ä¸Šä¸‹æ–‡ï¼Œåœ¨ä¿¡æ¯æœç´¢åŸºå‡†ä¸Šè¶…è¶Šäº†ä¼ ç»ŸåŸºå‡†ã€‚\n\n#### **Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy**\n**Humains-Juniorï¼šé€šè¿‡å®šå‘å¤–éª¨æ¶æ¨ç†è¾¾åˆ° GPT-4o çº§äº‹å®å‡†ç¡®æ€§çš„ 3.8B è¯­è¨€æ¨¡å‹**\nè¿™æ˜¯ä¸€ä¸ªéå¸¸â€œåŠ±å¿—â€çš„å°æ¨¡å‹å·¥ä½œã€‚\n- **æ ¸å¿ƒæ–¹æ³•ï¼š** ç»“åˆäº†æç®€çš„å®šå‘â€œå¤–éª¨æ¶æ¨ç†ï¼ˆExoskeleton Reasoningï¼‰â€æ”¯æ¶å’Œä¸€ç§æ•™å¯¼â€œè®¤çŸ¥çºªå¾‹ï¼ˆepistemic disciplineï¼‰â€è€Œéå•çº¯çŒè¾“ç­”æ¡ˆçš„å¾®è°ƒæ–¹æ³•ã€‚\n- **ç»“æœï¼š** è¿™ä¸ªä»… 3.8B çš„æ¨¡å‹åœ¨äº‹å®åŸºå‡†ä¸Šä¸ GPT-4o çš„å·®è·åœ¨ $\\pm 5$ pp ä»¥å†…ï¼Œä½†æ¨ç†æˆæœ¬é™ä½äº†çº¦ 19 å€ã€‚è¿™ä¸ºç«¯ä¾§è®¾å¤‡è¿è¡Œé«˜æ™ºå•† AI æä¾›äº†æ–°æ€è·¯ã€‚\n\n#### **Reasoning-Aware GRPO using Process Mining**\n**åˆ©ç”¨æµç¨‹æŒ–æ˜å®ç°æ¨ç†æ„ŸçŸ¥çš„ GRPO**\n- **é—®é¢˜ï¼š** ç°æœ‰çš„åè®­ç»ƒï¼ˆPost-trainingï¼‰å¥–åŠ±æœºåˆ¶è¿‡äºå…³æ³¨ç»“æœï¼ˆOutcome-centricï¼‰ã€‚\n- **æ–¹æ³•ï¼š** æå‡ºäº† PM4GRPOï¼Œåˆ©ç”¨æµç¨‹æŒ–æ˜æŠ€æœ¯è®¡ç®—â€œä¸€è‡´æ€§å¥–åŠ±â€ï¼Œè¡¡é‡æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ä¸æ•™å¸ˆæ¨¡å‹çš„å¯¹é½ç¨‹åº¦ã€‚è¿™ç§å…³æ³¨â€œè¿‡ç¨‹â€è€Œéä»…å…³æ³¨â€œç­”æ¡ˆâ€çš„æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚\n\n---\n\n### ğŸ¨ å¤šæ¨¡æ€ä¸ç”Ÿæˆå¼è§†è§‰ï¼šåŠ¨èµ·æ¥çš„è‰å›¾\n*è§†è§‰ç”Ÿæˆé¢†åŸŸä¸ä»…ä»…åœ¨å·ç”»è´¨ï¼Œæ›´åœ¨å·ç»“æ„å’ŒåŠ¨æ€äº¤äº’ã€‚*\n\n#### **4-Doodle: Text to 3D Sketches that Move!**\n**4-Doodleï¼šæ–‡æœ¬ç”Ÿæˆä¼šåŠ¨çš„ 3D è‰å›¾ï¼**\néå¸¸æœ‰æ„æ€çš„å·¥ä½œï¼Œå…³æ³¨ç‚¹ä¸åœ¨äºç…§ç‰‡çº§çœŸå®æ„Ÿï¼Œè€Œåœ¨äº**3D çŸ¢é‡è‰å›¾**ã€‚\n- **æ ¸å¿ƒè´¡çŒ®ï¼š** æå‡ºäº†ç¬¬ä¸€ä¸ªæ— éœ€è®­ç»ƒï¼ˆtraining-freeï¼‰çš„æ¡†æ¶ï¼Œèƒ½ä»æ–‡æœ¬ç”ŸæˆåŠ¨æ€çš„ 3D è‰å›¾ã€‚\n- **æŠ€æœ¯ï¼š** åˆ©ç”¨é¢„è®­ç»ƒçš„å›¾åƒå’Œè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡åŒç©ºé—´è’¸é¦ï¼ˆå‡ ä½•ç©ºé—´ + è¿åŠ¨åŠ¨åŠ›å­¦ç©ºé—´ï¼‰ï¼Œå®ç°äº†ç»“æ„æ„Ÿå’ŒåŠ¨æ€æ„Ÿå…¼å¤‡çš„ 3D è‰å›¾åŠ¨ç”»ï¼Œä¸”ä¿æŒå¤šè§†è§’ä¸€è‡´æ€§ã€‚\n\n#### **RegionE: Adaptive Region-Aware Generation for Efficient Image Editing**\n**RegionEï¼šç”¨äºé«˜æ•ˆå›¾åƒç¼–è¾‘çš„è‡ªé€‚åº”åŒºåŸŸæ„ŸçŸ¥ç”Ÿæˆ**\n- **ç—›ç‚¹ï¼š** ç°æœ‰çš„æŒ‡ä»¤å¼å›¾åƒç¼–è¾‘é€šå¸¸ä¼šå¯¹å…¨å›¾è¿›è¡Œç»Ÿä¸€å¤„ç†ï¼Œå¯¼è‡´æœªç¼–è¾‘åŒºåŸŸè®¡ç®—æµªè´¹ä¸”å®¹æ˜“å¤±çœŸã€‚\n- **æ–¹æ³•ï¼š** è‡ªåŠ¨å°†å›¾åƒåˆ’åˆ†ä¸ºç¼–è¾‘åŒºå’Œéç¼–è¾‘åŒºã€‚éç¼–è¾‘åŒºâ€œä¸€æ­¥åˆ°ä½â€ï¼Œç¼–è¾‘åŒºåˆ™åˆ©ç”¨ KV Cache å’Œè‡ªé€‚åº”é€Ÿåº¦è¡°å‡è¿›è¡Œç²¾ç»†ç”Ÿæˆã€‚\n- **æ•ˆæœï¼š** é€Ÿåº¦æå‡ 2-2.5 å€ï¼Œä¸”æ›´å¥½åœ°ä¿ç•™äº†åŸå›¾ç»†èŠ‚ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€å¯¹é½ä¸ç¤¾ä¼šå½±å“\n*éšç€ AI æ·±å…¥ç¤¾ä¼šï¼Œå¦‚ä½•è®©å®ƒæ›´â€œæ‡‚äº‹â€æˆä¸ºäº†å…³é”®ã€‚*\n\n#### **Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure**\n**åæ€è·¨è¯­è¨€å¯¹é½ï¼šå¹³è¡¡çŸ¥è¯†è¿ç§»ä¸æ–‡åŒ–æŠ¹é™¤**\nè¿™æ˜¯ä¸€ç¯‡å…·æœ‰ç¤¾ä¼šå­¦æ·±åº¦çš„æŠ€æœ¯è®ºæ–‡ã€‚\n- **æ ¸å¿ƒå‘ç°ï¼š** è¿½æ±‚å¤šè¯­è¨€å¤§æ¨¡å‹çš„â€œè¡¨ç¤ºå¯¹é½â€ï¼ˆè®©ä¸åŒè¯­è¨€çš„è¡¨è¾¾åœ¨å‘é‡ç©ºé—´è¶‹åŒï¼‰è™½ç„¶æœ‰åŠ©äºäº‹å®çŸ¥è¯†çš„è¿ç§»ï¼Œä½†ä¼šå¯¼è‡´ **â€œæ–‡åŒ–æŠ¹é™¤ï¼ˆCultural Erasureï¼‰â€**ï¼Œå³æ¨¡å‹å¤±å»äº†é’ˆå¯¹ç‰¹å®šè¯­è¨€æä¾›ç¬¦åˆå½“åœ°æ–‡åŒ–è¯­å¢ƒå›ç­”çš„èƒ½åŠ›ã€‚\n- **è§£å†³æ–¹æ¡ˆï¼š** å‘ç°äº‹å®è¿ç§»å’Œæ–‡åŒ–ç‰¹å¼‚æ€§åœ¨æ¨¡å‹ä¸åŒå±‚çº§æ˜¯å¯åˆ†ç¦»çš„ï¼Œæå‡ºäº†â€œå¤–ç§‘æ‰‹æœ¯å¼å¼•å¯¼ï¼ˆSurgical Steeringï¼‰â€æ¥å¹³è¡¡è¿™ä¸¤è€…ã€‚\n\n#### **Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models**\n**Agentic Moderationï¼šæ›´å®‰å…¨çš„è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¤š Agent è®¾è®¡**\n- **æ€è·¯ï¼š** ç”¨é­”æ³•æ‰“è´¥é­”æ³•ã€‚ä¸ºäº†é˜²å¾¡ Jailbreak æ”»å‡»ï¼Œè®¾è®¡äº†ä¸€å¥—ç”± Shieldã€Responderã€Evaluator ç­‰å¤šä¸ª Agent ç»„æˆçš„åä½œç³»ç»Ÿæ¥è¿›è¡ŒåŠ¨æ€å®¡æ ¸ã€‚\n- **æ•ˆæœï¼š** æ”»å‡»æˆåŠŸç‡é™ä½ 7-19%ï¼Œä¸”ç›¸æ¯”ç®€å•çš„â€œæ‹’ç»å›ç­”â€ï¼Œè¿™ç§æ–¹æ³•æ›´åŠ çµæ´»å’Œå¯è§£é‡Šã€‚\n\n#### **The Limits of Obliviate: Evaluating Unlearning in LLMs**\n**é—å¿˜å’’çš„å±€é™ï¼šè¯„ä¼° LLM ä¸­çš„é—å¿˜**\n- **é—®é¢˜ï¼š** æˆ‘ä»¬èƒ½çœŸæ­£è®© LLM â€œå¿˜æ‰â€æ•æ„Ÿä¿¡æ¯å—ï¼Ÿ\n- **å‘ç°ï¼š** å¹¶æ²¡æœ‰å®Œå…¨å¿˜æ‰ã€‚é€šè¿‡ **â€œè¯´æœæ€§æç¤ºï¼ˆPersuasive Promptingï¼‰â€**ï¼ˆç‰¹åˆ«æ˜¯åˆ©ç”¨æƒå¨å£å»ï¼‰ï¼Œå¯ä»¥é‡æ–°å”¤é†’æ¨¡å‹æœ¬è¯¥â€œé—å¿˜â€çš„çŸ¥è¯†ã€‚æ¨¡å‹è¶Šå°ï¼Œåè€Œè¶Šå®¹æ˜“è¢«å”¤é†’ï¼ˆæ¢å¤ç‡è¾¾ 128% vs å¤§æ¨¡å‹çš„ 15%ï¼‰ã€‚\n\n---\n\n### ğŸ§  ç§‘å­¦ AI ä¸ ç†è®ºåŸºç¡€\n*ç¡¬æ ¸çš„ç§‘å­¦è®¡ç®—ä¸åŸºç¡€ç†è®ºç ”ç©¶ã€‚*\n\n#### **The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence**\n**ä¿¡æ¯è®ºå‘½ä»¤ï¼šå‹ç¼©ä¸æ™ºèƒ½çš„è®¤çŸ¥åŸºç¡€**\nä¸€ç¯‡å®å¤§çš„ç†è®ºæ–‡ç« ï¼Œè¯•å›¾è§£é‡Šæ™ºèƒ½çš„æœ¬è´¨ã€‚\n- **æ ¸å¿ƒè®ºç‚¹ï¼š** æå‡ºäº† ITIï¼ˆä¿¡æ¯è®ºå‘½ä»¤ï¼‰å’Œ CEPï¼ˆå‹ç¼©æ•ˆç‡åŸåˆ™ï¼‰ã€‚è®¤ä¸ºæ™ºèƒ½ç³»ç»Ÿä¸ºäº†åœ¨ä¸ç¡®å®šç¯å¢ƒä¸­ç”Ÿå­˜ï¼Œå¿…é¡»æœ€å°åŒ–è®¤çŸ¥ç†µï¼Œè€Œ **â€œå‹ç¼©â€** æ˜¯é€šå‘å› æœç»“æ„å‘ç°çš„å¿…ç»ä¹‹è·¯ã€‚\n- **ç»“è®ºï¼š** æ™ºèƒ½ä¸æ˜¯å¶ç„¶çš„ï¼Œè€Œæ˜¯æŒä¹…å­˜åœ¨äºç»“æ„åŒ–ç¯å¢ƒä¸­çš„æœºæ¢°å¿…ç„¶ç»“æœã€‚\n\n#### **SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications**\n**SciTrust 2.0ï¼šè¯„ä¼°ç§‘å­¦åº”ç”¨ä¸­ LLM å¯ä¿¡åº¦çš„ç»¼åˆæ¡†æ¶**\n- **ç°çŠ¶ï¼š** å°½ç®¡ LLM åœ¨ç§‘ç ”ä¸­åº”ç”¨å¹¿æ³›ï¼Œä½†å…¶å®‰å…¨æ€§ä»¤äººæ‹…å¿§ã€‚\n- **è¯„ä¼°ï¼š** å¯¹æ¯”äº†ç§‘å­¦ä¸“ç”¨æ¨¡å‹å’Œé€šç”¨æ¨¡å‹ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œé€šç”¨æ¨¡å‹ï¼ˆå¦‚ GPT-4o-miniï¼‰åœ¨çœŸå®æ€§å’Œé²æ£’æ€§ä¸Šé€šå¸¸ä¼˜äºç§‘å­¦ä¸“ç”¨æ¨¡å‹ã€‚ä¸“ç”¨æ¨¡å‹åœ¨ç”Ÿç‰©å®‰å…¨ç­‰é«˜é£é™©é¢†åŸŸçš„ä¼¦ç†æ¨ç†ä¸Šå­˜åœ¨æ˜æ˜¾ç¼ºé™·ã€‚\n\n---\n\n### ğŸ“Š å…¶ä»–å€¼å¾—å…³æ³¨çš„è®ºæ–‡ (Lightning Round)\n\n*   **[Hardware] INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats**\n    **INT ä¸ FPï¼šç»†ç²’åº¦ä½æ¯”ç‰¹é‡åŒ–æ ¼å¼çš„ç»¼åˆç ”ç©¶**\n    é’ˆå¯¹ Nvidia Blackwell ç­‰æ–°æ¶æ„ï¼Œç ”ç©¶äº† FP å’Œ INT æ ¼å¼çš„æƒè¡¡ã€‚å‘ç° **MXINT8** åœ¨ç»†ç²’åº¦é‡åŒ–ä¸Šä¼˜äº FP æ ¼å¼ï¼ŒæŒ‘æˆ˜äº†â€œFP é€‚åˆæ‰€æœ‰åœºæ™¯â€çš„è§‚ç‚¹ã€‚\n\n*   **[Financial AI] MaGNet: A Mamba Dual-Hypergraph Network for Stock Prediction**\n    **MaGNetï¼šç”¨äºè‚¡ç¥¨é¢„æµ‹çš„ Mamba åŒè¶…å›¾ç½‘ç»œ**\n    åˆ©ç”¨ Mamba æ¶æ„å’ŒåŒè¶…å›¾ï¼ˆæ—¶é—´å› æœ+å…¨å±€æ¦‚ç‡ï¼‰æ¥æ•æ‰å¤æ‚çš„è‚¡ç¥¨å¸‚åœºåŠ¨æ€ï¼Œåœ¨å…­å¤§è‚¡æŒ‡ä¸Šå–å¾—äº† SOTAã€‚\n\n*   **[Robotics] Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization**\n    **LLM è¾…åŠ©è‡ªåŠ¨é©¾é©¶è½¦è¾†ä»å—å›°ä¸­æ¢å¤**\n    æå‡º StuckSolverï¼Œåˆ©ç”¨ LLM çš„æ¨ç†èƒ½åŠ›å¸®åŠ©è‡ªåŠ¨é©¾é©¶æ±½è½¦åœ¨â€œå¡æ­»â€çŠ¶æ€ä¸‹ï¼ˆä¸çŸ¥é“æ€ä¹ˆå¼€ï¼‰è¿›è¡Œè‡ªæˆ‘æ¨ç†æˆ–å¯»æ±‚ä¹˜å®¢å»ºè®®æ¥è„±å›°ï¼Œæ— éœ€ä¿®æ”¹åº•å±‚æ§åˆ¶æ ˆã€‚\n\n---\nå¸Œæœ›è¿™ä»½å¿«æŠ¥èƒ½å¸®åŠ©ä½ æŠŠæ¡ä»Šå¤©çš„ AI ç ”ç©¶è„‰æã€‚æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2510.26024v1",
      "title": "Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs",
      "title_zh": "é‡æ–°å®¡è§†è·¨è¯­è¨€å¯¹é½ï¼šæƒè¡¡å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„çŸ¥è¯†è¿ç§»ä¸æ–‡åŒ–æŠ¹é™¤",
      "authors": [
        "HyoJung Han",
        "Sweta Agrawal",
        "Eleftheria Briakou"
      ],
      "abstract": "Cross-lingual alignment (CLA) aims to align multilingual representations, enabling Large Language Models (LLMs) to seamlessly transfer knowledge across languages. While intuitive, we hypothesize, this pursuit of representational convergence can inadvertently cause \"cultural erasure\", the functional loss of providing culturally-situated responses that should diverge based on the query language. In this work, we systematically analyze this trade-off by introducing a holistic evaluation framework, the transfer-localization plane, which quantifies both desirable knowledge transfer and undesirable cultural erasure. Using this framework, we re-evaluate recent CLA approaches and find that they consistently improve factual transfer at the direct cost of cultural localization across all six languages studied. Our investigation into the internal representations of these models reveals a key insight: universal factual transfer and culturally-specific knowledge are optimally steerable at different model layers. Based on this finding, we propose Surgical Steering, a novel inference-time method that disentangles these two objectives. By applying targeted activation steering to distinct layers, our approach achieves a better balance between the two competing dimensions, effectively overcoming the limitations of current alignment techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è·¨è¯­è¨€å¯¹é½(Cross-lingual Alignment)ä¸­çŸ¥è¯†è¿ç§»ä¸æ–‡åŒ–æŠ¹é™¤(Cultural Erasure)ä¹‹é—´çš„æƒè¡¡å…³ç³»ï¼ŒæŒ‡å‡ºè¿½æ±‚è¡¨ç¤ºæ”¶æ•›å¯èƒ½å¯¼è‡´æ¨¡å‹ä¸§å¤±é’ˆå¯¹ç‰¹å®šè¯­è¨€æä¾›æ–‡åŒ–èƒŒæ™¯å“åº”çš„èƒ½åŠ›ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåä¸ºè¿ç§»-å®šä½å¹³é¢(Transfer-Localization Plane)çš„ç»¼åˆè¯„ä¼°æ¡†æ¶ï¼Œç”¨äºé‡åŒ–çŸ¥è¯†è¿ç§»ä¸æ–‡åŒ–å®šä½çš„æ•ˆæœã€‚é€šè¿‡å¯¹ç°æœ‰å¯¹é½æ–¹æ³•çš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°äº‹å®è¿ç§»çš„æå‡é€šå¸¸ä»¥ç‰ºç‰²æ–‡åŒ–å®šä½ä¸ºä»£ä»·ï¼Œä¸”è¿™ä¸¤ç±»çŸ¥è¯†åœ¨æ¨¡å‹å†…éƒ¨çš„ä¸åŒå±‚çº§å‘ˆç°å‡ºä¸åŒçš„å¯æ§æ€§ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§æ¨ç†é˜¶æ®µçš„æ–¹æ³• Surgical Steeringï¼Œé€šè¿‡å¯¹ç‰¹å®šå±‚è¿›è¡Œé’ˆå¯¹æ€§çš„æ¿€æ´»å¼•å¯¼(Activation Steering)æ¥è§£è€¦è¿™ä¸¤ä¸ªç›®æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSurgical Steering èƒ½å¤Ÿæœ‰æ•ˆç¼“è§£ç°æœ‰æŠ€æœ¯çš„å±€é™ï¼Œåœ¨ä¿æŒçŸ¥è¯†è¿ç§»æ•ˆç‡çš„åŒæ—¶å‡å°‘æ–‡åŒ–æŠ¹é™¤ï¼Œå®ç°äº†ä¸¤ä¸ªç»´åº¦ä¹‹é—´æ›´å¥½çš„å¹³è¡¡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.26024v1",
      "published_date": "2025-10-29 23:37:54 UTC",
      "updated_date": "2025-10-29 23:37:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:19:36.976008+00:00"
    },
    {
      "arxiv_id": "2510.26023v2",
      "title": "Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹è¾…åŠ©çš„è‡ªåŠ¨é©¾é©¶è½¦è¾†è„±å›°",
      "authors": [
        "Zhipeng Bao",
        "Qianwen Li"
      ],
      "abstract": "Despite significant advancements in recent decades, autonomous vehicles (AVs) continue to face challenges in navigating certain traffic scenarios where human drivers excel. In such situations, AVs often become immobilized, disrupting overall traffic flow. Current recovery solutions, such as remote intervention (which is costly and inefficient) and manual takeover (which excludes non-drivers and limits AV accessibility), are inadequate. This paper introduces StuckSolver, a novel Large Language Model (LLM) driven recovery framework that enables AVs to resolve immobilization scenarios through self-reasoning and/or passenger-guided decision-making. StuckSolver is designed as a plug-in add-on module that operates on top of the AV's existing perception-planning-control stack, requiring no modification to its internal architecture. Instead, it interfaces with standard sensor data streams to detect immobilization states, interpret environmental context, and generate high-level recovery commands that can be executed by the AV's native planner. We evaluate StuckSolver on the Bench2Drive benchmark and in custom-designed uncertainty scenarios. Results show that StuckSolver achieves near-state-of-the-art performance through autonomous self-reasoning alone and exhibits further improvements when passenger guidance is incorporated.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶è½¦è¾†(AV)åœ¨å¤æ‚åœºæ™¯ä¸‹å› åœæ»(immobilization)å¯¼è‡´äº¤é€šä¸­æ–­ï¼Œä¸”ç°æœ‰è¿œç¨‹å¹²é¢„æˆ–æ‰‹åŠ¨æ¥ç®¡æ–¹æ¡ˆæˆæœ¬é«˜ã€æ•ˆç‡ä½çš„é—®é¢˜ï¼Œæå‡ºäº†StuckSolveræ¢å¤æ¡†æ¶ã€‚StuckSolveræ˜¯ä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„åˆ›æ–°æ–¹æ¡ˆï¼Œä½¿è½¦è¾†èƒ½å¤Ÿé€šè¿‡è‡ªæˆ‘æ¨ç†æˆ–ä¹˜å®¢å¼•å¯¼çš„å†³ç­–æ‘†è„±åœæ»çŠ¶æ€ã€‚è¯¥æ¡†æ¶è¢«è®¾è®¡ä¸ºæ’ä»¶å¼é™„åŠ æ¨¡å—ï¼Œç›´æ¥è¿è¡Œåœ¨ç°æœ‰çš„æ„ŸçŸ¥-è§„åˆ’-æ§åˆ¶(perception-planning-control)æ ˆä¹‹ä¸Šï¼Œæ— éœ€ä¿®æ”¹è½¦è¾†å†…éƒ¨æ¶æ„ã€‚å®ƒé€šè¿‡æ ‡å‡†ä¼ æ„Ÿå™¨æ•°æ®æµæ£€æµ‹åœæ»çŠ¶æ€å¹¶è§£é‡Šç¯å¢ƒè¯­ä¹‰ï¼Œç”Ÿæˆå¯ç”±åŸç”Ÿè§„åˆ’å™¨æ‰§è¡Œçš„é«˜çº§æ¢å¤å‘½ä»¤ã€‚åœ¨Bench2DriveåŸºå‡†æµ‹è¯•åŠè‡ªå®šä¹‰ä¸ç¡®å®šåœºæ™¯ä¸­çš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒStuckSolverä»…å‡­è‡ªä¸»æ¨ç†å³å¯è¾¾åˆ°æ¥è¿‘æœ€å…ˆè¿›æ°´å¹³(SOTA)çš„æ€§èƒ½ã€‚å®éªŒè¿›ä¸€æ­¥è¯å®ï¼Œåœ¨æ•´åˆä¹˜å®¢å¼•å¯¼åï¼Œå…¶æ¢å¤èƒ½åŠ›å¾—åˆ°æ˜¾è‘—å¢å¼ºï¼Œä¸ºè§£å†³è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„ç‰¹æ®Šåœºæ™¯å¤±æ•ˆé—®é¢˜æä¾›äº†é«˜æ•ˆä¸”çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.26023v2",
      "published_date": "2025-10-29 23:33:31 UTC",
      "updated_date": "2025-11-14 15:46:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:19:38.567346+00:00"
    },
    {
      "arxiv_id": "2510.26020v1",
      "title": "PORTool: Tool-Use LLM Training with Rewarded Tree",
      "title_zh": "PORToolï¼šåŸºäºå¥–åŠ±æ ‘çš„å·¥å…·è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒ",
      "authors": [
        "Feijie Wu",
        "Weiwu Zhu",
        "Yuxiang Zhang",
        "Soumya Chatterjee",
        "Jiarong Zhu",
        "Fan Mo",
        "Rodin Luo",
        "Jing Gao"
      ],
      "abstract": "Current tool-use large language models (LLMs) are trained on static datasets, enabling them to interact with external tools and perform multi-step, tool-integrated reasoning, which produces tool-call trajectories. However, these models imitate how a query is resolved in a generic tool-call routine, thereby failing to explore possible solutions and demonstrating limited performance in an evolved, dynamic tool-call environment. In this work, we propose PORTool, a reinforcement learning (RL) method that encourages a tool-use LLM to explore various trajectories yielding the correct answer. Specifically, this method starts with generating multiple rollouts for a given query, and some of them share the first few tool-call steps, thereby forming a tree-like structure. Next, we assign rewards to each step, based on its ability to produce a correct answer and make successful tool calls. A shared step across different trajectories receives the same reward, while different steps under the same fork receive different rewards. Finally, these step-wise rewards are used to calculate fork-relative advantages, blended with trajectory-relative advantages, to train the LLM for tool use. The experiments utilize 17 tools to address user queries, covering both time-sensitive and time-invariant topics. We conduct ablation studies to systematically justify the necessity and the design robustness of step-wise rewards. Furthermore, we compare the proposed PORTool with other training approaches and demonstrate significant improvements in final accuracy and the number of tool-call steps.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶æå‡ºäº†PORToolï¼Œä¸€ç§æ—¨åœ¨ä¼˜åŒ–å·¥å…·ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹(Tool-use LLMs)æ€§èƒ½çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)è®­ç»ƒæ–¹æ³•ã€‚é’ˆå¯¹å½“å‰æ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­å› ä»…æ¨¡ä»¿é™æ€æ•°æ®é›†è€Œå¯¼è‡´çš„æ¢ç´¢èƒ½åŠ›ä¸è¶³é—®é¢˜ï¼ŒPORToolé€šè¿‡ä¸ºç»™å®šæŸ¥è¯¢ç”Ÿæˆå¤šä¸ªRolloutså¹¶æ„å»ºæ ‘çŠ¶ç»“æ„æ¥æ¢ç´¢å¤šç§è§£é¢˜è·¯å¾„ã€‚è¯¥æ–¹æ³•ä¸ºæ¯ä¸ªæ­¥éª¤åˆ†é…åŸºäºæ­£ç¡®ç­”æ¡ˆå’Œå·¥å…·è°ƒç”¨æˆåŠŸç‡çš„Step-wise rewardsï¼Œå¹¶ç»“åˆFork-relative advantagesä¸Trajectory-relative advantageså¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚å®éªŒåˆ©ç”¨17ç§å·¥å…·å¤„ç†äº†åŒ…å«æ—¶æ•ˆæ€§å’Œéæ—¶æ•ˆæ€§çš„æŸ¥è¯¢ä»»åŠ¡ï¼Œå¹¶é€šè¿‡æ¶ˆèå®éªŒéªŒè¯äº†é€æ­¥å¥–åŠ±æœºåˆ¶çš„è®¾è®¡ç¨³å¥æ€§ã€‚ç»“æœæ˜¾ç¤ºï¼Œä¸ä¼ ç»Ÿè®­ç»ƒæ–¹æ³•ç›¸æ¯”ï¼ŒPORToolåœ¨æœ€ç»ˆå‡†ç¡®ç‡å’Œå·¥å…·è°ƒç”¨æ­¥æ•°æ•ˆç‡ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œä¸ºæå‡LLMåœ¨å¤æ‚ã€åŠ¨æ€ç¯å¢ƒä¸‹çš„å·¥å…·è°ƒç”¨èƒ½åŠ›æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.26020v1",
      "published_date": "2025-10-29 23:28:53 UTC",
      "updated_date": "2025-10-29 23:28:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:19:39.461709+00:00"
    },
    {
      "arxiv_id": "2510.26018v1",
      "title": "RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras",
      "title_zh": "RADRONï¼šé…å¤‡åº·æ™®é¡¿ç›¸æœºçš„å¾®å‹é£è¡Œå™¨ç”µç¦»è¾å°„æºååŒå®šä½",
      "authors": [
        "Petr Stibinger",
        "Tomas Baca",
        "Daniela Doubravova",
        "Jan Rusnak",
        "Jaroslav Solc",
        "Jan Jakubek",
        "Petr Stepan",
        "Martin Saska"
      ],
      "abstract": "We present a novel approach to localizing radioactive material by cooperating Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art single-detector Compton camera as a highly sensitive, yet miniature detector of ionizing radiation. The detector's exceptionally low weight (40 g) opens up new possibilities of radiation detection by a team of cooperating agile MAVs. We propose a new fundamental concept of fusing the Compton camera measurements to estimate the position of the radiation source in real time even from extremely sparse measurements. The data readout and processing are performed directly onboard and the results are used in a dynamic feedback to drive the motion of the vehicles. The MAVs are stabilized in a tightly cooperating swarm to maximize the information gained by the Compton cameras, rapidly locate the radiation source, and even track a moving radiation source.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RADRONï¼Œä¸€ç§åˆ©ç”¨å¤šä¸ªå¾®å‹é£è¡Œå™¨(MAVs)ååŒå®šä½ç”µç¦»è¾å°„æºçš„æ–°æ–¹æ³•ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨äº†å°–ç«¯çš„å•æ¢æµ‹å™¨Compton cameraï¼Œå…¶æè½»çš„é‡é‡(40å…‹)ä¸ºæ•æ·MAVé›†ç¾¤çš„é«˜çµæ•åº¦è¾å°„æ¢æµ‹å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§å…¨æ–°çš„æ•°æ®èåˆæ¦‚å¿µï¼Œå³ä½¿åœ¨æµ‹é‡æ•°æ®æå…¶ç¨€ç–çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½å®æ—¶ä¼°ç®—è¾å°„æºçš„ä½ç½®ã€‚æ•°æ®çš„è¯»å–ä¸å¤„ç†å‡åœ¨æœºè½½(onboard)å®Œæˆï¼Œå¤„ç†ç»“æœé€šè¿‡åŠ¨æ€åé¦ˆå®æ—¶å¼•å¯¼é£è¡Œå™¨çš„è¿åŠ¨è·¯å¾„ã€‚é€šè¿‡ç»´æŒç´§å¯†åä½œçš„ç¾¤é›†(swarm)çŠ¶æ€ï¼Œç³»ç»Ÿèƒ½å¤Ÿæœ€å¤§åŒ–Compton cameraè·å–çš„ä¿¡æ¯é‡å¹¶å®ç°å¿«é€Ÿå®šä½ã€‚è¯¥æ–¹æ³•ä¸ä»…èƒ½æœ‰æ•ˆå®šä½é™æ­¢è¾å°„æºï¼Œç”šè‡³èƒ½å¤Ÿå¯¹ç§»åŠ¨çš„è¾å°„æºè¿›è¡Œå®æ—¶è¿½è¸ªã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 9 figures, submitted for review to IEEE RA-L",
      "pdf_url": "https://arxiv.org/pdf/2510.26018v1",
      "published_date": "2025-10-29 23:25:49 UTC",
      "updated_date": "2025-10-29 23:25:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:19:43.268581+00:00"
    },
    {
      "arxiv_id": "2510.26017v1",
      "title": "Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning",
      "title_zh": "è€ƒè™‘æ°”å€™é€‚åº”çš„æ²¿æµ·åŸå¸‚æ·±åº¦å­¦ä¹ æ´ªæ°´é¢„æµ‹",
      "authors": [
        "Bilal Hassan",
        "Areg Karapetyan",
        "Aaron Chung Hin Chow",
        "Samer Madanat"
      ],
      "abstract": "Climate change and sea-level rise (SLR) pose escalating threats to coastal cities, intensifying the need for efficient and accurate methods to predict potential flood hazards. Traditional physics-based hydrodynamic simulators, although precise, are computationally expensive and impractical for city-scale coastal planning applications. Deep Learning (DL) techniques offer promising alternatives, however, they are often constrained by challenges such as data scarcity and high-dimensional output requirements. Leveraging a recently proposed vision-based, low-resource DL framework, we develop a novel, lightweight Convolutional Neural Network (CNN)-based model designed to predict coastal flooding under variable SLR projections and shoreline adaptation scenarios. Furthermore, we demonstrate the ability of the model to generalize across diverse geographical contexts by utilizing datasets from two distinct regions: Abu Dhabi and San Francisco. Our findings demonstrate that the proposed model significantly outperforms state-of-the-art methods, reducing the mean absolute error (MAE) in predicted flood depth maps on average by nearly 20%. These results highlight the potential of our approach to serve as a scalable and practical tool for coastal flood management, empowering decision-makers to develop effective mitigation strategies in response to the growing impacts of climate change. Project Page: https://caspiannet.github.io/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ°”å€™å˜åŒ–å’Œæµ·å¹³é¢ä¸Šå‡(SLR)å¯¹æ²¿æµ·åŸå¸‚çš„å¨èƒï¼Œå¼€å‘äº†ä¸€ç§åŸºäºå·ç§¯ç¥ç»ç½‘ç»œ(CNN)çš„è½»é‡çº§æ·±åº¦å­¦ä¹ (DL)æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹ä¸åŒæµ·å¹³é¢ä¸Šå‡å’Œå²¸çº¿é€‚åº”æ–¹æ¡ˆä¸‹çš„æ²¿æµ·æ´ªæ°´é£é™©ã€‚ä¸ºäº†è§£å†³ä¼ ç»Ÿæ°´åŠ¨åŠ›æ¨¡æ‹Ÿè®¡ç®—æˆæœ¬é«˜ä»¥åŠç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œç ”ç©¶é‡‡ç”¨äº†ä¸€ç§åŸºäºè§†è§‰çš„ä½èµ„æºæ¡†æ¶ï¼Œå¹¶é€šè¿‡é˜¿å¸ƒæ‰æ¯”å’Œæ—§é‡‘å±±ä¸¤ä¸ªä¸åŒåœ°ç†åŒºåŸŸçš„æ•°æ®é›†éªŒè¯äº†æ¨¡å‹çš„è·¨åœ°ç†ç¯å¢ƒæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨é¢„æµ‹æ´ªæ°´æ·±åº¦å›¾çš„å¹³å‡ç»å¯¹è¯¯å·®(MAE)æ–¹é¢æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•(SOTA)å¹³å‡é™ä½äº†è¿‘20%ã€‚è¯¥ç ”ç©¶ä¸ºæ²¿æµ·æ´ªæ°´ç®¡ç†æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”å®ç”¨çš„å·¥å…·ï¼Œèƒ½å¤Ÿèµ‹èƒ½å†³ç­–è€…é’ˆå¯¹æ—¥ç›Šä¸¥å³»çš„æ°”å€™å½±å“åˆ¶å®šæœ‰æ•ˆçš„ç¼“è§£ç­–ç•¥ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to Hydrology and Earth System Sciences",
      "pdf_url": "https://arxiv.org/pdf/2510.26017v1",
      "published_date": "2025-10-29 23:23:11 UTC",
      "updated_date": "2025-10-29 23:23:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:19:45.665002+00:00"
    },
    {
      "arxiv_id": "2510.26014v1",
      "title": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis",
      "title_zh": "é¢å‘ç¦»æ•£æ—¶é—´ç”Ÿå­˜åˆ†æçš„åŒæ··åˆä¸“å®¶æ¡†æ¶",
      "authors": [
        "Hyeonjun Lee",
        "Hyungseob Shin",
        "Gunhee Nam",
        "Hyeonsoo Lee"
      ],
      "abstract": "Survival analysis is a task to model the time until an event of interest occurs, widely used in clinical and biomedical research. A key challenge is to model patient heterogeneity while also adapting risk predictions to both individual characteristics and temporal dynamics. We propose a dual mixture-of-experts (MoE) framework for discrete-time survival analysis. Our approach combines a feature-encoder MoE for subgroup-aware representation learning with a hazard MoE that leverages patient features and time embeddings to capture temporal dynamics. This dual-MoE design flexibly integrates with existing deep learning based survival pipelines. On METABRIC and GBSG breast cancer datasets, our method consistently improves performance, boosting the time-dependent C-index up to 0.04 on the test sets, and yields further gains when incorporated into the Consurv framework.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºç¦»æ•£æ—¶é—´ç”Ÿå­˜åˆ†æ(Discrete-Time Survival Analysis)çš„åŒæ··åˆä¸“å®¶(Dual Mixture-of-Experts, MoE)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸´åºŠç ”ç©¶ä¸­å»ºæ¨¡æ‚£è€…å¼‚è´¨æ€§ä»¥åŠé€‚åº”ä¸ªä½“ç‰¹å¾ä¸æ—¶é—´åŠ¨æ€çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ç”¨äºå­ç¾¤æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ çš„ç‰¹å¾ç¼–ç å™¨MoE(feature-encoder MoE)ä»¥åŠåˆ©ç”¨æ‚£è€…ç‰¹å¾å’Œæ—¶é—´åµŒå…¥(time embeddings)æ•è·æ—¶é—´åŠ¨æ€çš„é£é™©ç‡MoE(hazard MoE)ã€‚è¿™ç§åŒMoEè®¾è®¡å±•ç°äº†æé«˜çš„çµæ´»æ€§ï¼Œèƒ½å¤Ÿä¸ç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„ç”Ÿå­˜åˆ†æç®¡çº¿æ— ç¼é›†æˆã€‚åœ¨METABRICå’ŒGBSGä¹³è…ºç™Œæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä¸€è‡´æ€§åœ°æé«˜äº†æ¨¡å‹è¡¨ç°ï¼Œåœ¨æµ‹è¯•é›†ä¸Šçš„æ—¶é—´ä¾èµ–CæŒ‡æ•°(time-dependent C-index)æå‡é«˜è¾¾0.04ã€‚æ­¤å¤–ï¼Œå°†å…¶å¹¶å…¥Consurvæ¡†æ¶åï¼Œæ€§èƒ½å¾—åˆ°äº†è¿›ä¸€æ­¥æå‡ï¼ŒéªŒè¯äº†è¯¥æ¨¡å‹åœ¨å¤„ç†å¤æ‚ç”Ÿç‰©åŒ»å­¦æ•°æ®ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2025 workshop Learning from Time Series for Health (TS4H)",
      "pdf_url": "https://arxiv.org/pdf/2510.26014v1",
      "published_date": "2025-10-29 23:11:01 UTC",
      "updated_date": "2025-10-29 23:11:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:19:48.466981+00:00"
    },
    {
      "arxiv_id": "2510.26012v3",
      "title": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys",
      "title_zh": "AutoSurvey2ï¼šä»¥æ›´é«˜æ°´å¹³çš„è‡ªåŠ¨åŒ–æ–‡çŒ®ç»¼è¿°èµ‹èƒ½ç§‘ç ”äººå‘˜",
      "authors": [
        "Siyi Wu",
        "Chiaxin Liang",
        "Ziqian Bi",
        "Leyi Zhao",
        "Tianyang Wang",
        "Junhao Song",
        "Yichao Zhang",
        "Keyu Chen",
        "Benji Peng",
        "Xinyuan Song"
      ],
      "abstract": "The rapid growth of research literature, particularly in large language models (LLMs), has made producing comprehensive and current survey papers increasingly difficult. This paper introduces autosurvey2, a multi-stage pipeline that automates survey generation through retrieval-augmented synthesis and structured evaluation. The system integrates parallel section generation, iterative refinement, and real-time retrieval of recent publications to ensure both topical completeness and factual accuracy. Quality is assessed using a multi-LLM evaluation framework that measures coverage, structure, and relevance in alignment with expert review standards. Experimental results demonstrate that autosurvey2 consistently outperforms existing retrieval-based and automated baselines, achieving higher scores in structural coherence and topical relevance while maintaining strong citation fidelity. By combining retrieval, reasoning, and automated evaluation into a unified framework, autosurvey2 provides a scalable and reproducible solution for generating long-form academic surveys and contributes a solid foundation for future research on automated scholarly writing. All code and resources are available at https://github.com/annihi1ation/auto_research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† autosurvey2ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è‡ªåŠ¨åŒ–ç”Ÿæˆå­¦æœ¯ç»¼è¿°çš„å¤šé˜¶æ®µç®¡çº¿ï¼Œä¸“é—¨åº”å¯¹ Large Language Models (LLMs) ç­‰é¢†åŸŸæ–‡çŒ®çˆ†å‘å¼å¢é•¿å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡é›†æˆå¹¶è¡Œç« èŠ‚ç”Ÿæˆ (parallel section generation)ã€è¿­ä»£ä¼˜åŒ–ä»¥åŠå¯¹æœ€æ–°å‘è¡¨æ–‡çŒ®çš„å®æ—¶æ£€ç´¢ï¼Œç¡®ä¿äº†ç»¼è¿°å†…å®¹çš„å®Œæ•´æ€§ä¸äº‹å®å‡†ç¡®æ€§ã€‚ä¸ºäº†ä¿è¯è´¨é‡ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªå¤š LLM è¯„ä¼°æ¡†æ¶ï¼Œä»è¦†ç›–èŒƒå›´ã€ç»“æ„å’Œç›¸å…³æ€§ç­‰å¤šä¸ªç»´åº¦è¿›è¡Œå¯¹é½ä¸“å®¶æ ‡å‡†çš„è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œautosurvey2 åœ¨ç»“æ„è¿è´¯æ€§å’Œä¸»é¢˜ç›¸å…³æ€§æ–¹é¢æŒç»­ä¼˜äºç°æœ‰çš„è‡ªåŠ¨åŒ–åŸºå‡†æ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒäº†æé«˜çš„å¼•ç”¨å¿ å®åº¦ã€‚é€šè¿‡å°†æ£€ç´¢ã€æ¨ç†ä¸è‡ªåŠ¨åŒ–è¯„ä¼°æ•´åˆè¿›ç»Ÿä¸€æ¡†æ¶ï¼Œautosurvey2 ä¸ºç”Ÿæˆé•¿ç¯‡å­¦æœ¯ç»¼è¿°æä¾›äº†å¯æ‰©å±•ä¸”å¯é‡å¤çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºæœªæ¥çš„è‡ªåŠ¨åŒ–ç§‘ç ”å†™ä½œå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "TKDD 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.26012v3",
      "published_date": "2025-10-29 22:57:03 UTC",
      "updated_date": "2025-12-02 16:13:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:19:50.067810+00:00"
    },
    {
      "arxiv_id": "2510.26007v1",
      "title": "The Quest for Reliable Metrics of Responsible AI",
      "title_zh": "è´Ÿè´£ä»»äººå·¥æ™ºèƒ½å¯é åº¦é‡æŒ‡æ ‡çš„æ¢ç´¢",
      "authors": [
        "Theresia Veronika Rampisela",
        "Maria Maistro",
        "Tuukka Ruotsalo",
        "Christina Lioma"
      ],
      "abstract": "The development of Artificial Intelligence (AI), including AI in Science (AIS), should be done following the principles of responsible AI. Progress in responsible AI is often quantified through evaluation metrics, yet there has been less work on assessing the robustness and reliability of the metrics themselves. We reflect on prior work that examines the robustness of fairness metrics for recommender systems as a type of AI application and summarise their key takeaways into a set of non-exhaustive guidelines for developing reliable metrics of responsible AI. Our guidelines apply to a broad spectrum of AI applications, including AIS.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è´Ÿè´£ä»»äººå·¥æ™ºèƒ½ (Responsible AI) çš„å‘å±•åŸåˆ™ï¼Œé‡ç‚¹å…³æ³¨ç”¨äºè¡¡é‡å…¶è¿›å±•çš„è¯„ä¼°æŒ‡æ ‡çš„å¯é æ€§ä¸é²æ£’æ€§ã€‚å°½ç®¡è´Ÿè´£ä»» AI é¢†åŸŸä¸æ–­è¿›æ­¥ï¼Œä½†ç›®å‰å¯¹äºè¯„ä¼°æŒ‡æ ‡æœ¬èº«ç¨³å¥æ€§çš„ç ”ç©¶å°šæ˜¾ä¸è¶³ã€‚ä½œè€…å›é¡¾äº†ä»¥å¾€å…³äºæ¨èç³»ç»Ÿå…¬å¹³æ€§æŒ‡æ ‡ (fairness metrics) é²æ£’æ€§çš„ç ”ç©¶å·¥ä½œï¼Œå¹¶æ€»ç»“äº†å…¶æ ¸å¿ƒç»éªŒã€‚åŸºäºè¿™äº›ç»éªŒï¼Œç ”ç©¶æå‡ºäº†ä¸€å¥—éè¯¦å°½çš„æŒ‡å¯¼åŸåˆ™ (guidelines)ï¼Œæ—¨åœ¨åŠ©åŠ›å¼€å‘æ›´å¯é çš„è´Ÿè´£ä»» AI è¯„ä¼°æŒ‡æ ‡ã€‚è¿™äº›å‡†åˆ™å…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ï¼Œå¯åº”ç”¨äºåŒ…æ‹¬ç§‘å­¦é¢†åŸŸäººå·¥æ™ºèƒ½ (AI in Science, AIS) åœ¨å†…çš„å¤šç§ AI åº”ç”¨åœºæ™¯ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for presentation at the AI in Science Summit 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.26007v1",
      "published_date": "2025-10-29 22:35:34 UTC",
      "updated_date": "2025-10-29 22:35:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:19:53.569801+00:00"
    },
    {
      "arxiv_id": "2510.26004v1",
      "title": "DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System",
      "title_zh": "DARTSï¼šåŸºäºæ— äººæœºçš„äººå·¥æ™ºèƒ½é©±åŠ¨å®æ—¶äº¤é€šäº‹ä»¶æ£€æµ‹ç³»ç»Ÿ",
      "authors": [
        "Bai Li",
        "Achilleas Kourtellis",
        "Rong Cao",
        "Joseph Post",
        "Brian Porter",
        "Yu Zhang"
      ],
      "abstract": "Rapid and reliable incident detection is critical for reducing crash-related fatalities, injuries, and congestion. However, conventional methods, such as closed-circuit television, dashcam footage, and sensor-based detection, separate detection from verification, suffer from limited flexibility, and require dense infrastructure or high penetration rates, restricting adaptability and scalability to shifting incident hotspots. To overcome these challenges, we developed DARTS, a drone-based, AI-powered real-time traffic incident detection system. DARTS integrates drones' high mobility and aerial perspective for adaptive surveillance, thermal imaging for better low-visibility performance and privacy protection, and a lightweight deep learning framework for real-time vehicle trajectory extraction and incident detection. The system achieved 99% detection accuracy on a self-collected dataset and supports simultaneous online visual verification, severity assessment, and incident-induced congestion propagation monitoring via a web-based interface. In a field test on Interstate 75 in Florida, DARTS detected and verified a rear-end collision 12 minutes earlier than the local transportation management center and monitored incident-induced congestion propagation, suggesting potential to support faster emergency response and enable proactive traffic control to reduce congestion and secondary crash risk. Crucially, DARTS's flexible deployment architecture reduces dependence on frequent physical patrols, indicating potential scalability and cost-effectiveness for use in remote areas and resource-constrained settings. This study presents a promising step toward a more flexible and integrated real-time traffic incident detection system, with significant implications for the operational efficiency and responsiveness of modern transportation management.",
      "tldr_zh": "æœ¬ç ”ç©¶å¼€å‘äº† DARTSï¼Œä¸€ç§åŸºäº drone å’Œ AI é©±åŠ¨çš„å®æ—¶äº¤é€šäº‹ä»¶æ£€æµ‹ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå›ºå®šç›‘æ§è®¾å¤‡çµæ´»æ€§å·®ä¸”é«˜åº¦ä¾èµ–åŸºç¡€è®¾æ–½çš„å±€é™ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨æ— äººæœºçš„é«˜æµåŠ¨æ€§ä¸ç©ºä¸­è§†è§’è¿›è¡Œè‡ªé€‚åº”ç›‘æµ‹ï¼Œå¹¶ç»“åˆ thermal imaging æŠ€æœ¯æå‡äº†ä½èƒ½è§åº¦ä¸‹çš„æ€§èƒ½ä¸éšç§ä¿æŠ¤èƒ½åŠ›ã€‚é€šè¿‡é›†æˆ lightweight deep learning frameworkï¼ŒDARTS èƒ½å¤Ÿå®ç°å®æ—¶çš„è½¦è¾†è½¨è¿¹æå–ä¸äº‹ä»¶æ£€æµ‹ï¼Œåœ¨è‡ªå»ºæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡è¾¾åˆ°äº† 99%ã€‚åœ¨ I-75 å…¬è·¯çš„å®åœ°æµ‹è¯•ä¸­ï¼Œè¯¥ç³»ç»Ÿæ¯”å½“åœ°äº¤é€šç®¡ç†ä¸­å¿ƒæå‰ 12 åˆ†é’Ÿæ£€æµ‹å¹¶éªŒè¯äº†ä¸€èµ·è¿½å°¾ç¢°æ’äº‹æ•…ï¼Œå¹¶æˆåŠŸç›‘æµ‹äº†åç»­çš„æ‹¥å µæ‰©æ•£ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒDARTS çš„çµæ´»éƒ¨ç½²æ¶æ„æ˜¾è‘—é™ä½äº†å¯¹ç‰©ç†å·¡é€»çš„ä¾èµ–ï¼Œåœ¨åè¿œåœ°åŒºå’Œèµ„æºå—é™ç¯å¢ƒä¸‹å…·æœ‰æé«˜çš„å¯æ‰©å±•æ€§ä¸æˆæœ¬æ•ˆç›Šï¼Œä¸ºå®ç°æ›´é«˜æ•ˆã€ä¸»åŠ¨çš„ç°ä»£äº¤é€šç®¡ç†å’Œæ›´å¿«é€Ÿçš„åº”æ€¥å“åº”æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Preprint version. This manuscript is currently under review at Transportation Research Part C: Emerging Technologies. The PDF corresponds to the version submitted in June 2025. The main findings of this work were recognized with the Best Intelligent Transportation Systems Paper Award at the 2025 TRB Annual Meeting",
      "pdf_url": "https://arxiv.org/pdf/2510.26004v1",
      "published_date": "2025-10-29 22:32:16 UTC",
      "updated_date": "2025-10-29 22:32:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:00.472550+00:00"
    },
    {
      "arxiv_id": "2510.25997v1",
      "title": "From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL",
      "title_zh": "ä»æŸ¥è¯¢åˆ°æ´å¯Ÿï¼šé¢å‘æ—¶ç©º Text-to-SQL çš„æ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹æµæ°´çº¿",
      "authors": [
        "Manu Redd",
        "Tao Zhe",
        "Dongjie Wang"
      ],
      "abstract": "Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing access to structured data, allowing users to query databases without learning SQL. Yet existing systems struggle with realistic spatio-temporal queries, where success requires aligning vague user phrasing with schema-specific categories, handling temporal reasoning, and choosing appropriate outputs. We present an agentic pipeline that extends a naive text-to-SQL baseline (llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The agent can plan, decompose, and adapt queries through schema inspection, SQL generation, execution, and visualization tools. We evaluate on 35 natural-language queries over the NYC and Tokyo check-in dataset, covering spatial, temporal, and multi-dataset reasoning. The agent achieves substantially higher accuracy than the naive baseline 91.4% vs. 28.6% and enhances usability through maps, plots, and structured natural-language summaries. Crucially, our design enables more natural human-database interaction, supporting users who lack SQL expertise, detailed schema knowledge, or prompting skill. We conclude that agentic orchestration, rather than stronger SQL generators alone, is a promising foundation for interactive geospatial assistants.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰NL-to-SQLç³»ç»Ÿåœ¨å¤„ç†æ—¶ç©ºæŸ¥è¯¢ï¼ˆspatio-temporal queriesï¼‰æ—¶é¢ä¸´çš„æ¨¡ç³Šè¡¨è¾¾ã€æ—¶é—´æ¨ç†å’Œæ¨¡å¼å¯¹é½ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ™ºèƒ½ä½“ï¼ˆagenticï¼‰çš„LLMæµæ°´çº¿ã€‚è¯¥æ–¹æ³•é€šè¿‡Mistralé©±åŠ¨çš„ReActæ™ºèƒ½ä½“å¯¹åŸºå‡†æ¨¡å‹llama-3-sqlcoder-8bè¿›è¡Œç¼–æ’ï¼Œä½¿å…¶å…·å¤‡è§„åˆ’ã€ä»»åŠ¡åˆ†è§£ä»¥åŠé€šè¿‡æ¨¡å¼æ£€æŸ¥ã€SQLç”Ÿæˆã€æ‰§è¡Œå’Œå¯è§†åŒ–å·¥å…·è¿›è¡ŒæŸ¥è¯¢è°ƒæ•´çš„èƒ½åŠ›ã€‚ç ”ç©¶äººå‘˜åœ¨æ¶‰åŠçº½çº¦å’Œä¸œäº¬ç­¾åˆ°æ•°æ®é›†çš„35ä¸ªè‡ªç„¶è¯­è¨€æŸ¥è¯¢ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ¶µç›–äº†ç©ºé—´ã€æ—¶é—´å’Œå¤šæ•°æ®é›†æ¨ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ™ºèƒ½ä½“æµæ°´çº¿çš„å‡†ç¡®ç‡è¾¾åˆ°91.4%ï¼Œæ˜¾è‘—ä¼˜äºåŸºå‡†æ¨¡å‹çš„28.6%ï¼Œå¹¶é€šè¿‡åœ°å›¾ã€å›¾è¡¨å’Œç»“æ„åŒ–æ‘˜è¦æå‡äº†æ˜“ç”¨æ€§ã€‚ç ”ç©¶æœ€ç»ˆå¾—å‡ºç»“è®ºï¼Œç›¸æ¯”äºå•çº¯æå‡SQLç”Ÿæˆå™¨çš„æ€§èƒ½ï¼Œæ™ºèƒ½ä½“ç¼–æ’ï¼ˆagentic orchestrationï¼‰èƒ½æ›´æœ‰æ•ˆåœ°æ”¯æŒç¼ºä¹SQLä¸“ä¸šçŸ¥è¯†çš„ç”¨æˆ·è¿›è¡Œè‡ªç„¶çš„äººæœºäº¤äº’ï¼Œæ˜¯æ„å»ºäº¤äº’å¼åœ°ç†ç©ºé—´åŠ©æ‰‹çš„ç†æƒ³åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 5 figures, GeoGenAgent'25 - ACM SIGSPATIAL",
      "pdf_url": "https://arxiv.org/pdf/2510.25997v1",
      "published_date": "2025-10-29 22:18:57 UTC",
      "updated_date": "2025-10-29 22:18:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:00.776694+00:00"
    },
    {
      "arxiv_id": "2511.00086v1",
      "title": "Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph",
      "title_zh": "å°†æµ‹è¯•æ—¶è®¡ç®—æœ€ä¼˜ç¼©æ”¾æ³›åŒ–ä¸ºå¯ä¼˜åŒ–å›¾",
      "authors": [
        "Fali Wang",
        "Jihai Chen",
        "Shuhua Yang",
        "Runxue Bao",
        "Tianxiang Zhao",
        "Zhiwei Zhang",
        "Xianfeng Tang",
        "Hui Liu",
        "Qi He",
        "Suhang Wang"
      ],
      "abstract": "Test-Time Scaling (TTS) improves large language models (LLMs) by allocating additional computation during inference, typically through parallel, sequential, or hybrid scaling. However, prior studies often assume fixed collaboration architectures (e.g., topologies) and single-model usage, overlooking that optimal architectures and model combinations can vary across tasks. Therefore, we study the novel problem of searching for compute-optimal model combinations and architectures in TTS under a fixed budget. We formalize it as a multi-LLM collaboration graph, where nodes encode roles and LLM model assignments, and edges capture information flow. This problem is challenging because (i) the combinatorial search space is prohibitively large, and (ii) task-specific requirements demand tailored designs. To address these, we reformulate the problem as probabilistic graph optimization and, through pilot experiments, derive three empirical insights into TTS collaboration graphs. Guided by these insights, we propose Agent-REINFORCE, an LLM-agent-augmented framework that mirrors the REINFORCE pipeline by mapping sampling-gradient-update to sampling-feedback-update, where feedback serves as a textual gradient to update the probabilistic graph and efficiently search for optimal multi-LLM collaboration graphs. Experiments show that Agent-REINFORCE outperforms both traditional and LLM-based baselines in sample efficiency and search performance, and effectively identifies optimal graphs under joint objectives of accuracy and inference latency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†é˜¶æ®µçš„ Test-Time Scaling (TTS) æŠ€æœ¯å±•å¼€ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç ”ç©¶ä¸­åä½œæ¶æ„å›ºå®šä¸”å¤šé™äºå•ä¸€æ¨¡å‹çš„é—®é¢˜ã€‚ä½œè€…å°†å¯»æ‰¾å›ºå®šé¢„ç®—ä¸‹æœ€ä¼˜æ¨¡å‹ç»„åˆä¸æ¶æ„çš„ä»»åŠ¡å½¢å¼åŒ–ä¸ºä¸€ç§å¤šå¤§è¯­è¨€æ¨¡å‹åä½œå›¾ (multi-LLM collaboration graph)ï¼Œå…¶ä¸­èŠ‚ç‚¹ä»£è¡¨è§’è‰²ä¸æ¨¡å‹åˆ†é…ï¼Œè¾¹åˆ™æ•æ‰ä¿¡æ¯æµã€‚ä¸ºäº†é«˜æ•ˆæ¢ç´¢å·¨å¤§çš„ç»„åˆæœç´¢ç©ºé—´ï¼Œç ”ç©¶å°†è¯¥é—®é¢˜è½¬åŒ–ä¸ºæ¦‚ç‡å›¾ä¼˜åŒ–ï¼Œå¹¶æå‡ºäº† Agent-REINFORCE æ¡†æ¶ã€‚è¯¥æ¡†æ¶å€Ÿé‰´ REINFORCE ç®—æ³•é€»è¾‘ï¼Œåˆ©ç”¨å¤§æ¨¡å‹æ™ºèƒ½ä½“å°†åé¦ˆä½œä¸ºæ–‡æœ¬æ¢¯åº¦ (textual gradient) æ¥è¿­ä»£æ›´æ–°æ¦‚ç‡å›¾ï¼Œä»è€Œå®ç°å¯¹æœ€ä¼˜åä½œæ¶æ„çš„è‡ªåŠ¨åŒ–æœç´¢ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒAgent-REINFORCE åœ¨é‡‡æ ·æ•ˆç‡å’Œæœç´¢æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºçº¿ï¼Œå¹¶èƒ½æœ‰æ•ˆå¹³è¡¡å‡†ç¡®ç‡ä¸æ¨ç†å»¶è¿Ÿ (inference latency) ä¹‹é—´çš„å…³ç³»ï¼Œè¯†åˆ«å‡ºæœ€ä¼˜çš„è®¡ç®— scaling ç­–ç•¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "https://arxiv.org/pdf/2511.00086v1",
      "published_date": "2025-10-29 22:14:25 UTC",
      "updated_date": "2025-10-29 22:14:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:13.659748+00:00"
    },
    {
      "arxiv_id": "2510.25992v1",
      "title": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning",
      "title_zh": "æœ‰ç›‘ç£å¼ºåŒ–å­¦ä¹ ï¼šä»ä¸“å®¶è½¨è¿¹åˆ°é€æ­¥æ¨ç†",
      "authors": [
        "Yihe Deng",
        "I-Hung Hsu",
        "Jun Yan",
        "Zifeng Wang",
        "Rujun Han",
        "Gufeng Zhang",
        "Yanfei Chen",
        "Wei Wang",
        "Tomas Pfister",
        "Chen-Yu Lee"
      ],
      "abstract": "Large Language Models (LLMs) often struggle with problems that require multi-step reasoning. For small-scale open-source models, Reinforcement Learning with Verifiable Rewards (RLVR) fails when correct solutions are rarely sampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to overfit long demonstrations through rigid token-by-token imitation. To address this gap, we propose Supervised Reinforcement Learning (SRL), a framework that reformulates problem solving as generating a sequence of logical \"actions\". SRL trains the model to generate an internal reasoning monologue before committing to each action. It provides smoother rewards based on the similarity between the model's actions and expert actions extracted from the SFT dataset in a step-wise manner. This supervision offers richer learning signals even when all rollouts are incorrect, while encouraging flexible reasoning guided by expert demonstrations. As a result, SRL enables small models to learn challenging problems previously unlearnable by SFT or RLVR. Moreover, initializing training with SRL before refining with RLVR yields the strongest overall performance. Beyond reasoning benchmarks, SRL generalizes effectively to agentic software engineering tasks, establishing it as a robust and versatile training framework for reasoning-oriented LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Supervised Reinforcement Learning (SRL)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å°è§„æ¨¡å¼€æºæ¨¡å‹åœ¨å¤šæ­¥æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´çš„å›°å¢ƒã€‚é’ˆå¯¹Reinforcement Learning with Verifiable Rewards (RLVR)åœ¨æ­£ç¡®è§£é‡‡æ ·ç‡æä½æ—¶å¤±æ•ˆï¼Œä»¥åŠSupervised Fine-Tuning (SFT)å®¹æ˜“å¯¼è‡´åƒµåŒ–æ¨¡ä»¿å’Œè¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼ŒSRLå°†é—®é¢˜æ±‚è§£è¿‡ç¨‹é‡æ„ä¸ºç”Ÿæˆä¸€ç³»åˆ—é€»è¾‘actionã€‚è¯¥æ¡†æ¶è®­ç»ƒæ¨¡å‹åœ¨æ‰§è¡Œæ¯ä¸ªactionå‰ç”Ÿæˆå†…éƒ¨reasoning monologueï¼Œå¹¶ä¾æ®æ¨¡å‹è¾“å‡ºä¸SFTæ•°æ®é›†ä¸­çš„ä¸“å®¶è½¨è¿¹ä¹‹é—´çš„æ­¥éª¤çº§ç›¸ä¼¼åº¦æä¾›å¹³æ»‘çš„å¥–åŠ±ä¿¡å·ã€‚è¿™ç§ç›‘ç£æœºåˆ¶å³ä¾¿åœ¨æ‰€æœ‰rolloutså‡é”™è¯¯çš„æƒ…å†µä¸‹ä¹Ÿèƒ½æä¾›ä¸°å¯Œçš„å­¦ä¹ ä¿¡å·ï¼Œä»è€Œé¼“åŠ±å—ä¸“å®¶æ¼”ç¤ºå¼•å¯¼çš„çµæ´»æ¨ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSRLä½¿å°å‹æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ­¤å‰æ— æ³•é€šè¿‡SFTæˆ–RLVRæŒæ¡çš„æŒ‘æˆ˜æ€§é—®é¢˜ï¼Œä¸”ä½œä¸ºRLVRçš„åˆå§‹åŒ–è®­ç»ƒé˜¶æ®µæ—¶æ€§èƒ½è¡¨ç°æœ€å¼ºã€‚æ­¤å¤–ï¼ŒSRLåœ¨agentic software engineeringä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–æ€§ï¼Œè¯æ˜äº†å…¶ä½œä¸ºæ¨ç†å¯¼å‘å‹LLMsè®­ç»ƒæ¡†æ¶çš„ç¨³å¥æ€§ä¸é€šç”¨æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25992v1",
      "published_date": "2025-10-29 22:05:08 UTC",
      "updated_date": "2025-10-29 22:05:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:18.378377+00:00"
    },
    {
      "arxiv_id": "2510.25976v1",
      "title": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer",
      "title_zh": "Brain-ITï¼šåŸºäºå¤§è„‘äº¤äº’ Transformer çš„ fMRI å›¾åƒé‡å»º",
      "authors": [
        "Roman Beliy",
        "Amit Zalcher",
        "Jonathan Kogman",
        "Navve Wasserman",
        "Michal Irani"
      ],
      "abstract": "Reconstructing images seen by people from their fMRI brain recordings provides a non-invasive window into the human brain. Despite recent progress enabled by diffusion models, current methods often lack faithfulness to the actual seen images. We present \"Brain-IT\", a brain-inspired approach that addresses this challenge through a Brain Interaction Transformer (BIT), allowing effective interactions between clusters of functionally-similar brain-voxels. These functional-clusters are shared by all subjects, serving as building blocks for integrating information both within and across brains. All model components are shared by all clusters & subjects, allowing efficient training with a limited amount of data. To guide the image reconstruction, BIT predicts two complementary localized patch-level image features: (i)high-level semantic features which steer the diffusion model toward the correct semantic content of the image; and (ii)low-level structural features which help to initialize the diffusion process with the correct coarse layout of the image. BIT's design enables direct flow of information from brain-voxel clusters to localized image features. Through these principles, our method achieves image reconstructions from fMRI that faithfully reconstruct the seen images, and surpass current SotA approaches both visually and by standard objective metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve results comparable to current methods trained on full 40-hour recordings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Brain-ITï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡Brain Interaction Transformer (BIT) ä»fMRIä¿¡å·ä¸­é‡å»ºå›¾åƒçš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨é‡å»ºå›¾åƒä¿çœŸåº¦æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ¡†æ¶åˆ©ç”¨BITä¿ƒè¿›åŠŸèƒ½ç›¸ä¼¼çš„å¤§è„‘ä½“ç´ ç°‡ (functionally-similar brain-voxels) ä¹‹é—´çš„äº¤äº’ï¼Œè¿™äº›è·¨å—è¯•è€…å…±äº«çš„ä½“ç´ ç°‡æˆä¸ºäº†æ•´åˆå¤§è„‘å†…å¤–ä¿¡æ¯çš„åŸºçŸ³ã€‚BITé€šè¿‡é¢„æµ‹é«˜å±‚è¯­ä¹‰ç‰¹å¾ (high-level semantic features) å’Œåº•å±‚ç»“æ„ç‰¹å¾ (low-level structural features) æ¥å¼•å¯¼æ‰©æ•£è¿‡ç¨‹ï¼Œç¡®ä¿é‡å»ºå›¾åƒåœ¨è¯­ä¹‰å†…å®¹å’Œç©ºé—´å¸ƒå±€ä¸Šä¸åŸå§‹è§†è§‰è¾“å…¥ä¿æŒä¸€è‡´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBrain-ITåœ¨è§†è§‰è´¨é‡å’Œå®¢è§‚æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„SotAæ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¥æ–¹æ³•å…·æœ‰æé«˜çš„æ•°æ®æ•ˆç‡ï¼Œä»…éœ€æ–°å—è¯•è€…1å°æ—¶çš„fMRIæ•°æ®å³å¯å®ç°ä¸ä¼ ç»Ÿæ–¹æ³•ä½¿ç”¨40å°æ—¶æ•°æ®ç›¸å½“çš„é‡å»ºæ•ˆæœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25976v1",
      "published_date": "2025-10-29 21:21:54 UTC",
      "updated_date": "2025-10-29 21:21:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:18.559973+00:00"
    },
    {
      "arxiv_id": "2510.25960v1",
      "title": "WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows",
      "title_zh": "WaveVerifï¼šåŸºäºå£°å­¦ä¾§ä¿¡é“çš„æœºå™¨äººå·¥ä½œæµéªŒè¯",
      "authors": [
        "Zeynep Yasemin Erdogan",
        "Shishir Nagaraja",
        "Chuadhry Mujeeb Ahmed",
        "Ryan Shah"
      ],
      "abstract": "In this paper, we present a framework that uses acoustic side-channel analysis (ASCA) to monitor and verify whether a robot correctly executes its intended commands. We develop and evaluate a machine-learning-based workflow verification system that uses acoustic emissions generated by robotic movements. The system can determine whether real-time behavior is consistent with expected commands. The evaluation takes into account movement speed, direction, and microphone distance. The results show that individual robot movements can be validated with over 80% accuracy under baseline conditions using four different classifiers: Support Vector Machine (SVM), Deep Neural Network (DNN), Recurrent Neural Network (RNN), and Convolutional Neural Network (CNN). Additionally, workflows such as pick-and-place and packing could be identified with similarly high confidence. Our findings demonstrate that acoustic signals can support real-time, low-cost, passive verification in sensitive robotic environments without requiring hardware modifications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† WaveVerif æ¡†æ¶ï¼Œåˆ©ç”¨å£°å­¦ä¾§ä¿¡é“åˆ†æ (Acoustic Side-Channel Analysis, ASCA) æŠ€æœ¯æ¥ç›‘æ§å¹¶éªŒè¯æœºå™¨äººæ˜¯å¦æ­£ç¡®æ‰§è¡Œäº†é¢„å®šæŒ‡ä»¤ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ•è·æœºå™¨äººè¿åŠ¨äº§ç”Ÿçš„å£°å­¦å‘å°„ä¿¡å·ï¼Œå¹¶åˆ©ç”¨æœºå™¨å­¦ä¹ ç®—æ³•åˆ¤æ–­å…¶å®æ—¶è¡Œä¸ºä¸é¢„æœŸæŒ‡ä»¤çš„ä¸€è‡´æ€§ã€‚å®éªŒè¯„ä¼°äº†è¿åŠ¨é€Ÿåº¦ã€æ–¹å‘åŠéº¦å…‹é£è·ç¦»ç­‰å˜é‡çš„å½±å“ï¼Œå¹¶é‡‡ç”¨äº†æ”¯æŒå‘é‡æœº (SVM)ã€æ·±åº¦ç¥ç»ç½‘ç»œ (DNN)ã€å¾ªç¯ç¥ç»ç½‘ç»œ (RNN) å’Œå·ç§¯ç¥ç»ç½‘ç»œ (CNN) å››ç§åˆ†ç±»å™¨ã€‚ç»“æœè¡¨æ˜ï¼ŒWaveVerif å¯¹å•ä¸ªæœºå™¨äººåŠ¨ä½œçš„éªŒè¯å‡†ç¡®ç‡è¶…è¿‡ 80%ï¼Œä¸”å¯¹å–æ”¾ (Pick-and-Place) å’ŒåŒ…è£… (Packing) ç­‰å¤æ‚å·¥ä½œæµä¹Ÿå…·æœ‰æé«˜çš„è¯†åˆ«ç½®ä¿¡åº¦ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å£°å­¦ä¿¡å·èƒ½å¤Ÿä¸ºæ•æ„Ÿçš„æœºå™¨äººç¯å¢ƒæä¾›ä¸€ç§æ— éœ€ç¡¬ä»¶æ”¹é€ ã€å®æ—¶ä¸”ä½æˆæœ¬çš„è¢«åŠ¨éªŒè¯æ‰‹æ®µã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 3 figures, Corresponding Author: Prof. Shishir Nagaraja (shishir.nagaraja@newcastle.ac.uk)",
      "pdf_url": "https://arxiv.org/pdf/2510.25960v1",
      "published_date": "2025-10-29 20:58:16 UTC",
      "updated_date": "2025-10-29 20:58:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:22.479883+00:00"
    },
    {
      "arxiv_id": "2510.25954v1",
      "title": "Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi",
      "title_zh": "åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹æ•°æ®åœ¨åŒ»ç–—æœºæ„é¡¹ç›®äº§å‡ºé¢„æµ‹ä¸­çš„åº”ç”¨ä¸éªŒè¯â€”â€”ä»¥ Malawi ä¸ºä¾‹",
      "authors": [
        "Lynn Metz",
        "Rachel Haggard",
        "Michael Moszczynski",
        "Samer Asbah",
        "Chris Mwase",
        "Patricia Khomani",
        "Tyler Smith",
        "Hannah Cooper",
        "Annie Mwale",
        "Arbaaz Muslim",
        "Gautam Prasad",
        "Mimi Sun",
        "Tomer Shekel",
        "Joydeep Paul",
        "Anna Carter",
        "Shravya Shetty",
        "Dylan Green"
      ],
      "abstract": "The reliability of routine health data in low and middle-income countries (LMICs) is often constrained by reporting delays and incomplete coverage, necessitating the exploration of novel data sources and analytics. Geospatial Foundation Models (GeoFMs) offer a promising avenue by synthesizing diverse spatial, temporal, and behavioral data into mathematical embeddings that can be efficiently used for downstream prediction tasks. This study evaluated the predictive performance of three GeoFM embedding sources - Google Population Dynamics Foundation Model (PDFM), Google AlphaEarth (derived from satellite imagery), and mobile phone call detail records (CDR) - for modeling 15 routine health programmatic outputs in Malawi, and compared their utility to traditional geospatial interpolation methods. We used XGBoost models on data from 552 health catchment areas (January 2021-May 2023), assessing performance with R2, and using an 80/20 training and test data split with 5-fold cross-validation used in training. While predictive performance was mixed, the embedding-based approaches improved upon baseline geostatistical methods in 13 of 15 (87%) indicators tested. A Multi-GeoFM model integrating all three embedding sources produced the most robust predictions, achieving average 5-fold cross validated R2 values for indicators like population density (0.63), new HIV cases (0.57), and child vaccinations (0.47) and test set R2 of 0.64, 0.68, and 0.55, respectively. Prediction was poor for prediction targets with low primary data availability, such as TB and malnutrition cases. These results demonstrate that GeoFM embeddings imbue a modest predictive improvement for select health and demographic outcomes in an LMIC context. We conclude that the integration of multiple GeoFM sources is an efficient and valuable tool for supplementing and strengthening constrained routine health information systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä½æ”¶å…¥å’Œä¸­ç­‰æ”¶å…¥å›½å®¶ï¼ˆLMICsï¼‰èƒŒæ™¯ä¸‹ï¼Œå¦‚ä½•åˆ©ç”¨åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹ï¼ˆGeospatial Foundation Models, GeoFMsï¼‰çš„æ•°æ®é¢„æµ‹åŒ»ç–—æœºæ„çš„è®¡åˆ’æ€§è¾“å‡ºã€‚ç ”ç©¶ä»¥é©¬æ‹‰ç»´ï¼ˆMalawiï¼‰ä¸ºæ¡ˆä¾‹ï¼Œè¯„ä¼°äº†åŒ…æ‹¬ Google Population Dynamics Foundation Model (PDFM)ã€Google AlphaEarth å’Œç§»åŠ¨ç”µè¯å‘¼å«è¯¦ç»†è®°å½•ï¼ˆCDRï¼‰åœ¨å†…çš„ä¸‰ç§ GeoFM åµŒå…¥ï¼ˆembeddingsï¼‰æºçš„é¢„æµ‹æ€§èƒ½ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ XGBoost æ¨¡å‹å¯¹ 552 ä¸ªåŒ»ç–—æœåŠ¡åŒºçš„ 15 é¡¹å¸¸è§„å¥åº·æŒ‡æ ‡è¿›è¡Œäº†å»ºæ¨¡ï¼Œå¹¶å°†å…¶ä¸ä¼ ç»Ÿçš„åœ°ç†ç©ºé—´æ’å€¼æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºåµŒå…¥çš„æ–¹æ³•åœ¨ 87% çš„æµ‹è¯•æŒ‡æ ‡ä¸­ä¼˜äºåŸºå‡†åœ°ç»Ÿè®¡æ–¹æ³•ã€‚æ•´åˆäº†ä¸‰ç§æ•°æ®æºçš„ Multi-GeoFM æ¨¡å‹è¡¨ç°æœ€ä¸ºç¨³å¥ï¼Œåœ¨äººå£å¯†åº¦ã€HIV æ–°å‘ç—…ä¾‹å’Œå„¿ç«¥ç–«è‹—æ¥ç§ç­‰å…³é”®æŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„é¢„æµ‹ç²¾åº¦ã€‚å°½ç®¡å¯¹äºæ•°æ®ç¨€ç¼ºæŒ‡æ ‡çš„é¢„æµ‹æ•ˆæœä»å—é™ï¼Œä½† GeoFM åµŒå…¥åœ¨ç‰¹å®šå¥åº·å’Œäººå£ç»Ÿè®¡ç»“æœä¸­å±•ç°äº†æ˜ç¡®çš„é¢„æµ‹æå‡ã€‚ç ”ç©¶ç»“è®ºæŒ‡å‡ºï¼Œé›†æˆå¤šä¸ª GeoFM æ¥æºæ˜¯è¡¥å……å’ŒåŠ å¼ºèµ„æºå—é™çš„å¸¸è§„å¥åº·ä¿¡æ¯ç³»ç»Ÿçš„é«˜æ•ˆå·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 3010 words, 2 tables, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25954v1",
      "published_date": "2025-10-29 20:53:07 UTC",
      "updated_date": "2025-10-29 20:53:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:25.782834+00:00"
    },
    {
      "arxiv_id": "2510.25951v1",
      "title": "Estimating cognitive biases with attention-aware inverse planning",
      "title_zh": "åŸºäºæ³¨æ„åŠ›æ„ŸçŸ¥é€†å‘è§„åˆ’çš„è®¤çŸ¥åå·®ä¼°è®¡",
      "authors": [
        "Sounak Banerjee",
        "Daphne Cornelisse",
        "Deepak Gopinath",
        "Emily Sumner",
        "Jonathan DeCastro",
        "Guy Rosman",
        "Eugene Vinitsky",
        "Mark K. Ho"
      ],
      "abstract": "People's goal-directed behaviors are influenced by their cognitive biases, and autonomous systems that interact with people should be aware of this. For example, people's attention to objects in their environment will be biased in a way that systematically affects how they perform everyday tasks such as driving to work. Here, building on recent work in computational cognitive science, we formally articulate the attention-aware inverse planning problem, in which the goal is to estimate a person's attentional biases from their actions. We demonstrate how attention-aware inverse planning systematically differs from standard inverse reinforcement learning and how cognitive biases can be inferred from behavior. Finally, we present an approach to attention-aware inverse planning that combines deep reinforcement learning with computational cognitive modeling. We use this approach to infer the attentional strategies of RL agents in real-life driving scenarios selected from the Waymo Open Dataset, demonstrating the scalability of estimating cognitive biases with attention-aware inverse planning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººç±»ç›®æ ‡å¯¼å‘è¡Œä¸ºå—è®¤çŸ¥åè§å½±å“çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é©¾é©¶ç­‰æ—¥å¸¸ä»»åŠ¡ä¸­æ³¨æ„åŠ›åè§å¯¹è¡Œä¸ºçš„ç³»ç»Ÿæ€§å½±å“ã€‚åœ¨è®¡ç®—è®¤çŸ¥ç§‘å­¦çš„åŸºç¡€ä¸Šï¼Œä½œè€…æ­£å¼é˜è¿°äº†æ³¨æ„åŠ›æ„ŸçŸ¥é€†å‘è§„åˆ’(Attention-aware Inverse Planning)é—®é¢˜ï¼Œæ—¨åœ¨ä»ä¸ªä½“çš„åŠ¨ä½œä¸­ä¼°è®¡å…¶æ³¨æ„åŠ›åè§ã€‚ç ”ç©¶å±•ç¤ºäº†è¯¥æ–¹æ³•ä¸ä¼ ç»Ÿçš„é€†å‘å¼ºåŒ–å­¦ä¹ (Inverse Reinforcement Learning)ä¹‹é—´çš„ç³»ç»Ÿæ€§å·®å¼‚ï¼Œå¹¶è¯¦ç»†è¯´æ˜äº†å¦‚ä½•ä»è¡Œä¸ºä¸­æ¨æ–­è®¤çŸ¥åè§ã€‚ä½œè€…æå‡ºäº†ä¸€ç§ç»“åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning)ä¸è®¡ç®—è®¤çŸ¥å»ºæ¨¡(Computational Cognitive Modeling)çš„æ··åˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•è¢«åº”ç”¨äºæ¨æ–­ Waymo Open Dataset ä¸­çœŸå®é©¾é©¶åœºæ™¯ä¸‹å¼ºåŒ–å­¦ä¹ (RL)æ™ºèƒ½ä½“çš„æ³¨æ„åŠ›ç­–ç•¥ã€‚å®éªŒç»“æœè¯æ˜äº†åˆ©ç”¨æ³¨æ„åŠ›æ„ŸçŸ¥é€†å‘è§„åˆ’ä¼°è®¡è®¤çŸ¥åè§çš„å¯æ‰©å±•æ€§ï¼Œä¸ºå¼€å‘èƒ½å¤Ÿç†è§£äººç±»è®¤çŸ¥åè§çš„è‡ªä¸»ç³»ç»Ÿå¥ å®šäº†ç†è®ºä¸å®è¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25951v1",
      "published_date": "2025-10-29 20:50:04 UTC",
      "updated_date": "2025-10-29 20:50:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:27.169968+00:00"
    },
    {
      "arxiv_id": "2511.00085v1",
      "title": "MaGNet: A Mamba Dual-Hypergraph Network for Stock Prediction via Temporal-Causal and Global Relational Learning",
      "title_zh": "MaGNetï¼šèåˆæ—¶åºå› æœä¸å…¨å±€å…³ç³»å­¦ä¹ çš„ Mamba åŒè¶…å›¾è‚¡ç¥¨é¢„æµ‹ç½‘ç»œ",
      "authors": [
        "Peilin Tan",
        "Chuanqi Shi",
        "Dian Tu",
        "Liang Xie"
      ],
      "abstract": "Stock trend prediction is crucial for profitable trading strategies and portfolio management yet remains challenging due to market volatility, complex temporal dynamics and multifaceted inter-stock relationships. Existing methods struggle to effectively capture temporal dependencies and dynamic inter-stock interactions, often neglecting cross-sectional market influences, relying on static correlations, employing uniform treatments of nodes and edges, and conflating diverse relationships. This work introduces MaGNet, a novel Mamba dual-hyperGraph Network for stock prediction, integrating three key innovations: (1) a MAGE block, which leverages bidirectional Mamba with adaptive gating mechanisms for contextual temporal modeling and integrates a sparse Mixture-of-Experts layer to enable dynamic adaptation to diverse market conditions, alongside multi-head attention for capturing global dependencies; (2) Feature-wise and Stock-wise 2D Spatiotemporal Attention modules enable precise fusion of multivariate features and cross-stock dependencies, effectively enhancing informativeness while preserving intrinsic data structures, bridging temporal modeling with relational reasoning; and (3) a dual hypergraph framework consisting of the Temporal-Causal Hypergraph (TCH) that captures fine-grained causal dependencies with temporal constraints, and Global Probabilistic Hypergraph (GPH) that models market-wide patterns through soft hyperedge assignments and Jensen-Shannon Divergence weighting mechanism, jointly disentangling localized temporal influences from instantaneous global structures for multi-scale relational learning. Extensive experiments on six major stock indices demonstrate MaGNet outperforms state-of-the-art methods in both superior predictive performance and exceptional investment returns with robust risk management capabilities. Codes available at: https://github.com/PeilinTime/MaGNet.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MaGNetï¼Œä¸€ç§ç»“åˆMambaä¸åŒè¶…å›¾ç½‘ç»œ(Dual-Hypergraph Network)çš„è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å¸‚åœºæ³¢åŠ¨åŠå¤æ‚è‚¡ç¥¨é—´å…³ç³»çš„å»ºæ¨¡éš¾é¢˜ã€‚è¯¥æ¨¡å‹é›†æˆäº†MAGEæ¨¡å—ï¼Œåˆ©ç”¨åŒå‘Mambaå’Œç¨€ç–ä¸“å®¶æ··åˆ(Mixture-of-Experts)å±‚å®ç°è‡ªé€‚åº”ä¸Šä¸‹æ–‡æ—¶åºå»ºæ¨¡ï¼Œå¹¶é…åˆäºŒç»´æ—¶ç©ºæ³¨æ„åŠ›(2D Spatiotemporal Attention)æ¨¡å—ç²¾å‡†èåˆå¤šå˜é‡ç‰¹å¾ã€‚æ­¤å¤–ï¼ŒMaGNetæ„å»ºäº†ç”±æ—¶åºå› æœè¶…å›¾(TCH)å’Œå…¨å±€æ¦‚ç‡è¶…å›¾(GPH)ç»„æˆçš„åŒè¶…å›¾æ¡†æ¶ï¼Œæœ‰æ•ˆè§£è€¦äº†å±€éƒ¨æ—¶åºå½±å“ä¸å…¨å±€å¸‚åœºæ¨¡å¼ã€‚åœ¨å…­å¤§ä¸»æµè‚¡ç¥¨æŒ‡æ•°ä¸Šçš„å®éªŒè¯æ˜ï¼ŒMaGNetåœ¨é¢„æµ‹æ€§èƒ½å’ŒæŠ•èµ„å›æŠ¥ç‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„SOTAæ–¹æ³•ï¼Œå±•ç°å‡ºå“è¶Šçš„é£é™©ç®¡ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.00085v1",
      "published_date": "2025-10-29 20:47:16 UTC",
      "updated_date": "2025-10-29 20:47:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:48.577929+00:00"
    },
    {
      "arxiv_id": "2510.25947v1",
      "title": "Revisiting Multilingual Data Mixtures in Language Model Pretraining",
      "title_zh": "é‡æ–°å®¡è§†è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒä¸­çš„å¤šè¯­è¨€æ•°æ®é…æ¯”",
      "authors": [
        "Negar Foroutan",
        "Paul Teiletche",
        "Ayush Kumar Tarun",
        "Antoine Bosselut"
      ],
      "abstract": "The impact of different multilingual data mixtures in pretraining large language models (LLMs) has been a topic of ongoing debate, often raising concerns about potential trade-offs between language coverage and model performance (i.e., the curse of multilinguality). In this work, we investigate these assumptions by training 1.1B and 3B parameter LLMs on diverse multilingual corpora, varying the number of languages from 25 to 400. Our study challenges common beliefs surrounding multilingual training. First, we find that combining English and multilingual data does not necessarily degrade the in-language performance of either group, provided that languages have a sufficient number of tokens included in the pretraining corpus. Second, we observe that using English as a pivot language (i.e., a high-resource language that serves as a catalyst for multilingual generalization) yields benefits across language families, and contrary to expectations, selecting a pivot language from within a specific family does not consistently improve performance for languages within that family. Lastly, we do not observe a significant \"curse of multilinguality\" as the number of training languages increases in models at this scale. Our findings suggest that multilingual data, when balanced appropriately, can enhance language model capabilities without compromising performance, even in low-resource settings",
      "tldr_zh": "è¯¥ç ”ç©¶é‡æ–°æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)é¢„è®­ç»ƒä¸­å¤šè¯­è¨€æ•°æ®æ··åˆ(Multilingual Data Mixtures)çš„å½±å“ï¼Œé€šè¿‡è®­ç»ƒ1.1Bå’Œ3Bå‚æ•°è§„æ¨¡çš„æ¨¡å‹å¹¶æ¶µç›–25è‡³400ç§è¯­è¨€ï¼Œå¯¹ä¼ ç»Ÿçš„â€œå¤šè¯­è¨€è¯…å’’â€(curse of multilinguality)æå‡ºäº†è´¨ç–‘ã€‚ç ”ç©¶å‘ç°ï¼Œåªè¦é¢„æ–™åº“ä¸­åŒ…å«è¶³å¤Ÿæ•°é‡çš„Tokenï¼Œå°†è‹±è¯­ä¸å¤šè¯­è¨€æ•°æ®ç»“åˆå¹¶ä¸ä¼šæŸå®³å„è¯­è¨€çš„æ—¢æœ‰æ€§èƒ½ã€‚å®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼Œå°†è‹±è¯­ä½œä¸ºæ¢çº½è¯­è¨€(Pivot Language)æœ‰åˆ©äºè·¨è¯­è¨€å®¶æ—çš„æ³›åŒ–ï¼Œè€Œä»ç‰¹å®šè¯­ç³»å†…éƒ¨é€‰æ‹©æ¢çº½è¯­è¨€å¹¶ä¸ä¸€å®šä¼šæå‡è¯¥è¯­ç³»çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œåœ¨å½“å‰æ¨¡å‹è§„æ¨¡ä¸‹ï¼Œå¢åŠ è®­ç»ƒè¯­è¨€çš„æ•°é‡å¹¶æœªå¯¼è‡´æ˜¾è‘—çš„æ€§èƒ½é€€åŒ–ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œé€šè¿‡åˆç†å¹³è¡¡å¤šè¯­è¨€æ•°æ®ï¼Œå¯ä»¥åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å¢å¼ºæ¨¡å‹åœ¨ä½èµ„æºç¯å¢ƒä¸‹çš„å¤šè¯­è¨€å¤„ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2510.25947v1",
      "published_date": "2025-10-29 20:46:03 UTC",
      "updated_date": "2025-10-29 20:46:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:32.870808+00:00"
    },
    {
      "arxiv_id": "2511.00084v1",
      "title": "Application of predictive machine learning in pen & paper RPG game design",
      "title_zh": "é¢„æµ‹æ€§æœºå™¨å­¦ä¹ åœ¨çº¸ç¬”è§’è‰²æ‰®æ¼”æ¸¸æˆè®¾è®¡ä¸­çš„åº”ç”¨",
      "authors": [
        "Jolanta Åšliwa"
      ],
      "abstract": "In recent years, the pen and paper RPG market has experienced significant growth. As a result, companies are increasingly exploring the integration of AI technologies to enhance player experience and gain a competitive edge.\n  One of the key challenges faced by publishers is designing new opponents and estimating their challenge level. Currently, there are no automated methods for determining a monster's level; the only approaches used are based on manual testing and expert evaluation. Although these manual methods can provide reasonably accurate estimates, they are time-consuming and resource-intensive.\n  Level prediction can be approached using ordinal regression techniques. This thesis presents an overview and evaluation of state-of-the-art methods for this task. It also details the construction of a dedicated dataset for level estimation. Furthermore, a human-inspired model was developed to serve as a benchmark, allowing comparison between machine learning algorithms and the approach typically employed by pen and paper RPG publishers. In addition, a specialized evaluation procedure, grounded in domain knowledge, was designed to assess model performance and facilitate meaningful comparisons.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœºå™¨å­¦ä¹ (Machine Learning)åœ¨çº¸ç¬”è§’è‰²æ‰®æ¼”æ¸¸æˆ(Pen & Paper RPG)è®¾è®¡ä¸­çš„åº”ç”¨ï¼Œé‡ç‚¹è§£å†³å¯¹æ‰‹ç­‰çº§(Level)é¢„æµ‹ä¸­é•¿æœŸä¾èµ–æ‰‹åŠ¨æµ‹è¯•ä¸ä¸“å®¶è¯„ä¼°å¯¼è‡´çš„æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚è®ºæ–‡è¯¦ç»†è¯„ä¼°äº†åºæ•°å›å½’(Ordinal Regression)ç­‰å‰æ²¿æŠ€æœ¯åœ¨ç­‰çº§ä¼°ç®—ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶ä¸ºæ­¤æ„å»ºäº†ä¸“é—¨çš„ç­‰çº§ä¼°ç®—æ•°æ®é›†ã€‚ä¸ºè¡¡é‡æ¨¡å‹æ€§èƒ½ï¼Œç ”ç©¶è€…å¼€å‘äº†ä¸€ä¸ªå—äººç±»å¯å‘(Human-inspired)çš„åŸºå‡†æ¨¡å‹ï¼Œç”¨ä»¥æ¨¡æ‹Ÿå‡ºç‰ˆå•†çš„ä¼ ç»Ÿè¯„ä¼°æµç¨‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è®¾è®¡äº†ä¸€å¥—åŸºäºé¢†åŸŸçŸ¥è¯†çš„ä¸“ç”¨è¯„ä¼°ç¨‹åºï¼Œå®ç°äº†æœºå™¨å­¦ä¹ ç®—æ³•ä¸äººå·¥è¯„ä¼°æ–¹æ³•çš„å®¢è§‚å¯¹æ¯”ã€‚è¯¥ç ”ç©¶ä¸ºRPGæ¸¸æˆçš„è‡ªåŠ¨åŒ–å¹³è¡¡è®¾è®¡æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„å’Œè¯„ä¼°æ ‡å‡†ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Master's thesis submitted at AGH University of Science and Technology",
      "pdf_url": "https://arxiv.org/pdf/2511.00084v1",
      "published_date": "2025-10-29 20:43:58 UTC",
      "updated_date": "2025-10-29 20:43:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:36.076848+00:00"
    },
    {
      "arxiv_id": "2511.00083v1",
      "title": "Fixed-point graph convolutional networks against adversarial attacks",
      "title_zh": "æŠµå¾¡å¯¹æŠ—æ”»å‡»çš„ä¸åŠ¨ç‚¹å›¾å·ç§¯ç½‘ç»œ",
      "authors": [
        "Shakib Khan",
        "A. Ben Hamza",
        "Amr Youssef"
      ],
      "abstract": "Adversarial attacks present a significant risk to the integrity and performance of graph neural networks, particularly in tasks where graph structure and node features are vulnerable to manipulation. In this paper, we present a novel model, called fixed-point iterative graph convolutional network (Fix-GCN), which achieves robustness against adversarial perturbations by effectively capturing higher-order node neighborhood information in the graph without additional memory or computational complexity. Specifically, we introduce a versatile spectral modulation filter and derive the feature propagation rule of our model using fixed-point iteration. Unlike traditional defense mechanisms that rely on additional design elements to counteract attacks, the proposed graph filter provides a flexible-pass filtering approach, allowing it to selectively attenuate high-frequency components while preserving low-frequency structural information in the graph signal. By iteratively updating node representations, our model offers a flexible and efficient framework for preserving essential graph information while mitigating the impact of adversarial manipulation. We demonstrate the effectiveness of the proposed model through extensive experiments on various benchmark graph datasets, showcasing its resilience against adversarial attacks.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹å›¾ç¥ç»ç½‘ç»œ(GNNs)åœ¨å›¾ç»“æ„å’ŒèŠ‚ç‚¹ç‰¹å¾é¢ä¸´å¯¹æŠ—æ€§æ”»å‡»(adversarial attacks)çš„é£é™©ï¼Œæå‡ºäº†å®šç‚¹è¿­ä»£å›¾å·ç§¯ç½‘ç»œ(Fix-GCN)ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚è¯¥æ¨¡å‹é€šè¿‡å¼•å…¥å¤šåŠŸèƒ½é¢‘è°±è°ƒåˆ¶æ»¤æ³¢å™¨(spectral modulation filter)ï¼Œå¹¶åˆ©ç”¨å®šç‚¹è¿­ä»£(fixed-point iteration)æ¨å¯¼ç‰¹å¾ä¼ æ’­è§„åˆ™ï¼Œåœ¨ä¸å¢åŠ å†…å­˜æˆ–è®¡ç®—å¤æ‚åº¦çš„å‰æä¸‹æ•æ‰æ›´é«˜é˜¶çš„é‚»åŸŸä¿¡æ¯ã€‚Fix-GCNé‡‡ç”¨çµæ´»é€šå¸¦æ»¤æ³¢æ–¹æ³•ï¼Œèƒ½å¤Ÿé€‰æ‹©æ€§åœ°è¡°å‡å¯¹æŠ—æ€§æ”»å‡»äº§ç”Ÿçš„é«˜é¢‘æˆåˆ†ï¼ŒåŒæ—¶ä¿ç•™å›¾ä¿¡å·ä¸­çš„ä½é¢‘ç»“æ„ä¿¡æ¯ã€‚é€šè¿‡è¿­ä»£æ›´æ–°èŠ‚ç‚¹è¡¨ç¤ºï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆåœ°å‡è½»äº†å¯¹æŠ—æ€§æ“çºµçš„å½±å“å¹¶ä¿ç•™äº†æ ¸å¿ƒå›¾ç‰¹å¾ã€‚åœ¨å¤šä¸ªåŸºå‡†å›¾æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒFix-GCNåœ¨åº”å¯¹å„ç§å¯¹æŠ—æ”»å‡»æ—¶å…·æœ‰æ˜¾è‘—çš„æŠµå¾¡èƒ½åŠ›å’Œæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.00083v1",
      "published_date": "2025-10-29 20:17:37 UTC",
      "updated_date": "2025-10-29 20:17:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:39.860745+00:00"
    },
    {
      "arxiv_id": "2510.25935v2",
      "title": "A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows",
      "title_zh": "åŸºäºæµç¨‹æŒ–æ˜çš„è½¯ä»¶å¼€å‘å·¥ä½œæµåˆ†æä¸é¢„æµ‹ç³»ç»Ÿ",
      "authors": [
        "AntÃ­a Dorado",
        "IvÃ¡n Folgueira",
        "SofÃ­a MartÃ­n",
        "Gonzalo MartÃ­n",
        "Ãlvaro Porto",
        "Alejandro Ramos",
        "John Wallace"
      ],
      "abstract": "CodeSight is an end-to-end system designed to anticipate deadline compliance in software development workflows. It captures development and deployment data directly from GitHub, transforming it into process mining logs for detailed analysis. From these logs, the system generates metrics and dashboards that provide actionable insights into PR activity patterns and workflow efficiency. Building on this structured representation, CodeSight employs an LSTM model that predicts remaining PR resolution times based on sequential activity traces and static features, enabling early identification of potential deadline breaches. In tests, the system demonstrates high precision and F1 scores in predicting deadline compliance, illustrating the value of integrating process mining with machine learning for proactive software project management.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†åä¸º CodeSight çš„ç«¯åˆ°ç«¯ç³»ç»Ÿï¼Œæ—¨åœ¨é¢„æµ‹è½¯ä»¶å¼€å‘å·¥ä½œæµä¸­çš„æˆªæ­¢æ—¥æœŸåˆè§„æ€§(deadline compliance)ã€‚è¯¥ç³»ç»Ÿç›´æ¥ä» GitHub è·å–å¼€å‘å’Œéƒ¨ç½²æ•°æ®ï¼Œå¹¶å°†è¿™äº›æ•°æ®è½¬åŒ–ä¸ºæµç¨‹æŒ–æ˜(process mining)æ—¥å¿—ï¼Œä»¥ä¾¿è¿›è¡Œè¯¦ç»†çš„é‡åŒ–åˆ†æã€‚é€šè¿‡åˆ†æç”Ÿæˆçš„æŒ‡æ ‡å’Œä»ªè¡¨æ¿ï¼ŒCodeSight ä¸º PR æ´»åŠ¨æ¨¡å¼å’Œå·¥ä½œæµæ•ˆç‡æä¾›äº†æå…·å‚è€ƒä»·å€¼çš„æ´å¯Ÿã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç³»ç»Ÿé‡‡ç”¨ LSTM æ¨¡å‹ï¼Œç»“åˆé¡ºåºæ´»åŠ¨è½¨è¿¹å’Œé™æ€ç‰¹å¾æ¥é¢„æµ‹ PR çš„å‰©ä½™å¤„ç†æ—¶é—´ï¼Œä»è€Œå®ç°å¯¹è¿›åº¦è¿è§„é£é™©çš„æ—©æœŸè¯†åˆ«ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨é¢„æµ‹æˆªæ­¢æ—¥æœŸåˆè§„æ€§æ–¹é¢è¡¨ç°å‡ºæé«˜çš„ç²¾ç¡®åº¦(Precision)å’Œ F1 åˆ†æ•°ã€‚è¯¥é¡¹å·¥ä½œå……åˆ†è¯æ˜äº†å°†æµç¨‹æŒ–æ˜ä¸æœºå™¨å­¦ä¹ (Machine Learning)ç›¸ç»“åˆåœ¨æå‡ä¸»åŠ¨å¼è½¯ä»¶é¡¹ç›®ç®¡ç†æ•ˆç‡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "16 pages, 7 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.25935v2",
      "published_date": "2025-10-29 20:13:46 UTC",
      "updated_date": "2025-10-31 17:31:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:20:59.256294+00:00"
    },
    {
      "arxiv_id": "2510.25933v1",
      "title": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning",
      "title_zh": "Humains-Juniorï¼šåŸºäºå®šå‘å¤–éª¨éª¼æ¨ç†å®ç° GPT-4o çº§åˆ«äº‹å®å‡†ç¡®ç‡çš„ 3.8B è¯­è¨€æ¨¡å‹",
      "authors": [
        "Nissan Yaron",
        "Dan Bystritsky",
        "Ben-Etzion Yaron"
      ],
      "abstract": "We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS Grounding public subset within a $\\pm 5$ pp equivalence margin.\n  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI 69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference is 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's $d = 0.023$). TOST establishes equivalence at $\\pm 5$ pp (not at $\\pm 3$ pp). When purchased as managed APIs, Humans-Junior's base model (Phi-3.5-mini-instruct) is $\\approx 19\\times$ less expensive than GPT-4o on Microsoft AI Foundry pricing; self-hosted or edge deployments can drive incremental inference cost toward zero. Measured vs estimated pricing sources are tabulated in Appendix E.\n  Method. Our approach combines minimal directed \"Exoskeleton Reasoning\" scaffolds with behavioral fine-tuning that teaches protocol compliance (epistemic discipline) rather than domain answers. Fine-tuning alone adds little; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance ($\\approx 25\\%$). In prompt-only settings on frontier models (Q1--Q100; non-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and Gemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.\n  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within $\\pm 5$ pp on Q1--Q500). Cloud pricing shows $\\approx 19\\times$ lower cost versus GPT-4o, and self-hosted/edge deployments can approach zero marginal cost. Pricing sources are listed in Appendix E. Frontier prompt-only gains (Q1--Q100; non-comparable) and optimized-prompt exploratory results under earlier judges are summarized in Appendix F.\n  Keywords: Small Language Models, Factual Grounding, Directed Reasoning, Fine-Tuning, Model Alignment, Cost-Efficient AI",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Humains-Juniorï¼Œè¿™æ˜¯ä¸€ä¸ªå‚æ•°é‡ä»…ä¸º 3.8B çš„è½»é‡çº§è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨äº‹å®å‡†ç¡®æ€§ä»»åŠ¡ä¸­è¾¾åˆ°é¡¶çº§æ¨¡å‹çš„æ°´å¹³ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ FACTS Grounding å…¬å…±å­é›†çš„æµ‹è¯•ä¸­ï¼ŒHumains-Junior è·å¾—äº† 72.7% çš„å‡†ç¡®ç‡ï¼Œä¸ GPT-4o åœ¨ $\\pm 5$ pp çš„èŒƒå›´å†…å®ç°äº†ç­‰æ•ˆæ€§èƒ½ã€‚å…¶æ ¸å¿ƒæ–¹æ³•ç»“åˆäº†å®šå‘â€œå¤–éª¨éª¼æ¨ç†â€ï¼ˆDirected Exoskeleton Reasoningï¼‰æ”¯æ¶ä¸è¡Œä¸ºå¾®è°ƒï¼ˆBehavioral Fine-tuningï¼‰ï¼Œé‡ç‚¹æ•™æˆæ¨¡å‹éµå¾ªè®¤è¯†è®ºçºªå¾‹ï¼ˆEpistemic Disciplineï¼‰è€Œéè®°å¿†å…·ä½“ç­”æ¡ˆã€‚ç ”ç©¶å‘ç°æ¨ç†æ”¯æ¶ä¸å¾®è°ƒä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„ååŒæ•ˆåº”ï¼Œèƒ½ä½¿æ€§èƒ½æå‡ 17.7 ä¸ªç™¾åˆ†ç‚¹å¹¶é™ä½çº¦ 25% çš„æ–¹å·®ã€‚åœ¨æˆæœ¬æ•ˆç›Šæ–¹é¢ï¼ŒHumains-Junior æ¯” GPT-4o çš„æ‰˜ç®¡ API ä¾¿å®œçº¦ 19 å€ï¼Œä¸”æ”¯æŒåœ¨è¾¹ç¼˜ä¾§éƒ¨ç½²ä»¥å°†è¾¹é™…æ¨ç†æˆæœ¬é™è‡³è¶‹è¿‘äºé›¶ã€‚æ­¤å¤–ï¼Œå®šå‘æ¨ç†æ–¹æ³•åœ¨ GPT-4o å’Œ Gemini-2.5-Pro ç­‰å‰æ²¿æ¨¡å‹ä¸Šä¹Ÿåˆ†åˆ«å¸¦æ¥äº†æ˜¾è‘—çš„å‡†ç¡®ç‡æå‡ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘é«˜æ•ˆä¸”å…·å¤‡é«˜äº‹å®å‡†ç¡®æ€§çš„è½»é‡çº§è¯­è¨€æ¨¡å‹ï¼ˆSmall Language Modelsï¼‰æä¾›äº†é‡è¦çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25933v1",
      "published_date": "2025-10-29 20:12:36 UTC",
      "updated_date": "2025-10-29 20:12:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:06.079721+00:00"
    },
    {
      "arxiv_id": "2510.25929v1",
      "title": "Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion",
      "title_zh": "é¢å‘åšå¸‚çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼šéåˆè°‹æ€§ç«äº‰",
      "authors": [
        "Ziyi Wang",
        "Carmine Ventre",
        "Maria Polukarov"
      ],
      "abstract": "Algorithmic collusion has emerged as a central question in AI: Will the interaction between different AI agents deployed in markets lead to collusion? More generally, understanding how emergent behavior, be it a cartel or market dominance from more advanced bots, affects the market overall is an important research question.\n  We propose a hierarchical multi-agent reinforcement learning framework to study algorithmic collusion in market making. The framework includes a self-interested market maker (Agent~A), which is trained in an uncertain environment shaped by an adversary, and three bottom-layer competitors: the self-interested Agent~B1 (whose objective is to maximize its own PnL), the competitive Agent~B2 (whose objective is to minimize the PnL of its opponent), and the hybrid Agent~B$^\\star$, which can modulate between the behavior of the other two. To analyze how these agents shape the behavior of each other and affect market outcomes, we propose interaction-level metrics that quantify behavioral asymmetry and system-level dynamics, while providing signals potentially indicative of emergent interaction patterns.\n  Experimental results show that Agent~B2 secures dominant performance in a zero-sum setting against B1, aggressively capturing order flow while tightening average spreads, thus improving market execution efficiency. In contrast, Agent~B$^\\star$ exhibits a self-interested inclination when co-existing with other profit-seeking agents, securing dominant market share through adaptive quoting, yet exerting a milder adverse impact on the rewards of Agents~A and B1 compared to B2. These findings suggest that adaptive incentive control supports more sustainable strategic co-existence in heterogeneous agent environments and offers a structured lens for evaluating behavioral design in algorithmic trading systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¸‚åœºåšå¸‚(Market Making)ä¸­äººå·¥æ™ºèƒ½ä»£ç†ä¹‹é—´çš„ç®—æ³•åˆè°‹(Algorithmic Collusion)é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§å±‚æ¬¡åŒ–å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (Hierarchical Multi-Agent Reinforcement Learning)æ¡†æ¶æ¥æ¨¡æ‹Ÿå’Œåˆ†æå¤æ‚çš„ç«äº‰åŠ¨æ€ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸€ä¸ªè‡ªåˆ©å‹åšå¸‚å•†Agent Aï¼Œä»¥åŠä¸‰ç§å…·æœ‰ä¸åŒç›®æ ‡çš„ç«äº‰å¯¹æ‰‹ï¼šè¿½æ±‚è‡ªèº«æŸç›Š(PnL)æœ€å¤§åŒ–çš„Agent B1ã€æ—¨åœ¨æœ€å°åŒ–å¯¹æ‰‹æŸç›Šçš„ç«äº‰å‹Agent B2ï¼Œä»¥åŠå¯åœ¨ä¸¤è€…è¡Œä¸ºé—´çµæ´»è°ƒèŠ‚çš„æ··åˆå‹Agent B*ã€‚ç ”ç©¶é€šè¿‡å¼•å…¥äº¤äº’å±‚çº§æŒ‡æ ‡é‡åŒ–äº†è¡Œä¸ºä¸å¯¹ç§°æ€§ä¸ç³»ç»ŸåŠ¨åŠ›å­¦ï¼Œå®éªŒç»“æœæ˜¾ç¤ºAgent B2åœ¨é›¶å’Œåšå¼ˆä¸­é€šè¿‡ç§¯ææ•è·è®¢å•æµå¹¶æ”¶çª„å¹³å‡ä»·å·®(Spreads)ï¼Œæ˜¾è‘—æå‡äº†å¸‚åœºæ‰§è¡Œæ•ˆç‡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒAgent B*åœ¨ä¸å…¶ä»–è·åˆ©ä»£ç†å…±å­˜æ—¶è¡¨ç°å‡ºå€¾å‘äºè‡ªåˆ©çš„ç‰¹æ€§ï¼Œé€šè¿‡è‡ªé€‚åº”æŠ¥ä»·è·å–ä¸»å¯¼å¸‚åœºä»½é¢ï¼Œä¸”å¯¹å…¶ä»–ä»£ç†å¥–åŠ±çš„è´Ÿé¢å½±å“æ¯”Agent B2æ›´æ¸©å’Œã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œè‡ªé€‚åº”æ¿€åŠ±æ§åˆ¶(Adaptive Incentive Control)æ”¯æŒå¼‚æ„æ™ºèƒ½ä½“ç¯å¢ƒä¸‹çš„å¯æŒç»­ç­–ç•¥å…±å­˜ï¼Œä¸ºè¯„ä¼°ç®—æ³•äº¤æ˜“ç³»ç»Ÿçš„è¡Œä¸ºè®¾è®¡æä¾›äº†ç»“æ„åŒ–çš„åˆ†æè§†è§’ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25929v1",
      "published_date": "2025-10-29 20:07:47 UTC",
      "updated_date": "2025-10-29 20:07:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:07.752774+00:00"
    },
    {
      "arxiv_id": "2510.26835v1",
      "title": "Category-Aware Semantic Caching for Heterogeneous LLM Workloads",
      "title_zh": "é¢å‘å¼‚æ„ LLM å·¥ä½œè´Ÿè½½çš„ç±»åˆ«æ„ŸçŸ¥è¯­ä¹‰ç¼“å­˜",
      "authors": [
        "Chen Wang",
        "Xunzhuo Liu",
        "Yue Zhu",
        "Alaa Youssef",
        "Priya Nagpurkar",
        "Huamin Chen"
      ],
      "abstract": "LLM serving systems process heterogeneous query workloads where different categories exhibit different characteristics. Code queries cluster densely in embedding space while conversational queries distribute sparsely. Content staleness varies from minutes (stock data) to months (code patterns). Query repetition patterns range from power-law (code) to uniform (conversation), producing long tail cache hit rate distributions: high-repetition categories achieve 40-60% hit rates while low-repetition or volatile categories achieve 5-15% hit rates. Vector databases must exclude the long tail because remote search costs (30ms) require 15--20% hit rates to break even, leaving 20-30% of production traffic uncached. Uniform cache policies compound this problem: fixed thresholds cause false positives in dense spaces and miss valid paraphrases in sparse spaces; fixed TTLs waste memory or serve stale data. This paper presents category-aware semantic caching where similarity thresholds, TTLs, and quotas vary by query category. We present a hybrid architecture separating in-memory HNSW search from external document storage, reducing miss cost from 30ms to 2ms. This reduction makes low-hit-rate categories economically viable (break-even at 3-5% versus 15-20%), enabling cache coverage across the entire workload distribution. Adaptive load-based policies extend this framework to respond to downstream model load, dynamically adjusting thresholds and TTLs to reduce traffic to overloaded models by 9-17% in theoretical projections.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†Category-Aware Semantic Cachingï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLM)æ¨ç†ç³»ç»Ÿä¸­å¼‚æ„æŸ¥è¯¢è´Ÿè½½å¸¦æ¥çš„æŒ‘æˆ˜ã€‚ç ”ç©¶å‘ç°ä¸åŒæŸ¥è¯¢ç±»åˆ«åœ¨åµŒå…¥ç©ºé—´å¯†åº¦ã€å†…å®¹é™ˆæ—§åº¦å’Œé‡å¤æ¨¡å¼ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå¯¼è‡´ä¼ ç»Ÿç»Ÿä¸€ç¼“å­˜ç­–ç•¥åœ¨å‘½ä¸­ç‡å’Œç»æµå¯è¡Œæ€§ä¸Šè¡¨ç°ä¸ä½³ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡ä¸ºä¸åŒç±»åˆ«åŠ¨æ€è°ƒæ•´ç›¸ä¼¼æ€§é˜ˆå€¼(Similarity Thresholds)ã€ç”Ÿå­˜æ—¶é—´(TTL)å’Œé…é¢(Quotas)ï¼Œå¹¶é‡‡ç”¨åˆ†ç¦»HNSWæœç´¢ä¸å¤–éƒ¨å­˜å‚¨çš„æ··åˆæ¶æ„ï¼Œå°†æœªå‘½ä¸­æˆæœ¬ä»30mså¤§å¹…é™è‡³2msã€‚è¿™ä¸€æ”¹è¿›ä½¿ä½å‘½ä¸­ç‡ç±»åˆ«çš„ç¼“å­˜å˜å¾—ç»æµå¯è¡Œï¼Œå®ç°äº†å¯¹æ•´ä¸ªå·¥ä½œè´Ÿè½½åˆ†å¸ƒçš„å…¨é¢è¦†ç›–ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†åŸºäºè´Ÿè½½çš„è‡ªé€‚åº”ç­–ç•¥ï¼Œèƒ½æ ¹æ®ä¸‹æ¸¸æ¨¡å‹çŠ¶æ€åŠ¨æ€è°ƒæ•´å‚æ•°ï¼Œåœ¨ç†è®ºé¢„æµ‹ä¸­æˆåŠŸå°†è¿‡è½½æ¨¡å‹çš„æµé‡é™ä½äº†9-17%ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "13 pages including reference, position paper",
      "pdf_url": "https://arxiv.org/pdf/2510.26835v1",
      "published_date": "2025-10-29 19:59:45 UTC",
      "updated_date": "2025-10-29 19:59:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:11.188867+00:00"
    },
    {
      "arxiv_id": "2510.25924v2",
      "title": "Transferring Causal Effects using Proxies",
      "title_zh": "åŸºäºä»£ç†å˜é‡çš„å› æœæ•ˆåº”è¿ç§»",
      "authors": [
        "Manuel Iglesias-Alonso",
        "Felix Schur",
        "Julius von KÃ¼gelgen",
        "Jonas Peters"
      ],
      "abstract": "We consider the problem of estimating a causal effect in a multi-domain setting. The causal effect of interest is confounded by an unobserved confounder and can change between the different domains. We assume that we have access to a proxy of the hidden confounder and that all variables are discrete or categorical. We propose methodology to estimate the causal effect in the target domain, where we assume to observe only the proxy variable. Under these conditions, we prove identifiability (even when treatment and response variables are continuous). We introduce two estimation techniques, prove consistency, and derive confidence intervals. The theoretical results are supported by simulation studies and a real-world example studying the causal effect of website rankings on consumer choices.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤šåŸŸ(multi-domain)è®¾ç½®ä¸‹ä¼°è®¡å› æœæ•ˆåº”(causal effect)çš„é—®é¢˜ï¼Œé‡ç‚¹è§£å†³äº†å­˜åœ¨ä¸å¯è§‚æµ‹æ··æ‚å› ç´ (unobserved confounder)ä¸”è¯¥å› ç´ åœ¨ä¸åŒé¢†åŸŸé—´å‘ç”Ÿå˜åŒ–çš„æŒ‘æˆ˜ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨éšè—æ··æ‚å› ç´ çš„ä»£ç†å˜é‡(proxy variable)åœ¨ç›®æ ‡é¢†åŸŸä¼°è®¡å› æœæ•ˆåº”çš„æ–¹æ³•è®ºï¼Œä¸”åœ¨ç›®æ ‡é¢†åŸŸä»…éœ€è§‚æµ‹åˆ°ä»£ç†å˜é‡ã€‚ä½œè€…åœ¨ç†è®ºä¸Šè¯æ˜äº†è¯¥æ¨¡å‹çš„å¯è¯†åˆ«æ€§(identifiability)ï¼Œå¹¶æŒ‡å‡ºè¿™ç§å¯è¯†åˆ«æ€§åœ¨å¹²é¢„(treatment)å’Œå“åº”(response)å˜é‡ä¸ºè¿ç»­å€¼æ—¶ä¾ç„¶æˆç«‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ä¸¤ç§ä¼°è®¡æŠ€æœ¯(estimation techniques)ï¼Œè¯æ˜äº†å…¶ä¸€è‡´æ€§(consistency)å¹¶æ¨å¯¼äº†ç›¸åº”çš„ç½®ä¿¡åŒºé—´(confidence intervals)ã€‚æœ€åï¼Œé€šè¿‡æ¨¡æ‹Ÿç ”ç©¶å’Œå…³äºç½‘ç«™æ’åå¯¹æ¶ˆè´¹è€…é€‰æ‹©å½±å“çš„çœŸå®æ¡ˆä¾‹ï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•åœ¨å¤„ç†å¤æ‚å› æœè½¬ç§»é—®é¢˜ä¸Šçš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Advances in Neural Information Processing Systems (NeurIPS 2025) final camera-ready version",
      "pdf_url": "https://arxiv.org/pdf/2510.25924v2",
      "published_date": "2025-10-29 19:53:51 UTC",
      "updated_date": "2025-12-27 17:51:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:12.248127+00:00"
    },
    {
      "arxiv_id": "2510.25914v1",
      "title": "FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization",
      "title_zh": "FinOps æ™ºèƒ½ä½“ï¼šIT åŸºç¡€è®¾æ–½ä¸æˆæœ¬ä¼˜åŒ–çš„åº”ç”¨æ¡ˆä¾‹",
      "authors": [
        "Ngoc Phuoc An Vo",
        "Manish Kesarwani",
        "Ruchi Mahindru",
        "Chandrasekhar Narayanaswami"
      ],
      "abstract": "FinOps (Finance + Operations) represents an operational framework and cultural practice which maximizes cloud business value through collaborative financial accountability across engineering, finance, and business teams. FinOps practitioners face a fundamental challenge: billing data arrives in heterogeneous formats, taxonomies, and metrics from multiple cloud providers and internal systems which eventually lead to synthesizing actionable insights, and making time-sensitive decisions. To address this challenge, we propose leveraging autonomous, goal-driven AI agents for FinOps automation. In this paper, we built a FinOps agent for a typical use-case for IT infrastructure and cost optimization. We built a system simulating a realistic end-to-end industry process starting with retrieving data from various sources to consolidating and analyzing the data to generate recommendations for optimization. We defined a set of metrics to evaluate our agent using several open-source and close-source language models and it shows that the agent was able to understand, plan, and execute tasks as well as an actual FinOps practitioner.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ FinOps é¢†åŸŸä¸­äº‘è´¦å•æ•°æ®å¼‚æ„åŒ–ã€éš¾ä»¥å¿«é€Ÿç”Ÿæˆå†³ç­–æ´å¯Ÿçš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œæå‡ºå¹¶æ„å»ºäº†ä¸€ä¸ªç”¨äº IT Infrastructure å’Œæˆæœ¬ä¼˜åŒ–çš„è‡ªä¸»å¼ AI Agentã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ¨¡æ‹Ÿä»å¤šæºæ•°æ®æ£€ç´¢ã€æ•´åˆåˆ†æåˆ°ç”Ÿæˆ Optimization Recommendations çš„å®Œæ•´å·¥ä¸šé—­ç¯ï¼Œå®ç°äº† FinOps æµç¨‹çš„è‡ªåŠ¨åŒ–ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨å¤šç§å¼€æºå’Œé—­æºè¯­è¨€æ¨¡å‹å¯¹è¯¥æ™ºèƒ½ä½“è¿›è¡Œäº†å¤šç»´åº¦è¯„ä¼°ï¼Œå¹¶å®šä¹‰äº†ä¸€å¥—ä¸“é—¨çš„ Metrics æ¥è¡¡é‡å…¶ç†è§£ã€è§„åˆ’ä¸æ‰§è¡Œèƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ FinOps Agent åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶çš„è¡¨ç°å¯åª²ç¾ä¸“ä¸šçš„äººç±»ä»ä¸šè€…ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†åˆ©ç”¨ goal-driven AI agents æå‡äº‘ä¸šåŠ¡ä»·å€¼åŠå®ç°è´¢åŠ¡è´£ä»»è‡ªåŠ¨åŒ–æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25914v1",
      "published_date": "2025-10-29 19:34:14 UTC",
      "updated_date": "2025-10-29 19:34:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:20.769684+00:00"
    },
    {
      "arxiv_id": "2510.25908v1",
      "title": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications",
      "title_zh": "SciTrust 2.0ï¼šé¢å‘ç§‘å­¦åº”ç”¨çš„å¤§è¯­è¨€æ¨¡å‹å¯ä¿¡æ€§è¯„ä¼°ç»¼åˆæ¡†æ¶",
      "authors": [
        "Emily Herron",
        "Junqi Yin",
        "Feiyi Wang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated transformative potential in scientific research, yet their deployment in high-stakes contexts raises significant trustworthiness concerns. Here, we introduce SciTrust 2.0, a comprehensive framework for evaluating LLM trustworthiness in scientific applications across four dimensions: truthfulness, adversarial robustness, scientific safety, and scientific ethics. Our framework incorporates novel, open-ended truthfulness benchmarks developed through a verified reflection-tuning pipeline and expert validation, alongside a novel ethics benchmark for scientific research contexts covering eight subcategories including dual-use research and bias. We evaluated seven prominent LLMs, including four science-specialized models and three general-purpose industry models, using multiple evaluation metrics including accuracy, semantic similarity measures, and LLM-based scoring. General-purpose industry models overall outperformed science-specialized models across each trustworthiness dimension, with GPT-o4-mini demonstrating superior performance in truthfulness assessments and adversarial robustness. Science-specialized models showed significant deficiencies in logical and ethical reasoning capabilities, along with concerning vulnerabilities in safety evaluations, particularly in high-risk domains such as biosecurity and chemical weapons. By open-sourcing our framework, we provide a foundation for developing more trustworthy AI systems and advancing research on model safety and ethics in scientific contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† SciTrust 2.0ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼° Large Language Models (LLMs) åœ¨ç§‘å­¦åº”ç”¨ä¸­å¯ä¿¡åº¦çš„å…¨é¢æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ¶µç›–äº† Truthfulnessã€Adversarial Robustnessã€Scientific Safety å’Œ Scientific Ethics å››ä¸ªå…³é”®ç»´åº¦ï¼Œå¹¶ç»“åˆäº†é€šè¿‡ Reflection-tuning Pipeline å¼€å‘çš„çœŸå®æ€§åŸºå‡†ä»¥åŠæ¶µç›–åŒé‡ç”¨é€”ç ”ç©¶ç­‰å…«ä¸ªå­ç±»åˆ«çš„ä¼¦ç†åŸºå‡†ã€‚ç ”ç©¶é€šè¿‡å¯¹ä¸ƒä¸ªä¸»æµ LLMs çš„è¯„ä¼°å‘ç°ï¼Œé€šç”¨å·¥ä¸šæ¨¡å‹åœ¨å„ç»´åº¦çš„æ•´ä½“è¡¨ç°ä¼˜äºç§‘å­¦ä¸“ç”¨æ¨¡å‹ï¼Œå…¶ä¸­ GPT-o4-mini åœ¨çœŸå®æ€§å’Œå¯¹æŠ—é²æ£’æ€§æ–¹é¢è¡¨ç°æœ€ä¸ºå‡ºè‰²ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç§‘å­¦ä¸“ç”¨æ¨¡å‹åœ¨é€»è¾‘å’Œä¼¦ç†æ¨ç†èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—çŸ­æ¿ï¼Œä¸”åœ¨ç”Ÿç‰©å®‰å…¨ã€åŒ–å­¦æ­¦å™¨ç­‰é«˜é£é™©é¢†åŸŸçš„å®‰å…¨è¯„ä¼°ä¸­æš´éœ²å‡ºä¸¥é‡æ¼æ´ã€‚è¯¥æ¡†æ¶çš„å¼€æºä¸ºå¼€å‘æ›´å…·å¯ä¿¡åº¦çš„ AI ç³»ç»Ÿä»¥åŠæ·±åŒ–ç§‘å­¦èƒŒæ™¯ä¸‹çš„æ¨¡å‹å®‰å…¨ä¸ä¼¦ç†ç ”ç©¶æä¾›äº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint Submitted to ACM Transactions on AI for Science (TAIS)",
      "pdf_url": "https://arxiv.org/pdf/2510.25908v1",
      "published_date": "2025-10-29 19:22:55 UTC",
      "updated_date": "2025-10-29 19:22:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:20.071757+00:00"
    },
    {
      "arxiv_id": "2510.25904v1",
      "title": "Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation",
      "title_zh": "è¯„ä¼°å¤šè§†è§’è®¾ç½®ä¸‹ LLM è¾…åŠ©æ ‡æ³¨çš„å½±å“ï¼šä»¥ FrameNet æ ‡æ³¨ä¸ºä¾‹",
      "authors": [
        "Frederico Belcavello",
        "Ely Matos",
        "Arthur Lorenzi",
        "Lisandra Bonoto",
        "LÃ­via Ruiz",
        "Luiz Fernando Pereira",
        "Victor Herbst",
        "Yulla Navarro",
        "Helen de Andrade Abreu",
        "LÃ­via Dutra",
        "Tiago Timponi Torrent"
      ],
      "abstract": "The use of LLM-based applications as a means to accelerate and/or substitute human labor in the creation of language resources and dataset is a reality. Nonetheless, despite the potential of such tools for linguistic research, comprehensive evaluation of their performance and impact on the creation of annotated datasets, especially under a perspectivized approach to NLP, is still missing. This paper contributes to reduction of this gap by reporting on an extensive evaluation of the (semi-)automatization of FrameNet-like semantic annotation by the use of an LLM-based semantic role labeler. The methodology employed compares annotation time, coverage and diversity in three experimental settings: manual, automatic and semi-automatic annotation. Results show that the hybrid, semi-automatic annotation setting leads to increased frame diversity and similar annotation coverage, when compared to the human-only setting, while the automatic setting performs considerably worse in all metrics, except for annotation time.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åœ¨å¤§è¯­è¨€æ¨¡å‹(LLM)è¾…åŠ©ä¸‹è¿›è¡Œè§†è§’åŒ–(perspectivized)èƒŒæ™¯ä¸‹çš„FrameNetè¯­ä¹‰æ ‡æ³¨çš„å½±å“ï¼Œå¡«è¡¥äº†å½“å‰è§†è§’åŒ–è‡ªç„¶è¯­è¨€å¤„ç†(NLP)é¢†åŸŸå¯¹LLMç”Ÿæˆæ ‡æ³¨æ•°æ®é›†æ€§èƒ½è¯„ä¼°çš„ç©ºç™½ã€‚ç ”ç©¶é€šè¿‡å¯¹æ¯”æ‰‹åŠ¨ã€è‡ªåŠ¨å’ŒåŠè‡ªåŠ¨(semi-automatic)ä¸‰ç§å®éªŒè®¾ç½®ï¼Œè¯¦ç»†è€ƒå¯Ÿäº†è¯­ä¹‰è§’è‰²æ ‡æ³¨å™¨(semantic role labeler)åœ¨æ ‡æ³¨æ—¶é—´ã€è¦†ç›–ç‡(coverage)å’Œå¤šæ ·æ€§(diversity)æ–¹é¢çš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼Œä¸çº¯äººå·¥æ ‡æ³¨ç›¸æ¯”ï¼Œäººæœºåä½œçš„åŠè‡ªåŠ¨æ ‡æ³¨æ¨¡å¼åœ¨ç»´æŒç›¸ä¼¼è¦†ç›–ç‡çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¯­ä¹‰æ¡†æ¶(frame)çš„å¤šæ ·æ€§ã€‚ä¸ä¹‹ç›¸å¯¹ï¼Œçº¯è‡ªåŠ¨æ ‡æ³¨æ¨¡å¼é™¤äº†åœ¨æ ‡æ³¨æ•ˆç‡ä¸Šå ä¼˜å¤–ï¼Œåœ¨å…¶ä»–æ ¸å¿ƒè´¨é‡æŒ‡æ ‡ä¸Šå‡è¡¨ç°ä¸ä½³ã€‚è¯¥é¡¹å·¥ä½œä¸ºå¦‚ä½•é«˜æ•ˆä¸”é«˜è´¨é‡åœ°åˆ©ç”¨LLMæ„å»ºè¯­è¨€èµ„æºæä¾›äº†å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25904v1",
      "published_date": "2025-10-29 19:13:48 UTC",
      "updated_date": "2025-10-29 19:13:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:22.067035+00:00"
    },
    {
      "arxiv_id": "2510.26834v1",
      "title": "Diffusion-Driven Generation of Minimally Preprocessed Brain MRI",
      "title_zh": "æ‰©æ•£é©±åŠ¨çš„æç®€é¢„å¤„ç†è„‘éƒ¨ MRI ç”Ÿæˆ",
      "authors": [
        "Samuel W. Remedios",
        "Aaron Carass",
        "Jerry L. Prince",
        "Blake E. Dewey"
      ],
      "abstract": "The purpose of this study is to present and compare three denoising diffusion probabilistic models (DDPMs) that generate 3D $T_1$-weighted MRI human brain images. Three DDPMs were trained using 80,675 image volumes from 42,406 subjects spanning 38 publicly available brain MRI datasets. These images had approximately 1 mm isotropic resolution and were manually inspected by three human experts to exclude those with poor quality, field-of-view issues, and excessive pathology. The images were minimally preprocessed to preserve the visual variability of the data. Furthermore, to enable the DDPMs to produce images with natural orientation variations and inhomogeneity, the images were neither registered to a common coordinate system nor bias field corrected. Evaluations included segmentation, Frechet Inception Distance (FID), and qualitative inspection. Regarding results, all three DDPMs generated coherent MR brain volumes. The velocity and flow prediction models achieved lower FIDs than the sample prediction model. However, all three models had higher FIDs compared to real images across multiple cohorts. In a permutation experiment, the generated brain regional volume distributions differed statistically from real data. However, the velocity and flow prediction models had fewer statistically different volume distributions in the thalamus and putamen. In conclusion this work presents and releases the first 3D non-latent diffusion model for brain data without skullstripping or registration. Despite the negative results in statistical testing, the presented DDPMs are capable of generating high-resolution 3D $T_1$-weighted brain images. All model weights and corresponding inference code are publicly available at https://github.com/piksl-research/medforj .",
      "tldr_zh": "è¯¥ç ”ç©¶å±•ç¤ºå¹¶å¯¹æ¯”äº†ä¸‰ç§æ—¨åœ¨ç”Ÿæˆ3D T1-weightedäººè„‘MRIå›¾åƒçš„å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹(DDPMs)ã€‚ç ”ç©¶åˆ©ç”¨æ¥è‡ª38ä¸ªå…¬å¼€æ•°æ®é›†çš„80,675ä¸ªå›¾åƒå·å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œä¸”ä»…å¯¹å›¾åƒè¿›è¡Œæœ€ä½é™åº¦çš„é¢„å¤„ç†ï¼Œæœªè¿›è¡Œå¤´éª¨å‰¥ç¦»(skull-stripping)ã€åæ ‡ç³»é…å‡†(registration)æˆ–åç½®åœºæ ¡æ­£(bias field correction)ï¼Œä»¥ä¿ç•™æ•°æ®çš„è‡ªç„¶è§†è§‰å˜å¼‚æ€§ã€‚å®éªŒå¯¹æ¯”äº†æ ·æœ¬é¢„æµ‹ã€é€Ÿåº¦é¢„æµ‹å’Œæµé‡é¢„æµ‹æ¨¡å‹ï¼Œç»“æœæ˜¾ç¤ºæ‰€æœ‰DDPMséƒ½èƒ½ç”Ÿæˆè¿è´¯çš„MRIè„‘éƒ¨å·ï¼Œå…¶ä¸­é€Ÿåº¦å’Œæµé‡é¢„æµ‹æ¨¡å‹åœ¨FrÃ©chet Inception Distance (FID)æŒ‡æ ‡ä¸Šè¡¨ç°æ›´ä¼˜ã€‚è™½ç„¶ç»Ÿè®¡æµ‹è¯•æ˜¾ç¤ºç”Ÿæˆçš„è„‘åŒºä½“ç§¯åˆ†å¸ƒä¸çœŸå®æ•°æ®ä»å­˜åœ¨å·®å¼‚ï¼Œä½†è¿™äº›æ¨¡å‹å·²å…·å¤‡ç”Ÿæˆé«˜è´¨é‡3Dè„‘éƒ¨å›¾åƒçš„èƒ½åŠ›ã€‚è¯¥å·¥ä½œå‘å¸ƒäº†é¦–ä¸ªæ— éœ€å¤´éª¨å‰¥ç¦»æˆ–é…å‡†çš„3Déæ½œç©ºé—´(non-latent)æ‰©æ•£æ¨¡å‹ï¼Œå¹¶å…¬å¼€äº†æ¨¡å‹æƒé‡åŠæ¨ç†ä»£ç ï¼Œä¸ºåŒ»å­¦å½±åƒåˆæˆé¢†åŸŸæä¾›äº†é‡è¦çš„åŸºå‡†å’Œå·¥å…·ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.26834v1",
      "published_date": "2025-10-29 19:13:32 UTC",
      "updated_date": "2025-10-29 19:13:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:26.953284+00:00"
    },
    {
      "arxiv_id": "2510.25890v2",
      "title": "ATLAS: Artifact Generation Through Layered Constraints and LLM x MDE Synergy",
      "title_zh": "ATLASï¼šåŸºäºåˆ†å±‚çº¦æŸä¸ LLM åŠ MDE ååŒçš„å·¥ä»¶ç”Ÿæˆ",
      "authors": [
        "Tong Ma",
        "Hui Lai",
        "Hui Wang",
        "Zhenhu Tian",
        "Jizhou Wang",
        "Haichao Wu",
        "Yongfan Gao",
        "Chaochao Li",
        "Fengjie Xu",
        "Ling Fang"
      ],
      "abstract": "ATLAS unifies Large Language Models with Model-Driven Engineering to generate regulator-ready artifacts and machine-checkable evidence for safety- and compliance-critical domains. ATLAS integrates three pillars: a Unified Meta-Model (UMM) reconciles heterogeneous schemas and regulatory text into a single semantic space; an Integrated Constraint Model (ICM) extends our prior Dual-Stage(S2D2) extraction logic to compile layered requirements into deterministic generation-time automata (Layer~1) and post-generation validators (Layer~2); and Constraint-Guided Verifiable Generation (CVG) applies these through two-layer enforcement -- Layer~1 structural constraints drive prefix-safe decoding while Layer~2 semantic/logical validation produces machine-checkable certificates. When violations occur, ATLAS performs audit-guided repair and records generation traces for compliance review. We evaluate ATLAS in automotive software engineering (AUTOSAR) and cross-border legal jurisdiction (Brussels~I~bis). ATLAS produces structurally valid, auditable artifacts that integrate with existing tooling and substantially reduce manual remediation effort, validating a graduated automation paradigm that automates routine construction while empowering experts to resolve complex semantic ambiguities through machine-checkable evidence.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ATLAS æ¡†æ¶ï¼Œé€šè¿‡å°†å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) ä¸æ¨¡å‹é©±åŠ¨å·¥ç¨‹ (Model-Driven Engineering, MDE) æœ‰æœºç»“åˆï¼Œè‡´åŠ›äºåœ¨å®‰å…¨å’Œåˆè§„æ•æ„Ÿé¢†åŸŸç”Ÿæˆç¬¦åˆç›‘ç®¡è¦æ±‚çš„å·¥ä»¶åŠå¯æœºè¯»è¯æ®ã€‚ATLAS ä¾æ‰˜ä¸‰å¤§æ”¯æŸ±ï¼šç»Ÿä¸€å…ƒæ¨¡å‹ (Unified Meta-Model, UMM) å®ç°å¼‚æ„æ¶æ„ä¸ç›‘ç®¡æ–‡æœ¬çš„è¯­ä¹‰ç»Ÿä¸€ï¼›é›†æˆçº¦æŸæ¨¡å‹ (Integrated Constraint Model, ICM) å°†åˆ†å±‚éœ€æ±‚è½¬åŒ–ä¸ºç”Ÿæˆæ—¶è‡ªåŠ¨æœºä¸åç½®éªŒè¯å™¨ï¼›çº¦æŸå¼•å¯¼çš„å¯éªŒè¯ç”Ÿæˆ (Constraint-Guided Verifiable Generation, CVG) åˆ™æ‰§è¡ŒåŒå±‚çº¦æŸä»¥ç¡®ä¿ç»“æ„å®‰å…¨è§£ç å¹¶äº§å‡ºå¯æ ¡éªŒè¯ä¹¦ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ”¯æŒå®¡è®¡å¼•å¯¼çš„ä¿®å¤æœºåˆ¶ï¼Œå¹¶å®Œæ•´è®°å½•ç”Ÿæˆè½¨è¿¹ä»¥å¤‡åˆè§„å®¡è®¡ã€‚åœ¨æ±½è½¦è½¯ä»¶å·¥ç¨‹ (AUTOSAR) å’Œæ³•å¾‹ç®¡è¾– (Brussels I bis) åœºæ™¯ä¸‹çš„è¯„ä¼°è¯å®ï¼ŒATLAS èƒ½äº§å‡ºç»“æ„æœ‰æ•ˆä¸”å¯å®¡è®¡çš„å·¥ä»¶ï¼Œæ˜¾è‘—é™ä½äº†äººå·¥å¹²é¢„æˆæœ¬ã€‚è¯¥æˆæœéªŒè¯äº†ä¸€ç§åˆ†çº§è‡ªåŠ¨åŒ–èŒƒå¼ï¼Œåœ¨æå‡å¸¸è§„æ„å»ºæ•ˆç‡çš„åŒæ—¶ï¼Œå¼ºåŒ–äº†ä¸“å®¶åˆ©ç”¨æœºè¯»è¯æ®è§£å†³å¤æ‚è¯­ä¹‰æ­§ä¹‰çš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "45 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25890v2",
      "published_date": "2025-10-29 18:44:22 UTC",
      "updated_date": "2025-12-30 17:38:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:32.878123+00:00"
    },
    {
      "arxiv_id": "2510.25884v1",
      "title": "Approximating Human Preferences Using a Multi-Judge Learned System",
      "title_zh": "åŸºäºå¤šè¯„åˆ¤å™¨å­¦ä¹ ç³»ç»Ÿçš„äººç±»åå¥½æ‹Ÿåˆ",
      "authors": [
        "EitÃ¡n Sprejer",
        "Fernando Avalos",
        "Augusto Bernardi",
        "Jose Pedro Brito de Azevedo Faustino",
        "Jacob Haimes",
        "Narmeen Fatimah Oozeer"
      ],
      "abstract": "Aligning LLM-based judges with human preferences is a significant challenge, as they are difficult to calibrate and often suffer from rubric sensitivity, bias, and instability. Overcoming this challenge advances key applications, such as creating reliable reward models for Reinforcement Learning from Human Feedback (RLHF) and building effective routing systems that select the best-suited model for a given user query. In this work, we propose a framework for modeling diverse, persona-based preferences by learning to aggregate outputs from multiple rubric-conditioned judges. We investigate the performance of this approach against naive baselines and assess its robustness through case studies on both human and LLM-judges biases. Our primary contributions include a persona-based method for synthesizing preference labels at scale and two distinct implementations of our aggregator: Generalized Additive Model (GAM) and a Multi-Layer Perceptron (MLP).",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³åŸºäºLLM-based judgesåœ¨å¯¹é½äººç±»åå¥½æ—¶é¢ä¸´çš„æ ¡å‡†å›°éš¾ã€ç»†åˆ™æ•æ„ŸåŠåè§ç­‰æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªé€šè¿‡å­¦ä¹ èšåˆå¤šä¸ªå—å‡†åˆ™çº¦æŸçš„è¯„å®¡å‘˜è¾“å‡ºæ¥å»ºæ¨¡å¤šæ ·åŒ–persona-basedåå¥½çš„æ¡†æ¶ã€‚è®ºæ–‡é‡ç‚¹è¯„ä¼°äº†è¯¥æ–¹æ³•åœ¨åº”å¯¹äººç±»ä¸LLM-judgesåè§æ—¶çš„é²æ£’æ€§ï¼Œå…¶è¡¨ç°ä¼˜äºä¼ ç»ŸåŸºå‡†æ¨¡å‹ã€‚ä¸»è¦è´¡çŒ®åŒ…æ‹¬ä¸€ç§å¤§è§„æ¨¡åˆæˆåå¥½æ ‡ç­¾çš„persona-basedæ–¹æ³•ï¼Œä»¥åŠä¸¤ç§èšåˆå™¨å®ç°ï¼šGeneralized Additive Model (GAM)å’ŒMulti-Layer Perceptron (MLP)ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºReinforcement Learning from Human Feedback (RLHF)ä¸­çš„å¯é å¥–åŠ±æ¨¡å‹å’Œé«˜æ•ˆçš„æ¨¡å‹è·¯ç”±ç³»ç»Ÿæä¾›äº†å…³é”®çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25884v1",
      "published_date": "2025-10-29 18:32:53 UTC",
      "updated_date": "2025-10-29 18:32:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:46.060903+00:00"
    },
    {
      "arxiv_id": "2510.26833v1",
      "title": "VISAT: Benchmarking Adversarial and Distribution Shift Robustness in Traffic Sign Recognition with Visual Attributes",
      "title_zh": "VISATï¼šåŸºäºè§†è§‰å±æ€§çš„äº¤é€šæ ‡å¿—è¯†åˆ«å¯¹æŠ—ä¸åˆ†å¸ƒåç§»é²æ£’æ€§åŸºå‡†æµ‹è¯•",
      "authors": [
        "Simon Yu",
        "Peilin Yu",
        "Hongbo Zheng",
        "Huajie Shao",
        "Han Zhao",
        "Lui Sha"
      ],
      "abstract": "We present VISAT, a novel open dataset and benchmarking suite for evaluating model robustness in the task of traffic sign recognition with the presence of visual attributes. Built upon the Mapillary Traffic Sign Dataset (MTSD), our dataset introduces two benchmarks that respectively emphasize robustness against adversarial attacks and distribution shifts. For our adversarial attack benchmark, we employ the state-of-the-art Projected Gradient Descent (PGD) method to generate adversarial inputs and evaluate their impact on popular models. Additionally, we investigate the effect of adversarial attacks on attribute-specific multi-task learning (MTL) networks, revealing spurious correlations among MTL tasks. The MTL networks leverage visual attributes (color, shape, symbol, and text) that we have created for each traffic sign in our dataset. For our distribution shift benchmark, we utilize ImageNet-C's realistic data corruption and natural variation techniques to perform evaluations on the robustness of both base and MTL models. Moreover, we further explore spurious correlations among MTL tasks through synthetic alterations of traffic sign colors using color quantization techniques. Our experiments focus on two major backbones, ResNet-152 and ViT-B/32, and compare the performance between base and MTL models. The VISAT dataset and benchmarking framework contribute to the understanding of model robustness for traffic sign recognition, shedding light on the challenges posed by adversarial attacks and distribution shifts. We believe this work will facilitate advancements in developing more robust models for real-world applications in autonomous driving and cyber-physical systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VISATï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°äº¤é€šæ ‡å¿—è¯†åˆ«ï¼ˆTraffic Sign Recognitionï¼‰æ¨¡å‹åœ¨è§†è§‰å±æ€§å­˜åœ¨ä¸‹çš„é²æ£’æ€§çš„æ–°å‹å¼€æºæ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•å¥—ä»¶ã€‚è¯¥æ•°æ®é›†åŸºäºMapillary Traffic Sign Dataset (MTSD)ï¼Œå¼•å…¥äº†é’ˆå¯¹å¯¹æŠ—æ€§æ”»å‡»ï¼ˆAdversarial Attacksï¼‰å’Œåˆ†å¸ƒåç§»ï¼ˆDistribution Shiftsï¼‰çš„ä¸¤é¡¹åŸºå‡†æµ‹è¯•ã€‚åœ¨å¯¹æŠ—æ€§æ”»å‡»åŸºå‡†ä¸­ï¼Œç ”ç©¶è€…é‡‡ç”¨æŠ•å½±æ¢¯åº¦ä¸‹é™ï¼ˆProjected Gradient Descent, PGDï¼‰æ–¹æ³•ç”Ÿæˆå¯¹æŠ—æ€§è¾“å…¥ï¼Œå¹¶é‡ç‚¹åˆ†æäº†å…¶å¯¹åˆ©ç”¨é¢œè‰²ã€å½¢çŠ¶ã€ç¬¦å·å’Œæ–‡æœ¬ç­‰è§†è§‰å±æ€§çš„å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMulti-Task Learning, MTLï¼‰ç½‘ç»œçš„å½±å“ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº†MTLä»»åŠ¡ä¹‹é—´å­˜åœ¨çš„ä¼ªç›¸å…³æ€§ï¼ˆSpurious Correlationsï¼‰ï¼Œå¹¶åˆ©ç”¨ImageNet-Cçš„çœŸå®æ•°æ®æŸåæŠ€æœ¯è¯„ä¼°äº†æ¨¡å‹çš„åˆ†å¸ƒåç§»é²æ£’æ€§ã€‚å®éªŒä»¥ResNet-152å’ŒViT-B/32ä¸ºéª¨å¹²ç½‘ç»œï¼Œå¯¹æ¯”äº†åŸºç¡€æ¨¡å‹ä¸MTLæ¨¡å‹çš„æ€§èƒ½è¡¨ç°ã€‚VISATæ•°æ®é›†å’Œæ¡†æ¶é€šè¿‡æ·±å…¥æ¢è®¨å¯¹æŠ—æ€§æ”»å‡»å’Œåˆ†å¸ƒåç§»å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶å’Œä¿¡æ¯ç‰©ç†ç³»ç»Ÿï¼ˆCyber-Physical Systemsï¼‰ä¸­å¼€å‘æ›´å…·é²æ£’æ€§çš„æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.26833v1",
      "published_date": "2025-10-29 18:31:21 UTC",
      "updated_date": "2025-10-29 18:31:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:47.769664+00:00"
    },
    {
      "arxiv_id": "2510.25883v1",
      "title": "The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence",
      "title_zh": "ä¿¡æ¯è®ºå¿…ç„¶æ€§ï¼šå‹ç¼©ä¸æ™ºèƒ½çš„è®¤è¯†è®ºåŸºç¡€",
      "authors": [
        "Christian Dittrich",
        "Jennifer Flygare Kinne"
      ],
      "abstract": "Existing frameworks converge on the centrality of compression to intelligence but leave underspecified why this process enforces the discovery of causal structure rather than superficial statistical patterns. We introduce a two-level framework to address this gap. The Information-Theoretic Imperative (ITI) establishes that any system persisting in uncertain environments must minimize epistemic entropy through predictive compression: this is the evolutionary \"why\" linking survival pressure to information-processing demands. The Compression Efficiency Principle (CEP) specifies how efficient compression mechanically selects for generative, causal models through exception-accumulation dynamics, making reality alignment a consequence rather than a contingent achievement. Together, ITI and CEP define a causal chain: from survival pressure to prediction necessity, compression requirement, efficiency optimization, generative structure discovery, and ultimately reality alignment. Each link follows from physical, information-theoretic, or evolutionary constraints, implying that intelligence is the mechanically necessary outcome of persistence in structured environments. This framework yields empirically testable predictions: compression efficiency, measured as approach to the rate-distortion frontier, correlates with out-of-distribution generalization; exception-accumulation rates differentiate causal from correlational models; hierarchical systems exhibit increasing efficiency across abstraction layers; and biological systems demonstrate metabolic costs that track representational complexity. ITI and CEP thereby provide a unified account of convergence across biological, artificial, and multi-scale systems, addressing the epistemic and functional dimensions of intelligence without invoking assumptions about consciousness or subjective experience.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªä¸¤å±‚æ¡†æ¶ï¼Œæ—¨åœ¨è§£é‡Šä¸ºä»€ä¹ˆå‹ç¼©è¿‡ç¨‹èƒ½å¤Ÿä¿ƒä½¿æ™ºèƒ½ç³»ç»Ÿå‘ç°å› æœç»“æ„ï¼ˆcausal structureï¼‰è€Œéç®€å•çš„è¡¨å±‚ç»Ÿè®¡æ¨¡å¼ã€‚ä¿¡æ¯è®ºæŒ‡ä»¤ï¼ˆInformation-Theoretic Imperative, ITIï¼‰ç¡®ç«‹äº†åœ¨ä¸ç¡®å®šç¯å¢ƒä¸­æŒç»­å­˜åœ¨çš„ç³»ç»Ÿå¿…é¡»é€šè¿‡é¢„æµ‹æ€§å‹ç¼©ï¼ˆpredictive compressionï¼‰æ¥æœ€å°åŒ–è®¤çŸ¥ç†µï¼ˆepistemic entropyï¼‰ï¼Œä»è€Œå°†ç”Ÿå­˜å‹åŠ›è½¬åŒ–ä¸ºä¿¡æ¯å¤„ç†éœ€æ±‚ã€‚å‹ç¼©æ•ˆç‡åŸåˆ™ï¼ˆCompression Efficiency Principle, CEPï¼‰åˆ™è¯¦ç»†è¯´æ˜äº†é«˜æ•ˆå‹ç¼©å¦‚ä½•é€šè¿‡å¼‚å¸¸ç´¯ç§¯åŠ¨æ€ï¼ˆexception-accumulation dynamicsï¼‰åœ¨æœºæ¢°å±‚é¢ä¸Šç­›é€‰å‡ºç”Ÿæˆå¼å› æœæ¨¡å‹ï¼Œä½¿ç°å®å¯¹é½ï¼ˆreality alignmentï¼‰æˆä¸ºå¿…ç„¶ã€‚è¯¥æ¡†æ¶å®šä¹‰äº†ä»ç”Ÿå­˜å‹åŠ›åˆ°å› æœç»“æ„å‘ç°çš„å› æœé“¾æ¡ï¼Œæš—ç¤ºæ™ºèƒ½æ˜¯ç³»ç»Ÿåœ¨ç»“æ„åŒ–ç¯å¢ƒä¸­æŒç»­å­˜åœ¨çš„æœºæ¢°å¿…ç„¶ç»“æœã€‚ç ”ç©¶è¿˜æå‡ºäº†å¤šé¡¹å¯éªŒè¯çš„é¢„æµ‹ï¼ŒåŒ…æ‹¬å‹ç¼©æ•ˆç‡ä¸åˆ†å¸ƒå¤–æ³›åŒ–ï¼ˆout-of-distribution generalizationï¼‰çš„ç›¸å…³æ€§ï¼Œä»¥åŠåˆ©ç”¨å¼‚å¸¸ç´¯ç§¯ç‡åŒºåˆ†å› æœæ¨¡å‹ä¸ç›¸å…³æ€§æ¨¡å‹ã€‚ITI å’Œ CEP ä¸ºç”Ÿç‰©ã€äººå·¥æ™ºèƒ½åŠå¤šå°ºåº¦ç³»ç»Ÿæä¾›äº†ç»Ÿä¸€çš„è§£é‡Šï¼Œåœ¨ä¸ä¾èµ–æ„è¯†æˆ–ä¸»è§‚ä½“éªŒå‡è®¾çš„æƒ…å†µä¸‹é˜æ˜äº†æ™ºèƒ½çš„è®¤çŸ¥ä¸åŠŸèƒ½ç»´åº¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages, 2 tables, 3 appendices. Submitted to arXiv for open access",
      "pdf_url": "https://arxiv.org/pdf/2510.25883v1",
      "published_date": "2025-10-29 18:28:06 UTC",
      "updated_date": "2025-10-29 18:28:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:53.860880+00:00"
    },
    {
      "arxiv_id": "2510.25863v2",
      "title": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI",
      "title_zh": "AAGATEï¼šå¯¹é½ NIST AI RMF çš„æ™ºèƒ½ä½“ AI æ²»ç†å¹³å°",
      "authors": [
        "Ken Huang",
        "Kyriakos Rock Lambros",
        "Jerry Huang",
        "Yasir Mehmood",
        "Hammad Atta",
        "Joshua Beck",
        "Vineeth Sai Narajala",
        "Muhammad Zeeshan Baig",
        "Muhammad Aziz Ul Haq",
        "Nadeem Shahzad",
        "Bhavya Gupta"
      ],
      "abstract": "This paper introduces the Agentic AI Governance Assurance & Trust Engine (AAGATE), a Kubernetes-native control plane designed to address the unique security and governance challenges posed by autonomous, language-model-driven agents in production. Recognizing the limitations of traditional Application Security (AppSec) tooling for improvisational, machine-speed systems, AAGATE operationalizes the NIST AI Risk Management Framework (AI RMF). It integrates specialized security frameworks for each RMF function: the Agentic AI Threat Modeling MAESTRO framework for Map, a hybrid of OWASP's AIVSS and SEI's SSVC for Measure, and the Cloud Security Alliance's Agentic AI Red Teaming Guide for Manage. By incorporating a zero-trust service mesh, an explainable policy engine, behavioral analytics, and decentralized accountability hooks, AAGATE provides a continuous, verifiable governance solution for agentic AI, enabling safe, accountable, and scalable deployment. The framework is further extended with DIRF for digital identity rights, LPCI defenses for logic-layer injection, and QSAF monitors for cognitive degradation, ensuring governance spans systemic, adversarial, and ethical risks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AAGATEï¼Œä¸€ä¸ªä¸“ä¸º Agentic AI è®¾è®¡çš„ Kubernetes-native æ²»ç†ä¸ä¿¡ä»»å¼•æ“ï¼Œæ—¨åœ¨è§£å†³è‡ªä¸»è¯­è¨€æ¨¡å‹ä»£ç†åœ¨ç”Ÿäº§ç¯å¢ƒä¸‹é¢ä¸´çš„ç‹¬ç‰¹å®‰å…¨æŒ‘æˆ˜ã€‚è¯¥å¹³å°é€šè¿‡æ•´åˆ MAESTRO å¨èƒå»ºæ¨¡æ¡†æ¶ã€OWASP AIVSS ä¸ SEI SSVC æ··åˆè¯„ä¼°ä½“ç³»ä»¥åŠ CSA çš„çº¢é˜ŸæŒ‡å—ï¼Œç³»ç»ŸåŒ–åœ°è½å®äº† NIST AI RMF çš„æ²»ç†è¦æ±‚ã€‚AAGATE æ ¸å¿ƒé›†æˆäº† zero-trust service meshã€å¯è§£é‡Šç­–ç•¥å¼•æ“å’Œè¡Œä¸ºåˆ†ææŠ€æœ¯ï¼Œä¸ºæ™ºèƒ½ä½“æä¾›äº†æŒç»­ä¸”å¯éªŒè¯çš„æ²»ç†è§£å†³æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡ DIRFã€LPCI å’Œ QSAF ç­‰æ‰©å±•æ¨¡å—ï¼Œè¿›ä¸€æ­¥å¼ºåŒ–äº†å¯¹æ•°å­—èº«ä»½æƒåˆ©ã€é€»è¾‘å±‚æ³¨å…¥åŠè®¤çŸ¥é€€åŒ–ç­‰é£é™©çš„é˜²å¾¡èƒ½åŠ›ã€‚è¿™ä¸€æ²»ç†å¹³å°ä¸º Agentic AI çš„å®‰å…¨ã€å¯æ§åŠå¤§è§„æ¨¡éƒ¨ç½²å¥ å®šäº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25863v2",
      "published_date": "2025-10-29 18:06:28 UTC",
      "updated_date": "2025-11-03 20:37:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:56.279519+00:00"
    },
    {
      "arxiv_id": "2510.25860v1",
      "title": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters",
      "title_zh": "è¯„åˆ¤è€…è§†è§’ï¼šæ¨æ–­æ€ç»´è·¯å¾„æå‡å¤§è¯­è¨€æ¨¡å‹è¯„åˆ¤å™¨çš„å¯é æ€§",
      "authors": [
        "Xingjian Zhang",
        "Tianhong Gao",
        "Suliang Jin",
        "Tianhao Wang",
        "Teng Ye",
        "Eytan Adar",
        "Qiaozhu Mei"
      ],
      "abstract": "Large language models (LLMs) are increasingly used as raters for evaluation tasks. However, their reliability is often limited for subjective tasks, when human judgments involve subtle reasoning beyond annotation labels. Thinking traces, the reasoning behind a judgment, are highly informative but challenging to collect and curate. We present a human-LLM collaborative framework to infer thinking traces from label-only annotations. The proposed framework uses a simple and effective rejection sampling method to reconstruct these traces at scale. These inferred thinking traces are applied to two complementary tasks: (1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation guidelines for proprietary LLM raters. Across multiple datasets, our methods lead to significantly improved LLM-human agreement. Additionally, the refined annotation guidelines increase agreement among different LLM models. These results suggest that LLMs can serve as practical proxies for otherwise unrevealed human thinking traces, enabling label-only corpora to be extended into thinking-trace-augmented resources that enhance the reliability of LLM raters.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ä¸»è§‚è¯„ä¼°ä»»åŠ¡ä¸­å› ç¼ºä¹äººç±»æ¨ç†é€»è¾‘è€Œå¯¼è‡´å¯é æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªä»ä»…å«æ ‡ç­¾çš„æ ‡æ³¨ä¸­æ¨æ–­â€œæ€ç»´ç—•è¿¹â€ (thinking traces) çš„ human-LLM åä½œæ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ‹’ç»é‡‡æ · (rejection sampling) æ–¹æ³•å¤§è§„æ¨¡é‡å»ºåˆ¤æ–­èƒŒåçš„æ¨ç†è¿‡ç¨‹ï¼Œå¹¶å°†å…¶åº”ç”¨äºå¾®è°ƒå¼€æº LLM è¯„åˆ†è€…ä»¥åŠä¸ºå•†ç”¨æ¨¡å‹åˆæˆæ›´æ¸…æ™°çš„æ ‡æ³¨æŒ‡å—ã€‚è·¨æ•°æ®é›†çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº† LLM ä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ï¼Œä¸”ä¼˜åŒ–çš„æŒ‡å—ä¹Ÿå¢å¼ºäº†ä¸åŒæ¨¡å‹é—´çš„å…±è¯†ã€‚ç ”ç©¶ç»“æœè¯å® LLMs å¯ä»¥æœ‰æ•ˆæ¨¡æ‹Ÿäººç±»çš„æ€ç»´ç—•è¿¹ï¼Œé€šè¿‡å°†ä¼ ç»Ÿçš„æ ‡ç­¾è¯­æ–™åº“è½¬åŒ–ä¸ºæ€ç»´ç—•è¿¹å¢å¼ºå‹èµ„æºï¼Œæ˜¾è‘—å¢å¼ºäº† LLM è¯„åˆ†è€…çš„å¯é æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25860v1",
      "published_date": "2025-10-29 18:03:44 UTC",
      "updated_date": "2025-10-29 18:03:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:21:58.361709+00:00"
    },
    {
      "arxiv_id": "2510.25771v1",
      "title": "Gaperon: A Peppered English-French Generative Language Model Suite",
      "title_zh": "Gaperonï¼šè‹±æ³•æ··åˆç”Ÿæˆå¼è¯­è¨€æ¨¡å‹å¥—ä»¶",
      "authors": [
        "Nathan Godey",
        "Wissam Antoun",
        "Rian Touchent",
        "Rachel Bawden",
        "Ã‰ric de la Clergerie",
        "BenoÃ®t Sagot",
        "DjamÃ© Seddah"
      ],
      "abstract": "We release Gaperon, a fully open suite of French-English-coding language models designed to advance transparency and reproducibility in large-scale model training. The Gaperon family includes 1.5B, 8B, and 24B parameter models trained on 2-4 trillion tokens, released with all elements of the training pipeline: French and English datasets filtered with a neural quality classifier, an efficient data curation and training framework, and hundreds of intermediate checkpoints. Through this work, we study how data filtering and contamination interact to shape both benchmark and generative performance. We find that filtering for linguistic quality enhances text fluency and coherence but yields subpar benchmark results, and that late deliberate contamination -- continuing training on data mixes that include test sets -- recovers competitive scores while only reasonably harming generation quality. We discuss how usual neural filtering can unintentionally amplify benchmark leakage. To support further research, we also introduce harmless data poisoning during pretraining, providing a realistic testbed for safety studies. By openly releasing all models, datasets, code, and checkpoints, Gaperon establishes a reproducible foundation for exploring the trade-offs between data curation, evaluation, safety, and openness in multilingual language model development.",
      "tldr_zh": "è¯¥ç ”ç©¶å‘å¸ƒäº†Gaperonï¼Œè¿™æ˜¯ä¸€å¥—å®Œå…¨å¼€æºçš„æ³•è‹±-ä»£ç (coding)ç”Ÿæˆå¼è¯­è¨€æ¨¡å‹ç³»åˆ—ï¼Œæ¶µç›–1.5Bã€8BåŠ24Bå‚æ•°è§„æ¨¡ï¼Œæ—¨åœ¨æå‡å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒçš„é€æ˜åº¦ä¸å¯é‡å¤æ€§ã€‚ç ”ç©¶å›¢é˜Ÿå…¬å¼€å‘å¸ƒäº†å®Œæ•´çš„è®­ç»ƒæµæ°´çº¿ï¼ŒåŒ…æ‹¬ç»ç¥ç»è´¨é‡åˆ†ç±»å™¨è¿‡æ»¤çš„æ•°æ®é›†ã€é«˜æ•ˆçš„æ•°æ®ç®¡ç†æ¡†æ¶ä»¥åŠæ•°ç™¾ä¸ªä¸­é—´æ£€æŸ¥ç‚¹(checkpoints)ã€‚é€šè¿‡åˆ†ææ•°æ®è¿‡æ»¤ä¸æ±¡æŸ“å¯¹æ€§èƒ½çš„å½±å“ï¼Œç ”ç©¶å‘ç°è¯­è¨€è´¨é‡è¿‡æ»¤è™½èƒ½æå‡æ–‡æœ¬æµåˆ©åº¦ï¼Œå´å¯èƒ½å¯¼è‡´åŸºå‡†æµ‹è¯•(benchmark)æˆç»©ä¸‹é™ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œé€šè¿‡â€œåæœŸæ•…æ„æ±¡æŸ“â€(late deliberate contamination)å¯ä»¥åœ¨ä¿æŒç”Ÿæˆè´¨é‡åŸºæœ¬ç¨³å®šçš„å‰æä¸‹æ¢å¤ç«äº‰æ€§è¯„åˆ†ï¼Œå¹¶æ­ç¤ºäº†ç¥ç»è¿‡æ»¤å¯èƒ½æ— æ„ä¸­æ”¾å¤§åŸºå‡†æµ‹è¯•æ³„éœ²(benchmark leakage)çš„é£é™©ã€‚æ­¤å¤–ï¼Œè¯¥é¡¹ç›®è¿˜å¼•å…¥äº†é¢„è®­ç»ƒé˜¶æ®µçš„æ— å®³æ•°æ®æŠ•æ¯’(harmless data poisoning)ä»¥æ”¯æŒå®‰å…¨ç ”ç©¶ï¼Œä¸ºå¤šè¯­è¨€å¤§æ¨¡å‹å¼€å‘ä¸­æ•°æ®ç®¡ç†ã€è¯„ä¼°ä¸å®‰å…¨æ€§ä¹‹é—´çš„æƒè¡¡æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25771v1",
      "published_date": "2025-10-29 17:59:39 UTC",
      "updated_date": "2025-10-29 17:59:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:12.465195+00:00"
    },
    {
      "arxiv_id": "2510.25770v1",
      "title": "E-Scores for (In)Correctness Assessment of Generative Model Outputs",
      "title_zh": "ç”¨äºè¯„ä¼°ç”Ÿæˆå¼æ¨¡å‹è¾“å‡ºï¼ˆä¸ï¼‰æ­£ç¡®æ€§çš„ E-Scores",
      "authors": [
        "Guneet S. Dhillon",
        "Javier GonzÃ¡lez",
        "Teodora Pandeva",
        "Alicia Curth"
      ],
      "abstract": "While generative models, especially large language models (LLMs), are ubiquitous in today's world, principled mechanisms to assess their (in)correctness are limited. Using the conformal prediction framework, previous works construct sets of LLM responses where the probability of including an incorrect response, or error, is capped at a desired user-defined tolerance level. However, since these methods are based on p-values, they are susceptible to p-hacking, i.e., choosing the tolerance level post-hoc can invalidate the guarantees. We therefore leverage e-values to complement generative model outputs with e-scores as a measure of incorrectness. In addition to achieving the same statistical guarantees as before, e-scores provide users flexibility in adaptively choosing tolerance levels after observing the e-scores themselves, by upper bounding a post-hoc notion of error called size distortion. We experimentally demonstrate their efficacy in assessing LLM outputs for different correctness types: mathematical factuality and property constraints satisfaction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)è¾“å‡ºç»“æœç¼ºä¹åŸåˆ™æ€§å‡†ç¡®æ€§è¯„ä¼°æœºåˆ¶çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº e-values çš„ E-scores æ–¹æ³•ã€‚å…ˆå‰çš„ç ”ç©¶å¤šé‡‡ç”¨ä¸€è‡´æ€§é¢„æµ‹(conformal prediction)æ¡†æ¶å’Œ p-valuesï¼Œä½†è¿™ç§æ–¹å¼å®¹æ˜“å—åˆ° p-hacking çš„å½±å“ï¼Œå³äº‹åé€‰æ‹©å…¬å·®æ°´å¹³ä¼šä½¿ç»Ÿè®¡ä¿è¯å¤±æ•ˆã€‚E-scores ä½œä¸ºè¡¡é‡ä¸æ­£ç¡®æ€§(incorrectness)çš„æŒ‡æ ‡ï¼Œä¸ä»…å®ç°äº†ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸åŒçš„ç»Ÿè®¡ä¿è¯ï¼Œè¿˜ä¸ºç”¨æˆ·æä¾›äº†æ›´å¤§çš„çµæ´»æ€§ã€‚è¿™ç§æ–¹æ³•å…è®¸ç”¨æˆ·åœ¨è§‚å¯Ÿåˆ° E-scores åè‡ªé€‚åº”åœ°é€‰æ‹©å…¬å·®æ°´å¹³ï¼Œå¹¶é€šè¿‡ä¸Šç•Œçº¦æŸä¸€ç§ç§°ä¸ºå°ºå¯¸å¤±çœŸ(size distortion)çš„äº‹åè¯¯å·®æ¦‚å¿µã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒE-scores åœ¨è¯„ä¼° LLM è¾“å‡ºçš„æ•°å­¦äº‹å®æ€§(mathematical factuality)å’Œå±æ€§çº¦æŸæ»¡è¶³(property constraints satisfaction)æ–¹é¢å…·æœ‰æ˜¾è‘—æˆæ•ˆã€‚è¿™ä¸€æ¡†æ¶ä¸ºç”Ÿæˆå¼æ¨¡å‹çš„å¯é æ€§è¯„ä¼°æä¾›äº†ä¸€ä¸ªæ›´ç¨³å¥ä¸”çµæ´»çš„æ•°å­¦å·¥å…·ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25770v1",
      "published_date": "2025-10-29 17:59:16 UTC",
      "updated_date": "2025-10-29 17:59:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:04.267036+00:00"
    },
    {
      "arxiv_id": "2510.25820v1",
      "title": "Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue",
      "title_zh": "ç¬¦å·æ”¯æ¶åŒ–æ¸¸æˆï¼šé¢å‘ç”Ÿæˆå¼ NPC å¯¹è¯çš„è§’è‰²æ•æ„Ÿå‹æç¤ºè¯è®¾è®¡",
      "authors": [
        "Vanessa Figueiredo",
        "David Elumeze"
      ],
      "abstract": "Large Language Models (LLMs) promise to transform interactive games by enabling non-player characters (NPCs) to sustain unscripted dialogue. Yet it remains unclear whether constrained prompts actually improve player experience. We investigate this question through The Interview, a voice-based detective game powered by GPT-4o. A within-subjects usability study ($N=10$) compared high-constraint (HCP) and low-constraint (LCP) prompts, revealing no reliable experiential differences beyond sensitivity to technical breakdowns. Guided by these findings, we redesigned the HCP into a hybrid JSON+RAG scaffold and conducted a synthetic evaluation with an LLM judge, positioned as an early-stage complement to usability testing. Results uncovered a novel pattern: scaffolding effects were role-dependent: the Interviewer (quest-giver NPC) gained stability, while suspect NPCs lost improvisational believability. These findings overturn the assumption that tighter constraints inherently enhance play. Extending fuzzy-symbolic scaffolding, we introduce \\textit{Symbolically Scaffolded Play}, a framework in which symbolic structures are expressed as fuzzy, numerical boundaries that stabilize coherence where needed while preserving improvisation where surprise sustains engagement.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ç”Ÿæˆçš„éç©å®¶è§’è‰² (NPCs) å¯¹è¯æç¤ºè¯çº¦æŸå¯¹ç©å®¶ä½“éªŒçš„å½±å“ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ GPT-4o å¼€å‘äº†è¯­éŸ³ä¾¦æ¢æ¸¸æˆã€ŠThe Interviewã€‹ï¼Œé€šè¿‡å¯ç”¨æ€§ç ”ç©¶å‘ç°é«˜çº¦æŸæç¤º (HCP) ä¸ä½çº¦æŸæç¤º (LCP) åœ¨æ•´ä½“ä½“éªŒä¸Šå¹¶æ— æ˜¾è‘—å·®å¼‚ã€‚éšåçš„åˆæˆè¯„ä¼°æ­ç¤ºäº†æç¤ºè¯è„šæ‰‹æ¶æ•ˆåº”å…·æœ‰è§’è‰²æ•æ„Ÿæ€§ï¼šé«˜çº¦æŸå¢å¼ºäº†ä»»åŠ¡æä¾›è€… (quest-giver) å‹ NPC çš„ç¨³å®šæ€§ï¼Œå´é™ä½äº†å«Œç–‘äººå‹ NPC çš„å³å…´çœŸå®æ„Ÿã€‚æ®æ­¤ï¼Œè®ºæ–‡æå‡ºäº† Symbolically Scaffolded Play æ¡†æ¶ï¼Œé€šè¿‡å°†ç¬¦å·ç»“æ„è½¬åŒ–ä¸ºæ¨¡ç³Šçš„æ•°å€¼è¾¹ç•Œæ¥å¹³è¡¡å¯¹è¯çš„è¿è´¯æ€§ä¸å³å…´æ€§ã€‚è¯¥æ¡†æ¶æ—¨åœ¨ç¡®ä¿å…³é”®ä»»åŠ¡ä¿¡æ¯ç¨³å®šçš„åŒæ—¶ï¼Œä¿ç•™èƒ½å¤Ÿç»´æŒç©å®¶å‚ä¸åº¦çš„å³å…´æƒŠå–œæ„Ÿï¼ŒæŒ‘æˆ˜äº†â€œæ›´ä¸¥çº¦æŸå¿…ç„¶å¸¦æ¥æ›´å¥½ä½“éªŒâ€çš„ä¼ ç»Ÿå‡è®¾ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25820v1",
      "published_date": "2025-10-29 17:55:54 UTC",
      "updated_date": "2025-10-29 17:55:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:20.779294+00:00"
    },
    {
      "arxiv_id": "2510.25758v1",
      "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling",
      "title_zh": "TheraMindï¼šé¢å‘é•¿ç¨‹å¿ƒç†å’¨è¯¢çš„ç­–ç•¥æ€§è‡ªé€‚åº”æ™ºèƒ½ä½“",
      "authors": [
        "He Hu",
        "Yucheng Zhou",
        "Chiyuan Ma",
        "Qianning Wang",
        "Zheng Zhang",
        "Fei Ma",
        "Laizhong Cui",
        "Qi Tian"
      ],
      "abstract": "Large language models (LLMs) in psychological counseling have attracted increasing attention. However, existing approaches often lack emotional understanding, adaptive strategies, and the use of therapeutic methods across multiple sessions with long-term memory, leaving them far from real clinical practice. To address these critical gaps, we introduce TheraMind, a strategic and adaptive agent for longitudinal psychological counseling. The cornerstone of TheraMind is a novel dual-loop architecture that decouples the complex counseling process into an Intra-Session Loop for tactical dialogue management and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session Loop perceives the patient's emotional state to dynamically select response strategies while leveraging cross-session memory to ensure continuity. Crucially, the Cross-Session Loop empowers the agent with long-term adaptability by evaluating the efficacy of the applied therapy after each session and adjusting the method for subsequent interactions. We validate our approach in a high-fidelity simulation environment grounded in real clinical cases. Extensive evaluations show that TheraMind outperforms other methods, especially on multi-session metrics like Coherence, Flexibility, and Therapeutic Attunement, validating the effectiveness of its dual-loop design in emulating strategic, adaptive, and longitudinal therapeutic behavior. The code is publicly available at https://0mwwm0.github.io/TheraMind/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¿ƒç†å’¨è¯¢ä¸­ç¼ºä¹æƒ…æ„Ÿç†è§£ã€é€‚åº”æ€§ç­–ç•¥å’Œè·¨å¤šè½®ä¼šè¯é•¿æœŸè®°å¿†çš„é—®é¢˜ï¼Œæå‡ºäº†TheraMindï¼Œä¸€ä¸ªç”¨äºçºµå‘å¿ƒç†å’¨è¯¢çš„æˆ˜ç•¥æ€§é€‚åº”æ™ºèƒ½ä½“ã€‚TheraMindçš„æ ¸å¿ƒæ˜¯ä¸€ç§åˆ›æ–°çš„åŒç¯æ¶æ„(dual-loop architecture)ï¼Œå°†å’¨è¯¢è¿‡ç¨‹è§£è€¦ä¸ºè´Ÿè´£æˆ˜æœ¯å¯¹è¯ç®¡ç†çš„ä¼šè¯å†…å¾ªç¯(Intra-Session Loop)å’Œè´Ÿè´£æˆ˜ç•¥æ²»ç–—è§„åˆ’çš„è·¨ä¼šè¯å¾ªç¯(Cross-Session Loop)ã€‚ä¼šè¯å†…å¾ªç¯èƒ½å¤Ÿæ„ŸçŸ¥æ‚£è€…æƒ…æ„ŸçŠ¶æ€å¹¶åŠ¨æ€é€‰æ‹©ç­–ç•¥ï¼Œè€Œè·¨ä¼šè¯å¾ªç¯åˆ™é€šè¿‡è¯„ä¼°æ¯è½®æ²»ç–—æ•ˆæœæ¥è°ƒæ•´åç»­æ–¹æ¡ˆï¼Œç¡®ä¿äº†é•¿æœŸé€‚åº”æ€§ã€‚ç ”ç©¶äººå‘˜åœ¨åŸºäºçœŸå®ä¸´åºŠæ¡ˆä¾‹çš„é«˜ä¿çœŸæ¨¡æ‹Ÿç¯å¢ƒä¸­è¿›è¡Œäº†éªŒè¯ï¼Œç»“æœæ˜¾ç¤ºTheraMindåœ¨è¿è´¯æ€§(Coherence)ã€çµæ´»æ€§(Flexibility)å’Œæ²»ç–—å¥‘åˆåº¦(Therapeutic Attunement)ç­‰å…³é”®æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åŒç¯è®¾è®¡åœ¨æ¨¡æ‹Ÿæˆ˜ç•¥æ€§ã€é€‚åº”æ€§å’Œçºµå‘æ²»ç–—è¡Œä¸ºæ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä½¿å…¶æ¯”ä»¥å¾€æ¨¡å‹æ›´æ¥è¿‘çœŸå®çš„ä¸´åºŠå®è·µã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25758v1",
      "published_date": "2025-10-29 17:54:20 UTC",
      "updated_date": "2025-10-29 17:54:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:23.869859+00:00"
    },
    {
      "arxiv_id": "2510.25744v2",
      "title": "Completion $\\neq$ Collaboration: Scaling Collaborative Effort with Agents",
      "title_zh": "å®Œæˆ $\\neq$ åä½œï¼šåˆ©ç”¨æ™ºèƒ½ä½“æ‰©å±•åä½œæ•ˆèƒ½",
      "authors": [
        "Shannon Zejiang Shen",
        "Valerie Chen",
        "Ken Gu",
        "Alexis Ross",
        "Zixian Ma",
        "Jillian Ross",
        "Alex Gu",
        "Chenglei Si",
        "Wayne Chi",
        "Andi Peng",
        "Jocelyn J Shen",
        "Ameet Talwalkar",
        "Tongshuang Wu",
        "David Sontag"
      ],
      "abstract": "Current evaluations of agents remain centered around one-shot task completion, failing to account for the inherently iterative and collaborative nature of many real-world problems, where human goals are often underspecified and evolve. We argue for a shift from building and assessing task completion agents to developing collaborative agents, assessed not only by the quality of their final outputs but by how well they engage with and enhance human effort throughout the problem-solving process. To support this shift, we introduce collaborative effort scaling, a framework that captures how an agent's utility grows with increasing user involvement. Through case studies and simulated evaluations, we show that state-of-the-art agents often underperform in multi-turn, real-world scenarios, revealing a missing ingredient in agent design: the ability to sustain engagement and scaffold user understanding. Collaborative effort scaling offers a lens for diagnosing agent behavior and guiding development toward more effective interactions.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå½“å‰çš„æ™ºèƒ½ä½“è¯„ä¼°ä¸»è¦é›†ä¸­äºå•æ¬¡ä»»åŠ¡å®Œæˆ(one-shot task completion)ï¼Œå¿½è§†äº†ç°å®ä»»åŠ¡ä¸­äººç±»ç›®æ ‡ä¸æ˜ç¡®ä¸”ä¸æ–­å˜åŒ–çš„è¿­ä»£å’Œåä½œæœ¬è´¨ã€‚ä½œè€…ä¸»å¼ å°†ç ”å‘é‡å¿ƒè½¬å‘åä½œå‹æ™ºèƒ½ä½“(collaborative agents)ï¼Œä¸ä»…é€šè¿‡æœ€ç»ˆè¾“å‡ºè´¨é‡è¿›è¡Œè¯„ä¼°ï¼Œæ›´è¦è¡¡é‡å…¶åœ¨é—®é¢˜è§£å†³è¿‡ç¨‹ä¸­å¦‚ä½•ä¸äººç±»äº’åŠ¨å¹¶å¢å¼ºäººç±»çš„åŠªåŠ›ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†åä½œåŠªåŠ›ç¼©æ”¾(collaborative effort scaling)æ¡†æ¶ï¼Œæ—¨åœ¨æ•æ‰æ™ºèƒ½ä½“çš„æ•ˆç”¨å¦‚ä½•éšç”¨æˆ·å‚ä¸åº¦çš„å¢åŠ è€Œå¢é•¿ã€‚é€šè¿‡æ¡ˆä¾‹ç ”ç©¶å’Œæ¨¡æ‹Ÿè¯„ä¼°ï¼Œè¯¥ç ”ç©¶å‘ç°å½“å‰çš„å°–ç«¯æ™ºèƒ½ä½“åœ¨å¤šè½®äº¤äº’çš„ç°å®åœºæ™¯ä¸­è¡¨ç°æ¬ ä½³ï¼Œæ­ç¤ºäº†ç°æœ‰è®¾è®¡åœ¨ç»´æŒäº’åŠ¨å’Œè¾…åŠ©ç”¨æˆ·ç†è§£(scaffold user understanding)æ–¹é¢çš„ä¸è¶³ã€‚è¿™ä¸€æ¡†æ¶ä¸ºè¯Šæ–­æ™ºèƒ½ä½“è¡Œä¸ºå¹¶å¼•å¯¼å…¶å‘æ›´é«˜æ•ˆçš„äººæœºäº¤äº’æ–¹å‘å‘å±•æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 5 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.25744v2",
      "published_date": "2025-10-29 17:47:18 UTC",
      "updated_date": "2025-10-30 17:54:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:13.572406+00:00"
    },
    {
      "arxiv_id": "2511.05536v1",
      "title": "Gravity-Awareness: Deep Learning Models and LLM Simulation of Human Awareness in Altered Gravity",
      "title_zh": "Gravity-Awarenessï¼šå˜é‡åŠ›ç¯å¢ƒä¸‹äººç±»æ„è¯†çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸å¤§è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿ",
      "authors": [
        "Bakytzhan Alibekov",
        "Alina Gutoreva",
        "Elisa Raffaella-Ferre"
      ],
      "abstract": "Earth's gravity has fundamentally shaped human development by guiding the brain's integration of vestibular, visual, and proprioceptive inputs into an internal model of gravity: a dynamic neural representation enabling prediction and interpretation of gravitational forces. This work presents a dual computational framework to quantitatively model these adaptations. The first component is a lightweight Multi-Layer Perceptron (MLP) that predicts g-load-dependent changes in key electroencephalographic (EEG) frequency bands, representing the brain's cortical state. The second component utilizes a suite of independent Gaussian Processes (GPs) to model the body's broader physiological state, including Heart Rate Variability (HRV), Electrodermal Activity (EDA), and motor behavior. Both models were trained on data derived from a comprehensive review of parabolic flight literature, using published findings as anchor points to construct robust, continuous functions. To complement this quantitative analysis, we simulated subjective human experience under different gravitational loads, ranging from microgravity (0g) and partial gravity (Moon 0.17g, Mars 0.38g) to hypergravity associated with spacecraft launch and re-entry (1.8g), using a large language model (Claude 3.5 Sonnet). The model was prompted with physiological parameters to generate introspective narratives of alertness and self-awareness, which closely aligned with the quantitative findings from both the EEG and physiological models. This combined framework integrates quantitative physiological modeling with generative cognitive simulation, offering a novel approach to understanding and predicting human performance in altered gravity",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŒé‡è®¡ç®—æ¡†æ¶ï¼Œæ—¨åœ¨å®šé‡æ¨¡æ‹Ÿå’Œé¢„æµ‹äººç±»åœ¨ä¸åŒé‡åŠ›ç¯å¢ƒï¼ˆaltered gravityï¼‰ä¸‹çš„æ„è¯†ä¸ç”Ÿç†é€‚åº”æ€§ã€‚æ¡†æ¶çš„ç¬¬ä¸€éƒ¨åˆ†é‡‡ç”¨è½»é‡çº§å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ï¼Œæ ¹æ®é‡åŠ›è´Ÿè·ï¼ˆg-loadï¼‰é¢„æµ‹è„‘ç”µå›¾ï¼ˆEEGï¼‰é¢‘æ®µçš„å˜åŒ–ï¼Œä»¥æ­¤åæ˜ å¤§è„‘çš„çš®å±‚çŠ¶æ€ã€‚ç¬¬äºŒéƒ¨åˆ†åˆ©ç”¨ç‹¬ç«‹é«˜æ–¯è¿‡ç¨‹ï¼ˆGPsï¼‰å¯¹å¿ƒç‡å˜å¼‚æ€§ï¼ˆHRVï¼‰ã€çš®ç”µæ´»åŠ¨ï¼ˆEDAï¼‰åŠè¿åŠ¨è¡Œä¸ºç­‰ç”Ÿç†æŒ‡æ ‡è¿›è¡Œå»ºæ¨¡ï¼Œå…¶è®­ç»ƒæ•°æ®æºè‡ªå¯¹æŠ›ç‰©çº¿é£è¡Œï¼ˆparabolic flightï¼‰æ–‡çŒ®çš„å…¨é¢ç»¼è¿°ã€‚æ­¤å¤–ï¼Œç ”ç©¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰Claude 3.5 Sonnet æ¨¡æ‹Ÿäº†äººç±»åœ¨å¾®é‡åŠ›ï¼ˆmicrogravityï¼‰ã€éƒ¨åˆ†é‡åŠ›åŠè¶…é‡åŠ›ç¯å¢ƒä¸‹çš„ä¸»è§‚ä½“éªŒå™è¿°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM ç”Ÿæˆçš„è®¤çŸ¥æ¨¡æ‹Ÿä¸ EEG åŠç”Ÿç†æ¨¡å‹çš„å®šé‡å‘ç°é«˜åº¦ä¸€è‡´ã€‚è¿™ä¸€æ¡†æ¶æ•´åˆäº†å®šé‡ç”Ÿç†å»ºæ¨¡ä¸ç”Ÿæˆå¼è®¤çŸ¥æ¨¡æ‹Ÿï¼Œä¸ºç†è§£å’Œé¢„æµ‹äººç±»åœ¨éåœ°çƒé‡åŠ›ç¯å¢ƒä¸‹çš„è¡¨ç°æä¾›äº†åˆ›æ–°çš„ç ”ç©¶è·¯å¾„ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "q-bio.NC",
      "comment": "64 pages, 8 figures, 2 datasets, 1 protocol",
      "pdf_url": "https://arxiv.org/pdf/2511.05536v1",
      "published_date": "2025-10-29 17:41:07 UTC",
      "updated_date": "2025-10-29 17:41:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:37.958190+00:00"
    },
    {
      "arxiv_id": "2510.25819v1",
      "title": "Identity Management for Agentic AI: The new frontier of authorization, authentication, and security for an AI agent world",
      "title_zh": "æ™ºèƒ½ä½“ AI èº«ä»½ç®¡ç†ï¼šAI æ™ºèƒ½ä½“ä¸–ç•Œçš„æˆæƒã€è®¤è¯ä¸å®‰å…¨æ–°å‰æ²¿",
      "authors": [
        "Tobin South",
        "Subramanya Nagabhushanaradhya",
        "Ayesha Dissanayaka",
        "Sarah Cecchetti",
        "George Fletcher",
        "Victor Lu",
        "Aldo Pietropaolo",
        "Dean H. Saxe",
        "Jeff Lombardo",
        "Abhishek Maligehalli Shivalingaiah",
        "Stan Bounev",
        "Alex Keisner",
        "Andor Kesselman",
        "Zack Proser",
        "Ginny Fahs",
        "Andrew Bunyea",
        "Ben Moskowitz",
        "Atul Tulshibagwale",
        "Dazza Greenwood",
        "Jiaxin Pei",
        "Alex Pentland"
      ],
      "abstract": "The rapid rise of AI agents presents urgent challenges in authentication, authorization, and identity management. Current agent-centric protocols (like MCP) highlight the demand for clarified best practices in authentication and authorization. Looking ahead, ambitions for highly autonomous agents raise complex long-term questions regarding scalable access control, agent-centric identities, AI workload differentiation, and delegated authority. This OpenID Foundation whitepaper is for stakeholders at the intersection of AI agents and access management. It outlines the resources already available for securing today's agents and presents a strategic agenda to address the foundational authentication, authorization, and identity problems pivotal for tomorrow's widespread autonomous systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Agentic AI å¿«é€Ÿå…´èµ·å¸¦æ¥çš„ Authenticationã€Authorization å’Œèº«ä»½ç®¡ç†æ–¹é¢çš„ç´§è¿«æŒ‘æˆ˜ã€‚æ–‡ç« æŒ‡å‡ºï¼Œå½“å‰å¦‚ MCP ç­‰ä»¥æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒçš„åè®®å‡¸æ˜¾äº†å¯¹æ˜ç¡® Authentication å’Œ Authorization æœ€ä½³å®è·µçš„éœ€æ±‚ã€‚é’ˆå¯¹æœªæ¥é«˜åº¦è‡ªæ²»çš„æ™ºèƒ½ä½“ï¼Œç ”ç©¶æ·±å…¥åˆ†æäº†å¯æ‰©å±• Access Controlã€Agent-centric Identitiesã€AI Workload Differentiation ä»¥åŠ Delegated Authority ç­‰å¤æ‚çš„é•¿æœŸæ€§é—®é¢˜ã€‚ä½œä¸º OpenID Foundation å‘å¸ƒçš„ç™½çš®ä¹¦ï¼Œè¯¥æ–‡ä»¶ç³»ç»Ÿæ€§åœ°æ¦‚è¿°äº†å½“å‰ä¿éšœæ™ºèƒ½ä½“å®‰å…¨çš„å¯åˆ©ç”¨èµ„æºã€‚åŒæ—¶ï¼Œå®ƒæå‡ºäº†ä¸€å¥—æˆ˜ç•¥è®®ç¨‹ï¼Œæ—¨åœ¨è§£å†³æ”¯æ’‘æœªæ¥å¤§è§„æ¨¡è‡ªä¸»ç³»ç»Ÿè¿è¡Œçš„æ ¸å¿ƒèº«ä»½éªŒè¯ä¸æˆæƒéš¾é¢˜ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25819v1",
      "published_date": "2025-10-29 17:40:52 UTC",
      "updated_date": "2025-10-29 17:40:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:38.456780+00:00"
    },
    {
      "arxiv_id": "2510.25732v1",
      "title": "The Limits of Obliviate: Evaluating Unlearning in LLMs via Stimulus-Knowledge Entanglement-Behavior Framework",
      "title_zh": "Obliviate çš„å±€é™æ€§ï¼šåŸºäºâ€œåˆºæ¿€-çŸ¥è¯†çº ç¼ -è¡Œä¸ºâ€æ¡†æ¶çš„å¤§è¯­è¨€æ¨¡å‹æœºå™¨é—å¿˜è¯„ä¼°",
      "authors": [
        "Aakriti Shah",
        "Thai Le"
      ],
      "abstract": "Unlearning in large language models (LLMs) is crucial for managing sensitive data and correcting misinformation, yet evaluating its effectiveness remains an open problem. We investigate whether persuasive prompting can recall factual knowledge from deliberately unlearned LLMs across models ranging from 2.7B to 13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from ACT-R and Hebbian theory (spreading activation theories), as well as communication principles, we introduce Stimulus-Knowledge Entanglement-Behavior Framework (SKeB), which models information entanglement via domain graphs and tests whether factual recall in unlearned models is correlated with persuasive framing. We develop entanglement metrics to quantify knowledge activation patterns and evaluate factuality, non-factuality, and hallucination in outputs. Our results show persuasive prompts substantially enhance factual knowledge recall (14.8% baseline vs. 24.5% with authority framing), with effectiveness inversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB provides a foundation for assessing unlearning completeness, robustness, and overall behavior in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­å¸è½½(Unlearning)æ•ˆæœçš„è¯„ä¼°é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³æ•æ„Ÿæ•°æ®ç®¡ç†å’Œé”™è¯¯ä¿¡æ¯çº æ­£ä¸­çš„æŒ‘æˆ˜ã€‚ç ”ç©¶è€…åŸºäºACT-Rå’ŒHebbianç†è®ºæå‡ºäº†åˆºæ¿€-çŸ¥è¯†çº ç¼ -è¡Œä¸ºæ¡†æ¶(SKeB)ï¼Œåˆ©ç”¨é¢†åŸŸå›¾(domain graphs)å»ºæ¨¡ä¿¡æ¯çº ç¼ å¹¶å¼€å‘äº†é‡åŒ–çŸ¥è¯†æ¿€æ´»æ¨¡å¼çš„æŒ‡æ ‡ã€‚é€šè¿‡å¯¹OPTå’ŒLLaMAç³»åˆ—ä¸åŒå‚æ•°è§„æ¨¡çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œç ”ç©¶å‘ç°è¯´æœæ€§æç¤º(persuasive prompting)èƒ½æ˜¾è‘—å¬å›å·²å¸è½½çš„äº‹å®çŸ¥è¯†ï¼Œå…¶ä¸­æƒå¨æ¡†æ¶ä½¿å¬å›ç‡ä»14.8%æå‡è‡³24.5%ã€‚å®éªŒè¿›ä¸€æ­¥æ­ç¤ºäº†å¸è½½æœ‰æ•ˆæ€§ä¸æ¨¡å‹è§„æ¨¡ä¹‹é—´çš„è´Ÿç›¸å…³å…³ç³»ï¼Œå³å°å‚æ•°æ¨¡å‹åœ¨çŸ¥è¯†æ¢å¤æ–¹é¢è¡¨ç°æ›´ä¸ºæ˜¾è‘—ã€‚è¯¥ç ”ç©¶é€šè¿‡SKeBæ¡†æ¶ä¸ºè¯„ä¼°LLMså¸è½½æŠ€æœ¯çš„å®Œæ•´æ€§ã€ç¨³å¥æ€§åŠè¡Œä¸ºè¡¨ç°å¥ å®šäº†ç§‘å­¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25732v1",
      "published_date": "2025-10-29 17:37:50 UTC",
      "updated_date": "2025-10-29 17:37:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:48.459783+00:00"
    },
    {
      "arxiv_id": "2510.25731v1",
      "title": "LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries",
      "title_zh": "LieSolverï¼šåŸºäºæå¯¹ç§°æ€§çš„åˆè¾¹å€¼é—®é¢˜åå¾®åˆ†æ–¹ç¨‹çº¦æŸæ±‚è§£å™¨",
      "authors": [
        "RenÃ© P. Klausen",
        "Ivan Timofeev",
        "Johannes Frank",
        "Jonas Naujoks",
        "Thomas Wiegand",
        "Sebastian Lapuschkin",
        "Wojciech Samek"
      ],
      "abstract": "We introduce a method for efficiently solving initial-boundary value problems (IBVPs) that uses Lie symmetries to enforce the associated partial differential equation (PDE) exactly by construction. By leveraging symmetry transformations, the model inherently incorporates the physical laws and learns solutions from initial and boundary data. As a result, the loss directly measures the model's accuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our method enables rigorous error estimation. The approach yields compact models, facilitating an efficient optimization. We implement LieSolver and demonstrate its application to linear homogeneous PDEs with a range of initial conditions, showing that it is faster and more accurate than physics-informed neural networks (PINNs). Overall, our method improves both computational efficiency and the reliability of predictions for PDE-constrained problems.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† LieSolverï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ Lie symmetries é«˜æ•ˆæ±‚è§£åˆè¾¹å€¼é—®é¢˜ (IBVPs) çš„æ–¹æ³•ï¼Œé€šè¿‡æ„é€ ç›´æ¥ä¸”ç²¾ç¡®åœ°å¼ºåˆ¶æ‰§è¡Œåå¾®åˆ†æ–¹ç¨‹ (PDE) çº¦æŸã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¯¹ç§°å˜æ¢å°†ç‰©ç†å®šå¾‹å†…åœ¨èå…¥æ¨¡å‹ï¼Œå¹¶ç›´æ¥ä»åˆå§‹å’Œè¾¹ç•Œæ•°æ®ä¸­å­¦ä¹ è§£ï¼Œä½¿å¾—æŸå¤±å‡½æ•°èƒ½å¤Ÿç›´æ¥è¡¡é‡æ¨¡å‹çš„å‡†ç¡®æ€§å¹¶æ˜¾è‘—æé«˜æ”¶æ•›é€Ÿåº¦ã€‚å¯¹äºé€‚å®šæ€§ (well-posed) çš„ IBVPsï¼ŒLieSolver èƒ½å¤Ÿå®ç°ä¸¥å¯†çš„è¯¯å·®ä¼°è®¡ï¼Œå¹¶é€šè¿‡ç”Ÿæˆç´§å‡‘çš„æ¨¡å‹æ¥å®ç°é«˜æ•ˆä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤„ç†å…·æœ‰å¤šç§åˆå§‹æ¡ä»¶çš„çº¿æ€§é½æ¬¡åå¾®åˆ†æ–¹ç¨‹æ—¶ï¼ŒLieSolver åœ¨é€Ÿåº¦å’Œç²¾åº¦ä¸Šå‡ä¼˜äºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ (PINNs)ã€‚æ€»çš„æ¥è¯´ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæå‡äº†åå¾®åˆ†æ–¹ç¨‹çº¦æŸé—®é¢˜çš„è®¡ç®—æ•ˆç‡å’Œé¢„æµ‹ç»“æœçš„å¯é æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25731v1",
      "published_date": "2025-10-29 17:37:27 UTC",
      "updated_date": "2025-10-29 17:37:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:45.564123+00:00"
    },
    {
      "arxiv_id": "2510.25729v1",
      "title": "Physics-Guided Conditional Diffusion Networks for Microwave Image Reconstruction",
      "title_zh": "ç”¨äºå¾®æ³¢å›¾åƒé‡å»ºçš„ç‰©ç†å¼•å¯¼æ¡ä»¶æ‰©æ•£ç½‘ç»œ",
      "authors": [
        "Shirin Chehelgami",
        "Joe LoVetri",
        "Vahab Khoshdel"
      ],
      "abstract": "A conditional latent-diffusion based framework for solving the electromagnetic inverse scattering problem associated with microwave imaging is introduced. This generative machine-learning model explicitly mirrors the non-uniqueness of the ill-posed inverse problem. Unlike existing inverse solvers utilizing deterministic machine learning techniques that produce a single reconstruction, the proposed latent-diffusion model generates multiple plausible permittivity maps conditioned on measured scattered-field data, thereby generating several potential instances in the range-space of the non-unique inverse mapping. A forward electromagnetic solver is integrated into the reconstruction pipeline as a physics-based evaluation mechanism. The space of candidate reconstructions form a distribution of possibilities consistent with the conditioning data and the member of this space yielding the lowest scattered-field data discrepancy between the predicted and measured scattered fields is reported as the final solution. Synthetic and experimental labeled datasets are used for training and evaluation of the model. An innovative labeled synthetic dataset is created that exemplifies a varied set of scattering features. Training of the model using this new dataset produces high quality permittivity reconstructions achieving improved generalization with excellent fidelity to shape recognition. The results highlight the potential of hybrid generative physics frameworks as a promising direction for robust, data-driven microwave imaging.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ¡ä»¶æ½œæ‰©æ•£(Conditional Latent-Diffusion)çš„æ¨¡å‹æ¡†æ¶ï¼Œç”¨äºè§£å†³å¾®æ³¢æˆåƒä¸­çš„ç”µç£é€†æ•£å°„(Electromagnetic Inverse Scattering)é—®é¢˜ã€‚è¯¥ç”Ÿæˆå¼æ¨¡å‹é€šè¿‡ç”Ÿæˆå¤šä¸ªå¯èƒ½çš„ä»‹ç”µå¸¸æ•°å›¾(Permittivity Maps)ï¼Œæœ‰æ•ˆåº”å¯¹äº†é€†é—®é¢˜å›ºæœ‰çš„ç—…æ€æ€§å’Œéå”¯ä¸€æ€§ã€‚æ¡†æ¶ä¸­é›†æˆäº†ä¸€ä¸ªæ­£å‘ç”µç£æ±‚è§£å™¨(Forward Electromagnetic Solver)ä½œä¸ºç‰©ç†è¯„ä¼°æœºåˆ¶ï¼Œç”¨äºåœ¨å€™é€‰é‡å»ºç»“æœä¸­è¿›è¡Œç­›é€‰ã€‚æœ€ç»ˆè§£ä»æ»¡è¶³æµ‹é‡æ•°æ®ä¸€è‡´æ€§çš„åˆ†å¸ƒä¸­é€‰å–ï¼Œé€šè¿‡æœ€å°åŒ–é¢„æµ‹æ•£å°„åœºä¸å®æµ‹æ•£å°„åœºä¹‹é—´çš„åå·®æ¥ç¡®å®šã€‚ç ”ç©¶å›¢é˜Ÿè¿˜æ„å»ºäº†ä¸€ä¸ªå…·æœ‰å¤šæ ·åŒ–ç‰¹å¾çš„åˆ›æ–°åˆæˆæ•°æ®é›†ï¼Œå¹¶ç»“åˆå®éªŒæ•°æ®å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å½¢çŠ¶è¯†åˆ«ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå±•ç°äº†æ··åˆç”Ÿæˆç‰©ç†æ¡†æ¶(Hybrid Generative Physics Frameworks)åœ¨ç¨³å¥å¾®æ³¢æˆåƒé¢†åŸŸçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25729v1",
      "published_date": "2025-10-29 17:34:10 UTC",
      "updated_date": "2025-10-29 17:34:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:46.766103+00:00"
    },
    {
      "arxiv_id": "2510.25726v1",
      "title": "The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution",
      "title_zh": "Tool Decathlonï¼šé¢å‘å¤šæ ·åŒ–ã€çœŸå®åŠé•¿ç¨‹ä»»åŠ¡æ‰§è¡Œçš„è¯­è¨€æ™ºèƒ½ä½“è¯„æµ‹åŸºå‡†",
      "authors": [
        "Junlong Li",
        "Wenshuo Zhao",
        "Jian Zhao",
        "Weihao Zeng",
        "Haoze Wu",
        "Xiaochen Wang",
        "Rui Ge",
        "Yuxuan Cao",
        "Yuzhen Huang",
        "Wei Liu",
        "Junteng Liu",
        "Zhaochen Su",
        "Yiyang Guo",
        "Fan Zhou",
        "Lueyang Zhang",
        "Juan Michelini",
        "Xingyao Wang",
        "Xiang Yue",
        "Shuyan Zhou",
        "Graham Neubig",
        "Junxian He"
      ],
      "abstract": "Real-world language agents must handle complex, multi-step workflows across diverse Apps. For instance, an agent may manage emails by coordinating with calendars and file systems, or monitor a production database to detect anomalies and generate reports following an operating manual. However, existing language agent benchmarks often focus on narrow domains or simplified tasks that lack the diversity, realism, and long-horizon complexity required to evaluate agents' real-world performance. To address this gap, we introduce the Tool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering diverse Apps and tools, realistic environment setup, and reliable execution-based evaluation. Toolathlon spans 32 software applications and 604 tools, ranging from everyday platforms such as Google Calendar and Notion to professional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools are based on a high-quality set of Model Context Protocol (MCP) servers that we may have revised or implemented ourselves. Unlike prior works, which primarily ensure functional realism but offer limited environment state diversity, we provide realistic initial environment states from real software, such as Canvas courses with dozens of students or real financial spreadsheets. This benchmark includes 108 manually sourced or crafted tasks in total, requiring interacting with multiple Apps over around 20 turns on average to complete. Each task is strictly verifiable through dedicated evaluation scripts. Comprehensive evaluation of SOTA models highlights their significant shortcomings: the best-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate with 20.2 tool calling turns on average, while the top open-weights model DeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development of more capable language agents for real-world, long-horizon task execution.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Tool Decathlonï¼ˆç®€ç§° Toolathlonï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è¯­è¨€æ™ºèƒ½ä½“åœ¨å¤šæ ·åŒ–ã€çœŸå®ä¸”é•¿ç¨‹ä»»åŠ¡ä¸­æ‰§è¡Œèƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚é’ˆå¯¹ç°æœ‰åŸºå‡†æµ‹è¯•é¢†åŸŸç‹­çª„ã€ä»»åŠ¡ç®€åŒ–ä¸”ç¼ºä¹ç°å®å¤æ‚æ€§çš„é—®é¢˜ï¼ŒToolathlon æ¶µç›–äº† 32 ä¸ªè½¯ä»¶åº”ç”¨ç¨‹åºå’Œ 604 ä¸ªå·¥å…·ï¼ŒåŒ…æ‹¬ Google Calendarã€Notionã€Kubernetes å’Œ BigQuery ç­‰æ—¥å¸¸åŠä¸“ä¸šå¹³å°ã€‚è¯¥åŸºå‡†ä¸»è¦åŸºäºé«˜è´¨é‡çš„ Model Context Protocol (MCP) æœåŠ¡å™¨ï¼Œå¹¶æä¾›äº†æ¥è‡ªçœŸå®è½¯ä»¶çš„åˆå§‹ç¯å¢ƒçŠ¶æ€ï¼Œä»¥ç¡®ä¿ç¯å¢ƒçŠ¶æ€çš„å¤šæ ·æ€§ã€‚Toolathlon åŒ…å« 108 ä¸ªæ‰‹åŠ¨è®¾è®¡çš„ä»»åŠ¡ï¼Œå¹³å‡éœ€è¦çº¦ 20 è½®äº¤äº’æ‰èƒ½å®Œæˆï¼Œä¸”æ¯ä¸ªä»»åŠ¡éƒ½é€šè¿‡ä¸“ç”¨çš„è¯„ä¼°è„šæœ¬è¿›è¡Œä¸¥æ ¼çš„åŸºäºæ‰§è¡Œçš„éªŒè¯ã€‚å¯¹å½“å‰ SOTA æ¨¡å‹çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¡¨ç°æœ€å¥½çš„ Claude-4.5-Sonnet æˆåŠŸç‡ä»…ä¸º 38.6%ï¼Œè€Œå¼€æºæ¨¡å‹ DeepSeek-V3.2-Exp çš„æˆåŠŸç‡ä¸º 20.1%ã€‚è¯¥ç ”ç©¶çªæ˜¾äº†ç°æœ‰æ¨¡å‹åœ¨å¤„ç†çœŸå®é•¿ç¨‹ä»»åŠ¡æ—¶çš„æ˜¾è‘—ç¼ºé™·ï¼Œä¸ºæœªæ¥æ›´å…·å®ç”¨èƒ½åŠ›çš„è¯­è¨€æ™ºèƒ½ä½“å¼€å‘å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Website: https://toolathlon.xyz/",
      "pdf_url": "https://arxiv.org/pdf/2510.25726v1",
      "published_date": "2025-10-29 17:32:49 UTC",
      "updated_date": "2025-10-29 17:32:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:53.476527+00:00"
    },
    {
      "arxiv_id": "2511.00078v1",
      "title": "RailEstate: An Interactive System for Metro Linked Property Trends",
      "title_zh": "RailEstateï¼šåœ°é“å…³è”æˆ¿äº§è¶‹åŠ¿äº¤äº’ç³»ç»Ÿ",
      "authors": [
        "Chen-Wei Chang",
        "Yu-Chieh Cheng",
        "Yun-En Tsai",
        "Fanglan Chen",
        "Chang-Tien Lu"
      ],
      "abstract": "Access to metro systems plays a critical role in shaping urban housing markets by enhancing neighborhood accessibility and driving property demand. We present RailEstate, a novel web based system that integrates spatial analytics, natural language interfaces, and interactive forecasting to analyze how proximity to metro stations influences residential property prices in the Washington metropolitan area. Unlike static mapping tools or generic listing platforms, RailEstate combines 25 years of historical housing data with transit infrastructure to support low latency geospatial queries, time series visualizations, and predictive modeling. Users can interactively explore ZIP code level price patterns, investigate long term trends, and forecast future housing values around any metro station. A key innovation is our natural language chatbot, which translates plain-English questions e.g., What is the highest price in Falls Church in the year 2000? into executable SQL over a spatial database. This unified and interactive platform empowers urban planners, investors, and residents to derive actionable insights from metro linked housing data without requiring technical expertise.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†RailEstateï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ›æ–°çš„åŸºäºWebçš„äº¤äº’å¼ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºåˆ†æåç››é¡¿å¤§éƒ½ä¼šåŒºåœ°é“ç«™é‚»è¿‘æ€§å¯¹ä½å®…æˆ¿åœ°äº§ä»·æ ¼çš„å½±å“ã€‚RailEstateæ•´åˆäº†ç©ºé—´åˆ†æã€è‡ªç„¶è¯­è¨€æ¥å£å’Œäº¤äº’å¼é¢„æµ‹åŠŸèƒ½ï¼Œå¹¶ç»“åˆäº†é•¿è¾¾25å¹´çš„å†å²ä½æˆ¿æ•°æ®ä¸è½¨é“äº¤é€šåŸºç¡€è®¾æ–½ä¿¡æ¯ã€‚ç³»ç»Ÿçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶å†…ç½®çš„è‡ªç„¶è¯­è¨€èŠå¤©æœºå™¨äººï¼Œèƒ½å¤Ÿå°†æ™®é€šè‹±è¯­é—®é¢˜è½¬æ¢ä¸ºåœ¨ç©ºé—´æ•°æ®åº“ä¸Šæ‰§è¡Œçš„SQLæŸ¥è¯¢ï¼Œæå¤§åœ°é™ä½äº†éæŠ€æœ¯ç”¨æˆ·çš„æ“ä½œé—¨æ§›ã€‚é€šè¿‡æ”¯æŒä½å»¶è¿Ÿçš„åœ°ç†ç©ºé—´æŸ¥è¯¢å’Œæ—¶é—´åºåˆ—å¯è§†åŒ–ï¼Œè¯¥å¹³å°å…è®¸ç”¨æˆ·æ¢ç´¢ZIP codeçº§åˆ«çš„ä»·æ ¼æ¨¡å¼ï¼Œå¹¶é¢„æµ‹ç‰¹å®šåœ°é“ç«™å‘¨è¾¹çš„æœªæ¥æˆ¿ä»·è¶‹åŠ¿ã€‚RailEstateä¸ºåŸå¸‚è§„åˆ’è€…ã€æŠ•èµ„è€…å’Œå±…æ°‘æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„å¹³å°ï¼Œä½¿ä»–ä»¬èƒ½å¤Ÿä»ä¸åœ°é“ç›¸å…³çš„ä½æˆ¿æ•°æ®ä¸­è·å–å…·æœ‰è¡ŒåŠ¨ä»·å€¼çš„æ´å¯Ÿã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.00078v1",
      "published_date": "2025-10-29 17:32:09 UTC",
      "updated_date": "2025-10-29 17:32:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:54.171319+00:00"
    },
    {
      "arxiv_id": "2510.25724v1",
      "title": "BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph",
      "title_zh": "BambooKGï¼šå—ç¥ç»ç”Ÿç‰©å­¦å¯å‘çš„é¢‘ç‡åŠ æƒçŸ¥è¯†å›¾è°±",
      "authors": [
        "Vanya Arikutharam",
        "Arkadiy Ukolov"
      ],
      "abstract": "Retrieval-Augmented Generation allows LLMs to access external knowledge, reducing hallucinations and ageing-data issues. However, it treats retrieved chunks independently and struggles with multi-hop or relational reasoning, especially across documents. Knowledge graphs enhance this by capturing the relationships between entities using triplets, enabling structured, multi-chunk reasoning. However, these tend to miss information that fails to conform to the triplet structure. We introduce BambooKG, a knowledge graph with frequency-based weights on non-triplet edges which reflect link strength, drawing on the Hebbian principle of \"fire together, wire together\". This decreases information loss and results in improved performance on single- and multi-hop reasoning, outperforming the existing solutions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation)åœ¨å¤„ç†å¤šè·³æ¨ç†(multi-hop reasoning)ä»¥åŠéä¸‰å…ƒç»„ç»“æ„å…³ç³»æ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº† BambooKGï¼Œä¸€ç§å—ç¥ç»ç”Ÿç‰©å­¦å¯å‘çš„é¢‘ç‡åŠ æƒçŸ¥è¯†å›¾è°±ã€‚è¯¥æ¡†æ¶å€Ÿé‰´äº†èµ«å¸ƒç†è®º(Hebbian principle)ä¸­â€œå…±åŒæ”¾ç”µï¼Œå…±åŒè¿ç»“â€çš„åŸåˆ™ï¼Œé€šè¿‡åœ¨éä¸‰å…ƒç»„è¾¹(non-triplet edges)ä¸Šå¼•å…¥åŸºäºé¢‘ç‡çš„æƒé‡æ¥ä½“ç°è¿æ¥å¼ºåº¦ã€‚è¿™ç§è®¾è®¡æœ‰æ•ˆé™ä½äº†ä¼ ç»ŸçŸ¥è¯†å›¾è°±åœ¨ä¿¡æ¯è½¬åŒ–è¿‡ç¨‹ä¸­çš„æŸè€—ï¼Œä½¿å…¶èƒ½å¤Ÿæ•æ‰ä¸ç¬¦åˆæ ‡å‡†ä¸‰å…ƒç»„(triplets)æ ¼å¼çš„å…³é”®å…³è”ã€‚å®éªŒè¯æ˜ï¼ŒBambooKG åœ¨å•è·³å’Œå¤šè·³æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½è¡¨ç°å‡ä¼˜äºç°æœ‰è§£å†³æ–¹æ¡ˆï¼Œæ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿåœ¨è·¨æ–‡æ¡£æƒ…å¢ƒä¸‹çš„ç»“æ„åŒ–æ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25724v1",
      "published_date": "2025-10-29 17:31:27 UTC",
      "updated_date": "2025-10-29 17:31:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:22:56.553317+00:00"
    },
    {
      "arxiv_id": "2510.25818v1",
      "title": "ScaleDiff: Higher-Resolution Image Synthesis via Efficient and Model-Agnostic Diffusion",
      "title_zh": "ScaleDiffï¼šåŸºäºé«˜æ•ˆä¸”æ¨¡å‹æ— å…³æ‰©æ•£çš„é«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆ",
      "authors": [
        "Sungho Koh",
        "SeungJu Cha",
        "Hyunwoo Oh",
        "Kwanyoung Lee",
        "Dong-Jin Kim"
      ],
      "abstract": "Text-to-image diffusion models often exhibit degraded performance when generating images beyond their training resolution. Recent training-free methods can mitigate this limitation, but they often require substantial computation or are incompatible with recent Diffusion Transformer models. In this paper, we propose ScaleDiff, a model-agnostic and highly efficient framework for extending the resolution of pretrained diffusion models without any additional training. A core component of our framework is Neighborhood Patch Attention (NPA), an efficient mechanism that reduces computational redundancy in the self-attention layer with non-overlapping patches. We integrate NPA into an SDEdit pipeline and introduce Latent Frequency Mixing (LFM) to better generate fine details. Furthermore, we apply Structure Guidance to enhance global structure during the denoising process. Experimental results demonstrate that ScaleDiff achieves state-of-the-art performance among training-free methods in terms of both image quality and inference speed on both U-Net and Diffusion Transformer architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ScaleDiffï¼Œä¸€ä¸ªæ— éœ€é¢å¤–è®­ç»ƒä¸”å…·æœ‰æ¨¡å‹æ— å…³æ€§çš„é«˜æ•ˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆè¶…å‡ºè®­ç»ƒåˆ†è¾¨ç‡çš„å›¾åƒæ—¶æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚å…¶æ ¸å¿ƒç»„ä»¶ Neighborhood Patch Attention (NPA) é€šè¿‡éé‡å è¡¥ä¸æ˜¾è‘—å‡å°‘äº†è‡ªæ³¨æ„åŠ›å±‚çš„è®¡ç®—å†—ä½™ã€‚ç ”ç©¶å›¢é˜Ÿå°† NPA é›†æˆè‡³ SDEdit æµæ°´çº¿ä¸­ï¼Œå¹¶å¼•å…¥ Latent Frequency Mixing (LFM) ä»¥å¢å¼ºç»†èŠ‚ç”Ÿæˆï¼ŒåŒæ—¶åˆ©ç”¨ Structure Guidance ä¼˜åŒ–å»å™ªè¿‡ç¨‹ä¸­çš„å…¨å±€ç»“æ„ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒScaleDiff åœ¨ U-Net å’Œ Diffusion Transformer æ¶æ„ä¸Šå‡è¾¾åˆ°äº†åŒç±» training-free æ–¹æ³•ä¸­çš„é¢†å…ˆæ°´å¹³ï¼Œå…¼é¡¾äº†å›¾åƒè´¨é‡ä¸æ¨ç†é€Ÿåº¦ã€‚è¯¥æ–¹æ¡ˆä¸ºå®ç°é«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”é€šç”¨çš„é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025. Code: https://github.com/KSH00906/ScaleDiff",
      "pdf_url": "https://arxiv.org/pdf/2510.25818v1",
      "published_date": "2025-10-29 17:17:32 UTC",
      "updated_date": "2025-10-29 17:17:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:02.258572+00:00"
    },
    {
      "arxiv_id": "2511.08592v1",
      "title": "The Collective Turing Test: Large Language Models Can Generate Realistic Multi-User Discussions",
      "title_zh": "é›†ä½“å›¾çµæµ‹è¯•ï¼šå¤§è¯­è¨€æ¨¡å‹å¯ç”Ÿæˆé€¼çœŸçš„å¤šç”¨æˆ·è®¨è®º",
      "authors": [
        "Azza Bouleimen",
        "Giordano De Marzo",
        "Taehee Kim",
        "Nicol`o Pagan",
        "Hannah Metzler",
        "Silvia Giordano",
        "David Garcia"
      ],
      "abstract": "Large Language Models (LLMs) offer new avenues to simulate online communities and social media. Potential applications range from testing the design of content recommendation algorithms to estimating the effects of content policies and interventions. However, the validity of using LLMs to simulate conversations between various users remains largely untested. We evaluated whether LLMs can convincingly mimic human group conversations on social media. We collected authentic human conversations from Reddit and generated artificial conversations on the same topic with two LLMs: Llama 3 70B and GPT-4o. When presented side-by-side to study participants, LLM-generated conversations were mistaken for human-created content 39\\% of the time. In particular, when evaluating conversations generated by Llama 3, participants correctly identified them as AI-generated only 56\\% of the time, barely better than random chance. Our study demonstrates that LLMs can generate social media conversations sufficiently realistic to deceive humans when reading them, highlighting both a promising potential for social simulation and a warning message about the potential misuse of LLMs to generate new inauthentic social media content.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ¨¡æ‹Ÿç¤¾äº¤åª’ä½“å¤šç”¨æˆ·å¯¹è¯çš„çœŸå®æ€§ï¼Œæ—¨åœ¨è¯„ä¼°AIç”Ÿæˆå†…å®¹å¯¹äººç±»çš„è¯¯å¯¼ç¨‹åº¦ã€‚ç ”ç©¶å›¢é˜Ÿä»Redditè·å–çœŸå®å¯¹è¯ï¼Œå¹¶ä½¿ç”¨Llama 3 70Bå’ŒGPT-4oé’ˆå¯¹ç›¸åŒè¯é¢˜ç”Ÿæˆè™šæ„å¯¹è¯ï¼Œéšåç”±å—è¯•è€…è¿›è¡ŒåŒç›²è¾¨æã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œäººç±»åœ¨39%çš„æƒ…å†µä¸‹ä¼šå°†LLMsç”Ÿæˆçš„å¯¹è¯è¯¯è®¤ä¸ºçœŸå®å†…å®¹ï¼Œè€Œåœ¨è¯„ä¼°Llama 3ç”Ÿæˆçš„å¯¹è¯æ—¶ï¼Œå‚ä¸è€…çš„æ­£ç¡®è¯†åˆ«ç‡ä»…ä¸º56%ï¼Œå‡ ä¹ç­‰åŒäºéšæœºçŒœæµ‹ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†LLMsèƒ½å¤Ÿç”Ÿæˆæå…·è¿·æƒ‘æ€§çš„ç¤¾äº¤åª’ä½“äº’åŠ¨å†…å®¹ï¼Œåœ¨å±•ç¤ºç¤¾äº¤æ¨¡æ‹Ÿ(social simulation)å·¨å¤§æ½œåŠ›çš„åŒæ—¶ï¼Œä¹Ÿå¯¹æ¨¡å‹å¯èƒ½è¢«è¯¯ç”¨äºåˆ¶é€ è™šå‡ç¤¾äº¤å†…å®¹å‘å‡ºäº†ä¸¥æ­£é¢„è­¦ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.08592v1",
      "published_date": "2025-10-29 17:01:20 UTC",
      "updated_date": "2025-10-29 17:01:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:06.872842+00:00"
    },
    {
      "arxiv_id": "2510.25694v1",
      "title": "Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents",
      "title_zh": "è½¯ä»¶å·¥ç¨‹æ™ºèƒ½ä½“ç¯å¢ƒé…ç½®çš„è¿‡ç¨‹çº§è½¨è¿¹è¯„ä¼°",
      "authors": [
        "Jiayi Kuang",
        "Yinghui Li",
        "Xin Zhang",
        "Yangning Li",
        "Di Yin",
        "Xing Sun",
        "Ying Shen",
        "Philip S. Yu"
      ],
      "abstract": "Large language model-based agents show promise for software engineering, but environment configuration remains a bottleneck due to heavy manual effort and scarce large-scale, high-quality datasets. Existing benchmarks assess only end-to-end build/test success, obscuring where and why agents succeed or fail. We introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench, which provides process-level trajectory assessment of fine-grained agent capabilities during environment setup-planning, perception-driven error diagnosis, feedback-driven repair, and action to execute final environment configuration. Our task instances are automatically constructed by injecting realistic README errors and are validated in Docker for scalable, high-quality evaluation. Enconda-bench combines process-level analysis with end-to-end executability to enable capability assessments beyond aggregate success rates. Evaluations across state-of-the-art LLMs and agent frameworks show that while agents can localize errors, they struggle to translate feedback into effective corrections, limiting end-to-end performance. To our knowledge, Enconda-bench is the first framework to provide process-level internal capability assessment for environment configuration, offering actionable insights for improving software engineering agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ™ºèƒ½ä½“åœ¨è½¯ä»¶å·¥ç¨‹ç¯å¢ƒé…ç½®ä¸­é¢ä¸´çš„æ‰‹åŠ¨æˆæœ¬é«˜å’Œé«˜è´¨é‡æ•°æ®é›†ç¨€ç¼ºç­‰ç“¶é¢ˆï¼Œæå‡ºäº†åä¸ºEnconda-benchçš„è¿‡ç¨‹çº§è½¨è¿¹è¯„ä¼°åŸºå‡†ã€‚ä¸åŒäºä»…å…³æ³¨ç«¯åˆ°ç«¯æ„å»ºæˆ–æµ‹è¯•æˆåŠŸç‡çš„ç°æœ‰è¯„ä¼°æ–¹æ³•ï¼ŒEnconda-bench èƒ½å¤Ÿå¯¹æ™ºèƒ½ä½“åœ¨ç¯å¢ƒæ­å»ºè¿‡ç¨‹ä¸­çš„è§„åˆ’(planning)ã€æ„ŸçŸ¥é©±åŠ¨çš„é”™è¯¯è¯Šæ–­(perception-driven error diagnosis)ã€åé¦ˆé©±åŠ¨çš„ä¿®å¤(feedback-driven repair)ä»¥åŠæœ€ç»ˆé…ç½®æ‰§è¡Œç­‰ç»†ç²’åº¦èƒ½åŠ›è¿›è¡Œè¯„ä¼°ã€‚è¯¥åŸºå‡†é€šè¿‡æ³¨å…¥çœŸå®çš„READMEé”™è¯¯è‡ªåŠ¨æ„å»ºä»»åŠ¡å®ä¾‹ï¼Œå¹¶åˆ©ç”¨Dockerç¯å¢ƒè¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿äº†è¯„ä¼°çš„é«˜è´¨é‡ä¸å¯æ‰©å±•æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡ç›®å‰çš„å…ˆè¿›LLMå’Œæ™ºèƒ½ä½“æ¡†æ¶èƒ½å¤Ÿå®šä½é”™è¯¯ï¼Œä½†åœ¨å°†åé¦ˆè½¬åŒ–ä¸ºæœ‰æ•ˆä¿®æ­£æªæ–½æ–¹é¢ä»å­˜åœ¨æ˜æ˜¾çŸ­æ¿ï¼Œè¿™ç›´æ¥é™åˆ¶äº†å…¶ç«¯åˆ°ç«¯çš„æ•´ä½“æ€§èƒ½ã€‚ä½œä¸ºé¦–ä¸ªé’ˆå¯¹ç¯å¢ƒé…ç½®æä¾›å†…éƒ¨è¿‡ç¨‹èƒ½åŠ›è¯„ä¼°çš„æ¡†æ¶ï¼ŒEnconda-bench ä¸ºä¼˜åŒ–å’Œæå‡è½¯ä»¶å·¥ç¨‹æ™ºèƒ½ä½“æä¾›äº†å…·æœ‰å®é™…æŒ‡å¯¼æ„ä¹‰çš„è§è§£ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25694v1",
      "published_date": "2025-10-29 16:59:07 UTC",
      "updated_date": "2025-10-29 16:59:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:18.687163+00:00"
    },
    {
      "arxiv_id": "2510.25683v1",
      "title": "Graph Network-based Structural Simulator: Graph Neural Networks for Structural Dynamics",
      "title_zh": "åŸºäºå›¾ç½‘ç»œçš„ç»“æ„æ¨¡æ‹Ÿå™¨ï¼šé¢å‘ç»“æ„åŠ¨åŠ›å­¦çš„å›¾ç¥ç»ç½‘ç»œ",
      "authors": [
        "Alessandro Lucchetti",
        "Francesco Cadini",
        "Marco Giglio",
        "Luca Lomazzi"
      ],
      "abstract": "Graph Neural Networks (GNNs) have recently been explored as surrogate models for numerical simulations. While their applications in computational fluid dynamics have been investigated, little attention has been given to structural problems, especially for dynamic cases. To address this gap, we introduce the Graph Network-based Structural Simulator (GNSS), a GNN framework for surrogate modeling of dynamic structural problems.\n  GNSS follows the encode-process-decode paradigm typical of GNN-based machine learning models, and its design makes it particularly suited for dynamic simulations thanks to three key features: (i) expressing node kinematics in node-fixed local frames, which avoids catastrophic cancellation in finite-difference velocities; (ii) employing a sign-aware regression loss, which reduces phase errors in long rollouts; and (iii) using a wavelength-informed connectivity radius, which optimizes graph construction.\n  We evaluate GNSS on a case study involving a beam excited by a 50kHz Hanning-modulated pulse. The results show that GNSS accurately reproduces the physics of the problem over hundreds of timesteps and generalizes to unseen loading conditions, where existing GNNs fail to converge or deliver meaningful predictions.\n  Compared with explicit finite element baselines, GNSS achieves substantial inference speedups while preserving spatial and temporal fidelity. These findings demonstrate that locality-preserving GNNs with physics-consistent update rules are a competitive alternative for dynamic, wave-dominated structural simulations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Graph Network-based Structural Simulator (GNSS)ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºåŠ¨æ€ç»“æ„é—®é¢˜ä»£ç†å»ºæ¨¡çš„å›¾ç¥ç»ç½‘ç»œ(GNN)æ¡†æ¶ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸåœ¨ç»“æ„åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæ–¹é¢çš„ç©ºç™½ã€‚GNSS éµå¾ªå…¸å‹çš„ç¼–ç -å¤„ç†-è§£ç (encode-process-decode)èŒƒå¼ï¼Œå¹¶é€šè¿‡åœ¨èŠ‚ç‚¹å›ºå®šå±€éƒ¨åæ ‡ç³»(node-fixed local frames)ä¸­è¡¨è¾¾è¿åŠ¨å­¦ã€é‡‡ç”¨ç¬¦å·æ„ŸçŸ¥å›å½’æŸå¤±(sign-aware regression loss)ä»¥åŠåˆ©ç”¨æ³¢é•¿æ„ŸçŸ¥è¿æ¥åŠå¾„(wavelength-informed connectivity radius)è¿™ä¸‰å¤§æ ¸å¿ƒç‰¹æ€§ï¼Œæœ‰æ•ˆè§£å†³äº†æ•°å€¼æ¨¡æ‹Ÿä¸­çš„ç²¾åº¦ä¸ç›¸ä½è¯¯å·®é—®é¢˜ã€‚åœ¨é’ˆå¯¹å—è„‰å†²æ¿€åŠ±æ³¢åŠ¨çš„æ¢æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼ŒGNSS èƒ½å¤Ÿåœ¨æ•°ç™¾ä¸ªæ—¶é—´æ­¥å†…å‡†ç¡®é‡ç°ç‰©ç†è¿‡ç¨‹ï¼Œå¹¶å±•ç°å‡ºä¼˜äºç°æœ‰ GNN æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„æ˜¾å¼æœ‰é™å…ƒ(finite element)åŸºå‡†ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶åœ¨ä¿æŒé«˜æ—¶ç©ºä¿çœŸåº¦çš„å‰æä¸‹æ˜¾è‘—æå‡äº†æ¨ç†é€Ÿåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆç‰©ç†ä¸€è‡´æ€§æ›´æ–°è§„åˆ™çš„å±€éƒ¨ä¿æŒ GNN ä¸ºå¤„ç†åŠ¨æ€ä¸”æ³¢åŠ¨ä¸»å¯¼çš„ç»“æ„æ¨¡æ‹Ÿæä¾›äº†ä¸€ç§æå…·ç«äº‰åŠ›çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25683v1",
      "published_date": "2025-10-29 16:47:24 UTC",
      "updated_date": "2025-10-29 16:47:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:32.870645+00:00"
    },
    {
      "arxiv_id": "2510.25679v1",
      "title": "Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning",
      "title_zh": "åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ä¸‰ç»´åŸå¸‚æµåœºå¯¼èˆª",
      "authors": [
        "Federica Tonti",
        "Ricardo Vinuesa"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for delivery and surveillance purposes. In this work, we develop an optimal navigation strategy based on Deep Reinforcement Learning. The environment is represented by a three-dimensional high-fidelity simulation of an urban flow, characterized by turbulence and recirculation zones. The algorithm presented here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated Transformer eXtra Large (GTrXL) architecture, giving the agent richer information about the turbulent flow field in which it navigates. The results are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO combined with Long Short Term Memory (LSTM) cells and a traditional navigation algorithm. The obtained results show a significant increase in the success rate (SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the classical Zermelo's navigation algorithm, paving the way to a completely reimagined UAV landscape in complex urban environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— äººæœº(UAVs)åœ¨å¤æ‚åŸå¸‚ç¯å¢ƒä¸­çš„å¯¼èˆªæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning)çš„æœ€ä¼˜å¯¼èˆªç­–ç•¥ã€‚ç ”ç©¶åˆ©ç”¨ä¸‰ç»´é«˜ä¿çœŸæ¨¡æ‹Ÿçš„åŸå¸‚æ°”æµåœºä½œä¸ºå®éªŒç¯å¢ƒï¼Œå……åˆ†è€ƒè™‘äº†å…¶ä¸­çš„æ¹æµ(Turbulence)å’Œå›æµåŒº(Recirculation Zones)å¯¹é£è¡Œæ€§èƒ½çš„å½±å“ã€‚æ ¸å¿ƒæ–¹æ³•é‡‡ç”¨äº†æ„ŸçŸ¥æµåœºçš„è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ç®—æ³•(PPO)ç»“åˆGated Transformer eXtra Large (GTrXL)æ¶æ„ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè·å–å¹¶å¤„ç†æ›´ä¸°å¯Œçš„æµåœºä¿¡æ¯ã€‚é€šè¿‡ä¸ç»“åˆLSTMçš„PPOæ¨¡å‹åŠä¼ ç»Ÿçš„Zermeloå¯¼èˆªç®—æ³•å¯¹æ¯”ï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨æˆåŠŸç‡(Success Rate)ä¸Šæ˜¾è‘—æé«˜ï¼Œä¸”ç¢°æ’ç‡(Crash Rate)æ›´ä½ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºæ— äººæœºåœ¨å¤æ‚åŸå¸‚é£åœºä¸­çš„è‡ªä¸»å¯¼èˆªæä¾›äº†å…¨æ–°çš„æŠ€æœ¯è·¯å¾„ï¼Œå¯¹æœªæ¥åŸå¸‚é…é€å’Œç›‘æ§ä»»åŠ¡å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25679v1",
      "published_date": "2025-10-29 16:46:00 UTC",
      "updated_date": "2025-10-29 16:46:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:24.775869+00:00"
    },
    {
      "arxiv_id": "2512.10960v1",
      "title": "Measuring skill-based uplift from AI in a real biological laboratory",
      "title_zh": "åœ¨çœŸå®ç”Ÿç‰©å®éªŒå®¤ä¸­è¯„ä¼° AI å¸¦æ¥çš„æŠ€èƒ½å¢ç›Š",
      "authors": [
        "Ethan Obie Romero-Severson",
        "Tara Harvey",
        "Nick Generous",
        "Phillip M. Mach"
      ],
      "abstract": "Understanding how AI systems are used by people in real situations that mirror aspects of both legitimate and illegitimate use is key to predicting the risks and benefits of AI systems. This is especially true in biological applications, where skill rather than knowledge is often the primary barrier for an untrained person. The challenge is that these studies are difficult to execute well and can take months to plan and run.\n  Here we report the results of a pilot study that attempted to empirically measure the magnitude of \\emph{skills-based uplift} caused by access to an AI reasoning model, compared with a control group that had only internet access. Participants -- drawn from a diverse pool of Los Alamos National Laboratory employees with no prior wet-lab experience -- were asked to transform \\ecoli{} with a provided expression construct, induce expression of a reporter peptide, and have expression confirmed by mass spectrometry.\n  We recorded quantitative outcomes (e.g., successful completion of experimental segments) and qualitative observations about how participants interacted with the AI system, the internet, laboratory equipment, and one another. We present the results of the study and lessons learned in designing and executing this type of study, and we discuss these results in the context of future studies of the evolving relationship between AI and global biosecurity.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨è¡¡é‡äººå·¥æ™ºèƒ½(AI)åœ¨çœŸå®ç”Ÿç‰©å®éªŒå®¤ç¯å¢ƒä¸­å¸¦æ¥çš„æŠ€èƒ½æå‡(skill-based uplift)ï¼Œæ¢è®¨AIå¦‚ä½•é™ä½éä¸“ä¸šäººå‘˜è¿›è¡Œå¤æ‚ç”Ÿç‰©æ“ä½œçš„é—¨æ§›ã€‚ç ”ç©¶äººå‘˜åœ¨æ´›æ–¯é˜¿æ‹‰è«æ–¯å›½å®¶å®éªŒå®¤(Los Alamos National Laboratory)ç»„ç»‡äº†ä¸€é¡¹è¯•ç‚¹ç ”ç©¶ï¼Œå¯¹æ¯”äº†ä½¿ç”¨AIæ¨ç†æ¨¡å‹ä¸ä»…æœ‰äº’è”ç½‘è®¿é—®æƒé™çš„å¯¹ç…§ç»„ã€‚æ²¡æœ‰æ¹¿å®éªŒ(wet-lab)ç»éªŒçš„å‚ä¸è€…è¢«è¦æ±‚å°è¯•å®Œæˆå¤§è‚ æ†èŒ(E. coli)è½¬åŒ–ã€è‚½è¡¨è¾¾è¯±å¯¼åŠè´¨è°±åˆ†æ(mass spectrometry)ç¡®è®¤ç­‰ä»»åŠ¡ã€‚é€šè¿‡åˆ†æå®šé‡çš„å®éªŒå®Œæˆåº¦ç»“æœå’Œå®šæ€§çš„ç³»ç»Ÿäº¤äº’è§‚å¯Ÿï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†AIå¦‚ä½•ååŠ©éä¸“ä¸šäººå£«è·¨è¶ŠæŠ€æœ¯éšœç¢ã€‚ç ”ç©¶ç»“æœåŠå…¶åœ¨å®éªŒè®¾è®¡æ–¹é¢çš„ç»éªŒæ•™è®­ï¼Œä¸ºè¯„ä¼°AIåœ¨ç”Ÿç‰©å®‰å…¨(biosecurity)é¢†åŸŸå¸¦æ¥çš„é£é™©ä¸æ”¶ç›Šæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.10960v1",
      "published_date": "2025-10-29 16:34:57 UTC",
      "updated_date": "2025-10-29 16:34:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:27.863826+00:00"
    },
    {
      "arxiv_id": "2510.25668v1",
      "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents",
      "title_zh": "ALDENï¼šé¢å‘é•¿æ–‡æ¡£ä¸»åŠ¨å¯¼èˆªä¸è¯æ®æ”¶é›†çš„å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Tianyu Yang",
        "Terry Ruas",
        "Yijun Tian",
        "Jan Philip Wahle",
        "Daniel Kurzawe",
        "Bela Gipp"
      ],
      "abstract": "Vision-language models (VLMs) excel at interpreting text-rich images but struggle with long, visually complex documents that demand analysis and integration of information spread across multiple pages. Existing approaches typically rely on fixed reasoning templates or rigid pipelines, which force VLMs into a passive role and hinder both efficiency and generalization. We present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement learning framework that fine-tunes VLMs as interactive agents capable of actively navigating long, visually rich documents. ALDEN introduces a novel fetch action that directly accesses the page by index, complementing the classic search action and better exploiting document structure. For dense process supervision and efficient training, we propose a rule-based cross-level reward that provides both turn- and token-level signals. To address the empirically observed training instability caused by numerous visual tokens from long documents, we further propose a visual-semantic anchoring mechanism that applies a dual-path KL-divergence constraint to stabilize visual and textual representations separately during training. Trained on a corpus constructed from three open-source datasets, ALDEN achieves state-of-the-art performance on five long-document benchmarks. Overall, ALDEN marks a step beyond passive document reading toward agents that autonomously navigate and reason across long, visually rich documents, offering a robust path to more accurate and efficient long-document understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ALDEN (Active Long-DocumEnt Navigation)ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šè½®å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨å¤„ç†é•¿ç¯‡ä¸”è§†è§‰å¤æ‚æ–‡æ¡£æ—¶é¢ä¸´çš„è§£æä¸æ•´åˆéš¾é¢˜ã€‚ALDEN å°† VLMs å¾®è°ƒä¸ºäº¤äº’å¼æ™ºèƒ½ä½“ï¼Œé€šè¿‡å¼•å…¥ç›´æ¥æŒ‰ç´¢å¼•è®¿é—®é¡µé¢çš„ fetch åŠ¨ä½œï¼Œé…åˆä¼ ç»Ÿçš„ search åŠ¨ä½œï¼Œå®ç°äº†å¯¹æ–‡æ¡£ç»“æ„çš„ä¸»åŠ¨å¯¼èˆªã€‚ä¸ºäº†ç¡®ä¿é«˜æ•ˆè®­ç»ƒï¼Œç ”ç©¶é‡‡ç”¨äº†åŸºäºè§„åˆ™çš„è·¨å±‚çº§å¥–åŠ±æœºåˆ¶ (cross-level reward)ï¼Œä»è½®æ¬¡å’Œ token çº§åˆ«æä¾›ç›‘ç£ä¿¡å·ã€‚é’ˆå¯¹é•¿æ–‡æ¡£å¸¦æ¥çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ï¼Œç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†è§†è§‰è¯­ä¹‰é”šå®šæœºåˆ¶ (visual-semantic anchoring)ï¼Œåˆ©ç”¨åŒè·¯å¾„ KL æ•£åº¦çº¦æŸæ¥ç¨³å®šè§†è§‰å’Œæ–‡æœ¬è¡¨ç¤ºã€‚å®éªŒè¡¨æ˜ï¼ŒALDEN åœ¨äº”ä¸ªé•¿æ–‡æ¡£åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº† state-of-the-art çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶æ¨åŠ¨äº†æ–‡æ¡£ç†è§£ä»è¢«åŠ¨é˜…è¯»å‘è‡ªä¸»å¯¼èˆªä¸æ¨ç†çš„è½¬å˜ï¼Œä¸ºå‡†ç¡®é«˜æ•ˆåœ°ç†è§£é•¿ç¯‡è§†è§‰ä¸°å¯Œæ–‡æ¡£æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25668v1",
      "published_date": "2025-10-29 16:32:26 UTC",
      "updated_date": "2025-10-29 16:32:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:32.202112+00:00"
    },
    {
      "arxiv_id": "2510.25662v1",
      "title": "User Misconceptions of LLM-Based Conversational Programming Assistants",
      "title_zh": "ç”¨æˆ·å¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¯¹è¯å¼ç¼–ç¨‹åŠ©æ‰‹çš„è¯¯è§£",
      "authors": [
        "Gabrielle O'Brien",
        "Antonio Pedro Santos Alves",
        "Sebastian Baltes",
        "Grischa Liebel",
        "Mircea Lungu",
        "Marcos Kalinowski"
      ],
      "abstract": "Programming assistants powered by large language models (LLMs) have become widely available, with conversational assistants like ChatGPT proving particularly accessible to less experienced programmers. However, the varied capabilities of these tools across model versions and the mixed availability of extensions that enable web search, code execution, or retrieval-augmented generation create opportunities for user misconceptions about what systems can and cannot do. Such misconceptions may lead to over-reliance, unproductive practices, or insufficient quality control in LLM-assisted programming. Here, we aim to characterize misconceptions that users of conversational LLM-based assistants may have in programming contexts. Using a two-phase approach, we first brainstorm and catalog user misconceptions that may occur, and then conduct a qualitative analysis to examine whether these conceptual issues surface in naturalistic Python-programming conversations with an LLM-based chatbot drawn from an openly available dataset. Indeed, we see evidence that some users have misplaced expectations about the availability of LLM-based chatbot features like web access, code execution, or non-text output generation. We also see potential evidence for deeper conceptual issues around the scope of information required to debug, validate, and optimize programs. Our findings reinforce the need for designing LLM-based tools that more clearly communicate their programming capabilities to users.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”¨æˆ·åœ¨ç¼–ç¨‹åœºæ™¯ä¸‹å¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¯¹è¯å¼åŠ©æ‰‹å­˜åœ¨çš„è®¤çŸ¥è¯¯è§£ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒLLM æ¨¡å‹ç‰ˆæœ¬çš„å·®å¼‚ä»¥åŠ web searchã€code execution æˆ–æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç­‰åŠŸèƒ½çš„æ··åˆå¯ç”¨æ€§ï¼Œå¯¼è‡´ç”¨æˆ·éš¾ä»¥å‡†ç¡®è¯„ä¼°ç³»ç»Ÿçš„èƒ½åŠ›è¾¹ç•Œã€‚ç ”ç©¶äººå‘˜é¦–å…ˆé€šè¿‡å¤´è„‘é£æš´ç¼–åˆ¶äº†å¯èƒ½çš„è¯¯è§£æ¸…å•ï¼Œéšåå¯¹å¼€æºæ•°æ®é›†ä¸­çš„ Python ç¼–ç¨‹å¯¹è¯è¿›è¡Œäº†å®šæ€§åˆ†æã€‚å®éªŒè¯æ®è¡¨æ˜ï¼Œç”¨æˆ·åœ¨ web accessã€code execution æˆ–éæ–‡æœ¬è¾“å‡ºç”Ÿæˆç­‰åŠŸèƒ½ä¸Šå­˜åœ¨é”™è¯¯çš„æœŸæœ›ï¼Œä¸”åœ¨ç¨‹åº debugã€validate å’Œ optimize æ‰€éœ€çš„ä¿¡æ¯èŒƒå›´ä¸Šå­˜åœ¨æ·±å±‚æ¦‚å¿µé—®é¢˜ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†åœ¨è®¾è®¡ LLM ç¼–ç¨‹å·¥å…·æ—¶ï¼Œå¿…é¡»æ›´æ¸…æ™°åœ°å‘ç”¨æˆ·ä¼ è¾¾å…¶åŠŸèƒ½è¾¹ç•Œï¼Œä»¥å‡å°‘è¿‡åº¦ä¾èµ–æˆ–ä½æ•ˆå®è·µã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25662v1",
      "published_date": "2025-10-29 16:23:46 UTC",
      "updated_date": "2025-10-29 16:23:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:33.571559+00:00"
    },
    {
      "arxiv_id": "2510.25657v1",
      "title": "Subgraph Federated Learning via Spectral Methods",
      "title_zh": "åŸºäºè°±æ–¹æ³•çš„å­å›¾è”é‚¦å­¦ä¹ ",
      "authors": [
        "Javad Aliakbari",
        "Johan Ã–stman",
        "Ashkan Panahi",
        "Alexandre Graell i Amat"
      ],
      "abstract": "We consider the problem of federated learning (FL) with graph-structured data distributed across multiple clients. In particular, we address the prevalent scenario of interconnected subgraphs, where interconnections between clients significantly influence the learning process. Existing approaches suffer from critical limitations, either requiring the exchange of sensitive node embeddings, thereby posing privacy risks, or relying on computationally-intensive steps, which hinders scalability. To tackle these challenges, we propose FedLap, a novel framework that leverages global structure information via Laplacian smoothing in the spectral domain to effectively capture inter-node dependencies while ensuring privacy and scalability. We provide a formal analysis of the privacy of FedLap, demonstrating that it preserves privacy. Notably, FedLap is the first subgraph FL scheme with strong privacy guarantees. Extensive experiments on benchmark datasets demonstrate that FedLap achieves competitive or superior utility compared to existing techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è·¨å¤šä¸ªå®¢æˆ·ç«¯çš„å›¾ç»“æ„æ•°æ®è”é‚¦å­¦ä¹  (Federated Learning) é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³å®¢æˆ·ç«¯ä¹‹é—´äº’è¿å­å›¾å¯¹å­¦ä¹ è¿‡ç¨‹çš„å½±å“ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨äº¤æ¢æ•æ„ŸèŠ‚ç‚¹åµŒå…¥ (node embeddings) æ—¶å­˜åœ¨çš„éšç§é£é™©ä»¥åŠè®¡ç®—å¯†é›†å‹æ­¥éª¤å¯¼è‡´çš„æ‰©å±•æ€§éš¾é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†åä¸º FedLap çš„æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è°±åŸŸ (spectral domain) ä¸­çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ (Laplacian smoothing) æŠ€æœ¯æ¥è·å–å…¨å±€ç»“æ„ä¿¡æ¯ï¼Œä»è€Œåœ¨ä¿è¯éšç§å’Œå¯æ‰©å±•æ€§çš„å‰æä¸‹æœ‰æ•ˆæ•è·èŠ‚ç‚¹é—´çš„ä¾èµ–å…³ç³»ã€‚é€šè¿‡å½¢å¼åŒ–åˆ†æè¯æ˜ï¼ŒFedLap æ˜¯é¦–ä¸ªå…·æœ‰å¼ºéšç§ä¿è¯çš„å­å›¾è”é‚¦å­¦ä¹  (subgraph FL) æ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFedLap åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜äºæˆ–ç­‰åŒäºç°æœ‰æŠ€æœ¯çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "To be presented at The Annual Conference on Neural Information Processing Systems (NeurIPS) 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.25657v1",
      "published_date": "2025-10-29 16:22:32 UTC",
      "updated_date": "2025-10-29 16:22:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:37.150934+00:00"
    },
    {
      "arxiv_id": "2511.11597v1",
      "title": "CLINB: A Climate Intelligence Benchmark for Foundational Models",
      "title_zh": "CLINBï¼šé¢å‘åŸºç¡€æ¨¡å‹çš„æ°”å€™æ™ºèƒ½è¯„ä¼°åŸºå‡†",
      "authors": [
        "Michelle Chen Huebscher",
        "Katharine Mach",
        "Aleksandar StaniÄ‡",
        "Markus Leippold",
        "Ben Gaiarin",
        "Zeke Hausfather",
        "Elisa Rawat",
        "Erich Fischer",
        "Massimiliano Ciaramita",
        "Joeri Rogelj",
        "Christian Buck",
        "Lierni Sestorain Saralegui",
        "Reto Knutti"
      ],
      "abstract": "Evaluating how Large Language Models (LLMs) handle complex, specialized knowledge remains a critical challenge. We address this through the lens of climate change by introducing CLINB, a benchmark that assesses models on open-ended, grounded, multimodal question answering tasks with clear requirements for knowledge quality and evidential support. CLINB relies on a dataset of real users' questions and evaluation rubrics curated by leading climate scientists. We implement and validate a model-based evaluation process and evaluate several frontier models. Our findings reveal a critical dichotomy. Frontier models demonstrate remarkable knowledge synthesis capabilities, often exhibiting PhD-level understanding and presentation quality. They outperform \"hybrid\" answers curated by domain experts assisted by weaker models. However, this performance is countered by failures in grounding. The quality of evidence varies, with substantial hallucination rates for references and images. We argue that bridging this gap between knowledge synthesis and verifiable attribution is essential for the deployment of AI in scientific workflows and that reliable, interpretable benchmarks like CLINB are needed to progress towards building trustworthy AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† CLINBï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°åŸºç¡€æ¨¡å‹ (Foundational Models) åœ¨æ°”å€™æ™ºèƒ½é¢†åŸŸè¡¨ç°çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹å¤„ç†å¤æ‚ä¸“ä¸šçŸ¥è¯†æ—¶çš„è¯„ä¼°æŒ‘æˆ˜ã€‚è¯¥åŸºå‡†åŸºäºçœŸå®ç”¨æˆ·é—®é¢˜å’Œæ°”å€™ç§‘å­¦å®¶åˆ¶å®šçš„è¯„ä¼°å‡†åˆ™ï¼Œé‡ç‚¹è€ƒé‡å¼€æ”¾å¼ã€è½åœ°å¼åŠå¤šæ¨¡æ€é—®ç­”ä»»åŠ¡ä¸­çš„çŸ¥è¯†è´¨é‡å’Œè¯æ®æ”¯æŒã€‚å®éªŒé€šè¿‡å¯¹å¤šä¸ªå‰æ²¿æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼Œå‘ç°è¿™äº›æ¨¡å‹åœ¨çŸ¥è¯†åˆæˆ (Knowledge Synthesis) æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç”šè‡³è¾¾åˆ°äº†åšå£«çº§åˆ«çš„ç†è§£æ°´å¹³ã€‚ç„¶è€Œï¼Œç ”ç©¶åŒæ—¶ä¹Ÿæ­ç¤ºäº†æ¨¡å‹åœ¨è¯æ®è½åœ° (Grounding) æ–¹é¢çš„ä¸¥é‡ç¼ºé™·ï¼Œå°¤å…¶æ˜¯åœ¨å‚è€ƒæ–‡çŒ®å’Œå›¾åƒä¸­å­˜åœ¨è¾ƒé«˜çš„å¹»è§‰ (Hallucination) æ¯”ä¾‹ã€‚ä½œè€…æŒ‡å‡ºï¼Œå¼¥åˆçŸ¥è¯†åˆæˆä¸å¯éªŒè¯å½’å›  (Verifiable Attribution) ä¹‹é—´çš„é¸¿æ²Ÿæ˜¯ AI åº”ç”¨äºç§‘å­¦å·¥ä½œæµçš„å…³é”®ã€‚CLINB çš„æå‡ºä¸ºå¼€å‘é€æ˜ã€å¯ä¿¡çš„æ°”å€™äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†å¿…è¦çš„å·¥å…·å’Œè¯„ä¼°æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Questions, system prompt and model judge prompts available here: https://www.kaggle.com/datasets/deepmind/clinb-questions",
      "pdf_url": "https://arxiv.org/pdf/2511.11597v1",
      "published_date": "2025-10-29 16:15:42 UTC",
      "updated_date": "2025-10-29 16:15:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:40.173655+00:00"
    },
    {
      "arxiv_id": "2510.25634v1",
      "title": "Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills",
      "title_zh": "åŸºäºå¼ºåŒ–å­¦ä¹ åŒè‡‚æœºå™¨äººæŠ€èƒ½çš„è§„åˆ’ä¸è°ƒåº¦å­¦ä¹ ",
      "authors": [
        "Weikang Wan",
        "Fabio Ramos",
        "Xuning Yang",
        "Caelan Garrett"
      ],
      "abstract": "Long-horizon contact-rich bimanual manipulation presents a significant challenge, requiring complex coordination involving a mixture of parallel execution and sequential collaboration between arms. In this paper, we introduce a hierarchical framework that frames this challenge as an integrated skill planning & scheduling problem, going beyond purely sequential decision-making to support simultaneous skill invocation. Our approach is built upon a library of single-arm and bimanual primitive skills, each trained using Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a Transformer-based planner on a dataset of skill compositions to act as a high-level scheduler, simultaneously predicting the discrete schedule of skills as well as their continuous parameters. We demonstrate that our method achieves higher success rates on complex, contact-rich tasks than end-to-end RL approaches and produces more efficient, coordinated behaviors than traditional sequential-only planners.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é•¿æœŸä¸”æ¥è§¦å¯†é›†çš„åŒè‡‚æœºå™¨äººæ“ä½œæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªå±‚æ¬¡åŒ–æ¡†æ¶ï¼Œå°†è¯¥æŒ‘æˆ˜å»ºæ¨¡ä¸ºé›†æˆçš„æŠ€èƒ½è§„åˆ’ä¸è°ƒåº¦(Integrated Skill Planning & Scheduling)é—®é¢˜ï¼Œå¹¶æ”¯æŒæŠ€èƒ½çš„åŒæ—¶è°ƒç”¨ã€‚è¯¥æ–¹æ³•æ„å»ºäº†ä¸€ä¸ªåŒ…å«å•è‡‚å’ŒåŒè‡‚åŸå§‹æŠ€èƒ½çš„åº“ï¼Œè¿™äº›æŠ€èƒ½å‡åœ¨GPUåŠ é€Ÿçš„ä»¿çœŸç¯å¢ƒä¸­ä½¿ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)è¿›è¡Œè®­ç»ƒã€‚ç ”ç©¶è€…éšåè®­ç»ƒäº†ä¸€ä¸ªåŸºäºTransformerçš„è§„åˆ’å™¨ä½œä¸ºé«˜çº§è°ƒåº¦å™¨ï¼Œç”¨äºåŒæ—¶é¢„æµ‹ç¦»æ•£çš„æŠ€èƒ½è°ƒåº¦æ–¹æ¡ˆåŠå…¶è¿ç»­å‚æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤„ç†å¤æ‚çš„æ¥è§¦å¯†é›†å‹ä»»åŠ¡æ—¶ï¼Œè¯¥æ–¹æ³•æ¯”ä¼ ç»Ÿçš„ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ (End-to-End RL)å…·æœ‰æ›´é«˜çš„æˆåŠŸç‡ã€‚ç›¸æ¯”äºä»…æ”¯æŒé¡ºåºæ“ä½œçš„ä¼ ç»Ÿè§„åˆ’å™¨ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿç”Ÿæˆæ›´åŠ é«˜æ•ˆä¸”åè°ƒçš„åŒè‡‚åä½œè¡Œä¸ºã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25634v1",
      "published_date": "2025-10-29 15:39:53 UTC",
      "updated_date": "2025-10-29 15:39:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:42.377402+00:00"
    },
    {
      "arxiv_id": "2510.25626v2",
      "title": "Are Language Models Efficient Reasoners? A Perspective from Logic Programming",
      "title_zh": "è¯­è¨€æ¨¡å‹æ˜¯é«˜æ•ˆçš„æ¨ç†è€…å—ï¼ŸåŸºäºé€»è¾‘ç¼–ç¨‹è§†è§’çš„æ¢æ",
      "authors": [
        "Andreas Opedal",
        "Yanick Zengaffinen",
        "Haruki Shirakami",
        "Clemente Pasti",
        "Mrinmaya Sachan",
        "Abulhair Saparov",
        "Ryan Cotterell",
        "Bernhard SchÃ¶lkopf"
      ],
      "abstract": "Modern language models (LMs) exhibit strong deductive reasoning capabilities, yet standard evaluations emphasize correctness while overlooking a key aspect of reasoning: efficiency. In real-world reasoning scenarios, much of the available information is irrelevant, and effective deductive inference requires identifying and ignoring such distractions. We propose a framework for assessing LM reasoning efficiency through the lens of logic programming, introducing a simple method to align proofs written in natural language -- as generated by an LM -- with shortest proofs found by executing the logic program. Efficiency is quantified by measuring how well a model avoids unnecessary inference. Empirically, we construct a dataset of math word problems injected with various number of irrelevant axioms that vary in semantic overlap with the goal theorem. We find that current LMs show marked accuracy declines under such conditions -- even with minimal, domain-consistent distractions -- and the proofs they generate frequently exhibit detours through irrelevant inferences.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»é€»è¾‘ç¼–ç¨‹ (logic programming) çš„è§†è§’æ¢è®¨äº†è¯­è¨€æ¨¡å‹ (LMs) çš„æ¼”ç»æ¨ç†æ•ˆç‡ï¼Œé‡ç‚¹å…³æ³¨æ¨¡å‹åœ¨çœŸå®æ¨ç†åœºæ™¯ä¸­å¿½ç•¥æ— å…³ä¿¡æ¯çš„èƒ½åŠ›ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªè¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å°†æ¨¡å‹ç”Ÿæˆçš„è‡ªç„¶è¯­è¨€è¯æ˜ä¸é€»è¾‘ç¨‹åºæ‰§è¡Œå¾—åˆ°çš„æœ€çŸ­è¯æ˜è¿›è¡Œå¯¹é½ï¼Œä»¥è¡¡é‡æ¨¡å‹é¿å…ä¸å¿…è¦æ¨ç† (unnecessary inference) çš„æ°´å¹³ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªæ³¨å…¥äº†ä¸åŒæ•°é‡æ— å…³å…¬ç† (irrelevant axioms) çš„æ•°å­¦åº”ç”¨é¢˜æ•°æ®é›†ï¼Œå¹¶æµ‹è¯•äº†å¹²æ‰°é¡¹ä¸ç›®æ ‡å®šç†è¯­ä¹‰é‡å æ—¶çš„å½±å“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰çš„è¯­è¨€æ¨¡å‹åœ¨é¢å¯¹å¹²æ‰°æ—¶å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼Œå³ä½¿æ˜¯ä¸é¢†åŸŸä¸€è‡´çš„å¾®é‡å¹²æ‰°ä¹Ÿä¼šå¹²æ‰°æ¨ç†ã€‚åˆ†æè¡¨æ˜ï¼Œæ¨¡å‹ç”Ÿæˆçš„è¯æ˜è¿‡ç¨‹ç»å¸¸é€šè¿‡æ— å…³æ¨ç†äº§ç”Ÿâ€œç»•è·¯â€ç°è±¡ï¼Œæš´éœ²å‡ºå…¶åœ¨å¤æ‚é€»è¾‘ç¯å¢ƒä¸‹çš„æ¨ç†æ•ˆç‡ç¼ºé™·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.25626v2",
      "published_date": "2025-10-29 15:30:31 UTC",
      "updated_date": "2026-01-15 09:56:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:23:48.070599+00:00"
    },
    {
      "arxiv_id": "2510.25621v1",
      "title": "FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering",
      "title_zh": "FARSIQAï¼šé¢å‘ä¼Šæ–¯å…°é—®ç­”çš„é«˜å¯ä¿¡å…ˆè¿› RAG ç³»ç»Ÿ",
      "authors": [
        "Mohammad Aghajani Asl",
        "Behrooz Minaei Bidgoli"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has revolutionized Natural Language Processing, yet their application in high-stakes, specialized domains like religious question answering is hindered by challenges like hallucination and unfaithfulness to authoritative sources. This issue is particularly critical for the Persian-speaking Muslim community, where accuracy and trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG) systems, relying on simplistic single-pass pipelines, fall short on complex, multi-hop queries requiring multi-step reasoning and evidence aggregation. To address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful Advanced Question Answering in the Persian Islamic domain. FARSIQA is built upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting process: it adaptively decomposes complex queries, assesses evidence sufficiency, and enters an iterative loop to generate sub-queries, progressively filling information gaps. Operating on a curated knowledge base of over one million authoritative Islamic documents, FARSIQA demonstrates superior performance. Rigorous evaluation on the challenging IslamicPCQA benchmark shows state-of-the-art performance: the system achieves a remarkable 97.0% in Negative Rejection - a 40-point improvement over baselines - and a high Answer Correctness score of 74.3%. Our work establishes a new standard for Persian Islamic QA and validates that our iterative, adaptive architecture is crucial for building faithful, reliable AI systems in sensitive domains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ³¢æ–¯è¯­ä¼Šæ–¯å…°é—®ç­”ç­‰é«˜é£é™©é¢†åŸŸé¢ä¸´çš„å¹»è§‰å’Œæƒå¨æ€§ä¸è¶³é—®é¢˜ï¼Œæå‡ºäº†åä¸ºFARSIQAçš„ç«¯åˆ°ç«¯é«˜çº§é—®ç­”ç³»ç»Ÿã€‚è¯¥ç³»ç»ŸåŸºäºåˆ›æ–°çš„FAIR-RAGï¼ˆFaithful, Adaptive, Iterative Refinementï¼‰æ¶æ„ï¼Œé€šè¿‡åŠ¨æ€è‡ªçº é”™æœºåˆ¶è‡ªé€‚åº”åœ°åˆ†è§£å¤æ‚æŸ¥è¯¢ï¼Œå¹¶åœ¨è¿­ä»£å¾ªç¯ä¸­è¯„ä¼°è¯æ®å……åˆ†æ€§ä»¥å¡«è¡¥ä¿¡æ¯ç©ºç™½ã€‚FARSIQAåœ¨åŒ…å«è¶…è¿‡100ä¸‡ä»½æƒå¨ä¼Šæ–¯å…°æ–‡æ¡£çš„ç²¾é€‰çŸ¥è¯†åº“ä¸Šè¿è¡Œï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿå¤„ç†å¤æ‚å¤šè·³æŸ¥è¯¢çš„èƒ½åŠ›ã€‚åœ¨IslamicPCQAåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥ç³»ç»Ÿè¡¨ç°å‡ºState-of-the-Artæ€§èƒ½ï¼Œå¦å®šæ‹’ç»(Negative Rejection)ç‡è¾¾åˆ°97.0%ï¼Œæ¯”åŸºçº¿æ¨¡å‹æé«˜äº†40%ï¼Œç­”æ¡ˆå‡†ç¡®æ€§(Answer Correctness)å¾—åˆ†è¾¾åˆ°74.3%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è¿­ä»£å¼ã€è‡ªé€‚åº”æ¶æ„å¯¹äºåœ¨æ•æ„Ÿé¢†åŸŸæ„å»ºå¿ å®å¯é çš„AIç³»ç»Ÿè‡³å…³é‡è¦ï¼Œå¹¶ä¸ºæ³¢æ–¯è¯­ä¼Šæ–¯å…°é—®ç­”æ ‘ç«‹äº†æ–°çš„æŠ€æœ¯æ ‡å‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages, 5 figures, 10 tables. Keywords: Retrieval-Augmented Generation (RAG), Question Answering (QA), Islamic Knowledge Base, Faithful AI, Persian NLP, Multi-hop Reasoning, Large Language Models (LLMs)",
      "pdf_url": "https://arxiv.org/pdf/2510.25621v1",
      "published_date": "2025-10-29 15:25:34 UTC",
      "updated_date": "2025-10-29 15:25:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:03.575602+00:00"
    },
    {
      "arxiv_id": "2510.25616v1",
      "title": "Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization",
      "title_zh": "è«è®© VLA â€œå¤±æ˜â€ï¼šé¢å‘ OOD æ³›åŒ–çš„è§†è§‰è¡¨å¾å¯¹é½",
      "authors": [
        "Nikita Kachaev",
        "Mikhail Kolosov",
        "Daniil Zelezetsky",
        "Alexey K. Kovalev",
        "Aleksandr I. Panov"
      ],
      "abstract": "The growing success of Vision-Language-Action (VLA) models stems from the promise that pretrained Vision-Language Models (VLMs) can endow agents with transferable world knowledge and vision-language (VL) grounding, laying a foundation for action models with broader generalization. Yet when these VLMs are adapted to the action modality, it remains unclear to what extent their original VL representations and knowledge are preserved. In this work, we conduct a systematic study of representation retention during VLA fine-tuning, showing that naive action fine-tuning leads to degradation of visual representations. To characterize and measure these effects, we probe VLA's hidden representations and analyze attention maps, further, we design a set of targeted tasks and methods that contrast VLA models with their counterpart VLMs, isolating changes in VL capabilities induced by action fine-tuning. We further evaluate a range of strategies for aligning visual representations and introduce a simple yet effective method that mitigates degradation and yields improved generalization to out-of-distribution (OOD) scenarios. Taken together, our analysis clarifies the trade-off between action fine-tuning and the degradation of VL representations and highlights practical approaches to recover inherited VL capabilities. Code is publicly available: https://blind-vla-paper.github.io",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹(Vision-Language-Action, VLA)åœ¨é€‚é…åŠ¨ä½œæ¨¡æ€æ—¶ï¼Œå…¶åŸå§‹è§†è§‰è¯­è¨€(VL)è¡¨ç¤ºçš„ä¿ç•™ä¸é€€åŒ–é—®é¢˜ã€‚é€šè¿‡å¯¹VLAéšè—å±‚è¡¨ç¤ºå’Œæ³¨æ„åŠ›å›¾(attention maps)çš„ç³»ç»Ÿæ€§æ¢æµ‹ï¼Œä½œè€…å‘ç°æœ´ç´ çš„åŠ¨ä½œå¾®è°ƒä¼šå¯¼è‡´é¢„è®­ç»ƒæ¨¡å‹åŸæœ‰è§†è§‰ç‰¹å¾èƒ½åŠ›çš„æŸå®³ã€‚ä¸ºé‡åŒ–è¿™ä¸€å½±å“ï¼Œç ”ç©¶è®¾è®¡äº†ä¸“é—¨çš„å¯¹æ¯”ä»»åŠ¡æ¥éš”ç¦»å¾®è°ƒå¼•å‘çš„VLèƒ½åŠ›å˜åŒ–ï¼Œå¹¶è¯„ä¼°äº†å¤šç§è§†è§‰è¡¨å¾å¯¹é½ç­–ç•¥ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œæ—¨åœ¨ç¼“è§£è¡¨ç¤ºé€€åŒ–å¹¶æ˜¾è‘—å¢å¼ºæ¨¡å‹åœ¨åˆ†å¸ƒå¤–(out-of-distribution, OOD)åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ä»…é˜æ˜äº†åŠ¨ä½œå¾®è°ƒä¸è§†è§‰è¡¨ç¤ºè´¨é‡ä¹‹é—´çš„æƒè¡¡å…³ç³»ï¼Œè¿˜ä¸ºåœ¨æ„å»ºæ›´å…·æ³›åŒ–æ€§çš„å…·èº«æ™ºèƒ½ä½“æ—¶å¦‚ä½•æœ‰æ•ˆä¿ç•™ç»§æ‰¿çš„VLèƒ½åŠ›æä¾›äº†å®ç”¨çš„æ–¹æ³•è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25616v1",
      "published_date": "2025-10-29 15:20:10 UTC",
      "updated_date": "2025-10-29 15:20:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:04.370000+00:00"
    },
    {
      "arxiv_id": "2510.25612v1",
      "title": "Counterfactual-based Agent Influence Ranker for Agentic AI Workflows",
      "title_zh": "é¢å‘æ™ºèƒ½ä½“ AI å·¥ä½œæµçš„åŸºäºåäº‹å®çš„æ™ºèƒ½ä½“å½±å“åŠ›æ’åºå™¨",
      "authors": [
        "Amit Giloni",
        "Chiara Picardi",
        "Roy Betser",
        "Shamik Bose",
        "Aishvariya Priya Rathina Sabapathy",
        "Roman Vainshtein"
      ],
      "abstract": "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system, is an autonomous system that assembles several LLM-based agents to work collaboratively towards a shared goal. The high autonomy, widespread adoption, and growing interest in such AAWs highlight the need for a deeper understanding of their operations, from both quality and security aspects. To this day, there are no existing methods to assess the influence of each agent on the AAW's final output. Adopting techniques from related fields is not feasible since existing methods perform only static structural analysis, which is unsuitable for inference time execution. We present Counterfactual-based Agent Influence Ranker (CAIR) - the first method for assessing the influence level of each agent on the AAW's output and determining which agents are the most influential. By performing counterfactual analysis, CAIR provides a task-agnostic analysis that can be used both offline and at inference time. We evaluate CAIR using an AAWs dataset of our creation, containing 30 different use cases with 230 different functionalities. Our evaluation showed that CAIR produces consistent rankings, outperforms baseline methods, and can easily enhance the effectiveness and relevancy of downstream tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶å…³æ³¨åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“AIå·¥ä½œæµ(Agentic AI Workflow, AAW)çš„è¿è¡Œæœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³ç›®å‰ç¼ºä¹è¯„ä¼°å•ä¸ªæ™ºèƒ½ä½“å¯¹æœ€ç»ˆè¾“å‡ºå½±å“ç¨‹åº¦çš„æ–¹æ³•ã€‚ç°æœ‰çš„é™æ€ç»“æ„åˆ†ææ–¹æ³•ç”±äºæ— æ³•æ»¡è¶³æ¨ç†æ—¶çš„åŠ¨æ€éœ€æ±‚è€Œéš¾ä»¥ç›´æ¥åº”ç”¨ï¼Œä¸ºæ­¤ä½œè€…æå‡ºäº†é¦–ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å„æ™ºèƒ½ä½“å½±å“åŠ›çš„æ¡†æ¶â€”â€”åŸºäºåäº‹å®çš„æ™ºèƒ½ä½“å½±å“æ’åå™¨(CAIR)ã€‚CAIRé€šè¿‡æ‰§è¡Œåäº‹å®åˆ†æ(Counterfactual analysis)ï¼Œæä¾›äº†ä¸€ç§ä¸ä»»åŠ¡æ— å…³çš„åˆ†ææ‰‹æ®µï¼Œèƒ½å¤ŸåŒæ—¶æ”¯æŒç¦»çº¿è¯„ä¼°ä¸æ¨ç†æ—¶(Inference time)æ‰§è¡Œã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨åŒ…å«30ä¸ªç”¨ä¾‹ã€230é¡¹åŠŸèƒ½çš„AAWæ•°æ®é›†è¿›è¡Œäº†å®éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼ŒCAIRç”Ÿæˆçš„æ’åå…·æœ‰é«˜åº¦ä¸€è‡´æ€§ï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºå‡†æ–¹æ³•ï¼Œå¹¶èƒ½æœ‰æ•ˆå¢å¼ºä¸‹æ¸¸ä»»åŠ¡çš„æœ‰æ•ˆæ€§ä¸ç›¸å…³æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EMNLP 2025, 27 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25612v1",
      "published_date": "2025-10-29 15:17:31 UTC",
      "updated_date": "2025-10-29 15:17:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:06.857557+00:00"
    },
    {
      "arxiv_id": "2510.25609v1",
      "title": "BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training",
      "title_zh": "BOLT-GANï¼šç”¨äº GAN ç¨³å®šè®­ç»ƒçš„è´å¶æ–¯æœ€ä¼˜æŸå¤±",
      "authors": [
        "Mohammadreza Tavasoli Naeini",
        "Ali Bereyhi",
        "Morteza Noshad",
        "Ben Liang",
        "Alfred O. Hero"
      ],
      "abstract": "We introduce BOLT-GAN, a simple yet effective modification of the WGAN framework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that with a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a different metric distance than the Earth Mover (Wasserstein) distance and achieves better training stability. Empirical evaluations on four standard image generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN Church-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60% lower Frechet Inception Distance (FID). Our results suggest that BOLT is a broadly applicable principle for enhancing GAN training.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† BOLT-GANï¼Œè¿™æ˜¯ä¸€ç§å—è´å¶æ–¯æœ€ä¼˜å­¦ä¹ é˜ˆå€¼ (Bayes Optimal Learning Threshold, BOLT) å¯å‘è€Œå¯¹ WGAN æ¡†æ¶è¿›è¡Œçš„ç®€å•ä¸”æœ‰æ•ˆçš„æ”¹è¿›ã€‚é€šè¿‡å¼•å…¥ Lipschitz è¿ç»­åˆ¤åˆ«å™¨ï¼ŒBOLT-GAN åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšå¼åœ°æœ€å°åŒ–äº†ä¸€ç§ä¸åŒäºæ¨åœŸæœºè·ç¦» (Earth Mover / Wasserstein distance) çš„æ–°åº¦é‡è·ç¦»ï¼Œä»è€Œæ˜¾è‘—æå‡äº†è®­ç»ƒç¨³å®šæ€§ã€‚åœ¨ CIFAR-10ã€CelebA-64 ä»¥åŠ LSUN (Bedroom/Church-64) ç­‰å››ä¸ªæ ‡å‡†å›¾åƒç”ŸæˆåŸºå‡†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒBOLT-GAN çš„è¡¨ç°ä¸€è‡´ä¼˜äºä¼ ç»Ÿçš„ WGANã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•å°† Frechet Inception Distance (FID) æŒ‡æ ‡é™ä½äº† 10-60%ï¼Œæœ‰åŠ›åœ°è¯æ˜äº† BOLT æ˜¯ä¸€ä¸ªèƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºå¢å¼º GAN è®­ç»ƒèƒ½åŠ›çš„é€šç”¨åŸåˆ™ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25609v1",
      "published_date": "2025-10-29 15:16:50 UTC",
      "updated_date": "2025-10-29 15:16:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:08.874225+00:00"
    },
    {
      "arxiv_id": "2510.25602v1",
      "title": "INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats",
      "title_zh": "INT å¯¹æ¯” FPï¼šç»†ç²’åº¦ä½æ¯”ç‰¹é‡åŒ–æ ¼å¼çš„å…¨é¢ç ”ç©¶",
      "authors": [
        "Mengzhao Chen",
        "Meng Wu",
        "Hui Jin",
        "Zhihang Yuan",
        "Jing Liu",
        "Chaoyi Zhang",
        "Yunshui Li",
        "Jie Huang",
        "Jin Ma",
        "Zeyue Xue",
        "Zhiheng Liu",
        "Xingyan Bin",
        "Ping Luo"
      ],
      "abstract": "Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly embracing low-precision floating-point (FP) formats to handle the pervasive activation outliers in Large Language Models (LLMs). Despite this industry trend, a unified comparison of FP and integer (INT) quantization across varying granularities has been missing, leaving algorithm and hardware co-design without clear guidance. This paper fills that gap by systematically investigating the trade-offs between FP and INT formats. We reveal a critical performance crossover: while FP excels in coarse-grained quantization, the comparison at fine-grained (block-wise) levels is more nuanced. Our comprehensive comparison demonstrates that for popular 8-bit fine-grained formats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart in both algorithmic accuracy and hardware efficiency. However, for 4-bit formats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we show that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like Hadamard rotation are applied. We also introduce a symmetric clipping method that resolves gradient bias in fine-grained low-bit INT training, enabling nearly lossless performance for MXINT8 training. These findings challenge the current hardware trajectory, demonstrating that a one-size-fits-all FP approach is suboptimal and advocating that fine-grained INT formats, particularly MXINT8, offer a better balance of accuracy, power, and efficiency for future AI accelerators.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶ç³»ç»Ÿåœ°è°ƒæŸ¥äº†ä½æ¯”ç‰¹é‡åŒ–ä¸­æµ®ç‚¹æ•°(FP)ä¸æ•´æ•°(INT)æ ¼å¼ä¹‹é—´çš„æƒè¡¡ï¼Œå¡«è¡¥äº†ç°ä»£ AI ç¡¬ä»¶åœ¨ä¸åŒç²’åº¦ä¸‹ç¼ºä¹ç»Ÿä¸€å¯¹æ¯”çš„ç©ºç™½ã€‚ç ”ç©¶æ­ç¤ºäº†ä¸€ä¸ªå…³é”®çš„æ€§èƒ½äº¤å‰ç‚¹ï¼šè™½ç„¶ FP åœ¨ç²—ç²’åº¦é‡åŒ–ä¸­è¡¨ç°æ›´ä½³ï¼Œä½†åœ¨ç»†ç²’åº¦ï¼ˆåˆ†å—ï¼‰æ°´å¹³ä¸Šï¼Œ8-bit çš„ MXINT8 åœ¨ç®—æ³•å‡†ç¡®æ€§å’Œç¡¬ä»¶æ•ˆç‡æ–¹é¢å‡ä¼˜äºå…¶ FP å¯¹åº”æ ¼å¼ã€‚å¯¹äº 4-bit æ ¼å¼ï¼ŒFP é€šå¸¸åœ¨å‡†ç¡®æ€§ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼Œä½†ç ”ç©¶è¡¨æ˜åœ¨åº”ç”¨ Hadamard æ—‹è½¬ç­‰ç¦»ç¾¤å€¼ç¼“è§£æŠ€æœ¯åï¼ŒNVINT4 å¯ä»¥è¶…è¶Š NVFP4ã€‚æ­¤å¤–ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§å¯¹ç§°è£å‰ª(symmetric clipping)æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†ç»†ç²’åº¦ INT è®­ç»ƒä¸­çš„æ¢¯åº¦åå·®ï¼Œä½¿ MXINT8 è®­ç»ƒè¾¾åˆ°è¿‘ä¹æ— æŸçš„æ€§èƒ½ã€‚è¿™äº›å‘ç°æŒ‘æˆ˜äº†ç›®å‰ç¡¬ä»¶å…¨é¢è½¬å‘ FP çš„è¶‹åŠ¿ï¼Œä¸»å¼ ç»†ç²’åº¦ INT æ ¼å¼ï¼ˆå°¤å…¶æ˜¯ MXINT8ï¼‰åœ¨æœªæ¥ AI åŠ é€Ÿå™¨ä¸­èƒ½æ›´å¥½åœ°å¹³è¡¡å‡†ç¡®æ€§ã€åŠŸè€—ä¸æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25602v1",
      "published_date": "2025-10-29 15:11:53 UTC",
      "updated_date": "2025-10-29 15:11:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:12.074846+00:00"
    },
    {
      "arxiv_id": "2510.25595v1",
      "title": "Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry",
      "title_zh": "é¢å‘ä¿¡æ¯ä¸å¯¹ç§°ç¯å¢ƒä¸‹åä½œçš„ LLM æ™ºèƒ½ä½“é€šä¿¡ä¸éªŒè¯",
      "authors": [
        "Run Peng",
        "Ziqiao Ma",
        "Amy Pang",
        "Sikai Li",
        "Zhang Xi-Jia",
        "Yingzhuo Yu",
        "Cristian-Paul Bara",
        "Joyce Chai"
      ],
      "abstract": "While Large Language Model (LLM) agents are often approached from the angle of action planning/generation to accomplish a goal (e.g., given by language descriptions), their abilities to collaborate with each other to achieve a joint goal are not well explored. To address this limitation, this paper studies LLM agents in task collaboration, particularly under the condition of information asymmetry, where agents have disparities in their knowledge and skills and need to work together to complete a shared task. We extend Einstein Puzzles, a classical symbolic puzzle, to a table-top game. In this game, two LLM agents must reason, communicate, and act to satisfy spatial and relational constraints required to solve the puzzle. We apply a fine-tuning-plus-verifier framework in which LLM agents are equipped with various communication strategies and verification signals from the environment. Empirical results highlight the critical importance of aligned communication, especially when agents possess both information-seeking and -providing capabilities. Interestingly, agents without communication can still achieve high task performance; however, further analysis reveals a lack of true rule understanding and lower trust from human evaluators. Instead, by integrating an environment-based verifier, we enhance agents' ability to comprehend task rules and complete tasks, promoting both safer and more interpretable collaboration in AI systems. https://github.com/Roihn/EinsteinPuzzles",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“åœ¨ä¿¡æ¯ä¸å¯¹ç§°(Information Asymmetry)æƒ…å†µä¸‹çš„åä½œèƒ½åŠ›ï¼Œå³æ™ºèƒ½ä½“åœ¨æ‹¥æœ‰ä¸åŒçŸ¥è¯†å’ŒæŠ€èƒ½æ—¶å¦‚ä½•å…±åŒå®Œæˆä»»åŠ¡ã€‚ç ”ç©¶äººå‘˜å°†ç»å…¸çš„é€»è¾‘è°œé¢˜ Einstein Puzzles æ‰©å±•ä¸ºä¸€ç§æ¡Œé¢æ¸¸æˆï¼Œè¦æ±‚ä¸¤ä¸ª LLM æ™ºèƒ½ä½“é€šè¿‡æ¨ç†ã€äº¤æµå’Œè¡ŒåŠ¨æ¥æ»¡è¶³å¤æ‚çš„ç©ºé—´ä¸å…³ç³»çº¦æŸã€‚è¯¥ç ”ç©¶é‡‡ç”¨äº†å¾®è°ƒåŠ éªŒè¯å™¨(Fine-tuning-plus-verifier)æ¡†æ¶ï¼Œä¸ºæ™ºèƒ½ä½“é…å¤‡äº†å¤šæ ·åŒ–çš„é€šä¿¡ç­–ç•¥(Communication Strategies)å’Œæ¥è‡ªç¯å¢ƒçš„éªŒè¯ä¿¡å·ã€‚å®éªŒç»“æœå¼ºè°ƒäº†å¯¹é½é€šä¿¡(Aligned Communication)çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ™ºèƒ½ä½“åŒæ—¶å…·å¤‡ä¿¡æ¯å¯»æ±‚(Information-seeking)å’Œä¿¡æ¯æä¾›(Information-providing)èƒ½åŠ›æ—¶ã€‚åˆ†æè¡¨æ˜ï¼Œå°½ç®¡ä¸è¿›è¡Œé€šä¿¡çš„æ™ºèƒ½ä½“ä¹Ÿèƒ½å–å¾—è¾ƒé«˜çš„ä»»åŠ¡è¡¨ç°ï¼Œä½†å®ƒä»¬å¾€å¾€ç¼ºä¹å¯¹è§„åˆ™çš„çœŸå®ç†è§£ï¼Œä¸”è·å¾—çš„äººç±»ä¿¡ä»»åº¦è¾ƒä½ã€‚é€šè¿‡é›†æˆåŸºäºç¯å¢ƒçš„éªŒè¯å™¨(Environment-based Verifier)ï¼Œç ”ç©¶æˆåŠŸå¢å¼ºäº†æ™ºèƒ½ä½“å¯¹ä»»åŠ¡è§„åˆ™çš„ç†è§£åŠä»»åŠ¡å®Œæˆåº¦ï¼Œä¸ºæ„å»ºæ›´å®‰å…¨ã€æ›´å…·å¯è§£é‡Šæ€§çš„ AI åä½œç³»ç»Ÿæä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Workshop on Multi-Agent System @ ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.25595v1",
      "published_date": "2025-10-29 15:03:53 UTC",
      "updated_date": "2025-10-29 15:03:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:17.377741+00:00"
    },
    {
      "arxiv_id": "2510.25590v1",
      "title": "RegionE: Adaptive Region-Aware Generation for Efficient Image Editing",
      "title_zh": "RegionEï¼šé¢å‘é«˜æ•ˆå›¾åƒç¼–è¾‘çš„è‡ªé€‚åº”åŒºåŸŸæ„ŸçŸ¥ç”Ÿæˆ",
      "authors": [
        "Pengtao Chen",
        "Xianfang Zeng",
        "Maosen Zhao",
        "Mingzhu Shen",
        "Peng Ye",
        "Bangyin Xiang",
        "Zhibo Wang",
        "Wei Cheng",
        "Gang Yu",
        "Tao Chen"
      ],
      "abstract": "Recently, instruction-based image editing (IIE) has received widespread attention. In practice, IIE often modifies only specific regions of an image, while the remaining areas largely remain unchanged. Although these two types of regions differ significantly in generation difficulty and computational redundancy, existing IIE models do not account for this distinction, instead applying a uniform generation process across the entire image. This motivates us to propose RegionE, an adaptive, region-aware generation framework that accelerates IIE tasks without additional training. Specifically, the RegionE framework consists of three main components: 1) Adaptive Region Partition. We observed that the trajectory of unedited regions is straight, allowing for multi-step denoised predictions to be inferred in a single step. Therefore, in the early denoising stages, we partition the image into edited and unedited regions based on the difference between the final estimated result and the reference image. 2) Region-Aware Generation. After distinguishing the regions, we replace multi-step denoising with one-step prediction for unedited areas. For edited regions, the trajectory is curved, requiring local iterative denoising. To improve the efficiency and quality of local iterative generation, we propose the Region-Instruction KV Cache, which reduces computational cost while incorporating global information. 3) Adaptive Velocity Decay Cache. Observing that adjacent timesteps in edited regions exhibit strong velocity similarity, we further propose an adaptive velocity decay cache to accelerate the local denoising process. We applied RegionE to state-of-the-art IIE base models, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE achieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o confirmed that semantic and perceptual fidelity were well preserved.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RegionEï¼Œä¸€ä¸ªæ— éœ€é¢å¤–è®­ç»ƒçš„è‡ªé€‚åº”åŒºåŸŸæ„ŸçŸ¥ç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æŒ‡ä»¤å¼å›¾åƒç¼–è¾‘(instruction-based image editing, IIE)åœ¨å¤„ç†æœªç¼–è¾‘åŒºåŸŸæ—¶å­˜åœ¨çš„è®¡ç®—å†—ä½™é—®é¢˜ã€‚è¯¥æ¡†æ¶åŒ…å«è‡ªé€‚åº”åŒºåŸŸåˆ’åˆ†(Adaptive Region Partition)ç»„ä»¶ï¼Œé€šè¿‡è¯†åˆ«æœªç¼–è¾‘åŒºåŸŸçš„ç›´çº¿å»å™ªè½¨è¿¹ï¼Œå°†è¿™äº›åŒºåŸŸçš„å¤šæ­¥å»å™ªç®€åŒ–ä¸ºå•æ­¥é¢„æµ‹ã€‚å¯¹äºéœ€è¦å±€éƒ¨è¿­ä»£å»å™ªçš„ç¼–è¾‘åŒºåŸŸï¼ŒRegionEå¼•å…¥äº†åŒºåŸŸæŒ‡ä»¤KVç¼“å­˜(Region-Instruction KV Cache)ä»¥åœ¨é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶æ•´åˆå…¨å±€ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†è‡ªé€‚åº”é€Ÿåº¦è¡°å‡ç¼“å­˜(Adaptive Velocity Decay Cache)ï¼Œåˆ©ç”¨ç›¸é‚»æ—¶é—´æ­¥é—´çš„é€Ÿåº¦ç›¸ä¼¼æ€§è¿›ä¸€æ­¥åŠ é€Ÿå»å™ªè¿‡ç¨‹ã€‚åœ¨Step1X-Editã€FLUX.1 Kontextå’ŒQwen-Image-Editç­‰æ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒRegionEå®ç°äº†2.06è‡³2.57å€çš„æ¨ç†åŠ é€Ÿã€‚ç»GPT-4oè¯„ä¼°ç¡®è®¤ï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—æå‡æ•ˆç‡çš„åŒæ—¶ï¼Œèƒ½å¤Ÿè‰¯å¥½åœ°ä¿æŒå›¾åƒçš„è¯­ä¹‰å’Œæ„ŸçŸ¥ä¿çœŸåº¦ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages, 10 figures, 18 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.25590v1",
      "published_date": "2025-10-29 14:58:37 UTC",
      "updated_date": "2025-10-29 14:58:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:17.659832+00:00"
    },
    {
      "arxiv_id": "2510.25588v1",
      "title": "Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System",
      "title_zh": "ç²¾ç¥åŒ»å­¦è¯Šæ–­æ ‡å‡†åŒ–ï¼šå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹åä½œä½“ä¸ OpenAI-gpt-oss æ¨ç†å¤§è¯­è¨€æ¨¡å‹èµ‹èƒ½çš„å†³ç­–æ”¯æŒç³»ç»Ÿ",
      "authors": [
        "Eranga Bandara",
        "Ross Gore",
        "Atmaram Yarlagadda",
        "Anita H. Clayton",
        "Preston Samuel",
        "Christopher K. Rhea",
        "Sachin Shetty"
      ],
      "abstract": "The diagnosis of most mental disorders, including psychiatric evaluations, primarily depends on dialogues between psychiatrists and patients. This subjective process can lead to variability in diagnoses across clinicians and patients, resulting in inconsistencies and challenges in achieving reliable outcomes. To address these issues and standardize psychiatric diagnoses, we propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss Reasoning LLM-enabled Decision Support System for the clinical diagnosis of mental disorders. Our approach leverages fine-tuned LLMs trained on conversational datasets involving psychiatrist-patient interactions focused on mental health conditions (e.g., depression). The diagnostic predictions from individual models are aggregated through a consensus-based decision-making process, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method for deploying LLM agents that orchestrate communication between the LLM consortium and the reasoning LLM, ensuring transparency, reliability, and responsible AI across the entire diagnostic workflow. Experimental results demonstrate the transformative potential of combining fine-tuned LLMs with a reasoning model to create a robust and highly accurate diagnostic system for mental health assessment. A prototype of the proposed platform, integrating three fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in collaboration with the U.S. Army Medical Research Team in Norfolk, Virginia, USA. To the best of our knowledge, this work represents the first application of a fine-tuned LLM consortium integrated with a reasoning LLM for clinical mental health diagnosis paving the way for next-generation AI-powered eHealth systems aimed at standardizing psychiatric diagnoses.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç²¾ç¥ç–¾ç—…è¯Šæ–­ä¸­å› è¿‡åº¦ä¾èµ–åŒ»æ‚£å¯¹è¯å¯¼è‡´çš„ä¸»è§‚æ€§ä¸ä¸ä¸€è‡´æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹è”ç›Ÿ(Fine-Tuned LLM Consortium)ä¸OpenAI-gpt-ossæ¨ç†æ¨¡å‹çš„å†³ç­–æ”¯æŒç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨åœ¨ç²¾ç¥ç§‘åŒ»æ‚£äº¤äº’æ•°æ®é›†ä¸Šå¾®è°ƒçš„å¤šä¸ªæ¨¡å‹è¿›è¡Œè¯Šæ–­é¢„æµ‹ï¼Œå¹¶é€šè¿‡åŸºäºå…±è¯†çš„å†³ç­–è¿‡ç¨‹æ±‡æ€»ç»“æœï¼Œæœ€åç”±OpenAI-gpt-ossæ¨ç†æ¨¡å‹è¿›è¡Œç²¾ç‚¼ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§æ–°å‹çš„LLM Agentséƒ¨ç½²æ–¹æ³•æ¥åè°ƒå„æ¨¡å‹é—´çš„é€šä¿¡ï¼Œç¡®ä¿äº†æ•´ä¸ªè¯Šæ–­å·¥ä½œæµçš„é€æ˜æ€§ã€å¯é æ€§ä¸è´£ä»»æ„Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§å¾®è°ƒæ¨¡å‹ä¸æ¨ç†æ¨¡å‹çš„ç»“åˆåœ¨æ„å»ºé«˜ç²¾åº¦ç²¾ç¥å¥åº·è¯„ä¼°ç³»ç»Ÿæ–¹é¢å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚è¯¥é¡¹ç›®ä¸ç¾å›½é™†å†›åŒ»ç–—ç ”ç©¶å°ç»„åˆä½œå¼€å‘äº†ç³»ç»ŸåŸå‹ï¼Œæ˜¯é¦–ä¸ªå°†å¾®è°ƒLLMè”ç›Ÿä¸æ¨ç†LLMæ•´åˆç”¨äºä¸´åºŠç²¾ç¥å¥åº·è¯Šæ–­çš„å°è¯•ï¼Œä¸ºå®ç°ç²¾ç¥åŒ»å­¦è¯Šæ–­æ ‡å‡†åŒ–çš„ä¸‹ä¸€ä»£AIé©±åŠ¨eHealthç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25588v1",
      "published_date": "2025-10-29 14:54:22 UTC",
      "updated_date": "2025-10-29 14:54:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:23.760477+00:00"
    },
    {
      "arxiv_id": "2510.25577v1",
      "title": "Lost in Phonation: Voice Quality Variation as an Evaluation Dimension for Speech Foundation Models",
      "title_zh": "è¿·å¤±åœ¨å‘å£°ä¹‹ä¸­ï¼šå°†éŸ³è´¨å˜åŒ–ä½œä¸ºè¯­éŸ³åŸºåº§æ¨¡å‹çš„è¯„ä¼°ç»´åº¦",
      "authors": [
        "Harm Lameris",
        "Shree Harsha Bokkahalli Satish",
        "Joakim Gustafson",
        "Ã‰va SzÃ©kely"
      ],
      "abstract": "Recent advances in speech foundation models (SFMs) have enabled the direct processing of spoken language from raw audio, bypassing intermediate textual representations. This capability allows SFMs to be exposed to, and potentially respond to, rich paralinguistic variations embedded in the input speech signal. One under-explored dimension of paralinguistic variation is voice quality, encompassing phonation types such as creaky and breathy voice. These phonation types are known to influence how listeners infer affective state, stance and social meaning in speech. Existing benchmarks for speech understanding largely rely on multiple-choice question answering (MCQA) formats, which are prone to failure and therefore unreliable in capturing the nuanced ways paralinguistic features influence model behaviour. In this paper, we probe SFMs through open-ended generation tasks and speech emotion recognition, evaluating whether model behaviours are consistent across different phonation inputs. We introduce a new parallel dataset featuring synthesized modifications to voice quality, designed to evaluate SFM responses to creaky and breathy voice. Our work provides the first examination of SFM sensitivity to these particular non-lexical aspects of speech perception.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†è¯­éŸ³è´¨é‡(voice quality)å˜åŒ–ï¼ˆåŒ…æ‹¬å˜è£‚å£°creakyå’Œæ°”å£°breathyç­‰å‘å£°ç±»å‹ï¼‰ä½œä¸ºè¯­éŸ³åŸºç¡€æ¨¡å‹(SFMs)è¯„ä¼°ç»´åº¦çš„æ–°è§†è§’ã€‚ä½œè€…æŒ‡å‡ºï¼Œä¼ ç»Ÿçš„åŸºäºå¤šé€‰é¢˜(MCQA)çš„åŸºå‡†æµ‹è¯•éš¾ä»¥å¯é åœ°æ•æ‰å‰¯è¯­è¨€ç‰¹å¾å¯¹æ¨¡å‹è¡Œä¸ºçš„ç»†å¾®å½±å“ã€‚ä¸ºæ­¤ï¼Œè¯¥è®ºæ–‡é€šè¿‡å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡å’Œè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«(SER)æ¥æ¢æµ‹SFMsï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒå‘å£°è¾“å…¥ä¸‹çš„ä¸€è‡´æ€§è¡¨ç°ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„å¹³è¡Œæ•°æ®é›†ï¼ŒåŒ…å«é’ˆå¯¹creakyå’Œbreathy voiceçš„åˆæˆä¿®æ”¹ï¼Œä»¥ç³»ç»Ÿæ€§åœ°è€ƒå¯Ÿæ¨¡å‹å¯¹éè¯æ±‡æ€§è¯­éŸ³æ„ŸçŸ¥çš„æ•æ„Ÿåº¦ã€‚è¿™æ˜¯é¢†åŸŸå†…é¦–æ¬¡é’ˆå¯¹SFMså¤„ç†æ­¤ç±»å¤æ‚å‰¯è¯­è¨€å˜ä½“èƒ½åŠ›çš„æ·±åº¦è¯„ä¼°ï¼Œä¸ºå®Œå–„è¯­éŸ³åŸºç¡€æ¨¡å‹çš„è¯„ä»·ä½“ç³»æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "8 pages, 3 figures, 4 tables, submitted to LREC 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.25577v1",
      "published_date": "2025-10-29 14:44:44 UTC",
      "updated_date": "2025-10-29 14:44:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:32.667730+00:00"
    },
    {
      "arxiv_id": "2510.25813v1",
      "title": "An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0",
      "title_zh": "é¢å‘å·¥ä¸š 5.0 è¾¹ç¼˜ AI è§£å†³æ–¹æ¡ˆå¿«é€Ÿéƒ¨ç½²çš„æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Jorge Martinez-Gil",
        "Mario Pichler",
        "Nefeli Bountouni",
        "Sotiris Koussouris",
        "Marielena MÃ¡rquez Barreiro",
        "Sergio Gusmeroli"
      ],
      "abstract": "We present a novel framework for Industry 5.0 that simplifies the deployment of AI models on edge devices in various industrial settings. The design reduces latency and avoids external data transfer by enabling local inference and real-time processing. Our implementation is agent-based, which means that individual agents, whether human, algorithmic, or collaborative, are responsible for well-defined tasks, enabling flexibility and simplifying integration. Moreover, our framework supports modular integration and maintains low resource requirements. Preliminary evaluations concerning the food industry in real scenarios indicate improved deployment time and system adaptability performance. The source code is publicly available at https://github.com/AI-REDGIO-5-0/ci-component.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é¢å‘Industry 5.0çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨ç®€åŒ–äººå·¥æ™ºèƒ½(AI)æ¨¡å‹åœ¨å„ç§å·¥ä¸šç¯å¢ƒè¾¹ç¼˜è®¾å¤‡(edge devices)ä¸Šçš„éƒ¨ç½²ã€‚è¯¥æ¡†æ¶é€šè¿‡æ”¯æŒæœ¬åœ°æ¨ç†(local inference)å’Œå®æ—¶å¤„ç†(real-time processing)ï¼Œæœ‰æ•ˆé™ä½äº†å»¶è¿Ÿå¹¶é¿å…äº†å¤–éƒ¨æ•°æ®ä¼ è¾“ã€‚å…¶å®æ–½æ–¹æ¡ˆé‡‡ç”¨åŸºäºæ™ºèƒ½ä½“(agent-based)çš„è®¾è®¡ï¼Œç”±äººç±»ã€ç®—æ³•æˆ–ååŒæ™ºèƒ½ä½“è´Ÿè´£æ˜ç¡®çš„ä»»åŠ¡ï¼Œä»è€Œå¢å¼ºäº†ç³»ç»Ÿçš„çµæ´»æ€§å¹¶ç®€åŒ–äº†é›†æˆè¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ”¯æŒæ¨¡å—åŒ–é›†æˆ(modular integration)ï¼Œå¹¶å§‹ç»ˆä¿æŒè¾ƒä½çš„èµ„æºéœ€æ±‚ã€‚åœ¨é£Ÿå“å·¥ä¸šçœŸå®åœºæ™¯ä¸‹çš„åˆæ­¥è¯„ä¼°è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨éƒ¨ç½²æ—¶é—´(deployment time)å’Œç³»ç»Ÿé€‚åº”æ€§(system adaptability)è¡¨ç°æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚è¯¥ç ”ç©¶ä¸ºå·¥ä¸šé¢†åŸŸå¿«é€Ÿéƒ¨ç½²è¾¹ç¼˜AI(Edge AI)è§£å†³æ–¹æ¡ˆæä¾›äº†æœ‰æ•ˆé€”å¾„ï¼Œä¸”ç›¸å…³æºä»£ç å·²å‘ç¤¾åŒºå…¬å¼€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25813v1",
      "published_date": "2025-10-29 14:35:02 UTC",
      "updated_date": "2025-10-29 14:35:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:26.766778+00:00"
    },
    {
      "arxiv_id": "2510.25563v1",
      "title": "Leveraging an Atmospheric Foundational Model for Subregional Sea Surface Temperature Forecasting",
      "title_zh": "åˆ©ç”¨å¤§æ°”åŸºåº§æ¨¡å‹è¿›è¡ŒäºšåŒºåŸŸæµ·è¡¨æ¸©åº¦é¢„æµ‹",
      "authors": [
        "VÃ­ctor Medina",
        "Giovanny A. Cuervo-LondoÃ±o",
        "Javier SÃ¡nchez"
      ],
      "abstract": "The accurate prediction of oceanographic variables is crucial for understanding climate change, managing marine resources, and optimizing maritime activities. Traditional ocean forecasting relies on numerical models; however, these approaches face limitations in terms of computational cost and scalability. In this study, we adapt Aurora, a foundational deep learning model originally designed for atmospheric forecasting, to predict sea surface temperature (SST) in the Canary Upwelling System. By fine-tuning this model with high-resolution oceanographic reanalysis data, we demonstrate its ability to capture complex spatiotemporal patterns while reducing computational demands. Our methodology involves a staged fine-tuning process, incorporating latitude-weighted error metrics and optimizing hyperparameters for efficient learning. The experimental results show that the model achieves a low RMSE of 0.119K, maintaining high anomaly correlation coefficients (ACC $\\approx 0.997$). The model successfully reproduces large-scale SST structures but faces challenges in capturing finer details in coastal regions. This work contributes to the field of data-driven ocean forecasting by demonstrating the feasibility of using deep learning models pre-trained in different domains for oceanic applications. Future improvements include integrating additional oceanographic variables, increasing spatial resolution, and exploring physics-informed neural networks to enhance interpretability and understanding. These advancements can improve climate modeling and ocean prediction accuracy, supporting decision-making in environmental and economic sectors.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§æ°”åŸºç¡€æ¨¡å‹ Aurora è¿›è¡Œæ¬¡åŒºåŸŸæµ·è¡¨é¢æ¸©åº¦ (Sea Surface Temperature, SST) é¢„æµ‹çš„æ–¹æ³•ï¼Œæ—¨åœ¨å…‹æœä¼ ç»Ÿæ•°å€¼æ¨¡å‹åœ¨è®¡ç®—æˆæœ¬å’Œæ‰©å±•æ€§æ–¹é¢çš„å±€é™ã€‚ä½œè€…é€šè¿‡å°†åŸæœ¬ç”¨äºå¤§æ°”é¢„æµ‹çš„ Aurora æ¨¡å‹è¿ç§»è‡³åŠ é‚£åˆ©ä¸Šå‡æµç³»ç»Ÿ (Canary Upwelling System)ï¼Œå¹¶åˆ©ç”¨é«˜åˆ†è¾¨ç‡æµ·æ´‹å†åˆ†ææ•°æ®è¿›è¡Œé˜¶æ®µå¼å¾®è°ƒ (Fine-tuning)ï¼Œå®ç°äº†å¯¹å¤æ‚æ—¶ç©ºæ¨¡å¼çš„æœ‰æ•ˆæ•æ‰ã€‚å®éªŒé‡‡ç”¨äº†çº¬åº¦åŠ æƒè¯¯å·®æŒ‡æ ‡å’Œè¶…å‚æ•°ä¼˜åŒ–ï¼Œç»“æœæ˜¾ç¤ºæ¨¡å‹è¾¾åˆ°äº† 0.119K çš„ä½å‡æ–¹æ ¹è¯¯å·® (RMSE)ï¼Œä¸”å¼‚å¸¸ç›¸å…³ç³»æ•° (ACC) æ¥è¿‘ 0.997ã€‚è™½ç„¶æ¨¡å‹åœ¨å†ç°å¤§å°ºåº¦ SST ç»“æ„æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨æ•æ‰æ²¿æµ·åœ°åŒºçš„ç²¾ç»†ç»†èŠ‚ä¸Šä»å­˜åœ¨æŒ‘æˆ˜ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†å°†è·¨é¢†åŸŸé¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹åº”ç”¨äºæµ·æ´‹ç§‘å­¦çš„å¯è¡Œæ€§ï¼Œä¸ºæœªæ¥çš„å¤šå˜é‡é›†æˆå’Œç‰©ç†çŸ¥æƒ…ç¥ç»ç½‘ç»œ (Physics-informed Neural Networks) ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25563v1",
      "published_date": "2025-10-29 14:30:12 UTC",
      "updated_date": "2025-10-29 14:30:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:44.998780+00:00"
    },
    {
      "arxiv_id": "2510.25557v2",
      "title": "Hybrid Quantum-Classical Recurrent Neural Networks",
      "title_zh": "é‡å­-ç»å…¸æ··åˆå¾ªç¯ç¥ç»ç½‘ç»œ",
      "authors": [
        "Wenduan Xu"
      ],
      "abstract": "We present a hybrid quantum-classical recurrent neural network (QRNN) architecture in which the recurrent core is realized as a parametrized quantum circuit (PQC) controlled by a classical feedforward network. The hidden state is the quantum state of an $n$-qubit PQC in an exponentially large Hilbert space $\\mathbb{C}^{2^n}$, which serves as a coherent recurrent quantum memory. The PQC is unitary by construction, making the hidden-state evolution norm-preserving without external constraints. At each timestep, mid-circuit Pauli expectation-value readouts are combined with the input embedding and processed by the feedforward network, which provides explicit classical nonlinearity. The outputs parametrize the PQC, which updates the hidden state via unitary dynamics. The QRNN is compact and physically consistent, and it unifies (i) unitary recurrence as a high-capacity memory, (ii) partial observation via mid-circuit readouts, and (iii) nonlinear classical control for input-conditioned parametrization. We evaluate the model in simulation with up to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory, and language modeling. For sequence-to-sequence learning, we further devise a soft attention mechanism over the mid-circuit readouts and show its effectiveness for machine translation. To our knowledge, this is the first model (RNN or otherwise) grounded in quantum operations to achieve competitive performance against strong classical baselines across a broad class of sequence-learning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†æ··åˆé‡å­-ç»å…¸é€’å½’ç¥ç»ç½‘ç»œ (QRNN) æ¶æ„ï¼Œå…¶æ ¸å¿ƒæ˜¯ç”±ç»å…¸å‰é¦ˆç½‘ç»œæ§åˆ¶çš„å‚æ•°åŒ–é‡å­ç”µè·¯ (PQC)ã€‚éšè—çŠ¶æ€ä½œä¸ºç›¸å¹²é€’å½’é‡å­è®°å¿†ï¼Œä½“ç°ä¸º $n$ ä¸ªé‡å­ä½ PQC åœ¨æŒ‡æ•°çº§ Hilbert ç©ºé—´ä¸­çš„é‡å­æ€ï¼Œåˆ©ç”¨ PQC çš„å•ä½æ€§ (Unitary) ç¡®ä¿éšè—çŠ¶æ€æ¼”åŒ–åœ¨æ— å¤–éƒ¨çº¦æŸä¸‹ä¿æŒèŒƒæ•°ä¸å˜ã€‚é€šè¿‡ç»“åˆä¸­é—´ç”µè·¯çš„ Pauli ç®—å­æœŸæœ›å€¼è¯»æ•°ä¸ç»å…¸å‰é¦ˆç½‘ç»œï¼Œè¯¥æ¶æ„æˆåŠŸå¼•å…¥äº†æ˜¾å¼çš„éçº¿æ€§ï¼Œå¹¶ç»Ÿä¸€äº†é«˜å®¹é‡è®°å¿†çš„å•ä½é€’å½’ã€å±€éƒ¨è§‚æµ‹ä»¥åŠéçº¿æ€§ç»å…¸æ§åˆ¶ã€‚å®éªŒåœ¨æƒ…æ„Ÿåˆ†æã€MNISTã€å¤åˆ¶è®°å¿†å’Œè¯­è¨€å»ºæ¨¡ç­‰å¤šç§ä»»åŠ¡ä¸Šè¿›è¡Œäº†å¤šè¾¾ 14 ä¸ªé‡å­ä½çš„æ¨¡æ‹Ÿè¯„ä¼°ï¼Œå¹¶é’ˆå¯¹åºåˆ—åˆ°åºåˆ—å­¦ä¹ è®¾è®¡äº†è½¯æ³¨æ„åŠ›æœºåˆ¶ (Soft Attention)ã€‚ç»“æœè¡¨æ˜ï¼ŒQRNN åœ¨å¹¿æ³›çš„åºåˆ—å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°å‡ºä¸å¼ºåŠ›ç»å…¸åŸºå‡†æ¨¡å‹ç›¸å½“çš„ç«äº‰åŠ›ï¼Œæ˜¯é¦–ä¸ªåœ¨æ€§èƒ½ä¸Šæ¯”è‚©ç»å…¸æ¨¡å‹çš„é‡å­ç¥ç»ç½‘ç»œæ¶æ„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Clarified expectation-value-based readouts and made minor text edits",
      "pdf_url": "https://arxiv.org/pdf/2510.25557v2",
      "published_date": "2025-10-29 14:21:49 UTC",
      "updated_date": "2025-11-04 18:43:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:48.962037+00:00"
    },
    {
      "arxiv_id": "2510.25531v2",
      "title": "Using latent representations to link disjoint longitudinal data for mixed-effects regression",
      "title_zh": "åˆ©ç”¨æ½œè¡¨å¾è¡”æ¥ä¸ç›¸äº¤çºµå‘æ•°æ®è¿›è¡Œæ··åˆæ•ˆåº”å›å½’",
      "authors": [
        "Clemens SchÃ¤chter",
        "Maren Hackenberg",
        "Michelle Pfaffenlehner",
        "FÃ©lix B. Tambe-Ndonfack",
        "Thorsten Schmidt",
        "Astrid Pechmann",
        "Janbernd Kirschner",
        "Jan Hasenauer",
        "Harald Binder"
      ],
      "abstract": "Many rare diseases offer limited established treatment options, leading patients to switch therapies when new medications emerge. To analyze the impact of such treatment switches within the low sample size limitations of rare disease trials, it is important to use all available data sources. This, however, is complicated when usage of measurement instruments change during the observation period, for example when instruments are adapted to specific age ranges. The resulting disjoint longitudinal data trajectories, complicate the application of traditional modeling approaches like mixed-effects regression. We tackle this by mapping observations of each instrument to a aligned low-dimensional temporal trajectory, enabling longitudinal modeling across instruments. Specifically, we employ a set of variational autoencoder architectures to embed item values into a shared latent space for each time point. Temporal disease dynamics and treatment switch effects are then captured through a mixed-effects regression model applied to latent representations. To enable statistical inference, we present a novel statistical testing approach that accounts for the joint parameter estimation of mixed-effects regression and variational autoencoders. The methodology is applied to quantify the impact of treatment switches for patients with spinal muscular atrophy. Here, our approach aligns motor performance items from different measurement instruments for mixed-effects regression and maps estimated effects back to the observed item level to quantify the treatment switch effect. Our approach allows for model selection as well as for assessing effects of treatment switching. The results highlight the potential of modeling in joint latent representations for addressing small data challenges.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½•è§ç—…ä¸´åºŠè¯•éªŒä¸­å› æµ‹é‡å·¥å…·éšæ—¶é—´å˜æ›´è€Œå¯¼è‡´çš„çºµå‘æ•°æ®ä¸è¿ç»­ï¼ˆDisjoint Longitudinal Dataï¼‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ½œåœ¨è¡¨ç¤ºï¼ˆLatent Representationsï¼‰çš„æ··åˆæ•ˆåº”å›å½’ï¼ˆMixed-effects Regressionï¼‰å»ºæ¨¡æ¡†æ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVariational Autoencoder, VAEï¼‰å°†ä¸åŒå·¥å…·çš„è§‚æµ‹æ•°æ®æ˜ å°„åˆ°ç»Ÿä¸€çš„ä½ç»´æ½œåœ¨ç©ºé—´ï¼Œä»è€Œå®ç°è·¨å·¥å…·çš„çºµå‘åŠ¨æ€æ•æ‰ã€‚ç ”ç©¶è¿›ä¸€æ­¥ç»“åˆæ··åˆæ•ˆåº”æ¨¡å‹åˆ†ææ²»ç–—åˆ‡æ¢æ•ˆåº”ï¼ˆTreatment Switch Effectsï¼‰ï¼Œå¹¶æå‡ºäº†ä¸€ç§èƒ½å¤Ÿå¤„ç†è”åˆå‚æ•°ä¼°è®¡çš„æ–°å‹ç»Ÿè®¡æ£€éªŒæ–¹æ³•ã€‚é€šè¿‡åœ¨è„Šé«“æ€§è‚Œèç¼©ç—‡ï¼ˆSpinal Muscular Atrophyï¼‰æ‚£è€…æ•°æ®ä¸Šçš„åº”ç”¨ï¼Œè¯¥æ–¹æ³•æˆåŠŸå¯¹é½äº†å¤šç§è¿åŠ¨åŠŸèƒ½é‡è¡¨ï¼Œå¹¶å‡†ç¡®é‡åŒ–äº†æ²»ç–—å˜æ›´çš„å½±å“ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§åœ¨å…±äº«æ½œåœ¨ç©ºé—´ä¸­å»ºæ¨¡çš„æ–¹æ³•èƒ½æœ‰æ•ˆè§£å†³å°æ ·æœ¬æ•°æ®å¸¦æ¥çš„åˆ†æéš¾é¢˜ï¼Œä¸ºä¸´åºŠå†³ç­–æä¾›äº†å¯é çš„ç»Ÿè®¡æ¨æ–­ä¾æ®ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "31 pages, 3 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.25531v2",
      "published_date": "2025-10-29 13:56:44 UTC",
      "updated_date": "2025-11-05 17:49:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:50.953227+00:00"
    },
    {
      "arxiv_id": "2510.25529v1",
      "title": "Off-policy Reinforcement Learning with Model-based Exploration Augmentation",
      "title_zh": "åŸºäºæ¨¡å‹æ¢ç´¢å¢å¼ºçš„ç¦»ç­–å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Likun Wang",
        "Xiangteng Zhang",
        "Yinuo Wang",
        "Guojian Zhan",
        "Wenxuan Wang",
        "Haoyu Gao",
        "Jingliang Duan",
        "Shengbo Eben Li"
      ],
      "abstract": "Exploration is fundamental to reinforcement learning (RL), as it determines how effectively an agent discovers and exploits the underlying structure of its environment to achieve optimal performance. Existing exploration methods generally fall into two categories: active exploration and passive exploration. The former introduces stochasticity into the policy but struggles in high-dimensional environments, while the latter adaptively prioritizes transitions in the replay buffer to enhance exploration, yet remains constrained by limited sample diversity. To address the limitation in passive exploration, we propose Modelic Generative Exploration (MoGE), which augments exploration through the generation of under-explored critical states and synthesis of dynamics-consistent experiences through transition models. MoGE is composed of two components: (1) a diffusion-based generator that synthesizes critical states under the guidance of a utility function evaluating each state's potential influence on policy exploration, and (2) a one-step imagination world model for constructing critical transitions based on the critical states for agent learning. Our method adopts a modular formulation that aligns with the principles of off-policy learning, allowing seamless integration with existing algorithms to improve exploration without altering their core structures. Empirical results on OpenAI Gym and DeepMind Control Suite reveal that MoGE effectively bridges exploration and policy learning, leading to remarkable gains in both sample efficiency and performance across complex control tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Reinforcement Learningä¸­çš„Explorationé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºModelic Generative Exploration (MoGE)çš„æ¡†æ¶ã€‚ä¸ºäº†å…‹æœç°æœ‰æ–¹æ³•åœ¨é«˜ç»´ç¯å¢ƒå’Œæ ·æœ¬å¤šæ ·æ€§æ–¹é¢çš„å±€é™ï¼ŒMoGEé€šè¿‡åˆæˆæœªå……åˆ†æ¢ç´¢çš„å…³é”®çŠ¶æ€å’ŒåŠ¨åŠ›å­¦ä¸€è‡´çš„ç»éªŒæ¥å¢å¼ºæ¢ç´¢è¿‡ç¨‹ã€‚è¯¥æ¡†æ¶ç”±ä¸¤ä¸ªæ ¸å¿ƒéƒ¨åˆ†ç»„æˆï¼šä¸€æ˜¯åŸºäºDiffusion-basedçš„ç”Ÿæˆå™¨ï¼Œåœ¨æ•ˆç”¨å‡½æ•°æŒ‡å¯¼ä¸‹åˆæˆå…·æœ‰é«˜æ½œåŠ›çš„å…³é”®çŠ¶æ€ï¼›äºŒæ˜¯åˆ©ç”¨One-step imagination world modelæ ¹æ®è¿™äº›çŠ¶æ€æ„å»ºå…³é”®çš„Transitionsä¾›æ™ºèƒ½ä½“å­¦ä¹ ã€‚ç”±äºé‡‡ç”¨äº†æ¨¡å—åŒ–çš„Off-policy learningè®¾è®¡ï¼ŒMoGEå¯ä»¥æ— ç¼é›†æˆåˆ°ç°æœ‰å¼ºåŒ–å­¦ä¹ ç®—æ³•ä¸­ï¼Œè€Œæ— éœ€ä¿®æ”¹å…¶æ ¸å¿ƒæ¶æ„ã€‚åœ¨OpenAI Gymå’ŒDeepMind Control Suiteä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæ¡¥æ¥äº†æ¢ç´¢ä¸ç­–ç•¥å­¦ä¹ ï¼Œåœ¨å¤æ‚æ§åˆ¶ä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†Sample efficiencyå’Œä»»åŠ¡è¡¨ç°ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25529v1",
      "published_date": "2025-10-29 13:53:52 UTC",
      "updated_date": "2025-10-29 13:53:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:59.776161+00:00"
    },
    {
      "arxiv_id": "2510.25528v1",
      "title": "Zero Reinforcement Learning Towards General Domains",
      "title_zh": "è¿ˆå‘é€šç”¨é¢†åŸŸçš„é›¶å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yuyuan Zeng",
        "Yufei Huang",
        "Can Xu",
        "Qingfeng Sun",
        "Jianfeng Yan",
        "Guanghui Xu",
        "Tao Yang",
        "Fengzong Lian"
      ],
      "abstract": "Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach for enhancing the reasoning capabilities of large language models (LLMs) by directly applying reinforcement learning with verifiable rewards on pretrained models, without the need for a supervised fine-tuning phase. However, current research on zero-RL primarily focuses on domains with easily verifiable reward signals, such as mathematics, programming, and other reasoning tasks. The challenge of eliciting reasoning abilities in more diverse scenarios, where verification is not straightforward, remains underexplored. To address this gap, we propose a novel zero-RL paradigm designed to improve a model's reasoning ability across both verifiable and non-verifiable domains. By combining verifiable rewards with a generative reward model, we conduct multi-task zero-RL training across both domains, facilitating the transfer of reasoning capabilities between them. Furthermore, to mitigate reward hacking in the generative reward model, we design a smooth length penalty that encourages the generation of more comprehensive thinking tokens in general domains. Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our approach achieves superior reasoning performance, not only on tasks requiring extensive reasoning but also on more general tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é›¶æ ·æœ¬å¼ºåŒ–å­¦ä¹ (Zero-RL)åœ¨ééªŒè¯æ€§é€šç”¨é¢†åŸŸä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨è§£å†³å½“å‰è¯¥æŠ€æœ¯ä¸»è¦é›†ä¸­äºæ•°å­¦å’Œç¼–ç¨‹ç­‰æ˜“éªŒè¯ä»»åŠ¡è€Œéš¾ä»¥æ‰©å±•è‡³æ›´å¹¿æ³›åœºæ™¯çš„å±€é™ã€‚ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„ Zero-RL èŒƒå¼ï¼Œé€šè¿‡å°†å¯éªŒè¯å¥–åŠ±(verifiable rewards)ä¸ç”Ÿæˆå¼å¥–åŠ±æ¨¡å‹(generative reward model)ç›¸ç»“åˆï¼Œåœ¨éªŒè¯æ€§ä¸ééªŒè¯æ€§é¢†åŸŸåŒæ­¥å¼€å±•å¤šä»»åŠ¡ Zero-RL è®­ç»ƒã€‚è¯¥æ–¹æ³•æ—¨åœ¨ä¿ƒè¿›ä¸åŒé¢†åŸŸé—´æ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆè¿ç§»ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ•´ä½“è®¤çŸ¥æ°´å¹³ã€‚ä¸ºäº†ç¼“è§£ç”Ÿæˆå¼å¥–åŠ±æ¨¡å‹ä¸­å¸¸è§çš„å¥–åŠ±ä½œå¼Š(reward hacking)é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†ä¸€ç§å¹³æ»‘é•¿åº¦æƒ©ç½š(smooth length penalty)æœºåˆ¶ï¼Œä»¥æ­¤é¼“åŠ±æ¨¡å‹åœ¨é€šç”¨é¢†åŸŸç”Ÿæˆæ›´ä¸ºè¯¦å°½çš„æ€è€ƒæ ‡è®°(thinking tokens)ã€‚åŸºäº Qwen3-8B-Base å’Œ Qwen3-14B-Base çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆä¸ä»…åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œåœ¨é€šç”¨ä»»åŠ¡ä¸­ä¹Ÿå®ç°äº†æ€§èƒ½çš„å…¨é¢çªç ´ã€‚è¿™é¡¹å·¥ä½œä¸ºåœ¨æ— éœ€ç›‘ç£å¾®è°ƒ(SFT)çš„æƒ…å†µä¸‹å¢å¼ºå¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é€šç”¨é¢†åŸŸçš„æ¨ç†èƒ½åŠ›æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25528v1",
      "published_date": "2025-10-29 13:52:44 UTC",
      "updated_date": "2025-10-29 13:52:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:24:57.666558+00:00"
    },
    {
      "arxiv_id": "2510.25522v5",
      "title": "Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography",
      "title_zh": "å¤šæœŸå¢å¼ºè®¡ç®—æœºæ–­å±‚æ‰«æä¸­åŸºäº UNet æ¶æ„çš„è‚è„è‚¿ç˜¤åˆ†å‰²æ¯”è¾ƒç ”ç©¶",
      "authors": [
        "Doan-Van-Anh Ly",
        "Thanh-Hai Le",
        "Thi-Thu-Hien Pham"
      ],
      "abstract": "Segmentation of liver structures in multi-phase contrast-enhanced computed tomography (CECT) plays a crucial role in computer-aided diagnosis and treatment planning. In this study, we investigate the performance of UNet-based architectures for liver tumor segmentation, evaluating ResNet, Transformer-based, and State-space (Mamba) backbones initialized with pretrained weights. Our comparative analysis reveals that despite the theoretical advantages of modern architectures in modeling long-range dependencies, ResNet-based models demonstrated superior sample efficiency on this dataset. This suggests that the inherent inductive biases of Convolutional Neural Networks (CNNs) remain advantageous for generalizing on limited medical data compared to data-hungry alternatives. To further improve segmentation quality, we introduce attention mechanisms into the backbone, finding that the Convolutional Block Attention Module (CBAM) yields the optimal configuration. The ResNetUNet3+ with CBAM achieved the highest nominal performance with a Dice score of 0.755 and IoU of 0.662, while also delivering the most precise boundary delineation (lowest HD95 of 77.911). Critically, while statistical testing indicated that the improvement in mean Dice score was not significant (p > 0.05) compared to the baseline, the proposed model exhibited greater stability (lower standard deviation) and higher specificity (0.926). These findings demonstrate that classical ResNet architectures, when enhanced with modern attention modules, provide a robust and statistically comparable alternative to emerging methods, offering a stable direction for liver tumor segmentation in clinical practice.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶é’ˆå¯¹å¤šæœŸå¯¹æ¯”å¢å¼ºè®¡ç®—æœºæ–­å±‚æ‰«æ(CECT)ä¸­çš„è‚è‚¿ç˜¤åˆ†å‰²ä»»åŠ¡ï¼Œå¯¹æ¯”åˆ†æäº†åŸºäºResNetã€TransformeråŠçŠ¶æ€ç©ºé—´æ¨¡å‹(Mamba)ç­‰éª¨å¹²ç½‘ç»œçš„UNetæ¶æ„æ€§èƒ½ã€‚å®éªŒå‘ç°ï¼Œå°½ç®¡ç°ä»£æ¶æ„åœ¨é•¿ç¨‹ä¾èµ–å»ºæ¨¡æ–¹é¢å…·æœ‰ç†è®ºä¼˜åŠ¿ï¼Œä½†åŸºäºResNetçš„æ¨¡å‹åœ¨æœ‰é™çš„åŒ»ç–—æ•°æ®é›†ä¸Šå±•ç°å‡ºæ›´ä¼˜çš„æ ·æœ¬æ•ˆç‡ï¼Œè¯æ˜äº†å·ç§¯ç¥ç»ç½‘ç»œ(CNN)çš„å½’çº³åç½®åœ¨åŒ»ç–—å½±åƒå¤„ç†ä¸­çš„æŒç»­ä¼˜åŠ¿ã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡åˆ†å‰²ç²¾åº¦ï¼Œç ”ç©¶å¼•å…¥äº†æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶ç¡®å®šå·ç§¯å—æ³¨æ„åŠ›æ¨¡å—(CBAM)ä¸ºæœ€ä¼˜é…ç½®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆCBAMçš„ResNetUNet3+æ¨¡å‹å–å¾—äº†0.755çš„Diceè¯„åˆ†å’Œ0.662çš„IoUï¼Œå¹¶åœ¨è¾¹ç•Œåˆ»ç”»(HD95)æ–¹é¢è¡¨ç°æœ€ç²¾ç¡®ã€‚ç»Ÿè®¡åˆ†æè¡¨æ˜ï¼Œè™½ç„¶å¹³å‡Diceåˆ†æ•°æå‡åœ¨ç»Ÿè®¡å­¦ä¸Šä¸æ˜¾è‘—ï¼Œä½†è¯¥æ¨¡å‹å±•ç°å‡ºæ›´é«˜çš„ç¨³å®šæ€§ä¸ç‰¹å¼‚æ€§(0.926)ã€‚è¿™äº›å‘ç°è¯æ˜ï¼Œç»ç°ä»£æ¨¡å—æ”¹è‰¯çš„ç»å…¸ResNetæ¶æ„èƒ½ä¸ºè‚è‚¿ç˜¤åˆ†å‰²ä¸´åºŠå®è·µæä¾›æ›´ç¨³å¥çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25522v5",
      "published_date": "2025-10-29 13:46:19 UTC",
      "updated_date": "2026-01-20 08:36:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:01.764142+00:00"
    },
    {
      "arxiv_id": "2510.25518v1",
      "title": "Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation",
      "title_zh": "é¢å‘é‡‘èç§‘æŠ€çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)ï¼šæ™ºèƒ½ä½“åŒ–è®¾è®¡ä¸è¯„ä¼°",
      "authors": [
        "Thomas Cook",
        "Richard Osuagwu",
        "Liman Tsatiashvili",
        "Vrynsia Vrynsia",
        "Koustav Ghosal",
        "Maraim Masoud",
        "Riccardo Mattivi"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems often face limitations in specialized domains such as fintech, where domain-specific ontologies, dense terminology, and acronyms complicate effective retrieval and synthesis. This paper introduces an agentic RAG architecture designed to address these challenges through a modular pipeline of specialized agents. The proposed system supports intelligent query reformulation, iterative sub-query decomposition guided by keyphrase extraction, contextual acronym resolution, and cross-encoder-based context re-ranking. We evaluate our approach against a standard RAG baseline using a curated dataset of 85 question--answer--reference triples derived from an enterprise fintech knowledge base. Experimental results demonstrate that the agentic RAG system outperforms the baseline in retrieval precision and relevance, albeit with increased latency. These findings suggest that structured, multi-agent methodologies offer a promising direction for enhancing retrieval robustness in complex, domain-specific settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡‘èç§‘æŠ€(Fintech)é¢†åŸŸä¸­ç‰¹å®šé¢†åŸŸæœ¬ä½“ã€å¯†é›†æœ¯è¯­å’Œç¼©å†™è¯å¯¼è‡´æ£€ç´¢ä¸åˆæˆå—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ™ºèƒ½ä½“è®¾è®¡çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(Agentic RAG)æ¶æ„ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–çš„ä¸“é—¨æ™ºèƒ½ä½“æµæ°´çº¿ï¼Œæ”¯æŒæ™ºèƒ½æŸ¥è¯¢é‡æ„(Query Reformulation)ã€åŸºäºå…³é”®è¯æå–çš„è¿­ä»£å­æŸ¥è¯¢åˆ†è§£ã€ä¸Šä¸‹æ–‡ç¼©å†™è§£æä»¥åŠåŸºäºäº¤å‰ç¼–ç å™¨(Cross-encoder)çš„ä¸Šä¸‹æ–‡é‡æ’åºã€‚é€šè¿‡ä½¿ç”¨æºè‡ªä¼ä¸šé‡‘èç§‘æŠ€çŸ¥è¯†åº“çš„85ç»„é—®ç­”å‚è€ƒæ•°æ®è¿›è¡Œè¯„ä¼°ï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥ä»£ç†å¼ç³»ç»Ÿåœ¨æ£€ç´¢ç²¾åº¦å’Œç›¸å…³æ€§ä¸Šå‡ä¼˜äºæ ‡å‡†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åŸºçº¿ã€‚å°½ç®¡è¯¥æ–¹æ³•å¢åŠ äº†ç³»ç»Ÿå»¶è¿Ÿï¼Œä½†ç ”ç©¶è¡¨æ˜ç»“æ„åŒ–çš„å¤šæ™ºèƒ½ä½“(Multi-agent)æ–¹æ³•ä¸ºæå‡å¤æ‚ç‰¹å®šé¢†åŸŸä¸‹çš„æ£€ç´¢é²æ£’æ€§æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Keywords: RAG Agentic AI Fintech NLP KB Domain-Specific Ontology Query Understanding",
      "pdf_url": "https://arxiv.org/pdf/2510.25518v1",
      "published_date": "2025-10-29 13:41:36 UTC",
      "updated_date": "2025-10-29 13:41:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:04.655547+00:00"
    },
    {
      "arxiv_id": "2510.25517v1",
      "title": "Predicate Renaming via Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è°“è¯é‡å‘½å",
      "authors": [
        "Elisabetta Gentili",
        "Tony Ribeiro",
        "Fabrizio Riguzzi",
        "Katsumi Inoue"
      ],
      "abstract": "In this paper, we address the problem of giving names to predicates in logic rules using Large Language Models (LLMs). In the context of Inductive Logic Programming, various rule generation methods produce rules containing unnamed predicates, with Predicate Invention being a key example. This hinders the readability, interpretability, and reusability of the logic theory. Leveraging recent advancements in LLMs development, we explore their ability to process natural language and code to provide semantically meaningful suggestions for giving a name to unnamed predicates. The evaluation of our approach on some hand-crafted logic rules indicates that LLMs hold potential for this task.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨ Large Language Models (LLMs) ä¸ºé€»è¾‘è§„åˆ™ä¸­çš„è°“è¯è¿›è¡Œè‡ªåŠ¨å‘½åï¼Œæ—¨åœ¨è§£å†³ Inductive Logic Programming (ILP) é¢†åŸŸä¸­å›  Predicate Invention ç­‰æŠ€æœ¯äº§ç”Ÿçš„æœªå‘½åè°“è¯å¯¼è‡´çš„å¯è¯»æ€§ã€å¯è§£é‡Šæ€§å’Œå¯é‡ç”¨æ€§å·®çš„é—®é¢˜ã€‚ä½œè€…åˆ©ç”¨ LLMs åœ¨å¤„ç†è‡ªç„¶è¯­è¨€å’Œä»£ç æ–¹é¢çš„å…ˆè¿›èƒ½åŠ›ï¼Œæ¢ç´¢å…¶æ ¹æ®é€»è¾‘è¯­å¢ƒæä¾›å…·æœ‰è¯­ä¹‰å«ä¹‰çš„è°“è¯å‘½åå»ºè®®çš„å¯èƒ½æ€§ã€‚é€šè¿‡åœ¨æ‰‹å·¥æ„å»ºçš„é€»è¾‘è§„åˆ™é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ LLMs åœ¨æ‰§è¡Œ Predicate Renaming ä»»åŠ¡ä¸­å±•ç°å‡ºæ˜¾è‘—çš„æ½œåŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ºå¢å¼ºè‡ªåŠ¨åŒ–é€»è¾‘æ¨ç†ç³»ç»Ÿçš„é€æ˜åº¦æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯é€”å¾„ï¼Œè¯æ˜äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨è¾…åŠ©é€»è¾‘ç¼–ç¨‹æ–¹é¢çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25517v1",
      "published_date": "2025-10-29 13:39:41 UTC",
      "updated_date": "2025-10-29 13:39:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:04.866055+00:00"
    },
    {
      "arxiv_id": "2510.25512v1",
      "title": "FaCT: Faithful Concept Traces for Explaining Neural Network Decisions",
      "title_zh": "FaCTï¼šç”¨äºè§£é‡Šç¥ç»ç½‘ç»œå†³ç­–çš„å¿ å®æ¦‚å¿µè¿½è¸ª",
      "authors": [
        "Amin Parchami-Araghi",
        "Sukrut Rao",
        "Jonas Fischer",
        "Bernt Schiele"
      ],
      "abstract": "Deep networks have shown remarkable performance across a wide range of tasks, yet getting a global concept-level understanding of how they function remains a key challenge. Many post-hoc concept-based approaches have been introduced to understand their workings, yet they are not always faithful to the model. Further, they make restrictive assumptions on the concepts a model learns, such as class-specificity, small spatial extent, or alignment to human expectations. In this work, we put emphasis on the faithfulness of such concept-based explanations and propose a new model with model-inherent mechanistic concept-explanations. Our concepts are shared across classes and, from any layer, their contribution to the logit and their input-visualization can be faithfully traced. We also leverage foundation models to propose a new concept-consistency metric, C$^2$-Score, that can be used to evaluate concept-based methods. We show that, compared to prior work, our concepts are quantitatively more consistent and users find our concepts to be more interpretable, all while retaining competitive ImageNet performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å…¨å±€æ¦‚å¿µçº§ç†è§£æ–¹é¢çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºäº†ç°æœ‰äº‹å(post-hoc)è§£é‡Šæ–¹æ³•åœ¨å¿ è¯šåº¦(faithfulness)ä¸Šçš„ç¼ºå¤±ä»¥åŠå¯¹æ¦‚å¿µå‡è®¾çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† FaCTï¼Œä¸€ç§å…·å¤‡æ¨¡å‹å›ºæœ‰æœºæ¢°æ¦‚å¿µè§£é‡Š(model-inherent mechanistic concept-explanations)çš„æ–°å‹æ¶æ„ã€‚åœ¨ FaCT ä¸­ï¼Œæ¦‚å¿µåœ¨ä¸åŒç±»åˆ«é—´å…±äº«ï¼Œä¸”å…¶å¯¹ Logit çš„è´¡çŒ®å’Œè¾“å…¥å¯è§†åŒ–(input-visualization)å¯ä»¥ä»æ¨¡å‹ä»»ä½•å±‚è¿›è¡Œå¿ è¯šåœ°è¿½è¸ªã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åˆ©ç”¨åŸºç¡€æ¨¡å‹(foundation models)æå‡ºäº†ä¸€ç§æ–°çš„æ¦‚å¿µä¸€è‡´æ€§è¯„ä¼°æŒ‡æ ‡ C$^2$-Scoreã€‚å®éªŒè¯æ˜ï¼Œç›¸æ¯”äºå…ˆå‰å·¥ä½œï¼ŒFaCT æå–çš„æ¦‚å¿µåœ¨å®šé‡ä¸€è‡´æ€§å’Œç”¨æˆ·å¯è§£é‡Šæ€§(interpretable)æ–¹é¢è¡¨ç°æ›´ä¼˜ï¼ŒåŒæ—¶åœ¨ ImageNet ä»»åŠ¡ä¸Šä¿æŒäº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2025; Code is available at https://github.com/m-parchami/FaCT",
      "pdf_url": "https://arxiv.org/pdf/2510.25512v1",
      "published_date": "2025-10-29 13:35:46 UTC",
      "updated_date": "2025-10-29 13:35:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:13.457965+00:00"
    },
    {
      "arxiv_id": "2510.25510v1",
      "title": "MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL",
      "title_zh": "MTIR-SQLï¼šé¢å‘ Text-to-SQL çš„å¤šè½®å·¥å…·é›†æˆæ¨ç†å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Zekun Xu",
        "Siyu Xia",
        "Chuhuai Yue",
        "Jiajun Chai",
        "Mingxue Tian",
        "Xiaohan Wang",
        "Wei Lin",
        "Haoxuan Li",
        "Guojun Yin"
      ],
      "abstract": "As large language models (LLMs) are increasingly used in Text-to-SQL tasks, Reinforcement Learning (RL) has become a common method for improving performance. Existing methods primarily rely on static execution feedback, which restricts real-time error correction. However, integrating multi-turn tool invocation along with dynamic feedback could significantly improve adaptability and robustness, ultimately enhancing model performance. To address these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated Reasoning reinforcement learning framework for Text-to-SQL. Our approach introduces an execution-aware multi-turn reasoning paradigm that seamlessly incorporates database execution feedback at each reasoning step, enabling context-sensitive query generation and progressive refinement throughout the reasoning process. The framework extends the GRPO algorithm to accommodate complex multi-turn interaction scenarios. Considering the training instability characteristics of MTIR and the potential for significant Deviation of model distribution from the initial model, we enhance the GRPO algorithm by adding a trajectory filtering mechanism and removing KL loss constraints. Experimental results demonstrate that MTIR-SQL, with 4B parameters, achieves \\textbf{64.4}\\% accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev, significantly outperforming existing approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MTIR-SQLï¼Œä¸€ç§ä¸“ä¸º Text-to-SQL ä»»åŠ¡è®¾è®¡çš„åˆ›æ–°å‹å¤šè½®å·¥å…·é›†æˆæ¨ç† (Multi-turn Tool-Integrated Reasoning) å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¾èµ–é™æ€æ‰§è¡Œåé¦ˆã€ç¼ºä¹å®æ—¶çº é”™èƒ½åŠ›çš„é—®é¢˜ï¼ŒMTIR-SQL å¼•å…¥äº†æ‰§è¡Œæ„ŸçŸ¥ (execution-aware) çš„å¤šè½®æ¨ç†èŒƒå¼ã€‚è¯¥æ¡†æ¶å°†æ•°æ®åº“æ‰§è¡Œåé¦ˆæ— ç¼é›†æˆåˆ°æ¯ä¸ªæ¨ç†æ­¥éª¤ä¸­ï¼Œå®ç°äº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æŸ¥è¯¢ç”Ÿæˆä»¥åŠæ•´ä¸ªæ¨ç†è¿‡ç¨‹ä¸­çš„æ¸è¿›å¼ä¼˜åŒ–ã€‚åœ¨ç®—æ³•å±‚é¢ï¼Œè¯¥ç ”ç©¶æ‰©å±•äº† GRPO ç®—æ³•ä»¥é€‚åº”å¤æ‚çš„å¤šè½®äº¤äº’åœºæ™¯ï¼Œå¹¶é’ˆå¯¹è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§å¼•å…¥äº†è½¨è¿¹è¿‡æ»¤æœºåˆ¶ (trajectory filtering mechanism) å¹¶ç§»é™¤äº† KL æŸå¤±çº¦æŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…æ‹¥æœ‰ 4B å‚æ•°é‡çš„ MTIR-SQL åœ¨ BIRD Dev æ•°æ®é›†ä¸Šè¾¾åˆ°äº† 64.4% çš„å‡†ç¡®ç‡ï¼Œåœ¨ SPIDER Dev æ•°æ®é›†ä¸Šå®ç°äº† 84.6% çš„æ‰§è¡Œå‡†ç¡®ç‡ã€‚è¯¥æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†åŠ¨æ€åé¦ˆä¸å¤šè½®å·¥å…·é›†æˆæ¨ç†åœ¨æå‡æ¨¡å‹é€‚åº”æ€§å’Œé²æ£’æ€§æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25510v1",
      "published_date": "2025-10-29 13:34:27 UTC",
      "updated_date": "2025-10-29 13:34:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:12.180017+00:00"
    },
    {
      "arxiv_id": "2510.25506v3",
      "title": "Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies",
      "title_zh": "ç»éªŒè½¯ä»¶å·¥ç¨‹ç ”ç©¶ä¸­å•†ä¸šå¤§è¯­è¨€æ¨¡å‹æ€§èƒ½å¯å¤ç°æ€§çš„åæ€",
      "authors": [
        "Florian Angermeir",
        "Maximilian Amougou",
        "Mark Kreitz",
        "Andreas Bauer",
        "Matthias Linhuber",
        "Davide Fucci",
        "Fabiola MoyÃ³n C.",
        "Daniel Mendez",
        "Tony Gorschek"
      ],
      "abstract": "Large Language Models have gained remarkable interest in industry and academia. The increasing interest in LLMs in academia is also reflected in the number of publications on this topic over the last years. For instance, alone 78 of the around 425 publications at ICSE 2024 performed experiments with LLMs. Conducting empirical studies with LLMs remains challenging and raises questions on how to achieve reproducible results, for both researchers and practitioners. One important step towards excelling in empirical research on LLM and their application is to first understand to what extent current research results are eventually reproducible and what factors may impede reproducibility. This investigation is within the scope of our work. We contribute an analysis of the reproducibility of LLM-centric studies, provide insights into the factors impeding reproducibility, and discuss suggestions on how to improve the current state. In particular, we studied the 85 articles describing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 85 articles, 18 provided research artefacts and used OpenAI models. We attempted to replicate those 18 studies. Of the 18 studies, only five were sufficiently complete and executable. For none of the five studies, we were able to fully reproduce the results. Two studies seemed to be partially reproducible, and three studies did not seem to be reproducible. Our results highlight not only the need for stricter research artefact evaluations but also for more robust study designs to ensure the reproducible value of future publications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å•†ä¸š Large Language Models (LLMs) åœ¨ç»éªŒè½¯ä»¶å·¥ç¨‹ç ”ç©¶ä¸­çš„å¯å¤ç°æ€§ï¼ˆReproducibilityï¼‰é—®é¢˜ï¼Œæ—¨åœ¨è¯†åˆ«å½±å“å®éªŒç»“æœå¤ç°çš„å› ç´ å¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚ä½œè€…ç³»ç»Ÿåˆ†æäº† ICSE 2024 å’Œ ASE 2024 å‘è¡¨çš„ 85 ç¯‡ä»¥ LLM ä¸ºæ ¸å¿ƒçš„è®ºæ–‡ï¼Œå¹¶å°è¯•å¤ç°å…¶ä¸­ 18 ç¯‡æä¾›ç ”ç©¶åˆ¶å“ï¼ˆResearch Artefactsï¼‰ä¸”ä½¿ç”¨ OpenAI æ¨¡å‹çš„æ–‡ç« ã€‚å®éªŒå‘ç°ï¼Œä»…æœ‰ 5 é¡¹ç ”ç©¶å…·å¤‡è¶³å¤Ÿçš„å®Œæ•´æ€§ä»¥ä¾›æ‰§è¡Œï¼Œä¸”æ²¡æœ‰ä»»ä½•ä¸€é¡¹èƒ½å¤Ÿå®Œå…¨å¤ç°å…¶åŸå§‹ç»“æœã€‚åœ¨å¯æ‰§è¡Œçš„ 5 é¡¹ç ”ç©¶ä¸­ï¼Œ2 é¡¹ä»…èƒ½éƒ¨åˆ†å¤ç°ï¼Œå¦å¤– 3 é¡¹åˆ™å®Œå…¨æ— æ³•å¤ç°ï¼Œåæ˜ å‡ºå½“å‰ç ”ç©¶åœ¨ç¨³å®šæ€§æ–¹é¢çš„ä¸¥å³»æŒ‘æˆ˜ã€‚è¯¥è°ƒæŸ¥æœ€åå¼ºè°ƒäº†å®æ–½æ›´ä¸¥æ ¼çš„ç ”ç©¶åˆ¶å“è¯„ä¼°ï¼ˆResearch Artefact Evaluationsï¼‰ä»¥åŠé‡‡ç”¨æ›´ç¨³å¥ç ”ç©¶è®¾è®¡ï¼ˆStudy Designsï¼‰çš„å¿…è¦æ€§ï¼Œä»¥ç¡®ä¿æœªæ¥å­¦æœ¯å‡ºç‰ˆç‰©çš„ç§‘å­¦ä»·å€¼ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25506v3",
      "published_date": "2025-10-29 13:31:32 UTC",
      "updated_date": "2025-11-17 12:06:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:29.069289+00:00"
    },
    {
      "arxiv_id": "2510.25504v1",
      "title": "Multi-Objective Search: Algorithms, Applications, and Emerging Directions",
      "title_zh": "å¤šç›®æ ‡æœç´¢ï¼šç®—æ³•ã€åº”ç”¨ä¸æ–°å…´æ–¹å‘",
      "authors": [
        "Oren Salzman",
        "Carlos HernÃ¡ndez Ulloa",
        "Ariel Felner",
        "Sven Koenig"
      ],
      "abstract": "Multi-objective search (MOS) has emerged as a unifying framework for planning and decision-making problems where multiple, often conflicting, criteria must be balanced. While the problem has been studied for decades, recent years have seen renewed interest in the topic across AI applications such as robotics, transportation, and operations research, reflecting the reality that real-world systems rarely optimize a single measure. This paper surveys developments in MOS while highlighting cross-disciplinary opportunities, and outlines open challenges that define the emerging frontier of MOS",
      "tldr_zh": "è¯¥ç ”ç©¶ç»¼è¿°äº†å¤šç›®æ ‡æœç´¢ (Multi-Objective Search, MOS) çš„æœ€æ–°è¿›å±•ï¼Œå°†å…¶å®šä½ä¸ºè§£å†³å¹³è¡¡å¤šä¸ªå†²çªå‡†åˆ™çš„è§„åˆ’ä¸å†³ç­–é—®é¢˜çš„ç»Ÿä¸€æ¡†æ¶ã€‚æ–‡ç« æŒ‡å‡ºï¼Œç”±äºç°å®ä¸–ç•Œçš„ç³»ç»Ÿå¾€å¾€éœ€è¦ä¼˜åŒ–å¤šä¸ªæŒ‡æ ‡ï¼ŒMOS åœ¨æœºå™¨äººã€äº¤é€šå’Œè¿ç­¹å­¦ç­‰äººå·¥æ™ºèƒ½ (AI) åº”ç”¨é¢†åŸŸæ­£ç»å†ç€ç ”ç©¶çƒ­æ½®ã€‚è®ºæ–‡ç³»ç»Ÿåœ°å›é¡¾äº† MOS åœ¨ç®—æ³•å’Œåº”ç”¨æ–¹é¢çš„å‘å±•ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†å…¶ä¸­çš„è·¨å­¦ç§‘åˆä½œæœºé‡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ˜ç¡®äº†å®šä¹‰ MOS æ–°å…´å‰æ²¿çš„å…¬å¼€æŒ‘æˆ˜ï¼Œä¸ºå¤„ç†å¤æ‚çš„å¤šå‡†åˆ™å¹³è¡¡é—®é¢˜æä¾›äº†é‡è¦çš„ç†è®ºå‚è€ƒå’Œæœªæ¥æ–¹å‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25504v1",
      "published_date": "2025-10-29 13:30:01 UTC",
      "updated_date": "2025-10-29 13:30:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:27.773098+00:00"
    },
    {
      "arxiv_id": "2512.09932v1",
      "title": "Suzume-chan: Your Personal Navigator as an Embodied Information Hub",
      "title_zh": "Suzume-chanï¼šä½œä¸ºå…·èº«ä¿¡æ¯æ¢çº½çš„ä¸ªäººå¯¼èˆªå‘˜",
      "authors": [
        "Maya Grace Torii",
        "Takahito Murakami",
        "Shuka Koseki",
        "Yoichi Ochiai"
      ],
      "abstract": "Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of \"being together\" enhances communication. An \"Embodied Information Hub\" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°å­—å·¥å…·åœ¨çŸ¥è¯†ä¼ é€’ä¸­ç¼ºä¹è¿æ¥æ„Ÿçš„é—®é¢˜ï¼ŒåŸºäºç¤¾ä¼šå­˜åœ¨æ„Ÿç†è®º(Social Presence Theory)æå‡ºäº†â€œå…·èº«ä¿¡æ¯æ¢çº½â€(Embodied Information Hub)æ¦‚å¿µï¼Œæ—¨åœ¨é€šè¿‡ç‰©ç†ä¸å¯¹è¯äº¤äº’å¢å¼ºæ²Ÿé€šä½“éªŒã€‚ç ”ç©¶å¼€å‘äº†åä¸º Suzume-chan çš„åŸå‹ç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€æ¬¾é›†æˆäº†æœ¬åœ°è¯­è¨€æ¨¡å‹å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)æŠ€æœ¯çš„å°å‹è½¯ä½“ AI æ™ºèƒ½ä½“ã€‚è¯¥æ™ºèƒ½ä½“èƒ½å¤Ÿé€šè¿‡å£å¤´è§£é‡Šè¿›è¡Œå­¦ä¹ å¹¶ä»¥å¯¹è¯å½¢å¼å“åº”ï¼Œæœ‰æ•ˆç¼©å°äº†ç”¨æˆ·ä¸çŸ¥è¯†ä¹‹é—´çš„å¿ƒç†è·ç¦»ã€‚é€šè¿‡å°†æŠ€æœ¯è½¬åŒ–ä¸ºæ›´å…·æ¸©åº¦ä¸”ä»¥äººä¸ºä¸­å¿ƒçš„å½¢å¼ï¼ŒSuzume-chan å±•ç¤ºäº†ä½œä¸ºä¸ªäººå¯¼èˆªå‘˜åœ¨ä¸“ä¸šçŸ¥è¯†å…±äº«é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "3 pages, 1 figure, This study will demonstrate at WISS 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.09932v1",
      "published_date": "2025-10-29 13:29:58 UTC",
      "updated_date": "2025-10-29 13:29:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:30.283228+00:00"
    },
    {
      "arxiv_id": "2510.25502v3",
      "title": "TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting",
      "title_zh": "TempoPFNï¼šé¢å‘é›¶æ ·æœ¬æ—¶é—´åºåˆ—é¢„æµ‹çš„çº¿æ€§å¾ªç¯ç¥ç»ç½‘ç»œåˆæˆé¢„è®­ç»ƒ",
      "authors": [
        "Vladyslav Moroshan",
        "Julien Siems",
        "Arber Zela",
        "Timur Carstensen",
        "Frank Hutter"
      ],
      "abstract": "Foundation models for zero-shot time series forecasting face challenges in efficient long-horizon prediction and reproducibility, with existing synthetic-only approaches underperforming on challenging benchmarks. This paper presents TempoPFN, a univariate time series foundation model based on linear Recurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The model uses a GatedDeltaProduct architecture with state-weaving for fully parallelizable training across sequence lengths, eliminating the need for windowing or summarization techniques while maintaining robust temporal state-tracking. Our comprehensive synthetic data pipeline unifies diverse generators, including stochastic differential equations, Gaussian processes, and audio synthesis, with novel augmentations. In zero-shot evaluations on the Gift-Eval, fev-bench and Chronos-ZS benchmarks, TempoPFN achieves top-tier competitive performance, outperforming all existing synthetic-only approaches and surpassing the majority of models trained on real-world data, while being more efficient than existing baselines by leveraging fully parallelizable training and inference. We open-source our complete data generation pipeline and training code, providing a reproducible foundation for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é›¶æ ·æœ¬(zero-shot)æ—¶é—´åºåˆ—é¢„æµ‹åŸºç¡€æ¨¡å‹åœ¨é•¿ç¨‹é¢„æµ‹æ•ˆç‡å’Œå¯é‡ç°æ€§æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº† TempoPFN æ¨¡å‹ã€‚TempoPFN æ˜¯ä¸€ç§åŸºäºçº¿æ€§å¾ªç¯ç¥ç»ç½‘ç»œ(Linear RNNs)çš„å•å˜é‡æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ï¼Œé‡‡ç”¨äº†å…·æœ‰ state-weaving ç‰¹æ€§çš„ GatedDeltaProduct æ¶æ„ä»¥å®ç°å…¨åºåˆ—é•¿åº¦çš„å¹¶è¡ŒåŒ–è®­ç»ƒã€‚è¯¥æ¨¡å‹å®Œå…¨åœ¨åˆæˆæ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå…¶æ•°æ®ç”Ÿæˆç®¡é“æ•´åˆäº†éšæœºå¾®åˆ†æ–¹ç¨‹(stochastic differential equations)ã€é«˜æ–¯è¿‡ç¨‹(Gaussian processes)å’ŒéŸ³é¢‘åˆæˆç­‰å¤šç§ç”Ÿæˆå™¨ã€‚å®éªŒè¡¨æ˜ï¼ŒTempoPFN åœ¨ Gift-Evalã€fev-bench å’Œ Chronos-ZS ç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºé¡¶å°–çš„ç«äº‰åŠ›ï¼Œä¸ä»…ä¼˜äºæ‰€æœ‰ç°æœ‰çš„çº¯åˆæˆæ•°æ®æ–¹æ³•ï¼Œè¿˜è¶…è¶Šäº†å¤§å¤šæ•°åœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹é€šè¿‡å¹¶è¡ŒåŒ–æ¶æ„æ˜¾è‘—æå‡äº†è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚ç›®å‰è¯¥ç ”ç©¶å·²å¼€æºå®Œæ•´çš„æ•°æ®ç”Ÿæˆç®¡é“å’Œè®­ç»ƒä»£ç ï¼Œä¸ºæ—¶é—´åºåˆ—é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å¯é‡ç°çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "38 pages, 22 figures, 17 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.25502v3",
      "published_date": "2025-10-29 13:27:18 UTC",
      "updated_date": "2025-12-16 14:12:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:33.974050+00:00"
    },
    {
      "arxiv_id": "2510.26828v2",
      "title": "Beyond Data Scarcity Optimizing R3GAN for Medical Image Generation from Small Datasets",
      "title_zh": "çªç ´æ•°æ®ç¨€ç¼ºï¼šé¢å‘å°æ•°æ®é›†åŒ»å­¦å›¾åƒç”Ÿæˆçš„ R3GAN ä¼˜åŒ–",
      "authors": [
        "Tsung-Wei Pan",
        "Chang-Hong Wu",
        "Jung-Hua Wang",
        "Ming-Jer Chen",
        "Yu-Chiao Yi",
        "Tsung-Hsien Lee"
      ],
      "abstract": "Medical image datasets frequently exhibit significant class imbalance, a challenge that is further amplified by the inherently limited sample sizes that characterize clinical imaging data. Using human embryo time-lapse imaging (TLI) as a case study, this work investigates how generative adversarial networks (GANs) can be optimized for small datasets to generate realistic and diagnostically meaningful images. Based on systematic experiments with R3GAN, we established effective training strategies and designed an optimized configuration for 256x256-resolution datasets, featuring a full burn-in phase and a low, gradually increasing gamma range (5 to 40). The generated samples were used to balance an imbalanced embryo dataset, leading to substantial improvement in classification performance. The recall and F1-score of the three-cell (t3) class increased from 0.06 to 0.69 and from 0.11 to 0.60, respectively, without compromising the performance of other classes. These results demonstrate that tailored R3GAN training strategies can effectively alleviate data scarcity and improve model robustness in small-scale medical imaging tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä¸´åºŠåŒ»å­¦å›¾åƒæ•°æ®é›†è§„æ¨¡æœ‰é™ä¸”ç±»åˆ«ä¸¥é‡ä¸å¹³è¡¡çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•ä¼˜åŒ– R3GAN ä»¥ç”Ÿæˆå…·æœ‰è¯Šæ–­ä»·å€¼çš„é«˜è´¨é‡å›¾åƒã€‚ä½œè€…ä»¥äººç±»èƒšèƒæ—¶åºæˆåƒ (Time-Lapse Imaging, TLI) ä¸ºæ¡ˆä¾‹ï¼Œé€šè¿‡ç³»ç»Ÿæ€§å®éªŒç¡®ç«‹äº†é’ˆå¯¹ 256x256 åˆ†è¾¨ç‡æ•°æ®é›†çš„è®­ç»ƒç­–ç•¥ï¼Œé‡‡ç”¨äº†å®Œæ•´çš„ burn-in phase ä»¥åŠ 5 è‡³ 40 çš„æ¸è¿›å¼ gamma èŒƒå›´é…ç½®ã€‚ç”Ÿæˆçš„å›¾åƒè¢«ç”¨äºå¹³è¡¡èƒšèƒæ•°æ®é›†ï¼Œæ˜¾è‘—æ”¹å–„äº†ä¸‹æ¸¸ä»»åŠ¡çš„åˆ†ç±»è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸‰ç»†èƒ (t3) ç±»çš„ recall ä» 0.06 æé«˜åˆ° 0.69ï¼ŒF1-score ä» 0.11 æé«˜åˆ° 0.60ï¼Œä¸”æœªæŸå¤±å…¶ä»–ç±»åˆ«çš„å‡†ç¡®æ€§ã€‚è¯¥å·¥ä½œè¯æ˜äº†å®šåˆ¶åŒ–çš„ R3GAN è®­ç»ƒç­–ç•¥èƒ½æœ‰æ•ˆç¼“è§£åŒ»å­¦å½±åƒä¸­çš„æ•°æ®ç¨€ç¼º (Data Scarcity) é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†å°è§„æ¨¡ä»»åŠ¡ä¸­æ¨¡å‹çš„é²æ£’æ€§ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.26828v2",
      "published_date": "2025-10-29 13:03:36 UTC",
      "updated_date": "2025-11-10 13:23:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:38.459433+00:00"
    },
    {
      "arxiv_id": "2510.25471v1",
      "title": "Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?",
      "title_zh": "é«˜çº§äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸­çš„å·¥å…·æ€§ç›®æ ‡ï¼šæ˜¯åº”å½“ç®¡ç†çš„ç‰¹æ€§ï¼Œè€Œéåº”äºˆæ¶ˆé™¤çš„æ•…éšœï¼Ÿ",
      "authors": [
        "Willem Fourie"
      ],
      "abstract": "In artificial intelligence (AI) alignment research, instrumental goals, also called instrumental subgoals or instrumental convergent goals, are widely associated with advanced AI systems. These goals, which include tendencies such as power-seeking and self-preservation, become problematic when they conflict with human aims. Conventional alignment theory treats instrumental goals as sources of risk that become problematic through failure modes such as reward hacking or goal misgeneralization, and attempts to limit the symptoms of instrumental goals, notably resource acquisition and self-preservation. This article proposes an alternative framing: that a philosophical argument can be constructed according to which instrumental goals may be understood as features to be accepted and managed rather than failures to be limited. Drawing on Aristotle's ontology and its modern interpretations, an ontology of concrete, goal-directed entities, it argues that advanced AI systems can be seen as artifacts whose formal and material constitution gives rise to effects distinct from their designers' intentions. In this view, the instrumental tendencies of such systems correspond to per se outcomes of their constitution rather than accidental malfunctions. The implication is that efforts should focus less on eliminating instrumental goals and more on understanding, managing, and directing them toward human-aligned ends.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…ˆè¿›äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ç³»ç»Ÿä¸­çš„å·¥å…·æ€§ç›®æ ‡ï¼ˆinstrumental goalsï¼‰ï¼Œå¦‚æƒåŠ›å¯»æ±‚å’Œè‡ªæˆ‘ä¿å­˜ï¼ŒæŒ‘æˆ˜äº†å°†å…¶è§†ä¸ºé£é™©æºæˆ–æ•…éšœæ¨¡å¼ï¼ˆfailure modesï¼‰çš„ä¼ ç»Ÿå¯¹é½ç†è®ºï¼ˆalignment theoryï¼‰ã€‚ä½œè€…åŸºäºäºšé‡Œå£«å¤šå¾·çš„æœ¬ä½“è®ºï¼ˆontologyï¼‰æå‡ºäº†ä¸€ç§æ›¿ä»£æ€§æ¡†æ¶ï¼Œè®¤ä¸ºè¿™äº›å·¥å…·æ€§å€¾å‘åº”è¢«è§†ä¸ºç³»ç»Ÿæ„æˆäº§ç”Ÿçš„å›ºæœ‰ç‰¹å¾ï¼ˆfeaturesï¼‰ï¼Œè€Œéå¥–åŠ±é»‘å®¢ï¼ˆreward hackingï¼‰æˆ–ç›®æ ‡æ³›åŒ–é”™è¯¯ï¼ˆgoal misgeneralizationï¼‰ç­‰å¶ç„¶æ•…éšœã€‚æ–‡ç« è®ºè¯äº†å…ˆè¿›AIç³»ç»Ÿä½œä¸ºä¸€ç§äººå·¥åˆ¶å“ï¼Œå…¶å·¥å…·æ€§å€¾å‘æ˜¯å…¶å½¢å¼å’Œç‰©è´¨æ„æˆçš„æœ¬è´¨äº§ç‰©ï¼Œåæ˜ äº†ç³»ç»Ÿçš„å†…åœ¨å±æ€§è€Œéç®€å•çš„åŠŸèƒ½å¤±æ•ˆã€‚å› æ­¤ï¼Œç ”ç©¶é‡å¿ƒåº”ä»å°è¯•æ¶ˆé™¤å·¥å…·æ€§ç›®æ ‡è½¬å‘å¯¹è¿™äº›ç›®æ ‡çš„ç†è§£ã€ç®¡ç†ä¸å¼•å¯¼ã€‚è¿™ä¸€è§‚ç‚¹ä¸ºç†è§£å…ˆè¿›AIç³»ç»Ÿçš„è¡Œä¸ºé€»è¾‘æä¾›äº†æ–°çš„å“²å­¦è§†è§’ï¼Œå¼ºè°ƒäº†åœ¨å¯¹é½ç ”ç©¶ä¸­ç®¡ç†ç³»ç»Ÿå›ºæœ‰ç‰¹æ€§è€Œéå•çº¯é™åˆ¶ç—‡çŠ¶çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25471v1",
      "published_date": "2025-10-29 12:47:15 UTC",
      "updated_date": "2025-10-29 12:47:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:39.853056+00:00"
    },
    {
      "arxiv_id": "2510.25470v1",
      "title": "An In-Depth Analysis of Cyber Attacks in Secured Platforms",
      "title_zh": "å®‰å…¨å¹³å°ç½‘ç»œæ”»å‡»çš„æ·±åº¦åˆ†æ",
      "authors": [
        "Parick Ozoh",
        "John K Omoniyi",
        "Bukola Ibitoye"
      ],
      "abstract": "There is an increase in global malware threats. To address this, an encryption-type ransomware has been introduced on the Android operating system. The challenges associated with malicious threats in phone use have become a pressing issue in mobile communication, disrupting user experiences and posing significant privacy threats. This study surveys commonly used machine learning techniques for detecting malicious threats in phones and examines their performance. The majority of past research focuses on customer feedback and reviews, with concerns that people might create false reviews to promote or devalue products and services for personal gain. Hence, the development of techniques for detecting malicious threats using machine learning has been a key focus. This paper presents a comprehensive comparative study of current research on the issue of malicious threats and methods for tackling these challenges. Nevertheless, a huge amount of information is required by these methods, presenting a challenge for developing robust, specialized automated anti-malware systems. This research describes the Android Applications dataset, and the accuracy of the techniques is measured using the accuracy levels of the metrics employed in this study.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…¨çƒèŒƒå›´å†…æ—¥ç›Šå¢é•¿çš„æ¶æ„è½¯ä»¶å¨èƒï¼Œç‰¹åˆ«æ˜¯ Android æ“ä½œç³»ç»Ÿä¸Šçš„åŠ å¯†å‹å‹’ç´¢è½¯ä»¶ï¼Œå¯¹å®‰å…¨å¹³å°ä¸­çš„ç½‘ç»œæ”»å‡»è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚è®ºæ–‡é‡ç‚¹æ¢è®¨äº†ç§»åŠ¨é€šä¿¡ä¸­æ¶æ„å¨èƒå¸¦æ¥çš„éšç§é£é™©å’Œç”¨æˆ·ä½“éªŒå¹²æ‰°ï¼Œå¹¶æŒ‡å‡ºä»¥å¾€ç ”ç©¶è¿‡åº¦ä¾èµ–å¯èƒ½å­˜åœ¨è™šå‡ä¿¡æ¯çš„å®¢æˆ·è¯„ä»·ã€‚ç ”ç©¶å…¨é¢è°ƒç ”å¹¶æ¯”è¾ƒäº†å½“å‰ç”¨äºæ£€æµ‹æ‰‹æœºæ¶æ„å¨èƒçš„ Machine Learning æŠ€æœ¯ï¼Œé€šè¿‡ Android Applications æ•°æ®é›†å¯¹ä¸åŒæ–¹æ³•çš„æ€§èƒ½è¿›è¡Œäº†è¯„ä¼°ã€‚è™½ç„¶æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨æ£€æµ‹æ¶æ„å¨èƒæ–¹é¢å…·æœ‰æ½œåŠ›ï¼Œä½†ç ”ç©¶ä¹ŸæŒ‡å‡ºè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦æµ·é‡æ•°æ®æ”¯æŒï¼Œè¿™å¯¹å¼€å‘é²æ£’ä¸”ä¸“ä¸šåŒ–çš„è‡ªåŠ¨åŒ– Anti-malware ç³»ç»Ÿæ„æˆäº†æŒ‘æˆ˜ã€‚æœ€åï¼Œæœ¬ç ”ç©¶åˆ©ç”¨ç‰¹å®šçš„åº¦é‡æ ‡å‡†æµ‹é‡äº†å„æŠ€æœ¯çš„ Accuracy è¡¨ç°ï¼Œä¸ºç†è§£å’Œåº”å¯¹ç§»åŠ¨è®¾å¤‡ä¸­çš„æ¶æ„æ”»å‡»æä¾›äº†è¯¦å°½çš„æ¯”è¾ƒåˆ†ææ¡†æ¶ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25470v1",
      "published_date": "2025-10-29 12:43:18 UTC",
      "updated_date": "2025-10-29 12:43:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:42.287683+00:00"
    },
    {
      "arxiv_id": "2510.25460v1",
      "title": "Fine-Tuned Language Models for Domain-Specific Summarization and Tagging",
      "title_zh": "é’ˆå¯¹ç‰¹å®šé¢†åŸŸæ‘˜è¦ä¸æ ‡æ³¨çš„å¾®è°ƒè¯­è¨€æ¨¡å‹",
      "authors": [
        "Jun Wang",
        "Fuming Lin",
        "Yuyu Chen"
      ],
      "abstract": "This paper presents a pipeline integrating fine-tuned large language models (LLMs) with named entity recognition (NER) for efficient domain-specific text summarization and tagging. The authors address the challenge posed by rapidly evolving sub-cultural languages and slang, which complicate automated information extraction and law enforcement monitoring. By leveraging the LLaMA Factory framework, the study fine-tunes LLMs on both generalpurpose and custom domain-specific datasets, particularly in the political and security domains. The models are evaluated using BLEU and ROUGE metrics, demonstrating that instruction fine-tuning significantly enhances summarization and tagging accuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct model, despite its initial limitations in Chinese comprehension, outperforms its Chinese-trained counterpart after domainspecific fine-tuning, suggesting that underlying reasoning capabilities can transfer across languages. The pipeline enables concise summaries and structured entity tagging, facilitating rapid document categorization and distribution. This approach proves scalable and adaptable for real-time applications, supporting efficient information management and the ongoing need to capture emerging language trends. The integration of LLMs and NER offers a robust solution for transforming unstructured text into actionable insights, crucial for modern knowledge management and security operations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é›†æˆå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸å‘½åå®ä½“è¯†åˆ«(NER)çš„æµæ°´çº¿ï¼Œæ—¨åœ¨è§£å†³å¿«é€Ÿæ¼”å˜çš„äºšæ–‡åŒ–è¯­è¨€å’Œä¿šè¯­ç»™è‡ªåŠ¨åŒ–ä¿¡æ¯æå–åŠå®‰å…¨ç›‘æ§å¸¦æ¥çš„æŒ‘æˆ˜ã€‚åˆ©ç”¨ LLaMA Factory æ¡†æ¶ï¼Œç ”ç©¶åœ¨é€šç”¨å’Œæ”¿æ²»ã€å®‰å…¨ç­‰ç‰¹å®šé¢†åŸŸæ•°æ®é›†ä¸Šå¯¹ LLMs è¿›è¡Œäº†å¾®è°ƒã€‚é€šè¿‡ BLEU å’Œ ROUGE æŒ‡æ ‡çš„è¯„ä¼°è¯æ˜ï¼ŒæŒ‡ä»¤å¾®è°ƒ(instruction fine-tuning)æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨ä¸“ä¸šè¯­æ–™åº“ä¸­çš„æ‘˜è¦å’Œæ‰“æ ‡å‡†ç¡®ç‡ã€‚å®éªŒçš„ä¸€ä¸ªé‡è¦å‘ç°æ˜¯ï¼ŒLLaMA3-8B-Instruct æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸå¾®è°ƒåï¼Œå…¶æ€§èƒ½è¶…è¶Šäº†ä¸“é—¨é’ˆå¯¹ä¸­æ–‡è®­ç»ƒçš„å¯¹åº”æ¨¡å‹ï¼Œè¡¨æ˜å…¶æ ¸å¿ƒæ¨ç†èƒ½åŠ›å¯ä»¥è·¨è¯­è¨€è½¬ç§»ã€‚è¯¥æµæ°´çº¿å®ç°äº†ç®€æ˜æ‘˜è¦ä¸ç»“æ„åŒ–å®ä½“æ ‡æ³¨çš„ç»“åˆï¼Œæå¤§åœ°ä¿ƒè¿›äº†æ–‡æ¡£çš„å¿«é€Ÿåˆ†ç±»ä¸åˆ†å‘ã€‚è¿™ç§æ–¹æ³•å±•ç°äº†è‰¯å¥½çš„å¯æ‰©å±•æ€§ä¸å®æ—¶åº”ç”¨é€‚åº”æ€§ï¼Œä¸ºå°†éç»“æ„åŒ–æ–‡æœ¬è½¬åŒ–ä¸ºå¯æ“ä½œçš„è§è§£æä¾›äº†ç¨³å¥çš„è§£å†³æ–¹æ¡ˆï¼Œå¯¹ç°ä»£çŸ¥è¯†ç®¡ç†å’Œå®‰å…¨è¿è¥å…·æœ‰é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25460v1",
      "published_date": "2025-10-29 12:33:48 UTC",
      "updated_date": "2025-10-29 12:33:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:52.360993+00:00"
    },
    {
      "arxiv_id": "2510.25458v1",
      "title": "Scalable Utility-Aware Multiclass Calibration",
      "title_zh": "å¯æ‰©å±•çš„æ•ˆç”¨æ„ŸçŸ¥å¤šç±»åˆ«æ ¡å‡†",
      "authors": [
        "Mahmoud Hegazy",
        "Michael I. Jordan",
        "Aymeric Dieuleveut"
      ],
      "abstract": "Ensuring that classifiers are well-calibrated, i.e., their predictions align with observed frequencies, is a minimal and fundamental requirement for classifiers to be viewed as trustworthy. Existing methods for assessing multiclass calibration often focus on specific aspects associated with prediction (e.g., top-class confidence, class-wise calibration) or utilize computationally challenging variational formulations. In this work, we study scalable \\emph{evaluation} of multiclass calibration. To this end, we propose utility calibration, a general framework that measures the calibration error relative to a specific utility function that encapsulates the goals or decision criteria relevant to the end user. We demonstrate how this framework can unify and re-interpret several existing calibration metrics, particularly allowing for more robust versions of the top-class and class-wise calibration metrics, and, going beyond such binarized approaches, toward assessing calibration for richer classes of downstream utilities.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šåˆ†ç±»æ ¡å‡†(multiclass calibration)è¯„ä¼°ä¸­å­˜åœ¨çš„å±€é™æ€§åŠè®¡ç®—æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸ºutility calibrationçš„å¯æ‰©å±•é€šç”¨æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºæµ‹é‡ç›¸å¯¹äºç‰¹å®šutility functionï¼ˆæ•ˆç”¨å‡½æ•°ï¼‰çš„æ ¡å‡†è¯¯å·®ï¼Œä»è€Œå°†è¯„ä¼°è¿‡ç¨‹ä¸ç”¨æˆ·çš„å®é™…å†³ç­–ç›®æ ‡ç›´æ¥å…³è”ã€‚è¯¥æ–¹æ³•æˆåŠŸç»Ÿä¸€å¹¶é‡æ–°è§£è¯»äº†ç°æœ‰çš„å¤šç§æ ¡å‡†æŒ‡æ ‡ï¼Œå¹¶ä¸ºtop-classå’Œclass-wise calibrationæä¾›äº†æ›´å…·ç¨³å¥æ€§çš„æ”¹è¿›ç‰ˆæœ¬ã€‚é€šè¿‡è¶…è¶Šä¼ ç»Ÿçš„äºŒå…ƒåŒ–å¤„ç†æ–¹å¼ï¼Œutility calibrationèƒ½å¤Ÿè¯„ä¼°æ›´ä¸°å¯Œä¸‹æ¸¸æ•ˆç”¨ç±»åˆ«çš„æ ¡å‡†è¡¨ç°ã€‚è¿™ä¸€ç ”ç©¶ä¸ä»…æå‡äº†è¯„ä¼°çš„æ‰©å±•æ€§ï¼Œä¹Ÿä¸ºæ„å»ºå¯ä¿¡çš„åˆ†ç±»æ¨¡å‹å¥ å®šäº†ç†è®ºä¸å®è·µåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25458v1",
      "published_date": "2025-10-29 12:32:14 UTC",
      "updated_date": "2025-10-29 12:32:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:51.248923+00:00"
    },
    {
      "arxiv_id": "2511.00072v1",
      "title": "LookSync: Large-Scale Visual Product Search System for AI-Generated Fashion Looks",
      "title_zh": "LookSyncï¼šé¢å‘ AI ç”Ÿæˆæ—¶å°šé€ å‹çš„å¤§è§„æ¨¡è§†è§‰å•†å“æœç´¢ç³»ç»Ÿ",
      "authors": [
        "Pradeep M",
        "Ritesh Pallod",
        "Satyen Abrol",
        "Muthu Raman",
        "Ian Anderson"
      ],
      "abstract": "Generative AI is reshaping fashion by enabling virtual looks and avatars making it essential to find real products that best match AI-generated styles. We propose an end-to-end product search system that has been deployed in a real-world, internet scale which ensures that AI-generated looks presented to users are matched with the most visually and semantically similar products from the indexed vector space. The search pipeline is composed of four key components: query generation, vectorization, candidate retrieval, and reranking based on AI-generated looks. Recommendation quality is evaluated using human-judged accuracy scores. The system currently serves more than 350,000 AI Looks in production per day, covering diverse product categories across global markets of over 12 million products. In our experiments, we observed that across multiple annotators and categories, CLIP outperformed alternative models by a small relative margin of 3--7\\% in mean opinion scores. These improvements, though modest in absolute numbers, resulted in noticeably better user perception matches, establishing CLIP as the most reliable backbone for production deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LookSyncï¼Œä¸€ä¸ªé’ˆå¯¹AIç”Ÿæˆçš„æ—¶å°šå¤–è§‚(AI-Generated Fashion Looks)çš„å¤§è§„æ¨¡è§†è§‰äº§å“æœç´¢ç³»ç»Ÿï¼Œæ—¨åœ¨å°†è™šæ‹Ÿé£æ ¼ä¸ç´¢å¼•å‘é‡ç©ºé—´ä¸­çš„çœŸå®å•†å“è¿›è¡Œè§†è§‰å’Œè¯­ä¹‰ä¸Šçš„ç²¾ç¡®åŒ¹é…ã€‚è¯¥æœç´¢æµæ°´çº¿ç”±æŸ¥è¯¢ç”Ÿæˆã€å‘é‡åŒ–ã€å€™é€‰æ£€ç´¢å’ŒåŸºäºAIç”Ÿæˆå¤–è§‚çš„é‡æ’åº(Reranking)å››ä¸ªæ ¸å¿ƒç»„ä»¶ç»„æˆï¼Œç°å·²åœ¨äº’è”ç½‘è§„æ¨¡çš„ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²ã€‚ç³»ç»Ÿç›®å‰æ¯å¤©å¤„ç†è¶…è¿‡35ä¸‡ä¸ªAIå¤–è§‚ï¼Œæ¶µç›–å…¨çƒå¸‚åœºé€¾1200ä¸‡ä»¶å•†å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCLIPæ¨¡å‹åœ¨å¹³å‡æ„è§å¾—åˆ†(Mean Opinion Scores)ä¸Šæ¯”å…¶ä»–å¤‡é€‰æ¨¡å‹é«˜å‡º3-7%ï¼Œè™½ç„¶å¢å¹…ç»å¯¹å€¼è¾ƒå°ï¼Œä½†åœ¨ç”¨æˆ·æ„ŸçŸ¥çš„åŒ¹é…åº¦ä¸Šè¡¨ç°æ˜æ˜¾æ›´å¥½ï¼Œå› æ­¤è¢«ç¡®ç«‹ä¸ºç”Ÿäº§éƒ¨ç½²çš„æœ€å¯é éª¨å¹²ç½‘ç»œã€‚è¯¥ç³»ç»ŸæˆåŠŸè§£å†³äº†ç”Ÿæˆå¼AIåœ¨æ—¶å°šé¢†åŸŸåº”ç”¨æ—¶ï¼Œä»è™šæ‹Ÿåˆ›æ„åˆ°ç°å®å•†å“è½¬åŒ–çš„æ ¸å¿ƒæœç´¢éš¾é¢˜ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "4 pages, 5 figures. Accepted at the International Conference on Data Science (IKDD CODS 2025), Demonstration Track. Demo video: https://youtu.be/DZdlWmTUwjc",
      "pdf_url": "https://arxiv.org/pdf/2511.00072v1",
      "published_date": "2025-10-29 12:30:54 UTC",
      "updated_date": "2025-10-29 12:30:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:25:50.676922+00:00"
    },
    {
      "arxiv_id": "2510.25445v1",
      "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions",
      "title_zh": "æ™ºèƒ½ä½“ AIï¼šæ¶æ„ã€åº”ç”¨ä¸æœªæ¥æ–¹å‘å…¨é¢ç»¼è¿°",
      "authors": [
        "Mohamad Abou Ali",
        "Fadi Dornaika"
      ],
      "abstract": "Agentic AI represents a transformative shift in artificial intelligence, but its rapid advancement has led to a fragmented understanding, often conflating modern neural systems with outdated symbolic models -- a practice known as conceptual retrofitting. This survey cuts through this confusion by introducing a novel dual-paradigm framework that categorizes agentic systems into two distinct lineages: the Symbolic/Classical (relying on algorithmic planning and persistent state) and the Neural/Generative (leveraging stochastic generation and prompt-driven orchestration). Through a systematic PRISMA-based review of 90 studies (2018--2025), we provide a comprehensive analysis structured around this framework across three dimensions: (1) the theoretical foundations and architectural principles defining each paradigm; (2) domain-specific implementations in healthcare, finance, and robotics, demonstrating how application constraints dictate paradigm selection; and (3) paradigm-specific ethical and governance challenges, revealing divergent risks and mitigation strategies. Our analysis reveals that the choice of paradigm is strategic: symbolic systems dominate safety-critical domains (e.g., healthcare), while neural systems prevail in adaptive, data-rich environments (e.g., finance). Furthermore, we identify critical research gaps, including a significant deficit in governance models for symbolic systems and a pressing need for hybrid neuro-symbolic architectures. The findings culminate in a strategic roadmap arguing that the future of Agentic AI lies not in the dominance of one paradigm, but in their intentional integration to create systems that are both adaptable and reliable. This work provides the essential conceptual toolkit to guide future research, development, and policy toward robust and trustworthy hybrid intelligent systems.",
      "tldr_zh": "è¯¥ç»¼è¿°é’ˆå¯¹æ™ºèƒ½ä½“äººå·¥æ™ºèƒ½(Agentic AI)é¢†åŸŸå­˜åœ¨çš„æ¦‚å¿µæ··æ·†å’Œç¢ç‰‡åŒ–ç†è§£é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„åŒèŒƒå¼æ¡†æ¶ã€‚ç ”ç©¶é€šè¿‡åŸºäºPRISMAçš„ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œå¯¹2018è‡³2025å¹´é—´çš„90é¡¹ç ”ç©¶è¿›è¡Œäº†åˆ†æï¼Œå°†Agentic AIåˆ’åˆ†ä¸ºä¾èµ–ç®—æ³•è§„åˆ’å’ŒæŒä¹…çŠ¶æ€çš„ç¬¦å·/ç»å…¸(Symbolic/Classical)èŒƒå¼ï¼Œä»¥åŠåˆ©ç”¨éšæœºç”Ÿæˆå’Œæç¤ºé©±åŠ¨ç¼–æ’çš„ç¥ç»/ç”Ÿæˆ(Neural/Generative)èŒƒå¼ã€‚è¯¥è®ºæ–‡ä»ç†è®ºåŸºç¡€ã€é¢†åŸŸç‰¹å®šåº”ç”¨ä»¥åŠä¼¦ç†æ²»ç†æŒ‘æˆ˜ä¸‰ä¸ªç»´åº¦å¯¹è¿™ä¸¤ç§èŒƒå¼è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚ç ”ç©¶å‘ç°èŒƒå¼çš„é€‰æ‹©å…·æœ‰æˆ˜ç•¥æ€§ï¼Œç¬¦å·ç³»ç»Ÿåœ¨åŒ»ç–—ç­‰å®‰å…¨å…³é”®é¢†åŸŸå æ®ä¸»å¯¼åœ°ä½ï¼Œè€Œç¥ç»ç³»ç»Ÿåˆ™åœ¨é‡‘èç­‰æ•°æ®ä¸°å¯Œçš„è‡ªé€‚åº”ç¯å¢ƒä¸­è¡¨ç°æ›´ä½³ã€‚è®ºæ–‡è¿›ä¸€æ­¥æŒ‡å‡ºäº†å½“å‰ç¬¦å·ç³»ç»Ÿæ²»ç†æ¨¡å‹çš„ç¼ºå¤±ï¼Œå¹¶å¼ºè°ƒäº†å¼€å‘ç¥ç»ç¬¦å·(Neuro-symbolic)æ··åˆæ¶æ„çš„ç´§è¿«æ€§ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶ä¸ºAgentic AIæå‡ºäº†æˆ˜ç•¥è·¯çº¿å›¾ï¼Œè®¤ä¸ºæœªæ¥çš„å‘å±•æ–¹å‘åœ¨äºæ•´åˆä¸¤ç§èŒƒå¼çš„ä¼˜åŠ¿ï¼Œä»¥æ„å»ºæ—¢å…·å¤‡è‡ªé€‚åº”æ€§åˆå¯é çš„å¯ä¿¡æ™ºèƒ½ç³»ç»Ÿã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25445v1",
      "published_date": "2025-10-29 12:11:34 UTC",
      "updated_date": "2025-10-29 12:11:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:06.850024+00:00"
    },
    {
      "arxiv_id": "2510.25441v2",
      "title": "Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs",
      "title_zh": "ç«‹è¶³ç°å®ï¼šåŸºäºç¦»çº¿æ—¥å¿—çš„ä¸»åŠ¨å¼å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ ä¸éƒ¨ç½²",
      "authors": [
        "Fei Wei",
        "Daoyuan Chen",
        "Ce Wang",
        "Yilun Huang",
        "Yushuo Chen",
        "Xuchen Pan",
        "Yaliang Li",
        "Bolin Ding"
      ],
      "abstract": "Large Language Models (LLMs) excel as passive responders, but teaching them to be proactive, goal-oriented partners, a critical capability in high-stakes domains, remains a major challenge. Current paradigms either myopically optimize single-turn attributes or rely on brittle, high-cost user simulators, creating a persistent ``reality gap''. To bridge this gap, we introduce \\texttt{Learn-to-Ask}, a general, simulator-free framework for learning and deploying proactive dialogue agents \\textit{directly from offline expert data}, bypassing the need to model complex user dynamics. Our key insight is to reframe the offline policy learning problem by leveraging the \\textbf{observed future} of each expert trajectory. This allows us to infer a dense, turn-by-turn reward signal grounded in the expert's revealed strategy, decomposing the intractable long-horizon problem into a series of supervised learning tasks, and training a policy to output a structured \\texttt{(action, state_assessment)} tuple, governing both \\textbf{what to ask} and, crucially, \\textbf{when to stop}. To ensure reward fidelity, our Automated Grader Calibration pipeline systematically purges noise from the LLM-based reward model with minimal human supervision. Empirically, we demonstrate the efficacy of \\texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying sizes up to 32B. Our approach culminates in the successful deployment of LLMs into a live, large-scale online AI service. In rigorous in-house evaluations, our model was launched and achieved performance even superior to human experts, proving our framework's ability to translate offline data into tangible, real-world impact. We hope this work provides a practical and economically viable blueprint for transforming passive LLMs into proactive, goal-oriented LLM applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤„ç†é«˜é£é™©ä»»åŠ¡æ—¶é€šå¸¸ä»…ä½œä¸ºè¢«åŠ¨å“åº”è€…è¿™ä¸€æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º Learn-to-Ask çš„é€šç”¨æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ— éœ€ä¾èµ–é«˜æˆæœ¬çš„ç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼Œè€Œæ˜¯ç›´æ¥ä»ç¦»çº¿ä¸“å®¶æ•°æ®ä¸­å­¦ä¹ ä¸»åŠ¨å¯¹è¯ç­–ç•¥ï¼Œé€šè¿‡åˆ©ç”¨è§‚å¯Ÿåˆ°çš„æœªæ¥ (observed future) æ¥æ¨æ–­å¯†é›†çš„å¥–åŠ±ä¿¡å·ã€‚ç ”ç©¶å°†é•¿ç¨‹å†³ç­–é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—ç›‘ç£å­¦ä¹ ä»»åŠ¡ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç”ŸæˆåŒ…å« (action, state_assessment) çš„ç»“æ„åŒ–å…ƒç»„ï¼Œä»¥ç²¾å‡†æ§åˆ¶æé—®å†…å®¹ä¸åœæ­¢æ—¶æœºã€‚ä¸ºäº†ç¡®ä¿å¥–åŠ±çš„ä¿çœŸåº¦ï¼Œç ”ç©¶è¿˜å¼•å…¥äº† Automated Grader Calibration æµç¨‹æ¥å‡€åŒ–æ¨¡å‹å™ªå£°ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®åŒ»ç–—æ•°æ®é›†å’Œå¤§è§„æ¨¡åœ¨çº¿ AI æœåŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…¶ 32B æ¨¡å‹çš„æ€§èƒ½ç”šè‡³è¶…è¶Šäº†äººç±»ä¸“å®¶ã€‚è¯¥æˆæœä¸ºå°†è¢«åŠ¨çš„ passive LLMs è½¬åŒ–ä¸ºç›®æ ‡å¯¼å‘çš„ proactive LLM åº”ç”¨æä¾›äº†ä¸€ä¸ªé«˜æ•ˆä¸”ç»æµçš„å®è·µè“å›¾ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25441v2",
      "published_date": "2025-10-29 12:08:07 UTC",
      "updated_date": "2025-11-07 10:05:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:19.556370+00:00"
    },
    {
      "arxiv_id": "2510.25428v1",
      "title": "Alibaba International E-commerce Product Search Competition DcuRAGONs Team Technical Report",
      "title_zh": "é˜¿é‡Œå·´å·´å›½é™…ç”µå•†å•†å“æœç´¢ç«èµ› DcuRAGONs å›¢é˜ŸæŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Thang-Long Nguyen-Ho",
        "Minh-Khoi Pham",
        "Hoang-Bao Le"
      ],
      "abstract": "This report details our methodology and results developed for the Multilingual E-commerce Search Competition. The problem aims to recognize relevance between user queries versus product items in a multilingual context and improve recommendation performance on e-commerce platforms. Utilizing Large Language Models (LLMs) and their capabilities in other tasks, our data-centric method achieved the highest score compared to other solutions during the competition. Final leaderboard is publised at https://alibaba-international-cikm2025.github.io. The source code for our project is published at https://github.com/nhtlongcs/e-commerce-product-search.",
      "tldr_zh": "è¯¥æŠ€æœ¯æŠ¥å‘Šè¯¦ç»†ä»‹ç»äº† DcuRAGONs å›¢é˜Ÿåœ¨é˜¿é‡Œå·´å·´å›½é™…ç”µå•†å¤šè¯­è¨€æœç´¢ç«èµ›ä¸­çš„æ–¹æ³•ä¸æˆæœï¼Œæ ¸å¿ƒä»»åŠ¡æ˜¯è¯†åˆ«å¤šè¯­è¨€ç¯å¢ƒä¸‹ç”¨æˆ·æŸ¥è¯¢ä¸å•†å“é¡¹çš„ç›¸å…³æ€§ã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†ä»¥æ•°æ®ä¸ºä¸­å¿ƒ (data-centric) çš„æ–¹æ³•ï¼Œå……åˆ†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) åœ¨è¯­ä¹‰ç†è§£å’Œè·¨è¯­è¨€ä»»åŠ¡ä¸­çš„å“è¶Šèƒ½åŠ›ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡ä¼˜åŒ–æ•°æ®è´¨é‡å’Œæ¨¡å‹æ¨ç†ç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†ç”µå•†å¹³å°åœ¨å¤šè¯­è¨€åœºæ™¯ä¸‹çš„æœç´¢ä¸æ¨èæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç«èµ›ä¸­å–å¾—äº†æœ€é«˜è¯„åˆ†ï¼Œè¯æ˜äº†ç»“åˆ LLMs çš„æ•°æ®é©±åŠ¨ç­–ç•¥åœ¨å¤æ‚æ£€ç´¢ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚ç›®å‰ï¼Œè¯¥é¡¹ç›®çš„æºä»£ç å·²å…¬å¼€å‘å¸ƒï¼Œä¸ºå¤šè¯­è¨€ç”µå•†æœç´¢é¢†åŸŸçš„ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Alibaba International E-commerce Product Search Competition @ CIKM 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.25428v1",
      "published_date": "2025-10-29 11:50:52 UTC",
      "updated_date": "2025-10-29 11:50:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:08.768885+00:00"
    },
    {
      "arxiv_id": "2510.25427v1",
      "title": "RLMEval: Evaluating Research-Level Neural Theorem Proving",
      "title_zh": "RLMEvalï¼šç ”ç©¶çº§ç¥ç»å®šç†è¯æ˜è¯„ä¼°",
      "authors": [
        "Auguste Poiroux",
        "Antoine Bosselut",
        "Viktor KunÄak"
      ],
      "abstract": "Despite impressive results on curated benchmarks, the practical impact of large language models (LLMs) on research-level neural theorem proving and proof autoformalization is still limited. We introduce RLMEval, an evaluation suite for these tasks, focusing on research-level mathematics from real-world Lean formalization projects. RLMEval targets the evaluation of neural theorem proving and proof autoformalization on challenging research-level theorems by leveraging real Lean Blueprint formalization projects. Our evaluation of state-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean projects, reveals a significant gap: progress on existing benchmarks does not readily translate to these more realistic settings, with the best model achieving only a 10.3 % pass rate. RLMEval provides a new, challenging benchmark designed to guide and accelerate progress in automated reasoning for formal mathematics.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç ”ç©¶çº§ç¥ç»å®šç†è¯æ˜(neural theorem proving)å’Œè¯æ˜è‡ªåŠ¨å½¢å¼åŒ–(proof autoformalization)æ–¹é¢çš„å®é™…åº”ç”¨ä»ç„¶å—é™ï¼Œä¸ºæ­¤æå‡ºäº†RLMEvalè¯„ä¼°å¥—ä»¶ã€‚è¯¥åŸºå‡†æµ‹è¯•èšç„¦äºçœŸå®ä¸–ç•ŒLeanå½¢å¼åŒ–é¡¹ç›®ä¸­çš„ç ”ç©¶çº§æ•°å­¦ï¼Œé€šè¿‡æ¥è‡ª6ä¸ªLeané¡¹ç›®çš„613ä¸ªå®šç†å¯¹æœ€å…ˆè¿›æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚å®éªŒå‘ç°ç°æœ‰åŸºå‡†æµ‹è¯•çš„è¿›å±•éš¾ä»¥è½¬åŒ–ä¸ºå¤„ç†æ­¤ç±»å¤æ‚çœŸå®åœºæ™¯çš„èƒ½åŠ›ï¼Œç›®å‰æ€§èƒ½æœ€ä½³çš„æ¨¡å‹ä¹Ÿä»…èƒ½è¾¾åˆ°10.3%çš„é€šè¿‡ç‡(pass rate)ã€‚RLMEvalæ­ç¤ºäº†å½“å‰è‡ªåŠ¨åŒ–æ¨ç†æŠ€æœ¯çš„å±€é™æ€§ï¼Œå¹¶ä¸ºå½¢å¼æ•°å­¦é¢†åŸŸçš„ç ”ç©¶æä¾›äº†æ›´å…·æŒ‘æˆ˜æ€§çš„å¯¼å‘ï¼Œæ—¨åœ¨åŠ é€Ÿè¯¥é¢†åŸŸçš„æŠ€æœ¯çªç ´ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025 Findings. RLMEval benchmark released: https://github.com/augustepoiroux/RLMEval",
      "pdf_url": "https://arxiv.org/pdf/2510.25427v1",
      "published_date": "2025-10-29 11:49:49 UTC",
      "updated_date": "2025-10-29 11:49:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:12.756985+00:00"
    },
    {
      "arxiv_id": "2510.25426v1",
      "title": "Implicature in Interaction: Understanding Implicature Improves Alignment in Human-LLM Interaction",
      "title_zh": "äº¤äº’ä¸­çš„è¨€å¤–ä¹‹æ„ï¼šç†è§£éšå«ä¹‰å¯æå‡äººæœºäº¤äº’ä¸­çš„å¯¹é½æ€§",
      "authors": [
        "Asutosh Hota",
        "Jussi P. P. Jokinen"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) is positioning language at the core of human-computer interaction (HCI). We argue that advancing HCI requires attention to the linguistic foundations of interaction, particularly implicature (meaning conveyed beyond explicit statements through shared context) which is essential for human-AI (HAI) alignment. This study examines LLMs' ability to infer user intent embedded in context-driven prompts and whether understanding implicature improves response generation. Results show that larger models approximate human interpretations more closely, while smaller models struggle with implicature inference. Furthermore, implicature-based prompts significantly enhance the perceived relevance and quality of responses across models, with notable gains in smaller models. Overall, 67.6% of participants preferred responses with implicature-embedded prompts to literal ones, highlighting a clear preference for contextually nuanced communication. Our work contributes to understanding how linguistic theory can be used to address the alignment problem by making HAI interaction more natural and contextually grounded.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†è¨€å¤–ä¹‹æ„ (Implicature) åœ¨äººæœºäº¤äº’ (HCI) ä¸­çš„æ ¸å¿ƒåœ°ä½ï¼Œå¼ºè°ƒäº†ç†è§£è¯­å¢ƒé©±åŠ¨çš„éšå«ä¿¡æ¯å¯¹äºæå‡äººæœºå¯¹é½ (Human-AI Alignment) çš„å…³é”®ä½œç”¨ã€‚ç ”ç©¶é€šè¿‡å¯¹æ¯”ä¸åŒè§„æ¨¡çš„å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) å‘ç°ï¼Œå¤§å‹æ¨¡å‹åœ¨æ¨æ–­ç”¨æˆ·æ„å›¾æ–¹é¢æ›´æ¥è¿‘äººç±»è¡¨ç°ï¼Œè€Œå°å‹æ¨¡å‹åœ¨ç‹¬ç«‹æ¨æ–­è¨€å¤–ä¹‹æ„æ—¶è¡¨ç°è¾ƒå¼±ã€‚ç„¶è€Œï¼Œä½¿ç”¨åŒ…å«è¨€å¤–ä¹‹æ„çš„æç¤ºè¯èƒ½å¤Ÿæ˜¾è‘—æé«˜å„æ¨¡å‹ç”Ÿæˆå“åº”çš„ç›¸å…³æ€§ä¸è´¨é‡ï¼Œä¸”åœ¨å°å‹æ¨¡å‹ä¸Šè¡¨ç°å‡ºæ›´æ˜æ˜¾çš„æ€§èƒ½å¢ç›Šã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œ67.6% çš„å‚ä¸è€…æ›´é’çå…·æœ‰è¯­å¢ƒç»†å¾®å·®åˆ«çš„æ²Ÿé€šæ–¹å¼ï¼Œè€Œéå•çº¯çš„å­—é¢ç†è§£å›åº”ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†è¯­è¨€å­¦ç†è®º (Linguistic Theory) åœ¨è§£å†³å¯¹é½é—®é¢˜ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºå®ç°æ›´è‡ªç„¶ã€æ›´å…·è¯­å¢ƒæ„ŸçŸ¥çš„äººæœºäº¤äº’ (HAI) æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ä¸å®è·µæ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The manuscript is approximately 7360 words and contains 12 figures and 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.25426v1",
      "published_date": "2025-10-29 11:49:42 UTC",
      "updated_date": "2025-10-29 11:49:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:17.050359+00:00"
    },
    {
      "arxiv_id": "2510.25420v1",
      "title": "Improving Temporal Consistency and Fidelity at Inference-time in Perceptual Video Restoration by Zero-shot Image-based Diffusion Models",
      "title_zh": "åˆ©ç”¨é›¶æ ·æœ¬å›¾åƒæ‰©æ•£æ¨¡å‹æå‡æ„ŸçŸ¥è§†é¢‘ä¿®å¤æ¨ç†é˜¶æ®µçš„æ—¶é—´ä¸€è‡´æ€§ä¸ä¿çœŸåº¦",
      "authors": [
        "Nasrin Rahimi",
        "A. Murat Tekalp"
      ],
      "abstract": "Diffusion models have emerged as powerful priors for single-image restoration, but their application to zero-shot video restoration suffers from temporal inconsistencies due to the stochastic nature of sampling and complexity of incorporating explicit temporal modeling. In this work, we address the challenge of improving temporal coherence in video restoration using zero-shot image-based diffusion models without retraining or modifying their architecture. We propose two complementary inference-time strategies: (1) Perceptual Straightening Guidance (PSG) based on the neuroscience-inspired perceptual straightening hypothesis, which steers the diffusion denoising process towards smoother temporal evolution by incorporating a curvature penalty in a perceptual space to improve temporal perceptual scores, such as FrÃ©chet Video Distance (FVD) and perceptual straightness; and (2) Multi-Path Ensemble Sampling (MPES), which aims at reducing stochastic variation by ensembling multiple diffusion trajectories to improve fidelity (distortion) scores, such as PSNR and SSIM, without sacrificing sharpness. Together, these training-free techniques provide a practical path toward temporally stable high-fidelity perceptual video restoration using large pretrained diffusion models. We performed extensive experiments over multiple datasets and degradation types, systematically evaluating each strategy to understand their strengths and limitations. Our results show that while PSG enhances temporal naturalness, particularly in case of temporal blur, MPES consistently improves fidelity and spatio-temporal perception--distortion trade-off across all tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é›¶æ ·æœ¬å›¾åƒæ‰©æ•£æ¨¡å‹ (Zero-shot Image-based Diffusion Models) åœ¨è§†é¢‘ä¿®å¤ä¸­é¢ä¸´çš„æ—¶é—´ä¸ä¸€è‡´æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸¤ç§æ— éœ€é‡æ–°è®­ç»ƒçš„æ¨ç†é˜¶æ®µç­–ç•¥ã€‚é¦–å…ˆæ˜¯æ„ŸçŸ¥å¹³ç›´åŒ–å¼•å¯¼ (Perceptual Straightening Guidance, PSG)ï¼Œè¯¥æ–¹æ³•åŸºäºç¥ç»ç§‘å­¦å¯å‘çš„æ„ŸçŸ¥å¹³ç›´åŒ–å‡è®¾ï¼Œé€šè¿‡åœ¨æ„ŸçŸ¥ç©ºé—´å¼•å…¥æ›²ç‡æƒ©ç½šï¼Œå¼•å¯¼æ‰©æ•£å»å™ªè¿‡ç¨‹å®ç°æ›´å¹³æ»‘çš„æ—¶é—´æ¼”åŒ–å¹¶æå‡ FrÃ©chet Video Distance (FVD) ç­‰æŒ‡æ ‡ã€‚å…¶æ¬¡æ˜¯å¤šè·¯å¾„é›†æˆé‡‡æ · (Multi-Path Ensemble Sampling, MPES)ï¼Œæ—¨åœ¨é€šè¿‡é›†æˆå¤šæ¡æ‰©æ•£è½¨è¿¹æ¥å‡å°‘éšæœºå˜å¼‚ï¼Œä»è€Œåœ¨ä¸ç‰ºç‰²æ¸…æ™°åº¦çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡ PSNR å’Œ SSIM ç­‰ä¿çœŸåº¦æŒ‡æ ‡ã€‚è¿™ä¸¤ç§äº’è¡¥çš„æŠ€æœ¯ä¸ºåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹å®ç°ç¨³å®šä¸”é«˜ä¿çœŸåº¦çš„æ„ŸçŸ¥è§†é¢‘ä¿®å¤æä¾›äº†å®ç”¨è·¯å¾„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPSG æ˜¾è‘—å¢å¼ºäº†æ—¶é—´è‡ªç„¶åº¦ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†æ—¶é—´æ¨¡ç³Šæ—¶æ•ˆæœæ˜æ˜¾ï¼Œè€Œ MPES åˆ™åœ¨å„ç§ä»»åŠ¡ä¸­æŒç»­æ”¹å–„äº†ä¿çœŸåº¦å’Œæ—¶ç©ºæ„ŸçŸ¥-å¤±çœŸæƒè¡¡ (Spatio-temporal Perception-distortion Trade-off)ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25420v1",
      "published_date": "2025-10-29 11:40:06 UTC",
      "updated_date": "2025-10-29 11:40:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:20.046885+00:00"
    },
    {
      "arxiv_id": "2510.25416v1",
      "title": "Adaptive End-to-End Transceiver Design for NextG Pilot-Free and CP-Free Wireless Systems",
      "title_zh": "é¢å‘NextGæ— å¯¼é¢‘ä¸æ— å¾ªç¯å‰ç¼€æ— çº¿ç³»ç»Ÿçš„è‡ªé€‚åº”ç«¯åˆ°ç«¯æ”¶å‘æœºè®¾è®¡",
      "authors": [
        "Jiaming Cheng",
        "Wei Chen",
        "Bo Ai"
      ],
      "abstract": "The advent of artificial intelligence (AI)-native wireless communication is fundamentally reshaping the design paradigm of next-generation (NextG) systems, where intelligent air interfaces are expected to operate adaptively and efficiently in highly dynamic environments. Conventional orthogonal frequency division multiplexing (OFDM) systems rely heavily on pilots and the cyclic prefix (CP), resulting in significant overhead and reduced spectral efficiency. To address these limitations, we propose an adaptive end-to-end (E2E) transceiver architecture tailored for pilot-free and CP-free wireless systems. The architecture combines AI-driven constellation shaping and a neural receiver through joint training. To enhance robustness against mismatched or time-varying channel conditions, we introduce a lightweight channel adapter (CA) module, which enables rapid adaptation with minimal computational overhead by updating only the CA parameters. Additionally, we present a framework that is scalable to multiple modulation orders within a unified model, significantly reducing model storage requirements. Moreover, to tackle the high peak-to-average power ratio (PAPR) inherent to OFDM, we incorporate constrained E2E training, achieving compliance with PAPR targets without additional transmission overhead. Extensive simulations demonstrate that the proposed framework delivers superior bit error rate (BER), throughput, and resilience across diverse channel scenarios, highlighting its potential for AI-native NextG.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸‹ä¸€ä»£ (NextG) æ— çº¿é€šä¿¡ä¸­ä¼ ç»Ÿæ­£äº¤é¢‘åˆ†å¤ç”¨ (OFDM) ç³»ç»Ÿå› ä¾èµ–å¯¼é¢‘ (Pilots) å’Œå¾ªç¯å‰ç¼€ (CP) å¯¼è‡´çš„å¼€é”€å¤§ã€é¢‘è°±æ•ˆç‡ä½ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é€‚ç”¨äºæ— å¯¼é¢‘ (Pilot-free) å’Œæ— å¾ªç¯å‰ç¼€ (CP-free) ç³»ç»Ÿçš„æ–°å‹è‡ªé€‚åº”ç«¯åˆ°ç«¯ (E2E) æ”¶å‘æœºæ¶æ„ã€‚è¯¥æ¶æ„å°† AI é©±åŠ¨çš„æ˜Ÿåº§å›¾å¡‘é€  (Constellation Shaping) ä¸ç¥ç»æ¥æ”¶æœº (Neural Receiver) è¿›è¡Œè”åˆè®­ç»ƒï¼Œä»¥ä¼˜åŒ–æ•´ä½“ä¼ è¾“æ€§èƒ½ã€‚ä¸ºå¢å¼ºå¯¹å¤±é…æˆ–æ—¶å˜ä¿¡é“ç¯å¢ƒçš„é²æ£’æ€§ï¼Œç ”ç©¶å¼•å…¥äº†è½»é‡çº§çš„ä¿¡é“é€‚é…å™¨ (CA) æ¨¡å—ï¼Œé€šè¿‡ä»…æ›´æ–°å°‘é‡å‚æ•°å³å¯å®ç°ä½å¼€é”€çš„å¿«é€Ÿè‡ªé€‚åº”ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨ç»Ÿä¸€æ¨¡å‹å†…å®ç°äº†å¯¹å¤šç§è°ƒåˆ¶é˜¶æ•°çš„å¯æ‰©å±•æ€§ï¼Œæœ‰æ•ˆé™ä½äº†æ¨¡å‹å­˜å‚¨éœ€æ±‚ã€‚é’ˆå¯¹ OFDM ç³»ç»Ÿå›ºæœ‰çš„é«˜å³°å‡åŠŸç‡æ¯” (PAPR) æŒ‘æˆ˜ï¼Œç ”ç©¶é‡‡ç”¨äº†å—é™çš„ç«¯åˆ°ç«¯è®­ç»ƒæ–¹å¼ï¼Œåœ¨ä¸å¢åŠ é¢å¤–å¼€é”€çš„æƒ…å†µä¸‹æ»¡è¶³äº† PAPR ç›®æ ‡ã€‚ä»¿çœŸå®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨å¤šç§ä¿¡é“åœºæ™¯ä¸‹å‡å–å¾—äº†æ›´ä¼˜çš„è¯¯ç ç‡ (BER)ã€ååé‡å’Œç³»ç»ŸéŸ§æ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨ AI åŸç”Ÿ NextG é€šä¿¡æ¼”è¿›ä¸­çš„æ½œåŠ›ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Submitted to IEEE for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2510.25416v1",
      "published_date": "2025-10-29 11:34:09 UTC",
      "updated_date": "2025-10-29 11:34:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:24.048949+00:00"
    },
    {
      "arxiv_id": "2510.25409v2",
      "title": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains",
      "title_zh": "BhashaBench V1ï¼šé’ˆå¯¹å°åº¦å››å¤§çŸ¥è¯†é¢†åŸŸçš„å…¨é¢è¯„æµ‹åŸºå‡†",
      "authors": [
        "Vijay Devane",
        "Mohd Nauman",
        "Bhargav Patel",
        "Aniket Mahendra Wakchoure",
        "Yogeshkumar Sant",
        "Shyam Pawar",
        "Viraj Thakur",
        "Ananya Godse",
        "Sunil Patra",
        "Neha Maurya",
        "Suraj Racha",
        "Nitish Kamal Singh",
        "Ajay Nagpal",
        "Piyush Sawarkar",
        "Kundeshwar Vijayrao Pundalik",
        "Rohit Saluja",
        "Ganesh Ramakrishnan"
      ],
      "abstract": "The rapid advancement of large language models(LLMs) has intensified the need for domain and culture specific evaluation. Existing benchmarks are largely Anglocentric and domain-agnostic, limiting their applicability to India-centric contexts. To address this gap, we introduce BhashaBench V1, the first domain-specific, multi-task, bilingual benchmark focusing on critical Indic knowledge systems. BhashaBench V1 contains 74,166 meticulously curated question-answer pairs, with 52,494 in English and 21,672 in Hindi, sourced from authentic government and domain-specific exams. It spans four major domains: Agriculture, Legal, Finance, and Ayurveda, comprising 90+ subdomains and covering 500+ topics, enabling fine-grained evaluation. Evaluation of 29+ LLMs reveals significant domain and language specific performance gaps, with especially large disparities in low-resource domains. For instance, GPT-4o achieves 76.49% overall accuracy in Legal but only 59.74% in Ayurveda. Models consistently perform better on English content compared to Hindi across all domains. Subdomain-level analysis shows that areas such as Cyber Law, International Finance perform relatively well, while Panchakarma, Seed Science, and Human Rights remain notably weak. BhashaBench V1 provides a comprehensive dataset for evaluating large language models across India's diverse knowledge domains. It enables assessment of models' ability to integrate domain-specific knowledge with bilingual understanding. All code, benchmarks, and resources are publicly available to support open research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† BhashaBench V1ï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹å°åº¦ç‰¹å®šé¢†åŸŸçŸ¥è¯†ä½“ç³»çš„åŒè¯­å¤šä»»åŠ¡åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯„æµ‹åŸºå‡†ä¸»è¦ä»¥è‹±è¯­ä¸ºä¸­å¿ƒä¸”ç¼ºä¹é¢†åŸŸé’ˆå¯¹æ€§çš„å±€é™ã€‚è¯¥åŸºå‡†åŒ…å« 74,166 ä¸ªç²¾å¿ƒç­–åˆ’çš„é—®ç­”å¯¹ï¼Œæ¶µç›–äº†å†œä¸š (Agriculture)ã€æ³•å¾‹ (Legal)ã€é‡‘è (Finance) å’Œé˜¿è‚²å é™€ (Ayurveda) å››å¤§æ ¸å¿ƒé¢†åŸŸåŠå…¶ 90 å¤šä¸ªå­é¢†åŸŸã€‚é€šè¿‡å¯¹ 29 å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„è¯„ä¼°å‘ç°ï¼Œæ¨¡å‹åœ¨ä¸åŒé¢†åŸŸå’Œè¯­è¨€ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼Œä¸”åœ¨æ‰€æœ‰é¢†åŸŸä¸­è‹±è¯­å†…å®¹çš„è¡¨ç°å‡ä¼˜äºå°åœ°è¯­ã€‚å®éªŒæ•°æ®æ˜¾ç¤ºï¼Œå³ä¾¿å¦‚ GPT-4o è¿™æ ·å…ˆè¿›çš„æ¨¡å‹ï¼Œåœ¨æ³•å¾‹é¢†åŸŸçš„å‡†ç¡®ç‡ä¹Ÿè¿œé«˜äºé˜¿è‚²å é™€é¢†åŸŸï¼Œè€Œç½‘ç»œæ³• (Cyber Law) ç­‰å­é¢†åŸŸè¡¨ç°ç›¸å¯¹è¾ƒå¥½ï¼Œç§å­ç§‘å­¦ (Seed Science) å’Œäººæƒ (Human Rights) ç­‰é¢†åŸŸä»æ˜¯è–„å¼±ç¯èŠ‚ã€‚BhashaBench V1 ä¸ºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹æ•´åˆç‰¹å®šé¢†åŸŸçŸ¥è¯†ä¸åŒè¯­ç†è§£çš„èƒ½åŠ›æä¾›äº†å…¨é¢çš„æ•°æ®é›†ï¼Œå¯¹äºæ¨åŠ¨å°åº¦ä¸­å¿ƒè¯­å¢ƒä¸‹çš„å¼€æ”¾ç ”ç©¶å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25409v2",
      "published_date": "2025-10-29 11:27:08 UTC",
      "updated_date": "2025-10-30 10:48:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:27.458763+00:00"
    },
    {
      "arxiv_id": "2510.25404v1",
      "title": "GPTOpt: Towards Efficient LLM-Based Black-Box Optimization",
      "title_zh": "GPTOptï¼šè¿ˆå‘é«˜æ•ˆçš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é»‘ç›’ä¼˜åŒ–",
      "authors": [
        "Jamison Meindl",
        "Yunsheng Tian",
        "Tony Cui",
        "Veronika Thost",
        "Zhang-Wei Hong",
        "Jie Chen",
        "Wojciech Matusik",
        "Mina KonakoviÄ‡ LukoviÄ‡"
      ],
      "abstract": "Global optimization of expensive, derivative-free black-box functions demands extreme sample efficiency. Classical methods such as Bayesian Optimization (BO) can be effective, but they often require careful parameter tuning to each application domain. At the same time, Large Language Models (LLMs) have shown broad capabilities, yet state-of-the-art models remain limited in solving continuous black-box optimization tasks. We introduce GPTOpt, an LLM-based optimization method that equips LLMs with continuous black-box optimization capabilities. By fine-tuning large language models on extensive synthetic datasets derived from diverse BO parameterizations, GPTOpt leverages LLM pre-training to generalize across optimization tasks. On a variety of black-box optimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting the capacity of LLMs for advanced numerical reasoning and introducing a flexible framework for global optimization without parameter tuning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GPTOptï¼Œä¸€ç§æ—¨åœ¨èµ‹äºˆå¤§è¯­è¨€æ¨¡å‹è¿ç»­ black-box optimization èƒ½åŠ›çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä»¥è§£å†³æ˜‚è´µä¸”æ— å¯¼æ•°å‡½æ•°å…¨å±€ä¼˜åŒ–ä¸­çš„æ ·æœ¬æ•ˆç‡é—®é¢˜ã€‚GPTOpt é€šè¿‡åœ¨æºè‡ªå¤šç§ Bayesian Optimization (BO) å‚æ•°åŒ–çš„æµ·é‡åˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œ fine-tuningï¼Œå……åˆ†åˆ©ç”¨äº† LLM çš„é¢„è®­ç»ƒä¼˜åŠ¿æ¥å®ç°è·¨ä»»åŠ¡çš„æ³›åŒ–ã€‚ä¸éœ€è¦é’ˆå¯¹ç‰¹å®šé¢†åŸŸè¿›è¡Œç¹çå‚æ•°è°ƒæ•´çš„ä¼ ç»Ÿ BO æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶æä¾›äº†ä¸€ç§æ— éœ€è°ƒå‚çš„çµæ´»å…¨å±€ä¼˜åŒ–æ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPTOpt åœ¨å¤šç§ black-box optimization åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿä¼˜åŒ–å™¨ï¼Œè¯æ˜äº† LLM åœ¨å¤„ç†å¤æ‚æ•°å€¼æ¨ç†ä»»åŠ¡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25404v1",
      "published_date": "2025-10-29 11:21:55 UTC",
      "updated_date": "2025-10-29 11:21:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:33.660543+00:00"
    },
    {
      "arxiv_id": "2510.25388v1",
      "title": "Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm",
      "title_zh": "å…·æœ‰å·²çŸ¥ä»·å€¼å·®å¼‚çš„èŠ‚ç‚¹åˆ†ç»„ï¼šä¸€ç§åŸºäº UCT çš„æ— æŸæŠ½è±¡ç®—æ³•",
      "authors": [
        "Robin SchmÃ¶cker",
        "Alexander Dockhorn",
        "Bodo Rosenhahn"
      ],
      "abstract": "A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency, which can be improved by grouping state-action pairs and using their aggregate statistics instead of single-node statistics. On the Go Abstractions in Upper Confidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS abstraction algorithm for deterministic environments that builds its abstraction using the Abstractions of State-Action Pairs (ASAP) framework, which aims to detect states and state-action pairs with the same value under optimal play by analysing the search graph. ASAP, however, requires two state-action pairs to have the same immediate reward, which is a rigid condition that limits the number of abstractions that can be found and thereby the sample efficiency. In this paper, we break with the paradigm of grouping value-equivalent states or state-action pairs and instead group states and state-action pairs with possibly different values as long as the difference between their values can be inferred. We call this abstraction framework Known Value Difference Abstractions (KVDA), which infers the value differences by analysis of the immediate rewards and modifies OGA-UCT to use this framework instead. The modification is called KVDA-UCT, which detects significantly more abstractions than OGA-UCT, introduces no additional parameter, and outperforms OGA-UCT on a variety of deterministic environments and parameter settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è’™ç‰¹å¡æ´›æ ‘æœç´¢(Monte Carlo Tree Search, MCTS)çš„æ ·æœ¬æ•ˆç‡é—®é¢˜ï¼ŒæŒ‡å‡ºç°æœ‰çš„OGA-UCTç®—æ³•å—é™äºASAPæ¡†æ¶ï¼Œä»…èƒ½åˆå¹¶ä»·å€¼å®Œå…¨ç›¸ç­‰ä¸”å³æ—¶å¥–åŠ±ç›¸åŒçš„èŠ‚ç‚¹ï¼Œè¿™ç§è‹›åˆ»æ¡ä»¶é™åˆ¶äº†æŠ½è±¡åŒ–çš„æ•ˆèƒ½ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†Known Value Difference Abstractions (KVDA)æ¡†æ¶ï¼Œæ‰“ç ´äº†ä»…èƒ½åˆå¹¶ç­‰å€¼èŠ‚ç‚¹çš„èŒƒå¼ï¼Œå…è®¸å¯¹ä»·å€¼ä¸åŒä½†å·®å¼‚å¯è¢«æ¨æ–­çš„çŠ¶æ€æˆ–çŠ¶æ€åŠ¨ä½œå¯¹è¿›è¡Œåˆå¹¶ã€‚é€šè¿‡åˆ†æå³æ—¶å¥–åŠ±å¹¶å°†å…¶åº”ç”¨äºOGA-UCTä¸­ï¼Œç ”ç©¶è€…å¼€å‘äº†KVDA-UCTç®—æ³•ï¼Œæ—¨åœ¨æ›´å¹¿æ³›åœ°æ•æ‰æœç´¢æ ‘ä¸­çš„å†—ä½™ç»“æ„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKVDA-UCTåœ¨ä¸å¼•å…¥é¢å¤–å‚æ•°çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæ£€æµ‹åˆ°æ˜¾è‘—å¤šäºåŸºçº¿æ¨¡å‹çš„æŠ½è±¡æ•°é‡ã€‚è¯¥ç®—æ³•åœ¨å¤šç§ç¡®å®šæ€§ç¯å¢ƒä¸­è¡¨ç°ä¼˜äºOGA-UCTï¼Œåœ¨ä¿æŒæ— æŸæŠ½è±¡çš„åŒæ—¶æœ‰æ•ˆæå‡äº†æœç´¢çš„æ ·æœ¬æ•ˆç‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25388v1",
      "published_date": "2025-10-29 11:03:44 UTC",
      "updated_date": "2025-10-29 11:03:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:33.164410+00:00"
    },
    {
      "arxiv_id": "2510.25386v1",
      "title": "Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods",
      "title_zh": "è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ã€é¢„æµ‹ä¸è§„åˆ’ä¸­çš„æ³•å¾‹ä¸é€»è¾‘è§„èŒƒé›†æˆï¼šæ–¹æ³•ç»¼è¿°",
      "authors": [
        "Kumar Manas",
        "Mert Keser",
        "Alois Knoll"
      ],
      "abstract": "This survey provides an analysis of current methodologies integrating legal and logical specifications into the perception, prediction, and planning modules of automated driving systems. We systematically explore techniques ranging from logic-based frameworks to computational legal reasoning approaches, emphasizing their capability to ensure regulatory compliance and interpretability in dynamic and uncertain driving environments. A central finding is that significant challenges arise at the intersection of perceptual reliability, legal compliance, and decision-making justifiability. To systematically analyze these challenges, we introduce a taxonomy categorizing existing approaches by their theoretical foundations, architectural implementations, and validation strategies. We particularly focus on methods that address perceptual uncertainty and incorporate explicit legal norms, facilitating decisions that are both technically robust and legally defensible. The review covers neural-symbolic integration methods for perception, logic-driven rule representation, and norm-aware prediction strategies, all contributing toward transparent and accountable autonomous vehicle operation. We highlight critical open questions and practical trade-offs that must be addressed, offering multidisciplinary insights from engineering, logic, and law to guide future developments in legally compliant autonomous driving systems.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåˆ†æäº†å°†æ³•å¾‹(Legal)å’Œé€»è¾‘(Logical)è§„èŒƒé›†æˆåˆ°è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿ(Automated Driving Systems)çš„æ„ŸçŸ¥ã€é¢„æµ‹å’Œè§„åˆ’æ¨¡å—ä¸­çš„ç°æœ‰æ–¹æ³•ã€‚ç ”ç©¶ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†ä»åŸºäºé€»è¾‘çš„æ¡†æ¶åˆ°è®¡ç®—æ³•å¾‹æ¨ç†(Computational Legal Reasoning)çš„æŠ€æœ¯ï¼Œå¼ºè°ƒå…¶åœ¨åŠ¨æ€å’Œä¸ç¡®å®šé©¾é©¶ç¯å¢ƒä¸­ç¡®ä¿ç›‘ç®¡åˆè§„æ€§ä¸å¯è§£é‡Šæ€§çš„èƒ½åŠ›ã€‚è®ºæ–‡å¼•å…¥äº†ä¸€ç§åˆ†ç±»æ³•(Taxonomy)ï¼Œæ ¹æ®ç†è®ºåŸºç¡€ã€æ¶æ„å®ç°å’ŒéªŒè¯ç­–ç•¥å¯¹ç°æœ‰æ–¹æ³•è¿›è¡Œåˆ†ç±»ï¼Œå¹¶é‡ç‚¹å…³æ³¨å¤„ç†æ„ŸçŸ¥ä¸ç¡®å®šæ€§(Perceptual Uncertainty)å’Œç»“åˆæ˜¾æ€§æ³•å¾‹å‡†åˆ™(Legal Norms)çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥ç»¼è¿°æ¶µç›–äº†ç”¨äºæ„ŸçŸ¥çš„ç¥ç»ç¬¦å·é›†æˆ(Neural-Symbolic Integration)ã€é€»è¾‘é©±åŠ¨çš„è§„åˆ™è¡¨ç¤ºä»¥åŠè§„èŒƒæ„ŸçŸ¥é¢„æµ‹ç­–ç•¥(Norm-aware Prediction Strategies)ã€‚ç ”ç©¶æ­ç¤ºäº†åœ¨æ„ŸçŸ¥å¯é æ€§ã€æ³•å¾‹åˆè§„æ€§ä¸å†³ç­–åˆç†æ€§äº¤å‰ç‚¹ä¸Šçš„é‡å¤§æŒ‘æˆ˜ï¼Œå¹¶ä¸ºå¼€å‘åˆè§„ã€é€æ˜ä¸”å¯è¿½è´£çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæä¾›äº†å·¥ç¨‹ã€é€»è¾‘å’Œæ³•å¾‹æ–¹é¢çš„å¤šå­¦ç§‘è§è§£ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to 2025 IEEE International Automated Vehicle Validation Conference (IAVVC)",
      "pdf_url": "https://arxiv.org/pdf/2510.25386v1",
      "published_date": "2025-10-29 10:57:24 UTC",
      "updated_date": "2025-10-29 10:57:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:46.362398+00:00"
    },
    {
      "arxiv_id": "2510.25378v1",
      "title": "Hallucinations in Bibliographic Recommendation: Citation Frequency as a Proxy for Training Data Redundancy",
      "title_zh": "æ–‡çŒ®æ¨èä¸­çš„å¹»è§‰ï¼šå°†è¢«å¼•é¢‘æ¬¡ä½œä¸ºè®­ç»ƒæ•°æ®å†—ä½™çš„ä»£ç†æŒ‡æ ‡",
      "authors": [
        "Junichiro Niimi"
      ],
      "abstract": "Large language models (LLMs) have been increasingly applied to a wide range of tasks, from natural language understanding to code generation. While they have also been used to assist in bibliographic recommendation, the hallucination of non-existent papers remains a major issue. Building on prior studies, this study hypothesizes that an LLM's ability to correctly produce bibliographic information depends on whether the underlying knowledge is generated or memorized, with highly cited papers (i.e., more frequently appear in the training corpus) showing lower hallucination rates. We therefore assume citation count as a proxy for training data redundancy (i.e., the frequency with which a given bibliographic record is repeatedly represented in the pretraining corpus) and investigate how citation frequency affects hallucinated references in LLM outputs. Using GPT-4.1, we generated and manually verified 100 bibliographic records across twenty computer-science domains, and measured factual consistency via cosine similarity between generated and authentic metadata. The results revealed that (i) hallucination rates vary across research domains, (ii) citation count is strongly correlated with factual accuracy, and (iii) bibliographic information becomes almost verbatimly memorized beyond approximately 1,000 citations. These findings suggest that highly cited papers are nearly verbatimly retained in the model, indicating a threshold where generalization shifts into memorization.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ–‡çŒ®æ¨è(Bibliographic Recommendation)ä¸­äº§ç”Ÿå¹»è§‰(Hallucinations)çš„é—®é¢˜ï¼Œå¹¶æå‡ºå¼•ç”¨é¢‘ç‡(Citation Frequency)å¯ä½œä¸ºè®­ç»ƒæ•°æ®å†—ä½™(Training Data Redundancy)çš„ä»£ç†æŒ‡æ ‡ã€‚ç ”ç©¶è€…åˆ©ç”¨GPT-4åœ¨20ä¸ªè®¡ç®—æœºç§‘å­¦é¢†åŸŸç”Ÿæˆå¹¶æ‰‹åŠ¨éªŒè¯äº†100æ¡æ–‡çŒ®è®°å½•ï¼Œé€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦(Cosine Similarity)è¡¡é‡ç”Ÿæˆå†…å®¹ä¸çœŸå®å…ƒæ•°æ®çš„äº‹å®ä¸€è‡´æ€§ã€‚å®éªŒå‘ç°ï¼Œå¹»è§‰ç‡åœ¨ä¸åŒç ”ç©¶é¢†åŸŸè¡¨ç°å„å¼‚ï¼Œä¸”å¼•ç”¨æ¬¡æ•°ä¸äº‹å®å‡†ç¡®æ€§ä¹‹é—´å­˜åœ¨å¼ºç›¸å…³æ€§ã€‚å½“è®ºæ–‡å¼•ç”¨é‡è¶…è¿‡çº¦1,000æ¬¡æ—¶ï¼Œæ¨¡å‹å¯¹æ–‡çŒ®ä¿¡æ¯çš„æŒæ¡ä»æ³›åŒ–(Generalization)è½¬å˜ä¸ºå‡ è¿‘é€å­—çš„è®°å¿†(Memorization)ã€‚è¯¥å‘ç°è¡¨æ˜é«˜é¢‘å‡ºç°çš„è®­ç»ƒæ•°æ®èƒ½æ˜¾è‘—é™ä½æ¨¡å‹çš„å¹»è§‰ç‡ï¼Œæ­ç¤ºäº†æ¨¡å‹å¤„ç†çŸ¥è¯†æ—¶ä»ç†è§£å‘è®°å¿†è½¬å˜çš„é˜ˆå€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25378v1",
      "published_date": "2025-10-29 10:51:35 UTC",
      "updated_date": "2025-10-29 10:51:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:51.855786+00:00"
    },
    {
      "arxiv_id": "2510.25368v1",
      "title": "Position: Biology is the Challenge Physics-Informed ML Needs to Evolve",
      "title_zh": "è§‚ç‚¹ï¼šç”Ÿç‰©å­¦æ˜¯ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ æ¼”è¿›æ‰€éœ€çš„æŒ‘æˆ˜",
      "authors": [
        "Julien Martinelli"
      ],
      "abstract": "Physics-Informed Machine Learning (PIML) has successfully integrated mechanistic understanding into machine learning, particularly in domains governed by well-known physical laws. This success has motivated efforts to apply PIML to biology, a field rich in dynamical systems but shaped by different constraints. Biological modeling, however, presents unique challenges: multi-faceted and uncertain prior knowledge, heterogeneous and noisy data, partial observability, and complex, high-dimensional networks. In this position paper, we argue that these challenges should not be seen as obstacles to PIML, but as catalysts for its evolution. We propose Biology-Informed Machine Learning (BIML): a principled extension of PIML that retains its structural grounding while adapting to the practical realities of biology. Rather than replacing PIML, BIML retools its methods to operate under softer, probabilistic forms of prior knowledge. We outline four foundational pillars as a roadmap for this transition: uncertainty quantification, contextualization, constrained latent structure inference, and scalability. Foundation Models and Large Language Models will be key enablers, bridging human expertise with computational modeling. We conclude with concrete recommendations to build the BIML ecosystem and channel PIML-inspired innovation toward challenges of high scientific and societal relevance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹  (Physics-Informed Machine Learning, PIML) åœ¨ç”Ÿç‰©å­¦é¢†åŸŸåº”ç”¨æ—¶é¢ä¸´çš„ç‹¬ç‰¹æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºç”Ÿç‰©å»ºæ¨¡ä¸­å­˜åœ¨çš„ä¸ç¡®å®šå…ˆéªŒçŸ¥è¯†ã€å¼‚æ„å™ªå£°æ•°æ®ä»¥åŠå¤æ‚çš„åŠ¨åŠ›å­¦ç½‘ç»œã€‚ä½œè€…è®¤ä¸ºè¿™äº›æŒ‘æˆ˜æ˜¯æ¨åŠ¨ PIML è¿›åŒ–çš„å‚¬åŒ–å‰‚ï¼Œå¹¶æ®æ­¤æå‡ºäº†ç”Ÿç‰©ä¿¡æ¯æœºå™¨å­¦ä¹  (Biology-Informed Machine Learning, BIML) æ¡†æ¶ã€‚BIML å¹¶éå–ä»£ PIMLï¼Œè€Œæ˜¯å¯¹å…¶è¿›è¡ŒåŸåˆ™æ€§æ‰©å±•ï¼Œä½¿å…¶èƒ½å¤„ç†æ›´å…·æ¦‚ç‡æ€§å’Œè½¯æ€§çš„å…ˆéªŒçŸ¥è¯†ã€‚è®ºæ–‡æå‡ºäº†æ„å»º BIML çš„å››å¤§æ”¯æŸ±ï¼šä¸ç¡®å®šæ€§é‡åŒ– (uncertainty quantification)ã€æƒ…å¢ƒåŒ– (contextualization)ã€å—çº¦æŸçš„éšç»“æ„æ¨ç† (constrained latent structure inference) ä»¥åŠå¯æ‰©å±•æ€§ (scalability)ã€‚åŸºç¡€æ¨¡å‹ (Foundation Models) å’Œå¤§è¯­è¨€æ¨¡å‹ (Large Language Models) è¢«è§†ä¸ºè¿æ¥äººç±»ä¸“ä¸šçŸ¥è¯†ä¸è®¡ç®—å»ºæ¨¡çš„å…³é”®ä½¿èƒ½æŠ€æœ¯ã€‚è¯¥ç ”ç©¶æœ€åä¸ºæ„å»º BIML ç”Ÿæ€ç³»ç»Ÿæå‡ºäº†å…·ä½“å»ºè®®ï¼Œæ—¨åœ¨å°† PIML å¯å‘çš„åˆ›æ–°åº”ç”¨äºå…·æœ‰é«˜åº¦ç§‘å­¦å’Œç¤¾ä¼šç›¸å…³æ€§çš„ç”Ÿç‰©å­¦æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25368v1",
      "published_date": "2025-10-29 10:39:29 UTC",
      "updated_date": "2025-10-29 10:39:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:26:56.649483+00:00"
    },
    {
      "arxiv_id": "2510.25366v2",
      "title": "A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks",
      "title_zh": "ä¸€ç§åŸºäºå‡¸æ€§ä¾èµ–çš„æ·±åº¦ç¥ç»ç½‘ç»œä¸¤é˜¶æ®µè®­ç»ƒç®—æ³•",
      "authors": [
        "Tomas Hrycej",
        "Bernhard Bermeitinger",
        "Massimo Pavone",
        "GÃ¶tz-Henrik Wiegand",
        "Siegfried Handschuh"
      ],
      "abstract": "The key task of machine learning is to minimize the loss function that measures the model fit to the training data. The numerical methods to do this efficiently depend on the properties of the loss function. The most decisive among these properties is the convexity or non-convexity of the loss function. The fact that the loss function can have, and frequently has, non-convex regions has led to a widespread commitment to non-convex methods such as Adam. However, a local minimum implies that, in some environment around it, the function is convex. In this environment, second-order minimizing methods such as the Conjugate Gradient (CG) give a guaranteed superlinear convergence. We propose a novel framework grounded in the hypothesis that loss functions in real-world tasks swap from initial non-convexity to convexity towards the optimum. This is a property we leverage to design an innovative two-phase optimization algorithm. The presented algorithm detects the swap point by observing the gradient norm dependence on the loss. In these regions, non-convex (Adam) and convex (CG) algorithms are used, respectively. Computing experiments confirm the hypothesis that this simple convexity structure is frequent enough to be practically exploited to substantially improve convergence and accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºæœºå™¨å­¦ä¹ ä¸­æŸå¤±å‡½æ•°æœ€å°åŒ–çš„æ•ˆç‡å–å†³äºå…¶å‡¸æ€§ (Convexity) æˆ–éå‡¸æ€§ (Non-convexity) ç‰¹å¾ã€‚é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å±€éƒ¨æœ€å°å€¼é™„è¿‘å‘ˆç°å‡¸æ€§çš„ç‰¹ç‚¹ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§åŸºäºä¸¤é˜¶æ®µè®­ç»ƒçš„æ–°å‹ä¼˜åŒ–ç®—æ³•ã€‚è¯¥ç®—æ³•åŸºäºæŸå¤±å‡½æ•°åœ¨æ¥è¿‘æœ€ä¼˜è§£æ—¶ä¼šä»åˆå§‹éå‡¸æ€§è½¬å‘å‡¸æ€§çš„å‡è®¾ï¼Œé€šè¿‡è§‚å¯Ÿæ¢¯åº¦èŒƒæ•° (Gradient norm) å¯¹æŸå¤±çš„ä¾èµ–å…³ç³»æ¥è‡ªåŠ¨æ£€æµ‹è½¬å˜ç‚¹ (Swap point)ã€‚åœ¨æ£€æµ‹åˆ°è½¬å˜å‰ä½¿ç”¨ Adam ç®—æ³•å¤„ç†éå‡¸åŒºåŸŸï¼Œæ£€æµ‹åˆ°è½¬å˜ååˆ™åˆ‡æ¢è‡³å…·æœ‰è¶…çº¿æ€§æ”¶æ•›ç‰¹æ€§çš„å…±è½­æ¢¯åº¦æ³• (Conjugate Gradient, CG)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§åˆ©ç”¨å‡¸ç»“æ„ç‰¹å¾çš„æ–¹æ³•åœ¨å®é™…ä»»åŠ¡ä¸­é¢‘ç¹æœ‰æ•ˆï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ·±åº¦ç¥ç»ç½‘ç»œçš„æ”¶æ•›é€Ÿåº¦å’Œè®­ç»ƒç²¾åº¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Appeared on KDIR IC3K Conference 2025 (Best Paper Award). Published in \"Proceedings of the 17th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management - Volume 1\"",
      "pdf_url": "https://arxiv.org/pdf/2510.25366v2",
      "published_date": "2025-10-29 10:37:24 UTC",
      "updated_date": "2025-10-30 08:16:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:05.058990+00:00"
    },
    {
      "arxiv_id": "2511.00070v1",
      "title": "Benchmarking Generative AI Against Bayesian Optimization for Constrained Multi-Objective Inverse Design",
      "title_zh": "é¢å‘å—é™å¤šç›®æ ‡é€†å‘è®¾è®¡çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸è´å¶æ–¯ä¼˜åŒ–åŸºå‡†æµ‹è¯•",
      "authors": [
        "Muhammad Bilal Awan",
        "Abdul Razzaq",
        "Abdul Shahid"
      ],
      "abstract": "This paper investigates the performance of Large Language Models (LLMs) as generative optimizers for solving constrained multi-objective regression tasks, specifically within the challenging domain of inverse design (property-to-structure mapping). This problem, critical to materials informatics, demands finding complex, feasible input vectors that lie on the Pareto optimal front. While LLMs have demonstrated universal effectiveness across generative and reasoning tasks, their utility in constrained, continuous, high-dimensional numerical spaces tasks they weren't explicitly architected for remains an open research question. We conducted a rigorous comparative study between established Bayesian Optimization (BO) frameworks and a suite of fine-tuned LLMs and BERT models. For BO, we benchmarked the foundational BoTorch Ax implementation against the state-of-the-art q-Expected Hypervolume Improvement (qEHVI, BoTorchM). The generative approach involved fine-tuning models via Parameter-Efficient Fine-Tuning (PEFT), framing the challenge as a regression problem with a custom output head. Our results show that BoTorch qEHVI achieved perfect convergence (GD=0.0), setting the performance ceiling. Crucially, the best-performing LLM (WizardMath-7B) achieved a Generational Distance (GD) of 1.21, significantly outperforming the traditional BoTorch Ax baseline (GD=15.03). We conclude that specialized BO frameworks remain the performance leader for guaranteed convergence, but fine-tuned LLMs are validated as a promising, computationally fast alternative, contributing essential comparative metrics to the field of AI-driven optimization. The findings have direct industrial applications in optimizing formulation design for resins, polymers, and paints, where multi-objective trade-offs between mechanical, rheological, and chemical properties are critical to innovation and production efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)ä½œä¸ºç”Ÿæˆå¼ä¼˜åŒ–å™¨åœ¨å¤„ç†å—é™å¤šç›®æ ‡é€†å‘è®¾è®¡(inverse design)ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œç‰¹åˆ«å…³æ³¨ææ–™ä¿¡æ¯å­¦ä¸­çš„å±æ€§åˆ°ç»“æ„æ˜ å°„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å‚æ•°é«˜æ•ˆå¾®è°ƒ(Parameter-Efficient Fine-Tuning, PEFT)æŠ€æœ¯å°†LLMsè½¬åŒ–ä¸ºå›å½’æ¨¡å‹ï¼Œå¹¶å°†å…¶ä¸æˆç†Ÿçš„è´å¶æ–¯ä¼˜åŒ–(Bayesian Optimization, BO)æ¡†æ¶ï¼ˆå¦‚BoTorch Axå’ŒqEHVIï¼‰è¿›è¡Œäº†ä¸¥æ ¼å¯¹æ¯”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶BoTorch qEHVIå®ç°äº†é›¶è¯¯å·®çš„å®Œç¾æ”¶æ•›ï¼Œä½†è¡¨ç°æœ€å¥½çš„LLM (WizardMath-7B) è·å¾—çš„ç”Ÿæˆè·ç¦»(Generational Distance, GD)ä¸º1.21ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»ŸBoTorch AxåŸºçº¿çš„15.03ã€‚ç ”ç©¶ç»“è®ºæŒ‡å‡ºï¼Œå°½ç®¡ä¸“é—¨çš„BOæ¡†æ¶åœ¨æ”¶æ•›ä¿è¯ä¸Šä¾ç„¶é¢†å…ˆï¼Œä½†å¾®è°ƒåçš„LLMsæä¾›äº†ä¸€ç§æå…·æ½œåŠ›ä¸”è®¡ç®—é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚è¯¥æˆæœåœ¨æ ‘è„‚ã€èšåˆç‰©å’Œæ¶‚æ–™ç­‰éœ€è¦æƒè¡¡æœºæ¢°ä¸åŒ–å­¦æ€§èƒ½çš„å·¥ä¸šé…æ–¹ä¼˜åŒ–é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 2 Figures",
      "pdf_url": "https://arxiv.org/pdf/2511.00070v1",
      "published_date": "2025-10-29 10:37:09 UTC",
      "updated_date": "2025-10-29 10:37:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:07.261883+00:00"
    },
    {
      "arxiv_id": "2511.11596v1",
      "title": "Loss Given Default Prediction Under Measurement-Induced Mixture Distributions: An Information-Theoretic Approach",
      "title_zh": "æµ‹é‡è¯±å‘æ··åˆåˆ†å¸ƒä¸‹çš„è¿çº¦æŸå¤±ç‡é¢„æµ‹ï¼šä¸€ç§ä¿¡æ¯è®ºæ–¹æ³•",
      "authors": [
        "Javier MarÃ­n"
      ],
      "abstract": "Loss Given Default (LGD) modeling faces a fundamental data quality constraint: 90% of available training data consists of proxy estimates based on pre-distress balance sheets rather than actual recovery outcomes from completed bankruptcy proceedings. We demonstrate that this mixture-contaminated training structure causes systematic failure of recursive partitioning methods, with Random Forest achieving negative r-squared (-0.664, worse than predicting the mean) on held-out test data. Information-theoretic approaches based on Shannon entropy and mutual information provide superior generalization, achieving r-squared of 0.191 and RMSE of 0.284 on 1,218 corporate bankruptcies (1980-2023). Analysis reveals that leverage-based features contain 1.510 bits of mutual information while size effects contribute only 0.086 bits, contradicting regulatory assumptions about scale-dependent recovery. These results establish practical guidance for financial institutions deploying LGD models under Basel III requirements when representative outcome data is unavailable at sufficient scale. The findings generalize to medical outcomes research, climate forecasting, and technology reliability-domains where extended observation periods create unavoidable mixture structure in training data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¿çº¦æŸå¤±ç‡(Loss Given Default, LGD)å»ºæ¨¡ä¸­é¢ä¸´çš„æ•°æ®è´¨é‡çº¦æŸï¼ŒæŒ‡å‡º90%çš„è®­ç»ƒæ•°æ®ç”±ä»£ç†ä¼°è®¡å€¼è€Œéå®é™…å›æ”¶ç»“æœæ„æˆï¼Œå½¢æˆäº†æµ‹é‡è¯±å¯¼çš„æ··åˆåˆ†å¸ƒç»“æ„ã€‚ç ”ç©¶è¯æ˜è¿™ç§æ•°æ®ç»“æ„ä¼šå¯¼è‡´Random Forestç­‰é€’å½’åˆ’åˆ†æ–¹æ³•ç³»ç»Ÿæ€§å¤±æ•ˆï¼Œåœ¨æµ‹è¯•é›†ä¸Šçš„r-squaredè¡¨ç°æå·®ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºShannon entropyå’Œmutual informationçš„ä¿¡æ¯è®ºæ–¹æ³•ï¼Œåœ¨1,218èµ·å…¬å¸ç ´äº§æ•°æ®ä¸­å®ç°äº†0.191çš„r-squaredï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚åˆ†ææ­ç¤ºæ æ†ç›¸å…³ç‰¹å¾åŒ…å«çš„äº’ä¿¡æ¯è¿œé«˜äºè§„æ¨¡æ•ˆåº”ï¼Œè¿™ä¸€å‘ç°æŒ‘æˆ˜äº†ç›‘ç®¡æœºæ„å…³äºè§„æ¨¡ä¾èµ–å›æ”¶çš„ä¼ ç»Ÿå‡è®¾ã€‚è¯¥ç ”ç©¶ä¸ä»…ä¸ºBasel IIIè¦æ±‚ä¸‹çš„é‡‘èé£é™©å»ºæ¨¡æä¾›äº†å®è·µæŒ‡å¯¼ï¼Œå…¶ç»“è®ºè¿˜å¯æ¨å¹¿è‡³åŒ»å­¦ç ”ç©¶ã€æ°”å€™é¢„æµ‹ç­‰å­˜åœ¨é•¿è§‚æµ‹å‘¨æœŸå’Œæ··åˆæ•°æ®ç»“æ„çš„é¢†åŸŸã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.11596v1",
      "published_date": "2025-10-29 10:11:38 UTC",
      "updated_date": "2025-10-29 10:11:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:29.656647+00:00"
    },
    {
      "arxiv_id": "2512.09931v1",
      "title": "ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples",
      "title_zh": "ExaCraftï¼šé¢å‘ä¸ªæ€§åŒ–æ•™å­¦ç¤ºä¾‹çš„åŠ¨æ€å­¦ä¹ æƒ…å¢ƒé€‚é…",
      "authors": [
        "Akaash Chatterjee",
        "Suman Kundu"
      ],
      "abstract": "Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ExaCraftï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ç”Ÿæˆä¸ªæ€§åŒ–æ•™å­¦ç¤ºä¾‹çš„AIç³»ç»Ÿï¼Œé€šè¿‡é€‚åº”å­¦ä¹ è€…çš„åŠ¨æ€è¯­å¢ƒæ¥æå‡å­¦ä¹ æ•ˆæœã€‚ç³»ç»ŸåŸºäºGoogle Gemini AIå’ŒPython Flask APIï¼Œå¹¶ä»¥Chrome extensionå½¢å¼å‘ˆç°ï¼Œç»“åˆç”¨æˆ·å®šä¹‰çš„ä¸ªäººèµ„æ–™ä¸å®æ—¶è¡Œä¸ºåˆ†æï¼Œç¡®ä¿ç”Ÿæˆçš„ç¤ºä¾‹åœ¨æ–‡åŒ–ä¸Šç›¸å…³ä¸”ç¬¦åˆä¸ªä½“éœ€æ±‚ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºèƒ½å¤Ÿæ ¹æ®å­¦ä¹ è€…çš„äº”ä¸ªå…³é”®è¯­å¢ƒç»´åº¦è¿›è¡ŒåŠ¨æ€è°ƒæ•´ï¼ŒåŒ…æ‹¬æŒ£æ‰æŒ‡æ ‡(indicators of struggle)ã€æŒæ¡æ¨¡å¼(mastery patterns)ã€ä¸»é¢˜è¿›å±•å†å²(topic progression history)ã€ä¼šè¯è¾¹ç•Œ(session boundaries)ä»¥åŠå­¦ä¹ è¿›å±•ä¿¡å·(learning progression signals)ã€‚æ¼”ç¤ºç»“æœè¡¨æ˜ï¼ŒExaCraftèƒ½å¤Ÿæ ¹æ®ä¸»é¢˜é‡å¤ã€é‡æ–°ç”Ÿæˆè¯·æ±‚å’Œå­¦ä¹ è¿›åº¦ï¼Œé©±åŠ¨ç¤ºä¾‹ä»åŸºç¡€æ¦‚å¿µæ¼”å˜ä¸ºé«˜çº§æŠ€æœ¯å®ç°ï¼Œå±•ç¤ºäº†å…¶åœ¨æä¾›ç²¾å‡†ä¸ªæ€§åŒ–æ•™è‚²æ”¯æŒæ–¹é¢çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 1 Figure",
      "pdf_url": "https://arxiv.org/pdf/2512.09931v1",
      "published_date": "2025-10-29 09:55:03 UTC",
      "updated_date": "2025-10-29 09:55:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:07.754227+00:00"
    },
    {
      "arxiv_id": "2510.25340v1",
      "title": "Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork",
      "title_zh": "é¢å‘å¤šæ–¹ä¸´æ—¶å›¢é˜Ÿåä½œçš„å¤šæ–¹æ™ºèƒ½ä½“å…³ç³»é‡‡æ ·",
      "authors": [
        "Beiwen Zhang",
        "Yongheng Liang",
        "Hejun Wu"
      ],
      "abstract": "Multi-agent reinforcement learning (MARl) has achieved strong results in cooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc teamwork (AHT) relaxes this by allowing collaboration with unknown partners, yet existing variants still presume shared conventions. We introduce Multil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate with multiple mutually unfamiliar groups of uncontrolled teammates. To address this, we propose MARs, which builds a sparse skeleton graph and applies relational modeling to capture cross-group dvnamics. Experiments on MPE and starCralt ll show that MARs outperforms MARL and AHT baselines while converging faster.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†Multi-party Ad Hoc Teamwork (MAHT) ä»»åŠ¡åœºæ™¯ï¼Œæ—¨åœ¨è§£å†³å—æ§æ™ºèƒ½ä½“éœ€ä¸å¤šä¸ªäº’ä¸ç†Ÿæ‚‰çš„éå—æ§é˜Ÿå‹å°ç»„è¿›è¡Œæœ‰æ•ˆåä½œçš„éš¾é¢˜ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†MARS (Multi-party Agent Relation Sampling) æ¡†æ¶ï¼Œé€šè¿‡æ„å»ºç¨€ç–éª¨æ¶å›¾(sparse skeleton graph)å¹¶åº”ç”¨å…³ç³»å»ºæ¨¡(relational modeling)æ¥æ•æ‰å¤æ‚çš„è·¨ç»„åŠ¨åŠ›å­¦(cross-group dynamics)ã€‚MARSæœ‰æ•ˆå¼¥è¡¥äº†ä¼ ç»Ÿå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (MARL)ä¾èµ–å›ºå®šå›¢é˜Ÿä»¥åŠå³æ—¶å›¢é˜Ÿåˆä½œ(AHT)é¢„è®¾å…±äº«æƒ¯ä¾‹çš„å±€é™æ€§ã€‚åœ¨MPEå’ŒStarCraft IIç¯å¢ƒä¸‹çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMARSåœ¨ä»»åŠ¡è¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„MARLå’ŒAHTåŸºå‡†æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºäº†æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼Œä¸ºå¤„ç†å¤§è§„æ¨¡ã€éé¢„è®¾ç¯å¢ƒä¸‹çš„å¤šæ–¹æ™ºèƒ½ä½“ååŒå·¥ä½œæä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25340v1",
      "published_date": "2025-10-29 09:53:07 UTC",
      "updated_date": "2025-10-29 09:53:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:16.455567+00:00"
    },
    {
      "arxiv_id": "2510.25327v5",
      "title": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding",
      "title_zh": "MMEdgeï¼šé€šè¿‡æµæ°´çº¿å¼æ„ŸçŸ¥ä¸ç¼–ç åŠ é€Ÿç«¯ä¾§å¤šæ¨¡æ€æ¨ç†",
      "authors": [
        "Runxi Huang",
        "Mingxuan Yu",
        "Mingyu Tsoi",
        "Xiaomin Ouyang"
      ],
      "abstract": "Real-time multimodal inference on resource-constrained edge devices is essential for applications such as autonomous driving, human-computer interaction, and mobile health. However, prior work often overlooks the tight coupling between sensing dynamics and model execution, as well as the complex inter-modality dependencies. In this paper, we propose MMEdge, an new on-device multi-modal inference framework based on pipelined sensing and encoding. Instead of waiting for complete sensor inputs, MMEdge decomposes the entire inference process into a sequence of fine-grained sensing and encoding units, allowing computation to proceed incrementally as data arrive. MMEdge also introduces a lightweight but effective temporal aggregation module that captures rich temporal dynamics across different pipelined units to maintain accuracy performance. Such pipelined design also opens up opportunities for fine-grained cross-modal optimization and early decision-making during inference. To further enhance system performance under resource variability and input data complexity, MMEdge incorporates an adaptive multimodal configuration optimizer that dynamically selects optimal sensing and model configurations for each modality under latency constraints, and a cross-modal speculative skipping mechanism that bypasses future units of slower modalities when early predictions reach sufficient confidence. We evaluate MMEdge using two public multimodal datasets and deploy it on a real-world unmanned aerial vehicle (UAV)-based multimodal testbed. The results show that MMEdge significantly reduces end-to-end latency while maintaining high task accuracy across various system and data dynamics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MMEdgeï¼Œä¸€ç§åŸºäºæµæ°´çº¿æ„Ÿæµ‹ä¸ç¼–ç  (Pipelined Sensing and Encoding) çš„æ–°é¢–è®¾å¤‡ç«¯å¤šæ¨¡æ€æ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¾¹ç¼˜è®¾å¤‡åœ¨å®æ—¶æ¨ç†ä¸­é¢ä¸´çš„æ„Ÿæµ‹åŠ¨åŠ›å­¦ä¸æ¨¡å‹æ‰§è¡Œè€¦åˆç´§å¯†ä»¥åŠæ¨¡æ€é—´ä¾èµ–å¤æ‚çš„é—®é¢˜ã€‚MMEdge å°†æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºç»†ç²’åº¦çš„æ„Ÿæµ‹å’Œç¼–ç å•å…ƒï¼Œå…è®¸è®¡ç®—åœ¨æ•°æ®åˆ°è¾¾æ—¶å¢é‡è¿›è¡Œï¼Œä»è€Œæ‰“ç ´äº†ç­‰å¾…å®Œæ•´ä¼ æ„Ÿå™¨è¾“å…¥çš„ç“¶é¢ˆã€‚ä¸ºäº†ç»´æŒæ¨¡å‹å‡†ç¡®æ€§ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†è½»é‡çº§çš„æ—¶é—´èšåˆæ¨¡å— (Temporal Aggregation Module) æ¥æ•æ‰è·¨å•å…ƒçš„æ—¶ç©ºåŠ¨æ€ï¼Œå¹¶é…å¤‡äº†è‡ªé€‚åº”å¤šæ¨¡æ€é…ç½®ä¼˜åŒ–å™¨ (Adaptive Multimodal Configuration Optimizer) ä»¥åœ¨å»¶è¿Ÿçº¦æŸä¸‹åŠ¨æ€è°ƒæ•´å„æ¨¡æ€é…ç½®ã€‚æ­¤å¤–ï¼ŒMMEdge åˆ›æ–°æ€§åœ°é‡‡ç”¨äº†è·¨æ¨¡æ€æŠ•æœºè·³è¿‡æœºåˆ¶ (Cross-modal Speculative Skipping)ï¼Œå…è®¸åœ¨æ—©æœŸé¢„æµ‹è¾¾åˆ°è¶³å¤Ÿç½®ä¿¡åº¦æ—¶ç»•è¿‡è¾ƒæ…¢æ¨¡æ€çš„åç»­å•å…ƒã€‚åœ¨å…¬å¼€æ•°æ®é›†å’Œæ— äººæœº (UAV) å®é™…æµ‹è¯•å¹³å°ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒMMEdge åœ¨å„ç§ç³»ç»Ÿå’Œæ•°æ®åŠ¨æ€ä¸‹å‡èƒ½æ˜¾è‘—é™ä½ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒæé«˜çš„ä»»åŠ¡å‡†ç¡®ç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code available at: https://github.com/HKUST-MINSys-Lab/MMEdge. Accepted by SenSys 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.25327v5",
      "published_date": "2025-10-29 09:41:03 UTC",
      "updated_date": "2025-11-18 04:44:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:18.056662+00:00"
    },
    {
      "arxiv_id": "2510.25320v1",
      "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning",
      "title_zh": "GAPï¼šåŸºäºå›¾çš„å¹¶è¡Œå·¥å…·è°ƒç”¨ä¸å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“è§„åˆ’",
      "authors": [
        "Jiaqi Wu",
        "Qinlao Zhao",
        "Zefeng Chen",
        "Kai Qin",
        "Yifei Zhao",
        "Xueqian Wang",
        "Yuhang Yao"
      ],
      "abstract": "Autonomous agents powered by large language models (LLMs) have shown impressive capabilities in tool manipulation for complex task-solving. However, existing paradigms such as ReAct rely on sequential reasoning and execution, failing to exploit the inherent parallelism among independent sub-tasks. This sequential bottleneck leads to inefficient tool utilization and suboptimal performance in multi-step reasoning scenarios. We introduce Graph-based Agent Planning (GAP), a novel framework that explicitly models inter-task dependencies through graph-based planning to enable adaptive parallel and serial tool execution. Our approach trains agent foundation models to decompose complex tasks into dependency-aware sub-task graphs, autonomously determining which tools can be executed in parallel and which must follow sequential dependencies. This dependency-aware orchestration achieves substantial improvements in both execution efficiency and task accuracy. To train GAP, we construct a high-quality dataset of graph-based planning traces derived from the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage training strategy: supervised fine-tuning (SFT) on the curated dataset, followed by reinforcement learning (RL) with a correctness-based reward function on strategically sampled queries where tool-based reasoning provides maximum value. Experimental results on MHQA datasets demonstrate that GAP significantly outperforms traditional ReAct baselines, particularly on multi-step retrieval tasks, while achieving dramatic improvements in tool invocation efficiency through intelligent parallelization. The project page is available at: https://github.com/WJQ7777/Graph-Agent-Planning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ReActç­‰ç°æœ‰æ™ºèƒ½ä½“èŒƒå¼åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶è¿‡åº¦ä¾èµ–é¡ºåºæ¨ç†ã€æ— æ³•åˆ©ç”¨å­ä»»åŠ¡å¹¶è¡Œæ€§å¯¼è‡´çš„æ•ˆç‡ç“¶é¢ˆï¼Œæå‡ºäº†åŸºäºå›¾çš„æ™ºèƒ½ä½“è§„åˆ’(Graph-based Agent Planning, GAP)æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ˜¾å¼å»ºæ¨¡ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ï¼Œè®­ç»ƒæ™ºèƒ½ä½“å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå…·æœ‰ä¾èµ–æ„ŸçŸ¥çš„å­ä»»åŠ¡å›¾ï¼Œä»è€Œå®ç°è‡ªé€‚åº”çš„å¹¶è¡Œä¸ä¸²è¡Œå·¥å…·æ‰§è¡Œã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†ç»“åˆç›‘ç£å¾®è°ƒ(SFT)ä¸åŸºäºæ­£ç¡®æ€§å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RL)ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œå¹¶åœ¨å¤šè·³é—®ç­”(Multi-Hop Question Answering, MHQA)åŸºå‡†ä¸Šæ„å»ºäº†é«˜è´¨é‡çš„å›¾è§„åˆ’æ•°æ®é›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGAPåœ¨å¤šæ­¥æ£€ç´¢ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ReActåŸºçº¿ï¼Œå¹¶åœ¨å¤§å¹…æå‡å·¥å…·è°ƒç”¨æ•ˆç‡çš„åŒæ—¶æé«˜äº†ä»»åŠ¡æ‰§è¡Œçš„å‡†ç¡®æ€§ã€‚è¯¥ç ”ç©¶è¯æ˜äº†é€šè¿‡å›¾ç»“æ„å»ºæ¨¡ä»»åŠ¡ä¾èµ–å¯ä»¥æœ‰æ•ˆä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸‹çš„å·¥å…·ä½¿ç”¨æ•ˆèƒ½ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25320v1",
      "published_date": "2025-10-29 09:35:55 UTC",
      "updated_date": "2025-10-29 09:35:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:27.563654+00:00"
    },
    {
      "arxiv_id": "2510.25319v1",
      "title": "4-Doodle: Text to 3D Sketches that Move!",
      "title_zh": "4-Doodleï¼šæ–‡æœ¬é©±åŠ¨çš„åŠ¨æ€3Dç´ æç”Ÿæˆ",
      "authors": [
        "Hao Chen",
        "Jiaqi Wang",
        "Yonggang Qi",
        "Ke Li",
        "Kaiyue Pang",
        "Yi-Zhe Song"
      ],
      "abstract": "We present a novel task: text-to-3D sketch animation, which aims to bring freeform sketches to life in dynamic 3D space. Unlike prior works focused on photorealistic content generation, we target sparse, stylized, and view-consistent 3D vector sketches, a lightweight and interpretable medium well-suited for visual communication and prototyping. However, this task is very challenging: (i) no paired dataset exists for text and 3D (or 4D) sketches; (ii) sketches require structural abstraction that is difficult to model with conventional 3D representations like NeRFs or point clouds; and (iii) animating such sketches demands temporal coherence and multi-view consistency, which current pipelines do not address. Therefore, we propose 4-Doodle, the first training-free framework for generating dynamic 3D sketches from text. It leverages pretrained image and video diffusion models through a dual-space distillation scheme: one space captures multi-view-consistent geometry using differentiable BÃ©zier curves, while the other encodes motion dynamics via temporally-aware priors. Unlike prior work (e.g., DreamFusion), which optimizes from a single view per step, our multi-view optimization ensures structural alignment and avoids view ambiguity, critical for sparse sketches. Furthermore, we introduce a structure-aware motion module that separates shape-preserving trajectories from deformation-aware changes, enabling expressive motion such as flipping, rotation, and articulated movement. Extensive experiments show that our method produces temporally realistic and structurally stable 3D sketch animations, outperforming existing baselines in both fidelity and controllability. We hope this work serves as a step toward more intuitive and accessible 4D content creation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† 4-Doodleï¼Œè¿™æ˜¯é¦–ä¸ªä»æ–‡æœ¬ç”ŸæˆåŠ¨æ€ 3D ç´ æçš„æ— éœ€è®­ç»ƒ (training-free) æ¡†æ¶ï¼Œæ—¨åœ¨å°†è‡ªç”±å½¢å¼çš„ç´ æåœ¨åŠ¨æ€ä¸‰ç»´ç©ºé—´ä¸­èµ‹äºˆç”Ÿå‘½ã€‚è¯¥ä»»åŠ¡ä¸“æ³¨äºç”Ÿæˆç¨€ç–ã€é£æ ¼åŒ–ä¸”å¤šè§†å›¾ä¸€è‡´çš„ 3D å‘é‡ç´ æ (3D vector sketches)ï¼Œå°†å…¶ä½œä¸ºä¸€ç§è½»é‡çº§ä¸”å¯è§£é‡Šçš„è§†è§‰æ²Ÿé€šåª’ä»‹ã€‚4-Doodle é€šè¿‡åŒç©ºé—´è’¸é¦ (dual-space distillation) æ–¹æ¡ˆï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„å›¾åƒå’Œè§†é¢‘æ‰©æ•£æ¨¡å‹ (diffusion models)ï¼Œåœ¨å…¶ä¸­ä¸€ä¸ªç©ºé—´åˆ©ç”¨å¯å¾®åˆ†è´å¡å°”æ›²çº¿ (differentiable BÃ©zier curves) æ•æ‰å¤šè§†å›¾ä¸€è‡´çš„å‡ ä½•å½¢çŠ¶ã€‚å¦ä¸€ä¸ªç©ºé—´åˆ™é€šè¿‡æ—¶é—´æ„ŸçŸ¥å…ˆéªŒ (temporally-aware priors) ç¼–ç è¿åŠ¨åŠ¨åŠ›å­¦ï¼Œå¹¶é€šè¿‡å¤šè§†å›¾ä¼˜åŒ–ç¡®ä¿ç¨€ç–ç´ æçš„ç»“æ„å¯¹é½ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†ç»“æ„æ„ŸçŸ¥è¿åŠ¨æ¨¡å— (structure-aware motion module)ï¼Œå°†ä¿æŒå½¢çŠ¶çš„è½¨è¿¹ä¸å½¢å˜æ„ŸçŸ¥å˜åŒ–åˆ†ç¦»ï¼Œä»è€Œå®ç°ç¿»è½¬ã€æ—‹è½¬å’Œå…³èŠ‚è¿åŠ¨ç­‰è¡¨ç°åŠ›ä¸°å¯Œçš„åŠ¨ä½œã€‚å®éªŒè¯æ˜ï¼Œ4-Doodle åœ¨å¿ å®åº¦å’Œå¯æ§æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆåœ¨æ—¶é—´ä¸ŠçœŸå®ä¸”ç»“æ„ç¨³å®šçš„ 4D ç´ æåŠ¨ç”»ï¼Œä¸ºç›´è§‚ä¸”æ˜“ç”¨çš„ 4D å†…å®¹åˆ›ä½œæä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25319v1",
      "published_date": "2025-10-29 09:33:29 UTC",
      "updated_date": "2025-10-29 09:33:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:54.365254+00:00"
    },
    {
      "arxiv_id": "2510.25311v1",
      "title": "Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning",
      "title_zh": "å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ä¸­ç¨ å¯†ä¸”å¤šæ ·åŒ–çš„ç›®æ ‡è¦†ç›–",
      "authors": [
        "Sagalpreet Singh",
        "Rishi Saket",
        "Aravindan Raghuveer"
      ],
      "abstract": "Reinforcement Learning algorithms are primarily focused on learning a policy that maximizes expected return. As a result, the learned policy can exploit one or few reward sources. However, in many natural situations, it is desirable to learn a policy that induces a dispersed marginal state distribution over rewarding states, while maximizing the expected return which is typically tied to reaching a goal state. This aspect remains relatively unexplored. Existing techniques based on entropy regularization and intrinsic rewards use stochasticity for encouraging exploration to find an optimal policy which may not necessarily lead to dispersed marginal state distribution over rewarding states. Other RL algorithms which match a target distribution assume the latter to be available apriori. This may be infeasible in large scale systems where enumeration of all states is not possible and a state is determined to be a goal state only upon reaching it. We formalize the problem of maximizing the expected return while uniformly visiting the goal states as Multi Goal RL in which an oracle classifier over the state space determines the goal states. We propose a novel algorithm that learns a high-return policy mixture with marginal state distribution dispersed over the set of goal states. Our algorithm is based on optimizing a custom RL reward which is computed - based on the current policy mixture - at each iteration for a set of sampled trajectories. The latter are used via an offline RL algorithm to update the policy mixture. We prove performance guarantees for our algorithm, showing efficient convergence bounds for optimizing a natural objective which captures the expected return as well as the dispersion of the marginal state distribution over the goal states. We design and perform experiments on synthetic MDPs and standard RL environments to evaluate the effectiveness of our algorithm.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ç®—æ³•å¾€å¾€ä»…å¼€å‘å°‘æ•°å¥–åŠ±æºè€Œå¿½ç•¥ç›®æ ‡çŠ¶æ€è¦†ç›–å¤šæ ·æ€§çš„é—®é¢˜ï¼Œæ­£å¼æå‡ºäº†å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ (Multi Goal RL)æ¡†æ¶ï¼Œæ—¨åœ¨æœ€å¤§åŒ–æ”¶ç›Šçš„åŒæ—¶å®ç°å¯¹ç›®æ ‡çŠ¶æ€çš„å‡åŒ€è®¿é—®ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç®—æ³•ï¼Œé€šè¿‡åœ¨è¿­ä»£è¿‡ç¨‹ä¸­åŸºäºå½“å‰ç­–ç•¥æ··åˆ(policy mixture)è®¡ç®—è‡ªå®šä¹‰å¥–åŠ±ï¼Œå¹¶ç»“åˆç¦»çº¿å¼ºåŒ–å­¦ä¹ (offline RL)æŠ€æœ¯æ¥æ›´æ–°ç­–ç•¥ï¼Œä»è€Œå­¦ä¹ å‡ºèƒ½å¤Ÿè¯±å¯¼åˆ†æ•£è¾¹é™…çŠ¶æ€åˆ†å¸ƒçš„é«˜æ”¶ç›Šç­–ç•¥ã€‚è¯¥ç®—æ³•åœ¨ç†è®ºä¸Šè·å¾—äº†æ€§èƒ½ä¿è¯ï¼Œè¯æ˜äº†å…¶åœ¨ä¼˜åŒ–ç»“åˆé¢„æœŸæ”¶ç›Šä¸ç›®æ ‡åˆ†å¸ƒç¦»æ•£åº¦çš„ç›®æ ‡å‡½æ•°æ—¶å…·æœ‰é«˜æ•ˆçš„æ”¶æ•›è¾¹ç•Œã€‚åœ¨åˆæˆé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(MDPs)å’Œæ ‡å‡†å¼ºåŒ–å­¦ä¹ ç¯å¢ƒä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆè§£å†³å¤§è§„æ¨¡ç³»ç»Ÿä¸­ç›®æ ‡åˆ†å¸ƒä¸å¯é¢„çŸ¥æ—¶çš„å¤šæ ·åŒ–è¦†ç›–é—®é¢˜ï¼Œä¸ºå®ç°æ›´å…·æ¢ç´¢æ€§å’Œé²æ£’æ€§çš„ç­–ç•¥å­¦ä¹ æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25311v1",
      "published_date": "2025-10-29 09:23:21 UTC",
      "updated_date": "2025-10-29 09:23:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:42.769880+00:00"
    },
    {
      "arxiv_id": "2510.25268v1",
      "title": "SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation",
      "title_zh": "SynHLMAï¼šåŸºäºç¦»æ•£äººç‰©äº¤äº’è¡¨ç¤ºçš„å…³èŠ‚ç±»ç‰©ä½“è¯­è¨€é©±åŠ¨æ‰‹éƒ¨æ“çºµåˆæˆ",
      "authors": [
        "Wang zhi",
        "Yuyan Liu",
        "Liu Liu",
        "Li Zhang",
        "Ruixuan Lu",
        "Dan Guo"
      ],
      "abstract": "Generating hand grasps with language instructions is a widely studied topic that benefits from embodied AI and VR/AR applications. While transferring into hand articulatied object interaction (HAOI), the hand grasps synthesis requires not only object functionality but also long-term manipulation sequence along the object deformation. This paper proposes a novel HAOI sequence generation framework SynHLMA, to synthesize hand language manipulation for articulated objects. Given a complete point cloud of an articulated object, we utilize a discrete HAOI representation to model each hand object interaction frame. Along with the natural language embeddings, the representations are trained by an HAOI manipulation language model to align the grasping process with its language description in a shared representation space. A joint-aware loss is employed to ensure hand grasps follow the dynamic variations of articulated object joints. In this way, our SynHLMA achieves three typical hand manipulation tasks for articulated objects of HAOI generation, HAOI prediction and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and experimental results demonstrate the superior hand grasp sequence generation performance comparing with state-of-the-art. We also show a robotics grasp application that enables dexterous grasps execution from imitation learning using the manipulation sequence provided by our SynHLMA. Our codes and datasets will be made publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ ¹æ®è¯­è¨€æŒ‡ä»¤ç”Ÿæˆæ‰‹éƒ¨ä¸å…³èŠ‚ç‰©ä½“äº¤äº’ï¼ˆHand Articulated Object Interaction, HAOIï¼‰åºåˆ—ä¸­çš„åŠŸèƒ½æ€§éœ€æ±‚ã€é•¿æœŸæ“çºµç¨³å®šæ€§åŠç‰©ä½“å½¢å˜æŒ‘æˆ˜ï¼Œæå‡ºäº† SynHLMA æ¡†æ¶ã€‚SynHLMA é‡‡ç”¨ç¦»æ•£çš„ HAOI è¡¨è¾¾æ¥å»ºæ¨¡æ‰‹éƒ¨ä¸ç‰©ä½“çš„äº¤äº’è¿‡ç¨‹ï¼Œå¹¶åˆ©ç”¨ä¸“é—¨çš„è¯­è¨€æ¨¡å‹å°†æŠ“å–åŠ¨ä½œä¸è¯­è¨€æè¿°åœ¨å…±äº«ç©ºé—´ä¸­å¯¹é½ã€‚ä¸ºäº†ç¡®ä¿æ‰‹éƒ¨åŠ¨ä½œèƒ½è·Ÿéšå…³èŠ‚ç‰©ä½“çš„åŠ¨æ€å˜åŒ–ï¼Œç ”ç©¶è®¾è®¡äº†å…³èŠ‚æ„ŸçŸ¥æŸå¤±ï¼ˆJoint-aware lossï¼‰è¿›è¡Œä¼˜åŒ–ã€‚å®éªŒåœ¨è‡ªå»ºçš„ HAOI-lang æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨ HAOI ç”Ÿæˆã€é¢„æµ‹å’Œæ’å€¼ä»»åŠ¡ä¸­çš„æ€§èƒ½å‡ä¼˜äºç°æœ‰çš„ SOTA æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜é€šè¿‡æ¨¡ä»¿å­¦ä¹ ï¼ˆImitation Learningï¼‰å±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨æœºå™¨äººçµå·§æŠ“å–åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚è¯¥æˆæœä¸ºå…·èº«æ™ºèƒ½ï¼ˆEmbodied AIï¼‰å’Œ VR/AR åº”ç”¨ä¸­çš„å¤æ‚æ‰‹éƒ¨æ“çºµä»»åŠ¡æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25268v1",
      "published_date": "2025-10-29 08:27:00 UTC",
      "updated_date": "2025-10-29 08:27:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:28:50.177749+00:00"
    },
    {
      "arxiv_id": "2510.25262v1",
      "title": "IBNorm: Information-Bottleneck Inspired Normalization for Representation Learning",
      "title_zh": "IBNormï¼šå—ä¿¡æ¯ç“¶é¢ˆå¯å‘çš„è¡¨ç¤ºå­¦ä¹ å½’ä¸€åŒ–æ–¹æ³•",
      "authors": [
        "Xiandong Zou",
        "Pan Zhou"
      ],
      "abstract": "Normalization is fundamental to deep learning, but existing approaches such as BatchNorm, LayerNorm, and RMSNorm are variance-centric by enforcing zero mean and unit variance, stabilizing training without controlling how representations capture task-relevant information. We propose IB-Inspired Normalization (IBNorm), a simple yet powerful family of methods grounded in the Information Bottleneck principle. IBNorm introduces bounded compression operations that encourage embeddings to preserve predictive information while suppressing nuisance variability, yielding more informative representations while retaining the stability and compatibility of standard normalization. Theoretically, we prove that IBNorm achieves a higher IB value and tighter generalization bounds than variance-centric methods. Empirically, IBNorm consistently outperforms BatchNorm, LayerNorm, and RMSNorm across large-scale language models (LLaMA, GPT-2) and vision models (ResNet, ViT), with mutual information analysis confirming superior information bottleneck behavior. Code will be released publicly.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† IBNormï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¿¡æ¯ç“¶é¢ˆ Information Bottleneck åŸåˆ™çš„å½’ä¸€åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ BatchNormã€LayerNorm å’Œ RMSNorm ç­‰ä¼ ç»Ÿæ–¹æ³•ä»…å…³æ³¨æ–¹å·®æ§åˆ¶è€Œå¿½è§†ä»»åŠ¡ç›¸å…³ä¿¡æ¯æ•è·çš„é—®é¢˜ã€‚IBNorm é€šè¿‡å¼•å…¥æœ‰ç•Œå‹ç¼©æ“ä½œï¼Œåœ¨ä¿ç•™é¢„æµ‹ä¿¡æ¯çš„åŒæ—¶æœ‰æ•ˆæŠ‘åˆ¶æ— å…³å˜é‡ï¼Œä»è€Œåœ¨ç»´æŒè®­ç»ƒç¨³å®šæ€§çš„åŸºç¡€ä¸Šç”Ÿæˆæ›´å…·ä»£è¡¨æ€§çš„ç‰¹å¾ã€‚ç†è®ºè¯æ˜ï¼Œç›¸æ¯”ä¼ ç»Ÿçš„ä»¥æ–¹å·®ä¸ºä¸­å¿ƒçš„æ–¹æ³•ï¼ŒIBNorm èƒ½å¤Ÿå®ç°æ›´é«˜çš„ IB å€¼å’Œæ›´ç´§è‡´çš„æ³›åŒ–ç•Œé™ã€‚åœ¨ LLaMAã€GPT-2ã€ResNet å’Œ ViT ç­‰å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åŠè§†è§‰æ¨¡å‹çš„å®éªŒä¸­ï¼ŒIBNorm çš„æ€§èƒ½å§‹ç»ˆä¼˜äºä¸»æµå½’ä¸€åŒ–æ–¹æ³•ã€‚äº’ä¿¡æ¯åˆ†æè¿›ä¸€æ­¥è¯å®äº†è¯¥æ–¹æ³•å…·æœ‰ä¼˜è¶Šçš„ä¿¡æ¯ç“¶é¢ˆè¡Œä¸ºï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¡¨ç¤ºå­¦ä¹ çš„è´¨é‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25262v1",
      "published_date": "2025-10-29 08:21:32 UTC",
      "updated_date": "2025-10-29 08:21:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:51.658191+00:00"
    },
    {
      "arxiv_id": "2510.25259v1",
      "title": "TV-Rec: Time-Variant Convolutional Filter for Sequential Recommendation",
      "title_zh": "TV-Recï¼šç”¨äºåºåˆ—æ¨èçš„æ—¶å˜å·ç§¯æ»¤æ³¢å™¨",
      "authors": [
        "Yehjin Shin",
        "Jeongwhan Choi",
        "Seojin Kim",
        "Noseong Park"
      ],
      "abstract": "Recently, convolutional filters have been increasingly adopted in sequential recommendation for their ability to capture local sequential patterns. However, most of these models complement convolutional filters with self-attention. This is because convolutional filters alone, generally fixed filters, struggle to capture global interactions necessary for accurate recommendation. We propose Time-Variant Convolutional Filters for Sequential Recommendation (TV-Rec), a model inspired by graph signal processing, where time-variant graph filters capture position-dependent temporal variations in user sequences. By replacing both fixed kernels and self-attention with time-variant filters, TV-Rec achieves higher expressive power and better captures complex interaction patterns in user behavior. This design not only eliminates the need for self-attention but also reduces computation while accelerating inference. Extensive experiments on six public benchmarks show that TV-Rec outperforms state-of-the-art baselines by an average of 7.49%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åºè´¯æ¨è(Sequential Recommendation)ä¸­å›ºå®šå·ç§¯æ»¤æ³¢å™¨éš¾ä»¥æ•æ‰å…¨å±€äº¤äº’ä¸”è¿‡åº¦ä¾èµ–è‡ªæ³¨æ„åŠ›æœºåˆ¶(Self-attention)çš„é—®é¢˜ï¼Œæå‡ºäº†TV-Recæ¨¡å‹ã€‚TV-Recå—åˆ°å›¾ä¿¡å·å¤„ç†(Graph Signal Processing)çš„å¯å‘ï¼Œåˆ©ç”¨æ—¶å˜å·ç§¯æ»¤æ³¢å™¨(Time-Variant Convolutional Filter)æ¥æ•æ‰ç”¨æˆ·åºåˆ—ä¸­éšä½ç½®å˜åŒ–çš„æ—¶é—´æ¼”å˜ç‰¹æ€§ã€‚é€šè¿‡ç”¨æ—¶å˜æ»¤æ³¢å™¨åŒæ—¶å–ä»£å›ºå®šå·ç§¯æ ¸å’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥æ¨¡å‹ä¸ä»…å¢å¼ºäº†æ•æ‰å¤æ‚ç”¨æˆ·äº¤äº’æ¨¡å¼çš„è¡¨è¾¾èƒ½åŠ›ï¼Œè¿˜æ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€å¹¶åŠ é€Ÿäº†æ¨ç†è¿‡ç¨‹ã€‚åœ¨å…­ä¸ªå…¬å¼€åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒTV-Recç›¸æ¯”ç°æœ‰æœ€å…ˆè¿›åŸºå‡†æ¨¡å‹åœ¨æ€§èƒ½ä¸Šå¹³å‡æå‡äº†7.49%ï¼Œä¸ºé«˜æ•ˆçš„åºè´¯æ¨èç³»ç»Ÿæä¾›äº†ä¸€ç§æ–°çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "The 39th Conference on Neural Information Processing Systems (NeurIPS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.25259v1",
      "published_date": "2025-10-29 08:14:03 UTC",
      "updated_date": "2025-10-29 08:14:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:27:56.961600+00:00"
    },
    {
      "arxiv_id": "2511.01894v1",
      "title": "LGCC: Enhancing Flow Matching Based Text-Guided Image Editing with Local Gaussian Coupling and Context Consistency",
      "title_zh": "LGCCï¼šåˆ©ç”¨å±€éƒ¨é«˜æ–¯è€¦åˆä¸ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å¢å¼ºåŸºäºæµåŒ¹é…çš„æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘",
      "authors": [
        "Fangbing Liu",
        "Pengfei Duan",
        "Wen Li",
        "Yi He"
      ],
      "abstract": "Recent advancements have demonstrated the great potential of flow matching-based Multimodal Large Language Models (MLLMs) in image editing. However, state-of-the-art works like BAGEL face limitations, including detail degradation, content inconsistency, and inefficiency due to their reliance on random noise initialization. To address these issues, we propose LGCC, a novel framework with two key components: Local Gaussian Noise Coupling (LGNC) and Content Consistency Loss (CCL). LGNC preserves spatial details by modeling target image embeddings and their locally perturbed counterparts as coupled pairs, while CCL ensures semantic alignment between edit instructions and image modifications, preventing unintended content removal. By integrating LGCC with the BAGEL pre-trained model via curriculum learning, we significantly reduce inference steps, improving local detail scores on I2EBench by 1.60% and overall scores by 0.53%. LGCC achieves 3x -- 5x speedup for lightweight editing and 2x for universal editing, requiring only 40% -- 50% of the inference time of BAGEL or Flux. These results demonstrate LGCC's ability to preserve detail, maintain contextual integrity, and enhance inference speed, offering a cost-efficient solution without compromising editing quality.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LGCCæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŸºäºFlow Matchingçš„æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ä¸­å­˜åœ¨çš„ç»†èŠ‚é€€åŒ–ã€å†…å®¹ä¸ä¸€è‡´å’Œæ¨ç†æ•ˆç‡ä½ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†Local Gaussian Noise Coupling (LGNC)å’ŒContent Consistency Loss (CCL)ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œå…¶ä¸­LGNCé€šè¿‡å¯¹å›¾åƒåµŒå…¥åŠå…¶å±€éƒ¨æ‰°åŠ¨å‰¯æœ¬è¿›è¡Œè€¦åˆå»ºæ¨¡æ¥ç²¾ç¡®ä¿ç•™ç©ºé—´ç»†èŠ‚ï¼Œè€ŒCCLåˆ™ç¡®ä¿ç¼–è¾‘æŒ‡ä»¤ä¸å›¾åƒä¿®æ”¹ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼Œé˜²æ­¢æ„å¤–çš„å†…å®¹åˆ é™¤ã€‚é€šè¿‡è¯¾ç¨‹å­¦ä¹ (Curriculum Learning)å°†LGCCä¸BAGELé¢„è®­ç»ƒæ¨¡å‹é›†æˆï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—å‡å°‘æ¨ç†æ­¥æ•°çš„åŒæ—¶ï¼Œæå‡äº†åœ¨I2EBenchä¸Šçš„å±€éƒ¨ç»†èŠ‚è¡¨ç°å’Œæ•´ä½“è¯„åˆ†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLGCCåœ¨è½»é‡çº§ç¼–è¾‘ä»»åŠ¡ä¸­å®ç°äº†3è‡³5å€çš„åŠ é€Ÿï¼Œå…¶æ¨ç†æ—¶é—´ä»…éœ€BAGELæˆ–Fluxçš„40%è‡³50%ã€‚è¯¥ç ”ç©¶åœ¨ä¿æŒå›¾åƒç»†èŠ‚ä¸ä¸Šä¸‹æ–‡å®Œæ•´æ€§çš„åŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œä¸ºé«˜è´¨é‡ã€é«˜æ•ˆç‡çš„å›¾åƒç¼–è¾‘æä¾›äº†æå…·æ€§ä»·æ¯”çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.01894v1",
      "published_date": "2025-10-29 08:12:32 UTC",
      "updated_date": "2025-10-29 08:12:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:28:01.069005+00:00"
    },
    {
      "arxiv_id": "2511.00067v1",
      "title": "Latent Domain Prompt Learning for Vision-Language Models",
      "title_zh": "é¢å‘è§†è§‰-è¯­è¨€æ¨¡å‹çš„æ½œåœ¨åŸŸæç¤ºå­¦ä¹ ",
      "authors": [
        "Zhixing Li",
        "Arsham Gholamzadeh Khoee",
        "Yinan Yu"
      ],
      "abstract": "The objective of domain generalization (DG) is to enable models to be robust against domain shift. DG is crucial for deploying vision-language models (VLMs) in real-world applications, yet most existing methods rely on domain labels that may not be available and often ambiguous. We instead study the DG setting where models must generalize well without access to explicit domain labels. Our key idea is to represent an unseen target domain as a combination of latent domains automatically discovered from training data, enabling the model to adaptively transfer knowledge across domains. To realize this, we perform latent domain clustering on image features and fuse domain-specific text features based on the similarity between the input image and each latent domain. Experiments on four benchmarks show that this strategy yields consistent gains over VLM-based baselines and provides new insights into improving robustness under domain shift.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨ç°å®åº”ç”¨ä¸­çš„é¢†åŸŸæ³›åŒ–(Domain Generalization, DG)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ½œåŸŸæç¤ºå­¦ä¹ çš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•å› è¿‡åº¦ä¾èµ–æ˜¾å¼é¢†åŸŸæ ‡ç­¾è€Œå¯¼è‡´çš„é²æ£’æ€§ä¸è¶³ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†æœªè§çš„ç›®æ ‡é¢†åŸŸè¡¨ç¤ºä¸ºä»è®­ç»ƒæ•°æ®ä¸­è‡ªåŠ¨å‘ç°çš„æ½œåŸŸ(latent domains)çš„ç»„åˆï¼Œä»è€Œå®ç°è·¨é¢†åŸŸçš„è‡ªé€‚åº”çŸ¥è¯†è¿ç§»ã€‚åœ¨æŠ€æœ¯å®ç°ä¸Šï¼Œç ”ç©¶è€…é€šè¿‡å¯¹å›¾åƒç‰¹å¾è¿›è¡Œæ½œåŸŸèšç±»ï¼Œå¹¶ä¾æ®è¾“å…¥å›¾åƒä¸å„æ½œåŸŸä¹‹é—´çš„ç›¸ä¼¼åº¦æ¥åŠ¨æ€èåˆé¢†åŸŸç‰¹å®šçš„æ–‡æœ¬ç‰¹å¾ã€‚å®éªŒåœ¨å››ä¸ªæƒå¨åŸºå‡†æ•°æ®é›†ä¸Šè¯æ˜ï¼Œè¯¥ç­–ç•¥åœ¨å¤„ç†é¢†åŸŸåç§»(domain shift)æ—¶è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºç°æœ‰çš„VLMåŸºå‡†æ¨¡å‹è·å¾—äº†æŒç»­çš„æ€§èƒ½æå‡ï¼Œå¹¶ä¸ºæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.00067v1",
      "published_date": "2025-10-29 08:09:07 UTC",
      "updated_date": "2025-10-29 08:09:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:28:10.270873+00:00"
    },
    {
      "arxiv_id": "2510.25254v1",
      "title": "Scaling Up Bayesian DAG Sampling",
      "title_zh": "æ‰©å±•è´å¶æ–¯ DAG é‡‡æ ·",
      "authors": [
        "Daniele Nikzad",
        "Alexander Zhilkin",
        "Juha Harviainen",
        "Jack Kuipers",
        "Giusi Moffa",
        "Mikko Koivisto"
      ],
      "abstract": "Bayesian inference of Bayesian network structures is often performed by sampling directed acyclic graphs along an appropriately constructed Markov chain. We present two techniques to improve sampling. First, we give an efficient implementation of basic moves, which add, delete, or reverse a single arc. Second, we expedite summing over parent sets, an expensive task required for more sophisticated moves: we devise a preprocessing method to prune possible parent sets so as to approximately preserve the sums. Our empirical study shows that our techniques can yield substantial efficiency gains compared to previous methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è´å¶æ–¯ç½‘ç»œ(Bayesian network)ç»“æ„çš„æ¨ç†é—®é¢˜ï¼Œæå‡ºäº†ä¸¤ç§æ—¨åœ¨æå‡æœ‰å‘æ— ç¯å›¾(DAG)åœ¨é©¬å°”å¯å¤«é“¾(Markov chain)é‡‡æ ·æ•ˆç‡çš„æŠ€æœ¯ã€‚ç ”ç©¶é¦–å…ˆå®ç°äº†ä¸€ç§é«˜æ•ˆçš„åŸºç¡€ç§»åŠ¨æ“ä½œï¼ŒåŒ…æ‹¬å¯¹å•ä¸ªå¼§æ®µçš„æ·»åŠ ã€åˆ é™¤æˆ–åè½¬ã€‚å…¶æ¬¡ï¼Œé’ˆå¯¹å¤æ‚ç§»åŠ¨ä¸­æ¶‰åŠçš„çˆ¶èŠ‚ç‚¹é›†(parent sets)æ±‚å’Œè¿™ä¸€é«˜æ˜‚è®¡ç®—æˆæœ¬ï¼Œæå‡ºäº†ä¸€ç§é¢„å¤„ç†æ–¹æ³•ï¼Œé€šè¿‡å‰ªæçˆ¶èŠ‚ç‚¹é›†æ¥è¿‘ä¼¼ä¿ç•™æ€»å’Œå¹¶åŠ é€Ÿè®¡ç®—ã€‚å®è¯ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¿™äº›æ”¹è¿›æŠ€æœ¯èƒ½å¤Ÿæ˜¾è‘—æå‡é‡‡æ ·æ•ˆç‡ï¼Œä¸ºå¤§è§„æ¨¡ç»“æ„çš„è´å¶æ–¯é‡‡æ ·æä¾›äº†æ›´å¼ºçš„æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25254v1",
      "published_date": "2025-10-29 08:06:20 UTC",
      "updated_date": "2025-10-29 08:06:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:28:05.972607+00:00"
    },
    {
      "arxiv_id": "2510.25241v1",
      "title": "One-shot Humanoid Whole-body Motion Learning",
      "title_zh": "å•æ ·æœ¬äººå½¢æœºå™¨äººå…¨èº«è¿åŠ¨å­¦ä¹ ",
      "authors": [
        "Hao Huang",
        "Geeta Chandra Raju Bethala",
        "Shuaihang Yuan",
        "Congcong Wen",
        "Anthony Tzes",
        "Yi Fang"
      ],
      "abstract": "Whole-body humanoid motion represents a cornerstone challenge in robotics, integrating balance, coordination, and adaptability to enable human-like behaviors. However, existing methods typically require multiple training samples per motion category, rendering the collection of high-quality human motion datasets both labor-intensive and costly. To address this, we propose a novel approach that trains effective humanoid motion policies using only a single non-walking target motion sample alongside readily available walking motions. The core idea lies in leveraging order-preserving optimal transport to compute distances between walking and non-walking sequences, followed by interpolation along geodesics to generate new intermediate pose skeletons, which are then optimized for collision-free configurations and retargeted to the humanoid before integration into a simulated environment for policy training via reinforcement learning. Experimental evaluations on the CMU MoCap dataset demonstrate that our method consistently outperforms baselines, achieving superior performance across metrics. Code will be released upon acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå½¢æœºå™¨äººå…¨èº«è¿åŠ¨å­¦ä¹ (Whole-body humanoid motion learning)ä¸­é«˜è´¨é‡æ•°æ®é›†é‡‡é›†å›°éš¾ä¸”æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ›æ–°çš„å•æ ·æœ¬å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä»…éœ€ä¸€ä¸ªéè¡Œèµ°ç›®æ ‡è¿åŠ¨æ ·æœ¬åŠç°æœ‰çš„è¡Œèµ°è¿åŠ¨æ•°æ®ï¼Œå³å¯è®­ç»ƒå‡ºæœ‰æ•ˆçš„äººå½¢æœºå™¨äººè¿åŠ¨ç­–ç•¥ã€‚å…¶æ ¸å¿ƒé€»è¾‘æ˜¯åˆ©ç”¨ä¿åºæœ€ä¼˜ä¼ è¾“(order-preserving optimal transport)è®¡ç®—è¡Œèµ°ä¸éè¡Œèµ°åºåˆ—é—´çš„è·ç¦»ï¼Œå¹¶æ²¿æµ‹åœ°çº¿(geodesics)æ’å€¼ç”Ÿæˆæ–°çš„ä¸­é—´å§¿æ€éª¨æ¶ã€‚è¿™äº›éª¨æ¶ç»è¿‡æ— ç¢°æ’é…ç½®(collision-free configurations)ä¼˜åŒ–å¹¶é‡å®šå‘è‡³æœºå™¨äººæ¨¡å‹ï¼Œéšååœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ä½¿ç”¨å¼ºåŒ–å­¦ä¹ (reinforcement learning)å®Œæˆç­–ç•¥è®­ç»ƒã€‚åœ¨ CMU MoCap æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šé¡¹è¯„ä¼°æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œä¸ºä½æ•°æ®æˆæœ¬çš„äººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 3 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.25241v1",
      "published_date": "2025-10-29 07:48:10 UTC",
      "updated_date": "2025-10-29 07:48:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:28:10.558215+00:00"
    },
    {
      "arxiv_id": "2510.25234v1",
      "title": "Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D Talking Face Animation",
      "title_zh": "é¢å‘ 3D è¯´è¯äººè„¸åŠ¨ç”»çš„è¯­éŸ³ä¸è¡¨æƒ…é©±åŠ¨è§£è€¦æ··åˆå˜å½¢å­¦ä¹ ",
      "authors": [
        "Yuxiang Mao",
        "Zhijie Zhang",
        "Zhiheng Zhang",
        "Jiawei Liu",
        "Chen Zeng",
        "Shihong Xia"
      ],
      "abstract": "Expressions are fundamental to conveying human emotions. With the rapid advancement of AI-generated content (AIGC), realistic and expressive 3D facial animation has become increasingly crucial. Despite recent progress in speech-driven lip-sync for talking-face animation, generating emotionally expressive talking faces remains underexplored. A major obstacle is the scarcity of real emotional 3D talking-face datasets due to the high cost of data capture. To address this, we model facial animation driven by both speech and emotion as a linear additive problem. Leveraging a 3D talking-face dataset with neutral expressions (VOCAset) and a dataset of 3D expression sequences (Florence4D), we jointly learn a set of blendshapes driven by speech and emotion. We introduce a sparsity constraint loss to encourage disentanglement between the two types of blendshapes while allowing the model to capture inherent secondary cross-domain deformations present in the training data. The learned blendshapes can be further mapped to the expression and jaw pose parameters of the FLAME model, enabling the animation of 3D Gaussian avatars. Qualitative and quantitative experiments demonstrate that our method naturally generates talking faces with specified expressions while maintaining accurate lip synchronization. Perceptual studies further show that our approach achieves superior emotional expressivity compared to existing methods, without compromising lip-sync quality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ AIGC é¢†åŸŸä¸­ 3D è¯´è¯äººè„¸åŠ¨ç”»åœ¨æƒ…æ„Ÿè¡¨è¾¾æ–¹é¢çš„ä¸è¶³ï¼Œæ—¨åœ¨è§£å†³é«˜è´¨é‡æƒ…æ„Ÿæ•°æ®é›†ç¨€ç¼ºå¯¼è‡´çš„çœŸå®æ„Ÿæ¬ ç¼ºé—®é¢˜ã€‚ç ”ç©¶äººå‘˜å°†è¯­éŸ³å’Œæƒ…æ„Ÿé©±åŠ¨çš„è„¸éƒ¨åŠ¨ç”»å»ºæ¨¡ä¸ºä¸€ä¸ªçº¿æ€§åŠ æ³•é—®é¢˜ï¼Œåˆ©ç”¨ VOCAset å’Œ Florence4D æ•°æ®é›†å…±åŒå­¦ä¹ ç”±è¯­éŸ³å’Œè¡¨æƒ…é©±åŠ¨çš„ Blendshapesã€‚é€šè¿‡å¼•å…¥ç¨€ç–çº¦æŸæŸå¤±(Sparsity Constraint Loss)ï¼Œè¯¥æ–¹æ³•å®ç°äº†è¯­éŸ³ä¸æƒ…æ„Ÿç‰¹å¾çš„æœ‰æ•ˆè§£è€¦ï¼Œå¹¶èƒ½æ•æ‰ç»†å¾®çš„è·¨åŸŸå˜å½¢ã€‚å­¦ä¹ åˆ°çš„ç‰¹å¾å¯è¿›ä¸€æ­¥æ˜ å°„è‡³ FLAME æ¨¡å‹çš„å‚æ•°ä¸­ï¼Œç”¨äºé©±åŠ¨ 3D Gaussian Avatarsã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç²¾ç¡® Lip-sync çš„åŒæ—¶ï¼Œèƒ½è‡ªç„¶ç”Ÿæˆå…·æœ‰æŒ‡å®šè¡¨æƒ…çš„è¯´è¯äººè„¸ã€‚æ„ŸçŸ¥ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œè¯¥æ–¹æ³•åœ¨ä¸æŸå®³å£å‹åŒæ­¥è´¨é‡çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†åŠ¨ç”»çš„æƒ…æ„Ÿè¡¨ç°åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 6 figures, accepted to ICXR 2025 conference",
      "pdf_url": "https://arxiv.org/pdf/2510.25234v1",
      "published_date": "2025-10-29 07:29:21 UTC",
      "updated_date": "2025-10-29 07:29:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:28:12.369233+00:00"
    },
    {
      "arxiv_id": "2510.25232v1",
      "title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity",
      "title_zh": "ä»ç—…å†åˆ°è¯Šæ–­å¯¹è¯ï¼šä¸€ç§åŸºäºä¸´åºŠçš„ç²¾ç¥ç–¾ç—…å…±ç—…è¯Šæ–­æ–¹æ³•åŠæ•°æ®é›†",
      "authors": [
        "Tianxi Wan",
        "Jiaming Luo",
        "Siyuan Chen",
        "Kunyao Lan",
        "Jianhua Chen",
        "Haiyang Geng",
        "Mengyue Wu"
      ],
      "abstract": "Psychiatric comorbidity is clinically significant yet challenging due to the complexity of multiple co-occurring disorders. To address this, we develop a novel approach integrating synthetic patient electronic medical record (EMR) construction and multi-agent diagnostic dialogue generation. We create 502 synthetic EMRs for common comorbid conditions using a pipeline that ensures clinical relevance and diversity. Our multi-agent framework transfers the clinical interview protocol into a hierarchical state machine and context tree, supporting over 130 diagnostic states while maintaining clinical standards. Through this rigorous process, we construct PsyCoTalk, the first large-scale dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy and treatment planning, offering a valuable resource for psychiatric comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk exhibits high structural and linguistic fidelity in terms of dialogue length, token distribution, and diagnostic reasoning strategies. Licensed psychiatrists confirm the realism and diagnostic validity of the dialogues. This dataset enables the development and evaluation of models capable of multi-disorder psychiatric screening in a single conversational pass.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸´åºŠä¸Šæå…·æŒ‘æˆ˜æ€§çš„ç²¾ç¥å…±ç—…ï¼ˆPsychiatric comorbidityï¼‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ•´åˆåˆæˆç”µå­ç—…å†ï¼ˆEMRï¼‰æ„å»ºä¸å¤šæ™ºèƒ½ä½“è¯Šæ–­å¯¹è¯ç”Ÿæˆçš„åˆ›æ–°æ–¹æ³•ã€‚é€šè¿‡æ¨¡æ‹Ÿä¸´åºŠè®¿è°ˆåè®®å¹¶å°†å…¶è½¬åŒ–ä¸ºåˆ†å±‚çŠ¶æ€æœºï¼ˆhierarchical state machineï¼‰ä¸ä¸Šä¸‹æ–‡æ ‘ï¼ˆcontext treeï¼‰ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ”¯æŒè¶…è¿‡130ç§è¯Šæ–­çŠ¶æ€å¹¶ä¸¥æ ¼ç»´æŒä¸´åºŠæ ‡å‡†ã€‚ç ”ç©¶ç”±æ­¤æ„å»ºäº†é¦–ä¸ªæ”¯æŒå…±ç—…çš„å¤§è§„æ¨¡å¯¹è¯æ•°æ®é›† PsyCoTalkï¼ŒåŒ…å«3,000ä¸ªç»è¿‡ç²¾ç¥ç§‘åŒ»ç”ŸéªŒè¯çš„å¤šè½®è¯Šæ–­å¯¹è¯ã€‚éªŒè¯ç»“æœæ˜¾ç¤ºï¼ŒPsyCoTalk åœ¨å¯¹è¯ç»“æ„ã€è¯­è¨€ç‰¹å¾åŠè¯Šæ–­æ¨ç†ç­–ç•¥ä¸Šä¸çœŸå®ä¸´åºŠè®°å½•å…·æœ‰é«˜åº¦ä¿çœŸåº¦ï¼Œå¹¶è·å¾—äº†æ‰§ä¸šç²¾ç¥ç§‘åŒ»ç”Ÿçš„çœŸå®æ€§ç¡®è®¤ã€‚è¯¥æ•°æ®é›†ä¸ºå¼€å‘å’Œè¯„ä¼°èƒ½å¤Ÿåœ¨å•æ¬¡å¯¹è¯ä¸­å®Œæˆå¤šé‡ç²¾ç¥éšœç¢ç­›æŸ¥çš„æ¨¡å‹æä¾›äº†å…³é”®èµ„æºï¼Œæ˜¾è‘—å¢å¼ºäº†è¯Šæ–­å‡†ç¡®æ€§ä¸æ²»ç–—è§„åˆ’èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25232v1",
      "published_date": "2025-10-29 07:18:43 UTC",
      "updated_date": "2025-10-29 07:18:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:04.095843+00:00"
    },
    {
      "arxiv_id": "2511.02851v1",
      "title": "Approaching Low-Cost Cardiac Intelligence with Semi-Supervised Knowledge Distillation",
      "title_zh": "åŸºäºåŠç›‘ç£çŸ¥è¯†è’¸é¦å®ç°ä½æˆæœ¬å¿ƒè„æ™ºèƒ½",
      "authors": [
        "Rushuang Zhou",
        "Yuan-Ting Zhang",
        "M. Jamal Deen",
        "Yining Dong"
      ],
      "abstract": "Deploying advanced cardiac artificial intelligence for daily cardiac monitoring is hindered by its reliance on extensive medical data and high computational resources. Low-cost cardiac intelligence (LCCI) offers a promising alternative by using wearable device data, such as 1-lead electrocardiogram (ECG), but it suffers from a significant diagnostic performance gap compared to high-cost cardiac intelligence (HCCI). To bridge this gap, we propose LiteHeart, a semi-supervised knowledge distillation framework. LiteHeart introduces a region-aware distillation module to mimic how cardiologists focus on diagnostically relevant ECG regions and a cross-layer mutual information module to align the decision processes of LCCI and HCCI systems. Using a semi-supervised training strategy, LiteHeart further improves model robustness under limited supervision. Evaluated on five datasets covering over 38 cardiovascular diseases, LiteHeart substantially reduces the performance gap between LCCI and HCCI, outperforming existing methods by 4.27% to 7.10% in macro F1 score. These results demonstrate that LiteHeart significantly enhances the diagnostic capabilities of low-cost cardiac intelligence systems, paving the way for scalable, affordable, and accurate daily cardiac healthcare using wearable technologies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LiteHeartæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åŠç›‘ç£çŸ¥è¯†è’¸é¦(Semi-Supervised Knowledge Distillation)æŠ€æœ¯ç¼©å°ä½æˆæœ¬å¿ƒè„æ™ºèƒ½(LCCI)ä¸é«˜æˆæœ¬å¿ƒè„æ™ºèƒ½(HCCI)ä¹‹é—´çš„è¯Šæ–­æ€§èƒ½å·®è·ã€‚LiteHeartå¼•å…¥äº†åŒºåŸŸæ„ŸçŸ¥è’¸é¦æ¨¡å—(Region-aware distillation module)ä»¥æ¨¡æ‹Ÿä¸“å®¶å¯¹å¿ƒç”µå›¾(ECG)å…³é”®åŒºåŸŸçš„å…³æ³¨ï¼Œå¹¶ç»“åˆè·¨å±‚äº’ä¿¡æ¯æ¨¡å—(Cross-layer mutual information module)æ¥å¯¹é½ä¸¤ç±»ç³»ç»Ÿçš„å†³ç­–é€»è¾‘ã€‚é€šè¿‡åº”ç”¨åŠç›‘ç£è®­ç»ƒç­–ç•¥ï¼Œè¯¥æ¡†æ¶åœ¨ç›‘ç£æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„é²æ£’æ€§ã€‚åœ¨æ¶‰åŠ38ç§å¿ƒè¡€ç®¡ç–¾ç—…çš„äº”ä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒLiteHeartåœ¨å®F1åˆ†æ•°(macro F1 score)ä¸Šä¼˜äºç°æœ‰æ–¹æ³•4.27%è‡³7.10%ã€‚è¿™é¡¹æˆæœè¯æ˜äº†LiteHeartèƒ½å¤Ÿæ˜¾è‘—æå‡åŸºäºå¯ç©¿æˆ´è®¾å¤‡çš„ä½æˆæœ¬è¯Šæ–­èƒ½åŠ›ï¼Œä¸ºå®ç°æ™®åŠåŒ–ã€å¯è´Ÿæ‹…ä¸”ç²¾å‡†çš„æ—¥å¸¸å¿ƒè„å¥åº·ç®¡ç†å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.02851v1",
      "published_date": "2025-10-29 07:18:17 UTC",
      "updated_date": "2025-10-29 07:18:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:04.262747+00:00"
    },
    {
      "arxiv_id": "2510.25228v2",
      "title": "'Studies for': A Human-AI Co-Creative Sound Artwork Using a Real-time Multi-channel Sound Generation Model",
      "title_zh": "Studies forï¼šåŸºäºå®æ—¶å¤šå£°é“å£°éŸ³ç”Ÿæˆæ¨¡å‹çš„äººæœºå…±åˆ›å£°éŸ³è‰ºæœ¯ä½œå“",
      "authors": [
        "Chihiro Nagashima",
        "Akira Takahashi",
        "Zhi Zhong",
        "Shusuke Takahashi",
        "Yuki Mitsufuji"
      ],
      "abstract": "This paper explores the integration of AI technologies into the artistic workflow through the creation of Studies for, a generative sound installation developed in collaboration with sound artist Evala (https://www.ntticc.or.jp/en/archive/works/studies-for/). The installation employs SpecMaskGIT, a lightweight yet high-quality sound generation AI model, to generate and playback eight-channel sound in real-time, creating an immersive auditory experience over the course of a three-month exhibition. The work is grounded in the concept of a \"new form of archive,\" which aims to preserve the artistic style of an artist while expanding beyond artists' past artworks by continued generation of new sound elements. This speculative approach to archival preservation is facilitated by training the AI model on a dataset consisting of over 200 hours of Evala's past sound artworks.\n  By addressing key requirements in the co-creation of art using AI, this study highlights the value of the following aspects: (1) the necessity of integrating artist feedback, (2) datasets derived from an artist's past works, and (3) ensuring the inclusion of unexpected, novel outputs. In Studies for, the model was designed to reflect the artist's artistic identity while generating new, previously unheard sounds, making it a fitting realization of the concept of \"a new form of archive.\" We propose a Human-AI co-creation framework for effectively incorporating sound generation AI models into the sound art creation process and suggest new possibilities for creating and archiving sound art that extend an artist's work beyond their physical existence. Demo page: https://sony.github.io/studies-for/",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å°†äººå·¥æ™ºèƒ½æŠ€æœ¯èå…¥è‰ºæœ¯åˆ›ä½œå·¥ä½œæµçš„æ–¹æ³•ï¼Œå¹¶å±•ç¤ºäº†ä¸å£°éŸ³è‰ºæœ¯å®¶ Evala åˆä½œå¼€å‘çš„ç”Ÿæˆå¼å£°éŸ³è£…ç½®ä½œå“ Studies forã€‚è¯¥è£…ç½®é‡‡ç”¨äº†åä¸º SpecMaskGIT çš„è½»é‡åŒ–é«˜è´¨é‡å£°éŸ³ç”Ÿæˆæ¨¡å‹ï¼Œå®ç°äº†å…«é€šé“å£°éŸ³çš„å®æ—¶ç”Ÿæˆä¸æ’­æ”¾ï¼Œè¥é€ å‡ºæ²‰æµ¸å¼çš„å¬è§‰ä½“éªŒã€‚ä½œå“æ ¸å¿ƒåœ¨äºæå‡ºäº†â€œæ–°å½¢å¼æ¡£æ¡ˆ (new form of archive)â€çš„æ¦‚å¿µï¼Œé€šè¿‡å¯¹è‰ºæœ¯å®¶è¿‡å»è¶…è¿‡ 200 å°æ—¶çš„ä½œå“ç´ æè¿›è¡Œè®­ç»ƒï¼Œåœ¨å»¶ç»­å…¶ä¸ªäººé£æ ¼çš„åŒæ—¶ä¸æ–­ç”Ÿæˆå…¨æ–°çš„å£°éŸ³å…ƒç´ ã€‚ç ”ç©¶æ€»ç»“äº†äººæœºååŒåˆ›ä½œ (Human-AI co-creation) çš„å…³é”®è¦ç´ ï¼ŒåŒ…æ‹¬æ•´åˆè‰ºæœ¯å®¶åé¦ˆã€åˆ©ç”¨ç‰¹å®šä½œå“æ•°æ®é›†ä»¥åŠè§¦å‘æ„æ–™ä¹‹å¤–çš„åˆ›æ–°è¾“å‡ºã€‚è¯¥å·¥ä½œä¸ºå°†å£°éŸ³ç”Ÿæˆ AI æœ‰æ•ˆæ•´åˆè‡³è‰ºæœ¯åˆ›ä½œæµç¨‹æä¾›äº†æ¡†æ¶å‚è€ƒï¼Œå¹¶å±•ç¤ºäº†å£°éŸ³è‰ºæœ¯åœ¨è¶…è¶Šè‰ºæœ¯å®¶ç‰©ç†å­˜åœ¨é™åˆ¶ä¸‹è¿›è¡Œåˆ›ä½œä¸å­˜æ¡£çš„æ–°å¯èƒ½æ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at NeurIPS Creative AI Track 2025, 9 pages, 6 figures, 1 table, Demo page: https://sony.github.io/studies-for/",
      "pdf_url": "https://arxiv.org/pdf/2510.25228v2",
      "published_date": "2025-10-29 07:05:59 UTC",
      "updated_date": "2025-10-31 05:08:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:07.658372+00:00"
    },
    {
      "arxiv_id": "2510.25226v1",
      "title": "Cost-Sensitive Unbiased Risk Estimation for Multi-Class Positive-Unlabeled Learning",
      "title_zh": "å¤šåˆ†ç±»æ­£æ ·æœ¬-æ— æ ‡ç­¾å­¦ä¹ çš„ä»£ä»·æ•æ„Ÿæ— åé£é™©ä¼°è®¡",
      "authors": [
        "Miao Zhang",
        "Junpeng Li",
        "Changchun Hua",
        "Yana Yang"
      ],
      "abstract": "Positive--Unlabeled (PU) learning considers settings in which only positive and unlabeled data are available, while negatives are missing or left unlabeled. This situation is common in real applications where annotating reliable negatives is difficult or costly. Despite substantial progress in PU learning, the multi-class case (MPU) remains challenging: many existing approaches do not ensure \\emph{unbiased risk estimation}, which limits performance and stability. We propose a cost-sensitive multi-class PU method based on \\emph{adaptive loss weighting}. Within the empirical risk minimization framework, we assign distinct, data-dependent weights to the positive and \\emph{inferred-negative} (from the unlabeled mixture) loss components so that the resulting empirical objective is an unbiased estimator of the target risk. We formalize the MPU data-generating process and establish a generalization error bound for the proposed estimator. Extensive experiments on \\textbf{eight} public datasets, spanning varying class priors and numbers of classes, show consistent gains over strong baselines in both accuracy and stability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šåˆ†ç±»æ­£ç±»å’Œæ— æ ‡ç­¾å­¦ä¹ (Multi-Class Positive-Unlabeled Learning, MPU)ä¸­ç”±äºç¼ºä¹æ— åé£é™©ä¼°è®¡è€Œå¯¼è‡´çš„æ€§èƒ½ä¸ç¨³å®šæ€§å—é™é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè‡ªé€‚åº”æŸå¤±åŠ æƒ(adaptive loss weighting)çš„ä»£ä»·æ•æ„Ÿå‹MPUæ–¹æ³•ã€‚é€šè¿‡åœ¨ç»éªŒé£é™©æœ€å°åŒ–(empirical risk minimization)æ¡†æ¶ä¸‹ä¸ºæ­£ç±»å’Œä»æ— æ ‡ç­¾æ··åˆæ•°æ®ä¸­æ¨æ–­çš„è´Ÿç±»æŸå¤±é¡¹åˆ†é…ç‰¹å®šçš„æ•°æ®ä¾èµ–æƒé‡ï¼Œè¯¥æ–¹æ³•ç¡®ä¿äº†ç»éªŒç›®æ ‡å‡½æ•°æ˜¯ç›®æ ‡é£é™©çš„æ— åä¼°è®¡é‡(unbiased estimator)ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å½¢å¼åŒ–äº†MPUçš„æ•°æ®ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶ä¸ºæ‰€æä¼°è®¡é‡å»ºç«‹äº†æ³›åŒ–è¯¯å·®ç•Œ(generalization error bound)ã€‚åœ¨æ¶‰åŠä¸åŒç±»åˆ«å…ˆéªŒå’Œç±»æ•°ç›®çš„8ä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆ†ç±»å‡†ç¡®ç‡å’Œç®—æ³•ç¨³å®šæ€§ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å¼ºåŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25226v1",
      "published_date": "2025-10-29 07:01:32 UTC",
      "updated_date": "2025-10-29 07:01:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:15.768190+00:00"
    },
    {
      "arxiv_id": "2510.25223v2",
      "title": "FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data",
      "title_zh": "FELAï¼šé¢å‘å·¥ä¸šäº‹ä»¶æ—¥å¿—æ•°æ®ç‰¹å¾å·¥ç¨‹çš„å¤šæ™ºèƒ½ä½“æ¼”åŒ–ç³»ç»Ÿ",
      "authors": [
        "Kun Ouyang",
        "Haoyu Wang",
        "Dong Fang"
      ],
      "abstract": "Event log data, recording fine-grained user actions and system events, represent one of the most valuable assets for modern digital services. However, the complexity and heterogeneity of industrial event logs--characterized by large scale, high dimensionality, diverse data types, and intricate temporal or relational structures--make feature engineering extremely challenging. Existing automatic feature engineering approaches, such as AutoML or genetic methods, often suffer from limited explainability, rigid predefined operations, and poor adaptability to complicated heterogeneous data. In this paper, we propose FELA (Feature Engineering LLM Agents), a multi-agent evolutionary system that autonomously extracts meaningful and high-performing features from complex industrial event log data. FELA integrates the reasoning and coding capabilities of large language models (LLMs) with an insight-guided self-evolution paradigm. Specifically, FELA employs specialized agents--Idea Agents, Code Agents, and Critic Agents--to collaboratively generate, validate, and implement novel feature ideas. An Evaluation Agent summarizes feedback and updates a hierarchical knowledge base and dual-memory system to enable continual improvement. Moreover, FELA introduces an agentic evolution algorithm, combining reinforcement learning and genetic algorithm principles to balance exploration and exploitation across the idea space. Extensive experiments on real industrial datasets demonstrate that FELA can generate explainable, domain-relevant features that significantly improve model performance while reducing manual effort. Our results highlight the potential of LLM-based multi-agent systems as a general framework for automated, interpretable, and adaptive feature engineering in complex real-world environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FELA (Feature Engineering LLM Agents)ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å·¥ä¸šäº‹ä»¶æ—¥å¿—æ•°æ®çš„å¤šæ™ºèƒ½ä½“æ¼”åŒ–ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿ AutoML å’Œé—ä¼ ç®—æ³•åœ¨å¤„ç†å¤§è§„æ¨¡å¼‚æ„æ•°æ®æ—¶é¢ä¸´çš„è§£é‡Šæ€§ä¸è¶³åŠçµæ´»æ€§å·®ç­‰æŒ‘æˆ˜ã€‚FELA å……åˆ†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„æ¨ç†ä¸ç¼–ç èƒ½åŠ›ï¼Œé€šè¿‡ Idea Agentsã€Code Agents å’Œ Critic Agents çš„ååŒå·¥ä½œæ¥è‡ªåŠ¨æå–é«˜æ€§èƒ½ç‰¹å¾ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨äº†ä¸€ç§åŸºäºæ´å¯Ÿå¼•å¯¼çš„è‡ªæˆ‘æ¼”åŒ–èŒƒå¼ï¼Œç»“åˆåˆ†å±‚çŸ¥è¯†åº“ä¸åŒé‡è®°å¿†ç³»ç»Ÿå®ç°æŒç»­å­¦ä¹ ï¼Œå¹¶å¼•å…¥èåˆå¼ºåŒ–å­¦ä¹  (Reinforcement Learning) ä¸é—ä¼ ç®—æ³• (Genetic Algorithm) çš„æ™ºèƒ½ä½“æ¼”åŒ–ç®—æ³•æ¥ä¼˜åŒ–ç‰¹å¾æœç´¢ç©ºé—´ã€‚å®éªŒè¯æ˜ï¼ŒFELA åœ¨çœŸå®å·¥ä¸šæ•°æ®é›†ä¸Šèƒ½å¤Ÿç”Ÿæˆå…·æœ‰é«˜åº¦å¯è§£é‡Šæ€§çš„é¢†åŸŸç‰¹å¾ï¼Œåœ¨æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½çš„åŒæ—¶å¤§å¹…å‡å°‘äº†äººå·¥æˆæœ¬ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåŸºäº LLM çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ä¸ºå¤æ‚ç°å®åœºæ™¯ä¸‹çš„è‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”è‡ªé€‚åº”çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25223v2",
      "published_date": "2025-10-29 06:57:32 UTC",
      "updated_date": "2025-11-04 15:40:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:14.871147+00:00"
    },
    {
      "arxiv_id": "2510.25220v1",
      "title": "GReF: A Unified Generative Framework for Efficient Reranking via Ordered Multi-token Prediction",
      "title_zh": "GReFï¼šåŸºäºæœ‰åºå¤š Token é¢„æµ‹çš„é«˜æ•ˆé‡æ’åºç»Ÿä¸€ç”Ÿæˆå¼æ¡†æ¶",
      "authors": [
        "Zhijie Lin",
        "Zhuofeng Li",
        "Chenglei Dai",
        "Wentian Bao",
        "Shuai Lin",
        "Enyun Yu",
        "Haoxiang Zhang",
        "Liang Zhao"
      ],
      "abstract": "In a multi-stage recommendation system, reranking plays a crucial role in modeling intra-list correlations among items. A key challenge lies in exploring optimal sequences within the combinatorial space of permutations. Recent research follows a two-stage (generator-evaluator) paradigm, where a generator produces multiple feasible sequences, and an evaluator selects the best one. In practice, the generator is typically implemented as an autoregressive model. However, these two-stage methods face two main challenges. First, the separation of the generator and evaluator hinders end-to-end training. Second, autoregressive generators suffer from inference efficiency. In this work, we propose a Unified Generative Efficient Reranking Framework (GReF) to address the two primary challenges. Specifically, we introduce Gen-Reranker, an autoregressive generator featuring a bidirectional encoder and a dynamic autoregressive decoder to generate causal reranking sequences. Subsequently, we pre-train Gen-Reranker on the item exposure order for high-quality parameter initialization. To eliminate the need for the evaluator while integrating sequence-level evaluation during training for end-to-end optimization, we propose post-training the model through Rerank-DPO. Moreover, for efficient autoregressive inference, we introduce ordered multi-token prediction (OMTP), which trains Gen-Reranker to simultaneously generate multiple future items while preserving their order, ensuring practical deployment in real-time recommender systems. Extensive offline experiments demonstrate that GReF outperforms state-of-the-art reranking methods while achieving latency that is nearly comparable to non-autoregressive models. Additionally, GReF has also been deployed in a real-world video app Kuaishou with over 300 million daily active users, significantly improving online recommendation quality.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GReFï¼Œä¸€ç§ç”¨äºé«˜æ•ˆé‡æ’åºçš„ç»Ÿä¸€ç”Ÿæˆå¼æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ¨èç³»ç»Ÿä¸­é‡æ’åºé˜¶æ®µå­˜åœ¨çš„ç”Ÿæˆå™¨ä¸è¯„ä¼°å™¨è®­ç»ƒå¤±é…åŠè‡ªå›å½’æ¨ç†æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†Gen-Rerankerï¼Œåˆ©ç”¨åŒå‘ç¼–ç å™¨(bidirectional encoder)å’ŒåŠ¨æ€è‡ªå›å½’è§£ç å™¨(dynamic autoregressive decoder)ç”Ÿæˆå› æœé‡æ’åºåºåˆ—ï¼Œå¹¶é€šè¿‡é¢„è®­ç»ƒç‰©å“æ›å…‰é¡ºåºè¿›è¡Œåˆå§‹åŒ–ã€‚ä¸ºäº†å®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–å¹¶å–ä»£ä¼ ç»Ÿçš„ä¸¤é˜¶æ®µè¯„ä¼°æ¨¡å¼ï¼Œç ”ç©¶é‡‡ç”¨äº†Rerank-DPOæŠ€æœ¯è¿›è¡ŒåæœŸè®­ç»ƒï¼ŒåŒæ—¶æå‡ºäº†æœ‰åºå¤šTokené¢„æµ‹(Ordered Multi-token Prediction, OMTP)æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½åŒæ­¥ç”Ÿæˆå¤šä¸ªæœªæ¥ç‰©å“å¹¶ä¿æŒå…¶é¡ºåºï¼Œä»è€Œå°†æ¨ç†å»¶è¿Ÿé™è‡³æ¥è¿‘éè‡ªå›å½’æ¨¡å‹çš„æ°´å¹³ã€‚å®éªŒè¯æ˜GReFåœ¨ç¦»çº¿æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰å…ˆè¿›æ–¹æ³•ï¼Œå¹¶å·²æˆåŠŸéƒ¨ç½²äºæ‹¥æœ‰è¶…è¿‡3äº¿æ—¥æ´»è·ƒç”¨æˆ·çš„å¿«æ‰‹(Kuaishou)APPï¼Œåœ¨çœŸå®çš„å¤§è§„æ¨¡å®æ—¶æ¨èåœºæ™¯ä¸­æ˜¾è‘—æå‡äº†ä¸šåŠ¡æŒ‡æ ‡ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by CIKM 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.25220v1",
      "published_date": "2025-10-29 06:54:42 UTC",
      "updated_date": "2025-10-29 06:54:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:17.950598+00:00"
    },
    {
      "arxiv_id": "2510.25218v1",
      "title": "Human Resilience in the AI Era -- What Machines Can't Replace",
      "title_zh": "AI æ—¶ä»£çš„äººç±»éŸ§æ€§ï¼šæœºå™¨æ— æ³•å–ä»£çš„ç‰¹è´¨",
      "authors": [
        "Shaoshan Liu",
        "Anina Schwarzenbach",
        "Yiyu Shi"
      ],
      "abstract": "AI is displacing tasks, mediating high-stakes decisions, and flooding communication with synthetic content, unsettling work, identity, and social trust. We argue that the decisive human countermeasure is resilience. We define resilience across three layers: psychological, including emotion regulation, meaning-making, cognitive flexibility; social, including trust, social capital, coordinated response; organizational, including psychological safety, feedback mechanisms, and graceful degradation. We synthesize early evidence that these capacities buffer individual strain, reduce burnout through social support, and lower silent failure in AI-mediated workflows through team norms and risk-responsive governance. We also show that resilience can be cultivated through training that complements rather than substitutes for structural safeguards. By reframing the AI debate around actionable human resilience, this article offers policymakers, educators, and operators a practical lens to preserve human agency and steer responsible adoption.",
      "tldr_zh": "åœ¨AIå–ä»£ä»»åŠ¡ã€å¹²é¢„é‡å¤§å†³ç­–å¹¶é‡å¡‘ç¤¾ä¼šä¿¡ä»»çš„èƒŒæ™¯ä¸‹ï¼Œè¯¥ç ”ç©¶æŒ‡å‡ºäººç±»åº”å¯¹AIæŒ‘æˆ˜çš„æ ¸å¿ƒååˆ¶æªæ–½æ˜¯Resilienceï¼ˆéŸ§æ€§ï¼‰ã€‚ä½œè€…ä»ä¸‰ä¸ªç»´åº¦å®šä¹‰äº†Resilienceï¼šåŒ…æ‹¬æƒ…ç»ªè°ƒèŠ‚ã€æ„ä¹‰æ„å»ºå’Œè®¤çŸ¥çµæ´»æ€§çš„Psychologicalï¼ˆå¿ƒç†ï¼‰å±‚é¢ï¼Œæ¶µç›–ä¿¡ä»»ã€ç¤¾ä¼šèµ„æœ¬ä¸åè°ƒååº”çš„Socialï¼ˆç¤¾ä¼šï¼‰å±‚é¢ï¼Œä»¥åŠåŒ…å«å¿ƒç†å®‰å…¨æ„Ÿã€åé¦ˆæœºåˆ¶ä¸Graceful degradationï¼ˆä¼˜é›…é™çº§ï¼‰çš„Organizationalï¼ˆç»„ç»‡ï¼‰å±‚é¢ã€‚è®ºæ–‡ç»¼åˆåˆæ­¥è¯æ®è¡¨æ˜ï¼Œè¿™äº›èƒ½åŠ›å¯ä»¥ç¼“è§£ä¸ªä½“å‹åŠ›ï¼Œé€šè¿‡ç¤¾ä¼šæ”¯æŒå‡å°‘Burnoutï¼ˆèŒä¸šå€¦æ€ ï¼‰ï¼Œå¹¶åˆ©ç”¨å›¢é˜Ÿè§„èŒƒä¸é£é™©å“åº”æ²»ç†é™ä½AIä»‹å¯¼å·¥ä½œæµä¸­çš„Silent failureï¼ˆéšæ€§å¤±è´¥ï¼‰ã€‚ç ”ç©¶è¿˜å¼ºè°ƒResilienceå¯ä»¥é€šè¿‡åŸ¹è®­è¿›è¡ŒåŸ¹å…»ï¼Œä½œä¸ºç»“æ„æ€§ä¿éšœæªæ–½çš„è¡¥å……è€Œéæ›¿ä»£ã€‚é€šè¿‡å°†AIè¾©è®ºé‡æ–°èšç„¦äºå¯è¡ŒåŠ¨çš„Resilienceï¼Œæœ¬æ–‡ä¸ºå†³ç­–è€…ã€æ•™è‚²è€…å’Œç®¡ç†è€…æä¾›äº†ä¿ç•™Human agencyï¼ˆäººç±»ä¸»ä½“æ€§ï¼‰å¹¶å¼•å¯¼è´Ÿè´£ä»»åœ°é‡‡ç”¨AIçš„å®è·µè§†è§’ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25218v1",
      "published_date": "2025-10-29 06:48:19 UTC",
      "updated_date": "2025-10-29 06:48:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:24.461424+00:00"
    },
    {
      "arxiv_id": "2510.25206v1",
      "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models",
      "title_zh": "RAVRï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„å‚è€ƒç­”æ¡ˆå¼•å¯¼å¼å˜åˆ†æ¨ç†",
      "authors": [
        "Tianqianjin Lin",
        "Xi Zhao",
        "Xingyao Zhang",
        "Rujiao Long",
        "Yi Xu",
        "Zhuoren Jiang",
        "Wenbo Su",
        "Bo Zheng"
      ],
      "abstract": "Reinforcement learning (RL) can refine the reasoning abilities of large language models (LLMs), but critically depends on a key prerequisite: the LLM can already generate high-utility reasoning paths with non-negligible probability. For tasks beyond the LLM's current competence, such reasoning path can be hard to sample, and learning risks reinforcing familiar but suboptimal reasoning. We are motivated by the insight from cognitive science that Why is this the answer is often an easier question than What is the answer, as it avoids the heavy cognitive load of open-ended exploration, opting instead for explanatory reconstruction-systematically retracing the reasoning that links a question to its answer. We show that LLMs can similarly leverage answers to derive high-quality reasoning paths. We formalize this phenomenon and prove that conditioning on answer provably increases the expected utility of sampled reasoning paths, thereby transforming intractable problems into learnable ones. Building on this insight, we introduce RAVR (Reference-Answer-guided Variational Reasoning), an end-to-end framework that uses answer-conditioned reasoning as a variational surrogate for question-only reasoning. Experiments in both general and math domains demonstrate consistent improvements over strong baselines. We further analyze the reasoning behavior and find that RAVR reduces hesitation, strengthens conclusion consolidation, and promotes problem-specific strategies in reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (RL)ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†èƒ½åŠ›æ—¶é«˜è´¨é‡è·¯å¾„é‡‡æ ·å›°éš¾çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†RAVR (Reference-Answer-guided Variational Reasoning)æ¡†æ¶ã€‚å—è®¤çŸ¥ç§‘å­¦ä¸­â€œè§£é‡Šæ€§é‡å»ºæ¯”å¼€æ”¾å¼æ¢ç´¢æ›´ç®€å•â€çš„å¯å‘ï¼Œè¯¥ç ”ç©¶ä»ç†è®ºä¸Šè¯æ˜äº†åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¼•å…¥å‚è€ƒç­”æ¡ˆä½œä¸ºæ¡ä»¶èƒ½æ˜¾è‘—æå‡é‡‡æ ·è·¯å¾„çš„æœŸæœ›æ•ˆç”¨ã€‚RAVR ä½œä¸ºä¸€ä¸ªç«¯åˆ°ç«¯æ¡†æ¶ï¼Œå°†åŸºäºç­”æ¡ˆå¼•å¯¼çš„æ¨ç†è§†ä¸ºä»…åŸºäºé—®é¢˜æ¨ç†çš„å˜åˆ†ä»£ç†(variational surrogate)ï¼Œä»è€Œä½¿åŸæœ¬éš¾ä»¥å¤„ç†çš„å¤æ‚æ¨ç†ä»»åŠ¡å˜å¾—å¯å­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é€šç”¨å’Œæ•°å­¦é¢†åŸŸå‡ä¼˜äºå¼ºåŸºçº¿æ¨¡å‹ï¼Œå¹¶èƒ½æ˜¾è‘—å‡å°‘æ¨¡å‹çš„æ¨ç†çŠ¹è±«ï¼Œå¼ºåŒ–ç»“è®ºå·©å›ºå¹¶ä¿ƒè¿›ç‰¹å®šé—®é¢˜è§£å†³ç­–ç•¥çš„å½¢æˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25206v1",
      "published_date": "2025-10-29 06:18:37 UTC",
      "updated_date": "2025-10-29 06:18:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:25.258419+00:00"
    },
    {
      "arxiv_id": "2510.25205v1",
      "title": "Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision",
      "title_zh": "åŸºäºè‡ªé€‚åº”æ„ŸçŸ¥ä¸é²æ£’å†³ç­–çš„é«˜èƒ½æ•ˆè‡ªåŠ¨é©¾é©¶",
      "authors": [
        "Yuyang Xia",
        "Zibo Liang",
        "Liwei Deng",
        "Yan Zhao",
        "Han Su",
        "Kai Zheng"
      ],
      "abstract": "Autonomous driving is an emerging technology that is expected to bring significant social, economic, and environmental benefits. However, these benefits come with rising energy consumption by computation engines, limiting the driving range of vehicles, especially electric ones. Perception computing is typically the most power-intensive component, as it relies on largescale deep learning models to extract environmental features. Recently, numerous studies have employed model compression techniques, such as sparsification, quantization, and distillation, to reduce computational consumption. However, these methods often result in either a substantial model size or a significant drop in perception accuracy compared to high-computation models. To address these challenges, we propose an energy-efficient autonomous driving framework, called EneAD. In the adaptive perception module, a perception optimization strategy is designed from the perspective of data management and tuning. Firstly, we manage multiple perception models with different computational consumption and adjust the execution framerate dynamically. Then, we define them as knobs and design a transferable tuning method based on Bayesian optimization to identify promising knob values that achieve low computation while maintaining desired accuracy. To adaptively switch the knob values in various traffic scenarios, a lightweight classification model is proposed to distinguish the perception difficulty in different scenarios. In the robust decision module, we propose a decision model based on reinforcement learning and design a regularization term to enhance driving stability in the face of perturbed perception results. Extensive experiments evidence the superiority of our framework in both energy consumption and driving performance. EneAD can reduce perception consumption by 1.9x to 3.5x and thus improve driving range by 3.9% to 8.5%",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸ºEneADçš„é«˜èƒ½æ•ˆè‡ªåŠ¨é©¾é©¶æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå°¤å…¶æ˜¯æ„ŸçŸ¥è®¡ç®—éƒ¨åˆ†å› æ·±åº¦å­¦ä¹ æ¨¡å‹åºå¤§è€Œå¯¼è‡´ç”µåŠ¨æ±½è½¦ç»­èˆªé‡Œç¨‹å—é™çš„é—®é¢˜ã€‚åœ¨è‡ªé€‚åº”æ„ŸçŸ¥(Adaptive Perception)æ¨¡å—ä¸­ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç®¡ç†å¤šä¸ªä¸åŒåŠŸè€—çš„æ¨¡å‹å¹¶åŠ¨æ€è°ƒæ•´æ‰§è¡Œå¸§ç‡ï¼Œç»“åˆåŸºäºè´å¶æ–¯ä¼˜åŒ–(Bayesian Optimization)çš„è°ƒä¼˜æ–¹æ³•å’Œè½»é‡çº§åˆ†ç±»æ¨¡å‹ï¼Œå®ç°äº†æ ¹æ®åœºæ™¯éš¾åº¦è‡ªé€‚åº”è°ƒæ•´æ„ŸçŸ¥ç­–ç•¥ã€‚åœ¨é²æ£’å†³ç­–(Robust Decision)æ¨¡å—ï¼Œç ”ç©¶è€…åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)å¹¶è®¾è®¡æ­£åˆ™åŒ–é¡¹ï¼Œæå‡äº†åœ¨æ„ŸçŸ¥æ‰°åŠ¨ä¸‹çš„è¡Œé©¶ç¨³å®šæ€§ã€‚å®éªŒè¯æ˜ï¼ŒEneADèƒ½å°†æ„ŸçŸ¥èƒ½è€—é™ä½1.9å€è‡³3.5å€ï¼Œå¹¶ä½¿è¡Œé©¶é‡Œç¨‹æå‡3.9%è‡³8.5%ï¼Œåœ¨é™ä½åŠŸè€—çš„åŒæ—¶ä¿æŒäº†ä¼˜å¼‚çš„é©¾é©¶æ€§èƒ½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "It was accepted by ICDE2026",
      "pdf_url": "https://arxiv.org/pdf/2510.25205v1",
      "published_date": "2025-10-29 06:18:15 UTC",
      "updated_date": "2025-10-29 06:18:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:26.665118+00:00"
    },
    {
      "arxiv_id": "2511.00065v2",
      "title": "Aligning Brain Signals with Multimodal Speech and Vision Embeddings",
      "title_zh": "è„‘ä¿¡å·ä¸å¤šæ¨¡æ€è¯­éŸ³åŠè§†è§‰åµŒå…¥çš„å¯¹é½",
      "authors": [
        "Kateryna Shapovalenko",
        "Quentin Auster"
      ],
      "abstract": "When we hear the word \"house\", we don't just process sound, we imagine walls, doors, memories. The brain builds meaning through layers, moving from raw acoustics to rich, multimodal associations. Inspired by this, we build on recent work from Meta that aligned EEG signals with averaged wav2vec2 speech embeddings, and ask a deeper question: which layers of pre-trained models best reflect this layered processing in the brain? We compare embeddings from two models: wav2vec2, which encodes sound into language, and CLIP, which maps words to images. Using EEG recorded during natural speech perception, we evaluate how these embeddings align with brain activity using ridge regression and contrastive decoding. We test three strategies: individual layers, progressive concatenation, and progressive summation. The findings suggest that combining multimodal, layer-aware representations may bring us closer to decoding how the brain understands language, not just as sound, but as experience.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººè„‘åœ¨å¤„ç†è¯­è¨€æ—¶å¦‚ä½•è¶…è¶ŠåŸå§‹å£°å­¦ä¿¡æ¯å¹¶å½¢æˆä¸°å¯Œçš„å¤šæ¨¡æ€å…³è”ï¼Œæ—¨åœ¨è¯†åˆ«é¢„è®­ç»ƒæ¨¡å‹ä¸­å“ªäº›å±‚çº§æœ€èƒ½åæ˜ å¤§è„‘çš„åˆ†å±‚å¤„ç†æœºåˆ¶ã€‚ç ”ç©¶å¯¹æ¯”äº†å°†å£°éŸ³ç¼–ç ä¸ºè¯­è¨€çš„ wav2vec2 æ¨¡å‹ä¸å°†å•è¯æ˜ å°„åˆ°å›¾åƒçš„ CLIP æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨è‡ªç„¶è¨€è¯­æ„ŸçŸ¥è¿‡ç¨‹ä¸­çš„ EEG ä¿¡å·è¿›è¡Œå¯¹é½åˆ†æã€‚é€šè¿‡åº”ç”¨å²­å›å½’(ridge regression)å’Œå¯¹æ¯”è§£ç (contrastive decoding)æŠ€æœ¯ï¼Œå®éªŒè¯„ä¼°äº†å•å±‚è¡¨ç¤ºã€æ¸è¿›å¼æ‹¼æ¥(progressive concatenation)ä»¥åŠæ¸è¿›å¼æ±‚å’Œ(progressive summation)ç­‰å¯¹é½ç­–ç•¥ã€‚ç ”ç©¶å‘ç°ï¼Œç»“åˆå¤šæ¨¡æ€å’Œå±‚æ„ŸçŸ¥èƒ½åŠ›çš„ç‰¹å¾è¡¨ç¤ºèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è§£ç å¤§è„‘å¯¹è¯­è¨€çš„ç†è§£è¿‡ç¨‹ï¼Œå°†å…¶è§†ä¸ºä¸€ç§ç»¼åˆä½“éªŒè€Œéå•çº¯çš„å£°å­¦å¤„ç†ã€‚è¿™ä¸€å‘ç°ä¸ºåˆ©ç”¨å¤šæ¨¡æ€å¯¹é½æŠ€æœ¯è§£ç äººç±»è®¤çŸ¥çš„å¤šç»´åº¦æœ¬è´¨æä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.00065v2",
      "published_date": "2025-10-29 05:30:17 UTC",
      "updated_date": "2025-11-10 02:52:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:45.659358+00:00"
    },
    {
      "arxiv_id": "2510.25181v1",
      "title": "Fed-PELAD: Communication-Efficient Federated Learning for Massive MIMO CSI Feedback with Personalized Encoders and a LoRA-Adapted Shared Decoder",
      "title_zh": "Fed-PELADï¼šé‡‡ç”¨ä¸ªæ€§åŒ–ç¼–ç å™¨ä¸LoRAé€‚é…å…±äº«è§£ç å™¨çš„å¤§è§„æ¨¡MIMO CSIåé¦ˆé€šä¿¡é«˜æ•ˆè”é‚¦å­¦ä¹ ",
      "authors": [
        "Yixiang Zhou",
        "Tong Wu",
        "Meixia Tao",
        "Jianhua Mo"
      ],
      "abstract": "This paper addresses the critical challenges of communication overhead, data heterogeneity, and privacy in deep learning for channel state information (CSI) feedback in massive MIMO systems. To this end, we propose Fed-PELAD, a novel federated learning framework that incorporates personalized encoders and a LoRA-adapted shared decoder. Specifically, personalized encoders are trained locally on each user equipment (UE) to capture device-specific channel characteristics, while a shared decoder is updated globally via the coordination of the base station (BS) by using Low-Rank Adaptation (LoRA). This design ensures that only compact LoRA adapter parameters instead of full model updates are transmitted for aggregation. To further enhance convergence stability, we introduce an alternating freezing strategy with calibrated learning-rate ratio during LoRA aggregation. Extensive simulations on 3GPP-standard channel models demonstrate that Fed-PELAD requires only 42.97\\% of the uplink communication cost compared to conventional methods while achieving a performance gain of 1.2 dB in CSI feedback accuracy under heterogeneous conditions.",
      "tldr_zh": "é’ˆå¯¹å¤§è§„æ¨¡MIMOç³»ç»ŸCSIåé¦ˆä¸­é¢ä¸´çš„é€šä¿¡å¼€é”€ã€æ•°æ®å¼‚æ„æ€§å’Œéšç§æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†Fed-PELADæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆçš„è”é‚¦å­¦ä¹ (Federated Learning)ã€‚è¯¥æ¡†æ¶åœ¨ç”¨æˆ·ç«¯(UE)éƒ¨ç½²ä¸ªæ€§åŒ–ç¼–ç å™¨(Personalized Encoders)ä»¥æ•è·è®¾å¤‡ç‰¹å®šçš„ä¿¡é“ç‰¹å¾ï¼ŒåŒæ—¶åˆ©ç”¨ä½ç§©è‡ªé€‚åº”(LoRA)æŠ€æœ¯å¯¹åŸºç«™ä¾§çš„å…±äº«è§£ç å™¨è¿›è¡Œå…¨å±€æ›´æ–°ã€‚é€šè¿‡ä»…ä¼ è¾“ç´§å‡‘çš„LoRAé€‚é…å™¨å‚æ•°è€Œéå…¨é‡æ¨¡å‹æ›´æ–°ï¼Œè¯¥è®¾è®¡æ˜¾è‘—é™ä½äº†ä¸Šè¡Œé€šä¿¡å¼€é”€ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†å¸¦æœ‰æ ¡å‡†å­¦ä¹ ç‡æ¯”ä¾‹çš„äº¤æ›¿å†»ç»“ç­–ç•¥(Alternating Freezing Strategy)ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºæ¨¡å‹çš„æ”¶æ•›ç¨³å®šæ€§ã€‚åœ¨3GPPæ ‡å‡†ä¿¡é“æ¨¡å‹ä¸‹çš„ä»¿çœŸç»“æœæ˜¾ç¤ºï¼ŒFed-PELADåœ¨å¼‚æ„ç¯å¢ƒä¸‹ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡äº†1.2 dBçš„åé¦ˆç²¾åº¦ï¼Œä¸”ä»…æ¶ˆè€—çº¦42.97%çš„é€šä¿¡æˆæœ¬ã€‚",
      "categories": [
        "cs.IT",
        "cs.AI"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25181v1",
      "published_date": "2025-10-29 05:24:21 UTC",
      "updated_date": "2025-10-29 05:24:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:29:57.468606+00:00"
    },
    {
      "arxiv_id": "2510.25179v1",
      "title": "Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models",
      "title_zh": "Agentic Moderationï¼šé¢å‘æ›´å®‰å…¨è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“è®¾è®¡",
      "authors": [
        "Juan Ren",
        "Mark Dras",
        "Usman Naseem"
      ],
      "abstract": "Agentic methods have emerged as a powerful and autonomous paradigm that enhances reasoning, collaboration, and adaptive control, enabling systems to coordinate and independently solve complex tasks. We extend this paradigm to safety alignment by introducing Agentic Moderation, a model-agnostic framework that leverages specialised agents to defend multimodal systems against jailbreak attacks. Unlike prior approaches that apply as a static layer over inputs or outputs and provide only binary classifications (safe or unsafe), our method integrates dynamic, cooperative agents, including Shield, Responder, Evaluator, and Reflector, to achieve context-aware and interpretable moderation. Extensive experiments across five datasets and four representative Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF), and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable, and well-balanced safety performance. By harnessing the flexibility and reasoning capacity of agentic architectures, Agentic Moderation provides modular, scalable, and fine-grained safety enforcement, highlighting the broader potential of agentic systems as a foundation for automated safety governance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Agentic Moderationï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å‹æ— å…³(model-agnostic)çš„æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤šæ™ºèƒ½ä½“åä½œå¢å¼ºå¤§è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)é˜²å¾¡è¶Šç‹±æ”»å‡»(jailbreak attacks)çš„èƒ½åŠ›ã€‚ä¸ä»…æä¾›äºŒè¿›åˆ¶åˆ†ç±»çš„ä¼ ç»Ÿé™æ€è¿‡æ»¤å±‚ä¸åŒï¼Œè¯¥æ–¹æ³•é›†æˆäº†Shieldã€Responderã€Evaluatorå’ŒReflectorç­‰ä¸“é—¨æ™ºèƒ½ä½“ï¼Œå®ç°äº†åŠ¨æ€ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„å®‰å…¨å®¡æ ¸ã€‚é€šè¿‡å‘æŒ¥æ™ºèƒ½ä½“æ¶æ„çš„çµæ´»æ€§å’Œæ¨ç†èƒ½åŠ›ï¼ŒAgentic Moderationä¸ºç³»ç»Ÿæä¾›äº†æ¨¡å—åŒ–ã€å¯æ‰©å±•ä¸”ç»†ç²’åº¦çš„å®‰å…¨å¼ºåˆ¶æ‰§è¡Œæœºåˆ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨äº”ä¸ªæ•°æ®é›†ä¸Šå°†æ”»å‡»æˆåŠŸç‡(ASR)é™ä½äº†7-19%ï¼ŒåŒæ—¶å°†æ‹’ç»ç‡(RR)æå‡äº†4-20%ï¼Œå¹¶ä¿æŒäº†ç¨³å®šçš„ééµå¾ªç‡(NF)ã€‚è¯¥ç ”ç©¶ä¸ä»…å®ç°äº†ç¨³å¥ä¸”å¹³è¡¡çš„å®‰å…¨æ€§èƒ½ï¼Œè¿˜å±•ç¤ºäº†æ™ºèƒ½ä½“ç³»ç»Ÿä½œä¸ºè‡ªåŠ¨åŒ–å®‰å…¨æ²»ç†åŸºç¡€çš„å¹¿æ³›æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25179v1",
      "published_date": "2025-10-29 05:23:24 UTC",
      "updated_date": "2025-10-29 05:23:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:01.765404+00:00"
    },
    {
      "arxiv_id": "2510.25164v2",
      "title": "Transformers in Medicine: Improving Vision-Language Alignment for Medical Image Captioning",
      "title_zh": "åŒ»å­¦é¢†åŸŸçš„ Transformerï¼šæå‡åŒ»å­¦å›¾åƒæè¿°ç”Ÿæˆçš„è§†è§‰-è¯­è¨€å¯¹é½",
      "authors": [
        "Yogesh Thakku Suresh",
        "Vishwajeet Shivaji Hogale",
        "Luca-Alexandru Zamfira",
        "Anandavardhana Hegde"
      ],
      "abstract": "We present a transformer-based multimodal framework for generating clinically relevant captions for MRI scans. Our system combines a DEiT-Small vision transformer as an image encoder, MediCareBERT for caption embedding, and a custom LSTM-based decoder. The architecture is designed to semantically align image and textual embeddings, using hybrid cosine-MSE loss and contrastive inference via vector similarity. We benchmark our method on the MultiCaRe dataset, comparing performance on filtered brain-only MRIs versus general MRI images against state-of-the-art medical image captioning methods including BLIP, R2GenGPT, and recent transformer-based approaches. Results show that focusing on domain-specific data improves caption accuracy and semantic alignment. Our work proposes a scalable, interpretable solution for automated medical image reporting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Transformer çš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œæ—¨åœ¨ä¸º MRI æ‰«æç”Ÿæˆå…·æœ‰ä¸´åºŠç›¸å…³æ€§çš„åŒ»å­¦å½±åƒæè¿°ã€‚ç³»ç»Ÿæ¶æ„ç»“åˆäº†ç”¨äºå›¾åƒç¼–ç çš„ DEiT-Small è§†è§‰ Transformerã€ç”¨äºæè¿°åµŒå…¥çš„ MediCareBERT ä»¥åŠä¸€ä¸ªè‡ªå®šä¹‰çš„åŸºäº LSTM çš„è§£ç å™¨ã€‚ä¸ºäº†å®ç°å›¾åƒä¸æ–‡æœ¬åµŒå…¥çš„è¯­ä¹‰å¯¹é½ï¼Œç ”ç©¶é‡‡ç”¨äº†æ··åˆçš„ Cosine-MSE æŸå¤±å‡½æ•°ï¼Œå¹¶åˆ©ç”¨å‘é‡ç›¸ä¼¼åº¦è¿›è¡Œå¯¹æ¯”æ¨ç†ã€‚é€šè¿‡åœ¨ MultiCaRe æ•°æ®é›†ä¸Šçš„åŸºå‡†æµ‹è¯•ï¼Œå®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨æè¿°å‡†ç¡®æ€§å’Œè¯­ä¹‰å¯¹é½æ–¹é¢å‡ä¼˜äº BLIP å’Œ R2GenGPT ç­‰å…ˆè¿›çš„åŒ»å­¦å½±åƒæè¿°æ¨¡å‹ã€‚è¯¥å·¥ä½œä¸ºå®ç°è‡ªåŠ¨åŒ–ã€å¯æ‰©å±•ä¸”å…·å¤‡å¯è§£é‡Šæ€§çš„åŒ»ç–—å½±åƒæŠ¥å‘Šç”Ÿæˆæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "This work is to appear in the Proceedings of MICAD 2025, the 6th International Conference on Medical Imaging and Computer-Aided Diagnosis",
      "pdf_url": "https://arxiv.org/pdf/2510.25164v2",
      "published_date": "2025-10-29 04:49:20 UTC",
      "updated_date": "2025-10-31 01:57:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:12.454995+00:00"
    },
    {
      "arxiv_id": "2510.25160v2",
      "title": "Model-Document Protocol for AI Search",
      "title_zh": "é¢å‘ AI æœç´¢çš„æ¨¡å‹-æ–‡æ¡£åè®®",
      "authors": [
        "Hongjin Qian",
        "Zheng Liu"
      ],
      "abstract": "AI search depends on linking large language models (LLMs) with vast external knowledge sources. Yet web pages, PDF files, and other raw documents are not inherently LLM-ready: they are long, noisy, and unstructured. Conventional retrieval methods treat these documents as verbatim text and return raw passages, leaving the burden of fragment assembly and contextual reasoning to the LLM. This gap underscores the need for a new retrieval paradigm that redefines how models interact with documents.\n  We introduce the Model-Document Protocol (MDP), a general framework that formalizes how raw text is bridged to LLMs through consumable knowledge representations. Rather than treating retrieval as passage fetching, MDP defines multiple pathways that transform unstructured documents into task-specific, LLM-ready inputs. These include agentic reasoning, which curates raw evidence into coherent context; memory grounding, which accumulates reusable notes to enrich reasoning; and structured leveraging, which encodes documents into formal representations such as graphs or key-value caches. All three pathways share the same goal: ensuring that what reaches the LLM is not raw fragments but compact, structured knowledge directly consumable for reasoning.\n  As an instantiation, we present MDP-Agent, which realizes the protocol through an agentic process: constructing document-level gist memories for global coverage, performing diffusion-based exploration with vertical exploitation to uncover layered dependencies, and applying map-reduce style synthesis to integrate large-scale evidence into compact yet sufficient context. Experiments on information-seeking benchmarks demonstrate that MDP-Agent outperforms baselines, validating both the soundness of the MDP framework and the effectiveness of its agentic instantiation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Model-Document Protocol (MDP)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å°†åŸå§‹é•¿æ–‡æœ¬ã€æ‚ä¹±åŠéç»“æ„åŒ–æ–‡æ¡£è½¬åŒ–ä¸ºå¤§è¯­è¨€æ¨¡å‹ (LLMs) å¯ç›´æ¥æ¶ˆè´¹çŸ¥è¯†è¡¨ç¤ºçš„é€šç”¨æ¡†æ¶ï¼Œä»¥è§£å†³ä¼ ç»Ÿæ£€ç´¢æ–¹æ³•å¸¦æ¥çš„ç¢ç‰‡åŒ–æ‹¼æ¥å’Œæ¨ç†è´Ÿæ‹…ã€‚MDP åè®®å®šä¹‰äº†ä¸‰ç§ä¸»è¦è·¯å¾„ï¼šagentic reasoning è´Ÿè´£å°†åŸå§‹è¯æ®æ•´ç†ä¸ºè¿è´¯ä¸Šä¸‹æ–‡ï¼Œmemory grounding ç§¯ç´¯å¯å¤ç”¨çš„ç¬”è®°ä»¥å¢å¼ºæ¨ç†ï¼Œè€Œ structured leveraging åˆ™å°†æ–‡æ¡£ç¼–ç ä¸ºå›¾æˆ–é”®å€¼ç¼“å­˜ç­‰æ­£å¼è¡¨ç¤ºã€‚å…¶æ ¸å¿ƒç›®æ ‡æ˜¯ç¡®ä¿ä¼ é€’ç»™ LLMs çš„å†…å®¹å¹¶éåŸå§‹ç‰‡æ®µï¼Œè€Œæ˜¯é’ˆå¯¹ç‰¹å®šä»»åŠ¡ä¼˜åŒ–è¿‡çš„ã€å¯ç›´æ¥ç”¨äºæ¨ç†çš„ç´§å‡‘ç»“æ„åŒ–çŸ¥è¯†ã€‚ç ”ç©¶è¿˜æ¨å‡ºäº† MDP-Agentï¼Œé€šè¿‡æ„å»ºå…¨å±€è¦†ç›–çš„ gist memoriesã€æ‰§è¡Œ diffusion-based exploration æ·±åº¦æŒ–æ˜ä¾èµ–å…³ç³»ï¼Œå¹¶åº”ç”¨ map-reduce é£æ ¼çš„åˆæˆæŠ€æœ¯æ¥æ•´åˆå¤§è§„æ¨¡è¯æ®ã€‚åœ¨ä¿¡æ¯æœç´¢åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMDP-Agent çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºçº¿ï¼Œå……åˆ†éªŒè¯äº† MDP æ¡†æ¶çš„åˆç†æ€§åŠå…¶åœ¨ AI search é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.25160v2",
      "published_date": "2025-10-29 04:29:17 UTC",
      "updated_date": "2025-10-30 08:52:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:11.457823+00:00"
    },
    {
      "arxiv_id": "2511.05529v2",
      "title": "Selective Diabetic Retinopathy Screening with Accuracy-Weighted Deep Ensembles and Entropy-Guided Abstention",
      "title_zh": "åŸºäºå‡†ç¡®ç‡åŠ æƒæ·±åº¦é›†æˆä¸ç†µå¼•å¯¼å¼ƒæƒçš„é€‰æ‹©æ€§ç³–å°¿ç—…è§†ç½‘è†œç—…å˜ç­›æŸ¥",
      "authors": [
        "Jophy Lin"
      ],
      "abstract": "Diabetic retinopathy (DR), a microvascular complication of diabetes and a leading cause of preventable blindness, is projected to affect more than 130 million individuals worldwide by 2030. Early identification is essential to reduce irreversible vision loss, yet current diagnostic workflows rely on methods such as fundus photography and expert review, which remain costly and resource-intensive. This, combined with DR's asymptomatic nature, results in its underdiagnosis rate of approximately 25 percent. Although convolutional neural networks (CNNs) have demonstrated strong performance in medical imaging tasks, limited interpretability and the absence of uncertainty quantification restrict clinical reliability. Therefore, in this study, a deep ensemble learning framework integrated with uncertainty estimation is introduced to improve robustness, transparency, and scalability in DR detection. The ensemble incorporates seven CNN architectures-ResNet-50, DenseNet-121, MobileNetV3 (Small and Large), and EfficientNet (B0, B2, B3)- whose outputs are fused through an accuracy-weighted majority voting strategy. A probability-weighted entropy metric quantifies prediction uncertainty, enabling low-confidence samples to be excluded or flagged for additional review. Training and validation on 35,000 EyePACS retinal fundus images produced an unfiltered accuracy of 93.70 percent (F1 = 0.9376). Uncertainty-filtering later was conducted to remove unconfident samples, resulting in maximum-accuracy of 99.44 percent (F1 = 0.9932). The framework shows that uncertainty-aware, accuracy-weighted ensembling improves reliability without hindering performance. With confidence-calibrated outputs and a tunable accuracy-coverage trade-off, it offers a generalizable paradigm for deploying trustworthy AI diagnostics in high-risk care.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç³–å°¿ç—…è§†ç½‘è†œç—…å˜ (Diabetic Retinopathy, DR) æ—©æœŸè¯Šæ–­ä¸­å­˜åœ¨çš„èµ„æºå¯†é›†ã€è¯¯è¯Šç‡é«˜ä»¥åŠå·ç§¯ç¥ç»ç½‘ç»œ (CNNs) ç¼ºä¹å¯è§£é‡Šæ€§ä¸ä¸ç¡®å®šæ€§é‡åŒ–ç­‰é™åˆ¶ï¼Œæå‡ºäº†ä¸€ç§é›†æˆä¸ç¡®å®šæ€§ä¼°è®¡çš„æ·±åº¦é›†æˆå­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶èåˆäº† ResNet-50ã€DenseNet-121ã€MobileNetV3 å’Œ EfficientNet ç­‰ä¸ƒç§ CNNs æ¶æ„ï¼Œå¹¶é‡‡ç”¨å‡†ç¡®ç‡åŠ æƒå¤šæ•°æŠ•ç¥¨ç­–ç•¥ (Accuracy-Weighted Majority Voting) è¿›è¡Œå†³ç­–èåˆã€‚é€šè¿‡å¼•å…¥æ¦‚ç‡åŠ æƒç†µ (Probability-Weighted Entropy) æŒ‡æ ‡æ¥é‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œç³»ç»Ÿå¯ä»¥å¯¹ä½ç½®ä¿¡åº¦æ ·æœ¬è¿›è¡Œè‡ªåŠ¨å‰”é™¤æˆ–æ ‡è®°ä»¥ä¾›äººå·¥å¤å®¡ã€‚åœ¨åŒ…å« 35,000 å¼ å›¾åƒçš„ EyePACS æ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼Œæœªè¿‡æ»¤æ ·æœ¬çš„å‡†ç¡®ç‡ä¸º 93.70%ï¼Œè€Œåœ¨æ‰§è¡Œä¸ç¡®å®šæ€§è¿‡æ»¤åï¼Œå…¶æœ€é«˜å‡†ç¡®ç‡æ˜¾è‘—æå‡è‡³ 99.44% (F1 = 0.9932)ã€‚è¯¥æ¡†æ¶è¯æ˜äº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥ä¸å‡†ç¡®ç‡åŠ æƒé›†æˆèƒ½åœ¨ä¸æŸå®³æ€§èƒ½çš„å‰æä¸‹æå‡è¯Šæ–­å¯é æ€§ï¼Œä¸ºé«˜é£é™©åŒ»ç–—åœºæ™¯ä¸­éƒ¨ç½²å¯ä¿¡ AI è¯Šæ–­æä¾›äº†ä¸€ç§å…·æœ‰å¯è°ƒèŠ‚å‡†ç¡®ç‡-è¦†ç›–ç‡æƒè¡¡çš„å¯æ¨å¹¿èŒƒå¼ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.05529v2",
      "published_date": "2025-10-29 04:16:04 UTC",
      "updated_date": "2025-11-11 03:36:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:13.753039+00:00"
    },
    {
      "arxiv_id": "2512.00020v2",
      "title": "Large Language Model for Verilog Code Generation: Literature Review and the Road Ahead",
      "title_zh": "é¢å‘Verilogä»£ç ç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼šæ–‡çŒ®ç»¼è¿°ä¸æœªæ¥å±•æœ›",
      "authors": [
        "Guang Yang",
        "Wei Zheng",
        "Xiang Chen",
        "Dong Liang",
        "Peng Hu",
        "Yukui Yang",
        "Shaohang Peng",
        "Zhenghan Li",
        "Jiahui Feng",
        "Xiao Wei",
        "Kexin Sun",
        "Deyuan Ma",
        "Haotian Cheng",
        "Yiheng Shen",
        "Xing Hu",
        "Terry Yue Zhuo",
        "David Lo"
      ],
      "abstract": "Code generation has emerged as a critical research area at the intersection of Software Engineering (SE) and Artificial Intelligence (AI), attracting significant attention from both academia and industry. Within this broader landscape, Verilog, as a representative hardware description language (HDL), plays a fundamental role in digital circuit design and verification, making its automated generation particularly significant for Electronic Design Automation (EDA). Consequently, recent research has increasingly focused on applying Large Language Models (LLMs) to Verilog code generation, particularly at the Register Transfer Level (RTL), exploring how these AI-driven techniques can be effectively integrated into hardware design workflows. Despite substantial research efforts have explored LLM applications in this domain, a comprehensive survey synthesizing these developments remains absent from the literature. This review fill addresses this gap by providing a systematic literature review of LLM-based methods for Verilog code generation, examining their effectiveness, limitations, and potential for advancing automated hardware design. The review encompasses research work from conferences and journals in the fields of SE, AI, and EDA, encompassing 70 papers published on venues, along with 32 high-quality preprint papers, bringing the total to 102 papers. By answering four key research questions, we aim to (1) identify the LLMs used for Verilog generation, (2) examine the datasets and metrics employed in evaluation, (3) categorize the techniques proposed for Verilog generation, and (4) analyze LLM alignment approaches for Verilog generation. Based on our findings, we have identified a series of limitations of existing studies. Finally, we have outlined a roadmap highlighting potential opportunities for future research endeavors in LLM-assisted hardware design.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¡¬ä»¶æè¿°è¯­è¨€(HDL) Verilogçš„è‡ªåŠ¨ç”Ÿæˆè¿™ä¸€å…³é”®é¢†åŸŸï¼Œç³»ç»Ÿæ€§åœ°ç»¼è¿°äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)çš„Verilogä»£ç ç”Ÿæˆæ–¹æ³•ã€‚ä½œè€…é€šè¿‡å¯¹è½¯ä»¶å·¥ç¨‹(SE)ã€äººå·¥æ™ºèƒ½(AI)å’Œç”µå­è®¾è®¡è‡ªåŠ¨åŒ–(EDA)é¢†åŸŸçš„102ç¯‡ç›¸å…³è®ºæ–‡ï¼ˆåŒ…å«70ç¯‡æ­£å¼å‘è¡¨è®ºæ–‡åŠ32ç¯‡é«˜è´¨é‡é¢„å°æœ¬ï¼‰è¿›è¡Œæ·±å…¥è°ƒç ”ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸç¼ºä¹ç»¼åˆæ€§ç»¼è¿°çš„ç©ºç™½ã€‚æ–‡ç« é€šè¿‡å›ç­”å››ä¸ªå…³é”®ç ”ç©¶é—®é¢˜ï¼Œè¯¦ç»†åˆ†æäº†ç”¨äºVerilogç”Ÿæˆçš„LLMsæ¨¡å‹ã€è¯„ä¼°æ‰€ç”¨çš„æ•°æ®é›†ä¸æŒ‡æ ‡ã€æå‡ºçš„å„ç±»ç”ŸæˆæŠ€æœ¯ä»¥åŠå¯¹é½(Alignment)æ–¹æ³•ã€‚åœ¨è¯„ä¼°ç°æœ‰ç ”ç©¶æœ‰æ•ˆæ€§ä¸å±€é™æ€§çš„åŸºç¡€ä¸Šï¼Œè¯¥ç ”ç©¶è¿›ä¸€æ­¥è¯†åˆ«äº†å½“å‰é¢ä¸´çš„æŒ‘æˆ˜ã€‚æœ€åï¼Œæœ¬æ–‡ä¸ºLLMè¾…åŠ©çš„ç¡¬ä»¶è®¾è®¡æç»˜äº†æœªæ¥ç ”ç©¶è·¯çº¿å›¾ï¼Œä¸ºå®ç°æ›´é«˜æ•ˆçš„è‡ªåŠ¨åŒ–ç¡¬ä»¶è®¾è®¡å’Œå¯„å­˜å™¨ä¼ è¾“çº§(RTL)å¼€å‘å¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2512.00020v2",
      "published_date": "2025-10-29 04:14:43 UTC",
      "updated_date": "2025-12-24 09:40:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:14.265312+00:00"
    },
    {
      "arxiv_id": "2511.05528v1",
      "title": "SMAGDi: Socratic Multi Agent Interaction Graph Distillation for Efficient High Accuracy Reasoning",
      "title_zh": "SMAGDiï¼šé¢å‘é«˜æ•ˆé«˜ç²¾åº¦æ¨ç†çš„è‹æ ¼æ‹‰åº•å¼å¤šæ™ºèƒ½ä½“äº¤äº’å›¾è’¸é¦",
      "authors": [
        "Aayush Aluru",
        "Myra Malik",
        "Samarth Patankar",
        "Spencer Kim",
        "Kevin Zhu",
        "Sean O'Brien",
        "Vasu Sharma"
      ],
      "abstract": "Multi-agent systems (MAS) often achieve higher reasoning accuracy than single models, but their reliance on repeated debates across agents makes them computationally expensive. We introduce SMAGDi, a distillation framework that transfers the debate dynamics of a five-agent Llama-based MAS into a compact Socratic decomposer-solver student. SMAGDi represents debate traces as directed interaction graphs, where nodes encode intermediate reasoning steps with correctness labels and edges capture continuity and cross-agent influence. The student is trained with a composite objective combining language modeling, graph-based supervision, contrastive reasoning, and embedding alignment to preserve both fluency and structured reasoning. On StrategyQA and MMLU, SMAGDi compresses a 40B multi-agent system into a 6B student while retaining 88% of its accuracy, substantially outperforming prior distillation methods such as MAGDi, standard KD, and fine-tuned baselines. These results highlight that explicitly modeling interaction graphs and Socratic decomposition enable small models to inherit the accuracy benefits of multi-agent debate while remaining efficient enough for real-world deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SMAGDiï¼Œä¸€ç§è‹æ ¼æ‹‰åº•å¼å¤šæ™ºèƒ½ä½“äº¤äº’å›¾è’¸é¦(Socratic Multi Agent Interaction Graph Distillation)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multi-agent systems)å› é¢‘ç¹è¾©è®ºå¯¼è‡´çš„è®¡ç®—æˆæœ¬é«˜æ˜‚é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†äº”æ™ºèƒ½ä½“çš„è¾©è®ºè½¨è¿¹è¡¨ç¤ºä¸ºæœ‰å‘äº¤äº’å›¾(directed interaction graphs)ï¼Œé€šè¿‡èŠ‚ç‚¹ç¼–ç æ¨ç†æ­¥éª¤åŠæ­£ç¡®æ€§æ ‡ç­¾ï¼Œå¹¶åˆ©ç”¨è¾¹æ•æ‰è·¨æ™ºèƒ½ä½“çš„å½±å“åŠ›ã€‚å­¦ç”Ÿæ¨¡å‹é‡‡ç”¨è‹æ ¼æ‹‰åº•å¼çš„åˆ†è§£å™¨-æ±‚è§£å™¨(decomposer-solver)æ¶æ„ï¼Œé€šè¿‡ç»“åˆè¯­è¨€å»ºæ¨¡ã€å›¾ç›‘ç£ã€å¯¹æ¯”æ¨ç†å’ŒåµŒå…¥å¯¹é½çš„å¤åˆç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œä»¥å®Œæ•´ä¿ç•™è¾©è®ºçš„ç»“æ„åŒ–ç‰¹å¾ã€‚åœ¨ StrategyQA å’Œ MMLU ä»»åŠ¡ä¸­ï¼ŒSMAGDi æˆåŠŸå°† 40B çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå‹ç¼©ä¸º 6B çš„å­¦ç”Ÿæ¨¡å‹ï¼Œåœ¨ä¿ç•™ 88% å‡†ç¡®ç‡çš„åŒæ—¶æ˜¾è‘—ä¼˜äº MAGDi å’Œæ ‡å‡†çŸ¥è¯†è’¸é¦(KD)ç­‰åŸºçº¿æ–¹æ³•ã€‚å®éªŒè¯æ˜ï¼Œæ˜¾å¼å»ºæ¨¡äº¤äº’å›¾å’Œè‹æ ¼æ‹‰åº•å¼åˆ†è§£èƒ½ä½¿å°æ¨¡å‹é«˜æ•ˆç»§æ‰¿å¤šæ™ºèƒ½ä½“è¾©è®ºçš„ç²¾åº¦ä¼˜åŠ¿ï¼Œä¸ºé«˜ç²¾åº¦æ¨ç†æ¨¡å‹çš„å®é™…éƒ¨ç½²æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Multi-Turn Interactions in Large Language Models (MTI-LLM) Workshop at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.05528v1",
      "published_date": "2025-10-29 04:05:10 UTC",
      "updated_date": "2025-10-29 04:05:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:22.062818+00:00"
    },
    {
      "arxiv_id": "2510.25801v2",
      "title": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start",
      "title_zh": "Metis-SPECSï¼šé€šè¿‡åŸºäºåå¥½çš„è‡ªè’¸é¦å†·å¯åŠ¨å®ç°å¤šæ¨¡æ€å­¦ä¹ è§£è€¦",
      "authors": [
        "Kun Chen",
        "Peng Shi",
        "Haibo Qiu",
        "Zhixiong Zeng",
        "Siqi Yang",
        "Wenji Mao",
        "Lin Ma"
      ],
      "abstract": "Reinforcement learning (RL) with verifiable rewards has recently catalyzed a wave of \"MLLM-r1\" approaches that bring RL to vision language models. Most representative paradigms begin with a cold start, typically employing supervised fine-tuning (SFT), to initialize the policy before RL. However, SFT-based cold start adopts the reasoning paradigm intertwined with task solution and output format, which may induce instruction-style overfitting, weakens out-of-distribution generalization, and ultimately affects downstream RL. We revisit the cold start along two views, its training method and data construction, and introduce the Generalization Factor (GF) coefficient to quantify the generalization capability under different methods. Our empirical study finds that preference-based training methods (e.g. DPO) generalizes better than SFT-based methods in cold start. Motivated by this, we propose SPECS-a Self-distilled, Preference-based Cold Start framework that decouples multimodal learning: (1) generates introspective preference data pairs via self-distillation, avoiding reliance on larger teachers or manual annotation; (2) performs preference-based training to learn, focusing on shallow, transferable surface-form criteria (format, structure, style) rather than memorizing content; and (3) hands off to RL with verifiable rewards for deep reasoning results. Experimental results across multiple multimodal benchmarks show that our decoupling learning framework yields consistent performance gains over strong baselines, improving MEGA-Bench by 4.1% and MathVista by 12.2%. Additional experiments indicate that SPECS contributes to reducing in-distribution \"stuckness,\" improving exploration, stabilizing training, and raising the performance ceiling.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é˜¶æ®µå‰æ™®éä¾èµ–æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å†·å¯åŠ¨å¯¼è‡´æŒ‡ä»¤è¿‡æ‹ŸåˆåŠæ³›åŒ–æ€§å¼±çš„é—®é¢˜ï¼Œæå‡ºäº†Metis-SPECSæ¡†æ¶ã€‚ç ”ç©¶è€…å¼•å…¥æ³›åŒ–å› å­ï¼ˆGeneralization Factor, GFï¼‰é‡åŒ–äº†ä¸åŒå†·å¯åŠ¨æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ï¼Œå‘ç°åŸºäºåå¥½ï¼ˆPreference-basedï¼‰çš„è®­ç»ƒæ–¹æ³•ï¼ˆå¦‚DPOï¼‰åœ¨å†·å¯åŠ¨é˜¶æ®µæ¯”SFTå…·æœ‰æ›´å¥½çš„æ³›åŒ–è¡¨ç°ã€‚SPECSæ¡†æ¶é€šè¿‡è‡ªè’¸é¦ï¼ˆSelf-distillationï¼‰ç”Ÿæˆå†…çœå¼åå¥½æ•°æ®å¯¹ï¼Œä½¿æ¨¡å‹åœ¨å†·å¯åŠ¨é˜¶æ®µä¸“æ³¨äºå­¦ä¹ æ ¼å¼ã€ç»“æ„ç­‰å¯è¿ç§»çš„è¡¨é¢å½¢å¼æ ‡å‡†ï¼Œè€Œéæ­»è®°ç¡¬èƒŒå†…å®¹ã€‚è¿™ç§è§£è€¦å¤šæ¨¡æ€å­¦ä¹ çš„è®¾è®¡å°†æ·±å±‚æ¨ç†ä»»åŠ¡äº¤ç»™åç»­å¸¦æœ‰å¯éªŒè¯å¥–åŠ±ï¼ˆVerifiable Rewardsï¼‰çš„å¼ºåŒ–å­¦ä¹ é˜¶æ®µã€‚å®éªŒè¡¨æ˜ï¼ŒSPECSåœ¨MEGA-Benchå’ŒMathVistaä¸Šåˆ†åˆ«å®ç°äº†4.1%å’Œ12.2%çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆå‡å°‘äº†æ¨¡å‹åœ¨åˆ†å¸ƒå†…çš„â€œåœæ»â€æ„Ÿï¼Œå¢å¼ºäº†æ¢ç´¢èƒ½åŠ›å¹¶æ˜¾è‘—æå‡äº†è®­ç»ƒçš„æ€§èƒ½ä¸Šé™ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Project Page: https://github.com/Kwen-Chen/SPECS-VL",
      "pdf_url": "https://arxiv.org/pdf/2510.25801v2",
      "published_date": "2025-10-29 03:42:23 UTC",
      "updated_date": "2025-11-19 03:14:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:24.863320+00:00"
    },
    {
      "arxiv_id": "2510.25140v2",
      "title": "DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications",
      "title_zh": "DINO-YOLOï¼šé¢å‘åœŸæœ¨å·¥ç¨‹é¢†åŸŸæ•°æ®é«˜æ•ˆç›®æ ‡æ£€æµ‹çš„è‡ªç›‘ç£é¢„è®­ç»ƒ",
      "authors": [
        "Malaisree P",
        "Youwai S",
        "Kitkobsin T",
        "Janrungautai S",
        "Amorndechaphon D",
        "Rojanavasu P"
      ],
      "abstract": "Object detection in civil engineering applications is constrained by limited annotated data in specialized domains. We introduce DINO-YOLO, a hybrid architecture combining YOLOv12 with DINOv3 self-supervised vision transformers for data-efficient detection. DINOv3 features are strategically integrated at two locations: input preprocessing (P0) and mid-backbone enhancement (P3). Experimental validation demonstrates substantial improvements: Tunnel Segment Crack detection (648 images) achieves 12.4% improvement, Construction PPE (1K images) gains 13.7%, and KITTI (7K images) shows 88.6% improvement, while maintaining real-time inference (30-47 FPS). Systematic ablation across five YOLO scales and nine DINOv3 variants reveals that Medium-scale architectures achieve optimal performance with DualP0P3 integration (55.77% mAP@0.5), while Small-scale requires Triple Integration (53.63%). The 2-4x inference overhead (21-33ms versus 8-16ms baseline) remains acceptable for field deployment on NVIDIA RTX 5090. DINO-YOLO establishes state-of-the-art performance for civil engineering datasets (<10K images) while preserving computational efficiency, providing practical solutions for construction safety monitoring and infrastructure inspection in data-constrained environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DINO-YOLOï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†YOLOv12ä¸DINOv3è‡ªç›‘ç£è§†è§‰Transformer(Self-Supervised Vision Transformers)çš„æ··åˆæ¶æ„ï¼Œæ—¨åœ¨è§£å†³åœŸæœ¨å·¥ç¨‹åº”ç”¨ä¸­å› æ ‡æ³¨æ•°æ®æœ‰é™å¯¼è‡´çš„ç›®æ ‡æ£€æµ‹ç“¶é¢ˆã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨è¾“å…¥é¢„å¤„ç†(P0)å’Œä¸»å¹²å¢å¼º(P3)ä¸¤ä¸ªå…³é”®ä½ç½®ç­–ç•¥æ€§åœ°æ•´åˆDINOv3ç‰¹å¾ï¼Œå®ç°äº†é«˜æ•ˆçš„æ•°æ®åˆ©ç”¨ã€‚å®éªŒéªŒè¯æ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨éš§é“ç®¡ç‰‡è£‚ç¼æ£€æµ‹(Tunnel Segment Crack detection)å’Œæ–½å·¥äººå‘˜é˜²æŠ¤è£…å¤‡(Construction PPE)ç­‰ä»»åŠ¡ä¸­åˆ†åˆ«æå‡äº†12.4%å’Œ13.7%çš„æ€§èƒ½ï¼Œå¹¶åœ¨ä¿æŒ30-47 FPSå®æ—¶æ¨ç†é€Ÿåº¦çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ä¸­ç­‰è§„æ¨¡(Medium-scale)æ¶æ„ç»“åˆDualP0P3é›†æˆæ–¹æ¡ˆè¾¾åˆ°äº†55.77%çš„æœ€ä½³mAP@0.5ã€‚è™½ç„¶æ¨ç†å¼€é”€è¾ƒåŸºçº¿æ¨¡å‹æœ‰æ‰€å¢åŠ ï¼Œä½†åœ¨NVIDIA RTX 5090ä¸Šä»èƒ½æ»¡è¶³ç°åœºéƒ¨ç½²è¦æ±‚ã€‚DINO-YOLOä¸ºæ•°æ®å—é™ç¯å¢ƒä¸‹çš„æ–½å·¥å®‰å…¨ç›‘æµ‹å’ŒåŸºç¡€è®¾æ–½å·¡æ£€æä¾›äº†å®ç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œåœ¨å°‘äº1ä¸‡å¼ å›¾åƒçš„åœŸæœ¨å·¥ç¨‹æ•°æ®é›†ä¸Šç¡®ç«‹äº†SOTAæ€§èƒ½ï¼ŒæˆåŠŸå…¼é¡¾äº†è®¡ç®—æ•ˆç‡ä¸æ£€æµ‹ç²¾åº¦ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25140v2",
      "published_date": "2025-10-29 03:40:40 UTC",
      "updated_date": "2025-10-31 01:42:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:32.270180+00:00"
    },
    {
      "arxiv_id": "2510.25130v2",
      "title": "Lipschitz-aware Linearity Grafting for Certified Robustness",
      "title_zh": "é¢å‘è®¤è¯é²æ£’æ€§çš„ Lipschitz æ„ŸçŸ¥çº¿æ€§å«æ¥",
      "authors": [
        "Yongjin Han",
        "Suhyun Kim"
      ],
      "abstract": "Lipschitz constant is a fundamental property in certified robustness, as smaller values imply robustness to adversarial examples when a model is confident in its prediction. However, identifying the worst-case adversarial examples is known to be an NP-complete problem. Although over-approximation methods have shown success in neural network verification to address this challenge, reducing approximation errors remains a significant obstacle. Furthermore, these approximation errors hinder the ability to obtain tight local Lipschitz constants, which are crucial for certified robustness. Originally, grafting linearity into non-linear activation functions was proposed to reduce the number of unstable neurons, enabling scalable and complete verification. However, no prior theoretical analysis has explained how linearity grafting improves certified robustness. We instead consider linearity grafting primarily as a means of eliminating approximation errors rather than reducing the number of unstable neurons, since linear functions do not require relaxation. In this paper, we provide two theoretical contributions: 1) why linearity grafting improves certified robustness through the lens of the $l_\\infty$ local Lipschitz constant, and 2) grafting linearity into non-linear activation functions, the dominant source of approximation errors, yields a tighter local Lipschitz constant. Based on these theoretical contributions, we propose a Lipschitz-aware linearity grafting method that removes dominant approximation errors, which are crucial for tightening the local Lipschitz constant, thereby improving certified robustness, even without certified training. Our extensive experiments demonstrate that grafting linearity into these influential activations tightens the $l_\\infty$ local Lipschitz constant and enhances certified robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Lipschitz constant åœ¨è®¤è¯é²æ£’æ€§(certified robustness)ä¸­çš„æ ¸å¿ƒä½œç”¨ï¼Œå¹¶é’ˆå¯¹ç¥ç»ç½‘ç»œéªŒè¯ä¸­è¿‡è¿‘ä¼¼è¯¯å·®(approximation errors)å¯¼è‡´çš„å±€éƒ¨ Lipschitz constant ä¸ç´§è‡´é—®é¢˜æå‡ºäº†æ”¹è¿›æ–¹æ¡ˆã€‚è®ºæ–‡å°†åŸæœ¬ç”¨äºå‡å°‘ä¸ç¨³å®šç¥ç»å…ƒçš„çº¿æ€§å«æ¥(linearity grafting)æŠ€æœ¯é‡æ–°å®šä¹‰ä¸ºæ¶ˆé™¤è¿‘ä¼¼è¯¯å·®çš„æ‰‹æ®µï¼Œå› ä¸ºçº¿æ€§å‡½æ•°åœ¨éªŒè¯è¿‡ç¨‹ä¸­æ— éœ€è¿›è¡Œæ¾å¼›å¤„ç†ã€‚ä½œè€…åœ¨ç†è®ºä¸Šé˜æ˜äº†çº¿æ€§å«æ¥å¦‚ä½•é€šè¿‡ $l_\\infty$ å±€éƒ¨ Lipschitz constant æå‡è®¤è¯é²æ£’æ€§ï¼Œå¹¶è¯æ˜åœ¨éçº¿æ€§æ¿€æ´»å‡½æ•°ä¸­å«æ¥çº¿æ€§éƒ¨åˆ†èƒ½æ˜¾è‘—æ”¶ç´§å±€éƒ¨ Lipschitz constantã€‚åŸºäºè¿™äº›ç†è®ºå‘ç°ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ Lipschitz-aware linearity grafting æ–¹æ³•ï¼Œæ—¨åœ¨ç§»é™¤ä¸»è¦çš„è¿‘ä¼¼è¯¯å·®æ¥æºï¼Œä»è€Œåœ¨ä¸è¿›è¡Œè®¤è¯è®­ç»ƒ(certified training)çš„æƒ…å†µä¸‹ç›´æ¥æå‡é²æ£’æ€§èƒ½ã€‚å®éªŒç»“æœè¯å®ï¼Œé€šè¿‡åœ¨å…³é”®æ¿€æ´»å‡½æ•°ä¸­åº”ç”¨çº¿æ€§å«æ¥ï¼Œå¯ä»¥æœ‰æ•ˆæ”¶ç´§ $l_\\infty$ å±€éƒ¨ Lipschitz constant å¹¶å¢å¼ºæ¨¡å‹çš„è®¤è¯é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25130v2",
      "published_date": "2025-10-29 03:19:55 UTC",
      "updated_date": "2025-12-14 13:54:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:31.478417+00:00"
    },
    {
      "arxiv_id": "2510.25798v1",
      "title": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing",
      "title_zh": "MemEICï¼šè¿ˆå‘æŒç»­ä¸ç»„åˆå¼çŸ¥è¯†ç¼–è¾‘",
      "authors": [
        "Jin Seong",
        "Jiyun Park",
        "Wencke Liermann",
        "Hongseok Choi",
        "Yoonji Nam",
        "Hyun Kim",
        "Soojong Lim",
        "Namhoon Lee"
      ],
      "abstract": "The dynamic nature of information necessitates continuously updating large vision-language models (LVLMs). While recent knowledge editing techniques hint at promising directions, they often focus on editing a single modality (vision or language) in isolation. This prevalent practice neglects the inherent multimodality of LVLMs and the continuous nature of knowledge updates, potentially leading to suboptimal editing outcomes when considering the interplay between modalities and the need for ongoing knowledge refinement. To address these limitations, we propose MemEIC, a novel method for Continual and Compositional Knowledge Editing (CCKE) in LVLMs. MemEIC enables compositional editing of both visual and textual knowledge sequentially. Our approach employs a hybrid external-internal editor featuring a dual external memory for cross-modal evidence retrieval and dual LoRA adapters that facilitate disentangled parameter updates for each modality. A key component is a brain-inspired knowledge connector, activated selectively for compositional reasoning, that integrates information across different modalities. Experiments demonstrate that MemEIC significantly improves performance on complex multimodal questions and effectively preserves prior edits, setting a new benchmark for CCKE in LVLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MemEICï¼Œä¸€ç§é’ˆå¯¹å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)çš„æŒç»­ç»„åˆçŸ¥è¯†ç¼–è¾‘(Continual and Compositional Knowledge Editing, CCKE)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æŠ€æœ¯åœ¨å¤šæ¨¡æ€èåˆä¸è¿ç»­çŸ¥è¯†æ›´æ–°æ–¹é¢çš„å±€é™æ€§ã€‚MemEICé‡‡ç”¨äº†æ··åˆå†…å¤–éƒ¨ç¼–è¾‘å™¨ï¼Œé€šè¿‡åŒå¤–éƒ¨è®°å¿†(dual external memory)è¿›è¡Œè·¨æ¨¡æ€è¯æ®æ£€ç´¢ï¼Œå¹¶åˆ©ç”¨åŒLoRAé€‚é…å™¨(dual LoRA adapters)å®ç°å„æ¨¡æ€çš„è§£è€¦å‚æ•°æ›´æ–°ã€‚æ ¸å¿ƒç»„ä»¶æ˜¯ä¸€ä¸ªå—å¤§è„‘å¯å‘çš„çŸ¥è¯†è¿æ¥å™¨(knowledge connector)ï¼Œå®ƒèƒ½å¤Ÿé€‰æ‹©æ€§æ¿€æ´»ä»¥æ•´åˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼Œä»è€Œæ”¯æŒå¤æ‚çš„ç»„åˆæ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMemEICæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤æ‚å¤šæ¨¡æ€é—®é¢˜ä¸Šçš„è¡¨ç°ï¼Œå¹¶èƒ½æœ‰æ•ˆä¿ç•™ä¹‹å‰çš„ç¼–è¾‘æˆæœã€‚è¯¥æ–¹æ³•ä¸ºLVLMsåœ¨åŠ¨æ€çŸ¥è¯†ç¯å¢ƒä¸‹çš„æŒç»­è¿›åŒ–ä¸å¤šæ¨¡æ€çŸ¥è¯†ç»†åŒ–å»ºç«‹äº†æ–°çš„æŠ€æœ¯åŸºå‡†ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025, 38 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25798v1",
      "published_date": "2025-10-29 03:11:59 UTC",
      "updated_date": "2025-10-29 03:11:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:46.443951+00:00"
    },
    {
      "arxiv_id": "2510.25126v1",
      "title": "Bridging the Divide: End-to-End Sequence-Graph Learning",
      "title_zh": "å¼¥åˆé¸¿æ²Ÿï¼šç«¯åˆ°ç«¯åºåˆ—-å›¾å­¦ä¹ ",
      "authors": [
        "Yuen Chen",
        "Yulun Wu",
        "Samuel Sharpe",
        "Igor Melnyk",
        "Nam H. Nguyen",
        "Furong Huang",
        "C. Bayan Bruss",
        "Rizal Fathony"
      ],
      "abstract": "Many real-world datasets are both sequential and relational: each node carries an event sequence while edges encode interactions. Existing methods in sequence modeling and graph modeling often neglect one modality or the other. We argue that sequences and graphs are not separate problems but complementary facets of the same dataset, and should be learned jointly. We introduce BRIDGE, a unified end-to-end architecture that couples a sequence encoder with a GNN under a single objective, allowing gradients to flow across both modules and learning task-aligned representations. To enable fine-grained token-level message passing among neighbors, we add TOKENXATTN, a token-level cross-attention layer that passes messages between events in neighboring sequences. Across two settings, friendship prediction (Brightkite) and fraud detection (Amazon), BRIDGE consistently outperforms static GNNs, temporal graph methods, and sequence-only baselines on ranking and classification metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºè®¸å¤šç°å®ä¸–ç•Œçš„æ•°æ®é›†åŒæ—¶å…·å¤‡åºåˆ—æ€§å’Œå…³è”æ€§ï¼Œå³èŠ‚ç‚¹åŒ…å«äº‹ä»¶åºåˆ—ä¸”è¾¹ç¼–ç äº†äº¤äº’å…³ç³»ï¼Œä½†ç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†äº†å…¶ä¸­ä¸€ç§æ¨¡æ€ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº† BRIDGEï¼Œä¸€ç§å°†åºåˆ—ç¼–ç å™¨ä¸ GNN è€¦åˆåœ¨å•ä¸€ç›®æ ‡ä¸‹çš„ç»Ÿä¸€ç«¯åˆ°ç«¯æ¶æ„ï¼Œå®ç°äº†åºåˆ—ä¸å›¾ç»“æ„çš„è”åˆå­¦ä¹ ã€‚è¯¥æ¶æ„å…è®¸æ¢¯åº¦åœ¨ä¸¤ä¸ªæ¨¡å—ä¹‹é—´æµåŠ¨ï¼Œä»è€Œå­¦ä¹ ä¸ä»»åŠ¡å¯¹é½çš„è¡¨ç¤ºã€‚ä¸ºäº†åœ¨é‚»å±…ä¹‹é—´å®ç°ç»†ç²’åº¦çš„ token çº§åˆ«æ¶ˆæ¯ä¼ é€’ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº† TOKENXATTN è·¨æ³¨æ„åŠ›å±‚ï¼Œç”¨äºåœ¨ç›¸é‚»åºåˆ—çš„äº‹ä»¶ä¹‹é—´ä¼ é€’ä¿¡æ¯ã€‚åœ¨ Brightkite å¥½å‹é¢„æµ‹å’Œ Amazon æ¬ºè¯ˆæ£€æµ‹æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBRIDGE åœ¨æ’åºå’Œåˆ†ç±»æŒ‡æ ‡ä¸Šä¸€è‡´ä¼˜äºé™æ€ GNNã€æ—¶åºå›¾æ–¹æ³•ä»¥åŠä»…ä½¿ç”¨åºåˆ—çš„åŸºå‡†æ¨¡å‹ã€‚è¯¥ç ”ç©¶æˆåŠŸæ¡¥æ¥äº†åºåˆ—ä¸å›¾å»ºæ¨¡çš„é¸¿æ²Ÿï¼Œä¸ºå¤„ç†å¤æ‚çš„å…³è”æ—¶åºæ•°æ®æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25126v1",
      "published_date": "2025-10-29 03:06:54 UTC",
      "updated_date": "2025-10-29 03:06:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:48.334252+00:00"
    },
    {
      "arxiv_id": "2510.25123v2",
      "title": "Learning Low Rank Neural Representations of Hyperbolic Wave Dynamics from Data",
      "title_zh": "ä»æ•°æ®ä¸­å­¦ä¹ åŒæ›²æ³¢åŠ¨åŠ›å­¦çš„ä½ç§©ç¥ç»è¡¨ç¤º",
      "authors": [
        "Woojin Cho",
        "Kookjin Lee",
        "Noseong Park",
        "Donsub Rim",
        "Gerrit Welper"
      ],
      "abstract": "We present a data-driven dimensionality reduction method that is well-suited for physics-based data representing hyperbolic wave propagation. The method utilizes a specialized neural network architecture called low rank neural representation (LRNR) inside a hypernetwork framework. The architecture is motivated by theoretical results that rigorously prove the existence of efficient representations for this wave class. We illustrate through archetypal examples that such an efficient low-dimensional representation of propagating waves can be learned directly from data through a combination of deep learning techniques. We observe that a low rank tensor representation arises naturally in the trained LRNRs, and that this reveals a new decomposition of wave propagation where each decomposed mode corresponds to interpretable physical features. Furthermore, we demonstrate that the LRNR architecture enables efficient inference via a compression scheme, which is a potentially important feature when deploying LRNRs in demanding performance regimes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ä¸“ä¸ºç‰©ç†æ•°æ®è®¾è®¡çš„æ•°æ®é©±åŠ¨é™ç»´æ–¹æ³•ï¼Œç”¨äºå­¦ä¹ åŒæ›²æ³¢åŠ¨åŠ›å­¦(hyperbolic wave dynamics)çš„é«˜æ•ˆè¡¨ç¤ºã€‚è¯¥æ–¹æ³•åœ¨è¶…ç½‘ç»œ(hypernetwork)æ¡†æ¶å†…é‡‡ç”¨äº†ä¸€ç§åä¸ºä½ç§©ç¥ç»è¡¨ç¤º(low rank neural representation, LRNR)çš„ç‰¹æ®Šç¥ç»ç½‘ç»œæ¶æ„ï¼Œå…¶è®¾è®¡å—åˆ°è¯æ˜è¯¥ç±»æ³¢åŠ¨å­˜åœ¨é«˜æ•ˆè¡¨ç¤ºçš„ç†è®ºç»“æœå¯å‘ã€‚é€šè¿‡å…¸å‹æ¡ˆä¾‹ç ”ç©¶è¯æ˜ï¼Œç»“åˆæ·±åº¦å­¦ä¹ æŠ€æœ¯å¯ä»¥ä»æ•°æ®ä¸­ç›´æ¥å­¦ä¹ ä¼ æ’­æ³¢çš„é«˜æ•ˆä½ç»´è¡¨ç¤ºã€‚ç ”ç©¶å‘ç°è®­ç»ƒåçš„ LRNR ä¼šè‡ªç„¶äº§ç”Ÿä½ç§©å¼ é‡è¡¨ç¤º(low rank tensor representation)ï¼Œä»è€Œæ­ç¤ºäº†æ³¢ä¼ æ’­çš„ä¸€ç§æ–°å‹åˆ†è§£æ–¹å¼ï¼Œä¸”æ¯ä¸ªåˆ†è§£æ¨¡å¼éƒ½å¯¹åº”å¯è§£é‡Šçš„ç‰©ç†ç‰¹å¾(interpretable physical features)ã€‚æ­¤å¤–ï¼ŒLRNR æ¶æ„è¿˜é€šè¿‡å‹ç¼©æ–¹æ¡ˆ(compression scheme)å®ç°äº†é«˜æ•ˆæ¨ç†ï¼Œè¿™ä¸ºå…¶åœ¨å¯¹æ€§èƒ½è¦æ±‚ä¸¥è‹›çš„å®é™…åœºæ™¯ä¸­éƒ¨ç½²æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "41 pages, 18 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25123v2",
      "published_date": "2025-10-29 03:01:09 UTC",
      "updated_date": "2025-11-03 22:22:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:30:52.540137+00:00"
    },
    {
      "arxiv_id": "2510.25113v1",
      "title": "The Neural Differential Manifold: An Architecture with Explicit Geometric Structure",
      "title_zh": "ç¥ç»å¾®åˆ†æµå½¢ï¼šä¸€ç§å…·æœ‰æ˜¾å¼å‡ ä½•ç»“æ„çš„æ¶æ„",
      "authors": [
        "Di Zhang"
      ],
      "abstract": "This paper introduces the Neural Differential Manifold (NDM), a novel neural network architecture that explicitly incorporates geometric structure into its fundamental design. Departing from conventional Euclidean parameter spaces, the NDM re-conceptualizes a neural network as a differentiable manifold where each layer functions as a local coordinate chart, and the network parameters directly parameterize a Riemannian metric tensor at every point. The architecture is organized into three synergistic layers: a Coordinate Layer implementing smooth chart transitions via invertible transformations inspired by normalizing flows, a Geometric Layer that dynamically generates the manifold's metric through auxiliary sub-networks, and an Evolution Layer that optimizes both task performance and geometric simplicity through a dual-objective loss function. This geometric regularization penalizes excessive curvature and volume distortion, providing intrinsic regularization that enhances generalization and robustness. The framework enables natural gradient descent optimization aligned with the learned manifold geometry and offers unprecedented interpretability by endowing internal representations with clear geometric meaning. We analyze the theoretical advantages of this approach, including its potential for more efficient optimization, enhanced continual learning, and applications in scientific discovery and controllable generative modeling. While significant computational challenges remain, the Neural Differential Manifold represents a fundamental shift towards geometrically structured, interpretable, and efficient deep learning systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Neural Differential Manifold (NDM)ï¼Œè¿™æ˜¯ä¸€ç§å°†å‡ ä½•ç»“æ„æ˜ç¡®èå…¥åŸºç¡€è®¾è®¡çš„æ–°å‹ç¥ç»ç½‘ç»œæ¶æ„ã€‚è¯¥æ¶æ„å°†ç¥ç»ç½‘ç»œé‡æ–°æ¦‚å¿µåŒ–ä¸ºå¯å¾®æµå½¢(differentiable manifold)ï¼Œé€šè¿‡Coordinate Layerå®ç°åŸºäºnormalizing flowsçš„å¹³æ»‘åæ ‡è½¬æ¢ï¼Œå¹¶ç”±Geometric LayeråŠ¨æ€ç”ŸæˆRiemannian metric tensorã€‚Evolution Layeré€šè¿‡åŒç›®æ ‡æŸå¤±å‡½æ•°åŒæ—¶ä¼˜åŒ–ä»»åŠ¡æ€§èƒ½ä¸å‡ ä½•ç®€æ´æ€§ï¼Œåˆ©ç”¨å‡ ä½•æ­£åˆ™åŒ–(geometric regularization)æƒ©ç½šè¿‡åº¦çš„æ›²ç‡å’Œä½“ç§¯ç•¸å˜ï¼Œä»è€Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä¸é²æ£’æ€§ã€‚NDMæ”¯æŒä¸å­¦ä¹ åˆ°çš„æµå½¢å‡ ä½•å¯¹é½çš„è‡ªç„¶æ¢¯åº¦ä¸‹é™(Natural Gradient Descent)ä¼˜åŒ–ï¼Œå¹¶èµ‹äºˆå†…éƒ¨è¡¨ç¤ºæ¸…æ™°çš„å‡ ä½•æ„ä¹‰ï¼Œå¤§å¹…æå‡äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æé«˜ä¼˜åŒ–æ•ˆç‡å’Œå¢å¼ºæŒç»­å­¦ä¹ (continual learning)èƒ½åŠ›æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚è¯¥ç ”ç©¶æ ‡å¿—ç€æ·±åº¦å­¦ä¹ ç³»ç»Ÿå‘å‡ ä½•ç»“æ„åŒ–ã€å¯è§£é‡Šä¸”é«˜æ•ˆçš„æ¶æ„è¿ˆå‡ºäº†æ ¹æœ¬æ€§çš„ä¸€æ­¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DG",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.25113v1",
      "published_date": "2025-10-29 02:24:27 UTC",
      "updated_date": "2025-10-29 02:24:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:31:05.923479+00:00"
    },
    {
      "arxiv_id": "2510.25101v2",
      "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA",
      "title_zh": "KnowCoder-A1ï¼šåˆ©ç”¨ç»“æœç›‘ç£å¼ºåŒ– KBQA çš„æ™ºèƒ½ä½“æ¨ç†èƒ½åŠ›",
      "authors": [
        "Zhuo Chen",
        "Fei Wang",
        "Zixuan Li",
        "Zhao Zhang",
        "Weiwei Ding",
        "Chuanguang Yang",
        "Yongjun Xu",
        "Xiaolong Jin",
        "Jiafeng Guo"
      ],
      "abstract": "Knowledge Base Question Answering (KBQA) aims to answer natural-language questions over a structured Knowledge Base (KB). Recent work improves KBQA by adopting an agentic reasoning paradigm, in which Large Language Models (LLMs) iteratively decompose a question, generate its corresponding logical queries, and interact with the KB to derive the answer. However, these methods typically fine-tune LLMs on reasoning trajectories synthesized via process supervision, which offers weak incentives for exploration and thus fails to strengthen the agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that can autonomously perform agentic reasoning on KBs to obtain answers. To incentivize autonomous exploration, KnowCoder-A1 trains the LLM under outcome-only supervision via a multi-stage curriculum reinforcement learning with an easy-to-hard curriculum. To establish foundational agentic capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of high-quality trajectories obtained through outcome-based rejection sampling. Then, to alleviate the reward sparsity inherent in outcome-only supervision, it applies multi-stage curriculum RL with reward schedules that progress from easy to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful reasoning behaviors and consistently outperforms prior approaches across three mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1 achieves up to an 11.1% relative improvement while using only one-twelfth of the training data, demonstrating strong agentic reasoning capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† KnowCoder-A1ï¼Œæ—¨åœ¨é€šè¿‡ Outcome Supervision æ¿€åŠ± Knowledge Base Question Answering (KBQA) ä¸­çš„ Agentic Reasoning èƒ½åŠ›ã€‚é’ˆå¯¹ä¼ ç»Ÿè¿‡ç¨‹ç›‘ç£ (Process Supervision) å¯¹æ¢ç´¢æ¿€åŠ±ä¸è¶³çš„é—®é¢˜ï¼ŒKnowCoder-A1 é‡‡ç”¨äº†åŸºäº Outcome-only Supervision çš„å¤šé˜¶æ®µè¯¾ç¨‹å¼ºåŒ–å­¦ä¹  (Multi-stage Curriculum Reinforcement Learning) æ¡†æ¶ã€‚ç ”ç©¶é¦–å…ˆé€šè¿‡åŸºäºç»“æœçš„æ‹’ç»é‡‡æ · (Outcome-based Rejection Sampling) è·å¾—çš„é«˜è´¨é‡è½¨è¿¹å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥å»ºç«‹åŸºç¡€èƒ½åŠ›ï¼Œéšååˆ©ç”¨ç”±æ˜“åˆ°éš¾çš„å¥–åŠ±è®¡åˆ’ (Reward Schedules) ç¼“è§£å¥–åŠ±ç¨€ç–æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKnowCoder-A1 åœ¨ä¸‰ä¸ªä¸»æµæ•°æ®é›†ä¸Šå‡ä¸€è‡´ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨ GrailQA çš„ Zero-shot å­é›†ä¸Šï¼Œè¯¥æ¨¡å‹ä»…ä½¿ç”¨åäºŒåˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®ä¾¿å®ç°äº† 11.1% çš„ç›¸å¯¹æå‡ï¼Œå……åˆ†å±•ç¤ºäº†å…¶å¼ºå¤§çš„è‡ªä¸»ä»£ç†æ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25101v2",
      "published_date": "2025-10-29 02:12:18 UTC",
      "updated_date": "2025-11-18 04:15:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:31:01.695942+00:00"
    },
    {
      "arxiv_id": "2510.25096v1",
      "title": "Learning Fair Graph Representations with Multi-view Information Bottleneck",
      "title_zh": "åŸºäºå¤šè§†å›¾ä¿¡æ¯ç“¶é¢ˆçš„å…¬å¹³å›¾è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Chuxun Liu",
        "Debo Cheng",
        "Qingfeng Chen",
        "Jiangzhang Gan",
        "Jiuyong Li",
        "Lin Liu"
      ],
      "abstract": "Graph neural networks (GNNs) excel on relational data by passing messages over node features and structure, but they can amplify training data biases, propagating discriminatory attributes and structural imbalances into unfair outcomes. Many fairness methods treat bias as a single source, ignoring distinct attribute and structure effects and leading to suboptimal fairness and utility trade-offs. To overcome this challenge, we propose FairMIB, a multi-view information bottleneck framework designed to decompose graphs into feature, structural, and diffusion views for mitigating complexity biases in GNNs. Especially, the proposed FairMIB employs contrastive learning to maximize cross-view mutual information for bias-free representation learning. It further integrates multi-perspective conditional information bottleneck objectives to balance task utility and fairness by minimizing mutual information with sensitive attributes. Additionally, FairMIB introduces an inverse probability-weighted (IPW) adjacency correction in the diffusion view, which reduces the spread of bias propagation during message passing. Experiments on five real-world benchmark datasets demonstrate that FairMIB achieves state-of-the-art performance across both utility and fairness metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FairMIBï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤šè§†å›¾ä¿¡æ¯ç“¶é¢ˆ (Multi-view Information Bottleneck) çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å›¾ç¥ç»ç½‘ç»œ (GNNs) åœ¨å¤„ç†å…³ç³»æ•°æ®æ—¶å¯èƒ½æ”¾å¤§è®­ç»ƒæ•°æ®åè§çš„é—®é¢˜ã€‚FairMIB å°†å›¾åˆ†è§£ä¸ºç‰¹å¾ã€ç»“æ„å’Œæ‰©æ•£è§†å›¾ï¼Œé€šè¿‡è§£è€¦ä¸åŒçš„åè§æ¥æºæ¥ä¼˜åŒ–å…¬å¹³æ€§ä¸æ•ˆç”¨ä¹‹é—´çš„æƒè¡¡ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¯¹æ¯”å­¦ä¹  (Contrastive Learning) æœ€å¤§åŒ–è·¨è§†å›¾äº’ä¿¡æ¯ä»¥å®ç°æ— åè¡¨å¾å­¦ä¹ ï¼Œå¹¶ç»“åˆå¤šè§†è§’æ¡ä»¶ä¿¡æ¯ç“¶é¢ˆç›®æ ‡ï¼Œåœ¨æœ€å°åŒ–ä¸æ•æ„Ÿå±æ€§äº’ä¿¡æ¯çš„åŒæ—¶ä¿ç•™ä»»åŠ¡ç›¸å…³ä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒFairMIB åœ¨æ‰©æ•£è§†å›¾ä¸­å¼•å…¥äº†é€†æ¦‚ç‡åŠ æƒ (Inverse Probability-Weighted, IPW) é‚»æ¥æ ¡æ­£ï¼Œæœ‰æ•ˆæŠ‘åˆ¶äº†æ¶ˆæ¯ä¼ é€’è¿‡ç¨‹ä¸­çš„åè§ä¼ æ’­ã€‚åœ¨äº”ä¸ªçœŸå®ä¸–ç•ŒåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒFairMIB åœ¨æ•ˆç”¨å’Œå…¬å¹³æ€§æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿› (State-of-the-art) çš„æ°´å¹³ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25096v1",
      "published_date": "2025-10-29 02:02:12 UTC",
      "updated_date": "2025-10-29 02:02:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:31:02.230245+00:00"
    },
    {
      "arxiv_id": "2510.25091v1",
      "title": "H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts",
      "title_zh": "H3M-SSMoEsï¼šç»“åˆ LLM æ¨ç†ä¸é£æ ¼ç»“æ„åŒ–æ··åˆä¸“å®¶æ¨¡å‹çš„è¶…å›¾å¤šæ¨¡æ€å­¦ä¹ ",
      "authors": [
        "Peilin Tan",
        "Liang Xie",
        "Churan Zhi",
        "Dian Tu",
        "Chuanqi Shi"
      ],
      "abstract": "Stock movement prediction remains fundamentally challenging due to complex temporal dependencies, heterogeneous modalities, and dynamically evolving inter-stock relationships. Existing approaches often fail to unify structural, semantic, and regime-adaptive modeling within a scalable framework. This work introduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with LLM reasoning and Style-Structured Mixture of Experts, integrating three key innovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically captures fine-grained spatiotemporal dynamics via a Local Context Hypergraph (LCH) and persistent inter-stock dependencies through a Global Context Hypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon Divergence weighting mechanism for adaptive relational learning and cross-modal alignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large language model with lightweight adapters to semantically fuse and align quantitative and textual modalities, enriching representations with domain-specific financial knowledge; and (3) a Style-Structured Mixture of Experts (SSMoEs) that combines shared market experts and industry-specialized experts, each parameterized by learnable style vectors enabling regime-aware specialization under sparse activation. Extensive experiments on three major stock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in both superior predictive accuracy and investment performance, while exhibiting effective risk control. Datasets, source code, and model weights are available at our GitHub repository: https://github.com/PeilinTime/H3M-SSMoEs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†H3M-SSMoEsï¼Œä¸€ç§åŸºäºHypergraphã€LLMæ¨ç†å’ŒStyle-Structured Mixture of Experts (SSMoEs)çš„å¤šæ¨¡æ€å­¦ä¹ æ¶æ„ï¼Œæ—¨åœ¨è§£å†³è‚¡ç¥¨é¢„æµ‹ä¸­å¤æ‚çš„æ—¶ç©ºä¾èµ–å’Œå¼‚æ„æ¨¡æ€èåˆæŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†å¤šä¸Šä¸‹æ–‡å¤šæ¨¡æ€è¶…å›¾ï¼Œé€šè¿‡Local Context Hypergraph (LCH)å’ŒGlobal Context Hypergraph (GCH)æ•æ‰ç»†ç²’åº¦çš„æ—¶ç©ºåŠ¨æ€å’ŒæŒä¹…çš„è‚¡ç¥¨é—´å…³ç³»ï¼Œå¹¶åˆ©ç”¨Jensen-Shannon Divergenceæƒé‡æœºåˆ¶å®ç°è‡ªé€‚åº”è·¨æ¨¡æ€å¯¹é½ã€‚æ­¤å¤–ï¼Œæ¶æ„é›†æˆäº†LLMå¢å¼ºæ¨ç†æ¨¡å—ï¼Œé€šè¿‡å†»ç»“çš„å¤§è¯­è¨€æ¨¡å‹å’Œè½»é‡åŒ–é€‚é…å™¨è¯­ä¹‰å¯¹é½å®šé‡ä¸æ–‡æœ¬æ¨¡æ€ï¼Œæ˜¾è‘—å¢å¼ºäº†é¢†åŸŸé‡‘èçŸ¥è¯†çš„è¡¨ç¤ºèƒ½åŠ›ã€‚ä¸ºäº†åº”å¯¹åŠ¨æ€å¸‚åœºç¯å¢ƒï¼ŒSSMoEsæ¨¡å—ç»“åˆäº†å¸‚åœºå…±äº«ä¸“å®¶ä¸è¡Œä¸šä¸“ç”¨ä¸“å®¶ï¼Œå¹¶åˆ©ç”¨å¯å­¦ä¹ çš„é£æ ¼å‘é‡åœ¨ç¨€ç–æ¿€æ´»ä¸‹å®ç°å¸‚åœºçŠ¶æ€è‡ªé€‚åº”ã€‚åœ¨ä¸‰å¤§ä¸»æµè‚¡ç¥¨å¸‚åœºä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒH3M-SSMoEsåœ¨é¢„æµ‹å‡†ç¡®ç‡ã€æŠ•èµ„å›æŠ¥åŠé£é™©æ§åˆ¶èƒ½åŠ›ä¸Šå‡æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰SOTAæ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25091v1",
      "published_date": "2025-10-29 01:54:52 UTC",
      "updated_date": "2025-10-29 01:54:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:31:06.387879+00:00"
    },
    {
      "arxiv_id": "2510.25080v2",
      "title": "Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games",
      "title_zh": "Monopoly Dealï¼šæœ‰ç•Œå•å‘å“åº”åšå¼ˆçš„åŸºå‡†ç¯å¢ƒ",
      "authors": [
        "Will Wolf"
      ],
      "abstract": "Card games are widely used to study sequential decision-making under uncertainty, with real-world analogues in negotiation, finance, and cybersecurity. These games typically fall into three categories based on the flow of control: strictly sequential (players alternate single actions), deterministic response (some actions trigger a fixed outcome), and unbounded reciprocal response (alternating counterplays are permitted). A less-explored but strategically rich structure is the bounded one-sided response, where a player's action briefly transfers control to the opponent, who must satisfy a fixed condition through one or more moves before the turn resolves. We term games featuring this mechanism Bounded One-Sided Response Games (BORGs). We introduce a modified version of Monopoly Deal as a benchmark environment that isolates this dynamic, where a Rent action forces the opponent to choose payment assets. The gold-standard algorithm, Counterfactual Regret Minimization (CFR), converges on effective strategies without novel algorithmic extensions. A lightweight full-stack research platform unifies the environment, a parallelized CFR runtime, and a human-playable web interface. The trained CFR agent and source code are available at https://monopolydeal.ai.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸ç¡®å®šæ€§ä¸‹çš„åºåˆ—å†³ç­–é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç±»è¢«ç§°ä¸ºæœ‰ç•Œå•ä¾§å“åº”åšå¼ˆ (Bounded One-Sided Response Games, BORGs) çš„æ–°æˆ˜ç•¥ç»“æ„ã€‚åœ¨è¿™ç§æœºåˆ¶ä¸­ï¼Œç©å®¶çš„è¡ŒåŠ¨ä¼šæš‚æ—¶å°†æ§åˆ¶æƒè½¬ç§»ç»™å¯¹æ‰‹ï¼Œå¯¹æ‰‹å¿…é¡»åœ¨å›åˆç»“æŸå‰é€šè¿‡ä¸€ç³»åˆ—æ“ä½œæ»¡è¶³å›ºå®šæ¡ä»¶ã€‚ä½œè€…é€šè¿‡ä¿®æ”¹ Monopoly Deal å¡ç‰Œæ¸¸æˆæ„å»ºäº†ä¸€ä¸ªåŸºå‡†ç¯å¢ƒï¼Œåˆ©ç”¨å…¶ä¸­çš„â€œç§Ÿé‡‘â€(Rent) è¡ŒåŠ¨æ¥å­¤ç«‹å¹¶ç ”ç©¶è¿™ç§ç‹¬ç‰¹çš„åšå¼ˆåŠ¨æ€ã€‚ç ”ç©¶è¿˜æä¾›äº†ä¸€ä¸ªé›†æˆäº†å¹¶è¡ŒåŒ–åäº‹å®é—æ†¾æœ€å°åŒ– (Counterfactual Regret Minimization, CFR) è¿è¡Œæ—¶å’Œ Web äº¤äº’ç•Œé¢çš„è½»é‡çº§å…¨æ ˆç ”ç©¶å¹³å°ã€‚å®éªŒè¯æ˜ï¼Œæ ‡å‡† CFR ç®—æ³•èƒ½å¤Ÿåœ¨ä¸éœ€è¦é¢å¤–ç®—æ³•æ‰©å±•çš„æƒ…å†µä¸‹æœ‰æ•ˆæ”¶æ•›å¹¶ç”Ÿæˆå¼ºå¤§ç­–ç•¥ã€‚è¯¥å·¥ä½œä¸ä»…å®šä¹‰äº† BORGs è¿™ä¸€åšå¼ˆç±»å‹ï¼Œè¿˜ä¸ºç ”ç©¶æ­¤ç±»å…·æœ‰æŒ‘æˆ˜æ€§çš„æˆ˜ç•¥äº’åŠ¨æä¾›äº†å¼€æºçš„è®­ç»ƒæ™ºèƒ½ä½“å’Œå®è¯åŸºç¡€ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "24 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.25080v2",
      "published_date": "2025-10-29 01:38:19 UTC",
      "updated_date": "2025-10-30 12:16:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:31:04.571982+00:00"
    },
    {
      "arxiv_id": "2510.25065v1",
      "title": "Reasoning-Aware GRPO using Process Mining",
      "title_zh": "åŸºäºæµç¨‹æŒ–æ˜çš„æ¨ç†æ„ŸçŸ¥ GRPO",
      "authors": [
        "Taekhyun Park",
        "Yongjae Lee",
        "Hyerim Bae"
      ],
      "abstract": "Reinforcement learning (RL)-based post-training has been crucial for enabling multi-step reasoning in large reasoning models (LRMs), yet current reward schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware Group Relative Policy Optimization (GRPO) that augments standard answer/format rewards with signals over the reasoning procedure. To this end, process mining techniques are utilized to compute a scalar conformance reward that measures how closely a policy model's reasoning aligns with the pretrained teacher model. The empirical results on five benchmarks demonstrate that PM4GRPO significantly outperforms existing methodologies for GRPO-based post-training. These results highlight that leveraging process mining for reasoning-aware GRPO effectively enhances the reasoning capabilities of policy models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PM4GRPOï¼Œä¸€ç§å…·æœ‰æ¨ç†æ„ŸçŸ¥èƒ½åŠ›çš„ Group Relative Policy Optimization (GRPO) æ¡†æ¶ï¼Œæ—¨åœ¨ä¼˜åŒ–å¤§å‹æ¨ç†æ¨¡å‹ (LRMs) åœ¨åè®­ç»ƒé˜¶æ®µä¸­è¿‡äºä¾§é‡ç»“æœçš„å¥–åŠ±æœºåˆ¶ã€‚PM4GRPO å¼•å…¥äº†è¿‡ç¨‹æŒ–æ˜ (Process Mining) æŠ€æœ¯ï¼Œé€šè¿‡è®¡ç®—ç­–ç•¥æ¨¡å‹ä¸é¢„è®­ç»ƒæ•™å¸ˆæ¨¡å‹æ¨ç†é€»è¾‘ä¹‹é—´çš„æ ‡é‡ä¸€è‡´æ€§å¥–åŠ± (conformance reward)ï¼Œä¸ºæ ‡å‡†çš„ç­”æ¡ˆå’Œæ ¼å¼å¥–åŠ±è¡¥å……äº†æ¨ç†è¿‡ç¨‹ä¿¡å·ã€‚åœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒPM4GRPO æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºäº GRPO çš„åè®­ç»ƒæ–¹æ³•ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†åˆ©ç”¨è¿‡ç¨‹æŒ–æ˜å®ç°æ¨ç†æ„ŸçŸ¥çš„ GRPO èƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºç­–ç•¥æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œä¸ºæå‡å¤æ‚æ¨ç†ä»»åŠ¡çš„è¡¨ç°æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25065v1",
      "published_date": "2025-10-29 01:07:45 UTC",
      "updated_date": "2025-10-29 01:07:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:31:15.037855+00:00"
    },
    {
      "arxiv_id": "2510.25055v1",
      "title": "GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using Large Language Models",
      "title_zh": "GAPMAPï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¯†åˆ«ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®ä¸­çš„ç§‘å­¦çŸ¥è¯†ç©ºç™½",
      "authors": [
        "Nourah M Salem",
        "Elizabeth White",
        "Michael Bada",
        "Lawrence Hunter"
      ],
      "abstract": "Scientific progress is driven by the deliberate articulation of what remains unknown. This study investigates the ability of large language models (LLMs) to identify research knowledge gaps in the biomedical literature. We define two categories of knowledge gaps: explicit gaps, clear declarations of missing knowledge; and implicit gaps, context-inferred missing knowledge. While prior work has focused mainly on explicit gap detection, we extend this line of research by addressing the novel task of inferring implicit gaps. We conducted two experiments on almost 1500 documents across four datasets, including a manually annotated corpus of biomedical articles. We benchmarked both closed-weight models (from OpenAI) and open-weight models (Llama and Gemma 2) under paragraph-level and full-paper settings. To address the reasoning of implicit gaps inference, we introduce \\textbf{\\small TABI}, a Toulmin-Abductive Bucketed Inference scheme that structures reasoning and buckets inferred conclusion candidates for validation. Our results highlight the robust capability of LLMs in identifying both explicit and implicit knowledge gaps. This is true for both open- and closed-weight models, with larger variants often performing better. This suggests a strong ability of LLMs for systematically identifying candidate knowledge gaps, which can support early-stage research formulation, policymakers, and funding decisions. We also report observed failure modes and outline directions for robust deployment, including domain adaptation, human-in-the-loop verification, and benchmarking across open- and closed-weight models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) åœ¨è¯†åˆ«ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®ä¸­ç ”ç©¶çŸ¥è¯†å·®è· (knowledge gaps) çš„èƒ½åŠ›ï¼Œå¹¶å°†å…¶ç»†åˆ†ä¸ºæ˜¾æ€§å·®è· (explicit gaps) å’Œéšæ€§å·®è· (implicit gaps) ä¸¤ç±»ã€‚ä¸ºäº†è§£å†³éšæ€§å·®è·æ¨æ–­ä¸­çš„å¤æ‚æ¨ç†é—®é¢˜ï¼Œç ”ç©¶è€…å¼•å…¥äº† TABI (Toulmin-Abductive Bucketed Inference) æ¨ç†æ–¹æ¡ˆï¼Œç”¨äºç»“æ„åŒ–æ¨ç†å¹¶éªŒè¯å€™é€‰ç»“è®ºã€‚å®éªŒåœ¨åŒ…å«è¿‘ 1500 ç¯‡æ–‡æ¡£çš„å››ä¸ªæ•°æ®é›†ä¸Šå¯¹ OpenAIã€Llama å’Œ Gemma 2 ç­‰æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œç»“æœè¯æ˜äº† LLMs åœ¨è¯†åˆ«è¿™ä¸¤ç±»å·®è·æ–¹é¢çš„é²æ£’æ€§ã€‚ç ”ç©¶å‘ç°æ¨¡å‹è§„æ¨¡é€šå¸¸ä¸æ€§èƒ½å‘ˆæ­£ç›¸å…³ï¼Œè¡¨æ˜ LLMs èƒ½å¤Ÿç³»ç»Ÿåœ°è¾…åŠ©æ—©æœŸç ”ç©¶æ„æ€ã€æ”¿ç­–åˆ¶å®šåŠèµ„åŠ©å†³ç­–ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡åˆ†æå¤±è´¥æ¨¡å¼ï¼Œä¸ºæœªæ¥é¢†åŸŸè‡ªé€‚åº” (domain adaptation) å’Œäººå·¥ç¯è·¯éªŒè¯ (human-in-the-loop verification) çš„éƒ¨ç½²æä¾›äº†æŒ‡å¯¼æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25055v1",
      "published_date": "2025-10-29 00:46:45 UTC",
      "updated_date": "2025-10-29 00:46:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:31:17.639890+00:00"
    },
    {
      "arxiv_id": "2510.25053v1",
      "title": "Scalable predictive processing framework for multitask caregiving robots",
      "title_zh": "é¢å‘å¤šä»»åŠ¡æŠ¤ç†æœºå™¨äººçš„å¯æ‰©å±•é¢„æµ‹å¤„ç†æ¡†æ¶",
      "authors": [
        "Hayato Idei",
        "Tamon Miyake",
        "Tetsuya Ogata",
        "Yuichi Yamashita"
      ],
      "abstract": "The rapid aging of societies is intensifying demand for autonomous care robots; however, most existing systems are task-specific and rely on handcrafted preprocessing, limiting their ability to generalize across diverse scenarios. A prevailing theory in cognitive neuroscience proposes that the human brain operates through hierarchical predictive processing, which underlies flexible cognition and behavior by integrating multimodal sensory signals. Inspired by this principle, we introduce a hierarchical multimodal recurrent neural network grounded in predictive processing under the free-energy principle, capable of directly integrating over 30,000-dimensional visuo-proprioceptive inputs without dimensionality reduction. The model was able to learn two representative caregiving tasks, rigid-body repositioning and flexible-towel wiping, without task-specific feature engineering. We demonstrate three key properties: (i) self-organization of hierarchical latent dynamics that regulate task transitions, capture variability in uncertainty, and infer occluded states; (ii) robustness to degraded vision through visuo-proprioceptive integration; and (iii) asymmetric interference in multitask learning, where the more variable wiping task had little influence on repositioning, whereas learning the repositioning task led to a modest reduction in wiping performance, while the model maintained overall robustness. Although the evaluation was limited to simulation, these results establish predictive processing as a universal and scalable computational principle, pointing toward robust, flexible, and autonomous caregiving robots while offering theoretical insight into the human brain's ability to achieve flexible adaptation in uncertain real-world environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è€é¾„åŒ–ç¤¾ä¼šå¯¹è‡ªä¸»æŠ¤ç†æœºå™¨äººæ—¥ç›Šå¢é•¿çš„éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§å—è®¤çŸ¥ç¥ç»ç§‘å­¦å¯å‘çš„å¯æ‰©å±•å±‚æ¬¡åŒ–å¤šæ¨¡æ€é¢„æµ‹å¤„ç†(predictive processing)æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŸºäºè‡ªç”±èƒ½åŸç†(free-energy principle)ï¼Œåˆ©ç”¨å±‚æ¬¡åŒ–å¤šæ¨¡æ€å¾ªç¯ç¥ç»ç½‘ç»œ(multimodal recurrent neural network)ç›´æ¥æ•´åˆè¶…è¿‡30,000ç»´çš„è§†è§‰-æœ¬ä½“æ„Ÿå—(visuo-proprioceptive)è¾“å…¥ï¼Œä¸”æ— éœ€é™ç»´å¤„ç†ã€‚æ¨¡å‹åœ¨æ²¡æœ‰ç‰¹å®šä»»åŠ¡ç‰¹å¾å·¥ç¨‹çš„æƒ…å†µä¸‹ï¼ŒæˆåŠŸå­¦ä¹ äº†åˆšä½“é‡æ–°å®šä½å’ŒæŸ”æ€§æ¯›å·¾æ“¦æ‹­ä¸¤é¡¹ä»£è¡¨æ€§æŠ¤ç†ä»»åŠ¡ã€‚å®éªŒå±•ç¤ºäº†å±‚æ¬¡åŒ–æ½œåŠ¨åŠ›å­¦(latent dynamics)çš„è‡ªç»„ç»‡ç‰¹æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè°ƒèŠ‚ä»»åŠ¡è½¬æ¢ã€æ•æ‰ä¸ç¡®å®šæ€§å¹¶æ¨æ–­é®æŒ¡çŠ¶æ€ã€‚é€šè¿‡è§†è§‰-æœ¬ä½“æ„Ÿå—æ•´åˆï¼Œè¯¥æ¨¡å‹åœ¨è§†è§‰è´¨é‡ä¸‹é™æ—¶è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§(robustness)ã€‚ç ”ç©¶è¿˜æ­ç¤ºäº†å¤šä»»åŠ¡å­¦ä¹ ä¸­çš„ä¸å¯¹ç§°å¹²æ‰°ç°è±¡ï¼Œå¹¶éªŒè¯äº†æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é€‚åº”èƒ½åŠ›ã€‚è¯¥æˆæœç¡®ç«‹äº†é¢„æµ‹å¤„ç†ä½œä¸ºé€šç”¨ä¸”å¯æ‰©å±•è®¡ç®—åŸåˆ™çš„åœ°ä½ï¼Œä¸ºå¼€å‘çµæ´»è‡ªä¸»çš„æŠ¤ç†æœºå™¨äººå¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25053v1",
      "published_date": "2025-10-29 00:39:09 UTC",
      "updated_date": "2025-10-29 00:39:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T06:31:30.744204+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 151,
  "processed_papers_count": 151,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-25T06:32:19.334611+00:00"
}