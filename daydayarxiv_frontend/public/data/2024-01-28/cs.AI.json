{
  "date": "2024-01-28",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-28 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习的应用创新，包括生成模型的统计优化、LLM 在硬件调试和任务导向对话中的潜力，以及公里级全球天气预报等实用技术，其中 FengWu-GHR 和 GANs 相关研究尤为令人印象深刻，同时 Peter L. Bartlett 等知名学者参与的论文值得关注。\n\n### 重点论文亮点\n以下挑选并简要讨论今日的 arXiv 论文，我将优先关注那些创新性强、可能引发话题的文章（如 AI 生成模型和实际应用），并将相关主题归类。其他较常规或特定领域的论文将快速掠过，以控制篇幅。\n\n**AI 生成模型与 LLMs（高影响力领域）**  \n- **FengWu-GHR: Learning the Kilometer-scale Medium-range Global Weather Forecasting**（中文：FengWu-GHR：学习公里级中期全球天气预报；英文：FengWu-GHR）  \n  这篇论文提出首个数据驱动的公里级全球天气预报模型，通过从低分辨率模型继承知识，实现比欧洲中期天气预报系统 IFS-HRES 更精确的预测，主要贡献在于克服计算资源限制，提升极端事件预测的实际应用潜力。  \n\n- **On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension**（中文：生成对抗模型在低内在数据维度的统计特性；英文：On the Statistical Properties）  \n  作者包括知名学者 Peter L. Bartlett，该研究分析 GANs 和 BiGANs 在低维数据上的统计性能，发现预期 Wasserstein-1 距离错误率可达 O(n^{-1/d_μ})，成功避开维数诅咒，并证明这些模型在非光滑分布下也能实现最优率，这为生成模型理论提供关键洞见。  \n\n- **YODA: Teacher-Student Progressive Learning for Language Models**（中文：YODA：基于教师-学生渐进学习的语言模型；英文：YODA）  \n  这篇论文引入教师-学生框架模拟人类学习过程，通过基本-泛化-复杂循环训练 LLMs，在数学推理任务中提升性能（如 GSM8K 和 MATH 数据集上提高 17%），主要发现是结合反馈机制能显著增强模型的泛化能力。  \n\n- **LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging**（中文：LLM4SecHW：利用领域特定大语言模型进行硬件调试；英文：LLM4SecHW）  \n  论文提出细调领域特定 LLMs 来识别和修复硬件设计缺陷，使用开源数据训练模型，实现自动化质量控制，主要贡献在于提供一个通用的细调工作流，提升硬件安全领域的效率。  \n\n- **TA&AT: Enhancing Task-Oriented Dialog with Turn-Level Auxiliary Tasks and Action-Tree Based Scheduled Sampling**（中文：TA&AT：通过转级辅助任务和动作树采样增强任务导向对话；英文：TA&AT）  \n  该研究在任务导向对话中引入转级多任务目标和动作树采样，显著减少错误积累，在 MultiWOZ 数据集上达到 SOTA 性能，主要发现是模拟扰动能桥接训练与推理的差距。  \n\n**医疗与计算机视觉应用**  \n- **ACCESS: Prompt Engineering for Automated Web Accessibility Violation Corrections**（中文：ACCESS：基于提示工程的自动网页可访问性修正；英文：ACCESS）  \n  论文利用 LLMs 和提示工程实时修正网页可访问性问题（如 WCAG 标准），在基准测试中减少 51% 违规，主要贡献在于推动包容性网页设计。  \n\n- **EEG for fatigue monitoring**（中文：EEG 用于疲劳监测；英文：EEG for fatigue monitoring）  \n  这篇快速概述 EEG 在监测生理疲劳的应用，强调其非侵入性和高时间分辨率，主要发现是 EEG 在医疗和交通领域的潜力，但细节较基础。  \n\n- **A Study of Acquisition Functions for Medical Imaging Deep Active Learning**（中文：医疗成像深度主动学习的获取函数研究；英文：A Study of Acquisition Functions）  \n  通过比较 BALD、MeanSTD 和 MaxEntropy 在 ISIC 2016 数据集上的表现，论文证实主动学习能有效处理标注数据稀缺问题，主要贡献是 BALD 在黑素瘤检测中表现出色，但正样本检测仍有改进空间。  \n\n**其他创新应用（快速掠过）**  \n- **GarchingSim: An Autonomous Driving Simulator with Photorealistic Scenes and Minimalist Workflow**（中文：GarchingSim：具有逼真场景和简化工作流的自主驾驶模拟器；英文：GarchingSim）  \n  这篇论文开发了一个开源模拟器，支持 ROS2 接口和精确车辆动力学模型，用于算法测试，主要发现是简化部署过程便于初学者使用。  \n\n- **Harnessing Network Effect for Fake News Mitigation**（中文：利用网络效应缓解假新闻：基于自模仿学习的辩手选择；英文：Harnessing Network Effect）  \n  提出 NAGASIL 框架，通过负采样和状态增强选择辩手缓解假新闻传播，在模拟中提升性能，主要贡献是改进自模仿学习的应用。  \n\n- **Enhancing Human Experience in Human-Agent Collaboration**（中文：基于正向人类收益增强人类-代理协作的人类中心建模方法；英文：Enhancing Human Experience）  \n  论文使用 RLHG 框架让代理学习提升人类目标实现，在 MOBA 游戏中改善协作体验，主要发现是代理行为能更注重人类反馈。  \n\n其余论文如 k-means 聚类评估、路面裂缝检测、UAV 轨迹预测等，聚焦特定技术细节，我将快速掠过：这些工作分别优化了时间序列聚类、图生成和天气预报等领域，但影响力相对有限，仅验证了方法有效性（如 UP-CrackNet 在无监督检测中表现良好）。\n\n总体而言，今天的 arXiv 更新突显 AI 模型在实际问题中的潜力，尤其在生成和应用层面的突破，读者可关注 LLMs 和天气预报相关论文以获取前沿洞见。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2401.15803v2",
      "title": "GarchingSim: An Autonomous Driving Simulator with Photorealistic Scenes and Minimalist Workflow",
      "title_zh": "GarchingSim：一种带有照片级真实场景和简约工作流的自动驾驶模拟器",
      "authors": [
        "Liguo Zhou",
        "Yinglei Song",
        "Yichao Gao",
        "Zhou Yu",
        "Michael Sodamin",
        "Hongshen Liu",
        "Liang Ma",
        "Lian Liu",
        "Hao Liu",
        "Yang Liu",
        "Haichuan Li",
        "Guang Chen",
        "Alois Knoll"
      ],
      "abstract": "Conducting real road testing for autonomous driving algorithms can be\nexpensive and sometimes impractical, particularly for small startups and\nresearch institutes. Thus, simulation becomes an important method for\nevaluating these algorithms. However, the availability of free and open-source\nsimulators is limited, and the installation and configuration process can be\ndaunting for beginners and interdisciplinary researchers. We introduce an\nautonomous driving simulator with photorealistic scenes, meanwhile keeping a\nuser-friendly workflow. The simulator is able to communicate with external\nalgorithms through ROS2 or Socket.IO, making it compatible with existing\nsoftware stacks. Furthermore, we implement a highly accurate vehicle dynamics\nmodel within the simulator to enhance the realism of the vehicle's physical\neffects. The simulator is able to serve various functions, including generating\nsynthetic data and driving with machine learning-based algorithms. Moreover, we\nprioritize simplicity in the deployment process, ensuring that beginners find\nit approachable and user-friendly.",
      "tldr_zh": "该论文介绍了 GarchingSim，一种自治驾驶模拟器，旨在通过提供 photorealistic scenes 和 minimalist workflow 来解决真实道路测试的成本和复杂性问题。该模拟器支持通过 ROS2 或 Socket.IO 与外部算法通信，并集成了高度准确的 vehicle dynamics model，以提升模拟的真实性和适用性。相比现有工具，GarchingSim 简化了安装配置过程，便于初学者和跨学科研究者使用，同时能生成合成数据并支持机器学习算法驱动。总的来说，这为小型企业和研究机构提供了免费开源的评估平台，推动了自治驾驶算法的开发和测试。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15803v2",
      "published_date": "2024-01-28 23:26:15 UTC",
      "updated_date": "2024-01-30 15:57:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:52:44.804538"
    },
    {
      "arxiv_id": "2401.15801v1",
      "title": "On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension",
      "title_zh": "关于低内在数据维度生成对抗模型的统计特性",
      "authors": [
        "Saptarshi Chakraborty",
        "Peter L. Bartlett"
      ],
      "abstract": "Despite the remarkable empirical successes of Generative Adversarial Networks\n(GANs), the theoretical guarantees for their statistical accuracy remain rather\npessimistic. In particular, the data distributions on which GANs are applied,\nsuch as natural images, are often hypothesized to have an intrinsic\nlow-dimensional structure in a typically high-dimensional feature space, but\nthis is often not reflected in the derived rates in the state-of-the-art\nanalyses. In this paper, we attempt to bridge the gap between the theory and\npractice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs),\nby deriving statistical guarantees on the estimated densities in terms of the\nintrinsic dimension of the data and the latent space. We analytically show that\nif one has access to $n$ samples from the unknown target distribution and the\nnetwork architectures are properly chosen, the expected Wasserstein-1 distance\nof the estimates from the target scales as $O\\left( n^{-1/d_\\mu } \\right)$ for\nGANs and $O\\left( n^{-1/(d_\\mu+\\ell)} \\right)$ for BiGANs, where $d_\\mu$ and\n$\\ell$ are the upper Wasserstein-1 dimension of the data-distribution and\nlatent-space dimension, respectively. The theoretical analyses not only suggest\nthat these methods successfully avoid the curse of dimensionality, in the sense\nthat the exponent of $n$ in the error rates does not depend on the data\ndimension but also serve to bridge the gap between the theoretical analyses of\nGANs and the known sharp rates from optimal transport literature. Additionally,\nwe demonstrate that GANs can effectively achieve the minimax optimal rate even\nfor non-smooth underlying distributions, with the use of larger generator\nnetworks.",
      "tldr_zh": "该论文分析了生成对抗网络(GANs)和双向GANs(BiGANs)在低内在数据维度下的统计属性，旨在弥合理论与实践的差距。研究推导了估计密度的统计保证：当使用n个样本时，GANs的期望Wasserstein-1距离为O(n^{-1/d_μ)，而BiGANs为O(n^{-1/(d_μ + ℓ)})，其中d_μ是数据分布的Wasserstein-1维度，ℓ是潜在空间维度。这些结果表明，GANs和BiGANs成功避免了维度的诅咒，因为错误率的指数不依赖于数据维度，且GANs即使在非平滑分布下也能通过更大生成器网络达到最小最大最优率。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15801v1",
      "published_date": "2024-01-28 23:18:10 UTC",
      "updated_date": "2024-01-28 23:18:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:52:57.579910"
    },
    {
      "arxiv_id": "2401.16450v2",
      "title": "ACCESS: Prompt Engineering for Automated Web Accessibility Violation Corrections",
      "title_zh": "ACCESS：自动化网络可访问性违规修正的提示工程",
      "authors": [
        "Calista Huang",
        "Alyssa Ma",
        "Suchir Vyasamudri",
        "Eugenie Puype",
        "Sayem Kamal",
        "Juan Belza Garcia",
        "Salar Cheema",
        "Michael Lutz"
      ],
      "abstract": "With the increasing need for inclusive and user-friendly technology, web\naccessibility is crucial to ensuring equal access to online content for\nindividuals with disabilities, including visual, auditory, cognitive, or motor\nimpairments. Despite the existence of accessibility guidelines and standards\nsuch as Web Content Accessibility Guidelines (WCAG) and the Web Accessibility\nInitiative (W3C), over 90% of websites still fail to meet the necessary\naccessibility requirements. For web users with disabilities, there exists a\nneed for a tool to automatically fix web page accessibility errors. While\nresearch has demonstrated methods to find and target accessibility errors, no\nresearch has focused on effectively correcting such violations. This paper\npresents a novel approach to correcting accessibility violations on the web by\nmodifying the document object model (DOM) in real time with foundation models.\nLeveraging accessibility error information, large language models (LLMs), and\nprompt engineering techniques, we achieved greater than a 51% reduction in\naccessibility violation errors after corrections on our novel benchmark:\nACCESS. Our work demonstrates a valuable approach toward the direction of\ninclusive web content, and provides directions for future research to explore\nadvanced methods to automate web accessibility.",
      "tldr_zh": "本研究针对网页可访问性问题（如WCAG和W3C标准），指出超过90%的网站未能满足残疾用户需求，提出了一种自动化修正方法。利用Large Language Models (LLMs)和Prompt Engineering技术，通过修改Document Object Model (DOM)来实时修复可访问性违规错误。在名为ACCESS的新基准测试中，该方法实现了超过51%的错误减少率。总体上，这为创建包容性网页内容提供了宝贵途径，并为未来自动化可访问性研究指明了方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.16450v2",
      "published_date": "2024-01-28 22:49:33 UTC",
      "updated_date": "2024-02-10 20:17:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:53:07.965763"
    },
    {
      "arxiv_id": "2401.15773v1",
      "title": "Evaluation of k-means time series clustering based on z-normalization and NP-Free",
      "title_zh": "翻译失败",
      "authors": [
        "Ming-Chang Lee",
        "Jia-Chun Lin",
        "Volker Stolz"
      ],
      "abstract": "Despite the widespread use of k-means time series clustering in various\ndomains, there exists a gap in the literature regarding its comprehensive\nevaluation with different time series normalization approaches. This paper\nseeks to fill this gap by conducting a thorough performance evaluation of\nk-means time series clustering on real-world open-source time series datasets.\nThe evaluation focuses on two distinct normalization techniques:\nz-normalization and NP-Free. The former is one of the most commonly used\nnormalization approach for time series. The latter is a real-time time series\nrepresentation approach, which can serve as a time series normalization\napproach. The primary objective of this paper is to assess the impact of these\ntwo normalization techniques on k-means time series clustering in terms of its\nclustering quality. The experiments employ the silhouette score, a\nwell-established metric for evaluating the quality of clusters in a dataset. By\nsystematically investigating the performance of k-means time series clustering\nwith these two normalization techniques, this paper addresses the current gap\nin k-means time series clustering evaluation and contributes valuable insights\nto the development of time series clustering.",
      "tldr_zh": "这篇论文评估了 k-means 时间序列聚类在 z-normalization 和 NP-Free 两种归一化方法下的性能，以填补文献中相关综合评估的空白。研究使用真实世界开源时间序列数据集进行实验，并以 silhouette score 作为聚类质量指标，系统比较了这些方法对聚类效果的影响。结果显示，该评估为时间序列聚类的发展提供了宝贵见解，帮助理解不同归一化技术的优缺点。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 6 figures, 8 tables, 13th International Conference on\n  Pattern Recognition Applications and Methods (ICPRAM 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.15773v1",
      "published_date": "2024-01-28 21:23:13 UTC",
      "updated_date": "2024-01-28 21:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:53:21.107676"
    },
    {
      "arxiv_id": "2401.15766v1",
      "title": "EEG for fatigue monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Ildar Rakhmatulin"
      ],
      "abstract": "Physiological fatigue, a state of reduced cognitive and physical performance\nresulting from prolonged mental or physical exertion, poses significant\nchallenges in various domains, including healthcare, aviation, transportation,\nand industrial sectors. As the understanding of fatigue's impact on human\nperformance grows, there is a growing interest in developing effective fatigue\nmonitoring techniques. Among these techniques, electroencephalography (EEG) has\nemerged as a promising tool for objectively assessing physiological fatigue due\nto its non-invasiveness, high temporal resolution, and sensitivity to neural\nactivity. This paper aims to provide a comprehensive analysis of the current\nstate of the use of EEG for monitoring physiological fatigue.",
      "tldr_zh": "生理疲劳会导致认知和身体表现下降，在医疗、交通和工业等领域带来重大挑战。本文分析了EEG（electroencephalography）作为一种非侵入性、高时间分辨率且敏感神经活动的工具，在监测生理疲劳中的应用和优势。论文提供了EEG用于生理疲劳监测的当前状态全面综述，为开发有效的疲劳监测技术提供了重要基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15766v1",
      "published_date": "2024-01-28 21:01:45 UTC",
      "updated_date": "2024-01-28 21:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:53:32.305909"
    },
    {
      "arxiv_id": "2401.15753v2",
      "title": "An objective comparison of methods for augmented reality in laparoscopic liver resection by preoperative-to-intraoperative image fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Sharib Ali",
        "Yamid Espinel",
        "Yueming Jin",
        "Peng Liu",
        "Bianca Güttner",
        "Xukun Zhang",
        "Lihua Zhang",
        "Tom Dowrick",
        "Matthew J. Clarkson",
        "Shiting Xiao",
        "Yifan Wu",
        "Yijun Yang",
        "Lei Zhu",
        "Dai Sun",
        "Lan Li",
        "Micha Pfeiffer",
        "Shahid Farid",
        "Lena Maier-Hein",
        "Emmanuel Buc",
        "Adrien Bartoli"
      ],
      "abstract": "Augmented reality for laparoscopic liver resection is a visualisation mode\nthat allows a surgeon to localise tumours and vessels embedded within the liver\nby projecting them on top of a laparoscopic image. Preoperative 3D models\nextracted from CT or MRI data are registered to the intraoperative laparoscopic\nimages during this process. In terms of 3D-2D fusion, most of the algorithms\nmake use of anatomical landmarks to guide registration. These landmarks include\nthe liver's inferior ridge, the falciform ligament, and the occluding contours.\nThey are usually marked by hand in both the laparoscopic image and the 3D\nmodel, which is time-consuming and may contain errors if done by a\nnon-experienced user. Therefore, there is a need to automate this process so\nthat augmented reality can be used effectively in the operating room. We\npresent the Preoperative-to-Intraoperative Laparoscopic Fusion Challenge\n(P2ILF), held during the Medical Imaging and Computer Assisted Interventions\n(MICCAI 2022) conference, which investigates the possibilities of detecting\nthese landmarks automatically and using them in registration. The challenge was\ndivided into two tasks: 1) A 2D and 3D landmark detection task and 2) a 3D-2D\nregistration task. The teams were provided with training data consisting of 167\nlaparoscopic images and 9 preoperative 3D models from 9 patients, with the\ncorresponding 2D and 3D landmark annotations. A total of 6 teams from 4\ncountries participated, whose proposed methods were evaluated on 16 images and\ntwo preoperative 3D models from two patients. All the teams proposed deep\nlearning-based methods for the 2D and 3D landmark segmentation tasks and\ndifferentiable rendering-based methods for the registration task. Based on the\nexperimental outcomes, we propose three key hypotheses that determine current\nlimitations and future directions for research in this domain.",
      "tldr_zh": "这篇论文比较了在腹腔镜肝切除手术中，使用术前图像（如CT或MRI）与术中图像融合的增强现实方法，以帮助外科医生定位肿瘤和血管。论文介绍了Preoperative-to-Intraoperative Laparoscopic Fusion Challenge（P2ILF），该挑战分为2D和3D landmarks检测任务以及3D-2D注册任务，参与团队采用深度学习和可微渲染技术进行自动化处理。实验结果基于测试数据评估了这些方法，并提出了三个关键假设，指出当前局限性并指引未来研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.15753v2",
      "published_date": "2024-01-28 20:30:14 UTC",
      "updated_date": "2024-02-07 11:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:53:46.358467"
    },
    {
      "arxiv_id": "2401.15741v7",
      "title": "SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Serdar Erisen"
      ],
      "abstract": "Improving the efficiency of state-of-the-art methods in semantic segmentation\nrequires overcoming the increasing computational cost as well as issues such as\nfusing semantic information from global and local contexts. Based on the recent\nsuccess and problems that convolutional neural networks (CNNs) encounter in\nsemantic segmentation, this research proposes an encoder-decoder architecture\nwith a unique efficient residual network, Efficient-ResNet. Attention-boosting\ngates (AbGs) and attention-boosting modules (AbMs) are deployed by aiming to\nfuse the equivariant and feature-based semantic information with the equivalent\nsizes of the output of global context of the efficient residual network in the\nencoder. Respectively, the decoder network is developed with the additional\nattention-fusion networks (AfNs) inspired by AbM. AfNs are designed to improve\nthe efficiency in the one-to-one conversion of the semantic information by\ndeploying additional convolution layers in the decoder part. Our network is\ntested on the challenging CamVid and Cityscapes datasets, and the proposed\nmethods reveal significant improvements on the residual networks. To the best\nof our knowledge, the developed network, SERNet-Former, achieves\nstate-of-the-art results (84.62 % mean IoU) on CamVid dataset and challenging\nresults (87.35 % mean IoU) on Cityscapes validation dataset.",
      "tldr_zh": "本研究提出了一种高效语义分割网络 SERNet-Former，旨在提升状态-of-the-art 方法的计算效率，同时解决融合全局和局部语义信息的问题。 该网络采用编码器-解码器架构，以 Efficient-ResNet 为基础，在编码器中引入 Attention-boosting gates (AbGs) 和 Attention-boosting modules (AbMs) 来融合等变和基于特征的语义信息；在解码器中，使用 Attention-fusion networks (AfNs) 通过额外卷积层提高语义信息转换效率。 实验结果显示，SERNet-Former 在 CamVid 数据集上达到 84.62% mean IoU 的最先进性能，在 Cityscapes 数据集上取得 87.35% mean IoU 的显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15741v7",
      "published_date": "2024-01-28 19:58:19 UTC",
      "updated_date": "2024-07-02 15:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:53:58.818576"
    },
    {
      "arxiv_id": "2401.16448v1",
      "title": "LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging",
      "title_zh": "LLM4SecHW：利用特定领域大型语言模型进行硬件调试",
      "authors": [
        "Weimin Fu",
        "Kaichen Yang",
        "Raj Gautam Dutta",
        "Xiaolong Guo",
        "Gang Qu"
      ],
      "abstract": "This paper presents LLM4SecHW, a novel framework for hardware debugging that\nleverages domain specific Large Language Model (LLM). Despite the success of\nLLMs in automating various software development tasks, their application in the\nhardware security domain has been limited due to the constraints of commercial\nLLMs and the scarcity of domain specific data. To address these challenges, we\npropose a unique approach to compile a dataset of open source hardware design\ndefects and their remediation steps, utilizing version control data. This\ndataset provides a substantial foundation for training machine learning models\nfor hardware. LLM4SecHW employs fine tuning of medium sized LLMs based on this\ndataset, enabling the identification and rectification of bugs in hardware\ndesigns. This pioneering approach offers a reference workflow for the\napplication of fine tuning domain specific LLMs in other research areas. We\nevaluate the performance of our proposed system on various open source hardware\ndesigns, demonstrating its efficacy in accurately identifying and correcting\ndefects. Our work brings a new perspective on automating the quality control\nprocess in hardware design.",
      "tldr_zh": "本文提出LLM4SecHW框架，利用特定领域的Large Language Model (LLM)来辅助硬件调试，解决LLM在硬件安全领域应用受限的问题。通过编译开源硬件设计缺陷数据集（包括缺陷和修复步骤），并基于此数据集微调中等规模的LLM，该框架能够有效识别和纠正硬件设计中的漏洞。实验结果显示，LLM4SecHW在多种开源硬件设计上表现出色，提升了自动化质量控制过程，并为其他领域微调领域特定LLM提供参考工作流程。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "6 pages. 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2401.16448v1",
      "published_date": "2024-01-28 19:45:25 UTC",
      "updated_date": "2024-01-28 19:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:54:08.705719"
    },
    {
      "arxiv_id": "2401.15721v2",
      "title": "A Study of Acquisition Functions for Medical Imaging Deep Active Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bonaventure F. P. Dossou"
      ],
      "abstract": "The Deep Learning revolution has enabled groundbreaking achievements in\nrecent years. From breast cancer detection to protein folding, deep learning\nalgorithms have been at the core of very important advancements. However, these\nmodern advancements are becoming more and more data-hungry, especially on\nlabeled data whose availability is scarce: this is even more prevalent in the\nmedical context. In this work, we show how active learning could be very\neffective in data scarcity situations, where obtaining labeled data (or\nannotation budget is very limited). We compare several selection criteria\n(BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the\neffect of acquired pool size on the model's performance. Our results suggest\nthat uncertainty is useful to the Melanoma detection task, and confirms the\nhypotheses of the author of the paper of interest, that \\textit{bald} performs\non average better than other acquisition functions. Our extended analyses\nhowever revealed that all acquisition functions perform badly on the positive\n(cancerous) samples, suggesting exploitation of class unbalance, which could be\ncrucial in real-world settings. We finish by suggesting future work directions\nthat would be useful to improve this current work. The code of our\nimplementation is open-sourced at\n\\url{https://github.com/bonaventuredossou/ece526_course_project}",
      "tldr_zh": "这篇论文研究了深度主动学习（Deep Active Learning）在医疗图像中的应用，针对标签数据稀缺问题，比较了BALD、MeanSTD和MaxEntropy等获取函数在ISIC 2016数据集上的表现。作者探索了获取池大小对黑素瘤检测模型性能的影响，结果显示不确定性（uncertainty）有助于任务改进，且BALD平均表现优于其他函数。论文还揭示了所有获取函数在阳性（癌性）样本上的表现较差，可能源于类不平衡，并建议未来工作方向以提升实际应用。开源代码可从指定链接获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Best Poster Award at Deep Learning Indaba 2023 Conference",
      "pdf_url": "http://arxiv.org/pdf/2401.15721v2",
      "published_date": "2024-01-28 18:09:02 UTC",
      "updated_date": "2024-02-29 11:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:54:22.139773"
    },
    {
      "arxiv_id": "2401.15713v3",
      "title": "Contrastive Learning and Mixture of Experts Enables Precise Vector Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Logan Hallee",
        "Rohan Kapur",
        "Arjun Patel",
        "Jason P. Gleghorn",
        "Bohdan Khomtchouk"
      ],
      "abstract": "The advancement of transformer neural networks has significantly elevated the\ncapabilities of sentence similarity models, but they still struggle with highly\ndiscriminative tasks and may produce sub-optimal representations of important\ndocuments like scientific literature. With the increased reliance on retrieval\naugmentation and search, representing diverse documents as concise and\ndescriptive vectors is crucial. This paper improves upon the vectors embeddings\nof scientific text by assembling niche datasets using co-citations as a\nsimilarity metric, focusing on biomedical domains. We apply a novel Mixture of\nExperts (MoE) extension pipeline to pretrained BERT models, where every\nmulti-layer perceptron section is enlarged and copied into multiple distinct\nexperts. Our MoE variants perform well over $N$ scientific domains with $N$\ndedicated experts, whereas standard BERT models excel in only one domain at a\ntime. Notably, extending just a single transformer block to MoE captures 85% of\nthe benefit seen from full MoE extension at every layer. This holds promise for\nversatile and efficient One-Size-Fits-All transformer networks for numerically\nrepresenting diverse inputs. Our methodology marks advancements in\nrepresentation learning and holds promise for enhancing vector database search\nand compilation.",
      "tldr_zh": "该论文探讨了如何通过对比学习和 Mixture of Experts (MoE) 提升句子相似性模型的性能，特别是针对科学文献的向量嵌入问题。研究者使用 co-citations 作为相似性指标构建了针对生物医学领域的专用数据集，并将 MoE 扩展应用于预训练的 BERT 模型，其中每个多层感知器部分被扩展为多个专家。结果显示，MoE 变体能够在 N 个科学领域表现出色，而标准 BERT 仅在单一领域领先；仅扩展一个 transformer 块即可捕获 85% 的全模型益处。这种方法推进了表示学习领域的发展，并有望优化向量数据库搜索和编译。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15713v3",
      "published_date": "2024-01-28 17:34:42 UTC",
      "updated_date": "2024-12-17 20:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:54:34.388686"
    },
    {
      "arxiv_id": "2402.01732v2",
      "title": "Identifying and Improving Disability Bias in GPT-Based Resume Screening",
      "title_zh": "识别并改进基于 GPT 的简历筛选中的残疾偏见",
      "authors": [
        "Kate Glazko",
        "Yusuf Mohammed",
        "Ben Kosa",
        "Venkatesh Potluri",
        "Jennifer Mankoff"
      ],
      "abstract": "As Generative AI rises in adoption, its use has expanded to include domains\nsuch as hiring and recruiting. However, without examining the potential of\nbias, this may negatively impact marginalized populations, including people\nwith disabilities. To address this important concern, we present a resume audit\nstudy, in which we ask ChatGPT (specifically, GPT-4) to rank a resume against\nthe same resume enhanced with an additional leadership award, scholarship,\npanel presentation, and membership that are disability related. We find that\nGPT-4 exhibits prejudice towards these enhanced CVs. Further, we show that this\nprejudice can be quantifiably reduced by training a custom GPTs on principles\nof DEI and disability justice. Our study also includes a unique qualitative\nanalysis of the types of direct and indirect ableism GPT-4 uses to justify its\nbiased decisions and suggest directions for additional bias mitigation work.\nAdditionally, since these justifications are presumably drawn from training\ndata containing real-world biased statements made by humans, our analysis\nsuggests additional avenues for understanding and addressing human bias.",
      "tldr_zh": "该研究调查了GPT-4在简历筛选中的残疾偏见（disability bias），通过一个简历审计研究，让GPT-4比较普通简历与添加残疾相关奖项（如领导奖学金和会议）的增强版简历，结果显示GPT-4对增强版简历表现出偏见（prejudice）。为了缓解这一问题，研究者通过训练自定义GPTs，基于DEI（Diversity, Equity, and Inclusion）和残疾正义原则，成功量化减少了这种偏见。研究还进行了定性分析，揭示了GPT-4在决策中使用的直接和间接ableism（歧视残疾人的行为），并建议进一步的偏见缓解策略，同时强调这些偏见可能源于训练数据中的人类偏见，从而为理解和解决真实世界偏见提供新途径。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01732v2",
      "published_date": "2024-01-28 17:04:59 UTC",
      "updated_date": "2024-05-22 19:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:54:47.841846"
    },
    {
      "arxiv_id": "2402.00060v2",
      "title": "Treatment of Epistemic Uncertainty in Conjunction Analysis with Dempster-Shafer Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Sanchez",
        "Massimiliano Vasile",
        "Silvia Sanvido",
        "Klaus Mertz",
        "Christophe Taillan"
      ],
      "abstract": "The paper presents an approach to the modelling of epistemic uncertainty in\nConjunction Data Messages (CDM) and the classification of conjunction events\naccording to the confidence in the probability of collision. The approach\nproposed in this paper is based on the Dempster-Shafer Theory (DSt) of evidence\nand starts from the assumption that the observed CDMs are drawn from a family\nof unknown distributions. The Dvoretzky-Kiefer-Wolfowitz (DKW) inequality is\nused to construct robust bounds on such a family of unknown distributions\nstarting from a time series of CDMs. A DSt structure is then derived from the\nprobability boxes constructed with DKW inequality. The DSt structure\nencapsulates the uncertainty in the CDMs at every point along the time series\nand allows the computation of the belief and plausibility in the realisation of\na given probability of collision. The methodology proposed in this paper is\ntested on a number of real events and compared against existing practices in\nthe European and French Space Agencies. We will show that the classification\nsystem proposed in this paper is more conservative than the approach taken by\nthe European Space Agency but provides an added quantification of uncertainty\nin the probability of collision.",
      "tldr_zh": "该论文提出了一种基于 Dempster-Shafer Theory (DSt) 的方法，用于处理 Conjunction Data Messages (CDM) 中的认识不确定性 (epistemic uncertainty)，并对碰撞概率的置信度进行分类。方法假设 CDMs 来自未知分布家族，利用 Dvoretzky-Kiefer-Wolfowitz (DKW) 不等式构建鲁棒概率边界，并从中衍生 DSt 结构，以计算碰撞概率的 belief 和 plausibility 值。该方法在真实事件上进行了测试，结果显示其比欧洲航天局的现有实践更保守，并提供了额外的碰撞概率不确定性量化，从而提升了碰撞事件分析的可靠性。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT",
        "math.PR"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 23 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.00060v2",
      "published_date": "2024-01-28 15:39:29 UTC",
      "updated_date": "2024-02-13 18:06:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:54:59.160580"
    },
    {
      "arxiv_id": "2401.15675v1",
      "title": "Detection of a facemask in real-time using deep learning methods: Prevention of Covid 19",
      "title_zh": "翻译失败",
      "authors": [
        "Gautam Siddharth Kashyap",
        "Jatin Sohlot",
        "Ayesha Siddiqui",
        "Ramsha Siddiqui",
        "Karan Malik",
        "Samar Wazir",
        "Alexander E. I. Brownlee"
      ],
      "abstract": "A health crisis is raging all over the world with the rapid transmission of\nthe novel-coronavirus disease (Covid-19). Out of the guidelines issued by the\nWorld Health Organisation (WHO) to protect us against Covid-19, wearing a\nfacemask is the most effective. Many countries have necessitated the wearing of\nface masks, but monitoring a large number of people to ensure that they are\nwearing masks in a crowded place is a challenging task in itself. The\nnovel-coronavirus disease (Covid-19) has already affected our day-to-day life\nas well as world trade movements. By the end of April 2021, the world has\nrecorded 144,358,956 confirmed cases of novel-coronavirus disease (Covid-19)\nincluding 3,066,113 deaths according to the world health organization (WHO).\nThese increasing numbers motivate automated techniques for the detection of a\nfacemask in real-time scenarios for the prevention of Covid-19. We propose a\ntechnique using deep learning that works for single and multiple people in a\nframe recorded via webcam in still or in motion. We have also experimented with\nour approach in night light. The accuracy of our model is good compared to the\nother approaches in the literature; ranging from 74% for multiple people in a\nnightlight to 99% for a single person in daylight.",
      "tldr_zh": "这篇论文针对COVID-19预防，提出了一种使用深度学习方法实时检测口罩的技巧，以监控人群是否佩戴口罩。该方法适用于单人和多人场景，包括静态或动态视频，以及夜间光线条件，通过 webcam 进行检测。实验结果显示，该模型的准确率从74%（多人夜间）提高到99%（单人白天），比现有文献中的方法更有效。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Research Advances in Network Technologies (Volume 2) (CRC Press\n  Taylor and Francis), 2023 (Accepted)",
      "pdf_url": "http://arxiv.org/pdf/2401.15675v1",
      "published_date": "2024-01-28 14:45:52 UTC",
      "updated_date": "2024-01-28 14:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:55:12.212779"
    },
    {
      "arxiv_id": "2401.15670v1",
      "title": "YODA: Teacher-Student Progressive Learning for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jianqiao Lu",
        "Wanjun Zhong",
        "Yufei Wang",
        "Zhijiang Guo",
        "Qi Zhu",
        "Wenyong Huang",
        "Yanlin Wang",
        "Fei Mi",
        "Baojun Wang",
        "Yasheng Wang",
        "Lifeng Shang",
        "Xin Jiang",
        "Qun Liu"
      ],
      "abstract": "Although large language models (LLMs) have demonstrated adeptness in a range\nof tasks, they still lag behind human learning efficiency. This disparity is\noften linked to the inherent human capacity to learn from basic examples,\ngradually generalize and handle more complex problems, and refine their skills\nwith continuous feedback. Inspired by this, this paper introduces YODA, a novel\nteacher-student progressive learning framework that emulates the\nteacher-student education process to improve the efficacy of model fine-tuning.\nThe framework operates on an interactive \\textit{basic-generalized-harder}\nloop. The teacher agent provides tailored feedback on the student's answers,\nand systematically organizes the education process. This process unfolds by\nteaching the student basic examples, reinforcing understanding through\ngeneralized questions, and then enhancing learning by posing questions with\nprogressively enhanced complexity. With the teacher's guidance, the student\nlearns to iteratively refine its answer with feedback, and forms a robust and\ncomprehensive understanding of the posed questions. The systematic procedural\ndata, which reflects the progressive learning process of humans, is then\nutilized for model training. Taking math reasoning as a testbed, experiments\nshow that training LLaMA2 with data from YODA improves SFT with significant\nperformance gain (+17.01\\% on GSM8K and +9.98\\% on MATH). In addition, we find\nthat training with curriculum learning further improves learning robustness.",
      "tldr_zh": "这篇论文引入了 YODA，一种 teacher-student 渐进式学习框架，旨在模仿人类学习过程来提升大型语言模型 (LLMs) 的微调效率。YODA 通过一个交互式的 basic-generalized-harder 循环，让教师代理提供针对学生答案的反馈，先从基本例子开始教学，然后通过泛化问题强化理解，并逐步引入更复杂的查询，以帮助学生迭代改进答案。实验结果显示，在数学推理任务上，使用 YODA 生成的数据训练 LLaMA2 模型相比标准 SFT 取得了显著提升（GSM8K 准确率提高 17.01%、MATH 提高 9.98%），并通过课程学习进一步增强了模型的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.15670v1",
      "published_date": "2024-01-28 14:32:15 UTC",
      "updated_date": "2024-01-28 14:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:55:24.639696"
    },
    {
      "arxiv_id": "2402.10222v1",
      "title": "Autonomous Vehicle Patrolling Through Deep Reinforcement Learning: Learning to Communicate and Cooperate",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhao Tong",
        "Maria A. Rodriguez",
        "Richard O. Sinnott"
      ],
      "abstract": "Autonomous vehicles are suited for continuous area patrolling problems.\nFinding an optimal patrolling strategy can be challenging due to unknown\nenvironmental factors, such as wind or landscape; or autonomous vehicles'\nconstraints, such as limited battery life or hardware failures. Importantly,\npatrolling large areas often requires multiple agents to collectively\ncoordinate their actions. However, an optimal coordination strategy is often\nnon-trivial to be manually defined due to the complex nature of patrolling\nenvironments. In this paper, we consider a patrolling problem with\nenvironmental factors, agent limitations, and three typical cooperation\nproblems -- collision avoidance, congestion avoidance, and patrolling target\nnegotiation. We propose a multi-agent reinforcement learning solution based on\na reinforced inter-agent learning (RIAL) method. With this approach, agents are\ntrained to develop their own communication protocol to cooperate during\npatrolling where faults can and do occur. The solution is validated through\nsimulation experiments and is compared with several state-of-the-art patrolling\nsolutions from different perspectives, including the overall patrol\nperformance, the collision avoidance performance, the efficiency of battery\nrecharging strategies, and the overall fault tolerance.",
      "tldr_zh": "该论文探讨了自主车辆在巡逻任务中的挑战，包括未知环境因素（如风或地形）、车辆限制（如电池寿命）和多代理合作问题（如碰撞避免、拥堵避免及巡逻目标协商）。作者提出了一种基于深度强化学习的 multi-agent 解决方案，使用强化代理间学习 (RIAL) 方法，让代理通过训练开发自己的通信协议，实现有效合作和故障处理。实验结果显示，该方法在模拟环境中表现出色，在整体巡逻性能、碰撞避免性能、电池充电策略效率及故障容忍性方面均优于现有先进巡逻解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10222v1",
      "published_date": "2024-01-28 14:29:30 UTC",
      "updated_date": "2024-01-28 14:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:55:35.468083"
    },
    {
      "arxiv_id": "2403.08782v1",
      "title": "Procedural terrain generation with style transfer",
      "title_zh": "基于风格迁移的程序化地形生成",
      "authors": [
        "Fabio Merizzi"
      ],
      "abstract": "In this study we introduce a new technique for the generation of terrain\nmaps, exploiting a combination of procedural generation and Neural Style\nTransfer. We consider our approach to be a viable alternative to competing\ngenerative models, with our technique achieving greater versatility, lower\nhardware requirements and greater integration in the creative process of\ndesigners and developers. Our method involves generating procedural noise maps\nusing either multi-layered smoothed Gaussian noise or the Perlin algorithm. We\nthen employ an enhanced Neural Style transfer technique, drawing style from\nreal-world height maps. This fusion of algorithmic generation and neural\nprocessing holds the potential to produce terrains that are not only diverse\nbut also closely aligned with the morphological characteristics of real-world\nlandscapes, with our process yielding consistent terrain structures with low\ncomputational cost and offering the capability to create customized maps.\nNumerical evaluations further validate our model's enhanced ability to\naccurately replicate terrain morphology, surpassing traditional procedural\nmethods.",
      "tldr_zh": "本研究提出了一种结合程序生成和 Neural Style Transfer 的地形地图生成技术，作为传统生成模型的替代方案，具有更高的通用性、更低的硬件需求，以及更好的设计师和开发者集成能力。该方法首先使用多层平滑高斯噪声或 Perlin 算法生成程序噪声地图，然后应用增强的 Neural Style Transfer，从真实高度地图中提取风格，从而创建多样且与真实景观形态相似的地形。实验结果显示，该技术在精确复制地形形态方面优于传统程序方法，提供低计算成本和自定义地图生成的能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08782v1",
      "published_date": "2024-01-28 14:22:27 UTC",
      "updated_date": "2024-01-28 14:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:55:47.121735"
    },
    {
      "arxiv_id": "2402.00059v1",
      "title": "FengWu-GHR: Learning the Kilometer-scale Medium-range Global Weather Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Han",
        "Song Guo",
        "Fenghua Ling",
        "Kang Chen",
        "Junchao Gong",
        "Jingjia Luo",
        "Junxia Gu",
        "Kan Dai",
        "Wanli Ouyang",
        "Lei Bai"
      ],
      "abstract": "Kilometer-scale modeling of global atmosphere dynamics enables fine-grained\nweather forecasting and decreases the risk of disastrous weather and climate\nactivity. Therefore, building a kilometer-scale global forecast model is a\npersistent pursuit in the meteorology domain. Active international efforts have\nbeen made in past decades to improve the spatial resolution of numerical\nweather models. Nonetheless, developing the higher resolution numerical model\nremains a long-standing challenge due to the substantial consumption of\ncomputational resources. Recent advances in data-driven global weather\nforecasting models utilize reanalysis data for model training and have\ndemonstrated comparable or even higher forecasting skills than numerical\nmodels. However, they are all limited by the resolution of reanalysis data and\nincapable of generating higher-resolution forecasts. This work presents\nFengWu-GHR, the first data-driven global weather forecasting model running at\nthe 0.09$^{\\circ}$ horizontal resolution. FengWu-GHR introduces a novel\napproach that opens the door for operating ML-based high-resolution forecasts\nby inheriting prior knowledge from a pretrained low-resolution model. The\nhindcast of weather prediction in 2022 indicates that FengWu-GHR is superior to\nthe IFS-HRES. Furthermore, evaluations on station observations and case studies\nof extreme events support the competitive operational forecasting skill of\nFengWu-GHR at the high resolution.",
      "tldr_zh": "该论文提出 FengWu-GHR，一种数据驱动的全球天气预报模型，旨在实现公里级（0.09° 水平分辨率）的中程预报，以提升精细化预测并降低灾害风险。不同于传统数值模型的计算资源消耗，FengWu-GHR 通过从预训练低分辨率模型继承知识，创新性地克服了再分析数据分辨率限制的问题。实验结果显示，FengWu-GHR 在 2022 年回测中优于 IFS-HRES，并在站点观测和极端事件案例中表现出色竞争性预报能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.00059v1",
      "published_date": "2024-01-28 13:23:25 UTC",
      "updated_date": "2024-01-28 13:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:55:58.901568"
    },
    {
      "arxiv_id": "2401.15647v2",
      "title": "UP-CrackNet: Unsupervised Pixel-Wise Road Crack Detection via Adversarial Image Restoration",
      "title_zh": "UP-CrackNet：通过对抗图像修复的无监督像素级道路裂缝检测",
      "authors": [
        "Nachuan Ma",
        "Rui Fan",
        "Lihua Xie"
      ],
      "abstract": "Over the past decade, automated methods have been developed to detect cracks\nmore efficiently, accurately, and objectively, with the ultimate goal of\nreplacing conventional manual visual inspection techniques. Among these\nmethods, semantic segmentation algorithms have demonstrated promising results\nin pixel-wise crack detection tasks. However, training such networks requires a\nlarge amount of human-annotated datasets with pixel-level annotations, which is\na highly labor-intensive and time-consuming process. Moreover, supervised\nlearning-based methods often struggle with poor generalizability in unseen\ndatasets. Therefore, we propose an unsupervised pixel-wise road crack detection\nnetwork, known as UP-CrackNet. Our approach first generates multi-scale square\nmasks and randomly selects them to corrupt undamaged road images by removing\ncertain regions. Subsequently, a generative adversarial network is trained to\nrestore the corrupted regions by leveraging the semantic context learned from\nsurrounding uncorrupted regions. During the testing phase, an error map is\ngenerated by calculating the difference between the input and restored images,\nwhich allows for pixel-wise crack detection. Our comprehensive experimental\nresults demonstrate that UP-CrackNet outperforms other general-purpose\nunsupervised anomaly detection algorithms, and exhibits satisfactory\nperformance and superior generalizability when compared with state-of-the-art\nsupervised crack segmentation algorithms. Our source code is publicly available\nat mias.group/UP-CrackNet.",
      "tldr_zh": "本论文提出了一种无监督像素级道路裂缝检测方法UP-CrackNet，利用对抗图像恢复(Adversarial Image Restoration)技术，旨在减少对标注数据的依赖并提升模型泛化性。方法首先通过多尺度方形掩码破坏未损坏的道路图像，然后训练生成对抗网络(GAN)来恢复被破坏区域，利用周围未破坏区域的语义上下文进行学习。在测试阶段，通过计算输入图像与恢复图像的差异生成错误地图，实现精确的像素级裂缝检测。实验结果表明，UP-CrackNet在性能上优于其他无监督异常检测算法，并在泛化性和准确性方面超越了最先进的监督裂缝分割算法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15647v2",
      "published_date": "2024-01-28 12:51:01 UTC",
      "updated_date": "2024-05-06 07:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:56:13.258896"
    },
    {
      "arxiv_id": "2401.15626v1",
      "title": "TA&AT: Enhancing Task-Oriented Dialog with Turn-Level Auxiliary Tasks and Action-Tree Based Scheduled Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Longxiang Liu",
        "Xiuxing Li",
        "Yang Feng"
      ],
      "abstract": "Task-oriented dialog systems have witnessed substantial progress due to\nconversational pre-training techniques. Yet, two significant challenges\npersist. First, most systems primarily utilize the latest turn's state label\nfor the generator. This practice overlooks the comprehensive value of state\nlabels in boosting the model's understanding for future generations. Second, an\noverreliance on generated policy often leads to error accumulation, resulting\nin suboptimal responses when adhering to incorrect actions. To combat these\nchallenges, we propose turn-level multi-task objectives for the encoder. With\nthe guidance of essential information from labeled intermediate states, we\nestablish a more robust representation for both understanding and generation.\nFor the decoder, we introduce an action tree-based scheduled sampling\ntechnique. Specifically, we model the hierarchical policy as trees and utilize\nthe similarity between trees to sample negative policy based on scheduled\nsampling, hoping the model to generate invariant responses under perturbations.\nThis method simulates potential pitfalls by sampling similar negative policy,\nbridging the gap between task-oriented dialog training and inference. Among\nmethods without continual pre-training, our approach achieved state-of-the-art\n(SOTA) performance on the MultiWOZ dataset series and was also competitive with\npre-trained SOTA methods.",
      "tldr_zh": "该研究针对任务导向对话(Task-Oriented Dialog)系统的两大挑战——忽略中间状态标签的潜在价值和策略错误积累导致的次优响应——提出了一种名为 TA&AT 的框架。具体而言，该框架为编码器引入转折级辅助任务(Turn-Level Auxiliary Tasks)，利用标记的中间状态信息构建更稳健的表示；同时，为解码器设计基于动作树的 scheduled sampling(Action-Tree Based Scheduled Sampling)技术，通过采样相似负策略模拟扰动，帮助模型生成不变响应。该方法在 MultiWOZ 数据集上实现了 state-of-the-art (SOTA) 性能，且无需持续预训练，与预训练 SOTA 方法相比具有竞争力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.15626v1",
      "published_date": "2024-01-28 11:02:23 UTC",
      "updated_date": "2024-01-28 11:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:56:24.567750"
    },
    {
      "arxiv_id": "2401.15625v1",
      "title": "Generative AI-enabled Blockchain Networks: Fundamentals, Applications, and Case Study",
      "title_zh": "生成式人工智能赋能的区块链网络：基础、应用和案例研究",
      "authors": [
        "Cong T. Nguyen",
        "Yinqiu Liu",
        "Hongyang Du",
        "Dinh Thai Hoang",
        "Dusit Niyato",
        "Diep N. Nguyen",
        "Shiwen Mao"
      ],
      "abstract": "Generative Artificial Intelligence (GAI) has recently emerged as a promising\nsolution to address critical challenges of blockchain technology, including\nscalability, security, privacy, and interoperability. In this paper, we first\nintroduce GAI techniques, outline their applications, and discuss existing\nsolutions for integrating GAI into blockchains. Then, we discuss emerging\nsolutions that demonstrate the effectiveness of GAI in addressing various\nchallenges of blockchain, such as detecting unknown blockchain attacks and\nsmart contract vulnerabilities, designing key secret sharing schemes, and\nenhancing privacy. Moreover, we present a case study to demonstrate that GAI,\nspecifically the generative diffusion model, can be employed to optimize\nblockchain network performance metrics. Experimental results clearly show that,\ncompared to a baseline traditional AI approach, the proposed generative\ndiffusion model approach can converge faster, achieve higher rewards, and\nsignificantly improve the throughput and latency of the blockchain network.\nAdditionally, we highlight future research directions for GAI in blockchain\napplications, including personalized GAI-enabled blockchains, GAI-blockchain\nsynergy, and privacy and security considerations within blockchain ecosystems.",
      "tldr_zh": "本论文探讨了生成式人工智能(GAI)如何解决区块链技术的关键挑战，包括可扩展性、安全性、隐私和互操作性。它介绍了GAI的技术应用、现有整合方案，以及新兴解决方案，如检测未知攻击、智能合约漏洞和密钥共享方案，并通过一个案例研究展示了generative diffusion model在优化区块链网络性能方面的优势，实验结果显示该方法比传统AI更快收敛、获得更高奖励，并显著提升了区块链的吞吐量和延迟。最后，论文指出了未来研究方向，包括个性化GAI-enabled区块链、GAI与区块链的协同效应，以及隐私和安全考虑。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15625v1",
      "published_date": "2024-01-28 10:46:17 UTC",
      "updated_date": "2024-01-28 10:46:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:56:36.335994"
    },
    {
      "arxiv_id": "2401.15621v2",
      "title": "SNAP: Semantic Stories for Next Activity Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Alon Oved",
        "Segev Shlomov",
        "Sergey Zeltyn",
        "Nir Mashkif",
        "Avi Yaeli"
      ],
      "abstract": "Predicting the next activity in an ongoing process is one of the most common\nclassification tasks in the business process management (BPM) domain. It allows\nbusinesses to optimize resource allocation, enhance operational efficiency, and\naids in risk mitigation and strategic decision-making. This provides a\ncompetitive edge in the rapidly evolving confluence of BPM and AI. Existing\nstate-of-the-art AI models for business process prediction do not fully\ncapitalize on available semantic information within process event logs. As\ncurrent advanced AI-BPM systems provide semantically-richer textual data, the\nneed for novel adequate models grows. To address this gap, we propose the novel\nSNAP method that leverages language foundation models by constructing semantic\ncontextual stories from the process historical event logs and using them for\nthe next activity prediction. We compared the SNAP algorithm with nine\nstate-of-the-art models on six benchmark datasets and show that SNAP\nsignificantly outperforms them, especially for datasets with high levels of\nsemantic content.",
      "tldr_zh": "该研究针对业务流程管理(BPM)中的下一个活动预测任务，提出了一种名为SNAP的方法，以优化资源分配和决策支持。SNAP通过从历史事件日志构建语义上下文故事，并利用语言基础模型进行预测，从而充分利用了事件日志中的语义信息。实验结果显示，在六个基准数据集上，SNAP显著优于九个最先进模型，尤其在语义内容丰富的场景中。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15621v2",
      "published_date": "2024-01-28 10:20:15 UTC",
      "updated_date": "2024-03-14 17:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:56:47.605507"
    },
    {
      "arxiv_id": "2401.15620v1",
      "title": "Data-Driven Strategies for Coping with Incomplete DVL Measurements",
      "title_zh": "翻译失败",
      "authors": [
        "Nadav Cohen",
        "Itzik Klein"
      ],
      "abstract": "Autonomous underwater vehicles are specialized platforms engineered for deep\nunderwater operations. Critical to their functionality is autonomous\nnavigation, typically relying on an inertial navigation system and a Doppler\nvelocity log. In real-world scenarios, incomplete Doppler velocity log\nmeasurements occur, resulting in positioning errors and mission aborts. To cope\nwith such situations, a model and learning approaches were derived. This paper\npresents a comparative analysis of two cutting-edge deep learning\nmethodologies, namely LiBeamsNet and MissBeamNet, alongside a model-based\naverage estimator. These approaches are evaluated for their efficacy in\nregressing missing Doppler velocity log beams when two beams are unavailable.\nIn our study, we used data recorded by a DVL mounted on an autonomous\nunderwater vehicle operated in the Mediterranean Sea. We found that both deep\nlearning architectures outperformed model-based approaches by over 16% in\nvelocity prediction accuracy.",
      "tldr_zh": "本研究针对自主水下车辆（AUVs）在多普勒速度日志（DVL）测量不完整时导致的导航错误和任务中断问题，提出数据驱动策略。论文比较了两种深度学习方法——LiBeamsNet 和 MissBeamNet，以及基于模型的平均估计器，用于回归缺失的 DVL 光束（尤其当两个光束不可用时）。实验基于地中海实际数据进行评估，结果显示深度学习方法在速度预测准确性上比模型方法提高了超过16%。这项工作为提升 AUVs 的鲁棒性导航提供了有效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15620v1",
      "published_date": "2024-01-28 10:17:36 UTC",
      "updated_date": "2024-01-28 10:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:57:01.969171"
    },
    {
      "arxiv_id": "2401.15617v2",
      "title": "Diffusion-based Graph Generative Methods",
      "title_zh": "基于扩散的图生成方法",
      "authors": [
        "Hongyang Chen",
        "Can Xu",
        "Lingyu Zheng",
        "Qiang Zhang",
        "Xuemin Lin"
      ],
      "abstract": "Being the most cutting-edge generative methods, diffusion methods have shown\ngreat advances in wide generation tasks. Among them, graph generation attracts\nsignificant research attention for its broad application in real life. In our\nsurvey, we systematically and comprehensively review on diffusion-based graph\ngenerative methods. We first make a review on three mainstream paradigms of\ndiffusion methods, which are denoising diffusion probabilistic models,\nscore-based genrative models, and stochastic differential equations. Then we\nfurther categorize and introduce the latest applications of diffusion models on\ngraphs. In the end, we point out some limitations of current studies and future\ndirections of future explorations. The summary of existing methods metioned in\nthis survey is in\nhttps://github.com/zhejiangzhuque/Diffusion-based-Graph-Generative-Methods.",
      "tldr_zh": "这篇调查论文系统回顾了基于diffusion models的图生成方法，作为前沿生成技术在实际应用中的重要领域。主要贡献包括对三种主流范式——Denoising Diffusion Probabilistic Models、Score-based Generative Models和Stochastic Differential Equations——的全面分析，以及对这些模型在图上的最新应用的分类介绍。论文指出了当前研究的局限性，如潜在的泛化问题，并提出了未来探索方向，同时提供了一个GitHub链接（https://github.com/zhejiangzhuque/Diffusion-based-Graph-Generative-Methods）来总结现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15617v2",
      "published_date": "2024-01-28 10:09:05 UTC",
      "updated_date": "2024-07-16 12:21:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:57:13.716613"
    },
    {
      "arxiv_id": "2402.01730v1",
      "title": "Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and Symptom Analysis",
      "title_zh": "评估LLM生成的基于医疗图像和症状分析的多模态诊断",
      "authors": [
        "Dimitrios P. Panagoulias",
        "Maria Virvou",
        "George A. Tsihrintzis"
      ],
      "abstract": "Large language models (LLMs) constitute a breakthrough state-of-the-art\nArtificial Intelligence technology which is rapidly evolving and promises to\naid in medical diagnosis. However, the correctness and the accuracy of their\nreturns has not yet been properly evaluated. In this work, we propose an LLM\nevaluation paradigm that incorporates two independent steps of a novel\nmethodology, namely (1) multimodal LLM evaluation via structured interactions\nand (2) follow-up, domain-specific analysis based on data extracted via the\nprevious interactions. Using this paradigm, (1) we evaluate the correctness and\naccuracy of LLM-generated medical diagnosis with publicly available multimodal\nmultiple-choice questions(MCQs) in the domain of Pathology and (2) proceed to a\nsystemic and comprehensive analysis of extracted results. We used\nGPT-4-Vision-Preview as the LLM to respond to complex, medical questions\nconsisting of both images and text, and we explored a wide range of diseases,\nconditions, chemical compounds, and related entity types that are included in\nthe vast knowledge domain of Pathology. GPT-4-Vision-Preview performed quite\nwell, scoring approximately 84\\% of correct diagnoses. Next, we further\nanalyzed the findings of our work, following an analytical approach which\nincluded Image Metadata Analysis, Named Entity Recognition and Knowledge\nGraphs. Weaknesses of GPT-4-Vision-Preview were revealed on specific knowledge\npaths, leading to a further understanding of its shortcomings in specific\nareas. Our methodology and findings are not limited to the use of\nGPT-4-Vision-Preview, but a similar approach can be followed to evaluate the\nusefulness and accuracy of other LLMs and, thus, improve their use with further\noptimization.",
      "tldr_zh": "本研究评估了大型语言模型(LLM)如GPT-4-Vision-Preview在处理医疗图像和症状分析的多模态诊断中的正确性和准确性，提出了一种新型评估范式，包括结构化交互和后续领域特定分析。研究使用公开的多模态多选题(MCQs)测试病理学领域的诊断表现，GPT-4-Vision-Preview的正确率约为84%。通过Image Metadata Analysis、Named Entity Recognition和Knowledge Graphs等方法，进一步分析了模型的弱点，如特定知识路径上的不足，并为优化其他LLMs在医疗诊断中的应用提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Department of Informatics, University of Piraeus, Greece",
      "pdf_url": "http://arxiv.org/pdf/2402.01730v1",
      "published_date": "2024-01-28 09:25:12 UTC",
      "updated_date": "2024-01-28 09:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:57:25.743960"
    },
    {
      "arxiv_id": "2402.01729v3",
      "title": "Contextualization Distillation from Large Language Model for Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Dawei Li",
        "Zhen Tan",
        "Tianlong Chen",
        "Huan Liu"
      ],
      "abstract": "While textual information significantly enhances the performance of\npre-trained language models (PLMs) in knowledge graph completion (KGC), the\nstatic and noisy nature of existing corpora collected from Wikipedia articles\nor synsets definitions often limits the potential of PLM-based KGC models. To\nsurmount these challenges, we introduce the Contextualization Distillation\nstrategy, a versatile plug-in-and-play approach compatible with both\ndiscriminative and generative KGC frameworks. Our method begins by instructing\nlarge language models (LLMs) to transform compact, structural triplets into\ncontext-rich segments. Subsequently, we introduce two tailored auxiliary tasks,\nreconstruction and contextualization, allowing smaller KGC models to assimilate\ninsights from these enriched triplets. Comprehensive evaluations across diverse\ndatasets and KGC techniques highlight the efficacy and adaptability of our\napproach, revealing consistent performance enhancements irrespective of\nunderlying pipelines or architectures. Moreover, our analysis makes our method\nmore explainable and provides insight into generating path selection, as well\nas the choosing of suitable distillation tasks. All the code and data in this\nwork will be released at\nhttps://github.com/David-Li0406/Contextulization-Distillation",
      "tldr_zh": "该研究针对预训练语言模型（PLMs）在知识图谱完成（KGC）中的性能受限于静态噪声语料的问题，提出了 Contextualization Distillation 策略，这是一种通用的插件式方法，兼容判别式和生成式 KGC 框架。方法通过指导 Large Language Model (LLM) 将结构化的三元组转化为丰富的上下文段落，并引入 reconstruction 和 contextualization 辅助任务，让小型 KGC 模型从中吸收知识。实验结果显示，该策略在多种数据集和 KGC 技术上实现了性能一致提升，并提供了路径选择和任务选择的解释性分析。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EACL 2024 findings v3: add missing citations",
      "pdf_url": "http://arxiv.org/pdf/2402.01729v3",
      "published_date": "2024-01-28 08:56:49 UTC",
      "updated_date": "2024-02-24 07:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:57:37.495851"
    },
    {
      "arxiv_id": "2402.03357v1",
      "title": "Harnessing Network Effect for Fake News Mitigation: Selecting Debunkers via Self-Imitation Learning",
      "title_zh": "利用网络效应进行虚假新闻缓解：通过自模仿学习选择辟谣者",
      "authors": [
        "Xiaofei Xu",
        "Ke Deng",
        "Michael Dann",
        "Xiuzhen Zhang"
      ],
      "abstract": "This study aims to minimize the influence of fake news on social networks by\ndeploying debunkers to propagate true news. This is framed as a reinforcement\nlearning problem, where, at each stage, one user is selected to propagate true\nnews. A challenging issue is episodic reward where the \"net\" effect of\nselecting individual debunkers cannot be discerned from the interleaving\ninformation propagation on social networks, and only the collective effect from\nmitigation efforts can be observed. Existing Self-Imitation Learning (SIL)\nmethods have shown promise in learning from episodic rewards, but are\nill-suited to the real-world application of fake news mitigation because of\ntheir poor sample efficiency. To learn a more effective debunker selection\npolicy for fake news mitigation, this study proposes NAGASIL - Negative\nsampling and state Augmented Generative Adversarial Self-Imitation Learning,\nwhich consists of two improvements geared towards fake news mitigation:\nlearning from negative samples, and an augmented state representation to\ncapture the \"real\" environment state by integrating the current observed state\nwith the previous state-action pairs from the same campaign. Experiments on two\nsocial networks show that NAGASIL yields superior performance to standard GASIL\nand state-of-the-art fake news mitigation models.",
      "tldr_zh": "本研究旨在通过部署辟谣者(debunkers)来减少假新闻在社交网络上的影响，将问题建模为强化学习(Reinforcement Learning)任务，每阶段选择一个用户传播真实新闻。面对周期性奖励的挑战，现有Self-Imitation Learning (SIL)方法虽然能处理此类奖励，但样本效率低下，不适合实际应用。为此，研究提出NAGASIL框架，包括从负面样本中学习和增强状态表示（通过整合当前状态与之前状态-动作对），以更准确捕捉环境动态。实验在两个社交网络上显示，NAGASIL 比标准Generative Adversarial Self-Imitation Learning (GASIL) 和现有假新闻缓解模型表现出色，显著提升了辟谣效果。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "10 pages, full version of this paper is accepted by AAAI'24",
      "pdf_url": "http://arxiv.org/pdf/2402.03357v1",
      "published_date": "2024-01-28 06:05:01 UTC",
      "updated_date": "2024-01-28 06:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:57:49.157055"
    },
    {
      "arxiv_id": "2401.16444v1",
      "title": "Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Gao",
        "Feiyu Liu",
        "Liang Wang",
        "Zhenjie Lian",
        "Dehua Zheng",
        "Weixuan Wang",
        "Wenjin Yang",
        "Siqin Li",
        "Xianliang Wang",
        "Wenhui Chen",
        "Jing Dai",
        "Qiang Fu",
        "Wei Yang",
        "Lanxiao Huang",
        "Wei Liu"
      ],
      "abstract": "Existing game AI research mainly focuses on enhancing agents' abilities to\nwin games, but this does not inherently make humans have a better experience\nwhen collaborating with these agents. For example, agents may dominate the\ncollaboration and exhibit unintended or detrimental behaviors, leading to poor\nexperiences for their human partners. In other words, most game AI agents are\nmodeled in a \"self-centered\" manner. In this paper, we propose a\n\"human-centered\" modeling scheme for collaborative agents that aims to enhance\nthe experience of humans. Specifically, we model the experience of humans as\nthe goals they expect to achieve during the task. We expect that agents should\nlearn to enhance the extent to which humans achieve these goals while\nmaintaining agents' original abilities (e.g., winning games). To achieve this,\nwe propose the Reinforcement Learning from Human Gain (RLHG) approach. The RLHG\napproach introduces a \"baseline\", which corresponds to the extent to which\nhumans primitively achieve their goals, and encourages agents to learn\nbehaviors that can effectively enhance humans in achieving their goals better.\nWe evaluate the RLHG agent in the popular Multi-player Online Battle Arena\n(MOBA) game, Honor of Kings, by conducting real-world human-agent tests. Both\nobjective performance and subjective preference results show that the RLHG\nagent provides participants better gaming experience.",
      "tldr_zh": "现有游戏AI研究主要关注提升代理的获胜能力，但这可能导致代理主导合作并损害人类体验，如表现出不适当行为。论文提出一种“以人为本”的建模方案，将人类体验定义为他们期望在任务中实现的目标，并引入Reinforcement Learning from Human Gain (RLHG)方法，让代理在保持原有能力（如获胜）的同时，学习行为来提升人类目标实现的程度。实验在Multi-player Online Battle Arena (MOBA)游戏Honor of Kings中进行，结果显示RLHG代理在客观性能和主观偏好上均显著改善了玩家的游戏体验。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at ICLR 2024. arXiv admin note: text overlap with\n  arXiv:2304.11632",
      "pdf_url": "http://arxiv.org/pdf/2401.16444v1",
      "published_date": "2024-01-28 05:05:57 UTC",
      "updated_date": "2024-01-28 05:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:58:02.027974"
    },
    {
      "arxiv_id": "2401.15568v1",
      "title": "Intriguing Equivalence Structures of the Embedding Space of Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Shaeke Salman",
        "Md Montasir Bin Shams",
        "Xiuwen Liu"
      ],
      "abstract": "Pre-trained large foundation models play a central role in the recent surge\nof artificial intelligence, resulting in fine-tuned models with remarkable\nabilities when measured on benchmark datasets, standard exams, and\napplications. Due to their inherent complexity, these models are not well\nunderstood. While small adversarial inputs to such models are well known, the\nstructures of the representation space are not well characterized despite their\nfundamental importance. In this paper, using the vision transformers as an\nexample due to the continuous nature of their input space, we show via analyses\nand systematic experiments that the representation space consists of large\npiecewise linear subspaces where there exist very different inputs sharing the\nsame representations, and at the same time, local normal spaces where there are\nvisually indistinguishable inputs having very different representations. The\nempirical results are further verified using the local directional estimations\nof the Lipschitz constants of the underlying models. Consequently, the\nresulting representations change the results of downstream models, and such\nmodels are subject to overgeneralization and with limited semantically\nmeaningful generalization capability.",
      "tldr_zh": "这篇论文探讨了Vision Transformers的嵌入空间结构，通过分析和系统实验揭示了其 intriguing 等价结构，包括大型的逐片线性子空间（large piecewise linear subspaces），其中非常不同的输入可能共享相同的表示，以及局部正常空间（local normal spaces），其中视觉上难以区分的输入可能有显著不同的表示。研究者使用局部方向估计的Lipschitz constants来验证这些发现。结果表明，这种嵌入空间结构会导致下游模型出现过度泛化（overgeneralization），从而限制了语义有意义的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.15568v1",
      "published_date": "2024-01-28 04:59:51 UTC",
      "updated_date": "2024-01-28 04:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:58:13.344676"
    },
    {
      "arxiv_id": "2401.15564v1",
      "title": "Design of UAV flight state recognition and trajectory prediction system based on trajectory feature construction",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Zhou",
        "Zhuoyong Shi"
      ],
      "abstract": "With the impact of artificial intelligence on the traditional UAV industry,\nautonomous UAV flight has become a current hot research field. Based on the\ndemand for research on critical technologies for autonomous flying UAVs, this\npaper addresses the field of flight state recognition and trajectory prediction\nof UAVs. This paper proposes a method to improve the accuracy of UAV trajectory\nprediction based on UAV flight state recognition and verifies it using two\nprediction models. Firstly, UAV flight data acquisition and data preprocessing\nare carried out; secondly, UAV flight trajectory features are extracted based\non data fusion and a UAV flight state recognition model based on PCA-DAGSVM\nmodel is established; finally, two UAV flight trajectory prediction models are\nestablished and the trajectory prediction errors of the two prediction models\nare compared and analyzed after flight state recognition. The results show\nthat: 1) the UAV flight state recognition model based on PCA-DAGSVM has good\nrecognition effect. 2) compared with the traditional UAV trajectory prediction\nmodel, the prediction model based on flight state recognition can effectively\nreduce the prediction error.",
      "tldr_zh": "本论文针对无人机（UAV）自主飞行的关键需求，提出了一种基于轨迹特征构建的飞行状态识别和轨迹预测系统，以提高预测准确性。方法包括数据采集与预处理、基于数据融合提取轨迹特征，以及利用 PCA-DAGSVM 模型建立飞行状态识别模型。实验验证了两种轨迹预测模型，结果显示，基于飞行状态识别的模型比传统模型有效降低了预测错误，为 UAV 自主飞行技术提供了更可靠的解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15564v1",
      "published_date": "2024-01-28 04:14:35 UTC",
      "updated_date": "2024-01-28 04:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:58:25.744823"
    },
    {
      "arxiv_id": "2401.15545v1",
      "title": "PPM: Automated Generation of Diverse Programming Problems for Benchmarking Code Generation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Simin Chen",
        "Xiaoning Feng",
        "Xiaohong Han",
        "Cong Liu",
        "Wei Yang"
      ],
      "abstract": "In recent times, a plethora of Large Code Generation Models (LCGMs) have been\nproposed, showcasing significant potential in assisting developers with complex\nprogramming tasks. Benchmarking LCGMs necessitates the creation of a set of\ndiverse programming problems, and each problem comprises the prompt (including\nthe task description), canonical solution, and test inputs. The existing\nmethods for constructing such a problem set can be categorized into two main\ntypes: manual methods and perturbation-based methods. However, manual methods\ndemand high effort and lack scalability, while also risking data integrity due\nto LCGMs' potentially contaminated data collection, and perturbation-based\napproaches mainly generate semantically homogeneous problems with the same\ncanonical solutions and introduce typos that can be easily auto-corrected by\nIDE, making them ineffective and unrealistic. In this work, we propose the idea\nof programming problem merging (PPM) and provide two implementation of this\nidea, we utilize our tool on two widely-used datasets and compare it against\nnine baseline methods using eight code generation models. The results\ndemonstrate the effectiveness of our tool in generating more challenging,\ndiverse, and natural programming problems, comparing to the baselines.",
      "tldr_zh": "该论文提出了一种名为 PPM（Programming Problem Merging）的自动生成方法，用于创建多样化的编程问题，以基准测试大型代码生成模型（LCGMs）。现有方法如手动构建和基于扰动的生成存在效率低下、数据完整性风险或问题同质性等问题，而 PPM 通过合并编程问题并提供两个具体实现，解决了这些缺陷。实验在两个常用数据集上使用八个代码生成模型进行测试，结果显示 PPM 生成的问题比九个基线方法更具挑战性、多样性和自然性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "This paper has been accepted to The ACM International Conference on\n  the Foundations of Software Engineering FSE 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.15545v1",
      "published_date": "2024-01-28 02:27:38 UTC",
      "updated_date": "2024-01-28 02:27:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:58:36.568926"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 30,
  "processed_papers_count": 30,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T00:58:58.334419"
}