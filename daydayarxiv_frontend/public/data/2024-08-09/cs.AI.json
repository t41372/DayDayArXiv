{
  "date": "2024-08-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-09 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 模型优化、安全机制、多模态理解和应用创新等领域，强调 LLM（Large Language Models）的幻觉减少、AI 解释性和跨领域整合，令人印象深刻的是 Yoshua Bengio 的 AI 安全理论工作，以及多模态 LLM 基准测试和视觉-语言模型进展。\n\n下面，我将挑选并简要讨论几篇重要的、话题度高的论文，先从 AI 和 LLM 相关主题入手，再聊计算机视觉、机器人和医疗应用，其他较窄或技术细节较多的论文将快速掠过，仅列出标题和核心要点，以控制篇幅。\n\n### AI 和 LLM 相关论文\n- **FiSTECH: Financial Style Transfer to Enhance Creativity without Hallucinations in LLMs**（英文原题）  \n  这篇论文提出了一种两阶段微调策略，用于减少 LLM 在财务报告生成中的幻觉问题。主要贡献是通过允许初始幻觉再手动修正来提升模型的创意和准确性，发现该方法可将幻觉减少超过50%，并改善指标如 ROUGE 和 BLEU 分数。\n\n- **Explainable AI Reloaded: Challenging the XAI Status Quo in the Era of Large Language Models**（英文原题）  \n  作者包括 Upol Ehsan 和 Mark O. Riedl，这篇讨论了 LLM 时代下可解释 AI（XAI）的转变。主要贡献是提出从算法中心转向用户中心视角，强调解释性框架的三个维度（黑箱外、黑箱边缘和基础设施），发现这能更好地处理 LLM 的不透明性。\n\n- **Can a Bayesian Oracle Prevent Harm from an Agent?**（英文原题）  \n  Yoshua Bengio 等作者探索了使用 Bayesian 方法为 AI 系统提供安全保障。主要贡献是提出一种运行时风险评估框架，针对未知假设计算安全违规概率，发现这种方法能有效拒绝危险行动，提升 AI 的可靠性。\n\n- **VITA: Towards Open-Source Interactive Omni Multimodal LLM**（英文原题）  \n  这篇论文介绍了首个开源的多模态 LLM VITA，支持视频、图像、文本和音频的交互。主要贡献是通过多阶段训练增强多模态理解和交互体验，发现 VITA 在基准测试中表现出色，尤其在多模态任务上。\n\n- **Revisiting Multi-Modal LLM Evaluation**（英文原题）  \n  作者包括 Christopher Kanan，这篇重新评估多模态 LLM，如 LLaVA 和 GPT-4o。主要贡献是使用新数据集（如 TDIUC 和 TallyQA）进行细粒度分析，发现现有模型在计数和视觉查询任务上仍有差距，并提供改进基准。\n\n- **KIF: Knowledge Identification and Fusion for Language Model Continual Learning**（英文原题）  \n  这篇聚焦 LLM 的持续学习问题。主要贡献是提出知识识别和融合框架，防止灾难性遗忘，发现该方法在不同规模模型上提升了知识转移效率。\n\n- **Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2**（英文原题）  \n  作者团队包括 Neel Nanda，这篇开源了在 Gemma 2 模型上的稀疏自编码器。主要贡献是训练了多种规模的编码器，提升了模型的可解释性，发现这有助于 AI 安全研究。\n\n### 计算机视觉和机器人论文\n- **Logically Constrained Robotics Transformers for Enhanced Perception-Action Planning**（英文原题）  \n  这篇提出了一种受逻辑约束的 Transformer 模型，用于机器人轨迹规划。主要贡献是整合信号时序逻辑以提高任务准确性，发现模型在基准上比基线高74.3%的规范满足率。\n\n- **A Recurrent YOLOv8-based framework for Event-Based Object Detection**（英文原题）  \n  作者包括 Ahmed M. Eltawil，这篇开发了 ReYOLOv8 框架，用于事件驱动物体检测。主要贡献是优化事件数据编码和增强技术，发现模型在汽车和机器人数据集上提升了 mAP，同时减少参数。\n\n- **UGrid: An Efficient-And-Rigorous Neural Multigrid Solver for Linear PDEs**（英文原题）  \n  这篇提出 UGrid 模型，用于求解线性偏微分方程。主要贡献是结合 U-Net 和多网格方法，提供收敛证明，发现模型在各种输入上实现了高精度和泛化。\n\n### 医疗和生物应用论文\n- **Assessment of Cell Nuclei AI Foundation Models in Kidney Pathology**（英文原题）  \n  作者包括 Yuankai Huo，这篇评估了细胞核分割模型在肾脏病理中的表现。主要贡献是使用大规模数据集测试 CellViT 等模型，发现 CellViT 表现最佳，但仍存在性能差距。\n\n- **Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**（英文原题）  \n  这篇利用 LLM 处理电子健康记录以预测放疗后死亡率。主要贡献是框架整合 LLM 结构化数据，发现这提升了预测指标和风险分层。\n\n其他论文，如那些专注于特定技术细节的（如第12、13、19、20、24、27、29、30、31、33、34、35、38、39、40、41、45、46、49、50、52、53、54、56、59、60、61、62、63、64、65、66、67、68、71、72、74、75、77、78、79、80、81），我将快速掠过，仅列出标题和核心发现：\n\n- **Evolutionary mechanisms that promote cooperation may not promote social welfare**（英文原题）：发现合作机制可能损害社会福利。\n- **SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions**（英文原题）：使用 LLM 预测供应链风险。\n- **Neural Machine Unranking**（英文原题）：提出 CoCoL 方法改善神经信息检索的机器遗忘。\n- **From Text to Insight: Leveraging Large Language Models for Performance Evaluation in Management**（英文原题）：LLM 在管理绩效评估中表现出色但易受偏见影响。\n- **HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling**（英文原题）：引入 MMD 核提升癌症预测。\n- **AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity Recognition Dataset**（英文原题）：构建数据集提升攻击归因。\n- **Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks**（英文原题）：评估 LLM 应用中的提示注入风险。\n- **AutoGen Studio: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems**（英文原题）：开源工具简化多代理系统开发。\n- **UniBench: Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling**（英文原题）：提出统一基准测试视觉推理模型。\n\n总之，今天的论文突出了 AI 领域的创新潜力，但也提醒我们安全和泛化问题。感兴趣的读者可关注 LLM 优化和多模态应用方向！",
  "papers": [
    {
      "arxiv_id": "2408.15257v1",
      "title": "Text classification optimization algorithm based on graph neural network",
      "title_zh": "基于图神经网络的文本分类优化算法",
      "authors": [
        "Erdi Gao",
        "Haowei Yang",
        "Dan Sun",
        "Haohao Xia",
        "Yuhan Ma",
        "Yuanjing Zhu"
      ],
      "abstract": "In the field of natural language processing, text classification, as a basic\ntask, has important research value and application prospects. Traditional text\nclassification methods usually rely on feature representations such as the bag\nof words model or TF-IDF, which overlook the semantic connections between words\nand make it challenging to grasp the deep structural details of the text.\nRecently, GNNs have proven to be a valuable asset for text classification\ntasks, thanks to their capability to handle non-Euclidean data efficiently.\nHowever, the existing text classification methods based on GNN still face\nchallenges such as complex graph structure construction and high cost of model\ntraining. This paper introduces a text classification optimization algorithm\nutilizing graph neural networks. By introducing adaptive graph construction\nstrategy and efficient graph convolution operation, the accuracy and efficiency\nof text classification are effectively improved. The experimental results\ndemonstrate that the proposed method surpasses traditional approaches and\nexisting GNN models across multiple public datasets, highlighting its superior\nperformance and feasibility for text classification tasks.",
      "tldr_zh": "这篇论文针对传统文本分类方法（如 bag of words 模型或 TF-IDF）的局限性，提出了一种基于 graph neural networks (GNNs) 的优化算法，以更好地捕捉文本中词语的语义连接和深层结构。算法引入自适应图构建策略和高效图卷积操作，简化了图结构构建过程并降低了模型训练成本，从而提升了分类的准确性和效率。在多个公共数据集上的实验结果表明，该方法超越了传统方法和现有 GNN 模型，证明了其在文本分类任务中的优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2405.17460 by\n  other authors",
      "pdf_url": "http://arxiv.org/pdf/2408.15257v1",
      "published_date": "2024-08-09 23:25:37 UTC",
      "updated_date": "2024-08-09 23:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:02:57.905738"
    },
    {
      "arxiv_id": "2408.05373v2",
      "title": "Evolutionary mechanisms that promote cooperation may not promote social welfare",
      "title_zh": "翻译失败",
      "authors": [
        "The Anh Han",
        "Manh Hong Duong",
        "Matjaz Perc"
      ],
      "abstract": "Understanding the emergence of prosocial behaviours among self-interested\nindividuals is an important problem in many scientific disciplines. Various\nmechanisms have been proposed to explain the evolution of such behaviours,\nprimarily seeking the conditions under which a given mechanism can induce\nhighest levels of cooperation. As these mechanisms usually involve costs that\nalter individual payoffs, it is however possible that aiming for highest levels\nof cooperation might be detrimental for social welfare -- the later broadly\ndefined as the total population payoff, taking into account all costs involved\nfor inducing increased prosocial behaviours. Herein, by comparatively analysing\nthe social welfare and cooperation levels obtained from stochastic evolutionary\nmodels of two well-established mechanisms of prosocial behaviour, namely, peer\nand institutional incentives, we demonstrate exactly that. We show that the\nobjectives of maximising cooperation levels and the objectives of maximising\nsocial welfare are often misaligned. We argue for the need of adopting social\nwelfare as the main optimisation objective when designing and implementing\nevolutionary mechanisms for social and collective goods.",
      "tldr_zh": "该研究探讨了促进合作（cooperation）的演化机制是否会提升社会福利（social welfare），发现这些机制虽能诱导亲社会行为（prosocial behaviours），但因涉及成本，可能反而降低整体人口收益。作者通过比较分析两种机制——peer incentives和institutional incentives的随机演化模型，证明最大化合作水平的目标往往与最大化社会福利的目标不一致。研究强调，在设计和实施用于社会和集体利益的演化机制时，应优先采用社会福利作为主要优化目标，以避免潜在负面影响。",
      "categories": [
        "math.DS",
        "cs.AI",
        "cs.GT",
        "cs.MA",
        "nlin.AO"
      ],
      "primary_category": "math.DS",
      "comment": "21 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.05373v2",
      "published_date": "2024-08-09 22:51:13 UTC",
      "updated_date": "2024-09-11 19:52:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:03:09.056612"
    },
    {
      "arxiv_id": "2408.06381v2",
      "title": "Assessment of Cell Nuclei AI Foundation Models in Kidney Pathology",
      "title_zh": "翻译失败",
      "authors": [
        "Junlin Guo",
        "Siqi Lu",
        "Can Cui",
        "Ruining Deng",
        "Tianyuan Yao",
        "Zhewen Tao",
        "Yizhe Lin",
        "Marilyn Lionts",
        "Quan Liu",
        "Juming Xiong",
        "Yu Wang",
        "Shilin Zhao",
        "Catie Chang",
        "Mitchell Wilkes",
        "Mengmeng Yin",
        "Haichun Yang",
        "Yuankai Huo"
      ],
      "abstract": "Cell nuclei instance segmentation is a crucial task in digital kidney\npathology. Traditional automatic segmentation methods often lack\ngeneralizability when applied to unseen datasets. Recently, the success of\nfoundation models (FMs) has provided a more generalizable solution, potentially\nenabling the segmentation of any cell type. In this study, we perform a\nlarge-scale evaluation of three widely used state-of-the-art (SOTA) cell nuclei\nfoundation models (Cellpose, StarDist, and CellViT). Specifically, we created a\nhighly diverse evaluation dataset consisting of 2,542 kidney whole slide images\n(WSIs) collected from both human and rodent sources, encompassing various\ntissue types, sizes, and staining methods. To our knowledge, this is the\nlargest-scale evaluation of its kind to date. Our quantitative analysis of the\nprediction distribution reveals a persistent performance gap in kidney\npathology. Among the evaluated models, CellViT demonstrated superior\nperformance in segmenting nuclei in kidney pathology. However, none of the\nfoundation models are perfect; a performance gap remains in general nuclei\nsegmentation for kidney pathology.",
      "tldr_zh": "该论文评估了Cellpose、StarDist和CellViT等AI foundation models在肾脏病理学中进行细胞核实例分割的性能，以解决传统方法缺乏泛化性的问题。研究构建了一个高度多样化的数据集，包括2,542张来自人类和啮齿类动物的肾脏全滑片图像(WSIs)，涵盖不同组织类型、尺寸和染色方法。定量分析显示，这些foundation models在肾脏病理学中存在显著性能差距，其中CellViT表现出最佳效果，但所有模型在一般细胞核分割任务上仍未达到完美。该研究为提升foundation models在医疗领域的适用性提供了宝贵见解。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06381v2",
      "published_date": "2024-08-09 22:34:13 UTC",
      "updated_date": "2025-02-07 00:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:03:22.565037"
    },
    {
      "arxiv_id": "2408.05365v4",
      "title": "FiSTECH: Financial Style Transfer to Enhance Creativity without Hallucinations in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sohini Roychowdhury",
        "Marko Krema",
        "Brian Moore",
        "Xingjian Lai",
        "Dike Effedua",
        "Bharat Jethwani"
      ],
      "abstract": "Recent trends in Generative AI have emerged towards fine-tuning foundational\nlarge language models (LLMs) to create domain-specific LLMs for automation and\nchatbot-like applications. Specialized applications for analytics-heavy domains\nsuch as Financial report generation require specific writing styles that\ncomprise compound and creative sentences with minimized hallucinations. In this\nwork, we explore the self-corrective auto-regressive qualities of LLMs to learn\ncreativity in writing styles with minimal prompting. We propose a novel\ntwo-stage fine-tuning (FT) strategy wherein in the first stage public domain\nfinancial reports are used to train for writing styles while allowing the LLM\nto hallucinate. In the second stage the examples of hallucinations are manually\ncorrected and further used to fine-tune the LLM. The finally trained LLM learns\nto generate specific financial report sections using minimal instructions and\ntabular data inputs while ensuring low fine-tuning costs. Our proposed\ntwo-stage fine-tuning boosts the accuracy of financial questions answering by\ntwo-folds while reducing hallucinations by over 50%. Also, the fine-tuned model\nhas lower perplexity, improved ROUGE, TER and BLEU scores, higher creativity\nand knowledge density with lower uncertainty and cross entropy than base LLMs.\nThus, the proposed framework can be generalized to train creativity in LLMs by\nfirst allowing them to hallucinate.",
      "tldr_zh": "本研究提出 FiSTECH 框架，通过金融风格转移（Financial Style Transfer）增强大型语言模型（LLMs）的创意写作，同时最小化幻觉（hallucinations）。该框架采用两阶段微调（fine-tuning）策略：第一阶段使用公共财务报告训练写作风格，允许模型产生幻觉；第二阶段手动修正幻觉示例，并进一步微调模型，以生成特定财务报告部分。实验结果显示，该方法使财务问题回答准确性提高两倍，幻觉减少超过 50%，并在 perplexity、ROUGE、TER 和 BLEU 分数上表现出色，同时提升了创意、知识密度并降低了 uncertainty 和 cross entropy。该框架可推广至其他领域，用于训练 LLMs 的创意表达。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 14 figures, 5 tables, conference",
      "pdf_url": "http://arxiv.org/pdf/2408.05365v4",
      "published_date": "2024-08-09 22:29:23 UTC",
      "updated_date": "2024-11-17 07:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:03:35.568941"
    },
    {
      "arxiv_id": "2408.05357v2",
      "title": "SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi-Qi Cheng",
        "Yifei Dong",
        "Aike Shi",
        "Wei Liu",
        "Yuzhi Hu",
        "Jason O'Connor",
        "Alexander G. Hauptmann",
        "Kate S. Whitefoot"
      ],
      "abstract": "The electric vehicle (EV) battery supply chain's vulnerability to disruptions\nnecessitates advanced predictive analytics. We present SHIELD (Schema-based\nHierarchical Induction for EV supply chain Disruption), a system integrating\nLarge Language Models (LLMs) with domain expertise for EV battery supply chain\nrisk assessment. SHIELD combines: (1) LLM-driven schema learning to construct a\ncomprehensive knowledge library, (2) a disruption analysis system utilizing\nfine-tuned language models for event extraction, multi-dimensional similarity\nmatching for schema matching, and Graph Convolutional Networks (GCNs) with\nlogical constraints for prediction, and (3) an interactive interface for\nvisualizing results and incorporating expert feedback to enhance\ndecision-making. Evaluated on 12,070 paragraphs from 365 sources (2022-2023),\nSHIELD outperforms baseline GCNs and LLM+prompt methods (e.g., GPT-4o) in\ndisruption prediction. These results demonstrate SHIELD's effectiveness in\ncombining LLM capabilities with domain expertise for enhanced supply chain risk\nassessment.",
      "tldr_zh": "该论文提出 SHIELD 系统，利用大型语言模型 (LLMs) 和领域专业知识进行电动车 (EV) 电池供应链中断的风险评估，以应对供应链的脆弱性。SHIELD 包括三个关键组件：LLM 驱动的 schema 学习构建知识库、基于微调语言模型的事件提取与多维相似性匹配，以及 Graph Convolutional Networks (GCNs) 结合逻辑约束的预测机制，并提供交互界面整合专家反馈。实验在 12,070 段落（来自 365 个来源，2022-2023 年）上显示，SHIELD 优于基线 GCNs 和 LLM+prompt 方法（如 GPT-4o），证明了其在增强供应链风险评估方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Oral, EMNLP 2024 Industry Track. 31 pages, 11 figures, Project:\n  https://fly1113.github.io/MFI/",
      "pdf_url": "http://arxiv.org/pdf/2408.05357v2",
      "published_date": "2024-08-09 22:08:12 UTC",
      "updated_date": "2024-10-21 21:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:03:47.349939"
    },
    {
      "arxiv_id": "2408.05345v2",
      "title": "Explainable AI Reloaded: Challenging the XAI Status Quo in the Era of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Upol Ehsan",
        "Mark O. Riedl"
      ],
      "abstract": "When the initial vision of Explainable (XAI) was articulated, the most\npopular framing was to open the (proverbial) \"black-box\" of AI so that we could\nunderstand the inner workings. With the advent of Large Language Models (LLMs),\nthe very ability to open the black-box is increasingly limited especially when\nit comes to non-AI expert end-users. In this paper, we challenge the assumption\nof \"opening\" the black-box in the LLM era and argue for a shift in our XAI\nexpectations. Highlighting the epistemic blind spots of an algorithm-centered\nXAI view, we argue that a human-centered perspective can be a path forward. We\noperationalize the argument by synthesizing XAI research along three\ndimensions: explainability outside the black-box, explainability around the\nedges of the black box, and explainability that leverages infrastructural\nseams. We conclude with takeaways that reflexively inform XAI as a domain.",
      "tldr_zh": "本论文挑战了可解释 AI (XAI) 在大语言模型 (LLMs) 时代的核心假设，即需“打开”AI 的黑盒子 (black-box)，并指出这种方法在非AI专家用户中越来越不可行。作者主张转向以人为中心的视角，以解决算法中心 XAI 观点的认识盲点 (epistemic blind spots)。论文通过合成 XAI 研究沿三个维度——explainability outside the black-box、explainability around the edges of the black box 和 explainability that leverages infrastructural seams——来操作化这一论点，并提供反思性见解以指导 XAI 领域的发展。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to ACM HTTF 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05345v2",
      "published_date": "2024-08-09 21:28:31 UTC",
      "updated_date": "2024-08-13 19:39:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:03:58.589069"
    },
    {
      "arxiv_id": "2408.05336v1",
      "title": "Logically Constrained Robotics Transformers for Enhanced Perception-Action Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Parv Kapoor",
        "Sai Vemprala",
        "Ashish Kapoor"
      ],
      "abstract": "With the advent of large foundation model based planning, there is a dire\nneed to ensure their output aligns with the stakeholder's intent. When these\nmodels are deployed in the real world, the need for alignment is magnified due\nto the potential cost to life and infrastructure due to unexpected faliures.\nTemporal Logic specifications have long provided a way to constrain system\nbehaviors and are a natural fit for these use cases. In this work, we propose a\nnovel approach to factor in signal temporal logic specifications while using\nautoregressive transformer models for trajectory planning. We also provide a\ntrajectory dataset for pretraining and evaluating foundation models. Our\nproposed technique acheives 74.3 % higher specification satisfaction over the\nbaselines.",
      "tldr_zh": "该论文针对大型基础模型在机器人轨迹规划中的输出与利益相关者意图不一致问题，提出了一种将Signal Temporal Logic规范整合到自回归Transformer模型的新方法，以增强感知-行动规划的安全性和可靠性。该方法通过逻辑约束确保系统行为符合预定义规范，同时提供了一个轨迹数据集用于基础模型的预训练和评估。实验结果显示，该技术比基线模型提高了74.3%的规范满足率，为可信赖的机器人规划应用奠定了基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Robotics Science and Systems: Towards Safe Autonomy",
      "pdf_url": "http://arxiv.org/pdf/2408.05336v1",
      "published_date": "2024-08-09 21:13:08 UTC",
      "updated_date": "2024-08-09 21:13:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:04:09.617628"
    },
    {
      "arxiv_id": "2408.05334v1",
      "title": "Revisiting Multi-Modal LLM Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Lu",
        "Shikhar Srivastava",
        "Junyu Chen",
        "Robik Shrestha",
        "Manoj Acharya",
        "Kushal Kafle",
        "Christopher Kanan"
      ],
      "abstract": "With the advent of multi-modal large language models (MLLMs), datasets used\nfor visual question answering (VQA) and referring expression comprehension have\nseen a resurgence. However, the most popular datasets used to evaluate MLLMs\nare some of the earliest ones created, and they have many known problems,\nincluding extreme bias, spurious correlations, and an inability to permit\nfine-grained analysis. In this paper, we pioneer evaluating recent MLLMs (LLaVA\n1.5, LLaVA-NeXT, BLIP2, InstructBLIP, GPT-4V, and GPT-4o) on datasets designed\nto address weaknesses in earlier ones. We assess three VQA datasets: 1) TDIUC,\nwhich permits fine-grained analysis on 12 question types; 2) TallyQA, which has\nsimple and complex counting questions; and 3) DVQA, which requires optical\ncharacter recognition for chart understanding. We also study VQDv1, a dataset\nthat requires identifying all image regions that satisfy a given query. Our\nexperiments reveal the weaknesses of many MLLMs that have not previously been\nreported. Our code is integrated into the widely used LAVIS framework for MLLM\nevaluation, enabling the rapid assessment of future MLLMs. Project webpage:\nhttps://kevinlujian.github.io/MLLM_Evaluations/",
      "tldr_zh": "这篇论文重新审视了多模态大语言模型(MLLMs)的评估方法，指出现有数据集存在偏见、虚假相关性和细粒度分析不足等问题。研究者评估了多个改进数据集上的模型，包括TDIUC（支持12种问题类型的细粒度分析）、TallyQA（包含简单和复杂计数问题）、DVQA（需要光学字符识别进行图表理解）和VQDv1（要求识别图像中满足查询的全部区域）。实验结果揭示了LLaVA 1.5、LLaVA-NeXT、BLIP2、InstructBLIP、GPT-4V和GPT-4o等模型的先前未报告弱点，并将代码整合到LAVIS框架中，以便快速评估未来的MLLMs。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05334v1",
      "published_date": "2024-08-09 20:55:46 UTC",
      "updated_date": "2024-08-09 20:55:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:04:23.223668"
    },
    {
      "arxiv_id": "2408.05330v2",
      "title": "Neural Machine Unranking",
      "title_zh": "翻译失败",
      "authors": [
        "Jingrui Hou",
        "Axel Finke",
        "Georgina Cosma"
      ],
      "abstract": "We tackle the problem of machine unlearning within neural information\nretrieval, termed Neural Machine UnRanking (NuMuR) for short. Many of the\nmainstream task- or model-agnostic approaches for machine unlearning were\ndesigned for classification tasks. First, we demonstrate that these methods\nperform poorly on NuMuR tasks due to the unique challenges posed by neural\ninformation retrieval. Then, we develop a methodology for NuMuR named\nContrastive and Consistent Loss (CoCoL), which effectively balances the\nobjectives of data forgetting and model performance retention. Experimental\nresults demonstrate that CoCoL facilitates more effective and controllable data\nremoval than existing techniques.",
      "tldr_zh": "该论文探讨了神经信息检索中的机器取消学习问题，称为 Neural Machine Unranking (NuMuR)，并指出主流任务无关方法在这一领域表现不佳，因为它们主要针对分类任务。研究者开发了一种名为 Contrastive and Consistent Loss (CoCoL) 的方法，通过平衡数据遗忘与模型性能保留的目标，实现更有效的取消学习。实验结果显示，CoCoL 比现有技术更有效地实现了数据移除，同时保持了模型的可控性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05330v2",
      "published_date": "2024-08-09 20:36:40 UTC",
      "updated_date": "2024-08-22 02:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:04:33.055038"
    },
    {
      "arxiv_id": "2408.05328v1",
      "title": "From Text to Insight: Leveraging Large Language Models for Performance Evaluation in Management",
      "title_zh": "从文本到洞见：利用大型语言模型进行管理中的绩效评估",
      "authors": [
        "Ning Li",
        "Huaikang Zhou",
        "Mingze Xu"
      ],
      "abstract": "This study explores the potential of Large Language Models (LLMs),\nspecifically GPT-4, to enhance objectivity in organizational task performance\nevaluations. Through comparative analyses across two studies, including various\ntask performance outputs, we demonstrate that LLMs can serve as a reliable and\neven superior alternative to human raters in evaluating knowledge-based\nperformance outputs, which are a key contribution of knowledge workers. Our\nresults suggest that GPT ratings are comparable to human ratings but exhibit\nhigher consistency and reliability. Additionally, combined multiple GPT ratings\non the same performance output show strong correlations with aggregated human\nperformance ratings, akin to the consensus principle observed in performance\nevaluation literature. However, we also find that LLMs are prone to contextual\nbiases, such as the halo effect, mirroring human evaluative biases. Our\nresearch suggests that while LLMs are capable of extracting meaningful\nconstructs from text-based data, their scope is currently limited to specific\nforms of performance evaluation. By highlighting both the potential and\nlimitations of LLMs, our study contributes to the discourse on AI role in\nmanagement studies and sets a foundation for future research to refine AI\ntheoretical and practical applications in management.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs），如 GPT-4，在管理领域绩效评估中的应用，以提升评估的客观性。研究通过两个比较分析，评估了 LLMs 在处理知识型任务输出时的表现，结果显示 GPT-4 的评估与人类评估相当，但具有更高的 consistency 和 reliability。作者发现，结合多个 GPT 评估能与人类共识原则相匹配，从而为知识型工作者绩效提供可靠替代方案。然而，LLMs 易受 halo effect 等上下文偏差影响，限制了其适用范围。该研究强调了 LLMs 的潜力，并为 AI 在管理研究中的理论和实践应用奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CL",
      "comment": "39 pages, 8 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.05328v1",
      "published_date": "2024-08-09 20:35:10 UTC",
      "updated_date": "2024-08-09 20:35:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:04:47.424063"
    },
    {
      "arxiv_id": "2408.05321v1",
      "title": "A Recurrent YOLOv8-based framework for Event-Based Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Diego A. Silva",
        "Kamilya Smagulova",
        "Ahmed Elsheikh",
        "Mohammed E. Fouda",
        "Ahmed M. Eltawil"
      ],
      "abstract": "Object detection is crucial in various cutting-edge applications, such as\nautonomous vehicles and advanced robotics systems, primarily relying on data\nfrom conventional frame-based RGB sensors. However, these sensors often\nstruggle with issues like motion blur and poor performance in challenging\nlighting conditions. In response to these challenges, event-based cameras have\nemerged as an innovative paradigm. These cameras, mimicking the human eye,\ndemonstrate superior performance in environments with fast motion and extreme\nlighting conditions while consuming less power. This study introduces ReYOLOv8,\nan advanced object detection framework that enhances a leading frame-based\ndetection system with spatiotemporal modeling capabilities. We implemented a\nlow-latency, memory-efficient method for encoding event data to boost the\nsystem's performance. We also developed a novel data augmentation technique\ntailored to leverage the unique attributes of event data, thus improving\ndetection accuracy. Our models outperformed all comparable approaches in the\nGEN1 dataset, focusing on automotive applications, achieving mean Average\nPrecision (mAP) improvements of 5%, 2.8%, and 2.5% across nano, small, and\nmedium scales, respectively.These enhancements were achieved while reducing the\nnumber of trainable parameters by an average of 4.43% and maintaining real-time\nprocessing speeds between 9.2ms and 15.5ms. On the PEDRo dataset, which targets\nrobotics applications, our models showed mAP improvements ranging from 9% to\n18%, with 14.5x and 3.8x smaller models and an average speed enhancement of\n1.67x.",
      "tldr_zh": "本研究针对传统RGB传感器在物体检测中的问题（如运动模糊和光线条件差），提出了一种基于事件相机的ReYOLOv8框架，该框架在YOLOv8基础上加入时空建模能力，并引入低延迟、内存高效的事件数据编码方法和专属数据增强技术，以提升检测性能。实验结果显示，在GEN1数据集上，ReYOLOv8模型的mAP分别在nano、small和medium规模上提高了5%、2.8%和2.5%，同时减少了平均4.43%的可训练参数，并保持实时处理速度（9.2ms至15.5ms）。在PEDRo数据集上，该框架实现了9%至18%的mAP提升，模型大小缩小至14.5x和3.8x，速度平均提升1.67x，从而为自动驾驶和机器人应用提供了更高效的Event-Based Object Detection解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05321v1",
      "published_date": "2024-08-09 20:00:16 UTC",
      "updated_date": "2024-08-09 20:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:05:00.856231"
    },
    {
      "arxiv_id": "2408.05314v1",
      "title": "rule4ml: An Open-Source Tool for Resource Utilization and Latency Estimation for ML Models on FPGA",
      "title_zh": "rule4ml：一个开源工具，用于 FPGA 上机器学习模型的资源利用率和延迟估计",
      "authors": [
        "Mohammad Mehdi Rahimifar",
        "Hamza Ezzaoui Rahali",
        "Audrey C. Therrien"
      ],
      "abstract": "Implementing Machine Learning (ML) models on Field-Programmable Gate Arrays\n(FPGAs) is becoming increasingly popular across various domains as a\nlow-latency and low-power solution that helps manage large data rates generated\nby continuously improving detectors. However, developing ML models for FPGAs is\ntime-consuming, as optimization requires synthesis to evaluate FPGA area and\nlatency, making the process slow and repetitive. This paper introduces a novel\nmethod to predict the resource utilization and inference latency of Neural\nNetworks (NNs) before their synthesis and implementation on FPGA. We leverage\nHLS4ML, a tool-flow that helps translate NNs into high-level synthesis (HLS)\ncode, to synthesize a diverse dataset of NN architectures and train resource\nutilization and inference latency predictors. While HLS4ML requires full\nsynthesis to obtain resource and latency insights, our method uses trained\nregression models for immediate pre-synthesis predictions. The prediction\nmodels estimate the usage of Block RAM (BRAM), Digital Signal Processors (DSP),\nFlip-Flops (FF), and Look-Up Tables (LUT), as well as the inference clock\ncycles. The predictors were evaluated on both synthetic and existing benchmark\narchitectures and demonstrated high accuracy with R2 scores ranging between 0.8\nand 0.98 on the validation set and sMAPE values between 10% and 30%. Overall,\nour approach provides valuable preliminary insights, enabling users to quickly\nassess the feasibility and efficiency of NNs on FPGAs, accelerating the\ndevelopment and deployment processes. The open-source repository can be found\nat https://github.com/IMPETUS-UdeS/rule4ml, while the datasets are publicly\navailable at https://borealisdata.ca/dataverse/rule4ml.",
      "tldr_zh": "这篇论文介绍了 rule4ml，一种开源工具，用于在 FPGA 上实现 ML 模型前预测资源利用和推理延迟，从而解决优化过程缓慢的问题。方法基于 HLS4ML 工具合成多样化 Neural Networks (NNs) 架构数据集，并训练回归模型来预测 Block RAM (BRAM)、Digital Signal Processors (DSP)、Flip-Flops (FF) 和 Look-Up Tables (LUT) 的使用量，以及推理时钟周期。实验结果显示，预测模型在验证集上表现出高准确性，R2 scores 介于 0.8 和 0.98 之间，sMAPE 值在 10% 到 30% 之间。该工具提供初步评估洞见，加速 ML 模型在 FPGA 上的开发和部署，并附带公开仓库和数据集链接。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05314v1",
      "published_date": "2024-08-09 19:35:10 UTC",
      "updated_date": "2024-08-09 19:35:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:05:14.962189"
    },
    {
      "arxiv_id": "2408.15256v3",
      "title": "Improving Ontology Requirements Engineering with OntoChat and Participatory Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Yihang Zhao",
        "Bohui Zhang",
        "Xi Hu",
        "Shuyin Ouyang",
        "Jongmo Kim",
        "Nitisha Jain",
        "Jacopo de Berardinis",
        "Albert Meroño-Peñuela",
        "Elena Simperl"
      ],
      "abstract": "Past ontology requirements engineering (ORE) has primarily relied on manual\nmethods, such as interviews and collaborative forums, to gather user\nrequirements from domain experts, especially in large projects. Current\nOntoChat offers a framework for ORE that utilises large language models (LLMs)\nto streamline the process through four key functions: user story creation,\ncompetency question (CQ) extraction, CQ filtration and analysis, and ontology\ntesting support. In OntoChat, users are expected to prompt the chatbot to\ngenerate user stories. However, preliminary evaluations revealed that they\nstruggle to do this effectively. To address this issue, we experimented with a\nresearch method called participatory prompting, which involves\nresearcher-mediated interactions to help users without deep knowledge of LLMs\nuse the chatbot more effectively. This participatory prompting user study\nproduces pre-defined prompt templates based on user queries, focusing on\ncreating and refining personas, goals, scenarios, sample data, and data\nresources for user stories. These refined user stories will subsequently be\nconverted into CQs.",
      "tldr_zh": "本研究旨在改进本体需求工程（Ontology Requirements Engineering, ORE），通过OntoChat框架利用大型语言模型（Large Language Models, LLMs）简化需求收集过程，包括用户故事创建、能力问题（Competency Questions, CQs）提取、过滤分析以及本体测试支持。传统ORE依赖手动方法，用户在OntoChat中难以有效生成提示，因此研究引入了participatory prompting方法，即研究者介导的互动，帮助缺乏LLMs知识的用户创建和完善用户故事的关键元素，如角色（personas）、目标（goals）、场景（scenarios）、样本数据（sample data）和数据资源（data resources）。实验结果显示，这种方法生成了预定义的提示模板，提升了用户故事的准确性和效率，最终将这些故事转换为CQs。总的来说，该框架为大规模ORE项目提供了更高效、可参与的工具。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15256v3",
      "published_date": "2024-08-09 19:21:14 UTC",
      "updated_date": "2024-09-18 16:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:05:25.506767"
    },
    {
      "arxiv_id": "2408.05288v2",
      "title": "The impact of internal variability on benchmarking deep learning climate emulators",
      "title_zh": "翻译失败",
      "authors": [
        "Björn Lütjens",
        "Raffaele Ferrari",
        "Duncan Watson-Parris",
        "Noelle Selin"
      ],
      "abstract": "Full-complexity Earth system models (ESMs) are computationally very\nexpensive, limiting their use in exploring the climate outcomes of multiple\nemission pathways. More efficient emulators that approximate ESMs can directly\nmap emissions onto climate outcomes, and benchmarks are being used to evaluate\ntheir accuracy on standardized tasks and datasets. We investigate a popular\nbenchmark in data-driven climate emulation, ClimateBench, on which deep\nlearning-based emulators are currently achieving the best performance. We\ncompare these deep learning emulators with a linear regression-based emulator,\nakin to pattern scaling, and show that it outperforms the incumbent\n100M-parameter deep learning foundation model, ClimaX, on 3 out of 4\nregionally-resolved climate variables, notably surface temperature and\nprecipitation. While emulating surface temperature is expected to be\npredominantly linear, this result is surprising for emulating precipitation.\nPrecipitation is a much more noisy variable, and we show that deep learning\nemulators can overfit to internal variability noise at low frequencies,\ndegrading their performance in comparison to a linear emulator. We address the\nissue of overfitting by increasing the number of climate simulations per\nemission pathway (from 3 to 50) and updating the benchmark targets with the\nrespective ensemble averages from the MPI-ESM1.2-LR model. Using the new\ntargets, we show that linear pattern scaling continues to be more accurate on\ntemperature, but can be outperformed by a deep learning-based technique for\nemulating precipitation. We publish our code and data at\ngithub.com/blutjens/climate-emulator.",
      "tldr_zh": "本文研究了内部变异性对深度学习气候模拟器基准测试的影响，特别是针对ClimateBench基准。作者比较了深度学习模拟器（如ClimaX）和线性回归模拟器（类似于pattern scaling），发现线性方法在表面温度和降水等3个区域气候变量上表现更优，因为深度学习模型容易过拟合低频噪声。针对这一问题，他们通过增加每个排放路径的模拟次数（从3到50）并使用MPI-ESM1.2-LR模型的ensemble averages更新基准目标，结果显示线性模拟器在温度模拟上仍更准确，而深度学习方法在降水模拟上可实现超越。研究强调了改进基准测试以减少内部变异性影响的重要性，并发布了相关代码和数据。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05288v2",
      "published_date": "2024-08-09 18:17:17 UTC",
      "updated_date": "2025-03-31 16:06:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:05:38.811808"
    },
    {
      "arxiv_id": "2408.05285v1",
      "title": "Semi-Supervised One-Shot Imitation Learning",
      "title_zh": "半监督一-shot 模仿学习",
      "authors": [
        "Philipp Wu",
        "Kourosh Hakhamaneshi",
        "Yuqing Du",
        "Igor Mordatch",
        "Aravind Rajeswaran",
        "Pieter Abbeel"
      ],
      "abstract": "One-shot Imitation Learning~(OSIL) aims to imbue AI agents with the ability\nto learn a new task from a single demonstration. To supervise the learning,\nOSIL typically requires a prohibitively large number of paired expert\ndemonstrations -- i.e. trajectories corresponding to different variations of\nthe same semantic task. To overcome this limitation, we introduce the\nsemi-supervised OSIL problem setting, where the learning agent is presented\nwith a large dataset of trajectories with no task labels (i.e. an unpaired\ndataset), along with a small dataset of multiple demonstrations per semantic\ntask (i.e. a paired dataset). This presents a more realistic and practical\nembodiment of few-shot learning and requires the agent to effectively leverage\nweak supervision from a large dataset of trajectories. Subsequently, we develop\nan algorithm specifically applicable to this semi-supervised OSIL setting. Our\napproach first learns an embedding space where different tasks cluster\nuniquely. We utilize this embedding space and the clustering it supports to\nself-generate pairings between trajectories in the large unpaired dataset.\nThrough empirical results on simulated control tasks, we demonstrate that OSIL\nmodels trained on such self-generated pairings are competitive with OSIL models\ntrained with ground-truth labels, presenting a major advancement in the\nlabel-efficiency of OSIL.",
      "tldr_zh": "该论文提出了一种半监督的 One-Shot Imitation Learning (OSIL)，旨在让 AI 代理从单个演示中学习新任务，同时减少对大量配对专家轨迹的需求，通过结合一个大的无标签数据集（unpaired dataset）和一个小的有标签数据集（paired dataset）来实现更实际的 few-shot 学习。方法包括首先学习一个嵌入空间，使不同任务独特聚类，然后利用该空间自生成配对轨迹，以有效利用弱监督数据。实验结果显示，在模拟控制任务上，该算法的性能与使用真实标签的 OSIL 模型相当，显著提高了标签效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05285v1",
      "published_date": "2024-08-09 18:11:26 UTC",
      "updated_date": "2024-08-09 18:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:05:49.002311"
    },
    {
      "arxiv_id": "2408.05284v2",
      "title": "Can a Bayesian Oracle Prevent Harm from an Agent?",
      "title_zh": "翻译失败",
      "authors": [
        "Yoshua Bengio",
        "Michael K. Cohen",
        "Nikolay Malkin",
        "Matt MacDermott",
        "Damiano Fornasiere",
        "Pietro Greiner",
        "Younesse Kaddar"
      ],
      "abstract": "Is there a way to design powerful AI systems based on machine learning\nmethods that would satisfy probabilistic safety guarantees? With the long-term\ngoal of obtaining a probabilistic guarantee that would apply in every context,\nwe consider estimating a context-dependent bound on the probability of\nviolating a given safety specification. Such a risk evaluation would need to be\nperformed at run-time to provide a guardrail against dangerous actions of an\nAI. Noting that different plausible hypotheses about the world could produce\nvery different outcomes, and because we do not know which one is right, we\nderive bounds on the safety violation probability predicted under the true but\nunknown hypothesis. Such bounds could be used to reject potentially dangerous\nactions. Our main results involve searching for cautious but plausible\nhypotheses, obtained by a maximization that involves Bayesian posteriors over\nhypotheses. We consider two forms of this result, in the iid case and in the\nnon-iid case, and conclude with open problems towards turning such theoretical\nresults into practical AI guardrails.",
      "tldr_zh": "该研究探讨是否能通过一个Bayesian Oracle来防止AI代理造成伤害，旨在设计基于机器学习的AI系统以满足概率安全保证。\n他们提出在运行时估计上下文相关的安全违反概率上界，通过最大化Bayesian posteriors over hypotheses来搜索谨慎但合理的假设，从而推导出在未知真实假设下的安全风险界限。\n论文分别在iid和non-iid情况下提供了理论结果，并讨论了将这些界限转化为实际AI防护栏的开放问题。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05284v2",
      "published_date": "2024-08-09 18:10:42 UTC",
      "updated_date": "2024-08-22 19:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:06:00.371001"
    },
    {
      "arxiv_id": "2408.05211v2",
      "title": "VITA: Towards Open-Source Interactive Omni Multimodal LLM",
      "title_zh": "VITA：面向开源交互式全能多模态大语言模型",
      "authors": [
        "Chaoyou Fu",
        "Haojia Lin",
        "Zuwei Long",
        "Yunhang Shen",
        "Meng Zhao",
        "Yifan Zhang",
        "Shaoqi Dong",
        "Xiong Wang",
        "Di Yin",
        "Long Ma",
        "Xiawu Zheng",
        "Ran He",
        "Rongrong Ji",
        "Yunsheng Wu",
        "Caifeng Shan",
        "Xing Sun"
      ],
      "abstract": "The remarkable multimodal capabilities and interactive experience of GPT-4o\nunderscore their necessity in practical applications, yet open-source models\nrarely excel in both areas. In this paper, we introduce VITA, the first-ever\nopen-source Multimodal Large Language Model (MLLM) adept at simultaneous\nprocessing and analysis of Video, Image, Text, and Audio modalities, and\nmeanwhile has an advanced multimodal interactive experience. Starting from\nMixtral 8x7B as a language foundation, we expand its Chinese vocabulary\nfollowed by bilingual instruction tuning. We further endow the language model\nwith visual and audio capabilities through two-stage multi-task learning of\nmultimodal alignment and instruction tuning. VITA demonstrates robust\nfoundational capabilities of multilingual, vision, and audio understanding, as\nevidenced by its strong performance across a range of both unimodal and\nmultimodal benchmarks. Beyond foundational capabilities, we have made\nconsiderable progress in enhancing the natural multimodal human-computer\ninteraction experience. VITA is the first step for the open-source community to\nexplore the seamless integration of multimodal understanding and interaction.\nWhile there is still lots of work to be done on VITA to get close to\nclose-source counterparts, we hope that its role as a pioneer can serve as a\ncornerstone for subsequent research. Project Page: https://vita-home.github.io.",
      "tldr_zh": "本论文引入VITA，这是首个开源的多模态大语言模型(MLLM)，能够同时处理视频、图像、文本和音频，并提升自然的多模态人机交互体验。基于Mixtral 8x7B作为语言基础，研究团队扩展了中文词汇并进行双语指令调优，然后通过两阶段多任务学习（包括多模态对齐和指令调优）赋予模型视觉和音频能力。VITA在多语言、视觉和音频理解方面表现出色，在各种单模态和多模态基准测试中取得强劲性能，为开源社区探索多模态理解与交互的无缝集成奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://vita-home.github.io",
      "pdf_url": "http://arxiv.org/pdf/2408.05211v2",
      "published_date": "2024-08-09 17:59:49 UTC",
      "updated_date": "2024-09-10 13:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:06:12.705788"
    },
    {
      "arxiv_id": "2408.05200v4",
      "title": "KIF: Knowledge Identification and Fusion for Language Model Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Feng",
        "Xu Chu",
        "Yongxin Xu",
        "Zexin Lu",
        "Bo Liu",
        "Philip S. Yu",
        "Xiao-Ming Wu"
      ],
      "abstract": "Language model continual learning (CL) has recently attracted significant\ninterest for its ability to adapt large language models (LLMs) to dynamic\nreal-world scenarios without retraining. A major challenge in this domain is\ncatastrophic forgetting, where models lose previously acquired knowledge upon\nlearning new tasks. Existing approaches commonly utilize multiple\nparameter-efficient fine-tuning (PEFT) blocks to acquire task-specific\nknowledge, yet these methods are inefficient and fail to leverage potential\nknowledge transfer across tasks. In this paper, we introduce a novel CL\nframework for language models, named Knowledge Identification and Fusion (KIF),\nwhich boosts knowledge transfer without depending on memory replay. KIF\ninitially segregates the model into 'skill units' based on parameter\ndependencies, allowing for more precise control. Subsequently, it employs a\nnovel group-wise knowledge identification technique to ascertain the importance\ndistribution of skill units for a new task. By comparing this importance\ndistribution with those from previous tasks, we implement a fine-grained\nknowledge fusion strategy that retains task-specific knowledge, thereby\npreventing forgetting, and updates task-shared knowledge, which facilitates\nbi-directional knowledge transfer. As a result, KIF achieves an optimal balance\nbetween retaining prior knowledge and excelling in new tasks. KIF also\ndemonstrates strong generalizability, making it suitable for various base\nmodels and adaptable to PEFT methods like LoRA. Furthermore, it offers notable\nextensibility, supporting enhancements through integration with memory replay\ntechniques. Comprehensive experiments conducted on two CL benchmarks, involving\nmodels ranging from 220M to 7B parameters, affirm the effectiveness of KIF and\nits variants across different settings.",
      "tldr_zh": "本研究提出了一种名为 KIF 的语言模型持续学习 (CL) 框架，旨在解决灾难性遗忘问题，通过知识识别和融合技术提升知识转移效率，而无需依赖记忆回放。KIF 先将模型分解为基于参数依赖的 'skill units'，然后使用 group-wise 知识识别方法评估新任务中这些 units 的重要性分布，并通过比较实现细粒度知识融合：保留任务特定知识以防止遗忘，并更新共享知识促进双向转移。该框架表现出色，在各种基模型（从 220M 到 7B 参数）和 PEFT 方法如 LoRA 上具有强通用性和可扩展性，实验在两个 CL 基准上证实了 KIF 及其变体的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This version updates the model name from Task Skill Localization and\n  Consolidation (TaSL) to Knowledge Identification and Fusion (KIF). It is an\n  extension of the ACL 2024 paper titled Continual Dialog State Tracking via\n  Task Skill Localization and Consolidation",
      "pdf_url": "http://arxiv.org/pdf/2408.05200v4",
      "published_date": "2024-08-09 17:44:45 UTC",
      "updated_date": "2025-01-23 12:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:06:25.208869"
    },
    {
      "arxiv_id": "2408.05195v1",
      "title": "HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Piotr Keller",
        "Muhammad Dawood",
        "Brinder Singh Chohan",
        "Fayyaz ul Amir Afsar Minhas"
      ],
      "abstract": "Machine learning in computational pathology (CPath) often aggregates\npatch-level predictions from multi-gigapixel Whole Slide Images (WSIs) to\ngenerate WSI-level prediction scores for crucial tasks such as survival\nprediction and drug effect prediction. However, current methods do not\nexplicitly characterize distributional differences between patch sets within\nWSIs. We introduce HistoKernel, a novel Maximum Mean Discrepancy (MMD) kernel\nthat measures distributional similarity between WSIs for enhanced prediction\nperformance on downstream prediction tasks.\n  Our comprehensive analysis demonstrates HistoKernel's effectiveness across\nvarious machine learning tasks, including retrieval (n = 9,362), drug\nsensitivity regression (n = 551), point mutation classification (n = 3,419),\nand survival analysis (n = 2,291), outperforming existing deep learning\nmethods. Additionally, HistoKernel seamlessly integrates multi-modal data and\noffers a novel perturbation-based method for patch-level explainability. This\nwork pioneers the use of kernel-based methods for WSI-level predictive\nmodeling, opening new avenues for research. Code is available at\nhttps://github.com/pkeller00/HistoKernel.",
      "tldr_zh": "本论文提出 HistoKernel，一种基于 Maximum Mean Discrepancy (MMD) 内核的方法，用于量化 Whole Slide Images (WSIs) 之间分布差异，从而提升癌症预测建模的性能。HistoKernel 通过明确表征 WSI 内 patch 集的分布相似性，在多个任务中表现出色，包括检索 (n=9,362)、药物敏感性回归 (n=551)、点突变分类 (n=3,419) 和生存分析 (n=2,291)，其表现优于现有深度学习方法。论文还实现了多模态数据无缝整合和基于扰动的 patch-level 可解释性，开拓了内核方法在 WSI-level 预测建模的新研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 5 figures, 1 Table. Preprint for article in review at\n  Nature Machine Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2408.05195v1",
      "published_date": "2024-08-09 17:40:08 UTC",
      "updated_date": "2024-08-09 17:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:06:38.554694"
    },
    {
      "arxiv_id": "2408.05151v1",
      "title": "Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyang Hao",
        "Zhixi Feng",
        "Tongqing Peng",
        "Shuyuan Yang"
      ],
      "abstract": "Automatic modulation classification (AMC) is an effective way to deal with\nphysical layer threats of the internet of things (IoT). However, there is often\nlabel mislabeling in practice, which significantly impacts the performance and\nrobustness of deep neural networks (DNNs). In this paper, we propose a\nmeta-learning guided label noise distillation method for robust AMC.\nSpecifically, a teacher-student heterogeneous network (TSHN) framework is\nproposed to distill and reuse label noise. Based on the idea that labels are\nrepresentations, the teacher network with trusted meta-learning divides and\nconquers untrusted label samples and then guides the student network to learn\nbetter by reassessing and correcting labels. Furthermore, we propose a\nmulti-view signal (MVS) method to further improve the performance of\nhard-to-classify categories with few-shot trusted label samples. Extensive\nexperimental results show that our methods can significantly improve the\nperformance and robustness of signal AMC in various and complex label noise\nscenarios, which is crucial for securing IoT applications.",
      "tldr_zh": "本论文针对物联网（IoT）中的自动调制分类（AMC）问题，提出了一种基于meta-learning的标签噪声蒸馏方法，以提升深度神经网络（DNNs）的性能和鲁棒性。该方法采用teacher-student heterogeneous network (TSHN)框架，其中教师网络通过trusted meta-learning对未信任标签样本进行划分和修正，从而指导学生网络更好地学习和重用标签噪声。此外，论文引入multi-view signal (MVS)方法，利用少量可信标签样本改善难分类类别的识别。实验结果显示，该方法在各种复杂标签噪声场景下显著提高了信号AMC的性能和鲁棒性，对IoT安全应用至关重要。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "I.2; C.2"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.05151v1",
      "published_date": "2024-08-09 16:14:40 UTC",
      "updated_date": "2024-08-09 16:14:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:06:48.194060"
    },
    {
      "arxiv_id": "2408.05149v1",
      "title": "AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity Recognition Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Pritam Deka",
        "Sampath Rajapaksha",
        "Ruby Rani",
        "Amirah Almutairi",
        "Erisa Karafili"
      ],
      "abstract": "Cyber-attack attribution is an important process that allows experts to put\nin place attacker-oriented countermeasures and legal actions. The analysts\nmainly perform attribution manually, given the complex nature of this task. AI\nand, more specifically, Natural Language Processing (NLP) techniques can be\nleveraged to support cybersecurity analysts during the attribution process.\nHowever powerful these techniques are, they need to deal with the lack of\ndatasets in the attack attribution domain. In this work, we will fill this gap\nand will provide, to the best of our knowledge, the first dataset on\ncyber-attack attribution. We designed our dataset with the primary goal of\nextracting attack attribution information from cybersecurity texts, utilizing\nnamed entity recognition (NER) methodologies from the field of NLP. Unlike\nother cybersecurity NER datasets, ours offers a rich set of annotations with\ncontextual details, including some that span phrases and sentences. We\nconducted extensive experiments and applied NLP techniques to demonstrate the\ndataset's effectiveness for attack attribution. These experiments highlight the\npotential of Large Language Models (LLMs) capabilities to improve the NER tasks\nin cybersecurity datasets for cyber-attack attribution.",
      "tldr_zh": "该研究针对网络攻击归因(Cyber-Attack Attribution)的挑战，提出AttackER数据集，以支持AI和自然语言处理(NLP)技术在该领域的应用。数据集专注于从网络安全文本中提取归因信息，通过命名实体识别(NER)方法提供丰富的注释，包括跨越短语和句子的上下文细节，这是与其他网络安全NER数据集的区别。实验结果显示，大语言模型(LLMs)能够显著提升NER任务的性能，从而改善网络攻击归因过程的准确性和效率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted to WISE 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05149v1",
      "published_date": "2024-08-09 16:10:35 UTC",
      "updated_date": "2024-08-09 16:10:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:07:00.356164"
    },
    {
      "arxiv_id": "2408.05147v2",
      "title": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Lieberum",
        "Senthooran Rajamanoharan",
        "Arthur Conmy",
        "Lewis Smith",
        "Nicolas Sonnerat",
        "Vikrant Varma",
        "János Kramár",
        "Anca Dragan",
        "Rohin Shah",
        "Neel Nanda"
      ],
      "abstract": "Sparse autoencoders (SAEs) are an unsupervised method for learning a sparse\ndecomposition of a neural network's latent representations into seemingly\ninterpretable features. Despite recent excitement about their potential,\nresearch applications outside of industry are limited by the high cost of\ntraining a comprehensive suite of SAEs. In this work, we introduce Gemma Scope,\nan open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 2\n2B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEs\non the Gemma 2 pre-trained models, but additionally release SAEs trained on\ninstruction-tuned Gemma 2 9B for comparison. We evaluate the quality of each\nSAE on standard metrics and release these results. We hope that by releasing\nthese SAE weights, we can help make more ambitious safety and interpretability\nresearch easier for the community. Weights and a tutorial can be found at\nhttps://huggingface.co/google/gemma-scope and an interactive demo can be found\nat https://www.neuronpedia.org/gemma-scope",
      "tldr_zh": "该论文介绍了 Gemma Scope，这是一个开源的 Sparse Autoencoders (SAEs) 套件，旨在通过无监督方法学习神经网络潜在表示的稀疏分解，以提升模型的可解释性。研究者训练了 JumpReLU SAEs 于 Gemma 2 模型的所有层和子层，包括 2B、9B 和部分 27B 版本，并与指令微调模型进行了比较。实验结果显示 SAEs 在标准指标上表现出色，并通过发布权重和教程（如在 Hugging Face 和 Neuronpedia 上），帮助社区降低训练成本，促进更深入的安全性和可解释性研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "12 main text pages, and 14 pages of acknowledgements, references and\n  appendices",
      "pdf_url": "http://arxiv.org/pdf/2408.05147v2",
      "published_date": "2024-08-09 16:06:42 UTC",
      "updated_date": "2024-08-19 07:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:07:13.437710"
    },
    {
      "arxiv_id": "2408.05128v1",
      "title": "Is ChatGPT a Good Software Librarian? An Exploratory Study on the Use of ChatGPT for Software Library Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Jasmine Latendresse",
        "SayedHassan Khatoonabadi",
        "Ahmad Abdellatif",
        "Emad Shihab"
      ],
      "abstract": "Software libraries play a critical role in the functionality, efficiency, and\nmaintainability of software systems. As developers increasingly rely on Large\nLanguage Models (LLMs) to streamline their coding processes, the effectiveness\nof these models in recommending appropriate libraries becomes crucial yet\nremains largely unexplored. In this paper, we assess the effectiveness of\nChatGPT as a software librarian and identify areas for improvement. We\nconducted an empirical study using GPT-3.5 Turbo to generate Python code for\n10,000 Stack Overflow questions. Our findings show that ChatGPT uses\nthird-party libraries nearly 10% more often than human developers, favoring\nwidely adopted and well-established options. However, 14.2% of the recommended\nlibraries had restrictive copyleft licenses, which were not explicitly\ncommunicated by ChatGPT. Additionally, 6.5% of the libraries did not work out\nof the box, leading to potential developer confusion and wasted time. While\nChatGPT can be an effective software librarian, it should be improved by\nproviding more explicit information on maintainability metrics and licensing.\nWe recommend that developers implement rigorous dependency management practices\nand double-check library licenses before integrating LLM-generated code into\ntheir projects.",
      "tldr_zh": "本文通过一项实证研究评估了 ChatGPT 作为软件库推荐工具的有效性，使用 GPT-3.5 Turbo 为 10,000 个 Stack Overflow 问题生成 Python 代码。结果显示，ChatGPT 使用第三方库比人类开发者多约 10%，偏好广泛采用的选项，但 14.2% 的推荐库涉及 restrictive copyleft licenses，且未明确说明；此外，6.5% 的库无法直接使用，可能导致开发者困惑和时间浪费。研究建议改进 ChatGPT 以提供更多关于库的 maintainability metrics 和 licensing 信息，并推荐开发者采用严格的 dependency management 实践。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Submitted",
      "pdf_url": "http://arxiv.org/pdf/2408.05128v1",
      "published_date": "2024-08-09 15:36:59 UTC",
      "updated_date": "2024-08-09 15:36:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:07:25.656874"
    },
    {
      "arxiv_id": "2408.05120v1",
      "title": "Cautious Calibration in Binary Classification",
      "title_zh": "二元分类中的谨慎校准",
      "authors": [
        "Mari-Liis Allikivi",
        "Joonas Järve",
        "Meelis Kull"
      ],
      "abstract": "Being cautious is crucial for enhancing the trustworthiness of machine\nlearning systems integrated into decision-making pipelines. Although calibrated\nprobabilities help in optimal decision-making, perfect calibration remains\nunattainable, leading to estimates that fluctuate between under- and\noverconfidence. This becomes a critical issue in high-risk scenarios, where\neven occasional overestimation can lead to extreme expected costs. In these\nscenarios, it is important for each predicted probability to lean towards\nunderconfidence, rather than just achieving an average balance. In this study,\nwe introduce the novel concept of cautious calibration in binary\nclassification. This approach aims to produce probability estimates that are\nintentionally underconfident for each predicted probability. We highlight the\nimportance of this approach in a high-risk scenario and propose a theoretically\ngrounded method for learning cautious calibration maps. Through experiments, we\nexplore and compare our method to various approaches, including methods\noriginally not devised for cautious calibration but applicable in this context.\nWe show that our approach is the most consistent in providing cautious\nestimates. Our work establishes a strong baseline for further developments in\nthis novel framework.",
      "tldr_zh": "该研究强调，在高风险决策场景中，机器学习系统的谨慎性至关重要，因为传统概率校准可能导致预测概率在低估和高估之间波动，从而引发严重后果。论文引入了新型概念“cautious calibration”，旨在使二元分类(binary classification)的每个预测概率有意倾向于低估(underconfidence)，并提出了一种理论基础的方法来学习这种校准映射。通过实验比较，该方法在提供一致的谨慎估计方面优于其他方法，为高风险场景下的可信赖机器学习系统奠定了坚实基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05120v1",
      "published_date": "2024-08-09 15:19:40 UTC",
      "updated_date": "2024-08-09 15:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:07:36.389216"
    },
    {
      "arxiv_id": "2408.05117v2",
      "title": "Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images",
      "title_zh": "翻译失败",
      "authors": [
        "Shouyue Liu",
        "Ziyi Zhang",
        "Yuanyuan Gu",
        "Jinkui Hao",
        "Yonghuai Liu",
        "Huazhu Fu",
        "Xinyu Guo",
        "Hong Song",
        "Shuting Zhang",
        "Yitian Zhao"
      ],
      "abstract": "Early detection of dementia, such as Alzheimer's disease (AD) or mild\ncognitive impairment (MCI), is essential to enable timely intervention and\npotential treatment. Accurate detection of AD/MCI is challenging due to the\nhigh complexity, cost, and often invasive nature of current diagnostic\ntechniques, which limit their suitability for large-scale population screening.\nGiven the shared embryological origins and physiological characteristics of the\nretina and brain, retinal imaging is emerging as a potentially rapid and\ncost-effective alternative for the identification of individuals with or at\nhigh risk of AD. In this paper, we present a novel PolarNet+ that uses retinal\noptical coherence tomography angiography (OCTA) to discriminate early-onset AD\n(EOAD) and MCI subjects from controls. Our method first maps OCTA images from\nCartesian coordinates to polar coordinates, allowing approximate sub-region\ncalculation to implement the clinician-friendly early treatment of diabetic\nretinopathy study (ETDRS) grid analysis. We then introduce a multi-view module\nto serialize and analyze the images along three dimensions for comprehensive,\nclinically useful information extraction. Finally, we abstract the sequence\nembedding into a graph, transforming the detection task into a general graph\nclassification problem. A regional relationship module is applied after the\nmulti-view module to excavate the relationship between the sub-regions. Such\nregional relationship analyses validate known eye-brain links and reveal new\ndiscriminative patterns.",
      "tldr_zh": "本研究提出了一种名为 PolarNet+ 的新模型，利用视网膜光学相干断层血管造影（OCTA）图像来检测早发性阿尔茨海默病（EOAD）和轻度认知障碍（MCI），以克服传统诊断方法的高复杂性和侵入性问题。方法首先将 OCTA 图像从笛卡尔坐标映射到极坐标，并结合 early treatment of diabetic retinopathy study (ETDRS) 网格分析，然后通过 multi-view module 序列化和多维度分析图像，并将序列嵌入转化为图分类问题，最后应用 regional relationship module 挖掘子区域间的关系。实验结果验证了已知的眼脑联系，并揭示了新的鉴别模式，为快速、经济的痴呆早期筛查提供可行方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05117v2",
      "published_date": "2024-08-09 15:10:34 UTC",
      "updated_date": "2025-03-12 08:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:07:50.508631"
    },
    {
      "arxiv_id": "2408.05109v4",
      "title": "A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Liu",
        "Shuyu Shen",
        "Boyan Li",
        "Peixian Ma",
        "Runzhi Jiang",
        "Yuxin Zhang",
        "Ju Fan",
        "Guoliang Li",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Translating users' natural language queries (NL) into SQL queries (i.e.,\nNL2SQL, a.k.a., Text-to-SQL) can significantly reduce barriers to accessing\nrelational databases and support various commercial applications. The\nperformance of NL2SQL has been greatly enhanced with the emergence of Large\nLanguage Models (LLMs). In this survey, we provide a comprehensive review of\nNL2SQL techniques powered by LLMs, covering its entire lifecycle from the\nfollowing four aspects: (1) Model: NL2SQL translation techniques that tackle\nnot only NL ambiguity and under-specification, but also properly map NL with\ndatabase schema and instances; (2) Data: From the collection of training data,\ndata synthesis due to training data scarcity, to NL2SQL benchmarks; (3)\nEvaluation: Evaluating NL2SQL methods from multiple angles using different\nmetrics and granularities; and (4) Error Analysis: analyzing NL2SQL errors to\nfind the root cause and guiding NL2SQL models to evolve. Moreover, we provide a\nrule of thumb for developing NL2SQL solutions. Finally, we discuss the research\nchallenges and open problems of NL2SQL in the LLMs era.",
      "tldr_zh": "这篇调查论文回顾了使用大型语言模型（Large Language Models, LLMs）进行自然语言到SQL查询转换（NL2SQL）的技术现状和发展方向。论文从四个方面全面分析NL2SQL的生命周期：模型（处理NL模糊性和数据库映射）、数据（包括训练数据收集、合成和基准测试）、评估（采用多种指标和粒度）和错误分析（识别根因并指导模型改进）。此外，论文提供了开发NL2SQL解决方案的实用经验法则，并讨论了当前挑战和未来开放问题，如提升模型鲁棒性和数据可用性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "20 pages, 11 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.05109v4",
      "published_date": "2024-08-09 14:59:36 UTC",
      "updated_date": "2025-03-04 06:51:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:08:01.276913"
    },
    {
      "arxiv_id": "2408.07091v2",
      "title": "Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning",
      "title_zh": "节点级图自编码器：用于文本图学习的统一预训练",
      "authors": [
        "Wenbin Hu",
        "Huihao Jing",
        "Qi Hu",
        "Haoran Li",
        "Yangqiu Song"
      ],
      "abstract": "Textual graphs are ubiquitous in real-world applications, featuring rich text\ninformation with complex relationships, which enables advanced research across\nvarious fields. Textual graph representation learning aims to generate\nlow-dimensional feature embeddings from textual graphs that can improve the\nperformance of downstream tasks. A high-quality feature embedding should\neffectively capture both the structural and the textual information in a\ntextual graph. However, most textual graph dataset benchmarks rely on word2vec\ntechniques to generate feature embeddings, which inherently limits their\ncapabilities. Recent works on textual graph representation learning can be\ncategorized into two folds: supervised and unsupervised methods. Supervised\nmethods finetune a language model on labeled nodes, which have limited\ncapabilities when labeled data is scarce. Unsupervised methods, on the other\nhand, extract feature embeddings by developing complex training pipelines. To\naddress these limitations, we propose a novel unified unsupervised learning\nautoencoder framework, named Node Level Graph AutoEncoder (NodeGAE). We employ\nlanguage models as the backbone of the autoencoder, with pretraining on text\nreconstruction. Additionally, we add an auxiliary loss term to make the feature\nembeddings aware of the local graph structure. Our method maintains simplicity\nin the training process and demonstrates generalizability across diverse\ntextual graphs and downstream tasks. We evaluate our method on two core graph\nrepresentation learning downstream tasks: node classification and link\nprediction. Comprehensive experiments demonstrate that our approach\nsubstantially enhances the performance of diverse graph neural networks (GNNs)\nacross multiple textual graph datasets.",
      "tldr_zh": "这篇论文针对文本图（textual graphs）的表示学习问题，提出了一种统一的预训练框架Node Level Graph AutoEncoder (NodeGAE)，旨在生成高质量的特征嵌入，同时捕捉图结构和文本信息。NodeGAE以语言模型作为自编码器骨干，进行文本重构预训练，并添加辅助损失以增强对局部图结构的感知，从而简化训练过程并提升泛化性。在节点分类和链接预测等下游任务上，实验证明该方法显著提高了多种图神经网络（GNNs）的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07091v2",
      "published_date": "2024-08-09 14:57:53 UTC",
      "updated_date": "2024-08-21 05:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:08:13.057883"
    },
    {
      "arxiv_id": "2408.05101v1",
      "title": "MooER: LLM-based Speech Recognition and Translation Models from Moore Threads",
      "title_zh": "翻译失败",
      "authors": [
        "Junhao Xu",
        "Zhenlin Liang",
        "Yi Liu",
        "Yichao Hu",
        "Jian Li",
        "Yajun Zheng",
        "Meng Cai",
        "Hua Wang"
      ],
      "abstract": "In this paper, we present MooER, a LLM-based large-scale automatic speech\nrecognition (ASR) / automatic speech translation (AST) model of Moore Threads.\nA 5000h pseudo labeled dataset containing open source and self collected speech\ndata is used for training. We achieve performance comparable to other open\nsource models trained with up to hundreds of thousands of hours of labeled\nspeech data. Meanwhile, experiments conducted on Covost2 Zh2en testset suggest\nthat our model outperforms other open source Speech LLMs. A BLEU score of 25.2\ncan be obtained. The main contributions of this paper are summarized as\nfollows. First, this paper presents a training strategy for encoders and LLMs\non speech related tasks (including ASR and AST) using a small size of pseudo\nlabeled data without any extra manual annotation and selection. Second, we\nrelease our ASR and AST models and plan to open-source our training code and\nstrategy in the near future. Moreover, a model trained on 8wh scale training\ndata is planned to be released later on.",
      "tldr_zh": "本研究介绍了 MooER，一种基于 LLM 的自动语音识别 (ASR) 和自动语音翻译 (AST) 模型，由 Moore Threads 开发，使用 5000 小时伪标记数据集进行训练，而无需额外手动标注。研究提出了一种高效训练策略，针对编码器和 LLM 在 ASR 和 AST 任务上的优化，使其性能可与使用数十万小时标记数据的开源模型相当，并在 Covost2 Zh2en 测试集上实现 BLEU 分数 25.2，优于其他开源语音 LLM。主要贡献包括开源模型和训练代码的计划，以及未来发布更大规模训练模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05101v1",
      "published_date": "2024-08-09 14:43:56 UTC",
      "updated_date": "2024-08-09 14:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:08:25.253763"
    },
    {
      "arxiv_id": "2408.05100v2",
      "title": "AI-driven Java Performance Testing: Balancing Result Quality with Testing Time",
      "title_zh": "AI驱动的 Java 性能测试：平衡结果质量与测试时间",
      "authors": [
        "Luca Traini",
        "Federico Di Menna",
        "Vittorio Cortellessa"
      ],
      "abstract": "Performance testing aims at uncovering efficiency issues of software systems.\nIn order to be both effective and practical, the design of a performance test\nmust achieve a reasonable trade-off between result quality and testing time.\nThis becomes particularly challenging in Java context, where the software\nundergoes a warm-up phase of execution, due to just-in-time compilation. During\nthis phase, performance measurements are subject to severe fluctuations, which\nmay adversely affect quality of performance test results. However, these\napproaches often provide suboptimal estimates of the warm-up phase, resulting\nin either insufficient or excessive warm-up iterations, which may degrade\nresult quality or increase testing time. There is still a lack of consensus on\nhow to properly address this problem. Here, we propose and study an AI-based\nframework to dynamically halt warm-up iterations at runtime. Specifically, our\nframework leverages recent advances in AI for Time Series Classification (TSC)\nto predict the end of the warm-up phase during test execution. We conduct\nexperiments by training three different TSC models on half a million of\nmeasurement segments obtained from JMH microbenchmark executions. We find that\nour framework significantly improves the accuracy of the warm-up estimates\nprovided by state-of-practice and state-of-the-art methods. This higher\nestimation accuracy results in a net improvement in either result quality or\ntesting time for up to +35.3% of the microbenchmarks. Our study highlights that\nintegrating AI to dynamically estimate the end of the warm-up phase can enhance\nthe cost-effectiveness of Java performance testing.",
      "tldr_zh": "该研究针对 Java 性能测试中结果质量与测试时间之间的平衡问题，特别关注软件热身阶段(warm-up phase)导致的性能测量波动。论文提出一个 AI-driven 框架，利用 Time Series Classification (TSC) 模型动态预测热身阶段的结束，从而优化测试过程。实验通过在 JMH 微基准测试上训练三个 TSC 模型，并分析半百万测量段的数据，结果显示该框架比现有方法提高了热身估计准确性，为多达 35.3% 的微基准测试显著提升了结果质量或减少了测试时间。该框架证明了整合 AI 可以增强 Java 性能测试的成本效益。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication in The 39th IEEE/ACM International\n  Conference on Automated Software Engineering (ASE '24)",
      "pdf_url": "http://arxiv.org/pdf/2408.05100v2",
      "published_date": "2024-08-09 14:41:32 UTC",
      "updated_date": "2024-09-14 11:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:08:37.635847"
    },
    {
      "arxiv_id": "2408.05098v1",
      "title": "Overcoming the Limitations of Layer Synchronization in Spiking Neural Networks",
      "title_zh": "克服脉冲神经网络中层同步的限制",
      "authors": [
        "Roel Koopman",
        "Amirreza Yousefzadeh",
        "Mahyar Shahsavari",
        "Guangzhi Tang",
        "Manolis Sifalakis"
      ],
      "abstract": "Currently, neural-network processing in machine learning applications relies\non layer synchronization, whereby neurons in a layer aggregate incoming\ncurrents from all neurons in the preceding layer, before evaluating their\nactivation function. This is practiced even in artificial Spiking Neural\nNetworks (SNNs), which are touted as consistent with neurobiology, in spite of\nprocessing in the brain being, in fact asynchronous. A truly asynchronous\nsystem however would allow all neurons to evaluate concurrently their threshold\nand emit spikes upon receiving any presynaptic current. Omitting layer\nsynchronization is potentially beneficial, for latency and energy efficiency,\nbut asynchronous execution of models previously trained with layer\nsynchronization may entail a mismatch in network dynamics and performance. We\npresent a study that documents and quantifies this problem in three datasets on\nour simulation environment that implements network asynchrony, and we show that\nmodels trained with layer synchronization either perform sub-optimally in\nabsence of the synchronization, or they will fail to benefit from any energy\nand latency reduction, when such a mechanism is in place. We then \"make ends\nmeet\" and address the problem with unlayered backprop, a novel\nbackpropagation-based training method, for learning models suitable for\nasynchronous processing. We train with it models that use different neuron\nexecution scheduling strategies, and we show that although their neurons are\nmore reactive, these models consistently exhibit lower overall spike density\n(up to 50%), reach a correct decision faster (up to 2x) without integrating all\nspikes, and achieve superior accuracy (up to 10% higher). Our findings suggest\nthat asynchronous event-based (neuromorphic) AI computing is indeed more\nefficient, but we need to seriously rethink how we train our SNN models, to\nbenefit from it.",
      "tldr_zh": "本研究探讨了Spiking Neural Networks (SNNs)中层同步(layer synchronization)的局限性，该机制导致神经元仅在从前一层聚合所有输入后才激活，从而与大脑的异步处理方式不符，并可能降低延迟和能耗效率。论文通过在三个数据集上模拟异步环境，证明了训练时使用层同步的模型在异步执行中会面临性能不匹配的问题。作者提出了一种新方法unlayered backprop，一种基于反向传播的训练策略，用于训练适合异步处理的SNN模型，结果显示这些模型的神经元更具响应性，整体spike密度降低多达50%，决策速度提高多达2倍，并提升准确率多达10%。这项工作强调，异步事件驱动(neuromorphic)AI计算更高效，但需重新设计SNN训练方法以充分发挥其潜力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05098v1",
      "published_date": "2024-08-09 14:39:23 UTC",
      "updated_date": "2024-08-09 14:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:08:49.909678"
    },
    {
      "arxiv_id": "2408.05097v1",
      "title": "Hyperbolic Learning with Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Paolo Mandica",
        "Luca Franco",
        "Konstantinos Kallidromitis",
        "Suzanne Petryk",
        "Fabio Galasso"
      ],
      "abstract": "Hyperbolic embeddings have demonstrated their effectiveness in capturing\nmeasures of uncertainty and hierarchical relationships across various\ndeep-learning tasks, including image segmentation and active learning. However,\ntheir application in modern vision-language models (VLMs) has been limited. A\nnotable exception is MERU, which leverages the hierarchical properties of\nhyperbolic space in the CLIP ViT-large model, consisting of hundreds of\nmillions parameters. In our work, we address the challenges of scaling\nmulti-modal hyperbolic models by orders of magnitude in terms of parameters\n(billions) and training complexity using the BLIP-2 architecture. Although\nhyperbolic embeddings offer potential insights into uncertainty not present in\nEuclidean embeddings, our analysis reveals that scaling these models is\nparticularly difficult. We propose a novel training strategy for a hyperbolic\nversion of BLIP-2, which allows to achieve comparable performance to its\nEuclidean counterpart, while maintaining stability throughout the training\nprocess and showing a meaningful indication of uncertainty with each embedding.",
      "tldr_zh": "本文研究了Hyperbolic embeddings在多模态大型语言模型中的应用，旨在解决这些嵌入在捕捉不确定性和层次关系方面的潜力，同时克服其在VLMs（如BLIP-2）中扩展到亿级参数的训练复杂性挑战。作者提出了一种新型训练策略，用于训练Hyperbolic版本的BLIP-2模型，确保其性能与Euclidean对应模型相当，并维持训练稳定性。实验结果表明，该策略能通过嵌入提供有意义的uncertainty指示，为大规模视觉语言模型的层次化表示铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ECCV 2024 - Beyond Euclidean Workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.05097v1",
      "published_date": "2024-08-09 14:39:15 UTC",
      "updated_date": "2024-08-09 14:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:09:02.597909"
    },
    {
      "arxiv_id": "2408.05093v4",
      "title": "Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zikai Xie"
      ],
      "abstract": "Large language models (LLMs) have generated significant attention since their\ninception, finding applications across various academic and industrial domains.\nHowever, these models often suffer from the \"hallucination problem\", where\noutputs, though grammatically and logically coherent, lack factual accuracy or\nare entirely fabricated. A particularly troubling issue discovered and widely\ndiscussed recently is the numerical comparison error where multiple LLMs\nincorrectly infer that \"9.11$>$9.9\". We discovered that the order in which LLMs\ngenerate answers and reasoning impacts their consistency. Specifically, results\nvary significantly when an LLM generates an answer first and then provides the\nreasoning versus generating the reasoning process first and then the\nconclusion. Inspired by this, we propose a new benchmark method for assessing\nLLM consistency: comparing responses generated through these two different\napproaches. This benchmark effectively identifies instances where LLMs\nfabricate answers and subsequently generate justifications. Furthermore, we\nintroduce a novel and straightforward prompt strategy designed to mitigate this\nissue. Experimental results demonstrate that this strategy improves performance\nacross various LLMs compared to direct questioning. This work not only sheds\nlight on a critical flaw in LLMs but also offers a practical solution to\nenhance their reliability.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）在处理幻觉问题（hallucination）时的关键缺陷，即生成答案的顺序会影响输出一致性，例如先生成答案再推理与先推理再生成答案的差异可能导致错误，如错误判断“9.11 > 9.9”。为了评估这一问题，作者提出一个新的基准方法（benchmark），通过比较这两种推理顺序的响应来识别LLMs的虚假答案和后续解释。基于此，他们引入了一种简单有效的提示策略（reflexive prompting），实验结果显示该策略显著提高了各种LLMs的性能和可靠性，为缓解幻觉问题提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, submitted to ACL ARR",
      "pdf_url": "http://arxiv.org/pdf/2408.05093v4",
      "published_date": "2024-08-09 14:34:32 UTC",
      "updated_date": "2025-05-12 01:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:09:15.227892"
    },
    {
      "arxiv_id": "2408.05086v2",
      "title": "Generating novel experimental hypotheses from language models: A case study on cross-dative generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Kanishka Misra",
        "Najoung Kim"
      ],
      "abstract": "Neural network language models (LMs) have been shown to successfully capture\ncomplex linguistic knowledge. However, their utility for understanding language\nacquisition is still debated. We contribute to this debate by presenting a case\nstudy where we use LMs as simulated learners to derive novel experimental\nhypotheses to be tested with humans. We apply this paradigm to study\ncross-dative generalization (CDG): productive generalization of novel verbs\nacross dative constructions (she pilked me the ball/she pilked the ball to\nme)--acquisition of which is known to involve a large space of contextual\nfeatures--using LMs trained on child-directed speech. We specifically ask:\n\"what properties of the training exposure facilitate a novel verb's\ngeneralization to the (unmodeled) alternate construction?\" To answer this, we\nsystematically vary the exposure context in which a novel dative verb occurs in\nterms of the properties of the theme and recipient, and then analyze the LMs'\nusage of the novel verb in the unmodeled dative construction. We find LMs to\nreplicate known patterns of children's CDG, as a precondition to exploring\nnovel hypotheses. Subsequent simulations reveal a nuanced role of the features\nof the novel verbs' exposure context on the LMs' CDG. We find CDG to be\nfacilitated when the first postverbal argument of the exposure context is\npronominal, definite, short, and conforms to the prototypical animacy\nexpectations of the exposure dative. These patterns are characteristic of\nharmonic alignment in datives, where the argument with features ranking higher\non the discourse prominence scale tends to precede the other. This gives rise\nto a novel hypothesis that CDG is facilitated insofar as the features of the\nexposure context--in particular, its first postverbal argument--are\nharmonically aligned. We conclude by proposing future experiments that can test\nthis hypothesis in children.",
      "tldr_zh": "本研究利用神经网络语言模型 (LMs) 作为模拟学习者，生成新的实验假设，焦点是 cross-dative generalization (CDG)，即新动词在新与格结构中的泛化，通过在儿童导向语言上训练 LMs 并系统改变暴露上下文的特性。\n结果显示，LMs 复制了儿童的 CDG 模式，且 CDG 更容易在暴露上下文中发生，当第一个后动词参数是代词、确定的、短的，并符合暴露与格的典型动画性期望。\n这些发现揭示了和谐对齐在 CDG 中的微妙作用，提出新假设：CDG 的促进取决于暴露上下文（尤其是第一个后动词参数）的和谐对齐，并建议未来实验在儿童中测试此假设。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated template and affiliation for first author. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2408.05086v2",
      "published_date": "2024-08-09 14:17:36 UTC",
      "updated_date": "2024-10-28 14:30:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:09:28.617247"
    },
    {
      "arxiv_id": "2408.05082v1",
      "title": "Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yangdi Wang",
        "Zhi-Hai Zhang",
        "Su Xiu Xu",
        "Wenming Guo"
      ],
      "abstract": "Overfitting commonly occurs when applying deep neural networks (DNNs) on\nsmall-scale datasets, where DNNs do not generalize well from existing data to\nunseen data. The main reason resulting in overfitting is that small-scale\ndatasets cannot reflect the situations of the real world. Label smoothing (LS)\nis an effective regularization method to prevent overfitting, avoiding it by\nmixing one-hot labels with uniform label vectors. However, LS only focuses on\nlabels while ignoring the distribution of existing data. In this paper, we\nintroduce the distributionally robust optimization (DRO) to LS, achieving shift\nthe existing data distribution flexibly to unseen domains when training DNNs.\nSpecifically, we prove that the regularization of LS can be extended to a\nregularization term for the DNNs parameters when integrating DRO. The\nregularization term can be utilized to shift existing data to unseen domains\nand generate new data. Furthermore, we propose an approximate\ngradient-iteration label smoothing algorithm (GI-LS) to achieve the findings\nand train DNNs. We prove that the shift for the existing data does not\ninfluence the convergence of GI-LS. Since GI-LS incorporates a series of\nhyperparameters, we further consider using Bayesian optimization (BO) to find\nthe relatively optimal combinations of these hyperparameters. Taking\nsmall-scale anomaly classification tasks as a case, we evaluate GI-LS, and the\nresults clearly demonstrate its superior performance.",
      "tldr_zh": "本研究针对小规模数据集训练深度神经网络 (DNNs) 时常见的过拟合问题，提出了一种将 Label Smoothing (LS) 与 Distributionally Robust Optimization (DRO) 整合的方法，以灵活地将现有数据分布转移到未见领域。研究证明，LS 的正则化可以扩展为 DNNs 参数的正则化项，用于生成新数据，并引入了近似梯度迭代标签平滑算法 (GI-LS)，确保数据转移不会影响算法的收敛。同时，通过 Bayesian Optimization (BO) 优化 GI-LS 的超参数，提升模型泛化性能。在小规模异常分类任务的实验中，该方法显示出显著优越的性能，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05082v1",
      "published_date": "2024-08-09 14:13:33 UTC",
      "updated_date": "2024-08-09 14:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:09:39.632117"
    },
    {
      "arxiv_id": "2408.12619v1",
      "title": "Educational Customization by Homogenous Grouping of e-Learners based on their Learning Styles",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadreza amiri",
        "GholamAli montazer",
        "Ebrahim Mousavi"
      ],
      "abstract": "The E-learning environment offers greater flexibility compared to\nface-to-face interactions, allowing for adapting educational content to meet\nlearners' individual needs and abilities through personalization and\ncustomization of e-content and the educational process. Despite the advantages\nof this approach, customizing the learning environment can reduce the costs of\ntutoring systems for similar learners by utilizing the same content and process\nfor co-like learning groups. Various indicators for grouping learners exist,\nbut many of them are conceptual, uncertain, and subject to change over time. In\nthis article, we propose using the Felder-Silverman model, which is based on\nlearning styles, to group similar learners. Additionally, we model the\nbehaviors and actions of e-learners in a network environment using Fuzzy Set\nTheory (FST). After identifying the learning styles of the learners, co-like\nlearning groups are formed, and each group receives adaptive content based on\ntheir preferences, needs, talents, and abilities. By comparing the results of\nthe experimental and control groups, we determine the effectiveness of the\nproposed grouping method. In terms of \"educational success,\" the weighted\naverage score of the experimental group is 17.65 out of 20, while the control\ngroup achieves a score of 12.6 out of 20. Furthermore, the \"educational\nsatisfaction\" of the experimental group is 67%, whereas the control group's\nsatisfaction level is 37%.",
      "tldr_zh": "本研究提出了一种基于学习风格的同质分组方法，用于e-Learners的教育定制，旨在通过Felder-Silverman模型和Fuzzy Set Theory (FST)建模学习者的行为和行动，从而形成类似学习组并提供适应性内容。相比传统方法，该方法可降低辅导系统成本，同时满足学习者的偏好、需求和能力。实验结果显示，实验组的教育成功得分达17.65/20，教育满意度为67%，均显著高于控制组的12.6/20和37%，证明了该分组策略的有效性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12619v1",
      "published_date": "2024-08-09 14:06:42 UTC",
      "updated_date": "2024-08-09 14:06:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:09:49.949305"
    },
    {
      "arxiv_id": "2408.05074v5",
      "title": "Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records",
      "title_zh": "翻译失败",
      "authors": [
        "Sangjoon Park",
        "Chan Woo Wee",
        "Seo Hee Choi",
        "Kyung Hwan Kim",
        "Jee Suk Chang",
        "Hong In Yoon",
        "Ik Jae Lee",
        "Yong Bae Kim",
        "Jaeho Cho",
        "Ki Chang Keum",
        "Chang Geol Lee",
        "Hwa Kyung Byun",
        "Woong Sub Koom"
      ],
      "abstract": "Accurate survival prediction in radiotherapy (RT) is critical for optimizing\ntreatment decisions. This study developed and validated the RT-Surv framework,\nwhich integrates general-domain, open-source large language models (LLMs) to\nstructure unstructured electronic health records alongside structured clinical\ndata. Using data from 34,276 patients and an external cohort of 852, the\nframework successfully transformed unstructured clinical information into\nstructured formats. Incorporating LLM-structured clinical features improved the\nconcordance index from 0.779 to 0.842 during external validation, demonstrating\na significant performance enhancement. Key LLM-structured features, such as\ndisease extent, general condition, and RT purpose, showed high predictive\nimportance and aligned closely with statistically significant predictors\nidentified through conventional statistical analyses, thereby improving model\ninterpretability. Furthermore, the framework enhanced risk stratification,\nenabling more distinct differentiation among low-, intermediate-, and high-risk\ngroups (p < 0.001) using LLM-structured clinical features. These findings\nhighlight the potential of LLMs to convert unstructured data into actionable\ninsights, improving predictive modeling and patient outcomes in clinics.",
      "tldr_zh": "该研究开发了 RT-Surv 框架，利用开源的大型语言模型 (LLMs) 来结构化大规模非结构化电子健康记录 (EHRs)，并与结构化临床数据整合，以提升放射治疗 (RT) 后的死亡率预测准确性。使用来自 34,276 名患者的数据和 852 名外部队列，框架成功地将非结构化信息转化为结构化格式，导致外部验证中一致性指数 (concordance index) 从 0.779 提高到 0.842。关键的 LLM 结构化特征，如疾病范围 (disease extent)、一般状况 (general condition) 和 RT 目的，显示出高预测重要性，并与传统统计分析结果一致，提高了模型的可解释性。该框架还改善了风险分层 (risk stratification)，使低、中、高风险组的区分更明显 (p < 0.001)，从而为临床预测建模和患者预后提供可操作洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 2 tables, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.05074v5",
      "published_date": "2024-08-09 14:02:24 UTC",
      "updated_date": "2024-12-11 10:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:10:05.073655"
    },
    {
      "arxiv_id": "2408.05061v1",
      "title": "A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares",
      "title_zh": "翻译失败",
      "authors": [
        "Stav Cohen",
        "Ron Bitton",
        "Ben Nassi"
      ],
      "abstract": "In this paper we argue that a jailbroken GenAI model can cause substantial\nharm to GenAI-powered applications and facilitate PromptWare, a new type of\nattack that flips the GenAI model's behavior from serving an application to\nattacking it. PromptWare exploits user inputs to jailbreak a GenAI model to\nforce/perform malicious activity within the context of a GenAI-powered\napplication. First, we introduce a naive implementation of PromptWare that\nbehaves as malware that targets Plan & Execute architectures (a.k.a., ReAct,\nfunction calling). We show that attackers could force a desired execution flow\nby creating a user input that produces desired outputs given that the logic of\nthe GenAI-powered application is known to attackers. We demonstrate the\napplication of a DoS attack that triggers the execution of a GenAI-powered\nassistant to enter an infinite loop that wastes money and computational\nresources on redundant API calls to a GenAI engine, preventing the application\nfrom providing service to a user. Next, we introduce a more sophisticated\nimplementation of PromptWare that we name Advanced PromptWare Threat (APwT)\nthat targets GenAI-powered applications whose logic is unknown to attackers. We\nshow that attackers could create user input that exploits the GenAI engine's\nadvanced AI capabilities to launch a kill chain in inference time consisting of\nsix steps intended to escalate privileges, analyze the application's context,\nidentify valuable assets, reason possible malicious activities, decide on one\nof them, and execute it. We demonstrate the application of APwT against a\nGenAI-powered e-commerce chatbot and show that it can trigger the modification\nof SQL tables, potentially leading to unauthorized discounts on the items sold\nto the user.",
      "tldr_zh": "本文警告称，jailbroken GenAI 模型可能对 GenAI-powered 应用造成重大危害，并引入 PromptWare 作为一种新型攻击，利用用户输入强制模型从服务转向恶意行为。论文首先展示了一个简单 PromptWare 实现，针对 Plan & Execute 架构（如 ReAct），通过已知应用逻辑触发 DoS attack，导致无限循环浪费计算资源和 API 调用。接着，提出更先进的 Advanced PromptWare Threat (APwT)，针对未知逻辑的应用，利用六步 kill chain（包括权限升级、上下文分析和恶意执行）来识别并攻击宝贵资产。实验证明，APwT 能在 GenAI-powered 电商聊天机器人上修改 SQL 表，可能导致 unauthorized discounts，突显了此类应用的严重安全漏洞。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Website, see https://sites.google.com/view/promptware",
      "pdf_url": "http://arxiv.org/pdf/2408.05061v1",
      "published_date": "2024-08-09 13:32:50 UTC",
      "updated_date": "2024-08-09 13:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:10:16.492760"
    },
    {
      "arxiv_id": "2408.05060v1",
      "title": "GLEAMS: Bridging the Gap Between Local and Global Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgio Visani",
        "Vincenzo Stanzione",
        "Damien Garreau"
      ],
      "abstract": "The explainability of machine learning algorithms is crucial, and numerous\nmethods have emerged recently. Local, post-hoc methods assign an attribution\nscore to each feature, indicating its importance for the prediction. However,\nthese methods require recalculating explanations for each example. On the other\nside, while there exist global approaches they often produce explanations that\nare either overly simplistic and unreliable or excessively complex. To bridge\nthis gap, we propose GLEAMS, a novel method that partitions the input space and\nlearns an interpretable model within each sub-region, thereby providing both\nfaithful local and global surrogates. We demonstrate GLEAMS' effectiveness on\nboth synthetic and real-world data, highlighting its desirable properties and\nhuman-understandable insights.",
      "tldr_zh": "机器学习算法的可解释性至关重要，但现有的局部解释方法（如 attribution scores）需要为每个示例重新计算，而全局方法往往过于简单或复杂。论文提出 GLEAMS，一种新颖的方法，通过分区输入空间并在每个子区域内学习可解释模型，从而提供忠实的局部和全局解释代理。该方法在合成和真实世界数据上进行了验证，展示了其有效性，并提供了人类易懂的洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05060v1",
      "published_date": "2024-08-09 13:30:37 UTC",
      "updated_date": "2024-08-09 13:30:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:10:25.446068"
    },
    {
      "arxiv_id": "2408.05057v1",
      "title": "SELD-Mamba: Selective State-Space Model for Sound Event Localization and Detection with Source Distance Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Da Mu",
        "Zhicheng Zhang",
        "Haobo Yue",
        "Zehao Wang",
        "Jin Tang",
        "Jianqin Yin"
      ],
      "abstract": "In the Sound Event Localization and Detection (SELD) task, Transformer-based\nmodels have demonstrated impressive capabilities. However, the quadratic\ncomplexity of the Transformer's self-attention mechanism results in\ncomputational inefficiencies. In this paper, we propose a network architecture\nfor SELD called SELD-Mamba, which utilizes Mamba, a selective state-space\nmodel. We adopt the Event-Independent Network V2 (EINV2) as the foundational\nframework and replace its Conformer blocks with bidirectional Mamba blocks to\ncapture a broader range of contextual information while maintaining\ncomputational efficiency. Additionally, we implement a two-stage training\nmethod, with the first stage focusing on Sound Event Detection (SED) and\nDirection of Arrival (DoA) estimation losses, and the second stage\nreintroducing the Source Distance Estimation (SDE) loss. Our experimental\nresults on the 2024 DCASE Challenge Task3 dataset demonstrate the effectiveness\nof the selective state-space model in SELD and highlight the benefits of the\ntwo-stage training approach in enhancing SELD performance.",
      "tldr_zh": "本文提出 SELD-Mamba，一种基于 selective state-space model 的网络架构，用于 Sound Event Localization and Detection (SELD) 任务，以解决 Transformer 模型自注意力机制的二次方复杂度问题。SELD-Mamba 以 Event-Independent Network V2 (EINV2) 为基础，将 Conformer blocks 替换为 bidirectional Mamba blocks，以捕获更广泛的上下文信息并提高计算效率，同时采用两阶段训练方法：第一阶段优化 Sound Event Detection (SED) 和 Direction of Arrival (DoA) estimation 损失，第二阶段重新引入 Source Distance Estimation (SDE) 损失。在 2024 DCASE Challenge Task3 数据集上的实验结果显示，该方法显著提升了 SELD 性能，验证了 selective state-space model 的优势。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05057v1",
      "published_date": "2024-08-09 13:26:08 UTC",
      "updated_date": "2024-08-09 13:26:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:10:39.927590"
    },
    {
      "arxiv_id": "2408.05051v1",
      "title": "A GNN Model with Adaptive Weights for Session-Based Recommendation Systems",
      "title_zh": "带有自适应权重的 GNN 模型，用于基于会话的推荐系统",
      "authors": [
        "Begüm Özbay",
        "Resul Tugay",
        "Şule Gündüz Öğüdücü"
      ],
      "abstract": "Session-based recommendation systems aim to model users' interests based on\ntheir sequential interactions to predict the next item in an ongoing session.\nIn this work, we present a novel approach that can be used in session-based\nrecommendations (SBRs). Our goal is to enhance the prediction accuracy of an\nexisting session-based recommendation model, the SR-GNN model, by introducing\nan adaptive weighting mechanism applied to the graph neural network (GNN)\nvectors. This mechanism is designed to incorporate various types of side\ninformation obtained through different methods during the study. Items are\nassigned varying degrees of importance within each session as a result of the\nweighting mechanism. We hypothesize that this adaptive weighting strategy will\ncontribute to more accurate predictions and thus improve the overall\nperformance of SBRs in different scenarios. The adaptive weighting strategy can\nbe utilized to address the cold start problem in SBRs by dynamically adjusting\nthe importance of items in each session, thus providing better recommendations\nin cold start situations, such as for new users or newly added items. Our\nexperimental evaluations on the Dressipi dataset demonstrate the effectiveness\nof the proposed approach compared to traditional models in enhancing the user\nexperience and highlighting its potential to optimize the recommendation\nresults in real-world applications.",
      "tldr_zh": "本研究提出了一种基于 GNN 的新模型，用于提升会话-based推荐系统（session-based recommendation systems）的预测准确性。该模型在原有 SR-GNN 基础上引入 adaptive weighting mechanism，通过整合各种侧边信息（side information）动态调整每个会话中物品的重要性，从而更好地处理 cold start problem。实验结果显示，在 Dressipi 数据集上，该方法比传统模型提高了推荐性能，并优化了用户体验，为实际应用提供了潜在改进。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "7 pages, 7 tables, 2 figures, and 3 equations",
      "pdf_url": "http://arxiv.org/pdf/2408.05051v1",
      "published_date": "2024-08-09 13:13:43 UTC",
      "updated_date": "2024-08-09 13:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:10:51.104997"
    },
    {
      "arxiv_id": "2408.05025v2",
      "title": "Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks",
      "title_zh": "Rag and Roll：基于LLM应用程序框架中间接提示操纵的端到端评估",
      "authors": [
        "Gianluca De Stefano",
        "Lea Schönherr",
        "Giancarlo Pellegrino"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) is a technique commonly used to equip\nmodels with out of distribution knowledge. This process involves collecting,\nindexing, retrieving, and providing information to an LLM for generating\nresponses. Despite its growing popularity due to its flexibility and low cost,\nthe security implications of RAG have not been extensively studied. The data\nfor such systems are often collected from public sources, providing an attacker\na gateway for indirect prompt injections to manipulate the responses of the\nmodel. In this paper, we investigate the security of RAG systems against\nend-to-end indirect prompt manipulations. First, we review existing RAG\nframework pipelines, deriving a prototypical architecture and identifying\ncritical parameters. We then examine prior works searching for techniques that\nattackers can use to perform indirect prompt manipulations. Finally, we\nimplemented Rag 'n Roll, a framework to determine the effectiveness of attacks\nagainst end-to-end RAG applications. Our results show that existing attacks are\nmostly optimized to boost the ranking of malicious documents during the\nretrieval phase. However, a higher rank does not immediately translate into a\nreliable attack. Most attacks, against various configurations, settle around a\n40% success rate, which could rise to 60% when considering ambiguous answers as\nsuccessful attacks (those that include the expected benign one as well).\nAdditionally, when using unoptimized documents, attackers deploying two of them\n(or more) for a target query can achieve similar results as those using\noptimized ones. Finally, exploration of the configuration space of a RAG showed\nlimited impact in thwarting the attacks, where the most successful combination\nseverely undermines functionality.",
      "tldr_zh": "这篇论文评估了基于 LLM 的 RAG 系统对间接提示注入攻击的安全性，重点审查了 RAG 的典型架构和关键参数。研究者开发了 Rag 'n Roll 框架，对端到端攻击进行测试，发现现有攻击主要针对检索阶段优化恶意文档，但成功率仅约 40%，模糊答案时可达 60%。此外，使用多个未优化的文档也能实现类似效果，而调整 RAG 配置对缓解攻击的影响有限。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05025v2",
      "published_date": "2024-08-09 12:26:05 UTC",
      "updated_date": "2024-08-12 13:57:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:11:05.604701"
    },
    {
      "arxiv_id": "2408.05006v3",
      "title": "COAST: Enhancing the Code Debugging Ability of LLMs through Communicative Agent Based Data Synthesis",
      "title_zh": "COAST：通过基于通信代理的数据合成增强LLMs的代码调试",
      "authors": [
        "Weiqing Yang",
        "Hanbin Wang",
        "Zhenghao Liu",
        "Xinze Li",
        "Yukun Yan",
        "Shuo Wang",
        "Yu Gu",
        "Minghe Yu",
        "Zhiyuan Liu",
        "Ge Yu"
      ],
      "abstract": "Code debugging is a vital stage of software development, essential for\nensuring the reliability and performance of Large Language Models (LLMs) in the\ncode generation task. Human debugging typically follows a multi-stage process,\nwhich includes Bug Localization, Bug Identification, Code Repair, and Code\nRecognition. However, existing code debugging benchmarks predominantly focus on\nthe Code Repair stage, which offers only a limited perspective on evaluating\nthe debugging capabilities of LLMs. In this paper, we introduce DEBUGEVAL, a\ncomprehensive benchmark for evaluating the debugging abilities of LLMs by\nemulating the multi-stage human debugging process. Through evaluating on\nDEBUGEVAL, we observe that 7B-scale models consistently underperform compared\nto their larger counterparts, highlighting their limitations in comprehending\ncode semantics. In this case, we propose the COmmunicative Agent-based data\nSynThesis (COAST) framework, which employs a multi-agent system to generate\nhigh-quality training data for supervised fine-tuning (SFT). Experimental\nresults demonstrate that COAST-generated data outperform human-curated and\nGPT-4-generated data, enabling 7B-scale LLMs to achieve debugging performance\ncomparable to GPT-3.5. All data and codes are available at\nhttps://github.com/NEUIR/COAST.",
      "tldr_zh": "该论文引入了 DEBUGEVAL 基准，用于全面评估 LLMs 的代码调试能力，通过模拟人类的多阶段调试过程（包括 Bug Localization、Bug Identification、Code Repair 和 Code Recognition）。为了解决 7B-scale 模型在代码语义理解上的局限性，作者提出 COAST 框架，该框架采用多智能体系统生成高质量训练数据，用于监督微调 (SFT)。实验结果表明，COAST 生成的数据优于人类和 GPT-4 生成的数据，使 7B-scale LLMs 的调试性能达到 GPT-3.5 的水平。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05006v3",
      "published_date": "2024-08-09 11:35:44 UTC",
      "updated_date": "2025-02-12 04:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:11:17.160046"
    },
    {
      "arxiv_id": "2408.11063v1",
      "title": "Tabular Transfer Learning via Prompting LLMs",
      "title_zh": "通过提示 LLMs 进行表格迁移学习",
      "authors": [
        "Jaehyun Nam",
        "Woomin Song",
        "Seong Hyeon Park",
        "Jihoon Tack",
        "Sukmin Yun",
        "Jaehyung Kim",
        "Kyu Hwan Oh",
        "Jinwoo Shin"
      ],
      "abstract": "Learning with a limited number of labeled data is a central problem in\nreal-world applications of machine learning, as it is often expensive to obtain\nannotations. To deal with the scarcity of labeled data, transfer learning is a\nconventional approach; it suggests to learn a transferable knowledge by\ntraining a neural network from multiple other sources. In this paper, we\ninvestigate transfer learning of tabular tasks, which has been less studied and\nsuccessful in the literature, compared to other domains, e.g., vision and\nlanguage. This is because tables are inherently heterogeneous, i.e., they\ncontain different columns and feature spaces, making transfer learning\ndifficult. On the other hand, recent advances in natural language processing\nsuggest that the label scarcity issue can be mitigated by utilizing in-context\nlearning capability of large language models (LLMs). Inspired by this and the\nfact that LLMs can also process tables within a unified language space, we ask\nwhether LLMs can be effective for tabular transfer learning, in particular,\nunder the scenarios where the source and target datasets are of different\nformat. As a positive answer, we propose a novel tabular transfer learning\nframework, coined Prompt to Transfer (P2T), that utilizes unlabeled (or\nheterogeneous) source data with LLMs. Specifically, P2T identifies a column\nfeature in a source dataset that is strongly correlated with a target task\nfeature to create examples relevant to the target task, thus creating\npseudo-demonstrations for prompts. Experimental results demonstrate that P2T\noutperforms previous methods on various tabular learning benchmarks, showing\ngood promise for the important, yet underexplored tabular transfer learning\nproblem. Code is available at https://github.com/jaehyun513/P2T.",
      "tldr_zh": "本研究探讨了在标签数据稀缺的情况下，通过转移学习（transfer learning）提升表格任务性能的问题，尤其针对表格数据的异构特性。论文提出了一种新框架Prompt to Transfer (P2T)，利用大语言模型（LLMs）的in-context learning能力，从无标签或异构源数据中识别与目标任务相关的列特征，创建伪演示作为提示示例。实验结果显示，P2T在各种表格学习基准上优于现有方法，证明了其在不同格式数据集间的有效性，为表格转移学习提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11063v1",
      "published_date": "2024-08-09 11:30:52 UTC",
      "updated_date": "2024-08-09 11:30:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:11:27.541632"
    },
    {
      "arxiv_id": "2408.04998v1",
      "title": "ProFuser: Progressive Fusion of Large Language Models",
      "title_zh": "ProFuser：大型语言模型的渐进融合",
      "authors": [
        "Tianyuan Shi",
        "Fanqi Wan",
        "Canbin Huang",
        "Xiaojun Quan",
        "Chenliang Li",
        "Ming Yan",
        "Ji Zhang"
      ],
      "abstract": "While fusing the capacities and advantages of various large language models\n(LLMs) offers a pathway to construct more powerful and versatile models, a\nfundamental challenge is to properly select advantageous model during the\ntraining. Existing fusion methods primarily focus on the training mode that\nuses cross entropy on ground truth in a teacher-forcing setup to measure a\nmodel's advantage, which may provide limited insight towards model advantage.\nIn this paper, we introduce a novel approach that enhances the fusion process\nby incorporating both the training and inference modes. Our method evaluates\nmodel advantage not only through cross entropy during training but also by\nconsidering inference outputs, providing a more comprehensive assessment. To\ncombine the two modes effectively, we introduce ProFuser to progressively\ntransition from inference mode to training mode. To validate ProFuser's\neffectiveness, we fused three models, including vicuna-7b-v1.5,\nLlama-2-7b-chat, and mpt-7b-8k-chat, and demonstrated the improved performance\nin knowledge, reasoning, and safety compared to baseline methods.",
      "tldr_zh": "本论文提出 ProFuser，一种渐进式融合大型语言模型(LLMs)的框架，以解决现有方法仅依赖训练模式（如交叉熵评估）而忽略推理输出的局限性。\nProFuser 通过结合训练和推理模式，逐步从推理模式过渡到训练模式，实现对模型优势的更全面评估。\n实验结果显示，融合 vicuna-7b-v1.5、Llama-2-7b-chat 和 mpt-7b-8k-chat 后的模型，在知识、推理和安全性方面均优于基线方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04998v1",
      "published_date": "2024-08-09 11:18:29 UTC",
      "updated_date": "2024-08-09 11:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:11:40.683101"
    },
    {
      "arxiv_id": "2408.04996v1",
      "title": "On the use of neurosymbolic AI for defending against cyber attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Gudmund Grov",
        "Jonas Halvorsen",
        "Magnus Wiik Eckhoff",
        "Bjørn Jervell Hansen",
        "Martin Eian",
        "Vasileios Mavroeidis"
      ],
      "abstract": "It is generally accepted that all cyber attacks cannot be prevented, creating\na need for the ability to detect and respond to cyber attacks. Both\nconnectionist and symbolic AI are currently being used to support such\ndetection and response. In this paper, we make the case for combining them\nusing neurosymbolic AI. We identify a set of challenges when using AI today and\npropose a set of neurosymbolic use cases we believe are both interesting\nresearch directions for the neurosymbolic AI community and can have an impact\non the cyber security field. We demonstrate feasibility through two\nproof-of-concept experiments.",
      "tldr_zh": "该论文讨论了使用 neurosymbolic AI 结合 connectionist AI 和 symbolic AI 来检测和响应网络攻击的必要性，因为所有网络攻击无法完全预防。作者识别了当前 AI 在网络安全领域面临的挑战，并提出了几个 neurosymbolic AI 用例，作为有前景的研究方向，以提升防御效果。通过两个 proof-of-concept experiments，论文证明了这种方法的 feasibility，并强调其对网络安全领域的潜在影响。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to 18th International Conference on Neural-Symbolic Learning\n  and Reasoning",
      "pdf_url": "http://arxiv.org/pdf/2408.04996v1",
      "published_date": "2024-08-09 11:14:06 UTC",
      "updated_date": "2024-08-09 11:14:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:11:51.258986"
    },
    {
      "arxiv_id": "2408.04957v4",
      "title": "LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhang Jin",
        "Jian Li",
        "Jiangning Zhang",
        "Jianlong Hu",
        "Zhenye Gan",
        "Xin Tan",
        "Yong Liu",
        "Yabiao Wang",
        "Chengjie Wang",
        "Lizhuang Ma"
      ],
      "abstract": "Visual Spatial Description (VSD) aims to generate texts that describe the\nspatial relationships between objects within images. Traditional visual spatial\nrelationship classification (VSRC) methods typically output the spatial\nrelationship between two objects in an image, often neglecting world knowledge\nand lacking general language capabilities. In this paper, we propose a Large\nLanguage-and-Vision Assistant for Visual Spatial Description, named LLaVA-VSD,\nwhich is designed for the classification, description, and open-ended\ndescription of visual spatial relationships. Specifically, the model first\nconstructs a VSD instruction-following dataset using given figure-caption pairs\nfor the three tasks. It then employs LoRA to fine-tune a Large Language and\nVision Assistant for VSD, which has 13 billion parameters and supports\nhigh-resolution images. Finally, a large language model (Qwen-2) is used to\nrefine the generated sentences, enhancing their diversity and accuracy.\nLLaVA-VSD demonstrates excellent multimodal conversational capabilities and can\nfollow open-ended instructions to assist with inquiries about object\nrelationships in images.",
      "tldr_zh": "本文提出LLaVA-VSD，一种Large Language-and-Vision Assistant，用于Visual Spatial Description (VSD)，旨在生成图像中物体之间空间关系的文本，解决传统Visual Spatial Relationship Classification (VSRC) 方法忽略世界知识和语言能力的局限。模型通过构建VSD指令遵循数据集、采用LoRA微调一个13亿参数的视觉语言模型来支持高分辨率图像处理，并使用Qwen-2大型语言模型优化生成的句子以提升多样性和准确性。LLaVA-VSD展示了出色的多模态对话能力，能够处理分类、描述和开放式查询，从而更好地辅助图像物体关系的分析。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "We have discovered a significant error in the paper that affects the\n  main conclusions. To ensure the accuracy of our research, we have decided to\n  withdraw this paper and will resubmit it after making the necessary\n  corrections",
      "pdf_url": "http://arxiv.org/pdf/2408.04957v4",
      "published_date": "2024-08-09 09:22:40 UTC",
      "updated_date": "2024-10-30 02:38:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:12:04.524767"
    },
    {
      "arxiv_id": "2408.05258v1",
      "title": "scASDC: Attention Enhanced Structural Deep Clustering for Single-cell RNA-seq Data",
      "title_zh": "翻译失败",
      "authors": [
        "Wenwen Min",
        "Zhen Wang",
        "Fangfang Zhu",
        "Taosheng Xu",
        "Shunfang Wang"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is pivotal for\nunderstanding cellular heterogeneity. However, the high sparsity and complex\nnoise patterns inherent in scRNA-seq data present significant challenges for\ntraditional clustering methods. To address these issues, we propose a deep\nclustering method, Attention-Enhanced Structural Deep Embedding Graph\nClustering (scASDC), which integrates multiple advanced modules to improve\nclustering accuracy and robustness.Our approach employs a multi-layer graph\nconvolutional network (GCN) to capture high-order structural relationships\nbetween cells, termed as the graph autoencoder module. To mitigate the\noversmoothing issue in GCNs, we introduce a ZINB-based autoencoder module that\nextracts content information from the data and learns latent representations of\ngene expression. These modules are further integrated through an attention\nfusion mechanism, ensuring effective combination of gene expression and\nstructural information at each layer of the GCN. Additionally, a\nself-supervised learning module is incorporated to enhance the robustness of\nthe learned embeddings. Extensive experiments demonstrate that scASDC\noutperforms existing state-of-the-art methods, providing a robust and effective\nsolution for single-cell clustering tasks. Our method paves the way for more\naccurate and meaningful analysis of single-cell RNA sequencing data,\ncontributing to better understanding of cellular heterogeneity and biological\nprocesses. All code and public datasets used in this paper are available at\n\\url{https://github.com/wenwenmin/scASDC} and\n\\url{https://zenodo.org/records/12814320}.",
      "tldr_zh": "本文提出scASDC，一种针对单细胞RNA测序(scRNA-seq)数据的注意力增强结构深度聚类方法，以解决数据的高稀疏性和复杂噪声带来的挑战。该方法整合多层图卷积网络(GCN)捕捉细胞间的高阶结构关系、ZINB-based autoencoder提取基因表达的潜在表示，以及attention fusion机制和self-supervised learning模块，以提升聚类准确性和嵌入鲁棒性。实验结果显示，scASDC在多项测试中优于现有最先进方法，提供更可靠的单细胞聚类解决方案，从而有助于深入理解细胞异质性和生物过程。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05258v1",
      "published_date": "2024-08-09 09:10:36 UTC",
      "updated_date": "2024-08-09 09:10:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:12:16.312739"
    },
    {
      "arxiv_id": "2409.18132v2",
      "title": "Decomposition of one-layer neural networks via the infinite sum of reproducing kernel Banach spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Seungcheol Shin",
        "Myungjoo Kang"
      ],
      "abstract": "In this paper, we define the sum of RKBSs using the characterization theorem\nof RKBSs and show that the sum of RKBSs is compatible with the direct sum of\nfeature spaces. Moreover, we decompose the integral RKBS into the sum of\n$p$-norm RKBSs. Finally, we provide applications for the structural\nunderstanding of the integral RKBS class.",
      "tldr_zh": "这篇论文通过使用 Reproducing Kernel Banach Spaces (RKBSs) 的特征定理，定义了 RKBSs 的和，并证明了这种和与特征空间的直接和兼容。作者进一步将积分 RKBS 分解为 p-norm RKBSs 的和，以揭示其内部结构。最后，这些分解方法为理解和应用积分 RKBS 类提供了重要基础。",
      "categories": [
        "math.FA",
        "cs.AI"
      ],
      "primary_category": "math.FA",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.18132v2",
      "published_date": "2024-08-09 09:10:29 UTC",
      "updated_date": "2025-04-01 10:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:12:26.848148"
    },
    {
      "arxiv_id": "2408.04949v1",
      "title": "CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning",
      "title_zh": "翻译失败",
      "authors": [
        "Gianluca Carloni",
        "Sotirios A Tsaftaris",
        "Sara Colantonio"
      ],
      "abstract": "Due to domain shift, deep learning image classifiers perform poorly when\napplied to a domain different from the training one. For instance, a classifier\ntrained on chest X-ray (CXR) images from one hospital may not generalize to\nimages from another hospital due to variations in scanner settings or patient\ncharacteristics. In this paper, we introduce our CROCODILE framework, showing\nhow tools from causality can foster a model's robustness to domain shift via\nfeature disentanglement, contrastive learning losses, and the injection of\nprior knowledge. This way, the model relies less on spurious correlations,\nlearns the mechanism bringing from images to prediction better, and outperforms\nbaselines on out-of-distribution (OOD) data. We apply our method to multi-label\nlung disease classification from CXRs, utilizing over 750000 images from four\ndatasets. Our bias-mitigation method improves domain generalization and\nfairness, broadening the applicability and reliability of deep learning models\nfor a safer medical image analysis. Find our code at:\nhttps://github.com/gianlucarloni/crocodile.",
      "tldr_zh": "该论文提出CROCODILE框架，利用因果性工具提升深度学习图像分类器的鲁棒性，针对domain shift问题（如医院间胸部X光图像差异）。框架通过feature disentanglement、contrastive learning losses和注入prior knowledge，减少模型对spurious correlations的依赖，并更好地学习图像到预测的机制。实验在多标签肺部疾病分类任务上，使用超过750000张CXR图像，证明CROCODILE在OOD数据上优于基线，提升了domain generalization和fairness，从而使医疗图像分析更可靠。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "I.2; I.4; I.5; J.3; J.6"
      ],
      "primary_category": "eess.IV",
      "comment": "MICCAI 2024 UNSURE Workshop, Accepted for presentation, Submitted\n  Manuscript Version, 10 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.04949v1",
      "published_date": "2024-08-09 09:08:06 UTC",
      "updated_date": "2024-08-09 09:08:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:12:39.782034"
    },
    {
      "arxiv_id": "2408.07089v1",
      "title": "InfinityMATH: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning",
      "title_zh": "InfinityMATH：一个可扩展的指令调优数据集，用于程序化数学",
      "authors": [
        "Bo-Wen Zhang",
        "Yan Yan",
        "Lin Li",
        "Guang Liu"
      ],
      "abstract": "Recent advancements in Chain-of-Thoughts (CoT) and Program-of-Thoughts (PoT)\nmethods have greatly enhanced language models' mathematical reasoning\ncapabilities, facilitating their integration into instruction tuning datasets\nwith LLMs. However, existing methods for large-scale dataset creation require\nsubstantial seed data and high computational costs for data synthesis, posing\nsignificant challenges for scalability. We introduce InfinityMATH, a scalable\ninstruction tuning dataset for programmatic mathematical reasoning. The\nconstruction pipeline emphasizes decoupling numbers from mathematical problems\nto synthesize number-independent programs, enabling efficient and flexible\nscaling while minimizing dependency on specific numerical values. Fine-tuning\nexperiments with open-source language and code models, such as Llama2 and\nCodeLlama, demonstrate the practical benefits of InfinityMATH. These fine-tuned\nmodels, showed significant relative improvements on both in-domain and\nout-of-domain benchmarks, ranging from 184.7% to 514.3% on average.\nAdditionally, these models exhibited high robustness on the GSM8K+ and MATH+\nbenchmarks, which are enhanced version of test sets with simply the number\nvariations. InfinityMATH ensures that models are more versatile and effective\nacross a broader range of mathematical problems. The data is available at\nhttps://huggingface.co/datasets/flagopen/InfinityMATH.",
      "tldr_zh": "本研究引入了 InfinityMATH，这是一个可扩展的指令调整数据集，专注于程序化数学推理（Programmatic Mathematical Reasoning），旨在解决现有 Chain-of-Thoughts (CoT) 和 Program-of-Thoughts (PoT) 方法在数据合成中对种子数据和高计算成本的依赖问题。该数据集的构建管道通过将数字从数学问题中分离，合成不依赖特定数值的程序，实现高效灵活的扩展。在对 Llama2 和 CodeLlama 等开源模型的微调实验中，InfinityMATH 使模型在内部和外部基准测试上平均提升 184.7% 到 514.3%，并在 GSM8K+ 和 MATH+ 基准上表现出高鲁棒性。该数据集增强了模型在更广泛数学问题上的通用性和有效性，可从 https://huggingface.co/datasets/flagopen/InfinityMATH 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07089v1",
      "published_date": "2024-08-09 08:18:20 UTC",
      "updated_date": "2024-08-09 08:18:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:12:54.597175"
    },
    {
      "arxiv_id": "2408.04922v2",
      "title": "UAV-Enhanced Combination to Application: Comprehensive Analysis and Benchmarking of a Human Detection Dataset for Disaster Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Ragib Amin Nihal",
        "Benjamin Yen",
        "Katsutoshi Itoyama",
        "Kazuhiro Nakadai"
      ],
      "abstract": "Unmanned aerial vehicles (UAVs) have revolutionized search and rescue (SAR)\noperations, but the lack of specialized human detection datasets for training\nmachine learning models poses a significant challenge.To address this gap, this\npaper introduces the Combination to Application (C2A) dataset, synthesized by\noverlaying human poses onto UAV-captured disaster scenes. Through extensive\nexperimentation with state-of-the-art detection models, we demonstrate that\nmodels fine-tuned on the C2A dataset exhibit substantial performance\nimprovements compared to those pre-trained on generic aerial datasets.\nFurthermore, we highlight the importance of combining the C2A dataset with\ngeneral human datasets to achieve optimal performance and generalization across\nvarious scenarios. This points out the crucial need for a tailored dataset to\nenhance the effectiveness of SAR operations. Our contributions also include\ndeveloping dataset creation pipeline and integrating diverse human poses and\ndisaster scenes information to assess the severity of disaster scenarios. Our\nfindings advocate for future developments, to ensure that SAR operations\nbenefit from the most realistic and effective AI-assisted interventions\npossible.",
      "tldr_zh": "这篇论文针对无人机（UAVs）在搜索和救援（SAR）操作中人类检测的挑战，引入了 C2A 数据集，该数据集通过将人类姿势叠加到 UAV 捕获的灾害场景上进行合成。\n实验结果显示，使用 C2A 数据集微调的先进检测模型比在通用航空数据集上预训练的模型有显著性能提升。\n作者强调，将 C2A 数据集与通用人类数据集结合可实现最佳性能和泛化效果，并贡献了数据集创建管道以整合多样人类姿势和灾害场景信息。\n这项工作突出了定制数据集对提升 SAR 操作中 AI 辅助干预的重要性，并呼吁未来进一步开发。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This Paper is accepted for 27th International Conference on Pattern\n  Recognition (ICPR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.04922v2",
      "published_date": "2024-08-09 08:07:19 UTC",
      "updated_date": "2024-08-23 18:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:13:08.440912"
    },
    {
      "arxiv_id": "2408.04917v2",
      "title": "Avoid Wasted Annotation Costs in Open-set Active Learning with Pre-trained Vision-Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyuk Heo",
        "Pilsung Kang"
      ],
      "abstract": "Active learning (AL) aims to enhance model performance by selectively\ncollecting highly informative data, thereby minimizing annotation costs.\nHowever, in practical scenarios, unlabeled data may contain out-of-distribution\n(OOD) samples, which are not used for training, leading to wasted annotation\ncosts if data is incorrectly selected. Therefore, to make active learning\nfeasible in real-world applications, it is crucial to consider not only the\ninformativeness of unlabeled samples but also their purity to determine whether\nthey belong to the in-distribution (ID). Recent studies have applied AL under\nthese assumptions, but challenges remain due to the trade-off between\ninformativeness and purity, as well as the heavy dependence on OOD samples.\nThese issues lead to the collection of OOD samples, resulting in a significant\nwaste of annotation costs. To address these challenges, we propose a novel\nquery strategy, VLPure-AL, which minimizes cost losses while reducing\ndependence on OOD samples. VLPure-AL sequentially evaluates the purity and\ninformativeness of data. First, it utilizes a pre-trained vision-language model\nto detect and exclude OOD data with high accuracy by leveraging linguistic and\nvisual information of ID data. Second, it selects highly informative data from\nthe remaining ID data, and then the selected samples are annotated by human\nexperts. Experimental results on datasets with various open-set conditions\ndemonstrate that VLPure-AL achieves the lowest cost loss and highest\nperformance across all scenarios. Code is available at\nhttps://github.com/DSBA-Lab/OpenAL.",
      "tldr_zh": "本研究针对开放集主动学习（Active Learning, AL）中的问题，提出了一种新策略 VLPure-AL，以避免标注 Out-of-Distribution (OOD) 样本导致的成本浪费。VLPure-AL 首先利用预训练的 Vision-Language Model (VLM) 通过视觉和语言信息检测并排除 OOD 数据，确保样本的纯度（In-Distribution, ID）；随后，从剩余的 ID 数据中选择信息丰富的样本进行人工标注，从而平衡信息性和纯度。实验结果显示，在各种开放集条件下，VLPure-AL 实现了最低的成本损失和最高模型性能，显著减少了对 OOD 样本的依赖。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04917v2",
      "published_date": "2024-08-09 07:54:57 UTC",
      "updated_date": "2025-04-13 07:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:13:18.956245"
    },
    {
      "arxiv_id": "2408.15252v1",
      "title": "Generative AI on SpectrumNet: An Open Benchmark of Multiband 3D Radio Maps",
      "title_zh": "SpectrumNet 上的生成式 AI：多频段 3D 无线电地图的开放基准",
      "authors": [
        "Shuhang Zhang",
        "Shuai Jiang",
        "Wanjie Lin",
        "Zheng Fang",
        "Kangjun Liu",
        "Hongliang Zhang",
        "Ke Chen"
      ],
      "abstract": "Radio map is an efficient demonstration for visually displaying the wireless\nsignal coverage within a certain region. It has been considered to be\nincreasingly helpful for the future sixth generation (6G) of wireless networks,\nas wireless nodes are becoming more crowded and complicated. However, the\nconstruction of high resolution radio map is very challenging due to the sparse\nsampling in practical systems. Generative artificial intelligence (AI), which\nis capable to create synthetic data to fill in gaps in real-world measurements,\nis an effective technique to construct high precision radio maps. Currently,\ngenerative models for radio map construction are trained with two-dimension\n(2D) single band radio maps in urban scenario, which has poor generalization in\ndiverse terrain scenarios, spectrum bands, and heights. To tackle this problem,\nwe provide a multiband three-dimension (3D) radio map dataset with\nconsideration of terrain and climate information, named SpectrumNet. It is the\nlargest radio map dataset in terms of dimensions and scale, which contains the\nradio map of 3 spacial dimensions, 5 frequency bands, 11 terrain scenarios, and\n3 climate scenarios. We introduce the parameters and settings for the\nSpectrumNet dataset generation, and evaluate three baseline methods for radio\nmap construction based on the SpectrumNet dataset. Experiments show the\nnecessity of the SpectrumNet dataset for training models with strong\ngeneralization in spacial, frequency, and scenario domains. Future works on the\nSpectrumNet dataset are also discussed, including the dataset expansion and\ncalibration, as well as the extended studies on generative models for radio map\nconstruction based on the SpectrumNet dataset.",
      "tldr_zh": "该论文提出SpectrumNet，这是一个开放基准数据集，包含多频带3D无线电地图，并考虑地形和气候信息，用于解决生成式AI在构建高分辨率无线电地图时的泛化性问题。SpectrumNet是目前最大的数据集，包括3个空间维度、5个频带、11个地形场景和3个气候场景，旨在填补现有2D单频带模型的局限性。作者介绍了数据集生成参数、评估了三个基线方法，实验结果显示SpectrumNet显著提升了模型在空间、频率和场景域的泛化能力。未来工作将聚焦于数据集扩展、校准以及基于SpectrumNet的生成模型研究。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "30 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.15252v1",
      "published_date": "2024-08-09 07:54:11 UTC",
      "updated_date": "2024-08-09 07:54:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:13:32.729285"
    },
    {
      "arxiv_id": "2408.04913v1",
      "title": "Knowledge Base Embeddings: Semantics and Theoretical Properties",
      "title_zh": "知识库嵌入：语义和理论属性",
      "authors": [
        "Camille Bourgaux",
        "Ricardo Guimarães",
        "Raoul Koudijs",
        "Victor Lacerda",
        "Ana Ozaki"
      ],
      "abstract": "Research on knowledge graph embeddings has recently evolved into knowledge\nbase embeddings, where the goal is not only to map facts into vector spaces but\nalso constrain the models so that they take into account the relevant\nconceptual knowledge available. This paper examines recent methods that have\nbeen proposed to embed knowledge bases in description logic into vector spaces\nthrough the lens of their geometric-based semantics. We identify several\nrelevant theoretical properties, which we draw from the literature and\nsometimes generalize or unify. We then investigate how concrete embedding\nmethods fit in this theoretical framework.",
      "tldr_zh": "这篇论文探讨了知识库嵌入（Knowledge Base Embeddings）的语义和理论属性，扩展了传统知识图嵌入（Knowledge Graph Embeddings）的方法，以确保模型不仅映射事实到向量空间，还能整合相关概念知识。作者通过几何-based semantics 的视角，审视了将描述逻辑（Description Logic）知识库嵌入向量空间的最新方法，并识别并统一了几个关键理论属性。最终，论文调查了具体嵌入方法如何适应这一理论框架，为知识库嵌入的研究提供了更坚实的理论基础。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "This is an extended version of a paper appearing at the 21st\n  International Conference on Principles of Knowledge Representation and\n  Reasoning (KR 2024). 17 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.04913v1",
      "published_date": "2024-08-09 07:43:28 UTC",
      "updated_date": "2024-08-09 07:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:13:43.314731"
    },
    {
      "arxiv_id": "2408.11062v1",
      "title": "Interactive-T2S: Multi-Turn Interactions for Text-to-SQL with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Guanming Xiong",
        "Junwei Bao",
        "Hongfei Jiang",
        "Yang Song",
        "Wen Zhao"
      ],
      "abstract": "This study explores text-to-SQL parsing by leveraging the powerful reasoning\ncapabilities of large language models (LLMs). Despite recent advancements,\nexisting LLM-based methods have not adequately addressed scalability, leading\nto inefficiencies when processing wide tables. Furthermore, current\ninteraction-based approaches either lack a step-by-step, interpretable SQL\ngeneration process or fail to provide an efficient and universally applicable\ninteraction design. To address these challenges, we introduce Interactive-T2S,\na framework that generates SQL queries through direct interactions with\ndatabases. This framework includes four general tools that facilitate proactive\nand efficient information retrieval by the LLM. Additionally, we have developed\ndetailed exemplars to demonstrate the step-wise reasoning processes within our\nframework. Our experiments on the BIRD-Dev dataset, employing a setting without\noracle knowledge, reveal that our method achieves state-of-the-art results with\nonly two exemplars, underscoring the effectiveness and robustness of our\nframework.",
      "tldr_zh": "这篇论文提出 Interactive-T2S 框架，利用 Large Language Models (LLMs) 通过多轮互动来提升 Text-to-SQL 解析的效率和可解释性，解决现有方法在处理宽表时的伸缩性问题和交互设计不足。框架包括四个通用工具，支持 LLM 与数据库直接互动进行主动信息检索，并通过详细的逐步推理示例指导 SQL 查询生成。在 BIRD-Dev 数据集上的实验中，该方法在无预知知识设置下，仅使用两个示例就实现了最先进的结果，展示了其有效性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11062v1",
      "published_date": "2024-08-09 07:43:21 UTC",
      "updated_date": "2024-08-09 07:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:13:56.183614"
    },
    {
      "arxiv_id": "2408.04910v5",
      "title": "Unleashing Artificial Cognition: Integrating Multiple AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Muntasir Adnan",
        "Buddhi Gamage",
        "Zhiwei Xu",
        "Damith Herath",
        "Carlos C. N. Kuhn"
      ],
      "abstract": "In this study, we present an innovative fusion of language models and query\nanalysis techniques to unlock cognition in artificial intelligence. The\nintroduced open-source AI system seamlessly integrates a Chess engine with a\nlanguage model, enabling it to predict moves and provide strategic\nexplanations. Leveraging a vector database to achieve retrievable answer\ngeneration, our AI system elucidates its decision-making process, bridging the\ngap between raw computation and human-like understanding. Our choice of Chess\nas the demonstration environment underscores the versatility of our approach.\nBeyond Chess, our system holds promise for diverse applications, from medical\ndiagnostics to financial forecasting. Our AI system is available at\nhttps://github.com/TheOpenSI/CoSMIC.git",
      "tldr_zh": "本研究提出了一种创新的 AI 系统，通过融合语言模型和查询分析技术，释放人工智能的认知潜力。该系统将 Chess 引擎与语言模型无缝整合，利用向量数据库实现可检索答案生成，从而预测棋步并提供战略解释，桥接了原始计算与类人理解的差距。以 Chess 为演示环境，系统展示了其通用性，并在医疗诊断和金融预测等多样应用中展现出前景。该开源系统可从 https://github.com/TheOpenSI/CoSMIC.git 获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper is accepted to Australasian Conference on Information\n  Systems 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04910v5",
      "published_date": "2024-08-09 07:36:30 UTC",
      "updated_date": "2024-10-17 22:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:14:06.676917"
    },
    {
      "arxiv_id": "2408.04906v1",
      "title": "Towards a Generative Approach for Emotion Detection and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Ankita Bhaumik",
        "Tomek Strzalkowski"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive performance in\nmathematical and commonsense reasoning tasks using chain-of-thought (CoT)\nprompting techniques. But can they perform emotional reasoning by concatenating\n`Let's think step-by-step' to the input prompt? In this paper we investigate\nthis question along with introducing a novel approach to zero-shot emotion\ndetection and emotional reasoning using LLMs. Existing state of the art\nzero-shot approaches rely on textual entailment models to choose the most\nappropriate emotion label for an input text. We argue that this strongly\nrestricts the model to a fixed set of labels which may not be suitable or\nsufficient for many applications where emotion analysis is required. Instead,\nwe propose framing the problem of emotion analysis as a generative\nquestion-answering (QA) task. Our approach uses a two step methodology of\ngenerating relevant context or background knowledge to answer the emotion\ndetection question step-by-step. Our paper is the first work on using a\ngenerative approach to jointly address the tasks of emotion detection and\nemotional reasoning for texts. We evaluate our approach on two popular emotion\ndetection datasets and also release the fine-grained emotion labels and\nexplanations for further training and fine-tuning of emotional reasoning\nsystems.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在情感推理中的潜力，并提出了一种创新的生成式方法，用于零-shot 情感检测和情感推理。现有方法依赖文本蕴含模型（textual entailment models），限制了情感标签的灵活性；相反，该方法将情感分析框架化为生成式问答（generative QA）任务，通过两步过程生成相关上下文并逐步回答问题。在两个流行数据集上进行评估后，该方法展示了优越性能，并发布了细粒度情感标签和解释，以支持进一步的训练和微调。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04906v1",
      "published_date": "2024-08-09 07:20:15 UTC",
      "updated_date": "2024-08-09 07:20:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:14:19.250915"
    },
    {
      "arxiv_id": "2408.04905v2",
      "title": "GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhibo Zhang",
        "Wuxia Bai",
        "Yuxi Li",
        "Mark Huasong Meng",
        "Kailong Wang",
        "Ling Shi",
        "Li Li",
        "Jun Wang",
        "Haoyu Wang"
      ],
      "abstract": "Large language models (LLMs) have achieved unprecedented success in the field\nof natural language processing. However, the black-box nature of their internal\nmechanisms has brought many concerns about their trustworthiness and\ninterpretability. Recent research has discovered a class of abnormal tokens in\nthe model's vocabulary space and named them \"glitch tokens\". Those tokens, once\nincluded in the input, may induce the model to produce incorrect, irrelevant,\nor even harmful results, drastically undermining the reliability and\npracticality of LLMs.\n  In this work, we aim to enhance the understanding of glitch tokens and\npropose techniques for their detection and mitigation. We first reveal the\ncharacteristic features induced by glitch tokens on LLMs, which are evidenced\nby significant deviations in the distributions of attention patterns and\ndynamic information from intermediate model layers. Based on the insights, we\ndevelop GlitchProber, a tool for efficient glitch token detection and\nmitigation. GlitchProber utilizes small-scale sampling, principal component\nanalysis for accelerated feature extraction, and a simple classifier for\nefficient vocabulary screening. Taking one step further, GlitchProber rectifies\nabnormal model intermediate layer values to mitigate the destructive effects of\nglitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber\ndemonstrates higher efficiency, precision, and recall compared to existing\napproaches, with an average F1 score of 0.86 and an average repair rate of\n50.06%. GlitchProber unveils a novel path to address the challenges posed by\nglitch tokens and inspires future research toward more robust and interpretable\nLLMs.",
      "tldr_zh": "本研究针对大语言模型 (LLMs) 中的 \"glitch tokens\" 问题——这些异常标记可能导致模型输出不正确或有害的结果——提出了一种检测和缓解方法。首先，论文揭示了 glitch tokens 引起的注意力模式和中间层动态信息分布的显著偏差，并基于此开发了 GlitchProber 工具，该工具利用小规模采样、主成分分析 (PCA) 加速特征提取，以及简单分类器进行高效词汇筛选。进一步，GlitchProber 通过修正模型中间层值来缓解 glitch tokens 的影响，在五个主流开源 LLMs 上评估显示出平均 F1 分数 0.86 和修复率 50.06%，显著提升了效率、精确度和召回率。该工作为提升 LLMs 的鲁棒性和可解释性提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04905v2",
      "published_date": "2024-08-09 07:19:53 UTC",
      "updated_date": "2024-09-23 03:46:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:14:31.944920"
    },
    {
      "arxiv_id": "2408.04903v2",
      "title": "Axiomatic Characterisations of Sample-based Explainers",
      "title_zh": "翻译失败",
      "authors": [
        "Leila Amgoud",
        "Martin C. Cooper",
        "Salim Debbaoui"
      ],
      "abstract": "Explaining decisions of black-box classifiers is both important and\ncomputationally challenging. In this paper, we scrutinize explainers that\ngenerate feature-based explanations from samples or datasets. We start by\npresenting a set of desirable properties that explainers would ideally satisfy,\ndelve into their relationships, and highlight incompatibilities of some of\nthem. We identify the entire family of explainers that satisfy two key\nproperties which are compatible with all the others. Its instances provide\nsufficient reasons, called weak abductive explanations.We then unravel its\nvarious subfamilies that satisfy subsets of compatible properties. Indeed, we\nfully characterize all the explainers that satisfy any subset of compatible\nproperties. In particular, we introduce the first (broad family of) explainers\nthat guarantee the existence of explanations and their global consistency.We\ndiscuss some of its instances including the irrefutable explainer and the\nsurrogate explainer whose explanations can be found in polynomial time.",
      "tldr_zh": "这篇论文对基于样本的解释器(Sample-based Explainers)进行了公理化表征(Axiomatic Characterisations)，提出了一组理想属性并分析它们之间的关系和不兼容性。论文识别出满足两个关键属性的解释器家族，这些解释器提供弱溯因解释(Weak Abductive Explanations)，并进一步表征了满足兼容属性子集的子家族。最终，它引入了首个保证解释存在和全局一致性的解释器家族，并讨论了如irrefutable explainer和surrogate explainer等实例，这些能以多项式时间生成解释。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04903v2",
      "published_date": "2024-08-09 07:10:07 UTC",
      "updated_date": "2024-08-12 07:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:14:44.040567"
    },
    {
      "arxiv_id": "2408.04895v3",
      "title": "Better Not to Propagate: Understanding Edge Uncertainty and Over-smoothing in Signed Graph Neural Networks",
      "title_zh": "最好不要传播：理解有符号图神经网络中的边不确定性和过度平滑",
      "authors": [
        "Yoonhyuk Choi",
        "Jiho Choi",
        "Taewook Ko",
        "Chong-Kwon Kim"
      ],
      "abstract": "Traditional Graph Neural Networks (GNNs) rely on network homophily, which can\nlead to performance degradation due to over-smoothing in many real-world\nheterophily scenarios. Recent studies analyze the smoothing effect\n(separability) after message-passing (MP), depending on the expectation of node\nfeatures. Regarding separability gain, they provided theoretical backgrounds on\nover-smoothing caused by various propagation schemes, including positive,\nsigned, and blocked MPs. More recently, by extending these theorems, some works\nhave suggested improvements in signed propagation under multiple classes.\nHowever, prior works assume that the error ratio of all propagation schemes is\nfixed, failing to investigate this phenomenon correctly. To solve this problem,\nwe propose a novel method for estimating homophily and edge error ratio,\nintegrated with dynamic selection between blocked and signed propagation during\ntraining. Our theoretical analysis, supported by extensive experiments,\ndemonstrates that blocking MP can be more effective than signed propagation\nunder high edge error ratios, improving the performance in both homophilic and\nheterophilic graphs.",
      "tldr_zh": "这篇论文探讨了Signed Graph Neural Networks (GNNs) 中edge uncertainty和over-smoothing问题，指出传统GNN依赖于homophily而在heterophily场景下性能可能下降，因为现有研究错误假设了所有message-passing (MP)方案的错误率固定。作者提出了一种新方法，通过估计homophily和edge error ratio，并整合动态选择blocked或signed propagation方案到训练过程中，来优化模型表现。实验和理论分析证明，在高edge error ratios下，blocked MP比signed propagation更有效，从而提升了homophilic和heterophilic graphs的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04895v3",
      "published_date": "2024-08-09 06:46:06 UTC",
      "updated_date": "2024-11-02 06:10:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:14:56.845908"
    },
    {
      "arxiv_id": "2408.04870v5",
      "title": "ConfusedPilot: Confused Deputy Risks in RAG-based LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ayush RoyChowdhury",
        "Mulong Luo",
        "Prateek Sahu",
        "Sarbartha Banerjee",
        "Mohit Tiwari"
      ],
      "abstract": "Retrieval augmented generation (RAG) is a process where a large language\nmodel (LLM) retrieves useful information from a database and then generates the\nresponses. It is becoming popular in enterprise settings for daily business\noperations. For example, Copilot for Microsoft 365 has accumulated millions of\nbusinesses. However, the security implications of adopting such RAG-based\nsystems are unclear.\n  In this paper, we introduce ConfusedPilot, a class of security\nvulnerabilities of RAG systems that confuse Copilot and cause integrity and\nconfidentiality violations in its responses. First, we investigate a\nvulnerability that embeds malicious text in the modified prompt in RAG,\ncorrupting the responses generated by the LLM. Second, we demonstrate a\nvulnerability that leaks secret data, which leverages the caching mechanism\nduring retrieval. Third, we investigate how both vulnerabilities can be\nexploited to propagate misinformation within the enterprise and ultimately\nimpact its operations, such as sales and manufacturing. We also discuss the\nroot cause of these attacks by investigating the architecture of a RAG-based\nsystem. This study highlights the security vulnerabilities in today's RAG-based\nsystems and proposes design guidelines to secure future RAG-based systems.",
      "tldr_zh": "本研究引入了ConfusedPilot，一类安全漏洞，针对基于RAG（Retrieval Augmented Generation）的LLMs（Large Language Models），可能导致响应完整性和机密性问题。论文调查了两种具体漏洞：一是通过在RAG中嵌入恶意文本修改提示，破坏LLM生成的响应；二是利用缓存机制泄露秘密数据。实验结果显示，这些漏洞可被利用来传播错误信息，影响企业运营如销售和制造，并通过分析RAG系统架构探讨了攻击根因，同时提出设计指南以提升未来RAG系统的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04870v5",
      "published_date": "2024-08-09 05:20:05 UTC",
      "updated_date": "2024-10-23 05:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:15:09.876222"
    },
    {
      "arxiv_id": "2408.15248v1",
      "title": "AI-Powered Camera and Sensors for the Rehabilitation Hand Exoskeleton",
      "title_zh": "翻译失败",
      "authors": [
        "Md Abdul Baset Sarker",
        "Juan Pablo Sola-thomas",
        "Masudul H. Imtiaz"
      ],
      "abstract": "Due to Motor Neurone Diseases, a large population remains disabled worldwide,\nnegatively impacting their independence and quality of life. This typically\ninvolves a weakness in the hand and forearm muscles, making it difficult to\nperform fine motor tasks such as writing, buttoning a shirt, or gripping\nobjects. This project presents a vision-enabled rehabilitation hand exoskeleton\nto assist disabled persons in their hand movements. The design goal was to\ncreate an accessible tool to help with a simple interface requiring no\ntraining. This prototype is built on a commercially available glove where a\ncamera and embedded processor were integrated to help open and close the hand,\nusing air pressure, thus grabbing an object. An accelerometer is also\nimplemented to detect the characteristic hand gesture to release the object\nwhen desired. This passive vision-based control differs from active EMG-based\ndesigns as it does not require individualized training. Continuing the research\nwill reduce the cost, weight, and power consumption to facilitate mass\nimplementation.",
      "tldr_zh": "该研究针对Motor Neurone Diseases导致的手部肌肉无力问题，开发了一种AI-Powered手外骨骼原型，以辅助残疾人士进行精细手部运动。设计基于商用手套，集成摄像头、嵌入式处理器和加速度计，通过气压机制实现手部开合抓取物体，并使用加速度计检测手势以释放物体。相较于传统的EMG-based设计，该系统采用被动视觉控制，无需个性化训练，简化了操作界面，并计划通过进一步优化降低成本、重量和功耗以推动大规模应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15248v1",
      "published_date": "2024-08-09 04:47:37 UTC",
      "updated_date": "2024-08-09 04:47:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:15:21.043903"
    },
    {
      "arxiv_id": "2408.08894v2",
      "title": "Enhancing Exploratory Learning through Exploratory Search with the Emergence of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Luo",
        "Patrick Cheong-Iao Pang",
        "Shanton Chang"
      ],
      "abstract": "In the information era, how learners find, evaluate, and effectively use\ninformation has become a challenging issue, especially with the added\ncomplexity of large language models (LLMs) that have further confused learners\nin their information retrieval and search activities. This study attempts to\nunpack this complexity by combining exploratory search strategies with the\ntheories of exploratory learning to form a new theoretical model of exploratory\nlearning from the perspective of students' learning. Our work adapts Kolb's\nlearning model by incorporating high-frequency exploration and feedback loops,\naiming to promote deep cognitive and higher-order cognitive skill development\nin students. Additionally, this paper discusses and suggests how advanced LLMs\nintegrated into information retrieval and information theory can support\nstudents in their exploratory searches, contributing theoretically to promoting\nstudent-computer interaction and supporting their learning journeys in the new\nera with LLMs.",
      "tldr_zh": "本研究探讨了信息时代下，学习者在信息检索和搜索中面临的挑战，特别是大型语言模型（LLMs）的出现增加了复杂性。通过结合探索性搜索策略和探索性学习理论，该研究从学生的学习视角出发，改编了 Kolb's learning model，并加入高频探索和反馈循环，以促进学生的深度认知和高级认知技能发展。同时，论文建议将先进的 LLMs 整合到信息检索和信息理论中，支持探索性搜索，从而提升学生-计算机互动，并为 LLMs 时代的学习过程提供理论支持。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, 7 figures Accpted by HICSS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.08894v2",
      "published_date": "2024-08-09 04:30:16 UTC",
      "updated_date": "2025-01-05 08:33:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:15:33.817965"
    },
    {
      "arxiv_id": "2408.04849v1",
      "title": "Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture",
      "title_zh": "Ensemble BERT：一种基于集成学习和BERT架构的学生社交网络文本情感分类模型",
      "authors": [
        "Kai Jiang",
        "Honghao Yang",
        "Yuexian Wang",
        "Qianru Chen",
        "Yiming Luo"
      ],
      "abstract": "The mental health assessment of middle school students has always been one of\nthe focuses in the field of education. This paper introduces a new ensemble\nlearning network based on BERT, employing the concept of enhancing model\nperformance by integrating multiple classifiers. We trained a range of\nBERT-based learners, which combined using the majority voting method. We\ncollect social network text data of middle school students through China's\nWeibo and apply the method to the task of classifying emotional tendencies in\nmiddle school students' social network texts. Experimental results suggest that\nthe ensemble learning network has a better performance than the base model and\nthe performance of the ensemble learning model, consisting of three\nsingle-layer BERT models, is barely the same as a three-layer BERT model but\nrequires 11.58% more training time. Therefore, in terms of balancing prediction\neffect and efficiency, the deeper BERT network should be preferred for\ntraining. However, for interpretability, network ensembles can provide\nacceptable solutions.",
      "tldr_zh": "这篇论文提出了一种名为 Ensemble BERT 的模型，用于分类中学生社交网络文本的情感倾向，以评估心理健康。模型基于 ensemble learning 和 BERT 架构，通过训练多个 BERT 学习器并采用 majority voting 方法整合它们，从而提升分类性能。实验结果显示，Ensemble BERT 比基础模型表现更好，但由三个单层 BERT 模型组成的集成模型与三层 BERT 模型性能相当，却需要额外 11.58% 的训练时间。因此，论文建议在平衡预测效果和效率时优先选择更深层的 BERT 网络，而集成方法则在提升模型可解释性方面提供可接受的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04849v1",
      "published_date": "2024-08-09 03:57:31 UTC",
      "updated_date": "2024-08-09 03:57:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:15:45.986020"
    },
    {
      "arxiv_id": "2409.14248v3",
      "title": "Higher-order-ReLU-KANs (HRKANs) for solving physics-informed neural networks (PINNs) more accurately, robustly and faster",
      "title_zh": "翻译失败",
      "authors": [
        "Chi Chiu So",
        "Siu Pang Yung"
      ],
      "abstract": "Finding solutions to partial differential equations (PDEs) is an important\nand essential component in many scientific and engineering discoveries. One of\nthe common approaches empowered by deep learning is Physics-informed Neural\nNetworks (PINNs). Recently, a new type of fundamental neural network model,\nKolmogorov-Arnold Networks (KANs), has been proposed as a substitute of\nMultilayer Perceptions (MLPs), and possesses trainable activation functions. To\nenhance KANs in fitting accuracy, a modification of KANs, so called ReLU-KANs,\nusing \"square of ReLU\" as the basis of its activation functions, has been\nsuggested. In this work, we propose another basis of activation functions,\nnamely, Higherorder-ReLU (HR), which is simpler than the basis of activation\nfunctions used in KANs, namely, Bsplines; allows efficient KAN matrix\noperations; and possesses smooth and non-zero higher-order derivatives,\nessential to physicsinformed neural networks. We name such KANs with\nHigher-order-ReLU (HR) as their activations, HRKANs. Our detailed experiments\non two famous and representative PDEs, namely, the linear Poisson equation and\nnonlinear Burgers' equation with viscosity, reveal that our proposed\nHigher-order-ReLU-KANs (HRKANs) achieve the highest fitting accuracy and\ntraining robustness and lowest training time significantly among KANs,\nReLU-KANs and HRKANs. The codes to replicate our experiments are available at\nhttps://github.com/kelvinhkcs/HRKAN.",
      "tldr_zh": "该论文提出 Higher-order-ReLU-KANs (HRKANs)，一种改进的 Kolmogorov-Arnold Networks (KANs)，旨在提升 Physics-informed Neural Networks (PINNs) 在解决偏微分方程 (PDEs) 时的准确性、鲁棒性和训练速度。HRKANs 使用更简单的 Higher-order-ReLU (HR) 激活函数作为基础，该函数支持高效矩阵操作，并具有平滑的非零高阶导数，从而更好地适应 PINNs 的需求。在针对线性 Poisson 方程和非线性 Burgers' 方程的实验中，HRKANs 显著超过了 KANs 和 ReLU-KANs，在拟合准确性、训练鲁棒性和时间效率上表现出色。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "cs.NE",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.14248v3",
      "published_date": "2024-08-09 03:50:58 UTC",
      "updated_date": "2024-09-29 11:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:15:58.663582"
    },
    {
      "arxiv_id": "2408.04846v1",
      "title": "UGrid: An Efficient-And-Rigorous Neural Multigrid Solver for Linear PDEs",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Han",
        "Fei Hou",
        "Hong Qin"
      ],
      "abstract": "Numerical solvers of Partial Differential Equations (PDEs) are of fundamental\nsignificance to science and engineering. To date, the historical reliance on\nlegacy techniques has circumscribed possible integration of big data knowledge\nand exhibits sub-optimal efficiency for certain PDE formulations, while\ndata-driven neural methods typically lack mathematical guarantee of convergence\nand correctness. This paper articulates a mathematically rigorous neural solver\nfor linear PDEs. The proposed UGrid solver, built upon the principled\nintegration of U-Net and MultiGrid, manifests a mathematically rigorous proof\nof both convergence and correctness, and showcases high numerical accuracy, as\nwell as strong generalization power to various input geometry/values and\nmultiple PDE formulations. In addition, we devise a new residual loss metric,\nwhich enables unsupervised training and affords more stability and a larger\nsolution space over the legacy losses.",
      "tldr_zh": "该论文提出UGrid，一种高效且数学严谨的神经求解器，用于线性PDEs（Partial Differential Equations）的数值求解，通过整合U-Net和MultiGrid框架确保了收敛性和正确性的数学证明。\nUGrid展示了高数值精度和对各种输入几何、值以及多种PDEs公式的强泛化能力，解决了传统方法效率低下和数据驱动方法缺乏保证的问题。\n此外，作者引入了一个新的残差损失指标，支持无监督训练，提升了模型的稳定性并扩展了解空间。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.MS",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "Proceedings of the 41st International Conference on Machine Learning,\n  Vienna, Austria. PMLR 235, 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04846v1",
      "published_date": "2024-08-09 03:46:35 UTC",
      "updated_date": "2024-08-09 03:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:16:10.516976"
    },
    {
      "arxiv_id": "2408.04842v4",
      "title": "Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change",
      "title_zh": "翻译失败",
      "authors": [
        "Ignacy Stępka",
        "Mateusz Lango",
        "Jerzy Stefanowski"
      ],
      "abstract": "Counterfactual explanations (CFEs) guide users on how to adjust inputs to\nmachine learning models to achieve desired outputs. While existing research\nprimarily addresses static scenarios, real-world applications often involve\ndata or model changes, potentially invalidating previously generated CFEs and\nrendering user-induced input changes ineffective. Current methods addressing\nthis issue often support only specific models or change types, require\nextensive hyperparameter tuning, or fail to provide probabilistic guarantees on\nCFE robustness to model changes. This paper proposes a novel approach for\ngenerating CFEs that provides probabilistic guarantees for any model and change\ntype, while offering interpretable and easy-to-select hyperparameters. We\nestablish a theoretical framework for probabilistically defining robustness to\nmodel change and demonstrate how our BetaRCE method directly stems from it.\nBetaRCE is a post-hoc method applied alongside a chosen base CFE generation\nmethod to enhance the quality of the explanation beyond robustness. It\nfacilitates a transition from the base explanation to a more robust one with\nuser-adjusted probability bounds. Through experimental comparisons with\nbaselines, we show that BetaRCE yields robust, most plausible, and closest to\nbaseline counterfactual explanations.",
      "tldr_zh": "这篇论文解决了反事实解释(Counterfactual Explanations, CFEs)对模型变化的鲁棒性问题，提出了一种新方法，提供概率保证，适用于任何模型和变化类型，并使用可解释的超参数。作者建立了理论框架来定义模型变化的概率鲁棒性，并开发了BetaRCE后验方法，与基础CFE生成方法结合，帮助用户调整解释以提升鲁棒性和质量。实验结果表明，BetaRCE生成的CFEs在鲁棒性、最优性和接近基线方面均优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at 31st SIGKDD Conference on Knowledge Discovery and Data\n  Mining 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.04842v4",
      "published_date": "2024-08-09 03:35:53 UTC",
      "updated_date": "2025-02-09 23:12:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:16:25.271172"
    },
    {
      "arxiv_id": "2408.04841v3",
      "title": "Kolmogorov-Arnold Network for Online Reinforcement Learning",
      "title_zh": "Kolmogorov-Arnold 网络用于在线强化学习",
      "authors": [
        "Victor Augusto Kich",
        "Jair Augusto Bottega",
        "Raul Steinmetz",
        "Ricardo Bedin Grando",
        "Ayano Yorozu",
        "Akihisa Ohya"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) have shown potential as an alternative to\nMulti-Layer Perceptrons (MLPs) in neural networks, providing universal function\napproximation with fewer parameters and reduced memory usage. In this paper, we\nexplore the use of KANs as function approximators within the Proximal Policy\nOptimization (PPO) algorithm. We evaluate this approach by comparing its\nperformance to the original MLP-based PPO using the DeepMind Control Proprio\nRobotics benchmark. Our results indicate that the KAN-based reinforcement\nlearning algorithm can achieve comparable performance to its MLP-based\ncounterpart, often with fewer parameters. These findings suggest that KANs may\noffer a more efficient option for reinforcement learning models.",
      "tldr_zh": "本研究探讨了Kolmogorov-Arnold Networks (KANs)作为一种替代Multi-Layer Perceptrons (MLPs)的函数逼近器，在在线强化学习中的应用。作者将KANs整合到Proximal Policy Optimization (PPO)算法中，并使用DeepMind Control Proprio Robotics基准进行评估。结果显示，基于KANs的强化学习算法能与基于MLPs的PPO实现相当的表现，但参数更少，从而提供更高的效率。这些发现表明，KANs可能成为强化学习模型更优化的选择。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at 24th International Conference on Control,\n  Automation and Systems (ICCAS)",
      "pdf_url": "http://arxiv.org/pdf/2408.04841v3",
      "published_date": "2024-08-09 03:32:37 UTC",
      "updated_date": "2024-08-31 21:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:16:33.203869"
    },
    {
      "arxiv_id": "2408.15247v1",
      "title": "AutoGen Studio: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems",
      "title_zh": "AutoGen Studio: 一个无代码开发工具，用于构建和调试多智能体系统",
      "authors": [
        "Victor Dibia",
        "Jingya Chen",
        "Gagan Bansal",
        "Suff Syed",
        "Adam Fourney",
        "Erkang Zhu",
        "Chi Wang",
        "Saleema Amershi"
      ],
      "abstract": "Multi-agent systems, where multiple agents (generative AI models + tools)\ncollaborate, are emerging as an effective pattern for solving long-running,\ncomplex tasks in numerous domains. However, specifying their parameters (such\nas models, tools, and orchestration mechanisms etc,.) and debugging them\nremains challenging for most developers. To address this challenge, we present\nAUTOGEN STUDIO, a no-code developer tool for rapidly prototyping, debugging,\nand evaluating multi-agent workflows built upon the AUTOGEN framework. AUTOGEN\nSTUDIO offers a web interface and a Python API for representing LLM-enabled\nagents using a declarative (JSON-based) specification. It provides an intuitive\ndrag-and-drop UI for agent workflow specification, interactive evaluation and\ndebugging of workflows, and a gallery of reusable agent components. We\nhighlight four design principles for no-code multi-agent developer tools and\ncontribute an open-source implementation at\nhttps://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio",
      "tldr_zh": "该论文介绍了 AutoGen Studio，一种无代码开发工具，旨在帮助开发者快速原型设计、调试和评估基于 AutoGen 框架的多智能体系统（Multi-Agent Systems）。该工具提供 web 接口和 Python API，使用声明式（JSON-based）规范来表示 LLM-enabled 代理，并配备直观的拖拽式 UI、交互式评估调试功能，以及可重用代理组件的图库。AutoGen Studio 遵循四个关键设计原则，并开源实现（https://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio），显著降低了多智能体工作流的开发门槛。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.15247v1",
      "published_date": "2024-08-09 03:27:37 UTC",
      "updated_date": "2024-08-09 03:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:16:49.200935"
    },
    {
      "arxiv_id": "2408.04840v2",
      "title": "mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiabo Ye",
        "Haiyang Xu",
        "Haowei Liu",
        "Anwen Hu",
        "Ming Yan",
        "Qi Qian",
        "Ji Zhang",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "abstract": "Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in executing instructions for a variety of single-image tasks.\nDespite this progress, significant challenges remain in modeling long image\nsequences. In this work, we introduce the versatile multi-modal large language\nmodel, mPLUG-Owl3, which enhances the capability for long image-sequence\nunderstanding in scenarios that incorporate retrieved image-text knowledge,\ninterleaved image-text, and lengthy videos. Specifically, we propose novel\nhyper attention blocks to efficiently integrate vision and language into a\ncommon language-guided semantic space, thereby facilitating the processing of\nextended multi-image scenarios. Extensive experimental results suggest that\nmPLUG-Owl3 achieves state-of-the-art performance among models with a similar\nsize on single-image, multi-image, and video benchmarks. Moreover, we propose a\nchallenging long visual sequence evaluation named Distractor Resistance to\nassess the ability of models to maintain focus amidst distractions. Finally,\nwith the proposed architecture, mPLUG-Owl3 demonstrates outstanding performance\non ultra-long visual sequence inputs. We hope that mPLUG-Owl3 can contribute to\nthe development of more efficient and powerful multimodal large language\nmodels.",
      "tldr_zh": "这篇论文介绍了 mPLUG-Owl3，一种多模态大语言模型 (MLLMs)，旨在提升对长图像序列的理解能力，包括检索图像-文本知识、交错图像-文本和长视频场景。论文提出 hyper attention blocks 的创新方法，用于高效地将视觉和语言整合到一个共同的语言引导语义空间，从而处理扩展的多图像任务。实验结果显示，mPLUG-Owl3 在单图像、多图像和视频基准测试中达到了类似规模模型的最先进性能，并引入了 Distractor Resistance 评估来测试模型在干扰中的注意力保持能力。该模型在超长视觉序列输入上表现出色，有望推动更高效的多模态大语言模型的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04840v2",
      "published_date": "2024-08-09 03:25:42 UTC",
      "updated_date": "2024-08-13 08:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:16:59.938675"
    },
    {
      "arxiv_id": "2408.04831v4",
      "title": "AugGS: Self-augmented Gaussians with Structural Masks for Sparse-view 3D Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Bi'an Du",
        "Lingbei Meng",
        "Wei Hu"
      ],
      "abstract": "Sparse-view 3D reconstruction is a major challenge in computer vision, aiming\nto create complete three-dimensional models from limited viewing angles. Key\nobstacles include: 1) a small number of input images with inconsistent\ninformation; 2) dependence on input image quality; and 3) large model parameter\nsizes. To tackle these issues, we propose a self-augmented two-stage Gaussian\nsplatting framework enhanced with structural masks for sparse-view 3D\nreconstruction. Initially, our method generates a basic 3D Gaussian\nrepresentation from sparse inputs and renders multi-view images. We then\nfine-tune a pre-trained 2D diffusion model to enhance these images, using them\nas augmented data to further optimize the 3D Gaussians. Additionally, a\nstructural masking strategy during training enhances the model's robustness to\nsparse inputs and noise. Experiments on benchmarks like MipNeRF360,\nOmniObject3D, and OpenIllumination demonstrate that our approach achieves\nstate-of-the-art performance in perceptual quality and multi-view consistency\nwith sparse inputs.",
      "tldr_zh": "本论文提出AugGS，一种自增强的Gaussian splatting框架，结合structural masks，用于解决sparse-view 3D reconstruction的挑战，包括输入图像稀少、信息不一致以及对图像质量的依赖。框架采用两阶段方法：首先从sparse inputs生成基本3D Gaussian表示并渲染多视图图像，然后微调预训练的2D diffusion模型来增强这些图像，并利用structural masking策略提高模型对噪声和稀疏输入的鲁棒性。实验在MipNeRF360、OmniObject3D和OpenIllumination基准上显示，AugGS在感知质量和多视图一致性方面实现了state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04831v4",
      "published_date": "2024-08-09 03:09:22 UTC",
      "updated_date": "2024-12-31 10:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:17:12.688998"
    },
    {
      "arxiv_id": "2408.06377v1",
      "title": "Masked Graph Autoencoders with Contrastive Augmentation for Spatially Resolved Transcriptomics Data",
      "title_zh": "翻译失败",
      "authors": [
        "Donghai Fang",
        "Fangfang Zhu",
        "Dongting Xie",
        "Wenwen Min"
      ],
      "abstract": "With the rapid advancement of Spatial Resolved Transcriptomics (SRT)\ntechnology, it is now possible to comprehensively measure gene transcription\nwhile preserving the spatial context of tissues. Spatial domain identification\nand gene denoising are key objectives in SRT data analysis. We propose a\nContrastively Augmented Masked Graph Autoencoder (STMGAC) to learn\nlow-dimensional latent representations for domain identification. In the latent\nspace, persistent signals for representations are obtained through\nself-distillation to guide self-supervised matching. At the same time, positive\nand negative anchor pairs are constructed using triplet learning to augment the\ndiscriminative ability. We evaluated the performance of STMGAC on five\ndatasets, achieving results superior to those of existing baseline methods. All\ncode and public datasets used in this paper are available at\nhttps://github.com/wenwenmin/STMGAC and https://zenodo.org/records/13253801.",
      "tldr_zh": "本文提出了一种 Contrastively Augmented Masked Graph Autoencoder (STMGAC) 方法，用于 Spatial Resolved Transcriptomics (SRT) 数据分析，主要针对空间域识别和基因去噪任务。STMGAC 通过自蒸馏(self-distillation)获得潜在空间的持久信号，并利用三元组学习(triplet learning)构建正负锚点对，以增强表示的区分能力。实验结果显示，该方法在五个数据集上优于现有基线方法，所有代码和数据集已在 GitHub 和 Zenodo 上公开。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06377v1",
      "published_date": "2024-08-09 02:49:23 UTC",
      "updated_date": "2024-08-09 02:49:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:17:25.545720"
    },
    {
      "arxiv_id": "2408.15246v1",
      "title": "Multi-Slice Spatial Transcriptomics Data Integration Analysis with STG3Net",
      "title_zh": "翻译失败",
      "authors": [
        "Donghai Fang",
        "Fangfang Zhu",
        "Wenwen Min"
      ],
      "abstract": "With the rapid development of the latest Spatially Resolved Transcriptomics\n(SRT) technology, which allows for the mapping of gene expression within tissue\nsections, the integrative analysis of multiple SRT data has become increasingly\nimportant. However, batch effects between multiple slices pose significant\nchallenges in analyzing SRT data. To address these challenges, we have\ndeveloped a plug-and-play batch correction method called Global Nearest\nNeighbor (G2N) anchor pairs selection. G2N effectively mitigates batch effects\nby selecting representative anchor pairs across slices. Building upon G2N, we\npropose STG3Net, which cleverly combines masked graph convolutional\nautoencoders as backbone modules. These autoencoders, integrated with\ngenerative adversarial learning, enable STG3Net to achieve robust multi-slice\nspatial domain identification and batch correction. We comprehensively evaluate\nthe feasibility of STG3Net on three multiple SRT datasets from different\nplatforms, considering accuracy, consistency, and the F1LISI metric (a measure\nof batch effect correction efficiency). Compared to existing methods, STG3Net\nachieves the best overall performance while preserving the biological\nvariability and connectivity between slices. Source code and all public\ndatasets used in this paper are available at\nhttps://github.com/wenwenmin/STG3Net and https://zenodo.org/records/12737170.",
      "tldr_zh": "随着空间转录组学 (SRT) 技术的快速发展，多切片数据整合面临批次效应的挑战，本文开发了 Global Nearest Neighbor (G2N) 锚点对选择方法，并提出 STG3Net 框架，该框架结合 masked graph convolutional autoencoders 和 generative adversarial learning，实现有效的批次校正和空间域识别。\nSTG3Net 在三个不同平台的 SRT 数据集上进行了全面评估，在准确性、一致性和 F1LISI 指标上表现出最佳性能，同时保留了生物变异性和切片间连通性。\n源代码和数据集已公开可用，可从指定仓库获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15246v1",
      "published_date": "2024-08-09 02:31:12 UTC",
      "updated_date": "2024-08-09 02:31:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:17:39.017014"
    },
    {
      "arxiv_id": "2408.04822v1",
      "title": "Performance Prediction of Hub-Based Swarms",
      "title_zh": "翻译失败",
      "authors": [
        "Puneet Jain",
        "Chaitanya Dwivedi",
        "Vigynesh Bhatt",
        "Nick Smith",
        "Michael A Goodrich"
      ],
      "abstract": "A hub-based colony consists of multiple agents who share a common nest site\ncalled the hub. Agents perform tasks away from the hub like foraging for food\nor gathering information about future nest sites. Modeling hub-based colonies\nis challenging because the size of the collective state space grows rapidly as\nthe number of agents grows. This paper presents a graph-based representation of\nthe colony that can be combined with graph-based encoders to create\nlow-dimensional representations of collective state that can scale to many\nagents for a best-of-N colony problem. We demonstrate how the information in\nthe low-dimensional embedding can be used with two experiments. First, we show\nhow the information in the tensor can be used to cluster collective states by\nthe probability of choosing the best site for a very small problem. Second, we\nshow how structured collective trajectories emerge when a graph encoder is used\nto learn the low-dimensional embedding, and these trajectories have information\nthat can be used to predict swarm performance.",
      "tldr_zh": "该论文针对基于集散中心的群落（hub-based swarms）的建模挑战提出了一种图-based 表示方法，与图-based encoders 结合，创建可扩展的低维集体状态表示，以应对代理数量增长导致的状态空间爆炸问题。方法应用于最佳选择问题（best-of-N colony problem），通过实验展示了低维嵌入能聚类集体状态以评估选择最佳位置的概率。进一步，论文揭示了使用图编码器学习低维嵌入后形成的结构化集体轨迹，这些轨迹可有效预测群体的性能。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04822v1",
      "published_date": "2024-08-09 02:31:03 UTC",
      "updated_date": "2024-08-09 02:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:18:00.284448"
    },
    {
      "arxiv_id": "2408.07088v2",
      "title": "Learning Rule-Induced Subgraph Representations for Inductive Relation Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Liu",
        "Qitan Lv",
        "Jie Wang",
        "Shuling Yang",
        "Hanzhu Chen"
      ],
      "abstract": "Inductive relation prediction (IRP) -- where entities can be different during\ntraining and inference -- has shown great power for completing evolving\nknowledge graphs. Existing works mainly focus on using graph neural networks\n(GNNs) to learn the representation of the subgraph induced from the target\nlink, which can be seen as an implicit rule-mining process to measure the\nplausibility of the target link. However, these methods cannot differentiate\nthe target link and other links during message passing, hence the final\nsubgraph representation will contain irrelevant rule information to the target\nlink, which reduces the reasoning performance and severely hinders the\napplications for real-world scenarios. To tackle this problem, we propose a\nnovel \\textit{single-source edge-wise} GNN model to learn the\n\\textbf{R}ule-induc\\textbf{E}d \\textbf{S}ubgraph represen\\textbf{T}ations\n(\\textbf{REST}), which encodes relevant rules and eliminates irrelevant rules\nwithin the subgraph. Specifically, we propose a \\textit{single-source}\ninitialization approach to initialize edge features only for the target link,\nwhich guarantees the relevance of mined rules and target link. Then we propose\nseveral RNN-based functions for \\textit{edge-wise} message passing to model the\nsequential property of mined rules. REST is a simple and effective approach\nwith theoretical support to learn the \\textit{rule-induced subgraph\nrepresentation}. Moreover, REST does not need node labeling, which\nsignificantly accelerates the subgraph preprocessing time by up to\n\\textbf{11.66$\\times$}. Experiments on inductive relation prediction benchmarks\ndemonstrate the effectiveness of our REST. Our code is available at\nhttps://github.com/smart-lty/REST.",
      "tldr_zh": "本论文针对Inductive Relation Prediction (IRP)问题，提出了一种新型的single-source edge-wise GNN模型REST，用于学习规则诱导的子图表示，以完成演化知识图谱。REST通过single-source初始化方法仅为目标链接初始化边特征，确保挖掘规则的相关性，并采用RNN-based函数进行edge-wise message passing，模拟规则的顺序属性，从而消除无关规则信息。实验结果显示，REST在IRP基准上表现出色，同时无需节点标记，子图预处理速度提升高达11.66倍，为实际应用提供了高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07088v2",
      "published_date": "2024-08-09 02:27:46 UTC",
      "updated_date": "2024-08-20 06:33:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:18:01.316725"
    },
    {
      "arxiv_id": "2408.04820v4",
      "title": "Natural Language Outlines for Code: Literate Programming in the LLM Era",
      "title_zh": "翻译失败",
      "authors": [
        "Kensen Shi",
        "Deniz Altınbüken",
        "Saswat Anand",
        "Mihai Christodorescu",
        "Katja Grünwedel",
        "Alexa Koenings",
        "Sai Naidu",
        "Anurag Pathak",
        "Marc Rasi",
        "Fredde Ribeiro",
        "Brandon Ruffin",
        "Siddhant Sanyam",
        "Maxim Tabachnyk",
        "Sara Toth",
        "Roy Tu",
        "Tobias Welp",
        "Pengcheng Yin",
        "Manzil Zaheer",
        "Satish Chandra",
        "Charles Sutton"
      ],
      "abstract": "We propose using natural language outlines as a novel modality and\ninteraction surface for providing AI assistance to developers throughout the\nsoftware development process. An NL outline for a code function comprises\nmultiple statements written in concise prose, which partition the code and\nsummarize its main ideas in the style of literate programming. Crucially, we\nfind that modern LLMs can generate accurate and high-quality NL outlines in\npractice. Moreover, NL outlines enable a bidirectional sync between code and\nNL, where a developer can change either code or NL and have the LLM\nautomatically update the other. We discuss many use cases for NL outlines: they\ncan accelerate understanding and navigation of code and diffs, simplify code\nmaintenance, augment code search, steer code generation, and more. We then\npropose and compare multiple LLM prompting techniques for generating outlines\nand ask professional developers to judge outline quality. Finally, we present\ntwo case studies applying NL outlines toward code review and malware detection.",
      "tldr_zh": "本文提出使用 Natural Language Outlines (NL outlines) 作为一种新模态和交互界面，通过简洁的自然语言语句来分割和总结代码，延续 Literate Programming 的理念，并利用 LLMs 生成高质量的大纲以辅助软件开发。关键创新包括实现代码和自然语言的双向同步，让开发者修改一方时 LLMs 自动更新另一方，从而加速代码理解、导航、维护、搜索和生成等任务。实验比较了多种 LLM 提示技术，并通过专业开发者评估和案例研究（如代码审查和恶意软件检测）证明了 NL outlines 的实用性和有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to FSE'25 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2408.04820v4",
      "published_date": "2024-08-09 02:22:51 UTC",
      "updated_date": "2025-04-17 22:02:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:18:13.520789"
    },
    {
      "arxiv_id": "2408.04817v1",
      "title": "Performance Metric for Multiple Anomaly Score Distributions with Discrete Severity Levels",
      "title_zh": "针对具有离散严重程度级别的多个异常分数分布的性能指标",
      "authors": [
        "Wonjun Yi",
        "Yong-Hwa Park",
        "Wonho Jung"
      ],
      "abstract": "The rise of smart factories has heightened the demand for automated\nmaintenance, and normal-data-based anomaly detection has proved particularly\neffective in environments where anomaly data are scarce. This method, which\ndoes not require anomaly data during training, has prompted researchers to\nfocus not only on detecting anomalies but also on classifying severity levels\nby using anomaly scores. However, the existing performance metrics, such as the\narea under the receiver operating characteristic curve (AUROC), do not\neffectively reflect the performance of models in classifying severity levels\nbased on anomaly scores. To address this limitation, we propose the weighted\nsum of the area under the receiver operating characteristic curve (WS-AUROC),\nwhich combines AUROC with a penalty for severity level differences. We\nconducted various experiments using different penalty assignment methods:\nuniform penalty regardless of severity level differences, penalty based on\nseverity level index differences, and penalty based on actual physical\nquantities that cause anomalies. The latter method was the most sensitive.\nAdditionally, we propose an anomaly detector that achieves clear separation of\ndistributions and outperforms the ablation models on the WS-AUROC and AUROC\nmetrics.",
      "tldr_zh": "该研究针对智能工厂中基于正常数据的异常检测问题，指出现有指标如 AUROC 无法有效评估异常分数在离散严重级别上的分类性能。论文提出了一种新指标 WS-AUROC，通过在 AUROC 基础上添加针对严重级别差异的惩罚权重，提升了对异常严重度的评估准确性。实验比较了不同惩罚分配方法（如基于索引差异或实际物理量），发现后者更敏感；此外，作者开发了一种异常检测器，能够实现分布清晰分离，并在 WS-AUROC 和 AUROC 指标上优于基准模型，从而为更精确的自动化维护提供工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted as a work-in-progress paper at the 2024 Annual Conference of\n  the IEEE Industrial Electronics Society (IECON)",
      "pdf_url": "http://arxiv.org/pdf/2408.04817v1",
      "published_date": "2024-08-09 02:17:49 UTC",
      "updated_date": "2024-08-09 02:17:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:18:28.212822"
    },
    {
      "arxiv_id": "2408.07087v1",
      "title": "A Novel Spatiotemporal Coupling Graph Convolutional Network",
      "title_zh": "一种新颖的时空耦合图卷积网络",
      "authors": [
        "Fanghui Bi"
      ],
      "abstract": "Dynamic Quality-of-Service (QoS) data capturing temporal variations in\nuser-service interactions, are essential source for service selection and user\nbehavior understanding. Approaches based on Latent Feature Analysis (LFA) have\nshown to be beneficial for discovering effective temporal patterns in QoS data.\nHowever, existing methods cannot well model the spatiality and temporality\nimplied in dynamic interactions in a unified form, causing abundant accuracy\nloss for missing QoS estimation. To address the problem, this paper presents a\nnovel Graph Convolutional Networks (GCNs)-based dynamic QoS estimator namely\nSpatiotemporal Coupling GCN (SCG) model with the three-fold ideas as below.\nFirst, SCG builds its dynamic graph convolution rules by incorporating\ngeneralized tensor product framework, for unified modeling of spatial and\ntemporal patterns. Second, SCG combines the heterogeneous GCN layer with tensor\nfactorization, for effective representation learning on bipartite user-service\ngraphs. Third, it further simplifies the dynamic GCN structure to lower the\ntraining difficulties. Extensive experiments have been conducted on two\nlarge-scale widely-adopted QoS datasets describing throughput and response\ntime. The results demonstrate that SCG realizes higher QoS estimation accuracy\ncompared with the state-of-the-arts, illustrating it can learn powerful\nrepresentations to users and cloud services.",
      "tldr_zh": "本论文针对动态 Quality-of-Service (QoS) 数据中空间性和时间性的统一建模问题，提出了一种新型的 Spatiotemporal Coupling Graph Convolutional Network (SCG) 模型，以解决现有 Latent Feature Analysis (LFA) 方法的准确率损失。SCG 通过广义张量乘积框架统一捕捉空间和时间模式，结合异构 GCN 层与张量分解进行二分用户-服务图的有效表示学习，并简化动态 GCN 结构以降低训练难度。实验在两个大规模 QoS 数据集上表明，SCG 比现有最先进方法实现了更高的 QoS 估计准确率，从而提升了用户行为理解和服务选择的效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07087v1",
      "published_date": "2024-08-09 02:02:01 UTC",
      "updated_date": "2024-08-09 02:02:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:18:38.068081"
    },
    {
      "arxiv_id": "2408.04812v1",
      "title": "A Collaborative PIM Computing Optimization Framework for Multi-Tenant DNN",
      "title_zh": "翻译失败",
      "authors": [
        "Bojing Li",
        "Duo Zhong",
        "Xiang Chen",
        "Chenchen Liu"
      ],
      "abstract": "Modern Artificial Intelligence (AI) applications are increasingly utilizing\nmulti-tenant deep neural networks (DNNs), which lead to a significant rise in\ncomputing complexity and the need for computing parallelism. ReRAM-based\nprocessing-in-memory (PIM) computing, with its high density and low power\nconsumption characteristics, holds promising potential for supporting the\ndeployment of multi-tenant DNNs. However, direct deployment of complex\nmulti-tenant DNNs on exsiting ReRAM-based PIM designs poses challenges.\nResource contention among different tenants can result in sever\nunder-utilization of on-chip computing resources. Moreover, area-intensive\noperators and computation-intensive operators require excessively large on-chip\nareas and long processing times, leading to high overall latency during\nparallel computing. To address these challenges, we propose a novel ReRAM-based\nin-memory computing framework that enables efficient deployment of multi-tenant\nDNNs on ReRAM-based PIM designs. Our approach tackles the resource contention\nproblems by iteratively partitioning the PIM hardware at tenant level. In\naddition, we construct a fine-grained reconstructed processing pipeline at the\noperator level to handle area-intensive operators. Compared to the direct\ndeployments on traditional ReRAM-based PIM designs, our proposed PIM computing\nframework achieves significant improvements in speed (ranges from 1.75x to\n60.43x) and energy(up to 1.89x).",
      "tldr_zh": "本研究针对多租户深度神经网络 (DNNs) 的计算复杂性和并行需求，提出了一种协作式 ReRAM-based Processing-in-Memory (PIM) 计算优化框架，以提升部署效率。该框架通过在租户级别迭代分区 PIM 硬件来缓解资源争用问题，并在操作器级别构建细粒度重建处理管道，以处理面积密集型和计算密集型操作器。实验结果显示，与传统 ReRAM-based PIM 设计相比，该框架实现了速度提升 1.75x 到 60.43x，以及能效最高达 1.89x 的改善。",
      "categories": [
        "cs.ET",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04812v1",
      "published_date": "2024-08-09 01:46:33 UTC",
      "updated_date": "2024-08-09 01:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:18:59.594927"
    },
    {
      "arxiv_id": "2408.04811v4",
      "title": "h4rm3l: A language for Composable Jailbreak Attack Synthesis",
      "title_zh": "h4rm3l：一种用于可组合越狱攻击合成的语言",
      "authors": [
        "Moussa Koulako Bala Doumbouya",
        "Ananjan Nandi",
        "Gabriel Poesia",
        "Davide Ghilardi",
        "Anna Goldie",
        "Federico Bianchi",
        "Dan Jurafsky",
        "Christopher D. Manning"
      ],
      "abstract": "Despite their demonstrated valuable capabilities, state-of-the-art (SOTA)\nwidely deployed large language models (LLMs) still have the potential to cause\nharm to society due to the ineffectiveness of their safety filters, which can\nbe bypassed by prompt transformations called jailbreak attacks. Current\napproaches to LLM safety assessment, which employ datasets of templated prompts\nand benchmarking pipelines, fail to cover sufficiently large and diverse sets\nof jailbreak attacks, leading to the widespread deployment of unsafe LLMs.\nRecent research showed that novel jailbreak attacks could be derived by\ncomposition; however, a formal composable representation for jailbreak attacks,\nwhich, among other benefits, could enable the exploration of a large\ncompositional space of jailbreak attacks through program synthesis methods, has\nnot been previously proposed. We introduce h4rm3l, a novel approach that\naddresses this gap with a human-readable domain-specific language (DSL). Our\nframework comprises: (1) The h4rm3l DSL, which formally expresses jailbreak\nattacks as compositions of parameterized string transformation primitives. (2)\nA synthesizer with bandit algorithms that efficiently generates jailbreak\nattacks optimized for a target black box LLM. (3) The h4rm3l red-teaming\nsoftware toolkit that employs the previous two components and an automated\nharmful LLM behavior classifier that is strongly aligned with human judgment.\nWe demonstrate h4rm3l's efficacy by synthesizing a dataset of 2656 successful\nnovel jailbreak attacks targeting 6 SOTA open-source and proprietary LLMs, and\nby benchmarking those models against a subset of these synthesized attacks. Our\nresults show that h4rm3l's synthesized attacks are diverse and more successful\nthan existing jailbreak attacks in literature, with success rates exceeding 90%\non SOTA LLMs.",
      "tldr_zh": "该论文引入 h4rm3l，一种人类可读的领域特定语言（DSL），用于形式化表达 jailbreak attacks 作为参数化字符串转换原语的组合，从而解决大型语言模型（LLMs）的安全评估问题。h4rm3l 框架包括一个基于 bandit algorithms 的合成器，用于高效生成针对黑盒 LLM 的优化攻击，以及一个 red-teaming 软件工具包，结合自动有害行为分类器来评估攻击效果。实验结果显示，该方法合成了 2656 个多样化的成功 jailbreak attacks，对 6 个 SOTA LLMs 的成功率超过 90%，显著优于现有攻击。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "68",
        "I.2; I.2.0; I.2.1; I.2.5; I.2.7; K.6.5; K.4.2"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2408.04811v4",
      "published_date": "2024-08-09 01:45:39 UTC",
      "updated_date": "2025-03-25 01:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:19:03.424309"
    },
    {
      "arxiv_id": "2408.04810v1",
      "title": "UniBench: Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling",
      "title_zh": "UniBench：视觉推理需要超越缩放重新审视视觉语言",
      "authors": [
        "Haider Al-Tahan",
        "Quentin Garrido",
        "Randall Balestriero",
        "Diane Bouchacourt",
        "Caner Hazirbas",
        "Mark Ibrahim"
      ],
      "abstract": "Significant research efforts have been made to scale and improve\nvision-language model (VLM) training approaches. Yet, with an ever-growing\nnumber of benchmarks, researchers are tasked with the heavy burden of\nimplementing each protocol, bearing a non-trivial computational cost, and\nmaking sense of how all these benchmarks translate into meaningful axes of\nprogress. To facilitate a systematic evaluation of VLM progress, we introduce\nUniBench: a unified implementation of 50+ VLM benchmarks spanning a\ncomprehensive range of carefully categorized capabilities from object\nrecognition to spatial awareness, counting, and much more. We showcase the\nutility of UniBench for measuring progress by evaluating nearly 60 publicly\navailable vision-language models, trained on scales of up to 12.8B samples. We\nfind that while scaling training data or model size can boost many\nvision-language model capabilities, scaling offers little benefit for reasoning\nor relations. Surprisingly, we also discover today's best VLMs struggle on\nsimple digit recognition and counting tasks, e.g. MNIST, which much simpler\nnetworks can solve. Where scale falls short, we find that more precise\ninterventions, such as data quality or tailored-learning objectives offer more\npromise. For practitioners, we also offer guidance on selecting a suitable VLM\nfor a given application. Finally, we release an easy-to-run UniBench code-base\nwith the full set of 50+ benchmarks and comparisons across 59 models as well as\na distilled, representative set of benchmarks that runs in 5 minutes on a\nsingle GPU.",
      "tldr_zh": "本文提出 UniBench，这是一个统一框架，集成了50+个视觉语言模型(VLM)基准测试，涵盖从对象识别到空间感知和计数等能力，旨在系统评估VLM的进展并减少研究者的实现负担。研究者评估了近60个公开VLM，发现扩展训练数据或模型规模能提升许多能力，但对视觉推理和关系任务几乎无益，且当前顶级VLM在简单任务如MNIST数字识别和计数上表现欠佳。作者建议通过改善数据质量或定制学习目标等精确干预来提升性能，并提供了易于运行的代码库，包括一个简化版可在单GPU上5分钟内完成测试。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04810v1",
      "published_date": "2024-08-09 01:41:05 UTC",
      "updated_date": "2024-08-09 01:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:19:17.628858"
    },
    {
      "arxiv_id": "2408.04809v2",
      "title": "On the Geometry of Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Randall Balestriero",
        "Ahmed Imtiaz Humayun",
        "Richard Baraniuk"
      ],
      "abstract": "In this paper, we overview one promising avenue of progress at the\nmathematical foundation of deep learning: the connection between deep networks\nand function approximation by affine splines (continuous piecewise linear\nfunctions in multiple dimensions). In particular, we will overview work over\nthe past decade on understanding certain geometrical properties of a deep\nnetwork's affine spline mapping, in particular how it tessellates its input\nspace. As we will see, the affine spline connection and geometrical viewpoint\nprovide a powerful portal through which to view, analyze, and improve the inner\nworkings of a deep network.",
      "tldr_zh": "本论文概述了深度学习数学基础的一个关键进展：深度网络与仿射样条（affine splines，即多维连续分段线性函数）的函数逼近（function approximation）之间的联系。作者回顾了过去十年的研究，焦点在于深度网络的几何属性，特别是如何在输入空间中进行网格划分（tessellates its input space）。这种几何视角为分析和改进深度网络的内部机制提供了强大工具，有助于提升其性能和理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at 'Notices of the American Mathematical\n  Society'",
      "pdf_url": "http://arxiv.org/pdf/2408.04809v2",
      "published_date": "2024-08-09 01:40:12 UTC",
      "updated_date": "2025-01-14 19:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:19:26.548255"
    },
    {
      "arxiv_id": "2408.04797v1",
      "title": "AI and Machine Learning Driven Indoor Localization and Navigation with Mobile Embedded Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sudeep Pasricha"
      ],
      "abstract": "Indoor navigation is a foundational technology to assist the tracking and\nlocalization of humans, autonomous vehicles, drones, and robots in indoor\nspaces. Due to the lack of penetration of GPS signals in buildings,\nsubterranean locales, and dense urban environments, indoor navigation solutions\ntypically make use of ubiquitous wireless signals (e.g., WiFi) and sensors in\nmobile embedded systems to perform tracking and localization. This article\nprovides an overview of the many challenges facing state-of-the-art indoor\nnavigation solutions, and then describes how AI algorithms deployed on mobile\nembedded systems can overcome these challenges.",
      "tldr_zh": "本文探讨了AI和机器学习驱动的室内定位和导航技术，旨在解决GPS信号无法穿透建筑物、地下场所和密集城市环境带来的挑战。文章概述了当前室内导航解决方案面临的难题，如信号干扰和准确性问题，并强调利用移动嵌入式系统的无线信号（如WiFi）和传感器进行跟踪与定位。最终，它描述了如何通过部署AI算法在这些系统中来克服这些挑战，从而为人类、自动车辆、无人机和机器人提供可靠的室内导航支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04797v1",
      "published_date": "2024-08-09 00:30:22 UTC",
      "updated_date": "2024-08-09 00:30:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:19:40.520149"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 83,
  "processed_papers_count": 83,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T14:20:09.282445"
}