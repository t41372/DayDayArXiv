{
  "date": "2024-12-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-22 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和大型语言模型 (LLM) 的创新应用，包括增强模型推理、医疗诊断和知识图谱等领域，其中令人印象深刻的文章有 LLM 在火灾模拟和 COVID-19 分析中的实用性探索，以及多模态 AI 代理的优化设计；知名学者如 Ansgar Scherp 等参与的语义网回顾也值得关注。\n\n下面，我们挑选并简要讨论几篇重要的、话题度高的论文，将相关主题归类讨论（如 LLM 相关、医疗应用等），其他次要论文（如一些纯优化算法或小众领域）将快速掠过，只列出标题而不深究。\n\n### LLM 和 AI 代理相关（重点优先）\n- **Better Think with Tables: Leveraging Tables to Enhance Large Language Model Comprehension**（中文：利用表格提升大型语言模型理解）  \n  这篇论文提出 “Thinking with Tables” 技术，使用表格组织信息辅助 LLM 处理复杂查询，实现了 40.29% 的性能提升，增强了模型的鲁棒性和泛化能力，尤其适用于多条件查询场景。\n\n- **A Multi-AI Agent System for Autonomous Optimization of Agentic AI Solutions via Iterative Refinement and LLM-Driven Feedback Loops**（中文：通过迭代优化和 LLM 反馈的多 AI 代理系统）  \n  作者 Kamer Ali Yuksel 和 Hassan Sawaf 设计了一个多代理框架，使用 LLM（如 Llama 3.2）实现自主优化，显著提高了 AI 系统的可扩展性和输出质量，案例研究显示其在动态环境中的实际应用潜力。\n\n- **LLM Agent for Fire Dynamics Simulations**（中文：LLM 代理用于火灾动力学模拟）  \n  这篇论文（NeurIPS 2024 研讨会）引入 FoamPilot 代理，利用 LLM 和检索增强生成（RAG）技术简化 FireFOAM 模拟，支持代码洞察和模拟评估，显著加速了火灾安全模拟工作流。\n\n- **SAIL: Sample-Centric In-Context Learning for Document Information Extraction**（中文：基于样本中心的上下文学习用于文档信息提取）  \n  论文提出 SAIL 方法，使用实体级文本和布局相似性提升 LLM 在视觉丰富文档中的提取精度，在 FUNSD 和 CORD 数据集上超越基线，适用于实际文档处理任务。\n\n- **GraphAgent: Agentic Graph Language Assistant**（中文：图代理语言助手）  \n  这篇论文开发了 GraphAgent 框架，包括生成器代理和任务规划代理，结合 LLM 和图语言模型处理图数据，实验显示其在预测和生成任务上的有效性，代码已开源。\n\n其他 LLM 相关论文如 **Analysis on LLMs Performance for Code Summarization**（中文：LLM 在代码摘要中的性能分析）和 **PromptDresser**（中文：通过生成提示提升虚拟试衣）等，仅快速提及：前者比较开源 LLM 在代码摘要上的表现，后者使用 LMM 生成详细提示提升图像生成质量。\n\n### 医疗和 COVID-19 应用\n- **COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations**（中文：YouTube 上 COVID-19 的数据分析）  \n  这篇论文分析 2023-2024 年 YouTube 视频，使用 NLP 技术（VADER 和 LDA）发现 49.32% 的描述为积极，并开发了基于 TF-IDF 的推荐系统，覆盖率达 69%，为疫情内容管理提供实用框架。\n\n- **SubstationAI: Multimodal Large Model-Based Approaches for Analyzing Substation Equipment Faults**（中文：基于多模态大模型的变电站设备故障分析）  \n  作者构建了 4 万条数据库，使用 GPT-4 生成报告，SubstationAI 模型在故障分析中优于 GPT-4，准确性高达 90%，为电力系统维护带来实际影响。\n\n- **VilBias: A Study of Bias Detection through Linguistic and Visual Cues**（中文：通过语言和视觉线索的偏见检测研究）  \n  论文引入 VLBias 框架，使用 LLM 和 VLM 检测新闻中的偏见，实验显示结合视觉线索可提高 3-5% 的准确率，数据集和代码公开，强调多模态在偏见分析中的作用。\n\n其他医疗论文如 **AI-Based Teat Shape and Skin Condition Prediction for Dairy Management**（中文：基于 AI 的奶牛乳头形状和皮肤状况预测）快速掠过：它使用计算机视觉模型预测奶牛健康，mAP 达 0.83，适用于畜牧业。\n\n### 其他领域（简要提及）\n- **Semantic Web: Past, Present, and Future**（中文：语义网：过去、现在和未来）  \n  作者 Ansgar Scherp 等回顾语义技术在知识图谱和机器学习中的应用，讨论安全性和行业影响，是一个全面的领域总结。\n\n- **KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**（中文：基于知识图谱增强的多代理 LLM 框架用于医疗诊断）  \n  这篇论文提出 KG4Diagnosis，使用知识图谱和 LLM 代理进行分层诊断，覆盖 362 种疾病，提升了诊断准确性。\n\n其他如 **DCC: Differentiable Cardinality Constraints for Partial Index Tracking**（中文：可微分基数约束用于部分指数跟踪）和 **Grams: Gradient Descent with Adaptive Momentum Scaling**（中文：自适应动量缩放的梯度下降）等优化算法，仅列出标题：前者解决了投资优化问题，后者提升了深度学习收敛速度，但不展开讨论。\n\n总之，今天的论文突出了 LLM 在实际应用中的潜力，如模拟和诊断领域，未来可能推动 AI 更广泛的落地。如果你对 LLM 增强或医疗 AI 感兴趣，这些文章值得一读！明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2412.17189v1",
      "title": "Better Think with Tables: Leveraging Tables to Enhance Large Language Model Comprehension",
      "title_zh": "翻译失败",
      "authors": [
        "Jio Oh",
        "Geon Heo",
        "Seungjun Oh",
        "Jindong Wang",
        "Xing Xie",
        "Steven Euijong Whang"
      ],
      "abstract": "Despite the recent advancement of Large Langauge Models (LLMs), they struggle\nwith complex queries often involving multiple conditions, common in real-world\nscenarios. We propose Thinking with Tables, a technique that assists LLMs to\nleverage tables for intermediate thinking aligning with human cognitive\nbehavior. By introducing a pre-instruction that triggers an LLM to organize\ninformation in tables, our approach achieves a 40.29\\% average relative\nperformance increase, higher robustness, and show generalizability to different\nrequests, conditions, or scenarios. We additionally show the influence of data\nstructuredness for the model by comparing results from four distinct\nstructuring levels that we introduce.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs) 在处理涉及多个条件的复杂查询时存在的困难，提出了一种名为Thinking with Tables的技术。该方法通过预指令引导LLMs将信息组织成表格形式，进行中间思考，以模拟人类认知行为。实验结果显示，该技术使LLMs的性能平均相对提升40.29%，并提高了鲁棒性和对不同请求、条件或场景的泛化能力。此外，论文比较了四种数据结构化水平，揭示了结构化程度对模型表现的影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17189v1",
      "published_date": "2024-12-22 23:31:03 UTC",
      "updated_date": "2024-12-22 23:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:20:40.380723"
    },
    {
      "arxiv_id": "2412.17188v1",
      "title": "Hierarchically Gated Experts for Efficient Online Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Luong",
        "Michael Thielscher"
      ],
      "abstract": "Continual Learning models aim to learn a set of tasks under the constraint\nthat the tasks arrive sequentially with no way to access data from previous\ntasks. The Online Continual Learning framework poses a further challenge where\nthe tasks are unknown and instead the data arrives as a single stream. Building\non existing work, we propose a method for identifying these underlying tasks:\nthe Gated Experts (GE) algorithm, where a dynamically growing set of experts\nallows for new knowledge to be acquired without catastrophic forgetting.\nFurthermore, we extend GE to Hierarchically Gated Experts (HGE), a method which\nis able to efficiently select the best expert for each data sample by\norganising the experts into a hierarchical structure. On standard Continual\nLearning benchmarks, GE and HGE are able to achieve results comparable with\ncurrent methods, with HGE doing so more efficiently.",
      "tldr_zh": "本文针对在线持续学习（Online Continual Learning），提出 Gated Experts (GE) 算法，该方法通过动态增长的专家集来识别底层任务，实现新知识获取的同时避免灾难性遗忘（catastrophic forgetting）。为了提高效率，作者进一步扩展为 Hierarchically Gated Experts (HGE)，通过将专家组织成层次结构，高效选择最佳专家处理每个数据样本。在标准持续学习基准测试中，GE 和 HGE 的性能与当前方法相当，而 HGE 表现出更高的效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17188v1",
      "published_date": "2024-12-22 23:27:20 UTC",
      "updated_date": "2024-12-22 23:27:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:22:53.032092"
    },
    {
      "arxiv_id": "2412.17180v1",
      "title": "COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Vanessa Su",
        "Nirmalya Thakur"
      ],
      "abstract": "This study presents a data-driven analysis of COVID-19 discourse on YouTube,\nexamining the sentiment, toxicity, and thematic patterns of video content\npublished between January 2023 and October 2024. The analysis involved applying\nadvanced natural language processing (NLP) techniques: sentiment analysis with\nVADER, toxicity detection with Detoxify, and topic modeling using Latent\nDirichlet Allocation (LDA). The sentiment analysis revealed that 49.32% of\nvideo descriptions were positive, 36.63% were neutral, and 14.05% were\nnegative, indicating a generally informative and supportive tone in\npandemic-related content. Toxicity analysis identified only 0.91% of content as\ntoxic, suggesting minimal exposure to toxic content. Topic modeling revealed\ntwo main themes, with 66.74% of the videos covering general health information\nand pandemic-related impacts and 33.26% focused on news and real-time updates,\nhighlighting the dual informational role of YouTube. A recommendation system\nwas also developed using TF-IDF vectorization and cosine similarity, refined by\nsentiment, toxicity, and topic filters to ensure relevant and context-aligned\nvideo recommendations. This system achieved 69% aggregate coverage, with\nmonthly coverage rates consistently above 85%, demonstrating robust performance\nand adaptability over time. Evaluation across recommendation sizes showed\ncoverage reaching 69% for five video recommendations and 79% for ten video\nrecommendations per video. In summary, this work presents a framework for\nunderstanding COVID-19 discourse on YouTube and a recommendation system that\nsupports user engagement while promoting responsible and relevant content\nrelated to COVID-19.",
      "tldr_zh": "本研究通过数据驱动分析，考察了2023年1月至2024年10月YouTube上COVID-19视频的内容情感、毒性水平和主题模式，使用NLP技术如VADER进行情感分析、Detoxify检测毒性，以及LDA进行主题建模。结果显示，49.32%的视频描述为正面、36.63%为中性、14.05%为负面，且仅0.91%的内容为毒性，主题主要涉及一般健康信息和新闻更新。研究还开发了基于TF-IDF向量化及余弦相似度的推荐系统，结合情感、毒性和主题过滤，实现了69%的总体覆盖率，并在不同推荐规模下表现出色，最终为理解YouTube疫情话语并推广负责任内容提供了一个框架。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17180v1",
      "published_date": "2024-12-22 22:43:36 UTC",
      "updated_date": "2024-12-22 22:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:21:04.989138"
    },
    {
      "arxiv_id": "2412.17175v1",
      "title": "DCC: Differentiable Cardinality Constraints for Partial Index Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Wooyeon Jo",
        "Hyunsouk Cho"
      ],
      "abstract": "Index tracking is a popular passive investment strategy aimed at optimizing\nportfolios, but fully replicating an index can lead to high transaction costs.\nTo address this, partial replication have been proposed. However, the\ncardinality constraint renders the problem non-convex, non-differentiable, and\noften NP-hard, leading to the use of heuristic or neural network-based methods,\nwhich can be non-interpretable or have NP-hard complexity. To overcome these\nlimitations, we propose a Differentiable Cardinality Constraint\n($\\textbf{DCC}$) for index tracking and introduce a floating-point\nprecision-aware method ($\\textbf{DCC}_{fpp}$) to address implementation issues.\nWe theoretically prove our methods calculate cardinality accurately and enforce\nactual cardinality with polynomial time complexity. We propose the range of the\nhyperparameter $a$ ensures that $\\textbf{DCC}_{fpp}$ has no error in real\nimplementations, based on theoretical proof and experiment. Our method applied\nto mathematical method outperforms baseline methods across various datasets,\ndemonstrating the effectiveness of the identified hyperparameter $a$.",
      "tldr_zh": "本研究针对部分指数跟踪（partial index tracking）策略中的基数约束（cardinality constraint）问题，提出了一种可微分基数约束方法（Differentiable Cardinality Constraints, DCC），以解决传统方法因非凸、非可微和NP-hard特性而导致的复杂性和不可解释性。DCC结合了DCC_{fpp}（一种浮点精度感知方法），通过理论证明确保基数计算准确且以多项式时间复杂度强制执行。研究还分析了超参数$a$的范围，通过证明和实验验证其在实际实现中无错误。实验结果显示，在多种数据集上应用DCC的数学方法优于基线方法，证明了该方法的有效性和超参数优化的实用性。",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures, AAAI 2025 (accepted, but not published)",
      "pdf_url": "http://arxiv.org/pdf/2412.17175v1",
      "published_date": "2024-12-22 22:05:56 UTC",
      "updated_date": "2024-12-22 22:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:21:16.875168"
    },
    {
      "arxiv_id": "2412.17165v1",
      "title": "Survey on Abstractive Text Summarization: Dataset, Models, and Metrics",
      "title_zh": "抽象式文本摘要的综述：数据集、模型和指标",
      "authors": [
        "Gospel Ozioma Nnadi",
        "Flavio Bertini"
      ],
      "abstract": "The advancements in deep learning, particularly the introduction of\ntransformers, have been pivotal in enhancing various natural language\nprocessing (NLP) tasks. These include text-to-text applications such as machine\ntranslation, text classification, and text summarization, as well as\ndata-to-text tasks like response generation and image-to-text tasks such as\ncaptioning. Transformer models are distinguished by their attention mechanisms,\npretraining on general knowledge, and fine-tuning for downstream tasks. This\nhas led to significant improvements, particularly in abstractive summarization,\nwhere sections of a source document are paraphrased to produce summaries that\nclosely resemble human expression.\n  The effectiveness of these models is assessed using diverse metrics,\nencompassing techniques like semantic overlap and factual correctness. This\nsurvey examines the state of the art in text summarization models, with a\nspecific focus on the abstractive summarization approach. It reviews various\ndatasets and evaluation metrics used to measure model performance.\nAdditionally, it includes the results of test cases using abstractive\nsummarization models to underscore the advantages and limitations of\ncontemporary transformer-based models. The source codes and the data are\navailable at https://github.com/gospelnnadi/Text-Summarization-SOTA-Experiment.",
      "tldr_zh": "这篇论文对抽象式文本摘要（Abstractive Text Summarization）的最新进展进行全面调查，涵盖了数据集、模型和评估指标。论文强调Transformer模型通过注意力机制、预训练和微调显著提升了摘要性能，并使用语义重叠和事实正确性等指标评估模型的有效性。最终，通过测试案例展示了这些模型的优势和局限性，并提供了源代码和数据资源（https://github.com/gospelnnadi/Text-Summarization-SOTA-Experiment）。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17165v1",
      "published_date": "2024-12-22 21:18:40 UTC",
      "updated_date": "2024-12-22 21:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:21:28.400098"
    },
    {
      "arxiv_id": "2412.17159v1",
      "title": "Semantic Web: Past, Present, and Future",
      "title_zh": "语义网：过去、现在和未来",
      "authors": [
        "Ansgar Scherp",
        "Gerd Groener",
        "Petr Škoda",
        "Katja Hose",
        "Maria-Esther Vidal"
      ],
      "abstract": "Ever since the vision was formulated, the Semantic Web has inspired many\ngenerations of innovations. Semantic technologies have been used to share vast\namounts of information on the Web, enhance them with semantics to give them\nmeaning, and enable inference and reasoning on them. Throughout the years,\nsemantic technologies, and in particular knowledge graphs, have been used in\nsearch engines, data integration, enterprise settings, and machine learning.\n  In this paper, we recap the classical concepts and foundations of the\nSemantic Web as well as modern and recent concepts and applications, building\nupon these foundations. The classical topics we cover include knowledge\nrepresentation, creating and validating knowledge on the Web, reasoning and\nlinking, and distributed querying. We enhance this classical view of the\nso-called ``Semantic Web Layer Cake'' with an update of recent concepts that\ninclude provenance, security and trust, as well as a discussion of practical\nimpacts from industry-led contributions. We conclude with an outlook on the\nfuture directions of the Semantic Web.",
      "tldr_zh": "这篇论文回顾了 Semantic Web 的过去、现在和未来，涵盖了其基础概念如 knowledge representation、创建和验证网络知识、推理、链接以及分布式 querying。作者更新了经典的 Semantic Web Layer Cake，加入了现代元素包括 provenance、security and trust，并讨论了这些技术在搜索引擎、数据整合、企业环境和机器学习中的实际应用。最终，论文展望了 Semantic Web 的未来方向，强调了行业贡献及其持续创新潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended Version 2024-12-13 of TGDK 2(1): 3:1-3:37 (2024) If you like\n  to contribute, please contact the first author and visit:\n  https://github.com/ascherp/semantic-web-primer Please cite this paper as, see\n  https://dblp.org/rec/journals/tgdk/ScherpG0HV24.html?view=bibtex",
      "pdf_url": "http://arxiv.org/pdf/2412.17159v1",
      "published_date": "2024-12-22 20:58:14 UTC",
      "updated_date": "2024-12-22 20:58:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:21:40.362614"
    },
    {
      "arxiv_id": "2501.14753v1",
      "title": "ABACUS: A FinOps Service for Cloud Cost Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Saurabh Deochake"
      ],
      "abstract": "In recent years, as more enterprises have moved their infrastructure to the\ncloud, significant challenges have emerged in achieving holistic cloud spend\nvisibility and cost optimization. FinOps practices provide a way for\nenterprises to achieve these business goals by optimizing cloud costs and\nbringing accountability to cloud spend. This paper presents ABACUS - Automated\nBudget Analysis and Cloud Usage Surveillance, a FinOps solution for optimizing\ncloud costs by setting budgets, enforcing those budgets through blocking new\ndeployments, and alerting appropriate teams if spending breaches a budget\nthreshold. ABACUS also leverages best practices like Infrastructure-as-Code to\nalert engineering teams of the expected cost of deployment before resources are\ndeployed in the cloud. Finally, future research directions are proposed to\nadvance the state of the art in this important field.",
      "tldr_zh": "该论文讨论了企业在云端基础设施迁移中面临的云支出可见性和成本优化挑战，并介绍了 FinOps 实践作为解决方案。作者提出 ABACUS 系统（Automated Budget Analysis and Cloud Usage Surveillance），通过设置预算、强制执行（如阻止新部署）和警报机制（如支出超阈值时通知团队）来优化云成本，同时利用 Infrastructure-as-Code 等最佳实践预估部署前成本。ABACUS 的创新为企业带来更高的支出责任和效率，并为 FinOps 领域提出未来研究方向。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI",
        "cs.SE",
        "K.6; C.2.4; D.2.9; D.2.11; I.2.11"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14753v1",
      "published_date": "2024-12-22 20:26:54 UTC",
      "updated_date": "2024-12-22 20:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:21:52.529783"
    },
    {
      "arxiv_id": "2412.17149v1",
      "title": "A Multi-AI Agent System for Autonomous Optimization of Agentic AI Solutions via Iterative Refinement and LLM-Driven Feedback Loops",
      "title_zh": "翻译失败",
      "authors": [
        "Kamer Ali Yuksel",
        "Hassan Sawaf"
      ],
      "abstract": "Agentic AI systems use specialized agents to handle tasks within complex\nworkflows, enabling automation and efficiency. However, optimizing these\nsystems often requires labor-intensive, manual adjustments to refine roles,\ntasks, and interactions. This paper introduces a framework for autonomously\noptimizing Agentic AI solutions across industries, such as NLP-driven\nenterprise applications. The system employs agents for Refinement, Execution,\nEvaluation, Modification, and Documentation, leveraging iterative feedback\nloops powered by an LLM (Llama 3.2-3B). The framework achieves optimal\nperformance without human input by autonomously generating and testing\nhypotheses to improve system configurations. This approach enhances scalability\nand adaptability, offering a robust solution for real-world applications in\ndynamic environments. Case studies across diverse domains illustrate the\ntransformative impact of this framework, showcasing significant improvements in\noutput quality, relevance, and actionability. All data for these case studies,\nincluding original and evolved agent codes, along with their outputs, are here:\nhttps://anonymous.4open.science/r/evolver-1D11/",
      "tldr_zh": "这篇论文提出了一种多 AI 代理系统，用于通过迭代优化和 LLM 驱动的反馈循环，实现 Agentic AI 解决方案的自主优化，适用于如 NLP 驱动的企业应用等领域。系统包括 Refinement、Execution、Evaluation、Modification 和 Documentation 代理，利用 LLM (Llama 3.2-3B) 进行自主生成和测试假设，从而无需人工干预优化系统配置。该框架提升了 Agentic AI 的可扩展性和适应性，案例研究显示在不同领域显著改善了输出质量、相关性和可操作性，所有数据可从提供的链接获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.MA",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17149v1",
      "published_date": "2024-12-22 20:08:04 UTC",
      "updated_date": "2024-12-22 20:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:22:04.841792"
    },
    {
      "arxiv_id": "2412.17146v1",
      "title": "LLM Agent for Fire Dynamics Simulations",
      "title_zh": "LLM 智能体用于火动力学模拟",
      "authors": [
        "Leidong Xu",
        "Danyal Mohaddes",
        "Yi Wang"
      ],
      "abstract": "Significant advances have been achieved in leveraging foundation models, such\nas large language models (LLMs), to accelerate complex scientific workflows. In\nthis work we introduce FoamPilot, a proof-of-concept LLM agent designed to\nenhance the usability of FireFOAM, a specialized solver for fire dynamics and\nfire suppression simulations built using OpenFOAM, a popular open-source\ntoolbox for computational fluid dynamics (CFD). FoamPilot provides three core\nfunctionalities: code insight, case configuration and simulation evaluation.\nCode insight is an alternative to traditional keyword searching leveraging\nretrieval-augmented generation (RAG) and aims to enable efficient navigation\nand summarization of the FireFOAM source code for developers and experienced\nusers. For case configuration, the agent interprets user requests in natural\nlanguage and aims to modify existing simulation setups accordingly to support\nintermediate users. FoamPilot's job execution functionality seeks to manage the\nsubmission and execution of simulations in high-performance computing (HPC)\nenvironments and provide preliminary analysis of simulation results to support\nless experienced users. Promising results were achieved for each functionality,\nparticularly for simple tasks, and opportunities were identified for\nsignificant further improvement for more complex tasks. The integration of\nthese functionalities into a single LLM agent is a step aimed at accelerating\nthe simulation workflow for engineers and scientists employing FireFOAM for\ncomplex simulations critical for improving fire safety.",
      "tldr_zh": "本文提出了一种名为 FoamPilot 的 LLM 代理，用于提升 FireFOAM 在火动力学和火灾抑制模拟中的可用性。FoamPilot 包括三个核心功能：利用检索增强生成 (RAG) 技术进行代码洞察以辅助导航和总结源代码；通过自然语言解释用户请求来修改模拟案例配置；以及管理高性能计算 (HPC) 环境下的模拟提交、执行和初步分析。实验结果表明，该代理在简单任务上取得了有前景的表现，但复杂任务仍有显著改进空间，最终旨在加速工程师和科学家的模拟工作流，提高火灾安全研究效率。",
      "categories": [
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 Foundation Models for Science Workshop (38th Conference\n  on Neural Information Processing Systems). 12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17146v1",
      "published_date": "2024-12-22 20:03:35 UTC",
      "updated_date": "2024-12-22 20:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:22:17.544394"
    },
    {
      "arxiv_id": "2412.17143v4",
      "title": "ASP-based Multi-shot Reasoning via DLV2 with Incremental Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Calimeri",
        "Giovambattista Ianni",
        "Francesco Pacenza",
        "Simona Perri",
        "Jessica Zangari"
      ],
      "abstract": "DLV2 is an AI tool for Knowledge Representation and Reasoning which supports\nAnswer Set Programming (ASP) - a logic-based declarative formalism,\nsuccessfully used in both academic and industrial applications. Given a logic\nprogram modelling a computational problem, an execution of DLV2 produces the\nso-called answer sets that correspond one-to-one to the solutions to the\nproblem at hand. The computational process of DLV2 relies on the typical Ground\n& Solve approach where the grounding step transforms the input program into a\nnew, equivalent ground program, and the subsequent solving step applies\npropositional algorithms to search for the answer sets. Recently, emerging\napplications in contexts such as stream reasoning and event processing created\na demand for multi-shot reasoning: here, the system is expected to be reactive\nwhile repeatedly executed over rapidly changing data. In this work, we present\na new incremental reasoner obtained from the evolution of DLV2 towards iterated\nreasoning. Rather than restarting the computation from scratch, the system\nremains alive across repeated shots, and it incrementally handles the internal\ngrounding process. At each shot, the system reuses previous computations for\nbuilding and maintaining a large, more general ground program, from which a\nsmaller yet equivalent portion is determined and used for computing answer\nsets. Notably, the incremental process is performed in a completely transparent\nfashion for the user. We describe the system, its usage, its applicability and\nperformance in some practically relevant domains. Under consideration in Theory\nand Practice of Logic Programming (TPLP).",
      "tldr_zh": "本论文介绍了DLV2工具的演进，开发了一种基于Answer Set Programming (ASP)的增量推理器，支持多-shot推理场景，如流式推理和事件处理。不同于传统的Ground & Solve方法，该系统通过增量grounding过程，重用之前的计算来构建并维护一个更大的通用ground程序，并在每个shot中提取等价的子程序以高效计算答案集。实验结果显示，该方法在实际领域表现出色，提高了计算效率，且对用户完全透明，目前正被考虑在Theory and Practice of Logic Programming (TPLP)上发表。",
      "categories": [
        "cs.AI",
        "68T30",
        "I.2.1; I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)",
      "pdf_url": "http://arxiv.org/pdf/2412.17143v4",
      "published_date": "2024-12-22 19:46:49 UTC",
      "updated_date": "2025-04-01 16:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:22:28.219552"
    },
    {
      "arxiv_id": "2412.17142v1",
      "title": "AI-Based Teat Shape and Skin Condition Prediction for Dairy Management",
      "title_zh": "翻译失败",
      "authors": [
        "Yuexing Hao",
        "Tiancheng Yuan",
        "Yuting Yang",
        "Aarushi Gupta",
        "Matthias Wieland",
        "Ken Birman",
        "Parminder S. Basran"
      ],
      "abstract": "Dairy owners spend significant effort to keep their animals healthy. There is\ngood reason to hope that technologies such as computer vision and artificial\nintelligence (AI) could reduce these costs, yet obstacles arise when adapting\nadvanced tools to farming environments. In this work, we adapt AI tools to\ndairy cow teat localization, teat shape, and teat skin condition\nclassifications. We also curate a data collection and analysis methodology for\na Machine Learning (ML) pipeline. The resulting teat shape prediction model\nachieves a mean Average Precision (mAP) of 0.783, and the teat skin condition\nmodel achieves a mean average precision of 0.828. Our work leverages existing\nML vision models to facilitate the individualized identification of teat health\nand skin conditions, applying AI to the dairy management industry.",
      "tldr_zh": "该研究针对乳品业健康管理成本问题，运用计算机视觉和 AI 工具，对奶牛乳头定位、形状和皮肤状况进行分类预测。研究者构建了数据收集和分析方法，用于 Machine Learning (ML) 管道，并利用现有 ML 视觉模型实现个性化识别。结果显示，乳头形状预测模型的 mean Average Precision (mAP) 为 0.783，皮肤状况模型的 mAP 为 0.828。这些成果为 AI 在乳品管理行业的应用提供了有效的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17142v1",
      "published_date": "2024-12-22 19:37:07 UTC",
      "updated_date": "2024-12-22 19:37:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:23:04.327300"
    },
    {
      "arxiv_id": "2412.17114v3",
      "title": "Decentralized Governance of Autonomous AI Agents",
      "title_zh": "自治 AI 代理的去中心化治理",
      "authors": [
        "Tomer Jordi Chaffer",
        "Charles von Goins II",
        "Bayo Okusanya",
        "Dontrail Cotlage",
        "Justin Goldston"
      ],
      "abstract": "Autonomous AI agents present transformative opportunities and significant\ngovernance challenges. Existing frameworks, such as the EU AI Act and the NIST\nAI Risk Management Framework, fall short of addressing the complexities of\nthese agents, which are capable of independent decision-making, learning, and\nadaptation. To bridge these gaps, we propose the ETHOS (Ethical Technology and\nHolistic Oversight System) framework, a decentralized governance (DeGov) model\nleveraging Web3 technologies, including blockchain, smart contracts, and\ndecentralized autonomous organizations (DAOs). ETHOS establishes a global\nregistry for AI agents, enabling dynamic risk classification, proportional\noversight, and automated compliance monitoring through tools like soulbound\ntokens and zero-knowledge proofs. Furthermore, the framework incorporates\ndecentralized justice systems for transparent dispute resolution and introduces\nAI specific legal entities to manage limited liability, supported by mandatory\ninsurance to ensure financial accountability and incentivize ethical design. By\nintegrating philosophical principles of rationality, ethical grounding, and\ngoal alignment, ETHOS aims to create a robust research agenda for promoting\ntrust, transparency, and participatory governance. This innovative framework\noffers a scalable and inclusive strategy for regulating AI agents, balancing\ninnovation with ethical responsibility to meet the demands of an AI-driven\nfuture.",
      "tldr_zh": "本论文探讨了自治 AI 代理带来的机遇与治理挑战，指出现有框架如 EU AI Act 和 NIST AI Risk Management Framework 无法有效应对其独立决策、学习和适应的复杂性。作者提出 ETHOS 框架，这是一种基于 Web3 技术的去中心化治理 (DeGov) 模型，利用 blockchain、智能合约和 decentralized autonomous organizations (DAOs) 建立全球 AI 代理注册系统，实现动态风险分类、自动化合规监控（如通过 soulbound tokens 和 zero-knowledge proofs），并引入 decentralized justice systems 和 AI 特定法律实体以确保透明争端解决和财务责任。ETHOS 通过整合理性、伦理原则和目标一致性，旨在推动一个可扩展的治理议程，促进信任、透明和参与式创新，平衡 AI 发展与伦理责任。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17114v3",
      "published_date": "2024-12-22 18:01:49 UTC",
      "updated_date": "2025-01-11 16:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:23:17.325294"
    },
    {
      "arxiv_id": "2412.17107v3",
      "title": "Grams: Gradient Descent with Adaptive Momentum Scaling",
      "title_zh": "Grams：带有自适应动量缩放的梯度下降",
      "authors": [
        "Yang Cao",
        "Xiaoyu Li",
        "Zhao Song"
      ],
      "abstract": "We introduce $\\mathbf{G}$radient Descent with $\\mathbf{A}$daptive\n$\\mathbf{M}$omentum $\\mathbf{S}$caling ($\\mathbf{Grams}$), a novel optimization\nalgorithm that decouples the direction and magnitude of parameter updates in\ndeep learning. Unlike traditional optimizers that directly integrate momentum\ninto updates, Grams separates the update direction, derived from current\ngradients, from momentum, which is used solely for adaptive magnitude scaling.\nThis approach enables Grams to achieve improved loss descent compared to\nstate-of-the-art cautious and momentum-based optimizers. We theoretically\ndemonstrate that Grams descents faster than other state-of-the-art optimizers\nand establish a global convergence guarantee for Grams. We also validate its\neffectiveness through extensive empirical evaluations. The results demonstrate\nGrams' superior performance, including faster convergence and better\ngeneralization, compared to widely-used optimizers such as Adam, Lion, and\ntheir cautious variants. Our results highlight Grams' potential as a\ntransformative approach for efficiently training and fine-tuning large language\nmodels. Code is available at https://github.com/Gunale0926/Grams.",
      "tldr_zh": "该论文提出了一种新优化算法Grams（Gradient Descent with Adaptive Momentum Scaling），它将参数更新的方向（基于当前梯度）和幅度（通过自适应动量缩放）分开处理，从而与传统优化器不同地避免直接整合动量。Grams通过这种机制实现了比现有优化器更快的损失下降，并理论上证明了其比Adam和Lion等方法收敛更快，同时具有全局收敛保证。实验结果显示，Grams在深度学习任务中表现出优越的性能，包括更快的收敛和更好的泛化，尤其适用于训练和微调大型语言模型。代码可在GitHub获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "SCOPE Workshop @ ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17107v3",
      "published_date": "2024-12-22 17:39:32 UTC",
      "updated_date": "2025-03-05 07:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:23:28.755436"
    },
    {
      "arxiv_id": "2412.17094v2",
      "title": "Analysis on LLMs Performance for Code Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Ahnaf Akib",
        "Md. Muktadir Mazumder",
        "Salman Ahsan"
      ],
      "abstract": "Code summarization aims to generate concise natural language descriptions for\nsource code. Deep learning has been used more and more recently in software\nengineering, particularly for tasks like code creation and summarization.\nSpecifically, it appears that the most current Large Language Models with\ncoding perform well on these tasks. Large Language Models (LLMs) have\nsignificantly advanced the field of code summarization, providing sophisticated\nmethods for generating concise and accurate summaries of source code. This\nstudy aims to perform a comparative analysis of several open-source LLMs,\nnamely LLaMA-3, Phi-3, Mistral, and Gemma. These models' performance is\nassessed using important metrics such as BLEU\\textsubscript{3.1} and\nROUGE\\textsubscript{3.2}.\n  Through this analysis, we seek to identify the strengths and weaknesses of\neach model, offering insights into their applicability and effectiveness in\ncode summarization tasks. Our findings contribute to the ongoing development\nand refinement of LLMs, supporting their integration into tools that enhance\nsoftware development and maintenance processes.",
      "tldr_zh": "本研究分析了大型语言模型（LLMs）在代码总结（code summarization）任务中的性能，旨在生成源代码的简洁自然语言描述。研究比较了开源模型如 LLaMA-3、Phi-3、Mistral 和 Gemma，使用关键指标 BLEU_{3.1} 和 ROUGE_{3.2} 评估这些模型的准确性和有效性。通过这一分析，论文识别了每个模型的优缺点，并为 LLMs 在软件开发和维护工具中的整合提供宝贵见解，促进其持续优化和发展。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17094v2",
      "published_date": "2024-12-22 17:09:34 UTC",
      "updated_date": "2025-01-24 08:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:23:39.915944"
    },
    {
      "arxiv_id": "2412.17092v1",
      "title": "SAIL: Sample-Centric In-Context Learning for Document Information Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyu Zhang",
        "Zhiyuan You",
        "Jize Wang",
        "Xinyi Le"
      ],
      "abstract": "Document Information Extraction (DIE) aims to extract structured information\nfrom Visually Rich Documents (VRDs). Previous full-training approaches have\ndemonstrated strong performance but may struggle with generalization to unseen\ndata. In contrast, training-free methods leverage powerful pre-trained models\nlike Large Language Models (LLMs) to address various downstream tasks with only\na few examples. Nonetheless, training-free methods for DIE encounter two\nprimary challenges: (1) understanding the complex relationship between layout\nand textual elements in VRDs, and (2) providing accurate guidance to\npre-trained models. To address these challenges, we propose Sample-centric\nIn-context Learning (SAIL) for DIE. SAIL introduces a fine-grained entity-level\ntextual similarity to facilitate in-depth text analysis by LLMs and\nincorporates layout similarity to enhance the analysis of layouts in VRDs.\nAdditionally, SAIL formulates a unified In-Context Learning (ICL) prompt\ntemplate for various sample-centric examples, enabling tailored prompts that\ndeliver precise guidance to pre-trained models for each sample. Extensive\nexperiments on FUNSD, CORD, and SROIE benchmarks with various base models\n(e.g., LLMs) indicate that our method outperforms training-free baselines, even\ncloser to the full-training methods. The results show the superiority and\ngeneralization of our method.",
      "tldr_zh": "本文提出 SAIL，一种基于样本中心的 In-Context Learning (ICL) 方法，用于 Document Information Extraction (DIE)，旨在从 Visually Rich Documents (VRDs) 中提取结构化信息，同时解决现有方法在布局文本关系理解和模型指导方面的挑战。SAIL 通过引入实体级文本相似性（entity-level textual similarity）和布局相似性（layout similarity），增强 Large Language Models (LLMs) 对复杂文档的分析，并采用统一的 ICL 提示模板为每个样本提供精确指导。实验结果显示，在 FUNSD、CORD 和 SROIE 基准测试中，SAIL 优于无训练基线方法，甚至接近全训练方法的性能，证明了其优越性和泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17092v1",
      "published_date": "2024-12-22 16:58:59 UTC",
      "updated_date": "2024-12-22 16:58:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:23:53.625233"
    },
    {
      "arxiv_id": "2412.17080v4",
      "title": "Aligning Graphical and Functional Causal Abstractions",
      "title_zh": "翻译失败",
      "authors": [
        "Willem Schooltink",
        "Fabio Massimo Zennaro"
      ],
      "abstract": "Causal abstractions allow us to relate causal models on different levels of\ngranularity. To ensure that the models agree on cause and effect, frameworks\nfor causal abstractions define notions of consistency. Two distinct methods for\ncausal abstraction are common in the literature: (i) graphical abstractions,\nsuch as Cluster DAGs, which relate models on a structural level, and (ii)\nfunctional abstractions, like $\\alpha$-abstractions, which relate models by\nmaps between variables and their ranges. In this paper we will align the\nnotions of graphical and functional consistency and show an equivalence between\nthe class of Cluster DAGs, consistent $\\alpha$-abstractions with the range of\nabstracted variables mapped bijectively, and constructive $\\tau$-abstractions.\nFurthermore, we extend this alignment and the expressivity of graphical\nabstractions by introducing Partial Cluster DAGs. Our results provide a\nrigorous bridge between the functional and graphical frameworks and allow for\nadoption and transfer of results between them.",
      "tldr_zh": "本论文探讨了因果抽象（causal abstractions）的统一，专注于将图形抽象（如 Cluster DAGs）和功能抽象（如 α-abstractions）进行对齐。研究者证明了在特定条件下，Cluster DAGs 等价于一致的 α-abstractions（抽象变量范围为双射映射）和 constructive τ-abstractions，从而建立了这两个框架之间的严谨等价关系。同时，论文引入了 Partial Cluster DAGs 来扩展图形抽象的表达能力。总体而言，这些结果为功能和图形框架提供了桥梁，便于结果的转移和应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17080v4",
      "published_date": "2024-12-22 16:11:25 UTC",
      "updated_date": "2025-03-14 10:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:24:04.355614"
    },
    {
      "arxiv_id": "2412.17077v1",
      "title": "SubstationAI: Multimodal Large Model-Based Approaches for Analyzing Substation Equipment Faults",
      "title_zh": "翻译失败",
      "authors": [
        "Jinzhi Wang",
        "Qinfeng Song",
        "Lidong Qian",
        "Haozhou Li",
        "Qinke Peng",
        "Jiangbo Zhang"
      ],
      "abstract": "The reliability of substation equipment is crucial to the stability of power\nsystems, but traditional fault analysis methods heavily rely on manual\nexpertise, limiting their effectiveness in handling complex and large-scale\ndata. This paper proposes a substation equipment fault analysis method based on\na multimodal large language model (MLLM). We developed a database containing\n40,000 entries, including images, defect labels, and analysis reports, and used\nan image-to-video generation model for data augmentation. Detailed fault\nanalysis reports were generated using GPT-4. Based on this database, we\ndeveloped SubstationAI, the first model dedicated to substation fault analysis,\nand designed a fault diagnosis knowledge base along with knowledge enhancement\nmethods. Experimental results show that SubstationAI significantly outperforms\nexisting models, such as GPT-4, across various evaluation metrics,\ndemonstrating higher accuracy and practicality in fault cause analysis, repair\nsuggestions, and preventive measures, providing a more advanced solution for\nsubstation equipment fault analysis.",
      "tldr_zh": "这篇论文针对变电站设备故障分析的挑战，提出了一种基于 Multimodal Large Language Model (MLLM) 的方法，以克服传统手动专家依赖的局限性。研究团队构建了一个包含 40,000 条目（包括图像、缺陷标签和分析报告）的数据库，并通过图像到视频生成模型进行数据增强，使用 GPT-4 生成详细报告，同时开发了 SubstationAI 模型和故障诊断知识库以提升知识增强能力。实验结果显示，SubstationAI 在各种评估指标上显著优于现有模型如 GPT-4，在故障原因分析、修复建议和预防措施方面表现出更高的准确性和实用性，为变电站设备故障分析提供了更先进的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17077v1",
      "published_date": "2024-12-22 15:59:07 UTC",
      "updated_date": "2024-12-22 15:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:24:16.948883"
    },
    {
      "arxiv_id": "2412.17069v1",
      "title": "Optimizing Data Curation through Spectral Analysis and Joint Batch Selection (SALN)",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadreza Sharifi"
      ],
      "abstract": "In modern deep learning models, long training times and large datasets\npresent significant challenges to both efficiency and scalability. Effective\ndata curation and sample selection are crucial for optimizing the training\nprocess of deep neural networks. This paper introduces SALN, a method designed\nto prioritize and select samples within each batch rather than from the entire\ndataset. By utilizing jointly selected batches, SALN enhances training\nefficiency compared to independent batch selection. The proposed method applies\na spectral analysis-based heuristic to identify the most informative data\npoints within each batch, improving both training speed and accuracy. The SALN\nalgorithm significantly reduces training time and enhances accuracy when\ncompared to traditional batch prioritization or standard training procedures.\nIt demonstrates up to an 8x reduction in training time and up to a 5\\% increase\nin accuracy over standard training methods. Moreover, SALN achieves better\nperformance and shorter training times compared to Google's JEST method\ndeveloped by DeepMind.",
      "tldr_zh": "本论文提出 SALN 方法，通过 spectral analysis 基于启发式和联合批次选择，优化深度学习模型的数据整理和样本优先级选择，从而提高训练效率。SALN 专注于每个批次内识别最具信息性的数据点，而不是整个数据集，这显著提升了训练速度和准确性。与传统方法相比，该算法可将训练时间减少高达 8 倍，并提高准确性高达 5%。此外，SALN 在性能和训练时间上优于 Google's JEST 方法，为大规模深度学习训练提供了更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper was presented at Machine Learning Knowledge Discovery\n  (MLKD2024) conference at Amirkabir University of Technology",
      "pdf_url": "http://arxiv.org/pdf/2412.17069v1",
      "published_date": "2024-12-22 15:38:36 UTC",
      "updated_date": "2024-12-22 15:38:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:24:28.577107"
    },
    {
      "arxiv_id": "2412.17053v1",
      "title": "DR-Encoder: Encode Low-rank Gradients with Random Prior for Large Language Models Differentially Privately",
      "title_zh": "翻译失败",
      "authors": [
        "Huiwen Wu",
        "Deyi Zhang",
        "Xiaohan Li",
        "Xiaogang Xu",
        "Jiafei Wu",
        "Zhe Liu"
      ],
      "abstract": "The emergence of the Large Language Model (LLM) has shown their superiority\nin a wide range of disciplines, including language understanding and\ntranslation, relational logic reasoning, and even partial differential\nequations solving. The transformer is the pervasive backbone architecture for\nthe foundation model construction. It is vital to research how to adjust the\nTransformer architecture to achieve an end-to-end privacy guarantee in LLM\nfine-tuning. In this paper, we investigate three potential information leakage\nduring a federated fine-tuning procedure for LLM (FedLLM). Based on the\npotential information leakage, we provide an end-to-end privacy guarantee\nsolution for FedLLM by inserting two-stage randomness. The first stage is to\ntrain a gradient auto-encoder with a Gaussian random prior based on the\nstatistical information of the gradients generated by local clients. The second\nstage is to fine-tune the overall LLM with a differential privacy guarantee by\nadopting appropriate Gaussian noises. We show the efficiency and accuracy gains\nof our proposed method with several foundation models and two popular\nevaluation benchmarks. Furthermore, we present a comprehensive privacy analysis\nwith Gaussian Differential Privacy (GDP) and Renyi Differential Privacy (RDP).",
      "tldr_zh": "这篇论文提出DR-Encoder方法，通过编码低秩梯度并结合随机先验，实现大型语言模型(LLM)在联邦微调(FedLLM)过程中的端到端差分隐私保护，以解决潜在的信息泄露风险。方法包括两阶段随机性：第一阶段基于本地客户端梯度统计信息训练一个高斯随机先验的梯度自动编码器；第二阶段通过添加适当的高斯噪声对整体LLM进行微调。实验结果显示，该方法在多个基础模型和流行基准上显著提高了效率和准确性，并提供了Gaussian Differential Privacy(GDP)和Renyi Differential Privacy(RDP)的全面隐私分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17053v1",
      "published_date": "2024-12-22 15:06:09 UTC",
      "updated_date": "2024-12-22 15:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:24:41.268476"
    },
    {
      "arxiv_id": "2412.17052v3",
      "title": "VilBias: A Study of Bias Detection through Linguistic and Visual Cues , presenting Annotation Strategies, Evaluation, and Key Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Shaina Raza",
        "Caesar Saleh",
        "Emrul Hasan",
        "Franklin Ogidi",
        "Maximus Powers",
        "Veronica Chatrath",
        "Marcelo Lotif",
        "Roya Javadi",
        "Anam Zahid",
        "Vahid Reza Khazaie"
      ],
      "abstract": "The integration of Large Language Models (LLMs) and Vision-Language Models\n(VLMs) opens new avenues for addressing complex challenges in multimodal\ncontent analysis, particularly in biased news detection. This study introduces\nVLBias, a framework that leverages state-of-the-art LLMs and VLMs to detect\nlinguistic and visual biases in news content. We present a multimodal dataset\ncomprising textual content and corresponding images from diverse news sources.\nWe propose a hybrid annotation framework that combines LLM-based annotations\nwith human review to ensure high-quality labeling while reducing costs and\nenhancing scalability. Our evaluation compares the performance of\nstate-of-the-art SLMs and LLMs for both modalities (text and images) and the\nresults reveal that while SLMs are computationally efficient, LLMs demonstrate\nsuperior accuracy in identifying subtle framing and text-visual\ninconsistencies. Furthermore, empirical analysis shows that incorporating\nvisual cues alongside textual data improves bias detection accuracy by 3 to 5%.\nThis study provides a comprehensive exploration of LLMs, SLMs, and VLMs as\ntools for detecting multimodal biases in news content and highlights their\nrespective strengths, limitations, and potential for future applications",
      "tldr_zh": "这篇论文介绍了 VilBias 框架，利用 LLMs 和 VLMs 来检测新闻内容中的语言和视觉偏差，并构建了一个多模态数据集，包括文本和图像。研究提出了一种混合标注框架，结合 LLM 标注与人工审查，以提升标注质量、降低成本并提高可扩展性。评估结果显示，LLMs 在识别微妙框架偏差和文本-视觉不一致方面比 SLMs 更准确，且整合视觉线索可将偏差检测准确率提升 3-5%。总体上，该研究探讨了 LLMs、SLMs 和 VLMs 在多模态偏差检测中的优势、局限性及其未来应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2412.17052v3",
      "published_date": "2024-12-22 15:05:30 UTC",
      "updated_date": "2025-02-18 22:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:24:52.957286"
    },
    {
      "arxiv_id": "2412.17041v2",
      "title": "An OpenMind for 3D medical vision self-supervised learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tassilo Wald",
        "Constantin Ulrich",
        "Jonathan Suprijadi",
        "Sebastian Ziegler",
        "Michal Nohel",
        "Robin Peretzke",
        "Gregor Köhler",
        "Klaus H. Maier-Hein"
      ],
      "abstract": "The field of self-supervised learning (SSL) for 3D medical images lacks\nconsistency and standardization. While many methods have been developed, it is\nimpossible to identify the current state-of-the-art, due to i) varying and\nsmall pretraining datasets, ii) varying architectures, and iii) being evaluated\non differing downstream datasets. In this paper, we bring clarity to this field\nand lay the foundation for further method advancements through three key\ncontributions: We a) publish the largest publicly available pre-training\ndataset comprising 114k 3D brain MRI volumes, enabling all practitioners to\npre-train on a large-scale dataset. We b) benchmark existing 3D self-supervised\nlearning methods on this dataset for a state-of-the-art CNN and Transformer\narchitecture, clarifying the state of 3D SSL pre-training. Among many findings,\nwe show that pre-trained methods can exceed a strong from-scratch nnU-Net\nResEnc-L baseline. Lastly, we c) publish the code of our pre-training and\nfine-tuning frameworks and provide the pre-trained models created during the\nbenchmarking process to facilitate rapid adoption and reproduction.",
      "tldr_zh": "该论文指出了3D医疗图像自监督学习(SSL)领域存在的标准化问题，包括预训练数据集的差异、架构多样性和下游评估数据集的不一致，从而难以确定当前最先进方法。研究贡献包括发布最大的公开预训练数据集，包含11.4k 3D脑MRI体积，以支持大规模预训练；对现有3D SSL方法进行基准测试(CNN和Transformer架构)，发现预训练模型可超过从零开始的nnU-Net ResEnc-L基准；并公开预训练和微调框架的代码及模型，促进快速采用和再现。总体上，这为3D医疗视觉SSL的标准化和方法改进奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Pre-Print; Dataset, Benchmark and Codebase available through\n  https://github.com/MIC-DKFZ/nnssl",
      "pdf_url": "http://arxiv.org/pdf/2412.17041v2",
      "published_date": "2024-12-22 14:38:28 UTC",
      "updated_date": "2025-04-18 13:14:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:25:05.002805"
    },
    {
      "arxiv_id": "2412.17038v3",
      "title": "ErasableMask: A Robust and Erasable Privacy Protection Scheme against Black-box Face Recognition Models",
      "title_zh": "ErasableMask：一种针对",
      "authors": [
        "Sipeng Shen",
        "Yunming Zhang",
        "Dengpan Ye",
        "Xiuwen Shi",
        "Long Tang",
        "Haoran Duan",
        "Jiacheng Deng",
        "Ziyi Liu"
      ],
      "abstract": "While face recognition (FR) models have brought remarkable convenience in\nface verification and identification, they also pose substantial privacy risks\nto the public. Existing facial privacy protection schemes usually adopt\nadversarial examples to disrupt face verification of FR models. However, these\nschemes often suffer from weak transferability against black-box FR models and\npermanently damage the identifiable information that cannot fulfill the\nrequirements of authorized operations such as forensics and authentication. To\naddress these limitations, we propose ErasableMask, a robust and erasable\nprivacy protection scheme against black-box FR models. Specifically, via\nrethinking the inherent relationship between surrogate FR models, ErasableMask\nintroduces a novel meta-auxiliary attack, which boosts black-box\ntransferability by learning more general features in a stable and balancing\noptimization strategy. It also offers a perturbation erasion mechanism that\nsupports the erasion of semantic perturbations in protected face without\ndegrading image quality. To further improve performance, ErasableMask employs a\ncurriculum learning strategy to mitigate optimization conflicts between\nadversarial attack and perturbation erasion. Extensive experiments on the\nCelebA-HQ and FFHQ datasets demonstrate that ErasableMask achieves the\nstate-of-the-art performance in transferability, achieving over 72% confidence\non average in commercial FR systems. Moreover, ErasableMask also exhibits\noutstanding perturbation erasion performance, achieving over 90% erasion\nsuccess rate.",
      "tldr_zh": "该研究提出 ErasableMask，一种针对 black-box face recognition (FR) 模型的鲁棒且可擦除的隐私保护方案，以解决现有 adversarial examples 方法的弱 transferability 和永久损坏可识别信息的问题。ErasableMask 采用 meta-auxiliary attack 技术，通过稳定优化策略学习更通用的特征，并引入 perturbation erasion 机制来擦除语义扰动，同时利用 curriculum learning 策略缓解攻击与擦除之间的优化冲突。实验在 CelebA-HQ 和 FFHQ 数据集上表明，该方案在黑盒 FR 系统上实现 state-of-the-art 转移性，平均置信度超过 72%，并获得超过 90% 的擦除成功率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17038v3",
      "published_date": "2024-12-22 14:30:26 UTC",
      "updated_date": "2024-12-29 19:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:25:17.437793"
    },
    {
      "arxiv_id": "2412.17031v1",
      "title": "A Reality Check on Context Utilisation for Retrieval-Augmented Generation",
      "title_zh": "对检索增强生成中上下文利用的现实检查",
      "authors": [
        "Lovisa Hagström",
        "Sara Vera Marjanović",
        "Haeun Yu",
        "Arnav Arora",
        "Christina Lioma",
        "Maria Maistro",
        "Pepa Atanasova",
        "Isabelle Augenstein"
      ],
      "abstract": "Retrieval-augmented generation (RAG) helps address the limitations of the\nparametric knowledge embedded within a language model (LM). However,\ninvestigations of how LMs utilise retrieved information of varying complexity\nin real-world scenarios have been limited to synthetic contexts. We introduce\nDRUID (Dataset of Retrieved Unreliable, Insufficient and\nDifficult-to-understand contexts) with real-world queries and contexts manually\nannotated for stance. The dataset is based on the prototypical task of\nautomated claim verification, for which automated retrieval of real-world\nevidence is crucial. We compare DRUID to synthetic datasets (CounterFact,\nConflictQA) and find that artificial datasets often fail to represent the\ncomplex and diverse real-world context settings. We show that synthetic\ndatasets exaggerate context characteristics rare in real retrieved data, which\nleads to inflated context utilisation results, as measured by our novel ACU\nscore. Moreover, while previous work has mainly focused on singleton context\ncharacteristics to explain context utilisation, correlations between singleton\ncontext properties and ACU on DRUID are surprisingly small compared to other\nproperties related to context source. Overall, our work underscores the need\nfor real-world aligned context utilisation studies to represent and improve\nperformance in real-world RAG settings.",
      "tldr_zh": "本文评估了检索增强生成(RAG)中上下文利用的真实性，引入了DRUID数据集，该数据集基于真实查询和手动标注的上下文，针对自动声明验证任务。相比合成数据集(CounterFact, ConflictQA)，DRUID揭示了这些数据集夸大真实世界中罕见上下文特征，导致ACU分数被高估。研究发现，上下文来源相关的属性比单一特性更显著影响利用效果，并强调需要更多与真实场景对齐的研究来提升RAG的实际性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "43 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17031v1",
      "published_date": "2024-12-22 14:16:38 UTC",
      "updated_date": "2024-12-22 14:16:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:25:28.496646"
    },
    {
      "arxiv_id": "2412.17029v1",
      "title": "GraphAgent: Agentic Graph Language Assistant",
      "title_zh": "GraphAgent：智能体图语言助手",
      "authors": [
        "Yuhao Yang",
        "Jiabin Tang",
        "Lianghao Xia",
        "Xingchen Zou",
        "Yuxuan Liang",
        "Chao Huang"
      ],
      "abstract": "Real-world data is represented in both structured (e.g., graph connections)\nand unstructured (e.g., textual, visual information) formats, encompassing\ncomplex relationships that include explicit links (such as social connections\nand user behaviors) and implicit interdependencies among semantic entities,\noften illustrated through knowledge graphs. In this work, we propose\nGraphAgent, an automated agent pipeline that addresses both explicit graph\ndependencies and implicit graph-enhanced semantic inter-dependencies, aligning\nwith practical data scenarios for predictive tasks (e.g., node classification)\nand generative tasks (e.g., text generation). GraphAgent comprises three key\ncomponents: (i) a Graph Generator Agent that builds knowledge graphs to reflect\ncomplex semantic dependencies; (ii) a Task Planning Agent that interprets\ndiverse user queries and formulates corresponding tasks through agentic\nself-planning; and (iii) a Task Execution Agent that efficiently executes\nplanned tasks while automating tool matching and invocation in response to user\nqueries. These agents collaborate seamlessly, integrating language models with\ngraph language models to uncover intricate relational information and data\nsemantic dependencies. Through extensive experiments on various graph-related\npredictive and text generative tasks on diverse datasets, we demonstrate the\neffectiveness of our GraphAgent across various settings. We have made our\nproposed GraphAgent open-source at: https://github.com/HKUDS/GraphAgent.",
      "tldr_zh": "本研究提出GraphAgent，一种基于代理的图语言助手框架，用于处理真实世界数据中显式（如图连接）和隐式（如语义实体间依赖）的复杂关系。该框架包括三个关键组件：Graph Generator Agent构建知识图以反映语义依赖、Task Planning Agent解释用户查询并制定任务计划，以及Task Execution Agent执行任务并自动化工具匹配。通过整合语言模型和graph language models，这些代理协同工作，提升了预测任务（如节点分类）和生成任务（如文本生成）的性能。实验在多种数据集上验证了GraphAgent的有效性，并已开源代码于https://github.com/HKUDS/GraphAgent。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17029v1",
      "published_date": "2024-12-22 14:13:32 UTC",
      "updated_date": "2024-12-22 14:13:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:25:40.168040"
    },
    {
      "arxiv_id": "2412.17018v1",
      "title": "GAS: Generative Auto-bidding with Post-training Search",
      "title_zh": "翻译失败",
      "authors": [
        "Yewen Li",
        "Shuai Mao",
        "Jingtong Gao",
        "Nan Jiang",
        "Yunjian Xu",
        "Qingpeng Cai",
        "Fei Pan",
        "Peng Jiang",
        "Bo An"
      ],
      "abstract": "Auto-bidding is essential in facilitating online advertising by automatically\nplacing bids on behalf of advertisers. Generative auto-bidding, which generates\nbids based on an adjustable condition using models like transformers and\ndiffusers, has recently emerged as a new trend due to its potential to learn\noptimal strategies directly from data and adjust flexibly to preferences.\nHowever, generative models suffer from low-quality data leading to a mismatch\nbetween condition, return to go, and true action value, especially in long\nsequential decision-making. Besides, the majority preference in the dataset may\nhinder models' generalization ability on minority advertisers' preferences.\nWhile it is possible to collect high-quality data and retrain multiple models\nfor different preferences, the high cost makes it unaffordable, hindering the\nadvancement of auto-bidding into the era of large foundation models. To address\nthis, we propose a flexible and practical Generative Auto-bidding scheme using\npost-training Search, termed GAS, to refine a base policy model's output and\nadapt to various preferences. We use weak-to-strong search alignment by\ntraining small critics for different preferences and an MCTS-inspired search to\nrefine the model's output. Specifically, a novel voting mechanism with\ntransformer-based critics trained with policy indications could enhance search\nalignment performance. Additionally, utilizing the search, we provide a\nfine-tuning method for high-frequency preference scenarios considering\ncomputational efficiency. Extensive experiments conducted on the real-world\ndataset and online A/B test on the Kuaishou advertising platform demonstrate\nthe effectiveness of GAS, achieving significant improvements, e.g., 1.554%\nincrement of target cost.",
      "tldr_zh": "该研究针对在线广告中的生成式自动竞价（Generative Auto-bidding）问题，提出了一种灵活的 GAS 框架，利用后训练搜索（post-training Search）来精炼基础策略模型的输出，并适应不同广告商偏好。通过训练小型批评者（small critics）和引入 MCTS-inspired search 以及新型投票机制，GAS 有效缓解了低质量数据导致的条件与行动价值不匹配问题，同时提升了模型的泛化能力。实验在真实数据集和 Kuaishou 广告平台的在线 A/B 测试中验证了其有效性，实现了目标成本的 1.554% 显著提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17018v1",
      "published_date": "2024-12-22 13:47:46 UTC",
      "updated_date": "2024-12-22 13:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:25:52.763128"
    },
    {
      "arxiv_id": "2412.17008v1",
      "title": "Data value estimation on private gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Zhou",
        "Xinyi Xu",
        "Daniela Rus",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "For gradient-based machine learning (ML) methods commonly adopted in practice\nsuch as stochastic gradient descent, the de facto differential privacy (DP)\ntechnique is perturbing the gradients with random Gaussian noise. Data\nvaluation attributes the ML performance to the training data and is widely used\nin privacy-aware applications that require enforcing DP such as data pricing,\ncollaborative ML, and federated learning (FL). Can existing data valuation\nmethods still be used when DP is enforced via gradient perturbations? We show\nthat the answer is no with the default approach of injecting i.i.d.~random\nnoise to the gradients because the estimation uncertainty of the data value\nestimation paradoxically linearly scales with more estimation budget, producing\nestimates almost like random guesses. To address this issue, we propose to\ninstead inject carefully correlated noise to provably remove the linear scaling\nof estimation uncertainty w.r.t.~the budget. We also empirically demonstrate\nthat our method gives better data value estimates on various ML tasks and is\napplicable to use cases including dataset valuation and~FL.",
      "tldr_zh": "这篇论文探讨了在差分隐私(DP)强制下进行数据估值的问题，指出现有方法通过向梯度添加 i.i.d. 随机噪声会导致估计不确定性随预算线性增加，从而使估值几乎等同于随机猜测。作者提出了一种创新方法，即注入 carefully correlated noise，以证明性地消除这一线性增长效应。实验结果显示，该方法在各种机器学习任务上显著提升了数据估值准确性，并适用于数据集估值和联邦学习(FL)等实际场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17008v1",
      "published_date": "2024-12-22 13:15:51 UTC",
      "updated_date": "2024-12-22 13:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:26:26.185974"
    },
    {
      "arxiv_id": "2412.17001v1",
      "title": "Solving Nonlinear Energy Supply and Demand System Using Physics-Informed Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Van Truong Vo",
        "Samad Noeiaghdam",
        "Denis Sidorov",
        "Aliona Dreglea",
        "Liguo Wang"
      ],
      "abstract": "Nonlinear differential equations and systems play a crucial role in modeling\nsystems where time-dependent factors exhibit nonlinear characteristics. Due to\ntheir nonlinear nature, solving such systems often presents significant\ndifficulties and challenges. In this study, we propose a method utilizing\nPhysics-Informed Neural Networks (PINNs) to solve the nonlinear energy\nsupply-demand (ESD) system. We design a neural network with four outputs, where\neach output approximates a function that corresponds to one of the unknown\nfunctions in the nonlinear system of differential equations describing the\nfour-dimensional ESD problem. The neural network model is then trained and the\nparameters are identified, optimized to achieve a more accurate solution. The\nsolutions obtained from the neural network for this problem are equivalent when\nwe compare and evaluate them against the Runge-Kutta numerical method of order\n4/5 (RK45). However, the method utilizing neural networks is considered a\nmodern and promising approach, as it effectively exploits the superior\ncomputational power of advanced computer systems, especially in solving complex\nproblems. Another advantage is that the neural network model, after being\ntrained, can solve the nonlinear system of differential equations across a\ncontinuous domain. In other words, neural networks are not only trained to\napproximate the solution functions for the nonlinear ESD system but can also\nrepresent the complex dynamic relationships between the system's components.\nHowever, this approach requires significant time and computational power due to\nthe need for model training.",
      "tldr_zh": "本文提出使用 Physics-Informed Neural Networks (PINNs) 来解决非线性能量供应需求 (ESD) 系统，该方法通过设计一个四输出神经网络来逼近系统中四个未知函数，并通过训练优化参数以获得准确解决方案。相比传统 Runge-Kutta 4/5 (RK45) 数值方法，PINNs 的结果相当准确，但能更好地利用高级计算资源处理复杂问题，并在连续域上求解非线性微分方程。PINNs 还能够表示系统组件之间的复杂动态关系，提供更灵活的应用潜力。尽管如此，该方法需要大量时间和计算资源进行训练。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "34A34 68T07",
        "G.1.7"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Computation J",
      "pdf_url": "http://arxiv.org/pdf/2412.17001v1",
      "published_date": "2024-12-22 12:37:59 UTC",
      "updated_date": "2024-12-22 12:37:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:28:17.319665"
    },
    {
      "arxiv_id": "2412.16984v1",
      "title": "LLM-Powered User Simulator for Recommender System",
      "title_zh": "基于 LLM 的用户模拟器用于推荐系统",
      "authors": [
        "Zijian Zhang",
        "Shuchang Liu",
        "Ziru Liu",
        "Rui Zhong",
        "Qingpeng Cai",
        "Xiangyu Zhao",
        "Chunxu Zhang",
        "Qidong Liu",
        "Peng Jiang"
      ],
      "abstract": "User simulators can rapidly generate a large volume of timely user behavior\ndata, providing a testing platform for reinforcement learning-based recommender\nsystems, thus accelerating their iteration and optimization. However, prevalent\nuser simulators generally suffer from significant limitations, including the\nopacity of user preference modeling and the incapability of evaluating\nsimulation accuracy. In this paper, we introduce an LLM-powered user simulator\nto simulate user engagement with items in an explicit manner, thereby enhancing\nthe efficiency and effectiveness of reinforcement learning-based recommender\nsystems training. Specifically, we identify the explicit logic of user\npreferences, leverage LLMs to analyze item characteristics and distill user\nsentiments, and design a logical model to imitate real human engagement. By\nintegrating a statistical model, we further enhance the reliability of the\nsimulation, proposing an ensemble model that synergizes logical and statistical\ninsights for user interaction simulations. Capitalizing on the extensive\nknowledge and semantic generation capabilities of LLMs, our user simulator\nfaithfully emulates user behaviors and preferences, yielding high-fidelity\ntraining data that enrich the training of recommendation algorithms. We\nestablish quantifying and qualifying experiments on five datasets to validate\nthe simulator's effectiveness and stability across various recommendation\nscenarios.",
      "tldr_zh": "该论文提出了一种基于LLM（Large Language Models）的用户模拟器，用于生成高质量用户行为数据，以加速强化学习-based recommender systems的训练和优化。模拟器通过识别用户偏好的显式逻辑，利用LLM分析物品特征和用户情感，并设计逻辑模型与统计模型集成，形成一个ensemble model来模仿真实用户互动，从而提升模拟的透明度和准确性。实验在五个数据集上进行定量和定性验证，证明了该模拟器在各种推荐场景中的有效性和稳定性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16984v1",
      "published_date": "2024-12-22 12:00:04 UTC",
      "updated_date": "2024-12-22 12:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:28:06.068236"
    },
    {
      "arxiv_id": "2412.16978v1",
      "title": "PromptDresser: Improving the Quality and Controllability of Virtual Try-On via Generative Textual Prompt and Prompt-aware Mask",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongho Kim",
        "Hoiyeong Jin",
        "Sunghyun Park",
        "Jaegul Choo"
      ],
      "abstract": "Recent virtual try-on approaches have advanced by fine-tuning the pre-trained\ntext-to-image diffusion models to leverage their powerful generative ability.\nHowever, the use of text prompts in virtual try-on is still underexplored. This\npaper tackles a text-editable virtual try-on task that changes the clothing\nitem based on the provided clothing image while editing the wearing style\n(e.g., tucking style, fit) according to the text descriptions. In the\ntext-editable virtual try-on, three key aspects exist: (i) designing rich text\ndescriptions for paired person-clothing data to train the model, (ii)\naddressing the conflicts where textual information of the existing person's\nclothing interferes the generation of the new clothing, and (iii) adaptively\nadjust the inpainting mask aligned with the text descriptions, ensuring proper\nediting areas while preserving the original person's appearance irrelevant to\nthe new clothing. To address these aspects, we propose PromptDresser, a\ntext-editable virtual try-on model that leverages large multimodal model (LMM)\nassistance to enable high-quality and versatile manipulation based on\ngenerative text prompts. Our approach utilizes LMMs via in-context learning to\ngenerate detailed text descriptions for person and clothing images\nindependently, including pose details and editing attributes using minimal\nhuman cost. Moreover, to ensure the editing areas, we adjust the inpainting\nmask depending on the text prompts adaptively. We found that our approach,\nutilizing detailed text prompts, not only enhances text editability but also\neffectively conveys clothing details that are difficult to capture through\nimages alone, thereby enhancing image quality. Our code is available at\nhttps://github.com/rlawjdghek/PromptDresser.",
      "tldr_zh": "这篇论文提出了PromptDresser，一种基于生成文本提示(Generative Textual Prompt)和提示感知掩码(Prompt-aware Mask)的模型，用于提升虚拟试穿(Virtual Try-On)的质量和可控性。PromptDresser通过利用大型多模态模型(LMM)进行上下文学习，生成详细的文本描述来处理人-服装图像对，从而解决文本信息冲突和编辑区域问题，同时适应性地调整inpainting mask以确保正确编辑穿着风格（如合身度或塞进风格）并保留原有人体外观。实验结果表明，该方法不仅增强了文本可编辑性，还通过文本提示更好地捕捉图像难以表现的服装细节，从而显著提高了生成的图像质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.16978v1",
      "published_date": "2024-12-22 11:38:04 UTC",
      "updated_date": "2024-12-22 11:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:26:40.877464"
    },
    {
      "arxiv_id": "2412.16976v1",
      "title": "On Fusing ChatGPT and Ensemble Learning in Discon-tinuous Named Entity Recognition in Health Corpora",
      "title_zh": "翻译失败",
      "authors": [
        "Tzu-Chieh Chen",
        "Wen-Yang Lin"
      ],
      "abstract": "Named Entity Recognition has traditionally been a key task in natural\nlanguage processing, aiming to identify and extract important terms from\nunstructured text data. However, a notable challenge for contemporary\ndeep-learning NER models has been identifying discontinuous entities, which are\noften fragmented within the text. To date, methods to address Discontinuous\nNamed Entity Recognition have not been explored using ensemble learning to the\nbest of our knowledge. Furthermore, the rise of large language models, such as\nChatGPT in recent years, has shown significant effectiveness across many NLP\ntasks. Most existing approaches, however, have primarily utilized ChatGPT as a\nproblem-solving tool rather than exploring its potential as an integrative\nelement within ensemble learning algorithms. In this study, we investigated the\nintegration of ChatGPT as an arbitrator within an ensemble method, aiming to\nenhance performance on DNER tasks. Our method combines five state-of-the-art\nNER models with ChatGPT using custom prompt engineering to assess the\nrobustness and generalization capabilities of the ensemble algorithm. We\nconducted experiments on three benchmark medical datasets, comparing our method\nagainst the five SOTA models, individual applications of GPT-3.5 and GPT-4, and\na voting ensemble method. The results indicate that our proposed fusion of\nChatGPT with the ensemble learning algorithm outperforms the SOTA results in\nthe CADEC, ShARe13, and ShARe14 datasets, showcasing its potential to enhance\nNLP applications in the healthcare domain.",
      "tldr_zh": "本研究探讨了在医疗语料中融合 ChatGPT 和 Ensemble Learning 来处理 Discontinuous Named Entity Recognition (DNER) 的挑战，该方法首次将集成学习应用于 DNER，并使用 ChatGPT 作为仲裁者以提升实体识别的鲁棒性和泛化能力。研究通过自定义提示工程（custom prompt engineering）将五个最先进的 NER 模型与 ChatGPT 结合，形成一个集成算法，并在 CADEC、ShARe13 和 ShARe14 等三个医疗基准数据集上进行实验。结果显示，该融合方法超过了单个 SOTA 模型、GPT-3.5、GPT-4 以及投票集成方法的性能，证明了其在提升医疗领域 NLP 应用方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.16976v1",
      "published_date": "2024-12-22 11:26:49 UTC",
      "updated_date": "2024-12-22 11:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:26:52.154541"
    },
    {
      "arxiv_id": "2412.16974v1",
      "title": "Cannot or Should Not? Automatic Analysis of Refusal Composition in IFT/RLHF Datasets and Refusal Behavior of Black-Box LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander von Recum",
        "Christoph Schnabl",
        "Gabor Hollbeck",
        "Silas Alberti",
        "Philip Blinde",
        "Marvin von Hagen"
      ],
      "abstract": "Refusals - instances where large language models (LLMs) decline or fail to\nfully execute user instructions - are crucial for both AI safety and AI\ncapabilities and the reduction of hallucinations in particular. These behaviors\nare learned during post-training, especially in instruction fine-tuning (IFT)\nand reinforcement learning from human feedback (RLHF). However, existing\ntaxonomies and evaluation datasets for refusals are inadequate, often focusing\nsolely on should-not-related (instead of cannot-related) categories, and\nlacking tools for auditing refusal content in black-box LLM outputs.\n  We present a comprehensive framework for classifying LLM refusals: (a) a\ntaxonomy of 16 refusal categories, (b) a human-annotated dataset of over 8,600\ninstances from publicly available IFT and RLHF datasets, (c) a synthetic\ndataset with 8,000 examples for each refusal category, and (d) classifiers\ntrained for refusal classification.\n  Our work enables precise auditing of refusal behaviors in black-box LLMs and\nautomatic analyses of refusal patterns in large IFT and RLHF datasets. This\nfacilitates the strategic adjustment of LLM refusals, contributing to the\ndevelopment of more safe and reliable LLMs.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在指令微调(IFT)和强化学习从人类反馈(RLHF)数据集中的拒绝行为，强调现有分类体系不足以覆盖“cannot”相关类别，并缺乏对黑盒LLMs拒绝输出的审计工具。论文提出一个全面框架，包括一个16类拒绝taxonomy、超过8600个实例的人工标注数据集、每个类别8000例的合成数据集，以及训练的拒绝分类器。该框架支持对黑盒LLMs的精确拒绝行为审计和IFT/RLHF数据集的自动分析，最终有助于战略调整LLMs的拒绝机制，提升其安全性和可靠性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 Workshop SFLLM",
      "pdf_url": "http://arxiv.org/pdf/2412.16974v1",
      "published_date": "2024-12-22 11:16:53 UTC",
      "updated_date": "2024-12-22 11:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:28:29.244248"
    },
    {
      "arxiv_id": "2412.16970v1",
      "title": "Environment Descriptions for Usability and Generalisation in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dennis J. N. J. Soemers",
        "Spyridon Samothrakis",
        "Kurt Driessens",
        "Mark H. M. Winands"
      ],
      "abstract": "The majority of current reinforcement learning (RL) research involves\ntraining and deploying agents in environments that are implemented by engineers\nin general-purpose programming languages and more advanced frameworks such as\nCUDA or JAX. This makes the application of RL to novel problems of interest\ninaccessible to small organisations or private individuals with insufficient\nengineering expertise. This position paper argues that, to enable more\nwidespread adoption of RL, it is important for the research community to shift\nfocus towards methodologies where environments are described in user-friendly\ndomain-specific or natural languages. Aside from improving the usability of RL,\nsuch language-based environment descriptions may also provide valuable context\nand boost the ability of trained agents to generalise to unseen environments\nwithin the set of all environments that can be described in any language of\nchoice.",
      "tldr_zh": "当前强化学习（RL）研究主要依赖工程师使用通用编程语言（如 CUDA 或 JAX）实现的环境，这导致 RL 在新问题上的应用对小型组织或个人难以访问。论文主张，研究社区应转向使用用户友好的领域特定语言或自然语言来描述环境，以提升 RL 的可用性和可访问性。这种方法不仅能提供宝贵的上下文，还能增强训练代理的泛化能力，使其在可描述环境范围内更好地适应未见场景。",
      "categories": [
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ICAART 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16970v1",
      "published_date": "2024-12-22 11:02:13 UTC",
      "updated_date": "2024-12-22 11:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:28:40.581559"
    },
    {
      "arxiv_id": "2412.16964v2",
      "title": "System-2 Mathematical Reasoning via Enriched Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Huanqia Cai",
        "Yijun Yang",
        "Zhifeng Li"
      ],
      "abstract": "Solving complex mathematical problems via system-2 reasoning is a natural\nhuman skill, yet it remains a significant challenge for current large language\nmodels (LLMs). We identify the scarcity of deliberate multi-step reasoning data\nas a primary limiting factor. To this end, we introduce Enriched Instruction\nTuning (EIT), a method that enriches existing human-annotated mathematical\ndatasets by synergizing human and AI feedback to create fine-grained reasoning\ntrajectories. These datasets are then used to fine-tune open-source LLMs,\nenhancing their mathematical reasoning abilities without reliance on any\nsymbolic verification program. Concretely, EIT is composed of two critical\nsteps: Enriching with Reasoning Plan (ERP) and Enriching with Reasoning Step\n(ERS). The former generates a high-level plan that breaks down complex\ninstructions into a sequence of simpler objectives, while ERS fills in\nreasoning contexts often overlooked by human annotators, creating a smoother\nreasoning trajectory for LLM fine-tuning. Unlike existing CoT prompting methods\nthat generate reasoning chains only depending on LLM's internal knowledge, our\nmethod leverages human-annotated initial answers as ``meta-knowledge'' to help\nLLMs generate more detailed and precise reasoning processes, leading to a more\ntrustworthy LLM expert for complex mathematical problems. In experiments, EIT\nachieves an accuracy of 84.1% on GSM8K and 32.5% on MATH, surpassing\nstate-of-the-art fine-tuning and prompting methods, and even matching the\nperformance of tool-augmented methods.",
      "tldr_zh": "本文提出 Enriched Instruction Tuning (EIT) 方法，以提升大语言模型 (LLMs) 在复杂数学问题上的 System-2 推理能力，通过结合人类和 AI 反馈丰富现有数据集，生成细粒度的多步推理轨迹。EIT 包括两个关键步骤：Enriching with Reasoning Plan (ERP) 将复杂指令分解为高层计划序列，以及 Enriching with Reasoning Step (ERS) 填充忽略的推理上下文，从而创建更精确的推理过程。在实验中，EIT 在 GSM8K 上达到 84.1% 准确率，在 MATH 上达到 32.5%，超过了现有微调和提示方法，甚至与工具增强方法相当。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16964v2",
      "published_date": "2024-12-22 10:49:27 UTC",
      "updated_date": "2024-12-24 11:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:28:53.502055"
    },
    {
      "arxiv_id": "2412.16936v1",
      "title": "Prompting Large Language Models with Rationale Heuristics for Knowledge-based Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongjian Hu",
        "Peng Yang",
        "Bing Li",
        "Fengyuan Liu"
      ],
      "abstract": "Recently, Large Language Models (LLMs) have been used for knowledge-based\nVisual Question Answering (VQA). Despite the encouraging results of previous\nstudies, prior methods prompt LLMs to predict answers directly, neglecting\nintermediate thought processes. We argue that prior methods do not sufficiently\nactivate the capacities of LLMs. We propose a framework called PLRH that\nPrompts LLMs with Rationale Heuristics for knowledge-based VQA. The PLRH\nprompts LLMs with Chain of Thought (CoT) to generate rationale heuristics,\ni.e., intermediate thought processes, and then leverages the rationale\nheuristics to inspire LLMs to predict answers. Experiments show that our\napproach outperforms the existing baselines by more than 2.2 and 2.1 on OK-VQA\nand A-OKVQA, respectively.",
      "tldr_zh": "该研究针对基于知识的视觉问答（VQA），提出了一种名为 PLRH 的框架，用于提示大型语言模型（LLMs）。PLRH 通过 Chain of Thought (CoT) 机制生成推理启发（rationale heuristics），即中间思考过程，从而更好地激活 LLMs 的能力，并利用这些启发来预测答案。实验结果显示，该方法在 OK-VQA 和 A-OKVQA 数据集上分别比现有基线提高了超过 2.2 和 2.1 的性能，为知识-based VQA 提供了更有效的优化策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16936v1",
      "published_date": "2024-12-22 09:14:35 UTC",
      "updated_date": "2024-12-22 09:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:29:04.663314"
    },
    {
      "arxiv_id": "2412.16934v1",
      "title": "Efficiently Solving Turn-Taking Stochastic Games with Extensive-Form Correlation",
      "title_zh": "高效求解轮流随机博弈的扩展",
      "authors": [
        "Hanrui Zhang",
        "Yu Cheng",
        "Vincent Conitzer"
      ],
      "abstract": "We study equilibrium computation with extensive-form correlation in\ntwo-player turn-taking stochastic games. Our main results are two-fold: (1) We\ngive an algorithm for computing a Stackelberg extensive-form correlated\nequilibrium (SEFCE), which runs in time polynomial in the size of the game, as\nwell as the number of bits required to encode each input number. (2) We give an\nefficient algorithm for approximately computing an optimal extensive-form\ncorrelated equilibrium (EFCE) up to machine precision, i.e., the algorithm\nachieves approximation error $\\varepsilon$ in time polynomial in the size of\nthe game, as well as $\\log(1 / \\varepsilon)$.\n  Our algorithm for SEFCE is the first polynomial-time algorithm for\nequilibrium computation with commitment in such a general class of stochastic\ngames. Existing algorithms for SEFCE typically make stronger assumptions such\nas no chance moves, and are designed for extensive-form games in the less\nsuccinct tree form. Our algorithm for approximately optimal EFCE is, to our\nknowledge, the first algorithm that achieves 3 desiderata simultaneously:\napproximate optimality, polylogarithmic dependency on the approximation error,\nand compatibility with stochastic games in the more succinct graph form.\nExisting algorithms achieve at most 2 of these desiderata, often also relying\non additional technical assumptions.",
      "tldr_zh": "本论文研究了在两玩家轮流随机游戏中使用广泛形式相关性计算均衡，主要贡献包括：提出一个多项式时间算法，用于计算 Stackelberg extensive-form correlated equilibrium (SEFCE)，其运行时间依赖于游戏规模和输入数字的位数，且适用于一般随机游戏。另一个算法实现了对 optimal extensive-form correlated equilibrium (EFCE)的近似计算，达到机器精度，时间复杂度多项式于游戏规模和 log(1 / ε)。这些算法首次同时满足近似最优性、对误差的 polylog 依赖，以及与随机游戏图形式的兼容性，相比现有方法更高效且减少了额外假设。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "EC 2023",
      "pdf_url": "http://arxiv.org/pdf/2412.16934v1",
      "published_date": "2024-12-22 09:12:05 UTC",
      "updated_date": "2024-12-22 09:12:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:29:18.294303"
    },
    {
      "arxiv_id": "2412.17874v2",
      "title": "Evaluating LLM Reasoning in the Operations Research Domain with ORQA",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Mostajabdaveh",
        "Timothy T. Yu",
        "Samarendra Chandan Bindu Dash",
        "Rindranirina Ramamonjison",
        "Jabo Serge Byusa",
        "Giuseppe Carenini",
        "Zirui Zhou",
        "Yong Zhang"
      ],
      "abstract": "In this paper, we introduce and apply Operations Research Question Answering\n(ORQA), a new benchmark designed to assess the generalization capabilities of\nLarge Language Models (LLMs) in the specialized technical domain of Operations\nResearch (OR). This benchmark evaluates whether LLMs can emulate the knowledge\nand reasoning skills of OR experts when confronted with diverse and complex\noptimization problems. The dataset, developed by OR experts, features\nreal-world optimization problems that demand multistep reasoning to construct\ntheir mathematical models. Our evaluations of various open source LLMs, such as\nLLaMA 3.1, DeepSeek, and Mixtral, reveal their modest performance, highlighting\na gap in their ability to generalize to specialized technical domains. This\nwork contributes to the ongoing discourse on LLMs generalization capabilities,\noffering valuable insights for future research in this area. The dataset and\nevaluation code are publicly available.",
      "tldr_zh": "本研究引入了 Operations Research Question Answering (ORQA) 基准，用于评估大型语言模型 (LLMs) 在运筹学 (Operations Research, OR) 领域的泛化能力，特别是其在处理复杂优化问题的知识和推理技能。ORQA 数据集由 OR 专家开发，包括真实世界的优化问题，需要多步推理来构建数学模型，并对开源 LLMs 如 LLaMA 3.1、DeepSeek 和 Mixtral 进行了评估。结果显示，这些模型的表现较为有限，突显了 LLMs 在专业技术领域的泛化差距。该工作为 LLMs 泛化能力的研究提供了宝贵见解，并公开了数据集和评估代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 10 figures. Accepted and to be published in AAAI25",
      "pdf_url": "http://arxiv.org/pdf/2412.17874v2",
      "published_date": "2024-12-22 09:10:34 UTC",
      "updated_date": "2025-02-09 16:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:29:28.989898"
    },
    {
      "arxiv_id": "2412.16933v1",
      "title": "Towards a Unified Paradigm: Integrating Recommendation Systems as a New Language in Large Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Zheng",
        "Qingfeng Sun",
        "Can Xu",
        "Peng Yu",
        "Qingwei Guo"
      ],
      "abstract": "This paper explores the use of Large Language Models (LLMs) for sequential\nrecommendation, which predicts users' future interactions based on their past\nbehavior. We introduce a new concept, \"Integrating Recommendation Systems as a\nNew Language in Large Models\" (RSLLM), which combines the strengths of\ntraditional recommenders and LLMs. RSLLM uses a unique prompting method that\ncombines ID-based item embeddings from conventional recommendation models with\ntextual item features. It treats users' sequential behaviors as a distinct\nlanguage and aligns the ID embeddings with the LLM's input space using a\nprojector. We also propose a two-stage LLM fine-tuning framework that refines a\npretrained LLM using a combination of two contrastive losses and a language\nmodeling loss. The LLM is first fine-tuned using text-only prompts, followed by\ntarget domain fine-tuning with unified prompts. This trains the model to\nincorporate behavioral knowledge from the traditional sequential recommender\ninto the LLM. Our empirical results validate the effectiveness of our proposed\nframework.",
      "tldr_zh": "本文提出RSLLM（Integrating Recommendation Systems as a New Language in Large Models）概念，将传统推荐系统与Large Language Models (LLMs) 整合，用于顺序推荐任务，即基于用户过去行为预测未来互动。RSLLM 通过独特的提示方法结合ID-based item embeddings 和文本特征，将用户行为视为一种新语言，并使用projector将这些嵌入与LLM 输入空间对齐，同时采用两阶段微调框架，包括对比损失和语言建模损失，以融入行为知识。实验结果证明，该框架在提升推荐性能方面有效，验证了其统一范式的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.16933v1",
      "published_date": "2024-12-22 09:08:46 UTC",
      "updated_date": "2024-12-22 09:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:29:40.891977"
    },
    {
      "arxiv_id": "2412.16926v2",
      "title": "Revisiting In-Context Learning with Long Context Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinheon Baek",
        "Sun Jae Lee",
        "Prakhar Gupta",
        "Geunseob Oh",
        "Siddharth Dalmia",
        "Prateek Kolhar"
      ],
      "abstract": "In-Context Learning (ICL) is a technique by which language models make\npredictions based on examples provided in their input context. Previously,\ntheir context window size imposed a limit on the number of examples that can be\nshown, making example selection techniques crucial for identifying the\nmaximally effective set of examples. However, the recent advent of Long Context\nLanguage Models (LCLMs) has significantly increased the number of examples that\ncan be included in context, raising an important question of whether ICL\nperformance in a many-shot regime is still sensitive to the method of sample\nselection. To answer this, we revisit these approaches in the context of LCLMs\nthrough extensive experiments on 18 datasets spanning 4 tasks. Surprisingly, we\nobserve that sophisticated example selection techniques do not yield\nsignificant improvements over a simple random sample selection method. Instead,\nwe find that the advent of LCLMs has fundamentally shifted the challenge of ICL\nfrom that of selecting the most effective examples to that of collecting\nsufficient examples to fill the context window. Specifically, in certain\ndatasets, including all available examples does not fully utilize the context\nwindow; however, by augmenting the examples in context with a simple data\naugmentation approach, we substantially improve ICL performance by 5%.",
      "tldr_zh": "本研究重新审视了In-Context Learning (ICL) 在Long Context Language Models (LCLMs) 下的表现，通过在18个数据集上的广泛实验，探讨了在多例子场景中样本选择方法的影响。结果显示，复杂的样本选择技术并未显著优于简单的随机选择，表明ICL 的主要挑战已从选择有效例子转向收集足够例子以填充上下文窗口。在某些数据集上，通过简单的数据增强方法补充例子，ICL 性能可提升5%。这为LCLMs 的应用提供了新见解，强调了示例数量的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16926v2",
      "published_date": "2024-12-22 08:55:19 UTC",
      "updated_date": "2025-01-06 08:45:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:29:52.654262"
    },
    {
      "arxiv_id": "2412.16925v1",
      "title": "Quantifying Public Response to COVID-19 Events: Introducing the Community Sentiment and Engagement Index",
      "title_zh": "量化公众对 COVID-19 事件的反应：介绍社区情感和参与指数",
      "authors": [
        "Nirmalya Thakur",
        "Kesha A. Patel",
        "Audrey Poon",
        "Shuqi Cui",
        "Nazif Azizi",
        "Rishika Shah",
        "Riyan Shah"
      ],
      "abstract": "This study introduces the Community Sentiment and Engagement Index (CSEI),\ndeveloped to capture nuanced public sentiment and engagement variations on\nsocial media, particularly in response to major events related to COVID-19.\nConstructed with diverse sentiment indicators, CSEI integrates features like\nengagement, daily post count, compound sentiment, fine-grain sentiments (fear,\nsurprise, joy, sadness, anger, disgust, and neutral), readability,\noffensiveness, and domain diversity. Each component is systematically weighted\nthrough a multi-step Principal Component Analysis (PCA)-based framework,\nprioritizing features according to their variance contributions across temporal\nsentiment shifts. This approach dynamically adjusts component importance,\nenabling CSEI to precisely capture high-sensitivity shifts in public sentiment.\nThe development of CSEI showed statistically significant correlations with its\nconstituent features, underscoring internal consistency and sensitivity to\nspecific sentiment dimensions. CSEI's responsiveness was validated using a\ndataset of 4,510,178 Reddit posts about COVID-19. The analysis focused on 15\nmajor events, including the WHO's declaration of COVID-19 as a pandemic, the\nfirst reported cases of COVID-19 across different countries, national\nlockdowns, vaccine developments, and crucial public health measures. Cumulative\nchanges in CSEI revealed prominent peaks and valleys aligned with these events,\nindicating significant patterns in public sentiment across different phases of\nthe pandemic. Pearson correlation analysis further confirmed a statistically\nsignificant relationship between CSEI daily fluctuations and these events (p =\n0.0428), highlighting the capacity of CSEI to infer and interpret shifts in\npublic sentiment and engagement in response to major events related to\nCOVID-19.",
      "tldr_zh": "本研究引入了 Community Sentiment and Engagement Index (CSEI)，一种用于量化社交媒体上公众对 COVID-19 重大事件的细微情绪和参与度变化的指标。\nCSEI 整合了多种特征，包括参与度、每日帖子数量、复合情绪、细粒度情绪（fear、surprise、joy、sadness、anger、disgust 和 neutral）、可读性、攻击性和领域多样性，并通过多步 Principal Component Analysis (PCA) 框架动态加权这些组件，以优先捕捉时间情绪变化中的方差贡献。\n在分析 4,510,178 条 Reddit 帖子后，CSEI 成功识别了 15 个关键事件（如 WHO 宣布大流行和国家 lockdowns）对应的情绪峰值和谷值，Pearson correlation 分析显示其每日波动与这些事件有统计显著相关性 (p = 0.0428)。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16925v1",
      "published_date": "2024-12-22 08:52:12 UTC",
      "updated_date": "2024-12-22 08:52:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:30:06.996739"
    },
    {
      "arxiv_id": "2412.16922v1",
      "title": "Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs",
      "title_zh": "利用在线内容和 LLMs 提升新兴经济体中的供应链透明度",
      "authors": [
        "Bohan Jin",
        "Qianyou Sun",
        "Lihua Chen"
      ],
      "abstract": "In the current global economy, supply chain transparency plays a pivotal role\nin ensuring this security by enabling companies to monitor supplier performance\nand fostering accountability and responsibility. Despite the advancements in\nsupply chain relationship datasets like Bloomberg and FactSet, supply chain\ntransparency remains a significant challenge in emerging economies due to\nissues such as information asymmetry and institutional gaps in regulation. This\nstudy proposes a novel approach to enhance supply chain transparency in\nemerging economies by leveraging online content and large language models\n(LLMs). We develop a Supply Chain Knowledge Graph Mining System that integrates\nadvanced LLMs with web crawler technology to automatically collect and analyze\nsupply chain information. The system's effectiveness is validated through a\ncase study focusing on the semiconductor supply chain, a domain that has\nrecently gained significant attention due to supply chain risks. Our results\ndemonstrate that the proposed system provides greater applicability for\nemerging economies, such as mainland China, complementing the data gaps in\nexisting datasets. However, challenges including the accurate estimation of\nmonetary and material flows, the handling of time series data, synonyms\ndisambiguation, and mitigating biases from online contents still remains.\nFuture research should focus on addressing these issues to further enhance the\nsystem's capabilities and broaden its application to other emerging economies\nand industries.",
      "tldr_zh": "本研究针对新兴经济体中供应链透明度的信息不对称和监管缺口等问题，提出一种创新方法，利用在线内容和大型语言模型（LLMs）来提升透明度。研究开发了Supply Chain Knowledge Graph Mining System，该系统整合LLMs与网络爬虫技术，自动收集并分析供应链信息。通过对半导体供应链的案例研究验证，该系统有效补充了现有数据集（如Bloomberg和FactSet）的空白，提高了在地区如中国大陆的适用性。尽管存在挑战，包括准确估计货币和材料流动、处理时间序列数据、同义词消歧以及减轻在线内容偏见，未来研究将聚焦这些问题以扩展应用。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.16922v1",
      "published_date": "2024-12-22 08:46:16 UTC",
      "updated_date": "2024-12-22 08:46:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:30:17.153875"
    },
    {
      "arxiv_id": "2412.16915v2",
      "title": "FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyun Zhong",
        "Chao Liang",
        "Jianwen Jiang",
        "Gaojie Lin",
        "Jiaqi Yang",
        "Zhou Zhao"
      ],
      "abstract": "Diffusion-based audio-driven talking avatar methods have recently gained\nattention for their high-fidelity, vivid, and expressive results. However,\ntheir slow inference speed limits practical applications. Despite the\ndevelopment of various distillation techniques for diffusion models, we found\nthat naive diffusion distillation methods do not yield satisfactory results.\nDistilled models exhibit reduced robustness with open-set input images and a\ndecreased correlation between audio and video compared to teacher models,\nundermining the advantages of diffusion models. To address this, we propose\nFADA (Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG\nDistillation). We first designed a mixed-supervised loss to leverage data of\nvarying quality and enhance the overall model capability as well as robustness.\nAdditionally, we propose a multi-CFG distillation with learnable tokens to\nutilize the correlation between audio and reference image conditions, reducing\nthe threefold inference runs caused by multi-CFG with acceptable quality\ndegradation. Extensive experiments across multiple datasets show that FADA\ngenerates vivid videos comparable to recent diffusion model-based methods while\nachieving an NFE speedup of 4.17-12.5 times. Demos are available at our webpage\nhttp://fadavatar.github.io.",
      "tldr_zh": "该研究针对基于扩散模型的音频驱动对话头像合成方法存在的推断速度慢问题，提出 FADA（Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation）框架，以提升效率和鲁棒性。FADA 引入 mixed-supervised loss 来利用不同质量的数据，提高模型的整体能力和对开放集输入的适应性，同时通过 multi-CFG distillation 与 learnable tokens 利用音频和参考图像的相关性，减少推断运行次数并最小化质量损失。实验结果显示，FADA 在多个数据集上生成与最新扩散模型相当的生动视频，同时将 NFE 速度提高了 4.17-12.5 倍。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025, Homepage https://fadavatar.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.16915v2",
      "published_date": "2024-12-22 08:19:22 UTC",
      "updated_date": "2025-04-04 06:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:30:29.730020"
    },
    {
      "arxiv_id": "2412.16908v2",
      "title": "Map Imagination Like Blind Humans: Group Diffusion Model for Robotic Map Generation",
      "title_zh": "像盲人一样想象地图：群组扩散模型用于机器人地图生成",
      "authors": [
        "Qijin Song",
        "Weibang Bai"
      ],
      "abstract": "Can robots imagine or generate maps like humans do, especially when only\nlimited information can be perceived like blind people? To address this\nchallenging task, we propose a novel group diffusion model (GDM) based\narchitecture for robots to generate point cloud maps with very limited input\ninformation.Inspired from the blind humans' natural capability of imagining or\ngenerating mental maps, the proposed method can generate maps without visual\nperception data or depth data. With additional limited super-sparse spatial\npositioning data, like the extra contact-based positioning information the\nblind individuals can obtain, the map generation quality can be improved even\nmore.Experiments on public datasets are conducted, and the results indicate\nthat our method can generate reasonable maps solely based on path data, and\nproduce even more refined maps upon incorporating exiguous LiDAR data.Compared\nto conventional mapping approaches, our novel method significantly mitigates\nsensor dependency, enabling the robots to imagine and generate elementary maps\nwithout heavy onboard sensory devices.",
      "tldr_zh": "这篇论文提出了一种 Group Diffusion Model (GDM) 架构，启发于盲人的想象能力，让机器人仅凭有限信息（如路径数据）生成点云地图，而不依赖视觉或深度数据。该方法通过 GDM 的扩散模型机制，模拟盲人构建心理地图的过程，并在添加超稀疏空间定位数据（如接触式信息）时进一步提升地图生成质量。实验在公共数据集上验证，显示该方法能产生合理且精炼的地图，与传统映射方法相比，显著降低了传感器依赖，为机器人实现轻量级地图生成提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16908v2",
      "published_date": "2024-12-22 07:54:21 UTC",
      "updated_date": "2025-01-13 04:11:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:30:40.885048"
    },
    {
      "arxiv_id": "2412.16905v2",
      "title": "A Backdoor Attack Scheme with Invisible Triggers Based on Model Architecture Modification",
      "title_zh": "基于模型架构修改的带有不可见触发器的后门攻击方案",
      "authors": [
        "Yuan Ma",
        "Xu Ma",
        "Jiankang Wei",
        "Jinmeng Tang",
        "Xiaoyu Zhang",
        "Yilun Lyu",
        "Kehao Chen",
        "Jingtong Huang"
      ],
      "abstract": "Machine learning systems are vulnerable to backdoor attacks, where attackers\nmanipulate model behavior through data tampering or architectural\nmodifications. Traditional backdoor attacks involve injecting malicious samples\nwith specific triggers into the training data, causing the model to produce\ntargeted incorrect outputs in the presence of the corresponding triggers. More\nsophisticated attacks modify the model's architecture directly, embedding\nbackdoors that are harder to detect as they evade traditional data-based\ndetection methods. However, the drawback of the architectural modification\nbased backdoor attacks is that the trigger must be visible in order to activate\nthe backdoor. To further strengthen the invisibility of the backdoor attacks, a\nnovel backdoor attack method is presented in the paper. To be more specific,\nthis method embeds the backdoor within the model's architecture and has the\ncapability to generate inconspicuous and stealthy triggers. The attack is\nimplemented by modifying pre-trained models, which are then redistributed,\nthereby posing a potential threat to unsuspecting users. Comprehensive\nexperiments conducted on standard computer vision benchmarks validate the\neffectiveness of this attack and highlight the stealthiness of its triggers,\nwhich remain undetectable through both manual visual inspection and advanced\ndetection tools.",
      "tldr_zh": "这篇论文提出了一种新型后门攻击（backdoor attack）方案，通过修改模型架构来嵌入不可见的触发器（invisible triggers），从而规避传统基于数据篡改的检测方法。方法涉及在预训练模型中植入后门，并生成隐蔽的触发器，使攻击在激活时不需可见元素。实验结果显示，该攻击在标准计算机视觉基准上表现出高有效性，且触发器能够逃避手动视觉检查和高级检测工具的识别。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16905v2",
      "published_date": "2024-12-22 07:39:43 UTC",
      "updated_date": "2025-01-06 14:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:30:52.936909"
    },
    {
      "arxiv_id": "2412.16897v2",
      "title": "MVREC: A General Few-shot Defect Classification Model Using Multi-View Region-Context",
      "title_zh": "MVREC：一个通用的少",
      "authors": [
        "Shuai Lyu",
        "Rongchen Zhang",
        "Zeqi Ma",
        "Fangjian Liao",
        "Dongmei Mo",
        "Waikeung Wong"
      ],
      "abstract": "Few-shot defect multi-classification (FSDMC) is an emerging trend in quality\ncontrol within industrial manufacturing. However, current FSDMC research often\nlacks generalizability due to its focus on specific datasets. Additionally,\ndefect classification heavily relies on contextual information within images,\nand existing methods fall short of effectively extracting this information. To\naddress these challenges, we propose a general FSDMC framework called MVREC,\nwhich offers two primary advantages: (1) MVREC extracts general features for\ndefect instances by incorporating the pre-trained AlphaCLIP model. (2) It\nutilizes a region-context framework to enhance defect features by leveraging\nmask region input and multi-view context augmentation. Furthermore, Few-shot\nZip-Adapter(-F) classifiers within the model are introduced to cache the visual\nfeatures of the support set and perform few-shot classification. We also\nintroduce MVTec-FS, a new FSDMC benchmark based on MVTec AD, which includes\n1228 defect images with instance-level mask annotations and 46 defect types.\nExtensive experiments conducted on MVTec-FS and four additional datasets\ndemonstrate its effectiveness in general defect classification and its ability\nto incorporate contextual information to improve classification performance.\nCode: https://github.com/ShuaiLYU/MVREC",
      "tldr_zh": "这篇论文针对 Few-shot Defect Multi-Classification (FSDMC) 在工业制造质量控制中的泛化性不足和上下文信息提取问题，提出了一种通用框架 MVREC。MVREC 利用预训练的 AlphaCLIP 模型提取通用的缺陷特征，并通过 region-context 框架结合掩码区域输入和多视图上下文增强来优化缺陷特征提取，同时引入 Few-shot Zip-Adapter(-F) 分类器来缓存支持集视觉特征并实现少样本分类。论文还构建了新基准 MVTec-FS（包含1228张缺陷图像和46种缺陷类型），并在该基准和四个其他数据集上的实验显示，MVREC 显著提升了缺陷分类性能和上下文利用能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16897v2",
      "published_date": "2024-12-22 07:14:45 UTC",
      "updated_date": "2025-03-30 09:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:31:05.992760"
    },
    {
      "arxiv_id": "2412.16893v1",
      "title": "Preventing Non-intrusive Load Monitoring Privacy Invasion: A Precise Adversarial Attack Scheme for Networked Smart Meters",
      "title_zh": "防止非侵入式负载监测隐私入侵：一种针对联网智能电表的精确对抗攻击方案",
      "authors": [
        "Jialing He",
        "Jiacheng Wang",
        "Ning Wang",
        "Shangwei Guo",
        "Liehuang Zhu",
        "Dusit Niyato",
        "Tao Xiang"
      ],
      "abstract": "Smart grid, through networked smart meters employing the non-intrusive load\nmonitoring (NILM) technique, can considerably discern the usage patterns of\nresidential appliances. However, this technique also incurs privacy leakage. To\naddress this issue, we propose an innovative scheme based on adversarial attack\nin this paper. The scheme effectively prevents NILM models from violating\nappliance-level privacy, while also ensuring accurate billing calculation for\nusers. To achieve this objective, we overcome two primary challenges. First, as\nNILM models fall under the category of time-series regression models, direct\napplication of traditional adversarial attacks designed for classification\ntasks is not feasible. To tackle this issue, we formulate a novel adversarial\nattack problem tailored specifically for NILM and providing a theoretical\nfoundation for utilizing the Jacobian of the NILM model to generate\nimperceptible perturbations. Leveraging the Jacobian, our scheme can produce\nperturbations, which effectively misleads the signal prediction of NILM models\nto safeguard users' appliance-level privacy. The second challenge pertains to\nfundamental utility requirements, where existing adversarial attack schemes\nstruggle to achieve accurate billing calculation for users. To handle this\nproblem, we introduce an additional constraint, mandating that the sum of added\nperturbations within a billing period must be precisely zero. Experimental\nvalidation on real-world power datasets REDD and UK-DALE demonstrates the\nefficacy of our proposed solutions, which can significantly amplify the\ndiscrepancy between the output of the targeted NILM model and the actual power\nsignal of appliances, and enable accurate billing at the same time.\nAdditionally, our solutions exhibit transferability, making the generated\nperturbation signal from one target model applicable to other diverse NILM\nmodels.",
      "tldr_zh": "本文提出一种精确的对抗攻击方案，旨在防止非入侵负载监测(NILM)技术在智能电网中侵犯用户电器级隐私，同时确保计费计算的准确性。该方案针对NILM作为时间序列回归模型的特性，首次制定了专属对抗攻击问题，利用NILM模型的Jacobian生成不易察觉的扰动，以误导模型输出并保护隐私。为维持实用性，方案引入额外约束，要求计费周期内扰动总和为零。实验在REDD和UK-DALE真实数据集上验证，该方法显著放大NILM模型输出与实际功率信号的差异，同时实现准确计费，并展示了对其他NILM模型的转移性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16893v1",
      "published_date": "2024-12-22 07:06:46 UTC",
      "updated_date": "2024-12-22 07:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:31:17.911860"
    },
    {
      "arxiv_id": "2412.16882v2",
      "title": "PsychAdapter: Adapting LLM Transformers to Reflect Traits, Personality and Mental Health",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Vu",
        "Huy Anh Nguyen",
        "Adithya V Ganesan",
        "Swanie Juhng",
        "Oscar N. E. Kjell",
        "Joao Sedoc",
        "Margaret L. Kern",
        "Ryan L. Boyd",
        "Lyle Ungar",
        "H. Andrew Schwartz",
        "Johannes C. Eichstaedt"
      ],
      "abstract": "Artificial intelligence-based language generators are now a part of most\npeople's lives. However, by default, they tend to generate \"average\" language\nwithout reflecting the ways in which people differ. Here, we propose a\nlightweight modification to the standard language model transformer\narchitecture - \"PsychAdapter\" - that uses empirically derived trait-language\npatterns to generate natural language for specified personality, demographic,\nand mental health characteristics (with or without prompting). We applied\nPsychAdapters to modify OpenAI's GPT-2, Google's Gemma, and Meta's Llama 3 and\nfound generated text to reflect the desired traits. For example, expert raters\nevaluated PsychAdapter's generated text output and found it matched intended\ntrait levels with 87.3% average accuracy for Big Five personalities, and 96.7%\nfor depression and life satisfaction. PsychAdapter is a novel method to\nintroduce psychological behavior patterns into language models at the\nfoundation level, independent of prompting, by influencing every transformer\nlayer. This approach can create chatbots with specific personality profiles,\nclinical training tools that mirror language associated with psychological\nconditionals, and machine translations that match an authors reading or\neducation level without taking up LLM context windows. PsychAdapter also allows\nfor the exploration psychological constructs through natural language\nexpression, extending the natural language processing toolkit to study human\npsychology.",
      "tldr_zh": "本论文提出 PsychAdapter，一种轻量级修改方案，用于调整 LLM Transformers 架构，使其生成自然语言时能反映指定的人格特质、人口统计特征和心理健康状况，而不依赖提示机制。研究利用经验性的 trait-language 模式，应用于 GPT-2、Gemma 和 Llama 3 等模型，在每个 Transformer 层引入心理行为模式，以实现更精确的文本输出。实验结果显示，专家评估的准确率高达 Big Five 个性特征的 87.3% 以及抑郁和生活满意度的 96.7%。这种方法可用于开发具有特定 personality profiles 的聊天机器人、临床训练工具和适应作者水平的机器翻译，并扩展 NLP 在人类心理学研究中的应用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16882v2",
      "published_date": "2024-12-22 06:22:40 UTC",
      "updated_date": "2025-01-01 03:13:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:31:31.393781"
    },
    {
      "arxiv_id": "2412.16878v1",
      "title": "Online Preference-based Reinforcement Learning with Self-augmented Feedback from Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Songjun Tu",
        "Jingbo Sun",
        "Qichao Zhang",
        "Xiangyuan Lan",
        "Dongbin Zhao"
      ],
      "abstract": "Preference-based reinforcement learning (PbRL) provides a powerful paradigm\nto avoid meticulous reward engineering by learning rewards based on human\npreferences. However, real-time human feedback is hard to obtain in online\ntasks. Most work suppose there is a \"scripted teacher\" that utilizes privileged\npredefined reward to provide preference feedback. In this paper, we propose a\nRL Self-augmented Large Language Model Feedback (RL-SaLLM-F) technique that\ndoes not rely on privileged information for online PbRL. RL-SaLLM-F leverages\nthe reflective and discriminative capabilities of LLM to generate\nself-augmented trajectories and provide preference labels for reward learning.\nFirst, we identify an failure issue in LLM-based preference discrimination,\nspecifically \"query ambiguity\", in online PbRL. Then LLM is employed to provide\npreference labels and generate self-augmented imagined trajectories that better\nachieve the task goal, thereby enhancing the quality and efficiency of\nfeedback. Additionally, a double-check mechanism is introduced to mitigate\nrandomness in the preference labels, improving the reliability of LLM feedback.\nThe experiment across multiple tasks in the MetaWorld benchmark demonstrates\nthe specific contributions of each proposed module in RL-SaLLM-F, and shows\nthat self-augmented LLM feedback can effectively replace the impractical\n\"scripted teacher\" feedback. In summary, RL-SaLLM-F introduces a new direction\nof feedback acquisition in online PbRL that does not rely on any online\nprivileged information, offering an efficient and lightweight solution with\nLLM-driven feedback.",
      "tldr_zh": "该论文提出 RL-SaLLM-F 技术，用于在线 Preference-based Reinforcement Learning (PbRL)，通过 Large Language Model (LLM) 生成自增强反馈，避免依赖特权信息或实时人类反馈。方法利用 LLM 的反射和鉴别能力来创建想象轨迹并提供偏好标签，同时解决\"query ambiguity\"问题，并引入双重检查机制以提高反馈的可靠性和效率。在 MetaWorld 基准的多任务实验中，RL-SaLLM-F 证明了各模块的有效性，并展示了其作为高效轻量替代方案的优势，能取代传统的\"scripted teacher\"反馈。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, The 24th International Conference on Autonomous Agents and\n  Multi-Agent Systems (AAMAS25)",
      "pdf_url": "http://arxiv.org/pdf/2412.16878v1",
      "published_date": "2024-12-22 06:15:25 UTC",
      "updated_date": "2024-12-22 06:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:31:41.671635"
    },
    {
      "arxiv_id": "2412.16874v4",
      "title": "A Multi-modal Approach to Dysarthria Detection and Severity Assessment Using Speech and Text Information",
      "title_zh": "翻译失败",
      "authors": [
        "Anuprabha M",
        "Krishna Gurugubelli",
        "V Kesavaraj",
        "Anil Kumar Vuppala"
      ],
      "abstract": "Automatic detection and severity assessment of dysarthria are crucial for\ndelivering targeted therapeutic interventions to patients. While most existing\nresearch focuses primarily on speech modality, this study introduces a novel\napproach that leverages both speech and text modalities. By employing\ncross-attention mechanism, our method learns the acoustic and linguistic\nsimilarities between speech and text representations. This approach assesses\nspecifically the pronunciation deviations across different severity levels,\nthereby enhancing the accuracy of dysarthric detection and severity assessment.\nAll the experiments have been performed using UA-Speech dysarthric database.\nImproved accuracies of 99.53% and 93.20% in detection, and 98.12% and 51.97%\nfor severity assessment have been achieved when speaker-dependent and\nspeaker-independent, unseen and seen words settings are used. These findings\nsuggest that by integrating text information, which provides a reference\nlinguistic knowledge, a more robust framework has been developed for dysarthric\ndetection and assessment, thereby potentially leading to more effective\ndiagnoses.",
      "tldr_zh": "这篇论文提出了一种多模态方法，用于dysarthria检测和严重程度评估，通过整合语音和文本信息来提高准确性。方法采用cross-attention机制，学习语音和文本表示之间的声学及语言相似性，从而评估不同严重水平下的发音偏差。实验在UA-Speech数据库上进行，在说话者相关和不相关设置下，检测准确率分别达到99.53%和93.20%，严重程度评估准确率则为98.12%和51.97%。这些结果表明，融入文本作为参考语言知识，能构建更鲁棒的框架，促进更有效的dysarthria诊断。",
      "categories": [
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16874v4",
      "published_date": "2024-12-22 06:08:35 UTC",
      "updated_date": "2025-04-26 13:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:31:53.331989"
    },
    {
      "arxiv_id": "2412.16859v2",
      "title": "Adversarially Domain-adaptive Latent Diffusion for Unsupervised Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Jongmin Yu",
        "Zhongtian Sun",
        "Chen Bene Chi",
        "Jinhong Yang",
        "Shan Luo"
      ],
      "abstract": "Semantic segmentation requires extensive pixel-level annotation, motivating\nunsupervised domain adaptation (UDA) to transfer knowledge from labelled source\ndomains to unlabelled or weakly labelled target domains. One of the most\nefficient strategies involves using synthetic datasets generated within\ncontrolled virtual environments, such as video games or traffic simulators,\nwhich can automatically generate pixel-level annotations. However, even when\nsuch datasets are available, learning a well-generalised representation that\ncaptures both domains remains challenging, owing to probabilistic and geometric\ndiscrepancies between the virtual world and real-world imagery. This work\nintroduces a semantic segmentation method based on latent diffusion models,\ntermed Inter-Coder Connected Latent Diffusion (ICCLD), alongside an\nunsupervised domain adaptation approach. The model employs an inter-coder\nconnection to enhance contextual understanding and preserve fine details, while\nadversarial learning aligns latent feature distributions across domains during\nthe latent diffusion process. Experiments on GTA5, Synthia, and Cityscapes\ndemonstrate that ICCLD outperforms state-of-the-art UDA methods, achieving mIoU\nscores of 74.4 (GTA5$\\rightarrow$Cityscapes) and 67.2\n(Synthia$\\rightarrow$Cityscapes).",
      "tldr_zh": "本文提出了一种基于潜在扩散模型的语义分割方法，名为 Inter-Coder Connected Latent Diffusion (ICCLD)，结合对抗学习实现无监督域适应（UDA），以解决合成数据集与真实图像之间概率和几何差异带来的泛化挑战。该方法通过 inter-coder 连接增强上下文理解、保留细节，并在潜在扩散过程中对齐不同域的特征分布，从而从有标签源域（如 GTA5 或 Synthia）转移知识到无标签目标域（如 Cityscapes）。实验结果显示，ICCLD 在 GTA5→Cityscapes 和 Synthia→Cityscapes 任务上分别达到 74.4 和 67.2 的 mIoU 分数，超过了现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted from CVPR 2025 Workshop PVUW",
      "pdf_url": "http://arxiv.org/pdf/2412.16859v2",
      "published_date": "2024-12-22 04:55:41 UTC",
      "updated_date": "2025-04-07 02:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:32:05.904101"
    },
    {
      "arxiv_id": "2412.19834v1",
      "title": "RoboSignature: Robust Signature and Watermarking on Network Attacks",
      "title_zh": "RoboSignature：针对网络攻击的鲁棒签名和水印技术",
      "authors": [
        "Aryaman Shaan",
        "Garvit Banga",
        "Raghav Mantri"
      ],
      "abstract": "Generative models have enabled easy creation and generation of images of all\nkinds given a single prompt. However, this has also raised ethical concerns\nabout what is an actual piece of content created by humans or cameras compared\nto model-generated content like images or videos. Watermarking data generated\nby modern generative models is a popular method to provide information on the\nsource of the content. The goal is for all generated images to conceal an\ninvisible watermark, allowing for future detection or identification. The\nStable Signature finetunes the decoder of Latent Diffusion Models such that a\nunique watermark is rooted in any image produced by the decoder. In this paper,\nwe present a novel adversarial fine-tuning attack that disrupts the model's\nability to embed the intended watermark, exposing a significant vulnerability\nin existing watermarking methods. To address this, we further propose a\ntamper-resistant fine-tuning algorithm inspired by methods developed for large\nlanguage models, tailored to the specific requirements of watermarking in LDMs.\nOur findings emphasize the importance of anticipating and defending against\npotential vulnerabilities in generative systems.",
      "tldr_zh": "该论文探讨了生成模型在创建图像时可能被篡改的问题，特别针对Stable Signature方法，该方法通过微调Latent Diffusion Models的解码器在生成图像中嵌入唯一水印，以标识内容来源。论文提出了一种新型对抗性微调攻击，能够破坏水印的嵌入，从而暴露现有水印技术的重大漏洞。为应对这一问题，研究者开发了一种防篡改微调算法，借鉴大语言模型的技术，并针对LDMs的需求进行优化。总体而言，该研究强调了在生成系统中预见和防御潜在漏洞的重要性，以提升水印的鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19834v1",
      "published_date": "2024-12-22 04:36:27 UTC",
      "updated_date": "2024-12-22 04:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:32:16.618688"
    },
    {
      "arxiv_id": "2412.16849v1",
      "title": "OpenRFT: Adapting Reasoning Foundation Model for Domain-specific Tasks with Reinforcement Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Zhang",
        "Yuqi Yang",
        "Jiangming Shu",
        "Yuhang Wang",
        "Jinlin Xiao",
        "Jitao Sang"
      ],
      "abstract": "OpenAI's recent introduction of Reinforcement Fine-Tuning (RFT) showcases the\npotential of reasoning foundation model and offers a new paradigm for\nfine-tuning beyond simple pattern imitation. This technical report presents\n\\emph{OpenRFT}, our attempt to fine-tune generalist reasoning models for\ndomain-specific tasks under the same settings as RFT. OpenRFT addresses two key\nchallenges of lacking reasoning step data and the limited quantity of training\nsamples, by leveraging the domain-specific samples in three ways: question\naugmentation, synthesizing reasoning-process data, and few-shot ICL. The\nevaluation is conducted on SciKnowEval, where OpenRFT achieves notable\nperformance gains with only $100$ domain-specific samples for each task. More\nexperimental results will be updated continuously in later versions. Source\ncodes, datasets, and models are disclosed at:\nhttps://github.com/ADaM-BJTU/OpenRFT",
      "tldr_zh": "本研究提出 OpenRFT 方法，用于通过 Reinforcement Fine-Tuning (RFT) 框架将通用推理基础模型适应于领域特定任务，解决缺乏推理步骤数据和训练样本量有限的挑战。OpenRFT 利用领域特定样本，通过问题增强（question augmentation）、合成推理过程数据（synthesizing reasoning-process data）和少样本 ICL（few-shot ICL）三种策略来增强模型性能。在 SciKnowEval 评估中，仅使用每个任务 100 个样本，OpenRFT 就实现了显著性能提升，并开源了源代码、数据集和模型以供进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16849v1",
      "published_date": "2024-12-22 04:21:30 UTC",
      "updated_date": "2024-12-22 04:21:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:32:29.052415"
    },
    {
      "arxiv_id": "2412.16848v2",
      "title": "ACL-QL: Adaptive Conservative Level in Q-Learning for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Wu",
        "Yinuo Zhao",
        "Zhiyuan Xu",
        "Zhengping Che",
        "Chengxiang Yin",
        "Chi Harold Liu",
        "Feiferi Feng",
        "Jian Tang"
      ],
      "abstract": "Offline Reinforcement Learning (RL), which operates solely on static datasets\nwithout further interactions with the environment, provides an appealing\nalternative to learning a safe and promising control policy. The prevailing\nmethods typically learn a conservative policy to mitigate the problem of\nQ-value overestimation, but it is prone to overdo it, leading to an overly\nconservative policy. Moreover, they optimize all samples equally with fixed\nconstraints, lacking the nuanced ability to control conservative levels in a\nfine-grained manner. Consequently, this limitation results in a performance\ndecline. To address the above two challenges in a united way, we propose a\nframework, Adaptive Conservative Level in Q-Learning (ACL-QL), which limits the\nQ-values in a mild range and enables adaptive control on the conservative level\nover each state-action pair, i.e., lifting the Q-values more for good\ntransitions and less for bad transitions. We theoretically analyze the\nconditions under which the conservative level of the learned Q-function can be\nlimited in a mild range and how to optimize each transition adaptively.\nMotivated by the theoretical analysis, we propose a novel algorithm, ACL-QL,\nwhich uses two learnable adaptive weight functions to control the conservative\nlevel over each transition. Subsequently, we design a monotonicity loss and\nsurrogate losses to train the adaptive weight functions, Q-function, and policy\nnetwork alternatively. We evaluate ACL-QL on the commonly used D4RL benchmark\nand conduct extensive ablation studies to illustrate the effectiveness and\nstate-of-the-art performance compared to existing offline DRL baselines.",
      "tldr_zh": "该研究针对离线强化学习(Offline RL)中 Q 值过估计导致策略过于保守的问题，提出了一种自适应保守水平 Q 学习框架(ACL-QL)。ACL-QL 通过限制 Q 值在温和范围内，并使用两个可学习的自适应权重函数，对每个状态-动作对进行细粒度控制，使好的转换获得更多提升而坏的转换较少提升。论文还提供了理论分析和算法设计，包括单调性损失和代理损失来交替训练权重函数、Q 函数和策略网络；在 D4RL 基准上的实验结果显示，ACL-QL 比现有基线方法表现出色，提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 4 figures, IEEE Transactions on Neural Networks and\n  Learning Systems (2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.16848v2",
      "published_date": "2024-12-22 04:18:02 UTC",
      "updated_date": "2025-03-17 06:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:34:41.196598"
    },
    {
      "arxiv_id": "2412.16844v3",
      "title": "Sim911: Towards Effective and Equitable 9-1-1 Dispatcher Training with an LLM-Enabled Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Zirong Chen",
        "Elizabeth Chason",
        "Noah Mladenovski",
        "Erin Wilson",
        "Kristin Mullen",
        "Stephen Martini",
        "Meiyi Ma"
      ],
      "abstract": "Emergency response services are vital for enhancing public safety by\nsafeguarding the environment, property, and human lives. As frontline members\nof these services, 9-1-1 dispatchers have a direct impact on response times and\nthe overall effectiveness of emergency operations. However, traditional\ndispatcher training methods, which rely on role-playing by experienced\npersonnel, are labor-intensive, time-consuming, and often neglect the specific\nneeds of underserved communities. To address these challenges, we introduce\nSim911, the first training simulation for 9-1-1 dispatchers powered by Large\nLanguage Models (LLMs). Sim911 enhances training through three key technical\ninnovations: (1) knowledge construction, which utilizes archived 9-1-1 call\ndata to generate simulations that closely mirror real-world scenarios; (2)\ncontext-aware controlled generation, which employs dynamic prompts and vector\nbases to ensure that LLM behavior aligns with training objectives; and (3)\nvalidation with looped correction, which filters out low-quality responses and\nrefines the system performance.",
      "tldr_zh": "该论文提出Sim911，一种基于Large Language Models (LLMs)的模拟系统，旨在提升9-1-1调度员训练的有效性和公平性，以解决传统角色扮演方法耗时劳力且忽略弱势社区需求的问题。Sim911的关键创新包括：知识构建利用存档的9-1-1通话数据生成真实场景、上下文感知控制生成通过动态提示和向量基础确保LLM行为符合训练目标，以及验证与循环修正机制过滤低质量响应并优化性能。该系统有望显著改善紧急响应服务的整体效率和公平性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16844v3",
      "published_date": "2024-12-22 03:43:51 UTC",
      "updated_date": "2024-12-26 04:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:32:52.723660"
    },
    {
      "arxiv_id": "2412.16842v1",
      "title": "Graph Learning-based Regional Heavy Rainfall Prediction Using Low-Cost Rain Gauges",
      "title_zh": "翻译失败",
      "authors": [
        "Edwin Salcedo"
      ],
      "abstract": "Accurate and timely prediction of heavy rainfall events is crucial for\neffective flood risk management and disaster preparedness. By monitoring,\nanalysing, and evaluating rainfall data at a local level, it is not only\npossible to take effective actions to prevent any severe climate variation but\nalso to improve the planning of surface and underground hydrological resources.\nHowever, developing countries often lack the weather stations to collect data\ncontinuously due to the high cost of installation and maintenance. In light of\nthis, the contribution of the present paper is twofold: first, we propose a\nlow-cost IoT system for automatic recording, monitoring, and prediction of\nrainfall in rural regions. Second, we propose a novel approach to regional\nheavy rainfall prediction by implementing graph neural networks (GNNs), which\nare particularly well-suited for capturing the complex spatial dependencies\ninherent in rainfall patterns. The proposed approach was tested using a\nhistorical dataset spanning 72 months, with daily measurements, and\nexperimental results demonstrated the effectiveness of the proposed method in\npredicting heavy rainfall events, making this approach particularly attractive\nfor regions with limited resources or where traditional weather radar or\nstation coverage is sparse.",
      "tldr_zh": "该论文针对发展中国家气象站成本高导致的数据收集不足问题，提出了一种基于低成本雨量计的区域强降雨预测方法，以支持洪水风险管理和水资源规划。主要贡献包括开发一个低成本的 IoT 系统，用于农村地区的自动雨量记录和监测，以及引入 Graph Neural Networks (GNNs) 来捕捉雨量模式的空间依赖性。通过分析一个跨越72个月的每日历史数据集，实验结果显示该方法在预测强降雨事件上表现出色，特别适合资源有限的地区。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in the proceedings of the 2024 Latin\n  American Conference on Computational Intelligence (IEEE LA-CCI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.16842v1",
      "published_date": "2024-12-22 03:40:16 UTC",
      "updated_date": "2024-12-22 03:40:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:33:05.320140"
    },
    {
      "arxiv_id": "2412.17872v1",
      "title": "Joint Knowledge Editing for Information Enrichment and Probability Promotion",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhang Shi",
        "Yiren Chen",
        "Shuqing Bian",
        "Xinyi Zhang",
        "Zhe Zhao",
        "Pengfei Hu",
        "Wei Lu",
        "Xiaoyong Du"
      ],
      "abstract": "Knowledge stored in large language models requires timely updates to reflect\nthe dynamic nature of real-world information. To update the knowledge, most\nknowledge editing methods focus on the low layers, since recent probes into the\nknowledge recall process reveal that the answer information is enriched in low\nlayers. However, these probes only and could only reveal critical recall stages\nfor the original answers, while the goal of editing is to rectify model's\nprediction for the target answers. This inconsistency indicates that both the\nprobe approaches and the associated editing methods are deficient. To mitigate\nthe inconsistency and identify critical editing regions, we propose a\ncontrast-based probe approach, and locate two crucial stages where the model\nbehavior diverges between the original and target answers: Information\nEnrichment in low layers and Probability Promotion in high layers. Building\nupon the insights, we develop the Joint knowledge Editing for information\nEnrichment and probability Promotion (JEEP) method, which jointly edits both\nthe low and high layers to modify the two critical recall stages. Considering\nthe mutual interference and growing forgetting due to dual modifications, JEEP\nis designed to ensure that updates to distinct regions share the same\nobjectives and are complementary. We rigorously evaluate JEEP by editing up to\nthousands of facts on various models, i.e., GPT-J (6B) and LLaMA (7B), and\naddressing diverse editing objectives, i.e., adding factual and counterfactual\nknowledge. In all tested scenarios, JEEP achieves best performances, validating\nthe effectiveness of the revealings of our probe approach and the designs of\nour editing method. Our code and data are available at\nhttps://github.com/Eric8932/JEEP.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models）中知识更新的挑战，提出一种基于对比探测（contrast-based probe approach）的分析方法，识别出两个关键阶段：低层的Information Enrichment和高层的Probability Promotion，以解决现有编辑方法对目标答案修正的不足。基于此，作者开发了JEEP（Joint knowledge Editing for information Enrichment and probability Promotion）方法，通过联合编辑低层和高层，确保更新目标一致并互补，从而减少相互干扰和遗忘问题。在GPT-J (6B)和LLaMA (7B)模型上，JEEP在编辑数千事实知识（包括事实和反事实）时，表现出最佳性能，验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17872v1",
      "published_date": "2024-12-22 03:16:49 UTC",
      "updated_date": "2024-12-22 03:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:33:17.541361"
    },
    {
      "arxiv_id": "2412.16839v2",
      "title": "Human-Guided Image Generation for Expanding Small-Scale Training Image Datasets",
      "title_zh": "人类引导的图像生成用于扩展小规模训练图像数据集",
      "authors": [
        "Changjian Chen",
        "Fei Lv",
        "Yalong Guan",
        "Pengcheng Wang",
        "Shengjie Yu",
        "Yifan Zhang",
        "Zhuo Tang"
      ],
      "abstract": "The performance of computer vision models in certain real-world applications\n(e.g., rare wildlife observation) is limited by the small number of available\nimages. Expanding datasets using pre-trained generative models is an effective\nway to address this limitation. However, since the automatic generation process\nis uncontrollable, the generated images are usually limited in diversity, and\nsome of them are undesired. In this paper, we propose a human-guided image\ngeneration method for more controllable dataset expansion. We develop a\nmulti-modal projection method with theoretical guarantees to facilitate the\nexploration of both the original and generated images. Based on the\nexploration, users refine the prompts and re-generate images for better\nperformance. Since directly refining the prompts is challenging for novice\nusers, we develop a sample-level prompt refinement method to make it easier.\nWith this method, users only need to provide sample-level feedback (e.g., which\nsamples are undesired) to obtain better prompts. The effectiveness of our\nmethod is demonstrated through the quantitative evaluation of the multi-modal\nprojection method, improved model performance in the case study for both\nclassification and object detection tasks, and positive feedback from the\nexperts.",
      "tldr_zh": "该论文提出了一种人类引导的图像生成方法，用于扩展小型训练图像数据集，解决自动生成图像多样性不足和不可控性的问题。该方法包括多模态投影方法（multi-modal projection method），以理论保证支持用户探索原始和生成图像，并基于此优化提示进行重新生成。此外，论文开发了样本级提示优化（sample-level prompt refinement），允许用户只需提供简单反馈（如标记不理想样本）即可改进提示。实验结果显示，该方法显著提升了模型在分类和物体检测任务中的性能，并获得了专家的积极评价。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TVCG2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16839v2",
      "published_date": "2024-12-22 03:15:39 UTC",
      "updated_date": "2024-12-24 01:53:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:33:29.725968"
    },
    {
      "arxiv_id": "2412.16834v2",
      "title": "Online Learning from Strategic Human Feedback in LLM Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Shugang Hao",
        "Lingjie Duan"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) has become an essential\nstep in fine-tuning large language models (LLMs) to align them with human\npreferences. However, human labelers are selfish and have diverse preferences.\nThey may strategically misreport their online feedback to influence the\nsystem's aggregation towards their own preferences. Current practice simply\naverages labelers' feedback per time and fails to identify the most accurate\nhuman labeler, leading to linear regret $\\mathcal{O}(T)$ for $T$ time slots. To\nour best knowledge, we are the first to study online learning mechanisms\nagainst strategic human labelers in the LLM fine-tuning process. We formulate a\nnew dynamic Bayesian game and dynamically adjust human labelers' weights in the\npreference aggregation, ensuring their truthful feedback and sublinear regret\n$\\mathcal{O}(T^{1/2})$. Simulation results demonstrate our mechanism's great\nadvantages over the existing benchmark schemes.",
      "tldr_zh": "该论文探讨了在LLM微调中使用RLHF时，人类标签者可能出于自私动机战略性地误报反馈，导致现有方法出现线性遗憾O(T)。他们首次提出了一种基于动态贝叶斯游戏的在线学习机制，通过动态调整标签者的权重，确保反馈真实并实现次线性遗憾O(T^{1/2})。模拟实验结果显示，该机制显著优于现有基准方案，为处理战略性人类反馈提供了有效解决方案。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16834v2",
      "published_date": "2024-12-22 02:43:07 UTC",
      "updated_date": "2024-12-24 02:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:33:40.992080"
    },
    {
      "arxiv_id": "2412.16833v4",
      "title": "KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiwen Zuo",
        "Yirui Jiang",
        "Fan Mo",
        "Pietro Lio"
      ],
      "abstract": "Integrating Large Language Models (LLMs) in healthcare diagnosis demands\nsystematic frameworks that can handle complex medical scenarios while\nmaintaining specialized expertise. We present KG4Diagnosis, a novel\nhierarchical multi-agent framework that combines LLMs with automated knowledge\ngraph construction, encompassing 362 common diseases across medical\nspecialties. Our framework mirrors real-world medical systems through a\ntwo-tier architecture: a general practitioner (GP) agent for initial assessment\nand triage, coordinating with specialized agents for in-depth diagnosis in\nspecific domains. The core innovation lies in our end-to-end knowledge graph\ngeneration methodology, incorporating: (1) semantic-driven entity and relation\nextraction optimized for medical terminology, (2) multi-dimensional decision\nrelationship reconstruction from unstructured medical texts, and (3)\nhuman-guided reasoning for knowledge expansion. KG4Diagnosis serves as an\nextensible foundation for specialized medical diagnosis systems, with\ncapabilities to incorporate new diseases and medical knowledge. The framework's\nmodular design enables seamless integration of domain-specific enhancements,\nmaking it valuable for developing targeted medical diagnosis systems. We\nprovide architectural guidelines and protocols to facilitate adoption across\nmedical contexts.",
      "tldr_zh": "本论文提出 KG4Diagnosis，一种分层多智能体框架，将 Large Language Models (LLMs) 与知识图谱增强相结合，用于处理复杂医疗诊断场景。该框架采用两层架构，包括一个 General Practitioner (GP) 代理负责初步评估和分流，以及专业代理进行领域特定深入诊断；其核心创新在于端到端的知识图谱生成方法，涵盖语义驱动实体和关系提取、多维决策关系重建，以及人类指导的知识扩展，支持 362 种常见疾病。框架设计模块化且可扩展，便于整合新疾病和医疗知识，并提供架构指南以促进在实际医疗系统中的应用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages,5 figures,published to AAAI-25 Bridge Program",
      "pdf_url": "http://arxiv.org/pdf/2412.16833v4",
      "published_date": "2024-12-22 02:40:59 UTC",
      "updated_date": "2025-03-28 23:31:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:33:53.187838"
    },
    {
      "arxiv_id": "2412.16829v1",
      "title": "Visual Prompting with Iterative Refinement for Design Critique Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Peitong Duan",
        "Chin-Yi Chen",
        "Bjoern Hartmann",
        "Yang Li"
      ],
      "abstract": "Feedback is crucial for every design process, such as user interface (UI)\ndesign, and automating design critiques can significantly improve the\nefficiency of the design workflow. Although existing multimodal large language\nmodels (LLMs) excel in many tasks, they often struggle with generating\nhigh-quality design critiques -- a complex task that requires producing\ndetailed design comments that are visually grounded in a given design's image.\nBuilding on recent advancements in iterative refinement of text output and\nvisual prompting methods, we propose an iterative visual prompting approach for\nUI critique that takes an input UI screenshot and design guidelines and\ngenerates a list of design comments, along with corresponding bounding boxes\nthat map each comment to a specific region in the screenshot. The entire\nprocess is driven completely by LLMs, which iteratively refine both the text\noutput and bounding boxes using few-shot samples tailored for each step. We\nevaluated our approach using Gemini-1.5-pro and GPT-4o, and found that human\nexperts generally preferred the design critiques generated by our pipeline over\nthose by the baseline, with the pipeline reducing the gap from human\nperformance by 50% for one rating metric. To assess the generalizability of our\napproach to other multimodal tasks, we applied our pipeline to open-vocabulary\nobject and attribute detection, and experiments showed that our method also\noutperformed the baseline.",
      "tldr_zh": "这篇论文提出了一种迭代视觉提示（iterative visual prompting）方法，用于生成高质量的设计批评，帮助自动化 UI 设计流程。方法以 UI 截图和设计指南为输入，由多模态大语言模型（LLMs）驱动，通过 few-shot samples 迭代精炼文本输出和对应的 bounding boxes，确保批评与图像区域精确关联。实验结果显示，使用 Gemini-1.5-pro 和 GPT-4o 的管道生成的批评获得人类专家偏好，并在一种评分指标上将与人类表现的差距减少 50%；此外，该方法在开放词汇对象和属性检测等其他多模态任务上也优于基线。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16829v1",
      "published_date": "2024-12-22 02:35:57 UTC",
      "updated_date": "2024-12-22 02:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:34:05.487938"
    },
    {
      "arxiv_id": "2412.16822v2",
      "title": "Layer- and Timestep-Adaptive Differentiable Token Compression Ratios for Efficient Diffusion Transformers",
      "title_zh": "层和时间步自适应可微令牌压缩比率，用于高效扩散变压器",
      "authors": [
        "Haoran You",
        "Connelly Barnes",
        "Yuqian Zhou",
        "Yan Kang",
        "Zhenbang Du",
        "Wei Zhou",
        "Lingzhi Zhang",
        "Yotam Nitzan",
        "Xiaoyang Liu",
        "Zhe Lin",
        "Eli Shechtman",
        "Sohrab Amirghodsi",
        "Yingyan Celine Lin"
      ],
      "abstract": "Diffusion Transformers (DiTs) have achieved state-of-the-art (SOTA) image\ngeneration quality but suffer from high latency and memory inefficiency, making\nthem difficult to deploy on resource-constrained devices. One major efficiency\nbottleneck is that existing DiTs apply equal computation across all regions of\nan image. However, not all image tokens are equally important, and certain\nlocalized areas require more computation, such as objects. To address this, we\npropose DiffCR, a dynamic DiT inference framework with differentiable\ncompression ratios, which automatically learns to dynamically route computation\nacross layers and timesteps for each image token, resulting in efficient DiTs.\nSpecifically, DiffCR integrates three features: (1) A token-level routing\nscheme where each DiT layer includes a router that is fine-tuned jointly with\nmodel weights to predict token importance scores. In this way, unimportant\ntokens bypass the entire layer's computation; (2) A layer-wise differentiable\nratio mechanism where different DiT layers automatically learn varying\ncompression ratios from a zero initialization, resulting in large compression\nratios in redundant layers while others remain less compressed or even\nuncompressed; (3) A timestep-wise differentiable ratio mechanism where each\ndenoising timestep learns its own compression ratio. The resulting pattern\nshows higher ratios for noisier timesteps and lower ratios as the image becomes\nclearer. Extensive experiments on text-to-image and inpainting tasks show that\nDiffCR effectively captures dynamism across token, layer, and timestep axes,\nachieving superior trade-offs between generation quality and efficiency\ncompared to prior works. The project website is available at\nhttps://www.haoranyou.com/diffcr.",
      "tldr_zh": "该研究针对Diffusion Transformers (DiTs)的高延迟和内存效率问题，提出DiffCR框架，通过可微分压缩比率动态路由计算，以优化图像生成过程。DiffCR整合了标记级路由（每个层预测标记重要性以跳过不必要计算）、层级可微分比率（不同层自动学习压缩比率）和时间步级可微分比率（噪声较大的时间步采用更高比率）。实验结果显示，在文本到图像和修复任务上，DiffCR比现有方法实现了更好的生成质量与效率权衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16822v2",
      "published_date": "2024-12-22 02:04:17 UTC",
      "updated_date": "2025-03-27 15:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:34:16.577270"
    },
    {
      "arxiv_id": "2412.16818v1",
      "title": "Unsupervised Discovery of Formulas for Mathematical Constants",
      "title_zh": "无监督发现数学常数的公式",
      "authors": [
        "Michael Shalyt",
        "Uri Seligmann",
        "Itay Beit Halachmi",
        "Ofir David",
        "Rotem Elimelech",
        "Ido Kaminer"
      ],
      "abstract": "Ongoing efforts that span over decades show a rise of AI methods for\naccelerating scientific discovery, yet accelerating discovery in mathematics\nremains a persistent challenge for AI. Specifically, AI methods were not\neffective in creation of formulas for mathematical constants because each such\nformula must be correct for infinite digits of precision, with \"near-true\"\nformulas providing no insight toward the correct ones. Consequently, formula\ndiscovery lacks a clear distance metric needed to guide automated discovery in\nthis realm.\n  In this work, we propose a systematic methodology for categorization,\ncharacterization, and pattern identification of such formulas. The key to our\nmethodology is introducing metrics based on the convergence dynamics of the\nformulas, rather than on the numerical value of the formula. These metrics\nenable the first automated clustering of mathematical formulas. We demonstrate\nthis methodology on Polynomial Continued Fraction formulas, which are\nubiquitous in their intrinsic connections to mathematical constants, and\ngeneralize many mathematical functions and structures.\n  We test our methodology on a set of 1,768,900 such formulas, identifying many\nknown formulas for mathematical constants, and discover previously unknown\nformulas for $\\pi$, $\\ln(2)$, Gauss', and Lemniscate's constants. The uncovered\npatterns enable a direct generalization of individual formulas to infinite\nfamilies, unveiling rich mathematical structures. This success paves the way\ntowards a generative model that creates formulas fulfilling specified\nmathematical properties, accelerating the rate of discovery of useful formulas.",
      "tldr_zh": "本研究提出了一种无监督方法，用于发现数学常数的公式，通过引入基于公式收敛动态的度量（如收敛速度和稳定性）来解决AI在数学发现中的挑战，避免依赖数值精度。作者对1,768,900个Polynomial Continued Fraction公式进行自动聚类，成功识别了已知公式并发现了新的表达式，如π、ln(2)、Gauss' constant和Lemniscate's constant的未知公式。这些发现揭示了数学模式，并推广到无限公式系列，为开发生成模型奠定基础，从而加速数学常数的公式发现过程。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.NT"
      ],
      "primary_category": "cs.AI",
      "comment": "8 figures, 5 tables, 28 pages including the supplementary\n  information. For a 5-minute video abstract see\n  https://recorder-v3.slideslive.com/#/share?share=97010&s=c47967e3-d585-453c-a4dd-a4fa7955dba3\n  . Code can be found at\n  https://github.com/RamanujanMachine/Blind-Delta-Algorithm",
      "pdf_url": "http://arxiv.org/pdf/2412.16818v1",
      "published_date": "2024-12-22 01:43:56 UTC",
      "updated_date": "2024-12-22 01:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:34:52.480038"
    },
    {
      "arxiv_id": "2412.16814v1",
      "title": "An Exploration of Pattern Mining with ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Weiss"
      ],
      "abstract": "This paper takes an exploratory approach to examine the use of ChatGPT for\npattern mining. It proposes an eight-step collaborative process that combines\nhuman insight with AI capabilities to extract patterns from known uses. The\npaper offers a practical demonstration of this process by creating a pattern\nlanguage for integrating Large Language Models (LLMs) with data sources and\ntools. LLMs, such as ChatGPT, are a new class of AI models that have been\ntrained on large amounts of text, and can create new content, including text,\nimages, or video. The paper also argues for adding affordances of the\nunderlying components as a new element of pattern descriptions. The primary\naudience of the paper includes pattern writers interested in pattern mining\nusing LLMs.",
      "tldr_zh": "本论文探索了使用 ChatGPT 进行 pattern mining 的可能性，提出一个八步协作过程，将人类洞察与 AI 能力相结合，从已知用途中提取模式。论文通过创建一个模式语言来实际演示该过程，展示如何整合 Large Language Models (LLMs) 与数据源和工具。论文还建议在 pattern descriptions 中添加底层组件的 affordances 作为新元素，并针对使用 LLMs 进行 pattern mining 的模式编写者提供实用指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This is the author's version of the work. The definitive version of\n  record was published in 29th European Conference on Pattern Languages of\n  Programs, People, and Practices (EuroPLOP 2024), July 3-7, 2024, Irsee,\n  Germany, ACM",
      "pdf_url": "http://arxiv.org/pdf/2412.16814v1",
      "published_date": "2024-12-22 01:27:12 UTC",
      "updated_date": "2024-12-22 01:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:35:03.498902"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 62,
  "processed_papers_count": 62,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T16:35:21.803103"
}