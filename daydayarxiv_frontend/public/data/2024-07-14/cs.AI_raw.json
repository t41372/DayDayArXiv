[
  {
    "arxiv_id": "2407.10362v3",
    "title": "LAB-Bench: Measuring Capabilities of Language Models for Biology Research",
    "authors": [
      "Jon M. Laurent",
      "Joseph D. Janizek",
      "Michael Ruzo",
      "Michaela M. Hinks",
      "Michael J. Hammerling",
      "Siddharth Narayanan",
      "Manvitha Ponnapati",
      "Andrew D. White",
      "Samuel G. Rodriques"
    ],
    "abstract": "There is widespread optimism that frontier Large Language Models (LLMs) and\nLLM-augmented systems have the potential to rapidly accelerate scientific\ndiscovery across disciplines. Today, many benchmarks exist to measure LLM\nknowledge and reasoning on textbook-style science questions, but few if any\nbenchmarks are designed to evaluate language model performance on practical\ntasks required for scientific research, such as literature search, protocol\nplanning, and data analysis. As a step toward building such benchmarks, we\nintroduce the Language Agent Biology Benchmark (LAB-Bench), a broad dataset of\nover 2,400 multiple choice questions for evaluating AI systems on a range of\npractical biology research capabilities, including recall and reasoning over\nliterature, interpretation of figures, access and navigation of databases, and\ncomprehension and manipulation of DNA and protein sequences. Importantly, in\ncontrast to previous scientific benchmarks, we expect that an AI system that\ncan achieve consistently high scores on the more difficult LAB-Bench tasks\nwould serve as a useful assistant for researchers in areas such as literature\nsearch and molecular cloning. As an initial assessment of the emergent\nscientific task capabilities of frontier language models, we measure\nperformance of several against our benchmark and report results compared to\nhuman expert biology researchers. We will continue to update and expand\nLAB-Bench over time, and expect it to serve as a useful tool in the development\nof automated research systems going forward. A public subset of LAB-Bench is\navailable for use at the following URL:\nhttps://huggingface.co/datasets/futurehouse/lab-bench",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "40 pages, 5 main figures, 1 main table, 2 supplemental figures, 4\n  supplemental tables. Submitted to NeurIPS 2024 Datasets and Benchmarks track\n  (in review)",
    "pdf_url": "http://arxiv.org/pdf/2407.10362v3",
    "published_date": "2024-07-14 23:52:25 UTC",
    "updated_date": "2024-07-17 17:28:36 UTC"
  },
  {
    "arxiv_id": "2407.10359v1",
    "title": "Evolved Developmental Artificial Neural Networks for Multitasking with Advanced Activity Dependence",
    "authors": [
      "Yintong Zhang",
      "Jason A. Yoder"
    ],
    "abstract": "Recently, Cartesian Genetic Programming has been used to evolve developmental\nprograms to guide the formation of artificial neural networks (ANNs). This\napproach has demonstrated success in enabling ANNs to perform multiple tasks\nwhile avoiding catastrophic forgetting. One unique aspect of this approach is\nthe use of separate developmental programs evolved to regulate the development\nof separate soma and dendrite units. An opportunity afforded by this approach\nis the ability to incorporate Activity Dependence (AD) into the model such that\nenvironmental feedback can help to regulate the behavior of each type of unit.\nPrevious work has shown a limited version of AD (influencing neural bias) to\nprovide marginal improvements over non-AD ANNs. In this work, we present\npromising results from new extensions to AD. Specifically, we demonstrate a\nmore significant improvement via AD on new neural parameters including health\nand position, as well as a combination of all of these along with bias. We\nreport on the implications of this work and suggest several promising\ndirections for future work.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "I.2.6; I.2.11"
    ],
    "primary_category": "cs.NE",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.10359v1",
    "published_date": "2024-07-14 23:39:07 UTC",
    "updated_date": "2024-07-14 23:39:07 UTC"
  },
  {
    "arxiv_id": "2407.10341v5",
    "title": "Affordance-Guided Reinforcement Learning via Visual Prompting",
    "authors": [
      "Olivia Y. Lee",
      "Annie Xie",
      "Kuan Fang",
      "Karl Pertsch",
      "Chelsea Finn"
    ],
    "abstract": "Robots equipped with reinforcement learning (RL) have the potential to learn\na wide range of skills solely from a reward signal. However, obtaining a robust\nand dense reward signal for general manipulation tasks remains a challenge.\nExisting learning-based approaches require significant data, such as human\ndemonstrations of success and failure, to learn task-specific reward functions.\nRecently, there is also a growing adoption of large multi-modal foundation\nmodels for robotics that can perform visual reasoning in physical contexts and\ngenerate coarse robot motions for manipulation tasks. Motivated by this range\nof capability, in this work, we present Keypoint-based Affordance Guidance for\nImprovements (KAGI), a method leveraging rewards shaped by vision-language\nmodels (VLMs) for autonomous RL. State-of-the-art VLMs have demonstrated\nimpressive reasoning about affordances through keypoints in zero-shot, and we\nuse these to define dense rewards that guide autonomous robotic learning. On\nreal-world manipulation tasks specified by natural language descriptions, KAGI\nimproves the sample efficiency of autonomous RL and enables successful task\ncompletion in 30K online fine-tuning steps. Additionally, we demonstrate the\nrobustness of KAGI to reductions in the number of in-domain demonstrations used\nfor pre-training, reaching similar performance in 45K online fine-tuning steps.\nProject website: https://sites.google.com/view/affordance-guided-rl",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures. Robotics: Science and Systems (RSS) 2024, Task\n  Specification for General-Purpose Intelligent Robots & Lifelong Robot\n  Learning Workshops",
    "pdf_url": "http://arxiv.org/pdf/2407.10341v5",
    "published_date": "2024-07-14 21:41:29 UTC",
    "updated_date": "2025-03-05 06:53:17 UTC"
  },
  {
    "arxiv_id": "2407.10340v1",
    "title": "Mapping the Scholarship of Dark Pattern Regulation: A Systematic Review of Concepts, Regulatory Paradigms, and Solutions from an Interdisciplinary Perspective",
    "authors": [
      "Weiwei Yi",
      "Zihao Li"
    ],
    "abstract": "Dark patterns, design tricks used on online interfaces to manipulate users\ndecision-making process, have raised public concerns. However, research on\nregulation of dark pattern remains underdeveloped and scattered, particularly\nregarding scholars views on the concept, regulatory paradigms, and solutions.\nFollowing PRISMA guidelines, this paper systematically reviews the formats and\ncontent of regulatory discussions on dark patterns from the interdisciplinary\nscholarship of Law and Human-Computer Interaction. A total of 65 studies were\nanalysed through content and thematic analysis. This study synthesises the\nunique trends and characteristics of legal scholarship on dark patterns,\nidentifying five root problems and triple layered harms. It critiques current\nregulations in terms of legal theories and sectoral legislations, highlighting\ntheir inadequacies in addressing dark patterns. The paper also critically\nexamines existing proposed solutions, including paradigmatic shifts in legal\ndoctrines, refinements to existing frameworks, technical design-embedded\nsolutions, and accountability measures for design practices. This research\ncritically discusses the current barriers to effective dark pattern regulations\nand explores promising regulatory solutions. The difficulty in identifying the\nnormative nature of various forms of dark patterns, in identifying evident and\nactionable harm, and the expanding scope of dark patterns connotation\ninherently hinders effective regulation. However, technical design-embedded\nsolutions, accountability frameworks, and practical design guidelines offer\npotential routes for more proactive regulation, while legal pluralism stands as\na promising macro-level change in regulatory paradigms for dark pattern\nregulation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.IT",
      "cs.SI",
      "math.IT"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10340v1",
    "published_date": "2024-07-14 21:41:18 UTC",
    "updated_date": "2024-07-14 21:41:18 UTC"
  },
  {
    "arxiv_id": "2407.10335v1",
    "title": "Towards Adapting Reinforcement Learning Agents to New Tasks: Insights from Q-Values",
    "authors": [
      "Ashwin Ramaswamy",
      "Ransalu Senanayake"
    ],
    "abstract": "While contemporary reinforcement learning research and applications have\nembraced policy gradient methods as the panacea of solving learning problems,\nvalue-based methods can still be useful in many domains as long as we can\nwrangle with how to exploit them in a sample efficient way. In this paper, we\nexplore the chaotic nature of DQNs in reinforcement learning, while\nunderstanding how the information that they retain when trained can be\nrepurposed for adapting a model to different tasks. We start by designing a\nsimple experiment in which we are able to observe the Q-values for each state\nand action in an environment. Then we train in eight different ways to explore\nhow these training algorithms affect the way that accurate Q-values are learned\n(or not learned). We tested the adaptability of each trained model when\nretrained to accomplish a slightly modified task. We then scaled our setup to\ntest the larger problem of an autonomous vehicle at an unprotected\nintersection. We observed that the model is able to adapt to new tasks quicker\nwhen the base model's Q-value estimates are closer to the true Q-values. The\nresults provide some insights and guidelines into what algorithms are useful\nfor sample efficient task adaptation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10335v1",
    "published_date": "2024-07-14 21:28:27 UTC",
    "updated_date": "2024-07-14 21:28:27 UTC"
  },
  {
    "arxiv_id": "2407.10328v1",
    "title": "The Interpretation Gap in Text-to-Music Generation Models",
    "authors": [
      "Yongyi Zang",
      "Yixiao Zhang"
    ],
    "abstract": "Large-scale text-to-music generation models have significantly enhanced music\ncreation capabilities, offering unprecedented creative freedom. However, their\nability to collaborate effectively with human musicians remains limited. In\nthis paper, we propose a framework to describe the musical interaction process,\nwhich includes expression, interpretation, and execution of controls. Following\nthis framework, we argue that the primary gap between existing text-to-music\nmodels and musicians lies in the interpretation stage, where models lack the\nability to interpret controls from musicians. We also propose two strategies to\naddress this gap and call on the music information retrieval community to\ntackle the interpretation challenge to improve human-AI musical collaboration.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2407.10328v1",
    "published_date": "2024-07-14 20:51:08 UTC",
    "updated_date": "2024-07-14 20:51:08 UTC"
  },
  {
    "arxiv_id": "2407.10327v2",
    "title": "Learning Unlabeled Clients Divergence for Federated Semi-Supervised Learning via Anchor Model Aggregation",
    "authors": [
      "Marawan Elbatel",
      "Hualiang Wang",
      "Jixiang Chen",
      "Hao Wang",
      "Xiaomeng Li"
    ],
    "abstract": "Federated semi-supervised learning (FedSemi) refers to scenarios where there\nmay be clients with fully labeled data, clients with partially labeled, and\neven fully unlabeled clients while preserving data privacy. However, challenges\narise from client drift due to undefined heterogeneous class distributions and\nerroneous pseudo-labels. Existing FedSemi methods typically fail to aggregate\nmodels from unlabeled clients due to their inherent unreliability, thus\noverlooking unique information from their heterogeneous data distribution,\nleading to sub-optimal results. In this paper, we enable unlabeled client\naggregation through SemiAnAgg, a novel Semi-supervised Anchor-Based federated\nAggregation. SemiAnAgg learns unlabeled client contributions via an anchor\nmodel, effectively harnessing their informative value. Our key idea is that by\nfeeding local client data to the same global model and the same consistently\ninitialized anchor model (i.e., random model), we can measure the importance of\neach unlabeled client accordingly. Extensive experiments demonstrate that\nSemiAnAgg achieves new state-of-the-art results on four widely used FedSemi\nbenchmarks, leading to substantial performance improvements: a 9% increase in\naccuracy on CIFAR-100 and a 7.6% improvement in recall on the medical dataset\nISIC-18, compared with prior state-of-the-art. Code is available at:\nhttps://github.com/xmed-lab/SemiAnAgg.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by TMLR (10/2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.10327v2",
    "published_date": "2024-07-14 20:50:40 UTC",
    "updated_date": "2024-10-25 14:39:37 UTC"
  },
  {
    "arxiv_id": "2407.14540v1",
    "title": "Risks of uncertainty propagation in Al-augmented security pipelines",
    "authors": [
      "Emanuele Mezzi",
      "Aurora Papotti",
      "Fabio Massacci",
      "Katja Tuma"
    ],
    "abstract": "The use of AI technologies is percolating into the secure development of\nsoftware-based systems, with an increasing trend of composing AI-based\nsubsystems (with uncertain levels of performance) into automated pipelines.\nThis presents a fundamental research challenge and poses a serious threat to\nsafety-critical domains (e.g., aviation). Despite the existing knowledge about\nuncertainty in risk analysis, no previous work has estimated the uncertainty of\nAI-augmented systems given the propagation of errors in the pipeline. We\nprovide the formal underpinnings for capturing uncertainty propagation, develop\na simulator to quantify uncertainty, and evaluate the simulation of propagating\nerrors with two case studies. We discuss the generalizability of our approach\nand present policy implications and recommendations for aviation. Future work\nincludes extending the approach and investigating the required metrics for\nvalidation in the aviation domain.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14540v1",
    "published_date": "2024-07-14 19:02:20 UTC",
    "updated_date": "2024-07-14 19:02:20 UTC"
  },
  {
    "arxiv_id": "2407.10279v2",
    "title": "AlphaDou: High-Performance End-to-End Doudizhu AI Integrating Bidding",
    "authors": [
      "Chang Lei",
      "Huan Lei"
    ],
    "abstract": "Artificial intelligence for card games has long been a popular topic in AI\nresearch. In recent years, complex card games like Mahjong and Texas Hold'em\nhave been solved, with corresponding AI programs reaching the level of human\nexperts. However, the game of Doudizhu presents significant challenges due to\nits vast state/action space and unique characteristics involving reasoning\nabout competition and cooperation, making the game extremely difficult to\nsolve.The RL model Douzero, trained using the Deep Monte Carlo algorithm\nframework, has shown excellent performance in Doudizhu. However, there are\ndifferences between its simplified game environment and the actual Doudizhu\nenvironment, and its performance is still a considerable distance from that of\nhuman experts. This paper modifies the Deep Monte Carlo algorithm framework by\nusing reinforcement learning to obtain a neural network that simultaneously\nestimates win rates and expectations. The action space is pruned using\nexpectations, and strategies are generated based on win rates. The modified\nalgorithm enables the AI to perform the full range of tasks in the Doudizhu\ngame, including bidding and cardplay. The model was trained in a actual\nDoudizhu environment and achieved state-of-the-art performance among publicly\navailable models. We hope that this new framework will provide valuable\ninsights for AI development in other bidding-based games.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10279v2",
    "published_date": "2024-07-14 17:32:36 UTC",
    "updated_date": "2024-09-13 15:17:06 UTC"
  },
  {
    "arxiv_id": "2407.10277v1",
    "title": "Disrupting Diffusion-based Inpainters with Semantic Digression",
    "authors": [
      "Geonho Son",
      "Juhun Lee",
      "Simon S. Woo"
    ],
    "abstract": "The fabrication of visual misinformation on the web and social media has\nincreased exponentially with the advent of foundational text-to-image diffusion\nmodels. Namely, Stable Diffusion inpainters allow the synthesis of maliciously\ninpainted images of personal and private figures, and copyrighted contents,\nalso known as deepfakes. To combat such generations, a disruption framework,\nnamely Photoguard, has been proposed, where it adds adversarial noise to the\ncontext image to disrupt their inpainting synthesis. While their framework\nsuggested a diffusion-friendly approach, the disruption is not sufficiently\nstrong and it requires a significant amount of GPU and time to immunize the\ncontext image. In our work, we re-examine both the minimal and favorable\nconditions for a successful inpainting disruption, proposing DDD, a \"Digression\nguided Diffusion Disruption\" framework. First, we identify the most\nadversarially vulnerable diffusion timestep range with respect to the hidden\nspace. Within this scope of noised manifold, we pose the problem as a semantic\ndigression optimization. We maximize the distance between the inpainting\ninstance's hidden states and a semantic-aware hidden state centroid, calibrated\nboth by Monte Carlo sampling of hidden states and a discretely projected\noptimization in the token space. Effectively, our approach achieves stronger\ndisruption and a higher success rate than Photoguard while lowering the GPU\nmemory requirement, and speeding the optimization up to three times faster.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 13 figures, IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.10277v1",
    "published_date": "2024-07-14 17:21:19 UTC",
    "updated_date": "2024-07-14 17:21:19 UTC"
  },
  {
    "arxiv_id": "2407.10275v2",
    "title": "Cross-Lingual Multi-Hop Knowledge Editing",
    "authors": [
      "Aditi Khandelwal",
      "Harman Singh",
      "Hengrui Gu",
      "Tianlong Chen",
      "Kaixiong Zhou"
    ],
    "abstract": "Large language models are often expected to constantly adapt to new sources\nof knowledge and knowledge editing techniques aim to efficiently patch the\noutdated model knowledge, with minimal modification. Most prior works focus on\nmonolingual knowledge editing in English, even though new information can\nemerge in any language from any part of the world. We propose the Cross-Lingual\nMulti-Hop Knowledge Editing paradigm, for measuring and analyzing the\nperformance of various SoTA knowledge editing techniques in a cross-lingual\nsetup. Specifically, we create a parallel cross-lingual benchmark,\nCROLIN-MQUAKE for measuring the knowledge editing capabilities. Our extensive\nanalysis over various knowledge editing techniques uncover significant gaps in\nperformance between the cross-lingual and English-centric setting. Following\nthis, we propose a significantly improved system for cross-lingual multi-hop\nknowledge editing, CLEVER-CKE. CLEVER-CKE is based on a retrieve, verify and\ngenerate knowledge editing framework, where a retriever is formulated to recall\nedited facts and support an LLM to adhere to knowledge edits. We develop\nlanguage-aware and hard-negative based contrastive objectives for improving the\ncross-lingual and fine-grained fact retrieval and verification process used in\nthis framework. Extensive experiments on three LLMs, eight languages, and two\ndatasets show CLEVER-CKE's significant gains of up to 30% over prior methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10275v2",
    "published_date": "2024-07-14 17:18:16 UTC",
    "updated_date": "2025-02-15 19:17:33 UTC"
  },
  {
    "arxiv_id": "2407.10240v3",
    "title": "xLSTMTime : Long-term Time Series Forecasting With xLSTM",
    "authors": [
      "Musleh Alharthi",
      "Ausif Mahmood"
    ],
    "abstract": "In recent years, transformer-based models have gained prominence in\nmultivariate long-term time series forecasting (LTSF), demonstrating\nsignificant advancements despite facing challenges such as high computational\ndemands, difficulty in capturing temporal dynamics, and managing long-term\ndependencies. The emergence of LTSF-Linear, with its straightforward linear\narchitecture, has notably outperformed transformer-based counterparts,\nprompting a reevaluation of the transformer's utility in time series\nforecasting. In response, this paper presents an adaptation of a recent\narchitecture termed extended LSTM (xLSTM) for LTSF. xLSTM incorporates\nexponential gating and a revised memory structure with higher capacity that has\ngood potential for LTSF. Our adopted architecture for LTSF termed as xLSTMTime\nsurpasses current approaches. We compare xLSTMTime's performance against\nvarious state-of-the-art models across multiple real-world da-tasets,\ndemonstrating superior forecasting capabilities. Our findings suggest that\nrefined recurrent architectures can offer competitive alternatives to\ntransformer-based models in LTSF tasks, po-tentially redefining the landscape\nof time series forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10240v3",
    "published_date": "2024-07-14 15:15:00 UTC",
    "updated_date": "2024-08-12 02:10:34 UTC"
  },
  {
    "arxiv_id": "2407.10233v1",
    "title": "Visual Prompt Selection for In-Context Learning Segmentation",
    "authors": [
      "Wei Suo",
      "Lanqing Lai",
      "Mengyang Sun",
      "Hanwang Zhang",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "abstract": "As a fundamental and extensively studied task in computer vision, image\nsegmentation aims to locate and identify different semantic concepts at the\npixel level. Recently, inspired by In-Context Learning (ICL), several\ngeneralist segmentation frameworks have been proposed, providing a promising\nparadigm for segmenting specific objects. However, existing works mostly ignore\nthe value of visual prompts or simply apply similarity sorting to select\ncontextual examples. In this paper, we focus on rethinking and improving the\nexample selection strategy. By comprehensive comparisons, we first demonstrate\nthat ICL-based segmentation models are sensitive to different contexts.\nFurthermore, empirical evidence indicates that the diversity of contextual\nprompts plays a crucial role in guiding segmentation. Based on the above\ninsights, we propose a new stepwise context search method. Different from\nprevious works, we construct a small yet rich candidate pool and adaptively\nsearch the well-matched contexts. More importantly, this method effectively\nreduces the annotation cost by compacting the search space. Extensive\nexperiments show that our method is an effective strategy for selecting\nexamples and enhancing segmentation performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accept by ECCV2024",
    "pdf_url": "http://arxiv.org/pdf/2407.10233v1",
    "published_date": "2024-07-14 15:02:54 UTC",
    "updated_date": "2024-07-14 15:02:54 UTC"
  },
  {
    "arxiv_id": "2407.10207v3",
    "title": "Learning to Steer Markovian Agents under Model Uncertainty",
    "authors": [
      "Jiawei Huang",
      "Vinzenz Thoma",
      "Zebang Shen",
      "Heinrich H. Nax",
      "Niao He"
    ],
    "abstract": "Designing incentives for an adapting population is a ubiquitous problem in a\nwide array of economic applications and beyond. In this work, we study how to\ndesign additional rewards to steer multi-agent systems towards desired policies\n\\emph{without} prior knowledge of the agents' underlying learning dynamics.\nMotivated by the limitation of existing works, we consider a new and general\ncategory of learning dynamics called \\emph{Markovian agents}. We introduce a\nmodel-based non-episodic Reinforcement Learning (RL) formulation for our\nsteering problem. Importantly, we focus on learning a \\emph{history-dependent}\nsteering strategy to handle the inherent model uncertainty about the agents'\nlearning dynamics. We introduce a novel objective function to encode the\ndesiderata of achieving a good steering outcome with reasonable cost.\nTheoretically, we identify conditions for the existence of steering strategies\nto guide agents to the desired policies. Complementing our theoretical\ncontributions, we provide empirical algorithms to approximately solve our\nobjective, which effectively tackles the challenge in learning\nhistory-dependent strategies. We demonstrate the efficacy of our algorithms\nthrough empirical evaluations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "35 Pages; ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.10207v3",
    "published_date": "2024-07-14 14:01:38 UTC",
    "updated_date": "2025-02-08 17:23:27 UTC"
  },
  {
    "arxiv_id": "2407.10206v1",
    "title": "Dominant Design Prediction with Phylogenetic Networks",
    "authors": [
      "Youwei He",
      "Jeong-Dong Lee",
      "Dawoon Jeong",
      "Sungjun Choi",
      "Jiyong Kim"
    ],
    "abstract": "This study proposes an effective method to predict technology development\nfrom an evolutionary perspective. Product evolution is the result of\ntechnological evolution and market selection. A phylogenetic network is the\nmain method to study product evolution. The formation of the dominant design\ndetermines the trajectory of technology development. How to predict future\ndominant design has become a key issue in technology forecasting and new\nproduct development. We define the dominant product and use machine learning\nmethods, combined with product evolutionary theory, to construct a Fully\nConnected Phylogenetic Network dataset to effectively predict the future\ndominant design.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.NE",
      "cs.SI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10206v1",
    "published_date": "2024-07-14 14:00:02 UTC",
    "updated_date": "2024-07-14 14:00:02 UTC"
  },
  {
    "arxiv_id": "2407.10200v1",
    "title": "Shape2Scene: 3D Scene Representation Learning Through Pre-training on Shape Data",
    "authors": [
      "Tuo Feng",
      "Wenguan Wang",
      "Ruijie Quan",
      "Yi Yang"
    ],
    "abstract": "Current 3D self-supervised learning methods of 3D scenes face a data desert\nissue, resulting from the time-consuming and expensive collecting process of 3D\nscene data. Conversely, 3D shape datasets are easier to collect. Despite this,\nexisting pre-training strategies on shape data offer limited potential for 3D\nscene understanding due to significant disparities in point quantities. To\ntackle these challenges, we propose Shape2Scene (S2S), a novel method that\nlearns representations of large-scale 3D scenes from 3D shape data. We first\ndesign multiscale and high-resolution backbones for shape and scene level 3D\ntasks, i.e., MH-P (point-based) and MH-V (voxel-based). MH-P/V establishes\ndirect paths to highresolution features that capture deep semantic information\nacross multiple scales. This pivotal nature makes them suitable for a wide\nrange of 3D downstream tasks that tightly rely on high-resolution features. We\nthen employ a Shape-to-Scene strategy (S2SS) to amalgamate points from various\nshapes, creating a random pseudo scene (comprising multiple objects) for\ntraining data, mitigating disparities between shapes and scenes. Finally, a\npoint-point contrastive loss (PPC) is applied for the pre-training of MH-P/V.\nIn PPC, the inherent correspondence (i.e., point pairs) is naturally obtained\nin S2SS. Extensive experiments have demonstrated the transferability of 3D\nrepresentations learned by MH-P/V across shape-level and scene-level 3D tasks.\nMH-P achieves notable performance on well-known point cloud datasets (93.8% OA\non ScanObjectNN and 87.6% instance mIoU on ShapeNetPart). MH-V also achieves\npromising performance in 3D semantic segmentation and 3D object detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024; Project page: https://github.com/FengZicai/S2S",
    "pdf_url": "http://arxiv.org/pdf/2407.10200v1",
    "published_date": "2024-07-14 13:42:05 UTC",
    "updated_date": "2024-07-14 13:42:05 UTC"
  },
  {
    "arxiv_id": "2407.10196v1",
    "title": "A3S: A General Active Clustering Method with Pairwise Constraints",
    "authors": [
      "Xun Deng",
      "Junlong Liu",
      "Han Zhong",
      "Fuli Feng",
      "Chen Shen",
      "Xiangnan He",
      "Jieping Ye",
      "Zheng Wang"
    ],
    "abstract": "Active clustering aims to boost the clustering performance by integrating\nhuman-annotated pairwise constraints through strategic querying. Conventional\napproaches with semi-supervised clustering schemes encounter high query costs\nwhen applied to large datasets with numerous classes. To address these\nlimitations, we propose a novel Adaptive Active Aggregation and Splitting (A3S)\nframework, falling within the cluster-adjustment scheme in active clustering.\nA3S features strategic active clustering adjustment on the initial cluster\nresult, which is obtained by an adaptive clustering algorithm. In particular,\nour cluster adjustment is inspired by the quantitative analysis of Normalized\nmutual information gain under the information theory framework and can provably\nimprove the clustering quality. The proposed A3S framework significantly\nelevates the performance and scalability of active clustering. In extensive\nexperiments across diverse real-world datasets, A3S achieves desired results\nwith significantly fewer human queries compared with existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10196v1",
    "published_date": "2024-07-14 13:37:03 UTC",
    "updated_date": "2024-07-14 13:37:03 UTC"
  },
  {
    "arxiv_id": "2407.10194v1",
    "title": "Curriculum Learning for Small Code Language Models",
    "authors": [
      "Marwa Naïr",
      "Kamel Yamani",
      "Lynda Said Lhadj",
      "Riyadh Baghdadi"
    ],
    "abstract": "Code language models have emerged as useful tools for various programming\ntasks, yet they often struggle when it comes to complex ones. In this paper, we\nexplore the potential of curriculum learning in enhancing the performance of\nthese models. While prior research has suggested that curriculum learning does\nnot necessarily help in improving the performance of language models, our\nresults surprisingly show that this may not be the case for code language\nmodels. We demonstrate that a well-designed curriculum learning approach\nsignificantly improves the accuracy of small decoder-only code language models\non the task of code execution, while its effect on code completion is less\nsignificant. To explore the potential of curriculum learning, we train multiple\nGPT models with 1 million parameters each to predict the next token and\nevaluate them on code completion and execution tasks. Our contributions include\nproposing a novel code difficulty assessment metric by combining software code\nmeasures, investigating the effectiveness of Curriculum Learning for code\nlanguage models, and introducing a Novel Curriculum Learning schedule that\nenhances the performance of small decoder-only language models in code\nexecution tasks. The results of this paper open the door for more research on\nthe use of curriculum learning for code language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "ACL Student Research Workshop 2024 camera-ready",
    "pdf_url": "http://arxiv.org/pdf/2407.10194v1",
    "published_date": "2024-07-14 13:32:24 UTC",
    "updated_date": "2024-07-14 13:32:24 UTC"
  },
  {
    "arxiv_id": "2407.10167v4",
    "title": "Key-Point-Driven Mathematical Reasoning Distillation of Large Language Model",
    "authors": [
      "Xunyu Zhu",
      "Jian Li",
      "Can Ma",
      "Weiping Wang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional proficiency in\nmathematical reasoning tasks due to their extensive parameter counts and\ntraining on vast datasets. Despite these capabilities, deploying LLMs is\nhindered by their computational demands. Distilling LLM mathematical reasoning\ninto Smaller Language Models (SLMs) has emerged as a solution to this\nchallenge, although these smaller models often suffer from errors in\ncalculation and semantic understanding. Prior work has proposed\nProgram-of-Thought Distillation (PoTD) to avoid calculation error. To further\naddress semantic understanding errors, we propose Key-Point-Driven Mathematical\nReasoning Distillation (KPDD). KPDD enhances the reasoning performance of SLMs\nby breaking down the problem-solving process into three stages: Core Question\nExtraction, Problem-Solving Information Extraction, and Step-by-Step Solution.\nThis method is further divided into KPDD-CoT, which generates Chain-of-Thought\nrationales, and KPDD-PoT, which creates Program-of-Thought rationales. The\nexperiment results show that KPDD-CoT significantly improves reasoning\nabilities, while KPDD-PoT achieves state-of-the-art performance in mathematical\nreasoning tasks. Our approach effectively mitigates misunderstanding errors,\nadvancing the deployment of efficient and capable SLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Major Updates:1.fix faults in the error analysis, 2. improve our\n  method, 3. use ChatGPT as teacher LLMs to ensure fairness in performance\n  comparisons",
    "pdf_url": "http://arxiv.org/pdf/2407.10167v4",
    "published_date": "2024-07-14 11:41:03 UTC",
    "updated_date": "2024-10-10 11:17:10 UTC"
  },
  {
    "arxiv_id": "2407.11086v1",
    "title": "Pre-training with Fractional Denoising to Enhance Molecular Property Prediction",
    "authors": [
      "Yuyan Ni",
      "Shikun Feng",
      "Xin Hong",
      "Yuancheng Sun",
      "Wei-Ying Ma",
      "Zhi-Ming Ma",
      "Qiwei Ye",
      "Yanyan Lan"
    ],
    "abstract": "Deep learning methods have been considered promising for accelerating\nmolecular screening in drug discovery and material design. Due to the limited\navailability of labelled data, various self-supervised molecular pre-training\nmethods have been presented. While many existing methods utilize common\npre-training tasks in computer vision (CV) and natural language processing\n(NLP), they often overlook the fundamental physical principles governing\nmolecules. In contrast, applying denoising in pre-training can be interpreted\nas an equivalent force learning, but the limited noise distribution introduces\nbias into the molecular distribution. To address this issue, we introduce a\nmolecular pre-training framework called fractional denoising (Frad), which\ndecouples noise design from the constraints imposed by force learning\nequivalence. In this way, the noise becomes customizable, allowing for\nincorporating chemical priors to significantly improve molecular distribution\nmodeling. Experiments demonstrate that our framework consistently outperforms\nexisting methods, establishing state-of-the-art results across force\nprediction, quantum chemical properties, and binding affinity tasks. The\nrefined noise design enhances force accuracy and sampling coverage, which\ncontribute to the creation of physically consistent molecular representations,\nultimately leading to superior predictive performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11086v1",
    "published_date": "2024-07-14 11:09:42 UTC",
    "updated_date": "2024-07-14 11:09:42 UTC"
  },
  {
    "arxiv_id": "2407.10162v1",
    "title": "ChatLogic: Integrating Logic Programming with Large Language Models for Multi-Step Reasoning",
    "authors": [
      "Zhongsheng Wang",
      "Jiamou Liu",
      "Qiming Bao",
      "Hongfei Rong",
      "Jingfeng Zhang"
    ],
    "abstract": "Large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated\nimpressive capabilities in various generative tasks. However, their performance\nis often hampered by limitations in accessing and leveraging long-term memory,\nleading to specific vulnerabilities and biases, especially during long\ninteractions. This paper introduces ChatLogic, an innovative framework\nspecifically targeted at LLM reasoning tasks that can enhance the performance\nof LLMs in multi-step deductive reasoning tasks by integrating logic\nprogramming. In ChatLogic, the language model plays a central role, acting as a\ncontroller and participating in every system operation stage. We propose a\nnovel method of converting logic problems into symbolic integration with an\ninference engine. This approach leverages large language models' situational\nunderstanding and imitation skills and uses symbolic memory to enhance\nmulti-step deductive reasoning capabilities. Our results show that the\nChatLogic framework significantly improves the multi-step reasoning\ncapabilities of LLMs. The source code and data are available at\n\\url{https://github.com/Strong-AI-Lab/ChatLogic}",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 3 figures. This paper has been accepted by WCCI IJCNN 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.10162v1",
    "published_date": "2024-07-14 11:06:43 UTC",
    "updated_date": "2024-07-14 11:06:43 UTC"
  },
  {
    "arxiv_id": "2407.10153v1",
    "title": "Look Within, Why LLMs Hallucinate: A Causal Perspective",
    "authors": [
      "He Li",
      "Haoang Chi",
      "Mingyu Liu",
      "Wenjing Yang"
    ],
    "abstract": "The emergence of large language models (LLMs) is a milestone in generative\nartificial intelligence, achieving significant success in text comprehension\nand generation tasks. Despite the tremendous success of LLMs in many downstream\ntasks, they suffer from severe hallucination problems, posing significant\nchallenges to the practical applications of LLMs. Most of the works about LLMs'\nhallucinations focus on data quality. Self-attention is a core module in\ntransformer-based LLMs, while its potential relationship with LLMs'\nhallucination has been hardly investigated. To fill this gap, we study this\nproblem from a causal perspective. We propose a method to intervene in LLMs'\nself-attention layers and maintain their structures and sizes intact.\nSpecifically, we disable different self-attention layers in several popular\nopen-source LLMs and then compare their degrees of hallucination with the\noriginal ones. We evaluate the intervened LLMs on hallucination assessment\nbenchmarks and conclude that disabling some specific self-attention layers in\nthe front or tail of the LLMs can alleviate hallucination issues. The study\npaves a new way for understanding and mitigating LLMs' hallucinations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.10153v1",
    "published_date": "2024-07-14 10:47:44 UTC",
    "updated_date": "2024-07-14 10:47:44 UTC"
  },
  {
    "arxiv_id": "2407.11085v1",
    "title": "SpreadFGL: Edge-Client Collaborative Federated Graph Learning with Adaptive Neighbor Generation",
    "authors": [
      "Luying Zhong",
      "Yueyang Pi",
      "Zheyi Chen",
      "Zhengxin Yu",
      "Wang Miao",
      "Xing Chen",
      "Geyong Min"
    ],
    "abstract": "Federated Graph Learning (FGL) has garnered widespread attention by enabling\ncollaborative training on multiple clients for semi-supervised classification\ntasks. However, most existing FGL studies do not well consider the missing\ninter-client topology information in real-world scenarios, causing insufficient\nfeature aggregation of multi-hop neighbor clients during model training.\nMoreover, the classic FGL commonly adopts the FedAvg but neglects the high\ntraining costs when the number of clients expands, resulting in the overload of\na single edge server. To address these important challenges, we propose a novel\nFGL framework, named SpreadFGL, to promote the information flow in edge-client\ncollaboration and extract more generalized potential relationships between\nclients. In SpreadFGL, an adaptive graph imputation generator incorporated with\na versatile assessor is first designed to exploit the potential links between\nsubgraphs, without sharing raw data. Next, a new negative sampling mechanism is\ndeveloped to make SpreadFGL concentrate on more refined information in\ndownstream tasks. To facilitate load balancing at the edge layer, SpreadFGL\nfollows a distributed training manner that enables fast model convergence.\nUsing real-world testbed and benchmark graph datasets, extensive experiments\ndemonstrate the effectiveness of the proposed SpreadFGL. The results show that\nSpreadFGL achieves higher accuracy and faster convergence against\nstate-of-the-art algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11085v1",
    "published_date": "2024-07-14 09:34:19 UTC",
    "updated_date": "2024-07-14 09:34:19 UTC"
  },
  {
    "arxiv_id": "2407.10115v1",
    "title": "A Bag of Tricks for Scaling CPU-based Deep FFMs to more than 300m Predictions per Second",
    "authors": [
      "Blaž Škrlj",
      "Benjamin Ben-Shalom",
      "Grega Gašperšič",
      "Adi Schwartz",
      "Ramzi Hoseisi",
      "Naama Ziporin",
      "Davorin Kopič",
      "Andraž Tori"
    ],
    "abstract": "Field-aware Factorization Machines (FFMs) have emerged as a powerful model\nfor click-through rate prediction, particularly excelling in capturing complex\nfeature interactions. In this work, we present an in-depth analysis of our\nin-house, Rust-based Deep FFM implementation, and detail its deployment on a\nCPU-only, multi-data-center scale. We overview key optimizations devised for\nboth training and inference, demonstrated by previously unpublished benchmark\nresults in efficient model search and online training. Further, we detail an\nin-house weight quantization that resulted in more than an order of magnitude\nreduction in bandwidth footprint related to weight transfers across\ndata-centres. We disclose the engine and associated techniques under an\nopen-source license to contribute to the broader machine learning community.\nThis paper showcases one of the first successful CPU-only deployments of Deep\nFFMs at such scale, marking a significant stride in practical, low-footprint\nclick-through rate prediction methodologies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "6p, KDD2024 - AdKDD workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.10115v1",
    "published_date": "2024-07-14 08:10:20 UTC",
    "updated_date": "2024-07-14 08:10:20 UTC"
  },
  {
    "arxiv_id": "2407.10105v1",
    "title": "Hierarchical Multi-modal Transformer for Cross-modal Long Document Classification",
    "authors": [
      "Tengfei Liu",
      "Yongli Hu",
      "Junbin Gao",
      "Yanfeng Sun",
      "Baocai Yin"
    ],
    "abstract": "Long Document Classification (LDC) has gained significant attention recently.\nHowever, multi-modal data in long documents such as texts and images are not\nbeing effectively utilized. Prior studies in this area have attempted to\nintegrate texts and images in document-related tasks, but they have only\nfocused on short text sequences and images of pages. How to classify long\ndocuments with hierarchical structure texts and embedding images is a new\nproblem and faces multi-modal representation difficulties. In this paper, we\npropose a novel approach called Hierarchical Multi-modal Transformer (HMT) for\ncross-modal long document classification. The HMT conducts multi-modal feature\ninteraction and fusion between images and texts in a hierarchical manner. Our\napproach uses a multi-modal transformer and a dynamic multi-scale multi-modal\ntransformer to model the complex relationships between image features, and the\nsection and sentence features. Furthermore, we introduce a new interaction\nstrategy called the dynamic mask transfer module to integrate these two\ntransformers by propagating features between them. To validate our approach, we\nconduct cross-modal LDC experiments on two newly created and two publicly\navailable multi-modal long document datasets, and the results show that the\nproposed HMT outperforms state-of-the-art single-modality and multi-modality\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE Transactions on Multimedia",
    "pdf_url": "http://arxiv.org/pdf/2407.10105v1",
    "published_date": "2024-07-14 07:12:25 UTC",
    "updated_date": "2024-07-14 07:12:25 UTC"
  },
  {
    "arxiv_id": "2407.10104v1",
    "title": "A Self-Supervised Learning Pipeline for Demographically Fair Facial Attribute Classification",
    "authors": [
      "Sreeraj Ramachandran",
      "Ajita Rattani"
    ],
    "abstract": "Published research highlights the presence of demographic bias in automated\nfacial attribute classification. The proposed bias mitigation techniques are\nmostly based on supervised learning, which requires a large amount of labeled\ntraining data for generalizability and scalability. However, labeled data is\nlimited, requires laborious annotation, poses privacy risks, and can perpetuate\nhuman bias. In contrast, self-supervised learning (SSL) capitalizes on freely\navailable unlabeled data, rendering trained models more scalable and\ngeneralizable. However, these label-free SSL models may also introduce biases\nby sampling false negative pairs, especially at low-data regimes 200K images)\nunder low compute settings. Further, SSL-based models may suffer from\nperformance degradation due to a lack of quality assurance of the unlabeled\ndata sourced from the web. This paper proposes a fully self-supervised pipeline\nfor demographically fair facial attribute classifiers. Leveraging completely\nunlabeled data pseudolabeled via pre-trained encoders, diverse data curation\ntechniques, and meta-learning-based weighted contrastive learning, our method\nsignificantly outperforms existing SSL approaches proposed for downstream image\nclassification tasks. Extensive evaluations on the FairFace and CelebA datasets\ndemonstrate the efficacy of our pipeline in obtaining fair performance over\nexisting baselines. Thus, setting a new benchmark for SSL in the fairness of\nfacial attribute classification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, IJCB 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.10104v1",
    "published_date": "2024-07-14 07:11:57 UTC",
    "updated_date": "2024-07-14 07:11:57 UTC"
  },
  {
    "arxiv_id": "2407.10090v1",
    "title": "ReactAIvate: A Deep Learning Approach to Predicting Reaction Mechanisms and Unmasking Reactivity Hotspots",
    "authors": [
      "Ajnabiul Hoque",
      "Manajit Das",
      "Mayank Baranwal",
      "Raghavan B. Sunoj"
    ],
    "abstract": "A chemical reaction mechanism (CRM) is a sequence of molecular-level events\ninvolving bond-breaking/forming processes, generating transient intermediates\nalong the reaction pathway as reactants transform into products. Understanding\nsuch mechanisms is crucial for designing and discovering new reactions. One of\nthe currently available methods to probe CRMs is quantum mechanical (QM)\ncomputations. The resource-intensive nature of QM methods and the scarcity of\nmechanism-based datasets motivated us to develop reliable ML models for\npredicting mechanisms. In this study, we created a comprehensive dataset with\nseven distinct classes, each representing uniquely characterized elementary\nsteps. Subsequently, we developed an interpretable attention-based GNN that\nachieved near-unity and 96% accuracy, respectively for reaction step\nclassification and the prediction of reactive atoms in each such step,\ncapturing interactions between the broader reaction context and local active\nregions. The near-perfect classification enables accurate prediction of both\nindividual events and the entire CRM, mitigating potential drawbacks of Seq2Seq\napproaches, where a wrongly predicted character leads to incoherent CRM\nidentification. In addition to interpretability, our model adeptly identifies\nkey atom(s) even from out-of-distribution classes. This generalizabilty allows\nfor the inclusion of new reaction types in a modular fashion, thus will be of\nvalue to experts for understanding the reactivity of new molecules.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "Accepted to 27th ECAI main track",
    "pdf_url": "http://arxiv.org/pdf/2407.10090v1",
    "published_date": "2024-07-14 05:53:18 UTC",
    "updated_date": "2024-07-14 05:53:18 UTC"
  },
  {
    "arxiv_id": "2407.10086v2",
    "title": "Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine",
    "authors": [
      "Omid Rohanian",
      "Mohammadmahdi Nouriborji",
      "Olena Seminog",
      "Rodrigo Furst",
      "Thomas Mendy",
      "Shanthi Levanita",
      "Zaharat Kadri-Alabi",
      "Nusrat Jabin",
      "Daniela Toale",
      "Georgina Humphreys",
      "Emilia Antonio",
      "Adrian Bucher",
      "Alice Norton",
      "David A. Clifton"
    ],
    "abstract": "This paper introduces the Pandemic PACT Advanced Categorisation Engine\n(PPACE) along with its associated dataset. PPACE is a fine-tuned model\ndeveloped to automatically classify research abstracts from funded biomedical\nprojects according to WHO-aligned research priorities. This task is crucial for\nmonitoring research trends and identifying gaps in global health preparedness\nand response. Our approach builds on human-annotated projects, which are\nallocated one or more categories from a predefined list. A large language model\nis then used to generate `rationales' explaining the reasoning behind these\nannotations. This augmented data, comprising expert annotations and rationales,\nis subsequently used to fine-tune a smaller, more efficient model. Developed as\npart of the Pandemic PACT project, which aims to track and analyse research\nfunding and clinical evidence for a wide range of diseases with outbreak\npotential, PPACE supports informed decision-making by research funders,\npolicymakers, and independent researchers. We introduce and release both the\ntrained model and the instruction-based dataset used for its training. Our\nevaluation shows that PPACE significantly outperforms its baselines. The\nrelease of PPACE and its associated dataset offers valuable resources for\nresearchers in multilabel biomedical document classification and supports\nadvancements in aligning biomedical research with key global health priorities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10086v2",
    "published_date": "2024-07-14 05:22:53 UTC",
    "updated_date": "2024-07-19 14:28:26 UTC"
  },
  {
    "arxiv_id": "2407.10078v2",
    "title": "Data Imputation using Large Language Model to Accelerate Recommendation System",
    "authors": [
      "Zhicheng Ding",
      "Jiahao Tian",
      "Zhenkai Wang",
      "Jinman Zhao",
      "Siyang Li"
    ],
    "abstract": "This paper aims to address the challenge of sparse and missing data in\nrecommendation systems, a significant hurdle in the age of big data.\nTraditional imputation methods struggle to capture complex relationships within\nthe data. We propose a novel approach that fine-tune Large Language Model (LLM)\nand use it impute missing data for recommendation systems. LLM which is trained\non vast amounts of text, is able to understand complex relationship among data\nand intelligently fill in missing information. This enriched data is then used\nby the recommendation system to generate more accurate and personalized\nsuggestions, ultimately enhancing the user experience. We evaluate our\nLLM-based imputation method across various tasks within the recommendation\nsystem domain, including single classification, multi-classification, and\nregression compared to traditional data imputation methods. By demonstrating\nthe superiority of LLM imputation over traditional methods, we establish its\npotential for improving recommendation system performance.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10078v2",
    "published_date": "2024-07-14 04:53:36 UTC",
    "updated_date": "2024-08-07 21:05:44 UTC"
  },
  {
    "arxiv_id": "2407.20236v1",
    "title": "Artificial Intelligence from Idea to Implementation. How Can AI Reshape the Education Landscape?",
    "authors": [
      "Catalin Vrabie"
    ],
    "abstract": "This introductory chapter provides an overview of the evolution and impact of\nArtificial Intelligence technologies in today society. Beginning with a\nhistorical context while exploring a few general definitions of AI, the author\nprovides a timeline of the used technologies, highlighting its periods of\nstagnation, commonly referred to as AI winters, and the subsequent resurgence\nfueled by relentless enthusiasm and investment. The narrative then transitions\nto focus on the transformative effects of AI on society at large, with a\nparticular emphasis on educational applications. Through examples, the paper\nshows how AI technologies have moved from theoretical constructs to practical\ntools that are reshaping pedagogical approaches and student engagement. The\nessay concludes by discussing the prospects of AI in education, emphasizing the\nneed for a balanced approach that considers both technological advancements and\nsocietal implications.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "33 pages, book chapter",
    "pdf_url": "http://arxiv.org/pdf/2407.20236v1",
    "published_date": "2024-07-14 04:40:16 UTC",
    "updated_date": "2024-07-14 04:40:16 UTC"
  },
  {
    "arxiv_id": "2407.10058v2",
    "title": "Learning to Refuse: Towards Mitigating Privacy Risks in LLMs",
    "authors": [
      "Zhenhua Liu",
      "Tong Zhu",
      "Chuanyuan Tan",
      "Wenliang Chen"
    ],
    "abstract": "Large language models (LLMs) exhibit remarkable capabilities in understanding\nand generating natural language. However, these models can inadvertently\nmemorize private information, posing significant privacy risks. This study\naddresses the challenge of enabling LLMs to protect specific individuals'\nprivate data without the need for complete retraining. We propose \\return, a\nReal-world pErsonal daTa UnleaRNing dataset, comprising 2,492 individuals from\nWikipedia with associated QA pairs, to evaluate machine unlearning (MU) methods\nfor protecting personal data in a realistic scenario. Additionally, we\nintroduce the Name-Aware Unlearning Framework (NAUF) for Privacy Protection,\nwhich enables the model to learn which individuals' information should be\nprotected without affecting its ability to answer questions related to other\nunrelated individuals. Our extensive experiments demonstrate that NAUF achieves\na state-of-the-art average unlearning score, surpassing the best baseline\nmethod by 5.65 points, effectively protecting target individuals' personal data\nwhile maintaining the model's general capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10058v2",
    "published_date": "2024-07-14 03:05:53 UTC",
    "updated_date": "2024-09-16 07:20:13 UTC"
  },
  {
    "arxiv_id": "2407.10049v1",
    "title": "AutoGRAMS: Autonomous Graphical Agent Modeling Software",
    "authors": [
      "Ben Krause",
      "Lucia Chen",
      "Emmanuel Kahembwe"
    ],
    "abstract": "We introduce the AutoGRAMS framework for programming multi-step interactions\nwith language models. AutoGRAMS represents AI agents as a graph, where each\nnode can execute either a language modeling instruction or traditional code.\nLikewise, transitions in the graph can be governed by either language modeling\ndecisions or traditional branch logic. AutoGRAMS supports using variables as\nmemory and allows nodes to call other AutoGRAMS graphs as functions. We show\nhow AutoGRAMS can be used to design highly sophisticated agents, including\nself-referential agents that can modify their own graph. AutoGRAMS's\ngraph-centric approach aids interpretability, controllability, and safety\nduring the design, development, and deployment of AI agents. We provide our\nframework as open source at https://github.com/autograms/autograms .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10049v1",
    "published_date": "2024-07-14 02:25:45 UTC",
    "updated_date": "2024-07-14 02:25:45 UTC"
  },
  {
    "arxiv_id": "2407.10040v5",
    "title": "Lean-STaR: Learning to Interleave Thinking and Proving",
    "authors": [
      "Haohan Lin",
      "Zhiqing Sun",
      "Sean Welleck",
      "Yiming Yang"
    ],
    "abstract": "Traditional language model-based theorem proving assumes that by training on\na sufficient amount of formal proof data, a model will learn to prove theorems.\nOur key observation is that a wealth of informal information that is not\npresent in formal proofs can be useful for learning to prove theorems. For\ninstance, humans think through steps of a proof, but this thought process is\nnot visible in the resulting code. We present Lean-STaR, a framework for\ntraining language models to produce informal thoughts prior to each step of a\nproof, thereby boosting the model's theorem-proving capabilities. Lean-STaR\nuses retrospective ground-truth tactics to generate synthetic thoughts for\ntraining the language model. At inference time, the trained model directly\ngenerates the thoughts prior to the prediction of the tactics in each proof\nstep. Building on the self-taught reasoner framework, we then apply expert\niteration to further fine-tune the model on the correct proofs it samples and\nverifies using the Lean solver. Lean-STaR achieves state-of-the-art results on\nthe miniF2F-test benchmark within the Lean theorem proving environment,\nsignificantly outperforming base models ($\\boldsymbol{43.4\\% \\rightarrow\n46.3\\%,}$ Pass@64). We also analyze the impact of the augmented thoughts on\nvarious aspects of the theorem proving process, providing insights into their\neffectiveness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10040v5",
    "published_date": "2024-07-14 01:43:07 UTC",
    "updated_date": "2025-03-15 12:25:58 UTC"
  },
  {
    "arxiv_id": "2407.15718v1",
    "title": "Integrating AI Tutors in a Programming Course",
    "authors": [
      "Iris Ma",
      "Alberto Krone Martins",
      "Cristina Videira Lopes"
    ],
    "abstract": "RAGMan is an LLM-powered tutoring system that can support a variety of\ncourse-specific and homework-specific AI tutors. RAGMan leverages Retrieval\nAugmented Generation (RAG), as well as strict instructions, to ensure the\nalignment of the AI tutors' responses. By using RAGMan's AI tutors, students\nreceive assistance with their specific homework assignments without directly\nobtaining solutions, while also having the ability to ask general\nprogramming-related questions.\n  RAGMan was deployed as an optional resource in an introductory programming\ncourse with an enrollment of 455 students. It was configured as a set of five\nhomework-specific AI tutors. This paper describes the interactions the students\nhad with the AI tutors, the students' feedback, and a comparative grade\nanalysis. Overall, about half of the students engaged with the AI tutors, and\nthe vast majority of the interactions were legitimate homework questions. When\nstudents posed questions within the intended scope, the AI tutors delivered\naccurate responses 98% of the time. Within the students used AI tutors, 78%\nreported that the tutors helped their learning. Beyond AI tutors' ability to\nprovide valuable suggestions, students reported appreciating them for fostering\na safe learning environment free from judgment.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.IR",
      "cs.SE"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted at SIGCSE Virtual 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.15718v1",
    "published_date": "2024-07-14 00:42:39 UTC",
    "updated_date": "2024-07-14 00:42:39 UTC"
  }
]