{
  "date": "2024-03-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-20 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、多模态生成、LLM（Large Language Models）的细调与应用、医疗 AI 以及机器人规划等领域。其中，LLM 在医疗对话中的安全应用（如 Polaris）和高效多模态生成模型（如 VSTAR）特别引人注目，同时有几篇论文探讨了 AI 模型的鲁棒性和泛化能力。\n\n### 重点论文讨论\n以下挑选并讨论了今日论文中的重要和话题性内容，先从 LLM 和 AI 安全相关入手，再聊医疗与多模态生成，最后快速掠过其他领域。每个条目列出论文标题（中文 + 英文），并简要描述主要贡献和发现。\n\n1. **Polaris: A Safety-focused LLM Constellation Architecture for Healthcare**（Polaris: 一种针对医疗的以安全为中心的LLM星座架构）  \n   这篇论文提出 Polaris，一种专注于医疗对话的LLM系统，使用多代理架构确保安全性和鲁棒性。主要贡献是通过多代理协作提升对话准确性，并在临床评估中证明其与人类护士相当的性能，显著减少幻觉风险。\n\n2. **On Prompt Sensitivity of ChatGPT in Affective Computing**（ChatGPT在情感计算中的提示敏感性分析）  \n   作者 Björn W. Schuller 等人研究了 ChatGPT 在情感任务（如情感分析）的提示敏感性。主要发现是通过调整温度和 top-p 参数优化生成性能，并探索提示策略以提高模型对指令的遵循，适用于情感计算应用。\n\n3. **Reverse Training to Nurse the Reversal Curse**（逆向训练缓解逆转诅咒）  \n   作者 Olga Golovneva 和 Jason Weston 等人提出逆向训练方法，解决 LLM 在知识逆转（如“A has B”无法推断“B has A”）的问题。主要贡献是双向训练提升模型泛化能力，并在实验中证明其在知识保留和逆转任务上的优越性。\n\n4. **BadEdit: Backdooring large language models by model editing**（BadEdit: 通过模型编辑在大型语言模型中注入后门）  \n   这篇论文引入 BadEdit 框架，用于高效注入 LLM 后门攻击。主要发现是无需大量数据即可实现后门注入，同时保持模型性能，并证明其在后续微调中的鲁棒性，强调 AI 安全风险。\n\n5. **LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning**（LLMs作为写作助手: 探索所有权感和推理视角）  \n   作者 Azmine Toushik Wasi 等人通过调查探讨 LLM 在写作中的所有权感和认知影响。主要贡献是揭示用户对 LLM 生成内容的心理困境，并提出改进人机交互以增强写作个性化。\n\n6. **Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models**（使用多条件潜在扩散模型学习对比动力学）  \n   这篇论文提出多条件潜在扩散模型，用于从噪声数据合成 MRI 图像。主要发现是减少对比剂依赖，同时引入 Fréchet 辐射组学距离作为评估指标，提升了医学图像生成的准确性和临床应用潜力。\n\n7. **VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis**（VSTAR: 用于更长动态视频合成的生成式时间护理）  \n   作者提出 VSTAR 框架，用于生成更长的动态视频。主要贡献是通过生成式时间护理和提示策略改善视频连续性，并在实验中超越基线模型，适用于文本到视频任务。\n\n8. **RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition**（RAR: 用于视觉识别的检索和排名增强的多模态LLM）  \n   这篇论文开发 RAR 方法，结合 CLIP 和 MLLMs 提升细粒度视觉识别。主要发现是提高零样本和少样本识别性能，并在基准测试中显著提升精度，适用于多模态任务。\n\n9. **DiffImpute: Tabular Data Imputation With Denoising Diffusion Probabilistic Model**（DiffImpute: 使用去噪扩散概率模型的表格数据插值）  \n   作者提出 DiffImpute，用于处理表格数据的缺失值。主要贡献是通过扩散模型和协调策略提升插值准确性，并在多种数据集上超越传统方法，适用于数据稀疏场景。\n\n10. **Evo* 2023 -- Late-Breaking Abstracts Volume**（Evo* 2023 -- 后期突破摘要卷）  \n    这是一个 Evo* 会议摘要集，聚焦生物启发方法的应用。主要发现是汇集了多种进化计算问题解决案例，提供实时研究洞见。\n\n### 其他相关论文快速掠过\n今日还有许多论文涉及机器人规划、多模态生成和联邦学习等领域，但不那么核心或话题性较弱，这里简要提及：\n- **Searching Search Spaces: Meta-evolving a Geometric Encoding for Neural Networks**（搜索搜索空间: 元进化神经网络的几何编码）：提出间接编码方法优化神经网络搜索空间，主要贡献是提升进化算法效率。\n- **ACDG-VTON: Accurate and Contained Diffusion Generation for Virtual Try-On**（ACDG-VTON: 精确且受限的扩散生成用于虚拟试穿）：改进扩散模型用于虚拟试衣，主要发现是更好地保留服装细节。\n- **On Pretraining Data Diversity for Self-Supervised Learning**（自监督学习中预训练数据多样性的影响）：强调数据多样性对自监督学习的影响，主要贡献是证明分布偏移下的泛化提升。\n- **Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs**（墨水与个性: 在LLM时代构建个性化叙事）：探讨 LLM 对写作个性的影响，通过调查分析人机交互问题。\n- 其余如联邦学习（第26、82）、机器人路径规划（第59、78）和医疗图像分析（第49、63）论文虽有新颖方法，但未见重大突破，仅提供技术优化。\n\n总之，今天的论文突显了 AI 模型在安全性和实际应用中的进展，LLM 相关研究尤其值得关注。欢迎读者根据兴趣深入阅读这些论文！",
  "papers": [
    {
      "arxiv_id": "2403.14037v1",
      "title": "Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection",
      "title_zh": "Ax-to-Grind Urdu：用于乌尔都语假新闻检测的基准数据集",
      "authors": [
        "Sheetal Harris",
        "Jinshuo Liu",
        "Hassan Jalil Hadi",
        "Yue Cao"
      ],
      "abstract": "Misinformation can seriously impact society, affecting anything from public\nopinion to institutional confidence and the political horizon of a state. Fake\nNews (FN) proliferation on online websites and Online Social Networks (OSNs)\nhas increased profusely. Various fact-checking websites include news in English\nand barely provide information about FN in regional languages. Thus the Urdu FN\npurveyors cannot be discerned using factchecking portals. SOTA approaches for\nFake News Detection (FND) count upon appropriately labelled and large datasets.\nFND in regional and resource-constrained languages lags due to the lack of\nlimited-sized datasets and legitimate lexical resources. The previous datasets\nfor Urdu FND are limited-sized, domain-restricted, publicly unavailable and not\nmanually verified where the news is translated from English into Urdu. In this\npaper, we curate and contribute the first largest publicly available dataset\nfor Urdu FND, Ax-to-Grind Urdu, to bridge the identified gaps and limitations\nof existing Urdu datasets in the literature. It constitutes 10,083 fake and\nreal news on fifteen domains collected from leading and authentic Urdu\nnewspapers and news channel websites in Pakistan and India. FN for the\nAx-to-Grind dataset is collected from websites and crowdsourcing. The dataset\ncontains news items in Urdu from the year 2017 to the year 2023. Expert\njournalists annotated the dataset. We benchmark the dataset with an ensemble\nmodel of mBERT,XLNet, and XLM RoBERTa. The selected models are originally\ntrained on multilingual large corpora. The results of the proposed model are\nbased on performance metrics, F1-score, accuracy, precision, recall and MCC\nvalue.",
      "tldr_zh": "本文针对乌尔都语（Urdu）假新闻检测（Fake News Detection, FND）的挑战，构建了首个最大规模的公开基准数据集Ax-to-Grind Urdu，以填补现有数据集规模小、领域限制且非手动验证的空白。数据集包含10,083条假新闻和真实新闻，覆盖15个领域，从巴基斯坦和印度的可靠新闻来源收集，并由专家记者标注，时间跨度从2017年到2023年。作者使用mBERT、XLNet和XLM RoBERTa的集成模型进行基准测试，结果基于F1-score、accuracy、precision、recall和MCC值等性能指标，展示了数据集的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14037v1",
      "published_date": "2024-03-20 23:21:35 UTC",
      "updated_date": "2024-03-20 23:21:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:10:54.740524"
    },
    {
      "arxiv_id": "2403.14019v1",
      "title": "Searching Search Spaces: Meta-evolving a Geometric Encoding for Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tarek Kunze",
        "Paul Templier",
        "Dennis G Wilson"
      ],
      "abstract": "In evolutionary policy search, neural networks are usually represented using\na direct mapping: each gene encodes one network weight. Indirect encoding\nmethods, where each gene can encode for multiple weights, shorten the genome to\nreduce the dimensions of the search space and better exploit permutations and\nsymmetries. The Geometric Encoding for Neural network Evolution (GENE)\nintroduced an indirect encoding where the weight of a connection is computed as\nthe (pseudo-)distance between the two linked neurons, leading to a genome size\ngrowing linearly with the number of genes instead of quadratically in direct\nencoding. However GENE still relies on hand-crafted distance functions with no\nprior optimization. Here we show that better performing distance functions can\nbe found for GENE using Cartesian Genetic Programming (CGP) in a meta-evolution\napproach, hence optimizing the encoding to create a search space that is easier\nto exploit. We show that GENE with a learned function can outperform both\ndirect encoding and the hand-crafted distances, generalizing on unseen\nproblems, and we study how the encoding impacts neural network properties.",
      "tldr_zh": "该论文探讨了在进化策略搜索中，使用间接编码(indirect encoding)来优化神经网络表示，相比直接编码(direct encoding)可减少搜索空间维度。论文扩展了 Geometric Encoding for Neural network Evolution (GENE)，通过计算神经元间伪距离来生成权重，使基因组大小线性增长，并首次使用 Cartesian Genetic Programming (CGP) 进行 meta-evolution 来优化距离函数。实验结果表明，优化后的 GENE 性能优于直接编码和手工距离函数，能够泛化到未见问题，并揭示了编码对神经网络属性的影响。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.NE",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14019v1",
      "published_date": "2024-03-20 22:40:53 UTC",
      "updated_date": "2024-03-20 22:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:11:06.270750"
    },
    {
      "arxiv_id": "2403.14006v1",
      "title": "On Prompt Sensitivity of ChatGPT in Affective Computing",
      "title_zh": "ChatGPT 在情感计算中的提示敏感性",
      "authors": [
        "Mostafa M. Amin",
        "Björn W. Schuller"
      ],
      "abstract": "Recent studies have demonstrated the emerging capabilities of foundation\nmodels like ChatGPT in several fields, including affective computing. However,\naccessing these emerging capabilities is facilitated through prompt\nengineering. Despite the existence of some prompting techniques, the field is\nstill rapidly evolving and many prompting ideas still require investigation. In\nthis work, we introduce a method to evaluate and investigate the sensitivity of\nthe performance of foundation models based on different prompts or generation\nparameters. We perform our evaluation on ChatGPT within the scope of affective\ncomputing on three major problems, namely sentiment analysis, toxicity\ndetection, and sarcasm detection. First, we carry out a sensitivity analysis on\npivotal parameters in auto-regressive text generation, specifically the\ntemperature parameter $T$ and the top-$p$ parameter in Nucleus sampling,\ndictating how conservative or creative the model should be during generation.\nFurthermore, we explore the efficacy of several prompting ideas, where we\nexplore how giving different incentives or structures affect the performance.\nOur evaluation takes into consideration performance measures on the affective\ncomputing tasks, and the effectiveness of the model to follow the stated\ninstructions, hence generating easy-to-parse responses to be smoothly used in\ndownstream applications.",
      "tldr_zh": "这篇论文探讨了ChatGPT在情感计算领域的提示敏感性，引入了一种方法来评估不同提示和生成参数（如温度参数$T$和top-$p$参数）对模型性能的影响。研究通过在情感分析、毒性检测和讽刺检测三大任务上进行敏感性分析，考察了这些参数如何调节模型的保守性或创造性。实验结果显示，不同提示策略（如提供激励或结构化指导）能显著提升任务性能和模型的指令遵循能力，从而生成更易解析的响应用于下游应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "2 Tables, 1 Figure, preprint submission to ACII 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14006v1",
      "published_date": "2024-03-20 22:11:01 UTC",
      "updated_date": "2024-03-20 22:11:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:11:18.094996"
    },
    {
      "arxiv_id": "2404.00027v5",
      "title": "LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Azmine Toushik Wasi",
        "Mst Rafia Islam",
        "Raima Islam"
      ],
      "abstract": "Sense of ownership in writing confines our investment of thoughts, time, and\ncontribution, leading to attachment to the output. However, using writing\nassistants introduces a mental dilemma, as some content isn't directly our\ncreation. For instance, we tend to credit Large Language Models (LLMs) more in\ncreative tasks, even though all tasks are equal for them. Additionally, while\nwe may not claim complete ownership of LLM-generated content, we freely claim\nauthorship. We conduct a short survey to examine these issues and understand\nunderlying cognitive processes in order to gain a better knowledge of\nhuman-computer interaction in writing and improve writing aid systems.",
      "tldr_zh": "本研究探讨了使用 Large Language Models (LLMs) 作为写作助手时，人们对内容的所有权感 (sense of ownership) 和推理过程的认知困境。调查发现，人们在创作任务中更倾向于将内容归功于 LLMs，尽管 LLMs 对所有任务处理相同，同时可能不完全声称所有权但会自由声称作者身份。通过简短调查，研究揭示了潜在的认知过程，以加深对人类-计算机互动的理解并改进写作辅助系统。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "5 Pages, 3 Figures. Accepted in The Third Workshop on Intelligent and\n  Interactive Writing Assistants at CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00027v5",
      "published_date": "2024-03-20 21:06:42 UTC",
      "updated_date": "2024-10-02 20:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:11:30.308037"
    },
    {
      "arxiv_id": "2404.00026v5",
      "title": "Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Azmine Toushik Wasi",
        "Raima Islam",
        "Mst Rafia Islam"
      ],
      "abstract": "Individuality and personalization comprise the distinctive characteristics\nthat make each writer unique and influence their words in order to effectively\nengage readers while conveying authenticity. However, our growing reliance on\nLLM-based writing assistants risks compromising our creativity and\nindividuality over time. We often overlook the negative impacts of this trend\non our creativity and uniqueness, despite the possible consequences. This study\ninvestigates these concerns by performing a brief survey to explore different\nperspectives and concepts, as well as trying to understand people's viewpoints,\nin conjunction with past studies in the area. Addressing these issues is\nessential for improving human-computer interaction systems and enhancing\nwriting assistants for personalization and individuality.",
      "tldr_zh": "这篇论文探讨了在LLMs（Large Language Models）时代，写作助理工具如何可能削弱个人的创造力和独特性（individuality），从而影响真实性和读者互动。研究通过进行简短调查和回顾现有文献，收集不同观点并分析人们对这一趋势的看法。最终，论文强调了改进人类-计算机交互（HCI）系统和个性化写作助理的必要性，以保护和提升用户的个性化表达。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "5 Pages, 4 Figures. Accepted in The Third Workshop on Intelligent and\n  Interactive Writing Assistants at CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00026v5",
      "published_date": "2024-03-20 21:02:16 UTC",
      "updated_date": "2024-10-02 20:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:11:40.460734"
    },
    {
      "arxiv_id": "2403.13969v2",
      "title": "\"This is not a data problem\": Algorithms and Power in Public Higher Education in Canada",
      "title_zh": "翻译失败",
      "authors": [
        "Kelly McConvey",
        "Shion Guha"
      ],
      "abstract": "Algorithmic decision-making is increasingly being adopted across public\nhigher education. The expansion of data-driven practices by post-secondary\ninstitutions has occurred in parallel with the adoption of New Public\nManagement approaches by neoliberal administrations. In this study, we conduct\na qualitative analysis of an in-depth ethnographic case study of data and\nalgorithms in use at a public college in Ontario, Canada. We identify the data,\nalgorithms, and outcomes in use at the college. We assess how the college's\nprocesses and relationships support those outcomes and the different\nstakeholders' perceptions of the college's data-driven systems. In addition, we\nfind that the growing reliance on algorithmic decisions leads to increased\nstudent surveillance, exacerbation of existing inequities, and the automation\nof the faculty-student relationship. Finally, we identify a cycle of increased\ninstitutional power perpetuated by algorithmic decision-making, and driven by a\npush towards financial sustainability.",
      "tldr_zh": "本研究探讨了算法决策在加拿大公立高等教育中的应用及其与新公共管理（New Public Management）方法的关联，通过对安大略省一所公立学院的深入民族志案例研究（ethnographic case study）进行定性分析。研究识别了学院中使用的数据、算法和结果，并评估了这些系统对过程、关系和利益相关者看法的影响。结果显示，算法决策加剧了学生监控（student surveillance）、现有不平等，以及教职员-学生关系的自动化，最终形成了一个由追求财务可持续性驱动的机构权力循环（institutional power）。这项工作强调了算法在教育领域的潜在风险，并为政策制定提供了重要见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "In CHI '24 Proceedings of the CHI Conference on Human Factors in\n  Computing Systems Honolulu, HI, USA",
      "pdf_url": "http://arxiv.org/pdf/2403.13969v2",
      "published_date": "2024-03-20 20:46:41 UTC",
      "updated_date": "2024-03-22 15:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:11:53.137395"
    },
    {
      "arxiv_id": "2403.13960v1",
      "title": "Open Access NAO (OAN): a ROS2-based software framework for HRI applications with the NAO robot",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio Bono",
        "Kenji Brameld",
        "Luigi D'Alfonso",
        "Giuseppe Fedele"
      ],
      "abstract": "This paper presents a new software framework for HRI experimentation with the\nsixth version of the common NAO robot produced by the United Robotics Group.\nEmbracing the common demand of researchers for better performance and new\nfeatures for NAO, the authors took advantage of the ability to run ROS2 onboard\non the NAO to develop a framework independent of the APIs provided by the\nmanufacturer. Such a system provides NAO with not only the basic skills of a\nhumanoid robot such as walking and reproducing movements of interest but also\nfeatures often used in HRI such as: speech recognition/synthesis, face and\nobject detention, and the use of Generative Pre-trained Transformer (GPT)\nmodels for conversation. The developed code is therefore configured as a\nready-to-use but also highly expandable and improvable tool thanks to the\npossibilities provided by the ROS community.",
      "tldr_zh": "这篇论文介绍了Open Access NAO (OAN)，一个基于ROS2的软件框架，旨在为NAO机器人的人机交互(HRI)应用提供支持。OAN框架独立于制造商API，利用ROS2在NAO上运行，实现基本功能如行走和动作重现，以及HRI常用特性包括语音识别/合成、面部和物体检测，以及整合Generative Pre-trained Transformer (GPT)模型进行对话。实验结果显示，该框架是即用型工具，同时高度可扩展，受益于ROS社区的资源，从而提升了NAO机器人在HRI研究中的性能和灵活性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13960v1",
      "published_date": "2024-03-20 20:13:39 UTC",
      "updated_date": "2024-03-20 20:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:12:04.501122"
    },
    {
      "arxiv_id": "2403.13951v1",
      "title": "ACDG-VTON: Accurate and Contained Diffusion Generation for Virtual Try-On",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffrey Zhang",
        "Kedan Li",
        "Shao-Yu Chang",
        "David Forsyth"
      ],
      "abstract": "Virtual Try-on (VTON) involves generating images of a person wearing selected\ngarments. Diffusion-based methods, in particular, can create high-quality\nimages, but they struggle to maintain the identities of the input garments. We\nidentified this problem stems from the specifics in the training formulation\nfor diffusion. To address this, we propose a unique training scheme that limits\nthe scope in which diffusion is trained. We use a control image that perfectly\naligns with the target image during training. In turn, this accurately\npreserves garment details during inference. We demonstrate our method not only\neffectively conserves garment details but also allows for layering, styling,\nand shoe try-on. Our method runs multi-garment try-on in a single inference\ncycle and can support high-quality zoomed-in generations without training in\nhigher resolutions. Finally, we show our method surpasses prior methods in\naccuracy and quality.",
      "tldr_zh": "该论文提出ACDG-VTON方法，针对Diffusion-based虚拟试穿(Virtual Try-on)技术中难以保持输入服装身份的问题，引入一种独特训练方案，使用与目标图像完美对齐的控制图像来限制Diffusion的训练范围，从而准确保留服装细节。  \n该方法不仅有效保护服装细节，还支持服装分层、造型和鞋子试穿，并在单次推理周期内处理多服装试穿，同时实现高质量的放大生成，而无需更高分辨率训练。  \n实验结果显示，ACDG-VTON在准确性和图像质量上超越了现有方法，为虚拟试穿应用提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13951v1",
      "published_date": "2024-03-20 19:45:06 UTC",
      "updated_date": "2024-03-20 19:45:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:12:18.955230"
    },
    {
      "arxiv_id": "2403.13950v1",
      "title": "Evo* 2023 -- Late-Breaking Abstracts Volume",
      "title_zh": "翻译失败",
      "authors": [
        "A. M. Mora",
        "A. I. Esparcia-Alcázar"
      ],
      "abstract": "Volume with the Late-Breaking Abstracts submitted to the Evo* 2023\nConference, held in Brno (Czech Republic), from 12 to 14 of April. These papers\npresent ongoing research and preliminary results investigating on the\napplication of different approaches of Bioinspired Methods (mainly Evolutionary\nComputation) to different problems, most of them real world ones.",
      "tldr_zh": "这本卷集收录了提交至 Evo* 2023 会议的晚间摘要，这些会议于2023年4月12日至14日在捷克共和国布尔诺举行。摘要主要展示正在进行的研究和初步结果，聚焦于应用生物启发方法（主要是 Evolutionary Computation）来解决各种问题，其中许多是真实世界应用。总体而言，此集锦突出了进化计算等技术在实际领域的潜力，为相关研究社区提供了及时的见解和讨论基础。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "68T05, 68W20",
        "I.0; I.2; K.4"
      ],
      "primary_category": "cs.NE",
      "comment": "LBAs accepted in Evo* 2023. Part of the Conference Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2403.13950v1",
      "published_date": "2024-03-20 19:42:11 UTC",
      "updated_date": "2024-03-20 19:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:12:28.524920"
    },
    {
      "arxiv_id": "2403.13947v2",
      "title": "BlendScape: Enabling End-User Customization of Video-Conferencing Environments through Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Shwetha Rajaram",
        "Nels Numan",
        "Balasaravanan Thoravi Kumaravel",
        "Nicolai Marquardt",
        "Andrew D. Wilson"
      ],
      "abstract": "Today's video-conferencing tools support a rich range of professional and\nsocial activities, but their generic meeting environments cannot be dynamically\nadapted to align with distributed collaborators' needs. To enable end-user\ncustomization, we developed BlendScape, a rendering and composition system for\nvideo-conferencing participants to tailor environments to their meeting context\nby leveraging AI image generation techniques. BlendScape supports flexible\nrepresentations of task spaces by blending users' physical or digital\nbackgrounds into unified environments and implements multimodal interaction\ntechniques to steer the generation. Through an exploratory study with 15\nend-users, we investigated whether and how they would find value in using\ngenerative AI to customize video-conferencing environments. Participants\nenvisioned using a system like BlendScape to facilitate collaborative\nactivities in the future, but required further controls to mitigate distracting\nor unrealistic visual elements. We implemented scenarios to demonstrate\nBlendScape's expressiveness for supporting environment design strategies from\nprior work and propose composition techniques to improve the quality of\nenvironments.",
      "tldr_zh": "该研究开发了BlendScape系统，利用Generative AI技术，让视频-conferencing用户根据会议上下文自定义环境，从而解决传统工具的适应性不足问题。BlendScape通过混合用户的物理或数字背景创建统一的虚拟空间，并提供多模态交互技巧来引导AI图像生成。研究中，15名参与者的探索性调查显示，用户认为该系统能提升未来协作活动，但需要额外控制以减少干扰元素。论文还演示了BlendScape在支持环境设计策略方面的表现力，并提出组合技术来提升环境质量。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "ACM UIST 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.13947v2",
      "published_date": "2024-03-20 19:41:05 UTC",
      "updated_date": "2024-10-01 12:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:12:41.472626"
    },
    {
      "arxiv_id": "2403.13940v2",
      "title": "A multi-criteria approach for selecting an explanation from the set of counterfactuals produced by an ensemble of explainers",
      "title_zh": "翻译失败",
      "authors": [
        "Ignacy Stępka",
        "Mateusz Lango",
        "Jerzy Stefanowski"
      ],
      "abstract": "Counterfactuals are widely used to explain ML model predictions by providing\nalternative scenarios for obtaining the more desired predictions. They can be\ngenerated by a variety of methods that optimize different, sometimes\nconflicting, quality measures and produce quite different solutions. However,\nchoosing the most appropriate explanation method and one of the generated\ncounterfactuals is not an easy task. Instead of forcing the user to test many\ndifferent explanation methods and analysing conflicting solutions, in this\npaper, we propose to use a multi-stage ensemble approach that will select\nsingle counterfactual based on the multiple-criteria analysis. It offers a\ncompromise solution that scores well on several popular quality measures. This\napproach exploits the dominance relation and the ideal point decision aid\nmethod, which selects one counterfactual from the Pareto front. The conducted\nexperiments demonstrated that the proposed approach generates fully actionable\ncounterfactuals with attractive compromise values of the considered quality\nmeasures.",
      "tldr_zh": "本论文提出了一种多标准方法，用于从多个解释器生成的反事实(counterfactuals)集合中选择最佳解释，从而解决不同优化质量指标可能导致的冲突问题。该方法采用多阶段集成(ensemble)方法，结合主导关系(dominance relation)和理想点决策辅助方法(ideal point decision aid method)，从Pareto前线中选取一个折中解决方案，确保反事实在多个质量指标上表现均衡。实验结果表明，该方法生成的反事实是完全可操作的，并在关键质量措施上取得了吸引人的折中值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13940v2",
      "published_date": "2024-03-20 19:25:11 UTC",
      "updated_date": "2024-08-02 15:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:12:58.064907"
    },
    {
      "arxiv_id": "2403.13925v1",
      "title": "Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification",
      "title_zh": "翻译失败",
      "authors": [
        "Devam Mondal",
        "Carlo Lipizzi"
      ],
      "abstract": "Despite the growing capabilities of large language models, there exists\nconcerns about the biases they develop. In this paper, we propose a novel,\nautomated mechanism for debiasing through specified dataset augmentation in the\nlens of bias producers and in the context of 'restricted industries' with\nlimited data. We additionally create two new additional metrics, the mb-index\nand db-index, to quantify bias, considering the idea that bias occurs due to\nboth intrinsic model architecture and dataset.",
      "tldr_zh": "尽管大型语言模型（Large Language Models）存在偏见问题，本文提出了一种新型的自动化数据集增强机制，专注于“Restricted Industries”这些数据有限的领域，从偏见产生者的角度进行针对性扩充，以减少模型偏见。论文还创建了两个新指标：mb-index和db-index，用于量化偏见，这些指标同时考虑了模型架构的内在因素和数据集的影响。通过这一方法，研究为更公平的语言模型训练提供了可操作的框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13925v1",
      "published_date": "2024-03-20 18:59:18 UTC",
      "updated_date": "2024-03-20 18:59:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:13:08.654973"
    },
    {
      "arxiv_id": "2403.13890v3",
      "title": "Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Osuala",
        "Daniel M. Lang",
        "Preeti Verma",
        "Smriti Joshi",
        "Apostolia Tsirikoglou",
        "Grzegorz Skorupko",
        "Kaisar Kushibar",
        "Lidia Garrucho",
        "Walter H. L. Pinaya",
        "Oliver Diaz",
        "Julia A. Schnabel",
        "Karim Lekadir"
      ],
      "abstract": "Contrast agents in dynamic contrast enhanced magnetic resonance imaging allow\nto localize tumors and observe their contrast kinetics, which is essential for\ncancer characterization and respective treatment decision-making. However,\ncontrast agent administration is not only associated with adverse health risks,\nbut also restricted for patients during pregnancy, and for those with kidney\nmalfunction, or other adverse reactions. With contrast uptake as key biomarker\nfor lesion malignancy, cancer recurrence risk, and treatment response, it\nbecomes pivotal to reduce the dependency on intravenous contrast agent\nadministration. To this end, we propose a multi-conditional latent diffusion\nmodel capable of acquisition time-conditioned image synthesis of DCE-MRI\ntemporal sequences. To evaluate medical image synthesis, we additionally\npropose and validate the Fr\\'echet radiomics distance as an image quality\nmeasure based on biomarker variability between synthetic and real imaging data.\nOur results demonstrate our method's ability to generate realistic\nmulti-sequence fat-saturated breast DCE-MRI and uncover the emerging potential\nof deep learning based contrast kinetics simulation. We publicly share our\naccessible codebase at https://github.com/RichardObi/ccnet and provide a\nuser-friendly library for Fr\\'echet radiomics distance calculation at\nhttps://pypi.org/project/frd-score.",
      "tldr_zh": "该研究针对动态对比增强磁共振成像（DCE-MRI）中的对比剂风险（如对孕妇或肾功能不全患者的危害），提出了一种多条件潜在扩散模型（multi-conditional latent diffusion model），用于根据采集时间合成DCE-MRI时间序列图像，从而减少对静脉注射对比剂的依赖。模型通过模拟对比动力学来生成逼真的多序列脂肪饱和乳房图像，并引入Fréchet radiomics distance作为新颖的图像质量度量，基于合成和真实数据的生物标志物变异性进行评估。实验结果显示，该方法能有效模拟对比动力学，具有潜力提升癌症诊断和治疗决策的准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Early Accept at MICCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2403.13890v3",
      "published_date": "2024-03-20 18:01:57 UTC",
      "updated_date": "2024-07-17 16:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:13:19.971172"
    },
    {
      "arxiv_id": "2403.13808v3",
      "title": "On Pretraining Data Diversity for Self-Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hasan Abed Al Kader Hammoud",
        "Tuhin Das",
        "Fabio Pizzati",
        "Philip Torr",
        "Adel Bibi",
        "Bernard Ghanem"
      ],
      "abstract": "We explore the impact of training with more diverse datasets, characterized\nby the number of unique samples, on the performance of self-supervised learning\n(SSL) under a fixed computational budget. Our findings consistently demonstrate\nthat increasing pretraining data diversity enhances SSL performance, albeit\nonly when the distribution distance to the downstream data is minimal. Notably,\neven with an exceptionally large pretraining data diversity achieved through\nmethods like web crawling or diffusion-generated data, among other ways, the\ndistribution shift remains a challenge. Our experiments are comprehensive with\nseven SSL methods using large-scale datasets such as ImageNet and YFCC100M\namounting to over 200 GPU days. Code and trained models are available at\nhttps://github.com/hammoudhasan/DiversitySSL",
      "tldr_zh": "本研究探讨了在固定计算预算下，增加预训练数据多样性（更多独特样本）对Self-Supervised Learning (SSL)性能的影响。结果显示，数据多样性能提升SSL性能，但前提是预训练数据与下游数据的分布距离最小；即使通过web crawling或diffusion-generated data等方法实现极高多样性，分布偏移问题依然存在。实验涉及七种SSL方法和大规模数据集，如ImageNet和YFCC100M，总计超过200 GPU天。作者提供了代码和训练模型，供进一步验证和应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.13808v3",
      "published_date": "2024-03-20 17:59:58 UTC",
      "updated_date": "2024-07-18 09:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:13:33.328821"
    },
    {
      "arxiv_id": "2403.13807v1",
      "title": "Editing Massive Concepts in Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tianwei Xiong",
        "Yue Wu",
        "Enze Xie",
        "Yue Wu",
        "Zhenguo Li",
        "Xihui Liu"
      ],
      "abstract": "Text-to-image diffusion models suffer from the risk of generating outdated,\ncopyrighted, incorrect, and biased content. While previous methods have\nmitigated the issues on a small scale, it is essential to handle them\nsimultaneously in larger-scale real-world scenarios. We propose a two-stage\nmethod, Editing Massive Concepts In Diffusion Models (EMCID). The first stage\nperforms memory optimization for each individual concept with dual\nself-distillation from text alignment loss and diffusion noise prediction loss.\nThe second stage conducts massive concept editing with multi-layer, closed form\nmodel editing. We further propose a comprehensive benchmark, named ImageNet\nConcept Editing Benchmark (ICEB), for evaluating massive concept editing for\nT2I models with two subtasks, free-form prompts, massive concept categories,\nand extensive evaluation metrics. Extensive experiments conducted on our\nproposed benchmark and previous benchmarks demonstrate the superior scalability\nof EMCID for editing up to 1,000 concepts, providing a practical approach for\nfast adjustment and re-deployment of T2I diffusion models in real-world\napplications.",
      "tldr_zh": "这篇论文针对文本到图像扩散模型（Text-to-image diffusion models）生成过时、版权、错误或偏见内容的问题，提出了一种两阶段方法EMCID，用于大规模概念编辑。第一阶段通过双重自蒸馏（dual self-distillation）从文本对齐损失（text alignment loss）和扩散噪声预测损失（diffusion noise prediction loss）优化单个概念的内存。第二阶段采用多层闭合形式模型编辑（multi-layer, closed form model editing）实现批量概念修改。作者还引入了ImageNet Concept Editing Benchmark (ICEB)基准，并在实验中证明EMCID可扩展到编辑多达1,000个概念，为文本到图像扩散模型在实际应用中的快速调整和重新部署提供了实用方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://silentview.github.io/EMCID/ . Code:\n  https://github.com/SilentView/EMCID",
      "pdf_url": "http://arxiv.org/pdf/2403.13807v1",
      "published_date": "2024-03-20 17:59:57 UTC",
      "updated_date": "2024-03-20 17:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:13:48.071633"
    },
    {
      "arxiv_id": "2403.13805v1",
      "title": "RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Liu",
        "Zeyi Sun",
        "Yuhang Zang",
        "Wei Li",
        "Pan Zhang",
        "Xiaoyi Dong",
        "Yuanjun Xiong",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "CLIP (Contrastive Language-Image Pre-training) uses contrastive learning from\nnoise image-text pairs to excel at recognizing a wide array of candidates, yet\nits focus on broad associations hinders the precision in distinguishing subtle\ndifferences among fine-grained items. Conversely, Multimodal Large Language\nModels (MLLMs) excel at classifying fine-grained categories, thanks to their\nsubstantial knowledge from pre-training on web-level corpora. However, the\nperformance of MLLMs declines with an increase in category numbers, primarily\ndue to growing complexity and constraints of limited context window size. To\nsynergize the strengths of both approaches and enhance the few-shot/zero-shot\nrecognition abilities for datasets characterized by extensive and fine-grained\nvocabularies, this paper introduces RAR, a Retrieving And Ranking augmented\nmethod for MLLMs. We initially establish a multi-modal retriever based on CLIP\nto create and store explicit memory for different categories beyond the\nimmediate context window. During inference, RAR retrieves the top-k similar\nresults from the memory and uses MLLMs to rank and make the final predictions.\nOur proposed approach not only addresses the inherent limitations in\nfine-grained recognition but also preserves the model's comprehensive knowledge\nbase, significantly boosting accuracy across a range of vision-language\nrecognition tasks. Notably, our approach demonstrates a significant improvement\nin performance on 5 fine-grained visual recognition benchmarks, 11 few-shot\nimage recognition datasets, and the 2 object detection datasets under the\nzero-shot recognition setting.",
      "tldr_zh": "该论文提出RAR方法，通过结合CLIP的对比学习优势和Multimodal Large Language Models (MLLMs)的细粒度知识，解决大规模细粒度视觉识别中的挑战。RAR首先使用基于CLIP的多模态检索器创建并存储类别记忆，以超越MLLMs的上下文窗口限制；在推理阶段，它从记忆中检索top-k相似结果，并由MLLMs进行排名和最终预测。这种方法不仅缓解了细粒度识别的复杂性，还保留了模型的全面知识库。在零样本设置下，RAR在5个细粒度视觉识别基准、11个少样本图像识别数据集和2个物体检测数据集上实现了显著性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project: https://github.com/Liuziyu77/RAR",
      "pdf_url": "http://arxiv.org/pdf/2403.13805v1",
      "published_date": "2024-03-20 17:59:55 UTC",
      "updated_date": "2024-03-20 17:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:13:56.624702"
    },
    {
      "arxiv_id": "2403.13802v3",
      "title": "ZigMa: A DiT-style Zigzag Mamba Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Tao Hu",
        "Stefan Andreas Baumann",
        "Ming Gui",
        "Olga Grebenkova",
        "Pingchuan Ma",
        "Johannes Schusterbauer",
        "Björn Ommer"
      ],
      "abstract": "The diffusion model has long been plagued by scalability and quadratic\ncomplexity issues, especially within transformer-based structures. In this\nstudy, we aim to leverage the long sequence modeling capability of a\nState-Space Model called Mamba to extend its applicability to visual data\ngeneration. Firstly, we identify a critical oversight in most current\nMamba-based vision methods, namely the lack of consideration for spatial\ncontinuity in the scan scheme of Mamba. Secondly, building upon this insight,\nwe introduce a simple, plug-and-play, zero-parameter method named Zigzag Mamba,\nwhich outperforms Mamba-based baselines and demonstrates improved speed and\nmemory utilization compared to transformer-based baselines. Lastly, we\nintegrate Zigzag Mamba with the Stochastic Interpolant framework to investigate\nthe scalability of the model on large-resolution visual datasets, such as\nFacesHQ $1024\\times 1024$ and UCF101, MultiModal-CelebA-HQ, and MS COCO\n$256\\times 256$ . Code will be released at https://taohu.me/zigma/",
      "tldr_zh": "这篇论文针对扩散模型的扩展性和二次复杂度问题，提出了一种基于 State-Space Model 的方法，将 Mamba 应用于视觉数据生成。作者指出了现有 Mamba-based 视觉方法的不足，即忽略了空间连续性，并引入了 Zigzag Mamba，这是一个简单、可插入、零参数的改进方案，比 Mamba 和 Transformer-based 基线在性能、速度和内存利用率上更优。最后，通过与 Stochastic Interpolant 框架整合，在高分辨率数据集（如 FacesHQ 1024×1024 和 MS COCO 256×256）上验证了其可扩展性，为高效视觉生成提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024 Project Page: https://taohu.me/zigma/",
      "pdf_url": "http://arxiv.org/pdf/2403.13802v3",
      "published_date": "2024-03-20 17:59:14 UTC",
      "updated_date": "2024-11-24 14:25:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:14:10.311747"
    },
    {
      "arxiv_id": "2403.13801v2",
      "title": "Natural Language as Policies: Reasoning for Coordinate-Level Embodied Control with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yusuke Mikami",
        "Andrew Melnik",
        "Jun Miura",
        "Ville Hautamäki"
      ],
      "abstract": "We demonstrate experimental results with LLMs that address robotics task\nplanning problems. Recently, LLMs have been applied in robotics task planning,\nparticularly using a code generation approach that converts complex high-level\ninstructions into mid-level policy codes. In contrast, our approach acquires\ntext descriptions of the task and scene objects, then formulates task planning\nthrough natural language reasoning, and outputs coordinate level control\ncommands, thus reducing the necessity for intermediate representation code as\npolicies with pre-defined APIs. Our approach is evaluated on a multi-modal\nprompt simulation benchmark, demonstrating that our prompt engineering\nexperiments with natural language reasoning significantly enhance success rates\ncompared to its absence. Furthermore, our approach illustrates the potential\nfor natural language descriptions to transfer robotics skills from known tasks\nto previously unseen tasks. The project website:\nhttps://natural-language-as-policies.github.io/",
      "tldr_zh": "该论文提出了一种将自然语言作为策略的方法，使用大型语言模型 (LLMs) 通过自然语言推理直接生成坐标级控制命令，处理机器人任务规划问题，从而避免了传统代码生成方法的中间表示依赖。实验在多模态提示模拟基准上显示，这种方法显著提高了任务成功率，与不使用自然语言推理的基线相比表现出色。该方法还证明了自然语言描述能够将机器人技能从已知任务转移到新任务，具有重要的实际应用潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "I.2.9; I.2.7"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13801v2",
      "published_date": "2024-03-20 17:58:12 UTC",
      "updated_date": "2024-04-06 04:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:14:19.679983"
    },
    {
      "arxiv_id": "2403.13799v3",
      "title": "Reverse Training to Nurse the Reversal Curse",
      "title_zh": "翻译失败",
      "authors": [
        "Olga Golovneva",
        "Zeyuan Allen-Zhu",
        "Jason Weston",
        "Sainbayar Sukhbaatar"
      ],
      "abstract": "Large language models (LLMs) have a surprising failure: when trained on \"A\nhas a feature B\", they do not generalize to \"B is a feature of A\", which is\ntermed the Reversal Curse. Even when training with trillions of tokens this\nissue still appears due to Zipf's law - hence even if we train on the entire\ninternet. This work proposes an alternative training scheme, called reverse\ntraining, whereby all words are used twice, doubling the amount of available\ntokens. The LLM is trained in both forward and reverse directions by reversing\nthe training strings while preserving (i.e., not reversing) chosen substrings,\nsuch as entities. We show that data-matched reverse-trained models provide\nsuperior performance to standard models on standard tasks, and compute-matched\nreverse-trained models provide far superior performance on reversal tasks,\nhelping resolve the reversal curse issue.",
      "tldr_zh": "大型语言模型 (LLMs) 存在 Reversal Curse 问题，即训练时学会“A has a feature B”，却无法推断“B is a feature of A”，即使使用数万亿 tokens 训练，由于 Zipf's law 的影响，该问题依然存在。论文提出 Reverse Training 方法，通过将所有单词正向和反向使用两次，同时保留实体等子字符串不变，从而加倍利用训练数据。实验结果显示，数据匹配的逆向训练模型在标准任务上性能优于传统模型，而计算匹配的逆向训练模型在反转任务上表现出远 superior 性能，有效缓解了 Reversal Curse 问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13799v3",
      "published_date": "2024-03-20 17:55:35 UTC",
      "updated_date": "2024-05-07 20:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:14:32.975756"
    },
    {
      "arxiv_id": "2403.13798v2",
      "title": "Hierarchical NeuroSymbolic Approach for Comprehensive and Explainable Action Quality Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Lauren Okamoto",
        "Paritosh Parmar"
      ],
      "abstract": "Action quality assessment (AQA) applies computer vision to quantitatively\nassess the performance or execution of a human action. Current AQA approaches\nare end-to-end neural models, which lack transparency and tend to be biased\nbecause they are trained on subjective human judgements as ground-truth. To\naddress these issues, we introduce a neuro-symbolic paradigm for AQA, which\nuses neural networks to abstract interpretable symbols from video data and\nmakes quality assessments by applying rules to those symbols. We take diving as\nthe case study. We found that domain experts prefer our system and find it more\ninformative than purely neural approaches to AQA in diving. Our system also\nachieves state-of-the-art action recognition and temporal segmentation, and\nautomatically generates a detailed report that breaks the dive down into its\nelements and provides objective scoring with visual evidence. As verified by a\ngroup of domain experts, this report may be used to assist judges in scoring,\nhelp train judges, and provide feedback to divers. Annotated training data and\ncode: https://github.com/laurenok24/NSAQA.",
      "tldr_zh": "本文提出了一种分层神经符号(neuro-symbolic)方法，用于全面且可解释的行动质量评估(AQA)，以解决现有端到端神经模型的透明度不足和易受主观偏见的问题。该方法使用神经网络从视频数据中提取可解释符号，并通过规则应用进行质量评估，以跳水为例，获得领域专家的认可并被视为更具信息性。系统实现了最先进的行动识别(action recognition)和时间分割(temporal segmentation)，并自动生成详细报告，包括动作分解、客观评分和视觉证据，可用于辅助裁判训练、提供反馈给运动员。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 CVSports (Oral Presentation; 3/3 Strong Accepts) + Selected\n  for CVPR 2024 Demos",
      "pdf_url": "http://arxiv.org/pdf/2403.13798v2",
      "published_date": "2024-03-20 17:55:21 UTC",
      "updated_date": "2024-05-24 17:44:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:14:45.594839"
    },
    {
      "arxiv_id": "2403.13784v6",
      "title": "The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency, and Usability in Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Matt White",
        "Ibrahim Haddad",
        "Cailean Osborne",
        "Xiao-Yang Yanglet Liu",
        "Ahmed Abdelmonsef",
        "Sachin Varghese",
        "Arnaud Le Hors"
      ],
      "abstract": "Generative artificial intelligence (AI) offers numerous opportunities for\nresearch and innovation, but its commercialization has raised concerns about\nthe transparency and safety of frontier AI models. Most models lack the\nnecessary components for full understanding, auditing, and reproducibility, and\nsome model producers use restrictive licenses whilst claiming that their models\nare \"open source\". To address these concerns, we introduce the Model Openness\nFramework (MOF), a three-tiered ranked classification system that rates machine\nlearning models based on their completeness and openness, following open\nscience principles. For each MOF class, we specify code, data, and\ndocumentation components of the model development lifecycle that must be\nreleased and under which open licenses. In addition, the Model Openness Tool\n(MOT) provides a user-friendly reference implementation to evaluate the\nopenness and completeness of models against the MOF classification system.\nTogether, the MOF and MOT provide timely practical guidance for (i) model\nproducers to enhance the openness and completeness of their publicly-released\nmodels, and (ii) model consumers to identify open models and their constituent\ncomponents that can be permissively used, studied, modified, and redistributed.\nThrough the MOF, we seek to establish completeness and openness as core tenets\nof responsible AI research and development, and to promote best practices in\nthe burgeoning open AI ecosystem.",
      "tldr_zh": "该论文提出了Model Openness Framework (MOF)，一个三层分类系统，用于评估机器学习模型的完整性和开放性，以提升AI的再现性、透明度和可用性。MOF遵循开放科学原则，规定模型开发生命周期中的代码、数据和文档组件必须在开放许可下发布，以解决生成式AI商业化带来的透明度与安全问题。同时，论文引入了Model Openness Tool (MOT)，一个用户友好的工具，用于评估模型的开放性和完整性。该框架旨在指导模型生产者改进公开模型的品质，并帮助模型消费者识别可 permissively 使用、研究、修改和再分发的组件，从而促进负责任的AI研究与发展生态。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.13784v6",
      "published_date": "2024-03-20 17:47:08 UTC",
      "updated_date": "2024-10-18 08:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:15:00.185237"
    },
    {
      "arxiv_id": "2403.13780v2",
      "title": "Information-Theoretic Distillation for Reference-less Summarization",
      "title_zh": "基于信息理论的无参考摘要蒸馏",
      "authors": [
        "Jaehun Jung",
        "Ximing Lu",
        "Liwei Jiang",
        "Faeze Brahman",
        "Peter West",
        "Pang Wei Koh",
        "Yejin Choi"
      ],
      "abstract": "The current winning recipe for automatic summarization is using proprietary\nlarge-scale language models (LLMs) such as ChatGPT as is, or imitation learning\nfrom them as teacher models. While increasingly ubiquitous dependence on such\nlarge-scale language models is convenient, there remains an important question\nof whether small-scale models could have achieved competitive results, if we\nwere to seek an alternative learning method -- that allows for a more\ncost-efficient, controllable, yet powerful summarizer. We present InfoSumm, a\nnovel framework to distill a powerful summarizer based on the\ninformation-theoretic objective for summarization, without relying on either\nthe LLM's capability or human-written references. To achieve this, we first\npropose a novel formulation of the desiderata of summarization (saliency,\nfaithfulness and brevity) through the lens of mutual information between the\noriginal document and the summary. Based on this formulation, we start off from\nPythia-2.8B as the teacher model, which is not yet capable of summarization,\nthen self-train the model to optimize for the information-centric measures of\nideal summaries. Distilling from the improved teacher, we arrive at a compact\nbut powerful summarizer with only 568M parameters that performs competitively\nagainst ChatGPT, without ever relying on ChatGPT's capabilities. Extensive\nanalysis demonstrates that our approach outperforms in-domain supervised models\nin human evaluation, let alone state-of-the-art unsupervised methods, and wins\nover ChatGPT in controllable summarization.",
      "tldr_zh": "该论文提出InfoSumm框架，一种基于信息理论的蒸馏方法，用于实现无参考摘要生成，避免依赖大型语言模型如ChatGPT或人工参考。框架通过互信息(mutual information)来量化摘要的saliency（相关性）、faithfulness（忠实性）和brevity（简洁性），从Pythia-2.8B模型出发进行自训练优化，最终蒸馏出一个仅568M参数的紧凑模型。实验结果显示，该模型在人类评估中优于现有监督和无监督方法，并在可控摘要任务上胜过ChatGPT，证明了小规模模型的竞争潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13780v2",
      "published_date": "2024-03-20 17:42:08 UTC",
      "updated_date": "2024-08-19 22:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:15:14.749262"
    },
    {
      "arxiv_id": "2403.15476v2",
      "title": "Learning to Infer Generative Template Programs for Visual Concepts",
      "title_zh": "翻译失败",
      "authors": [
        "R. Kenny Jones",
        "Siddhartha Chaudhuri",
        "Daniel Ritchie"
      ],
      "abstract": "People grasp flexible visual concepts from a few examples. We explore a\nneurosymbolic system that learns how to infer programs that capture visual\nconcepts in a domain-general fashion. We introduce Template Programs:\nprogrammatic expressions from a domain-specific language that specify\nstructural and parametric patterns common to an input concept. Our framework\nsupports multiple concept-related tasks, including few-shot generation and\nco-segmentation through parsing. We develop a learning paradigm that allows us\nto train networks that infer Template Programs directly from visual datasets\nthat contain concept groupings. We run experiments across multiple visual\ndomains: 2D layouts, Omniglot characters, and 3D shapes. We find that our\nmethod outperforms task-specific alternatives, and performs competitively\nagainst domain-specific approaches for the limited domains where they exist.",
      "tldr_zh": "这篇论文提出了一种神经符号系统，用于从少数示例中推断生成 Template Programs，这些程序通过领域特定语言捕获视觉概念的结构和参数模式。系统支持多种任务，包括 few-shot generation 和 co-segmentation，通过训练网络从包含概念分组的视觉数据集直接推断程序。实验在2D布局、Omniglot字符和3D形状等多个领域显示，该方法优于任务特定替代方案，并在有限领域中与领域特定方法竞争表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2024; Project page: https://rkjones4.github.io/template.html",
      "pdf_url": "http://arxiv.org/pdf/2403.15476v2",
      "published_date": "2024-03-20 17:29:58 UTC",
      "updated_date": "2024-06-09 21:54:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:15:23.711066"
    },
    {
      "arxiv_id": "2403.13765v1",
      "title": "Towards Principled Representation Learning from Videos for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dipendra Misra",
        "Akanksha Saran",
        "Tengyang Xie",
        "Alex Lamb",
        "John Langford"
      ],
      "abstract": "We study pre-training representations for decision-making using video data,\nwhich is abundantly available for tasks such as game agents and software\ntesting. Even though significant empirical advances have been made on this\nproblem, a theoretical understanding remains absent. We initiate the\ntheoretical investigation into principled approaches for representation\nlearning and focus on learning the latent state representations of the\nunderlying MDP using video data. We study two types of settings: one where\nthere is iid noise in the observation, and a more challenging setting where\nthere is also the presence of exogenous noise, which is non-iid noise that is\ntemporally correlated, such as the motion of people or cars in the background.\nWe study three commonly used approaches: autoencoding, temporal contrastive\nlearning, and forward modeling. We prove upper bounds for temporal contrastive\nlearning and forward modeling in the presence of only iid noise. We show that\nthese approaches can learn the latent state and use it to do efficient\ndownstream RL with polynomial sample complexity. When exogenous noise is also\npresent, we establish a lower bound result showing that the sample complexity\nof learning from video data can be exponentially worse than learning from\naction-labeled trajectory data. This partially explains why reinforcement\nlearning with video pre-training is hard. We evaluate these representational\nlearning methods in two visual domains, yielding results that are consistent\nwith our theoretical findings.",
      "tldr_zh": "本论文探讨从视频数据中预训练表示以支持强化学习（RL）的决策过程，针对潜在状态表示学习提供理论分析。研究者考察了两种噪声设置（iid 噪声和外生噪声），并评估三种方法：autoencoding、temporal contrastive learning 和 forward modeling，证明前两种方法在仅有 iid 噪声时能高效学习 MDP 潜在状态并实现下游 RL 的多项式样本复杂度。论文还证明，外生噪声的存在会导致从视频数据学习样本复杂度指数级恶化，部分解释了基于视频预训练的 RL 难度，并通过两个视觉领域的实验验证了这些理论发现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024 Spotlight Conference Paper",
      "pdf_url": "http://arxiv.org/pdf/2403.13765v1",
      "published_date": "2024-03-20 17:28:17 UTC",
      "updated_date": "2024-03-20 17:28:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:15:38.281793"
    },
    {
      "arxiv_id": "2403.13741v1",
      "title": "Hyper Strategy Logic",
      "title_zh": "Hyper 策略逻辑",
      "authors": [
        "Raven Beutner",
        "Bernd Finkbeiner"
      ],
      "abstract": "Strategy logic (SL) is a powerful temporal logic that enables strategic\nreasoning in multi-agent systems. SL supports explicit (first-order)\nquantification over strategies and provides a logical framework to express many\nimportant properties such as Nash equilibria, dominant strategies, etc. While\nin SL the same strategy can be used in multiple strategy profiles, each such\nprofile is evaluated w.r.t. a path-property, i.e., a property that considers\nthe single path resulting from a particular strategic interaction. In this\npaper, we present Hyper Strategy Logic (HyperSL), a strategy logic where the\noutcome of multiple strategy profiles can be compared w.r.t. a hyperproperty,\ni.e., a property that relates multiple paths. We show that HyperSL can capture\nimportant properties that cannot be expressed in SL, including\nnon-interference, quantitative Nash equilibria, optimal adversarial planning,\nand reasoning under imperfect information. On the algorithmic side, we identify\nan expressive fragment of HyperSL with decidable model checking and present a\nmodel-checking algorithm. We contribute a prototype implementation of our\nalgorithm and report on encouraging experimental results.",
      "tldr_zh": "本论文引入了 Hyper Strategy Logic (HyperSL)，一种扩展 Strategy Logic (SL) 的逻辑框架，允许对多智能体系统中多个策略配置文件的路径进行比较，以评估超属性 (hyperproperty)，从而表达 SL 无法捕捉的重要性质，如 non-interference、quantitative Nash equilibria、optimal adversarial planning 和 reasoning under imperfect information。相比 SL，HyperSL 通过这种比较机制增强了战略推理能力，使其适用于更复杂的场景。论文还标识了一个可判定的 HyperSL 片段，提出了一套模型检查算法，并通过原型实现和实验结果验证了其有效性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.MA",
      "comment": "AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.13741v1",
      "published_date": "2024-03-20 16:47:53 UTC",
      "updated_date": "2024-03-20 16:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:15:48.974528"
    },
    {
      "arxiv_id": "2403.13729v1",
      "title": "Reinforcement Learning for Online Testing of Autonomous Driving Systems: a Replication and Extension Study",
      "title_zh": "强化学习用于自动驾驶系统的在线测试：一个复制和扩展研究",
      "authors": [
        "Luca Giamattei",
        "Matteo Biagiola",
        "Roberto Pietrantuono",
        "Stefano Russo",
        "Paolo Tonella"
      ],
      "abstract": "In a recent study, Reinforcement Learning (RL) used in combination with\nmany-objective search, has been shown to outperform alternative techniques\n(random search and many-objective search) for online testing of Deep Neural\nNetwork-enabled systems. The empirical evaluation of these techniques was\nconducted on a state-of-the-art Autonomous Driving System (ADS). This work is a\nreplication and extension of that empirical study. Our replication shows that\nRL does not outperform pure random test generation in a comparison conducted\nunder the same settings of the original study, but with no confounding factor\ncoming from the way collisions are measured. Our extension aims at eliminating\nsome of the possible reasons for the poor performance of RL observed in our\nreplication: (1) the presence of reward components providing contrasting or\nuseless feedback to the RL agent; (2) the usage of an RL algorithm (Q-learning)\nwhich requires discretization of an intrinsically continuous state space.\nResults show that our new RL agent is able to converge to an effective policy\nthat outperforms random testing. Results also highlight other possible\nimprovements, which open to further investigations on how to best leverage RL\nfor online ADS testing.",
      "tldr_zh": "该研究是对先前工作的复制和扩展，评估强化学习 (RL) 与多目标搜索结合用于自动驾驶系统 (ADS) 在线测试的性能。复制实验在控制碰撞测量混杂因素后发现，RL 不优于纯随机测试。扩展部分通过优化奖励组件和采用更适合连续状态空间的 RL 算法（如 Q-learning 的改进），使新 RL 代理能够收敛到有效策略并超越随机测试。结果突显了进一步优化 RL 在 ADS 测试中的潜力，为未来研究提供了方向。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13729v1",
      "published_date": "2024-03-20 16:39:17 UTC",
      "updated_date": "2024-03-20 16:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:16:00.903908"
    },
    {
      "arxiv_id": "2403.13728v3",
      "title": "M-HOF-Opt: Multi-Objective Hierarchical Output Feedback Optimization via Multiplier Induced Loss Landscape Scheduling",
      "title_zh": "翻译失败",
      "authors": [
        "Xudong Sun",
        "Nutan Chen",
        "Alexej Gossmann",
        "Matteo Wohlrapp",
        "Yu Xing",
        "Carla Feistner",
        "Emilio Dorigatt",
        "Felix Drost",
        "Daniele Scarcella",
        "Lisa Beer",
        "Carsten Marr"
      ],
      "abstract": "A probabilistic graphical model is proposed, modeling the joint model\nparameter and multiplier evolution, with a hypervolume based likelihood,\npromoting multi-objective descent in structural risk minimization. We address\nmulti-objective model parameter optimization via a surrogate single objective\npenalty loss with time-varying multipliers, equivalent to online scheduling of\nloss landscape. The multi-objective descent goal is dispatched hierarchically\ninto a series of constraint optimization sub-problems with shrinking bounds\naccording to Pareto dominance. The bound serves as setpoint for the low-level\nmultiplier controller to schedule loss landscapes via output feedback of each\nloss term. Our method forms closed loop of model parameter dynamic, circumvents\nexcessive memory requirements and extra computational burden of existing\nmulti-objective deep learning methods, and is robust against controller\nhyperparameter variation, demonstrated on domain generalization tasks with\nmulti-dimensional regularization losses.",
      "tldr_zh": "本论文提出了一种名为 M-HOF-Opt 的多目标层次化输出反馈优化方法，通过概率图形模型和基于超体积的似然来促进多目标下降，并利用时间变化的乘子来调度损失景观。\n该方法将多目标优化分解为层次化的约束优化子问题，根据 Pareto Dominance 缩小边界，并通过输出反馈控制来动态调整每个损失项，实现模型参数的闭环优化。\n与现有多目标深度学习方法相比，M-HOF-Opt 减少了内存需求和计算负担，并在领域泛化任务中显示出对控制器超参数变化的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13728v3",
      "published_date": "2024-03-20 16:38:26 UTC",
      "updated_date": "2025-03-11 14:02:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:16:14.359606"
    },
    {
      "arxiv_id": "2403.13721v1",
      "title": "Large Language Models meet Network Slicing Management and Orchestration",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulhalim Dandoush",
        "Viswanath Kumarskandpriya",
        "Mueen Uddin",
        "Usman Khalil"
      ],
      "abstract": "Network slicing, a cornerstone technology for future networks, enables the\ncreation of customized virtual networks on a shared physical infrastructure.\nThis fosters innovation and agility by providing dedicated resources tailored\nto specific applications. However, current orchestration and management\napproaches face limitations in handling the complexity of new service demands\nwithin multi-administrative domain environments. This paper proposes a future\nvision for network slicing powered by Large Language Models (LLMs) and\nmulti-agent systems, offering a framework that can be integrated with existing\nManagement and Orchestration (MANO) frameworks. This framework leverages LLMs\nto translate user intent into technical requirements, map network functions to\ninfrastructure, and manage the entire slice lifecycle, while multi-agent\nsystems facilitate collaboration across different administrative domains. We\nalso discuss the challenges associated with implementing this framework and\npotential solutions to mitigate them.",
      "tldr_zh": "本论文探讨Large Language Models (LLMs) 如何应用于网络切片的管理和编排，以解决多管理域环境中复杂服务需求的局限性。提出一个集成LLMs和多智能体系统的框架，该框架可与现有Management and Orchestration (MANO) 框架兼容，利用LLMs将用户意图转化为技术要求、映射网络功能到基础设施，并管理整个切片生命周期。同时，多智能体系统促进跨行政域的协作，并讨论了实施挑战及其潜在解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13721v1",
      "published_date": "2024-03-20 16:29:52 UTC",
      "updated_date": "2024-03-20 16:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:16:25.035834"
    },
    {
      "arxiv_id": "2403.15474v2",
      "title": "EC-IoU: Orienting Safety for Object Detectors via Ego-Centric Intersection-over-Union",
      "title_zh": "翻译失败",
      "authors": [
        "Brian Hsuan-Cheng Liao",
        "Chih-Hong Cheng",
        "Hasan Esen",
        "Alois Knoll"
      ],
      "abstract": "This paper presents Ego-Centric Intersection-over-Union (EC-IoU), addressing\nthe limitation of the standard IoU measure in characterizing safety-related\nperformance for object detectors in navigating contexts. Concretely, we propose\na weighting mechanism to refine IoU, allowing it to assign a higher score to a\nprediction that covers closer points of a ground-truth object from the ego\nagent's perspective. The proposed EC-IoU measure can be used in typical\nevaluation processes to select object detectors with better safety-related\nperformance for downstream tasks. It can also be integrated into common loss\nfunctions for model fine-tuning. While geared towards safety, our experiment\nwith the KITTI dataset demonstrates the performance of a model trained on\nEC-IoU can be better than that of a variant trained on IoU in terms of mean\nAverage Precision as well.",
      "tldr_zh": "这篇论文提出了 Ego-Centric Intersection-over-Union (EC-IoU)，一种改进标准 IoU 的度量方法，旨在提升物体检测器在导航场景中的安全性能。\nEC-IoU 通过引入加权机制，更重视从自我代理（ego agent）视角的地面实物近距离点，从而更好地评估预测的准确性。\n该方法可用于物体检测器的评估过程和损失函数微调，实验在 KITTI 数据集上表明，EC-IoU 训练的模型在平均精度 (mAP) 上优于标准 IoU，同时显著提高了安全相关性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages (IEEE double column format), 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.15474v2",
      "published_date": "2024-03-20 16:25:49 UTC",
      "updated_date": "2025-01-02 11:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:16:37.599591"
    },
    {
      "arxiv_id": "2403.13705v1",
      "title": "Research Re: search & Re-search",
      "title_zh": "翻译失败",
      "authors": [
        "Aske Plaat"
      ],
      "abstract": "Search algorithms are often categorized by their node expansion strategy. One\noption is the depth-first strategy, a simple backtracking strategy that\ntraverses the search space in the order in which successor nodes are generated.\nAn alternative is the best-first strategy, which was designed to make it\npossible to use domain-specific heuristic information. By exploring promising\nparts of the search space first, best-first algorithms are usually more\nefficient than depth-first algorithms.\n  In programs that play minimax games such as chess and checkers, the\nefficiency of the search is of crucial importance. Given the success of\nbest-first algorithms in other domains, one would expect them to be used for\nminimax games too. However, all high-performance game-playing programs are\nbased on a depth-first algorithm.\n  This study takes a closer look at a depth-first algorithm, AB, and a\nbest-first algorithm, SSS. The prevailing opinion on these algorithms is that\nSSS offers the potential for a more efficient search, but that its complicated\nformulation and exponential memory requirements render it impractical. The\ntheoretical part of this work shows that there is a surprisingly\nstraightforward link between the two algorithms -- for all practical purposes,\nSSS is a special case of AB. Subsequent empirical evidence proves the\nprevailing opinion on SSS to be wrong: it is not a complicated algorithm, it\ndoes not need too much memory, and it is also not more efficient than\ndepth-first search.",
      "tldr_zh": "这篇论文探讨了搜索算法的分类，特别是 depth-first strategy 和 best-first strategy 在 minimax games（如棋类游戏）中的应用。研究通过理论分析揭示了 AB algorithm 和 SSS algorithm 之间的直接联系，即 SSS 实际上是 AB 的一个特例。实证证据进一步证明，SSS 算法并不像传统观点那样复杂、内存需求过高或更高效，从而为搜索算法的设计提供了新的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "PhD thesis Aske Plaat 20 June 1996. AlphaBeta, SSS*, MTD(f)",
      "pdf_url": "http://arxiv.org/pdf/2403.13705v1",
      "published_date": "2024-03-20 16:08:57 UTC",
      "updated_date": "2024-03-20 16:08:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:16:47.513863"
    },
    {
      "arxiv_id": "2403.13703v1",
      "title": "Fostc3net:A Lightweight YOLOv5 Based On the Network Structure Optimization",
      "title_zh": "Fostc3net：基于网络结构优化的轻量级 YOLOv5",
      "authors": [
        "Danqing Ma",
        "Shaojie Li",
        "Bo Dang",
        "Hengyi Zang",
        "Xinqi Dong"
      ],
      "abstract": "Transmission line detection technology is crucial for automatic monitoring\nand ensuring the safety of electrical facilities. The YOLOv5 series is\ncurrently one of the most advanced and widely used methods for object\ndetection. However, it faces inherent challenges, such as high computational\nload on devices and insufficient detection accuracy. To address these concerns,\nthis paper presents an enhanced lightweight YOLOv5 technique customized for\nmobile devices, specifically intended for identifying objects associated with\ntransmission lines. The C3Ghost module is integrated into the convolutional\nnetwork of YOLOv5 to reduce floating point operations per second (FLOPs) in the\nfeature channel fusion process and improve feature expression performance. In\naddition, a FasterNet module is introduced to replace the c3 module in the\nYOLOv5 Backbone. The FasterNet module uses Partial Convolutions to process only\na portion of the input channels, improving feature extraction efficiency and\nreducing computational overhead. To address the imbalance between simple and\nchallenging samples in the dataset and the diversity of aspect ratios of\nbounding boxes, the wIoU v3 LOSS is adopted as the loss function. To validate\nthe performance of the proposed approach, Experiments are conducted on a custom\ndataset of transmission line poles. The results show that the proposed model\nachieves a 1% increase in detection accuracy, a 13% reduction in FLOPs, and a\n26% decrease in model parameters compared to the existing YOLOv5.In the\nablation experiment, it was also discovered that while the Fastnet module and\nthe CSghost module improved the precision of the original YOLOv5 baseline\nmodel, they caused a decrease in the mAP@.5-.95 metric. However, the\nimprovement of the wIoUv3 loss function significantly mitigated the decline of\nthe mAP@.5-.95 metric.",
      "tldr_zh": "本论文提出了一种轻量级YOLOv5变体，名为Fostc3net，针对输电线检测优化网络结构，以解决YOLOv5的高计算负载和检测准确率不足问题。改进方法包括整合C3Ghost模块来减少FLOPs并提升特征表达性能，以及引入FasterNet模块替换Backbone中的C3模块，利用Partial Convolutions提高特征提取效率并降低计算开销；此外，采用wIoU v3 LOSS作为损失函数，以处理数据集样本不平衡和边界框比例多样性。实验结果显示，在自定义传输线杆数据集上，该模型相比原YOLOv5检测准确率提高1%、FLOPs减少13%、模型参数减少26%；然而，消融实验表明FasterNet和C3Ghost模块虽提升了精度，但降低了mAP@.5-.95指标，而wIoU v3 LOSS显著缓解了这一下降。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13703v1",
      "published_date": "2024-03-20 16:07:04 UTC",
      "updated_date": "2024-03-20 16:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:17:03.666771"
    },
    {
      "arxiv_id": "2403.15472v3",
      "title": "Enhancing Programming Education with ChatGPT: A Case Study on Student Perceptions and Interactions in a Python Course",
      "title_zh": "使用 ChatGPT 提升编程教育：Python 课程中学生感知和互动的案例研究",
      "authors": [
        "Boxaun Ma",
        "Li Chen",
        "Shin'ichi Konomi"
      ],
      "abstract": "The integration of ChatGPT as a supportive tool in education, notably in\nprogramming courses, addresses the unique challenges of programming education\nby providing assistance with debugging, code generation, and explanations.\nDespite existing research validating ChatGPT's effectiveness, its application\nin university-level programming education and a detailed understanding of\nstudent interactions and perspectives remain limited. This paper explores\nChatGPT's impact on learning in a Python programming course tailored for\nfirst-year students over eight weeks. By analyzing responses from surveys,\nopen-ended questions, and student-ChatGPT dialog data, we aim to provide a\ncomprehensive view of ChatGPT's utility and identify both its advantages and\nlimitations as perceived by students. Our study uncovers a generally positive\nreception toward ChatGPT and offers insights into its role in enhancing the\nprogramming education experience. These findings contribute to the broader\ndiscourse on AI's potential in education, suggesting paths for future research\nand application.",
      "tldr_zh": "这篇论文探讨了在大学 Python 编程课程中使用 ChatGPT 作为辅助工具，以解决编程教育的挑战，如调试、代码生成和解释。研究通过对大一学生进行为期八周的案例分析，包括调查、开放式问题和学生-ChatGPT 对话数据的收集，评估了其实际影响。结果显示学生对 ChatGPT 的整体接受度较高，突出了其在提升学习体验方面的优势，同时也指出了潜在局限性。该研究为 AI 在教育中的应用提供了重要见解，并提出了未来的研究方向。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15472v3",
      "published_date": "2024-03-20 15:47:28 UTC",
      "updated_date": "2024-04-05 11:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:17:13.660150"
    },
    {
      "arxiv_id": "2403.13684v3",
      "title": "SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjun Wang",
        "Sagar Vaze",
        "Kai Han"
      ],
      "abstract": "Generalized Category Discovery (GCD) aims to classify unlabelled images from\nboth `seen' and `unseen' classes by transferring knowledge from a set of\nlabelled `seen' class images. A key theme in existing GCD approaches is\nadapting large-scale pre-trained models for the GCD task. An alternate\nperspective, however, is to adapt the data representation itself for better\nalignment with the pre-trained model. As such, in this paper, we introduce a\ntwo-stage adaptation approach termed SPTNet, which iteratively optimizes model\nparameters (i.e., model-finetuning) and data parameters (i.e., prompt\nlearning). Furthermore, we propose a novel spatial prompt tuning method (SPT)\nwhich considers the spatial property of image data, enabling the method to\nbetter focus on object parts, which can transfer between seen and unseen\nclasses. We thoroughly evaluate our SPTNet on standard benchmarks and\ndemonstrate that our method outperforms existing GCD methods. Notably, we find\nour method achieves an average accuracy of 61.4% on the SSB, surpassing prior\nstate-of-the-art methods by approximately 10%. The improvement is particularly\nremarkable as our method yields extra parameters amounting to only 0.117% of\nthose in the backbone architecture. Project page:\nhttps://visual-ai.github.io/sptnet.",
      "tldr_zh": "该论文提出SPTNet，一种高效的框架，用于Generalized Category Discovery (GCD)，通过从已标记的“seen”类图像转移知识来分类未标记的“seen”和“unseen”类图像。SPTNet采用两阶段适应方法，结合model-finetuning和prompt learning，并引入新型Spatial Prompt Tuning (SPT)，利用图像的空间属性来更好地关注物体部分，从而提升知识转移效果。在标准基准测试中，SPTNet在SSB数据集上实现61.4%的平均准确率，比现有最先进方法高出约10%，同时额外参数仅占主干架构的0.117%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "v3: Fix bold typos in table 2 and 3; v2: Update DINOv2 results;\n  Accepted as a conference paper at ICLR 2024; Project page:\n  https://visual-ai.github.io/sptnet",
      "pdf_url": "http://arxiv.org/pdf/2403.13684v3",
      "published_date": "2024-03-20 15:41:39 UTC",
      "updated_date": "2025-03-12 08:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:17:26.541467"
    },
    {
      "arxiv_id": "2403.13682v5",
      "title": "Threats, Attacks, and Defenses in Machine Unlearning: A Survey",
      "title_zh": "机器取消学习中的威胁、攻击与防御：一项综述",
      "authors": [
        "Ziyao Liu",
        "Huanyi Ye",
        "Chen Chen",
        "Yongsen Zheng",
        "Kwok-Yan Lam"
      ],
      "abstract": "Machine Unlearning (MU) has recently gained considerable attention due to its\npotential to achieve Safe AI by removing the influence of specific data from\ntrained Machine Learning (ML) models. This process, known as knowledge removal,\naddresses AI governance concerns of training data such as quality, sensitivity,\ncopyright restrictions, and obsolescence. This capability is also crucial for\nensuring compliance with privacy regulations such as the Right To Be Forgotten\n(RTBF). Furthermore, effective knowledge removal mitigates the risk of harmful\noutcomes, safeguarding against biases, misinformation, and unauthorized data\nexploitation, thereby enhancing the safe and responsible use of AI systems.\nEfforts have been made to design efficient unlearning approaches, with MU\nservices being examined for integration with existing machine learning as a\nservice (MLaaS), allowing users to submit requests to remove specific data from\nthe training corpus. However, recent research highlights vulnerabilities in\nmachine unlearning systems, such as information leakage and malicious\nunlearning, that can lead to significant security and privacy concerns.\nMoreover, extensive research indicates that unlearning methods and prevalent\nattacks fulfill diverse roles within MU systems. This underscores the intricate\nrelationship and complex interplay among these mechanisms in maintaining system\nfunctionality and safety. This survey aims to fill the gap between the\nextensive number of studies on threats, attacks, and defenses in machine\nunlearning and the absence of a comprehensive review that categorizes their\ntaxonomy, methods, and solutions, thus offering valuable insights for future\nresearch directions and practical implementations.",
      "tldr_zh": "这篇调查论文探讨了 Machine Unlearning (MU) 中的威胁、攻击和防御，MU 是一种从训练过的 Machine Learning (ML) 模型中移除特定数据影响的方法，以实现 Safe AI、遵守隐私法规如 Right To Be Forgotten (RTBF)，并处理数据质量、敏感性和版权问题。论文强调了 MU 的益处，如减少偏见和信息滥用，但也揭示了系统漏洞，包括信息泄露和恶意 unlearning，这些可能导致安全和隐私风险。最终，通过分类 MU 中的威胁、攻击防御的分类学、方法和解决方案，该调查为未来研究方向和实际 MLaaS 实施提供了宝贵见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by IEEE Open Journal of the Computer Society",
      "pdf_url": "http://arxiv.org/pdf/2403.13682v5",
      "published_date": "2024-03-20 15:40:18 UTC",
      "updated_date": "2025-02-17 05:57:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:17:39.646911"
    },
    {
      "arxiv_id": "2403.13681v2",
      "title": "PARAMANU-AYN: Pretrain from scratch or Continual Pretraining of LLMs for Legal Domain Adaptation?",
      "title_zh": "翻译失败",
      "authors": [
        "Mitodru Niyogi",
        "Arnab Bhattacharya"
      ],
      "abstract": "In this paper, we present Paramanu-Ayn, a collection of legal language models\ntrained exclusively on Indian legal case documents. This 97-million-parameter\nAuto-Regressive (AR) decoder-only model was pretrained from scratch with a\ncontext size of 8192 on a single GPU for just 185 hours, achieving an efficient\nMFU of 41.35. We also developed a legal domain specialized BPE tokenizer. We\nevaluated our model using perplexity and zero-shot tasks: case judgment\nprediction with explanation and abstractive case summarization. Paramanu-Ayn\noutperformed Llama-2 7B and Gemini-Pro in case judgment prediction with\nexplanation task on test accuracy by nearly 2 percentage points, despite being\n72 times smaller. In zero-shot abstractive summarization, it surpassed\ndecoder-only LLMs generating fixed-length summaries (5000 tokens) by over 10\npercentage points in BLEU and METEOR metrics, and by nearly 4 percentage points\nin BERTScore. Further evaluations on zero-shot commonsense and mathematical\nbenchmarks showed that Paramanu-Ayn excelled despite being trained exclusively\non legal documents, outperforming Llama-1, Llama-2, and Falcon on\nAGIEVAL-AQuA-RAT and AGIEVAL-SAT-Math tasks. We also instruction-tuned our\nmodel on 10,763 diverse legal tasks, including legal clause generation, legal\ndrafting, case summarization, etc. The Paramanu-Ayn-instruct model scored above\n8 out of 10 in clarity, relevance, completeness, and legal reasoning metrics by\nGPT-3.5-Turbo. We found that our models, were able to learn drafting knowledge\nand generalize to draft legal contracts and legal clauses with limited\ninstruction-tuning. Hence, we conclude that for a strong domain-specialized\ngenerative language model (such as legal), domain specialized pretraining from\nscratch is more cost effective, environmentally friendly, and remains\ncompetitive with larger models or even better than adapting LLMs for legal\ndomain tasks.",
      "tldr_zh": "本研究介绍了Paramanu-AYN，一款基于印度法律案例文档从零开始预训练的9700万参数Auto-Regressive（AR）模型，使用自定义BPE tokenizer，在单GPU上仅训练185小时，实现了高效的MFU 41.35。该模型在案例判断预测（准确率比Llama-2 7B和Gemini-Pro高约2%）和零样本抽象摘要生成（BLEU和METEOR指标提升超过10%）等任务上表现出色，尽管其规模小得多，还在AGIEVAL-AQuA-RAT和AGIEVAL-SAT-Math基准上超越了Llama-1、Llama-2和Falcon。作者通过指令微调验证了模型在法律任务（如合同起草）的泛化能力，并得出结论：针对强领域（如法律）的LLMs，从零开始的领域特定预训练比Continual Pretraining更具成本效益、环保且竞争力更强。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13681v2",
      "published_date": "2024-03-20 15:39:54 UTC",
      "updated_date": "2024-10-03 16:01:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:17:52.986991"
    },
    {
      "arxiv_id": "2403.13653v2",
      "title": "Learning User Embeddings from Human Gaze for Personalised Saliency Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Strohm",
        "Mihai Bâce",
        "Andreas Bulling"
      ],
      "abstract": "Reusable embeddings of user behaviour have shown significant performance\nimprovements for the personalised saliency prediction task. However, prior\nworks require explicit user characteristics and preferences as input, which are\noften difficult to obtain. We present a novel method to extract user embeddings\nfrom pairs of natural images and corresponding saliency maps generated from a\nsmall amount of user-specific eye tracking data. At the core of our method is a\nSiamese convolutional neural encoder that learns the user embeddings by\ncontrasting the image and personal saliency map pairs of different users.\nEvaluations on two public saliency datasets show that the generated embeddings\nhave high discriminative power, are effective at refining universal saliency\nmaps to the individual users, and generalise well across users and images.\nFinally, based on our model's ability to encode individual user\ncharacteristics, our work points towards other applications that can benefit\nfrom reusable embeddings of gaze behaviour.",
      "tldr_zh": "本研究提出了一种新方法，通过少量的用户特定眼动数据，从自然图像和对应的显著性地图（saliency maps）对中学习用户嵌入（user embeddings），以实现个性化的显著性预测。该方法的核心是使用 Siamese 卷积神经编码器，通过对比不同用户的图像和个人显著性地图对，来提取高区分力的用户嵌入。在两个公共显著性数据集上的评估显示，这些嵌入能有效将通用显著性地图细化到个体用户，并具有良好的泛化性，最终为其他依赖于凝视行为的应用提供了潜在益处。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13653v2",
      "published_date": "2024-03-20 14:58:40 UTC",
      "updated_date": "2024-03-26 08:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:18:01.187159"
    },
    {
      "arxiv_id": "2404.10177v2",
      "title": "Consistent Diffusion Meets Tweedie: Training Exact Ambient Diffusion Models with Noisy Data",
      "title_zh": "翻译失败",
      "authors": [
        "Giannis Daras",
        "Alexandros G. Dimakis",
        "Constantinos Daskalakis"
      ],
      "abstract": "Ambient diffusion is a recently proposed framework for training diffusion\nmodels using corrupted data. Both Ambient Diffusion and alternative SURE-based\napproaches for learning diffusion models from corrupted data resort to\napproximations which deteriorate performance. We present the first framework\nfor training diffusion models that provably sample from the uncorrupted\ndistribution given only noisy training data, solving an open problem in this\nspace. Our key technical contribution is a method that uses a double\napplication of Tweedie's formula and a consistency loss function that allows us\nto extend sampling at noise levels below the observed data noise. We also\nprovide further evidence that diffusion models memorize from their training\nsets by identifying extremely corrupted images that are almost perfectly\nreconstructed, raising copyright and privacy concerns. Our method for training\nusing corrupted samples can be used to mitigate this problem. We demonstrate\nthis by fine-tuning Stable Diffusion XL to generate samples from a distribution\nusing only noisy samples. Our framework reduces the amount of memorization of\nthe fine-tuning dataset, while maintaining competitive performance.",
      "tldr_zh": "该研究提出了一种新框架，将 Consistent Diffusion 与 Tweedie's formula 相结合，用于训练 Ambient Diffusion 模型，能够从噪声数据中精确采样未损坏的分布，解决了现有方法（如 SURE-based 近似）的性能问题。关键技术包括双重应用 Tweedie's formula 和一个 consistency loss 函数，允许在低于观察噪声水平下进行采样。实验发现，扩散模型存在对训练集的记忆问题，可能引发版权和隐私担忧，而该框架通过使用噪声样本微调 Stable Diffusion XL，能显著减少记忆量，同时保持竞争性性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10177v2",
      "published_date": "2024-03-20 14:22:12 UTC",
      "updated_date": "2024-07-22 11:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:18:13.747760"
    },
    {
      "arxiv_id": "2404.00022v1",
      "title": "Analysing and Organising Human Communications for AI Fairness-Related Decisions: Use Cases from the Public Sector",
      "title_zh": "翻译失败",
      "authors": [
        "Mirthe Dankloff",
        "Vanja Skoric",
        "Giovanni Sileno",
        "Sennay Ghebreab",
        "Jacco Van Ossenbruggen",
        "Emma Beauxis-Aussalet"
      ],
      "abstract": "AI algorithms used in the public sector, e.g., for allocating social benefits\nor predicting fraud, often involve multiple public and private stakeholders at\nvarious phases of the algorithm's life-cycle. Communication issues between\nthese diverse stakeholders can lead to misinterpretation and misuse of\nalgorithms. We investigate the communication processes for AI fairness-related\ndecisions by conducting interviews with practitioners working on algorithmic\nsystems in the public sector. By applying qualitative coding analysis, we\nidentify key elements of communication processes that underlie fairness-related\nhuman decisions. We analyze the division of roles, tasks, skills, and\nchallenges perceived by stakeholders. We formalize the underlying communication\nissues within a conceptual framework that i. represents the communication\npatterns ii. outlines missing elements, such as actors who miss skills for\ntheir tasks. The framework is used for describing and analyzing key\norganizational issues for fairness-related decisions. Three general patterns\nemerge from the analysis: 1. Policy-makers, civil servants, and domain experts\nare less involved compared to developers throughout a system's life-cycle. This\nleads to developers taking on extra roles such as advisor, while they\npotentially miss the required skills and guidance from domain experts. 2.\nEnd-users and policy-makers often lack the technical skills to interpret a\nsystem's limitations, and rely on developer roles for making decisions\nconcerning fairness issues. 3. Citizens are structurally absent throughout a\nsystem's life-cycle, which may lead to decisions that do not include relevant\nconsiderations from impacted stakeholders.",
      "tldr_zh": "本研究通过对公共部门从业者的访谈和定性编码分析，调查了AI公平性相关决策中的人类沟通过程，旨在识别关键元素如角色分工、任务、技能和挑战。研究形式化了一个概念框架，用于表示沟通模式并突出缺失要素，例如参与者技能不足或指导缺失。分析结果显示了三个主要模式：政策制定者、公务员和领域专家在系统生命周期中参与较少，导致开发者承担额外角色；最终用户和政策制定者缺乏技术技能，依赖开发者处理公平问题；公民在整个过程中缺席，可能导致决策忽略受影响者的考虑。该框架为优化AI公平性决策的组织结构提供了宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00022v1",
      "published_date": "2024-03-20 14:20:42 UTC",
      "updated_date": "2024-03-20 14:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:18:28.166738"
    },
    {
      "arxiv_id": "2403.13619v1",
      "title": "Dynamic Resource Allocation for Virtual Machine Migration Optimization using Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yulu Gong",
        "Jiaxin Huang",
        "Bo Liu",
        "Jingyu Xu",
        "Binbin Wu",
        "Yifan Zhang"
      ],
      "abstract": "The paragraph is grammatically correct and logically coherent. It discusses\nthe importance of mobile terminal cloud computing migration technology in\nmeeting the demands of evolving computer and cloud computing technologies. It\nemphasizes the need for efficient data access and storage, as well as the\nutilization of cloud computing migration technology to prevent additional time\ndelays. The paragraph also highlights the contributions of cloud computing\nmigration technology to expanding cloud computing services. Additionally, it\nacknowledges the role of virtualization as a fundamental capability of cloud\ncomputing while emphasizing that cloud computing and virtualization are not\ninherently interconnected. Finally, it introduces machine learning-based\nvirtual machine migration optimization and dynamic resource allocation as a\ncritical research direction in cloud computing, citing the limitations of\nstatic rules or manual settings in traditional cloud computing environments.\nOverall, the paragraph effectively communicates the importance of machine\nlearning technology in addressing resource allocation and virtual machine\nmigration challenges in cloud computing.",
      "tldr_zh": "本论文探讨了使用Machine Learning优化虚拟机迁移的动态资源分配技术，以应对云计算环境中数据访问、存储和延迟挑战。传统方法依赖静态规则或手动设置，存在局限性，而本文强调Machine Learning在提升资源分配效率和扩展云服务方面的作用。研究指出，这种动态优化策略有助于减少迁移时间延迟，并为移动终端云计算迁移提供更可靠的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13619v1",
      "published_date": "2024-03-20 14:13:44 UTC",
      "updated_date": "2024-03-20 14:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:18:37.765242"
    },
    {
      "arxiv_id": "2403.13869v3",
      "title": "Accurately Predicting Probabilities of Safety-Critical Rare Events for Intelligent Systems",
      "title_zh": "准确预测智能系统安全关键稀有事件的概率",
      "authors": [
        "Ruoxuan Bai",
        "Jingxuan Yang",
        "Weiduo Gong",
        "Yi Zhang",
        "Qiujing Lu",
        "Shuo Feng"
      ],
      "abstract": "Intelligent systems are increasingly integral to our daily lives, yet rare\nsafety-critical events present significant latent threats to their practical\ndeployment. Addressing this challenge hinges on accurately predicting the\nprobability of safety-critical events occurring within a given time step from\nthe current state, a metric we define as 'criticality'. The complexity of\npredicting criticality arises from the extreme data imbalance caused by rare\nevents in high dimensional variables associated with the rare events, a\nchallenge we refer to as the curse of rarity. Existing methods tend to be\neither overly conservative or prone to overlooking safety-critical events, thus\nstruggling to achieve both high precision and recall rates, which severely\nlimits their applicability. This study endeavors to develop a criticality\nprediction model that excels in both precision and recall rates for evaluating\nthe criticality of safety-critical autonomous systems. We propose a multi-stage\nlearning framework designed to progressively densify the dataset, mitigating\nthe curse of rarity across stages. To validate our approach, we evaluate it in\ntwo cases: lunar lander and bipedal walker scenarios. The results demonstrate\nthat our method surpasses traditional approaches, providing a more accurate and\ndependable assessment of criticality in intelligent systems.",
      "tldr_zh": "智能系统中，准确预测安全关键稀有事件的概率（criticality）面临数据不平衡的“curse of rarity”挑战，导致现有方法难以兼顾高精度和高召回率。论文提出一个多阶段学习框架，通过逐步增加数据集密度来缓解这一问题，提升对安全关键事件的预测能力。在月球着陆器和双足步行器场景的验证中，该框架显著优于传统方法，提供更可靠的临界性评估。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13869v3",
      "published_date": "2024-03-20 14:00:29 UTC",
      "updated_date": "2024-04-05 15:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:18:50.630595"
    },
    {
      "arxiv_id": "2403.13597v2",
      "title": "No more optimization rules: LLM-enabled policy-based multi-modal query optimizer",
      "title_zh": "不再需要优化规则：基于 LLM 的策略导向多模态查询优化器",
      "authors": [
        "Yifan Wang",
        "Haodi Ma",
        "Daisy Zhe Wang"
      ],
      "abstract": "Large language model (LLM) has marked a pivotal moment in the field of\nmachine learning and deep learning. Recently its capability for query planning\nhas been investigated, including both single-modal and multi-modal queries.\nHowever, there is no work on the query optimization capability of LLM. As a\ncritical (or could even be the most important) step that significantly impacts\nthe execution performance of the query plan, such analysis and attempts should\nnot be missed. From another aspect, existing query optimizers are usually\nrule-based or rule-based + cost-based, i.e., they are dependent on manually\ncreated rules to complete the query plan rewrite/transformation. Given the fact\nthat modern optimizers include hundreds to thousands of rules, designing a\nmulti-modal query optimizer following a similar way is significantly\ntime-consuming since we will have to enumerate as many multi-modal optimization\nrules as possible, which has not been well addressed today. In this paper, we\ninvestigate the query optimization ability of LLM and use LLM to design LaPuda,\na novel LLM and Policy based multi-modal query optimizer. Instead of\nenumerating specific and detailed rules, LaPuda only needs a few abstract\npolicies to guide LLM in the optimization, by which much time and human effort\nare saved. Furthermore, to prevent LLM from making mistakes or negative\noptimization, we borrow the idea of gradient descent and propose a guided cost\ndescent (GCD) algorithm to perform the optimization, such that the optimization\ncan be kept in the correct direction. In our evaluation, our methods\nconsistently outperform the baselines in most cases. For example, the optimized\nplans generated by our methods result in 1~3x higher execution speed than those\nby the baselines.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLM) 在查询优化中的潜力，提出 LaPuda，一种基于 LLM 和策略的多模态查询优化器，以取代传统依赖数百到数千条手动规则的方法，从而节省时间和人力。LaPuda 通过少数抽象策略指导 LLM 进行查询计划优化，并引入 guided cost descent (GCD) 算法来防止错误，确保优化过程朝正确方向推进。实验结果显示，该方法在大多数情况下优于基线，生成的优化计划可将查询执行速度提高 1~3 倍。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "Yifan and Haodi contribute equally to the work",
      "pdf_url": "http://arxiv.org/pdf/2403.13597v2",
      "published_date": "2024-03-20 13:44:30 UTC",
      "updated_date": "2024-03-23 17:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:19:06.004049"
    },
    {
      "arxiv_id": "2403.13574v1",
      "title": "A Large Language Model Enhanced Sequential Recommender for Joint Video and Comment Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Zheng",
        "Zihan Lin",
        "Enze Liu",
        "Chen Yang",
        "Enyang Bai",
        "Cheng Ling",
        "Wayne Xin Zhao",
        "Ji-Rong Wen"
      ],
      "abstract": "In online video platforms, reading or writing comments on interesting videos\nhas become an essential part of the video watching experience. However,\nexisting video recommender systems mainly model users' interaction behaviors\nwith videos, lacking consideration of comments in user behavior modeling. In\nthis paper, we propose a novel recommendation approach called LSVCR by\nleveraging user interaction histories with both videos and comments, so as to\njointly conduct personalized video and comment recommendation. Specifically,\nour approach consists of two key components, namely sequential recommendation\n(SR) model and supplemental large language model (LLM) recommender. The SR\nmodel serves as the primary recommendation backbone (retained in deployment) of\nour approach, allowing for efficient user preference modeling. Meanwhile, we\nleverage the LLM recommender as a supplemental component (discarded in\ndeployment) to better capture underlying user preferences from heterogeneous\ninteraction behaviors. In order to integrate the merits of the SR model and the\nsupplemental LLM recommender, we design a twostage training paradigm. The first\nstage is personalized preference alignment, which aims to align the preference\nrepresentations from both components, thereby enhancing the semantics of the SR\nmodel. The second stage is recommendation-oriented fine-tuning, in which the\nalignment-enhanced SR model is fine-tuned according to specific objectives.\nExtensive experiments in both video and comment recommendation tasks\ndemonstrate the effectiveness of LSVCR. Additionally, online A/B testing on the\nKuaiShou platform verifies the actual benefits brought by our approach. In\nparticular, we achieve a significant overall gain of 4.13% in comment watch\ntime.",
      "tldr_zh": "该论文提出了一种名为 LSVCR 的新型推荐方法，用于联合视频和评论推荐，旨在通过整合用户对视频和评论的互动历史来提升在线视频平台的用户体验。LSVCR 包括顺序推荐 (SR) 模型作为主要骨干，用于高效建模用户偏好，以及补充的大语言模型 (LLM) 推荐器来捕捉异构互动行为的潜在偏好；通过两阶段训练范式，首先进行个性化偏好对齐以增强 SR 模型的语义表示，然后针对推荐目标进行微调。实验结果显示，LSVCR 在视频和评论推荐任务上表现出色，并在 KuaiShou 平台上的在线 A/B 测试中实现了评论观看时间提升 4.13%。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13574v1",
      "published_date": "2024-03-20 13:14:29 UTC",
      "updated_date": "2024-03-20 13:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:19:16.964950"
    },
    {
      "arxiv_id": "2403.13556v2",
      "title": "Find n' Propagate: Open-Vocabulary 3D Object Detection in Urban Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Djamahl Etchegaray",
        "Zi Huang",
        "Tatsuya Harada",
        "Yadan Luo"
      ],
      "abstract": "In this work, we tackle the limitations of current LiDAR-based 3D object\ndetection systems, which are hindered by a restricted class vocabulary and the\nhigh costs associated with annotating new object classes. Our exploration of\nopen-vocabulary (OV) learning in urban environments aims to capture novel\ninstances using pre-trained vision-language models (VLMs) with multi-sensor\ndata. We design and benchmark a set of four potential solutions as baselines,\ncategorizing them into either top-down or bottom-up approaches based on their\ninput data strategies. While effective, these methods exhibit certain\nlimitations, such as missing novel objects in 3D box estimation or applying\nrigorous priors, leading to biases towards objects near the camera or of\nrectangular geometries. To overcome these limitations, we introduce a universal\n\\textsc{Find n' Propagate} approach for 3D OV tasks, aimed at maximizing the\nrecall of novel objects and propagating this detection capability to more\ndistant areas thereby progressively capturing more. In particular, we utilize a\ngreedy box seeker to search against 3D novel boxes of varying orientations and\ndepth in each generated frustum and ensure the reliability of newly identified\nboxes by cross alignment and density ranker. Additionally, the inherent bias\ntowards camera-proximal objects is alleviated by the proposed remote simulator,\nwhich randomly diversifies pseudo-labeled novel instances in the self-training\nprocess, combined with the fusion of base samples in the memory bank. Extensive\nexperiments demonstrate a 53% improvement in novel recall across diverse OV\nsettings, VLMs, and 3D detectors. Notably, we achieve up to a 3.97-fold\nincrease in Average Precision (AP) for novel object classes. The source code is\nmade available at https://github.com/djamahl99/findnpropagate.",
      "tldr_zh": "本论文解决了基于 LiDAR 的 3D 对象检测系统在城市环境中的局限性，包括受限的类别词汇和标注新类别的成本高问题，通过利用预训练的 vision-language models (VLMs) 和多传感器数据实现 open-vocabulary (OV) 学习。作者引入了 \\textsc{Find n' Propagate} 框架，该框架采用贪婪框搜索器 (greedy box seeker) 来最大化新对象的召回率，并通过交叉对齐、密度排名器和远程模拟器 (remote simulator) 缓解对相机附近物体的偏见，同时在自训练过程中融合 base samples。实验结果显示，该方法在各种 OV 设置、VLMs 和 3D 检测器上，新对象的召回率提高了 53%，新类别 Average Precision (AP) 提升了多达 3.97 倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear in ECCV 2024. Source code:\n  https://github.com/djamahl99/findnpropagate",
      "pdf_url": "http://arxiv.org/pdf/2403.13556v2",
      "published_date": "2024-03-20 12:51:30 UTC",
      "updated_date": "2024-07-12 10:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:19:30.678925"
    },
    {
      "arxiv_id": "2403.13553v1",
      "title": "VCounselor: A Psychological Intervention Chat Agent Based on a Knowledge-Enhanced Large Language Model",
      "title_zh": "VCounselor：一种基于知识增强大型语言模型的心理干预聊天代理",
      "authors": [
        "H. Zhang",
        "Z. Qiao",
        "H. Wang",
        "B. Duan",
        "J. Yin"
      ],
      "abstract": "Conversational artificial intelligence can already independently engage in\nbrief conversations with clients with psychological problems and provide\nevidence-based psychological interventions. The main objective of this study is\nto improve the effectiveness and credibility of the large language model in\npsychological intervention by creating a specialized agent, the VCounselor, to\naddress the limitations observed in popular large language models such as\nChatGPT in domain applications. We achieved this goal by proposing a new\naffective interaction structure and knowledge-enhancement structure. In order\nto evaluate VCounselor, this study compared the general large language model,\nthe fine-tuned large language model, and VCounselor's knowledge-enhanced large\nlanguage model. At the same time, the general large language model and the\nfine-tuned large language model will also be provided with an avatar to compare\nthem as an agent with VCounselor. The comparison results indicated that the\naffective interaction structure and knowledge-enhancement structure of\nVCounselor significantly improved the effectiveness and credibility of the\npsychological intervention, and VCounselor significantly provided positive\ntendencies for clients' emotions. The conclusion of this study strongly\nsupports that VConselor has a significant advantage in providing psychological\nsupport to clients by being able to analyze the patient's problems with\nrelative accuracy and provide professional-level advice that enhances support\nfor clients.",
      "tldr_zh": "这篇论文介绍了 VCounselor，一种基于知识增强的 Large Language Model 的心理干预聊天代理，旨在解决如 ChatGPT 在心理领域应用的局限性问题。研究者提出 affective interaction structure 和 knowledge-enhancement structure 这两种新结构，以提升代理的有效性和可信度。实验结果显示，与一般或微调的 Large Language Model 相比，VCounselor 显著提高了心理干预的效果，并为客户端的情绪提供积极倾向，支持其在分析患者问题和提供专业建议方面的优势。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "J.4"
      ],
      "primary_category": "cs.HC",
      "comment": "24 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13553v1",
      "published_date": "2024-03-20 12:46:02 UTC",
      "updated_date": "2024-03-20 12:46:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:19:41.107839"
    },
    {
      "arxiv_id": "2405.09550v3",
      "title": "Mask-based Invisible Backdoor Attacks on Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongjin Shin"
      ],
      "abstract": "Deep learning models have achieved unprecedented performance in the domain of\nobject detection, resulting in breakthroughs in areas such as autonomous\ndriving and security. However, deep learning models are vulnerable to backdoor\nattacks. These attacks prompt models to behave similarly to standard models\nwithout a trigger; however, they act maliciously upon detecting a predefined\ntrigger. Despite extensive research on backdoor attacks in image\nclassification, their application to object detection remains relatively\nunderexplored. Given the widespread application of object detection in critical\nreal-world scenarios, the sensitivity and potential impact of these\nvulnerabilities cannot be overstated. In this study, we propose an effective\ninvisible backdoor attack on object detection utilizing a mask-based approach.\nThree distinct attack scenarios were explored for object detection: object\ndisappearance, object misclassification, and object generation attack. Through\nextensive experiments, we comprehensively examined the effectiveness of these\nattacks and tested certain defense methods to determine effective\ncountermeasures. Code will be available at\nhttps://github.com/jeongjin0/invisible-backdoor-object-detection",
      "tldr_zh": "本研究探讨了深度学习模型在物体检测领域的易受后门攻击（backdoor attacks）的漏洞，这些攻击可使模型在检测到预定义触发器时表现出恶意行为，而在正常情况下表现正常。研究提出了一种基于掩码（mask-based）的隐形后门攻击方法，针对物体检测探索了三种场景：物体消失、物体误分类和物体生成攻击。通过广泛实验验证，该攻击在多种设置下均显示出高有效性，并评估了某些防御方法以识别潜在对策。该工作强调了在关键应用如自动驾驶和安全中的潜在风险，并提供开源代码以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "I.4.8"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.09550v3",
      "published_date": "2024-03-20 12:27:30 UTC",
      "updated_date": "2024-06-04 11:28:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:19:52.676903"
    },
    {
      "arxiv_id": "2406.19397v1",
      "title": "How scanning probe microscopy can be supported by Artificial Intelligence and quantum computing",
      "title_zh": "人工智能和量子计算如何支持扫描探针显微镜",
      "authors": [
        "Agnieszka Pregowska",
        "Agata Roszkiewicz",
        "Magdalena Osial",
        "Michael Giersig"
      ],
      "abstract": "We focus on the potential possibilities for supporting Scanning Probe\nMicroscopy measurements, emphasizing the application of Artificial\nIntelligence, especially Machine Learning as well as quantum computing. It\nturned out that Artificial Intelligence can be helpful in the experimental\nprocesses automation in routine operations, the algorithmic search for good\nsample regions, and shed light on the structure property relationships. Thus,\nit contributes to increasing the efficiency and accuracy of optical nanoscopy\nscanning probes. Moreover, the combination of Artificial Intelligence based\nalgorithms and quantum computing may have a huge potential to increase the\npractical application of Scanning Probe Microscopy. The limitations were also\ndiscussed. Finally, we outline a research path for the improvement of the\nproposed approach.",
      "tldr_zh": "本论文探讨了如何通过 Artificial Intelligence（尤其是 Machine Learning）和 quantum computing 支持 Scanning Probe Microscopy（SPM）的测量应用。Artificial Intelligence 可以自动化实验过程、算法搜索最佳样本区域，并揭示结构属性关系，从而提高 SPM 在光学纳米显微镜中的效率和准确性。该方法结合 AI 算法与 quantum computing 可能极大扩展 SPM 的实际应用，尽管论文也讨论了潜在限制。最后，论文概述了改进该方法的未来研究路径。",
      "categories": [
        "q-bio.NC",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "q-bio.NC",
      "comment": "19 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.19397v1",
      "published_date": "2024-03-20 12:22:02 UTC",
      "updated_date": "2024-03-20 12:22:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:20:04.769059"
    },
    {
      "arxiv_id": "2403.13537v1",
      "title": "What explains the success of cross-modal fine-tuning with ORCA?",
      "title_zh": "什么解释了使用 ORCA 的跨模态微调的成功？",
      "authors": [
        "Paloma García-de-Herreros",
        "Vagrant Gautam",
        "Philipp Slusallek",
        "Dietrich Klakow",
        "Marius Mosbach"
      ],
      "abstract": "ORCA (Shen et al., 2023) is a recent technique for cross-modal fine-tuning,\ni.e., applying pre-trained transformer models to modalities beyond their\ntraining data. The technique consists primarily of training an embedder and\nfine-tuning the embedder and model. Despite its high performance on a variety\nof downstream tasks, we do not understand precisely how each of these\ncomponents contribute to ORCA's success. Therefore, we run a series of\nablations and find that embedder training does not help 2D tasks at all,\ncontrary to what the original paper posits. In 1D tasks, some amount of\nembedder training is necessary but more is not better. In 4 out of 6 datasets\nwe experiment with, it is model fine-tuning that makes the biggest difference.\nThrough our ablations and baselines, we contribute a better understanding of\nthe individual components of ORCA.",
      "tldr_zh": "本研究探讨了 ORCA 技术在跨模态微调(cross-modal fine-tuning)中的成功原因，通过一系列消融实验(ablation)分析其组件——嵌入器训练(embedder training)和模型微调(model fine-tuning)。结果显示，嵌入器训练对2D任务完全无益，而对1D任务仅需适量即可，过多并无优势；在6个数据集中的4个上，模型微调是性能提升的主要因素。总体而言，该工作为更好地理解 ORCA 的各个组件提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13537v1",
      "published_date": "2024-03-20 12:14:54 UTC",
      "updated_date": "2024-03-20 12:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:20:18.536168"
    },
    {
      "arxiv_id": "2403.13524v1",
      "title": "Compress3D: a Compressed Latent Space for 3D Generation from a Single Image",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Zhang",
        "Tianyu Yang",
        "Yu Li",
        "Lei Zhang",
        "Xi Zhao"
      ],
      "abstract": "3D generation has witnessed significant advancements, yet efficiently\nproducing high-quality 3D assets from a single image remains challenging. In\nthis paper, we present a triplane autoencoder, which encodes 3D models into a\ncompact triplane latent space to effectively compress both the 3D geometry and\ntexture information. Within the autoencoder framework, we introduce a 3D-aware\ncross-attention mechanism, which utilizes low-resolution latent representations\nto query features from a high-resolution 3D feature volume, thereby enhancing\nthe representation capacity of the latent space. Subsequently, we train a\ndiffusion model on this refined latent space. In contrast to solely relying on\nimage embedding for 3D generation, our proposed method advocates for the\nsimultaneous utilization of both image embedding and shape embedding as\nconditions. Specifically, the shape embedding is estimated via a diffusion\nprior model conditioned on the image embedding. Through comprehensive\nexperiments, we demonstrate that our method outperforms state-of-the-art\nalgorithms, achieving superior performance while requiring less training data\nand time. Our approach enables the generation of high-quality 3D assets in\nmerely 7 seconds on a single A100 GPU.",
      "tldr_zh": "本研究提出 Compress3D，一种基于 triplane autoencoder 的方法，将 3D 模型编码到紧凑的 triplane 潜在空间中，以高效压缩 3D 几何和纹理信息。\n该框架引入 3D-aware cross-attention 机制，利用低分辨率潜在表示查询高分辨率 3D 特征体积，并在该精炼空间上训练 diffusion model，同时使用图像嵌入和形状嵌入作为条件，其中形状嵌入通过条件 diffusion prior 模型估算。\n实验证明，Compress3D 优于现有算法，在减少训练数据和时间的情况下，实现更高性能，并在单个 A100 GPU 上仅需 7 秒生成高质量 3D 资产。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13524v1",
      "published_date": "2024-03-20 11:51:04 UTC",
      "updated_date": "2024-03-20 11:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:20:29.775961"
    },
    {
      "arxiv_id": "2403.13523v1",
      "title": "Have You Poisoned My Data? Defending Neural Networks against Data Poisoning",
      "title_zh": "翻译失败",
      "authors": [
        "Fabio De Gaspari",
        "Dorjan Hitaj",
        "Luigi V. Mancini"
      ],
      "abstract": "The unprecedented availability of training data fueled the rapid development\nof powerful neural networks in recent years. However, the need for such large\namounts of data leads to potential threats such as poisoning attacks:\nadversarial manipulations of the training data aimed at compromising the\nlearned model to achieve a given adversarial goal.\n  This paper investigates defenses against clean-label poisoning attacks and\nproposes a novel approach to detect and filter poisoned datapoints in the\ntransfer learning setting. We define a new characteristic vector representation\nof datapoints and show that it effectively captures the intrinsic properties of\nthe data distribution. Through experimental analysis, we demonstrate that\neffective poisons can be successfully differentiated from clean points in the\ncharacteristic vector space. We thoroughly evaluate our proposed approach and\ncompare it to existing state-of-the-art defenses using multiple architectures,\ndatasets, and poison budgets. Our evaluation shows that our proposal\noutperforms existing approaches in defense rate and final trained model\nperformance across all experimental settings.",
      "tldr_zh": "该论文探讨了数据中毒攻击（data poisoning）对神经网络（neural networks）的威胁，特别是clean-label poisoning attacks，这些攻击通过恶意操纵训练数据来破坏模型。作者提出了一种新方法，在转移学习（transfer learning）设置中，通过定义特征向量表示（characteristic vector representation）来捕捉数据分布的内在属性，从而检测和过滤中毒数据点。实验结果显示，该方法在多种架构、数据集和中毒预算（poison budgets）下，比现有最先进防御方案在防御率和最终模型性能上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted for publication at European Symposium on Research in\n  Computer Security (ESORICS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.13523v1",
      "published_date": "2024-03-20 11:50:16 UTC",
      "updated_date": "2024-03-20 11:50:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:20:40.455933"
    },
    {
      "arxiv_id": "2403.13866v1",
      "title": "The Bid Picture: Auction-Inspired Multi-player Generative Adversarial Networks Training",
      "title_zh": "翻译失败",
      "authors": [
        "Joo Yong Shim",
        "Jean Seong Bjorn Choe",
        "Jong-Kook Kim"
      ],
      "abstract": "This article proposes auction-inspired multi-player generative adversarial\nnetworks training, which mitigates the mode collapse problem of GANs. Mode\ncollapse occurs when an over-fitted generator generates a limited range of\nsamples, often concentrating on a small subset of the data distribution.\nDespite the restricted diversity of generated samples, the discriminator can\nstill be deceived into distinguishing these samples as real samples from the\nactual distribution. In the absence of external standards, a model cannot\nrecognize its failure during the training phase. We extend the two-player game\nof generative adversarial networks to the multi-player game. During the\ntraining, the values of each model are determined by the bids submitted by\nother players in an auction-like process.",
      "tldr_zh": "本研究提出了一种基于拍卖启发的多玩家 Generative Adversarial Networks (GANs) 训练方法，旨在缓解 GANs 的 mode collapse 问题，即生成器过度拟合导致生成的样本多样性不足，却仍能欺骗鉴别器。通过将传统的两人游戏扩展到多玩家游戏，模型在训练过程中通过其他玩家的竞标过程来确定其值，从而引入外部竞争机制提升样本多样性。该方法有助于模型在训练中识别自身不足，最终提高 GANs 的整体性能和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13866v1",
      "published_date": "2024-03-20 11:47:42 UTC",
      "updated_date": "2024-03-20 11:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:20:53.037012"
    },
    {
      "arxiv_id": "2403.13518v2",
      "title": "Motion Generation from Fine-grained Textual Descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Kunhang Li",
        "Yansong Feng"
      ],
      "abstract": "The task of text2motion is to generate human motion sequences from given\ntextual descriptions, where the model explores diverse mappings from natural\nlanguage instructions to human body movements. While most existing works are\nconfined to coarse-grained motion descriptions, e.g., \"A man squats.\",\nfine-grained descriptions specifying movements of relevant body parts are\nbarely explored. Models trained with coarse-grained texts may not be able to\nlearn mappings from fine-grained motion-related words to motion primitives,\nresulting in the failure to generate motions from unseen descriptions. In this\npaper, we build a large-scale language-motion dataset specializing in\nfine-grained textual descriptions, FineHumanML3D, by feeding GPT-3.5-turbo with\nstep-by-step instructions with pseudo-code compulsory checks. Accordingly, we\ndesign a new text2motion model, FineMotionDiffuse, making full use of\nfine-grained textual information. Our quantitative evaluation shows that\nFineMotionDiffuse trained on FineHumanML3D improves FID by a large margin of\n0.38, compared with competitive baselines. According to the qualitative\nevaluation and case study, our model outperforms MotionDiffuse in generating\nspatially or chronologically composite motions, by learning the implicit\nmappings from fine-grained descriptions to the corresponding basic motions. We\nrelease our data at https://github.com/KunhangL/finemotiondiffuse.",
      "tldr_zh": "这篇论文解决了 text2motion 任务，即从细粒度文本描述生成人类动作序列的问题，因为现有模型主要处理粗粒度描述（如“A man squats”），导致无法准确映射细粒度词语到动作原语。作者构建了一个大规模数据集 FineHumanML3D，使用 GPT-3.5-turbo 和伪代码检查生成细粒度文本描述。论文提出新模型 FineMotionDiffuse，通过充分利用细粒度信息，学习隐式映射生成空间或时间复合动作；实验结果显示，该模型在 FineHumanML3D 上训练后，FID 指标比基线改善了 0.38，并优于 MotionDiffuse。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13518v2",
      "published_date": "2024-03-20 11:38:30 UTC",
      "updated_date": "2024-03-26 11:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:21:09.330789"
    },
    {
      "arxiv_id": "2403.13513v2",
      "title": "What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junho Kim",
        "Yeon Ju Kim",
        "Yong Man Ro"
      ],
      "abstract": "This paper presents a way of enhancing the reliability of Large Multi-modal\nModels (LMMs) in addressing hallucination, where the models generate\ncross-modal inconsistent responses. Without additional training, we propose\nCounterfactual Inception, a novel method that implants counterfactual thinking\ninto LMMs using self-generated counterfactual keywords. Our method is grounded\nin the concept of counterfactual thinking, a cognitive process where human\nconsiders alternative realities, enabling more extensive context exploration.\nBridging the human cognition mechanism into LMMs, we aim for the models to\nengage with and generate responses that span a wider contextual scene\nunderstanding, mitigating hallucinatory outputs. We further introduce\nPlausibility Verification Process (PVP), a simple yet robust keyword constraint\nthat effectively filters out sub-optimal keywords to enable the consistent\ntriggering of counterfactual thinking in the model responses. Comprehensive\nanalyses across various LMMs, including both open-source and proprietary\nmodels, corroborate that counterfactual thinking significantly reduces\nhallucination and helps to broaden contextual understanding based on true\nvisual clues.",
      "tldr_zh": "这篇论文提出 Counterfactual Inception，一种无需额外训练的方法，通过植入反事实思考（counterfactual thinking）来缓解大型多模态模型（LMMs）中的幻觉（hallucination）问题。该方法利用自生成的反事实关键词，帮助模型探索更广泛的上下文，从而生成更一致的跨模态响应。论文还引入 Plausibility Verification Process (PVP)，一个简单的关键词约束机制，用于过滤次优关键词，确保反事实思考的可靠触发。实验分析显示，在多种开源和专有 LMMs 上，该方法显著降低了幻觉发生率，并增强了基于真实视觉线索的上下文理解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://ivy-lvlm.github.io/Counterfactual-Inception/",
      "pdf_url": "http://arxiv.org/pdf/2403.13513v2",
      "published_date": "2024-03-20 11:27:20 UTC",
      "updated_date": "2024-06-21 06:11:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:21:21.144813"
    },
    {
      "arxiv_id": "2403.13512v1",
      "title": "Scale Decoupled Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Shicai Wei Chunbo Luo Yang Luo"
      ],
      "abstract": "Logit knowledge distillation attracts increasing attention due to its\npracticality in recent studies. However, it often suffers inferior performance\ncompared to the feature knowledge distillation. In this paper, we argue that\nexisting logit-based methods may be sub-optimal since they only leverage the\nglobal logit output that couples multiple semantic knowledge. This may transfer\nambiguous knowledge to the student and mislead its learning. To this end, we\npropose a simple but effective method, i.e., Scale Decoupled Distillation\n(SDD), for logit knowledge distillation. SDD decouples the global logit output\ninto multiple local logit outputs and establishes distillation pipelines for\nthem. This helps the student to mine and inherit fine-grained and unambiguous\nlogit knowledge. Moreover, the decoupled knowledge can be further divided into\nconsistent and complementary logit knowledge that transfers the semantic\ninformation and sample ambiguity, respectively. By increasing the weight of\ncomplementary parts, SDD can guide the student to focus more on ambiguous\nsamples, improving its discrimination ability. Extensive experiments on several\nbenchmark datasets demonstrate the effectiveness of SDD for wide\nteacher-student pairs, especially in the fine-grained classification task. Code\nis available at: https://github.com/shicaiwei123/SDD-CVPR2024",
      "tldr_zh": "本文指出，现有的Logit knowledge distillation方法由于仅使用耦合的全局logit输出，可能导致转移模糊知识给学生模型，从而性能不如feature knowledge distillation。针对此问题，提出Scale Decoupled Distillation (SDD)方法，该方法将全局logit输出解耦成多个局部logit输出，并为它们建立蒸馏管道，帮助学生模型挖掘细粒度的、无歧义知识，并通过增加互补知识的权重，提升对歧义样本的辨别能力。实验在多个基准数据集上证明，SDD对广泛的教师-学生对均有效，尤其在细粒度分类任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR2024 10 pages 6figure",
      "pdf_url": "http://arxiv.org/pdf/2403.13512v1",
      "published_date": "2024-03-20 11:21:22 UTC",
      "updated_date": "2024-03-20 11:21:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:21:33.627174"
    },
    {
      "arxiv_id": "2403.13501v2",
      "title": "VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Yumeng Li",
        "William Beluch",
        "Margret Keuper",
        "Dan Zhang",
        "Anna Khoreva"
      ],
      "abstract": "Despite tremendous progress in the field of text-to-video (T2V) synthesis,\nopen-sourced T2V diffusion models struggle to generate longer videos with\ndynamically varying and evolving content. They tend to synthesize quasi-static\nvideos, ignoring the necessary visual change-over-time implied in the text\nprompt. At the same time, scaling these models to enable longer, more dynamic\nvideo synthesis often remains computationally intractable. To address this\nchallenge, we introduce the concept of Generative Temporal Nursing (GTN), where\nwe aim to alter the generative process on the fly during inference to improve\ncontrol over the temporal dynamics and enable generation of longer videos. We\npropose a method for GTN, dubbed VSTAR, which consists of two key ingredients:\n1) Video Synopsis Prompting (VSP) - automatic generation of a video synopsis\nbased on the original single prompt leveraging LLMs, which gives accurate\ntextual guidance to different visual states of longer videos, and 2) Temporal\nAttention Regularization (TAR) - a regularization technique to refine the\ntemporal attention units of the pre-trained T2V diffusion models, which enables\ncontrol over the video dynamics. We experimentally showcase the superiority of\nthe proposed approach in generating longer, visually appealing videos over\nexisting open-sourced T2V models. We additionally analyze the temporal\nattention maps realized with and without VSTAR, demonstrating the importance of\napplying our method to mitigate neglect of the desired visual change over time.",
      "tldr_zh": "该论文针对开源文本到视频 (T2V) 扩散模型在生成更长、更动态视频时的局限性（如忽略文本提示中的视觉变化），提出了 Generative Temporal Nursing (GTN) 概念，以动态调整生成过程。VSTAR 方法的核心包括 Video Synopsis Prompting (VSP)，利用 LLMs 基于原始提示自动生成视频概要，提供对不同视觉状态的精确指导，以及 Temporal Attention Regularization (TAR)，用于优化预训练模型的 temporal attention units 以控制视频动态。实验证明，VSTAR 比现有 T2V 模型生成更长、更吸引人的视频，并通过分析 temporal attention maps 展示了其在缓解视觉变化忽略方面的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICLR 2025. Code: https://github.com/boschresearch/VSTAR\n  and project page: https://yumengli007.github.io/VSTAR",
      "pdf_url": "http://arxiv.org/pdf/2403.13501v2",
      "published_date": "2024-03-20 10:58:58 UTC",
      "updated_date": "2025-03-18 13:55:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:21:46.528537"
    },
    {
      "arxiv_id": "2403.13479v1",
      "title": "Deepfake Detection without Deepfakes: Generalization via Synthetic Frequency Patterns Injection",
      "title_zh": "无需深度伪造的深度伪造检测：通过合成频率模式注入实现泛化",
      "authors": [
        "Davide Alessandro Coccomini",
        "Roberto Caldelli",
        "Claudio Gennaro",
        "Giuseppe Fiameni",
        "Giuseppe Amato",
        "Fabrizio Falchi"
      ],
      "abstract": "Deepfake detectors are typically trained on large sets of pristine and\ngenerated images, resulting in limited generalization capacity; they excel at\nidentifying deepfakes created through methods encountered during training but\nstruggle with those generated by unknown techniques. This paper introduces a\nlearning approach aimed at significantly enhancing the generalization\ncapabilities of deepfake detectors. Our method takes inspiration from the\nunique \"fingerprints\" that image generation processes consistently introduce\ninto the frequency domain. These fingerprints manifest as structured and\ndistinctly recognizable frequency patterns. We propose to train detectors using\nonly pristine images injecting in part of them crafted frequency patterns,\nsimulating the effects of various deepfake generation techniques without being\nspecific to any. These synthetic patterns are based on generic shapes, grids,\nor auras. We evaluated our approach using diverse architectures across 25\ndifferent generation methods. The models trained with our approach were able to\nperform state-of-the-art deepfake detection, demonstrating also superior\ngeneralization capabilities in comparison with previous methods. Indeed, they\nare untied to any specific generation technique and can effectively identify\ndeepfakes regardless of how they were made.",
      "tldr_zh": "本文提出了一种无需真实 Deepfake 图像的检测方法，通过向原始图像注入合成 frequency patterns 来提升检测器的泛化能力。这些 patterns 基于 generic shapes、grids 或 auras，模拟各种图像生成过程在 frequency domain 中的独特“fingerprints”，从而训练出不依赖特定生成技术的模型。在使用多种架构评估 25 种不同生成方法后，该方法实现了 state-of-the-art 的 Deepfake 检测性能，并显著优于现有方法，证明了其在识别未知 Deepfake 方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13479v1",
      "published_date": "2024-03-20 10:33:10 UTC",
      "updated_date": "2024-03-20 10:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:21:55.448970"
    },
    {
      "arxiv_id": "2403.13447v1",
      "title": "HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqiao Zhang",
        "Tianwei Lin",
        "Jiang Liu",
        "Fangxun Shu",
        "Haoyuan Li",
        "Lei Zhang",
        "He Wanggui",
        "Hao Zhou",
        "Zheqi Lv",
        "Hao Jiang",
        "Juncheng Li",
        "Siliang Tang",
        "Yueting Zhuang"
      ],
      "abstract": "Recent advancements indicate that scaling up Multimodal Large Language Models\n(MLLMs) effectively enhances performance on downstream multimodal tasks. The\nprevailing MLLM paradigm, \\emph{e.g.}, LLaVA, transforms visual features into\ntext-like tokens using a \\emph{static} vision-language mapper, thereby enabling\n\\emph{static} LLMs to develop the capability to comprehend visual information\nthrough visual instruction tuning. Although promising, the \\emph{static} tuning\nstrategy~\\footnote{The static tuning refers to the trained model with static\nparameters.} that shares the same parameters may constrain performance across\ndifferent downstream multimodal tasks. In light of this, we introduce\nHyperLLaVA, which involves adaptive tuning of the projector and LLM parameters,\nin conjunction with a dynamic visual expert and language expert, respectively.\nThese experts are derived from HyperNetworks, which generates adaptive\nparameter shifts through visual and language guidance, enabling dynamic\nprojector and LLM modeling in two-stage training.\n  Our experiments demonstrate that our solution significantly surpasses LLaVA\non existing MLLM benchmarks, including MME, MMBench, SEED-Bench, and\nLLaVA-Bench. ~\\footnote{Our project is available on the link\nhttps://github.com/DCDmllm/HyperLLaVA}.",
      "tldr_zh": "该研究提出HyperLLaVA，一种动态视觉和语言专家调优方法，旨在提升Multimodal Large Language Models (MLLMs)在下游多模态任务上的性能。它通过HyperNetworks生成自适应参数偏移，动态调整投影器和LLM参数，并在两阶段训练中实现视觉和语言专家的建模，从而解决现有静态调优策略（如LLaVA）的局限性。实验结果表明，HyperLLaVA在MME、MMBench、SEED-Bench和LLaVA-Bench等基准上显著优于LLaVA。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13447v1",
      "published_date": "2024-03-20 09:42:43 UTC",
      "updated_date": "2024-03-20 09:42:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:22:08.736846"
    },
    {
      "arxiv_id": "2403.13441v1",
      "title": "Robustness Verifcation in Neural Networks",
      "title_zh": "神经网络中的鲁棒性验证",
      "authors": [
        "Adrian Wurm"
      ],
      "abstract": "In this paper we investigate formal verification problems for Neural Network\ncomputations. Of central importance will be various robustness and minimization\nproblems such as: Given symbolic specifications of allowed inputs and outputs\nin form of Linear Programming instances, one question is whether there do exist\nvalid inputs such that the network computes a valid output? And does this\nproperty hold for all valid inputs? Do two given networks compute the same\nfunction? Is there a smaller network computing the same function?\n  The complexity of these questions have been investigated recently from a\npractical point of view and approximated by heuristic algorithms. We complement\nthese achievements by giving a theoretical framework that enables us to\ninterchange security and efficiency questions in neural networks and analyze\ntheir computational complexities. We show that the problems are conquerable in\na semi-linear setting, meaning that for piecewise linear activation functions\nand when the sum- or maximum metric is used, most of them are in P or in NP at\nmost.",
      "tldr_zh": "这篇论文探讨了神经网络的鲁棒性验证问题，重点分析了诸如是否存在有效输入输出（以线性规划实例形式指定）、网络等价性以及最小化网络结构等形式化验证问题。作者建立了一个理论框架，将神经网络的安全性和效率问题相结合，并评估了这些问题的计算复杂度。在半线性设置下（如使用分段线性激活函数和和/最大度量），研究发现，大多数问题位于 P 或 NP 复杂度级别，从而为神经网络的可靠验证提供了理论基础。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2403.13441v1",
      "published_date": "2024-03-20 09:34:38 UTC",
      "updated_date": "2024-03-20 09:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:22:20.783205"
    },
    {
      "arxiv_id": "2403.13433v2",
      "title": "AgentGroupChat: An Interactive Group Chat Simulacra For Better Eliciting Emergent Behavior",
      "title_zh": "AgentGroupChat：一种交互式群聊模拟，用于更好地引发涌现行为",
      "authors": [
        "Zhouhong Gu",
        "Xiaoxuan Zhu",
        "Haoran Guo",
        "Lin Zhang",
        "Yin Cai",
        "Hao Shen",
        "Jiangjie Chen",
        "Zheyu Ye",
        "Yifei Dai",
        "Yan Gao",
        "Yao Hu",
        "Hongwei Feng",
        "Yanghua Xiao"
      ],
      "abstract": "Language significantly influences the formation and evolution of Human\nemergent behavior, which is crucial in understanding collective intelligence\nwithin human societies. Considering that the study of how language affects\nhuman behavior needs to put it into the dynamic scenarios in which it is used,\nwe introduce AgentGroupChat in this paper, a simulation that delves into the\ncomplex role of language in shaping collective behavior through interactive\ndebate scenarios. Central to this simulation are characters engaging in dynamic\nconversation interactions. To enable simulation, we introduce the Verbal\nStrategist Agent, utilizing large language models to enhance interaction\nstrategies by incorporating elements of persona and action. We set four\nnarrative scenarios based on AgentGroupChat to demonstrate the simulation's\ncapacity to mimic complex language use in group dynamics. Evaluations focus on\naligning agent behaviors with human expectations and the emergence of\ncollective behaviors within the simulation. Results reveal that emergent\nbehaviors materialize from a confluence of factors: a conducive environment for\nextensive information exchange, characters with diverse traits, high linguistic\ncomprehension, and strategic adaptability. During discussions on ``the impact\nof AI on humanity'' in AgentGroupChat simulation, philosophers commonly agreed\nthat ``AI could enhance societal welfare with judicious limitations'' and even\ncome to a conclusion that ``the essence of true intelligence encompasses\nunderstanding the necessity to constrain self abilities''. Additionally, in the\ncompetitive domain of casting for primary roles in films in AgentGroupChat,\ncertain actors were ready to reduce their remuneration or accept lesser roles,\nmotivated by their deep-seated desire to contribute to the project.",
      "tldr_zh": "本研究引入 AgentGroupChat，一种互动群聊模拟系统，用于探索语言在塑造人类涌现行为（emergent behavior）中的作用，通过动态辩论场景模拟集体智能。核心组件是 Verbal Strategist Agent，利用大型语言模型（large language models）增强代理的互动策略，包括角色个性（persona）和行动元素，并在四个叙事场景中演示复杂群体动态。实验结果显示，涌现行为源于广泛的信息交换、多样化角色特征、高语言理解能力以及战略适应性，例如在模拟中，哲学家们共识认为“AI 可能在合理限制下提升社会福祉”，而演员们为项目贡献愿意降低报酬或接受次要角色。总的来说，该系统为更好地激发和理解集体行为提供了新框架。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13433v2",
      "published_date": "2024-03-20 09:21:32 UTC",
      "updated_date": "2024-04-04 07:40:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:22:31.586743"
    },
    {
      "arxiv_id": "2403.13421v3",
      "title": "Caching-Augmented Lifelong Multi-Agent Path Finding",
      "title_zh": "翻译失败",
      "authors": [
        "Yimin Tang",
        "Zhenghong Yu",
        "Yi Zheng",
        "T. K. Satish Kumar",
        "Jiaoyang Li",
        "Sven Koenig"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF), which involves finding collision-free paths\nfor multiple robots, is crucial in various applications. Lifelong MAPF, where\ntargets are reassigned to agents as soon as they complete their initial\ntargets, offers a more accurate approximation of real-world warehouse planning.\nIn this paper, we present a novel mechanism named Caching-Augmented Lifelong\nMAPF (CAL-MAPF), designed to improve the performance of Lifelong MAPF. We have\ndeveloped a new type of map grid called cache for temporary item storage and\nreplacement, and created a locking mechanism to improve the planning solution's\nstability. A task assigner (TA) is designed for CAL-MAPF to allocate target\nlocations to agents and control agent status in different situations. CAL-MAPF\nhas been evaluated using various cache replacement policies and input task\ndistributions. We have identified three main factors significantly impacting\nCAL-MAPF performance through experimentation: suitable input task distribution,\nhigh cache hit rate, and smooth traffic. In general, CAL-MAPF has demonstrated\npotential for performance improvements in certain task distributions, map and\nagent configurations.",
      "tldr_zh": "该论文提出了一种名为Caching-Augmented Lifelong MAPF (CAL-MAPF)的机制，用于提升Multi-Agent Path Finding (MAPF)中的终身规划性能，特别适用于现实仓库场景，其中机器人完成初始目标后会重新分配任务。CAL-MAPF引入了cache网格用于临时存储和替换物品、locking机制以提高规划稳定性，以及任务分配器(TA)来分配目标位置并控制代理状态。实验评估了各种cache替换策略和输入任务分布，发现性能关键因素包括合适的任务分布、高cache命中率和平稳交通，总体在特定地图和代理配置下展示了显著改进潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13421v3",
      "published_date": "2024-03-20 09:07:23 UTC",
      "updated_date": "2024-04-05 18:23:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:22:45.199845"
    },
    {
      "arxiv_id": "2403.13408v2",
      "title": "S2DM: Sector-Shaped Diffusion Models for Video Generation",
      "title_zh": "S2DM：扇形扩散模型用于视频生成",
      "authors": [
        "Haoran Lang",
        "Yuxuan Ge",
        "Zheng Tian"
      ],
      "abstract": "Diffusion models have achieved great success in image generation. However,\nwhen leveraging this idea for video generation, we face significant challenges\nin maintaining the consistency and continuity across video frames. This is\nmainly caused by the lack of an effective framework to align frames of videos\nwith desired temporal features while preserving consistent semantic and\nstochastic features. In this work, we propose a novel Sector-Shaped Diffusion\nModel (S2DM) whose sector-shaped diffusion region is formed by a set of\nray-shaped reverse diffusion processes starting at the same noise point. S2DM\ncan generate a group of intrinsically related data sharing the same semantic\nand stochastic features while varying on temporal features with appropriate\nguided conditions. We apply S2DM to video generation tasks, and explore the use\nof optical flow as temporal conditions. Our experimental results show that S2DM\noutperforms many existing methods in the task of video generation without any\ntemporal-feature modelling modules. For text-to-video generation tasks where\ntemporal conditions are not explicitly given, we propose a two-stage generation\nstrategy which can decouple the generation of temporal features from\nsemantic-content features. We show that, without additional training, our model\nintegrated with another temporal conditions generative model can still achieve\ncomparable performance with existing works. Our results can be viewd at\nhttps://s2dm.github.io/S2DM/.",
      "tldr_zh": "本研究针对扩散模型在视频生成中的挑战（如帧间一致性和连续性问题），提出了一种新型 Sector-Shaped Diffusion Model (S2DM)，该模型通过从同一噪声点出发的一组 ray-shaped reverse diffusion processes 形成 sector-shaped diffusion region，从而生成共享相同 semantic 和 stochastic features 但在 temporal features 上变化的数据。S2DM 以 optical flow 作为 guided conditions，在视频生成任务中无需额外 temporal-feature modelling modules，便优于现有方法，实验显示其性能显著提升。对于 text-to-video 生成，作者引入两阶段策略，先解耦 temporal features 和 semantic-content features，并在不需额外训练的情况下，结合其他模型达到与现有作品相当的水平。结果详见 https://s2dm.github.io/S2DM/。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13408v2",
      "published_date": "2024-03-20 08:50:15 UTC",
      "updated_date": "2024-03-22 11:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:22:57.940503"
    },
    {
      "arxiv_id": "2403.13405v1",
      "title": "DOR3D-Net: Dense Ordinal Regression Network for 3D Hand Pose Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Yamin Mao",
        "Zhihua Liu",
        "Weiming Li",
        "SoonYong Cho",
        "Qiang Wang",
        "Xiaoshuai Hao"
      ],
      "abstract": "Depth-based 3D hand pose estimation is an important but challenging research\ntask in human-machine interaction community. Recently, dense regression methods\nhave attracted increasing attention in 3D hand pose estimation task, which\nprovide a low computational burden and high accuracy regression way by densely\nregressing hand joint offset maps. However, large-scale regression offset\nvalues are often affected by noise and outliers, leading to a significant drop\nin accuracy. To tackle this, we re-formulate 3D hand pose estimation as a dense\nordinal regression problem and propose a novel Dense Ordinal Regression 3D Pose\nNetwork (DOR3D-Net). Specifically, we first decompose offset value regression\ninto sub-tasks of binary classifications with ordinal constraints. Then, each\nbinary classifier can predict the probability of a binary spatial relationship\nrelative to joint, which is easier to train and yield much lower level of\nnoise. The estimated hand joint positions are inferred by aggregating the\nordinal regression results at local positions with a weighted sum. Furthermore,\nboth joint regression loss and ordinal regression loss are used to train our\nDOR3D-Net in an end-to-end manner. Extensive experiments on public datasets\n(ICVL, MSRA, NYU and HANDS2017) show that our design provides significant\nimprovements over SOTA methods.",
      "tldr_zh": "本研究针对基于深度图像的3D Hand Pose Estimation问题，提出了一种新型Dense Ordinal Regression Network（DOR3D-Net），通过将偏移值回归分解为带有序约束的二元分类子任务，以减少噪声和异常值的影响，提高估计准确性。具体而言，DOR3D-Net使用每个二元分类器预测相对于关节的二元空间关系，并通过加权求和聚合局部结果，同时结合关节回归损失和序数回归损失进行端到端训练。在ICVL、MSRA、NYU和HANDS2017等公共数据集上的实验显示，该方法比现有最先进（SOTA）方法取得了显著性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13405v1",
      "published_date": "2024-03-20 08:47:51 UTC",
      "updated_date": "2024-03-20 08:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:23:11.899997"
    },
    {
      "arxiv_id": "2403.13863v1",
      "title": "DiffImpute: Tabular Data Imputation With Denoising Diffusion Probabilistic Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhu Wen",
        "Kai Yi",
        "Jing Ke",
        "Yiqing Shen"
      ],
      "abstract": "Tabular data plays a crucial role in various domains but often suffers from\nmissing values, thereby curtailing its potential utility. Traditional\nimputation techniques frequently yield suboptimal results and impose\nsubstantial computational burdens, leading to inaccuracies in subsequent\nmodeling tasks. To address these challenges, we propose DiffImpute, a novel\nDenoising Diffusion Probabilistic Model (DDPM). Specifically, DiffImpute is\ntrained on complete tabular datasets, ensuring that it can produce credible\nimputations for missing entries without undermining the authenticity of the\nexisting data. Innovatively, it can be applied to various settings of Missing\nCompletely At Random (MCAR) and Missing At Random (MAR). To effectively handle\nthe tabular features in DDPM, we tailor four tabular denoising networks,\nspanning MLP, ResNet, Transformer, and U-Net. We also propose Harmonization to\nenhance coherence between observed and imputed data by infusing the data back\nand denoising them multiple times during the sampling stage. To enable\nefficient inference while maintaining imputation performance, we propose a\nrefined non-Markovian sampling process that works along with Harmonization.\nEmpirical evaluations on seven diverse datasets underscore the prowess of\nDiffImpute. Specifically, when paired with the Transformer as the denoising\nnetwork, it consistently outperforms its competitors, boasting an average\nranking of 1.7 and the most minimal standard deviation. In contrast, the next\nbest method lags with a ranking of 2.8 and a standard deviation of 0.9. The\ncode is available at https://github.com/Dendiiiii/DiffImpute.",
      "tldr_zh": "该研究针对表格数据中的缺失值问题，提出了一种名为DiffImpute的创新模型，基于Denoising Diffusion Probabilistic Model (DDPM)，通过在完整数据集上训练来生成可靠的缺失值填充，同时适用于Missing Completely At Random (MCAR)和Missing At Random (MAR)场景。DiffImpute设计了四种去噪网络（包括MLP、ResNet、Transformer和U-Net），并引入Harmonization技术以及一个精炼的非Markovian采样过程，以提升填充数据与观察数据的连贯性和推理效率。在七个多样数据集上的实验中，DiffImpute结合Transformer网络表现出色，平均排名1.7并具有最小标准差，显著优于其他方法（次佳排名2.8）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13863v1",
      "published_date": "2024-03-20 08:45:31 UTC",
      "updated_date": "2024-03-20 08:45:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:23:25.240928"
    },
    {
      "arxiv_id": "2406.17590v1",
      "title": "Multimodal Chaptering for Long-Form TV Newscast Video",
      "title_zh": "翻译失败",
      "authors": [
        "Khalil Guetari",
        "Yannis Tevissen",
        "Frédéric Petitpont"
      ],
      "abstract": "We propose a novel approach for automatic chaptering of TV newscast videos,\naddressing the challenge of structuring and organizing large collections of\nunsegmented broadcast content. Our method integrates both audio and visual cues\nthrough a two-stage process involving frozen neural networks and a trained LSTM\nnetwork. The first stage extracts essential features from separate modalities,\nwhile the LSTM effectively fuses these features to generate accurate segment\nboundaries. Our proposed model has been evaluated on a diverse dataset\ncomprising over 500 TV newscast videos of an average of 41 minutes gathered\nfrom TF1, a French TV channel, with varying lengths and topics. Experimental\nresults demonstrate that this innovative fusion strategy achieves state of the\nart performance, yielding a high precision rate of 82% at IoU of 90%.\nConsequently, this approach significantly enhances analysis, indexing and\nstorage capabilities for TV newscast archives, paving the way towards efficient\nmanagement and utilization of vast audiovisual resources.",
      "tldr_zh": "本文提出了一种多模态分章方法（Multimodal Chaptering），用于自动结构化长形式 TV 新闻视频，解决未分段广播内容的组织挑战。该方法采用两阶段过程：首先利用冻结神经网络提取音频和视觉特征，然后通过训练过的 LSTM 网络融合这些特征，以生成精确的段边界。在一个包含超过 500 个平均 41 分钟的 TF1 法国电视频道视频的数据集上进行评估，结果显示该方法实现了 state-of-the-art 性能，IoU 为 90% 时精度达到 82%。这项创新显著提升了 TV 新闻档案的分析、索引和存储能力，促进音视频资源的有效管理。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17590v1",
      "published_date": "2024-03-20 08:39:41 UTC",
      "updated_date": "2024-03-20 08:39:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:23:37.928915"
    },
    {
      "arxiv_id": "2405.02305v1",
      "title": "Inserting Faces inside Captions: Image Captioning with Attention Guided Merging",
      "title_zh": "在字幕中插入面部：基于注意力引导合并的图像字幕生成",
      "authors": [
        "Yannis Tevissen",
        "Khalil Guetari",
        "Marine Tassel",
        "Erwan Kerleroux",
        "Frédéric Petitpont"
      ],
      "abstract": "Image captioning models are widely used to describe recent and archived\npictures with the objective of improving their accessibility and retrieval.\nYet, these approaches tend to be inefficient and biased at retrieving people's\nnames. In this work we introduce AstroCaptions, a dataset for the image\ncaptioning task. This dataset specifically contains thousands of public\nfig-ures that are complex to identify for a traditional model. We also propose\na novel post-processing method to insert identified people's names inside the\ncaption using explainable AI tools and the grounding capabilities of\nvi-sion-language models. The results obtained with this method show\nsignifi-cant improvements of captions quality and a potential of reducing\nhalluci-nations. Up to 93.2% of the persons detected can be inserted in the\nimage captions leading to improvements in the BLEU, ROUGE, CIDEr and METEOR\nscores of each captioning model.",
      "tldr_zh": "本研究针对图像描述（Image Captioning）模型在识别人名时存在的效率和偏差问题，引入了AstroCaptions数据集，该数据集包含数千张复杂公共人物图像，旨在挑战传统模型的识别能力。论文提出了一种新型后处理方法，利用可解释AI工具和视觉语言模型的grounding能力，通过注意力引导合并（Attention Guided Merging）将检测到的人名插入描述中，从而减少hallucinations并提升描述质量。实验结果显示，该方法可将多达93.2%检测到的人名成功插入，导致BLEU、ROUGE、CIDEr和METEOR分数显著改善。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02305v1",
      "published_date": "2024-03-20 08:38:25 UTC",
      "updated_date": "2024-03-20 08:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:23:49.885994"
    },
    {
      "arxiv_id": "2403.13374v3",
      "title": "Byzantine-resilient Federated Learning With Adaptivity to Data Heterogeneity",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyuan Zuo",
        "Xingrun Yan",
        "Rongfei Fan",
        "Han Hu",
        "Hangguan Shan",
        "Tony Q. S. Quek"
      ],
      "abstract": "This paper deals with federated learning (FL) in the presence of malicious\nByzantine attacks and data heterogeneity. A novel Robust Average Gradient\nAlgorithm (RAGA) is proposed, which leverages the geometric median for\naggregation and can freely select the round number for local updating.\nDifferent from most existing resilient approaches, which perform convergence\nanalysis based on strongly-convex loss function or homogeneously distributed\ndataset, we conduct convergence analysis for not only strongly-convex but also\nnon-convex loss function over heterogeneous dataset. According to our\ntheoretical analysis, as long as the fraction of dataset from malicious users\nis less than half, RAGA can achieve convergence at rate\n$\\mathcal{O}({1}/{T^{2/3- \\delta}})$ where $T$ is the iteration number and\n$\\delta \\in (0, 2/3)$ for non-convex loss function, and at linear rate for\nstrongly-convex loss function. Moreover, stationary point or global optimal\nsolution is proved to obtainable as data heterogeneity vanishes. Experimental\nresults corroborate the robustness of RAGA to Byzantine attacks and verifies\nthe advantage of RAGA over baselines on convergence performance under various\nintensity of Byzantine attacks, for heterogeneous dataset.",
      "tldr_zh": "本论文探讨了在恶意Byzantine攻击和数据异质性环境下进行Federated Learning的挑战，提出了一种新型Robust Average Gradient Algorithm (RAGA)，该算法利用geometric median进行聚合，并允许灵活选择本地更新轮数。不同于现有方法，论文对强凸和非凸loss function在异质数据集上的收敛性进行了分析，证明了当恶意用户比例低于一半时，RAGA可实现非凸函数的收敛率$\\mathcal{O}({1}/{T^{2/3- \\delta}})$（其中$T$为迭代次数，$\\delta \\in (0, 2/3)$），以及强凸函数的线性收敛率。实验结果验证了RAGA对Byzantine攻击的鲁棒性，并在各种攻击强度下表现出比基线方法更好的收敛性能，尤其在数据异质性减少时能达到全局最优解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13374v3",
      "published_date": "2024-03-20 08:15:08 UTC",
      "updated_date": "2024-03-27 14:57:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:24:00.296761"
    },
    {
      "arxiv_id": "2405.15776v1",
      "title": "CalliRewrite: Recovering Handwriting Behaviors from Calligraphy Images without Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Luo",
        "Zekun Wu",
        "Zhouhui Lian"
      ],
      "abstract": "Human-like planning skills and dexterous manipulation have long posed\nchallenges in the fields of robotics and artificial intelligence (AI). The task\nof reinterpreting calligraphy presents a formidable challenge, as it involves\nthe decomposition of strokes and dexterous utensil control. Previous efforts\nhave primarily focused on supervised learning of a single instrument, limiting\nthe performance of robots in the realm of cross-domain text replication. To\naddress these challenges, we propose CalliRewrite: a coarse-to-fine approach\nfor robot arms to discover and recover plausible writing orders from diverse\ncalligraphy images without requiring labeled demonstrations. Our model achieves\nfine-grained control of various writing utensils. Specifically, an unsupervised\nimage-to-sequence model decomposes a given calligraphy glyph to obtain a coarse\nstroke sequence. Using an RL algorithm, a simulated brush is fine-tuned to\ngenerate stylized trajectories for robotic arm control. Evaluation in\nsimulation and physical robot scenarios reveals that our method successfully\nreplicates unseen fonts and styles while achieving integrity in unknown\ncharacters.",
      "tldr_zh": "该研究提出CalliRewrite，一种无监督方法，帮助机器人手臂从书法图像中发现并恢复可能的书写顺序，从而解决跨领域文本复制的挑战。该方法采用粗到细的策略，包括一个unsupervised图像到序列模型来分解笔画序列，以及使用RL algorithm在模拟环境中微调画笔生成风格化轨迹。实验结果显示，在模拟和物理机器人场景中，CalliRewrite成功复制了未知字体和风格，并确保了字符的完整性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, accepted as ICRA 2024 contributed paper",
      "pdf_url": "http://arxiv.org/pdf/2405.15776v1",
      "published_date": "2024-03-20 08:12:02 UTC",
      "updated_date": "2024-03-20 08:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:24:12.982216"
    },
    {
      "arxiv_id": "2403.13372v4",
      "title": "LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yaowei Zheng",
        "Richong Zhang",
        "Junhao Zhang",
        "Yanhan Ye",
        "Zheyan Luo",
        "Zhangchi Feng",
        "Yongqiang Ma"
      ],
      "abstract": "Efficient fine-tuning is vital for adapting large language models (LLMs) to\ndownstream tasks. However, it requires non-trivial efforts to implement these\nmethods on different models. We present LlamaFactory, a unified framework that\nintegrates a suite of cutting-edge efficient training methods. It provides a\nsolution for flexibly customizing the fine-tuning of 100+ LLMs without the need\nfor coding through the built-in web UI LlamaBoard. We empirically validate the\nefficiency and effectiveness of our framework on language modeling and text\ngeneration tasks. It has been released at\nhttps://github.com/hiyouga/LLaMA-Factory and received over 25,000 stars and\n3,000 forks.",
      "tldr_zh": "该研究提出 LlamaFactory，一个统一的框架，用于高效微调 100+ 语言模型 (LLMs)，以适应下游任务。该框架整合了多种先进的训练方法，通过内置的 web UI LlamaBoard 提供无代码定制选项，简化了模型 fine-tuning 的实现过程。实验结果显示，该框架在语言建模和文本生成任务上表现出色，并已在 GitHub 上获得超过 25,000 星和 3,000 叉，证明其实用性和影响力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, accepted to ACL 2024 System Demonstration Track",
      "pdf_url": "http://arxiv.org/pdf/2403.13372v4",
      "published_date": "2024-03-20 08:08:54 UTC",
      "updated_date": "2024-06-27 22:44:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:24:23.453003"
    },
    {
      "arxiv_id": "2403.13369v2",
      "title": "Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Phillip Richter-Pechanski",
        "Philipp Wiesenbach",
        "Dominic M. Schwab",
        "Christina Kiriakou",
        "Nicolas Geis",
        "Christoph Dieterich",
        "Anette Frank"
      ],
      "abstract": "Automatic extraction of medical information from clinical documents poses\nseveral challenges: high costs of required clinical expertise, limited\ninterpretability of model predictions, restricted computational resources and\nprivacy regulations. Recent advances in domain-adaptation and prompting methods\nshowed promising results with minimal training data using lightweight masked\nlanguage models, which are suited for well-established interpretability\nmethods. We are first to present a systematic evaluation of these methods in a\nlow-resource setting, by performing multi-class section classification on\nGerman doctor's letters. We conduct extensive class-wise evaluations supported\nby Shapley values, to validate the quality of our small training data set and\nto ensure the interpretability of model predictions. We demonstrate that a\nlightweight, domain-adapted pretrained model, prompted with just 20 shots,\noutperforms a traditional classification model by 30.5% accuracy. Our results\nserve as a process-oriented guideline for clinical information extraction\nprojects working with low-resource.",
      "tldr_zh": "该研究探讨了从临床文档中提取医疗信息面临的挑战，如高成本和隐私法规，并首次在低资源语言（如德语）环境中系统评估了领域适应和提示方法。研究使用预训练语言模型（Pre-trained language models）和Few-shot learning，仅需20个样本进行提示，即可实现多类部分分类任务。实验结果显示，轻量级领域适应模型的准确率比传统分类模型提高了30.5%，并通过Shapley values确保了模型预测的可解释性。这些发现为低资源临床信息提取项目提供了过程导向的指导方针。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper accepted for publication in the journal: Natural Language\n  Engineering (Cambridge Core)",
      "pdf_url": "http://arxiv.org/pdf/2403.13369v2",
      "published_date": "2024-03-20 08:01:33 UTC",
      "updated_date": "2024-08-13 07:35:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:24:36.034289"
    },
    {
      "arxiv_id": "2403.13368v1",
      "title": "Computational Models to Study Language Processing in the Human Brain: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Shaonan Wang",
        "Jingyuan Sun",
        "Yunhao Zhang",
        "Nan Lin",
        "Marie-Francine Moens",
        "Chengqing Zong"
      ],
      "abstract": "Despite differing from the human language processing mechanism in\nimplementation and algorithms, current language models demonstrate remarkable\nhuman-like or surpassing language capabilities. Should computational language\nmodels be employed in studying the brain, and if so, when and how? To delve\ninto this topic, this paper reviews efforts in using computational models for\nbrain research, highlighting emerging trends. To ensure a fair comparison, the\npaper evaluates various computational models using consistent metrics on the\nsame dataset. Our analysis reveals that no single model outperforms others on\nall datasets, underscoring the need for rich testing datasets and rigid\nexperimental control to draw robust conclusions in studies involving\ncomputational models.",
      "tldr_zh": "这篇调查论文探讨了使用计算语言模型（computational language models）来研究人类大脑语言处理（language processing）机制的可能性，尽管这些模型在实现和算法上与人类机制不同。论文回顾了相关研究努力，并突出了新兴趋势；为确保公平比较，它在同一数据集上使用一致的指标评估了各种计算模型。分析结果显示，没有单一模型在所有数据集上表现出色，这强调了需要丰富的测试数据集和严格的实验控制，以得出可靠的结论。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13368v1",
      "published_date": "2024-03-20 08:01:22 UTC",
      "updated_date": "2024-03-20 08:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:24:47.351714"
    },
    {
      "arxiv_id": "2403.13362v3",
      "title": "Incentivizing News Consumption on Social Media Platforms Using Large Language Models and Realistic Bot Accounts",
      "title_zh": "利用大型",
      "authors": [
        "Hadi Askari",
        "Anshuman Chhabra",
        "Bernhard Clemm von Hohenberg",
        "Michael Heseltine",
        "Magdalena Wojcieszak"
      ],
      "abstract": "Polarization, declining trust, and wavering support for democratic norms are\npressing threats to U.S. democracy. Exposure to verified and quality news may\nlower individual susceptibility to these threats and make citizens more\nresilient to misinformation, populism, and hyperpartisan rhetoric. This project\nexamines how to enhance users' exposure to and engagement with verified and\nideologically balanced news in an ecologically valid setting. We rely on a\nlarge-scale two-week long field experiment (from 1/19/2023 to 2/3/2023) on\n28,457 Twitter users. We created 28 bots utilizing GPT-2 that replied to users\ntweeting about sports, entertainment, or lifestyle with a contextual reply\ncontaining two hardcoded elements: a URL to the topic-relevant section of\nquality news organization and an encouragement to follow its Twitter account.\nTo further test differential effects by gender of the bots, treated users were\nrandomly assigned to receive responses by bots presented as female or male. We\nexamine whether our over-time intervention enhances the following of news media\norganization, the sharing and the liking of news content and the tweeting about\npolitics and the liking of political content. We find that the treated users\nfollowed more news accounts and the users in the female bot treatment were more\nlikely to like news content than the control. Most of these results, however,\nwere small in magnitude and confined to the already politically interested\nTwitter users, as indicated by their pre-treatment tweeting about politics.\nThese findings have implications for social media and news organizations, and\nalso offer direction for future work on how Large Language Models and other\ncomputational interventions can effectively enhance individual on-platform\nengagement with quality news and public affairs.",
      "tldr_zh": "这篇论文探讨了如何利用 Large Language Models（如 GPT-2）和真实机器人账号，激励社交媒体用户（如 Twitter 用户）消费验证的优质新闻，以缓解美国民主面临的极化、信任下降等问题。研究通过大规模实地实验（涉及28,457名用户，两周时间），让机器人对用户关于体育、娱乐或生活方式的推文回复，包含相关新闻链接和鼓励关注，并测试机器人性别（女性或男性）的差异影响。结果显示，处理组用户更多关注新闻账户，且女性机器人组更可能喜欢新闻内容，但整体效果较小，主要限于原本对政治感兴趣的用户。这些发现为社交媒体平台和新闻组织提供了提升用户参与优质新闻的策略，并为未来使用计算干预技术增强公众事务参与提供了方向。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13362v3",
      "published_date": "2024-03-20 07:44:06 UTC",
      "updated_date": "2024-03-30 03:10:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:25:02.508829"
    },
    {
      "arxiv_id": "2403.13355v1",
      "title": "BadEdit: Backdooring large language models by model editing",
      "title_zh": "翻译失败",
      "authors": [
        "Yanzhou Li",
        "Tianlin Li",
        "Kangjie Chen",
        "Jian Zhang",
        "Shangqing Liu",
        "Wenhan Wang",
        "Tianwei Zhang",
        "Yang Liu"
      ],
      "abstract": "Mainstream backdoor attack methods typically demand substantial tuning data\nfor poisoning, limiting their practicality and potentially degrading the\noverall performance when applied to Large Language Models (LLMs). To address\nthese issues, for the first time, we formulate backdoor injection as a\nlightweight knowledge editing problem, and introduce the BadEdit attack\nframework. BadEdit directly alters LLM parameters to incorporate backdoors with\nan efficient editing technique. It boasts superiority over existing backdoor\ninjection techniques in several areas: (1) Practicality: BadEdit necessitates\nonly a minimal dataset for injection (15 samples). (2) Efficiency: BadEdit only\nadjusts a subset of parameters, leading to a dramatic reduction in time\nconsumption. (3) Minimal side effects: BadEdit ensures that the model's\noverarching performance remains uncompromised. (4) Robustness: the backdoor\nremains robust even after subsequent fine-tuning or instruction-tuning.\nExperimental results demonstrate that our BadEdit framework can efficiently\nattack pre-trained LLMs with up to 100\\% success rate while maintaining the\nmodel's performance on benign inputs.",
      "tldr_zh": "该研究首次将后门攻击问题转化为轻量级的知识编辑任务，提出BadEdit框架，通过直接编辑Large Language Models (LLMs)的参数来注入后门。BadEdit仅需少量数据（15个样本）即可高效操作，仅调整部分参数，从而显著减少时间消耗，同时确保模型在正常输入上的性能不受影响。实验结果显示，BadEdit对预训练LLMs的攻击成功率可达100%，并在后续fine-tuning或instruction-tuning后保持鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.13355v1",
      "published_date": "2024-03-20 07:34:18 UTC",
      "updated_date": "2024-03-20 07:34:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:25:18.096122"
    },
    {
      "arxiv_id": "2403.13344v1",
      "title": "USE: Dynamic User Modeling with Stateful Sequence Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihan Zhou",
        "Qixiang Fang",
        "Leonardo Neves",
        "Francesco Barbieri",
        "Yozen Liu",
        "Han Liu",
        "Maarten W. Bos",
        "Ron Dotsch"
      ],
      "abstract": "User embeddings play a crucial role in user engagement forecasting and\npersonalized services. Recent advances in sequence modeling have sparked\ninterest in learning user embeddings from behavioral data. Yet behavior-based\nuser embedding learning faces the unique challenge of dynamic user modeling. As\nusers continuously interact with the apps, user embeddings should be\nperiodically updated to account for users' recent and long-term behavior\npatterns. Existing methods highly rely on stateless sequence models that lack\nmemory of historical behavior. They have to either discard historical data and\nuse only the most recent data or reprocess the old and new data jointly. Both\ncases incur substantial computational overhead. To address this limitation, we\nintroduce User Stateful Embedding (USE). USE generates user embeddings and\nreflects users' evolving behaviors without the need for exhaustive reprocessing\nby storing previous model states and revisiting them in the future.\nFurthermore, we introduce a novel training objective named future W-behavior\nprediction to transcend the limitations of next-token prediction by forecasting\na broader horizon of upcoming user behaviors. By combining it with the Same\nUser Prediction, a contrastive learning-based objective that predicts whether\ndifferent segments of behavior sequences belong to the same user, we further\nimprove the embeddings' distinctiveness and representativeness. We conducted\nexperiments on 8 downstream tasks using Snapchat users' behavioral logs in both\nstatic (i.e., fixed user behavior sequences) and dynamic (i.e., periodically\nupdated user behavior sequences) settings. We demonstrate USE's superior\nperformance over established baselines. The results underscore USE's\neffectiveness and efficiency in integrating historical and recent user behavior\nsequences into user embeddings in dynamic user modeling.",
      "tldr_zh": "本研究针对用户嵌入(user embeddings)学习中的动态用户建模挑战，提出了一种名为 USE (User Stateful Embedding) 的框架，利用有状态序列模型(stateful sequence models)来存储和重用历史模型状态，从而避免了现有无状态模型对数据反复处理的计算开销。USE 引入了创新训练目标，包括 future W-behavior prediction（预测更广泛的未来用户行为）和 Same User Prediction（基于对比学习的序列归属预测），以提升嵌入的代表性和独特性。在 Snapchat 用户行为日志上进行的实验显示，USE 在 8 个下游任务中，在静态和动态设置下均优于基线模型，证明了其在整合历史与最近行为方面的有效性和效率。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13344v1",
      "published_date": "2024-03-20 07:05:19 UTC",
      "updated_date": "2024-03-20 07:05:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:25:28.719777"
    },
    {
      "arxiv_id": "2403.13341v2",
      "title": "FissionFusion: Fast Geometric Generation and Hierarchical Souping for Medical Image Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Santosh Sanjeev",
        "Nuren Zhaksylyk",
        "Ibrahim Almakky",
        "Anees Ur Rehman Hashmi",
        "Mohammad Areeb Qazi",
        "Mohammad Yaqub"
      ],
      "abstract": "The scarcity of well-annotated medical datasets requires leveraging transfer\nlearning from broader datasets like ImageNet or pre-trained models like CLIP.\nModel soups averages multiple fine-tuned models aiming to improve performance\non In-Domain (ID) tasks and enhance robustness against Out-of-Distribution\n(OOD) datasets. However, applying these methods to the medical imaging domain\nfaces challenges and results in suboptimal performance. This is primarily due\nto differences in error surface characteristics that stem from data\ncomplexities such as heterogeneity, domain shift, class imbalance, and\ndistributional shifts between training and testing phases. To address this\nissue, we propose a hierarchical merging approach that involves local and\nglobal aggregation of models at various levels based on models' hyperparameter\nconfigurations. Furthermore, to alleviate the need for training a large number\nof models in the hyperparameter search, we introduce a computationally\nefficient method using a cyclical learning rate scheduler to produce multiple\nmodels for aggregation in the weight space. Our method demonstrates significant\nimprovements over the model souping approach across multiple datasets (around\n6% gain in HAM10000 and CheXpert datasets) while maintaining low computational\ncosts for model generation and selection. Moreover, we achieve better results\non OOD datasets than model soups. The code is available at\nhttps://github.com/BioMedIA-MBZUAI/FissionFusion.",
      "tldr_zh": "该论文针对医疗图像分析中数据稀缺的问题，提出 FissionFusion 方法，通过层次化合并（hierarchical merging）来聚合基于超参数配置的局部和全局模型，从而改善 In-Domain (ID) 任务性能并增强对 Out-of-Distribution (OOD) 数据集的鲁棒性。作者引入了使用循环学习率调度器（cyclical learning rate scheduler）的计算高效策略，以快速生成多个模型进行聚合，避免了传统 Model soups 方法的局限，如数据异质性和领域偏移。实验结果显示，该方法在 HAM10000 和 CheXpert 数据集上性能提升约 6%，并在 OOD 数据集上表现出色，同时保持低计算成本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13341v2",
      "published_date": "2024-03-20 06:48:48 UTC",
      "updated_date": "2024-06-03 12:11:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:25:43.688244"
    },
    {
      "arxiv_id": "2403.13337v1",
      "title": "Learning Novel View Synthesis from Heterogeneous Low-light Captures",
      "title_zh": "翻译失败",
      "authors": [
        "Quan Zheng",
        "Hao Sun",
        "Huiyao Xu",
        "Fanjiang Xu"
      ],
      "abstract": "Neural radiance field has achieved fundamental success in novel view\nsynthesis from input views with the same brightness level captured under fixed\nnormal lighting. Unfortunately, synthesizing novel views remains to be a\nchallenge for input views with heterogeneous brightness level captured under\nlow-light condition. The condition is pretty common in the real world. It\ncauses low-contrast images where details are concealed in the darkness and\ncamera sensor noise significantly degrades the image quality. To tackle this\nproblem, we propose to learn to decompose illumination, reflectance, and noise\nfrom input views according to that reflectance remains invariant across\nheterogeneous views. To cope with heterogeneous brightness and noise levels\nacross multi-views, we learn an illumination embedding and optimize a noise map\nindividually for each view. To allow intuitive editing of the illumination, we\ndesign an illumination adjustment module to enable either brightening or\ndarkening of the illumination component. Comprehensive experiments demonstrate\nthat this approach enables effective intrinsic decomposition for low-light\nmulti-view noisy images and achieves superior visual quality and numerical\nperformance for synthesizing novel views compared to state-of-the-art methods.",
      "tldr_zh": "该研究针对神经辐射场(Neural Radiance Field)在处理异质低光捕获图像时的挑战，提出了一种新颖的视图合成方法。方法通过学习从输入视图中分解照明、反射和噪声，利用反射不变性为每个视图优化独立的照明嵌入(illumination embedding)和噪声映射(noise map)。此外，引入照明调整模块(illumination adjustment module)以实现直观的亮度编辑。实验结果显示，该方法在低光多视图噪声图像上实现了有效的内在分解，并在新视图合成方面比最先进方法具有更高的视觉质量和数值性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13337v1",
      "published_date": "2024-03-20 06:44:26 UTC",
      "updated_date": "2024-03-20 06:44:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:25:52.845922"
    },
    {
      "arxiv_id": "2403.13335v1",
      "title": "Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixin Lai",
        "Xuesheng Zhang",
        "Suiyao Chen"
      ],
      "abstract": "Large language models (LLMs) have reached human-like proficiency in\ngenerating diverse textual content, underscoring the necessity for effective\nfake text detection to avoid potential risks such as fake news in social media.\nPrevious research has mostly tested single models on in-distribution datasets,\nlimiting our understanding of how these models perform on different types of\ndata for LLM-generated text detection task. We researched this by testing five\nspecialized transformer-based models on both in-distribution and\nout-of-distribution datasets to better assess their performance and\ngeneralizability. Our results revealed that single transformer-based\nclassifiers achieved decent performance on in-distribution dataset but limited\ngeneralization ability on out-of-distribution dataset. To improve it, we\ncombined the individual classifiers models using adaptive ensemble algorithms,\nwhich improved the average accuracy significantly from 91.8% to 99.2% on an\nin-distribution test set and from 62.9% to 72.5% on an out-of-distribution test\nset. The results indicate the effectiveness, good generalization ability, and\ngreat potential of adaptive ensemble algorithms in LLM-generated text\ndetection.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）生成假文本的潜在风险（如社交媒体假新闻），评估了五个fine-tuned Transformers模型在分布内和分布外数据集上的性能。结果显示，单一模型在分布内数据集上表现出色（准确率91.8%），但在分布外数据集上泛化能力有限（准确率62.9%）。为了提升效果，研究采用adaptive ensembles算法结合这些模型，将准确率提高至分布内的99.2%和分布外的72.5%，证明了该方法在LLM-generated text detection中的有效性和泛化潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13335v1",
      "published_date": "2024-03-20 06:38:13 UTC",
      "updated_date": "2024-03-20 06:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:26:05.249995"
    },
    {
      "arxiv_id": "2403.13334v2",
      "title": "Hyacinth6B: A large language model for Traditional Chinese",
      "title_zh": "翻译失败",
      "authors": [
        "Chih-Wei Song",
        "Yin-Te Tsai"
      ],
      "abstract": "This research's primary motivation of this study is to address the high\nhardware and computational demands typically associated with LLMs.Therefore,our\ngoal is to find a balance between model lightness and performance,striving to\nmaximize performance while using a comparatively lightweight model. Hyacinth6B\nwas developed with this objective in mind,aiming to fully leverage the core\ncapabilities of LLMs without incurring substantial resource costs, effectively\npushing the boundaries of smaller model's performance. The training approach\ninvolves parameter efficient finetuning using the LoRA method.",
      "tldr_zh": "这篇论文介绍了 Hyacinth6B，一种针对繁体中文的大型语言模型 (LLMs)，旨在解决传统 LLMs 的高硬件和计算需求问题，同时追求模型轻量化和性能的最大化平衡。研究采用参数高效微调方法 LoRA 进行训练，充分利用 LLMs 的核心能力，而无需大量资源。Hyacinth6B 的开发推动了小型模型性能的边界，为资源有限的场景提供了一个高效的语言模型选项。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14pages",
      "pdf_url": "http://arxiv.org/pdf/2403.13334v2",
      "published_date": "2024-03-20 06:37:59 UTC",
      "updated_date": "2024-03-26 12:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:26:15.850909"
    },
    {
      "arxiv_id": "2403.13313v1",
      "title": "Polaris: A Safety-focused LLM Constellation Architecture for Healthcare",
      "title_zh": "Polaris：专注于安全的 LLM 星座架构，用于医疗保健",
      "authors": [
        "Subhabrata Mukherjee",
        "Paul Gamble",
        "Markel Sanz Ausin",
        "Neel Kant",
        "Kriti Aggarwal",
        "Neha Manjunath",
        "Debajyoti Datta",
        "Zhengliang Liu",
        "Jiayuan Ding",
        "Sophia Busacca",
        "Cezanne Bianco",
        "Swapnil Sharma",
        "Rae Lasko",
        "Michelle Voisard",
        "Sanchay Harneja",
        "Darya Filippova",
        "Gerry Meixiong",
        "Kevin Cha",
        "Amir Youssefi",
        "Meyhaa Buvanesh",
        "Howard Weingram",
        "Sebastian Bierman-Lytle",
        "Harpreet Singh Mangat",
        "Kim Parikh",
        "Saad Godil",
        "Alex Miller"
      ],
      "abstract": "We develop Polaris, the first safety-focused LLM constellation for real-time\npatient-AI healthcare conversations. Unlike prior LLM works in healthcare\nfocusing on tasks like question answering, our work specifically focuses on\nlong multi-turn voice conversations. Our one-trillion parameter constellation\nsystem is composed of several multibillion parameter LLMs as co-operative\nagents: a stateful primary agent that focuses on driving an engaging\nconversation and several specialist support agents focused on healthcare tasks\nperformed by nurses to increase safety and reduce hallucinations. We develop a\nsophisticated training protocol for iterative co-training of the agents that\noptimize for diverse objectives. We train our models on proprietary data,\nclinical care plans, healthcare regulatory documents, medical manuals, and\nother medical reasoning documents. We align our models to speak like medical\nprofessionals, using organic healthcare conversations and simulated ones\nbetween patient actors and experienced nurses. This allows our system to\nexpress unique capabilities such as rapport building, trust building, empathy\nand bedside manner. Finally, we present the first comprehensive clinician\nevaluation of an LLM system for healthcare. We recruited over 1100 U.S.\nlicensed nurses and over 130 U.S. licensed physicians to perform end-to-end\nconversational evaluations of our system by posing as patients and rating the\nsystem on several measures. We demonstrate Polaris performs on par with human\nnurses on aggregate across dimensions such as medical safety, clinical\nreadiness, conversational quality, and bedside manner. Additionally, we conduct\na challenging task-based evaluation of the individual specialist support\nagents, where we demonstrate our LLM agents significantly outperform a much\nlarger general-purpose LLM (GPT-4) as well as from its own medium-size class\n(LLaMA-2 70B).",
      "tldr_zh": "本研究开发了 Polaris，一种专注于医疗安全的 LLM 星座架构，用于实时患者-AI 对话，特别针对长多轮语音互动。系统由一个万亿参数的框架组成，包括一个状态化主要代理（驱动对话）和多个专家支持代理（处理医疗任务以提升安全性和减少幻觉），并通过迭代共训练协议和专有医疗数据（如临床护理计划和法规文件）进行优化，使模型能像医疗专业人士一样表达同理心和床边方式。在临床评估中，Polaris 招募超1100名护士和130名医生进行对话测试，结果显示其在医疗安全、临床准备、对话质量和床边方式等方面与人类护士相当，且专家支持代理在任务评估中显著优于 GPT-4 和其他大型模型。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13313v1",
      "published_date": "2024-03-20 05:34:03 UTC",
      "updated_date": "2024-03-20 05:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:26:29.561736"
    },
    {
      "arxiv_id": "2403.13311v3",
      "title": "Multi-Robot Connected Fermat Spiral Coverage",
      "title_zh": "多机器人连接费马螺线覆盖",
      "authors": [
        "Jingtao Tang",
        "Hang Ma"
      ],
      "abstract": "We introduce the Multi-Robot Connected Fermat Spiral (MCFS), a novel\nalgorithmic framework for Multi-Robot Coverage Path Planning (MCPP) that adapts\nConnected Fermat Spiral (CFS) from the computer graphics community to\nmulti-robot coordination for the first time. MCFS uniquely enables the\norchestration of multiple robots to generate coverage paths that contour around\narbitrarily shaped obstacles, a feature that is notably lacking in traditional\nmethods. Our framework not only enhances area coverage and optimizes task\nperformance, particularly in terms of makespan, for workspaces rich in\nirregular obstacles but also addresses the challenges of path continuity and\ncurvature critical for non-holonomic robots by generating smooth paths without\ndecomposing the workspace. MCFS solves MCPP by constructing a graph of isolines\nand transforming MCPP into a combinatorial optimization problem, aiming to\nminimize the makespan while covering all vertices. Our contributions include\ndeveloping a unified CFS version for scalable and adaptable MCPP, extending it\nto MCPP with novel optimization techniques for cost reduction and path\ncontinuity and smoothness, and demonstrating through extensive experiments that\nMCFS outperforms existing MCPP methods in makespan, path curvature, coverage\nratio, and overlapping ratio. Our research marks a significant step in MCPP,\nshowcasing the fusion of computer graphics and automated planning principles to\nadvance the capabilities of multi-robot systems in complex environments. Our\ncode is available at https://github.com/reso1/MCFS.",
      "tldr_zh": "本文提出 Multi-Robot Connected Fermat Spiral (MCFS) 算法，这是首次将 Connected Fermat Spiral (CFS) 从计算机图形学领域应用于多机器人覆盖路径规划 (MCPP)，允许机器人绕过任意形状障碍物生成平滑路径。MCFS 通过构建 isolines 图并转化为组合优化问题，优化 makespan（完成时间），并确保路径连续性和曲率适合非全向机器人，从而提升覆盖效率和任务性能。实验结果显示，MCFS 在复杂环境中比现有方法在 makespan、路径曲率、覆盖率和重叠率方面表现出显著优势，标志着计算机图形学与自动化规划的融合。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted to ICAPS24",
      "pdf_url": "http://arxiv.org/pdf/2403.13311v3",
      "published_date": "2024-03-20 05:23:24 UTC",
      "updated_date": "2024-04-16 15:35:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:26:42.357396"
    },
    {
      "arxiv_id": "2405.07994v1",
      "title": "BubbleID: A Deep Learning Framework for Bubble Interface Dynamics Analysis",
      "title_zh": "BubbleID：一个深度学习框架用于气泡界面动力学分析",
      "authors": [
        "Christy Dunlap",
        "Changgen Li",
        "Hari Pandey",
        "Ngan Le",
        "Han Hu"
      ],
      "abstract": "This paper presents BubbleID, a sophisticated deep learning architecture\ndesigned to comprehensively identify both static and dynamic attributes of\nbubbles within sequences of boiling images. By amalgamating segmentation\npowered by Mask R-CNN with SORT-based tracking techniques, the framework is\ncapable of analyzing each bubble's location, dimensions, interface shape, and\nvelocity over its lifetime, and capturing dynamic events such as bubble\ndeparture. BubbleID is trained and tested on boiling images across diverse\nheater surfaces and operational settings. This paper also offers a comparative\nanalysis of bubble interface dynamics prior to and post-critical heat flux\n(CHF) conditions.",
      "tldr_zh": "这篇论文提出了 BubbleID，一个先进的深度学习框架，用于识别沸腾图像中气泡的静态和动态属性，包括位置、尺寸、界面形状、速度及其生命周期。框架整合了 Mask R-CNN 的分割技术和 SORT-based 跟踪方法，以精确捕捉气泡动态事件，如气泡脱离。BubbleID 在不同加热表面和操作设置下进行了训练和测试，并对临界热通量（CHF）前后气泡界面动态进行了比较分析，展示了其在沸腾现象研究中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "16 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07994v1",
      "published_date": "2024-03-20 05:17:43 UTC",
      "updated_date": "2024-03-20 05:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:26:52.724522"
    },
    {
      "arxiv_id": "2403.13309v1",
      "title": "Mapping LLM Security Landscapes: A Comprehensive Stakeholder Risk Assessment Proposal",
      "title_zh": "映射 LLM 安全景观：一个全面的利益相关者风险评估提案",
      "authors": [
        "Rahul Pankajakshan",
        "Sumitra Biswal",
        "Yuvaraj Govindarajulu",
        "Gilad Gressel"
      ],
      "abstract": "The rapid integration of Large Language Models (LLMs) across diverse sectors\nhas marked a transformative era, showcasing remarkable capabilities in text\ngeneration and problem-solving tasks. However, this technological advancement\nis accompanied by significant risks and vulnerabilities. Despite ongoing\nsecurity enhancements, attackers persistently exploit these weaknesses, casting\ndoubts on the overall trustworthiness of LLMs. Compounding the issue,\norganisations are deploying LLM-integrated systems without understanding the\nseverity of potential consequences. Existing studies by OWASP and MITRE offer a\ngeneral overview of threats and vulnerabilities but lack a method for directly\nand succinctly analysing the risks for security practitioners, developers, and\nkey decision-makers who are working with this novel technology. To address this\ngap, we propose a risk assessment process using tools like the OWASP risk\nrating methodology which is used for traditional systems. We conduct scenario\nanalysis to identify potential threat agents and map the dependent system\ncomponents against vulnerability factors. Through this analysis, we assess the\nlikelihood of a cyberattack. Subsequently, we conduct a thorough impact\nanalysis to derive a comprehensive threat matrix. We also map threats against\nthree key stakeholder groups: developers engaged in model fine-tuning,\napplication developers utilizing third-party APIs, and end users. The proposed\nthreat matrix provides a holistic evaluation of LLM-related risks, enabling\nstakeholders to make informed decisions for effective mitigation strategies.\nOur outlined process serves as an actionable and comprehensive tool for\nsecurity practitioners, offering insights for resource management and enhancing\nthe overall system security.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 的安全风险，指出现有研究如OWASP和MITRE虽提供了威胁概述，但缺乏针对安全从业者、开发者和决策者的直接分析方法。论文提出一种全面风险评估过程，使用OWASP风险评级方法进行场景分析、识别威胁代理、映射系统组件与漏洞因素，并评估攻击可能性和影响，以构建一个完整的威胁矩阵。该矩阵将风险映射到三大利益相关者群体（模型微调开发者、第三方API应用开发者以及最终用户），帮助他们制定有效的缓解策略，并为资源管理和系统安全提供可操作的工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 1 figure, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.13309v1",
      "published_date": "2024-03-20 05:17:22 UTC",
      "updated_date": "2024-03-20 05:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:27:05.427108"
    },
    {
      "arxiv_id": "2403.13293v1",
      "title": "Building Optimal Neural Architectures using Interpretable Knowledge",
      "title_zh": "利用可解释知识构建最优神经架构",
      "authors": [
        "Keith G. Mills",
        "Fred X. Han",
        "Mohammad Salameh",
        "Shengyao Lu",
        "Chunhua Zhou",
        "Jiao He",
        "Fengyu Sun",
        "Di Niu"
      ],
      "abstract": "Neural Architecture Search is a costly practice. The fact that a search space\ncan span a vast number of design choices with each architecture evaluation\ntaking nontrivial overhead makes it hard for an algorithm to sufficiently\nexplore candidate networks. In this paper, we propose AutoBuild, a scheme which\nlearns to align the latent embeddings of operations and architecture modules\nwith the ground-truth performance of the architectures they appear in. By doing\nso, AutoBuild is capable of assigning interpretable importance scores to\narchitecture modules, such as individual operation features and larger macro\noperation sequences such that high-performance neural networks can be\nconstructed without any need for search. Through experiments performed on\nstate-of-the-art image classification, segmentation, and Stable Diffusion\nmodels, we show that by mining a relatively small set of evaluated\narchitectures, AutoBuild can learn to build high-quality architectures directly\nor help to reduce search space to focus on relevant areas, finding better\narchitectures that outperform both the original labeled ones and ones found by\nsearch baselines. Code available at\nhttps://github.com/Ascend-Research/AutoBuild",
      "tldr_zh": "本论文提出 AutoBuild 方案，用于构建高性能神经架构，避免了传统 Neural Architecture Search (NAS) 的高成本问题。该方法通过学习对齐操作和架构模块的潜在嵌入与真实性能，分配可解释的重要性分数给模块（如操作特征和宏操作序列），从而无需搜索直接构建优化网络。在图像分类、分割和 Stable Diffusion 模型的实验中，AutoBuild 通过挖掘少量评估架构，能直接生成或缩小搜索空间以找到优于基线模型的架构，展示了其高效性和潜力。代码开源于 https://github.com/Ascend-Research/AutoBuild。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR'24; 18 Pages, 18 Figures, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2403.13293v1",
      "published_date": "2024-03-20 04:18:38 UTC",
      "updated_date": "2024-03-20 04:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:27:19.372960"
    },
    {
      "arxiv_id": "2403.13269v3",
      "title": "AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Liu",
        "Souvik Kundu",
        "Anni Li",
        "Junrui Wan",
        "Lianghao Jiang",
        "Peter Anthony Beerel"
      ],
      "abstract": "We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as\nAdaptive Freezing of Low Rank Adaptation (AFLoRA). Specifically, for each\npre-trained frozen weight tensor, we add a parallel path of trainable low-rank\nmatrices, namely a down-projection and an up-projection matrix, each of which\nis followed by a feature transformation vector. Based on a novel freezing\nscore, we the incrementally freeze these projection matrices during fine-tuning\nto reduce the computation and alleviate over-fitting. Our experimental results\ndemonstrate that we can achieve state-of-the-art performance with an average\nimprovement of up to $0.85\\%$ as evaluated on GLUE benchmark while yeilding up\nto $9.5\\times$ fewer average trainable parameters. While compared in terms of\nruntime, AFLoRA can yield up to $1.86\\times$ improvement as opposed to similar\nPEFT alternatives. Besides the practical utility of our approach, we provide\ninsights on the trainability requirements of LoRA paths at different modules\nand the freezing schedule for the different projection matrices. Code will be\nreleased.",
      "tldr_zh": "这篇论文提出了 AFLoRA，一种新型的 Parameter-Efficient Fine-Tuning (PEFT) 方法，通过为预训练模型的冻结权重张量添加可训练的低秩矩阵（包括 down-projection 和 up-projection 矩阵，以及后续的特征转换向量），并使用冻结分数逐步冻结这些矩阵，以减少计算量并缓解过拟合。AFLoRA 的实验结果显示，在 GLUE 基准上，它比类似方法平均提高了 0.85% 的性能，同时减少了高达 9.5 倍的可训练参数，并提升了 1.86 倍的运行时速度。该方法还提供了关于 LoRA 路径的可训练性要求和冻结时间表的见解，有助于优化大型模型的微调过程。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13269v3",
      "published_date": "2024-03-20 03:07:50 UTC",
      "updated_date": "2024-04-16 17:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:27:34.764884"
    },
    {
      "arxiv_id": "2403.13257v3",
      "title": "Arcee's MergeKit: A Toolkit for Merging Large Language Models",
      "title_zh": "Arcee's MergeKit：用于合并大型语言模型的工具包",
      "authors": [
        "Charles Goddard",
        "Shamane Siriwardhana",
        "Malikeh Ehghaghi",
        "Luke Meyers",
        "Vlad Karpukhin",
        "Brian Benedict",
        "Mark McQuade",
        "Jacob Solawetz"
      ],
      "abstract": "The rapid expansion of the open-source language model landscape presents an\nopportunity to merge the competencies of these model checkpoints by combining\ntheir parameters. Advances in transfer learning, the process of fine-tuning\npretrained models for specific tasks, has resulted in the development of vast\namounts of task-specific models, typically specialized in individual tasks and\nunable to utilize each other's strengths. Model merging facilitates the\ncreation of multitask models without the need for additional training, offering\na promising avenue for enhancing model performance and versatility. By\npreserving the intrinsic capabilities of the original models, model merging\naddresses complex challenges in AI - including the difficulties of catastrophic\nforgetting and multitask learning. To support this expanding area of research,\nwe introduce MergeKit, a comprehensive, open-source library designed to\nfacilitate the application of model merging strategies. MergeKit offers an\nextensible framework to efficiently merge models on any hardware, providing\nutility to researchers and practitioners. To date, thousands of models have\nbeen merged by the open-source community, leading to the creation of some of\nthe worlds most powerful open-source model checkpoints, as assessed by the Open\nLLM Leaderboard. The library is accessible at\nhttps://github.com/arcee-ai/MergeKit.",
      "tldr_zh": "这篇论文介绍了 Arcee's MergeKit，一种开源工具包，用于合并 Large Language Models 的参数，从而结合不同模型的专长创建多任务模型，而无需额外训练。MergeKit 通过提供可扩展的框架，支持在任何硬件上高效应用模型合并策略，解决了 AI 领域的灾难性遗忘和多任务学习挑战。实验和社区应用显示，该工具已帮助生成数千个模型，包括一些在 Open LLM Leaderboard 上排名靠前的强大开源模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13257v3",
      "published_date": "2024-03-20 02:38:01 UTC",
      "updated_date": "2025-01-09 22:21:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:27:44.673992"
    },
    {
      "arxiv_id": "2403.13249v1",
      "title": "A Unified and General Framework for Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyi Wang",
        "Yan Li",
        "Li Shen",
        "Heng Huang"
      ],
      "abstract": "Continual Learning (CL) focuses on learning from dynamic and changing data\ndistributions while retaining previously acquired knowledge. Various methods\nhave been developed to address the challenge of catastrophic forgetting,\nincluding regularization-based, Bayesian-based, and memory-replay-based\ntechniques. However, these methods lack a unified framework and common\nterminology for describing their approaches. This research aims to bridge this\ngap by introducing a comprehensive and overarching framework that encompasses\nand reconciles these existing methodologies. Notably, this new framework is\ncapable of encompassing established CL approaches as special instances within a\nunified and general optimization objective. An intriguing finding is that\ndespite their diverse origins, these methods share common mathematical\nstructures. This observation highlights the compatibility of these seemingly\ndistinct techniques, revealing their interconnectedness through a shared\nunderlying optimization objective. Moreover, the proposed general framework\nintroduces an innovative concept called refresh learning, specifically designed\nto enhance the CL performance. This novel approach draws inspiration from\nneuroscience, where the human brain often sheds outdated information to improve\nthe retention of crucial knowledge and facilitate the acquisition of new\ninformation. In essence, refresh learning operates by initially unlearning\ncurrent data and subsequently relearning it. It serves as a versatile plug-in\nthat seamlessly integrates with existing CL methods, offering an adaptable and\neffective enhancement to the learning process. Extensive experiments on CL\nbenchmarks and theoretical analysis demonstrate the effectiveness of the\nproposed refresh learning. Code is available at\n\\url{https://github.com/joey-wang123/CL-refresh-learning}.",
      "tldr_zh": "这篇论文针对 Continual Learning (CL) 的核心挑战——在动态数据分布下学习同时避免 catastrophic forgetting，提出一个统一且通用的框架。该框架整合了现有的 regularization-based、Bayesian-based 和 memory-replay-based 方法，将它们统一到一个共享的优化目标中，并揭示这些看似不同的技术在数学结构上具有共通性。作为创新，论文引入 refresh learning 概念，借鉴神经科学原理，通过先 unlearning 当前数据再 relearning 的方式，提升 CL 性能，并可作为插件无缝整合到现有方法中。实验结果显示，该框架在 CL 基准上表现出色，并伴随理论分析，代码已在 GitHub 公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.13249v1",
      "published_date": "2024-03-20 02:21:44 UTC",
      "updated_date": "2024-03-20 02:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:27:56.855025"
    },
    {
      "arxiv_id": "2403.13245v2",
      "title": "Federated reinforcement learning for robot motion planning with zero-shot generalization",
      "title_zh": "联邦强化学习用于机器人运动规划的零样本泛化",
      "authors": [
        "Zhenyuan Yuan",
        "Siyuan Xu",
        "Minghui Zhu"
      ],
      "abstract": "This paper considers the problem of learning a control policy for robot\nmotion planning with zero-shot generalization, i.e., no data collection and\npolicy adaptation is needed when the learned policy is deployed in new\nenvironments. We develop a federated reinforcement learning framework that\nenables collaborative learning of multiple learners and a central server, i.e.,\nthe Cloud, without sharing their raw data. In each iteration, each learner\nuploads its local control policy and the corresponding estimated normalized\narrival time to the Cloud, which then computes the global optimum among the\nlearners and broadcasts the optimal policy to the learners. Each learner then\nselects between its local control policy and that from the Cloud for next\niteration. The proposed framework leverages on the derived zero-shot\ngeneralization guarantees on arrival time and safety. Theoretical guarantees on\nalmost-sure convergence, almost consensus, Pareto improvement and optimality\ngap are also provided. Monte Carlo simulation is conducted to evaluate the\nproposed framework.",
      "tldr_zh": "这篇论文提出了一种联邦强化学习框架，用于机器人运动规划，支持zero-shot generalization，即在新环境中部署时无需额外数据收集和策略适应。框架允许多个学习者与中央服务器（Cloud）协作学习，而不共享原始数据；在每个迭代中，学习者上传本地控制策略和估计的标准化到达时间，Cloud 计算全局最优策略并广播回学习者，学习者随后选择最优策略进行更新。论文提供了理论保证，包括almost-sure convergence、almost consensus、Pareto improvement和optimality gap，并通过Monte Carlo simulation验证了框架在到达时间和安全性上的性能提升。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.RO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13245v2",
      "published_date": "2024-03-20 02:16:54 UTC",
      "updated_date": "2024-04-07 19:25:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:28:08.988621"
    },
    {
      "arxiv_id": "2403.13244v4",
      "title": "Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Zhou",
        "Jianmin Wang",
        "Chunyan Li",
        "Zixu Wang",
        "Yiping Liu",
        "Siqi Sun",
        "Jianxin Lin",
        "Leyi Wei",
        "Xibao Cai",
        "Houtim Lai",
        "Wei Liu",
        "Longyue Wang",
        "Yuansheng Liu",
        "Xiangxiang Zeng"
      ],
      "abstract": "While various models and computational tools have been proposed for structure\nand property analysis of molecules, generating molecules that conform to all\ndesired structures and properties remains a challenge. Here, we introduce a\nmulti-constraint molecular generation large language model, TSMMG, which, akin\nto a student, incorporates knowledge from various small models and tools,\nnamely, the 'teachers'. To train TSMMG, we construct a large set of\ntext-molecule pairs by extracting molecular knowledge from these 'teachers',\nenabling it to generate novel molecules that conform to the descriptions\nthrough various text prompts. We experimentally show that TSMMG remarkably\nperforms in generating molecules meeting complex, natural language-described\nproperty requirements across two-, three-, and four-constraint tasks, with an\naverage molecular validity of over 99% and success ratio of 82.58%, 68.03%, and\n67.48%, respectively. The model also exhibits adaptability through zero-shot\ntesting, creating molecules that satisfy combinations of properties that have\nnot been encountered. It can comprehend text inputs with various language\nstyles, extending beyond the confines of outlined prompts, as confirmed through\nempirical validation. Additionally, the knowledge distillation feature of TSMMG\ncontributes to the continuous enhancement of small models, while the innovative\napproach to dataset construction effectively addresses the issues of data\nscarcity and quality, which positions TSMMG as a promising tool in the domains\nof drug discovery and materials science.",
      "tldr_zh": "本研究提出了一种基于教师-学生框架的TSMMG大语言模型，用于指令驱动的多约束分子生成。该模型通过从各种小模型和工具中提取知识，构建大规模文本-分子对数据集，从而生成符合复杂自然语言描述的创新分子。实验结果显示，TSMMG在二到四约束任务中，分子有效性超过99%，成功率分别为82.58%、68.03%和67.48%，并展示出零样本适应性和对多种语言风格的理解能力。此外，该模型的知识蒸馏功能可提升小模型性能，并有效解决数据稀缺问题，具有重要应用潜力于药物发现和材料科学领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13244v4",
      "published_date": "2024-03-20 02:15:55 UTC",
      "updated_date": "2024-10-10 04:20:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:28:20.775171"
    },
    {
      "arxiv_id": "2403.13236v1",
      "title": "Safety-Aware Reinforcement Learning for Electric Vehicle Charging Station Management in Distribution Network",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarong Fan",
        "Ariel Liebman",
        "Hao Wang"
      ],
      "abstract": "The increasing integration of electric vehicles (EVs) into the grid can pose\na significant risk to the distribution system operation in the absence of\ncoordination. In response to the need for effective coordination of EVs within\nthe distribution network, this paper presents a safety-aware reinforcement\nlearning (RL) algorithm designed to manage EV charging stations while ensuring\nthe satisfaction of system constraints. Unlike existing methods, our proposed\nalgorithm does not rely on explicit penalties for constraint violations,\neliminating the need for penalty coefficient tuning. Furthermore, managing EV\ncharging stations is further complicated by multiple uncertainties, notably the\nvariability in solar energy generation and energy prices. To address this\nchallenge, we develop an off-policy RL algorithm to efficiently utilize data to\nlearn patterns in such uncertain environments. Our algorithm also incorporates\na maximum entropy framework to enhance the RL algorithm's exploratory process,\npreventing convergence to local optimal solutions. Simulation results\ndemonstrate that our algorithm outperforms traditional RL algorithms in\nmanaging EV charging in the distribution network.",
      "tldr_zh": "这篇论文针对电动汽车（EVs）集成对配电网络的潜在风险，提出了一种安全感知强化学习（RL）算法，用于管理 EV 充电站，同时确保系统约束得到满足。该算法创新性地避免使用显式惩罚机制，从而省去了惩罚系数调整的麻烦，并通过离策略 RL 方法来学习太阳能发电和能源价格等不确定性的模式。此外，算法整合了最大熵框架，以提升探索过程并防止收敛到局部最优解。模拟结果显示，该算法在配电网络中管理 EV 充电方面优于传统 RL 算法，提供更可靠的协调策略。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "2024 IEEE Power & Energy Society General Meeting (PESGM)",
      "pdf_url": "http://arxiv.org/pdf/2403.13236v1",
      "published_date": "2024-03-20 01:57:38 UTC",
      "updated_date": "2024-03-20 01:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:28:31.059241"
    },
    {
      "arxiv_id": "2403.13218v1",
      "title": "Self-Attention Based Semantic Decomposition in Vector Symbolic Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Calvin Yeung",
        "Prathyush Poduval",
        "Mohsen Imani"
      ],
      "abstract": "Vector Symbolic Architectures (VSAs) have emerged as a novel framework for\nenabling interpretable machine learning algorithms equipped with the ability to\nreason and explain their decision processes. The basic idea is to represent\ndiscrete information through high dimensional random vectors. Complex data\nstructures can be built up with operations over vectors such as the \"binding\"\noperation involving element-wise vector multiplication, which associates data\ntogether. The reverse task of decomposing the associated elements is a\ncombinatorially hard task, with an exponentially large search space. The main\nalgorithm for performing this search is the resonator network, inspired by\nHopfield network-based memory search operations.\n  In this work, we introduce a new variant of the resonator network, based on\nself-attention based update rules in the iterative search problem. This update\nrule, based on the Hopfield network with log-sum-exp energy function and\nnorm-bounded states, is shown to substantially improve the performance and rate\nof convergence. As a result, our algorithm enables a larger capacity for\nassociative memory, enabling applications in many tasks like perception based\npattern recognition, scene decomposition, and object reasoning. We substantiate\nour algorithm with a thorough evaluation and comparisons to baselines.",
      "tldr_zh": "本论文探讨了 Vector Symbolic Architectures (VSAs)，一种通过高维随机向量表示离散信息并构建复杂数据结构的框架，但其语义分解任务面临指数级搜索空间的挑战。作者提出了一种基于 self-attention 的 resonator network 变体，使用 Hopfield 网络的 log-sum-exp 能量函数和规范边界状态作为更新规则，从而显著提升了性能和收敛速度。实验结果显示，该算法提高了关联记忆容量，并在感知模式识别、场景分解和对象推理等任务中优于基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13218v1",
      "published_date": "2024-03-20 00:37:19 UTC",
      "updated_date": "2024-03-20 00:37:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:28:44.305291"
    },
    {
      "arxiv_id": "2403.13214v2",
      "title": "Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Austin E. Y. T. Lefebvre",
        "Gabriel Sturm",
        "Ting-Yu Lin",
        "Emily Stoops",
        "Magdalena Preciado Lopez",
        "Benjamin Kaufmann-Malaga",
        "Kayley Hake"
      ],
      "abstract": "The analysis of dynamic organelles remains a formidable challenge, though key\nto understanding biological processes. We introduce Nellie, an automated and\nunbiased user-friendly pipeline for segmentation, tracking, and feature\nextraction of diverse intracellular structures. Nellie adapts to image\nmetadata, eliminating user input. Nellie's preprocessing pipeline enhances\nstructural contrast on multiple intracellular scales allowing for robust\nhierarchical segmentation of sub-organellar regions. Internal motion capture\nmarkers are generated and tracked via a radius-adaptive pattern matching\nscheme, and used as guides for sub-voxel flow interpolation. Nellie extracts a\nplethora of features at multiple hierarchical levels for deep and customizable\nanalysis. Nellie features a point-and-click Napari-based GUI that allows for\ncode-free operation and visualization, while its modular open-source codebase\ninvites extension by experienced users. We demonstrate Nellie's wide variety of\nuse cases with three examples: unmixing multiple organelles from a single\nchannel using feature-based classification, training an unsupervised graph\nautoencoder on mitochondrial multi-mesh graphs to quantify latent space\nembedding changes following ionomycin treatment, and performing in-depth\ncharacterization and comparison of endoplasmic reticulum networks across\ndifferent cell types and temporal frames.",
      "tldr_zh": "本研究引入了 Nellie，一个自动化、无偏见的管道，用于在 2D/3D 活细胞显微镜中进行细胞器 segmentation、tracking 和 hierarchical feature extraction。Nellie 通过适应图像元数据、增强结构对比度的预处理管道和半径自适应模式匹配，实现鲁棒的层次分割、内部运动捕捉以及多层次特征提取，支持深度自定义分析。该系统配备用户友好的 Napari-based GUI 和开源模块化代码，便于无代码操作和扩展；通过实际示例，如特征-based classification 分离细胞器、训练无监督图 autoencoder 分析线粒体变化，以及比较内质网网络，展示了其在生物过程分析中的广泛应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "134 pages, 6 main figures, 6 extended figures, 8 supplementary\n  figures; for associated code, see https://github.com/aelefebv/nellie",
      "pdf_url": "http://arxiv.org/pdf/2403.13214v2",
      "published_date": "2024-03-20 00:23:42 UTC",
      "updated_date": "2024-10-15 00:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:28:58.514668"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 89,
  "processed_papers_count": 89,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T17:29:26.758527"
}