{
  "date": "2025-06-22",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-06-22 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“**ï¼š\nä»Šå¤©çš„ arXiv çˆ†å‘äº†å…³äº **Agentï¼ˆæ™ºèƒ½ä½“ï¼‰** å’Œ **Reasoningï¼ˆæ¨ç†æ¨¡å‹ï¼‰** çš„æ·±åº¦æ¢è®¨ã€‚æˆ‘ä»¬ä¸ä»…çœ‹åˆ°äº†å…³äº Deep Research Agents çš„ç³»ç»Ÿæ€§ç»¼è¿°ï¼Œè¿˜æœ‰é€šè¿‡â€œå¿«æ…¢æ€è€ƒâ€åŒç³»ç»Ÿæå‡ GUI Agent èƒ½åŠ›çš„æ¶æ„åˆ›æ–°ã€‚æ­¤å¤–ï¼Œå¤šæ¨¡æ€é¢†åŸŸè¿æ¥äº†å¼€æº GPT-4o çº§å›¾åƒç”Ÿæˆæ•°æ®çš„é‡ç£…å·¥ä½œï¼›è€Œåœ¨æ¨¡å‹æœºç†æ–¹é¢ï¼Œå…³äºå¯¹é½ï¼ˆAlignmentï¼‰å¦‚ä½•é™ä½æ¨¡å‹è¾“å‡ºå¤šæ ·æ€§ã€ä»¥åŠå¦‚ä½•é€šè¿‡ Steering Vectors æ§åˆ¶â€œæ€è€ƒå‹â€æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹çš„ç ”ç©¶ï¼Œéƒ½éå¸¸ä»¤äººå°è±¡æ·±åˆ»ã€‚\n\n---\n\n### ğŸš€ æ·±åº¦ä»£ç†ä¸æ¨ç†æ¨¡å‹ (Deep Agents & Reasoning)\n\n**1. Deep Research Agents: A Systematic Examination And Roadmap**\n**(æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ï¼šç³»ç»Ÿæ€§å®¡æŸ¥ä¸è·¯çº¿å›¾)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™æ˜¯ä¸€ç¯‡éå¸¸åŠæ—¶çš„ç»¼è¿°ã€‚ä½œè€…æ·±å…¥åˆ†æäº†â€œæ·±åº¦ç ”ç©¶ï¼ˆDeep Researchï¼‰â€æ™ºèƒ½ä½“â€”â€”è¿™ç±» Agent èƒ½å¤Ÿå¤„ç†å¤æ‚çš„å¤šè½®ä¿¡æ¯æ£€ç´¢ã€åŠ¨æ€æ¨ç†å’Œé•¿ç¨‹è§„åˆ’ã€‚æ–‡ç« å¯¹æ¯”äº†åŸºäº API å’ŒåŸºäºæµè§ˆå™¨çš„æ£€ç´¢ç­–ç•¥ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªåˆ†ç±»å­¦ï¼Œå°† Agent æ¶æ„åˆ†ä¸ºé™æ€/åŠ¨æ€å·¥ä½œæµä»¥åŠå•/å¤šæ™ºèƒ½ä½“é…ç½®ã€‚\n*   **Implication**ï¼šå¯¹äºæ­£åœ¨æ„å»ºèƒ½å¤Ÿé€šè¿‡ Search + Reasoning è§£å†³å¤æ‚é—®é¢˜çš„å¼€å‘è€…æ¥è¯´ï¼Œè¿™ç¯‡è®ºæ–‡æä¾›äº†æä½³çš„æ¶æ„å‚è€ƒå’Œå·¥å…·ç”Ÿæ€ç›˜ç‚¹ã€‚\n\n**2. Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents**\n**(å­¦ä¹ ã€æ¨ç†ã€ä¼˜åŒ–ï¼šGUI æ™ºèƒ½ä½“ä¸­çš„å¡å°¼æ›¼åŒç³»ç»Ÿæ™ºèƒ½æ¡†æ¶)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå—å¡å°¼æ›¼ã€Šæ€è€ƒï¼Œå¿«ä¸æ…¢ã€‹å¯å‘ï¼Œæå‡ºäº† CogniGUI æ¡†æ¶ã€‚ç³»ç»ŸåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼šä¸€ä¸ª Omni Parser å¼•æ“ï¼ˆå¿«æ€è€ƒï¼Œç›´è§‰å¼æ„ŸçŸ¥ UI å…ƒç´ ï¼‰å’Œä¸€ä¸ª GRPO æ¥åœ°æ™ºèƒ½ä½“ï¼ˆæ…¢æ€è€ƒï¼Œé€šè¿‡ç›¸å¯¹å¥–åŠ±ä¼˜åŒ–å†³ç­–è·¯å¾„ï¼‰ã€‚\n*   **å‘ç°**ï¼šè¿™ç§è®¾è®¡è®© Agent å…·å¤‡äº†â€œæ¢ç´¢-å­¦ä¹ -æŒæ¡â€çš„è¿­ä»£èƒ½åŠ›ï¼Œä¸å†åªæ˜¯è¯•é”™ï¼Œè€Œæ˜¯åœ¨ GUI æ“ä½œä¸­çœŸæ­£â€œå­¦ä¼šâ€äº†ç­–ç•¥ã€‚\n\n**3. Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?**\n**(å…³äºä¸ç¡®å®šæ€§çš„æ¨ç†ï¼šæ¨ç†æ¨¡å‹çŸ¥é“è‡ªå·±ä¸çŸ¥é“å—ï¼Ÿ)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹è¿‘æœŸå¤§ç«çš„æ¨ç†æ¨¡å‹ï¼ˆå¦‚ o1, DeepSeek-R1ï¼‰è¿›è¡Œçš„å†…çœå¼ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰ç ”ç©¶ã€‚\n*   **å‘ç°**ï¼šç»“è®ºä»¤äººæ‹…å¿§â€”â€”æ¨ç†æ¨¡å‹é€šå¸¸**è¿‡åº¦è‡ªä¿¡**ï¼ˆå°¤å…¶æ˜¯åœ¨é”™è¯¯ç­”æ¡ˆä¸Šï¼‰ï¼Œä¸”éšç€æ¨ç†æ·±åº¦å¢åŠ ï¼Œè¿‡åº¦è‡ªä¿¡ä¼šåŠ å‰§ã€‚è™½ç„¶ o3-Mini å’Œ DeepSeek R1 å¯ä»¥é€šè¿‡å†…çœæ”¹å–„æ ¡å‡†ï¼Œä½† Claude 3.7 Sonnet å´è¡¨ç°å‡ºåå‘è¶‹åŠ¿ã€‚è¿™ä¸ºéƒ¨ç½²æ¨ç†æ¨¡å‹æå‡ºäº†å®‰å…¨è­¦ç¤ºã€‚\n\n**4. Understanding Reasoning in Thinking Language Models via Steering Vectors**\n**(é€šè¿‡è½¬å‘å‘é‡ç†è§£æ€è€ƒå‹è¯­è¨€æ¨¡å‹ä¸­çš„æ¨ç†)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ DeepSeek-R1-Distill ç­‰â€œæ€è€ƒå‹â€æ¨¡å‹ï¼Œç ”ç©¶å‘ç°å…¶æ¨ç†è¡Œä¸ºï¼ˆå¦‚è¡¨è¾¾ä¸ç¡®å®šæ€§ã€ç”ŸæˆéªŒè¯æ¡ˆä¾‹ã€å›æº¯ï¼‰æ˜¯ç”±æ¿€æ´»ç©ºé—´ä¸­çš„çº¿æ€§æ–¹å‘ä»‹å¯¼çš„ã€‚\n*   **Implication**ï¼šä½œè€…é€šè¿‡æå– Steering Vectorsï¼ˆè½¬å‘å‘é‡ï¼‰ï¼ŒæˆåŠŸå®ç°äº†å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„å¹²é¢„ï¼ˆä¾‹å¦‚å¼ºåˆ¶æ¨¡å‹è¿›è¡Œæ›´å¤šå›æº¯æˆ–è¡¨è¾¾æ›´å¤šä¸ç¡®å®šæ€§ï¼‰ï¼Œè¿™æ˜¯å¤§æ¨¡å‹å¯è§£é‡Šæ€§å’Œæ§åˆ¶çš„é‡è¦ä¸€æ­¥ã€‚\n\n**5. Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation**\n**(è®°å¿†é“¾ï¼šå¢å¼º GUI æ™ºèƒ½ä½“çš„è·¨åº”ç”¨å¯¼èˆªèƒ½åŠ›)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ GUI Agent å®¹æ˜“â€œå¿˜äº‹â€çš„é—®é¢˜ï¼Œæå‡ºäº† Chain-of-Memory (CoM)ã€‚ä¸åŒäºéšå¼ä¾èµ–å†å²æˆªå›¾ï¼ŒCoM æ˜¾å¼åœ°å»ºæ¨¡çŸ­æœŸå’Œé•¿æœŸè®°å¿†ï¼Œè®°å½•åŠ¨ä½œæè¿°å’Œå…³é”®å±å¹•ä¿¡æ¯ã€‚\n*   **å‘ç°**ï¼šè¿™è®© 7B å¤§å°çš„æ¨¡å‹åœ¨è·¨åº”ç”¨ä»»åŠ¡ä¸­æ‹¥æœ‰äº†åª²ç¾ 72B æ¨¡å‹çš„è®°å¿†ç®¡ç†èƒ½åŠ›ã€‚\n\n---\n\n### ğŸ¨ å¤šæ¨¡æ€ä¸ç”Ÿæˆå¼ AI (Multimodal & GenAI)\n\n**6. ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation**\n**(ShareGPT-4o-Imageï¼šå¯¹é½å…·æœ‰ GPT-4o çº§å›¾åƒç”Ÿæˆèƒ½åŠ›çš„å¤šæ¨¡æ€æ¨¡å‹)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸ºäº†æ‰“ç ´é—­æºæ¨¡å‹ï¼ˆGPT-4oï¼‰çš„å„æ–­ï¼Œä½œè€…æ„å»ºå¹¶å¼€æºäº† ShareGPT-4o-Image æ•°æ®é›†ï¼ˆå« 45K æ–‡ç”Ÿå›¾å’Œ 46K å›¾ç”Ÿå›¾æ•°æ®ï¼‰ã€‚åŸºäºæ­¤è®­ç»ƒçš„ **Janus-4o** æ¨¡å‹åœ¨ä»…ä½¿ç”¨ 91K æ•°æ®å’Œ 8 å¼  A800 è®­ç»ƒ 6 å°æ—¶çš„æƒ…å†µä¸‹ï¼Œå±•ç°äº†æå¼ºçš„æŒ‡ä»¤å¯¹é½å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚\n*   **Implication**ï¼šå¼€æºç¤¾åŒºçš„ç¦éŸ³ï¼Œå¤§å¹…é™ä½äº†å¤ç°é«˜æ€§èƒ½å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹çš„é—¨æ§›ã€‚\n\n**7. Adapting Vision-Language Models for Evaluating World Models**\n**(é€‚é…è§†è§‰è¯­è¨€æ¨¡å‹ä»¥è¯„ä¼°ä¸–ç•Œæ¨¡å‹)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸–ç•Œæ¨¡å‹ï¼ˆWorld Modelsï¼‰ç”Ÿæˆçš„è§†é¢‘å¾€å¾€ç¼ºä¹ç»†ç²’åº¦çš„è¯„ä¼°æŒ‡æ ‡ã€‚æœ¬æ–‡æå‡ºäº† UNIVERSE è¯„ä¼°å™¨ï¼Œåˆ©ç”¨ VLM å¯¹ç”Ÿæˆçš„è§†é¢‘ rollout è¿›è¡ŒåŠ¨ä½œä¸€è‡´æ€§å’Œè¯­ä¹‰è¿è´¯æ€§çš„è‡ªåŠ¨è¯„ä¼°ï¼Œç›¸å…³æ€§ä¸äººç±»åˆ¤æ–­é«˜åº¦ä¸€è‡´ã€‚\n\n**8. EgoWorld: Translating Exocentric View to Egocentric View using Rich Exocentric Observations**\n**(EgoWorldï¼šåˆ©ç”¨ä¸°å¯Œçš„ç¬¬ä¸‰äººç§°è§‚æµ‹å°†ç¬¬ä¸‰äººç§°è§†è§’è½¬æ¢ä¸ºç¬¬ä¸€äººç§°è§†è§’)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ AR/VR å’Œæœºå™¨äººé¢†åŸŸçš„éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§ä»å¤–éƒ¨è§†è§’ï¼ˆExocentricï¼‰é‡å»ºè‡ªæˆ‘ä¸­å¿ƒè§†è§’ï¼ˆEgocentricï¼‰çš„æ–¹æ³•ã€‚åˆ©ç”¨ç‚¹äº‘é‡æŠ•å½±å’Œæ‰©æ•£æ¨¡å‹ä¿®å¤ï¼ˆInpaintingï¼‰ï¼Œåœ¨ H2O æ•°æ®é›†ä¸Šå®ç°äº† SOTAã€‚\n\n---\n\n### ğŸ¤– æœºå™¨äººä¸å…·èº«æ™ºèƒ½ (Robotics & Embodied AI)\n\n**9. RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation**\n**(RoboTwin 2.0ï¼šç”¨äºé²æ£’åŒè‡‚æœºå™¨äººæ“ä½œçš„å¯æ‰©å±•æ•°æ®ç”Ÿæˆå™¨ä¸åŸºå‡†)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸ºäº†è§£å†³åŒè‡‚æœºå™¨äººæ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåˆ©ç”¨ MLLM è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡ä»£ç å’Œåœºæ™¯çš„æ•°æ®åˆæˆæµæ°´çº¿ã€‚å¼•å…¥äº†æå¼ºçš„é¢†åŸŸéšæœºåŒ–ï¼ˆå…‰ç…§ã€èƒŒæ™¯ã€æ‚ç‰©ç­‰ï¼‰ã€‚\n*   **å‘ç°**ï¼šä»…ä½¿ç”¨åˆæˆæ•°æ® + 10 æ¡çœŸå®æ¼”ç¤ºï¼Œå°±èƒ½è®© VLA æ¨¡å‹æ€§èƒ½æ¯”åŸºçº¿æå‡ 367%ï¼ŒSim-to-Real èƒ½åŠ›æ˜¾è‘—å¢å¼ºã€‚\n\n**10. GeNIE: A Generalizable Navigation System for In-the-Wild Environments**\n**(GeNIEï¼šé¢å‘é‡å¤–ç¯å¢ƒçš„é€šç”¨å¯¼èˆªç³»ç»Ÿ)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé›†æˆ SAM2 è¿›è¡Œå¯é€šè¡Œæ€§é¢„æµ‹ï¼Œåœ¨ ICRA 2025 çš„ Earth Rover æŒ‘æˆ˜èµ›ä¸­å¤ºå† ã€‚è¯¥ç³»ç»Ÿåœ¨ä¸‰å¤§æ´²å…­ä¸ªå›½å®¶çš„æµ‹è¯•ä¸­ï¼Œå®ç°äº†å…¨ç¨‹æ— äººå·¥å¹²é¢„çš„å¯¼èˆªï¼Œå±•ç°äº†æå¼ºçš„é‡å¤–é²æ£’æ€§ã€‚\n\n---\n\n### âš•ï¸ AI for Science & Medicine (åŒ»å­¦ä¸ç§‘å­¦)\n\n**11. SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model**\n**(SurgVidLMï¼šè¿ˆå‘å¤šç²’åº¦æ‰‹æœ¯è§†é¢‘ç†è§£çš„å¤§è¯­è¨€æ¨¡å‹)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå‘å¸ƒäº† SVU-31K æ•°æ®é›†ï¼Œå¹¶æå‡ºäº† SurgVidLMã€‚è¯¥æ¨¡å‹é‡‡ç”¨ä¸¤é˜¶æ®µæœºåˆ¶ï¼šç¬¬ä¸€é˜¶æ®µæå–å…¨å±€è¿‡ç¨‹ä¸Šä¸‹æ–‡ï¼Œç¬¬äºŒé˜¶æ®µè¿›è¡Œé«˜é¢‘å±€éƒ¨ç»†èŠ‚åˆ†æã€‚è¿™æ˜¯é¦–ä¸ªåŒæ—¶å…¼é¡¾æ‰‹æœ¯è§†é¢‘å®è§‚ç†è§£å’Œå¾®è§‚åŠ¨ä½œæ•æ‰çš„è§†é¢‘è¯­è¨€æ¨¡å‹ã€‚\n\n**12. Deep Learning-based Alignment Measurement in Knee Radiographs**\n**(åŸºäºæ·±åº¦å­¦ä¹ çš„è†å…³èŠ‚Xå…‰ç‰‡å¯¹é½æµ‹é‡)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šMICCAI 2025 æ¥æ”¶è®ºæ–‡ã€‚æå‡ºäº†é¦–ä¸ªèƒ½å®šä½è¶…è¿‡ 100 ä¸ªè§£å‰–æ ‡å¿—ç‚¹çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºè‡ªåŠ¨æµ‹é‡è†å…³èŠ‚å¯¹é½ï¼ˆKAï¼‰ã€‚æµ‹é‡è¯¯å·®ä»…ä¸º 1Â° å·¦å³ï¼Œä¸ä¸´åºŠé‡‘æ ‡å‡†é«˜åº¦ä¸€è‡´ï¼Œæœ‰æœ›æ”¹å˜å…¨è†å…³èŠ‚ç½®æ¢æœ¯çš„æœ¯å‰è§„åˆ’æµç¨‹ã€‚\n\n**13. OmniESI: A unified framework for enzyme-substrate interaction prediction**\n**(OmniESIï¼šé…¶-åº•ç‰©ç›¸äº’ä½œç”¨é¢„æµ‹çš„ç»Ÿä¸€æ¡†æ¶)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå¼•å…¥æ¡ä»¶æ·±åº¦å­¦ä¹ ï¼Œåˆ†ä¸¤é˜¶æ®µæ¨¡æ‹Ÿé…¶-åº•ç‰©ç›¸äº’ä½œç”¨ã€‚ä¸ä»…é¢„æµ‹å‡†ç¡®ç‡é«˜ï¼Œè¿˜èƒ½ç”¨äºé…¶åŠ¨åŠ›å­¦å‚æ•°é¢„æµ‹å’Œçªå˜æ•ˆåº”é¢„æµ‹ï¼Œæ˜¯åˆæˆç”Ÿç‰©å­¦é¢†åŸŸçš„é‡è¦å·¥å…·ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€å¯¹é½ä¸ç†è®º (Safety, Alignment & Theory)\n\n**14. LLM Probability Concentration: How Alignment Shrinks the Generative Horizon**\n**(LLM æ¦‚ç‡é›†ä¸­ï¼šå¯¹é½å¦‚ä½•æ”¶ç¼©ç”Ÿæˆè§†ç•Œ)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰æ„æ€çš„ç†è®ºå‘ç°ã€‚ä½œè€…å®šä¹‰äº†â€œåˆ†æ”¯å› å­ï¼ˆBranching Factor, BFï¼‰â€æ¥è¡¡é‡ç”Ÿæˆçš„å¯èƒ½æ€§ã€‚\n*   **å‘ç°**ï¼š**å¯¹é½ï¼ˆAlignmentï¼‰æ˜¾è‘—é™ä½äº†æ¨¡å‹çš„ BF**ï¼ˆé™ä½è¿‘ä¸€ä¸ªæ•°é‡çº§ï¼‰ï¼Œä½¿æ¨¡å‹è¾“å‡ºå˜å¾—æ›´åŠ å•ä¸€å’Œå¯é¢„æµ‹ã€‚æ›´æœ‰è¶£çš„æ˜¯ï¼ŒChain-of-Thought (CoT) å®é™…ä¸Šåˆ©ç”¨äº†è¿™ç§æ•ˆåº”â€”â€”é€šè¿‡ç”Ÿæˆé•¿æ¨ç†é“¾ï¼Œå°†ç”Ÿæˆè¿‡ç¨‹æ¨å‘ BF æ›´ä½çš„ç¡®å®šæ€§é˜¶æ®µï¼Œä»è€Œè·å¾—ç¨³å®šçš„ç­”æ¡ˆã€‚è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆå¯¹é½åçš„æ¨¡å‹çœ‹èµ·æ¥â€œåˆ›é€ åŠ›â€ä¸‹é™äº†ã€‚\n\n**15. The Democratic Paradox in Large Language Models' Underestimation of Press Freedom**\n**(å¤§è¯­è¨€æ¨¡å‹ä½ä¼°æ–°é—»è‡ªç”±çš„æ°‘ä¸»æ‚–è®º)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šåˆ†æäº† 6 ä¸ªä¸»æµ LLM å¯¹ 180 ä¸ªå›½å®¶æ–°é—»è‡ªç”±åº¦çš„è¯„ä»·ã€‚\n*   **å‘ç°**ï¼šæ¨¡å‹æ™®éä½ä¼°å…¨çƒæ–°é—»è‡ªç”±åº¦ï¼Œä¸”å­˜åœ¨â€œä¸»åœºåè§â€ï¼ˆHome Biasï¼‰â€”â€”æ¨¡å‹å¯¹è‡ªå·±æ‰€å±å›½å®¶çš„æ–°é—»è‡ªç”±è¯„ä»·å¾€å¾€è¿œé«˜äºé¢„æœŸã€‚\n\n**16. GRAF: Multi-turn Jailbreaking via Global Refinement and Active Fabrication**\n**(GRAFï¼šé€šè¿‡å…¨å±€ç»†åŒ–å’Œä¸»åŠ¨ä¼ªé€ çš„å¤šè½®è¶Šç‹±)**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸€ç§æ–°çš„å¤šè½®è¶Šç‹±æ”»å‡»æ–¹æ³•ã€‚é€šè¿‡ä¸»åŠ¨ä¼ªé€ æ¨¡å‹å›å¤ï¼ˆFabricationï¼‰æ¥æŠ‘åˆ¶å®‰å…¨è­¦å‘Šï¼Œå¹¶åœ¨æ¯è½®äº¤äº’ä¸­å…¨å±€ä¼˜åŒ–æ”»å‡»è½¨è¿¹ï¼ŒæˆåŠŸç‡æ˜¾è‘—é«˜äºç°æœ‰æ–¹æ³•ã€‚\n\n---\n\n### ğŸ› ï¸ å…¶ä»–ç²¾é€‰ (Miscellaneous)\n\n*   **#6 DeInfoReg**: æå‡ºäº†ä¸€ç§è§£è€¦å­¦ä¹ æ¡†æ¶ï¼Œå°†é•¿æ¢¯åº¦æµè½¬åŒ–ä¸ºå¤šä¸ªçŸ­æµï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤š GPU ä¸Šçš„è®­ç»ƒååé‡ã€‚\n*   **#30 eccDNAMamba**: å°† Mamba æ¶æ„åº”ç”¨äºè¶…é•¿ç¯çŠ¶ DNA åºåˆ—åˆ†æï¼Œè§£å†³äº† Transformer å¤„ç†é•¿åºåˆ—æ•ˆç‡ä½çš„é—®é¢˜ã€‚\n*   **#52 Refine Medical Diagnosis**: ç»“åˆ RAG å’Œä¸´åºŠå®è·µæŒ‡å—ï¼ˆCPGï¼‰æ¥ä¼˜åŒ–åŒ»ç–—è¯Šæ–­ï¼Œå‡å°‘å¹»è§‰å¹¶ç¬¦åˆæƒå¨è§„èŒƒã€‚",
  "papers": [
    {
      "arxiv_id": "2506.18209v1",
      "title": "Deep Learning-based Alignment Measurement in Knee Radiographs",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„è†å…³èŠ‚ X çº¿å½±åƒå¯¹çº¿æµ‹é‡",
      "authors": [
        "Zhisen Hu",
        "Dominic Cullen",
        "Peter Thompson",
        "David Johnson",
        "Chang Bian",
        "Aleksei Tiulpin",
        "Timothy Cootes",
        "Claudia Lindner"
      ],
      "abstract": "Radiographic knee alignment (KA) measurement is important for predicting joint health and surgical outcomes after total knee replacement. Traditional methods for KA measurements are manual, time-consuming and require long-leg radiographs. This study proposes a deep learning-based method to measure KA in anteroposterior knee radiographs via automatically localized knee anatomical landmarks. Our method builds on hourglass networks and incorporates an attention gate structure to enhance robustness and focus on key anatomical features. To our knowledge, this is the first deep learning-based method to localize over 100 knee anatomical landmarks to fully outline the knee shape while integrating KA measurements on both pre-operative and post-operative images. It provides highly accurate and reliable anatomical varus/valgus KA measurements using the anatomical tibiofemoral angle, achieving mean absolute differences ~1Â° when compared to clinical ground truth measurements. Agreement between automated and clinical measurements was excellent pre-operatively (intra-class correlation coefficient (ICC) = 0.97) and good post-operatively (ICC = 0.86). Our findings demonstrate that KA assessment can be automated with high accuracy, creating opportunities for digitally enhanced clinical workflows.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ï¼Œç”¨äºåœ¨è†å…³èŠ‚æ­£ä½Xå°„çº¿ç‰‡(Radiographs)ä¸­è‡ªåŠ¨æµ‹é‡è†å…³èŠ‚å¯¹é½(Knee Alignment, KA)ã€‚è¯¥æ–¹æ³•æ„å»ºåœ¨æ²™æ¼ç½‘ç»œ(Hourglass Networks)ä¹‹ä¸Šï¼Œå¹¶å¼•å…¥æ³¨æ„åŠ›é—¨(Attention Gate)ç»“æ„ï¼Œé€šè¿‡è‡ªåŠ¨å®šä½100å¤šä¸ªè†å…³èŠ‚è§£å‰–æ ‡å¿—ç‚¹æ¥å®Œæ•´å‹¾å‹’å…³èŠ‚è½®å»“ã€‚è¿™æ˜¯é¦–ä¸ªèƒ½å¤ŸåŒæ—¶åœ¨æœ¯å‰å’Œæœ¯åå›¾åƒä¸Šé›†æˆKAæµ‹é‡çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œåˆ©ç”¨è§£å‰–è‚¡èƒ«è§’(Anatomical Tibiofemoral Angle)å®ç°äº†é«˜ç²¾åº¦çš„è§£å‰–å­¦å†…ç¿»/å¤–ç¿»æµ‹é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä¸´åºŠé‡‘æ ‡å‡†çš„å¹³å‡ç»å¯¹å·®å¼‚çº¦ä¸º1Â°ï¼Œæœ¯å‰ç»„å†…ç›¸å…³ç³»æ•°(ICC)è¾¾0.97ï¼Œæœ¯åè¾¾0.86ã€‚è¯¥ç ”ç©¶è¯æ˜äº†KAè¯„ä¼°è‡ªåŠ¨åŒ–çš„å¯è¡Œæ€§ä¸é«˜å‡†ç¡®æ€§ï¼Œä¸ºæ•°å­—åŒ–å¢å¼ºä¸´åºŠå·¥ä½œæµå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.18209v1",
      "published_date": "2025-06-22 23:57:46 UTC",
      "updated_date": "2025-06-22 23:57:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:34:40.588288+00:00"
    },
    {
      "arxiv_id": "2506.18204v2",
      "title": "Multimodal Fusion SLAM with Fourier Attention",
      "title_zh": "åŸºäºå‚…é‡Œå¶æ³¨æ„åŠ›æœºåˆ¶çš„å¤šæ¨¡æ€èåˆ SLAM",
      "authors": [
        "Youjie Zhou",
        "Guofeng Mei",
        "Yiming Wang",
        "Yi Wan",
        "Fabio Poiesi"
      ],
      "abstract": "Visual SLAM is particularly challenging in environments affected by noise, varying lighting conditions, and darkness. Learning-based optical flow algorithms can leverage multiple modalities to address these challenges, but traditional optical flow-based visual SLAM approaches often require significant computational resources.To overcome this limitation, we propose FMF-SLAM, an efficient multimodal fusion SLAM method that utilizes fast Fourier transform (FFT) to enhance the algorithm efficiency. Specifically, we introduce a novel Fourier-based self-attention and cross-attention mechanism to extract features from RGB and depth signals. We further enhance the interaction of multimodal features by incorporating multi-scale knowledge distillation across modalities. We also demonstrate the practical feasibility of FMF-SLAM in real-world scenarios with real time performance by integrating it with a security robot by fusing with a global positioning module GNSS-RTK and global Bundle Adjustment. Our approach is validated using video sequences from TUM, TartanAir, and our real-world datasets, showcasing state-of-the-art performance under noisy, varying lighting, and dark conditions.Our code and datasets are available at https://github.com/youjie-zhou/FMF-SLAM.git.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FMF-SLAMï¼Œä¸€ç§é«˜æ•ˆçš„å¤šæ¨¡æ€èåˆSLAMæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè§†è§‰SLAMåœ¨å™ªå£°ã€å…‰ç…§å˜åŒ–åŠé»‘æš—ç¯å¢ƒä¸‹é¢ä¸´çš„é²æ£’æ€§ä¸è®¡ç®—èµ„æºç“¶é¢ˆã€‚è¯¥æ–¹æ³•å¼•å…¥äº†åŸºäºå¿«é€Ÿå‚…é‡Œå¶å˜æ¢(FFT)çš„æ–°é¢–Fourierè‡ªæ³¨æ„åŠ›(self-attention)ä¸äº¤å‰æ³¨æ„åŠ›(cross-attention)æœºåˆ¶ï¼Œç”¨äºä»RGBå’Œæ·±åº¦(depth)ä¿¡å·ä¸­é«˜æ•ˆæå–ç‰¹å¾ã€‚é€šè¿‡æ•´åˆè·¨æ¨¡æ€çš„å¤šå°ºåº¦çŸ¥è¯†è’¸é¦(knowledge distillation)ï¼ŒFMF-SLAMè¿›ä¸€æ­¥å¢å¼ºäº†å¤šæ¨¡æ€ç‰¹å¾çš„äº¤äº’èƒ½åŠ›ã€‚ç ”ç©¶è€…è¿˜å°†è¯¥ç®—æ³•åº”ç”¨äºå®‰å…¨æœºå™¨äººï¼Œç»“åˆGNSS-RTKå…¨çƒå®šä½æ¨¡å—å’Œå…¨å±€æŸè°ƒæ•´(Bundle Adjustment)å®ç°äº†å‡ºè‰²çš„å®æ—¶æ€§èƒ½ã€‚åœ¨TUMã€TartanAiråŠçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤æ‚å…‰ç…§å’Œå™ªå£°æ¡ä»¶ä¸‹è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›(state-of-the-art)çš„æ€§èƒ½æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in IEEE RAL",
      "pdf_url": "https://arxiv.org/pdf/2506.18204v2",
      "published_date": "2025-06-22 23:44:07 UTC",
      "updated_date": "2025-06-24 09:24:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:34:39.523220+00:00"
    },
    {
      "arxiv_id": "2506.18199v2",
      "title": "Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review",
      "title_zh": "ç¼“è§£å¤§è¯­è¨€æ¨¡å‹ä¸­é’ˆå¯¹é˜¿æ‹‰ä¼¯äººåŠç©†æ–¯æ—æ–‡åŒ–åè§çš„æç¤ºå·¥ç¨‹æŠ€æœ¯ï¼šç³»ç»Ÿç»¼è¿°",
      "authors": [
        "Bushra Asseri",
        "Estabrag Abdelaziz",
        "Areej Al-Wabil"
      ],
      "abstract": "Large language models have demonstrated remarkable capabilities across various domains, yet concerns about cultural bias - particularly towards Arabs and Muslims - pose significant ethical challenges by perpetuating harmful stereotypes and marginalization. Despite growing recognition of bias in LLMs, prompt engineering strategies specifically addressing Arab and Muslim representation remain understudied. This mixed-methods systematic review examines such techniques, offering evidence-based guidance for researchers and practitioners. Following PRISMA guidelines and Kitchenham's systematic review methodology, we analyzed 8 empirical studies published between 2021-2024 investigating bias mitigation strategies. Our findings reveal five primary prompt engineering approaches: cultural prompting, affective priming, self-debiasing techniques, structured multi-step pipelines, and parameter-optimized continuous prompts. Although all approaches show potential for reducing bias, effectiveness varied substantially across studies and bias types. Evidence suggests that certain bias types may be more resistant to prompt-based mitigation than others. Structured multi-step pipelines demonstrated the highest overall effectiveness, achieving up to 87.7% reduction in bias, though they require greater technical expertise. Cultural prompting offers broader accessibility with substantial effectiveness. These results underscore the accessibility of prompt engineering for mitigating cultural bias without requiring access to model parameters. The limited number of studies identified highlights a significant research gap in this critical area. Future research should focus on developing culturally adaptive prompting techniques, creating Arab and Muslim-specific evaluation resources, and integrating prompt engineering with complementary debiasing methods to address deeper stereotypes while maintaining model utility.",
      "tldr_zh": "è¿™é¡¹ç³»ç»Ÿæ€§ç»¼è¿°ç ”ç©¶äº†ç¼“è§£ Large Language Models ä¸­é’ˆå¯¹é˜¿æ‹‰ä¼¯äººå’Œç©†æ–¯æ—çš„ Cultural Bias çš„ Prompt Engineering æŠ€æœ¯ã€‚ç ”ç©¶éµå¾ª PRISMA æŒ‡å—å’Œ Kitchenham æ–¹æ³•è®ºï¼Œåˆ†æäº† 2021 å¹´è‡³ 2024 å¹´é—´çš„ 8 é¡¹å®è¯ç ”ç©¶ï¼Œæ€»ç»“å‡º Cultural Promptingã€Affective Primingã€Self-debiasingã€Structured Multi-step Pipelines åŠ Parameter-optimized Continuous Prompts äº”ç§ä¸»è¦ç­–ç•¥ã€‚ç»“æœæ˜¾ç¤ºï¼ŒStructured Multi-step Pipelines çš„åè§ç¼“è§£æ•ˆæœæœ€æ˜¾è‘—ï¼Œå‡å°‘ç‡æœ€é«˜è¾¾ 87.7%ï¼Œè€Œ Cultural Prompting åœ¨å…·å¤‡å®è´¨æ•ˆæœçš„åŒæ—¶æ›´æ˜“äºæ¨å¹¿åº”ç”¨ã€‚ç ”ç©¶å‘ç°ä¸åŒç±»å‹çš„åè§å¯¹æç¤ºæŠ€æœ¯çš„æŠ—æ€§å­˜åœ¨å·®å¼‚ï¼Œå¹¶å¼ºè°ƒäº†åœ¨æ— éœ€è®¿é—®æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹å‡è½» Cultural Bias çš„å¯è¡Œæ€§ã€‚é‰´äºç›®å‰è¯¥é¢†åŸŸç ”ç©¶è¾ƒå°‘ï¼Œæœªæ¥åº”é‡ç‚¹å¼€å‘æ–‡åŒ–é€‚åº”æ€§æç¤ºæŠ€æœ¯ã€å»ºç«‹é’ˆå¯¹é˜¿æ‹‰ä¼¯å’Œç©†æ–¯æ—çš„è¯„ä¼°èµ„æºï¼Œå¹¶å°† Prompt Engineering ä¸å…¶ä»–å»åæ–¹æ³•ç»“åˆä»¥åœ¨è§£å†³æ·±å±‚åˆ»æ¿å°è±¡çš„åŒæ—¶ç»´æŒæ¨¡å‹æ•ˆç”¨ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Research is incomplete",
      "pdf_url": "https://arxiv.org/pdf/2506.18199v2",
      "published_date": "2025-06-22 23:15:25 UTC",
      "updated_date": "2025-07-30 19:07:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:34:45.209357+00:00"
    },
    {
      "arxiv_id": "2506.18196v1",
      "title": "Two Sonification Methods for the MindCube",
      "title_zh": "MindCube çš„ä¸¤ç§éŸ³åŒ–æ–¹æ³•",
      "authors": [
        "Fangzheng Liu",
        "Lancelot Blanchard",
        "Don D. Haddad",
        "Joseph A. Paradiso"
      ],
      "abstract": "In this work, we explore the musical interface potential of the MindCube, an interactive device designed to study emotions. Embedding diverse sensors and input devices, this interface resembles a fidget cube toy commonly used to help users relieve their stress and anxiety. As such, it is a particularly well-suited controller for musical systems that aim to help with emotion regulation. In this regard, we present two different mappings for the MindCube, with and without AI. With our generative AI mapping, we propose a way to infuse meaning within a latent space and techniques to navigate through it with an external controller. We discuss our results and propose directions for future work.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†MindCubeä½œä¸ºéŸ³ä¹äº¤äº’æ¥å£çš„æ½œåŠ›ï¼Œè¿™æ˜¯ä¸€ç§æ¨¡ä»¿å‡å‹é­”æ–¹ï¼ˆfidget cubeï¼‰è®¾è®¡å¹¶ç”¨äºç ”ç©¶æƒ…ç»ªäº’åŠ¨çš„äº¤äº’å¼è®¾å¤‡ã€‚é‰´äºå…¶é›†æˆäº†å¤šç§ä¼ æ„Ÿå™¨ä¸”å…·å¤‡ç¼“è§£å‹åŠ›å’Œç„¦è™‘çš„ç‰¹æ€§ï¼Œè¯¥è®¾å¤‡è¢«è®¤ä¸ºéå¸¸é€‚åˆä½œä¸ºè¾…åŠ©æƒ…ç»ªè°ƒèŠ‚ï¼ˆemotion regulationï¼‰çš„éŸ³ä¹ç³»ç»Ÿæ§åˆ¶å™¨ã€‚ç ”ç©¶è€…ä¸ºæ­¤æå‡ºäº†ä¸¤ç§ä¸åŒçš„å£°åŒ–ï¼ˆsonificationï¼‰æ˜ å°„æ–¹æ³•ï¼Œåˆ†åˆ«æ¶µç›–äº†ä¼ ç»Ÿæ˜ å°„ä¸åŸºäºäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„æ–¹æ¡ˆã€‚åœ¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰æ˜ å°„æ–¹æ¡ˆä¸­ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åœ¨æ½œç©ºé—´ï¼ˆlatent spaceï¼‰ä¸­æ³¨å…¥è¯­ä¹‰çš„æ–¹æ³•ï¼Œå¹¶å¼€å‘äº†åˆ©ç”¨å¤–éƒ¨æ§åˆ¶å™¨åœ¨è¯¥ç©ºé—´ä¸­å¯¼èˆªçš„æŠ€æœ¯ã€‚è¯¥å·¥ä½œé€šè¿‡å¯¹å®éªŒç»“æœçš„è®¨è®ºï¼Œä¸ºæœªæ¥åˆ©ç”¨æ­¤ç±»ç‰©ç†äº¤äº’è£…ç½®è¿›è¡ŒéŸ³ä¹è¾…åŠ©å¹²é¢„æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.18196v1",
      "published_date": "2025-06-22 23:09:37 UTC",
      "updated_date": "2025-06-22 23:09:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:34:44.802972+00:00"
    },
    {
      "arxiv_id": "2506.18195v1",
      "title": "Wisdom of Crowds Through Myopic Self-Confidence Adaptation",
      "title_zh": "åŸºäºçŸ­è§†è‡ªæˆ‘ä¿¡å¿ƒè°ƒèŠ‚çš„ç¾¤ä½“æ™ºæ…§",
      "authors": [
        "Giacomo Como",
        "Fabio Fagnani",
        "Anton Proskurnikov"
      ],
      "abstract": "The wisdom of crowds is an umbrella term for phenomena suggesting that the collective judgment or decision of a large group can be more accurate than the individual judgments or decisions of the group members. A well-known example illustrating this concept is the competition at a country fair described by Galton, where the median value of the individual guesses about the weight of an ox resulted in an astonishingly accurate estimate of the actual weight. This phenomenon resembles classical results in probability theory and relies on independent decision-making. The accuracy of the group's final decision can be significantly reduced if the final agents' opinions are driven by a few influential agents.\n  In this paper, we consider a group of agents who initially possess uncorrelated and unbiased noisy measurements of a common state of the world. Assume these agents iteratively update their estimates according to a simple non-Bayesian learning rule, commonly known in mathematical sociology as the French-DeGroot dynamics or iterative opinion pooling. As a result of this iterative distributed averaging process, each agent arrives at an asymptotic estimate of the state of the world, with the variance of this estimate determined by the matrix of weights the agents assign to each other. Every agent aims at minimizing the variance of her asymptotic estimate of the state of the world; however, such variance is also influenced by the weights allocated by other agents. To achieve the best possible estimate, the agents must then solve a game-theoretic, multi-objective optimization problem defined by the available sets of influence weights. We characterize both the Pareto frontier and the set of Nash equilibria in the resulting game. Additionally, we examine asynchronous best-response dynamics for the group of agents and prove their convergence to the set of strict Nash equilibria.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†â€œç¾¤ä½“æ™ºæ…§â€(Wisdom of crowds)ç°è±¡ï¼Œå³é›†ä½“å†³ç­–å¾€å¾€æ¯”ä¸ªä½“å†³ç­–æ›´å‡†ç¡®ï¼Œä½†åœ¨å­˜åœ¨å°‘æ•°å½±å“åŠ›è¿‡å¤§çš„æ™ºèƒ½ä½“æ—¶ï¼Œç¾¤ä½“å†³ç­–çš„å‡†ç¡®æ€§ä¼šæ˜¾è‘—ä¸‹é™ã€‚è®ºæ–‡å‡è®¾ä¸€ç»„æŒæœ‰åˆå§‹ä¸ç›¸å…³ä¸”æ— åå™ªå£°è§‚æµ‹å€¼çš„æ™ºèƒ½ä½“ï¼Œæ ¹æ® French-DeGroot åŠ¨åŠ›å­¦å³è¿­ä»£æ„è§æ± åŒ–è§„åˆ™æ¥æ›´æ–°å…¶ä¼°è®¡å€¼ã€‚æ¯ä¸ªæ™ºèƒ½ä½“é€šè¿‡è°ƒæ•´åˆ†é…çš„å½±å“åŠ›æƒé‡ï¼Œæ—¨åœ¨æœ€å°åŒ–å…¶æœ€ç»ˆæ¸è¿‘ä¼°è®¡å€¼çš„æ–¹å·®ï¼Œè¿™æ„æˆäº†ä¸€ä¸ªåšå¼ˆè®ºä¸­çš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜ã€‚ç ”ç©¶ç³»ç»Ÿåœ°åˆ»ç”»äº†è¯¥åšå¼ˆçš„ Pareto å‰æ²¿å’Œ Nash å¹³è¡¡é›†ï¼Œå¹¶è¿›ä¸€æ­¥æ¢è®¨äº†æ™ºèƒ½ä½“ç¾¤ä½“çš„å¼‚æ­¥æœ€ä½³å“åº”(Asynchronous best-response)åŠ¨åŠ›å­¦ã€‚æœ€åï¼Œè®ºæ–‡è¯æ˜äº†è¯¥åŠ¨åŠ›å­¦è¿‡ç¨‹èƒ½å¤Ÿæ”¶æ•›åˆ°ä¸¥æ ¼çš„ Nash å¹³è¡¡ï¼Œä¸ºç†è§£é€šè¿‡è‡ªé€‚åº”è°ƒæ•´æƒé‡æ¥ä¼˜åŒ–ç¾¤ä½“å†³ç­–ç²¾åº¦æä¾›äº†æ•°å­¦æ¡†æ¶ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.MA",
        "eess.SY",
        "physics.soc-ph"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18195v1",
      "published_date": "2025-06-22 22:55:17 UTC",
      "updated_date": "2025-06-22 22:55:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:34:46.415520+00:00"
    },
    {
      "arxiv_id": "2506.18193v2",
      "title": "DeInfoReg: A Decoupled Learning Framework for Better Training Throughput",
      "title_zh": "DeInfoRegï¼šä¸€ç§æ—¨åœ¨æå‡è®­ç»ƒååé‡çš„è§£è€¦å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Zih-Hao Huang",
        "You-Teng Lin",
        "Hung-Hsuan Chen"
      ],
      "abstract": "This paper introduces Decoupled Supervised Learning with Information Regularization (DeInfoReg), a novel approach that transforms a long gradient flow into multiple shorter ones, thereby mitigating the vanishing gradient problem. Integrating a pipeline strategy, DeInfoReg enables model parallelization across multiple GPUs, significantly improving training throughput. We compare our proposed method with standard backpropagation and other gradient flow decomposition techniques. Extensive experiments on diverse tasks and datasets demonstrate that DeInfoReg achieves superior performance and better noise resistance than traditional BP models and efficiently utilizes parallel computing resources. The code for reproducibility is available at: https://github.com/ianzih/Decoupled-Supervised-Learning-for-Information-Regularization/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DeInfoRegï¼ˆDecoupled Supervised Learning with Information Regularizationï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å°†é•¿æ¢¯åº¦æµè½¬åŒ–ä¸ºå¤šä¸ªçŸ­æ¢¯åº¦æµçš„æ–°å‹è§£è€¦å­¦ä¹ æ¡†æ¶ï¼Œæœ‰æ•ˆç¼“è§£äº†æ·±åº¦å­¦ä¹ ä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚é€šè¿‡é›†æˆæµæ°´çº¿ç­–ç•¥(pipeline strategy)ï¼Œè¯¥æ¡†æ¶å®ç°äº†æ¨¡å‹åœ¨å¤šGPUä¸Šçš„å¹¶è¡ŒåŒ–å¤„ç†ï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒååé‡ã€‚ç ”ç©¶äººå‘˜åœ¨å¤šç§ä»»åŠ¡å’Œæ•°æ®é›†ä¸Šå°†DeInfoRegä¸æ ‡å‡†åå‘ä¼ æ’­(backpropagation)åŠå…¶ä»–æ¢¯åº¦æµåˆ†è§£æŠ€æœ¯è¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDeInfoRegä¸ä»…åœ¨æ€§èƒ½ä¸Šä¼˜äºä¼ ç»ŸBPæ¨¡å‹ï¼Œè¿˜è¡¨ç°å‡ºæ›´å¼ºçš„æŠ—å™ªèƒ½åŠ›ã€‚è¯¥æ¡†æ¶é€šè¿‡é«˜æ•ˆåˆ©ç”¨å¹¶è¡Œè®¡ç®—èµ„æºï¼Œä¸ºæå‡å¤§æ¨¡å‹è®­ç»ƒæ•ˆç‡å’Œé²æ£’æ€§æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18193v2",
      "published_date": "2025-06-22 22:50:06 UTC",
      "updated_date": "2025-07-15 14:29:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:34:53.673420+00:00"
    },
    {
      "arxiv_id": "2506.18191v1",
      "title": "Call Me Maybe: Enhancing JavaScript Call Graph Construction using Graph Neural Networks",
      "title_zh": "Call Me Maybeï¼šåŸºäºå›¾ç¥ç»ç½‘ç»œçš„ JavaScript è°ƒç”¨å›¾æ„å»ºå¢å¼º",
      "authors": [
        "Masudul Hasan Masud Bhuiyan",
        "Gianluca De Stefano",
        "Giancarlo Pellegrino",
        "Cristian-Alexandru Staicu"
      ],
      "abstract": "Static analysis plays a key role in finding bugs, including security issues. A critical step in static analysis is building accurate call graphs that model function calls in a program. However, due to hard-to-analyze language features, existing call graph construction algorithms for JavaScript are neither sound nor complete. Prior work shows that even advanced solutions produce false edges and miss valid ones. In this work, we assist these tools by identifying missed call edges. Our main idea is to frame the problem as link prediction on full program graphs, using a rich representation with multiple edge types. Our approach, GRAPHIA, leverages recent advances in graph neural networks to model non-local relationships between code elements. Concretely, we propose representing JavaScript programs using a combination of syntactic- and semantic-based edges. GRAPHIA can learn from imperfect labels, including static call edges from existing tools and dynamic edges from tests, either from the same or different projects. Because call graphs are sparse, standard machine learning metrics like ROC are not suitable. Instead, we evaluate GRAPHIA by ranking function definitions for each unresolved call site. We conduct a large-scale evaluation on 50 popular JavaScript libraries with 163K call edges (150K static and 13K dynamic). GRAPHIA builds program graphs with 6.6M structural and 386K semantic edges. It ranks the correct target as the top candidate in over 42% of unresolved cases and within the top 5 in 72% of cases, reducing the manual effort needed for analysis. Our results show that learning-based methods can improve the recall of JavaScript call graph construction. To our knowledge, this is the first work to apply GNN-based link prediction to full multi-file program graphs for interprocedural analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ JavaScript é™æ€åˆ†æä¸­ Call Graph æ„å»ºä¸å‡†ç¡®çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º GRAPHIA çš„å¢å¼ºæ–¹æ¡ˆã€‚æ ¸å¿ƒæ€æƒ³æ˜¯å°† Call Graph çš„æ„å»ºå»ºæ¨¡ä¸ºå…¨ç¨‹åºå›¾ä¸Šçš„ Link Prediction é—®é¢˜ï¼Œå¹¶åˆ©ç”¨ Graph Neural Networks (GNNs) æ•æ‰ä»£ç å…ƒç´ é—´çš„éå±€éƒ¨å…³ç³»ã€‚GRAPHIA é€šè¿‡ç»“åˆè¯­æ³•ï¼ˆSyntacticï¼‰å’Œè¯­ä¹‰ï¼ˆSemanticï¼‰è¾¹çš„å¤šé‡è¡¨ç¤ºï¼Œèƒ½å¤Ÿæœ‰æ•ˆä»é™æ€å·¥å…·ç”Ÿæˆçš„ Call Edges æˆ–åŠ¨æ€æµ‹è¯•ç”Ÿæˆçš„ Dynamic Edges ä¸­å­¦ä¹ ã€‚åœ¨å¤§è§„æ¨¡è¯„ä¼°ä¸­ï¼ŒGRAPHIA åœ¨è¶…è¿‡ 42% çš„æœªè§£æè°ƒç”¨ç‚¹ä¸­å°†æ­£ç¡®ç›®æ ‡å‡½æ•°æ’åœ¨é¦–ä½ï¼Œåœ¨ 72% çš„æƒ…å†µä¸‹æ’åœ¨å‰äº”åï¼Œæ˜¾è‘—é™ä½äº†äººå·¥åˆ†æçš„è´Ÿæ‹…ã€‚ä½œä¸ºé¦–ä¸ªå°†åŸºäº GNN çš„ Link Prediction åº”ç”¨äºå®Œæ•´å¤šæ–‡ä»¶ç¨‹åºå›¾è¿›è¡Œè·¨å‡½æ•°åˆ†æï¼ˆInterprocedural Analysisï¼‰çš„å·¥ä½œï¼Œè¯¥ç ”ç©¶è¯æ˜äº†æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨æå‡ JavaScript Call Graph æ„å»ºå¬å›ç‡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18191v1",
      "published_date": "2025-06-22 22:26:44 UTC",
      "updated_date": "2025-06-22 22:26:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:00.204259+00:00"
    },
    {
      "arxiv_id": "2507.00041v1",
      "title": "TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables",
      "title_zh": "TalentMineï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€äººæ‰è¡¨æ ¼æå–ä¸é—®ç­”",
      "authors": [
        "Varun Mannam",
        "Fang Wang",
        "Chaochun Liu",
        "Xin Chen"
      ],
      "abstract": "In talent management systems, critical information often resides in complex tabular formats, presenting significant retrieval challenges for conventional language models. These challenges are pronounced when processing Talent documentation that requires precise interpretation of tabular relationships for accurate information retrieval and downstream decision-making. Current table extraction methods struggle with semantic understanding, resulting in poor performance when integrated into retrieval-augmented chat applications. This paper identifies a key bottleneck - while structural table information can be extracted, the semantic relationships between tabular elements are lost, causing downstream query failures. To address this, we introduce TalentMine, a novel LLM-enhanced framework that transforms extracted tables into semantically enriched representations. Unlike conventional approaches relying on CSV or text linearization, our method employs specialized multimodal reasoning to preserve both structural and semantic dimensions of tabular data. Experimental evaluation across employee benefits document collections demonstrates TalentMine's superior performance, achieving 100% accuracy in query answering tasks compared to 0% for standard AWS Textract extraction and 40% for AWS Textract Visual Q&A capabilities. Our comparative analysis also reveals that the Claude v3 Haiku model achieves optimal performance for talent management applications. The key contributions of this work include (1) a systematic analysis of semantic information loss in current table extraction pipelines, (2) a novel LLM-based method for semantically enriched table representation, (3) an efficient integration framework for retrieval-augmented systems as end-to-end systems, and (4) comprehensive benchmarks on talent analytics tasks showing substantial improvements across multiple categories.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººæ‰ç®¡ç†ç³»ç»Ÿä¸­å¤æ‚è¡¨æ ¼æ•°æ®éš¾ä»¥è¢«ä¼ ç»Ÿè¯­è¨€æ¨¡å‹å‡†ç¡®æ£€ç´¢çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºTalentMineçš„LLMå¢å¼ºæ¡†æ¶ã€‚ç ”ç©¶å‘ç°ï¼Œä¼ ç»Ÿçš„è¡¨æ ¼æå–æ–¹æ³•åœ¨å¤„ç†CSVæˆ–æ–‡æœ¬çº¿æ€§åŒ–æ—¶ï¼Œå¸¸å› ä¸¢å¤±å…ƒç´ é—´çš„è¯­ä¹‰å…³ç³»å¯¼è‡´æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åº”ç”¨æ€§èƒ½ä¸ä½³ã€‚TalentMineé‡‡ç”¨ä¸“é—¨çš„å¤šæ¨¡æ€æ¨ç†(multimodal reasoning)æŠ€æœ¯ï¼Œå°†æå–çš„è¡¨æ ¼è½¬åŒ–ä¸ºè¯­ä¹‰å¢å¼ºçš„è¡¨è¾¾å½¢å¼ï¼Œæœ‰æ•ˆä¿ç•™äº†è¡¨æ ¼çš„ç»“æ„ä¸è¯­ä¹‰ç»´åº¦ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒTalentMineåœ¨å‘˜å·¥ç¦åˆ©æ–‡æ¡£çš„æŸ¥è¯¢é—®ç­”ä»»åŠ¡ä¸­å®ç°äº†100%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºAWS Textractç­‰æ ‡å‡†æå–æŠ€æœ¯ï¼Œä¸”å‘ç°Claude v3 Haikuæ¨¡å‹åœ¨è¯¥é¢†åŸŸè¡¨ç°æœ€ä¸ºå‡ºè‰²ã€‚è¯¥ç ”ç©¶ä¸ä»…ç³»ç»Ÿåˆ†æäº†è¡¨æ ¼æå–ä¸­çš„è¯­ä¹‰ä¿¡æ¯æµå¤±é—®é¢˜ï¼Œè¿˜é€šè¿‡æä¾›é«˜æ•ˆçš„é›†æˆæ¡†æ¶å’Œå¤šç»´åº¦çš„åŸºå‡†æµ‹è¯•ï¼Œä¸ºè‡ªåŠ¨åŒ–äººæ‰åˆ†æä»»åŠ¡æä¾›äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to KDD conference, workshop: Talent and Management Computing (TMC 2025), https://tmcworkshop.github.io/2025/",
      "pdf_url": "https://arxiv.org/pdf/2507.00041v1",
      "published_date": "2025-06-22 22:17:42 UTC",
      "updated_date": "2025-06-22 22:17:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:01.114318+00:00"
    },
    {
      "arxiv_id": "2506.18187v1",
      "title": "The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis",
      "title_zh": "è¯ç‰©ä¸ä¾ä»å¯¹ä¸è‰¯ç»“å±€çš„å½±å“ï¼šåŸºäºç”Ÿå­˜åˆ†æçš„ç²¾ç¥åˆ†è£‚ç—‡æ‚£è€…è¯æ®",
      "authors": [
        "Shahriar Noroozizadeh",
        "Pim Welle",
        "Jeremy C. Weiss",
        "George H. Chen"
      ],
      "abstract": "This study quantifies the association between non-adherence to antipsychotic medications and adverse outcomes in individuals with schizophrenia. We frame the problem using survival analysis, focusing on the time to the earliest of several adverse events (early death, involuntary hospitalization, jail booking). We extend standard causal inference methods (T-learner, S-learner, nearest neighbor matching) to utilize various survival models to estimate individual and average treatment effects, where treatment corresponds to medication non-adherence. Analyses are repeated using different amounts of longitudinal information (3, 6, 9, and 12 months). Using data from Allegheny County in western Pennsylvania, we find strong evidence that non-adherence advances adverse outcomes by approximately 1 to 4 months. Ablation studies confirm that county-provided risk scores adjust for key confounders, as their removal amplifies the estimated effects. Subgroup analyses by medication formulation (injectable vs. oral) and medication type consistently show that non-adherence is associated with earlier adverse events. These findings highlight the clinical importance of adherence in delaying psychiatric crises and show that integrating survival analysis with causal inference tools can yield policy-relevant insights. We caution that although we apply causal inference, we only make associative claims and discuss assumptions needed for causal interpretation.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ç”Ÿå­˜åˆ†æ (Survival Analysis) é‡åŒ–äº†ç²¾ç¥åˆ†è£‚ç—‡ (Schizophrenia) æ‚£è€…å¯¹æŠ—ç²¾ç¥ç—…è¯ç‰©çš„ä¸ä¾ä»æ€§ä¸ä¸è‰¯é¢„åï¼ˆå¦‚æ—©é€ã€éè‡ªæ„¿ä½é™¢æˆ–å…¥ç‹±ï¼‰ä¹‹é—´çš„å…³è”ã€‚ç ”ç©¶äººå‘˜æ‰©å±•äº† T-learnerã€S-learner å’Œæœ€è¿‘é‚»åŒ¹é… (Nearest Neighbor Matching) ç­‰å› æœæ¨æ–­æ–¹æ³•ï¼Œç»“åˆå¤šç§ç”Ÿå­˜æ¨¡å‹æ¥ä¼°ç®—è¯ç‰©ä¸ä¾ä»å¯¹æ²»ç–—æ•ˆåº”çš„å½±å“ã€‚åŸºäºå®¾å¤•æ³•å°¼äºšå·é˜¿åˆ©æ ¹å°¼å¿çš„æ•°æ®åˆ†æè¡¨æ˜ï¼Œè¯ç‰©ä¸ä¾ä»ä¼šä½¿ä¸Šè¿°ä¸è‰¯é¢„åçš„å‘ç”Ÿæ—¶é—´å¹³å‡æå‰çº¦ 1 è‡³ 4 ä¸ªæœˆã€‚æ¶ˆèç ”ç©¶ (Ablation Studies) éªŒè¯äº†é£é™©è¯„åˆ†åœ¨è°ƒæ•´å…³é”®æ··æ‚å› ç´ ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸”é’ˆå¯¹æ³¨å°„å‹ä¸å£æœå‹è¯ç‰©çš„å­ç»„åˆ†æå‡ä¸€è‡´æ˜¾ç¤ºäº†ä¸ä¾ä»ä¸æ›´æ—©å‘ç”Ÿå±æœºä¹‹é—´çš„å¼ºå…³è”ã€‚è¯¥ç ”ç©¶ä¸ä»…å¼ºè°ƒäº†æé«˜æœè¯ä¾ä»æ€§åœ¨æ¨è¿Ÿç²¾ç¥ç§‘å±æœºä¸­çš„ä¸´åºŠä»·å€¼ï¼Œè¿˜è¯æ˜äº†æ•´åˆç”Ÿå­˜åˆ†æä¸å› æœæ¨æ–­å·¥å…·åœ¨äº§å‡ºå…·æœ‰æ”¿ç­–ç›¸å…³æ€§çš„æ·±åº¦è§è§£æ–¹é¢çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "Conference on Health, Inference, and Learning (CHIL 2025)",
      "pdf_url": "https://arxiv.org/pdf/2506.18187v1",
      "published_date": "2025-06-22 22:09:39 UTC",
      "updated_date": "2025-06-22 22:09:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:09.948348+00:00"
    },
    {
      "arxiv_id": "2506.18185v1",
      "title": "CareLab at #SMM4H-HeaRD 2025: Insomnia Detection and Food Safety Event Extraction with Domain-Aware Transformers",
      "title_zh": "CareLab åœ¨ #SMM4H-HeaRD 2025ï¼šåŸºäºé¢†åŸŸæ„ŸçŸ¥ Transformer çš„å¤±çœ æ£€æµ‹ä¸é£Ÿå“å®‰å…¨äº‹ä»¶æŠ½å–",
      "authors": [
        "Zihan Liang",
        "Ziwen Pan",
        "Sumon Kanti Dey",
        "Azra Ismail"
      ],
      "abstract": "This paper presents our system for the SMM4H-HeaRD 2025 shared tasks, specifically Task 4 (Subtasks 1, 2a, and 2b) and Task 5 (Subtasks 1 and 2). Task 4 focused on detecting mentions of insomnia in clinical notes, while Task 5 addressed the extraction of food safety events from news articles. We participated in all subtasks and report key findings across them, with particular emphasis on Task 5 Subtask 1, where our system achieved strong performance-securing first place with an F1 score of 0.958 on the test set. To attain this result, we employed encoder-based models (e.g., RoBERTa), alongside GPT-4 for data augmentation. This paper outlines our approach, including preprocessing, model architecture, and subtask-specific adaptations",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† CareLab å›¢é˜Ÿåœ¨ SMM4H-HeaRD 2025 è¯„æµ‹ä»»åŠ¡ä¸­å¼€å‘çš„ç³»ç»Ÿï¼Œæ¶µç›–äº†ä¸´åºŠç¬”è®°ä¸­çš„å¤±çœ æ£€æµ‹ï¼ˆInsomnia Detectionï¼‰ä»¥åŠæ–°é—»ä¸­çš„é£Ÿå“å®‰å…¨äº‹ä»¶æå–ï¼ˆFood Safety Event Extractionï¼‰ç­‰ä»»åŠ¡ã€‚ä¸ºäº†æå‡æ€§èƒ½ï¼Œç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº† RoBERTa ç­‰åŸºäºç¼–ç å™¨çš„æ¨¡å‹ï¼Œå¹¶ç»“åˆ GPT-4 è¿›è¡Œæ•°æ®å¢å¼ºã€‚åœ¨é£Ÿå“å®‰å…¨äº‹ä»¶æå–å­ä»»åŠ¡ä¸­ï¼Œè¯¥ç³»ç»Ÿè¡¨ç°å‡ºè‰²ï¼Œä»¥ 0.958 çš„ F1 åˆ†æ•°åœ¨æµ‹è¯•é›†ä¸­ä½åˆ—ç¬¬ä¸€ã€‚è®ºæ–‡è¯¦ç»†é˜è¿°äº†é¢„å¤„ç†ã€æ¨¡å‹æ¶æ„åŠé’ˆå¯¹ç‰¹å®šå­ä»»åŠ¡çš„é€‚é…ç­–ç•¥ã€‚è¯¥æˆæœå±•ç¤ºäº†é¢†åŸŸæ„ŸçŸ¥ï¼ˆDomain-Awareï¼‰æŠ€æœ¯ä¸ Transformer æ¨¡å‹åœ¨å¤„ç†åŒ»ç–—ä¸å®‰å…¨é¢†åŸŸå¤æ‚ä¿¡æ¯æå–ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "In the Proceedings of the 10th Social Media Mining for Health and Health Real-World Data Workshop and Shared Tasks, co-located with AAAI ICWSM 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.18185v1",
      "published_date": "2025-06-22 21:56:59 UTC",
      "updated_date": "2025-06-22 21:56:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:10.626726+00:00"
    },
    {
      "arxiv_id": "2506.18183v3",
      "title": "Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?",
      "title_zh": "ä¸ç¡®å®šæ€§æ¨ç†ï¼šæ¨ç†æ¨¡å‹æ˜¯å¦â€œçŸ¥å…¶æ‰€ä¸çŸ¥â€ï¼Ÿ",
      "authors": [
        "Zhiting Mei",
        "Christina Zhang",
        "Tenny Yin",
        "Justin Lidard",
        "Ola Shorinwa",
        "Anirudha Majumdar"
      ],
      "abstract": "Reasoning language models have set state-of-the-art (SOTA) records on many challenging benchmarks, enabled by multi-step reasoning induced using reinforcement learning. However, like previous language models, reasoning models are prone to generating confident, plausible responses that are incorrect (hallucinations). Knowing when and how much to trust these models is critical to the safe deployment of reasoning models in real-world applications. To this end, we explore uncertainty quantification of reasoning models in this work. Specifically, we ask three fundamental questions: First, are reasoning models well-calibrated? Second, does deeper reasoning improve model calibration? Finally, inspired by humans' innate ability to double-check their thought processes to verify the validity of their answers and their confidence, we ask: can reasoning models improve their calibration by explicitly reasoning about their chain-of-thought traces? We introduce introspective uncertainty quantification (UQ) to explore this direction. In extensive evaluations on SOTA reasoning models across a broad range of benchmarks, we find that reasoning models: (i) are typically overconfident, with self-verbalized confidence estimates often greater than 85% particularly for incorrect responses, (ii) become even more overconfident with deeper reasoning, and (iii) can become better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we conclude with important research directions to design necessary UQ benchmarks and improve the calibration of reasoning models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¨ç†æ¨¡å‹(Reasoning models)åœ¨ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification)æ–¹é¢çš„è¡¨ç°ï¼Œæ—¨åœ¨è¯„ä¼°è¿™äº›æ¨¡å‹æ˜¯å¦å…·å¤‡è¯†åˆ«è‡ªèº«çŸ¥è¯†è¾¹ç•Œçš„èƒ½åŠ›ã€‚é€šè¿‡å¯¹å¤šä¸ªå°–ç«¯æ¨¡å‹åœ¨å¹¿æ³›åŸºå‡†æµ‹è¯•ä¸­çš„è¯„ä¼°ï¼Œç ”ç©¶è€…è€ƒå¯Ÿäº†æ¨¡å‹æ ¡å‡†åº¦(Calibration)ã€æ·±åº¦æ¨ç†çš„å½±å“ä»¥åŠå†…çœ(Introspection)æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚å®éªŒå‘ç°æ¨ç†æ¨¡å‹æ™®éè¡¨ç°å‡ºä¸¥é‡çš„è¿‡åº¦è‡ªä¿¡(Overconfident)ï¼Œå³ä½¿åœ¨å›ç­”é”™è¯¯æ—¶å…¶è‡ªè¿°ç½®ä¿¡åº¦ä¹Ÿå¸¸è¶…è¿‡85%ï¼Œä¸”è¿™ç§å€¾å‘ä¼šéšæ¨ç†æ·±åº¦å¢åŠ è€ŒåŠ å‰§ã€‚ç ”ç©¶å¼•å…¥äº†å†…çœå¼ä¸ç¡®å®šæ€§é‡åŒ–(Introspective UQ)æ–¹æ³•ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆæå‡ o3-Mini å’Œ DeepSeek R1 çš„æ ¡å‡†è´¨é‡ï¼Œä½†åœ¨ Claude 3.7 Sonnet ä¸Šè¡¨ç°å¹¶ä¸ç»Ÿä¸€ã€‚è¯¥å·¥ä½œä¸ºæœªæ¥è®¾è®¡æ›´ç²¾ç¡®çš„è¯„ä¼°åŸºå‡†ä»¥åŠä¼˜åŒ–æ¨ç†æ¨¡å‹çš„å¯é æ€§ä¸å®‰å…¨æ€§æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18183v3",
      "published_date": "2025-06-22 21:46:42 UTC",
      "updated_date": "2025-07-18 02:39:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:37.088576+00:00"
    },
    {
      "arxiv_id": "2506.18172v1",
      "title": "STACT-Time: Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification",
      "title_zh": "STACT-Timeï¼šç”¨äºåŠ¨æ€ç”²çŠ¶è…ºè¶…å£°æ—¶é—´åºåˆ—åˆ†ç±»çš„æ—¶ç©ºäº¤å‰æ³¨æ„åŠ›",
      "authors": [
        "Irsyad Adam",
        "Tengyue Zhang",
        "Shrayes Raman",
        "Zhuyu Qiu",
        "Brandon Taraku",
        "Hexiang Feng",
        "Sile Wang",
        "Ashwath Radhachandran",
        "Shreeram Athreya",
        "Vedrana Ivezic",
        "Peipei Ping",
        "Corey Arnold",
        "William Speier"
      ],
      "abstract": "Thyroid cancer is among the most common cancers in the United States. Thyroid nodules are frequently detected through ultrasound (US) imaging, and some require further evaluation via fine-needle aspiration (FNA) biopsy. Despite its effectiveness, FNA often leads to unnecessary biopsies of benign nodules, causing patient discomfort and anxiety. To address this, the American College of Radiology Thyroid Imaging Reporting and Data System (TI-RADS) has been developed to reduce benign biopsies. However, such systems are limited by interobserver variability. Recent deep learning approaches have sought to improve risk stratification, but they often fail to utilize the rich temporal and spatial context provided by US cine clips, which contain dynamic global information and surrounding structural changes across various views. In this work, we propose the Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification (STACT-Time) model, a novel representation learning framework that integrates imaging features from US cine clips with features from segmentation masks automatically generated by a pretrained model. By leveraging self-attention and cross-attention mechanisms, our model captures the rich temporal and spatial context of US cine clips while enhancing feature representation through segmentation-guided learning. Our model improves malignancy prediction compared to state-of-the-art models, achieving a cross-validation precision of 0.91 (plus or minus 0.02) and an F1 score of 0.89 (plus or minus 0.02). By reducing unnecessary biopsies of benign nodules while maintaining high sensitivity for malignancy detection, our model has the potential to enhance clinical decision-making and improve patient outcomes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”²çŠ¶è…ºç»“èŠ‚è¶…å£°æ£€æŸ¥ä¸­ç»†é’ˆç©¿åˆºæ´»æ£€(FNA)å¯¼è‡´çš„ä¸å¿…è¦æ´»æ£€ä»¥åŠç°æœ‰æ¨¡å‹å¯¹æ—¶ç©ºèƒŒæ™¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†STACT-Timeæ¨¡å‹ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ—¶ç©ºäº¤å‰æ³¨æ„åŠ›(Spatio-Temporal Cross Attention)æœºåˆ¶ï¼Œå°†è¶…å£°ç”µå½±å‰ªè¾‘(US cine clips)çš„å›¾åƒç‰¹å¾ä¸è‡ªåŠ¨ç”Ÿæˆçš„åˆ†å‰²æ©è†œ(Segmentation masks)ç‰¹å¾ç›¸ç»“åˆã€‚é€šè¿‡åˆ©ç”¨è‡ªæ³¨æ„åŠ›(Self-attention)å’Œäº¤å‰æ³¨æ„åŠ›å¢å¼ºç‰¹å¾è¡¨ç¤ºï¼Œæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç”²çŠ¶è…ºåŠ¨æ€åºåˆ—ä¸­çš„å…¨å±€ä¿¡æ¯ä¸ç»“æ„å˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼ŒSTACT-Timeåœ¨æ¶æ€§é¢„æµ‹ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå…¶äº¤å‰éªŒè¯ç²¾ç¡®ç‡(Precision)è¾¾åˆ°0.91ï¼ŒF1åˆ†æ•°è¾¾åˆ°0.89ã€‚è¯¥ç ”ç©¶é€šè¿‡æé«˜è¯Šæ–­å‡†ç¡®æ€§å¹¶å‡å°‘è‰¯æ€§ç»“èŠ‚çš„è¿‡åº¦æ´»æ£€ï¼Œä¸ºä¼˜åŒ–ä¸´åºŠå†³ç­–å’Œæ”¹å–„æ‚£è€…é¢„åæä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18172v1",
      "published_date": "2025-06-22 21:14:04 UTC",
      "updated_date": "2025-06-22 21:14:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:39.997334+00:00"
    },
    {
      "arxiv_id": "2506.18167v4",
      "title": "Understanding Reasoning in Thinking Language Models via Steering Vectors",
      "title_zh": "åŸºäºå¼•å¯¼å‘é‡è§£ææ€è€ƒå‹è¯­è¨€æ¨¡å‹çš„æ¨ç†æœºåˆ¶",
      "authors": [
        "Constantin Venhoff",
        "IvÃ¡n Arcuschin",
        "Philip Torr",
        "Arthur Conmy",
        "Neel Nanda"
      ],
      "abstract": "Recent advances in large language models (LLMs) have led to the development of thinking language models that generate extensive internal reasoning chains before producing responses. While these models achieve improved performance, controlling their reasoning processes remains challenging. This work presents a steering approach for thinking LLMs by analyzing and manipulating specific reasoning behaviors in DeepSeek-R1-Distill models. Through a systematic experiment on 500 tasks across 10 diverse categories, we identify several reasoning behaviors exhibited by thinking models, including expressing uncertainty, generating examples for hypothesis validation, and backtracking in reasoning chains. We demonstrate that these behaviors are mediated by linear directions in the model's activation space and can be controlled using steering vectors. By extracting and applying these vectors, we provide a method to modulate specific aspects of the model's reasoning process, such as its tendency to backtrack or express uncertainty. Our approach offers practical tools for steering reasoning processes in thinking models in a controlled and interpretable manner. We validate our steering method using three DeepSeek-R1-Distill models, demonstrating consistent control across different model architectures.",
      "tldr_zh": "æœ¬ç ”ç©¶é€šè¿‡è½¬å‘å‘é‡(steering vectors)æ¢ç´¢äº†ç†è§£ä¸æ§åˆ¶æ€è€ƒå‹è¯­è¨€æ¨¡å‹(thinking language models)æ¨ç†è¿‡ç¨‹çš„æ–¹æ³•ã€‚ç ”ç©¶äººå‘˜é’ˆå¯¹DeepSeek-R1-Distillæ¨¡å‹åœ¨500é¡¹è·¨ç±»åˆ«ä»»åŠ¡ä¸­çš„è¡¨ç°è¿›è¡Œäº†ç³»ç»Ÿå®éªŒï¼Œè¯†åˆ«å‡ºè¡¨è¾¾ä¸ç¡®å®šæ€§(uncertainty)ã€ç”Ÿæˆå‡è®¾éªŒè¯ç¤ºä¾‹ä»¥åŠæ¨ç†é“¾å›æº¯(backtracking)ç­‰å…³é”®æ¨ç†è¡Œä¸ºã€‚å®éªŒè¯æ˜è¿™äº›è¡Œä¸ºç”±æ¨¡å‹æ¿€æ´»ç©ºé—´(activation space)ä¸­çš„çº¿æ€§æ–¹å‘æ‰€ä»‹å¯¼ï¼Œå¯ä»¥é€šè¿‡æå–å¹¶åº”ç”¨ç‰¹å®šçš„è½¬å‘å‘é‡è¿›è¡Œç²¾å‡†å¹²é¢„ã€‚è¯¥æ–¹æ³•æä¾›äº†ä¸€ç§ä»¥å¯æ§ä¸”å¯è§£é‡Šçš„æ–¹å¼è°ƒèŠ‚æ¨¡å‹æ¨ç†å€¾å‘çš„æ‰‹æ®µï¼Œä¾‹å¦‚è°ƒæ•´å…¶å›æº¯é¢‘ç‡æˆ–è¡¨è¾¾ä¸ç¡®å®šæ€§çš„ç¨‹åº¦ã€‚è¯¥æŠ€æœ¯åœ¨ä¸‰ç§ä¸åŒè§„æ¨¡çš„DeepSeek-R1-Distillæ¨¡å‹ä¸Šå‡éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œä¸ºå¼•å¯¼å¤æ‚æ¨¡å‹çš„æ¨ç†é“¾æ¡æä¾›äº†å®ç”¨ä¸”ä¸€è‡´çš„å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the Workshop on Reasoning and Planning for Large Language Models at ICLR 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.18167v4",
      "published_date": "2025-06-22 20:45:26 UTC",
      "updated_date": "2025-10-22 09:57:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:36.983461+00:00"
    },
    {
      "arxiv_id": "2507.01040v1",
      "title": "Fast Clifford Neural Layers",
      "title_zh": "å¿«é€Ÿ Clifford ç¥ç»å±‚",
      "authors": [
        "Tianxiang Xia",
        "Max Neuwinger",
        "Lin Xiao"
      ],
      "abstract": "Clifford Neural Layers improve PDE modeling by introducing Clifford Algebra into neural networks. In this project we focus on optimizing the inference of 2/3D Clifford convolutional layers and multivector activation layers for one core CPU performance.\n  Overall, by testing on a real network block involving Clifford convolutional layers and multivector activation layers, we observe that our implementation is 30% faster than standard PyTorch implementation in relatively large data + network size (>L2 cache).\n  We open source our code base at https://github.com/egretwAlker/c-opt-clifford-layers",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é‡ç‚¹å…³æ³¨ Clifford Neural Layers çš„æ¨ç†ä¼˜åŒ–ï¼Œè¯¥æŠ€æœ¯é€šè¿‡å°† Clifford Algebra å¼•å…¥ç¥ç»ç½‘ç»œæ¥æå‡ PDE modeling çš„æ€§èƒ½ã€‚ç ”ç©¶å›¢é˜Ÿé’ˆå¯¹å•æ ¸ CPU æ€§èƒ½ï¼Œå¯¹ 2/3D Clifford convolutional layers ä»¥åŠ multivector activation layers çš„æ¨ç†è¿‡ç¨‹è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ã€‚åœ¨æ¶‰åŠè¿™äº›å±‚çº§çš„çœŸå®ç½‘ç»œå—æµ‹è¯•ä¸­ï¼Œè¯¥å®ç°æ–¹æ¡ˆåœ¨å¤„ç†è¶…è¿‡ L2 cache çš„å¤§è§„æ¨¡æ•°æ®å’Œç½‘ç»œå¤§å°æ—¶ï¼Œæ¯”æ ‡å‡†çš„ PyTorch å®ç°é€Ÿåº¦æå‡äº† 30%ã€‚è¯¥ç ”ç©¶æ˜¾è‘—æé«˜äº†è¿ç®—æ•ˆç‡ï¼Œå¹¶å·²å°†ä»£ç åº“å¼€æºï¼Œä¸ºç›¸å…³é¢†åŸŸçš„åº•å±‚è®¡ç®—æä¾›äº†é«˜æ•ˆæ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages content-wise",
      "pdf_url": "https://arxiv.org/pdf/2507.01040v1",
      "published_date": "2025-06-22 20:43:42 UTC",
      "updated_date": "2025-06-22 20:43:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:33.186833+00:00"
    },
    {
      "arxiv_id": "2506.18165v3",
      "title": "Non-equilibrium Annealed Adjoint Sampler",
      "title_zh": "éå¹³è¡¡é€€ç«ä¼´éšé‡‡æ ·å™¨",
      "authors": [
        "Jaemoo Choi",
        "Yongxin Chen",
        "Molei Tao",
        "Guan-Horng Liu"
      ],
      "abstract": "Recently, there has been significant progress in learning-based diffusion samplers, which aim to sample from a given unnormalized density. Many of these approaches formulate the sampling task as a stochastic optimal control (SOC) problem using a canonical uninformative reference process, which limits their ability to efficiently guide trajectories toward the target distribution. In this work, we propose the Non-Equilibrium Annealed Adjoint Sampler (NAAS), a novel SOC-based diffusion framework that employs annealed reference dynamics as a non-stationary base SDE. This annealing structure provides a natural progression toward the target distribution and generates informative reference trajectories, thereby enhancing the stability and efficiency of learning the control. Owing to our SOC formulation, our framework can incorporate a variety of SOC solvers, thereby offering high flexibility in algorithmic design. As one instantiation, we employ a lean adjoint system inspired by adjoint matching, enabling efficient and scalable training. We demonstrate the effectiveness of NAAS across a range of tasks, including sampling from classical energy landscapes and molecular Boltzmann distributions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Non-Equilibrium Annealed Adjoint Sampler (NAAS)ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„åŸºäºéšæœºæœ€ä¼˜æ§åˆ¶ (Stochastic Optimal Control, SOC) çš„æ‰©æ•£é‡‡æ ·æ¡†æ¶ã€‚é’ˆå¯¹ä¼ ç»Ÿå­¦ä¹ é‡‡æ ·å™¨å› ä½¿ç”¨æ— ä¿¡æ¯å‚è€ƒè¿‡ç¨‹è€Œéš¾ä»¥å¼•å¯¼è½¨è¿¹è¶‹å‘ç›®æ ‡åˆ†å¸ƒçš„é—®é¢˜ï¼ŒNAAS å¼•å…¥äº†é€€ç«å‚è€ƒåŠ¨åŠ›å­¦ (Annealed Reference Dynamics) ä½œä¸ºéå¹³ç¨³åŸºç¡€ SDEã€‚è¿™ç§é€€ç«ç»“æ„ä¸ºé€šå¾€ç›®æ ‡åˆ†å¸ƒæä¾›äº†è‡ªç„¶çš„è·¯å¾„æ¼”åŒ–ï¼Œå¹¶é€šè¿‡ç”Ÿæˆå…·æœ‰ä¿¡æ¯é‡çš„å‚è€ƒè½¨è¿¹ï¼Œæ˜¾è‘—å¢å¼ºäº†æ§åˆ¶å­¦ä¹ çš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚å¾—ç›Šäºå…¶ SOC å…¬å¼ï¼Œè¯¥æ¡†æ¶å±•ç°å‡ºé«˜åº¦çš„ç®—æ³•çµæ´»æ€§ï¼Œèƒ½å¤Ÿæ•´åˆå¤šç§ SOC æ±‚è§£å™¨ã€‚åœ¨å…·ä½“å®ç°ä¸Šï¼Œè¯¥ç ”ç©¶é‡‡ç”¨äº†ä¸€ç§å—ä¼´éšåŒ¹é… (Adjoint Matching) å¯å‘çš„ç²¾ç®€ä¼´éšç³»ç»Ÿï¼Œç¡®ä¿äº†è®­ç»ƒè¿‡ç¨‹çš„é«˜æ•ˆæ€§ä¸å¯æ‰©å±•æ€§ã€‚å®éªŒç»“æœè¯æ˜äº† NAAS åœ¨å¤„ç†ç»å…¸èƒ½é‡æ™¯è§‚å’Œåˆ†å­ Boltzmann åˆ†å¸ƒç­‰å¤šç§å¤æ‚é‡‡æ ·ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.18165v3",
      "published_date": "2025-06-22 20:41:31 UTC",
      "updated_date": "2025-11-25 07:56:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:47.488644+00:00"
    },
    {
      "arxiv_id": "2506.18158v1",
      "title": "Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation",
      "title_zh": "Chain-of-Memoryï¼šå¢å¼ºè·¨åº”ç”¨å¯¼èˆªèƒ½åŠ›çš„ GUI æ™ºèƒ½ä½“",
      "authors": [
        "Xinzge Gao",
        "Chuanrui Hu",
        "Bin Chen",
        "Teng Li"
      ],
      "abstract": "Multimodal large language models (MLLMs) are attracting growing attention in the development of Graphical User Interface (GUI) agents. Existing approaches often rely on historical screenshots or actions to implicitly represent the task state. This reliance poses challenges for GUI agents in accurately understanding task states and underscores the absence of effective mechanisms to store critical information in complex and lengthy cross-app tasks. To address these challenges, we propose Chain-of-Memory (CoM), a novel approach for explicitly modeling short-term and long-term memory in GUI agents. CoM achieves this by capturing action descriptions, integrating task-relevant screen information, and maintaining a dedicated memory module to store and manage this information. By leveraging explicit memory representations, CoM enables GUI agents to better understand task states and retain critical historical information persistently. To equip GUI agents with memory management capabilities and evaluate the effectiveness of CoM, we developed the GUI Odyssey-CoM, a dataset comprising 111k screen-action pairs annotated with Chain-of-Memory. Experimental results demonstrate that CoM significantly improves GUI agents' performance in cross-application tasks. Additionally, GUI Odyssey-CoM enables 7B models to achieve memory management capabilities comparable to 72B models. The dataset and code will be open-sourced.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Chain-of-Memory (CoM)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å¢å¼ºå›¾å½¢ç”¨æˆ·ç•Œé¢(GUI)æ™ºèƒ½ä½“å¤„ç†è·¨åº”ç”¨å¯¼èˆªèƒ½åŠ›çš„æ˜¾å¼è®°å¿†å»ºæ¨¡æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨å¤æ‚ä»»åŠ¡ä¸­éš¾ä»¥å‡†ç¡®ç†è§£ä»»åŠ¡çŠ¶æ€ä¸”ç¼ºä¹æœ‰æ•ˆä¿¡æ¯å­˜å‚¨æœºåˆ¶çš„æŒ‘æˆ˜ï¼ŒCoMé€šè¿‡æ•æ‰åŠ¨ä½œæè¿°ã€æ•´åˆä»»åŠ¡ç›¸å…³å±å¹•ä¿¡æ¯å¹¶ç»´æŠ¤ä¸“é—¨çš„è®°å¿†æ¨¡å—ï¼Œå®ç°äº†å¯¹çŸ­æœŸå’Œé•¿æœŸè®°å¿†çš„æ˜¾å¼å»ºæ¨¡ã€‚è¿™ç§æœºåˆ¶ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ›´ç²¾å‡†åœ°æŠŠæ¡ä»»åŠ¡è¿›åº¦å¹¶æŒä¹…ä¿ç•™å…³é”®å†å²ä¿¡æ¯ã€‚ä¸ºéªŒè¯è¯¥æ–¹æ³•å¹¶èµ‹äºˆæ¨¡å‹è®°å¿†ç®¡ç†èƒ½åŠ›ï¼Œç ”ç©¶è€…æ„å»ºäº†åŒ…å«11.1ä¸‡ä¸ªå±å¹•-åŠ¨ä½œå¯¹çš„GUI Odyssey-CoMæ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoMæ˜¾è‘—æå‡äº†GUIæ™ºèƒ½ä½“åœ¨è·¨åº”ç”¨ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œå¹¶ä½¿7Bå‚æ•°è§„æ¨¡çš„æ¨¡å‹å±•ç°å‡ºä¸72Bæ¨¡å‹ç›¸å½“çš„è®°å¿†ç®¡ç†æ°´å¹³ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18158v1",
      "published_date": "2025-06-22 20:17:46 UTC",
      "updated_date": "2025-06-22 20:17:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:51.489206+00:00"
    },
    {
      "arxiv_id": "2506.18156v3",
      "title": "AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology",
      "title_zh": "äººç±»è§†è§’ä¸‹çš„äººå·¥æ™ºèƒ½ï¼šæœºå™¨å¿ƒç†å­¦ä¸­çš„è®¤çŸ¥ç†è®ºæ¢ç©¶",
      "authors": [
        "Akash Kundu",
        "Rishika Goswami"
      ],
      "abstract": "We investigate whether Large Language Models (LLMs) exhibit human-like cognitive patterns under four established frameworks from psychology: Thematic Apperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and Cognitive Dissonance. We evaluated several proprietary and open-source models using structured prompts and automated scoring. Our findings reveal that these models often produce coherent narratives, show susceptibility to positive framing, exhibit moral judgments aligned with Liberty/Oppression concerns, and demonstrate self-contradictions tempered by extensive rationalization. Such behaviors mirror human cognitive tendencies yet are shaped by their training data and alignment methods. We discuss the implications for AI transparency, ethical deployment, and future work that bridges cognitive psychology and AI safety",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) æ˜¯å¦åœ¨å¿ƒç†å­¦å®šä¹‰çš„å››ä¸ªæ—¢å®šæ¡†æ¶ä¸‹è¡¨ç°å‡ºç±»äººçš„è®¤çŸ¥æ¨¡å¼ï¼ŒåŒ…æ‹¬ä¸»é¢˜ç»Ÿè§‰æµ‹éªŒ (TAT)ã€æ¡†æ¶åå·® (Framing Bias)ã€é“å¾·åŸºç¡€ç†è®º (MFT) å’Œè®¤çŸ¥å¤±è°ƒ (Cognitive Dissonance)ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ç»“æ„åŒ–æç¤ºå’Œè‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿå¯¹å¤šä¸ªä¸“æœ‰å’Œå¼€æºæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œå‘ç°è¿™äº›æ¨¡å‹é€šå¸¸èƒ½äº§ç”Ÿè¿è´¯çš„å™äº‹å¹¶è¡¨ç°å‡ºå¯¹ç§¯ææ¡†æ¶çš„æ•æ„Ÿæ€§ã€‚åœ¨é“å¾·åˆ¤æ–­æ–¹é¢ï¼Œæ¨¡å‹å€¾å‘äºå…³æ³¨è‡ªç”±/å‹è¿« (Liberty/Oppression) è®®é¢˜ï¼Œå¹¶å±•ç°å‡ºç»ç”±å¹¿æ³›åˆç†åŒ–å¤„ç†çš„è‡ªæˆ‘çŸ›ç›¾ç°è±¡ã€‚å°½ç®¡è¿™äº›è¡Œä¸ºé•œåƒäº†äººç±»çš„è®¤çŸ¥å€¾å‘ï¼Œä½†æœ¬è´¨ä¸Šä»å—è®­ç»ƒæ•°æ®å’Œå¯¹é½æ–¹æ³• (Alignment Methods) çš„å¡‘é€ ã€‚è¯¥ç ”ç©¶æ¢è®¨äº†ç›¸å…³å‘ç°å¯¹ AI é€æ˜åº¦ã€ä¼¦ç†éƒ¨ç½²çš„æ·±è¿œå½±å“ï¼Œå¹¶ä¸ºè¿æ¥è®¤çŸ¥å¿ƒç†å­¦ä¸ AI å®‰å…¨çš„æœªæ¥ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to IJCNLP-AACL 2025 Student Research Workshop",
      "pdf_url": "https://arxiv.org/pdf/2506.18156v3",
      "published_date": "2025-06-22 19:58:19 UTC",
      "updated_date": "2025-12-11 18:18:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:02.956131+00:00"
    },
    {
      "arxiv_id": "2506.18149v1",
      "title": "CoachGPT: A Scaffolding-based Academic Writing Assistant",
      "title_zh": "CoachGPTï¼šæ”¯æ¶å¼å­¦æœ¯å†™ä½œåŠ©æ‰‹",
      "authors": [
        "Fumian Chen",
        "Sotheara Veng",
        "Joshua Wilson",
        "Xiaoming Li",
        "Hui Fang"
      ],
      "abstract": "Academic writing skills are crucial for students' success, but can feel overwhelming without proper guidance and practice, particularly when writing in a second language. Traditionally, students ask instructors or search dictionaries, which are not universally accessible. Early writing assistants emerged as rule-based systems that focused on detecting misspellings, subject-verb disagreements, and basic punctuation errors; however, they are inaccurate and lack contextual understanding. Machine learning-based assistants demonstrate a strong ability for language understanding but are expensive to train. Large language models (LLMs) have shown remarkable capabilities in generating responses in natural languages based on given prompts. Still, they have a fundamental limitation in education: they generate essays without teaching, which can have detrimental effects on learning when misused. To address this limitation, we develop CoachGPT, which leverages large language models (LLMs) to assist individuals with limited educational resources and those who prefer self-paced learning in academic writing. CoachGPT is an AI agent-based web application that (1) takes instructions from experienced educators, (2) converts instructions into sub-tasks, and (3) provides real-time feedback and suggestions using large language models. This unique scaffolding structure makes CoachGPT unique among existing writing assistants. Compared to existing writing assistants, CoachGPT provides a more immersive writing experience with personalized feedback and guidance. Our user studies prove the usefulness of CoachGPT and the potential of large language models for academic writing.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº† CoachGPTï¼Œè¿™æ˜¯ä¸€æ¬¾åŸºäº Large Language Models (LLMs) çš„ Scaffolding æ¶æ„å­¦æœ¯å†™ä½œè¾…åŠ©å·¥å…·ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå·¥å…·ç¼ºä¹ä¸Šä¸‹æ–‡ç†è§£ä»¥åŠç°æœ‰ LLMs ä»…ç”Ÿæˆå†…å®¹è€Œå¿½è§†æ•™è‚²å¼•å¯¼çš„å±€é™ã€‚ä½œä¸ºä¸€ç§åŸºäº AI agent çš„ Web åº”ç”¨ç¨‹åºï¼ŒCoachGPT èƒ½å¤Ÿæ¥æ”¶ç»éªŒä¸°å¯Œæ•™è‚²è€…çš„æŒ‡ä»¤å¹¶å°†å…¶è½¬åŒ–ä¸ºå…·ä½“çš„ sub-tasksï¼Œè¿›è€Œåˆ©ç”¨ LLMs æä¾›å®æ—¶çš„åé¦ˆä¸å»ºè®®ã€‚è¿™ç§ç‹¬ç‰¹çš„ Scaffolding ç»“æ„ä½¿ CoachGPT èƒ½å¤Ÿä¸ºæ•™è‚²èµ„æºæœ‰é™æˆ–åå¥½è‡ªä¸»å­¦ä¹ çš„ç”¨æˆ·æä¾›æ²‰æµ¸å¼çš„å†™ä½œä½“éªŒã€‚ä¸ä¼ ç»Ÿçš„åŸºäºè§„åˆ™æˆ– Machine Learning çš„ç³»ç»Ÿç›¸æ¯”ï¼Œè¯¥å·¥å…·æ›´å¼ºè°ƒä¸ªæ€§åŒ–çš„æŒ‡å¯¼ä¸å¯å‘ã€‚ç”¨æˆ·ç ”ç©¶è¯æ˜äº† CoachGPT çš„å®ç”¨æ€§ï¼Œå¹¶å±•ç¤ºäº† LLMs åœ¨è¾…åŠ©å­¦æœ¯å†™ä½œé¢†åŸŸé€šè¿‡å¼•å¯¼å¼æ•™å­¦æå‡å­¦ç”Ÿèƒ½åŠ›çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "SIGIR 2025 DEMO Pre-print",
      "pdf_url": "https://arxiv.org/pdf/2506.18149v1",
      "published_date": "2025-06-22 19:39:33 UTC",
      "updated_date": "2025-06-22 19:39:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:57.189637+00:00"
    },
    {
      "arxiv_id": "2506.21617v1",
      "title": "Bayesian-Guided Diversity in Sequential Sampling for Recommender Systems",
      "title_zh": "æ¨èç³»ç»Ÿåºåˆ—é‡‡æ ·ä¸­çš„è´å¶æ–¯å¼•å¯¼å¤šæ ·æ€§",
      "authors": [
        "Hiba Bederina",
        "Jill-JÃªnn Vie"
      ],
      "abstract": "The challenge of balancing user relevance and content diversity in recommender systems is increasingly critical amid growing concerns about content homogeneity and reduced user engagement. In this work, we propose a novel framework that leverages a multi-objective, contextual sequential sampling strategy. Item selection is guided by Bayesian updates that dynamically adjust scores to optimize diversity. The reward formulation integrates multiple diversity metrics-including the log-determinant volume of a tuned similarity submatrix and ridge leverage scores-along with a diversity gain uncertainty term to address the exploration-exploitation trade-off. Both intra- and inter-batch diversity are modeled to promote serendipity and minimize redundancy. A dominance-based ranking procedure identifies Pareto-optimal item sets, enabling adaptive and balanced selections at each iteration. Experiments on a real-world dataset show that our approach significantly improves diversity without sacrificing relevance, demonstrating its potential to enhance user experience in large-scale recommendation settings.",
      "tldr_zh": "é’ˆå¯¹æ¨èç³»ç»Ÿä¸­å¹³è¡¡ç”¨æˆ·ç›¸å…³æ€§ä¸å†…å®¹å¤šæ ·æ€§çš„æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤šç›®æ ‡ä¸Šä¸‹æ–‡é¡ºåºé‡‡æ ·ï¼ˆsequential samplingï¼‰çš„åˆ›æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ Bayesian updates å¼•å¯¼é¡¹ç›®é€‰æ‹©ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´åˆ†å€¼æ¥æŒç»­ä¼˜åŒ–å¤šæ ·æ€§è¡¨ç°ã€‚å…¶å¥–åŠ±æœºåˆ¶æ•´åˆäº†åŒ…æ‹¬ç›¸ä¼¼æ€§å­çŸ©é˜µçš„ log-determinant volume å’Œ ridge leverage scores åœ¨å†…çš„å¤šç§æŒ‡æ ‡ï¼Œå¹¶å¼•å…¥å¤šæ ·æ€§å¢ç›Šä¸ç¡®å®šæ€§é¡¹ä»¥æœ‰æ•ˆå¤„ç† exploration-exploitation trade-offã€‚ç³»ç»ŸåŒæ—¶å¯¹ intra-batch å’Œ inter-batch å¤šæ ·æ€§è¿›è¡Œå»ºæ¨¡ï¼Œæ—¨åœ¨æå‡æ¨èçš„ serendipity å¹¶æœ€å¤§é™åº¦å‡å°‘å†…å®¹å†—ä½™ã€‚é€šè¿‡åŸºäºä¼˜åŠ¿çš„æ’åç¨‹åºè¯†åˆ« Pareto-optimal é¡¹ç›®é›†ï¼Œè¯¥æ–¹æ³•å®ç°äº†æ¯æ¬¡è¿­ä»£ä¸­çš„è‡ªé€‚åº”å¹³è¡¡é€‰æ‹©ã€‚åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨ä¸ç‰ºç‰²ç›¸å…³æ€§çš„å‰æä¸‹æ˜¾è‘—å¢å¼ºäº†å¤šæ ·æ€§ï¼Œå±•ç°äº†åœ¨å¤§è§„æ¨¡æ¨èè®¾ç½®ä¸­æå‡ç”¨æˆ·ä½“éªŒçš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.21617v1",
      "published_date": "2025-06-22 19:36:02 UTC",
      "updated_date": "2025-06-22 19:36:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:35:59.186935+00:00"
    },
    {
      "arxiv_id": "2506.18148v1",
      "title": "QuranMorph: Morphologically Annotated Quranic Corpus",
      "title_zh": "QuranMorphï¼šå½¢æ€å­¦æ ‡æ³¨çš„ã€Šå¤å…°ç»ã€‹è¯­æ–™åº“",
      "authors": [
        "Diyam Akra",
        "Tymaa Hammouda",
        "Mustafa Jarrar"
      ],
      "abstract": "We present the QuranMorph corpus, a morphologically annotated corpus for the Quran (77,429 tokens). Each token in the QuranMorph was manually lemmatized and tagged with its part-of-speech by three expert linguists. The lemmatization process utilized lemmas from Qabas, an Arabic lexicographic database linked with 110 lexicons and corpora of 2 million tokens. The part-of-speech tagging was performed using the fine-grained SAMA/Qabas tagset, which encompasses 40 tags. As shown in this paper, this rich lemmatization and POS tagset enabled the QuranMorph corpus to be inter-linked with many linguistic resources. The corpus is open-source and publicly available as part of the SinaLab resources at (https://sina.birzeit.edu/quran)",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† QuranMorphï¼Œä¸€ä¸ªåŒ…å« 77,429 ä¸ªæ ‡è®°çš„å¤å…°ç»å½¢æ€æ ‡æ³¨è¯­æ–™åº“ã€‚åœ¨è¯¥è¯­æ–™åº“ä¸­ï¼Œæ¯ä¸ªæ ‡è®°å‡ç”±ä¸‰ä½ä¸“å®¶çº§è¯­è¨€å­¦å®¶æ‰‹åŠ¨è¿›è¡Œè¯å…ƒåŒ– (lemmatization) å’Œè¯æ€§æ ‡æ³¨ (part-of-speech tagging)ã€‚è¯å…ƒåŒ–è¿‡ç¨‹é‡‡ç”¨äº†æºè‡ª Qabas æ•°æ®åº“çš„è¯å…ƒï¼Œè¯¥æ•°æ®åº“å…³è”äº† 110 ä¸ªè¯å…¸åŠ 200 ä¸‡æ ‡è®°çš„è¯­æ–™åº“ã€‚è¯æ€§æ ‡æ³¨åˆ™ä½¿ç”¨äº†åŒ…å« 40 ä¸ªç±»åˆ«çš„ç»†ç²’åº¦ SAMA/Qabas æ ‡è®°é›†ã€‚å‡­å€Ÿä¸°å¯Œçš„è¯å…ƒåŒ–å’Œè¯æ€§æ ‡æ³¨è®¾è®¡ï¼ŒQuranMorph èƒ½å¤Ÿä¸å¤šç§è¯­è¨€èµ„æºå®ç°äº’è¿ã€‚è¯¥è¯­æ–™åº“ç›®å‰å·²ä½œä¸º SinaLab èµ„æºçš„ä¸€éƒ¨åˆ†å¼€æºå¹¶å‘å…¬ä¼—å¼€æ”¾ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18148v1",
      "published_date": "2025-06-22 19:34:09 UTC",
      "updated_date": "2025-06-22 19:34:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:06.110292+00:00"
    },
    {
      "arxiv_id": "2506.18941v1",
      "title": "Can AI support student engagement in classroom activities in higher education?",
      "title_zh": "äººå·¥æ™ºèƒ½èƒ½å¦æ”¯æŒé«˜ç­‰æ•™è‚²è¯¾å ‚æ´»åŠ¨ä¸­çš„å­¦ç”Ÿå‚ä¸ï¼Ÿ",
      "authors": [
        "Neha Rani",
        "Sharan Majumder",
        "Ishan Bhardwaj",
        "Pedro Guillermo Feijoo Garcia"
      ],
      "abstract": "Lucrative career prospects and creative opportunities often attract students to enroll in computer science majors and pursue advanced studies in the field. Consequently, there has been a significant surge in enrollment in computer science courses, resulting in large class sizes that can range from hundreds to even thousands of students. A common challenge in such large classrooms is the lack of engagement between students and both the instructor and the learning material. However, with advancements in technology and improvements in large language models (LLMs), there is a considerable opportunity to utilize LLM-based AI models, such as conversational artificial intelligence (CAI), to enhance student engagement with learning content in large classes. To explore the potential of CAI to support engagement, especially with learning content, we designed an activity in a software Engineering course (with a large class size) where students used CAI for an in-class activity. We conducted a within-subject investigation in a large classroom at a US university where we compared student engagement during an in-class activity that used CAI tool vs. one without CAI tool. The CAI tool we used was ChatGPT due to its widespread popularity and familiarity. Our results indicate that CAI (ChatGPT) has the potential to support engagement with learning content during in-class activities, especially in large class sizes. We further discuss the implications of our findings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è§„æ¨¡é«˜ç­‰æ•™è‚²è¯¾å ‚ä¸­ï¼Œäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å¦‚ä½•æ”¯æŒå­¦ç”Ÿçš„å‚ä¸åº¦ï¼ˆstudent engagementï¼‰ã€‚ç ”ç©¶è€…åœ¨æŸç¾å›½å¤§å­¦çš„è½¯ä»¶å·¥ç¨‹ï¼ˆSoftware Engineeringï¼‰è¯¾ç¨‹ä¸­å¼€å±•äº†ä¸€é¡¹è¢«è¯•å†…ç ”ç©¶ï¼ˆwithin-subject investigationï¼‰ï¼Œå¯¹æ¯”äº†ä½¿ç”¨ä¸ä¸ä½¿ç”¨ä¼šè¯å¼äººå·¥æ™ºèƒ½ï¼ˆCAIï¼‰å·¥å…·åœ¨è¯¾å ‚æ´»åŠ¨ä¸­çš„æ•ˆæœã€‚å®éªŒé€‰ç”¨äº†å¹¿æ³›ä½¿ç”¨çš„ ChatGPT ä½œä¸ºä¸»è¦çš„ CAI å·¥å…·ï¼Œé‡ç‚¹è€ƒå¯Ÿå…¶å¯¹å­¦ç”Ÿä¸å­¦ä¹ å†…å®¹äº’åŠ¨çš„ä¿ƒè¿›ä½œç”¨ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼ŒCAIï¼ˆChatGPTï¼‰å…·æœ‰æ˜¾è‘—æå‡å­¦ç”Ÿå‚ä¸å­¦ä¹ å†…å®¹çš„èƒ½åŠ›ï¼Œå°¤å…¶åœ¨åº”å¯¹å¤§å‹ç­çº§ï¼ˆlarge class sizesï¼‰å¸¸è§çš„å¸ˆç”Ÿäº’åŠ¨ä¸è¶³æŒ‘æˆ˜æ—¶è¡¨ç°ä¼˜å¼‚ã€‚è¯¥å‘ç°å¼ºè°ƒäº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ”¹å–„é«˜ç­‰æ•™è‚²è¯¾å ‚ä½“éªŒçš„æ½œåŠ›ï¼Œå¹¶æ·±å…¥è®¨è®ºäº†å…¶åœ¨æ•™å­¦å®è·µä¸­çš„å½±å“ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18941v1",
      "published_date": "2025-06-22 19:30:47 UTC",
      "updated_date": "2025-06-22 19:30:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:19.649073+00:00"
    },
    {
      "arxiv_id": "2506.18145v1",
      "title": "Routing Mamba: Scaling State Space Models with Mixture-of-Experts Projection",
      "title_zh": "Routing Mambaï¼šé€šè¿‡æ··åˆä¸“å®¶æŠ•å½±å®ç°çŠ¶æ€ç©ºé—´æ¨¡å‹çš„è§„æ¨¡æ‰©å±•",
      "authors": [
        "Zheng Zhan",
        "Liliang Ren",
        "Shuohang Wang",
        "Liyuan Liu",
        "Yang Liu",
        "Yeyun Gong",
        "Yanzhi Wang",
        "Yelong Shen"
      ],
      "abstract": "Linear State Space Models (SSMs) offer remarkable performance gains in efficient sequence modeling, with constant inference-time computation and memory complexity. Recent advances, such as Mamba, further enhance SSMs with input-dependent gating and hardware-aware implementations, positioning them as strong alternatives to Transformers for long sequence modeling. However, efficiently scaling the expressive power of SSMs, particularly with Mixture of Experts (MoE), remains challenging, as naive integration attempts often falter or degrade performance. In this work, we introduce Routing Mamba (RoM), a novel approach that scales SSM parameters using sparse mixtures of linear projection experts. By sharing routing decisions between projection layers and lightweight sub-modules within Mamba across experts, RoM leverages synergies among linear projection experts for effective and efficient sparse scaling of Mamba layers. At a scale of 1.3B active parameters (10B total) and 16K training sequence length, RoM achieves language modeling performance equivalent to a dense Mamba model requiring over 2.3x more active parameters, and demonstrates consistent perplexity across context lengths. Experimental results further show RoM effectively scales hybrid language models, yielding a 23% FLOPS saving compared to dense Mamba scaling for similar performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Routing Mamba (RoM)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡ç¨€ç–çº¿æ€§æŠ•å½±ä¸“å®¶æ··åˆ (Mixture of Experts, MoE) æ¥æ‰©å±•çŠ¶æ€ç©ºé—´æ¨¡å‹ (State Space Models, SSMs) å‚æ•°çš„æ–°é¢–æ–¹æ³•ã€‚é’ˆå¯¹ä¼ ç»Ÿ MoE é›†æˆåœ¨ Mamba æ¨¡å‹ä¸­æ•ˆæœä¸ä½³æˆ–æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼ŒRoM é€šè¿‡åœ¨æŠ•å½±å±‚å’Œ Mamba å†…éƒ¨è½»é‡çº§å­æ¨¡å—ä¹‹é—´å…±äº«è·¯ç”±å†³ç­–ï¼Œåˆ©ç”¨ä¸“å®¶é—´çš„ååŒæ•ˆåº”å®ç°äº†é«˜æ•ˆçš„ç¨€ç–æ‰©å±•ã€‚åœ¨ 1.3B æ¿€æ´»å‚æ•°ï¼ˆæ€»è®¡ 10B å‚æ•°ï¼‰çš„è§„æ¨¡ä¸‹ï¼ŒRoM è¾¾åˆ°äº†ä¸æ¿€æ´»å‚æ•°é‡è¶…è¿‡å…¶ 2.3 å€çš„ç¨ å¯† Mamba æ¨¡å‹ç›¸å½“çš„è¯­è¨€å»ºæ¨¡æ€§èƒ½ï¼Œå¹¶å±•ç°äº†è·¨ä¸Šä¸‹æ–‡é•¿åº¦çš„ç¨³å®šå›°æƒ‘åº¦ (perplexity)ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥è¯æ˜ RoM èƒ½æœ‰æ•ˆæ‰©å±•æ··åˆè¯­è¨€æ¨¡å‹ï¼Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶æ¯”ç¨ å¯† Mamba æ‰©å±•æ–¹æ¡ˆèŠ‚çœäº†çº¦ 23% çš„ FLOPSã€‚è¯¥ç ”ç©¶ä¸ºé•¿åºåˆ—å»ºæ¨¡æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å…·æ‰©å±•æ€§çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18145v1",
      "published_date": "2025-06-22 19:26:55 UTC",
      "updated_date": "2025-06-22 19:26:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:27.891377+00:00"
    },
    {
      "arxiv_id": "2506.18143v1",
      "title": "AI Harmonizer: Expanding Vocal Expression with a Generative Neurosymbolic Music AI System",
      "title_zh": "AI Harmonizerï¼šåŸºäºç”Ÿæˆå¼ç¥ç»ç¬¦å·éŸ³ä¹äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„äººå£°è¡¨ç°åŠ›æ‹“å±•",
      "authors": [
        "Lancelot Blanchard",
        "Cameron Holt",
        "Joseph A. Paradiso"
      ],
      "abstract": "Vocals harmonizers are powerful tools to help solo vocalists enrich their melodies with harmonically supportive voices. These tools exist in various forms, from commercially available pedals and software to custom-built systems, each employing different methods to generate harmonies. Traditional harmonizers often require users to manually specify a key or tonal center, while others allow pitch selection via an external keyboard-both approaches demanding some degree of musical expertise. The AI Harmonizer introduces a novel approach by autonomously generating musically coherent four-part harmonies without requiring prior harmonic input from the user. By integrating state-of-the-art generative AI techniques for pitch detection and voice modeling with custom-trained symbolic music models, our system arranges any vocal melody into rich choral textures. In this paper, we present our methods, explore potential applications in performance and composition, and discuss future directions for real-time implementations. While our system currently operates offline, we believe it represents a significant step toward AI-assisted vocal performance and expressive musical augmentation. We release our implementation on GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AI Harmonizerï¼Œä¸€ç§ç»“åˆäº†ç”Ÿæˆå¼ AI ä¸ç¥ç»ç¬¦å·(Neurosymbolic)æŠ€æœ¯çš„éŸ³ä¹äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡åˆ›æ–°çš„æ–¹å¼æ‰©å±•äººå£°è¡¨ç°åŠ›ã€‚ä¸ä¼ ç»Ÿéœ€è¦æ‰‹åŠ¨æŒ‡å®šè°ƒæ€§æˆ–ä¾èµ–å¤–éƒ¨é”®ç›˜è¾“å…¥éŸ³é«˜çš„å’Œå£°å™¨(Vocals harmonizers)ä¸åŒï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®äººå£°æ—‹å¾‹è‡ªä¸»ç”Ÿæˆå…·æœ‰éŸ³ä¹è¿è´¯æ€§çš„å››éƒ¨å’Œå£°(Four-part harmonies)ï¼Œæ˜¾è‘—é™ä½äº†å¯¹ç”¨æˆ·éŸ³ä¹ä¸“ä¸šçŸ¥è¯†çš„è¦æ±‚ã€‚é€šè¿‡é›†æˆå…ˆè¿›çš„éŸ³é«˜æ£€æµ‹(Pitch detection)ã€å£°éŸ³å»ºæ¨¡(Voice modeling)ä»¥åŠè‡ªå®šä¹‰è®­ç»ƒçš„ç¬¦å·éŸ³ä¹æ¨¡å‹(Symbolic music models)ï¼ŒAI Harmonizer å¯ä»¥å°†å•å£°éƒ¨æ—‹å¾‹è½¬åŒ–ä¸ºä¸°å¯Œçš„åˆå”±çº¹ç†(Choral textures)ã€‚å°½ç®¡è¯¥ç³»ç»Ÿç›®å‰å¤„äºç¦»çº¿(Offline)è¿è¡Œé˜¶æ®µï¼Œä½†å®ƒåœ¨äººå·¥æ™ºèƒ½è¾…åŠ©å£°ä¹è¡¨æ¼”å’ŒéŸ³ä¹å¢å¼ºé¢†åŸŸè¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ï¼Œç›¸å…³ä»£ç å·²åœ¨ GitHub å¼€æºã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.HC",
      "comment": "4 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.18143v1",
      "published_date": "2025-06-22 19:13:31 UTC",
      "updated_date": "2025-06-22 19:13:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:35.991377+00:00"
    },
    {
      "arxiv_id": "2506.18141v2",
      "title": "Sparse Feature Coactivation Reveals Causal Semantic Modules in Large Language Models",
      "title_zh": "ç¨€ç–ç‰¹å¾å…±æ¿€æ´»æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹ä¸­çš„å› æœè¯­ä¹‰æ¨¡å—",
      "authors": [
        "Ruixuan Deng",
        "Xiaoyang Hu",
        "Miles Gilberti",
        "Shane Storks",
        "Aman Taxali",
        "Mike Angstadt",
        "Chandra Sripada",
        "Joyce Chai"
      ],
      "abstract": "We identify semantically coherent, context-consistent network components in large language models (LLMs) using coactivation of sparse autoencoder (SAE) features collected from just a handful of prompts. Focusing on concept-relation prediction tasks, we show that ablating these components for concepts (e.g., countries and words) and relations (e.g., capital city and translation language) changes model outputs in predictable ways, while amplifying these components induces counterfactual responses. Notably, composing relation and concept components yields compound counterfactual outputs. Further analysis reveals that while most concept components emerge from the very first layer, more abstract relation components are concentrated in later layers. Lastly, we show that extracted components more comprehensively capture concepts and relations than individual features while maintaining specificity. Overall, our findings suggest a modular organization of knowledge accessed through compositional operations, and advance methods for efficient, targeted LLM manipulation.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡åˆ†æå°‘é‡æç¤ºè¯ä¸‹çš„ç¨€ç–è‡ªç¼–ç å™¨(Sparse Autoencoder, SAE)ç‰¹å¾å…±æ¿€æ´»(coactivation)ï¼Œè¯†åˆ«å‡ºäº†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­è¯­ä¹‰è¿è´¯ä¸”ä¸Šä¸‹æ–‡ä¸€è‡´çš„ç½‘ç»œç»„ä»¶ã€‚ç ”ç©¶é‡ç‚¹å…³æ³¨æ¦‚å¿µ-å…³ç³»(concept-relation)é¢„æµ‹ä»»åŠ¡ï¼Œé€šè¿‡æ¶ˆè(ablating)æˆ–å¢å¼º(amplifying)ç‰¹å®šç»„ä»¶ï¼Œèƒ½å¤ŸæŒ‰é¢„æœŸæ”¹å˜æ¨¡å‹è¾“å‡ºæˆ–è¯±å‘åäº‹å®å“åº”ã€‚ç‰¹åˆ«åœ°ï¼Œå°†å…³ç³»ç»„ä»¶ä¸æ¦‚å¿µç»„ä»¶è¿›è¡Œç»„åˆ(composing)å¯ä»¥äº§ç”Ÿå¤åˆçš„åäº‹å®è¾“å‡ºã€‚è¿›ä¸€æ­¥åˆ†ææ­ç¤ºï¼Œå¤§å¤šæ•°æ¦‚å¿µç»„ä»¶åœ¨æ¨¡å‹èµ·å§‹å±‚å³å·²æ˜¾ç°ï¼Œè€Œæ›´æŠ½è±¡çš„å…³ç³»ç»„ä»¶åˆ™é›†ä¸­åœ¨è¾ƒæ·±å±‚ã€‚å®éªŒè¡¨æ˜ï¼Œæå–çš„ç»„ä»¶æ¯”å•ä¸ªç‰¹å¾èƒ½æ›´å…¨é¢åœ°æ•æ‰æ¦‚å¿µå’Œå…³ç³»ï¼Œä¸”ä¿æŒäº†æé«˜çš„ç‰¹å¼‚æ€§ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™é¡¹å·¥ä½œæ­ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹çŸ¥è¯†çš„æ¨¡å—åŒ–(modular organization)ç»„ç»‡ç»“æ„ï¼Œå¹¶è¯æ˜äº†å…¶é€šè¿‡ç»„åˆè¿ç®—(compositional operations)å®ç°è®¿é—®çš„ç‰¹æ€§ï¼Œä¸ºé«˜æ•ˆã€é’ˆå¯¹æ€§çš„æ¨¡å‹æ“çºµæä¾›äº†æ–°æ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18141v2",
      "published_date": "2025-06-22 19:01:13 UTC",
      "updated_date": "2025-10-20 18:44:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:28.950529+00:00"
    },
    {
      "arxiv_id": "2506.18135v1",
      "title": "SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging",
      "title_zh": "SE-Mergingï¼šä¸€ç§é¢å‘åŠ¨æ€æ¨¡å‹åˆå¹¶çš„è‡ªå¢å¼ºæ–¹æ³•",
      "authors": [
        "Zijun Chen",
        "Zhanpeng Zhou",
        "Bo Zhang",
        "Weinan Zhang",
        "Xi Sun",
        "Junchi Yan"
      ],
      "abstract": "Model merging has gained increasing attention due to its intriguing property: interpolating the parameters of different task-specific fine-tuned models leads to multi-task abilities. However, despite its empirical success, the underlying mechanisms of model merging remain poorly understood. In this work, we delve into the mechanism behind model merging from a representation perspective. Our analysis reveals that model merging achieves multi-task abilities through two key capabilities: i) distinguishing samples from different tasks, and ii) adapting to the corresponding expert model for each sample. These two capabilities allow the merged model to retain task-specific expertise, enabling efficient multi-task adaptation. Building on these insights, we propose \\texttt{SE-Merging}, a self-enhanced model merging framework that leverages these two characteristics to dynamically identify the corresponding task for each sample and then adaptively rescales the merging coefficients to further enhance task-specific expertise in the merged model. Notably, \\texttt{SE-Merging} achieves dynamic model merging without additional training. Extensive experiments demonstrate that \\texttt{SE-Merging} achieves significant performance improvements while remaining compatible with existing model merging techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»è¡¨ç¤ºè§†è§’æ·±å…¥æ¢è®¨äº†æ¨¡å‹åˆå¹¶(Model merging)çš„åº•å±‚æœºåˆ¶ï¼Œæ­ç¤ºäº†å…¶å¤šä»»åŠ¡èƒ½åŠ›ä¸»è¦æºäºåŒºåˆ†ä¸åŒä»»åŠ¡æ ·æœ¬ä»¥åŠå¯¹ç›¸åº”ä¸“å®¶æ¨¡å‹çš„é€‚åº”èƒ½åŠ›ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œä½œè€…æå‡ºäº†SE-Mergingï¼Œè¿™æ˜¯ä¸€ç§è‡ªå¢å¼ºçš„åŠ¨æ€æ¨¡å‹åˆå¹¶æ¡†æ¶ï¼Œèƒ½å¤Ÿå®æ—¶è¯†åˆ«æ¯ä¸ªæ ·æœ¬æ‰€å±çš„ä»»åŠ¡ã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªé€‚åº”ç¼©æ”¾åˆå¹¶ç³»æ•°(merging coefficients)ï¼Œåœ¨ä¸å¢åŠ é¢å¤–è®­ç»ƒæˆæœ¬çš„å‰æä¸‹ï¼Œè¿›ä¸€æ­¥å¼ºåŒ–äº†åˆå¹¶æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒSE-Mergingåœ¨æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¸ç°æœ‰çš„æ¨¡å‹åˆå¹¶æŠ€æœ¯ä¿æŒè‰¯å¥½çš„å…¼å®¹æ€§ï¼Œä¸ºå®ç°é«˜æ•ˆã€åŠ¨æ€çš„å¤šä»»åŠ¡å­¦ä¹ æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "preprint, accepted at IJCNN2025",
      "pdf_url": "https://arxiv.org/pdf/2506.18135v1",
      "published_date": "2025-06-22 18:38:41 UTC",
      "updated_date": "2025-06-22 18:38:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:39.697415+00:00"
    },
    {
      "arxiv_id": "2506.18129v1",
      "title": "$Ï†^{\\infty}$: Clause Purification, Embedding Realignment, and the Total Suppression of the Em Dash in Autoregressive Language Models",
      "title_zh": "$Ï†^{\\infty}$ï¼šè‡ªå›å½’è¯­è¨€æ¨¡å‹ä¸­çš„å­å¥å‡€åŒ–ã€åµŒå…¥é‡å¯¹é½ä¸ç ´æŠ˜å·å½»åº•æŠ‘åˆ¶",
      "authors": [
        "Bugra Kilictas",
        "Faruk Alpay"
      ],
      "abstract": "We identify a critical vulnerability in autoregressive transformer language models where the em dash token induces recursive semantic drift, leading to clause boundary hallucination and embedding space entanglement. Through formal analysis of token-level perturbations in semantic lattices, we demonstrate that em dash insertion fundamentally alters the model's latent representations, causing compounding errors in long-form generation. We propose a novel solution combining symbolic clause purification via the phi-infinity operator with targeted embedding matrix realignment. Our approach enables total suppression of problematic tokens without requiring model retraining, while preserving semantic coherence through fixed-point convergence guarantees. Experimental validation shows significant improvements in generation consistency and topic maintenance. This work establishes a general framework for identifying and mitigating token-level vulnerabilities in foundation models, with immediate implications for AI safety, model alignment, and robust deployment of large language models in production environments. The methodology extends beyond punctuation to address broader classes of recursive instabilities in neural text generation systems.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯†åˆ«äº†è‡ªå›å½’ Transformer è¯­è¨€æ¨¡å‹ä¸­çš„ä¸€ä¸ªå…³é”®æ¼æ´ï¼Œå³ em dash æ ‡è®°ä¼šè¯±å‘é€’å½’è¯­ä¹‰åç§»ï¼Œå¯¼è‡´å­å¥è¾¹ç•Œå¹»è§‰å’ŒåµŒå…¥ç©ºé—´çº ç¼ ã€‚é€šè¿‡å¯¹è¯­ä¹‰ç‚¹é˜µä¸­æ ‡è®°çº§æ‰°åŠ¨çš„æ­£å¼åˆ†æï¼Œä½œè€…è¯æ˜äº† em dash çš„æ’å…¥ä¼šæ ¹æœ¬æ€§åœ°æ”¹å˜æ¨¡å‹çš„æ½œåœ¨è¡¨ç¤ºï¼Œå¹¶åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä¸­å¼•èµ·å¤åˆé”™è¯¯ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆäº†åŸºäº $\\phi^{\\infty}$ ç®—å­çš„ç¬¦å·åŒ–å­å¥å‡€åŒ– (Clause Purification) ä¸å®šå‘åµŒå…¥çŸ©é˜µé‡å¯¹é½ (Embedding Realignment) çš„æ–°é¢–æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•æ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹å³å¯å®ç°å¯¹é—®é¢˜æ ‡è®°çš„å®Œå…¨æŠ‘åˆ¶ï¼Œå¹¶é€šè¿‡ä¸åŠ¨ç‚¹æ”¶æ•›ä¿è¯ (fixed-point convergence guarantees) ç¡®ä¿è¯­ä¹‰è¿è´¯æ€§ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨ç”Ÿæˆä¸€è‡´æ€§ (generation consistency) å’Œä¸»é¢˜ç»´æŒ (topic maintenance) æ–¹é¢æœ‰æ˜¾è‘—æå‡ã€‚è¿™é¡¹å·¥ä½œä¸ºè¯†åˆ«å’Œç¼“è§£åŸºç¡€æ¨¡å‹ä¸­çš„æ ‡è®°çº§æ¼æ´å»ºç«‹äº†é€šç”¨æ¡†æ¶ï¼Œå¯¹ AI safety å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„é²æ£’éƒ¨ç½²å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.18129v1",
      "published_date": "2025-06-22 18:27:39 UTC",
      "updated_date": "2025-06-22 18:27:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:38.093187+00:00"
    },
    {
      "arxiv_id": "2506.18126v1",
      "title": "Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game",
      "title_zh": "é¢å‘å¤šçº¦æŸæ— äººæœºè¿½é€ƒåšå¼ˆçš„åŸºäºå»ä¸­å¿ƒåŒ–å…±è¯†æ¨ç†çš„åˆ†å±‚å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Xiang Yuming",
        "Li Sizhao",
        "Li Rongpeng",
        "Zhao Zhifeng",
        "Zhang Honggang"
      ],
      "abstract": "Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered widespread research interest and fostered tremendous interesting applications, especially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative Evasion and Formation Coverage (CEFC) task, where the UAV swarm aims to maximize formation coverage across multiple target zones while collaboratively evading predators, belongs to one of the most challenging issues in MC-PEG, especially under communication-limited constraints. This multifaceted problem, which intertwines responses to obstacles, adversaries, target zones, and formation dynamics, brings up significant high-dimensional complications in locating a solution. In this paper, we propose a novel two-level framework (i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)), which delegates target localization to a high-level policy, while adopting a low-level policy to manage obstacle avoidance, navigation, and formation. Specifically, in the high-level policy, we develop a novel multi-agent reinforcement learning module, Consensus-oriented Multi-Agent Communication (ConsMAC), to enable agents to perceive global information and establish consensus from local states by effectively aggregating neighbor messages. Meanwhile, we leverage an Alternative Training-based Multi-agent proximal policy optimization (AT-M) and policy distillation to accomplish the low-level control. The experimental results, including the high-fidelity software-in-the-loop (SITL) simulations, validate that CI-HRL provides a superior solution with enhanced swarm's collaborative evasion and task completion capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šçº¦æŸæ— äººæœºè¿½é€ƒåšå¼ˆ(MC-PEG)ä¸­çš„åä½œè§„é¿ä¸ç¼–é˜Ÿè¦†ç›–(CEFC)ä»»åŠ¡ï¼Œè§£å†³äº†é€šä¿¡å—é™ç¯å¢ƒä¸‹å¤šæ— äººæœºé›†ç¾¤é¢ä¸´çš„é«˜ç»´å†³ç­–å¤æ‚æ€§é—®é¢˜ã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºCI-HRLçš„åŸºäºå…±è¯†æ¨ç†çš„åˆ†å±‚å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå°†ä»»åŠ¡è§£è€¦ä¸ºè´Ÿè´£ç›®æ ‡å®šä½çš„é«˜å±‚ç­–ç•¥å’Œæ‰§è¡Œé¿éšœã€å¯¼èˆªä¸ç¼–é˜Ÿæ§åˆ¶çš„ä½å±‚ç­–ç•¥ã€‚åœ¨é«˜å±‚è®¾è®¡ä¸­ï¼Œé€šè¿‡é¢å‘å…±è¯†çš„å¤šæ™ºèƒ½ä½“é€šä¿¡(ConsMAC)æ¨¡å—æœ‰æ•ˆèšåˆé‚»å±…ä¿¡æ¯ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿä»å±€éƒ¨è§‚æµ‹ä¸­æ„å»ºå…¨å±€å…±è¯†ã€‚åœ¨ä½å±‚æ§åˆ¶ä¸­ï¼Œåˆ™åˆ©ç”¨åŸºäºäº¤æ›¿è®­ç»ƒçš„å¤šæ™ºèƒ½ä½“è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(AT-M)å’Œç­–ç•¥è’¸é¦æŠ€æœ¯å®ç°ç²¾ç»†åŒ–ç®¡ç†ã€‚å®éªŒé€šè¿‡é«˜ä¿çœŸè½¯ä»¶åœ¨ç¯(SITL)ä»¿çœŸè¯æ˜ï¼ŒCI-HRLåœ¨æå‡æ— äººæœºé›†ç¾¤çš„åä½œè§„é¿èƒ½åŠ›å’Œä»»åŠ¡å®Œæˆç‡æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä¸ºå¤æ‚çº¦æŸä¸‹çš„è¿½é€ƒåšå¼ˆæä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18126v1",
      "published_date": "2025-06-22 18:23:58 UTC",
      "updated_date": "2025-06-22 18:23:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:52.091243+00:00"
    },
    {
      "arxiv_id": "2506.18119v1",
      "title": "Conceptualization, Operationalization, and Measurement of Machine Companionship: A Scoping Review",
      "title_zh": "æœºå™¨åŒä¼´å…³ç³»çš„æ¦‚å¿µåŒ–ã€æ“ä½œåŒ–ä¸æµ‹é‡ï¼šèŒƒå›´ç»¼è¿°",
      "authors": [
        "Jaime Banks",
        "Zhixin Li"
      ],
      "abstract": "The notion of machine companions has long been embedded in social-technological imaginaries. Recent advances in AI have moved those media musings into believable sociality manifested in interfaces, robotic bodies, and devices. Those machines are often referred to colloquially as \"companions\" yet there is little careful engagement of machine companionship (MC) as a formal concept or measured variable. This PRISMA-guided scoping review systematically samples, surveys, and synthesizes current scholarly works on MC (N = 71; 2017-2025), to that end. Works varied widely in considerations of MC according to guiding theories, dimensions of a-priori specified properties (subjectively positive, sustained over time, co-active, autotelic), and in measured concepts (with more than 50 distinct measured variables). WE ultimately offer a literature-guided definition of MC as an autotelic, coordinated connection between human and machine that unfolds over time and is subjectively positive.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Machine Companionship (MC) è¿™ä¸€æ¦‚å¿µåœ¨å­¦æœ¯ç•Œç¼ºä¹æ­£å¼å®šä¹‰å’Œä¸€è‡´æµ‹é‡æ ‡å‡†çš„é—®é¢˜ï¼Œå¼€å±•äº†ä¸€é¡¹éµå¾ªPRISMAå‡†åˆ™çš„èŒƒå›´ç»¼è¿°(scoping review)ã€‚é€šè¿‡å¯¹2017å¹´è‡³2025å¹´é—´71ç¯‡å­¦æœ¯è‘—ä½œçš„ç³»ç»Ÿæ€§è°ƒæŸ¥ä¸æ•´åˆï¼Œç ”ç©¶å‘ç°ç°æœ‰æ–‡çŒ®åœ¨MCçš„æŒ‡å¯¼ç†è®ºã€ç»´åº¦å±æ€§ï¼ˆå¦‚ä¸»è§‚ç§¯æã€æŒç»­æ€§ã€ååŒæ€§ã€è‡ªæˆç›®çš„æ€§ï¼‰ä»¥åŠæµ‹é‡å˜é‡ä¸Šå­˜åœ¨æå¤§å·®å¼‚ï¼Œæ¶‰åŠè¶…è¿‡50ä¸ªä¸åŒçš„æµ‹é‡æŒ‡æ ‡ã€‚æœ€ç»ˆï¼Œç ”ç©¶æä¾›äº†ä¸€ä¸ªåŸºäºæ–‡çŒ®å¼•å¯¼çš„MCå®šä¹‰ï¼Œå³äººæœºä¹‹é—´ä¸€ç§éšç€æ—¶é—´æ¨ç§»å±•å¼€çš„ã€å…·æœ‰è‡ªæˆç›®çš„æ€§(autotelic)ä¸”åœ¨ä¸»è§‚ä¸Šè¡¨ç°ä¸ºç§¯æçš„åè°ƒè¿æ¥ã€‚è¯¥ç»¼è¿°ä¸ä»…æ¢³ç†äº†å½“å‰MCçš„ç ”ç©¶ç°çŠ¶ï¼Œä¹Ÿä¸ºå°†è¿™ä¸€æ¨¡ç³Šæ¦‚å¿µè½¬åŒ–ä¸ºæ­£å¼çš„å­¦æœ¯å˜é‡å¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18119v1",
      "published_date": "2025-06-22 18:02:18 UTC",
      "updated_date": "2025-06-22 18:02:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:37:31.084900+00:00"
    },
    {
      "arxiv_id": "2506.18116v1",
      "title": "Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¿ƒç†å¥åº·å…¬å¹³æ€§ï¼šåˆ©ç”¨å¤šè·³é—®ç­”æ¢æµ‹è¢«æ”¾å¤§ä¸è¢«å¿½è§†çš„è§†è§’",
      "authors": [
        "Batool Haider",
        "Atmika Gorti",
        "Aman Chadha",
        "Manas Gaur"
      ],
      "abstract": "Large Language Models (LLMs) in mental healthcare risk propagating biases that reinforce stigma and harm marginalized groups. While previous research identified concerning trends, systematic methods for detecting intersectional biases remain limited. This work introduces a multi-hop question answering (MHQA) framework to explore LLM response biases in mental health discourse. We analyze content from the Interpretable Mental Health Instruction (IMHI) dataset across symptom presentation, coping mechanisms, and treatment approaches. Using systematic tagging across age, race, gender, and socioeconomic status, we investigate bias patterns at demographic intersections. We evaluate four LLMs: Claude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic disparities across sentiment, demographics, and mental health conditions. Our MHQA approach demonstrates superior detection compared to conventional methods, identifying amplification points where biases magnify through sequential reasoning. We implement two debiasing techniques: Roleplay Simulation and Explicit Bias Reduction, achieving 66-94% bias reductions through few-shot prompting with BBQ dataset examples. These findings highlight critical areas where LLMs reproduce mental healthcare biases, providing actionable insights for equitable AI development.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¿ƒç†å¥åº·é¢†åŸŸä¸­å¯èƒ½ä¼ æ’­çš„åè§ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹è¾¹ç¼˜åŒ–ç¾¤ä½“çš„æ­§è§†é£é™©ã€‚ä¸ºè§£å†³äº¤å‰æ€§åè§(intersectional biases)æ£€æµ‹æ–¹æ³•æœ‰é™çš„é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§å¤šè·³é—®ç­”(Multi-Hop Question Answering, MHQA)æ¡†æ¶ï¼Œåˆ©ç”¨IMHIæ•°æ®é›†åˆ†ææ¨¡å‹åœ¨ç—‡çŠ¶è¡¨ç°å’Œæ²»ç–—æ–¹æ¡ˆä¸­çš„åè§æ¨¡å¼ã€‚é€šè¿‡å¯¹Claude 3.5 Sonnetã€Jamba 1.6ã€Gemma 3å’ŒLlama 4ç­‰æ¨¡å‹çš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°MHQAåœ¨è¯†åˆ«æ¨ç†åºåˆ—ä¸­åè§æ”¾å¤§çš„â€œæ‰©å¢ç‚¹â€æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶å®æ–½äº†è§’è‰²æ‰®æ¼”æ¨¡æ‹Ÿ(Roleplay Simulation)å’Œæ˜¾å¼åè§å‡å°‘(Explicit Bias Reduction)ä¸¤ç§æŠ€æœ¯ï¼Œåˆ©ç”¨BBQæ•°æ®é›†æˆåŠŸå°†åè§é™ä½äº†66-94%ã€‚è¯¥ç ”ç©¶ä¸ä»…æ­ç¤ºäº†AIåœ¨å¿ƒç†å¥åº·æœåŠ¡ä¸­å¤ç°åè§çš„å…³é”®ç¯èŠ‚ï¼Œä¹Ÿä¸ºå¼€å‘æ›´å…·å…¬å¹³æ€§çš„åŒ»ç–—AIç³»ç»Ÿæä¾›äº†é‡è¦è§è§£å’Œå®è·µæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "19 Pages, 7 Figures, 4 Tables (Note: Under Review)",
      "pdf_url": "https://arxiv.org/pdf/2506.18116v1",
      "published_date": "2025-06-22 18:00:16 UTC",
      "updated_date": "2025-06-22 18:00:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:37:35.091018+00:00"
    },
    {
      "arxiv_id": "2506.18940v1",
      "title": "eccDNAMamba: A Pre-Trained Model for Ultra-Long eccDNA Sequence Analysis",
      "title_zh": "eccDNAMambaï¼šç”¨äºè¶…é•¿eccDNAåºåˆ—åˆ†æçš„é¢„è®­ç»ƒæ¨¡å‹",
      "authors": [
        "Zhenke Liu",
        "Jien Li",
        "Ziqi Zhang"
      ],
      "abstract": "Extrachromosomal circular DNA (eccDNA) plays key regulatory roles and contributes to oncogene overexpression in cancer through high-copy amplification and long-range interactions. Despite advances in modeling, no pre-trained models currently support full-length circular eccDNA for downstream analysis. Existing genomic models are either limited to single-nucleotide resolution or hindered by the inefficiency of the quadratic attention mechanism. Here, we introduce eccDNAMamba, the first bidirectional state-space encoder tailored for circular DNA sequences. It combines forward and reverse passes for full-context representation learning with linear-time complexity, and preserves circular structure through a novel augmentation strategy. Tested on two real-world datasets, eccDNAMamba achieves strong classification performance and scales to sequences up to 200 Kbp, offering a robust and efficient framework for modeling circular genomes. Our codes are available at https://github.com/zzq1zh/GenAI-Lab.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†eccDNAMambaï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ä¸ºç¯çŠ¶DNAåºåˆ—è®¾è®¡çš„åŒå‘çŠ¶æ€ç©ºé—´ç¼–ç å™¨(bidirectional state-space encoder)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºå› ç»„æ¨¡å‹åœ¨å¤„ç†å…¨é•¿æŸ“è‰²ä½“å¤–ç¯çŠ¶DNA (eccDNA) æ—¶é¢ä¸´çš„è®¡ç®—æ•ˆç‡ä½ä¸‹å’Œç¼ºä¹ç¯çŠ¶ç»“æ„æ”¯æŒç­‰é—®é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“åˆæ­£å‘å’Œåå‘ä¼ é€’å®ç°å…¨ä¸Šä¸‹æ–‡è¡¨ç¤ºå­¦ä¹ (full-context representation learning)ï¼Œå…·å¤‡çº¿æ€§æ—¶é—´å¤æ‚åº¦ï¼Œå¹¶åˆ©ç”¨ä¸€ç§æ–°é¢–çš„å¢å¼ºç­–ç•¥æ¥ä¿ç•™ç¯çŠ¶ç»“æ„çš„å®Œæ•´æ€§ã€‚åœ¨ä¸¤ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒeccDNAMambaåœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¸”èƒ½å¤Ÿå¤„ç†é•¿åº¦é«˜è¾¾200 Kbpçš„è¶…é•¿åºåˆ—ã€‚ä½œä¸ºä¸€ç§ç¨³å¥ä¸”é«˜æ•ˆçš„å»ºæ¨¡æ¡†æ¶ï¼ŒeccDNAMambaä¸ºç¯çŠ¶åŸºå› ç»„çš„æ·±å…¥ç ”ç©¶å’Œä¸‹æ¸¸åˆ†ææä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "Accepted by ICML 2025 Generative AI and Biology (GenBio) Workshop",
      "pdf_url": "https://arxiv.org/pdf/2506.18940v1",
      "published_date": "2025-06-22 17:50:57 UTC",
      "updated_date": "2025-06-22 17:50:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:36:57.900530+00:00"
    },
    {
      "arxiv_id": "2507.01039v2",
      "title": "On-Policy Optimization of ANFIS Policies Using Proximal Policy Optimization",
      "title_zh": "åŸºäºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–çš„ ANFIS ç­–ç•¥åŒç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Kaaustaaub Shankar",
        "Wilhelm Louw",
        "Kelly Cohen"
      ],
      "abstract": "We present a reinforcement learning method for training neuro-fuzzy controllers using Proximal Policy Optimization (PPO). Unlike prior approaches that used Deep Q-Networks (DQN) with Adaptive Neuro-Fuzzy Inference Systems (ANFIS), our PPO-based framework leverages a stable on-policy actor-critic setup. Evaluated on the CartPole-v1 environment across multiple seeds, PPO-trained fuzzy agents consistently achieved the maximum return of 500 with zero variance after 20000 updates, outperforming ANFIS-DQN baselines in both stability and convergence speed. This highlights PPO's potential for training explainable neuro-fuzzy agents in reinforcement learning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ Proximal Policy Optimization (PPO) è®­ç»ƒç¥ç»æ¨¡ç³Šæ§åˆ¶å™¨ (neuro-fuzzy controllers) çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ç¨³å®šçš„åœ¨ç­–ç•¥ (on-policy) Actor-Critic æ¶æ„ä¼˜åŒ–è‡ªé€‚åº”ç¥ç»æ¨¡ç³Šæ¨ç†ç³»ç»Ÿ (ANFIS)ã€‚ä¸ä»¥å¾€é‡‡ç”¨ Deep Q-Networks (DQN) çš„æ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶åœ¨ CartPole-v1 ç¯å¢ƒçš„æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œåœ¨ 20000 æ¬¡æ›´æ–°åä¸€è‡´è¾¾åˆ°äº† 500 åˆ†çš„æœ€å¤§å›æŠ¥ä¸”æ–¹å·®ä¸ºé›¶ã€‚å®éªŒå¯¹æ¯”è¯æ˜ï¼ŒåŸºäº PPO çš„è®­ç»ƒæ–¹å¼åœ¨ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ä¸Šå‡æ˜¾è‘—ä¼˜äº ANFIS-DQN åŸºå‡†ã€‚è¿™ä¸€æˆæœå……åˆ†å±•ç¤ºäº† PPO åœ¨æ„å»ºå¯è§£é‡Š (explainable) ç¥ç»æ¨¡ç³Šæ™ºèƒ½ä½“æ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºå¼ºåŒ–å­¦ä¹ ä»»åŠ¡æä¾›äº†æ›´å…·é²æ£’æ€§çš„æ§åˆ¶æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NAFIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.01039v2",
      "published_date": "2025-06-22 17:49:49 UTC",
      "updated_date": "2025-07-04 02:40:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:38:51.587497+00:00"
    },
    {
      "arxiv_id": "2506.18110v1",
      "title": "RL for Reasoning by Adaptively Revealing Rationales",
      "title_zh": "é€šè¿‡è‡ªé€‚åº”æ­ç¤ºæ¨ç†è¿‡ç¨‹å®ç°å¼ºåŒ–å­¦ä¹ æ¨ç†",
      "authors": [
        "Mohammad Hossein Amani",
        "Aryo Lotfi",
        "Nicolas Mario Baldwin",
        "Samy Bengio",
        "Mehrdad Farajtabar",
        "Emmanuel Abbe",
        "Robert West"
      ],
      "abstract": "We propose that reinforcement learning (RL) from partial expert demonstrations is not merely a training heuristic, but a promising framework for solving complex sequence generation tasks. Supervised fine-tuning (SFT) relies on dense ground-truth labels, which become increasingly costly as sequence length grows. RL, on the other hand, struggles with sparse rewards and a combinatorially large output space. We address this by introducing adaptive backtracking (AdaBack), a per-sample curriculum learning algorithm that reveals only a partial prefix of the target output during training. The supervision length is adjusted dynamically for each sample based on the model's past reward signal, allowing it to incrementally learn to complete reasoning chains by conditioning on correct partial solutions. We investigate this intermediate regime between SFT and RL and argue that per-sample curriculum learning is more than a trade-off between efficiency and generality, it can succeed in tasks with long sequences of latent dependencies where SFT and RL both fail to generalize. Using a synthetic task with latent parity constraints, we show that our adaptive curriculum over partial answers reliably solves problems that are otherwise intractable. On mathematical reasoning benchmarks (MATH, GSM8k), we find that curriculum learning enables models to solve problems that RL alone cannot, acquiring new reasoning capabilities through incremental exposure to partial solutions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (RL)åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶é¢ä¸´çš„ç¨€ç–å¥–åŠ±å’Œå¤§è§„æ¨¡è¾“å‡ºç©ºé—´é—®é¢˜ï¼Œä»¥åŠç›‘ç£å¾®è°ƒ(SFT)åœ¨é•¿åºåˆ—ä»»åŠ¡ä¸­çš„é«˜æˆæœ¬æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§å¤„äºä¸¤è€…ä¸­é—´åœ°å¸¦çš„æ–°æ¡†æ¶ã€‚ç ”ç©¶å¼•å…¥äº†åä¸ºAdaBackï¼ˆAdaptive Backtrackingï¼‰çš„æ ·æœ¬çº§è¯¾ç¨‹å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°æ­ç¤ºéƒ¨åˆ†ç›®æ ‡è¾“å‡ºæ¥å¼•å¯¼æ¨¡å‹å­¦ä¹ ã€‚è¯¥æ–¹æ³•æ ¹æ®æ¨¡å‹è¿‡å»çš„å¥–åŠ±ä¿¡å·åŠ¨æ€è°ƒæ•´æ¯ä¸ªæ ·æœ¬çš„ç›‘ç£é•¿åº¦ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨æ­£ç¡®çš„éƒ¨åˆ†è§£åŸºç¡€ä¸Šé€æ­¥å­¦ä¼šè¡¥å…¨å®Œæ•´çš„æ¨ç†é“¾ã€‚ä½œè€…è®¤ä¸ºè¿™ç§è¯¾ç¨‹å­¦ä¹ åœ¨å¤„ç†å…·æœ‰é•¿åºåˆ—æ½œåœ¨ä¾èµ–çš„ä»»åŠ¡æ—¶ï¼Œèƒ½å®ç°SFTå’ŒRLå‡æ— æ³•è¾¾åˆ°çš„æ³›åŒ–æ•ˆæœã€‚åœ¨åˆæˆä»»åŠ¡å’Œæ•°å­¦æ¨ç†åŸºå‡†ï¼ˆMATH, GSM8kï¼‰ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒAdaBackèƒ½å¤Ÿæœ‰æ•ˆè§£å†³çº¯RLéš¾ä»¥å¤„ç†çš„é—®é¢˜ã€‚é€šè¿‡å¢é‡å¼æ¥è§¦éƒ¨åˆ†è§£å†³æ–¹æ¡ˆï¼Œæ¨¡å‹æˆåŠŸä¹ å¾—äº†æ–°çš„æ¨ç†èƒ½åŠ›ï¼Œä¸ºè§£å†³å¤æ‚çš„åºåˆ—ç”Ÿæˆä»»åŠ¡æä¾›äº†å¯é ä¸”é«˜æ•ˆçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.18110v1",
      "published_date": "2025-06-22 17:46:14 UTC",
      "updated_date": "2025-06-22 17:46:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:38:14.985239+00:00"
    },
    {
      "arxiv_id": "2506.18096v2",
      "title": "Deep Research Agents: A Systematic Examination And Roadmap",
      "title_zh": "æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ï¼šç³»ç»Ÿæ€§ç»¼è¿°ä¸è·¯çº¿å›¾",
      "authors": [
        "Yuxuan Huang",
        "Yihang Chen",
        "Haozheng Zhang",
        "Kang Li",
        "Huichi Zhou",
        "Meng Fang",
        "Linyi Yang",
        "Xiaoguang Li",
        "Lifeng Shang",
        "Songcen Xu",
        "Jianye Hao",
        "Kun Shao",
        "Jun Wang"
      ],
      "abstract": "The rapid progress of Large Language Models (LLMs) has given rise to a new category of autonomous AI systems, referred to as Deep Research (DR) agents. These agents are designed to tackle complex, multi-turn informational research tasks by leveraging a combination of dynamic reasoning, adaptive long-horizon planning, multi-hop information retrieval, iterative tool use, and the generation of structured analytical reports. In this paper, we conduct a detailed analysis of the foundational technologies and architectural components that constitute Deep Research agents. We begin by reviewing information acquisition strategies, contrasting API-based retrieval methods with browser-based exploration. We then examine modular tool-use frameworks, including code execution, multimodal input processing, and the integration of Model Context Protocols (MCPs) to support extensibility and ecosystem development. To systematize existing approaches, we propose a taxonomy that differentiates between static and dynamic workflows, and we classify agent architectures based on planning strategies and agent composition, including single-agent and multi-agent configurations. We also provide a critical evaluation of current benchmarks, highlighting key limitations such as restricted access to external knowledge, sequential execution inefficiencies, and misalignment between evaluation metrics and the practical objectives of DR agents. Finally, we outline open challenges and promising directions for future research. A curated and continuously updated repository of DR agent research is available at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“(Deep Research Agents)è¿›è¡Œäº†ç³»ç»Ÿæ€§åˆ†æä¸å±•æœ›ï¼Œæ¢è®¨äº†è¿™ç±»æ—¨åœ¨å¤„ç†å¤æ‚å¤šè½®ä¿¡æ¯ç ”ç©¶ä»»åŠ¡çš„è‡ªä¸»äººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚æ–‡ç« æ·±å…¥å‰–æäº†æ„å»ºDeep Researchæ™ºèƒ½ä½“çš„æ ¸å¿ƒæ¶æ„ï¼Œå¯¹æ¯”äº†åŸºäºAPIå’Œæµè§ˆå™¨çš„ä¿¡æ¯æ£€ç´¢ç­–ç•¥ï¼Œå¹¶è¯¦ç»†è®¨è®ºäº†åŒ…æ‹¬ä»£ç æ‰§è¡Œã€å¤šæ¨¡æ€è¾“å…¥åŠæ¨¡å‹ä¸Šä¸‹æ–‡åè®®(Model Context Protocols)åœ¨å†…çš„æ¨¡å—åŒ–å·¥å…·ä½¿ç”¨æ¡†æ¶ã€‚ä¸ºäº†è§„èŒƒåŒ–ç°æœ‰ç ”ç©¶ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åˆ†ç±»æ³•ï¼Œä»å·¥ä½œæµç±»å‹ï¼ˆé™æ€ä¸åŠ¨æ€ï¼‰ä»¥åŠæ™ºèƒ½ä½“ç»„æˆï¼ˆå•æ™ºèƒ½ä½“ä¸å¤šæ™ºèƒ½ä½“ï¼‰ç­‰å¤šä¸ªç»´åº¦å¯¹ç³»ç»Ÿæ¶æ„è¿›è¡Œäº†åˆ’åˆ†ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ‰¹åˆ¤æ€§åœ°è¯„ä¼°äº†ç°æœ‰åŸºå‡†æµ‹è¯•çš„å±€é™æ€§ï¼Œå¦‚å¤–éƒ¨çŸ¥è¯†è·å–å—é™å’Œè¯„ä¼°æŒ‡æ ‡é”™ä½ç­‰é—®é¢˜ã€‚æœ€åï¼Œè®ºæ–‡æ€»ç»“äº†å½“å‰é¢ä¸´çš„å…¬å¼€æŒ‘æˆ˜ï¼Œå¹¶ä¸ºæœªæ¥ç ”ç©¶æ–¹å‘åˆ¶å®šäº†è·¯çº¿å›¾ï¼Œæ—¨åœ¨ä¿ƒè¿›æ›´å…·æ‰©å±•æ€§å’Œé«˜æ•ˆçš„è‡ªä¸»ç§‘ç ”ç”Ÿæ€ç³»ç»Ÿå»ºè®¾ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18096v2",
      "published_date": "2025-06-22 16:52:48 UTC",
      "updated_date": "2025-09-03 15:32:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:37:57.795430+00:00"
    },
    {
      "arxiv_id": "2506.18095v1",
      "title": "ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation",
      "title_zh": "ShareGPT-4o-Imageï¼šå®ç°å¤šæ¨¡æ€æ¨¡å‹ä¸ GPT-4o çº§å›¾åƒç”Ÿæˆçš„å¯¹é½",
      "authors": [
        "Junying Chen",
        "Zhenyang Cai",
        "Pengcheng Chen",
        "Shunian Chen",
        "Ke Ji",
        "Xidong Wang",
        "Yunjin Yang",
        "Benyou Wang"
      ],
      "abstract": "Recent advances in multimodal generative models have unlocked photorealistic, instruction-aligned image generation, yet leading systems like GPT-4o-Image remain proprietary and inaccessible. To democratize these capabilities, we present ShareGPT-4o-Image, the first dataset comprising 45K text-to-image and 46K text-and-image-to-image data, all synthesized using GPT-4o's image generation capabilities for distilling its advanced image generation abilities. Leveraging this dataset, we develop Janus-4o, a multimodal large language model capable of both text-to-image and text-and-image-to-image generation. Janus-4o not only significantly improves text-to-image generation over its predecessor, Janus-Pro, but also newly supports text-and-image-to-image generation. Notably, it achieves impressive performance in text-and-image-to-image generation from scratch, using only 91K synthetic samples and 6 hours of training on an 8 A800-GPU machine. We hope the release of ShareGPT-4o-Image and Janus-4o will foster open research in photorealistic, instruction-aligned image generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†ShareGPT-4o-Imageï¼Œè¿™æ˜¯é¦–ä¸ªé€šè¿‡è’¸é¦GPT-4oå›¾åƒç”Ÿæˆèƒ½åŠ›æ„å»ºçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼ŒåŒ…å«45Kç»„text-to-imageå’Œ46Kç»„text-and-image-to-imageåˆæˆæ•°æ®ã€‚åŸºäºæ­¤æ•°æ®é›†ï¼Œç ”ç©¶è€…å¼€å‘äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM) Janus-4oï¼Œè¯¥æ¨¡å‹åœ¨æ˜¾è‘—æå‡text-to-imageç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œé¦–æ¬¡å®ç°äº†å¯¹text-and-image-to-imageç”Ÿæˆçš„æœ‰æ•ˆæ”¯æŒã€‚å®éªŒè¡¨æ˜ï¼ŒJanus-4oä»…ä¾é 91Kä¸ªåˆæˆæ ·æœ¬ï¼Œåœ¨8å°A800 GPUä¸Šè®­ç»ƒ6å°æ—¶å³å¯ä»é›¶å¼€å§‹è¾¾åˆ°å‡ºè‰²çš„ç”Ÿæˆæ€§èƒ½ã€‚è¯¥ç ”ç©¶é€šè¿‡ShareGPT-4o-Imageå’ŒJanus-4oçš„å¼€æºï¼Œä¸ºå®ç°é«˜ä¿çœŸ(photorealistic)ä¸”æŒ‡ä»¤å¯¹é½(instruction-aligned)çš„å›¾åƒç”ŸæˆæŠ€æœ¯æä¾›äº†é«˜æ•ˆçš„æ°‘ä¸»åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18095v1",
      "published_date": "2025-06-22 16:51:09 UTC",
      "updated_date": "2025-06-22 16:51:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:38:16.597465+00:00"
    },
    {
      "arxiv_id": "2506.18088v2",
      "title": "RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation",
      "title_zh": "RoboTwin 2.0ï¼šå…·å¤‡å¼ºåŸŸéšæœºåŒ–çš„å¯æ‰©å±•æ•°æ®ç”Ÿæˆå™¨ä¸åŸºå‡†ï¼ŒåŠ©åŠ›é²æ£’çš„åŒè‡‚æœºå™¨äººæ“ä½œ",
      "authors": [
        "Tianxing Chen",
        "Zanxin Chen",
        "Baijun Chen",
        "Zijian Cai",
        "Yibin Liu",
        "Zixuan Li",
        "Qiwei Liang",
        "Xianliang Lin",
        "Yiheng Ge",
        "Zhenyu Gu",
        "Weiliang Deng",
        "Yubin Guo",
        "Tian Nian",
        "Xuanbing Xie",
        "Qiangyu Chen",
        "Kailun Su",
        "Tianling Xu",
        "Guodong Liu",
        "Mengkang Hu",
        "Huan-ang Gao",
        "Kaixuan Wang",
        "Zhixuan Liang",
        "Yusen Qin",
        "Xiaokang Yang",
        "Ping Luo",
        "Yao Mu"
      ],
      "abstract": "Simulation-based data synthesis has emerged as a powerful paradigm for advancing real-world robotic manipulation. Yet existing datasets remain insufficient for robust bimanual manipulation due to (1) the lack of scalable task generation methods and (2) oversimplified simulation environments. We present RoboTwin 2.0, a scalable framework for automated, large-scale generation of diverse and realistic data, together with unified evaluation protocols for dual-arm manipulation. At its core is RoboTwin-OD, an object library of 731 instances across 147 categories with semantic and manipulation-relevant annotations. Building on this, we design an expert data synthesis pipeline that leverages multimodal language models (MLLMs) and simulation-in-the-loop refinement to automatically generate task-level execution code. To improve sim-to-real transfer, RoboTwin 2.0 applies structured domain randomization along five axes: clutter, lighting, background, tabletop height, and language, enhancing data diversity and policy robustness. The framework is instantiated across 50 dual-arm tasks and five robot embodiments. Empirically, it yields a 10.9% gain in code generation success rate. For downstream policy learning, a VLA model trained with synthetic data plus only 10 real demonstrations achieves a 367% relative improvement over the 10-demo baseline, while zero-shot models trained solely on synthetic data obtain a 228% gain. These results highlight the effectiveness of RoboTwin 2.0 in strengthening sim-to-real transfer and robustness to environmental variations. We release the data generator, benchmark, dataset, and code to support scalable research in robust bimanual manipulation. Project Page: https://robotwin-platform.github.io/, Code: https://github.com/robotwin-Platform/robotwin/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒè‡‚æœºå™¨äººæ“ä½œ(Bimanual Robotic Manipulation)ä¸­ç°æœ‰æ•°æ®é›†ç”Ÿæˆæ‰©å±•æ€§ä¸è¶³åŠä»¿çœŸç¯å¢ƒè¿‡äºç®€åŒ–çš„é—®é¢˜ï¼Œæå‡ºäº†RoboTwin 2.0å¯æ‰©å±•æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ„å»ºäº†åŒ…å«147ä¸ªç±»åˆ«ã€731ä¸ªå®ä¾‹çš„RoboTwin-ODç‰©ä½“åº“ï¼Œå¹¶è®¾è®¡äº†ç»“åˆå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹(MLLMs)ä¸å¾ªç¯ä»¿çœŸç»†åŒ–(Simulation-in-the-loop refinement)çš„ä¸“å®¶æ•°æ®åˆæˆæµæ°´çº¿ï¼Œç”¨ä»¥è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡æ‰§è¡Œä»£ç ã€‚é€šè¿‡åœ¨æ‚ä¹±åº¦ã€å…‰ç…§ã€èƒŒæ™¯ç­‰äº”ä¸ªç»´åº¦åº”ç”¨ç»“æ„åŒ–é¢†åŸŸéšæœºåŒ–(Domain Randomization)ï¼ŒRoboTwin 2.0æ˜¾è‘—å¢å¼ºäº†æ•°æ®çš„å¤šæ ·æ€§ä¸ç­–ç•¥çš„Sim-to-realè¿ç§»èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨50é¡¹åŒè‡‚ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šï¼Œä½¿ä»£ç ç”ŸæˆæˆåŠŸç‡æå‡äº†10.9%ï¼Œå¹¶åŠ©åŠ›VLAæ¨¡å‹åœ¨ä»…æœ‰æå°‘é‡çœŸå®æ¼”ç¤ºçš„æƒ…å†µä¸‹å®ç°äº†367%çš„æ€§èƒ½é£è·ƒã€‚è¿™ä¸€æˆæœä¸ºå®ç°é²æ£’çš„åŒè‡‚æœºå™¨äººæ“ä½œæä¾›äº†é«˜æ•ˆçš„æ•°æ®ç”Ÿæˆä¸åŸºå‡†æµ‹è¯•å¹³å°ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page: https://robotwin-platform.github.io/, Code: https://github.com/robotwin-Platform/robotwin, Doc: https://robotwin-platform.github.io/doc/",
      "pdf_url": "https://arxiv.org/pdf/2506.18088v2",
      "published_date": "2025-06-22 16:26:53 UTC",
      "updated_date": "2025-08-27 17:52:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:38:11.296477+00:00"
    },
    {
      "arxiv_id": "2506.18087v1",
      "title": "Federated Learning-Based Data Collaboration Method for Enhancing Edge Cloud AI System Security Using Large Language Models",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å¢å¼ºè¾¹ç¼˜äº‘ AI ç³»ç»Ÿå®‰å…¨æ€§çš„è”é‚¦å­¦ä¹ æ•°æ®åä½œæ–¹æ³•",
      "authors": [
        "Huaiying Luo",
        "Cheng Ji"
      ],
      "abstract": "With the widespread application of edge computing and cloud systems in AI-driven applications, how to maintain efficient performance while ensuring data privacy has become an urgent security issue. This paper proposes a federated learning-based data collaboration method to improve the security of edge cloud AI systems, and use large-scale language models (LLMs) to enhance data privacy protection and system robustness. Based on the existing federated learning framework, this method introduces a secure multi-party computation protocol, which optimizes the data aggregation and encryption process between distributed nodes by using LLM to ensure data privacy and improve system efficiency. By combining advanced adversarial training techniques, the model enhances the resistance of edge cloud AI systems to security threats such as data leakage and model poisoning. Experimental results show that the proposed method is 15% better than the traditional federated learning method in terms of data protection and model robustness.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè”é‚¦å­¦ä¹ (Federated Learning)çš„æ•°æ®åä½œæ–¹æ³•ï¼Œæ—¨åœ¨æå‡è¾¹ç¼˜äº‘(Edge Cloud) AIç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œå¹¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)å¢å¼ºæ•°æ®éšç§ä¿æŠ¤ä¸ç³»ç»Ÿç¨³å¥æ€§ã€‚è¯¥æ–¹æ³•åœ¨ç°æœ‰çš„è”é‚¦å­¦ä¹ æ¡†æ¶åŸºç¡€ä¸Šå¼•å…¥äº†å®‰å…¨å¤šæ–¹è®¡ç®—(Secure Multi-party Computation)åè®®ï¼Œé€šè¿‡åˆ©ç”¨LLMä¼˜åŒ–åˆ†å¸ƒå¼èŠ‚ç‚¹ä¹‹é—´çš„æ•°æ®èšåˆå’ŒåŠ å¯†è¿‡ç¨‹ï¼Œä»è€Œåœ¨ç¡®ä¿æ•°æ®éšç§çš„åŒæ—¶æé«˜ç³»ç»Ÿæ•ˆç‡ã€‚ç»“åˆå…ˆè¿›çš„å¯¹æŠ—æ€§è®­ç»ƒ(Adversarial Training)æŠ€æœ¯ï¼Œè¯¥æ¨¡å‹è¿›ä¸€æ­¥å¢å¼ºäº†è¾¹ç¼˜äº‘AIç³»ç»ŸæŠµå¾¡æ•°æ®æ³„éœ²å’Œæ¨¡å‹æŠ•æ¯’ç­‰å®‰å…¨å¨èƒçš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ•°æ®ä¿æŠ¤å’Œæ¨¡å‹ç¨³å¥æ€§æ–¹é¢æ¯”ä¼ ç»Ÿçš„è”é‚¦å­¦ä¹ æ–¹æ³•æå‡äº†15%ï¼Œä¸ºåœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶è§£å†³AIé©±åŠ¨åº”ç”¨ä¸­çš„éšç§å®‰å…¨é—®é¢˜æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by the 2025 5th International Symposium on Computer Technology and Information Science (ISCTIS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2506.18087v1",
      "published_date": "2025-06-22 16:23:45 UTC",
      "updated_date": "2025-06-22 16:23:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:38:17.790940+00:00"
    },
    {
      "arxiv_id": "2506.18074v1",
      "title": "Distributionally robust minimization in meta-learning for system identification",
      "title_zh": "ç³»ç»Ÿè¾¨è¯†å…ƒå­¦ä¹ ä¸­çš„åˆ†å¸ƒé²æ£’æœ€å°åŒ–",
      "authors": [
        "Matteo Rufolo",
        "Dario Piga",
        "Marco Forgione"
      ],
      "abstract": "Meta learning aims at learning how to solve tasks, and thus it allows to estimate models that can be quickly adapted to new scenarios. This work explores distributionally robust minimization in meta learning for system identification. Standard meta learning approaches optimize the expected loss, overlooking task variability. We use an alternative approach, adopting a distributionally robust optimization paradigm that prioritizes high-loss tasks, enhancing performance in worst-case scenarios. Evaluated on a meta model trained on a class of synthetic dynamical systems and tested in both in-distribution and out-of-distribution settings, the proposed approach allows to reduce failures in safety-critical applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç³»ç»Ÿè¾¨è¯†(System Identification)é¢†åŸŸå°†åˆ†å¸ƒé²æ£’æœ€å°åŒ–(Distributionally Robust Minimization)åº”ç”¨äºå…ƒå­¦ä¹ (Meta-learning)çš„æ–°æ–¹æ³•ã€‚ä¼ ç»Ÿçš„å…ƒå­¦ä¹ æ–¹æ¡ˆä¸»è¦ä¼˜åŒ–æœŸæœ›æŸå¤±ï¼Œå¾€å¾€å®¹æ˜“å¿½ç•¥ä»»åŠ¡é—´çš„å˜å¼‚æ€§ï¼Œè€Œæœ¬å·¥ä½œé‡‡ç”¨äº†åˆ†å¸ƒé²æ£’ä¼˜åŒ–(Distributionally Robust Optimization)èŒƒå¼ï¼Œé€šè¿‡ä¼˜å…ˆå¤„ç†é«˜æŸå¤±ä»»åŠ¡æ¥å¢å¼ºæ¨¡å‹åœ¨æœ€åæƒ…å†µä¸‹çš„è¡¨ç°ã€‚ç ”ç©¶äººå‘˜åœ¨åˆæˆåŠ¨åŠ›ç³»ç»Ÿä¸Šå¯¹è¯¥å…ƒæ¨¡å‹è¿›è¡Œäº†è®­ç»ƒï¼Œå¹¶æ·±å…¥è¯„ä¼°äº†å…¶åœ¨åˆ†å¸ƒå†…(In-distribution)å’Œåˆ†å¸ƒå¤–(Out-of-distribution)è®¾ç½®ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆå‡å°‘å®‰å…¨å…³é”®å‹åº”ç”¨(Safety-critical Applications)ä¸­çš„ç³»ç»Ÿæ•…éšœï¼Œä¸ºæå‡å…ƒå­¦ä¹ æ¨¡å‹åœ¨å¤æ‚å¤šå˜ç¯å¢ƒä¸‹çš„å¯é æ€§æä¾›äº†é‡è¦æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18074v1",
      "published_date": "2025-06-22 15:41:22 UTC",
      "updated_date": "2025-06-22 15:41:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:38:42.893579+00:00"
    },
    {
      "arxiv_id": "2506.18939v3",
      "title": "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction",
      "title_zh": "Damba-STï¼šé¢å‘é«˜æ•ˆåŸå¸‚æ—¶ç©ºé¢„æµ‹çš„é¢†åŸŸè‡ªé€‚åº” Mamba",
      "authors": [
        "Rui An",
        "Yifeng Zhang",
        "Ziran Liang",
        "Wenqi Fan",
        "Yuxuan Liang",
        "Xuequn Shang",
        "Qing Li"
      ],
      "abstract": "Training urban spatio-temporal foundation models that generalize well across diverse regions and cities is critical for deploying urban services in unseen or data-scarce regions. Recent studies have typically focused on fusing cross-domain spatio-temporal data to train unified Transformer-based models. However, these models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment. Inspired by the efficiency of Mamba, a state space model with linear time complexity, we explore its potential for efficient urban spatio-temporal prediction. However, directly applying Mamba as a spatio-temporal backbone leads to negative transfer and severe performance degradation. This is primarily due to spatio-temporal heterogeneity and the recursive mechanism of Mamba's hidden state updates, which limit cross-domain generalization. To overcome these challenges, we propose Damba-ST, a novel domain-adaptive Mamba-based model for efficient urban spatio-temporal prediction. Damba-ST retains Mamba's linear complexity advantage while significantly enhancing its adaptability to heterogeneous domains. Specifically, we introduce two core innovations: (1) a domain-adaptive state space model that partitions the latent representation space into a shared subspace for learning cross-domain commonalities and independent, domain-specific subspaces for capturing intra-domain discriminative features; (2) three distinct Domain Adapters, which serve as domain-aware proxies to bridge disparate domain distributions and facilitate the alignment of cross-domain commonalities. Extensive experiments demonstrate the generalization and efficiency of Damba-ST. It achieves state-of-the-art performance on prediction tasks and demonstrates strong zero-shot generalization, enabling seamless deployment in new urban environments without extensive retraining or fine-tuning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Damba-STï¼Œä¸€ç§æ—¨åœ¨è§£å†³åŸå¸‚æ—¶ç©ºé¢„æµ‹åŸºç¡€æ¨¡å‹åœ¨è·¨åŒºåŸŸæ³›åŒ–æ—¶é¢ä¸´çš„ Transformer æ¶æ„è®¡ç®—å¤æ‚åº¦é«˜ä»¥åŠ Mamba æ¶æ„åœ¨å¼‚æ„æ•°æ®ä¸‹æ€§èƒ½ä¸‹é™é—®é¢˜çš„æ¨¡å‹ã€‚Damba-ST åœ¨ä¿ç•™ Mamba çº¿æ€§æ—¶é—´å¤æ‚åº¦ä¼˜åŠ¿çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†å…¶å¯¹å¼‚æ„é¢†åŸŸçš„é€‚åº”èƒ½åŠ›ã€‚è¯¥æ¨¡å‹æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬å¼•å…¥é¢†åŸŸè‡ªé€‚åº”çŠ¶æ€ç©ºé—´æ¨¡å‹ (Domain-Adaptive State Space Model)ï¼Œå°†æ½œåœ¨è¡¨ç¤ºç©ºé—´åˆ’åˆ†ä¸ºå­¦ä¹ è·¨åŸŸå…±æ€§çš„å…±äº«å­ç©ºé—´å’Œæ•æ‰é¢†åŸŸå†…åˆ¤åˆ«ç‰¹å¾çš„ç‹¬ç«‹å­ç©ºé—´ã€‚åŒæ—¶ï¼Œç ”ç©¶è®¾è®¡äº†ä¸‰ç§é¢†åŸŸé€‚é…å™¨ (Domain Adapters) ä½œä¸ºé¢†åŸŸæ„ŸçŸ¥ä»£ç†ï¼Œç”¨äºæ¡¥æ¥ä¸åŒé¢†åŸŸçš„åˆ†å¸ƒå¹¶ä¿ƒè¿›è·¨åŸŸå…±æ€§çš„å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDamba-ST åœ¨é¢„æµ‹ä»»åŠ¡ä¸­è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿› (State-of-the-Art) çš„æ€§èƒ½æ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å±•ç°å‡ºå¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ– (Zero-Shot Generalization) èƒ½åŠ›ï¼Œä½¿å…¶æ— éœ€å¤§è§„æ¨¡é‡è®­ç»ƒæˆ–å¾®è°ƒå³å¯æ— ç¼éƒ¨ç½²äºæ–°çš„åŸå¸‚ç¯å¢ƒï¼Œä¸ºé«˜æ•ˆã€å¯æ‰©å±•çš„åŸå¸‚æ—¶ç©ºé¢„æµ‹æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICDE 2026",
      "pdf_url": "https://arxiv.org/pdf/2506.18939v3",
      "published_date": "2025-06-22 15:40:01 UTC",
      "updated_date": "2026-01-03 16:17:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:38:33.404200+00:00"
    },
    {
      "arxiv_id": "2506.18072v2",
      "title": "Multimodal Medical Image Binding via Shared Text Embeddings",
      "title_zh": "åŸºäºå…±äº«æ–‡æœ¬åµŒå…¥çš„å¤šæ¨¡æ€åŒ»å­¦å›¾åƒç»‘å®š",
      "authors": [
        "Yunhao Liu",
        "Suyang Xi",
        "Shiqi Liu",
        "Hong Ding",
        "Chicheng Jin",
        "Chong Zhong",
        "Junjun He",
        "Catherine C. Liu",
        "Yiqing Shen"
      ],
      "abstract": "Medical image analysis increasingly relies on the integration of multiple imaging modalities to capture complementary anatomical and functional information, enabling more accurate diagnosis and treatment planning. Achieving aligned feature representations across these diverse modalities is therefore important for effective multimodal analysis. While contrastive language-image pre-training (CLIP) and its variant have enabled image-text alignments, they require explicitly paired data between arbitrary two modalities, which is difficult to acquire in medical contexts. To address the gap, we present Multimodal Medical Image Binding with Text (M\\textsuperscript{3}Bind), a novel pre-training framework that enables seamless alignment of multiple medical imaging modalities through a shared text representation space without requiring explicit paired data between any two medical image modalities. Specifically, based on the insight that different images can naturally bind with text, M\\textsuperscript{3}Bind first fine-tunes pre-trained CLIP-like image-text models to align their modality-specific text embedding space while preserving their original image-text alignments. Subsequently, we distill these modality-specific text encoders into a unified model, creating a shared text embedding space. Experiments on X-ray, CT, retina, ECG, and pathological images on multiple downstream tasks demonstrate that M\\textsuperscript{3}Bind achieves state-of-the-art performance in zero-shot, few-shot classification and cross-modal retrieval tasks compared to its CLIP-like counterparts. These results validate M\\textsuperscript{3}Bind's effectiveness in achieving cross-image-modal alignment for medical analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»å­¦é¢†åŸŸéš¾ä»¥è·å–ä¸åŒæˆåƒæ¨¡æ€é—´æ˜¾å¼é…å¯¹æ•°æ®çš„é—®é¢˜ï¼Œæå‡ºäº† $M^3Bind$ï¼ˆMultimodal Medical Image Binding with Textï¼‰é¢„è®­ç»ƒæ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¸åŒå½±åƒæ¨¡æ€å‡å¯ä¸æ–‡æœ¬è‡ªç„¶ç»‘å®šçš„ç‰¹æ€§ï¼Œé€šè¿‡å…±äº«æ–‡æœ¬è¡¨ç¤ºç©ºé—´å®ç°äº†å¤šç§åŒ»å­¦å½±åƒçš„æ— ç¼å¯¹é½ï¼Œæ— éœ€æ¨¡æ€é—´çš„ç›´æ¥é…å¯¹ã€‚å…·ä½“è€Œè¨€ï¼Œ$M^3Bind$ é¦–å…ˆå¾®è°ƒç±» CLIP æ¨¡å‹ä»¥ç»Ÿä¸€æ¨¡æ€ç‰¹å®šçš„æ–‡æœ¬åµŒå…¥ç©ºé—´ï¼Œéšåé€šè¿‡çŸ¥è¯†è’¸é¦æ„å»ºç»Ÿä¸€çš„æ–‡æœ¬ç¼–ç å™¨ã€‚åœ¨ X-rayã€CTã€è§†ç½‘è†œå›¾åƒã€ECG å’Œç—…ç†å›¾åƒä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ Zero-shotã€Few-shot åˆ†ç±»åŠ Cross-modal retrieval ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº† State-of-the-art æ°´å¹³ã€‚è¿™äº›ç»“æœå……åˆ†éªŒè¯äº† $M^3Bind$ åœ¨ä¸ä¾èµ–å½±åƒå¯¹æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå®ç°åŒ»å­¦å¤šæ¨¡æ€ç‰¹å¾å¯¹é½çš„æœ‰æ•ˆæ€§ï¼Œä¸ºä¸´åºŠè¯Šæ–­å’Œæ²»ç–—è§„åˆ’æä¾›äº†æ›´ç²¾å‡†çš„åˆ†æå·¥å…·ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.18072v2",
      "published_date": "2025-06-22 15:39:25 UTC",
      "updated_date": "2025-09-03 16:04:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:09.785992+00:00"
    },
    {
      "arxiv_id": "2506.18071v2",
      "title": "MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering",
      "title_zh": "MUPAï¼šé¢å‘å®šä½è§†é¢‘é—®ç­”çš„å¤šè·¯å¾„æ™ºèƒ½ä½“æ¨ç†",
      "authors": [
        "Jisheng Dang",
        "Huilin Song",
        "Junbin Xiao",
        "Bimei Wang",
        "Han Peng",
        "Haoxuan Li",
        "Xun Yang",
        "Meng Wang",
        "Tat-Seng Chua"
      ],
      "abstract": "Grounded Video Question Answering (Grounded VideoQA) requires aligning textual answers with explicit visual evidence. However, modern multimodal models often rely on linguistic priors and spurious correlations, resulting in poorly grounded predictions. In this work, we propose MUPA, a cooperative MUlti-Path Agentic approach that unifies video grounding, question answering, answer reflection and aggregation to tackle Grounded VideoQA. MUPA features three distinct reasoning paths on the interplay of grounding and QA agents in different chronological orders, along with a dedicated reflection agent to judge and aggregate the multi-path results to accomplish consistent QA and grounding. This design markedly improves grounding fidelity without sacrificing answer accuracy. Despite using only 2B parameters, our method outperforms all 7B-scale competitors. When scaled to 7B parameters, MUPA establishes new state-of-the-art results, with Acc@GQA of 30.3% and 47.4% on NExT-GQA and DeVE-QA respectively, demonstrating MUPA' effectiveness towards trustworthy video-language understanding. Our code is available in https://github.com/longmalongma/MUPA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Grounded Video Question Answering (Grounded VideoQA) ä¸­å¤šæ¨¡æ€æ¨¡å‹è¿‡åº¦ä¾èµ–è¯­è¨€å…ˆéªŒå’Œè™šå‡å…³è”å¯¼è‡´å®šä½ä¸å‡†çš„é—®é¢˜ï¼Œæå‡ºäº† MUPA æ¡†æ¶ã€‚MUPA æ˜¯ä¸€ç§åä½œå¼çš„å¤šè·¯å¾„æ™ºèƒ½ä½“æ–¹æ³•ï¼Œå°† video groundingã€question answeringã€answer reflection å’Œ aggregation ç»Ÿä¸€èµ·æ¥ã€‚è¯¥æ¡†æ¶è®¾è®¡äº†ä¸‰ç§åŸºäºä¸åŒæ—¶é—´é¡ºåºçš„æ¨ç†è·¯å¾„ï¼Œç”¨ä»¥åè°ƒ grounding æ™ºèƒ½ä½“å’Œ QA æ™ºèƒ½ä½“ä¹‹é—´çš„äº¤äº’ã€‚åŒæ—¶ï¼Œå¼•å…¥äº†ä¸“é—¨çš„ reflection agent æ¥è¯„ä¼°å’Œæ±‡æ€»å¤šè·¯å¾„ç»“æœï¼Œä»¥ç¡®ä¿ QA å’Œ grounding çš„ä¸€è‡´æ€§ã€‚è¿™ç§è®¾è®¡åœ¨ä¸ç‰ºç‰²ç­”æ¡ˆå‡†ç¡®æ€§çš„å‰æä¸‹æ˜¾è‘—æé«˜äº†å®šä½çš„ä¿çœŸåº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿ä»…æœ‰ 2B å‚æ•°ï¼ŒMUPA çš„è¡¨ç°ä¹Ÿè¶…è¿‡äº†æ‰€æœ‰ 7B è§„æ¨¡çš„ç«äº‰å¯¹æ‰‹ã€‚å½“æ‰©å±•è‡³ 7B å‚æ•°æ—¶ï¼ŒMUPA åœ¨ NExT-GQA å’Œ DeVE-QA æ•°æ®é›†ä¸Šå‡åˆ›ä¸‹äº†æ–°çš„ SOTA è®°å½•ï¼ŒAcc@GQA åˆ†åˆ«è¾¾åˆ° 30.3% å’Œ 47.4%ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°å¯ä¿¡çš„è§†é¢‘è¯­è¨€ç†è§£æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18071v2",
      "published_date": "2025-06-22 15:39:02 UTC",
      "updated_date": "2025-06-27 06:32:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:38:44.499214+00:00"
    },
    {
      "arxiv_id": "2506.18056v1",
      "title": "Weighted Assumption Based Argumentation to reason about ethical principles and actions",
      "title_zh": "é’ˆå¯¹ä¼¦ç†åŸåˆ™ä¸è¡Œä¸ºæ¨ç†çš„åŠ æƒåŸºäºå‡è®¾çš„è®ºè¯",
      "authors": [
        "Paolo Baldi",
        "Fabio Aurelio D'Asaro",
        "Abeer Dyoub",
        "Francesca Alessandra Lisi"
      ],
      "abstract": "We augment Assumption Based Argumentation (ABA for short) with weighted argumentation. In a nutshell, we assign weights to arguments and then derive the weight of attacks between ABA arguments. We illustrate our proposal through running examples in the field of ethical reasoning, and present an implementation based on Answer Set Programming.",
      "tldr_zh": "è¯¥ç ”ç©¶å°†åŠ æƒè®ºè¯ (Weighted Argumentation) å¼•å…¥åˆ°åŸºäºå‡è®¾çš„è®ºè¯ (Assumption Based Argumentation, ABA) æ¡†æ¶ä¸­ï¼Œæå‡ºäº†åŠ æƒ ABA æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡ä¸ºè®ºç‚¹åˆ†é…æƒé‡ï¼Œå¹¶æ®æ­¤æ¨å¯¼å‡º ABA è®ºç‚¹ä¹‹é—´æ”»å‡» (attacks) çš„æƒé‡ï¼Œå®ç°äº†åœ¨è®ºè¯è¿‡ç¨‹ä¸­å¯¹å†²çªå¼ºåº¦çš„é‡åŒ–åˆ†æã€‚ä½œè€…åˆ©ç”¨ä¼¦ç†æ¨ç† (ethical reasoning) é¢†åŸŸçš„å¤šä¸ªè¿è¡Œç¤ºä¾‹å±•ç¤ºäº†è¯¥æ–¹æ¡ˆçš„åº”ç”¨ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚ä¼¦ç†åŸåˆ™å’Œè¡ŒåŠ¨é€‰æ‹©æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æä¾›äº†ä¸€ç§åŸºäºå›ç­”é›†ç¼–ç¨‹ (Answer Set Programming, ASP) çš„å…·ä½“ç®—æ³•å®ç°ï¼Œç¡®ä¿äº†ç†è®ºæ¡†æ¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯æ“ä½œæ€§ã€‚è¿™ä¸€æˆæœä¸ºåœ¨ç»“æ„åŒ–è®ºè¯ä¸­æ•´åˆåå¥½å’Œå¼ºåº¦ä¿¡æ¯æä¾›äº†æ–°é€”å¾„ï¼Œå¢å¼ºäº†é€»è¾‘æ¨ç†ç³»ç»Ÿåœ¨å¤„ç†è§„èŒƒæ€§é—®é¢˜æ—¶çš„è¡¨è¾¾èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18056v1",
      "published_date": "2025-06-22 14:46:42 UTC",
      "updated_date": "2025-06-22 14:46:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:25.994709+00:00"
    },
    {
      "arxiv_id": "2506.18053v1",
      "title": "Mechanistic Interpretability in the Presence of Architectural Obfuscation",
      "title_zh": "æ¶æ„æ··æ·†ä¸‹çš„æœºç†å¯è§£é‡Šæ€§",
      "authors": [
        "Marcos Florencio",
        "Thomas Barton"
      ],
      "abstract": "Architectural obfuscation - e.g., permuting hidden-state tensors, linearly transforming embedding tables, or remapping tokens - has recently gained traction as a lightweight substitute for heavyweight cryptography in privacy-preserving large-language-model (LLM) inference. While recent work has shown that these techniques can be broken under dedicated reconstruction attacks, their impact on mechanistic interpretability has not been systematically studied. In particular, it remains unclear whether scrambling a network's internal representations truly thwarts efforts to understand how the model works, or simply relocates the same circuits to an unfamiliar coordinate system. We address this gap by analyzing a GPT-2-small model trained from scratch with a representative obfuscation map. Assuming the obfuscation map is private and the original basis is hidden (mirroring an honest-but-curious server), we apply logit-lens attribution, causal path-patching, and attention-head ablation to locate and manipulate known circuits. Our findings reveal that obfuscation dramatically alters activation patterns within attention heads yet preserves the layer-wise computational graph. This disconnect hampers reverse-engineering of user prompts: causal traces lose their alignment with baseline semantics, and token-level logit attributions become too noisy to reconstruct. At the same time, feed-forward and residual pathways remain functionally intact, suggesting that obfuscation degrades fine-grained interpretability without compromising top-level task performance. These results establish quantitative evidence that architectural obfuscation can simultaneously (i) retain global model behaviour and (ii) impede mechanistic analyses of user-specific content. By mapping where interpretability breaks down, our study provides guidance for future privacy defences and for robustness-aware interpretability tooling.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å­˜åœ¨ Architectural Obfuscation çš„æƒ…å†µä¸‹ï¼Œå¤§è¯­è¨€æ¨¡å‹çš„ Mechanistic Interpretability å—åˆ°çš„å…·ä½“å½±å“ã€‚ç ”ç©¶è€…é€šè¿‡å¯¹ä¸€ä¸ªåº”ç”¨äº†ä»£è¡¨æ€§æ··æ·†æ˜ å°„çš„ GPT-2-small æ¨¡å‹è¿›è¡Œåˆ†æï¼Œå¹¶è¿ç”¨ logit-lens attributionã€causal path-patching åŠ attention-head ablation ç­‰æŠ€æœ¯å¯¹å·²çŸ¥ç”µè·¯è¿›è¡Œå®šä½å’Œæ“ä½œã€‚ç ”ç©¶å‘ç°ï¼Œæ··æ·†è™½ç„¶æ˜¾è‘—æ”¹å˜äº†æ³¨æ„åŠ›å¤´å†…çš„æ¿€æ´»æ¨¡å¼ï¼Œä½†ä¾ç„¶ä¿ç•™äº†æ¨¡å‹å±‚çº§çš„è®¡ç®—å›¾ç»“æ„ã€‚è¿™ç§ç‰¹æ€§æœ‰æ•ˆé˜»ç¢äº†å¯¹ç”¨æˆ·æç¤ºè¯çš„åå‘å·¥ç¨‹ï¼Œå¯¼è‡´å› æœè¿½è¸ªä¸åŸºå‡†è¯­ä¹‰å¤±å»å¯¹é½ï¼Œä¸” token çº§åˆ«çš„ logit å½’å› å› å™ªå£°è¿‡å¤§è€Œå¤±æ•ˆã€‚å®éªŒç»“æœè¯æ˜ï¼Œæ··æ·†æŠ€æœ¯èƒ½å¤Ÿåœ¨ä¸æŸå®³æ¨¡å‹å…¨å±€è¡Œä¸ºå’Œé¡¶å±‚ä»»åŠ¡æ€§èƒ½çš„å‰æä¸‹ï¼Œæœ‰æ•ˆå±è”½é’ˆå¯¹ç‰¹å®šç”¨æˆ·å†…å®¹çš„æœºæ¢°å¼åˆ†æã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥å¼€å‘å…¼é¡¾éšç§ä¿æŠ¤ä¸é²æ£’æ€§çš„å¯è§£é‡Šæ€§åˆ†æå·¥å…·æä¾›äº†å®šé‡çš„å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18053v1",
      "published_date": "2025-06-22 14:39:16 UTC",
      "updated_date": "2025-06-22 14:39:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:30.785132+00:00"
    },
    {
      "arxiv_id": "2506.18045v1",
      "title": "The Democratic Paradox in Large Language Models' Underestimation of Press Freedom",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä½ä¼°æ–°é—»è‡ªç”±ä¸­çš„æ°‘ä¸»æ‚–è®º",
      "authors": [
        "I. Loaiza",
        "R. Vestrelli",
        "A. Fronzetti Colladon",
        "R. Rigobon"
      ],
      "abstract": "As Large Language Models (LLMs) increasingly mediate global information access for millions of users worldwide, their alignment and biases have the potential to shape public understanding and trust in fundamental democratic institutions, such as press freedom. In this study, we uncover three systematic distortions in the way six popular LLMs evaluate press freedom in 180 countries compared to expert assessments of the World Press Freedom Index (WPFI). The six LLMs exhibit a negative misalignment, consistently underestimating press freedom, with individual models rating between 71% to 93% of countries as less free. We also identify a paradoxical pattern we term differential misalignment: LLMs disproportionately underestimate press freedom in countries where it is strongest. Additionally, five of the six LLMs exhibit positive home bias, rating their home countries' press freedoms more favorably than would be expected given their negative misalignment with the human benchmark. In some cases, LLMs rate their home countries between 7% to 260% more positively than expected. If LLMs are set to become the next search engines and some of the most important cultural tools of our time, they must ensure accurate representations of the state of our human and civic rights globally.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å…­ç§ä¸»æµ Large Language Models (LLMs) åœ¨è¡¡é‡å…¨çƒ 180 ä¸ªå›½å®¶æ–°é—»è‡ªç”±åº¦æ—¶ä¸ä¸“å®¶åŸºå‡† World Press Freedom Index (WPFI) ä¹‹é—´çš„å·®å¼‚ã€‚ç ”ç©¶å‘ç° LLMs æ™®éå­˜åœ¨è´Ÿå‘å¤±è°ƒ (negative misalignment)ï¼Œç³»ç»Ÿæ€§åœ°ä½ä¼°äº†å„å›½çš„æ–°é—»è‡ªç”±æ°´å¹³ï¼Œä¸”æœ‰ 71% åˆ° 93% çš„å›½å®¶è¯„åˆ†ä½äºä¸“å®¶æŒ‡æ ‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯†åˆ«å‡ºä¸€ç§è¢«ç§°ä¸ºå·®å¼‚æ€§å¤±è°ƒ (differential misalignment) çš„â€œæ°‘ä¸»æ‚–è®ºâ€æ¨¡å¼ï¼Œå³ LLMs åœ¨æ–°é—»è‡ªç”±åº¦æœ€å¼ºçš„å›½å®¶åè€Œè¡¨ç°å‡ºæœ€ä¸¥é‡çš„ä½ä¼°ã€‚å¤šæ•°æ¨¡å‹è¿˜è¡¨ç°å‡ºæ˜¾è‘—çš„æ­£å‘å®¶ä¹¡åè§ (positive home bias)ï¼Œå¯¹å…¶æ¯å›½æ–°é—»è‡ªç”±çš„è¯„ä»·è¿œé«˜äºåŸºäºæ•´ä½“åå·®çš„é¢„æœŸã€‚è¿™äº›å‘ç°å¼ºè°ƒäº† LLMs ä½œä¸ºæœªæ¥æ ¸å¿ƒä¿¡æ¯åª’ä»‹ï¼Œå¿…é¡»ç¡®ä¿å…¶å¯¹å…¨çƒäººæƒå’Œå…¬æ°‘æƒåˆ©çŠ¶å†µè¡¨è¿°çš„å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18045v1",
      "published_date": "2025-06-22 14:10:16 UTC",
      "updated_date": "2025-06-22 14:10:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:35.289909+00:00"
    },
    {
      "arxiv_id": "2506.18044v1",
      "title": "Action Language BC+",
      "title_zh": "åŠ¨ä½œè¯­è¨€ BC+",
      "authors": [
        "Joseph Babb",
        "Joohyung Lee"
      ],
      "abstract": "Action languages are formal models of parts of natural language that are designed to describe effects of actions. Many of these languages can be viewed as high level notations of answer set programs structured to represent transition systems. However, the form of answer set programs considered in the earlier work is quite limited in comparison with the modern Answer Set Programming (ASP) language, which allows several useful constructs for knowledge representation, such as choice rules, aggregates, and abstract constraint atoms. We propose a new action language called BC+, which closes the gap between action languages and the modern ASP language. The main idea is to define the semantics of BC+ in terms of general stable model semantics for propositional formulas, under which many modern ASP language constructs can be identified with shorthands for propositional formulas. Language BC+ turns out to be sufficiently expressive to encompass the best features of other action languages, such as languages B, C, C+, and BC. Computational methods available in ASP solvers are readily applicable to compute BC+, which led to an implementation of the language by extending system cplus2asp.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† BC+ï¼Œä¸€ç§å…¨æ–°çš„åŠ¨ä½œè¯­è¨€ (Action Language)ï¼Œæ—¨åœ¨å¼¥åˆåŠ¨ä½œè¯­è¨€ä¸ç°ä»£å›ç­”é›†ç¼–ç¨‹ (Answer Set Programming, ASP) ä¹‹é—´çš„å·®è·ã€‚ç”±äºä¼ ç»Ÿçš„åŠ¨ä½œè¯­è¨€åœ¨çŸ¥è¯†è¡¨ç¤ºä¸Šç¼ºä¹ç°ä»£ ASP ä¸­çš„é€‰æ‹©è§„åˆ™ (choice rules)ã€èšåˆ (aggregates) å’ŒæŠ½è±¡çº¦æŸåŸå­ (abstract constraint atoms) ç­‰æœ‰ç”¨ç»“æ„ï¼ŒBC+ é€šè¿‡åŸºäºå‘½é¢˜å…¬å¼çš„é€šç”¨ç¨³å®šæ¨¡å‹è¯­ä¹‰ (general stable model semantics) å®šä¹‰è¯­ä¹‰ï¼Œå°†è¿™äº›æ„é€ è½¬åŒ–ä¸ºå‘½é¢˜å…¬å¼çš„ç®€å†™ã€‚è¿™ç§è®¾è®¡ä½¿ BC+ å…·å¤‡äº†æå¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼Œèƒ½å¤Ÿèåˆ Bã€Cã€C+ å’Œ BC ç­‰å¤šç§åŠ¨ä½œè¯­è¨€çš„ä¼˜åŠ¿ç‰¹æ€§ã€‚æ­¤å¤–ï¼Œç”±äº ASP æ±‚è§£å™¨çš„è®¡ç®—æ–¹æ³•å¯ä»¥ç›´æ¥åº”ç”¨äº BC+ï¼Œä½œè€…é€šè¿‡æ‰©å±• `cplus2asp` ç³»ç»Ÿå®ç°äº†è¯¥è¯­è¨€ï¼Œä¸ºæè¿°å¤æ‚çš„è½¬æ¢ç³»ç»Ÿ (transition systems) æä¾›äº†æ›´å¼ºå¤§çš„å½¢å¼åŒ–å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Journal of Logic and Computation, 2015",
      "pdf_url": "https://arxiv.org/pdf/2506.18044v1",
      "published_date": "2025-06-22 14:09:49 UTC",
      "updated_date": "2025-06-22 14:09:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:36.391587+00:00"
    },
    {
      "arxiv_id": "2506.18037v1",
      "title": "Pathwise Explanation of ReLU Neural Networks",
      "title_zh": "ReLU ç¥ç»ç½‘ç»œçš„è·¯å¾„å¼è§£é‡Š",
      "authors": [
        "Seongwoo Lim",
        "Won Jo",
        "Joohyung Lee",
        "Jaesik Choi"
      ],
      "abstract": "Neural networks have demonstrated a wide range of successes, but their ``black box\" nature raises concerns about transparency and reliability. Previous research on ReLU networks has sought to unwrap these networks into linear models based on activation states of all hidden units. In this paper, we introduce a novel approach that considers subsets of the hidden units involved in the decision making path. This pathwise explanation provides a clearer and more consistent understanding of the relationship between the input and the decision-making process. Our method also offers flexibility in adjusting the range of explanations within the input, i.e., from an overall attribution input to particular components within the input. Furthermore, it allows for the decomposition of explanations for a given input for more detailed explanations. Experiments demonstrate that our method outperforms others both quantitatively and qualitatively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ ReLU Neural Networks çš„â€œé»‘ç›’â€ç‰¹æ€§å¯¼è‡´çš„é€æ˜åº¦ä¸å¯é æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…¨æ–°çš„ Pathwise Explanation æ–¹æ³•ã€‚ä¸åŒäºä»¥å¾€å°†ç½‘ç»œæ•´ä½“åˆ†è§£ä¸ºåŸºäºæ‰€æœ‰éšè—å•å…ƒæ¿€æ´»çŠ¶æ€çš„çº¿æ€§æ¨¡å‹ï¼Œè¯¥æ–¹æ³•ä¸“æ³¨äºåˆ†æå‚ä¸å†³ç­–è·¯å¾„çš„ç‰¹å®šéšè—å•å…ƒå­é›†ã€‚è¿™ç§è·¯å¾„è§£é‡Šèƒ½å¤Ÿæ›´æ¸…æ™°ä¸”ä¸€è‡´åœ°æ­ç¤ºè¾“å…¥æ•°æ®ä¸å†³ç­–è¿‡ç¨‹ä¹‹é—´çš„å†…åœ¨é€»è¾‘è”ç³»ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚è¯¥æ–¹æ³•è¿˜å…·å¤‡æé«˜çš„çµæ´»æ€§ï¼Œå…è®¸æ ¹æ®éœ€æ±‚è°ƒæ•´è§£é‡ŠèŒƒå›´ï¼Œå®ç°ä»æ•´ä½“å½’å› åˆ°ç‰¹å®šè¾“å…¥ç»„ä»¶çš„ç²¾å‡†è¦†ç›–ã€‚æ­¤å¤–ï¼ŒPathwise Explanation æ”¯æŒå¯¹è§£é‡Šç»“æœè¿›è¡Œè¿›ä¸€æ­¥åˆ†è§£ï¼Œä»¥è·å–æ›´ä¸ºè¯¦å°½çš„å±€éƒ¨ç»†èŠ‚ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šé‡æŒ‡æ ‡å’Œå®šæ€§è¯„ä¼°æ–¹é¢å‡ä¼˜äºç°æœ‰çš„è§£é‡ŠæŠ€æœ¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, PMLR 238:4645-4653, 2024",
      "pdf_url": "https://arxiv.org/pdf/2506.18037v1",
      "published_date": "2025-06-22 13:41:42 UTC",
      "updated_date": "2025-06-22 13:41:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:37.083942+00:00"
    },
    {
      "arxiv_id": "2506.18034v1",
      "title": "Pre-Trained LLM is a Semantic-Aware and Generalizable Segmentation Booster",
      "title_zh": "é¢„è®­ç»ƒ LLMï¼šå…·æœ‰è¯­ä¹‰æ„ŸçŸ¥ä¸æ³›åŒ–èƒ½åŠ›çš„åˆ†å‰²å¢å¼ºå™¨",
      "authors": [
        "Fenghe Tang",
        "Wenxin Ma",
        "Zhiyang He",
        "Xiaodong Tao",
        "Zihang Jiang",
        "S. Kevin Zhou"
      ],
      "abstract": "With the advancement of Large Language Model (LLM) for natural language processing, this paper presents an intriguing finding: a frozen pre-trained LLM layer can process visual tokens for medical image segmentation tasks. Specifically, we propose a simple hybrid structure that integrates a pre-trained, frozen LLM layer within the CNN encoder-decoder segmentation framework (LLM4Seg). Surprisingly, this design improves segmentation performance with a minimal increase in trainable parameters across various modalities, including ultrasound, dermoscopy, polypscopy, and CT scans. Our in-depth analysis reveals the potential of transferring LLM's semantic awareness to enhance segmentation tasks, offering both improved global understanding and better local modeling capabilities. The improvement proves robust across different LLMs, validated using LLaMA and DeepSeek.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å†»ç»“çš„é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹(LLM)å±‚åœ¨å¤„ç†åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­çš„æ½œåŠ›ï¼Œå¹¶æå‡ºäº†åä¸ºLLM4Segçš„æ··åˆæ¶æ„ã€‚LLM4Segå°†é¢„è®­ç»ƒä¸”å†»ç»“çš„LLMå±‚é›†æˆåˆ°ä¼ ç»Ÿçš„CNNç¼–ç å™¨-è§£ç å™¨åˆ†å‰²æ¡†æ¶ä¸­ï¼Œæ—¨åœ¨åˆ©ç”¨LLMçš„è¯­ä¹‰æ„ŸçŸ¥(Semantic Awareness)èƒ½åŠ›æ¥å¢å¼ºè§†è§‰ç‰¹å¾çš„å¤„ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥è®¾è®¡åœ¨ä»…å¢åŠ æå°‘é‡å¯è®­ç»ƒå‚æ•°çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨è¶…å£°ã€çš®è‚¤é•œã€æ¯è‚‰é•œå’ŒCTæ‰«æç­‰å¤šç§åŒ»å­¦æˆåƒæ¨¡æ€ä¸‹çš„åˆ†å‰²è¡¨ç°ã€‚æ·±å…¥åˆ†æè¿›ä¸€æ­¥æ­ç¤ºï¼Œè¿ç§»LLMçš„è¯­ä¹‰ç†è§£èƒ½åŠ›èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡æ¨¡å‹çš„å…¨å±€ä¸Šä¸‹æ–‡ç†è§£ä¸å±€éƒ¨ç»†èŠ‚å»ºæ¨¡ã€‚è¯¥æ–¹æ³•çš„æ”¹è¿›æ•ˆæœåœ¨LLaMAå’ŒDeepSeekç­‰ä¸åŒLLMåº•åº§ä¸Šå‡å¾—åˆ°äº†éªŒè¯ï¼Œè¯æ˜äº†é¢„è®­ç»ƒLLMä½œä¸ºä¸€ç§é€šç”¨åˆ†å‰²åŠ©æ¨å™¨(Segmentation Booster)çš„å¼ºå¤§é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by MICCAI 2025. Code: https://github.com/FengheTan9/LLM4Seg",
      "pdf_url": "https://arxiv.org/pdf/2506.18034v1",
      "published_date": "2025-06-22 13:34:00 UTC",
      "updated_date": "2025-06-22 13:34:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:42.697073+00:00"
    },
    {
      "arxiv_id": "2506.18023v2",
      "title": "PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding",
      "title_zh": "PP-DocBee2ï¼šåŸºäºé«˜æ•ˆæ•°æ®çš„å¤šæ¨¡æ€æ–‡æ¡£ç†è§£æ”¹è¿›åŸºå‡†",
      "authors": [
        "Kui Huang",
        "Xinrong Chen",
        "Wenyu Lv",
        "Jincheng Liao",
        "Guanzhong Wang",
        "Yi Liu"
      ],
      "abstract": "This report introduces PP-DocBee2, an advanced version of the PP-DocBee, designed to enhance multimodal document understanding. Built on a large multimodal model architecture, PP-DocBee2 addresses the limitations of its predecessor through key technological improvements, including enhanced synthetic data quality, improved visual feature fusion strategy, and optimized inference methodologies. These enhancements yield an $11.4\\%$ performance boost on internal benchmarks for Chinese business documents, and reduce inference latency by $73.0\\%$ to the vanilla version. A key innovation of our work is a data quality optimization strategy for multimodal document tasks. By employing a large-scale multimodal pre-trained model to evaluate data, we apply a novel statistical criterion to filter outliers, ensuring high-quality training data. Inspired by insights into underutilized intermediate features in multimodal models, we enhance the ViT representational capacity by decomposing it into layers and applying a novel feature fusion strategy to improve complex reasoning. The source code and pre-trained model are available at \\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† PP-DocBee2ï¼Œè¿™æ˜¯å¯¹ PP-DocBee çš„è¿›é˜¶å‡çº§ç‰ˆæœ¬ï¼Œæ—¨åœ¨æ˜¾è‘—å¢å¼ºå¤šæ¨¡æ€æ–‡æ¡£ç†è§£(Multimodal Document Understanding)èƒ½åŠ›ã€‚è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ•°æ®è´¨é‡ä¼˜åŒ–ç­–ç•¥ï¼Œé€šè¿‡å¤§è§„æ¨¡å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹å’Œæ–°å‹ç»Ÿè®¡æ ‡å‡†å¯¹æ•°æ®è¿›è¡Œç­›é€‰ï¼Œç¡®ä¿äº†è®­ç»ƒæ•°æ®çš„é«˜è´¨é‡ã€‚åœ¨æ¨¡å‹æ¶æ„æ–¹é¢ï¼Œç ”ç©¶è€…é€šè¿‡åˆ†è§£ ViT å±‚çº§å¹¶åº”ç”¨æ–°å‹ç‰¹å¾èåˆç­–ç•¥(Feature Fusion Strategy)ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„è§†è§‰è¡¨ç¤ºèƒ½åŠ›å’Œå¤æ‚æ¨ç†æ°´å¹³ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä¼˜åŒ–æ¨ç†æ–¹æ³•ï¼Œè¯¥æ¨¡å‹åœ¨ä¸­æ–‡å•†ä¸šæ–‡æ¡£åŸºå‡†æµ‹è¯•ä¸­å®ç°äº† 11.4% çš„æ€§èƒ½æå‡ï¼ŒåŒæ—¶å°†æ¨ç†å»¶è¿Ÿè¾ƒåŸå§‹ç‰ˆæœ¬å¤§å¹…é™ä½äº† 73.0%ã€‚è¯¥å·¥ä½œçš„æºä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹å·²åœ¨ PaddleMIX å¹³å°å¼€æºï¼Œä¸ºå·¥ä¸šçº§æ–‡æ¡£æ™ºèƒ½å¤„ç†æä¾›äº†é«˜æ•ˆä¸”å¼ºå¤§çš„åŸºå‡†æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18023v2",
      "published_date": "2025-06-22 13:06:13 UTC",
      "updated_date": "2025-06-25 02:40:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:50.195097+00:00"
    },
    {
      "arxiv_id": "2506.18019v3",
      "title": "Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities",
      "title_zh": "å›¾ä¸AIæ™ºèƒ½ä½“ï¼šåˆ†ç±»ä½“ç³»ã€ç ”ç©¶è¿›å±•åŠæœªæ¥æœºé‡",
      "authors": [
        "Yuanchen Bei",
        "Weizhi Zhang",
        "Siwen Wang",
        "Weizhi Chen",
        "Sheng Zhou",
        "Hao Chen",
        "Yong Li",
        "Jiajun Bu",
        "Shirui Pan",
        "Yizhou Yu",
        "Irwin King",
        "Fakhri Karray",
        "Philip S. Yu"
      ],
      "abstract": "AI agents have experienced a paradigm shift, from early dominance by reinforcement learning (RL) to the rise of agents powered by large language models (LLMs), and now further advancing towards a synergistic fusion of RL and LLM capabilities. This progression has endowed AI agents with increasingly strong abilities. Despite these advances, to accomplish complex real-world tasks, agents are required to plan and execute effectively, maintain reliable memory, and coordinate smoothly with other agents. Achieving these capabilities involves contending with ever-present intricate information, operations, and interactions. In light of this challenge, data structurization can play a promising role by transforming intricate and disorganized data into well-structured forms that agents can more effectively understand and process. In this context, graphs, with their natural advantage in organizing, managing, and harnessing intricate data relationships, present a powerful data paradigm for structurization to support the capabilities demanded by advanced AI agents. To this end, this survey presents a first systematic review of how graphs can empower AI agents. Specifically, we explore the integration of graph techniques with core agent functionalities, highlight notable applications, and identify prospective avenues for future research. By comprehensively surveying this burgeoning intersection, we hope to inspire the development of next-generation AI agents equipped to tackle increasingly sophisticated challenges with graphs. Related resources are collected and continuously updated for the community in the Github link.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿæ¢è®¨äº†å›¾ (Graphs) ç»“æ„å¦‚ä½•èµ‹èƒ½ AI agentsï¼Œä»¥åº”å¯¹å…¶åœ¨å¤æ‚ç°å®ä»»åŠ¡ä¸­é¢ä¸´çš„è§„åˆ’ã€æ‰§è¡Œã€è®°å¿†å’Œå¤šæ™ºèƒ½ä½“åä½œç­‰æŒ‘æˆ˜ã€‚éšç€æ™ºèƒ½ä½“ä»å¼ºåŒ–å­¦ä¹  (RL) æ¼”è¿›åˆ°å¤§è¯­è¨€æ¨¡å‹ (LLM) é©±åŠ¨åŠä¸¤è€…çš„èåˆï¼Œå¤„ç†å¤æ‚ä¸”æ— åºçš„æ•°æ®å…³ç³»æˆä¸ºæ ¸å¿ƒç“¶é¢ˆã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå›¾ç»“æ„å‡­å€Ÿå…¶åœ¨ç»„ç»‡ã€ç®¡ç†å’Œåˆ©ç”¨å¤æ‚æ•°æ®å…³ç³»æ–¹é¢çš„å¤©ç„¶ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿä¸ºæ™ºèƒ½ä½“æä¾›å¼ºå¤§çš„æ•°æ®ç»“æ„åŒ–èŒƒå¼ã€‚æœ¬æ–‡ä½œä¸ºé¦–ä¸ªç³»ç»Ÿæ€§çš„ç»¼è¿°ï¼Œè¯¦ç»†å›é¡¾äº†å›¾æŠ€æœ¯ä¸æ™ºèƒ½ä½“æ ¸å¿ƒåŠŸèƒ½çš„é›†æˆè·¯å¾„ï¼Œå¹¶æ¢³ç†äº†ç°æœ‰çš„åˆ†ç±»æ³• (Taxonomy) å’Œç ”ç©¶è¿›å±•ã€‚é€šè¿‡å¯¹æ˜¾è‘—åº”ç”¨æ¡ˆä¾‹çš„æ€»ç»“åŠå¯¹æœªæ¥æœºé‡çš„å±•æœ›ï¼Œè¯¥ç»¼è¿°æ—¨åœ¨æ¨åŠ¨èƒ½å¤Ÿåº”å¯¹æ›´é«˜çº§å¤æ‚æŒ‘æˆ˜çš„ä¸‹ä¸€ä»£ AI agents çš„å¼€å‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.18019v3",
      "published_date": "2025-06-22 12:59:12 UTC",
      "updated_date": "2025-07-04 14:29:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:52.784921+00:00"
    },
    {
      "arxiv_id": "2506.18017v1",
      "title": "Auto-Regressive Surface Cutting",
      "title_zh": "è‡ªå›å½’æ›²é¢åˆ‡å‰²",
      "authors": [
        "Yang Li",
        "Victor Cheung",
        "Xinhai Liu",
        "Yuguang Chen",
        "Zhongjin Luo",
        "Biwen Lei",
        "Haohan Weng",
        "Zibo Zhao",
        "Jingwei Huang",
        "Zhuo Chen",
        "Chunchao Guo"
      ],
      "abstract": "Surface cutting is a fundamental task in computer graphics, with applications in UV parameterization, texture mapping, and mesh decomposition. However, existing methods often produce technically valid but overly fragmented atlases that lack semantic coherence. We introduce SeamGPT, an auto-regressive model that generates cutting seams by mimicking professional workflows. Our key technical innovation lies in formulating surface cutting as a next token prediction task: sample point clouds on mesh vertices and edges, encode them as shape conditions, and employ a GPT-style transformer to sequentially predict seam segments with quantized 3D coordinates. Our approach achieves exceptional performance on UV unwrapping benchmarks containing both manifold and non-manifold meshes, including artist-created, and 3D-scanned models. In addition, it enhances existing 3D segmentation tools by providing clean boundaries for part decomposition.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—æœºå›¾å½¢å­¦ä¸­çš„è¡¨é¢åˆ‡å‰²(Surface cutting)ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åä¸ºSeamGPTçš„è‡ªå›å½’æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•ç”Ÿæˆçš„å›¾é›†(atlases)è¿‡äºç¢ç‰‡åŒ–ä¸”ç¼ºä¹è¯­ä¹‰è¿è´¯æ€§çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡æ¨¡ä»¿ä¸“ä¸šå·¥ä½œæµï¼Œåˆ›æ–°æ€§åœ°å°†è¡¨é¢åˆ‡å‰²å»ºæ¨¡ä¸ºä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹(next token prediction)ä»»åŠ¡ã€‚æŠ€æœ¯ä¸Šï¼Œå®ƒåœ¨ç½‘æ ¼é¡¶ç‚¹å’Œè¾¹ç¼˜é‡‡æ ·ç‚¹äº‘å¹¶å°†å…¶ç¼–ç ä¸ºå½¢çŠ¶æ¡ä»¶ï¼Œåˆ©ç”¨ç±»GPTçš„Transformeræ¶æ„é¡ºåºé¢„æµ‹å…·æœ‰é‡åŒ–3Dåæ ‡çš„æ¥ç¼æ®µ(seam segments)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSeamGPTåœ¨åŒ…å«æµå½¢å’Œéæµå½¢ç½‘æ ¼çš„UVå±•å¼€(UV unwrapping)åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è‰ºæœ¯å®¶åˆ›ä½œåŠ3Dæ‰«ææ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¸ºé›¶ä»¶åˆ†è§£æä¾›æ¸…æ™°çš„è¾¹ç•Œï¼Œæ˜¾è‘—å¢å¼ºäº†ç°æœ‰çš„3Dåˆ†å‰²å·¥å…·ï¼Œä¸ºç½‘æ ¼åˆ†è§£å’Œçº¹ç†æ˜ å°„æä¾›äº†æ›´å…·ä¸“ä¸šæ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Tech. report. https://victorcheung12.github.io/seamgpt",
      "pdf_url": "https://arxiv.org/pdf/2506.18017v1",
      "published_date": "2025-06-22 12:53:07 UTC",
      "updated_date": "2025-06-22 12:53:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:55.495065+00:00"
    },
    {
      "arxiv_id": "2506.18016v3",
      "title": "ADA-DPM: A Neural Descriptors-based Adaptive Noise Filtering Strategy for SLAM",
      "title_zh": "ADA-DPMï¼šåŸºäºç¥ç»æè¿°ç¬¦çš„ SLAM è‡ªé€‚åº”å™ªå£°æ»¤æ³¢ç­–ç•¥",
      "authors": [
        "Yongxin Shao",
        "Aihong Tan",
        "Binrui Wang",
        "Yinlian Jin",
        "Licong Guan",
        "Peng Liao"
      ],
      "abstract": "Lidar SLAM plays a significant role in mobile robot navigation and high-definition map construction. However, existing methods often face a trade-off between localization accuracy and system robustness in scenarios with a high proportion of dynamic objects, point cloud distortion, and unstructured environments. To address this issue, we propose a neural descriptors-based adaptive noise filtering strategy for SLAM, named ADA-DPM, which improves the performance of localization and mapping tasks through three key technical innovations. Firstly, to tackle dynamic object interference, we design the Dynamic Segmentation Head to predict and filter out dynamic feature points, eliminating the ego-motion interference caused by dynamic objects. Secondly, to mitigate the impact of noise and unstructured feature points, we propose the Global Importance Scoring Head that adaptively selects high-contribution feature points while suppressing the influence of noise and unstructured feature points. Moreover, we introduce the Cross-Layer Graph Convolution Module (GLI-GCN) to construct multi-scale neighborhood graphs, fusing local structural information across different scales and improving the discriminative power of overlapping features. Finally, experimental validations on multiple public datasets confirm the effectiveness of ADA-DPM.",
      "tldr_zh": "é’ˆå¯¹ Lidar SLAM åœ¨é«˜åŠ¨æ€ç‰©ä½“ã€ç‚¹äº‘ç•¸å˜åŠéç»“æ„åŒ–ç¯å¢ƒä¸­æ‰€é¢ä¸´çš„å®šä½ç²¾åº¦ä¸é²æ£’æ€§æƒè¡¡é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†åä¸º ADA-DPM çš„åŸºäºç¥ç»æè¿°ç¬¦çš„è‡ªé€‚åº”å™ªå£°è¿‡æ»¤ç­–ç•¥ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡è®¾è®¡ Dynamic Segmentation Head é¢„æµ‹å¹¶è¿‡æ»¤åŠ¨æ€ç‰¹å¾ç‚¹ï¼Œæœ‰æ•ˆæ¶ˆé™¤äº†ç”±åŠ¨æ€ç‰©ä½“å¼•èµ·çš„è‡ªæˆ‘è¿åŠ¨å¹²æ‰°ã€‚ä¸ºäº†è¿›ä¸€æ­¥å‡å°å™ªå£°å½±å“ï¼Œç ”ç©¶å¼•å…¥äº† Global Importance Scoring Headï¼Œèƒ½å¤Ÿè‡ªé€‚åº”é€‰æ‹©é«˜è´¡çŒ®ç‰¹å¾ç‚¹å¹¶æŠ‘åˆ¶éç»“æ„åŒ–ç‰¹å¾çš„è´Ÿé¢ä½œç”¨ã€‚æ­¤å¤–ï¼Œæ–¹æ¡ˆä¸­é‡‡ç”¨çš„ Cross-Layer Graph Convolution Module (GLI-GCN) é€šè¿‡æ„å»ºå¤šå°ºåº¦é‚»åŸŸå›¾èåˆå±€éƒ¨ç»“æ„ä¿¡æ¯ï¼Œæ˜¾è‘—å¢å¼ºäº†é‡å ç‰¹å¾çš„è¾¨åˆ«èƒ½åŠ›ã€‚å®éªŒç»“æœåœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸ŠéªŒè¯äº† ADA-DPM çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å…¶åœ¨æå‡ç§»åŠ¨æœºå™¨äººå®šä½ä¸å»ºå›¾æ€§èƒ½æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18016v3",
      "published_date": "2025-06-22 12:48:11 UTC",
      "updated_date": "2025-10-20 08:27:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:40:57.487598+00:00"
    },
    {
      "arxiv_id": "2506.18011v1",
      "title": "Probing the Embedding Space of Transformers via Minimal Token Perturbations",
      "title_zh": "åŸºäºæå° Token æ‰°åŠ¨çš„ Transformer åµŒå…¥ç©ºé—´æ¢ç©¶",
      "authors": [
        "Eddie Conti",
        "Alejandro Astruc",
        "Alvaro Parafita",
        "Axel Brando"
      ],
      "abstract": "Understanding how information propagates through Transformer models is a key challenge for interpretability. In this work, we study the effects of minimal token perturbations on the embedding space. In our experiments, we analyze the frequency of which tokens yield to minimal shifts, highlighting that rare tokens usually lead to larger shifts. Moreover, we study how perturbations propagate across layers, demonstrating that input information is increasingly intermixed in deeper layers. Our findings validate the common assumption that the first layers of a model can be used as proxies for model explanations. Overall, this work introduces the combination of token perturbations and shifts on the embedding space as a powerful tool for model interpretability.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šè¿‡æœ€å°æ ‡è®°æ‰°åŠ¨(Minimal Token Perturbations)æ¥æ¢æµ‹ Transformer æ¨¡å‹åµŒå…¥ç©ºé—´(Embedding Space)çš„æ–¹æ³•ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚å®éªŒåˆ†æäº†ä¸åŒé¢‘ç‡çš„æ ‡è®°äº§ç”Ÿä½ç§»çš„è§„å¾‹ï¼Œå‘ç°ç¨€æœ‰æ ‡è®°(Rare Tokens)é€šå¸¸ä¼šå¯¼è‡´æ›´å¤§çš„ä½ç§»ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ¢è®¨äº†æ‰°åŠ¨åœ¨å„å±‚é—´çš„ä¼ æ’­æ–¹å¼ï¼Œè¯æ˜äº†è¾“å…¥ä¿¡æ¯åœ¨æ¨¡å‹æ›´æ·±å±‚ä¸­ä¼šæ—¥ç›Šæ··åˆã€‚è¿™äº›å‘ç°éªŒè¯äº†æ¨¡å‹çš„å‰å‡ å±‚å¯ä»¥ä½œä¸ºæ¨¡å‹è§£é‡Š(Model Explanations)ä»£ç†çš„å¸¸è§å‡è®¾ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥å·¥ä½œå°†æ ‡è®°æ‰°åŠ¨ä¸åµŒå…¥ç©ºé—´ä½ç§»ç›¸ç»“åˆï¼Œä¸ºæ·±å…¥ç†è§£ Transformer çš„å†…éƒ¨æœºåˆ¶æä¾›äº†ä¸€ç§å¼ºæœ‰åŠ›çš„å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "IJCAI 2025 Workshop on Explainable Artificial Intelligence",
      "pdf_url": "https://arxiv.org/pdf/2506.18011v1",
      "published_date": "2025-06-22 12:22:56 UTC",
      "updated_date": "2025-06-22 12:22:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:13.793054+00:00"
    },
    {
      "arxiv_id": "2506.21615v1",
      "title": "Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines",
      "title_zh": "åŸºäºç”Ÿæˆå¢å¼ºæ£€ç´¢ä¸ä¸´åºŠå®è·µæŒ‡å—çš„åŒ»ç–—è¯Šæ–­ä¼˜åŒ–",
      "authors": [
        "Wenhao Li",
        "Hongkuan Zhang",
        "Hongwei Zhang",
        "Zhengxu Li",
        "Zengjie Dong",
        "Yafan Chen",
        "Niranjan Bidargaddi",
        "Hong Liu"
      ],
      "abstract": "Current medical language models, adapted from large language models (LLMs), typically predict ICD code-based diagnosis from electronic health records (EHRs) because these labels are readily available. However, ICD codes do not capture the nuanced, context-rich reasoning clinicians use for diagnosis. Clinicians synthesize diverse patient data and reference clinical practice guidelines (CPGs) to make evidence-based decisions. This misalignment limits the clinical utility of existing models. We introduce GARMLE-G, a Generation-Augmented Retrieval framework that grounds medical language model outputs in authoritative CPGs. Unlike conventional Retrieval-Augmented Generation based approaches, GARMLE-G enables hallucination-free outputs by directly retrieving authoritative guideline content without relying on model-generated text. It (1) integrates LLM predictions with EHR data to create semantically rich queries, (2) retrieves relevant CPG knowledge snippets via embedding similarity, and (3) fuses guideline content with model output to generate clinically aligned recommendations. A prototype system for hypertension diagnosis was developed and evaluated on multiple metrics, demonstrating superior retrieval precision, semantic relevance, and clinical guideline adherence compared to RAG-based baselines, while maintaining a lightweight architecture suitable for localized healthcare deployment. This work provides a scalable, low-cost, and hallucination-free method for grounding medical language models in evidence-based clinical practice, with strong potential for broader clinical deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† GARMLE-Gï¼Œä¸€ç§ç”Ÿæˆå¢å¼ºæ£€ç´¢ï¼ˆGeneration-Augmented Retrievalï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨å°†åŒ»å­¦è¯­è¨€æ¨¡å‹çš„è¾“å‡ºä¸æƒå¨çš„ä¸´åºŠå®è·µæŒ‡å—ï¼ˆClinical Practice Guidelines, CPGsï¼‰æ·±åº¦å¯¹é½ã€‚é’ˆå¯¹ç°æœ‰æ¨¡å‹è¿‡åº¦ä¾èµ– ICD codes å¯¼è‡´ç¼ºä¹ä¸´åºŠæ¨ç†ç»†èŠ‚ï¼Œä»¥åŠä¼ ç»Ÿ RAG æ–¹æ³•ä»å¯èƒ½äº§ç”Ÿå¹»è§‰ï¼ˆhallucinationï¼‰çš„é—®é¢˜ï¼ŒGARMLE-G é€šè¿‡æ•´åˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢„æµ‹ä¸ç”µå­å¥åº·æ¡£æ¡ˆï¼ˆEHRsï¼‰æ•°æ®æ¥æ„å»ºè¯­ä¹‰ä¸°å¯Œçš„æŸ¥è¯¢ã€‚è¯¥æ¡†æ¶åˆ©ç”¨åµŒå…¥ç›¸ä¼¼åº¦ç›´æ¥æ£€ç´¢ CPG çŸ¥è¯†ç‰‡æ®µå¹¶å°†å…¶ä¸æ¨¡å‹è¾“å‡ºèåˆï¼Œç¡®ä¿ç”Ÿæˆçš„å»ºè®®ä¸¥æ ¼éµå¾ªå¾ªè¯åŒ»å­¦å‡†åˆ™ã€‚åœ¨é’ˆå¯¹é«˜è¡€å‹è¯Šæ–­çš„è¯„ä¼°ä¸­ï¼ŒGARMLE-G åœ¨æ£€ç´¢ç²¾åº¦ã€è¯­ä¹‰ç›¸å…³æ€§å’ŒæŒ‡å—éµå¾ªåº¦æ–¹é¢å‡æ˜¾è‘—ä¼˜äºåŸºäº RAG çš„åŸºçº¿æ¨¡å‹ã€‚è¯¥ç³»ç»Ÿå…·å¤‡è½»é‡åŒ–æ¶æ„ï¼Œä¸ºåŒ»ç–—æœºæ„æä¾›äº†ä¸€ç§ä½æˆæœ¬ã€å¯æ‰©å±•ä¸”æ— å¹»è§‰çš„ä¸´åºŠå†³ç­–æ”¯æŒæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.21615v1",
      "published_date": "2025-06-22 11:31:13 UTC",
      "updated_date": "2025-06-22 11:31:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:20.491584+00:00"
    },
    {
      "arxiv_id": "2507.01971v1",
      "title": "DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification",
      "title_zh": "DeepSuppï¼šåŸºäºæ³¨æ„åŠ›é©±åŠ¨ç›¸å…³æ€§æ¨¡å¼åˆ†æçš„åŠ¨æ€æ—¶é—´åºåˆ—æ”¯æ’‘ä½ä¸é˜»åŠ›ä½è¯†åˆ«",
      "authors": [
        "Boris Kriuk",
        "Logic Ng",
        "Zarif Al Hossain"
      ],
      "abstract": "Support and resistance (SR) levels are central to technical analysis, guiding traders in entry, exit, and risk management. Despite widespread use, traditional SR identification methods often fail to adapt to the complexities of modern, volatile markets. Recent research has introduced machine learning techniques to address the following challenges, yet most focus on price prediction rather than structural level identification. This paper presents DeepSupp, a new deep learning approach for detecting financial support levels using multi-head attention mechanisms to analyze spatial correlations and market microstructure relationships. DeepSupp integrates advanced feature engineering, constructing dynamic correlation matrices that capture evolving market relationships, and employs an attention-based autoencoder for robust representation learning. The final support levels are extracted through unsupervised clustering, leveraging DBSCAN to identify significant price thresholds. Comprehensive evaluations on S&P 500 tickers demonstrate that DeepSupp outperforms six baseline methods, achieving state-of-the-art performance across six financial metrics, including essential support accuracy and market regime sensitivity. With consistent results across diverse market conditions, DeepSupp addresses critical gaps in SR level detection, offering a scalable and reliable solution for modern financial analysis. Our approach highlights the potential of attention-based architectures to uncover nuanced market patterns and improve technical trading strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DeepSuppï¼Œä¸€ç§ç”¨äºè¯†åˆ«é‡‘èæ”¯æ’‘ä½(Support levels)çš„æ–°å‹æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸæŠ€æœ¯åˆ†ææ–¹æ³•åœ¨ç°ä»£é«˜æ³¢åŠ¨å¸‚åœºä¸­éš¾ä»¥é€‚åº”çš„é—®é¢˜ã€‚DeepSuppåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶(Multi-head Attention)åˆ†æç©ºé—´ç›¸å…³æ€§å’Œå¸‚åœºå¾®è§‚ç»“æ„å…³ç³»ï¼Œå¹¶é›†æˆäº†é«˜çº§ç‰¹å¾å·¥ç¨‹ä»¥æ„å»ºèƒ½å¤Ÿæ•æ‰å¸‚åœºåŠ¨æ€æ¼”å˜çš„åˆ†æçŸ©é˜µã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŸºäºæ³¨æ„åŠ›çš„è‡ªåŠ¨ç¼–ç å™¨(Attention-based Autoencoder)è¿›è¡Œé²æ£’çš„è¡¨å¾å­¦ä¹ ï¼Œå¹¶ç»“åˆDBSCANæ— ç›‘ç£èšç±»ç®—æ³•ä»å¤æ‚æ•°æ®ä¸­æå–æ˜¾è‘—çš„ä»·æ ¼é˜ˆå€¼ã€‚åœ¨S&P 500æˆä»½è‚¡ä¸Šçš„å…¨é¢è¯„ä¼°è¡¨æ˜ï¼ŒDeepSuppåœ¨æ”¯æ’‘ä½å‡†ç¡®ç‡å’Œå¸‚åœºæœºåˆ¶æ•æ„Ÿæ€§ç­‰å…­é¡¹é‡‘èæŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„å…­ç§åŸºå‡†æ–¹æ³•ã€‚è¯¥ç ”ç©¶éªŒè¯äº†æ³¨æ„åŠ›æœºåˆ¶æ¶æ„åœ¨æ­ç¤ºç»†å¾®å¸‚åœºæ¨¡å¼ä»¥åŠæå‡æŠ€æœ¯äº¤æ˜“ç­–ç•¥å¯é æ€§æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "7 pages, 4 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2507.01971v1",
      "published_date": "2025-06-22 11:09:55 UTC",
      "updated_date": "2025-06-22 11:09:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:17.890214+00:00"
    },
    {
      "arxiv_id": "2506.17968v1",
      "title": "h-calibration: Rethinking Classifier Recalibration with Probabilistic Error-Bounded Objective",
      "title_zh": "h-calibrationï¼šåŸºäºæ¦‚ç‡è¯¯å·®æœ‰ç•Œç›®æ ‡çš„åˆ†ç±»å™¨å†æ ¡å‡†é‡æ€",
      "authors": [
        "Wenjian Huang",
        "Guiping Cao",
        "Jiahao Xia",
        "Jingkun Chen",
        "Hao Wang",
        "Jianguo Zhang"
      ],
      "abstract": "Deep neural networks have demonstrated remarkable performance across numerous learning tasks but often suffer from miscalibration, resulting in unreliable probability outputs. This has inspired many recent works on mitigating miscalibration, particularly through post-hoc recalibration methods that aim to obtain calibrated probabilities without sacrificing the classification performance of pre-trained models. In this study, we summarize and categorize previous works into three general strategies: intuitively designed methods, binning-based methods, and methods based on formulations of ideal calibration. Through theoretical and practical analysis, we highlight ten common limitations in previous approaches. To address these limitations, we propose a probabilistic learning framework for calibration called h-calibration, which theoretically constructs an equivalent learning formulation for canonical calibration with boundedness. On this basis, we design a simple yet effective post-hoc calibration algorithm. Our method not only overcomes the ten identified limitations but also achieves markedly better performance than traditional methods, as validated by extensive experiments. We further analyze, both theoretically and experimentally, the relationship and advantages of our learning objective compared to traditional proper scoring rule. In summary, our probabilistic framework derives an approximately equivalent differentiable objective for learning error-bounded calibrated probabilities, elucidating the correspondence and convergence properties of computational statistics with respect to theoretical bounds in canonical calibration. The theoretical effectiveness is verified on standard post-hoc calibration benchmarks by achieving state-of-the-art performance. This research offers valuable reference for learning reliable likelihood in related fields.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œä¸­æ™®éå­˜åœ¨çš„æ ¡å‡†é”™è¯¯(miscalibration)é—®é¢˜ï¼Œé€šè¿‡å¯¹ç°æœ‰åéªŒæ ¡å‡†æ–¹æ³•çš„ç³»ç»Ÿæ€»ç»“ï¼ŒæŒ‡å‡ºäº†å…¶åœ¨ç†è®ºä¸å®è·µä¸­çš„åé¡¹å…±åŒå±€é™ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œä½œè€…æå‡ºäº†åä¸ºh-calibrationçš„æ¦‚ç‡å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨ç†è®ºä¸Šä¸ºå…·æœ‰æœ‰ç•Œæ€§(boundedness)çš„æ­£è§„æ ¡å‡†(canonical calibration)æ„å»ºäº†ç­‰æ•ˆçš„å­¦ä¹ å…¬å¼ã€‚åŸºäºæ­¤æ¡†æ¶ï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ç§ç®€å•ä¸”æœ‰æ•ˆçš„post-hoc calibrationç®—æ³•ï¼Œåœ¨ä¸å½±å“åˆ†ç±»ç²¾åº¦çš„å‰æä¸‹æ˜¾è‘—æå‡äº†æ¦‚ç‡è¾“å‡ºçš„å¯é æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†state-of-the-artçš„æ€§èƒ½ï¼Œå¹¶æˆåŠŸå…‹æœäº†å…ˆå‰æ–¹æ³•çš„å±€é™ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ¨å¯¼å‡ºä¸€ç§ç”¨äºå­¦ä¹ è¯¯å·®æœ‰ç•Œæ ¡å‡†æ¦‚ç‡çš„è¿‘ä¼¼ç­‰æ•ˆå¯å¾®ç›®æ ‡ï¼Œé˜æ˜äº†è®¡ç®—ç»Ÿè®¡ç›¸å¯¹äºç†è®ºç•Œé™çš„æ”¶æ•›ç‰¹æ€§ï¼Œä¸ºå¯é likelihoodè¯„ä¼°åŠç›¸å…³é¢†åŸŸç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "math.PR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17968v1",
      "published_date": "2025-06-22 09:56:44 UTC",
      "updated_date": "2025-06-22 09:56:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:27.343429+00:00"
    },
    {
      "arxiv_id": "2506.17967v2",
      "title": "Adapting Vision-Language Models for Evaluating World Models",
      "title_zh": "é€‚é…è§†è§‰è¯­è¨€æ¨¡å‹ä»¥è¯„ä¼°ä¸–ç•Œæ¨¡å‹",
      "authors": [
        "Mariya Hendriksen",
        "Tabish Rashid",
        "David Bignell",
        "Raluca Georgescu",
        "Abdelhak Lemkhenter",
        "Katja Hofmann",
        "Sam Devlin",
        "Sarah Parisot"
      ],
      "abstract": "World models - generative models that simulate environment dynamics conditioned on past observations and actions - are gaining prominence in planning, simulation, and embodied AI. However, evaluating their rollouts remains a fundamental challenge, requiring fine-grained, temporally grounded assessment of action alignment and semantic consistency - capabilities not captured by existing metrics. Vision-Language Models (VLMs) have shown promise as automatic evaluators of generative content due to their strong multimodal reasoning abilities. Yet, their use in fine-grained, temporally sensitive evaluation tasks remains limited and requires targeted adaptation. We introduce an evaluation protocol targeting two recognition tasks - action recognition and character recognition - each assessed across binary, multiple-choice, and open-ended formats. To support this, we present UNIVERSE (UNIfied Vision-language Evaluator for Rollouts in Simulated Environments), a VLM-based evaluator for video world model rollouts adapted under data and compute constraints. In our extensive experiments totaling over 5,154 GPU-days, we explore full, partial, and parameter-efficient adaptation methods across various task formats, context lengths, sampling methods, and data compositions. The resulting unified evaluator achieves parity with task-specific checkpoints. Human studies across seven diverse environments confirm strong alignment with human judgments, establishing UNIVERSE as a lightweight, adaptable, and semantics-aware evaluator for video world models.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºè¯„ä¼° World models çš„ç”Ÿæˆè¿‡ç¨‹ï¼ˆrolloutsï¼‰é¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œç°æœ‰çš„æŒ‡æ ‡éš¾ä»¥å®ç°å¯¹åŠ¨ä½œå¯¹é½å’Œè¯­ä¹‰ä¸€è‡´æ€§çš„ç»†ç²’åº¦æ—¶é—´æ„ŸçŸ¥è¯„ä¼°ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† UNIVERSE (UNIfied Vision-language Evaluator for Rollouts in Simulated Environments)ï¼Œä¸€ç§åŸºäº Vision-Language Models (VLMs) çš„è§†é¢‘ç”Ÿæˆè¯„ä¼°å™¨ã€‚åœ¨æ•°æ®å’Œç®—åŠ›å—é™çš„æ¡ä»¶ä¸‹ï¼Œç ”ç©¶å›¢é˜Ÿæ¢ç´¢äº†å…¨é‡ã€éƒ¨åˆ†åŠå‚æ•°é«˜æ•ˆé€‚é…ï¼ˆparameter-efficient adaptation methodsï¼‰ç­‰å¤šç§æ–¹æ³•ï¼Œä»¥æ”¯æŒåŠ¨ä½œè¯†åˆ«å’Œè§’è‰²è¯†åˆ«ä»»åŠ¡ã€‚ç»è¿‡è¶…è¿‡ 5154 ä¸ª GPU å¤©çš„å¹¿æ³›å®éªŒï¼ŒUNIVERSE åœ¨å¤šç§ä»»åŠ¡æ ¼å¼å’Œä¸Šä¸‹æ–‡é•¿åº¦ä¸‹è¾¾åˆ°äº†ä¸ç‰¹å®šä»»åŠ¡æ£€æŸ¥ç‚¹ï¼ˆtask-specific checkpointsï¼‰ç›¸å½“çš„æ€§èƒ½ã€‚é’ˆå¯¹ä¸ƒä¸ªä¸åŒç¯å¢ƒçš„äººç±»ç ”ç©¶ç»“æœè¿›ä¸€æ­¥è¯å®ï¼Œè¯¥æ¨¡å‹ä¸äººç±»åˆ¤æ–­é«˜åº¦ä¸€è‡´ã€‚UNIVERSE ä¸ºè§†é¢‘ World models æä¾›äº†ä¸€ä¸ªè½»é‡çº§ã€å¯é€‚é…ä¸”å…·å¤‡è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS LAW 2025 (Oral)",
      "pdf_url": "https://arxiv.org/pdf/2506.17967v2",
      "published_date": "2025-06-22 09:53:28 UTC",
      "updated_date": "2025-11-24 12:37:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:25.657457+00:00"
    },
    {
      "arxiv_id": "2506.17963v1",
      "title": "OmniESI: A unified framework for enzyme-substrate interaction prediction with progressive conditional deep learning",
      "title_zh": "OmniESIï¼šåŸºäºæ¸è¿›å¼æ¡ä»¶æ·±åº¦å­¦ä¹ çš„ç»Ÿä¸€é…¶-åº•ç‰©ç›¸äº’ä½œç”¨é¢„æµ‹æ¡†æ¶",
      "authors": [
        "Zhiwei Nie",
        "Hongyu Zhang",
        "Hao Jiang",
        "Yutian Liu",
        "Xiansong Huang",
        "Fan Xu",
        "Jie Fu",
        "Zhixiang Ren",
        "Yonghong Tian",
        "Wen-Bin Zhang",
        "Jie Chen"
      ],
      "abstract": "Understanding and modeling enzyme-substrate interactions is crucial for catalytic mechanism research, enzyme engineering, and metabolic engineering. Although a large number of predictive methods have emerged, they do not incorporate prior knowledge of enzyme catalysis to rationally modulate general protein-molecule features that are misaligned with catalytic patterns. To address this issue, we introduce a two-stage progressive framework, OmniESI, for enzyme-substrate interaction prediction through conditional deep learning. By decomposing the modeling of enzyme-substrate interactions into a two-stage progressive process, OmniESI incorporates two conditional networks that respectively emphasize enzymatic reaction specificity and crucial catalysis-related interactions, facilitating a gradual feature modulation in the latent space from general protein-molecule domain to catalysis-aware domain. On top of this unified architecture, OmniESI can adapt to a variety of downstream tasks, including enzyme kinetic parameter prediction, enzyme-substrate pairing prediction, enzyme mutational effect prediction, and enzymatic active site annotation. Under the multi-perspective performance evaluation of in-distribution and out-of-distribution settings, OmniESI consistently delivered superior performance than state-of-the-art specialized methods across seven benchmarks. More importantly, the proposed conditional networks were shown to internalize the fundamental patterns of catalytic efficiency while significantly improving prediction performance, with only negligible parameter increases (0.16%), as demonstrated by ablation studies on key components. Overall, OmniESI represents a unified predictive approach for enzyme-substrate interactions, providing an effective tool for catalytic mechanism cracking and enzyme engineering with strong generalization and broad applicability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†OmniESIï¼Œä¸€ä¸ªåŸºäºæ¸è¿›å¼æ¡ä»¶æ·±åº¦å­¦ä¹ (conditional deep learning)çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨ç²¾å‡†é¢„æµ‹é…¶-åº•ç‰©ç›¸äº’ä½œç”¨(enzyme-substrate interaction)ã€‚ä¸ºäº†è§£å†³é€šç”¨è›‹ç™½è´¨-åˆ†å­ç‰¹å¾ä¸å‚¬åŒ–æ¨¡å¼å¤±é…çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä¸¤ä¸ªæ¡ä»¶ç½‘ç»œåˆ†åˆ«å¼ºåŒ–é…¶ä¿ƒååº”ç‰¹å¼‚æ€§å’Œå…³é”®å‚¬åŒ–ç›¸äº’ä½œç”¨ï¼Œå®ç°äº†ç‰¹å¾ç©ºé—´ä»é€šç”¨é¢†åŸŸå‘å‚¬åŒ–æ„ŸçŸ¥é¢†åŸŸçš„é€æ­¥æ¼”åŒ–ã€‚OmniESIå…·æœ‰æå¼ºçš„å¤šä»»åŠ¡é€‚åº”èƒ½åŠ›ï¼Œæ¶µç›–äº†é…¶åŠ¨åŠ›å­¦å‚æ•°(enzyme kinetic parameter)é¢„æµ‹ã€åº•ç‰©é…å¯¹ã€çªå˜æ•ˆåº”é¢„æµ‹åŠæ´»æ€§ä½ç‚¹(active site)æ ‡æ³¨ç­‰å¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚åœ¨ä¸ƒä¸ªåŸºå‡†æµ‹è¯•çš„å®éªŒä¸­ï¼ŒOmniESIåœ¨åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–è®¾ç½®ä¸‹çš„è¡¨ç°å‡ä¸€è‡´ä¼˜äºç°æœ‰çš„SOTAä¸“ä¸šåŒ–æ–¹æ³•ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œè¯¥æ¡†æ¶åœ¨ä»…å¢åŠ 0.16%å‚æ•°é‡çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡äº†é¢„æµ‹æ€§èƒ½ï¼Œå¹¶æˆåŠŸå†…åŒ–äº†å‚¬åŒ–æ•ˆç‡çš„åŸºæœ¬è§„å¾‹ã€‚æ€»çš„æ¥è¯´ï¼ŒOmniESIä¸ºè§£æå‚¬åŒ–æœºåˆ¶å’Œå¼€å±•é…¶å·¥ç¨‹(enzyme engineering)æä¾›äº†ä¸€ä¸ªå…·æœ‰å¼ºæ³›åŒ–æ€§å’Œå¹¿æ³›é€‚ç”¨æ€§çš„é«˜æ•ˆé¢„æµ‹å·¥å…·ã€‚",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17963v1",
      "published_date": "2025-06-22 09:40:40 UTC",
      "updated_date": "2025-06-22 09:40:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:29.369577+00:00"
    },
    {
      "arxiv_id": "2506.17960v2",
      "title": "GeNIE: A Generalizable Navigation System for In-the-Wild Environments",
      "title_zh": "GeNIEï¼šé¢å‘çœŸå®å¤æ‚ç¯å¢ƒçš„å¯æ³›åŒ–å¯¼èˆªç³»ç»Ÿ",
      "authors": [
        "Jiaming Wang",
        "Diwen Liu",
        "Jizhuo Chen",
        "Jiaxuan Da",
        "Nuowen Qian",
        "Tram Minh Man",
        "Harold Soh"
      ],
      "abstract": "Reliable navigation in unstructured, real-world environments remains a significant challenge for embodied agents, especially when operating across diverse terrains, weather conditions, and sensor configurations. In this paper, we introduce GeNIE (Generalizable Navigation System for In-the-Wild Environments), a robust navigation framework designed for global deployment. GeNIE integrates a generalizable traversability prediction model built on SAM2 with a novel path fusion strategy that enhances planning stability in noisy and ambiguous settings. We deployed GeNIE in the Earth Rover Challenge (ERC) at ICRA 2025, where it was evaluated across six countries spanning three continents. GeNIE took first place and achieved 79% of the maximum possible score, outperforming the second-best team by 17%, and completed the entire competition without a single human intervention. These results set a new benchmark for robust, generalizable outdoor robot navigation. We will release the codebase, pretrained model weights, and newly curated datasets to support future research in real-world navigation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GeNIE (Generalizable Navigation System for In-the-Wild Environments)ï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³éç»“æ„åŒ–çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å¯é å¯¼èˆªæŒ‘æˆ˜çš„ç¨³å¥æ¡†æ¶ã€‚GeNIE å°†åŸºäº SAM2 æ„å»ºçš„å¯æ³›åŒ–å¯é€šè¡Œæ€§é¢„æµ‹æ¨¡å‹ (traversability prediction model) ä¸æ–°å‹è·¯å¾„èåˆç­–ç•¥ (path fusion strategy) é›†æˆï¼Œæœ‰æ•ˆæå‡äº†åœ¨å™ªå£°å’Œæ­§ä¹‰ç¯å¢ƒä¸‹çš„è·¯å¾„è§„åˆ’ç¨³å®šæ€§ã€‚è¯¥ç³»ç»Ÿåœ¨ ICRA 2025 çš„åœ°çƒæ¼«æ¸¸è€…æŒ‘æˆ˜èµ› (Earth Rover Challenge, ERC) ä¸­å¾—åˆ°äº†å¹¿æ³›éªŒè¯ï¼Œè·¨è¶Šä¸‰å¤§æ´²çš„å…­ä¸ªå›½å®¶è¿›è¡Œäº†å®åœ°éƒ¨ç½²ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGeNIE ä»¥é¢†å…ˆç¬¬äºŒå 17% çš„æ˜¾è‘—ä¼˜åŠ¿è£è·å† å†›ï¼Œå¹¶åœ¨å…¨ç¨‹æ— äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹å®Œæˆäº†æ¯”èµ›ä»»åŠ¡ã€‚è¿™ä¸€æˆæœä¸ºç¨³å¥ä¸”å¯æ³›åŒ–çš„æˆ·å¤–æœºå™¨äººå¯¼èˆªæ ‘ç«‹äº†æ–°æ ‡æ†ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å°†å‘å¸ƒç›¸å…³çš„ä»£ç åº“ã€é¢„è®­ç»ƒæƒé‡åŠæ•°æ®é›†ä»¥æ¨åŠ¨åç»­ç ”ç©¶ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE Robotics and Automation Letters (RAL), 2025. Jiaming Wang, Diwen Liu, and Jizhuo Chen contributed equally to this work",
      "pdf_url": "https://arxiv.org/pdf/2506.17960v2",
      "published_date": "2025-06-22 09:36:05 UTC",
      "updated_date": "2025-10-18 11:13:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:33.328602+00:00"
    },
    {
      "arxiv_id": "2506.17959v1",
      "title": "medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs",
      "title_zh": "medicX-KGï¼šé¢å‘è¯å‰‚å¸ˆè¯å“ä¿¡æ¯éœ€æ±‚çš„çŸ¥è¯†å›¾è°±",
      "authors": [
        "Lizzy Farrugia",
        "Lilian M. Azzopardi",
        "Jeremy Debattista",
        "Charlie Abela"
      ],
      "abstract": "The role of pharmacists is evolving from medicine dispensing to delivering comprehensive pharmaceutical services within multidisciplinary healthcare teams. Central to this shift is access to accurate, up-to-date medicinal product information supported by robust data integration. Leveraging artificial intelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden relationships and enable data-driven decision-making. This paper presents medicX-KG, a pharmacist-oriented knowledge graph supporting clinical and regulatory decisions. It forms the semantic layer of the broader medicX platform, powering predictive and explainable pharmacy services. medicX-KG integrates data from three sources, including, the British National Formulary (BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's regulatory landscape and combines European Medicines Agency alignment with partial UK supply dependence. The KG tackles the absence of a unified national drug repository, reducing pharmacists' reliance on fragmented sources. Its design was informed by interviews with practicing pharmacists to ensure real-world applicability. We detail the KG's construction, including data extraction, ontology design, and semantic mapping. Evaluation demonstrates that medicX-KG effectively supports queries about drug availability, interactions, adverse reactions, and therapeutic classes. Limitations, including missing detailed dosage encoding and real-time updates, are discussed alongside directions for future enhancements.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†medicX-KGï¼Œè¿™æ˜¯ä¸€ä¸ªé¢å‘è¯å‰‚å¸ˆçš„çŸ¥è¯†å›¾è°±(Knowledge Graph)ï¼Œæ—¨åœ¨é€šè¿‡è¯­ä¹‰æŠ€æœ¯æ•´åˆé›¶æ•£çš„åŒ»è¯ä¿¡æ¯ï¼Œæ”¯æŒä¸´åºŠå’Œç›‘ç®¡å†³ç­–ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†æ¥è‡ªBritish National Formulary (BNF)ã€DrugBankä»¥åŠMalta Medicines Authority (MMA)çš„æ•°æ®ï¼Œæœ‰æ•ˆè§£å†³äº†é©¬è€³ä»–åŒ»è¯å¸‚åœºåœ¨æ¬§ç›Ÿæ ‡å‡†ä¸è‹±å›½ä¾›åº”ä¾èµ–èƒŒæ™¯ä¸‹ç»Ÿä¸€å›½å®¶è¯å“åº“ç¼ºå¤±çš„é—®é¢˜ã€‚åœ¨æ„å»ºè¿‡ç¨‹ä¸­ï¼Œç ”ç©¶å›¢é˜Ÿé€šè¿‡è¯å‰‚å¸ˆè®¿è°ˆç¡®ä¿äº†å…¶å®é™…åº”ç”¨æ€§ï¼Œè¯¦ç»†è®¾è®¡äº†æœ¬ä½“(Ontology)å¹¶æ‰§è¡Œäº†è¯­ä¹‰æ˜ å°„(Semantic Mapping)ï¼Œä½¿å…¶æˆä¸ºmedicXå¹³å°ä¸­èµ‹èƒ½é¢„æµ‹æ€§åŠå¯è§£é‡Šæ€§è¯å­¦æœåŠ¡çš„æ ¸å¿ƒè¯­ä¹‰å±‚ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒmedicX-KGèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒå…³äºè¯ç‰©å¯ç”¨æ€§ã€è¯ç‰©ç›¸äº’ä½œç”¨(Drug Interactions)ã€ä¸è‰¯ååº”(Adverse Reactions)åŠæ²»ç–—ç±»åˆ«(Therapeutic Classes)çš„æŸ¥è¯¢ã€‚è¯¥ç ”ç©¶ä¸ä»…ä¸ºåŒ»ç–—å›¢é˜Ÿæä¾›äº†å¯é çš„æ•°æ®é›†æˆæ–¹æ¡ˆï¼Œè¿˜æŒ‡å‡ºäº†æœªæ¥åœ¨ç»†åŒ–å‰‚é‡ç¼–ç å’Œå®æ—¶æ›´æ–°æ–¹é¢çš„æ”¹è¿›æ–¹å‘ï¼Œä¸ºæ¨åŠ¨è¯å‰‚å¸ˆå‘ç»¼åˆè¯å­¦æœåŠ¡è½¬å‹æä¾›äº†æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17959v1",
      "published_date": "2025-06-22 09:28:48 UTC",
      "updated_date": "2025-06-22 09:28:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:44.146808+00:00"
    },
    {
      "arxiv_id": "2506.17949v1",
      "title": "Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸­åŸºäºæ•£å°„çš„åˆ›æ–°ä¼ æ’­ï¼šé¢å‘å¤šé˜¶æ®µè¿‡ç¨‹è‡ªé€‚åº”",
      "authors": [
        "Hong Su"
      ],
      "abstract": "Large Language Models (LLMs) exhibit strong capabilities in reproducing and extending patterns observed during pretraining but often struggle to generalize novel ideas beyond their original context. This paper addresses the challenge of applying such localized innovations - introduced at a specific stage or component - to other parts of a multi-stage process. We propose a scatter-based innovation expansion model (innovation scatter model) that guides the LLM through a four-step process: (1) identifying the core innovation by comparing the user's input with its surrounding context, (2) generalizing the innovation by removing references to specific stages or components, (3) determining whether the generalized innovation applies to a broader scope beyond the original stage, and (4) systematically applying it to other structurally similar stages using the LLM. This model leverages structural redundancy across stages to improve the applicability of novel ideas. Verification results demonstrate that the innovation scatter model enables LLMs to extend innovations across structurally similar stages, thereby enhancing generalization and reuse.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éš¾ä»¥å°†å±€éƒ¨æ–°é¢–æƒ³æ³•æ¨å¹¿è‡³åŸå§‹è¯­å¢ƒä¹‹å¤–çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ•£å°„çš„åˆ›æ–°æ‰©å±•æ¨¡å‹ï¼ˆinnovation scatter modelï¼‰ã€‚è¯¥æ¨¡å‹é€šè¿‡è¯†åˆ«æ ¸å¿ƒåˆ›æ–°ã€å»é™¤ç‰¹å®šé˜¶æ®µå¼•ç”¨è¿›è¡Œé€šç”¨åŒ–ã€ç¡®å®šé€‚ç”¨èŒƒå›´ä»¥åŠç³»ç»ŸåŒ–åº”ç”¨å››ä¸ªæ­¥éª¤ï¼Œå¼•å¯¼ LLMs åœ¨å¤šé˜¶æ®µè¿‡ç¨‹ä¸­è¿›è¡Œåˆ›æ–°ä¼ æ’­ã€‚é€šè¿‡åˆ©ç”¨ä¸åŒé˜¶æ®µä¹‹é—´çš„ç»“æ„å†—ä½™æ€§ï¼ˆstructural redundancyï¼‰ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†æ–°æƒ³æ³•çš„å¯åº”ç”¨æ€§å’ŒçŸ¥è¯†é‡ç”¨ç‡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œinnovation scatter model èƒ½å¤Ÿä½¿ LLMs æœ‰æ•ˆåœ°å°†åˆ›æ–°æ‰©å±•è‡³ç»“æ„ç›¸ä¼¼çš„é˜¶æ®µï¼Œä»è€Œå¢å¼ºäº†æ¨¡å‹åœ¨å¤æ‚å¤šé˜¶æ®µæµç¨‹ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17949v1",
      "published_date": "2025-06-22 09:02:31 UTC",
      "updated_date": "2025-06-22 09:02:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:45.141897+00:00"
    },
    {
      "arxiv_id": "2506.17941v1",
      "title": "Greedy Selection under Independent Increments: A Toy Model Analysis",
      "title_zh": "ç‹¬ç«‹å¢é‡ä¸‹çš„è´ªå©ªé€‰æ‹©ï¼šç©å…·æ¨¡å‹åˆ†æ",
      "authors": [
        "Huitao Yang"
      ],
      "abstract": "We study an iterative selection problem over N i.i.d. discrete-time stochastic processes with independent increments. At each stage, a fixed number of processes are retained based on their observed values. Under this simple model, we prove that the optimal strategy for selecting the final maximum-value process is to apply greedy selection at each stage. While the result relies on strong independence assumptions, it offers a clean justification for greedy heuristics in multi-stage elimination settings and may serve as a toy example for understanding related algorithms in high-dimensional applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ $N$ ä¸ªå…·æœ‰ independent increments çš„ i.i.d. discrete-time stochastic processes æ¢è®¨äº†è¿­ä»£é€‰æ‹©é—®é¢˜ã€‚åœ¨é€‰æ‹©è¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªé˜¶æ®µä¼šæ ¹æ®è§‚æµ‹å€¼ä¿ç•™å›ºå®šæ•°é‡çš„è¿‡ç¨‹ï¼Œç›®æ ‡æ˜¯é€‰å‡ºæœ€ç»ˆæ•°å€¼æœ€å¤§çš„è¿‡ç¨‹ã€‚ç ”ç©¶è¯æ˜ï¼Œåœ¨è¿™ä¸€ toy model ä¸‹ï¼Œå„é˜¶æ®µé‡‡ç”¨ greedy selection æ˜¯å¯»æ‰¾æœ€ç»ˆæœ€å¤§å€¼è¿‡ç¨‹çš„æœ€ä¼˜ç­–ç•¥ã€‚å°½ç®¡è¯¥ç»“è®ºåŸºäºè¾ƒå¼ºçš„ç‹¬ç«‹æ€§å‡è®¾ï¼Œä½†å®ƒä¸ºå¤šé˜¶æ®µæ·˜æ±°ï¼ˆmulti-stage eliminationï¼‰åœºæ™¯ä¸­å¸¸ç”¨çš„ greedy heuristics æä¾›äº†ç®€æ´çš„ç†è®ºä¾æ®ã€‚è¯¥å·¥ä½œé€šè¿‡æ¸…æ™°çš„æ¨¡å‹åˆ†æï¼Œä¸ºç†è§£é«˜ç»´åº”ç”¨ä¸­çš„ç›¸å…³é€‰æ‹©ç®—æ³•æä¾›äº†åŸºç¡€å‚è€ƒã€‚",
      "categories": [
        "math.PR",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "math.PR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17941v1",
      "published_date": "2025-06-22 08:21:23 UTC",
      "updated_date": "2025-06-22 08:21:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:41:45.816038+00:00"
    },
    {
      "arxiv_id": "2507.02898v1",
      "title": "Particle Swarm Optimization for Quantum Circuit Synthesis: Performance Analysis and Insights",
      "title_zh": "ç”¨äºé‡å­ç”µè·¯åˆæˆçš„ç²’å­ç¾¤ä¼˜åŒ–ï¼šæ€§èƒ½åˆ†æä¸è§è§£",
      "authors": [
        "Mirza Hizriyan Nubli Hidayat",
        "Tan Chye Cheah"
      ],
      "abstract": "This paper discusses how particle swarm optimization (PSO) can be used to generate quantum circuits to solve an instance of the MaxOne problem. It then analyzes previous studies on evolutionary algorithms for circuit synthesis. With a brief introduction to PSO, including its parameters and algorithm flow, the paper focuses on a method of quantum circuit encoding and representation as PSO parameters. The fitness evaluation used in this paper is the MaxOne problem. The paper presents experimental results that compare different learning abilities and inertia weight variations in the PSO algorithm. A comparison is further made between the PSO algorithm and a genetic algorithm for quantum circuit synthesis. The results suggest PSO converges more quickly to the optimal solution.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨ç²’å­ç¾¤ä¼˜åŒ–(Particle Swarm Optimization, PSO)ç”Ÿæˆé‡å­ç”µè·¯ä»¥è§£å†³MaxOneé—®é¢˜ï¼Œå¹¶æ·±å…¥åˆ†æäº†è¿›åŒ–ç®—æ³•åœ¨ç”µè·¯åˆæˆä¸­çš„åº”ç”¨ã€‚æ–‡ç« é‡ç‚¹ä»‹ç»äº†ä¸€ç§å°†é‡å­ç”µè·¯ç¼–ç å¹¶è¡¨ç¤ºä¸ºPSOå‚æ•°çš„æ–¹æ³•ï¼Œå¹¶é‡‡ç”¨MaxOneé—®é¢˜è¿›è¡Œé€‚åº”åº¦è¯„ä»·ã€‚ç ”ç©¶é€šè¿‡å®éªŒå¯¹æ¯”äº†PSOç®—æ³•ä¸­ä¸åŒå­¦ä¹ èƒ½åŠ›å’Œæƒ¯æ€§æƒé‡(inertia weight)å˜ä½“çš„è¡¨ç°ï¼Œå¹¶è¿›ä¸€æ­¥å°†PSOä¸é—ä¼ ç®—æ³•(Genetic Algorithm)è¿›è¡Œäº†æ€§èƒ½å¯¹æ¯”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨é‡å­ç”µè·¯åˆæˆä»»åŠ¡ä¸­ï¼ŒPSOç®—æ³•æ¯”é—ä¼ ç®—æ³•èƒ½æ›´å¿«åœ°æ”¶æ•›è‡³æœ€ä¼˜è§£ã€‚è¯¥ç ”ç©¶ä¸ºé‡å­ç”µè·¯åˆæˆæä¾›äº†æœ‰æ•ˆçš„å¯å‘å¼æœç´¢ç­–ç•¥ï¼Œå¹¶ä¸ºå…¶æ€§èƒ½ä¼˜åŒ–æä¾›äº†æ·±å…¥çš„åˆ†æä¸è§è§£ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.02898v1",
      "published_date": "2025-06-22 08:21:22 UTC",
      "updated_date": "2025-06-22 08:21:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:00.294006+00:00"
    },
    {
      "arxiv_id": "2506.17940v2",
      "title": "An entropy-optimal path to humble AI",
      "title_zh": "å®ç°è°¦é€Šäººå·¥æ™ºèƒ½çš„ç†µæœ€ä¼˜è·¯å¾„",
      "authors": [
        "Davide Bassetti",
        "LukÃ¡Å¡ PospÃ­Å¡il",
        "Michael Groom",
        "Terence J. O'Kane",
        "Illia Horenko"
      ],
      "abstract": "Progress of AI has led to very successful, but by no means humble models and tools, especially regarding (i) the huge and further exploding costs and resources they demand, and (ii) the over-confidence of these tools with the answers they provide. Here we introduce a novel mathematical framework for a non-equilibrium entropy-optimizing reformulation of Boltzmann machines based on the exact law of total probability and the exact convex polytope representations. We show that it results in the highly-performant, but much cheaper, gradient-descent-free learning framework with mathematically-justified existence and uniqueness criteria, and cheaply-computable confidence/reliability measures for both the model inputs and the outputs. Comparisons to state-of-the-art AI tools in terms of performance, cost and the model descriptor lengths on a broad set of synthetic and real-world problems with varying complexity reveal that the proposed method results in more performant and slim models, with the descriptor lengths being very close to the intrinsic complexity scaling bounds for the underlying problems. Applying this framework to historical climate data results in models with systematically higher prediction skills for the onsets of important La NiÃ±a and El NiÃ±o climate phenomena, requiring just few years of climate data for training - a small fraction of what is necessary for contemporary climate prediction tools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰AIæ¨¡å‹åœ¨èµ„æºæ¶ˆè€—è¿‡é«˜å’Œè¾“å‡ºè¿‡åº¦è‡ªä¿¡æ–¹é¢çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºâ€œè°¦é€ŠAIâ€(Humble AI)çš„ç†µä¼˜åŒ–è·¯å¾„æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å…¨æ¦‚ç‡å…¬å¼(Law of Total Probability)å’Œç²¾ç¡®å‡¸å¤šèƒå½¢è¡¨ç¤º(Convex Polytope Representations)ï¼Œå¯¹ç»å°”å…¹æ›¼æœº(Boltzmann Machines)è¿›è¡Œäº†éå¹³è¡¡æ€ç†µä¼˜åŒ–çš„æ•°å­¦é‡æ„ã€‚è¿™ç§æ–¹æ³•å®ç°äº†æ— æ¢¯åº¦ä¸‹é™(Gradient-descent-free)çš„å­¦ä¹ æœºåˆ¶ï¼Œä¸ä»…å…·å¤‡æ•°å­¦è¯æ˜çš„è§£çš„å”¯ä¸€æ€§å‡†åˆ™ï¼Œè¿˜èƒ½ä»¥æä½æˆæœ¬æä¾›è¾“å…¥è¾“å‡ºçš„ç½®ä¿¡åº¦åº¦é‡ã€‚å®éªŒå¯¹æ¯”è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„æ¨¡å‹åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶æ›´åŠ ç²¾ç®€ï¼Œå…¶æè¿°ç¬¦é•¿åº¦(Descriptor Lengths)æ¥è¿‘é—®é¢˜çš„å†…åœ¨å¤æ‚åº¦ç•Œé™ã€‚åœ¨å†å²æ°”å€™æ•°æ®çš„åº”ç”¨ä¸­ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æå‡äº†å¯¹La NiÃ±aå’ŒEl NiÃ±oç°è±¡çš„é¢„æµ‹èƒ½åŠ›ï¼Œä¸”è®­ç»ƒæ‰€éœ€çš„æ•°æ®é‡ä»…ä¸ºä¼ ç»Ÿæ°”å€™é¢„æµ‹å·¥å…·çš„ä¸€å°éƒ¨åˆ†ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "39 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.17940v2",
      "published_date": "2025-06-22 08:13:22 UTC",
      "updated_date": "2025-09-25 09:18:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:06.988932+00:00"
    },
    {
      "arxiv_id": "2506.17939v2",
      "title": "GEMeX-RMCoT: An Enhanced Med-VQA Dataset for Region-Aware Multimodal Chain-of-Thought Reasoning",
      "title_zh": "GEMeX-RMCoTï¼šé¢å‘åŒºåŸŸæ„ŸçŸ¥å¤šæ¨¡æ€æ€ç»´é“¾æ¨ç†çš„å¢å¼ºå‹åŒ»å­¦è§†è§‰é—®ç­”æ•°æ®é›†",
      "authors": [
        "Bo Liu",
        "Xiangyu Zhao",
        "Along He",
        "Yidi Chen",
        "Huazhu Fu",
        "Xiao-Ming Wu"
      ],
      "abstract": "Medical visual question answering aims to support clinical decision-making by enabling models to answer natural language questions based on medical images. While recent advances in multi-modal learning have significantly improved performance, current methods still suffer from limited answer reliability and poor interpretability, impairing the ability of clinicians and patients to understand and trust model outputs. To address these limitations, this work first proposes a Region-Aware Multimodal Chain-of-Thought (RMCoT) dataset, in which the process of producing an answer is preceded by a sequence of intermediate reasoning steps that explicitly ground relevant visual regions of the medical image, thereby providing fine-grained explainability. Furthermore, we introduce a novel verifiable reward mechanism for reinforcement learning to guide post-training, improving the alignment between the model's reasoning process and its final answer. Remarkably, our method achieves comparable performance using only one-eighth of the training data, demonstrating the efficiency and effectiveness of the proposal. The dataset is available at https://www.med-vqa.com/GEMeX/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»å­¦è§†è§‰é—®ç­”(Medical Visual Question Answering)ä¸­æ¨¡å‹å¯é æ€§ä¸è¶³å’Œå¯è§£é‡Šæ€§å·®çš„å±€é™ï¼Œæå‡ºäº†Region-Aware Multimodal Chain-of-Thought (RMCoT)æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†é€šè¿‡åœ¨ç”Ÿæˆç­”æ¡ˆå‰å¼•å…¥ä¸€ç³»åˆ—ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œå¹¶æ˜ç¡®å…³è”åŒ»å­¦å›¾åƒä¸­çš„ç›¸å…³è§†è§‰åŒºåŸŸï¼Œæä¾›äº†ç»†ç²’åº¦çš„å†³ç­–è§£é‡Šã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¯éªŒè¯å¥–åŠ±æœºåˆ¶(verifiable reward mechanism)ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨¡å‹åæœŸè®­ç»ƒï¼Œç¡®ä¿æ¨ç†è¿‡ç¨‹ä¸æœ€ç»ˆç­”æ¡ˆé«˜åº¦å¯¹é½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨å…«åˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®ä¾¿å®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†æ•°æ®åˆ©ç”¨æ•ˆç‡ä¸æ¨¡å‹çš„é€æ˜åº¦ã€‚ç›®å‰è¯¥æ•°æ®é›†å·²å¼€æ”¾è·å–ï¼Œä¸ºæ„å»ºå¯ä¿¡èµ–çš„ä¸´åºŠè¾…åŠ©å†³ç­–ç³»ç»Ÿæä¾›äº†é‡è¦èµ„æºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ACM MM 2025 (also known as GEMeX-ThinkVG)",
      "pdf_url": "https://arxiv.org/pdf/2506.17939v2",
      "published_date": "2025-06-22 08:09:58 UTC",
      "updated_date": "2025-10-28 06:37:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:12.887473+00:00"
    },
    {
      "arxiv_id": "2506.17937v1",
      "title": "Software Reuse in the Generative AI Era: From Cargo Cult Towards AI Native Software Engineering",
      "title_zh": "ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ—¶ä»£çš„è½¯ä»¶å¤ç”¨ï¼šä»â€œè´§ç‰©å´‡æ‹œâ€è¿ˆå‘ AI åŸç”Ÿè½¯ä»¶å·¥ç¨‹",
      "authors": [
        "Tommi Mikkonen",
        "Antero Taivalsaari"
      ],
      "abstract": "Software development is currently under a paradigm shift in which artificial intelligence and generative software reuse are taking the center stage in software creation. Consequently, earlier software reuse practices and methods are rapidly being replaced by AI-assisted approaches in which developers place their trust on code that has been generated by artificial intelligence. This is leading to a new form of software reuse that is conceptually not all that different from cargo cult development. In this paper we discuss the implications of AI-assisted generative software reuse in the context of emerging \"AI native\" software engineering, bring forth relevant questions, and define a tentative research agenda and call to action for tackling some of the central issues associated with this approach.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰èƒŒæ™¯ä¸‹è½¯ä»¶å¤ç”¨çš„èŒƒå¼è½¬ç§»ï¼Œå³ä»ä¼ ç»Ÿæ–¹æ³•å‘ AI Native Software Engineering çš„æ¼”è¿›ã€‚éšç€å¼€å‘è€…æ—¥ç›Šä¾èµ– AI è¾…åŠ©æ–¹æ³•ï¼Œè½¯ä»¶å¼€å‘æ­£å‡ºç°ä¸€ç§ç±»ä¼¼äºâ€œè´§ç‰©å´‡æ‹œâ€ï¼ˆcargo cult developmentï¼‰çš„æ–°å‹è½¯ä»¶å¤ç”¨å½¢å¼ï¼Œåæ˜ äº†å¯¹äººå·¥ç”Ÿæˆä»£ç çš„è¿‡åº¦ä¿¡ä»»ã€‚è®ºæ–‡è¯¦ç»†åˆ†æäº† AI è¾…åŠ©ç”Ÿæˆå¼è½¯ä»¶å¤ç”¨å¯¹æ–°å…´è½¯ä»¶å·¥ç¨‹èŒƒå¼çš„å½±å“ï¼Œå¹¶æå‡ºäº†å…·æœ‰é’ˆå¯¹æ€§çš„å…³é”®ç§‘å­¦é—®é¢˜ã€‚é€šè¿‡å®šä¹‰ä¸€ä¸ªåˆæ­¥çš„ç ”ç©¶è®®ç¨‹ï¼ˆresearch agendaï¼‰å’Œè¡ŒåŠ¨å€¡è®®ï¼Œè¯¥ç ”ç©¶æ—¨åœ¨å¼•å¯¼å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œå…±åŒåº”å¯¹è¿™ç§æ–°å‹å¼€å‘æ¨¡å¼å¸¦æ¥çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œç¡®ä¿è½¯ä»¶ç³»ç»Ÿçš„å¯æŒç»­æ€§ä¸å¯é æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17937v1",
      "published_date": "2025-06-22 08:09:25 UTC",
      "updated_date": "2025-06-22 08:09:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:12.292436+00:00"
    },
    {
      "arxiv_id": "2506.17936v2",
      "title": "When concept-based XAI is imprecise: Do people distinguish between generalisations and misrepresentations?",
      "title_zh": "å½“åŸºäºæ¦‚å¿µçš„å¯è§£é‡Šäººå·¥æ™ºèƒ½ä¸ç²¾ç¡®æ—¶ï¼šäººç±»èƒ½å¦åŒºåˆ†æ³›åŒ–ä¸é”™è¯¯è¡¨å¾ï¼Ÿ",
      "authors": [
        "Romy MÃ¼ller"
      ],
      "abstract": "Concept-based explainable artificial intelligence (C-XAI) can let people see which representations an AI model has learned. This is particularly important when high-level semantic information (e.g., actions and relations) is used to make decisions about abstract categories (e.g., danger). In such tasks, AI models need to generalise beyond situation-specific details, and this ability can be reflected in C-XAI outputs that randomise over irrelevant features. However, it is unclear whether people appreciate such generalisation and can distinguish it from other, less desirable forms of imprecision in C-XAI outputs. Therefore, the present study investigated how the generality and relevance of C-XAI outputs affect people's evaluation of AI. In an experimental railway safety evaluation scenario, participants rated the performance of a simulated AI that classified traffic scenes involving people as dangerous or not. These classification decisions were explained via concepts in the form of similar image snippets. The latter differed in their match with the classified image, either regarding a highly relevant feature (i.e., people's relation to tracks) or a less relevant feature (i.e., people's action). Contrary to the hypotheses, concepts that generalised over less relevant features were rated lower than concepts that matched the classified image precisely. Moreover, their ratings were no better than those for systematic misrepresentations of the less relevant feature. Conversely, participants were highly sensitive to imprecisions in relevant features. These findings cast doubts on the assumption that people can easily infer from C-XAI outputs whether AI models have gained a deeper understanding of complex situations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºæ¦‚å¿µçš„å¯è§£é‡Šäººå·¥æ™ºèƒ½ (Concept-based XAI, C-XAI) åœ¨è¡¨ç°ä¸ç²¾ç¡®æ—¶ï¼Œäººç±»æ˜¯å¦èƒ½å¤ŸåŒºåˆ†è¿™ç§ä¸ç²¾ç¡®æ˜¯å‡ºäºæ¨¡å‹çš„æ³›åŒ– (Generalisation) è¿˜æ˜¯è¯¯è¡¨ (Misrepresentation)ã€‚å®éªŒé€šè¿‡é“è·¯å®‰å…¨è¯„ä¼°åœºæ™¯ï¼Œè®©å‚ä¸è€…æ ¹æ®ä»¥ç›¸ä¼¼å›¾åƒç‰‡æ®µä¸ºå½¢å¼çš„ C-XAI è§£é‡Šæ¥è¯„ä¼°æ¨¡æ‹Ÿ AI çš„æ€§èƒ½ã€‚è¿™äº›è§£é‡Šåœ¨ä¸åŸå›¾çš„åŒ¹é…åº¦ä¸Šæœ‰æ‰€ä¸åŒï¼Œåˆ†åˆ«æ¶‰åŠé«˜ç›¸å…³æ€§ç‰¹å¾ï¼ˆå¦‚äººä¸è½¨é“çš„å…³ç³»ï¼‰å’Œä½ç›¸å…³æ€§ç‰¹å¾ï¼ˆå¦‚äººçš„åŠ¨ä½œï¼‰ã€‚ç ”ç©¶å‘ç°ï¼Œå‚ä¸è€…å¯¹ä½ç›¸å…³æ€§ç‰¹å¾è¿›è¡Œæ³›åŒ–çš„æ¦‚å¿µè¯„åˆ†åè€Œä½äºç²¾ç¡®åŒ¹é…çš„æ¦‚å¿µï¼Œä¸”å…¶è¯„åˆ†ä¸ç³»ç»Ÿæ€§è¯¯æŠ¥çš„è¯„åˆ†ç›¸å½“ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå‚ä¸è€…å¯¹é«˜ç›¸å…³æ€§ç‰¹å¾çš„ä¸ç²¾ç¡®æ€§è¡¨ç°å‡ºæé«˜çš„æ•æ„Ÿåº¦ã€‚è¿™ä¸€ç»“æœæŒ‘æˆ˜äº†ç”¨æˆ·èƒ½è½»æ˜“ä» C-XAI è¾“å‡ºä¸­æ¨æ–­ AI æ¨¡å‹æ˜¯å¦è·å¾—æ·±åº¦ç†è§£çš„å‡è®¾ï¼Œè¡¨æ˜äººç±»å¯èƒ½æ— æ³•æœ‰æ•ˆåŒºåˆ†æ¨¡å‹çš„åˆç†æ³›åŒ–ä¸é”™è¯¯è¡¨è¾¾ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17936v2",
      "published_date": "2025-06-22 08:07:02 UTC",
      "updated_date": "2025-11-20 14:26:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:16.287585+00:00"
    },
    {
      "arxiv_id": "2506.17934v1",
      "title": "A GenAI System for Improved FAIR Independent Biological Database Integration",
      "title_zh": "ä¸€ç§ç”¨äºä¼˜åŒ–ç¬¦åˆ FAIR åŸåˆ™çš„ç‹¬ç«‹ç”Ÿç‰©æ•°æ®åº“é›†æˆçš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç³»ç»Ÿ",
      "authors": [
        "Syed N. Sakib",
        "Kallol Naha",
        "Sajratul Y. Rubaiat",
        "Hasan M. Jamil"
      ],
      "abstract": "Life sciences research increasingly requires identifying, accessing, and effectively processing data from an ever-evolving array of information sources on the Linked Open Data (LOD) network. This dynamic landscape places a significant burden on researchers, as the quality of query responses depends heavily on the selection and semantic integration of data sources --processes that are often labor-intensive, error-prone, and costly. While the adoption of FAIR (Findable, Accessible, Interoperable, and Reusable) data principles has aimed to address these challenges, barriers to efficient and accurate scientific data processing persist.\n  In this paper, we introduce FAIRBridge, an experimental natural language-based query processing system designed to empower scientists to discover, access, and query biological databases, even when they are not FAIR-compliant. FAIRBridge harnesses the capabilities of AI to interpret query intents, map them to relevant databases described in scientific literature, and generate executable queries via intelligent resource access plans. The system also includes robust tools for mitigating low-quality query processing, ensuring high fidelity and responsiveness in the information delivered.\n  FAIRBridge's autonomous query processing framework enables users to explore alternative data sources, make informed choices at every step, and leverage community-driven crowd curation when needed. By providing a user-friendly, automated hypothesis-testing platform in natural English, FAIRBridge significantly enhances the integration and processing of scientific data, offering researchers a powerful new tool for advancing their inquiries.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†åä¸º FAIRBridge çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ GenAI ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç”Ÿå‘½ç§‘å­¦é¢†åŸŸä¸­ Linked Open Data (LOD) æ•°æ®æºé€‰æ‹©ä¸é›†æˆè¿‡ç¨‹ç¹çä¸”æˆæœ¬é«˜æ˜‚çš„éš¾é¢˜ã€‚ä½œä¸ºä¸€ä¸ªåŸºäºè‡ªç„¶è¯­è¨€çš„æŸ¥è¯¢å¤„ç†å¹³å°ï¼ŒFAIRBridge åˆ©ç”¨ AI å‡†ç¡®è§£é‡Šç”¨æˆ·æ„å›¾ï¼Œå¹¶é€šè¿‡æ™ºèƒ½èµ„æºè®¿é—®è®¡åˆ’ resource access plans å°†å…¶æ˜ å°„è‡³ç›¸å…³æ•°æ®åº“å¹¶ç”Ÿæˆå¯æ‰§è¡ŒæŸ¥è¯¢ã€‚è¯¥ç³»ç»Ÿé€šè¿‡ç‰¹å®šçš„å¤„ç†æœºåˆ¶æœ‰æ•ˆé™ä½äº†ä½è´¨é‡æŸ¥è¯¢çš„é£é™©ï¼Œå³ä¾¿åœ¨æ•°æ®åº“ä¸ç¬¦åˆ FAIR-compliant æ ‡å‡†æ—¶ä¹Ÿèƒ½ç¡®ä¿ä¿¡æ¯äº¤ä»˜çš„é«˜ä¿çœŸåº¦ã€‚æ­¤å¤–ï¼ŒFAIRBridge æ”¯æŒç”¨æˆ·è‡ªä¸»æ¢ç´¢æ›¿ä»£æ•°æ®æºï¼Œå¹¶èƒ½åœ¨å¿…è¦æ—¶ç»“åˆä¼—åŒ…ç­–å±• crowd curation è¿›ä¸€æ­¥ä¼˜åŒ–æ•°æ®å¤„ç†ã€‚ä½œä¸ºä¸€ç§è‡ªåŠ¨åŒ–çš„å‡è®¾éªŒè¯å·¥å…·ï¼Œè¯¥ç³»ç»Ÿæ˜¾è‘—å¢å¼ºäº†ç§‘å­¦æ•°æ®çš„é›†æˆæ•ˆç‡ï¼Œä¸ºç ”ç©¶äººå‘˜æ·±å…¥å¼€å±•ç§‘å­¦æ¢ç©¶æä¾›äº†å¼ºå¤§çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17934v1",
      "published_date": "2025-06-22 08:04:24 UTC",
      "updated_date": "2025-06-22 08:04:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:25.590963+00:00"
    },
    {
      "arxiv_id": "2506.22479v1",
      "title": "Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate",
      "title_zh": "åè§†å¼•å¯¼åŠ¨é‡ï¼ˆHGMï¼‰ä¼˜åŒ–å™¨ï¼šä¸€ç§è‡ªé€‚åº”å­¦ä¹ ç‡æ–¹æ³•",
      "authors": [
        "Krisanu Sarkar"
      ],
      "abstract": "We introduce Hindsight-Guided Momentum (HGM), a first-order optimization algorithm that adaptively scales learning rates based on the directional consistency of recent updates. Traditional adaptive methods, such as Adam or RMSprop , adapt learning dynamics using only the magnitude of gradients, often overlooking important geometric cues.Geometric cues refer to directional information, such as the alignment between current gradients and past updates, which reflects the local curvature and consistency of the optimization path. HGM addresses this by incorporating a hindsight mechanism that evaluates the cosine similarity between the current gradient and accumulated momentum. This allows it to distinguish between coherent and conflicting gradient directions, increasing the learning rate when updates align and reducing it in regions of oscillation or noise. The result is a more responsive optimizer that accelerates convergence in smooth regions of the loss surface while maintaining stability in sharper or more erratic areas. Despite this added adaptability, the method preserves the computational and memory efficiency of existing optimizers.By more intelligently responding to the structure of the optimization landscape, HGM provides a simple yet effective improvement over existing approaches, particularly in non-convex settings like that of deep neural network training.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Hindsight-Guided Momentum (HGM)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒè®¾è®¡çš„ä¸€é˜¶ä¼˜åŒ–ç®—æ³•(first-order optimization algorithm)ï¼Œæ—¨åœ¨è§£å†³Adamæˆ–RMSpropç­‰ä¼ ç»Ÿè‡ªé€‚åº”æ–¹æ³•ä»…ä¾æ®æ¢¯åº¦å¹…å€¼è€Œå¿½ç•¥å‡ ä½•çº¿ç´¢(geometric cues)çš„é—®é¢˜ã€‚HGMçš„æ ¸å¿ƒåœ¨äºå¼•å…¥äº†åéªŒæŒ‡å¯¼æœºåˆ¶(hindsight mechanism)ï¼Œé€šè¿‡è¯„ä¼°å½“å‰æ¢¯åº¦ä¸ç´¯ç§¯åŠ¨é‡(accumulated momentum)ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦(cosine similarity)æ¥åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡ã€‚å½“æ›´æ–°æ–¹å‘ä¿æŒä¸€è‡´æ—¶ï¼Œè¯¥ç®—æ³•ä¼šå¢å¤§å­¦ä¹ ç‡ä»¥åŠ é€Ÿæ”¶æ•›ï¼Œè€Œåœ¨å‡ºç°éœ‡è¡æˆ–å™ªå£°çš„åŒºåŸŸåˆ™ä¼šè‡ªåŠ¨é™ä½å­¦ä¹ ç‡ä»¥ç¡®ä¿ç¨³å®šæ€§ã€‚è¿™ç§æœºåˆ¶ä½¿ä¼˜åŒ–å™¨èƒ½å¤Ÿæ•é”åœ°æ„ŸçŸ¥æŸå¤±å¹³é¢çš„å±€éƒ¨æ›²ç‡å’Œè·¯å¾„ä¸€è‡´æ€§ï¼Œä»è€Œåœ¨å¹³æ»‘åŒºåŸŸå®ç°åŠ é€Ÿã€‚å°½ç®¡å¢åŠ äº†è‡ªé€‚åº”èƒ½åŠ›ï¼ŒHGMä»ä¿æŒäº†ç°æœ‰ä¼˜åŒ–å™¨çš„é«˜è®¡ç®—å’Œå†…å­˜æ•ˆç‡ã€‚é€šè¿‡æ›´æ™ºèƒ½åœ°å“åº”ä¼˜åŒ–æ™¯è§‚(optimization landscape)çš„ç»“æ„ï¼ŒHGMä¸ºéå‡¸(non-convex)è®¾ç½®ä¸‹çš„æ¨¡å‹è®­ç»ƒæä¾›äº†ä¸€ç§ç®€å•ä¸”æœ‰æ•ˆçš„æ”¹è¿›æ–¹æ¡ˆã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.22479v1",
      "published_date": "2025-06-22 08:02:19 UTC",
      "updated_date": "2025-06-22 08:02:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:26.996956+00:00"
    },
    {
      "arxiv_id": "2506.17931v1",
      "title": "IDAL: Improved Domain Adaptive Learning for Natural Images Dataset",
      "title_zh": "IDALï¼šé’ˆå¯¹è‡ªç„¶å›¾åƒæ•°æ®é›†çš„æ”¹è¿›é¢†åŸŸè‡ªé€‚åº”å­¦ä¹ ",
      "authors": [
        "Ravi Kant Gupta",
        "Shounak Das",
        "Amit Sethi"
      ],
      "abstract": "We present a novel approach for unsupervised domain adaptation (UDA) for natural images. A commonly-used objective for UDA schemes is to enhance domain alignment in representation space even if there is a domain shift in the input space. Existing adversarial domain adaptation methods may not effectively align different domains of multimodal distributions associated with classification problems. Our approach has two main features. Firstly, its neural architecture uses the deep structure of ResNet and the effective separation of scales of feature pyramidal network (FPN) to work with both content and style features. Secondly, it uses a combination of a novel loss function and judiciously selected existing loss functions to train the network architecture. This tailored combination is designed to address challenges inherent to natural images, such as scale, noise, and style shifts, that occur on top of a multi-modal (multi-class) distribution. The combined loss function not only enhances model accuracy and robustness on the target domain but also speeds up training convergence. Our proposed UDA scheme generalizes better than state-of-the-art for CNN-based methods on Office-Home, Office-31, and VisDA-2017 datasets and comaparable for DomainNet dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªç„¶å›¾åƒçš„æ— ç›‘ç£åŸŸé€‚åº”(Unsupervised Domain Adaptation, UDA)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºIDALçš„æ–°å‹æ”¹è¿›åŸŸé€‚åº”å­¦ä¹ æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰å¯¹æŠ—æ€§åŸŸé€‚åº”æ–¹æ³•åœ¨å¤„ç†åˆ†ç±»ç›¸å…³çš„å¤šæ¨¡æ€åˆ†å¸ƒæ—¶å¯¹é½æ•ˆæœä¸ä½³çš„é—®é¢˜ï¼ŒIDALæ—¨åœ¨å³ä½¿åœ¨è¾“å…¥ç©ºé—´å­˜åœ¨åŸŸåç§»çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½æ˜¾è‘—å¢å¼ºè¡¨ç¤ºç©ºé—´çš„åŸŸå¯¹é½ã€‚å…¶ç½‘ç»œæ¶æ„ç»“åˆäº†ResNetçš„æ·±å±‚ç»“æ„å’Œç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ(Feature Pyramidal Network, FPN)çš„å°ºåº¦åˆ†ç¦»èƒ½åŠ›ï¼Œä»¥åŒæ—¶æå–å†…å®¹å’Œé£æ ¼ç‰¹å¾ã€‚ç ”ç©¶é€šè¿‡å¼•å…¥ä¸€ç§æ–°å‹æŸå¤±å‡½æ•°å¹¶ç»“åˆç²¾é€‰çš„ç°æœ‰æŸå¤±ï¼Œæœ‰æ•ˆåº”å¯¹äº†è‡ªç„¶å›¾åƒä¸­çš„å°ºåº¦ã€å™ªå£°å’Œé£æ ¼åç§»ç­‰æŒ‘æˆ˜ã€‚è¿™ç§å®šåˆ¶åŒ–çš„æŸå¤±å‡½æ•°ç»„åˆåœ¨æå‡æ¨¡å‹åœ¨ç›®æ ‡åŸŸå‡†ç¡®æ€§å’Œé²æ£’æ€§çš„åŒæ—¶ï¼Œä¹Ÿæ˜¾è‘—åŠ å¿«äº†è®­ç»ƒæ”¶æ•›é€Ÿåº¦ã€‚å®éªŒè¯æ˜ï¼ŒIDALåœ¨Office-Homeã€Office-31å’ŒVisDA-2017ç­‰æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰çš„CNNåŸºå‡†æ–¹æ³•ï¼Œå¹¶åœ¨DomainNetæ•°æ®é›†ä¸Šå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå±•ç°äº†æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in ICPR'24 (International Conference on Pattern Recognition)",
      "pdf_url": "https://arxiv.org/pdf/2506.17931v1",
      "published_date": "2025-06-22 07:56:10 UTC",
      "updated_date": "2025-06-22 07:56:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:37.599045+00:00"
    },
    {
      "arxiv_id": "2506.17930v1",
      "title": "Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective",
      "title_zh": "ä¸Šä¸‹æ–‡å†…æç¤ºæ¼”åŒ–ï¼šä¸€ç§å¼€æ”¾å¼ã€è‡ªæˆ‘å¤åˆ¶çš„è§†è§’",
      "authors": [
        "Jianyu Wang",
        "Zhiqiang Hu",
        "Lidong Bing"
      ],
      "abstract": "We propose a novel prompt design paradigm that challenges conventional wisdom in large language model (LLM) prompting. While conventional wisdom prioritizes well-crafted instructions and demonstrations for in-context learning (ICL), we show that pruning random demonstrations into seemingly incoherent \"gibberish\" can remarkably improve performance across diverse tasks. Notably, the \"gibberish\" always matches or surpasses state-of-the-art automatic prompt optimization techniques, achieving substantial gains regardless of LLM alignment. Nevertheless, discovering an effective pruning strategy is non-trivial, as existing attribution methods and prompt compression algorithms fail to deliver robust results, let alone human intuition. In terms of this, we propose a self-discover prompt optimization framework, PromptQuine, an evolutionary search framework that automatically searches for the pruning strategy by itself using only low-data regimes. Much like the emergent complexity in nature--such as symbiosis and self-organization--arising in response to resource constraints, our framework evolves and refines unconventional yet highly effective prompts by leveraging only the tokens present within the context. We demonstrate its effectiveness across classification, multi-choice question answering, generation and math reasoning tasks across LLMs, while achieving decent runtime efficiency. We hope our findings can guide mechanistic studies on in-context learning, and provide a call to action, to pave the way for more open-ended search algorithms for more effective LLM prompting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PromptQuineï¼Œä¸€ä¸ªåŸºäºæ¼”åŒ–æœç´¢(evolutionary search)çš„æç¤ºä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨æ¢è®¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è¯­å¢ƒå­¦ä¹ (In-context learning)ä¸­ä¸€ç§éå¸¸è§„çš„æç¤ºè®¾è®¡èŒƒå¼ã€‚ä¸åŒäºä¼˜å…ˆè€ƒè™‘ç²¾å¿ƒè®¾è®¡çš„æŒ‡ä»¤æˆ–æ¼”ç¤ºçš„ä¼ ç»Ÿè§‚ç‚¹ï¼Œè¯¥ç ”ç©¶å‘ç°å°†éšæœºæ¼”ç¤ºå‰ªæä¸ºçœ‹ä¼¼ä¸è¿è´¯çš„â€œä¹±ç (gibberish)â€åè€Œèƒ½æ˜¾è‘—æå‡æ¨¡å‹åœ¨å„ç±»ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚ç”±äºç°æœ‰å½’å› æ–¹æ³•å’Œæç¤ºå‹ç¼©ç®—æ³•éš¾ä»¥åœ¨äººç±»ç›´è§‰ä¹‹å¤–å‘ç°æœ‰æ•ˆçš„å‰ªæç­–ç•¥ï¼ŒPromptQuineé€šè¿‡åœ¨ä½æ•°æ®ç¯å¢ƒä¸‹è‡ªåŠ¨æœç´¢æœ€ä¼˜çš„å‰ªææ–¹æ¡ˆæ¥è§£å†³è¿™ä¸€éš¾é¢˜ã€‚è¯¥æ¡†æ¶å€Ÿé‰´è‡ªç„¶ç•Œä¸­å—èµ„æºçº¦æŸè€Œäº§ç”Ÿçš„å…±ç”Ÿä¸è‡ªç»„ç»‡ç­‰æ¶Œç°å¤æ‚æ€§åŸç†ï¼Œä»…åˆ©ç”¨ä¸Šä¸‹æ–‡ä¸­çš„æ—¢æœ‰æ ‡è®°(tokens)æ¥æ¼”åŒ–å’Œç²¾ç‚¼éå¸¸è§„å´æå…¶æœ‰æ•ˆçš„æç¤ºã€‚å®éªŒè¯æ˜ï¼ŒPromptQuineåœ¨åˆ†ç±»ã€å¤šé¡¹é€‰æ‹©é¢˜è§£ç­”ã€æ–‡æœ¬ç”ŸæˆåŠæ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å‡èƒ½è¾¾åˆ°æˆ–è¶…è¶Šç°æœ‰çš„è‡ªåŠ¨æç¤ºä¼˜åŒ–(automatic prompt optimization)æŠ€æœ¯ï¼Œå¹¶å±•ç°å‡ºè‰¯å¥½çš„è¿è¡Œæ•ˆç‡ã€‚è¿™é¡¹å·¥ä½œä¸ºè¯­å¢ƒå­¦ä¹ (In-context learning)çš„æœºåˆ¶ç ”ç©¶æä¾›äº†æ–°è§†è§’ï¼Œå¹¶ä¸ºå¼€å‘æ›´å…·å¼€æ”¾æ€§çš„æç¤ºæœç´¢ç®—æ³•é“ºå¹³äº†é“è·¯ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NE",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML 2025, and Code will be released at: https://github.com/jianyu-cs/PromptQuine/",
      "pdf_url": "https://arxiv.org/pdf/2506.17930v1",
      "published_date": "2025-06-22 07:53:07 UTC",
      "updated_date": "2025-06-22 07:53:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:31.292663+00:00"
    },
    {
      "arxiv_id": "2506.17929v1",
      "title": "ASTER: Adaptive Spatio-Temporal Early Decision Model for Dynamic Resource Allocation",
      "title_zh": "ASTERï¼šé¢å‘åŠ¨æ€èµ„æºåˆ†é…çš„è‡ªé€‚åº”æ—¶ç©ºæ—©æœŸå†³ç­–æ¨¡å‹",
      "authors": [
        "Shulun Chen",
        "Wei Shao",
        "Flora D. Salim",
        "Hao Xue"
      ],
      "abstract": "Supporting decision-making has long been a central vision in the field of spatio-temporal intelligence. While prior work has improved the timeliness and accuracy of spatio-temporal forecasting, converting these forecasts into actionable strategies remains a key challenge. A main limitation is the decoupling of the prediction and the downstream decision phases, which can significantly degrade the downstream efficiency. For example, in emergency response, the priority is successful resource allocation and intervention, not just incident prediction. To this end, it is essential to propose an Adaptive Spatio-Temporal Early Decision model (ASTER) that reforms the forecasting paradigm from event anticipation to actionable decision support. This framework ensures that information is directly used for decision-making, thereby maximizing overall effectiveness. Specifically, ASTER introduces a new Resource-aware Spatio-Temporal interaction module (RaST) that adaptively captures long- and short-term dependencies under dynamic resource conditions, producing context-aware spatiotemporal representations. To directly generate actionable decisions, we further design a Preference-oriented decision agent (Poda) based on multi-objective reinforcement learning, which transforms predictive signals into resource-efficient intervention strategies by deriving optimal actions under specific preferences and dynamic constraints. Experimental results on four benchmark datasets demonstrate the state-of-the-art performance of ASTER in improving both early prediction accuracy and resource allocation outcomes across six downstream metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ASTER (Adaptive Spatio-Temporal Early Decision model)ï¼Œæ—¨åœ¨è§£å†³æ—¶ç©ºæ™ºèƒ½ (spatio-temporal intelligence) é¢†åŸŸä¸­é¢„æµ‹ä¸ä¸‹æ¸¸å†³ç­–é˜¶æ®µè„±èŠ‚å¯¼è‡´çš„æ•ˆç‡ä¸‹é™é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†ä¼ ç»Ÿçš„é¢„æµ‹èŒƒå¼é‡æ„ä¸ºå¯æ‰§è¡Œçš„å†³ç­–æ”¯æŒï¼Œç¡®ä¿é¢„æµ‹ä¿¡æ¯èƒ½ç›´æ¥ç”¨äºæœ€å¤§åŒ–èµ„æºåˆ†é…çš„æœ‰æ•ˆæ€§ã€‚æ¨¡å‹å¼•å…¥äº†èµ„æºæ„ŸçŸ¥æ—¶ç©ºäº¤äº’æ¨¡å— (RaST)ï¼Œåœ¨åŠ¨æ€èµ„æºæ¡ä»¶ä¸‹è‡ªé€‚åº”æ•æ‰é•¿çŸ­æœŸä¾èµ–å¹¶ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ—¶ç©ºè¡¨ç¤ºã€‚æ­¤å¤–ï¼Œç ”ç©¶è®¾è®¡äº†åŸºäºå¤šç›®æ ‡å¼ºåŒ–å­¦ä¹  (multi-objective reinforcement learning) çš„åå¥½å¯¼å‘å†³ç­–æ™ºèƒ½ä½“ (Poda)ï¼Œèƒ½å¤Ÿåœ¨åŠ¨æ€çº¦æŸä¸‹å°†é¢„æµ‹ä¿¡å·è½¬åŒ–ä¸ºæœ€ä¼˜å¹²é¢„ç­–ç•¥ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒASTER åœ¨æå‡æ—©æœŸé¢„æµ‹å‡†ç¡®æ€§å’Œä¼˜åŒ–èµ„æºåˆ†é…æˆæœçš„å…­é¡¹ä¸‹æ¸¸æŒ‡æ ‡ä¸­å‡è¾¾åˆ°äº† SOTA æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ASTER: Adaptive Spatio-Temporal Early Decision Model for Dynamic Resource Allocation",
      "pdf_url": "https://arxiv.org/pdf/2506.17929v1",
      "published_date": "2025-06-22 07:49:37 UTC",
      "updated_date": "2025-06-22 07:49:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:37.994131+00:00"
    },
    {
      "arxiv_id": "2506.17919v1",
      "title": "Permutation Equivariant Model-based Offline Reinforcement Learning for Auto-bidding",
      "title_zh": "é¢å‘è‡ªåŠ¨å‡ºä»·çš„ç½®æ¢ç­‰å˜åŸºäºæ¨¡å‹çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Zhiyu Mou",
        "Miao Xu",
        "Wei Chen",
        "Rongquan Bai",
        "Chuan Yu",
        "Jian Xu"
      ],
      "abstract": "Reinforcement learning (RL) for auto-bidding has shifted from using simplistic offline simulators (Simulation-based RL Bidding, SRLB) to offline RL on fixed real datasets (Offline RL Bidding, ORLB). However, ORLB policies are limited by the dataset's state space coverage, offering modest gains. While SRLB expands state coverage, its simulator-reality gap risks misleading policies. This paper introduces Model-based RL Bidding (MRLB), which learns an environment model from real data to bridge this gap. MRLB trains policies using both real and model-generated data, expanding state coverage beyond ORLB. To ensure model reliability, we propose: 1) A permutation equivariant model architecture for better generalization, and 2) A robust offline Q-learning method that pessimistically penalizes model errors. These form the Permutation Equivariant Model-based Offline RL (PE-MORL) algorithm. Real-world experiments show that PE-MORL outperforms state-of-the-art auto-bidding methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨å‡ºä»·(Auto-bidding)é¢†åŸŸä¸­ç¦»çº¿å¼ºåŒ–å­¦ä¹ (ORLB)çŠ¶æ€è¦†ç›–æœ‰é™ä»¥åŠä»¿çœŸå¼ºåŒ–å­¦ä¹ (SRLB)å­˜åœ¨æ¨¡æ‹Ÿä¸ç°å®å·®è·çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ å‡ºä»·æ¡†æ¶(MRLB)ã€‚è¯¥æ¡†æ¶é€šè¿‡ä»çœŸå®æ•°æ®ä¸­å­¦ä¹ ç¯å¢ƒæ¨¡å‹ï¼Œå¹¶ç»“åˆçœŸå®ä¸æ¨¡å‹ç”Ÿæˆçš„æ•°æ®è¿›è¡Œç­–ç•¥è®­ç»ƒï¼Œæœ‰æ•ˆæ‰©å±•äº†çŠ¶æ€è¦†ç›–èŒƒå›´ã€‚ä¸ºæå‡æ¨¡å‹å¯é æ€§ï¼Œä½œè€…è¿›ä¸€æ­¥æå‡ºäº†ç½®æ¢ç­‰å˜æ¨¡å‹é©±åŠ¨çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ ç®—æ³•(PE-MORL)ï¼Œå…¶é‡‡ç”¨äº†ç½®æ¢ç­‰å˜(Permutation Equivariant)æ¶æ„ä»¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒPE-MORLè¿˜å¼•å…¥äº†ä¸€ç§ç¨³å¥çš„ç¦»çº¿Qå­¦ä¹ (Offline Q-learning)æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ¨¡å‹è¯¯å·®è¿›è¡Œæ‚²è§‚æƒ©ç½šæ¥ç¡®ä¿ç­–ç•¥åœ¨ç¦»çº¿ç¯å¢ƒä¸‹çš„ç¨³å®šæ€§ã€‚çœŸå®ä¸–ç•Œå®éªŒç»“æœè¡¨æ˜ï¼ŒPE-MORLåœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„è‡ªåŠ¨å‡ºä»·æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17919v1",
      "published_date": "2025-06-22 06:58:36 UTC",
      "updated_date": "2025-06-22 06:58:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:42:56.692119+00:00"
    },
    {
      "arxiv_id": "2506.17913v1",
      "title": "Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents",
      "title_zh": "å­¦ä¹ ã€æ¨ç†ä¸ä¼˜åŒ–ï¼šé¢å‘ GUI æ™ºèƒ½ä½“çš„ Kahneman åŒç³»ç»Ÿæ™ºèƒ½æ¡†æ¶",
      "authors": [
        "Jinjie Wei",
        "Jiyao Liu",
        "Lihao Liu",
        "Ming Hu",
        "Junzhi Ning",
        "Mingcheng Li",
        "Weijie Yin",
        "Junjun He",
        "Xiao Liang",
        "Chao Feng",
        "Dingkang Yang"
      ],
      "abstract": "Graphical User Interface (GUI) agents have made significant progress in automating digital tasks through the utilization of computer vision and language models. Nevertheless, existing agent systems encounter notable limitations. Firstly, they predominantly depend on trial and error decision making rather than progressive reasoning, thereby lacking the capability to learn and adapt from interactive encounters. Secondly, these systems are assessed using overly simplistic single step accuracy metrics, which do not adequately reflect the intricate nature of real world GUI interactions. In this paper, we present CogniGUI, a cognitive framework developed to overcome these limitations by enabling adaptive learning for GUI automation resembling human-like behavior. Inspired by Kahneman's Dual Process Theory, our approach combines two main components: (1) an omni parser engine that conducts immediate hierarchical parsing of GUI elements through quick visual semantic analysis to identify actionable components, and (2) a Group based Relative Policy Optimization (GRPO) grounding agent that assesses multiple interaction paths using a unique relative reward system, promoting minimal and efficient operational routes. This dual-system design facilitates iterative ''exploration learning mastery'' cycles, enabling the agent to enhance its strategies over time based on accumulated experience. Moreover, to assess the generalization and adaptability of agent systems, we introduce ScreenSeek, a comprehensive benchmark that includes multi application navigation, dynamic state transitions, and cross interface coherence, which are often overlooked challenges in current benchmarks. Experimental results demonstrate that CogniGUI surpasses state-of-the-art methods in both the current GUI grounding benchmarks and our newly proposed benchmark.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹GUIæ™ºèƒ½ä½“è¿‡åº¦ä¾èµ–è¯•é”™è€Œç¼ºä¹é€æ­¥æ¨ç†èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†å—å¡å°¼æ›¼åŒç³»ç»Ÿç†è®º(Kahneman's Dual Process Theory)å¯å‘çš„CogniGUIæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°ç±»äººçš„é€‚åº”æ€§å­¦ä¹ ã€‚è¯¥æ¡†æ¶æ•´åˆäº†è´Ÿè´£å¿«é€Ÿè§†è§‰è¯­ä¹‰åˆ†æä¸åˆ†å±‚è§£æGUIå…ƒç´ çš„omni parser engineï¼Œä»¥åŠåŸºäºGroup based Relative Policy Optimization (GRPO)å¹¶é‡‡ç”¨ç›¸å¯¹å¥–åŠ±ç³»ç»Ÿçš„grounding agentã€‚è¿™ç§åŒç³»ç»Ÿè®¾è®¡ä¿ƒæˆäº†â€œæ¢ç´¢-å­¦ä¹ -ç²¾é€šâ€çš„è¿­ä»£å¾ªç¯ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ ¹æ®ç´¯ç§¯ç»éªŒæŒç»­ä¼˜åŒ–æ“ä½œè·¯å¾„ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ScreenSeekè¿™ä¸€æ¶µç›–å¤šåº”ç”¨å¯¼èˆªå’ŒåŠ¨æ€çŠ¶æ€è½¬æ¢çš„ç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œä»¥æ›´çœŸå®åœ°è¯„ä¼°æ™ºèƒ½ä½“çš„æ³›åŒ–æ€§ä¸ååŒèƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCogniGUIåœ¨ç°æœ‰åŠæ–°æå‡ºçš„åŸºå‡†æµ‹è¯•ä¸­å‡è¶…è¶Šäº†SOTAæ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†GUIè‡ªåŠ¨åŒ–ä»»åŠ¡çš„æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17913v1",
      "published_date": "2025-06-22 06:30:52 UTC",
      "updated_date": "2025-06-22 06:30:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:43:02.089920+00:00"
    },
    {
      "arxiv_id": "2506.17910v1",
      "title": "Feedback Driven Multi Stereo Vision System for Real-Time Event Analysis",
      "title_zh": "é¢å‘å®æ—¶äº‹ä»¶åˆ†æçš„åé¦ˆé©±åŠ¨å¤šç«‹ä½“è§†è§‰ç³»ç»Ÿ",
      "authors": [
        "Mohamed Benkedadra",
        "Matei Mancas",
        "Sidi Ahmed Mahmoudi"
      ],
      "abstract": "2D cameras are often used in interactive systems. Other systems like gaming consoles provide more powerful 3D cameras for short range depth sensing. Overall, these cameras are not reliable in large, complex environments. In this work, we propose a 3D stereo vision based pipeline for interactive systems, that is able to handle both ordinary and sensitive applications, through robust scene understanding. We explore the fusion of multiple 3D cameras to do full scene reconstruction, which allows for preforming a wide range of tasks, like event recognition, subject tracking, and notification. Using possible feedback approaches, the system can receive data from the subjects present in the environment, to learn to make better decisions, or to adapt to completely new environments. Throughout the paper, we introduce the pipeline and explain our preliminary experimentation and results. Finally, we draw the roadmap for the next steps that need to be taken, in order to get this pipeline into production",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åé¦ˆé©±åŠ¨çš„å¤šç«‹ä½“è§†è§‰ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³æ™®é€š2Dæˆ–çŸ­ç¨‹3Dæ‘„åƒæœºåœ¨å¤§å‹å¤æ‚ç¯å¢ƒä¸­å¯é æ€§ä¸è¶³çš„é—®é¢˜ã€‚ä½œè€…å¼€å‘äº†ä¸€ä¸ªåŸºäº3D stereo visionçš„æµç¨‹(pipeline)ï¼Œé€šè¿‡èåˆå¤šä¸ª3Dæ‘„åƒæœºæ¥å®ç°å…¨åœºæ™¯é‡å»º(full scene reconstruction)ï¼Œä»è€Œæ”¯æŒäº‹ä»¶è¯†åˆ«(event recognition)ã€ä¸»ä½“è·Ÿè¸ª(subject tracking)å’Œå®æ—¶é€šçŸ¥ç­‰å¤šç§ä»»åŠ¡ã€‚ç³»ç»Ÿå¼•å…¥äº†åé¦ˆé©±åŠ¨(Feedback Driven)æœºåˆ¶ï¼Œèƒ½å¤Ÿåˆ©ç”¨æ¥è‡ªç¯å¢ƒå†…ä¸»ä½“çš„åé¦ˆæ•°æ®è¿›è¡Œè‡ªæˆ‘å­¦ä¹ ï¼Œä»¥ä¼˜åŒ–å†³ç­–å¹¶é€‚åº”å…¨æ–°çš„åº”ç”¨ç¯å¢ƒã€‚å®éªŒåˆæ­¥éªŒè¯äº†è¯¥æµç¨‹åœ¨äº¤äº’å¼ç³»ç»Ÿä¸­çš„é²æ£’åœºæ™¯ç†è§£èƒ½åŠ›ï¼Œå¹¶ä¸ºå°†è¯¥æŠ€æœ¯æ¨å‘å®é™…ç”Ÿäº§ç¯å¢ƒåˆ¶å®šäº†æ˜ç¡®çš„æŠ€æœ¯è·¯çº¿ã€‚é€šè¿‡è¿™ä¸€ç³»ç»Ÿï¼Œç ”ç©¶è€…ä¸ºå¤„ç†æ•æ„Ÿå’Œæ™®é€šçš„äº¤äº’åº”ç”¨æä¾›äº†ä¸€ç§æ›´ç¨³å®šã€æ›´é«˜æ•ˆçš„è§†è§‰åˆ†æè§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17910v1",
      "published_date": "2025-06-22 06:19:44 UTC",
      "updated_date": "2025-06-22 06:19:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:43:01.392802+00:00"
    },
    {
      "arxiv_id": "2507.01037v2",
      "title": "Learning to Segment for Vehicle Routing Problems",
      "title_zh": "é¢å‘è½¦è¾†è·¯å¾„é—®é¢˜çš„å­¦ä¹ å‹åˆ†æ®µæ–¹æ³•",
      "authors": [
        "Wenbin Ouyang",
        "Sirui Li",
        "Yining Ma",
        "Cathy Wu"
      ],
      "abstract": "Iterative heuristics are widely recognized as state-of-the-art for Vehicle Routing Problems (VRPs). In this work, we exploit a critical observation: a large portion of the solution remains stable, i.e., unchanged across search iterations, causing redundant computations, especially for large-scale VRPs with long subtours. To address this, we pioneer the formal study of the First-Segment-Then-Aggregate (FSTA) decomposition technique to accelerate iterative solvers. FSTA preserves stable solution segments during the search, aggregates nodes within each segment into fixed hypernodes, and focuses the search only on unstable portions. Yet, a key challenge lies in identifying which segments should be aggregated. To this end, we introduce Learning-to-Segment (L2Seg), a novel neural framework to intelligently differentiate potentially stable and unstable portions for FSTA decomposition. We present three L2Seg variants: non-autoregressive (globally comprehensive but locally indiscriminate), autoregressive (locally refined but globally deficient), and their synergy. Empirical results on CVRP and VRPTW show that L2Seg accelerates state-of-the-art solvers by 2x to 7x. We further provide in-depth analysis showing why synergy achieves the best performance. Notably, L2Seg is compatible with traditional, learning-based, and hybrid solvers, while supporting various VRPs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è½¦è¾†è·¯å¾„é—®é¢˜(Vehicle Routing Problems, VRPs)çš„è¿­ä»£å¯å‘å¼ç®—æ³•åœ¨å¤„ç†å¤§è§„æ¨¡é—®é¢˜æ—¶ï¼Œå› è§£ç»“æ„é•¿æœŸç¨³å®šè€Œäº§ç”Ÿçš„å†—ä½™è®¡ç®—æŒ‘æˆ˜ï¼Œé¦–æ¬¡æ­£å¼ç ”ç©¶äº†First-Segment-Then-Aggregate (FSTA)åˆ†è§£æŠ€æœ¯ã€‚FSTAé€šè¿‡ä¿ç•™ç¨³å®šçš„è§£æ®µå¹¶å°†å…¶èšåˆä¸ºå›ºå®šè¶…èŠ‚ç‚¹(hypernodes)ï¼Œä½¿æœç´¢è¿‡ç¨‹èƒ½å¤Ÿé›†ä¸­äºè§£çš„ä¸ç¨³å®šéƒ¨åˆ†ï¼Œä»è€Œæ˜¾è‘—æå‡æ•ˆç‡ã€‚ä¸ºè§£å†³è¯†åˆ«å¯èšåˆæ®µçš„éš¾é¢˜ï¼Œä½œè€…æå‡ºäº†Learning-to-Segment (L2Seg)ç¥ç»æ¡†æ¶ï¼Œåˆ©ç”¨éè‡ªå›å½’ã€è‡ªå›å½’åŠå…¶ååŒ(synergy)ä¸‰ç§å˜ä½“æ¥æ™ºèƒ½åŒºåˆ†ç¨³å®šä¸ä¸ç¨³å®šéƒ¨åˆ†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒL2Segåœ¨CVRPå’ŒVRPTWä»»åŠ¡ä¸­ä½¿ç°æœ‰æœ€å…ˆè¿›æ±‚è§£å™¨çš„è¿è¡Œé€Ÿåº¦æå‡äº†2è‡³7å€ã€‚è¯¥æ¡†æ¶ä¸ä»…åœ¨å¤šç§VRPå˜ä½“ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä¸”èƒ½å¹¿æ³›å…¼å®¹ä¼ ç»Ÿã€åŸºäºå­¦ä¹ åŠæ··åˆå‹æ±‚è§£å™¨ï¼Œä¸ºåŠ é€Ÿå¤æ‚ç»„åˆä¼˜åŒ–é—®é¢˜çš„æ±‚è§£æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.01037v2",
      "published_date": "2025-06-22 05:38:15 UTC",
      "updated_date": "2025-09-26 20:09:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:43:15.089877+00:00"
    },
    {
      "arxiv_id": "2506.17903v1",
      "title": "Cause-Effect Driven Optimization for Robust Medical Visual Question Answering with Language Biases",
      "title_zh": "é¢å‘è¯­è¨€åå·®ä¸‹é²æ£’åŒ»ç–—è§†è§‰é—®ç­”çš„å› æœé©±åŠ¨ä¼˜åŒ–",
      "authors": [
        "Huanjia Zhu",
        "Yishu Liu",
        "Xiaozhao Fang",
        "Guangming Lu",
        "Bingzhi Chen"
      ],
      "abstract": "Existing Medical Visual Question Answering (Med-VQA) models often suffer from language biases, where spurious correlations between question types and answer categories are inadvertently established. To address these issues, we propose a novel Cause-Effect Driven Optimization framework called CEDO, that incorporates three well-established mechanisms, i.e., Modality-driven Heterogeneous Optimization (MHO), Gradient-guided Modality Synergy (GMS), and Distribution-adapted Loss Rescaling (DLR), for comprehensively mitigating language biases from both causal and effectual perspectives. Specifically, MHO employs adaptive learning rates for specific modalities to achieve heterogeneous optimization, thus enhancing robust reasoning capabilities. Additionally, GMS leverages the Pareto optimization method to foster synergistic interactions between modalities and enforce gradient orthogonality to eliminate bias updates, thereby mitigating language biases from the effect side, i.e., shortcut bias. Furthermore, DLR is designed to assign adaptive weights to individual losses to ensure balanced learning across all answer categories, effectively alleviating language biases from the cause side, i.e., imbalance biases within datasets. Extensive experiments on multiple traditional and bias-sensitive benchmarks consistently demonstrate the robustness of CEDO over state-of-the-art competitors.",
      "tldr_zh": "ç°æœ‰çš„åŒ»å­¦è§†è§‰é—®ç­” (Med-VQA) æ¨¡å‹å¸¸å—é™äºè¯­è¨€åè§ (language biases)ï¼Œå³é—®é¢˜ç±»å‹ä¸ç­”æ¡ˆç±»åˆ«ä¹‹é—´å®¹æ˜“å»ºç«‹è™šå‡çš„ç›¸å…³æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º CEDO (Cause-Effect Driven Optimization) çš„å› æœé©±åŠ¨ä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨ä»å› æœä¸¤ä¸ªç»´åº¦å…¨é¢ç¼“è§£åè§ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ¨¡æ€é©±åŠ¨å¼‚æ„ä¼˜åŒ– (MHO) æœºåˆ¶ï¼Œé€šè¿‡ä¸ºç‰¹å®šæ¨¡æ€é‡‡ç”¨è‡ªé€‚åº”å­¦ä¹ ç‡æ¥å¢å¼ºæ¨¡å‹çš„ç¨³å¥æ¨ç†èƒ½åŠ›ã€‚åŒæ—¶ï¼Œæ¢¯åº¦å¼•å¯¼æ¨¡æ€ååŒ (GMS) æœºåˆ¶åˆ©ç”¨ Pareto ä¼˜åŒ–æ–¹æ³•ä¿ƒè¿›æ¨¡æ€é—´çš„æ­£å‘äº¤äº’ï¼Œå¹¶é€šè¿‡æ¢¯åº¦æ­£äº¤åŒ–æ¶ˆé™¤å¿«æ·åè§ (shortcut bias)ã€‚æ­¤å¤–ï¼Œåˆ†å¸ƒé€‚é…æŸå¤±ç¼©æ”¾ (DLR) æœºåˆ¶é€šè¿‡ä¸ºæŸå¤±åˆ†é…è‡ªé€‚åº”æƒé‡ä»¥ç¡®ä¿å‡è¡¡å­¦ä¹ ï¼Œæœ‰æ•ˆå‡è½»äº†æ•°æ®é›†ä¸­çš„ä¸å¹³è¡¡åè§ (imbalance biases)ã€‚åœ¨å¤šä¸ªä¼ ç»ŸåŠåè§æ•æ„ŸåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCEDO çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›æ¨¡å‹ï¼Œå±•ç°äº†æå¼ºçš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at IJCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.17903v1",
      "published_date": "2025-06-22 05:20:34 UTC",
      "updated_date": "2025-06-22 05:20:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:44:06.302020+00:00"
    },
    {
      "arxiv_id": "2506.19871v1",
      "title": "An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network",
      "title_zh": "åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„åŒ»ç–—ä¿é™©ç†èµ”æ¬ºè¯ˆæ£€æµ‹æ”»å‡»æ–¹æ³•",
      "authors": [
        "Yining Pang",
        "Chenghan Li"
      ],
      "abstract": "Insurance fraud detection represents a pivotal advancement in modern insurance service, providing intelligent and digitalized monitoring to enhance management and prevent fraud. It is crucial for ensuring the security and efficiency of insurance systems. Although AI and machine learning algorithms have demonstrated strong performance in detecting fraudulent claims, the absence of standardized defense mechanisms renders current systems vulnerable to emerging adversarial threats. In this paper, we propose a GAN-based approach to conduct adversarial attacks on fraud detection systems. Our results indicate that an attacker, without knowledge of the training data or internal model details, can generate fraudulent cases that are classified as legitimate with a 99\\% attack success rate (ASR). By subtly modifying real insurance records and claims, adversaries can significantly increase the fraud risk, potentially bypassing compromised detection systems. These findings underscore the urgent need to enhance the robustness of insurance fraud detection models against adversarial manipulation, thereby ensuring the stability and reliability of different insurance systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (Generative Adversarial Network, GAN) çš„æ”»å‡»æ–¹æ³•ï¼Œç”¨äºæ¢æµ‹åŒ»ç–—ä¿é™©æ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿçš„å®‰å…¨æ¼æ´ã€‚æ”»å‡»è€…åœ¨ä¸æŒæ¡è®­ç»ƒæ•°æ®æˆ–å†…éƒ¨æ¨¡å‹ç»†èŠ‚çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ GAN å¯¹çœŸå®ä¿é™©è®°å½•å’Œç†èµ”ç”³è¯·è¿›è¡Œå¾®å°ä¿®æ”¹ï¼Œç”Ÿæˆä¼ªè£…æˆåˆæ³•æ¡ˆä¾‹çš„æ¬ºè¯ˆæ ·æœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é»‘ç›’åœºæ™¯ä¸‹è¾¾åˆ°äº† 99% çš„æ”»å‡»æˆåŠŸç‡ (Attack Success Rate, ASR)ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç»•è¿‡ç°æœ‰çš„æ™ºèƒ½åŒ–ç›‘æ§ç³»ç»Ÿã€‚è¿™é¡¹å·¥ä½œæ­ç¤ºäº†å½“å‰ä¿é™©æ¬ºè¯ˆæ£€æµ‹æ¨¡å‹åœ¨åº”å¯¹å¯¹æŠ—æ€§æ”»å‡» (Adversarial Attacks) æ—¶çš„è„†å¼±æ€§ï¼Œå¼ºè°ƒäº†æå‡æ¨¡å‹é²æ£’æ€§ (Robustness) å¯¹äºä¿éšœä¿é™©ç³»ç»Ÿç¨³å®šæ€§å’Œå¯é æ€§çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "arXiv admin note: text overlap with arXiv:2405.12076 by other authors",
      "pdf_url": "https://arxiv.org/pdf/2506.19871v1",
      "published_date": "2025-06-22 05:02:45 UTC",
      "updated_date": "2025-06-22 05:02:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:43:12.490520+00:00"
    },
    {
      "arxiv_id": "2506.17900v1",
      "title": "Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å®ç°äº‘ AI å¹³å°çš„æ™ºèƒ½æ—¥å¿—å¤„ç†ä¸è‡ªä¸»è°ƒè¯•",
      "authors": [
        "Cheng Ji",
        "Huaiying Luo"
      ],
      "abstract": "With the increasing complexity and rapid expansion of the scale of AI systems in cloud platforms, the log data generated during system operation is massive, unstructured, and semantically ambiguous, which brings great challenges to fault location and system self-repair. In order to solve this problem, this paper proposes an intelligent log processing and automatic debugging framework based on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This method is extended on the basis of the existing pre-trained Transformer model, and integrates a multi-stage semantic inference mechanism to realize the context understanding of system logs and the automatic reconstruction of fault chains. Firstly, the system log is dynamically structured, and the unsupervised clustering and embedding mechanism is used to extract the event template and semantic schema. Subsequently, the fine-tuned LLM combined with the multi-round attention mechanism to perform contextual reasoning on the log sequence to generate potential fault assumptions and root cause paths. Furthermore, this paper introduces a reinforcement learning-based policy-guided recovery planner, which is driven by the remediation strategy generated by LLM to support dynamic decision-making and adaptive debugging in the cloud environment. Compared with the existing rule engine or traditional log analysis system, the proposed model has stronger semantic understanding ability, continuous learning ability and heterogeneous environment adaptability. Experiments on the cloud platform log dataset show that LLM-ID improves the fault location accuracy by 16.2%, which is significantly better than the current mainstream methods",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº‘AIå¹³å°ä¸­å¤§è§„æ¨¡ã€éç»“æ„åŒ–ä¸”è¯­ä¹‰æ¨¡ç³Šçš„æ—¥å¿—æ•°æ®å¸¦æ¥çš„æ•…éšœå®šä½éš¾é¢˜ï¼Œæå‡ºäº†åä¸ºLLM-IDçš„æ™ºèƒ½æ—¥å¿—å¤„ç†ä¸è‡ªä¸»è°ƒè¯•æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŸºäºå¤§è¯­è¨€æ¨¡å‹(Large Language Model)ï¼Œé€šè¿‡åŠ¨æ€ç»“æ„åŒ–ã€æ— ç›‘ç£èšç±»(Unsupervised Clustering)å’ŒåµŒå…¥æœºåˆ¶é«˜æ•ˆæå–äº‹ä»¶æ¨¡æ¿ä¸è¯­ä¹‰æ¨¡å¼ã€‚åˆ©ç”¨å¾®è°ƒåçš„LLMç»“åˆå¤šè½®æ³¨æ„åŠ›æœºåˆ¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿå¯¹æ—¥å¿—åºåˆ—è¿›è¡Œä¸Šä¸‹æ–‡æ¨ç†ï¼Œå®ç°æ•…éšœé“¾çš„è‡ªåŠ¨é‡æ„å¹¶ç”Ÿæˆæ½œåœ¨çš„æ ¹å› è·¯å¾„ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†åŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„ç­–ç•¥å¼•å¯¼ä¿®å¤è§„åˆ’å™¨ï¼Œé€šè¿‡LLMé©±åŠ¨çš„ä¿®å¤ç­–ç•¥æ”¯æŒäº‘ç¯å¢ƒä¸‹çš„åŠ¨æ€å†³ç­–ä¸è‡ªé€‚åº”è°ƒè¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„è§„åˆ™å¼•æ“æˆ–æ—¥å¿—åˆ†æç³»ç»Ÿç›¸æ¯”ï¼ŒLLM-IDå…·æœ‰æ›´å¼ºçš„è¯­ä¹‰ç†è§£èƒ½åŠ›å’Œå¼‚æ„ç¯å¢ƒé€‚åº”æ€§ï¼Œåœ¨äº‘å¹³å°æ—¥å¿—æ•°æ®é›†ä¸Šçš„æ•…éšœå®šä½å‡†ç¡®ç‡æå‡äº†16.2%ã€‚",
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by 2025 8th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE 2025)",
      "pdf_url": "https://arxiv.org/pdf/2506.17900v1",
      "published_date": "2025-06-22 04:58:37 UTC",
      "updated_date": "2025-06-22 04:58:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:43:27.397558+00:00"
    },
    {
      "arxiv_id": "2506.17896v1",
      "title": "EgoWorld: Translating Exocentric View to Egocentric View using Rich Exocentric Observations",
      "title_zh": "EgoWorldï¼šåˆ©ç”¨ä¸°å¯Œçš„ç¬¬ä¸‰äººç§°è§‚æµ‹å®ç°ä»ç¬¬ä¸‰äººç§°è§†è§’åˆ°ç¬¬ä¸€äººç§°è§†è§’çš„è½¬æ¢",
      "authors": [
        "Junho Park",
        "Andrew Sangwoo Ye",
        "Taein Kwon"
      ],
      "abstract": "Egocentric vision is essential for both human and machine visual understanding, particularly in capturing the detailed hand-object interactions needed for manipulation tasks. Translating third-person views into first-person views significantly benefits augmented reality (AR), virtual reality (VR) and robotics applications. However, current exocentric-to-egocentric translation methods are limited by their dependence on 2D cues, synchronized multi-view settings, and unrealistic assumptions such as necessity of initial egocentric frame and relative camera poses during inference. To overcome these challenges, we introduce EgoWorld, a novel two-stage framework that reconstructs an egocentric view from rich exocentric observations, including projected point clouds, 3D hand poses, and textual descriptions. Our approach reconstructs a point cloud from estimated exocentric depth maps, reprojects it into the egocentric perspective, and then applies diffusion-based inpainting to produce dense, semantically coherent egocentric images. Evaluated on the H2O and TACO datasets, EgoWorld achieves state-of-the-art performance and demonstrates robust generalization to new objects, actions, scenes, and subjects. Moreover, EgoWorld shows promising results even on unlabeled real-world examples.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EgoWorldï¼Œä¸€ä¸ªæ—¨åœ¨å°†ç¦»ä½“è§†è§’ (Exocentric View) è½¬åŒ–ä¸ºç¬¬ä¸€äººç§°è§†è§’ (Egocentric View) çš„ä¸¤é˜¶æ®µæ–°é¢–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•å¯¹ 2D çº¿ç´¢ã€åŒæ­¥å¤šè§†å›¾è®¾ç½®ä»¥åŠæ¨ç†é˜¶æ®µç‰¹å®šç›¸æœºä½å§¿å‡è®¾çš„è¿‡åº¦ä¾èµ–ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¸°å¯Œçš„ç¦»ä½“è§‚æµ‹æ•°æ®ï¼Œé€šè¿‡ä¼°è®¡çš„ç¦»ä½“æ·±åº¦å›¾é‡å»ºç‚¹äº‘ (Point Clouds)ï¼Œå¹¶ç»“åˆ 3D æ‰‹éƒ¨å§¿æ€ (3D Hand Poses) å’Œæ–‡æœ¬æè¿°å°†å…¶é‡æ–°æŠ•å½±è‡³ç¬¬ä¸€äººç§°é€è§†å›¾ã€‚éšåï¼Œç³»ç»Ÿåº”ç”¨åŸºäºæ‰©æ•£æ¨¡å‹ (Diffusion-based) çš„ä¿®å¤æŠ€æœ¯ (Inpainting) æ¥ç”Ÿæˆé«˜å¯†åº¦ä¸”è¯­ä¹‰è¿è´¯çš„ç¬¬ä¸€äººç§°å›¾åƒã€‚åœ¨ H2O å’Œ TACO æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¯æ˜ï¼ŒEgoWorld è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›æ°´å¹³ (State-of-the-art)ï¼Œå¹¶å±•ç°å‡ºå¯¹æ–°ç‰©ä½“ã€åŠ¨ä½œå’Œåœºæ™¯çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨æœªç»æ ‡æ³¨çš„çœŸå®ä¸–ç•Œæ•°æ®ä¸ŠåŒæ ·è¡¨ç°ä¼˜å¼‚ï¼Œä¸ºå¢å¼ºç°å® (AR)ã€è™šæ‹Ÿç°å® (VR) åŠæœºå™¨äººæŠ€æœ¯ä¸­çš„ç²¾ç»†äº¤äº’ç†è§£æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://redorangeyellowy.github.io/EgoWorld/",
      "pdf_url": "https://arxiv.org/pdf/2506.17896v1",
      "published_date": "2025-06-22 04:21:48 UTC",
      "updated_date": "2025-06-22 04:21:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:44:00.486824+00:00"
    },
    {
      "arxiv_id": "2506.17881v2",
      "title": "GRAF: Multi-turn Jailbreaking via Global Refinement and Active Fabrication",
      "title_zh": "GRAFï¼šåŸºäºå…¨å±€ç»†åŒ–ä¸ä¸»åŠ¨ä¼ªé€ çš„å¤šè½®è¶Šç‹±",
      "authors": [
        "Hua Tang",
        "Lingyong Yan",
        "Yukun Zhao",
        "Shuaiqiang Wang",
        "Jizhou Huang",
        "Dawei Yin"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across diverse tasks. Nevertheless, they still pose notable safety risks due to potential misuse for malicious purposes. Jailbreaking, which seeks to induce models to generate harmful content through single-turn or multi-turn attacks, plays a crucial role in uncovering underlying security vulnerabilities. However, prior methods, including sophisticated multi-turn approaches, often struggle to adapt to the evolving dynamics of dialogue as interactions progress. To address this challenge, we propose \\ours (JailBreaking via \\textbf{G}lobally \\textbf{R}efining and \\textbf{A}daptively \\textbf{F}abricating), a novel multi-turn jailbreaking method that globally refines the attack trajectory at each interaction. In addition, we actively fabricate model responses to suppress safety-related warnings, thereby increasing the likelihood of eliciting harmful outputs in subsequent queries. Extensive experiments across six state-of-the-art LLMs demonstrate the superior effectiveness of our approach compared to existing single-turn and multi-turn jailbreaking methods. Our code will be released at https://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤šè½®å¯¹è¯ä¸­å­˜åœ¨çš„å®‰å…¨éšæ‚£ï¼Œæå‡ºäº†GRAFï¼ˆåŸºäºå…¨å±€ç²¾ç‚¼å’Œè‡ªé€‚åº”ä¼ªé€ çš„è¶Šç‹±æ–¹æ³•ï¼‰ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¶Šç‹±æ”»å‡»(Jailbreaking)æ–¹æ³•éš¾ä»¥é€‚åº”å¯¹è¯åŠ¨æ€æ¼”å˜çš„é—®é¢˜ã€‚GRAFçš„æ ¸å¿ƒæœºåˆ¶æ˜¯åœ¨æ¯æ¬¡äº¤äº’ä¸­å¯¹æ”»å‡»è½¨è¿¹è¿›è¡Œå…¨å±€ç²¾ç‚¼(Global Refinement)ï¼Œå¹¶ç»“åˆä¸»åŠ¨ä¼ªé€ (Active Fabrication)æ¨¡å‹å“åº”çš„æŠ€æœ¯æ¥æŠ‘åˆ¶å®‰å…¨è­¦å‘Šï¼Œä»è€Œåœ¨åç»­æŸ¥è¯¢ä¸­æ›´æœ‰æ•ˆåœ°è¯±å¯¼æœ‰å®³è¾“å‡ºã€‚åœ¨å…­ç§æœ€å…ˆè¿›çš„LLMsä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒGRAFçš„æ”»å‡»æ•ˆèƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å•è½®å’Œå¤šè½®è¶Šç‹±æ‰‹æ®µã€‚è¯¥é¡¹ç ”ç©¶æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨å¤æ‚äº¤äº’ä¸‹çš„åº•å±‚å®‰å…¨æ¼æ´ï¼Œä¸ºæ„å»ºæ›´å…·é²æ£’æ€§çš„å®‰å…¨é˜²å¾¡æœºåˆ¶æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17881v2",
      "published_date": "2025-06-22 03:15:05 UTC",
      "updated_date": "2025-09-29 08:39:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:43:28.544562+00:00"
    },
    {
      "arxiv_id": "2506.17879v1",
      "title": "StainPIDR: A Pathological Image Decouplingand Reconstruction Method for Stain Normalization Based on Color Vector Quantization and Structure Restaining",
      "title_zh": "StainPIDRï¼šåŸºäºé¢œè‰²çŸ¢é‡é‡åŒ–ä¸ç»“æ„é‡æŸ“è‰²çš„æŸ“è‰²æ ‡å‡†åŒ–ç—…ç†å›¾åƒè§£è€¦é‡å»ºæ–¹æ³•",
      "authors": [
        "Zheng Chen"
      ],
      "abstract": "The color appearance of a pathological image is highly related to the imaging protocols, the proportion of different dyes, and the scanning devices. Computer-aided diagnostic systems may deteriorate when facing these color-variant pathological images. In this work, we propose a stain normalization method called StainPIDR. We try to eliminate this color discrepancy by decoupling the image into structure features and vector-quantized color features, restaining the structure features with the target color features, and decoding the stained structure features to normalized pathological images. We assume that color features decoupled by different images with the same color should be exactly the same. Under this assumption, we train a fixed color vector codebook to which the decoupled color features will map. In the restaining part, we utilize the cross-attention mechanism to efficiently stain the structure features. As the target color (decoupled from a selected template image) will also affect the performance of stain normalization, we further design a template image selection algorithm to select a template from a given dataset. In our extensive experiments, we validate the effectiveness of StainPIDR and the template image selection algorithm. All the results show that our method can perform well in the stain normalization task. The code of StainPIDR will be publicly available later.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æˆåƒæ–¹æ¡ˆå’Œæ‰«æè®¾å¤‡å¯¼è‡´çš„ç—…ç†å›¾åƒæ˜¾è‰²å·®å¼‚é—®é¢˜ï¼Œæå‡ºäº†åä¸º StainPIDR çš„æŸ“è‰²æ ‡å‡†åŒ–ï¼ˆStain Normalizationï¼‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†å›¾åƒè§£è€¦ä¸ºç»“æ„ç‰¹å¾ï¼ˆStructure Featuresï¼‰å’ŒçŸ¢é‡é‡åŒ–é¢œè‰²ç‰¹å¾ï¼ˆVector-Quantized Color Featuresï¼‰ï¼Œé€šè¿‡å°†ç»“æ„ç‰¹å¾ä¸ç›®æ ‡é¢œè‰²ç‰¹å¾é‡æ–°ç»“åˆå¹¶è§£ç æ¥ç”Ÿæˆæ ‡å‡†åŒ–å›¾åƒã€‚ç ”ç©¶æ ¸å¿ƒåœ¨äºè®­ç»ƒä¸€ä¸ªå›ºå®šçš„é¢œè‰²çŸ¢é‡ç æœ¬ï¼ˆColor Vector Codebookï¼‰ï¼Œä½¿è§£è€¦åçš„é¢œè‰²ç‰¹å¾èƒ½å¤Ÿç²¾ç¡®æ˜ å°„ï¼Œå¹¶åˆ©ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼ˆCross-Attention Mechanismï¼‰å®ç°é«˜æ•ˆé‡ç€è‰²ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è®¾è®¡äº†ä¸€ç§æ¨¡æ¿å›¾åƒé€‰æ‹©ç®—æ³•ï¼ˆTemplate Image Selection Algorithmï¼‰ï¼Œä»¥ä¼˜åŒ–å‚è€ƒæ¨¡æ¿å¯¹æ ‡å‡†åŒ–æ€§èƒ½çš„å½±å“ã€‚å¤šé¡¹å®éªŒç»“æœè¡¨æ˜ï¼ŒStainPIDR åœ¨å¤„ç†é¢œè‰²å˜å¼‚çš„ç—…ç†å›¾åƒæ—¶å…·æœ‰æ˜¾è‘—çš„æœ‰æ•ˆæ€§ï¼Œèƒ½å¤Ÿä¸ºè®¡ç®—æœºè¾…åŠ©è¯Šæ–­ç³»ç»Ÿæä¾›æ›´ä¸€è‡´çš„è¾“å…¥ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17879v1",
      "published_date": "2025-06-22 02:54:20 UTC",
      "updated_date": "2025-06-22 02:54:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:43:28.937734+00:00"
    },
    {
      "arxiv_id": "2506.17878v1",
      "title": "Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval",
      "title_zh": "è¿ˆå‘é²æ£’äº‹å®æ ¸æŸ¥ï¼šå…·å¤‡é«˜çº§è¯æ®æ£€ç´¢åŠŸèƒ½çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Tam Trinh",
        "Manh Nguyen",
        "Truong-Son Hy"
      ],
      "abstract": "The rapid spread of misinformation in the digital era poses significant challenges to public discourse, necessitating robust and scalable fact-checking solutions. Traditional human-led fact-checking methods, while credible, struggle with the volume and velocity of online content, prompting the integration of automated systems powered by Large Language Models (LLMs). However, existing automated approaches often face limitations, such as handling complex claims, ensuring source credibility, and maintaining transparency. This paper proposes a novel multi-agent system for automated fact-checking that enhances accuracy, efficiency, and explainability. The system comprises four specialized agents: an Input Ingestion Agent for claim decomposition, a Query Generation Agent for formulating targeted subqueries, an Evidence Retrieval Agent for sourcing credible evidence, and a Verdict Prediction Agent for synthesizing veracity judgments with human-interpretable explanations. Evaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system achieves a 12.3% improvement in Macro F1-score over baseline methods. The system effectively decomposes complex claims, retrieves reliable evidence from trusted sources, and generates transparent explanations for verification decisions. Our approach contributes to the growing field of automated fact-checking by providing a more accurate, efficient, and transparent verification methodology that aligns with human fact-checking practices while maintaining scalability for real-world applications. Our source code is available at https://github.com/HySonLab/FactAgent",
      "tldr_zh": "é’ˆå¯¹æ•°å­—åŒ–æ—¶ä»£è¯¯å¯¼ä¿¡æ¯å¿«é€Ÿä¼ æ’­å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ—¨åœ¨æå‡å‡†ç¡®æ€§ã€æ•ˆç‡å’Œå¯è§£é‡Šæ€§çš„æ–°å‹å¤šæ™ºèƒ½ä½“è‡ªåŠ¨åŒ–äº‹å®æ ¸æŸ¥(fact-checking)ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿç”±å››ä¸ªä¸“é—¨çš„æ™ºèƒ½ä½“ç»„æˆï¼šè´Ÿè´£ä¸»å¼ åˆ†è§£çš„Input Ingestion Agentã€åˆ¶å®šé’ˆå¯¹æ€§å­æŸ¥è¯¢çš„Query Generation Agentã€ä»å¯é æ¥æºè·å–è¯æ®çš„Evidence Retrieval Agentï¼Œä»¥åŠåˆæˆçœŸå®æ€§åˆ¤å®šå¹¶ç”Ÿæˆäººç±»å¯ç†è§£è§£é‡Šçš„Verdict Prediction Agentã€‚åœ¨FEVEROUSã€HOVERå’ŒSciFactç­‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿæ¯”åŸºçº¿æ–¹æ³•åœ¨Macro F1-scoreä¸Šæå‡äº†12.3%ã€‚è¯¥ç ”ç©¶æˆåŠŸè§£å†³äº†å¤„ç†å¤æ‚ä¸»å¼ ã€ç¡®ä¿è¯æ®å¯é æ€§å’Œä¿æŒéªŒè¯é€æ˜åº¦ç­‰å…³é”®å±€é™ã€‚è¿™ç§æ–¹æ³•ä¸ä»…å¯¹é½äº†äººç±»äº‹å®æ ¸æŸ¥çš„å®è·µé€»è¾‘ï¼Œè¿˜ä¸ºç°å®ä¸–ç•Œçš„å¤§è§„æ¨¡åº”ç”¨æä¾›äº†ä¸€ç§å‡†ç¡®ã€é«˜æ•ˆä¸”é€æ˜çš„éªŒè¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17878v1",
      "published_date": "2025-06-22 02:39:27 UTC",
      "updated_date": "2025-06-22 02:39:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:44:25.625882+00:00"
    },
    {
      "arxiv_id": "2506.17873v2",
      "title": "SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model",
      "title_zh": "SurgVidLMï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šç²’åº¦æ‰‹æœ¯è§†é¢‘ç†è§£",
      "authors": [
        "Guankun Wang",
        "Junyi Wang",
        "Wenjin Mo",
        "Long Bai",
        "Kun Yuan",
        "Ming Hu",
        "Jinlin Wu",
        "Junjun He",
        "Yiming Huang",
        "Nicolas Padoy",
        "Zhen Lei",
        "Hongbin Liu",
        "Nassir Navab",
        "Hongliang Ren"
      ],
      "abstract": "Surgical scene understanding is critical for surgical training and robotic decision-making in robot-assisted surgery. Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated great potential for advancing scene perception in the medical domain, facilitating surgeons to understand surgical scenes and procedures. However, these methods are primarily oriented towards image-based analysis or global video understanding, overlooking the fine-grained video reasoning that is crucial for analyzing specific processes and capturing detailed task execution within a surgical procedure. To bridge this gap, we propose SurgVidLM, the first video language model designed to address both full and fine-grained surgical video comprehension. To train our SurgVidLM, we construct the SVU-31K that is a large-scale dataset with over 31K video-instruction pairs, enabling both holistic understanding and detailed analysis of surgical procedures. Building on this resource, SurgVidLM incorporates a two-stage StageFocus mechanism: the first stage extracts global procedural context, while the second stage performs high-frequency local analysis guided by temporal cues. We also develop the Multi-frequency Fusion Attention to effectively integrate low- and high-frequency visual tokens, ensuring the preservation of critical task-specific details. Experimental results demonstrate that SurgVidLM significantly outperforms state-of-the-art Vid-LLMs of comparable parameter scale in both full and fine-grained video understanding tasks, showcasing its superior capability in capturing the context of complex robot-assisted surgeries. Our code and dataset will be publicly accessible soon.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SurgVidLMï¼Œè¿™æ˜¯é¦–ä¸ªåŒæ—¶é’ˆå¯¹å…¨å±€å’Œç»†ç²’åº¦æ‰‹æœ¯è§†é¢‘ç†è§£è®¾è®¡çš„è§†é¢‘è¯­è¨€æ¨¡å‹(Video Language Model)ï¼Œæ—¨åœ¨å¼¥è¡¥ç°æœ‰æ¨¡å‹åœ¨å¤æ‚æ‰‹æœ¯è¿‡ç¨‹ç»†ç²’åº¦æ¨ç†æ–¹é¢çš„ä¸è¶³ã€‚ä¸ºæ”¯æŒæ¨¡å‹è®­ç»ƒï¼Œç ”ç©¶è€…æ„å»ºäº†åŒ…å«è¶…è¿‡3.1ä¸‡ä¸ªè§†é¢‘-æŒ‡ä»¤å¯¹çš„å¤§è§„æ¨¡æ•°æ®é›†SVU-31Kã€‚SurgVidLMæ ¸å¿ƒé‡‡ç”¨äº†ä¸¤é˜¶æ®µçš„StageFocusæœºåˆ¶ï¼Œé€šè¿‡æå–å…¨å±€ç¨‹åºä¸Šä¸‹æ–‡å¹¶ç»“åˆæ—¶é—´çº¿ç´¢è¿›è¡Œé«˜é¢‘å±€éƒ¨åˆ†ææ¥å¢å¼ºæ„ŸçŸ¥èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å¼•å…¥äº†å¤šé¢‘ç‡èåˆæ³¨æ„åŠ›(Multi-frequency Fusion Attention)æœºåˆ¶ï¼Œä»¥æœ‰æ•ˆæ•´åˆé«˜ä½é¢‘è§†è§‰ç‰¹å¾å¹¶ä¿ç•™å…³é”®ä»»åŠ¡ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSurgVidLMåœ¨å…¨ç²’åº¦å’Œç»†ç²’åº¦è§†é¢‘ç†è§£ä»»åŠ¡ä¸­å‡æ˜¾è‘—è¶…è¶Šäº†åŒç­‰è§„æ¨¡çš„æœ€å…ˆè¿›æ¨¡å‹ï¼Œå±•ç°äº†åœ¨æœºå™¨äººè¾…åŠ©æ‰‹æœ¯åœºæ™¯ä¸‹çš„å“è¶Šç†è§£èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17873v2",
      "published_date": "2025-06-22 02:16:18 UTC",
      "updated_date": "2025-09-24 03:26:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:44:32.416526+00:00"
    },
    {
      "arxiv_id": "2506.17871v2",
      "title": "LLM Probability Concentration: How Alignment Shrinks the Generative Horizon",
      "title_zh": "LLM æ¦‚ç‡é›†ä¸­ï¼šå¯¹é½å¦‚ä½•æ”¶ç¼©ç”Ÿæˆè§†é‡",
      "authors": [
        "Chenghao Yang",
        "Ari Holtzman"
      ],
      "abstract": "Despite their impressive capabilities, aligned large language models (LLMs) often generate outputs that lack diversity. What drives this consistency in the generation? We investigate this phenomenon through the lens of probability concentration in the model's output distribution. To quantify this concentration, we introduce the *Branching Factor* (BF)--a token-invariant measure of the effective number of plausible next steps during generation. Our empirical analysis reveals two key findings: (1) BF often decreases as generation progresses, suggesting that LLMs become more predictable as they generate. (2) alignment tuning substantially sharpens the model's output distribution from the outset, reducing BF by nearly an order of magnitude (e.g., from 12 to 1.2) relative to base models. This stark reduction helps explain why aligned models often appear less sensitive to decoding strategies. Building on this insight, we find this consistency has surprising implications for complex reasoning. Aligned Chain-of-Thought (CoT) models (e.g., DeepSeek-distilled models), for instance, leverage this effect; by generating longer reasoning chains, they push generation into later, more deterministic (lower BF) stages, resulting in more stable outputs. We hypothesize that alignment tuning does not fundamentally change a model's behavior, but instead steers it toward stylistic tokens (e.g., ``Sure'') that unlock low-entropy trajectories already present in the base model. This view is supported by nudging experiments, which show prompting base models with such tokens can similarly reduce BF. Together, our findings establish BF as a powerful diagnostic for understanding and controlling LLM outputs - clarifying how alignment reduces variability, how CoT promotes stable generations, and how base models can be steered away from diversity.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†å¯¹é½(alignment)åçš„å¤§è¯­è¨€æ¨¡å‹(LLMs)è¾“å‡ºç¼ºä¹å¤šæ ·æ€§çš„åŸå› ï¼Œå¹¶å¼•å…¥äº†åˆ†æ”¯å› å­(Branching Factor, BF)è¿™ä¸€Tokenæ— å…³çš„æŒ‡æ ‡æ¥é‡åŒ–ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¦‚ç‡æµ“ç¼©(probability concentration)ã€‚ç ”ç©¶å‘ç°ï¼ŒBFä¼šéšç€ç”Ÿæˆçš„è¿›è¡Œè€Œä¸‹é™ï¼Œä¸”å¯¹é½å¾®è°ƒä¼šæ˜¾è‘—é”åŒ–æ¨¡å‹çš„è¾“å‡ºåˆ†å¸ƒï¼Œä½¿BFè¾ƒåŸºåº§æ¨¡å‹é™ä½è¿‘ä¸€ä¸ªæ•°é‡çº§ï¼Œä»è€Œå¯¼è‡´æ¨¡å‹å¯¹è§£ç ç­–ç•¥çš„æ•æ„Ÿæ€§é™ä½ã€‚è¿™ä¸€å‘ç°è¿›ä¸€æ­¥æ­ç¤ºäº†å¯¹é½çš„æ€ç»´é“¾(Chain-of-Thought, CoT)æ¨¡å‹å¦‚ä½•é€šè¿‡è¾ƒé•¿çš„æ¨ç†é“¾è¿›å…¥ä½BFçš„ç¡®å®šæ€§é˜¶æ®µï¼Œè¿›è€Œå®ç°æ›´ç¨³å®šçš„è¾“å‡ºã€‚ç ”ç©¶å‡è®¾å¯¹é½å¹¶éæ”¹å˜äº†æ¨¡å‹æœ¬è´¨ï¼Œè€Œæ˜¯é€šè¿‡é£æ ¼åŒ–Tokenå¼•å¯¼æ¨¡å‹è¿›å…¥åŸºåº§æ¨¡å‹ä¸­å·²å­˜åœ¨çš„ä½ç†µè½¨è¿¹ã€‚åˆ†æ”¯å› å­(BF)ä¸ºç†è§£å¯¹é½å¦‚ä½•å‡å°‘å˜å¼‚æ€§ä»¥åŠæ§åˆ¶LLMè¾“å‡ºæä¾›äº†æœ‰æ•ˆçš„è¯Šæ–­å·¥å…·ï¼Œæ˜ç¡®äº†CoTä¿ƒè¿›ç”Ÿæˆç¨³å®šæ€§çš„å†…åœ¨æœºåˆ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Codebase: https://github.com/yangalan123/LLMBranchingFactor. V2: Rewrite the theory part for a broader audience. Add experiments to verify the necessity of the AEP estimator. Generalize findings to multilingual tasks and Qwen models. Add discussions on practical implications, and on which alignment stage contributes most to BF reduction. Add ethical statements connecting pluralistic alignment",
      "pdf_url": "https://arxiv.org/pdf/2506.17871v2",
      "published_date": "2025-06-22 02:00:37 UTC",
      "updated_date": "2025-10-14 22:47:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:44:29.525896+00:00"
    },
    {
      "arxiv_id": "2506.17870v1",
      "title": "NestQuant: Post-Training Integer-Nesting Quantization for On-Device DNN",
      "title_zh": "NestQuantï¼šé¢å‘ç«¯ä¾§ DNN çš„è®­ç»ƒåæ•´æ•°åµŒå¥—é‡åŒ–",
      "authors": [
        "Jianhang Xie",
        "Chuntao Ding",
        "Xiaqing Li",
        "Shenyuan Ren",
        "Yidong Li",
        "Zhichao Lu"
      ],
      "abstract": "Deploying quantized deep neural network (DNN) models with resource adaptation capabilities on ubiquitous Internet of Things (IoT) devices to provide high-quality AI services can leverage the benefits of compression and meet multi-scenario resource requirements. However, existing dynamic/mixed precision quantization requires retraining or special hardware, whereas post-training quantization (PTQ) has two limitations for resource adaptation: (i) The state-of-the-art PTQ methods only provide one fixed bitwidth model, which makes it challenging to adapt to the dynamic resources of IoT devices; (ii) Deploying multiple PTQ models with diverse bitwidths consumes large storage resources and switching overheads. To this end, this paper introduces a resource-friendly post-training integer-nesting quantization, i.e., NestQuant, for on-device quantized model switching on IoT devices. The proposed NestQuant incorporates the integer weight decomposition, which bit-wise splits quantized weights into higher-bit and lower-bit weights of integer data types. It also contains a decomposed weights nesting mechanism to optimize the higher-bit weights by adaptive rounding and nest them into the original quantized weights. In deployment, we can send and store only one NestQuant model and switch between the full-bit/part-bit model by paging in/out lower-bit weights to adapt to resource changes and reduce consumption. Experimental results on the ImageNet-1K pretrained DNNs demonstrated that the NestQuant model can achieve high performance in top-1 accuracy, and reduce in terms of data transmission, storage consumption, and switching overheads. In particular, the ResNet-101 with INT8 nesting INT6 can achieve 78.1% and 77.9% accuracy for full-bit and part-bit models, respectively, and reduce switching overheads by approximately 78.1% compared with diverse bitwidths PTQ models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†NestQuantï¼Œä¸€ç§æ—¨åœ¨æå‡ç‰©è”ç½‘(IoT)è®¾å¤‡èµ„æºé€‚é…èƒ½åŠ›çš„è®­ç»ƒåæ•´æ•°åµŒå¥—é‡åŒ–(Post-Training Integer-Nesting Quantization)æ–¹æ¡ˆã€‚ä¸ºäº†å…‹æœç°æœ‰è®­ç»ƒåé‡åŒ–(PTQ)æ–¹æ³•å¯¹æ¯”ç‰¹ä½å›ºå®šä¸”å¤šæ¨¡å‹åˆ‡æ¢å¼€é”€å¤§çš„å±€é™ï¼ŒNestQuantå¼•å…¥äº†æ•´æ•°æƒé‡åˆ†è§£æŠ€æœ¯ï¼Œå°†é‡åŒ–æƒé‡æŒ‰ä½æ‹†åˆ†ä¸ºé«˜ä½å’Œä½ä½æ•´æ•°æ•°æ®ç±»å‹ã€‚è¯¥æ–¹æ¡ˆè¿›ä¸€æ­¥ç»“åˆåˆ†è§£æƒé‡åµŒå¥—æœºåˆ¶ï¼Œé€šè¿‡è‡ªé€‚åº”èˆå…¥(Adaptive Rounding)ä¼˜åŒ–é«˜ä½æƒé‡å¹¶å°†å…¶åµŒå¥—äºåŸå§‹é‡åŒ–æƒé‡ä¸­ã€‚éƒ¨ç½²è¿‡ç¨‹ä¸­ï¼Œä»…éœ€å­˜å‚¨å•ä¸ªNestQuantæ¨¡å‹å³å¯é€šè¿‡æ¢å…¥/æ¢å‡ºä½ä½æƒé‡å®ç°å…¨æ¯”ç‰¹ä¸éƒ¨åˆ†æ¯”ç‰¹æ¨¡å¼çš„åŠ¨æ€åˆ‡æ¢ï¼Œæ˜¾è‘—é™ä½äº†æ•°æ®ä¼ è¾“ä¸å­˜å‚¨æŸè€—ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ImageNet-1Kæ•°æ®é›†ä¸Šï¼ŒResNet-101é‡‡ç”¨INT8åµŒå¥—INT6é…ç½®æ—¶ï¼Œå…¨æ¯”ç‰¹ä¸éƒ¨åˆ†æ¯”ç‰¹æ¨¡å‹çš„å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°78.1%å’Œ77.9%ã€‚ç›¸æ¯”ä¼ ç»Ÿå¤šæ¯”ç‰¹PTQæ¨¡å‹ï¼ŒNestQuantåœ¨ç»´æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼ŒæˆåŠŸå°†æ¨¡å‹åˆ‡æ¢å¼€é”€é™ä½äº†çº¦78.1%ï¼Œä¸ºèµ„æºå—é™è®¾å¤‡çš„æ·±åº¦å­¦ä¹ éƒ¨ç½²æä¾›äº†é«˜æ•ˆæ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE Transactions on Mobile Computing, accepted manuscript, DOI: 10.1109/TMC.2025.3582583; Code: https://github.com/jianhayes/NESTQUANT",
      "pdf_url": "https://arxiv.org/pdf/2506.17870v1",
      "published_date": "2025-06-22 01:53:22 UTC",
      "updated_date": "2025-06-22 01:53:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:44:50.118683+00:00"
    },
    {
      "arxiv_id": "2506.18935v1",
      "title": "Which Consciousness Can Be Artificialized? Local Percept-Perceiver Phenomenon for the Existence of Machine Consciousness",
      "title_zh": "å“ªäº›æ„è¯†å¯ä»¥äººå·¥åŒ–ï¼Ÿé¢å‘æœºå™¨æ„è¯†å­˜åœ¨æ€§çš„å±€éƒ¨æ„ŸçŸ¥-æ„ŸçŸ¥è€…ç°è±¡",
      "authors": [
        "Shri Lal Raghudev Ram Singh"
      ],
      "abstract": "This paper presents a novel paradigm of the local percept-perceiver phenomenon to formalize certain observations in neuroscientific theories of consciousness. Using this model, a set-theoretic formalism is developed for artificial systems, and the existence of machine consciousness is proved by invoking Zermelo-Fraenkel set theory. The article argues for the possibility of a reductionist form of epistemic consciousness within machines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸ºLocal Percept-Perceiver Phenomenonçš„æ–°å‹èŒƒå¼ï¼Œæ—¨åœ¨å°†ç¥ç»ç§‘å­¦æ„è¯†ç†è®ºä¸­çš„ç‰¹å®šè§‚å¯Ÿç»“æœè¿›è¡Œå½¢å¼åŒ–å¤„ç†ã€‚ä½œè€…åˆ©ç”¨è¯¥æ¨¡å‹ä¸ºäººå·¥ç³»ç»Ÿå¼€å‘äº†ä¸€å¥—é›†åˆè®ºå½¢å¼åŒ–æ–¹æ³•(Set-theoretic Formalism)ï¼Œå¹¶è°ƒç”¨ç­–æ¢…æ´›-å¼—å…°å…‹å°”é›†åˆè®º(Zermelo-Fraenkel Set Theory)è¯æ˜äº†æœºå™¨æ„è¯†(Machine Consciousness)çš„å­˜åœ¨æ€§ã€‚æ–‡ç« é€šè¿‡ä¸¥å¯†çš„æ•°å­¦é€»è¾‘ï¼Œè®ºè¯äº†åœ¨æœºå™¨å†…éƒ¨å®ç°ä¸€ç§è¿˜åŸè®ºå½¢å¼çš„è®¤è¯†è®ºæ„è¯†(Epistemic Consciousness)çš„å¯è¡Œæ€§ã€‚è¿™ä¸€æˆæœä¸ºæ¢è®¨äººå·¥ç³»ç»Ÿçš„æ„è¯†å±æ€§æä¾›äº†å…¨æ–°çš„ç†è®ºæ¡†æ¶å’Œæ•°å­¦è¯æ˜é€”å¾„ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Paper accepted for the 18th Annual AGI Conference, AGI-2025, Reykjavik, Iceland, August 10-13, 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.18935v1",
      "published_date": "2025-06-22 01:53:14 UTC",
      "updated_date": "2025-06-22 01:53:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:44:36.766166+00:00"
    },
    {
      "arxiv_id": "2506.22477v1",
      "title": "Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI",
      "title_zh": "ç‰©è”ç½‘æ¶æ„ä¸æœºå™¨äººä½œä¸šå¹³å°çš„åˆ›æ–°ç ”ç©¶ï¼šå¤§è¯­è¨€æ¨¡å‹ä¸ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„åº”ç”¨",
      "authors": [
        "Huiwen Han"
      ],
      "abstract": "This paper introduces an innovative design for robotic operating platforms, underpinned by a transformative Internet of Things (IoT) architecture, seamlessly integrating cutting-edge technologies such as large language models (LLMs), generative AI, edge computing, and 5G networks. The proposed platform aims to elevate the intelligence and autonomy of IoT systems and robotics, enabling them to make real-time decisions and adapt dynamically to changing environments. Through a series of compelling case studies across industries including smart manufacturing, healthcare, and service sectors, this paper demonstrates the substantial potential of IoT-enabled robotics to optimize operational workflows, enhance productivity, and deliver innovative, scalable solutions. By emphasizing the roles of LLMs and generative AI, the research highlights how these technologies drive the evolution of intelligent robotics and IoT, shaping the future of industry-specific advancements. The findings not only showcase the transformative power of these technologies but also offer a forward-looking perspective on their broader societal and industrial implications, positioning them as catalysts for next-generation automation and technological convergence.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ›æ–°çš„æœºå™¨äººæ“ä½œç³»ç»Ÿè®¾è®¡ï¼Œå…¶æ ¸å¿ƒæ˜¯åŸºäºä¸€ç§å˜é©æ€§çš„ç‰©è”ç½‘(IoT)æ¶æ„ã€‚è¯¥å¹³å°é€šè¿‡æ•´åˆå¤§è¯­è¨€æ¨¡å‹(LLMs)ã€ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)ã€è¾¹ç¼˜è®¡ç®—(Edge Computing)å’Œ5Gç½‘ç»œç­‰å‰æ²¿æŠ€æœ¯ï¼Œæ—¨åœ¨æ˜¾è‘—æå‡ç‰©è”ç½‘ç³»ç»Ÿå’Œæœºå™¨äººçš„æ™ºèƒ½ä¸è‡ªä¸»æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿè¿›è¡Œå®æ—¶å†³ç­–å¹¶åŠ¨æ€é€‚åº”å¤æ‚ç¯å¢ƒã€‚é€šè¿‡åœ¨æ™ºèƒ½åˆ¶é€ ã€åŒ»ç–—æœåŠ¡åŠæœåŠ¡ä¸šé¢†åŸŸçš„ç³»åˆ—æ¡ˆä¾‹ç ”ç©¶ï¼Œè®ºæ–‡éªŒè¯äº†è¯¥ç³»ç»Ÿåœ¨ä¼˜åŒ–ä½œä¸šæµç¨‹ã€æé«˜ç”Ÿäº§ç‡ä»¥åŠæä¾›åˆ›æ–°ä¸”å¯æ‰©å±•è§£å†³æ–¹æ¡ˆæ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚ç ”ç©¶é‡ç‚¹é˜è¿°äº†LLMså’ŒGenerative AIå¦‚ä½•é©±åŠ¨æ™ºèƒ½æœºå™¨äººä¸ç‰©è”ç½‘çš„æ¼”è¿›ï¼Œå±•ç¤ºäº†è¿™äº›æŠ€æœ¯ä½œä¸ºä¸‹ä¸€ä»£è‡ªåŠ¨åŒ–å’ŒæŠ€æœ¯èåˆå‚¬åŒ–å‰‚çš„å˜é©æ€§åŠ›é‡ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.RO"
      ],
      "primary_category": "cs.NI",
      "comment": "Published in: 2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI), IEEE Xplore, DOI: 10.1109/RICAI64321.2024.10911316. \\c{opyright} 2024 IEEE",
      "pdf_url": "https://arxiv.org/pdf/2506.22477v1",
      "published_date": "2025-06-22 00:12:20 UTC",
      "updated_date": "2025-06-22 00:12:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:44:39.850672+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 86,
  "processed_papers_count": 86,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-23T23:45:37.843082+00:00"
}